From sven.demaeyer at ua.ac.be  Thu Oct  1 22:49:29 2009
From: sven.demaeyer at ua.ac.be (Sven De Maeyer)
Date: Thu, 1 Oct 2009 22:49:29 +0200
Subject: [R-sig-ME] complex cross classified model
Message-ID: <DBD81D7A-918D-4CC0-A46A-2ADCDE6BE258@ua.ac.be>

Hi all,

I'm analysing data with the following structure:828 students nested  
within 138 schools. Every student supplied 13 items (wright/wrong).  
The data set contains 13 lines for every student. I consider a random  
effect for items as well. The model was set-up as follows, with the  
resulting output are presented at the bottom. My question now is  
whether setting-up the model like this implies that ITEM and IDSTUD  
are crossed and IDSTUD's are nested within SCHOOLS. Or do I make a  
mistake here?

 > Model1<-lmer(SCORE~1+(1|IDSCHOOL)+(1|IDSCHOOL:IDSTUD)+(1| 
ITEM),data=Items, family=binomial)
 > summary(Model1)
Generalized linear mixed model fit using Laplace
Formula: SCORE ~ 1 + (1 | IDSCHOOL) + (1 | IDSCHOOL:IDSTUD) + (1 | ITEM)
    Data: Items
  Family: binomial(logit link)
    AIC   BIC logLik deviance
  10761 10790  -5376    10753
Random effects:
  Groups          Name        Variance Std.Dev.
  IDSCHOOL:IDSTUD (Intercept) 0.772882 0.87914
  IDSCHOOL        (Intercept) 0.076846 0.27721
  ITEM            (Intercept) 1.727892 1.31449
number of obs: 10764, groups: IDSCHOOL:IDSTUD, 828; IDSCHOOL, 138;  
ITEM, 13

Estimated scale (compare to  1 )  0.9272256

Fixed effects:
             Estimate Std. Error z value Pr(>|z|)
(Intercept)   0.8852     0.3676   2.408   0.0160 *
---

With kind regards,

Sven De Maeyer
University of Antwerp



From steffi.lazerte at mail.mcgill.ca  Fri Oct  2 01:15:37 2009
From: steffi.lazerte at mail.mcgill.ca (Stefanie LaZerte)
Date: Thu, 01 Oct 2009 19:15:37 -0400
Subject: [R-sig-ME] Probability of Independence in lmer with categorical
	variables
Message-ID: <4AC53819.40009@mail.mcgill.ca>

Hi,

I've been reading through this list's archives for the better part of a
year and have always managed to find the solution to my problems.
However, this time I'm stumped.

I'm performing a path analysis (structural equation model) using the
d-separation technique developed by Bill Shipley. What it boils down to
is many tests of independence between different variables while
controlling for other variables in the model. The numeric results of
these tests of independence (namely, the p-values) are then combined in
a statistic that tests the fit of the model as a whole.

Right now I'm having problems getting a value of the probability of
independence between variables when one is categorical. The lmer
function calculates the estimates and probabilities for each level of
the variable I'm interested in, instead of the variable as a whole.
Since lmer doesn't have support for the anova() function, I cannot
determine the probability of each factor that way, either.

I was wondering if anyone was aware of a way to determine the overall
probability of independence for a categorical variable in lmer? I'm
pretty sure that the anova table question has been asked to death, but
if there's another way, or a manual way, of calculating it, I'd be much
obliged!

Thanks for any help or advice,

Stefanie LaZerte


For clarity, below is the example I'm having trouble with:

For the activity of chipmunks measured each day and each night for each
individual over a period of 3 months
day = continuous, activity throughout the day
night = binary, 0/1, activity at night
sex = binary, F/M
seasons = categorical (5 levels)
ID = individual ID

Here I want the probability of night being independent from seasons
while controlling for day and seasons:sex and controlling in a
mixed-model way for the repeated measures on individuals. Bear in mind
that this is a nonesense model in that I'm simply using it to derive the
independence between variables.

m=lmer(night~day+seasons:sex+seasons+(1|ID), data=data,
na.action=na.omit,family=binomial)

Fixed effects:
		   Estimate Std.  Error     z value  Pr(>|z|)
(Intercept) 		-2.65001  0.79877   -3.318   0.000908 ***
day			 5.88333  1.25466   4.689    2.74e-06 ***
seasonsLull 		2.12974   1.01252   2.103    0.035431 *
seasonsEnd Lull 	1.47929   0.89018   1.662    0.096556 .
seasonspost lull 	1.85385   0.83792   2.212    0.026936 *
seasonsPost-post lull 	0.96935   0.87141   1.112    0.265968
seasonsStart Lull:sexF 	0.47920   0.95042   0.504    0.614120
seasonsLull:sexF 	-0.22464  0.89293   -0.252   0.801368
seasonsEnd Lull:sexF 	-0.17084  0.65332   -0.261   0.793714
seasonspost lull:sexF 	0.16982   0.47757   0.356    0.722146
seasonsPost-post lull:sexF  -0.08716   0.73669 -0.118   0.905816



From bates at stat.wisc.edu  Fri Oct  2 14:04:03 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 2 Oct 2009 07:04:03 -0500
Subject: [R-sig-ME] complex cross classified model
In-Reply-To: <DBD81D7A-918D-4CC0-A46A-2ADCDE6BE258@ua.ac.be>
References: <DBD81D7A-918D-4CC0-A46A-2ADCDE6BE258@ua.ac.be>
Message-ID: <40e66e0b0910020504x756a0b5fl901de3c1c918d540@mail.gmail.com>

On Thu, Oct 1, 2009 at 3:49 PM, Sven De Maeyer <sven.demaeyer at ua.ac.be> wrote:
> Hi all,
>
> I'm analysing data with the following structure:828 students nested within
> 138 schools. Every student supplied 13 items (wright/wrong). The data set
> contains 13 lines for every student. I consider a random effect for items as
> well. The model was set-up as follows, with the resulting output are
> presented at the bottom. My question now is whether setting-up the model
> like this implies that ITEM and IDSTUD are crossed and IDSTUD's are nested
> within SCHOOLS. Or do I make a mistake here?
>
>> Model1<-lmer(SCORE~1+(1|IDSCHOOL)+(1|IDSCHOOL:IDSTUD)+(1|ITEM),data=Items,
>> family=binomial)
>> summary(Model1)
> Generalized linear mixed model fit using Laplace
> Formula: SCORE ~ 1 + (1 | IDSCHOOL) + (1 | IDSCHOOL:IDSTUD) + (1 | ITEM)
> ? Data: Items
> ?Family: binomial(logit link)
> ? AIC ? BIC logLik deviance
> ?10761 10790 ?-5376 ? ?10753
> Random effects:
> ?Groups ? ? ? ? ?Name ? ? ? ?Variance Std.Dev.
> ?IDSCHOOL:IDSTUD (Intercept) 0.772882 0.87914
> ?IDSCHOOL ? ? ? ?(Intercept) 0.076846 0.27721
> ?ITEM ? ? ? ? ? ?(Intercept) 1.727892 1.31449
> number of obs: 10764, groups: IDSCHOOL:IDSTUD, 828; IDSCHOOL, 138; ITEM, 13
>
> Estimated scale (compare to ?1 ) ?0.9272256
>
> Fixed effects:
> ? ? ? ? ? ?Estimate Std. Error z value Pr(>|z|)
> (Intercept) ? 0.8852 ? ? 0.3676 ? 2.408 ? 0.0160 *
> ---

That model specification seems fine to me.  If the student labels are
828 unique labels (that is, if it is not the case that different
schools can each have a student with the same IDSTUD) then the
specification (1|IDSCHOOL:IDSTUD) could be shortened to (1|IDSTUD).
However, specifying  (1|IDSCHOOL:IDSTUD) is not harmful in any way and
is safer so I would stay with that.

When random effects are associated with different factors, lmer does
not distinguish between nested and non-nested factors.  It just uses
the factors as they are specified.  In fact, the calculations are
identical for nested or non-nested.  The only thing that happens with
nested factors is that some of the model structures are simpler but
that is a side-effect, not an assumed property.

I think I am running the risk of over-explaining, a common fault of
mine.  The short answer is that you have got it right.



From izahn at psych.rochester.edu  Tue Oct  6 21:35:06 2009
From: izahn at psych.rochester.edu (Ista Zahn)
Date: Tue, 6 Oct 2009 15:35:06 -0400
Subject: [R-sig-ME] Design question about repeated measures as nested vs
	crossed structures
Message-ID: <f55e7cf50910061235s2f0d3b06q4339d4f0314a469e@mail.gmail.com>

Sorry for the off-topic post, I've been struggling to understand
something and don't know where else to turn. I don't understand the
distinction between nested and cross classified, and I'd really
appreciate if someone can take a moment to set me straight. The
example below illustrates my confusion.

I often read/hear multivariate measures data described as nested, but
this doesn't make sense to me. Here is a typical explanation from
http://www.cmm.bris.ac.uk/lemma/mod/lesson/view.php?id=255:

"Sometimes we may wish to model more than one response. For example,
we may wish to consider jointly English and mathematics exam scores
for students because the two responses are likely to be related. We
can regard this as a multilevel structure with subjects (English and
maths) nested within students as shown in Figure 4.5. ..." (the figure
is here: http://www.cmm.bris.ac.uk/lemma/file.php/13/images-C4/image007.gif).

To my mind this sounds cross-classified, because each observation is a
particular combination of person and exam subject. It seems to make
just as much sense to describe these data as participant nested within
exam subject, as I've diagrammed here:
http://ista.scp.rochester.edu/snapshot1.png.

Please, if anyone can clear this up for me I'd really appreciate it.

-Ista

-- 
Ista Zahn
Graduate student
University of Rochester
Department of Clinical and Social Psychology
http://yourpsyche.org



From HDoran at air.org  Tue Oct  6 21:47:32 2009
From: HDoran at air.org (Doran, Harold)
Date: Tue, 6 Oct 2009 15:47:32 -0400
Subject: [R-sig-ME] Design question about repeated measures as nested
	vscrossed structures
In-Reply-To: <f55e7cf50910061235s2f0d3b06q4339d4f0314a469e@mail.gmail.com>
Message-ID: <ED7B522EE00C9A4FA515AA71724D61EE0202DA17@DC1EXCL01.air.org>

Ista

We have a description of what this means in the paper in the link below.
See section 1.6 of the paper. Using your example below, whether or not
the multiple observations are nested would depend on the setting in
which they were observed. For instance, if all students had two scores
and both of those scores were observed in one and only one classroom,
you would have a nested design. 

If some students had one of those scores observed with teacher i and
another observed with teacher i', then your design would be partially
crossed.

If every student had one observation observed in one class and the
second observation in a different class, you would have a fully crossed
design.

http://www.jstatsoft.org/v20/i02/paper

 

> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org 
> [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf 
> Of Ista Zahn
> Sent: Tuesday, October 06, 2009 3:35 PM
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] Design question about repeated measures 
> as nested vscrossed structures
> 
> Sorry for the off-topic post, I've been struggling to 
> understand something and don't know where else to turn. I 
> don't understand the distinction between nested and cross 
> classified, and I'd really appreciate if someone can take a 
> moment to set me straight. The example below illustrates my confusion.
> 
> I often read/hear multivariate measures data described as 
> nested, but this doesn't make sense to me. Here is a typical 
> explanation from
> http://www.cmm.bris.ac.uk/lemma/mod/lesson/view.php?id=255:
> 
> "Sometimes we may wish to model more than one response. For 
> example, we may wish to consider jointly English and 
> mathematics exam scores for students because the two 
> responses are likely to be related. We can regard this as a 
> multilevel structure with subjects (English and
> maths) nested within students as shown in Figure 4.5. ..." 
> (the figure is here: 
> http://www.cmm.bris.ac.uk/lemma/file.php/13/images-C4/image007.gif).
> 
> To my mind this sounds cross-classified, because each 
> observation is a particular combination of person and exam 
> subject. It seems to make just as much sense to describe 
> these data as participant nested within exam subject, as I've 
> diagrammed here:
> http://ista.scp.rochester.edu/snapshot1.png.
> 
> Please, if anyone can clear this up for me I'd really appreciate it.
> 
> -Ista
> 
> --
> Ista Zahn
> Graduate student
> University of Rochester
> Department of Clinical and Social Psychology http://yourpsyche.org
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 



From pauljohn32 at gmail.com  Tue Oct  6 21:57:48 2009
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Tue, 6 Oct 2009 14:57:48 -0500
Subject: [R-sig-ME] Links to that "slow" lmer example I asked about
Message-ID: <13e802630910061257o58263f62k6fa6c87e85bfc868@mail.gmail.com>

Dear Everybody:

I asked a couple of weeks ago about the puzzle that my colleague's
linear mixed model can be estimated in HLM6 in 3 seconds, while lmer
requires about 50 seconds.  I wondered if that was expected/known.

The discussion seemed to end with the conclusion "if you expect us to
evaluate that, give us the working example."  Due to a death in my
family, I was delayed in responding, but here are the links to the
example data and code.

The data frame is saved with R's write function

http://pj.freefaculty.org/R/MixedModel/myframe.Rdata

I believe that is workable on all platforms. That's about 26,000 rows.
Variable V33 represents the groups (in this case, country).  The
variables are generically named V1-V33.

The small simple test program to load the data and estimate the model:

http://pj.freefaculty.org/R/MixedModel/replicateMM.R

The output I get, which has system.time wrapped around the use of lmer:

http://pj.freefaculty.org/R/MixedModel/replicateMM.Rout

I get
##  user  system elapsed
##55.448   0.216  55.756

Please remember I am not saying that lmer should work faster.  I
understand it is capable of estimating models that other programs
cannot.  I'm only trying to explain to a user why this one linear
model takes more time in lmer than in HLM6.

pj
-- 
Paul E. Johnson
Professor, Political Science
1541 Lilac Lane, Room 504
University of Kansas



From r.turner at auckland.ac.nz  Tue Oct  6 22:11:21 2009
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Wed, 7 Oct 2009 09:11:21 +1300
Subject: [R-sig-ME] Design question about repeated measures as nested vs
	crossed structures
In-Reply-To: <f55e7cf50910061235s2f0d3b06q4339d4f0314a469e@mail.gmail.com>
References: <f55e7cf50910061235s2f0d3b06q4339d4f0314a469e@mail.gmail.com>
Message-ID: <D21B2007-EBC5-419F-8E2F-344687DB93CE@auckland.ac.nz>


On 7/10/2009, at 8:35 AM, Ista Zahn wrote:

> Sorry for the off-topic post, I've been struggling to understand
> something and don't know where else to turn. I don't understand the
> distinction between nested and cross classified, and I'd really
> appreciate if someone can take a moment to set me straight. The
> example below illustrates my confusion.
>
> I often read/hear multivariate measures data described as nested, but
> this doesn't make sense to me. Here is a typical explanation from
> http://www.cmm.bris.ac.uk/lemma/mod/lesson/view.php?id=255:
>
> "Sometimes we may wish to model more than one response. For example,
> we may wish to consider jointly English and mathematics exam scores
> for students because the two responses are likely to be related. We
> can regard this as a multilevel structure with subjects (English and
> maths) nested within students as shown in Figure 4.5. ..." (the figure
> is here: http://www.cmm.bris.ac.uk/lemma/file.php/13/images-C4/ 
> image007.gif).
>
> To my mind this sounds cross-classified, because each observation is a
> particular combination of person and exam subject. It seems to make
> just as much sense to describe these data as participant nested within
> exam subject, as I've diagrammed here:
> http://ista.scp.rochester.edu/snapshot1.png.
>
> Please, if anyone can clear this up for me I'd really appreciate it.

Dunno if I can clear this up for you.  Unfortunately I usually feel as
confused as you are feeling.  But for what it's worth, my opinion is  
that
the paragraph in quote marks given above is a load of dingos' kidneys  
and
those who wrote it haven't a clue.

Specifically you are *correct* in saying that the design is  
*crossed*. You
have an observation on each student-(exam subject) combination.

Your diagram showing student nested within exam subject is misleading.
Presumably ``St1'' under E is the same student as ``St1'' under M, etc.
You only get nesting if the set of students taking English exams is
different from the set of students taking Maths exams.

Of course you could have partial overlap, in which case you'd get what
I think is called ``partial nesting'', but that's a whole other can of
worms.

Of course the structure described --- with just the two factors
``student'' and ``exam subject'' is so simple that discussing it in
terms of crossing and nesting is overkill.  If the students doing
the maths exam and the students doing the english exam are the same
students you have a ``paired design'' which would usually (rightly
or wrongly) be analyzed via a paired t-test (or possibly the
non-parametric equivalent).  If the students constitute two different
sets of students then you'd have a ``two independent samples'' setting,
and analyze via a two-sample t-test or the non-parametric equivalent.

[In either case the only (possibly) concern would be to make inferences
about the difference between the population mean maths exam score and
the population mean english exam score.  Which is kind of silly anyhow
since you'd be comparing apples and oranges; but that's another story.]

I hope this clarifies more than it obscures.

	cheers,

		Rolf Turner

######################################################################
Attention:\ This e-mail message is privileged and confid...{{dropped:9}}



From bates at stat.wisc.edu  Tue Oct  6 22:11:31 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 6 Oct 2009 15:11:31 -0500
Subject: [R-sig-ME] Design question about repeated measures as nested
	vscrossed structures
In-Reply-To: <ED7B522EE00C9A4FA515AA71724D61EE0202DA17@DC1EXCL01.air.org>
References: <f55e7cf50910061235s2f0d3b06q4339d4f0314a469e@mail.gmail.com>
	<ED7B522EE00C9A4FA515AA71724D61EE0202DA17@DC1EXCL01.air.org>
Message-ID: <40e66e0b0910061311t199108b7xb1515ff14e871985@mail.gmail.com>

On Tue, Oct 6, 2009 at 2:47 PM, Doran, Harold <HDoran at air.org> wrote:
> Ista
>
> We have a description of what this means in the paper in the link below.
> See section 1.6 of the paper. Using your example below, whether or not
> the multiple observations are nested would depend on the setting in
> which they were observed. For instance, if all students had two scores
> and both of those scores were observed in one and only one classroom,
> you would have a nested design.
>
> If some students had one of those scores observed with teacher i and
> another observed with teacher i', then your design would be partially
> crossed.
>
> If every student had one observation observed in one class and the
> second observation in a different class, you would have a fully crossed
> design.

I think Ista's point is somewhat different, Harold, and I would agree
with him that it is more appropriate to consider student and subject
as crossed factors, rather than as nested.

The figure in Ista's message indicates that there are two subjects and
scores for students nested within the subjects.  But that is not what
the description says.  We would generally expect that there would be a
student effect in common with the two scores  Some students may do
better in math than in English and vice versa for others but if we
plotted the two scores by student we would expect them to be
correlated.

Some of the discussion of nested versus non-nested has a "when all
that you have is a hammer, everything looks like a nail" nature to it.
 If you can't fit models with crossed or partially crossed random
effects then you look for ways to characterize effects as nested.

It is somewhat ironic that the motivating example, longitudinal
responses on subjects in some social context (e.g. school, classroom,
neighborhood), for hierarchical linear models or multilevel models
almost inevitably ends up with non-nested groupings.  All you need is
for one subject to move from one group to another over the course of
the study and you no longer have subjects nested within schools, say

This example is a bit different in that we may consider math versus
English to be a fixed-effect and model the random effects as a
vector-valued random effect by student.  We don't have to consider one
factor as nested within the other; we can just use random effects at
the student level but have one component for the math and one
component for the English.  That is, the model could be

score ~ subj + (0+subj|student)

>> -----Original Message-----
>> From: r-sig-mixed-models-bounces at r-project.org
>> [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf
>> Of Ista Zahn
>> Sent: Tuesday, October 06, 2009 3:35 PM
>> To: r-sig-mixed-models at r-project.org
>> Subject: [R-sig-ME] Design question about repeated measures
>> as nested vscrossed structures
>>
>> Sorry for the off-topic post, I've been struggling to
>> understand something and don't know where else to turn. I
>> don't understand the distinction between nested and cross
>> classified, and I'd really appreciate if someone can take a
>> moment to set me straight. The example below illustrates my confusion.
>>
>> I often read/hear multivariate measures data described as
>> nested, but this doesn't make sense to me. Here is a typical
>> explanation from
>> http://www.cmm.bris.ac.uk/lemma/mod/lesson/view.php?id=255:
>>
>> "Sometimes we may wish to model more than one response. For
>> example, we may wish to consider jointly English and
>> mathematics exam scores for students because the two
>> responses are likely to be related. We can regard this as a
>> multilevel structure with subjects (English and
>> maths) nested within students as shown in Figure 4.5. ..."
>> (the figure is here:
>> http://www.cmm.bris.ac.uk/lemma/file.php/13/images-C4/image007.gif).
>>
>> To my mind this sounds cross-classified, because each
>> observation is a particular combination of person and exam
>> subject. It seems to make just as much sense to describe
>> these data as participant nested within exam subject, as I've
>> diagrammed here:
>> http://ista.scp.rochester.edu/snapshot1.png.
>>
>> Please, if anyone can clear this up for me I'd really appreciate it.
>>
>> -Ista
>>
>> --
>> Ista Zahn
>> Graduate student
>> University of Rochester
>> Department of Clinical and Social Psychology http://yourpsyche.org
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From bates at stat.wisc.edu  Tue Oct  6 22:16:21 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 6 Oct 2009 15:16:21 -0500
Subject: [R-sig-ME] Design question about repeated measures as nested
	vscrossed structures
In-Reply-To: <40e66e0b0910061311t199108b7xb1515ff14e871985@mail.gmail.com>
References: <f55e7cf50910061235s2f0d3b06q4339d4f0314a469e@mail.gmail.com>
	<ED7B522EE00C9A4FA515AA71724D61EE0202DA17@DC1EXCL01.air.org>
	<40e66e0b0910061311t199108b7xb1515ff14e871985@mail.gmail.com>
Message-ID: <40e66e0b0910061316k602be85csffdb12b78b9a1024@mail.gmail.com>

In re-reading my posting I see that I have used the word "subject" in
two different ways, perhaps causing some confusion.  In the early
going my use of subject is to distinguish math from English.  In the
later going I slip into using subject as the observational unit, which
earlier I was calling student.  Sorry for the confusion.

On Tue, Oct 6, 2009 at 3:11 PM, Douglas Bates <bates at stat.wisc.edu> wrote:
> On Tue, Oct 6, 2009 at 2:47 PM, Doran, Harold <HDoran at air.org> wrote:
>> Ista
>>
>> We have a description of what this means in the paper in the link below.
>> See section 1.6 of the paper. Using your example below, whether or not
>> the multiple observations are nested would depend on the setting in
>> which they were observed. For instance, if all students had two scores
>> and both of those scores were observed in one and only one classroom,
>> you would have a nested design.
>>
>> If some students had one of those scores observed with teacher i and
>> another observed with teacher i', then your design would be partially
>> crossed.
>>
>> If every student had one observation observed in one class and the
>> second observation in a different class, you would have a fully crossed
>> design.
>
> I think Ista's point is somewhat different, Harold, and I would agree
> with him that it is more appropriate to consider student and subject
> as crossed factors, rather than as nested.
>
> The figure in Ista's message indicates that there are two subjects and
> scores for students nested within the subjects. ?But that is not what
> the description says. ?We would generally expect that there would be a
> student effect in common with the two scores ?Some students may do
> better in math than in English and vice versa for others but if we
> plotted the two scores by student we would expect them to be
> correlated.
>
> Some of the discussion of nested versus non-nested has a "when all
> that you have is a hammer, everything looks like a nail" nature to it.
> ?If you can't fit models with crossed or partially crossed random
> effects then you look for ways to characterize effects as nested.
>
> It is somewhat ironic that the motivating example, longitudinal
> responses on subjects in some social context (e.g. school, classroom,
> neighborhood), for hierarchical linear models or multilevel models
> almost inevitably ends up with non-nested groupings. ?All you need is
> for one subject to move from one group to another over the course of
> the study and you no longer have subjects nested within schools, say
>
> This example is a bit different in that we may consider math versus
> English to be a fixed-effect and model the random effects as a
> vector-valued random effect by student. ?We don't have to consider one
> factor as nested within the other; we can just use random effects at
> the student level but have one component for the math and one
> component for the English. ?That is, the model could be
>
> score ~ subj + (0+subj|student)
>
>>> -----Original Message-----
>>> From: r-sig-mixed-models-bounces at r-project.org
>>> [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf
>>> Of Ista Zahn
>>> Sent: Tuesday, October 06, 2009 3:35 PM
>>> To: r-sig-mixed-models at r-project.org
>>> Subject: [R-sig-ME] Design question about repeated measures
>>> as nested vscrossed structures
>>>
>>> Sorry for the off-topic post, I've been struggling to
>>> understand something and don't know where else to turn. I
>>> don't understand the distinction between nested and cross
>>> classified, and I'd really appreciate if someone can take a
>>> moment to set me straight. The example below illustrates my confusion.
>>>
>>> I often read/hear multivariate measures data described as
>>> nested, but this doesn't make sense to me. Here is a typical
>>> explanation from
>>> http://www.cmm.bris.ac.uk/lemma/mod/lesson/view.php?id=255:
>>>
>>> "Sometimes we may wish to model more than one response. For
>>> example, we may wish to consider jointly English and
>>> mathematics exam scores for students because the two
>>> responses are likely to be related. We can regard this as a
>>> multilevel structure with subjects (English and
>>> maths) nested within students as shown in Figure 4.5. ..."
>>> (the figure is here:
>>> http://www.cmm.bris.ac.uk/lemma/file.php/13/images-C4/image007.gif).
>>>
>>> To my mind this sounds cross-classified, because each
>>> observation is a particular combination of person and exam
>>> subject. It seems to make just as much sense to describe
>>> these data as participant nested within exam subject, as I've
>>> diagrammed here:
>>> http://ista.scp.rochester.edu/snapshot1.png.
>>>
>>> Please, if anyone can clear this up for me I'd really appreciate it.
>>>
>>> -Ista
>>>
>>> --
>>> Ista Zahn
>>> Graduate student
>>> University of Rochester
>>> Department of Clinical and Social Psychology http://yourpsyche.org
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>



From pauljohn32 at gmail.com  Tue Oct  6 22:19:14 2009
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Tue, 6 Oct 2009 15:19:14 -0500
Subject: [R-sig-ME] lme vs. lmer
In-Reply-To: <30406dd0909301240w456a19d9jd54966cd1c0fa43e@mail.gmail.com>
References: <4AC24A2D.2090606@umn.edu> <4AC24BB9.5000609@ufl.edu>
	<40e66e0b0909291132qcfce47awf8a1e527ea970544@mail.gmail.com>
	<4AC255CE.1090904@ufl.edu> <4AC27502.7070104@biostat.ku.dk>
	<40e66e0b0909291450s39bb48c2p1b3e372bcc52eed0@mail.gmail.com>
	<30406dd0909300245j78380cfesa28d4e056d99cd82@mail.gmail.com>
	<40e66e0b0909300920m53f79d7fke12dbe19bb6f7793@mail.gmail.com>
	<30406dd0909301240w456a19d9jd54966cd1c0fa43e@mail.gmail.com>
Message-ID: <13e802630910061319j7119c572m30779e98804e2014@mail.gmail.com>

On Wed, Sep 30, 2009 at 2:40 PM, Raldo Kruger <raldo.kruger at gmail.com> wrote:
> Chris,
> Thanks for that - I should probably have mentioned that I'm using
> family=quasipoisson ?in glmer since my data has Poisson distribution
> as well as being overdispersed. I'm unsure how one decides which term
> to drop without being informed by p-values, and so don't quite
> understand how the "Likelihood ratio test using anova()" , or the AIC
> or BIC model comparison will work in this case (I thought one's
> supposed to remove the term with the highest p-value from the model,
> and compare it with the model with the term included to see if there's
> a difference, not so?).

Dear Raldo:

Finally there is a question that I can help with!  It appears to me
you don't have much experience with regression modeling in R and the
other people who answer you are talking a bit "over your head".

In your case, call this fit the "full" or "unrestricted" model:

ex4o_r2<-glmer(Counts~N+G+Year+N:Year+G:Year+N:G:Year+(Year|Site),
data=ex4o, family=quasipoisson)

(I'm not commenting the specification).

Suppose you wonder "Should I leave out the multiplicative effect
between N and Year?"  THen you fit the model that excludes that one
element:

ex4o_new <-glmer(Counts~N+G+Year +G:Year+N:G:Year+(Year|Site),
data=ex4o, family=quasipoisson)

And then use the anova function to compare the 2 models

anova(ex4o_r2, ex4o_new)

This is a "pretty standard" R regression thing, similar to what people
do with all sorts of models in R.  It is what the "drop1" function
does for lm models, I believe.

You may have seen regression models where an F test is done comparing
a full model against a restricted model?  This is following the same
line of thought.

To test your question about the factor levels, here is what you should
do. SUppose the initial factor has 5 levels, and you wonder "do I
really need 5 levels, or can I drop out the separate estimations for 3
of the levels?"  Create a new factor with the simpler structure, run
it through the model in place of the original factor, and run anova to
compare the 2 models.  I wrote down some of those ideas in a paper
last spring (http://pj.freefaculty.org/Papers/MidWest09/Midwest09.pdf),
but when I was done it seemed so obvious to me (& my friends) that I
did not try to publish it.

With anova, there is a test= option where you can specify if you want
a chisq or F test.

And, for future reference, when the experts ask you for a data example
to work on, they do not mean a copy of your printout, although that
may help.  What they want is the actual data and commands that you
use.  Usually, you have to upload the data somewhere for us to see,
along with the code.

Good luck with your project.

pj

-- 
Paul E. Johnson
Professor, Political Science
1541 Lilac Lane, Room 504
University of Kansas



From izahn at psych.rochester.edu  Tue Oct  6 23:00:14 2009
From: izahn at psych.rochester.edu (Ista Zahn)
Date: Tue, 6 Oct 2009 17:00:14 -0400
Subject: [R-sig-ME] Design question about repeated measures as nested
	vscrossed structures
In-Reply-To: <40e66e0b0910061316k602be85csffdb12b78b9a1024@mail.gmail.com>
References: <f55e7cf50910061235s2f0d3b06q4339d4f0314a469e@mail.gmail.com> 
	<ED7B522EE00C9A4FA515AA71724D61EE0202DA17@DC1EXCL01.air.org> 
	<40e66e0b0910061311t199108b7xb1515ff14e871985@mail.gmail.com> 
	<40e66e0b0910061316k602be85csffdb12b78b9a1024@mail.gmail.com>
Message-ID: <f55e7cf50910061400j3b34b4fdpf1d03698e6ff2e48@mail.gmail.com>

Thanks for all the responses, it helps. Professor Turner -- I realize
my diagram showing students nested withing exam subject is misleading
-- my question was "why is it less misleading to diagram exam subject
as being nesting within students?". Your response, in conjunction with
Professor Bates' response helped clear that up for me (i.e., it
doesn't really make sense to describe nesting either way: it's
crossed!).

Also, I recognize (as you both pointed out) that the example is
somewhat trivial and with only two levels of exam subject there are
much simpler ways to look at it. I wanted to keep the example as
simple as possible in order to focus on the nested/crossed issue.

It's confusing when people use the "hammer and nail" approach,
especially as with the case I quoted the authors take care to
distinguish between crossed and nested structures in other contexts. I
had assumed that because they paid a lot of attention to this in a
previous discussion they would be careful with their examples, but I
think now they were just being a bit sloppy.

Thanks again for helping me understand.

-Ista

On Tue, Oct 6, 2009 at 4:16 PM, Douglas Bates <bates at stat.wisc.edu> wrote:
> In re-reading my posting I see that I have used the word "subject" in
> two different ways, perhaps causing some confusion. ?In the early
> going my use of subject is to distinguish math from English. ?In the
> later going I slip into using subject as the observational unit, which
> earlier I was calling student. ?Sorry for the confusion.
>
> On Tue, Oct 6, 2009 at 3:11 PM, Douglas Bates <bates at stat.wisc.edu> wrote:
>> On Tue, Oct 6, 2009 at 2:47 PM, Doran, Harold <HDoran at air.org> wrote:
>>> Ista
>>>
>>> We have a description of what this means in the paper in the link below.
>>> See section 1.6 of the paper. Using your example below, whether or not
>>> the multiple observations are nested would depend on the setting in
>>> which they were observed. For instance, if all students had two scores
>>> and both of those scores were observed in one and only one classroom,
>>> you would have a nested design.
>>>
>>> If some students had one of those scores observed with teacher i and
>>> another observed with teacher i', then your design would be partially
>>> crossed.
>>>
>>> If every student had one observation observed in one class and the
>>> second observation in a different class, you would have a fully crossed
>>> design.
>>
>> I think Ista's point is somewhat different, Harold, and I would agree
>> with him that it is more appropriate to consider student and subject
>> as crossed factors, rather than as nested.
>>
>> The figure in Ista's message indicates that there are two subjects and
>> scores for students nested within the subjects. ?But that is not what
>> the description says. ?We would generally expect that there would be a
>> student effect in common with the two scores ?Some students may do
>> better in math than in English and vice versa for others but if we
>> plotted the two scores by student we would expect them to be
>> correlated.
>>
>> Some of the discussion of nested versus non-nested has a "when all
>> that you have is a hammer, everything looks like a nail" nature to it.
>> ?If you can't fit models with crossed or partially crossed random
>> effects then you look for ways to characterize effects as nested.
>>
>> It is somewhat ironic that the motivating example, longitudinal
>> responses on subjects in some social context (e.g. school, classroom,
>> neighborhood), for hierarchical linear models or multilevel models
>> almost inevitably ends up with non-nested groupings. ?All you need is
>> for one subject to move from one group to another over the course of
>> the study and you no longer have subjects nested within schools, say
>>
>> This example is a bit different in that we may consider math versus
>> English to be a fixed-effect and model the random effects as a
>> vector-valued random effect by student. ?We don't have to consider one
>> factor as nested within the other; we can just use random effects at
>> the student level but have one component for the math and one
>> component for the English. ?That is, the model could be
>>
>> score ~ subj + (0+subj|student)
>>
>>>> -----Original Message-----
>>>> From: r-sig-mixed-models-bounces at r-project.org
>>>> [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf
>>>> Of Ista Zahn
>>>> Sent: Tuesday, October 06, 2009 3:35 PM
>>>> To: r-sig-mixed-models at r-project.org
>>>> Subject: [R-sig-ME] Design question about repeated measures
>>>> as nested vscrossed structures
>>>>
>>>> Sorry for the off-topic post, I've been struggling to
>>>> understand something and don't know where else to turn. I
>>>> don't understand the distinction between nested and cross
>>>> classified, and I'd really appreciate if someone can take a
>>>> moment to set me straight. The example below illustrates my confusion.
>>>>
>>>> I often read/hear multivariate measures data described as
>>>> nested, but this doesn't make sense to me. Here is a typical
>>>> explanation from
>>>> http://www.cmm.bris.ac.uk/lemma/mod/lesson/view.php?id=255:
>>>>
>>>> "Sometimes we may wish to model more than one response. For
>>>> example, we may wish to consider jointly English and
>>>> mathematics exam scores for students because the two
>>>> responses are likely to be related. We can regard this as a
>>>> multilevel structure with subjects (English and
>>>> maths) nested within students as shown in Figure 4.5. ..."
>>>> (the figure is here:
>>>> http://www.cmm.bris.ac.uk/lemma/file.php/13/images-C4/image007.gif).
>>>>
>>>> To my mind this sounds cross-classified, because each
>>>> observation is a particular combination of person and exam
>>>> subject. It seems to make just as much sense to describe
>>>> these data as participant nested within exam subject, as I've
>>>> diagrammed here:
>>>> http://ista.scp.rochester.edu/snapshot1.png.
>>>>
>>>> Please, if anyone can clear this up for me I'd really appreciate it.
>>>>
>>>> -Ista
>>>>
>>>> --
>>>> Ista Zahn
>>>> Graduate student
>>>> University of Rochester
>>>> Department of Clinical and Social Psychology http://yourpsyche.org
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>



-- 
Ista Zahn
Graduate student
University of Rochester
Department of Clinical and Social Psychology
http://yourpsyche.org



From bates at stat.wisc.edu  Tue Oct  6 23:44:12 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 6 Oct 2009 16:44:12 -0500
Subject: [R-sig-ME] Links to that "slow" lmer example I asked about
In-Reply-To: <13e802630910061257o58263f62k6fa6c87e85bfc868@mail.gmail.com>
References: <13e802630910061257o58263f62k6fa6c87e85bfc868@mail.gmail.com>
Message-ID: <40e66e0b0910061444i3eb40358jfc46874f0566b46b@mail.gmail.com>

Thanks for providing the data, Paui.  As I said in a private message,
this helps a lot to be able to discuss a concrete example and I thank
your colleague for allowing you to provide these.

My initial timing is using the development version of the lme4
package, the so-called lme4a.  I separated the creation of the
structures from the actual optimization.  Setup takes about 3 seconds,
optimization with nlminb about 7 seconds and optimization with bobyqa
about 3.5 seconds.

This was done on my desktop computer - a dual-core 2.0 GHz AMD64 with
4GB of memory.

On Tue, Oct 6, 2009 at 2:57 PM, Paul Johnson <pauljohn32 at gmail.com> wrote:
> Dear Everybody:
>
> I asked a couple of weeks ago about the puzzle that my colleague's
> linear mixed model can be estimated in HLM6 in 3 seconds, while lmer
> requires about 50 seconds. ?I wondered if that was expected/known.
>
> The discussion seemed to end with the conclusion "if you expect us to
> evaluate that, give us the working example." ?Due to a death in my
> family, I was delayed in responding, but here are the links to the
> example data and code.
>
> The data frame is saved with R's write function
>
> http://pj.freefaculty.org/R/MixedModel/myframe.Rdata
>
> I believe that is workable on all platforms. That's about 26,000 rows.
> Variable V33 represents the groups (in this case, country). ?The
> variables are generically named V1-V33.
>
> The small simple test program to load the data and estimate the model:
>
> http://pj.freefaculty.org/R/MixedModel/replicateMM.R
>
> The output I get, which has system.time wrapped around the use of lmer:
>
> http://pj.freefaculty.org/R/MixedModel/replicateMM.Rout
>
> I get
> ## ?user ?system elapsed
> ##55.448 ? 0.216 ?55.756
>
> Please remember I am not saying that lmer should work faster. ?I
> understand it is capable of estimating models that other programs
> cannot. ?I'm only trying to explain to a user why this one linear
> model takes more time in lmer than in HLM6.
>
> pj
> --
> Paul E. Johnson
> Professor, Political Science
> 1541 Lilac Lane, Room 504
> University of Kansas
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
-------------- next part --------------

R version 2.11.0 Under development (unstable) (2009-10-06 r49951)
Copyright (C) 2009 The R Foundation for Statistical Computing
ISBN 3-900051-07-0

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> ## crude benchmark of speed on numerical linear algebra
> mm <- matrix(rnorm(1000 * 1000), nc = 1000)
> system.time(solve(mm, rnorm(1000)))
   user  system elapsed 
  0.628   0.012   0.652 
> system.time(solve(mm, rnorm(1000)))
   user  system elapsed 
  0.300   0.008   0.309 
> system.time(solve(mm, rnorm(1000)))
   user  system elapsed 
  0.296   0.012   0.308 
> rm(mm)
> 
> 
> load(url("http://pj.freefaculty.org/R/MixedModel/myframe.Rdata"))
> attr(myframe, "terms") <- NULL
> attr(myframe, "na.action") <- NULL
> 
> str(myframe)
'data.frame':	23898 obs. of  33 variables:
 $ V1 : num  5 5 5 3 7 9 9 4 7 9 ...
 $ V2 : num  4 4 4 4 5 2 4 3 4 4 ...
 $ V3 : num  28335 28335 28335 28335 28335 ...
 $ V4 : num  4.78 4.78 4.78 4.78 4.78 ...
 $ V5 : num  2 0 0 1 0 0 0 0 0 0 ...
 $ V6 : num  5 5 3 2 4 2 3 2 4 4 ...
 $ V7 : num  3 1 1 2 1 2 1 2 1 1 ...
 $ V8 : num  2 2 2 4 1 1 1 4 2 1 ...
 $ V9 : num  2 1 2 2 2 2 1 4 2 1 ...
 $ V10: num  1 0 0 0 1 0 1 1 0 1 ...
 $ V11: num  0 0 1 1 0 1 0 0 0 0 ...
 $ V12: num  0 1 0 0 0 0 0 0 0 0 ...
 $ V13: num  0 0 1 0 0 1 0 0 0 0 ...
 $ V14: num  0 0 0 0 0 0 0 0 0 0 ...
 $ V15: num  0 0 0 1 0 0 1 0 0 0 ...
 $ V16: num  0 0 0 0 0 0 0 0 0 0 ...
 $ V17: num  0 0 0 0 0 0 0 0 0 0 ...
 $ V18: num  1 1 1 1 1 1 1 2 2 1 ...
 $ V19: num  0 0 0 0 0 0 1 0 0 0 ...
 $ V20: num  1 0 1 1 1 1 0 0 1 0 ...
 $ V21: num  0 1 0 0 0 0 0 0 0 0 ...
 $ V22: num  0 0 0 0 0 0 0 0 0 0 ...
 $ V23: num  0 0 1 1 1 0 0 0 0 0 ...
 $ V24: num  0 0 0 0 0 0 1 0 0 1 ...
 $ V25: num  0 1 0 0 0 1 0 0 1 0 ...
 $ V26: num  1 0 1 0 1 1 -1 0 1 1 ...
 $ V27: num  0 0 0 0 2 0 1 1 0 1 ...
 $ V28: num  2 1 3 2 2 3 2 1 1 2 ...
 $ V29: num  0 0 0 0 0 0 0 0 0 0 ...
 $ V30: num  0 0 0 0 8 0 3 2 0 4 ...
 $ V31: num  0 0 0 0 10 0 4 3 0 4 ...
 $ V32: num  0 0 0 0 2 0 -1 0 0 1 ...
 $ V33: Factor w/ 25 levels "Austria","Belgium",..: 2 2 2 2 2 2 2 2 2 2 ...
> summary(myframe)
       V1              V2              V3              V4       
 Min.   :3.000   Min.   :2.000   Min.   :10270   Min.   :1.260  
 1st Qu.:5.000   1st Qu.:4.000   1st Qu.:16357   1st Qu.:2.000  
 Median :7.000   Median :4.000   Median :26750   Median :3.930  
 Mean   :6.315   Mean   :4.089   Mean   :23385   Mean   :3.758  
 3rd Qu.:8.000   3rd Qu.:5.000   3rd Qu.:27756   3rd Qu.:5.680  
 Max.   :9.000   Max.   :6.000   Max.   :62298   Max.   :6.530  
                                                                
       V5               V6              V7              V8       
 Min.   :0.0000   Min.   :2.000   Min.   :1.000   Min.   :1.000  
 1st Qu.:0.0000   1st Qu.:2.000   1st Qu.:1.000   1st Qu.:1.000  
 Median :0.0000   Median :4.000   Median :1.000   Median :1.000  
 Mean   :0.4353   Mean   :3.562   Mean   :1.545   Mean   :1.708  
 3rd Qu.:1.0000   3rd Qu.:4.000   3rd Qu.:2.000   3rd Qu.:2.000  
 Max.   :2.0000   Max.   :6.000   Max.   :3.000   Max.   :5.000  
                                                                 
       V9            V10              V11              V12         
 Min.   :1.00   Min.   :0.0000   Min.   :0.0000   Min.   :0.00000  
 1st Qu.:2.00   1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.00000  
 Median :2.00   Median :0.0000   Median :0.0000   Median :0.00000  
 Mean   :2.61   Mean   :0.4377   Mean   :0.3108   Mean   :0.01151  
 3rd Qu.:4.00   3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:0.00000  
 Max.   :6.00   Max.   :1.0000   Max.   :1.0000   Max.   :1.00000  
                                                                   
      V13               V14              V15              V16         
 Min.   :0.00000   Min.   :0.0000   Min.   :0.0000   Min.   :0.00000  
 1st Qu.:0.00000   1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.00000  
 Median :0.00000   Median :0.0000   Median :0.0000   Median :0.00000  
 Mean   :0.07164   Mean   :0.1809   Mean   :0.1493   Mean   :0.05415  
 3rd Qu.:0.00000   3rd Qu.:0.0000   3rd Qu.:0.0000   3rd Qu.:0.00000  
 Max.   :1.00000   Max.   :1.0000   Max.   :1.0000   Max.   :1.00000  
                                                                      
      V17              V18             V19              V20        
 Min.   :0.0000   Min.   :1.000   Min.   :0.0000   Min.   :0.0000  
 1st Qu.:0.0000   1st Qu.:1.000   1st Qu.:0.0000   1st Qu.:0.0000  
 Median :0.0000   Median :2.000   Median :0.0000   Median :0.0000  
 Mean   :0.1783   Mean   :1.556   Mean   :0.1577   Mean   :0.3507  
 3rd Qu.:0.0000   3rd Qu.:2.000   3rd Qu.:0.0000   3rd Qu.:1.0000  
 Max.   :1.0000   Max.   :2.000   Max.   :1.0000   Max.   :1.0000  
                                                                   
      V21              V22               V23              V24        
 Min.   :0.0000   Min.   :0.00000   Min.   :0.0000   Min.   :0.0000  
 1st Qu.:0.0000   1st Qu.:0.00000   1st Qu.:0.0000   1st Qu.:0.0000  
 Median :0.0000   Median :0.00000   Median :0.0000   Median :0.0000  
 Mean   :0.2678   Mean   :0.07595   Mean   :0.2111   Mean   :0.2652  
 3rd Qu.:1.0000   3rd Qu.:0.00000   3rd Qu.:0.0000   3rd Qu.:1.0000  
 Max.   :1.0000   Max.   :1.00000   Max.   :1.0000   Max.   :1.0000  
                                                                     
      V25              V26                V27              V28       
 Min.   :0.0000   Min.   :-3.00000   Min.   :0.0000   Min.   :1.000  
 1st Qu.:0.0000   1st Qu.: 0.00000   1st Qu.:0.0000   1st Qu.:1.000  
 Median :0.0000   Median : 0.00000   Median :1.0000   Median :2.000  
 Mean   :0.2466   Mean   : 0.08398   Mean   :0.9125   Mean   :1.899  
 3rd Qu.:0.0000   3rd Qu.: 0.00000   3rd Qu.:1.0000   3rd Qu.:2.000  
 Max.   :1.0000   Max.   : 3.00000   Max.   :2.0000   Max.   :3.000  
                                                                     
      V29              V30              V31              V32          
 Min.   :0.0000   Min.   : 0.000   Min.   : 0.000   Min.   :-6.00000  
 1st Qu.:0.0000   1st Qu.: 0.000   1st Qu.: 0.000   1st Qu.: 0.00000  
 Median :0.0000   Median : 3.000   Median : 4.000   Median : 0.00000  
 Mean   :0.3912   Mean   : 3.155   Mean   : 3.679   Mean   : 0.03741  
 3rd Qu.:0.0000   3rd Qu.: 4.000   3rd Qu.: 5.000   3rd Qu.: 0.00000  
 Max.   :4.0000   Max.   :12.000   Max.   :12.000   Max.   : 6.00000  
                                                                      
            V33       
 Slovakia     : 1245  
 CzechRepublic: 1069  
 WGermany     : 1033  
 Denmark      : 1027  
 Spain        : 1019  
 France       : 1018  
 (Other)      :17487  
Warning message:
closing unused connection 3 (gzcon(http://pj.freefaculty.org/R/MixedModel/myframe.Rdata)) 
> ## several variables are binary and probably should be recoded as factors
> sapply(myframe, function(v) length(unique(v)))
 V1  V2  V3  V4  V5  V6  V7  V8  V9 V10 V11 V12 V13 V14 V15 V16 V17 V18 V19 V20 
  7   5  24  24   3   5   3   5   6   2   2   2   2   2   2   2   2   2   2   2 
V21 V22 V23 V24 V25 V26 V27 V28 V29 V30 V31 V32 V33 
  2   2   2   2   2   7   3   3   4   9   9  11  25 
> myframeA <-
+     do.call(data.frame, lapply(myframe,
+                                function(v)
+                                if(length(unique(v)) == 2) factor(v) else v))
> str(myframeA)
'data.frame':	23898 obs. of  33 variables:
 $ V1 : num  5 5 5 3 7 9 9 4 7 9 ...
 $ V2 : num  4 4 4 4 5 2 4 3 4 4 ...
 $ V3 : num  28335 28335 28335 28335 28335 ...
 $ V4 : num  4.78 4.78 4.78 4.78 4.78 ...
 $ V5 : num  2 0 0 1 0 0 0 0 0 0 ...
 $ V6 : num  5 5 3 2 4 2 3 2 4 4 ...
 $ V7 : num  3 1 1 2 1 2 1 2 1 1 ...
 $ V8 : num  2 2 2 4 1 1 1 4 2 1 ...
 $ V9 : num  2 1 2 2 2 2 1 4 2 1 ...
 $ V10: Factor w/ 2 levels "0","1": 2 1 1 1 2 1 2 2 1 2 ...
 $ V11: Factor w/ 2 levels "0","1": 1 1 2 2 1 2 1 1 1 1 ...
 $ V12: Factor w/ 2 levels "0","1": 1 2 1 1 1 1 1 1 1 1 ...
 $ V13: Factor w/ 2 levels "0","1": 1 1 2 1 1 2 1 1 1 1 ...
 $ V14: Factor w/ 2 levels "0","1": 1 1 1 1 1 1 1 1 1 1 ...
 $ V15: Factor w/ 2 levels "0","1": 1 1 1 2 1 1 2 1 1 1 ...
 $ V16: Factor w/ 2 levels "0","1": 1 1 1 1 1 1 1 1 1 1 ...
 $ V17: Factor w/ 2 levels "0","1": 1 1 1 1 1 1 1 1 1 1 ...
 $ V18: Factor w/ 2 levels "1","2": 1 1 1 1 1 1 1 2 2 1 ...
 $ V19: Factor w/ 2 levels "0","1": 1 1 1 1 1 1 2 1 1 1 ...
 $ V20: Factor w/ 2 levels "0","1": 2 1 2 2 2 2 1 1 2 1 ...
 $ V21: Factor w/ 2 levels "0","1": 1 2 1 1 1 1 1 1 1 1 ...
 $ V22: Factor w/ 2 levels "0","1": 1 1 1 1 1 1 1 1 1 1 ...
 $ V23: Factor w/ 2 levels "0","1": 1 1 2 2 2 1 1 1 1 1 ...
 $ V24: Factor w/ 2 levels "0","1": 1 1 1 1 1 1 2 1 1 2 ...
 $ V25: Factor w/ 2 levels "0","1": 1 2 1 1 1 2 1 1 2 1 ...
 $ V26: num  1 0 1 0 1 1 -1 0 1 1 ...
 $ V27: num  0 0 0 0 2 0 1 1 0 1 ...
 $ V28: num  2 1 3 2 2 3 2 1 1 2 ...
 $ V29: num  0 0 0 0 0 0 0 0 0 0 ...
 $ V30: num  0 0 0 0 8 0 3 2 0 4 ...
 $ V31: num  0 0 0 0 10 0 4 3 0 4 ...
 $ V32: num  0 0 0 0 2 0 -1 0 0 1 ...
 $ V33: Factor w/ 25 levels "Austria","Belgium",..: 2 2 2 2 2 2 2 2 2 2 ...
> summary(myframeA)
       V1              V2              V3              V4       
 Min.   :3.000   Min.   :2.000   Min.   :10270   Min.   :1.260  
 1st Qu.:5.000   1st Qu.:4.000   1st Qu.:16357   1st Qu.:2.000  
 Median :7.000   Median :4.000   Median :26750   Median :3.930  
 Mean   :6.315   Mean   :4.089   Mean   :23385   Mean   :3.758  
 3rd Qu.:8.000   3rd Qu.:5.000   3rd Qu.:27756   3rd Qu.:5.680  
 Max.   :9.000   Max.   :6.000   Max.   :62298   Max.   :6.530  
                                                                
       V5               V6              V7              V8       
 Min.   :0.0000   Min.   :2.000   Min.   :1.000   Min.   :1.000  
 1st Qu.:0.0000   1st Qu.:2.000   1st Qu.:1.000   1st Qu.:1.000  
 Median :0.0000   Median :4.000   Median :1.000   Median :1.000  
 Mean   :0.4353   Mean   :3.562   Mean   :1.545   Mean   :1.708  
 3rd Qu.:1.0000   3rd Qu.:4.000   3rd Qu.:2.000   3rd Qu.:2.000  
 Max.   :2.0000   Max.   :6.000   Max.   :3.000   Max.   :5.000  
                                                                 
       V9       V10       V11       V12       V13       V14       V15      
 Min.   :1.00   0:13438   0:16470   0:23623   0:22186   0:19575   0:20330  
 1st Qu.:2.00   1:10460   1: 7428   1:  275   1: 1712   1: 4323   1: 3568  
 Median :2.00                                                              
 Mean   :2.61                                                              
 3rd Qu.:4.00                                                              
 Max.   :6.00                                                              
                                                                           
 V16       V17       V18       V19       V20       V21       V22      
 0:22604   0:19636   1:10600   0:20129   0:15517   0:17497   0:22083  
 1: 1294   1: 4262   2:13298   1: 3769   1: 8381   1: 6401   1: 1815  
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
 V23       V24       V25            V26                V27        
 0:18853   0:17560   0:18004   Min.   :-3.00000   Min.   :0.0000  
 1: 5045   1: 6338   1: 5894   1st Qu.: 0.00000   1st Qu.:0.0000  
                               Median : 0.00000   Median :1.0000  
                               Mean   : 0.08398   Mean   :0.9125  
                               3rd Qu.: 0.00000   3rd Qu.:1.0000  
                               Max.   : 3.00000   Max.   :2.0000  
                                                                  
      V28             V29              V30              V31        
 Min.   :1.000   Min.   :0.0000   Min.   : 0.000   Min.   : 0.000  
 1st Qu.:1.000   1st Qu.:0.0000   1st Qu.: 0.000   1st Qu.: 0.000  
 Median :2.000   Median :0.0000   Median : 3.000   Median : 4.000  
 Mean   :1.899   Mean   :0.3912   Mean   : 3.155   Mean   : 3.679  
 3rd Qu.:2.000   3rd Qu.:0.0000   3rd Qu.: 4.000   3rd Qu.: 5.000  
 Max.   :3.000   Max.   :4.0000   Max.   :12.000   Max.   :12.000  
                                                                   
      V32                      V33       
 Min.   :-6.00000   Slovakia     : 1245  
 1st Qu.: 0.00000   CzechRepublic: 1069  
 Median : 0.00000   WGermany     : 1033  
 Mean   : 0.03741   Denmark      : 1027  
 3rd Qu.: 0.00000   Spain        : 1019  
 Max.   : 6.00000   France       : 1018  
                    (Other)      :17487  
> 
> if (require(lme4a)) {
+     ## Separate the setup time from the actual optimization time
+     cat ("Setup time\n\n")
+     print(system.time(fm1 <- lmer (V1 ~ V2*V3 + V4*V5 + V6*V5  + V7 + V8 +
+                                    V9 + V10 + V11 + V12 + V13 + V14 + V15 +
+                                    V16 + V17 + V18 + V19 + V20 + V21 + V22 +
+                                    V23 + V24 + V25  + V26 + V27 + V28 + V29 +
+                                    V30 + V31 + V32 +  (1 | V33) +
+                                    (0 + V6 | V33) + (0 + V2 | V33) +
+                                    (0 + V5 | V33) + (0 + V26 | V33),
+                                    data=myframe, doFit = FALSE)
+                 ))
+     cat("\nOptimization timings with nlminb\n\n")
+     ## optimize with nlminb
+     print(system.time(nlminb(c(1,1,1,1,1), fm1 at setPars, lower = c(0,0,0,0,0),
+                        control = list(trace = 1))))
+     ## replicate the timing
+     print(system.time(nlminb(c(1,1,1,1,1), fm1 at setPars, lower = c(0,0,0,0,0))))
+     print(system.time(nlminb(c(1,1,1,1,1), fm1 at setPars, lower = c(0,0,0,0,0))))
+     if (require(minqa)) {
+         ## optimize with bobyqa
+         cat("\nOptimization timings with bobyqa\n\n")
+         print(system.time(bobyqa(c(1,1,1,1,1), fm1 at setPars,
+                                  lower = c(0,0,0,0,0),
+                                  control = list(iprint = 2))))
+         print(system.time(bobyqa(c(1,1,1,1,1), fm1 at setPars,
+                                  lower = c(0,0,0,0,0))))
+         print(system.time(bobyqa(c(1,1,1,1,1), fm1 at setPars,
+                                  lower = c(0,0,0,0,0))))
+     }
+     print(fm1, corr = FALSE)
+ }
Loading required package: lme4a
Loading required package: Matrix
Loading required package: lattice
Setup time

   user  system elapsed 
  2.960   0.080   3.071 

Optimization timings with nlminb

  0:     96426.599:  1.00000  1.00000  1.00000  1.00000  1.00000
  1:     96295.996: 0.623983 0.523427 0.543702 0.552827 0.527435
  2:     96273.069: 0.591226 0.459321 0.484632 0.498523 0.465737
  3:     96168.044: 0.331374  0.00000  0.00000 0.0294945  0.00000
  4:     96107.379: 0.320822 0.00821871 0.00428477 0.328686 0.00269471
  5:     96087.796: 0.315190 0.149213 0.0445160 0.317986 0.0248490
  6:     96059.148: 0.315299 0.111180 0.0161098 0.302705 0.165021
  7:     96048.107: 0.312250  0.00000 0.0797214 0.263896 0.101371
  8:     96038.427: 0.309184 0.000451603 0.0369773 0.247601 0.0875081
  9:     96034.899: 0.270801 0.00896652 0.0608070 0.234734 0.0836041
 10:     96026.837: 0.233547 0.0319941 0.0721202 0.218979 0.0838261
 11:     96015.892: 0.242373 0.0461792 0.0294698 0.204983 0.0844199
 12:     96014.352: 0.245708 0.0355295 0.0310036 0.198239 0.0842762
 13:     96013.370: 0.249612 0.0427201 0.0332018 0.188210 0.0840645
 14:     96012.451: 0.254820 0.0341747 0.0305940 0.180119 0.0839994
 15:     96011.593: 0.262654 0.0420466 0.0339186 0.173954 0.0839426
 16:     96010.874: 0.271355 0.0354723 0.0316494 0.167002 0.0838920
 17:     96010.410: 0.280745 0.0424404 0.0346307 0.161826 0.0838721
 18:     96010.005: 0.291164 0.0364633 0.0331619 0.156732 0.0838985
 19:     96009.684: 0.281064 0.0421504 0.0314490 0.150807 0.0839873
 20:     96009.393: 0.277039 0.0361296 0.0330630 0.139974 0.0840539
 21:     96009.300: 0.288448 0.0418852 0.0354611 0.138146 0.0838848
 22:     96009.268: 0.276539 0.0403528 0.0302351 0.137239 0.0835648
 23:     96009.231: 0.277666 0.0385172 0.0344151 0.136062 0.0837730
 24:     96009.164: 0.281748 0.0389283 0.0319074 0.135416 0.0837814
 25:     96009.148: 0.285829 0.0397878 0.0340193 0.134406 0.0845960
 26:     96009.131: 0.287489 0.0389874 0.0328717 0.134196 0.0840812
 27:     96009.125: 0.287565 0.0398061 0.0328296 0.134120 0.0840057
 28:     96009.123: 0.288329 0.0395811 0.0328756 0.133984 0.0838227
 29:     96009.122: 0.289089 0.0398303 0.0329540 0.133897 0.0840147
 30:     96009.122: 0.289132 0.0396825 0.0327625 0.133853 0.0839632
 31:     96009.122: 0.289242 0.0398505 0.0327353 0.133743 0.0838536
 32:     96009.121: 0.289427 0.0396997 0.0327953 0.133712 0.0837955
 33:     96009.121: 0.289602 0.0397620 0.0327613 0.133658 0.0839591
 34:     96009.121: 0.289830 0.0397528 0.0327968 0.133663 0.0838508
 35:     96009.121: 0.289839 0.0397436 0.0327714 0.133658 0.0838547
 36:     96009.121: 0.289859 0.0397484 0.0327543 0.133648 0.0838609
 37:     96009.121: 0.289922 0.0397486 0.0327835 0.133623 0.0838680
 38:     96009.121: 0.289980 0.0397393 0.0327546 0.133650 0.0838892
 39:     96009.121: 0.289986 0.0397575 0.0327645 0.133645 0.0838784
 40:     96009.121: 0.289997 0.0397410 0.0327606 0.133635 0.0838667
 41:     96009.121: 0.290016 0.0397534 0.0327647 0.133645 0.0838675
 42:     96009.121: 0.290035 0.0397447 0.0327612 0.133631 0.0838666
 43:     96009.121: 0.290052 0.0397524 0.0327717 0.133626 0.0838776
 44:     96009.121: 0.290069 0.0397521 0.0327574 0.133632 0.0838684
 45:     96009.121: 0.290087 0.0397534 0.0327713 0.133641 0.0838641
 46:     96009.121: 0.290083 0.0397521 0.0327649 0.133618 0.0838614
 47:     96009.121: 0.290104 0.0397626 0.0327640 0.133619 0.0838678
 48:     96009.121: 0.290109 0.0397512 0.0327633 0.133620 0.0838668
 49:     96009.121: 0.290121 0.0397555 0.0327657 0.133623 0.0838665
   user  system elapsed 
  7.124   0.004   7.377 
   user  system elapsed 
  7.393   0.004   7.555 
   user  system elapsed 
  7.132   0.008   7.287 
Loading required package: minqa

Optimization timings with bobyqa

   user  system elapsed 
  3.268   0.004   3.400 
   user  system elapsed 
  3.437   0.012   3.810 
   user  system elapsed 
  3.412   0.004   3.508 
Linear mixed model fit by REML 
Formula: V1 ~ V2 * V3 + V4 * V5 + V6 * V5 + V7 + V8 + V9 + V10 + V11 +      V12 + V13 + V14 + V15 + V16 + V17 + V18 + V19 + V20 + V21 +      V22 + V23 + V24 + V25 + V26 + V27 + V28 + V29 + V30 + V31 +      V32 + (1 | V33) + (0 + V6 | V33) + (0 + V2 | V33) + (0 +      V5 | V33) + (0 + V26 | V33) 
   Data: myframe 
 REML 
96009 

Random effects:
 Groups   Name        Variance  Std.Dev.
 V33      (Intercept) 0.2690735 0.518723
 V33      V6          0.0050509 0.071070
 V33      V2          0.0034311 0.058576
 V33      V5          0.0570574 0.238867
 V33      V26         0.0224763 0.149921
 Residual             3.1958550 1.787695
Number of obs: 23898, groups: V33, 25

Fixed effects:
              Estimate Std. Error t value
(Intercept)  5.786e+00  3.324e-01   17.41
V2           2.101e-01  5.299e-02    3.97
V3           3.319e-05  1.665e-05    1.99
V4           1.165e-01  9.334e-02    1.25
V5          -5.375e-01  1.377e-01   -3.90
V6           1.788e-01  2.393e-02    7.47
V7          -3.933e-01  1.820e-02  -21.61
V8          -6.010e-02  1.367e-02   -4.39
V9          -3.200e-01  9.021e-03  -35.48
V10          3.137e-02  3.282e-02    0.96
V11          2.106e-02  3.683e-02    0.57
V12         -1.629e-01  1.144e-01   -1.42
V13         -1.247e-01  4.830e-02   -2.58
V14         -7.770e-02  3.376e-02   -2.30
V15         -2.026e-02  3.609e-02   -0.56
V16          1.036e-02  5.448e-02    0.19
V17         -1.938e-01  3.482e-02   -5.57
V18          1.014e-01  2.429e-02    4.18
V19         -1.349e-02  4.245e-02   -0.32
V20         -1.090e-01  4.635e-02   -2.35
V21         -1.724e-01  4.943e-02   -3.49
V22         -1.223e-01  5.062e-02   -2.42
V23         -5.598e-02  3.745e-02   -1.49
V24         -1.693e-03  4.675e-02   -0.04
V25         -3.927e-03  3.658e-02   -0.11
V26         -2.022e-01  4.131e-02   -4.90
V27         -8.758e-02  7.698e-02   -1.14
V28          1.035e-01  1.935e-02    5.35
V29          1.723e-02  2.819e-02    0.61
V30         -1.781e-02  1.587e-02   -1.12
V31          2.365e-02  1.977e-02    1.20
V32          2.921e-02  2.432e-02    1.20
V2:V3       -4.980e-06  1.862e-06   -2.67
V4:V5       -3.981e-02  2.893e-02   -1.38
V5:V6        2.813e-02  1.490e-02    1.89
> sessionInfo()
R version 2.11.0 Under development (unstable) (2009-10-06 r49951) 
x86_64-unknown-linux-gnu 

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    
 [5] LC_MONETARY=C              LC_MESSAGES=en_US.UTF-8   
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 
 [9] LC_ADDRESS=C               LC_TELEPHONE=C            
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] minqa_1.0          lme4a_0.999375-42  Matrix_0.999375-31 lattice_0.17-25   

loaded via a namespace (and not attached):
[1] grid_2.11.0
> 
> proc.time()
   user  system elapsed 
 53.947   0.416  56.324 

    New RHO = 1.0000D-01     Number of function values =     9
    Least value of F =  9.624386213834802D+04         The corresponding X is:
     1.131302D+00   0.000000D+00   0.000000D+00   0.000000D+00   0.000000D+00

    New RHO = 1.0000D-02     Number of function values =    21
    Least value of F =  9.604800640818221D+04         The corresponding X is:
     3.863002D-01   1.080197D-01   0.000000D+00   8.785680D-02   4.566788D-02

    New RHO = 1.0000D-03     Number of function values =    38
    Least value of F =  9.601658930561419D+04         The corresponding X is:
     3.201117D-01   6.523331D-02   4.684635D-02   1.315661D-01   7.357206D-02

    New RHO = 1.0000D-04     Number of function values =    61
    Least value of F =  9.600965193028880D+04         The corresponding X is:
     3.298372D-01   4.106806D-02   3.237175D-02   1.310226D-01   8.226777D-02

    New RHO = 1.0000D-05     Number of function values =   133
    Least value of F =  9.600912133381938D+04         The corresponding X is:
     2.904136D-01   3.981970D-02   3.272126D-02   1.334382D-01   8.380486D-02

    New RHO = 1.0000D-06     Number of function values =   171
    Least value of F =  9.600912118859364D+04         The corresponding X is:
     2.901974D-01   3.975666D-02   3.276056D-02   1.336079D-01   8.385492D-02

    At the return from BOBYQA     Number of function values =   201
    Least value of F =  9.600912118737071D+04         The corresponding X is:
     2.901622D-01   3.975474D-02   3.276600D-02   1.336172D-01   8.386269D-02

From bates at stat.wisc.edu  Wed Oct  7 00:03:19 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 6 Oct 2009 17:03:19 -0500
Subject: [R-sig-ME] Links to that "slow" lmer example I asked about
In-Reply-To: <40e66e0b0910061444i3eb40358jfc46874f0566b46b@mail.gmail.com>
References: <13e802630910061257o58263f62k6fa6c87e85bfc868@mail.gmail.com>
	<40e66e0b0910061444i3eb40358jfc46874f0566b46b@mail.gmail.com>
Message-ID: <40e66e0b0910061503i1f541f6cu7009272ccac82aff@mail.gmail.com>

I enclose a timing using the currently released lme4 on the same
machine.  You are right - it is considerably slower.  Good thing I'm
working on the next version.  Now I want you all to remember this when
you find out that I've all the internal structures - again!  There's a
reason.

On Tue, Oct 6, 2009 at 4:44 PM, Douglas Bates <bates at stat.wisc.edu> wrote:
> Thanks for providing the data, Paui. ?As I said in a private message,
> this helps a lot to be able to discuss a concrete example and I thank
> your colleague for allowing you to provide these.
>
> My initial timing is using the development version of the lme4
> package, the so-called lme4a. ?I separated the creation of the
> structures from the actual optimization. ?Setup takes about 3 seconds,
> optimization with nlminb about 7 seconds and optimization with bobyqa
> about 3.5 seconds.
>
> This was done on my desktop computer - a dual-core 2.0 GHz AMD64 with
> 4GB of memory.
>
> On Tue, Oct 6, 2009 at 2:57 PM, Paul Johnson <pauljohn32 at gmail.com> wrote:
>> Dear Everybody:
>>
>> I asked a couple of weeks ago about the puzzle that my colleague's
>> linear mixed model can be estimated in HLM6 in 3 seconds, while lmer
>> requires about 50 seconds. ?I wondered if that was expected/known.
>>
>> The discussion seemed to end with the conclusion "if you expect us to
>> evaluate that, give us the working example." ?Due to a death in my
>> family, I was delayed in responding, but here are the links to the
>> example data and code.
>>
>> The data frame is saved with R's write function
>>
>> http://pj.freefaculty.org/R/MixedModel/myframe.Rdata
>>
>> I believe that is workable on all platforms. That's about 26,000 rows.
>> Variable V33 represents the groups (in this case, country). ?The
>> variables are generically named V1-V33.
>>
>> The small simple test program to load the data and estimate the model:
>>
>> http://pj.freefaculty.org/R/MixedModel/replicateMM.R
>>
>> The output I get, which has system.time wrapped around the use of lmer:
>>
>> http://pj.freefaculty.org/R/MixedModel/replicateMM.Rout
>>
>> I get
>> ## ?user ?system elapsed
>> ##55.448 ? 0.216 ?55.756
>>
>> Please remember I am not saying that lmer should work faster. ?I
>> understand it is capable of estimating models that other programs
>> cannot. ?I'm only trying to explain to a user why this one linear
>> model takes more time in lmer than in HLM6.
>>
>> pj
>> --
>> Paul E. Johnson
>> Professor, Political Science
>> 1541 Lilac Lane, Room 504
>> University of Kansas
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
-------------- next part --------------

R version 2.9.2 (2009-08-24)
Copyright (C) 2009 The R Foundation for Statistical Computing
ISBN 3-900051-07-0

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> ## crude benchmark of speed on numerical linear algebra
> mm <- matrix(rnorm(1000 * 1000), nc = 1000)
> system.time(solve(mm, rnorm(1000)))
   user  system elapsed 
  0.644   0.028   0.715 
> system.time(solve(mm, rnorm(1000)))
   user  system elapsed 
  0.408   0.024   0.461 
> system.time(solve(mm, rnorm(1000)))
   user  system elapsed 
  0.300   0.012   0.318 
> rm(mm)
> 
> 
> load(url("http://pj.freefaculty.org/R/MixedModel/myframe.Rdata"))
> attr(myframe, "terms") <- NULL
> attr(myframe, "na.action") <- NULL
> 
> str(myframe)
'data.frame':	23898 obs. of  33 variables:
 $ V1 : num  5 5 5 3 7 9 9 4 7 9 ...
 $ V2 : num  4 4 4 4 5 2 4 3 4 4 ...
 $ V3 : num  28335 28335 28335 28335 28335 ...
 $ V4 : num  4.78 4.78 4.78 4.78 4.78 ...
 $ V5 : num  2 0 0 1 0 0 0 0 0 0 ...
 $ V6 : num  5 5 3 2 4 2 3 2 4 4 ...
 $ V7 : num  3 1 1 2 1 2 1 2 1 1 ...
 $ V8 : num  2 2 2 4 1 1 1 4 2 1 ...
 $ V9 : num  2 1 2 2 2 2 1 4 2 1 ...
 $ V10: num  1 0 0 0 1 0 1 1 0 1 ...
 $ V11: num  0 0 1 1 0 1 0 0 0 0 ...
 $ V12: num  0 1 0 0 0 0 0 0 0 0 ...
 $ V13: num  0 0 1 0 0 1 0 0 0 0 ...
 $ V14: num  0 0 0 0 0 0 0 0 0 0 ...
 $ V15: num  0 0 0 1 0 0 1 0 0 0 ...
 $ V16: num  0 0 0 0 0 0 0 0 0 0 ...
 $ V17: num  0 0 0 0 0 0 0 0 0 0 ...
 $ V18: num  1 1 1 1 1 1 1 2 2 1 ...
 $ V19: num  0 0 0 0 0 0 1 0 0 0 ...
 $ V20: num  1 0 1 1 1 1 0 0 1 0 ...
 $ V21: num  0 1 0 0 0 0 0 0 0 0 ...
 $ V22: num  0 0 0 0 0 0 0 0 0 0 ...
 $ V23: num  0 0 1 1 1 0 0 0 0 0 ...
 $ V24: num  0 0 0 0 0 0 1 0 0 1 ...
 $ V25: num  0 1 0 0 0 1 0 0 1 0 ...
 $ V26: num  1 0 1 0 1 1 -1 0 1 1 ...
 $ V27: num  0 0 0 0 2 0 1 1 0 1 ...
 $ V28: num  2 1 3 2 2 3 2 1 1 2 ...
 $ V29: num  0 0 0 0 0 0 0 0 0 0 ...
 $ V30: num  0 0 0 0 8 0 3 2 0 4 ...
 $ V31: num  0 0 0 0 10 0 4 3 0 4 ...
 $ V32: num  0 0 0 0 2 0 -1 0 0 1 ...
 $ V33: Factor w/ 25 levels "Austria","Belgium",..: 2 2 2 2 2 2 2 2 2 2 ...
> summary(myframe)
       V1              V2              V3              V4       
 Min.   :3.000   Min.   :2.000   Min.   :10270   Min.   :1.260  
 1st Qu.:5.000   1st Qu.:4.000   1st Qu.:16357   1st Qu.:2.000  
 Median :7.000   Median :4.000   Median :26750   Median :3.930  
 Mean   :6.315   Mean   :4.089   Mean   :23385   Mean   :3.758  
 3rd Qu.:8.000   3rd Qu.:5.000   3rd Qu.:27756   3rd Qu.:5.680  
 Max.   :9.000   Max.   :6.000   Max.   :62298   Max.   :6.530  
                                                                
       V5               V6              V7              V8       
 Min.   :0.0000   Min.   :2.000   Min.   :1.000   Min.   :1.000  
 1st Qu.:0.0000   1st Qu.:2.000   1st Qu.:1.000   1st Qu.:1.000  
 Median :0.0000   Median :4.000   Median :1.000   Median :1.000  
 Mean   :0.4353   Mean   :3.562   Mean   :1.545   Mean   :1.708  
 3rd Qu.:1.0000   3rd Qu.:4.000   3rd Qu.:2.000   3rd Qu.:2.000  
 Max.   :2.0000   Max.   :6.000   Max.   :3.000   Max.   :5.000  
                                                                 
       V9            V10              V11              V12         
 Min.   :1.00   Min.   :0.0000   Min.   :0.0000   Min.   :0.00000  
 1st Qu.:2.00   1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.00000  
 Median :2.00   Median :0.0000   Median :0.0000   Median :0.00000  
 Mean   :2.61   Mean   :0.4377   Mean   :0.3108   Mean   :0.01151  
 3rd Qu.:4.00   3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:0.00000  
 Max.   :6.00   Max.   :1.0000   Max.   :1.0000   Max.   :1.00000  
                                                                   
      V13               V14              V15              V16         
 Min.   :0.00000   Min.   :0.0000   Min.   :0.0000   Min.   :0.00000  
 1st Qu.:0.00000   1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.00000  
 Median :0.00000   Median :0.0000   Median :0.0000   Median :0.00000  
 Mean   :0.07164   Mean   :0.1809   Mean   :0.1493   Mean   :0.05415  
 3rd Qu.:0.00000   3rd Qu.:0.0000   3rd Qu.:0.0000   3rd Qu.:0.00000  
 Max.   :1.00000   Max.   :1.0000   Max.   :1.0000   Max.   :1.00000  
                                                                      
      V17              V18             V19              V20        
 Min.   :0.0000   Min.   :1.000   Min.   :0.0000   Min.   :0.0000  
 1st Qu.:0.0000   1st Qu.:1.000   1st Qu.:0.0000   1st Qu.:0.0000  
 Median :0.0000   Median :2.000   Median :0.0000   Median :0.0000  
 Mean   :0.1783   Mean   :1.556   Mean   :0.1577   Mean   :0.3507  
 3rd Qu.:0.0000   3rd Qu.:2.000   3rd Qu.:0.0000   3rd Qu.:1.0000  
 Max.   :1.0000   Max.   :2.000   Max.   :1.0000   Max.   :1.0000  
                                                                   
      V21              V22               V23              V24        
 Min.   :0.0000   Min.   :0.00000   Min.   :0.0000   Min.   :0.0000  
 1st Qu.:0.0000   1st Qu.:0.00000   1st Qu.:0.0000   1st Qu.:0.0000  
 Median :0.0000   Median :0.00000   Median :0.0000   Median :0.0000  
 Mean   :0.2678   Mean   :0.07595   Mean   :0.2111   Mean   :0.2652  
 3rd Qu.:1.0000   3rd Qu.:0.00000   3rd Qu.:0.0000   3rd Qu.:1.0000  
 Max.   :1.0000   Max.   :1.00000   Max.   :1.0000   Max.   :1.0000  
                                                                     
      V25              V26                V27              V28       
 Min.   :0.0000   Min.   :-3.00000   Min.   :0.0000   Min.   :1.000  
 1st Qu.:0.0000   1st Qu.: 0.00000   1st Qu.:0.0000   1st Qu.:1.000  
 Median :0.0000   Median : 0.00000   Median :1.0000   Median :2.000  
 Mean   :0.2466   Mean   : 0.08398   Mean   :0.9125   Mean   :1.899  
 3rd Qu.:0.0000   3rd Qu.: 0.00000   3rd Qu.:1.0000   3rd Qu.:2.000  
 Max.   :1.0000   Max.   : 3.00000   Max.   :2.0000   Max.   :3.000  
                                                                     
      V29              V30              V31              V32          
 Min.   :0.0000   Min.   : 0.000   Min.   : 0.000   Min.   :-6.00000  
 1st Qu.:0.0000   1st Qu.: 0.000   1st Qu.: 0.000   1st Qu.: 0.00000  
 Median :0.0000   Median : 3.000   Median : 4.000   Median : 0.00000  
 Mean   :0.3912   Mean   : 3.155   Mean   : 3.679   Mean   : 0.03741  
 3rd Qu.:0.0000   3rd Qu.: 4.000   3rd Qu.: 5.000   3rd Qu.: 0.00000  
 Max.   :4.0000   Max.   :12.000   Max.   :12.000   Max.   : 6.00000  
                                                                      
            V33       
 Slovakia     : 1245  
 CzechRepublic: 1069  
 WGermany     : 1033  
 Denmark      : 1027  
 Spain        : 1019  
 France       : 1018  
 (Other)      :17487  
Warning message:
closing unused connection 3 (gzcon(http://pj.freefaculty.org/R/MixedModel/myframe.Rdata)) 
> ## several variables are binary and probably should be recoded as factors
> sapply(myframe, function(v) length(unique(v)))
 V1  V2  V3  V4  V5  V6  V7  V8  V9 V10 V11 V12 V13 V14 V15 V16 V17 V18 V19 V20 
  7   5  24  24   3   5   3   5   6   2   2   2   2   2   2   2   2   2   2   2 
V21 V22 V23 V24 V25 V26 V27 V28 V29 V30 V31 V32 V33 
  2   2   2   2   2   7   3   3   4   9   9  11  25 
> myframeA <-
+     do.call(data.frame, lapply(myframe,
+                                function(v)
+                                if(length(unique(v)) == 2) factor(v) else v))
> str(myframeA)
'data.frame':	23898 obs. of  33 variables:
 $ V1 : num  5 5 5 3 7 9 9 4 7 9 ...
 $ V2 : num  4 4 4 4 5 2 4 3 4 4 ...
 $ V3 : num  28335 28335 28335 28335 28335 ...
 $ V4 : num  4.78 4.78 4.78 4.78 4.78 ...
 $ V5 : num  2 0 0 1 0 0 0 0 0 0 ...
 $ V6 : num  5 5 3 2 4 2 3 2 4 4 ...
 $ V7 : num  3 1 1 2 1 2 1 2 1 1 ...
 $ V8 : num  2 2 2 4 1 1 1 4 2 1 ...
 $ V9 : num  2 1 2 2 2 2 1 4 2 1 ...
 $ V10: Factor w/ 2 levels "0","1": 2 1 1 1 2 1 2 2 1 2 ...
 $ V11: Factor w/ 2 levels "0","1": 1 1 2 2 1 2 1 1 1 1 ...
 $ V12: Factor w/ 2 levels "0","1": 1 2 1 1 1 1 1 1 1 1 ...
 $ V13: Factor w/ 2 levels "0","1": 1 1 2 1 1 2 1 1 1 1 ...
 $ V14: Factor w/ 2 levels "0","1": 1 1 1 1 1 1 1 1 1 1 ...
 $ V15: Factor w/ 2 levels "0","1": 1 1 1 2 1 1 2 1 1 1 ...
 $ V16: Factor w/ 2 levels "0","1": 1 1 1 1 1 1 1 1 1 1 ...
 $ V17: Factor w/ 2 levels "0","1": 1 1 1 1 1 1 1 1 1 1 ...
 $ V18: Factor w/ 2 levels "1","2": 1 1 1 1 1 1 1 2 2 1 ...
 $ V19: Factor w/ 2 levels "0","1": 1 1 1 1 1 1 2 1 1 1 ...
 $ V20: Factor w/ 2 levels "0","1": 2 1 2 2 2 2 1 1 2 1 ...
 $ V21: Factor w/ 2 levels "0","1": 1 2 1 1 1 1 1 1 1 1 ...
 $ V22: Factor w/ 2 levels "0","1": 1 1 1 1 1 1 1 1 1 1 ...
 $ V23: Factor w/ 2 levels "0","1": 1 1 2 2 2 1 1 1 1 1 ...
 $ V24: Factor w/ 2 levels "0","1": 1 1 1 1 1 1 2 1 1 2 ...
 $ V25: Factor w/ 2 levels "0","1": 1 2 1 1 1 2 1 1 2 1 ...
 $ V26: num  1 0 1 0 1 1 -1 0 1 1 ...
 $ V27: num  0 0 0 0 2 0 1 1 0 1 ...
 $ V28: num  2 1 3 2 2 3 2 1 1 2 ...
 $ V29: num  0 0 0 0 0 0 0 0 0 0 ...
 $ V30: num  0 0 0 0 8 0 3 2 0 4 ...
 $ V31: num  0 0 0 0 10 0 4 3 0 4 ...
 $ V32: num  0 0 0 0 2 0 -1 0 0 1 ...
 $ V33: Factor w/ 25 levels "Austria","Belgium",..: 2 2 2 2 2 2 2 2 2 2 ...
> summary(myframeA)
       V1              V2              V3              V4       
 Min.   :3.000   Min.   :2.000   Min.   :10270   Min.   :1.260  
 1st Qu.:5.000   1st Qu.:4.000   1st Qu.:16357   1st Qu.:2.000  
 Median :7.000   Median :4.000   Median :26750   Median :3.930  
 Mean   :6.315   Mean   :4.089   Mean   :23385   Mean   :3.758  
 3rd Qu.:8.000   3rd Qu.:5.000   3rd Qu.:27756   3rd Qu.:5.680  
 Max.   :9.000   Max.   :6.000   Max.   :62298   Max.   :6.530  
                                                                
       V5               V6              V7              V8       
 Min.   :0.0000   Min.   :2.000   Min.   :1.000   Min.   :1.000  
 1st Qu.:0.0000   1st Qu.:2.000   1st Qu.:1.000   1st Qu.:1.000  
 Median :0.0000   Median :4.000   Median :1.000   Median :1.000  
 Mean   :0.4353   Mean   :3.562   Mean   :1.545   Mean   :1.708  
 3rd Qu.:1.0000   3rd Qu.:4.000   3rd Qu.:2.000   3rd Qu.:2.000  
 Max.   :2.0000   Max.   :6.000   Max.   :3.000   Max.   :5.000  
                                                                 
       V9       V10       V11       V12       V13       V14       V15      
 Min.   :1.00   0:13438   0:16470   0:23623   0:22186   0:19575   0:20330  
 1st Qu.:2.00   1:10460   1: 7428   1:  275   1: 1712   1: 4323   1: 3568  
 Median :2.00                                                              
 Mean   :2.61                                                              
 3rd Qu.:4.00                                                              
 Max.   :6.00                                                              
                                                                           
 V16       V17       V18       V19       V20       V21       V22      
 0:22604   0:19636   1:10600   0:20129   0:15517   0:17497   0:22083  
 1: 1294   1: 4262   2:13298   1: 3769   1: 8381   1: 6401   1: 1815  
                                                                      
                                                                      
                                                                      
                                                                      
                                                                      
 V23       V24       V25            V26                V27        
 0:18853   0:17560   0:18004   Min.   :-3.00000   Min.   :0.0000  
 1: 5045   1: 6338   1: 5894   1st Qu.: 0.00000   1st Qu.:0.0000  
                               Median : 0.00000   Median :1.0000  
                               Mean   : 0.08398   Mean   :0.9125  
                               3rd Qu.: 0.00000   3rd Qu.:1.0000  
                               Max.   : 3.00000   Max.   :2.0000  
                                                                  
      V28             V29              V30              V31        
 Min.   :1.000   Min.   :0.0000   Min.   : 0.000   Min.   : 0.000  
 1st Qu.:1.000   1st Qu.:0.0000   1st Qu.: 0.000   1st Qu.: 0.000  
 Median :2.000   Median :0.0000   Median : 3.000   Median : 4.000  
 Mean   :1.899   Mean   :0.3912   Mean   : 3.155   Mean   : 3.679  
 3rd Qu.:2.000   3rd Qu.:0.0000   3rd Qu.: 4.000   3rd Qu.: 5.000  
 Max.   :3.000   Max.   :4.0000   Max.   :12.000   Max.   :12.000  
                                                                   
      V32                      V33       
 Min.   :-6.00000   Slovakia     : 1245  
 1st Qu.: 0.00000   CzechRepublic: 1069  
 Median : 0.00000   WGermany     : 1033  
 Mean   : 0.03741   Denmark      : 1027  
 3rd Qu.: 0.00000   Spain        : 1019  
 Max.   : 6.00000   France       : 1018  
                    (Other)      :17487  
> 
> if (require(lme4a, quietly = TRUE)) {
+     ## Separate the setup time from the actual optimization time
+     cat ("Setup time\n\n")
+     print(system.time(fm1 <- lmer (V1 ~ V2*V3 + V4*V5 + V6*V5  + V7 + V8 +
+                                    V9 + V10 + V11 + V12 + V13 + V14 + V15 +
+                                    V16 + V17 + V18 + V19 + V20 + V21 + V22 +
+                                    V23 + V24 + V25  + V26 + V27 + V28 + V29 +
+                                    V30 + V31 + V32 +  (1 | V33) +
+                                    (0 + V6 | V33) + (0 + V2 | V33) +
+                                    (0 + V5 | V33) + (0 + V26 | V33),
+                                    data=myframe, doFit = FALSE)
+                 ))
+     cat("\nOptimization timings with nlminb\n\n")
+     ## optimize with nlminb
+     print(system.time(nlminb(c(1,1,1,1,1), fm1 at setPars, lower = c(0,0,0,0,0),
+                        control = list(trace = 1))))
+     ## replicate the timing
+     print(system.time(nlminb(c(1,1,1,1,1), fm1 at setPars, lower = c(0,0,0,0,0))))
+     print(system.time(nlminb(c(1,1,1,1,1), fm1 at setPars, lower = c(0,0,0,0,0))))
+     if (require(minqa)) {
+         ## optimize with bobyqa
+         cat("\nOptimization timings with bobyqa\n\n")
+         print(system.time(bobyqa(c(1,1,1,1,1), fm1 at setPars,
+                                  lower = c(0,0,0,0,0),
+                                  control = list(iprint = 2))))
+         print(system.time(bobyqa(c(1,1,1,1,1), fm1 at setPars,
+                                  lower = c(0,0,0,0,0))))
+         print(system.time(bobyqa(c(1,1,1,1,1), fm1 at setPars,
+                                  lower = c(0,0,0,0,0))))
+     }
+     print(fm1, corr = FALSE)
+ } else {
+     if (require(lme4)) {
+         print(system.time(fm1 <- lmer (V1 ~ V2*V3 + V4*V5 + V6*V5  + V7 + V8 +
+                                        V9 + V10 + V11 + V12 + V13 + V14 + V15 +
+                                        V16 + V17 + V18 + V19 + V20 + V21 + V22 +
+                                        V23 + V24 + V25  + V26 + V27 + V28 + V29 +
+                                        V30 + V31 + V32 +  (1 | V33) +
+                                        (0 + V6 | V33) + (0 + V2 | V33) +
+                                        (0 + V5 | V33) + (0 + V26 | V33),
+                                        myframe)))
+         print(system.time(fm1 <- lmer (V1 ~ V2*V3 + V4*V5 + V6*V5  + V7 + V8 +
+                                        V9 + V10 + V11 + V12 + V13 + V14 + V15 +
+                                        V16 + V17 + V18 + V19 + V20 + V21 + V22 +
+                                        V23 + V24 + V25  + V26 + V27 + V28 + V29 +
+                                        V30 + V31 + V32 +  (1 | V33) +
+                                        (0 + V6 | V33) + (0 + V2 | V33) +
+                                        (0 + V5 | V33) + (0 + V26 | V33),
+                                        myframe)))
+         print(system.time(fm1 <- lmer (V1 ~ V2*V3 + V4*V5 + V6*V5  + V7 + V8 +
+                                        V9 + V10 + V11 + V12 + V13 + V14 + V15 +
+                                        V16 + V17 + V18 + V19 + V20 + V21 + V22 +
+                                        V23 + V24 + V25  + V26 + V27 + V28 + V29 +
+                                        V30 + V31 + V32 +  (1 | V33) +
+                                        (0 + V6 | V33) + (0 + V2 | V33) +
+                                        (0 + V5 | V33) + (0 + V26 | V33),
+                                        myframe)))
+     }
+ }
Loading required package: lme4
Loading required package: Matrix
Loading required package: lattice

Attaching package: 'Matrix'


	The following object(s) are masked from package:stats :

	 contr.helmert,
	 contr.poly,
	 contr.SAS,
	 contr.sum,
	 contr.treatment,
	 xtabs 


	The following object(s) are masked from package:base :

	 rcond 

   user  system elapsed 
 48.699   0.168  49.904 
   user  system elapsed 
 47.963   0.148  49.180 
   user  system elapsed 
 45.062   0.040  46.258 
Warning message:
In library(package, lib.loc = lib.loc, character.only = TRUE, logical.return = TRUE,  :
  there is no package called 'lme4a'
> sessionInfo()
R version 2.9.2 (2009-08-24) 
x86_64-pc-linux-gnu 

locale:
LC_CTYPE=en_US.UTF-8;LC_NUMERIC=C;LC_TIME=en_US.UTF-8;LC_COLLATE=en_US.UTF-8;LC_MONETARY=C;LC_MESSAGES=en_US.UTF-8;LC_PAPER=en_US.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_US.UTF-8;LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] lme4_0.999375-32   Matrix_0.999375-31 lattice_0.17-25   

loaded via a namespace (and not attached):
[1] grid_2.9.2
> 
> proc.time()
   user  system elapsed 
158.413   0.720 163.360 

From raldo.kruger at gmail.com  Wed Oct  7 13:03:46 2009
From: raldo.kruger at gmail.com (Raldo Kruger)
Date: Wed, 7 Oct 2009 13:03:46 +0200
Subject: [R-sig-ME] lme vs. lmer
In-Reply-To: <13e802630910061319j7119c572m30779e98804e2014@mail.gmail.com>
References: <4AC24A2D.2090606@umn.edu> <4AC24BB9.5000609@ufl.edu>
	<40e66e0b0909291132qcfce47awf8a1e527ea970544@mail.gmail.com>
	<4AC255CE.1090904@ufl.edu> <4AC27502.7070104@biostat.ku.dk>
	<40e66e0b0909291450s39bb48c2p1b3e372bcc52eed0@mail.gmail.com>
	<30406dd0909300245j78380cfesa28d4e056d99cd82@mail.gmail.com>
	<40e66e0b0909300920m53f79d7fke12dbe19bb6f7793@mail.gmail.com>
	<30406dd0909301240w456a19d9jd54966cd1c0fa43e@mail.gmail.com>
	<13e802630910061319j7119c572m30779e98804e2014@mail.gmail.com>
Message-ID: <30406dd0910070403n1e141f89wd546b8cb5eacaa66@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20091007/4814df63/attachment.pl>

From pauljohn32 at gmail.com  Wed Oct  7 20:37:32 2009
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Wed, 7 Oct 2009 13:37:32 -0500
Subject: [R-sig-ME] lme vs. lmer
In-Reply-To: <30406dd0910070403n1e141f89wd546b8cb5eacaa66@mail.gmail.com>
References: <4AC24A2D.2090606@umn.edu>
	<40e66e0b0909291132qcfce47awf8a1e527ea970544@mail.gmail.com>
	<4AC255CE.1090904@ufl.edu> <4AC27502.7070104@biostat.ku.dk>
	<40e66e0b0909291450s39bb48c2p1b3e372bcc52eed0@mail.gmail.com>
	<30406dd0909300245j78380cfesa28d4e056d99cd82@mail.gmail.com>
	<40e66e0b0909300920m53f79d7fke12dbe19bb6f7793@mail.gmail.com>
	<30406dd0909301240w456a19d9jd54966cd1c0fa43e@mail.gmail.com>
	<13e802630910061319j7119c572m30779e98804e2014@mail.gmail.com>
	<30406dd0910070403n1e141f89wd546b8cb5eacaa66@mail.gmail.com>
Message-ID: <13e802630910071137ie2273eemc8ebe324b67df64f@mail.gmail.com>

On Wed, Oct 7, 2009 at 6:03 AM, Raldo Kruger <raldo.kruger at gmail.com> wrote:
> Hi Paul,
>
> Thanks for your response - it's much appreciated! Yes, I confess I'm new to
> R and regression modeling, so it has been a challenge trying to decipher the
> 'R- and modeling-speak' of the experts! I do understand what you've said
> below (which is great because it confirms that i'm on the right track...),
> however, my question relates more to how one decides which terms to drop.
>
> As i understand, one can use the p-values to determined which terms to drop
> first (i.e. drop the term with the highest p-value, then re-run the model
> and compare the two results with anova; if there's a significant difference,
> then accept the new model. Correct?)

No, that is backwards.  If the anova says the two models are
different, keep the full, unrestricted model. The significance of the
difference indicates you lost "explanatory power" when you removed a
variable or recoded to remove a parameter.


This is done since one wants a model
> that explains the data well, and non-significant terms don't contribute to
> explaining the data, right?
>
> The challenge with using glmer with quasipoisson is that it does not give
> p-values for each term or interaction - so how does one decide which term to
> drop...if any. From what i've gleaned from previous advice from others is
> that one can drop any term and compare the results with the full model by
> anova to get the p-value for that term. So should one do that for all the
> terms first (one at a time), then drop the term with the highest p-value,
> and then repeat the whole process again?

It's not a problem that "the program does not give you a p-value."
The problem is that the statistical theory is tenuous enough that
nobody is sure what the p-value ought to be.  The quasi model is based
on the idea that nobody know the sampling distribution of the random
component very well, so the standard errors are, well, sorta
not-really-standard.  I think you'd probably want to calculate some
kind of robust standard error, but I've not done it with a
quasi-poisson model.

Instead of a quasi-poisson, you could look around for a mixed model
program that has a negative binomial option.  For negative binomial,
we have more exact model of randomness and the standard errors are
more well understood.  lmer does not have nb, but I'm pretty sure I've
seen one somewhere.

If you really believe you want a p-value, you can calculate one
yourself.  From the "summary" output, inspect and you'll see there are
columns of b's and standard errrors.  divide away for yourself.

The problem of deciding which variable to drop is a hard one, it is
the same in ordinary regression.

I'm trained in a tradition that says you should try to choose
variables by theory, and don't commit the sin of dropping variables
just because they are "not significant".  If there is any
multicollinearity, the dropping process may lead to mistaken
conclusions.  This is the flaw in so-called "stepwise" regression. You
are a "bonehead" if you let the model tell you which parameters to
include.  Models will lie to you.  Model pruning of that sort--the
search for "significant" estimates--produces bad t-tests and a lot of
silly articles getting published.  I've seen economists and political
scientists crop up with survey articles saying that just about
everything we publish is misleading/wrong because of the model pruning
approach.

I've wondered if we could not work out a "regression tree" or "forest"
framework to choose which variables are needed in your glm.  I read a
lot about it, but concluded it did not exactly fit my need.  If you
are looking for some rigorous justification to include/exclude
variables, I think you have to look in that more exotic direction.  I
saw a beautiful presentation about the LASSO that selects and
estimates and accounts for shrinkage as well.

There's an article by Ed Leamer from AER with a title like "Let's take
the con out of econometrics."  it deals with the variable selection
problem. I *think* his suggested approach would be the one we call
Bayesian Model Averaging today.   If you fit a lot of models, drop
variables in and out, then the final result should somehow summarize
the variety of estimates you observed.

Sorry, this is preaching in the wrong context. You don't really have a
r-sig-mixed problem here, you have a more general (somewhat religious)
question about regression modeling.

pj

>
> Any further advice would be greatly appreciated.
> Thanks,
> Raldo
>
>
> PS. I had attached the data in a Text file in the previous e-mail; is that
> not acceptable for R Help? (I've attached the file again and it is also
> available here).
>
>
>
> On Tue, Oct 6, 2009 at 10:19 PM, Paul Johnson <pauljohn32 at gmail.com> wrote:
>> On Wed, Sep 30, 2009 at 2:40 PM, Raldo Kruger <raldo.kruger at gmail.com>
>> wrote:
>>> Chris,
>>> Thanks for that - I should probably have mentioned that I'm using
>>> family=quasipoisson ?in glmer since my data has Poisson distribution
>>> as well as being overdispersed. I'm unsure how one decides which term
>>> to drop without being informed by p-values, and so don't quite
>>> understand how the "Likelihood ratio test using anova()" , or the AIC
>>> or BIC model comparison will work in this case (I thought one's
>>> supposed to remove the term with the highest p-value from the model,
>>> and compare it with the model with the term included to see if there's
>>> a difference, not so?).
>>
>> Dear Raldo:
>>
>> Finally there is a question that I can help with! ?It appears to me
>> you don't have much experience with regression modeling in R and the
>> other people who answer you are talking a bit "over your head".
>>
>> In your case, call this fit the "full" or "unrestricted" model:
>>
>> ex4o_r2<-glmer(Counts~N+G+Year+N:Year+G:Year+N:G:Year+(Year|Site),
>> data=ex4o, family=quasipoisson)
>>
>> (I'm not commenting the specification).
>>
>> Suppose you wonder "Should I leave out the multiplicative effect
>> between N and Year?" ?THen you fit the model that excludes that one
>> element:
>>
>> ex4o_new <-glmer(Counts~N+G+Year +G:Year+N:G:Year+(Year|Site),
>> data=ex4o, family=quasipoisson)
>>
>> And then use the anova function to compare the 2 models
>>
>> anova(ex4o_r2, ex4o_new)
>>
>> This is a "pretty standard" R regression thing, similar to what people
>> do with all sorts of models in R. ?It is what the "drop1" function
>> does for lm models, I believe.
>>
>> You may have seen regression models where an F test is done comparing
>> a full model against a restricted model? ?This is following the same
>> line of thought.
>>
>> To test your question about the factor levels, here is what you should
>> do. SUppose the initial factor has 5 levels, and you wonder "do I
>> really need 5 levels, or can I drop out the separate estimations for 3
>> of the levels?" ?Create a new factor with the simpler structure, run
>> it through the model in place of the original factor, and run anova to
>> compare the 2 models. ?I wrote down some of those ideas in a paper
>> last spring (http://pj.freefaculty.org/Papers/MidWest09/Midwest09.pdf),
>> but when I was done it seemed so obvious to me (& my friends) that I
>> did not try to publish it.
>>
>> With anova, there is a test= option where you can specify if you want
>> a chisq or F test.
>>
>> And, for future reference, when the experts ask you for a data example
>> to work on, they do not mean a copy of your printout, although that
>> may help. ?What they want is the actual data and commands that you
>> use. ?Usually, you have to upload the data somewhere for us to see,
>> along with the code.
>>
>> Good luck with your project.
>>
>> pj
>>
>> --
>> Paul E. Johnson
>> Professor, Political Science
>> 1541 Lilac Lane, Room 504
>> University of Kansas
>>
>
>
>
> --
> Raldo
>
>
> On Tue, Oct 6, 2009 at 10:19 PM, Paul Johnson <pauljohn32 at gmail.com> wrote:
>>
>> On Wed, Sep 30, 2009 at 2:40 PM, Raldo Kruger <raldo.kruger at gmail.com>
>> wrote:
>> > Chris,
>> > Thanks for that - I should probably have mentioned that I'm using
>> > family=quasipoisson ?in glmer since my data has Poisson distribution
>> > as well as being overdispersed. I'm unsure how one decides which term
>> > to drop without being informed by p-values, and so don't quite
>> > understand how the "Likelihood ratio test using anova()" , or the AIC
>> > or BIC model comparison will work in this case (I thought one's
>> > supposed to remove the term with the highest p-value from the model,
>> > and compare it with the model with the term included to see if there's
>> > a difference, not so?).
>>
>> Dear Raldo:
>>
>> Finally there is a question that I can help with! ?It appears to me
>> you don't have much experience with regression modeling in R and the
>> other people who answer you are talking a bit "over your head".
>>
>> In your case, call this fit the "full" or "unrestricted" model:
>>
>> ex4o_r2<-glmer(Counts~N+G+Year+N:Year+G:Year+N:G:Year+(Year|Site),
>> data=ex4o, family=quasipoisson)
>>
>> (I'm not commenting the specification).
>>
>> Suppose you wonder "Should I leave out the multiplicative effect
>> between N and Year?" ?THen you fit the model that excludes that one
>> element:
>>
>> ex4o_new <-glmer(Counts~N+G+Year +G:Year+N:G:Year+(Year|Site),
>> data=ex4o, family=quasipoisson)
>>
>> And then use the anova function to compare the 2 models
>>
>> anova(ex4o_r2, ex4o_new)
>>
>> This is a "pretty standard" R regression thing, similar to what people
>> do with all sorts of models in R. ?It is what the "drop1" function
>> does for lm models, I believe.
>>
>> You may have seen regression models where an F test is done comparing
>> a full model against a restricted model? ?This is following the same
>> line of thought.
>>
>> To test your question about the factor levels, here is what you should
>> do. SUppose the initial factor has 5 levels, and you wonder "do I
>> really need 5 levels, or can I drop out the separate estimations for 3
>> of the levels?" ?Create a new factor with the simpler structure, run
>> it through the model in place of the original factor, and run anova to
>> compare the 2 models. ?I wrote down some of those ideas in a paper
>> last spring (http://pj.freefaculty.org/Papers/MidWest09/Midwest09.pdf),
>> but when I was done it seemed so obvious to me (& my friends) that I
>> did not try to publish it.
>>
>> With anova, there is a test= option where you can specify if you want
>> a chisq or F test.
>>
>> And, for future reference, when the experts ask you for a data example
>> to work on, they do not mean a copy of your printout, although that
>> may help. ?What they want is the actual data and commands that you
>> use. ?Usually, you have to upload the data somewhere for us to see,
>> along with the code.
>>
>> Good luck with your project.
>>
>> pj
>>
>> --
>> Paul E. Johnson
>> Professor, Political Science
>> 1541 Lilac Lane, Room 504
>> University of Kansas
>
>
>
> --
> Raldo
>



-- 
Paul E. Johnson
Professor, Political Science
1541 Lilac Lane, Room 504
University of Kansas



From maloneyk at si.edu  Thu Oct  8 00:05:48 2009
From: maloneyk at si.edu (Maloney, Kelly)
Date: Wed, 7 Oct 2009 18:05:48 -0400
Subject: [R-sig-ME] Help with a mixed effects design
Message-ID: <E2037BBDCE25274082B092982D08F12D04C3085C@SI-MSEV02.US.SINET.SI.EDU>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20091007/8c086b61/attachment.pl>

From babila_tachu at yahoo.co.uk  Thu Oct  8 09:56:11 2009
From: babila_tachu at yahoo.co.uk (Babila Tachu)
Date: Thu, 8 Oct 2009 07:56:11 +0000 (GMT)
Subject: [R-sig-ME] p values for models with random correlation parameters
Message-ID: <218313.87815.qm@web27406.mail.ukl.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20091008/0af34644/attachment.pl>

From bolker at ufl.edu  Thu Oct  8 16:43:21 2009
From: bolker at ufl.edu (Ben Bolker)
Date: Thu, 08 Oct 2009 10:43:21 -0400
Subject: [R-sig-ME] p values for models with random correlation
	parameters
In-Reply-To: <218313.87815.qm@web27406.mail.ukl.yahoo.com>
References: <218313.87815.qm@web27406.mail.ukl.yahoo.com>
Message-ID: <4ACDFA89.3040206@ufl.edu>

Babila Tachu wrote:
> Hello R programmers!
> 
> I used the package languageR for mixed effect models with the syntax
> at the end of this posting. I can use pvals.fnc to get p-values for
> model 1 and 3 (hd_lmer1 and hd_lmer3). Using this with model 2 gives
> the following error message:
> 
> p2 = pvals.fnc(hd_lmer2) Error in pvals.fnc(hd_lmer2) : MCMC sampling
> is not yet implemented in lme4_0.999375 for models with random
> correlation parameters
> 
> I'd be grateful if any one could help me out on how to get p-values
> for such models.
> 
> Models:
> 
> hd_lmer1 <- lmer(rot~ time + group + sex + gen + (1 | subject) +
> (1|rot.pre), data = data_long,REML = TRUE) hd_lmer2 <- lmer(rot~ time
> + group + sex + gen + (time | subject) + (1|rot.pre), data =
> data_long,REML = TRUE) hd_lmer3 <- lmer(rot~ time*group + sex + gen +
> (1 | subject) + (1|rot.pre), data =data_long,REML = TRUE)
> 
> rot = time spent by mice on an apparatus; gen= genotype
> 

  *If* the simulate method is working for these models (I'm not sure,
you haven't provided a reproducible example, and I'm too lazy to make
one up right now), you can get a p-value by simulating from the null
(reduced) model and fitting both the reduced and full models to the
simulated data.  For examples, to test the effect of the random effect
of time by subject:

devdiff <- numeric(1000)
newdata <- data_long
for (i in 1:1000) {
   newdata$rot <- simulate(hd_lmer3)  ## sim from model without time
   fit1 <- update(hd_lmer2,data=newdata)
   fit0 <- update(hd_lmer3,data=newdata)
   devdiff[i] <- -2*(logLik(fit1)-logLik(fit0))
}
mean(devdiff>=(logLik(hd_lmer2)-logLik(hd_lmer3))

 or something like that.

  warning, this may take a while ...

  Ben Bolker



From robert.espesser at lpl-aix.fr  Thu Oct  8 17:18:18 2009
From: robert.espesser at lpl-aix.fr (espesser)
Date: Thu, 08 Oct 2009 17:18:18 +0200
Subject: [R-sig-ME] p values for models with random
	correlation	parameters
In-Reply-To: <4ACDFA89.3040206@ufl.edu>
References: <218313.87815.qm@web27406.mail.ukl.yahoo.com>
	<4ACDFA89.3040206@ufl.edu>
Message-ID: <4ACE02BA.9020204@lpl-aix.fr>

Ben Bolker a ?crit :
> Babila Tachu wrote:
>   
>> Hello R programmers!
>>
>> I used the package languageR for mixed effect models with the syntax
>> at the end of this posting. I can use pvals.fnc to get p-values for
>> model 1 and 3 (hd_lmer1 and hd_lmer3). Using this with model 2 gives
>> the following error message:
>>
>> p2 = pvals.fnc(hd_lmer2) Error in pvals.fnc(hd_lmer2) : MCMC sampling
>> is not yet implemented in lme4_0.999375 for models with random
>> correlation parameters
>>
>> I'd be grateful if any one could help me out on how to get p-values
>> for such models.
>>
>> Models:
>>
>> hd_lmer1 <- lmer(rot~ time + group + sex + gen + (1 | subject) +
>> (1|rot.pre), data = data_long,REML = TRUE) hd_lmer2 <- lmer(rot~ time
>> + group + sex + gen + (time | subject) + (1|rot.pre), data =
>> data_long,REML = TRUE) hd_lmer3 <- lmer(rot~ time*group + sex + gen +
>> (1 | subject) + (1|rot.pre), data =data_long,REML = TRUE)
>>
>> rot = time spent by mice on an apparatus; gen= genotype
>>
>>     
>
>   *If* the simulate method is working for these models (I'm not sure,
> you haven't provided a reproducible example, and I'm too lazy to make
> one up right now), you can get a p-value by simulating from the null
> (reduced) model and fitting both the reduced and full models to the
> simulated data.  For examples, to test the effect of the random effect
> of time by subject:
>
> devdiff <- numeric(1000)
> newdata <- data_long
> for (i in 1:1000) {
>    newdata$rot <- simulate(hd_lmer3)  ## sim from model without time
>    fit1 <- update(hd_lmer2,data=newdata)
>    fit0 <- update(hd_lmer3,data=newdata)
>    devdiff[i] <- -2*(logLik(fit1)-logLik(fit0))
> }
> mean(devdiff>=(logLik(hd_lmer2)-logLik(hd_lmer3))
>
>  or something like that.
>
>   warning, this may take a while ...
>
>   Ben Bolker
>
>   
You can also run a variant of hd_lmer2 without the correlation between 
the random intercept for subject
and the random slope for subject. You can test if this correlation term 
is needed with:
anova(hd_lmer2, hd_lmer2_bis)

hd_lmer2_bis <- lmer(rot~ time
+ group + sex + gen + (1|subject) +(0+ time | subject) + (1|rot.pre), data =
data_long,REML = TRUE) 

On this model, pvals.fnc would run.



From wayne.dawson at ips.unibe.ch  Mon Oct 12 16:50:19 2009
From: wayne.dawson at ips.unibe.ch (Dawson Wayne)
Date: Mon, 12 Oct 2009 16:50:19 +0200
Subject: [R-sig-ME] Modelling missing data in MCMCglmm()
Message-ID: <20091012165019.18753xdarp6xare3@mail.unibe.ch>

Hi R users,

This is more of a forward planning question on my part, as I am still  
constructing this particular dataset, but I want to use MCMCglmm to  
test for factors contributing to naturalisation success of alien  
plants, whilst including a phylogeny. I will have missing data in this  
dataset, especially seed size for a number of species. I have read  
through the MCMCglmm vignette and package pdf and cannot see an  
example of how to include code for modelling missing data. To model  
missing seed sizes per species, I would like to use the mean and  
variance of seed size for congeners.

I'm guessing they would be included as priors somehow, but I'm unsure  
how this coding would work. Any suggestions/further reading advice  
appreciated.

Cheers,

Wayne

-- 
Dr. Wayne Dawson
Institute of Plant Sciences
University of Bern
Altenbergrain 21
3013 Bern
Switzerland
+41 (0)31 631 49 25



From alexandre.villers at cebc.cnrs.fr  Tue Oct 13 08:36:32 2009
From: alexandre.villers at cebc.cnrs.fr (alexandre villers)
Date: Tue, 13 Oct 2009 08:36:32 +0200
Subject: [R-sig-ME] estimating the "right" theta in a glmmmPQL model with
	neg bin error family and spatial structure
Message-ID: <1255415792.825faf4alexandre.villers@cebc.cnrs.fr>

Good evening dear R-list members,

I would like to have your advices on the best way to estimate the theta in a spatial glmmPQL with a correlation structure (such as correlation=corSpher(form=~X+Y)) and a negative.binomial family.
Contrary to gam and the negbin family (mgcv), which can estimate theta, the negative.binomial family of MASS requires a fixed value of theta.
How am I to specify this value ? Shall I run the model on a range of values for theta and look for one that gets the scale parameter close to 1 (by the way, is it the $sigma in glmmPQL objects ?). Or is there a way to use the different functions in MASS (theta.md, theta.ml) for that purpose ?

I could not find anything on the forum pages but hope it is not a too trivial question...

Best regards
Alexandre Villers
PhD. Student
Team Biodiversity
CEBC CNRS
79360 Beauvoir sur Niort


__________ Information from ESET Mail Security, version of virus signature database 4501 (20091012) __________

The message was checked by ESET Mail Security.
http://www.eset.com



From j.hadfield at ed.ac.uk  Tue Oct 13 09:11:12 2009
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Tue, 13 Oct 2009 08:11:12 +0100
Subject: [R-sig-ME] Modelling missing data in MCMCglmm()
In-Reply-To: <20091012165019.18753xdarp6xare3@mail.unibe.ch>
References: <20091012165019.18753xdarp6xare3@mail.unibe.ch>
Message-ID: <20091013081112.ope7z2z77ogcwogc@www.staffmail.ed.ac.uk>

Hi Wayne,

If you have missing data in your response(s) then MCMCglmm samples  
them under the assumption of an MAR (missing at random) process. The  
terminology is confusing and MAR should not be confused with MCAR  
(missing completely at random) which is what most people think of when  
making the statement "missing at random".  Under MAR the missing  
species data are updated conditional on the model so that if the  
phylogenetic signal is high and the species with the missing data have  
close relatives, then the missing species data are weighted  
(appropriately) to the data of their sibling taxa.

If there are missing data in the fixed effects MCMCglmm will  
terminate. Sometimes if there are a lot of missing data for a fixed  
predictor it can be handy to move it into the response:

cbind(y_1, y_2)

if missing data occur in y_1, then y_2 can help predict the missing  
data if a  relationship exists between the two responses.

This scheme is better than using point estimates for the missing data  
because the uncertainty in their values is integrated out.

Jarrod





Quoting Dawson Wayne <wayne.dawson at ips.unibe.ch>:

> Hi R users,
>
> This is more of a forward planning question on my part, as I am still
> constructing this particular dataset, but I want to use MCMCglmm to
> test for factors contributing to naturalisation success of alien
> plants, whilst including a phylogeny. I will have missing data in this
> dataset, especially seed size for a number of species. I have read
> through the MCMCglmm vignette and package pdf and cannot see an example
> of how to include code for modelling missing data. To model missing
> seed sizes per species, I would like to use the mean and variance of
> seed size for congeners.
>
> I'm guessing they would be included as priors somehow, but I'm unsure
> how this coding would work. Any suggestions/further reading advice
> appreciated.
>
> Cheers,
>
> Wayne
>
> -- 
> Dr. Wayne Dawson
> Institute of Plant Sciences
> University of Bern
> Altenbergrain 21
> 3013 Bern
> Switzerland
> +41 (0)31 631 49 25
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From a.j.close at newcastle.ac.uk  Tue Oct 13 16:08:25 2009
From: a.j.close at newcastle.ac.uk (Andrew Close)
Date: Tue, 13 Oct 2009 15:08:25 +0100
Subject: [R-sig-ME] lme4 and calculating QAICc
Message-ID: <6EC8ACEECB03A94F91EFB55F0FA3630E677A350E05@EXSAN03.campus.ncl.ac.uk>

Dear all,

I am trying to calculate QAICc using to compare two Poisson models. Unfortunately all I seem to get as printed values is NaN.

Is there something I'm missing? Even though I am able to generate model output, I do receive "convergence errors". Would these warning message have anything to do with this?

Incidentally, I'm using the methodology extracted from Bolker et al (2009)

Here is the code I have used.

######
library(lme4)
######
mp1=lmer(abundance~year+controlA+(year|groupC:sitecode),family="poisson",data=testData)

######
mq1=lmer(abundance~year+controlA+(year|groupC:sitecode),family="quasipoisson",data=testData)

######
QAICc <- function(mod, scale, QAICc = TRUE) {
LL <- logLik(mod)
ll <- as.numeric(LL)
df <- attr(LL, "df")
n <- length(mod at y)
if (QAICc)
qaic = as.numeric(-2 * ll/scale + 2 * df + 2 * df * (df +
1)/(n - df - 1))
else qaic = as.numeric(-2 * ll/scale + 2 * df)
qaic
}
#######
QAICc(mq1,scale=phi)

....and this is what I generate...

[1] NaN

Thank you.


Andrew


Andrew Close
Research Associate
Institute for Research on Environment and Sustainability (IRES)
School of Biology
4th Floor Devonshire Building
Newcastle University
NE1 7RU
+44 (0)191 2464840



From Christoph.Scherber at agr.uni-goettingen.de  Tue Oct 13 18:28:00 2009
From: Christoph.Scherber at agr.uni-goettingen.de (Dr. Christoph Scherber)
Date: Tue, 13 Oct 2009 18:28:00 +0200 (CEST)
Subject: [R-sig-ME] lme4 and calculating QAICc
In-Reply-To: <6EC8ACEECB03A94F91EFB55F0FA3630E677A350E05@EXSAN03.campus.ncl.ac.uk>
References: <6EC8ACEECB03A94F91EFB55F0FA3630E677A350E05@EXSAN03.campus.ncl.ac.uk>
Message-ID: <2282.134.76.2.71.1255451280.squirrel@mailbox.gwdg.de>

Dear Andrew,

You might want to check if you can extract a log-Likelihood from your models

logLik(mq1)

If you get an NaN here, there may be something wrong with your model(s).

Best wishes
Christoph


> Dear all,
>
> I am trying to calculate QAICc using to compare two Poisson models.
> Unfortunately all I seem to get as printed values is NaN.
>
> Is there something I'm missing? Even though I am able to generate model
> output, I do receive "convergence errors". Would these warning message
> have anything to do with this?
>
> Incidentally, I'm using the methodology extracted from Bolker et al (2009)
>
> Here is the code I have used.
>
> ######
> library(lme4)
> ######
> mp1=lmer(abundance~year+controlA+(year|groupC:sitecode),family="poisson",data=testData)
>
> ######
> mq1=lmer(abundance~year+controlA+(year|groupC:sitecode),family="quasipoisson",data=testData)
>
> ######
> QAICc <- function(mod, scale, QAICc = TRUE) {
> LL <- logLik(mod)
> ll <- as.numeric(LL)
> df <- attr(LL, "df")
> n <- length(mod at y)
> if (QAICc)
> qaic = as.numeric(-2 * ll/scale + 2 * df + 2 * df * (df +
> 1)/(n - df - 1))
> else qaic = as.numeric(-2 * ll/scale + 2 * df)
> qaic
> }
> #######
> QAICc(mq1,scale=phi)
>
> ....and this is what I generate...
>
> [1] NaN
>
> Thank you.
>
>
> Andrew
>
>
> Andrew Close
> Research Associate
> Institute for Research on Environment and Sustainability (IRES)
> School of Biology
> 4th Floor Devonshire Building
> Newcastle University
> NE1 7RU
> +44 (0)191 2464840
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From datkins at u.washington.edu  Tue Oct 13 20:04:27 2009
From: datkins at u.washington.edu (David Atkins)
Date: Tue, 13 Oct 2009 11:04:27 -0700
Subject: [R-sig-ME] lme4 and calculating QAICc
In-Reply-To: <6EC8ACEECB03A94F91EFB55F0FA3630E677A350E05@EXSAN03.campus.ncl.ac.uk>
References: <6EC8ACEECB03A94F91EFB55F0FA3630E677A350E05@EXSAN03.campus.ncl.ac.uk>
Message-ID: <4AD4C12B.9080503@u.washington.edu>


Andrew--

Your code worked fine for me using an lmer() fit on some of my own data, 
and setting scale = 1.

Is phi defined somewhere that we can't see, or might that be causing 
your problems?  I think it should work if scale is passed a numeric value.

cheers, Dave

-- 
Dave Atkins, PhD
Research Associate Professor
Center for the Study of Health and Risk Behaviors
Department of  Psychiatry and Behavioral Science
University of Washington
1100 NE 45th Street, Suite 300
Seattle, WA  98105
206-616-3879
datkins at u.washington.edu

Dear all,

I am trying to calculate QAICc using to compare two Poisson models. 
Unfortunately all I seem to get as printed values is NaN.

Is there something I'm missing? Even though I am able to generate model 
output, I do receive "convergence errors". Would these warning message 
have anything to do with this?

Incidentally, I'm using the methodology extracted from Bolker et al (2009)

Here is the code I have used.

######
library(lme4)
######
mp1=lmer(abundance~year+controlA+(year|groupC:sitecode),family="poisson",data=testData)

######
mq1=lmer(abundance~year+controlA+(year|groupC:sitecode),family="quasipoisson",data=testData)

######
QAICc <- function(mod, scale, QAICc = TRUE) {
LL <- logLik(mod)
ll <- as.numeric(LL)
df <- attr(LL, "df")
n <- length(mod at y)
if (QAICc)
qaic = as.numeric(-2 * ll/scale + 2 * df + 2 * df * (df +
1)/(n - df - 1))
else qaic = as.numeric(-2 * ll/scale + 2 * df)
qaic
}
#######
QAICc(mq1,scale=phi)

....and this is what I generate...

[1] NaN

Thank you.


Andrew


Andrew Close
Research Associate
Institute for Research on Environment and Sustainability (IRES)
School of Biology
4th Floor Devonshire Building
Newcastle University
NE1 7RU
+44 (0)191 2464840



From bolker at ufl.edu  Tue Oct 13 20:25:45 2009
From: bolker at ufl.edu (Ben Bolker)
Date: Tue, 13 Oct 2009 14:25:45 -0400
Subject: [R-sig-ME] lme4 and calculating QAICc
In-Reply-To: <2282.134.76.2.71.1255451280.squirrel@mailbox.gwdg.de>
References: <6EC8ACEECB03A94F91EFB55F0FA3630E677A350E05@EXSAN03.campus.ncl.ac.uk>
	<2282.134.76.2.71.1255451280.squirrel@mailbox.gwdg.de>
Message-ID: <4AD4C629.4040900@ufl.edu>


  Checking in a bit late here ... been busy the last couple of days.

Dr. Christoph Scherber wrote:
> Dear Andrew,
> 
> You might want to check if you can extract a log-Likelihood from your models
> 
> logLik(mq1)
> 
> If you get an NaN here, there may be something wrong with your model(s).
> 
> Best wishes
> Christoph
> 
> 
>> Dear all,
>>
>> I am trying to calculate QAICc using to compare two Poisson models.
>> Unfortunately all I seem to get as printed values is NaN.
>>
>> Is there something I'm missing? Even though I am able to generate model
>> output, I do receive "convergence errors". Would these warning message
>> have anything to do with this?
>>
>> Incidentally, I'm using the methodology extracted from Bolker et al (2009)
>>
>> Here is the code I have used.
>>
>> ######
>> library(lme4)
>> ######
>> mp1=lmer(abundance~year+controlA+(year|groupC:sitecode),family="poisson",data=testData)
>>
>> ######
>> mq1=lmer(abundance~year+controlA+(year|groupC:sitecode),family="quasipoisson",data=testData)

  OR

  mq1 = update(mp1,family="quasipoisson")

(as in Bolker et al supplement)

>>
>> ######
>> QAICc <- function(mod, scale, QAICc = TRUE) {
>> LL <- logLik(mod)
>> ll <- as.numeric(LL)
>> df <- attr(LL, "df")
>> n <- length(mod at y)
>> if (QAICc)
>> qaic = as.numeric(-2 * ll/scale + 2 * df + 2 * df * (df +
>> 1)/(n - df - 1))
>> else qaic = as.numeric(-2 * ll/scale + 2 * df)
>> qaic
>> }
>> #######
>> QAICc(mq1,scale=phi)

   In order to use QAICc you have to do the following:

phi = lme4:::sigma(mq1)
QAICc(mp1,scale=phi)

  (see p. 8 of the Bolker et al supplement)

The basic problem is that quasi- models don't return likelihoods,
and non-quasi- models don't return estimates of scale parameters,
so you have fit both and combine the information.

  good luck,
    Ben Bolker



From amelie.lescroel at cebc.cnrs.fr  Wed Oct 14 14:24:44 2009
From: amelie.lescroel at cebc.cnrs.fr (amelie lescroel)
Date: Wed, 14 Oct 2009 12:24:44 +0000
Subject: [R-sig-ME] Calculating an Intraclass Correlation Coefficient or
	Repeatability estimate from lmer() output
Message-ID: <1255523084.833d834amelie.lescroel@cebc.cnrs.fr>

Dear all,

I am interested in calculating an Intraclass Correlation Coefficient (ICC) or Repeatability estimate from a mixed model output (lmer()). Lessels & Boag (1987) defined repeatability as the intraclass correlation coefficient based on variance components derived from a one-way anova: 
r = among-groups variance components / (within-group variance components + among-group variance components)
What I would like to know is where/how to find these variance components in a lmer() output.

Specifically, we measured foraging efficiency (CPUE) of birds during 10 consecutive years. We have several measures per bird for each year and the same birds were measured over multiple years. What I would like to get is an estimate of the intra-individual consistency of foraging efficiency over time. And I thought that the ICC or repeatability would be this estimate (recently used in the same manner in Lang et al. 2009 Ecology 90(9): 2513-2523).

Let?s run a model with the ID of the birds as a random factor:

> (fm1 <- lmer(log.CPUE~(1|ID)))
Linear mixed model fit by REML 
Formula: log.CPUE ~ (1 | ID) 
   AIC   BIC logLik deviance REMLdev
 -1144 -1126  575.2    -1158   -1150
Random effects:
 Groups   Name        Variance Std.Dev.
 ID       (Intercept) 0.010292 0.10145 
 Residual             0.036602 0.19132 
Number of obs: 3320, groups: ID, 341

Fixed effects:
            Estimate Std. Error t value
(Intercept)   0.3484     0.0068   51.24

In this case, is the within-individual variance = 0.010 and the among-individuals variance = 0.037?

Thanks for your help,

Amelie

Am?lie Lescro?l
Seabird ecologist
URU 420, Universit? de Rennes I - Service du Patrimoine Naturel, Museum National d?Histoire Naturelle
263 Av. du Gal Leclerc
35042 Rennes Cedex
France




__________ Information from ESET Mail Security, version of virus signature database 4506 (20091014) __________

The message was checked by ESET Mail Security.
http://www.eset.com



From j.hadfield at ed.ac.uk  Wed Oct 14 16:38:44 2009
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Wed, 14 Oct 2009 15:38:44 +0100
Subject: [R-sig-ME] Calculating an Intraclass Correlation Coefficient or
	Repeatability estimate from lmer() output
In-Reply-To: <1255523084.833d834amelie.lescroel@cebc.cnrs.fr>
References: <1255523084.833d834amelie.lescroel@cebc.cnrs.fr>
Message-ID: <FFB768C7-D112-41B5-9D42-EEF6A0C45A79@ed.ac.uk>

Hi,

You have the components the wrong way round:  the ID variance is the  
among groups, and the Residual variance is the within groups, but  
other than that it looks fine.

Jarrod
On 14 Oct 2009, at 13:24, amelie lescroel wrote:

> Dear all,
>
> I am interested in calculating an Intraclass Correlation Coefficient  
> (ICC) or Repeatability estimate from a mixed model output (lmer()).  
> Lessels & Boag (1987) defined repeatability as the intraclass  
> correlation coefficient based on variance components derived from a  
> one-way anova:
> r = among-groups variance components / (within-group variance  
> components + among-group variance components)
> What I would like to know is where/how to find these variance  
> components in a lmer() output.
>
> Specifically, we measured foraging efficiency (CPUE) of birds during  
> 10 consecutive years. We have several measures per bird for each  
> year and the same birds were measured over multiple years. What I  
> would like to get is an estimate of the intra-individual consistency  
> of foraging efficiency over time. And I thought that the ICC or  
> repeatability would be this estimate (recently used in the same  
> manner in Lang et al. 2009 Ecology 90(9): 2513-2523).
>
> Let?s run a model with the ID of the birds as a random factor:
>
>> (fm1 <- lmer(log.CPUE~(1|ID)))
> Linear mixed model fit by REML
> Formula: log.CPUE ~ (1 | ID)
>   AIC   BIC logLik deviance REMLdev
> -1144 -1126  575.2    -1158   -1150
> Random effects:
> Groups   Name        Variance Std.Dev.
> ID       (Intercept) 0.010292 0.10145
> Residual             0.036602 0.19132
> Number of obs: 3320, groups: ID, 341
>
> Fixed effects:
>            Estimate Std. Error t value
> (Intercept)   0.3484     0.0068   51.24
>
> In this case, is the within-individual variance = 0.010 and the  
> among-individuals variance = 0.037?
>
> Thanks for your help,
>
> Amelie
>
> Am?lie Lescro?l
> Seabird ecologist
> URU 420, Universit? de Rennes I - Service du Patrimoine Naturel,  
> Museum National d?Histoire Naturelle
> 263 Av. du Gal Leclerc
> 35042 Rennes Cedex
> France
>
>
>
>
> __________ Information from ESET Mail Security, version of virus  
> signature database 4506 (20091014) __________
>
> The message was checked by ESET Mail Security.
> http://www.eset.com
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From g.humphreys.1 at research.gla.ac.uk  Fri Oct 16 10:55:39 2009
From: g.humphreys.1 at research.gla.ac.uk (Georgina Sarah Humphreys)
Date: Fri, 16 Oct 2009 09:55:39 +0100
Subject: [R-sig-ME] malaria data set question
Message-ID: <1255683339.995585fcg.humphreys.1@research.gla.ac.uk>

I have a data set of number of malaria parasite genomes inside single oocysts (like egg sacks) dissected from guts of mosquitoes.  The data set includes some single oocysts that were collected from the same mosquitoes and multiple different experiments, conducted on different days.

The question I want to ask is:
Are the genome numbers in single oocysts associated with any of three variables measured -
1. number of oocysts on the gut (continuous)
2. the wing length of the mosquito (continuous)
3. the species of the parasite used (binary)
I also have the random effect of the mosquito nested in the random effect of experiment.

I have tried the following model;
model <- lmer(genomes~oocysts+wingsize+species+(1|mosq)+(1|expt), REML=FALSE)

But I'm not sure this is correct... should I use (1|mosq:expt) instead? 

Any help would be gratefully received - I have to hand-in my thesis in 10 days, and I'm new to lmer!
Many thanks in advance,
Georgina
PhD Student
Division of Infection and Immunity
B5-29, GBRC
120 University Place
Glasgow
G12 8TA
Tel: 0141 330 5650



From Paul.Prew at ecolab.com  Fri Oct 16 16:54:07 2009
From: Paul.Prew at ecolab.com (Prew, Paul)
Date: Fri, 16 Oct 2009 09:54:07 -0500
Subject: [R-sig-ME] P-values for balanced mixed model with nesting
Message-ID: <6B810AFB14C606439FD57E5985E037910433958A@useagan1500p.GLOBAL.ECOLAB.CORP>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20091016/ca86e8da/attachment.pl>

From Paul.Prew at ecolab.com  Fri Oct 16 20:15:51 2009
From: Paul.Prew at ecolab.com (Prew, Paul)
Date: Fri, 16 Oct 2009 13:15:51 -0500
Subject: [R-sig-ME] P-values for balanced mixed model with nesting
Message-ID: <6B810AFB14C606439FD57E5985E037910433982F@useagan1500p.GLOBAL.ECOLAB.CORP>

My apologies for sending this message twice, my first attempt was interpreted as an HTML document and "scrubbed", which I guess means removed.  MS Outlook says the current format is plain text.  If it also causes problems, I would appreciate advice on how to post to this list.

Hello, I am working with data from a balanced designed experiment and I'm unsure of how to model it to get the answers I'm seeking.  Two Detergents (current vs. experimental) are being compared against 6 different types of fabric Soils (motor oil, lipstick, etc).  Thus Soil and Detergent have fixed effects.  Each Detergent was tested on 3 different Loads of laundry. A single laundry Load consists of 3 "Backers"  where a Backer is a fabric sample that's been partitioned into a grid of 6 areas.  Each area contains one of the 6 soils.  All experiments were conducted in a lab using the same washing machine.  Soil Removal is the response measurement.
Whole plots:  Loads    --- 3 nested within each Detergent
Whole plot factor:  Detergent   --- 2 levels
Split Plot:  Backer   --- 3 nested within each Load
Split Plot factor:  Soil   --- 6 levels
Here's my question:  I have somehow gotten the impression that for balanced data, the p-values from a mixed effects analysis can be trusted.  However, the lmer function doesn't output p-values regardless of the case.  I'd like to do multiple comparisons to find the Soil:Detergent combinations that stand out as statistically significant.  Does anyone have advice for accomplishing this? 
Ultimately, my purpose is to provide a method to this chemist who is studying detergents, because he wants do the analysis himself.  Admirable, wouldn't you agree?    I want to avoid a discussion of 'p-values aren't that important, just make a qualitative comparison using the t-values'.  That would be a mixed message considering our statistics group's attempts to get the scientists to do less eyeballing and make decisions more objectively, i.e. consider statistical significance.
I asked a similar question a few months ago, and got a reasonable answer that the blocking factors such as Load and Backer could be modeled as fixed effects.  However, if I do that for this nested case, the Soil effects are conditional on the Load and the Backer.  I apologize if I'm not providing enough information.  Please let me know if I could add anything.  Thank you for taking the time to consider my request.

Regards, Paul

====================================================
> str(SoilOut)
'data.frame': 108 obs. of 6 variables:
$ Soil : Factor w/ 6 levels "DSB.P/C","EMPA.101",..: 1 1 1 2 2 2 3 3 3 4 ...
$ Detergent : Factor w/ 2 levels "EXP2","Xtra": 2 2 2 2 2 2 2 2 2 2 ...
$ X.SoilRemoval: num 76 76 76.5 41.2 34.8 ...
$ Load : Factor w/ 6 levels "1","2","3","4",..: 1 1 1 1 1 1 1 1 1 1 ...
$ Backer : Factor w/ 18 levels "1","2","3","4",..: 1 1 1 1 1 1 2 2 2 2 ... 
==============================================
m2<-lmer(X.SoilRemoval~Detergent*Soil + (1 | Load/Backer), SoilOut) 
> summary (m2)
Fixed effects:
                                   Estimate Std. Error t value
(Intercept)                         74.1804     1.7712   41.88
Detergent[T.Xtra]                   -3.2044     2.5049   -1.28
Soil[T.EMPA.101]                   -35.1601     2.0543  -17.12
Soil[T.EMPA.104]                   -26.2447     2.5049  -10.48
Soil[T.EMPA.106]                   -35.4014     2.5049  -14.13
Soil[T.LIPSTICK]                   -12.1608     2.5049   -4.85
Soil[T.MAKE-UP]                    -38.1436     2.5049  -15.23
Detergent[T.Xtra]:Soil[T.EMPA.101]   0.8651     2.9053    0.30
Detergent[T.Xtra]:Soil[T.EMPA.104]  -4.0126     3.5425   -1.13
Detergent[T.Xtra]:Soil[T.EMPA.106]   0.6405     3.5425    0.18
Detergent[T.Xtra]:Soil[T.LIPSTICK]  -0.9912     3.5425   -0.28
Detergent[T.Xtra]:Soil[T.MAKE-UP]    2.9547     3.5425    0.83

Paul Prew   ?  Statistician
651-795-5942   ?   fax 651-204-7504 
Ecolab Research Center   ?  Mail Stop ESC-F4412-A 
655 Lone Oak Drive   ?   Eagan, MN 55121-1560 


CONFIDENTIALITY NOTICE: 
This e-mail communication and any attachments may contain proprietary and privileged information for the use of the designated recipients named above. 
Any unauthorized review, use, disclosure or distribution is prohibited. 
If you are not the intended recipient, please contact the sender by reply e-mail and destroy all copies of the original message.


From bates at stat.wisc.edu  Fri Oct 16 20:19:04 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 16 Oct 2009 13:19:04 -0500
Subject: [R-sig-ME] P-values for balanced mixed model with nesting
In-Reply-To: <6B810AFB14C606439FD57E5985E037910433982F@useagan1500p.GLOBAL.ECOLAB.CORP>
References: <6B810AFB14C606439FD57E5985E037910433982F@useagan1500p.GLOBAL.ECOLAB.CORP>
Message-ID: <40e66e0b0910161119k3209ea1sec649d2de5264e6b@mail.gmail.com>

Whenever HTML mail is sent there is always a text copy included with
it.  All that the "scrubbed" message means is that the HTML part was
removed and the text part sent to the list.

On Fri, Oct 16, 2009 at 1:15 PM, Prew, Paul <Paul.Prew at ecolab.com> wrote:
> My apologies for sending this message twice, my first attempt was interpreted as an HTML document and "scrubbed", which I guess means removed. ?MS Outlook says the current format is plain text. ?If it also causes problems, I would appreciate advice on how to post to this list.
>
> Hello, I am working with data from a balanced designed experiment and I'm unsure of how to model it to get the answers I'm seeking. ?Two Detergents (current vs. experimental) are being compared against 6 different types of fabric Soils (motor oil, lipstick, etc). ?Thus Soil and Detergent have fixed effects. ?Each Detergent was tested on 3 different Loads of laundry. A single laundry Load consists of 3 "Backers" ?where a Backer is a fabric sample that's been partitioned into a grid of 6 areas. ?Each area contains one of the 6 soils. ?All experiments were conducted in a lab using the same washing machine. ?Soil Removal is the response measurement.
> Whole plots: ?Loads ? ?--- 3 nested within each Detergent
> Whole plot factor: ?Detergent ? --- 2 levels
> Split Plot: ?Backer ? --- 3 nested within each Load
> Split Plot factor: ?Soil ? --- 6 levels
> Here's my question: ?I have somehow gotten the impression that for balanced data, the p-values from a mixed effects analysis can be trusted. ?However, the lmer function doesn't output p-values regardless of the case. ?I'd like to do multiple comparisons to find the Soil:Detergent combinations that stand out as statistically significant. ?Does anyone have advice for accomplishing this?
> Ultimately, my purpose is to provide a method to this chemist who is studying detergents, because he wants do the analysis himself. ?Admirable, wouldn't you agree? ? ?I want to avoid a discussion of 'p-values aren't that important, just make a qualitative comparison using the t-values'. ?That would be a mixed message considering our statistics group's attempts to get the scientists to do less eyeballing and make decisions more objectively, i.e. consider statistical significance.
> I asked a similar question a few months ago, and got a reasonable answer that the blocking factors such as Load and Backer could be modeled as fixed effects. ?However, if I do that for this nested case, the Soil effects are conditional on the Load and the Backer. ?I apologize if I'm not providing enough information. ?Please let me know if I could add anything. ?Thank you for taking the time to consider my request.
>
> Regards, Paul
>
> ====================================================
>> str(SoilOut)
> 'data.frame': 108 obs. of 6 variables:
> $ Soil : Factor w/ 6 levels "DSB.P/C","EMPA.101",..: 1 1 1 2 2 2 3 3 3 4 ...
> $ Detergent : Factor w/ 2 levels "EXP2","Xtra": 2 2 2 2 2 2 2 2 2 2 ...
> $ X.SoilRemoval: num 76 76 76.5 41.2 34.8 ...
> $ Load : Factor w/ 6 levels "1","2","3","4",..: 1 1 1 1 1 1 1 1 1 1 ...
> $ Backer : Factor w/ 18 levels "1","2","3","4",..: 1 1 1 1 1 1 2 2 2 2 ...
> ==============================================
> m2<-lmer(X.SoilRemoval~Detergent*Soil + (1 | Load/Backer), SoilOut)
>> summary (m2)
> Fixed effects:
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? Estimate Std. Error t value
> (Intercept) ? ? ? ? ? ? ? ? ? ? ? ? 74.1804 ? ? 1.7712 ? 41.88
> Detergent[T.Xtra] ? ? ? ? ? ? ? ? ? -3.2044 ? ? 2.5049 ? -1.28
> Soil[T.EMPA.101] ? ? ? ? ? ? ? ? ? -35.1601 ? ? 2.0543 ?-17.12
> Soil[T.EMPA.104] ? ? ? ? ? ? ? ? ? -26.2447 ? ? 2.5049 ?-10.48
> Soil[T.EMPA.106] ? ? ? ? ? ? ? ? ? -35.4014 ? ? 2.5049 ?-14.13
> Soil[T.LIPSTICK] ? ? ? ? ? ? ? ? ? -12.1608 ? ? 2.5049 ? -4.85
> Soil[T.MAKE-UP] ? ? ? ? ? ? ? ? ? ?-38.1436 ? ? 2.5049 ?-15.23
> Detergent[T.Xtra]:Soil[T.EMPA.101] ? 0.8651 ? ? 2.9053 ? ?0.30
> Detergent[T.Xtra]:Soil[T.EMPA.104] ?-4.0126 ? ? 3.5425 ? -1.13
> Detergent[T.Xtra]:Soil[T.EMPA.106] ? 0.6405 ? ? 3.5425 ? ?0.18
> Detergent[T.Xtra]:Soil[T.LIPSTICK] ?-0.9912 ? ? 3.5425 ? -0.28
> Detergent[T.Xtra]:Soil[T.MAKE-UP] ? ?2.9547 ? ? 3.5425 ? ?0.83
>
> Paul Prew ? ? ?Statistician
> 651-795-5942 ? ? ? fax 651-204-7504
> Ecolab Research Center ? ? ?Mail Stop ESC-F4412-A
> 655 Lone Oak Drive ? ? ? Eagan, MN 55121-1560
>
>
> CONFIDENTIALITY NOTICE:
> This e-mail communication and any attachments may contain proprietary and privileged information for the use of the designated recipients named above.
> Any unauthorized review, use, disclosure or distribution is prohibited.
> If you are not the intended recipient, please contact the sender by reply e-mail and destroy all copies of the original message.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From trea26 at gmail.com  Sat Oct 17 17:33:49 2009
From: trea26 at gmail.com (Antoine Tremblay)
Date: Sat, 17 Oct 2009 11:33:49 -0400
Subject: [R-sig-ME] To conjoin or not to conjoin factorial variables?
Message-ID: <581a8bcf0910170833l2d3bda57idf70c5c6bb0a5947@mail.gmail.com>

Hello all,

We are interested in an interaction between FACTOR A (levels "a" and
"b"), FACTOR B (levels "c" and "d") and variable TIME (which we model
with a 5 knot restricted cubic spline). That is:

              m1=
lmer(LogRT~A*B*rcs(TIME,5)+(1|Subject)+(1|Item)+(1|TIME)+(0+TIME|Subject),data=dat).
              (1)

Because (i) plotLMER.fnc cannot plot 3-way interactions, and (ii) we
are unable to look at the contrasts of interest, which are ("ac" vs.
"bc"), ("ad" vs. "bd"), ("bc" vs. "bd"), and ("ac" vs. "ad"), we
decided to collapse factors A and B into a new variable ConjVar with 4
levels "ac", "ad", "bc", and "bd". The model thus becomes:

              m2=lmer(LogRT~ConjVar*rcs(TIME,5)+(1|Subject)+(1|Item)+(1|TIME)+(0+TIME|Subject),data=dat)
          (2)

We find significant differences in the first spline only between
levels "ac" and "bc", between "ad" and "bd", between "bc" and "bd",
but not between "ac" and "ad". Having the ConjVar also enables us to
plot the ConjVar*rcs(TIME,5) interaction with plotLMER.fnc():

              plotLMER.fnc(m2,pred="TIME",intr=list("ConjVar",levels(dat$ConjVar),"mid",list(1:4,rep(1,4))),lwd=2)
       (3)

Now, here comes the part we don't understand.

If we do "anova(m1)", the interaction A*B*rcs(TIME,5) is not
significant, but if we look at the table returned by "anova(m2)", then
the ConjVar*rcs(TIME,5) interaction is highly significant. The
questions we have are the following:

   (i)  Is it correct to conjoin factors A and B into ConjVar and run
our analyses using this variable?

   (ii) Why is the interaction A*B*rcs(TIME,5) not significant in (1)
but highly significant in (2)?

   (iii) Would the proper steps here rather be:
                        (I) run the model with A*B*rcs(TIME,5) and see
if this interaction is significant
                            (as shown in the "anova(m1)" table);
                        (II) and, if it is significant, then refit a
model with the conjoined variable ConjVar and
                             determine where the actual differences
are and plot them?

Thank you very much for your time,

--
Antoine Tremblay
Department of Neuroscience
Georgetown University
Washington DC



From trea26 at gmail.com  Sun Oct 18 14:39:59 2009
From: trea26 at gmail.com (Antoine Tremblay)
Date: Sun, 18 Oct 2009 08:39:59 -0400
Subject: [R-sig-ME] To conjoin or not to conjoin factorial variables?
Message-ID: <581a8bcf0910180539i2484b563w8a9a57af73740d7c@mail.gmail.com>

Hello all,

We are interested in an interaction between FACTOR A (levels "a" and
"b"), FACTOR B (levels "c" and "d") and variable TIME (which we model
with a 5 knot restricted cubic spline). That is:

             m1=
lmer(LogRT~A*B*rcs(TIME,5)+(1|Subject)+(1|Item)+(1|TIME)+(0+TIME|Subject),data=dat).
             (1)

Because (i) plotLMER.fnc cannot plot 3-way interactions, and (ii) we
are unable to look at the contrasts of interest, which are ("ac" vs.
"bc"), ("ad" vs. "bd"), ("bc" vs. "bd"), and ("ac" vs. "ad"), we
decided to collapse factors A and B into a new variable ConjVar with 4
levels "ac", "ad", "bc", and "bd". The model thus becomes:

             m2=lmer(LogRT~ConjVar*rcs(TIME,5)+(1|Subject)+(1|Item)+(1|TIME)+(0+TIME|Subject),data=dat)
         (2)

We find significant differences in the first spline only between
levels "ac" and "bc", between "ad" and "bd", between "bc" and "bd",
but not between "ac" and "ad". Having the ConjVar also enables us to
plot the ConjVar*rcs(TIME,5) interaction with plotLMER.fnc():

             plotLMER.fnc(m2,pred="TIME",intr=list("ConjVar",levels(dat$ConjVar),"mid",list(1:4,rep(1,4))),lwd=2)
      (3)

Now, here comes the part we don't understand.

If we do "anova(m1)", the interaction A*B*rcs(TIME,5) is not
significant, but if we look at the table returned by "anova(m2)", then
the ConjVar*rcs(TIME,5) interaction is highly significant. The
questions we have are the following:

  (i)  Is it correct to conjoin factors A and B into ConjVar and run
our analyses using this variable?

  (ii) Why is the interaction A*B*rcs(TIME,5) not significant in (1)
but highly significant in (2)?

  (iii) Would the proper steps here rather be:
                       (I) run the model with A*B*rcs(TIME,5) and see
if this interaction is significant
                           (as shown in the "anova(m1)" table);
                       (II) and, if it is significant, then refit a
model with the conjoined variable ConjVar and
                            determine where the actual differences
are and plot them?

Thank you very much for your time,

-- 
Antoine Tremblay
Department of Neuroscience
Georgetown University
Washington DC



From bates at stat.wisc.edu  Sun Oct 18 18:24:59 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Sun, 18 Oct 2009 11:24:59 -0500
Subject: [R-sig-ME] To conjoin or not to conjoin factorial variables?
In-Reply-To: <581a8bcf0910170833l2d3bda57idf70c5c6bb0a5947@mail.gmail.com>
References: <581a8bcf0910170833l2d3bda57idf70c5c6bb0a5947@mail.gmail.com>
Message-ID: <40e66e0b0910180924j4af55fc5xe347ab2e63bef944@mail.gmail.com>

On Sat, Oct 17, 2009 at 10:33 AM, Antoine Tremblay <trea26 at gmail.com> wrote:
> Hello all,
>
> We are interested in an interaction between FACTOR A (levels "a" and
> "b"), FACTOR B (levels "c" and "d") and variable TIME (which we model
> with a 5 knot restricted cubic spline). That is:
>
> ? ? ? ? ? ? ?m1=
> lmer(LogRT~A*B*rcs(TIME,5)+(1|Subject)+(1|Item)+(1|TIME)+(0+TIME|Subject),data=dat).
> ? ? ? ? ? ? ?(1)

I'm not sure I understand the model specification.  Is TIME numeric or
a factor or ...?  It unusual to have a term (1|TIME), which would
indicate that TIME is a factor with a large number of levels, and
another term of the form (0+TIME|Subject), which would indicate that
TIME is a continuous covariate or a factor with a small number of
levels.

> Because (i) plotLMER.fnc cannot plot 3-way interactions,

Are you referring to a function in the languageR package?

> and (ii) we
> are unable to look at the contrasts of interest, which are ("ac" vs.
> "bc"), ("ad" vs. "bd"), ("bc" vs. "bd"), and ("ac" vs. "ad"), we
> decided to collapse factors A and B into a new variable ConjVar with 4
> levels "ac", "ad", "bc", and "bd". The model thus becomes:
>
> ? ? ? ? ? ? ?m2=lmer(LogRT~ConjVar*rcs(TIME,5)+(1|Subject)+(1|Item)+(1|TIME)+(0+TIME|Subject),data=dat)
> ? ? ? ? ?(2)
>
> We find significant differences in the first spline only between
> levels "ac" and "bc", between "ad" and "bd", between "bc" and "bd",
> but not between "ac" and "ad". Having the ConjVar also enables us to
> plot the ConjVar*rcs(TIME,5) interaction with plotLMER.fnc():
>
> ? ? ? ? ? ? ?plotLMER.fnc(m2,pred="TIME",intr=list("ConjVar",levels(dat$ConjVar),"mid",list(1:4,rep(1,4))),lwd=2)
> ? ? ? (3)
>
> Now, here comes the part we don't understand.
>
> If we do "anova(m1)", the interaction A*B*rcs(TIME,5) is not
> significant, but if we look at the table returned by "anova(m2)", then
> the ConjVar*rcs(TIME,5) interaction is highly significant. The
> questions we have are the following:
>
> ? (i) ?Is it correct to conjoin factors A and B into ConjVar and run
> our analyses using this variable?
>
> ? (ii) Why is the interaction A*B*rcs(TIME,5) not significant in (1)
> but highly significant in (2)?
>
> ? (iii) Would the proper steps here rather be:
> ? ? ? ? ? ? ? ? ? ? ? ?(I) run the model with A*B*rcs(TIME,5) and see
> if this interaction is significant
> ? ? ? ? ? ? ? ? ? ? ? ? ? ?(as shown in the "anova(m1)" table);
> ? ? ? ? ? ? ? ? ? ? ? ?(II) and, if it is significant, then refit a
> model with the conjoined variable ConjVar and
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? determine where the actual differences
> are and plot them?
>
> Thank you very much for your time,
>
> --
> Antoine Tremblay
> Department of Neuroscience
> Georgetown University
> Washington DC
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From bates at stat.wisc.edu  Mon Oct 19 01:28:37 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Sun, 18 Oct 2009 18:28:37 -0500
Subject: [R-sig-ME] To conjoin or not to conjoin factorial variables?
In-Reply-To: <581a8bcf0910181326k529f4c7bw40a2151d99d71a96@mail.gmail.com>
References: <581a8bcf0910170833l2d3bda57idf70c5c6bb0a5947@mail.gmail.com>
	<40e66e0b0910180924j4af55fc5xe347ab2e63bef944@mail.gmail.com>
	<581a8bcf0910181326k529f4c7bw40a2151d99d71a96@mail.gmail.com>
Message-ID: <40e66e0b0910181628m19ae6fa3p4ba7f344371247c@mail.gmail.com>

On Sun, Oct 18, 2009 at 3:26 PM, Antoine Tremblay <trea26 at gmail.com> wrote:
> On Sun, Oct 18, 2009 at 12:24 PM, Douglas Bates <bates at stat.wisc.edu> wrote:
>> On Sat, Oct 17, 2009 at 10:33 AM, Antoine Tremblay <trea26 at gmail.com> wrote:
>>> Hello all,
>>>
>>> We are interested in an interaction between FACTOR A (levels "a" and
>>> "b"), FACTOR B (levels "c" and "d") and variable TIME (which we model
>>> with a 5 knot restricted cubic spline). That is:
>>>
>>> ? ? ? ? ? ? ?m1=
>>> lmer(LogRT~A*B*rcs(TIME,5)+(1|Subject)+(1|Item)+(1|TIME)+(0+TIME|Subject),data=dat).
>>> ? ? ? ? ? ? ?(1)
>>
>> I'm not sure I understand the model specification. ?Is TIME numeric or
>> a factor or ...?
>
> TIME is a numeric variable ranging from 1 to 1600.
>
>> It unusual to have a term (1|TIME), which would
>> indicate that TIME is a factor with a large number of levels, and
>> another term of the form (0+TIME|Subject), which would indicate that
>> TIME is a continuous covariate or a factor with a small number of
>> levels.
>
> Please correct me if I'm wrong, but I understood from Baayen, Davidson
> & Bates (2008) [Baayen, R.H., Davidson, D.J. & Bates, D.M. (2008).
> Mixed-effects modeling with crossed random effects for subjects and
> items. Journal of Memory and Language, 59, Special Issue: Emerging
> Data Analysis Techniques, 390-412] that putting a variable in the
> random-effects structure (in LMER) can model potential
> heteroscedasticity in that variable.

> So I tested (using the log-likelihood ratio test) whether having
> (1|TIME) in the model was warranted or not and it was. I thus took
> this to mean that there was significant heteroscedasticity in TIME
> (i.e., the difference between the mean variance of all time points and
> the variance of each time-point is big enough to be statistically
> significant).

> ?Regarding (0+TIME|Subject), well I tested (log-likelihood ratio
> test) to see whether the slope for TIME significantly differed between
> subjets (i.e., heteroscedasticity regarding the slopes for TIME).

I'm afraid I am still confused.  If TIME is on a continuous scale then
(1|TIME) doesn't make sense.  If TIME is a factor then
(0+TIME|Subject) will result in an attempt to estimate a huge
variance-covariance matrix.

>>> Because (i) plotLMER.fnc cannot plot 3-way interactions,
>>
>> Are you referring to a function in the languageR package?
>
> Yes, I am referring to plotLMER in the languageR package.
>
>>
>>> and (ii) we
>>> are unable to look at the contrasts of interest, which are ("ac" vs.
>>> "bc"), ("ad" vs. "bd"), ("bc" vs. "bd"), and ("ac" vs. "ad"), we
>>> decided to collapse factors A and B into a new variable ConjVar with 4
>>> levels "ac", "ad", "bc", and "bd". The model thus becomes:
>>>
>>> ? ? ? ? ? ? ?m2=lmer(LogRT~ConjVar*rcs(TIME,5)+(1|Subject)+(1|Item)+(1|TIME)+(0+TIME|Subject),data=dat)
>>> ? ? ? ? ?(2)
>>>
>>> We find significant differences in the first spline only between
>>> levels "ac" and "bc", between "ad" and "bd", between "bc" and "bd",
>>> but not between "ac" and "ad". Having the ConjVar also enables us to
>>> plot the ConjVar*rcs(TIME,5) interaction with plotLMER.fnc():
>>>
>>> ? ? ? ? ? ? ?plotLMER.fnc(m2,pred="TIME",intr=list("ConjVar",levels(dat$ConjVar),"mid",list(1:4,rep(1,4))),lwd=2)
>>> ? ? ? (3)
>>>
>>> Now, here comes the part we don't understand.
>>>
>>> If we do "anova(m1)", the interaction A*B*rcs(TIME,5) is not
>>> significant, but if we look at the table returned by "anova(m2)", then
>>> the ConjVar*rcs(TIME,5) interaction is highly significant. The
>>> questions we have are the following:
>>>
>>> ? (i) ?Is it correct to conjoin factors A and B into ConjVar and run
>>> our analyses using this variable?
>>>
>>> ? (ii) Why is the interaction A*B*rcs(TIME,5) not significant in (1)
>>> but highly significant in (2)?
>>>
>>> ? (iii) Would the proper steps here rather be:
>>> ? ? ? ? ? ? ? ? ? ? ? ?(I) run the model with A*B*rcs(TIME,5) and see
>>> if this interaction is significant
>>> ? ? ? ? ? ? ? ? ? ? ? ? ? ?(as shown in the "anova(m1)" table);
>>> ? ? ? ? ? ? ? ? ? ? ? ?(II) and, if it is significant, then refit a
>>> model with the conjoined variable ConjVar and
>>> ? ? ? ? ? ? ? ? ? ? ? ? ? ? determine where the actual differences
>>> are and plot them?
>>>
>>> Thank you very much for your time,
>>>
>>> --
>>> Antoine Tremblay
>>> Department of Neuroscience
>>> Georgetown University
>>> Washington DC
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>
>
>
> --
> Antoine Tremblay
> Department of Neuroscience
> Georgetown University
> Washington DC
>



From trea26 at gmail.com  Tue Oct 20 21:55:08 2009
From: trea26 at gmail.com (Antoine Tremblay)
Date: Tue, 20 Oct 2009 15:55:08 -0400
Subject: [R-sig-ME] Interactions and posthocs for LMER models
Message-ID: <581a8bcf0910201255x1f49ef87v5333b9c0ced20bb0@mail.gmail.com>

Hello all,
here's a question about interactions.
Let's just say you have the variables Diagnosis with two levels LI
(language impaired) and N (normals) and FreqGroup with two levels High
and Low. Then you have the following linear mixed-effects model:

model1=lmer(RT~Diagnosis*FreqGroup+(1|Subject)+(1|Item))

the last line of the model summary (print(model1,corr=F) will give you
for the 2-way interaction the following:
                         Estimate    Std. Error   t value
DiagnosisN:FreqGroupLow  1.187e-04   4.022e-05    2.95

Considering that the intercept will embody
"DiagnosisLI:FreqGroupHigh", that is, the levels from each variable
that comes first in the alphabet, does this mean that the line above
is
giving you the estimate, std. error and t-value of the difference between
DiagnosisLI and DiagnosisN minus the difference between FreqGroupHigh
and FreqGroupLow?


Now, in order to determine whether DiagnosisN:FreqGroupHigh is
different from DiagnosisN:FreqGroupLow, you have to create the dummy
variable DiagFreq which has now four levels (LI.High, LI.Low, N.High,
and N.Low) and rerun a model with that dummy variable and then
relevel() to N.Low and look at the comparison with N.High (and apply a
Bonferroni correction for the number of comparisons you made). Is that
right?

OK, say you have a slightly more complex model such as this one:

lmer(RT~Diagnosis*FreqGroup + Gender*FreqGroup+(1|Subject)+(1|Item),data=dat)

and say both interactions were significant. I don't know how I would
proceed to determine whether N-High is significantly different than
N-Low. That is, I will not be able to fit a model such as the one
below, where Diagnosis and FreqGroup are conjoined but FreqGroup is
present also and interacting with Gender:

lmer(RT~DiagFreq + Gender*FreqGroup +(1|Subject)+(1|Item), data=dat)

I thus tried conjoining Diagnosis, FreqGroup, and Gender into a
variable named DiagFreqGend with 8 levels now and contrast code so I
get only the N-High vs. N-Low, LI-High vs LI-Low and the interaction
(N-High minus N-Low) minus (LI-High-LI-Low). But it doesn't work. The
contrast matrix is singular and I get this error: Error in mer_finalize(ans) :
Downdated X'X is not positive definite, 6.

Maybe then I should use relevel() and look at the contrasts of interest only?


But then, what if the model becomes even more complex, such as the
following, where IQ_continuous is a continuous variable:

lmer(RT~Diagnosis*FreqGroup + Gender*FreqGroup + Handedness*FreqGroup +
IQ_continuous*FreqGroup +(1|Subject)+(1|Item), data=dat)

It's now impossible to make a super big conjoined variable because of
IQ_continuous.

What is a (or the) way out of this?

Your help is well appreciated,
Sincerely,
Antoine Tremblay



-- 
Antoine Tremblay
Department of Neuroscience
Georgetown University
Washington DC



From raldo.kruger at gmail.com  Wed Oct 21 11:24:22 2009
From: raldo.kruger at gmail.com (Raldo Kruger)
Date: Wed, 21 Oct 2009 11:24:22 +0200
Subject: [R-sig-ME] glmm.admb {glmmADMB} vs glmer {lme4}
Message-ID: <30406dd0910210224y661cd326q87c47392d70bce5@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20091021/3dd9d8b5/attachment.pl>

From J.Schliesser at uu.nl  Wed Oct 21 11:50:44 2009
From: J.Schliesser at uu.nl (Johannes Schliesser)
Date: Wed, 21 Oct 2009 11:50:44 +0200
Subject: [R-sig-ME] Crossing Interaction and lmer
Message-ID: <200910211150.44514.J.Schliesser@uu.nl>

Dear mixed model experts

I have troubles with a wired outcome with lmer(). 

I was testing effects on reaction times for two fixed factors, Identity 
(levels identical "id" and non-identical ("ni") and Bonus Size ("h"igh and 
"l"ow). Subjects "subj" and "items" were Random Effects. In fact, Bonus Size 
is nested within Items, as half of the Items were of high, the other half of 
low Bonus size.

The results indicate a strong crossing interaction:


       |    h   |    l   |   ALL  |
|id   |839.	 |861  |  850   |

|ni    |879    |829 |  854   |

|ALL| 859    |845  |852    |

Subjects tend to be about 40 ms faster for identical than for non-identical in 
the high bonus group, but about 30 ms slower for identical than for non-
identical in the low bonus group. Grand means for identical and non-identical 
items differ only for 4 ms.

So far so good.
Classic ANOVA rejects all main effects but confirmes the interaction.

The lmer analysis instead suggests a fixed effect for identity: 
----------
lmer.rtNA2 = lmer(rtNA~id*bonus+(1|subj)+(1|bonus/item), data = x4)
 lmer.rtNA
Linear mixed model fit by REML 
Formula: rtNA ~ id * bonus + (1 | subj) + (1 | item) 
   Data: x4 
   AIC   BIC logLik deviance REMLdev
 24346 24385 -12166    24360   24332
Random effects:
 Groups   Name        Variance Std.Dev.
 item     (Intercept)  1926.9   43.896 
 subj     (Intercept)  9648.6   98.227 
 Residual             19026.7  137.937 
Number of obs: 1905, groups: item, 80; subj, 24

Fixed effects:
            Estimate Std. Error t value
(Intercept)  839.804     22.132   37.95
idni          40.264      8.942    4.50
bonusl        22.841     13.278    1.72
idni:bonusl  -73.346     12.644   -5.80

Correlation of Fixed Effects:
            (Intr) idni   bonusl
idni        -0.202              
bonusl      -0.300  0.336       
idni:bonusl  0.143 -0.707 -0.476
-----------------------------------

The lmer model seems to test Identical vs. Non-Identical for the High-Bonus 
group only, but not overall (same as estimates for Bonus Size only in the "id" 
row). pvals.fnc() asssigns significance for Identity and the interaction 
Identity*Bonus Size.

I have the impression that this is missleading: we certainly cannot speak of  
slower reaction times for non-identical stimuli than for identical.

Leaving out the Bonus Size as a fixed factor "lmer(rt~id+(1|subj)+(1|item), 
data = x4)" gives a realistic t-value below 1 for Identity.

So, I ask: 
Is the missleading handling of crossing interactions a bug ? 
Or do I simply have to know that if there is a huge crossing interaction I 
should not generalize the Fixed Factor effects ?

And more relevant: How do I get an analysis that is appropriate to the data ?

Thanks for your help

Johannes



From trea26 at gmail.com  Wed Oct 21 13:31:52 2009
From: trea26 at gmail.com (Antoine Tremblay)
Date: Wed, 21 Oct 2009 07:31:52 -0400
Subject: [R-sig-ME] follow-up (posthoc) analyses from an LMER model
Message-ID: <581a8bcf0910210431p95e9654xbff089f20bceb@mail.gmail.com>

Hi everyone,
I'm wondering how to do follow-ups for an LMER model (e.g., Y ~ A * B
+ (1|Subject) + (1|Item) )

If you fit a model using the function aov(), naturally without the
random effects terms, you can use the TukeyHDS() function to do
multiple comparisons or the pairwise.t.test() function. Unfortunately,
these two functions can't be used to do posthocs analyses from an LMER
model (at least to the extent of my knowledge).

Thanks for your time!

Antoine

-- 
Antoine Tremblay
Department of Neuroscience
Georgetown University
Washington DC



From tobias.verbeke at telenet.be  Wed Oct 21 16:29:55 2009
From: tobias.verbeke at telenet.be (Tobias Verbeke)
Date: Wed, 21 Oct 2009 16:29:55 +0200
Subject: [R-sig-ME] follow-up (posthoc) analyses from an LMER model
In-Reply-To: <581a8bcf0910210431p95e9654xbff089f20bceb@mail.gmail.com>
References: <581a8bcf0910210431p95e9654xbff089f20bceb@mail.gmail.com>
Message-ID: <4ADF1AE3.9060708@telenet.be>

Hi Antoine,

> I'm wondering how to do follow-ups for an LMER model (e.g., Y ~ A * B
> + (1|Subject) + (1|Item) )
> 
> If you fit a model using the function aov(), naturally without the
> random effects terms, you can use the TukeyHDS() function to do
> multiple comparisons or the pairwise.t.test() function. Unfortunately,
> these two functions can't be used to do posthocs analyses from an LMER
> model (at least to the extent of my knowledge).

Have a look at the multcomp package. It knows how
to deal with lmer objects (and has lmer examples
in the package vignettes).

http://cran.r-project.org/web/packages/multcomp/index.html

HTH,
Tobias



From Mark.Lyman at atk.com  Wed Oct 21 18:34:41 2009
From: Mark.Lyman at atk.com (Lyman, Mark)
Date: Wed, 21 Oct 2009 10:34:41 -0600
Subject: [R-sig-ME] nlmer/nlme with custom selfStart
In-Reply-To: <mailman.7.1256119202.11965.r-sig-mixed-models@r-project.org>
References: <mailman.7.1256119202.11965.r-sig-mixed-models@r-project.org>
Message-ID: <A6BB278845329C41A08CB3C52A0E2C1001F00FBE@ut40se02.atk.com>

I am trying to fit a nonlinear mixed effects model with a my own
selfStart model. The selfStart model works fine with nls. I have tried
fitting the model in nlme and nlmer, but I have been unable to
understand the error message either produces. The following example
demonstrates my problem. Can anybody tell me what I am doing wrong? I
have had this problem on R 2.9.1, lme4 0.999375-31, and nlme 3.1-92 on
Windows and R 2.9.0, lme4 0.999375-28, and nlme 3.1-90 on Linux.

> library(nlme)
> 
> SSslgr <-
selfStart(~log(epsilon0)+(alpha0)*x-log(1+epsilon0/(alpha0)*9.6770731089
10072*(exp((alpha0)*x)-1)),
+ function(mCall, data, LHS)
+ {
+ xy <- sortedXyData(mCall[["x"]], LHS, data)
+ tmp <- coef(lm(y~x, data=xy))
+ value <- c(exp(tmp[1]), tmp[2])
+ names(value) <- mCall[c("epsilon0", "alpha0")]
+ value
+ }, c("epsilon0", "alpha0"))
> 
> 
> my.data <- expand.grid(x=seq(10, 120, length=12), group=1:50)
> epsilon0 <- 0.0004
> alpha0 <- 0.02
> my.data$y <- exp((rnorm(600)%*%chol(diag(50)%x%(diag(0.01,
12)+0.001)))[1,]+log(epsilon0)+(alpha0)*my.data$x-log(1+epsilon0/(alpha0
)*9.677073108910072*(exp((alpha0)*my.data$x)-1)))
> 
> nls(log(y)~SSslgr(x, epsilon0, alpha0), data=my.data)
Nonlinear regression model
  model:  log(y) ~ SSslgr(x, epsilon0, alpha0) 
   data:  my.data 
 epsilon0    alpha0 
0.0004001 0.0200358 
 residual sum-of-squares: 6.346

Number of iterations to convergence: 3 
Achieved convergence tolerance: 1.508e-07 
> 
> nlme(log(y)~SSslgr(x, epsilon0, alpha0), fixed=epsilon0+alpha0~1,
random=alpha0~1|group, data=my.data)
Error in nlmeCall[[i]] <- NULL : subscript out of bounds
> 
> unloadNamespace("nlme")
> 
> library(lme4)
Warning message:
package 'lme4' was built under R version 2.9.2 
> 
> nlmer(log(y)~SSslgr(x, epsilon0, alpha0) ~ alpha0|group, data=my.data,
start=list(fixef=c(epsilon0=0.0004, alpha0=0.02)))
Error: object 'y' not found
Error in model.frame(data = my.data, formula = log(y),
drop.unused.levels = TRUE) : 
  error in evaluating the argument 'formula' in selecting a method for
function 'model.frame'

Mark Lyman, Statistician
Engineering Systems & Integration, ATK



From grahamleask at btinternet.com  Thu Oct 22 12:18:36 2009
From: grahamleask at btinternet.com (Graham Leask)
Date: Thu, 22 Oct 2009 11:18:36 +0100
Subject: [R-sig-ME] Multinomial mixed effect model
Message-ID: <000601ca5301$09973e60$1cc5bb20$@com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20091022/69dfb45e/attachment.pl>

From bates at stat.wisc.edu  Thu Oct 22 15:27:20 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 22 Oct 2009 08:27:20 -0500
Subject: [R-sig-ME] glmm.admb {glmmADMB} vs glmer {lme4}
In-Reply-To: <30406dd0910210224y661cd326q87c47392d70bce5@mail.gmail.com>
References: <30406dd0910210224y661cd326q87c47392d70bce5@mail.gmail.com>
Message-ID: <40e66e0b0910220627u2530c497n8ebbdc03f8c825f9@mail.gmail.com>

On Wed, Oct 21, 2009 at 4:24 AM, Raldo Kruger <raldo.kruger at gmail.com> wrote:
> Hi mixed modelers,
>
> I'm using glmm.admb and glmer functions to fit mixed models on the same data
> (downloadable here
> <http://www.castafile.com/get/03a1935310acf4a7271b09cbfbf477d1>) and trying
> to assess which model provides the better fit.
>
> m1<-glmm.admb(Counts~T*Year+B*Year+P*Year, random=Site, group="Year",
> data=ex1o, family="nbinom", zeroInflation=TRUE)
>
> m2<-glmer(Counts~T*Year+B*Year+P*Year*(1|Site), data=ex1o,
> family=quasipoisson)

Should that formula be Counts~T*Year+B*Year+P*Year + (1|Site)?  I
don't know what a term like P*Year*(1|Site) in the formula passed to
glmer would do but it should throw an error.

>
> My questions are:
>
> 1) How can I extract the AIC values from m1?
>
> 2) Are the AIC values comparable between the two models (i.e. can I compare
> them for model selection)?
>
> 3) For m2, the true estimates for the fixed effects can be calculated by
> exp(returned estimate). Is this true for m1 too, or does the negative
> binomial distribution require a different conversion?
>
> 4) What is the difference between the 'random' and the 'group' argument in
> the glmm.admb function (I've read the documentation but it's still unclear)?
>
> Much appreciated,
>
> Raldo
> MSc student
> University of Cape Town
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From bates at stat.wisc.edu  Thu Oct 22 16:03:22 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 22 Oct 2009 09:03:22 -0500
Subject: [R-sig-ME] Crossing Interaction and lmer
In-Reply-To: <200910211150.44514.J.Schliesser@uu.nl>
References: <200910211150.44514.J.Schliesser@uu.nl>
Message-ID: <40e66e0b0910220703q5e1dd819m516a30178c98782d@mail.gmail.com>

On Wed, Oct 21, 2009 at 4:50 AM, Johannes Schliesser <J.Schliesser at uu.nl> wrote:
> Dear mixed model experts
>
> I have troubles with a wired outcome with lmer().
>
> I was testing effects on reaction times for two fixed factors, Identity
> (levels identical "id" and non-identical ("ni") and Bonus Size ("h"igh and
> "l"ow). Subjects "subj" and "items" were Random Effects. In fact, Bonus Size
> is nested within Items, as half of the Items were of high, the other half of
> low Bonus size.
>
> The results indicate a strong crossing interaction:
>
>
> ? ? ? | ? ?h ? | ? ?l ? | ? ALL ?|
> |id ? |839. ? ? ?|861 ?| ?850 ? |
>
> |ni ? ?|879 ? ?|829 | ?854 ? |
>
> |ALL| 859 ? ?|845 ?|852 ? ?|
>
> Subjects tend to be about 40 ms faster for identical than for non-identical in
> the high bonus group, but about 30 ms slower for identical than for non-
> identical in the low bonus group. Grand means for identical and non-identical
> items differ only for 4 ms.
>
> So far so good.
> Classic ANOVA rejects all main effects but confirmes the interaction.
>
> The lmer analysis instead suggests a fixed effect for identity:
> ----------
> lmer.rtNA2 = lmer(rtNA~id*bonus+(1|subj)+(1|bonus/item), data = x4)

The model that you summarize below is not the model fit by this
expression and, in fact, this model would not make sense.

> ?lmer.rtNA
> Linear mixed model fit by REML
> Formula: rtNA ~ id * bonus + (1 | subj) + (1 | item)
> ? Data: x4
> ? AIC ? BIC logLik deviance REMLdev
> ?24346 24385 -12166 ? ?24360 ? 24332
> Random effects:
> ?Groups ? Name ? ? ? ?Variance Std.Dev.
> ?item ? ? (Intercept) ?1926.9 ? 43.896
> ?subj ? ? (Intercept) ?9648.6 ? 98.227
> ?Residual ? ? ? ? ? ? 19026.7 ?137.937
> Number of obs: 1905, groups: item, 80; subj, 24
>
> Fixed effects:
> ? ? ? ? ? ?Estimate Std. Error t value
> (Intercept) ?839.804 ? ? 22.132 ? 37.95
> idni ? ? ? ? ?40.264 ? ? ?8.942 ? ?4.50
> bonusl ? ? ? ?22.841 ? ? 13.278 ? ?1.72
> idni:bonusl ?-73.346 ? ? 12.644 ? -5.80
>
> Correlation of Fixed Effects:
> ? ? ? ? ? ?(Intr) idni ? bonusl
> idni ? ? ? ?-0.202
> bonusl ? ? ?-0.300 ?0.336
> idni:bonusl ?0.143 -0.707 -0.476
> -----------------------------------
>
> The lmer model seems to test Identical vs. Non-Identical for the High-Bonus
> group only, but not overall (same as estimates for Bonus Size only in the "id"
> row). pvals.fnc() asssigns significance for Identity and the interaction
> Identity*Bonus Size.

You are paying too much attention to the test statistics.  The general
rule is that you check the interaction first and, if the interaction
is significant, then you do not proceed to check the main effects.  As
you have seen, the coefficient for id relates to the behavior at the
reference level of the bonus.  If there is no interaction then this
will also relate to the behavior at the other level of bonus.  When
there is an interaction the behavior with respect to id depends on the
level of bonus.  That's what an interaction means.

> I have the impression that this is missleading: we certainly cannot speak of
> slower reaction times for non-identical stimuli than for identical.

You are trying to make statements about the overall behavior of one
factor in the presence of a non-ignorable interaction with another.
Contrary to popular belief this is not possible.  Look at your
original table or, better yet, create an interaction plot.  These
coefficient estimates are just another way of expressing that table.
At the high level of bonus non-identical are slower than identical.
At the low level of bonus it is the other way around.

> Leaving out the Bonus Size as a fixed factor "lmer(rt~id+(1|subj)+(1|item),
> data = x4)" gives a realistic t-value below 1 for Identity.
>
> So, I ask:
> Is the missleading handling of crossing interactions a bug ?

No.  You have fallen into the trap of associating the result of a test
with a term when, in fact, the test is on the value of the coefficient
and the interpretation of the tests depends on how the coefficients
are defined.

In R there are many different ways of defining such coefficients
related to how the "contrasts" for a factor are assigned.  For a
two-level factorial model like this I often define the contrasts to be
contr.sum so that I get orthogonal columns in the model matrix
(assuming that the original factors are balanced).  For example

> contr.sum(2)
  [,1]
1    1
2   -1
> contr.poly(2)
             .L
[1,] -0.7071068
[2,]  0.7071068
> dat <- data.frame(iden = gl(2,2,labels = c("id","ni")),
+   bonus = gl(2,1,4, labels = c('h','l')))
> dat
  iden bonus
1   id     h
2   id     l
3   ni     h
4   ni     l
> model.matrix(~ iden * bonus, dat)
  (Intercept) idenni bonusl idenni:bonusl
1           1      0      0             0
2           1      0      1             0
3           1      1      0             0
4           1      1      1             1
attr(,"assign")
[1] 0 1 2 3
attr(,"contrasts")
attr(,"contrasts")$iden
[1] "contr.treatment"

attr(,"contrasts")$bonus
[1] "contr.treatment"

> options(contrasts = c("contr.sum", "contr.poly"))
> model.matrix(~ iden * bonus, dat)
  (Intercept) iden1 bonus1 iden1:bonus1
1           1     1      1            1
2           1     1     -1           -1
3           1    -1      1           -1
4           1    -1     -1            1
attr(,"assign")
[1] 0 1 2 3
attr(,"contrasts")
attr(,"contrasts")$iden
[1] "contr.sum"

attr(,"contrasts")$bonus
[1] "contr.sum"

> Or do I simply have to know that if there is a huge crossing interaction I
> should not generalize the Fixed Factor effects ?

Exactly.

> And more relevant: How do I get an analysis that is appropriate to the data ?

The first analysis is appropriate.  For me the main question to
address in interpretation would be why does the effect of
identical/non-identical at low bonus look so different from the effect
at high bonus.



From maj at stats.waikato.ac.nz  Thu Oct 22 23:23:26 2009
From: maj at stats.waikato.ac.nz (Murray Jorgensen)
Date: Fri, 23 Oct 2009 10:23:26 +1300
Subject: [R-sig-ME] Multinomial mixed effect model
In-Reply-To: <000601ca5301$09973e60$1cc5bb20$@com>
References: <000601ca5301$09973e60$1cc5bb20$@com>
Message-ID: <4AE0CD4E.8030203@stats.waikato.ac.nz>

I don't know about others on this list but I would find it easier to 
think about an appropriate model if more detail were given about the 
application.

Murray Jorgensen

Graham Leask wrote:
> Dear List Members
> 
>  
> 
> I am looking to fit a multinomial mixed effect model in R. Can someone
> please point me in the direction
> 
> of the appropriate package or an example in R?
> 
>  
> 
> The response variable consists of 6 categories and the random effects
> include both time and individual 
> 
> where each individual may account for between a few and perhaps 50 separate
> observations.
> 
>  
> 
> Any help would be most appreciated.
> 
>  
> 
> Best wishes
> 
>  
> 
>  
> 
> Graham
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Dr Murray Jorgensen      http://www.stats.waikato.ac.nz/Staff/maj.html
Department of Statistics, University of Waikato, Hamilton, New Zealand
Email: maj at waikato.ac.nz                                Fax 7 838 4155
Phone  +64 7 838 4773 wk    Home +64 7 825 0441   Mobile 021 0200 8350



From trea26 at gmail.com  Fri Oct 23 05:05:17 2009
From: trea26 at gmail.com (Antoine Tremblay)
Date: Thu, 22 Oct 2009 23:05:17 -0400
Subject: [R-sig-ME] plotting 3-way interactions
Message-ID: <581a8bcf0910222005s6c1d353ft21f2a14080dcba83@mail.gmail.com>

Hello all,
It appears that the plotLMER.fnc function from languageR library
cannot plot 3-way interactions
(for an LMER model naturally).?Is there any way to plot them?

Your help is well appreciated,

--
Antoine Tremblay
Department of Neuroscience
Georgetown University
Washington DC



From raldo.kruger at gmail.com  Fri Oct 23 09:18:20 2009
From: raldo.kruger at gmail.com (Raldo Kruger)
Date: Fri, 23 Oct 2009 09:18:20 +0200
Subject: [R-sig-ME] glmm.admb {glmmADMB} vs glmer {lme4}
In-Reply-To: <40e66e0b0910220627u2530c497n8ebbdc03f8c825f9@mail.gmail.com>
References: <30406dd0910210224y661cd326q87c47392d70bce5@mail.gmail.com>
	<40e66e0b0910220627u2530c497n8ebbdc03f8c825f9@mail.gmail.com>
Message-ID: <30406dd0910230018r64a8d4e6g6802243d8ab19959@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20091023/aa32265b/attachment.pl>

From Manuel.A.Morales at williams.edu  Fri Oct 23 18:37:21 2009
From: Manuel.A.Morales at williams.edu (Manuel Morales)
Date: Fri, 23 Oct 2009 12:37:21 -0400
Subject: [R-sig-ME] Prediction, Poisson and Intercepts
Message-ID: <1256315841.8569.52.camel@localhost.localdomain>

Dear list,

I have a question about how to efficiently generate predictions from a
poisson mixed model in lmer. A previous post by Bert Gunter
(http://markmail.org/message/22ncrgbt76bj5bmo) suggested the following:

model.matrix(terms(a.lmer.model),new.data) %*% fixef(a.lmer.model)

However, the back-transformed values from these predictions do not match
the original means because the fixed effect estimate of the intercept
does not include the random effects (see code below).

One alternative is:

new.Intercept <- log(mean(exp(coef(a.lmer.model)[[1]][,1])))
new.fixed <- fixef(a.lmer.model)
new.fixed[1] <- new.Intercept
model.matrix(terms(a.lmer.model),newdata) %*% new.fixed

But this seems awfully clunky ... Any suggestions for a more elegant
solution?

Demonstration code for mean model below:
library(reshape)
library(lme4)

seed=1
data <- melt(sapply(c(.1,.5,1,5),function(x) rpois(50,x)))

mean(data$value)  #Overall mean

m.glm <- glm(value~1,data=data, family=poisson)
exp(coef(m.glm))     #Exponent of intercept = population mean

m.lmer <- lmer(value~(1|X2),data=data, family=poisson, nAGQ=20)
ranef(m.lmer)$X2+fixef(m.lmer)==coef(m.lmer)
mean(exp(unlist(coef(m.lmer))))   #Mean of exp of coefs = overall mean


-- 
http://mutualism.williams.edu



From j.hadfield at ed.ac.uk  Fri Oct 23 19:04:29 2009
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Fri, 23 Oct 2009 18:04:29 +0100
Subject: [R-sig-ME] Prediction, Poisson and Intercepts
In-Reply-To: <1256315841.8569.52.camel@localhost.localdomain>
References: <1256315841.8569.52.camel@localhost.localdomain>
Message-ID: <13F34972-FC93-4ECA-95E5-237203EF1DF8@ed.ac.uk>

Hi Manuel,

The function below is taken from the MCMCglmm course notes that will  
be available soon. It  generates predictions for GLMM, and the random  
effects can be marginalised if you wish (I think this is what you  
want?). For the Poisson distribution this can be done exactly, for  
distributions such as the binomial, approximations have to be used.

mu is the fixed effect prediction, var is the sum of the variance  
components you want to average over.

Cheers,

Jarrod



predict.MCMCglmm<-function(mu, var=NULL, family="gaussian"){
   if(family=="gaussian"){
     return(mu)
   }
   if(family=="poisson"){
     return(exp(mu+0.5*var))
   }
   if(family=="binomial"){
     return(inv.logit(mu-0.5*var*tanh(mu*(1+2*exp(-0.5*var))/6)))
   }
}



On 23 Oct 2009, at 17:37, Manuel Morales wrote:

> Dear list,
>
> I have a question about how to efficiently generate predictions from a
> poisson mixed model in lmer. A previous post by Bert Gunter
> (http://markmail.org/message/22ncrgbt76bj5bmo) suggested the  
> following:
>
> model.matrix(terms(a.lmer.model),new.data) %*% fixef(a.lmer.model)
>
> However, the back-transformed values from these predictions do not  
> match
> the original means because the fixed effect estimate of the intercept
> does not include the random effects (see code below).
>
> One alternative is:
>
> new.Intercept <- log(mean(exp(coef(a.lmer.model)[[1]][,1])))
> new.fixed <- fixef(a.lmer.model)
> new.fixed[1] <- new.Intercept
> model.matrix(terms(a.lmer.model),newdata) %*% new.fixed
>
> But this seems awfully clunky ... Any suggestions for a more elegant
> solution?
>
> Demonstration code for mean model below:
> library(reshape)
> library(lme4)
>
> seed=1
> data <- melt(sapply(c(.1,.5,1,5),function(x) rpois(50,x)))
>
> mean(data$value)  #Overall mean
>
> m.glm <- glm(value~1,data=data, family=poisson)
> exp(coef(m.glm))     #Exponent of intercept = population mean
>
> m.lmer <- lmer(value~(1|X2),data=data, family=poisson, nAGQ=20)
> ranef(m.lmer)$X2+fixef(m.lmer)==coef(m.lmer)
> mean(exp(unlist(coef(m.lmer))))   #Mean of exp of coefs = overall mean
>
>
> -- 
> http://mutualism.williams.edu
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From desja004 at umn.edu  Fri Oct 23 19:12:38 2009
From: desja004 at umn.edu (Christopher David Desjardins)
Date: Fri, 23 Oct 2009 12:12:38 -0500
Subject: [R-sig-ME] Default number of chains in MCMCglmm
Message-ID: <4AE1E406.5000000@umn.edu>

Hi,
I am trying to figure out what the default number of chains are in 
MCMCglmm and how to change this. I've checked out the help page with 
MCMCglmm and don't see any reference to this. I imagine I'm missing 
something obvious.
Thanks,
Chris



From j.hadfield at ed.ac.uk  Fri Oct 23 19:38:33 2009
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Fri, 23 Oct 2009 18:38:33 +0100
Subject: [R-sig-ME] Default number of chains in MCMCglmm
In-Reply-To: <4AE1E406.5000000@umn.edu>
References: <4AE1E406.5000000@umn.edu>
Message-ID: <20091023183833.b8a82oszy8k48gck@www.staffmail.ed.ac.uk>

Hi Chris,

Only a single chain. If you want two, you have to run it twice - not  
very sophisticated, I know. If you want over-dispersed starting values  
to make sure the chain is converging to the same distribution you can  
specify starting values in the start argument of MCMCglmm.   
start=list(QUASI=FALSE) is a quick way of getting sei-overdispersed  
starting values.

If you are referring to the concept of heated chains, then there is  
only one chain - the "cold" one.

Cheers,

Jarrod


Quoting Christopher David Desjardins <desja004 at umn.edu>:

> Hi,
> I am trying to figure out what the default number of chains are in
> MCMCglmm and how to change this. I've checked out the help page with
> MCMCglmm and don't see any reference to this. I imagine I'm missing
> something obvious.
> Thanks,
> Chris
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From lborger at uoguelph.ca  Fri Oct 23 20:17:26 2009
From: lborger at uoguelph.ca (Luca Borger)
Date: Fri, 23 Oct 2009 14:17:26 -0400 (EDT)
Subject: [R-sig-ME] Prediction, Poisson and Intercepts
In-Reply-To: <833879939.11943341256321715065.JavaMail.root@huron.cs.uoguelph.ca>
Message-ID: <570301980.11944901256321846591.JavaMail.root@huron.cs.uoguelph.ca>

Not sure this helps at all, but you get the same result for the mean by this:


> mean(fitted(m.lmer))
[1] 1.674732
> 


HTH


Cheers,

Luca


----- Messaggio originale -----
Da: "Manuel Morales" <Manuel.A.Morales at williams.edu>
A: "r-sig-mixed-models" <r-sig-mixed-models at r-project.org>
Inviato: Venerd?, 23 ottobre 2009 12:37:21 GMT -05:00 U.S.A./Canada, stati orientali
Oggetto: [R-sig-ME] Prediction, Poisson and Intercepts

Dear list,

I have a question about how to efficiently generate predictions from a
poisson mixed model in lmer. A previous post by Bert Gunter
(http://markmail.org/message/22ncrgbt76bj5bmo) suggested the following:

model.matrix(terms(a.lmer.model),new.data) %*% fixef(a.lmer.model)

However, the back-transformed values from these predictions do not match
the original means because the fixed effect estimate of the intercept
does not include the random effects (see code below).

One alternative is:

new.Intercept <- log(mean(exp(coef(a.lmer.model)[[1]][,1])))
new.fixed <- fixef(a.lmer.model)
new.fixed[1] <- new.Intercept
model.matrix(terms(a.lmer.model),newdata) %*% new.fixed

But this seems awfully clunky ... Any suggestions for a more elegant
solution?

Demonstration code for mean model below:
library(reshape)
library(lme4)

seed=1
data <- melt(sapply(c(.1,.5,1,5),function(x) rpois(50,x)))

mean(data$value)  #Overall mean

m.glm <- glm(value~1,data=data, family=poisson)
exp(coef(m.glm))     #Exponent of intercept = population mean

m.lmer <- lmer(value~(1|X2),data=data, family=poisson, nAGQ=20)
ranef(m.lmer)$X2+fixef(m.lmer)==coef(m.lmer)
mean(exp(unlist(coef(m.lmer))))   #Mean of exp of coefs = overall mean


-- 
http://mutualism.williams.edu

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From Manuel.A.Morales at williams.edu  Fri Oct 23 21:21:06 2009
From: Manuel.A.Morales at williams.edu (Manuel Morales)
Date: Fri, 23 Oct 2009 15:21:06 -0400
Subject: [R-sig-ME] Prediction, Poisson and Intercepts
In-Reply-To: <13F34972-FC93-4ECA-95E5-237203EF1DF8@ed.ac.uk>
References: <1256315841.8569.52.camel@localhost.localdomain>
	<13F34972-FC93-4ECA-95E5-237203EF1DF8@ed.ac.uk>
Message-ID: <1256325666.8569.66.camel@localhost.localdomain>

On Fri, 2009-10-23 at 18:04 +0100, Jarrod Hadfield wrote:
> Hi Manuel,
> 
> The function below is taken from the MCMCglmm course notes that will  
> be available soon. It  generates predictions for GLMM, and the random  
> effects can be marginalised if you wish (I think this is what you  
> want?). For the Poisson distribution this can be done exactly, for  
> distributions such as the binomial, approximations have to be used.
> 
> mu is the fixed effect prediction, var is the sum of the variance  
> components you want to average over.

Trying that in the demo code below doesn't seem to work for, but maybe
I'm misunderstanding (or more likely I'm not being clear).

Using the variance of the single random effect:
exp(fixef(m.lmer)+.5* 2.3184) equals 2.093279. 

When I try mean(exp(unlist(coef(m.lmer)))) or mean(data$value), both
equal 1.595.

> Cheers,
> 
> Jarrod
> 
> 
> 
> predict.MCMCglmm<-function(mu, var=NULL, family="gaussian"){
>    if(family=="gaussian"){
>      return(mu)
>    }
>    if(family=="poisson"){
>      return(exp(mu+0.5*var))
>    }
>    if(family=="binomial"){
>      return(inv.logit(mu-0.5*var*tanh(mu*(1+2*exp(-0.5*var))/6)))
>    }
> }
> 
> 
> 
> On 23 Oct 2009, at 17:37, Manuel Morales wrote:
> 
> > Dear list,
> >
> > I have a question about how to efficiently generate predictions from a
> > poisson mixed model in lmer. A previous post by Bert Gunter
> > (http://markmail.org/message/22ncrgbt76bj5bmo) suggested the  
> > following:
> >
> > model.matrix(terms(a.lmer.model),new.data) %*% fixef(a.lmer.model)
> >
> > However, the back-transformed values from these predictions do not  
> > match
> > the original means because the fixed effect estimate of the intercept
> > does not include the random effects (see code below).
> >
> > One alternative is:
> >
> > new.Intercept <- log(mean(exp(coef(a.lmer.model)[[1]][,1])))
> > new.fixed <- fixef(a.lmer.model)
> > new.fixed[1] <- new.Intercept
> > model.matrix(terms(a.lmer.model),newdata) %*% new.fixed
> >
> > But this seems awfully clunky ... Any suggestions for a more elegant
> > solution?
> >
> > Demonstration code for mean model below:
> > library(reshape)
> > library(lme4)
> >
> > seed=1
> > data <- melt(sapply(c(.1,.5,1,5),function(x) rpois(50,x)))
> >
> > mean(data$value)  #Overall mean
> >
> > m.glm <- glm(value~1,data=data, family=poisson)
> > exp(coef(m.glm))     #Exponent of intercept = population mean
> >
> > m.lmer <- lmer(value~(1|X2),data=data, family=poisson, nAGQ=20)
> > ranef(m.lmer)$X2+fixef(m.lmer)==coef(m.lmer)
> > mean(exp(unlist(coef(m.lmer))))   #Mean of exp of coefs = overall mean
> >
> >
> > -- 
> > http://mutualism.williams.edu
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> 
> 
-- 
http://mutualism.williams.edu



From j.hadfield at ed.ac.uk  Sat Oct 24 09:51:20 2009
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Sat, 24 Oct 2009 08:51:20 +0100
Subject: [R-sig-ME] Prediction, Poisson and Intercepts
In-Reply-To: <1256325666.8569.66.camel@localhost.localdomain>
References: <1256315841.8569.52.camel@localhost.localdomain>
	<13F34972-FC93-4ECA-95E5-237203EF1DF8@ed.ac.uk>
	<1256325666.8569.66.camel@localhost.localdomain>
Message-ID: <20091024085120.1ogvlyybk4cwg404@www.staffmail.ed.ac.uk>

Hi Manuel,

Sorry - I misunderstood.  I thought you wanted to predict what the  
mean would be for some fixed effects, under a new random set of random  
effects - rather than the 4-levels of X2 you observed. The function I  
sent does the former.

Cheers,

Jarrod



Quoting Manuel Morales <Manuel.A.Morales at williams.edu>:

> On Fri, 2009-10-23 at 18:04 +0100, Jarrod Hadfield wrote:
>> Hi Manuel,
>>
>> The function below is taken from the MCMCglmm course notes that will
>> be available soon. It  generates predictions for GLMM, and the random
>> effects can be marginalised if you wish (I think this is what you
>> want?). For the Poisson distribution this can be done exactly, for
>> distributions such as the binomial, approximations have to be used.
>>
>> mu is the fixed effect prediction, var is the sum of the variance
>> components you want to average over.
>
> Trying that in the demo code below doesn't seem to work for, but maybe
> I'm misunderstanding (or more likely I'm not being clear).
>
> Using the variance of the single random effect:
> exp(fixef(m.lmer)+.5* 2.3184) equals 2.093279.
>
> When I try mean(exp(unlist(coef(m.lmer)))) or mean(data$value), both
> equal 1.595.
>
>> Cheers,
>>
>> Jarrod
>>
>>
>>
>> predict.MCMCglmm<-function(mu, var=NULL, family="gaussian"){
>>    if(family=="gaussian"){
>>      return(mu)
>>    }
>>    if(family=="poisson"){
>>      return(exp(mu+0.5*var))
>>    }
>>    if(family=="binomial"){
>>      return(inv.logit(mu-0.5*var*tanh(mu*(1+2*exp(-0.5*var))/6)))
>>    }
>> }
>>
>>
>>
>> On 23 Oct 2009, at 17:37, Manuel Morales wrote:
>>
>> > Dear list,
>> >
>> > I have a question about how to efficiently generate predictions from a
>> > poisson mixed model in lmer. A previous post by Bert Gunter
>> > (http://markmail.org/message/22ncrgbt76bj5bmo) suggested the
>> > following:
>> >
>> > model.matrix(terms(a.lmer.model),new.data) %*% fixef(a.lmer.model)
>> >
>> > However, the back-transformed values from these predictions do not
>> > match
>> > the original means because the fixed effect estimate of the intercept
>> > does not include the random effects (see code below).
>> >
>> > One alternative is:
>> >
>> > new.Intercept <- log(mean(exp(coef(a.lmer.model)[[1]][,1])))
>> > new.fixed <- fixef(a.lmer.model)
>> > new.fixed[1] <- new.Intercept
>> > model.matrix(terms(a.lmer.model),newdata) %*% new.fixed
>> >
>> > But this seems awfully clunky ... Any suggestions for a more elegant
>> > solution?
>> >
>> > Demonstration code for mean model below:
>> > library(reshape)
>> > library(lme4)
>> >
>> > seed=1
>> > data <- melt(sapply(c(.1,.5,1,5),function(x) rpois(50,x)))
>> >
>> > mean(data$value)  #Overall mean
>> >
>> > m.glm <- glm(value~1,data=data, family=poisson)
>> > exp(coef(m.glm))     #Exponent of intercept = population mean
>> >
>> > m.lmer <- lmer(value~(1|X2),data=data, family=poisson, nAGQ=20)
>> > ranef(m.lmer)$X2+fixef(m.lmer)==coef(m.lmer)
>> > mean(exp(unlist(coef(m.lmer))))   #Mean of exp of coefs = overall mean
>> >
>> >
>> > --
>> > http://mutualism.williams.edu
>> >
>> > _______________________________________________
>> > R-sig-mixed-models at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >
>>
>>
> --
> http://mutualism.williams.edu
>
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From kagba2006 at yahoo.com  Tue Oct 27 11:19:11 2009
From: kagba2006 at yahoo.com (FMH)
Date: Tue, 27 Oct 2009 03:19:11 -0700 (PDT)
Subject: [R-sig-ME] Error message in the confidence interval for the
	autocorrelation
Message-ID: <393692.97146.qm@web38303.mail.mud.yahoo.com>

Dear All,

I have fitted?two different mixed models, with the AR(1) and AR(2) correlation structure, respectively, and tried to find the confidence interval of the intervals of the aurocorrelation estimation i.e. ?phi1 in the first model and phi1 and phi2 in the second model, via 'intervals' command. The first model worked fine as it gives the required confidence interval for phi1, but there is an error message for the second model, as shown below.

###################################################################################
> (lme2 <- lme(Temp ~ t1 + t2, data, random = ~ t1 + t2 | group, correlation = corARMA(p = 2, form = ~ t1 | group)))
> intervals(lme2)
###################################################################################
?
Error in intervals.lme(lme2) : 
Cannot get confidence intervals on var-cov components: Non-positive definite approximate variance-covariance
Calls: intervals -> intervals.lme
Execution halted
?
###################################################################################
?
Could someone please tell me the meaning of this error and i'd be grateful?for any?advice or suggestion?on the best way to tackle on this problem?
?
Cheers
Fir


    


From adrion at ibe.med.uni-muenchen.de  Tue Oct 27 13:22:56 2009
From: adrion at ibe.med.uni-muenchen.de (Christine Adrion)
Date: Tue, 27 Oct 2009 13:22:56 +0100
Subject: [R-sig-ME] lme(): Error message in the confidence interval
In-Reply-To: <mailman.5.1256641202.24807.r-sig-mixed-models@r-project.org>
References: <mailman.5.1256641202.24807.r-sig-mixed-models@r-project.org>
Message-ID: <4AE6E620.5020204@ibe.med.uni-muenchen.de>

Hello,

you get this error message when your LME-Model is too complex, i.e. the 
result of estimating a complicated model with very little data.
Generally, if the variance covariance matrix of the random effects is 
not positive definite this could be a sign of a model that is 
inappropriate and not a good match for the available data.
Using the nlme-package, you do not get an error message like this when 
using intervals(my.lme.fit), in contrast to summary(my.lme.fit) where 
this problem remains undetected....

Best,
Christine

r-sig-mixed-models-request at r-project.org schrieb:
> Send R-sig-mixed-models mailing list submissions to
> 	r-sig-mixed-models at r-project.org
>
> To subscribe or unsubscribe via the World Wide Web, visit
> 	https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> or, via email, send a message with subject or body 'help' to
> 	r-sig-mixed-models-request at r-project.org
>
> You can reach the person managing the list at
> 	r-sig-mixed-models-owner at r-project.org
>
> When replying, please edit your Subject line so it is more specific
> than "Re: Contents of R-sig-mixed-models digest..."
>
>
> Today's Topics:
>
>    1. Error message in the confidence interval for the
>       autocorrelation (FMH)
>
>
> ----------------------------------------------------------------------
>
> Message: 1
> Date: Tue, 27 Oct 2009 03:19:11 -0700 (PDT)
> From: FMH <kagba2006 at yahoo.com>
> Subject: [R-sig-ME] Error message in the confidence interval for the
> 	autocorrelation
> To: r-sig-mixed-models at r-project.org
> Message-ID: <393692.97146.qm at web38303.mail.mud.yahoo.com>
> Content-Type: text/plain; charset=iso-8859-1
>
> Dear All,
>
> I have fitted?two different mixed models, with the AR(1) and AR(2) correlation structure, respectively, and tried to find the confidence interval of the intervals of the aurocorrelation estimation i.e. ?phi1 in the first model and phi1 and phi2 in the second model, via 'intervals' command. The first model worked fine as it gives the required confidence interval for phi1, but there is an error message for the second model, as shown below.
>
> ###################################################################################
>   
>> (lme2 <- lme(Temp ~ t1 + t2, data, random = ~ t1 + t2 | group, correlation = corARMA(p = 2, form = ~ t1 | group)))
>> intervals(lme2)
>>     
> ###################################################################################
> ?
> Error in intervals.lme(lme2) : 
> Cannot get confidence intervals on var-cov components: Non-positive definite approximate variance-covariance
> Calls: intervals -> intervals.lme
> Execution halted
> ?
> ###################################################################################
> ?
> Could someone please tell me the meaning of this error and i'd be grateful?for any?advice or suggestion?on the best way to tackle on this problem?
> ?
> Cheers
> Fir
>
>
>     
>
>
> ------------------------------
>
> _______________________________________________
> R-sig-mixed-models mailing list
> R-sig-mixed-models at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
> End of R-sig-mixed-models Digest, Vol 34, Issue 19
> **************************************************
>   
-- 
Christine Adrion, Dipl.-Stat., MPH

LMU Ludwig-Maximilians-Universitaet Muenchen
IBE  - Institut fuer Medizinische Informations-
verarbeitung, Biometrie und Epidemiologie
Marchioninistr. 15
D- 81377 Muenchen
 
Tel.:      +49 (0)89 7095 - 7486
Fax:      +49 (0)89 7095 - 7491
eMail:    adrion at ibe.med.uni-muenchen.de
web:     http://www.ibe.med.uni-muenchen.de



From lucianolasala at yahoo.com.ar  Tue Oct 27 23:32:32 2009
From: lucianolasala at yahoo.com.ar (Luciano La Sala)
Date: Tue, 27 Oct 2009 15:32:32 -0700 (PDT)
Subject: [R-sig-ME] Model fit after false convergence
Message-ID: <550043.27661.qm@web59913.mail.ac4.yahoo.com>

Dear R-crew, 

I am using lmer to fit a model for epidemiological data. I start from a saturated model containing all the main effects of interest (all with p < 0.25 in a bivariate screening) plus one random intercept (please see below). From there, I need to refine my model based on AIC criterion. 

As you can see below, I'm getting a convergence error after fitting the saturated model, which I don't know how to deal with. 
 
I read somewhere that this problem can be solved by adding "verbose = TRUE" in the model. After doing this, I get the output below. 

At this point my questions are: 

1. Are thses results worth trusting?

2. What does "verbose=T" do? If not added, the only thing I get is the "convergence error" message. If added, the model keeps running after the "convergence error" line.  

3. What do the strings of numbers after "0: ... ", "1: ..." and "2: ..." below represent? I'd never seen that before. 

4. The error message "Warning message: In mer_finalize(ans) : false convergence (8)" still shows up. Should I worry, or just disregard it and start simplifying my model from there on? 

5. I have only 196 observations, but 104 random effects. Maybe this is the problem?    

Thank you so much in advance!! 

Luciano 

CODE AND OUTPUT: 

> full.model1 <- lmer(Death~HatchOrder + Year + ClutchSize + EggBreadth + EggVolume + ClutchVolume + I(ClutchVolume^2) + Asynchrony + SibingCompetence + (1|NestID),family=binomial,1,verbose = TRUE)

0: 210.20372:  1.18952 -4.38021 -2.14958 -2.47874 -0.643502 0.412270 0.811849 -1.48282 -0.875658 -0.0777208 -0.677601 -0.0518550 -0.604514 0.0650300 -0.000209959  1.31029  1.03084

1: 210.10114:  1.18952 -4.38021 -2.14958 -2.47874 -0.643502 0.412270 0.811849 -1.48282 -0.875658 -0.0777208 -0.677601 -0.0518550 -0.604514 0.0650299 -0.000211591  1.31029  1.03084

2: 210.10114:  1.18952 -4.38021 -2.14958 -2.47874 -0.643502 0.412270 0.811849 -1.48282 -0.875658 -0.0777208 -0.677601 -0.0518550 -0.604514 0.0650299 -0.000211591  1.31029  1.03084

Warning message: In mer_finalize(ans) : false convergence (8)

> full.model1

Generalized linear mixed model fit by the Laplace approximation 
Formula: Death~HatchOrder+Year+ClutchSize+EggBreadth+EggVolume+ ClutchVolume+I(ClutchVolume^2)+Asynchrony+SiblingCompetence+(1|NestID) 

   Data: 1 
   AIC   BIC logLik deviance
 244.1 299.8 -105.1    210.1

Random effects:
 Groups Name        Variance Std.Dev.
 NestID (Intercept) 1.4150   1.1895  
Number of obs: 196, groups: NestID, 104

Fixed effects:
                       Estimate Std. Error z value Pr(>|z|)   
(Intercept)          -4.3802131  5.6178408 -0.7797  0.43557   
HatchOrderSecond     -2.1495845  1.2872835 -1.6699  0.09495 . 
HatchOrderThird      -2.4787439  1.8973058 -1.3065  0.19140   
Year2007             -0.6435022  0.4793135 -1.3425  0.17942   
ClutchSizeTwo-eggs    0.4122699  3.2797887  0.1257  0.89997   
ClutchSizeThree-eggs  0.8118488  4.9473010  0.1641  0.86965   
BreadthCATBLarge     -1.4828236  0.7150390 -2.0738  0.03810 * 
BreadthCATBMedium    -0.8756582  0.8789277 -0.9963  0.31911   
BreadthCATBSmall     -0.0777208  1.0925961 -0.0711  0.94329   
VolumeCATBLarge      -0.6776006  0.7200754 -0.9410  0.34670   
VolumeCATBMedium     -0.0518550  0.9619276 -0.0539  0.95701   
VolumeCATBSmall      -0.6045140  1.1920193 -0.5071  0.61206   
ClutchVolume          0.0650299  0.0828151  0.7852  0.43231   
I(ClutchVolume^2)    -0.0002116  0.0001869 -1.1318  0.25770   
Asynchrony            1.3102881  0.4369016  2.9990  0.00271 **
SibCompPresent        1.0308412  1.0857487  0.9494  0.34240   
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1 




      Yahoo! Cocina

Encontra las mejores recetas con Yahoo! Cocina.


http://ar.mujer.yahoo.com/cocina/



From David.Duffy at qimr.edu.au  Wed Oct 28 02:59:31 2009
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Wed, 28 Oct 2009 11:59:31 +1000 (EST)
Subject: [R-sig-ME] Model fit after false convergence
In-Reply-To: <550043.27661.qm@web59913.mail.ac4.yahoo.com>
References: <550043.27661.qm@web59913.mail.ac4.yahoo.com>
Message-ID: <Pine.LNX.4.64.0910281154270.2438@orpheus.qimr.edu.au>

On Tue, 27 Oct 2009, Luciano La Sala wrote:

> Dear R-crew, 
> 
> I am using lmer to fit a model for epidemiological data. I start from a 
> saturated model containing all the main effects of interest (all with p < 
> 0.25 in a bivariate screening) plus one random intercept (please see 
> below). From there, I need to refine my model based on AIC criterion.
> 
> As you can see below, I'm getting a convergence error after fitting the 
> saturated model, which I don't know how to deal with.

Does the equivalent fixed effects model (ignoring nest) converge?  Maybe
there is separation.

Cheers, David Duffy.



From marieantoine at gmx.ch  Wed Oct 28 15:18:08 2009
From: marieantoine at gmx.ch (Eva Frei)
Date: Wed, 28 Oct 2009 15:18:08 +0100
Subject: [R-sig-ME] mcmcpvalue and error message
Message-ID: <20091028141808.157630@gmx.net>

Dear all,

I am currently analyzing data from a mixed model with lmer.
I`ve tried to follow the suggestions for a correct estimation of p-values as discussed at R-Wiki (http://wiki.r-project.org/rwiki/doku.php?id=guides:lmer-tests&s=lme%20and%20aov).

mcmcpvalue <- function(samp)
{std <- backsolve(chol(var(samp)),
cbind(0, t(samp)) - colMeans(samp),
transpose = TRUE)
sqdist <- colSums(std * std)
sum(sqdist[-1] > sqdist[1])/nrow(samp)
}

Example that works from D. Bates on RWiki:
fm1Adg <- lmer(adg ~ InitWt*Treatment - 1 + (1|Block), AvgDailyGain)
AdgS1 <- mcmcsamp(fm1Adg, 50000)
library(coda)
HPDinterval(AdgS1)
mcmcpvalue(as.matrix(AdgS1)[, 6:8])

In my example, I must use the HPDinterval of the library(lme4) because of S4 classes I think, and that my Output of HPDinterval is splitted into subsets $fixef, $ST and $sigma.
And when I try to extract information exspecially from one subset with
@fixef, that gives me not an mcmcpvalue, but the following error message:

My example:
library(lme4)
fm1Marie<-lmer(a ~ covar + b*c + (1|d) + (1|d:e),na.action=na.omit)
MarieS1<-mcmcsamp(fm1Marie, 50000)
HPDinterval(MarieS1) #gives me an Output with subsets
HPDinterval(MarieS1 at fixef)
str(MarieS1 at fixef)
mcmcpvalue(as.matrix(MarieS1 at fixef)[3:5,])

Error in chol(val(samp)): error in evaluating the argument 'x' in selecting a method for function 'chol'. 


My questions:
Is this because I use a newer version of HPDinterval than D. Bates?

Is this because the matrix is not of positive infinites in my case? 

Can I write an other mcmcpvalue that allows non-positive values in the matrix?

How I can even so became mcmcpvalues for my fixed effects?

Or can I suppress the slots $ST and $sigma? I`m only interessted in the p-values of my covariable covar and the fixed effects b, c, b:c!

Thanks for any advice!


Marieantoine

PhD. student, Switzerland



>>
>> However, I have the problem that my model only consists of parameters
>> with just 1 d.f. (intercepts, slopes), so that the "mcmcpvalue" function
>> defined below obviously produces error messages.
>>
>> How can I proceed in estimating the p-values, then?
>>
>> I very much acknowledge any suggestions.
>>
>> Best regards
>> Christoph.

-- 
GRATIS f?r alle GMX-Mitglieder: Die maxdome Movie-FLAT!



From bates at stat.wisc.edu  Wed Oct 28 19:45:13 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 28 Oct 2009 13:45:13 -0500
Subject: [R-sig-ME] error in LMM fit
In-Reply-To: <109007.29797.qm@web23702.mail.ird.yahoo.com>
References: <109007.29797.qm@web23702.mail.ird.yahoo.com>
Message-ID: <40e66e0b0910281145x445f8e80j329f79a705f4b899@mail.gmail.com>

On Wed, Oct 28, 2009 at 1:11 PM, Bernet Kato <b_s_kato at yahoo.com> wrote:
> Dear Prof. Bates,
>
> I am fitting a linear mixed model using the lmer routine and I am getting
> the error message below:
>
> Error in mer_finalize(ans) : Calculated PWRSS for a LMM is negative
> In addition: Warning message:
> 1: In mer_finalize(ans) : false convergence (8)
>
> ?I am not sure what is causing this error and how to deal with it. Please
> advise me.

It is best to send queries like this to the
R-SIG-Mixed-Models at R-project.org mailing list.  When doing so please
include a reproducible example and the output of

sessionInfo()

so we can tell which version of the lme4 package you are using and in
what environment.

I have taken the liberty of copying the list on this reply.



From sylvestre at lunenfeld.ca  Thu Oct 29 17:06:30 2009
From: sylvestre at lunenfeld.ca (Marie-Pierre Sylvestre)
Date: Thu, 29 Oct 2009 12:06:30 -0400
Subject: [R-sig-ME] niterEM in the control option of lme
Message-ID: <A249C197854D3442BDAE4C6BA4D5553C026A3D78@ex1.ad.mshri.on.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20091029/13b90650/attachment.pl>

From desja004 at umn.edu  Thu Oct 29 17:21:01 2009
From: desja004 at umn.edu (Christopher David Desjardins)
Date: Thu, 29 Oct 2009 11:21:01 -0500
Subject: [R-sig-ME] Does lmer use Empirical Bayes to estimate random effects
Message-ID: <4AE9C0ED.3080102@umn.edu>

I noticed that HLM uses Empirical Bayes to estimate the random effects 
and I was curious if this is what lmer() does to? I came across this 
https://stat.ethz.ch/pipermail/r-sig-mixed-models/2009q1/002107.html
but it is unclear to me if it is correct to say that lmer() uses 
Empirical Bayes to estimate these effects.
Thanks,
Chris

-- 
Christopher David Desjardins, Ph.D. Student
Quantitative Methods in Education
Department of Educational Psychology
University of Minnesota
http://cddesjardins.wordpress.com/



From bates at stat.wisc.edu  Thu Oct 29 19:16:36 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 29 Oct 2009 13:16:36 -0500
Subject: [R-sig-ME] Does lmer use Empirical Bayes to estimate random
	effects
In-Reply-To: <4AE9C0ED.3080102@umn.edu>
References: <4AE9C0ED.3080102@umn.edu>
Message-ID: <40e66e0b0910291116n204b6679w8b6a94174c34748a@mail.gmail.com>

On Thu, Oct 29, 2009 at 11:21 AM, Christopher David Desjardins
<desja004 at umn.edu> wrote:
> I noticed that HLM uses Empirical Bayes to estimate the random effects and I
> was curious if this is what lmer() does to? I came across this
> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2009q1/002107.html
> but it is unclear to me if it is correct to say that lmer() uses Empirical
> Bayes to estimate these effects.

The short answer is "It depends on what you mean by Empirical Bayes
but probably yes".

The longer answer is that the term "Empirical Bayes" by itself is not
sufficiently specific to indicate a way to evaluate an "estimate".  It
is a description of a type of technique, not a statistical model per
se.

It is also symptomatic of a kind of fuzzy thinking that I would prefer
to avoid.  Technically the random effects are unobserved random
variables, not parameters, so it is questionable what one would mean
by estimates of the random effects.  I prefer to describe the values
returned by ranef as the conditional modes of the random effects given
the observed data values and the estimated parameter values.  In the
case of a linear mixed-effects model with underlying Gaussian
distributions the conditional modes are also the conditional means,
which may be easier to explain.



From pchapman at stat.colostate.edu  Thu Oct 29 20:05:22 2009
From: pchapman at stat.colostate.edu (Phillip Chapman)
Date: Thu, 29 Oct 2009 13:05:22 -0600
Subject: [R-sig-ME] Apparent false convergence in lmer with some BIBD data
Message-ID: <4AE9E772.4020500@stat.colostate.edu>


Greetings ME Board members,

Is it possible to manipulate the convergence parameters in lmer?
The control options on the lmer help page are very limited.  I would like
to alter the convergence criteria.  Also, it would be nice to be able to
input my own starting values. Can someone tell me whether this is 
possible and
point me to an appropriate reference.

I am using the "Pillow" BIBD data from page 1066 of Ott and
Longnecker, 5th edition. My lmer program seems to have a false 
convergence with
the random block estimate at zero.  At the risk of committing heresy, I 
have posted
SAS analysis of the same data.  The SAS solution has a lower 
REMLDeviance than the lmer solution.
I also ran the SAS code with the lmer solution to confirm that the 
problem is with the
optimization, not with the data or the REML likelihood.  lmer and SAS 
give the same
REMLDeviance at the lmer solution.  I have plotted the likelihood 
surface (vertical=block
variance, horizontal=error variance) and see that there is a ridge 
running from SW to NE on
plot.  The lmer solution is not on that ridge.  

Any help or suggestions would be appreciated.

Thanks,
Phil Chapman

Here is the data:

blk pillow firmness
1 A 59
1 B 26
1 C 38
2 D 85
2 E 92
2 F 69
3 G 74
3 H 52
3 I 27
4 A 62
4 D 70
4 G 68
5 B 27
5 E 98
5 H 59
6 C 31
6 F 60
6 I 35
7 A 63
7 E 85
7 I 30
8 B 22
8 F 73
8 G 75
9 C 45
9 D 74
9 H 51
10 A 52
10 F 76
10 H 43
11 B 18
11 D 79
11 I 41
12 C 41
12 E 84
12 G 81

Here is my program and some of its output.

data <- read.table(file="c:/temp/Pillow data.txt",header=T)
attach(data)

blk <- factor(blk)

install.packages("lme4")
library(lme4)

h <- lmer(firmness ~ pillow + (1|blk), REML=TRUE, verbose=TRUE)
print(h, digits=10)

Linear mixed model fit by REML
Formula: firmness ~ pillow + (1 | blk)
         AIC         BIC       logLik    deviance     REMLdev
 207.3991367 224.8178450 -92.69956833 220.2067619 185.3991367
Random effects:
 Groups   Name        Variance   Std.Dev.  
 blk      (Intercept) 2.6584e-10 1.6305e-05
 Residual             3.5398e+01 5.9496e+00
Number of obs: 36, groups: blk, 12




Here is a SAS program with the same model:

proc mixed data=pillow;
class blk pillow;
model firmness=pillow;
random blk;

                           The Mixed Procedure

                            Iteration History

       Iteration    Evaluations    -2 Res Log Like       Criterion

               0              1       185.39913672
               1              2       185.35185521      0.00000016
               2              1       185.35184420      0.00000000


                        Convergence criteria met.


                          Covariance Parameter
                                Estimates

                          Cov Parm     Estimate

                          blk            2.0411
                          Residual      33.3815


                             Fit Statistics

                  -2 Res Log Likelihood           185.4
                  AIC (smaller is better)         189.4
                  AICC (smaller is better)        189.9
                  BIC (smaller is better)         190.3


                      Type 3 Tests of Fixed Effects

                            Num     Den
              Effect         DF      DF    F Value    Pr > F

              pillow          8      16      57.59    <.0001





Here is SAS code with the parameters fixed at the lmer variance estimates:


proc mixed data=pillow;
class blk pillow;
model firmness=pillow;
random blk;
parms (2.6584e-10) (3.5398e+01) /noiter;
run;



                           The Mixed Procedure

                             Parameter Search

    CovP1      CovP2   Variance           Res Log Like   -2 Res Log Like

 2.66E-10    35.3980    35.3981               -92.6996          185.3991


                          Covariance Parameter
                                Estimates

                          Cov Parm     Estimate

                          blk          2.66E-10
                          Residual      35.3981


                             Fit Statistics

                  -2 Res Log Likelihood           185.4
                  AIC (smaller is better)         185.4
                  AICC (smaller is better)        185.4
                  BIC (smaller is better)         185.4


                      Type 3 Tests of Fixed Effects

                            Num     Den
              Effect         DF      DF    F Value    Pr > F

              pillow          8      16      56.60    <.0001



From bates at stat.wisc.edu  Thu Oct 29 21:40:29 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 29 Oct 2009 15:40:29 -0500
Subject: [R-sig-ME] Apparent false convergence in lmer with some BIBD
	data
In-Reply-To: <4AE9E772.4020500@stat.colostate.edu>
References: <4AE9E772.4020500@stat.colostate.edu>
Message-ID: <40e66e0b0910291340s64fac493l5efd5cc1de78445@mail.gmail.com>

On Thu, Oct 29, 2009 at 2:05 PM, Phillip Chapman
<pchapman at stat.colostate.edu> wrote:

> Greetings ME Board members,

There's an ME Board?  I didn't know.

> Is it possible to manipulate the convergence parameters in lmer?
> The control options on the lmer help page are very limited. ?I would like
> to alter the convergence criteria. ?Also, it would be nice to be able to
> input my own starting values. Can someone tell me whether this is possible
> and
> point me to an appropriate reference.

The news that readers of this list have come to fear from me are, "I'm
in the midst of reformulating the lmer function" and, well, I am.  In
the formulation being developed in the lme4a package under the R-forge
site, lme4.r-forge.r-project.org there is an option for the lmer
function to return an object that has a function to evaluate the
deviance for various choices of the relative variance parameters.  In
this model there is only one relative variance parameter which is
expressed as the ratio of sigma_b (the standard deviation of the
random effects) to sigma (the residual standard deviation).

What is happening here is that the likelihood surface is unusually
flat so a wide range of values provide a likelihood close to that at
the mle.  Consider the enclosed plot of the profiled deviance as a
function of theta, this relative standard deviation parameter.
Because this is the profiled deviance we would compare the change in
the profiled deviance (the difference between the value shown here and
the minimum) to a chisquared distribution with 11 degrees of freedom
(from 9 fixed-effects parameters and two variance components).  A 95%
joint confidence region would include all the values shown here and
many more.  The difference between the value at theta = 0 and at the
optimal theta is negligible.

You are correct that the nlminb optimizer used in the released value
of lmer produces a false optimum for this problem but, as I said, the
difference in the profiled deviance is negligible.

> I am using the "Pillow" BIBD data from page 1066 of Ott and
> Longnecker, 5th edition. My lmer program seems to have a false convergence
> with
> the random block estimate at zero. ?At the risk of committing heresy, I have
> posted
> SAS analysis of the same data. ?The SAS solution has a lower REMLDeviance
> than the lmer solution.
> I also ran the SAS code with the lmer solution to confirm that the problem
> is with the
> optimization, not with the data or the REML likelihood. ?lmer and SAS give
> the same
> REMLDeviance at the lmer solution. ?I have plotted the likelihood surface
> (vertical=block
> variance, horizontal=error variance) and see that there is a ridge running
> from SW to NE on
> plot. ?The lmer solution is not on that ridge.
> Any help or suggestions would be appreciated.
>
> Thanks,
> Phil Chapman
>
> Here is the data:
>
> blk pillow firmness
> 1 A 59
> 1 B 26
> 1 C 38
> 2 D 85
> 2 E 92
> 2 F 69
> 3 G 74
> 3 H 52
> 3 I 27
> 4 A 62
> 4 D 70
> 4 G 68
> 5 B 27
> 5 E 98
> 5 H 59
> 6 C 31
> 6 F 60
> 6 I 35
> 7 A 63
> 7 E 85
> 7 I 30
> 8 B 22
> 8 F 73
> 8 G 75
> 9 C 45
> 9 D 74
> 9 H 51
> 10 A 52
> 10 F 76
> 10 H 43
> 11 B 18
> 11 D 79
> 11 I 41
> 12 C 41
> 12 E 84
> 12 G 81
>
> Here is my program and some of its output.
>
> data <- read.table(file="c:/temp/Pillow data.txt",header=T)
> attach(data)
>
> blk <- factor(blk)
>
> install.packages("lme4")
> library(lme4)
>
> h <- lmer(firmness ~ pillow + (1|blk), REML=TRUE, verbose=TRUE)
> print(h, digits=10)
>
> Linear mixed model fit by REML
> Formula: firmness ~ pillow + (1 | blk)
> ? ? ? ?AIC ? ? ? ? BIC ? ? ? logLik ? ?deviance ? ? REMLdev
> 207.3991367 224.8178450 -92.69956833 220.2067619 185.3991367
> Random effects:
> Groups ? Name ? ? ? ?Variance ? Std.Dev. ?blk ? ? ?(Intercept) 2.6584e-10
> 1.6305e-05
> Residual ? ? ? ? ? ? 3.5398e+01 5.9496e+00
> Number of obs: 36, groups: blk, 12
>
>
>
>
> Here is a SAS program with the same model:
>
> proc mixed data=pillow;
> class blk pillow;
> model firmness=pillow;
> random blk;
>
> ? ? ? ? ? ? ? ? ? ? ? ? ?The Mixed Procedure
>
> ? ? ? ? ? ? ? ? ? ? ? ? ? Iteration History
>
> ? ? ?Iteration ? ?Evaluations ? ?-2 Res Log Like ? ? ? Criterion
>
> ? ? ? ? ? ? ?0 ? ? ? ? ? ? ?1 ? ? ? 185.39913672
> ? ? ? ? ? ? ?1 ? ? ? ? ? ? ?2 ? ? ? 185.35185521 ? ? ?0.00000016
> ? ? ? ? ? ? ?2 ? ? ? ? ? ? ?1 ? ? ? 185.35184420 ? ? ?0.00000000
>
>
> ? ? ? ? ? ? ? ? ? ? ? Convergence criteria met.
>
>
> ? ? ? ? ? ? ? ? ? ? ? ? Covariance Parameter
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? Estimates
>
> ? ? ? ? ? ? ? ? ? ? ? ? Cov Parm ? ? Estimate
>
> ? ? ? ? ? ? ? ? ? ? ? ? blk ? ? ? ? ? ?2.0411
> ? ? ? ? ? ? ? ? ? ? ? ? Residual ? ? ?33.3815
>
>
> ? ? ? ? ? ? ? ? ? ? ? ? ? ?Fit Statistics
>
> ? ? ? ? ? ? ? ? -2 Res Log Likelihood ? ? ? ? ? 185.4
> ? ? ? ? ? ? ? ? AIC (smaller is better) ? ? ? ? 189.4
> ? ? ? ? ? ? ? ? AICC (smaller is better) ? ? ? ?189.9
> ? ? ? ? ? ? ? ? BIC (smaller is better) ? ? ? ? 190.3
>
>
> ? ? ? ? ? ? ? ? ? ? Type 3 Tests of Fixed Effects
>
> ? ? ? ? ? ? ? ? ? ? ? ? ? Num ? ? Den
> ? ? ? ? ? ? Effect ? ? ? ? DF ? ? ?DF ? ?F Value ? ?Pr > F
>
> ? ? ? ? ? ? pillow ? ? ? ? ?8 ? ? ?16 ? ? ?57.59 ? ?<.0001
>
>
>
>
>
> Here is SAS code with the parameters fixed at the lmer variance estimates:
>
>
> proc mixed data=pillow;
> class blk pillow;
> model firmness=pillow;
> random blk;
> parms (2.6584e-10) (3.5398e+01) /noiter;
> run;
>
>
>
> ? ? ? ? ? ? ? ? ? ? ? ? ?The Mixed Procedure
>
> ? ? ? ? ? ? ? ? ? ? ? ? ? ?Parameter Search
>
> ? CovP1 ? ? ?CovP2 ? Variance ? ? ? ? ? Res Log Like ? -2 Res Log Like
>
> 2.66E-10 ? ?35.3980 ? ?35.3981 ? ? ? ? ? ? ? -92.6996 ? ? ? ? ?185.3991
>
>
> ? ? ? ? ? ? ? ? ? ? ? ? Covariance Parameter
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? Estimates
>
> ? ? ? ? ? ? ? ? ? ? ? ? Cov Parm ? ? Estimate
>
> ? ? ? ? ? ? ? ? ? ? ? ? blk ? ? ? ? ?2.66E-10
> ? ? ? ? ? ? ? ? ? ? ? ? Residual ? ? ?35.3981
>
>
> ? ? ? ? ? ? ? ? ? ? ? ? ? ?Fit Statistics
>
> ? ? ? ? ? ? ? ? -2 Res Log Likelihood ? ? ? ? ? 185.4
> ? ? ? ? ? ? ? ? AIC (smaller is better) ? ? ? ? 185.4
> ? ? ? ? ? ? ? ? AICC (smaller is better) ? ? ? ?185.4
> ? ? ? ? ? ? ? ? BIC (smaller is better) ? ? ? ? 185.4
>
>
> ? ? ? ? ? ? ? ? ? ? Type 3 Tests of Fixed Effects
>
> ? ? ? ? ? ? ? ? ? ? ? ? ? Num ? ? Den
> ? ? ? ? ? ? Effect ? ? ? ? DF ? ? ?DF ? ?F Value ? ?Pr > F
>
> ? ? ? ? ? ? pillow ? ? ? ? ?8 ? ? ?16 ? ? ?56.60 ? ?<.0001
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
-------------- next part --------------

R version 2.11.0 Under development (unstable) (2009-10-28 r50245)
Copyright (C) 2009 The R Foundation for Statistical Computing
ISBN 3-900051-07-0

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> sessionInfo()
R version 2.11.0 Under development (unstable) (2009-10-28 r50245) 
x86_64-unknown-linux-gnu 

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    
 [5] LC_MONETARY=C              LC_MESSAGES=en_US.UTF-8   
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 
 [9] LC_ADDRESS=C               LC_TELEPHONE=C            
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     
> library(lme4a)
Loading required package: stats4
Loading required package: Matrix
Loading required package: lattice
Loading required package: splines
> pillow <- within(read.table("./pillow.txt", header = TRUE),
+                  blk <- factor(blk))
> h <- lmer(firmness ~ pillow + (1|blk), pillow, doFit = FALSE)
> (opt <- optimize(h at setPars, c(0,1)))
$minimum
[1] 0.2472657

$objective
[1] 185.3518

> h at setPars(0)
[1] 185.3991
> h at setPars(0.5)
[1] 185.6404
> thvals <- seq(0, 1, 0.01)
> xyplot(sapply(thvals, h at setPars) ~ thvals, type = "l",
+        xlab = expression(theta), ylab = "Profiled deviance")
> 
> proc.time()
   user  system elapsed 
 12.660   0.150  13.283 
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Rplots.pdf
Type: application/pdf
Size: 5147 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20091029/d50277c9/attachment.pdf>

From bolker at ufl.edu  Thu Oct 29 21:52:43 2009
From: bolker at ufl.edu (Ben Bolker)
Date: Thu, 29 Oct 2009 16:52:43 -0400
Subject: [R-sig-ME] Apparent false convergence in lmer with some BIBD
 data
In-Reply-To: <40e66e0b0910291340s64fac493l5efd5cc1de78445@mail.gmail.com>
References: <4AE9E772.4020500@stat.colostate.edu>
	<40e66e0b0910291340s64fac493l5efd5cc1de78445@mail.gmail.com>
Message-ID: <4AEA009B.8060003@ufl.edu>

Douglas Bates wrote:

  [snip]

> What is happening here is that the likelihood surface is unusually
> flat so a wide range of values provide a likelihood close to that at
> the mle.  Consider the enclosed plot of the profiled deviance as a
> function of theta, this relative standard deviation parameter.
> Because this is the profiled deviance we would compare the change in
> the profiled deviance (the difference between the value shown here and
> the minimum) to a chisquared distribution with 11 degrees of freedom
> (from 9 fixed-effects parameters and two variance components).  A 95%
> joint confidence region would include all the values shown here and
> many more.  The difference between the value at theta = 0 and at the
> optimal theta is negligible.

   Silly question, but I would have thought that the relevant number of
df would be 1, counting only the parameter we are NOT allowing to vary
(i.e. we're profiling on theta), rather than the 11 that we ARE allowing
to vary?

  This wouldn't change the argument that theta=0 is nearly
indistinguishable from theta-hat approx 0.3, but the 95% confidence
region would only go out to about theta=0.8?

  Or am I just thinking about this wrong?

 Ben Bolker



From bates at stat.wisc.edu  Fri Oct 30 03:29:31 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 29 Oct 2009 21:29:31 -0500
Subject: [R-sig-ME] Apparent false convergence in lmer with some BIBD
	data
In-Reply-To: <4AEA009B.8060003@ufl.edu>
References: <4AE9E772.4020500@stat.colostate.edu>
	<40e66e0b0910291340s64fac493l5efd5cc1de78445@mail.gmail.com>
	<4AEA009B.8060003@ufl.edu>
Message-ID: <40e66e0b0910291929g149c3788sf2b2fa126acc327f@mail.gmail.com>

On Thu, Oct 29, 2009 at 3:52 PM, Ben Bolker <bolker at ufl.edu> wrote:
> Douglas Bates wrote:

> ?[snip]

>> What is happening here is that the likelihood surface is unusually
>> flat so a wide range of values provide a likelihood close to that at
>> the mle. ?Consider the enclosed plot of the profiled deviance as a
>> function of theta, this relative standard deviation parameter.
>> Because this is the profiled deviance we would compare the change in
>> the profiled deviance (the difference between the value shown here and
>> the minimum) to a chisquared distribution with 11 degrees of freedom
>> (from 9 fixed-effects parameters and two variance components). ?A 95%
>> joint confidence region would include all the values shown here and
>> many more. ?The difference between the value at theta = 0 and at the
>> optimal theta is negligible.

> ? Silly question, but I would have thought that the relevant number of
> df would be 1, counting only the parameter we are NOT allowing to vary
> (i.e. we're profiling on theta), rather than the 11 that we ARE allowing
> to vary?

> ?This wouldn't change the argument that theta=0 is nearly
> indistinguishable from theta-hat approx 0.3, but the 95% confidence
> region would only go out to about theta=0.8?

It depends on whether you want a confidence interval for this
parameter, which is an unusual parameter chosen for computational
convenience and not something that generally would be of interest, or
the projection of a joint confidence region, which is what I had in
mind.  I will admit that my statement was poorly phrased and easily
misinterpreted.
> ?Or am I just thinking about this wrong?
>
> ?Ben Bolker
>
>



From drbn at yahoo.com  Fri Oct 30 20:21:23 2009
From: drbn at yahoo.com (David R.)
Date: Fri, 30 Oct 2009 12:21:23 -0700 (PDT)
Subject: [R-sig-ME] Modelling intraspecific differences with random slopes
Message-ID: <608996.78381.qm@web113213.mail.gq1.yahoo.com>

Hi, 
I'm using mixed models (lme4 package) to analyze variability in 13 SPECIES of birds observed during 15 YEARS across 5 sites. All the species were observed in all the sites in most YEARS. 
My initial model was: 
response ~ a + b + c + d + e + (1 | YEAR) + (1 | SITE) + (1 | SPECIES) 
that after some LRT was simplified to: 
response ~ a + b + c + d + e + (1 | SPECIES) 
I was not interested in these species in their own right and treated them as being representative members of a population of similar species. But now I was asked about the possible intraspecific differences in the effect of a, b, c, d and e on the response. 
My question is: Is it appropriate a model of random intercept and slopes as initial full model to estimate these differences? 
For example: 
response ~ a + b + c + d + e + (1 | YEAR) + (1 | SITE) + (1 | SPECIES) + (1 + a | SPECIES) + (1 + b | SPECIES) + (1 + c | SPECIES) + (1 + d | SPECIES) + (1 + e | SPECIES) 
Or perhaps?is it more appropriate to work with species as fixed effects like: 
response ~ (a + b + c + d + e) * SPECIES + (1 | YEAR) + (1 | SITE) 

Thanks in advance?
David






From drbn at yahoo.com  Fri Oct 30 22:02:08 2009
From: drbn at yahoo.com (David R.)
Date: Fri, 30 Oct 2009 14:02:08 -0700 (PDT)
Subject: [R-sig-ME] Sorry,
	I meant: Modelling INTERspecific differences with random slopes
Message-ID: <775668.65766.qm@web113214.mail.gq1.yahoo.com>

Sorry for my poor English in the previous message, I meant INTERspecific differences, not INTRAspecific. This is the corrected question:

Hi, 
I'm using mixed models (lme4 package) to analyze variability in 13 SPECIES of birds observed during 15 YEARS across 5 sites. All the species were observed in all the sites in most YEARS. 
My initial model was: 
response ~ a + b + c + d + e + (1 | YEAR) + (1 | SITE) + (1 | SPECIES) 
that after some LRT was simplified to: 
response ~ a + b + c + d + e + (1 | SPECIES) 
I was not interested in these species in their own right and treated them as being representative members of a population of similar species. But now I was asked about the possible interspecific differences in the effect of a, b, c, d and e on the response. 
My question is: Is it appropriate a model of random intercept and slopes as initial full model to estimate these differences? 
For example: 
response ~ a + b + c + d + e + (1 | YEAR) + (1 | SITE) + (1 | SPECIES) + (1 + a | SPECIES) + (1 + b | SPECIES) + (1 + c | SPECIES) + (1 + d | SPECIES) + (1 + e | SPECIES) 
Or perhaps?is it more appropriate to work with species as fixed effects like: 
response ~ (a + b + c + d + e) * SPECIES + (1 | YEAR) + (1 | SITE) 

Thanks in advance?
David






From otter at otter-rsch.com  Sun Nov  1 00:13:08 2009
From: otter at otter-rsch.com (dave fournier)
Date: Sat, 31 Oct 2009 15:13:08 -0800
Subject: [R-sig-ME] glmm.admb {glmmADMB} vs glmer {lme4}
In-Reply-To: <30406dd0910230018r64a8d4e6g6802243d8ab19959@mail.gmail.com>
References: <30406dd0910230018r64a8d4e6g6802243d8ab19959@mail.gmail.com>
Message-ID: <4AECC484.7000600@otter-rsch.com>

> > My questions are:
> >
> > 1) How can I extract the AIC values from m1?
> >
> > 2) Are the AIC values comparable between the two models (i.e. can I
> compare
> > them for model selection)?
> >
> > 3) For m2, the true estimates for the fixed effects can be calculated by
> > exp(returned estimate). Is this true for m1 too, or does the negative
> > binomial distribution require a different conversion?
> >

The simplest way is to use the save.dir option as in
 if(nchar(pkg)) library(pkg, character.only=TRUE)})
 ex1m <-read.table("C:\\....\\ex1m.txt", header=TRUE, sep="\t")
 m1a<-glmm.admb(Counts~T+T:Year2+T:Year3+B+B:Year2+B:Year3+P+P:Year2+P:Year3+Year2+Year3,
random=~Site, group="Year", data=ex1m,
family="nbinom",zeroInflation=TRUE,save.dir="c:/dir1")
 m1b<-glmm.admb(Counts~T:Year2+T:Year3+B+B:Year2+B:Year3+P+P:Year2+P:Year3+Year2+Year3,
random=~Site, group="Year", data=ex1m,
family="nbinom",zeroInflation=TRUE,dir="c:/dir2")

The parameters together with estimated standard deviations will be found
in c:/dir1 and c:/dir2 in the file nbmm.std. the -log-likelihood is in
the file nbmm.par. that can be used for a likelihood ratio test on the
significance of adding the parameter T to the model.

The file nbmm.rep contains the predicted mean for each observation in
the second column of the list.  I believe this is what you mean by
"exp(returned estimate)".


The standard glmmADMB parameterizes the variance as mu*(1+mu/alpha)
However for you data it turns out that parameterizing the variance as
mu*tau produces a much better fit to the data.  The  log-likelihoods are
about -1530 and -1465 so you should use this formulation.

Interestingly it turns out that adding T  signficantly improves the fit
for the former parametrization of the variance but not for the latter
parametrization.

I think this illustrates the importance of estimating the overdispersion
within the model rather than by ad hoc quasi-likelihood hacks. It also
illustrates the utility of employing tools like AD Model Builder
which make it easy to  modify the form of your model rather than being
trapped in the glmm paradigm.




-- 
David A. Fournier
P.O. Box 2040,
Sidney, B.C. V8l 3S3
Canada
Phone/FAX 250-655-3364
http://otter-rsch.com



From colabarria at uvigo.es  Mon Nov  2 17:20:32 2009
From: colabarria at uvigo.es (Celia Olabarria)
Date: Mon, 02 Nov 2009 17:20:32 +0100
Subject: [R-sig-ME] scaler parameters
Message-ID: <E1N4zdx-0005ca-6U@cacahuete.uvigo.es>

Dear all,
I am dealing with a model in lmer and I would like to know how to 
retrieve the scale parameter values. It does not give it by default

thank you very much in advance



From bates at stat.wisc.edu  Mon Nov  2 18:26:53 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 2 Nov 2009 11:26:53 -0600
Subject: [R-sig-ME] scaler parameters
In-Reply-To: <E1N4zdx-0005ca-6U@cacahuete.uvigo.es>
References: <E1N4zdx-0005ca-6U@cacahuete.uvigo.es>
Message-ID: <40e66e0b0911020926s29b382acuf6349698dfcae260@mail.gmail.com>

I think we will need a bit more information to be able to help you.
Could you perhaps include the output from a model that you have fit
and describe in more detail what parameters estimates you wish to get?

On Mon, Nov 2, 2009 at 10:20 AM, Celia Olabarria <colabarria at uvigo.es> wrote:
> Dear all,
> I am dealing with a model in lmer and I would like to know how to retrieve
> the scale parameter values. It does not give it by default
>
> thank you very much in advance
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From Nicolas.RODE at cefe.cnrs.fr  Mon Nov  2 19:20:12 2009
From: Nicolas.RODE at cefe.cnrs.fr (Nicolas RODE)
Date: Mon, 2 Nov 2009 19:20:12 +0100
Subject: [R-sig-ME] Interaction estimates with glm.nb
Message-ID: <F83F6C9516C4C94D883690BD8B9CCC9F35908A@ZZML.newcefe.newage.fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20091102/aa2f6b85/attachment.pl>

From bates at stat.wisc.edu  Mon Nov  2 21:12:23 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 2 Nov 2009 14:12:23 -0600
Subject: [R-sig-ME] Modelling intraspecific differences with random
	slopes
In-Reply-To: <608996.78381.qm@web113213.mail.gq1.yahoo.com>
References: <608996.78381.qm@web113213.mail.gq1.yahoo.com>
Message-ID: <40e66e0b0911021212n21e3f42cube508a5c593468ad@mail.gmail.com>

On Fri, Oct 30, 2009 at 1:21 PM, David R. <drbn at yahoo.com> wrote:
> Hi,
> I'm using mixed models (lme4 package) to analyze variability in 13 SPECIES of birds observed during 15 YEARS across 5 sites. All the species were observed in all the sites in most YEARS.
> My initial model was:
> response ~ a + b + c + d + e + (1 | YEAR) + (1 | SITE) + (1 | SPECIES)
> that after some LRT was simplified to:
> response ~ a + b + c + d + e + (1 | SPECIES)
> I was not interested in these species in their own right and treated them as being representative members of a population of similar species. But now I was asked about the possible intraspecific differences in the effect of a, b, c, d and e on the response.
> My question is: Is it appropriate a model of random intercept and slopes as initial full model to estimate these differences?
> For example:
> response ~ a + b + c + d + e + (1 | YEAR) + (1 | SITE) + (1 | SPECIES) + (1 + a | SPECIES) + (1 + b | SPECIES) + (1 + c | SPECIES) + (1 + d | SPECIES) + (1 + e | SPECIES)

You don't want to do that.  If you want to try to estimate all the
variances and covariances in the interactions you could put in just
one term of the form (1 + a + b + c + d + c|SPECIES) but you would
need a large amount of data to estimate all the resulting covariance
terms.  If you are willing to assume independent random effects you
could reduce this to

(1|SPECIES) + (0+a|SPECIES) + (0 + b|SPECIES) ...

That is, the model that you specified but replacing 1 + a, etc. with 0 + a, etc.

> Or perhaps?is it more appropriate to work with species as fixed effects like:
> response ~ (a + b + c + d + e) * SPECIES + (1 | YEAR) + (1 | SITE)

That seems more appropriate in this case.  Estimating a large number
of interactions between fixed-effects terms and random-effects
grouping variables is not a good idea.



From jaakko.heinonen at metla.fi  Wed Nov  4 11:03:49 2009
From: jaakko.heinonen at metla.fi (Jaakko Heinonen)
Date: Wed, 04 Nov 2009 12:03:49 +0200
Subject: [R-sig-ME] Localization of nonlinear mixed models
Message-ID: <4AF15185.8050503@metla.fi>

Dear list,

My question is about the localization (or calibration) of nonlinear 
mixed models.

I have the estimates of the parameters of some hierarchical nonlinear 
mixed models that we?d like to use to predict new responses. I also have 
measurements that can be used to calibrate the models and my question is 
how to compute the conditional expected values of the random parameter 
given the new measurements.

One way could be to find the maximum of p1(u)*p2(y|u) using nlm 
procedure, where p1(u) is the density of random parameters u and p2(y|u) 
is the conditional density of the response y. But can this be done using 
nlme? In nlme the models can be formulated in a familiar and handy way, 
which would be a great advantage. I understand that if I give nlme the 
estimates of the fixed mean and variance parameters as initial values 
and prevent nlme from updating the initial values, nlme computes the 
conditional expectations (and their variances) I need. If this is true, 
how can I give the initial values and prevent updating? Or is there a 
better way to do the job?

Best regards
Jaakko Heinonen



From david.airey at Vanderbilt.Edu  Thu Nov  5 15:29:14 2009
From: david.airey at Vanderbilt.Edu (David Airey)
Date: Thu, 5 Nov 2009 08:29:14 -0600
Subject: [R-sig-ME] I can still use nlme instead of nlmer/lme4 right?
Message-ID: <32FE23E2-2E01-4ACC-B0A1-EEAE33889D8C@vanderbilt.edu>

I have a project to conduct simulations for which I must consider a  
nonlinear mixed model (dose-response, 4 parameter logistic model).  
Because I have the Pinheiro and Bates book, which does such a great  
job explaining things, whereas lme4 documentation is too thin for me,  
I'd like to stick with the NLME package for now. Is that in some way  
unadvisable?

Thanks,

-Dave



From HDoran at air.org  Thu Nov  5 15:38:11 2009
From: HDoran at air.org (Doran, Harold)
Date: Thu, 5 Nov 2009 09:38:11 -0500
Subject: [R-sig-ME] I can still use nlme instead of nlmer/lme4 right?
In-Reply-To: <32FE23E2-2E01-4ACC-B0A1-EEAE33889D8C@vanderbilt.edu>
Message-ID: <C0772C7568B5374481D2F8A880E9BBDF5B4E03B6@DC1EX07CMS.air.org>

Yes and no. There are no particular problems with nlme that would impede you from completing scientific work properly. With that said, lmer is substantially improved from its primative cousins in many ways; primarily it is more capable of estimating models with large data.

You are correct that documentation is thinner than what is available for nlme. But, there is plently of help on this list. I'm quite sure with good questions, you'll find all the support on this list you could possibly need.

> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org 
> [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf 
> Of David Airey
> Sent: Thursday, November 05, 2009 9:29 AM
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] I can still use nlme instead of nlmer/lme4 right?
> 
> I have a project to conduct simulations for which I must 
> consider a nonlinear mixed model (dose-response, 4 parameter 
> logistic model).  
> Because I have the Pinheiro and Bates book, which does such a 
> great job explaining things, whereas lme4 documentation is 
> too thin for me, I'd like to stick with the NLME package for 
> now. Is that in some way unadvisable?
> 
> Thanks,
> 
> -Dave
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 


From bolker at ufl.edu  Thu Nov  5 17:06:29 2009
From: bolker at ufl.edu (Ben Bolker)
Date: Thu, 05 Nov 2009 11:06:29 -0500
Subject: [R-sig-ME] I can still use nlme instead of nlmer/lme4 right?
In-Reply-To: <C0772C7568B5374481D2F8A880E9BBDF5B4E03B6@DC1EX07CMS.air.org>
References: <C0772C7568B5374481D2F8A880E9BBDF5B4E03B6@DC1EX07CMS.air.org>
Message-ID: <4AF2F805.3000902@ufl.edu>


  Respectfully, I would say that's a big "but" in the second paragraph.
 lme4 has enormous potential, and is already much better than nlme for
some things (crossed designs, large data sets, GLMMs), but its edges are
still rough.  Accessor methods are less available/fully
developed/documented, and in particular it's my impression that
nonlinear models have been less thoroughly exercised in lme4 ... Using
lme4 would be a form of contributing back to the community
(beta-testing), but if you're in a hurry my HO would be that sticking
with nlme sounds like a good idea.  (Others should as always feel free
to disagree.)

Doran, Harold wrote:
> Yes and no. There are no particular problems with nlme that would
> impede you from completing scientific work properly. With that said,
> lmer is substantially improved from its primative cousins in many
> ways; primarily it is more capable of estimating models with large
> data.
> 
> You are correct that documentation is thinner than what is available
> for nlme. But, there is plently of help on this list. I'm quite sure
> with good questions, you'll find all the support on this list you
> could possibly need.
> 
>> -----Original Message----- From:
>> r-sig-mixed-models-bounces at r-project.org 
>> [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of
>> David Airey Sent: Thursday, November 05, 2009 9:29 AM To:
>> r-sig-mixed-models at r-project.org Subject: [R-sig-ME] I can still
>> use nlme instead of nlmer/lme4 right?
>> 
>> I have a project to conduct simulations for which I must consider a
>> nonlinear mixed model (dose-response, 4 parameter logistic model).
>>  Because I have the Pinheiro and Bates book, which does such a 
>> great job explaining things, whereas lme4 documentation is too thin
>> for me, I'd like to stick with the NLME package for now. Is that in
>> some way unadvisable?
>> 
>> Thanks,
>> 
>> -Dave
>> 
>> _______________________________________________ 
>> R-sig-mixed-models at r-project.org mailing list 
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 
> _______________________________________________ 
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / www.zoology.ufl.edu/bolker
GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc



From A.Oxbrough at ucc.ie  Fri Nov  6 13:04:17 2009
From: A.Oxbrough at ucc.ie (Oxbrough, Anne)
Date: Fri, 6 Nov 2009 12:04:17 -0000
Subject: [R-sig-ME] Measuring overdispersion in GLMM (poisson)
Message-ID: <7FB19F2B1B0F7C46BB4B1A663CEFFAC06E82C0@EXCH1.central.ad.ucc.ie>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20091106/d25430cf/attachment.pl>

From david.airey at Vanderbilt.Edu  Fri Nov  6 15:27:25 2009
From: david.airey at Vanderbilt.Edu (David Airey)
Date: Fri, 6 Nov 2009 08:27:25 -0600
Subject: [R-sig-ME] R-sig-mixed-models Digest, Vol 35, Issue 4
In-Reply-To: <mailman.7.1257505202.10406.r-sig-mixed-models@r-project.org>
References: <mailman.7.1257505202.10406.r-sig-mixed-models@r-project.org>
Message-ID: <633498BD-CB49-465F-8C22-381C3542F4DB@vanderbilt.edu>

Thanks for the responses.

We'll start simulations with nlme(). Once we get things working, I'll  
ask about using nlmer().

[Motivating science (skip if not interested in drug genetics!): There  
is likely a need for nlmer(), because the projected data set is 100  
curves, each curve estimated by 12 dose levels, and the context is a  
genome scan. If feasibility doesn't kill this simulation project, then  
it might be a good testing bed for nlmer(). The curves can be grouped  
(nested) in one of two possible alleles at each genetic marker along  
each chromosome. There are only two possible alleles at each marker,  
because the subjects are from a set of recombinant inbred lines  
derived from two parental standard inbred mouse strains. The twist  
here is that each curve is estimated by 24 independent mice per line,  
2 mice per dose level, rather than exposing mice to multiple doses to  
achieve a true repeated measures design. The key is that a curve per  
RI line can still be estimated with independent mice, because mice  
within RI line are isogenic (genetic clones). The environment of each  
mouse will of course be assumed equivalent, otherwise this design is  
problematic. If you have 24 mice per RI line, how do you spend them in  
the context of drug quantitative genetics? The dose response curve is  
extremely important to know. Do you put 8 independent mice in each of  
three dose levels and use a linear model? Or can you distribute the  
mice 2 mice per dose level, and use a nonlinear model such as the four  
parameter logistic function? What is typically done in drug response  
quantitative genetics with mice is to use a _single_ dose level that  
was optimized for differences among mice in a small pilot study.  
That's feasible but arguably inadequate.]

-Dave

I asked:

> "I have a project to conduct simulations for which I must consider a
> nonlinear mixed model (dose-response, 4 parameter logistic model).
> Because I have the Pinheiro and Bates book, which does such a great
> job explaining things, whereas lme4 documentation is too thin for me,
> I'd like to stick with the NLME package for now. Is that in some way
> unadvisable?"


Ben Bolker wrote:

>  Respectfully, I would say that's a big "but" in the second paragraph.
> lme4 has enormous potential, and is already much better than nlme for
> some things (crossed designs, large data sets, GLMMs), but its edges  
> are
> still rough.  Accessor methods are less available/fully
> developed/documented, and in particular it's my impression that
> nonlinear models have been less thoroughly exercised in lme4 ... Using
> lme4 would be a form of contributing back to the community
> (beta-testing), but if you're in a hurry my HO would be that sticking
> with nlme sounds like a good idea.  (Others should as always feel free
> to disagree.)

Harold Doran wrote:

> Yes and no. There are no particular problems with nlme that would  
> impede you from completing scientific work properly. With that said,  
> lmer is substantially improved from its primative cousins in many  
> ways; primarily it is more capable of estimating models with large  
> data.
>
> You are correct that documentation is thinner than what is available  
> for nlme. But, there is plently of help on this list. I'm quite sure  
> with good questions, you'll find all the support on this list you  
> could possibly need.


--
David C. Airey, Ph.D.
Pharmacology Research Assistant Professor
Center for Human Genetics Research Member
Vanderbilt University School of Medicine



From Marcus.Rowcliffe at ioz.ac.uk  Fri Nov  6 18:03:03 2009
From: Marcus.Rowcliffe at ioz.ac.uk (Marcus Rowcliffe)
Date: Fri, 6 Nov 2009 17:03:03 -0000
Subject: [R-sig-ME] Scale parameters and assessing overdispersion
Message-ID: <B1436FB2EE57AB40A56AA806EEB273010237AB12@ZSL26.zsl.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20091106/56524a47/attachment.pl>

From thomasmang.ng at googlemail.com  Sun Nov  8 01:01:36 2009
From: thomasmang.ng at googlemail.com (Thomas Mang)
Date: Sun, 08 Nov 2009 00:01:36 +0000
Subject: [R-sig-ME] heteroscedasticity
Message-ID: <4AF60A60.5030701@gmail.com>

Hi,

Suppose may data consist of groups (which also define the levels for 
random effects), which show group-wise heteroscedasticity, that is for 
some groups the variance of residuals is larger than for the others.  
Based on specific knowledge of the data and the problem this even makes 
perfect sense and is actually a good sign. Technically however it's not 
good of course, to put it mildly.
Is there a way in lme4 to handle heteroscedasticity (with known grouping 
for the different variances) ?
Any suggestions ?

thanks
Thomas



From cotter.rs at gmail.com  Mon Nov  9 08:01:09 2009
From: cotter.rs at gmail.com (R.S. Cotter)
Date: Sun, 8 Nov 2009 23:01:09 -0800
Subject: [R-sig-ME] Linear Mixed-Effects Models (lme),
	question about parameter estimates 	and random effect
Message-ID: <742479270911082301m52c22450pc7ce082c32ced5a0@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20091108/c5d411c4/attachment.pl>

From emm.charpentier at free.fr  Sun Nov  8 17:27:25 2009
From: emm.charpentier at free.fr (Emmanuel Charpentier)
Date: Sun, 08 Nov 2009 17:27:25 +0100
Subject: [R-sig-ME] heteroscedasticity
In-Reply-To: <4AF60A60.5030701@gmail.com>
References: <4AF60A60.5030701@gmail.com>
Message-ID: <1257697645.15964.45.camel@PortableToshiba>

Le dimanche 08 novembre 2009 ? 00:01 +0000, Thomas Mang a ?crit :
> Hi,
> 
> Suppose may data consist of groups (which also define the levels for 
> random effects), which show group-wise heteroscedasticity, that is for 
> some groups the variance of residuals is larger than for the others.  
> Based on specific knowledge of the data and the problem this even makes 
> perfect sense and is actually a good sign. Technically however it's not 
> good of course, to put it mildly.
> Is there a way in lme4 to handle heteroscedasticity (with known grouping 
> for the different variances) ?
> Any suggestions ?

Well, you might try to equalize dependent variable variances by the
"classical" transformations (log, sqrt) and their generalizations
(Box-Cox nd siblings, see "boxcox" and "logtrans" in MASS). Lrger sets
of transformations of both dependents nd independent variables are
proposed in ace and avas, and Harrell's Design (now rms) package has lso
some functions aimed at this kind of problems.

Be aware, however, that most of these functions im t finding optimal
transformations in  fixed-effect context, and that using them with
random-effects models is not necessarily a good solution.

HTH,

					Emmanuel Charpentier



From DAfshartous at med.miami.edu  Mon Nov  9 14:50:39 2009
From: DAfshartous at med.miami.edu (Afshartous, David)
Date: Mon, 9 Nov 2009 08:50:39 -0500
Subject: [R-sig-ME] heteroscedasticity
In-Reply-To: <1257697645.15964.45.camel@PortableToshiba>
Message-ID: <C71D885F.C387%dafshartous@med.miami.edu>


For lme4, search the archives for "random effect variance per treatment group in lmer", I wrote a summary e-mail on this issue on 7/13/07.   For details on variance modeling per group in nlme, see Pinheiro & Bates (2004; chapter 5); for a  discussion of issue with respect to SAS, see Little et al (2006; chapter 9) (SAS for mixed models).
Cheers,
David


On 11/8/09 11:27 AM, "Emmanuel Charpentier" <emm.charpentier at free.fr> wrote:

Le dimanche 08 novembre 2009 ? 00:01 +0000, Thomas Mang a ?crit :
> Hi,
>
> Suppose may data consist of groups (which also define the levels for
> random effects), which show group-wise heteroscedasticity, that is for
> some groups the variance of residuals is larger than for the others.
> Based on specific knowledge of the data and the problem this even makes
> perfect sense and is actually a good sign. Technically however it's not
> good of course, to put it mildly.
> Is there a way in lme4 to handle heteroscedasticity (with known grouping
> for the different variances) ?
> Any suggestions ?

Well, you might try to equalize dependent variable variances by the
"classical" transformations (log, sqrt) and their generalizations
(Box-Cox nd siblings, see "boxcox" and "logtrans" in MASS). Lrger sets
of transformations of both dependents nd independent variables are
proposed in ace and avas, and Harrell's Design (now rms) package has lso
some functions aimed at this kind of problems.

Be aware, however, that most of these functions im t finding optimal
transformations in  fixed-effect context, and that using them with
random-effects models is not necessarily a good solution.

HTH,

                                        Emmanuel Charpentier

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From Sebastiaan.DeSmedt at ua.ac.be  Tue Nov 10 12:08:49 2009
From: Sebastiaan.DeSmedt at ua.ac.be (De Smedt Sebastiaan)
Date: Tue, 10 Nov 2009 12:08:49 +0100
Subject: [R-sig-ME] heteroscedasticity (Thomas Mang)
In-Reply-To: <mailman.3.1257764402.14274.r-sig-mixed-models@r-project.org>
References: <mailman.3.1257764402.14274.r-sig-mixed-models@r-project.org>
Message-ID: <930B1A45F446404FA4D99A46F09209C401540D7F@xmail05.ad.ua.ac.be>


Hi,

In lme4 it is at this moment not possible to add variance structures to
mixed-effects models. However in the former version of lme4, nlme, you
can add these functions. See the book of Pinheiro & Bates, 2002 or this
mailing list!

Hope this helps,
Sebastiaan De Smedt


-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org
[mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of
r-sig-mixed-models-request at r-project.org
Sent: Monday, November 09, 2009 12:00 PM
To: r-sig-mixed-models at r-project.org
Subject: R-sig-mixed-models Digest, Vol 35, Issue 6

Send R-sig-mixed-models mailing list submissions to
	r-sig-mixed-models at r-project.org

To subscribe or unsubscribe via the World Wide Web, visit
	https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
or, via email, send a message with subject or body 'help' to
	r-sig-mixed-models-request at r-project.org

You can reach the person managing the list at
	r-sig-mixed-models-owner at r-project.org

When replying, please edit your Subject line so it is more specific
than "Re: Contents of R-sig-mixed-models digest..."


Today's Topics:

   1. heteroscedasticity (Thomas Mang)
   2. Linear Mixed-Effects Models (lme),	question about parameter
      estimates 	and random effect (R.S. Cotter)


----------------------------------------------------------------------

Message: 1
Date: Sun, 08 Nov 2009 00:01:36 +0000
From: Thomas Mang <thomasmang.ng at googlemail.com>
Subject: [R-sig-ME] heteroscedasticity
To: r-sig-mixed-models at r-project.org
Message-ID: <4AF60A60.5030701 at gmail.com>
Content-Type: text/plain; charset=ISO-8859-1; format=flowed

Hi,

Suppose may data consist of groups (which also define the levels for 
random effects), which show group-wise heteroscedasticity, that is for 
some groups the variance of residuals is larger than for the others.  
Based on specific knowledge of the data and the problem this even makes 
perfect sense and is actually a good sign. Technically however it's not 
good of course, to put it mildly.
Is there a way in lme4 to handle heteroscedasticity (with known grouping

for the different variances) ?
Any suggestions ?

thanks
Thomas



------------------------------

Message: 2
Date: Sun, 8 Nov 2009 23:01:09 -0800
From: "R.S. Cotter" <cotter.rs at gmail.com>
Subject: [R-sig-ME] Linear Mixed-Effects Models (lme),	question about
	parameter estimates 	and random effect
To: r-sig-mixed-models at r-project.org
Message-ID:
	<742479270911082301m52c22450pc7ce082c32ced5a0 at mail.gmail.com>
Content-Type: text/plain

Hello,

I have a question regarding Linear Mixed-Effects Models (lme). I have
searched help forum, but find it difficult to find an answer on my
question.
Probaly there is an easy answer to this, but due to lack of knowledge I
can
not understand following :

I look at whether there is a difference in the effect of weight (gram)
between two diets ("a" and "b") on feeding time. Place is random effect
(5
different locations). I ran script 1a), so far so good. I get the
intercept
and slope for diet "a" and "b". But for diet "b" I also want to add
extra
time needed for preparing (only diet "b" needs preparing). Feeding time
for
diet "a" is the same, only feeding time for diet "b" increases. I ran
script
1b), as expect intercept and slope for diet "b" changes, but why does
intercept and slope for diet "a" change? The feeding time is equal for
diet "a" in both script 1a) and 1b). Then I tried to see what happens
when
not control for random effect by using lm, and ran script 2a) and 2b).
And
now the intercept and slope for diet "a" is the same for both script
(without and with preparing time for diet "b"). Could the difference be
a
result of how the random effect is being calculated for in lme? The
difference is minimal, but I would like to understand why the intercept
and
slope for diet "a" changes?

Sorry if my question is too simple.

Regards Cotter

1a)
> lmefit1<-lme(log10(FeedingTime) ~
log10(Gram)*Diet,random=~1|Place,data=diet)
1b)
> lmefit2<-lme(log10(FeedingtimeWithPrep) ~
log10(Gram)*Diet,random=~1|Place,data=diet)
> summary(lmefit1)
Linear mixed-effects model fit by REML
 Data: diet
        AIC       BIC   logLik
  -24.12282 -19.12354 18.06141
Random effects:
 Formula: ~1 | Place
        (Intercept)   Residual
StdDev:   0.0505571 0.07350342
Fixed effects: log10(FeedingTime) ~ log10(Gram) * Diet
                       Value Std.Error DF   t-value p-value
(Intercept)        0.3111653 0.3737451 13  0.832560  0.4201
log10(Gram)        1.1664078 0.2735981 13  4.263216  0.0009
Dietb              1.1580016 0.5148035 13  2.249405  0.0425
log10(Gram):Dietb -0.6904469 0.3321850 13 -2.078501  0.0580
 Correlation:
                  (Intr) lg10(G) Dietb
log10(Gram)       -0.996
Dietb             -0.740  0.726
log10(Gram):Dietb  0.833 -0.826  -0.985
Standardized Within-Group Residuals:
       Min         Q1        Med         Q3        Max
-2.2608248 -0.3226060 -0.1256394  0.5658181  1.6808270
Number of Observations: 21
Number of Groups: 5

> summary(lmefit2)
Linear mixed-effects model fit by REML
 Data: diet
        AIC       BIC   logLik
  -29.98107 -24.98179 20.99054
Random effects:
 Formula: ~1 | Place
        (Intercept)   Residual
StdDev:  0.03568998 0.06341113
Fixed effects: log10(FeedingtimeWithPrep) ~ log10(Gram) * Diet
                       Value Std.Error DF   t-value p-value
(Intercept)        0.3001162 0.3210428 13  0.934817  0.3669
log10(Gram)        1.1760924 0.2352253 13  4.999855  0.0002
Dietb              1.0937006 0.4302214 13  2.542181  0.0246
log10(Gram):Dietb -0.5178826 0.2805392 13 -1.846026  0.0878
 Correlation:
                  (Intr) lg10(G) Dietb
log10(Gram)       -0.996
Dietb             -0.757  0.746
log10(Gram):Dietb  0.845 -0.840  -0.986
Standardized Within-Group Residuals:
        Min          Q1         Med          Q3         Max
-2.94950911 -0.19998787 -0.11069540  0.09370866  1.65930147
Number of Observations: 21
Number of Groups: 5


2a)
> lmfit1<-lm(log10(FeedingTime) ~ log10(Gram)*Diet,data=diet)
2b)
> lmfit2<-lm(log10(FeedingtimeWithPrep) ~ log10(Gram)*Diet,data=diet)
> summary(lmfit1)
Call:
lm(formula = log10(FeedingTime) ~ log10(Gram) * Diet, data = diet)
Residuals:
     Min       1Q   Median       3Q      Max
-0.23163 -0.03347  0.01312  0.05164  0.12056
Coefficients:
                  Estimate Std. Error t value Pr(>|t|)
(Intercept)         0.2942     0.4297   0.685  0.50277
log10(Gram)         1.1833     0.3156   3.750  0.00160 **
Dietb               1.1472     0.5302   2.164  0.04501 *
log10(Gram):Dietb  -0.6922     0.3578  -1.935  0.06983 .
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
Residual standard error: 0.08699 on 17 degrees of freedom
Multiple R-squared: 0.901,      Adjusted R-squared: 0.8836
F-statistic: 51.59 on 3 and 17 DF,  p-value: 9.492e-09
2b)
> summary(lmfit2)
Call:
lm(formula = log10(FeedingtimeWithPrep) ~ log10(Gram) * Diet,
    data = diet)
Residuals:
       Min         1Q     Median         3Q        Max
-0.2316266 -0.0003216  0.0001792  0.0058846  0.1205559
Coefficients:
                  Estimate Std. Error t value Pr(>|t|)
(Intercept)         0.2942     0.3512   0.838 0.413840
log10(Gram)         1.1833     0.2579   4.588 0.000262 ***
Dietb               1.0359     0.4333   2.391 0.028665 *
log10(Gram):Dietb  -0.4902     0.2924  -1.676 0.112005
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
Residual standard error: 0.0711 on 17 degrees of freedom
Multiple R-squared: 0.9698,     Adjusted R-squared: 0.9645
F-statistic:   182 on 3 and 17 DF,  p-value: 4.069e-13

	[[alternative HTML version deleted]]



------------------------------

_______________________________________________
R-sig-mixed-models mailing list
R-sig-mixed-models at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


End of R-sig-mixed-models Digest, Vol 35, Issue 6



From trea26 at gmail.com  Tue Nov 10 15:58:54 2009
From: trea26 at gmail.com (Antoine Tremblay)
Date: Tue, 10 Nov 2009 09:58:54 -0500
Subject: [R-sig-ME] Including by-item random intercepts for
	generalizability. Also to model (potential) heteroscedasticity?
Message-ID: <581a8bcf0911100658s74e7a85ex79b3acf06ce7c49f@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20091110/06d9305b/attachment.pl>

From baron at psych.upenn.edu  Tue Nov 10 17:12:49 2009
From: baron at psych.upenn.edu (Jonathan Baron)
Date: Tue, 10 Nov 2009 11:12:49 -0500
Subject: [R-sig-ME] Including by-item random intercepts for
	generalizability. Also to model (potential) heteroscedasticity?
In-Reply-To: <581a8bcf0911100658s74e7a85ex79b3acf06ce7c49f@mail.gmail.com>
References: <581a8bcf0911100658s74e7a85ex79b3acf06ce7c49f@mail.gmail.com>
Message-ID: <20091110161249.GA3440@psych.upenn.edu>

An attempt at an answer to part of ONE of your questions:

On 11/10/09 09:58, Antoine Tremblay wrote:
> It is our understanding that including participants and items in the random
> effect structure (in a mixed-effect regression) not only deals with issues
> of generalizability ...

I think that if you are after generalizability in Clark's ("Language
as fixed-effect fallacy") sense, you need more than this.  I think you
need random slopes as well as the random intercepts that you get from
simply including "+ (1|Subject) + (1|Item)".  That is, you need to ask
whether the variance across subjects or items in the size of the
effect is too big.  Thus, for a variable X, you need something like

(1+X|Subject) + (1+X|Item)

If you use pvals.fnc() in languageR, this won't work, because it won't
deal with correlated random effects.  So you have to do something
like:

(1|Subject) + (0+X|Subject) + (1|Item) + (0+X|Item)

which assumes that the random effects are independent.  I think you
can make them independent by centering (subtracting the mean from each
value) X and Y (the dependent variable) before including them.

On the other hand, I have argued that, if one-tailed tests are
appropriate, as they usually are in this sort of work, then

(1|Subject)+(1|Item)

is perfectly fine.  If it is "significant", it tells you that some
subject and some item show the effect of interest, even if other
subjects and other items go the other way (but less).  Arguably, this
is all you can ever know.

I'm saying this in part because I'd like to hear what others have to
say.

Jon
-- 
Jonathan Baron, Professor of Psychology, University of Pennsylvania
Home page: http://www.sas.upenn.edu/~baron



From trea26 at gmail.com  Tue Nov 10 17:57:28 2009
From: trea26 at gmail.com (Antoine Tremblay)
Date: Tue, 10 Nov 2009 11:57:28 -0500
Subject: [R-sig-ME] Including by-item random intercepts for
	generalizability. Also to model (potential) heteroscedasticity?
In-Reply-To: <20091110161249.GA3440@psych.upenn.edu>
References: <581a8bcf0911100658s74e7a85ex79b3acf06ce7c49f@mail.gmail.com>
	<20091110161249.GA3440@psych.upenn.edu>
Message-ID: <581a8bcf0911100857pa1fe245u5bc54fe33e3451e8@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20091110/5c9979dd/attachment.pl>

From danielezrajohnson at gmail.com  Tue Nov 10 18:20:32 2009
From: danielezrajohnson at gmail.com (Daniel Ezra Johnson)
Date: Tue, 10 Nov 2009 12:20:32 -0500
Subject: [R-sig-ME] Including by-item random intercepts for
	generalizability. Also to model (potential) heteroscedasticity?
In-Reply-To: <581a8bcf0911100857pa1fe245u5bc54fe33e3451e8@mail.gmail.com>
References: <581a8bcf0911100658s74e7a85ex79b3acf06ce7c49f@mail.gmail.com>
	<20091110161249.GA3440@psych.upenn.edu>
	<581a8bcf0911100857pa1fe245u5bc54fe33e3451e8@mail.gmail.com>
Message-ID: <a46630750911100920o4927ada2p87488b9cb3fea3f0@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20091110/dc63d85d/attachment.pl>

From trea26 at gmail.com  Tue Nov 10 19:30:33 2009
From: trea26 at gmail.com (Antoine Tremblay)
Date: Tue, 10 Nov 2009 13:30:33 -0500
Subject: [R-sig-ME] Including by-item random intercepts for
	generalizability. Also to model (potential) heteroscedasticity?
In-Reply-To: <a46630750911100920o4927ada2p87488b9cb3fea3f0@mail.gmail.com>
References: <581a8bcf0911100658s74e7a85ex79b3acf06ce7c49f@mail.gmail.com>
	<20091110161249.GA3440@psych.upenn.edu>
	<581a8bcf0911100857pa1fe245u5bc54fe33e3451e8@mail.gmail.com>
	<a46630750911100920o4927ada2p87488b9cb3fea3f0@mail.gmail.com>
Message-ID: <581a8bcf0911101030q677c9353pdd8a6b4b77c20257@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20091110/59ccb54c/attachment.pl>

From jropers at gmail.com  Tue Nov 10 21:11:41 2009
From: jropers at gmail.com (Jacques Ropers)
Date: Tue, 10 Nov 2009 21:11:41 +0100
Subject: [R-sig-ME] Contrasts with nlme
Message-ID: <4AF9C8FD.8020808@gmail.com>

Dear All,

I'm modelling some longitudinal data (1 continuous
response variable measured at 6 times (covariate time taken as factor), 
1 continuous baseline, one "treatment" variable also taken as a factor) 
collected in the same subjects using the following model:


model.lme<- lme(response ~ V0+ time + tt + tt:time, random = 
~1|subject,correlation = corSymm(form = ~ 1 | subject), 
na.action=na.omit, data=total)

Then I would lke to estimate the effect of "treatment" at time = 6 using 
the package "contrast"

library(contrast)
contrast(model.lme ,
a = list(tt="1",time="6"),
b = list(tt="0",time="6")
)

But I get the following error message
"Erreur dans gendata.default(fit = list(modelStruct = list(reStruct = 
list(:   not enough factors"

I'm obviously doing something wrong.

Thanks for your help.

Jacques



From trea26 at gmail.com  Wed Nov 11 16:02:49 2009
From: trea26 at gmail.com (Antoine Tremblay)
Date: Wed, 11 Nov 2009 10:02:49 -0500
Subject: [R-sig-ME] R-sig-mixed-models Digest, Vol 35, Issue 9
In-Reply-To: <mailman.9.1257937202.14992.r-sig-mixed-models@r-project.org>
References: <mailman.9.1257937202.14992.r-sig-mixed-models@r-project.org>
Message-ID: <581a8bcf0911110702g3591ab4ax873786b3fda02036@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20091111/95a6736f/attachment.pl>

From bates at stat.wisc.edu  Wed Nov 11 18:52:51 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 11 Nov 2009 11:52:51 -0600
Subject: [R-sig-ME] Contrasts with nlme
In-Reply-To: <4AF9C8FD.8020808@gmail.com>
References: <4AF9C8FD.8020808@gmail.com>
Message-ID: <40e66e0b0911110952t7d22b817w7ff4d7216a72a932@mail.gmail.com>

I think you will need to check with the author of the contrast package
regarding this error.  It is entirely possible that the methods in the
package do not accept lme models.

On Tue, Nov 10, 2009 at 2:11 PM, Jacques Ropers <jropers at gmail.com> wrote:
> Dear All,
>
> I'm modelling some longitudinal data (1 continuous
> response variable measured at 6 times (covariate time taken as factor), 1
> continuous baseline, one "treatment" variable also taken as a factor)
> collected in the same subjects using the following model:
>
>
> model.lme<- lme(response ~ V0+ time + tt + tt:time, random =
> ~1|subject,correlation = corSymm(form = ~ 1 | subject), na.action=na.omit,
> data=total)
>
> Then I would lke to estimate the effect of "treatment" at time = 6 using the
> package "contrast"
>
> library(contrast)
> contrast(model.lme ,
> a = list(tt="1",time="6"),
> b = list(tt="0",time="6")
> )
>
> But I get the following error message
> "Erreur dans gendata.default(fit = list(modelStruct = list(reStruct = list(:
> ? not enough factors"
>
> I'm obviously doing something wrong.
>
> Thanks for your help.
>
> Jacques
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From ken.knoblauch at inserm.fr  Wed Nov 11 19:10:07 2009
From: ken.knoblauch at inserm.fr (Ken Knoblauch)
Date: Wed, 11 Nov 2009 18:10:07 +0000 (UTC)
Subject: [R-sig-ME] Contrasts with nlme
References: <4AF9C8FD.8020808@gmail.com>
	<40e66e0b0911110952t7d22b817w7ff4d7216a72a932@mail.gmail.com>
Message-ID: <loom.20091111T190423-451@post.gmane.org>

Douglas Bates <bates at ...> writes:

> 
> I think you will need to check with the author of the contrast package
> regarding this error.  It is entirely possible that the methods in the
> package do not accept lme models.
> 
> On Tue, Nov 10, 2009 at 2:11 PM, Jacques Ropers <jropers at ...> wrote:
> > Dear All,
> >
> > I'm modelling some longitudinal data (1 continuous
> > response variable measured at 6 times (covariate time taken as factor), 1
> > continuous baseline, one "treatment" variable also taken as a factor)
> > collected in the same subjects using the following model:
> >
> >
> > model.lme<- lme(response ~ V0+ time + tt + tt:time, random =
> > ~1|subject,correlation = corSymm(form = ~ 1 | subject), na.action=na.omit,
> > data=total)
> >
> > Then I would lke to estimate the effect of "treatment" at time = 6 using the
> > package "contrast"
> >
> > library(contrast)
> > contrast(model.lme ,
> > a = list(tt="1",time="6"),
> > b = list(tt="0",time="6")
> > )
> >
> > But I get the following error message
> > "Erreur dans gendata.default(fit = list(modelStruct = list(reStruct = list(:
> > ? not enough factors"
> >
> > I'm obviously doing something wrong.

The vignette with the package contains an example
for an lme object, however, which is in no way
incompatible with the advice at the top.

Ken

> > Thanks for your help.
> >
> > Jacques
-- 
Ken Knoblauch
Inserm U846
Stem-cell and Brain Research Institute
Department of Integrative Neurosciences
18 avenue du Doyen L?pine
69500 Bron
France
tel: +33 (0)4 72 91 34 77
fax: +33 (0)4 72 91 34 61
portable: +33 (0)6 84 10 64 10
http://www.sbri.fr/members/kenneth-knoblauch.html



From elisa.fuentes-montemayor at stir.ac.uk  Thu Nov 12 18:33:27 2009
From: elisa.fuentes-montemayor at stir.ac.uk (Elisa Fuentes-Montemayor)
Date: Thu, 12 Nov 2009 17:33:27 +0000
Subject: [R-sig-ME] glmer - help with t values
Message-ID: <1B8AD69721636A40A87E271479473D7201289B6AA798@EXCH2007.ad.stir.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20091112/a11bd6d7/attachment.pl>

From ebszolocsucsor at freemail.hu  Thu Nov 12 22:50:29 2009
From: ebszolocsucsor at freemail.hu (=?ISO-8859-2?Q?Bal=E1zs_Lest=E1r?=)
Date: Thu, 12 Nov 2009 22:50:29 +0100 (CET)
Subject: [R-sig-ME] poly- results
Message-ID: <freemail.20091012225029.24888@fm21.freemail.hu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20091112/9746c160/attachment.pl>

From metras.raphaelle at choisyclub.org  Fri Nov 13 14:23:49 2009
From: metras.raphaelle at choisyclub.org (=?iso-8859-1?Q?rapha=EBlle_m=E9tras?=)
Date: Fri, 13 Nov 2009 14:23:49 +0100 (CET)
Subject: [R-sig-ME] convert into ORs
In-Reply-To: <1255523084.833d834amelie.lescroel@cebc.cnrs.fr>
References: <1255523084.833d834amelie.lescroel@cebc.cnrs.fr>
Message-ID: <51893.86.5.244.26.1258118629.squirrel@wwws.choisyclub.org>

Dear all,

I run a GLMM binomial, using glmer function. Please see the command and
the ouputs at the end of my message.

I wanted to know if there is a command that would convert my estimates
into odds ratios, e.g. similar to the command logistic.display() that is
working for 'glm'.

I've been looking for a while but I really cant find it.

Thanks very much for your help,

Regards,

Raphaelle


> k8b <- glmer(status  ~ no_tradcat + dayscat + (1|fm_id) ,
family=binomial, data=basket)
> summary(k8b)
Generalized linear mixed model fit by the Laplace approximation
Formula: status ~ no_tradcat + dayscat + (1 | fm_id)
   Data: basket
 AIC BIC logLik deviance
 120 134  -54.8      110
Random effects:
 Groups Name        Variance Std.Dev.
 fm_id  (Intercept)  1        1
Number of obs: 117, groups: fm_id, 48

Fixed effects:
                  Estimate Std. Error z value Pr(>|z|)
(Intercept)         -4.501      1.166   -3.86  0.00011 ***
no_tradcat1-2trad    2.686      0.752    3.57  0.00036 ***
dayscat1-2days       2.896      1.072    2.70  0.00689 **
dayscatsame day      3.563      1.015    3.51  0.00045 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Correlation of Fixed Effects:
            (Intr) n_t1-2 dys1-2
n_trdct1-2t -0.617
dysct1-2dys -0.878  0.339
dayscatsmdy -0.745  0.067  0.793



From bolker at ufl.edu  Fri Nov 13 21:56:37 2009
From: bolker at ufl.edu (Ben Bolker)
Date: Fri, 13 Nov 2009 15:56:37 -0500
Subject: [R-sig-ME] glmer - help with t values
In-Reply-To: <1B8AD69721636A40A87E271479473D7201289B6AA798@EXCH2007.ad.stir.ac.uk>
References: <1B8AD69721636A40A87E271479473D7201289B6AA798@EXCH2007.ad.stir.ac.uk>
Message-ID: <4AFDC805.1040106@ufl.edu>

Elisa Fuentes-Montemayor wrote:
> Hi,
> 
> I'm new in R and I've performed a glmer with several factors, but more than two levels in some of the factors. In the output I get after performing the glmer I obtain t values for each of the factor levels, like this:
> 
> Fixed effects:
>                                 Estimate Std. Error t value
> (Intercept)                      3.72592    2.71117   1.374
> Farm.typeCONV                   -1.17776    0.36591  -3.219
> HabitatHR                        0.55193    0.23882   2.311
> HabitatSRG                       0.08069    0.25854   0.312
> HabitatWM                        0.42429    0.23221   1.827
> ActivityMixed                    1.33646    0.41566   3.215
> ActivityPastoral                -0.71769    1.62846  -0.441
> 
> But what I really need is an overall t value for each factor (Farm.type, Habitat, Activity). Could anyone please tell me how I can do this?
> 
> Thanks!
> 
> Elisa
> 

  What you need is a Wald F value, rather than a Wald t value

http://glmm.wikidot.com/local--files/examples/glmmfuns.R
has a waldF(object, variable, den.df) function where "object"
is your lme4 fit, "variable" is the name of your variable,
and "den.df" is your denominator df (you can just make it NA):

e.g.

tmp <- "http://glmm.wikidot.com/local--files/examples/glmmfuns.R"
source(url(tmp))

set.seed(1001)
x <- runif(300)
f <- factor(rep(LETTERS[1:3],each=100))
g <- factor(rep(letters[1:10],each=30))
params <- list(slope=2,int=c(-0.5,0.5,1),
               grp=rnorm(10,sd=1))
eta <- with(params,int[f]+slope*x+grp[g])
y <- rbinom(300,prob=plogis(eta),size=10)
X <- data.frame(x,f,y)

library(lme4)
m1 <- glmer(cbind(y,10-y)~f+x+(1|g),data=X,family=binomial)
summary(m1)

waldF(m1,"f",NA)



> Elisa Fuentes-Montemayor, MSc
> PhD student
> School of Biological & Environmental Sciences
> University of Stirling
> Stirling FK9 4LA
> Scotland, UK
> http://www.sbes.stir.ac.uk/people/postgrads/fuentes-montemayor.html
> 
> 
> 
> 


-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / www.zoology.ufl.edu/bolker
GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc



From trea26 at gmail.com  Fri Nov 13 23:01:21 2009
From: trea26 at gmail.com (Antoine Tremblay)
Date: Fri, 13 Nov 2009 17:01:21 -0500
Subject: [R-sig-ME] poly() or rcs()?
Message-ID: <581a8bcf0911131401v5742f919haaffd5200ae9d76f@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20091113/a4ad2978/attachment.pl>

From David.Duffy at qimr.edu.au  Sat Nov 14 23:11:56 2009
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Sun, 15 Nov 2009 08:11:56 +1000 (EST)
Subject: [R-sig-ME] convert into ORs
In-Reply-To: <51893.86.5.244.26.1258118629.squirrel@wwws.choisyclub.org>
References: <1255523084.833d834amelie.lescroel@cebc.cnrs.fr>
	<51893.86.5.244.26.1258118629.squirrel@wwws.choisyclub.org>
Message-ID: <Pine.LNX.4.64.0911150800580.12493@orpheus.qimr.edu.au>

On Fri, 13 Nov 2009, rapha?lle m?tras wrote:

> I run a GLMM binomial, using glmer function. Please see the command and
> the ouputs at the end of my message.
>
> I wanted to know if there is a command that would convert my estimates
> into odds ratios, e.g. similar to the command logistic.display() that is
> working for 'glm'.
>
>> k8b <- glmer(status  ~ no_tradcat + dayscat + (1|fm_id) ,
> family=binomial, data=basket)

The default contrasts used by glmer (and glm etc) make the 
coefficients the log(OR) with respect to base category of each 
predictor variable.

so

my.logistic.display <- function(glmer.model) {
   coefs <- summary(glmer.model)@coefs
   data.frame(OR=exp(coefs[,1]),
              Lower=exp(coefs[,1]-1.96*coefs[,2]),
              Upper=exp(coefs[,1]+1.96*coefs[,2]))
}


-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v

From trea26 at gmail.com  Sun Nov 15 21:20:07 2009
From: trea26 at gmail.com (Antoine Tremblay)
Date: Sun, 15 Nov 2009 15:20:07 -0500
Subject: [R-sig-ME] poly() and rcs()?
Message-ID: <581a8bcf0911151220u2edeaa33s3e5efcdbaa7fc918@mail.gmail.com>

Dear all,

Here is a question regarding the difference between using poly() and rcs().

If you fit a model using poly(), as shown below, the summary returns
statistics for the term "linear" term,
poly(TrialContinuous,2,raw=TRUE)1, and statistics for the quadratic,
poly(TrialContinuous,2,raw=TRUE)2. Here, the summary tells us that the
"linear" and quadratic terms are significant, that the interaction
between the linear term and the factor variable FreqGroup is
significant, but that the interaction between the quadratic and
FreqGroup is not significant.

> m1=lmer(LogRT~poly(TrialContinuous,2,raw=TRUE)*FreqGroup+(1|Subject),data=dat.li)
> print(m1,corr=F)
Linear mixed model fit by REML
Formula: LogRT ~ poly(TrialContinuous, 2, raw = TRUE) * FreqGroup + (1
|      Subject)
   Data: dat.li
   AIC   BIC     logLik deviance REMLdev
 17199 17266  -8592    17056   17183
Random effects:
 Groups   Name        Variance   Std.Dev.
 Subject  (Intercept)   0.014825  0.12176
 Residual                  0.101560  0.31868
Number of obs: 30742, groups: Subject, 25

Fixed effects:

         Estimate    Std. Error    t value
(Intercept)
     6.307e+00  2.456e-02    256.85
poly(TrialContinuous, 2, raw = TRUE)1                       -1.570e-04
  4.639e-06   -33.84
poly(TrialContinuous, 2, raw = TRUE)2                        9.779e-08
  1.120e-08    8.73
FreqGroupLow
3.299e-02   6.085e-03    5.42
poly(TrialContinuous, 2, raw = TRUE)1:FreqGroupLow  1.769e-05
8.736e-06    2.03
poly(TrialContinuous, 2, raw = TRUE)2:FreqGroupLow -1.168e-08
2.123e-08   -0.55

Now, if you use rcs() instead, the summary return statistics for the
first and second splines, as shown below. We see that the 2 splines
are significant, but there is no interaction between any of the
splines and FreqGroup. This reflects what we see in the model fitted
with poly(), where the the linear and quadratic terms were significant
but the quadratic by FreqGroup interaction was not significant. What's
missing in the model fitted with rcs() is the linear term.

> m2=lmer(LogRT~rcs(TrialContinuous,3)*FreqGroup+(1|Subject),data=dat.li)
> print(m2,corr=F)
Linear mixed model fit by REML
Formula: LogRT ~ rcs(TrialContinuous, 3) * FreqGroup + (1 | Subject)
   Data: dat.li
   AIC   BIC     logLik deviance REMLdev
 17180 17247  -8582    17065   17164
Random effects:
 Groups   Name        Variance   Std.Dev.
 Subject  (Intercept)  0.014826   0.12176
 Residual                 0.101592   0.31874
Number of obs: 30742, groups: Subject, 25

Fixed effects:

         Estimate    Std. Error    t value
(Intercept)
     6.286e+00  2.498e-02    251.62
rcs(TrialContinuous, 3)TrialContinuous
-2.538e-04  1.253e-05   -20.26
rcs(TrialContinuous, 3)TrialContinuous'
1.285e-04   1.547e-05    8.31
FreqGroupLow
3.599e-02   1.061e-02    3.39
rcs(TrialContinuous, 3)TrialContinuous:FreqGroupLow   3.018e-05
2.379e-05    1.27
rcs(TrialContinuous, 3)TrialContinuous':FreqGroupLow -1.660e-05
2.936e-05   -0.57

I tried adding a linear term "TrialContinuous" to the model fitted
with rcs(), as shown below, but that doesn't work, the model is not
positive definite.

> m3=lmer(LogRT ~ (TrialContinuous + rcs(TrialContinuous,3)) * FreqGroup + (1|Subject), data = dat.li)
> Error in mer_finalize(ans) : Downdated X'X is not positive definite, 7.

The question is where is the linear term (if there is one)?
Is it hidden somewhere? Or is it simply not a question to ask when
using rcs() to fit models?
Should I use poly() rather than rcs()?
Are there situations where you would want to use poly() over rcs() and
vice versa?

Additionally, how should we interpret the statistics for the splines?
Does their significance mean that the slopes in the splines are
significantly different than 0?
In the case of the second spline, does it's significance mean that it
is significantly different than the first spline?

Thank you very much for your time and efforts. Your help is greatly appreciated.
Sincerely

--
Antoine Tremblay
Department of Neuroscience
Georgetown University
Washington DC



From vito.muggeo at unipa.it  Mon Nov 16 16:58:34 2009
From: vito.muggeo at unipa.it (Vito Muggeo (UniPa))
Date: Mon, 16 Nov 2009 16:58:34 +0100
Subject: [R-sig-ME] poly() and rcs()?
In-Reply-To: <581a8bcf0911151220u2edeaa33s3e5efcdbaa7fc918@mail.gmail.com>
References: <581a8bcf0911151220u2edeaa33s3e5efcdbaa7fc918@mail.gmail.com>
Message-ID: <4B0176AA.3000907@unipa.it>

dear Antoine,
I don't know the rcs() function (from which package..?)

BTW, why do you want add a linear term? I presume it is "included" in 
rcs().. I mean the linear term you want to include is linear combination 
of two bases (colums) returned by rcs(). So if you want include it, you 
should remove one column of rcs()...

Also the parameter estimates you get depend on parameterization of 
poly() and rcs(). Using basis splines it is meaningless to test for some 
spline coefficient to be different from zero.. I imagine, again I don't 
know rcs(), the same holds for rcs().
If you want to simplify your model I suggest to use differences in log 
likelihoods

Hope this helps you,
vito

Antoine Tremblay ha scritto:
> Dear all,
> 
> Here is a question regarding the difference between using poly() and rcs().
> 
> If you fit a model using poly(), as shown below, the summary returns
> statistics for the term "linear" term,
> poly(TrialContinuous,2,raw=TRUE)1, and statistics for the quadratic,
> poly(TrialContinuous,2,raw=TRUE)2. Here, the summary tells us that the
> "linear" and quadratic terms are significant, that the interaction
> between the linear term and the factor variable FreqGroup is
> significant, but that the interaction between the quadratic and
> FreqGroup is not significant.
> 
>> m1=lmer(LogRT~poly(TrialContinuous,2,raw=TRUE)*FreqGroup+(1|Subject),data=dat.li)
>> print(m1,corr=F)
> Linear mixed model fit by REML
> Formula: LogRT ~ poly(TrialContinuous, 2, raw = TRUE) * FreqGroup + (1
> |      Subject)
>    Data: dat.li
>    AIC   BIC     logLik deviance REMLdev
>  17199 17266  -8592    17056   17183
> Random effects:
>  Groups   Name        Variance   Std.Dev.
>  Subject  (Intercept)   0.014825  0.12176
>  Residual                  0.101560  0.31868
> Number of obs: 30742, groups: Subject, 25
> 
> Fixed effects:
> 
>          Estimate    Std. Error    t value
> (Intercept)
>      6.307e+00  2.456e-02    256.85
> poly(TrialContinuous, 2, raw = TRUE)1                       -1.570e-04
>   4.639e-06   -33.84
> poly(TrialContinuous, 2, raw = TRUE)2                        9.779e-08
>   1.120e-08    8.73
> FreqGroupLow
> 3.299e-02   6.085e-03    5.42
> poly(TrialContinuous, 2, raw = TRUE)1:FreqGroupLow  1.769e-05
> 8.736e-06    2.03
> poly(TrialContinuous, 2, raw = TRUE)2:FreqGroupLow -1.168e-08
> 2.123e-08   -0.55
> 
> Now, if you use rcs() instead, the summary return statistics for the
> first and second splines, as shown below. We see that the 2 splines
> are significant, but there is no interaction between any of the
> splines and FreqGroup. This reflects what we see in the model fitted
> with poly(), where the the linear and quadratic terms were significant
> but the quadratic by FreqGroup interaction was not significant. What's
> missing in the model fitted with rcs() is the linear term.
> 
>> m2=lmer(LogRT~rcs(TrialContinuous,3)*FreqGroup+(1|Subject),data=dat.li)
>> print(m2,corr=F)
> Linear mixed model fit by REML
> Formula: LogRT ~ rcs(TrialContinuous, 3) * FreqGroup + (1 | Subject)
>    Data: dat.li
>    AIC   BIC     logLik deviance REMLdev
>  17180 17247  -8582    17065   17164
> Random effects:
>  Groups   Name        Variance   Std.Dev.
>  Subject  (Intercept)  0.014826   0.12176
>  Residual                 0.101592   0.31874
> Number of obs: 30742, groups: Subject, 25
> 
> Fixed effects:
> 
>          Estimate    Std. Error    t value
> (Intercept)
>      6.286e+00  2.498e-02    251.62
> rcs(TrialContinuous, 3)TrialContinuous
> -2.538e-04  1.253e-05   -20.26
> rcs(TrialContinuous, 3)TrialContinuous'
> 1.285e-04   1.547e-05    8.31
> FreqGroupLow
> 3.599e-02   1.061e-02    3.39
> rcs(TrialContinuous, 3)TrialContinuous:FreqGroupLow   3.018e-05
> 2.379e-05    1.27
> rcs(TrialContinuous, 3)TrialContinuous':FreqGroupLow -1.660e-05
> 2.936e-05   -0.57
> 
> I tried adding a linear term "TrialContinuous" to the model fitted
> with rcs(), as shown below, but that doesn't work, the model is not
> positive definite.
> 
>> m3=lmer(LogRT ~ (TrialContinuous + rcs(TrialContinuous,3)) * FreqGroup + (1|Subject), data = dat.li)
>> Error in mer_finalize(ans) : Downdated X'X is not positive definite, 7.
> 
> The question is where is the linear term (if there is one)?
> Is it hidden somewhere? Or is it simply not a question to ask when
> using rcs() to fit models?
> Should I use poly() rather than rcs()?
> Are there situations where you would want to use poly() over rcs() and
> vice versa?
> 
> Additionally, how should we interpret the statistics for the splines?
> Does their significance mean that the slopes in the splines are
> significantly different than 0?
> In the case of the second spline, does it's significance mean that it
> is significantly different than the first spline?
> 
> Thank you very much for your time and efforts. Your help is greatly appreciated.
> Sincerely
> 
> --
> Antoine Tremblay
> Department of Neuroscience
> Georgetown University
> Washington DC
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

-- 
====================================
Vito M.R. Muggeo
Dip.to Sc Statist e Matem `Vianelli'
Universit? di Palermo
viale delle Scienze, edificio 13
90128 Palermo - ITALY
tel: 091 6626240
fax: 091 485726/485612
http://dssm.unipa.it/vmuggeo



From t.j.m.van.dooren at biology.leidenuniv.nl  Mon Nov 16 23:37:57 2009
From: t.j.m.van.dooren at biology.leidenuniv.nl (Tom Van Dooren)
Date: Mon, 16 Nov 2009 23:37:57 +0100
Subject: [R-sig-ME] test significance of single random effect
Message-ID: <4B01D445.2020606@biology.leidenuniv.nl>

I tried to find an easy way to test whether the random effect would be 
significant in a (generalized) mixed model with a single random effect.
It annoyed me that log-likelihoods of lm or glm and lmer are not 
necesarily directly comparable -> trouble with calculating likelihood 
ratios.
What do members of this list think of the following simulation approach?
It basically amounts to simulating a distribution for the log 
likelihood, given the null hypothesis that there is no random effect 
variance and that the fixed effect model is correct.


library(lme4)
mm1 <- lmer(Reaction ~ Days + (1|Subject), sleepstudy)
lm1<- lm(Reaction ~ Days, sleepstudy)


LL<-numeric(500)
for(i in 1:500){
resp<-simulate(lm1)
LL[i]<-logLik(lmer(resp[,1] ~ Days + (1|Subject), sleepstudy))
}

hist(LL)
logLik(mm1)
mean(LL>logLik(mm1))



From bolker at ufl.edu  Tue Nov 17 00:26:06 2009
From: bolker at ufl.edu (Ben Bolker)
Date: Mon, 16 Nov 2009 18:26:06 -0500
Subject: [R-sig-ME] test significance of single random effect
In-Reply-To: <4B01D445.2020606@biology.leidenuniv.nl>
References: <4B01D445.2020606@biology.leidenuniv.nl>
Message-ID: <4B01DF8E.1060100@ufl.edu>


  Have you tried the RLRsim package??

Tom Van Dooren wrote:
> I tried to find an easy way to test whether the random effect would be 
> significant in a (generalized) mixed model with a single random effect.
> It annoyed me that log-likelihoods of lm or glm and lmer are not 
> necesarily directly comparable -> trouble with calculating likelihood 
> ratios.
> What do members of this list think of the following simulation approach?
> It basically amounts to simulating a distribution for the log 
> likelihood, given the null hypothesis that there is no random effect 
> variance and that the fixed effect model is correct.
> 
> 
> library(lme4)
> mm1 <- lmer(Reaction ~ Days + (1|Subject), sleepstudy)
> lm1<- lm(Reaction ~ Days, sleepstudy)
> 
> 
> LL<-numeric(500)
> for(i in 1:500){
> resp<-simulate(lm1)
> LL[i]<-logLik(lmer(resp[,1] ~ Days + (1|Subject), sleepstudy))
> }
> 
> hist(LL)
> logLik(mm1)
> mean(LL>logLik(mm1))
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / www.zoology.ufl.edu/bolker
GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc



From matthias_gralle at eva.mpg.de  Tue Nov 17 10:49:39 2009
From: matthias_gralle at eva.mpg.de (Matthias Gralle)
Date: Tue, 17 Nov 2009 10:49:39 +0100
Subject: [R-sig-ME] test significance of single random effect
In-Reply-To: <4B01DF8E.1060100@ufl.edu>
References: <4B01D445.2020606@biology.leidenuniv.nl> <4B01DF8E.1060100@ufl.edu>
Message-ID: <4B0271B3.4000300@eva.mpg.de>

I had basically the same problem a short time ago, and resorted to lme 
instead of lmer, because one can directly compare lme and lm objects 
using anova(). Is that OK, or is this feature of lme depreciated ?

Ben Bolker wrote:
>   Have you tried the RLRsim package??
>
> Tom Van Dooren wrote:
>   
>> I tried to find an easy way to test whether the random effect would be 
>> significant in a (generalized) mixed model with a single random effect.
>> It annoyed me that log-likelihoods of lm or glm and lmer are not 
>> necesarily directly comparable -> trouble with calculating likelihood 
>> ratios.
>> What do members of this list think of the following simulation approach?
>> It basically amounts to simulating a distribution for the log 
>> likelihood, given the null hypothesis that there is no random effect 
>> variance and that the fixed effect model is correct.
>>
>>
>> library(lme4)
>> mm1 <- lmer(Reaction ~ Days + (1|Subject), sleepstudy)
>> lm1<- lm(Reaction ~ Days, sleepstudy)
>>
>>
>> LL<-numeric(500)
>> for(i in 1:500){
>> resp<-simulate(lm1)
>> LL[i]<-logLik(lmer(resp[,1] ~ Days + (1|Subject), sleepstudy))
>> }
>>
>> hist(LL)
>> logLik(mm1)
>> mean(LL>logLik(mm1))
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>     
>
>
>   


-- 
Matthias Gralle, PhD
Dept. Evolutionary Genetics
Max Planck Institute for Evolutionary Anthropology
Deutscher Platz 6
04103 Leipzig, Germany
Tel +49 341 3550 519
Fax +49 341 3550 555



From t.j.m.van.dooren at biology.leidenuniv.nl  Tue Nov 17 10:23:24 2009
From: t.j.m.van.dooren at biology.leidenuniv.nl (Tom Van Dooren)
Date: Tue, 17 Nov 2009 10:23:24 +0100
Subject: [R-sig-ME] test significance of single random effect
In-Reply-To: <4B01DF8E.1060100@ufl.edu>
References: <4B01D445.2020606@biology.leidenuniv.nl> <4B01DF8E.1060100@ufl.edu>
Message-ID: <20091117102324.7ozhcspggks4kk00@webmail.gorlaeus.net>

Hi Ben,
yes I did. The Orthodont example in the LRTSim() help file ran  
perfectly well using lme(), but not with lmer().
Do you think it is OK to use simulated log-likelihoods as a test  
statistic, instead of a likelihood ratio?
Cheers, Tom


Quoting Ben Bolker <bolker at ufl.edu>:

>
>   Have you tried the RLRsim package??
>
> Tom Van Dooren wrote:
>> I tried to find an easy way to test whether the random effect would be
>> significant in a (generalized) mixed model with a single random effect.
>> It annoyed me that log-likelihoods of lm or glm and lmer are not
>> necesarily directly comparable -> trouble with calculating likelihood
>> ratios.
>> What do members of this list think of the following simulation approach?
>> It basically amounts to simulating a distribution for the log
>> likelihood, given the null hypothesis that there is no random effect
>> variance and that the fixed effect model is correct.
>>
>>
>> library(lme4)
>> mm1 <- lmer(Reaction ~ Days + (1|Subject), sleepstudy)
>> lm1<- lm(Reaction ~ Days, sleepstudy)
>>
>>
>> LL<-numeric(500)
>> for(i in 1:500){
>> resp<-simulate(lm1)
>> LL[i]<-logLik(lmer(resp[,1] ~ Days + (1|Subject), sleepstudy))
>> }
>>
>> hist(LL)
>> logLik(mm1)
>> mean(LL>logLik(mm1))
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
> --
> Ben Bolker
> Associate professor, Biology Dep't, Univ. of Florida
> bolker at ufl.edu / www.zoology.ufl.edu/bolker
> GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc
>



From bates at stat.wisc.edu  Tue Nov 17 18:03:25 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 17 Nov 2009 11:03:25 -0600
Subject: [R-sig-ME] test significance of single random effect
In-Reply-To: <4B0271B3.4000300@eva.mpg.de>
References: <4B01D445.2020606@biology.leidenuniv.nl> <4B01DF8E.1060100@ufl.edu>
	<4B0271B3.4000300@eva.mpg.de>
Message-ID: <40e66e0b0911170903y67f57699pb002bb9500826f2f@mail.gmail.com>

On Tue, Nov 17, 2009 at 3:49 AM, Matthias Gralle
<matthias_gralle at eva.mpg.de> wrote:
> I had basically the same problem a short time ago, and resorted to lme
> instead of lmer, because one can directly compare lme and lm objects using
> anova(). Is that OK, or is this feature of lme depreciated ?

Is that not possible for linear mixed-effects models fit by lmer using
REML = FALSE? (Occasionally I lose track of what can be done in
different versions of lme4.)  You don't want to compare an lmer model
fit by REML with the log-likelihood of an lm model but you should be
able to compare likelihoods (subject to the caveat that the p-value
for the likelihood ratio test on the boundary of the parameter space
is conservative).

> Ben Bolker wrote:
>>
>> ?Have you tried the RLRsim package??
>>
>> Tom Van Dooren wrote:
>>
>>>
>>> I tried to find an easy way to test whether the random effect would be
>>> significant in a (generalized) mixed model with a single random effect.
>>> It annoyed me that log-likelihoods of lm or glm and lmer are not
>>> necesarily directly comparable -> trouble with calculating likelihood
>>> ratios.
>>> What do members of this list think of the following simulation approach?
>>> It basically amounts to simulating a distribution for the log likelihood,
>>> given the null hypothesis that there is no random effect variance and that
>>> the fixed effect model is correct.
>>>
>>>
>>> library(lme4)
>>> mm1 <- lmer(Reaction ~ Days + (1|Subject), sleepstudy)
>>> lm1<- lm(Reaction ~ Days, sleepstudy)
>>>
>>>
>>> LL<-numeric(500)
>>> for(i in 1:500){
>>> resp<-simulate(lm1)
>>> LL[i]<-logLik(lmer(resp[,1] ~ Days + (1|Subject), sleepstudy))
>>> }
>>>
>>> hist(LL)
>>> logLik(mm1)
>>> mean(LL>logLik(mm1))
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>>
>>
>
>
> --
> Matthias Gralle, PhD
> Dept. Evolutionary Genetics
> Max Planck Institute for Evolutionary Anthropology
> Deutscher Platz 6
> 04103 Leipzig, Germany
> Tel +49 341 3550 519
> Fax +49 341 3550 555
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From datkins at u.washington.edu  Tue Nov 17 17:10:38 2009
From: datkins at u.washington.edu (David Atkins)
Date: Tue, 17 Nov 2009 08:10:38 -0800
Subject: [R-sig-ME] [Fwd: effective sample size]
Message-ID: <4B02CAFE.5050607@u.washington.edu>


This was just posted to the multilevel listserv, and I have taken a very 
quick glance.  It appears to offer an alternative form for estimating 
degrees of freedom.  It's focused on longitudinal data, and I have not 
looked closely enough to see whether it would be more generally 
applicable to mixed-models (multilevel, nested, crossed, etc.) or 
whether it would "scale up" for larger problems.

Given all the hoo-hah around dfs, thought I would at least kick it out 
to the group.

cheers, Dave

-------- Original Message --------
Subject: effective sample size
Date: Tue, 17 Nov 2009 09:12:47 -0600
From: Stas Kolenikov <skolenik at GMAIL.COM>
Reply-To: Multilevel modelling discussion list <MULTILEVEL at JISCMAIL.AC.UK>
To: MULTILEVEL at JISCMAIL.AC.UK

The recent issue of The American Statistician contains a pretty neat
paper on the effective sample size and degrees of freedom in
longitudinal studies: see
http://www.citeulike.org/user/ctacmo/article/6129798. Highly
recommended; there aren't that many people who understand longitudinal
data as well as the Geert duo.

-- 
Stas Kolenikov, also found at http://stas.kolenikov.name
Small print: I use this email account for mailing lists only.

-------------------------- Multilevel list --------------------------
To leave, send    leave multilevel    to jiscmail at jiscmail.ac.uk
For further info about the Multilevel list, please see
http://www.jiscmail.ac.uk/lists/multilevel.html     and
http://www.nursing.teaching.man.ac.uk/staff/mcampbell/multilevel.html

-- 
Dave Atkins, PhD
Research Associate Professor
Center for the Study of Health and Risk Behaviors
Department of  Psychiatry and Behavioral Science
University of Washington
1100 NE 45th Street, Suite 300
Seattle, WA  98105
206-616-3879
datkins at u.washington.edu



From t.j.m.van.dooren at biology.leidenuniv.nl  Tue Nov 17 21:41:47 2009
From: t.j.m.van.dooren at biology.leidenuniv.nl (Tom Van Dooren)
Date: Tue, 17 Nov 2009 21:41:47 +0100
Subject: [R-sig-ME] test significance of single random effect
In-Reply-To: <40e66e0b0911170903y67f57699pb002bb9500826f2f@mail.gmail.com>
References: <4B01D445.2020606@biology.leidenuniv.nl>
	<4B01DF8E.1060100@ufl.edu>	 <4B0271B3.4000300@eva.mpg.de>
	<40e66e0b0911170903y67f57699pb002bb9500826f2f@mail.gmail.com>
Message-ID: <4B030A8B.206@biology.leidenuniv.nl>

With REML=FALSE RLRsim seems to work fine in R 2.10, if I use the design 
matrix and Zt as arguments in LRTSim().
Otherwise I didn't get useful results out.

That's not too much of a problem.
It is not difficult to simulate the null model without random effect, 
extract logLikelihoods from the (generalized) mixed model and the 
(generalized) linear model fitted to those pseudo-data, to calculate a 
distribution of likelihood ratios,
which are then maybe off by a constant.
What I was mainly uncertain about, is whether the log-likelihood of a 
mixed model (also fitted to data simulated from the null model without 
random effect),
can be used as a statistic itself?
The answer might be a simple NO! of course, or something more involved...

Tom


Douglas Bates wrote:
> On Tue, Nov 17, 2009 at 3:49 AM, Matthias Gralle
> <matthias_gralle at eva.mpg.de> wrote:
>   
>> I had basically the same problem a short time ago, and resorted to lme
>> instead of lmer, because one can directly compare lme and lm objects using
>> anova(). Is that OK, or is this feature of lme depreciated ?
>>     
>
> Is that not possible for linear mixed-effects models fit by lmer using
> REML = FALSE? (Occasionally I lose track of what can be done in
> different versions of lme4.)  You don't want to compare an lmer model
> fit by REML with the log-likelihood of an lm model but you should be
> able to compare likelihoods (subject to the caveat that the p-value
> for the likelihood ratio test on the boundary of the parameter space
> is conservative).
>
>   
>> Ben Bolker wrote:
>>     
>>>  Have you tried the RLRsim package??
>>>
>>> Tom Van Dooren wrote:
>>>
>>>       
>>>> I tried to find an easy way to test whether the random effect would be
>>>> significant in a (generalized) mixed model with a single random effect.
>>>> It annoyed me that log-likelihoods of lm or glm and lmer are not
>>>> necesarily directly comparable -> trouble with calculating likelihood
>>>> ratios.
>>>> What do members of this list think of the following simulation approach?
>>>> It basically amounts to simulating a distribution for the log likelihood,
>>>> given the null hypothesis that there is no random effect variance and that
>>>> the fixed effect model is correct.
>>>>
>>>>
>>>> library(lme4)
>>>> mm1 <- lmer(Reaction ~ Days + (1|Subject), sleepstudy)
>>>> lm1<- lm(Reaction ~ Days, sleepstudy)
>>>>
>>>>
>>>> LL<-numeric(500)
>>>> for(i in 1:500){
>>>> resp<-simulate(lm1)
>>>> LL[i]<-logLik(lmer(resp[,1] ~ Days + (1|Subject), sleepstudy))
>>>> }
>>>>
>>>> hist(LL)
>>>> logLik(mm1)
>>>> mean(LL>logLik(mm1))
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>>         
>>>
>>>       
>> --
>> Matthias Gralle, PhD
>> Dept. Evolutionary Genetics
>> Max Planck Institute for Evolutionary Anthropology
>> Deutscher Platz 6
>> 04103 Leipzig, Germany
>> Tel +49 341 3550 519
>> Fax +49 341 3550 555
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>



From pauljohn32 at gmail.com  Wed Nov 18 05:19:51 2009
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Tue, 17 Nov 2009 22:19:51 -0600
Subject: [R-sig-ME] poly() and rcs()?
In-Reply-To: <581a8bcf0911151220u2edeaa33s3e5efcdbaa7fc918@mail.gmail.com>
References: <581a8bcf0911151220u2edeaa33s3e5efcdbaa7fc918@mail.gmail.com>
Message-ID: <13e802630911172019q56c0414fi76b79271d38c3bb1@mail.gmail.com>

On Sun, Nov 15, 2009 at 2:20 PM, Antoine Tremblay <trea26 at gmail.com> wrote:
> Dear all,
>
> Here is a question regarding the difference between using poly() and rcs().
>
> If you fit a model using poly(), as shown below, the summary returns
> statistics for the term "linear" term,
> poly(TrialContinuous,2,raw=TRUE)1, and statistics for the quadratic,
> poly(TrialContinuous,2,raw=TRUE)2.
[snip]
> Now, if you use rcs() instead, the summary return statistics for the
> first and second splines, as shown below. We see that the 2 splines
> are significant, but there is no interaction between any of the
> splines and FreqGroup.

Dear Antoine:

I am not an expert, but I *think* you need to more carefully consider
what rcs does. If you are using rcs from the  Design package, that is:
  It is a restricted cubic spline.  It is not similar to poly looking
for a parametric curve across the whole range. Rather, it is dividing
up the range of X into pieces and then fitting a cubic curve to each
one. There is not supposed to be a "linear" term.

A couple of years ago, I decided to try to master some of that
terminology and I wrote up something for my class.  I'm pretty sure I
got the rcs part correct.

http://pj.freefaculty.org/stat/Splines/nonparametricModels.pdf

Look down to p. 17, where (I see now) I was curious about where the
linear term went, just like you are now.

Good luck

pj

> --
> Antoine Tremblay
> Department of Neuroscience
> Georgetown University
> Washington DC
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
Paul E. Johnson
Professor, Political Science
1541 Lilac Lane, Room 504
University of Kansas



From trea26 at gmail.com  Wed Nov 18 06:12:22 2009
From: trea26 at gmail.com (Antoine Tremblay)
Date: Wed, 18 Nov 2009 00:12:22 -0500
Subject: [R-sig-ME] poly() and rcs()?
In-Reply-To: <13e802630911172019q56c0414fi76b79271d38c3bb1@mail.gmail.com>
References: <581a8bcf0911151220u2edeaa33s3e5efcdbaa7fc918@mail.gmail.com>
	<13e802630911172019q56c0414fi76b79271d38c3bb1@mail.gmail.com>
Message-ID: <581a8bcf0911172112k57554e7fh6dbe8a9394b9605c@mail.gmail.com>

Dear Paul,
Thank you very much for the document, it is of great help :-)

I guess what I mean by the linear term is the b1xi in the equation yi
= ?b0 + ?b1 xi + ?b2 (xi ? ?1 )3 + ?b3 (xi ? ?2 )3  + + . . .

The summary output for lmer with rcs() only seems to give statistics
for the b(xi ? ?)3 s, but not for the b1xi term.

Thanks again for that document, it's great!

Antoine

On Tue, Nov 17, 2009 at 11:19 PM, Paul Johnson <pauljohn32 at gmail.com> wrote:
> On Sun, Nov 15, 2009 at 2:20 PM, Antoine Tremblay <trea26 at gmail.com> wrote:
>> Dear all,
>>
>> Here is a question regarding the difference between using poly() and rcs().
>>
>> If you fit a model using poly(), as shown below, the summary returns
>> statistics for the term "linear" term,
>> poly(TrialContinuous,2,raw=TRUE)1, and statistics for the quadratic,
>> poly(TrialContinuous,2,raw=TRUE)2.
> [snip]
>> Now, if you use rcs() instead, the summary return statistics for the
>> first and second splines, as shown below. We see that the 2 splines
>> are significant, but there is no interaction between any of the
>> splines and FreqGroup.
>
> Dear Antoine:
>
> I am not an expert, but I *think* you need to more carefully consider
> what rcs does. If you are using rcs from the ?Design package, that is:
> ?It is a restricted cubic spline. ?It is not similar to poly looking
> for a parametric curve across the whole range. Rather, it is dividing
> up the range of X into pieces and then fitting a cubic curve to each
> one. There is not supposed to be a "linear" term.
>
> A couple of years ago, I decided to try to master some of that
> terminology and I wrote up something for my class. ?I'm pretty sure I
> got the rcs part correct.
>
> http://pj.freefaculty.org/stat/Splines/nonparametricModels.pdf
>
> Look down to p. 17, where (I see now) I was curious about where the
> linear term went, just like you are now.
>
> Good luck
>
> pj
>
>> --
>> Antoine Tremblay
>> Department of Neuroscience
>> Georgetown University
>> Washington DC
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>
>
> --
> Paul E. Johnson
> Professor, Political Science
> 1541 Lilac Lane, Room 504
> University of Kansas
>



-- 
Antoine Tremblay
Department of Neuroscience
Georgetown University
Washington DC



From pauljohn32 at gmail.com  Wed Nov 18 06:25:07 2009
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Tue, 17 Nov 2009 23:25:07 -0600
Subject: [R-sig-ME] Linear Mixed-Effects Models (lme),
	question about 	parameter estimates and random effect
In-Reply-To: <742479270911082301m52c22450pc7ce082c32ced5a0@mail.gmail.com>
References: <742479270911082301m52c22450pc7ce082c32ced5a0@mail.gmail.com>
Message-ID: <13e802630911172125w6c8709cfud064603005fd6065@mail.gmail.com>

On Mon, Nov 9, 2009 at 1:01 AM, R.S. Cotter <cotter.rs at gmail.com> wrote:
> Hello,
>
> I have a question regarding Linear Mixed-Effects Models (lme). I have
> searched help forum, but find it difficult to find an answer on my question.
> Probaly there is an easy answer to this, but due to lack of knowledge I can
> not understand following :
>

I had to read this a few times before I got it. Maybe others struggle as well.

Can I try to re-state it?

The data matrix looks like this, where two outcome variables,
FeedingTime and FeedingWithPrep are the same for group a, but differ
for group b.

Diet        FeedingTime   FeedingWithPrep
a                 2                    2
a                 3                    3
a                  1                   1
b                 4                    5
b                 5                     7
b                 3                     4

You note that linear models fitted to these 2 outcome variables have
the same estimates for group a (the intercept and Gramm), which makes
sense because the group a data is unchanged. The estimates including b
are different.

But the mixed model, which includes a random effect for the place, is
different.  The estimates for group a are altered, even though the
dependent variable is the same in either case.

If that's the question, I think the answer is that the random place
effect "ranges across" both groups a and b, so it is only natural that
the estimates for both groups would be affected.  Place is apparently
not completely independent of diet in the realization of the sample,
so the intercept and the estimate for Gram are affected slightly.

But I'm not completely certain of that answer.  But I'm pretty sure
that's your question. :)
Maybe the folks who actually know the answer will speak up on this.

HTH
pj




> I look at whether there is a difference in the effect of weight (gram)
> between two diets ("a" and "b") on feeding time. Place is random effect (5
> different locations). I ran script 1a), so far so good. I get the intercept
> and slope for diet "a" and "b". But for diet "b" I also want to add extra
> time needed for preparing (only diet "b" needs preparing). Feeding time for
> diet "a" is the same, only feeding time for diet "b" increases. I ran script
> 1b), as expect intercept and slope for diet "b" changes, but why does
> intercept and slope for diet "a" change? The feeding time is equal for
> diet "a" in both script 1a) and 1b). Then I tried to see what happens when
> not control for random effect by using lm, and ran script 2a) and 2b). And
> now the intercept and slope for diet "a" is the same for both script
> (without and with preparing time for diet "b"). Could the difference be a
> result of how the random effect is being calculated for in lme? The
> difference is minimal, but I would like to understand why the intercept and
> slope for diet "a" changes?
>
> Sorry if my question is too simple.
>
> Regards Cotter
>
> 1a)
>> lmefit1<-lme(log10(FeedingTime) ~
> log10(Gram)*Diet,random=~1|Place,data=diet)
> 1b)
>> lmefit2<-lme(log10(FeedingtimeWithPrep) ~
> log10(Gram)*Diet,random=~1|Place,data=diet)
>> summary(lmefit1)
> Linear mixed-effects model fit by REML
> ?Data: diet
> ? ? ? ?AIC ? ? ? BIC ? logLik
> ?-24.12282 -19.12354 18.06141
> Random effects:
> ?Formula: ~1 | Place
> ? ? ? ?(Intercept) ? Residual
> StdDev: ? 0.0505571 0.07350342
> Fixed effects: log10(FeedingTime) ~ log10(Gram) * Diet
> ? ? ? ? ? ? ? ? ? ? ? Value Std.Error DF ? t-value p-value
> (Intercept) ? ? ? ?0.3111653 0.3737451 13 ?0.832560 ?0.4201
> log10(Gram) ? ? ? ?1.1664078 0.2735981 13 ?4.263216 ?0.0009
> Dietb ? ? ? ? ? ? ?1.1580016 0.5148035 13 ?2.249405 ?0.0425
> log10(Gram):Dietb -0.6904469 0.3321850 13 -2.078501 ?0.0580
> ?Correlation:
> ? ? ? ? ? ? ? ? ?(Intr) lg10(G) Dietb
> log10(Gram) ? ? ? -0.996
> Dietb ? ? ? ? ? ? -0.740 ?0.726
> log10(Gram):Dietb ?0.833 -0.826 ?-0.985
> Standardized Within-Group Residuals:
> ? ? ? Min ? ? ? ? Q1 ? ? ? ?Med ? ? ? ? Q3 ? ? ? ?Max
> -2.2608248 -0.3226060 -0.1256394 ?0.5658181 ?1.6808270
> Number of Observations: 21
> Number of Groups: 5
>
>> summary(lmefit2)
> Linear mixed-effects model fit by REML
> ?Data: diet
> ? ? ? ?AIC ? ? ? BIC ? logLik
> ?-29.98107 -24.98179 20.99054
> Random effects:
> ?Formula: ~1 | Place
> ? ? ? ?(Intercept) ? Residual
> StdDev: ?0.03568998 0.06341113
> Fixed effects: log10(FeedingtimeWithPrep) ~ log10(Gram) * Diet
> ? ? ? ? ? ? ? ? ? ? ? Value Std.Error DF ? t-value p-value
> (Intercept) ? ? ? ?0.3001162 0.3210428 13 ?0.934817 ?0.3669
> log10(Gram) ? ? ? ?1.1760924 0.2352253 13 ?4.999855 ?0.0002
> Dietb ? ? ? ? ? ? ?1.0937006 0.4302214 13 ?2.542181 ?0.0246
> log10(Gram):Dietb -0.5178826 0.2805392 13 -1.846026 ?0.0878
> ?Correlation:
> ? ? ? ? ? ? ? ? ?(Intr) lg10(G) Dietb
> log10(Gram) ? ? ? -0.996
> Dietb ? ? ? ? ? ? -0.757 ?0.746
> log10(Gram):Dietb ?0.845 -0.840 ?-0.986
> Standardized Within-Group Residuals:
> ? ? ? ?Min ? ? ? ? ?Q1 ? ? ? ? Med ? ? ? ? ?Q3 ? ? ? ? Max
> -2.94950911 -0.19998787 -0.11069540 ?0.09370866 ?1.65930147
> Number of Observations: 21
> Number of Groups: 5
>
>
> 2a)
>> lmfit1<-lm(log10(FeedingTime) ~ log10(Gram)*Diet,data=diet)
> 2b)
>> lmfit2<-lm(log10(FeedingtimeWithPrep) ~ log10(Gram)*Diet,data=diet)
>> summary(lmfit1)
> Call:
> lm(formula = log10(FeedingTime) ~ log10(Gram) * Diet, data = diet)
> Residuals:
> ? ? Min ? ? ? 1Q ? Median ? ? ? 3Q ? ? ?Max
> -0.23163 -0.03347 ?0.01312 ?0.05164 ?0.12056
> Coefficients:
> ? ? ? ? ? ? ? ? ?Estimate Std. Error t value Pr(>|t|)
> (Intercept) ? ? ? ? 0.2942 ? ? 0.4297 ? 0.685 ?0.50277
> log10(Gram) ? ? ? ? 1.1833 ? ? 0.3156 ? 3.750 ?0.00160 **
> Dietb ? ? ? ? ? ? ? 1.1472 ? ? 0.5302 ? 2.164 ?0.04501 *
> log10(Gram):Dietb ?-0.6922 ? ? 0.3578 ?-1.935 ?0.06983 .
> ---
> Signif. codes: ?0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> Residual standard error: 0.08699 on 17 degrees of freedom
> Multiple R-squared: 0.901, ? ? ?Adjusted R-squared: 0.8836
> F-statistic: 51.59 on 3 and 17 DF, ?p-value: 9.492e-09
> 2b)
>> summary(lmfit2)
> Call:
> lm(formula = log10(FeedingtimeWithPrep) ~ log10(Gram) * Diet,
> ? ?data = diet)
> Residuals:
> ? ? ? Min ? ? ? ? 1Q ? ? Median ? ? ? ? 3Q ? ? ? ?Max
> -0.2316266 -0.0003216 ?0.0001792 ?0.0058846 ?0.1205559
> Coefficients:
> ? ? ? ? ? ? ? ? ?Estimate Std. Error t value Pr(>|t|)
> (Intercept) ? ? ? ? 0.2942 ? ? 0.3512 ? 0.838 0.413840
> log10(Gram) ? ? ? ? 1.1833 ? ? 0.2579 ? 4.588 0.000262 ***
> Dietb ? ? ? ? ? ? ? 1.0359 ? ? 0.4333 ? 2.391 0.028665 *
> log10(Gram):Dietb ?-0.4902 ? ? 0.2924 ?-1.676 0.112005
> ---
> Signif. codes: ?0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> Residual standard error: 0.0711 on 17 degrees of freedom
> Multiple R-squared: 0.9698, ? ? Adjusted R-squared: 0.9645
> F-statistic: ? 182 on 3 and 17 DF, ?p-value: 4.069e-13
>
> ? ? ? ?[[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
Paul E. Johnson
Professor, Political Science
1541 Lilac Lane, Room 504
University of Kansas



From Fabian.Scheipl at stat.uni-muenchen.de  Wed Nov 18 10:02:23 2009
From: Fabian.Scheipl at stat.uni-muenchen.de (Fabian Scheipl)
Date: Wed, 18 Nov 2009 10:02:23 +0100
Subject: [R-sig-ME] test significance of single random effect
Message-ID: <4836bc6a0911180102t33d0ade9w8ecf7c16cedc058a@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20091118/3b876d1f/attachment.pl>

From aalisiyan at gmail.com  Wed Nov 18 15:57:21 2009
From: aalisiyan at gmail.com (alis villiyam)
Date: Wed, 18 Nov 2009 15:57:21 +0100
Subject: [R-sig-ME] help in R
Message-ID: <509507040911180657g93fc1d6l42d15acaeaaa8cf4@mail.gmail.com>

Dear All ,

I measured COD  in two depths for 8 weeks.

I have D and V and C0 , but i want to find mu in R program.

C0 = 300 and 200 and 100 and 0.

Could you please help me if you have time.

kind regards,

Alie

From lborger at uoguelph.ca  Wed Nov 18 16:06:39 2009
From: lborger at uoguelph.ca (Luca Borger)
Date: Wed, 18 Nov 2009 10:06:39 -0500 (EST)
Subject: [R-sig-ME] help in R
In-Reply-To: <509507040911180657g93fc1d6l42d15acaeaaa8cf4@mail.gmail.com>
Message-ID: <568068510.25170581258556799190.JavaMail.root@huron.cs.uoguelph.ca>

Hello,

probably a good place to start with ;-)p

http://www.r-project.org/posting-guide.html



Cheers,

Luca


----- Original Message -----
From: "alis villiyam" <aalisiyan at gmail.com>
To: r-sig-mixed-models at r-project.org, r-sig-mixed-models-owner at r-project.org
Sent: Wednesday, 18 November, 2009 09:57:21 GMT -05:00 US/Canada Eastern
Subject: [R-sig-ME] help in R

Dear All ,

I measured COD  in two depths for 8 weeks.

I have D and V and C0 , but i want to find mu in R program.

C0 = 300 and 200 and 100 and 0.

Could you please help me if you have time.

kind regards,

Alie

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From brendan.halpin at ul.ie  Wed Nov 18 18:54:31 2009
From: brendan.halpin at ul.ie (Brendan Halpin)
Date: Wed, 18 Nov 2009 17:54:31 +0000
Subject: [R-sig-ME] Interpretation of odd error variances in glmer
Message-ID: <87iqd7qtvy.fsf@wivenhoe.ul.ie>

I'm trying to fit a cross-classified multi-level logistic regression
using glmer and am getting exactly zero variance on one of the grouping
levels. I have observations on grades, nested within class within
department on the one hand, and within student on the other.

Here is an example:

     Generalized linear mixed model fit by the Laplace approximation 
     Formula: gradeA ~ 1 + cao + subj1 + subj2 + subj3 + as.factor(stu_gend)
      + ageentry + as.factor(yrs5) + as.factor(year) + modsize + meancao +
        depfemr + (1 | deptno) + (1 | modinst) + (1 | id)
     
         AIC    BIC logLik deviance
      155671 155901 -77813   155627
     Random effects:
      Groups  Name        Variance Std.Dev.
      id      (Intercept) 1.9624   1.4009  
      modinst (Intercept) 1.6783   1.2955  
      deptno  (Intercept) 0.0000   0.0000  
     Number of obs: 264059, groups: id, 11656; modinst, 6420; deptno, 26

If I change the outcome variable, I get non-zero variance.

How do I interpret this? Is it a model estimation problem?


Regards,

Brendan
-- 
Brendan Halpin,  Department of Sociology,  University of Limerick,  Ireland
Tel: w +353-61-213147 f +353-61-202569 h +353-61-338562; Room F2-025 x 3147
mailto:brendan.halpin at ul.ie  http://www.ul.ie/sociology/brendan.halpin.html



From bates at stat.wisc.edu  Thu Nov 19 04:24:35 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 18 Nov 2009 21:24:35 -0600
Subject: [R-sig-ME] Interpretation of odd error variances in glmer
In-Reply-To: <87iqd7qtvy.fsf@wivenhoe.ul.ie>
References: <87iqd7qtvy.fsf@wivenhoe.ul.ie>
Message-ID: <40e66e0b0911181924p7803e316j6dcf752cb75e79ad@mail.gmail.com>

On Wed, Nov 18, 2009 at 11:54 AM, Brendan Halpin <brendan.halpin at ul.ie> wrote:
> I'm trying to fit a cross-classified multi-level logistic regression
> using glmer and am getting exactly zero variance on one of the grouping
> levels. I have observations on grades, nested within class within
> department on the one hand, and within student on the other.
>
> Here is an example:
>
> ? ? Generalized linear mixed model fit by the Laplace approximation
> ? ? Formula: gradeA ~ 1 + cao + subj1 + subj2 + subj3 + as.factor(stu_gend)
> ? ? ?+ ageentry + as.factor(yrs5) + as.factor(year) + modsize + meancao +
> ? ? ? ?depfemr + (1 | deptno) + (1 | modinst) + (1 | id)
>
> ? ? ? ? AIC ? ?BIC logLik deviance
> ? ? ?155671 155901 -77813 ? 155627
> ? ? Random effects:
> ? ? ?Groups ?Name ? ? ? ?Variance Std.Dev.
> ? ? ?id ? ? ?(Intercept) 1.9624 ? 1.4009
> ? ? ?modinst (Intercept) 1.6783 ? 1.2955
> ? ? ?deptno ?(Intercept) 0.0000 ? 0.0000
> ? ? Number of obs: 264059, groups: id, 11656; modinst, 6420; deptno, 26
>
> If I change the outcome variable, I get non-zero variance.
>
> How do I interpret this? Is it a model estimation problem?

It is quite legitimate for the ML estimates of a variance component to
be zero.  It simply means that there is not enough variability
accounted for by that term to warrant incorporating the term.

For another outcome variable there may be enough variation that can be
attributed to this factor.



From wayne.dawson at ips.unibe.ch  Thu Nov 19 14:20:27 2009
From: wayne.dawson at ips.unibe.ch (Dawson Wayne)
Date: Thu, 19 Nov 2009 14:20:27 +0100
Subject: [R-sig-ME] Convergence diagnostics for MCMCglmm
Message-ID: <20091119142027.194855m4qmgl9hjv@mail.unibe.ch>

Dear R users,

I've managed to get to grips with using MCMCglmm for phylogenetic  
meta-analysis, thanks to help on here from Jarrod Hadfield. However, I  
haven't yet worked out how to use convergence diagnostics on MCMCglmm  
output.

I am currently running models for 50,000 iterations, with a long  
burnin of 25000, and a thinning interval of 10. Whilst my trace plots  
look good, I would like to use the Gelman-Rubin or Raftery-Lewis  
diagnostics in the coda package to check that my burnin/no. of  
iterations are adequate. I've read relevant sections in Ch. 7 of Ben  
Bolkers ecological models book, and the coda/MCMCglmm package pdfs,  
but I'm still not sure what mcmc output from MCMCglmm I am supposed to  
pass to the coda diagnostic functions. Apologies for the simple  
question, but hopefully there is a simple answer!

Any suggestions appreciated as always,

Thanks,

Wayne

-- 
Dr. Wayne Dawson
Institute of Plant Sciences
University of Bern
Altenbergrain 21
3013 Bern
Switzerland
+41 (0)31 631 49 25



From j.hadfield at ed.ac.uk  Thu Nov 19 14:36:42 2009
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Thu, 19 Nov 2009 13:36:42 +0000
Subject: [R-sig-ME] Convergence diagnostics for MCMCglmm
In-Reply-To: <20091119142027.194855m4qmgl9hjv@mail.unibe.ch>
References: <20091119142027.194855m4qmgl9hjv@mail.unibe.ch>
Message-ID: <C6B558AE-70B8-4066-B014-48F9542BD6AF@ed.ac.uk>

Hi Wayne,

You should pass the mcmc objects from >2 models as a list. For  
example, the fixed effects:

diag.gelman(mcmc.list(m1$Sol, m2$Sol))

Ideally the models should have over-dispersed starting values, which  
you can specify in the start argument. This will stop MCMCglmm finding  
"heuristically" good starting values.

If you have access to ASReml you could always fit the model using REML  
and check to see whether the estimates are the same/similar.

Cheers,

Jarrod


On 19 Nov 2009, at 13:20, Dawson Wayne wrote:

> Dear R users,
>
> I've managed to get to grips with using MCMCglmm for phylogenetic  
> meta-analysis, thanks to help on here from Jarrod Hadfield. However,  
> I haven't yet worked out how to use convergence diagnostics on  
> MCMCglmm output.
>
> I am currently running models for 50,000 iterations, with a long  
> burnin of 25000, and a thinning interval of 10. Whilst my trace  
> plots look good, I would like to use the Gelman-Rubin or Raftery- 
> Lewis diagnostics in the coda package to check that my burnin/no. of  
> iterations are adequate. I've read relevant sections in Ch. 7 of Ben  
> Bolkers ecological models book, and the coda/MCMCglmm package pdfs,  
> but I'm still not sure what mcmc output from MCMCglmm I am supposed  
> to pass to the coda diagnostic functions. Apologies for the simple  
> question, but hopefully there is a simple answer!
>
> Any suggestions appreciated as always,
>
> Thanks,
>
> Wayne
>
> -- 
> Dr. Wayne Dawson
> Institute of Plant Sciences
> University of Bern
> Altenbergrain 21
> 3013 Bern
> Switzerland
> +41 (0)31 631 49 25
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From bolker at ufl.edu  Thu Nov 19 14:37:57 2009
From: bolker at ufl.edu (Ben Bolker)
Date: Thu, 19 Nov 2009 08:37:57 -0500
Subject: [R-sig-ME] Convergence diagnostics for MCMCglmm
In-Reply-To: <20091119142027.194855m4qmgl9hjv@mail.unibe.ch>
References: <20091119142027.194855m4qmgl9hjv@mail.unibe.ch>
Message-ID: <4B054A35.6010801@ufl.edu>

  library(MCMCglmm)
  example(MCMCglmm)
  ## what do the results look like?
  class(model1) ## oh, it's a list?
  str(model1)   ##  first element has class
                ## "mcmc" -- that's good ...
  library(coda)
  raftery.diag(model1$Sol)
  xyplot(model1$Sol)

  I'm too lazy to look through the vignette at the moment but at least
this model is not multi-chain, so no Gelman-Rubin ...

  geweke.diag(model1$Sol) ##
  geweke.plot(model1$Sol)

Dawson Wayne wrote:
> Dear R users,
> 
> I've managed to get to grips with using MCMCglmm for phylogenetic  
> meta-analysis, thanks to help on here from Jarrod Hadfield. However, I  
> haven't yet worked out how to use convergence diagnostics on MCMCglmm  
> output.
> 
> I am currently running models for 50,000 iterations, with a long  
> burnin of 25000, and a thinning interval of 10. Whilst my trace plots  
> look good, I would like to use the Gelman-Rubin or Raftery-Lewis  
> diagnostics in the coda package to check that my burnin/no. of  
> iterations are adequate. I've read relevant sections in Ch. 7 of Ben  
> Bolkers ecological models book, and the coda/MCMCglmm package pdfs,  
> but I'm still not sure what mcmc output from MCMCglmm I am supposed to  
> pass to the coda diagnostic functions. Apologies for the simple  
> question, but hopefully there is a simple answer!
> 
> Any suggestions appreciated as always,
> 
> Thanks,
> 
> Wayne
> 


-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / www.zoology.ufl.edu/bolker
GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc



From wayne.dawson at ips.unibe.ch  Thu Nov 19 14:57:45 2009
From: wayne.dawson at ips.unibe.ch (Dawson Wayne)
Date: Thu, 19 Nov 2009 14:57:45 +0100
Subject: [R-sig-ME] Convergence diagnostics for MCMCglmm
In-Reply-To: <C6B558AE-70B8-4066-B014-48F9542BD6AF@ed.ac.uk>
References: <20091119142027.194855m4qmgl9hjv@mail.unibe.ch>
	<C6B558AE-70B8-4066-B014-48F9542BD6AF@ed.ac.uk>
Message-ID: <20091119145745.10111ihr9nf8a5ll@mail.unibe.ch>

That's great, thought the lists to use might have been $Sol, but hey,  
that just seemed too simple!

Thanks Jarrod and Ben.

Wayne

Quoting Jarrod Hadfield <j.hadfield at ed.ac.uk>:

> Hi Wayne,
>
> You should pass the mcmc objects from >2 models as a list. For  
> example, the fixed effects:
>
> diag.gelman(mcmc.list(m1$Sol, m2$Sol))
>
> Ideally the models should have over-dispersed starting values, which  
> you can specify in the start argument. This will stop MCMCglmm  
> finding "heuristically" good starting values.
>
> If you have access to ASReml you could always fit the model using  
> REML and check to see whether the estimates are the same/similar.
>
> Cheers,
>
> Jarrod
>
>
> On 19 Nov 2009, at 13:20, Dawson Wayne wrote:
>
>> Dear R users,
>>
>> I've managed to get to grips with using MCMCglmm for phylogenetic  
>> meta-analysis, thanks to help on here from Jarrod Hadfield.  
>> However, I haven't yet worked out how to use convergence  
>> diagnostics on MCMCglmm output.
>>
>> I am currently running models for 50,000 iterations, with a long  
>> burnin of 25000, and a thinning interval of 10. Whilst my trace  
>> plots look good, I would like to use the Gelman-Rubin or  
>> Raftery-Lewis diagnostics in the coda package to check that my  
>> burnin/no. of iterations are adequate. I've read relevant sections  
>> in Ch. 7 of Ben Bolkers ecological models book, and the  
>> coda/MCMCglmm package pdfs, but I'm still not sure what mcmc output  
>> from MCMCglmm I am supposed to pass to the coda diagnostic  
>> functions. Apologies for the simple question, but hopefully there  
>> is a simple answer!
>>
>> Any suggestions appreciated as always,
>>
>> Thanks,
>>
>> Wayne
>>
>> -- 
>> Dr. Wayne Dawson
>> Institute of Plant Sciences
>> University of Bern
>> Altenbergrain 21
>> 3013 Bern
>> Switzerland
>> +41 (0)31 631 49 25
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>
> -- 
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
>
>



-- 
Dr. Wayne Dawson
Institute of Plant Sciences
University of Bern
Altenbergrain 21
3013 Bern
Switzerland
+41 (0)31 631 49 25



From brendan.halpin at ul.ie  Thu Nov 19 15:24:04 2009
From: brendan.halpin at ul.ie (Brendan Halpin)
Date: Thu, 19 Nov 2009 14:24:04 +0000
Subject: [R-sig-ME] Interpretation of odd error variances in glmer
In-Reply-To: <40e66e0b0911181924p7803e316j6dcf752cb75e79ad@mail.gmail.com>
	(Douglas Bates's message of "Wed, 18 Nov 2009 21:24:35 -0600")
References: <87iqd7qtvy.fsf@wivenhoe.ul.ie>
	<40e66e0b0911181924p7803e316j6dcf752cb75e79ad@mail.gmail.com>
Message-ID: <87pr7ezj7f.fsf@wivenhoe.ul.ie>


On Thu, Nov 19 2009, Douglas Bates wrote:

> It is quite legitimate for the ML estimates of a variance component to
> be zero.  It simply means that there is not enough variability
> accounted for by that term to warrant incorporating the term.

Thanks for the swift response.

Given that the estimate seems to be exactly zero, can I read your answer
to say that the term has somehow been dropped by the algorithm?


I've investigated a bit more and find that the zero variance seems to
occur with the combination of the inclusion of a department-level
covariate (depfemr), and the cross-classifying individual-level random
effect (ulid):


Cross-classified model without dept-level covariate: 

    Generalized linear mixed model fit by the Laplace approximation 
    Formula: gradeA ~ 1 + cao + gender * yr0 + modsize + (1 | deptno) + (1 | modinst) + (1 | ulid) 
       AIC   BIC logLik deviance
     13379 13457  -6681    13361
    Random effects:
     Groups  Name        Variance Std.Dev.
     modinst (Intercept) 1.55918  1.24867 
     ulid    (Intercept) 2.23646  1.49548 
     deptno  (Intercept) 0.37642  0.61353 
    Number of obs: 43955, groups: modinst, 9686; ulid, 1850; deptno, 28
    
    
Cross-classified model with dept-level covariate added:

    Generalized linear mixed model fit by the Laplace approximation 
    Formula: gradeA ~ 1 + cao + gender * yr0 + modsize + depfemr + (1 | deptno) + (1 | modinst) + (1 | ulid) 
       AIC   BIC logLik deviance
     13301 13388  -6640    13281
    Random effects:
     Groups  Name        Variance Std.Dev.
     modinst (Intercept) 3.7718   1.9421  
     ulid    (Intercept) 2.4429   1.5630  
     deptno  (Intercept) 0.0000   0.0000  
    Number of obs: 43955, groups: modinst, 9686; ulid, 1850; deptno, 28


Brendan
-- 
Brendan Halpin,  Department of Sociology,  University of Limerick,  Ireland
Tel: w +353-61-213147 f +353-61-202569 h +353-61-338562; Room F2-025 x 3147
mailto:brendan.halpin at ul.ie  http://www.ul.ie/sociology/brendan.halpin.html



From danielezrajohnson at gmail.com  Thu Nov 19 15:30:07 2009
From: danielezrajohnson at gmail.com (Daniel Ezra Johnson)
Date: Thu, 19 Nov 2009 09:30:07 -0500
Subject: [R-sig-ME] Interpretation of odd error variances in glmer
In-Reply-To: <87pr7ezj7f.fsf@wivenhoe.ul.ie>
References: <87iqd7qtvy.fsf@wivenhoe.ul.ie>
	<40e66e0b0911181924p7803e316j6dcf752cb75e79ad@mail.gmail.com>
	<87pr7ezj7f.fsf@wivenhoe.ul.ie>
Message-ID: <a46630750911190630y7d270f7ds7b3dfabfbb432874@mail.gmail.com>

On Thu, Nov 19, 2009 at 9:24 AM, Brendan Halpin <brendan.halpin at ul.ie> wrote:
>
> On Thu, Nov 19 2009, Douglas Bates wrote:
>
>> It is quite legitimate for the ML estimates of a variance component to
>> be zero. ?It simply means that there is not enough variability
>> accounted for by that term to warrant incorporating the term.
>
> Thanks for the swift response.
>
> Given that the estimate seems to be exactly zero, can I read your answer
> to say that the term has somehow been dropped by the algorithm?

For all intents and purposes, yes.

>
>
> I've investigated a bit more and find that the zero variance seems to
> occur with the combination of the inclusion of a department-level
> covariate (depfemr), and the cross-classifying individual-level random
> effect (ulid).

I wasn't quite sure of the structure of the data here, but it raised a
question for me. I understand that when a random effect is fully
nested within a fixed effect, the penalty on the random effect
resolves the singularity and allows estimation of both. (That is, if
appropriate, you could model depfemr as a fixed effect?)

But if/when two random effects are fully nested, as is frequently
modeled and I think is the case here, how does the algorithm know how
to assign the variance as between e.g. depfemr and ulid?

Dan



From bolker at ufl.edu  Thu Nov 19 15:56:47 2009
From: bolker at ufl.edu (Ben Bolker)
Date: Thu, 19 Nov 2009 09:56:47 -0500
Subject: [R-sig-ME] Convergence diagnostics for MCMCglmm
In-Reply-To: <C6B558AE-70B8-4066-B014-48F9542BD6AF@ed.ac.uk>
References: <20091119142027.194855m4qmgl9hjv@mail.unibe.ch>
	<C6B558AE-70B8-4066-B014-48F9542BD6AF@ed.ac.uk>
Message-ID: <4B055CAF.1050808@ufl.edu>

Jarrod Hadfield wrote:
> Hi Wayne,
> 
> You should pass the mcmc objects from >2 models as a list. For  
> example, the fixed effects:
> 
> diag.gelman(mcmc.list(m1$Sol, m2$Sol))

  PS I think that's gelman.diag()



From bates at stat.wisc.edu  Thu Nov 19 16:03:54 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 19 Nov 2009 09:03:54 -0600
Subject: [R-sig-ME] Interpretation of odd error variances in glmer
In-Reply-To: <a46630750911190630y7d270f7ds7b3dfabfbb432874@mail.gmail.com>
References: <87iqd7qtvy.fsf@wivenhoe.ul.ie>
	<40e66e0b0911181924p7803e316j6dcf752cb75e79ad@mail.gmail.com>
	<87pr7ezj7f.fsf@wivenhoe.ul.ie>
	<a46630750911190630y7d270f7ds7b3dfabfbb432874@mail.gmail.com>
Message-ID: <40e66e0b0911190703x37f6c0c7x7cd9d99942941762@mail.gmail.com>

On Thu, Nov 19, 2009 at 8:30 AM, Daniel Ezra Johnson
<danielezrajohnson at gmail.com> wrote:
> On Thu, Nov 19, 2009 at 9:24 AM, Brendan Halpin <brendan.halpin at ul.ie> wrote:
>>
>> On Thu, Nov 19 2009, Douglas Bates wrote:
>>
>>> It is quite legitimate for the ML estimates of a variance component to
>>> be zero. ?It simply means that there is not enough variability
>>> accounted for by that term to warrant incorporating the term.
>>
>> Thanks for the swift response.
>>
>> Given that the estimate seems to be exactly zero, can I read your answer
>> to say that the term has somehow been dropped by the algorithm?
>
> For all intents and purposes, yes.

Indeed.  Saying that "the term has somehow been dropped by the
algorithm" implies that the model structure has been altered for a
special case.  That is not quite what is going on here.  The
likelihood is being maximized with respect to parameters that
correspond to the standard deviations of the random effects, which
must be greater than or equal to zero, and the fixed-effects
parameters.  This is a constrained optimization problem and in this
case convergence is on the boundary of the parameter region.

The likelihood for such models can be considered as balancing fidelity
to the data versus complexity of the model.  The simplest model is the
one that eliminates the random effects by setting all the standard
deviations to zero.  Generally the quality of the fit from such a
model is much worse than for models that allow non-zero standard
deviations.  In this case the improvement in the quality of the fit by
allowing a non-zero standard deviation for the random effect for this
term is not sufficient to overcome the increase in model complexity,
as measure by the likelihood.

On a technical note, it took me a very long time to come up with a
formulation of the linear mixed-effects and generalized linear
mixed-effects model that allows for evaluation of the likelihood so
that these parameters go to zero smoothly.  Evaluation of the
log-likelihood for such models is almost universally described in
terms of the inverse of the variance-covariance matrix for the random
effects and that causes problems when you get zeros on the diagonal.
It is also a tricky part of trying to do Markov chain Monte Carlo
methods or similar calculations.  I haven't examined Jarrod's code for
MCMCglmm to see how that situation is handled there but I know that I
found it very difficult to work around zero or near-zero standard
deviations.

>> I've investigated a bit more and find that the zero variance seems to
>> occur with the combination of the inclusion of a department-level
>> covariate (depfemr), and the cross-classifying individual-level random
>> effect (ulid).

Understandable.  If the explanatory power of these random effects can
be expressed, at least partially, by other terms then the advantages
of having the random effects in the model are diminished and the
balance tips in favor of the model without these effects.

> I wasn't quite sure of the structure of the data here, but it raised a
> question for me. I understand that when a random effect is fully
> nested within a fixed effect, the penalty on the random effect
> resolves the singularity and allows estimation of both. (That is, if
> appropriate, you could model depfemr as a fixed effect?)
>
> But if/when two random effects are fully nested, as is frequently
> modeled and I think is the case here, how does the algorithm know how
> to assign the variance as between e.g. depfemr and ulid?
>
> Dan
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From Paul.Prew at ecolab.com  Thu Nov 19 18:56:27 2009
From: Paul.Prew at ecolab.com (Prew, Paul)
Date: Thu, 19 Nov 2009 11:56:27 -0600
Subject: [R-sig-ME] Penalty = shrinkage = ?
Message-ID: <6B810AFB14C606439FD57E5985E037910459D780@useagan1500p.GLOBAL.ECOLAB.CORP>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20091119/85af6c2f/attachment.pl>

From bates at stat.wisc.edu  Thu Nov 19 19:09:46 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 19 Nov 2009 12:09:46 -0600
Subject: [R-sig-ME] Penalty = shrinkage = ?
In-Reply-To: <6B810AFB14C606439FD57E5985E037910459D780@useagan1500p.GLOBAL.ECOLAB.CORP>
References: <6B810AFB14C606439FD57E5985E037910459D780@useagan1500p.GLOBAL.ECOLAB.CORP>
Message-ID: <40e66e0b0911191009q4060e4b3l98415aec89243120@mail.gmail.com>

On Thu, Nov 19, 2009 at 11:56 AM, Prew, Paul <Paul.Prew at ecolab.com> wrote:
> I found the comment below interesting in one of yesterday's threads, as I am currently analyzing a data set with a random effect fully nested within a fixed factor. ?Could anyone elaborate on what is meant by "penalty on the random effect"? Is this also what is deemed "shrinkage"? ?How does it work? ?Thanks, Paul

Look at slide 25 in
http://lme4.r-forge.r-project.org/slides/2009-07-21-Seewiesen/5LongitudinalD.pdf

In this slide the parameter estimates that you would have gotten by
fitting each subject's data separately are compared with the estimates
from a mixed-effects model with random effects for slope and
intercept.  The effective slope and intercept for each subject is
shrunk toward the population-wide estimate compared to the
within-subject estimate.  John Tukey referred to this as "borrowing
strength" from the population.

The extent of the shrinkage is controlled by the variance-covariance
matrix of the random effects.  A large variance results in parameter
estimates that are close to the within-subject estimates.  In terms of
the discussion on fidelity to the data versus model complexity in
another thread, such a model has high complexity and high fidelity.
The opposite case, very low variance for the random effects provides a
low complexity model but with correspondingly low fidelity to the
data.

Slide 26 in that presentation shows that the subjects whose data is
rather noisy, and hence whose within-subject parameter estimates are
poorly determined (330 or 331), have their coefficients "shrunk" more
than those whose data determines the within-subject estimates very
well (309 or 349).

> "I understand that when a random effect is fully
> nested within a fixed effect, the penalty on the random effect
> resolves the singularity and allows estimation of both. (That is, if
> appropriate, you could model depfemr as a fixed effect?)"
>
>
>
> Paul Prew ? ? ?Statistician
> 651-795-5942 ? ? ? fax 651-204-7504
> Ecolab Research Center ? ? ?Mail Stop ESC-F4412-A
> 655 Lone Oak Drive ? ? ? Eagan, MN 55121-1560
>
>
>
> CONFIDENTIALITY NOTICE:
> This e-mail communication and any attachments may contain proprietary and privileged information for the use of the designated recipients named above.
> Any unauthorized review, use, disclosure or distribution is prohibited.
> If you are not the intended recipient, please contact the sender by reply e-mail and destroy all copies of the original message.
>
>
> ? ? ? ?[[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



From Paul.Prew at ecolab.com  Thu Nov 19 21:37:05 2009
From: Paul.Prew at ecolab.com (Prew, Paul)
Date: Thu, 19 Nov 2009 14:37:05 -0600
Subject: [R-sig-ME] Penalty = shrinkage = ?
In-Reply-To: <40e66e0b0911191009q4060e4b3l98415aec89243120@mail.gmail.com>
References: <6B810AFB14C606439FD57E5985E037910459D780@useagan1500p.GLOBAL.ECOLAB.CORP>
	<40e66e0b0911191009q4060e4b3l98415aec89243120@mail.gmail.com>
Message-ID: <6B810AFB14C606439FD57E5985E037910459D95B@useagan1500p.GLOBAL.ECOLAB.CORP>


Douglas,  thank you for the explanation and the slides.  I understand the mixed modeling approach better now, or think I do.  Shrinkage seems analogous to weighted least squares (a method that's commonly taught and rarely if ever used, from what I've seen).  Regards, Paul


Paul Prew  |  Statistician
651-795-5942?? |?? fax 651-204-7504 
Ecolab Research Center  | Mail Stop ESC-F4412-A 
655 Lone Oak Drive  |  Eagan, MN 55121-1560 


-----Original Message-----
From: dmbates at gmail.com [mailto:dmbates at gmail.com] On Behalf Of Douglas Bates
Sent: Thursday, November 19, 2009 12:10 PM
To: Prew, Paul
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Penalty = shrinkage = ?

On Thu, Nov 19, 2009 at 11:56 AM, Prew, Paul <Paul.Prew at ecolab.com> wrote:
> I found the comment below interesting in one of yesterday's threads, 
> as I am currently analyzing a data set with a random effect fully 
> nested within a fixed factor. ?Could anyone elaborate on what is meant 
> by "penalty on the random effect"? Is this also what is deemed 
> "shrinkage"? ?How does it work? ?Thanks, Paul

Look at slide 25 in
http://lme4.r-forge.r-project.org/slides/2009-07-21-Seewiesen/5LongitudinalD.pdf

In this slide the parameter estimates that you would have gotten by fitting each subject's data separately are compared with the estimates from a mixed-effects model with random effects for slope and intercept.  The effective slope and intercept for each subject is shrunk toward the population-wide estimate compared to the within-subject estimate.  John Tukey referred to this as "borrowing strength" from the population.

The extent of the shrinkage is controlled by the variance-covariance matrix of the random effects.  A large variance results in parameter estimates that are close to the within-subject estimates.  In terms of the discussion on fidelity to the data versus model complexity in another thread, such a model has high complexity and high fidelity.
The opposite case, very low variance for the random effects provides a low complexity model but with correspondingly low fidelity to the data.

Slide 26 in that presentation shows that the subjects whose data is rather noisy, and hence whose within-subject parameter estimates are poorly determined (330 or 331), have their coefficients "shrunk" more than those whose data determines the within-subject estimates very well (309 or 349).

> "I understand that when a random effect is fully nested within a fixed 
> effect, the penalty on the random effect resolves the singularity and 
> allows estimation of both. (That is, if appropriate, you could model 
> depfemr as a fixed effect?)"
>
>
>
> Paul Prew ? ? ?Statistician
> 651-795-5942 ? ? ? fax 651-204-7504
> Ecolab Research Center ? ? ?Mail Stop ESC-F4412-A
> 655 Lone Oak Drive ? ? ? Eagan, MN 55121-1560
>
>
>
> CONFIDENTIALITY NOTICE:
> This e-mail communication and any attachments may contain proprietary and privileged information for the use of the designated recipients named above.
> Any unauthorized review, use, disclosure or distribution is prohibited.
> If you are not the intended recipient, please contact the sender by reply e-mail and destroy all copies of the original message.
>
>
> ? ? ? ?[[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>

CONFIDENTIALITY NOTICE: 
This e-mail communication and any attachments may contain proprietary and privileged information for the use of the designated recipients named above. 
Any unauthorized review, use, disclosure or distribution is prohibited. 
If you are not the intended recipient, please contact the sender by reply e-mail and destroy all copies of the original message.


From evap120 at gmail.com  Fri Nov 20 02:48:49 2009
From: evap120 at gmail.com (eva petkova)
Date: Thu, 19 Nov 2009 20:48:49 -0500
Subject: [R-sig-ME] estimating contrasts and their standard errors from
	mixed effects models in lme4
Message-ID: <754b10c00911191748j5590441eofa422484f16e6c8b@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20091119/81a1405f/attachment.pl>

From john.maindonald at anu.edu.au  Fri Nov 20 03:17:28 2009
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Fri, 20 Nov 2009 13:17:28 +1100
Subject: [R-sig-ME] [Fwd: effective sample size]
In-Reply-To: <4B02CAFE.5050607@u.washington.edu>
References: <4B02CAFE.5050607@u.washington.edu>
Message-ID: <A4253750-1062-460E-AF1C-64094E8E6A63@anu.edu.au>

That is a neat paper.  The formula that is used for calculating
effective sample size is remarkably simple, an obvious thing
to try once one has seen it.  It seems to me likely that, by taking
better account of off-diagonal elements in the variance-covariance
matrix, it should be possible to improve on their formula.

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.
http://www.maths.anu.edu.au/~johnm

On 18/11/2009, at 3:10 AM, David Atkins wrote:

>
> This was just posted to the multilevel listserv, and I have taken a  
> very quick glance.  It appears to offer an alternative form for  
> estimating degrees of freedom.  It's focused on longitudinal data,  
> and I have not looked closely enough to see whether it would be more  
> generally applicable to mixed-models (multilevel, nested, crossed,  
> etc.) or whether it would "scale up" for larger problems.
>
> Given all the hoo-hah around dfs, thought I would at least kick it  
> out to the group.
>
> cheers, Dave
>
> -------- Original Message --------
> Subject: effective sample size
> Date: Tue, 17 Nov 2009 09:12:47 -0600
> From: Stas Kolenikov <skolenik at GMAIL.COM>
> Reply-To: Multilevel modelling discussion list <MULTILEVEL at JISCMAIL.AC.UK 
> >
> To: MULTILEVEL at JISCMAIL.AC.UK
>
> The recent issue of The American Statistician contains a pretty neat
> paper on the effective sample size and degrees of freedom in
> longitudinal studies: see
> http://www.citeulike.org/user/ctacmo/article/6129798. Highly
> recommended; there aren't that many people who understand longitudinal
> data as well as the Geert duo.
>
> -- 
> Stas Kolenikov, also found at http://stas.kolenikov.name
> Small print: I use this email account for mailing lists only.
>
> -------------------------- Multilevel list --------------------------
> To leave, send    leave multilevel    to jiscmail at jiscmail.ac.uk
> For further info about the Multilevel list, please see
> http://www.jiscmail.ac.uk/lists/multilevel.html     and
> http://www.nursing.teaching.man.ac.uk/staff/mcampbell/multilevel.html
>
> -- 
> Dave Atkins, PhD
> Research Associate Professor
> Center for the Study of Health and Risk Behaviors
> Department of  Psychiatry and Behavioral Science
> University of Washington
> 1100 NE 45th Street, Suite 300
> Seattle, WA  98105
> 206-616-3879
> datkins at u.washington.edu
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From adik at ilovebacon.org  Fri Nov 20 03:18:40 2009
From: adik at ilovebacon.org (Adam D. I. Kramer)
Date: Thu, 19 Nov 2009 18:18:40 -0800 (PST)
Subject: [R-sig-ME] estimating contrasts and their standard errors from
 mixed effects models in lme4
In-Reply-To: <754b10c00911191748j5590441eofa422484f16e6c8b@mail.gmail.com>
References: <754b10c00911191748j5590441eofa422484f16e6c8b@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0911191808000.20340@ilovebacon.org>

Hi Eva,

 	If your data frame contains the factor variables you are interested
in analyzing, use the contrasts() function to get and set which contrasts
you would like.

 	Then, just use the factor variable in your fixed-effects formula.
lmer will automatically use the contrasts you provided, and you will get a
effect line for each contrast (including estimate and standard error).

So, for example, I just completed this analysis and set it to my advisor. 
We're looking at the perception of personal risk of an adverse outcome
occurring. There were three adverse outcomes, which I had contrast-coded in
the following manner:

> contrasts(h3a2$effect)
     heaVcri achVcri
cri       0       0
hea       1       0
ach       0       1

...so when I use the h3a2$effect variable using lmer:

> summary( lmer(risk ~ effect*order + income + (1|subj), data=h3a2) )
... I get these fixed effects:

Fixed effects:
                     Estimate Std. Error t value
(Intercept)          0.92254    0.21431   4.305
effectheaVcri       -0.53837    0.24859  -2.166
effectachVcri       -0.40662    0.25000  -1.627
order               -0.31194    0.07823  -3.987
income              -0.08551    0.03618  -2.363
effectheaVcri:order  0.27001    0.11736   2.301
effectachVcri:order  0.19991    0.11764   1.699

...output lines 2 and 3 are the two contrasts (labeled with the name of the
variable and then the name of the contrast: effectheaVcri is really
"effect""heaVcri"), with their estimates, and standard errors.  Lines 6 and
7 are the same contrasts' interactions with the "order" variable.

Really, the order effect is what I'm interested in here--order predicted
less risk, meaning that people who rated a given disorder later on in the
experiment thought they were less at risk for the disorder (even after we
control for what the disorder is, so for me the contrasts are more or less
control variables).

Hope this helps!

--Adam

On Thu, 19 Nov 2009, eva petkova wrote:

> This must have come up before, but i did not find it in the help archive.
>
> in a mixed effects model fitted with lmer, i have an interaction term
> between two factors, each with more than two levels and would like to
> estimate and test  various contrasts between different combinations of the
> factor levels. i need the point estimates and the standard errors for these
> many contrasts.  does anyone know if there is a function that calculates the
> standard errors of contrasts?
>
> thank you
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From queirozrafaelmv at yahoo.com.br  Fri Nov 20 04:34:08 2009
From: queirozrafaelmv at yahoo.com.br (Rafael Maia)
Date: Thu, 19 Nov 2009 22:34:08 -0500
Subject: [R-sig-ME] [Fwd: effective sample size]
In-Reply-To: <4B02CAFE.5050607@u.washington.edu>
References: <4B02CAFE.5050607@u.washington.edu>
Message-ID: <370466A6-6FF6-4DC6-9D24-881F1B3546C7@yahoo.com.br>

Could somebody possibly send me a copy of the pdf? I don't have access to that journal at this time...

thanks!


Abra?os,
Rafael Maia
---
webpage: http://gozips.uakron.edu/~rm72
"A little learning is a dangerous thing; drink deep, or taste not the Pierian spring." (A. Pope)
Graduate Student - Integrated Bioscience
University of Akron
http://gozips.uakron.edu/~shawkey/

On Nov 17, 2009, at 11:10 AM, David Atkins wrote:

> 
> This was just posted to the multilevel listserv, and I have taken a very quick glance.  It appears to offer an alternative form for estimating degrees of freedom.  It's focused on longitudinal data, and I have not looked closely enough to see whether it would be more generally applicable to mixed-models (multilevel, nested, crossed, etc.) or whether it would "scale up" for larger problems.
> 
> Given all the hoo-hah around dfs, thought I would at least kick it out to the group.
> 
> cheers, Dave
> 
> -------- Original Message --------
> Subject: effective sample size
> Date: Tue, 17 Nov 2009 09:12:47 -0600
> From: Stas Kolenikov <skolenik at GMAIL.COM>
> Reply-To: Multilevel modelling discussion list <MULTILEVEL at JISCMAIL.AC.UK>
> To: MULTILEVEL at JISCMAIL.AC.UK
> 
> The recent issue of The American Statistician contains a pretty neat
> paper on the effective sample size and degrees of freedom in
> longitudinal studies: see
> http://www.citeulike.org/user/ctacmo/article/6129798. Highly
> recommended; there aren't that many people who understand longitudinal
> data as well as the Geert duo.
> 
> -- 
> Stas Kolenikov, also found at http://stas.kolenikov.name
> Small print: I use this email account for mailing lists only.
> 
> -------------------------- Multilevel list --------------------------
> To leave, send    leave multilevel    to jiscmail at jiscmail.ac.uk
> For further info about the Multilevel list, please see
> http://www.jiscmail.ac.uk/lists/multilevel.html     and
> http://www.nursing.teaching.man.ac.uk/staff/mcampbell/multilevel.html
> 
> -- 
> Dave Atkins, PhD
> Research Associate Professor
> Center for the Study of Health and Risk Behaviors
> Department of  Psychiatry and Behavioral Science
> University of Washington
> 1100 NE 45th Street, Suite 300
> Seattle, WA  98105
> 206-616-3879
> datkins at u.washington.edu
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From p.dalgaard at biostat.ku.dk  Fri Nov 20 10:06:07 2009
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Fri, 20 Nov 2009 10:06:07 +0100
Subject: [R-sig-ME] [Fwd: effective sample size]
In-Reply-To: <4B02CAFE.5050607@u.washington.edu>
References: <4B02CAFE.5050607@u.washington.edu>
Message-ID: <4B065BFF.9080001@biostat.ku.dk>

David Atkins wrote:

> 
> -------- Original Message --------
> From: Stas Kolenikov <skolenik at GMAIL.COM>
...
> The recent issue of The American Statistician contains a pretty neat
> paper on the effective sample size and degrees of freedom in
> longitudinal studies: see
> http://www.citeulike.org/user/ctacmo/article/6129798. Highly
> recommended; there aren't that many people who understand longitudinal
> data as well as the Geert duo.
> 

(That's G.Moolenberghs and G.Verbeke, for the lazy and uninitiated.)

The notion that the information content can be bounded as the number of 
data points go to infinity should come as no shock to anyone who has 
looked at experimental data with subsecond resolution, BTW. At the end 
of the day, you still have only five rats!


-- 
    O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
   c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
  (*) \(*) -- University of Copenhagen   Denmark      Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)              FAX: (+45) 35327907



From Howsun.Jow at newcastle.ac.uk  Fri Nov 20 11:23:43 2009
From: Howsun.Jow at newcastle.ac.uk (Howsun.Jow at newcastle.ac.uk)
Date: Fri, 20 Nov 2009 10:23:43 -0000 (GMT)
Subject: [R-sig-ME] Residual Sum Squares Issues with Linear Mixed Models
Message-ID: <db5e2a8fd949c5c907123a474679c335.squirrel@webmail.ncl.ac.uk>

I'm having problems understanding why the residual sum squares for a reduced
linear mixed model is sometimes smaller for a "reduced" model than for a
"full" model. Take the "Pastes" dataset for example:

fm3M <- lmer(strength ~ 1 + (1|batch) + (1|sample), Pastes), REML=F)
fm4M <- lmer(strength ~ 1 + (1|sample), Pastes), REML=F)

> sum(resid(fm3M)^2)
[1] 21.04984
> sum(resid(fm4M)^2)
[1] 21.03147

The reduced model seems to fit the data better than the full model. Is there
something fundamental I'm missing about linear mixed effects models?



From evap120 at gmail.com  Fri Nov 20 14:05:24 2009
From: evap120 at gmail.com (eva petkova)
Date: Fri, 20 Nov 2009 08:05:24 -0500
Subject: [R-sig-ME] estimating contrasts and their standard errors from
	mixed effects models in lme4
In-Reply-To: <Pine.LNX.4.64.0911191808000.20340@ilovebacon.org>
References: <754b10c00911191748j5590441eofa422484f16e6c8b@mail.gmail.com>
	<Pine.LNX.4.64.0911191808000.20340@ilovebacon.org>
Message-ID: <754b10c00911200505u378741c5y3d01c5a0c236fa23@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20091120/19cccb95/attachment.pl>

From bates at stat.wisc.edu  Fri Nov 20 15:50:29 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 20 Nov 2009 08:50:29 -0600
Subject: [R-sig-ME] Residual Sum Squares Issues with Linear Mixed Models
In-Reply-To: <db5e2a8fd949c5c907123a474679c335.squirrel@webmail.ncl.ac.uk>
References: <db5e2a8fd949c5c907123a474679c335.squirrel@webmail.ncl.ac.uk>
Message-ID: <40e66e0b0911200650g7b991487tfef1b0b1caed9235@mail.gmail.com>

On Fri, Nov 20, 2009 at 4:23 AM,  <Howsun.Jow at newcastle.ac.uk> wrote:
> I'm having problems understanding why the residual sum squares for a reduced
> linear mixed model is sometimes smaller for a "reduced" model than for a
> "full" model. Take the "Pastes" dataset for example:
>
> fm3M <- lmer(strength ~ 1 + (1|batch) + (1|sample), Pastes), REML=F)
> fm4M <- lmer(strength ~ 1 + (1|sample), Pastes), REML=F)
>
>> sum(resid(fm3M)^2)
> [1] 21.04984
>> sum(resid(fm4M)^2)
> [1] 21.03147
>
> The reduced model seems to fit the data better than the full model. Is there
> something fundamental I'm missing about linear mixed effects models?

The maximum likelihood estimates of the parameters in a linear
mixed-effects model are not the least squares estimates.  The
conditional means of the random effects and the estimates of the
fixed-effects parameters are penalized least squares estimates.  When
you remove one random effects term you may change the estimates of
variance of the random effects for the other term, resulting in a
different penalty and possibly a larger sum of squares of residuals.



From frederic.gosselin at cemagref.fr  Fri Nov 20 16:16:17 2009
From: frederic.gosselin at cemagref.fr (Gosselin Frederic)
Date: Fri, 20 Nov 2009 16:16:17 +0100
Subject: [R-sig-ME] different results across versions for glmer/lmer with
	the quasi-poisson or quasi-binomial families: the lattest
	version might not be accurate...
Message-ID: <D74CFE08A4F86B45870D14844A636E90011D2885@murier.nogent.cemagref.fr>

************** Slightly modified version of a mail Already posted in the R-help list
************* but Ben Bolker suggested me to also post it here
************* Sorry for cross-posting ******************

 

Dear R-helpers,

this mail is intended to mention a rather strange result and generate potential useful comments on it. I am not aware of another posts on this issue ( RSiteSearch("quasipoisson lmer version dispersion")). (But see http://r-forge.r-project.org/tracker/index.php?func=detail&aid=307&group_id=60&atid=298).

Using the exemple in the reference of the lmer function (in lme4 library) and turning it into a quasi-poisson or quasi-binomial analysis, we get different results across lme4 and R versions, especially for the dispersion parameter (section 1 in the following). For the quasi-poisson, we found even stronger differences with another, bigger database on which we worked (residual variance from approx. 0.7 to 1.2). We also tested the differences between versions for plain likelihood families (poisson and binomial): the differences were slighter, and were actually very small in the case of the poisson family. 

My first reaction was that the later version should have been better. However, the quasibinomial results of this version are rather strange. Therefore, I simulated a bigger data set corresponding to Poisson and binomial mixed models (section 2 in the following). I actually found that the later version of lme4 was suspect but not the old one. My temptative conclusion is therefore to use the old versions of lme4 (here:  lme4 version 0.99875-9) when using quasi-binomial and quasi-poisson methods.

Any comment/insight appreciated.

 
All the best,
 
Fr?d?ric Gosselin
Engineer & Researcher (PhD) in Forest Ecology
Cemagref
Domaine des Barres
F-45290 Nogent sur Vernisson
France


############### 1- EXAMPLE FROM LMER HELP

############# here are the commands for the quasipoisson:
library(lme4)
gm1 <- lmer(incidence ~ period + (1 | herd), family = quasipoisson, data = cbpp)
summary(gm1)


########## here is the result under R2.5.1 and Package lme4 version 0.99875-9:
Generalized linear mixed model fit using Laplace
Formula: incidence ~ period + (1 | herd)
   Data: cbpp
 Family: quasipoisson(log link)
   AIC   BIC logLik deviance
 112.2 122.3 -51.11    102.2
Random effects:
 Groups   Name        Variance Std.Dev.
 herd     (Intercept) 0.35085  0.59233
 Residual             1.40470  1.18520
number of obs: 56, groups: herd, 15

Fixed effects:
            Estimate Std. Error t value
(Intercept)   1.2812     0.2200   5.824
period2      -1.1240     0.3315  -3.391
period3      -1.3203     0.3579  -3.689
period4      -1.9477     0.4808  -4.051

Correlation of Fixed Effects:
        (Intr) perid2 perid3
period2 -0.339             
period3 -0.314  0.219      
period4 -0.233  0.163  0.151


#############" here is the result on R2.7.1 and Package lme4 version 0.999375-26

Generalized linear mixed model fit by the Laplace approximation
Formula: incidence ~ period + (1 | herd)
   Data: cbpp
   AIC   BIC logLik deviance
 114.2 126.4  -51.1    102.2
Random effects:
 Groups   Name        Variance Std.Dev.
 herd     (Intercept) 0.32421  0.56939
 Residual             1.29474  1.13786
Number of obs: 56, groups: herd, 15

Fixed effects:
            Estimate Std. Error t value
(Intercept)   1.2762     0.2115   6.035
period2      -1.1249     0.3187  -3.530
period3      -1.3190     0.3438  -3.837
period4      -1.9450     0.4615  -4.215

Correlation of Fixed Effects:
        (Intr) perid2 perid3
period2 -0.339             
period3 -0.314  0.219      
period4 -0.233  0.163  0.151



############# now the commands for the quasibinomial:
library(lme4)
toto<-as.double(cbpp$incidence>0)
gm2 <- lmer(toto ~ period + (1 | herd), family = quasibinomial, data = cbpp)
summary(gm2)
 
########## here is the result under R2.5.1 and Package lme4 version 0.99875-9:

Generalized linear mixed model fit using Laplace 
Formula: toto ~ period + (1 | herd) 
   Data: cbpp 
 Family: quasibinomial(logit link)
   AIC   BIC logLik deviance
 72.04 82.17 -31.02    62.04
Random effects:
 Groups   Name        Variance   Std.Dev.  
 herd     (Intercept) 5.0259e-10 2.2418e-05
 Residual             1.0052e+00 1.0026e+00
number of obs: 56, groups: herd, 15
 
Fixed effects:
            Estimate Std. Error t value
(Intercept)    2.662      1.048   2.540
period2       -2.078      1.188  -1.750
period3       -2.950      1.180  -2.501
period4       -3.135      1.194  -2.626
 
Correlation of Fixed Effects:
        (Intr) perid2 perid3
period2 -0.882              
period3 -0.888  0.784       
period4 -0.878  0.775  0.780

 
 
############# here is the result on R2.7.1 and Package lme4 version 0.999375-26

Generalized linear mixed model fit by the Laplace approximation 
Formula: toto ~ period + (1 | herd) 
   Data: cbpp 
   AIC  BIC logLik deviance
 74.04 86.2 -31.02    62.04
Random effects:
 Groups   Name        Variance Std.Dev.
 herd     (Intercept) 0.00000  0.00000 
 Residual             0.13522  0.36772 
Number of obs: 56, groups: herd, 15
 
Fixed effects:
            Estimate Std. Error t value
(Intercept)   2.6391     0.3806   6.933
period2      -2.0513     0.4324  -4.744
period3      -2.9267     0.4293  -6.817
period4      -3.1091     0.4345  -7.155
 
Correlation of Fixed Effects:
        (Intr) perid2 perid3
period2 -0.880              
period3 -0.887  0.780       
period4 -0.876  0.771  0.777

 
 
 
 
############### 2- SIMULATED EXAMPLE

############# here are the commands both for the quasibinomial and  quasipoisson:


library(lme4)

set.seed(1)

period<-rnorm(1000)

herd<-rep(1:50,eac=20)

herd.effect<-rnorm(50)

toto<-rbinom(1000,1,exp(period+herd.effect[herd])/(1+exp(period+herd.effect[herd])))

gm2s <- lmer(toto ~ period + (1 | herd), family = quasibinomial)

summary(gm2s)

 

gm2sL <- lmer(toto ~ period + (1 | herd), family = binomial)

summary(gm2sL)

 

#now poisson with similar data:

#essai avec jeu de donn?es simul?:

set.seed(2)

toto<-rpois(1000,exp(period+herd.effect[herd]))

gm1s <- lmer(toto ~ period + (1 | herd), family = quasipoisson)

summary(gm1s)

 

gm1sL <- lmer(toto ~ period + (1 | herd), family = poisson)

summary(gm1sL)

 

 

########## here is the quasi-poisson result under R2.5.1 and Package lme4 version 0.99875-9: (all is OK)


Generalized linear mixed model fit using Laplace 
Formula: toto ~ period + (1 | herd) 
 Family: quasipoisson(log link)
  AIC  BIC logLik deviance
 1151 1166 -572.7     1145
Random effects:
 Groups   Name        Variance Std.Dev.
 herd     (Intercept) 0.83605  0.91436 
 Residual             0.97980  0.98985 
number of obs: 1000, groups: herd, 50
 
Fixed effects:
            Estimate Std. Error t value
(Intercept)  0.02775    0.13419    0.21
period       0.97424    0.02291   42.52
 
Correlation of Fixed Effects:
       (Intr)
period -0.157

 
############# here is the quasipoisson result on R2.7.1 and Package lme4 version 0.999375-26: the variance estimates are suspect
Generalized linear mixed model fit by the Laplace approximation 
Formula: toto ~ period + (1 | herd) 
  AIC  BIC logLik deviance
 1153 1173 -572.7     1145
Random effects:
 Groups   Name        Variance Std.Dev.
 herd     (Intercept) 0.35305  0.59418 
 Residual             0.41370  0.64320 
Number of obs: 1000, groups: herd, 50
 
Fixed effects:
            Estimate Std. Error t value
(Intercept)  0.02757    0.08720    0.32
period       0.97423    0.01489   65.44
 
Correlation of Fixed Effects:
       (Intr)
period -0.157

 
 

########## here is the quasi-binomial result under R2.5.1 and Package lme4 version 0.99875-9: (all is OK)


Generalized linear mixed model fit using Laplace 
Formula: toto ~ period + (1 | herd) 
 Family: quasibinomial(logit link)
  AIC  BIC logLik deviance
 1145 1160 -569.6     1139
Random effects:
 Groups   Name        Variance Std.Dev.
 herd     (Intercept) 0.85697  0.92573 
 Residual             0.94584  0.97254 
number of obs: 1000, groups: herd, 50
 
Fixed effects:
            Estimate Std. Error t value
(Intercept) -0.05493    0.14949  -0.367
period       1.02879    0.08360  12.306
 
Correlation of Fixed Effects:
       (Intr)
period -0.001

 
############# here is the quasi-binomial result on R2.7.1 and Package lme4 version 0.999375-26: the variance estimates are very suspect
Generalized linear mixed model fit by the Laplace approximation 
Formula: toto ~ period + (1 | herd) 
  AIC  BIC logLik deviance
 1147 1167 -569.6     1139
Random effects:
 Groups   Name        Variance Std.Dev.
 herd     (Intercept) 0.12520  0.35384 
 Residual             0.13819  0.37173 
Number of obs: 1000, groups: herd, 50
 
Fixed effects:
            Estimate Std. Error t value
(Intercept) -0.05503    0.05714   -0.96
period       1.03117    0.03199   32.24
 
Correlation of Fixed Effects:
       (Intr)


 



From cmswoboda at students.wisc.edu  Sat Nov 21 16:46:04 2009
From: cmswoboda at students.wisc.edu (CHRIS M SWOBODA)
Date: Sat, 21 Nov 2009 09:46:04 -0600
Subject: [R-sig-ME] Generating correlated multilevel data
In-Reply-To: <mailman.3.1258801202.5491.r-sig-mixed-models@r-project.org>
References: <mailman.3.1258801202.5491.r-sig-mixed-models@r-project.org>
Message-ID: <6e10adb15024e.4b07b6dc@wiscmail.wisc.edu>

Hi,

Does anyone know of a package or some available code for generating multilevel data with multiple predictors at each level that can be correlated across levels?  I assume this has been done and I don't really want to reinvent the wheel, but I cannot seem to find the actual code.  

For some specifics:
I want to generate three-level data with 2-3 predictors at each level and correlations throughout the predictors where I would specify the sample sizes, correlations and error at each level.  

Thanks for any help!
Chris



From nikko at hailmail.net  Sun Nov 22 20:15:38 2009
From: nikko at hailmail.net (Nicholas Lewin-Koh)
Date: Sun, 22 Nov 2009 11:15:38 -0800
Subject: [R-sig-ME] estimating contrasts and their standard errors from
 mixed effects models in lme4
In-Reply-To: <mailman.3.1258801202.5491.r-sig-mixed-models@r-project.org>
References: <mailman.3.1258801202.5491.r-sig-mixed-models@r-project.org>
Message-ID: <1258917338.1037.1346483679@webmail.messagingengine.com>

Hi Eva,
Be careful when estimating contrasts when you have interactions in the
model. When doing contrasts on
the fixed effects you need to account for the interactions when looking
at the main effects.
Since I invariably screw up the contrast matrices, I like to use both
the contrast package to get the contrast matrix,
and then multcomp to calculate the contrasts and adjust for multiple
comparisons. Here is 
an example

library(contrasts)
library(multcomp)
library(mlmRev)
library(lme4)
data(egsingle)
 
fm1 <- lmer(math~year*size+female+(1|childid)+(1|schoolid), egsingle) ##
The mixed model
fm2 <- lm(math~year*size+female, data=egsingle) ## Main effects to get
contrast matrix, there is no method for lme4 objects

cc<-contrast(fm2,a=list(year=c(.5,1.5,2.5),size=380, female="Male"),
b=list(year=c(.5,1.5,2.5),size=800, female="Male"))

summary(glht(fm1, linfct = cc$X)) ## Plug in the contrast matrix from
contrast, multcomp will use the variance covariance matrix

	 Simultaneous Tests for General Linear Hypotheses

Fit: lmer(formula = math ~ year * size + female + (1 | childid) + 
    (1 | schoolid), data = egsingle, verbose = 1)

Linear Hypotheses:
       Estimate Std. Error z value Pr(>|z|)  
1 == 0  0.12774    0.08018   1.593   0.1271  
2 == 0  0.15323    0.08065   1.900   0.0661 .
3 == 0  0.17871    0.08177   2.185   0.0341 *
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1 
(Adjusted p values reported -- single-step method)


Note,the degrees of freedom in these tests is still a contentious issue.
But I think this is what
you are looking for.

Nicholas


> Message: 1
> Date: Fri, 20 Nov 2009 08:05:24 -0500
> From: eva petkova <evap120 at gmail.com>
> Subject: Re: [R-sig-ME] estimating contrasts and their standard errors
> 	from	mixed effects models in lme4
> To: adik at ilovebacon.org
> Cc: r-sig-mixed-models at r-project.org
> Message-ID:
> 	<754b10c00911200505u378741c5y3d01c5a0c236fa23 at mail.gmail.com>
> Content-Type: text/plain
> 
> Thank you Adam,
> 
> i am actually interested in estimating various contrasts without having
> to
> re-parametrize the factors in order to estimate different contrasts.  in
> your example, the parametrization of the effect factor you are using will
> estimate the contrasts  hea vs.cri or ach vs.cri, but if you wanted to
> estimate hea vs. ach, you will have to reparametrize the effect factor
> and
> refit the model.  in your case it it just one more reparametrization and
> fitting of the model but with factors that have more levels and
> interactions
> between them it is quite an elaborate process.  so i wondered if there is
> a
> function that can use the fit from one model and take as an input a
> linear
> combination of the regression coefficients and estimate the standard
> error
> of teh linear combination -- something similar to the "estimate"
> statement
> in Proc Mixed in SAS does.
> 
> Thanks again
> 
> e
> 
> On Thu, Nov 19, 2009 at 9:18 PM, Adam D. I. Kramer
> <adik at ilovebacon.org>wrote:
> 
> > Hi Eva,
> >
> >        If your data frame contains the factor variables you are interested
> > in analyzing, use the contrasts() function to get and set which contrasts
> > you would like.
> >
> >        Then, just use the factor variable in your fixed-effects formula.
> > lmer will automatically use the contrasts you provided, and you will get a
> > effect line for each contrast (including estimate and standard error).
> >
> > So, for example, I just completed this analysis and set it to my advisor.
> > We're looking at the perception of personal risk of an adverse outcome
> > occurring. There were three adverse outcomes, which I had contrast-coded in
> > the following manner:
> >
> >  contrasts(h3a2$effect)
> >>
> >    heaVcri achVcri
> > cri       0       0
> > hea       1       0
> > ach       0       1
> >
> > ...so when I use the h3a2$effect variable using lmer:
> >
> >  summary( lmer(risk ~ effect*order + income + (1|subj), data=h3a2) )
> >>
> > ... I get these fixed effects:
> >
> > Fixed effects:
> >                    Estimate Std. Error t value
> > (Intercept)          0.92254    0.21431   4.305
> > effectheaVcri       -0.53837    0.24859  -2.166
> > effectachVcri       -0.40662    0.25000  -1.627
> > order               -0.31194    0.07823  -3.987
> > income              -0.08551    0.03618  -2.363
> > effectheaVcri:order  0.27001    0.11736   2.301
> > effectachVcri:order  0.19991    0.11764   1.699
> >
> > ...output lines 2 and 3 are the two contrasts (labeled with the name of the
> > variable and then the name of the contrast: effectheaVcri is really
> > "effect""heaVcri"), with their estimates, and standard errors.  Lines 6 and
> > 7 are the same contrasts' interactions with the "order" variable.
> >
> > Really, the order effect is what I'm interested in here--order predicted
> > less risk, meaning that people who rated a given disorder later on in the
> > experiment thought they were less at risk for the disorder (even after we
> > control for what the disorder is, so for me the contrasts are more or less
> > control variables).
> >
> > Hope this helps!
> >
> > --Adam
> >
> >
> > On Thu, 19 Nov 2009, eva petkova wrote:
> >
> >  This must have come up before, but i did not find it in the help archive.
> >>
> >> in a mixed effects model fitted with lmer, i have an interaction term
> >> between two factors, each with more than two levels and would like to
> >> estimate and test  various contrasts between different combinations of the
> >> factor levels. i need the point estimates and the standard errors for
> >> these
> >> many contrasts.  does anyone know if there is a function that calculates
> >> the
> >> standard errors of contrasts?
> >>
> >> thank you
> >>
> >>        [[alternative HTML version deleted]]
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>
> >>
> 
> 
> -- 
> Eva,
> 
> 	[[alternative HTML version deleted]]
> 
> 
> 
> ------------------------------



From alice at blarg.net  Mon Nov 23 20:32:12 2009
From: alice at blarg.net (Alice Shelly)
Date: Mon, 23 Nov 2009 13:32:12 -0600
Subject: [R-sig-ME] correlation structure with glmer?
Message-ID: <8507A603412D4EC89FE2A36499CA4440@alicemobile>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20091123/cf936892/attachment.pl>

From bates at stat.wisc.edu  Mon Nov 23 21:08:18 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 23 Nov 2009 14:08:18 -0600
Subject: [R-sig-ME] correlation structure with glmer?
In-Reply-To: <8507A603412D4EC89FE2A36499CA4440@alicemobile>
References: <8507A603412D4EC89FE2A36499CA4440@alicemobile>
Message-ID: <40e66e0b0911231208v677f7ea9yd93aa906406ebd1f@mail.gmail.com>

On Mon, Nov 23, 2009 at 1:32 PM, Alice Shelly <alice at blarg.net> wrote:
> Hello-
> Is there any way to introduce correlation structure into a glmer model?
> I tried using
> correlation = corAR1(form= ~age|plot)
> as you would in lme, but I was ignored (so rude).

Well, first you would need to decide how to define such a model.  It
is not trivial.  For a linear mixed-effects model you can separately
modify the specification of the mean and the variance of the
conditional distribution of the response given the random effects.
For common generalized linear mixed models (family = binomial or
family = poisson) you can't.  Once you have the conditional
independence assumption and you specify the conditional mean you have
completely specified the conditional distribution.



From birdlists at gmail.com  Mon Nov 23 21:57:39 2009
From: birdlists at gmail.com (Jude Phillips)
Date: Mon, 23 Nov 2009 15:57:39 -0500
Subject: [R-sig-ME] can mixed effects models handle two dependent variables
Message-ID: <2d850d6d0911231257m7a4d86d9ob9817a4b0fa9444@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20091123/fb12bffb/attachment.pl>

From DAfshartous at med.miami.edu  Mon Nov 23 22:08:34 2009
From: DAfshartous at med.miami.edu (Afshartous, David)
Date: Mon, 23 Nov 2009 16:08:34 -0500
Subject: [R-sig-ME] can mixed effects models handle two dependent
 variables
In-Reply-To: <2d850d6d0911231257m7a4d86d9ob9817a4b0fa9444@mail.gmail.com>
Message-ID: <C7306402.C76C%dafshartous@med.miami.edu>


A good starting point is Doran & Lockwood (2006), Journal of Educational and Behavioral Statistics, 31:205-230 (see p.223).   There are also a couple of recent threads on this issue, e.g., see
[R-sig-ME] Multivariate mixed effects model
[R-sig-ME] weighting nlme and multivariate outcomes

HTH,
David




On 11/23/09 3:57 PM, "Jude Phillips" <birdlists at gmail.com> wrote:

Hi,

I am carrying out a stable isotope study, where I have measured stable
isotopes of nitrogen and carbon in plants at different sites.  I have been
able to create mixed models for each isotope separately - eg

fit1.c<-lme(X13c~soil+manure, random=~1|site, weights=varIdent(form = ~ 1 |
soil), data)
fit1.n<-lme(X15n~soil+manure, random=~1|site, weights=varIdent(form = ~ 1 |
soil), data)

What I'm wondering is if I can test both stable isotopes at the same time,
in a MANOVA style analysis.  I can't seem to find any info on this - if
someone could point me in the direction of some info, or tell me if this
isn't possible , I'd much appreciate it.

Thanks, Sarah Adams

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From j.hadfield at ed.ac.uk  Tue Nov 24 11:21:05 2009
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Tue, 24 Nov 2009 10:21:05 +0000
Subject: [R-sig-ME] can mixed effects models handle two
	dependent	variables
In-Reply-To: <2d850d6d0911231257m7a4d86d9ob9817a4b0fa9444@mail.gmail.com>
References: <2d850d6d0911231257m7a4d86d9ob9817a4b0fa9444@mail.gmail.com>
Message-ID: <20091124102105.t347k6wfms0csg40@www.staffmail.ed.ac.uk>

Hi  Sarah,

If you're prepared to MCMC it you can use MCMCglmm. Something like:

fit1.cn<-MCMCglmm(cbind(X13c,X15n)~trait+trait:soil+trait:manure-1,  
random=us(trait):site, rcov=~us(trait):units, data=data,  
family=c("gaussian", "gaussian")

where trait indexes columns of the response (X13c & X13n) and units  
indexes rows.

trait+trait:soil+trait:manure-1 fits trait specific intercepts and separate
effects of soil and manure.

us(trait):site fits different site variances for X13c & X13n, together  
with the covariance.

us(trait):units fits different residual variances for X13c & X13n,  
together with the covariance.

You can not fit the heteroscedastic model exactly, but you could fit  
something like

us(trait:soil):units or idh(trait:soil):units in the random effects in  
addition to the residual component - a bit like a nugget effect I guess.

Cheers,

Jarrod


Quoting Jude Phillips <birdlists at gmail.com>:

> Hi,
>
> I am carrying out a stable isotope study, where I have measured stable
> isotopes of nitrogen and carbon in plants at different sites.  I have been
> able to create mixed models for each isotope separately - eg
>
> fit1.c<-lme(X13c~soil+manure, random=~1|site, weights=varIdent(form = ~ 1 |
> soil), data)
> fit1.n<-lme(X15n~soil+manure, random=~1|site, weights=varIdent(form = ~ 1 |
> soil), data)
>
> What I'm wondering is if I can test both stable isotopes at the same time,
> in a MANOVA style analysis.  I can't seem to find any info on this - if
> someone could point me in the direction of some info, or tell me if this
> isn't possible , I'd much appreciate it.
>
> Thanks, Sarah Adams
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From cornelia at mcs.st-and.ac.uk  Tue Nov 24 14:48:51 2009
From: cornelia at mcs.st-and.ac.uk (Cornelia Oedekoven)
Date: Tue, 24 Nov 2009 13:48:51 +0000
Subject: [R-sig-ME] random effects coefficients
Message-ID: <4B0BE443.1020800@mcs.st-and.ac.uk>

Hi,

I am using the glmer function from the lme4 library to fit mixed-effect 
models to my data. When using the ranef function I can extract the 
random effect coefficients from the model. What I would like to know is 
how these are estimated. What is the algebra involved in getting these 
estimates?

Thank you very much. Cheers, Cornelia



From lborger at uoguelph.ca  Tue Nov 24 15:12:18 2009
From: lborger at uoguelph.ca (Luca Borger)
Date: Tue, 24 Nov 2009 09:12:18 -0500 (EST)
Subject: [R-sig-ME] random effects coefficients
In-Reply-To: <999668290.28124921259071769211.JavaMail.root@huron.cs.uoguelph.ca>
Message-ID: <578223315.28128141259071938947.JavaMail.root@huron.cs.uoguelph.ca>

Hello,

have a look at these slides by Douglas Bates on mixed effects models:
 
http://lme4.r-forge.r-project.org/slides/

e.g.
http://lme4.r-forge.r-project.org/slides/2009-07-07-Rennes/4Theory-4.pdf

perhaps you might find them useful.



HTH

Cheers,

Luca


----- Original Message -----
From: "Cornelia Oedekoven" <cornelia at mcs.st-and.ac.uk>
To: r-sig-mixed-models at r-project.org
Sent: Tuesday, 24 November, 2009 08:48:51 GMT -05:00 US/Canada Eastern
Subject: [R-sig-ME] random effects coefficients

Hi,

I am using the glmer function from the lme4 library to fit mixed-effect 
models to my data. When using the ranef function I can extract the 
random effect coefficients from the model. What I would like to know is 
how these are estimated. What is the algebra involved in getting these 
estimates?

Thank you very much. Cheers, Cornelia

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From danielezrajohnson at gmail.com  Tue Nov 24 15:39:38 2009
From: danielezrajohnson at gmail.com (Daniel Ezra Johnson)
Date: Tue, 24 Nov 2009 09:39:38 -0500
Subject: [R-sig-ME] random effects coefficients
In-Reply-To: <578223315.28128141259071938947.JavaMail.root@huron.cs.uoguelph.ca>
References: <999668290.28124921259071769211.JavaMail.root@huron.cs.uoguelph.ca>
	<578223315.28128141259071938947.JavaMail.root@huron.cs.uoguelph.ca>
Message-ID: <a46630750911240639o56380ad6wbb369c70a9dc0f3f@mail.gmail.com>

Cornelia,

And don't call them estimates!

D

On Tue, Nov 24, 2009 at 9:12 AM, Luca Borger <lborger at uoguelph.ca> wrote:
> Hello,
>
> have a look at these slides by Douglas Bates on mixed effects models:
>
> http://lme4.r-forge.r-project.org/slides/
>
> e.g.
> http://lme4.r-forge.r-project.org/slides/2009-07-07-Rennes/4Theory-4.pdf
>
> perhaps you might find them useful.
>
>
>
> HTH
>
> Cheers,
>
> Luca
>
>
> ----- Original Message -----
> From: "Cornelia Oedekoven" <cornelia at mcs.st-and.ac.uk>
> To: r-sig-mixed-models at r-project.org
> Sent: Tuesday, 24 November, 2009 08:48:51 GMT -05:00 US/Canada Eastern
> Subject: [R-sig-ME] random effects coefficients
>
> Hi,
>
> I am using the glmer function from the lme4 library to fit mixed-effect
> models to my data. When using the ranef function I can extract the
> random effect coefficients from the model. What I would like to know is
> how these are estimated. What is the algebra involved in getting these
> estimates?
>
> Thank you very much. Cheers, Cornelia
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From ledonret at email.unc.edu  Tue Nov 24 17:42:30 2009
From: ledonret at email.unc.edu (ledonret at email.unc.edu)
Date: Tue, 24 Nov 2009 11:42:30 -0500
Subject: [R-sig-ME] MCMCglmm and prior specification
Message-ID: <20091124114230.2vjzu6g4g0040w4g@webmail5.isis.unc.edu>

Dear all,

I am trying to use the MCMCglmm package to create credibility intervals 
for random variables in my data. I'm having a bit of trouble though 
determining what the best prior to use for each model is, since the 
results seem to differ tremendously depending on which prior I am 
using, for instance, I've tried these three types of priors,

> halfFam<-var(data$Family)/2
> prior1=list(R=list(V=1,n=1,fix=1),G=list(G1=list(V=1,n=1),G2=list(V=1,n=1)))
> prior2=list(R=list(V=1,n=1),G=list(G1=list(V=1,n=1),G2=list(V=1,n=1)))
> prior3=list(R=list(V=halfFam,n=1),G=list(G1=list(V=halfFam,n=1),G2=list(V=halfFam,n=1)))

For the model,
> model<-MCMCglmm(Length~1,random=~Family+Rep,data=data,verbose=FALSE,prior=prior,burnin=10000,nitt=75000)

Where the random factors are Family and Replicate.
 From these priors, I get intervals for my Family effect,

> HPDinterval(model1$VCV[,"Family"])
          lower     upper
var1 0.09660338 0.8888039

> HPDinterval(model2$VCV[,"Family"])
         lower    upper
var1 0.1944570 2.120540

> HPDinterval(model3$VCV[,"Family"])
         lower    upper
var1 0.2099238 1.529794


I feel bad that I don't understand better how to specify the components 
of these priors, but from what I understand, the model should return 
similar values even if the priors are very different. I've looked 
through the vignette thoroughly, but didn't get a sense of what I was 
supposed to do if alternate priors returned different answers. I'm not 
sure whether this is telling me that all the information is coming from 
my priors (and there is, in fact, no information in the data), or I am 
just incorrectly specifying my priors.

Any insight would be very much appreciated! Happy holidays,

Cristina Ledon-Rettig
UNC-Chapel Hill

*I am using lme4 version 0.99375-28 with Mac OS X version 10.5



From desja004 at umn.edu  Tue Nov 24 17:59:03 2009
From: desja004 at umn.edu (Christopher David Desjardins)
Date: Tue, 24 Nov 2009 10:59:03 -0600
Subject: [R-sig-ME] MCMCglmm and prior specification
In-Reply-To: <20091124114230.2vjzu6g4g0040w4g@webmail5.isis.unc.edu>
References: <20091124114230.2vjzu6g4g0040w4g@webmail5.isis.unc.edu>
Message-ID: <4B0C10D7.4040100@umn.edu>

Hi Cristina,
I'm sure Jarrod or someone else more knowledgeable will address this but 
your random variables are highly susceptible to changes in the prior 
unless you have an extremely large sample size. One thing that is worth 
noting is that your credible intervals overlap regardless of priors, 
however, that difference below seems like it could be pretty high. Is 
it? What's the mean and variance of Length? If the variance is large 
than maybe this difference isn't that big and this difference based on 
priors is moot.

One prior worth trying is the inverse gamma prior.

prior=list(R=list(V=1, nu=0.002),
           G=list(G1=list(V=1, nu=0.002),
                  G2=list(V=1, nu=0.002),
                  G3=list(V=1, nu=0.002)))

I guess this used to be the default prior in WinBUGS. But this will just 
give you another estimate.

On 11/24/2009 10:42 AM, ledonret at email.unc.edu wrote:
> Dear all,
>
> I am trying to use the MCMCglmm package to create credibility 
> intervals for random variables in my data. I'm having a bit of trouble 
> though determining what the best prior to use for each model is, since 
> the results seem to differ tremendously depending on which prior I am 
> using, for instance, I've tried these three types of priors,
>
>> halfFam<-var(data$Family)/2
>> prior1=list(R=list(V=1,n=1,fix=1),G=list(G1=list(V=1,n=1),G2=list(V=1,n=1))) 
>>
>> prior2=list(R=list(V=1,n=1),G=list(G1=list(V=1,n=1),G2=list(V=1,n=1)))
>> prior3=list(R=list(V=halfFam,n=1),G=list(G1=list(V=halfFam,n=1),G2=list(V=halfFam,n=1))) 
>>
One thing you could try is setting nu to a smaller value to make it less 
informative.

Chris


> For the model,
>> model<-MCMCglmm(Length~1,random=~Family+Rep,data=data,verbose=FALSE,prior=prior,burnin=10000,nitt=75000) 
>>
>
> Where the random factors are Family and Replicate.
> From these priors, I get intervals for my Family effect,
>
>> HPDinterval(model1$VCV[,"Family"])
>          lower     upper
> var1 0.09660338 0.8888039
>
>> HPDinterval(model2$VCV[,"Family"])
>         lower    upper
> var1 0.1944570 2.120540
>
>> HPDinterval(model3$VCV[,"Family"])
>         lower    upper
> var1 0.2099238 1.529794
>
>
> I feel bad that I don't understand better how to specify the 
> components of these priors, but from what I understand, the model 
> should return similar values even if the priors are very different. 
> I've looked through the vignette thoroughly, but didn't get a sense of 
> what I was supposed to do if alternate priors returned different 
> answers. I'm not sure whether this is telling me that all the 
> information is coming from my priors (and there is, in fact, no 
> information in the data), or I am just incorrectly specifying my priors.
>
> Any insight would be very much appreciated! Happy holidays,
>
> Cristina Ledon-Rettig
> UNC-Chapel Hill
>
> *I am using lme4 version 0.99375-28 with Mac OS X version 10.5
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Christopher David Desjardins, Ph.D. Student
Quantitative Methods in Education
Department of Educational Psychology
University of Minnesota
http://cddesjardins.wordpress.com/



From j.hadfield at ed.ac.uk  Tue Nov 24 18:03:36 2009
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Tue, 24 Nov 2009 17:03:36 +0000
Subject: [R-sig-ME] MCMCglmm and prior specification
In-Reply-To: <20091124114230.2vjzu6g4g0040w4g@webmail5.isis.unc.edu>
References: <20091124114230.2vjzu6g4g0040w4g@webmail5.isis.unc.edu>
Message-ID: <D8835F58-95DA-4ABD-A1A2-F3BB844276F3@ed.ac.uk>

Dear Cristina,

I am currently writing a better guide to MCMCglmm which deals more  
extensively with prior specifications - it should be ready soon.

In your first prior you have fixed the residual variance to be V=1, so  
it's not surprising that this gives very different answers from models  
2 and 3.

Often variance components are sensitive to prior information, in part  
because the data may not contain much information but also because the  
inverse-Wishart prior used is not really flexible enough (again, I am  
working on this).

The various improper priors often lead to numerical problems which  
precludes their use, but the resulting posterior does have some useful  
properties:

when V=anything & nu=0 the joint posterior modes  should be equal to  
the ML estimate
when V=0 & nu=-2 the joint posterior modes should be equal to the REML  
estimate (in practice you will have to use V=1e-6, or something small)

A commonly used proper prior is V=1 & nu=0.002.  This is equivalent to  
the inverse gamma distribution with shape=scale=0.001. This was the  
"default" in WinBUGS for a while before Andrew Gelman showed why it  
shouldn't be - it can be informative if the variances are close to zero.

Hope this helps,

If anyone wants an unfinished copy of the MCMCglmm guide just email me.

Jarod



On 24 Nov 2009, at 16:42, ledonret at email.unc.edu wrote:

> Dear all,
>
> I am trying to use the MCMCglmm package to create credibility  
> intervals for random variables in my data. I'm having a bit of  
> trouble though determining what the best prior to use for each model  
> is, since the results seem to differ tremendously depending on which  
> prior I am using, for instance, I've tried these three types of  
> priors,
>
>> halfFam<-var(data$Family)/2
>> prior1 
>> = 
>> list(R=list(V=1,n=1,fix=1),G=list(G1=list(V=1,n=1),G2=list(V=1,n=1)))
>> prior2 
>> =list(R=list(V=1,n=1),G=list(G1=list(V=1,n=1),G2=list(V=1,n=1)))
>> prior3 
>> = 
>> list 
>> (R 
>> = 
>> list 
>> (V 
>> =halfFam,n=1),G=list(G1=list(V=halfFam,n=1),G2=list(V=halfFam,n=1)))
>
> For the model,
>> model<-MCMCglmm(Length~1,random=~Family 
>> +Rep,data=data,verbose=FALSE,prior=prior,burnin=10000,nitt=75000)
>
> Where the random factors are Family and Replicate.
> From these priors, I get intervals for my Family effect,
>
>> HPDinterval(model1$VCV[,"Family"])
>         lower     upper
> var1 0.09660338 0.8888039
>
>> HPDinterval(model2$VCV[,"Family"])
>        lower    upper
> var1 0.1944570 2.120540
>
>> HPDinterval(model3$VCV[,"Family"])
>        lower    upper
> var1 0.2099238 1.529794
>
>
> I feel bad that I don't understand better how to specify the  
> components of these priors, but from what I understand, the model  
> should return similar values even if the priors are very different.  
> I've looked through the vignette thoroughly, but didn't get a sense  
> of what I was supposed to do if alternate priors returned different  
> answers. I'm not sure whether this is telling me that all the  
> information is coming from my priors (and there is, in fact, no  
> information in the data), or I am just incorrectly specifying my  
> priors.
>
> Any insight would be very much appreciated! Happy holidays,
>
> Cristina Ledon-Rettig
> UNC-Chapel Hill
>
> *I am using lme4 version 0.99375-28 with Mac OS X version 10.5
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From ssj1364 at gmail.com  Tue Nov 24 22:03:06 2009
From: ssj1364 at gmail.com (sj)
Date: Tue, 24 Nov 2009 13:03:06 -0800
Subject: [R-sig-ME] predict from glmer
Message-ID: <1c6126db0911241303w84d28b4tbf5aaf7a4a910e16@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20091124/fd549e72/attachment.pl>

From j.hadfield at ed.ac.uk  Wed Nov 25 08:08:55 2009
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Wed, 25 Nov 2009 07:08:55 +0000
Subject: [R-sig-ME] MCMCglmm and prior specification
In-Reply-To: <D8835F58-95DA-4ABD-A1A2-F3BB844276F3@ed.ac.uk>
References: <20091124114230.2vjzu6g4g0040w4g@webmail5.isis.unc.edu>
	<D8835F58-95DA-4ABD-A1A2-F3BB844276F3@ed.ac.uk>
Message-ID: <20091125070855.fwdco051c0wo4ssc@www.staffmail.ed.ac.uk>

Hi Cristina,

Sorry, yesterday I should have said

when V=0 & nu=-2 the MARGINAL posterior modes should be equal to the REML
estimates

not

when V=0 & nu=-2 the JOINT posterior modes should be equal to the REML
estimates

Cheers,

Jarrod
Sorry, yesterday I said
Quoting Jarrod Hadfield <j.hadfield at ed.ac.uk>:

> Dear Cristina,
>
> I am currently writing a better guide to MCMCglmm which deals more
> extensively with prior specifications - it should be ready soon.
>
> In your first prior you have fixed the residual variance to be V=1, so
> it's not surprising that this gives very different answers from models
> 2 and 3.
>
> Often variance components are sensitive to prior information, in part
> because the data may not contain much information but also because the
> inverse-Wishart prior used is not really flexible enough (again, I am
> working on this).
>
> The various improper priors often lead to numerical problems which
> precludes their use, but the resulting posterior does have some useful
> properties:
>
> when V=anything & nu=0 the joint posterior modes  should be equal to
> the ML estimate
> when V=0 & nu=-2 the joint posterior modes should be equal to the REML
> estimate (in practice you will have to use V=1e-6, or something small)
>
> A commonly used proper prior is V=1 & nu=0.002.  This is equivalent to
> the inverse gamma distribution with shape=scale=0.001. This was the
> "default" in WinBUGS for a while before Andrew Gelman showed why it
> shouldn't be - it can be informative if the variances are close to zero.
>
> Hope this helps,
>
> If anyone wants an unfinished copy of the MCMCglmm guide just email me.
>
> Jarod
>
>
>
> On 24 Nov 2009, at 16:42, ledonret at email.unc.edu wrote:
>
>> Dear all,
>>
>> I am trying to use the MCMCglmm package to create credibility   
>> intervals for random variables in my data. I'm having a bit of   
>> trouble though determining what the best prior to use for each   
>> model is, since the results seem to differ tremendously depending   
>> on which prior I am using, for instance, I've tried these three   
>> types of priors,
>>
>>> halfFam<-var(data$Family)/2
>>> prior1=list(R=list(V=1,n=1,fix=1),G=list(G1=list(V=1,n=1),G2=list(V=1,n=1)))
>>> prior2=list(R=list(V=1,n=1),G=list(G1=list(V=1,n=1),G2=list(V=1,n=1)))
>>> prior3=list(R=list(V=halfFam,n=1),G=list(G1=list(V=halfFam,n=1),G2=list(V=halfFam,n=1)))
>>
>> For the model,
>>> model<-MCMCglmm(Length~1,random=~Family+Rep,data=data,verbose=FALSE,prior=prior,burnin=10000,nitt=75000)
>>
>> Where the random factors are Family and Replicate.
>> From these priors, I get intervals for my Family effect,
>>
>>> HPDinterval(model1$VCV[,"Family"])
>>        lower     upper
>> var1 0.09660338 0.8888039
>>
>>> HPDinterval(model2$VCV[,"Family"])
>>       lower    upper
>> var1 0.1944570 2.120540
>>
>>> HPDinterval(model3$VCV[,"Family"])
>>       lower    upper
>> var1 0.2099238 1.529794
>>
>>
>> I feel bad that I don't understand better how to specify the   
>> components of these priors, but from what I understand, the model   
>> should return similar values even if the priors are very different.  
>>  I've looked through the vignette thoroughly, but didn't get a  
>> sense  of what I was supposed to do if alternate priors returned  
>> different  answers. I'm not sure whether this is telling me that  
>> all the  information is coming from my priors (and there is, in  
>> fact, no  information in the data), or I am just incorrectly  
>> specifying my  priors.
>>
>> Any insight would be very much appreciated! Happy holidays,
>>
>> Cristina Ledon-Rettig
>> UNC-Chapel Hill
>>
>> *I am using lme4 version 0.99375-28 with Mac OS X version 10.5
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>
> -- 
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From jstorracchi at utpl.edu.ec  Wed Nov 25 15:08:10 2009
From: jstorracchi at utpl.edu.ec (jstorracchi at utpl.edu.ec)
Date: Wed, 25 Nov 2009 09:08:10 -0500 (ECT)
Subject: [R-sig-ME] anova for lmer
Message-ID: <52439.138.100.88.217.1259158090.squirrel@mail.utpl.edu.ec>

Dear Partners

What is the quickest and easiest way to make an anova test to the outcome
lmer model.

Your sincerly.

Blgo. Esteban Toral


-----------------------------------------
This email was sent using SquirrelMail.
   "Webmail for nuts!"
http://squirrelmail.org/



From bz73 at cornell.edu  Wed Nov 25 16:24:50 2009
From: bz73 at cornell.edu (Ben Zuckerberg)
Date: Wed, 25 Nov 2009 10:24:50 -0500
Subject: [R-sig-ME] Extracting p-values from an lme object (any help would
	be appreciated)
Message-ID: <4B0D4C42.2090607@cornell.edu>

Greetings,

I know that p-value estimation in mixed models are somewhat 
controversial at the moment, but I am simply curious how one extracts 
p-values for the fixed factors from an lme object (using nlme)? The 
summary() gives the desired p-values; all I want to do is access them.  
The names() command shows the returned values (e.g., fitted, residuals) 
for many components of the model, but I can't seem to access the 
p-values.  Thank you in advance!



From datkins at U.WASHINGTON.EDU  Wed Nov 25 16:33:43 2009
From: datkins at U.WASHINGTON.EDU (David Atkins)
Date: Wed, 25 Nov 2009 07:33:43 -0800
Subject: [R-sig-ME] predict from glmer
In-Reply-To: <1c6126db0911241303w84d28b4tbf5aaf7a4a910e16@mail.gmail.com>
References: <1c6126db0911241303w84d28b4tbf5aaf7a4a910e16@mail.gmail.com>
Message-ID: <4B0D4E57.3080701@u.washington.edu>


Spencer--

Almost positive that your predictions are on the linear predictor scale 
(that is, logit of the response).  plogis() will get you the predicted 
probabilities.

Hope that helps.

cheers, Dave

-- 
Dave Atkins, PhD
Research Associate Professor
Center for the Study of Health and Risk Behaviors
Department of  Psychiatry and Behavioral Science
University of Washington
1100 NE 45th Street, Suite 300
Seattle, WA  98105
206-616-3879
datkins at u.washington.edu



From bolker at ufl.edu  Wed Nov 25 16:40:00 2009
From: bolker at ufl.edu (Ben Bolker)
Date: Wed, 25 Nov 2009 10:40:00 -0500
Subject: [R-sig-ME] Extracting p-values from an lme object (any help
 would be appreciated)
In-Reply-To: <4B0D4C42.2090607@cornell.edu>
References: <4B0D4C42.2090607@cornell.edu>
Message-ID: <4B0D4FD0.9070908@ufl.edu>

Ben Zuckerberg wrote:
> Greetings,
> 
> I know that p-value estimation in mixed models are somewhat 
> controversial at the moment, but I am simply curious how one extracts 
> p-values for the fixed factors from an lme object (using nlme)? The 
> summary() gives the desired p-values; all I want to do is access them.  
> The names() command shows the returned values (e.g., fitted, residuals) 
> for many components of the model, but I can't seem to access the 
> p-values.  Thank you in advance!
> 

library(nlme)
example(lme)
summary(fm1)$tTable[,"p-value"]



-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / www.zoology.ufl.edu/bolker
GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc



From adik at ilovebacon.org  Wed Nov 25 19:43:10 2009
From: adik at ilovebacon.org (Adam D. I. Kramer)
Date: Wed, 25 Nov 2009 10:43:10 -0800 (PST)
Subject: [R-sig-ME] Extracting p-values from an lme object (any help
 would be appreciated)
In-Reply-To: <4B0D4FD0.9070908@ufl.edu>
References: <4B0D4C42.2090607@cornell.edu> <4B0D4FD0.9070908@ufl.edu>
Message-ID: <Pine.LNX.4.64.0911251042510.31358@ilovebacon.org>


On Wed, 25 Nov 2009, Ben Bolker wrote:

> Ben Zuckerberg wrote:
>> I know that p-value estimation in mixed models are somewhat
>> controversial at the moment, but I am simply curious how one extracts
>> p-values for the fixed factors from an lme object (using nlme)? The
>> summary() gives the desired p-values; all I want to do is access them.
>> The names() command shows the returned values (e.g., fitted, residuals)
>> for many components of the model, but I can't seem to access the
>> p-values.  Thank you in advance!
>>
>
> library(nlme)
> example(lme)
> summary(fm1)$tTable[,"p-value"]

Or perhaps more simply,

pt(t, df, lower.tail)

gives you the p-value associated with a given t-value and its degrees of
freedom. lower.tail is whether you want the p below the t-value (usually you
want this when p is negative), or above. Multiply by 2 for a 2-tailed test.

summary() is almost certainly just calling pt().

--Adam



From kushler at oakland.edu  Wed Nov 25 20:47:39 2009
From: kushler at oakland.edu (Robert Kushler)
Date: Wed, 25 Nov 2009 14:47:39 -0500
Subject: [R-sig-ME] Extracting p-values from an lme object (any help
 would be appreciated)
In-Reply-To: <Pine.LNX.4.64.0911251042510.31358@ilovebacon.org>
References: <4B0D4C42.2090607@cornell.edu> <4B0D4FD0.9070908@ufl.edu>
	<Pine.LNX.4.64.0911251042510.31358@ilovebacon.org>
Message-ID: <4B0D89DB.5070904@oakland.edu>

Adam,

I'm sorry, I must jump in here.  See responses to specific points below.

Regards,   Rob Kushler



Adam D. I. Kramer wrote:
> 
> On Wed, 25 Nov 2009, Ben Bolker wrote:
> 
>> Ben Zuckerberg wrote:
>>> I know that p-value estimation in mixed models are somewhat
>>> controversial at the moment, but I am simply curious how one extracts
>>> p-values for the fixed factors from an lme object (using nlme)? The
>>> summary() gives the desired p-values; all I want to do is access them.
>>> The names() command shows the returned values (e.g., fitted, residuals)
>>> for many components of the model, but I can't seem to access the
>>> p-values.  Thank you in advance!
>>>
>>
>> library(nlme)
>> example(lme)
>> summary(fm1)$tTable[,"p-value"]
> 
> Or perhaps more simply,

     It's true that calling "pt" is a simple way to *compute* the
     p-values, but the question was how to *extract* them.  In general
     the ability to manipulate objects is a key advantage of R.

> 
> pt(t, df, lower.tail)
> 
> gives you the p-value associated with a given t-value and its degrees of
> freedom. lower.tail is whether you want the p below the t-value (usually 
> you want this when p is negative), or above.

     I think you mean "when t is negative" - but that's still not correct.
     You want "lower=TRUE" when the alternative hypothesis Ha says "<" and
     "lower=FALSE" when Ha says ">", regardless of the sign of t.

> Multiply by 2 for a 2-tailed test.


     Actually you need "2*pt(-abs(t), df, lower=TRUE)" to ensure a
     correct two-sided p-value.


> 
> summary() is almost certainly just calling pt().
> 
> --Adam
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From alice at blarg.net  Wed Nov 25 22:47:35 2009
From: alice at blarg.net (Alice Shelly)
Date: Wed, 25 Nov 2009 15:47:35 -0600
Subject: [R-sig-ME] correlation structure with glmer?
References: <8507A603412D4EC89FE2A36499CA4440@alicemobile>
	<40e66e0b0911231208v677f7ea9yd93aa906406ebd1f@mail.gmail.com>
Message-ID: <2628906AA5D341659897985728E17EA3@alicemobile>

Very good point, and it makes me wonder why and how other methods (like 
glmmPQL) are
providing results.
Thanks so much for your response and all your work in R!
Alice
----- Original Message ----- 
From: "Douglas Bates" <bates at stat.wisc.edu>
To: "Alice Shelly" <alice at blarg.net>
Cc: <r-sig-mixed-models at r-project.org>
Sent: Monday, November 23, 2009 2:08 PM
Subject: Re: [R-sig-ME] correlation structure with glmer?


> On Mon, Nov 23, 2009 at 1:32 PM, Alice Shelly <alice at blarg.net> wrote:
>> Hello-
>> Is there any way to introduce correlation structure into a glmer model?
>> I tried using
>> correlation = corAR1(form= ~age|plot)
>> as you would in lme, but I was ignored (so rude).
>
> Well, first you would need to decide how to define such a model.  It
> is not trivial.  For a linear mixed-effects model you can separately
> modify the specification of the mean and the variance of the
> conditional distribution of the response given the random effects.
> For common generalized linear mixed models (family = binomial or
> family = poisson) you can't.  Once you have the conditional
> independence assumption and you specify the conditional mean you have
> completely specified the conditional distribution.
>
>



From achaz.hardenberg at gmail.com  Wed Nov 25 12:35:36 2009
From: achaz.hardenberg at gmail.com (Achaz von Hardenberg)
Date: Wed, 25 Nov 2009 11:35:36 +0000
Subject: [R-sig-ME] different fits for geese and geeglm in geepack?
In-Reply-To: <C2B799BF-2FB5-4B55-B37F-D1E41EEEAB67@kjbeath.com.au>
References: <772cb06e0810011239xedce0e0ia55c225f9215db5c@mail.gmail.com>
	<C2B799BF-2FB5-4B55-B37F-D1E41EEEAB67@kjbeath.com.au>
Message-ID: <5B99CB3C-8D82-4CC6-9AFD-1A2B23D2B001@pngp.it>

>>
Dear all,

I am trying to fit a GEE model on eagle productivity (number of  
hatched offspring per nest) using the geeglm function in the library  
geepack and I found an odd result.
My understanding is that the function geese and geeglm should give the  
same fits, as actually geeglm uses geese to fit the model, providing a  
glm style output.
However, if I fit the same model with geeglm and geese I get slightly  
different estimates of the parameters. Most striking  is the  
difference between the estimates of the correlation parameter where  
the differences are huge:
(geese: alpha= -0.0727, se= 0.0608; geeglm:  -0.219, se=  0.091).

Anybody knows why this is like that and which of the two I should  
rather trust? (I attach the outputs of the two models at the end of  
this mail)

thanks a lot for your hints!

Achaz von Hardenberg

PS:
One more question actually: anybody has got some code to calculate the  
QICu values to compare GEE models with and without specific fixed  
factors using geepack?

##################
GEESE OUTPUT:

Call:
geese(formula = PROD ~ as.factor(clas3) + Twinter + Tprecova,
     id = Nterr, waves = anno, data = aquile.dat2, family = poisson,
     corstr = "ar1")

Mean Model:
  Mean Link:                 log
  Variance to Mean Relation: poisson

  Coefficients:
                   estimate san.se  wald        p
(Intercept)        -1.7850 0.3661 23.77 1.08e-06
as.factor(clas3)2   0.7165 0.2475  8.38 3.79e-03
as.factor(clas3)3   0.5052 0.3368  2.25 1.34e-01
Twinter            -0.1066 0.0464  5.28 2.16e-02
Tprecova           -0.0549 0.0368  2.22 1.36e-01

Scale Model:
  Scale Link:                identity

  Estimated Scale Parameters:
             estimate san.se wald        p
(Intercept)    0.764  0.123 38.6 5.17e-10

Correlation Model:
  Correlation Structure:     ar1
  Correlation Link:          identity

  Estimated Correlation Parameters:
       estimate san.se wald     p
alpha  -0.0727 0.0608 1.43 0.232

Returned Error Value:    0
Number of clusters:   21   Maximum cluster size: 20

###############################################
GEEGLM OUTPUT:

Call:
geeglm(formula = PROD ~ as.factor(clas3) + Twinter + Tprecova,
     family = poisson, data = aquile.dat2, id = Nterr, waves = anno,
     corstr = "ar1")

  Coefficients:
                   Estimate Std.err  Wald Pr(>|W|)
(Intercept)        -1.7992  0.3751 23.01  1.6e-06 ***
as.factor(clas3)2   0.7412  0.2623  7.99   0.0047 **
as.factor(clas3)3   0.5253  0.3335  2.48   0.1152
Twinter            -0.1083  0.0473  5.24   0.0220 *
Tprecova           -0.0483  0.0354  1.86   0.1721
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Estimated Scale Parameters:
             Estimate Std.err
(Intercept)    0.773   0.117

Correlation: Structure = ar1  Link = identity

Estimated Correlation Parameters:
       Estimate Std.err
alpha   -0.219   0.091
Number of clusters:   21   Maximum cluster size: 20


Dr. Achaz von Hardenberg
--------------------------------------------------------------------------------------------------------
Centro Studi Fauna Alpina - Alpine Wildlife Research Centre
Servizio Sanitario e della Ricerca Scientifica
Parco Nazionale Gran Paradiso, Degioz, 11, 11010-Valsavarenche (Ao),  
Italy

Present address:
National Centre for Statistical Ecology
School of Mathematics, Statistics and Actuarial Science,
University of Kent,  Canterbury, UK

E-mail: achaz.hardenberg at pngp.it
	     fauna at pngp.it
Skype: achazhardenberg
Mobile: +44.(0)783.266.5995



From dfowler at u.washington.edu  Wed Nov 25 23:39:42 2009
From: dfowler at u.washington.edu (Doug Fowler)
Date: Wed, 25 Nov 2009 14:39:42 -0800
Subject: [R-sig-ME] Dimension error message when using lmer()
Message-ID: <21701F9E-8724-4916-95A5-016E85C27FB6@u.washington.edu>

Dear list,

I am quite new to R and linear mixed models, and am struggling to fit  
some microarray data.  Here is what I am trying to do:

lmer(fittedResidual ~ logRatioAverage + logRatioAverage:condition +  
(1| logRatioAverage:array)

on the data set (also attached as a text file, if that helps):

         array condition systematicName logRatioAverage         
fittedresid     fittedResidual
6730   090409     Cond1        YHR055C      1.39287821    
1.38727125276748   1.38727125276748
7171   090909     Cond4        YHR055C     1.164289223    
1.15424383373922   1.15424383373922
7825   090909     Cond1        YHR055C     1.453747825    
1.44370243573922   1.44370243573922
12055  090409     Cond3        YHR055C      1.04792081    
1.04231385276748   1.04231385276748
25611  090409     Cond2        YHR055C   -0.4305436158  
-0.436150573032517 -0.436150573032517
26799  090909     Cond3        YHR055C     1.223053989    
1.21300859973922   1.21300859973922
51051  090409     Cond5        YHR055C   -0.6111279389  
-0.616734896132517 -0.616734896132517
56939  092909     Cond5        YHR055C   -0.3191377724  
-0.328468510731881 -0.328468510731881
79176  090909     Cond5        YHR055C   -0.3398805279  
-0.349925917160780 -0.349925917160780
87437  092909     Cond2        YHR055C   -0.2774113157  
-0.286742054031881 -0.286742054031881
93622  092909     Cond1        YHR055C    0.4629267583   
0.453596019968119  0.453596019968119
100011 092909     Cond6        YHR055C    0.2566897012   
0.247358962868119  0.247358962868119
100588 092909     Cond4        YHR055C     0.300567509   
0.291236770668119  0.291236770668119
105792 092909     Cond3        YHR055C    0.5033090594   
0.493978321068119  0.493978321068119
105796 090909     Cond2        YHR055C   -0.2170950589  
-0.227140448160780 -0.227140448160780
106182 090909     Cond6        YHR055C    0.8978423582    
0.88779696893922   0.88779696893922
107145 090409     Cond4        YHR055C     1.096596091    
1.09098913376748   1.09098913376748
18     090409     Cond6        YHR055C              NA                  
NA                 NA

produces the errors and warnings:

Error in validObject(.Object) :
   invalid class "mer" object: Slot Zt must by dims['q']  by  
dims['n']*dims['s']
In addition: Warning messages:
1: In logRatioAverage:array :
   numerical expression has 17 elements: only the first used
2: In logRatioAverage:array :
   numerical expression has 17 elements: only the first used

Any help diagnosing what I'm doing wrong or even advice about where  
some good resources are to be found would be greatly appreciated!

Thanks,

Doug

Douglas M. Fowler, Ph. D.
Department of Genome Sciences
University of Washington
dfowler at u.washington.edu


-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: example.txt
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20091125/13f47f63/attachment.txt>

From lborger at uoguelph.ca  Thu Nov 26 16:37:45 2009
From: lborger at uoguelph.ca (Luca Borger)
Date: Thu, 26 Nov 2009 10:37:45 -0500 (EST)
Subject: [R-sig-ME] Dimension error message when using lmer()
In-Reply-To: <581346900.29633121259248860683.JavaMail.root@huron.cs.uoguelph.ca>
Message-ID: <1884183590.29648501259249865921.JavaMail.root@huron.cs.uoguelph.ca>

Hello,

>>1: In logRatioAverage:array :
   numerical expression has 17 elements: only the first used

logRatioAverage and array are numbers which creates this error message when you write the random effects as xx:yy. Recode them as factor levels and the error message should disappear.

>>Error in validObject(.Object) :
   invalid class "mer" object: Slot Zt must by dims['q']  by  
dims['n']*dims['s']

are you fitting more random effects levels then data available? If I remember well this is when this error message pops up (please correct me if I'm wrong).


HTH


Cheers,

Luca


 

----- Original Message -----
From: "Doug Fowler" <dfowler at u.washington.edu>
To: r-sig-mixed-models at r-project.org
Sent: Wednesday, 25 November, 2009 17:39:42 GMT -05:00 US/Canada Eastern
Subject: [R-sig-ME] Dimension error message when using lmer()

Dear list,

I am quite new to R and linear mixed models, and am struggling to fit  
some microarray data.  Here is what I am trying to do:

lmer(fittedResidual ~ logRatioAverage + logRatioAverage:condition +  
(1| logRatioAverage:array)

on the data set (also attached as a text file, if that helps):

         array condition systematicName logRatioAverage         
fittedresid     fittedResidual
6730   090409     Cond1        YHR055C      1.39287821    
1.38727125276748   1.38727125276748
7171   090909     Cond4        YHR055C     1.164289223    
1.15424383373922   1.15424383373922
7825   090909     Cond1        YHR055C     1.453747825    
1.44370243573922   1.44370243573922
12055  090409     Cond3        YHR055C      1.04792081    
1.04231385276748   1.04231385276748
25611  090409     Cond2        YHR055C   -0.4305436158  
-0.436150573032517 -0.436150573032517
26799  090909     Cond3        YHR055C     1.223053989    
1.21300859973922   1.21300859973922
51051  090409     Cond5        YHR055C   -0.6111279389  
-0.616734896132517 -0.616734896132517
56939  092909     Cond5        YHR055C   -0.3191377724  
-0.328468510731881 -0.328468510731881
79176  090909     Cond5        YHR055C   -0.3398805279  
-0.349925917160780 -0.349925917160780
87437  092909     Cond2        YHR055C   -0.2774113157  
-0.286742054031881 -0.286742054031881
93622  092909     Cond1        YHR055C    0.4629267583   
0.453596019968119  0.453596019968119
100011 092909     Cond6        YHR055C    0.2566897012   
0.247358962868119  0.247358962868119
100588 092909     Cond4        YHR055C     0.300567509   
0.291236770668119  0.291236770668119
105792 092909     Cond3        YHR055C    0.5033090594   
0.493978321068119  0.493978321068119
105796 090909     Cond2        YHR055C   -0.2170950589  
-0.227140448160780 -0.227140448160780
106182 090909     Cond6        YHR055C    0.8978423582    
0.88779696893922   0.88779696893922
107145 090409     Cond4        YHR055C     1.096596091    
1.09098913376748   1.09098913376748
18     090409     Cond6        YHR055C              NA                  
NA                 NA

produces the errors and warnings:

Error in validObject(.Object) :
   invalid class "mer" object: Slot Zt must by dims['q']  by  
dims['n']*dims['s']
In addition: Warning messages:
1: In logRatioAverage:array :
   numerical expression has 17 elements: only the first used
2: In logRatioAverage:array :
   numerical expression has 17 elements: only the first used

Any help diagnosing what I'm doing wrong or even advice about where  
some good resources are to be found would be greatly appreciated!

Thanks,

Doug

Douglas M. Fowler, Ph. D.
Department of Genome Sciences
University of Washington
dfowler at u.washington.edu



_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From Thierry.ONKELINX at inbo.be  Thu Nov 26 16:38:55 2009
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Thu, 26 Nov 2009 16:38:55 +0100
Subject: [R-sig-ME] Dimension error message when using lmer()
In-Reply-To: <21701F9E-8724-4916-95A5-016E85C27FB6@u.washington.edu>
References: <21701F9E-8724-4916-95A5-016E85C27FB6@u.washington.edu>
Message-ID: <2E9C414912813E4EB981326983E0A10406D5C9AF@inboexch.inbo.be>

Dear Doug,

Since logRatioAverage is not a factor you get a random effect for each
levels. Hence you end up with more random effects than you can estimate
on the data. 

I suppose that you want a random intercept and a random slope along
logRatioAverage for each array. In that case the model looks like:

lmer(fittedResidual ~ logRatioAverage + logRatioAverage:condition +
(logRatioAverage|array)

HTH,

Thierry
------------------------------------------------------------------------
----
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek
team Biometrie & Kwaliteitszorg
Gaverstraat 4
9500 Geraardsbergen
Belgium

Research Institute for Nature and Forest
team Biometrics & Quality Assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium

tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to
say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of
data.
~ John Tukey

-----Oorspronkelijk bericht-----
Van: r-sig-mixed-models-bounces at r-project.org
[mailto:r-sig-mixed-models-bounces at r-project.org] Namens Doug Fowler
Verzonden: woensdag 25 november 2009 23:40
Aan: r-sig-mixed-models at r-project.org
Onderwerp: [R-sig-ME] Dimension error message when using lmer()

Dear list,

I am quite new to R and linear mixed models, and am struggling to fit
some microarray data.  Here is what I am trying to do:

lmer(fittedResidual ~ logRatioAverage + logRatioAverage:condition + (1|
logRatioAverage:array)

on the data set (also attached as a text file, if that helps):

         array condition systematicName logRatioAverage         
fittedresid     fittedResidual
6730   090409     Cond1        YHR055C      1.39287821    
1.38727125276748   1.38727125276748
7171   090909     Cond4        YHR055C     1.164289223    
1.15424383373922   1.15424383373922
7825   090909     Cond1        YHR055C     1.453747825    
1.44370243573922   1.44370243573922
12055  090409     Cond3        YHR055C      1.04792081    
1.04231385276748   1.04231385276748
25611  090409     Cond2        YHR055C   -0.4305436158  
-0.436150573032517 -0.436150573032517
26799  090909     Cond3        YHR055C     1.223053989    
1.21300859973922   1.21300859973922
51051  090409     Cond5        YHR055C   -0.6111279389  
-0.616734896132517 -0.616734896132517
56939  092909     Cond5        YHR055C   -0.3191377724  
-0.328468510731881 -0.328468510731881
79176  090909     Cond5        YHR055C   -0.3398805279  
-0.349925917160780 -0.349925917160780
87437  092909     Cond2        YHR055C   -0.2774113157  
-0.286742054031881 -0.286742054031881
93622  092909     Cond1        YHR055C    0.4629267583   
0.453596019968119  0.453596019968119
100011 092909     Cond6        YHR055C    0.2566897012   
0.247358962868119  0.247358962868119
100588 092909     Cond4        YHR055C     0.300567509   
0.291236770668119  0.291236770668119
105792 092909     Cond3        YHR055C    0.5033090594   
0.493978321068119  0.493978321068119
105796 090909     Cond2        YHR055C   -0.2170950589  
-0.227140448160780 -0.227140448160780
106182 090909     Cond6        YHR055C    0.8978423582    
0.88779696893922   0.88779696893922
107145 090409     Cond4        YHR055C     1.096596091    
1.09098913376748   1.09098913376748
18     090409     Cond6        YHR055C              NA                  
NA                 NA

produces the errors and warnings:

Error in validObject(.Object) :
   invalid class "mer" object: Slot Zt must by dims['q']  by
dims['n']*dims['s'] In addition: Warning messages:
1: In logRatioAverage:array :
   numerical expression has 17 elements: only the first used
2: In logRatioAverage:array :
   numerical expression has 17 elements: only the first used

Any help diagnosing what I'm doing wrong or even advice about where some
good resources are to be found would be greatly appreciated!

Thanks,

Doug

Douglas M. Fowler, Ph. D.
Department of Genome Sciences
University of Washington
dfowler at u.washington.edu



Druk dit bericht a.u.b. niet onnodig af.
Please do not print this message unnecessarily.

Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer 
en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is
door een geldig ondertekend document. The views expressed in  this message 
and any annex are purely those of the writer and may not be regarded as stating 
an official position of INBO, as long as the message is not confirmed by a duly 
signed document.



From pauljohn32 at gmail.com  Sat Nov 28 07:25:19 2009
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Sat, 28 Nov 2009 00:25:19 -0600
Subject: [R-sig-ME] different fits for geese and geeglm in geepack?
In-Reply-To: <5B99CB3C-8D82-4CC6-9AFD-1A2B23D2B001@pngp.it>
References: <772cb06e0810011239xedce0e0ia55c225f9215db5c@mail.gmail.com>
	<C2B799BF-2FB5-4B55-B37F-D1E41EEEAB67@kjbeath.com.au>
	<5B99CB3C-8D82-4CC6-9AFD-1A2B23D2B001@pngp.it>
Message-ID: <13e802630911272225v7e569aa7kc88f78802c7d4826@mail.gmail.com>

On Wed, Nov 25, 2009 at 5:35 AM, Achaz von Hardenberg
<achaz.hardenberg at gmail.com> wrote:
>>>
> Dear all,
>
> I am trying to fit a GEE model on eagle productivity (number of hatched
> offspring per nest) using the geeglm function in the library geepack and I
> found an odd result.
> My understanding is that the function geese and geeglm should give the same
> fits, as actually geeglm uses geese to fit the model, providing a glm style
> output.

If you gave us the exact commands that were run & the data, we could
probably figure this out.

I was interested to observe the problem you found, but can't reproduce
it.  I've installed geepack and run the examples for geese.fit, and
then too exact same options and put them inside geeglm. I get the
exact same results.

As a result, I think you have either not run exactly the same model in
the 2 cases, or geeglm is putting some settings in an unexpected way.

I think you will find your answer if you study the defaults as they
are set in geeglm.  Type

> geeglm

It will show the actual formula, you can see options that the function
is setting on your behalf. It appears to me geeglm assumes your link
function is identity, but the other might offer you the usual poisson
with a log link.

Then again, with a working example of geese.fit and geeglm that give
different estimates, I could probably get further.

-- 
Paul E. Johnson
Professor, Political Science
1541 Lilac Lane, Room 504
University of Kansas



From achaz.hardenberg at gmail.com  Sat Nov 28 16:23:01 2009
From: achaz.hardenberg at gmail.com (Achaz von Hardenberg)
Date: Sat, 28 Nov 2009 15:23:01 +0000
Subject: [R-sig-ME] test significance of single random effect
In-Reply-To: <4B030A8B.206@biology.leidenuniv.nl>
References: <4B01D445.2020606@biology.leidenuniv.nl>
	<4B01DF8E.1060100@ufl.edu>	 <4B0271B3.4000300@eva.mpg.de>
	<40e66e0b0911170903y67f57699pb002bb9500826f2f@mail.gmail.com>
	<4B030A8B.206@biology.leidenuniv.nl>
Message-ID: <E7D9F7E1-84DA-4C1F-B9D4-F6222564975E@pngp.it>

Dear all,
I am coming back on the recent issue on how to test the significance  
of a single random term in linear mixed models...

In Zuur et al.  "Mixed Models and Extentions in Ecology with R"  
Springer, 2009, the authors suggest to compare a lme model (with the  
random effect) with a gls model with the same fixed effects structure,  
and then compare the AICs of the two models or using a likelihood  
ratio test via the ANOVA comand (pages 122 - 128).

I would be interested in hearing the opinion of other members of the  
list on this approach...

Thanks a lot,

Achaz


On 17 Nov 2009, at 20:41, Tom Van Dooren wrote:

> With REML=FALSE RLRsim seems to work fine in R 2.10, if I use the  
> design matrix and Zt as arguments in LRTSim().
> Otherwise I didn't get useful results out.
>
> That's not too much of a problem.
> It is not difficult to simulate the null model without random  
> effect, extract logLikelihoods from the (generalized) mixed model  
> and the (generalized) linear model fitted to those pseudo-data, to  
> calculate a distribution of likelihood ratios,
> which are then maybe off by a constant.
> What I was mainly uncertain about, is whether the log-likelihood of  
> a mixed model (also fitted to data simulated from the null model  
> without random effect),
> can be used as a statistic itself?
> The answer might be a simple NO! of course, or something more  
> involved...
>
> Tom
>
>
> Douglas Bates wrote:
>> On Tue, Nov 17, 2009 at 3:49 AM, Matthias Gralle
>> <matthias_gralle at eva.mpg.de> wrote:
>>
>>> I had basically the same problem a short time ago, and resorted to  
>>> lme
>>> instead of lmer, because one can directly compare lme and lm  
>>> objects using
>>> anova(). Is that OK, or is this feature of lme depreciated ?
>>>
>>
>> Is that not possible for linear mixed-effects models fit by lmer  
>> using
>> REML = FALSE? (Occasionally I lose track of what can be done in
>> different versions of lme4.)  You don't want to compare an lmer model
>> fit by REML with the log-likelihood of an lm model but you should be
>> able to compare likelihoods (subject to the caveat that the p-value
>> for the likelihood ratio test on the boundary of the parameter space
>> is conservative).
>>
>>
>>> Ben Bolker wrote:
>>>
>>>> Have you tried the RLRsim package??
>>>>
>>>> Tom Van Dooren wrote:
>>>>
>>>>
>>>>> I tried to find an easy way to test whether the random effect  
>>>>> would be
>>>>> significant in a (generalized) mixed model with a single random  
>>>>> effect.
>>>>> It annoyed me that log-likelihoods of lm or glm and lmer are not
>>>>> necesarily directly comparable -> trouble with calculating  
>>>>> likelihood
>>>>> ratios.
>>>>> What do members of this list think of the following simulation  
>>>>> approach?
>>>>> It basically amounts to simulating a distribution for the log  
>>>>> likelihood,
>>>>> given the null hypothesis that there is no random effect  
>>>>> variance and that
>>>>> the fixed effect model is correct.
>>>>>
>>>>>
>>>>> library(lme4)
>>>>> mm1 <- lmer(Reaction ~ Days + (1|Subject), sleepstudy)
>>>>> lm1<- lm(Reaction ~ Days, sleepstudy)
>>>>>
>>>>>
>>>>> LL<-numeric(500)
>>>>> for(i in 1:500){
>>>>> resp<-simulate(lm1)
>>>>> LL[i]<-logLik(lmer(resp[,1] ~ Days + (1|Subject), sleepstudy))
>>>>> }
>>>>>
>>>>> hist(LL)
>>>>> logLik(mm1)
>>>>> mean(LL>logLik(mm1))
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>
>>>>>
>>>>
>>>>
>>> --
>>> Matthias Gralle, PhD
>>> Dept. Evolutionary Genetics
>>> Max Planck Institute for Evolutionary Anthropology
>>> Deutscher Platz 6
>>> 04103 Leipzig, Germany
>>> Tel +49 341 3550 519
>>> Fax +49 341 3550 555
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>

Dr. Achaz von Hardenberg
--------------------------------------------------------------------------------------------------------
Centro Studi Fauna Alpina - Alpine Wildlife Research Centre
Servizio Sanitario e della Ricerca Scientifica
Parco Nazionale Gran Paradiso, Degioz, 11, 11010-Valsavarenche (Ao),  
Italy

Present address:
National Centre for Statistical Ecology
School of Mathematics, Statistics and Actuarial Science,
University of Kent,  Canterbury, UK



From bolker at ufl.edu  Sun Nov 29 03:49:34 2009
From: bolker at ufl.edu (Ben Bolker)
Date: Sat, 28 Nov 2009 21:49:34 -0500
Subject: [R-sig-ME] test significance of single random effect
In-Reply-To: <E7D9F7E1-84DA-4C1F-B9D4-F6222564975E@pngp.it>
References: <4B01D445.2020606@biology.leidenuniv.nl>	<4B01DF8E.1060100@ufl.edu>	
	<4B0271B3.4000300@eva.mpg.de>	<40e66e0b0911170903y67f57699pb002bb9500826f2f@mail.gmail.com>	<4B030A8B.206@biology.leidenuniv.nl>
	<E7D9F7E1-84DA-4C1F-B9D4-F6222564975E@pngp.it>
Message-ID: <4B11E13E.3030105@ufl.edu>

  I think it will be conservative (in the sense of underestimating the
significance of the random effect), because of the well-known(?)
boundary issue (the null hypothesis for random effects, variance==0, is
on the boundary of the feasible space).

  I went a little overboard in testing this: see
<http://glmm.wikidot.com/random-effects-testing> , and feel free to
improve it ...

Achaz von Hardenberg wrote:
> Dear all,
> I am coming back on the recent issue on how to test the significance  
> of a single random term in linear mixed models...
> 
> In Zuur et al.  "Mixed Models and Extentions in Ecology with R"  
> Springer, 2009, the authors suggest to compare a lme model (with the  
> random effect) with a gls model with the same fixed effects structure,  
> and then compare the AICs of the two models or using a likelihood  
> ratio test via the ANOVA comand (pages 122 - 128).
> 
> I would be interested in hearing the opinion of other members of the  
> list on this approach...
> 
> Thanks a lot,
> 
> Achaz
> 
> 
> On 17 Nov 2009, at 20:41, Tom Van Dooren wrote:
> 
>> With REML=FALSE RLRsim seems to work fine in R 2.10, if I use the  
>> design matrix and Zt as arguments in LRTSim().
>> Otherwise I didn't get useful results out.
>>
>> That's not too much of a problem.
>> It is not difficult to simulate the null model without random  
>> effect, extract logLikelihoods from the (generalized) mixed model  
>> and the (generalized) linear model fitted to those pseudo-data, to  
>> calculate a distribution of likelihood ratios,
>> which are then maybe off by a constant.
>> What I was mainly uncertain about, is whether the log-likelihood of  
>> a mixed model (also fitted to data simulated from the null model  
>> without random effect),
>> can be used as a statistic itself?
>> The answer might be a simple NO! of course, or something more  
>> involved...
>>
>> Tom
>>
>>
>> Douglas Bates wrote:
>>> On Tue, Nov 17, 2009 at 3:49 AM, Matthias Gralle
>>> <matthias_gralle at eva.mpg.de> wrote:
>>>
>>>> I had basically the same problem a short time ago, and resorted to  
>>>> lme
>>>> instead of lmer, because one can directly compare lme and lm  
>>>> objects using
>>>> anova(). Is that OK, or is this feature of lme depreciated ?
>>>>
>>> Is that not possible for linear mixed-effects models fit by lmer  
>>> using
>>> REML = FALSE? (Occasionally I lose track of what can be done in
>>> different versions of lme4.)  You don't want to compare an lmer model
>>> fit by REML with the log-likelihood of an lm model but you should be
>>> able to compare likelihoods (subject to the caveat that the p-value
>>> for the likelihood ratio test on the boundary of the parameter space
>>> is conservative).
>>>
>>>
>>>> Ben Bolker wrote:
>>>>
>>>>> Have you tried the RLRsim package??
>>>>>
>>>>> Tom Van Dooren wrote:
>>>>>
>>>>>
>>>>>> I tried to find an easy way to test whether the random effect  
>>>>>> would be
>>>>>> significant in a (generalized) mixed model with a single random  
>>>>>> effect.
>>>>>> It annoyed me that log-likelihoods of lm or glm and lmer are not
>>>>>> necesarily directly comparable -> trouble with calculating  
>>>>>> likelihood
>>>>>> ratios.
>>>>>> What do members of this list think of the following simulation  
>>>>>> approach?
>>>>>> It basically amounts to simulating a distribution for the log  
>>>>>> likelihood,
>>>>>> given the null hypothesis that there is no random effect  
>>>>>> variance and that
>>>>>> the fixed effect model is correct.
>>>>>>
>>>>>>
>>>>>> library(lme4)
>>>>>> mm1 <- lmer(Reaction ~ Days + (1|Subject), sleepstudy)
>>>>>> lm1<- lm(Reaction ~ Days, sleepstudy)
>>>>>>
>>>>>>
>>>>>> LL<-numeric(500)
>>>>>> for(i in 1:500){
>>>>>> resp<-simulate(lm1)
>>>>>> LL[i]<-logLik(lmer(resp[,1] ~ Days + (1|Subject), sleepstudy))
>>>>>> }
>>>>>>
>>>>>> hist(LL)
>>>>>> logLik(mm1)
>>>>>> mean(LL>logLik(mm1))
>>>>>>
>>>>>> _______________________________________________
>>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>>
>>>>>>
>>>>>
>>>> --
>>>> Matthias Gralle, PhD
>>>> Dept. Evolutionary Genetics
>>>> Max Planck Institute for Evolutionary Anthropology
>>>> Deutscher Platz 6
>>>> 04103 Leipzig, Germany
>>>> Tel +49 341 3550 519
>>>> Fax +49 341 3550 555
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>>
> 
> Dr. Achaz von Hardenberg
> --------------------------------------------------------------------------------------------------------
> Centro Studi Fauna Alpina - Alpine Wildlife Research Centre
> Servizio Sanitario e della Ricerca Scientifica
> Parco Nazionale Gran Paradiso, Degioz, 11, 11010-Valsavarenche (Ao),  
> Italy
> 
> Present address:
> National Centre for Statistical Ecology
> School of Mathematics, Statistics and Actuarial Science,
> University of Kent,  Canterbury, UK
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / www.zoology.ufl.edu/bolker
GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc



From highstat at highstat.com  Sun Nov 29 12:36:06 2009
From: highstat at highstat.com (Highland Statistics Ltd.)
Date: Sun, 29 Nov 2009 12:36:06 +0100
Subject: [R-sig-ME] Mixed modelling course
Message-ID: <4B125CA6.1070701@highstat.com>

Dear list member,

There are 4 remaining seats on a 3-day mixed modelling course in 
Balmedie, Aberdeenshire, UK. 3-5 February 2009.
This is a non-technical course.

For further info, see the "Open courses in 2009 and 2010" section at:

http://www.highstat.com/statscourse.htm


Kind regards,

Alain




-- 


Dr. Alain F. Zuur
First author of:

1. Analysing Ecological Data (2007).
Zuur, AF, Ieno, EN and Smith, GM. Springer. 680 p.
URL: www.springer.com/0-387-45967-7


2. Mixed effects models and extensions in ecology with R. (2009).
Zuur, AF, Ieno, EN, Walker, N, Saveliev, AA, and Smith, GM. Springer.
http://www.springer.com/life+sci/ecology/book/978-0-387-87457-9


3. A Beginner's Guide to R (2009).
Zuur, AF, Ieno, EN, Meesters, EHWG. Springer
http://www.springer.com/statistics/computational/book/978-0-387-93836-3


Other books: http://www.highstat.com/books.htm


Statistical consultancy, courses, data analysis and software
Highland Statistics Ltd.
6 Laverock road
UK - AB41 6FN Newburgh
Tel: 0044 1358 788177
Email: highstat at highstat.com
URL: www.highstat.com
URL: www.brodgar.com



From highstat at highstat.com  Sun Nov 29 12:36:23 2009
From: highstat at highstat.com (Highland Statistics Ltd.)
Date: Sun, 29 Nov 2009 12:36:23 +0100
Subject: [R-sig-ME] test significance of single random effect
In-Reply-To: <mailman.3.1259492401.11850.r-sig-mixed-models@r-project.org>
References: <mailman.3.1259492401.11850.r-sig-mixed-models@r-project.org>
Message-ID: <4B125CB7.8030006@highstat.com>


>    1. Re: test significance of single random effect
>       (Achaz von Hardenberg)
>    2. Re: test significance of single random effect (Ben Bolker)
>
>
> ----------------------------------------------------------------------
>
> Message: 1
> Date: Sat, 28 Nov 2009 15:23:01 +0000
> From: Achaz von Hardenberg <achaz.hardenberg at gmail.com>
> Subject: Re: [R-sig-ME] test significance of single random effect
> To: R Mixed Models <r-sig-mixed-models at r-project.org>
> Message-ID: <E7D9F7E1-84DA-4C1F-B9D4-F6222564975E at pngp.it>
> Content-Type: text/plain; charset=US-ASCII; format=flowed; delsp=yes
>
> Dear all,
> I am coming back on the recent issue on how to test the significance  
> of a single random term in linear mixed models...
>
> In Zuur et al.  "Mixed Models and Extentions in Ecology with R"  
> Springer, 2009, the authors suggest to compare a lme model (with the  
> random effect) with a gls model with the same fixed effects structure,  
> and then compare the AICs of the two models or using a likelihood  
> ratio test via the ANOVA comand (pages 122 - 128).
>
>   

See also Verbeke and Molenberghs (2000)... The correction for testing on 
the boundary is described on page 123 (and see also V&M) and is viewed 
as quick and dirty.

My question to you...why do you want to test the significance of a 
random term in a linear mixed model? Why not include it purely based on 
the design of the experiment?

Alain






> I would be interested in hearing the opinion of other members of the  
> list on this approach...
>
> Thanks a lot,
>
> Achaz
>
>
> On 17 Nov 2009, at 20:41, Tom Van Dooren wrote:
>
>   
>> With REML=FALSE RLRsim seems to work fine in R 2.10, if I use the  
>> design matrix and Zt as arguments in LRTSim().
>> Otherwise I didn't get useful results out.
>>
>> That's not too much of a problem.
>> It is not difficult to simulate the null model without random  
>> effect, extract logLikelihoods from the (generalized) mixed model  
>> and the (generalized) linear model fitted to those pseudo-data, to  
>> calculate a distribution of likelihood ratios,
>> which are then maybe off by a constant.
>> What I was mainly uncertain about, is whether the log-likelihood of  
>> a mixed model (also fitted to data simulated from the null model  
>> without random effect),
>> can be used as a statistic itself?
>> The answer might be a simple NO! of course, or something more  
>> involved...
>>
>> Tom
>>
>>
>> Douglas Bates wrote:
>>     
>>> On Tue, Nov 17, 2009 at 3:49 AM, Matthias Gralle
>>> <matthias_gralle at eva.mpg.de> wrote:
>>>
>>>       
>>>> I had basically the same problem a short time ago, and resorted to  
>>>> lme
>>>> instead of lmer, because one can directly compare lme and lm  
>>>> objects using
>>>> anova(). Is that OK, or is this feature of lme depreciated ?
>>>>
>>>>         
>>> Is that not possible for linear mixed-effects models fit by lmer  
>>> using
>>> REML = FALSE? (Occasionally I lose track of what can be done in
>>> different versions of lme4.)  You don't want to compare an lmer model
>>> fit by REML with the log-likelihood of an lm model but you should be
>>> able to compare likelihoods (subject to the caveat that the p-value
>>> for the likelihood ratio test on the boundary of the parameter space
>>> is conservative).
>>>
>>>
>>>       
>>>> Ben Bolker wrote:
>>>>
>>>>         
>>>>> Have you tried the RLRsim package??
>>>>>
>>>>> Tom Van Dooren wrote:
>>>>>
>>>>>
>>>>>           
>>>>>> I tried to find an easy way to test whether the random effect  
>>>>>> would be
>>>>>> significant in a (generalized) mixed model with a single random  
>>>>>> effect.
>>>>>> It annoyed me that log-likelihoods of lm or glm and lmer are not
>>>>>> necesarily directly comparable -> trouble with calculating  
>>>>>> likelihood
>>>>>> ratios.
>>>>>> What do members of this list think of the following simulation  
>>>>>> approach?
>>>>>> It basically amounts to simulating a distribution for the log  
>>>>>> likelihood,
>>>>>> given the null hypothesis that there is no random effect  
>>>>>> variance and that
>>>>>> the fixed effect model is correct.
>>>>>>
>>>>>>
>>>>>> library(lme4)
>>>>>> mm1 <- lmer(Reaction ~ Days + (1|Subject), sleepstudy)
>>>>>> lm1<- lm(Reaction ~ Days, sleepstudy)
>>>>>>
>>>>>>
>>>>>> LL<-numeric(500)
>>>>>> for(i in 1:500){
>>>>>> resp<-simulate(lm1)
>>>>>> LL[i]<-logLik(lmer(resp[,1] ~ Days + (1|Subject), sleepstudy))
>>>>>> }
>>>>>>
>>>>>> hist(LL)
>>>>>> logLik(mm1)
>>>>>> mean(LL>logLik(mm1))
>>>>>>
>>>>>> _______________________________________________
>>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>>
>>>>>>
>>>>>>             
>>>>>           
>>>> --
>>>> Matthias Gralle, PhD
>>>> Dept. Evolutionary Genetics
>>>> Max Planck Institute for Evolutionary Anthropology
>>>> Deutscher Platz 6
>>>> 04103 Leipzig, Germany
>>>> Tel +49 341 3550 519
>>>> Fax +49 341 3550 555
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>>
>>>>         
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>>
>>     
>
> Dr. Achaz von Hardenberg
> --------------------------------------------------------------------------------------------------------
> Centro Studi Fauna Alpina - Alpine Wildlife Research Centre
> Servizio Sanitario e della Ricerca Scientifica
> Parco Nazionale Gran Paradiso, Degioz, 11, 11010-Valsavarenche (Ao),  
> Italy
>
> Present address:
> National Centre for Statistical Ecology
> School of Mathematics, Statistics and Actuarial Science,
> University of Kent,  Canterbury, UK
>
>
>
> ------------------------------
>
> Message: 2
> Date: Sat, 28 Nov 2009 21:49:34 -0500
> From: Ben Bolker <bolker at ufl.edu>
> Subject: Re: [R-sig-ME] test significance of single random effect
> To: Achaz von Hardenberg <achaz.hardenberg at gmail.com>
> Cc: R Mixed Models <r-sig-mixed-models at r-project.org>
> Message-ID: <4B11E13E.3030105 at ufl.edu>
> Content-Type: text/plain; charset=ISO-8859-1
>
>   I think it will be conservative (in the sense of underestimating the
> significance of the random effect), because of the well-known(?)
> boundary issue (the null hypothesis for random effects, variance==0, is
> on the boundary of the feasible space).
>
>   I went a little overboard in testing this: see
> <http://glmm.wikidot.com/random-effects-testing> , and feel free to
> improve it ...
>
> Achaz von Hardenberg wrote:
>   
>> Dear all,
>> I am coming back on the recent issue on how to test the significance  
>> of a single random term in linear mixed models...
>>
>> In Zuur et al.  "Mixed Models and Extentions in Ecology with R"  
>> Springer, 2009, the authors suggest to compare a lme model (with the  
>> random effect) with a gls model with the same fixed effects structure,  
>> and then compare the AICs of the two models or using a likelihood  
>> ratio test via the ANOVA comand (pages 122 - 128).
>>
>> I would be interested in hearing the opinion of other members of the  
>> list on this approach...
>>
>> Thanks a lot,
>>
>> Achaz
>>
>>
>> On 17 Nov 2009, at 20:41, Tom Van Dooren wrote:
>>
>>     
>>> With REML=FALSE RLRsim seems to work fine in R 2.10, if I use the  
>>> design matrix and Zt as arguments in LRTSim().
>>> Otherwise I didn't get useful results out.
>>>
>>> That's not too much of a problem.
>>> It is not difficult to simulate the null model without random  
>>> effect, extract logLikelihoods from the (generalized) mixed model  
>>> and the (generalized) linear model fitted to those pseudo-data, to  
>>> calculate a distribution of likelihood ratios,
>>> which are then maybe off by a constant.
>>> What I was mainly uncertain about, is whether the log-likelihood of  
>>> a mixed model (also fitted to data simulated from the null model  
>>> without random effect),
>>> can be used as a statistic itself?
>>> The answer might be a simple NO! of course, or something more  
>>> involved...
>>>
>>> Tom
>>>
>>>
>>> Douglas Bates wrote:
>>>       
>>>> On Tue, Nov 17, 2009 at 3:49 AM, Matthias Gralle
>>>> <matthias_gralle at eva.mpg.de> wrote:
>>>>
>>>>         
>>>>> I had basically the same problem a short time ago, and resorted to  
>>>>> lme
>>>>> instead of lmer, because one can directly compare lme and lm  
>>>>> objects using
>>>>> anova(). Is that OK, or is this feature of lme depreciated ?
>>>>>
>>>>>           
>>>> Is that not possible for linear mixed-effects models fit by lmer  
>>>> using
>>>> REML = FALSE? (Occasionally I lose track of what can be done in
>>>> different versions of lme4.)  You don't want to compare an lmer model
>>>> fit by REML with the log-likelihood of an lm model but you should be
>>>> able to compare likelihoods (subject to the caveat that the p-value
>>>> for the likelihood ratio test on the boundary of the parameter space
>>>> is conservative).
>>>>
>>>>
>>>>         
>>>>> Ben Bolker wrote:
>>>>>
>>>>>           
>>>>>> Have you tried the RLRsim package??
>>>>>>
>>>>>> Tom Van Dooren wrote:
>>>>>>
>>>>>>
>>>>>>             
>>>>>>> I tried to find an easy way to test whether the random effect  
>>>>>>> would be
>>>>>>> significant in a (generalized) mixed model with a single random  
>>>>>>> effect.
>>>>>>> It annoyed me that log-likelihoods of lm or glm and lmer are not
>>>>>>> necesarily directly comparable -> trouble with calculating  
>>>>>>> likelihood
>>>>>>> ratios.
>>>>>>> What do members of this list think of the following simulation  
>>>>>>> approach?
>>>>>>> It basically amounts to simulating a distribution for the log  
>>>>>>> likelihood,
>>>>>>> given the null hypothesis that there is no random effect  
>>>>>>> variance and that
>>>>>>> the fixed effect model is correct.
>>>>>>>
>>>>>>>
>>>>>>> library(lme4)
>>>>>>> mm1 <- lmer(Reaction ~ Days + (1|Subject), sleepstudy)
>>>>>>> lm1<- lm(Reaction ~ Days, sleepstudy)
>>>>>>>
>>>>>>>
>>>>>>> LL<-numeric(500)
>>>>>>> for(i in 1:500){
>>>>>>> resp<-simulate(lm1)
>>>>>>> LL[i]<-logLik(lmer(resp[,1] ~ Days + (1|Subject), sleepstudy))
>>>>>>> }
>>>>>>>
>>>>>>> hist(LL)
>>>>>>> logLik(mm1)
>>>>>>> mean(LL>logLik(mm1))
>>>>>>>
>>>>>>> _______________________________________________
>>>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>>>
>>>>>>>
>>>>>>>               
>>>>> --
>>>>> Matthias Gralle, PhD
>>>>> Dept. Evolutionary Genetics
>>>>> Max Planck Institute for Evolutionary Anthropology
>>>>> Deutscher Platz 6
>>>>> 04103 Leipzig, Germany
>>>>> Tel +49 341 3550 519
>>>>> Fax +49 341 3550 555
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>
>>>>>
>>>>>           
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>>
>>>
>>>       
>> Dr. Achaz von Hardenberg
>> --------------------------------------------------------------------------------------------------------
>> Centro Studi Fauna Alpina - Alpine Wildlife Research Centre
>> Servizio Sanitario e della Ricerca Scientifica
>> Parco Nazionale Gran Paradiso, Degioz, 11, 11010-Valsavarenche (Ao),  
>> Italy
>>
>> Present address:
>> National Centre for Statistical Ecology
>> School of Mathematics, Statistics and Actuarial Science,
>> University of Kent,  Canterbury, UK
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>     
>
>
>   


-- 


Dr. Alain F. Zuur
First author of:

1. Analysing Ecological Data (2007).
Zuur, AF, Ieno, EN and Smith, GM. Springer. 680 p.
URL: www.springer.com/0-387-45967-7


2. Mixed effects models and extensions in ecology with R. (2009).
Zuur, AF, Ieno, EN, Walker, N, Saveliev, AA, and Smith, GM. Springer.
http://www.springer.com/life+sci/ecology/book/978-0-387-87457-9


3. A Beginner's Guide to R (2009).
Zuur, AF, Ieno, EN, Meesters, EHWG. Springer
http://www.springer.com/statistics/computational/book/978-0-387-93836-3


Other books: http://www.highstat.com/books.htm


Statistical consultancy, courses, data analysis and software
Highland Statistics Ltd.
6 Laverock road
UK - AB41 6FN Newburgh
Tel: 0044 1358 788177
Email: highstat at highstat.com
URL: www.highstat.com
URL: www.brodgar.com



From Fabian.Scheipl at stat.uni-muenchen.de  Mon Nov 30 09:40:23 2009
From: Fabian.Scheipl at stat.uni-muenchen.de (Fabian Scheipl)
Date: Mon, 30 Nov 2009 09:40:23 +0100
Subject: [R-sig-ME] test significance of single random effect
Message-ID: <4836bc6a0911300040g461983beid789580eaac6b07b@mail.gmail.com>

Comparing the AICs roughly corresponds to a LR-test with a level of
about .16 (Greven S, Kneib T(2009),
http://www.bepress.com/jhubiostat/paper202/), and the standard
likelihood ratio tests or F-tests will give you a (very) conservative
test (as you can see from Ben Bolker's GLMM -Wiki).

Package RLRsim provides an exact restricted likelihood ratio test for
testing single random effects in linear mixed models. It only works if
the random effect you're testing is uncorrelated with the remaining
random effects in the model, though.

HTH,
Fabian



From adik at ilovebacon.org  Tue Dec  1 07:30:48 2009
From: adik at ilovebacon.org (Adam D. I. Kramer)
Date: Mon, 30 Nov 2009 22:30:48 -0800 (PST)
Subject: [R-sig-ME] Mixed models and mediation
Message-ID: <Pine.LNX.4.64.0911302216440.5027@ilovebacon.org>

Hello,

 	Could anyone recommend a document or resource for doing a mediation
analysis for some glmer models?  I've seen a few hints of "mediation using
mixed models" in general online (something akin to "do a sobel test with the
estimates and standard errors, but bootstrap significance"), but no examples
of anybody doing this in R.

 	My research question is basically summarized like this: Does whether
a person (subjID) chooses an option offered to them (chosen) depend on the
value of that option (value) as well as how many options they've seen
already (option)?  Specifically, does adding "value" to the model partially
mediate the role that option plays?  There is also another nesting factor, a
between-subjects condition (thisDist), in which values are nested.

g <- glmer(chosen ~ option + value + (1|subjID) + (value|thisDist), data=r1,
family="binomial")

...my intuition would be to use boot() to randomly vary the levels of
"value" within each subject and re-run glmer() a few thousand times to
estimate a standard error for the fixed effect of "option" with something
like "value" in the model, but I wanted to see whether anybody had done an
analysis like this before I think too hard about reinventing the wheel.

Many thanks,
--
Adam D. I. Kramer
Ph.D. Candidate, Social Psychology
University of Oregon
adik at uoregon.edu



From baron at psych.upenn.edu  Tue Dec  1 12:32:45 2009
From: baron at psych.upenn.edu (Jonathan Baron)
Date: Tue, 1 Dec 2009 06:32:45 -0500
Subject: [R-sig-ME] Mixed models and mediation
In-Reply-To: <Pine.LNX.4.64.0911302216440.5027@ilovebacon.org>
References: <Pine.LNX.4.64.0911302216440.5027@ilovebacon.org>
Message-ID: <20091201113245.GA17121@psych.upenn.edu>

Adam,

The following article might help:

MacKinnon, D. P., Lockwood, C. M., Hoffman, J. M., West, S. G., &
Sheets, V. (2002).  A comparison of methods to test mediation and
other intervening variable effects.  Psychological Methods, 7, 83-104.

It argues that you can test mediation very simply by taking the
maximum of two p-values.  One is the regression of the mediator M on
the independent variable X.  The other is the coefficient for M when
the dependent variable Y is regressed on M and X.  This seems slightly
better than the Sobel test, and it may avoid the need for
bootstrapping.  (I have also run some simulations, and, indeed, this
method is very good.)

Another article by Lois Gelfand (2008?, maybe 2009) in "Journal of
General Psychology" reviews the more recent literature but does not (I
think) change the main conclusion.

So far as I can tell, the use of mixed models should not change these
conclusions.  You still have to get p-values, though.

Jon

On 11/30/09 22:30, Adam D. I. Kramer wrote:
> Hello,
> 
>  	Could anyone recommend a document or resource for doing a mediation
> analysis for some glmer models?  I've seen a few hints of "mediation using
> mixed models" in general online (something akin to "do a sobel test with the
> estimates and standard errors, but bootstrap significance"), but no examples
> of anybody doing this in R.
> 
>  	My research question is basically summarized like this: Does whether
> a person (subjID) chooses an option offered to them (chosen) depend on the
> value of that option (value) as well as how many options they've seen
> already (option)?  Specifically, does adding "value" to the model partially
> mediate the role that option plays?  There is also another nesting factor, a
> between-subjects condition (thisDist), in which values are nested.
> 
> g <- glmer(chosen ~ option + value + (1|subjID) + (value|thisDist), data=r1,
> family="binomial")
> 
> ...my intuition would be to use boot() to randomly vary the levels of
> "value" within each subject and re-run glmer() a few thousand times to
> estimate a standard error for the fixed effect of "option" with something
> like "value" in the model, but I wanted to see whether anybody had done an
> analysis like this before I think too hard about reinventing the wheel.
> 
> Many thanks,
> --
> Adam D. I. Kramer
> Ph.D. Candidate, Social Psychology
> University of Oregon
> adik at uoregon.edu
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Jonathan Baron, Professor of Psychology, University of Pennsylvania
Home page: http://www.sas.upenn.edu/~baron
Editor: Judgment and Decision Making (http://journal.sjdm.org)



From datkins at u.washington.edu  Tue Dec  1 22:22:09 2009
From: datkins at u.washington.edu (David Atkins)
Date: Tue, 01 Dec 2009 13:22:09 -0800
Subject: [R-sig-ME] Mixed models and mediation
In-Reply-To: <20091201113245.GA17121@psych.upenn.edu>
References: <20091201113245.GA17121@psych.upenn.edu>
Message-ID: <4B158901.20402@u.washington.edu>


Adam--

Not 100% sure what you're looking for, but a couple resources:

-- Krull and MacKinnon 2001 in Multivariate Behavioral Research describe 
mediation in multilevel designs

-- Shrout and Bolger 2002 in Psychological Methods discuss use of 
bootstrap to estimate SE of indirect effect

-- Kenny et al. 2004 in Evaluation Review present methods for mediation 
in longitudinal treatment designs, in which they extend the classic 
Baron and Kenny criteria, focusing on the c to c' change.

Hope that helps.

cheers, Dave

-- 
Dave Atkins, PhD
Research Associate Professor
Center for the Study of Health and Risk Behaviors
Department of  Psychiatry and Behavioral Science
University of Washington
1100 NE 45th Street, Suite 300
Seattle, WA  98105
206-616-3879
datkins at u.washington.edu



Adam,

The following article might help:

MacKinnon, D. P., Lockwood, C. M., Hoffman, J. M., West, S. G., &
Sheets, V. (2002).  A comparison of methods to test mediation and
other intervening variable effects.  Psychological Methods, 7, 83-104.

It argues that you can test mediation very simply by taking the
maximum of two p-values.  One is the regression of the mediator M on
the independent variable X.  The other is the coefficient for M when
the dependent variable Y is regressed on M and X.  This seems slightly
better than the Sobel test, and it may avoid the need for
bootstrapping.  (I have also run some simulations, and, indeed, this
method is very good.)

Another article by Lois Gelfand (2008?, maybe 2009) in "Journal of
General Psychology" reviews the more recent literature but does not (I
think) change the main conclusion.

So far as I can tell, the use of mixed models should not change these
conclusions.  You still have to get p-values, though.

Jon

On 11/30/09 22:30, Adam D. I. Kramer wrote:
 > Hello,
 >
 >  	Could anyone recommend a document or resource for doing a mediation
 > analysis for some glmer models?  I've seen a few hints of "mediation 
using
 > mixed models" in general online (something akin to "do a sobel test 
with the
 > estimates and standard errors, but bootstrap significance"), but no 
examples
 > of anybody doing this in R.
 >
 >  	My research question is basically summarized like this: Does whether
 > a person (subjID) chooses an option offered to them (chosen) depend 
on the
 > value of that option (value) as well as how many options they've seen
 > already (option)?  Specifically, does adding "value" to the model 
partially
 > mediate the role that option plays?  There is also another nesting 
factor, a
 > between-subjects condition (thisDist), in which values are nested.
 >
 > g <- glmer(chosen ~ option + value + (1|subjID) + (value|thisDist), 
data=r1,
 > family="binomial")
 >
 > ...my intuition would be to use boot() to randomly vary the levels of
 > "value" within each subject and re-run glmer() a few thousand times to
 > estimate a standard error for the fixed effect of "option" with something
 > like "value" in the model, but I wanted to see whether anybody had 
done an
 > analysis like this before I think too hard about reinventing the wheel.
 >
 > Many thanks,
 > --
 > Adam D. I. Kramer
 > Ph.D. Candidate, Social Psychology
 > University of Oregon
 > adik at uoregon.edu
 >
 > _______________________________________________
 > R-sig-mixed-models at r-project.org mailing list
 > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Jonathan Baron, Professor of Psychology, University of Pennsylvania
Home page: http://www.sas.upenn.edu/~baron
Editor: Judgment and Decision Making (http://journal.sjdm.org)



From gwynwilson3 at hotmail.com  Wed Dec  2 08:00:44 2009
From: gwynwilson3 at hotmail.com (Gwyneth Wilson)
Date: Wed, 2 Dec 2009 09:00:44 +0200
Subject: [R-sig-ME] lmer models-confusing results??
Message-ID: <BLU139-W180DB8C2DAEB2EE56647A2FB950@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20091202/136a4536/attachment.pl>

From gwynwilson3 at hotmail.com  Wed Dec  2 08:53:27 2009
From: gwynwilson3 at hotmail.com (Gwyneth Wilson)
Date: Wed, 2 Dec 2009 09:53:27 +0200
Subject: [R-sig-ME] How do I test for overdispersion with a binomial glmm?
Message-ID: <BLU139-W2001F1D2F1E8B3BFA48D42FB950@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20091202/11f27366/attachment.pl>

From gwynwilson3 at hotmail.com  Wed Dec  2 07:57:33 2009
From: gwynwilson3 at hotmail.com (Gwyneth Wilson)
Date: Wed, 2 Dec 2009 08:57:33 +0200
Subject: [R-sig-ME] Question about lmer - confounding results?!
Message-ID: <BLU139-W16BEDF75CDBAC6D74999FAFB950@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20091202/55db28c5/attachment.pl>

From j.hadfield at ed.ac.uk  Wed Dec  2 19:29:37 2009
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Wed, 2 Dec 2009 18:29:37 +0000
Subject: [R-sig-ME] BUG in MCMCglmm
Message-ID: <E59DED5D-D290-4BB1-8432-548D92051DE8@ed.ac.uk>

Hi,

Sorry - I have found a bug in MCMCglmm which may effect results from  
ordinal models with 3 or more categories. In some cases the effect  
will be small and may not be obvious.  Binary probit models using  
family="ordinal" are fine.

I will update the package soon - but I am close to finishing a  
substantial upgrade so will probably wait till then.

Cheers,

Jarrod



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From weigand.stephen at gmail.com  Thu Dec  3 00:36:57 2009
From: weigand.stephen at gmail.com (Stephen Weigand)
Date: Wed, 2 Dec 2009 17:36:57 -0600
Subject: [R-sig-ME] Analyzing hierarchical MRI data
Message-ID: <bc47d3330912021536i833d285ue7c1a07cd9909c0@mail.gmail.com>

Hello,

I'd like to explore ways to analyze data from brain MRIs using lmer.

My data are typically of the following form:

* There are a small number of groups (e.g., disease 1, disease 2,
control) with from 10 to 50 human subjects in each group.

* Each subject has had an MRI of the head. From the MRI I get one
value at each of 30 different regions of the brain (e.g., a value for
the amygdala, a value for the hippocampus, etc.). This value is
typically an estimate of the region size. So I get 30 values for each
subject. These values are typically conditionally Gaussian. My data
frame may look like this

group subject region y
A Subj1 Amygdala 2.5
A Subj1 Hippocampus 2.8
A Subj2 Amygdala 3.2
A Subj2 Hippocampus 4.8
...
B Subj3 Amygdala 1.7
B Subj3 Hippocampus 4.9
B Subj4 Amygdala 2.2
B Subj4 Hippocampus 3.5
...

The question is, In which regions do the groups differ and by how much?

I can treat group and region as fixed effects by arguing that they are
the only groups and regions of interest and fit a random intercept
model with a group by region interaction of the form:

lmer(y ~ group*region + (1 | subject))

But I would like to take advantage of pooling/penalization/shrinkage
to get more reliable estimates of the differences between groups at
each region.  So I think I want to turn region (and maybe group?) into
random effects.

I want to try

lmer(y ~ (1 | group) + (1 | region) + (1 | subject))

but is that ignoring the nested structure of the data? I would greatly
appreciate suggestions.

Thank you,

Stephen

PS I'm OK with ignoring spatial correlation for now although I expect
that regions that are close to one another in the brain are going to
be more correlated than regions at opposite sides of the brain.

PPS I would guess that to the experts these questions seem all the
same but to the uninitiated, every problem seems like a unique case!!

-- 
Rochester, Minn. USA



From gwynwilson3 at hotmail.com  Thu Dec  3 07:33:23 2009
From: gwynwilson3 at hotmail.com (Gwyneth Wilson)
Date: Thu, 3 Dec 2009 08:33:23 +0200
Subject: [R-sig-ME] lmer models-confusing results - more information!
Message-ID: <BLU139-W20698BCF1B76DA57159E01FB940@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20091203/37a3f84b/attachment.pl>

From j.hadfield at ed.ac.uk  Thu Dec  3 11:19:31 2009
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Thu, 3 Dec 2009 10:19:31 +0000
Subject: [R-sig-ME] lmer models-confusing results - more information!
In-Reply-To: <BLU139-W20698BCF1B76DA57159E01FB940@phx.gbl>
References: <BLU139-W20698BCF1B76DA57159E01FB940@phx.gbl>
Message-ID: <EA49A8CE-4EAD-4079-8C39-C72C4DE0295B@ed.ac.uk>

Dear Gwyneth,

Since you're not getting any answers - I'l give it a go, at the risk  
of being wrong.

The likelihood for non-Gaussian GLMM cannot be obtained in closed  
form  and needs to be approximated. Often the approximation is good,  
but in some cases it can be bad, particularly with binary data when  
the incidence is extreme (low/high) and/or there is little replication  
within factor levels. In extreme cases the parameter estimates +/- the  
2*SE's do not even include the "true" values.

 From your fixed effect summary it appears that reproductive successes  
within some factor levels are all zero. If this is the case, this may  
well be what is causing the problem and treating year as a random  
effect may help. MCMC solutions are probably more robust for these  
types of data because they use approximations which get more exact the  
longer you run the analysis.

With regards to an earlier  email, over-dispersed binary data does not  
occur, because the mean determines the variance completely. This does  
not mean that the probability of success is constant (after  
conditioning on the model), it just means that any heterogeneity  
cannot be observed and therefore estimated. In short, you don't need  
to worry about it.

Cheers,

Jarrod








On 3 Dec 2009, at 06:33, Gwyneth Wilson wrote:

>
> I have been running lmer models in R, looking at what effects  
> reproductive success in Ground Hornbills (a South African Bird). My  
> response variable is breeding success and is binomial (0-1) and my  
> random effect is group ID. My response variables include rainfall,  
> vegetation, group size, year, nests, and proportion of open woodland.
>
> I have run numerous models with success but I am confused about what  
> the outputs are. When I run my first model with all my variables  
> (all additive) then i get a low AIC value with only a few of the  
> variables being significant. When i take out the varaibles that are  
> not significant then my AIC becomes higher but I have more  
> significant variables! When I keep taking out the unsignificant  
> variables, I am left with a model that has nests, open woodland, and  
> group size as being extremely significant BUT the AIC is high! Why  
> is my AIC value increasing when I have fewer varaibles that are all  
> significant and seem to be best explaining my data? Do i look at  
> only the AIC when choosing the 'best' model or do I look at only the  
> p-values? or both? The model with the lowest AIC at the moment has  
> the most variables and most are not significant?
>
> Please help. Any suggestions would be great!!
>
>
>
> Here is some more information and some of my outputs:
>
>
>
> The first model has all my variables included and i get a low AIC  
> with only grp.sz and wood being significant:
>
>
>
> model1<-lmer(br.su~factor(art.n)+factor(yr)+grp.sz+rain+veg+wood+(1| 
> grp.id),data=hornbill,family=binomial)
>> summary(model1)
> Generalized linear mixed model fit by the Laplace approximation
> Formula: br.su ~ factor(art.n) + factor(yr) + grp.sz + rain + veg +  
> wood +      (1 | grp.id)
>   Data: hornbill
>   AIC   BIC    logLik   deviance
> 138.5 182.3  -55.26    110.5
> Random effects:
> Groups Name   Variance Std.Dev.
> grp.id (Intercept) 1.2913   1.1364
> Number of obs: 169, groups: grp.id, 23
>
> Fixed effects:
>                  Estimate      Std. Error  z value  Pr(>|z|)
> (Intercept)      -3.930736   3.672337  -1.070    0.2845
> factor(art.n)1  1.462829   0.903328   1.619     0.1054
> factor(yr)2002 -2.592315   1.764551  -1.469   0.1418
> factor(yr)2003 -3.169365   1.759981  -1.801   0.0717 .
> factor(yr)2004  0.702210   1.341524   0.523   0.6007
> factor(yr)2005 -2.264257   1.722130  -1.315   0.1886
> factor(yr)2006  2.129728   1.270996   1.676   0.0938 .
> factor(yr)2007 -0.579961   1.390345  -0.417   0.6766
> factor(yr)2008 -1.062933   1.640774  -0.648   0.5171
> grp.sz             1.882616    0.368317   5.111   3.2e-07 ***
> rain                -0.005896   0.003561  -1.656   0.0977 .
> veg                 -1.993443   1.948738  -1.023   0.3063
> wood               6.832543   3.050573   2.240   0.0251 *
>
>
> Then i carry on and remove varaibles i think are not having an  
> influence on breeding success like the year, vegetation and rain.  
> And i get this:
>
> model3<-lmer(br.su~factor(art.n)+grp.sz+wood+(1| 
> grp.id),data=hornbill,family=binomial)
>> summary(model3)
> Generalized linear mixed model fit by the Laplace approximation
> Formula: br.su ~ factor(art.n) + grp.sz + wood + (1 | grp.id)
>   Data: hornbill
>   AIC    BIC    logLik deviance
> 143.8  159.4  -66.88    133.8
> Random effects:
> Groups Name        Variance Std.Dev.
> grp.id (Intercept)     0.75607  0.86953
> Number of obs: 169, groups: grp.id, 23
>
> Fixed effects:
>                   Estimate Std. Error  z value   Pr(>|z|)
> (Intercept)      -8.6619     1.3528   -6.403   1.52e-10 ***
> factor(art.n)1   1.5337     0.6420    2.389    0.0169 *
> grp.sz            1.6631     0.2968    5.604    2.09e-08 ***
> wood              3.2177     1.5793    2.037   0.0416 *
>
> So all the variables are significant but the AIC value is higher!
>
> I thought that with fewer variables and they are all showing  
> significance which means they are influencing breeding success-then  
> why is my AIC higher in this model??
> Do i only look at the AIC values and ignore the p-values? or only  
> look at the p-values??
>
> Thanks!!
>
>
> 		 	   		
> _________________________________________________________________
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From gwynwilson3 at hotmail.com  Thu Dec  3 12:12:33 2009
From: gwynwilson3 at hotmail.com (Gwyneth Wilson)
Date: Thu, 3 Dec 2009 13:12:33 +0200
Subject: [R-sig-ME] Summary output for lmer
Message-ID: <BLU139-W3082D288F313D5DBC48C47FB940@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20091203/e303c2cf/attachment.pl>

From robert.espesser at lpl-aix.fr  Thu Dec  3 12:22:09 2009
From: robert.espesser at lpl-aix.fr (espesser)
Date: Thu, 03 Dec 2009 12:22:09 +0100
Subject: [R-sig-ME] z transform versus random intercept
Message-ID: <4B179F61.2050209@lpl-aix.fr>

Dear all

In my domain (phonetics) , it is usual to z-transform the response
(i.e. using  scale( ... ,scale=T)   -by subjects, for example-  )
before doing classical regression analysis. I'm not awared enough in 
statistics to
see and explain all the statistical and fundamental differences there 
are between this approach
and mixed models.

For example , with the data "sleepstudy" from package lme4, is there 
something wrong or
dubious  with the following model ?  :

 
(a)    lm ( zreaction ~ Days ,data=sleepstudy)  

where zreaction is   Reaction   scaled by Subject.


to be compared with:

(b)    lmer( Reaction ~Days +(1|Subject), data=sleepstudy)


 (a) still considers all the z-measures as independant, and I think that
it is still "dubious" , despite the fact that after the scaling, all the 
zreaction
have a  mean==0 and a sd ==1. Am I right ?

Apparently, there are no differences between (a) and the following mixed 
model :

(c) lmer(zreac ~ Days + (1 | Subject) ...)

(Of course this last  model found a null variance inter-subject).

Would differences be appeared if  I run simulations on (a) ,(b) and (c) 
to test
the effect of Days ?

I'm looking for "good" arguments to convince my colleagues that
mixed model is a better way than z-transform, even for such a simple model,
for which it would be not only an easier or more elegant way to do the 
same .

(I know that the "good model" is the mixed model with a random slope, 
and that
this time  the "z-model" and the mixed one cannot be compared )


Thank you for your help.


Dear all

In my domain (phonetics) , it is usual to z-transform the response
(i.e. using  scale( )   -by subjects, for example-  )
before doing classical regression analysis. I'm not awared enough in 
statistics to
see and explain all the statistical and fundamental differences there 
are between this approach
and mixed models.

For example , with the data "sleepstudy" from package lme4, is there 
something wrong or
dubious  with the following model ?  :

 
(a)    lm( zreaction ~ Days ,data=sleepstudy) 

where zreaction is   Reaction   scaled by Subject.


to be compared with:

(b)    lmer( Reaction ~Days +(1|Subject), data=sleepstudy)


 (a) still considers all the z-measures as independant, and I think that
it is still "dubious" , despite the fact that after the scaling, all the 
zreaction
have a  mean==0 and a sd ==1. Am I right ?

Apparently, there are no differences between (a) and the following mixed 
model :

(c) lmer(zreac ~ Days + (1 | Subject) ...)

(Of course this last  model found a null variance inter-subject).

Would differences be appeared if  I run simulations on (a) ,(b) and (c) 
to test
the effect of Days ?

I'm looking for "good" arguments to convince my colleagues that
mixed model is a better way than z-transform, even for such a simple model,
for which it would be not only an easier or more elegant way to do the 
same .

(I know that the "good model" is the mixed model with a random slope, 
and that
this time  the "z-model" and the mixed one cannot be compared )


Thank you for your help.


######   output from   classical lm   on z scaling data

Dear all

In my domain (phonetics) , it is usual to z-transform the response
(i.e. using  scale( )   -by subjects, for example-  )
before doing classical regression analysis. I'm not awared enough in 
statistics to
see and explain all the statistical and fundamental differences there 
are between this approach
and mixed models.

For example , with the data "sleepstudy" from package lme4, is there 
something wrong or
dubious  with the following model ?  :

 
(a)    lm( zreaction ~ Days ,data=sleepstudy) 

where zreaction is   Reaction   scaled by Subject.


to be compared with:

(b)    lmer( Reaction ~Days +(1|Subject), data=sleepstudy)


the model (a) still considers all the z-measures as independant, and I 
think that
it is still "dubious" , despite the fact that after the scaling, all the 
zreaction
have a  mean==0 and a sd ==1. Am I right ?

Apparently, there are no differences between (a) and the following mixed 
model :

(c) lmer(zreac ~ Days + (1 | Subject) ...)

(Of course this last  model found a null variance inter-subject).

Am I wrong when I expect some (hidden) differences betwenn (a) and (c) ?

Would differences be appeared if  I run simulations on (a) ,(b) and (c) 
to test
the effect of Days ? 
 

I'm looking for "good" arguments to convince my colleagues that
mixed model is a better way than z-transform for such a simple model,
for which it would be not only an easier or more elegant way to do the 
same .
(I know that the "good model" is the mixed model with a random slope, 
and that
this time  the "z-model" and the mixed one cannot be compared )


Thank you for your help.


######   : output from   classical lm   on the z-scaled data ,model (a)

 > summary( fm0z.lm)

Call:
lm(formula = zreac ~ Days, data = zsleep)

Residuals:
     Min       1Q   Median       3Q      Max
-1.98864 -0.36035  0.01233  0.35292  2.55175

Coefficients:
            Estimate Std. Error t value Pr(>|t|)   
(Intercept) -1.06168    0.09249  -11.48   <2e-16 ***
Days         0.23593    0.01733   13.62   <2e-16 ***


Residual standard error: 0.6676 on 178 degrees of freedom

###  output from lmer on z-scaled data  , model (c)

 > summary( fm0z.lmer)
Linear mixed model fit by REML
Formula: zreac ~ Days + (1 | Subject)
   Data: zsleep
   AIC   BIC logLik deviance REMLdev
 381.8 394.6 -186.9    363.4   373.8
Random effects:
 Groups   Name        Variance Std.Dev.
 Subject  (Intercept) 0.00000  0.00000
 Residual             0.44574  0.66764
Number of obs: 180, groups: Subject, 18

Fixed effects:
            Estimate Std. Error t value
(Intercept) -1.06168    0.09249  -11.48
Days         0.23593    0.01733   13.62

Correlation of Fixed Effects:
     (Intr)
Days -0.843



From m.fairbrother at bristol.ac.uk  Thu Dec  3 13:08:05 2009
From: m.fairbrother at bristol.ac.uk (Malcolm Fairbrother)
Date: Thu, 3 Dec 2009 12:08:05 +0000
Subject: [R-sig-ME] R-sig-mixed-models Digest, Vol 36, Issue 3
In-Reply-To: <mailman.5.1259838002.28855.r-sig-mixed-models@r-project.org>
References: <mailman.5.1259838002.28855.r-sig-mixed-models@r-project.org>
Message-ID: <44425734-72EE-4832-BA33-3751044C42E8@bristol.ac.uk>

Dear Stephen,

If I understand correctly, you're trying to estimate the unique effect of group for each specific region, while also taking into account what you know about overall differences across individuals (since, I presume, individuals with a large region 1 will also tend to have larger regions 2-30, etc.).

To me, that implies:

lmer(y ~ group + (group | region) + (1 | subject))

This will get you a random (unique) intercept for each subject and each region, and a unique effect of (each level of) group for each separate region, net of the average effect of group across all regions, captured by the fixed effect. The unique effect is your primary interest, as I take it.

Hope that's useful.

Cheers,
Malcolm


Dr Malcolm Fairbrother
Lecturer in Global Policy and Politics
School of Geographical Sciences
University of Bristol



> Message: 3
> Date: Wed, 2 Dec 2009 17:36:57 -0600
> From: Stephen Weigand <weigand.stephen at gmail.com>
> Subject: [R-sig-ME] Analyzing hierarchical MRI data
> To: r-sig-mixed-models at r-project.org
> Message-ID:
> 	<bc47d3330912021536i833d285ue7c1a07cd9909c0 at mail.gmail.com>
> Content-Type: text/plain; charset=ISO-8859-1
> 
> Hello,
> 
> I'd like to explore ways to analyze data from brain MRIs using lmer.
> 
> My data are typically of the following form:
> 
> * There are a small number of groups (e.g., disease 1, disease 2,
> control) with from 10 to 50 human subjects in each group.
> 
> * Each subject has had an MRI of the head. From the MRI I get one
> value at each of 30 different regions of the brain (e.g., a value for
> the amygdala, a value for the hippocampus, etc.). This value is
> typically an estimate of the region size. So I get 30 values for each
> subject. These values are typically conditionally Gaussian. My data
> frame may look like this
> 
> group subject region y
> A Subj1 Amygdala 2.5
> A Subj1 Hippocampus 2.8
> A Subj2 Amygdala 3.2
> A Subj2 Hippocampus 4.8
> ...
> B Subj3 Amygdala 1.7
> B Subj3 Hippocampus 4.9
> B Subj4 Amygdala 2.2
> B Subj4 Hippocampus 3.5
> ...
> 
> The question is, In which regions do the groups differ and by how much?
> 
> I can treat group and region as fixed effects by arguing that they are
> the only groups and regions of interest and fit a random intercept
> model with a group by region interaction of the form:
> 
> lmer(y ~ group*region + (1 | subject))
> 
> But I would like to take advantage of pooling/penalization/shrinkage
> to get more reliable estimates of the differences between groups at
> each region.  So I think I want to turn region (and maybe group?) into
> random effects.
> 
> I want to try
> 
> lmer(y ~ (1 | group) + (1 | region) + (1 | subject))
> 
> but is that ignoring the nested structure of the data? I would greatly
> appreciate suggestions.
> 
> Thank you,
> 
> Stephen
> 
> PS I'm OK with ignoring spatial correlation for now although I expect
> that regions that are close to one another in the brain are going to
> be more correlated than regions at opposite sides of the brain.
> 
> PPS I would guess that to the experts these questions seem all the
> same but to the uninitiated, every problem seems like a unique case!!
> 
> -- 
> Rochester, Minn. USA



From matejus106 at googlemail.com  Thu Dec  3 13:10:31 2009
From: matejus106 at googlemail.com (jos matejus)
Date: Thu, 3 Dec 2009 12:10:31 +0000
Subject: [R-sig-ME] randomized block design model specification
Message-ID: <d003a00f0912030410x38bf4a6bqadc2b771763b7cff@mail.gmail.com>

Dear list members,

Could anyone shed some illumination on the best way to specify a model
with the following experimental design?

Briefly, I have 75 individual rats, 47 of which are lactating and  18
are non reproductive. I measured the gene expression of 6 genes for
each rat. The underlying research question is whether the gene
expression of rats is different depending on reproductive status and
whether this varies between genes. Many of the 7 genes are strongly
correlated.

My first approach was to use a simple linear model with gene
expression as the response variable and reproductive status and geneID
as explanatory variables. Something like:

M1.lm <- lm(expression ~ reprostatus*geneID)

However, as the expression levels of the 6 genes were measured from
each rat, there is potentially an issue with non independence. I
therefore thought I could use the rat ID as a random effect. Something
like

M2.lme <- lmer(expression~reprostatus*geneID+(1|ratID)

My question is whether this seems like a sensible approach. I guess I
am confusing myself a little as I cant visualize the consequence of
having rat ID as a random effect as I only have one observation for
each rat gene combination. Also, does the above lmer model assume that
the reprostatus*geneID interaction in the fixed effects is the same
for each rat? If so, does it make sense to include this interaction in
the random effects term aswell? (although my intuition tells me I dont
have the replication for this)

Many thanks in advance for any advice offered
Cheers
Jos



From bates at stat.wisc.edu  Thu Dec  3 13:51:39 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 3 Dec 2009 06:51:39 -0600
Subject: [R-sig-ME] Summary output for lmer
In-Reply-To: <BLU139-W3082D288F313D5DBC48C47FB940@phx.gbl>
References: <BLU139-W3082D288F313D5DBC48C47FB940@phx.gbl>
Message-ID: <40e66e0b0912030451i3101097blae2ffb896886d98f@mail.gmail.com>

anova() provides a breakdown by terms but be aware that the terms are
regarded sequentially.  The coefficients table in some model summaries
(but not lmer summaries) provides p-values for a two-sided test on the
null hypothesis of a specific coefficient is zero.

On Thu, Dec 3, 2009 at 5:12 AM, Gwyneth Wilson <gwynwilson3 at hotmail.com> wrote:
>
> Is there a function in R that will include a table with the summary output that shows the p-values for all the factors and not the parameters.
>
>
>
> In my summary output for my models it gives a break down for each parameter with a p-value. So for my variable year there are 7 parameters (2002-2008) and a value for each. Is there any way of generating a summary that will show the effect of year as a whole not browkn up into each year! so what is the effect of year on my dependent variable?
>
>
>
> so instead of typing: summary(model1) is there some other way of extracting more information from the model?
>
>
>
> Thanks!
>
> _________________________________________________________________
>
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From bates at stat.wisc.edu  Thu Dec  3 16:12:42 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 3 Dec 2009 09:12:42 -0600
Subject: [R-sig-ME] z transform versus random intercept
In-Reply-To: <4B179F61.2050209@lpl-aix.fr>
References: <4B179F61.2050209@lpl-aix.fr>
Message-ID: <40e66e0b0912030712y64b1bcf6x44959355ee30db5e@mail.gmail.com>

As you can imagine the two models handle the variability between the
subjects very differently.  The use of scaling is a rather crude way
of handling this variability, which is understandable in that it
originated at a time when computing resources were much less powerful
than they are today.  The problem with scaling is that it is very
sensitive to the extreme observations, which are the ones that are
most likely to be outliers or in some way problematic.

The mixed-effects model determines the distribution of the random
effects for the subjects to balance fidelity to the data with
complexity of the model.  John Tukey referred to this as "borrowing
strength" between the subjects.  You assume that the subjects come
from a population of varying abilities and damp down the individual
estimates toward the population means, as long as doing so can produce
a reasonable fit.

If, like me, you think in pictures, you might find the slides at
http://lme4.r-forge.r-project.org/slides/2009-07-21-Seewiesen/5LongitudinalD.pdf
helpful in understanding this shrinkage idea.


On Thu, Dec 3, 2009 at 5:22 AM, espesser <robert.espesser at lpl-aix.fr> wrote:
> Dear all
>
> In my domain (phonetics) , it is usual to z-transform the response
> (i.e. using ?scale( ... ,scale=T) ? -by subjects, for example- ?)
> before doing classical regression analysis. I'm not awared enough in
> statistics to
> see and explain all the statistical and fundamental differences there are
> between this approach
> and mixed models.
>
> For example , with the data "sleepstudy" from package lme4, is there
> something wrong or
> dubious ?with the following model ? ?:
>
>
> (a) ? ?lm ( zreaction ~ Days ,data=sleepstudy)
> where zreaction is ? Reaction ? scaled by Subject.
>
>
> to be compared with:
>
> (b) ? ?lmer( Reaction ~Days +(1|Subject), data=sleepstudy)
>
>
> (a) still considers all the z-measures as independant, and I think that
> it is still "dubious" , despite the fact that after the scaling, all the
> zreaction
> have a ?mean==0 and a sd ==1. Am I right ?
>
> Apparently, there are no differences between (a) and the following mixed
> model :
>
> (c) lmer(zreac ~ Days + (1 | Subject) ...)
>
> (Of course this last ?model found a null variance inter-subject).
>
> Would differences be appeared if ?I run simulations on (a) ,(b) and (c) to
> test
> the effect of Days ?
>
> I'm looking for "good" arguments to convince my colleagues that
> mixed model is a better way than z-transform, even for such a simple model,
> for which it would be not only an easier or more elegant way to do the same
> .
>
> (I know that the "good model" is the mixed model with a random slope, and
> that
> this time ?the "z-model" and the mixed one cannot be compared )
>
>
> Thank you for your help.
>
>
> Dear all
>
> In my domain (phonetics) , it is usual to z-transform the response
> (i.e. using ?scale( ) ? -by subjects, for example- ?)
> before doing classical regression analysis. I'm not awared enough in
> statistics to
> see and explain all the statistical and fundamental differences there are
> between this approach
> and mixed models.
>
> For example , with the data "sleepstudy" from package lme4, is there
> something wrong or
> dubious ?with the following model ? ?:
>
>
> (a) ? ?lm( zreaction ~ Days ,data=sleepstudy)
> where zreaction is ? Reaction ? scaled by Subject.
>
>
> to be compared with:
>
> (b) ? ?lmer( Reaction ~Days +(1|Subject), data=sleepstudy)
>
>
> (a) still considers all the z-measures as independant, and I think that
> it is still "dubious" , despite the fact that after the scaling, all the
> zreaction
> have a ?mean==0 and a sd ==1. Am I right ?
>
> Apparently, there are no differences between (a) and the following mixed
> model :
>
> (c) lmer(zreac ~ Days + (1 | Subject) ...)
>
> (Of course this last ?model found a null variance inter-subject).
>
> Would differences be appeared if ?I run simulations on (a) ,(b) and (c) to
> test
> the effect of Days ?
>
> I'm looking for "good" arguments to convince my colleagues that
> mixed model is a better way than z-transform, even for such a simple model,
> for which it would be not only an easier or more elegant way to do the same
> .
>
> (I know that the "good model" is the mixed model with a random slope, and
> that
> this time ?the "z-model" and the mixed one cannot be compared )
>
>
> Thank you for your help.
>
>
> ###### ? output from ? classical lm ? on z scaling data
>
> Dear all
>
> In my domain (phonetics) , it is usual to z-transform the response
> (i.e. using ?scale( ) ? -by subjects, for example- ?)
> before doing classical regression analysis. I'm not awared enough in
> statistics to
> see and explain all the statistical and fundamental differences there are
> between this approach
> and mixed models.
>
> For example , with the data "sleepstudy" from package lme4, is there
> something wrong or
> dubious ?with the following model ? ?:
>
>
> (a) ? ?lm( zreaction ~ Days ,data=sleepstudy)
> where zreaction is ? Reaction ? scaled by Subject.
>
>
> to be compared with:
>
> (b) ? ?lmer( Reaction ~Days +(1|Subject), data=sleepstudy)
>
>
> the model (a) still considers all the z-measures as independant, and I think
> that
> it is still "dubious" , despite the fact that after the scaling, all the
> zreaction
> have a ?mean==0 and a sd ==1. Am I right ?
>
> Apparently, there are no differences between (a) and the following mixed
> model :
>
> (c) lmer(zreac ~ Days + (1 | Subject) ...)
>
> (Of course this last ?model found a null variance inter-subject).
>
> Am I wrong when I expect some (hidden) differences betwenn (a) and (c) ?
>
> Would differences be appeared if ?I run simulations on (a) ,(b) and (c) to
> test
> the effect of Days ?
>
> I'm looking for "good" arguments to convince my colleagues that
> mixed model is a better way than z-transform for such a simple model,
> for which it would be not only an easier or more elegant way to do the same
> .
> (I know that the "good model" is the mixed model with a random slope, and
> that
> this time ?the "z-model" and the mixed one cannot be compared )
>
>
> Thank you for your help.
>
>
> ###### ? : output from ? classical lm ? on the z-scaled data ,model (a)
>
>> summary( fm0z.lm)
>
> Call:
> lm(formula = zreac ~ Days, data = zsleep)
>
> Residuals:
> ? ?Min ? ? ? 1Q ? Median ? ? ? 3Q ? ? ?Max
> -1.98864 -0.36035 ?0.01233 ?0.35292 ?2.55175
>
> Coefficients:
> ? ? ? ? ? Estimate Std. Error t value Pr(>|t|) ? (Intercept) -1.06168
> ?0.09249 ?-11.48 ? <2e-16 ***
> Days ? ? ? ? 0.23593 ? ?0.01733 ? 13.62 ? <2e-16 ***
>
>
> Residual standard error: 0.6676 on 178 degrees of freedom
>
> ### ?output from lmer on z-scaled data ?, model (c)
>
>> summary( fm0z.lmer)
> Linear mixed model fit by REML
> Formula: zreac ~ Days + (1 | Subject)
> ?Data: zsleep
> ?AIC ? BIC logLik deviance REMLdev
> 381.8 394.6 -186.9 ? ?363.4 ? 373.8
> Random effects:
> Groups ? Name ? ? ? ?Variance Std.Dev.
> Subject ?(Intercept) 0.00000 ?0.00000
> Residual ? ? ? ? ? ? 0.44574 ?0.66764
> Number of obs: 180, groups: Subject, 18
>
> Fixed effects:
> ? ? ? ? ? Estimate Std. Error t value
> (Intercept) -1.06168 ? ?0.09249 ?-11.48
> Days ? ? ? ? 0.23593 ? ?0.01733 ? 13.62
>
> Correlation of Fixed Effects:
> ? ?(Intr)
> Days -0.843
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From danielezrajohnson at gmail.com  Thu Dec  3 17:09:49 2009
From: danielezrajohnson at gmail.com (Daniel Ezra Johnson)
Date: Thu, 3 Dec 2009 11:09:49 -0500
Subject: [R-sig-ME] z transform versus random intercept
In-Reply-To: <40e66e0b0912030712y64b1bcf6x44959355ee30db5e@mail.gmail.com>
References: <4B179F61.2050209@lpl-aix.fr>
	<40e66e0b0912030712y64b1bcf6x44959355ee30db5e@mail.gmail.com>
Message-ID: <a46630750912030809j3ce9856bv8f9f49011fa7bb27@mail.gmail.com>

Is another, perhaps less important, difference that the z-scaling
approach does "handle" (or remove) heteroscedasticity between subjects
- at least in some fashion - whereas an lmer() model with random
intercept would assume that each subject's observations have the same
variance?

DEJ



From bolker at ufl.edu  Thu Dec  3 20:43:06 2009
From: bolker at ufl.edu (Ben Bolker)
Date: Thu, 03 Dec 2009 14:43:06 -0500
Subject: [R-sig-ME] lmer models-confusing results - more information!
In-Reply-To: <BLU139-W20698BCF1B76DA57159E01FB940@phx.gbl>
References: <BLU139-W20698BCF1B76DA57159E01FB940@phx.gbl>
Message-ID: <4B1814CA.5000802@ufl.edu>

Gwyneth Wilson wrote:
> I have been running lmer models in R, looking at what effects
> reproductive success in Ground Hornbills (a South African Bird). My
> response variable is breeding success and is binomial (0-1) and my
> random effect is group ID. My response variables include rainfall,
> vegetation, group size, year, nests, and proportion of open woodland.
> 
> 
> I have run numerous models with success but I am confused about what
> the outputs are. When I run my first model with all my variables (all
> additive) then i get a low AIC value with only a few of the variables
> being significant. When i take out the varaibles that are not
> significant then my AIC becomes higher but I have more significant
> variables! When I keep taking out the unsignificant variables, I am
> left with a model that has nests, open woodland, and group size as
> being extremely significant BUT the AIC is high! Why is my AIC value
> increasing when I have fewer varaibles that are all significant and
> seem to be best explaining my data? Do i look at only the AIC when
> choosing the 'best' model or do I look at only the p-values? or both?
> The model with the lowest AIC at the moment has the most variables
> and most are not significant?

   This happens a lot when you have correlated variables: although I
don't agree with absolutely everything it says, Zuur et al 2009 is a
good start for looking at this. When you have correlated variables, it's
easy for them collectively to explain a lot of the pattern but
individually not to explain much.

Zuur, A. F., E. N. Ieno, and C. S. Elphick. 2009. A protocol for data
exploration to avoid common statistical problems. Methods in Ecology and
Evolution. doi: 10.1111/j.2041-210X.2009.00001.x.

  In general, you should *either* (1)fit all sensible models and
model-average the results (if you are interested in prediction) or (2)
use the full model to evaluate p-values, test hypotheses etc. (providing
you have _already_ removed correlated variables).  In general (although
Murtaugh 2009 provides a counterexample of sorts), you should **not**
select a model and then (afterwards) evaluate the significance of the
parameters in the model ...

Murtaugh, P. A. 2009. Performance of several variable-selection methods
applied to real ecological data. Ecology Letters 12:1061-1068. doi:
10.1111/j.1461-0248.2009.01361.x.


> 
> Please help. Any suggestions would be great!!
> 
> 
> 
> Here is some more information and some of my outputs:
> 
> 
> 
> The first model has all my variables included and i get a low AIC
> with only grp.sz and wood being significant:
>
> model1<-lmer(br.su~factor(art.n)+factor(yr)+grp.sz+rain+veg+wood+(1|grp.id),data=hornbill,family=binomial)
> 
>> summary(model1)
> Generalized linear mixed model fit by the Laplace approximation 
> Formula: br.su ~ factor(art.n) + factor(yr) + grp.sz + rain + veg +
> wood +      (1 | grp.id) Data: hornbill AIC   BIC    logLik
> deviance 138.5 182.3  -55.26    110.5 Random effects: Groups Name
> Variance Std.Dev. grp.id (Intercept) 1.2913   1.1364 Number of obs:
> 169, groups: grp.id, 23
> 
> Fixed effects: Estimate      Std. Error  z value  Pr(>|z|) 
> (Intercept)      -3.930736   3.672337  -1.070    0.2845 
> factor(art.n)1  1.462829   0.903328   1.619     0.1054 factor(yr)2002
> -2.592315   1.764551  -1.469   0.1418 factor(yr)2003 -3.169365
> 1.759981  -1.801   0.0717 . factor(yr)2004  0.702210   1.341524
> 0.523   0.6007 factor(yr)2005 -2.264257   1.722130  -1.315   0.1886
>  factor(yr)2006  2.129728   1.270996   1.676   0.0938 . 
> factor(yr)2007 -0.579961   1.390345  -0.417   0.6766 factor(yr)2008
> -1.062933   1.640774  -0.648   0.5171 grp.sz             1.882616
> 0.368317   5.111   3.2e-07 *** rain                -0.005896
> 0.003561  -1.656   0.0977 . veg                 -1.993443   1.948738
> -1.023   0.3063 wood               6.832543   3.050573   2.240
> 0.0251 *
> 
> 
> Then i carry on and remove varaibles i think are not having an
> influence on breeding success like the year, vegetation and rain. And
> i get this:
> 
> model3<-lmer(br.su~factor(art.n)+grp.sz+wood+(1|grp.id),data=hornbill,family=binomial)
> 
>> summary(model3)
> Generalized linear mixed model fit by the Laplace approximation 
> Formula: br.su ~ factor(art.n) + grp.sz + wood + (1 | grp.id) Data:
> hornbill AIC    BIC    logLik deviance 143.8  159.4  -66.88    133.8 
> Random effects: Groups Name        Variance Std.Dev. grp.id
> (Intercept)     0.75607  0.86953 Number of obs: 169, groups: grp.id,
> 23
> 
> Fixed effects: Estimate Std. Error  z value   Pr(>|z|) (Intercept)
> -8.6619     1.3528   -6.403   1.52e-10 *** factor(art.n)1   1.5337
> 0.6420    2.389    0.0169 * grp.sz            1.6631     0.2968
> 5.604    2.09e-08 *** wood              3.2177     1.5793    2.037
> 0.0416 *
> 
> So all the variables are significant but the AIC value is higher!
> 
> I thought that with fewer variables and they are all showing
> significance which means they are influencing breeding success-then
> why is my AIC higher in this model?? Do i only look at the AIC values
> and ignore the p-values? or only look at the p-values??
> 
> Thanks!!
> 
> 
>  _________________________________________________________________
> 
> 
> [[alternative HTML version deleted]]
> 
> _______________________________________________ 
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / www.zoology.ufl.edu/bolker
GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc



From pchapman at stat.colostate.edu  Thu Dec  3 23:18:17 2009
From: pchapman at stat.colostate.edu (Phillip Chapman)
Date: Thu, 03 Dec 2009 15:18:17 -0700
Subject: [R-sig-ME] Convergence problem with lmer with non-centered WWheat
	data
Message-ID: <4B183929.7020904@stat.colostate.edu>

Dear All,

I am trying to run a random coefficients regression using the winter 
wheat data from the "SAS System for Mixed Models" book. lmer appears to 
be converging to an erroneous solution for the second model (diagonal 
cov matrix for random effects).   Is there a better way to specify my 
lmer model (h1 in the text below)?  Note: this convergence problem goes 
away when I center (i.e. subtract the mean of) the continuous predictor, 
Moisture.  I would usually center predictors in random coefficients 
models anyway.

The data frame is WWheat from the "SASmixed" package.  The response is 
Yield; the continuous predictor is Moisture; and the factor with 10 
levels is Variety.

I have no problem with the first model in the book; it fits random 
intercept/slope pairs for each variety.  The following three analyses 
produce almost same results, out to a reasonable number of significant 
digits:

1.   Using lme4:       g1 <- lmer(Yield ~ Moisture + (Moisture | 
Variety), data=WWheat)

2.   Using nlme:        g2 <- lme(Yield ~ Moisture, random = ~ Moisture 
| Variety, data=WWheat)

3.  Using SAS:
   proc mixed data=wheat scoring=8;
   class variety;
   model yield = moist/solution;
   random int moist/sub=variety type=un solution G Gcorr;
   run;

The second model restricts the covariance matrix of the intercept/slope 
pairs to be diagonal.  For this model I get the same result using lme 
and SAS, but lmer converges to a different solution, which appears to be 
erroneous:

1.  Using lme4:       h1 <- lmer(Yield ~ Moisture + (1 | Variety) + 
(Moisture -1 | Variety), data=WWheat)

2. Using nlme (I could only figure out how to do this after creating a 
grouped data object):
                      WWheat2 <- groupedData(Yield ~ Moisture | Variety, 
data=WWheat)
                       h2 <- lme(Yield ~ Moisture, random =  pdDiag(~ 
Moisture), data=WWheat2)

3. Using SAS:
   proc mixed data=wheat scoring=8;
   class variety;
   model yield = moist/solution;
   random int moist/sub=variety type=un(1) solution G Gcorr;
   run;

I took the variance estimates from lmer and put them into SAS Proc Mixed 
to see if the REML deviances match: they do. Both SAS and lmer give the 
same deviance of 205.7, which is much greater than the optimum value of 
187.1 produced by SAS and lme.  The fixed effects estimates from SAS and 
lmer also match when these variance estimates are used.
proc mixed data=wheat scoring=8;
   class variety;
   model yield = moist/solution;
   random int moist/sub=variety type=un(1) solution G Gcorr;
  parms (1.6854e+01)(0) ( 2.6133e-16) (7.5295e-01)/noiter; *the solution 
from lmer;
  run;

Thanks,

Phil Chapman



From bates at stat.wisc.edu  Fri Dec  4 00:12:30 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 3 Dec 2009 17:12:30 -0600
Subject: [R-sig-ME] Convergence problem with lmer with non-centered
	WWheat data
In-Reply-To: <4B183929.7020904@stat.colostate.edu>
References: <4B183929.7020904@stat.colostate.edu>
Message-ID: <40e66e0b0912031512l1dd01ff8yca47c39666968711@mail.gmail.com>

On Thu, Dec 3, 2009 at 4:18 PM, Phillip Chapman
<pchapman at stat.colostate.edu> wrote:
> Dear All,
>
> I am trying to run a random coefficients regression using the winter wheat
> data from the "SAS System for Mixed Models" book. lmer appears to be
> converging to an erroneous solution for the second model (diagonal cov
> matrix for random effects). ? Is there a better way to specify my lmer model
> (h1 in the text below)? ?Note: this convergence problem goes away when I
> center (i.e. subtract the mean of) the continuous predictor, Moisture. ?I
> would usually center predictors in random coefficients models anyway.
>
> The data frame is WWheat from the "SASmixed" package. ?The response is
> Yield; the continuous predictor is Moisture; and the factor with 10 levels
> is Variety.
>
> I have no problem with the first model in the book; it fits random
> intercept/slope pairs for each variety. ?The following three analyses
> produce almost same results, out to a reasonable number of significant
> digits:
>
> 1. ? Using lme4: ? ? ? g1 <- lmer(Yield ~ Moisture + (Moisture | Variety),
> data=WWheat)
>
> 2. ? Using nlme: ? ? ? ?g2 <- lme(Yield ~ Moisture, random = ~ Moisture |
> Variety, data=WWheat)
>
> 3. ?Using SAS:
> ?proc mixed data=wheat scoring=8;
> ?class variety;
> ?model yield = moist/solution;
> ?random int moist/sub=variety type=un solution G Gcorr;
> ?run;
>
> The second model restricts the covariance matrix of the intercept/slope
> pairs to be diagonal. ?For this model I get the same result using lme and
> SAS, but lmer converges to a different solution, which appears to be
> erroneous:
>
> 1. ?Using lme4: ? ? ? h1 <- lmer(Yield ~ Moisture + (1 | Variety) +
> (Moisture -1 | Variety), data=WWheat)
> 2. Using nlme (I could only figure out how to do this after creating a
> grouped data object):
> ? ? ? ? ? ? ? ? ? ? WWheat2 <- groupedData(Yield ~ Moisture | Variety,
> data=WWheat)
> ? ? ? ? ? ? ? ? ? ? ?h2 <- lme(Yield ~ Moisture, random = ?pdDiag(~
> Moisture), data=WWheat2)
>
> 3. Using SAS:
> ?proc mixed data=wheat scoring=8;
> ?class variety;
> ?model yield = moist/solution;
> ?random int moist/sub=variety type=un(1) solution G Gcorr;
> ?run;
>
> I took the variance estimates from lmer and put them into SAS Proc Mixed to
> see if the REML deviances match: they do. Both SAS and lmer give the same
> deviance of 205.7, which is much greater than the optimum value of 187.1
> produced by SAS and lme. ?The fixed effects estimates from SAS and lmer also
> match when these variance estimates are used.
> proc mixed data=wheat scoring=8;
> ?class variety;
> ?model yield = moist/solution;
> ?random int moist/sub=variety type=un(1) solution G Gcorr;
> ?parms (1.6854e+01)(0) ( 2.6133e-16) (7.5295e-01)/noiter; *the solution from
> lmer;
> ?run;

It does look like a convergence problem because of the 2.6133e-16 for
the variance of the random effects for slope.  Could you tell us what
version of the lme4 package you are using?  It is easiest just to send
the output of sessionInfo()

This problem will occur because of the need to use a constrained
nonlinear optimizer to determine the ML or REML estimates.  The
evaluation of the deviance is done very carefully so as to give the
optimizer a good shot at the getting the optimum but it doesn't always
work.

In the development branch of the lme4 package (the lme4a branch) there
is the capability of switching to a different optimizer.  I have found
the bobyqa optimizer in the package by Kate Mullen and John Nash to be
more robust and faster in most cases than is nlminb, which is the
default. However, even nlminb converges to the correct optimum in that
branch.



From Manuel.A.Morales at williams.edu  Fri Dec  4 15:18:53 2009
From: Manuel.A.Morales at williams.edu (Manuel Morales)
Date: Fri, 04 Dec 2009 09:18:53 -0500
Subject: [R-sig-ME] lmer models-confusing results - more information!
In-Reply-To: <4B1814CA.5000802@ufl.edu>
References: <BLU139-W20698BCF1B76DA57159E01FB940@phx.gbl>
	<4B1814CA.5000802@ufl.edu>
Message-ID: <1259936333.3065.5.camel@localhost.localdomain>

On Thu, 2009-12-03 at 14:43 -0500, Ben Bolker wrote:
> Gwyneth Wilson wrote:
> > I have been running lmer models in R, looking at what effects
> > reproductive success in Ground Hornbills (a South African Bird). My
> > response variable is breeding success and is binomial (0-1) and my
> > random effect is group ID. My response variables include rainfall,
> > vegetation, group size, year, nests, and proportion of open woodland.
> > 
> > 
> > I have run numerous models with success but I am confused about what
> > the outputs are. When I run my first model with all my variables (all
> > additive) then i get a low AIC value with only a few of the variables
> > being significant. When i take out the varaibles that are not
> > significant then my AIC becomes higher but I have more significant
> > variables! When I keep taking out the unsignificant variables, I am
> > left with a model that has nests, open woodland, and group size as
> > being extremely significant BUT the AIC is high! Why is my AIC value
> > increasing when I have fewer varaibles that are all significant and
> > seem to be best explaining my data? Do i look at only the AIC when
> > choosing the 'best' model or do I look at only the p-values? or both?
> > The model with the lowest AIC at the moment has the most variables
> > and most are not significant?
> 
>    This happens a lot when you have correlated variables: although I
> don't agree with absolutely everything it says, Zuur et al 2009 is a
> good start for looking at this. When you have correlated variables, it's
> easy for them collectively to explain a lot of the pattern but
> individually not to explain much.
> 
> Zuur, A. F., E. N. Ieno, and C. S. Elphick. 2009. A protocol for data
> exploration to avoid common statistical problems. Methods in Ecology and
> Evolution. doi: 10.1111/j.2041-210X.2009.00001.x.
> 
>   In general, you should *either* (1)fit all sensible models and
> model-average the results (if you are interested in prediction) or (2)
> use the full model to evaluate p-values, test hypotheses etc. (providing
> you have _already_ removed correlated variables).  In general (although
> Murtaugh 2009 provides a counterexample of sorts), you should **not**
> select a model and then (afterwards) evaluate the significance of the
> parameters in the model ...

Is this in the context of non-nested models? Otherwise, a very common
scenario is to test interaction terms first and then remove from the
model if not significant (i.e., to test the significance of main
effects).


> 
> Murtaugh, P. A. 2009. Performance of several variable-selection methods
> applied to real ecological data. Ecology Letters 12:1061-1068. doi:
> 10.1111/j.1461-0248.2009.01361.x.
> 
> 
> > 
> > Please help. Any suggestions would be great!!
> > 
> > 
> > 
> > Here is some more information and some of my outputs:
> > 
> > 
> > 
> > The first model has all my variables included and i get a low AIC
> > with only grp.sz and wood being significant:
> >
> > model1<-lmer(br.su~factor(art.n)+factor(yr)+grp.sz+rain+veg+wood+(1|grp.id),data=hornbill,family=binomial)
> > 
> >> summary(model1)
> > Generalized linear mixed model fit by the Laplace approximation 
> > Formula: br.su ~ factor(art.n) + factor(yr) + grp.sz + rain + veg +
> > wood +      (1 | grp.id) Data: hornbill AIC   BIC    logLik
> > deviance 138.5 182.3  -55.26    110.5 Random effects: Groups Name
> > Variance Std.Dev. grp.id (Intercept) 1.2913   1.1364 Number of obs:
> > 169, groups: grp.id, 23
> > 
> > Fixed effects: Estimate      Std. Error  z value  Pr(>|z|) 
> > (Intercept)      -3.930736   3.672337  -1.070    0.2845 
> > factor(art.n)1  1.462829   0.903328   1.619     0.1054 factor(yr)2002
> > -2.592315   1.764551  -1.469   0.1418 factor(yr)2003 -3.169365
> > 1.759981  -1.801   0.0717 . factor(yr)2004  0.702210   1.341524
> > 0.523   0.6007 factor(yr)2005 -2.264257   1.722130  -1.315   0.1886
> >  factor(yr)2006  2.129728   1.270996   1.676   0.0938 . 
> > factor(yr)2007 -0.579961   1.390345  -0.417   0.6766 factor(yr)2008
> > -1.062933   1.640774  -0.648   0.5171 grp.sz             1.882616
> > 0.368317   5.111   3.2e-07 *** rain                -0.005896
> > 0.003561  -1.656   0.0977 . veg                 -1.993443   1.948738
> > -1.023   0.3063 wood               6.832543   3.050573   2.240
> > 0.0251 *
> > 
> > 
> > Then i carry on and remove varaibles i think are not having an
> > influence on breeding success like the year, vegetation and rain. And
> > i get this:
> > 
> > model3<-lmer(br.su~factor(art.n)+grp.sz+wood+(1|grp.id),data=hornbill,family=binomial)
> > 
> >> summary(model3)
> > Generalized linear mixed model fit by the Laplace approximation 
> > Formula: br.su ~ factor(art.n) + grp.sz + wood + (1 | grp.id) Data:
> > hornbill AIC    BIC    logLik deviance 143.8  159.4  -66.88    133.8 
> > Random effects: Groups Name        Variance Std.Dev. grp.id
> > (Intercept)     0.75607  0.86953 Number of obs: 169, groups: grp.id,
> > 23
> > 
> > Fixed effects: Estimate Std. Error  z value   Pr(>|z|) (Intercept)
> > -8.6619     1.3528   -6.403   1.52e-10 *** factor(art.n)1   1.5337
> > 0.6420    2.389    0.0169 * grp.sz            1.6631     0.2968
> > 5.604    2.09e-08 *** wood              3.2177     1.5793    2.037
> > 0.0416 *
> > 
> > So all the variables are significant but the AIC value is higher!
> > 
> > I thought that with fewer variables and they are all showing
> > significance which means they are influencing breeding success-then
> > why is my AIC higher in this model?? Do i only look at the AIC values
> > and ignore the p-values? or only look at the p-values??
> > 
> > Thanks!!
> > 
> > 
> >  _________________________________________________________________
> > 
> > 
> > [[alternative HTML version deleted]]
> > 
> > _______________________________________________ 
> > R-sig-mixed-models at r-project.org mailing list 
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 


-- 
http://mutualism.williams.edu



From cmswoboda at students.wisc.edu  Fri Dec  4 15:31:43 2009
From: cmswoboda at students.wisc.edu (CHRIS M SWOBODA)
Date: Fri, 04 Dec 2009 08:31:43 -0600
Subject: [R-sig-ME] Simulation of Multilevel (nested) data
In-Reply-To: <mailman.3.1259924401.26599.r-sig-mixed-models@r-project.org>
References: <mailman.3.1259924401.26599.r-sig-mixed-models@r-project.org>
Message-ID: <7090f27e70bd5.4b18c8ef@wiscmail.wisc.edu>

Hi everyone,

I asked this question right before Thanksgiving, so I wonder if maybe it slid under the radar, so I'll ask again.  Does anyone know of any available code or actual R modules that can facilitate the process of simulating multilevel data?  

I would like to generate this data to use for some simulation for an already developed method for looking into various patterns of missingness and the subsequent models with lmer.  Specifically, I am interested in 3-level models where I can specify the correlation between predictors within and across levels.  

If this is not in the correct place, I would welcome suggestions as to where else I could look for help.

Thanks,
Chris Swoboda
University of Wisconsin - Madison

----- Original Message -----
From: r-sig-mixed-models-request at r-project.org
Date: Friday, December 4, 2009 5:01 am
Subject: R-sig-mixed-models Digest, Vol 36, Issue 5
To: r-sig-mixed-models at r-project.org


> Send R-sig-mixed-models mailing list submissions to
> 	r-sig-mixed-models at r-project.org
> 
> To subscribe or unsubscribe via the World Wide Web, visit
> 	https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> or, via email, send a message with subject or body 'help' to
> 	r-sig-mixed-models-request at r-project.org
> 
> You can reach the person managing the list at
> 	r-sig-mixed-models-owner at r-project.org
> 
> When replying, please edit your Subject line so it is more specific
> than "Re: Contents of R-sig-mixed-models digest..."
> 
> 
> Today's Topics:
> 
>    1. Re: z transform versus random intercept (Daniel Ezra Johnson)
>    2. Re: lmer models-confusing results - more information! (Ben Bolker)
>    3. Convergence problem with lmer with non-centered WWheat	data
>       (Phillip Chapman)
>    4. Re: Convergence problem with lmer with non-centered	WWheat
>       data (Douglas Bates)
> 
> 
> ----------------------------------------------------------------------
> 
> Message: 1
> Date: Thu, 3 Dec 2009 11:09:49 -0500
> From: Daniel Ezra Johnson <danielezrajohnson at gmail.com>
> Subject: Re: [R-sig-ME] z transform versus random intercept
> To: Douglas Bates <bates at stat.wisc.edu>
> Cc: r-sig-mixed-models at r-project.org
> Message-ID:
> 	<a46630750912030809j3ce9856bv8f9f49011fa7bb27 at mail.gmail.com>
> Content-Type: text/plain; charset=ISO-8859-1
> 
> Is another, perhaps less important, difference that the z-scaling
> approach does "handle" (or remove) heteroscedasticity between subjects
> - at least in some fashion - whereas an lmer() model with random
> intercept would assume that each subject's observations have the same
> variance?
> 
> DEJ
> 
> 
> 
> ------------------------------
> 
> Message: 2
> Date: Thu, 03 Dec 2009 14:43:06 -0500
> From: Ben Bolker <bolker at ufl.edu>
> Subject: Re: [R-sig-ME] lmer models-confusing results - more
> 	information!
> To: Gwyneth Wilson <gwynwilson3 at hotmail.com>
> Cc: "r-sig-mixed-models at r-project.org"
> 	<r-sig-mixed-models at r-project.org>
> Message-ID: <4B1814CA.5000802 at ufl.edu>
> Content-Type: text/plain; charset=ISO-8859-1
> 
> Gwyneth Wilson wrote:
> > I have been running lmer models in R, looking at what effects
> > reproductive success in Ground Hornbills (a South African Bird). My
> > response variable is breeding success and is binomial (0-1) and my
> > random effect is group ID. My response variables include rainfall,
> > vegetation, group size, year, nests, and proportion of open woodland.
> > 
> > 
> > I have run numerous models with success but I am confused about what
> > the outputs are. When I run my first model with all my variables (all
> > additive) then i get a low AIC value with only a few of the variables
> > being significant. When i take out the varaibles that are not
> > significant then my AIC becomes higher but I have more significant
> > variables! When I keep taking out the unsignificant variables, I am
> > left with a model that has nests, open woodland, and group size as
> > being extremely significant BUT the AIC is high! Why is my AIC value
> > increasing when I have fewer varaibles that are all significant and
> > seem to be best explaining my data? Do i look at only the AIC when
> > choosing the 'best' model or do I look at only the p-values? or both?
> > The model with the lowest AIC at the moment has the most variables
> > and most are not significant?
> 
>    This happens a lot when you have correlated variables: although I
> don't agree with absolutely everything it says, Zuur et al 2009 is a
> good start for looking at this. When you have correlated variables, it's
> easy for them collectively to explain a lot of the pattern but
> individually not to explain much.
> 
> Zuur, A. F., E. N. Ieno, and C. S. Elphick. 2009. A protocol for data
> exploration to avoid common statistical problems. Methods in Ecology and
> Evolution. doi: 10.1111/j.2041-210X.2009.00001.x.
> 
>   In general, you should *either* (1)fit all sensible models and
> model-average the results (if you are interested in prediction) or (2)
> use the full model to evaluate p-values, test hypotheses etc. (providing
> you have _already_ removed correlated variables).  In general (although
> Murtaugh 2009 provides a counterexample of sorts), you should **not**
> select a model and then (afterwards) evaluate the significance of the
> parameters in the model ...
> 
> Murtaugh, P. A. 2009. Performance of several variable-selection methods
> applied to real ecological data. Ecology Letters 12:1061-1068. doi:
> 10.1111/j.1461-0248.2009.01361.x.
> 
> 
> > 
> > Please help. Any suggestions would be great!!
> > 
> > 
> > 
> > Here is some more information and some of my outputs:
> > 
> > 
> > 
> > The first model has all my variables included and i get a low AIC
> > with only grp.sz and wood being significant:
> >
> > model1<-lmer(br.su~factor(art.n)+factor(yr)+grp.sz+rain+veg+wood+(1|grp.id),data=hornbill,family=binomial)
> > 
> >> summary(model1)
> > Generalized linear mixed model fit by the Laplace approximation 
> > Formula: br.su ~ factor(art.n) + factor(yr) + grp.sz + rain + veg +
> > wood +      (1 | grp.id) Data: hornbill AIC   BIC    logLik
> > deviance 138.5 182.3  -55.26    110.5 Random effects: Groups Name
> > Variance Std.Dev. grp.id (Intercept) 1.2913   1.1364 Number of obs:
> > 169, groups: grp.id, 23
> > 
> > Fixed effects: Estimate      Std. Error  z value  Pr(>|z|) 
> > (Intercept)      -3.930736   3.672337  -1.070    0.2845 
> > factor(art.n)1  1.462829   0.903328   1.619     0.1054 factor(yr)2002
> > -2.592315   1.764551  -1.469   0.1418 factor(yr)2003 -3.169365
> > 1.759981  -1.801   0.0717 . factor(yr)2004  0.702210   1.341524
> > 0.523   0.6007 factor(yr)2005 -2.264257   1.722130  -1.315   0.1886
> >  factor(yr)2006  2.129728   1.270996   1.676   0.0938 . 
> > factor(yr)2007 -0.579961   1.390345  -0.417   0.6766 factor(yr)2008
> > -1.062933   1.640774  -0.648   0.5171 grp.sz             1.882616
> > 0.368317   5.111   3.2e-07 *** rain                -0.005896
> > 0.003561  -1.656   0.0977 . veg                 -1.993443   1.948738
> > -1.023   0.3063 wood               6.832543   3.050573   2.240
> > 0.0251 *
> > 
> > 
> > Then i carry on and remove varaibles i think are not having an
> > influence on breeding success like the year, vegetation and rain. And
> > i get this:
> > 
> > model3<-lmer(br.su~factor(art.n)+grp.sz+wood+(1|grp.id),data=hornbill,family=binomial)
> > 
> >> summary(model3)
> > Generalized linear mixed model fit by the Laplace approximation 
> > Formula: br.su ~ factor(art.n) + grp.sz + wood + (1 | grp.id) Data:
> > hornbill AIC    BIC    logLik deviance 143.8  159.4  -66.88    133.8 
> 
> > Random effects: Groups Name        Variance Std.Dev. grp.id
> > (Intercept)     0.75607  0.86953 Number of obs: 169, groups: grp.id,
> > 23
> > 
> > Fixed effects: Estimate Std. Error  z value   Pr(>|z|) (Intercept)
> > -8.6619     1.3528   -6.403   1.52e-10 *** factor(art.n)1   1.5337
> > 0.6420    2.389    0.0169 * grp.sz            1.6631     0.2968
> > 5.604    2.09e-08 *** wood              3.2177     1.5793    2.037
> > 0.0416 *
> > 
> > So all the variables are significant but the AIC value is higher!
> > 
> > I thought that with fewer variables and they are all showing
> > significance which means they are influencing breeding success-then
> > why is my AIC higher in this model?? Do i only look at the AIC values
> > and ignore the p-values? or only look at the p-values??
> > 
> > Thanks!!
> > 
> > 
> >  _________________________________________________________________
> > 
> > 
> > [[alternative HTML version deleted]]
> > 
> > _______________________________________________ 
> > R-sig-mixed-models at r-project.org mailing list 
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
> -- 
> Ben Bolker
> Associate professor, Biology Dep't, Univ. of Florida
> bolker at ufl.edu / www.zoology.ufl.edu/bolker
> GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc
> 
> 
> 
> ------------------------------
> 
> Message: 3
> Date: Thu, 03 Dec 2009 15:18:17 -0700
> From: Phillip Chapman <pchapman at stat.colostate.edu>
> Subject: [R-sig-ME] Convergence problem with lmer with non-centered
> 	WWheat	data
> To: "r-sig-mixed-models at r-project.org"
> 	<r-sig-mixed-models at r-project.org>
> Message-ID: <4B183929.7020904 at stat.colostate.edu>
> Content-Type: text/plain; charset=ISO-8859-1; format=flowed
> 
> Dear All,
> 
> I am trying to run a random coefficients regression using the winter 
> wheat data from the "SAS System for Mixed Models" book. lmer appears 
> to 
> be converging to an erroneous solution for the second model (diagonal 
> 
> cov matrix for random effects).   Is there a better way to specify my 
> 
> lmer model (h1 in the text below)?  Note: this convergence problem 
> goes 
> away when I center (i.e. subtract the mean of) the continuous 
> predictor, 
> Moisture.  I would usually center predictors in random coefficients 
> models anyway.
> 
> The data frame is WWheat from the "SASmixed" package.  The response is 
> 
> Yield; the continuous predictor is Moisture; and the factor with 10 
> levels is Variety.
> 
> I have no problem with the first model in the book; it fits random 
> intercept/slope pairs for each variety.  The following three analyses 
> 
> produce almost same results, out to a reasonable number of significant 
> 
> digits:
> 
> 1.   Using lme4:       g1 <- lmer(Yield ~ Moisture + (Moisture | 
> Variety), data=WWheat)
> 
> 2.   Using nlme:        g2 <- lme(Yield ~ Moisture, random = ~ 
> Moisture 
> | Variety, data=WWheat)
> 
> 3.  Using SAS:
>    proc mixed data=wheat scoring=8;
>    class variety;
>    model yield = moist/solution;
>    random int moist/sub=variety type=un solution G Gcorr;
>    run;
> 
> The second model restricts the covariance matrix of the 
> intercept/slope 
> pairs to be diagonal.  For this model I get the same result using lme 
> 
> and SAS, but lmer converges to a different solution, which appears to 
> be 
> erroneous:
> 
> 1.  Using lme4:       h1 <- lmer(Yield ~ Moisture + (1 | Variety) + 
> (Moisture -1 | Variety), data=WWheat)
> 
> 2. Using nlme (I could only figure out how to do this after creating a 
> 
> grouped data object):
>                       WWheat2 <- groupedData(Yield ~ Moisture | 
> Variety, 
> data=WWheat)
>                        h2 <- lme(Yield ~ Moisture, random =  pdDiag(~ 
> 
> Moisture), data=WWheat2)
> 
> 3. Using SAS:
>    proc mixed data=wheat scoring=8;
>    class variety;
>    model yield = moist/solution;
>    random int moist/sub=variety type=un(1) solution G Gcorr;
>    run;
> 
> I took the variance estimates from lmer and put them into SAS Proc 
> Mixed 
> to see if the REML deviances match: they do. Both SAS and lmer give 
> the 
> same deviance of 205.7, which is much greater than the optimum value 
> of 
> 187.1 produced by SAS and lme.  The fixed effects estimates from SAS 
> and 
> lmer also match when these variance estimates are used.
> proc mixed data=wheat scoring=8;
>    class variety;
>    model yield = moist/solution;
>    random int moist/sub=variety type=un(1) solution G Gcorr;
>   parms (1.6854e+01)(0) ( 2.6133e-16) (7.5295e-01)/noiter; *the 
> solution 
> from lmer;
>   run;
> 
> Thanks,
> 
> Phil Chapman
> 
> 
> 
> ------------------------------
> 
> Message: 4
> Date: Thu, 3 Dec 2009 17:12:30 -0600
> From: Douglas Bates <bates at stat.wisc.edu>
> Subject: Re: [R-sig-ME] Convergence problem with lmer with
> 	non-centered	WWheat data
> To: Phillip Chapman <pchapman at stat.colostate.edu>
> Cc: "r-sig-mixed-models at r-project.org"
> 	<r-sig-mixed-models at r-project.org>
> Message-ID:
> 	<40e66e0b0912031512l1dd01ff8yca47c39666968711 at mail.gmail.com>
> Content-Type: text/plain; charset=ISO-8859-1
> 
> On Thu, Dec 3, 2009 at 4:18 PM, Phillip Chapman
> <pchapman at stat.colostate.edu> wrote:
> > Dear All,
> >
> > I am trying to run a random coefficients regression using the winter 
> wheat
> > data from the "SAS System for Mixed Models" book. lmer appears to be
> > converging to an erroneous solution for the second model (diagonal cov
> > matrix for random effects). ? Is there a better way to specify my 
> lmer model
> > (h1 in the text below)? ?Note: this convergence problem goes away 
> when I
> > center (i.e. subtract the mean of) the continuous predictor, 
> Moisture. ?I
> > would usually center predictors in random coefficients models anyway.
> >
> > The data frame is WWheat from the "SASmixed" package. ?The response 
> is
> > Yield; the continuous predictor is Moisture; and the factor with 10 
> levels
> > is Variety.
> >
> > I have no problem with the first model in the book; it fits random
> > intercept/slope pairs for each variety. ?The following three analyses
> > produce almost same results, out to a reasonable number of significant
> > digits:
> >
> > 1. ? Using lme4: ? ? ? g1 <- lmer(Yield ~ Moisture + (Moisture | Variety),
> > data=WWheat)
> >
> > 2. ? Using nlme: ? ? ? ?g2 <- lme(Yield ~ Moisture, random = ~ 
> Moisture |
> > Variety, data=WWheat)
> >
> > 3. ?Using SAS:
> > ?proc mixed data=wheat scoring=8;
> > ?class variety;
> > ?model yield = moist/solution;
> > ?random int moist/sub=variety type=un solution G Gcorr;
> > ?run;
> >
> > The second model restricts the covariance matrix of the intercept/slope
> > pairs to be diagonal. ?For this model I get the same result using 
> lme and
> > SAS, but lmer converges to a different solution, which appears to be
> > erroneous:
> >
> > 1. ?Using lme4: ? ? ? h1 <- lmer(Yield ~ Moisture + (1 | Variety) +
> > (Moisture -1 | Variety), data=WWheat)
> > 2. Using nlme (I could only figure out how to do this after creating 
> a
> > grouped data object):
> > ? ? ? ? ? ? ? ? ? ? WWheat2 <- groupedData(Yield ~ Moisture | Variety,
> > data=WWheat)
> > ? ? ? ? ? ? ? ? ? ? ?h2 <- lme(Yield ~ Moisture, random = ?pdDiag(~
> > Moisture), data=WWheat2)
> >
> > 3. Using SAS:
> > ?proc mixed data=wheat scoring=8;
> > ?class variety;
> > ?model yield = moist/solution;
> > ?random int moist/sub=variety type=un(1) solution G Gcorr;
> > ?run;
> >
> > I took the variance estimates from lmer and put them into SAS Proc 
> Mixed to
> > see if the REML deviances match: they do. Both SAS and lmer give the 
> same
> > deviance of 205.7, which is much greater than the optimum value of 187.1
> > produced by SAS and lme. ?The fixed effects estimates from SAS and 
> lmer also
> > match when these variance estimates are used.
> > proc mixed data=wheat scoring=8;
> > ?class variety;
> > ?model yield = moist/solution;
> > ?random int moist/sub=variety type=un(1) solution G Gcorr;
> > ?parms (1.6854e+01)(0) ( 2.6133e-16) (7.5295e-01)/noiter; *the 
> solution from
> > lmer;
> > ?run;
> 
> It does look like a convergence problem because of the 2.6133e-16 for
> the variance of the random effects for slope.  Could you tell us what
> version of the lme4 package you are using?  It is easiest just to send
> the output of sessionInfo()
> 
> This problem will occur because of the need to use a constrained
> nonlinear optimizer to determine the ML or REML estimates.  The
> evaluation of the deviance is done very carefully so as to give the
> optimizer a good shot at the getting the optimum but it doesn't always
> work.
> 
> In the development branch of the lme4 package (the lme4a branch) there
> is the capability of switching to a different optimizer.  I have found
> the bobyqa optimizer in the package by Kate Mullen and John Nash to be
> more robust and faster in most cases than is nlminb, which is the
> default. However, even nlminb converges to the correct optimum in that
> branch.
> 
> 
> 
> ------------------------------
> 
> _______________________________________________
> R-sig-mixed-models mailing list
> R-sig-mixed-models at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
> End of R-sig-mixed-models Digest, Vol 36, Issue 5
> *************************************************



From bolker at ufl.edu  Fri Dec  4 18:29:36 2009
From: bolker at ufl.edu (Ben Bolker)
Date: Fri, 04 Dec 2009 12:29:36 -0500
Subject: [R-sig-ME] lmer models-confusing results - more information!
In-Reply-To: <1259936333.3065.5.camel@localhost.localdomain>
References: <BLU139-W20698BCF1B76DA57159E01FB940@phx.gbl>	
	<4B1814CA.5000802@ufl.edu>
	<1259936333.3065.5.camel@localhost.localdomain>
Message-ID: <4B194700.6010909@ufl.edu>

Manuel Morales wrote:
> On Thu, 2009-12-03 at 14:43 -0500, Ben Bolker wrote:
>> Gwyneth Wilson wrote:
>>> I have been running lmer models in R, looking at what effects
>>> reproductive success in Ground Hornbills (a South African Bird). My
>>> response variable is breeding success and is binomial (0-1) and my
>>> random effect is group ID. My response variables include rainfall,
>>> vegetation, group size, year, nests, and proportion of open woodland.
>>>
>>>
>>> I have run numerous models with success but I am confused about what
>>> the outputs are. When I run my first model with all my variables (all
>>> additive) then i get a low AIC value with only a few of the variables
>>> being significant. When i take out the varaibles that are not
>>> significant then my AIC becomes higher but I have more significant
>>> variables! When I keep taking out the unsignificant variables, I am
>>> left with a model that has nests, open woodland, and group size as
>>> being extremely significant BUT the AIC is high! Why is my AIC value
>>> increasing when I have fewer varaibles that are all significant and
>>> seem to be best explaining my data? Do i look at only the AIC when
>>> choosing the 'best' model or do I look at only the p-values? or both?
>>> The model with the lowest AIC at the moment has the most variables
>>> and most are not significant?
>>    This happens a lot when you have correlated variables: although I
>> don't agree with absolutely everything it says, Zuur et al 2009 is a
>> good start for looking at this. When you have correlated variables, it's
>> easy for them collectively to explain a lot of the pattern but
>> individually not to explain much.
>>
>> Zuur, A. F., E. N. Ieno, and C. S. Elphick. 2009. A protocol for data
>> exploration to avoid common statistical problems. Methods in Ecology and
>> Evolution. doi: 10.1111/j.2041-210X.2009.00001.x.
>>
>>   In general, you should *either* (1)fit all sensible models and
>> model-average the results (if you are interested in prediction) or (2)
>> use the full model to evaluate p-values, test hypotheses etc. (providing
>> you have _already_ removed correlated variables).  In general (although
>> Murtaugh 2009 provides a counterexample of sorts), you should **not**
>> select a model and then (afterwards) evaluate the significance of the
>> parameters in the model ...
> 
> Is this in the context of non-nested models? Otherwise, a very common
> scenario is to test interaction terms first and then remove from the
> model if not significant (i.e., to test the significance of main
> effects).

  Yes.  I think removing interactions is technically violating the
"don't select models and then test them" rule, but it also seems
reasonable to remove a _small_ number of non-significant interactions on
the grounds of interpretability.  (I believe Pinheiro and Bates do this
to some extent in the example in PB2000).

  cheers
   Ben



From john.maindonald at anu.edu.au  Sat Dec  5 09:21:21 2009
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Sat, 5 Dec 2009 19:21:21 +1100
Subject: [R-sig-ME] Intelligent use of mcmcsamp()
In-Reply-To: <1259936333.3065.5.camel@localhost.localdomain>
References: <BLU139-W20698BCF1B76DA57159E01FB940@phx.gbl>
	<4B1814CA.5000802@ufl.edu>
	<1259936333.3065.5.camel@localhost.localdomain>
Message-ID: <61210C29-FEEA-455A-8F43-51B51C86FAB9@anu.edu.au>

Below are two examples of the use of mcmcsamp() with output
from lmer().  The first set of results are believable.  
For the second set of results, both variance estimates
(for 'site' and for 'Residual' or scale) lie outside of the
credible intervals that are obtained.  Assuming I have
used the functions correctly, it seems surprising that
mcmcsamp() would 'fail' on the second example, which is
balanced and where both variances seem well away from
zero.  These results are consistent over repeated 
simulations.

I'd be interested to hear from list members who make regular use of
mcmcsamp(), as well as maybe from Douglas. Is there any advance on
the current routines in the development branch? 

Questions:

(1) Are instances of less obvious failoure common? How does one check?  
(2) Is there are more direct way to get the credible intervals?
(3) What insight is avaiable on why the second example fails?

John Maindonald.


## EXAMPLE 1:

library(DAAG)
science1.lmer <- lmer(like ~ sex + PrivPub + (1 | school:class),
                     data = science)
> science1.lmer
> ...
Random effects:
Groups       Name        Variance Std.Dev.
school:class (Intercept) 0.321    0.566   
Residual                 3.052    1.747   
Number of obs: 1383, groups: school:class, 66
> ...

science1.mcmc <- mcmcsamp(science1.lmer , n=1000)
z <- VarCorr(science1.mcmc, type="varcov")
colnames(z) <- c("school:class", "Residual")

> ## The following are believable!
> t(apply(z,2, function(x)quantile(x, prob=c(.025, .975))))
              2.5%  97.5%
school:class 0.1442 0.4334
Residual     2.8601 3.3427


## EXAMPLE 2:
ant111b.lmer <- lmer(harvwt ~ 1 + (1 | site), data=ant111b)
> ant111b.lmer
...
Random effects:
Groups   Name        Variance Std.Dev.
site     (Intercept) 2.368    1.54    
Residual             0.578    0.76
Number of obs: 32, groups: site, 8    
> ...

ant111b.mcmc <- mcmcsamp(ant111b.lmer, n=1000)
z <- VarCorr(ant111b.mcmc, type="varcov")
colnames(z) <- c("site", "Residual")
> t(apply(z,2, function(x)quantile(x, prob=c(.025, .975))))
          2.5% 97.5%
site     0.2376 1.878
Residual 0.6370 2.488


John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.
http://www.maths.anu.edu.au/~johnm



From jwb1970 at gmail.com  Sat Dec  5 16:00:22 2009
From: jwb1970 at gmail.com (Jake Bowers)
Date: Sat, 5 Dec 2009 09:00:22 -0600
Subject: [R-sig-ME] Intelligent use of mcmcsamp()
In-Reply-To: <61210C29-FEEA-455A-8F43-51B51C86FAB9@anu.edu.au>
References: <BLU139-W20698BCF1B76DA57159E01FB940@phx.gbl>
	<4B1814CA.5000802@ufl.edu>
	<1259936333.3065.5.camel@localhost.localdomain>
	<61210C29-FEEA-455A-8F43-51B51C86FAB9@anu.edu.au>
Message-ID: <B55C4B1B-046D-4AFF-A9A0-427E70782E99@gmail.com>


Hi All, There are 8 groups in the second example versus 66 in the  
first. Are we seeing a consistency/central limit problem. Thus,  
mcmcsamp() works when the posterior is plausibly mvnormal but not  
otherwise and in this particular example the information content of  
the data is too low? How's that for a guess? Jake

http://jakebowers.org


On Dec 5, 2009, at 2:21 AM, John Maindonald  
<john.maindonald at anu.edu.au> wrote:

> Below are two examples of the use of mcmcsamp() with output
> from lmer().  The first set of results are believable.
> For the second set of results, both variance estimates
> (for 'site' and for 'Residual' or scale) lie outside of the
> credible intervals that are obtained.  Assuming I have
> used the functions correctly, it seems surprising that
> mcmcsamp() would 'fail' on the second example, which is
> balanced and where both variances seem well away from
> zero.  These results are consistent over repeated
> simulations.
>
> I'd be interested to hear from list members who make regular use of
> mcmcsamp(), as well as maybe from Douglas. Is there any advance on
> the current routines in the development branch?
>
> Questions:
>
> (1) Are instances of less obvious failoure common? How does one check?
> (2) Is there are more direct way to get the credible intervals?
> (3) What insight is avaiable on why the second example fails?
>
> John Maindonald.
>
>
> ## EXAMPLE 1:
>
> library(DAAG)
> science1.lmer <- lmer(like ~ sex + PrivPub + (1 | school:class),
>                     data = science)
>> science1.lmer
>> ...
> Random effects:
> Groups       Name        Variance Std.Dev.
> school:class (Intercept) 0.321    0.566
> Residual                 3.052    1.747
> Number of obs: 1383, groups: school:class, 66
>> ...
>
> science1.mcmc <- mcmcsamp(science1.lmer , n=1000)
> z <- VarCorr(science1.mcmc, type="varcov")
> colnames(z) <- c("school:class", "Residual")
>
>> ## The following are believable!
>> t(apply(z,2, function(x)quantile(x, prob=c(.025, .975))))
>              2.5%  97.5%
> school:class 0.1442 0.4334
> Residual     2.8601 3.3427
>
>
> ## EXAMPLE 2:
> ant111b.lmer <- lmer(harvwt ~ 1 + (1 | site), data=ant111b)
>> ant111b.lmer
> ...
> Random effects:
> Groups   Name        Variance Std.Dev.
> site     (Intercept) 2.368    1.54
> Residual             0.578    0.76
> Number of obs: 32, groups: site, 8
>> ...
>
> ant111b.mcmc <- mcmcsamp(ant111b.lmer, n=1000)
> z <- VarCorr(ant111b.mcmc, type="varcov")
> colnames(z) <- c("site", "Residual")
>> t(apply(z,2, function(x)quantile(x, prob=c(.025, .975))))
>          2.5% 97.5%
> site     0.2376 1.878
> Residual 0.6370 2.488
>
>
> John Maindonald             email: john.maindonald at anu.edu.au
> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
> Centre for Mathematics & Its Applications, Room 1194,
> John Dedman Mathematical Sciences Building (Building 27)
> Australian National University, Canberra ACT 0200.
> http://www.maths.anu.edu.au/~johnm
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From john.maindonald at anu.edu.au  Mon Dec  7 10:10:27 2009
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Mon, 7 Dec 2009 20:10:27 +1100
Subject: [R-sig-ME] Restrictions on the class of GLMMs
In-Reply-To: <4B1814CA.5000802@ufl.edu>
References: <BLU139-W20698BCF1B76DA57159E01FB940@phx.gbl>
	<4B1814CA.5000802@ufl.edu>
Message-ID: <49F9C2D7-81EE-4853-956F-6589E29A1516@anu.edu.au>

Reasonably recently, it used to be possible, with glmer, to
associate one random term with each observation.  With the
current version of glmer(), I find that this is not allowed.  In the
case I was using it for, this allowed me to fit a random between
observations variance that was additive on the scale of the
linear predictor, rather than as with the dispersion estimate
fudge which estimates a constant multiplier for the theoretical
variance.  I am wondering what the reason may be for disallowing
this; does it unduly complicate code somewhere or other?

I am using lme4_0.999375-32;    Matrix_0.999375-32

Here is what I had been doing:

library(DAAG)
moths$transect <- 1:41  # Each row is from a different transect
moths$habitat <- relevel(moths$habitat, ref="Lowerside")
(A.glmer <-  glmer(A~habitat+log(meters)+(1|transect), 
                                family=poisson, data=moths))


Generalized linear mixed model fit by the Laplace approximation 
Formula: A ~ habitat + log(meters) + (1 | transect) 
  Data: moths 
AIC BIC logLik deviance
 95 112  -37.5       75
Random effects:
Groups   Name        Variance Std.Dev.
transect (Intercept) 0.234    0.483   
Number of obs: 41, groups: transect, 41

...

Thanks

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.
http://www.maths.anu.edu.au/~johnm


John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.
http://www.maths.anu.edu.au/~johnm



From cotter.rs at gmail.com  Mon Dec  7 14:43:39 2009
From: cotter.rs at gmail.com (R.S. Cotter)
Date: Mon, 7 Dec 2009 05:43:39 -0800
Subject: [R-sig-ME] Interpretation of the random effect in Linear
	Mixed-Effects Models (lme) and parameter estimation
Message-ID: <742479270912070543y46281675w2e1f43a17e7fb020@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20091207/b058f2c8/attachment.pl>

From bates at stat.wisc.edu  Mon Dec  7 14:41:56 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 7 Dec 2009 07:41:56 -0600
Subject: [R-sig-ME] Intelligent use of mcmcsamp()
In-Reply-To: <61210C29-FEEA-455A-8F43-51B51C86FAB9@anu.edu.au>
References: <BLU139-W20698BCF1B76DA57159E01FB940@phx.gbl>
	<4B1814CA.5000802@ufl.edu>
	<1259936333.3065.5.camel@localhost.localdomain>
	<61210C29-FEEA-455A-8F43-51B51C86FAB9@anu.edu.au>
Message-ID: <40e66e0b0912070541y2b5fc559x63b163655c40ecf6@mail.gmail.com>

I agree that mcmcsamp in current versions of the lme4 package provide
suspect results.  I still have problems formulating an MCMC update for
the variance components when there is a possibility the value getting
close to zero.

In the development branch of the lme4 package I have added profiling
of the deviance with respect to the parameters as a method of
determining the precision of the parameter estimates.  This package is
called lme4a in the R packages tab of
http://lme4.r-forge.r-project.org/  Unfortunately it looks like the
Windows binary is not available at R-forge (and the error message
looks peculiar because it is an error from an R declarations file - it
may be that I don't have the correct sequence of include files).

I usually look at profiles of the change in the deviance by taking the
signed square root transformation.  Results for your models are
enclosed.  In these cases there aren't problems with the variance of
the random effects approaching zero.  In the case of the Dyestuff data
we do get such behavior and the splom plot shows some rough edges as a
result.



On Sat, Dec 5, 2009 at 2:21 AM, John Maindonald
<john.maindonald at anu.edu.au> wrote:
> Below are two examples of the use of mcmcsamp() with output
> from lmer(). ?The first set of results are believable.
> For the second set of results, both variance estimates
> (for 'site' and for 'Residual' or scale) lie outside of the
> credible intervals that are obtained. ?Assuming I have
> used the functions correctly, it seems surprising that
> mcmcsamp() would 'fail' on the second example, which is
> balanced and where both variances seem well away from
> zero. ?These results are consistent over repeated
> simulations.
>
> I'd be interested to hear from list members who make regular use of
> mcmcsamp(), as well as maybe from Douglas. Is there any advance on
> the current routines in the development branch?
>
> Questions:
>
> (1) Are instances of less obvious failoure common? How does one check?
> (2) Is there are more direct way to get the credible intervals?
> (3) What insight is avaiable on why the second example fails?
>
> John Maindonald.
>
>
> ## EXAMPLE 1:
>
> library(DAAG)
> science1.lmer <- lmer(like ~ sex + PrivPub + (1 | school:class),
> ? ? ? ? ? ? ? ? ? ? data = science)
>> science1.lmer
>> ...
> Random effects:
> Groups ? ? ? Name ? ? ? ?Variance Std.Dev.
> school:class (Intercept) 0.321 ? ?0.566
> Residual ? ? ? ? ? ? ? ? 3.052 ? ?1.747
> Number of obs: 1383, groups: school:class, 66
>> ...
>
> science1.mcmc <- mcmcsamp(science1.lmer , n=1000)
> z <- VarCorr(science1.mcmc, type="varcov")
> colnames(z) <- c("school:class", "Residual")
>
>> ## The following are believable!
>> t(apply(z,2, function(x)quantile(x, prob=c(.025, .975))))
> ? ? ? ? ? ? ?2.5% ?97.5%
> school:class 0.1442 0.4334
> Residual ? ? 2.8601 3.3427
>
>
> ## EXAMPLE 2:
> ant111b.lmer <- lmer(harvwt ~ 1 + (1 | site), data=ant111b)
>> ant111b.lmer
> ...
> Random effects:
> Groups ? Name ? ? ? ?Variance Std.Dev.
> site ? ? (Intercept) 2.368 ? ?1.54
> Residual ? ? ? ? ? ? 0.578 ? ?0.76
> Number of obs: 32, groups: site, 8
>> ...
>
> ant111b.mcmc <- mcmcsamp(ant111b.lmer, n=1000)
> z <- VarCorr(ant111b.mcmc, type="varcov")
> colnames(z) <- c("site", "Residual")
>> t(apply(z,2, function(x)quantile(x, prob=c(.025, .975))))
> ? ? ? ? ?2.5% 97.5%
> site ? ? 0.2376 1.878
> Residual 0.6370 2.488
>
>
> John Maindonald ? ? ? ? ? ? email: john.maindonald at anu.edu.au
> phone : +61 2 (6125)3473 ? ?fax ?: +61 2(6125)5549
> Centre for Mathematics & Its Applications, Room 1194,
> John Dedman Mathematical Sciences Building (Building 27)
> Australian National University, Canberra ACT 0200.
> http://www.maths.anu.edu.au/~johnm
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Rplots.pdf
Type: application/pdf
Size: 175874 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20091207/e62db89c/attachment.pdf>

From john.maindonald at anu.edu.au  Mon Dec  7 23:30:58 2009
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Tue, 8 Dec 2009 09:30:58 +1100
Subject: [R-sig-ME] Intelligent use of mcmcsamp()
In-Reply-To: <40e66e0b0912070541y2b5fc559x63b163655c40ecf6@mail.gmail.com>
References: <BLU139-W20698BCF1B76DA57159E01FB940@phx.gbl>
	<4B1814CA.5000802@ufl.edu>
	<1259936333.3065.5.camel@localhost.localdomain>
	<61210C29-FEEA-455A-8F43-51B51C86FAB9@anu.edu.au>
	<40e66e0b0912070541y2b5fc559x63b163655c40ecf6@mail.gmail.com>
Message-ID: <7E346591-296A-474C-977B-844F28EE49EC@anu.edu.au>

This looks promising, thanks for your efforts.  Fortunately the MacOS X 
version runs fine, under R-devel (2.11.0 Under development).

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.
http://www.maths.anu.edu.au/~johnm

On 08/12/2009, at 12:41 AM, Douglas Bates wrote:

> I agree that mcmcsamp in current versions of the lme4 package provide
> suspect results.  I still have problems formulating an MCMC update for
> the variance components when there is a possibility the value getting
> close to zero.
> 
> In the development branch of the lme4 package I have added profiling
> of the deviance with respect to the parameters as a method of
> determining the precision of the parameter estimates.  This package is
> called lme4a in the R packages tab of
> http://lme4.r-forge.r-project.org/  Unfortunately it looks like the
> Windows binary is not available at R-forge (and the error message
> looks peculiar because it is an error from an R declarations file - it
> may be that I don't have the correct sequence of include files).
> 
> I usually look at profiles of the change in the deviance by taking the
> signed square root transformation.  Results for your models are
> enclosed.  In these cases there aren't problems with the variance of
> the random effects approaching zero.  In the case of the Dyestuff data
> we do get such behavior and the splom plot shows some rough edges as a
> result.
> 
> 
> 
> On Sat, Dec 5, 2009 at 2:21 AM, John Maindonald
> <john.maindonald at anu.edu.au> wrote:
>> Below are two examples of the use of mcmcsamp() with output
>> from lmer().  The first set of results are believable.
>> For the second set of results, both variance estimates
>> (for 'site' and for 'Residual' or scale) lie outside of the
>> credible intervals that are obtained.  Assuming I have
>> used the functions correctly, it seems surprising that
>> mcmcsamp() would 'fail' on the second example, which is
>> balanced and where both variances seem well away from
>> zero.  These results are consistent over repeated
>> simulations.
>> 
>> I'd be interested to hear from list members who make regular use of
>> mcmcsamp(), as well as maybe from Douglas. Is there any advance on
>> the current routines in the development branch?
>> 
>> Questions:
>> 
>> (1) Are instances of less obvious failoure common? How does one check?
>> (2) Is there are more direct way to get the credible intervals?
>> (3) What insight is avaiable on why the second example fails?
>> 
>> John Maindonald.
>> 
>> 
>> ## EXAMPLE 1:
>> 
>> library(DAAG)
>> science1.lmer <- lmer(like ~ sex + PrivPub + (1 | school:class),
>>                     data = science)
>>> science1.lmer
>>> ...
>> Random effects:
>> Groups       Name        Variance Std.Dev.
>> school:class (Intercept) 0.321    0.566
>> Residual                 3.052    1.747
>> Number of obs: 1383, groups: school:class, 66
>>> ...
>> 
>> science1.mcmc <- mcmcsamp(science1.lmer , n=1000)
>> z <- VarCorr(science1.mcmc, type="varcov")
>> colnames(z) <- c("school:class", "Residual")
>> 
>>> ## The following are believable!
>>> t(apply(z,2, function(x)quantile(x, prob=c(.025, .975))))
>>              2.5%  97.5%
>> school:class 0.1442 0.4334
>> Residual     2.8601 3.3427
>> 
>> 
>> ## EXAMPLE 2:
>> ant111b.lmer <- lmer(harvwt ~ 1 + (1 | site), data=ant111b)
>>> ant111b.lmer
>> ...
>> Random effects:
>> Groups   Name        Variance Std.Dev.
>> site     (Intercept) 2.368    1.54
>> Residual             0.578    0.76
>> Number of obs: 32, groups: site, 8
>>> ...
>> 
>> ant111b.mcmc <- mcmcsamp(ant111b.lmer, n=1000)
>> z <- VarCorr(ant111b.mcmc, type="varcov")
>> colnames(z) <- c("site", "Residual")
>>> t(apply(z,2, function(x)quantile(x, prob=c(.025, .975))))
>>          2.5% 97.5%
>> site     0.2376 1.878
>> Residual 0.6370 2.488
>> 
>> 
>> John Maindonald             email: john.maindonald at anu.edu.au
>> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
>> Centre for Mathematics & Its Applications, Room 1194,
>> John Dedman Mathematical Sciences Building (Building 27)
>> Australian National University, Canberra ACT 0200.
>> http://www.maths.anu.edu.au/~johnm
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 
> <john.Rout><Rplots.pdf>



From trea26 at gmail.com  Tue Dec  8 07:59:25 2009
From: trea26 at gmail.com (Antoine Tremblay)
Date: Tue, 8 Dec 2009 01:59:25 -0500
Subject: [R-sig-ME] Should I include Items as a random effect?
Message-ID: <581a8bcf0912072259v6bf87fb8q4b9a04b3211920ef@mail.gmail.com>

Dear all,

I am unsure whether I should include Items as a random effect in my model.

I have an experiment in which all of the items were created
and I'm analyzing a substantial subset of the full set of actual
items (48 out of 64, with 16 excluded because they have
somewhat strange properties). Is it warranted (or necessary or ill-advised)
to include by-item random intercepts?

I believe one school of thought would say something like "test it
(i.e., log-likelihood ratio test --> model without the term and model
with the term)
if the test is significant, leave it in".

But another school of thought would probably say "No, don't include it because
you're not interested in generalizing and you have almost the whole population".

What should I do?

Thank you in advance.
:-)

--
Antoine Tremblay
Department of Neuroscience
Georgetown University
Washington DC



From trea26 at gmail.com  Tue Dec  8 08:15:43 2009
From: trea26 at gmail.com (Antoine Tremblay)
Date: Tue, 8 Dec 2009 02:15:43 -0500
Subject: [R-sig-ME] The effects of adding by-subject or by-item random
	intercepts
Message-ID: <581a8bcf0912072315s12a418fw4f5f7c0e07f533e3@mail.gmail.com>

Dear all,

This question is about the effects of adding by-subject or by-item
random intercepts to a model.

If we are contrasting a single condition between two subject groups,
say ReactionTime ~ Sex,
is it warranted (or necessary or ill-advised) to include by-subjects
random intercepts,
since this could (if I'm understanding it correctly) adjust the mean
reaction time for each subject (and thus for
each condition) towards the grand mean, thus reducing or
eliminating the difference in the condition between subjects? And
similarly if we are contrasting a
single condition between two sets of items, say ReactionTime ~ Frequency?

I believe that the addition of the random effect may reduce the effect
of the fixed effect, but should
not remove it entirely. Is this right?

The question would then become: Why would the addition of say by-item
random intercepts to a model
take away an effect that was present in a model without by-item random
intercepts?

Thank you again, your help is well appreciated.

-- 
Antoine Tremblay
Department of Neuroscience
Georgetown University
Washington DC



From john.maindonald at anu.edu.au  Tue Dec  8 09:07:41 2009
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Tue, 8 Dec 2009 19:07:41 +1100
Subject: [R-sig-ME] The effects of adding by-subject or by-item random
	intercepts
In-Reply-To: <581a8bcf0912072315s12a418fw4f5f7c0e07f533e3@mail.gmail.com>
References: <581a8bcf0912072315s12a418fw4f5f7c0e07f533e3@mail.gmail.com>
Message-ID: <E77382C0-A993-4CD5-8DC7-F42EE75D8F95@anu.edu.au>

Think of the intercept (probably at the mean of x)  and slope 
of the fitted lines as statistics that you want to compare between 
groups.  You might use a t-test the test for no significant 
difference in intercept between the two groups. Similarly
for the slope, if you look at that on its own.

If the intercepts do differ between subjects, then the difference
in intercepts must, to be real, be greater than can be explained
by within group variation in intercepts.  Similarly for the slopes.

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.
http://www.maths.anu.edu.au/~johnm

On 08/12/2009, at 6:15 PM, Antoine Tremblay wrote:

> Dear all,
> 
> This question is about the effects of adding by-subject or by-item
> random intercepts to a model.
> 
> If we are contrasting a single condition between two subject groups,
> say ReactionTime ~ Sex,
> is it warranted (or necessary or ill-advised) to include by-subjects
> random intercepts,
> since this could (if I'm understanding it correctly) adjust the mean
> reaction time for each subject (and thus for
> each condition) towards the grand mean, thus reducing or
> eliminating the difference in the condition between subjects? And
> similarly if we are contrasting a
> single condition between two sets of items, say ReactionTime ~ Frequency?
> 
> I believe that the addition of the random effect may reduce the effect
> of the fixed effect, but should
> not remove it entirely. Is this right?
> 
> The question would then become: Why would the addition of say by-item
> random intercepts to a model
> take away an effect that was present in a model without by-item random
> intercepts?
> 
> Thank you again, your help is well appreciated.
> 
> -- 
> Antoine Tremblay
> Department of Neuroscience
> Georgetown University
> Washington DC
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From robert.espesser at lpl-aix.fr  Tue Dec  8 10:43:00 2009
From: robert.espesser at lpl-aix.fr (espesser)
Date: Tue, 08 Dec 2009 10:43:00 +0100
Subject: [R-sig-ME] possible side effect of gdata library on dotplot of
	random terms
Message-ID: <4B1E1FA4.1000704@lpl-aix.fr>

Dear all

It seems there is a name conflict between the reorder.factor() function
from the package "gdata" and the reorder.factor() from the package "stats" .
After loading the  library "gdata", dotplot(ranef( model_object.lmer)  )
 - which seems using internally  by default reorder.factor()  from the 
package "stats"  -
does not plot the random terms sorted any more .
The regular behavior can be recovered with:
detach("package:gdata",unload=T)
but is there an easier or a more convenient way ?

Thank you for your help

R. Espesser
CNRS - Universit? de Provence
Laboratoire Parole & Langage
5 avenue Pasteur
BP 80975
13604 Aix en Provence Cedex 1 (France)

web : www.lpl-aix.fr/~espesser



From moraisjr at gmail.com  Tue Dec  8 13:37:28 2009
From: moraisjr at gmail.com (Marcio M. de Morais Jr.)
Date: Tue, 8 Dec 2009 10:37:28 -0200
Subject: [R-sig-ME] Model selection and averaging
Message-ID: <2a4cf8f40912080437n38914b7co9ea34c86ab818619@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20091208/f19044f4/attachment.pl>

From danielezrajohnson at gmail.com  Tue Dec  8 13:38:18 2009
From: danielezrajohnson at gmail.com (Daniel Ezra Johnson)
Date: Tue, 8 Dec 2009 07:38:18 -0500
Subject: [R-sig-ME] The effects of adding by-subject or by-item random
	intercepts
In-Reply-To: <581a8bcf0912072315s12a418fw4f5f7c0e07f533e3@mail.gmail.com>
References: <581a8bcf0912072315s12a418fw4f5f7c0e07f533e3@mail.gmail.com>
Message-ID: <15252146-6732-46B3-A8B3-B10E2323DE23@gmail.com>

Shrinkage is not the main issue, as I see it here. When the predictor  
of interest is Sex you should include by-subject random effect(s),  
when it's Frequency you should include by-item. Probably you should  
include both in both cases. You can't do accurate hypothesis testing  
on Sex and Frequency if you ignore the variation among Subjects and  
Items.

On Dec 8, 2009, at 2:15 AM, Antoine Tremblay <trea26 at gmail.com> wrote:

> Dear all,
>
> This question is about the effects of adding by-subject or by-item
> random intercepts to a model.
>
> If we are contrasting a single condition between two subject groups,
> say ReactionTime ~ Sex,
> is it warranted (or necessary or ill-advised) to include by-subjects
> random intercepts,
> since this could (if I'm understanding it correctly) adjust the mean
> reaction time for each subject (and thus for
> each condition) towards the grand mean, thus reducing or
> eliminating the difference in the condition between subjects? And
> similarly if we are contrasting a
> single condition between two sets of items, say ReactionTime ~  
> Frequency?
>
> I believe that the addition of the random effect may reduce the effect
> of the fixed effect, but should
> not remove it entirely. Is this right?
>
> The question would then become: Why would the addition of say by-item
> random intercepts to a model
> take away an effect that was present in a model without by-item random
> intercepts?
>
> Thank you again, your help is well appreciated.
>
> -- 
> Antoine Tremblay
> Department of Neuroscience
> Georgetown University
> Washington DC
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From lborger at uoguelph.ca  Tue Dec  8 13:54:50 2009
From: lborger at uoguelph.ca (Luca Borger)
Date: Tue, 8 Dec 2009 07:54:50 -0500 (EST)
Subject: [R-sig-ME] Model selection and averaging
In-Reply-To: <523842273.35669561260276838751.JavaMail.root@huron.cs.uoguelph.ca>
Message-ID: <1181424095.35669641260276890937.JavaMail.root@huron.cs.uoguelph.ca>

Hello

>is there any
>package capable to do model selection using a glmm object fitted by ML?

unless I got this wrong, GLMMs are fitted by ML. If you type

?lmer

after loading the lme4 library you can see that it says:

"REML logical argument to lmer only."


HTH


Cheers,

Luca

 
----- Original Message -----
From: "Marcio M. de Morais Jr." <moraisjr at gmail.com>
To: r-sig-mixed-models at r-project.org
Sent: Tuesday, 8 December, 2009 13:37:28 GMT +01:00 Amsterdam / Berlin / Bern / Rome / Stockholm / Vienna
Subject: [R-sig-ME] Model selection and averaging

Dear list members,

I am using glmmML package to access the effects of variables on
presence-absence data set.  I intend to use IC model selection and
averaging, and have looked for a package to do it. I have found none that
can work with glmmML objects, but MuMIn works with glmer. Since my models
are only different in their fixed effects, I would like to know if it is
correct to use model selection for glmer objects that are fitted by REML. I
have read that models fitted by REML can be compared only if they are
different in their random effect. Is that right? If it is, is there any
package capable to do model selection using a glmm object fitted by ML?

Thank you very much for your consideration

Marcio de Morais

	[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From moraisjr at gmail.com  Tue Dec  8 14:10:12 2009
From: moraisjr at gmail.com (Marcio M. de Morais Jr.)
Date: Tue, 8 Dec 2009 11:10:12 -0200
Subject: [R-sig-ME] Model selection and averaging
In-Reply-To: <1181424095.35669641260276890937.JavaMail.root@huron.cs.uoguelph.ca>
References: <523842273.35669561260276838751.JavaMail.root@huron.cs.uoguelph.ca>
	<1181424095.35669641260276890937.JavaMail.root@huron.cs.uoguelph.ca>
Message-ID: <2a4cf8f40912080510k1d18eb51s24c5c371a4e8a488@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20091208/07671388/attachment.pl>

From bates at stat.wisc.edu  Tue Dec  8 14:59:45 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 8 Dec 2009 07:59:45 -0600
Subject: [R-sig-ME] possible side effect of gdata library on dotplot of
	random terms
In-Reply-To: <4B1E1FA4.1000704@lpl-aix.fr>
References: <4B1E1FA4.1000704@lpl-aix.fr>
Message-ID: <40e66e0b0912080559g4cc66cf0m27258ae8dc23ab97@mail.gmail.com>

My suggestion would be not to use gdata. :-)

More seriously, as I understand it you are saying that gdata provides
a method for reorder that is not upwardly compatible with the method
in the stats package.  If so, I would regard this as a flaw in the
design of the gdata package.   One should not willfully change the
behavior of functions in required packages.

Having said that, I am a bit confused by your saying that dotplot
seems to be using the method from the stats package but it does not
provide the desired reordering when gdata is attached in the search
path before stats.  The first part (continuing to use the method from
stats) is what I would expect to happen.  This is exactly what
namespaces are for - to seal the set of functions and methods that are
seen inside the lme4 package.  What I don't understand is why the plot
does not then work as before.

Could you provide us with a reproducible example and the output of
sessionInfo() please?

On Tue, Dec 8, 2009 at 3:43 AM, espesser <robert.espesser at lpl-aix.fr> wrote:
> Dear all
>
> It seems there is a name conflict between the reorder.factor() function
> from the package "gdata" and the reorder.factor() from the package "stats" .
> After loading the ?library "gdata", dotplot(ranef( model_object.lmer) ?)
> - which seems using internally ?by default reorder.factor() ?from the
> package "stats" ?-
> does not plot the random terms sorted any more .
> The regular behavior can be recovered with:
> detach("package:gdata",unload=T)
> but is there an easier or a more convenient way ?
>
> Thank you for your help
>
> R. Espesser
> CNRS - Universit? de Provence
> Laboratoire Parole & Langage
> 5 avenue Pasteur
> BP 80975
> 13604 Aix en Provence Cedex 1 (France)
>
> web : www.lpl-aix.fr/~espesser
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From bolker at ufl.edu  Tue Dec  8 16:01:00 2009
From: bolker at ufl.edu (Ben Bolker)
Date: Tue, 08 Dec 2009 10:01:00 -0500
Subject: [R-sig-ME] Model selection and averaging
In-Reply-To: <2a4cf8f40912080510k1d18eb51s24c5c371a4e8a488@mail.gmail.com>
References: <523842273.35669561260276838751.JavaMail.root@huron.cs.uoguelph.ca>	<1181424095.35669641260276890937.JavaMail.root@huron.cs.uoguelph.ca>
	<2a4cf8f40912080510k1d18eb51s24c5c371a4e8a488@mail.gmail.com>
Message-ID: <4B1E6A2C.9000603@ufl.edu>

  How different are your results?  Are you using Laplace or AGQ in lmer?
Are the results really very different? (Two possibilities that aren't
"really different": (1) p-values on either side of a magic p=0.05 line
but numerically reasonably close; (2) estimates that are biologically
(or whatever) significantly different, but with confidence intervals on
each that suggest we can't really tell them apart.)
In one small example
<http://glmm.wdfiles.com/local--files/examples/culcita_glmm.pdf> I got
similar results between the two.

  More details?

   Ben Bolker

Marcio M. de Morais Jr. wrote:
> Thank you Luca
> 
> Reading that I interpreted you could choose REML or ML for lmer, but
> glmer would
> use REML. I thought that, mainly because I have got different results
> fitting the same model in glmer and glmmML and differences in REML and ML
> could be the reason.
> 
> Cheers,
> 
> Marcio
> 
> 2009/12/8 Luca Borger <lborger at uoguelph.ca>
> 
>> Hello
>>
>>> is there any
>>> package capable to do model selection using a glmm object fitted by ML?
>> unless I got this wrong, GLMMs are fitted by ML. If you type
>>
>> ?lmer
>>
>> after loading the lme4 library you can see that it says:
>>
>> "REML logical argument to lmer only."
>>
>>
>> HTH
>>
>>
>> Cheers,
>>
>> Luca
>>
>>
>> ----- Original Message -----
>> From: "Marcio M. de Morais Jr." <moraisjr at gmail.com>
>> To: r-sig-mixed-models at r-project.org
>> Sent: Tuesday, 8 December, 2009 13:37:28 GMT +01:00 Amsterdam / Berlin /
>> Bern / Rome / Stockholm / Vienna
>> Subject: [R-sig-ME] Model selection and averaging
>>
>> Dear list members,
>>
>> I am using glmmML package to access the effects of variables on
>> presence-absence data set.  I intend to use IC model selection and
>> averaging, and have looked for a package to do it. I have found none that
>> can work with glmmML objects, but MuMIn works with glmer. Since my models
>> are only different in their fixed effects, I would like to know if it is
>> correct to use model selection for glmer objects that are fitted by REML. I
>> have read that models fitted by REML can be compared only if they are
>> different in their random effect. Is that right? If it is, is there any
>> package capable to do model selection using a glmm object fitted by ML?
>>
>> Thank you very much for your consideration
>>
>> Marcio de Morais
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
> 
> 
> 


-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / www.zoology.ufl.edu/bolker
GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc



From kw.stat at gmail.com  Tue Dec  8 16:25:37 2009
From: kw.stat at gmail.com (Kevin Wright)
Date: Tue, 8 Dec 2009 09:25:37 -0600
Subject: [R-sig-ME] possible side effect of gdata library on dotplot of
	random terms
In-Reply-To: <4B1E1FA4.1000704@lpl-aix.fr>
References: <4B1E1FA4.1000704@lpl-aix.fr>
Message-ID: <5c62e0070912080725jc7626dds4e3f9372de32d34d@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20091208/e2bfab68/attachment.pl>

From robert.espesser at lpl-aix.fr  Tue Dec  8 18:53:06 2009
From: robert.espesser at lpl-aix.fr (espesser)
Date: Tue, 08 Dec 2009 18:53:06 +0100
Subject: [R-sig-ME] possible side effect of gdata library on dotplot of
 random terms
In-Reply-To: <40e66e0b0912080559g4cc66cf0m27258ae8dc23ab97@mail.gmail.com>
References: <4B1E1FA4.1000704@lpl-aix.fr>
	<40e66e0b0912080559g4cc66cf0m27258ae8dc23ab97@mail.gmail.com>
Message-ID: <4B1E9282.30200@lpl-aix.fr>

Here is a reproducible example:

# begin of a  new session of R
 > sessionInfo()
R version 2.8.1 (2008-12-22)
i386-pc-mingw32

locale:
LC_COLLATE=French_France.1252;LC_CTYPE=French_France.1252;LC_MONETARY=French_France.1252;LC_NUMERIC=C;LC_TIME=French_France.1252

attached base packages:
[1] stats     graphics  grDevices datasets  utils     methods   base    

loaded via a namespace (and not attached):
[1] grid_2.8.1         lattice_0.17-17    lme4_0.999375-28   
Matrix_0.999375-21


##### REM:  I got  same results with a scratch install of R 2.10.0

 > library(lme4)
 > data(sleepstudy)
 > fm2 <- lmer(Reaction ~ Days + (1|Subject),data=sleepstudy)
 > dotplot(ranef(fm2))

# dotplot OK

 > library(gdata)
 > dotplot(ranef(fm2))
# dotplot  not in order

# the suggestion of Kevin Wright  seems OK :
 >Maybe just copy the correct version of the function into .GlobalEnv
 >so that it is first on the search path:

reorder.factor=stats:::reorder.factor
dotplot(ranef(fm2))
# OK

Douglas Bates a ?crit :
> My suggestion would be not to use gdata. :-)
>
> More seriously, as I understand it you are saying that gdata provides
> a method for reorder that is not upwardly compatible with the method
> in the stats package.  If so, I would regard this as a flaw in the
> design of the gdata package.   One should not willfully change the
> behavior of functions in required packages.
>
> Having said that, I am a bit confused by your saying that dotplot
> seems to be using the method from the stats package but it does not
> provide the desired reordering when gdata is attached in the search
> path before stats.  The first part (continuing to use the method from
> stats) is what I would expect to happen.  This is exactly what
> namespaces are for - to seal the set of functions and methods that are
> seen inside the lme4 package.  What I don't understand is why the plot
> does not then work as before.
>
> Could you provide us with a reproducible example and the output of
> sessionInfo() please?
>
> On Tue, Dec 8, 2009 at 3:43 AM, espesser <robert.espesser at lpl-aix.fr> wrote:
>   
>> Dear all
>>
>> It seems there is a name conflict between the reorder.factor() function
>> from the package "gdata" and the reorder.factor() from the package "stats" .
>> After loading the  library "gdata", dotplot(ranef( model_object.lmer)  )
>> - which seems using internally  by default reorder.factor()  from the
>> package "stats"  -
>> does not plot the random terms sorted any more .
>> The regular behavior can be recovered with:
>> detach("package:gdata",unload=T)
>> but is there an easier or a more convenient way ?
>>
>> Thank you for your help
>>
>> R. Espesser
>> CNRS - Universit? de Provence
>> Laboratoire Parole & Langage
>> 5 avenue Pasteur
>> BP 80975
>> 13604 Aix en Provence Cedex 1 (France)
>>
>> web : www.lpl-aix.fr/~espesser
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>



From bolker at ufl.edu  Tue Dec  8 19:17:56 2009
From: bolker at ufl.edu (Ben Bolker)
Date: Tue, 08 Dec 2009 13:17:56 -0500
Subject: [R-sig-ME] compilation errors on current (r-forge) lme4a
Message-ID: <4B1E9854.9020104@ufl.edu>


  this is on Ubuntu 8.04 (I think: it's "Intrepid Ibex", I have trouble
keeping track of the numbers):
Linux bolker-lap2 2.6.27-16-generic #1 SMP Tue Dec 1 17:56:54 UTC 2009
i686 GNU/Linux
ben at bolker-lap2:~/lib/R/pkgs/lme4/pkg$ g++ --version
g++ (Ubuntu 4.3.2-1ubuntu12) 4.3.2

  I will work on tracking this down later, but wondered if anyone had
run into/solved the same problem ...  I've never had trouble compiling
these before, perhaps it's some new Ubuntu bug?

ben at bolker-lap2:~/lib/R/pkgs/lme4/pkg$ sudo R CMD INSTALL lme4a
* installing to library ?/usr/local/lib/R/site-library?
* installing *source* package ?lme4a? ...
** libs
g++ -I/usr/share/R/include   -I"/usr/lib/R/library/Matrix/include"
-fpic  -g -O2 -c ST.cpp -o ST.o
gcc -std=gnu99 -I/usr/share/R/include
-I"/usr/lib/R/library/Matrix/include"   -fpic  -g -O2 -c init.c -o init.o
g++ -I/usr/share/R/include   -I"/usr/lib/R/library/Matrix/include"
-fpic  -g -O2 -c lme4utils.cpp -o lme4utils.o
gcc -std=gnu99 -I/usr/share/R/include
-I"/usr/lib/R/library/Matrix/include"   -fpic  -g -O2 -c local_stubs.c
-o local_stubs.o
g++ -I/usr/share/R/include   -I"/usr/lib/R/library/Matrix/include"
-fpic  -g -O2 -c mer.cpp -o mer.o
g++ -I/usr/share/R/include   -I"/usr/lib/R/library/Matrix/include"
-fpic  -g -O2 -c merenv.cpp -o merenv.o
In file included from lme4utils.hpp:3,
                 from merenv.cpp:3:
/usr/include/c++/4.3/cstdarg:58: error: expected unqualified-id before
?namespace?
make: *** [merenv.o] Error 1
ERROR: compilation failed for package ?lme4a?
* removing ?/usr/local/lib/R/site-library/lme4a?

-- 
Ben Bolker
Associate professor, Biology Dep't, Univ. of Florida
bolker at ufl.edu / www.zoology.ufl.edu/bolker
GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc



From trea26 at gmail.com  Tue Dec  8 19:19:17 2009
From: trea26 at gmail.com (Antoine Tremblay)
Date: Tue, 8 Dec 2009 13:19:17 -0500
Subject: [R-sig-ME] The effects of adding by-subject or by-item random
	intercepts
In-Reply-To: <15252146-6732-46B3-A8B3-B10E2323DE23@gmail.com>
References: <581a8bcf0912072315s12a418fw4f5f7c0e07f533e3@mail.gmail.com>
	<15252146-6732-46B3-A8B3-B10E2323DE23@gmail.com>
Message-ID: <581a8bcf0912081019j76a63ffcm209c8498724c3863@mail.gmail.com>

Thank you for your replies.
:-)

Let's see if I understood well. Say I test for a frequency effect
(high vs low) ReactionTime ~ Frequency without the by-items random
intercepts and find a difference.

Now in a model where I do include by-items random intercepts
ReactionTime ~ Frequency + (1|Item) the frequency effect disappears.

Then the frequency effect found in the model without by-item random
intercepts was spurious, i.e., was due only to within group
variability and not to a true population effect. Is that right?

Now say I have created artificial items, which I used in my
experiment. I thus have all the whole population of items. Should I
still include Items as a random effect? If it is the case, then,
including or not a random effect is not only a matter of wanting to
generalize over subjects or items, but rather a matter of getting rid
of, so to speak, within-group variability, which, if uncontrolled for,
may lead to spurious effects. Is that right?

Thank you again for your help.
Sincerely,

Antoine

On Tue, Dec 8, 2009 at 7:38 AM, Daniel Ezra Johnson
<danielezrajohnson at gmail.com> wrote:
> Shrinkage is not the main issue, as I see it here. When the predictor of
> interest is Sex you should include by-subject random effect(s), when it's
> Frequency you should include by-item. Probably you should include both in
> both cases. You can't do accurate hypothesis testing on Sex and Frequency if
> you ignore the variation among Subjects and Items.
>
> On Dec 8, 2009, at 2:15 AM, Antoine Tremblay <trea26 at gmail.com> wrote:
>
>> Dear all,
>>
>> This question is about the effects of adding by-subject or by-item
>> random intercepts to a model.
>>
>> If we are contrasting a single condition between two subject groups,
>> say ReactionTime ~ Sex,
>> is it warranted (or necessary or ill-advised) to include by-subjects
>> random intercepts,
>> since this could (if I'm understanding it correctly) adjust the mean
>> reaction time for each subject (and thus for
>> each condition) towards the grand mean, thus reducing or
>> eliminating the difference in the condition between subjects? And
>> similarly if we are contrasting a
>> single condition between two sets of items, say ReactionTime ~ Frequency?
>>
>> I believe that the addition of the random effect may reduce the effect
>> of the fixed effect, but should
>> not remove it entirely. Is this right?
>>
>> The question would then become: Why would the addition of say by-item
>> random intercepts to a model
>> take away an effect that was present in a model without by-item random
>> intercepts?
>>
>> Thank you again, your help is well appreciated.
>>
>> --
>> Antoine Tremblay
>> Department of Neuroscience
>> Georgetown University
>> Washington DC
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
Antoine Tremblay
Department of Neuroscience
Georgetown University
Washington DC



From danielezrajohnson at gmail.com  Tue Dec  8 19:24:33 2009
From: danielezrajohnson at gmail.com (Daniel Ezra Johnson)
Date: Tue, 8 Dec 2009 13:24:33 -0500
Subject: [R-sig-ME] The effects of adding by-subject or by-item random
	intercepts
In-Reply-To: <581a8bcf0912081019j76a63ffcm209c8498724c3863@mail.gmail.com>
References: <581a8bcf0912072315s12a418fw4f5f7c0e07f533e3@mail.gmail.com>
	<15252146-6732-46B3-A8B3-B10E2323DE23@gmail.com>
	<581a8bcf0912081019j76a63ffcm209c8498724c3863@mail.gmail.com>
Message-ID: <2CB5FD8D-89C1-4927-A403-44743D833866@gmail.com>

The choice is in theory between treating Item as a random effect or a  
fixed effect. Not in my view omitting it totally.

In practice you have to use a random effect or a singularity (non- 
estimable model) results.

Dan

  Tremblay <trea26 at gmail.com> wrote:

> Thank you for your replies.
> :-)
>
> Let's see if I understood well. Say I test for a frequency effect
> (high vs low) ReactionTime ~ Frequency without the by-items random
> intercepts and find a difference.
>
> Now in a model where I do include by-items random intercepts
> ReactionTime ~ Frequency + (1|Item) the frequency effect disappears.
>
> Then the frequency effect found in the model without by-item random
> intercepts was spurious, i.e., was due only to within group
> variability and not to a true population effect. Is that right?
>
> Now say I have created artificial items, which I used in my
> experiment. I thus have all the whole population of items. Should I
> still include Items as a random effect? If it is the case, then,
> including or not a random effect is not only a matter of wanting to
> generalize over subjects or items, but rather a matter of getting rid
> of, so to speak, within-group variability, which, if uncontrolled for,
> may lead to spurious effects. Is that right?
>
> Thank you again for your help.
> Sincerely,
>
> Antoine
>
> On Tue, Dec 8, 2009 at 7:38 AM, Daniel Ezra Johnson
> <danielezrajohnson at gmail.com> wrote:
>> Shrinkage is not the main issue, as I see it here. When the  
>> predictor of
>> interest is Sex you should include by-subject random effect(s),  
>> when it's
>> Frequency you should include by-item. Probably you should include  
>> both in
>> both cases. You can't do accurate hypothesis testing on Sex and  
>> Frequency if
>> you ignore the variation among Subjects and Items.
>>
>> On Dec 8, 2009, at 2:15 AM, Antoine Tremblay <trea26 at gmail.com>  
>> wrote:
>>
>>> Dear all,
>>>
>>> This question is about the effects of adding by-subject or by-item
>>> random intercepts to a model.
>>>
>>> If we are contrasting a single condition between two subject groups,
>>> say ReactionTime ~ Sex,
>>> is it warranted (or necessary or ill-advised) to include by-subjects
>>> random intercepts,
>>> since this could (if I'm understanding it correctly) adjust the mean
>>> reaction time for each subject (and thus for
>>> each condition) towards the grand mean, thus reducing or
>>> eliminating the difference in the condition between subjects? And
>>> similarly if we are contrasting a
>>> single condition between two sets of items, say ReactionTime ~  
>>> Frequency?
>>>
>>> I believe that the addition of the random effect may reduce the  
>>> effect
>>> of the fixed effect, but should
>>> not remove it entirely. Is this right?
>>>
>>> The question would then become: Why would the addition of say by- 
>>> item
>>> random intercepts to a model
>>> take away an effect that was present in a model without by-item  
>>> random
>>> intercepts?
>>>
>>> Thank you again, your help is well appreciated.
>>>
>>> --
>>> Antoine Tremblay
>>> Department of Neuroscience
>>> Georgetown University
>>> Washington DC
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>
>
> -- 
> Antoine Tremblay
> Department of Neuroscience
> Georgetown University
> Washington DC



From bates at stat.wisc.edu  Tue Dec  8 19:55:13 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 8 Dec 2009 12:55:13 -0600
Subject: [R-sig-ME] compilation errors on current (r-forge) lme4a
In-Reply-To: <4B1E9854.9020104@ufl.edu>
References: <4B1E9854.9020104@ufl.edu>
Message-ID: <40e66e0b0912081055mdb0b589hfceace45c8f4f9be@mail.gmail.com>

Thanks for the heads up, Ben.  This is a classic error made by C
programmers writing C++; forgetting the semicolon after a class
declaration.  It is difficult to diagnose because the error isn't
detected until the next file so one always ends up looking in the
wrong place.  For example, the error is actually in merenv.hpp, not in
any of the files mentioned in the error report.

Fixed in SVN version 550.

Normally I would catch this before committing but we have a winter
storm warning here today with a severe blizzard on its way so I
committed before leaving for home to allow me to continue to work from
home.



On Tue, Dec 8, 2009 at 12:17 PM, Ben Bolker <bolker at ufl.edu> wrote:
>
> ?this is on Ubuntu 8.04 (I think: it's "Intrepid Ibex", I have trouble
> keeping track of the numbers):
> Linux bolker-lap2 2.6.27-16-generic #1 SMP Tue Dec 1 17:56:54 UTC 2009
> i686 GNU/Linux
> ben at bolker-lap2:~/lib/R/pkgs/lme4/pkg$ g++ --version
> g++ (Ubuntu 4.3.2-1ubuntu12) 4.3.2
>
> ?I will work on tracking this down later, but wondered if anyone had
> run into/solved the same problem ... ?I've never had trouble compiling
> these before, perhaps it's some new Ubuntu bug?
>
> ben at bolker-lap2:~/lib/R/pkgs/lme4/pkg$ sudo R CMD INSTALL lme4a
> * installing to library ?/usr/local/lib/R/site-library?
> * installing *source* package ?lme4a? ...
> ** libs
> g++ -I/usr/share/R/include ? -I"/usr/lib/R/library/Matrix/include"
> -fpic ?-g -O2 -c ST.cpp -o ST.o
> gcc -std=gnu99 -I/usr/share/R/include
> -I"/usr/lib/R/library/Matrix/include" ? -fpic ?-g -O2 -c init.c -o init.o
> g++ -I/usr/share/R/include ? -I"/usr/lib/R/library/Matrix/include"
> -fpic ?-g -O2 -c lme4utils.cpp -o lme4utils.o
> gcc -std=gnu99 -I/usr/share/R/include
> -I"/usr/lib/R/library/Matrix/include" ? -fpic ?-g -O2 -c local_stubs.c
> -o local_stubs.o
> g++ -I/usr/share/R/include ? -I"/usr/lib/R/library/Matrix/include"
> -fpic ?-g -O2 -c mer.cpp -o mer.o
> g++ -I/usr/share/R/include ? -I"/usr/lib/R/library/Matrix/include"
> -fpic ?-g -O2 -c merenv.cpp -o merenv.o
> In file included from lme4utils.hpp:3,
> ? ? ? ? ? ? ? ? from merenv.cpp:3:
> /usr/include/c++/4.3/cstdarg:58: error: expected unqualified-id before
> ?namespace?
> make: *** [merenv.o] Error 1
> ERROR: compilation failed for package ?lme4a?
> * removing ?/usr/local/lib/R/site-library/lme4a?
>
> --
> Ben Bolker
> Associate professor, Biology Dep't, Univ. of Florida
> bolker at ufl.edu / www.zoology.ufl.edu/bolker
> GPG key: www.zoology.ufl.edu/bolker/benbolker-publickey.asc
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From john.maindonald at anu.edu.au  Tue Dec  8 23:19:31 2009
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Wed, 9 Dec 2009 09:19:31 +1100
Subject: [R-sig-ME] Restrictions on the class of GLMMs
In-Reply-To: <29604_1260177252_4B1CC763_29604_99_1_49F9C2D7-81EE-4853-956F-6589E29A1516@anu.edu.au>
References: <BLU139-W20698BCF1B76DA57159E01FB940@phx.gbl>
	<4B1814CA.5000802@ufl.edu>
	<29604_1260177252_4B1CC763_29604_99_1_49F9C2D7-81EE-4853-956F-6589E29A1516@anu.edu.au>
Message-ID: <5F931E24-5D83-451D-ABE6-A8400FDAF484@anu.edu.au>

It occurred to me that I should try the calculation that I was after with
the development version (lme4a).  This version does allow the calculation 
(with one level of the grouping factor transect for the random effects
the same as the number of observations) to proceed. So I am hoping that 
lme4a is the way that it will be.  [Below, I compare the result with that from
glmmPQL from MASS.]

For this particular example, there are particular issues with the "Bank" habitat.
The count is zero, and the relevant parameter (on a log scale) has to 
represent 0 as exp(-C), where C is a suitably large number whose estimate 
depends on the convergence criteria.  So it is probably sensible to leave "Bank" 
out of the main calculation.  One has:

[lme4a_0.999375-44]
[Dependencies create problems for loading DAAG into R-devel.
So I saved the image under R-2.10.0 into moths.RData, and then
loaded that image.]
> library(lme4a)
> moths$transect <- 1:41  # Each row is from a different transect 
> moths$habitat <- relevel(moths$habitat, ref="Lowerside") 
> (A.glmer <-  glmer(A~habitat+log(meters)+(1|transect),  
+                    family=poisson, data=subset(moths,subset=habitat!="Bank"))) 
Generalized linear mixed model fit by the Laplace approximation 
Formula: A ~ habitat + log(meters) + (1 | transect) 
  Data: subset(moths, subset = habitat != "Bank") 
AIC BIC logLik deviance
208 223    -95      190
Random effects:
Groups   Name        Variance Std.Dev.
transect (Intercept) 0.229    0.478   
Number of obs: 40, groups: transect, 40

Fixed effects:
                Estimate Std. Error z value Pr(>|z|)
(Intercept)        1.0876     0.3963    2.74  0.00607
habitatDisturbed  -1.2326     0.4699   -2.62  0.00872
habitatNEsoak     -0.8210     0.4402   -1.87  0.06216
habitatNWsoak      1.5166     0.3915    3.87  0.00011
habitatSEsoak      0.0515     0.3505    0.15  0.88321
habitatSWsoak      0.2435     0.4543    0.54  0.59188
habitatUpperside  -0.1669     0.5366   -0.31  0.75570
log(meters)        0.1506     0.1374    1.10  0.27293
. . . .

The same (?) analysis is possible under glmmPQL from MASS.  
(This relies on iterated calls to lme(), from nlme.) The estimates are 
very similar, but the SEs are noticeably different:

> A.glmmPQL <-  glmmPQL(A~habitat+log(meters), random=~1|transect,  
+                    family=poisson, data=subset(moths,subset=habitat!="Bank"))
Random effects:
Formula: ~1 | transect
       (Intercept) Residual
StdDev:       0.448     1.04

Variance function:
Structure: fixed weights
Formula: ~invwt 
Fixed effects: A ~ habitat + log(meters) 
                 Value Std.Error DF t-value p-value
(Intercept)       1.110     0.437 32    2.54  0.0162
habitatDisturbed -1.240     0.528 32   -2.35  0.0253
habitatNEsoak    -0.821     0.488 32   -1.68  0.1027
habitatNWsoak     1.514     0.422 32    3.58  0.0011
habitatSEsoak     0.053     0.385 32    0.14  0.8917
habitatSWsoak     0.240     0.497 32    0.48  0.6326
habitatUpperside -0.166     0.590 32   -0.28  0.7795
log(meters)       0.147     0.151 32    0.97  0.3399

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.
http://www.maths.anu.edu.au/~johnm

On 07/12/2009, at 8:10 PM, John Maindonald wrote:

> Reasonably recently, it used to be possible, with glmer, to
> associate one random term with each observation.  With the
> current version of glmer(), I find that this is not allowed.  In the
> case I was using it for, this allowed me to fit a random between
> observations variance that was additive on the scale of the
> linear predictor, rather than as with the dispersion estimate
> fudge which estimates a constant multiplier for the theoretical
> variance.  I am wondering what the reason may be for disallowing
> this; does it unduly complicate code somewhere or other?
> 
> I am using lme4_0.999375-32;    Matrix_0.999375-32
> 
> Here is what I had been doing:
> 
> library(DAAG)
> moths$transect <- 1:41  # Each row is from a different transect
> moths$habitat <- relevel(moths$habitat, ref="Lowerside")
> (A.glmer <-  glmer(A~habitat+log(meters)+(1|transect), 
>                               family=poisson, data=moths))
> 
> 
> Generalized linear mixed model fit by the Laplace approximation 
> Formula: A ~ habitat + log(meters) + (1 | transect) 
> Data: moths 
> AIC BIC logLik deviance
> 95 112  -37.5       75
> Random effects:
> Groups   Name        Variance Std.Dev.
> transect (Intercept) 0.234    0.483   
> Number of obs: 41, groups: transect, 41
> 
> ...
> 
> Thanks
> 
> John Maindonald             email: john.maindonald at anu.edu.au
> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
> Centre for Mathematics & Its Applications, Room 1194,
> John Dedman Mathematical Sciences Building (Building 27)
> Australian National University, Canberra ACT 0200.
> http://www.maths.anu.edu.au/~johnm
> 
> 
> John Maindonald             email: john.maindonald at anu.edu.au
> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
> Centre for Mathematics & Its Applications, Room 1194,
> John Dedman Mathematical Sciences Building (Building 27)
> Australian National University, Canberra ACT 0200.
> http://www.maths.anu.edu.au/~johnm
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From john.maindonald at anu.edu.au  Wed Dec  9 00:18:40 2009
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Wed, 9 Dec 2009 10:18:40 +1100
Subject: [R-sig-ME] Intelligent use of mcmcsamp()
In-Reply-To: <13629_1260225217_4B1D82C1_13629_2098_1_7E346591-296A-474C-977B-844F28EE49EC@anu.edu.au>
References: <BLU139-W20698BCF1B76DA57159E01FB940@phx.gbl>
	<4B1814CA.5000802@ufl.edu>
	<1259936333.3065.5.camel@localhost.localdomain>
	<61210C29-FEEA-455A-8F43-51B51C86FAB9@anu.edu.au>
	<40e66e0b0912070541y2b5fc559x63b163655c40ecf6@mail.gmail.com>
	<13629_1260225217_4B1D82C1_13629_2098_1_7E346591-296A-474C-977B-844F28EE49EC@anu.edu.au>
Message-ID: <6B1B6D5B-99E9-49D3-AFAC-2A999CC3F241@anu.edu.au>

I wonder whether you have considered simulation from the full
variance-covariance matrix.  For some samples, one or more
variance parameter estimates will be allowed to go negative, 
but the full variance-covariance matrix should still be positive 
definite.  This avoids any problem with variance close to zero,
but it does mean (and I think this a useful side-effect) that 
credible intervals will sometimes have a negative lower bound,
or even lie entirely on the negative real line!

Why a useful side effect?  I've encountered cases where scientists, 
in a field experiment, have chosen blocks that are e.g., long strip 
at right angles to a river bank, thus spanning about as wide a range 
of variation as is possible.  (I've been told about the river bank 
example, the examples in my own experience were a bit different.)
A model in which there is a negative component of variance may 
then give a formally correct variance-covariance structure.  It is a bit 
like using a complex number representation to solve some problems 
on the real line.

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.
http://www.maths.anu.edu.au/~johnm

On 08/12/2009, at 9:30 AM, John Maindonald wrote:

> This looks promising, thanks for your efforts.  Fortunately the MacOS X 
> version runs fine, under R-devel (2.11.0 Under development).
> 
> John Maindonald             email: john.maindonald at anu.edu.au
> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
> Centre for Mathematics & Its Applications, Room 1194,
> John Dedman Mathematical Sciences Building (Building 27)
> Australian National University, Canberra ACT 0200.
> http://www.maths.anu.edu.au/~johnm
> 
> On 08/12/2009, at 12:41 AM, Douglas Bates wrote:
> 
>> I agree that mcmcsamp in current versions of the lme4 package provide
>> suspect results.  I still have problems formulating an MCMC update for
>> the variance components when there is a possibility the value getting
>> close to zero.
>> 
>> In the development branch of the lme4 package I have added profiling
>> of the deviance with respect to the parameters as a method of
>> determining the precision of the parameter estimates.  This package is
>> called lme4a in the R packages tab of
>> http://lme4.r-forge.r-project.org/  Unfortunately it looks like the
>> Windows binary is not available at R-forge (and the error message
>> looks peculiar because it is an error from an R declarations file - it
>> may be that I don't have the correct sequence of include files).
>> 
>> I usually look at profiles of the change in the deviance by taking the
>> signed square root transformation.  Results for your models are
>> enclosed.  In these cases there aren't problems with the variance of
>> the random effects approaching zero.  In the case of the Dyestuff data
>> we do get such behavior and the splom plot shows some rough edges as a
>> result.
>> 
>> 
>> 
>> On Sat, Dec 5, 2009 at 2:21 AM, John Maindonald
>> <john.maindonald at anu.edu.au> wrote:
>>> Below are two examples of the use of mcmcsamp() with output
>>> from lmer().  The first set of results are believable.
>>> For the second set of results, both variance estimates
>>> (for 'site' and for 'Residual' or scale) lie outside of the
>>> credible intervals that are obtained.  Assuming I have
>>> used the functions correctly, it seems surprising that
>>> mcmcsamp() would 'fail' on the second example, which is
>>> balanced and where both variances seem well away from
>>> zero.  These results are consistent over repeated
>>> simulations.
>>> 
>>> I'd be interested to hear from list members who make regular use of
>>> mcmcsamp(), as well as maybe from Douglas. Is there any advance on
>>> the current routines in the development branch?
>>> 
>>> Questions:
>>> 
>>> (1) Are instances of less obvious failoure common? How does one check?
>>> (2) Is there are more direct way to get the credible intervals?
>>> (3) What insight is avaiable on why the second example fails?
>>> 
>>> John Maindonald.
>>> 
>>> 
>>> ## EXAMPLE 1:
>>> 
>>> library(DAAG)
>>> science1.lmer <- lmer(like ~ sex + PrivPub + (1 | school:class),
>>>                   data = science)
>>>> science1.lmer
>>>> ...
>>> Random effects:
>>> Groups       Name        Variance Std.Dev.
>>> school:class (Intercept) 0.321    0.566
>>> Residual                 3.052    1.747
>>> Number of obs: 1383, groups: school:class, 66
>>>> ...
>>> 
>>> science1.mcmc <- mcmcsamp(science1.lmer , n=1000)
>>> z <- VarCorr(science1.mcmc, type="varcov")
>>> colnames(z) <- c("school:class", "Residual")
>>> 
>>>> ## The following are believable!
>>>> t(apply(z,2, function(x)quantile(x, prob=c(.025, .975))))
>>>            2.5%  97.5%
>>> school:class 0.1442 0.4334
>>> Residual     2.8601 3.3427
>>> 
>>> 
>>> ## EXAMPLE 2:
>>> ant111b.lmer <- lmer(harvwt ~ 1 + (1 | site), data=ant111b)
>>>> ant111b.lmer
>>> ...
>>> Random effects:
>>> Groups   Name        Variance Std.Dev.
>>> site     (Intercept) 2.368    1.54
>>> Residual             0.578    0.76
>>> Number of obs: 32, groups: site, 8
>>>> ...
>>> 
>>> ant111b.mcmc <- mcmcsamp(ant111b.lmer, n=1000)
>>> z <- VarCorr(ant111b.mcmc, type="varcov")
>>> colnames(z) <- c("site", "Residual")
>>>> t(apply(z,2, function(x)quantile(x, prob=c(.025, .975))))
>>>        2.5% 97.5%
>>> site     0.2376 1.878
>>> Residual 0.6370 2.488
>>> 
>>> 
>>> John Maindonald             email: john.maindonald at anu.edu.au
>>> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
>>> Centre for Mathematics & Its Applications, Room 1194,
>>> John Dedman Mathematical Sciences Building (Building 27)
>>> Australian National University, Canberra ACT 0200.
>>> http://www.maths.anu.edu.au/~johnm
>>> 
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> 
>> <john.Rout><Rplots.pdf>
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From r.j.forsyth at newcastle.ac.uk  Thu Dec 10 17:31:21 2009
From: r.j.forsyth at newcastle.ac.uk (Rob Forsyth)
Date: Thu, 10 Dec 2009 16:31:21 +0000
Subject: [R-sig-ME] specifying independence of random effects?
Message-ID: <AA561C0A-6456-403B-93D6-284E50A6AC7D@newcastle.ac.uk>

Hello

I'm trying to specify a mixed-effect model describing "unmet NEED" (of  
families with disabled children) as a function of IMPAIRMENT (i.e.  
intrinsic severity of the child's condition) and AREA of residence  
(factor with ~15 levels). The impairment measure is a unidimensional  
variable but it needs "calibrating" for separate types of disability  
(autism, cerebral palsy etc) represented by another factor, DISCAT

In lmer syntax I have

NEED ~ IMPAIRMENT | DISCAT + 1 | AREA

but I want to specify independence of random effects. I'm aware of the  
pdDiag options in the nlme library but unsure how to specify the model  
in lme syntax?

Thank you

Rob



From Thierry.ONKELINX at inbo.be  Thu Dec 10 17:59:24 2009
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Thu, 10 Dec 2009 17:59:24 +0100
Subject: [R-sig-ME] specifying independence of random effects?
In-Reply-To: <AA561C0A-6456-403B-93D6-284E50A6AC7D@newcastle.ac.uk>
References: <AA561C0A-6456-403B-93D6-284E50A6AC7D@newcastle.ac.uk>
Message-ID: <2E9C414912813E4EB981326983E0A10406DF87A6@inboexch.inbo.be>

Dear Rob,

I suppose that IMPAIRMENT is a continunous variable. In that case you
can use (IMPAIRMENT - 1|DISCAT) + (1 |DISCAT) to indicate that the
random intercept and the random slope are independent. AFAIK you can
only specify a full variance-covariance matrix between random effects or
independent random effects. So structures like pdIdent, pdCompSymm, ...
are not available in lme4.

HTH,

Thierry


------------------------------------------------------------------------
----
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek
team Biometrie & Kwaliteitszorg
Gaverstraat 4
9500 Geraardsbergen
Belgium

Research Institute for Nature and Forest
team Biometrics & Quality Assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium

tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to
say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of
data.
~ John Tukey

-----Oorspronkelijk bericht-----
Van: r-sig-mixed-models-bounces at r-project.org
[mailto:r-sig-mixed-models-bounces at r-project.org] Namens Rob Forsyth
Verzonden: donderdag 10 december 2009 17:31
Aan: r-sig-mixed-models at r-project.org
Onderwerp: [R-sig-ME] specifying independence of random effects?

Hello

I'm trying to specify a mixed-effect model describing "unmet NEED" (of
families with disabled children) as a function of IMPAIRMENT (i.e.  
intrinsic severity of the child's condition) and AREA of residence
(factor with ~15 levels). The impairment measure is a unidimensional
variable but it needs "calibrating" for separate types of disability
(autism, cerebral palsy etc) represented by another factor, DISCAT

In lmer syntax I have

NEED ~ IMPAIRMENT | DISCAT + 1 | AREA

but I want to specify independence of random effects. I'm aware of the
pdDiag options in the nlme library but unsure how to specify the model
in lme syntax?

Thank you

Rob

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

Druk dit bericht a.u.b. niet onnodig af.
Please do not print this message unnecessarily.

Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer 
en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is
door een geldig ondertekend document. The views expressed in  this message 
and any annex are purely those of the writer and may not be regarded as stating 
an official position of INBO, as long as the message is not confirmed by a duly 
signed document.



From M.I.Coco at sms.ed.ac.uk  Thu Dec 10 18:42:46 2009
From: M.I.Coco at sms.ed.ac.uk (Moreno Ignazio Coco)
Date: Thu, 10 Dec 2009 17:42:46 +0000
Subject: [R-sig-ME] [R] updating arguments of formulae
In-Reply-To: <A46302538426124AA1DDBFAFA0896497197E4E@HQVEVE0022.nestle.com>
References: <20091210123524.fvg164bz0g40s4k0@www.sms.ed.ac.uk>
	<A46302538426124AA1DDBFAFA0896497197E4E@HQVEVE0022.nestle.com>
Message-ID: <20091210174246.fj2toziz8cwoco4c@www.sms.ed.ac.uk>

Michael,

Thanks a lot for your reply, I have now understood how to fiddle  
around with the formulae updates...my question (see my previous e-mail  
where I was sketching this problem out) about LME models remains open...
whether:

depM ~ (1 |Sb2) + OS + (1 + OS | Sb2) + VR + (1 + VR | Sb2)

is equivalent to:

depM ~ OS + VR + (1 + OS + VR | Sb2)

and if probably not what is the best approach to it and where I can  
find a kind of guideline/rule of thumb list to build  
"semi-automatically" linear mixed effect models with fixed effects and  
random intercepts/slopes on it.

I am putting in copy the group  you suggested me...

Thanks again,

Moreno

Quoting "Meyners,Michael,LAUSANNE,AppliedMathematics"  
<Michael.Meyners at rdls.nestle.com>:

> Moreno,
>
> I leave the discussion on the mixed models to others (you might consider
> the SIG group on mixed models as well for this), but try a few hints to
> make your code more accessible:
>
> * The "." in updating a formula is substituted with the respective old
> formula (depending on the side), but is not mandatory. You could give
> the new formula explicitly, i.e. consider something like
> model1 = update(model, . ~ (1 |Sb2) + OS)
> if you loose control about your models. See ?update.formula
>
> * I don't see the need for using your construct with
> as.formula(paste()), this makes things unnecessarily complicated. See my
> above example, which should work as well on your data (and see ?update)
>
> * There is also the "-" operator available in update.formula to remove
> terms (because it uses formula, see ?formula). As to your question on
> how to move from
>> depM ~ OS + (1 + OS | Sb2)
>> to
>> depM ~ OS + VR + (1 + OS + VR | Sb2)
> try something like
> update(model1, .~. - (1 + OS|Sb2) + VR + (1 + OS + VR | Sb2))
> while it goes without saying that in this case, it would be easier to
> drop the "." and use something like
> update(model1, .~ OS + VR + (1 + OS + VR | Sb2))
> directly.
>
> * paste accepts more than just two arguments to be pasted: Try somthing
> like
> model2 = update(model1, as.formula(paste(". ~ . + (1 + ", "OS", "|" ,
> "Sb2", ")"))
> instead of your construct with several nested calls to paste, and see
> ?paste. (Note that I added quotes to "OS" and "Sb2", it didn't work for
> me otherwise as I have no object OS, not sure what happens if you have
> such an object on our search path, but I would suspect you encounter
> problems as well.)
>
> If you work yourself through these and thereby simplify your code, you
> are more likely to get responses to your questions on which model to use
> (which is actually independent from the use of update). As far as I see
> it, it doesn't make sense to use a formula like in your model4, but the
> mixed model experts might tell me wrong (and I got a bit lost in your
> code as well). Please also try to provide commented, minimal,
> self-contained, reproducible code for further enquiries (use e.g. one of
> the examples on ?lmer to create appropriate examples for your
> questions).
>
> HTH, Michael
>
>
>> -----Original Message-----
>> From: r-help-bounces at r-project.org
>> [mailto:r-help-bounces at r-project.org] On Behalf Of Moreno Ignazio Coco
>> Sent: Donnerstag, 10. Dezember 2009 13:35
>> To: R-help at r-project.org
>> Subject: [R] updating arguments of formulae
>>
>> Dear R-Community,
>>
>> I am relatively new with R, so sorry for things which for you
>> might be obvious...
>> I am trying to automatically update lmer formulae.
>>
>> the variables of the model are:
>>
>> depM= my dependent measure
>> Sb2= a random factor
>> OS = a predictor
>> VR= another predictor
>>
>> So, I am building the first model with random intercept only:
>>
>> model = lmer(depM ~ (1 |Sb2))
>>
>> then I update the formula adding the first predictor
>>
>> model1 = update(model, as.formula(paste(". ~ . + ", OS)))
>>
>> the resulting formula will be:
>>
>> depM ~ (1 |Sb2) + OS
>>
>> let suppose now I want to update the model to have OS both as
>> a fixed effect and in the random term, something like:
>>
>> depM ~ (1 + OS |Sb2) + OS
>>
>> I can do something very ugly (please tell me if there is a
>> more elegant way to do it) that looks like:
>>
>> model2 = update(model1, as.formula(paste(paste(paste(paste(".
>> ~ . + (1
>> + ", OS), "|" ), Sb2), ")")))
>>
>> the resulting model2 formula will be:
>>
>> depM ~ (1 |Sb2) + OS + (1 + OS | Sb2)
>>
>> one first thing I am wondering at this point is whether having
>> (1 |Sb2) and (1 + OS | Sb2) in the same expression is redundant.
>> in the output it will obviously tell me that group Sb2 is
>> considered twice:
>>
>> number of obs: 6514, groups:  Sb2, 23; Sb2, 23
>>
>> and i am not sure if am doing it correctly...any advice?
>>
>> So let suppose now I want to add the new predictor VR again
>> both in the fixed and in the random part of the formula.
>> If i just repeat the two steps above:
>>
>> model3 = update(model2, as.formula(paste(". ~ . + ", VR)))
>>
>> and then:
>>
>> model4 = update(model3, as.formula(paste(paste(paste(paste(".
>> ~ . + (1
>> + ", VR), "|" ), Sb2), ")")))
>>
>> the formula I get is:
>>
>> depM ~ (1 |Sb2) + OS + (1 + OS | Sb2) + VR + (1 + VR | Sb2)
>>
>> so, basically I am adding new stuff on the right side of the
>> formula...
>>
>> My first question at this point is whether the above formula
>> is equivalent to:
>>
>> depM ~ OS + VR + (1 + OS + VR | Sb2)
>>
>> if is not equivalent, which one of the two is correct?
>>
>> obviously in the second case, group Sb2, is considered only once.
>>
>> If the second version of the formula is the correct one, I
>> don't understand how I can update arguments inside the
>> formula rather than adding things on his right side...
>>
>> thus, in the ideal case,  how do I go from something like this:
>>
>> depM ~ OS + (1 + OS | Sb2)
>>
>> to something like this:
>>
>> depM ~ OS + VR + (1 + OS + VR | Sb2)
>>
>> Thanks a lot for your help,
>> Best,
>>
>> Moreno
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>> --
>> The University of Edinburgh is a charitable body, registered
>> in Scotland, with registration number SC005336.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From Michael.Meyners at rdls.nestle.com  Fri Dec 11 09:27:29 2009
From: Michael.Meyners at rdls.nestle.com (Meyners, Michael, LAUSANNE,
	AppliedMathematics)
Date: Fri, 11 Dec 2009 09:27:29 +0100
Subject: [R-sig-ME] [R] updating arguments of formulae
In-Reply-To: <20091210174246.fj2toziz8cwoco4c@www.sms.ed.ac.uk>
References: <20091210123524.fvg164bz0g40s4k0@www.sms.ed.ac.uk><A46302538426124AA1DDBFAFA0896497197E4E@HQVEVE0022.nestle.com>
	<20091210174246.fj2toziz8cwoco4c@www.sms.ed.ac.uk>
Message-ID: <A46302538426124AA1DDBFAFA0896497197E9F@HQVEVE0022.nestle.com>

Moreno,

to my understanding, 

(1) depM ~ OS + VR + (1 + OS + VR | Sb2)
(2) depM ~ OS + VR + (1 |Sb2) + (1 + OS | Sb2) + (1 + VR | Sb2)

will not yield the same results. In (1), you model a random intercept
and slopes for OS and VR once for each group of Sb2. In (2), you model
an intercept, then again an intercept together with a slope for OS, and
then the same once more for VR. If anything, you might want to model the
three random effects as independent, then you should use something like 

(3) depM ~ OS + VR + (1 |Sb2) + (0 + OS | Sb2) + (0 + VR | Sb2)

hence not estimating three random intercepts for each group of Sb2 (as
is done by (2)). I would not know how to build the models
semi-automatically, for me, there are a lot of assumptions in it that I
may or may not justify conceptually or based on the data. There are a
lot of choices, and different people might make different ones at times,
so I doubt that this could be automatized. 

Try to look at 

require(lme4)
vignette("Implementation")

In Section 3 and in particular pages 15-16, you find a similar model to
(3), and there is some motivation why this model was chosen.

I hope that I have not completely misinterpreted lme4 now and hope that
some of the experts in the area will correct me in case.

HTH, Michael


> -----Original Message-----
> From: Moreno Ignazio Coco [mailto:M.I.Coco at sms.ed.ac.uk] 
> Sent: Donnerstag, 10. Dezember 2009 18:43
> To: Meyners,Michael,LAUSANNE,AppliedMathematics
> Cc: R-help at r-project.org; r-sig-mixed-models at r-project.org
> Subject: RE: [R] updating arguments of formulae
> 
> Michael,
> 
> Thanks a lot for your reply, I have now understood how to 
> fiddle around with the formulae updates...my question (see my 
> previous e-mail where I was sketching this problem out) about 
> LME models remains open...
> whether:
> 
> depM ~ (1 |Sb2) + OS + (1 + OS | Sb2) + VR + (1 + VR | Sb2)
> 
> is equivalent to:
> 
> depM ~ OS + VR + (1 + OS + VR | Sb2)
> 
> and if probably not what is the best approach to it and where 
> I can find a kind of guideline/rule of thumb list to build 
> "semi-automatically" linear mixed effect models with fixed 
> effects and random intercepts/slopes on it.
> 
> I am putting in copy the group  you suggested me...
> 
> Thanks again,
> 
> Moreno
> 
> Quoting "Meyners,Michael,LAUSANNE,AppliedMathematics"  
> <Michael.Meyners at rdls.nestle.com>:
> 
> > Moreno,
> >
> > I leave the discussion on the mixed models to others (you might 
> > consider the SIG group on mixed models as well for this), but try a 
> > few hints to make your code more accessible:
> >
> > * The "." in updating a formula is substituted with the 
> respective old 
> > formula (depending on the side), but is not mandatory. You 
> could give 
> > the new formula explicitly, i.e. consider something like
> > model1 = update(model, . ~ (1 |Sb2) + OS) if you loose 
> control about 
> > your models. See ?update.formula
> >
> > * I don't see the need for using your construct with 
> > as.formula(paste()), this makes things unnecessarily 
> complicated. See 
> > my above example, which should work as well on your data (and see 
> > ?update)
> >
> > * There is also the "-" operator available in 
> update.formula to remove 
> > terms (because it uses formula, see ?formula). As to your 
> question on 
> > how to move from
> >> depM ~ OS + (1 + OS | Sb2)
> >> to
> >> depM ~ OS + VR + (1 + OS + VR | Sb2)
> > try something like
> > update(model1, .~. - (1 + OS|Sb2) + VR + (1 + OS + VR | 
> Sb2)) while it 
> > goes without saying that in this case, it would be easier 
> to drop the 
> > "." and use something like update(model1, .~ OS + VR + (1 + 
> OS + VR | 
> > Sb2)) directly.
> >
> > * paste accepts more than just two arguments to be pasted: Try 
> > somthing like
> > model2 = update(model1, as.formula(paste(". ~ . + (1 + ", 
> "OS", "|" , 
> > "Sb2", ")")) instead of your construct with several nested calls to 
> > paste, and see ?paste. (Note that I added quotes to "OS" 
> and "Sb2", it 
> > didn't work for me otherwise as I have no object OS, not sure what 
> > happens if you have such an object on our search path, but I would 
> > suspect you encounter problems as well.)
> >
> > If you work yourself through these and thereby simplify 
> your code, you 
> > are more likely to get responses to your questions on which 
> model to 
> > use (which is actually independent from the use of update). 
> As far as 
> > I see it, it doesn't make sense to use a formula like in 
> your model4, 
> > but the mixed model experts might tell me wrong (and I got 
> a bit lost 
> > in your code as well). Please also try to provide 
> commented, minimal, 
> > self-contained, reproducible code for further enquiries 
> (use e.g. one 
> > of the examples on ?lmer to create appropriate examples for your 
> > questions).
> >
> > HTH, Michael
> >
> >
> >> -----Original Message-----
> >> From: r-help-bounces at r-project.org
> >> [mailto:r-help-bounces at r-project.org] On Behalf Of Moreno Ignazio 
> >> Coco
> >> Sent: Donnerstag, 10. Dezember 2009 13:35
> >> To: R-help at r-project.org
> >> Subject: [R] updating arguments of formulae
> >>
> >> Dear R-Community,
> >>
> >> I am relatively new with R, so sorry for things which for 
> you might 
> >> be obvious...
> >> I am trying to automatically update lmer formulae.
> >>
> >> the variables of the model are:
> >>
> >> depM= my dependent measure
> >> Sb2= a random factor
> >> OS = a predictor
> >> VR= another predictor
> >>
> >> So, I am building the first model with random intercept only:
> >>
> >> model = lmer(depM ~ (1 |Sb2))
> >>
> >> then I update the formula adding the first predictor
> >>
> >> model1 = update(model, as.formula(paste(". ~ . + ", OS)))
> >>
> >> the resulting formula will be:
> >>
> >> depM ~ (1 |Sb2) + OS
> >>
> >> let suppose now I want to update the model to have OS both 
> as a fixed 
> >> effect and in the random term, something like:
> >>
> >> depM ~ (1 + OS |Sb2) + OS
> >>
> >> I can do something very ugly (please tell me if there is a more 
> >> elegant way to do it) that looks like:
> >>
> >> model2 = update(model1, as.formula(paste(paste(paste(paste(".
> >> ~ . + (1
> >> + ", OS), "|" ), Sb2), ")")))
> >>
> >> the resulting model2 formula will be:
> >>
> >> depM ~ (1 |Sb2) + OS + (1 + OS | Sb2)
> >>
> >> one first thing I am wondering at this point is whether having
> >> (1 |Sb2) and (1 + OS | Sb2) in the same expression is redundant.
> >> in the output it will obviously tell me that group Sb2 is 
> considered 
> >> twice:
> >>
> >> number of obs: 6514, groups:  Sb2, 23; Sb2, 23
> >>
> >> and i am not sure if am doing it correctly...any advice?
> >>
> >> So let suppose now I want to add the new predictor VR 
> again both in 
> >> the fixed and in the random part of the formula.
> >> If i just repeat the two steps above:
> >>
> >> model3 = update(model2, as.formula(paste(". ~ . + ", VR)))
> >>
> >> and then:
> >>
> >> model4 = update(model3, as.formula(paste(paste(paste(paste(".
> >> ~ . + (1
> >> + ", VR), "|" ), Sb2), ")")))
> >>
> >> the formula I get is:
> >>
> >> depM ~ (1 |Sb2) + OS + (1 + OS | Sb2) + VR + (1 + VR | Sb2)
> >>
> >> so, basically I am adding new stuff on the right side of the 
> >> formula...
> >>
> >> My first question at this point is whether the above formula is 
> >> equivalent to:
> >>
> >> depM ~ OS + VR + (1 + OS + VR | Sb2)
> >>
> >> if is not equivalent, which one of the two is correct?
> >>
> >> obviously in the second case, group Sb2, is considered only once.
> >>
> >> If the second version of the formula is the correct one, I don't 
> >> understand how I can update arguments inside the formula 
> rather than 
> >> adding things on his right side...
> >>
> >> thus, in the ideal case,  how do I go from something like this:
> >>
> >> depM ~ OS + (1 + OS | Sb2)
> >>
> >> to something like this:
> >>
> >> depM ~ OS + VR + (1 + OS + VR | Sb2)
> >>
> >> Thanks a lot for your help,
> >> Best,
> >>
> >> Moreno
> >> --
> >> The University of Edinburgh is a charitable body, registered in 
> >> Scotland, with registration number SC005336.
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.



From teplitsky at mnhn.fr  Fri Dec 11 14:32:40 2009
From: teplitsky at mnhn.fr (Celine Teplitsky)
Date: Fri, 11 Dec 2009 14:32:40 +0100
Subject: [R-sig-ME] zipoisson in MCMCglmm
Message-ID: <4B2249F8.1060501@mnhn.fr>

Dear all,

I am trying to run a zero inflated model with MCMCglmm as the number of 
days of parades in the birds is overdispersed.

I used this code:

priorA <- list(R=list(V=diag(2),n=2,fix=2), 
G=list(G1=list(V=diag(2),n=2),G2=list(V=diag(2),n=2)))


NBJ_ZIP<- MCMCglmm(NBJ~trait, random=~idh(trait):animal+idh(trait):IDb, 
rcov=~idh(trait):units,data=Data , 
family="zipoisson",pedigree=PedR,prior=priorA)


I got this error message:

Error in if (max(data_tmp$MCMC_y) == 1) { :
   missing value where TRUE/FALSE needed

and I don't manage to understand what I should change. I'm sorry if this 
was already answered but I could not find it.

Many thanks in advance

All the best

Celine



From R.COE at CGIAR.ORG  Tue Dec 15 07:55:47 2009
From: R.COE at CGIAR.ORG (Coe, Richard (ICRAF-ILRI))
Date: Tue, 15 Dec 2009 09:55:47 +0300
Subject: [R-sig-ME] nlmer model syntax
Message-ID: <4658B112D15C194CAC8A76DCFE75E22B06327289@icrafmx.ICRAF.CGIARAD.ORG>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20091215/26786fc9/attachment.pl>

From h.lingsma at erasmusmc.nl  Tue Dec 15 09:16:29 2009
From: h.lingsma at erasmusmc.nl (Hester Lingsma)
Date: Tue, 15 Dec 2009 09:16:29 +0100
Subject: [R-sig-ME] random effects estimation in Lmer
Message-ID: <4B2745DD.5020308@erasmusmc.nl>

Dear R-users,
I have a question on how the random effects are estimated in Lmer

I have a dataset with families with women who have breastcancer. The age
of cancer diagnosis is highly variable between the families. We want to
predict the age of cancer diagnosis (for screening purposes) for 'new'
family members. I have fitted a linear random effects model with lmer 
(model
1)  with age at diagnosis as outcome, a random intercept for family, and
cancer type (three subtypes, on family level) in the fixed part.
I now want to make a regression formula (for a predction rule) which is of
course easy for the fixed part of the model (intercept + coefs for type) 
but
more difficult for the random effect part.
My practical solution was the following: I fitted a new model (model 2) on
the familiy level aggregated dataset with the estimated random effect as an
outcome, and number of fam members and the distance between the expected 
age
for the family based on type (the fixed part of model) and the observed 
mean
age, as predictors.
Model 2 has an R2 of 0.85 and the predicted ages (fixed part + the random
part as 'estimated' in model 2) for some families are 4 years away from the
posterior estimate (from model 1). So we want to do better. I tried some
polynomials in model 2, since we do not expect the effect of the parameters
to be linear, but it did not help a lot. I also included the within family
variance (the sd) in model 2 since I noticed that the predicted ages got
worse in families with high within family variance, also without much
succes.
So basically my question is: is there a (better) way to approximate the
random effects estimated in model 1, to formulate a 'random' part of the
regression formula/a predction rule?

Thank you very much in advance.

Hester Lingsma



From David.Duffy at qimr.edu.au  Tue Dec 15 09:23:55 2009
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Tue, 15 Dec 2009 18:23:55 +1000 (EST)
Subject: [R-sig-ME] random effects estimation in Lmer
In-Reply-To: <4B2745DD.5020308@erasmusmc.nl>
References: <4B2745DD.5020308@erasmusmc.nl>
Message-ID: <Pine.LNX.4.64.0912151821280.15161@orpheus.qimr.edu.au>

On Tue, 15 Dec 2009, Hester Lingsma wrote:

> Dear R-users,
> I have a question on how the random effects are estimated in Lmer
>
> I have a dataset with families with women who have breastcancer. The age
> of cancer diagnosis is highly variable between the families. We want to
> predict the age of cancer diagnosis (for screening purposes) for 'new'
> family members. I have fitted a linear random effects model with lmer (model
> 1)  with age at diagnosis as outcome, a random intercept for family, and
> cancer type (three subtypes, on family level) in the fixed part.
>

Have you looked at the kinship package at all?  It uses lme, but analyses 
age at onset data from families more nicely than lmer can (see the coxme()
function and the vignette/documentation).

David Duffy.

-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From nilsson.henric at gmail.com  Tue Dec 15 12:03:47 2009
From: nilsson.henric at gmail.com (Henric (Nilsson) Winell)
Date: Tue, 15 Dec 2009 12:03:47 +0100
Subject: [R-sig-ME] random effects estimation in Lmer
In-Reply-To: <Pine.LNX.4.64.0912151821280.15161@orpheus.qimr.edu.au>
References: <4B2745DD.5020308@erasmusmc.nl>
	<Pine.LNX.4.64.0912151821280.15161@orpheus.qimr.edu.au>
Message-ID: <4B276D13.7080901@gmail.com>

On 2009-12-15 09:23, David Duffy wrote:

> On Tue, 15 Dec 2009, Hester Lingsma wrote:
> 
>> Dear R-users,
>> I have a question on how the random effects are estimated in Lmer
>>
>> I have a dataset with families with women who have breastcancer. The age
>> of cancer diagnosis is highly variable between the families. We want to
>> predict the age of cancer diagnosis (for screening purposes) for 'new'
>> family members. I have fitted a linear random effects model with lmer 
>> (model
>> 1)  with age at diagnosis as outcome, a random intercept for family, and
>> cancer type (three subtypes, on family level) in the fixed part.
>>
> 
> Have you looked at the kinship package at all?  It uses lme, but 
> analyses age at onset data from families more nicely than lmer can (see 
> the coxme() function and the vignette/documentation).

Actually, the latest version of the coxme() function now lives in Terry 
Therneau's new 'coxme' package.

It no longer depends on 'nlme', but uses its own fitting routines and 
sparse matrix representation, and has a lme4-like syntax for the 
specification of random effects.


Henric



> 
> David Duffy.
>



From h.lingsma at erasmusmc.nl  Tue Dec 15 09:09:20 2009
From: h.lingsma at erasmusmc.nl (Hester Lingsma)
Date: Tue, 15 Dec 2009 09:09:20 +0100
Subject: [R-sig-ME] Random effects estimation in Lmer
Message-ID: <4B274430.9030301@erasmusmc.nl>

Dear R-users,
>>
>> I have a question on how the random effects are estimated in Lmer

>> I have a dataset with families with women who have breastcancer. The age
>> of cancer diagnosis is highly variable between the families. We want to
>> predict the age of cancer diagnosis (for screening purposes) for 'new'
>> family members. I have fitted a linear random effects model with lmer (model
>> 1)  with age at diagnosis as outcome, a random intercept for family, and
>> cancer type (three subtypes, on family level) in the fixed part.
>> I now want to make a regression formula (for a predction rule) which is of
>> course easy for the fixed part of the model (intercept + coefs for type) but
>> more difficult for the random effect part.
>> My practical solution was the following: I fitted a new model (model 2) on
>> the familiy level aggregated dataset with the estimated random effect as an
>> outcome, and number of fam members and the distance between the expected age
>> for the family based on type (the fixed part of model) and the observed mean
>> age, as predictors.
>> Model 2 has an R2 of 0.85 and the predicted ages (fixed part + the random
>> part as 'estimated' in model 2) for some families are 4 years away from the
>> posterior estimate (from model 1). So we want to do better. I tried some
>> polynomials in model 2, since we do not expect the effect of the parameters
>> to be linear, but it did not help a lot. I also included the within family
>> variance (the sd) in model 2 since I noticed that the predicted ages got
>> worse in families with high within family variance, also without much
>> succes.
>> So basically my question is: is there a (better) way to approximate the
>> random effects estimated in model 1, to formulate a 'random' part of the
>> regression formula/a predction rule?
>>
>> Thank you very much in advance.
>>
>> Hester Lingsma
>>

-- 
_________________________________________________
Hester F. Lingsma, MSc
Dept of Public Health
Room AE-141
Erasmus MC
P.O. Box 2040
3000 CA Rotterdam
The Netherlands
Phone: (+31) (0)10 7038458/7038460
Mobile: (+31) (0)6 26467338



From njbisaac at googlemail.com  Tue Dec 15 19:00:14 2009
From: njbisaac at googlemail.com (Nick Isaac)
Date: Tue, 15 Dec 2009 18:00:14 +0000
Subject: [R-sig-ME] Estimating the correlation between random slopes and
	intercepts
Message-ID: <a072ed700912151000w1578006ah966d5edec2b8ceb8@mail.gmail.com>

Dear all,

I wonder if anyone can help me estimate the correlation between random
slopes and intercepts without autocorrelation problems?

I've followed the advice in Reinhold Kliegl's recent paper (in Visual
Cognition) and performed simple model comparison between with a model
lacking the correlation. Both fixed effects in Kliegl et al's study
were categorical, so the autocorrelation issue doesn't arise. I've
also followed standard procedure in centering my fixed effect on zero.
My data are on species body mass, M, and metabolic rate, Q. The
grouping factor is taxonomic identity:

mlm <- mean(log(M))
x <- log(M) - mlm
m1<- lmer( log(Q) ~ x + (x | Taxon) )
m0<- lmer( log(Q) ~ x + (x+0 | Taxon) + (1 | Taxon))

My problem is that the total range of the log(M) is much larger than
in any one of the Taxa. This means that the intercept random effect is
estimated at a value of log(M) well outside range for most groups
(i.e. it's a fitted value of log(Q) extrapolated to the point where
x=0). I thought that centering the data on zero would mean that the
number of taxa extrapolated up would balance the number extrapolated
down. Unfortunately, the data are so unbalanced that the overall mean
log(M) is much less than the mean of the group-level means. This means
that centering the species data on zero (as above) means that many
more groups are extrapolated down than up, which might cause my
correlation to be more negative than it truly is. I've tried different
values of log(M) around which to centre the data (see example below):
my estimate of the correlation and strength of inference depends on
the value of log(M) at which I centre the data.

The bottom line is that I have a manuscript in which this correlation
is quite important. A reviewer has raised the autocorrelation problem
and made suggestions that have none of the strengths of mixed models
(including extracting the taxon random effects and doing regressions
on residuals from a regression of these). I can bang the drum for
mixed models and explain Reinhold Kliegl's simulations, but this won't
overcome the autocorrelation problem.

I've included a simple example to show how I've explored the problem:

s<-summary(sleepstudy$Days)
sm1<-lapply(s, function(x) lmer(Reaction~ I(Days-x) + (I(Days-x) |
Subject), sleepstudy)) #correlated random effects
sm0<-lapply(s, function(x) lmer(Reaction~ I(Days-x) + (I(Days-x)+0 |
Subject)+(1|Subject), sleepstudy)) #uncorrelated
correl <- sapply(sm1, function(x)
attr(VarCorr(x)$Subject,"correlation")[1,2]) #extract the correlation
a.var <- sapply(sm1, function(x) VarCorr(x)$Subject[1,1]) #extract the
variance in the intercept
delta <- sapply(1:length(s), function(i) AIC(logLik(sm0[[i]])) -
AIC(logLik(sm1[[i]]))) #compare the model AIC
cbind(s, correl, a.var, delta)

Any suggestions would be gratefully received.

Best wishes, Nick



Nick Isaac
Macroecologist
Centre for Ecology & Hydrology
Wallingford
Oxon, UK

http://www.ceh.ac.uk/StaffWebPages/DrNickIsaac.html



From ltiana_m at yahoo.com  Wed Dec 16 00:24:02 2009
From: ltiana_m at yahoo.com (Liliana Martinez)
Date: Tue, 15 Dec 2009 15:24:02 -0800 (PST)
Subject: [R-sig-ME] what kind of analysis should be used when there are
	several correlated dependent variables?
Message-ID: <549650.80238.qm@web53002.mail.re2.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20091215/920fc461/attachment.pl>

From David.Duffy at qimr.edu.au  Wed Dec 16 08:01:01 2009
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Wed, 16 Dec 2009 17:01:01 +1000 (EST)
Subject: [R-sig-ME] random effects estimation in Lmer
In-Reply-To: <4B276D13.7080901@gmail.com>
References: <4B2745DD.5020308@erasmusmc.nl>
	<Pine.LNX.4.64.0912151821280.15161@orpheus.qimr.edu.au>
	<4B276D13.7080901@gmail.com>
Message-ID: <Pine.LNX.4.64.0912161649350.27583@orpheus.qimr.edu.au>

On Tue, 15 Dec 2009, Henric (Nilsson) Winell wrote:

> On 2009-12-15 09:23, David Duffy wrote:
>> 
>> Have you looked at the kinship package at all?  It uses lme, but analyses 
>> age at onset data from families more nicely than lmer can (see the coxme() 
>> function and the vignette/documentation).
>
> Actually, the latest version of the coxme() function now lives in Terry 
> Therneau's new 'coxme' package.
>
> It no longer depends on 'nlme', but uses its own fitting routines and sparse 
> matrix representation, and has a lme4-like syntax for the specification of 
> random effects.

Good to know!

The OP may want to use the kinship package to generate kinship matrices, 
and to look at the breast cancer example therein.

Cheers, David Duffy.

-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From h.lingsma at erasmusmc.nl  Wed Dec 16 08:51:40 2009
From: h.lingsma at erasmusmc.nl (Hester Lingsma)
Date: Wed, 16 Dec 2009 08:51:40 +0100
Subject: [R-sig-ME] random effects estimation in Lmer
In-Reply-To: <Pine.LNX.4.64.0912161649350.27583@orpheus.qimr.edu.au>
References: <4B2745DD.5020308@erasmusmc.nl>
	<Pine.LNX.4.64.0912151821280.15161@orpheus.qimr.edu.au>
	<4B276D13.7080901@gmail.com>
	<Pine.LNX.4.64.0912161649350.27583@orpheus.qimr.edu.au>
Message-ID: <4B28918C.3010200@erasmusmc.nl>

Dear all,
Thanks for the suggestions. I will take a look at the coxme package.
Regards,
Hester Lingsma

on 16-12-2009 08:01 David Duffy said the following:
> On Tue, 15 Dec 2009, Henric (Nilsson) Winell wrote:
>
>> On 2009-12-15 09:23, David Duffy wrote:
>>>
>>> Have you looked at the kinship package at all?  It uses lme, but 
>>> analyses age at onset data from families more nicely than lmer can 
>>> (see the coxme() function and the vignette/documentation).
>>
>> Actually, the latest version of the coxme() function now lives in 
>> Terry Therneau's new 'coxme' package.
>>
>> It no longer depends on 'nlme', but uses its own fitting routines and 
>> sparse matrix representation, and has a lme4-like syntax for the 
>> specification of random effects.
>
> Good to know!
>
> The OP may want to use the kinship package to generate kinship 
> matrices, and to look at the breast cancer example therein.
>
> Cheers, David Duffy.
>

-- 
_________________________________________________
Hester F. Lingsma, MSc
Dept of Public Health
Room AE-141
Erasmus MC
P.O. Box 2040
3000 CA Rotterdam
The Netherlands
Phone: (+31) (0)10 7038458/7038460
Mobile: (+31) (0)6 26467338



From backstage7 at naver.com  Thu Dec 17 18:03:23 2009
From: backstage7 at naver.com (=?EUC-KR?B?sejH/bz3?=)
Date: Fri, 18 Dec 2009 02:03:23 +0900
Subject: [R-sig-ME] =?euc-kr?q?Inquiry_regarding_=27lme4=27_package_in_R?=
Message-ID: <9308d4419dbf8383139e9cbd2186599b@a51104>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20091218/13df53e1/attachment.pl>

From backstage7 at naver.com  Fri Dec 18 10:08:12 2009
From: backstage7 at naver.com (=?EUC-KR?B?sejH/bz3?=)
Date: Fri, 18 Dec 2009 18:08:12 +0900
Subject: [R-sig-ME] =?euc-kr?q?Inquiry_regarding_=27lme4=27_package_in_R?=
Message-ID: <0326ad97e8fadb4060d5a77cc0fa8ae9@i61791>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20091218/3937101c/attachment.pl>

From ltiana_m at yahoo.com  Fri Dec 18 11:08:25 2009
From: ltiana_m at yahoo.com (Liliana Martinez)
Date: Fri, 18 Dec 2009 02:08:25 -0800 (PST)
Subject: [R-sig-ME] what kind of analysis should be used when there are
	several correlated dependent variables?
Message-ID: <181434.72347.qm@web53002.mail.re2.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20091218/96435e24/attachment.pl>

From R.COE at CGIAR.ORG  Fri Dec 18 15:16:12 2009
From: R.COE at CGIAR.ORG (Coe, Richard (ICRAF-ILRI))
Date: Fri, 18 Dec 2009 17:16:12 +0300
Subject: [R-sig-ME] nlmer model syntax
Message-ID: <4658B112D15C194CAC8A76DCFE75E22B0640291C@icrafmx.ICRAF.CGIARAD.ORG>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20091218/bc62bba5/attachment.pl>

From gomez3 at wisc.edu  Fri Dec 18 18:26:18 2009
From: gomez3 at wisc.edu (Arturo Gomez)
Date: Fri, 18 Dec 2009 11:26:18 -0600
Subject: [R-sig-ME] lmer binomial CI
Message-ID: <6e00fb2d70882.4b2b66da@wiscmail.wisc.edu>

Hello,

I first apologize for my knowledge in R. I hope that the question will not be too basic.

I would like to obtain the OR and the CI for the OR from a lmer and/or a glmer model. Is there some way to do it?

Thanks

Arturo Gomez Rivas, LV
Resident in Food Animal Production Medicine
University of Wisconsin-Madison
School of Veterinary Medicine
2015 Linden Drive
Madison, WI 53706
Phone (608)263-5089 
Web Site: http://www.vetmed.wisc.edu/dms/fapm/index.html



From datkins at u.washington.edu  Fri Dec 18 19:51:30 2009
From: datkins at u.washington.edu (David Atkins)
Date: Fri, 18 Dec 2009 10:51:30 -0800
Subject: [R-sig-ME] what kind of analysis should be used when there are
 several correlated dependent variables?
In-Reply-To: <181434.72347.qm@web53002.mail.re2.yahoo.com>
References: <181434.72347.qm@web53002.mail.re2.yahoo.com>
Message-ID: <4B2BCF32.2000302@u.washington.edu>


Liliana--

One route would be to fit a multivariate mixed-effects model, in which 
the multiple outcomes are jointly treated as a DV.  Neither lme() nor 
lmer() have a way of explicitly specifying a multivariate model (ie, 
MCMCglmm can "cbind" multiple outcomes together), but it is possible to 
fit at least some basic multivariate models with some data manipulation.

The main "trick" here is to reshape your data by stacking all DVs into a 
single DV column and creating a factor that identifies which values in 
the DV correspond to your 4 separate DVs.

I recently used lme() to do this with a study of daily positive mood, 
negative mood, and fatigue in women with breast cancer (each woman had 
30 days of data).

Here was the code to reshape the data (where "id" identifies the 
individual, and "day" identifies -- shockingly -- day):

tmp.long.df <- reshape(my.df,
                       idvar=c("id","day"),
                       varying = c("posemo","negemo","fatigue"),
                       v.names = "dv",
                       times = 1:3,
                       direction="long")
names(tmp.long.df)[8] <- "dv.f" # rename times
tmp.long.df$dv.f <- factor(tmp.long.df$dv.f, 1:3, 
c("posemo","negemo","fatigue"))

So, your separate columns of DVs are specified on "varying", and the new 
data.frame has a column called "times" that identifies which DV is which 
in your new "dv" column.  I change times (which just happened to be the 
8th column in my data, you'll likely need to change that) to "dv.f" and 
then change that to factor with levels identifying separate DVs.

Then, here is an example of a call to lme() that I used:

mult.lme3.2 <- lme(dv ~ -1 + dv.f/(supp.sat.c*(emot.iss.c + phys.iss.c + 
comm.iss.c)),
				 data = mult.df, na.action = na.omit, control = list(msVerbose = TRUE),
				 random = list(id = ~ -1 + dv.f),
				 weights = varIdent(form = ~ 1 | dv.f),
				 correlation = corAR1(form = ~ 1 | id/dv.f))

So, a couple comments:

-- With this set-up, getting rid of the intercept makes the models a bit 
easier to interpret (for me) as you get separate intercepts for each DV.

-- Similarly, the "dv.f/..." fits the covariates nested within each DV, 
which again makes things a bit easier to interpret.

-- The random statement fits separate random-intercepts by DV that are 
correlated.

-- The weights statement allows different residual error terms by DV.

-- For our data, we fit an AR1 correlation model because of 30 days of data.

Hope that helps; I think David Afshartous has some postings about 
multivariate models in lme which you can probably find in the archive 
(if memory serves).

[And, I am again impressed at how flexible the mixed-effects tools are 
in R -- kudos to Jose and Doug for the great software.]

cheers, Dave

-- 
Dave Atkins, PhD
Research Associate Professor
Center for the Study of Health and Risk Behaviors
Department of  Psychiatry and Behavioral Science
University of Washington
1100 NE 45th Street, Suite 300
Seattle, WA  98105
206-616-3879
datkins at u.washington.edu



From ltiana_m at yahoo.com  Sat Dec 19 14:19:18 2009
From: ltiana_m at yahoo.com (Liliana Martinez)
Date: Sat, 19 Dec 2009 05:19:18 -0800 (PST)
Subject: [R-sig-ME] Vedr. what kind of analysis should be used when there
	are several correlated dependent variables?
In-Reply-To: <4B2BCF32.2000302@u.washington.edu>
References: <181434.72347.qm@web53002.mail.re2.yahoo.com>
	<4B2BCF32.2000302@u.washington.edu>
Message-ID: <322286.3974.qm@web53003.mail.re2.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20091219/463e4fc7/attachment.pl>

From datkins at u.washington.edu  Sat Dec 19 16:05:35 2009
From: datkins at u.washington.edu (David Atkins)
Date: Sat, 19 Dec 2009 07:05:35 -0800
Subject: [R-sig-ME] Vedr. what kind of analysis should be used when
 there are several correlated dependent variables?
In-Reply-To: <322286.3974.qm@web53003.mail.re2.yahoo.com>
References: <181434.72347.qm@web53002.mail.re2.yahoo.com>
	<4B2BCF32.2000302@u.washington.edu>
	<322286.3974.qm@web53003.mail.re2.yahoo.com>
Message-ID: <4B2CEBBF.8080506@u.washington.edu>


Liliana Martinez wrote:
> 
> Dear David,
> Thank you very much for the help! I managed to reshape my data and fit a 
> multi-variate mixed effects model the way you advised me to do (at least 
> I hope this is what I've done).
>  
> risuvane2 = reshape (risuvane, idvar = c("subj", "stim"), varying = 
> c("cext_linear", "dir0_dist1", "prec01", "fol01"), v.names = "dv4", 
> times = 1:4, direction = "long")
> risuvane2$time = factor(risuvane2$time, 1:4, c("cext_linear", 
> "dir0_dist1", "prec01", "fol01"))
> 
> I used your lme-call and replaced your variable names with mine. 
> Unfortunately, my understanding of statistics and mathematics is not so 

Honestly, I would recommend trying to do some background reading and 
seek consultation from someone local.  The model that I suggested (and 
you fit) is quite complex.

The Pinheiro and Bates book is the "bible" for lme and will discuss 
model syntax, including weights and correlation.

The following article discusses multivariate models, and I am sure there 
are others:

MacCallum, R. C., Kim, C., Malarkey, W. B., & Kiecolt-Glaser, J. K. 
(1997). Studying multivariate change using
multilevel models and latent curve models. Multivariate Behavioral 
Research, 32, 215-253.

[Also, assuming that the data reshaping and model were specified 
correctly, there appears to be *no* correlation between DVs.  Though, 
there are huge differences across variances; I do not know your data, 
but this strikes me as odd]

All the best, Dave


> good as I'd want it to be, so the part about weights and correlations is 
> still a mystery to me. I managed to obtain some results when the 
> 'weights' statement was not included:
>  
>  > mult4.lme = lme (dv4 ~ -1 + time*((verb_complex + movent + ROshape + 
> ROdimensionality)^2 ), data = risuvane2, random = list(subj = ~ -1 + 
> time), correlation = corAR1(form = ~ 1 | subj/time))
>  > anova(mult4.lme)
>                                    numDF denDF  F-value p-value
> time                                   4  3208 576.6028  <.0001
> verb_complex                           6  3208 373.4833  <.0001
> movent                                 1    29   0.0055  0.9413
> ROshape                                1  3208   0.0067  0.9349
> ROdimensionality                       1  3208   3.4778  0.0623
> verb_complex:movent                    6  3208   2.4096  0.0251
> verb_complex:ROshape                   6  3208   0.2297  0.9671
> verb_complex:ROdimensionality          6  3208   0.6016  0.7293
> movent:ROshape                         1  3208   1.7516  0.1858
> movent:ROdimensionality                1  3208   0.0119  0.9133
> ROshape:ROdimensionality               1  3208   0.3397  0.5600
> time:verb_complex                     18  3208 372.8322  <.0001
> time:movent                            3  3208   0.2730  0.8449
> time:ROshape                           3  3208   0.0199  0.9962
> time:ROdimensionality                  3  3208   3.5088  0.0147
> time:verb_complex:movent              18  3208   2.4822  0.0005
> time:verb_complex:ROshape             18  3208   0.2257  0.9997
> time:verb_complex:ROdimensionality    18  3208   0.6165  0.8898
> time:movent:ROshape                    3  3208   1.7935  0.1462
> time:movent:ROdimensionality           3  3208   0.0053  0.9995
> time:ROshape:ROdimensionality          3  3208   0.3398  0.7966
> 
>  > print(mult4.lme, corr = F)
> Linear mixed-effects model fit by REML
>   Data: risuvane2
>   Log-restricted-likelihood: -15231.59
>   Fixed: dv4 ~ -1 + time * ((verb_complex + movent + ROshape + 
> ROdimensionality)^2)
> ....
> ....
> .... 
>  
> Random effects:
>  Formula: ~-1 + time | subj
>  Structure: General positive-definite, Log-Cholesky parametrization
>                 StdDev       Corr               
> timecext_linear 19.011722951 tmcxt_ tmd0_1 tmpr01
> timedir0_dist1   0.001260818 0                  
> timeprec01       0.001263319 0      0           
> timefol01        0.001270533 0      0      0    
> Residual        25.169136027                    
> Correlation Structure: AR(1)
>  Formula: ~1 | subj/time
>  Parameter estimate(s):
>       Phi
> 0.1935926
> Number of Observations: 3360
> Number of Groups: 30
>  
>  
> However, each time I tried to include weights, I got an error message, 
> even when I reduced the number of fixed effects in the model:
> 
>  > mult4.lme = lme (dv4 ~ -1 + time*((verb_complex + movent + ROshape + 
> ROdimensionality)^2 ), data = risuvane2, random = list(subj = ~ -1 + 
> time), weights = varIdent(form = ~ 1 | time), correlation = corAR1(form 
> = ~ 1 | subj/time))
> Error in lme.formula(dv4 ~ -1 + time * ((verb_complex + movent + ROshape 
> +  :
>   nlminb problem, convergence error code = 1
>   message = iteration limit reached without convergence (9)
>  
> 
> In this case, will it be inappropriate/ dangerous to stick to the 
> version without weights? Also, I am not sure how to interpret the 
> results, and how is this to be reported. Do you have a paper I can use 
> as reference?
>  
> 
> best regards
> 
> Liliana
> 
>  
>  
>  
>  
>  
> 
> ------------------------------------------------------------------------
> *Fra:* David Atkins <datkins at u.washington.edu>
> *Til:* r-sig-mixed-models at r-project.org
> *Sendt:* fre, desember 18, 2009 7:51:30 PM
> *Emne:* Re: [R-sig-ME] what kind of analysis should be used when there 
> are several correlated dependent variables?
> 
> 
> Liliana--
> 
> One route would be to fit a multivariate mixed-effects model, in which 
> the multiple outcomes are jointly treated as a DV.  Neither lme() nor 
> lmer() have a way of explicitly specifying a multivariate model (ie, 
> MCMCglmm can "cbind" multiple outcomes together), but it is possible to 
> fit at least some basic multivariate models with some data manipulation.
> 
> The main "trick" here is to reshape your data by stacking all DVs into a 
> single DV column and creating a factor that identifies which values in 
> the DV correspond to your 4 separate DVs.
> 
> I recently used lme() to do this with a study of daily positive mood, 
> negative mood, and fatigue in women with breast cancer (each woman had 
> 30 days of data).
> 
> Here was the code to reshape the data (where "id" identifies the 
> individual, and "day" identifies -- shockingly -- day):
> 
> tmp.long.df <- reshape(my.df,
>                       idvar=c("id","day"),
>                       varying = c("posemo","negemo","fatigue"),
>                       v.names = "dv",
>                       times = 1:3,
>                       direction="long")
> names(tmp.long.df)[8] <- "dv.f" # rename times
> tmp.long.df$dv.f <- factor(tmp.long.df$dv.f, 1:3, 
> c("posemo","negemo","fatigue"))
> 
> So, your separate columns of DVs are specified on "varying", and the new 
> data.frame has a column called "times" that identifies which DV is which 
> in your new "dv" column.  I change times (which just happened to be the 
> 8th column in my data, you'll likely need to change that) to "dv.f" and 
> then change that to factor with levels identifying separate DVs.
> 
> Then, here is an example of a call to lme() that I used:
> 
> mult.lme3.2 <- lme(dv ~ -1 + dv.f/(supp.sat.c*(emot.iss.c + phys.iss.c + 
> comm.iss.c)),
>                 data = mult.df, na.action = na.omit, control = 
> list(msVerbose = TRUE),
>                 random = list(id = ~ -1 + dv.f),
>                 weights = varIdent(form = ~ 1 | dv.f),
>                 correlation = corAR1(form = ~ 1 | id/dv.f))
> 
> So, a couple comments:
> 
> -- With this set-up, getting rid of the intercept makes the models a bit 
> easier to interpret (for me) as you get separate intercepts for each DV.
> 
> -- Similarly, the "dv.f/..." fits the covariates nested within each DV, 
> which again makes things a bit easier to interpret.
> 
> -- The random statement fits separate random-intercepts by DV that are 
> correlated.
> 
> -- The weights statement allows different residual error terms by DV.
> 
> -- For our data, we fit an AR1 correlation model because of 30 days of data.
> 
> Hope that helps; I think David Afshartous has some postings about 
> multivariate models in lme which you can probably find in the archive 
> (if memory serves).
> 
> [And, I am again impressed at how flexible the mixed-effects tools are 
> in R -- kudos to Jose and Doug for the great software.]
> 
> cheers, Dave
> 
> -- Dave Atkins, PhD
> Research Associate Professor
> Center for the Study of Health and Risk Behaviors
> Department of  Psychiatry and Behavioral Science
> University of Washington
> 1100 NE 45th Street, Suite 300
> Seattle, WA  98105
> 206-616-3879
> datkins at u.washington.edu <mailto:datkins at u.washington.edu>
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org 
> <mailto:R-sig-mixed-models at r-project.org> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> ------------------------------------------------------------------------
> 
> Alt i ett. F? Yahoo! Mail <http://no.mail.yahoo.com> med 
> adressekartotek, kalender og notisblokk.
>



From j.hadfield at ed.ac.uk  Sat Dec 19 18:29:46 2009
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Sat, 19 Dec 2009 17:29:46 +0000
Subject: [R-sig-ME] MCMCglmm_2.00
Message-ID: <E1EAF9E5-66B0-4329-9D38-8367ED324996@ed.ac.uk>

Hi All,

I've released a new version of MCMCglmm which should appear on CRAN  
soon.  The main updates are:

I) Parameter expanded models now implemented which a) speed up mixing  
when variances are close to zero  and b) allow non-central F- 
distributed priors for the variance components
||) Latent variables in binary models can be updated using slice  
sampling (slice=TRUE) - this is usually more efficient
|||) Known bugs fixed - all but one (for ordinal models with more than  
2 categories) resulted in failure to fit a model rather than fitting  
an incorrect model.
||||) Extended set of course notes vignette("CourseNotes",  
"MCMCglmm"). These are incomplete, but better than not having them,  
hopefully. There will undoubtedly be errors in there - if you could  
let me know I'd be grateful.

Cheers,

Jarrod
  
  

-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.



From tahirajamil at yahoo.com  Thu Dec 24 00:41:10 2009
From: tahirajamil at yahoo.com (Tahira Jamil)
Date: Wed, 23 Dec 2009 15:41:10 -0800 (PST)
Subject: [R-sig-ME] False convergence of glmer model and loglikelihood
Message-ID: <43812.73195.qm@web113513.mail.gq1.yahoo.com>

Dear R user:
To examine the power of the LRT, I have simulated replicate data sets under H1 and analyzed them using both H0 (interaction term=0)and H1 to see whether H0 is rejected by the LRT. My algorithm is

Log.Lik<-
          function(  n.sim ,n,K){

        LogL0<- rep(NA,n.sim)
        Df0<-rep(NA,n.sim)


       LogL<-rep(NA,n.sim)
       Df<-rep(NA,n.sim)



     for (s in  1:n.sim ){
                                                
              site<-rep(1:n,each=K)  # K= No of sp
              sp<-rep(1:K,n)
              Z<-runif(K,2,10)

             r.coef<- rmvnorm(K, mean=c(0,0),
                            sigma=matrix(c(6.65,-1.237,           
                                         -1.237,0.3033), 2),
                                        method="chol")
             i.coef<-5.045-1.05612*Z+r.coef[,1]
             s.coef<- (-1.9315)+0.322*Z+r.coef[,2]
          

            site.coef<-rnorm(n,0,0.37)
            random.intercept <- i.coef[sp]
            random.slope <- s.coef[sp]
            random.site<-site.coef[site]
            # Z<-rnorm(K,5.89,1.89)
            X<-runif(n,0,5)


            X0<-X[site]
            Z0<-Z[sp]


            Y0<-invlogit(random.intercept+  random.slope *X0+        random.site )
         #  Y<-exp(Y)/(1+exp(Y))
            y0=rbinom(n*K,1,Y0)
            data0<-data.frame(sp,site,y0,X0,Z0 )
            fm0<-glmer(y0 ~ X0+Z0+ (1+X0 | sp)+(1|site),
                         family = binomial,data0)

              LL0 <- logLik(fm0)
              LogL0[s] <- as.numeric(LL0)
              Df0[s] <- attr(LL0, "df")




            fm<-glmer(y0 ~ X0*Z0+ (1+X0 | sp)+(1|site),
                         family = binomial,data0)

              LL <- logLik(fm)
              LogL[s] <- as.numeric(LL)
              Df[s] <- attr(LL, "df")
              
              
            }
         no.sim<- seq(1,n.sim,1)
      return(data.frame(no.sim,LogL0,Df0,LogL,Df))
      }

If i run my Programe n.sim=1000 I got 37 warnings

> warnings()
Warning messages:
1: In mer_finalize(ans) : singular convergence (7)
2: In mer_finalize(ans) : false convergence (8)
3: In mer_finalize(ans) : false convergence (8).................


Now my question is how can I have a statement in my progromme that if false convergence then Loglik==NA

Some help will be great!
Cheers

Tahira Jamil
Biometris (Ph.D student)
Wageningen University Wageningen
Email: tahira.jamil at wur.nl



From Wolfgang.Viechtbauer at STAT.unimaas.nl  Thu Dec 24 01:41:39 2009
From: Wolfgang.Viechtbauer at STAT.unimaas.nl (Viechtbauer Wolfgang (STAT))
Date: Thu, 24 Dec 2009 01:41:39 +0100
Subject: [R-sig-ME] False convergence of glmer model and loglikelihood
In-Reply-To: <43812.73195.qm@web113513.mail.gq1.yahoo.com>
References: <43812.73195.qm@web113513.mail.gq1.yahoo.com>
Message-ID: <077E31A57DA26E46AB0D493C9966AC7305804AB73F@UM-MAIL4112.unimaas.nl>

Dear Tahira,

Have a look at "try". In particular, put try() around your glmer() calls, then check for the class of the returned object, and if it is not what you want, set Loglik==NA.

Best,

--
Wolfgang Viechtbauer                        http://www.wvbauer.com/
Department of Methodology and Statistics    Tel: +31 (0)43 388-2277
School for Public Health and Primary Care   Office Location:
Maastricht University, P.O. Box 616         Room B2.01 (second floor)
6200 MD Maastricht, The Netherlands         Debyeplein 1 (Randwyck)
________________________________________
From: r-sig-mixed-models-bounces at r-project.org [r-sig-mixed-models-bounces at r-project.org] On Behalf Of Tahira Jamil [tahirajamil at yahoo.com]
Sent: Thursday, December 24, 2009 12:41 AM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] False convergence of glmer model and loglikelihood

Dear R user:
To examine the power of the LRT, I have simulated replicate data sets under H1 and analyzed them using both H0 (interaction term=0)and H1 to see whether H0 is rejected by the LRT. My algorithm is

Log.Lik<-
          function(  n.sim ,n,K){

        LogL0<- rep(NA,n.sim)
        Df0<-rep(NA,n.sim)


       LogL<-rep(NA,n.sim)
       Df<-rep(NA,n.sim)



     for (s in  1:n.sim ){

              site<-rep(1:n,each=K)  # K= No of sp
              sp<-rep(1:K,n)
              Z<-runif(K,2,10)

             r.coef<- rmvnorm(K, mean=c(0,0),
                            sigma=matrix(c(6.65,-1.237,
                                         -1.237,0.3033), 2),
                                        method="chol")
             i.coef<-5.045-1.05612*Z+r.coef[,1]
             s.coef<- (-1.9315)+0.322*Z+r.coef[,2]


            site.coef<-rnorm(n,0,0.37)
            random.intercept <- i.coef[sp]
            random.slope <- s.coef[sp]
            random.site<-site.coef[site]
            # Z<-rnorm(K,5.89,1.89)
            X<-runif(n,0,5)


            X0<-X[site]
            Z0<-Z[sp]


            Y0<-invlogit(random.intercept+  random.slope *X0+        random.site )
         #  Y<-exp(Y)/(1+exp(Y))
            y0=rbinom(n*K,1,Y0)
            data0<-data.frame(sp,site,y0,X0,Z0 )
            fm0<-glmer(y0 ~ X0+Z0+ (1+X0 | sp)+(1|site),
                         family = binomial,data0)

              LL0 <- logLik(fm0)
              LogL0[s] <- as.numeric(LL0)
              Df0[s] <- attr(LL0, "df")




            fm<-glmer(y0 ~ X0*Z0+ (1+X0 | sp)+(1|site),
                         family = binomial,data0)

              LL <- logLik(fm)
              LogL[s] <- as.numeric(LL)
              Df[s] <- attr(LL, "df")


            }
         no.sim<- seq(1,n.sim,1)
      return(data.frame(no.sim,LogL0,Df0,LogL,Df))
      }

If i run my Programe n.sim=1000 I got 37 warnings

> warnings()
Warning messages:
1: In mer_finalize(ans) : singular convergence (7)
2: In mer_finalize(ans) : false convergence (8)
3: In mer_finalize(ans) : false convergence (8).................


Now my question is how can I have a statement in my progromme that if false convergence then Loglik==NA

Some help will be great!
Cheers

Tahira Jamil
Biometris (Ph.D student)
Wageningen University Wageningen
Email: tahira.jamil at wur.nl

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From Kevin.Kardynal at EC.gc.ca  Wed Dec 23 23:34:48 2009
From: Kevin.Kardynal at EC.gc.ca (Kardynal,Kevin [Yel])
Date: Wed, 23 Dec 2009 15:34:48 -0700
Subject: [R-sig-ME] Variable selection: AIC versus Z-statistic
Message-ID: <09359F11B0FD38458672F47AE757EEEF01531A68@sr-yel-exch2.prairie.int.ec.gc.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20091223/9b870eeb/attachment.pl>

From grahamleask at btinternet.com  Thu Dec 24 13:33:21 2009
From: grahamleask at btinternet.com (Graham Leask)
Date: Thu, 24 Dec 2009 12:33:21 +0000
Subject: [R-sig-ME] Aggregate binary response variable
Message-ID: <BE3C17F1-1940-471A-A80F-216621DCE35E@btinternet.com>

Dear list

I have a response variable coded 0/1 i.e. a binary response. There are  
20,000 individual responses that I would like to aggregate into  
numbers of each category (i.e. 0/1) by
group (350 different groups) and by month (there are several hundred  
responses per month.

What is the simplest way to perform this operation in R?



From milton.ruser at gmail.com  Thu Dec 24 16:43:49 2009
From: milton.ruser at gmail.com (milton ruser)
Date: Thu, 24 Dec 2009 10:43:49 -0500
Subject: [R-sig-ME] Aggregate binary response variable
In-Reply-To: <BE3C17F1-1940-471A-A80F-216621DCE35E@btinternet.com>
References: <BE3C17F1-1940-471A-A80F-216621DCE35E@btinternet.com>
Message-ID: <3aaf1a030912240743i613b04ere5d1ee23ce3cbaec@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20091224/36eeeff3/attachment.pl>

From bolker at ufl.edu  Thu Dec 24 22:51:41 2009
From: bolker at ufl.edu (Ben Bolker)
Date: Thu, 24 Dec 2009 16:51:41 -0500
Subject: [R-sig-ME] Variable selection: AIC versus Z-statistic
In-Reply-To: <09359F11B0FD38458672F47AE757EEEF01531A68@sr-yel-exch2.prairie.int.ec.gc.ca>
References: <09359F11B0FD38458672F47AE757EEEF01531A68@sr-yel-exch2.prairie.int.ec.gc.ca>
Message-ID: <4B33E26D.20906@ufl.edu>

Kardynal,Kevin [Yel] wrote:
>> Hello,
>>
>> I am analyzing time-series data for multiple songbird species where
>> data were collected at 3 point count stations within a stand (~150
>> stations) visited twice a year and with multiple observers. Point
>> count stations along seismic lines (10-12 stations/seismic line) were
>> added three years after the start of the surveys with 10-12
>> stations/seismic line which created an unbalanced design. I am using a
>> linear mixed effects model in lme4 that includes year and visit (first
>> or second visit to a sight) as fixed effects and observer and station
>> nested within stand (or seismic line) (to account for spatial
>> auto-correlation) as random variables. The full model includes a
>> quadratic effect of year plus their interaction terms (several species
>> have shown a quadratic response to budworm outbreak): 
>>
>> lme1a<-lmer(Abundance ~ Yr + Yr2 + Seismic + Yr*Seismic + Yr2*Seismic
>> + Visit + (1|Site/Station) + (1|Observer), data=CAWA, family =
>> poisson(link=log))
>> summary(lme1a)
>>
>> Reduced models:
>> lme2a<-lmer(Abundance ~ Yr + Seismic + Yr*Seismic + Visit +
>> (1|Observer) + (1|Site/Station), data=CAWA, family =
>> poisson(link=log))
>> summary(lme2a)
>>
>> lme3a<-lmer(Abundance ~ Yr + Yr2 + Visit + (1|Site/Station)+
>> (1|Observer), data=CAWA, family = poisson(link=log))
>> summary(lme3a)
>>
>> lme4a <- lmer(Abundance ~ Yr + Visit + (1|Site/Station)+ (1|Observer),
>> data=CAWA, family = poisson(link = log))
>> summary(lme4a)
>>
>> I initially included visit as a random effect but since there are only
>> 2 levels in this parameter, made it a fixed effect. Doing this changes
>> the parameter estimates for the fixed effects only slightly, including
>> their AIC values (delta <0.5 in most cases) and has not changed their
>> 'significance' (according to the Z-statistic).  
>>
>> Based on AIC, the full model fits the data the best (although delta
>> AIC for all models is <3). 
>>
>>   AIC  BIC logLik deviance
>>  1398 1458 -689.1     1378
>> Random effects:
>>  Groups       Name        Variance Std.Dev.
>>  Station:Site (Intercept) 0.272577 0.52209 
>>  Site         (Intercept) 2.922394 1.70950 
>>  Observer     (Intercept) 0.045124 0.21242 
>> Number of obs: 2807, groups: Station:Site, 242; Site, 65; Observer, 19
>>
>> Fixed effects:
>>              Estimate Std. Error z value Pr(>|z|)    
>> (Intercept) -2.847531   0.316017  -9.011   <2e-16 ***
>> Yr           0.127510   0.067730   1.883   0.0598 .  
>> Yr2         -0.014141   0.006561  -2.155   0.0311 *  
>> Seismic     -0.437059   1.263792  -0.346   0.7295    
>> Visit       -0.201875   0.092130  -2.191   0.0284 *  
>> Yr:Seismic  -0.159138   0.351301  -0.453   0.6506    
>> Yr2:Seismic  0.024156   0.026194   0.922   0.3564    
>>
>>       Df     AIC     BIC  logLik  Chisq Chi Df Pr(>Chisq)  
>> lme4a  6 1400.97 1436.61 -694.49                           
>> lme3a  7 1401.86 1443.44 -693.93 1.1086      1    0.29238  
>> lme2a  8 1398.46 1445.98 -691.23 5.4011      1    0.02012 *
>> lme1a 10 1398.15 1457.54 -689.07 4.3172      2    0.11548 
>>
>> Question #1: Because the parameter estimates change only slightly with
>> the inclusion of visit as a fixed instead of a random effect, is this
>> evidence that we could model visit as a random effect since visit is
>> really a nuisance variable?

  Opinions differ.  Since we know that random-effects estimates are
likely to be quite inaccurate with only 2 levels (consider estimating a
variance from 2 values), I would say that fixed is probably better.  In
principle one could say whether one had better predictive performance
(or characterize some other loss function) on the basis of completely
pooled (no effect), random/mixed, or completely separated models, and
which summary statistics would tell you which case you were in, but in
this case I would simply go with the fixed effect.  If you were really
committed to keeping visit as a random effect I would probably use a
Bayesian hierarchical model with an informative prior, or a half-Cauchy
uninformative prior, but that's more work.

>>
>> Question #2: I am interested only in knowing if the trend of a species
>> is significant or if changes (slopes) in trends between seismic and
>> non-seismic are different. To select models, I initially used AIC to
>> select the most appropriate model and then reduced the fixed
>> parameters in the model based on their Z-statistic (a la Zuur et al
>> 2009) but have since read that that step-wise model selection is not
>> appropriate for GLMM. 

  Opinions differ, again. Some (including me) would say that stepwise
selection, and in fact ANY selection followed by interpretation of the
remaining non-zero effects, is wrong -- Harrell _Applied Regression
Strategies_ is the best place to read about this.

I've also heard (without actually seeing any
>> published reference) that model averaging can't be used with quadratic
>> terms(?) 

  In general model averaging is tricky/often wrong/hard to interpret
when you are considering a 'main effect' in the presence of 'interaction
effects' (the _principle of marginality_) -- quadratic models are a
special case of this.  It's not *necessarily* wrong, but my rule is
'don't try it unless you know why it is wrong in general and you know
why it's *not* wrong in your case' -- I suggest Venables "Exegesis on
Linear Models" for this.

and log likelihoods are anti-conservative.

  Likelihood ratio tests are only valid asymptotically, and in some
cases the "N" that must be large for the LRT to be accurate is the
number of random-effects units.  I wouldn't guarantee that the results
are necessarily anticonservative, but Pinheiro and Bates 2000 find that
they are anticonservative for one particular case that they analyze.

  Of course, AIC is based on the same kind of asymptotic arguments, and
thus may be wrong as well.


Leaving variables
>> in a model to predict trend that apparently have little effect on the
>> results seems illogical in this case, particularly when no one model
>> fits the data much 'better' than any other model. 

  Harrell would argue (I think -- he may speak up for himself since he
sometimes reads this list) that the correct thing to do **if you want to
test significance of effects** is to use the full model.

  If you want to make predictions (rather than test significance) then
you should use model averaging.

>>
> Can anyone help me with understanding the most appropriate approach to
> selecting a model/parameters with my data set/goals?

   That's my two cents.  On the other hand, I don't think you will go
terribly far wrong using Zuur's approach either, especially because the
AIC says to keep the full model.  My guess is that the parameter values,
predictions, etc., are all pretty close together in all of your
different models, so model averaging OR just taking the top (full)
model or just _a priori_ using the full model will all give similar
answers.  If your different models do *not* give similar answers (which
is not impossible, but slightly pathological) then you should look
carefully at how & why the answers differ and proceed with great caution.

  By the way,  "Yr*Seismic" in your formula expands to "Yr:Seismic +
Seismic + Yr" -- you probably mean "Yr:Seismic" for the interaction.
Gets adjusted automatically in this case, but you might as well be
precise ...


Venables, W. N. 1998. Exegeses on Linear Modelsin . Washington, DC.
Retrieved from http://www.stats.ox.ac.uk/pub/MASS3/Exegeses.pdf.

Harrell, F. J. 2001. Regression Modeling Strategies. Springer.

Pinheiro, J. C., and D. M. Bates. 2000. Mixed-effects models in S and
S-PLUS. Springer, New York.


> 
>> (I've read and re-read multiple papers, books and threads on this
>> mailing list but have they have only left me more confused!)
>>
>> Thanks a lot for your help!
>>
>> Kevin



From highstat at highstat.com  Fri Dec 25 12:11:00 2009
From: highstat at highstat.com (Highland Statistics Ltd.)
Date: Fri, 25 Dec 2009 12:11:00 +0100
Subject: [R-sig-ME] Aggregate binary response variable
In-Reply-To: <mailman.5.1261738801.17731.r-sig-mixed-models@r-project.org>
References: <mailman.5.1261738801.17731.r-sig-mixed-models@r-project.org>
Message-ID: <4B349DC4.9050204@highstat.com>


> Message: 2
> Date: Thu, 24 Dec 2009 12:33:21 +0000
> From: Graham Leask <grahamleask at btinternet.com>
> Subject: [R-sig-ME] Aggregate binary response variable
> To: r-sig-mixed-models at r-project.org
> Message-ID: <BE3C17F1-1940-471A-A80F-216621DCE35E at btinternet.com>
> Content-Type: text/plain; charset=us-ascii; format=flowed; delsp=yes
>
> Dear list
>
> I have a response variable coded 0/1 i.e. a binary response. There are  
> 20,000 individual responses that I would like to aggregate into  
> numbers of each category (i.e. 0/1) by
> group (350 different groups) and by month (there are several hundred  
> responses per month.
>
> What is the simplest way to perform this operation in R?
>
>   


Hello Graham,

tapply is your best friend here.

There will be plenty of examples online...and if you can't find it..see 
Section 4.2 in our "Beginner's Guide to R" book...(and change mean by sum)

Happy New Year.
Alain

-- 


Dr. Alain F. Zuur
First author of:

1. Analysing Ecological Data (2007).
Zuur, AF, Ieno, EN and Smith, GM. Springer. 680 p.
URL: www.springer.com/0-387-45967-7


2. Mixed effects models and extensions in ecology with R. (2009).
Zuur, AF, Ieno, EN, Walker, N, Saveliev, AA, and Smith, GM. Springer.
http://www.springer.com/life+sci/ecology/book/978-0-387-87457-9


3. A Beginner's Guide to R (2009).
Zuur, AF, Ieno, EN, Meesters, EHWG. Springer
http://www.springer.com/statistics/computational/book/978-0-387-93836-3


Other books: http://www.highstat.com/books.htm


Statistical consultancy, courses, data analysis and software
Highland Statistics Ltd.
6 Laverock road
UK - AB41 6FN Newburgh
Tel: 0044 1358 788177
Email: highstat at highstat.com
URL: www.highstat.com
URL: www.brodgar.com



From bates at stat.wisc.edu  Fri Dec 25 17:24:11 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 25 Dec 2009 10:24:11 -0600
Subject: [R-sig-ME] [R] Multiple CHOLMOD errors when attempting poisson
	glmm
In-Reply-To: <1261681380945-978573.post@n4.nabble.com>
References: <1261681380945-978573.post@n4.nabble.com>
Message-ID: <40e66e0b0912250824m36915da2r93b8652a5d263f1a@mail.gmail.com>

On Thu, Dec 24, 2009 at 1:03 PM, postava-davig.m
<postava-davig.m at husky.neu.edu> wrote:
>
> Hello,

> I have been attempting to run a poisson glmm using lme4 for some time now
> and have had a lot of trouble. ?I would say 9 times out of 10 I receive the
> following warning:

> CHOLMOD warning: ?%h
> Error in mer_finalize(ans) :
> ?Cholmod error `not positive definite' at
> file:../Cholesky/t_cholmod_rowfac.c, line 432

That is an (admittedly obscure) indication that the Cholesky
factorization of a matrix derived from the random-effects model matrix
cannot be performed.

> My data are counts of microbe colony forming units (CFUs) collected from
> termite cuticles and the surrounding environment over a 3 year period. ?I am
> attempting to analyze the effect of several factors on these counts (termite
> nest volume, temperature, humidity, light, incubation temperature, habitat,
> year, sample location, etc.) to determine which account for the variance in
> microbial communities. ?These data are observations, so there are many
> missing values....which may be part of the problem. ?I've tried many
> different combinations of variables, and also have tried reducing my data
> set to remove as many NA's and confounding variables as possible, but I
> still can't get any models to work consistently. ?One most recent attempt
> had the following output:

 model1=lmer(totalcfus~habitat*temp*moisture*light+location+(1|habitat/colony/location),family=poisson,control=list(msVerbose=1))
> ?0: ? ? 553377.59: ?1.00573 0.620530 0.169516 ?26.3904 -13.1266 -33.2286
> -21.1955 -21.1064 -0.590761 -0.217403 -0.0342272 -0.960593 -0.0962517
> 0.441626 ?1.20575 0.718621 0.680580 0.171006 0.403729 0.278822 0.275395
> 0.00707767 0.0225599 0.0854869 0.0533373 0.0243451 0.00114120 0.000403226
> -0.00566960 -0.0143715 -0.00931896 -0.00879323 -0.000753236 -0.00335745
> -0.00178054 -0.000788027 -0.000288944 -0.000909455 -0.000839295 -0.000309293
> -1.35885e-05 9.76120e-06 3.57035e-05 2.78985e-05 1.01880e-05
> CHOLMOD warning: ?%h
> Error in mer_finalize(ans) :
> ?Cholmod error `not positive definite' at
> file:../Cholesky/t_cholmod_rowfac.c, line 432

Thank you for including the output from verbose = TRUE.  It would also
help if you included the output from sessionInfo() so we can see which
version of R you are using and which version of the lme4 package you
are using.

How many observations are used in this fit?  As you can see, the
number of parameters being fit is very large and encountering
singularities is not unexpected.

May I suggest that we move this discussion to the
R-SIG-Mixed-Models at R-project.org mailing list, which I have cc:d on
this reply?  That list is specifically intended for discussions of
this type.
> I have to admit that I'm at a loss, and have been unable to determine any
> pattern to when this error message comes up. ?I'm hoping that someone can
> help me eek out what the issue is with my data so that I can eventually work
> out a usable model.
>
> Thanks so much, and happy holidays.
> --
> View this message in context: http://n4.nabble.com/Multiple-CHOLMOD-errors-when-attempting-poisson-glmm-tp978573p978573.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From postava-davig.m at husky.neu.edu  Sat Dec 26 19:36:30 2009
From: postava-davig.m at husky.neu.edu (Marielle Postava-Davig)
Date: Sat, 26 Dec 2009 13:36:30 -0500
Subject: [R-sig-ME] [R] Multiple CHOLMOD errors when attempting poisson glmm
In-Reply-To: <7b2077810912261021j40975bc1w626086447fdc1fa9@mail.gmail.com>
References: <1261681380945-978573.post@n4.nabble.com>
	<40e66e0b0912250824m36915da2r93b8652a5d263f1a@mail.gmail.com>
	<7b2077810912261021j40975bc1w626086447fdc1fa9@mail.gmail.com>
Message-ID: <7b2077810912261036p36b2a08egcb4976b2162daf62@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20091226/96a14065/attachment.pl>

From ggrothendieck at gmail.com  Sun Dec 27 16:46:02 2009
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sun, 27 Dec 2009 10:46:02 -0500
Subject: [R-sig-ME] MlmSoftRev
Message-ID: <971536df0912270746o4a5793d1j4b9fc28c9482c87f@mail.gmail.com>

The MlmSoftRev vignette in the mlmRev package has several pages of
stack imbalance messages in it.

http://cran.r-project.org/web/packages/mlmRev/vignettes/MlmSoftRev.pdf



From postava-davig.m at husky.neu.edu  Sun Dec 27 17:02:53 2009
From: postava-davig.m at husky.neu.edu (Marielle Postava-Davig)
Date: Sun, 27 Dec 2009 11:02:53 -0500
Subject: [R-sig-ME] Update: Multiple CHOLMOD errors when attempting poisson
	glmm
Message-ID: <7b2077810912270802k56e8d2fbw26ee387bc3cf5d2@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20091227/a89de6e4/attachment.pl>

From bates at stat.wisc.edu  Sun Dec 27 19:09:17 2009
From: bates at stat.wisc.edu (Douglas Bates)
Date: Sun, 27 Dec 2009 12:09:17 -0600
Subject: [R-sig-ME] MlmSoftRev
In-Reply-To: <971536df0912270746o4a5793d1j4b9fc28c9482c87f@mail.gmail.com>
References: <971536df0912270746o4a5793d1j4b9fc28c9482c87f@mail.gmail.com>
Message-ID: <40e66e0b0912271009m53ed2458ja0583318ba85c9c6@mail.gmail.com>

Thanks, I'll take a look.

On Sun, Dec 27, 2009 at 9:46 AM, Gabor Grothendieck
<ggrothendieck at gmail.com> wrote:
> The MlmSoftRev vignette in the mlmRev package has several pages of
> stack imbalance messages in it.
>
> http://cran.r-project.org/web/packages/mlmRev/vignettes/MlmSoftRev.pdf
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



