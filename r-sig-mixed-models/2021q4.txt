From @@@h@@m@v@@conce|o@ @end|ng |rom gm@||@com  Mon Oct  4 16:05:25 2021
From: @@@h@@m@v@@conce|o@ @end|ng |rom gm@||@com (Sasha Vasconcelos)
Date: Mon, 4 Oct 2021 15:05:25 +0100
Subject: [R-sig-ME] Issue with boundary (singular) fit: see ?isSingular
Message-ID: <CAF08B3iWYHzsiVSHUyTCSgg-nbG2dX6nv0D3QW7PPAm+yGvAnA@mail.gmail.com>

Hi,

I'm running a piecewise SEM with 3 component models:

lmer(response variable1 ~ predictors + (1|Point) + (1|Year), input_table)

glmer(response variable2 ~ predictors + (1| Point) + (1|Year), family =
"binomial", input_table)

glmer(response variable3 ~ predictors + (1| Point) + (1|Year), family =
"binomial", input_table)

Because sampling involved visiting 18 points in spring of 2018 and again in
spring of 2019, I specified samping point and year as random effects.

When I run the model, this warning message appears:
Check model convergence: log-likelihood estimates lead to negative
Chi-squared!

This message also appears:
boundary (singular) fit: see ?isSingular

>From what I've read about the second message, it could be due to random
effect variance estimates of zero. I checked and this happens in the 1st
and 3rd component models. In the 1st model "Point" has zero variance, and
in the 3rd model "Year" has zero variance.

My first question is (and I apologize in advance if this is silly to ask)
whether this means that there's not really an effect coming from Point in
component model 1 and from Year in component model 2? If so, would it be
possible to remove those random effects to end up with:

lmer(Response variable1 ~ Predictors + (1|Year), input_table)

glmer(Response variable2 ~Predictors + (1| Point) + (1|Year), family =
"binomial", input_table)

glmer(Response variable3 ~ Predictors + (1| Point), family = "binomial",
input_table)

My second question is whether the warning "Check model convergence:
log-likelihood estimates lead to negative Chi-squared!" is related to these
singularity issues?

Oh and I am using the development version of the piecewise SEM package
installed using devtools. This is because this version provides additional
standardized coefficients for GLMM.


Thanks!


-- 
Sasha Vasconcelos

PhD student
CIBIO/InBIO, Research Center in Biodiversity and Genetic Resources,
Associate Laboratory
Instituto Superior de Agronomia
Tapada da Ajuda
1349-017 Lisbon, Portugal

ResearchGate <https://www.researchgate.net/profile/Sasha_Vasconcelos>
ResearcherID
<https://publons.com/researcher/2593829/sasha-vasconcelos/publications/>

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Mon Oct  4 15:12:03 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Mon, 4 Oct 2021 09:12:03 -0400
Subject: [R-sig-ME] Issue with boundary (singular) fit: see ?isSingular
In-Reply-To: <CAF08B3iWYHzsiVSHUyTCSgg-nbG2dX6nv0D3QW7PPAm+yGvAnA@mail.gmail.com>
References: <CAF08B3iWYHzsiVSHUyTCSgg-nbG2dX6nv0D3QW7PPAm+yGvAnA@mail.gmail.com>
Message-ID: <0e42048d-d240-74cc-61b5-c12582ca1f71@gmail.com>



On 10/4/21 10:05 AM, Sasha Vasconcelos wrote:
> Hi,
> 
> I'm running a piecewise SEM with 3 component models:
> 
> lmer(response variable1 ~ predictors + (1|Point) + (1|Year), input_table)
> 
> glmer(response variable2 ~ predictors + (1| Point) + (1|Year), family =
> "binomial", input_table)
> 
> glmer(response variable3 ~ predictors + (1| Point) + (1|Year), family =
> "binomial", input_table)
> 
> Because sampling involved visiting 18 points in spring of 2018 and again in
> spring of 2019, I specified samping point and year as random effects.

   If there are only two years, it's not surprising that you'll get 
estimates of zero variance for (1|Year).  I would probably make Year a 
fixed effect.

> 
> When I run the model, this warning message appears:
> Check model convergence: log-likelihood estimates lead to negative
> Chi-squared!

   I can't find this warning message anywhere, even in the development 
branch of piecewiseSEM:

https://github.com/jslefche/piecewiseSEM/search?q=convergence

??

> 
> This message also appears:
> boundary (singular) fit: see ?isSingular
> 
>  From what I've read about the second message, it could be due to random
> effect variance estimates of zero. I checked and this happens in the 1st
> and 3rd component models. In the 1st model "Point" has zero variance, and
> in the 3rd model "Year" has zero variance.
> 
> My first question is (and I apologize in advance if this is silly to ask)
> whether this means that there's not really an effect coming from Point in
> component model 1 and from Year in component model 2? If so, would it be
> possible to remove those random effects to end up with:
> 
> lmer(Response variable1 ~ Predictors + (1|Year), input_table)
> 
> glmer(Response variable2 ~Predictors + (1| Point) + (1|Year), family =
> "binomial", input_table)
> 
> glmer(Response variable3 ~ Predictors + (1| Point), family = "binomial",
> input_table)

   Seems reasonable.
> 
> My second question is whether the warning "Check model convergence:
> log-likelihood estimates lead to negative Chi-squared!" is related to these
> singularity issues?
> 
> Oh and I am using the development version of the piecewise SEM package
> installed using devtools. This is because this version provides additional
> standardized coefficients for GLMM.
> 
> 
> Thanks!
> 
> 

-- 
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
Graduate chair, Mathematics & Statistics


From @@@h@@m@v@@conce|o@ @end|ng |rom gm@||@com  Mon Oct  4 16:23:11 2021
From: @@@h@@m@v@@conce|o@ @end|ng |rom gm@||@com (Sasha Vasconcelos)
Date: Mon, 4 Oct 2021 15:23:11 +0100
Subject: [R-sig-ME] Issue with boundary (singular) fit: see ?isSingular
In-Reply-To: <0e42048d-d240-74cc-61b5-c12582ca1f71@gmail.com>
References: <CAF08B3iWYHzsiVSHUyTCSgg-nbG2dX6nv0D3QW7PPAm+yGvAnA@mail.gmail.com>
 <0e42048d-d240-74cc-61b5-c12582ca1f71@gmail.com>
Message-ID: <CAF08B3gfD1btXipyo8wdO9LNQmdHTBFTaavGRVYvOHjqdyDaaA@mail.gmail.com>

If there are only two years, it's not surprising that you'll get
estimates of zero variance for (1|Year).  I would probably make Year a
fixed effect.
I also tried that, leaving only Point as a random effect. But I still get
the singularity warning. Could it be that the sample size is simply too
small to handle any sort of random structure..?


   I can't find this warning message anywhere, even in the development
branch of piecewiseSEM:

https://github.com/jslefche/piecewiseSEM/search?q=convergence

??

 I also haven't been able to find anything about that warning message
anywhere, so I've posted this same question to
jslefche <https://github.com/jslefche>/piecewiseSEM
<https://github.com/jslefche/piecewiseSEM> on github and am hoping for an
answer soon.

On Mon, 4 Oct 2021 at 14:16, Ben Bolker <bbolker at gmail.com> wrote:

>
>
> On 10/4/21 10:05 AM, Sasha Vasconcelos wrote:
> > Hi,
> >
> > I'm running a piecewise SEM with 3 component models:
> >
> > lmer(response variable1 ~ predictors + (1|Point) + (1|Year), input_table)
> >
> > glmer(response variable2 ~ predictors + (1| Point) + (1|Year), family =
> > "binomial", input_table)
> >
> > glmer(response variable3 ~ predictors + (1| Point) + (1|Year), family =
> > "binomial", input_table)
> >
> > Because sampling involved visiting 18 points in spring of 2018 and again
> in
> > spring of 2019, I specified samping point and year as random effects.
>
>    If there are only two years, it's not surprising that you'll get
> estimates of zero variance for (1|Year).  I would probably make Year a
> fixed effect.
>
> >
> > When I run the model, this warning message appears:
> > Check model convergence: log-likelihood estimates lead to negative
> > Chi-squared!
>
>    I can't find this warning message anywhere, even in the development
> branch of piecewiseSEM:
>
> https://github.com/jslefche/piecewiseSEM/search?q=convergence
>
> ??
>
> >
> > This message also appears:
> > boundary (singular) fit: see ?isSingular
> >
> >  From what I've read about the second message, it could be due to random
> > effect variance estimates of zero. I checked and this happens in the 1st
> > and 3rd component models. In the 1st model "Point" has zero variance, and
> > in the 3rd model "Year" has zero variance.
> >
> > My first question is (and I apologize in advance if this is silly to ask)
> > whether this means that there's not really an effect coming from Point in
> > component model 1 and from Year in component model 2? If so, would it be
> > possible to remove those random effects to end up with:
> >
> > lmer(Response variable1 ~ Predictors + (1|Year), input_table)
> >
> > glmer(Response variable2 ~Predictors + (1| Point) + (1|Year), family =
> > "binomial", input_table)
> >
> > glmer(Response variable3 ~ Predictors + (1| Point), family = "binomial",
> > input_table)
>
>    Seems reasonable.
> >
> > My second question is whether the warning "Check model convergence:
> > log-likelihood estimates lead to negative Chi-squared!" is related to
> these
> > singularity issues?
> >
> > Oh and I am using the development version of the piecewise SEM package
> > installed using devtools. This is because this version provides
> additional
> > standardized coefficients for GLMM.
> >
> >
> > Thanks!
> >
> >
>
> --
> Dr. Benjamin Bolker
> Professor, Mathematics & Statistics and Biology, McMaster University
> Director, School of Computational Science and Engineering
> Graduate chair, Mathematics & Statistics
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


-- 
Sasha Vasconcelos

PhD student
CIBIO/InBIO, Research Center in Biodiversity and Genetic Resources,
Associate Laboratory
Instituto Superior de Agronomia
Tapada da Ajuda
1349-017 Lisbon, Portugal

ResearchGate <https://www.researchgate.net/profile/Sasha_Vasconcelos>
ResearcherID
<https://publons.com/researcher/2593829/sasha-vasconcelos/publications/>

	[[alternative HTML version deleted]]


From @@@h@@m@v@@conce|o@ @end|ng |rom gm@||@com  Mon Oct  4 22:03:18 2021
From: @@@h@@m@v@@conce|o@ @end|ng |rom gm@||@com (Sasha Vasconcelos)
Date: Mon, 4 Oct 2021 21:03:18 +0100
Subject: [R-sig-ME] Issue with boundary (singular) fit: see ?isSingular
In-Reply-To: <CAF08B3gfD1btXipyo8wdO9LNQmdHTBFTaavGRVYvOHjqdyDaaA@mail.gmail.com>
References: <CAF08B3iWYHzsiVSHUyTCSgg-nbG2dX6nv0D3QW7PPAm+yGvAnA@mail.gmail.com>
 <0e42048d-d240-74cc-61b5-c12582ca1f71@gmail.com>
 <CAF08B3gfD1btXipyo8wdO9LNQmdHTBFTaavGRVYvOHjqdyDaaA@mail.gmail.com>
Message-ID: <CAF08B3j2L63_fY2AR2PnmN5Petr7tRs2O0nnFeGOX4xSeHBW9A@mail.gmail.com>

Hi again,

Just an update. I received this reply about the strange warning (Check
model convergence: log-likelihood estimates lead to negative Chi-squared!)

Yes, the convergence issues will lead to non-observable Chi-squared. If you
remove those random components with variance close to 0, it should help.



On Mon, 4 Oct 2021 at 15:23, Sasha Vasconcelos <
sasha.m.vasconcelos at gmail.com> wrote:

> If there are only two years, it's not surprising that you'll get
> estimates of zero variance for (1|Year).  I would probably make Year a
> fixed effect.
> I also tried that, leaving only Point as a random effect. But I still get
> the singularity warning. Could it be that the sample size is simply too
> small to handle any sort of random structure..?
>
>
>    I can't find this warning message anywhere, even in the development
> branch of piecewiseSEM:
>
> https://github.com/jslefche/piecewiseSEM/search?q=convergence
>
> ??
>
>  I also haven't been able to find anything about that warning message
> anywhere, so I've posted this same question to
> jslefche <https://github.com/jslefche>/piecewiseSEM
> <https://github.com/jslefche/piecewiseSEM> on github and am hoping for an
> answer soon.
>
> On Mon, 4 Oct 2021 at 14:16, Ben Bolker <bbolker at gmail.com> wrote:
>
>>
>>
>> On 10/4/21 10:05 AM, Sasha Vasconcelos wrote:
>> > Hi,
>> >
>> > I'm running a piecewise SEM with 3 component models:
>> >
>> > lmer(response variable1 ~ predictors + (1|Point) + (1|Year),
>> input_table)
>> >
>> > glmer(response variable2 ~ predictors + (1| Point) + (1|Year), family =
>> > "binomial", input_table)
>> >
>> > glmer(response variable3 ~ predictors + (1| Point) + (1|Year), family =
>> > "binomial", input_table)
>> >
>> > Because sampling involved visiting 18 points in spring of 2018 and
>> again in
>> > spring of 2019, I specified samping point and year as random effects.
>>
>>    If there are only two years, it's not surprising that you'll get
>> estimates of zero variance for (1|Year).  I would probably make Year a
>> fixed effect.
>>
>> >
>> > When I run the model, this warning message appears:
>> > Check model convergence: log-likelihood estimates lead to negative
>> > Chi-squared!
>>
>>    I can't find this warning message anywhere, even in the development
>> branch of piecewiseSEM:
>>
>> https://github.com/jslefche/piecewiseSEM/search?q=convergence
>>
>> ??
>>
>> >
>> > This message also appears:
>> > boundary (singular) fit: see ?isSingular
>> >
>> >  From what I've read about the second message, it could be due to random
>> > effect variance estimates of zero. I checked and this happens in the 1st
>> > and 3rd component models. In the 1st model "Point" has zero variance,
>> and
>> > in the 3rd model "Year" has zero variance.
>> >
>> > My first question is (and I apologize in advance if this is silly to
>> ask)
>> > whether this means that there's not really an effect coming from Point
>> in
>> > component model 1 and from Year in component model 2? If so, would it be
>> > possible to remove those random effects to end up with:
>> >
>> > lmer(Response variable1 ~ Predictors + (1|Year), input_table)
>> >
>> > glmer(Response variable2 ~Predictors + (1| Point) + (1|Year), family =
>> > "binomial", input_table)
>> >
>> > glmer(Response variable3 ~ Predictors + (1| Point), family = "binomial",
>> > input_table)
>>
>>    Seems reasonable.
>> >
>> > My second question is whether the warning "Check model convergence:
>> > log-likelihood estimates lead to negative Chi-squared!" is related to
>> these
>> > singularity issues?
>> >
>> > Oh and I am using the development version of the piecewise SEM package
>> > installed using devtools. This is because this version provides
>> additional
>> > standardized coefficients for GLMM.
>> >
>> >
>> > Thanks!
>> >
>> >
>>
>> --
>> Dr. Benjamin Bolker
>> Professor, Mathematics & Statistics and Biology, McMaster University
>> Director, School of Computational Science and Engineering
>> Graduate chair, Mathematics & Statistics
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>
> --
> Sasha Vasconcelos
>
> PhD student
> CIBIO/InBIO, Research Center in Biodiversity and Genetic Resources,
> Associate Laboratory
> Instituto Superior de Agronomia
> Tapada da Ajuda
> 1349-017 Lisbon, Portugal
>
> ResearchGate <https://www.researchgate.net/profile/Sasha_Vasconcelos>
> ResearcherID
> <https://publons.com/researcher/2593829/sasha-vasconcelos/publications/>
>
>

-- 
Sasha Vasconcelos

PhD student
CIBIO/InBIO, Research Center in Biodiversity and Genetic Resources,
Associate Laboratory
Instituto Superior de Agronomia
Tapada da Ajuda
1349-017 Lisbon, Portugal

ResearchGate <https://www.researchgate.net/profile/Sasha_Vasconcelos>
ResearcherID
<https://publons.com/researcher/2593829/sasha-vasconcelos/publications/>

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Mon Oct  4 21:12:41 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Mon, 4 Oct 2021 15:12:41 -0400
Subject: [R-sig-ME] Issue with boundary (singular) fit: see ?isSingular
In-Reply-To: <CAF08B3j2L63_fY2AR2PnmN5Petr7tRs2O0nnFeGOX4xSeHBW9A@mail.gmail.com>
References: <CAF08B3iWYHzsiVSHUyTCSgg-nbG2dX6nv0D3QW7PPAm+yGvAnA@mail.gmail.com>
 <0e42048d-d240-74cc-61b5-c12582ca1f71@gmail.com>
 <CAF08B3gfD1btXipyo8wdO9LNQmdHTBFTaavGRVYvOHjqdyDaaA@mail.gmail.com>
 <CAF08B3j2L63_fY2AR2PnmN5Petr7tRs2O0nnFeGOX4xSeHBW9A@mail.gmail.com>
Message-ID: <CABghstTb5f8xvcKD14q+COnJQxgXREtUmJX8kRS1q6AW9bq-DQ@mail.gmail.com>

  From whom? Is piecewiseSEM really the only package you're using? It
disconcerts me that I can't locate the error message in any source
code I've found so far.

On Mon, Oct 4, 2021 at 3:04 PM Sasha Vasconcelos
<sasha.m.vasconcelos at gmail.com> wrote:
>
> Hi again,
>
> Just an update. I received this reply about the strange warning (Check model convergence: log-likelihood estimates lead to negative Chi-squared!)
>
> Yes, the convergence issues will lead to non-observable Chi-squared. If you remove those random components with variance close to 0, it should help.
>
>
>
> On Mon, 4 Oct 2021 at 15:23, Sasha Vasconcelos <sasha.m.vasconcelos at gmail.com> wrote:
>>
>> If there are only two years, it's not surprising that you'll get
>> estimates of zero variance for (1|Year).  I would probably make Year a
>> fixed effect.
>> I also tried that, leaving only Point as a random effect. But I still get the singularity warning. Could it be that the sample size is simply too small to handle any sort of random structure..?
>>
>>
>>    I can't find this warning message anywhere, even in the development
>> branch of piecewiseSEM:
>>
>> https://github.com/jslefche/piecewiseSEM/search?q=convergence
>>
>> ??
>>
>>  I also haven't been able to find anything about that warning message anywhere, so I've posted this same question to
>>
>> jslefche/piecewiseSEM on github and am hoping for an answer soon.
>>
>>
>>
>> On Mon, 4 Oct 2021 at 14:16, Ben Bolker <bbolker at gmail.com> wrote:
>>>
>>>
>>>
>>> On 10/4/21 10:05 AM, Sasha Vasconcelos wrote:
>>> > Hi,
>>> >
>>> > I'm running a piecewise SEM with 3 component models:
>>> >
>>> > lmer(response variable1 ~ predictors + (1|Point) + (1|Year), input_table)
>>> >
>>> > glmer(response variable2 ~ predictors + (1| Point) + (1|Year), family =
>>> > "binomial", input_table)
>>> >
>>> > glmer(response variable3 ~ predictors + (1| Point) + (1|Year), family =
>>> > "binomial", input_table)
>>> >
>>> > Because sampling involved visiting 18 points in spring of 2018 and again in
>>> > spring of 2019, I specified samping point and year as random effects.
>>>
>>>    If there are only two years, it's not surprising that you'll get
>>> estimates of zero variance for (1|Year).  I would probably make Year a
>>> fixed effect.
>>>
>>> >
>>> > When I run the model, this warning message appears:
>>> > Check model convergence: log-likelihood estimates lead to negative
>>> > Chi-squared!
>>>
>>>    I can't find this warning message anywhere, even in the development
>>> branch of piecewiseSEM:
>>>
>>> https://github.com/jslefche/piecewiseSEM/search?q=convergence
>>>
>>> ??
>>>
>>> >
>>> > This message also appears:
>>> > boundary (singular) fit: see ?isSingular
>>> >
>>> >  From what I've read about the second message, it could be due to random
>>> > effect variance estimates of zero. I checked and this happens in the 1st
>>> > and 3rd component models. In the 1st model "Point" has zero variance, and
>>> > in the 3rd model "Year" has zero variance.
>>> >
>>> > My first question is (and I apologize in advance if this is silly to ask)
>>> > whether this means that there's not really an effect coming from Point in
>>> > component model 1 and from Year in component model 2? If so, would it be
>>> > possible to remove those random effects to end up with:
>>> >
>>> > lmer(Response variable1 ~ Predictors + (1|Year), input_table)
>>> >
>>> > glmer(Response variable2 ~Predictors + (1| Point) + (1|Year), family =
>>> > "binomial", input_table)
>>> >
>>> > glmer(Response variable3 ~ Predictors + (1| Point), family = "binomial",
>>> > input_table)
>>>
>>>    Seems reasonable.
>>> >
>>> > My second question is whether the warning "Check model convergence:
>>> > log-likelihood estimates lead to negative Chi-squared!" is related to these
>>> > singularity issues?
>>> >
>>> > Oh and I am using the development version of the piecewise SEM package
>>> > installed using devtools. This is because this version provides additional
>>> > standardized coefficients for GLMM.
>>> >
>>> >
>>> > Thanks!
>>> >
>>> >
>>>
>>> --
>>> Dr. Benjamin Bolker
>>> Professor, Mathematics & Statistics and Biology, McMaster University
>>> Director, School of Computational Science and Engineering
>>> Graduate chair, Mathematics & Statistics
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>>
>> --
>> Sasha Vasconcelos
>>
>> PhD student
>> CIBIO/InBIO, Research Center in Biodiversity and Genetic Resources, Associate Laboratory
>> Instituto Superior de Agronomia
>> Tapada da Ajuda
>> 1349-017 Lisbon, Portugal
>>
>> ResearchGate
>> ResearcherID
>>
>
>
> --
> Sasha Vasconcelos
>
> PhD student
> CIBIO/InBIO, Research Center in Biodiversity and Genetic Resources, Associate Laboratory
> Instituto Superior de Agronomia
> Tapada da Ajuda
> 1349-017 Lisbon, Portugal
>
> ResearchGate
> ResearcherID
>


From @@@h@@m@v@@conce|o@ @end|ng |rom gm@||@com  Mon Oct  4 22:20:20 2021
From: @@@h@@m@v@@conce|o@ @end|ng |rom gm@||@com (Sasha Vasconcelos)
Date: Mon, 4 Oct 2021 21:20:20 +0100
Subject: [R-sig-ME] Issue with boundary (singular) fit: see ?isSingular
In-Reply-To: <CABghstTb5f8xvcKD14q+COnJQxgXREtUmJX8kRS1q6AW9bq-DQ@mail.gmail.com>
References: <CAF08B3iWYHzsiVSHUyTCSgg-nbG2dX6nv0D3QW7PPAm+yGvAnA@mail.gmail.com>
 <0e42048d-d240-74cc-61b5-c12582ca1f71@gmail.com>
 <CAF08B3gfD1btXipyo8wdO9LNQmdHTBFTaavGRVYvOHjqdyDaaA@mail.gmail.com>
 <CAF08B3j2L63_fY2AR2PnmN5Petr7tRs2O0nnFeGOX4xSeHBW9A@mail.gmail.com>
 <CABghstTb5f8xvcKD14q+COnJQxgXREtUmJX8kRS1q6AW9bq-DQ@mail.gmail.com>
Message-ID: <CAF08B3gc+wRFa4omCfHNUL9+BbSckOtzNV_FkCdg7fyYGehGiQ@mail.gmail.com>

It was from Jon Lefcheck. Yes piecewiseSEM is the only package I'm using.

Sasha

On Mon, 4 Oct 2021 at 20:12, Ben Bolker <bbolker at gmail.com> wrote:

>   From whom? Is piecewiseSEM really the only package you're using? It
> disconcerts me that I can't locate the error message in any source
> code I've found so far.
>
> On Mon, Oct 4, 2021 at 3:04 PM Sasha Vasconcelos
> <sasha.m.vasconcelos at gmail.com> wrote:
> >
> > Hi again,
> >
> > Just an update. I received this reply about the strange warning (Check
> model convergence: log-likelihood estimates lead to negative Chi-squared!)
> >
> > Yes, the convergence issues will lead to non-observable Chi-squared. If
> you remove those random components with variance close to 0, it should help.
> >
> >
> >
> > On Mon, 4 Oct 2021 at 15:23, Sasha Vasconcelos <
> sasha.m.vasconcelos at gmail.com> wrote:
> >>
> >> If there are only two years, it's not surprising that you'll get
> >> estimates of zero variance for (1|Year).  I would probably make Year a
> >> fixed effect.
> >> I also tried that, leaving only Point as a random effect. But I still
> get the singularity warning. Could it be that the sample size is simply too
> small to handle any sort of random structure..?
> >>
> >>
> >>    I can't find this warning message anywhere, even in the development
> >> branch of piecewiseSEM:
> >>
> >> https://github.com/jslefche/piecewiseSEM/search?q=convergence
> >>
> >> ??
> >>
> >>  I also haven't been able to find anything about that warning message
> anywhere, so I've posted this same question to
> >>
> >> jslefche/piecewiseSEM on github and am hoping for an answer soon.
> >>
> >>
> >>
> >> On Mon, 4 Oct 2021 at 14:16, Ben Bolker <bbolker at gmail.com> wrote:
> >>>
> >>>
> >>>
> >>> On 10/4/21 10:05 AM, Sasha Vasconcelos wrote:
> >>> > Hi,
> >>> >
> >>> > I'm running a piecewise SEM with 3 component models:
> >>> >
> >>> > lmer(response variable1 ~ predictors + (1|Point) + (1|Year),
> input_table)
> >>> >
> >>> > glmer(response variable2 ~ predictors + (1| Point) + (1|Year),
> family =
> >>> > "binomial", input_table)
> >>> >
> >>> > glmer(response variable3 ~ predictors + (1| Point) + (1|Year),
> family =
> >>> > "binomial", input_table)
> >>> >
> >>> > Because sampling involved visiting 18 points in spring of 2018 and
> again in
> >>> > spring of 2019, I specified samping point and year as random effects.
> >>>
> >>>    If there are only two years, it's not surprising that you'll get
> >>> estimates of zero variance for (1|Year).  I would probably make Year a
> >>> fixed effect.
> >>>
> >>> >
> >>> > When I run the model, this warning message appears:
> >>> > Check model convergence: log-likelihood estimates lead to negative
> >>> > Chi-squared!
> >>>
> >>>    I can't find this warning message anywhere, even in the development
> >>> branch of piecewiseSEM:
> >>>
> >>> https://github.com/jslefche/piecewiseSEM/search?q=convergence
> >>>
> >>> ??
> >>>
> >>> >
> >>> > This message also appears:
> >>> > boundary (singular) fit: see ?isSingular
> >>> >
> >>> >  From what I've read about the second message, it could be due to
> random
> >>> > effect variance estimates of zero. I checked and this happens in the
> 1st
> >>> > and 3rd component models. In the 1st model "Point" has zero
> variance, and
> >>> > in the 3rd model "Year" has zero variance.
> >>> >
> >>> > My first question is (and I apologize in advance if this is silly to
> ask)
> >>> > whether this means that there's not really an effect coming from
> Point in
> >>> > component model 1 and from Year in component model 2? If so, would
> it be
> >>> > possible to remove those random effects to end up with:
> >>> >
> >>> > lmer(Response variable1 ~ Predictors + (1|Year), input_table)
> >>> >
> >>> > glmer(Response variable2 ~Predictors + (1| Point) + (1|Year), family
> =
> >>> > "binomial", input_table)
> >>> >
> >>> > glmer(Response variable3 ~ Predictors + (1| Point), family =
> "binomial",
> >>> > input_table)
> >>>
> >>>    Seems reasonable.
> >>> >
> >>> > My second question is whether the warning "Check model convergence:
> >>> > log-likelihood estimates lead to negative Chi-squared!" is related
> to these
> >>> > singularity issues?
> >>> >
> >>> > Oh and I am using the development version of the piecewise SEM
> package
> >>> > installed using devtools. This is because this version provides
> additional
> >>> > standardized coefficients for GLMM.
> >>> >
> >>> >
> >>> > Thanks!
> >>> >
> >>> >
> >>>
> >>> --
> >>> Dr. Benjamin Bolker
> >>> Professor, Mathematics & Statistics and Biology, McMaster University
> >>> Director, School of Computational Science and Engineering
> >>> Graduate chair, Mathematics & Statistics
> >>>
> >>> _______________________________________________
> >>> R-sig-mixed-models at r-project.org mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>
> >>
> >>
> >> --
> >> Sasha Vasconcelos
> >>
> >> PhD student
> >> CIBIO/InBIO, Research Center in Biodiversity and Genetic Resources,
> Associate Laboratory
> >> Instituto Superior de Agronomia
> >> Tapada da Ajuda
> >> 1349-017 Lisbon, Portugal
> >>
> >> ResearchGate
> >> ResearcherID
> >>
> >
> >
> > --
> > Sasha Vasconcelos
> >
> > PhD student
> > CIBIO/InBIO, Research Center in Biodiversity and Genetic Resources,
> Associate Laboratory
> > Instituto Superior de Agronomia
> > Tapada da Ajuda
> > 1349-017 Lisbon, Portugal
> >
> > ResearchGate
> > ResearcherID
> >
>


-- 
Sasha Vasconcelos

PhD student
CIBIO/InBIO, Research Center in Biodiversity and Genetic Resources,
Associate Laboratory
Instituto Superior de Agronomia
Tapada da Ajuda
1349-017 Lisbon, Portugal

ResearchGate <https://www.researchgate.net/profile/Sasha_Vasconcelos>
ResearcherID
<https://publons.com/researcher/2593829/sasha-vasconcelos/publications/>

	[[alternative HTML version deleted]]


From |@w|@wt @end|ng |rom gm@||@com  Wed Oct  6 05:20:00 2021
From: |@w|@wt @end|ng |rom gm@||@com (Timothy MacKenzie)
Date: Tue, 5 Oct 2021 22:20:00 -0500
Subject: [R-sig-ME] Random slopes for categorical variables
Message-ID: <CADreqiwQs=Ts9x=XwN4B-knHtH8zRzwybYRyfxE9phOmqjx8hg@mail.gmail.com>

Hello All,

I had a basic question. For continuous variables (X) killing the
intercept in the random part kills the correlation between random
effects (intercepts and slopes):

(0 + X | ID)

But for categorical variables (CAT) killing the intercept actually
allows for all levels of CAT (including the reference level) to be
correlated that is:

(0 + CAT | ID) estimates more correlations than (CAT | ID)

Am I correct?

Thanks,
Tim M


From me @end|ng |rom ph||||p@|d@y@com  Wed Oct  6 05:23:23 2021
From: me @end|ng |rom ph||||p@|d@y@com (Phillip Alday)
Date: Tue, 5 Oct 2021 22:23:23 -0500
Subject: [R-sig-ME] Random slopes for categorical variables
In-Reply-To: <CADreqiwQs=Ts9x=XwN4B-knHtH8zRzwybYRyfxE9phOmqjx8hg@mail.gmail.com>
References: <CADreqiwQs=Ts9x=XwN4B-knHtH8zRzwybYRyfxE9phOmqjx8hg@mail.gmail.com>
Message-ID: <5bc75a4d-bf86-8274-b6de-9f9043b59e98@phillipalday.com>

Yes.

Well, to be more precise 0 + CAT and 1 + CAT estimate different
contrasts and so the correlation you're estimating correspond to
whatever contrast comes out.

Same deal for 1 + CAT with sum vs treatment vs. Helmert coding.

On 5/10/21 10:20 pm, Timothy MacKenzie wrote:
> Hello All,
> 
> I had a basic question. For continuous variables (X) killing the
> intercept in the random part kills the correlation between random
> effects (intercepts and slopes):
> 
> (0 + X | ID)
> 
> But for categorical variables (CAT) killing the intercept actually
> allows for all levels of CAT (including the reference level) to be
> correlated that is:
> 
> (0 + CAT | ID) estimates more correlations than (CAT | ID)
> 
> Am I correct?
> 
> Thanks,
> Tim M
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From |@w|@wt @end|ng |rom gm@||@com  Wed Oct  6 05:39:17 2021
From: |@w|@wt @end|ng |rom gm@||@com (Timothy MacKenzie)
Date: Tue, 5 Oct 2021 22:39:17 -0500
Subject: [R-sig-ME] Random slopes for categorical variables
In-Reply-To: <5bc75a4d-bf86-8274-b6de-9f9043b59e98@phillipalday.com>
References: <CADreqiwQs=Ts9x=XwN4B-knHtH8zRzwybYRyfxE9phOmqjx8hg@mail.gmail.com>
 <5bc75a4d-bf86-8274-b6de-9f9043b59e98@phillipalday.com>
Message-ID: <CADreqixPnrHEsuJhvgst7ZaTw9+npLe7czR7XCdYLoytycjNbg@mail.gmail.com>

Sure, what if CAT has 2 levels, given R's default dummy coding, what
is the difference between (1 + CAT | ID) and (0 + CAT | ID), then?

On Tue, Oct 5, 2021 at 10:23 PM Phillip Alday <me at phillipalday.com> wrote:
>
> Yes.
>
> Well, to be more precise 0 + CAT and 1 + CAT estimate different
> contrasts and so the correlation you're estimating correspond to
> whatever contrast comes out.
>
> Same deal for 1 + CAT with sum vs treatment vs. Helmert coding.
>
> On 5/10/21 10:20 pm, Timothy MacKenzie wrote:
> > Hello All,
> >
> > I had a basic question. For continuous variables (X) killing the
> > intercept in the random part kills the correlation between random
> > effects (intercepts and slopes):
> >
> > (0 + X | ID)
> >
> > But for categorical variables (CAT) killing the intercept actually
> > allows for all levels of CAT (including the reference level) to be
> > correlated that is:
> >
> > (0 + CAT | ID) estimates more correlations than (CAT | ID)
> >
> > Am I correct?
> >
> > Thanks,
> > Tim M
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >


From |@w|@wt @end|ng |rom gm@||@com  Wed Oct  6 05:44:25 2021
From: |@w|@wt @end|ng |rom gm@||@com (Timothy MacKenzie)
Date: Tue, 5 Oct 2021 22:44:25 -0500
Subject: [R-sig-ME] Random slopes for categorical variables
In-Reply-To: <CADreqixPnrHEsuJhvgst7ZaTw9+npLe7czR7XCdYLoytycjNbg@mail.gmail.com>
References: <CADreqiwQs=Ts9x=XwN4B-knHtH8zRzwybYRyfxE9phOmqjx8hg@mail.gmail.com>
 <5bc75a4d-bf86-8274-b6de-9f9043b59e98@phillipalday.com>
 <CADreqixPnrHEsuJhvgst7ZaTw9+npLe7czR7XCdYLoytycjNbg@mail.gmail.com>
Message-ID: <CADreqiyCV+-odWWm9jWPx+ywNYu_RMzGGFvOHpX2YSJAsJF+zQ@mail.gmail.com>

My point is when we use (0 + CAT | ID) we get the pure coef. for each
level of CAT not any contrast. So, here we simply, I think, get the
difference in pure coef. of each level of CAT across levels of ID.

On Tue, Oct 5, 2021 at 10:39 PM Timothy MacKenzie <fswfswt at gmail.com> wrote:
>
> Sure, what if CAT has 2 levels, given R's default dummy coding, what
> is the difference between (1 + CAT | ID) and (0 + CAT | ID), then?
>
> On Tue, Oct 5, 2021 at 10:23 PM Phillip Alday <me at phillipalday.com> wrote:
> >
> > Yes.
> >
> > Well, to be more precise 0 + CAT and 1 + CAT estimate different
> > contrasts and so the correlation you're estimating correspond to
> > whatever contrast comes out.
> >
> > Same deal for 1 + CAT with sum vs treatment vs. Helmert coding.
> >
> > On 5/10/21 10:20 pm, Timothy MacKenzie wrote:
> > > Hello All,
> > >
> > > I had a basic question. For continuous variables (X) killing the
> > > intercept in the random part kills the correlation between random
> > > effects (intercepts and slopes):
> > >
> > > (0 + X | ID)
> > >
> > > But for categorical variables (CAT) killing the intercept actually
> > > allows for all levels of CAT (including the reference level) to be
> > > correlated that is:
> > >
> > > (0 + CAT | ID) estimates more correlations than (CAT | ID)
> > >
> > > Am I correct?
> > >
> > > Thanks,
> > > Tim M
> > >
> > > _______________________________________________
> > > R-sig-mixed-models at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > >


From @|m@h@rme| @end|ng |rom gm@||@com  Wed Oct  6 07:43:58 2021
From: @|m@h@rme| @end|ng |rom gm@||@com (Simon Harmel)
Date: Wed, 6 Oct 2021 00:43:58 -0500
Subject: [R-sig-ME] Comparing two models with different sample sizes
Message-ID: <CACgv6yW-+-as0iGvSe01oHYYuuqpkWi+hLmBQ30OHQ5sh3rjeQ@mail.gmail.com>

Dear Colleagues,

I had to remove three extremely outlying (in terms of residuals, cook's
distances, and hat values) observations from my model.

Now, can I compare the fit of my initial model that has three more
observations with my outlier-corrected model using AICc?

Thanks,
Simon

	[[alternative HTML version deleted]]


From th|erry@onke||nx @end|ng |rom |nbo@be  Wed Oct  6 09:24:25 2021
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Wed, 6 Oct 2021 09:24:25 +0200
Subject: [R-sig-ME] Comparing two models with different sample sizes
In-Reply-To: <CACgv6yW-+-as0iGvSe01oHYYuuqpkWi+hLmBQ30OHQ5sh3rjeQ@mail.gmail.com>
References: <CACgv6yW-+-as0iGvSe01oHYYuuqpkWi+hLmBQ30OHQ5sh3rjeQ@mail.gmail.com>
Message-ID: <CAJuCY5w0xF9b4pxU8rUFcv-mare36y-kaekpeGKBA7wOm_Na4Q@mail.gmail.com>

No. The likelihood of a model is given the data. Only compare models based
on the same data. Therefore make sure there are no missing values in the
covariates when comparing models. When na.action = na.omit the model will
silently ignore observations with missing values a covariate.

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op wo 6 okt. 2021 om 07:44 schreef Simon Harmel <sim.harmel at gmail.com>:

> Dear Colleagues,
>
> I had to remove three extremely outlying (in terms of residuals, cook's
> distances, and hat values) observations from my model.
>
> Now, can I compare the fit of my initial model that has three more
> observations with my outlier-corrected model using AICc?
>
> Thanks,
> Simon
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From ykoo1 @end|ng |rom umbc@edu  Wed Oct  6 17:51:44 2021
From: ykoo1 @end|ng |rom umbc@edu (Isaac Kookhyun Yoo)
Date: Wed, 6 Oct 2021 11:51:44 -0400
Subject: [R-sig-ME] "pdCompSymm" function in R package "nlme"
Message-ID: <CAO_UFABE3v+LUjnx5puh-4Kj9mbqhD+HpvEoWK8tCv89icVSZA@mail.gmail.com>

Dear all,

I am a graduate student. I have a question about pdCompSymm.
pdCompSymm can be used for compound symmetry matrix only (All the variances
are equal and all the covariances are equal.)

Are there any functions for unequal variances or unequal covariances matrix?

Thank you in advance.

Isaac

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Wed Oct  6 18:09:49 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Wed, 6 Oct 2021 12:09:49 -0400
Subject: [R-sig-ME] "pdCompSymm" function in R package "nlme"
In-Reply-To: <CAO_UFABE3v+LUjnx5puh-4Kj9mbqhD+HpvEoWK8tCv89icVSZA@mail.gmail.com>
References: <CAO_UFABE3v+LUjnx5puh-4Kj9mbqhD+HpvEoWK8tCv89icVSZA@mail.gmail.com>
Message-ID: <67580e7b-efe7-29b0-f9e3-42919494590b@gmail.com>

   Here are the available matrix classes available in nlme:

library(nlme)
apropos("^pd[^f]")
  [1] "pdBlocked"   "pdCompSymm"  "pdConstruct" "pdDiag"      "pdIdent"
  [6] "pdLogChol"   "pdMat"       "pdMatrix"    "pdNatural"   "pdSymm"

?pdClasses


  Unfortunately, I don't think there's anything useful in there:

pdIdent is a multiple of the identity matrix, pdDiag is (heterogeneous) 
diagonal.

I believe pdNatural, pdLogChol, pdSymm represent different 
parameterizations for the general positive-definite ("unstructured") 
correlation matrix.

   So "equal correlations but heterogeneous variances" doesn't appear to 
be an option.

   The MCMCglmm package has more options.
   glmmTMB offers a 'heterogeneous compound symmetric" but *not* (at 
present) a *homogeneous compound symmetric" option (although that could 
be achieved without too much difficulty by using the 'map' parameter to 
set some parameters equal ...)

On 10/6/21 11:51 AM, Isaac Kookhyun Yoo wrote:
> Dear all,
> 
> I am a graduate student. I have a question about pdCompSymm.
> pdCompSymm can be used for compound symmetry matrix only (All the variances
> are equal and all the covariances are equal.)
> 
> Are there any functions for unequal variances or unequal covariances matrix?
> 
> Thank you in advance.
> 
> Isaac
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

-- 
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
Graduate chair, Mathematics & Statistics


From dong|w17 @end|ng |rom |zu@edu@cn  Fri Oct  8 13:11:21 2021
From: dong|w17 @end|ng |rom |zu@edu@cn (=?UTF-8?B?6JGj6b6Z5Lyf?=)
Date: Fri, 8 Oct 2021 19:11:21 +0800 (GMT+08:00)
Subject: [R-sig-ME] QUESTIONS ABOUT MIXED-LINEAR MODELS
Message-ID: <31684f57.143c5.17c5f99b5b8.Coremail.donglw17@lzu.edu.cn>

Dear friends

Hope you are in good health. Recently, I want to calculate the parameters and effect size of the random effect from the the mixed-linear models. I am still confused about the the parameters and effect size by using the R software. Would you give me some help?
Best wishes to you and your team.

Longwei

	[[alternative HTML version deleted]]


From @|m@h@rme| @end|ng |rom gm@||@com  Fri Oct  8 23:32:59 2021
From: @|m@h@rme| @end|ng |rom gm@||@com (Simon Harmel)
Date: Fri, 8 Oct 2021 16:32:59 -0500
Subject: [R-sig-ME] Why || doesn't zero out the correlations in lmer
Message-ID: <CACgv6yWY1MhqZ61mQO-BJLyJZwLdW60S+tx_FN+DtfMbtF0t+w@mail.gmail.com>

Dear Colleagues,

I have a 'factor' predictor called 'type' (with 4 levels). In the
random part, I have used `||` so the levels of 'type' can't correlate
with each other.

But I wonder why still correlations are reported in the output?
Thanks, Simon

lmer(y~type + (type || ID), data = data)

Random effects:
 Groups   Name  Std.Dev. Corr
 ID     type0 0.4276
          type1 0.7012   0.81
          type2 0.7115   0.72 0.97
          type3 0.7655   0.83 1.00 0.98


From me @end|ng |rom ph||||p@|d@y@com  Fri Oct  8 23:46:24 2021
From: me @end|ng |rom ph||||p@|d@y@com (Phillip Alday)
Date: Fri, 8 Oct 2021 16:46:24 -0500
Subject: [R-sig-ME] Why || doesn't zero out the correlations in lmer
In-Reply-To: <CACgv6yWY1MhqZ61mQO-BJLyJZwLdW60S+tx_FN+DtfMbtF0t+w@mail.gmail.com>
References: <CACgv6yWY1MhqZ61mQO-BJLyJZwLdW60S+tx_FN+DtfMbtF0t+w@mail.gmail.com>
Message-ID: <1a3e04f2-d028-edac-cd47-03ef9beb70e2@phillipalday.com>

This is a well-documented issue: || doesn't zero correlations between a
categorical variable's levels. As far as I know, there are
software-development/technical reasons for this, not statistical ones.

The afex package has an implementation that zeroes everything out.

On 8/10/21 4:32 pm, Simon Harmel wrote:
> Dear Colleagues,
> 
> I have a 'factor' predictor called 'type' (with 4 levels). In the
> random part, I have used `||` so the levels of 'type' can't correlate
> with each other.
> 
> But I wonder why still correlations are reported in the output?
> Thanks, Simon
> 
> lmer(y~type + (type || ID), data = data)
> 
> Random effects:
>  Groups   Name  Std.Dev. Corr
>  ID     type0 0.4276
>           type1 0.7012   0.81
>           type2 0.7115   0.72 0.97
>           type3 0.7655   0.83 1.00 0.98
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From @|m@h@rme| @end|ng |rom gm@||@com  Sat Oct  9 00:07:08 2021
From: @|m@h@rme| @end|ng |rom gm@||@com (Simon Harmel)
Date: Fri, 8 Oct 2021 17:07:08 -0500
Subject: [R-sig-ME] Why || doesn't zero out the correlations in lmer
In-Reply-To: <1a3e04f2-d028-edac-cd47-03ef9beb70e2@phillipalday.com>
References: <CACgv6yWY1MhqZ61mQO-BJLyJZwLdW60S+tx_FN+DtfMbtF0t+w@mail.gmail.com>
 <1a3e04f2-d028-edac-cd47-03ef9beb70e2@phillipalday.com>
Message-ID: <CACgv6yWC0JeyQAa5T0wLKj9mH1HpiOeHTVu2BEOjqn+Y8dBTpw@mail.gmail.com>

Thank you, this is extremely helpful to know. You mentioned it's well
documented, any possible links to share?

Also, does nlme::lme() behave in the same manner in this regard?

On Fri, Oct 8, 2021 at 4:46 PM Phillip Alday <me at phillipalday.com> wrote:
>
> This is a well-documented issue: || doesn't zero correlations between a
> categorical variable's levels. As far as I know, there are
> software-development/technical reasons for this, not statistical ones.
>
> The afex package has an implementation that zeroes everything out.
>
> On 8/10/21 4:32 pm, Simon Harmel wrote:
> > Dear Colleagues,
> >
> > I have a 'factor' predictor called 'type' (with 4 levels). In the
> > random part, I have used `||` so the levels of 'type' can't correlate
> > with each other.
> >
> > But I wonder why still correlations are reported in the output?
> > Thanks, Simon
> >
> > lmer(y~type + (type || ID), data = data)
> >
> > Random effects:
> >  Groups   Name  Std.Dev. Corr
> >  ID     type0 0.4276
> >           type1 0.7012   0.81
> >           type2 0.7115   0.72 0.97
> >           type3 0.7655   0.83 1.00 0.98
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >


From ji@verissimo m@iii@g oii gm@ii@com  Sat Oct  9 01:01:46 2021
From: ji@verissimo m@iii@g oii gm@ii@com (ji@verissimo m@iii@g oii gm@ii@com)
Date: Sat, 09 Oct 2021 00:01:46 +0100
Subject: [R-sig-ME] Why || doesn't zero out the correlations in lmer
In-Reply-To: <CACgv6yWC0JeyQAa5T0wLKj9mH1HpiOeHTVu2BEOjqn+Y8dBTpw@mail.gmail.com>
References: <CACgv6yWY1MhqZ61mQO-BJLyJZwLdW60S+tx_FN+DtfMbtF0t+w@mail.gmail.com>
 <1a3e04f2-d028-edac-cd47-03ef9beb70e2@phillipalday.com>
 <CACgv6yWC0JeyQAa5T0wLKj9mH1HpiOeHTVu2BEOjqn+Y8dBTpw@mail.gmail.com>
Message-ID: <9ee31082e6c906cf74124822dc541933b72ee41e.camel@gmail.com>

You can also convert your factor to (three) numerical predictors,
according to its contrasts.
In that case, the double bar will remove the correlation parameters.

This is well explained by Reinhold Kliegl here:
https://rpubs.com/Reinhold/22193
Jo?o
On Fri, 2021-10-08 at 17:07 -0500, Simon Harmel wrote:
> Thank you, this is extremely helpful to know. You mentioned it's
> welldocumented, any possible links to share?
> Also, does nlme::lme() behave in the same manner in this regard?
> On Fri, Oct 8, 2021 at 4:46 PM Phillip Alday <me at phillipalday.com>
> wrote:
> > This is a well-documented issue: || doesn't zero correlations
> > between acategorical variable's levels. As far as I know, there
> > aresoftware-development/technical reasons for this, not statistical
> > ones.
> > The afex package has an implementation that zeroes everything out.
> > On 8/10/21 4:32 pm, Simon Harmel wrote:
> > > Dear Colleagues,
> > > I have a 'factor' predictor called 'type' (with 4 levels). In
> > > therandom part, I have used `||` so the levels of 'type' can't
> > > correlatewith each other.
> > > But I wonder why still correlations are reported in the
> > > output?Thanks, Simon
> > > lmer(y~type + (type || ID), data = data)
> > > Random effects: Groups   Name  Std.Dev. Corr ID     type0
> > > 0.4276          type1 0.7012   0.81          type2 0.7115   0.72
> > > 0.97          type3 0.7655   0.83 1.00 0.98
> > > _______________________________________________R-sig-mixed-
> > > models at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > > 
> 
> _______________________________________________R-sig-mixed-models at r-
> project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From me @end|ng |rom ph||||p@|d@y@com  Sat Oct  9 05:46:48 2021
From: me @end|ng |rom ph||||p@|d@y@com (Phillip Alday)
Date: Fri, 8 Oct 2021 22:46:48 -0500
Subject: [R-sig-ME] Why || doesn't zero out the correlations in lmer
In-Reply-To: <CACgv6yWC0JeyQAa5T0wLKj9mH1HpiOeHTVu2BEOjqn+Y8dBTpw@mail.gmail.com>
References: <CACgv6yWY1MhqZ61mQO-BJLyJZwLdW60S+tx_FN+DtfMbtF0t+w@mail.gmail.com>
 <1a3e04f2-d028-edac-cd47-03ef9beb70e2@phillipalday.com>
 <CACgv6yWC0JeyQAa5T0wLKj9mH1HpiOeHTVu2BEOjqn+Y8dBTpw@mail.gmail.com>
Message-ID: <d82cee35-5181-6ff9-331e-8f0e69196258@phillipalday.com>


On 10/8/21 17:07, Simon Harmel wrote:
> Thank you, this is extremely helpful to know. You mentioned it's well
> documented, any possible links to share?

The lme4 documentation, e.g.

https://www.rdocumentation.org/packages/lme4/versions/1.1-27.1/topics/lmer

> (Because of the way it is implemented, the ||||-syntax /works only for
> design matrices containing numeric (continuous) predictors/; to fit
> models with independent categorical effects, see |dummy
> <https://www.rdocumentation.org/link/dummy?package=lme4&version=1.1-27.1>|
> or the |lmer_alt| function from the afex package.)

> Also, does nlme::lme() behave in the same manner in this regard?

I am unaware of nlme supporting the double-bar syntax at all, but
specifing the correlation structure to be diagonal (pdDiagonal? it's
been a while) will force all correlations to zero.


>
> On Fri, Oct 8, 2021 at 4:46 PM Phillip Alday <me at phillipalday.com> wrote:
>> This is a well-documented issue: || doesn't zero correlations between a
>> categorical variable's levels. As far as I know, there are
>> software-development/technical reasons for this, not statistical ones.
>>
>> The afex package has an implementation that zeroes everything out.
>>
>> On 8/10/21 4:32 pm, Simon Harmel wrote:
>>> Dear Colleagues,
>>>
>>> I have a 'factor' predictor called 'type' (with 4 levels). In the
>>> random part, I have used `||` so the levels of 'type' can't correlate
>>> with each other.
>>>
>>> But I wonder why still correlations are reported in the output?
>>> Thanks, Simon
>>>
>>> lmer(y~type + (type || ID), data = data)
>>>
>>> Random effects:
>>>  Groups   Name  Std.Dev. Corr
>>>  ID     type0 0.4276
>>>           type1 0.7012   0.81
>>>           type2 0.7115   0.72 0.97
>>>           type3 0.7655   0.83 1.00 0.98
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>


From @|m@h@rme| @end|ng |rom gm@||@com  Sat Oct  9 05:48:53 2021
From: @|m@h@rme| @end|ng |rom gm@||@com (Simon Harmel)
Date: Fri, 8 Oct 2021 22:48:53 -0500
Subject: [R-sig-ME] Why || doesn't zero out the correlations in lmer
In-Reply-To: <d82cee35-5181-6ff9-331e-8f0e69196258@phillipalday.com>
References: <CACgv6yWY1MhqZ61mQO-BJLyJZwLdW60S+tx_FN+DtfMbtF0t+w@mail.gmail.com>
 <1a3e04f2-d028-edac-cd47-03ef9beb70e2@phillipalday.com>
 <CACgv6yWC0JeyQAa5T0wLKj9mH1HpiOeHTVu2BEOjqn+Y8dBTpw@mail.gmail.com>
 <d82cee35-5181-6ff9-331e-8f0e69196258@phillipalday.com>
Message-ID: <CACgv6yW2NAmPgwxis5QU_8GhB=t=r5xS83WK05kAd09r9K4YJA@mail.gmail.com>

Thank you all for the informative comments.

Simon

On Fri, Oct 8, 2021 at 10:46 PM Phillip Alday <me at phillipalday.com> wrote:
>
>
> On 10/8/21 17:07, Simon Harmel wrote:
> > Thank you, this is extremely helpful to know. You mentioned it's well
> > documented, any possible links to share?
>
> The lme4 documentation, e.g.
>
> https://www.rdocumentation.org/packages/lme4/versions/1.1-27.1/topics/lmer
>
> > (Because of the way it is implemented, the ||||-syntax /works only for
> > design matrices containing numeric (continuous) predictors/; to fit
> > models with independent categorical effects, see |dummy
> > <https://www.rdocumentation.org/link/dummy?package=lme4&version=1.1-27.1>|
> > or the |lmer_alt| function from the afex package.)
>
> > Also, does nlme::lme() behave in the same manner in this regard?
>
> I am unaware of nlme supporting the double-bar syntax at all, but
> specifing the correlation structure to be diagonal (pdDiagonal? it's
> been a while) will force all correlations to zero.
>
>
> >
> > On Fri, Oct 8, 2021 at 4:46 PM Phillip Alday <me at phillipalday.com> wrote:
> >> This is a well-documented issue: || doesn't zero correlations between a
> >> categorical variable's levels. As far as I know, there are
> >> software-development/technical reasons for this, not statistical ones.
> >>
> >> The afex package has an implementation that zeroes everything out.
> >>
> >> On 8/10/21 4:32 pm, Simon Harmel wrote:
> >>> Dear Colleagues,
> >>>
> >>> I have a 'factor' predictor called 'type' (with 4 levels). In the
> >>> random part, I have used `||` so the levels of 'type' can't correlate
> >>> with each other.
> >>>
> >>> But I wonder why still correlations are reported in the output?
> >>> Thanks, Simon
> >>>
> >>> lmer(y~type + (type || ID), data = data)
> >>>
> >>> Random effects:
> >>>  Groups   Name  Std.Dev. Corr
> >>>  ID     type0 0.4276
> >>>           type1 0.7012   0.81
> >>>           type2 0.7115   0.72 0.97
> >>>           type3 0.7655   0.83 1.00 0.98
> >>>
> >>> _______________________________________________
> >>> R-sig-mixed-models at r-project.org mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>>


From r@turner @end|ng |rom @uck|@nd@@c@nz  Sun Oct 10 10:35:14 2021
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Sun, 10 Oct 2021 21:35:14 +1300
Subject: [R-sig-ME] QUESTIONS ABOUT MIXED-LINEAR MODELS
In-Reply-To: <31684f57.143c5.17c5f99b5b8.Coremail.donglw17@lzu.edu.cn>
References: <31684f57.143c5.17c5f99b5b8.Coremail.donglw17@lzu.edu.cn>
Message-ID: <20211010213514.1beebce4@rolf-Latitude-E7470>

On Fri, 8 Oct 2021 19:11:21 +0800
??? <donglw17 at lzu.edu.cn> wrote:

> Dear friends
> 
> Hope you are in good health. Recently, I want to calculate the
> parameters and effect size of the random effect from the the
> mixed-linear models. I am still confused about the the parameters and
> effect size by using the R software. Would you give me some help?
> Best wishes to you and your team.
> 
> Longwei

This question is far too vague for anyone to have any hope of
formulating a useful reply.

cheers,

Rolf Turner

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From @@|v@dor@@nchezco|on @end|ng |rom prod|gy@net@mx  Sun Oct 10 17:40:43 2021
From: @@|v@dor@@nchezco|on @end|ng |rom prod|gy@net@mx (=?utf-8?Q?Salvador_S=C3=A1nchez-Col=C3=B3n?=)
Date: Sun, 10 Oct 2021 10:40:43 -0500
Subject: [R-sig-ME] QUESTIONS ABOUT MIXED-LINEAR MODELS
In-Reply-To: <31684f57.143c5.17c5f99b5b8.Coremail.donglw17@lzu.edu.cn>
References: <31684f57.143c5.17c5f99b5b8.Coremail.donglw17@lzu.edu.cn>
Message-ID: <03AFDC0B-90A3-42F3-8772-D700565A8100@prodigy.net.mx>

Hi Longwei,

I have found this reference extremely useful to understand Generalized Linear Mixed Models and their implementation in R:

https://www.springer.com/gp/book/9780387874579

Best regards,

Salvador 


> On 8 Oct 2021, at 8:27, ??? <donglw17 at lzu.edu.cn> wrote:
> 
> ?Dear friends
> 
> Hope you are in good health. Recently, I want to calculate the parameters and effect size of the random effect from the the mixed-linear models. I am still confused about the the parameters and effect size by using the R software. Would you give me some help?
> Best wishes to you and your team.
> 
> Longwei
> 
>    [[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From r@turner @end|ng |rom @uck|@nd@@c@nz  Sun Oct 10 22:36:32 2021
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Mon, 11 Oct 2021 09:36:32 +1300
Subject: [R-sig-ME] 
 QUESTIONS ABOUT THE PARAMETERS AND EFFECT SIZE OF THR
 RANDOM EFFECT IN MIXED LINEAR MODEL
In-Reply-To: <492f65a1.15766.17c69dd8027.Coremail.donglw17@lzu.edu.cn>
References: <31684f57.143c5.17c5f99b5b8.Coremail.donglw17@lzu.edu.cn>
 <20211010213514.1beebce4@rolf-Latitude-E7470>
 <492f65a1.15766.17c69dd8027.Coremail.donglw17@lzu.edu.cn>
Message-ID: <20211011093632.46bee0c7@rolf-Latitude-E7470>

On Sun, 10 Oct 2021 19:01:36 +0800
??? <donglw17 at lzu.edu.cn> wrote:

> Dear Rolf Turner and other friends
> 
> Thank you for friendly help, and sorry for the vague expression.
> I build the mixed linear model using the lme4, for example
> 
> f1 =lmer(y~x1+x2+x3+(1|r1)+(1|r2),data = dat)
> Note: x1, x2 and x3 are fixed factors, r1 and r2 is the random
> factors. the code and the data been loaded as an attachment
> 
> My questions is how to calculate the parameters and effect size of
> the random effect (r1 and r2). Best wishes to you.

Random effects are not parameters; they are (as the name would imply)
random variables.   The ranef()  function from lme4 will extract the
modes of the instances of these random variables, associated with your
model.  The function VarCorr() will provide estimates of the standard
deviations of these random variables.

I know next to nothing about effect sizes, so I do not have the
expertise to explore your question any further.  Others on
the r-sig-mixed-models list will have such expertise, but unfortunately
the attachment that you sent will not have gone through to the list.
The list mail-handler strips most attachments from email (as a security
measure.

Moreover the "code and result.txt" file in the zip archive that I
received was empty --- which is not much use.

Instead of a zip archive you should send your data and code as separate
text files (with a .txt extension) --- these should go through.  Or you
could simply include your code in the body of the email, and include
the data as well (as long as the data set is not too huge), using
dput().

cheers,

Rolf Turner

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From @reedt@8 @end|ng |rom gm@||@com  Mon Oct 11 04:25:04 2021
From: @reedt@8 @end|ng |rom gm@||@com (sree datta)
Date: Sun, 10 Oct 2021 22:25:04 -0400
Subject: [R-sig-ME] QUESTIONS ABOUT MIXED-LINEAR MODELS
In-Reply-To: <03AFDC0B-90A3-42F3-8772-D700565A8100@prodigy.net.mx>
References: <31684f57.143c5.17c5f99b5b8.Coremail.donglw17@lzu.edu.cn>
 <03AFDC0B-90A3-42F3-8772-D700565A8100@prodigy.net.mx>
Message-ID: <CAHftDbjRkhY5n9GXEV2Eq6S3w3wapbF1amOePUq+L0qSr4obbA@mail.gmail.com>

Hi

Please see the link below about fitting Linear Mixed Effects models in R
using "lme4" package by Doublas Bates, the author of "lme4".

http://mirrors.nics.utk.edu/cran/web/packages/lme4/vignettes/lmer.pdf

Another nice conceptual introduction / tutorial on linear mixed effects by
Bodo Winter using "lme4" in R:

https://jontalle.web.engr.illinois.edu/MISC/lme4/bw_LME_tutorial.pdf



On Sun, Oct 10, 2021 at 11:41 AM Salvador S?nchez-Col?n <
salvadorsanchezcolon at prodigy.net.mx> wrote:

> Hi Longwei,
>
> I have found this reference extremely useful to understand Generalized
> Linear Mixed Models and their implementation in R:
>
> https://www.springer.com/gp/book/9780387874579
>
> Best regards,
>
> Salvador
>
>
> > On 8 Oct 2021, at 8:27, ??? <donglw17 at lzu.edu.cn> wrote:
> >
> > ?Dear friends
> >
> > Hope you are in good health. Recently, I want to calculate the
> parameters and effect size of the random effect from the the mixed-linear
> models. I am still confused about the the parameters and effect size by
> using the R software. Would you give me some help?
> > Best wishes to you and your team.
> >
> > Longwei
> >
> >    [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From g@ngchen6 @end|ng |rom gm@||@com  Mon Oct 11 13:27:07 2021
From: g@ngchen6 @end|ng |rom gm@||@com (Gang Chen)
Date: Mon, 11 Oct 2021 07:27:07 -0400
Subject: [R-sig-ME] Recovering correlations
Message-ID: <CAHmzXO5a6nQnST-zMS=ypNr9m3Fe=iRdnWVb+-YCc6Esixws6Q@mail.gmail.com>

I'm trying to recover the correlations in a multivariate dataset. Let me
first start with a trivariate case.

require(MASS); require(lme4)

# trivariate case

r1 <- 0.5               # correlation value to be recovered

ns <- 200               # number of samples

S1 <- matrix(c(1,r1,0,  # correlation structure of trivariate data

               r1,1,0,

               0,0,1), nrow=3, ncol=3)

# simulated trivariate data

dat <- data.frame(f = c(rep(paste0('P',1:ns), 2), paste0('S',1:ns)),

                  y = c(mvrnorm(n=ns, mu=c(0, 0, 0), Sigma=S1)))


Now I can construct the following model


m1 <- lmer(y ~ 1 + (1|f), data=dat)


Then with the variances from the random effects in summary(m1)


summary(m1)


Random effects:

 Groups   Name        Variance Std.Dev.

 f        (Intercept) 0.4996   0.7068

 Residual             0.4907   0.7005


I can recover the correlation r1:


tmp <- unlist(lapply(VarCorr(m1), `[`, 1))

# recover the correlation r1

tmp/(tmp+attr(VarCorr(m1), "sc")^2)


Let's switch to a pentavariate case:

# pentavariate case

r1 <- 0.2; r2 <- 0.8        # correlation value to be recovered

ns <- 200                   # number of samples

S  <- matrix(c(1,r1,0,0,0,  # correlation structure of pentavariate data

               r1,1,0,0,0,  # the first and second variables are correlated

               0,0,1,r2,0,  # the third and fourth variables are correlated

               0,0,r2,1,0,

               0,0,0,0,1), nrow=5,ncol=5)

# simulated data

dat <- data.frame(f = c(rep(paste0('P',1:ns), 2), rep(paste0('T',1:ns), 2),
paste0('S',1:ns)),

                  R=c(rep('P',2*ns), rep('T',2*ns), rep('S', ns)),

                  y = c(mvrnorm(n=ns, mu=rep(0,5), Sigma=S)))

dat$R1 <- as.numeric(dat$R=='P')   # dummy code the first and second
variables (r1)

dat$R2 <- as.numeric(dat$R=='T')   # dummy code the third and fourth
variables (r2)

I have thought about the following models

m2 <- lmer(y ~ 1 + (0+R1|f) + (0+R2|f), data=dat)

m3 <- lmer(y ~ 1 + (1|f) + (0+R2|f), data=dat)

but I've been struggling to figure out a way to recover the correlations r1
and r2 with the variances from the random effects based on the models m2
and m3.

Of course I could use a workaround solution by reducing the
pentavariate data into two trivariate cases:

# workaround solution

m4 <- lmer(y ~ 1 + (1|f), data=dat[dat$R2!=1,]) # recover r1 like model m1
above

m5 <- lmer(y ~ 1 + (1|f), data=dat[dat$R1!=1,]) # recover r2 like model m1
above

However, I would really like to find a way to recover r1 and r2 directly
using models like m2 and m3. Suggestions?

Thanks,
Gang Chen

	[[alternative HTML version deleted]]


From j@v|ermore|r@ @end|ng |rom gm@||@com  Tue Oct 12 01:18:05 2021
From: j@v|ermore|r@ @end|ng |rom gm@||@com (Javier Moreira)
Date: Mon, 11 Oct 2021 20:18:05 -0300
Subject: [R-sig-ME] comparing GLS residuals with lme +
 correlation=corExp(form=~1, nugget=T) residuals
Message-ID: <CAEyHP-1P4EbOWwCCVbi2azWJ256DBLD6Ah-UK4vFNDN72e2fnw@mail.gmail.com>

hi,
i'm trying to make a comparison between a series of models, and I'm trying
to understand how to find the autocorrelation that the lme + correlation
model removed.
Is the solution to just use type="normalized"? if I do this I'm getting the
final residuals ( with the already subtract spatial ) or the residuals
without considering spatial autocorrelation?

if anybody has struggled with the same, I could use some help.
thanks a lot!
great forum!

greatings

-- 
Javier Moreira de Souza
Ingeniero Agr?nomo
099 406 006

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Tue Oct 12 01:28:22 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Mon, 11 Oct 2021 19:28:22 -0400
Subject: [R-sig-ME] comparing GLS residuals with lme +
 correlation=corExp(form=~1, nugget=T) residuals
In-Reply-To: <CAEyHP-1P4EbOWwCCVbi2azWJ256DBLD6Ah-UK4vFNDN72e2fnw@mail.gmail.com>
References: <CAEyHP-1P4EbOWwCCVbi2azWJ256DBLD6Ah-UK4vFNDN72e2fnw@mail.gmail.com>
Message-ID: <4c35c0b0-eec1-ecc2-b9a8-eadaf1c59f7e@gmail.com>

    Yes, that should be correct. type="normalized" should get you the 
residuals corrected for autocorrelation and heteroscedasticity (if it's 
in the model).  A lot of people (including me!) routinely get confused 
because the default residuals are "response" (i.e. accounting for 
neither heterosced. nor correlation).

On 10/11/21 7:18 PM, Javier Moreira wrote:
> hi,
> i'm trying to make a comparison between a series of models, and I'm trying
> to understand how to find the autocorrelation that the lme + correlation
> model removed.
> Is the solution to just use type="normalized"? if I do this I'm getting the
> final residuals ( with the already subtract spatial ) or the residuals
> without considering spatial autocorrelation?
> 
> if anybody has struggled with the same, I could use some help.
> thanks a lot!
> great forum!
> 
> greatings
>


From zengd|@eed @end|ng |rom gm@||@com  Fri Oct 22 03:32:00 2021
From: zengd|@eed @end|ng |rom gm@||@com (Di Zeng)
Date: Thu, 21 Oct 2021 18:32:00 -0700
Subject: [R-sig-ME] Predictor standardized transformation in GLMM
Message-ID: <CAOtvA4td_=VyD1YtWkf_56-_LAvR2uK8kGmKjejro4AJyGze5A@mail.gmail.com>

Dear all,

My colleagues and I have a question when we use the generalized linear
mixed models to analyze our data:

# Creating an example dataset

group <- factor(c('A','A','A','B','B','C','D'))#Random effects
y <- c(1:7)
x1 <- c(6,6,6,5,5,4,3)
x2 <- c(11,11,11,5,5,6,8)


Because the predictors (x1, x2) have different units, we need to
standardize them before running our models. There are two ways to conduct
this standardized transformation.

First, standardizing x1, x2 directly, like:

scale(dt$x1)
scale(dt$x2)

Second, standardizing x1, x2 based on unique group, like:

scale(unique(dt$x1))
scale(unique(dt$x2))


We wonder which way is reasonable? In my own idea, we should use the second
one. Because data points in the same group are non-independent replication
in read dataset.

Could you mind giving us some suggestions or ideas on this problem?

Thanks very much,

Di

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Fri Oct 22 03:44:20 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Thu, 21 Oct 2021 21:44:20 -0400
Subject: [R-sig-ME] Predictor standardized transformation in GLMM
In-Reply-To: <CAOtvA4td_=VyD1YtWkf_56-_LAvR2uK8kGmKjejro4AJyGze5A@mail.gmail.com>
References: <CAOtvA4td_=VyD1YtWkf_56-_LAvR2uK8kGmKjejro4AJyGze5A@mail.gmail.com>
Message-ID: <a0f0335a-a983-3e0f-e20f-e52858638013@gmail.com>

   The first way is more standard and makes more sense to me.

   Note that standardizing variables doesn't make any difference to the 
*statistical* results; it may improve the computational stability of the 
model, and it definitely changes the interpretation of the parameters.

   I understand the meaning of the parameters in the first case: "what 
is the expected change in log-odds of the outcome for a 1-SD change in 
predictor x1, holding everything else fixed"?  I'm not so sure how I 
would interpret "1 SD of the unique values of x1", but if you can (and 
can explain it!), and that version makes more sense, then you should go 
ahead and use it.

   The structure of your example seems a bit odd -- is this a nested 
design, i.e. the predictors only vary across levels of the 
random-effects grouping factor, not within them?  In that case (if your 
real data follow the same structure), you would probably be better 
collapsing the values rather than dealing with the complexities of a 
random-effect linear regression - in other words,

   y <- c(mean(1:3), mean(4:5), 6, 7)
   x1 <- c(6,5,4,3)
   x2 <- c(11, 5, 6, 8)

lm(y~x1 + x2, weights=c(3,2,1,1))

  (see Murtaugh, "Simplicity and complexity in ecological data analysis")

On 10/21/21 9:32 PM, Di Zeng wrote:
> Dear all,
> 
> My colleagues and I have a question when we use the generalized linear
> mixed models to analyze our data:
> 
> # Creating an example dataset
> 
> group <- factor(c('A','A','A','B','B','C','D'))#Random effects
> y <- c(1:7)
> x1 <- c(6,6,6,5,5,4,3)
> x2 <- c(11,11,11,5,5,6,8)
> 
> 
> Because the predictors (x1, x2) have different units, we need to
> standardize them before running our models. There are two ways to conduct
> this standardized transformation.
> 
> First, standardizing x1, x2 directly, like:
> 
> scale(dt$x1)
> scale(dt$x2)
> 
> Second, standardizing x1, x2 based on unique group, like:
> 
> scale(unique(dt$x1))
> scale(unique(dt$x2))
> 
> 
> We wonder which way is reasonable? In my own idea, we should use the second
> one. Because data points in the same group are non-independent replication
> in read dataset.
> 
> Could you mind giving us some suggestions or ideas on this problem?
> 
> Thanks very much,
> 
> Di
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

-- 
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
Graduate chair, Mathematics & Statistics


From zengd|@eed @end|ng |rom gm@||@com  Sat Oct 23 04:34:57 2021
From: zengd|@eed @end|ng |rom gm@||@com (Di Zeng)
Date: Sat, 23 Oct 2021 02:34:57 +0000
Subject: [R-sig-ME] Predictor standardized transformation in GLMM
In-Reply-To: <mailman.19458.9.1634896802.54623.r-sig-mixed-models@r-project.org>
References: <mailman.19458.9.1634896802.54623.r-sig-mixed-models@r-project.org>
Message-ID: <CAOtvA4vAypjVQf4OBZeEof1W=e+vRpDik4eCTdmmthrCsgsndA@mail.gmail.com>

Hi?Dr. Benjamin Bolker,

I got it.

Thanks so much for your ideas and suggestions.

Cheers,

Di


> ------------------------------
>
> Message: 2
> Date: Thu, 21 Oct 2021 21:44:20 -0400
> From: Ben Bolker
> To: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Predictor standardized transformation in GLMM
> Message-ID:
> Content-Type: text/plain; charset="utf-8"; Format="flowed"
>
> The first way is more standard and makes more sense to me.
>
> Note that standardizing variables doesn't make any difference to the
> *statistical* results; it may improve the computational stability of the
> model, and it definitely changes the interpretation of the parameters.
>
> I understand the meaning of the parameters in the first case: "what
> is the expected change in log-odds of the outcome for a 1-SD change in
> predictor x1, holding everything else fixed"? I'm not so sure how I
> would interpret "1 SD of the unique values of x1", but if you can (and
> can explain it!), and that version makes more sense, then you should go
> ahead and use it.
>
> The structure of your example seems a bit odd -- is this a nested
> design, i.e. the predictors only vary across levels of the
> random-effects grouping factor, not within them? In that case (if your
> real data follow the same structure), you would probably be better
> collapsing the values rather than dealing with the complexities of a
> random-effect linear regression - in other words,
>
> y <- c(mean(1:3), mean(4:5), 6, 7)
> x1 <- c(6,5,4,3)
> x2 <- c(11, 5, 6, 8)
>
> lm(y~x1 + x2, weights=c(3,2,1,1))
>
> (see Murtaugh, "Simplicity and complexity in ecological data analysis?)
>
>
> --
> Dr. Benjamin Bolker
> Professor, Mathematics & Statistics and Biology, McMaster University
> Director, School of Computational Science and Engineering
> Graduate chair, Mathematics & Statistics
>
>
>
>
> ------------------------------
>
> Subject: Digest Footer
>
> _______________________________________________
> R-sig-mixed-models mailing list
> R-sig-mixed-models at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
> ------------------------------
>
> End of R-sig-mixed-models Digest, Vol 178, Issue 12
> ***************************************************
>


From o||verhooker @end|ng |rom pr@t@t|@t|c@@com  Tue Oct 26 16:12:57 2021
From: o||verhooker @end|ng |rom pr@t@t|@t|c@@com (Oliver Hooker)
Date: Tue, 26 Oct 2021 15:12:57 +0100
Subject: [R-sig-ME] Model selection and model simplification (MSMS02)
Message-ID: <CAEsSYzxisxKLuhnesCeDsciC_9hwm+gOf+WW0P+yiUyfhx8LMQ@mail.gmail.com>

Model selection and model simplification (MSMS02)

https://www.prstatistics.com/course/model-selection-and-model-simplification-msms02/
24 November 2021 - 25 November 2021
Course Overview:

This two day course covers the important and general topics of statistical
model building, model evaluation, model selection, model comparison, model
simplification, and model averaging. These topics are vitally important to
almost every type of statistical analysis, yet these topics are often
poorly or incompletely understood. We begin by considering the fundamental
issue of how to measure model fit and a model?s predictive performance, and
discuss a wide range of other major model fit measurement concepts like
likelihood, log likelihood, deviance, residual sums of squares etc. We then
turn to nested model comparison, particularly in general and generalized
linear models, and their mixed effects counterparts. We then consider the
key concept of out-of-sample predictive performance, and discuss
over-fitting or how excellent fits to the observed data can lead to very
poor generalization performance. As part of this discussion of
out-of-sample generalization, we introduce leave-one-out cross-validation
and Akaike Information Criterion (AIC). We then cover general concepts and
methods related to variable selection, including stepwise regression, ridge
regression, Lasso, and elastic nets. Following this, we turn to model
averaging, which is an arguably always preferable alternative to model
selection. Finally, we cover Bayesian methods of model comparison. Here, we
describe how Bayesian methods allow us to easily compare completely
distinct statistical models using a common metric. We also describe how
Bayesian methods allow us to fit all the candidate models of potential
interest, including cases were traditional methods fail.

THIS IS ONE COURSE IN OUR R SERIES ? LOOK OUT FOR COURSES WITH THE SAME
COURSE IMAGE TO FIND MORE IN THIS SERIES
Email oliverhooker at prstatistics.com with any questions
Up-coming courses

*GIS AND REMOTE SENSING ANALYSES WITH R (GARM01)*

Online (live and recorded) 14th February 2022 - 18th February 2022

?400 reduced from ?450

https://www.prstatistics.com/course/gis-and-remote-sensing-analyses-with-r-garm01/

*ADAPTING TO THE RECENT CHANGES IN R SPATIAL PACKAGES (SF, TERRA, PROJ
LIBRARY) (PROJ02)*

Online (live and recorded) 13th January 2022 - 14th January 2022

?275 reduced from ?300

https://www.prstatistics.com/course/adapting-to-the-recent-changes-in-r-spatial-packages-sf-terra-proj-library-proj02/


*BIOACOUSTICS FOR ECOLOGISTS: HARDWARE, SURVEY DESIGN AND DATA ANALYSIS
(BIAC02)*

Online (live and recorded) 22nd March 2022 - 24th March 2022

?280 reduced from ?350

https://www.prstatistics.com/course/bioacoustics-for-ecologists-hardware-survey-design-and-data-analysis-biac02/



*MULTIVARIATE ANALYSIS OF ECOLOGICAL COMMUNITIES IN R WITH THE VEGAN
PACKAGE (VGNR04)*

12th September 2022 - 16th September 2022

?400 reduced from ?480

https://www.prstatistics.com/course/multivariate-analysis-of-ecological-communities-in-r-with-the-vegan-package-vgnr04/



*TIME SERIES DATA ANALYSIS (TSDA01)*

Online (live and recorded) 14 December 2021 - 17 December 2021

?400 reduced from ?450

https://www.prstatistics.com/course/time-series-data-analysis-tsda01/



*STABLE ISOTOPE MIXING MODELS USING SIBER, SIAR, MIXSIAR (SIMM08)*

Online (live and recorded) 1st February 2022 - 4th February 2022

?430 reduced from ?480

https://www.prstatistics.com/course/stable-isotope-mixing-models-using-r-simm08/



*BAYESIAN DATA ANALYSIS (BADA01)*

Online (live and recorded) 10th January 2022 - 14th January 2022

?375 reduced from ?450

https://www.prstatistics.com/course/bayesian-data-analysis-bada01/



*INTRODUCTION TO STAN FOR BAYESIAN DATA ANALYSIS (ISBD01)*

Online (live and recorded) 18th January 2022 - 20th January 2022

?200 reduced from ?275.00

https://www.prstatistics.com/course/introduction-to-stan-for-bayesian-data-analysis-isbd01/



*MAKING BEAUTIFUL AND EFFECTIVE MAPS IN R (MAPR03)*

Online (live and recorded) 9th February 2022 - 10th February 2022

?275 reduced from ?300.00

https://www.prstatistics.com/course/making-beautiful-and-effective-maps-in-r-mapr03/

*ADVANCES IN SPATIAL ANALYSIS OF MULTIVARIATE ECOLOGICAL DATA: THEORY AND
PRACTICE (MVSP04)*

Online (pre-recorded with live support) 25th April 2022 - 29th April 2022

?375 reduced from ?400

https://www.prstatistics.com/course/advances-in-spatial-analysis-of-multivariate-ecological-data-theory-and-practice-mvsp04/



*FREE RECORDED 1 DAY INTRO TO R AND R STUDIO (FIRR01) *

Online (recorded) 29 October 2021

Free

https://www.prstatistics.com/course/free-1-day-intro-to-r-and-r-studio-firr01/



*INTRODUCTION TO GENERALISED LINEAR MODELS USING R AND RSTUDIO (IGLM04)*

Online (live and recorded) 3 November 2021 - 4 November 2021

?200 reduced from ?275.00

https://www.prstatistics.com/course/introduction-to-generalised-linear-models-using-r-and-rstudio-iglm04/

*INTRODUCTION TO MIXED MODELS USING R AND RSTUDIO (IMMR05)*

Online (live and recorded) 10 November 2021 - 11 November 2021

?200 reduced from ?275.00

https://www.prstatistics.com/course/introduction-to-mixed-models-using-r-and-rstudio-immr05/

*INTRODUCTION TO MACHINE LEARNING AND DEEP LEARNING USING R (IMDL02) *

Online (live and recorded) 17 November 2021 - 18 November 2021

?200 reduced from ?275.00

https://www.prstatistics.com/course/introduction-to-machine-learning-and-deep-learning-using-r-imdl02/

*MODEL SELECTION AND MODEL SIMPLIFICATION (MSMS02)*

Online (live and recorded) 24 November 2021 - 25 November 2021

?200 reduced from ?275.00

https://www.prstatistics.com/course/model-selection-and-model-simplification-msms02/



*SPECIES DISTRIBUTION MODELLING WITH BAYESIAN STATISTICS IN R (SDMB03)*

Online (live and recorded) 6 December 2021 - 10 December 2021

https://www.prstatistics.com/course/species-distribution-modelling-with-bayesian-statistics-in-r-sdmb03/



*SPECIES DISTRIBUTION MODELING USING R (SDMR04)*

Online (live and recorded) 2nd February 2022 - 10th February 2022

https://www.prstatistics.com/course/species-distribution-modeling-using-r-sdmr04/



*INTRODUCTION TO ECO-PHYLOGENETICS AND COMPARATIVE ANALYSES USING R
(ECPH01)*

Online (live and recorded) 7th February 2022 - 11th February 2022

https://www.prstatistics.com/course/introduction-to-eco-phylogenetics-and-comparative-analyses-using-r-ecph01/



*FUNCTIONAL ECOLOGY FROM ORGANISM TO ECOSYSTEM: THEORY AND COMPUTATION
(FEER02)*

Online (live and recorded) 5th September 2022 - 9th September 2022
https://www.prstatistics.com/course/functional-ecology-from-organism-to-ecosystem-theory-and-computation-feer02/
-- 

-- 
Oliver Hooker PhD.
PR statistics

	[[alternative HTML version deleted]]


From c|emen@@wu|||en @end|ng |rom gm@||@com  Sat Oct 30 14:47:23 2021
From: c|emen@@wu|||en @end|ng |rom gm@||@com (Clemens von Wulffen)
Date: Sat, 30 Oct 2021 14:47:23 +0200
Subject: [R-sig-ME] Power calculation three way interaction
Message-ID: <CAC41oroSZimN2U3hJmDZRJ7Wupgt9OvYo33owC1C-vddvqf2qA@mail.gmail.com>

Hello Team,

I was wondering if anyone here has an answer to my question:

I am conducting a *power calculation* to find the required sample size
for *binomial
GLMER *study.
Short description of experiment: Participants rate *120 statements* as *true
or false.* Half of the statements have been repeated previously (in an
exposure task). The subjects are placed into three groups (*1 control and 2
treatments* groups called: affect reattribution and fluency reattribution).
These groups also get additional information during the second phase (the
second 60 statements to be judged from the 120 overall). We are trying to
see now *if the varying additional information* given to the two
treatment groups* changes the likelihood to rate a statement as true in the
second phase.*

I have gained parameters for my simulation from a mixture of pilot data and
previous study (since pilot data only has a results for one group).

One of the aims of the study is to get results for a *three way interaction
between status of repetition (new or repeated), judgement phase (1 or 2),
and condition (group control, af-reat, and flu-reat). *

I was wondering now how and *if I need to specify the three way interaction
in any specific way for my power calculation other than simply plugging the
variables for IV's and for the random effects? *

glmer(dv ~ fluency_reat * status.t * judge.t +
                  affect_reat * status.t * judge.t  +
                  (1 | subj) + (1 | item) , data = data,
             family = binomial(link = "logit"))

for clarification: since there are three condition groups --> the formula
gets repeated for each treatment group.

I have my code attached to this email. I personally thought that I have
specified everything and can just run it, but my supervisor said I need to
specify the three way interaction previously. I just am  not sure how to.

If anyone has had this question before and has some thoughts on it, I would
highly appreciate it.

Cheers,

Clemens

From Ju||@n@G@v|r|@Lopez @end|ng |rom un|ge@ch  Sat Oct 30 21:21:21 2021
From: Ju||@n@G@v|r|@Lopez @end|ng |rom un|ge@ch (Julian Gaviria Lopez)
Date: Sat, 30 Oct 2021 19:21:21 +0000
Subject: [R-sig-ME] Power calculation three way interaction
In-Reply-To: <CAC41oroSZimN2U3hJmDZRJ7Wupgt9OvYo33owC1C-vddvqf2qA@mail.gmail.com>
References: <CAC41oroSZimN2U3hJmDZRJ7Wupgt9OvYo33owC1C-vddvqf2qA@mail.gmail.com>
Message-ID: <0553fea4785241ab851acde2a2c47e4b@unige.ch>

Hi Clemens,


The following tutorials might be helpful:


https://doi.org/10.1177/2515245920965119

https://doi.org/10.3758/s13428-021-01546-0


Hope it helps, best wishes.


Julian Gaviria
Neurology and Imaging of cognition lab (Labnic)
University of Geneva. Campus Biotech.
9 Chemin des Mines, 1202 Geneva, CH
Tel: +41 22 379 0380
Email: Julian.GaviriaLopez at unige.ch
________________________________
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of Clemens von Wulffen <clemens.wulffen at gmail.com>
Sent: Saturday, October 30, 2021 2:47:23 PM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] Power calculation three way interaction

Hello Team,

I was wondering if anyone here has an answer to my question:

I am conducting a *power calculation* to find the required sample size
for *binomial
GLMER *study.
Short description of experiment: Participants rate *120 statements* as *true
or false.* Half of the statements have been repeated previously (in an
exposure task). The subjects are placed into three groups (*1 control and 2
treatments* groups called: affect reattribution and fluency reattribution).
These groups also get additional information during the second phase (the
second 60 statements to be judged from the 120 overall). We are trying to
see now *if the varying additional information* given to the two
treatment groups* changes the likelihood to rate a statement as true in the
second phase.*

I have gained parameters for my simulation from a mixture of pilot data and
previous study (since pilot data only has a results for one group).

One of the aims of the study is to get results for a *three way interaction
between status of repetition (new or repeated), judgement phase (1 or 2),
and condition (group control, af-reat, and flu-reat). *

I was wondering now how and *if I need to specify the three way interaction
in any specific way for my power calculation other than simply plugging the
variables for IV's and for the random effects? *

glmer(dv ~ fluency_reat * status.t * judge.t +
                  affect_reat * status.t * judge.t  +
                  (1 | subj) + (1 | item) , data = data,
             family = binomial(link = "logit"))

for clarification: since there are three condition groups --> the formula
gets repeated for each treatment group.

I have my code attached to this email. I personally thought that I have
specified everything and can just run it, but my supervisor said I need to
specify the three way interaction previously. I just am  not sure how to.

If anyone has had this question before and has some thoughts on it, I would
highly appreciate it.

Cheers,

Clemens
_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From t@h@|n|erdou@uo|c @end|ng |rom gm@||@com  Tue Nov  2 05:57:26 2021
From: t@h@|n|erdou@uo|c @end|ng |rom gm@||@com (Tahsin Ferdous)
Date: Mon, 1 Nov 2021 22:57:26 -0600
Subject: [R-sig-ME] zero variance and standard deviation in random effects
Message-ID: <CAE5DuhshgZxSjb_NJcMa_sABbOf_sMeKCJVZ0p_NzGDvrLk6AA@mail.gmail.com>

Hi,

I am running a mixed model using lmer like this:

m2<-lmer( logSeverity~  Incidence+Year+ (1|Prov), data = prov1,REML = FALSE)

Here, prov is my random effect. But I have the result, where the random
intercept of random effect is zero.

Random effects:
 Groups   Name        Variance Std.Dev.
 Prov     (Intercept) 0.00000  0.0000
 Residual             0.01149  0.1072
Number of obs: 54, groups:  Prov, 3

Should I still run a mixed model using Prov as a random effect, or I run
regression model here instead of mixed model by removing "Prov".
My data structure is like this:

   Prov Year Incidence Severity
  MB 2020 31.5 0.29
  MB 2019 21.8 0.36
  MB 2018 20.4 0.23
  MB 2017 31.1 0.31
  MB 2016 90.1 1.34
  MB 2015 63.4 0.5
  MB 2014 57.5 0.7
  MB 2013 44.1 0.45
  MB 2012 42.9 0.8
  MB 2011 15.6 0.92
  MB 2010 50.9 1.23
  MB 2009 32.1 1.56
  MB 2008 52.4 1.71
  MB 2007 15.1       0.83
  MB 2006 4.3       0.65
  MB 2005 47.7 1.4
  MB 2004 16.4 1.58
  MB 2003 39.3 0.33
  SK 2020 25.7 0.33
  SK 2019 37.3 0.54
  SK 2018 14.2 0.32
  SK 2017 4.8        0.51
  SK 2016 85.2 1.53
  SK 2015 53.2 0.57
  SK 2014 68.1        1.45
  SK 2013 23.2 0.39
  SK 2012 49.8 1.14
  SK 2011 10.6 0.79
  SK 2010 13.5 1.5
  SK 2009 6.9       0.56
  SK 2008 7.6 0.92
  SK 2007 2.4 0.75
  SK 2006 0.7 0.58
  SK 2005 4.1 0.71
  SK 2004 1.7 0.4
  SK 2003 1.9 0.09
  AB 2020 8 0.34
  AB 2019 28.3 0.52
  AB 2018 2.8 0.37
  AB 2017 3.7 0.49
  AB 2016 32.8 0.59
  AB 2015 9.2 0.29
  AB 2014 24.6 0.25
  AB 2013 17.6 0.4
  AB 2012 10.3 0.63
  AB 2011 5.2 0.87
  AB 2010 3.9 1.68
  AB 2009 3.2 1.13
  AB 2008 0.4 0.78
  AB 2007 0.1 0.45
  AB 2006 0.1 0.78
  AB 2005 1.1 1.09
  AB 2004 1.2 0.82
  AB 2003 1.2 0.08

	[[alternative HTML version deleted]]


From c@ro|@@b|och @end|ng |rom uk-koe|n@de  Tue Nov  2 07:11:06 2021
From: c@ro|@@b|och @end|ng |rom uk-koe|n@de (Carola Bloch)
Date: Tue, 2 Nov 2021 06:11:06 +0000
Subject: [R-sig-ME] 
 zero variance and standard deviation in random effects
In-Reply-To: <CAE5DuhshgZxSjb_NJcMa_sABbOf_sMeKCJVZ0p_NzGDvrLk6AA@mail.gmail.com>
References: <CAE5DuhshgZxSjb_NJcMa_sABbOf_sMeKCJVZ0p_NzGDvrLk6AA@mail.gmail.com>
Message-ID: <ec9bab0e850540408103aa2d50c97a9b@uk-koeln.de>

Hi,


thanks for sharing your problem. Concerning your first question, I would not recommend running a regular regression, as the data points in your sample are not independent and this would inflate the type 1 error rate.


In order to find out why the residual variance shows strange values, I would try some trouble shooting. You could run coef(m2) and check whether there are actually different intercepts for Prof. Second I would check the model assumptions, possibly there is a violation of the assumptions that affects model fit (I'd recommend performance::check_model()). Furthermore, how many factor levels does Prof have, I assume 3 according to your output? A small number of levels might be problematic, see Singman & Kellen, 2019*.


*Singmann, H., & Kellen, D. (2019). An introduction to mixed models for experimental psychology. In New methods in cognitive psychology (pp. 4-31). Routledge.


Hope this helps!

________________________________
Von: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> im Auftrag von Tahsin Ferdous <tahsinferdousuofc at gmail.com>
Gesendet: Dienstag, 2. November 2021 05:57:26
An: r-sig-mixed-models at r-project.org
Betreff: [R-sig-ME] zero variance and standard deviation in random effects

Hi,

I am running a mixed model using lmer like this:

m2<-lmer( logSeverity~  Incidence+Year+ (1|Prov), data = prov1,REML = FALSE)

Here, prov is my random effect. But I have the result, where the random
intercept of random effect is zero.

Random effects:
 Groups   Name        Variance Std.Dev.
 Prov     (Intercept) 0.00000  0.0000
 Residual             0.01149  0.1072
Number of obs: 54, groups:  Prov, 3

Should I still run a mixed model using Prov as a random effect, or I run
regression model here instead of mixed model by removing "Prov".
My data structure is like this:

   Prov Year Incidence Severity
  MB 2020 31.5 0.29
  MB 2019 21.8 0.36
  MB 2018 20.4 0.23
  MB 2017 31.1 0.31
  MB 2016 90.1 1.34
  MB 2015 63.4 0.5
  MB 2014 57.5 0.7
  MB 2013 44.1 0.45
  MB 2012 42.9 0.8
  MB 2011 15.6 0.92
  MB 2010 50.9 1.23
  MB 2009 32.1 1.56
  MB 2008 52.4 1.71
  MB 2007 15.1       0.83
  MB 2006 4.3       0.65
  MB 2005 47.7 1.4
  MB 2004 16.4 1.58
  MB 2003 39.3 0.33
  SK 2020 25.7 0.33
  SK 2019 37.3 0.54
  SK 2018 14.2 0.32
  SK 2017 4.8        0.51
  SK 2016 85.2 1.53
  SK 2015 53.2 0.57
  SK 2014 68.1        1.45
  SK 2013 23.2 0.39
  SK 2012 49.8 1.14
  SK 2011 10.6 0.79
  SK 2010 13.5 1.5
  SK 2009 6.9       0.56
  SK 2008 7.6 0.92
  SK 2007 2.4 0.75
  SK 2006 0.7 0.58
  SK 2005 4.1 0.71
  SK 2004 1.7 0.4
  SK 2003 1.9 0.09
  AB 2020 8 0.34
  AB 2019 28.3 0.52
  AB 2018 2.8 0.37
  AB 2017 3.7 0.49
  AB 2016 32.8 0.59
  AB 2015 9.2 0.29
  AB 2014 24.6 0.25
  AB 2013 17.6 0.4
  AB 2012 10.3 0.63
  AB 2011 5.2 0.87
  AB 2010 3.9 1.68
  AB 2009 3.2 1.13
  AB 2008 0.4 0.78
  AB 2007 0.1 0.45
  AB 2006 0.1 0.78
  AB 2005 1.1 1.09
  AB 2004 1.2 0.82
  AB 2003 1.2 0.08

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From t@h@|n|erdou@uo|c @end|ng |rom gm@||@com  Tue Nov  2 14:57:19 2021
From: t@h@|n|erdou@uo|c @end|ng |rom gm@||@com (Tahsin Ferdous)
Date: Tue, 2 Nov 2021 07:57:19 -0600
Subject: [R-sig-ME] 
 zero variance and standard deviation in random effects
In-Reply-To: <ec9bab0e850540408103aa2d50c97a9b@uk-koeln.de>
References: <CAE5DuhshgZxSjb_NJcMa_sABbOf_sMeKCJVZ0p_NzGDvrLk6AA@mail.gmail.com>
 <ec9bab0e850540408103aa2d50c97a9b@uk-koeln.de>
Message-ID: <CAE5DuhuD6UFroaOBRVbaBrdohHGOhWe+v+dsTzNu6j=XCh0wgg@mail.gmail.com>

Thanks a lot. My model is a random intercept model. But from the "coef(m2)"
command, I have found the following results:

Prov      Intercept
 AB.       0.07346574
 MB.      0.07346574
 SK.       0.07346574

That means intercepts are identical for all three provinces. In this model,
Prov is the random effect that has three-level (AB, MB and SK). In this
case, what should I do? If I remove province, the model will not be then
mixed model. But my data is repeated measures. I have also attached the
plot by running the command ( performance::check_model()).

On Tue, Nov 2, 2021 at 12:11 AM Carola Bloch <carola.bloch at uk-koeln.de>
wrote:

> Hi,
>
>
> thanks for sharing your problem. Concerning your first question, I would
> not recommend running a regular regression, as the data points in your
> sample are not independent and this would inflate the type 1 error rate.
>
>
> In order to find out why the residual variance shows strange values, I
> would try some trouble shooting. You could run coef(m2) and check whether
> there are actually different intercepts for Prof. Second I would check
> the model assumptions, possibly there is a violation of the assumptions
> that affects model fit (I'd recommend performance::check_model()).
> Furthermore, how many factor levels does Prof have, I assume 3 according
> to your output? A small number of levels might be problematic, see
> Singman & Kellen, 2019*.
>
>
> *Singmann, H., & Kellen, D. (2019). An introduction to mixed models for
> experimental psychology. In *New methods in cognitive psychology* (pp.
> 4-31). Routledge.
>
>
> Hope this helps!
> ------------------------------
> *Von:* R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> im
> Auftrag von Tahsin Ferdous <tahsinferdousuofc at gmail.com>
> *Gesendet:* Dienstag, 2. November 2021 05:57:26
> *An:* r-sig-mixed-models at r-project.org
> *Betreff:* [R-sig-ME] zero variance and standard deviation in random
> effects
>
> Hi,
>
> I am running a mixed model using lmer like this:
>
> m2<-lmer( logSeverity~  Incidence+Year+ (1|Prov), data = prov1,REML =
> FALSE)
>
> Here, prov is my random effect. But I have the result, where the random
> intercept of random effect is zero.
>
> Random effects:
>  Groups   Name        Variance Std.Dev.
>  Prov     (Intercept) 0.00000  0.0000
>  Residual             0.01149  0.1072
> Number of obs: 54, groups:  Prov, 3
>
> Should I still run a mixed model using Prov as a random effect, or I run
> regression model here instead of mixed model by removing "Prov".
> My data structure is like this:
>
>    Prov Year Incidence Severity
>   MB 2020 31.5 0.29
>   MB 2019 21.8 0.36
>   MB 2018 20.4 0.23
>   MB 2017 31.1 0.31
>   MB 2016 90.1 1.34
>   MB 2015 63.4 0.5
>   MB 2014 57.5 0.7
>   MB 2013 44.1 0.45
>   MB 2012 42.9 0.8
>   MB 2011 15.6 0.92
>   MB 2010 50.9 1.23
>   MB 2009 32.1 1.56
>   MB 2008 52.4 1.71
>   MB 2007 15.1       0.83
>   MB 2006 4.3       0.65
>   MB 2005 47.7 1.4
>   MB 2004 16.4 1.58
>   MB 2003 39.3 0.33
>   SK 2020 25.7 0.33
>   SK 2019 37.3 0.54
>   SK 2018 14.2 0.32
>   SK 2017 4.8        0.51
>   SK 2016 85.2 1.53
>   SK 2015 53.2 0.57
>   SK 2014 68.1        1.45
>   SK 2013 23.2 0.39
>   SK 2012 49.8 1.14
>   SK 2011 10.6 0.79
>   SK 2010 13.5 1.5
>   SK 2009 6.9       0.56
>   SK 2008 7.6 0.92
>   SK 2007 2.4 0.75
>   SK 2006 0.7 0.58
>   SK 2005 4.1 0.71
>   SK 2004 1.7 0.4
>   SK 2003 1.9 0.09
>   AB 2020 8 0.34
>   AB 2019 28.3 0.52
>   AB 2018 2.8 0.37
>   AB 2017 3.7 0.49
>   AB 2016 32.8 0.59
>   AB 2015 9.2 0.29
>   AB 2014 24.6 0.25
>   AB 2013 17.6 0.4
>   AB 2012 10.3 0.63
>   AB 2011 5.2 0.87
>   AB 2010 3.9 1.68
>   AB 2009 3.2 1.13
>   AB 2008 0.4 0.78
>   AB 2007 0.1 0.45
>   AB 2006 0.1 0.78
>   AB 2005 1.1 1.09
>   AB 2004 1.2 0.82
>   AB 2003 1.2 0.08
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

-------------- next part --------------
A non-text attachment was scrubbed...
Name: Rplot01.png
Type: image/png
Size: 174452 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20211102/3efa8e7b/attachment-0001.png>

From wo||g@ng@v|echtb@uer @end|ng |rom m@@@tr|chtun|ver@|ty@n|  Tue Nov  2 15:57:44 2021
From: wo||g@ng@v|echtb@uer @end|ng |rom m@@@tr|chtun|ver@|ty@n| (Viechtbauer, Wolfgang (SP))
Date: Tue, 2 Nov 2021 14:57:44 +0000
Subject: [R-sig-ME] 
 zero variance and standard deviation in random effects
In-Reply-To: <CAE5DuhuD6UFroaOBRVbaBrdohHGOhWe+v+dsTzNu6j=XCh0wgg@mail.gmail.com>
References: <CAE5DuhshgZxSjb_NJcMa_sABbOf_sMeKCJVZ0p_NzGDvrLk6AA@mail.gmail.com>
 <ec9bab0e850540408103aa2d50c97a9b@uk-koeln.de>
 <CAE5DuhuD6UFroaOBRVbaBrdohHGOhWe+v+dsTzNu6j=XCh0wgg@mail.gmail.com>
Message-ID: <97abfe2c760e4e719760ab01b7c9e810@UM-MAIL3214.unimaas.nl>

When the variance is estimated to be zero, then this is identical to removing the random effect altogether. So whether you remove it or not will not make any difference. I would leave it in and just report the results you obtained. One can also use confint() then to obtain a CI for this variance component. While the estimate (and hence lower bound) are 0, the upper bound is likely to indicate that there could be (substantial) variance associated with this random effect.

Best,
Wolfgang

>-----Original Message-----
>From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] On
>Behalf Of Tahsin Ferdous
>Sent: Tuesday, 02 November, 2021 14:57
>To: Carola Bloch; r-sig-mixed-models at r-project.org
>Subject: Re: [R-sig-ME] zero variance and standard deviation in random effects
>
>Thanks a lot. My model is a random intercept model. But from the "coef(m2)"
>command, I have found the following results:
>
>Prov      Intercept
> AB.       0.07346574
> MB.      0.07346574
> SK.       0.07346574
>
>That means intercepts are identical for all three provinces. In this model,
>Prov is the random effect that has three-level (AB, MB and SK). In this
>case, what should I do? If I remove province, the model will not be then
>mixed model. But my data is repeated measures. I have also attached the
>plot by running the command ( performance::check_model()).
>
>On Tue, Nov 2, 2021 at 12:11 AM Carola Bloch <carola.bloch at uk-koeln.de>
>wrote:
>
>> Hi,
>>
>> thanks for sharing your problem. Concerning your first question, I would
>> not recommend running a regular regression, as the data points in your
>> sample are not independent and this would inflate the type 1 error rate.
>>
>> In order to find out why the residual variance shows strange values, I
>> would try some trouble shooting. You could run coef(m2) and check whether
>> there are actually different intercepts for Prof. Second I would check
>> the model assumptions, possibly there is a violation of the assumptions
>> that affects model fit (I'd recommend performance::check_model()).
>> Furthermore, how many factor levels does Prof have, I assume 3 according
>> to your output? A small number of levels might be problematic, see
>> Singman & Kellen, 2019*.
>>
>> *Singmann, H., & Kellen, D. (2019). An introduction to mixed models for
>> experimental psychology. In *New methods in cognitive psychology* (pp.
>> 4-31). Routledge.
>>
>> Hope this helps!
>> ------------------------------
>> *Von:* R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> im
>> Auftrag von Tahsin Ferdous <tahsinferdousuofc at gmail.com>
>> *Gesendet:* Dienstag, 2. November 2021 05:57:26
>> *An:* r-sig-mixed-models at r-project.org
>> *Betreff:* [R-sig-ME] zero variance and standard deviation in random
>> effects
>>
>> Hi,
>>
>> I am running a mixed model using lmer like this:
>>
>> m2<-lmer( logSeverity~  Incidence+Year+ (1|Prov), data = prov1,REML =
>> FALSE)
>>
>> Here, prov is my random effect. But I have the result, where the random
>> intercept of random effect is zero.
>>
>> Random effects:
>>  Groups   Name        Variance Std.Dev.
>>  Prov     (Intercept) 0.00000  0.0000
>>  Residual             0.01149  0.1072
>> Number of obs: 54, groups:  Prov, 3
>>
>> Should I still run a mixed model using Prov as a random effect, or I run
>> regression model here instead of mixed model by removing "Prov".
>> My data structure is like this:
>>
>>    Prov Year Incidence Severity
>>   MB 2020 31.5 0.29
>>   MB 2019 21.8 0.36
>>   MB 2018 20.4 0.23
>>   MB 2017 31.1 0.31
>>   MB 2016 90.1 1.34
>>   MB 2015 63.4 0.5
>>   MB 2014 57.5 0.7
>>   MB 2013 44.1 0.45
>>   MB 2012 42.9 0.8
>>   MB 2011 15.6 0.92
>>   MB 2010 50.9 1.23
>>   MB 2009 32.1 1.56
>>   MB 2008 52.4 1.71
>>   MB 2007 15.1       0.83
>>   MB 2006 4.3       0.65
>>   MB 2005 47.7 1.4
>>   MB 2004 16.4 1.58
>>   MB 2003 39.3 0.33
>>   SK 2020 25.7 0.33
>>   SK 2019 37.3 0.54
>>   SK 2018 14.2 0.32
>>   SK 2017 4.8        0.51
>>   SK 2016 85.2 1.53
>>   SK 2015 53.2 0.57
>>   SK 2014 68.1        1.45
>>   SK 2013 23.2 0.39
>>   SK 2012 49.8 1.14
>>   SK 2011 10.6 0.79
>>   SK 2010 13.5 1.5
>>   SK 2009 6.9       0.56
>>   SK 2008 7.6 0.92
>>   SK 2007 2.4 0.75
>>   SK 2006 0.7 0.58
>>   SK 2005 4.1 0.71
>>   SK 2004 1.7 0.4
>>   SK 2003 1.9 0.09
>>   AB 2020 8 0.34
>>   AB 2019 28.3 0.52
>>   AB 2018 2.8 0.37
>>   AB 2017 3.7 0.49
>>   AB 2016 32.8 0.59
>>   AB 2015 9.2 0.29
>>   AB 2014 24.6 0.25
>>   AB 2013 17.6 0.4
>>   AB 2012 10.3 0.63
>>   AB 2011 5.2 0.87
>>   AB 2010 3.9 1.68
>>   AB 2009 3.2 1.13
>>   AB 2008 0.4 0.78
>>   AB 2007 0.1 0.45
>>   AB 2006 0.1 0.78
>>   AB 2005 1.1 1.09
>>   AB 2004 1.2 0.82
>>   AB 2003 1.2 0.08

From bbo|ker @end|ng |rom gm@||@com  Tue Nov  2 16:20:25 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Tue, 2 Nov 2021 11:20:25 -0400
Subject: [R-sig-ME] 
 zero variance and standard deviation in random effects
In-Reply-To: <97abfe2c760e4e719760ab01b7c9e810@UM-MAIL3214.unimaas.nl>
References: <CAE5DuhshgZxSjb_NJcMa_sABbOf_sMeKCJVZ0p_NzGDvrLk6AA@mail.gmail.com>
 <ec9bab0e850540408103aa2d50c97a9b@uk-koeln.de>
 <CAE5DuhuD6UFroaOBRVbaBrdohHGOhWe+v+dsTzNu6j=XCh0wgg@mail.gmail.com>
 <97abfe2c760e4e719760ab01b7c9e810@UM-MAIL3214.unimaas.nl>
Message-ID: <aa725aca-cd6d-1bfd-6374-9a950b691729@gmail.com>

   I agree.  There is more discussion at

http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#singular-models-random-effect-variances-estimated-as-zero-or-correlations-estimated-as---1

   While I appreciate Carola Bloch's input, I think it's a little 
misguided.  Having only three levels of the random effect is indeed 
problematic, but it doesn't actually violate any assumptions of the 
model, and there isn't necessarily anything else wrong with the model -- 
it's just hard to estimate variance reliably from a sample of three. 
(See https://rpubs.com/bbolker/4187 for some simulated examples.) One 
standard approach to this problem is to treat province as a *fixed* effect.

On 11/2/21 10:57 AM, Viechtbauer, Wolfgang (SP) wrote:
> When the variance is estimated to be zero, then this is identical to removing the random effect altogether. So whether you remove it or not will not make any difference. I would leave it in and just report the results you obtained. One can also use confint() then to obtain a CI for this variance component. While the estimate (and hence lower bound) are 0, the upper bound is likely to indicate that there could be (substantial) variance associated with this random effect.
> 
> Best,
> Wolfgang
> 
>> -----Original Message-----
>> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] On
>> Behalf Of Tahsin Ferdous
>> Sent: Tuesday, 02 November, 2021 14:57
>> To: Carola Bloch; r-sig-mixed-models at r-project.org
>> Subject: Re: [R-sig-ME] zero variance and standard deviation in random effects
>>
>> Thanks a lot. My model is a random intercept model. But from the "coef(m2)"
>> command, I have found the following results:
>>
>> Prov      Intercept
>> AB.       0.07346574
>> MB.      0.07346574
>> SK.       0.07346574
>>
>> That means intercepts are identical for all three provinces. In this model,
>> Prov is the random effect that has three-level (AB, MB and SK). In this
>> case, what should I do? If I remove province, the model will not be then
>> mixed model. But my data is repeated measures. I have also attached the
>> plot by running the command ( performance::check_model()).
>>
>> On Tue, Nov 2, 2021 at 12:11 AM Carola Bloch <carola.bloch at uk-koeln.de>
>> wrote:
>>
>>> Hi,
>>>
>>> thanks for sharing your problem. Concerning your first question, I would
>>> not recommend running a regular regression, as the data points in your
>>> sample are not independent and this would inflate the type 1 error rate.
>>>
>>> In order to find out why the residual variance shows strange values, I
>>> would try some trouble shooting. You could run coef(m2) and check whether
>>> there are actually different intercepts for Prof. Second I would check
>>> the model assumptions, possibly there is a violation of the assumptions
>>> that affects model fit (I'd recommend performance::check_model()).
>>> Furthermore, how many factor levels does Prof have, I assume 3 according
>>> to your output? A small number of levels might be problematic, see
>>> Singman & Kellen, 2019*.
>>>
>>> *Singmann, H., & Kellen, D. (2019). An introduction to mixed models for
>>> experimental psychology. In *New methods in cognitive psychology* (pp.
>>> 4-31). Routledge.
>>>
>>> Hope this helps!
>>> ------------------------------
>>> *Von:* R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> im
>>> Auftrag von Tahsin Ferdous <tahsinferdousuofc at gmail.com>
>>> *Gesendet:* Dienstag, 2. November 2021 05:57:26
>>> *An:* r-sig-mixed-models at r-project.org
>>> *Betreff:* [R-sig-ME] zero variance and standard deviation in random
>>> effects
>>>
>>> Hi,
>>>
>>> I am running a mixed model using lmer like this:
>>>
>>> m2<-lmer( logSeverity~  Incidence+Year+ (1|Prov), data = prov1,REML =
>>> FALSE)
>>>
>>> Here, prov is my random effect. But I have the result, where the random
>>> intercept of random effect is zero.
>>>
>>> Random effects:
>>>   Groups   Name        Variance Std.Dev.
>>>   Prov     (Intercept) 0.00000  0.0000
>>>   Residual             0.01149  0.1072
>>> Number of obs: 54, groups:  Prov, 3
>>>
>>> Should I still run a mixed model using Prov as a random effect, or I run
>>> regression model here instead of mixed model by removing "Prov".
>>> My data structure is like this:
>>>
>>>     Prov Year Incidence Severity
>>>    MB 2020 31.5 0.29
>>>    MB 2019 21.8 0.36
>>>    MB 2018 20.4 0.23
>>>    MB 2017 31.1 0.31
>>>    MB 2016 90.1 1.34
>>>    MB 2015 63.4 0.5
>>>    MB 2014 57.5 0.7
>>>    MB 2013 44.1 0.45
>>>    MB 2012 42.9 0.8
>>>    MB 2011 15.6 0.92
>>>    MB 2010 50.9 1.23
>>>    MB 2009 32.1 1.56
>>>    MB 2008 52.4 1.71
>>>    MB 2007 15.1       0.83
>>>    MB 2006 4.3       0.65
>>>    MB 2005 47.7 1.4
>>>    MB 2004 16.4 1.58
>>>    MB 2003 39.3 0.33
>>>    SK 2020 25.7 0.33
>>>    SK 2019 37.3 0.54
>>>    SK 2018 14.2 0.32
>>>    SK 2017 4.8        0.51
>>>    SK 2016 85.2 1.53
>>>    SK 2015 53.2 0.57
>>>    SK 2014 68.1        1.45
>>>    SK 2013 23.2 0.39
>>>    SK 2012 49.8 1.14
>>>    SK 2011 10.6 0.79
>>>    SK 2010 13.5 1.5
>>>    SK 2009 6.9       0.56
>>>    SK 2008 7.6 0.92
>>>    SK 2007 2.4 0.75
>>>    SK 2006 0.7 0.58
>>>    SK 2005 4.1 0.71
>>>    SK 2004 1.7 0.4
>>>    SK 2003 1.9 0.09
>>>    AB 2020 8 0.34
>>>    AB 2019 28.3 0.52
>>>    AB 2018 2.8 0.37
>>>    AB 2017 3.7 0.49
>>>    AB 2016 32.8 0.59
>>>    AB 2015 9.2 0.29
>>>    AB 2014 24.6 0.25
>>>    AB 2013 17.6 0.4
>>>    AB 2012 10.3 0.63
>>>    AB 2011 5.2 0.87
>>>    AB 2010 3.9 1.68
>>>    AB 2009 3.2 1.13
>>>    AB 2008 0.4 0.78
>>>    AB 2007 0.1 0.45
>>>    AB 2006 0.1 0.78
>>>    AB 2005 1.1 1.09
>>>    AB 2004 1.2 0.82
>>>    AB 2003 1.2 0.08
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

-- 
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
(Acting) Graduate chair, Mathematics & Statistics


From c@ro|@@b|och @end|ng |rom uk-koe|n@de  Tue Nov  2 16:52:57 2021
From: c@ro|@@b|och @end|ng |rom uk-koe|n@de (Carola Bloch)
Date: Tue, 2 Nov 2021 15:52:57 +0000
Subject: [R-sig-ME] 
 zero variance and standard deviation in random effects
In-Reply-To: <aa725aca-cd6d-1bfd-6374-9a950b691729@gmail.com>
References: <CAE5DuhshgZxSjb_NJcMa_sABbOf_sMeKCJVZ0p_NzGDvrLk6AA@mail.gmail.com>
 <ec9bab0e850540408103aa2d50c97a9b@uk-koeln.de>
 <CAE5DuhuD6UFroaOBRVbaBrdohHGOhWe+v+dsTzNu6j=XCh0wgg@mail.gmail.com>
 <97abfe2c760e4e719760ab01b7c9e810@UM-MAIL3214.unimaas.nl>
 <aa725aca-cd6d-1bfd-6374-9a950b691729@gmail.com>
Message-ID: <a0a761b4a26149899cdcfca6fea50b66@uk-koeln.de>

Thank you for the clarification. I was recommending the assumption check as an independent step that I'd recommend to do in the course of trouble-shooting with mixed models. That was however not related to the aspect of small numbers of factor levels for random effects. Sorry if that was misguiding.

Best regards,
Carola


-----Urspr?ngliche Nachricht-----
Von: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> Im Auftrag von Ben Bolker
Gesendet: Dienstag, 2. November 2021 16:20
An: r-sig-mixed-models at r-project.org
Betreff: Re: [R-sig-ME] zero variance and standard deviation in random effects

   I agree.  There is more discussion at

http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#singular-models-random-effect-variances-estimated-as-zero-or-correlations-estimated-as---1

   While I appreciate Carola Bloch's input, I think it's a little misguided.  Having only three levels of the random effect is indeed problematic, but it doesn't actually violate any assumptions of the model, and there isn't necessarily anything else wrong with the model -- it's just hard to estimate variance reliably from a sample of three. 
(See https://rpubs.com/bbolker/4187 for some simulated examples.) One standard approach to this problem is to treat province as a *fixed* effect.

On 11/2/21 10:57 AM, Viechtbauer, Wolfgang (SP) wrote:
> When the variance is estimated to be zero, then this is identical to removing the random effect altogether. So whether you remove it or not will not make any difference. I would leave it in and just report the results you obtained. One can also use confint() then to obtain a CI for this variance component. While the estimate (and hence lower bound) are 0, the upper bound is likely to indicate that there could be (substantial) variance associated with this random effect.
> 
> Best,
> Wolfgang
> 
>> -----Original Message-----
>> From: R-sig-mixed-models 
>> [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Tahsin 
>> Ferdous
>> Sent: Tuesday, 02 November, 2021 14:57
>> To: Carola Bloch; r-sig-mixed-models at r-project.org
>> Subject: Re: [R-sig-ME] zero variance and standard deviation in 
>> random effects
>>
>> Thanks a lot. My model is a random intercept model. But from the "coef(m2)"
>> command, I have found the following results:
>>
>> Prov      Intercept
>> AB.       0.07346574
>> MB.      0.07346574
>> SK.       0.07346574
>>
>> That means intercepts are identical for all three provinces. In this 
>> model, Prov is the random effect that has three-level (AB, MB and 
>> SK). In this case, what should I do? If I remove province, the model 
>> will not be then mixed model. But my data is repeated measures. I 
>> have also attached the plot by running the command ( performance::check_model()).
>>
>> On Tue, Nov 2, 2021 at 12:11 AM Carola Bloch 
>> <carola.bloch at uk-koeln.de>
>> wrote:
>>
>>> Hi,
>>>
>>> thanks for sharing your problem. Concerning your first question, I 
>>> would not recommend running a regular regression, as the data points 
>>> in your sample are not independent and this would inflate the type 1 error rate.
>>>
>>> In order to find out why the residual variance shows strange values, 
>>> I would try some trouble shooting. You could run coef(m2) and check 
>>> whether there are actually different intercepts for Prof. Second I 
>>> would check the model assumptions, possibly there is a violation of 
>>> the assumptions that affects model fit (I'd recommend performance::check_model()).
>>> Furthermore, how many factor levels does Prof have, I assume 3 
>>> according to your output? A small number of levels might be 
>>> problematic, see Singman & Kellen, 2019*.
>>>
>>> *Singmann, H., & Kellen, D. (2019). An introduction to mixed models 
>>> for experimental psychology. In *New methods in cognitive psychology* (pp.
>>> 4-31). Routledge.
>>>
>>> Hope this helps!
>>> ------------------------------
>>> *Von:* R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> 
>>> im Auftrag von Tahsin Ferdous <tahsinferdousuofc at gmail.com>
>>> *Gesendet:* Dienstag, 2. November 2021 05:57:26
>>> *An:* r-sig-mixed-models at r-project.org
>>> *Betreff:* [R-sig-ME] zero variance and standard deviation in random 
>>> effects
>>>
>>> Hi,
>>>
>>> I am running a mixed model using lmer like this:
>>>
>>> m2<-lmer( logSeverity~  Incidence+Year+ (1|Prov), data = prov1,REML 
>>> =
>>> FALSE)
>>>
>>> Here, prov is my random effect. But I have the result, where the 
>>> random intercept of random effect is zero.
>>>
>>> Random effects:
>>>   Groups   Name        Variance Std.Dev.
>>>   Prov     (Intercept) 0.00000  0.0000
>>>   Residual             0.01149  0.1072
>>> Number of obs: 54, groups:  Prov, 3
>>>
>>> Should I still run a mixed model using Prov as a random effect, or I 
>>> run regression model here instead of mixed model by removing "Prov".
>>> My data structure is like this:
>>>
>>>     Prov Year Incidence Severity
>>>    MB 2020 31.5 0.29
>>>    MB 2019 21.8 0.36
>>>    MB 2018 20.4 0.23
>>>    MB 2017 31.1 0.31
>>>    MB 2016 90.1 1.34
>>>    MB 2015 63.4 0.5
>>>    MB 2014 57.5 0.7
>>>    MB 2013 44.1 0.45
>>>    MB 2012 42.9 0.8
>>>    MB 2011 15.6 0.92
>>>    MB 2010 50.9 1.23
>>>    MB 2009 32.1 1.56
>>>    MB 2008 52.4 1.71
>>>    MB 2007 15.1       0.83
>>>    MB 2006 4.3       0.65
>>>    MB 2005 47.7 1.4
>>>    MB 2004 16.4 1.58
>>>    MB 2003 39.3 0.33
>>>    SK 2020 25.7 0.33
>>>    SK 2019 37.3 0.54
>>>    SK 2018 14.2 0.32
>>>    SK 2017 4.8        0.51
>>>    SK 2016 85.2 1.53
>>>    SK 2015 53.2 0.57
>>>    SK 2014 68.1        1.45
>>>    SK 2013 23.2 0.39
>>>    SK 2012 49.8 1.14
>>>    SK 2011 10.6 0.79
>>>    SK 2010 13.5 1.5
>>>    SK 2009 6.9       0.56
>>>    SK 2008 7.6 0.92
>>>    SK 2007 2.4 0.75
>>>    SK 2006 0.7 0.58
>>>    SK 2005 4.1 0.71
>>>    SK 2004 1.7 0.4
>>>    SK 2003 1.9 0.09
>>>    AB 2020 8 0.34
>>>    AB 2019 28.3 0.52
>>>    AB 2018 2.8 0.37
>>>    AB 2017 3.7 0.49
>>>    AB 2016 32.8 0.59
>>>    AB 2015 9.2 0.29
>>>    AB 2014 24.6 0.25
>>>    AB 2013 17.6 0.4
>>>    AB 2012 10.3 0.63
>>>    AB 2011 5.2 0.87
>>>    AB 2010 3.9 1.68
>>>    AB 2009 3.2 1.13
>>>    AB 2008 0.4 0.78
>>>    AB 2007 0.1 0.45
>>>    AB 2006 0.1 0.78
>>>    AB 2005 1.1 1.09
>>>    AB 2004 1.2 0.82
>>>    AB 2003 1.2 0.08
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

--
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University Director, School of Computational Science and Engineering
(Acting) Graduate chair, Mathematics & Statistics

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From r@turner @end|ng |rom @uck|@nd@@c@nz  Wed Nov  3 00:58:35 2021
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Wed, 3 Nov 2021 12:58:35 +1300
Subject: [R-sig-ME] 
 zero variance and standard deviation in random effects
In-Reply-To: <aa725aca-cd6d-1bfd-6374-9a950b691729@gmail.com>
References: <CAE5DuhshgZxSjb_NJcMa_sABbOf_sMeKCJVZ0p_NzGDvrLk6AA@mail.gmail.com>
 <ec9bab0e850540408103aa2d50c97a9b@uk-koeln.de>
 <CAE5DuhuD6UFroaOBRVbaBrdohHGOhWe+v+dsTzNu6j=XCh0wgg@mail.gmail.com>
 <97abfe2c760e4e719760ab01b7c9e810@UM-MAIL3214.unimaas.nl>
 <aa725aca-cd6d-1bfd-6374-9a950b691729@gmail.com>
Message-ID: <20211103125835.1a1fd952@rolf-Latitude-E7470>


On Tue, 2 Nov 2021 11:20:25 -0400
Ben Bolker <bbolker at gmail.com> wrote:

<SNIP>

> -- it's just hard to estimate variance reliably from a sample of
> three. (See
> https://rpubs.com/bbolker/4187
> for some simulated examples.) One standard approach to this problem
> is to treat province as a *fixed* effect.

<SNIP>

To me it makes little or no sense to treat "province" as a random
effect in any case.  Conceivably Alberta, Saskatchewan and Manitoba
could have been chosen at random from the 10 provinces, but it sure
doesn't look like it.  Moreover drawing inferences about the
"population of provinces" (which is the whole idea of random effects)
would be highly dubious, given the completely different nature of (e.g.
PEI) from the three prairie provinces in the "sample".

The data set involves the three prairie provinces; inferences drawn can
really only apply to those provinces.  Ergo "province" is a fixed
effect.

cheers,

Rolf Turner

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From me @end|ng |rom ph||||p@|d@y@com  Wed Nov  3 01:04:34 2021
From: me @end|ng |rom ph||||p@|d@y@com (Phillip Alday)
Date: Tue, 2 Nov 2021 19:04:34 -0500
Subject: [R-sig-ME] 
 zero variance and standard deviation in random effects
In-Reply-To: <20211103125835.1a1fd952@rolf-Latitude-E7470>
References: <CAE5DuhshgZxSjb_NJcMa_sABbOf_sMeKCJVZ0p_NzGDvrLk6AA@mail.gmail.com>
 <ec9bab0e850540408103aa2d50c97a9b@uk-koeln.de>
 <CAE5DuhuD6UFroaOBRVbaBrdohHGOhWe+v+dsTzNu6j=XCh0wgg@mail.gmail.com>
 <97abfe2c760e4e719760ab01b7c9e810@UM-MAIL3214.unimaas.nl>
 <aa725aca-cd6d-1bfd-6374-9a950b691729@gmail.com>
 <20211103125835.1a1fd952@rolf-Latitude-E7470>
Message-ID: <bbed9a37-5717-2777-d140-af0abeff826e@phillipalday.com>

I think one useful case for treating small, closed populations as a
random-effect is that you get the shrinkage/regularization. Of course,
the estimated variances will be nonsense. But the regularization may
still be useful for other things, cf. "new style" random effects:

http://www.biostat.umn.edu/~hodges/PubH8492/Hodges-ClaytonREONsubToStatSci.pdf

http://www.biostat.umn.edu/~hodges/PubH8492/Lectures_13.pdf

Of course, this is the statistical equivalent of "if you have to ask,
you can't afford it" / "shouldn't be using it".

(This is a general comment and _not_ advocating for any approach in this
particular case -- I haven't looked at the OP's problem enough to have
any idea about which approach is suitable there.)

Phillip

On 2/11/21 6:58 pm, Rolf Turner wrote:
> 
> On Tue, 2 Nov 2021 11:20:25 -0400
> Ben Bolker <bbolker at gmail.com> wrote:
> 
> <SNIP>
> 
>> -- it's just hard to estimate variance reliably from a sample of
>> three. (See
>> https://rpubs.com/bbolker/4187
>> for some simulated examples.) One standard approach to this problem
>> is to treat province as a *fixed* effect.
> 
> <SNIP>
> 
> To me it makes little or no sense to treat "province" as a random
> effect in any case.  Conceivably Alberta, Saskatchewan and Manitoba
> could have been chosen at random from the 10 provinces, but it sure
> doesn't look like it.  Moreover drawing inferences about the
> "population of provinces" (which is the whole idea of random effects)
> would be highly dubious, given the completely different nature of (e.g.
> PEI) from the three prairie provinces in the "sample".
> 
> The data set involves the three prairie provinces; inferences drawn can
> really only apply to those provinces.  Ergo "province" is a fixed
> effect.
> 
> cheers,
> 
> Rolf Turner
>


From rez@pour2088 @end|ng |rom y@hoo@com  Tue Nov  2 20:53:47 2021
From: rez@pour2088 @end|ng |rom y@hoo@com (Mehdi Rezapour)
Date: Tue, 2 Nov 2021 19:53:47 +0000 (UTC)
Subject: [R-sig-ME] Fw: lme4 error
In-Reply-To: <35053577.2123867.1635870324935@mail.yahoo.com>
References: <1710671081.2125810.1635868844523.ref@mail.yahoo.com>
 <1710671081.2125810.1635868844523@mail.yahoo.com>
 <35053577.2123867.1635870324935@mail.yahoo.com>
Message-ID: <1252569631.2119.1635882827599@mail.yahoo.com>



 Dear Dr. Bolker,

Hope all is well.I am trying to understand the C code in lme4 by use of load_all function, which is loading the package and walk through C function.But when i am trying to load the package it gives me an error of " error: Index is not a member of ?lme4::lme4CholmodDecomposition<Eigen::SparseMatrix<double, 0, int> >::Base{aka ?Eigen::CholmodDecomposition<Eigen::SparseMatrix<double, 0, int>, 1>"which is related to document "lme4CholmodDecomposition.h"Could you please tell me if you have any input?
kind?regardsMahdi
    
	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Wed Nov  3 02:09:47 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Tue, 2 Nov 2021 21:09:47 -0400
Subject: [R-sig-ME] Fw: lme4 error
In-Reply-To: <1252569631.2119.1635882827599@mail.yahoo.com>
References: <1710671081.2125810.1635868844523.ref@mail.yahoo.com>
 <1710671081.2125810.1635868844523@mail.yahoo.com>
 <35053577.2123867.1635870324935@mail.yahoo.com>
 <1252569631.2119.1635882827599@mail.yahoo.com>
Message-ID: <33a22cbc-d790-1fd9-fa67-98157ab3bc76@gmail.com>


   Assuming this is devtools::load_all() (please confirm? I'm not sure, 
as it doesn't that I know of "walk through [the] C function")

  * I have no idea offhand
  * it might help to reinstall Rcpp, RcppEigen, lme4 *from source* in 
that order
  * are you able to build the package from source and load it in the 
usual way?

   cheers
    Ben Bolker

On 11/2/21 3:53 PM, Mehdi Rezapour via R-sig-mixed-models wrote:
> 
> 
>   Dear Dr. Bolker,
> 
> Hope all is well.I am trying to understand the C code in lme4 by use of load_all function, which is loading the package and walk through C function.But when i am trying to load the package it gives me an error of " error: Index is not a member of ?lme4::lme4CholmodDecomposition<Eigen::SparseMatrix<double, 0, int> >::Base{aka ?Eigen::CholmodDecomposition<Eigen::SparseMatrix<double, 0, int>, 1>"which is related to document "lme4CholmodDecomposition.h"Could you please tell me if you have any input?
> kind?regardsMahdi
>      
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From t@h@|n|erdou@uo|c @end|ng |rom gm@||@com  Wed Nov  3 05:46:07 2021
From: t@h@|n|erdou@uo|c @end|ng |rom gm@||@com (Tahsin Ferdous)
Date: Tue, 2 Nov 2021 22:46:07 -0600
Subject: [R-sig-ME] 
 zero variance and standard deviation in random effects
In-Reply-To: <aa725aca-cd6d-1bfd-6374-9a950b691729@gmail.com>
References: <CAE5DuhshgZxSjb_NJcMa_sABbOf_sMeKCJVZ0p_NzGDvrLk6AA@mail.gmail.com>
 <ec9bab0e850540408103aa2d50c97a9b@uk-koeln.de>
 <CAE5DuhuD6UFroaOBRVbaBrdohHGOhWe+v+dsTzNu6j=XCh0wgg@mail.gmail.com>
 <97abfe2c760e4e719760ab01b7c9e810@UM-MAIL3214.unimaas.nl>
 <aa725aca-cd6d-1bfd-6374-9a950b691729@gmail.com>
Message-ID: <CAE5DuhtMqD5HFOPcvmwkCSSCc5Rq6SsSPfjLg64zPQCqu7k1Cg@mail.gmail.com>

Thanks a lot, everyone, for your valuable suggestion. I have run another
mixed model that assumes the district as random effects; each district has
values (yield) at different years. There are 12 districts; the data is
repeated measures. I get a very small variance for the districts
(5.692e-17). I checked the coefficients of the model. The intercepts for
all districts are the same. In this case, can I run a random intercept
mixed model? Or, which model will be appropriate in this case? Can I run a
regression model assuming year (2000 to 2018) and district ( 12 districts)
as covariates?

On Tue, Nov 2, 2021 at 9:20 AM Ben Bolker <bbolker at gmail.com> wrote:

>    I agree.  There is more discussion at
>
>
> http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#singular-models-random-effect-variances-estimated-as-zero-or-correlations-estimated-as---1
>
>    While I appreciate Carola Bloch's input, I think it's a little
> misguided.  Having only three levels of the random effect is indeed
> problematic, but it doesn't actually violate any assumptions of the
> model, and there isn't necessarily anything else wrong with the model --
> it's just hard to estimate variance reliably from a sample of three.
> (See https://rpubs.com/bbolker/4187 for some simulated examples.) One
> standard approach to this problem is to treat province as a *fixed* effect.
>
> On 11/2/21 10:57 AM, Viechtbauer, Wolfgang (SP) wrote:
> > When the variance is estimated to be zero, then this is identical to
> removing the random effect altogether. So whether you remove it or not will
> not make any difference. I would leave it in and just report the results
> you obtained. One can also use confint() then to obtain a CI for this
> variance component. While the estimate (and hence lower bound) are 0, the
> upper bound is likely to indicate that there could be (substantial)
> variance associated with this random effect.
> >
> > Best,
> > Wolfgang
> >
> >> -----Original Message-----
> >> From: R-sig-mixed-models [mailto:
> r-sig-mixed-models-bounces at r-project.org] On
> >> Behalf Of Tahsin Ferdous
> >> Sent: Tuesday, 02 November, 2021 14:57
> >> To: Carola Bloch; r-sig-mixed-models at r-project.org
> >> Subject: Re: [R-sig-ME] zero variance and standard deviation in random
> effects
> >>
> >> Thanks a lot. My model is a random intercept model. But from the
> "coef(m2)"
> >> command, I have found the following results:
> >>
> >> Prov      Intercept
> >> AB.       0.07346574
> >> MB.      0.07346574
> >> SK.       0.07346574
> >>
> >> That means intercepts are identical for all three provinces. In this
> model,
> >> Prov is the random effect that has three-level (AB, MB and SK). In this
> >> case, what should I do? If I remove province, the model will not be then
> >> mixed model. But my data is repeated measures. I have also attached the
> >> plot by running the command ( performance::check_model()).
> >>
> >> On Tue, Nov 2, 2021 at 12:11 AM Carola Bloch <carola.bloch at uk-koeln.de>
> >> wrote:
> >>
> >>> Hi,
> >>>
> >>> thanks for sharing your problem. Concerning your first question, I
> would
> >>> not recommend running a regular regression, as the data points in your
> >>> sample are not independent and this would inflate the type 1 error
> rate.
> >>>
> >>> In order to find out why the residual variance shows strange values, I
> >>> would try some trouble shooting. You could run coef(m2) and check
> whether
> >>> there are actually different intercepts for Prof. Second I would check
> >>> the model assumptions, possibly there is a violation of the assumptions
> >>> that affects model fit (I'd recommend performance::check_model()).
> >>> Furthermore, how many factor levels does Prof have, I assume 3
> according
> >>> to your output? A small number of levels might be problematic, see
> >>> Singman & Kellen, 2019*.
> >>>
> >>> *Singmann, H., & Kellen, D. (2019). An introduction to mixed models for
> >>> experimental psychology. In *New methods in cognitive psychology* (pp.
> >>> 4-31). Routledge.
> >>>
> >>> Hope this helps!
> >>> ------------------------------
> >>> *Von:* R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org>
> im
> >>> Auftrag von Tahsin Ferdous <tahsinferdousuofc at gmail.com>
> >>> *Gesendet:* Dienstag, 2. November 2021 05:57:26
> >>> *An:* r-sig-mixed-models at r-project.org
> >>> *Betreff:* [R-sig-ME] zero variance and standard deviation in random
> >>> effects
> >>>
> >>> Hi,
> >>>
> >>> I am running a mixed model using lmer like this:
> >>>
> >>> m2<-lmer( logSeverity~  Incidence+Year+ (1|Prov), data = prov1,REML =
> >>> FALSE)
> >>>
> >>> Here, prov is my random effect. But I have the result, where the random
> >>> intercept of random effect is zero.
> >>>
> >>> Random effects:
> >>>   Groups   Name        Variance Std.Dev.
> >>>   Prov     (Intercept) 0.00000  0.0000
> >>>   Residual             0.01149  0.1072
> >>> Number of obs: 54, groups:  Prov, 3
> >>>
> >>> Should I still run a mixed model using Prov as a random effect, or I
> run
> >>> regression model here instead of mixed model by removing "Prov".
> >>> My data structure is like this:
> >>>
> >>>     Prov Year Incidence Severity
> >>>    MB 2020 31.5 0.29
> >>>    MB 2019 21.8 0.36
> >>>    MB 2018 20.4 0.23
> >>>    MB 2017 31.1 0.31
> >>>    MB 2016 90.1 1.34
> >>>    MB 2015 63.4 0.5
> >>>    MB 2014 57.5 0.7
> >>>    MB 2013 44.1 0.45
> >>>    MB 2012 42.9 0.8
> >>>    MB 2011 15.6 0.92
> >>>    MB 2010 50.9 1.23
> >>>    MB 2009 32.1 1.56
> >>>    MB 2008 52.4 1.71
> >>>    MB 2007 15.1       0.83
> >>>    MB 2006 4.3       0.65
> >>>    MB 2005 47.7 1.4
> >>>    MB 2004 16.4 1.58
> >>>    MB 2003 39.3 0.33
> >>>    SK 2020 25.7 0.33
> >>>    SK 2019 37.3 0.54
> >>>    SK 2018 14.2 0.32
> >>>    SK 2017 4.8        0.51
> >>>    SK 2016 85.2 1.53
> >>>    SK 2015 53.2 0.57
> >>>    SK 2014 68.1        1.45
> >>>    SK 2013 23.2 0.39
> >>>    SK 2012 49.8 1.14
> >>>    SK 2011 10.6 0.79
> >>>    SK 2010 13.5 1.5
> >>>    SK 2009 6.9       0.56
> >>>    SK 2008 7.6 0.92
> >>>    SK 2007 2.4 0.75
> >>>    SK 2006 0.7 0.58
> >>>    SK 2005 4.1 0.71
> >>>    SK 2004 1.7 0.4
> >>>    SK 2003 1.9 0.09
> >>>    AB 2020 8 0.34
> >>>    AB 2019 28.3 0.52
> >>>    AB 2018 2.8 0.37
> >>>    AB 2017 3.7 0.49
> >>>    AB 2016 32.8 0.59
> >>>    AB 2015 9.2 0.29
> >>>    AB 2014 24.6 0.25
> >>>    AB 2013 17.6 0.4
> >>>    AB 2012 10.3 0.63
> >>>    AB 2011 5.2 0.87
> >>>    AB 2010 3.9 1.68
> >>>    AB 2009 3.2 1.13
> >>>    AB 2008 0.4 0.78
> >>>    AB 2007 0.1 0.45
> >>>    AB 2006 0.1 0.78
> >>>    AB 2005 1.1 1.09
> >>>    AB 2004 1.2 0.82
> >>>    AB 2003 1.2 0.08
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
> --
> Dr. Benjamin Bolker
> Professor, Mathematics & Statistics and Biology, McMaster University
> Director, School of Computational Science and Engineering
> (Acting) Graduate chair, Mathematics & Statistics
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From t@h@|n|erdou@uo|c @end|ng |rom gm@||@com  Fri Nov  5 01:22:24 2021
From: t@h@|n|erdou@uo|c @end|ng |rom gm@||@com (Tahsin Ferdous)
Date: Thu, 4 Nov 2021 18:22:24 -0600
Subject: [R-sig-ME] Mixed model vs GEE
Message-ID: <CAE5DuhuOSzD=haYtgR-u631RDei_9C1n8BVYnPwXvtqF0H0mzw@mail.gmail.com>

Hi all,


I am analyzing repeated measures data. Both the mixed model and generalized
estimating equation are appropriate for my data. In this case, how can I
decide that which one is better (LMM or GEE)? I know that GEE is a *marginal
model*. It seeks to model a population average. Mixed-effect/Multilevel
models are *subject-specific*, or *conditional*, models. Thanks.


Best,

Tahsin

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Fri Nov  5 01:38:24 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Thu, 4 Nov 2021 20:38:24 -0400
Subject: [R-sig-ME] Mixed model vs GEE
In-Reply-To: <CAE5DuhuOSzD=haYtgR-u631RDei_9C1n8BVYnPwXvtqF0H0mzw@mail.gmail.com>
References: <CAE5DuhuOSzD=haYtgR-u631RDei_9C1n8BVYnPwXvtqF0H0mzw@mail.gmail.com>
Message-ID: <739dc508-6a34-23e9-2f89-de0c926a4e51@gmail.com>

    I think that depends on what kind of questions you are asking ... ?? 
(If anyone wants to point to a great resource on marginal vs conditional 
models and when each type is appropriate, that would be great.  I know 
this distinction is discussed in Agresti's _Categorical Data Analysis_ 
book but I don't know if it goes into detail / gives examples about when 
one would want either one ...)

On 11/4/21 8:22 PM, Tahsin Ferdous wrote:
> Hi all,
> 
> 
> I am analyzing repeated measures data. Both the mixed model and generalized
> estimating equation are appropriate for my data. In this case, how can I
> decide that which one is better (LMM or GEE)? I know that GEE is a *marginal
> model*. It seeks to model a population average. Mixed-effect/Multilevel
> models are *subject-specific*, or *conditional*, models. Thanks.
> 
> 
> Best,
> 
> Tahsin
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From m@ch@|oupk@ @end|ng |rom uq@edu@@u  Fri Nov  5 05:01:25 2021
From: m@ch@|oupk@ @end|ng |rom uq@edu@@u (Milani Chaloupka)
Date: Fri, 5 Nov 2021 04:01:25 +0000
Subject: [R-sig-ME] Mixed model vs GEE
In-Reply-To: <739dc508-6a34-23e9-2f89-de0c926a4e51@gmail.com>
References: <CAE5DuhuOSzD=haYtgR-u631RDei_9C1n8BVYnPwXvtqF0H0mzw@mail.gmail.com>
 <739dc508-6a34-23e9-2f89-de0c926a4e51@gmail.com>
Message-ID: <14309503-E20C-4256-84BA-22C638F4D95C@uq.edu.au>

One useful reference is :

Muff S, Held L, Keller L (2016) Marginal or conditional regression models for correlated non-normal data? Methods in Ecology and Evolution 7: 1514?1524. doi: 10.1111/2041-210X.12623

Milani


> On 5 Nov 2021, at 10:38 am, Ben Bolker <bbolker at gmail.com> wrote:
> 
>   I think that depends on what kind of questions you are asking ... ?? (If anyone wants to point to a great resource on marginal vs conditional models and when each type is appropriate, that would be great.  I know this distinction is discussed in Agresti's _Categorical Data Analysis_ book but I don't know if it goes into detail / gives examples about when one would want either one ...)
> 
> On 11/4/21 8:22 PM, Tahsin Ferdous wrote:
>> Hi all,
>> I am analyzing repeated measures data. Both the mixed model and generalized
>> estimating equation are appropriate for my data. In this case, how can I
>> decide that which one is better (LMM or GEE)? I know that GEE is a *marginal
>> model*. It seeks to model a population average. Mixed-effect/Multilevel
>> models are *subject-specific*, or *conditional*, models. Thanks.
>> Best,
>> Tahsin
>> 	[[alternative HTML version deleted]]
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From t@h@|n|erdou@uo|c @end|ng |rom gm@||@com  Fri Nov  5 06:07:13 2021
From: t@h@|n|erdou@uo|c @end|ng |rom gm@||@com (Tahsin Ferdous)
Date: Thu, 4 Nov 2021 23:07:13 -0600
Subject: [R-sig-ME] Mixed model vs GEE
In-Reply-To: <14309503-E20C-4256-84BA-22C638F4D95C@uq.edu.au>
References: <CAE5DuhuOSzD=haYtgR-u631RDei_9C1n8BVYnPwXvtqF0H0mzw@mail.gmail.com>
 <739dc508-6a34-23e9-2f89-de0c926a4e51@gmail.com>
 <14309503-E20C-4256-84BA-22C638F4D95C@uq.edu.au>
Message-ID: <CAE5Duht+V7=ZVh3vAQVLqyPrbJSnmrijhGJbAvmqQ_ZZ95oz9A@mail.gmail.com>

Dear all,

Thanks a lot.

Best,

Tahsin

On Thu, Nov 4, 2021 at 10:02 PM Milani Chaloupka <m.chaloupka at uq.edu.au>
wrote:

> One useful reference is :
>
> Muff S, Held L, Keller L (2016) Marginal or conditional regression models
> for correlated non-normal data? Methods in Ecology and Evolution 7:
> 1514?1524. doi: 10.1111/2041-210X.12623
>
> Milani
>
>
> > On 5 Nov 2021, at 10:38 am, Ben Bolker <bbolker at gmail.com> wrote:
> >
> >   I think that depends on what kind of questions you are asking ... ??
> (If anyone wants to point to a great resource on marginal vs conditional
> models and when each type is appropriate, that would be great.  I know this
> distinction is discussed in Agresti's _Categorical Data Analysis_ book but
> I don't know if it goes into detail / gives examples about when one would
> want either one ...)
> >
> > On 11/4/21 8:22 PM, Tahsin Ferdous wrote:
> >> Hi all,
> >> I am analyzing repeated measures data. Both the mixed model and
> generalized
> >> estimating equation are appropriate for my data. In this case, how can I
> >> decide that which one is better (LMM or GEE)? I know that GEE is a
> *marginal
> >> model*. It seeks to model a population average. Mixed-effect/Multilevel
> >> models are *subject-specific*, or *conditional*, models. Thanks.
> >> Best,
> >> Tahsin
> >>      [[alternative HTML version deleted]]
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From t@h@|n|erdou@uo|c @end|ng |rom gm@||@com  Fri Nov  5 06:10:28 2021
From: t@h@|n|erdou@uo|c @end|ng |rom gm@||@com (Tahsin Ferdous)
Date: Thu, 4 Nov 2021 23:10:28 -0600
Subject: [R-sig-ME] Mixed model for unbalanced data
Message-ID: <CAE5DuhtopeZP8v031Y9D952kOQ1Z2CdgMKardiX1dXzw69hksw@mail.gmail.com>

Dear all,

Can we use unbalanced data for the mixed model with nested random effects?

Best,

Tahsin

	[[alternative HTML version deleted]]


From p@u|@john@on @end|ng |rom g|@@gow@@c@uk  Fri Nov  5 12:51:54 2021
From: p@u|@john@on @end|ng |rom g|@@gow@@c@uk (Paul Johnson)
Date: Fri, 5 Nov 2021 11:51:54 +0000
Subject: [R-sig-ME] Mixed model vs GEE
In-Reply-To: <739dc508-6a34-23e9-2f89-de0c926a4e51@gmail.com>
References: <CAE5DuhuOSzD=haYtgR-u631RDei_9C1n8BVYnPwXvtqF0H0mzw@mail.gmail.com>
 <739dc508-6a34-23e9-2f89-de0c926a4e51@gmail.com>
Message-ID: <DE210BC8-89AF-45D8-8AE1-8C58AEBC6DF0@glasgow.ac.uk>

This might be useful, although it's focussed on non-normal GLMMs, not LMMs. I read it a while ago, but I remember it being excellent:

Marginal or conditional regression models for correlated non-normal data?
Stefanie Muff, Leonhard Held, Lukas F. Keller
https://doi.org/10.1111/2041-210X.12623

"For normally distributed response variables, that is in linear regression, the choice between a marginal and a conditional formulation is not particularly delicate, because the interpretation of conditional and marginal linear regression models turns out to be equivalent. On the other hand, the choice is relevant for non-normal data, as the interpretation of conditional and marginal regression models is usually different."


On 05/11/2021, 00:38, "R-sig-mixed-models on behalf of Ben Bolker" <r-sig-mixed-models-bounces at r-project.org on behalf of bbolker at gmail.com> wrote:

        I think that depends on what kind of questions you are asking ... ?? 
    (If anyone wants to point to a great resource on marginal vs conditional 
    models and when each type is appropriate, that would be great.  I know 
    this distinction is discussed in Agresti's _Categorical Data Analysis_ 
    book but I don't know if it goes into detail / gives examples about when 
    one would want either one ...)

    On 11/4/21 8:22 PM, Tahsin Ferdous wrote:
    > Hi all,
    > 
    > 
    > I am analyzing repeated measures data. Both the mixed model and generalized
    > estimating equation are appropriate for my data. In this case, how can I
    > decide that which one is better (LMM or GEE)? I know that GEE is a *marginal
    > model*. It seeks to model a population average. Mixed-effect/Multilevel
    > models are *subject-specific*, or *conditional*, models. Thanks.
    > 
    > 
    > Best,
    > 
    > Tahsin
    > 
    > 	[[alternative HTML version deleted]]
    > 
    > _______________________________________________
    > R-sig-mixed-models at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
    >

    _______________________________________________
    R-sig-mixed-models at r-project.org mailing list
    https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From me @end|ng |rom ph||||p@|d@y@com  Fri Nov  5 14:22:11 2021
From: me @end|ng |rom ph||||p@|d@y@com (Phillip Alday)
Date: Fri, 5 Nov 2021 08:22:11 -0500
Subject: [R-sig-ME] Mixed model vs GEE
In-Reply-To: <739dc508-6a34-23e9-2f89-de0c926a4e51@gmail.com>
References: <CAE5DuhuOSzD=haYtgR-u631RDei_9C1n8BVYnPwXvtqF0H0mzw@mail.gmail.com>
 <739dc508-6a34-23e9-2f89-de0c926a4e51@gmail.com>
Message-ID: <9067f07b-5ba5-9346-0f0b-3b340a821a34@phillipalday.com>

Dimitris Rizopoulos covers this in his course slides:

http://www.drizopoulos.com/courses/EMC/CE08.pdf

The slides might be a bit math heavy for end users, but big important
assumptions and intuitions are called out in clear language.



On 4/11/21 7:38 pm, Ben Bolker wrote:
> ?? I think that depends on what kind of questions you are asking ... ??
> (If anyone wants to point to a great resource on marginal vs conditional
> models and when each type is appropriate, that would be great.? I know
> this distinction is discussed in Agresti's _Categorical Data Analysis_
> book but I don't know if it goes into detail / gives examples about when
> one would want either one ...)
> 
> On 11/4/21 8:22 PM, Tahsin Ferdous wrote:
>> Hi all,
>>
>>
>> I am analyzing repeated measures data. Both the mixed model and
>> generalized
>> estimating equation are appropriate for my data. In this case, how can I
>> decide that which one is better (LMM or GEE)? I know that GEE is a
>> *marginal
>> model*. It seeks to model a population average. Mixed-effect/Multilevel
>> models are *subject-specific*, or *conditional*, models. Thanks.
>>
>>
>> Best,
>>
>> Tahsin
>>
>> ????[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From me @end|ng |rom ph||||p@|d@y@com  Fri Nov  5 15:20:43 2021
From: me @end|ng |rom ph||||p@|d@y@com (Phillip Alday)
Date: Fri, 5 Nov 2021 09:20:43 -0500
Subject: [R-sig-ME] Mixed model for unbalanced data
In-Reply-To: <CAE5DuhtopeZP8v031Y9D952kOQ1Z2CdgMKardiX1dXzw69hksw@mail.gmail.com>
References: <CAE5DuhtopeZP8v031Y9D952kOQ1Z2CdgMKardiX1dXzw69hksw@mail.gmail.com>
Message-ID: <434e4c2a-c4c4-1dc6-1392-88b4b4cd92e5@phillipalday.com>

Yes.

There will of course be greater uncertainty for conditions/groups with
less data.

The best way to see how this impacts your inference is to simulate
balanced and unbalanced data for your hypothesis and look at the
difference in estimates, standard errors, etc.


On 5/11/21 12:10 am, Tahsin Ferdous wrote:
> Dear all,
> 
> Can we use unbalanced data for the mixed model with nested random effects?
> 
> Best,
> 
> Tahsin
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From Ar|e|@Mu|doon @end|ng |rom oregon@t@te@edu  Fri Nov  5 15:32:52 2021
From: Ar|e|@Mu|doon @end|ng |rom oregon@t@te@edu (Muldoon, Ariel)
Date: Fri, 5 Nov 2021 14:32:52 +0000
Subject: [R-sig-ME] Mixed model vs GEE
In-Reply-To: <9067f07b-5ba5-9346-0f0b-3b340a821a34@phillipalday.com>
References: <CAE5DuhuOSzD=haYtgR-u631RDei_9C1n8BVYnPwXvtqF0H0mzw@mail.gmail.com>
 <739dc508-6a34-23e9-2f89-de0c926a4e51@gmail.com>
 <9067f07b-5ba5-9346-0f0b-3b340a821a34@phillipalday.com>
Message-ID: <CO6PR11MB56027A32A3145B17B2E0917AEA8E9@CO6PR11MB5602.namprd11.prod.outlook.com>

I remember enjoying the discussion of marginal vs conditional inference in Stroup's book Generalized Linear Mixed Models: Modern Concepts, Methods and Applications . It is not in front of me at the moment but I think this is covered chapter 3. He specifically discusses how the issue affects non-normal GLMM's and I believe he first shows an example of the non-issue in (normal) LMM vs GEE and then goes on to a binomial example. There is also a brief overview of when/why we might want conditional vs marginal inference (he seems to come down hard on the side of conditional).
________________________________
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of Phillip Alday <me at phillipalday.com>
Sent: Friday, November 5, 2021 6:22 AM
To: Ben Bolker <bbolker at gmail.com>; r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] Mixed model vs GEE

[This email originated from outside of OSU. Use caution with links and attachments.]

Dimitris Rizopoulos covers this in his course slides:

https://nam04.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.drizopoulos.com%2Fcourses%2FEMC%2FCE08.pdf&amp;data=04%7C01%7Cariel.muldoon%40oregonstate.edu%7C38f85934acc948fe154d08d9a05f580f%7Cce6d05e13c5e4d6287a84c4a2713c113%7C0%7C0%7C637717154499841395%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000&amp;sdata=CqC3kwu%2FeyuX4n5n4kAD8ff69XKC2MWh%2BaWqjYUPwZo%3D&amp;reserved=0

The slides might be a bit math heavy for end users, but big important
assumptions and intuitions are called out in clear language.



On 4/11/21 7:38 pm, Ben Bolker wrote:
>    I think that depends on what kind of questions you are asking ... ??
> (If anyone wants to point to a great resource on marginal vs conditional
> models and when each type is appropriate, that would be great.  I know
> this distinction is discussed in Agresti's _Categorical Data Analysis_
> book but I don't know if it goes into detail / gives examples about when
> one would want either one ...)
>
> On 11/4/21 8:22 PM, Tahsin Ferdous wrote:
>> Hi all,
>>
>>
>> I am analyzing repeated measures data. Both the mixed model and
>> generalized
>> estimating equation are appropriate for my data. In this case, how can I
>> decide that which one is better (LMM or GEE)? I know that GEE is a
>> *marginal
>> model*. It seeks to model a population average. Mixed-effect/Multilevel
>> models are *subject-specific*, or *conditional*, models. Thanks.
>>
>>
>> Best,
>>
>> Tahsin
>>
>>     [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://nam04.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=04%7C01%7Cariel.muldoon%40oregonstate.edu%7C38f85934acc948fe154d08d9a05f580f%7Cce6d05e13c5e4d6287a84c4a2713c113%7C0%7C0%7C637717154499841395%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000&amp;sdata=xoVPM9dnKWBYmFHlA1mGu9fgWw%2B9NzpdY9FWWj%2BO1H4%3D&amp;reserved=0
>>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://nam04.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=04%7C01%7Cariel.muldoon%40oregonstate.edu%7C38f85934acc948fe154d08d9a05f580f%7Cce6d05e13c5e4d6287a84c4a2713c113%7C0%7C0%7C637717154499851348%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000&amp;sdata=SJKHcYbKmFUExoGZaxtg43qddgoY%2BL56rEMhWlSnS6s%3D&amp;reserved=0

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://nam04.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=04%7C01%7Cariel.muldoon%40oregonstate.edu%7C38f85934acc948fe154d08d9a05f580f%7Cce6d05e13c5e4d6287a84c4a2713c113%7C0%7C0%7C637717154499851348%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000&amp;sdata=SJKHcYbKmFUExoGZaxtg43qddgoY%2BL56rEMhWlSnS6s%3D&amp;reserved=0

	[[alternative HTML version deleted]]


From cvonende @end|ng |rom n|u@edu  Sat Nov  6 23:34:02 2021
From: cvonende @end|ng |rom n|u@edu (Carl Von Ende)
Date: Sat, 6 Nov 2021 22:34:02 +0000
Subject: [R-sig-ME] Mixed model vs GEE
Message-ID: <37E4D09E-9CFF-484F-9013-F93B86D8B0FA@niu.edu>

Two Wiley references  that specifically  GEE might be useful.  They both are listed in the References of the Muff et al. (2016) paper cited below in Message 1. 

1. Applied Longitudinal Analysis, 2nd Edition, 2011
by Garrett Fitzmaurice, Nan Laird & James Ware'

Then spend considerable time comparing LMM vs GEE

https://content.sph.harvard.edu/fitzmaur/ala2e/

The software used primarily is SAS, but there are a few R programs on the above website.  

2. Generalized Estimating Equations, 2nd Edition, 2013 

The authors use the R packages geepack, gee, and vags, as well Stata. 


?On 11/5/21, 9:31 AM, "R-sig-mixed-models on behalf of r-sig-mixed-models-request at r-project.org" <r-sig-mixed-models-bounces at r-project.org on behalf of r-sig-mixed-models-request at r-project.org> wrote:

    Send R-sig-mixed-models mailing list submissions to
    	r-sig-mixed-models at r-project.org

    To subscribe or unsubscribe via the World Wide Web, visit
    	https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
    or, via email, send a message with subject or body 'help' to
    	r-sig-mixed-models-request at r-project.org

    You can reach the person managing the list at
    	r-sig-mixed-models-owner at r-project.org

    When replying, please edit your Subject line so it is more specific
    than "Re: Contents of R-sig-mixed-models digest..."


    Today's Topics:

       1. Re: Mixed model vs GEE (Paul Johnson)
       2. Re: Mixed model vs GEE (Phillip Alday)
       3. Re: Mixed model for unbalanced data (Phillip Alday)

    ----------------------------------------------------------------------

    Message: 1
    Date: Fri, 5 Nov 2021 11:51:54 +0000
    From: Paul Johnson <paul.johnson at glasgow.ac.uk>
    To: Ben Bolker <bbolker at gmail.com>, "r-sig-mixed-models at r-project.org"
    	<r-sig-mixed-models at r-project.org>
    Subject: Re: [R-sig-ME] Mixed model vs GEE
    Message-ID: <DE210BC8-89AF-45D8-8AE1-8C58AEBC6DF0 at glasgow.ac.uk>
    Content-Type: text/plain; charset="utf-8"

    This might be useful, although it's focussed on non-normal GLMMs, not LMMs. I read it a while ago, but I remember it being excellent:

    Marginal or conditional regression models for correlated non-normal data?
    Stefanie Muff, Leonhard Held, Lukas F. Keller
    https://doi.org/10.1111/2041-210X.12623

    "For normally distributed response variables, that is in linear regression, the choice between a marginal and a conditional formulation is not particularly delicate, because the interpretation of conditional and marginal linear regression models turns out to be equivalent. On the other hand, the choice is relevant for non-normal data, as the interpretation of conditional and marginal regression models is usually different."


    On 05/11/2021, 00:38, "R-sig-mixed-models on behalf of Ben Bolker" <r-sig-mixed-models-bounces at r-project.org on behalf of bbolker at gmail.com> wrote:

            I think that depends on what kind of questions you are asking ... ?? 
        (If anyone wants to point to a great resource on marginal vs conditional 
        models and when each type is appropriate, that would be great.  I know 
        this distinction is discussed in Agresti's _Categorical Data Analysis_ 
        book but I don't know if it goes into detail / gives examples about when 
        one would want either one ...)

        On 11/4/21 8:22 PM, Tahsin Ferdous wrote:
        > Hi all,
        > 
        > 
        > I am analyzing repeated measures data. Both the mixed model and generalized
        > estimating equation are appropriate for my data. In this case, how can I
        > decide that which one is better (LMM or GEE)? I know that GEE is a *marginal
        > model*. It seeks to model a population average. Mixed-effect/Multilevel
        > models are *subject-specific*, or *conditional*, models. Thanks.
        > 
        > 
        > Best,
        > 
        > Tahsin
        > 
        > 	[[alternative HTML version deleted]]
        > 
        > _______________________________________________
        > R-sig-mixed-models at r-project.org mailing list
        > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
        >

        _______________________________________________
        R-sig-mixed-models at r-project.org mailing list
        https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



    ------------------------------

    Message: 2
    Date: Fri, 5 Nov 2021 08:22:11 -0500
    From: Phillip Alday <me at phillipalday.com>
    To: Ben Bolker <bbolker at gmail.com>, r-sig-mixed-models at r-project.org
    Subject: Re: [R-sig-ME] Mixed model vs GEE
    Message-ID: <9067f07b-5ba5-9346-0f0b-3b340a821a34 at phillipalday.com>
    Content-Type: text/plain; charset="utf-8"

    Dimitris Rizopoulos covers this in his course slides:

    http://www.drizopoulos.com/courses/EMC/CE08.pdf

    The slides might be a bit math heavy for end users, but big important
    assumptions and intuitions are called out in clear language.



    On 4/11/21 7:38 pm, Ben Bolker wrote:
    >    I think that depends on what kind of questions you are asking ... ??
    > (If anyone wants to point to a great resource on marginal vs conditional
    > models and when each type is appropriate, that would be great.  I know
    > this distinction is discussed in Agresti's _Categorical Data Analysis_
    > book but I don't know if it goes into detail / gives examples about when
    > one would want either one ...)
    > 
    > On 11/4/21 8:22 PM, Tahsin Ferdous wrote:
    >> Hi all,
    >>
    >>
    >> I am analyzing repeated measures data. Both the mixed model and
    >> generalized
    >> estimating equation are appropriate for my data. In this case, how can I
    >> decide that which one is better (LMM or GEE)? I know that GEE is a
    >> *marginal
    >> model*. It seeks to model a population average. Mixed-effect/Multilevel
    >> models are *subject-specific*, or *conditional*, models. Thanks.
    >>
    >>
    >> Best,
    >>
    >> Tahsin
    >>
    >>     [[alternative HTML version deleted]]
    >>
    >> _______________________________________________
    >> R-sig-mixed-models at r-project.org mailing list
    >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
    >>
    > 
    > _______________________________________________
    > R-sig-mixed-models at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models




    ------------------------------

    Message: 3
    Date: Fri, 5 Nov 2021 09:20:43 -0500
    From: Phillip Alday <me at phillipalday.com>
    To: Tahsin Ferdous <tahsinferdousuofc at gmail.com>,
    	r-sig-mixed-models at r-project.org, Ben Bolker <bbolker at gmail.com>
    Subject: Re: [R-sig-ME] Mixed model for unbalanced data
    Message-ID: <434e4c2a-c4c4-1dc6-1392-88b4b4cd92e5 at phillipalday.com>
    Content-Type: text/plain; charset="utf-8"

    Yes.

    There will of course be greater uncertainty for conditions/groups with
    less data.

    The best way to see how this impacts your inference is to simulate
    balanced and unbalanced data for your hypothesis and look at the
    difference in estimates, standard errors, etc.


    On 5/11/21 12:10 am, Tahsin Ferdous wrote:
    > Dear all,
    > 
    > Can we use unbalanced data for the mixed model with nested random effects?
    > 
    > Best,
    > 
    > Tahsin
    > 
    > 	[[alternative HTML version deleted]]
    > 
    > _______________________________________________
    > R-sig-mixed-models at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
    >




    ------------------------------

    Subject: Digest Footer

    _______________________________________________
    R-sig-mixed-models mailing list
    R-sig-mixed-models at r-project.org
    https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


    ------------------------------

    End of R-sig-mixed-models Digest, Vol 179, Issue 8
    **************************************************


From |@w|@wt @end|ng |rom gm@||@com  Sun Nov  7 23:20:42 2021
From: |@w|@wt @end|ng |rom gm@||@com (Timothy MacKenzie)
Date: Sun, 7 Nov 2021 16:20:42 -0600
Subject: [R-sig-ME] Grouping variables technically suitable for modeling
Message-ID: <CADreqiwk+9DqbfmbGYDv4fq8jHWq9TGRxdB_b-G=uSkC_4bMNA@mail.gmail.com>

Dear Experts,

Apologies if this question has come up before. But I'm looking for
published references that provide guidance on when one or more grouping
variables that theoretically need to be random factors can also
"technically" be used as random factors?

For example, I have heard for a grouping variable to be technically taken
as a random factor, it needs to have at least 10 or so unique categories?
(Any reference to confirm or disconfirm this?)

For example, I have heard for two grouping variables to be technically
taken as random factors, they each need to have a sufficiently different
number of unique categories relative to the other one. Otherwise, their
variance components can't be distinguished from one another and thus only
one of them can be taken as random, not both (Any reference to confirm or
disconfirm this?)

Thanks,
Tim M

	[[alternative HTML version deleted]]


From @neup@ne2 @end|ng |rom @tudent@g@u@edu  Mon Nov  8 12:49:25 2021
From: @neup@ne2 @end|ng |rom @tudent@g@u@edu (Suresh N Neupane)
Date: Mon, 8 Nov 2021 11:49:25 +0000
Subject: [R-sig-ME] Using Robust Standard Errors lme4
Message-ID: <MWHPR0101MB31986D54DDD4BACBA61E4EBDA3919@MWHPR0101MB3198.prod.exchangelabs.com>

Dear all,
I am using lme4 package to run a hierarchical logistic regression model (with random county effect) for my binomial dependent variable, COVID death (0/1). This is a very large dataset with ~ 8 million observations.
I need to find the robust standard error but was not sure about any package. I tried robustlmm (although my DV is not continuous) and got this error when used MerDeriv (sandwich):
Error in UseMethod("estfun") :
no applicable method for 'estfun' applied to an object of class "c('glmerMod', 'merMod')"
The real tricky part is it takes several hours to compute because of the dataset length.
All I need is to get robust standard error values.
I already fit the models:
fit <- glmer(death ~ (1|county_fips_code) + IV).
Thank you so much,
Suresh Neupane


	[[alternative HTML version deleted]]


From |@brun@ @end|ng |rom udc@e@  Mon Nov  8 14:51:34 2021
From: |@brun@ @end|ng |rom udc@e@ (Fernando Pedro Bruna Quintas)
Date: Mon, 8 Nov 2021 13:51:34 +0000
Subject: [R-sig-ME] Using Robust Standard Errors lme4
In-Reply-To: <MWHPR0101MB31986D54DDD4BACBA61E4EBDA3919@MWHPR0101MB3198.prod.exchangelabs.com>
References: <MWHPR0101MB31986D54DDD4BACBA61E4EBDA3919@MWHPR0101MB3198.prod.exchangelabs.com>
Message-ID: <PAXPR02MB7798D370AD8B329E178F9FBA92919@PAXPR02MB7798.eurprd02.prod.outlook.com>


Hi,

I have tried to do that with lme4 and the function tab_model() of pacakge sjPlot. That works for other types of models, but it did not worked for lme4. Try WeMix package, which mimic Stata?s mixed function.

However, I have substantive doubts about this. Do  robust standard errors make sense in multilevel models?. For instance, using clustered standard errors is a way of introducing level-two correlations in OLS, but in hierarchical models we are already modelling that correlation. Additionally, there are more general doubts about that. See:
https://www.nber.org/papers/w24003

I would like to listen more thoughts about robust and clustered standard errors in multilevel models, both from the philosophical point of view and the practical one.

Best,

Fernando Bruna
Department of Economics
Universidade da Corunha, Spain.




________________________________
De: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> en nombre de Suresh N Neupane via R-sig-mixed-models <r-sig-mixed-models at r-project.org>
Enviado: lunes, 8 de noviembre de 2021 12:49
Para: r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>
Asunto: [R-sig-ME] Using Robust Standard Errors lme4

Dear all,
I am using lme4 package to run a hierarchical logistic regression model (with random county effect) for my binomial dependent variable, COVID death (0/1). This is a very large dataset with ~ 8 million observations.
I need to find the robust standard error but was not sure about any package. I tried robustlmm (although my DV is not continuous) and got this error when used MerDeriv (sandwich):
Error in UseMethod("estfun") :
no applicable method for 'estfun' applied to an object of class "c('glmerMod', 'merMod')"
The real tricky part is it takes several hours to compute because of the dataset length.
All I need is to get robust standard error values.
I already fit the models:
fit <- glmer(death ~ (1|county_fips_code) + IV).
Thank you so much,
Suresh Neupane


        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Tue Nov  9 02:34:35 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Mon, 8 Nov 2021 20:34:35 -0500
Subject: [R-sig-ME] Grouping variables technically suitable for modeling
In-Reply-To: <CADreqiwk+9DqbfmbGYDv4fq8jHWq9TGRxdB_b-G=uSkC_4bMNA@mail.gmail.com>
References: <CADreqiwk+9DqbfmbGYDv4fq8jHWq9TGRxdB_b-G=uSkC_4bMNA@mail.gmail.com>
Message-ID: <6b8abdb3-b60d-8869-b0f7-43b7294e140a@gmail.com>


    This is a bit of a "how long is a piece of string" question ...


   The "5-6 levels of a grouping variable" rule of thumb is quoted in 
various places: a variety of those references (Gelman and Hill 2006, 
K?ry and Royle 2015, Harrison et al 2018, Arnqvist 2020) are collected 
by Gomes 
(https://www.biorxiv.org/content/10.1101/2021.04.11.439357v2.full).

   I sort of see what you mean by your second paragraph, but can you 
give an example?


On 11/7/21 5:20 PM, Timothy MacKenzie wrote:
> Dear Experts,
> 
> Apologies if this question has come up before. But I'm looking for
> published references that provide guidance on when one or more grouping
> variables that theoretically need to be random factors can also
> "technically" be used as random factors?
> 
> For example, I have heard for a grouping variable to be technically taken
> as a random factor, it needs to have at least 10 or so unique categories?
> (Any reference to confirm or disconfirm this?)
> 
> For example, I have heard for two grouping variables to be technically
> taken as random factors, they each need to have a sufficiently different
> number of unique categories relative to the other one. Otherwise, their
> variance components can't be distinguished from one another and thus only
> one of them can be taken as random, not both (Any reference to confirm or
> disconfirm this?)
> 
> Thanks,
> Tim M
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From d@|uedecke @end|ng |rom uke@de  Tue Nov  9 10:32:58 2021
From: d@|uedecke @end|ng |rom uke@de (=?iso-8859-1?Q?Daniel_L=FCdecke?=)
Date: Tue, 9 Nov 2021 10:32:58 +0100
Subject: [R-sig-ME] Using Robust Standard Errors lme4
In-Reply-To: <MWHPR0101MB31986D54DDD4BACBA61E4EBDA3919@MWHPR0101MB3198.prod.exchangelabs.com>
References: <MWHPR0101MB31986D54DDD4BACBA61E4EBDA3919@MWHPR0101MB3198.prod.exchangelabs.com>
Message-ID: <001e01d7d54c$c87d13b0$59773b10$@uke.de>

Hi Suresh,

you could try the "parameters" package, which should (easily) return
different types of robust standard errors, including cluster-robust standard
errors for mixed models:

https://easystats.github.io/parameters/articles/model_parameters_robust.html

Maybe you try this out on a very small subset of your model to see if it
works. Also, since the "model_parameters()" function includes random effects
variances by default, you may set the effects-argument to "fixed" to speed
up computation. The call to the function could then look like something like
this:

model_parameters(
  model,
  effects = "fixed",
  robust = TRUE,
  vcov_estimation = "CL",
  vcov_type = "HC1",
  vcov_args = list(cluster = <your cluster variable from the data>)
)


Best
Daniel

-----Urspr?ngliche Nachricht-----
Von: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> Im
Auftrag von Suresh N Neupane via R-sig-mixed-models
Gesendet: Montag, 8. November 2021 12:49
An: r-sig-mixed-models at r-project.org
Betreff: [R-sig-ME] Using Robust Standard Errors lme4

Dear all,
I am using lme4 package to run a hierarchical logistic regression model
(with random county effect) for my binomial dependent variable, COVID death
(0/1). This is a very large dataset with ~ 8 million observations.
I need to find the robust standard error but was not sure about any package.
I tried robustlmm (although my DV is not continuous) and got this error when
used MerDeriv (sandwich):
Error in UseMethod("estfun") :
no applicable method for 'estfun' applied to an object of class
"c('glmerMod', 'merMod')"
The real tricky part is it takes several hours to compute because of the
dataset length.
All I need is to get robust standard error values.
I already fit the models:
fit <- glmer(death ~ (1|county_fips_code) + IV).
Thank you so much,
Suresh Neupane


	[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

--

_____________________________________________________________________

Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen Rechts; Gerichtsstand: Hamburg | www.uke.de
Vorstandsmitglieder: Prof. Dr. Burkhard G?ke (Vorsitzender), Joachim Pr?l?, Prof. Dr. Blanche Schwappach-Pignataro, Marya Verdel
_____________________________________________________________________

SAVE PAPER - THINK BEFORE PRINTING


From |@w|@wt @end|ng |rom gm@||@com  Tue Nov  9 15:18:28 2021
From: |@w|@wt @end|ng |rom gm@||@com (Timothy MacKenzie)
Date: Tue, 9 Nov 2021 08:18:28 -0600
Subject: [R-sig-ME] Grouping variables technically suitable for modeling
In-Reply-To: <6b8abdb3-b60d-8869-b0f7-43b7294e140a@gmail.com>
References: <CADreqiwk+9DqbfmbGYDv4fq8jHWq9TGRxdB_b-G=uSkC_4bMNA@mail.gmail.com>
 <6b8abdb3-b60d-8869-b0f7-43b7294e140a@gmail.com>
Message-ID: <CADreqiw47aY_KRtHuPtRe8xbKOFZ27weX1c_yEBrcQC6W7Kp1Q@mail.gmail.com>

Dear Ben,

Thank you for sharing the references regarding my first question.

Regarding my second question, I simply mean if we have say ID1 and ID2,
then for ID2 to be distinguishably nested in ID1, it needs to have a
different unique categories relative to those of ID1.

For example, if ID1 has 120 unique categories and ID2 has 130
unique categories nested in ID1, then the variance components for ID1 and
ID2 are not distinguishable from each other. As a result, only one of them
can be added as a random effect; either (1 | ID1) or (1 | |ID2), but not (1
| ID1/ID2).

Is this correct and is there a published reference confirming or
disconfirming this?

Thanks,
Tim M

On Mon, Nov 8, 2021 at 7:35 PM Ben Bolker <bbolker at gmail.com> wrote:

>
>     This is a bit of a "how long is a piece of string" question ...
>
>
>    The "5-6 levels of a grouping variable" rule of thumb is quoted in
> various places: a variety of those references (Gelman and Hill 2006,
> K?ry and Royle 2015, Harrison et al 2018, Arnqvist 2020) are collected
> by Gomes
> (https://www.biorxiv.org/content/10.1101/2021.04.11.439357v2.full).
>
>    I sort of see what you mean by your second paragraph, but can you
> give an example?
>
>
> On 11/7/21 5:20 PM, Timothy MacKenzie wrote:
> > Dear Experts,
> >
> > Apologies if this question has come up before. But I'm looking for
> > published references that provide guidance on when one or more grouping
> > variables that theoretically need to be random factors can also
> > "technically" be used as random factors?
> >
> > For example, I have heard for a grouping variable to be technically taken
> > as a random factor, it needs to have at least 10 or so unique categories?
> > (Any reference to confirm or disconfirm this?)
> >
> > For example, I have heard for two grouping variables to be technically
> > taken as random factors, they each need to have a sufficiently different
> > number of unique categories relative to the other one. Otherwise, their
> > variance components can't be distinguished from one another and thus only
> > one of them can be taken as random, not both (Any reference to confirm or
> > disconfirm this?)
> >
> > Thanks,
> > Tim M
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From th|erry@onke||nx @end|ng |rom |nbo@be  Tue Nov  9 16:02:59 2021
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Tue, 9 Nov 2021 16:02:59 +0100
Subject: [R-sig-ME] Grouping variables technically suitable for modeling
In-Reply-To: <CADreqiw47aY_KRtHuPtRe8xbKOFZ27weX1c_yEBrcQC6W7Kp1Q@mail.gmail.com>
References: <CADreqiwk+9DqbfmbGYDv4fq8jHWq9TGRxdB_b-G=uSkC_4bMNA@mail.gmail.com>
 <6b8abdb3-b60d-8869-b0f7-43b7294e140a@gmail.com>
 <CADreqiw47aY_KRtHuPtRe8xbKOFZ27weX1c_yEBrcQC6W7Kp1Q@mail.gmail.com>
Message-ID: <CAJuCY5w03buCp-BqBOyA9BRd5wYn-YJew3DkB_f=Wo+PpLiooQ@mail.gmail.com>

Dear Timothy,

I would expect in your example that the combined effect of ID1 and ID2 will
be more or less equally split over ID1 and ID2. As this would yield a lower
penalty then attributing the effect fully to either ID1 or ID2. Hence the
random effect variances of 1|ID1/ID2 will be a lot smaller than 1|ID1 or
1|ID2.

As ID2 defines almost the same grouping as ID1, it doesn't make sense to
include both of them in the model.

I have no reference at hand for this. Just common sense.

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op di 9 nov. 2021 om 15:19 schreef Timothy MacKenzie <fswfswt at gmail.com>:

> Dear Ben,
>
> Thank you for sharing the references regarding my first question.
>
> Regarding my second question, I simply mean if we have say ID1 and ID2,
> then for ID2 to be distinguishably nested in ID1, it needs to have a
> different unique categories relative to those of ID1.
>
> For example, if ID1 has 120 unique categories and ID2 has 130
> unique categories nested in ID1, then the variance components for ID1 and
> ID2 are not distinguishable from each other. As a result, only one of them
> can be added as a random effect; either (1 | ID1) or (1 | |ID2), but not (1
> | ID1/ID2).
>
> Is this correct and is there a published reference confirming or
> disconfirming this?
>
> Thanks,
> Tim M
>
> On Mon, Nov 8, 2021 at 7:35 PM Ben Bolker <bbolker at gmail.com> wrote:
>
> >
> >     This is a bit of a "how long is a piece of string" question ...
> >
> >
> >    The "5-6 levels of a grouping variable" rule of thumb is quoted in
> > various places: a variety of those references (Gelman and Hill 2006,
> > K?ry and Royle 2015, Harrison et al 2018, Arnqvist 2020) are collected
> > by Gomes
> > (https://www.biorxiv.org/content/10.1101/2021.04.11.439357v2.full).
> >
> >    I sort of see what you mean by your second paragraph, but can you
> > give an example?
> >
> >
> > On 11/7/21 5:20 PM, Timothy MacKenzie wrote:
> > > Dear Experts,
> > >
> > > Apologies if this question has come up before. But I'm looking for
> > > published references that provide guidance on when one or more grouping
> > > variables that theoretically need to be random factors can also
> > > "technically" be used as random factors?
> > >
> > > For example, I have heard for a grouping variable to be technically
> taken
> > > as a random factor, it needs to have at least 10 or so unique
> categories?
> > > (Any reference to confirm or disconfirm this?)
> > >
> > > For example, I have heard for two grouping variables to be technically
> > > taken as random factors, they each need to have a sufficiently
> different
> > > number of unique categories relative to the other one. Otherwise, their
> > > variance components can't be distinguished from one another and thus
> only
> > > one of them can be taken as random, not both (Any reference to confirm
> or
> > > disconfirm this?)
> > >
> > > Thanks,
> > > Tim M
> > >
> > >       [[alternative HTML version deleted]]
> > >
> > > _______________________________________________
> > > R-sig-mixed-models at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > >
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From |@w|@wt @end|ng |rom gm@||@com  Tue Nov  9 18:30:49 2021
From: |@w|@wt @end|ng |rom gm@||@com (Timothy MacKenzie)
Date: Tue, 9 Nov 2021 11:30:49 -0600
Subject: [R-sig-ME] Grouping variables technically suitable for modeling
In-Reply-To: <CAJuCY5w03buCp-BqBOyA9BRd5wYn-YJew3DkB_f=Wo+PpLiooQ@mail.gmail.com>
References: <CADreqiwk+9DqbfmbGYDv4fq8jHWq9TGRxdB_b-G=uSkC_4bMNA@mail.gmail.com>
 <6b8abdb3-b60d-8869-b0f7-43b7294e140a@gmail.com>
 <CADreqiw47aY_KRtHuPtRe8xbKOFZ27weX1c_yEBrcQC6W7Kp1Q@mail.gmail.com>
 <CAJuCY5w03buCp-BqBOyA9BRd5wYn-YJew3DkB_f=Wo+PpLiooQ@mail.gmail.com>
Message-ID: <CADreqiwAE8-KhoUZ2PonOYrx4jvqFpfb87+3QXtJ6HQqje40Qg@mail.gmail.com>

Dear Thierry,

That "As ID2 defines almost the same grouping as ID1, it doesn't make
sense to include both of them in the model." makes good sense.

Thanks!
Tim M

On Tue, Nov 9, 2021 at 9:03 AM Thierry Onkelinx
<thierry.onkelinx at inbo.be> wrote:
>
> Dear Timothy,
>
> I would expect in your example that the combined effect of ID1 and ID2 will be more or less equally split over ID1 and ID2. As this would yield a lower penalty then attributing the effect fully to either ID1 or ID2. Hence the random effect variances of 1|ID1/ID2 will be a lot smaller than 1|ID1 or 1|ID2.
>
> As ID2 defines almost the same grouping as ID1, it doesn't make sense to include both of them in the model.
>
> I have no reference at hand for this. Just common sense.
>
> ir. Thierry Onkelinx
> Statisticus / Statistician
>
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Havenlaan 88 bus 73, 1000 Brussel
> www.inbo.be
>
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey
> ///////////////////////////////////////////////////////////////////////////////////////////
>
>
>
>
> Op di 9 nov. 2021 om 15:19 schreef Timothy MacKenzie <fswfswt at gmail.com>:
>>
>> Dear Ben,
>>
>> Thank you for sharing the references regarding my first question.
>>
>> Regarding my second question, I simply mean if we have say ID1 and ID2,
>> then for ID2 to be distinguishably nested in ID1, it needs to have a
>> different unique categories relative to those of ID1.
>>
>> For example, if ID1 has 120 unique categories and ID2 has 130
>> unique categories nested in ID1, then the variance components for ID1 and
>> ID2 are not distinguishable from each other. As a result, only one of them
>> can be added as a random effect; either (1 | ID1) or (1 | |ID2), but not (1
>> | ID1/ID2).
>>
>> Is this correct and is there a published reference confirming or
>> disconfirming this?
>>
>> Thanks,
>> Tim M
>>
>> On Mon, Nov 8, 2021 at 7:35 PM Ben Bolker <bbolker at gmail.com> wrote:
>>
>> >
>> >     This is a bit of a "how long is a piece of string" question ...
>> >
>> >
>> >    The "5-6 levels of a grouping variable" rule of thumb is quoted in
>> > various places: a variety of those references (Gelman and Hill 2006,
>> > K?ry and Royle 2015, Harrison et al 2018, Arnqvist 2020) are collected
>> > by Gomes
>> > (https://www.biorxiv.org/content/10.1101/2021.04.11.439357v2.full).
>> >
>> >    I sort of see what you mean by your second paragraph, but can you
>> > give an example?
>> >
>> >
>> > On 11/7/21 5:20 PM, Timothy MacKenzie wrote:
>> > > Dear Experts,
>> > >
>> > > Apologies if this question has come up before. But I'm looking for
>> > > published references that provide guidance on when one or more grouping
>> > > variables that theoretically need to be random factors can also
>> > > "technically" be used as random factors?
>> > >
>> > > For example, I have heard for a grouping variable to be technically taken
>> > > as a random factor, it needs to have at least 10 or so unique categories?
>> > > (Any reference to confirm or disconfirm this?)
>> > >
>> > > For example, I have heard for two grouping variables to be technically
>> > > taken as random factors, they each need to have a sufficiently different
>> > > number of unique categories relative to the other one. Otherwise, their
>> > > variance components can't be distinguished from one another and thus only
>> > > one of them can be taken as random, not both (Any reference to confirm or
>> > > disconfirm this?)
>> > >
>> > > Thanks,
>> > > Tim M
>> > >
>> > >       [[alternative HTML version deleted]]
>> > >
>> > > _______________________________________________
>> > > R-sig-mixed-models at r-project.org mailing list
>> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> > >
>> >
>> > _______________________________________________
>> > R-sig-mixed-models at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From |@keyh@n|h@ @end|ng |rom gm@||@com  Tue Nov  9 19:36:54 2021
From: |@keyh@n|h@ @end|ng |rom gm@||@com (Farzad Keyhan)
Date: Tue, 9 Nov 2021 12:36:54 -0600
Subject: [R-sig-ME] When a higher level can't be modeled due to one row
Message-ID: <CAEvy2r0SZJS0=R8xXatuu1hpA2hMFgerPxt43m9HTP0fkK2oKA@mail.gmail.com>

Dear Colleagues,

I initially posted my query on the meta-analysis SIG. But I realized
my question is related to multilevel modeling.

Below is my data structure. If in row # 3, "measure" was 2 (instead of
1), then, I could model "measure" as a level above "study":

 (1 | measure / study / outcome)

But right now, because in study 2 (rows # 3 and 4) "measure" can vary,
"measure" can't be considered a level above "study".

On the other hand, because "measure" varies only in one "study" level
(i.e., study 2), I can't model "measure" as a crossed effect with
"study" either:

 (1 | study / outcome) + (1 | measure)

So, to model "measure" as a random factor what can we do?

Best,
Fred
   measure  study  outcome
   1              1          1
   1              1          2
# 1              2          1<--row #3
   2              2          1
   1              3          3
   1              3          2
   2              4          3
   9              5          1
   9              6          2


From d@|uedecke @end|ng |rom uke@de  Tue Nov  9 22:19:30 2021
From: d@|uedecke @end|ng |rom uke@de (=?UTF-8?Q?Daniel_L=C3=BCdecke?=)
Date: Tue, 9 Nov 2021 22:19:30 +0100
Subject: [R-sig-ME] Using Robust Standard Errors lme4
In-Reply-To: <MWHPR0101MB3198819EF6CC17B29082EB70A3929@MWHPR0101MB3198.prod.exchangelabs.com>
References: <MWHPR0101MB31986D54DDD4BACBA61E4EBDA3919@MWHPR0101MB3198.prod.exchangelabs.com>
 <001e01d7d54c$c87d13b0$59773b10$@uke.de>
 <MWHPR0101MB3198819EF6CC17B29082EB70A3929@MWHPR0101MB3198.prod.exchangelabs.com>
Message-ID: <CANiAikHG3g8J+z66e=fXjm2uxPNeq2c7Gg8k0fjomfzxwgWeMw@mail.gmail.com>

Hi Suresh,
I just tried to find an example with glmer(), but it indeed looks like the
clubSandwich package only supports lmer() models, not glmer(). So my
suggested approach unfortunately doesn't seem to work.

Best
Daniel

Am Di., 9. Nov. 2021 um 17:24 Uhr schrieb Suresh N Neupane <
sneupane2 at student.gsu.edu>:

> Hi Daniel,
> Thank you so much for your suggestions. I tried that but it gives me an
> error:
>
> Error in UseMethod("estfun") :
>   no applicable method for 'estfun' applied to an object of class
> "c('glmerMod', 'merMod')"
>
> My DV is death (0/1) and IV other variables:
> Model: (with random county effects):
> fit <- glmer(death ~ (1|county_fips_code) +white + black + pop.density ,
> family = binomial("logit"), nAGQ=0, data = data.thesis)
>  I tried the code you sent and used "county_fips_code" as my cluster
> variable but it says did not find "county_fips_code".
> I was able to use parameters::model_parameters(fit) to extract some info
> (This is great!) such as;
>  Parameter     |  Log-Odds |   SE |  95% CI |   z |     p
>
> Thank you so much again,
> I'd really appreciate if you would have more input on this.
> Sincerely,
> Suresh
>
>
>
>
> ------------------------------
> *From:* Daniel L?decke <d.luedecke at uke.de>
> *Sent:* Tuesday, November 9, 2021 4:32 AM
> *To:* Suresh N Neupane <sneupane2 at student.gsu.edu>
> *Cc:* r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>
> *Subject:* AW: [R-sig-ME] Using Robust Standard Errors lme4
>
> Hi Suresh,
>
> you could try the "parameters" package, which should (easily) return
> different types of robust standard errors, including cluster-robust
> standard
> errors for mixed models:
>
>
> https://nam12.safelinks.protection.outlook.com/?url=https%3A%2F%2Feasystats.github.io%2Fparameters%2Farticles%2Fmodel_parameters_robust.html&amp;data=04%7C01%7Csneupane2%40student.gsu.edu%7Ca99f7d4a171f419a724a08d9a363ee14%7C704d822c358a47849a1649e20b75f941%7C0%7C0%7C637720471875578865%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&amp;sdata=DOoXhh%2FzuFnNc6ZTAb9hry9%2FSB7QD%2F7bEYX%2BaHLQBhE%3D&amp;reserved=0
>
> Maybe you try this out on a very small subset of your model to see if it
> works. Also, since the "model_parameters()" function includes random
> effects
> variances by default, you may set the effects-argument to "fixed" to speed
> up computation. The call to the function could then look like something
> like
> this:
>
> model_parameters(
>   model,
>   effects = "fixed",
>   robust = TRUE,
>   vcov_estimation = "CL",
>   vcov_type = "HC1",
>   vcov_args = list(cluster = <your cluster variable from the data>)
> )
>
>
> Best
> Daniel
>
> -----Urspr?ngliche Nachricht-----
> Von: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> Im
> Auftrag von Suresh N Neupane via R-sig-mixed-models
> Gesendet: Montag, 8. November 2021 12:49
> An: r-sig-mixed-models at r-project.org
> Betreff: [R-sig-ME] Using Robust Standard Errors lme4
>
> Dear all,
> I am using lme4 package to run a hierarchical logistic regression model
> (with random county effect) for my binomial dependent variable, COVID death
> (0/1). This is a very large dataset with ~ 8 million observations.
> I need to find the robust standard error but was not sure about any
> package.
> I tried robustlmm (although my DV is not continuous) and got this error
> when
> used MerDeriv (sandwich):
> Error in UseMethod("estfun") :
> no applicable method for 'estfun' applied to an object of class
> "c('glmerMod', 'merMod')"
> The real tricky part is it takes several hours to compute because of the
> dataset length.
> All I need is to get robust standard error values.
> I already fit the models:
> fit <- glmer(death ~ (1|county_fips_code) + IV).
> Thank you so much,
> Suresh Neupane
>
>
--

_____________________________________________________________________

Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen Rechts; Gerichtsstand: Hamburg | www.uke.de
Vorstandsmitglieder: Prof. Dr. Burkhard G?ke (Vorsitzender), Joachim Pr?l?, Prof. Dr. Blanche Schwappach-Pignataro, Marya Verdel
_____________________________________________________________________

SAVE PAPER - THINK BEFORE PRINTING

	[[alternative HTML version deleted]]


From jepu@to @end|ng |rom gm@||@com  Tue Nov  9 23:44:44 2021
From: jepu@to @end|ng |rom gm@||@com (James Pustejovsky)
Date: Tue, 9 Nov 2021 16:44:44 -0600
Subject: [R-sig-ME] Using Robust Standard Errors lme4
In-Reply-To: <CANiAikHG3g8J+z66e=fXjm2uxPNeq2c7Gg8k0fjomfzxwgWeMw@mail.gmail.com>
References: <MWHPR0101MB31986D54DDD4BACBA61E4EBDA3919@MWHPR0101MB3198.prod.exchangelabs.com>
 <001e01d7d54c$c87d13b0$59773b10$@uke.de>
 <MWHPR0101MB3198819EF6CC17B29082EB70A3929@MWHPR0101MB3198.prod.exchangelabs.com>
 <CANiAikHG3g8J+z66e=fXjm2uxPNeq2c7Gg8k0fjomfzxwgWeMw@mail.gmail.com>
Message-ID: <CAFUVuJyhvfhWwCkbEq97zW=c7_5pHtvMo4kgXQBS4TtRBH3h4w@mail.gmail.com>

I can confirm, clubSandwich does not currently support glmerMod
objects. It may be possible to implement methods for such models, but
it will take some time. I welcome feedback on whether this would be of
broad interest, as well as expressions of interest if anyone would
like to contribute to implementation.

James

On Tue, Nov 9, 2021 at 3:20 PM Daniel L?decke <d.luedecke at uke.de> wrote:
>
> Hi Suresh,
> I just tried to find an example with glmer(), but it indeed looks like the
> clubSandwich package only supports lmer() models, not glmer(). So my
> suggested approach unfortunately doesn't seem to work.
>
> Best
> Daniel
>
> Am Di., 9. Nov. 2021 um 17:24 Uhr schrieb Suresh N Neupane <
> sneupane2 at student.gsu.edu>:
>
> > Hi Daniel,
> > Thank you so much for your suggestions. I tried that but it gives me an
> > error:
> >
> > Error in UseMethod("estfun") :
> >   no applicable method for 'estfun' applied to an object of class
> > "c('glmerMod', 'merMod')"
> >
> > My DV is death (0/1) and IV other variables:
> > Model: (with random county effects):
> > fit <- glmer(death ~ (1|county_fips_code) +white + black + pop.density ,
> > family = binomial("logit"), nAGQ=0, data = data.thesis)
> >  I tried the code you sent and used "county_fips_code" as my cluster
> > variable but it says did not find "county_fips_code".
> > I was able to use parameters::model_parameters(fit) to extract some info
> > (This is great!) such as;
> >  Parameter     |  Log-Odds |   SE |  95% CI |   z |     p
> >
> > Thank you so much again,
> > I'd really appreciate if you would have more input on this.
> > Sincerely,
> > Suresh
> >
> >
> >
> >
> > ------------------------------
> > *From:* Daniel L?decke <d.luedecke at uke.de>
> > *Sent:* Tuesday, November 9, 2021 4:32 AM
> > *To:* Suresh N Neupane <sneupane2 at student.gsu.edu>
> > *Cc:* r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>
> > *Subject:* AW: [R-sig-ME] Using Robust Standard Errors lme4
> >
> > Hi Suresh,
> >
> > you could try the "parameters" package, which should (easily) return
> > different types of robust standard errors, including cluster-robust
> > standard
> > errors for mixed models:
> >
> >
> > https://nam12.safelinks.protection.outlook.com/?url=https%3A%2F%2Feasystats.github.io%2Fparameters%2Farticles%2Fmodel_parameters_robust.html&amp;data=04%7C01%7Csneupane2%40student.gsu.edu%7Ca99f7d4a171f419a724a08d9a363ee14%7C704d822c358a47849a1649e20b75f941%7C0%7C0%7C637720471875578865%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&amp;sdata=DOoXhh%2FzuFnNc6ZTAb9hry9%2FSB7QD%2F7bEYX%2BaHLQBhE%3D&amp;reserved=0
> >
> > Maybe you try this out on a very small subset of your model to see if it
> > works. Also, since the "model_parameters()" function includes random
> > effects
> > variances by default, you may set the effects-argument to "fixed" to speed
> > up computation. The call to the function could then look like something
> > like
> > this:
> >
> > model_parameters(
> >   model,
> >   effects = "fixed",
> >   robust = TRUE,
> >   vcov_estimation = "CL",
> >   vcov_type = "HC1",
> >   vcov_args = list(cluster = <your cluster variable from the data>)
> > )
> >
> >
> > Best
> > Daniel
> >
> > -----Urspr?ngliche Nachricht-----
> > Von: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> Im
> > Auftrag von Suresh N Neupane via R-sig-mixed-models
> > Gesendet: Montag, 8. November 2021 12:49
> > An: r-sig-mixed-models at r-project.org
> > Betreff: [R-sig-ME] Using Robust Standard Errors lme4
> >
> > Dear all,
> > I am using lme4 package to run a hierarchical logistic regression model
> > (with random county effect) for my binomial dependent variable, COVID death
> > (0/1). This is a very large dataset with ~ 8 million observations.
> > I need to find the robust standard error but was not sure about any
> > package.
> > I tried robustlmm (although my DV is not continuous) and got this error
> > when
> > used MerDeriv (sandwich):
> > Error in UseMethod("estfun") :
> > no applicable method for 'estfun' applied to an object of class
> > "c('glmerMod', 'merMod')"
> > The real tricky part is it takes several hours to compute because of the
> > dataset length.
> > All I need is to get robust standard error values.
> > I already fit the models:
> > fit <- glmer(death ~ (1|county_fips_code) + IV).
> > Thank you so much,
> > Suresh Neupane
> >
> >
> --
>
> _____________________________________________________________________
>
> Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen Rechts; Gerichtsstand: Hamburg | www.uke.de
> Vorstandsmitglieder: Prof. Dr. Burkhard G?ke (Vorsitzender), Joachim Pr?l?, Prof. Dr. Blanche Schwappach-Pignataro, Marya Verdel
> _____________________________________________________________________
>
> SAVE PAPER - THINK BEFORE PRINTING
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From d@r|zopou|o@ @end|ng |rom er@@mu@mc@n|  Wed Nov 10 05:51:47 2021
From: d@r|zopou|o@ @end|ng |rom er@@mu@mc@n| (Dimitris Rizopoulos)
Date: Wed, 10 Nov 2021 04:51:47 +0000
Subject: [R-sig-ME] Using Robust Standard Errors lme4
In-Reply-To: <CAFUVuJyhvfhWwCkbEq97zW=c7_5pHtvMo4kgXQBS4TtRBH3h4w@mail.gmail.com>
References: <MWHPR0101MB31986D54DDD4BACBA61E4EBDA3919@MWHPR0101MB3198.prod.exchangelabs.com>
 <001e01d7d54c$c87d13b0$59773b10$@uke.de>
 <MWHPR0101MB3198819EF6CC17B29082EB70A3929@MWHPR0101MB3198.prod.exchangelabs.com>
 <CANiAikHG3g8J+z66e=fXjm2uxPNeq2c7Gg8k0fjomfzxwgWeMw@mail.gmail.com>
 <CAFUVuJyhvfhWwCkbEq97zW=c7_5pHtvMo4kgXQBS4TtRBH3h4w@mail.gmail.com>
Message-ID: <AM8PR04MB7843B84BE14BD8498AB5314BE8939@AM8PR04MB7843.eurprd04.prod.outlook.com>

Robust standard errors are available is GLMMadaptive. For more info, see here: https://drizopoulos.github.io/GLMMadaptive/articles/Methods.html#detailed-output-confidence-intervals-covariance-matrix-of-the-mles-and-robust-standard-errors-1

Best,
Dimitris


??
Dimitris Rizopoulos
Professor of Biostatistics
Erasmus University Medical Center
The Netherlands
________________________________
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of James Pustejovsky <jepusto at gmail.com>
Sent: Tuesday, November 9, 2021 11:44:44 PM
To: Daniel L?decke <d.luedecke at uke.de>
Cc: Suresh N Neupane <sneupane2 at student.gsu.edu>; r-sig-mixed-models <r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] Using Robust Standard Errors lme4



Waarschuwing: Deze e-mail is afkomstig van buiten de organisatie. Klik niet op links en open geen bijlagen, tenzij u de afzender herkent en weet dat de inhoud veilig is.
Caution: This email originated from outside of the organization. Do not click links or open attachments unless you recognize the sender and know the content is safe.



I can confirm, clubSandwich does not currently support glmerMod
objects. It may be possible to implement methods for such models, but
it will take some time. I welcome feedback on whether this would be of
broad interest, as well as expressions of interest if anyone would
like to contribute to implementation.

James

On Tue, Nov 9, 2021 at 3:20 PM Daniel L?decke <d.luedecke at uke.de> wrote:
>
> Hi Suresh,
> I just tried to find an example with glmer(), but it indeed looks like the
> clubSandwich package only supports lmer() models, not glmer(). So my
> suggested approach unfortunately doesn't seem to work.
>
> Best
> Daniel
>
> Am Di., 9. Nov. 2021 um 17:24 Uhr schrieb Suresh N Neupane <
> sneupane2 at student.gsu.edu>:
>
> > Hi Daniel,
> > Thank you so much for your suggestions. I tried that but it gives me an
> > error:
> >
> > Error in UseMethod("estfun") :
> >   no applicable method for 'estfun' applied to an object of class
> > "c('glmerMod', 'merMod')"
> >
> > My DV is death (0/1) and IV other variables:
> > Model: (with random county effects):
> > fit <- glmer(death ~ (1|county_fips_code) +white + black + pop.density ,
> > family = binomial("logit"), nAGQ=0, data = data.thesis)
> >  I tried the code you sent and used "county_fips_code" as my cluster
> > variable but it says did not find "county_fips_code".
> > I was able to use parameters::model_parameters(fit) to extract some info
> > (This is great!) such as;
> >  Parameter     |  Log-Odds |   SE |  95% CI |   z |     p
> >
> > Thank you so much again,
> > I'd really appreciate if you would have more input on this.
> > Sincerely,
> > Suresh
> >
> >
> >
> >
> > ------------------------------
> > *From:* Daniel L?decke <d.luedecke at uke.de>
> > *Sent:* Tuesday, November 9, 2021 4:32 AM
> > *To:* Suresh N Neupane <sneupane2 at student.gsu.edu>
> > *Cc:* r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>
> > *Subject:* AW: [R-sig-ME] Using Robust Standard Errors lme4
> >
> > Hi Suresh,
> >
> > you could try the "parameters" package, which should (easily) return
> > different types of robust standard errors, including cluster-robust
> > standard
> > errors for mixed models:
> >
> >
> > https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Feasystats.github.io%2Fparameters%2Farticles%2Fmodel_parameters_robust.html&amp;data=04%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C97ab93a935614522a3ef08d9a3d299dc%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C1%7C637720947192192478%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000&amp;sdata=EVr5Y257ErigeHaaeqjmOPQ1zka6ZQ%2BN%2BXxLIJUGarU%3D&amp;reserved=0
> >
> > Maybe you try this out on a very small subset of your model to see if it
> > works. Also, since the "model_parameters()" function includes random
> > effects
> > variances by default, you may set the effects-argument to "fixed" to speed
> > up computation. The call to the function could then look like something
> > like
> > this:
> >
> > model_parameters(
> >   model,
> >   effects = "fixed",
> >   robust = TRUE,
> >   vcov_estimation = "CL",
> >   vcov_type = "HC1",
> >   vcov_args = list(cluster = <your cluster variable from the data>)
> > )
> >
> >
> > Best
> > Daniel
> >
> > -----Urspr?ngliche Nachricht-----
> > Von: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> Im
> > Auftrag von Suresh N Neupane via R-sig-mixed-models
> > Gesendet: Montag, 8. November 2021 12:49
> > An: r-sig-mixed-models at r-project.org
> > Betreff: [R-sig-ME] Using Robust Standard Errors lme4
> >
> > Dear all,
> > I am using lme4 package to run a hierarchical logistic regression model
> > (with random county effect) for my binomial dependent variable, COVID death
> > (0/1). This is a very large dataset with ~ 8 million observations.
> > I need to find the robust standard error but was not sure about any
> > package.
> > I tried robustlmm (although my DV is not continuous) and got this error
> > when
> > used MerDeriv (sandwich):
> > Error in UseMethod("estfun") :
> > no applicable method for 'estfun' applied to an object of class
> > "c('glmerMod', 'merMod')"
> > The real tricky part is it takes several hours to compute because of the
> > dataset length.
> > All I need is to get robust standard error values.
> > I already fit the models:
> > fit <- glmer(death ~ (1|county_fips_code) + IV).
> > Thank you so much,
> > Suresh Neupane
> >
> >
> --
>
> _____________________________________________________________________
>
> Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen Rechts; Gerichtsstand: Hamburg | https://eur01.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.uke.de%2F&amp;data=04%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C97ab93a935614522a3ef08d9a3d299dc%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C1%7C637720947192192478%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000&amp;sdata=2Qofa4o0G55DGO3qEkRD%2BD0CT7Fy2%2F9LA0ETWfHOAMU%3D&amp;reserved=0
> Vorstandsmitglieder: Prof. Dr. Burkhard G?ke (Vorsitzender), Joachim Pr?l?, Prof. Dr. Blanche Schwappach-Pignataro, Marya Verdel
> _____________________________________________________________________
>
> SAVE PAPER - THINK BEFORE PRINTING
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=04%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C97ab93a935614522a3ef08d9a3d299dc%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C1%7C637720947192192478%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000&amp;sdata=Jk8XBNlm94jgM%2BkqHQdOex2XgWtbUbq658amvA0kGG0%3D&amp;reserved=0

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=04%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C97ab93a935614522a3ef08d9a3d299dc%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C1%7C637720947192192478%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000&amp;sdata=Jk8XBNlm94jgM%2BkqHQdOex2XgWtbUbq658amvA0kGG0%3D&amp;reserved=0

	[[alternative HTML version deleted]]


From t@h@|n|erdou@uo|c @end|ng |rom gm@||@com  Sat Nov 13 02:32:16 2021
From: t@h@|n|erdou@uo|c @end|ng |rom gm@||@com (Tahsin Ferdous)
Date: Fri, 12 Nov 2021 18:32:16 -0700
Subject: [R-sig-ME] GEE with gamma family and log link
Message-ID: <CAE5Duhsub2H6zUgNREL6m5xJ2xG6_vv-0nm2VxgFFhqD2qU0Xw@mail.gmail.com>

I am fitting a generalized estimating equation with gamma family and log
link. I am using GEE (geeglm function) from the R pcakage ?geepack? with
gamma family and log link and unstructured correlation structure.

Here, response variable or outcome is IFN_gamma_protein_pg_mg . Exposure is
intervention or probiotic use. Another covariate is Timepoint.



My code and the output is as mentioned below.

m8<geeglm(IFN_gamma_protein_pg_mg~Intervention+Timepoint,data=B,family=Gamma(link=log),id=
Participant_ID,corstr="exchangeable")

summary(m8)




* IFN_gamma_protein_pg_mg*

*Predictors*

*Estimates*

*p*

(Intercept)

0.01

*<0.001*

Intervention [Probiotics]

0.34

*0.029*

Timepoint [T2]

0.99

0.979

Timepoint [T3]

5.30

0.059

Timepoint [T4]

0.48

*0.039*

Timepoint [T5]

0.11

*<0.001*

















I am trying to interpret the coefficients as follows:

For every one-unit increase in the probiotic across the population, the log
average of IFN_gamma_protein increases by 0.34 units.



The exponentiated coefficient ( exp )= (exp(0.34)=1.41) is the factor by
which the arithmetic mean outcome on the original scale multiplied, i.e.,
when intervention is probiotic, for every one-unit increase in the
probiotic across the population, the average of IFN_gamma_protein on the
original scale is 1.41 times higher compared to when intervention is
control within levels of other variable.

Similarly, for timepoint 2, the average of IFN_gamma_protein on the
original scale is exp(  )= exp(0.99)= 2.69 times higher compared to
timepoint 1 within levels of other variable.

For time point 3, the average of IFN_gamma_protein on the original scale is
exp(  )= exp(5.30)= 200.34 times higher compared to timepoint 1 within
levels of other variable.

Can someone confirm me that I am in the right track in the interpretation
of parameters?

I am  posting here as I also want to fit a Gamma GLMM.

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Mon Nov 15 16:27:16 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Mon, 15 Nov 2021 10:27:16 -0500
Subject: [R-sig-ME] GEE with gamma family and log link
In-Reply-To: <CAE5Duhsub2H6zUgNREL6m5xJ2xG6_vv-0nm2VxgFFhqD2qU0Xw@mail.gmail.com>
References: <CAE5Duhsub2H6zUgNREL6m5xJ2xG6_vv-0nm2VxgFFhqD2qU0Xw@mail.gmail.com>
Message-ID: <759c5b61-44e6-bbfb-5345-d6cd8f832cfe@gmail.com>

   Except for the details of conditional vs marginal effects (discussed 
in a previous thread), the interpretation of fixed effects of a model 
with a log link (GLM(M), GEE, etc.) are not really a 
mixed-model-specific issue, but apply to any model with a log link.

   Your interpretations below sound correct (although you say something 
about "multiplying the arithmetic mean" by exp(beta); this is true, but 
it's also true that you would equivalently be multiplying any sensible 
location parameter (such as the geometric mean) by the same factor

On 11/12/21 8:32 PM, Tahsin Ferdous wrote:
> I am fitting a generalized estimating equation with gamma family and log
> link. I am using GEE (geeglm function) from the R pcakage ?geepack? with
> gamma family and log link and unstructured correlation structure.
> 
> Here, response variable or outcome is IFN_gamma_protein_pg_mg . Exposure is
> intervention or probiotic use. Another covariate is Timepoint.
> 
> My code and the output is as mentioned below.
> 
> m8<geeglm(IFN_gamma_protein_pg_mg~Intervention+Timepoint,data=B,family=Gamma(link=log),id=
> Participant_ID,corstr="exchangeable")
> 
> summary(m8)
> 
> * IFN_gamma_protein_pg_mg*
> 
> *Predictors*
> 
> *Estimates*
> 
> *p*
> 
> (Intercept)
> 
> 0.01
> 
> *<0.001*
> 
> Intervention [Probiotics]
> 
> 0.34
> 
> *0.029*
> 
> Timepoint [T2]
> 
> 0.99
> 
> 0.979
> 
> Timepoint [T3]
> 
> 5.30
> 
> 0.059
> 
> Timepoint [T4]
> 
> 0.48
> 
> *0.039*
> 
> Timepoint [T5]
> 
> 0.11
> 
> *<0.001*
> 

> 
> 
> I am trying to interpret the coefficients as follows:
> 
> For every one-unit increase in the probiotic across the population, the log
> average of IFN_gamma_protein increases by 0.34 units.
> 
> The exponentiated coefficient ( exp )= (exp(0.34)=1.41) is the factor by
> which the arithmetic mean outcome on the original scale multiplied, i.e.,
> when intervention is probiotic, for every one-unit increase in the
> probiotic across the population, the average of IFN_gamma_protein on the
> original scale is 1.41 times higher compared to when intervention is
> control within levels of other variable.
> 
> Similarly, for timepoint 2, the average of IFN_gamma_protein on the
> original scale is exp(  )= exp(0.99)= 2.69 times higher compared to
> timepoint 1 within levels of other variable.
> 
> For time point 3, the average of IFN_gamma_protein on the original scale is
> exp(  )= exp(5.30)= 200.34 times higher compared to timepoint 1 within
> levels of other variable.
> 
> Can someone confirm me that I am in the right track in the interpretation
> of parameters?
> 
> I am  posting here as I also want to fit a Gamma GLMM.
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

-- 
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
(Acting) Graduate chair, Mathematics & Statistics


From rev@theth|||@|kum@r @end|ng |rom gm@||@com  Fri Nov 19 05:22:54 2021
From: rev@theth|||@|kum@r @end|ng |rom gm@||@com (Revathe Thillaikumar)
Date: Fri, 19 Nov 2021 09:52:54 +0530
Subject: [R-sig-ME] Help with specifying interaction term involving nested
 factor
Message-ID: <CAEktutCGBazB6pnUuF7T2+3acdukzvKYdOCjKeygx1L+MV2w=Q@mail.gmail.com>

Hello all,

I have a doubt regarding how to specify a Poisson model and NBM with nested
effects using glmer, glmer.nb, and glmmTMB functions. I will explain the
factors below:

X - response variable
A - fixed factor
B - random factor; nested within C

I want to check the effect of A, B (nested within C), and the interaction
effect: B (nested within C) * A. I understand that the nested random factor
can be specified as (1 | C/B), but I am not sure how the interaction term
should be specified.

mF <- glmer(X ~ A + (1 | C/B) + (1 | C/B : A), family = "poisson", data = d)

If I run the above formula, the effect of C is computed twice, and I am not
interested in looking at that effect.

Could someone please help me with this? Thank you very much.


Best regards,
Revathe

--
PhD student
Animal Behaviour and Sociogenetics lab
Evolutionary and Organismal Biology Unit
Jawaharlal Nehru Centre for Advanced Scientific Research
Bengaluru
India

	[[alternative HTML version deleted]]


From t@h@|n|erdou@uo|c @end|ng |rom gm@||@com  Fri Nov 19 21:38:14 2021
From: t@h@|n|erdou@uo|c @end|ng |rom gm@||@com (Tahsin Ferdous)
Date: Fri, 19 Nov 2021 13:38:14 -0700
Subject: [R-sig-ME] Identifying link functions for gamma glmm
Message-ID: <CAE5Duhuum1OkkCgZvvwd+qEYb_-pXgSmn8ZHOy2rF-CssVEt9A@mail.gmail.com>

I am running a generalized linear mixed model with a gamma family. How can
I understand which link function I should use (log link, identity link, or
inverse link)? I tried to plot observed vs fitted values plots. But they
look similar? Should I look at AIC? If I fit a gamma glm, should I also
look at AIC to know which link function I should use in my model?

If I fit gamma GEE . should I look at QIC for choosing the appropriate
model with link function?

	[[alternative HTML version deleted]]


From r@turner @end|ng |rom @uck|@nd@@c@nz  Sat Nov 20 01:07:28 2021
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Sat, 20 Nov 2021 13:07:28 +1300
Subject: [R-sig-ME] Identifying link functions for gamma glmm
In-Reply-To: <CAE5Duhuum1OkkCgZvvwd+qEYb_-pXgSmn8ZHOy2rF-CssVEt9A@mail.gmail.com>
References: <CAE5Duhuum1OkkCgZvvwd+qEYb_-pXgSmn8ZHOy2rF-CssVEt9A@mail.gmail.com>
Message-ID: <20211120130728.157b923a@rolf-Latitude-E7470>


On Fri, 19 Nov 2021 13:38:14 -0700
Tahsin Ferdous <tahsinferdousuofc at gmail.com> wrote:

> I am running a generalized linear mixed model with a gamma family.
> How can I understand which link function I should use (log link,
> identity link, or inverse link)? I tried to plot observed vs fitted
> values plots. But they look similar? Should I look at AIC? If I fit a
> gamma glm, should I also look at AIC to know which link function I
> should use in my model?
> 
> If I fit gamma GEE . should I look at QIC for choosing the appropriate
> model with link function?

I used a cross-validation approach, in a somewhat similar context.  I
tried both leave-one-out and k-fold cross-validation, with moderate
success.  The complete story is complicated, and has an unsatisfactory
ending (I wound up getting answers that the client did not like!) so
I shall not go into any more detail.

OTOH if your plots "look similar", perhaps it doesn't really matter.
Can you think of a criterion for deciding whether it *does* matter?

cheers,

Rolf Turner

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From v|tor@v@v @end|ng |rom gm@||@com  Sat Nov 20 01:21:31 2021
From: v|tor@v@v @end|ng |rom gm@||@com (Vitor Vieira Vasconcelos)
Date: Fri, 19 Nov 2021 21:21:31 -0300
Subject: [R-sig-ME] Multi-level models for nested variables in time dimension
Message-ID: <CANAwtjtVAwBzq7DHX9sP+XN0skET=eh+cdG2Ww5R-QZ1To0Pyg@mail.gmail.com>

Good night, friends!

     I have been seeing many multi-level models, using the mixed models'
framework, that use groups nested in "space", such as students nested in
classes, which are nested in schools, and with independent variables for
each of these spatial resolutions.
    Then I was thinking whether we could use this same framework to model
variables nested in the time dimension. For example, if we have some
variables sampled at daily resolution, other variables at monthly
resolution and others at year resolution, and we would like to use all them
in the same model to predict a dependent variable at daily resolution.
   Basically, I am just thinking about transposing the same framework from
"space" dimension to "time" dimension, and not thinking yet about
autocorrelation or other time-series analyses.
    Do you think that these ideas make sense to you?

Best regards,
Vitor Vieira Vasconcelos
+55-31-99331-1593

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Sat Nov 20 01:40:02 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Fri, 19 Nov 2021 19:40:02 -0500
Subject: [R-sig-ME] Identifying link functions for gamma glmm
In-Reply-To: <CAE5Duhuum1OkkCgZvvwd+qEYb_-pXgSmn8ZHOy2rF-CssVEt9A@mail.gmail.com>
References: <CAE5Duhuum1OkkCgZvvwd+qEYb_-pXgSmn8ZHOy2rF-CssVEt9A@mail.gmail.com>
Message-ID: <8ce5bb62-620f-ea0e-0852-4ccfb4cd7d4a@gmail.com>

   Most of the time I would suggest choosing link functions on 
scientific grounds, i.e. what scale makes sense for the expected 
effects? Link functions change the expected relationship with continuous 
predictors (do I expect the effects of predictors to be linear 
(identity), exponential (log), or hyperbolic (inverse)?) and change the 
meaning of interactions (does the value of one variable change the 
expected effect of the other additively (identity), proportionally 
(log), or ?? (inverse)).

   I generally find that log links are more numerically stable (both 
identity and inverse links can sometimes lead to negative predictions). 
Logs are also nice because they essentially split the difference between 
the identity and inverse links.  If I have (say) responses that are time 
intervals, then analyzing on the identity scale describes additive 
effects on the time scale; analyzing on the inverse scale describes 
additive effects on the rate or speed (1/time) of the response; 
analyzing on the log scale describes proportional changes in *either* 
time or rate (because log(time) = -1*log(1/time)).

   My general procedure would be to use a log link and see if the 
diagnostics detected any problems.

   That said, you could use AIC or cross-validation if you are primarily 
interested in prediction (and aren't worried about snooping). 
Cross-validation will be slower but more reliable, *if* you are careful 
to maintain independence structure when you specify your training and 
testing sets (i.e., you should sample by levels of your grouping 
variable, not by individual observations)


On 11/19/21 3:38 PM, Tahsin Ferdous wrote:
> I am running a generalized linear mixed model with a gamma family. How can
> I understand which link function I should use (log link, identity link, or
> inverse link)? I tried to plot observed vs fitted values plots. But they
> look similar? Should I look at AIC? If I fit a gamma glm, should I also
> look at AIC to know which link function I should use in my model?
> 
> If I fit gamma GEE . should I look at QIC for choosing the appropriate
> model with link function?
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

-- 
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
(Acting) Graduate chair, Mathematics & Statistics


From t@h@|n|erdou@uo|c @end|ng |rom gm@||@com  Sat Nov 20 02:18:56 2021
From: t@h@|n|erdou@uo|c @end|ng |rom gm@||@com (Tahsin Ferdous)
Date: Fri, 19 Nov 2021 18:18:56 -0700
Subject: [R-sig-ME] Identifying link functions for gamma glmm
In-Reply-To: <8ce5bb62-620f-ea0e-0852-4ccfb4cd7d4a@gmail.com>
References: <CAE5Duhuum1OkkCgZvvwd+qEYb_-pXgSmn8ZHOy2rF-CssVEt9A@mail.gmail.com>
 <8ce5bb62-620f-ea0e-0852-4ccfb4cd7d4a@gmail.com>
Message-ID: <CAE5Duhv9KDKnJk8a2amaz-vixm9PYsV-+SJ2MwKBWMt7OsOxqg@mail.gmail.com>

Dear Dr Ben,

Thanks a lot for the valuable information. At first, I tried to fit a glm
with a log link. I attached the residual vs fitted plot of this model. I
have seen an outlier in the plot (I am not sure what is meant by 300 in
this plot?). Should we always look at the diagnostic plots (residual vs
fitted) for glm, glmm or gee? If I run the model with the outlier, does it
give valid results?

Kindest regards,

Tahsin

On Fri, Nov 19, 2021 at 5:40 PM Ben Bolker <bbolker at gmail.com> wrote:

>    Most of the time I would suggest choosing link functions on
> scientific grounds, i.e. what scale makes sense for the expected
> effects? Link functions change the expected relationship with continuous
> predictors (do I expect the effects of predictors to be linear
> (identity), exponential (log), or hyperbolic (inverse)?) and change the
> meaning of interactions (does the value of one variable change the
> expected effect of the other additively (identity), proportionally
> (log), or ?? (inverse)).
>
>    I generally find that log links are more numerically stable (both
> identity and inverse links can sometimes lead to negative predictions).
> Logs are also nice because they essentially split the difference between
> the identity and inverse links.  If I have (say) responses that are time
> intervals, then analyzing on the identity scale describes additive
> effects on the time scale; analyzing on the inverse scale describes
> additive effects on the rate or speed (1/time) of the response;
> analyzing on the log scale describes proportional changes in *either*
> time or rate (because log(time) = -1*log(1/time)).
>
>    My general procedure would be to use a log link and see if the
> diagnostics detected any problems.
>
>    That said, you could use AIC or cross-validation if you are primarily
> interested in prediction (and aren't worried about snooping).
> Cross-validation will be slower but more reliable, *if* you are careful
> to maintain independence structure when you specify your training and
> testing sets (i.e., you should sample by levels of your grouping
> variable, not by individual observations)
>
>
> On 11/19/21 3:38 PM, Tahsin Ferdous wrote:
> > I am running a generalized linear mixed model with a gamma family. How
> can
> > I understand which link function I should use (log link, identity link,
> or
> > inverse link)? I tried to plot observed vs fitted values plots. But they
> > look similar? Should I look at AIC? If I fit a gamma glm, should I also
> > look at AIC to know which link function I should use in my model?
> >
> > If I fit gamma GEE . should I look at QIC for choosing the appropriate
> > model with link function?
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
> --
> Dr. Benjamin Bolker
> Professor, Mathematics & Statistics and Biology, McMaster University
> Director, School of Computational Science and Engineering
> (Acting) Graduate chair, Mathematics & Statistics
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

-------------- next part --------------
A non-text attachment was scrubbed...
Name: Rplot 1.png
Type: image/png
Size: 31426 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20211119/13710482/attachment-0001.png>

From boj@n@@d|n|c @end|ng |rom gm@||@com  Fri Nov 26 08:41:26 2021
From: boj@n@@d|n|c @end|ng |rom gm@||@com (Bojana Dinic)
Date: Fri, 26 Nov 2021 08:41:26 +0100
Subject: [R-sig-ME] p-correction for effects in LMM
Message-ID: <814eac33-350c-f5e0-5d35-727451c5e519@gmail.com>

Dear colleagues,

 ??? I use linear mixed models with 1 random effect (subject), 2 fixed
 ??? factors (one? is between factor and another is repeated) and one 
covariate, and
 ??? explore all main effects, 2-way interactions and one 3-way 
interaction.
 ??? Regarding of used software, somewhere I get effect of intercept,
 ??? somewhere not. Reviewer asks to use p-adjustment for these
 ??? effects. My dilemma is should I apply p-correction for 7 tests or 8 
(including
 ??? random intercept for subjects)?

 ??? The output do not contain F for random effect, but only variance.
 ??? Also, the output do not contain effect size. CIs are available only 
for
 ??? betas as product of specific level of both fixed effects and 
covariate, but
 ??? since I have 3 levels for between and 4 for repeated effects, the
 ??? output is not helpful + there is no possibility to change reference 
group.
 ??? Thus, I'm stuck with p-adjustment.

 ?? Any help is welcomed.
 ??? Thank you.

-- 
Kind regards,
Bojana Dinic


From mtonc|c @end|ng |rom ||r|@un|r|@hr  Fri Nov 26 20:29:30 2021
From: mtonc|c @end|ng |rom ||r|@un|r|@hr (marKo)
Date: Fri, 26 Nov 2021 20:29:30 +0100
Subject: [R-sig-ME] p-correction for effects in LMM
In-Reply-To: <814eac33-350c-f5e0-5d35-727451c5e519@gmail.com>
References: <814eac33-350c-f5e0-5d35-727451c5e519@gmail.com>
Message-ID: <82d6d954-9afc-df69-4000-a40184574bff@ffri.uniri.hr>

On 26. 11. 2021. 08:41, Bojana Dinic wrote:
> Dear colleagues,
> 
>  ??? I use linear mixed models with 1 random effect (subject), 2 fixed
>  ??? factors (one? is between factor and another is repeated) and one 
> covariate, and
>  ??? explore all main effects, 2-way interactions and one 3-way 
> interaction.
>  ??? Regarding of used software, somewhere I get effect of intercept,
>  ??? somewhere not. Reviewer asks to use p-adjustment for these
>  ??? effects. My dilemma is should I apply p-correction for 7 tests or 8 
> (including
>  ??? random intercept for subjects)?
> 
>  ??? The output do not contain F for random effect, but only variance.
>  ??? Also, the output do not contain effect size. CIs are available only 
> for
>  ??? betas as product of specific level of both fixed effects and 
> covariate, but
>  ??? since I have 3 levels for between and 4 for repeated effects, the
>  ??? output is not helpful + there is no possibility to change reference 
> group.
>  ??? Thus, I'm stuck with p-adjustment.
> 
>  ?? Any help is welcomed.
>  ??? Thank you.
> 

As I understand, p-values are somewhat unreliable (In LMM). As a 
sensible alternative maybe you could compute bootstrap CI and use that 
to infer about significance of specific effects (if i have understood 
your problem correctly).
I you use lme4 or nlme, this should not be a problem.

You ca use (for model  m)

confint(m, level=0.95, method="boot", nsim=No.of.SIMULATIONS)

even use some multi-core processing to speed thing up

confint(m, level=0.95, method="boot", parallel = "multicore", ncpus = 
No.of.CORES, nsim=No.of.SIMULATIONS)

change No.of.SIMULATIONS with the desired number of repetitions (1000 or so)
change No.of.CORES with the desired number of cores (depends of your 
machine).

Hope it helps.


-- 
Marko Ton?i?, PhD
Assistant professor
University of Rijeka
Faculty of Humanities and Social Sciences
Department of Psychology
Sveucilisna avenija 4, 51000 Rijeka, CROATIA
e-mail: mtoncic at ffri.uniri.hr


From v|ctor|@@w||||t@ @end|ng |rom gm@||@com  Tue Nov 30 16:40:32 2021
From: v|ctor|@@w||||t@ @end|ng |rom gm@||@com (Victoria Pattison-Willits)
Date: Tue, 30 Nov 2021 10:40:32 -0500
Subject: [R-sig-ME] p-correction for effects in LMM
In-Reply-To: <82d6d954-9afc-df69-4000-a40184574bff@ffri.uniri.hr>
References: <814eac33-350c-f5e0-5d35-727451c5e519@gmail.com>
 <82d6d954-9afc-df69-4000-a40184574bff@ffri.uniri.hr>
Message-ID: <CAPzcKfsgT+N4yhzGG5bkq-0LV=2jz45zn50MkW2R=Lu0NGQw=w@mail.gmail.com>

Hi there
Thank you to the OP for sharing this question and I am following this
thread as I was wondering which CIs were the best to go with for mixed
models - I have been calculating three different types (Wald, Boot and
Profile) and was not really sure for mixed models (in my case v similar an
lmer with a nested random effect crossed with a second random effect and 8
fixed effects (no interactive terms)). I have been on a massive learning
curve and so still a little hazy how the t approaches differ in their calc
of  the CIs - I have been reporting the bootstrap CIs in my project
although there was only a very small difference when plotted for all 3
across all my fixed effects. Just want to check in light of this question
this is the correct approach!

One also quick q related to OQ - how do you determine the number of CORES
if I wanted to include that code - does it depend on processing speeds etc?

Cheers and this is my first question and I still am a relative novice so
thanks in advance for patience with probably very simple questions! :)

Vicki PW

On Fri, Nov 26, 2021 at 2:30 PM marKo <mtoncic at ffri.uniri.hr> wrote:

> On 26. 11. 2021. 08:41, Bojana Dinic wrote:
> > Dear colleagues,
> >
> >      I use linear mixed models with 1 random effect (subject), 2 fixed
> >      factors (one  is between factor and another is repeated) and one
> > covariate, and
> >      explore all main effects, 2-way interactions and one 3-way
> > interaction.
> >      Regarding of used software, somewhere I get effect of intercept,
> >      somewhere not. Reviewer asks to use p-adjustment for these
> >      effects. My dilemma is should I apply p-correction for 7 tests or 8
> > (including
> >      random intercept for subjects)?
> >
> >      The output do not contain F for random effect, but only variance.
> >      Also, the output do not contain effect size. CIs are available only
> > for
> >      betas as product of specific level of both fixed effects and
> > covariate, but
> >      since I have 3 levels for between and 4 for repeated effects, the
> >      output is not helpful + there is no possibility to change reference
> > group.
> >      Thus, I'm stuck with p-adjustment.
> >
> >     Any help is welcomed.
> >      Thank you.
> >
>
> As I understand, p-values are somewhat unreliable (In LMM). As a
> sensible alternative maybe you could compute bootstrap CI and use that
> to infer about significance of specific effects (if i have understood
> your problem correctly).
> I you use lme4 or nlme, this should not be a problem.
>
> You ca use (for model  m)
>
> confint(m, level=0.95, method="boot", nsim=No.of.SIMULATIONS)
>
> even use some multi-core processing to speed thing up
>
> confint(m, level=0.95, method="boot", parallel = "multicore", ncpus =
> No.of.CORES, nsim=No.of.SIMULATIONS)
>
> change No.of.SIMULATIONS with the desired number of repetitions (1000 or
> so)
> change No.of.CORES with the desired number of cores (depends of your
> machine).
>
> Hope it helps.
>
>
> --
> Marko Ton?i?, PhD
> Assistant professor
> University of Rijeka
> Faculty of Humanities and Social Sciences
> Department of Psychology
> Sveucilisna avenija 4, 51000 Rijeka, CROATIA
> e-mail: mtoncic at ffri.uniri.hr
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From mtonc|c @end|ng |rom ||r|@un|r|@hr  Wed Dec  1 13:48:20 2021
From: mtonc|c @end|ng |rom ||r|@un|r|@hr (marKo)
Date: Wed, 1 Dec 2021 13:48:20 +0100
Subject: [R-sig-ME] p-correction for effects in LMM
In-Reply-To: <CAPzcKfsgT+N4yhzGG5bkq-0LV=2jz45zn50MkW2R=Lu0NGQw=w@mail.gmail.com>
References: <814eac33-350c-f5e0-5d35-727451c5e519@gmail.com>
 <82d6d954-9afc-df69-4000-a40184574bff@ffri.uniri.hr>
 <CAPzcKfsgT+N4yhzGG5bkq-0LV=2jz45zn50MkW2R=Lu0NGQw=w@mail.gmail.com>
Message-ID: <74c1a5d3-fd82-5210-1bb6-ad06e8c6c93d@ffri.uniri.hr>

Not sure what to say in this regard, as those methods will produce very 
similar results. If  I recall it correctly, Douglas Bates suggests doing 
a profile CI.
I usually do a bootstrap and do not think much about it (sorry to say 
that, actually).

As for the number of cores (CORES in the mentioned code), they depends 
on the processor you have. To establish the max number, in Windows start 
the task manager and see how many threads you have. In Linux, You can 
use some system monitor to check that.

Hope it helps,

Marko

  On 30. 11. 2021. 16:40, Victoria Pattison-Willits wrote:
> Hi there
> Thank you to the OP for sharing this question and I am following this
> thread as I was wondering which CIs were the best to go with for mixed
> models - I have been calculating three different types (Wald, Boot and
> Profile) and was not really sure for mixed models (in my case v similar an
> lmer with a nested random effect crossed with a second random effect and 8
> fixed effects (no interactive terms)). I have been on a massive learning
> curve and so still a little hazy how the t approaches differ in their calc
> of  the CIs - I have been reporting the bootstrap CIs in my project
> although there was only a very small difference when plotted for all 3
> across all my fixed effects. Just want to check in light of this question
> this is the correct approach!
> 
> One also quick q related to OQ - how do you determine the number of CORES
> if I wanted to include that code - does it depend on processing speeds etc?
> 
> Cheers and this is my first question and I still am a relative novice so
> thanks in advance for patience with probably very simple questions! :)
> 
> Vicki PW
> 
> On Fri, Nov 26, 2021 at 2:30 PM marKo <mtoncic at ffri.uniri.hr> wrote:
> 
>> On 26. 11. 2021. 08:41, Bojana Dinic wrote:
>>> Dear colleagues,
>>>
>>>       I use linear mixed models with 1 random effect (subject), 2 fixed
>>>       factors (one  is between factor and another is repeated) and one
>>> covariate, and
>>>       explore all main effects, 2-way interactions and one 3-way
>>> interaction.
>>>       Regarding of used software, somewhere I get effect of intercept,
>>>       somewhere not. Reviewer asks to use p-adjustment for these
>>>       effects. My dilemma is should I apply p-correction for 7 tests or 8
>>> (including
>>>       random intercept for subjects)?
>>>
>>>       The output do not contain F for random effect, but only variance.
>>>       Also, the output do not contain effect size. CIs are available only
>>> for
>>>       betas as product of specific level of both fixed effects and
>>> covariate, but
>>>       since I have 3 levels for between and 4 for repeated effects, the
>>>       output is not helpful + there is no possibility to change reference
>>> group.
>>>       Thus, I'm stuck with p-adjustment.
>>>
>>>      Any help is welcomed.
>>>       Thank you.
>>>
>>
>> As I understand, p-values are somewhat unreliable (In LMM). As a
>> sensible alternative maybe you could compute bootstrap CI and use that
>> to infer about significance of specific effects (if i have understood
>> your problem correctly).
>> I you use lme4 or nlme, this should not be a problem.
>>
>> You ca use (for model  m)
>>
>> confint(m, level=0.95, method="boot", nsim=No.of.SIMULATIONS)
>>
>> even use some multi-core processing to speed thing up
>>
>> confint(m, level=0.95, method="boot", parallel = "multicore", ncpus =
>> No.of.CORES, nsim=No.of.SIMULATIONS)
>>
>> change No.of.SIMULATIONS with the desired number of repetitions (1000 or
>> so)
>> change No.of.CORES with the desired number of cores (depends of your
>> machine).
>>
>> Hope it helps.
>>
>>
>> --
>> Marko Ton?i?, PhD
>> Assistant professor
>> University of Rijeka
>> Faculty of Humanities and Social Sciences
>> Department of Psychology
>> Sveucilisna avenija 4, 51000 Rijeka, CROATIA
>> e-mail: mtoncic at ffri.uniri.hr
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From bjorn@@|@ten @end|ng |rom te||@@com  Thu Dec  2 11:58:59 2021
From: bjorn@@|@ten @end|ng |rom te||@@com (=?utf-8?Q?Bj=C3=B6rn_Johansson?=)
Date: Thu, 2 Dec 2021 11:58:59 +0100
Subject: [R-sig-ME] Variance estimation in gamma GLMMs
Message-ID: <61A897060000DA06@ts201-smtpout71.ddc.teliasonera.net> (added by
 MAILER-DAEMON@telia.com)

In the program below I am making comparisons between lme4::glmer and glmmTMB for some simple randomly generated data with just an intercept and a single random effect, for the distributions Poisson, binomial and gamma with log link. For the Poisson and binomial data the results are almost identical. For the gamma data they are very close, except for the estimates of the variance of the random effects (the actual variance is 0.15 in all cases). I would like to understand why.

Kind regards

-----------------------------------------------------------------

library(lme4)
library(glmmTMB)

# Poisson

beta <- 3  # Intercept
varv <- 0.15 # Variance of random effect
mlf <- sample(1:100,10000,replace=TRUE) # Levels of the random effect
simdata <- data.frame(mlf)
v <- rnorm(100,sd=sqrt(varv))
simdata$v <- v[simdata$mlf]
simdata$expx <- exp(beta + simdata$v)
simdata$x <- rpois(nrow(simdata),simdata$expx)

est_glmer <- glmer(x ~ 1 + (1|mlf), family = poisson, data = simdata, nAGQ=1L)
est_tmb <- glmmTMB(x ~ 1 + (1|mlf), data=simdata, family=poisson)
summary(est_glmer)$varcor$mlf[[1]]
unname(unlist(summary(est_tmb)$varcor))

# Binomial

beta <- 0.5 # Intercept
varv <- 0.15  # Variance of random effect
mlf <- sample(1:100,10000,replace=TRUE) # Levels for the random effect
simdata <- data.frame(mlf)
v <- rnorm(100,sd=sqrt(varv))
simdata$v <- v[simdata$mlf]
simdata$p <- exp(beta+simdata$v)/(1+exp(beta+simdata$v))
simdata$x <- rbinom(nrow(simdata),1,simdata$p)

est_glmer <- glmer(x ~ 1 + (1|mlf), family = binomial, data = simdata, nAGQ=1L)
est_tmb <- glmmTMB(x ~ 1 + (1|mlf), data=simdata, family=binomial)
summary(est_glmer)$varcor$mlf[[1]]
unname(unlist(summary(est_tmb)$varcor))

# Gamma

mlf <- sample(1:100,10000,replace=TRUE)
beta <- 7  # Intercept
phi <- 0.5 # 1/(shape parameter) in the gamma distribution
varv=0.15    # Variance of the random effect
simdata <- data.frame(mlf)
v <- rnorm(100,sd=sqrt(varv))
simdata$v <- v[simdata$mlf]
simdata$expx <- exp(beta + simdata$v)
simdata$x <- rgamma(nrow(simdata),1/phi,1/(simdata$expx*phi))

est_glmer <- glmer(x ~ 1 + (1|mlf), family = Gamma(link="log"), data = simdata, nAGQ=1L)
est_tmb <- glmmTMB(x ~ 1 + (1|mlf), data=simdata, family=Gamma(link="log"))
summary(est_glmer)$varcor$mlf[[1]]
unname(unlist(summary(est_tmb)$varcor))


Skickades fr?n E-post f?r Windows


	[[alternative HTML version deleted]]


From v|ctor|@@w||||t@ @end|ng |rom gm@||@com  Thu Dec  2 15:02:50 2021
From: v|ctor|@@w||||t@ @end|ng |rom gm@||@com (Victoria Pattison-Willits)
Date: Thu, 2 Dec 2021 09:02:50 -0500
Subject: [R-sig-ME] p-correction for effects in LMM
In-Reply-To: <74c1a5d3-fd82-5210-1bb6-ad06e8c6c93d@ffri.uniri.hr>
References: <814eac33-350c-f5e0-5d35-727451c5e519@gmail.com>
 <82d6d954-9afc-df69-4000-a40184574bff@ffri.uniri.hr>
 <CAPzcKfsgT+N4yhzGG5bkq-0LV=2jz45zn50MkW2R=Lu0NGQw=w@mail.gmail.com>
 <74c1a5d3-fd82-5210-1bb6-ad06e8c6c93d@ffri.uniri.hr>
Message-ID: <CAPzcKfuQj+L+UwDKaRjoPqPsJugsBEpP2OVvrbsqEbPMz7DYsw@mail.gmail.com>

That is great thank you for the quick reply Marko :)

On Wed, Dec 1, 2021 at 7:48 AM marKo <mtoncic at ffri.uniri.hr> wrote:

> Not sure what to say in this regard, as those methods will produce very
> similar results. If  I recall it correctly, Douglas Bates suggests doing
> a profile CI.
> I usually do a bootstrap and do not think much about it (sorry to say
> that, actually).
>
> As for the number of cores (CORES in the mentioned code), they depends
> on the processor you have. To establish the max number, in Windows start
> the task manager and see how many threads you have. In Linux, You can
> use some system monitor to check that.
>
> Hope it helps,
>
> Marko
>
>   On 30. 11. 2021. 16:40, Victoria Pattison-Willits wrote:
> > Hi there
> > Thank you to the OP for sharing this question and I am following this
> > thread as I was wondering which CIs were the best to go with for mixed
> > models - I have been calculating three different types (Wald, Boot and
> > Profile) and was not really sure for mixed models (in my case v similar
> an
> > lmer with a nested random effect crossed with a second random effect and
> 8
> > fixed effects (no interactive terms)). I have been on a massive learning
> > curve and so still a little hazy how the t approaches differ in their
> calc
> > of  the CIs - I have been reporting the bootstrap CIs in my project
> > although there was only a very small difference when plotted for all 3
> > across all my fixed effects. Just want to check in light of this question
> > this is the correct approach!
> >
> > One also quick q related to OQ - how do you determine the number of CORES
> > if I wanted to include that code - does it depend on processing speeds
> etc?
> >
> > Cheers and this is my first question and I still am a relative novice so
> > thanks in advance for patience with probably very simple questions! :)
> >
> > Vicki PW
> >
> > On Fri, Nov 26, 2021 at 2:30 PM marKo <mtoncic at ffri.uniri.hr> wrote:
> >
> >> On 26. 11. 2021. 08:41, Bojana Dinic wrote:
> >>> Dear colleagues,
> >>>
> >>>       I use linear mixed models with 1 random effect (subject), 2 fixed
> >>>       factors (one  is between factor and another is repeated) and one
> >>> covariate, and
> >>>       explore all main effects, 2-way interactions and one 3-way
> >>> interaction.
> >>>       Regarding of used software, somewhere I get effect of intercept,
> >>>       somewhere not. Reviewer asks to use p-adjustment for these
> >>>       effects. My dilemma is should I apply p-correction for 7 tests
> or 8
> >>> (including
> >>>       random intercept for subjects)?
> >>>
> >>>       The output do not contain F for random effect, but only variance.
> >>>       Also, the output do not contain effect size. CIs are available
> only
> >>> for
> >>>       betas as product of specific level of both fixed effects and
> >>> covariate, but
> >>>       since I have 3 levels for between and 4 for repeated effects, the
> >>>       output is not helpful + there is no possibility to change
> reference
> >>> group.
> >>>       Thus, I'm stuck with p-adjustment.
> >>>
> >>>      Any help is welcomed.
> >>>       Thank you.
> >>>
> >>
> >> As I understand, p-values are somewhat unreliable (In LMM). As a
> >> sensible alternative maybe you could compute bootstrap CI and use that
> >> to infer about significance of specific effects (if i have understood
> >> your problem correctly).
> >> I you use lme4 or nlme, this should not be a problem.
> >>
> >> You ca use (for model  m)
> >>
> >> confint(m, level=0.95, method="boot", nsim=No.of.SIMULATIONS)
> >>
> >> even use some multi-core processing to speed thing up
> >>
> >> confint(m, level=0.95, method="boot", parallel = "multicore", ncpus =
> >> No.of.CORES, nsim=No.of.SIMULATIONS)
> >>
> >> change No.of.SIMULATIONS with the desired number of repetitions (1000 or
> >> so)
> >> change No.of.CORES with the desired number of cores (depends of your
> >> machine).
> >>
> >> Hope it helps.
> >>
> >>
> >> --
> >> Marko Ton?i?, PhD
> >> Assistant professor
> >> University of Rijeka
> >> Faculty of Humanities and Social Sciences
> >> Department of Psychology
> >> Sveucilisna avenija 4, 51000 Rijeka, CROATIA
> >> e-mail: mtoncic at ffri.uniri.hr
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Thu Dec  2 16:22:09 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Thu, 2 Dec 2021 10:22:09 -0500
Subject: [R-sig-ME] p-correction for effects in LMM
In-Reply-To: <74c1a5d3-fd82-5210-1bb6-ad06e8c6c93d@ffri.uniri.hr>
References: <814eac33-350c-f5e0-5d35-727451c5e519@gmail.com>
 <82d6d954-9afc-df69-4000-a40184574bff@ffri.uniri.hr>
 <CAPzcKfsgT+N4yhzGG5bkq-0LV=2jz45zn50MkW2R=Lu0NGQw=w@mail.gmail.com>
 <74c1a5d3-fd82-5210-1bb6-ad06e8c6c93d@ffri.uniri.hr>
Message-ID: <587ce506-2824-01b8-fb36-d13befc0ccfb@gmail.com>

   Just to follow up:

   parametric bootstrap is more accurate, but slower, than profile CIs. 
Profile CIs are more accurate, but slower, than Wald CIs.  It is not 
unusual for all three CIs to be similar, especially for the fixed 
effects, and especially for LMMs/clean data/large data.

https://stats.stackexchange.com/questions/351164/confidence-intervals-for-glmm-bootstrap-vs-likelihood-profile/351171#351171

   parallel::detectCores() should (?) tell you how many cores you have. 
You may not want to use all of them at once (e.g. so you have some 
resources left for interactive work).

On 12/1/21 7:48 AM, marKo wrote:
> Not sure what to say in this regard, as those methods will produce very 
> similar results. If? I recall it correctly, Douglas Bates suggests doing 
> a profile CI.
> I usually do a bootstrap and do not think much about it (sorry to say 
> that, actually).
> 
> As for the number of cores (CORES in the mentioned code), they depends 
> on the processor you have. To establish the max number, in Windows start 
> the task manager and see how many threads you have. In Linux, You can 
> use some system monitor to check that.
> 
> Hope it helps,
> 
> Marko
> 
>  ?On 30. 11. 2021. 16:40, Victoria Pattison-Willits wrote:
>> Hi there
>> Thank you to the OP for sharing this question and I am following this
>> thread as I was wondering which CIs were the best to go with for mixed
>> models - I have been calculating three different types (Wald, Boot and
>> Profile) and was not really sure for mixed models (in my case v 
>> similar an
>> lmer with a nested random effect crossed with a second random effect 
>> and 8
>> fixed effects (no interactive terms)). I have been on a massive learning
>> curve and so still a little hazy how the t approaches differ in their 
>> calc
>> of? the CIs - I have been reporting the bootstrap CIs in my project
>> although there was only a very small difference when plotted for all 3
>> across all my fixed effects. Just want to check in light of this question
>> this is the correct approach!
>>
>> One also quick q related to OQ - how do you determine the number of CORES
>> if I wanted to include that code - does it depend on processing speeds 
>> etc?
>>
>> Cheers and this is my first question and I still am a relative novice so
>> thanks in advance for patience with probably very simple questions! :)
>>
>> Vicki PW
>>
>> On Fri, Nov 26, 2021 at 2:30 PM marKo <mtoncic at ffri.uniri.hr> wrote:
>>
>>> On 26. 11. 2021. 08:41, Bojana Dinic wrote:
>>>> Dear colleagues,
>>>>
>>>> ????? I use linear mixed models with 1 random effect (subject), 2 fixed
>>>> ????? factors (one? is between factor and another is repeated) and one
>>>> covariate, and
>>>> ????? explore all main effects, 2-way interactions and one 3-way
>>>> interaction.
>>>> ????? Regarding of used software, somewhere I get effect of intercept,
>>>> ????? somewhere not. Reviewer asks to use p-adjustment for these
>>>> ????? effects. My dilemma is should I apply p-correction for 7 tests 
>>>> or 8
>>>> (including
>>>> ????? random intercept for subjects)?
>>>>
>>>> ????? The output do not contain F for random effect, but only variance.
>>>> ????? Also, the output do not contain effect size. CIs are available 
>>>> only
>>>> for
>>>> ????? betas as product of specific level of both fixed effects and
>>>> covariate, but
>>>> ????? since I have 3 levels for between and 4 for repeated effects, the
>>>> ????? output is not helpful + there is no possibility to change 
>>>> reference
>>>> group.
>>>> ????? Thus, I'm stuck with p-adjustment.
>>>>
>>>> ???? Any help is welcomed.
>>>> ????? Thank you.
>>>>
>>>
>>> As I understand, p-values are somewhat unreliable (In LMM). As a
>>> sensible alternative maybe you could compute bootstrap CI and use that
>>> to infer about significance of specific effects (if i have understood
>>> your problem correctly).
>>> I you use lme4 or nlme, this should not be a problem.
>>>
>>> You ca use (for model? m)
>>>
>>> confint(m, level=0.95, method="boot", nsim=No.of.SIMULATIONS)
>>>
>>> even use some multi-core processing to speed thing up
>>>
>>> confint(m, level=0.95, method="boot", parallel = "multicore", ncpus =
>>> No.of.CORES, nsim=No.of.SIMULATIONS)
>>>
>>> change No.of.SIMULATIONS with the desired number of repetitions (1000 or
>>> so)
>>> change No.of.CORES with the desired number of cores (depends of your
>>> machine).
>>>
>>> Hope it helps.
>>>
>>>
>>> -- 
>>> Marko Ton?i?, PhD
>>> Assistant professor
>>> University of Rijeka
>>> Faculty of Humanities and Social Sciences
>>> Department of Psychology
>>> Sveucilisna avenija 4, 51000 Rijeka, CROATIA
>>> e-mail: mtoncic at ffri.uniri.hr
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>> ????[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
(Acting) Graduate chair, Mathematics & Statistics


From me @end|ng |rom ph||||p@|d@y@com  Sat Dec  4 05:27:23 2021
From: me @end|ng |rom ph||||p@|d@y@com (Phillip Alday)
Date: Fri, 3 Dec 2021 22:27:23 -0600
Subject: [R-sig-ME] Multi-level models for nested variables in time
 dimension
In-Reply-To: <CANAwtjtVAwBzq7DHX9sP+XN0skET=eh+cdG2Ww5R-QZ1To0Pyg@mail.gmail.com>
References: <CANAwtjtVAwBzq7DHX9sP+XN0skET=eh+cdG2Ww5R-QZ1To0Pyg@mail.gmail.com>
Message-ID: <ac88e587-39d0-541a-8e19-a49195aef4af@phillipalday.com>

The math of mixed models doesn't care whether the original dimension was
space, time or something else entirely. In both time and space, you can
have autocorrelation that messes with model assumptions, but it's that
autocorrelation that matters more than the physical interpretation of
the dimension.

All that said, it's incumbent on the user to know what the inferential
interpretation of the resulting model is. Methods designed to deal with
serial autocorrelation may have a more obvious interpretation. But the
question of which model gives you the inferences you need is one that
requires the knowledge of your data and research question that only you
have.

Hope that helps,

Phillip

On 11/19/21 18:21, Vitor Vieira Vasconcelos wrote:
> Good night, friends!
>
>      I have been seeing many multi-level models, using the mixed models'
> framework, that use groups nested in "space", such as students nested in
> classes, which are nested in schools, and with independent variables for
> each of these spatial resolutions.
>     Then I was thinking whether we could use this same framework to model
> variables nested in the time dimension. For example, if we have some
> variables sampled at daily resolution, other variables at monthly
> resolution and others at year resolution, and we would like to use all them
> in the same model to predict a dependent variable at daily resolution.
>    Basically, I am just thinking about transposing the same framework from
> "space" dimension to "time" dimension, and not thinking yet about
> autocorrelation or other time-series analyses.
>     Do you think that these ideas make sense to you?
>
> Best regards,
> Vitor Vieira Vasconcelos
> +55-31-99331-1593
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From me @end|ng |rom ph||||p@|d@y@com  Sat Dec  4 06:10:07 2021
From: me @end|ng |rom ph||||p@|d@y@com (Phillip Alday)
Date: Fri, 3 Dec 2021 23:10:07 -0600
Subject: [R-sig-ME] When a higher level can't be modeled due to one row
In-Reply-To: <CAEvy2r0SZJS0=R8xXatuu1hpA2hMFgerPxt43m9HTP0fkK2oKA@mail.gmail.com>
References: <CAEvy2r0SZJS0=R8xXatuu1hpA2hMFgerPxt43m9HTP0fkK2oKA@mail.gmail.com>
Message-ID: <181d05f1-f9c7-1901-a2b9-6d720c54ee91@phillipalday.com>

If measure varies within one study level, but is present and constant in
the others, then you can still do:

?(1 | study / outcome) + (1 | measure)

You'll just get one BLUP/conditional mode for each study where measure
is constant. That's fine and expected -- the measure is constant for the
entire study, so its associated random effect shouldn't change. Of
course, the measure and study effects (BLUPs) are conflated for every
study but 2 (so you shouldn't overinterpret the BLUPs), but you may
still be able to separate their overall variance contribution (the bits
reported in the "random effects" section of lme4's output).

The big fine print here is that you need to have enough

- observations in each study

- levels of study (with only 3 levels, study probably shouldn't be
treated as a blocking variable....)

- variabiity between studies

- levels of measure in study 2

- variability between measures

On 11/9/21 12:36, Farzad Keyhan wrote:
> Dear Colleagues,
>
> I initially posted my query on the meta-analysis SIG. But I realized
> my question is related to multilevel modeling.
>
> Below is my data structure. If in row # 3, "measure" was 2 (instead of
> 1), then, I could model "measure" as a level above "study":
>
>  (1 | measure / study / outcome)
>
> But right now, because in study 2 (rows # 3 and 4) "measure" can vary,
> "measure" can't be considered a level above "study".
>
> On the other hand, because "measure" varies only in one "study" level
> (i.e., study 2), I can't model "measure" as a crossed effect with
> "study" either:
>
>  (1 | study / outcome) + (1 | measure)
>
> So, to model "measure" as a random factor what can we do?
>
> Best,
> Fred
>    measure  study  outcome
>    1              1          1
>    1              1          2
> # 1              2          1<--row #3
>    2              2          1
>    1              3          3
>    1              3          2
>    2              4          3
>    9              5          1
>    9              6          2
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From me @end|ng |rom ph||||p@|d@y@com  Sat Dec  4 06:23:33 2021
From: me @end|ng |rom ph||||p@|d@y@com (Phillip Alday)
Date: Fri, 3 Dec 2021 23:23:33 -0600
Subject: [R-sig-ME] Recovering correlations
In-Reply-To: <CAHmzXO5a6nQnST-zMS=ypNr9m3Fe=iRdnWVb+-YCc6Esixws6Q@mail.gmail.com>
References: <CAHmzXO5a6nQnST-zMS=ypNr9m3Fe=iRdnWVb+-YCc6Esixws6Q@mail.gmail.com>
Message-ID: <c1c76a9a-aed3-97b5-54a0-ff7247bc8cf3@phillipalday.com>

I haven't looked at your whole simulation, but I can make a few quick
comments that hopefully help

On 10/11/21 06:27, Gang Chen wrote:
> I have thought about the following models
>
> m2 <- lmer(y ~ 1 + (0+R1|f) + (0+R2|f), data=dat)
>
> m3 <- lmer(y ~ 1 + (1|f) + (0+R2|f), data=dat)
>
> but I've been struggling to figure out a way to recover the correlations r1
> and r2 with the variances from the random effects based on the models m2
> and m3.

Splitting these out into separate |f terms suppresses the computation of
the correlations. If you want the associated correlations, then you need
to have them in one group, e.g. (0 + R1 + R2 | f).

lme4 uses an unstructured covariance structure, so there's no real
middle ground between estimating all correlations (one grouping term) or
estimating no correlations (split things into separate grouping terms)
without having repeated/overlapping grouping terms.

There's nothing wrong per se with a correlation you assume is zero --
maybe you'll even get zero back. However, if you want to make that
assumption stronger and selectively constrain certain elements in the
covariance matrix to be zero, you'll probably need to use nlme (I think
you could hack a solution there?), handroll something in TMB or use a
Bayesian method where you're expressing exactly the model structure you
want (either through the likelihood or the prior). If you're willing to
go over to the Julia side and use MixedModels.jl, it wouldn't be too
difficult to construct a model, then selectively constrain certain
elements of the covariance matrix to zero. We don't have a interface for
this at the moment, but the code for ZeroCorr (roughly equal to || in
lme4) just does this for every off-diagonal element, and it wouldn't be
too hard to adapt that code for a single model to only zero-out certain
off-diagonal elements.

Also, for the construction of dummy variables in the random effects,
make sure to check out lme4::dummy.

Hope this helps

Phillip


From boj@n@@d|n|c @end|ng |rom gm@||@com  Sat Dec  4 11:26:17 2021
From: boj@n@@d|n|c @end|ng |rom gm@||@com (Bojana Dinic)
Date: Sat, 4 Dec 2021 11:26:17 +0100
Subject: [R-sig-ME] p-correction for effects in LMM
In-Reply-To: <82d6d954-9afc-df69-4000-a40184574bff@ffri.uniri.hr>
References: <814eac33-350c-f5e0-5d35-727451c5e519@gmail.com>
 <82d6d954-9afc-df69-4000-a40184574bff@ffri.uniri.hr>
Message-ID: <fa07f367-996f-b283-a0dc-6f05ad60d776@gmail.com>

Dear Marko,

Thank you. I have question, these are CIs for which statistic (I have 2 
factors, cond and rep, and their interaction)?
 ???????????????????????? 2.5 %??? 97.5 %
.sig01??????? 8.6062568 12.035500
.sigma?????? 12.8489647 14.841375
(Intercept)? -2.1807253? 9.047992
cond1??????? -4.1126524 11.296070
cond3??????? -5.8346317? 7.649526
rep2???????? -8.0280001? 5.220439
rep3???????? -4.0846168? 9.194793
rep4????????? 6.1875602 18.878770
cond1:rep2? -11.2367698? 8.031134
cond3:rep2?? -7.9112913? 7.491230
cond1:rep3?? -8.2536791 10.129607
cond3:rep3?? -5.9766989 10.071404
cond1:rep4?? -0.9371539 17.551132
cond3:rep4?? -4.2738610 11.020311

Kind regars,
Bojana

On 26-Nov-21 20:29, marKo wrote:
> On 26. 11. 2021. 08:41, Bojana Dinic wrote:
>> Dear colleagues,
>>
>> ???? I use linear mixed models with 1 random effect (subject), 2 fixed
>> ???? factors (one? is between factor and another is repeated) and one 
>> covariate, and
>> ???? explore all main effects, 2-way interactions and one 3-way 
>> interaction.
>> ???? Regarding of used software, somewhere I get effect of intercept,
>> ???? somewhere not. Reviewer asks to use p-adjustment for these
>> ???? effects. My dilemma is should I apply p-correction for 7 tests 
>> or 8 (including
>> ???? random intercept for subjects)?
>>
>> ???? The output do not contain F for random effect, but only variance.
>> ???? Also, the output do not contain effect size. CIs are available 
>> only for
>> ???? betas as product of specific level of both fixed effects and 
>> covariate, but
>> ???? since I have 3 levels for between and 4 for repeated effects, the
>> ???? output is not helpful + there is no possibility to change 
>> reference group.
>> ???? Thus, I'm stuck with p-adjustment.
>>
>> ??? Any help is welcomed.
>> ???? Thank you.
>>
>
> As I understand, p-values are somewhat unreliable (In LMM). As a 
> sensible alternative maybe you could compute bootstrap CI and use that 
> to infer about significance of specific effects (if i have understood 
> your problem correctly).
> I you use lme4 or nlme, this should not be a problem.
>
> You ca use (for model? m)
>
> confint(m, level=0.95, method="boot", nsim=No.of.SIMULATIONS)
>
> even use some multi-core processing to speed thing up
>
> confint(m, level=0.95, method="boot", parallel = "multicore", ncpus = 
> No.of.CORES, nsim=No.of.SIMULATIONS)
>
> change No.of.SIMULATIONS with the desired number of repetitions (1000 
> or so)
> change No.of.CORES with the desired number of cores (depends of your 
> machine).
>
> Hope it helps.
>
>


From v@r|n@@ch@ @end|ng |rom y@hoo@|r  Sat Dec  4 20:47:07 2021
From: v@r|n@@ch@ @end|ng |rom y@hoo@|r (varin sacha)
Date: Sat, 4 Dec 2021 19:47:07 +0000 (UTC)
Subject: [R-sig-ME] Reference ?
References: <2035506915.12831566.1638647227536.ref@mail.yahoo.com>
Message-ID: <2035506915.12831566.1638647227536@mail.yahoo.com>

Dear Mixed modelers experts,

I am looking for a reference to justify my sentence here below.
Many thanks for your help.

"The mixed model seemed well specified ? it converged and had no singular problem, no overfitting problem. So, even if the sample size is quite small, the estimates are stable and can be trusted".

Best Regards,
SV
?


From |@brun@ @end|ng |rom udc@e@  Sat Dec  4 20:55:18 2021
From: |@brun@ @end|ng |rom udc@e@ (Fernando Pedro Bruna Quintas)
Date: Sat, 4 Dec 2021 19:55:18 +0000
Subject: [R-sig-ME] Reference ?
In-Reply-To: <2035506915.12831566.1638647227536@mail.yahoo.com>
References: <2035506915.12831566.1638647227536.ref@mail.yahoo.com>
 <2035506915.12831566.1638647227536@mail.yahoo.com>
Message-ID: <PAXPR02MB77981C10DFB439406A216959926B9@PAXPR02MB7798.eurprd02.prod.outlook.com>


Dear SV,

I can feel that you have a very promising research career just in front of your eyes.

FB

________________________________
De: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> en nombre de varin sacha via R-sig-mixed-models <r-sig-mixed-models at r-project.org>
Enviado: s?bado, 4 de diciembre de 2021 20:47
Para: R-sig-mixed-models <r-sig-mixed-models at r-project.org>
Asunto: [R-sig-ME] Reference ?

Dear Mixed modelers experts,

I am looking for a reference to justify my sentence here below.
Many thanks for your help.

"The mixed model seemed well specified ? it converged and had no singular problem, no overfitting problem. So, even if the sample size is quite small, the estimates are stable and can be trusted".

Best Regards,
SV


_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From mtonc|c @end|ng |rom ||r|@un|r|@hr  Sat Dec  4 23:38:31 2021
From: mtonc|c @end|ng |rom ||r|@un|r|@hr (marKo)
Date: Sat, 4 Dec 2021 23:38:31 +0100
Subject: [R-sig-ME] p-correction for effects in LMM
In-Reply-To: <fa07f367-996f-b283-a0dc-6f05ad60d776@gmail.com>
References: <814eac33-350c-f5e0-5d35-727451c5e519@gmail.com>
 <82d6d954-9afc-df69-4000-a40184574bff@ffri.uniri.hr>
 <fa07f367-996f-b283-a0dc-6f05ad60d776@gmail.com>
Message-ID: <00737030-8883-ae8b-3185-b0d8c0d6b833@ffri.uniri.hr>

I must admit that I do not understand what is that you are asking. Those 
CIs are for the parameters of your model (a 3x4 model + random effects: 
subject + residuals).
The referent group here are cond2 and rep1.
Maybe the problem that you have is that you would like to have an F 
statistic for the main effects and for the interaction. I do not know.

Marko


On 04. 12. 2021. 11:26, Bojana Dinic wrote:
> Dear Marko,
> 
> Thank you. I have question, these are CIs for which statistic (I have 2 
> factors, cond and rep, and their interaction)?
>  ???????????????????????? 2.5 %??? 97.5 %
> .sig01??????? 8.6062568 12.035500
> .sigma?????? 12.8489647 14.841375
> (Intercept)? -2.1807253? 9.047992
> cond1??????? -4.1126524 11.296070
> cond3??????? -5.8346317? 7.649526
> rep2???????? -8.0280001? 5.220439
> rep3???????? -4.0846168? 9.194793
> rep4????????? 6.1875602 18.878770
> cond1:rep2? -11.2367698? 8.031134
> cond3:rep2?? -7.9112913? 7.491230
> cond1:rep3?? -8.2536791 10.129607
> cond3:rep3?? -5.9766989 10.071404
> cond1:rep4?? -0.9371539 17.551132
> cond3:rep4?? -4.2738610 11.020311
> 
> Kind regars,
> Bojana
> 
> On 26-Nov-21 20:29, marKo wrote:
>> On 26. 11. 2021. 08:41, Bojana Dinic wrote:
>>> Dear colleagues,
>>>
>>> ???? I use linear mixed models with 1 random effect (subject), 2 fixed
>>> ???? factors (one? is between factor and another is repeated) and one 
>>> covariate, and
>>> ???? explore all main effects, 2-way interactions and one 3-way 
>>> interaction.
>>> ???? Regarding of used software, somewhere I get effect of intercept,
>>> ???? somewhere not. Reviewer asks to use p-adjustment for these
>>> ???? effects. My dilemma is should I apply p-correction for 7 tests 
>>> or 8 (including
>>> ???? random intercept for subjects)?
>>>
>>> ???? The output do not contain F for random effect, but only variance.
>>> ???? Also, the output do not contain effect size. CIs are available 
>>> only for
>>> ???? betas as product of specific level of both fixed effects and 
>>> covariate, but
>>> ???? since I have 3 levels for between and 4 for repeated effects, the
>>> ???? output is not helpful + there is no possibility to change 
>>> reference group.
>>> ???? Thus, I'm stuck with p-adjustment.
>>>
>>> ??? Any help is welcomed.
>>> ???? Thank you.
>>>
>>
>> As I understand, p-values are somewhat unreliable (In LMM). As a 
>> sensible alternative maybe you could compute bootstrap CI and use that 
>> to infer about significance of specific effects (if i have understood 
>> your problem correctly).
>> I you use lme4 or nlme, this should not be a problem.
>>
>> You ca use (for model? m)
>>
>> confint(m, level=0.95, method="boot", nsim=No.of.SIMULATIONS)
>>
>> even use some multi-core processing to speed thing up
>>
>> confint(m, level=0.95, method="boot", parallel = "multicore", ncpus = 
>> No.of.CORES, nsim=No.of.SIMULATIONS)
>>
>> change No.of.SIMULATIONS with the desired number of repetitions (1000 
>> or so)
>> change No.of.CORES with the desired number of cores (depends of your 
>> machine).
>>
>> Hope it helps.
>>
>>
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From @h@ne@|r@nk @end|ng |rom u@n@no  Sun Dec  5 03:26:24 2021
From: @h@ne@|r@nk @end|ng |rom u@n@no (Shane Frank)
Date: Sun, 5 Dec 2021 02:26:24 +0000
Subject: [R-sig-ME] Reference ?
In-Reply-To: <PAXPR02MB77981C10DFB439406A216959926B9@PAXPR02MB7798.eurprd02.prod.outlook.com>
References: <2035506915.12831566.1638647227536.ref@mail.yahoo.com>
 <2035506915.12831566.1638647227536@mail.yahoo.com>
 <PAXPR02MB77981C10DFB439406A216959926B9@PAXPR02MB7798.eurprd02.prod.outlook.com>
Message-ID: <SVAP279MB0223B4E65217009D6F3C5613926C9@SVAP279MB0223.NORP279.PROD.OUTLOOK.COM>

Hi SV,

I think there is doubt whether a ?small? sample size adequately represents your population of interest. You can argue from a study design perspective that you avoided bias with a random sample, but the game of (low) numbers during sampling could create a bias due to randomness as well. ?Trusting? your estimates and the uncertainty around them goes beyond the fitting process. I apologize if this is obvious to you. But, I think this push-pull idea might help explain why it is difficult to give you some coup de grace reference to ?solve? your problem. I think your rationale and argumentation will be more helpful than a reference anyway. Perhaps that was what FB was insinuating. You could try sensitivity analysis to help bolster your confidence in the results if that was your goal.

SF





________________________________
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of Fernando Pedro Bruna Quintas <f.bruna at udc.es>
Sent: Saturday, December 4, 2021 12:55:18 PM
To: R-sig-mixed-models <r-sig-mixed-models at r-project.org>; varin sacha <varinsacha at yahoo.fr>
Subject: Re: [R-sig-ME] Reference ?


Dear SV,

I can feel that you have a very promising research career just in front of your eyes.

FB

________________________________
De: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> en nombre de varin sacha via R-sig-mixed-models <r-sig-mixed-models at r-project.org>
Enviado: s?bado, 4 de diciembre de 2021 20:47
Para: R-sig-mixed-models <r-sig-mixed-models at r-project.org>
Asunto: [R-sig-ME] Reference ?

Dear Mixed modelers experts,

I am looking for a reference to justify my sentence here below.
Many thanks for your help.

"The mixed model seemed well specified ? it converged and had no singular problem, no overfitting problem. So, even if the sample size is quite small, the estimates are stable and can be trusted".

Best Regards,
SV


_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://eur03.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=04%7C01%7Cshane.frank%40usn.no%7Ccdcc63706cfd4868a1ad08d9b7605f81%7Cbc758dd0ab5343729a7ce98a9620862c%7C0%7C0%7C637742446819356248%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C2000&amp;sdata=%2BSjexgAApNHSzlHbZr0vAz8vsbW71nS%2BHQ1BaEeOPvs%3D&amp;reserved=0

        [[alternative HTML version deleted]]


	[[alternative HTML version deleted]]


From chr|@ @end|ng |rom tr|cky@o|ut|on@@com@@u  Mon Dec  6 00:20:52 2021
From: chr|@ @end|ng |rom tr|cky@o|ut|on@@com@@u (Chris Howden)
Date: Sun, 5 Dec 2021 23:20:52 +0000
Subject: [R-sig-ME] Reference ?
In-Reply-To: <PAXPR02MB77981C10DFB439406A216959926B9@PAXPR02MB7798.eurprd02.prod.outlook.com>
References: <2035506915.12831566.1638647227536.ref@mail.yahoo.com>
 <2035506915.12831566.1638647227536@mail.yahoo.com>
 <PAXPR02MB77981C10DFB439406A216959926B9@PAXPR02MB7798.eurprd02.prod.outlook.com>
Message-ID: <SYBPR01MB71939A3CD0B57198FD14AF6D986C9@SYBPR01MB7193.ausprd01.prod.outlook.com>

Hi Sacha,

I'm not sure I really agree with that statement, although some may. 

Say your sample size was really small, only 6. A simple model may still fit, but I wouldn?t expect the parameters to be particularly stable. Only 1 or 2 different datum could change everything. 

I would also want to consider the SE of the parameter estimates. If they are very large (compared to the parameter estimates), then this is telling me the parameter estimates aren't very stable. Even though the model converged. 

Chris Howden B.Sc. (Hons)
Founding Partner
Data Analysis, Modelling and Training
Evidence Based Strategy/Policy Development, IP Commercialisation and Innovation
(mobile) +61 (0) 410 689 945 | (skype) chris at trickysolutions.com.au

-----Original Message-----
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> On Behalf Of Fernando Pedro Bruna Quintas
Sent: Sunday, 5 December 2021 6:55 AM
To: R-sig-mixed-models <r-sig-mixed-models at r-project.org>; varin sacha <varinsacha at yahoo.fr>
Subject: Re: [R-sig-ME] Reference ?


Dear SV,

I can feel that you have a very promising research career just in front of your eyes.

FB

________________________________
De: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> en nombre de varin sacha via R-sig-mixed-models <r-sig-mixed-models at r-project.org>
Enviado: s bado, 4 de diciembre de 2021 20:47
Para: R-sig-mixed-models <r-sig-mixed-models at r-project.org>
Asunto: [R-sig-ME] Reference ?

Dear Mixed modelers experts,

I am looking for a reference to justify my sentence here below.
Many thanks for your help.

"The mixed model seemed well specified   it converged and had no singular problem, no overfitting problem. So, even if the sample size is quite small, the estimates are stable and can be trusted".

Best Regards,
SV


_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Mon Dec  6 01:09:58 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Sun, 5 Dec 2021 19:09:58 -0500
Subject: [R-sig-ME] Reference ?
In-Reply-To: <SYBPR01MB71939A3CD0B57198FD14AF6D986C9@SYBPR01MB7193.ausprd01.prod.outlook.com>
References: <2035506915.12831566.1638647227536.ref@mail.yahoo.com>
 <2035506915.12831566.1638647227536@mail.yahoo.com>
 <PAXPR02MB77981C10DFB439406A216959926B9@PAXPR02MB7798.eurprd02.prod.outlook.com>
 <SYBPR01MB71939A3CD0B57198FD14AF6D986C9@SYBPR01MB7193.ausprd01.prod.outlook.com>
Message-ID: <68828f6f-ccea-04c7-cbe2-ebac5829dccc@gmail.com>

    More bad news:

  * I can't point you to a specific, published/peer-reviewed 'best 
practices in mixed modeling' document; maybe someone else here can.
  * As Chris says, the lack of obvious numerical problems doesn't 
necessarily mean the model estimates are stable.
  * The other issue with a small sample is that a lot of the inferential 
machinery of mixed models (p-values, confidence intervals, etc.) rests 
on asymptotic assumptions.

  What kinds of "overfitting problems" did you have in mind? What would 
the symptoms be?



On 12/5/21 6:20 PM, Chris Howden wrote:
> Hi Sacha,
> 
> I'm not sure I really agree with that statement, although some may.
> 
> Say your sample size was really small, only 6. A simple model may still fit, but I wouldn?t expect the parameters to be particularly stable. Only 1 or 2 different datum could change everything.
> 
> I would also want to consider the SE of the parameter estimates. If they are very large (compared to the parameter estimates), then this is telling me the parameter estimates aren't very stable. Even though the model converged.
> 
> Chris Howden B.Sc. (Hons)
> Founding Partner
> Data Analysis, Modelling and Training
> Evidence Based Strategy/Policy Development, IP Commercialisation and Innovation
> (mobile) +61 (0) 410 689 945 | (skype) chris at trickysolutions.com.au
> 
> -----Original Message-----
> From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> On Behalf Of Fernando Pedro Bruna Quintas
> Sent: Sunday, 5 December 2021 6:55 AM
> To: R-sig-mixed-models <r-sig-mixed-models at r-project.org>; varin sacha <varinsacha at yahoo.fr>
> Subject: Re: [R-sig-ME] Reference ?
> 
> 
> Dear SV,
> 
> I can feel that you have a very promising research career just in front of your eyes.
> 
> FB
> 
> ________________________________
> De: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> en nombre de varin sacha via R-sig-mixed-models <r-sig-mixed-models at r-project.org>
> Enviado: s bado, 4 de diciembre de 2021 20:47
> Para: R-sig-mixed-models <r-sig-mixed-models at r-project.org>
> Asunto: [R-sig-ME] Reference ?
> 
> Dear Mixed modelers experts,
> 
> I am looking for a reference to justify my sentence here below.
> Many thanks for your help.
> 
> "The mixed model seemed well specified   it converged and had no singular problem, no overfitting problem. So, even if the sample size is quite small, the estimates are stable and can be trusted".
> 
> Best Regards,
> SV
> 
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

-- 
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
(Acting) Graduate chair, Mathematics & Statistics


From me @end|ng |rom ph||||p@|d@y@com  Mon Dec  6 07:32:27 2021
From: me @end|ng |rom ph||||p@|d@y@com (Phillip Alday)
Date: Mon, 6 Dec 2021 00:32:27 -0600
Subject: [R-sig-ME] Reference ?
In-Reply-To: <68828f6f-ccea-04c7-cbe2-ebac5829dccc@gmail.com>
References: <2035506915.12831566.1638647227536.ref@mail.yahoo.com>
 <2035506915.12831566.1638647227536@mail.yahoo.com>
 <PAXPR02MB77981C10DFB439406A216959926B9@PAXPR02MB7798.eurprd02.prod.outlook.com>
 <SYBPR01MB71939A3CD0B57198FD14AF6D986C9@SYBPR01MB7193.ausprd01.prod.outlook.com>
 <68828f6f-ccea-04c7-cbe2-ebac5829dccc@gmail.com>
Message-ID: <6d653e26-f048-a565-2038-99a9c2e7d80e@phillipalday.com>



On 5/12/21 6:09 pm, Ben Bolker wrote:
> ?? More bad news:
> 
> ?* I can't point you to a specific, published/peer-reviewed 'best
> practices in mixed modeling' document; maybe someone else here can.

I don't really know of a single, short-ish document that covers this. A
lot of best practices follow from general statistical and numerical best
practices (see e.g. the "stable and can be trusted" bit that started
this -- you may have precise, well-defined estimates, but that's not
necessarily "stable" in the sense you want; perhaps confidence intervals
would be closer) and the underlying mathematics of mixed models.

There are a lot of introductory texts (both articles and books) on mixed
models in general, mixed models in particular problem domains (e.g.
ecology, cognitive science) and particular issues in mixed models
(random effects selection, etc.), but the quality of these varies
greatly. I recently came across one that has concrete reporting
recommendations (Meteyard and Davies 2020,
https://doi.org/10.1016/j.jml.2020.104092), but I think that they leave
out a lot of fine print (e.g., R2-like measures for mixed models are
problematic; the Kenward-Roger ddf approximation requires inverting a
large matrix, etc.).

> ?* As Chris says, the lack of obvious numerical problems doesn't
> necessarily mean the model estimates are stable.
> ?* The other issue with a small sample is that a lot of the inferential
> machinery of mixed models (p-values, confidence intervals, etc.) rests
> on asymptotic assumptions.
> 
> ?What kinds of "overfitting problems" did you have in mind? What would
> the symptoms be?
> 
> 
> 
> On 12/5/21 6:20 PM, Chris Howden wrote:
>> Hi Sacha,
>>
>> I'm not sure I really agree with that statement, although some may.
>>
>> Say your sample size was really small, only 6. A simple model may
>> still fit, but I wouldn?t expect the parameters to be particularly
>> stable. Only 1 or 2 different datum could change everything.
>>
>> I would also want to consider the SE of the parameter estimates. If
>> they are very large (compared to the parameter estimates), then this
>> is telling me the parameter estimates aren't very stable. Even though
>> the model converged.
>>
>> Chris Howden B.Sc. (Hons)
>> Founding Partner
>> Data Analysis, Modelling and Training
>> Evidence Based Strategy/Policy Development, IP Commercialisation and
>> Innovation
>> (mobile) +61 (0) 410 689 945 | (skype) chris at trickysolutions.com.au
>>
>> -----Original Message-----
>> From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> On
>> Behalf Of Fernando Pedro Bruna Quintas
>> Sent: Sunday, 5 December 2021 6:55 AM
>> To: R-sig-mixed-models <r-sig-mixed-models at r-project.org>; varin sacha
>> <varinsacha at yahoo.fr>
>> Subject: Re: [R-sig-ME] Reference ?
>>
>>
>> Dear SV,
>>
>> I can feel that you have a very promising research career just in
>> front of your eyes.
>>
>> FB
>>
>> ________________________________
>> De: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> en
>> nombre de varin sacha via R-sig-mixed-models
>> <r-sig-mixed-models at r-project.org>
>> Enviado: s bado, 4 de diciembre de 2021 20:47
>> Para: R-sig-mixed-models <r-sig-mixed-models at r-project.org>
>> Asunto: [R-sig-ME] Reference ?
>>
>> Dear Mixed modelers experts,
>>
>> I am looking for a reference to justify my sentence here below.
>> Many thanks for your help.
>>
>> "The mixed model seemed well specified?? it converged and had no
>> singular problem, no overfitting problem. So, even if the sample size
>> is quite small, the estimates are stable and can be trusted".
>>
>> Best Regards,
>> SV
>>
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>> ????[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>


From boj@n@@d|n|c @end|ng |rom gm@||@com  Mon Dec  6 23:04:16 2021
From: boj@n@@d|n|c @end|ng |rom gm@||@com (Bojana Dinic)
Date: Mon, 6 Dec 2021 23:04:16 +0100
Subject: [R-sig-ME] p-correction for effects in LMM
In-Reply-To: <00737030-8883-ae8b-3185-b0d8c0d6b833@ffri.uniri.hr>
References: <814eac33-350c-f5e0-5d35-727451c5e519@gmail.com>
 <82d6d954-9afc-df69-4000-a40184574bff@ffri.uniri.hr>
 <fa07f367-996f-b283-a0dc-6f05ad60d776@gmail.com>
 <00737030-8883-ae8b-3185-b0d8c0d6b833@ffri.uniri.hr>
Message-ID: <9eb40418-30a7-2144-55f1-a2152498cdaf@gmail.com>

Dear Marko,
Yes, I need effect size for F tests or p-adjustment for it. Thus, is 
there any procedure to obtain effect sizes or if I use p-adjustments I 
am not sure whether I need to involve random effect in calculation or not?
Thank you.

Regards,
Bojana

On 04-Dec-21 23:38, marKo wrote:
> I must admit that I do not understand what is that you are asking. 
> Those CIs are for the parameters of your model (a 3x4 model + random 
> effects: subject + residuals).
> The referent group here are cond2 and rep1.
> Maybe the problem that you have is that you would like to have an F 
> statistic for the main effects and for the interaction. I do not know.
>
> Marko
>
>
> On 04. 12. 2021. 11:26, Bojana Dinic wrote:
>> Dear Marko,
>>
>> Thank you. I have question, these are CIs for which statistic (I have 
>> 2 factors, cond and rep, and their interaction)?
>> ????????????????????????? 2.5 %??? 97.5 %
>> .sig01??????? 8.6062568 12.035500
>> .sigma?????? 12.8489647 14.841375
>> (Intercept)? -2.1807253? 9.047992
>> cond1??????? -4.1126524 11.296070
>> cond3??????? -5.8346317? 7.649526
>> rep2???????? -8.0280001? 5.220439
>> rep3???????? -4.0846168? 9.194793
>> rep4????????? 6.1875602 18.878770
>> cond1:rep2? -11.2367698? 8.031134
>> cond3:rep2?? -7.9112913? 7.491230
>> cond1:rep3?? -8.2536791 10.129607
>> cond3:rep3?? -5.9766989 10.071404
>> cond1:rep4?? -0.9371539 17.551132
>> cond3:rep4?? -4.2738610 11.020311
>>
>> Kind regars,
>> Bojana
>>
>> On 26-Nov-21 20:29, marKo wrote:
>>> On 26. 11. 2021. 08:41, Bojana Dinic wrote:
>>>> Dear colleagues,
>>>>
>>>> ???? I use linear mixed models with 1 random effect (subject), 2 fixed
>>>> ???? factors (one? is between factor and another is repeated) and 
>>>> one covariate, and
>>>> ???? explore all main effects, 2-way interactions and one 3-way 
>>>> interaction.
>>>> ???? Regarding of used software, somewhere I get effect of intercept,
>>>> ???? somewhere not. Reviewer asks to use p-adjustment for these
>>>> ???? effects. My dilemma is should I apply p-correction for 7 tests 
>>>> or 8 (including
>>>> ???? random intercept for subjects)?
>>>>
>>>> ???? The output do not contain F for random effect, but only variance.
>>>> ???? Also, the output do not contain effect size. CIs are available 
>>>> only for
>>>> ???? betas as product of specific level of both fixed effects and 
>>>> covariate, but
>>>> ???? since I have 3 levels for between and 4 for repeated effects, the
>>>> ???? output is not helpful + there is no possibility to change 
>>>> reference group.
>>>> ???? Thus, I'm stuck with p-adjustment.
>>>>
>>>> ??? Any help is welcomed.
>>>> ???? Thank you.
>>>>
>>>
>>> As I understand, p-values are somewhat unreliable (In LMM). As a 
>>> sensible alternative maybe you could compute bootstrap CI and use 
>>> that to infer about significance of specific effects (if i have 
>>> understood your problem correctly).
>>> I you use lme4 or nlme, this should not be a problem.
>>>
>>> You ca use (for model? m)
>>>
>>> confint(m, level=0.95, method="boot", nsim=No.of.SIMULATIONS)
>>>
>>> even use some multi-core processing to speed thing up
>>>
>>> confint(m, level=0.95, method="boot", parallel = "multicore", ncpus 
>>> = No.of.CORES, nsim=No.of.SIMULATIONS)
>>>
>>> change No.of.SIMULATIONS with the desired number of repetitions 
>>> (1000 or so)
>>> change No.of.CORES with the desired number of cores (depends of your 
>>> machine).
>>>
>>> Hope it helps.
>>>
>>>
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From b|@hop@g@br|e||@@ @end|ng |rom gm@||@com  Tue Dec  7 10:58:58 2021
From: b|@hop@g@br|e||@@ @end|ng |rom gm@||@com (Gabriella Bishop)
Date: Tue, 7 Dec 2021 10:58:58 +0100
Subject: [R-sig-ME] glmmTMB compatibility for piecewiseSEM 2.1.2?
Message-ID: <CACLfpHj6UzdU0Ov5A-Y45aZw1Pm17Phr1GBaAzHos9mdqVZEFg@mail.gmail.com>

Hi,

I would like to be able to use glmmTMB with piecewiseSEM but I see the
developers of piecewiseSEM have simply left instructions on how to add a
new model class in their readme. This is definitely beyond my coding
abilities and I am wondering if anyone knows of a resource that has
accomplished this. The currently supported model classes are not suitable
for my needs.

The older version of piecewiseSEM does include glmmTMB compatibility but it
does not allow for interaction effects and lacks some key functionality
that was introduced in 2.1.2.

Please let me know if anyone has information or work-arounds!

Thanks very much,
Gabriella

	[[alternative HTML version deleted]]


From mtonc|c @end|ng |rom ||r|@un|r|@hr  Tue Dec  7 23:32:14 2021
From: mtonc|c @end|ng |rom ||r|@un|r|@hr (marko)
Date: Tue, 7 Dec 2021 23:32:14 +0100
Subject: [R-sig-ME] p-correction for effects in LMM
In-Reply-To: <9eb40418-30a7-2144-55f1-a2152498cdaf@gmail.com>
References: <814eac33-350c-f5e0-5d35-727451c5e519@gmail.com>
 <82d6d954-9afc-df69-4000-a40184574bff@ffri.uniri.hr>
 <fa07f367-996f-b283-a0dc-6f05ad60d776@gmail.com>
 <00737030-8883-ae8b-3185-b0d8c0d6b833@ffri.uniri.hr>
 <9eb40418-30a7-2144-55f1-a2152498cdaf@gmail.com>
Message-ID: <633d3e25-1b48-2002-c922-acd8b62ddd25@ffri.uniri.hr>

I think that the only viable option (at least that i know of; please 
someone from the group to back me up on this) is to compare 
competing/nested models (the ones with and without some specific 
parameters; e.g. the model without and with the interaction parameters) 
via LR test ("anova(m1, m2)" in R).

As an estimate of effect size, you can compute omega^2 (even though it 
is just a pseudo R^2 measure; a mere squared correlation between 
predicted and actual results) for those competing/nested models. See 
more in;

Xu, R. (2003). Measuring explained variation in linear mixed effects 
models. Statistics in Medicine, 22(22), 3527?3541. 
https://doi.org/10.1002/sim.1572

I think that some of that is implemented in the package "sjstats" if 
this might be of any help.

Cheers,

Marko



On 12/6/21 11:04 PM, Bojana Dinic wrote:
> Dear Marko,
> Yes, I need effect size for F tests or p-adjustment for it. Thus, is 
> there any procedure to obtain effect sizes or if I use p-adjustments I 
> am not sure whether I need to involve random effect in calculation or 
> not?
> Thank you.
>
> Regards,
> Bojana
>
> On 04-Dec-21 23:38, marKo wrote:
>> I must admit that I do not understand what is that you are asking. 
>> Those CIs are for the parameters of your model (a 3x4 model + random 
>> effects: subject + residuals).
>> The referent group here are cond2 and rep1.
>> Maybe the problem that you have is that you would like to have an F 
>> statistic for the main effects and for the interaction. I do not know.
>>
>> Marko
>>
>>
>> On 04. 12. 2021. 11:26, Bojana Dinic wrote:
>>> Dear Marko,
>>>
>>> Thank you. I have question, these are CIs for which statistic (I 
>>> have 2 factors, cond and rep, and their interaction)?
>>> ????????????????????????? 2.5 %??? 97.5 %
>>> .sig01??????? 8.6062568 12.035500
>>> .sigma?????? 12.8489647 14.841375
>>> (Intercept)? -2.1807253? 9.047992
>>> cond1??????? -4.1126524 11.296070
>>> cond3??????? -5.8346317? 7.649526
>>> rep2???????? -8.0280001? 5.220439
>>> rep3???????? -4.0846168? 9.194793
>>> rep4????????? 6.1875602 18.878770
>>> cond1:rep2? -11.2367698? 8.031134
>>> cond3:rep2?? -7.9112913? 7.491230
>>> cond1:rep3?? -8.2536791 10.129607
>>> cond3:rep3?? -5.9766989 10.071404
>>> cond1:rep4?? -0.9371539 17.551132
>>> cond3:rep4?? -4.2738610 11.020311
>>>
>>> Kind regars,
>>> Bojana
>>>
>>> On 26-Nov-21 20:29, marKo wrote:
>>>> On 26. 11. 2021. 08:41, Bojana Dinic wrote:
>>>>> Dear colleagues,
>>>>>
>>>>> ???? I use linear mixed models with 1 random effect (subject), 2 
>>>>> fixed
>>>>> ???? factors (one? is between factor and another is repeated) and 
>>>>> one covariate, and
>>>>> ???? explore all main effects, 2-way interactions and one 3-way 
>>>>> interaction.
>>>>> ???? Regarding of used software, somewhere I get effect of intercept,
>>>>> ???? somewhere not. Reviewer asks to use p-adjustment for these
>>>>> ???? effects. My dilemma is should I apply p-correction for 7 
>>>>> tests or 8 (including
>>>>> ???? random intercept for subjects)?
>>>>>
>>>>> ???? The output do not contain F for random effect, but only 
>>>>> variance.
>>>>> ???? Also, the output do not contain effect size. CIs are 
>>>>> available only for
>>>>> ???? betas as product of specific level of both fixed effects and 
>>>>> covariate, but
>>>>> ???? since I have 3 levels for between and 4 for repeated effects, 
>>>>> the
>>>>> ???? output is not helpful + there is no possibility to change 
>>>>> reference group.
>>>>> ???? Thus, I'm stuck with p-adjustment.
>>>>>
>>>>> ??? Any help is welcomed.
>>>>> ???? Thank you.
>>>>>
>>>>
>>>> As I understand, p-values are somewhat unreliable (In LMM). As a 
>>>> sensible alternative maybe you could compute bootstrap CI and use 
>>>> that to infer about significance of specific effects (if i have 
>>>> understood your problem correctly).
>>>> I you use lme4 or nlme, this should not be a problem.
>>>>
>>>> You ca use (for model? m)
>>>>
>>>> confint(m, level=0.95, method="boot", nsim=No.of.SIMULATIONS)
>>>>
>>>> even use some multi-core processing to speed thing up
>>>>
>>>> confint(m, level=0.95, method="boot", parallel = "multicore", ncpus 
>>>> = No.of.CORES, nsim=No.of.SIMULATIONS)
>>>>
>>>> change No.of.SIMULATIONS with the desired number of repetitions 
>>>> (1000 or so)
>>>> change No.of.CORES with the desired number of cores (depends of 
>>>> your machine).
>>>>
>>>> Hope it helps.
>>>>
>>>>
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbo|ker @end|ng |rom gm@||@com  Tue Dec  7 23:44:45 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Tue, 7 Dec 2021 17:44:45 -0500
Subject: [R-sig-ME] p-correction for effects in LMM
In-Reply-To: <633d3e25-1b48-2002-c922-acd8b62ddd25@ffri.uniri.hr>
References: <814eac33-350c-f5e0-5d35-727451c5e519@gmail.com>
 <82d6d954-9afc-df69-4000-a40184574bff@ffri.uniri.hr>
 <fa07f367-996f-b283-a0dc-6f05ad60d776@gmail.com>
 <00737030-8883-ae8b-3185-b0d8c0d6b833@ffri.uniri.hr>
 <9eb40418-30a7-2144-55f1-a2152498cdaf@gmail.com>
 <633d3e25-1b48-2002-c922-acd8b62ddd25@ffri.uniri.hr>
Message-ID: <beb7f962-5cf7-6c9e-0b2d-b73a9c0a32b5@gmail.com>

  If you just want to do multiple comparisons corrections (to be honest 
I'm not quite sure what your goal is here -- I can't see why 
multiple-comparisons corrections and computations of effect sizes would 
be solving the same problem ...), then using lmerTest and extracting the 
fixed-effect p-values via

pvals <- coef(summary(fitted_model))[,"Pr(>|t|)"]

and calculating corrections via

p.adjust(pvals, "holm")

(or whatever method you prefer) should work.

Maybe applying car::Anova() to your model, which would give you 
term-level rather than parameter-level p-values, would help?

In the category of effect sizes, the code from 
https://github.com/bcjaeger/r2glmm can compute partial R^2 values for 
LMMs ...

On 12/7/21 5:32 PM, marko wrote:
> I think that the only viable option (at least that i know of; please 
> someone from the group to back me up on this) is to compare 
> competing/nested models (the ones with and without some specific 
> parameters; e.g. the model without and with the interaction parameters) 
> via LR test ("anova(m1, m2)" in R).
> 
> As an estimate of effect size, you can compute omega^2 (even though it 
> is just a pseudo R^2 measure; a mere squared correlation between 
> predicted and actual results) for those competing/nested models. See 
> more in;
> 
> Xu, R. (2003). Measuring explained variation in linear mixed effects 
> models. Statistics in Medicine, 22(22), 3527?3541. 
> https://doi.org/10.1002/sim.1572
> 
> I think that some of that is implemented in the package "sjstats" if 
> this might be of any help.
> 
> Cheers,
> 
> Marko
> 
> 
> 
> On 12/6/21 11:04 PM, Bojana Dinic wrote:
>> Dear Marko,
>> Yes, I need effect size for F tests or p-adjustment for it. Thus, is 
>> there any procedure to obtain effect sizes or if I use p-adjustments I 
>> am not sure whether I need to involve random effect in calculation or 
>> not?
>> Thank you.
>>
>> Regards,
>> Bojana
>>
>> On 04-Dec-21 23:38, marKo wrote:
>>> I must admit that I do not understand what is that you are asking. 
>>> Those CIs are for the parameters of your model (a 3x4 model + random 
>>> effects: subject + residuals).
>>> The referent group here are cond2 and rep1.
>>> Maybe the problem that you have is that you would like to have an F 
>>> statistic for the main effects and for the interaction. I do not know.
>>>
>>> Marko
>>>
>>>
>>> On 04. 12. 2021. 11:26, Bojana Dinic wrote:
>>>> Dear Marko,
>>>>
>>>> Thank you. I have question, these are CIs for which statistic (I 
>>>> have 2 factors, cond and rep, and their interaction)?
>>>> ????????????????????????? 2.5 %??? 97.5 %
>>>> .sig01??????? 8.6062568 12.035500
>>>> .sigma?????? 12.8489647 14.841375
>>>> (Intercept)? -2.1807253? 9.047992
>>>> cond1??????? -4.1126524 11.296070
>>>> cond3??????? -5.8346317? 7.649526
>>>> rep2???????? -8.0280001? 5.220439
>>>> rep3???????? -4.0846168? 9.194793
>>>> rep4????????? 6.1875602 18.878770
>>>> cond1:rep2? -11.2367698? 8.031134
>>>> cond3:rep2?? -7.9112913? 7.491230
>>>> cond1:rep3?? -8.2536791 10.129607
>>>> cond3:rep3?? -5.9766989 10.071404
>>>> cond1:rep4?? -0.9371539 17.551132
>>>> cond3:rep4?? -4.2738610 11.020311
>>>>
>>>> Kind regars,
>>>> Bojana
>>>>
>>>> On 26-Nov-21 20:29, marKo wrote:
>>>>> On 26. 11. 2021. 08:41, Bojana Dinic wrote:
>>>>>> Dear colleagues,
>>>>>>
>>>>>> ???? I use linear mixed models with 1 random effect (subject), 2 
>>>>>> fixed
>>>>>> ???? factors (one? is between factor and another is repeated) and 
>>>>>> one covariate, and
>>>>>> ???? explore all main effects, 2-way interactions and one 3-way 
>>>>>> interaction.
>>>>>> ???? Regarding of used software, somewhere I get effect of intercept,
>>>>>> ???? somewhere not. Reviewer asks to use p-adjustment for these
>>>>>> ???? effects. My dilemma is should I apply p-correction for 7 
>>>>>> tests or 8 (including
>>>>>> ???? random intercept for subjects)?
>>>>>>
>>>>>> ???? The output do not contain F for random effect, but only 
>>>>>> variance.
>>>>>> ???? Also, the output do not contain effect size. CIs are 
>>>>>> available only for
>>>>>> ???? betas as product of specific level of both fixed effects and 
>>>>>> covariate, but
>>>>>> ???? since I have 3 levels for between and 4 for repeated effects, 
>>>>>> the
>>>>>> ???? output is not helpful + there is no possibility to change 
>>>>>> reference group.
>>>>>> ???? Thus, I'm stuck with p-adjustment.
>>>>>>
>>>>>> ??? Any help is welcomed.
>>>>>> ???? Thank you.
>>>>>>
>>>>>
>>>>> As I understand, p-values are somewhat unreliable (In LMM). As a 
>>>>> sensible alternative maybe you could compute bootstrap CI and use 
>>>>> that to infer about significance of specific effects (if i have 
>>>>> understood your problem correctly).
>>>>> I you use lme4 or nlme, this should not be a problem.
>>>>>
>>>>> You ca use (for model? m)
>>>>>
>>>>> confint(m, level=0.95, method="boot", nsim=No.of.SIMULATIONS)
>>>>>
>>>>> even use some multi-core processing to speed thing up
>>>>>
>>>>> confint(m, level=0.95, method="boot", parallel = "multicore", ncpus 
>>>>> = No.of.CORES, nsim=No.of.SIMULATIONS)
>>>>>
>>>>> change No.of.SIMULATIONS with the desired number of repetitions 
>>>>> (1000 or so)
>>>>> change No.of.CORES with the desired number of cores (depends of 
>>>>> your machine).
>>>>>
>>>>> Hope it helps.
>>>>>
>>>>>
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
(Acting) Graduate chair, Mathematics & Statistics


From v@r|n@@ch@ @end|ng |rom y@hoo@|r  Wed Dec  8 17:29:39 2021
From: v@r|n@@ch@ @end|ng |rom y@hoo@|r (varin sacha)
Date: Wed, 8 Dec 2021 16:29:39 +0000 (UTC)
Subject: [R-sig-ME] Reference ?
In-Reply-To: <6d653e26-f048-a565-2038-99a9c2e7d80e@phillipalday.com>
References: <2035506915.12831566.1638647227536.ref@mail.yahoo.com>
 <2035506915.12831566.1638647227536@mail.yahoo.com>
 <PAXPR02MB77981C10DFB439406A216959926B9@PAXPR02MB7798.eurprd02.prod.outlook.com>
 <SYBPR01MB71939A3CD0B57198FD14AF6D986C9@SYBPR01MB7193.ausprd01.prod.outlook.com>
 <68828f6f-ccea-04c7-cbe2-ebac5829dccc@gmail.com>
 <6d653e26-f048-a565-2038-99a9c2e7d80e@phillipalday.com>
Message-ID: <1301870573.14988398.1638980979559@mail.yahoo.com>

Dear all,

Many thanks for all your precious comments.

Best,
SV







Le lundi 6 d?cembre 2021, 07:32:36 UTC+1, Phillip Alday <me at phillipalday.com> a ?crit : 







On 5/12/21 6:09 pm, Ben Bolker wrote:
> ?? More bad news:
> 
> ?* I can't point you to a specific, published/peer-reviewed 'best
> practices in mixed modeling' document; maybe someone else here can.

I don't really know of a single, short-ish document that covers this. A
lot of best practices follow from general statistical and numerical best
practices (see e.g. the "stable and can be trusted" bit that started
this -- you may have precise, well-defined estimates, but that's not
necessarily "stable" in the sense you want; perhaps confidence intervals
would be closer) and the underlying mathematics of mixed models.

There are a lot of introductory texts (both articles and books) on mixed
models in general, mixed models in particular problem domains (e.g.
ecology, cognitive science) and particular issues in mixed models
(random effects selection, etc.), but the quality of these varies
greatly. I recently came across one that has concrete reporting
recommendations (Meteyard and Davies 2020,
https://doi.org/10.1016/j.jml.2020.104092), but I think that they leave
out a lot of fine print (e.g., R2-like measures for mixed models are
problematic; the Kenward-Roger ddf approximation requires inverting a
large matrix, etc.).


> ?* As Chris says, the lack of obvious numerical problems doesn't
> necessarily mean the model estimates are stable.
> ?* The other issue with a small sample is that a lot of the inferential
> machinery of mixed models (p-values, confidence intervals, etc.) rests
> on asymptotic assumptions.
> 
> ?What kinds of "overfitting problems" did you have in mind? What would
> the symptoms be?
> 
> 
> 
> On 12/5/21 6:20 PM, Chris Howden wrote:
>> Hi Sacha,
>>
>> I'm not sure I really agree with that statement, although some may.
>>
>> Say your sample size was really small, only 6. A simple model may
>> still fit, but I wouldn?t expect the parameters to be particularly
>> stable. Only 1 or 2 different datum could change everything.
>>
>> I would also want to consider the SE of the parameter estimates. If
>> they are very large (compared to the parameter estimates), then this
>> is telling me the parameter estimates aren't very stable. Even though
>> the model converged.
>>
>> Chris Howden B.Sc. (Hons)
>> Founding Partner
>> Data Analysis, Modelling and Training
>> Evidence Based Strategy/Policy Development, IP Commercialisation and
>> Innovation
>> (mobile) +61 (0) 410 689 945 | (skype) chris at trickysolutions.com.au
>>
>> -----Original Message-----
>> From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> On
>> Behalf Of Fernando Pedro Bruna Quintas
>> Sent: Sunday, 5 December 2021 6:55 AM
>> To: R-sig-mixed-models <r-sig-mixed-models at r-project.org>; varin sacha
>> <varinsacha at yahoo.fr>
>> Subject: Re: [R-sig-ME] Reference ?
>>
>>
>> Dear SV,
>>
>> I can feel that you have a very promising research career just in
>> front of your eyes.
>>
>> FB
>>
>> ________________________________
>> De: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> en
>> nombre de varin sacha via R-sig-mixed-models
>> <r-sig-mixed-models at r-project.org>
>> Enviado: s bado, 4 de diciembre de 2021 20:47
>> Para: R-sig-mixed-models <r-sig-mixed-models at r-project.org>
>> Asunto: [R-sig-ME] Reference ?
>>
>> Dear Mixed modelers experts,
>>
>> I am looking for a reference to justify my sentence here below.
>> Many thanks for your help.
>>
>> "The mixed model seemed well specified?? it converged and had no
>> singular problem, no overfitting problem. So, even if the sample size
>> is quite small, the estimates are stable and can be trusted".
>>
>> Best Regards,
>> SV
>>
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>> ????[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
> 


From kenj|ro @end|ng |rom @ho|n@@c@jp  Fri Dec 10 12:29:45 2021
From: kenj|ro @end|ng |rom @ho|n@@c@jp (N o s t a l g i a)
Date: Fri, 10 Dec 2021 20:29:45 +0900
Subject: [R-sig-ME] Nested model variance/parameter value
Message-ID: <2e2a3e1f-2e64-78fc-6f63-2e3eb558ec68@shoin.ac.jp>

I am a novice in mixed models, and I am trying to fit a model to a 
survey data with an interval-scale dependent variable (hon), four 
fixed-effect variables (sex, age, schooling, and questions) and two 
random effects. The random effects are interviewer (intv) and 
interviewee (ID), and as such, they are in a nested relationship. Sex, 
age and questions are found to be in an interacting relationship.

A major question I am asking here is whether the interviewer effect is 
significant or not, so I tried the following intercept-only models, 
with model 1 using the nested model, model 2 only the interviewer 
effect, and model 3 only the interviewee effect:

model1 <- lmer(hon ~ sex * age * Question + schooling + (1|intv/ID)
model2 <- lmer(hon ~ sex * age * Question + schooling + (1|intv)
model3 <- lmer(hon ~ sex * age * Question + schooling + (1|ID)

The output from each model says the following:

model 1:
Random effects:
  Groups   Name        Variance Std.Dev.
  ID:intv  (Intercept) 0.03988  0.1997
  intv     (Intercept) 0.00000  0.0000
  Residual             0.16847  0.4105
Number of obs: 3283, groups:  ID:intv, 305; intv, 28

model 2:
Random effects:
  Groups   Name        Variance Std.Dev.
  intv     (Intercept) 0.002348 0.04846
  Residual             0.205998 0.45387
Number of obs: 3283, groups:  intv, 28

model 3:
Random effects:
  Groups   Name        Variance Std.Dev.
  ID       (Intercept) 0.04107  0.2027
  Residual             0.16894  0.4110
Number of obs: 3294, groups:  ID, 306

The respective Log likelihood and AIC values are:

model1	AIC = 4249.232  LL = -2076.616 (df=48)
model2	AIC = 4539.69   LL = -2222.845 (df=47)
model3	AIC = 4274.99   LL = -2090.495 (df=47)

Since I got an error message saying "models were not all fitted to the 
same size of dataset" while running anova(), I compared the AICs and 
concluded that model2 is the best model of the three.

Here I have three questions:

1. Why is the variance for the interviewer effect(intv) zero? Is it 
necessarily so because of the nested model, or is it simply because 
that there is no interviewer effect?

2. If intv is really zero, why does not the model 3 give a better AIC?

3. Am I allowed to compare the three models with AIC as I did above? 
Or should I use LL?

Thanks in advance,

Kenjiro Matsuda


From john@m@|ndon@|d @end|ng |rom @nu@edu@@u  Sat Dec 11 02:03:31 2021
From: john@m@|ndon@|d @end|ng |rom @nu@edu@@u (John Maindonald)
Date: Sat, 11 Dec 2021 01:03:31 +0000
Subject: [R-sig-ME] Nested model variance/parameter value
In-Reply-To: <2e2a3e1f-2e64-78fc-6f63-2e3eb558ec68@shoin.ac.jp>
References: <2e2a3e1f-2e64-78fc-6f63-2e3eb558ec68@shoin.ac.jp>
Message-ID: <2AC0B386-6093-4FB9-8722-1CE35D1F9181@anu.edu.au>

My guess is that you should not be treating answers from different
questions as independent.  They are nested within individuals, and
a main effect is not sufficient to account for systematic differences.
There are shades of the story I heard of an experimenter whose blocks
were made up of plots that moved successively away from the river.
What do you get if you analyse a summary measure for the questionnaire
or individual questions?


John Maindonald             email: john.maindonald at anu.edu.au<mailto:john.maindonald at anu.edu.au>

On 11/12/2021, at 00:29, N o s t a l g i a <kenjiro at shoin.ac.jp<mailto:kenjiro at shoin.ac.jp>> wrote:

I am a novice in mixed models, and I am trying to fit a model to a survey data with an interval-scale dependent variable (hon), four fixed-effect variables (sex, age, schooling, and questions) and two random effects. The random effects are interviewer (intv) and interviewee (ID), and as such, they are in a nested relationship. Sex, age and questions are found to be in an interacting relationship.

A major question I am asking here is whether the interviewer effect is significant or not, so I tried the following intercept-only models, with model 1 using the nested model, model 2 only the interviewer effect, and model 3 only the interviewee effect:

model1 <- lmer(hon ~ sex * age * Question + schooling + (1|intv/ID)
model2 <- lmer(hon ~ sex * age * Question + schooling + (1|intv)
model3 <- lmer(hon ~ sex * age * Question + schooling + (1|ID)

The output from each model says the following:

model 1:
Random effects:
Groups   Name        Variance Std.Dev.
ID:intv  (Intercept) 0.03988  0.1997
intv     (Intercept) 0.00000  0.0000
Residual             0.16847  0.4105
Number of obs: 3283, groups:  ID:intv, 305; intv, 28

model 2:
Random effects:
Groups   Name        Variance Std.Dev.
intv     (Intercept) 0.002348 0.04846
Residual             0.205998 0.45387
Number of obs: 3283, groups:  intv, 28

model 3:
Random effects:
Groups   Name        Variance Std.Dev.
ID       (Intercept) 0.04107  0.2027
Residual             0.16894  0.4110
Number of obs: 3294, groups:  ID, 306

The respective Log likelihood and AIC values are:

model1 AIC = 4249.232  LL = -2076.616 (df=48)
model2 AIC = 4539.69   LL = -2222.845 (df=47)
model3 AIC = 4274.99   LL = -2090.495 (df=47)

Since I got an error message saying "models were not all fitted to the same size of dataset" while running anova(), I compared the AICs and concluded that model2 is the best model of the three.

Here I have three questions:

1. Why is the variance for the interviewer effect(intv) zero? Is it necessarily so because of the nested model, or is it simply because that there is no interviewer effect?

2. If intv is really zero, why does not the model 3 give a better AIC?

3. Am I allowed to compare the three models with AIC as I did above? Or should I use LL?

Thanks in advance,

Kenjiro Matsuda

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://aus01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=04%7C01%7Cjohn.maindonald%40anu.edu.au%7C5a76556ebeb544a5b77e08d9bbd07302%7Ce37d725cab5c46249ae5f0533e486437%7C0%7C0%7C637747797303366625%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000&amp;sdata=leBHp2TfI6mW1m4YIqeMw2czjyr%2FI7wrKiSWxFIAtO0%3D&amp;reserved=0


	[[alternative HTML version deleted]]


From kenj|ro @end|ng |rom @ho|n@@c@jp  Sat Dec 11 06:29:18 2021
From: kenj|ro @end|ng |rom @ho|n@@c@jp (N o s t a l g i a)
Date: Sat, 11 Dec 2021 14:29:18 +0900
Subject: [R-sig-ME] Nested model variance/parameter value
In-Reply-To: <2AC0B386-6093-4FB9-8722-1CE35D1F9181@anu.edu.au>
References: <2e2a3e1f-2e64-78fc-6f63-2e3eb558ec68@shoin.ac.jp>
 <2AC0B386-6093-4FB9-8722-1CE35D1F9181@anu.edu.au>
Message-ID: <58cc93fd-a1ea-b982-23a1-722de7b12028@shoin.ac.jp>

Hi John,

Treating answers (Q) as a random effect nested within an individual 
sounds like an interesting idea. As Qs are not part of my main 
interest, that would pose no problem to me. I guess it would be like:

model4 <- lmer(hon ~ sex * age * Question + schooling + 
(1|intv/ID/Question)

Or should I drop it from the interaction of the fixed effect?

- Ken


On 2021/12/11 10:03, John Maindonald wrote:
> My guess is that you should not be treating answers from different
> questions as independent. ?They are nested within individuals, and
> a main effect is not sufficient to account for systematic differences.
> There are shades of the story I heard of an experimenter whose blocks
> were made up of plots that moved successively away from the river.
> What do you get if you analyse a summary measure for the questionnaire
> or individual questions?
> 
> John Maindonaldemail: john.maindonald at anu.edu.au 
> <mailto:john.maindonald at anu.edu.au>
> 
> 
>> On 11/12/2021, at 00:29, N o s t a l g i a <kenjiro at shoin.ac.jp 
>> <mailto:kenjiro at shoin.ac.jp>> wrote:
>>
>> I am a novice in mixed models, and I am trying to fit a model to a 
>> survey data with an interval-scale dependent variable (hon), four 
>> fixed-effect variables (sex, age, schooling, and questions) and two 
>> random effects. The random effects are interviewer (intv) and 
>> interviewee (ID), and as such, they are in a nested relationship. 
>> Sex, age and questions are found to be in an interacting relationship.
>>
>> A major question I am asking here is whether the interviewer effect 
>> is significant or not, so I tried the following intercept-only 
>> models, with model 1 using the nested model, model 2 only the 
>> interviewer effect, and model 3 only the interviewee effect:
>>
>> model1 <- lmer(hon ~ sex * age * Question + schooling + (1|intv/ID)
>> model2 <- lmer(hon ~ sex * age * Question + schooling + (1|intv)
>> model3 <- lmer(hon ~ sex * age * Question + schooling + (1|ID)
>>
>> The output from each model says the following:
>>
>> model 1:
>> Random effects:
>> Groups ??Name ???????Variance Std.Dev.
>> ID:intv ?(Intercept) 0.03988 ?0.1997
>> intv ????(Intercept) 0.00000 ?0.0000
>> Residual ????????????0.16847 ?0.4105
>> Number of obs: 3283, groups: ?ID:intv, 305; intv, 28
>>
>> model 2:
>> Random effects:
>> Groups ??Name ???????Variance Std.Dev.
>> intv ????(Intercept) 0.002348 0.04846
>> Residual ????????????0.205998 0.45387
>> Number of obs: 3283, groups: ?intv, 28
>>
>> model 3:
>> Random effects:
>> Groups ??Name ???????Variance Std.Dev.
>> ID ??????(Intercept) 0.04107 ?0.2027
>> Residual ????????????0.16894 ?0.4110
>> Number of obs: 3294, groups: ?ID, 306
>>
>> The respective Log likelihood and AIC values are:
>>
>> model1AIC = 4249.232 ?LL = -2076.616 (df=48)
>> model2AIC = 4539.69 ??LL = -2222.845 (df=47)
>> model3AIC = 4274.99 ??LL = -2090.495 (df=47)
>>
>> Since I got an error message saying "models were not all fitted to 
>> the same size of dataset" while running anova(), I compared the AICs 
>> and concluded that model2 is the best model of the three.
>>
>> Here I have three questions:
>>
>> 1. Why is the variance for the interviewer effect(intv) zero? Is it 
>> necessarily so because of the nested model, or is it simply because 
>> that there is no interviewer effect?
>>
>> 2. If intv is really zero, why does not the model 3 give a better AIC?
>>
>> 3. Am I allowed to compare the three models with AIC as I did above? 
>> Or should I use LL?
>>
>> Thanks in advance,
>>
>> Kenjiro Matsuda
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org 
>> <mailto:R-sig-mixed-models at r-project.org> mailing list
>> https://aus01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=04%7C01%7Cjohn.maindonald%40anu.edu.au%7C5a76556ebeb544a5b77e08d9bbd07302%7Ce37d725cab5c46249ae5f0533e486437%7C0%7C0%7C637747797303366625%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000&amp;sdata=leBHp2TfI6mW1m4YIqeMw2czjyr%2FI7wrKiSWxFIAtO0%3D&amp;reserved=0 
>> <https://aus01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=04%7C01%7Cjohn.maindonald%40anu.edu.au%7C5a76556ebeb544a5b77e08d9bbd07302%7Ce37d725cab5c46249ae5f0533e486437%7C0%7C0%7C637747797303366625%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000&amp;sdata=leBHp2TfI6mW1m4YIqeMw2czjyr%2FI7wrKiSWxFIAtO0%3D&amp;reserved=0>
> 


From k@r| @end|ng |rom hu|t|@@org  Sat Dec 11 11:55:30 2021
From: k@r| @end|ng |rom hu|t|@@org (Karl Ove Hufthammer)
Date: Sat, 11 Dec 2021 11:55:30 +0100
Subject: [R-sig-ME] Nested model variance/parameter value
In-Reply-To: <2e2a3e1f-2e64-78fc-6f63-2e3eb558ec68@shoin.ac.jp>
References: <2e2a3e1f-2e64-78fc-6f63-2e3eb558ec68@shoin.ac.jp>
Message-ID: <cdf5cadd-24ca-7c6a-19fd-1b6b65199e2e@huftis.org>

N o s t a l g i a skreiv 10.12.2021 12:29:
> Since I got an error message saying "models were not all fitted to the 
> same size of dataset" while running anova(), I compared the AICs and 
> concluded that model2 is the best model of the three.

No, model 2 has the *highest* AIC, and based on AIC, it would be the 
*worst* model. The best model would be the one with the lowest AIC. 
(Also, it doesn?t seem realistic to assume no random effect for the 
interviewees, so I would also dismiss model 2 based on *theoretical* 
grounds.)

But in this case, comparing the AICs (or log likelihood) is actually 
*not* valid, as the data were not fitted to the same dataset (something 
which anova() warns you about). In model 3, you have 3294 observations, 
but in model 1 and 2, you only have 3283 observations. The only 
difference between the models is that model 3 doesn?t include the ?intv? 
variable. In other words, for 11 responses, you don?t know who the 
interviewer was.

So you have to refit the models to the *same* dataset, e.g., by removing 
the observation where ?is.na(intv)? before fitting the models.


-- 
Karl Ove Hufthammer


From john@m@|ndon@|d @end|ng |rom @nu@edu@@u  Sat Dec 11 19:58:18 2021
From: john@m@|ndon@|d @end|ng |rom @nu@edu@@u (John Maindonald)
Date: Sat, 11 Dec 2021 18:58:18 +0000
Subject: [R-sig-ME] Nested model variance/parameter value
In-Reply-To: <58cc93fd-a1ea-b982-23a1-722de7b12028@shoin.ac.jp>
References: <2e2a3e1f-2e64-78fc-6f63-2e3eb558ec68@shoin.ac.jp>
 <2AC0B386-6093-4FB9-8722-1CE35D1F9181@anu.edu.au>
 <58cc93fd-a1ea-b982-23a1-722de7b12028@shoin.ac.jp>
Message-ID: <64F05672-B0CE-433A-B9BA-27785258E15A@anu.edu.au>

Possibly, you need to allow for a within individual correlation structure.
What I should have said was that the correlation structure within
individuals persists even when allowance is made for the other fixed
effects.  But why not start by looking at total scores?  Looking at
principal components after a principal components breakdown might
be another possibility.  Have you been able to find published analyses,
or on the web, that have broken results down by individual question0
results?

John Maindonald             email: john.maindonald at anu.edu.au<mailto:john.maindonald at anu.edu.au>


On 11/12/2021, at 18:29, N o s t a l g i a <kenjiro at shoin.ac.jp<mailto:kenjiro at shoin.ac.jp>> wrote:

Hi John,

Treating answers (Q) as a random effect nested within an individual sounds like an interesting idea. As Qs are not part of my main interest, that would pose no problem to me. I guess it would be like:

model4 <- lmer(hon ~ sex * age * Question + schooling + (1|intv/ID/Question)

Or should I drop it from the interaction of the fixed effect?

- Ken


On 2021/12/11 10:03, John Maindonald wrote:
My guess is that you should not be treating answers from different
questions as independent.  They are nested within individuals, and
a main effect is not sufficient to account for systematic differences.
There are shades of the story I heard of an experimenter whose blocks
were made up of plots that moved successively away from the river.
What do you get if you analyse a summary measure for the questionnaire
or individual questions?
John Maindonaldemail: john.maindonald at anu.edu.au<mailto:john.maindonald at anu.edu.au> <mailto:john.maindonald at anu.edu.au>
On 11/12/2021, at 00:29, N o s t a l g i a <kenjiro at shoin.ac.jp<mailto:kenjiro at shoin.ac.jp> <mailto:kenjiro at shoin.ac.jp>> wrote:

I am a novice in mixed models, and I am trying to fit a model to a survey data with an interval-scale dependent variable (hon), four fixed-effect variables (sex, age, schooling, and questions) and two random effects. The random effects are interviewer (intv) and interviewee (ID), and as such, they are in a nested relationship. Sex, age and questions are found to be in an interacting relationship.

A major question I am asking here is whether the interviewer effect is significant or not, so I tried the following intercept-only models, with model 1 using the nested model, model 2 only the interviewer effect, and model 3 only the interviewee effect:

model1 <- lmer(hon ~ sex * age * Question + schooling + (1|intv/ID)
model2 <- lmer(hon ~ sex * age * Question + schooling + (1|intv)
model3 <- lmer(hon ~ sex * age * Question + schooling + (1|ID)

The output from each model says the following:

model 1:
Random effects:
Groups   Name        Variance Std.Dev.
ID:intv  (Intercept) 0.03988  0.1997
intv     (Intercept) 0.00000  0.0000
Residual             0.16847  0.4105
Number of obs: 3283, groups:  ID:intv, 305; intv, 28

model 2:
Random effects:
Groups   Name        Variance Std.Dev.
intv     (Intercept) 0.002348 0.04846
Residual             0.205998 0.45387
Number of obs: 3283, groups:  intv, 28

model 3:
Random effects:
Groups   Name        Variance Std.Dev.
ID       (Intercept) 0.04107  0.2027
Residual             0.16894  0.4110
Number of obs: 3294, groups:  ID, 306

The respective Log likelihood and AIC values are:

model1AIC = 4249.232  LL = -2076.616 (df=48)
model2AIC = 4539.69   LL = -2222.845 (df=47)
model3AIC = 4274.99   LL = -2090.495 (df=47)

Since I got an error message saying "models were not all fitted to the same size of dataset" while running anova(), I compared the AICs and concluded that model2 is the best model of the three.

Here I have three questions:

1. Why is the variance for the interviewer effect(intv) zero? Is it necessarily so because of the nested model, or is it simply because that there is no interviewer effect?

2. If intv is really zero, why does not the model 3 give a better AIC?

3. Am I allowed to compare the three models with AIC as I did above? Or should I use LL?

Thanks in advance,

Kenjiro Matsuda

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> <mailto:R-sig-mixed-models at r-project.org> mailing list
https://aus01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=04%7C01%7Cjohn.maindonald%40anu.edu.au%7Cdbe70cc56c264314b20508d9bc673512%7Ce37d725cab5c46249ae5f0533e486437%7C0%7C0%7C637747973731627086%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000&amp;sdata=ei93uMUtP1IC3TPFAriLh0VcHVQjaTY8OXfOs9uVDdk%3D&amp;reserved=0<https://aus01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=04%7C01%7Cjohn.maindonald%40anu.edu.au%7Cdbe70cc56c264314b20508d9bc673512%7Ce37d725cab5c46249ae5f0533e486437%7C0%7C0%7C637747973731627086%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000&amp;sdata=ei93uMUtP1IC3TPFAriLh0VcHVQjaTY8OXfOs9uVDdk%3D&amp;reserved=0>


	[[alternative HTML version deleted]]


From kenj|ro @end|ng |rom @ho|n@@c@jp  Mon Dec 13 07:38:22 2021
From: kenj|ro @end|ng |rom @ho|n@@c@jp (N o s t a l g i a)
Date: Mon, 13 Dec 2021 15:38:22 +0900
Subject: [R-sig-ME] Nested model variance/parameter value
In-Reply-To: <cdf5cadd-24ca-7c6a-19fd-1b6b65199e2e@huftis.org>
References: <2e2a3e1f-2e64-78fc-6f63-2e3eb558ec68@shoin.ac.jp>
 <cdf5cadd-24ca-7c6a-19fd-1b6b65199e2e@huftis.org>
Message-ID: <3ad6730e-15ca-c6dc-3e96-f2636731c86e@shoin.ac.jp>

Karl,

Thanks for pointing out my mistakes. Yes,I should have chosen model1 
with the least AIC among the three, and I should not have compared the 
three with different dataset to start with.

I went back the original dataset and deleted all the cases that 
includes NAs manually (somehow "na.action = na.exclude, data = third2" 
did not work). Now anova() works fine, and the best model turned out 
to be (anova-wise as well asa AIC-wise) the one with only ID as the 
random variable. Everything seems fine -- except that the variace for 
intv remained zero in the model that incorporates both intv and ID as 
a random variable.  This probably I need to accept as it is: there is 
absolutely no interviewer effect.

Thanks again,

- Ken


On 2021/12/11 19:55, Karl Ove Hufthammer wrote:
> N o s t a l g i a skreiv 10.12.2021 12:29:
>> Since I got an error message saying "models were not all fitted to 
>> the same size of dataset" while running anova(), I compared the AICs 
>> and concluded that model2 is the best model of the three.
> 
> No, model 2 has the *highest* AIC, and based on AIC, it would be the 
> *worst* model. The best model would be the one with the lowest AIC. 
> (Also, it doesn?t seem realistic to assume no random effect for the 
> interviewees, so I would also dismiss model 2 based on *theoretical* 
> grounds.)
> 
> But in this case, comparing the AICs (or log likelihood) is actually 
> *not* valid, as the data were not fitted to the same dataset 
> (something which anova() warns you about). In model 3, you have 3294 
> observations, but in model 1 and 2, you only have 3283 observations. 
> The only difference between the models is that model 3 doesn?t include 
> the ?intv? variable. In other words, for 11 responses, you don?t know 
> who the interviewer was.
> 
> So you have to refit the models to the *same* dataset, e.g., by 
> removing the observation where ?is.na(intv)? before fitting the models.
> 
> 


From w@ngt@one|u @end|ng |rom gm@||@com  Mon Dec 13 02:28:35 2021
From: w@ngt@one|u @end|ng |rom gm@||@com (tao wang)
Date: Mon, 13 Dec 2021 09:28:35 +0800
Subject: [R-sig-ME] How can I predict a new data (or newlevel) for
 generalized linear mixed model with both random and fixed effect in GLMM
Message-ID: <CAJiQag9xhxRVJ2Ac-e1zrnrSRKqPT-87-d0LH-D7bEZNNTN5fg@mail.gmail.com>

A non-text attachment was scrubbed...
Name: NonlinearMixedVolume-AgeModel-2013A.pdf
Type: application/pdf
Size: 2138140 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20211213/eeea86c7/attachment-0001.pdf>

From @dh@n333 @end|ng |rom gm@||@com  Mon Dec 13 16:49:40 2021
From: @dh@n333 @end|ng |rom gm@||@com (=?UTF-8?B?U2HDomQgSEFOQU5F?=)
Date: Mon, 13 Dec 2021 16:49:40 +0100
Subject: [R-sig-ME] GLMM replicated data
Message-ID: <CA+QAJT7-sW-+KC-gsB64PZDsAGv3DxFF19n5SLZWYRdtg9Y4PQ@mail.gmail.com>

Dear all,
One aim of my study is to assess the effect of temporal variation in
habitat availability on the number of male singing per point count (p). To
this end, 60 point counts were randomly distributed in the study area, but
these points were fixed over the months (I recorded the number of singing
males at the same points but at successive months). At each point, I
recorded the cover of habitat available (e.g., shrubs, cereals,
alfalfa...etc).
I'm wondering if I should consider the ID as a random factor in this case?
If yes, is this command correct?
model=glmer(p~cover of habitat + (1|month/ID), famlily=poisson, data=data)
Thank you very much for your help.
Regards
---
Sa?d Hanane, PhD
Service d'?cologie, de Biodiversit? et de Conservation des Sols
Centre de Recherche Foresti?re
Chariae Omar Ibn Al Khattab, BP 763, Rabat-Agdal/Maroc.

	[[alternative HTML version deleted]]


From mo|||eebrook@ @end|ng |rom gm@||@com  Mon Dec 13 17:13:30 2021
From: mo|||eebrook@ @end|ng |rom gm@||@com (Mollie Brooks)
Date: Mon, 13 Dec 2021 17:13:30 +0100
Subject: [R-sig-ME] GLMM replicated data
In-Reply-To: <CA+QAJT7-sW-+KC-gsB64PZDsAGv3DxFF19n5SLZWYRdtg9Y4PQ@mail.gmail.com>
References: <CA+QAJT7-sW-+KC-gsB64PZDsAGv3DxFF19n5SLZWYRdtg9Y4PQ@mail.gmail.com>
Message-ID: <00F57BE3-C9DE-4C1B-896A-824A3CBAC0DD@gmail.com>

You probably want crossed random effects of month and point ID:

model=glmer(p~cover of habitat + (1|month)+(1|ID), famlily=poisson, data=data)

Does your variable "cover of habitat" change over the months to possibly capture the effect of temporal variation in
habitat availability that you want? If "cover of habitat" is constant through time, then all of the temporal variation will be represented in your random effect of month. If  "cover of habitat" changes through time, then it will include part of the temporal variation, but some will still go into the random effect of month.

Using the Poisson distribution is an assumption that is usually violated in ecology. After fitting the model, you could check for over- or underdispersion and then consider a negative binomial distribution if it?s overdispersed or a Conway Maxwell Poisson if it?s underdispersed. I wrote about dispersion issues in this paper: Brooks, M. E., K. Kristensen, M. R. Darrigo, P. Rubim, M. Uriarte, E. Bruna, and B. M. Bolker. 2019. Statistical modeling of patterns in annual reproductive rates. Ecology 00(00):e02706. 10.1002/ecy.2706. Let me know if you want a copy.

Cheers,
Mollie


> On 13 Dec 2021, at 16.49, Sa?d HANANE <sdhan333 at gmail.com> wrote:
> 
> Dear all,
> One aim of my study is to assess the effect of temporal variation in
> habitat availability on the number of male singing per point count (p). To
> this end, 60 point counts were randomly distributed in the study area, but
> these points were fixed over the months (I recorded the number of singing
> males at the same points but at successive months). At each point, I
> recorded the cover of habitat available (e.g., shrubs, cereals,
> alfalfa...etc).
> I'm wondering if I should consider the ID as a random factor in this case?
> If yes, is this command correct?
> model=glmer(p~cover of habitat + (1|month/ID), famlily=poisson, data=data)
> Thank you very much for your help.
> Regards
> ---
> Sa?d Hanane, PhD
> Service d'?cologie, de Biodiversit? et de Conservation des Sols
> Centre de Recherche Foresti?re
> Chariae Omar Ibn Al Khattab, BP 763, Rabat-Agdal/Maroc.
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


	[[alternative HTML version deleted]]


From j@m|ed@||@@88 @end|ng |rom gm@||@com  Mon Dec 13 22:36:28 2021
From: j@m|ed@||@@88 @end|ng |rom gm@||@com (Jamie Dallas)
Date: Mon, 13 Dec 2021 13:36:28 -0800
Subject: [R-sig-ME] A GLMER Question
Message-ID: <CAMUd9hEiX7erLad2cPEOSimB8rTbVLF-EG9k4PGy4jsTA+eN7g@mail.gmail.com>

Hello All,
I am running a GLMER with Gamma distribution and identity link. I have to
add a small constant (1 or 0.001) to my outcome to be able to run my models.

I know in a linear regression with Normality assumption, this only effects
my intercept but my other coefficient estimates will stay the same.

However, in my GLMER models I am noticing the choice of constant effects
all my parameter estimates. I thought since I am using an identity link
this should not happen.

1- Is my understanding wrong?

2- Why are my parameter estimates changing in my Gamma distributed GLMER
with identity link models, depending on the choice of added constant to my
outcome?

Thank you in advance!

Best,

Jamie

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Wed Dec 15 00:48:58 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Tue, 14 Dec 2021 18:48:58 -0500
Subject: [R-sig-ME] A GLMER Question
In-Reply-To: <CAMUd9hEiX7erLad2cPEOSimB8rTbVLF-EG9k4PGy4jsTA+eN7g@mail.gmail.com>
References: <CAMUd9hEiX7erLad2cPEOSimB8rTbVLF-EG9k4PGy4jsTA+eN7g@mail.gmail.com>
Message-ID: <97f1afc4-ff50-9537-c01e-dd10da08efa8@gmail.com>



On 12/13/21 4:36 PM, Jamie Dallas wrote:
> Hello All,
> I am running a GLMER with Gamma distribution and identity link. I have to
> add a small constant (1 or 0.001) to my outcome to be able to run my models.
> 
> I know in a linear regression with Normality assumption, this only effects
> my intercept but my other coefficient estimates will stay the same.
> 
> However, in my GLMER models I am noticing the choice of constant effects
> all my parameter estimates. I thought since I am using an identity link
> this should not happen.
> 
> 1- Is my understanding wrong?
> 
> 2- Why are my parameter estimates changing in my Gamma distributed GLMER
> with identity link models, depending on the choice of added constant to my
> outcome?
> 
> Thank you in advance!
> 
> Best,
> 
> Jamie

   I don't necessarily see why you should expect the slopes to be 
invariant; GLMs don't have the same properties as LMs, even with an 
identity link. "Small" will be context-dependent.  If this makes much of 
a difference to your results, or if you have more than a few zero 
values, you might need to think about a more principled approach such as 
a hurdle model ...

Example:

library(lme4)
dd <- data.frame(x = runif(100),
                  f = factor(rep(1:10, 10)))
set.seed(101)
dd$y <- simulate(~ x + (1|f),
                  family = Gamma(link = "identity"),
                  newdata = dd,
                  newparams = list(beta = rep(1,2),
                                   theta = 1,
                                   sigma = 1))[[1]]
dd$y[sample(nrow(dd), size = 10)] <- 0

fitf <- function(off) {
     g1 <- glmer(y + off ~ x + (1|f),
                 family = Gamma(link = "identity"),
                 data = dd)
     return(fixef(g1))
}

try(fitf(0))
offvec <- 10^c((-5):(-2))
cbind(offvec, t(sapply(offvec, fitf)))


      offvec (Intercept)           x
[1,]  1e-05    1.408488 -0.08994451
[2,]  1e-04    1.408578 -0.08994445
[3,]  1e-03    1.409508 -0.09000147
[4,]  1e-02    1.085238  0.45049626
 >

try(fitf(0))
offvec <- 10^c((-5):(-2))
cbind(offvec, t(sapply(offvec, fitf)))


From mrm|500 @end|ng |rom york@@c@uk  Mon Dec 20 18:43:34 2021
From: mrm|500 @end|ng |rom york@@c@uk (Mike Lawson)
Date: Mon, 20 Dec 2021 17:43:34 +0000
Subject: [R-sig-ME] 
 Modelling with uncertain (but not missing) categorical
 random effect values
In-Reply-To: <b15a5261-9d37-9283-0f61-3c776cb1f929@gmail.com>
References: <CACtWw1HWv6ph0vwt4TLpUxiojZ_3993Kop0bvfXe=3yt2Lu9JA@mail.gmail.com>
 <CAJuCY5xD_4QNNhbKMOjsJ2uQETWyHzaBznkUxg65_+QV-5Vw9A@mail.gmail.com>
 <47d07adf-6db0-e441-6e86-29d896c12ad1@phillipalday.com>
 <b15a5261-9d37-9283-0f61-3c776cb1f929@gmail.com>
Message-ID: <CACtWw1Hza-aaBy3hq8RrqqwwXdt5zWC31U2mejeF0-0HPSTg+g@mail.gmail.com>

Thanks for the suggestions Philip and Ben,

I'm coming back to this after a hiatus and this may be quite a basic question.

I managed to get the lme4 hack working with my data, but not if I
include other random effects (that are not multi membership and not in
the matrix).
i.e. in the example you provide, if I add a new random predictor, how
do I incorporate this into the model? As this line directly changes
Ztlist and Zt to be the matrix:

lmod$reTrms$Zt <- lmod$reTrms$Ztlist[[1]] <- Matrix(t(W))

Many thanks,
Mike


On Tue, 3 Aug 2021 at 23:16, Ben Bolker <bbolker at gmail.com> wrote:
>
>    Also see
> https://bbolker.github.io/mixedmodels-misc/notes/multimember.html (i.e.
> you can do it in lme4, but it takes a bit of hacking)
>
> On 8/3/21 5:19 PM, Phillip Alday wrote:
> > If I'm not mistaken, Thierry's suggestion is a particular case of
> > multi-membership models, which you can also do in brms. See e.g.:
> >
> >
> > https://rdrr.io/cran/brms/man/mm.html
> >
> > https://github.com/paul-buerkner/brms/issues/130
> >
> > https://discourse.mc-stan.org/t/cross-classified-multiple-membership-models-with-brms/8691
> >
> >
> > On 13/07/2021 06:09, Thierry Onkelinx via R-sig-mixed-models wrote:
> >> Dear Michael,
> >>
> >> Maybe something like (0 + w_1 | dad_1) + (0 + w_2 | dad_2) + (0 + w_3 |
> >> dad_3). Where w_1 is the probability of dad_1.
> >>
> >> Make sure that dad_1, dad_2 and dad_3 are factors with the same levels.
> >> Then INLA allows you to add this as f(dad_1, w_1, model = "iid") + f(dad_2,
> >> w_2, copy = "dad_"1) + f(dad_3, w_3, copy = "dad_1"). So you end up with a
> >> single random intercept for every dad (dad_2 and dad_3 share their
> >> estimates with dad_1).
> >>
> >> mum_id  mum_sp  dad_sp dad_id                    con    dad_1   w_1 dad_2
> >> w_ 2 dad_3 w_3
> >>
> >> Af1          A              A           Am1 / Am2             1      Am1
> >> 0.6   Am2 0.4  NA 0
> >> Af1          A              A           Am2                       1
> >> Am2    1     NA     0     NA 0
> >> Bf1          B             A           Am1 / Am2 / Am4   0      Am1    0.4
> >>   Am2 0.3   Am4 0.3
> >> Bf2          B              B          Bm1 / Bm3              1      Bm1
> >> 0.5   Bm2  0.5  NA 0
> >>
> >> Best regards,
> >>
> >> ir. Thierry Onkelinx
> >> Statisticus / Statistician
> >>
> >> Vlaamse Overheid / Government of Flanders
> >> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
> >> FOREST
> >> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> >> thierry.onkelinx at inbo.be
> >> Havenlaan 88 bus 73, 1000 Brussel
> >> www.inbo.be
> >>
> >> ///////////////////////////////////////////////////////////////////////////////////////////
> >> To call in the statistician after the experiment is done may be no more
> >> than asking him to perform a post-mortem examination: he may be able to say
> >> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> >> The plural of anecdote is not data. ~ Roger Brinner
> >> The combination of some data and an aching desire for an answer does not
> >> ensure that a reasonable answer can be extracted from a given body of data.
> >> ~ John Tukey
> >> ///////////////////////////////////////////////////////////////////////////////////////////
> >>
> >> <https://www.inbo.be>
> >>
> >>
> >> Op di 13 jul. 2021 om 12:30 schreef Michael Lawson via R-sig-mixed-models <
> >> r-sig-mixed-models at r-project.org>:
> >>
> >>> I have a dataset where I have offspring paternity of females with
> >>> males of different species. However, many of the offspring have
> >>> ambiguous paternity - where I know the offspring must be from
> >>> particular fathers, but not from others. The data currently looks a
> >>> bit like this (but with many more rows per mum_id):
> >>>
> >>> mum_id  mum_sp  dad_sp dad_id                    con
> >>>
> >>> Af1          A              A           Am1 / Am2             1
> >>> Af1          A              A           Am2                       1
> >>> Bf1          B             A           Am1 / Am2 / Am4   0
> >>> Bf2          B              B          Bm1 / Bm3              1
> >>>
> >>> Which I have so far run as a binomial GLMM with con (conspecific mating) as
> >>> a binary response, mum_sp and dad_sp (species) as fixed factors and
> >>> mum_id as a random factor - and have just not included dad_id as
> >>> a random factor. The ambiguously assigned fathers in dad_id is also
> >>> non-random, i.e.
> >>> certain individuals are more likely to be ambiguously assigned than
> >>> others, so just leaving these cases as NA is problematic.
> >>>
> >>> For some of the ambiguous assignments, I can also extract
> >>> probabilities that a possible male is the father of the offspring,
> >>> e.g. for the first row, father Am1 is 60% likely to be the father and
> >>> Am2 40% likely.
> >>>
> >>> Are there any approaches where I can include the ambiguous dad_id in
> >>> a GLMM framework? - where the uncertainty of the assignment contributes to
> >>> the
> >>> overall uncertainty in the tested relationship.
> >>>
> >>> Thank you for any suggestions,
> >>> Mike
> >>>
> >>> _______________________________________________
> >>> R-sig-mixed-models at r-project.org mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>>
> >>      [[alternative HTML version deleted]]
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
> --
> Dr. Benjamin Bolker
> Professor, Mathematics & Statistics and Biology, McMaster University
> Director, School of Computational Science and Engineering
> Graduate chair, Mathematics & Statistics
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbo|ker @end|ng |rom gm@||@com  Mon Dec 20 19:10:52 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Mon, 20 Dec 2021 13:10:52 -0500
Subject: [R-sig-ME] 
 Modelling with uncertain (but not missing) categorical
 random effect values
In-Reply-To: <CACtWw1Hza-aaBy3hq8RrqqwwXdt5zWC31U2mejeF0-0HPSTg+g@mail.gmail.com>
References: <CACtWw1HWv6ph0vwt4TLpUxiojZ_3993Kop0bvfXe=3yt2Lu9JA@mail.gmail.com>
 <CAJuCY5xD_4QNNhbKMOjsJ2uQETWyHzaBznkUxg65_+QV-5Vw9A@mail.gmail.com>
 <47d07adf-6db0-e441-6e86-29d896c12ad1@phillipalday.com>
 <b15a5261-9d37-9283-0f61-3c776cb1f929@gmail.com>
 <CACtWw1Hza-aaBy3hq8RrqqwwXdt5zWC31U2mejeF0-0HPSTg+g@mail.gmail.com>
Message-ID: <79b321be-8d3c-6224-485f-0653ff3e9645@gmail.com>

    Something like:

   lmod$reTrms$Ztlist <- list(Matrix(t(W)), Z2, Z3, Z4, ...)

where the additional `Z` components are the random-effects models for 
the additional terms you want (you could for example pull these from an 
`lFormula()` call using a formula that included those components in the 
random effects), and

   lmod$reTrms$Zt <- do.call(rbind, lmod$reTrms$Ztlist)

(I think)

On 12/20/21 12:43 PM, Mike Lawson wrote:
> Thanks for the suggestions Philip and Ben,
> 
> I'm coming back to this after a hiatus and this may be quite a basic question.
> 
> I managed to get the lme4 hack working with my data, but not if I
> include other random effects (that are not multi membership and not in
> the matrix).
> i.e. in the example you provide, if I add a new random predictor, how
> do I incorporate this into the model? As this line directly changes
> Ztlist and Zt to be the matrix:
> 
> lmod$reTrms$Zt <- lmod$reTrms$Ztlist[[1]] <- Matrix(t(W))
> 
> Many thanks,
> Mike
> 
> 
> On Tue, 3 Aug 2021 at 23:16, Ben Bolker <bbolker at gmail.com> wrote:
>>
>>     Also see
>> https://bbolker.github.io/mixedmodels-misc/notes/multimember.html (i.e.
>> you can do it in lme4, but it takes a bit of hacking)
>>
>> On 8/3/21 5:19 PM, Phillip Alday wrote:
>>> If I'm not mistaken, Thierry's suggestion is a particular case of
>>> multi-membership models, which you can also do in brms. See e.g.:
>>>
>>>
>>> https://rdrr.io/cran/brms/man/mm.html
>>>
>>> https://github.com/paul-buerkner/brms/issues/130
>>>
>>> https://discourse.mc-stan.org/t/cross-classified-multiple-membership-models-with-brms/8691
>>>
>>>
>>> On 13/07/2021 06:09, Thierry Onkelinx via R-sig-mixed-models wrote:
>>>> Dear Michael,
>>>>
>>>> Maybe something like (0 + w_1 | dad_1) + (0 + w_2 | dad_2) + (0 + w_3 |
>>>> dad_3). Where w_1 is the probability of dad_1.
>>>>
>>>> Make sure that dad_1, dad_2 and dad_3 are factors with the same levels.
>>>> Then INLA allows you to add this as f(dad_1, w_1, model = "iid") + f(dad_2,
>>>> w_2, copy = "dad_"1) + f(dad_3, w_3, copy = "dad_1"). So you end up with a
>>>> single random intercept for every dad (dad_2 and dad_3 share their
>>>> estimates with dad_1).
>>>>
>>>> mum_id  mum_sp  dad_sp dad_id                    con    dad_1   w_1 dad_2
>>>> w_ 2 dad_3 w_3
>>>>
>>>> Af1          A              A           Am1 / Am2             1      Am1
>>>> 0.6   Am2 0.4  NA 0
>>>> Af1          A              A           Am2                       1
>>>> Am2    1     NA     0     NA 0
>>>> Bf1          B             A           Am1 / Am2 / Am4   0      Am1    0.4
>>>>    Am2 0.3   Am4 0.3
>>>> Bf2          B              B          Bm1 / Bm3              1      Bm1
>>>> 0.5   Bm2  0.5  NA 0
>>>>
>>>> Best regards,
>>>>
>>>> ir. Thierry Onkelinx
>>>> Statisticus / Statistician
>>>>
>>>> Vlaamse Overheid / Government of Flanders
>>>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
>>>> FOREST
>>>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
>>>> thierry.onkelinx at inbo.be
>>>> Havenlaan 88 bus 73, 1000 Brussel
>>>> www.inbo.be
>>>>
>>>> ///////////////////////////////////////////////////////////////////////////////////////////
>>>> To call in the statistician after the experiment is done may be no more
>>>> than asking him to perform a post-mortem examination: he may be able to say
>>>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>>>> The plural of anecdote is not data. ~ Roger Brinner
>>>> The combination of some data and an aching desire for an answer does not
>>>> ensure that a reasonable answer can be extracted from a given body of data.
>>>> ~ John Tukey
>>>> ///////////////////////////////////////////////////////////////////////////////////////////
>>>>
>>>> <https://www.inbo.be>
>>>>
>>>>
>>>> Op di 13 jul. 2021 om 12:30 schreef Michael Lawson via R-sig-mixed-models <
>>>> r-sig-mixed-models at r-project.org>:
>>>>
>>>>> I have a dataset where I have offspring paternity of females with
>>>>> males of different species. However, many of the offspring have
>>>>> ambiguous paternity - where I know the offspring must be from
>>>>> particular fathers, but not from others. The data currently looks a
>>>>> bit like this (but with many more rows per mum_id):
>>>>>
>>>>> mum_id  mum_sp  dad_sp dad_id                    con
>>>>>
>>>>> Af1          A              A           Am1 / Am2             1
>>>>> Af1          A              A           Am2                       1
>>>>> Bf1          B             A           Am1 / Am2 / Am4   0
>>>>> Bf2          B              B          Bm1 / Bm3              1
>>>>>
>>>>> Which I have so far run as a binomial GLMM with con (conspecific mating) as
>>>>> a binary response, mum_sp and dad_sp (species) as fixed factors and
>>>>> mum_id as a random factor - and have just not included dad_id as
>>>>> a random factor. The ambiguously assigned fathers in dad_id is also
>>>>> non-random, i.e.
>>>>> certain individuals are more likely to be ambiguously assigned than
>>>>> others, so just leaving these cases as NA is problematic.
>>>>>
>>>>> For some of the ambiguous assignments, I can also extract
>>>>> probabilities that a possible male is the father of the offspring,
>>>>> e.g. for the first row, father Am1 is 60% likely to be the father and
>>>>> Am2 40% likely.
>>>>>
>>>>> Are there any approaches where I can include the ambiguous dad_id in
>>>>> a GLMM framework? - where the uncertainty of the assignment contributes to
>>>>> the
>>>>> overall uncertainty in the tested relationship.
>>>>>
>>>>> Thank you for any suggestions,
>>>>> Mike
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>
>>>>       [[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>> --
>> Dr. Benjamin Bolker
>> Professor, Mathematics & Statistics and Biology, McMaster University
>> Director, School of Computational Science and Engineering
>> Graduate chair, Mathematics & Statistics
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
Graduate chair, Mathematics & Statistics


From t|bor@k|@@ @end|ng |rom ruhr-un|-bochum@de  Mon Dec 20 19:56:16 2021
From: t|bor@k|@@ @end|ng |rom ruhr-un|-bochum@de (Tibor Kiss)
Date: Mon, 20 Dec 2021 19:56:16 +0100
Subject: [R-sig-ME] Random structure more complex than fixed structure
Message-ID: <566A93D4-DB13-492E-8A2D-EB32F8339293@ruhr-uni-bochum.de>

Dear list members,

I have a model where I assume a more complex structure for the random effects than for the fixed effects. Schematically, the model looks like the following, it is a cumulative link mixed model (ordinal::clmm), because the response consists of a five point Likert scale (the same would apply to a binomial GLMM). You can find the output of the model for the fixed and random structures below.

model <- 
  clmm(ANSWER  ~ ADVERBIAL  + POSITION + 
         (0 + ADVERBIAL * POSITION | subjects) +
         (0 + POSITION | items),  # ADVERBIAL constant for items
       data)

The reason for assuming random slopes with interaction, but no such interaction in the fixed effects are as follows:

1. I am interested in the by-subject variability for each condition. This is a 3 x 2 design, with three ADVERBIAL types, and two POSITIONs, and I assume that there is less by-subject variance in the second level of POSITION. Hence, I need an interaction to get simple effects for each combination of the two predictors.

2. If I compare this model with a simpler one, where I assume a random slope for POSITION only, then the more complex structure is indicated as significant in comparison to the simpler model (p < 0.01). 

3. Also, an interaction of the fixed effects does not prove to be significant.

In addition, the output of the model makes perfect sense to me: for each pair of POSITION and ADVERBIAL the by-subject variance for POSITION 2 is lower than the one for POSITION 1, which I interpret as a stronger confidence in judgments for POSITION 2 across the participants of the experiment. 

My question is: is it ok/justified to assume a random structure that is more complex than the fixed structure, if I want to find out about the by-subject variability for each condition in an experiment. Also: would there be a simpler way to do the same? 

Thanks for your help.

With kind regards


Tibor

## Coefficients:
##                     			 Estimate Std. Error z value Pr(>|z|)    
## ADVERBIAL COM(O)  	-0.9571     0.3479  -2.751  0.00594 ** 
## ADVERBIAL ILOC    		-1.0353     0.3396  -3.049  0.00230 ** 
## POSITION  2                       1.1916     0.1738   6.856 7.08e-12 ***
## ---

## Threshold coefficients:
##     Estimate Std. Error z value
## 1|2  -4.5321     0.3557 -12.740
## 2|3  -2.0566     0.3301  -6.231
## 3|4  -1.3708     0.3278  -4.182
## 4|5   1.7521     0.3286   5.333


## Random effects:
##  Groups   Name                                		Variance Std.Dev. Corr                               
##  subjects ADVERBIAL INSTR                 	2.3987   1.5488                                      
##           ADVERBIAL COM(O)                	2.3873   1.5451    0.748                             
##           ADVERBIAL ILOC                  		2.1802   1.4766    0.898  0.561                      
##           POSITION 2                      		0.8843   0.9404   -0.078 -0.109 -0.088               
##           ADVERBIAL COM(O):POSITION 2 0.7158   0.8460    0.240 -0.334  0.487 -0.178        
##           ADVERBIAL ILOC:POSITION 2   	0.6667   0.8165   -0.430  0.083 -0.595 -0.386 -0.790 
##  items    POSITION 1                      		0.5416   0.7359                                      
##              POSITION 2                      		0.6100   0.7810   0.781                              
## Number of groups:  subjects 51,  items 36 



???????????????????

Prof. Dr. Tibor Kiss
Linguistic Data Science Lab
Ruhr-Universit?t Bochum


From mrm|500 @end|ng |rom york@@c@uk  Tue Dec 21 09:48:19 2021
From: mrm|500 @end|ng |rom york@@c@uk (Mike Lawson)
Date: Tue, 21 Dec 2021 08:48:19 +0000
Subject: [R-sig-ME] 
 Modelling with uncertain (but not missing) categorical
 random effect values
In-Reply-To: <79b321be-8d3c-6224-485f-0653ff3e9645@gmail.com>
References: <CACtWw1HWv6ph0vwt4TLpUxiojZ_3993Kop0bvfXe=3yt2Lu9JA@mail.gmail.com>
 <CAJuCY5xD_4QNNhbKMOjsJ2uQETWyHzaBznkUxg65_+QV-5Vw9A@mail.gmail.com>
 <47d07adf-6db0-e441-6e86-29d896c12ad1@phillipalday.com>
 <b15a5261-9d37-9283-0f61-3c776cb1f929@gmail.com>
 <CACtWw1Hza-aaBy3hq8RrqqwwXdt5zWC31U2mejeF0-0HPSTg+g@mail.gmail.com>
 <79b321be-8d3c-6224-485f-0653ff3e9645@gmail.com>
Message-ID: <CACtWw1E4ue6r8G4vHoCxVJY=y2gE=UvQaL2eBWVU8ja0tGGicA@mail.gmail.com>

Thanks for the quick response - that did the trick.

All the best,
Mike

On Mon, 20 Dec 2021 at 18:10, Ben Bolker <bbolker at gmail.com> wrote:
>
>     Something like:
>
>    lmod$reTrms$Ztlist <- list(Matrix(t(W)), Z2, Z3, Z4, ...)
>
> where the additional `Z` components are the random-effects models for
> the additional terms you want (you could for example pull these from an
> `lFormula()` call using a formula that included those components in the
> random effects), and
>
>    lmod$reTrms$Zt <- do.call(rbind, lmod$reTrms$Ztlist)
>
> (I think)
>
> On 12/20/21 12:43 PM, Mike Lawson wrote:
> > Thanks for the suggestions Philip and Ben,
> >
> > I'm coming back to this after a hiatus and this may be quite a basic question.
> >
> > I managed to get the lme4 hack working with my data, but not if I
> > include other random effects (that are not multi membership and not in
> > the matrix).
> > i.e. in the example you provide, if I add a new random predictor, how
> > do I incorporate this into the model? As this line directly changes
> > Ztlist and Zt to be the matrix:
> >
> > lmod$reTrms$Zt <- lmod$reTrms$Ztlist[[1]] <- Matrix(t(W))
> >
> > Many thanks,
> > Mike
> >
> >
> > On Tue, 3 Aug 2021 at 23:16, Ben Bolker <bbolker at gmail.com> wrote:
> >>
> >>     Also see
> >> https://bbolker.github.io/mixedmodels-misc/notes/multimember.html (i.e.
> >> you can do it in lme4, but it takes a bit of hacking)
> >>
> >> On 8/3/21 5:19 PM, Phillip Alday wrote:
> >>> If I'm not mistaken, Thierry's suggestion is a particular case of
> >>> multi-membership models, which you can also do in brms. See e.g.:
> >>>
> >>>
> >>> https://rdrr.io/cran/brms/man/mm.html
> >>>
> >>> https://github.com/paul-buerkner/brms/issues/130
> >>>
> >>> https://discourse.mc-stan.org/t/cross-classified-multiple-membership-models-with-brms/8691
> >>>
> >>>
> >>> On 13/07/2021 06:09, Thierry Onkelinx via R-sig-mixed-models wrote:
> >>>> Dear Michael,
> >>>>
> >>>> Maybe something like (0 + w_1 | dad_1) + (0 + w_2 | dad_2) + (0 + w_3 |
> >>>> dad_3). Where w_1 is the probability of dad_1.
> >>>>
> >>>> Make sure that dad_1, dad_2 and dad_3 are factors with the same levels.
> >>>> Then INLA allows you to add this as f(dad_1, w_1, model = "iid") + f(dad_2,
> >>>> w_2, copy = "dad_"1) + f(dad_3, w_3, copy = "dad_1"). So you end up with a
> >>>> single random intercept for every dad (dad_2 and dad_3 share their
> >>>> estimates with dad_1).
> >>>>
> >>>> mum_id  mum_sp  dad_sp dad_id                    con    dad_1   w_1 dad_2
> >>>> w_ 2 dad_3 w_3
> >>>>
> >>>> Af1          A              A           Am1 / Am2             1      Am1
> >>>> 0.6   Am2 0.4  NA 0
> >>>> Af1          A              A           Am2                       1
> >>>> Am2    1     NA     0     NA 0
> >>>> Bf1          B             A           Am1 / Am2 / Am4   0      Am1    0.4
> >>>>    Am2 0.3   Am4 0.3
> >>>> Bf2          B              B          Bm1 / Bm3              1      Bm1
> >>>> 0.5   Bm2  0.5  NA 0
> >>>>
> >>>> Best regards,
> >>>>
> >>>> ir. Thierry Onkelinx
> >>>> Statisticus / Statistician
> >>>>
> >>>> Vlaamse Overheid / Government of Flanders
> >>>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
> >>>> FOREST
> >>>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> >>>> thierry.onkelinx at inbo.be
> >>>> Havenlaan 88 bus 73, 1000 Brussel
> >>>> www.inbo.be
> >>>>
> >>>> ///////////////////////////////////////////////////////////////////////////////////////////
> >>>> To call in the statistician after the experiment is done may be no more
> >>>> than asking him to perform a post-mortem examination: he may be able to say
> >>>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> >>>> The plural of anecdote is not data. ~ Roger Brinner
> >>>> The combination of some data and an aching desire for an answer does not
> >>>> ensure that a reasonable answer can be extracted from a given body of data.
> >>>> ~ John Tukey
> >>>> ///////////////////////////////////////////////////////////////////////////////////////////
> >>>>
> >>>> <https://www.inbo.be>
> >>>>
> >>>>
> >>>> Op di 13 jul. 2021 om 12:30 schreef Michael Lawson via R-sig-mixed-models <
> >>>> r-sig-mixed-models at r-project.org>:
> >>>>
> >>>>> I have a dataset where I have offspring paternity of females with
> >>>>> males of different species. However, many of the offspring have
> >>>>> ambiguous paternity - where I know the offspring must be from
> >>>>> particular fathers, but not from others. The data currently looks a
> >>>>> bit like this (but with many more rows per mum_id):
> >>>>>
> >>>>> mum_id  mum_sp  dad_sp dad_id                    con
> >>>>>
> >>>>> Af1          A              A           Am1 / Am2             1
> >>>>> Af1          A              A           Am2                       1
> >>>>> Bf1          B             A           Am1 / Am2 / Am4   0
> >>>>> Bf2          B              B          Bm1 / Bm3              1
> >>>>>
> >>>>> Which I have so far run as a binomial GLMM with con (conspecific mating) as
> >>>>> a binary response, mum_sp and dad_sp (species) as fixed factors and
> >>>>> mum_id as a random factor - and have just not included dad_id as
> >>>>> a random factor. The ambiguously assigned fathers in dad_id is also
> >>>>> non-random, i.e.
> >>>>> certain individuals are more likely to be ambiguously assigned than
> >>>>> others, so just leaving these cases as NA is problematic.
> >>>>>
> >>>>> For some of the ambiguous assignments, I can also extract
> >>>>> probabilities that a possible male is the father of the offspring,
> >>>>> e.g. for the first row, father Am1 is 60% likely to be the father and
> >>>>> Am2 40% likely.
> >>>>>
> >>>>> Are there any approaches where I can include the ambiguous dad_id in
> >>>>> a GLMM framework? - where the uncertainty of the assignment contributes to
> >>>>> the
> >>>>> overall uncertainty in the tested relationship.
> >>>>>
> >>>>> Thank you for any suggestions,
> >>>>> Mike
> >>>>>
> >>>>> _______________________________________________
> >>>>> R-sig-mixed-models at r-project.org mailing list
> >>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>>>>
> >>>>       [[alternative HTML version deleted]]
> >>>>
> >>>> _______________________________________________
> >>>> R-sig-mixed-models at r-project.org mailing list
> >>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>>
> >>> _______________________________________________
> >>> R-sig-mixed-models at r-project.org mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>>
> >>
> >> --
> >> Dr. Benjamin Bolker
> >> Professor, Mathematics & Statistics and Biology, McMaster University
> >> Director, School of Computational Science and Engineering
> >> Graduate chair, Mathematics & Statistics
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> --
> Dr. Benjamin Bolker
> Professor, Mathematics & Statistics and Biology, McMaster University
> Director, School of Computational Science and Engineering
> Graduate chair, Mathematics & Statistics


From k@m@|@@tmeh @end|ng |rom hotm@||@com  Mon Dec 27 19:46:06 2021
From: k@m@|@@tmeh @end|ng |rom hotm@||@com (Kamal Atmeh)
Date: Mon, 27 Dec 2021 19:46:06 +0100
Subject: [R-sig-ME] Error using MCMCglmm
Message-ID: <DBBP189MB13407A0E9B4A6683992D3B01FE429@DBBP189MB1340.EURP189.PROD.OUTLOOK.COM>

Dear list,

I am trying to run bayesian phylogenetic mixed models using MCMCglmm but 
I keep getting the following error:

 ?? " Error in MCMCglmm(ltau ~ x * x2 + lbmM + age + lmean_ndvi + :
 ? no slot of name "i" for this object of class "ddiMatrix" "

This is not the first time I use MCMCglmm and it usually works 
flawlessly. I thought that there may be a conflict with the "tidyverse" 
package since some functions of "Matrix" are masked, but I tried to run 
the model without loading the "tidyverse" package and still received the 
same error. I was not able to find answers online and am thus turning to 
this list for answers if you can help please.

I am running the following model:

 >>>? prior1 <-list (G = list(G1 = list(V = 1, nu = 0.02)
 ?????????????????? ?? ??? ? ,G2 = list(V = 1, nu = 0.02)
 ??????????????????? ??? ??? ,G3 = list(V = 1, nu = 0.02)
 ??????????????????? ??? ??? ,G4 = list(V = 1, nu = 0.02)),
 ??????????? ?? ??? ? R = list(V = 1, nu = 0.02)
 ???????????? ??? ??? )

 >>> mod_tau_mc <- MCMCglmm(ltau ~ x * x2+??? # x and x2 are categorical 
variables
 ???????????????????????? ??? ??? lbmM +????? # continuous variable
 ???????????????????????? ??? ??? age + ??? ??? # categorical
 ??????????????????????? ?? ??? ? lmean_ndvi + ??? ??? # continuous
 ???????????????????????? ??? ??? lrange_ndvi + ??? ??? # continuous
 ??????????????????????? ?? ??? ? lnb.loc + ??? ??? # continuous
 ??????????????????????? ?? ??? ? lduration ??? ??? # continuous
 ?????????????????????? , random = ~sp_phylo+species2+phylo_pop+phylo_pop_id
 ?????????????????????? , ginverse = list(sp_phylo = inv.phylo$Ainv) ??? 
 ??? # include a custom matrix for argument sp_phylo
 ?????????????????????? , family = "gaussian"
 ?????????????????????? , prior = prior1
 ?????????????????????? , data = dt
 ?????????????????????? , nitt = 22e+03 ??? ??? # number of iteration 
after burnin
 ?????????????????????? , burnin = 2000 ??? ??? # number of iteration 
before beginning sample
 ?????????????????????? , thin = 100?? ??? ? # nb of iteration between 
sample
 ?????????????????????? , pr = TRUE)?? ??? ? #save random posterior 
distribution

I would greatly appreciate your help and happy to provide further 
information if needed!

Thank you in advance!

Kamal


From j@h@d||e|d @end|ng |rom ed@@c@uk  Mon Dec 27 19:49:13 2021
From: j@h@d||e|d @end|ng |rom ed@@c@uk (Jarrod Hadfield)
Date: Mon, 27 Dec 2021 18:49:13 +0000
Subject: [R-sig-ME] Error using MCMCglmm
In-Reply-To: <DBBP189MB13407A0E9B4A6683992D3B01FE429@DBBP189MB1340.EURP189.PROD.OUTLOOK.COM>
References: <DBBP189MB13407A0E9B4A6683992D3B01FE429@DBBP189MB1340.EURP189.PROD.OUTLOOK.COM>
Message-ID: <532604ae-da23-5aa5-5321-841768a7da95@ed.ac.uk>

Hi,

Is your data frame a tibble? If so, make it a standard data frame and retry.

Cheers,

Jarrod

On 27/12/2021 18:46, Kamal Atmeh wrote:
> This email was sent to you by someone outside the University.
> You should only click on links or attachments if you are certain that
> the email is genuine and the content is safe.
>
> Dear list,
>
> I am trying to run bayesian phylogenetic mixed models using MCMCglmm but
> I keep getting the following error:
>
>    " Error in MCMCglmm(ltau ~ x * x2 + lbmM + age + lmean_ndvi + :
>   no slot of name "i" for this object of class "ddiMatrix" "
>
> This is not the first time I use MCMCglmm and it usually works
> flawlessly. I thought that there may be a conflict with the "tidyverse"
> package since some functions of "Matrix" are masked, but I tried to run
> the model without loading the "tidyverse" package and still received the
> same error. I was not able to find answers online and am thus turning to
> this list for answers if you can help please.
>
> I am running the following model:
>
> >>>? prior1 <-list (G = list(G1 = list(V = 1, nu = 0.02)
>                             ,G2 = list(V = 1, nu = 0.02)
>                             ,G3 = list(V = 1, nu = 0.02)
>                             ,G4 = list(V = 1, nu = 0.02)),
>                      R = list(V = 1, nu = 0.02)
>                      )
>
> >>> mod_tau_mc <- MCMCglmm(ltau ~ x * x2+    # x and x2 are categorical
> variables
>                                  lbmM +      # continuous variable
>                                  age +         # categorical
>                                  lmean_ndvi +         # continuous
>                                  lrange_ndvi +         # continuous
>                                  lnb.loc +         # continuous
>                                  lduration         # continuous
>                        , random =
> ~sp_phylo+species2+phylo_pop+phylo_pop_id
>                        , ginverse = list(sp_phylo = inv.phylo$Ainv)
>     # include a custom matrix for argument sp_phylo
>                        , family = "gaussian"
>                        , prior = prior1
>                        , data = dt
>                        , nitt = 22e+03         # number of iteration
> after burnin
>                        , burnin = 2000         # number of iteration
> before beginning sample
>                        , thin = 100         # nb of iteration between
> sample
>                        , pr = TRUE)         #save random posterior
> distribution
>
> I would greatly appreciate your help and happy to provide further
> information if needed!
>
> Thank you in advance!
>
> Kamal
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
The University of Edinburgh is a charitable body, registered in Scotland, with registration number SC005336. Is e buidheann carthannais a th? ann an Oilthigh Dh?n ?ideann, cl?raichte an Alba, ?ireamh cl?raidh SC005336.


From k@m@|@@tmeh @end|ng |rom hotm@||@com  Mon Dec 27 20:05:51 2021
From: k@m@|@@tmeh @end|ng |rom hotm@||@com (Kamal Atmeh)
Date: Mon, 27 Dec 2021 20:05:51 +0100
Subject: [R-sig-ME] Error using MCMCglmm
In-Reply-To: <532604ae-da23-5aa5-5321-841768a7da95@ed.ac.uk>
References: <DBBP189MB13407A0E9B4A6683992D3B01FE429@DBBP189MB1340.EURP189.PROD.OUTLOOK.COM>
 <532604ae-da23-5aa5-5321-841768a7da95@ed.ac.uk>
Message-ID: <DBBP189MB1340AC1087BE1FCC3836A69DFE429@DBBP189MB1340.EURP189.PROD.OUTLOOK.COM>

Hi Jarrod,

Thank you for your answer.

Yes I transformed the dataset to a classic dataframe but the error remained.

If it can help, please find below my sessionInfo(). I eventually loaded 
the tidyverse.

Cheers,

Kamal


R version 4.0.3 (2020-10-10)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 10 x64 (build 19043)

Matrix products: default

locale:
[1] LC_COLLATE=French_France.1252? LC_CTYPE=French_France.1252
[3] LC_MONETARY=French_France.1252 LC_NUMERIC=C
[5] LC_TIME=French_France.1252

attached base packages:
[1] stats???? graphics? grDevices utils???? datasets? methods base

other attached packages:
 ?[1] MCMCglmm_2.29???? ape_5.4-1???????? coda_0.19-4 performance_0.7.0
 ?[5] MuMIn_1.43.17???? visreg_2.7.0????? merTools_0.5.2 arm_1.11-2
 ?[9] MASS_7.3-53?????? glmmTMB_1.1.2.3?? lmerTest_3.1-3 lme4_1.1-27.1
[13] Matrix_1.4-0????? scales_1.1.1????? forcats_0.5.1 stringr_1.4.0
[17] dplyr_1.0.7?????? purrr_0.3.4?????? readr_1.4.0 tidyr_1.1.3
[21] tibble_3.0.4????? ggplot2_3.3.5???? tidyverse_1.3.1 plyr_1.8.6

loaded via a namespace (and not attached):
 ? [1] cubature_2.0.4.2??? TH.data_1.0-10????? minqa_1.2.4 colorspace_1.4-1
 ? [5] ellipsis_0.3.2????? estimability_1.3??? htmlTable_2.2.1 
corpcor_1.6.9
 ? [9] base64enc_0.1-3???? fs_1.5.0??????????? rstudioapi_0.13 fansi_0.4.1
 ?[13] mvtnorm_1.1-1?????? lubridate_1.7.10??? xml2_1.3.2 codetools_0.2-16
 ?[17] splines_4.0.3?????? knitr_1.33????????? Formula_1.2-4 jsonlite_1.7.2
 ?[21] nloptr_1.2.2.2????? packrat_0.6.0?????? broom_0.7.8 cluster_2.1.0
 ?[25] dbplyr_2.1.1??????? png_0.1-7?????????? broom.mixed_0.2.6 
shiny_1.5.0
 ?[29] compiler_4.0.3????? httr_1.4.2????????? emmeans_1.6.1 
backports_1.2.1
 ?[33] fastmap_1.1.0?????? assertthat_0.2.1??? cli_2.5.0 later_1.2.0
 ?[37] htmltools_0.5.1.1?? tools_4.0.3???????? gtable_0.3.0 glue_1.4.2
 ?[41] reshape2_1.4.4????? Rcpp_1.0.7????????? cellranger_1.1.0 vctrs_0.3.8
 ?[45] nlme_3.1-149??????? iterators_1.0.13??? insight_0.14.2 
tensorA_0.36.1
 ?[49] xfun_0.24?????????? rvest_1.0.0???????? mime_0.9 lifecycle_1.0.0
 ?[53] zoo_1.8-8?????????? promises_1.1.1????? hms_1.1.0 parallel_4.0.3
 ?[57] sandwich_3.0-0????? TMB_1.7.22????????? RColorBrewer_1.1-2 
gridExtra_2.3
 ?[61] rpart_4.1-15??????? latticeExtra_0.6-29 stringi_1.5.3 
bayestestR_0.10.0
 ?[65] foreach_1.5.1?????? blme_1.0-5????????? checkmate_2.0.0 boot_1.3-25
 ?[69] rlang_0.4.11??????? pkgconfig_2.0.3???? lattice_0.20-41 
htmlwidgets_1.5.3
 ?[73] tidyselect_1.1.0??? magrittr_2.0.1????? R6_2.4.1 generics_0.1.0
 ?[77] Hmisc_4.5-0???????? multcomp_1.4-14???? DBI_1.1.1 pillar_1.6.4
 ?[81] haven_2.4.1???????? foreign_0.8-80????? withr_2.3.0 survival_3.2-7
 ?[85] abind_1.4-5???????? nnet_7.3-14???????? modelr_0.1.8 crayon_1.4.1
 ?[89] utf8_1.1.4????????? jpeg_0.1-8.1??????? grid_4.0.3 readxl_1.3.1
 ?[93] data.table_1.14.0?? reprex_2.0.0??????? digest_0.6.27 xtable_1.8-4
 ?[97] httpuv_1.6.1??????? numDeriv_2016.8-1.1 stats4_4.0.3 munsell_0.5.0



Le 27/12/2021 ? 19:49, Jarrod Hadfield a ?crit?:
> Hi,
>
> Is your data frame a tibble? If so, make it a standard data frame and 
> retry.
>
> Cheers,
>
> Jarrod
>
> On 27/12/2021 18:46, Kamal Atmeh wrote:
>> This email was sent to you by someone outside the University.
>> You should only click on links or attachments if you are certain that
>> the email is genuine and the content is safe.
>>
>> Dear list,
>>
>> I am trying to run bayesian phylogenetic mixed models using MCMCglmm but
>> I keep getting the following error:
>>
>> ?? " Error in MCMCglmm(ltau ~ x * x2 + lbmM + age + lmean_ndvi + :
>> ? no slot of name "i" for this object of class "ddiMatrix" "
>>
>> This is not the first time I use MCMCglmm and it usually works
>> flawlessly. I thought that there may be a conflict with the "tidyverse"
>> package since some functions of "Matrix" are masked, but I tried to run
>> the model without loading the "tidyverse" package and still received the
>> same error. I was not able to find answers online and am thus turning to
>> this list for answers if you can help please.
>>
>> I am running the following model:
>>
>> >>>? prior1 <-list (G = list(G1 = list(V = 1, nu = 0.02)
>> ??????????????????????????? ,G2 = list(V = 1, nu = 0.02)
>> ??????????????????????????? ,G3 = list(V = 1, nu = 0.02)
>> ??????????????????????????? ,G4 = list(V = 1, nu = 0.02)),
>> ???????????????????? R = list(V = 1, nu = 0.02)
>> ???????????????????? )
>>
>> >>> mod_tau_mc <- MCMCglmm(ltau ~ x * x2+??? # x and x2 are categorical
>> variables
>> ???????????????????????????????? lbmM +????? # continuous variable
>> ???????????????????????????????? age +???????? # categorical
>> ???????????????????????????????? lmean_ndvi +???????? # continuous
>> ???????????????????????????????? lrange_ndvi +???????? # continuous
>> ???????????????????????????????? lnb.loc +???????? # continuous
>> ???????????????????????????????? lduration???????? # continuous
>> ?????????????????????? , random =
>> ~sp_phylo+species2+phylo_pop+phylo_pop_id
>> ?????????????????????? , ginverse = list(sp_phylo = inv.phylo$Ainv)
>> ??? # include a custom matrix for argument sp_phylo
>> ?????????????????????? , family = "gaussian"
>> ?????????????????????? , prior = prior1
>> ?????????????????????? , data = dt
>> ?????????????????????? , nitt = 22e+03???????? # number of iteration
>> after burnin
>> ?????????????????????? , burnin = 2000???????? # number of iteration
>> before beginning sample
>> ?????????????????????? , thin = 100???????? # nb of iteration between
>> sample
>> ?????????????????????? , pr = TRUE)???????? #save random posterior
>> distribution
>>
>> I would greatly appreciate your help and happy to provide further
>> information if needed!
>>
>> Thank you in advance!
>>
>> Kamal
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> The University of Edinburgh is a charitable body, registered in 
> Scotland, with registration number SC005336. Is e buidheann 
> carthannais a th? ann an Oilthigh Dh?n ?ideann, cl?raichte an Alba, 
> ?ireamh cl?raidh SC005336.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From w@||dm@w@@@10 @end|ng |rom gm@||@com  Mon Dec 27 20:13:09 2021
From: w@||dm@w@@@10 @end|ng |rom gm@||@com (Walid Crampton-Mawass)
Date: Mon, 27 Dec 2021 12:13:09 -0700
Subject: [R-sig-ME] Error using MCMCglmm
In-Reply-To: <DBBP189MB1340AC1087BE1FCC3836A69DFE429@DBBP189MB1340.EURP189.PROD.OUTLOOK.COM>
References: <DBBP189MB13407A0E9B4A6683992D3B01FE429@DBBP189MB1340.EURP189.PROD.OUTLOOK.COM>
 <532604ae-da23-5aa5-5321-841768a7da95@ed.ac.uk>
 <DBBP189MB1340AC1087BE1FCC3836A69DFE429@DBBP189MB1340.EURP189.PROD.OUTLOOK.COM>
Message-ID: <CAJtCY7VDyjY-ApmN24MfnN5f5W18x5Bp+RLzpChn8opSrKSh=w@mail.gmail.com>

Hey Kamal,

one possible solution is to run the same code in a new session where you
only call the MCMCglmm package and input your data and phylogenetic
pedigree as dataframes. That way you can figure out if there were any
conflicts in the attached packages in your session.

Cheers
-- 
Walid Crampton-Mawass

On Mon, Dec 27, 2021 at 12:06 PM Kamal Atmeh <kamal.atmeh at hotmail.com>
wrote:

> Hi Jarrod,
>
> Thank you for your answer.
>
> Yes I transformed the dataset to a classic dataframe but the error
> remained.
>
> If it can help, please find below my sessionInfo(). I eventually loaded
> the tidyverse.
>
> Cheers,
>
> Kamal
>
>
> R version 4.0.3 (2020-10-10)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows 10 x64 (build 19043)
>
> Matrix products: default
>
> locale:
> [1] LC_COLLATE=French_France.1252  LC_CTYPE=French_France.1252
> [3] LC_MONETARY=French_France.1252 LC_NUMERIC=C
> [5] LC_TIME=French_France.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods base
>
> other attached packages:
>   [1] MCMCglmm_2.29     ape_5.4-1         coda_0.19-4 performance_0.7.0
>   [5] MuMIn_1.43.17     visreg_2.7.0      merTools_0.5.2 arm_1.11-2
>   [9] MASS_7.3-53       glmmTMB_1.1.2.3   lmerTest_3.1-3 lme4_1.1-27.1
> [13] Matrix_1.4-0      scales_1.1.1      forcats_0.5.1 stringr_1.4.0
> [17] dplyr_1.0.7       purrr_0.3.4       readr_1.4.0 tidyr_1.1.3
> [21] tibble_3.0.4      ggplot2_3.3.5     tidyverse_1.3.1 plyr_1.8.6
>
> loaded via a namespace (and not attached):
>    [1] cubature_2.0.4.2    TH.data_1.0-10      minqa_1.2.4 colorspace_1.4-1
>    [5] ellipsis_0.3.2      estimability_1.3    htmlTable_2.2.1
> corpcor_1.6.9
>    [9] base64enc_0.1-3     fs_1.5.0            rstudioapi_0.13 fansi_0.4.1
>   [13] mvtnorm_1.1-1       lubridate_1.7.10    xml2_1.3.2 codetools_0.2-16
>   [17] splines_4.0.3       knitr_1.33          Formula_1.2-4 jsonlite_1.7.2
>   [21] nloptr_1.2.2.2      packrat_0.6.0       broom_0.7.8 cluster_2.1.0
>   [25] dbplyr_2.1.1        png_0.1-7           broom.mixed_0.2.6
> shiny_1.5.0
>   [29] compiler_4.0.3      httr_1.4.2          emmeans_1.6.1
> backports_1.2.1
>   [33] fastmap_1.1.0       assertthat_0.2.1    cli_2.5.0 later_1.2.0
>   [37] htmltools_0.5.1.1   tools_4.0.3         gtable_0.3.0 glue_1.4.2
>   [41] reshape2_1.4.4      Rcpp_1.0.7          cellranger_1.1.0 vctrs_0.3.8
>   [45] nlme_3.1-149        iterators_1.0.13    insight_0.14.2
> tensorA_0.36.1
>   [49] xfun_0.24           rvest_1.0.0         mime_0.9 lifecycle_1.0.0
>   [53] zoo_1.8-8           promises_1.1.1      hms_1.1.0 parallel_4.0.3
>   [57] sandwich_3.0-0      TMB_1.7.22          RColorBrewer_1.1-2
> gridExtra_2.3
>   [61] rpart_4.1-15        latticeExtra_0.6-29 stringi_1.5.3
> bayestestR_0.10.0
>   [65] foreach_1.5.1       blme_1.0-5          checkmate_2.0.0 boot_1.3-25
>   [69] rlang_0.4.11        pkgconfig_2.0.3     lattice_0.20-41
> htmlwidgets_1.5.3
>   [73] tidyselect_1.1.0    magrittr_2.0.1      R6_2.4.1 generics_0.1.0
>   [77] Hmisc_4.5-0         multcomp_1.4-14     DBI_1.1.1 pillar_1.6.4
>   [81] haven_2.4.1         foreign_0.8-80      withr_2.3.0 survival_3.2-7
>   [85] abind_1.4-5         nnet_7.3-14         modelr_0.1.8 crayon_1.4.1
>   [89] utf8_1.1.4          jpeg_0.1-8.1        grid_4.0.3 readxl_1.3.1
>   [93] data.table_1.14.0   reprex_2.0.0        digest_0.6.27 xtable_1.8-4
>   [97] httpuv_1.6.1        numDeriv_2016.8-1.1 stats4_4.0.3 munsell_0.5.0
>
>
>
> Le 27/12/2021 ? 19:49, Jarrod Hadfield a ?crit :
> > Hi,
> >
> > Is your data frame a tibble? If so, make it a standard data frame and
> > retry.
> >
> > Cheers,
> >
> > Jarrod
> >
> > On 27/12/2021 18:46, Kamal Atmeh wrote:
> >> This email was sent to you by someone outside the University.
> >> You should only click on links or attachments if you are certain that
> >> the email is genuine and the content is safe.
> >>
> >> Dear list,
> >>
> >> I am trying to run bayesian phylogenetic mixed models using MCMCglmm but
> >> I keep getting the following error:
> >>
> >>    " Error in MCMCglmm(ltau ~ x * x2 + lbmM + age + lmean_ndvi + :
> >>   no slot of name "i" for this object of class "ddiMatrix" "
> >>
> >> This is not the first time I use MCMCglmm and it usually works
> >> flawlessly. I thought that there may be a conflict with the "tidyverse"
> >> package since some functions of "Matrix" are masked, but I tried to run
> >> the model without loading the "tidyverse" package and still received the
> >> same error. I was not able to find answers online and am thus turning to
> >> this list for answers if you can help please.
> >>
> >> I am running the following model:
> >>
> >> >>>  prior1 <-list (G = list(G1 = list(V = 1, nu = 0.02)
> >>                             ,G2 = list(V = 1, nu = 0.02)
> >>                             ,G3 = list(V = 1, nu = 0.02)
> >>                             ,G4 = list(V = 1, nu = 0.02)),
> >>                      R = list(V = 1, nu = 0.02)
> >>                      )
> >>
> >> >>> mod_tau_mc <- MCMCglmm(ltau ~ x * x2+    # x and x2 are categorical
> >> variables
> >>                                  lbmM +      # continuous variable
> >>                                  age +         # categorical
> >>                                  lmean_ndvi +         # continuous
> >>                                  lrange_ndvi +         # continuous
> >>                                  lnb.loc +         # continuous
> >>                                  lduration         # continuous
> >>                        , random =
> >> ~sp_phylo+species2+phylo_pop+phylo_pop_id
> >>                        , ginverse = list(sp_phylo = inv.phylo$Ainv)
> >>     # include a custom matrix for argument sp_phylo
> >>                        , family = "gaussian"
> >>                        , prior = prior1
> >>                        , data = dt
> >>                        , nitt = 22e+03         # number of iteration
> >> after burnin
> >>                        , burnin = 2000         # number of iteration
> >> before beginning sample
> >>                        , thin = 100         # nb of iteration between
> >> sample
> >>                        , pr = TRUE)         #save random posterior
> >> distribution
> >>
> >> I would greatly appreciate your help and happy to provide further
> >> information if needed!
> >>
> >> Thank you in advance!
> >>
> >> Kamal
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > The University of Edinburgh is a charitable body, registered in
> > Scotland, with registration number SC005336. Is e buidheann
> > carthannais a th? ann an Oilthigh Dh?n ?ideann, cl?raichte an Alba,
> > ?ireamh cl?raidh SC005336.
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Mon Dec 27 20:18:28 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Mon, 27 Dec 2021 14:18:28 -0500
Subject: [R-sig-ME] Error using MCMCglmm
In-Reply-To: <CAJtCY7VDyjY-ApmN24MfnN5f5W18x5Bp+RLzpChn8opSrKSh=w@mail.gmail.com>
References: <DBBP189MB13407A0E9B4A6683992D3B01FE429@DBBP189MB1340.EURP189.PROD.OUTLOOK.COM>
 <532604ae-da23-5aa5-5321-841768a7da95@ed.ac.uk>
 <DBBP189MB1340AC1087BE1FCC3836A69DFE429@DBBP189MB1340.EURP189.PROD.OUTLOOK.COM>
 <CAJtCY7VDyjY-ApmN24MfnN5f5W18x5Bp+RLzpChn8opSrKSh=w@mail.gmail.com>
Message-ID: <78e0b0d7-e797-b62b-efbd-087e75c3af8d@gmail.com>

   Good point. If that doesn't work, though, we're going to hit the 
rapidly-diminishing-returns part of the remote-debugging cycle. Can you 
post a reproducible example (possibly with data posted elsewhere as the 
list doesn't support large messages or attachments, possibly 
fuzzed/anonymized if you're worried about data confidentiality)?

   Ben Bolker

On 12/27/21 2:13 PM, Walid Crampton-Mawass wrote:
> Hey Kamal,
> 
> one possible solution is to run the same code in a new session where you
> only call the MCMCglmm package and input your data and phylogenetic
> pedigree as dataframes. That way you can figure out if there were any
> conflicts in the attached packages in your session.
> 
> Cheers
>


From k@m@|@@tmeh @end|ng |rom hotm@||@com  Mon Dec 27 21:30:42 2021
From: k@m@|@@tmeh @end|ng |rom hotm@||@com (Kamal Atmeh)
Date: Mon, 27 Dec 2021 21:30:42 +0100
Subject: [R-sig-ME] Error using MCMCglmm
In-Reply-To: <52390f9d-2013-f550-f740-1f26605fa570@gmail.com>
References: <52390f9d-2013-f550-f740-1f26605fa570@gmail.com>
Message-ID: <DBBP189MB134071094D4D9E7257EA1404FE429@DBBP189MB1340.EURP189.PROD.OUTLOOK.COM>

Dear all,

I have shared the data with Ben and Jarrod and the code works for Ben 
(please see below his answer). I decided to go for the old 
uninstall-reinstall of the MCMCglmm package and the code works now. 
Thank you again all for your help and time with this problem.

Cheers,

Kamal


-------- Message transf?r? --------
Sujet?: 	Re: [R-sig-ME] Error using MCMCglmm
Date?: 	Mon, 27 Dec 2021 15:08:28 -0500
De?: 	Ben Bolker <bbolker at gmail.com>
Pour?: 	Kamal Atmeh <kamal.atmeh at hotmail.com>
Copie ??: 	Jarrod Hadfield <j.hadfield at ed.ac.uk>



Your data + code runs for me, although with a warning:

Warning message:
In MCMCglmm(y ~ x * x2 + x3 + x4 + x5 + x6 + x7 + x8, random = ~r + :
some fixed effects are not estimable and have been removed. Use 
singular.ok=TRUE to sample these effects, but use an informative prior!

The trace plots of the fixed effects look mediocre but not awful, 
presumably fixable by the old brute force run-it-much-longer strategy (I 
assume you kept the runs short here for troubleshooting efficiency ...)

mod_tau_mc <- readRDS("mod_tau_mc.rds")
library(coda)
library(lattice)
ss <- mod_tau_mc$Sol
ff <- as.mcmc(ss[,startsWith(colnames(ss), "x")])
library(coda)
library(lattice)
xyplot(ff)



Results attached.

Slightly redacted sessionInfo():

R Under development (unstable) (2021-12-11 r81355)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Pop!_OS 21.04

Matrix products: default
BLAS: /usr/local/lib/R/lib/libRblas.so
LAPACK: /usr/local/lib/R/lib/libRlapack.so

attached base packages:
[1] stats graphics grDevices utils datasets methods base

other attached packages:
[1] MCMCglmm_2.32 ape_5.6 coda_0.19-4 Matrix_1.4-0

loaded via a namespace (and not attached):
[1] cubature_2.0.4.2 compiler_4.2.0 tools_4.2.0 corpcor_1.6.10
[5] parallel_4.2.0 Rcpp_1.0.7 nlme_3.1-153 grid_4.2.0
[9] tensorA_0.36.2 lattice_0.20-45
 >

[I'm cc'ing Jarrod; it would actually be best to have as much of this 
discussion in public/on the list as possible, in case we discover 
something of general interest, and it's definitely best to keep both me 
and Jarrod in the loop so that we don't duplicate effort -- we're both 
pretty busy ...]

cheers
Ben Bolker


On 12/27/21 2:55 PM, Kamal Atmeh wrote:
> Hi Ben,
>
> Thank you for your answer. I shared the data with Jarrod and I will 
> share it with you too. Please find it attached in the email. I 
> anonymized the data since it is a collaboration with multiple labs and 
> it would be better for confidentiality.
>
> Please find below the code that I am running.
>
> Cheers,
>
> Kamal
>
> library(MCMCglmm)
>
> prior1<-list(G = list(G1 = list(V = 1, nu = 0.02)
> ??????????????????? ,G2 = list(V = 1, nu = 0.02)
> ??????????????????? ,G3 = list(V = 1, nu = 0.02)
> ??????????????????? ,G4 = list(V = 1, nu = 0.02)),
> ???????????? R = list(V = 1, nu = 0.02)
> ???????????? )
>
> mod_tau_mc <- MCMCglmm(y ~ x*x2 +
> ???????????????????????? x3+
> ???????????????????????? x4+
> ???????????????????????? x5+
> ???????????????????????? x6+
> ???????????????????????? x7 +
> ???????????????????????? x8
> ?????????????????????? , random = ~r+r2+r3+r4
> ?????????????????????? , family = "gaussian"
> ?????????????????????? , ginverse = list(r4 = phylo) # include a 
> custom matrix for argument phylo
> ?????????????????????? , prior = prior1
> ?????????????????????? , data = dataKamal
> ?????????????????????? , nitt = 22e+03 # number of iteration after burnin
> ?????????????????????? , burnin = 2000 # number of iteration before 
> beginning sample
> ?????????????????????? , thin = 100 # nb of iteration between sample
> ?????????????????????? , pr = TRUE) #save random posterior distribution
>
>
> Le 27/12/2021 ? 20:18, Ben Bolker a ?crit?:
>> ? Good point. If that doesn't work, though, we're going to hit the 
>> rapidly-diminishing-returns part of the remote-debugging cycle. Can 
>> you post a reproducible example (possibly with data posted elsewhere 
>> as the list doesn't support large messages or attachments, possibly 
>> fuzzed/anonymized if you're worried about data confidentiality)?
>>
>> ? Ben Bolker
>>
>> On 12/27/21 2:13 PM, Walid Crampton-Mawass wrote:
>>> Hey Kamal,
>>>
>>> one possible solution is to run the same code in a new session where you
>>> only call the MCMCglmm package and input your data and phylogenetic
>>> pedigree as dataframes. That way you can figure out if there were any
>>> conflicts in the attached packages in your session.
>>>
>>> Cheers
>>>
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Dr. Benjamin Bolker
Professor, Mathematics & Statistics and Biology, McMaster University
Director, School of Computational Science and Engineering
Graduate chair, Mathematics & Statistics

	[[alternative HTML version deleted]]


