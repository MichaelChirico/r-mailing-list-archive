From luysgarcia at gmail.com  Tue Jan  2 09:00:53 2018
From: luysgarcia at gmail.com (=?UTF-8?Q?Luis_Fernando_Garc=C3=ADa?=)
Date: Tue, 2 Jan 2018 05:00:53 -0300
Subject: [R-sig-ME] LMM power analysis
Message-ID: <CANxP2S4b3xD6dR-V5d7P3k_27MGvwYF3qKaZkYHhJJ4wS6HxOQ@mail.gmail.com>

Dear all,

Currently I am having some issues trying to make a power analysis for a
LMM. I have found several sources, but some of them with very different
approaches. I just wanted to know if you could suggest me a recent
references like textbook or package where it says how to make this
analysis.

Many thanks

	[[alternative HTML version deleted]]


From andrea.p.drager at rice.edu  Tue Jan  2 20:38:06 2018
From: andrea.p.drager at rice.edu (Drager, Andrea Pilar)
Date: Tue, 02 Jan 2018 13:38:06 -0600
Subject: [R-sig-ME] Continuous vs. categorical correlated group effects
Message-ID: <20180102133806.Horde.CX7pDtKat-xRgjpBSZO7rQ5@webmail.rice.edu>


Hi All,

I am having trouble running a Bayesian mixed model in MCMCglmm where I  
have individual-level data for my response variable, and species-level  
data as the random effect (such as "species"), plus any other  
species-level continuous variable, such as abundance, in the model.  
But if the the other species-level variable is categorical--whether  
because I make it a random effect or because it is in fact  
categorical--the model runs! Could someone please explain the stats  
behind this?


prior = list(R = list(V = 1, nu = 0, fix = 1),  G = list(G1=list(V =  
1,nu = 0.002)))

Won't run-->MCMCglmm(binary_individual_repsonse ~ species_abund_continuous,
                      random = ~ species_id_categorical, family =  
"categorical")

             Error : Mixed model equations singular: use a (stronger) prior


Runs-->MCMCglmm(binary_individual_response ~ 1,
                 random = ~ species_abund_categorical +  
species_id_categorical, family = "categorical")

Runs-->MCMCglmm(binary_individual_response  ~ species_id_categorical,
                 random = ~ species_abund_categorical, family= "categorical")


Thanks in advance!
Andrea Pilar Drager
PhD. student
Ecology and Evolutionary Biology, Rice University


From bbolker at gmail.com  Tue Jan  2 21:48:10 2018
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 2 Jan 2018 15:48:10 -0500
Subject: [R-sig-ME] Continuous vs. categorical correlated group effects
In-Reply-To: <20180102133806.Horde.CX7pDtKat-xRgjpBSZO7rQ5@webmail.rice.edu>
References: <20180102133806.Horde.CX7pDtKat-xRgjpBSZO7rQ5@webmail.rice.edu>
Message-ID: <1db59d58-6329-18eb-52af-8ac556481cd0@gmail.com>


  Can you show us the summary() of your data?
  Is it possible you have complete separation in your continuous predictor?

On 18-01-02 02:38 PM, Drager, Andrea Pilar wrote:
> 
> Hi All,
> 
> I am having trouble running a Bayesian mixed model in MCMCglmm where I
> have individual-level data for my response variable, and species-level
> data as the random effect (such as "species"), plus any other
> species-level continuous variable, such as abundance, in the model. But
> if the the other species-level variable is categorical--whether because
> I make it a random effect or because it is in fact categorical--the
> model runs! Could someone please explain the stats behind this?
> 
> 
> prior = list(R = list(V = 1, nu = 0, fix = 1),? G = list(G1=list(V =
> 1,nu = 0.002)))
> 
> Won't run-->MCMCglmm(binary_individual_repsonse ~ species_abund_continuous,
> ???????????????????? random = ~ species_id_categorical, family =
> "categorical")
> 
> ??????????? Error : Mixed model equations singular: use a (stronger) prior
> 
> 
> Runs-->MCMCglmm(binary_individual_response ~ 1,
> ??????????????? random = ~ species_abund_categorical +
> species_id_categorical, family = "categorical")
> 
> Runs-->MCMCglmm(binary_individual_response? ~ species_id_categorical,
> ??????????????? random = ~ species_abund_categorical, family=
> "categorical")
> 
> 
> Thanks in advance!
> Andrea Pilar Drager
> PhD. student
> Ecology and Evolutionary Biology, Rice University
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From andrea.p.drager at rice.edu  Tue Jan  2 23:21:12 2018
From: andrea.p.drager at rice.edu (Drager, Andrea Pilar)
Date: Tue, 02 Jan 2018 16:21:12 -0600
Subject: [R-sig-ME] Continuous vs. categorical correlated group effects
In-Reply-To: <1db59d58-6329-18eb-52af-8ac556481cd0@gmail.com>
References: <20180102133806.Horde.CX7pDtKat-xRgjpBSZO7rQ5@webmail.rice.edu>
 <1db59d58-6329-18eb-52af-8ac556481cd0@gmail.com>
Message-ID: <20180102162112.Horde.vSdPcP-67CKyWZSHd7ovMw6@webmail.rice.edu>


summary(flor_data)

  species_id         binary_individual_response

  Length:29609       Min.   :0.00000
  Class :character   1st Qu.:0.00000
  Mode  :character   Median :0.00000
                     Mean   :0.06018
                     3rd Qu.:0.00000
                     Max.   :1.00000

   species_abund
   Min.   :  11.23
   1st Qu.:1996.23
   Median :2548.23
   Mean   :3438.20
   3rd Qu.:5310.23
   Max.   :6116.23


The following is also the case:

Won't run-->glmer(binary_indivdual_response ~ species_abund  
+(1|species_id),family=binomial(link='logit')

Runs-->glm(binary_individual_response ~ species_abund + species_id,  
family=binomial(link='logit')


Quoting Ben Bolker <bbolker at gmail.com>:

> Can you show us the summary() of your data?
>   Is it possible you have complete separation in your continuous predictor?
>
> On 18-01-02 02:38 PM, Drager, Andrea Pilar wrote:
>>
>> Hi All,
>>
>> I am having trouble running a Bayesian mixed model in MCMCglmm where I
>> have individual-level data for my response variable, and species-level
>> data as the random effect (such as "species"), plus any other
>> species-level continuous variable, such as abundance, in the model. But
>> if the the other species-level variable is categorical--whether because
>> I make it a random effect or because it is in fact categorical--the
>> model runs! Could someone please explain the stats behind this?
>>
>>
>> prior = list(R = list(V = 1, nu = 0, fix = 1),? G = list(G1=list(V =
>> 1,nu = 0.002)))
>>
>> Won't run-->MCMCglmm(binary_individual_repsonse ~ species_abund_continuous,
>> ???????????????????? random = ~ species_id_categorical, family =
>> "categorical")
>>
>> ??????????? Error : Mixed model equations singular: use a (stronger) prior
>>
>>
>> Runs-->MCMCglmm(binary_individual_response ~ 1,
>> ??????????????? random = ~ species_abund_categorical +
>> species_id_categorical, family = "categorical")
>>
>> Runs-->MCMCglmm(binary_individual_response? ~ species_id_categorical,
>> ??????????????? random = ~ species_abund_categorical, family=
>> "categorical")
>>
>>
>> Thanks in advance!
>> Andrea Pilar Drager
>> PhD. student
>> Ecology and Evolutionary Biology, Rice University
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


Andrea Pilar Drager
PhD. student
Ecology and Evolutionary Biology, Rice University


From bbolker at gmail.com  Wed Jan  3 01:03:51 2018
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 2 Jan 2018 19:03:51 -0500
Subject: [R-sig-ME] Continuous vs. categorical correlated group effects
In-Reply-To: <20180102162112.Horde.vSdPcP-67CKyWZSHd7ovMw6@webmail.rice.edu>
References: <20180102133806.Horde.CX7pDtKat-xRgjpBSZO7rQ5@webmail.rice.edu>
 <1db59d58-6329-18eb-52af-8ac556481cd0@gmail.com>
 <20180102162112.Horde.vSdPcP-67CKyWZSHd7ovMw6@webmail.rice.edu>
Message-ID: <CABghstS_JaoFhvV_GkWj9dfm+2yb3sd2bo0NuKHfMRPFMX1wyQ@mail.gmail.com>

The first thing I would try is rescaling your abundance value.  The
second is to tell us *exactly* what error messages
you get when you run glmer.  Also, how many species do you have?

===
fake_data <- data.frame(
   species_id = rep(outer(LETTERS,LETTERS,paste,sep="/"),40),
   stringsAsFactors=FALSE)
nn <- nrow(fake_data)
set.seed(101)
fake_data$resp <- rbinom(nn,prob=0.06,size=1)
fake_data$abund <- rlnorm(nn,meanlog=log(2500),
                          sdlog=0.75)

library(lme4)
g1 <- glmer(resp ~ abund +(1|species_id),data=fake_data,
      family=binomial(link='logit'))

## produces a fit, but lots of warnings.

fake_data$sc_abund <- scale(fake_data$abund)

update(g1, . ~ . - abund + sc_abund)

## The glm works on the first 1000 rows, but is very slow for the
whole data set (I may have invented too many species)


On Tue, Jan 2, 2018 at 5:21 PM, Drager, Andrea Pilar
<andrea.p.drager at rice.edu> wrote:
>
> summary(flor_data)
>
>  species_id         binary_individual_response
>
>  Length:29609       Min.   :0.00000
>  Class :character   1st Qu.:0.00000
>  Mode  :character   Median :0.00000
>                     Mean   :0.06018
>                     3rd Qu.:0.00000
>                     Max.   :1.00000
>
>   species_abund
>   Min.   :  11.23
>   1st Qu.:1996.23
>   Median :2548.23
>   Mean   :3438.20
>   3rd Qu.:5310.23
>   Max.   :6116.23
>
>
> The following is also the case:
>
> Won't run-->glmer(binary_indivdual_response ~ species_abund
> +(1|species_id),family=binomial(link='logit')
>
> Runs-->glm(binary_individual_response ~ species_abund + species_id,
> family=binomial(link='logit')
>
>
>
> Quoting Ben Bolker <bbolker at gmail.com>:
>
>> Can you show us the summary() of your data?
>>   Is it possible you have complete separation in your continuous
>> predictor?
>>
>> On 18-01-02 02:38 PM, Drager, Andrea Pilar wrote:
>>>
>>>
>>> Hi All,
>>>
>>> I am having trouble running a Bayesian mixed model in MCMCglmm where I
>>> have individual-level data for my response variable, and species-level
>>> data as the random effect (such as "species"), plus any other
>>> species-level continuous variable, such as abundance, in the model. But
>>> if the the other species-level variable is categorical--whether because
>>> I make it a random effect or because it is in fact categorical--the
>>> model runs! Could someone please explain the stats behind this?
>>>
>>>
>>> prior = list(R = list(V = 1, nu = 0, fix = 1),  G = list(G1=list(V =
>>> 1,nu = 0.002)))
>>>
>>> Won't run-->MCMCglmm(binary_individual_repsonse ~
>>> species_abund_continuous,
>>>                      random = ~ species_id_categorical, family =
>>> "categorical")
>>>
>>>             Error : Mixed model equations singular: use a (stronger)
>>> prior
>>>
>>>
>>> Runs-->MCMCglmm(binary_individual_response ~ 1,
>>>                 random = ~ species_abund_categorical +
>>> species_id_categorical, family = "categorical")
>>>
>>> Runs-->MCMCglmm(binary_individual_response  ~ species_id_categorical,
>>>                 random = ~ species_abund_categorical, family=
>>> "categorical")
>>>
>>>
>>> Thanks in advance!
>>> Andrea Pilar Drager
>>> PhD. student
>>> Ecology and Evolutionary Biology, Rice University
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>
> Andrea Pilar Drager
> PhD. student
> Ecology and Evolutionary Biology, Rice University
>


From paul.johnson at glasgow.ac.uk  Wed Jan  3 01:12:05 2018
From: paul.johnson at glasgow.ac.uk (Paul Johnson)
Date: Wed, 3 Jan 2018 00:12:05 +0000
Subject: [R-sig-ME] LMM power analysis
In-Reply-To: <CANxP2S4b3xD6dR-V5d7P3k_27MGvwYF3qKaZkYHhJJ4wS6HxOQ@mail.gmail.com>
References: <CANxP2S4b3xD6dR-V5d7P3k_27MGvwYF3qKaZkYHhJJ4wS6HxOQ@mail.gmail.com>
Message-ID: <A30447FA-9385-4998-B0CB-13594B19F155@glasgow.ac.uk>

Hi Luis,

The simr package:
http://onlinelibrary.wiley.com/doi/10.1111/2041-210X.12504/abstract

Simulation-based power analysis for mixed models in lme4:
http://rpubs.com/bbolker/11703

A tutorial on power analysis using simulation (supplementary file):
http://onlinelibrary.wiley.com/doi/10.1111/2041-210X.12306/abstract

Best wishes,
Paul



> On 2 Jan 2018, at 08:00, Luis Fernando Garc?a <luysgarcia at gmail.com> wrote:
> 
> Dear all,
> 
> Currently I am having some issues trying to make a power analysis for a
> LMM. I have found several sources, but some of them with very different
> approaches. I just wanted to know if you could suggest me a recent
> references like textbook or package where it says how to make this
> analysis.
> 
> Many thanks
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From manfrin at igb-berlin.de  Wed Jan  3 16:57:16 2018
From: manfrin at igb-berlin.de (=?utf-8?Q?Alessandro_Manfrin?=)
Date: Wed, 3 Jan 2018 16:57:16 +0100
Subject: [R-sig-ME] Unevely-spaced time dependency in a multiple-river
	dataset
Message-ID: <kcim.5a4cfd5c.2523.0e680ee54092f1f7@ucsmail01.ad.igb-berlin.de>

Dear all,


   I am writing you because you might be able to answer to some questions that I am trying to answer myself since few months (unfortunately without great success). 

Briefly: 


-I am working with a large dataset of more then 300 Restoration Projects in 80 rivers in 4 countries Germany, France, Finland and Switzerland. 
-Fish where collected in each site in a restored (i.e. removal of dams, restoration of the river bed, and so on) and in unrestored condition (i.e. no changes) 
->The main aim of the study is to analyse changes in the fish diversity index ratio (as delta (Unrestored-Restored)/Unrestored) over several years (that I grouped in categories to deal with data linearity (a=0-2 years after restoration; b =3-5 years after; c= and so on up to 20 years)

However, I believe I have to correct for the fact that I have temporally dependent data. Furthermore, in each river data were collected
not-uniformly: in some rivers fish were collected for 21 years every year, in other rivers data were collected only for 10 years and in others only 1 year (unevenly spaced time series?)
so I though to include a weights correction in the model inversely proportional to the observations.



I thougt to perform in R a mixed effect model as:

lmer (delta Fish diversity (as Impact-Control)/Control)~as.factor(Years from restoration)*Countries, random factor = Restoration Project, weights=1/observations)



I have few questions:



1-Is the weights option used correctly in the above model? (or should be weights=observations??, I read some differences between lme and lmer in the use of weights option)



2-From the analysis of the residuals it looks like there is a trend in my data (see plots) 






I do not know how to deal with it. Maybe CorrAR() option in lme? But how can I correct for that as I have different Restoration

Projects (random factor)? Do I have to run a single model for each project (as unique time series?). The main aim is to try to show a general pattern, therefore I would like to use all the project together.


Hoping in some good suggestions I thank you for your consideration.




Best wishes

Alessandro





?

From rshepard at appl-ecosys.com  Wed Jan  3 17:31:13 2018
From: rshepard at appl-ecosys.com (Rich Shepard)
Date: Wed, 3 Jan 2018 08:31:13 -0800 (PST)
Subject: [R-sig-ME] Unevely-spaced time dependency in a multiple-river
 dataset
In-Reply-To: <kcim.5a4cfd5c.2523.0e680ee54092f1f7@ucsmail01.ad.igb-berlin.de>
References: <kcim.5a4cfd5c.2523.0e680ee54092f1f7@ucsmail01.ad.igb-berlin.de>
Message-ID: <alpine.LNX.2.20.1801030819160.17319@salmo.appl-ecosys.com>

On Wed, 3 Jan 2018, Alessandro Manfrin wrote:

> ->The main aim of the study is to analyse changes in the fish diversity
> index ratio (as delta (Unrestored-Restored)/Unrestored) over several years
> (that I grouped in categories to deal with data linearity (a=0-2 years
> after restoration; b =3-5 years after; c= and so on up to 20 years)

Alessandro,

   With the vast amount of information available to you perhaps a Bayesian
approach would best fit your objectives. You might look at Pulkkinen, H.
2015. Embracing uncertainty in fisheries stock assessment using Bayesian
hierarchical models. Thesis at the University of Helsinki. It's available on
the Web.

   There are Bayesian time series models available, but if you want to stay
with glm there is the tscount package in CRAN: "tscount: An R Package for
Analysis of Count Time Series Following Generalized Linear Models" since
fish survey data often are in counts/proportions. Looks like your data are
in counts and not presence/absence.

HTH,

Rich


From andrea.p.drager at rice.edu  Thu Jan  4 02:07:41 2018
From: andrea.p.drager at rice.edu (Drager, Andrea Pilar)
Date: Wed, 03 Jan 2018 19:07:41 -0600
Subject: [R-sig-ME] Continuous vs. categorical correlated group effects
In-Reply-To: <CABghstS_JaoFhvV_GkWj9dfm+2yb3sd2bo0NuKHfMRPFMX1wyQ@mail.gmail.com>
References: <20180102133806.Horde.CX7pDtKat-xRgjpBSZO7rQ5@webmail.rice.edu>
 <1db59d58-6329-18eb-52af-8ac556481cd0@gmail.com>
 <20180102162112.Horde.vSdPcP-67CKyWZSHd7ovMw6@webmail.rice.edu>
 <CABghstS_JaoFhvV_GkWj9dfm+2yb3sd2bo0NuKHfMRPFMX1wyQ@mail.gmail.com>
Message-ID: <20180103190741.Horde.5u8raMjKGNjG31niXllDkA9@webmail.rice.edu>

Dear Ben,

Thank you very much! I have only 23 species, and yes, you are right  
that the glmer model did run before but with lots of warnings:
Warning messages:
1: Some predictor variables are on very different scales: consider rescaling
2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
   Model is nearly unidentifiable: very large eigenvalue
  - Rescale variables?;Model is nearly unidentifiable: large eigenvalue ratio
  - Rescale variables?

I log-transformed my abundance variable and now both the glmer and  
MCMCglmm models run fine, with no warnings.






Quoting Ben Bolker <bbolker at gmail.com>:

> The first thing I would try is rescaling your abundance value.  The
> second is to tell us *exactly* what error messages
> you get when you run glmer.  Also, how many species do you have?
>
> ===
> fake_data <- data.frame(
>    species_id = rep(outer(LETTERS,LETTERS,paste,sep="/"),40),
>    stringsAsFactors=FALSE)
> nn <- nrow(fake_data)
> set.seed(101)
> fake_data$resp <- rbinom(nn,prob=0.06,size=1)
> fake_data$abund <- rlnorm(nn,meanlog=log(2500),
>                           sdlog=0.75)
>
> library(lme4)
> g1 <- glmer(resp ~ abund +(1|species_id),data=fake_data,
>       family=binomial(link='logit'))
>
> ## produces a fit, but lots of warnings.
>
> fake_data$sc_abund <- scale(fake_data$abund)
>
> update(g1, . ~ . - abund + sc_abund)
>
> ## The glm works on the first 1000 rows, but is very slow for the
> whole data set (I may have invented too many species)
>
>
> On Tue, Jan 2, 2018 at 5:21 PM, Drager, Andrea Pilar
> <andrea.p.drager at rice.edu> wrote:
>>
>> summary(flor_data)
>>
>>  species_id         binary_individual_response
>>
>>  Length:29609       Min.   :0.00000
>>  Class :character   1st Qu.:0.00000
>>  Mode  :character   Median :0.00000
>>                     Mean   :0.06018
>>                     3rd Qu.:0.00000
>>                     Max.   :1.00000
>>
>>   species_abund
>>   Min.   :  11.23
>>   1st Qu.:1996.23
>>   Median :2548.23
>>   Mean   :3438.20
>>   3rd Qu.:5310.23
>>   Max.   :6116.23
>>
>>
>> The following is also the case:
>>
>> Won't run-->glmer(binary_indivdual_response ~ species_abund
>> +(1|species_id),family=binomial(link='logit')
>>
>> Runs-->glm(binary_individual_response ~ species_abund + species_id,
>> family=binomial(link='logit')
>>
>>
>>
>> Quoting Ben Bolker <bbolker at gmail.com>:
>>
>>> Can you show us the summary() of your data?
>>>   Is it possible you have complete separation in your continuous
>>> predictor?
>>>
>>> On 18-01-02 02:38 PM, Drager, Andrea Pilar wrote:
>>>>
>>>>
>>>> Hi All,
>>>>
>>>> I am having trouble running a Bayesian mixed model in MCMCglmm where I
>>>> have individual-level data for my response variable, and species-level
>>>> data as the random effect (such as "species"), plus any other
>>>> species-level continuous variable, such as abundance, in the model. But
>>>> if the the other species-level variable is categorical--whether because
>>>> I make it a random effect or because it is in fact categorical--the
>>>> model runs! Could someone please explain the stats behind this?
>>>>
>>>>
>>>> prior = list(R = list(V = 1, nu = 0, fix = 1),  G = list(G1=list(V =
>>>> 1,nu = 0.002)))
>>>>
>>>> Won't run-->MCMCglmm(binary_individual_repsonse ~
>>>> species_abund_continuous,
>>>>                      random = ~ species_id_categorical, family =
>>>> "categorical")
>>>>
>>>>             Error : Mixed model equations singular: use a (stronger)
>>>> prior
>>>>
>>>>
>>>> Runs-->MCMCglmm(binary_individual_response ~ 1,
>>>>                 random = ~ species_abund_categorical +
>>>> species_id_categorical, family = "categorical")
>>>>
>>>> Runs-->MCMCglmm(binary_individual_response  ~ species_id_categorical,
>>>>                 random = ~ species_abund_categorical, family=
>>>> "categorical")
>>>>
>>>>
>>>> Thanks in advance!
>>>> Andrea Pilar Drager
>>>> PhD. student
>>>> Ecology and Evolutionary Biology, Rice University
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>>
>> Andrea Pilar Drager
>> PhD. student
>> Ecology and Evolutionary Biology, Rice University
>>


Andrea Pilar Drager
PhD. student
Ecology and Evolutionary Biology, Rice University


From bbolker at gmail.com  Thu Jan  4 02:12:27 2018
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 3 Jan 2018 20:12:27 -0500
Subject: [R-sig-ME] Continuous vs. categorical correlated group effects
In-Reply-To: <20180103190741.Horde.5u8raMjKGNjG31niXllDkA9@webmail.rice.edu>
References: <20180102133806.Horde.CX7pDtKat-xRgjpBSZO7rQ5@webmail.rice.edu>
 <1db59d58-6329-18eb-52af-8ac556481cd0@gmail.com>
 <20180102162112.Horde.vSdPcP-67CKyWZSHd7ovMw6@webmail.rice.edu>
 <CABghstS_JaoFhvV_GkWj9dfm+2yb3sd2bo0NuKHfMRPFMX1wyQ@mail.gmail.com>
 <20180103190741.Horde.5u8raMjKGNjG31niXllDkA9@webmail.rice.edu>
Message-ID: <73f12135-e96a-1be7-1400-a8a44f6357f2@gmail.com>


  That's fine.

  Note that linearly scaling your predictor variable (e.g. subtracting
the mean and scaling by the standard deviation, which is what scale()
does) changes only the parameterization and not the underlying
definition of the model (e.g. the likelihood and any inferences drawn
the model will be the same).  In contrast, log-transforming the
predictor changes the meaning of the model -- it might be a more
sensible model, but it will be different from the original model.

  cheers
    Ben Bolker


On 18-01-03 08:07 PM, Drager, Andrea Pilar wrote:
> Dear Ben,
> 
> Thank you very much! I have only 23 species, and yes, you are right that
> the glmer model did run before but with lots of warnings:
> Warning messages:
> 1: Some predictor variables are on very different scales: consider
> rescaling
> 2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,? :
> ? Model is nearly unidentifiable: very large eigenvalue
> ?- Rescale variables?;Model is nearly unidentifiable: large eigenvalue
> ratio
> ?- Rescale variables?
> 
> I log-transformed my abundance variable and now both the glmer and
> MCMCglmm models run fine, with no warnings.
> 
> 
> 
> 
> 
> 
> Quoting Ben Bolker <bbolker at gmail.com>:
> 
>> The first thing I would try is rescaling your abundance value.? The
>> second is to tell us *exactly* what error messages
>> you get when you run glmer.? Also, how many species do you have?
>>
>> ===
>> fake_data <- data.frame(
>> ?? species_id = rep(outer(LETTERS,LETTERS,paste,sep="/"),40),
>> ?? stringsAsFactors=FALSE)
>> nn <- nrow(fake_data)
>> set.seed(101)
>> fake_data$resp <- rbinom(nn,prob=0.06,size=1)
>> fake_data$abund <- rlnorm(nn,meanlog=log(2500),
>> ????????????????????????? sdlog=0.75)
>>
>> library(lme4)
>> g1 <- glmer(resp ~ abund +(1|species_id),data=fake_data,
>> ????? family=binomial(link='logit'))
>>
>> ## produces a fit, but lots of warnings.
>>
>> fake_data$sc_abund <- scale(fake_data$abund)
>>
>> update(g1, . ~ . - abund + sc_abund)
>>
>> ## The glm works on the first 1000 rows, but is very slow for the
>> whole data set (I may have invented too many species)
>>
>>
>> On Tue, Jan 2, 2018 at 5:21 PM, Drager, Andrea Pilar
>> <andrea.p.drager at rice.edu> wrote:
>>>
>>> summary(flor_data)
>>>
>>> ?species_id???????? binary_individual_response
>>>
>>> ?Length:29609?????? Min.?? :0.00000
>>> ?Class :character?? 1st Qu.:0.00000
>>> ?Mode? :character?? Median :0.00000
>>> ??????????????????? Mean?? :0.06018
>>> ??????????????????? 3rd Qu.:0.00000
>>> ??????????????????? Max.?? :1.00000
>>>
>>> ? species_abund
>>> ? Min.?? :? 11.23
>>> ? 1st Qu.:1996.23
>>> ? Median :2548.23
>>> ? Mean?? :3438.20
>>> ? 3rd Qu.:5310.23
>>> ? Max.?? :6116.23
>>>
>>>
>>> The following is also the case:
>>>
>>> Won't run-->glmer(binary_indivdual_response ~ species_abund
>>> +(1|species_id),family=binomial(link='logit')
>>>
>>> Runs-->glm(binary_individual_response ~ species_abund + species_id,
>>> family=binomial(link='logit')
>>>
>>>
>>>
>>> Quoting Ben Bolker <bbolker at gmail.com>:
>>>
>>>> Can you show us the summary() of your data?
>>>> ? Is it possible you have complete separation in your continuous
>>>> predictor?
>>>>
>>>> On 18-01-02 02:38 PM, Drager, Andrea Pilar wrote:
>>>>>
>>>>>
>>>>> Hi All,
>>>>>
>>>>> I am having trouble running a Bayesian mixed model in MCMCglmm where I
>>>>> have individual-level data for my response variable, and species-level
>>>>> data as the random effect (such as "species"), plus any other
>>>>> species-level continuous variable, such as abundance, in the model.
>>>>> But
>>>>> if the the other species-level variable is categorical--whether
>>>>> because
>>>>> I make it a random effect or because it is in fact categorical--the
>>>>> model runs! Could someone please explain the stats behind this?
>>>>>
>>>>>
>>>>> prior = list(R = list(V = 1, nu = 0, fix = 1),? G = list(G1=list(V =
>>>>> 1,nu = 0.002)))
>>>>>
>>>>> Won't run-->MCMCglmm(binary_individual_repsonse ~
>>>>> species_abund_continuous,
>>>>> ???????????????????? random = ~ species_id_categorical, family =
>>>>> "categorical")
>>>>>
>>>>> ??????????? Error : Mixed model equations singular: use a (stronger)
>>>>> prior
>>>>>
>>>>>
>>>>> Runs-->MCMCglmm(binary_individual_response ~ 1,
>>>>> ??????????????? random = ~ species_abund_categorical +
>>>>> species_id_categorical, family = "categorical")
>>>>>
>>>>> Runs-->MCMCglmm(binary_individual_response? ~ species_id_categorical,
>>>>> ??????????????? random = ~ species_abund_categorical, family=
>>>>> "categorical")
>>>>>
>>>>>
>>>>> Thanks in advance!
>>>>> Andrea Pilar Drager
>>>>> PhD. student
>>>>> Ecology and Evolutionary Biology, Rice University
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>>
>>>
>>> Andrea Pilar Drager
>>> PhD. student
>>> Ecology and Evolutionary Biology, Rice University
>>>
> 
> 
> Andrea Pilar Drager
> PhD. student
> Ecology and Evolutionary Biology, Rice University
>


From bbolker at gmail.com  Fri Jan  5 15:31:19 2018
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 5 Jan 2018 09:31:19 -0500
Subject: [R-sig-ME] Fwd: Re: Plotting partial residuals from a glmmADMB model
In-Reply-To: <7801f9d6-5436-99f0-3ba3-b40a3ac4ea88@gmail.com>
References: <7801f9d6-5436-99f0-3ba3-b40a3ac4ea88@gmail.com>
Message-ID: <796f4c97-f3f3-3301-9e27-ee529d3efa9e@gmail.com>



Here are some examples of partial residual plots ... the only fanciness
available in the base-R machinery [e.g. for partial residuals for lm()
objects] that can't be implemented with the simple machinery here is
collapsing entire terms (due to e.g. factors with more than two levels,
orthogonal polynomials, splines ...) into a single effect

library(glmmADMB)
## ran without FoodTreatment, had trouble with convergence ...
owlfit <- glmmadmb(SiblingNegotiation~ArrivalTime+SexParent+
                       (1|Nest),family="nbinom1",data=Owls)

X <- model.matrix(~ArrivalTime+SexParent,data=Owls)

beta <- fixef(owlfit)

## <https://en.wikipedia.org/wiki/Partial_residual_plot> gives the
## definition of a partial residual as (residuals + \hat beta_i X_i)

## multiply each column of X by the corresponding beta
beta_X <- sweep(X,MARGIN=2,STATS=beta,FUN="*")

## add residuals (columnwise addition works automatically,
## although we could use sweep with MARGIN=1)
p_resid <- sweep(beta_X,MARGIN=1,STATS=residuals(owlfit),FUN="+")

par(mfrow=c(1,2))
for (i in 2:3) {
    plot(X[,i],p_resid[,i],xlab=colnames(X)[i],ylab="partial residuals")
}

(Would be better to plot partial residuals for the binary predictor
as a boxplot ...)

If you were doing this in glmmTMB you can take a couple of shortcuts:

library(glmmTMB)
owlfit2 <- glmmTMB(SiblingNegotiation~ArrivalTime+SexParent+FoodTreatment+
                       (1|Nest),family="nbinom1",data=Owls)

X <- getME(owlfit2,"X")
beta <- fixef(owlfit2)$cond
beta_X <- sweep(X,MARGIN=2,STATS=beta,FUN="*")
p_resid <- sweep(beta_X,MARGIN=1,STATS=residuals(owlfit2),FUN="+")
par(mfrow=c(1,3))
for (i in 2:4) {
    plot(X[,i],p_resid[,i],xlab=colnames(X)[i],ylab="partial residuals")
}



> -----Original Message----- From: Sivakoff, Frances Sent: Tuesday,
> December 19, 2017 3:42 PM To: 'Ben Bolker' <bbolker at gmail.com> Cc:
> r-sig-mixed-models at r-project.org Subject: RE: [R-sig-ME] Plotting
> partial residuals from a glmmADMB model
> 
> Dear Dr. Bolker, Thank you very much for your response. After trying
> to implement your suggestion, I'm unfortunately stuck. It appears
> that the getME function does not work with glmmADMB. I get the
> following error message:
> 
> Error in UseMethod("getME") : no applicable method for 'getME'
> applied to an object of class "glmmadmb"
> 
> A potential work around to this may be to use the "predict" function,
> which can generate the components, but I'm not sure if this is
> equivalent. Also, I'm having trouble following the steps that you
> outlined in your email to generate the partial residuals. Would you
> be willing to work through how to generate the partial residuals for
> the fixed effect "FoodTreatment" in the model below that uses the Owl
> data set?
> 
> ##Using the Owl Data om <-
> glmmadmb(SiblingNegotiation~FoodTreatment+ArrivalTime+SexParent+
> (1|Nest),family="nbinom1",data=Owls)
> 
> Thank you, Frances
> 
> -----Original Message----- From: Ben Bolker
> [mailto:bbolker at gmail.com] Sent: Thursday, December 14, 2017 9:54 PM 
> To: Sivakoff, Frances <sivakoff.3 at osu.edu> Cc:
> r-sig-mixed-models at r-project.org Subject: Re: [R-sig-ME] Plotting
> partial residuals from a glmmADMB model
> 
> You'll have to find a way to make "partial predictions". I don't
> think there's anything built in for this.  *Very* briefly,
> considering only fixed effects, if you retrieve the X matrix 
> (getME(fitted_model,"X")) and the fixed-effect parameters
> (fixef(fitted_model)), you can drop any columns/parameters you want
> and do exp(X %*% beta) with the remaining columns/parameters to get a
> prediction that includes some but not all of the predictors.
> Subtracting the observed value should get you the partial residuals
> ...
> 
> 
> On Tue, Dec 12, 2017 at 2:19 PM, Sivakoff, Frances
> <sivakoff.3 at osu.edu> wrote:
>> I would like to use ggplot2 to plot the partial residuals of an
>> indicator (0 or 1) independent variable in a generalized linear
>> mixed model fit with a "nbinom1" family using glmmadmb. My model
>> has a response variable that is a count, 3 explanatory variables
>> that are continuous, and 7 indicator variables that are 0 when a
>> particular heavy metal is not detected and 1 when it is detected
>> above a threshold value. I'd like to plot the partial residuals of
>> the various independent variables. I think that the model below
>> using the Owl data would be a good example data set for how to do
>> this. The model below has a response variable that is a count, an
>> explanatory variables that is continuous (arrivalTime), two
>> categorical variables (FoodTreatment and SexParent), a random
>> effect of Nest, and uses a "nbinom1" family.
>> 
>> ##Using the Owl Data om <-
>> glmmadmb(SiblingNegotiation~FoodTreatment+ArrivalTime+SexParent+ 
>> (1|Nest),family="nbinom1",data=Owls)
>> 
>> Could you please suggest a method for plotting the partial
>> residuals of the explanatory variables.
>> 
>> Thank you, Frances
>> 
>> 
>> [[alternative HTML version deleted]]
>> 
>> _______________________________________________ 
>> R-sig-mixed-models at r-project.org mailing list 
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From dcepulic at gmail.com  Mon Jan  8 10:21:06 2018
From: dcepulic at gmail.com (=?UTF-8?B?RG9taW5payDEhmVwdWxpxIc=?=)
Date: Mon, 8 Jan 2018 10:21:06 +0100
Subject: [R-sig-ME] Defining interaction in random effects in lme4
Message-ID: <CAGbn3HY-qeqF4k1ofeasGRV0p1r7ffiF3nG2g_vvrBXPcPvFPA@mail.gmail.com>

Dear everybody!

My fixed-effects-only model looks like this: glmer(Accuracy ~ C.RT*Group,
data = da)

C.RT is the reaction time variable, and Group is a categorical variable
with 0 and 1 as values. I would like to specify that main intercept, Group
intercept, C.RT slope and C.RT*Group slope vary across subjects and trials.

All subjects have values in Group = 0 and in Group = 1. Trials are nested
within Group because each trial belongs either to Group = 0 or Group = 1.
How should I specify the model?

My ideas were:

   1. glmer(Accuracy ~ C.RT*Group + (C.RT*Group|subject) + (1+C.RT|trial),
   data = da)

or
    2. glmer(Accuracy ~ C.RT*Group + (1+C.RT|Group:subject) +
(1+C.RT|Group:trial), data = da)

Here, Group:trial does not make much sense as trials are*per se* divided in
Group 0 or Group 1.

What is, in your opinion, the best way to specify the model that I want to
test?

Additionally, the difference between (1+C.RT|Group:subject)and
(C.RT*Object|subject) is not clear to me. Can someone also shed some light
here?

Thanks,
Dominik!

	[[alternative HTML version deleted]]


From manfrin at igb-berlin.de  Wed Jan 10 12:20:26 2018
From: manfrin at igb-berlin.de (=?utf-8?Q?Alessandro_Manfrin?=)
Date: Wed, 10 Jan 2018 12:20:26 +0100
Subject: [R-sig-ME] Fitting CorAR1 in lme with multiple time series
Message-ID: <kcim.5a55f6fa.177a.13c2c3b92f8144e8@ucsmail01.ad.igb-berlin.de>

Dear all,
  I have maybe for the "time series" experts a silly question: 
I have a dataset of European rivers =80
In 50% of the rivers I have more than 1 project; in the other 50% is 1 river = 1 project
In 50 % of the projects I have data collected only for 1 year; in the other 50% of the projects data were collected over years (from 2 untill 20 years, depending on the project)
I want to assess the Fish diversity depending on the altitude, latitude, catchment size.

After exploring data for the model assumption of normality, variance heterogeneity etc..I though to run this model: 
mod<-lme(Fish Diversity~log(altitude)+log(latitude)+log(catchment size), random~1|Rivers/Projects, method="ML", data=dati)

When I look at the residuals of model mod and at the acf (residuals(mod) and pacf(residuals(mod), they are pretty good but in acf there is autocorrelation in lag1 
and in pacf the line goes slightly over in lag 3. I think I would give it a try with CorAR1 (p=1) correction in lme:

My questions are:

1- Is the model developed in your opinion correct?

2- Can I fit a correlation CorrAR1 in the lme by just looking at the acf and pacf plots from the model mod? As u see I have different project over time
that means potentially multiple time series (for each project). Can I just fit a unique AR1 structure looking at the residuals of the model (without CorrAR1) 
(and not at the raw data) and assume that the same temporal trend is present in all the projects analysed? How can the acf and pacf know what is the temporal repetion (i.e.
how the acf and pacf biuld the lags in the plots)?

3- if the question number 2 is yes, do I have to organise in the dataframe chronologically 
in the dataset for each project? (e.g. Project1 from 2000 untill 2008; Project 2 from 1998 untill 2015, and so on?) 
as dati[order(dati$Project_names, dati$Year_evaluation), ] and give to the corrAR1 the form structure form = ~1|Rivers/Project_names

Would this model be ok?
modAR<-lme(Abu~log(altitude)+log(latitude)+log(catchment size), random~1|Rivers/Project_names, method="ML",
correlation=corARMA(form = ~1|Rivers/Project_names, p=1)

Thank you for your time

Alessandro


---------------------------------------------------------------------------------------
Dr. Alessandro Manfrin

University of Applied Sciences Trier, Umwelt Campus Birkenfeld/
University of Duisburg-Essen, Faculty of Biology

Working place:
Department of Aquatic Ecology
Room S05 T03 B02
Universit?tsstr. 5
45141 Essen (DE)
Tel.: +49 (0)201/183-3113
Fax: +49 (0)201/183-2179







?

	[[alternative HTML version deleted]]


From singmann at psychologie.uzh.ch  Wed Jan 10 15:09:29 2018
From: singmann at psychologie.uzh.ch (Henrik Singmann)
Date: Wed, 10 Jan 2018 15:09:29 +0100
Subject: [R-sig-ME] new afex version on CRAN: full emmeans support
Message-ID: <ea5b4b43-9767-a425-8b73-22d6d7eed430@psychologie.uzh.ch>

Dear all,

A few days ago I have released a new version of afex (0.19.1) to CRAN:
https://cran.r-project.org/package=afex

The main new feature is that afex now fully supports emmeans, the 
successor of the lsmeans package:
https://cran.r-project.org/package=emmeans

Furthermore, I removed the annoying warning that appeared when 
calculating an ANOVA with repeated-measures factors and had units of 
observations with missing data.

Cheers,
Henrik


-- 
Dr. Henrik Singmann
PostDoc
Universit?t Z?rich, Schweiz
http://singmann.org


From dcepulic at gmail.com  Sun Jan  7 23:00:43 2018
From: dcepulic at gmail.com (=?UTF-8?B?RG9taW5payDEhmVwdWxpxIc=?=)
Date: Sun, 7 Jan 2018 23:00:43 +0100
Subject: [R-sig-ME] Defining interaction in random effects in lme4
Message-ID: <CAGbn3HYZWtyTy6JO4YEtXkzNRm4iByHZCqXvi=Sf8Bo_XgukkQ@mail.gmail.com>

Dear everybody!

My fixed-effects-only model looks like this: glmer(Accuracy ~ C.RT*Group,
data = da)

C.RT is the reaction time variable, and Group is a categorical variable
with 0 and 1 as values. I would like to specify that main intercept, Group
intercept, C.RT slope and C.RT*Group slope vary across subjects and trials.

All subjects have values in Group = 0 and in Group = 1. Trials are nested
within Group because each trial belongs either to Group = 0 or Group = 1.
How should I specify the model?

My ideas were:

   1. glmer(Accuracy ~ C.RT*Group + (C.RT*Group|subject) + (1+C.RT|trial),
   data = da)

or
    2. glmer(Accuracy ~ C.RT*Group + (1+C.RT|Group:subject) +
(1+C.RT|Group:trial), data = da)

Here, Group:trial does not make much sense as trials are *per se* divided
in Group 0 or Group 1.

What is, in your opinion, the best way to specify the model that I want to
test?

Additionally, the difference between (1+C.RT|Group:subject) and
(C.RT*Object|subject) is not clear to me. Can someone also shed some light
here?

Thanks,
Dominik!

	[[alternative HTML version deleted]]


From ghiaco at gmail.com  Wed Jan 10 21:59:02 2018
From: ghiaco at gmail.com (Sima Usvyatsov)
Date: Wed, 10 Jan 2018 16:59:02 -0400
Subject: [R-sig-ME] spatial autocorrelation as random effect with count data
Message-ID: <CAFGTTqT8cDbDeKg2cikgdBkjAGz0spXakoEne7EmA28D3vVjgg@mail.gmail.com>

Hello,

I am working on a spatially autocorrelated dataset with a negative binomial
(count) response variable. I have been using the glmmPQL approach (MASS),
but I seem to have a hard time fitting the fixed effects. I came across the
mention that one could build the spatial autocorrelation into a random
effect (https://stat.ethz.ch/pipermail/r-sig-mixed-models/2011q1/015364.html).


I've done some searching but could not find a straightforward example of
this practice. I have 20 sampling locations (sampled repeatedly to a 4,000
point dataset) and I know that there is spatial autocorrelation between
them (by looking at autocorrelation plots of a naive model). The 20 grid
points are clustered into 4 strata, and I am interested in the strata
effects (so would like to keep the strata as fixed).

How would I go about expressing the spatial autocorrelation in this setup?
In the future I'd like to explore GAMs for this application, but for now
I'm stuck with a GLM approach... I would love to be able to use glmer()
with a random effect that expresses spatial autocorrelation.

Here's a fake dataset.

library(MASS)

df <- data.frame(Loc = as.factor(rep(1:20, each = 5)), Lat = rep(rnorm(20,
30, 0.1), each = 5), Lon = rep(rnorm(20, -75, 1), each = 5), x =
rnegbin(100, 1, 1), Stratum = rep(1:5, each = 20))

Thank you so much!

	[[alternative HTML version deleted]]


From paul.buerkner at gmail.com  Wed Jan 10 22:28:05 2018
From: paul.buerkner at gmail.com (Paul Buerkner)
Date: Wed, 10 Jan 2018 22:28:05 +0100
Subject: [R-sig-ME] spatial autocorrelation as random effect with count
	data
In-Reply-To: <CAFGTTqT8cDbDeKg2cikgdBkjAGz0spXakoEne7EmA28D3vVjgg@mail.gmail.com>
References: <CAFGTTqT8cDbDeKg2cikgdBkjAGz0spXakoEne7EmA28D3vVjgg@mail.gmail.com>
Message-ID: <CAGoSky-51s13X2stKfZV69YAzbL8dJZFXsKr+qDcNeZ8X=5A5A@mail.gmail.com>

It seems as if GAM(M)s are well suited for this situation, why would you
prefer to stay with the GLM approach?

2018-01-10 21:59 GMT+01:00 Sima Usvyatsov <ghiaco at gmail.com>:

> Hello,
>
> I am working on a spatially autocorrelated dataset with a negative binomial
> (count) response variable. I have been using the glmmPQL approach (MASS),
> but I seem to have a hard time fitting the fixed effects. I came across the
> mention that one could build the spatial autocorrelation into a random
> effect (https://stat.ethz.ch/pipermail/r-sig-mixed-models/
> 2011q1/015364.html).
>
>
> I've done some searching but could not find a straightforward example of
> this practice. I have 20 sampling locations (sampled repeatedly to a 4,000
> point dataset) and I know that there is spatial autocorrelation between
> them (by looking at autocorrelation plots of a naive model). The 20 grid
> points are clustered into 4 strata, and I am interested in the strata
> effects (so would like to keep the strata as fixed).
>
> How would I go about expressing the spatial autocorrelation in this setup?
> In the future I'd like to explore GAMs for this application, but for now
> I'm stuck with a GLM approach... I would love to be able to use glmer()
> with a random effect that expresses spatial autocorrelation.
>
> Here's a fake dataset.
>
> library(MASS)
>
> df <- data.frame(Loc = as.factor(rep(1:20, each = 5)), Lat = rep(rnorm(20,
> 30, 0.1), each = 5), Lon = rep(rnorm(20, -75, 1), each = 5), x =
> rnegbin(100, 1, 1), Stratum = rep(1:5, each = 20))
>
> Thank you so much!
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Wed Jan 10 22:34:27 2018
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 10 Jan 2018 16:34:27 -0500
Subject: [R-sig-ME] spatial autocorrelation as random effect with count
	data
In-Reply-To: <CAFGTTqT8cDbDeKg2cikgdBkjAGz0spXakoEne7EmA28D3vVjgg@mail.gmail.com>
References: <CAFGTTqT8cDbDeKg2cikgdBkjAGz0spXakoEne7EmA28D3vVjgg@mail.gmail.com>
Message-ID: <CABghstTbmhXQyWC69CtJFvvT=dSEUfrdGCu2GdshNUcd5OBOTg@mail.gmail.com>

PS: depending on how badly you wanted this, it would be possible to
what Doug Bates said (impose spatial dependence on the random effects
for the 20 spatial points) via the modular machinery of glmer, but it
would take some effort and knowledge ...


On Wed, Jan 10, 2018 at 3:59 PM, Sima Usvyatsov <ghiaco at gmail.com> wrote:
> Hello,
>
> I am working on a spatially autocorrelated dataset with a negative binomial
> (count) response variable. I have been using the glmmPQL approach (MASS),
> but I seem to have a hard time fitting the fixed effects. I came across the
> mention that one could build the spatial autocorrelation into a random
> effect (https://stat.ethz.ch/pipermail/r-sig-mixed-models/2011q1/015364.html).
>
>
> I've done some searching but could not find a straightforward example of
> this practice. I have 20 sampling locations (sampled repeatedly to a 4,000
> point dataset) and I know that there is spatial autocorrelation between
> them (by looking at autocorrelation plots of a naive model). The 20 grid
> points are clustered into 4 strata, and I am interested in the strata
> effects (so would like to keep the strata as fixed).
>
> How would I go about expressing the spatial autocorrelation in this setup?
> In the future I'd like to explore GAMs for this application, but for now
> I'm stuck with a GLM approach... I would love to be able to use glmer()
> with a random effect that expresses spatial autocorrelation.
>
> Here's a fake dataset.
>
> library(MASS)
>
> df <- data.frame(Loc = as.factor(rep(1:20, each = 5)), Lat = rep(rnorm(20,
> 30, 0.1), each = 5), Lon = rep(rnorm(20, -75, 1), each = 5), x =
> rnegbin(100, 1, 1), Stratum = rep(1:5, each = 20))
>
> Thank you so much!
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbolker at gmail.com  Wed Jan 10 22:30:57 2018
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 10 Jan 2018 16:30:57 -0500
Subject: [R-sig-ME] spatial autocorrelation as random effect with count
	data
In-Reply-To: <CAFGTTqT8cDbDeKg2cikgdBkjAGz0spXakoEne7EmA28D3vVjgg@mail.gmail.com>
References: <CAFGTTqT8cDbDeKg2cikgdBkjAGz0spXakoEne7EmA28D3vVjgg@mail.gmail.com>
Message-ID: <CABghstTC0Gwzs8z1KBtpf3WHWjYzbGMzHYjS=J45EfS+_ywdUw@mail.gmail.com>

  It will be hard to make this work with glmer at present.

 If you want to use geostatistical models (i.e., specifying spatial
autocorrelation function explicitly), as far as I know at present your
best options are

  INLA  (possibly via the inlabru package): looks like this implements
the Matern family (which includes exponential and Gaussian
autocorrelation functions as special cases)

  spaMM: spatial models etc. via h-likelihood

  would welcome more informed advice from other people on the list!


On Wed, Jan 10, 2018 at 3:59 PM, Sima Usvyatsov <ghiaco at gmail.com> wrote:
> Hello,
>
> I am working on a spatially autocorrelated dataset with a negative binomial
> (count) response variable. I have been using the glmmPQL approach (MASS),
> but I seem to have a hard time fitting the fixed effects. I came across the
> mention that one could build the spatial autocorrelation into a random
> effect (https://stat.ethz.ch/pipermail/r-sig-mixed-models/2011q1/015364.html).
>
>
> I've done some searching but could not find a straightforward example of
> this practice. I have 20 sampling locations (sampled repeatedly to a 4,000
> point dataset) and I know that there is spatial autocorrelation between
> them (by looking at autocorrelation plots of a naive model). The 20 grid
> points are clustered into 4 strata, and I am interested in the strata
> effects (so would like to keep the strata as fixed).
>
> How would I go about expressing the spatial autocorrelation in this setup?
> In the future I'd like to explore GAMs for this application, but for now
> I'm stuck with a GLM approach... I would love to be able to use glmer()
> with a random effect that expresses spatial autocorrelation.
>
> Here's a fake dataset.
>
> library(MASS)
>
> df <- data.frame(Loc = as.factor(rep(1:20, each = 5)), Lat = rep(rnorm(20,
> 30, 0.1), each = 5), Lon = rep(rnorm(20, -75, 1), each = 5), x =
> rnegbin(100, 1, 1), Stratum = rep(1:5, each = 20))
>
> Thank you so much!
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From highstat at highstat.com  Wed Jan 10 23:35:55 2018
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Wed, 10 Jan 2018 18:35:55 -0400
Subject: [R-sig-ME] spatial autocorrelation as random effect with,
	count data
In-Reply-To: <mailman.940.1515620073.1387.r-sig-mixed-models@r-project.org>
References: <mailman.940.1515620073.1387.r-sig-mixed-models@r-project.org>
Message-ID: <5a8ec454-3ac8-6fa9-6924-ab31cf98a19a@highstat.com>

Try R-INLA.....much easier.


Alain




------------------------------

Message: 4
Date: Wed, 10 Jan 2018 16:59:02 -0400
From: Sima Usvyatsov <ghiaco at gmail.com>
To: R-sig-mixed-models at r-project.org
Subject: [R-sig-ME] spatial autocorrelation as random effect with
	count data
Message-ID:
	<CAFGTTqT8cDbDeKg2cikgdBkjAGz0spXakoEne7EmA28D3vVjgg at mail.gmail.com>
Content-Type: text/plain; charset="UTF-8"

Hello,

I am working on a spatially autocorrelated dataset with a negative binomial
(count) response variable. I have been using the glmmPQL approach (MASS),
but I seem to have a hard time fitting the fixed effects. I came across the
mention that one could build the spatial autocorrelation into a random
effect (https://stat.ethz.ch/pipermail/r-sig-mixed-models/2011q1/015364.html).


I've done some searching but could not find a straightforward example of
this practice. I have 20 sampling locations (sampled repeatedly to a 4,000
point dataset) and I know that there is spatial autocorrelation between
them (by looking at autocorrelation plots of a naive model). The 20 grid
points are clustered into 4 strata, and I am interested in the strata
effects (so would like to keep the strata as fixed).

How would I go about expressing the spatial autocorrelation in this setup?
In the future I'd like to explore GAMs for this application, but for now
I'm stuck with a GLM approach... I would love to be able to use glmer()
with a random effect that expresses spatial autocorrelation.

Here's a fake dataset.

library(MASS)

df <- data.frame(Loc = as.factor(rep(1:20, each = 5)), Lat = rep(rnorm(20,
30, 0.1), each = 5), Lon = rep(rnorm(20, -75, 1), each = 5), x =
rnegbin(100, 1, 1), Stratum = rep(1:5, each = 20))

Thank you so much!

	[[alternative HTML version deleted]]



-- 

Dr. Alain F. Zuur
Highland Statistics Ltd.
9 St Clair Wynd
AB41 6DZ Newburgh, UK
Email: highstat at highstat.com
URL:   www.highstat.com

And:
NIOZ Royal Netherlands Institute for Sea Research,
Department of Coastal Systems, and Utrecht University,
P.O. Box 59, 1790 AB Den Burg,
Texel, The Netherlands



Author of:
1. Beginner's Guide to Spatial, Temporal and Spatial-Temporal Ecological Data Analysis with R-INLA. (2017).
2. Beginner's Guide to Zero-Inflated Models with R (2016).
3. Beginner's Guide to Data Exploration and Visualisation with R (2015).
4. Beginner's Guide to GAMM with R (2014).
5. Beginner's Guide to GLM and GLMM with R (2013).
6. Beginner's Guide to GAM with R (2012).
7. Zero Inflated Models and GLMM with R (2012).
8. A Beginner's Guide to R (2009).
9. Mixed effects models and extensions in ecology with R (2009).
10. Analysing Ecological Data (2007).


From rshepard at appl-ecosys.com  Wed Jan 10 23:42:18 2018
From: rshepard at appl-ecosys.com (Rich Shepard)
Date: Wed, 10 Jan 2018 14:42:18 -0800 (PST)
Subject: [R-sig-ME] spatial autocorrelation as random effect with,
 count data
In-Reply-To: <5a8ec454-3ac8-6fa9-6924-ab31cf98a19a@highstat.com>
References: <mailman.940.1515620073.1387.r-sig-mixed-models@r-project.org>
 <5a8ec454-3ac8-6fa9-6924-ab31cf98a19a@highstat.com>
Message-ID: <alpine.LNX.2.20.1801101440550.1470@salmo.appl-ecosys.com>

On Wed, 10 Jan 2018, Highland Statistics Ltd wrote:

> Try R-INLA.....much easier.

   +1

   I highly recommend Blangiardo & Cameletti's book, "Spatial and
Spatio-Temporal Bayesian Models with R-Inla."

Rich


From rshepard at appl-ecosys.com  Wed Jan 10 23:43:42 2018
From: rshepard at appl-ecosys.com (Rich Shepard)
Date: Wed, 10 Jan 2018 14:43:42 -0800 (PST)
Subject: [R-sig-ME] spatial autocorrelation as random effect with,
 count data
In-Reply-To: <alpine.LNX.2.20.1801101440550.1470@salmo.appl-ecosys.com>
References: <mailman.940.1515620073.1387.r-sig-mixed-models@r-project.org>
 <5a8ec454-3ac8-6fa9-6924-ab31cf98a19a@highstat.com>
 <alpine.LNX.2.20.1801101440550.1470@salmo.appl-ecosys.com>
Message-ID: <alpine.LNX.2.20.1801101443000.1470@salmo.appl-ecosys.com>

On Wed, 10 Jan 2018, Rich Shepard wrote:

>  +1
>
>  I highly recommend Blangiardo & Cameletti's book, "Spatial and
> Spatio-Temporal Bayesian Models with R-Inla."

   Forgot to mention that they cover hierarchical models which look
appropriate for the subject of this thread.

Rich


From ghiaco at gmail.com  Wed Jan 10 23:46:04 2018
From: ghiaco at gmail.com (Sima Usvyatsov)
Date: Wed, 10 Jan 2018 18:46:04 -0400
Subject: [R-sig-ME] spatial autocorrelation as random effect with count data
Message-ID: <CAFGTTqSo3rhKRKCJT+mjGXDHbRqo=4=66UR5Xt7rcm=JsJ2BUA@mail.gmail.com>

Thanks for your replies, everyone.

As for why I "choose" to stick with GLM - I have zero experience with GAM,
and it's a time-sensitive analysis, so there's just a time x experience
issue.

It sounds like maybe the glmer() way is not the way to go...

I'm also exploring the SpatialFilter approach to getting rid of nuisance
spatial autocorrelation, but am running into computational issues - it
_really_ doesn't like my dataset.

If anyone on here has any experience, input would be welcome. I have
already posted a SpatialFilter-specific question on the r-sig-geo mailing
list (https://stat.ethz.ch/pipermail/r-sig-geo/2018-January/026282.html),
although I managed to provide a toy dataset with a mistake in it.

Either way, thank you! At least I can stop digging in this direction.

	[[alternative HTML version deleted]]


From paul.buerkner at gmail.com  Thu Jan 11 00:22:01 2018
From: paul.buerkner at gmail.com (Paul Buerkner)
Date: Thu, 11 Jan 2018 00:22:01 +0100
Subject: [R-sig-ME] spatial autocorrelation as random effect with count
	data
In-Reply-To: <CAFGTTqSo3rhKRKCJT+mjGXDHbRqo=4=66UR5Xt7rcm=JsJ2BUA@mail.gmail.com>
References: <CAFGTTqSo3rhKRKCJT+mjGXDHbRqo=4=66UR5Xt7rcm=JsJ2BUA@mail.gmail.com>
Message-ID: <CAGoSky_Y+TZK-mP0YLNLNa6a7+23spsiSv1DACWfZoZGHSsZ7Q@mail.gmail.com>

Modelling spatial structures is always a bit more diffult that just calling
glmer() regardless of the way you go. Here is an example of how your may
fit your data using GAMMs in a Bayesian framework:

library(brms)
fit <- brm(x ~ Stratum + t2(Lat, Lon) + (1|Loc),
                data = df, family = negbinomial())
summary(fit)
marginal_effects(fit)
marginal_smooths(fit)


2018-01-10 23:46 GMT+01:00 Sima Usvyatsov <ghiaco at gmail.com>:

> Thanks for your replies, everyone.
>
> As for why I "choose" to stick with GLM - I have zero experience with GAM,
> and it's a time-sensitive analysis, so there's just a time x experience
> issue.
>
> It sounds like maybe the glmer() way is not the way to go...
>
> I'm also exploring the SpatialFilter approach to getting rid of nuisance
> spatial autocorrelation, but am running into computational issues - it
> _really_ doesn't like my dataset.
>
> If anyone on here has any experience, input would be welcome. I have
> already posted a SpatialFilter-specific question on the r-sig-geo mailing
> list (https://stat.ethz.ch/pipermail/r-sig-geo/2018-January/026282.html),
> although I managed to provide a toy dataset with a mistake in it.
>
> Either way, thank you! At least I can stop digging in this direction.
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From mr.lucedan at hotmail.it  Thu Jan 11 16:10:37 2018
From: mr.lucedan at hotmail.it (Luca Danieli)
Date: Thu, 11 Jan 2018 15:10:37 +0000
Subject: [R-sig-ME] Different results for between/within groups and within
 group regression analyses
Message-ID: <CWXP265MB021632613051497DCE3D4803F6160@CWXP265MB0216.GBRP265.PROD.OUTLOOK.COM>

Dear all,

from CrossValidates I was suggested to repost my question to you, as it is a technical question about R and mixed models.
Particularly, as I have a thesis to hand in in a few weeks, I hope you are able to help me understanding some problems that I cannot figure out by myself.

In this case, I have used the function lmer() to look for an interaction between groups and then used the function predict() to plot the fits for each group on a graphic.
Then I applied the lmer() to just one of those groups (same formula, technically) and used the predict() function to plot the fits for that specific group. I was thinking to obtain the same graphic for that group type and instead I obtained two different results.

I explained the process, models and presented the plots in this post:
https://stats.stackexchange.com/questions/322608/different-results-for-between-within-groups-and-within-group-regression-analyses

Can somebody help me understand this?

Best
Luca



	[[alternative HTML version deleted]]


From Phillip.Alday at mpi.nl  Thu Jan 11 16:18:46 2018
From: Phillip.Alday at mpi.nl (Alday, Phillip)
Date: Thu, 11 Jan 2018 15:18:46 +0000
Subject: [R-sig-ME] Different results for between/within groups and
 within group regression analyses
Message-ID: <c17c68e5-6c2b-441a-99e1-17f37344c040@mpi.nl>

By only using one group, you're changing the amount of pooling going on, which affects shrinkage and the bias-variance / over- vs. underfitting tradeoff. When you fit a model to a subset, it will generally be better at describing that subset but often worse at describing the full set / other sets. In other words, your subset model better describes the subset because it doesn't have to spend "resources" describing the other data, but of course this also means that it will tend to not describe the other data as well - it's better at the small details but worse at the big picture.

Best,
Phillip

Sent from my mobile, please excuse my brevity.

________________________________
From: Luca Danieli <mr.lucedan at hotmail.it>
Sent: Thursday, January 11, 2018 10:10 AM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] Different results for between/within groups and within group regression analyses


Dear all,

from CrossValidates I was suggested to repost my question to you, as it is a technical question about R and mixed models.
Particularly, as I have a thesis to hand in in a few weeks, I hope you are able to help me understanding some problems that I cannot figure out by myself.

In this case, I have used the function lmer() to look for an interaction between groups and then used the function predict() to plot the fits for each group on a graphic.
Then I applied the lmer() to just one of those groups (same formula, technically) and used the predict() function to plot the fits for that specific group. I was thinking to obtain the same graphic for that group type and instead I obtained two different results.

I explained the process, models and presented the plots in this post:
https://stats.stackexchange.com/questions/322608/different-results-for-between-within-groups-and-within-group-regression-analyses

Can somebody help me understand this?

Best
Luca



[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From mr.lucedan at hotmail.it  Thu Jan 11 16:26:04 2018
From: mr.lucedan at hotmail.it (Luca Danieli)
Date: Thu, 11 Jan 2018 15:26:04 +0000
Subject: [R-sig-ME] Different results for between/within groups and
 within group regression analyses
In-Reply-To: <c17c68e5-6c2b-441a-99e1-17f37344c040@mpi.nl>
References: <c17c68e5-6c2b-441a-99e1-17f37344c040@mpi.nl>
Message-ID: <CWXP265MB0216E5DD57A215B7FA17227AF6160@CWXP265MB0216.GBRP265.PROD.OUTLOOK.COM>

Thank you Phillip!

Can I add your answer to CrossValidated for future concerns by other users?

Best
Luca
________________________________
From: Alday, Phillip <Phillip.Alday at mpi.nl>
Sent: 11 January 2018 15:18
To: Luca Danieli; r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Different results for between/within groups and within group regression analyses

By only using one group, you're changing the amount of pooling going on, which affects shrinkage and the bias-variance / over- vs. underfitting tradeoff. When you fit a model to a subset, it will generally be better at describing that subset but often worse at describing the full set / other sets. In other words, your subset model better describes the subset because it doesn't have to spend "resources" describing the other data, but of course this also means that it will tend to not describe the other data as well - it's better at the small details but worse at the big picture.

Best,
Phillip

Sent from my mobile, please excuse my brevity.

________________________________
From: Luca Danieli <mr.lucedan at hotmail.it>
Sent: Thursday, January 11, 2018 10:10 AM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] Different results for between/within groups and within group regression analyses


Dear all,

from CrossValidates I was suggested to repost my question to you, as it is a technical question about R and mixed models.
Particularly, as I have a thesis to hand in in a few weeks, I hope you are able to help me understanding some problems that I cannot figure out by myself.

In this case, I have used the function lmer() to look for an interaction between groups and then used the function predict() to plot the fits for each group on a graphic.
Then I applied the lmer() to just one of those groups (same formula, technically) and used the predict() function to plot the fits for that specific group. I was thinking to obtain the same graphic for that group type and instead I obtained two different results.

I explained the process, models and presented the plots in this post:
https://stats.stackexchange.com/questions/322608/different-results-for-between-within-groups-and-within-group-regression-analyses

Can somebody help me understand this?

Best
Luca



[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From Phillip.Alday at mpi.nl  Thu Jan 11 16:38:33 2018
From: Phillip.Alday at mpi.nl (Alday, Phillip)
Date: Thu, 11 Jan 2018 15:38:33 +0000
Subject: [R-sig-ME] Different results for between/within groups and
 within group regression analyses
Message-ID: <da248a32-1d80-4cdd-9c96-7e80c199d086@mpi.nl>

I'll do it myself when I get the chance in the next day or so.  :-)

Phillip

________________________________
From: Luca Danieli <mr.lucedan at hotmail.it>
Sent: Thursday, January 11, 2018 10:26 AM
To: Alday, Phillip; r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Different results for between/within groups and within group regression analyses

Thank you Phillip!

Can I add your answer to CrossValidated for future concerns by other users?

Best
Luca
________________________________
From: Alday, Phillip <Phillip.Alday at mpi.nl>
Sent: 11 January 2018 15:18
To: Luca Danieli; r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Different results for between/within groups and within group regression analyses

By only using one group, you're changing the amount of pooling going on, which affects shrinkage and the bias-variance / over- vs. underfitting tradeoff. When you fit a model to a subset, it will generally be better at describing that subset but often worse at describing the full set / other sets. In other words, your subset model better describes the subset because it doesn't have to spend "resources" describing the other data, but of course this also means that it will tend to not describe the other data as well - it's better at the small details but worse at the big picture.

Best,
Phillip

Sent from my mobile, please excuse my brevity.

________________________________
From: Luca Danieli <mr.lucedan at hotmail.it>
Sent: Thursday, January 11, 2018 10:10 AM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] Different results for between/within groups and within group regression analyses


Dear all,

from CrossValidates I was suggested to repost my question to you, as it is a technical question about R and mixed models.
Particularly, as I have a thesis to hand in in a few weeks, I hope you are able to help me understanding some problems that I cannot figure out by myself.

In this case, I have used the function lmer() to look for an interaction between groups and then used the function predict() to plot the fits for each group on a graphic.
Then I applied the lmer() to just one of those groups (same formula, technically) and used the predict() function to plot the fits for that specific group. I was thinking to obtain the same graphic for that group type and instead I obtained two different results.

I explained the process, models and presented the plots in this post:
https://stats.stackexchange.com/questions/322608/different-results-for-between-within-groups-and-within-group-regression-analyses

Can somebody help me understand this?

Best
Luca



[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From ghiaco at gmail.com  Thu Jan 11 23:15:18 2018
From: ghiaco at gmail.com (Sima Usvyatsov)
Date: Thu, 11 Jan 2018 18:15:18 -0400
Subject: [R-sig-ME] spatial autocorrelation as random effect with count
	data
In-Reply-To: <CABghstTbmhXQyWC69CtJFvvT=dSEUfrdGCu2GdshNUcd5OBOTg@mail.gmail.com>
References: <CAFGTTqT8cDbDeKg2cikgdBkjAGz0spXakoEne7EmA28D3vVjgg@mail.gmail.com>
 <CABghstTbmhXQyWC69CtJFvvT=dSEUfrdGCu2GdshNUcd5OBOTg@mail.gmail.com>
Message-ID: <CAFGTTqQ+X-YZc7A21kE96aychzRbjyWCtO0YQOWDZc5P0XLqug@mail.gmail.com>

I was introduced today (by Roger Bivand) to the glmmTMB package that looks
very exciting. As a co-author, I was wondering why you didn't suggest it -
is there a reason it's a no-go in my situation? From a super quick read,
and a very naive thinking, is this not equivalent to the gpmmPQL setup
below?

mod1 <- glmmTMB(Count ~ Stratum + SiteInStratum + ...other predictors +
# random variable
(1 | RoundStart) +
# autocorrelation
exp(site.Easting + site.Northing | RoundStart),

family = nbinom2, # or nbinom1 - I guess decide based on residuals?
correlation = corExp(form=~site.Easting + site.Northing + RoundStart)

where RoundStart is the time of starting sampling along the repeated, set,
20-point sampling grid, easting and northing are the 20 points' coords,
Stratum is the allocation of the 20 sampling points to 5 strata and
SiteInStratum is  the 1:4 allocation within stratum.

This is my current setup:

mod1 <- glmmPQL(Count ~ Stratum + SiteInStratum + ...other predictors,
random = ~ 1 |RoundStart,
family = quasipoisson,
correlation = corExp(form=~site.Easting + site.Northing + RoundStart)

I have INLA and GAMs on my to-do list for this year - sounds like really
helpful ways to go about things, I just haven't gotten there yet...

Thank you so much!

On Wed, Jan 10, 2018 at 5:34 PM, Ben Bolker <bbolker at gmail.com> wrote:
>
> PS: depending on how badly you wanted this, it would be possible to
> what Doug Bates said (impose spatial dependence on the random effects
> for the 20 spatial points) via the modular machinery of glmer, but it
> would take some effort and knowledge ...
>
>
> On Wed, Jan 10, 2018 at 3:59 PM, Sima Usvyatsov <ghiaco at gmail.com> wrote:
> > Hello,
> >
> > I am working on a spatially autocorrelated dataset with a negative
binomial
> > (count) response variable. I have been using the glmmPQL approach
(MASS),
> > but I seem to have a hard time fitting the fixed effects. I came across
the
> > mention that one could build the spatial autocorrelation into a random
> > effect (
https://stat.ethz.ch/pipermail/r-sig-mixed-models/2011q1/015364.html).
> >
> >
> > I've done some searching but could not find a straightforward example of
> > this practice. I have 20 sampling locations (sampled repeatedly to a
4,000
> > point dataset) and I know that there is spatial autocorrelation between
> > them (by looking at autocorrelation plots of a naive model). The 20 grid
> > points are clustered into 4 strata, and I am interested in the strata
> > effects (so would like to keep the strata as fixed).
> >
> > How would I go about expressing the spatial autocorrelation in this
setup?
> > In the future I'd like to explore GAMs for this application, but for now
> > I'm stuck with a GLM approach... I would love to be able to use glmer()
> > with a random effect that expresses spatial autocorrelation.
> >
> > Here's a fake dataset.
> >
> > library(MASS)
> >
> > df <- data.frame(Loc = as.factor(rep(1:20, each = 5)), Lat =
rep(rnorm(20,
> > 30, 0.1), each = 5), Lon = rep(rnorm(20, -75, 1), each = 5), x =
> > rnegbin(100, 1, 1), Stratum = rep(1:5, each = 20))
> >
> > Thank you so much!
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Thu Jan 11 23:41:58 2018
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 11 Jan 2018 17:41:58 -0500
Subject: [R-sig-ME] spatial autocorrelation as random effect with count
 data
In-Reply-To: <CAFGTTqQ+X-YZc7A21kE96aychzRbjyWCtO0YQOWDZc5P0XLqug@mail.gmail.com>
References: <CAFGTTqT8cDbDeKg2cikgdBkjAGz0spXakoEne7EmA28D3vVjgg@mail.gmail.com>
 <CABghstTbmhXQyWC69CtJFvvT=dSEUfrdGCu2GdshNUcd5OBOTg@mail.gmail.com>
 <CAFGTTqQ+X-YZc7A21kE96aychzRbjyWCtO0YQOWDZc5P0XLqug@mail.gmail.com>
Message-ID: <d91ac16b-b155-bb80-d25f-ba0812d195ea@gmail.com>


  Because the spatial correlation machinery is extremely experimental
(and, to be honest, I didn't realize it was actually working already).
Kasper Kristensen added the spatial example to the "covstruct" vignette
a couple of months ago, and I just looked at it now - it seems
interesting.  Try it out: if it works (or doesn't work), I'd be happy to
hear about it. If you encounter problems (and please do check your
results **very** carefully), post an issue at
https://github.com/glmmtmb/glmmTMB/issues ...

  I think your "correlation=" specification below is
incorrect/redundant. Reading vignette("covstruct",package="glmmTMB") and
looking at the volcano example, I would try:

your_data$pos <- numFactor(d$site.Easting, d$site.Northing)

mod1 <- glmmTMB(Count ~ Stratum + SiteInStratum + ...other predictors +
> # random variable  ["nugget effect"]
> (1 | RoundStart) +
> # autocorrelation
> exp(0 + pos | RoundStart),
> data= your_data)

  cheers
   Ben Bolker

On 18-01-11 05:15 PM, Sima Usvyatsov wrote:
> I was introduced today (by Roger Bivand) to the glmmTMB package that
> looks very exciting. As a co-author, I was wondering why you didn't
> suggest it - is there a reason it's a no-go in my situation? From a
> super quick read, and a very naive thinking, is this not equivalent to
> the gpmmPQL setup below?
> 
> mod1 <- glmmTMB(Count ~ Stratum + SiteInStratum + ...other predictors +
> # random variable
> (1 | RoundStart) + ?
> # autocorrelation
> exp(site.Easting + site.Northing | RoundStart),
> 
> family = nbinom2, # or nbinom1 - I guess decide based on residuals?
> correlation = corExp(form=~site.Easting + site.Northing + RoundStart)
> 
> where RoundStart is the time of starting sampling along the repeated,
> set, 20-point sampling grid, easting and northing are the 20 points'
> coords, Stratum is the allocation of the 20 sampling points to 5 strata
> and SiteInStratum is ?the 1:4 allocation within stratum.
> 
> This is my current setup:
> 
> mod1 <- glmmPQL(Count ~ Stratum + SiteInStratum + ...other predictors,
> random = ~ 1 |RoundStart,
> family = quasipoisson,
> correlation = corExp(form=~site.Easting + site.Northing + RoundStart)
> 
> I have INLA and GAMs on my to-do list for this year - sounds like really
> helpful ways to go about things, I just haven't gotten there yet...
> 
> Thank you so much!
> 
> On Wed, Jan 10, 2018 at 5:34 PM, Ben Bolker <bbolker at gmail.com
> <mailto:bbolker at gmail.com>> wrote:
>>
>> PS: depending on how badly you wanted this, it would be possible to
>> what Doug Bates said (impose spatial dependence on the random effects
>> for the 20 spatial points) via the modular machinery of glmer, but it
>> would take some effort and knowledge ...
>>
>>
>> On Wed, Jan 10, 2018 at 3:59 PM, Sima Usvyatsov <ghiaco at gmail.com
> <mailto:ghiaco at gmail.com>> wrote:
>> > Hello,
>> >
>> > I am working on a spatially autocorrelated dataset with a negative
> binomial
>> > (count) response variable. I have been using the glmmPQL approach
> (MASS),
>> > but I seem to have a hard time fitting the fixed effects. I came
> across the
>> > mention that one could build the spatial autocorrelation into a random
>> > effect
> (https://stat.ethz.ch/pipermail/r-sig-mixed-models/2011q1/015364.html).
>> >
>> >
>> > I've done some searching but could not find a straightforward example of
>> > this practice. I have 20 sampling locations (sampled repeatedly to a
> 4,000
>> > point dataset) and I know that there is spatial autocorrelation between
>> > them (by looking at autocorrelation plots of a naive model). The 20 grid
>> > points are clustered into 4 strata, and I am interested in the strata
>> > effects (so would like to keep the strata as fixed).
>> >
>> > How would I go about expressing the spatial autocorrelation in this
> setup?
>> > In the future I'd like to explore GAMs for this application, but for now
>> > I'm stuck with a GLM approach... I would love to be able to use glmer()
>> > with a random effect that expresses spatial autocorrelation.
>> >
>> > Here's a fake dataset.
>> >
>> > library(MASS)
>> >
>> > df <- data.frame(Loc = as.factor(rep(1:20, each = 5)), Lat =
> rep(rnorm(20,
>> > 30, 0.1), each = 5), Lon = rep(rnorm(20, -75, 1), each = 5), x =
>> > rnegbin(100, 1, 1), Stratum = rep(1:5, each = 20))
>> >
>> > Thank you so much!
>> >
>> > ? ? ? ? [[alternative HTML version deleted]]
>> >
>> > _______________________________________________
>> > R-sig-mixed-models at r-project.org
> <mailto:R-sig-mixed-models at r-project.org> mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From paul.lantos at duke.edu  Fri Jan 12 22:15:03 2018
From: paul.lantos at duke.edu (Paul Lantos)
Date: Fri, 12 Jan 2018 21:15:03 +0000
Subject: [R-sig-ME] spatial autocorrelation as random effect with
	count	data
In-Reply-To: <CAFGTTqQ+X-YZc7A21kE96aychzRbjyWCtO0YQOWDZc5P0XLqug@mail.gmail.com>
References: <CAFGTTqT8cDbDeKg2cikgdBkjAGz0spXakoEne7EmA28D3vVjgg@mail.gmail.com>
 <CABghstTbmhXQyWC69CtJFvvT=dSEUfrdGCu2GdshNUcd5OBOTg@mail.gmail.com>
 <CAFGTTqQ+X-YZc7A21kE96aychzRbjyWCtO0YQOWDZc5P0XLqug@mail.gmail.com>
Message-ID: <CO2PR0501MB837682AC523ECA811CDF16C92170@CO2PR0501MB837.namprd05.prod.outlook.com>

Hi Sima,
 You might do this as a GAM using the mgcv package with a syntax something like this -

mod1 <- gam( Count ~ Stratum + SiteInStratum + s( site.Easting , site.Northing ) + s( Roundstart , bs="re" ) , family = Poisson , data=yourdata )

I haven't used quasipoisson models in mgcv so you'd need to look to see if that's an available family

The s( site.Easting , site.Northing ) term produces a 2-dimensional smooth of the coordinate pairs, in essence modeling how Count varies by location within 2-dimensional coordinate space.

The s( Roundstart , bs="re" ) term treats Roundstart as a random effect. You might do a model just using Roundstart as a linear predictor to see how it compares.

mgcv has some nice plotting options. My preference is to create a grid of the x/y or easting/northing coordinates and predict your model to that grid

You could also do a Bayesian version using the brms package. The syntax would be nearly identical except that the function call would be brm instead of gam.

Paul
_____________________________________________
Paul M. Lantos, MD, MS GIS, FIDSA, FAAP, FAAP            
Assistant Professor of Internal Medicine and Pediatrics
  Pediatric Infectious Diseases
  General Internal Medicine
Duke University School of Medicine
Duke Global Health Institute
_____________________________________________



-----Original Message-----
From: Sima Usvyatsov [mailto:ghiaco at gmail.com] 
Sent: Thursday, January 11, 2018 5:15 PM
To: Ben Bolker <bbolker at gmail.com>
Cc: R-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] spatial autocorrelation as random effect with count data

I was introduced today (by Roger Bivand) to the glmmTMB package that looks very exciting. As a co-author, I was wondering why you didn't suggest it - is there a reason it's a no-go in my situation? From a super quick read, and a very naive thinking, is this not equivalent to the gpmmPQL setup below?

mod1 <- glmmTMB(Count ~ Stratum + SiteInStratum + ...other predictors + # random variable
(1 | RoundStart) +
# autocorrelation
exp(site.Easting + site.Northing | RoundStart),

family = nbinom2, # or nbinom1 - I guess decide based on residuals?
correlation = corExp(form=~site.Easting + site.Northing + RoundStart)

where RoundStart is the time of starting sampling along the repeated, set, 20-point sampling grid, easting and northing are the 20 points' coords, Stratum is the allocation of the 20 sampling points to 5 strata and SiteInStratum is  the 1:4 allocation within stratum.

This is my current setup:

mod1 <- glmmPQL(Count ~ Stratum + SiteInStratum + ...other predictors, random = ~ 1 |RoundStart, family = quasipoisson, correlation = corExp(form=~site.Easting + site.Northing + RoundStart)

I have INLA and GAMs on my to-do list for this year - sounds like really helpful ways to go about things, I just haven't gotten there yet...

Thank you so much!

On Wed, Jan 10, 2018 at 5:34 PM, Ben Bolker <bbolker at gmail.com> wrote:
>
> PS: depending on how badly you wanted this, it would be possible to 
> what Doug Bates said (impose spatial dependence on the random effects 
> for the 20 spatial points) via the modular machinery of glmer, but it 
> would take some effort and knowledge ...
>
>
> On Wed, Jan 10, 2018 at 3:59 PM, Sima Usvyatsov <ghiaco at gmail.com> wrote:
> > Hello,
> >
> > I am working on a spatially autocorrelated dataset with a negative
binomial
> > (count) response variable. I have been using the glmmPQL approach
(MASS),
> > but I seem to have a hard time fitting the fixed effects. I came 
> > across
the
> > mention that one could build the spatial autocorrelation into a 
> > random effect (
https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_pipermail_r-2Dsig-2Dmixed-2Dmodels_2011q1_015364.html&d=DwICaQ&c=imBPVzF25OnBgGmVOlcsiEgHoG1i6YHLR0Sj_gZ4adc&r=pCiIbVPBNWU0azo0D48ChUH_fawb-FalNVOf1sUn1r4&m=ueQxw_NiRoOZc6904koetGkyojO7A7EYG2wnkc-_Q5o&s=inAqkRaPqS5USvZxt-SLYQqnz1nQJra1b8WGyXU9Gno&e= ).
> >
> >
> > I've done some searching but could not find a straightforward 
> > example of this practice. I have 20 sampling locations (sampled 
> > repeatedly to a
4,000
> > point dataset) and I know that there is spatial autocorrelation 
> > between them (by looking at autocorrelation plots of a naive model). 
> > The 20 grid points are clustered into 4 strata, and I am interested 
> > in the strata effects (so would like to keep the strata as fixed).
> >
> > How would I go about expressing the spatial autocorrelation in this
setup?
> > In the future I'd like to explore GAMs for this application, but for 
> > now I'm stuck with a GLM approach... I would love to be able to use 
> > glmer() with a random effect that expresses spatial autocorrelation.
> >
> > Here's a fake dataset.
> >
> > library(MASS)
> >
> > df <- data.frame(Loc = as.factor(rep(1:20, each = 5)), Lat =
rep(rnorm(20,
> > 30, 0.1), each = 5), Lon = rep(rnorm(20, -75, 1), each = 5), x = 
> > rnegbin(100, 1, 1), Stratum = rep(1:5, each = 20))
> >
> > Thank you so much!
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list 
> > https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_ma
> > ilman_listinfo_r-2Dsig-2Dmixed-2Dmodels&d=DwICaQ&c=imBPVzF25OnBgGmVO
> > lcsiEgHoG1i6YHLR0Sj_gZ4adc&r=pCiIbVPBNWU0azo0D48ChUH_fawb-FalNVOf1sU
> > n1r4&m=ueQxw_NiRoOZc6904koetGkyojO7A7EYG2wnkc-_Q5o&s=EtMa42Gf0VSujtL
> > vU32z0Ienku6iMHQS3hZrVoiuOaI&e=

	[[alternative HTML version deleted]]



From mr.lucedan at hotmail.it  Sat Jan 13 23:07:09 2018
From: mr.lucedan at hotmail.it (Luca Danieli)
Date: Sat, 13 Jan 2018 22:07:09 +0000
Subject: [R-sig-ME] Different results for between/within groups and
 within group regression analyses
In-Reply-To: <da248a32-1d80-4cdd-9c96-7e80c199d086@mpi.nl>
References: <da248a32-1d80-4cdd-9c96-7e80c199d086@mpi.nl>
Message-ID: <CWXP265MB02168DCE36AA7142EEE8840DF6140@CWXP265MB0216.GBRP265.PROD.OUTLOOK.COM>

Hi Phillip,

sorry if I ask you a question.
In this moment I have a 3x4x8 matrix, where '3' is the number of groups, '8' the number of tests, and '4' the levels of the potential main effect.

Following your explanation, I was before thinking that leaving interactions out of the models would give you a better approximation of the main effect. But now that I read it again, I am unsure about it.

In my case, the '4' levels are nested in each set.
If I write lmer(Score ~ pot_ME + random effects) I have no statistical significance.
If I write lmer(Score ~ pot_ME*groups + random effects) I have statistical significance for the main effect (p<0.05) and a strong interaction (p<.001).
If I write lmer(Score ~ pot_ME*groups*tests + random effects) I have no statistical significance nor interactions.

What approach is the more correct to get information about the presence of a main effect?

(My parameters are not-continuous)

Best
Luca
________________________________
From: Alday, Phillip <Phillip.Alday at mpi.nl>
Sent: 11 January 2018 15:38
To: Luca Danieli; r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Different results for between/within groups and within group regression analyses

I'll do it myself when I get the chance in the next day or so.  :-)

Phillip

________________________________
From: Luca Danieli <mr.lucedan at hotmail.it>
Sent: Thursday, January 11, 2018 10:26 AM
To: Alday, Phillip; r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Different results for between/within groups and within group regression analyses

Thank you Phillip!

Can I add your answer to CrossValidated for future concerns by other users?

Best
Luca
________________________________
From: Alday, Phillip <Phillip.Alday at mpi.nl>
Sent: 11 January 2018 15:18
To: Luca Danieli; r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Different results for between/within groups and within group regression analyses

By only using one group, you're changing the amount of pooling going on, which affects shrinkage and the bias-variance / over- vs. underfitting tradeoff. When you fit a model to a subset, it will generally be better at describing that subset but often worse at describing the full set / other sets. In other words, your subset model better describes the subset because it doesn't have to spend "resources" describing the other data, but of course this also means that it will tend to not describe the other data as well - it's better at the small details but worse at the big picture.

Best,
Phillip

Sent from my mobile, please excuse my brevity.

________________________________
From: Luca Danieli <mr.lucedan at hotmail.it>
Sent: Thursday, January 11, 2018 10:10 AM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] Different results for between/within groups and within group regression analyses


Dear all,

from CrossValidates I was suggested to repost my question to you, as it is a technical question about R and mixed models.
Particularly, as I have a thesis to hand in in a few weeks, I hope you are able to help me understanding some problems that I cannot figure out by myself.

In this case, I have used the function lmer() to look for an interaction between groups and then used the function predict() to plot the fits for each group on a graphic.
Then I applied the lmer() to just one of those groups (same formula, technically) and used the predict() function to plot the fits for that specific group. I was thinking to obtain the same graphic for that group type and instead I obtained two different results.

I explained the process, models and presented the plots in this post:
https://stats.stackexchange.com/questions/322608/different-results-for-between-within-groups-and-within-group-regression-analyses

Can somebody help me understand this?

Best
Luca



[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From simonakf at gmail.com  Tue Jan 16 13:22:47 2018
From: simonakf at gmail.com (Simona Kralj Fiser)
Date: Tue, 16 Jan 2018 13:22:47 +0100
Subject: [R-sig-ME] cross-sex genetic correlation
In-Reply-To: <e8420da6-93bb-5ea5-d6e7-8602b1e71fc9@ed.ac.uk>
References: <CAPkBqk=4cQ73W4JizDeYFZ2CMUndNFb3JPe_enSv630ohn-zNQ@mail.gmail.com>
 <e8420da6-93bb-5ea5-d6e7-8602b1e71fc9@ed.ac.uk>
Message-ID: <CAPkBqkkZW_iSiWpJLie_ej=XiBSmcEYhe7qNSrr_kUEMsbP3vQ@mail.gmail.com>

Hi!

I have some further questions on the cross-sex genetic correlations.

It seems that many studies fail to obtain sample sizes that is big enough
to get the realistic 95% CI. One of the solutions I noticed is comparing
the models (ASReml) where rmf is set to 1 or 0. How could that be done when
using MCMCglmm models? I was thinking of comparing

1. model 1, rmf=1

prior1<-list(G=list(G1=list(V=matrix(p.var*0.5),n=1)),R=list(V=matrix(p.var*0.5),n=1))

model1 <- MCMCglmm(trait ~ sex, random = ~animal, pedigree = pedigree,data
= data, nitt = 100000, thin = 100, burnin = 15000, prior = prior1,verbose =
FALSE)

2. model 2 allowing sexes to have different variance and covariance

prior2 <- list(R=list(V=diag(2), nu=0.02), G=list(G1=list(V=diag(2), nu=2,
alpha.mu=c(0,0),alpha.V=diag(2)*1000)))

model1 <- MCMCglmm(trait~sex, random=~us(sex):animal, rcov=~idh(sex):units,
prior=prior2, pedigree=Ped, data=Data1, nitt=100000, burnin=10000, thin=10)


3. model 3 allowing sexes to have different variance, but covariance = 0
--> rmf = 0

prior2 <- list(R=list(V=diag(2), nu=0.02), G=list(G1=list(V=diag(2), nu=2,
alpha.mu=c(0,0),alpha.V=diag(2)*1000)))

model3 <- MCMCglmm(trait~sex, random=~idh(sex):animal,
rcov=~idh(sex):units, prior=prior2, pedigree=Ped, data=Data1, nitt=100000,
burnin=10000, thin=10)


My reasoning may be stupid, I hope that's not forbidden :-)

Is there any other way? Fixing variances with prior?

Thank you. Best wishes

Simona

On 26 July 2017 at 14:42, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:

> Hi,
>
> The second way is a *much* better way of doing it but should give the same
> answer. However, in both cases the residual covariance is not identifiable
> (no individual is both male and female) and so you should use idh rather
> than us.
>
> The "subscript out of bounds" error is to do with your code that
> post-processes the model output not an issue with MCMCglmm. Probably you
> have used the wrong names for the (co)variance components.
>
> Also, you haven't passed the prior to MCMCglmm, nor is the prior a valid
> one for the problem as it specifies scalar variances rather than 2x2
> covariance matrices. You could try
>
> prior2 <- list(R=list(V=diag(2), nu=0.02), G=list(G1=list(V=diag(2), nu=2,
> alpha.mu=c(0,0),alpha.V=diag(2)*1000)))
>
> Cheers,
>
> Jarrod
>
>
>
>
> On 26/07/2017 13:33, Simona Kralj Fiser wrote:
>
>> model <- MCMCglmm(W~sex, random=~us(sex):animal, rcov=~us(sex):units,
>> prior=prior2, pedigree=Ped, data=Data1, nitt=100000, burnin=10000,
>> thin=10)
>>
>
>
> --
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
>
>

	[[alternative HTML version deleted]]


From j.hadfield at ed.ac.uk  Tue Jan 16 17:48:34 2018
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Tue, 16 Jan 2018 16:48:34 +0000
Subject: [R-sig-ME] cross-sex genetic correlation
In-Reply-To: <CAPkBqkkZW_iSiWpJLie_ej=XiBSmcEYhe7qNSrr_kUEMsbP3vQ@mail.gmail.com>
References: <CAPkBqk=4cQ73W4JizDeYFZ2CMUndNFb3JPe_enSv630ohn-zNQ@mail.gmail.com>
 <e8420da6-93bb-5ea5-d6e7-8602b1e71fc9@ed.ac.uk>
 <CAPkBqkkZW_iSiWpJLie_ej=XiBSmcEYhe7qNSrr_kUEMsbP3vQ@mail.gmail.com>
Message-ID: <88546674-a44c-bc51-16d1-747431e04820@ed.ac.uk>

Hi,

Your reasoning is correct. Other options are also:

~sex:animal? which restrictis rmf=0 and vm=vf

~animal+sex:animal which restricts rmf>0 and vm=vf

Cheers,

Jarrod


On 16/01/2018 12:22, Simona Kralj Fiser wrote:
>
> Hi!
>
> I have some further questions on the cross-sex genetic correlations.
>
> It seems that many studies fail to obtain sample sizes that is big 
> enough to get the realistic 95% CI. One of the solutions I noticed is 
> comparing the models (ASReml) where rmf is set to 1 or 0. How could 
> that be done when using MCMCglmm models? I was thinking of comparing
>
> 1. model 1, rmf=1
>
> prior1<-list(G=list(G1=list(V=matrix(p.var*0.5),n=1)),R=list(V=matrix(p.var*0.5),n=1))
>
> model1 <- MCMCglmm(trait ~ sex, random = ~animal, pedigree = 
> pedigree,data = data, nitt = 100000, thin = 100, burnin = 15000, prior 
> = prior1,verbose = FALSE)
>
> 2. model 2 allowing sexes to have different variance and covariance
>
> prior2 <- list(R=list(V=diag(2), nu=0.02), G=list(G1=list(V=diag(2), 
> nu=2, alpha.mu <http://alpha.mu/>=c(0,0),alpha.V=diag(2)*1000)))
>
> model1 <- MCMCglmm(trait~sex, random=~us(sex):animal, 
> rcov=~idh(sex):units, prior=prior2, pedigree=Ped, data=Data1, 
> nitt=100000, burnin=10000, thin=10)
>
>
> 3. model 3 allowing sexes to have different variance, but covariance = 
> 0 --> rmf = 0
>
> prior2 <- list(R=list(V=diag(2), nu=0.02), G=list(G1=list(V=diag(2), 
> nu=2, alpha.mu <http://alpha.mu/>=c(0,0),alpha.V=diag(2)*1000)))
>
> model3 <- MCMCglmm(trait~sex, random=~idh(sex):animal, 
> rcov=~idh(sex):units, prior=prior2, pedigree=Ped, data=Data1, 
> nitt=100000, burnin=10000, thin=10)
>
>
> My reasoning may be stupid, I hope that's not forbidden :-)
>
> Is there any other way? Fixing variances with prior?
>
> Thank you. Best wishes
>
> Simona
>
>
> On 26 July 2017 at 14:42, Jarrod Hadfield <j.hadfield at ed.ac.uk 
> <mailto:j.hadfield at ed.ac.uk>> wrote:
>
>     Hi,
>
>     The second way is a *much* better way of doing it but should give
>     the same answer. However, in both cases the residual covariance is
>     not identifiable (no individual is both male and female) and so
>     you should use idh rather than us.
>
>     The "subscript out of bounds" error is to do with your code that
>     post-processes the model output not an issue with MCMCglmm.
>     Probably you have used the wrong names for the (co)variance
>     components.
>
>     Also, you haven't passed the prior to MCMCglmm, nor is the prior a
>     valid one for the problem as it specifies scalar variances rather
>     than 2x2 covariance matrices. You could try
>
>     prior2 <- list(R=list(V=diag(2), nu=0.02),
>     G=list(G1=list(V=diag(2), nu=2, alpha.mu
>     <http://alpha.mu>=c(0,0),alpha.V=diag(2)*1000)))
>
>     Cheers,
>
>     Jarrod
>
>
>
>
>     On 26/07/2017 13:33, Simona Kralj Fiser wrote:
>
>         model <- MCMCglmm(W~sex, random=~us(sex):animal,
>         rcov=~us(sex):units,
>         prior=prior2, pedigree=Ped, data=Data1, nitt=100000,
>         burnin=10000, thin=10)
>
>
>
>     -- 
>     The University of Edinburgh is a charitable body, registered in
>     Scotland, with registration number SC005336.
>
>

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20180116/2da68f43/attachment.ksh>

From mr.lucedan at hotmail.it  Wed Jan 17 19:26:38 2018
From: mr.lucedan at hotmail.it (Luca Danieli)
Date: Wed, 17 Jan 2018 18:26:38 +0000
Subject: [R-sig-ME] show p_value for the interaction between two main effects
Message-ID: <CWXP265MB021650D216F539E46628239DF6E90@CWXP265MB0216.GBRP265.PROD.OUTLOOK.COM>

Hello all.

I have the following model,

me.model = lmer(Score ~ Closure*ExpertiseType + (Closure|Participant) + (1|Item), datasheet.complete)

in which Closure and ExpertiseType are ordinal data (so I use the function factor()).

This does not provide me anymore with an output

Closure (estimate) (error) (t) (p_value)
ExpertiseTye ... ... ... ...
Closure*ExpertiseType ... ... ... ...

I would need to know the p_value of the interaction, I could I do it?

Best
Luca

	[[alternative HTML version deleted]]


From mlathouri at yahoo.gr  Thu Jan 18 17:50:54 2018
From: mlathouri at yahoo.gr (Maria Lathouri)
Date: Thu, 18 Jan 2018 16:50:54 +0000 (UTC)
Subject: [R-sig-ME] tensor term by a factor in gamm4 error
References: <1725280561.916610.1516294254818.ref@mail.yahoo.com>
Message-ID: <1725280561.916610.1516294254818@mail.yahoo.com>

Dear all, 
I am writing as I would really need your help on the problem with gamm4. I am running a gamm4 model with an interaction between two variable using the tensor term, t2. I have a group variable (super end group) with six factors; I would like to run the model to see the how the interaction term varies across the factor levels and get the plot for each factor in one page. Here is my code but I get the following message 

dat<-read.table("dat.txt", header=TRUE) 
str(dat) 
#'data.frame':	11744 obs. of  11 variables: 
#$ WATERBODY_ID          : Factor w/ 1994 levels "GB102021072830",..: 1 1 2 2 2 3 3 3 4 4 5 5 5 5 5 6 ... 
#$ SITE_ID               : int  157166 157166 1636 1636 1636 1635 1635 1635 134261 1631 65383 65383 65383 111828 ... 
#$ Year                  : int  2011 2014 2013 2006 2003 2002 2013 2005 2013 2006 2011 2005 2004 ... 
#$ ResidualQ95           : num  100 100 80 80 80 98 98 98 105 105 101 101 130 120 120 ... 
#$ LIFE.OE_spring        : num  1.02 1.03 1.02 1.06 1.06 1.07 1.12 1.05 1.14 1.05 1.09 1.14 1.04 0.97 0.98 ... 
#$ super.end.group       : Factor w/ 6 levels "B","C","D","E",..: 1 1 3 3 3 2 2 2 4 4 ... 
#$ X.urban.suburban      : num  0 0 0.07 0.07 0.07 0.53 0.53 0.53 8.07 8.07 0.27 0.27 0.27 0.27 0.27 0.72 ... 
#$ X.broadleaved_woodland: num  2.83 2.83 10.39 10.39 10.39 7.72 7.72 21.15 21.15 14.44 14.44 ... 
#$ X.CapWks              : num  0 0 0 0 0 0 0 0 0 0 8.11 8.11 8.11 0 0 0 42.06 42.06 7.08 0.2 ... 
#$ Hms_Poaching          : num  0 0 10 10 10 0 0 0 0 10 10 20 40 5 30 15 15 0 0 0 50 50 ... 
#$ Hms_Rsctned           : num  0 0 0 0 0 0 0 0 0 0 2480 800 1960 1160 740 0 0 960 ...
library(gamm4) 

model<-gamm4(LIFE.OE_spring~s(ResidualQ95, by=super.end.group)+t2(ResidualQ95, Hms_Rsctned, by=super.end.group)+Year +Hms_Poaching +X.broadleaved_woodland +X.urban.suburban +X.CapWks, data=dat, random=~(1|WATERBODY_ID/SITE_ID)) 
#Warning messages: 
#1: In optwrap(optimizer, devfun, getStart(start, rho$lower, rho$pp),  : 
#  convergence code 1 from bobyqa: bobyqa -- maximum number of function evaluations exceeded 
#2: In optwrap(optimizer, devfun, opt$par, lower = rho$lower, control = control,  : 
#  convergence code 1 from bobyqa: bobyqa -- maximum number of function evaluations exceeded 

I also tried the following but I got the same message as before. 

model<-gamm4(LIFE.OE_spring~s(ResidualQ95)+t2(ResidualQ95, Hms_Rsctned, by=super.end.group)+Year+ Hms_Poaching +X.broadleaved_woodland +X.urban.suburban +X.CapWks, data=dat, random=~(1|WATERBODY_ID/SITE_ID)) 
#fixed-effect model matrix is rank deficient so dropping 1 column / coefficient 

#Warning messages: 
#1: In optwrap(optimizer, devfun, getStart(start, rho$lower, rho$pp),  : 
#  convergence code 1 from bobyqa: bobyqa -- maximum number of function evaluations exceeded 
#2: In optwrap(optimizer, devfun, opt$par, lower = rho$lower, control = control,  : 
#  convergence code 1 from bobyqa: bobyqa -- maximum number of function evaluations exceeded 

When I tried to plot, I got the following error: 
plot(model$gam, page=1) 
#Error in plot.window(...) : need finite 'ylim' values 
#In addition: Warning messages: 
#  1: In min(ll, na.rm = TRUE) : 
#  no non-missing arguments to min; returning Inf 
#  2: In max(ul, na.rm = TRUE) : 
#  no non-missing arguments to max; returning -Inf 

I would really appreciate your help. My dataset is quite large that is why I have used the str() to get an idea; I have attached a txt file as well but I have trimmed it a lot so it can fit the email size as a sample of my dataset. 

Thank you very much. 

Kind regards, 
Maria
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: dat.txt
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20180118/a2480f5e/attachment-0001.txt>

From mr.lucedan at hotmail.it  Thu Jan 18 18:21:36 2018
From: mr.lucedan at hotmail.it (Luca Danieli)
Date: Thu, 18 Jan 2018 17:21:36 +0000
Subject: [R-sig-ME] show p_value for the interaction between two main
	effects
In-Reply-To: <CWXP265MB021650D216F539E46628239DF6E90@CWXP265MB0216.GBRP265.PROD.OUTLOOK.COM>
References: <CWXP265MB021650D216F539E46628239DF6E90@CWXP265MB0216.GBRP265.PROD.OUTLOOK.COM>
Message-ID: <CWXP265MB02169B1726ADF11D6F2C6620F6E80@CWXP265MB0216.GBRP265.PROD.OUTLOOK.COM>

Hello everybody,

sorry to disturb you again.
Is it possible to obtain only the p_value of an interaction for a lmer() model that uses the function factor()?

Best
Luca
________________________________
From: Luca Danieli
Sent: 17 January 2018 18:26
To: r-sig-mixed-models at r-project.org
Subject: show p_value for the interaction between two main effects

Hello all.

I have the following model,

me.model = lmer(Score ~ Closure*ExpertiseType + (Closure|Participant) + (1|Item), datasheet.complete)

in which Closure and ExpertiseType are ordinal data (so I use the function factor()).

This does not provide me anymore with an output

Closure (estimate) (error) (t) (p_value)
ExpertiseTye ... ... ... ...
Closure*ExpertiseType ... ... ... ...

I would need to know the p_value of the interaction, I could I do it?

Best
Luca

	[[alternative HTML version deleted]]


From pgreenw1 at gmu.edu  Thu Jan 18 18:51:25 2018
From: pgreenw1 at gmu.edu (P Greenwood)
Date: Thu, 18 Jan 2018 12:51:25 -0500
Subject: [R-sig-ME] subjects within groups and effects of group
Message-ID: <CC4B04FD-6934-4E94-B9A6-8E7AA8FBA33A@gmu.edu>

Hello

I wanted some advice about handling subjects within groups and effects of group (randomly assigned).  I want to predict reaction time (RT) as a function of  ?Condition,?  alpha band power (PzAlpha), and drive. People (subjects) are randomly assigned to Condition, of which there are two.  Each person has data from 5 drives, and for each drive there are 10 trials.  There are 19 subjects in one group and 20 in the other.

My question is this: Am I handling the ?between subjects? factor of Condition correctly?  Also, am I treating subjects within group correctly?  I am pasting in some of my data.  The output is below.  

Regards

Pam Greenwood

library(lme4)
library(lmerTest)
INFAST_Behavioral <- read.csv(??.
na.omit(INFAST_Behavioral)
INFAST_Behavioral$RT = scale(INFAST_Behavioral$RT, center = TRUE, scale = TRUE)
INFAST_Behavioral$PzAlpha = scale(INFAST_Behavioral$PzAlpha, center = TRUE, scale = TRUE)
sumModelInteraction <- lmer(RT ~ 1 + (Condition + PzAlpha + Drive + PzAlpha*Condition) + (1 | subject) + (1 | trial), data = INFAST_Behavioral)
summary(sumModelInteraction)

subject	Condition		Drive		trial	FzAlpha	CzAlpha	PzAlpha	FzTheta	CzTheta	PzTheta	FzDelta	CzDelta	PzDelta		RT	ACC
1	HumanLanguage	1	1	-1.41	-4.3585	-5.5431	6.1516	1.5911	3.6247	22.38	18.181	13.812		1568.984857	1
1	HumanLanguage	1	2	-7.8605	2.0156	4.7392	15.992	12.122	6.9088	26.861	20.592	16.326	1721.359714	1
1	HumanLanguage	1	3	-2.6982	-5.6067	-10.038	6.285	5.5172	1.2894	13.565	12.981	11.63	1257.092571	1
1	HumanLanguage	1	4	3.3975	4.8789	-1.3249	7.0177	9.6703	6.1539	10.231	12.261	12.485	1559.461429	1
?(skipping to Subject 2)
2	HumanLanguage			1	1	1.6791	2.8887	0.28174	-11.387	-9.9352	3.5936	-1.5767	3.9401	6.7201		1302.328857	1
2	HumanLanguage	1	2	-13.284	-8.2603	-6.6124	-5.9373	-8.7551	0.10394	4.5621	10.204	12.261	969.0088571	1
2	HumanLanguage	1	3	-0.048973	1.1329	0.67399	-2.1432	2.5077	-2.4641	9.4667	10.883	7.1396	721.3997143	1
2	HumanLanguage	1	4	5.0779	6.8916	6.3892	-1.8682	3.1637	7.9712	8.0994	10.883	10.975	707.1145714	1
2	HumanLanguage	1	5	-7.0495	-2.782	3.1668	8.4332	10.646	9.3726	-3.5937	-7.3769	5.4472	892.8214286	1
2	HumanLanguage	1	6	-1.462	-8.1223	-6.5896	-10.895	-5.6311	0.39941	7.5473	12.783	14.698	611.8802857	1
2	HumanLanguage	1	7	-2.6402	-5.1213	-3.7372	3.4542	4.2234	-0.99898	1.4089	4.1976	0.56587	761.8742857	1
2	HumanLanguage	1	8	3.4393	4.6302	1.5525	1.4604	3.1716	3.1622	-2.3427	2.908	4.2259	680.9251429	1
2	HumanLanguage	1	9	-0.81024	-0.21642	-2.3876	2.5839	4.7307	1.5441	3.3761	8.4485	12.02	769.0168571	1
2	HumanLanguage	1	10	-6.4045	-4.4937	-2.2449	0.94456	2.7048	0.65565	-1.9791	0.26436	1.8435	885.6788571	1

Results:

Linear mixed model fit by REML t-tests use Satterthwaite approximations to degrees of freedom [
lmerMod]
Formula: RT ~ 1 + (Condition + PzAlpha + Drive + PzAlpha * Condition) +  
    (1 | subject) + (1 | trial)
   Data: INFAST_Behavioral

REML criterion at convergence: 3876.4

Scaled residuals: 
    Min      1Q  Median      3Q     Max 
-3.4308 -0.5227 -0.1194  0.3547  8.4095 

Random effects:
 Groups   Name        Variance Std.Dev.
 subject  (Intercept) 0.580073 0.76163 
 trial    (Intercept) 0.004778 0.06912 
 Residual             0.434918 0.65948 
Number of obs: 1839, groups:  subject, 39; trial, 10

Fixed effects:
                                  	 Estimate 		Std. Error         df t value Pr(>|t|)   
(Intercept)                        -0.27054    0.17607   40.80000  -1.537  0.13213   
ConditionMachineLang 0.41644    0.24595   36.90000   1.693  0.09884 . 
PzAlpha                             0.01192    0.02411 1797.40000   0.494  0.62117   
Drive                               0.02948    0.01083 1788.40000   2.722  0.00655 **
ConditionMachineLanguage:PzAlpha   -0.01998    0.03476 1803.10000  -0.575  0.56560   
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
P.M. Greenwood, Ph.D.
Associate Professor of Psychology
Editorial Board, NeuroImage
David King Hall 2052
George Mason University
MSN 3F5, 4400 University Drive
Fairfax, VA 22030-4444

Ph: 703 993-4268
fax: 703 993-1359
email: Pgreenw1 at gmu.edu
http://psychology.gmu.edu/people/pgreenw1


	[[alternative HTML version deleted]]


From bbolker at gmail.com  Thu Jan 18 19:15:35 2018
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 18 Jan 2018 13:15:35 -0500
Subject: [R-sig-ME] show p_value for the interaction between two main
 effects
In-Reply-To: <CWXP265MB02169B1726ADF11D6F2C6620F6E80@CWXP265MB0216.GBRP265.PROD.OUTLOOK.COM>
References: <CWXP265MB021650D216F539E46628239DF6E90@CWXP265MB0216.GBRP265.PROD.OUTLOOK.COM>
 <CWXP265MB02169B1726ADF11D6F2C6620F6E80@CWXP265MB0216.GBRP265.PROD.OUTLOOK.COM>
Message-ID: <db80b4cd-86e9-91c0-f5c8-e3f47283b507@gmail.com>


  To get the p-value of terms with more than one parameter (like
factors) you typically need to use anova(...,test="Chisq") to compare a
full and a reduced model.  drop1(test="Chisq") might work too.



On 18-01-18 12:21 PM, Luca Danieli wrote:
> Hello everybody,
> 
> sorry to disturb you again.
> Is it possible to obtain only the p_value of an interaction for a lmer() model that uses the function factor()?
> 
> Best
> Luca
> ________________________________
> From: Luca Danieli
> Sent: 17 January 2018 18:26
> To: r-sig-mixed-models at r-project.org
> Subject: show p_value for the interaction between two main effects
> 
> Hello all.
> 
> I have the following model,
> 
> me.model = lmer(Score ~ Closure*ExpertiseType + (Closure|Participant) + (1|Item), datasheet.complete)
> 
> in which Closure and ExpertiseType are ordinal data (so I use the function factor()).
> 
> This does not provide me anymore with an output
> 
> Closure (estimate) (error) (t) (p_value)
> ExpertiseTye ... ... ... ...
> Closure*ExpertiseType ... ... ... ...
> 
> I would need to know the p_value of the interaction, I could I do it?
> 
> Best
> Luca
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From n.bedere at gmail.com  Thu Jan 18 21:03:02 2018
From: n.bedere at gmail.com (=?UTF-8?B?Tmljb2xhcyBCw6lkw6hyZQ==?=)
Date: Thu, 18 Jan 2018 21:03:02 +0100
Subject: [R-sig-ME] How can I make R using more than 1 core (8 available) on
 a Ubuntu Rstudio server ?
Message-ID: <CALFoxB9zy7mXDRj8Ub+9M_ZVFK-8Cgk1Q7AvFG2dDAUT4oBQAQ@mail.gmail.com>

I want to run the *glmer* procedure on a ?large? dataset (250,000
observations). The model includes 5 fixed effects, 2 interactions terms and
3 random effects. It takes more than 15 min to run on my laptop (recent
intel core i7, RAM = 4GO). Thus, the IT department of the University I am
working at developed a Rstudio server based on the Ubuntu system. My
problem is that 8 cores are available on this server but when I run the *glmer
*procedure, only 1 of them is being used and it takes more than 1h to get
the results... How can I solve that problem and improve time efficiency? I
found on google I may have to use the parallel procedure but (i) I am not
familiar at all with those informatics procedures and they look a bit
complicated, (ii) the code I picked works with other functions in other
packages such as *kmeans{stats}* (
https://stackoverflow.com/questions/29998718/how-can-i-make-r-use-more-cpu-and-memory)
but neither with *lmer *nor *glmer.*



Can you please help with a simple procedure to tackle the problem?


Many thanks !

	[[alternative HTML version deleted]]


From bates at stat.wisc.edu  Thu Jan 18 21:07:03 2018
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 18 Jan 2018 20:07:03 +0000
Subject: [R-sig-ME] How can I make R using more than 1 core (8
 available) on a Ubuntu Rstudio server ?
In-Reply-To: <CALFoxB9zy7mXDRj8Ub+9M_ZVFK-8Cgk1Q7AvFG2dDAUT4oBQAQ@mail.gmail.com>
References: <CALFoxB9zy7mXDRj8Ub+9M_ZVFK-8Cgk1Q7AvFG2dDAUT4oBQAQ@mail.gmail.com>
Message-ID: <CAO7JsnSPPbk_rqZiCkkuQGQRMRHFE3c5RmAYGdees=qPZTDQ_Q@mail.gmail.com>

The procedure is fairly simple - just rewrite the lme4 package from
scratch. :-)

On Thu, Jan 18, 2018 at 2:03 PM Nicolas B?d?re <n.bedere at gmail.com> wrote:

> I want to run the *glmer* procedure on a ?large? dataset (250,000
> observations). The model includes 5 fixed effects, 2 interactions terms and
> 3 random effects. It takes more than 15 min to run on my laptop (recent
> intel core i7, RAM = 4GO). Thus, the IT department of the University I am
> working at developed a Rstudio server based on the Ubuntu system. My
> problem is that 8 cores are available on this server but when I run the
> *glmer
> *procedure, only 1 of them is being used and it takes more than 1h to get
> the results... How can I solve that problem and improve time efficiency? I
> found on google I may have to use the parallel procedure but (i) I am not
> familiar at all with those informatics procedures and they look a bit
> complicated, (ii) the code I picked works with other functions in other
> packages such as *kmeans{stats}* (
>
> https://stackoverflow.com/questions/29998718/how-can-i-make-r-use-more-cpu-and-memory
> )
> but neither with *lmer *nor *glmer.*
>
>
>
> Can you please help with a simple procedure to tackle the problem?
>
>
> Many thanks !
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From HDoran at air.org  Thu Jan 18 21:16:04 2018
From: HDoran at air.org (Doran, Harold)
Date: Thu, 18 Jan 2018 20:16:04 +0000
Subject: [R-sig-ME] How can I make R using more than 1 core (8
 available) on a Ubuntu Rstudio server ?
In-Reply-To: <CAO7JsnSPPbk_rqZiCkkuQGQRMRHFE3c5RmAYGdees=qPZTDQ_Q@mail.gmail.com>
References: <CALFoxB9zy7mXDRj8Ub+9M_ZVFK-8Cgk1Q7AvFG2dDAUT4oBQAQ@mail.gmail.com>
 <CAO7JsnSPPbk_rqZiCkkuQGQRMRHFE3c5RmAYGdees=qPZTDQ_Q@mail.gmail.com>
Message-ID: <DM2PR0501MB1280E608AEA0B5D0C1C01322CAE80@DM2PR0501MB1280.namprd05.prod.outlook.com>

@DB, I thought you were retired :)  But, to the OP, lme4 functions already take advantage of many computational methods that make computing these models to large data sets faster than (virtually) all other packages for estimating mixed linear models.

The packages you might come across for parallel processing won't necessarily apply here. For example, the foreach package is fantastic, but could not be applied to a glmer model.

Although, Doug, I do recall coming across some work I think in the Microsoft R distribution that did some parallel computing for matrix problems by default. I'm saying this by memory and cannot recall specifics.

With that said, I'm not certain parallel processing is the right thing to do with problems of this sort. Iteration t+1 depends on iteration t and when solutions to the problem live on a different processor, the expense of combining those things back together is not always faster, but instead can actually be even more expensive and slower.



-----Original Message-----
From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Douglas Bates
Sent: Thursday, January 18, 2018 3:07 PM
To: Nicolas B?d?re <n.bedere at gmail.com>
Cc: R SIG Mixed Models <r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] How can I make R using more than 1 core (8 available) on a Ubuntu Rstudio server ?

The procedure is fairly simple - just rewrite the lme4 package from scratch. :-)

On Thu, Jan 18, 2018 at 2:03 PM Nicolas B?d?re <n.bedere at gmail.com> wrote:

> I want to run the *glmer* procedure on a ?large? dataset (250,000 
> observations). The model includes 5 fixed effects, 2 interactions 
> terms and
> 3 random effects. It takes more than 15 min to run on my laptop 
> (recent intel core i7, RAM = 4GO). Thus, the IT department of the 
> University I am working at developed a Rstudio server based on the 
> Ubuntu system. My problem is that 8 cores are available on this server 
> but when I run the *glmer *procedure, only 1 of them is being used and 
> it takes more than 1h to get the results... How can I solve that 
> problem and improve time efficiency? I found on google I may have to 
> use the parallel procedure but (i) I am not familiar at all with those 
> informatics procedures and they look a bit complicated, (ii) the code 
> I picked works with other functions in other packages such as 
> *kmeans{stats}* (
>
> https://stackoverflow.com/questions/29998718/how-can-i-make-r-use-more
> -cpu-and-memory
> )
> but neither with *lmer *nor *glmer.*
>
>
>
> Can you please help with a simple procedure to tackle the problem?
>
>
> Many thanks !
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

From bates at stat.wisc.edu  Thu Jan 18 21:18:26 2018
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 18 Jan 2018 20:18:26 +0000
Subject: [R-sig-ME] How can I make R using more than 1 core (8
 available) on a Ubuntu Rstudio server ?
In-Reply-To: <CAO7JsnSPPbk_rqZiCkkuQGQRMRHFE3c5RmAYGdees=qPZTDQ_Q@mail.gmail.com>
References: <CALFoxB9zy7mXDRj8Ub+9M_ZVFK-8Cgk1Q7AvFG2dDAUT4oBQAQ@mail.gmail.com>
 <CAO7JsnSPPbk_rqZiCkkuQGQRMRHFE3c5RmAYGdees=qPZTDQ_Q@mail.gmail.com>
Message-ID: <CAO7JsnQG0jNS52JQwt4MAj9Jrd10v2zfYMafAgbqt+mdMKYaiw@mail.gmail.com>

On Thu, Jan 18, 2018 at 2:07 PM Douglas Bates <bates at stat.wisc.edu> wrote:

> The procedure is fairly simple - just rewrite the lme4 package from
> scratch. :-)
>

On a less facetious note, you may find it worthwhile installing Julia (see
https://julialang.org/downloads) and the MixedModels package.  The
MixedModels package itself is not multi-threaded but most of the linear
algebra goes through the BLAS (Basic Linear Algebra Subroutines) and, by
default, Julia is compiled against OpenBLAS.  You can, in a reasonably
straightforward way - as these things go, compile Julia against Intel's
Math Kernel Library (MKL) which helps accelerate the linear algebra.

An accelerated BLAS is not likely to buy you too much in lme4 because the
linear algebra uses Eigen and SuiteSparse.

	[[alternative HTML version deleted]]


From bates at stat.wisc.edu  Thu Jan 18 21:30:56 2018
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 18 Jan 2018 20:30:56 +0000
Subject: [R-sig-ME] How can I make R using more than 1 core (8
 available) on a Ubuntu Rstudio server ?
In-Reply-To: <DM2PR0501MB1280E608AEA0B5D0C1C01322CAE80@DM2PR0501MB1280.namprd05.prod.outlook.com>
References: <CALFoxB9zy7mXDRj8Ub+9M_ZVFK-8Cgk1Q7AvFG2dDAUT4oBQAQ@mail.gmail.com>
 <CAO7JsnSPPbk_rqZiCkkuQGQRMRHFE3c5RmAYGdees=qPZTDQ_Q@mail.gmail.com>
 <DM2PR0501MB1280E608AEA0B5D0C1C01322CAE80@DM2PR0501MB1280.namprd05.prod.outlook.com>
Message-ID: <CAO7JsnRWqo2CwOOUEQAtspYnUR+b=zdn_F_ZYz8HwB8LWmw_1A@mail.gmail.com>

On Thu, Jan 18, 2018 at 2:16 PM Doran, Harold <HDoran at air.org> wrote:

> @DB, I thought you were retired :)


I am retired.  I'm just not very good at it and keep coming in to the
office to work on various projects.

But, to the OP, lme4 functions already take advantage of many computational
> methods that make computing these models to large data sets faster than
> (virtually) all other packages for estimating mixed linear models.
>

The MixedModels package in Julia will usually perform at least as well as
lme4 and sometimes much better.  Of course, using it entails learning a bit
of Julia.  I would point out that with the RCall and RData packages for
Julia it is fairly straightforward to pass the data back and forth between
R and Julia.

The packages you might come across for parallel processing won't
> necessarily apply here. For example, the foreach package is fantastic, but
> could not be applied to a glmer model.
>
> Although, Doug, I do recall coming across some work I think in the
> Microsoft R distribution that did some parallel computing for matrix
> problems by default. I'm saying this by memory and cannot recall specifics.
>

The Microsoft R distribution (and, before that, Revolution R) use the MKL
BLAS that I mentioned.  Thanks for the reminder.  It may be worthwhile
trying with lme4.  Those benchmarks are somewhat disingenuous because they
only benchmark some linear algebra operations which is what MKL does very
well.  Interestingly, the most important operation for statisticians -
obtaining least squares solutions - is not accelerated in the standard R
solution.


> With that said, I'm not certain parallel processing is the right thing to
> do with problems of this sort. Iteration t+1 depends on iteration t and
> when solutions to the problem live on a different processor, the expense of
> combining those things back together is not always faster, but instead can
> actually be even more expensive and slower.
>

Parallelizing model fitting code is very tricky.

-----Original Message-----

> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org]
> On Behalf Of Douglas Bates
> Sent: Thursday, January 18, 2018 3:07 PM
> To: Nicolas B?d?re <n.bedere at gmail.com>
> Cc: R SIG Mixed Models <r-sig-mixed-models at r-project.org>
> Subject: Re: [R-sig-ME] How can I make R using more than 1 core (8
> available) on a Ubuntu Rstudio server ?
>
> The procedure is fairly simple - just rewrite the lme4 package from
> scratch. :-)
>
> On Thu, Jan 18, 2018 at 2:03 PM Nicolas B?d?re <n.bedere at gmail.com> wrote:
>
> > I want to run the *glmer* procedure on a ?large? dataset (250,000
> > observations). The model includes 5 fixed effects, 2 interactions
> > terms and
> > 3 random effects. It takes more than 15 min to run on my laptop
> > (recent intel core i7, RAM = 4GO). Thus, the IT department of the
> > University I am working at developed a Rstudio server based on the
> > Ubuntu system. My problem is that 8 cores are available on this server
> > but when I run the *glmer *procedure, only 1 of them is being used and
> > it takes more than 1h to get the results... How can I solve that
> > problem and improve time efficiency? I found on google I may have to
> > use the parallel procedure but (i) I am not familiar at all with those
> > informatics procedures and they look a bit complicated, (ii) the code
> > I picked works with other functions in other packages such as
> > *kmeans{stats}* (
> >
> > https://stackoverflow.com/questions/29998718/how-can-i-make-r-use-more
> > -cpu-and-memory
> > )
> > but neither with *lmer *nor *glmer.*
> >
> >
> >
> > Can you please help with a simple procedure to tackle the problem?
> >
> >
> > Many thanks !
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Thu Jan 18 21:36:08 2018
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 18 Jan 2018 15:36:08 -0500
Subject: [R-sig-ME] How can I make R using more than 1 core (8
 available) on a Ubuntu Rstudio server ?
In-Reply-To: <CAO7JsnSPPbk_rqZiCkkuQGQRMRHFE3c5RmAYGdees=qPZTDQ_Q@mail.gmail.com>
References: <CALFoxB9zy7mXDRj8Ub+9M_ZVFK-8Cgk1Q7AvFG2dDAUT4oBQAQ@mail.gmail.com>
 <CAO7JsnSPPbk_rqZiCkkuQGQRMRHFE3c5RmAYGdees=qPZTDQ_Q@mail.gmail.com>
Message-ID: <CABghstSjmPLxA9VnQNdaZ7gQX3e-jwO9bKAqMrS-+v2YdT5Z8g@mail.gmail.com>

  Explaining a little bit more; unlike a lot of informatics/machine
learning procedures, the algorithm underlying lme4 is not naturally
parallelizable. There are components that *could* be done in parallel,
but it's not simple.

  If you need faster computation, you could either try Doug's
MixedModels.jl package for Julia, or the glmmTMB package (on CRAN),
which may scale better than glmer for problems with large numbers of
fixed-effect parameters (although my guess is that it's close to a tie
for the problem specs you quote below, unless your fixed effects are
factors with several levels).

  Sometimes installing better-optimized linear algebra libraries or
better-optimized builds of R can help (optimized BLAS or Microsoft's
"R Open"), although likely not in the case of lme4.

  My other comment is that a lot of the computational load of modeling
has to do with running lots of different models, not with how long a
single model takes.  For example,

 - likelihood profiling
 - parametric bootstrapping
 - model comparison and testing via likelihood ratio tests or
information criteria
 - model selection (ugh)

Are all procedures that can be easily parallelized (support for
parallel computation is built-in for the first two).

  cheers
    Ben Bolker

On Thu, Jan 18, 2018 at 3:07 PM, Douglas Bates <bates at stat.wisc.edu> wrote:
> The procedure is fairly simple - just rewrite the lme4 package from
> scratch. :-)
>
> On Thu, Jan 18, 2018 at 2:03 PM Nicolas B?d?re <n.bedere at gmail.com> wrote:
>
>> I want to run the *glmer* procedure on a ?large? dataset (250,000
>> observations). The model includes 5 fixed effects, 2 interactions terms and
>> 3 random effects. It takes more than 15 min to run on my laptop (recent
>> intel core i7, RAM = 4GO). Thus, the IT department of the University I am
>> working at developed a Rstudio server based on the Ubuntu system. My
>> problem is that 8 cores are available on this server but when I run the
>> *glmer
>> *procedure, only 1 of them is being used and it takes more than 1h to get
>> the results... How can I solve that problem and improve time efficiency? I
>> found on google I may have to use the parallel procedure but (i) I am not
>> familiar at all with those informatics procedures and they look a bit
>> complicated, (ii) the code I picked works with other functions in other
>> packages such as *kmeans{stats}* (
>>
>> https://stackoverflow.com/questions/29998718/how-can-i-make-r-use-more-cpu-and-memory
>> )
>> but neither with *lmer *nor *glmer.*
>>
>>
>>
>> Can you please help with a simple procedure to tackle the problem?
>>
>>
>> Many thanks !
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From HDoran at air.org  Fri Jan 19 00:52:53 2018
From: HDoran at air.org (Doran, Harold)
Date: Thu, 18 Jan 2018 23:52:53 +0000
Subject: [R-sig-ME] How can I make R using more than 1 core (8
 available) on a Ubuntu Rstudio server ?
In-Reply-To: <CAO7JsnRWqo2CwOOUEQAtspYnUR+b=zdn_F_ZYz8HwB8LWmw_1A@mail.gmail.com>
References: <CALFoxB9zy7mXDRj8Ub+9M_ZVFK-8Cgk1Q7AvFG2dDAUT4oBQAQ@mail.gmail.com>
 <CAO7JsnSPPbk_rqZiCkkuQGQRMRHFE3c5RmAYGdees=qPZTDQ_Q@mail.gmail.com>
 <DM2PR0501MB1280E608AEA0B5D0C1C01322CAE80@DM2PR0501MB1280.namprd05.prod.outlook.com>
 <CAO7JsnRWqo2CwOOUEQAtspYnUR+b=zdn_F_ZYz8HwB8LWmw_1A@mail.gmail.com>
Message-ID: <D6869D15.4D88E%hdoran@air.org>

A while back, I did run lmer using a very large model in Microsoft R vs R and the timing was indeed faster for the same model on the same computer. Not by any meaningful order of magnitude that would be life changing, but faster nonetheless.



From: Douglas Bates <bates at stat.wisc.edu<mailto:bates at stat.wisc.edu>>
Date: Thursday, January 18, 2018 at 3:30 PM
To: AIR <hdoran at air.org<mailto:hdoran at air.org>>
Cc: Nicolas B?d?re <n.bedere at gmail.com<mailto:n.bedere at gmail.com>>, "r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>" <r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>>
Subject: Re: [R-sig-ME] How can I make R using more than 1 core (8 available) on a Ubuntu Rstudio server ?

On Thu, Jan 18, 2018 at 2:16 PM Doran, Harold <HDoran at air.org<mailto:HDoran at air.org>> wrote:
@DB, I thought you were retired :)

I am retired.  I'm just not very good at it and keep coming in to the office to work on various projects.

But, to the OP, lme4 functions already take advantage of many computational methods that make computing these models to large data sets faster than (virtually) all other packages for estimating mixed linear models.

The MixedModels package in Julia will usually perform at least as well as lme4 and sometimes much better.  Of course, using it entails learning a bit of Julia.  I would point out that with the RCall and RData packages for Julia it is fairly straightforward to pass the data back and forth between R and Julia.

The packages you might come across for parallel processing won't necessarily apply here. For example, the foreach package is fantastic, but could not be applied to a glmer model.

Although, Doug, I do recall coming across some work I think in the Microsoft R distribution that did some parallel computing for matrix problems by default. I'm saying this by memory and cannot recall specifics.

The Microsoft R distribution (and, before that, Revolution R) use the MKL BLAS that I mentioned.  Thanks for the reminder.  It may be worthwhile trying with lme4.  Those benchmarks are somewhat disingenuous because they only benchmark some linear algebra operations which is what MKL does very well.  Interestingly, the most important operation for statisticians - obtaining least squares solutions - is not accelerated in the standard R solution.

With that said, I'm not certain parallel processing is the right thing to do with problems of this sort. Iteration t+1 depends on iteration t and when solutions to the problem live on a different processor, the expense of combining those things back together is not always faster, but instead can actually be even more expensive and slower.

Parallelizing model fitting code is very tricky.

-----Original Message-----
From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org<mailto:r-sig-mixed-models-bounces at r-project.org>] On Behalf Of Douglas Bates
Sent: Thursday, January 18, 2018 3:07 PM
To: Nicolas B?d?re <n.bedere at gmail.com<mailto:n.bedere at gmail.com>>
Cc: R SIG Mixed Models <r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>>
Subject: Re: [R-sig-ME] How can I make R using more than 1 core (8 available) on a Ubuntu Rstudio server ?

The procedure is fairly simple - just rewrite the lme4 package from scratch. :-)

On Thu, Jan 18, 2018 at 2:03 PM Nicolas B?d?re <n.bedere at gmail.com<mailto:n.bedere at gmail.com>> wrote:

> I want to run the *glmer* procedure on a ?large? dataset (250,000
> observations). The model includes 5 fixed effects, 2 interactions
> terms and
> 3 random effects. It takes more than 15 min to run on my laptop
> (recent intel core i7, RAM = 4GO). Thus, the IT department of the
> University I am working at developed a Rstudio server based on the
> Ubuntu system. My problem is that 8 cores are available on this server
> but when I run the *glmer *procedure, only 1 of them is being used and
> it takes more than 1h to get the results... How can I solve that
> problem and improve time efficiency? I found on google I may have to
> use the parallel procedure but (i) I am not familiar at all with those
> informatics procedures and they look a bit complicated, (ii) the code
> I picked works with other functions in other packages such as
> *kmeans{stats}* (
>
> https://stackoverflow.com/questions/29998718/how-can-i-make-r-use-more
> -cpu-and-memory
> )
> but neither with *lmer *nor *glmer.*
>
>
>
> Can you please help with a simple procedure to tackle the problem?
>
>
> Many thanks !
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From n.bedere at gmail.com  Fri Jan 19 08:37:28 2018
From: n.bedere at gmail.com (=?UTF-8?B?Tmljb2xhcyBCw6lkw6hyZQ==?=)
Date: Fri, 19 Jan 2018 08:37:28 +0100
Subject: [R-sig-ME] How can I make R using more than 1 core (8
 available) on a Ubuntu Rstudio server ?
In-Reply-To: <D6869D15.4D88E%hdoran@air.org>
References: <CALFoxB9zy7mXDRj8Ub+9M_ZVFK-8Cgk1Q7AvFG2dDAUT4oBQAQ@mail.gmail.com>
 <CAO7JsnSPPbk_rqZiCkkuQGQRMRHFE3c5RmAYGdees=qPZTDQ_Q@mail.gmail.com>
 <DM2PR0501MB1280E608AEA0B5D0C1C01322CAE80@DM2PR0501MB1280.namprd05.prod.outlook.com>
 <CAO7JsnRWqo2CwOOUEQAtspYnUR+b=zdn_F_ZYz8HwB8LWmw_1A@mail.gmail.com>
 <D6869D15.4D88E%hdoran@air.org>
Message-ID: <CALFoxB8RH8QeMvzX9qUAKyx5XnBkF7NiJu7jrA2VZRVtd6=bTA@mail.gmail.com>

Dear Mr Bates, Bolker and Harold,

Thanks for your quick and enlightining answers!
I will then have a look at the different solutions you proposed (Julia and
glmTMB) waiting for you to rewrite your marvelous package from scratch to
break through this limit! :-)

Cheers


2018-01-19 0:52 GMT+01:00 Doran, Harold <HDoran at air.org>:

> A while back, I did run lmer using a very large model in Microsoft R vs R
> and the timing was indeed faster for the same model on the same computer.
> Not by any meaningful order of magnitude that would be life changing, but
> faster nonetheless.
>
>
>
> From: Douglas Bates <bates at stat.wisc.edu>
> Date: Thursday, January 18, 2018 at 3:30 PM
> To: AIR <hdoran at air.org>
> Cc: Nicolas B?d?re <n.bedere at gmail.com>, "r-sig-mixed-models at r-project.org"
> <r-sig-mixed-models at r-project.org>
>
> Subject: Re: [R-sig-ME] How can I make R using more than 1 core (8
> available) on a Ubuntu Rstudio server ?
>
> On Thu, Jan 18, 2018 at 2:16 PM Doran, Harold <HDoran at air.org> wrote:
>
>> @DB, I thought you were retired :)
>
>
> I am retired.  I'm just not very good at it and keep coming in to the
> office to work on various projects.
>
> But, to the OP, lme4 functions already take advantage of many
>> computational methods that make computing these models to large data sets
>> faster than (virtually) all other packages for estimating mixed linear
>> models.
>>
>
> The MixedModels package in Julia will usually perform at least as well as
> lme4 and sometimes much better.  Of course, using it entails learning a bit
> of Julia.  I would point out that with the RCall and RData packages for
> Julia it is fairly straightforward to pass the data back and forth between
> R and Julia.
>
> The packages you might come across for parallel processing won't
>> necessarily apply here. For example, the foreach package is fantastic, but
>> could not be applied to a glmer model.
>>
>> Although, Doug, I do recall coming across some work I think in the
>> Microsoft R distribution that did some parallel computing for matrix
>> problems by default. I'm saying this by memory and cannot recall specifics.
>>
>
> The Microsoft R distribution (and, before that, Revolution R) use the MKL
> BLAS that I mentioned.  Thanks for the reminder.  It may be worthwhile
> trying with lme4.  Those benchmarks are somewhat disingenuous because they
> only benchmark some linear algebra operations which is what MKL does very
> well.  Interestingly, the most important operation for statisticians -
> obtaining least squares solutions - is not accelerated in the standard R
> solution.
>
>
>> With that said, I'm not certain parallel processing is the right thing to
>> do with problems of this sort. Iteration t+1 depends on iteration t and
>> when solutions to the problem live on a different processor, the expense of
>> combining those things back together is not always faster, but instead can
>> actually be even more expensive and slower.
>>
>
> Parallelizing model fitting code is very tricky.
>
> -----Original Message-----
>
>> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org]
>> On Behalf Of Douglas Bates
>> Sent: Thursday, January 18, 2018 3:07 PM
>> To: Nicolas B?d?re <n.bedere at gmail.com>
>> Cc: R SIG Mixed Models <r-sig-mixed-models at r-project.org>
>> Subject: Re: [R-sig-ME] How can I make R using more than 1 core (8
>> available) on a Ubuntu Rstudio server ?
>>
>> The procedure is fairly simple - just rewrite the lme4 package from
>> scratch. :-)
>>
>> On Thu, Jan 18, 2018 at 2:03 PM Nicolas B?d?re <n.bedere at gmail.com>
>> wrote:
>>
>> > I want to run the *glmer* procedure on a ?large? dataset (250,000
>> > observations). The model includes 5 fixed effects, 2 interactions
>> > terms and
>> > 3 random effects. It takes more than 15 min to run on my laptop
>> > (recent intel core i7, RAM = 4GO). Thus, the IT department of the
>> > University I am working at developed a Rstudio server based on the
>> > Ubuntu system. My problem is that 8 cores are available on this server
>> > but when I run the *glmer *procedure, only 1 of them is being used and
>> > it takes more than 1h to get the results... How can I solve that
>> > problem and improve time efficiency? I found on google I may have to
>> > use the parallel procedure but (i) I am not familiar at all with those
>> > informatics procedures and they look a bit complicated, (ii) the code
>> > I picked works with other functions in other packages such as
>> > *kmeans{stats}* (
>> >
>> > https://stackoverflow.com/questions/29998718/how-can-i-make-r-use-more
>> > -cpu-and-memory
>> > )
>> > but neither with *lmer *nor *glmer.*
>> >
>> >
>> >
>> > Can you please help with a simple procedure to tackle the problem?
>> >
>> >
>> > Many thanks !
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > _______________________________________________
>> > R-sig-mixed-models at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Fri Jan 19 10:44:39 2018
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Fri, 19 Jan 2018 10:44:39 +0100
Subject: [R-sig-ME] subjects within groups and effects of group
In-Reply-To: <CC4B04FD-6934-4E94-B9A6-8E7AA8FBA33A@gmu.edu>
References: <CC4B04FD-6934-4E94-B9A6-8E7AA8FBA33A@gmu.edu>
Message-ID: <CAJuCY5xjL6wb5MxQs=MMum9BcqK-2QD6YNuythpa0a23uknT6g@mail.gmail.com>

Dear Pam,

You are handling condition and subject correctly.

There might be a problem with trial. Does trial indicates dependent
replication of the study? Is there a common effect of trial X for all
subjects? Because that is what your current model assumes. In case the
trials are independent, then you don't need to include it in the
model.

Note that Condition + PzAlpha + PzAlpha*Condition is verbose. You can
write it as PzAlpha*Condition.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
AND FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////




2018-01-18 18:51 GMT+01:00 P Greenwood <pgreenw1 at gmu.edu>:
> Hello
>
> I wanted some advice about handling subjects within groups and effects of group (randomly assigned).  I want to predict reaction time (RT) as a function of  ?Condition,?  alpha band power (PzAlpha), and drive. People (subjects) are randomly assigned to Condition, of which there are two.  Each person has data from 5 drives, and for each drive there are 10 trials.  There are 19 subjects in one group and 20 in the other.
>
> My question is this: Am I handling the ?between subjects? factor of Condition correctly?  Also, am I treating subjects within group correctly?  I am pasting in some of my data.  The output is below.
>
> Regards
>
> Pam Greenwood
>
> library(lme4)
> library(lmerTest)
> INFAST_Behavioral <- read.csv(??.
> na.omit(INFAST_Behavioral)
> INFAST_Behavioral$RT = scale(INFAST_Behavioral$RT, center = TRUE, scale = TRUE)
> INFAST_Behavioral$PzAlpha = scale(INFAST_Behavioral$PzAlpha, center = TRUE, scale = TRUE)
> sumModelInteraction <- lmer(RT ~ 1 + (Condition + PzAlpha + Drive + PzAlpha*Condition) + (1 | subject) + (1 | trial), data = INFAST_Behavioral)
> summary(sumModelInteraction)
>
> subject Condition               Drive           trial   FzAlpha CzAlpha PzAlpha FzTheta CzTheta PzTheta FzDelta CzDelta PzDelta         RT      ACC
> 1       HumanLanguage   1       1       -1.41   -4.3585 -5.5431 6.1516  1.5911  3.6247  22.38   18.181  13.812          1568.984857     1
> 1       HumanLanguage   1       2       -7.8605 2.0156  4.7392  15.992  12.122  6.9088  26.861  20.592  16.326  1721.359714     1
> 1       HumanLanguage   1       3       -2.6982 -5.6067 -10.038 6.285   5.5172  1.2894  13.565  12.981  11.63   1257.092571     1
> 1       HumanLanguage   1       4       3.3975  4.8789  -1.3249 7.0177  9.6703  6.1539  10.231  12.261  12.485  1559.461429     1
> ?(skipping to Subject 2)
> 2       HumanLanguage                   1       1       1.6791  2.8887  0.28174 -11.387 -9.9352 3.5936  -1.5767 3.9401  6.7201          1302.328857     1
> 2       HumanLanguage   1       2       -13.284 -8.2603 -6.6124 -5.9373 -8.7551 0.10394 4.5621  10.204  12.261  969.0088571     1
> 2       HumanLanguage   1       3       -0.048973       1.1329  0.67399 -2.1432 2.5077  -2.4641 9.4667  10.883  7.1396  721.3997143     1
> 2       HumanLanguage   1       4       5.0779  6.8916  6.3892  -1.8682 3.1637  7.9712  8.0994  10.883  10.975  707.1145714     1
> 2       HumanLanguage   1       5       -7.0495 -2.782  3.1668  8.4332  10.646  9.3726  -3.5937 -7.3769 5.4472  892.8214286     1
> 2       HumanLanguage   1       6       -1.462  -8.1223 -6.5896 -10.895 -5.6311 0.39941 7.5473  12.783  14.698  611.8802857     1
> 2       HumanLanguage   1       7       -2.6402 -5.1213 -3.7372 3.4542  4.2234  -0.99898        1.4089  4.1976  0.56587 761.8742857     1
> 2       HumanLanguage   1       8       3.4393  4.6302  1.5525  1.4604  3.1716  3.1622  -2.3427 2.908   4.2259  680.9251429     1
> 2       HumanLanguage   1       9       -0.81024        -0.21642        -2.3876 2.5839  4.7307  1.5441  3.3761  8.4485  12.02   769.0168571     1
> 2       HumanLanguage   1       10      -6.4045 -4.4937 -2.2449 0.94456 2.7048  0.65565 -1.9791 0.26436 1.8435  885.6788571     1
>
> Results:
>
> Linear mixed model fit by REML t-tests use Satterthwaite approximations to degrees of freedom [
> lmerMod]
> Formula: RT ~ 1 + (Condition + PzAlpha + Drive + PzAlpha * Condition) +
>     (1 | subject) + (1 | trial)
>    Data: INFAST_Behavioral
>
> REML criterion at convergence: 3876.4
>
> Scaled residuals:
>     Min      1Q  Median      3Q     Max
> -3.4308 -0.5227 -0.1194  0.3547  8.4095
>
> Random effects:
>  Groups   Name        Variance Std.Dev.
>  subject  (Intercept) 0.580073 0.76163
>  trial    (Intercept) 0.004778 0.06912
>  Residual             0.434918 0.65948
> Number of obs: 1839, groups:  subject, 39; trial, 10
>
> Fixed effects:
>                                          Estimate               Std. Error         df t value Pr(>|t|)
> (Intercept)                        -0.27054    0.17607   40.80000  -1.537  0.13213
> ConditionMachineLang 0.41644    0.24595   36.90000   1.693  0.09884 .
> PzAlpha                             0.01192    0.02411 1797.40000   0.494  0.62117
> Drive                               0.02948    0.01083 1788.40000   2.722  0.00655 **
> ConditionMachineLanguage:PzAlpha   -0.01998    0.03476 1803.10000  -0.575  0.56560
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> P.M. Greenwood, Ph.D.
> Associate Professor of Psychology
> Editorial Board, NeuroImage
> David King Hall 2052
> George Mason University
> MSN 3F5, 4400 University Drive
> Fairfax, VA 22030-4444
>
> Ph: 703 993-4268
> fax: 703 993-1359
> email: Pgreenw1 at gmu.edu
> http://psychology.gmu.edu/people/pgreenw1
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From phillip.alday at mpi.nl  Fri Jan 19 11:58:25 2018
From: phillip.alday at mpi.nl (Phillip Alday)
Date: Fri, 19 Jan 2018 11:58:25 +0100
Subject: [R-sig-ME] subjects within groups and effects of group
In-Reply-To: <CAJuCY5xjL6wb5MxQs=MMum9BcqK-2QD6YNuythpa0a23uknT6g@mail.gmail.com>
References: <CC4B04FD-6934-4E94-B9A6-8E7AA8FBA33A@gmu.edu>
 <CAJuCY5xjL6wb5MxQs=MMum9BcqK-2QD6YNuythpa0a23uknT6g@mail.gmail.com>
Message-ID: <99620d09-4dd7-5dac-e46e-4eb205be9cf7@mpi.nl>

Dear Pam, (dear Thierry,)

if I'm reading the description correctly, Pam is conceiving of Trial as
being an "Item"-type factor (crossed with subject). To rephrase
Thierry's comment a bit -- if Trial corresponds to an Item (concrete
stimulus realization sampled from the population of possible stimuli for
this manipulation) that is the same across subjects, then this is a good
way to model that. If Trial doesn't correspond to an invariant set of
items, but is rather just repetitions of the same task (perhaps with
some random variation that isn't identical across subjects), then
modeling Trial as a random effect doesn't really help much. However, if
Trial is just a sequence number for the repetition, it might make sense
to instead include Trial as a continuous fixed effect in order to model
adaptation effects.

Best,
Phillip

On 19/01/18 10:44, Thierry Onkelinx wrote:
> Dear Pam,
> 
> You are handling condition and subject correctly.
> 
> There might be a problem with trial. Does trial indicates dependent
> replication of the study? Is there a common effect of trial X for all
> subjects? Because that is what your current model assumes. In case the
> trials are independent, then you don't need to include it in the
> model.
> 
> Note that Condition + PzAlpha + PzAlpha*Condition is verbose. You can
> write it as PzAlpha*Condition.
> 
> Best regards,
> 
> ir. Thierry Onkelinx
> Statisticus / Statistician
> 
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
> AND FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Havenlaan 88 bus 73, 1000 Brussel
> www.inbo.be
> 
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no
> more than asking him to perform a post-mortem examination: he may be
> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does
> not ensure that a reasonable answer can be extracted from a given body
> of data. ~ John Tukey
> ///////////////////////////////////////////////////////////////////////////////////////////
> 
> 
> 
> 
> 2018-01-18 18:51 GMT+01:00 P Greenwood <pgreenw1 at gmu.edu>:
>> Hello
>>
>> I wanted some advice about handling subjects within groups and effects of group (randomly assigned).  I want to predict reaction time (RT) as a function of  ?Condition,?  alpha band power (PzAlpha), and drive. People (subjects) are randomly assigned to Condition, of which there are two.  Each person has data from 5 drives, and for each drive there are 10 trials.  There are 19 subjects in one group and 20 in the other.
>>
>> My question is this: Am I handling the ?between subjects? factor of Condition correctly?  Also, am I treating subjects within group correctly?  I am pasting in some of my data.  The output is below.
>>
>> Regards
>>
>> Pam Greenwood
>>
>> library(lme4)
>> library(lmerTest)
>> INFAST_Behavioral <- read.csv(??.
>> na.omit(INFAST_Behavioral)
>> INFAST_Behavioral$RT = scale(INFAST_Behavioral$RT, center = TRUE, scale = TRUE)
>> INFAST_Behavioral$PzAlpha = scale(INFAST_Behavioral$PzAlpha, center = TRUE, scale = TRUE)
>> sumModelInteraction <- lmer(RT ~ 1 + (Condition + PzAlpha + Drive + PzAlpha*Condition) + (1 | subject) + (1 | trial), data = INFAST_Behavioral)
>> summary(sumModelInteraction)
>>
>> subject Condition               Drive           trial   FzAlpha CzAlpha PzAlpha FzTheta CzTheta PzTheta FzDelta CzDelta PzDelta         RT      ACC
>> 1       HumanLanguage   1       1       -1.41   -4.3585 -5.5431 6.1516  1.5911  3.6247  22.38   18.181  13.812          1568.984857     1
>> 1       HumanLanguage   1       2       -7.8605 2.0156  4.7392  15.992  12.122  6.9088  26.861  20.592  16.326  1721.359714     1
>> 1       HumanLanguage   1       3       -2.6982 -5.6067 -10.038 6.285   5.5172  1.2894  13.565  12.981  11.63   1257.092571     1
>> 1       HumanLanguage   1       4       3.3975  4.8789  -1.3249 7.0177  9.6703  6.1539  10.231  12.261  12.485  1559.461429     1
>> ?(skipping to Subject 2)
>> 2       HumanLanguage                   1       1       1.6791  2.8887  0.28174 -11.387 -9.9352 3.5936  -1.5767 3.9401  6.7201          1302.328857     1
>> 2       HumanLanguage   1       2       -13.284 -8.2603 -6.6124 -5.9373 -8.7551 0.10394 4.5621  10.204  12.261  969.0088571     1
>> 2       HumanLanguage   1       3       -0.048973       1.1329  0.67399 -2.1432 2.5077  -2.4641 9.4667  10.883  7.1396  721.3997143     1
>> 2       HumanLanguage   1       4       5.0779  6.8916  6.3892  -1.8682 3.1637  7.9712  8.0994  10.883  10.975  707.1145714     1
>> 2       HumanLanguage   1       5       -7.0495 -2.782  3.1668  8.4332  10.646  9.3726  -3.5937 -7.3769 5.4472  892.8214286     1
>> 2       HumanLanguage   1       6       -1.462  -8.1223 -6.5896 -10.895 -5.6311 0.39941 7.5473  12.783  14.698  611.8802857     1
>> 2       HumanLanguage   1       7       -2.6402 -5.1213 -3.7372 3.4542  4.2234  -0.99898        1.4089  4.1976  0.56587 761.8742857     1
>> 2       HumanLanguage   1       8       3.4393  4.6302  1.5525  1.4604  3.1716  3.1622  -2.3427 2.908   4.2259  680.9251429     1
>> 2       HumanLanguage   1       9       -0.81024        -0.21642        -2.3876 2.5839  4.7307  1.5441  3.3761  8.4485  12.02   769.0168571     1
>> 2       HumanLanguage   1       10      -6.4045 -4.4937 -2.2449 0.94456 2.7048  0.65565 -1.9791 0.26436 1.8435  885.6788571     1
>>
>> Results:
>>
>> Linear mixed model fit by REML t-tests use Satterthwaite approximations to degrees of freedom [
>> lmerMod]
>> Formula: RT ~ 1 + (Condition + PzAlpha + Drive + PzAlpha * Condition) +
>>     (1 | subject) + (1 | trial)
>>    Data: INFAST_Behavioral
>>
>> REML criterion at convergence: 3876.4
>>
>> Scaled residuals:
>>     Min      1Q  Median      3Q     Max
>> -3.4308 -0.5227 -0.1194  0.3547  8.4095
>>
>> Random effects:
>>  Groups   Name        Variance Std.Dev.
>>  subject  (Intercept) 0.580073 0.76163
>>  trial    (Intercept) 0.004778 0.06912
>>  Residual             0.434918 0.65948
>> Number of obs: 1839, groups:  subject, 39; trial, 10
>>
>> Fixed effects:
>>                                          Estimate               Std. Error         df t value Pr(>|t|)
>> (Intercept)                        -0.27054    0.17607   40.80000  -1.537  0.13213
>> ConditionMachineLang 0.41644    0.24595   36.90000   1.693  0.09884 .
>> PzAlpha                             0.01192    0.02411 1797.40000   0.494  0.62117
>> Drive                               0.02948    0.01083 1788.40000   2.722  0.00655 **
>> ConditionMachineLanguage:PzAlpha   -0.01998    0.03476 1803.10000  -0.575  0.56560
>> ---
>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>> P.M. Greenwood, Ph.D.
>> Associate Professor of Psychology
>> Editorial Board, NeuroImage
>> David King Hall 2052
>> George Mason University
>> MSN 3F5, 4400 University Drive
>> Fairfax, VA 22030-4444
>>
>> Ph: 703 993-4268
>> fax: 703 993-1359
>> email: Pgreenw1 at gmu.edu
>> http://psychology.gmu.edu/people/pgreenw1
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From pgreenw1 at gmu.edu  Fri Jan 19 14:09:33 2018
From: pgreenw1 at gmu.edu (P Greenwood)
Date: Fri, 19 Jan 2018 08:09:33 -0500
Subject: [R-sig-ME] subjects within groups and effects of group
In-Reply-To: <99620d09-4dd7-5dac-e46e-4eb205be9cf7@mpi.nl>
References: <CC4B04FD-6934-4E94-B9A6-8E7AA8FBA33A@gmu.edu>
 <CAJuCY5xjL6wb5MxQs=MMum9BcqK-2QD6YNuythpa0a23uknT6g@mail.gmail.com>
 <99620d09-4dd7-5dac-e46e-4eb205be9cf7@mpi.nl>
Message-ID: <B9A8DD23-7CFB-4380-A6C0-22E35F661F6E@gmu.edu>

Thanks to you both.

Trial refers to stimulus events.  The stimuli are the same on each Trial, although the order of the Trials varies between Drives.   But, yes, Trial is a sequence number for the repetition so that there could be some adaptation or change in response related to number of exposures.  (Assuming that is what you meant).  How would I include Trial as a continuous fixed effect?

If the effect of Condition were ?significant.? how would one decompose that to examine each group (Condition) separately?

Regards

Pam


P.M. Greenwood, Ph.D.
Associate Professor of Psychology
Editorial Board, NeuroImage
David King Hall 2052
George Mason University
MSN 3F5, 4400 University Drive
Fairfax, VA 22030-4444

Ph: 703 993-4268
fax: 703 993-1359
email: Pgreenw1 at gmu.edu
http://psychology.gmu.edu/people/pgreenw1

> On Jan 19, 2018, at 5:58 AM, Phillip Alday <phillip.alday at mpi.nl> wrote:
> 
> Dear Pam, (dear Thierry,)
> 
> if I'm reading the description correctly, Pam is conceiving of Trial as
> being an "Item"-type factor (crossed with subject). To rephrase
> Thierry's comment a bit -- if Trial corresponds to an Item (concrete
> stimulus realization sampled from the population of possible stimuli for
> this manipulation) that is the same across subjects, then this is a good
> way to model that. If Trial doesn't correspond to an invariant set of
> items, but is rather just repetitions of the same task (perhaps with
> some random variation that isn't identical across subjects), then
> modeling Trial as a random effect doesn't really help much. However, if
> Trial is just a sequence number for the repetition, it might make sense
> to instead include Trial as a continuous fixed effect in order to model
> adaptation effects.
> 
> Best,
> Phillip
> 
> On 19/01/18 10:44, Thierry Onkelinx wrote:
>> Dear Pam,
>> 
>> You are handling condition and subject correctly.
>> 
>> There might be a problem with trial. Does trial indicates dependent
>> replication of the study? Is there a common effect of trial X for all
>> subjects? Because that is what your current model assumes. In case the
>> trials are independent, then you don't need to include it in the
>> model.
>> 
>> Note that Condition + PzAlpha + PzAlpha*Condition is verbose. You can
>> write it as PzAlpha*Condition.
>> 
>> Best regards,
>> 
>> ir. Thierry Onkelinx
>> Statisticus / Statistician
>> 
>> Vlaamse Overheid / Government of Flanders
>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
>> AND FOREST
>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
>> thierry.onkelinx at inbo.be
>> Havenlaan 88 bus 73, 1000 Brussel
>> www.inbo.be
>> 
>> ///////////////////////////////////////////////////////////////////////////////////////////
>> To call in the statistician after the experiment is done may be no
>> more than asking him to perform a post-mortem examination: he may be
>> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does
>> not ensure that a reasonable answer can be extracted from a given body
>> of data. ~ John Tukey
>> ///////////////////////////////////////////////////////////////////////////////////////////
>> 
>> 
>> 
>> 
>> 2018-01-18 18:51 GMT+01:00 P Greenwood <pgreenw1 at gmu.edu>:
>>> Hello
>>> 
>>> I wanted some advice about handling subjects within groups and effects of group (randomly assigned).  I want to predict reaction time (RT) as a function of  ?Condition,?  alpha band power (PzAlpha), and drive. People (subjects) are randomly assigned to Condition, of which there are two. Each person has data from 5 drives, and for each drive there are 10 trials.  There are 19 subjects in one group and 20 in the other.
>>> 
>>> My question is this: Am I handling the ?between subjects? factor of Condition correctly?  Also, am I treating subjects within group correctly?  I am pasting in some of my data.  The output is below.
>>> 
>>> Regards
>>> 
>>> Pam Greenwood
>>> 
>>> library(lme4)
>>> library(lmerTest)
>>> INFAST_Behavioral <- read.csv(??.
>>> na.omit(INFAST_Behavioral)
>>> INFAST_Behavioral$RT = scale(INFAST_Behavioral$RT, center = TRUE, scale = TRUE)
>>> INFAST_Behavioral$PzAlpha = scale(INFAST_Behavioral$PzAlpha, center = TRUE, scale = TRUE)
>>> sumModelInteraction <- lmer(RT ~ 1 + (Condition + PzAlpha + Drive + PzAlpha*Condition) + (1 | subject) + (1 | trial), data = INFAST_Behavioral)
>>> summary(sumModelInteraction)
>>> 
>>> subject Condition               Drive           trial   FzAlpha CzAlpha PzAlpha FzTheta CzTheta PzTheta FzDelta CzDelta PzDelta         RT      ACC
>>> 1       HumanLanguage   1       1       -1.41   -4.3585 -5.5431 6.1516  1.5911  3.6247  22.38   18.181 13.812          1568.984857     1
>>> 1       HumanLanguage   1       2       -7.8605 2.0156  4.7392  15.992  12.122  6.9088  26.861 20.592  16.326  1721.359714     1
>>> 1       HumanLanguage   1       3       -2.6982 -5.6067 -10.038 6.285   5.5172  1.2894  13.565 12.981  11.63   1257.092571     1
>>> 1       HumanLanguage   1       4       3.3975  4.8789  -1.3249 7.0177  9.6703  6.1539  10.231 12.261  12.485  1559.461429     1
>>> ?(skipping to Subject 2)
>>> 2       HumanLanguage                   1       1       1.6791  2.8887  0.28174 -11.387 -9.9352 3.5936 -1.5767 3.9401  6.7201          1302.328857     1
>>> 2       HumanLanguage   1       2       -13.284 -8.2603 -6.6124 -5.9373 -8.7551 0.10394 4.5621 10.204  12.261  969.0088571     1
>>> 2       HumanLanguage   1       3       -0.048973       1.1329  0.67399 -2.1432 2.5077  -2.4641 9.4667 10.883  7.1396  721.3997143     1
>>> 2       HumanLanguage   1       4       5.0779  6.8916  6.3892  -1.8682 3.1637  7.9712  8.0994 10.883  10.975  707.1145714     1
>>> 2       HumanLanguage   1       5       -7.0495 -2.782  3.1668  8.4332  10.646  9.3726  -3.5937 -7.3769 5.4472  892.8214286     1
>>> 2       HumanLanguage   1       6       -1.462  -8.1223 -6.5896 -10.895 -5.6311 0.39941 7.5473 12.783  14.698  611.8802857     1
>>> 2       HumanLanguage   1       7       -2.6402 -5.1213 -3.7372 3.4542  4.2234  -0.99898        1.4089 4.1976  0.56587 761.8742857     1
>>> 2       HumanLanguage   1       8       3.4393  4.6302  1.5525  1.4604  3.1716  3.1622  -2.3427 2.908 4.2259  680.9251429     1
>>> 2       HumanLanguage   1       9       -0.81024        -0.21642        -2.3876 2.5839  4.7307  1.5441 3.3761  8.4485  12.02   769.0168571     1
>>> 2       HumanLanguage   1       10      -6.4045 -4.4937 -2.2449 0.94456 2.7048  0.65565 -1.9791 0.26436 1.8435  885.6788571     1
>>> 
>>> Results:
>>> 
>>> Linear mixed model fit by REML t-tests use Satterthwaite approximations to degrees of freedom [
>>> lmerMod]
>>> Formula: RT ~ 1 + (Condition + PzAlpha + Drive + PzAlpha * Condition) +
>>>    (1 | subject) + (1 | trial)
>>>   Data: INFAST_Behavioral
>>> 
>>> REML criterion at convergence: 3876.4
>>> 
>>> Scaled residuals:
>>>    Min      1Q  Median      3Q     Max
>>> -3.4308 -0.5227 -0.1194  0.3547  8.4095
>>> 
>>> Random effects:
>>> Groups   Name        Variance Std.Dev.
>>> subject  (Intercept) 0.580073 0.76163
>>> trial    (Intercept) 0.004778 0.06912
>>> Residual             0.434918 0.65948
>>> Number of obs: 1839, groups:  subject, 39; trial, 10
>>> 
>>> Fixed effects:
>>>                                         Estimate               Std. Error         df t value Pr(>|t|)
>>> (Intercept)                        -0.27054    0.17607   40.80000  -1.537  0.13213
>>> ConditionMachineLang 0.41644    0.24595   36.90000   1.693  0.09884 .
>>> PzAlpha                             0.01192    0.02411 1797.40000   0.494  0.62117
>>> Drive                               0.02948    0.01083 1788.40000   2.722  0.00655 **
>>> ConditionMachineLanguage:PzAlpha   -0.01998    0.03476 1803.10000  -0.575  0.56560
>>> ---
>>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>> P.M. Greenwood, Ph.D.
>>> Associate Professor of Psychology
>>> Editorial Board, NeuroImage
>>> David King Hall 2052
>>> George Mason University
>>> MSN 3F5, 4400 University Drive
>>> Fairfax, VA 22030-4444
>>> 
>>> Ph: 703 993-4268
>>> fax: 703 993-1359
>>> email: Pgreenw1 at gmu.edu
>>> http://psychology.gmu.edu/people/pgreenw1
>>> 
>>> 
>>>        [[alternative HTML version deleted]]
>>> 
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://secure-web.cisco.com/1joP--B1_xWT50x7mVQZsmihBAOqrRroakmdBR5MIMiOARC9Fd1hE1yw-1sCnwGxdnwBghNSYF9p3BRdhCaL0o-KBtN4F3VSOMBOaVY1oHIj6WYPh_sr8e-zRksQa9F4ECA_XGS2Afp73TF2WsPYwPhZh0vxQMs_BOy--csyKCdriarDzsvIs-lPMcfSch2Ym2oCTwBXQ_YkEWQehip65TFdXUagB8dg1r-d1G0r841y-84pF20_DPQ6J18R57bYFsQp5D34gsd2C2Jf6WMFXlHUZLbGyg7TV0F8CEvUF6vNcNdjIJTUSz79up7bz_iYDKOezABzwahOdHoC45jHqvTmDYhjaqzCkPsymio7HL4h8UlFKyj0xzrIe3rEFvRQsMaNQdctVCMacfdjj-nJiV9Ab0-aVDdezvOlj8IwbPCwr9QwTBeZzUqOwf5ENxq1r/https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models <https://secure-web.cisco.com/1joP--B1_xWT50x7mVQZsmihBAOqrRroakmdBR5MIMiOARC9Fd1hE1yw-1sCnwGxdnwBghNSYF9p3BRdhCaL0o-KBtN4F3VSOMBOaVY1oHIj6WYPh_sr8e-zRksQa9F4ECA_XGS2Afp73TF2WsPYwPhZh0vxQMs_BOy--csyKCdriarDzsvIs-lPMcfSch2Ym2oCTwBXQ_YkEWQehip65TFdXUagB8dg1r-d1G0r841y-84pF20_DPQ6J18R57bYFsQp5D34gsd2C2Jf6WMFXlHUZLbGyg7TV0F8CEvUF6vNcNdjIJTUSz79up7bz_iYDKOezABzwahOdHoC45jHqvTmDYhjaqzCkPsymio7HL4h8UlFKyj0xzrIe3rEFvRQsMaNQdctVCMacfdjj-nJiV9Ab0-aVDdezvOlj8IwbPCwr9QwTBeZzUqOwf5ENxq1r/https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models>
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org <mailto:R-sig-mixed-models at r-project.org> mailing list
>> https://secure-web.cisco.com/1joP--B1_xWT50x7mVQZsmihBAOqrRroakmdBR5MIMiOARC9Fd1hE1yw-1sCnwGxdnwBghNSYF9p3BRdhCaL0o-KBtN4F3VSOMBOaVY1oHIj6WYPh_sr8e-zRksQa9F4ECA_XGS2Afp73TF2WsPYwPhZh0vxQMs_BOy--csyKCdriarDzsvIs-lPMcfSch2Ym2oCTwBXQ_YkEWQehip65TFdXUagB8dg1r-d1G0r841y-84pF20_DPQ6J18R57bYFsQp5D34gsd2C2Jf6WMFXlHUZLbGyg7TV0F8CEvUF6vNcNdjIJTUSz79up7bz_iYDKOezABzwahOdHoC45jHqvTmDYhjaqzCkPsymio7HL4h8UlFKyj0xzrIe3rEFvRQsMaNQdctVCMacfdjj-nJiV9Ab0-aVDdezvOlj8IwbPCwr9QwTBeZzUqOwf5ENxq1r/https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models <https://secure-web.cisco.com/1joP--B1_xWT50x7mVQZsmihBAOqrRroakmdBR5MIMiOARC9Fd1hE1yw-1sCnwGxdnwBghNSYF9p3BRdhCaL0o-KBtN4F3VSOMBOaVY1oHIj6WYPh_sr8e-zRksQa9F4ECA_XGS2Afp73TF2WsPYwPhZh0vxQMs_BOy--csyKCdriarDzsvIs-lPMcfSch2Ym2oCTwBXQ_YkEWQehip65TFdXUagB8dg1r-d1G0r841y-84pF20_DPQ6J18R57bYFsQp5D34gsd2C2Jf6WMFXlHUZLbGyg7TV0F8CEvUF6vNcNdjIJTUSz79up7bz_iYDKOezABzwahOdHoC45jHqvTmDYhjaqzCkPsymio7HL4h8UlFKyj0xzrIe3rEFvRQsMaNQdctVCMacfdjj-nJiV9Ab0-aVDdezvOlj8IwbPCwr9QwTBeZzUqOwf5ENxq1r/https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models>

	[[alternative HTML version deleted]]


From jduenas at zedat.fu-berlin.de  Fri Jan 19 14:29:47 2018
From: jduenas at zedat.fu-berlin.de (=?UTF-8?Q?Juan_Due=c3=b1as?=)
Date: Fri, 19 Jan 2018 14:29:47 +0100
Subject: [R-sig-ME] Help - I have an underdispersed glmm :(
Message-ID: <402b15d6-ba07-59f3-9178-a6825fed03ab@zedat.fu-berlin.de>

Dear all,


I wish to describe the relationship between the diversity of soil fungi 
and the application of different nutrients (fertilization). My response 
variable is the exponentiated Shannon index of diversity (q1). The 
explanatory variable has four levels. Each of the treatment factors was 
applied at the plot level and there are four replicates of each factor 
per elevation. Six randomly distributed soil cores were taken within 
each of the plots.

For the GLMMs I used lme4 package version 1.1-15, and vegan 2.4-4 to 
estimate q1.

One of the problems I have is that q1 takes decimal values, therefore it 
would be inappropriate (or impossible?) to fit my response variable with 
a poisson probability distribution. Therefore I tried gamma for the 
model specification with a log link function. I performed model 
selection with pairwise likelihood ratio tests.

I then checked my favored model for over-dispersion (which is depicted 
in the output below). It seems, that the model is under dispersed! I was 
checking the literature for solutions to this issue, but I could only 
find some vague notions, namely that some level of underdispersion is 
tolerated. In the case of overdispersion, it is recommended to use 
quasilikelihood, but apparently this solution has been disabled a while 
ago in lme4.

Generalized linear mixed model fit by maximum likelihood (Laplace 
Approximation) ['glmerMod']
Family: Gamma ( log )
Formula: q1 ~ Treatment + (1 | Elevation) + (1 | Elevation:Plot)
Data: dat
Control: glmerControl(optimizer = "nlminbw")

AIC BIC logLik deviance df.resid
1523.6 1547.9 -754.8 1509.6 231

Scaled residuals:
Min 1Q Median 3Q Max
-2.0938 -0.6378 -0.0694 0.5815 3.1634

Random effects:
Groups Name Variance Std.Dev.
Elevation:Plot (Intercept) 0.02632 0.1622
Elevation (Intercept) 0.01366 0.1169
Residual 0.17924 0.4234
Number of obs: 238, groups: Elevation:Plot, 47; Elevation, 3

Fixed effects:
Estimate Std. Error t value Pr(>|z|)
(Intercept) 2.63742 0.16504 15.981 <2e-16 ***
TreatmentN -0.08395 0.13284 -0.632 0.527
TreatmentNP -0.15163 0.12964 -1.170 0.242
TreatmentP -0.12925 0.12998 -0.994 0.320
---
Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Correlation of Fixed Effects:
(Intr) TrtmnN TrtmNP
TreatmentN -0.412
TreatmentNP -0.418 0.522
TreatmentP -0.417 0.524 0.535


chisq ratio rdf p
38.4696552 0.1658175 232.0000000 1.0000000


My concrete questions are: Should I be concerned that my model is 
underdispersed? Will the coeficients of the fixed terms be reliable in 
this scenario?


I appreciate any help on this regard.


Best regards,

Juan F. Due?as


From bbolker at gmail.com  Fri Jan 19 14:34:58 2018
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 19 Jan 2018 08:34:58 -0500
Subject: [R-sig-ME] Help - I have an underdispersed glmm :(
In-Reply-To: <402b15d6-ba07-59f3-9178-a6825fed03ab@zedat.fu-berlin.de>
References: <402b15d6-ba07-59f3-9178-a6825fed03ab@zedat.fu-berlin.de>
Message-ID: <6438e320-dffc-16cd-66f8-843c40fd5b82@gmail.com>


  Can you say a little more about why you expect q1 to be
Poisson-distributed, or more generally what mean-variance relationship
you expect?  Is there a mechanistic/theoretical framework for the
distribution of this variable?  Some reason not to find a transform that
makes the responses reasonably homoscedastic and linear?

  In general, it *only* makes sense to compute/test dispersion for model
families where the variance has a fixed relationship with the mean
(binomial, Poisson, ...), not when there is an estimated scale parameter
(Gaussian, Gamma, ...)

  Ben Bolker

On 18-01-19 08:29 AM, Juan Due?as wrote:
> Dear all,
> 
> 
> I wish to describe the relationship between the diversity of soil fungi
> and the application of different nutrients (fertilization). My response
> variable is the exponentiated Shannon index of diversity (q1). The
> explanatory variable has four levels. Each of the treatment factors was
> applied at the plot level and there are four replicates of each factor
> per elevation. Six randomly distributed soil cores were taken within
> each of the plots.
> 
> For the GLMMs I used lme4 package version 1.1-15, and vegan 2.4-4 to
> estimate q1.
> 
> One of the problems I have is that q1 takes decimal values, therefore it
> would be inappropriate (or impossible?) to fit my response variable with
> a poisson probability distribution. Therefore I tried gamma for the
> model specification with a log link function. I performed model
> selection with pairwise likelihood ratio tests.
> 
> I then checked my favored model for over-dispersion (which is depicted
> in the output below). It seems, that the model is under dispersed! I was
> checking the literature for solutions to this issue, but I could only
> find some vague notions, namely that some level of underdispersion is
> tolerated. In the case of overdispersion, it is recommended to use
> quasilikelihood, but apparently this solution has been disabled a while
> ago in lme4.
> 
> Generalized linear mixed model fit by maximum likelihood (Laplace
> Approximation) ['glmerMod']
> Family: Gamma ( log )
> Formula: q1 ~ Treatment + (1 | Elevation) + (1 | Elevation:Plot)
> Data: dat
> Control: glmerControl(optimizer = "nlminbw")
> 
> AIC BIC logLik deviance df.resid
> 1523.6 1547.9 -754.8 1509.6 231
> 
> Scaled residuals:
> Min 1Q Median 3Q Max
> -2.0938 -0.6378 -0.0694 0.5815 3.1634
> 
> Random effects:
> Groups Name Variance Std.Dev.
> Elevation:Plot (Intercept) 0.02632 0.1622
> Elevation (Intercept) 0.01366 0.1169
> Residual 0.17924 0.4234
> Number of obs: 238, groups: Elevation:Plot, 47; Elevation, 3
> 
> Fixed effects:
> Estimate Std. Error t value Pr(>|z|)
> (Intercept) 2.63742 0.16504 15.981 <2e-16 ***
> TreatmentN -0.08395 0.13284 -0.632 0.527
> TreatmentNP -0.15163 0.12964 -1.170 0.242
> TreatmentP -0.12925 0.12998 -0.994 0.320
> ---
> Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
> 
> Correlation of Fixed Effects:
> (Intr) TrtmnN TrtmNP
> TreatmentN -0.412
> TreatmentNP -0.418 0.522
> TreatmentP -0.417 0.524 0.535
> 
> 
> chisq ratio rdf p
> 38.4696552 0.1658175 232.0000000 1.0000000
> 
> 
> My concrete questions are: Should I be concerned that my model is
> underdispersed? Will the coeficients of the fixed terms be reliable in
> this scenario?
> 
> 
> I appreciate any help on this regard.
> 
> 
> Best regards,
> 
> Juan F. Due?as
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From itzikf at outlook.com  Sat Jan 20 12:34:45 2018
From: itzikf at outlook.com (Isaac Fradkin)
Date: Sat, 20 Jan 2018 11:34:45 +0000
Subject: [R-sig-ME] Accounting for dv score's validity using weights -
	metafor or lme4?
Message-ID: <AM0PR0702MB371671BBED4F7F6C2D1A3441DFEE0@AM0PR0702MB3716.eurprd07.prod.outlook.com>

Dear all.

I have a dataset of 964 data points clustered within 250 participant. Each participant gave several open-responses to a specific question, and these responses were then coded by additional participants (~25 per response) on a scale from 0-100 (representing probability, but it doesn't seem to matter for the question here). Now, the simplest way to analyze this is to simply take the median (or winsorized mean) of the different ratings, and using this as the dv. However, because some responses produced more disagreement between raters than others, I thought it might be wise to account for this 'uncertainty' in some way.
I've considered two ways. First, I believe one might try to think of the problem in a meta-analytic framework. Each median rating in-fact represents sort of a 'sample estimate' taken from a distribution which variance corresponds to the variance between ratings, just like in random effects meta-analysis each effect size is weighted by its precision because it is assumed to come from a population effect size for this study. If this sound ok I could use the metafor package to specify a multilevel model. The problem is that I don't know of any study using such an approach.
Second, I know there is a weights argument in lme4, but not exactly sure how it works, and how its results will relate to the first solution.

Any advise or relevant reference is highly appreciated!
Isaac.

	[[alternative HTML version deleted]]


From wolfgang.viechtbauer at maastrichtuniversity.nl  Sat Jan 20 13:02:16 2018
From: wolfgang.viechtbauer at maastrichtuniversity.nl (Viechtbauer Wolfgang (SP))
Date: Sat, 20 Jan 2018 12:02:16 +0000
Subject: [R-sig-ME] Accounting for dv score's validity using weights -
 metafor or lme4?
Message-ID: <7a0f1cb655d94738a40724eb8c396008@UM-MAIL3214.unimaas.nl>

Hi Isaac,

If I understand you correctly, the data structure looks something like this:

participant response coder value
================================
1           1        1     y
1           1        2     y
...         ...     ...    ...
1           1       25     y
--------------------------------
1           2        1     y
1           2        2     y
...         ...     ...    ...
1           2       25     y
--------------------------------
2           1        1     y
2           1        2     y
...         ...     ...    ...
2           1       25     y
--------------------------------
2           2        1     y
2           2        2     y
...         ...     ...    ...
2           2       25     y
--------------------------------

So, subject 1 gave two responses, each of which was coded by 25 coders; subject 2 gave 2 (or maybe more) responses, again each of which was coded by 25 coders; and so on. I assume the same coders were used across participants (with maybe some slight variation) and that you know who the coders were (so coder 1 for subject 1 is the same person as coder 1 for subject 2, since the coder ID numbers are the same).

I see no need for treating this 'meta-analytically'. You have the raw data, so you might as well analyze them as such. A starting point to consider would be a model along the lines of:

lme(y ~ 1 + (1 | participant/response) + (1 | coder), ...)

that is, random effects for participants, random effects for responses within participants, and then crossed random efects for coders (since coders may have a propensity to give higher/lower values, regardless of whose participant's responses they are coding).

Since the outcome represents a probability, you might run into floor/ceiling issues, leading to violations of distributional assumptions (normality of random effects, normality of residuals), so this is something to examine.

Best,
Wolfgang

-- 
Wolfgang Viechtbauer, Ph.D., Statistician | Department of Psychiatry and 
Neuropsychology | Maastricht University | P.O. Box 616 (VIJV1) | 6200 MD 
Maastricht, The Netherlands | +31 (43) 388-4170 | http://www.wvbauer.com 

>-----Original Message-----
>From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-
>project.org] On Behalf Of Isaac Fradkin
>Sent: Saturday, 20 January, 2018 12:35
>To: r-sig-mixed-models at r-project.org
>Subject: [R-sig-ME] Accounting for dv score's validity using weights -
>metafor or lme4?
>
>Dear all.
>
>I have a dataset of 964 data points clustered within 250 participant.
>Each participant gave several open-responses to a specific question, and
>these responses were then coded by additional participants (~25 per
>response) on a scale from 0-100 (representing probability, but it doesn't
>seem to matter for the question here). Now, the simplest way to analyze
>this is to simply take the median (or winsorized mean) of the different
>ratings, and using this as the dv. However, because some responses
>produced more disagreement between raters than others, I thought it might
>be wise to account for this 'uncertainty' in some way.
>I've considered two ways. First, I believe one might try to think of the
>problem in a meta-analytic framework. Each median rating in-fact
>represents sort of a 'sample estimate' taken from a distribution which
>variance corresponds to the variance between ratings, just like in random
>effects meta-analysis each effect size is weighted by its precision
>because it is assumed to come from a population effect size for this
>study. If this sound ok I could use the metafor package to specify a
>multilevel model. The problem is that I don't know of any study using
>such an approach.
>Second, I know there is a weights argument in lme4, but not exactly sure
>how it works, and how its results will relate to the first solution.
>
>Any advise or relevant reference is highly appreciated!
>Isaac.


From Maarten.Jung at mailbox.tu-dresden.de  Sat Jan 20 15:13:56 2018
From: Maarten.Jung at mailbox.tu-dresden.de (Maarten Jung)
Date: Sat, 20 Jan 2018 15:13:56 +0100
Subject: [R-sig-ME] Df for 'random-intercept-only' model
Message-ID: <CAHr4Dyd0vr-LQcdmwq6A+pHcbJUcS+uFGC_SV6_vDKTgqqQRLg@mail.gmail.com>

Dear list,

I'm trying to get an estimate for the degrees of freedom of the following
'random-intercept-only' model: lmer(value ~ 1 + (1|participant), data = d).
Normally, I know that one can achieve this via the lmerTest package but in
this case it doesn't seem to work.

library(lmerTest)

d <- structure(list(value = c(8.25313070764297, 17.0453980104411,
14.7103370498893, 15.8219809684075, 18.0962761595002, 15.0493332821287,
17.5226332786703, 18.0503969664744, 13.9450638512715, 16.5332566133129,
13.1299408088999, 15.7163333693101, 17.5128147209307, 13.8564235534667,
11.3690970113334, 11.458250790531, 12.4039353096013, 16.9168322671145,
14.5580055004946, 17.5039029057499, 17.4265303119576, 10.3394971583312,
14.3327437896945, 10.1075784647337, 13.5324234318869, 12.9997105711724,
18.0080570272635, 15.2842579562302, 15.2356443644651, 15.813831547332,
14.8905281019859, 12.9039538908697, 17.3783863341884, 16.0160603506154,
18.4540620620647, 8.68750928534364, 14.462724834603, 16.8719660771132,
16.3784470438622, 16.228431742704, 17.2260499546157, 14.4592109398455,
12.9768791191779, 16.0745074082946, 14.4003729683924, 18.3820335802969,
13.8298449655042, 13.3898039860578, 11.2943669087644, 11.3711693435468,
18.1917812063674, 13.5455973955032, 17.0505866395927, 15.6054278307471,
12.1163489978806, 16.5776960925959, 15.5595289759737, 13.1383036025308,
16.7858376357516, 18.5934575849391, 12.6122831749272, 17.0565311301485,
13.2374564449912, 15.6139433555906, 14.6293717224923, 17.3818235894563,
15.7412428493826, 22.1877337982038, 18.3842887975238, 10.0701573038888,
10.8804812404375, 11.7148149325827, 14.4690669558257, 14.50516878681,
17.9920135587834, 19.6609636797189, 14.3073652841217, 16.4785695045202,
12.6811309533188, 14.6032532299404, 12.3152507852885, 18.1340692925595,
15.4724734122014, 17.406638598528, 12.2625532078185, 11.8729946785576,
15.9063789963309, 15.8208702113247, 12.203938368013, 14.894840829895,
15.5397556234126, 17.0641047610171, 18.3147667118571, 16.3914422509424,
14.5539887230189, 15.2870912573834, 17.0165733030807, 16.5537600282835,
12.1300522052001, 18.291737264292), participant = structure(c(15L,
3L, 6L, 6L, 11L, 57L, 43L, 10L, 16L, 49L, 54L, 11L, 22L, 24L, 41L, 48L,
35L, 46L, 59L, 23L, 55L, 41L, 39L, 15L, 60L, 52L, 5L,
48L, 33L, 50L, 2L, 53L, 11L, 47L, 19L, 15L, 60L, 22L, 31L, 21L, 11L, 59L,
24L, 50L, 20L, 5L, 14L, 3L, 39L, 18L, 9L, 33L, 46L,
49L, 38L, 19L, 33L, 46L, 45L, 22L, 14L, 10L, 4L, 33L, 44L, 43L, 47L, 13L,
22L, 42L, 35L, 38L, 40L, 33L, 10L, 2L, 55L, 40L, 48L,
57L, 41L, 16L, 2L, 8L, 48L, 47L, 30L, 7L, 48L, 6L, 44L, 9L, 22L, 9L, 56L,
40L, 6L, 59L, 3L, 26L), .Label = c("1", "2", "3", "4",
"5", "6", "7", "8", "9", "10", "11", "12", "13", "14", "15", "16", "17",
"18", "19", "20", "21", "22", "23", "24", "25", "26",
"27", "28", "29", "30", "31", "32", "33", "34", "35", "36", "37", "38",
"39", "40", "41", "42", "43", "44", "45", "46", "47", "48",
"49", "50", "51", "52", "53", "54", "55", "56", "57", "58", "59", "60"),
class = "factor")), .Names = c("value", "participant"), row.names = c(NA,
-100L), class = c("tbl_df", "tbl", "data.frame"))

summary(m1 <- lmer(value ~ 1 + (1|participant), data = d))

Running this code returns "summary from lme4 is returned. some
computational error has occurred in lmerTest".


Thanks a lot for any help!


Best,

Maarten

	[[alternative HTML version deleted]]


From hans.ekbrand at gmail.com  Sun Jan 21 00:24:15 2018
From: hans.ekbrand at gmail.com (Hans Ekbrand)
Date: Sun, 21 Jan 2018 00:24:15 +0100
Subject: [R-sig-ME] How can I make R using more than 1 core (8
 available) on a Ubuntu Rstudio server ?
In-Reply-To: <CABghstSjmPLxA9VnQNdaZ7gQX3e-jwO9bKAqMrS-+v2YdT5Z8g@mail.gmail.com>
References: <CALFoxB9zy7mXDRj8Ub+9M_ZVFK-8Cgk1Q7AvFG2dDAUT4oBQAQ@mail.gmail.com>
 <CAO7JsnSPPbk_rqZiCkkuQGQRMRHFE3c5RmAYGdees=qPZTDQ_Q@mail.gmail.com>
 <CABghstSjmPLxA9VnQNdaZ7gQX3e-jwO9bKAqMrS-+v2YdT5Z8g@mail.gmail.com>
Message-ID: <20180120232415.fpynz3y2vqvgr76w@hans>

On Thu, Jan 18, 2018 at 03:36:08PM -0500, Ben Bolker wrote:
>   Explaining a little bit more; unlike a lot of informatics/machine
> learning procedures, the algorithm underlying lme4 is not naturally
> parallelizable. There are components that *could* be done in parallel,
> but it's not simple.
> 
>   If you need faster computation, you could either try Doug's
> MixedModels.jl package for Julia, or the glmmTMB package (on CRAN),
> which may scale better than glmer for problems with large numbers of
> fixed-effect parameters (although my guess is that it's close to a tie
> for the problem specs you quote below, unless your fixed effects are
> factors with several levels).

I'm currently analysing a few huge datasets and in one of the cases
the outcome was binary (in the other cases, the outcome was count data
so I used negative binomial in glmmTMB), so I tried both glmer and
glmmTMB and glmmTMB was faster. My model included about 11 fixed
effects without interactions and three random intercept terms.

However, I had problem getting a clean convergence when I tried to fit
the model to the complete dataset, both with glmer and glmmTMB, and
what I did might help Nicolas B?d?re too. I think the convergence
problems in my case was related to the fact that the outcome was very
rare, only 11.221 cases had the outcome (death), while 5.674.928
didn't have the outcome (the were alive). 

Anyway, I divided the dataset into 8 bins, and fitted the same model
to each dataset, and since I had a 4 core CPU, 4 datasets could be
independently fitted in parallel. Then I took the estimates and
applied Rubin's Rule on them, to get pooled results.

(In my particular case, I left all 11.221 positive cases in each of
the 8 datasets, while each negative case only appeared in one of the 8
datasets.)

I consider what I did as a kind of poor-man's-bootstrapping, but I
would like to have some feedback on the valididity of results one gets
with the method I used. If it is valid, then it is one way of
parallelising glmer.

-- 
Hans Ekbrand, Fil Dr
Epost/email: <hans.ekbrand at gu.se>
Telefon/phone: +46-31 786 47 73
Institutionen f?r sociologi och arbetsvetenskap, G?teborgs universitet
Department of sociology and work science, Gothenburg university


From jduenas at zedat.fu-berlin.de  Mon Jan 22 09:56:22 2018
From: jduenas at zedat.fu-berlin.de (=?UTF-8?Q?Juan_F_Due=c3=b1as?=)
Date: Mon, 22 Jan 2018 09:56:22 +0100
Subject: [R-sig-ME] Help - I have an underdispersed glmm :(
In-Reply-To: <6438e320-dffc-16cd-66f8-843c40fd5b82@gmail.com>
References: <6438e320-dffc-16cd-66f8-843c40fd5b82@gmail.com>
Message-ID: <c65da47e-0d0b-0098-2a2c-24d289102fcc@zedat.fu-berlin.de>

Hello Ben and everybody,

Thanks for your answer. I will try to answer to your questions in order.

Maybe I expressed myself wrong. I have no good reason to expect q1 to
follow poisson. All I understand - in my comic book type understanding-
is that shannon's H is a measure of diversity that results from the
weighting of the number of species in a sample by the individual
abundance within each species. Therefore q1 is a proportion and in that
case is not formally a count, so poisson will not work.

As to what sort of variance structure to expect from this response
variable, what I can say is that when I ignore the random effects and
fit a glm with gaussian (link="log"), there is almost no
heteroscedasticity, which is confirmed by a Bartlett's test
(below). However, the Q-Q plot of this same model shows that the std.dev
residuals do not adjust well to normality. I then re-specify the same
glm with a gamma distribution and log link function and that seems to
resolve both the heteroscedasticity and the fit of the std.dev
residuals.

Bartlett test of homogeneity of variances
data: resid(glm) by meta.ec.n$Treatment
Bartlett's K-squared = 0.94193, df = 3, p-value = 0.8153

Finally, I am not aware of any theoretical framework for the
distribution of this variable. And the reason for not simply
transforming my response variable to linearize the relationship and then
fit my data with lmer is that I was under the impression that GLMM are a
more efficient way to deal with these issues. The other reason is that I
am worried that the transformation over corrects the residual fit to
the theoretical distribution.

In addition to the statements of the glm, I ran a boxcox command (from
package:MASS) on the glm. It seemed to confirm that log transformation
of the response variable would be the best shot. I then specify a linear
mixed effect model, with the log transformed variable. However the
diagnostic plots, showed some heteroscedasticity and not that optimal fit to normality.

lme.1 <- lmer(log.q1~Treatment +(1|Elevation) + (1|Elevation:Plot), data=dat)

Do you think it would be better then to go for the linear model transforming the data, instead of the glmm?

Best regards,

Juan

/
>    Can you say a little more about why you expect q1 to be
> Poisson-distributed, or more generally what mean-variance relationship
> you expect?  Is there a mechanistic/theoretical framework for the
> distribution of this variable?  Some reason not to find a transform that
> makes the responses reasonably homoscedastic and linear?
>
>    In general, it *only* makes sense to compute/test dispersion for model
> families where the variance has a fixed relationship with the mean
> (binomial, Poisson, ...), not when there is an estimated scale parameter
> (Gaussian, Gamma, ...)
>
>    Ben Bolker
>
> On 18-01-19 08:29 AM, Juan Due?as wrote:
> >/Dear all, />//>//>/I wish to describe the relationship between the diversity of soil fungi />/and the application of different nutrients (fertilization). My response />/variable is the exponentiated Shannon index of diversity (q1). The />/explanatory variable has four levels. Each of the treatment factors was />/applied at the plot level and there are four replicates of each factor />/per elevation. Six randomly distributed soil cores were taken within />/each of the plots. />//>/For the GLMMs I used lme4 package version 1.1-15, and vegan 2.4-4 to />/estimate q1. />//>/One of the problems I have is that q1 takes decimal values, therefore it />/would be inappropriate (or impossible?) to fit my response variable with />/a poisson probability distribution. Therefore I tried gamma for the />/model specification with a log link function. I performed model />/selection with pairwise likelihood ratio tests. />//>/I then checked my favored model for over-dispersion (which is depicted />/in the output below). It seems, that the model is under dispersed! I was />/checking the literature for solutions to this issue, but I could only />/find some vague notions, namely that some level of underdispersion is />/tolerated. In the case of overdispersion, it is recommended to use />/quasilikelihood, but apparently this solution has been disabled a while />/ago in lme4. />//>/Generalized linear mixed model fit by maximum likelihood (Laplace />/Approximation) ['glmerMod'] />/Family: Gamma ( log ) />/Formula: q1 ~ Treatment + (1 | Elevation) + (1 | Elevation:Plot) />/Data: dat />/Control: glmerControl(optimizer = "nlminbw") />//>/AIC BIC logLik deviance df.resid />/1523.6 1547.9 -754.8 1509.6 231 />//>/Scaled residuals: />/Min 1Q Median 3Q Max />/-2.0938 -0.6378 -0.0694 0.5815 3.1634 />//>/Random effects: />/Groups Name Variance Std.Dev. />/Elevation:Plot (Intercept) 0.02632 0.1622 />/Elevation (Intercept) 0.01366 0.1169 />/Residual 0.17924 0.4234 />/Number of obs: 238, groups: Elevation:Plot, 47; Elevation, 3 />//>/Fixed effects: />/Estimate Std. Error t value Pr(>|z|) />/(Intercept) 2.63742 0.16504 15.981 <2e-16 *** />/TreatmentN -0.08395 0.13284 -0.632 0.527 />/TreatmentNP -0.15163 0.12964 -1.170 0.242 />/TreatmentP -0.12925 0.12998 -0.994 0.320 />/--- />/Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 />//>/Correlation of Fixed Effects: />/(Intr) TrtmnN TrtmNP />/TreatmentN -0.412 />/TreatmentNP -0.418 0.522 />/TreatmentP -0.417 0.524 0.535 />//>//>/chisq ratio rdf p />/38.4696552 0.1658175 232.0000000 1.0000000 />//>//>/My concrete questions are: Should I be concerned that my model is />/underdispersed? Will the coeficients of the fixed terms be reliable in />/this scenario? />//>//>/I appreciate any help on this regard. />//>//>/Best regards, />//>/Juan F. Due?as />//>/_______________________________________________ />/R-sig-mixed-models at r-project.org 
> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models> mailing list />/https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models /
/


From pgreenw1 at gmu.edu  Wed Jan 24 14:02:26 2018
From: pgreenw1 at gmu.edu (P Greenwood)
Date: Wed, 24 Jan 2018 08:02:26 -0500
Subject: [R-sig-ME] subjects within groups and effects of group
In-Reply-To: <B9A8DD23-7CFB-4380-A6C0-22E35F661F6E@gmu.edu>
References: <CC4B04FD-6934-4E94-B9A6-8E7AA8FBA33A@gmu.edu>
 <CAJuCY5xjL6wb5MxQs=MMum9BcqK-2QD6YNuythpa0a23uknT6g@mail.gmail.com>
 <99620d09-4dd7-5dac-e46e-4eb205be9cf7@mpi.nl>
 <B9A8DD23-7CFB-4380-A6C0-22E35F661F6E@gmu.edu>
Message-ID: <CB5DAA4D-57A8-45C5-948B-336B235350BF@gmu.edu>

Dear Drs Alday and Onkelinx

I wondered if you had thoughts on the best way to conduct followup analysis of the between-subjects Condition to which people were randomly assigned.

Pam Greenwood

P.M. Greenwood, Ph.D.
Associate Professor of Psychology
Editorial Board, NeuroImage
David King Hall 2052
George Mason University
MSN 3F5, 4400 University Drive
Fairfax, VA 22030-4444

Ph: 703 993-4268
fax: 703 993-1359
email: Pgreenw1 at gmu.edu
http://psychology.gmu.edu/people/pgreenw1

> On Jan 19, 2018, at 8:09 AM, P Greenwood <pgreenw1 at gmu.edu> wrote:
> 
> Thanks to you both.
> 
> Trial refers to stimulus events.  The stimuli are the same on each Trial, although the order of the Trials varies between Drives.   But, yes, Trial is a sequence number for the repetition so that there could be some adaptation or change in response related to number of exposures.  (Assuming that is what you meant).  How would I include Trial as a continuous fixed effect?
> 
> If the effect of Condition were ?significant.? how would one decompose that to examine each group (Condition) separately?
> 
> Regards
> 
> Pam
> 
> 
> P.M. Greenwood, Ph.D.
> Associate Professor of Psychology
> Editorial Board, NeuroImage
> David King Hall 2052
> George Mason University
> MSN 3F5, 4400 University Drive
> Fairfax, VA 22030-4444
> 
> Ph: 703 993-4268
> fax: 703 993-1359
> email: Pgreenw1 at gmu.edu <mailto:Pgreenw1 at gmu.edu>
> http://psychology.gmu.edu/people/pgreenw1 <http://psychology.gmu.edu/people/pgreenw1>
>> On Jan 19, 2018, at 5:58 AM, Phillip Alday <phillip.alday at mpi.nl <mailto:phillip.alday at mpi.nl>> wrote:
>> 
>> Dear Pam, (dear Thierry,)
>> 
>> if I'm reading the description correctly, Pam is conceiving of Trial as
>> being an "Item"-type factor (crossed with subject). To rephrase
>> Thierry's comment a bit -- if Trial corresponds to an Item (concrete
>> stimulus realization sampled from the population of possible stimuli for
>> this manipulation) that is the same across subjects, then this is a good
>> way to model that. If Trial doesn't correspond to an invariant set of
>> items, but is rather just repetitions of the same task (perhaps with
>> some random variation that isn't identical across subjects), then
>> modeling Trial as a random effect doesn't really help much. However, if
>> Trial is just a sequence number for the repetition, it might make sense
>> to instead include Trial as a continuous fixed effect in order to model
>> adaptation effects.
>> 
>> Best,
>> Phillip
>> 
>> On 19/01/18 10:44, Thierry Onkelinx wrote:
>>> Dear Pam,
>>> 
>>> You are handling condition and subject correctly.
>>> 
>>> There might be a problem with trial. Does trial indicates dependent
>>> replication of the study? Is there a common effect of trial X for all
>>> subjects? Because that is what your current model assumes. In case the
>>> trials are independent, then you don't need to include it in the
>>> model.
>>> 
>>> Note that Condition + PzAlpha + PzAlpha*Condition is verbose. You can
>>> write it as PzAlpha*Condition.
>>> 
>>> Best regards,
>>> 
>>> ir. Thierry Onkelinx
>>> Statisticus / Statistician
>>> 
>>> Vlaamse Overheid / Government of Flanders
>>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
>>> AND FOREST
>>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
>>> thierry.onkelinx at inbo.be <mailto:thierry.onkelinx at inbo.be>
>>> Havenlaan 88 bus 73, 1000 Brussel
>>> www.inbo.be
>>> 
>>> ///////////////////////////////////////////////////////////////////////////////////////////
>>> To call in the statistician after the experiment is done may be no
>>> more than asking him to perform a post-mortem examination: he may be
>>> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
>>> The plural of anecdote is not data. ~ Roger Brinner
>>> The combination of some data and an aching desire for an answer does
>>> not ensure that a reasonable answer can be extracted from a given body
>>> of data. ~ John Tukey
>>> ///////////////////////////////////////////////////////////////////////////////////////////
>>> 
>>> 
>>> 
>>> 
>>> 2018-01-18 18:51 GMT+01:00 P Greenwood <pgreenw1 at gmu.edu>:
>>>> Hello
>>>> 
>>>> I wanted some advice about handling subjects within groups and effects of group (randomly assigned).  I want to predict reaction time (RT) as a function of  ?Condition,?  alpha band power (PzAlpha), and drive. People (subjects) are randomly assigned to Condition, of which there are two. Each person has data from 5 drives, and for each drive there are 10 trials.  There are 19 subjects in one group and 20 in the other.
>>>> 
>>>> My question is this: Am I handling the ?between subjects? factor of Condition correctly?  Also, am I treating subjects within group correctly?  I am pasting in some of my data.  The output is below.
>>>> 
>>>> Regards
>>>> 
>>>> Pam Greenwood
>>>> 
>>>> library(lme4)
>>>> library(lmerTest)
>>>> INFAST_Behavioral <- read.csv(??.
>>>> na.omit(INFAST_Behavioral)
>>>> INFAST_Behavioral$RT = scale(INFAST_Behavioral$RT, center = TRUE, scale = TRUE)
>>>> INFAST_Behavioral$PzAlpha = scale(INFAST_Behavioral$PzAlpha, center = TRUE, scale = TRUE)
>>>> sumModelInteraction <- lmer(RT ~ 1 + (Condition + PzAlpha + Drive + PzAlpha*Condition) + (1 | subject) + (1 | trial), data = INFAST_Behavioral)
>>>> summary(sumModelInteraction)
>>>> 
>>>> subject Condition               Drive           trial   FzAlpha CzAlpha PzAlpha FzTheta CzTheta PzTheta FzDelta CzDelta PzDelta         RT      ACC
>>>> 1       HumanLanguage   1       1       -1.41   -4.3585 -5.5431 6.1516  1.5911  3.6247  22.38   18.181 13.812          1568.984857     1
>>>> 1       HumanLanguage   1       2       -7.8605 2.0156  4.7392  15.992  12.122  6.9088  26.861 20.592  16.326  1721.359714     1
>>>> 1       HumanLanguage   1       3       -2.6982 -5.6067 -10.038 6.285   5.5172  1.2894  13.565 12.981  11.63   1257.092571     1
>>>> 1       HumanLanguage   1       4       3.3975  4.8789  -1.3249 7.0177  9.6703  6.1539  10.231 12.261  12.485  1559.461429     1
>>>> ?(skipping to Subject 2)
>>>> 2       HumanLanguage                   1       1       1.6791  2.8887  0.28174 -11.387 -9.9352 3.5936 -1.5767 3.9401  6.7201          1302.328857     1
>>>> 2       HumanLanguage   1       2       -13.284 -8.2603 -6.6124 -5.9373 -8.7551 0.10394 4.5621 10.204  12.261  969.0088571     1
>>>> 2       HumanLanguage   1       3       -0.048973       1.1329  0.67399 -2.1432 2.5077  -2.4641 9.4667 10.883  7.1396  721.3997143     1
>>>> 2       HumanLanguage   1       4       5.0779  6.8916  6.3892  -1.8682 3.1637  7.9712  8.0994 10.883  10.975  707.1145714     1
>>>> 2       HumanLanguage   1       5       -7.0495 -2.782  3.1668  8.4332  10.646  9.3726  -3.5937 -7.3769 5.4472  892.8214286     1
>>>> 2       HumanLanguage   1       6       -1.462  -8.1223 -6.5896 -10.895 -5.6311 0.39941 7.5473 12.783  14.698  611.8802857     1
>>>> 2       HumanLanguage   1       7       -2.6402 -5.1213 -3.7372 3.4542  4.2234  -0.99898        1.4089 4.1976  0.56587 761.8742857     1
>>>> 2       HumanLanguage   1       8       3.4393  4.6302  1.5525  1.4604  3.1716  3.1622  -2.3427 2.908 4.2259  680.9251429     1
>>>> 2       HumanLanguage   1       9       -0.81024        -0.21642        -2.3876 2.5839  4.7307  1.5441 3.3761  8.4485  12.02   769.0168571     1
>>>> 2       HumanLanguage   1       10      -6.4045 -4.4937 -2.2449 0.94456 2.7048  0.65565 -1.9791 0.26436 1.8435  885.6788571     1
>>>> 
>>>> Results:
>>>> 
>>>> Linear mixed model fit by REML t-tests use Satterthwaite approximations to degrees of freedom [
>>>> lmerMod]
>>>> Formula: RT ~ 1 + (Condition + PzAlpha + Drive + PzAlpha * Condition) +
>>>>    (1 | subject) + (1 | trial)
>>>>   Data: INFAST_Behavioral
>>>> 
>>>> REML criterion at convergence: 3876.4
>>>> 
>>>> Scaled residuals:
>>>>    Min      1Q  Median      3Q     Max
>>>> -3.4308 -0.5227 -0.1194  0.3547  8.4095
>>>> 
>>>> Random effects:
>>>> Groups   Name        Variance Std.Dev.
>>>> subject  (Intercept) 0.580073 0.76163
>>>> trial    (Intercept) 0.004778 0.06912
>>>> Residual             0.434918 0.65948
>>>> Number of obs: 1839, groups:  subject, 39; trial, 10
>>>> 
>>>> Fixed effects:
>>>>                                         Estimate               Std. Error         df t value Pr(>|t|)
>>>> (Intercept)                        -0.27054    0.17607   40.80000  -1.537  0.13213
>>>> ConditionMachineLang 0.41644    0.24595   36.90000   1.693  0.09884 .
>>>> PzAlpha                             0.01192    0.02411 1797.40000   0.494  0.62117
>>>> Drive                               0.02948    0.01083 1788.40000   2.722  0.00655 **
>>>> ConditionMachineLanguage:PzAlpha   -0.01998    0.03476 1803.10000  -0.575  0.56560
>>>> ---
>>>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>>> P.M. Greenwood, Ph.D.
>>>> Associate Professor of Psychology
>>>> Editorial Board, NeuroImage
>>>> David King Hall 2052
>>>> George Mason University
>>>> MSN 3F5, 4400 University Drive
>>>> Fairfax, VA 22030-4444
>>>> 
>>>> Ph: 703 993-4268
>>>> fax: 703 993-1359
>>>> email: Pgreenw1 at gmu.edu
>>>> http://psychology.gmu.edu/people/pgreenw1
>>>> 
>>>> 
>>>>        [[alternative HTML version deleted]]
>>>> 
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://secure-web.cisco.com/1joP--B1_xWT50x7mVQZsmihBAOqrRroakmdBR5MIMiOARC9Fd1hE1yw-1sCnwGxdnwBghNSYF9p3BRdhCaL0o-KBtN4F3VSOMBOaVY1oHIj6WYPh_sr8e-zRksQa9F4ECA_XGS2Afp73TF2WsPYwPhZh0vxQMs_BOy--csyKCdriarDzsvIs-lPMcfSch2Ym2oCTwBXQ_YkEWQehip65TFdXUagB8dg1r-d1G0r841y-84pF20_DPQ6J18R57bYFsQp5D34gsd2C2Jf6WMFXlHUZLbGyg7TV0F8CEvUF6vNcNdjIJTUSz79up7bz_iYDKOezABzwahOdHoC45jHqvTmDYhjaqzCkPsymio7HL4h8UlFKyj0xzrIe3rEFvRQsMaNQdctVCMacfdjj-nJiV9Ab0-aVDdezvOlj8IwbPCwr9QwTBeZzUqOwf5ENxq1r/https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models <https://secure-web.cisco.com/1joP--B1_xWT50x7mVQZsmihBAOqrRroakmdBR5MIMiOARC9Fd1hE1yw-1sCnwGxdnwBghNSYF9p3BRdhCaL0o-KBtN4F3VSOMBOaVY1oHIj6WYPh_sr8e-zRksQa9F4ECA_XGS2Afp73TF2WsPYwPhZh0vxQMs_BOy--csyKCdriarDzsvIs-lPMcfSch2Ym2oCTwBXQ_YkEWQehip65TFdXUagB8dg1r-d1G0r841y-84pF20_DPQ6J18R57bYFsQp5D34gsd2C2Jf6WMFXlHUZLbGyg7TV0F8CEvUF6vNcNdjIJTUSz79up7bz_iYDKOezABzwahOdHoC45jHqvTmDYhjaqzCkPsymio7HL4h8UlFKyj0xzrIe3rEFvRQsMaNQdctVCMacfdjj-nJiV9Ab0-aVDdezvOlj8IwbPCwr9QwTBeZzUqOwf5ENxq1r/https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models>
>>> 
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org <mailto:R-sig-mixed-models at r-project.org> mailing list
>>> https://secure-web.cisco.com/1joP--B1_xWT50x7mVQZsmihBAOqrRroakmdBR5MIMiOARC9Fd1hE1yw-1sCnwGxdnwBghNSYF9p3BRdhCaL0o-KBtN4F3VSOMBOaVY1oHIj6WYPh_sr8e-zRksQa9F4ECA_XGS2Afp73TF2WsPYwPhZh0vxQMs_BOy--csyKCdriarDzsvIs-lPMcfSch2Ym2oCTwBXQ_YkEWQehip65TFdXUagB8dg1r-d1G0r841y-84pF20_DPQ6J18R57bYFsQp5D34gsd2C2Jf6WMFXlHUZLbGyg7TV0F8CEvUF6vNcNdjIJTUSz79up7bz_iYDKOezABzwahOdHoC45jHqvTmDYhjaqzCkPsymio7HL4h8UlFKyj0xzrIe3rEFvRQsMaNQdctVCMacfdjj-nJiV9Ab0-aVDdezvOlj8IwbPCwr9QwTBeZzUqOwf5ENxq1r/https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models <https://secure-web.cisco.com/1joP--B1_xWT50x7mVQZsmihBAOqrRroakmdBR5MIMiOARC9Fd1hE1yw-1sCnwGxdnwBghNSYF9p3BRdhCaL0o-KBtN4F3VSOMBOaVY1oHIj6WYPh_sr8e-zRksQa9F4ECA_XGS2Afp73TF2WsPYwPhZh0vxQMs_BOy--csyKCdriarDzsvIs-lPMcfSch2Ym2oCTwBXQ_YkEWQehip65TFdXUagB8dg1r-d1G0r841y-84pF20_DPQ6J18R57bYFsQp5D34gsd2C2Jf6WMFXlHUZLbGyg7TV0F8CEvUF6vNcNdjIJTUSz79up7bz_iYDKOezABzwahOdHoC45jHqvTmDYhjaqzCkPsymio7HL4h8UlFKyj0xzrIe3rEFvRQsMaNQdctVCMacfdjj-nJiV9Ab0-aVDdezvOlj8IwbPCwr9QwTBeZzUqOwf5ENxq1r/https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models>


	[[alternative HTML version deleted]]


From melanie.lindner at helsinki.fi  Wed Jan 24 19:02:27 2018
From: melanie.lindner at helsinki.fi (Lindner, Melanie)
Date: Wed, 24 Jan 2018 18:02:27 +0000
Subject: [R-sig-ME] residual variance estimates fixed to 1
Message-ID: <85B56551-A631-4FAB-B696-1068DB85D8A8@ad.helsinki.fi>

Hi again,

I use lme4 to model methylation count data. I specify my response as cbind(methylation count, unmethylation count) and use the argument family=binomial.
In my data set I have count information for 500,000 CpG sites over 64 samples (so, each sample contains count information for all 500,000 sites). 32 per treatment group. I model each site separately to see if there is a significant difference between the treatments and therefore use a loop. Since I cannot look at the summary of each site, I saved different estimates from the loop and recognised that the residual standard deviation is always 1. To evaluate the model fit, I would like to understand why the residual variance is fixed to one. It would be great if someone can tell me where to find information on that.

Thanks in advance,
Melanie



	[[alternative HTML version deleted]]


From jake.a.westfall at gmail.com  Wed Jan 24 23:41:01 2018
From: jake.a.westfall at gmail.com (Jake Westfall)
Date: Wed, 24 Jan 2018 16:41:01 -0600
Subject: [R-sig-ME] residual variance estimates fixed to 1
In-Reply-To: <85B56551-A631-4FAB-B696-1068DB85D8A8@ad.helsinki.fi>
References: <85B56551-A631-4FAB-B696-1068DB85D8A8@ad.helsinki.fi>
Message-ID: <CAE9_Wg7d_fH9_ihS9oqqKGzWgWP=CniXJPV3fE9spCB8udKAkA@mail.gmail.com>

Hi Melanie,

As far as I know, lmer never fixes the residual variance to 1 or any other
value, and in fact this isn't even possible to do with lmer (at least not
without resorting to add-on packages). My guess is that in your loop you
accidentally grabbed the wrong field, not the variable giving the residual
variance estimate. If you give us a sample of the code you used, we could
help figure out what happened.

Jake

On Wed, Jan 24, 2018 at 12:02 PM, Lindner, Melanie <
melanie.lindner at helsinki.fi> wrote:

> Hi again,
>
> I use lme4 to model methylation count data. I specify my response as
> cbind(methylation count, unmethylation count) and use the argument
> family=binomial.
> In my data set I have count information for 500,000 CpG sites over 64
> samples (so, each sample contains count information for all 500,000 sites).
> 32 per treatment group. I model each site separately to see if there is a
> significant difference between the treatments and therefore use a loop.
> Since I cannot look at the summary of each site, I saved different
> estimates from the loop and recognised that the residual standard deviation
> is always 1. To evaluate the model fit, I would like to understand why the
> residual variance is fixed to one. It would be great if someone can tell me
> where to find information on that.
>
> Thanks in advance,
> Melanie
>
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From wolfgang.viechtbauer at maastrichtuniversity.nl  Thu Jan 25 00:02:48 2018
From: wolfgang.viechtbauer at maastrichtuniversity.nl (Viechtbauer Wolfgang (SP))
Date: Wed, 24 Jan 2018 23:02:48 +0000
Subject: [R-sig-ME] residual variance estimates fixed to 1
In-Reply-To: <CAE9_Wg7d_fH9_ihS9oqqKGzWgWP=CniXJPV3fE9spCB8udKAkA@mail.gmail.com>
References: <85B56551-A631-4FAB-B696-1068DB85D8A8@ad.helsinki.fi>
 <CAE9_Wg7d_fH9_ihS9oqqKGzWgWP=CniXJPV3fE9spCB8udKAkA@mail.gmail.com>
Message-ID: <9beef66e74eb4defb9cced8ab615b899@UM-MAIL3214.unimaas.nl>

For glmer() with family=binomial, there is no 'residual variance'. If you use sigma() to extract it, it will always return 1.

Best,
Wolfgang

>-----Original Message-----
>From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-
>project.org] On Behalf Of Jake Westfall
>Sent: Wednesday, 24 January, 2018 23:41
>To: Lindner, Melanie
>Cc: r-sig-mixed-models at r-project.org
>Subject: Re: [R-sig-ME] residual variance estimates fixed to 1
>
>Hi Melanie,
>
>As far as I know, lmer never fixes the residual variance to 1 or any
>other
>value, and in fact this isn't even possible to do with lmer (at least not
>without resorting to add-on packages). My guess is that in your loop you
>accidentally grabbed the wrong field, not the variable giving the
>residual
>variance estimate. If you give us a sample of the code you used, we could
>help figure out what happened.
>
>Jake
>
>On Wed, Jan 24, 2018 at 12:02 PM, Lindner, Melanie <
>melanie.lindner at helsinki.fi> wrote:
>
>> Hi again,
>>
>> I use lme4 to model methylation count data. I specify my response as
>> cbind(methylation count, unmethylation count) and use the argument
>> family=binomial.
>> In my data set I have count information for 500,000 CpG sites over 64
>> samples (so, each sample contains count information for all 500,000
>sites).
>> 32 per treatment group. I model each site separately to see if there is
>a
>> significant difference between the treatments and therefore use a loop.
>> Since I cannot look at the summary of each site, I saved different
>> estimates from the loop and recognised that the residual standard
>deviation
>> is always 1. To evaluate the model fit, I would like to understand why
>the
>> residual variance is fixed to one. It would be great if someone can
>tell me
>> where to find information on that.
>>
>> Thanks in advance,
>> Melanie


From jake.a.westfall at gmail.com  Thu Jan 25 03:29:43 2018
From: jake.a.westfall at gmail.com (Jake Westfall)
Date: Wed, 24 Jan 2018 20:29:43 -0600
Subject: [R-sig-ME] residual variance estimates fixed to 1
In-Reply-To: <9beef66e74eb4defb9cced8ab615b899@UM-MAIL3214.unimaas.nl>
References: <85B56551-A631-4FAB-B696-1068DB85D8A8@ad.helsinki.fi>
 <CAE9_Wg7d_fH9_ihS9oqqKGzWgWP=CniXJPV3fE9spCB8udKAkA@mail.gmail.com>
 <9beef66e74eb4defb9cced8ab615b899@UM-MAIL3214.unimaas.nl>
Message-ID: <CAE9_Wg7XtwmAnVgnWQc=hNMXG=618f=g=JdwtnN0UUR506Yk7w@mail.gmail.com>

Ah, I missed the detail about family=binomial. That is definitely what's
going on.

Jake

On Wed, Jan 24, 2018 at 5:02 PM, Viechtbauer Wolfgang (SP) <
wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:

> For glmer() with family=binomial, there is no 'residual variance'. If you
> use sigma() to extract it, it will always return 1.
>
> Best,
> Wolfgang
>
> >-----Original Message-----
> >From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-
> >project.org] On Behalf Of Jake Westfall
> >Sent: Wednesday, 24 January, 2018 23:41
> >To: Lindner, Melanie
> >Cc: r-sig-mixed-models at r-project.org
> >Subject: Re: [R-sig-ME] residual variance estimates fixed to 1
> >
> >Hi Melanie,
> >
> >As far as I know, lmer never fixes the residual variance to 1 or any
> >other
> >value, and in fact this isn't even possible to do with lmer (at least not
> >without resorting to add-on packages). My guess is that in your loop you
> >accidentally grabbed the wrong field, not the variable giving the
> >residual
> >variance estimate. If you give us a sample of the code you used, we could
> >help figure out what happened.
> >
> >Jake
> >
> >On Wed, Jan 24, 2018 at 12:02 PM, Lindner, Melanie <
> >melanie.lindner at helsinki.fi> wrote:
> >
> >> Hi again,
> >>
> >> I use lme4 to model methylation count data. I specify my response as
> >> cbind(methylation count, unmethylation count) and use the argument
> >> family=binomial.
> >> In my data set I have count information for 500,000 CpG sites over 64
> >> samples (so, each sample contains count information for all 500,000
> >sites).
> >> 32 per treatment group. I model each site separately to see if there is
> >a
> >> significant difference between the treatments and therefore use a loop.
> >> Since I cannot look at the summary of each site, I saved different
> >> estimates from the loop and recognised that the residual standard
> >deviation
> >> is always 1. To evaluate the model fit, I would like to understand why
> >the
> >> residual variance is fixed to one. It would be great if someone can
> >tell me
> >> where to find information on that.
> >>
> >> Thanks in advance,
> >> Melanie
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From jorge.cueva at tum.de  Thu Jan 25 15:09:33 2018
From: jorge.cueva at tum.de (Cueva, Jorge)
Date: Thu, 25 Jan 2018 14:09:33 +0000
Subject: [R-sig-ME] glmmPQL: random effects
Message-ID: <e25ff30d936845ba85e558500202893f@tum.de>

Hello everyone,

I am working with glmmPQL because have data count (richness and number of individuals), in both cases have mean >5 and overdispersion. The literature says is necessary to distinct between ML (for random effects) and REML (fixed effects), but I got one error even with the nlme package active:

Error in ML(x = c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,  :
  could not find function "ML"

I am using:

glmmPQL(Spp~1+Cattle+Equine+Mth.Prec,random = list(~1|Formation,~1|Cluster),data = VariabRLplot, family = "quasipoisson", method="ML")

If I not use  --method="ML"--   the model runs without warnings

The questions are:

  1.  Can I distinct between "ML" and "REML" using glmmPQL? Or I must use some function like lme or lmer and later pass to glmmPQL
  2.  By other hand, with the random effects, "Cluster" is nested in "Formation", the syntax should be right, but I am not 100% sure.

Thanks so much

Jorge Cueva Ortiz
Ing. Forestal
ECU: 0993085161
GER: 0049 1631327886


	[[alternative HTML version deleted]]


From rune.haubo at gmail.com  Thu Jan 25 15:21:10 2018
From: rune.haubo at gmail.com (Rune Haubo)
Date: Thu, 25 Jan 2018 15:21:10 +0100
Subject: [R-sig-ME] Df for 'random-intercept-only' model
In-Reply-To: <CAHr4Dyd0vr-LQcdmwq6A+pHcbJUcS+uFGC_SV6_vDKTgqqQRLg@mail.gmail.com>
References: <CAHr4Dyd0vr-LQcdmwq6A+pHcbJUcS+uFGC_SV6_vDKTgqqQRLg@mail.gmail.com>
Message-ID: <CAG_uk93cXhnWMKyMKafhjUh1m6NRBp_iOOGdzBLYN0bh7LfijQ@mail.gmail.com>

Hi Maarten,

This is fixed in the development version of lmerTest on GitHub - you
may install with

library("devtools") # install if you don't have it already.
install_github("runehaubo/lmerTest?)

Furture bug-reports are also welcome here.

For your example data I get:

Linear mixed model fit by REML t-tests use Satterthwaite
approximations to degrees of
  freedom [merModLmerTest]
Formula: value ~ 1 + (1 | participant)
   Data: d

REML criterion at convergence: 430.6

Scaled residuals:
     Min       1Q   Median       3Q      Max
-1.95994 -0.51445  0.09534  0.47149  2.28058

Random effects:
 Groups      Name        Variance Std.Dev.
 participant (Intercept) 4.714    2.171
 Residual                1.945    1.395
Number of obs: 100, groups:  participant, 47

Fixed effects:
            Estimate Std. Error      df t value Pr(>|t|)
(Intercept)  15.0660     0.3529 44.6400   42.69   <2e-16 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1


Best regards
Rune (for the lmerTest developers)


On 20 January 2018 at 15:13, Maarten Jung
<Maarten.Jung at mailbox.tu-dresden.de> wrote:
> Dear list,
>
> I'm trying to get an estimate for the degrees of freedom of the following
> 'random-intercept-only' model: lmer(value ~ 1 + (1|participant), data = d).
> Normally, I know that one can achieve this via the lmerTest package but in
> this case it doesn't seem to work.
>
> library(lmerTest)
>
> d <- structure(list(value = c(8.25313070764297, 17.0453980104411,
> 14.7103370498893, 15.8219809684075, 18.0962761595002, 15.0493332821287,
> 17.5226332786703, 18.0503969664744, 13.9450638512715, 16.5332566133129,
> 13.1299408088999, 15.7163333693101, 17.5128147209307, 13.8564235534667,
> 11.3690970113334, 11.458250790531, 12.4039353096013, 16.9168322671145,
> 14.5580055004946, 17.5039029057499, 17.4265303119576, 10.3394971583312,
> 14.3327437896945, 10.1075784647337, 13.5324234318869, 12.9997105711724,
> 18.0080570272635, 15.2842579562302, 15.2356443644651, 15.813831547332,
> 14.8905281019859, 12.9039538908697, 17.3783863341884, 16.0160603506154,
> 18.4540620620647, 8.68750928534364, 14.462724834603, 16.8719660771132,
> 16.3784470438622, 16.228431742704, 17.2260499546157, 14.4592109398455,
> 12.9768791191779, 16.0745074082946, 14.4003729683924, 18.3820335802969,
> 13.8298449655042, 13.3898039860578, 11.2943669087644, 11.3711693435468,
> 18.1917812063674, 13.5455973955032, 17.0505866395927, 15.6054278307471,
> 12.1163489978806, 16.5776960925959, 15.5595289759737, 13.1383036025308,
> 16.7858376357516, 18.5934575849391, 12.6122831749272, 17.0565311301485,
> 13.2374564449912, 15.6139433555906, 14.6293717224923, 17.3818235894563,
> 15.7412428493826, 22.1877337982038, 18.3842887975238, 10.0701573038888,
> 10.8804812404375, 11.7148149325827, 14.4690669558257, 14.50516878681,
> 17.9920135587834, 19.6609636797189, 14.3073652841217, 16.4785695045202,
> 12.6811309533188, 14.6032532299404, 12.3152507852885, 18.1340692925595,
> 15.4724734122014, 17.406638598528, 12.2625532078185, 11.8729946785576,
> 15.9063789963309, 15.8208702113247, 12.203938368013, 14.894840829895,
> 15.5397556234126, 17.0641047610171, 18.3147667118571, 16.3914422509424,
> 14.5539887230189, 15.2870912573834, 17.0165733030807, 16.5537600282835,
> 12.1300522052001, 18.291737264292), participant = structure(c(15L,
> 3L, 6L, 6L, 11L, 57L, 43L, 10L, 16L, 49L, 54L, 11L, 22L, 24L, 41L, 48L,
> 35L, 46L, 59L, 23L, 55L, 41L, 39L, 15L, 60L, 52L, 5L,
> 48L, 33L, 50L, 2L, 53L, 11L, 47L, 19L, 15L, 60L, 22L, 31L, 21L, 11L, 59L,
> 24L, 50L, 20L, 5L, 14L, 3L, 39L, 18L, 9L, 33L, 46L,
> 49L, 38L, 19L, 33L, 46L, 45L, 22L, 14L, 10L, 4L, 33L, 44L, 43L, 47L, 13L,
> 22L, 42L, 35L, 38L, 40L, 33L, 10L, 2L, 55L, 40L, 48L,
> 57L, 41L, 16L, 2L, 8L, 48L, 47L, 30L, 7L, 48L, 6L, 44L, 9L, 22L, 9L, 56L,
> 40L, 6L, 59L, 3L, 26L), .Label = c("1", "2", "3", "4",
> "5", "6", "7", "8", "9", "10", "11", "12", "13", "14", "15", "16", "17",
> "18", "19", "20", "21", "22", "23", "24", "25", "26",
> "27", "28", "29", "30", "31", "32", "33", "34", "35", "36", "37", "38",
> "39", "40", "41", "42", "43", "44", "45", "46", "47", "48",
> "49", "50", "51", "52", "53", "54", "55", "56", "57", "58", "59", "60"),
> class = "factor")), .Names = c("value", "participant"), row.names = c(NA,
> -100L), class = c("tbl_df", "tbl", "data.frame"))
>
> summary(m1 <- lmer(value ~ 1 + (1|participant), data = d))
>
> Running this code returns "summary from lme4 is returned. some
> computational error has occurred in lmerTest".
>
>
> Thanks a lot for any help!
>
>
> Best,
>
> Maarten
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From Maarten.Jung at mailbox.tu-dresden.de  Thu Jan 25 15:35:06 2018
From: Maarten.Jung at mailbox.tu-dresden.de (Maarten Jung)
Date: Thu, 25 Jan 2018 15:35:06 +0100
Subject: [R-sig-ME] Specifying the correct LMM for 'unsual' data
Message-ID: <CAHr4DyewQMU0gFTD9cWAWMO0kOEnHjn7SLQCZEcYf+ucKKKX2g@mail.gmail.com>

Dear list,

a colleague of mine asked me to help her planing a linear mixed models
analysis and, as handling her data and the corresponding research questions
with lmer seems kind of tricky to me, I hope one of you can help me along.

+++++++++++++++++++++++++++++++++++++
The experiment is as follows:

Participants (46 younger and 45 older children) looked at a series of
pictures (one picture per trial) and had to solve two tasks consecutively:

- Task block 1: Prospective memory (PM) task: while doing other tasks,
participants had to remember to press a specified button when they saw a
certain object
- Task block 2. Visual search: participants had only this one task ?
pressing a button as soon as possible when seeing a certain object

Each child saw the same pictures in the same task block ? pictures 1-6 in
task block 1 and pictures 7-18 in task block 2. Each picture was presented
only once, so there were different pictures in the task blocks.

Trials with target object in task 1 are allocated regarding the
participant?s reactions in PM hits (participants did press the button) and
PM misses (participants did not press the button). (Therefore, a certain
picture can be a PM hit trial for one child and a PM miss trial for the
other.) As there were six trials (= pictures), which contained the target
object, each participant can have a minimum of zero and a maximum of six PM
hits with the according number of PM misses.
Here is the number of PM hits per age group:

Younger children:
- 2 children: 0 hits
- 9 children: 1 hit
- 8 children : 2 hits
- 12 children: 3 hits
- 4 children: 4 hits
- 4 children: 5 hits
- 7 children: 6 hits

Older children
- 2 children: 0 hits
- 3 children: 1 hit
- 4 children: 2 hits
- 6 children: 3 hits
- 7 children: 4 hits
- 11 children: 5 hits
- 12 children: 6 hits

(In the visual search task almost all children have pressed the button
correctly in all 12 visual search target trials).

She is interested in how long participants looked at the PM and visual
search target, respectively, depending on if it was a PM hit, a PM miss or
a visual search hit and how this is influenced by the age group. Therefore,
she has got only one data point per trial. And if a participant has no PM
misses there is no data point at all in this condition for this participant.

The variables are defined as follows:
- age_group: categorical predictor with 2 levels (younger and older
children)
- condition: categorical predictor with 3 levels (PM hit, PM miss, visual
search hit)
+++++++++++++++++++++++++++++++++++++

My suggestion for the maximal linear mixed model would be:

lmer(dwell_time ~ age_group*condition + (1 + condition|participant) +
(1|picture), data)

I intentionally didn`t use (1 + condition|picture) here because there are
different pictures in the task blocks (see above) - hope this makes sense.

I have two questions:
1. Am I correct with the maximal linear mixed model specifications?
2. I think that the data points in the PM-miss-condition (or
PM-hit-condition) are not missing at random because they are missing if
(and only if) there are 6 data point for the same participant in the
PM-hit-condition (and vice versa). Do you think one has to worry about this
and are there any suggestions how to deal with it?

Best,
Maarten

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Thu Jan 25 16:01:21 2018
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 25 Jan 2018 10:01:21 -0500
Subject: [R-sig-ME] glmmPQL: random effects
In-Reply-To: <e25ff30d936845ba85e558500202893f@tum.de>
References: <e25ff30d936845ba85e558500202893f@tum.de>
Message-ID: <4d2e13b0-292e-c56a-e342-24a02c2343b2@gmail.com>


  This is a good question - surprised I haven't seen it before.

  The general answer to your question is that people don't generally
worry about REML vs ML for generalized mixed models:

http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#reml-for-glmms

  The proximal answer is that glmmPQL is a hybrid between lme and glm.
When you specify a method= argument, glmmPQL tries to pass it to the glm
function, which is expecting a function name. (i.e., "don't do this, it
doesn't work")


On 18-01-25 09:09 AM, Cueva, Jorge wrote:
> Hello everyone,
> 
> I am working with glmmPQL because have data count (richness and number of individuals), in both cases have mean >5 and overdispersion. The literature says is necessary to distinct between ML (for random effects) and REML (fixed effects), but I got one error even with the nlme package active:
> 
> Error in ML(x = c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,  :
>   could not find function "ML"
> 
> I am using:
> 
> glmmPQL(Spp~1+Cattle+Equine+Mth.Prec,random = list(~1|Formation,~1|Cluster),data = VariabRLplot, family = "quasipoisson", method="ML")
> 
> If I not use  --method="ML"--   the model runs without warnings
> 
> The questions are:
> 
>   1.  Can I distinct between "ML" and "REML" using glmmPQL? Or I must use some function like lme or lmer and later pass to glmmPQL
>   2.  By other hand, with the random effects, "Cluster" is nested in "Formation", the syntax should be right, but I am not 100% sure.
> 
> Thanks so much
> 
> Jorge Cueva Ortiz
> Ing. Forestal
> ECU: 0993085161
> GER: 0049 1631327886
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From tom.fritzsche at uni-potsdam.de  Thu Jan 25 16:08:10 2018
From: tom.fritzsche at uni-potsdam.de (Tom Fritzsche)
Date: Thu, 25 Jan 2018 16:08:10 +0100
Subject: [R-sig-ME] Specifying the correct LMM for 'unsual' data
In-Reply-To: <CAHr4DyewQMU0gFTD9cWAWMO0kOEnHjn7SLQCZEcYf+ucKKKX2g@mail.gmail.com>
References: <CAHr4DyewQMU0gFTD9cWAWMO0kOEnHjn7SLQCZEcYf+ucKKKX2g@mail.gmail.com>
Message-ID: <CAGLQsKcpKXYyHAAUi7jPKStYmSWGohkV2eVwCgLZ6_CCOZ3hXw@mail.gmail.com>

Hi Maarten,

I would not collapse the task and the kind of response (hit/miss) into
one condition predictor. They are conceptually independent as task is
a manipulated factor and response a measured value (covariate in this
model). Also, one of them can vary within pictures the other not (see
model specification below).

So my suggestion would be to have those two predictors:

task: 2-level factor: PM, VS
response: 2-level predictor: hit, miss

Beware of how you specify the contrasts for (all of) the categorical
predictors. The default treatment contrast is most likely not the most
straight-forward way to interpret the model estimates.

Regarding your questions:

1. Am I correct with the maximal linear mixed model specifications?

With the changed predictors I think that this would be the maximal
model. Response can vary also within pictures as each can be a hit or
miss.

lmer(dwell_time ~ age_group * task * response + (1 + task * response |
participant) + (1 + response | picture), data)


2. I think that the data points in the PM-miss-condition (or
PM-hit-condition) are not missing at random because they are missing if
(and only if) there are 6 data point for the same participant in the
PM-hit-condition (and vice versa). Do you think one has to worry about this
and are there any suggestions how to deal with it?

Imbalanced data sets and even missing design cells are not a problem
for mixed models as they take the number of the observation into
account (shrinkage).

Best,
Tom

---

Tom Fritzsche
University of Potsdam
Department of Linguistics
Karl-Liebknecht-Str. 24-25
14476 Potsdam
Germany

office: 14.140
phone: +49 331 977 2296
fax: +49 331 977 2095
e-mail: tom.fritzsche at uni-potsdam.de
web:    www.ling.uni-potsdam.de/~fritzsche



On 25 January 2018 at 15:35, Maarten Jung
<Maarten.Jung at mailbox.tu-dresden.de> wrote:
> Dear list,
>
> a colleague of mine asked me to help her planing a linear mixed models
> analysis and, as handling her data and the corresponding research questions
> with lmer seems kind of tricky to me, I hope one of you can help me along.
>
> +++++++++++++++++++++++++++++++++++++
> The experiment is as follows:
>
> Participants (46 younger and 45 older children) looked at a series of
> pictures (one picture per trial) and had to solve two tasks consecutively:
>
> - Task block 1: Prospective memory (PM) task: while doing other tasks,
> participants had to remember to press a specified button when they saw a
> certain object
> - Task block 2. Visual search: participants had only this one task ?
> pressing a button as soon as possible when seeing a certain object
>
> Each child saw the same pictures in the same task block ? pictures 1-6 in
> task block 1 and pictures 7-18 in task block 2. Each picture was presented
> only once, so there were different pictures in the task blocks.
>
> Trials with target object in task 1 are allocated regarding the
> participant?s reactions in PM hits (participants did press the button) and
> PM misses (participants did not press the button). (Therefore, a certain
> picture can be a PM hit trial for one child and a PM miss trial for the
> other.) As there were six trials (= pictures), which contained the target
> object, each participant can have a minimum of zero and a maximum of six PM
> hits with the according number of PM misses.
> Here is the number of PM hits per age group:
>
> Younger children:
> - 2 children: 0 hits
> - 9 children: 1 hit
> - 8 children : 2 hits
> - 12 children: 3 hits
> - 4 children: 4 hits
> - 4 children: 5 hits
> - 7 children: 6 hits
>
> Older children
> - 2 children: 0 hits
> - 3 children: 1 hit
> - 4 children: 2 hits
> - 6 children: 3 hits
> - 7 children: 4 hits
> - 11 children: 5 hits
> - 12 children: 6 hits
>
> (In the visual search task almost all children have pressed the button
> correctly in all 12 visual search target trials).
>
> She is interested in how long participants looked at the PM and visual
> search target, respectively, depending on if it was a PM hit, a PM miss or
> a visual search hit and how this is influenced by the age group. Therefore,
> she has got only one data point per trial. And if a participant has no PM
> misses there is no data point at all in this condition for this participant.
>
> The variables are defined as follows:
> - age_group: categorical predictor with 2 levels (younger and older
> children)
> - condition: categorical predictor with 3 levels (PM hit, PM miss, visual
> search hit)
> +++++++++++++++++++++++++++++++++++++
>
> My suggestion for the maximal linear mixed model would be:
>
> lmer(dwell_time ~ age_group*condition + (1 + condition|participant) +
> (1|picture), data)
>
> I intentionally didn`t use (1 + condition|picture) here because there are
> different pictures in the task blocks (see above) - hope this makes sense.
>
> I have two questions:
> 1. Am I correct with the maximal linear mixed model specifications?
> 2. I think that the data points in the PM-miss-condition (or
> PM-hit-condition) are not missing at random because they are missing if
> (and only if) there are 6 data point for the same participant in the
> PM-hit-condition (and vice versa). Do you think one has to worry about this
> and are there any suggestions how to deal with it?
>
> Best,
> Maarten
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From thierry.onkelinx at inbo.be  Thu Jan 25 17:33:28 2018
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Thu, 25 Jan 2018 17:33:28 +0100
Subject: [R-sig-ME] subjects within groups and effects of group
In-Reply-To: <CB5DAA4D-57A8-45C5-948B-336B235350BF@gmu.edu>
References: <CC4B04FD-6934-4E94-B9A6-8E7AA8FBA33A@gmu.edu>
 <CAJuCY5xjL6wb5MxQs=MMum9BcqK-2QD6YNuythpa0a23uknT6g@mail.gmail.com>
 <99620d09-4dd7-5dac-e46e-4eb205be9cf7@mpi.nl>
 <B9A8DD23-7CFB-4380-A6C0-22E35F661F6E@gmu.edu>
 <CB5DAA4D-57A8-45C5-948B-336B235350BF@gmu.edu>
Message-ID: <CAJuCY5yPSDBrejqwNV=VO30yS30+1f+rzjDDUikOwE+QF6QoYQ@mail.gmail.com>

Dear Pam,

I'd probably combine both datasets in a single analysis.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
AND FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////




2018-01-24 14:02 GMT+01:00 P Greenwood <pgreenw1 at gmu.edu>:
> Dear Drs Alday and Onkelinx
>
> I wondered if you had thoughts on the best way to conduct followup analysis
> of the between-subjects Condition to which people were randomly assigned.
>
> Pam Greenwood
>
> P.M. Greenwood, Ph.D.
> Associate Professor of Psychology
> Editorial Board, NeuroImage
> David King Hall 2052
> George Mason University
> MSN 3F5, 4400 University Drive
> Fairfax, VA 22030-4444
>
> Ph: 703 993-4268
> fax: 703 993-1359
> email: Pgreenw1 at gmu.edu
> http://psychology.gmu.edu/people/pgreenw1
>
> On Jan 19, 2018, at 8:09 AM, P Greenwood <pgreenw1 at gmu.edu> wrote:
>
> Thanks to you both.
>
> Trial refers to stimulus events.  The stimuli are the same on each Trial,
> although the order of the Trials varies between Drives.   But, yes, Trial is
> a sequence number for the repetition so that there could be some adaptation
> or change in response related to number of exposures.  (Assuming that is
> what you meant).  How would I include Trial as a continuous fixed effect?
>
> If the effect of Condition were ?significant.? how would one decompose that
> to examine each group (Condition) separately?
>
> Regards
>
> Pam
>
>
> P.M. Greenwood, Ph.D.
> Associate Professor of Psychology
> Editorial Board, NeuroImage
> David King Hall 2052
> George Mason University
> MSN 3F5, 4400 University Drive
> Fairfax, VA 22030-4444
>
> Ph: 703 993-4268
> fax: 703 993-1359
> email: Pgreenw1 at gmu.edu
> http://psychology.gmu.edu/people/pgreenw1
>
> On Jan 19, 2018, at 5:58 AM, Phillip Alday <phillip.alday at mpi.nl> wrote:
>
> Dear Pam, (dear Thierry,)
>
> if I'm reading the description correctly, Pam is conceiving of Trial as
> being an "Item"-type factor (crossed with subject). To rephrase
> Thierry's comment a bit -- if Trial corresponds to an Item (concrete
> stimulus realization sampled from the population of possible stimuli for
> this manipulation) that is the same across subjects, then this is a good
> way to model that. If Trial doesn't correspond to an invariant set of
> items, but is rather just repetitions of the same task (perhaps with
> some random variation that isn't identical across subjects), then
> modeling Trial as a random effect doesn't really help much. However, if
> Trial is just a sequence number for the repetition, it might make sense
> to instead include Trial as a continuous fixed effect in order to model
> adaptation effects.
>
> Best,
> Phillip
>
> On 19/01/18 10:44, Thierry Onkelinx wrote:
>
> Dear Pam,
>
> You are handling condition and subject correctly.
>
> There might be a problem with trial. Does trial indicates dependent
> replication of the study? Is there a common effect of trial X for all
> subjects? Because that is what your current model assumes. In case the
> trials are independent, then you don't need to include it in the
> model.
>
> Note that Condition + PzAlpha + PzAlpha*Condition is verbose. You can
> write it as PzAlpha*Condition.
>
> Best regards,
>
> ir. Thierry Onkelinx
> Statisticus / Statistician
>
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
> AND FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Havenlaan 88 bus 73, 1000 Brussel
> www.inbo.be
>
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no
> more than asking him to perform a post-mortem examination: he may be
> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does
> not ensure that a reasonable answer can be extracted from a given body
> of data. ~ John Tukey
> ///////////////////////////////////////////////////////////////////////////////////////////
>
>
>
>
> 2018-01-18 18:51 GMT+01:00 P Greenwood <pgreenw1 at gmu.edu>:
>
> Hello
>
> I wanted some advice about handling subjects within groups and effects of
> group (randomly assigned).  I want to predict reaction time (RT) as a
> function of  ?Condition,?  alpha band power (PzAlpha), and drive. People
> (subjects) are randomly assigned to Condition, of which there are two. Each
> person has data from 5 drives, and for each drive there are 10 trials.
> There are 19 subjects in one group and 20 in the other.
>
> My question is this: Am I handling the ?between subjects? factor of
> Condition correctly?  Also, am I treating subjects within group correctly?
> I am pasting in some of my data.  The output is below.
>
> Regards
>
> Pam Greenwood
>
> library(lme4)
> library(lmerTest)
> INFAST_Behavioral <- read.csv(??.
> na.omit(INFAST_Behavioral)
> INFAST_Behavioral$RT = scale(INFAST_Behavioral$RT, center = TRUE, scale =
> TRUE)
> INFAST_Behavioral$PzAlpha = scale(INFAST_Behavioral$PzAlpha, center = TRUE,
> scale = TRUE)
> sumModelInteraction <- lmer(RT ~ 1 + (Condition + PzAlpha + Drive +
> PzAlpha*Condition) + (1 | subject) + (1 | trial), data = INFAST_Behavioral)
> summary(sumModelInteraction)
>
> subject Condition               Drive           trial   FzAlpha CzAlpha
> PzAlpha FzTheta CzTheta PzTheta FzDelta CzDelta PzDelta         RT      ACC
> 1       HumanLanguage   1       1       -1.41   -4.3585 -5.5431 6.1516
> 1.5911  3.6247  22.38   18.181 13.812          1568.984857     1
> 1       HumanLanguage   1       2       -7.8605 2.0156  4.7392  15.992
> 12.122  6.9088  26.861 20.592  16.326  1721.359714     1
> 1       HumanLanguage   1       3       -2.6982 -5.6067 -10.038 6.285
> 5.5172  1.2894  13.565 12.981  11.63   1257.092571     1
> 1       HumanLanguage   1       4       3.3975  4.8789  -1.3249 7.0177
> 9.6703  6.1539  10.231 12.261  12.485  1559.461429     1
> ?(skipping to Subject 2)
> 2       HumanLanguage                   1       1       1.6791  2.8887
> 0.28174 -11.387 -9.9352 3.5936 -1.5767 3.9401  6.7201          1302.328857
> 1
> 2       HumanLanguage   1       2       -13.284 -8.2603 -6.6124 -5.9373
> -8.7551 0.10394 4.5621 10.204  12.261  969.0088571     1
> 2       HumanLanguage   1       3       -0.048973       1.1329  0.67399
> -2.1432 2.5077  -2.4641 9.4667 10.883  7.1396  721.3997143     1
> 2       HumanLanguage   1       4       5.0779  6.8916  6.3892  -1.8682
> 3.1637  7.9712  8.0994 10.883  10.975  707.1145714     1
> 2       HumanLanguage   1       5       -7.0495 -2.782  3.1668  8.4332
> 10.646  9.3726  -3.5937 -7.3769 5.4472  892.8214286     1
> 2       HumanLanguage   1       6       -1.462  -8.1223 -6.5896 -10.895
> -5.6311 0.39941 7.5473 12.783  14.698  611.8802857     1
> 2       HumanLanguage   1       7       -2.6402 -5.1213 -3.7372 3.4542
> 4.2234  -0.99898        1.4089 4.1976  0.56587 761.8742857     1
> 2       HumanLanguage   1       8       3.4393  4.6302  1.5525  1.4604
> 3.1716  3.1622  -2.3427 2.908 4.2259  680.9251429     1
> 2       HumanLanguage   1       9       -0.81024        -0.21642
> -2.3876 2.5839  4.7307  1.5441 3.3761  8.4485  12.02   769.0168571     1
> 2       HumanLanguage   1       10      -6.4045 -4.4937 -2.2449 0.94456
> 2.7048  0.65565 -1.9791 0.26436 1.8435  885.6788571     1
>
> Results:
>
> Linear mixed model fit by REML t-tests use Satterthwaite approximations to
> degrees of freedom [
> lmerMod]
> Formula: RT ~ 1 + (Condition + PzAlpha + Drive + PzAlpha * Condition) +
>    (1 | subject) + (1 | trial)
>   Data: INFAST_Behavioral
>
> REML criterion at convergence: 3876.4
>
> Scaled residuals:
>    Min      1Q  Median      3Q     Max
> -3.4308 -0.5227 -0.1194  0.3547  8.4095
>
> Random effects:
> Groups   Name        Variance Std.Dev.
> subject  (Intercept) 0.580073 0.76163
> trial    (Intercept) 0.004778 0.06912
> Residual             0.434918 0.65948
> Number of obs: 1839, groups:  subject, 39; trial, 10
>
> Fixed effects:
>                                         Estimate               Std. Error
> df t value Pr(>|t|)
> (Intercept)                        -0.27054    0.17607   40.80000  -1.537
> 0.13213
> ConditionMachineLang 0.41644    0.24595   36.90000   1.693  0.09884 .
> PzAlpha                             0.01192    0.02411 1797.40000   0.494
> 0.62117
> Drive                               0.02948    0.01083 1788.40000   2.722
> 0.00655 **
> ConditionMachineLanguage:PzAlpha   -0.01998    0.03476 1803.10000  -0.575
> 0.56560
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> P.M. Greenwood, Ph.D.
> Associate Professor of Psychology
> Editorial Board, NeuroImage
> David King Hall 2052
> George Mason University
> MSN 3F5, 4400 University Drive
> Fairfax, VA 22030-4444
>
> Ph: 703 993-4268
> fax: 703 993-1359
> email: Pgreenw1 at gmu.edu
> http://psychology.gmu.edu/people/pgreenw1
>
>
>        [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://secure-web.cisco.com/1joP--B1_xWT50x7mVQZsmihBAOqrRroakmdBR5MIMiOARC9Fd1hE1yw-1sCnwGxdnwBghNSYF9p3BRdhCaL0o-KBtN4F3VSOMBOaVY1oHIj6WYPh_sr8e-zRksQa9F4ECA_XGS2Afp73TF2WsPYwPhZh0vxQMs_BOy--csyKCdriarDzsvIs-lPMcfSch2Ym2oCTwBXQ_YkEWQehip65TFdXUagB8dg1r-d1G0r841y-84pF20_DPQ6J18R57bYFsQp5D34gsd2C2Jf6WMFXlHUZLbGyg7TV0F8CEvUF6vNcNdjIJTUSz79up7bz_iYDKOezABzwahOdHoC45jHqvTmDYhjaqzCkPsymio7HL4h8UlFKyj0xzrIe3rEFvRQsMaNQdctVCMacfdjj-nJiV9Ab0-aVDdezvOlj8IwbPCwr9QwTBeZzUqOwf5ENxq1r/https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://secure-web.cisco.com/1joP--B1_xWT50x7mVQZsmihBAOqrRroakmdBR5MIMiOARC9Fd1hE1yw-1sCnwGxdnwBghNSYF9p3BRdhCaL0o-KBtN4F3VSOMBOaVY1oHIj6WYPh_sr8e-zRksQa9F4ECA_XGS2Afp73TF2WsPYwPhZh0vxQMs_BOy--csyKCdriarDzsvIs-lPMcfSch2Ym2oCTwBXQ_YkEWQehip65TFdXUagB8dg1r-d1G0r841y-84pF20_DPQ6J18R57bYFsQp5D34gsd2C2Jf6WMFXlHUZLbGyg7TV0F8CEvUF6vNcNdjIJTUSz79up7bz_iYDKOezABzwahOdHoC45jHqvTmDYhjaqzCkPsymio7HL4h8UlFKyj0xzrIe3rEFvRQsMaNQdctVCMacfdjj-nJiV9Ab0-aVDdezvOlj8IwbPCwr9QwTBeZzUqOwf5ENxq1r/https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models
>
>
>


From tamas.ferenci at medstat.hu  Thu Jan 25 18:05:02 2018
From: tamas.ferenci at medstat.hu (Ferenci Tamas)
Date: Thu, 25 Jan 2018 18:05:02 +0100
Subject: [R-sig-ME] bug or numerical problem in nlme's corCAR1
Message-ID: <1379024905.20180125180502@medstat.hu>

Dear list members,

Consider the following example (yes, I haven't centered age, corCAR1
is not necessarily needed here etc., so it is perhaps not the most
meaningful model, I use it just to show the problem):

lme(distance ~ age + factor(Sex),random = ~ 1 | Subject,
   cor=corCAR1(form=~age|Subject),data = Orthodont)

Everything works perfectly.

Let's now multiply age, say, we measure it in months:

Orthodont$agemos <- Orthodont$age*12
lme(distance ~ agemos + factor(Sex),random = ~ 1 | Subject,
    cor=corCAR1(form=~agemos|Subject),data = Orthodont)

It shouldn't make any difference, but check the autocorrelation
coefficient! It changed from 0.2418536 to 0.2... i.e. it stuck at its
default value, as if it was not optimized at all! (One can verify that
it is indeed the case, and 0.2 was not a coincidence by calling
lme(distance ~ agemos + factor(Sex),random = ~ 1 | Subject,
cor=corCAR1(0.1234,form=~agemos|Subject),data = Orthodont) which will
return a coefficient of 0.1234 and so on.)

What's going on...?

Thank you in advance,
Tamas Ferenci


From jfox at mcmaster.ca  Thu Jan 25 18:40:55 2018
From: jfox at mcmaster.ca (Fox, John)
Date: Thu, 25 Jan 2018 17:40:55 +0000
Subject: [R-sig-ME] bug or numerical problem in nlme's corCAR1
In-Reply-To: <25591_1516899910_w0PH58cC031612_1379024905.20180125180502@medstat.hu>
References: <25591_1516899910_w0PH58cC031612_1379024905.20180125180502@medstat.hu>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC8367625D5@FHSDB2D11-2.csu.mcmaster.ca>

Dear Tamas Farenci,

You're mistaken: For the continuous first-order AR process, the unit of time matters. Measuring time in months implies a much larger autocorrelation at lag 1 than measuring time in years. As it turns out, 0.2 is a poor start values for the former:

> library(nlme)
> lme(distance ~ age + factor(Sex),random = ~ 1 | Subject,
+     cor=corCAR1(form=~age|Subject),data = Orthodont)
Linear mixed-effects model fit by REML
  Data: Orthodont 
  Log-restricted-likelihood: -218.6984
  Fixed: distance ~ age + factor(Sex) 
      (Intercept)               age factor(Sex)Female 
       17.7214161         0.6594049        -2.3274848 

Random effects:
 Formula: ~1 | Subject
        (Intercept) Residual
StdDev:    1.788899 1.454494

Correlation Structure: Continuous AR(1)
 Formula: ~age | Subject 
 Parameter estimate(s):
      Phi 
0.2418536 
Number of Observations: 108
Number of Groups: 27 

> Orthodont$agemos <- Orthodont$age*12
> lme(distance ~ agemos + factor(Sex),random = ~ 1 | Subject,
+     cor=corCAR1(0.8, form=~agemos|Subject),data = Orthodont)
Linear mixed-effects model fit by REML
  Data: Orthodont 
  Log-restricted-likelihood: -221.1833
  Fixed: distance ~ agemos + factor(Sex) 
      (Intercept)            agemos factor(Sex)Female 
      17.72141619        0.05495041       -2.32748480 

Random effects:
 Formula: ~1 | Subject
        (Intercept) Residual
StdDev:    1.788899 1.454494

Correlation Structure: Continuous AR(1)
 Formula: ~agemos | Subject 
 Parameter estimate(s):
      Phi 
0.8884427 
Number of Observations: 108
Number of Groups: 27 

> .8884427^12
[1] 0.2418539

Thus, the two solutions agree. I agree, however, that it's slightly disconcerting that lme() can't overcome the poor start value.

I hope this helps,
 John

-----------------------------
John Fox, Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
Web: socialsciences.mcmaster.ca/jfox/




> -----Original Message-----
> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-
> project.org] On Behalf Of Ferenci Tamas
> Sent: Thursday, January 25, 2018 12:05 PM
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] bug or numerical problem in nlme's corCAR1
> 
> Dear list members,
> 
> Consider the following example (yes, I haven't centered age, corCAR1 is not
> necessarily needed here etc., so it is perhaps not the most meaningful model,
> I use it just to show the problem):
> 
> lme(distance ~ age + factor(Sex),random = ~ 1 | Subject,
>    cor=corCAR1(form=~age|Subject),data = Orthodont)
> 
> Everything works perfectly.
> 
> Let's now multiply age, say, we measure it in months:
> 
> Orthodont$agemos <- Orthodont$age*12
> lme(distance ~ agemos + factor(Sex),random = ~ 1 | Subject,
>     cor=corCAR1(form=~agemos|Subject),data = Orthodont)
> 
> It shouldn't make any difference, but check the autocorrelation coefficient!
> It changed from 0.2418536 to 0.2... i.e. it stuck at its default value, as if it
> was not optimized at all! (One can verify that it is indeed the case, and 0.2
> was not a coincidence by calling lme(distance ~ agemos +
> factor(Sex),random = ~ 1 | Subject,
> cor=corCAR1(0.1234,form=~agemos|Subject),data = Orthodont) which will
> return a coefficient of 0.1234 and so on.)
> 
> What's going on...?
> 
> Thank you in advance,
> Tamas Ferenci
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbolker at gmail.com  Thu Jan 25 18:57:25 2018
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 25 Jan 2018 12:57:25 -0500
Subject: [R-sig-ME] bug or numerical problem in nlme's corCAR1
In-Reply-To: <ACD1644AA6C67E4FBD0C350625508EC8367625D5@FHSDB2D11-2.csu.mcmaster.ca>
References: <25591_1516899910_w0PH58cC031612_1379024905.20180125180502@medstat.hu>
 <ACD1644AA6C67E4FBD0C350625508EC8367625D5@FHSDB2D11-2.csu.mcmaster.ca>
Message-ID: <CABghstQEcpvZ7rm7crDNtQaOROOsEv9KXc_fEz+OYgmRE+equQ@mail.gmail.com>

The alarming part is the lack of any warning.  I don't know whether
there's any easy way to detect this case, though ...  FWIW the
starting value has to be above about 0.62 before it works

ff <- function(rhostart) {
  m <- lme(distance ~ agemos + factor(Sex),random = ~ 1 | Subject,
    cor=corCAR1(rhostart,form=~agemos|Subject),
    data = Orthodont)
  return(coef(m$modelStruct$corStruct,unconstrained=FALSE))
}

startvec <- seq(0.02,0.98,by=0.02)
estvec <- sapply(startvec,ff)

plot(startvec,estvec)

On Thu, Jan 25, 2018 at 12:40 PM, Fox, John <jfox at mcmaster.ca> wrote:
> Dear Tamas Farenci,
>
> You're mistaken: For the continuous first-order AR process, the unit of time matters. Measuring time in months implies a much larger autocorrelation at lag 1 than measuring time in years. As it turns out, 0.2 is a poor start values for the former:
>
>> library(nlme)
>> lme(distance ~ age + factor(Sex),random = ~ 1 | Subject,
> +     cor=corCAR1(form=~age|Subject),data = Orthodont)
> Linear mixed-effects model fit by REML
>   Data: Orthodont
>   Log-restricted-likelihood: -218.6984
>   Fixed: distance ~ age + factor(Sex)
>       (Intercept)               age factor(Sex)Female
>        17.7214161         0.6594049        -2.3274848
>
> Random effects:
>  Formula: ~1 | Subject
>         (Intercept) Residual
> StdDev:    1.788899 1.454494
>
> Correlation Structure: Continuous AR(1)
>  Formula: ~age | Subject
>  Parameter estimate(s):
>       Phi
> 0.2418536
> Number of Observations: 108
> Number of Groups: 27
>
>> Orthodont$agemos <- Orthodont$age*12
>> lme(distance ~ agemos + factor(Sex),random = ~ 1 | Subject,
> +     cor=corCAR1(0.8, form=~agemos|Subject),data = Orthodont)
> Linear mixed-effects model fit by REML
>   Data: Orthodont
>   Log-restricted-likelihood: -221.1833
>   Fixed: distance ~ agemos + factor(Sex)
>       (Intercept)            agemos factor(Sex)Female
>       17.72141619        0.05495041       -2.32748480
>
> Random effects:
>  Formula: ~1 | Subject
>         (Intercept) Residual
> StdDev:    1.788899 1.454494
>
> Correlation Structure: Continuous AR(1)
>  Formula: ~agemos | Subject
>  Parameter estimate(s):
>       Phi
> 0.8884427
> Number of Observations: 108
> Number of Groups: 27
>
>> .8884427^12
> [1] 0.2418539
>
> Thus, the two solutions agree. I agree, however, that it's slightly disconcerting that lme() can't overcome the poor start value.
>
> I hope this helps,
>  John
>
> -----------------------------
> John Fox, Professor Emeritus
> McMaster University
> Hamilton, Ontario, Canada
> Web: socialsciences.mcmaster.ca/jfox/
>
>
>
>
>> -----Original Message-----
>> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-
>> project.org] On Behalf Of Ferenci Tamas
>> Sent: Thursday, January 25, 2018 12:05 PM
>> To: r-sig-mixed-models at r-project.org
>> Subject: [R-sig-ME] bug or numerical problem in nlme's corCAR1
>>
>> Dear list members,
>>
>> Consider the following example (yes, I haven't centered age, corCAR1 is not
>> necessarily needed here etc., so it is perhaps not the most meaningful model,
>> I use it just to show the problem):
>>
>> lme(distance ~ age + factor(Sex),random = ~ 1 | Subject,
>>    cor=corCAR1(form=~age|Subject),data = Orthodont)
>>
>> Everything works perfectly.
>>
>> Let's now multiply age, say, we measure it in months:
>>
>> Orthodont$agemos <- Orthodont$age*12
>> lme(distance ~ agemos + factor(Sex),random = ~ 1 | Subject,
>>     cor=corCAR1(form=~agemos|Subject),data = Orthodont)
>>
>> It shouldn't make any difference, but check the autocorrelation coefficient!
>> It changed from 0.2418536 to 0.2... i.e. it stuck at its default value, as if it
>> was not optimized at all! (One can verify that it is indeed the case, and 0.2
>> was not a coincidence by calling lme(distance ~ agemos +
>> factor(Sex),random = ~ 1 | Subject,
>> cor=corCAR1(0.1234,form=~agemos|Subject),data = Orthodont) which will
>> return a coefficient of 0.1234 and so on.)
>>
>> What's going on...?
>>
>> Thank you in advance,
>> Tamas Ferenci
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From jfox at mcmaster.ca  Thu Jan 25 19:18:40 2018
From: jfox at mcmaster.ca (Fox, John)
Date: Thu, 25 Jan 2018 18:18:40 +0000
Subject: [R-sig-ME] bug or numerical problem in nlme's corCAR1
In-Reply-To: <CABghstQEcpvZ7rm7crDNtQaOROOsEv9KXc_fEz+OYgmRE+equQ@mail.gmail.com>
References: <25591_1516899910_w0PH58cC031612_1379024905.20180125180502@medstat.hu>
 <ACD1644AA6C67E4FBD0C350625508EC8367625D5@FHSDB2D11-2.csu.mcmaster.ca>
 <CABghstQEcpvZ7rm7crDNtQaOROOsEv9KXc_fEz+OYgmRE+equQ@mail.gmail.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC836762701@FHSDB2D11-2.csu.mcmaster.ca>

Hi Ben,

A possible solution would be to see whether the estimated autoregressive parameter is stuck at the start value and then try something like a bisection search. That's pretty crude and I bet there's a smarter way to do it.

Best,
 John

> -----Original Message-----
> From: Ben Bolker [mailto:bbolker at gmail.com]
> Sent: Thursday, January 25, 2018 12:57 PM
> To: Fox, John <jfox at mcmaster.ca>
> Cc: Ferenci Tamas <tamas.ferenci at medstat.hu>; r-sig-mixed-models at r-
> project.org
> Subject: Re: [R-sig-ME] bug or numerical problem in nlme's corCAR1
> 
> The alarming part is the lack of any warning.  I don't know whether there's
> any easy way to detect this case, though ...  FWIW the starting value has to
> be above about 0.62 before it works
> 
> ff <- function(rhostart) {
>   m <- lme(distance ~ agemos + factor(Sex),random = ~ 1 | Subject,
>     cor=corCAR1(rhostart,form=~agemos|Subject),
>     data = Orthodont)
>   return(coef(m$modelStruct$corStruct,unconstrained=FALSE))
> }
> 
> startvec <- seq(0.02,0.98,by=0.02)
> estvec <- sapply(startvec,ff)
> 
> plot(startvec,estvec)
> 
> On Thu, Jan 25, 2018 at 12:40 PM, Fox, John <jfox at mcmaster.ca> wrote:
> > Dear Tamas Farenci,
> >
> > You're mistaken: For the continuous first-order AR process, the unit of time
> matters. Measuring time in months implies a much larger autocorrelation at
> lag 1 than measuring time in years. As it turns out, 0.2 is a poor start values
> for the former:
> >
> >> library(nlme)
> >> lme(distance ~ age + factor(Sex),random = ~ 1 | Subject,
> > +     cor=corCAR1(form=~age|Subject),data = Orthodont)
> > Linear mixed-effects model fit by REML
> >   Data: Orthodont
> >   Log-restricted-likelihood: -218.6984
> >   Fixed: distance ~ age + factor(Sex)
> >       (Intercept)               age factor(Sex)Female
> >        17.7214161         0.6594049        -2.3274848
> >
> > Random effects:
> >  Formula: ~1 | Subject
> >         (Intercept) Residual
> > StdDev:    1.788899 1.454494
> >
> > Correlation Structure: Continuous AR(1)
> >  Formula: ~age | Subject
> >  Parameter estimate(s):
> >       Phi
> > 0.2418536
> > Number of Observations: 108
> > Number of Groups: 27
> >
> >> Orthodont$agemos <- Orthodont$age*12
> >> lme(distance ~ agemos + factor(Sex),random = ~ 1 | Subject,
> > +     cor=corCAR1(0.8, form=~agemos|Subject),data = Orthodont)
> > Linear mixed-effects model fit by REML
> >   Data: Orthodont
> >   Log-restricted-likelihood: -221.1833
> >   Fixed: distance ~ agemos + factor(Sex)
> >       (Intercept)            agemos factor(Sex)Female
> >       17.72141619        0.05495041       -2.32748480
> >
> > Random effects:
> >  Formula: ~1 | Subject
> >         (Intercept) Residual
> > StdDev:    1.788899 1.454494
> >
> > Correlation Structure: Continuous AR(1)
> >  Formula: ~agemos | Subject
> >  Parameter estimate(s):
> >       Phi
> > 0.8884427
> > Number of Observations: 108
> > Number of Groups: 27
> >
> >> .8884427^12
> > [1] 0.2418539
> >
> > Thus, the two solutions agree. I agree, however, that it's slightly
> disconcerting that lme() can't overcome the poor start value.
> >
> > I hope this helps,
> >  John
> >
> > -----------------------------
> > John Fox, Professor Emeritus
> > McMaster University
> > Hamilton, Ontario, Canada
> > Web: socialsciences.mcmaster.ca/jfox/
> >
> >
> >
> >
> >> -----Original Message-----
> >> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-
> >> project.org] On Behalf Of Ferenci Tamas
> >> Sent: Thursday, January 25, 2018 12:05 PM
> >> To: r-sig-mixed-models at r-project.org
> >> Subject: [R-sig-ME] bug or numerical problem in nlme's corCAR1
> >>
> >> Dear list members,
> >>
> >> Consider the following example (yes, I haven't centered age, corCAR1
> >> is not necessarily needed here etc., so it is perhaps not the most
> >> meaningful model, I use it just to show the problem):
> >>
> >> lme(distance ~ age + factor(Sex),random = ~ 1 | Subject,
> >>    cor=corCAR1(form=~age|Subject),data = Orthodont)
> >>
> >> Everything works perfectly.
> >>
> >> Let's now multiply age, say, we measure it in months:
> >>
> >> Orthodont$agemos <- Orthodont$age*12
> >> lme(distance ~ agemos + factor(Sex),random = ~ 1 | Subject,
> >>     cor=corCAR1(form=~agemos|Subject),data = Orthodont)
> >>
> >> It shouldn't make any difference, but check the autocorrelation
> coefficient!
> >> It changed from 0.2418536 to 0.2... i.e. it stuck at its default
> >> value, as if it was not optimized at all! (One can verify that it is
> >> indeed the case, and 0.2 was not a coincidence by calling
> >> lme(distance ~ agemos + factor(Sex),random = ~ 1 | Subject,
> >> cor=corCAR1(0.1234,form=~agemos|Subject),data = Orthodont) which
> will
> >> return a coefficient of 0.1234 and so on.)
> >>
> >> What's going on...?
> >>
> >> Thank you in advance,
> >> Tamas Ferenci
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

From tamas.ferenci at medstat.hu  Thu Jan 25 22:16:41 2018
From: tamas.ferenci at medstat.hu (Ferenci Tamas)
Date: Thu, 25 Jan 2018 22:16:41 +0100
Subject: [R-sig-ME] bug or numerical problem in nlme's corCAR1
In-Reply-To: <CABghstQEcpvZ7rm7crDNtQaOROOsEv9KXc_fEz+OYgmRE+equQ@mail.gmail.com>
References: <25591_1516899910_w0PH58cC031612_1379024905.20180125180502@medstat.hu> 
 <ACD1644AA6C67E4FBD0C350625508EC8367625D5@FHSDB2D11-2.csu.mcmaster.ca>
 <CABghstQEcpvZ7rm7crDNtQaOROOsEv9KXc_fEz+OYgmRE+equQ@mail.gmail.com>
Message-ID: <942759561.20180125221641@medstat.hu>

Dear Ben,

In addition to that, if you run that script with age, it will be
correct... *regardless* of the starting value!

> The alarming part is the lack of any warning.

Yes, what I found suspicious was that it was _exactly_ 0.2... and it
was only accidental that I remembered that it is the default value in
corCAR1, so I realized what is going on. But I can imagine that it
might go unnoticed...

Tamas


2018. janu?r 25., 18:57:25, ?rtad:

> The alarming part is the lack of any warning.  I don't know whether
> there's any easy way to detect this case, though ...  FWIW the
> starting value has to be above about 0.62 before it works

> ff <- function(rhostart) {
>   m <- lme(distance ~ agemos + factor(Sex),random = ~ 1 | Subject,
>     cor=corCAR1(rhostart,form=~agemos|Subject),
>     data = Orthodont)
>   return(coef(m$modelStruct$corStruct,unconstrained=FALSE))
> }

> startvec <- seq(0.02,0.98,by=0.02)
> estvec <- sapply(startvec,ff)

> plot(startvec,estvec)

> On Thu, Jan 25, 2018 at 12:40 PM, Fox, John <jfox at mcmaster.ca> wrote:
>> Dear Tamas Farenci,
>>
>> You're mistaken: For the continuous first-order AR process, the unit of time matters. Measuring time in months implies a much larger autocorrelation at lag 1 than measuring time in years. As it turns out, 0.2 is a poor start values for the former:
>>
>>> library(nlme)
>>> lme(distance ~ age + factor(Sex),random = ~ 1 | Subject,
>> +     cor=corCAR1(form=~age|Subject),data = Orthodont)
>> Linear mixed-effects model fit by REML
>>   Data: Orthodont
>>   Log-restricted-likelihood: -218.6984
>>   Fixed: distance ~ age + factor(Sex)
>>       (Intercept)               age factor(Sex)Female
>>        17.7214161         0.6594049        -2.3274848
>>
>> Random effects:
>>  Formula: ~1 | Subject
>>         (Intercept) Residual
>> StdDev:    1.788899 1.454494
>>
>> Correlation Structure: Continuous AR(1)
>>  Formula: ~age | Subject
>>  Parameter estimate(s):
>>       Phi
>> 0.2418536
>> Number of Observations: 108
>> Number of Groups: 27
>>
>>> Orthodont$agemos <- Orthodont$age*12
>>> lme(distance ~ agemos + factor(Sex),random = ~ 1 | Subject,
>> +     cor=corCAR1(0.8, form=~agemos|Subject),data = Orthodont)
>> Linear mixed-effects model fit by REML
>>   Data: Orthodont
>>   Log-restricted-likelihood: -221.1833
>>   Fixed: distance ~ agemos + factor(Sex)
>>       (Intercept)            agemos factor(Sex)Female
>>       17.72141619        0.05495041       -2.32748480
>>
>> Random effects:
>>  Formula: ~1 | Subject
>>         (Intercept) Residual
>> StdDev:    1.788899 1.454494
>>
>> Correlation Structure: Continuous AR(1)
>>  Formula: ~agemos | Subject
>>  Parameter estimate(s):
>>       Phi
>> 0.8884427
>> Number of Observations: 108
>> Number of Groups: 27
>>
>>> .8884427^12
>> [1] 0.2418539
>>
>> Thus, the two solutions agree. I agree, however, that it's slightly disconcerting that lme() can't overcome the poor start value.
>>
>> I hope this helps,
>>  John
>>
>> -----------------------------
>> John Fox, Professor Emeritus
>> McMaster University
>> Hamilton, Ontario, Canada
>> Web: socialsciences.mcmaster.ca/jfox/
>>
>>
>>
>>
>>> -----Original Message-----
>>> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-
>>> project.org] On Behalf Of Ferenci Tamas
>>> Sent: Thursday, January 25, 2018 12:05 PM
>>> To: r-sig-mixed-models at r-project.org
>>> Subject: [R-sig-ME] bug or numerical problem in nlme's corCAR1
>>>
>>> Dear list members,
>>>
>>> Consider the following example (yes, I haven't centered age, corCAR1 is not
>>> necessarily needed here etc., so it is perhaps not the most meaningful model,
>>> I use it just to show the problem):
>>>
>>> lme(distance ~ age + factor(Sex),random = ~ 1 | Subject,
>>>    cor=corCAR1(form=~age|Subject),data = Orthodont)
>>>
>>> Everything works perfectly.
>>>
>>> Let's now multiply age, say, we measure it in months:
>>>
>>> Orthodont$agemos <- Orthodont$age*12
>>> lme(distance ~ agemos + factor(Sex),random = ~ 1 | Subject,
>>>     cor=corCAR1(form=~agemos|Subject),data = Orthodont)
>>>
>>> It shouldn't make any difference, but check the autocorrelation coefficient!
>>> It changed from 0.2418536 to 0.2... i.e. it stuck at its default value, as if it
>>> was not optimized at all! (One can verify that it is indeed the case, and 0.2
>>> was not a coincidence by calling lme(distance ~ agemos +
>>> factor(Sex),random = ~ 1 | Subject,
>>> cor=corCAR1(0.1234,form=~agemos|Subject),data = Orthodont) which will
>>> return a coefficient of 0.1234 and so on.)
>>>
>>> What's going on...?
>>>
>>> Thank you in advance,
>>> Tamas Ferenci
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From tamas.ferenci at medstat.hu  Thu Jan 25 22:17:55 2018
From: tamas.ferenci at medstat.hu (Ferenci Tamas)
Date: Thu, 25 Jan 2018 22:17:55 +0100
Subject: [R-sig-ME] bug or numerical problem in nlme's corCAR1
In-Reply-To: <ACD1644AA6C67E4FBD0C350625508EC836762701@FHSDB2D11-2.csu.mcmaster.ca>
References: <25591_1516899910_w0PH58cC031612_1379024905.20180125180502@medstat.hu> 
 <ACD1644AA6C67E4FBD0C350625508EC8367625D5@FHSDB2D11-2.csu.mcmaster.ca>
 <CABghstQEcpvZ7rm7crDNtQaOROOsEv9KXc_fEz+OYgmRE+equQ@mail.gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC836762701@FHSDB2D11-2.csu.mcmaster.ca>
Message-ID: <1414439859.20180125221755@medstat.hu>

Dear John,

That's a possible solution IF you realize something is wrong, but what
I find problematic is that one might not realize at all that such
measures are needed!

Tamas


2018. janu?r 25., 19:18:40, ?rtad:

> Hi Ben,

> A possible solution would be to see whether the estimated
> autoregressive parameter is stuck at the start value and then try
> something like a bisection search. That's pretty crude and I bet there's a smarter way to do it.

> Best,
>  John

>> -----Original Message-----
>> From: Ben Bolker [mailto:bbolker at gmail.com]
>> Sent: Thursday, January 25, 2018 12:57 PM
>> To: Fox, John <jfox at mcmaster.ca>
>> Cc: Ferenci Tamas <tamas.ferenci at medstat.hu>; r-sig-mixed-models at r-
>> project.org
>> Subject: Re: [R-sig-ME] bug or numerical problem in nlme's corCAR1
>> 
>> The alarming part is the lack of any warning.  I don't know whether there's
>> any easy way to detect this case, though ...  FWIW the starting value has to
>> be above about 0.62 before it works
>> 
>> ff <- function(rhostart) {
>>   m <- lme(distance ~ agemos + factor(Sex),random = ~ 1 | Subject,
>>     cor=corCAR1(rhostart,form=~agemos|Subject),
>>     data = Orthodont)
>>   return(coef(m$modelStruct$corStruct,unconstrained=FALSE))
>> }
>> 
>> startvec <- seq(0.02,0.98,by=0.02)
>> estvec <- sapply(startvec,ff)
>> 
>> plot(startvec,estvec)
>> 
>> On Thu, Jan 25, 2018 at 12:40 PM, Fox, John <jfox at mcmaster.ca> wrote:
>> > Dear Tamas Farenci,
>> >
>> > You're mistaken: For the continuous first-order AR process, the unit of time
>> matters. Measuring time in months implies a much larger autocorrelation at
>> lag 1 than measuring time in years. As it turns out, 0.2 is a poor start values
>> for the former:
>> >
>> >> library(nlme)
>> >> lme(distance ~ age + factor(Sex),random = ~ 1 | Subject,
>> > +     cor=corCAR1(form=~age|Subject),data = Orthodont)
>> > Linear mixed-effects model fit by REML
>> >   Data: Orthodont
>> >   Log-restricted-likelihood: -218.6984
>> >   Fixed: distance ~ age + factor(Sex)
>> >       (Intercept)               age factor(Sex)Female
>> >        17.7214161         0.6594049        -2.3274848
>> >
>> > Random effects:
>> >  Formula: ~1 | Subject
>> >         (Intercept) Residual
>> > StdDev:    1.788899 1.454494
>> >
>> > Correlation Structure: Continuous AR(1)
>> >  Formula: ~age | Subject
>> >  Parameter estimate(s):
>> >       Phi
>> > 0.2418536
>> > Number of Observations: 108
>> > Number of Groups: 27
>> >
>> >> Orthodont$agemos <- Orthodont$age*12
>> >> lme(distance ~ agemos + factor(Sex),random = ~ 1 | Subject,
>> > +     cor=corCAR1(0.8, form=~agemos|Subject),data = Orthodont)
>> > Linear mixed-effects model fit by REML
>> >   Data: Orthodont
>> >   Log-restricted-likelihood: -221.1833
>> >   Fixed: distance ~ agemos + factor(Sex)
>> >       (Intercept)            agemos factor(Sex)Female
>> >       17.72141619        0.05495041       -2.32748480
>> >
>> > Random effects:
>> >  Formula: ~1 | Subject
>> >         (Intercept) Residual
>> > StdDev:    1.788899 1.454494
>> >
>> > Correlation Structure: Continuous AR(1)
>> >  Formula: ~agemos | Subject
>> >  Parameter estimate(s):
>> >       Phi
>> > 0.8884427
>> > Number of Observations: 108
>> > Number of Groups: 27
>> >
>> >> .8884427^12
>> > [1] 0.2418539
>> >
>> > Thus, the two solutions agree. I agree, however, that it's slightly
>> disconcerting that lme() can't overcome the poor start value.
>> >
>> > I hope this helps,
>> >  John
>> >
>> > -----------------------------
>> > John Fox, Professor Emeritus
>> > McMaster University
>> > Hamilton, Ontario, Canada
>> > Web: socialsciences.mcmaster.ca/jfox/
>> >
>> >
>> >
>> >
>> >> -----Original Message-----
>> >> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-
>> >> project.org] On Behalf Of Ferenci Tamas
>> >> Sent: Thursday, January 25, 2018 12:05 PM
>> >> To: r-sig-mixed-models at r-project.org
>> >> Subject: [R-sig-ME] bug or numerical problem in nlme's corCAR1
>> >>
>> >> Dear list members,
>> >>
>> >> Consider the following example (yes, I haven't centered age, corCAR1
>> >> is not necessarily needed here etc., so it is perhaps not the most
>> >> meaningful model, I use it just to show the problem):
>> >>
>> >> lme(distance ~ age + factor(Sex),random = ~ 1 | Subject,
>> >>    cor=corCAR1(form=~age|Subject),data = Orthodont)
>> >>
>> >> Everything works perfectly.
>> >>
>> >> Let's now multiply age, say, we measure it in months:
>> >>
>> >> Orthodont$agemos <- Orthodont$age*12
>> >> lme(distance ~ agemos + factor(Sex),random = ~ 1 | Subject,
>> >>     cor=corCAR1(form=~agemos|Subject),data = Orthodont)
>> >>
>> >> It shouldn't make any difference, but check the autocorrelation
>> coefficient!
>> >> It changed from 0.2418536 to 0.2... i.e. it stuck at its default
>> >> value, as if it was not optimized at all! (One can verify that it is
>> >> indeed the case, and 0.2 was not a coincidence by calling
>> >> lme(distance ~ agemos + factor(Sex),random = ~ 1 | Subject,
>> >> cor=corCAR1(0.1234,form=~agemos|Subject),data = Orthodont) which
>> will
>> >> return a coefficient of 0.1234 and so on.)
>> >>
>> >> What's going on...?
>> >>
>> >> Thank you in advance,
>> >> Tamas Ferenci
>> >>
>> >> _______________________________________________
>> >> R-sig-mixed-models at r-project.org mailing list
>> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >
>> > _______________________________________________
>> > R-sig-mixed-models at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From Phillip.Alday at mpi.nl  Thu Jan 25 23:30:10 2018
From: Phillip.Alday at mpi.nl (Alday, Phillip)
Date: Thu, 25 Jan 2018 22:30:10 +0000
Subject: [R-sig-ME] Different results for between/within groups and
 within group regression analyses
In-Reply-To: <CWXP265MB02168DCE36AA7142EEE8840DF6140@CWXP265MB0216.GBRP265.PROD.OUTLOOK.COM>
References: <da248a32-1d80-4cdd-9c96-7e80c199d086@mpi.nl>
 <CWXP265MB02168DCE36AA7142EEE8840DF6140@CWXP265MB0216.GBRP265.PROD.OUTLOOK.COM>
Message-ID: <cffb13f7-d16f-2b5b-a090-debc90bbe87d@mpi.nl>

I don't think this set of questions was ever addressed in any of the subsequent threads on this or other forums .... and so I'll give you a quick non answer of bullet points:


* "significance" should not be the driving force in whether or not an estimate is correct. While it does tell you something about the relative error in that estimate, but it tells you very little about how well that estimate describes the data or predicts future data.


* Much as it is difficult and potentially problematic to interpret a main effect in the presence of interactions (after all, by definition, an interaction implies that the main effect changes conditional on another variable), it is also problematic to intentionally exclude a known interaction to better estimate the main effect.


* However, this above advice has to be tempered by the issues related to statistical power, the bias-variance tradeoff and over- vs. underfitting -- a lot of preprints, journal articles and recent textbooks by members of this list and their collaborators have tried to address different aspects of this in the context of mixed models, but the issues are fundamentally the same for *all* statistical models. My advice is to find the parsimonious model that best describes the data (so the best model according to AIC or BIC) and look at the predictions that model makes and derive your inferences from that, instead of getting hung up on the significance of any one coefficient. The effects package can be particularly useful here, especially for plotting these things.


Phillip

On 13/01/18 23:07, Luca Danieli wrote:
Hi Phillip,

sorry if I ask you a question.
In this moment I have a 3x4x8 matrix, where '3' is the number of groups, '8' the number of tests, and '4' the levels of the potential main effect.

Following your explanation, I was before thinking that leaving interactions out of the models would give you a better approximation of the main effect. But now that I read it again, I am unsure about it.

In my case, the '4' levels are nested in each set.
If I write lmer(Score ~ pot_ME + random effects) I have no statistical significance.
If I write lmer(Score ~ pot_ME*groups + random effects) I have statistical significance for the main effect (p<0.05) and a strong interaction (p<.001).
If I write lmer(Score ~ pot_ME*groups*tests + random effects) I have no statistical significance nor interactions.

What approach is the more correct to get information about the presence of a main effect?

(My parameters are not-continuous)

Best
Luca
________________________________
From: Alday, Phillip <Phillip.Alday at mpi.nl><mailto:Phillip.Alday at mpi.nl>
Sent: 11 January 2018 15:38
To: Luca Danieli; r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] Different results for between/within groups and within group regression analyses

I'll do it myself when I get the chance in the next day or so.  :-)

Phillip

________________________________
From: Luca Danieli <mr.lucedan at hotmail.it><mailto:mr.lucedan at hotmail.it>
Sent: Thursday, January 11, 2018 10:26 AM
To: Alday, Phillip; r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] Different results for between/within groups and within group regression analyses

Thank you Phillip!

Can I add your answer to CrossValidated for future concerns by other users?

Best
Luca
________________________________
From: Alday, Phillip <Phillip.Alday at mpi.nl><mailto:Phillip.Alday at mpi.nl>
Sent: 11 January 2018 15:18
To: Luca Danieli; r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] Different results for between/within groups and within group regression analyses

By only using one group, you're changing the amount of pooling going on, which affects shrinkage and the bias-variance / over- vs. underfitting tradeoff. When you fit a model to a subset, it will generally be better at describing that subset but often worse at describing the full set / other sets. In other words, your subset model better describes the subset because it doesn't have to spend "resources" describing the other data, but of course this also means that it will tend to not describe the other data as well - it's better at the small details but worse at the big picture.

Best,
Phillip

Sent from my mobile, please excuse my brevity.

________________________________
From: Luca Danieli <mr.lucedan at hotmail.it><mailto:mr.lucedan at hotmail.it>
Sent: Thursday, January 11, 2018 10:10 AM
To: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
Subject: [R-sig-ME] Different results for between/within groups and within group regression analyses


Dear all,

from CrossValidates I was suggested to repost my question to you, as it is a technical question about R and mixed models.
Particularly, as I have a thesis to hand in in a few weeks, I hope you are able to help me understanding some problems that I cannot figure out by myself.

In this case, I have used the function lmer() to look for an interaction between groups and then used the function predict() to plot the fits for each group on a graphic.
Then I applied the lmer() to just one of those groups (same formula, technically) and used the predict() function to plot the fits for that specific group. I was thinking to obtain the same graphic for that group type and instead I obtained two different results.

I explained the process, models and presented the plots in this post:
https://stats.stackexchange.com/questions/322608/different-results-for-between-within-groups-and-within-group-regression-analyses

Can somebody help me understand this?

Best
Luca



[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


	[[alternative HTML version deleted]]


From jfox at mcmaster.ca  Thu Jan 25 23:43:46 2018
From: jfox at mcmaster.ca (Fox, John)
Date: Thu, 25 Jan 2018 22:43:46 +0000
Subject: [R-sig-ME] bug or numerical problem in nlme's corCAR1
In-Reply-To: <1414439859.20180125221755@medstat.hu>
References: <25591_1516899910_w0PH58cC031612_1379024905.20180125180502@medstat.hu>
 <ACD1644AA6C67E4FBD0C350625508EC8367625D5@FHSDB2D11-2.csu.mcmaster.ca>
 <CABghstQEcpvZ7rm7crDNtQaOROOsEv9KXc_fEz+OYgmRE+equQ@mail.gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC836762701@FHSDB2D11-2.csu.mcmaster.ca>
 <1414439859.20180125221755@medstat.hu>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC836762C45@FHSDB2D11-2.csu.mcmaster.ca>

Dear Tamas,

> -----Original Message-----
> From: Ferenci Tamas [mailto:tamas.ferenci at medstat.hu]
> Sent: Thursday, January 25, 2018 4:18 PM
> To: Fox, John <jfox at mcmaster.ca>; Ben Bolker <bbolker at gmail.com>
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] bug or numerical problem in nlme's corCAR1
> 
> Dear John,
> 
> That's a possible solution IF you realize something is wrong, but what I find
> problematic is that one might not realize at all that such measures are needed!

I was suggesting to Ben that lme() might do it.

John

> 
> Tamas
> 
> 
> 2018. janu?r 25., 19:18:40, ?rtad:
> 
> > Hi Ben,
> 
> > A possible solution would be to see whether the estimated
> > autoregressive parameter is stuck at the start value and then try
> > something like a bisection search. That's pretty crude and I bet there's a
> smarter way to do it.
> 
> > Best,
> >  John
> 
> >> -----Original Message-----
> >> From: Ben Bolker [mailto:bbolker at gmail.com]
> >> Sent: Thursday, January 25, 2018 12:57 PM
> >> To: Fox, John <jfox at mcmaster.ca>
> >> Cc: Ferenci Tamas <tamas.ferenci at medstat.hu>; r-sig-mixed-models at r-
> >> project.org
> >> Subject: Re: [R-sig-ME] bug or numerical problem in nlme's corCAR1
> >>
> >> The alarming part is the lack of any warning.  I don't know whether
> >> there's any easy way to detect this case, though ...  FWIW the
> >> starting value has to be above about 0.62 before it works
> >>
> >> ff <- function(rhostart) {
> >>   m <- lme(distance ~ agemos + factor(Sex),random = ~ 1 | Subject,
> >>     cor=corCAR1(rhostart,form=~agemos|Subject),
> >>     data = Orthodont)
> >>   return(coef(m$modelStruct$corStruct,unconstrained=FALSE))
> >> }
> >>
> >> startvec <- seq(0.02,0.98,by=0.02)
> >> estvec <- sapply(startvec,ff)
> >>
> >> plot(startvec,estvec)
> >>
> >> On Thu, Jan 25, 2018 at 12:40 PM, Fox, John <jfox at mcmaster.ca> wrote:
> >> > Dear Tamas Farenci,
> >> >
> >> > You're mistaken: For the continuous first-order AR process, the
> >> > unit of time
> >> matters. Measuring time in months implies a much larger
> >> autocorrelation at lag 1 than measuring time in years. As it turns
> >> out, 0.2 is a poor start values for the former:
> >> >
> >> >> library(nlme)
> >> >> lme(distance ~ age + factor(Sex),random = ~ 1 | Subject,
> >> > +     cor=corCAR1(form=~age|Subject),data = Orthodont)
> >> > Linear mixed-effects model fit by REML
> >> >   Data: Orthodont
> >> >   Log-restricted-likelihood: -218.6984
> >> >   Fixed: distance ~ age + factor(Sex)
> >> >       (Intercept)               age factor(Sex)Female
> >> >        17.7214161         0.6594049        -2.3274848
> >> >
> >> > Random effects:
> >> >  Formula: ~1 | Subject
> >> >         (Intercept) Residual
> >> > StdDev:    1.788899 1.454494
> >> >
> >> > Correlation Structure: Continuous AR(1)
> >> >  Formula: ~age | Subject
> >> >  Parameter estimate(s):
> >> >       Phi
> >> > 0.2418536
> >> > Number of Observations: 108
> >> > Number of Groups: 27
> >> >
> >> >> Orthodont$agemos <- Orthodont$age*12 lme(distance ~ agemos +
> >> >> factor(Sex),random = ~ 1 | Subject,
> >> > +     cor=corCAR1(0.8, form=~agemos|Subject),data = Orthodont)
> >> > Linear mixed-effects model fit by REML
> >> >   Data: Orthodont
> >> >   Log-restricted-likelihood: -221.1833
> >> >   Fixed: distance ~ agemos + factor(Sex)
> >> >       (Intercept)            agemos factor(Sex)Female
> >> >       17.72141619        0.05495041       -2.32748480
> >> >
> >> > Random effects:
> >> >  Formula: ~1 | Subject
> >> >         (Intercept) Residual
> >> > StdDev:    1.788899 1.454494
> >> >
> >> > Correlation Structure: Continuous AR(1)
> >> >  Formula: ~agemos | Subject
> >> >  Parameter estimate(s):
> >> >       Phi
> >> > 0.8884427
> >> > Number of Observations: 108
> >> > Number of Groups: 27
> >> >
> >> >> .8884427^12
> >> > [1] 0.2418539
> >> >
> >> > Thus, the two solutions agree. I agree, however, that it's slightly
> >> disconcerting that lme() can't overcome the poor start value.
> >> >
> >> > I hope this helps,
> >> >  John
> >> >
> >> > -----------------------------
> >> > John Fox, Professor Emeritus
> >> > McMaster University
> >> > Hamilton, Ontario, Canada
> >> > Web: socialsciences.mcmaster.ca/jfox/
> >> >
> >> >
> >> >
> >> >
> >> >> -----Original Message-----
> >> >> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-
> >> >> project.org] On Behalf Of Ferenci Tamas
> >> >> Sent: Thursday, January 25, 2018 12:05 PM
> >> >> To: r-sig-mixed-models at r-project.org
> >> >> Subject: [R-sig-ME] bug or numerical problem in nlme's corCAR1
> >> >>
> >> >> Dear list members,
> >> >>
> >> >> Consider the following example (yes, I haven't centered age,
> >> >> corCAR1 is not necessarily needed here etc., so it is perhaps not
> >> >> the most meaningful model, I use it just to show the problem):
> >> >>
> >> >> lme(distance ~ age + factor(Sex),random = ~ 1 | Subject,
> >> >>    cor=corCAR1(form=~age|Subject),data = Orthodont)
> >> >>
> >> >> Everything works perfectly.
> >> >>
> >> >> Let's now multiply age, say, we measure it in months:
> >> >>
> >> >> Orthodont$agemos <- Orthodont$age*12 lme(distance ~ agemos +
> >> >> factor(Sex),random = ~ 1 | Subject,
> >> >>     cor=corCAR1(form=~agemos|Subject),data = Orthodont)
> >> >>
> >> >> It shouldn't make any difference, but check the autocorrelation
> >> coefficient!
> >> >> It changed from 0.2418536 to 0.2... i.e. it stuck at its default
> >> >> value, as if it was not optimized at all! (One can verify that it
> >> >> is indeed the case, and 0.2 was not a coincidence by calling
> >> >> lme(distance ~ agemos + factor(Sex),random = ~ 1 | Subject,
> >> >> cor=corCAR1(0.1234,form=~agemos|Subject),data = Orthodont) which
> >> will
> >> >> return a coefficient of 0.1234 and so on.)
> >> >>
> >> >> What's going on...?
> >> >>
> >> >> Thank you in advance,
> >> >> Tamas Ferenci
> >> >>
> >> >> _______________________________________________
> >> >> R-sig-mixed-models at r-project.org mailing list
> >> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >> >
> >> > _______________________________________________
> >> > R-sig-mixed-models at r-project.org mailing list
> >> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From Phillip.Alday at mpi.nl  Thu Jan 25 23:44:57 2018
From: Phillip.Alday at mpi.nl (Alday, Phillip)
Date: Thu, 25 Jan 2018 22:44:57 +0000
Subject: [R-sig-ME] subjects within groups and effects of group
In-Reply-To: <CAJuCY5yPSDBrejqwNV=VO30yS30+1f+rzjDDUikOwE+QF6QoYQ@mail.gmail.com>
References: <CC4B04FD-6934-4E94-B9A6-8E7AA8FBA33A@gmu.edu>
 <CAJuCY5xjL6wb5MxQs=MMum9BcqK-2QD6YNuythpa0a23uknT6g@mail.gmail.com>
 <99620d09-4dd7-5dac-e46e-4eb205be9cf7@mpi.nl>
 <B9A8DD23-7CFB-4380-A6C0-22E35F661F6E@gmu.edu>
 <CB5DAA4D-57A8-45C5-948B-336B235350BF@gmu.edu>
 <CAJuCY5yPSDBrejqwNV=VO30yS30+1f+rzjDDUikOwE+QF6QoYQ@mail.gmail.com>
Message-ID: <ca89fd98-0528-0777-7d54-ca59eebce535@mpi.nl>

Completely agree with Thierry here.

In addition to the usual considerations about the bias-variance tradeoff and partial pooling, you need to have things in one model if you really want to compare them. The Difference Between ?Significant? and ?Not Significant? is not Itself Statistically Significant (Gelman and Stern 2012, doi:10.1198/000313006X152649<https://doi.org/10.1198/000313006X152649>), so if you care about the significance of the difference, then you need to actually test the difference!

For your other question

Trial refers to stimulus events.  The stimuli are the same on each Trial, although the order of the Trials varies between Drives.   But, yes, Trial is a sequence number for the repetition so that there could be some adaptation or change in response related to number of exposures.  (Assuming that is what you meant).  How would I include Trial as a continuous fixed effect?

I would use slightly different names to make things clear. Separate 'Trial' (a fixed series of stimuli) from SeqNo (the sequential position of a given Trial within a Drive).

Then your model looks something like this:

lmer(RT ~ 1 + Condition*PzAlpha + Drive + SeqNo + (1 | subject) + (1 | trial)

I've left out any interactions there, but I suspect you'll at least have an interaction with alpha and sequence number -- I imagine that later trials (i.e. higher sequence numbers) will have worse RTs (exhaustion effects) as will trials with higher alpha power and that this two effects will enhance each other.

Including sequence information in the model has received some attention in the psycholinguistic as well as the broader psychology literature as a way of controlling for adapt ion effects. GAMMs have been proposed for such cases to allow for non linear adaptation effects, but I wouldn't mess around with that until you feel much more comfortable with the standard LMMs.

And of course, if SeqNo doesn't improve model fit, you can simply omit it for parsimony and easy of both interpretation and fitting.

Phillip

On 25/01/18 17:33, Thierry Onkelinx wrote:

Dear Pam,

I'd probably combine both datasets in a single analysis.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
AND FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be<mailto:thierry.onkelinx at inbo.be>
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be<http://www.inbo.be>

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////




2018-01-24 14:02 GMT+01:00 P Greenwood <pgreenw1 at gmu.edu><mailto:pgreenw1 at gmu.edu>:


Dear Drs Alday and Onkelinx

I wondered if you had thoughts on the best way to conduct followup analysis
of the between-subjects Condition to which people were randomly assigned.

Pam Greenwood

P.M. Greenwood, Ph.D.
Associate Professor of Psychology
Editorial Board, NeuroImage
David King Hall 2052
George Mason University
MSN 3F5, 4400 University Drive
Fairfax, VA 22030-4444

Ph: 703 993-4268
fax: 703 993-1359
email: Pgreenw1 at gmu.edu<mailto:Pgreenw1 at gmu.edu>
http://psychology.gmu.edu/people/pgreenw1

On Jan 19, 2018, at 8:09 AM, P Greenwood <pgreenw1 at gmu.edu><mailto:pgreenw1 at gmu.edu> wrote:

Thanks to you both.

Trial refers to stimulus events.  The stimuli are the same on each Trial,
although the order of the Trials varies between Drives.   But, yes, Trial is
a sequence number for the repetition so that there could be some adaptation
or change in response related to number of exposures.  (Assuming that is
what you meant).  How would I include Trial as a continuous fixed effect?

If the effect of Condition were ?significant.? how would one decompose that
to examine each group (Condition) separately?

Regards

Pam


P.M. Greenwood, Ph.D.
Associate Professor of Psychology
Editorial Board, NeuroImage
David King Hall 2052
George Mason University
MSN 3F5, 4400 University Drive
Fairfax, VA 22030-4444

Ph: 703 993-4268
fax: 703 993-1359
email: Pgreenw1 at gmu.edu<mailto:Pgreenw1 at gmu.edu>
http://psychology.gmu.edu/people/pgreenw1

On Jan 19, 2018, at 5:58 AM, Phillip Alday <phillip.alday at mpi.nl><mailto:phillip.alday at mpi.nl> wrote:

Dear Pam, (dear Thierry,)

if I'm reading the description correctly, Pam is conceiving of Trial as
being an "Item"-type factor (crossed with subject). To rephrase
Thierry's comment a bit -- if Trial corresponds to an Item (concrete
stimulus realization sampled from the population of possible stimuli for
this manipulation) that is the same across subjects, then this is a good
way to model that. If Trial doesn't correspond to an invariant set of
items, but is rather just repetitions of the same task (perhaps with
some random variation that isn't identical across subjects), then
modeling Trial as a random effect doesn't really help much. However, if
Trial is just a sequence number for the repetition, it might make sense
to instead include Trial as a continuous fixed effect in order to model
adaptation effects.

Best,
Phillip

On 19/01/18 10:44, Thierry Onkelinx wrote:

Dear Pam,

You are handling condition and subject correctly.

There might be a problem with trial. Does trial indicates dependent
replication of the study? Is there a common effect of trial X for all
subjects? Because that is what your current model assumes. In case the
trials are independent, then you don't need to include it in the
model.

Note that Condition + PzAlpha + PzAlpha*Condition is verbose. You can
write it as PzAlpha*Condition.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
AND FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be<mailto:thierry.onkelinx at inbo.be>
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be<http://www.inbo.be>

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////




2018-01-18 18:51 GMT+01:00 P Greenwood <pgreenw1 at gmu.edu><mailto:pgreenw1 at gmu.edu>:

Hello

I wanted some advice about handling subjects within groups and effects of
group (randomly assigned).  I want to predict reaction time (RT) as a
function of  ?Condition,?  alpha band power (PzAlpha), and drive. People
(subjects) are randomly assigned to Condition, of which there are two. Each
person has data from 5 drives, and for each drive there are 10 trials.
There are 19 subjects in one group and 20 in the other.

My question is this: Am I handling the ?between subjects? factor of
Condition correctly?  Also, am I treating subjects within group correctly?
I am pasting in some of my data.  The output is below.

Regards

Pam Greenwood

library(lme4)
library(lmerTest)
INFAST_Behavioral <- read.csv(??.
na.omit(INFAST_Behavioral)
INFAST_Behavioral$RT = scale(INFAST_Behavioral$RT, center = TRUE, scale =
TRUE)
INFAST_Behavioral$PzAlpha = scale(INFAST_Behavioral$PzAlpha, center = TRUE,
scale = TRUE)
sumModelInteraction <- lmer(RT ~ 1 + (Condition + PzAlpha + Drive +
PzAlpha*Condition) + (1 | subject) + (1 | trial), data = INFAST_Behavioral)
summary(sumModelInteraction)

subject Condition               Drive           trial   FzAlpha CzAlpha
PzAlpha FzTheta CzTheta PzTheta FzDelta CzDelta PzDelta         RT      ACC
1       HumanLanguage   1       1       -1.41   -4.3585 -5.5431 6.1516
1.5911  3.6247  22.38   18.181 13.812          1568.984857     1
1       HumanLanguage   1       2       -7.8605 2.0156  4.7392  15.992
12.122  6.9088  26.861 20.592  16.326  1721.359714     1
1       HumanLanguage   1       3       -2.6982 -5.6067 -10.038 6.285
5.5172  1.2894  13.565 12.981  11.63   1257.092571     1
1       HumanLanguage   1       4       3.3975  4.8789  -1.3249 7.0177
9.6703  6.1539  10.231 12.261  12.485  1559.461429     1
?(skipping to Subject 2)
2       HumanLanguage                   1       1       1.6791  2.8887
0.28174 -11.387 -9.9352 3.5936 -1.5767 3.9401  6.7201          1302.328857
1
2       HumanLanguage   1       2       -13.284 -8.2603 -6.6124 -5.9373
-8.7551 0.10394 4.5621 10.204  12.261  969.0088571     1
2       HumanLanguage   1       3       -0.048973       1.1329  0.67399
-2.1432 2.5077  -2.4641 9.4667 10.883  7.1396  721.3997143     1
2       HumanLanguage   1       4       5.0779  6.8916  6.3892  -1.8682
3.1637  7.9712  8.0994 10.883  10.975  707.1145714     1
2       HumanLanguage   1       5       -7.0495 -2.782  3.1668  8.4332
10.646  9.3726  -3.5937 -7.3769 5.4472  892.8214286     1
2       HumanLanguage   1       6       -1.462  -8.1223 -6.5896 -10.895
-5.6311 0.39941 7.5473 12.783  14.698  611.8802857     1
2       HumanLanguage   1       7       -2.6402 -5.1213 -3.7372 3.4542
4.2234  -0.99898        1.4089 4.1976  0.56587 761.8742857     1
2       HumanLanguage   1       8       3.4393  4.6302  1.5525  1.4604
3.1716  3.1622  -2.3427 2.908 4.2259  680.9251429     1
2       HumanLanguage   1       9       -0.81024        -0.21642
-2.3876 2.5839  4.7307  1.5441 3.3761  8.4485  12.02   769.0168571     1
2       HumanLanguage   1       10      -6.4045 -4.4937 -2.2449 0.94456
2.7048  0.65565 -1.9791 0.26436 1.8435  885.6788571     1

Results:

Linear mixed model fit by REML t-tests use Satterthwaite approximations to
degrees of freedom [
lmerMod]
Formula: RT ~ 1 + (Condition + PzAlpha + Drive + PzAlpha * Condition) +
   (1 | subject) + (1 | trial)
  Data: INFAST_Behavioral

REML criterion at convergence: 3876.4

Scaled residuals:
   Min      1Q  Median      3Q     Max
-3.4308 -0.5227 -0.1194  0.3547  8.4095

Random effects:
Groups   Name        Variance Std.Dev.
subject  (Intercept) 0.580073 0.76163
trial    (Intercept) 0.004778 0.06912
Residual             0.434918 0.65948
Number of obs: 1839, groups:  subject, 39; trial, 10

Fixed effects:
                                        Estimate               Std. Error
df t value Pr(>|t|)
(Intercept)                        -0.27054    0.17607   40.80000  -1.537
0.13213
ConditionMachineLang 0.41644    0.24595   36.90000   1.693  0.09884 .
PzAlpha                             0.01192    0.02411 1797.40000   0.494
0.62117
Drive                               0.02948    0.01083 1788.40000   2.722
0.00655 **
ConditionMachineLanguage:PzAlpha   -0.01998    0.03476 1803.10000  -0.575
0.56560
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
P.M. Greenwood, Ph.D.
Associate Professor of Psychology
Editorial Board, NeuroImage
David King Hall 2052
George Mason University
MSN 3F5, 4400 University Drive
Fairfax, VA 22030-4444

Ph: 703 993-4268
fax: 703 993-1359
email: Pgreenw1 at gmu.edu<mailto:Pgreenw1 at gmu.edu>
http://psychology.gmu.edu/people/pgreenw1


       [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://secure-web.cisco.com/1joP--B1_xWT50x7mVQZsmihBAOqrRroakmdBR5MIMiOARC9Fd1hE1yw-1sCnwGxdnwBghNSYF9p3BRdhCaL0o-KBtN4F3VSOMBOaVY1oHIj6WYPh_sr8e-zRksQa9F4ECA_XGS2Afp73TF2WsPYwPhZh0vxQMs_BOy--csyKCdriarDzsvIs-lPMcfSch2Ym2oCTwBXQ_YkEWQehip65TFdXUagB8dg1r-d1G0r841y-84pF20_DPQ6J18R57bYFsQp5D34gsd2C2Jf6WMFXlHUZLbGyg7TV0F8CEvUF6vNcNdjIJTUSz79up7bz_iYDKOezABzwahOdHoC45jHqvTmDYhjaqzCkPsymio7HL4h8UlFKyj0xzrIe3rEFvRQsMaNQdctVCMacfdjj-nJiV9Ab0-aVDdezvOlj8IwbPCwr9QwTBeZzUqOwf5ENxq1r/https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models


_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://secure-web.cisco.com/1joP--B1_xWT50x7mVQZsmihBAOqrRroakmdBR5MIMiOARC9Fd1hE1yw-1sCnwGxdnwBghNSYF9p3BRdhCaL0o-KBtN4F3VSOMBOaVY1oHIj6WYPh_sr8e-zRksQa9F4ECA_XGS2Afp73TF2WsPYwPhZh0vxQMs_BOy--csyKCdriarDzsvIs-lPMcfSch2Ym2oCTwBXQ_YkEWQehip65TFdXUagB8dg1r-d1G0r841y-84pF20_DPQ6J18R57bYFsQp5D34gsd2C2Jf6WMFXlHUZLbGyg7TV0F8CEvUF6vNcNdjIJTUSz79up7bz_iYDKOezABzwahOdHoC45jHqvTmDYhjaqzCkPsymio7HL4h8UlFKyj0xzrIe3rEFvRQsMaNQdctVCMacfdjj-nJiV9Ab0-aVDdezvOlj8IwbPCwr9QwTBeZzUqOwf5ENxq1r/https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models






	[[alternative HTML version deleted]]


From bbolker at gmail.com  Fri Jan 26 01:19:30 2018
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 25 Jan 2018 19:19:30 -0500
Subject: [R-sig-ME] bug or numerical problem in nlme's corCAR1
In-Reply-To: <ACD1644AA6C67E4FBD0C350625508EC836762C45@FHSDB2D11-2.csu.mcmaster.ca>
References: <25591_1516899910_w0PH58cC031612_1379024905.20180125180502@medstat.hu>
 <ACD1644AA6C67E4FBD0C350625508EC8367625D5@FHSDB2D11-2.csu.mcmaster.ca>
 <CABghstQEcpvZ7rm7crDNtQaOROOsEv9KXc_fEz+OYgmRE+equQ@mail.gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC836762701@FHSDB2D11-2.csu.mcmaster.ca>
 <1414439859.20180125221755@medstat.hu>
 <ACD1644AA6C67E4FBD0C350625508EC836762C45@FHSDB2D11-2.csu.mcmaster.ca>
Message-ID: <d7652115-ba70-2191-9726-6d28617d1fe5@gmail.com>


 Yes (although I'd like to remind everyone that I am *not* the
maintainer of nlme; R-core is).

  cheers
   Ben


On 18-01-25 05:43 PM, Fox, John wrote:
> Dear Tamas,
> 
>> -----Original Message-----
>> From: Ferenci Tamas [mailto:tamas.ferenci at medstat.hu]
>> Sent: Thursday, January 25, 2018 4:18 PM
>> To: Fox, John <jfox at mcmaster.ca>; Ben Bolker <bbolker at gmail.com>
>> Cc: r-sig-mixed-models at r-project.org
>> Subject: Re: [R-sig-ME] bug or numerical problem in nlme's corCAR1
>>
>> Dear John,
>>
>> That's a possible solution IF you realize something is wrong, but what I find
>> problematic is that one might not realize at all that such measures are needed!
> 
> I was suggesting to Ben that lme() might do it.
> 
> John
> 
>>
>> Tamas
>>
>>
>> 2018. janu?r 25., 19:18:40, ?rtad:
>>
>>> Hi Ben,
>>
>>> A possible solution would be to see whether the estimated
>>> autoregressive parameter is stuck at the start value and then try
>>> something like a bisection search. That's pretty crude and I bet there's a
>> smarter way to do it.
>>
>>> Best,
>>>  John
>>
>>>> -----Original Message-----
>>>> From: Ben Bolker [mailto:bbolker at gmail.com]
>>>> Sent: Thursday, January 25, 2018 12:57 PM
>>>> To: Fox, John <jfox at mcmaster.ca>
>>>> Cc: Ferenci Tamas <tamas.ferenci at medstat.hu>; r-sig-mixed-models at r-
>>>> project.org
>>>> Subject: Re: [R-sig-ME] bug or numerical problem in nlme's corCAR1
>>>>
>>>> The alarming part is the lack of any warning.  I don't know whether
>>>> there's any easy way to detect this case, though ...  FWIW the
>>>> starting value has to be above about 0.62 before it works
>>>>
>>>> ff <- function(rhostart) {
>>>>   m <- lme(distance ~ agemos + factor(Sex),random = ~ 1 | Subject,
>>>>     cor=corCAR1(rhostart,form=~agemos|Subject),
>>>>     data = Orthodont)
>>>>   return(coef(m$modelStruct$corStruct,unconstrained=FALSE))
>>>> }
>>>>
>>>> startvec <- seq(0.02,0.98,by=0.02)
>>>> estvec <- sapply(startvec,ff)
>>>>
>>>> plot(startvec,estvec)
>>>>
>>>> On Thu, Jan 25, 2018 at 12:40 PM, Fox, John <jfox at mcmaster.ca> wrote:
>>>>> Dear Tamas Farenci,
>>>>>
>>>>> You're mistaken: For the continuous first-order AR process, the
>>>>> unit of time
>>>> matters. Measuring time in months implies a much larger
>>>> autocorrelation at lag 1 than measuring time in years. As it turns
>>>> out, 0.2 is a poor start values for the former:
>>>>>
>>>>>> library(nlme)
>>>>>> lme(distance ~ age + factor(Sex),random = ~ 1 | Subject,
>>>>> +     cor=corCAR1(form=~age|Subject),data = Orthodont)
>>>>> Linear mixed-effects model fit by REML
>>>>>   Data: Orthodont
>>>>>   Log-restricted-likelihood: -218.6984
>>>>>   Fixed: distance ~ age + factor(Sex)
>>>>>       (Intercept)               age factor(Sex)Female
>>>>>        17.7214161         0.6594049        -2.3274848
>>>>>
>>>>> Random effects:
>>>>>  Formula: ~1 | Subject
>>>>>         (Intercept) Residual
>>>>> StdDev:    1.788899 1.454494
>>>>>
>>>>> Correlation Structure: Continuous AR(1)
>>>>>  Formula: ~age | Subject
>>>>>  Parameter estimate(s):
>>>>>       Phi
>>>>> 0.2418536
>>>>> Number of Observations: 108
>>>>> Number of Groups: 27
>>>>>
>>>>>> Orthodont$agemos <- Orthodont$age*12 lme(distance ~ agemos +
>>>>>> factor(Sex),random = ~ 1 | Subject,
>>>>> +     cor=corCAR1(0.8, form=~agemos|Subject),data = Orthodont)
>>>>> Linear mixed-effects model fit by REML
>>>>>   Data: Orthodont
>>>>>   Log-restricted-likelihood: -221.1833
>>>>>   Fixed: distance ~ agemos + factor(Sex)
>>>>>       (Intercept)            agemos factor(Sex)Female
>>>>>       17.72141619        0.05495041       -2.32748480
>>>>>
>>>>> Random effects:
>>>>>  Formula: ~1 | Subject
>>>>>         (Intercept) Residual
>>>>> StdDev:    1.788899 1.454494
>>>>>
>>>>> Correlation Structure: Continuous AR(1)
>>>>>  Formula: ~agemos | Subject
>>>>>  Parameter estimate(s):
>>>>>       Phi
>>>>> 0.8884427
>>>>> Number of Observations: 108
>>>>> Number of Groups: 27
>>>>>
>>>>>> .8884427^12
>>>>> [1] 0.2418539
>>>>>
>>>>> Thus, the two solutions agree. I agree, however, that it's slightly
>>>> disconcerting that lme() can't overcome the poor start value.
>>>>>
>>>>> I hope this helps,
>>>>>  John
>>>>>
>>>>> -----------------------------
>>>>> John Fox, Professor Emeritus
>>>>> McMaster University
>>>>> Hamilton, Ontario, Canada
>>>>> Web: socialsciences.mcmaster.ca/jfox/
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>> -----Original Message-----
>>>>>> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-
>>>>>> project.org] On Behalf Of Ferenci Tamas
>>>>>> Sent: Thursday, January 25, 2018 12:05 PM
>>>>>> To: r-sig-mixed-models at r-project.org
>>>>>> Subject: [R-sig-ME] bug or numerical problem in nlme's corCAR1
>>>>>>
>>>>>> Dear list members,
>>>>>>
>>>>>> Consider the following example (yes, I haven't centered age,
>>>>>> corCAR1 is not necessarily needed here etc., so it is perhaps not
>>>>>> the most meaningful model, I use it just to show the problem):
>>>>>>
>>>>>> lme(distance ~ age + factor(Sex),random = ~ 1 | Subject,
>>>>>>    cor=corCAR1(form=~age|Subject),data = Orthodont)
>>>>>>
>>>>>> Everything works perfectly.
>>>>>>
>>>>>> Let's now multiply age, say, we measure it in months:
>>>>>>
>>>>>> Orthodont$agemos <- Orthodont$age*12 lme(distance ~ agemos +
>>>>>> factor(Sex),random = ~ 1 | Subject,
>>>>>>     cor=corCAR1(form=~agemos|Subject),data = Orthodont)
>>>>>>
>>>>>> It shouldn't make any difference, but check the autocorrelation
>>>> coefficient!
>>>>>> It changed from 0.2418536 to 0.2... i.e. it stuck at its default
>>>>>> value, as if it was not optimized at all! (One can verify that it
>>>>>> is indeed the case, and 0.2 was not a coincidence by calling
>>>>>> lme(distance ~ agemos + factor(Sex),random = ~ 1 | Subject,
>>>>>> cor=corCAR1(0.1234,form=~agemos|Subject),data = Orthodont) which
>>>> will
>>>>>> return a coefficient of 0.1234 and so on.)
>>>>>>
>>>>>> What's going on...?
>>>>>>
>>>>>> Thank you in advance,
>>>>>> Tamas Ferenci
>>>>>>
>>>>>> _______________________________________________
>>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From Christoph.Scherber at uni-muenster.de  Fri Jan 26 13:46:57 2018
From: Christoph.Scherber at uni-muenster.de (Christoph Scherber)
Date: Fri, 26 Jan 2018 13:46:57 +0100
Subject: [R-sig-ME] Different results for between/within groups and
 within group regression analyses
In-Reply-To: <cffb13f7-d16f-2b5b-a090-debc90bbe87d@mpi.nl>
References: <da248a32-1d80-4cdd-9c96-7e80c199d086@mpi.nl>
 <CWXP265MB02168DCE36AA7142EEE8840DF6140@CWXP265MB0216.GBRP265.PROD.OUTLOOK.COM>
 <cffb13f7-d16f-2b5b-a090-debc90bbe87d@mpi.nl>
Message-ID: <2389ee71-7e05-ac95-0181-59af1fd1db2f@uni-muenster.de>

Dear Luca,

I?d usually use the Anova() function from John Fox?s car package for 
that. It will give you order-independent tests on the terms in your model.

Best wishes,
Christoph

Am 25.01.2018 um 23:30 schrieb Alday, Phillip:
> I don't think this set of questions was ever addressed in any of the subsequent threads on this or other forums .... and so I'll give you a quick non answer of bullet points:
>
>
> * "significance" should not be the driving force in whether or not an estimate is correct. While it does tell you something about the relative error in that estimate, but it tells you very little about how well that estimate describes the data or predicts future data.
>
>
> * Much as it is difficult and potentially problematic to interpret a main effect in the presence of interactions (after all, by definition, an interaction implies that the main effect changes conditional on another variable), it is also problematic to intentionally exclude a known interaction to better estimate the main effect.
>
>
> * However, this above advice has to be tempered by the issues related to statistical power, the bias-variance tradeoff and over- vs. underfitting -- a lot of preprints, journal articles and recent textbooks by members of this list and their collaborators have tried to address different aspects of this in the context of mixed models, but the issues are fundamentally the same for *all* statistical models. My advice is to find the parsimonious model that best describes the data (so the best model according to AIC or BIC) and look at the predictions that model makes and derive your inferences from that, instead of getting hung up on the significance of any one coefficient. The effects package can be particularly useful here, especially for plotting these things.
>
>
> Phillip
>
> On 13/01/18 23:07, Luca Danieli wrote:
> Hi Phillip,
>
> sorry if I ask you a question.
> In this moment I have a 3x4x8 matrix, where '3' is the number of groups, '8' the number of tests, and '4' the levels of the potential main effect.
>
> Following your explanation, I was before thinking that leaving interactions out of the models would give you a better approximation of the main effect. But now that I read it again, I am unsure about it.
>
> In my case, the '4' levels are nested in each set.
> If I write lmer(Score ~ pot_ME + random effects) I have no statistical significance.
> If I write lmer(Score ~ pot_ME*groups + random effects) I have statistical significance for the main effect (p<0.05) and a strong interaction (p<.001).
> If I write lmer(Score ~ pot_ME*groups*tests + random effects) I have no statistical significance nor interactions.
>
> What approach is the more correct to get information about the presence of a main effect?
>
> (My parameters are not-continuous)
>
> Best
> Luca
> ________________________________
> From: Alday, Phillip <Phillip.Alday at mpi.nl><mailto:Phillip.Alday at mpi.nl>
> Sent: 11 January 2018 15:38
> To: Luca Danieli; r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
> Subject: Re: [R-sig-ME] Different results for between/within groups and within group regression analyses
>
> I'll do it myself when I get the chance in the next day or so.  :-)
>
> Phillip
>
> ________________________________
> From: Luca Danieli <mr.lucedan at hotmail.it><mailto:mr.lucedan at hotmail.it>
> Sent: Thursday, January 11, 2018 10:26 AM
> To: Alday, Phillip; r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
> Subject: Re: [R-sig-ME] Different results for between/within groups and within group regression analyses
>
> Thank you Phillip!
>
> Can I add your answer to CrossValidated for future concerns by other users?
>
> Best
> Luca
> ________________________________
> From: Alday, Phillip <Phillip.Alday at mpi.nl><mailto:Phillip.Alday at mpi.nl>
> Sent: 11 January 2018 15:18
> To: Luca Danieli; r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
> Subject: Re: [R-sig-ME] Different results for between/within groups and within group regression analyses
>
> By only using one group, you're changing the amount of pooling going on, which affects shrinkage and the bias-variance / over- vs. underfitting tradeoff. When you fit a model to a subset, it will generally be better at describing that subset but often worse at describing the full set / other sets. In other words, your subset model better describes the subset because it doesn't have to spend "resources" describing the other data, but of course this also means that it will tend to not describe the other data as well - it's better at the small details but worse at the big picture.
>
> Best,
> Phillip
>
> Sent from my mobile, please excuse my brevity.
>
> ________________________________
> From: Luca Danieli <mr.lucedan at hotmail.it><mailto:mr.lucedan at hotmail.it>
> Sent: Thursday, January 11, 2018 10:10 AM
> To: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
> Subject: [R-sig-ME] Different results for between/within groups and within group regression analyses
>
>
> Dear all,
>
> from CrossValidates I was suggested to repost my question to you, as it is a technical question about R and mixed models.
> Particularly, as I have a thesis to hand in in a few weeks, I hope you are able to help me understanding some problems that I cannot figure out by myself.
>
> In this case, I have used the function lmer() to look for an interaction between groups and then used the function predict() to plot the fits for each group on a graphic.
> Then I applied the lmer() to just one of those groups (same formula, technically) and used the predict() function to plot the fits for that specific group. I was thinking to obtain the same graphic for that group type and instead I obtained two different results.
>
> I explained the process, models and presented the plots in this post:
> https://stats.stackexchange.com/questions/322608/different-results-for-between-within-groups-and-within-group-regression-analyses
>
> Can somebody help me understand this?
>
> Best
> Luca
>
>
>
> [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 

*Prof. Dr. Christoph Scherber*

Institute of Landscape Ecology
Animal ecology and multitrophic interactions 
<http://www.uni-muenster.de/tieroekologie/en/index.html>
Room 536
University of M?nster
Heisenbergstr. 2
48149 M?nster
Germany
phone +49(0)251-83 33 996
facsimile +49 (0)251 - 83 38 338

See also my Personal website <http://www.christoph-scherber.de>

____________________________________________________

*----See the following recently published manuscripts----*

  * *Biodiversity effects on ecosystem functioning in a 15-year
    grassland experiment: patterns, mechanisms, and open questions*
    <https://doi.org/10.1016/j.baae.2017.06.002>*(2017)*
  * *Consistent drivers of plant biodiversity across managed ecosystems
    <http://dx.doi.org/10.1098/rstb.2015.0284> (2016)*
  * *Trophic and Non-Trophic Interactions in a Biodiversity Experiment
    Assessed by Next-Generation Sequencing
    <http://dx.doi.org/10.1371/journal.pone.0148781> (2016)*
  * *Plant diversity increases spatio-temporal niche complementarity in
    plant-pollinator interactions
    <http://dx.doi.org/10.1002/ece3.2026>(2016)*
  * *Corridors restore animal-mediated pollination in fragmented
    tropical forest landscapes
    <http://rspb.royalsocietypublishing.org/content/283/1823/20152347>
    (2016) *


	[[alternative HTML version deleted]]


From Maarten.Jung at mailbox.tu-dresden.de  Fri Jan 26 17:54:20 2018
From: Maarten.Jung at mailbox.tu-dresden.de (Maarten Jung)
Date: Fri, 26 Jan 2018 17:54:20 +0100
Subject: [R-sig-ME] Specifying the correct LMM for 'unsual' data
In-Reply-To: <CAGLQsKcpKXYyHAAUi7jPKStYmSWGohkV2eVwCgLZ6_CCOZ3hXw@mail.gmail.com>
References: <CAHr4DyewQMU0gFTD9cWAWMO0kOEnHjn7SLQCZEcYf+ucKKKX2g@mail.gmail.com>
 <CAGLQsKcpKXYyHAAUi7jPKStYmSWGohkV2eVwCgLZ6_CCOZ3hXw@mail.gmail.com>
Message-ID: <CAHr4Dyd6O3tB+Dqq5oWSCdRd+WqAi0ap-PL+UaQy0dYdKAznKA@mail.gmail.com>

Hi Tom,

your suggestions for the categorical predictors make sense and are
conceptually a much better solution than collapsing everything into a
single predictor - many thanks for that!

I am aware of the partial pooling/shrinkage in the estimation process,
although for your suggestion there would literally be no data for the
VS-miss-condition. And I think that, in this case, the estimation would be
based on the younger children given that there are clearly more missing
data points for older children.

With my second question I was referring to the MAR (missing at random)
assumption of mixed models: "missing data on a given variable
may depend on other observed information, but does not depend on the data
that would have been observed but were in fact missing" (West, Welch &
Galecki, 2015).
I have read that including covariates which 'predict' the nonavailability
of data points should be included (but, to be honest, I have no idea how
this helps with the missing data) and wonder if the inclusion of say number
of hits (if this is a better predictor than age_group) would improve the
model.

Best,
Maarten

On Thu, Jan 25, 2018 at 4:08 PM, Tom Fritzsche <tom.fritzsche at uni-potsdam.de
> wrote:

> Hi Maarten,
>
> I would not collapse the task and the kind of response (hit/miss) into
> one condition predictor. They are conceptually independent as task is
> a manipulated factor and response a measured value (covariate in this
> model). Also, one of them can vary within pictures the other not (see
> model specification below).
>
> So my suggestion would be to have those two predictors:
>
> task: 2-level factor: PM, VS
> response: 2-level predictor: hit, miss
>
> Beware of how you specify the contrasts for (all of) the categorical
> predictors. The default treatment contrast is most likely not the most
> straight-forward way to interpret the model estimates.
>
> Regarding your questions:
>
> 1. Am I correct with the maximal linear mixed model specifications?
>
> With the changed predictors I think that this would be the maximal
> model. Response can vary also within pictures as each can be a hit or
> miss.
>
> lmer(dwell_time ~ age_group * task * response + (1 + task * response |
> participant) + (1 + response | picture), data)
>
>
> 2. I think that the data points in the PM-miss-condition (or
> PM-hit-condition) are not missing at random because they are missing if
> (and only if) there are 6 data point for the same participant in the
> PM-hit-condition (and vice versa). Do you think one has to worry about this
> and are there any suggestions how to deal with it?
>
> Imbalanced data sets and even missing design cells are not a problem
> for mixed models as they take the number of the observation into
> account (shrinkage).
>
> Best,
> Tom
>
> ---
>
> Tom Fritzsche
> University of Potsdam
> Department of Linguistics
> Karl-Liebknecht-Str. 24-25
> 14476 Potsdam
> Germany
>
> office: 14.140
> phone: +49 331 977 2296 <+49%20331%209772296>
> fax: +49 331 977 2095 <+49%20331%209772095>
> e-mail: tom.fritzsche at uni-potsdam.de
> web:    www.ling.uni-potsdam.de/~fritzsche
>
>
>
> On 25 January 2018 at 15:35, Maarten Jung
> <Maarten.Jung at mailbox.tu-dresden.de> wrote:
> > Dear list,
> >
> > a colleague of mine asked me to help her planing a linear mixed models
> > analysis and, as handling her data and the corresponding research
> questions
> > with lmer seems kind of tricky to me, I hope one of you can help me
> along.
> >
> > +++++++++++++++++++++++++++++++++++++
> > The experiment is as follows:
> >
> > Participants (46 younger and 45 older children) looked at a series of
> > pictures (one picture per trial) and had to solve two tasks
> consecutively:
> >
> > - Task block 1: Prospective memory (PM) task: while doing other tasks,
> > participants had to remember to press a specified button when they saw a
> > certain object
> > - Task block 2. Visual search: participants had only this one task ?
> > pressing a button as soon as possible when seeing a certain object
> >
> > Each child saw the same pictures in the same task block ? pictures 1-6 in
> > task block 1 and pictures 7-18 in task block 2. Each picture was
> presented
> > only once, so there were different pictures in the task blocks.
> >
> > Trials with target object in task 1 are allocated regarding the
> > participant?s reactions in PM hits (participants did press the button)
> and
> > PM misses (participants did not press the button). (Therefore, a certain
> > picture can be a PM hit trial for one child and a PM miss trial for the
> > other.) As there were six trials (= pictures), which contained the target
> > object, each participant can have a minimum of zero and a maximum of six
> PM
> > hits with the according number of PM misses.
> > Here is the number of PM hits per age group:
> >
> > Younger children:
> > - 2 children: 0 hits
> > - 9 children: 1 hit
> > - 8 children : 2 hits
> > - 12 children: 3 hits
> > - 4 children: 4 hits
> > - 4 children: 5 hits
> > - 7 children: 6 hits
> >
> > Older children
> > - 2 children: 0 hits
> > - 3 children: 1 hit
> > - 4 children: 2 hits
> > - 6 children: 3 hits
> > - 7 children: 4 hits
> > - 11 children: 5 hits
> > - 12 children: 6 hits
> >
> > (In the visual search task almost all children have pressed the button
> > correctly in all 12 visual search target trials).
> >
> > She is interested in how long participants looked at the PM and visual
> > search target, respectively, depending on if it was a PM hit, a PM miss
> or
> > a visual search hit and how this is influenced by the age group.
> Therefore,
> > she has got only one data point per trial. And if a participant has no PM
> > misses there is no data point at all in this condition for this
> participant.
> >
> > The variables are defined as follows:
> > - age_group: categorical predictor with 2 levels (younger and older
> > children)
> > - condition: categorical predictor with 3 levels (PM hit, PM miss, visual
> > search hit)
> > +++++++++++++++++++++++++++++++++++++
> >
> > My suggestion for the maximal linear mixed model would be:
> >
> > lmer(dwell_time ~ age_group*condition + (1 + condition|participant) +
> > (1|picture), data)
> >
> > I intentionally didn`t use (1 + condition|picture) here because there are
> > different pictures in the task blocks (see above) - hope this makes
> sense.
> >
> > I have two questions:
> > 1. Am I correct with the maximal linear mixed model specifications?
> > 2. I think that the data points in the PM-miss-condition (or
> > PM-hit-condition) are not missing at random because they are missing if
> > (and only if) there are 6 data point for the same participant in the
> > PM-hit-condition (and vice versa). Do you think one has to worry about
> this
> > and are there any suggestions how to deal with it?
> >
> > Best,
> > Maarten
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From Maarten.Jung at mailbox.tu-dresden.de  Fri Jan 26 17:57:54 2018
From: Maarten.Jung at mailbox.tu-dresden.de (Maarten Jung)
Date: Fri, 26 Jan 2018 17:57:54 +0100
Subject: [R-sig-ME] Df for 'random-intercept-only' model
In-Reply-To: <CAG_uk93cXhnWMKyMKafhjUh1m6NRBp_iOOGdzBLYN0bh7LfijQ@mail.gmail.com>
References: <CAHr4Dyd0vr-LQcdmwq6A+pHcbJUcS+uFGC_SV6_vDKTgqqQRLg@mail.gmail.com>
 <CAG_uk93cXhnWMKyMKafhjUh1m6NRBp_iOOGdzBLYN0bh7LfijQ@mail.gmail.com>
Message-ID: <CAHr4DyeYTwBymNP8im8zh4m+LJT=EyT-DBxBDgCmyonQb10tdA@mail.gmail.com>

Hi Rune,

many thanks for the bug fix!

Best,
Maarten

On Jan 25, 2018 15:21, "Rune Haubo" <rune.haubo at gmail.com> wrote:

Hi Maarten,

This is fixed in the development version of lmerTest on GitHub - you
may install with

library("devtools") # install if you don't have it already.
install_github("runehaubo/lmerTest?)

Furture bug-reports are also welcome here.

For your example data I get:

Linear mixed model fit by REML t-tests use Satterthwaite
approximations to degrees of
  freedom [merModLmerTest]
Formula: value ~ 1 + (1 | participant)
   Data: d

REML criterion at convergence: 430.6

Scaled residuals:
     Min       1Q   Median       3Q      Max
-1.95994 -0.51445  0.09534  0.47149  2.28058

Random effects:
 Groups      Name        Variance Std.Dev.
 participant (Intercept) 4.714    2.171
 Residual                1.945    1.395
Number of obs: 100, groups:  participant, 47

Fixed effects:
            Estimate Std. Error      df t value Pr(>|t|)
(Intercept)  15.0660     0.3529 44.6400   42.69   <2e-16 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1


Best regards
Rune (for the lmerTest developers)


On 20 January 2018 at 15:13, Maarten Jung
<Maarten.Jung at mailbox.tu-dresden.de> wrote:
> Dear list,
>
> I'm trying to get an estimate for the degrees of freedom of the following
> 'random-intercept-only' model: lmer(value ~ 1 + (1|participant), data =
d).
> Normally, I know that one can achieve this via the lmerTest package but in
> this case it doesn't seem to work.
>
> library(lmerTest)
>
> d <- structure(list(value = c(8.25313070764297, 17.0453980104411,
> 14.7103370498893, 15.8219809684075, 18.0962761595002, 15.0493332821287,
> 17.5226332786703, 18.0503969664744, 13.9450638512715, 16.5332566133129,
> 13.1299408088999, 15.7163333693101, 17.5128147209307, 13.8564235534667,
> 11.3690970113334, 11.458250790531, 12.4039353096013, 16.9168322671145,
> 14.5580055004946, 17.5039029057499, 17.4265303119576, 10.3394971583312,
> 14.3327437896945, 10.1075784647337, 13.5324234318869, 12.9997105711724,
> 18.0080570272635, 15.2842579562302, 15.2356443644651, 15.813831547332,
> 14.8905281019859, 12.9039538908697, 17.3783863341884, 16.0160603506154,
> 18.4540620620647, 8.68750928534364, 14.462724834603, 16.8719660771132,
> 16.3784470438622, 16.228431742704, 17.2260499546157, 14.4592109398455,
> 12.9768791191779, 16.0745074082946, 14.4003729683924, 18.3820335802969,
> 13.8298449655042, 13.3898039860578, 11.2943669087644, 11.3711693435468,
> 18.1917812063674, 13.5455973955032, 17.0505866395927, 15.6054278307471,
> 12.1163489978806, 16.5776960925959, 15.5595289759737, 13.1383036025308,
> 16.7858376357516, 18.5934575849391, 12.6122831749272, 17.0565311301485,
> 13.2374564449912, 15.6139433555906, 14.6293717224923, 17.3818235894563,
> 15.7412428493826, 22.1877337982038, 18.3842887975238, 10.0701573038888,
> 10.8804812404375, 11.7148149325827, 14.4690669558257, 14.50516878681,
> 17.9920135587834, 19.6609636797189, 14.3073652841217, 16.4785695045202,
> 12.6811309533188, 14.6032532299404, 12.3152507852885, 18.1340692925595,
> 15.4724734122014, 17.406638598528, 12.2625532078185, 11.8729946785576,
> 15.9063789963309, 15.8208702113247, 12.203938368013, 14.894840829895,
> 15.5397556234126, 17.0641047610171, 18.3147667118571, 16.3914422509424,
> 14.5539887230189, 15.2870912573834, 17.0165733030807, 16.5537600282835,
> 12.1300522052001, 18.291737264292), participant = structure(c(15L,
> 3L, 6L, 6L, 11L, 57L, 43L, 10L, 16L, 49L, 54L, 11L, 22L, 24L, 41L, 48L,
> 35L, 46L, 59L, 23L, 55L, 41L, 39L, 15L, 60L, 52L, 5L,
> 48L, 33L, 50L, 2L, 53L, 11L, 47L, 19L, 15L, 60L, 22L, 31L, 21L, 11L, 59L,
> 24L, 50L, 20L, 5L, 14L, 3L, 39L, 18L, 9L, 33L, 46L,
> 49L, 38L, 19L, 33L, 46L, 45L, 22L, 14L, 10L, 4L, 33L, 44L, 43L, 47L, 13L,
> 22L, 42L, 35L, 38L, 40L, 33L, 10L, 2L, 55L, 40L, 48L,
> 57L, 41L, 16L, 2L, 8L, 48L, 47L, 30L, 7L, 48L, 6L, 44L, 9L, 22L, 9L, 56L,
> 40L, 6L, 59L, 3L, 26L), .Label = c("1", "2", "3", "4",
> "5", "6", "7", "8", "9", "10", "11", "12", "13", "14", "15", "16", "17",
> "18", "19", "20", "21", "22", "23", "24", "25", "26",
> "27", "28", "29", "30", "31", "32", "33", "34", "35", "36", "37", "38",
> "39", "40", "41", "42", "43", "44", "45", "46", "47", "48",
> "49", "50", "51", "52", "53", "54", "55", "56", "57", "58", "59", "60"),
> class = "factor")), .Names = c("value", "participant"), row.names = c(NA,
> -100L), class = c("tbl_df", "tbl", "data.frame"))
>
> summary(m1 <- lmer(value ~ 1 + (1|participant), data = d))
>
> Running this code returns "summary from lme4 is returned. some
> computational error has occurred in lmerTest".
>
>
> Thanks a lot for any help!
>
>
> Best,
>
> Maarten
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From pgreenw1 at gmu.edu  Fri Jan 26 23:37:58 2018
From: pgreenw1 at gmu.edu (P Greenwood)
Date: Fri, 26 Jan 2018 17:37:58 -0500
Subject: [R-sig-ME] subjects within groups and effects of group
In-Reply-To: <ca89fd98-0528-0777-7d54-ca59eebce535@mpi.nl>
References: <CC4B04FD-6934-4E94-B9A6-8E7AA8FBA33A@gmu.edu>
 <CAJuCY5xjL6wb5MxQs=MMum9BcqK-2QD6YNuythpa0a23uknT6g@mail.gmail.com>
 <99620d09-4dd7-5dac-e46e-4eb205be9cf7@mpi.nl>
 <B9A8DD23-7CFB-4380-A6C0-22E35F661F6E@gmu.edu>
 <CB5DAA4D-57A8-45C5-948B-336B235350BF@gmu.edu>
 <CAJuCY5yPSDBrejqwNV=VO30yS30+1f+rzjDDUikOwE+QF6QoYQ@mail.gmail.com>
 <ca89fd98-0528-0777-7d54-ca59eebce535@mpi.nl>
Message-ID: <0DAB7B5E-3B2B-4077-A75B-70424EB71599@gmu.edu>

Dear Dr. Alday

Could you elaborate a bit on your answer to my question in decomposing the effect of condition. Condition was randomly assigned to two groups of participants. I did include both levels of Condition in my analysis (the output I sent originally). One approach might be to use the Anova command to perform a likelihood ratio test to compare a model that includes condition with a model that does not include condition. (Perhaps that is what you mean by ?test the difference??)  However, I would like to know how effects of spectral power (Alpha) over Drive vary as a function of Condition. 

Thanks also for the information on sequence information. 

Thanks so much

Pam


P.M. Greenwood, Ph.D.
Associate Professor of Psychology
Editorial Board, NeuroImage
David King Hall 2052
George Mason University
MSN 3F5, 4400 University Drive
Fairfax, VA 22030-4444

Ph: 703 993-4268
fax: 703 993-1359
email: Pgreenw1 at gmu.edu
http://psychology.gmu.edu/people/pgreenw1

> On Jan 25, 2018, at 5:44 PM, Alday, Phillip <Phillip.Alday at mpi.nl> wrote:
> 
> Completely agree with Thierry here. 
> In addition to the usual considerations about the bias-variance tradeoff and partial pooling, you need to have things in one model if you really want to compare them. The Difference Between ?Significant? and ?Not Significant? is not Itself Statistically Significant (Gelman and Stern 2012, doi:10.1198/000313006X152649 <https://secure-web.cisco.com/1K0nLxMcHeaEQ3zltL5zGKV6Wf3PuASMvvhRXl8z8qKf_35cqaaAeKSo2Q9Jln-azfrr34PbzOOlzZaZYuDWxL5arm_4R9mtGR3Sfsj9-ShTlNCxMGN06gFN5920BieQ1AbiUfjBLRNCvTRcAUTTNlwGGWzVpfqdGudEkiQ-lN89uB95el2DuEfyJW_E5dtTTKpWwSEYaJQc-1ZqKU74d4imV2ENHCLwror_8EZuYaZ51caefF2SHC0JYTTA_uKYgP_FECA8Q_-j4IjYDn_ZmjdvhekseOw9ixb4f2uGavmMS9iVdBAbeqT7xIO8l66l4yZaRUC7isfxVvlhJDIVb4-gRWFgjzG6uSmMzHBhJL44Y26l0SXjQcNYytqFIhCBmM8ZP-SmusBWVAQAymVxHbPAYWXgqpQif7ESbchFfnl3NrBmMQzazxgNQt-ymStEY0d-GMFAIpZfZxFmXh9Y570HQn5LungV8fQy2VbMa-yw/https%3A%2F%2Fdoi.org%2F10.1198%2F000313006X152649>), so if you care about the significance of the difference, then you need to actually test the difference!
> For your other question
> 
> 
>> Trial refers to stimulus events.  The stimuli are the same on each Trial, although the order of the Trials varies between Drives.   But, yes, Trial is a sequence number for the repetition so that there could be some adaptation or change in response related to number of exposures.  (Assuming that is what you meant).  How would I include Trial as a continuous fixed effect?
> 
> I would use slightly different names to make things clear. Separate 'Trial' (a fixed series of stimuli) from SeqNo (the sequential position of a given Trial within a Drive).
> Then your model looks something like this:
> lmer(RT ~ 1 + Condition*PzAlpha + Drive + SeqNo + (1 | subject) + (1 | trial)
> 
> I've left out any interactions there, but I suspect you'll at least have an interaction with alpha and sequence number -- I imagine that later trials (i.e. higher sequence numbers) will have worse RTs (exhaustion effects) as will trials with higher alpha power and that this two effects will enhance each other. 
> Including sequence information in the model has received some attention in the psycholinguistic as well as the broader psychology literature as a way of controlling for adapt ion effects. GAMMs have been proposed for such cases to allow for non linear adaptation effects, but I wouldn't mess around with that until you feel much more comfortable with the standard LMMs.
> 
> And of course, if SeqNo doesn't improve model fit, you can simply omit it for parsimony and easy of both interpretation and fitting.
> 
> Phillip
> 
> On 25/01/18 17:33, Thierry Onkelinx wrote:
>> Dear Pam,
>> 
>> I'd probably combine both datasets in a single analysis.
>> 
>> Best regards,
>> 
>> ir. Thierry Onkelinx
>> Statisticus / Statistician
>> 
>> Vlaamse Overheid / Government of Flanders
>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
>> AND FOREST
>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
>> thierry.onkelinx at inbo.be <mailto:thierry.onkelinx at inbo.be>
>> Havenlaan 88 bus 73, 1000 Brussel
>> www.inbo.be <http://www.inbo.be/>
>> 
>> ///////////////////////////////////////////////////////////////////////////////////////////
>> To call in the statistician after the experiment is done may be no
>> more than asking him to perform a post-mortem examination: he may be
>> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does
>> not ensure that a reasonable answer can be extracted from a given body
>> of data. ~ John Tukey
>> ///////////////////////////////////////////////////////////////////////////////////////////
>> 
>> 
>> 
>> 
>> 2018-01-24 14:02 GMT+01:00 P Greenwood <pgreenw1 at gmu.edu> <mailto:pgreenw1 at gmu.edu>:
>>> Dear Drs Alday and Onkelinx
>>> 
>>> I wondered if you had thoughts on the best way to conduct followup analysis
>>> of the between-subjects Condition to which people were randomly assigned.
>>> 
>>> Pam Greenwood
>>> 
>>> P.M. Greenwood, Ph.D.
>>> Associate Professor of Psychology
>>> Editorial Board, NeuroImage
>>> David King Hall 2052
>>> George Mason University
>>> MSN 3F5, 4400 University Drive
>>> Fairfax, VA 22030-4444
>>> 
>>> Ph: 703 993-4268
>>> fax: 703 993-1359
>>> email: Pgreenw1 at gmu.edu <mailto:Pgreenw1 at gmu.edu>
>>> http://psychology.gmu.edu/people/pgreenw1 <http://psychology.gmu.edu/people/pgreenw1>
>>> 
>>> On Jan 19, 2018, at 8:09 AM, P Greenwood <pgreenw1 at gmu.edu> <mailto:pgreenw1 at gmu.edu> wrote:
>>> 
>>> Thanks to you both.
>>> 
>>> Trial refers to stimulus events.  The stimuli are the same on each Trial,
>>> although the order of the Trials varies between Drives.   But, yes, Trial is
>>> a sequence number for the repetition so that there could be some adaptation
>>> or change in response related to number of exposures.  (Assuming that is
>>> what you meant).  How would I include Trial as a continuous fixed effect?
>>> 
>>> If the effect of Condition were ?significant.? how would one decompose that
>>> to examine each group (Condition) separately?
>>> 
>>> Regards
>>> 
>>> Pam
>>> 
>>> 
>>> P.M. Greenwood, Ph.D.
>>> Associate Professor of Psychology
>>> Editorial Board, NeuroImage
>>> David King Hall 2052
>>> George Mason University
>>> MSN 3F5, 4400 University Drive
>>> Fairfax, VA 22030-4444
>>> 
>>> Ph: 703 993-4268
>>> fax: 703 993-1359
>>> email: Pgreenw1 at gmu.edu <mailto:Pgreenw1 at gmu.edu>
>>> http://psychology.gmu.edu/people/pgreenw1 <http://psychology.gmu.edu/people/pgreenw1>
>>> 
>>> On Jan 19, 2018, at 5:58 AM, Phillip Alday <phillip.alday at mpi.nl> <mailto:phillip.alday at mpi.nl> wrote:
>>> 
>>> Dear Pam, (dear Thierry,)
>>> 
>>> if I'm reading the description correctly, Pam is conceiving of Trial as
>>> being an "Item"-type factor (crossed with subject). To rephrase
>>> Thierry's comment a bit -- if Trial corresponds to an Item (concrete
>>> stimulus realization sampled from the population of possible stimuli for
>>> this manipulation) that is the same across subjects, then this is a good
>>> way to model that. If Trial doesn't correspond to an invariant set of
>>> items, but is rather just repetitions of the same task (perhaps with
>>> some random variation that isn't identical across subjects), then
>>> modeling Trial as a random effect doesn't really help much. However, if
>>> Trial is just a sequence number for the repetition, it might make sense
>>> to instead include Trial as a continuous fixed effect in order to model
>>> adaptation effects.
>>> 
>>> Best,
>>> Phillip
>>> 
>>> On 19/01/18 10:44, Thierry Onkelinx wrote:
>>> 
>>> Dear Pam,
>>> 
>>> You are handling condition and subject correctly.
>>> 
>>> There might be a problem with trial. Does trial indicates dependent
>>> replication of the study? Is there a common effect of trial X for all
>>> subjects? Because that is what your current model assumes. In case the
>>> trials are independent, then you don't need to include it in the
>>> model.
>>> 
>>> Note that Condition + PzAlpha + PzAlpha*Condition is verbose. You can
>>> write it as PzAlpha*Condition.
>>> 
>>> Best regards,
>>> 
>>> ir. Thierry Onkelinx
>>> Statisticus / Statistician
>>> 
>>> Vlaamse Overheid / Government of Flanders
>>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
>>> AND FOREST
>>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
>>> thierry.onkelinx at inbo.be <mailto:thierry.onkelinx at inbo.be>
>>> Havenlaan 88 bus 73, 1000 Brussel
>>> www.inbo.be <http://www.inbo.be/>
>>> 
>>> ///////////////////////////////////////////////////////////////////////////////////////////
>>> To call in the statistician after the experiment is done may be no
>>> more than asking him to perform a post-mortem examination: he may be
>>> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
>>> The plural of anecdote is not data. ~ Roger Brinner
>>> The combination of some data and an aching desire for an answer does
>>> not ensure that a reasonable answer can be extracted from a given body
>>> of data. ~ John Tukey
>>> ///////////////////////////////////////////////////////////////////////////////////////////
>>> 
>>> 
>>> 
>>> 
>>> 2018-01-18 18:51 GMT+01:00 P Greenwood <pgreenw1 at gmu.edu> <mailto:pgreenw1 at gmu.edu>:
>>> 
>>> Hello
>>> 
>>> I wanted some advice about handling subjects within groups and effects of
>>> group (randomly assigned).  I want to predict reaction time (RT) as a
>>> function of  ?Condition,?  alpha band power (PzAlpha), and drive. People
>>> (subjects) are randomly assigned to Condition, of which there are two. Each
>>> person has data from 5 drives, and for each drive there are 10 trials.
>>> There are 19 subjects in one group and 20 in the other.
>>> 
>>> My question is this: Am I handling the ?between subjects? factor of
>>> Condition correctly?  Also, am I treating subjects within group correctly?
>>> I am pasting in some of my data.  The output is below.
>>> 
>>> Regards
>>> 
>>> Pam Greenwood
>>> 
>>> library(lme4)
>>> library(lmerTest)
>>> INFAST_Behavioral <- read.csv(??.
>>> na.omit(INFAST_Behavioral)
>>> INFAST_Behavioral$RT = scale(INFAST_Behavioral$RT, center = TRUE, scale =
>>> TRUE)
>>> INFAST_Behavioral$PzAlpha = scale(INFAST_Behavioral$PzAlpha, center = TRUE,
>>> scale = TRUE)
>>> sumModelInteraction <- lmer(RT ~ 1 + (Condition + PzAlpha + Drive +
>>> PzAlpha*Condition) + (1 | subject) + (1 | trial), data = INFAST_Behavioral)
>>> summary(sumModelInteraction)
>>> 
>>> subject Condition               Drive           trial   FzAlpha CzAlpha
>>> PzAlpha FzTheta CzTheta PzTheta FzDelta CzDelta PzDelta         RT      ACC
>>> 1       HumanLanguage   1       1       -1.41   -4.3585 -5.5431 6.1516
>>> 1.5911  3.6247  22.38   18.181 13.812          1568.984857     1
>>> 1       HumanLanguage   1       2       -7.8605 2.0156  4.7392  15.992
>>> 12.122  6.9088  26.861 20.592  16.326  1721.359714     1
>>> 1       HumanLanguage   1       3       -2.6982 -5.6067 -10.038 6.285
>>> 5.5172  1.2894  13.565 12.981  11.63   1257.092571     1
>>> 1       HumanLanguage   1       4       3.3975  4.8789  -1.3249 7.0177
>>> 9.6703  6.1539  10.231 12.261  12.485  1559.461429     1
>>> ?(skipping to Subject 2)
>>> 2       HumanLanguage                   1       1       1.6791  2.8887
>>> 0.28174 -11.387 -9.9352 3.5936 -1.5767 3.9401  6.7201          1302.328857
>>> 1
>>> 2       HumanLanguage   1       2       -13.284 -8.2603 -6.6124 -5.9373
>>> -8.7551 0.10394 4.5621 10.204  12.261  969.0088571     1
>>> 2       HumanLanguage   1       3       -0.048973       1.1329  0.67399
>>> -2.1432 2.5077  -2.4641 9.4667 10.883  7.1396  721.3997143     1
>>> 2       HumanLanguage   1       4       5.0779  6.8916  6.3892  -1.8682
>>> 3.1637  7.9712  8.0994 10.883  10.975  707.1145714     1
>>> 2       HumanLanguage   1       5       -7.0495 -2.782  3.1668  8.4332
>>> 10.646  9.3726  -3.5937 -7.3769 5.4472  892.8214286     1
>>> 2       HumanLanguage   1       6       -1.462  -8.1223 -6.5896 -10.895
>>> -5.6311 0.39941 7.5473 12.783  14.698  611.8802857     1
>>> 2       HumanLanguage   1       7       -2.6402 -5.1213 -3.7372 3.4542
>>> 4.2234  -0.99898        1.4089 4.1976  0.56587 761.8742857     1
>>> 2       HumanLanguage   1       8       3.4393  4.6302  1.5525  1.4604
>>> 3.1716  3.1622  -2.3427 2.908 4.2259  680.9251429     1
>>> 2       HumanLanguage   1       9       -0.81024        -0.21642
>>> -2.3876 2.5839  4.7307  1.5441 3.3761  8.4485  12.02   769.0168571     1
>>> 2       HumanLanguage   1       10      -6.4045 -4.4937 -2.2449 0.94456
>>> 2.7048  0.65565 -1.9791 0.26436 1.8435  885.6788571     1
>>> 
>>> Results:
>>> 
>>> Linear mixed model fit by REML t-tests use Satterthwaite approximations to
>>> degrees of freedom [
>>> lmerMod]
>>> Formula: RT ~ 1 + (Condition + PzAlpha + Drive + PzAlpha * Condition) +
>>>    (1 | subject) + (1 | trial)
>>>   Data: INFAST_Behavioral
>>> 
>>> REML criterion at convergence: 3876.4
>>> 
>>> Scaled residuals:
>>>    Min      1Q  Median      3Q     Max
>>> -3.4308 -0.5227 -0.1194  0.3547  8.4095
>>> 
>>> Random effects:
>>> Groups   Name        Variance Std.Dev.
>>> subject  (Intercept) 0.580073 0.76163
>>> trial    (Intercept) 0.004778 0.06912
>>> Residual             0.434918 0.65948
>>> Number of obs: 1839, groups:  subject, 39; trial, 10
>>> 
>>> Fixed effects:
>>>                                         Estimate               Std. Error
>>> df t value Pr(>|t|)
>>> (Intercept)                        -0.27054    0.17607   40.80000  -1.537
>>> 0.13213
>>> ConditionMachineLang 0.41644    0.24595   36.90000   1.693  0.09884 .
>>> PzAlpha                             0.01192    0.02411 1797.40000   0.494
>>> 0.62117
>>> Drive                               0.02948    0.01083 1788.40000   2.722
>>> 0.00655 **
>>> ConditionMachineLanguage:PzAlpha   -0.01998    0.03476 1803.10000  -0.575
>>> 0.56560
>>> ---
>>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>> P.M. Greenwood, Ph.D.
>>> Associate Professor of Psychology
>>> Editorial Board, NeuroImage
>>> David King Hall 2052
>>> George Mason University
>>> MSN 3F5, 4400 University Drive
>>> Fairfax, VA 22030-4444
>>> 
>>> Ph: 703 993-4268
>>> fax: 703 993-1359
>>> email: Pgreenw1 at gmu.edu <mailto:Pgreenw1 at gmu.edu>
>>> http://psychology.gmu.edu/people/pgreenw1 <http://psychology.gmu.edu/people/pgreenw1>
>>> 
>>> 
>>>        [[alternative HTML version deleted]]
>>> 
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org <mailto:R-sig-mixed-models at r-project.org> mailing list
>>> https://secure-web.cisco.com/1joP--B1_xWT50x7mVQZsmihBAOqrRroakmdBR5MIMiOARC9Fd1hE1yw-1sCnwGxdnwBghNSYF9p3BRdhCaL0o-KBtN4F3VSOMBOaVY1oHIj6WYPh_sr8e-zRksQa9F4ECA_XGS2Afp73TF2WsPYwPhZh0vxQMs_BOy--csyKCdriarDzsvIs-lPMcfSch2Ym2oCTwBXQ_YkEWQehip65TFdXUagB8dg1r-d1G0r841y-84pF20_DPQ6J18R57bYFsQp5D34gsd2C2Jf6WMFXlHUZLbGyg7TV0F8CEvUF6vNcNdjIJTUSz79up7bz_iYDKOezABzwahOdHoC45jHqvTmDYhjaqzCkPsymio7HL4h8UlFKyj0xzrIe3rEFvRQsMaNQdctVCMacfdjj-nJiV9Ab0-aVDdezvOlj8IwbPCwr9QwTBeZzUqOwf5ENxq1r/https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models <https://secure-web.cisco.com/1joP--B1_xWT50x7mVQZsmihBAOqrRroakmdBR5MIMiOARC9Fd1hE1yw-1sCnwGxdnwBghNSYF9p3BRdhCaL0o-KBtN4F3VSOMBOaVY1oHIj6WYPh_sr8e-zRksQa9F4ECA_XGS2Afp73TF2WsPYwPhZh0vxQMs_BOy--csyKCdriarDzsvIs-lPMcfSch2Ym2oCTwBXQ_YkEWQehip65TFdXUagB8dg1r-d1G0r841y-84pF20_DPQ6J18R57bYFsQp5D34gsd2C2Jf6WMFXlHUZLbGyg7TV0F8CEvUF6vNcNdjIJTUSz79up7bz_iYDKOezABzwahOdHoC45jHqvTmDYhjaqzCkPsymio7HL4h8UlFKyj0xzrIe3rEFvRQsMaNQdctVCMacfdjj-nJiV9Ab0-aVDdezvOlj8IwbPCwr9QwTBeZzUqOwf5ENxq1r/https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models>
>>> 
>>> 
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org <mailto:R-sig-mixed-models at r-project.org> mailing list
>>> https://secure-web.cisco.com/1joP--B1_xWT50x7mVQZsmihBAOqrRroakmdBR5MIMiOARC9Fd1hE1yw-1sCnwGxdnwBghNSYF9p3BRdhCaL0o-KBtN4F3VSOMBOaVY1oHIj6WYPh_sr8e-zRksQa9F4ECA_XGS2Afp73TF2WsPYwPhZh0vxQMs_BOy--csyKCdriarDzsvIs-lPMcfSch2Ym2oCTwBXQ_YkEWQehip65TFdXUagB8dg1r-d1G0r841y-84pF20_DPQ6J18R57bYFsQp5D34gsd2C2Jf6WMFXlHUZLbGyg7TV0F8CEvUF6vNcNdjIJTUSz79up7bz_iYDKOezABzwahOdHoC45jHqvTmDYhjaqzCkPsymio7HL4h8UlFKyj0xzrIe3rEFvRQsMaNQdctVCMacfdjj-nJiV9Ab0-aVDdezvOlj8IwbPCwr9QwTBeZzUqOwf5ENxq1r/https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models <https://secure-web.cisco.com/1joP--B1_xWT50x7mVQZsmihBAOqrRroakmdBR5MIMiOARC9Fd1hE1yw-1sCnwGxdnwBghNSYF9p3BRdhCaL0o-KBtN4F3VSOMBOaVY1oHIj6WYPh_sr8e-zRksQa9F4ECA_XGS2Afp73TF2WsPYwPhZh0vxQMs_BOy--csyKCdriarDzsvIs-lPMcfSch2Ym2oCTwBXQ_YkEWQehip65TFdXUagB8dg1r-d1G0r841y-84pF20_DPQ6J18R57bYFsQp5D34gsd2C2Jf6WMFXlHUZLbGyg7TV0F8CEvUF6vNcNdjIJTUSz79up7bz_iYDKOezABzwahOdHoC45jHqvTmDYhjaqzCkPsymio7HL4h8UlFKyj0xzrIe3rEFvRQsMaNQdctVCMacfdjj-nJiV9Ab0-aVDdezvOlj8IwbPCwr9QwTBeZzUqOwf5ENxq1r/https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models>
>>> 
>>> 
>>> 
> 


	[[alternative HTML version deleted]]


From aglowka at stanford.edu  Sat Jan 27 23:19:35 2018
From: aglowka at stanford.edu (=?UTF-8?Q?Aleksander_G=c5=82=c3=b3wka?=)
Date: Sat, 27 Jan 2018 14:19:35 -0800
Subject: [R-sig-ME] bootstrapping coefficient p-values under null hypothesis
 in case-resampling multiple linear mixed-effects regression
Message-ID: <935f50d9-02d5-ddd9-c196-6989bc0d652b@stanford.edu>

Dear mixed-effects community,

I am fitting a multiple linear mixed-effects regression model in lme4. 
The residual fit is near-linear, enough to warrant not assuming residual 
homoscedasticity. One way to model regression without explicitly making 
this assumption is to use case-resampling regression (Davison & Hinkley 
1997), an application of the bootstrap (Efron & Tibshirani 1993).

In case-resampling regression, rather than assuming a normal 
distribution for the T-statistic, we estimate the distribution of T 
empirically. We mimic sampling from the original population by treating 
the original sample as if it were the population: for each bootstrap 
sample of size n we randomly select n values with replacement from the 
original sample and then fit regression giving estimates, repeating this 
procedure R times.

Having applied this procedure, I am trying to calculate empirical 
p-values for my regression coefficients. As in parametric regression, I 
want to conduct the two-tailed hypothesis test of significance for slope 
with test statistic T under the null hypothesis H0:?^1=0. Since we are 
treating the original sample as the population, our T=t is the observed 
value from the original sample. For ?^{0,1,?,p} We calculate the p-value 
as follows:

(1) min(p=(1{T?t}/R),p=(1{T?t})/R)

Davison and Hinkley take t=?^1

so that, in practice

(2) min(p=(1{??^1??^1}+1)/(R+1),p=(1{??^1??^1}+1)/(R+1))

The major problem here is that the bootstrap samples were not sampled 
under the null hypothesis, so in (1) and (2) we are evaluating the 
alternative hypothesis rather than the null. Efron & Tibshirani (1993) 
indeed caution that all hypothesis testing must be performed by sampling 
under the null. This is relatively simple for, say, testing the 
difference between two means, where the null H0:?1=?2, and which 
requires a simple transformation of the data prior to sampling.

So my question here is: how do I perform significance testing under the 
null hypothesis in case-resampling regression? As far as I could see, 
neither Davison & Hinkley (1997) nor Efron & Tibshirani (1993) seem to 
mention how to sample under the null. Is there some adjustment that I 
can introduce before (to the data) or after case-resampling (to the 
least-squares formula) in a way that is easily implementable in R and 
lme4? Any ideas and or algorithms would be greatly appreciated.

N.B. With all due respect, please don?t advise me to fit a GLM instead 
or to talk directly with Rob Tibshirani.

Thank you,

Aleksander Glowka
PhD Candidate in Linguistics
Stanford University

Works cited:

Davison, A. C. and D. V. Hinkley (1997). Bootstrap Methods and their 
Applications. Cambridge, England: Cambridge University Press.

Efron, B. and Tibshirani, R.J. (1993). An Introduction to the Bootstrap. 
New York: Champman & Hall.


From bbolker at gmail.com  Sun Jan 28 00:02:07 2018
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 27 Jan 2018 18:02:07 -0500
Subject: [R-sig-ME] bootstrapping coefficient p-values under null
 hypothesis in case-resampling multiple linear mixed-effects regression
In-Reply-To: <935f50d9-02d5-ddd9-c196-6989bc0d652b@stanford.edu>
References: <935f50d9-02d5-ddd9-c196-6989bc0d652b@stanford.edu>
Message-ID: <ea333a2a-f00a-0d86-29bb-97d616b40951@gmail.com>


  I don't know. But I have the following suggestions/questions:

- the closest/simplest analogue for what you want to do would seem to be
a *permutation test*: that is, rather than sampling your data with
replacement, sample the predictor variables _without_ replacement, to
simulate the null hypothesis (independence between predictors and responses)
- alternatively you could try robust methods, e.g. the robustlmm package

On 18-01-27 05:19 PM, Aleksander G??wka wrote:
> Dear mixed-effects community,
> 
> I am fitting a multiple linear mixed-effects regression model in lme4.
> The residual fit is near-linear, enough to warrant not assuming residual
> homoscedasticity. One way to model regression without explicitly making
> this assumption is to use case-resampling regression (Davison & Hinkley
> 1997), an application of the bootstrap (Efron & Tibshirani 1993).
> 
> In case-resampling regression, rather than assuming a normal
> distribution for the T-statistic, we estimate the distribution of T
> empirically. We mimic sampling from the original population by treating
> the original sample as if it were the population: for each bootstrap
> sample of size n we randomly select n values with replacement from the
> original sample and then fit regression giving estimates, repeating this
> procedure R times.
> 
> Having applied this procedure, I am trying to calculate empirical
> p-values for my regression coefficients. As in parametric regression, I
> want to conduct the two-tailed hypothesis test of significance for slope
> with test statistic T under the null hypothesis H0:?^1=0. Since we are
> treating the original sample as the population, our T=t is the observed
> value from the original sample. For ?^{0,1,?,p} We calculate the p-value
> as follows:
> 
> (1) min(p=(1{T?t}/R),p=(1{T?t})/R)
> 
> Davison and Hinkley take t=?^1
> 
> so that, in practice
> 
> (2) min(p=(1{??^1??^1}+1)/(R+1),p=(1{??^1??^1}+1)/(R+1))
> 
> The major problem here is that the bootstrap samples were not sampled
> under the null hypothesis, so in (1) and (2) we are evaluating the
> alternative hypothesis rather than the null. Efron & Tibshirani (1993)
> indeed caution that all hypothesis testing must be performed by sampling
> under the null. This is relatively simple for, say, testing the
> difference between two means, where the null H0:?1=?2, and which
> requires a simple transformation of the data prior to sampling.
> 
> So my question here is: how do I perform significance testing under the
> null hypothesis in case-resampling regression? As far as I could see,
> neither Davison & Hinkley (1997) nor Efron & Tibshirani (1993) seem to
> mention how to sample under the null. Is there some adjustment that I
> can introduce before (to the data) or after case-resampling (to the
> least-squares formula) in a way that is easily implementable in R and
> lme4? Any ideas and or algorithms would be greatly appreciated.
> 
> N.B. With all due respect, please don?t advise me to fit a GLM instead
> or to talk directly with Rob Tibshirani.
> 
> Thank you,
> 
> Aleksander Glowka
> PhD Candidate in Linguistics
> Stanford University
> 
> Works cited:
> 
> Davison, A. C. and D. V. Hinkley (1997). Bootstrap Methods and their
> Applications. Cambridge, England: Cambridge University Press.
> 
> Efron, B. and Tibshirani, R.J. (1993). An Introduction to the Bootstrap.
> New York: Champman & Hall.
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From alethephant at verizon.net  Sun Jan 28 04:20:26 2018
From: alethephant at verizon.net (Robert LaBudde)
Date: Sat, 27 Jan 2018 22:20:26 -0500
Subject: [R-sig-ME] bootstrapping coefficient p-values under null
 hypothesis in case-resampling multiple linear mixed-effects regression
In-Reply-To: <935f50d9-02d5-ddd9-c196-6989bc0d652b@stanford.edu>
References: <935f50d9-02d5-ddd9-c196-6989bc0d652b@stanford.edu>
Message-ID: <136466f7-1d62-84c9-5c51-1d7bca790117@verizon.net>

If your null hypothesis is that variable X has a coefficient of zero in 
the model, would not sampling under the null hypothesis be done by case 
resampling of every variable except X, and then resample X from its set 
of values?

It would appear wise to just do case resampling and construct a 
confidence interval for the coefficient from the bootstrap. I avoid 
statistical testing as completely as possible.


On 1/27/2018 5:19 PM, Aleksander G??wka wrote:
> Dear mixed-effects community,
>
> I am fitting a multiple linear mixed-effects regression model in lme4. 
> The residual fit is near-linear, enough to warrant not assuming 
> residual homoscedasticity. One way to model regression without 
> explicitly making this assumption is to use case-resampling regression 
> (Davison & Hinkley 1997), an application of the bootstrap (Efron & 
> Tibshirani 1993).
>
> In case-resampling regression, rather than assuming a normal 
> distribution for the T-statistic, we estimate the distribution of T 
> empirically. We mimic sampling from the original population by 
> treating the original sample as if it were the population: for each 
> bootstrap sample of size n we randomly select n values with 
> replacement from the original sample and then fit regression giving 
> estimates, repeating this procedure R times.
>
> Having applied this procedure, I am trying to calculate empirical 
> p-values for my regression coefficients. As in parametric regression, 
> I want to conduct the two-tailed hypothesis test of significance for 
> slope with test statistic T under the null hypothesis H0:?^1=0. Since 
> we are treating the original sample as the population, our T=t is the 
> observed value from the original sample. For ?^{0,1,?,p} We calculate 
> the p-value as follows:
>
> (1) min(p=(1{T?t}/R),p=(1{T?t})/R)
>
> Davison and Hinkley take t=?^1
>
> so that, in practice
>
> (2) min(p=(1{??^1??^1}+1)/(R+1),p=(1{??^1??^1}+1)/(R+1))
>
> The major problem here is that the bootstrap samples were not sampled 
> under the null hypothesis, so in (1) and (2) we are evaluating the 
> alternative hypothesis rather than the null. Efron & Tibshirani (1993) 
> indeed caution that all hypothesis testing must be performed by 
> sampling under the null. This is relatively simple for, say, testing 
> the difference between two means, where the null H0:?1=?2, and which 
> requires a simple transformation of the data prior to sampling.
>
> So my question here is: how do I perform significance testing under 
> the null hypothesis in case-resampling regression? As far as I could 
> see, neither Davison & Hinkley (1997) nor Efron & Tibshirani (1993) 
> seem to mention how to sample under the null. Is there some adjustment 
> that I can introduce before (to the data) or after case-resampling (to 
> the least-squares formula) in a way that is easily implementable in R 
> and lme4? Any ideas and or algorithms would be greatly appreciated.
>
> N.B. With all due respect, please don?t advise me to fit a GLM instead 
> or to talk directly with Rob Tibshirani.
>
> Thank you,
>
> Aleksander Glowka
> PhD Candidate in Linguistics
> Stanford University
>
> Works cited:
>
> Davison, A. C. and D. V. Hinkley (1997). Bootstrap Methods and their 
> Applications. Cambridge, England: Cambridge University Press.
>
> Efron, B. and Tibshirani, R.J. (1993). An Introduction to the 
> Bootstrap. New York: Champman & Hall.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Robert A LaBudde, BS, MS, PhD, ChDipl ACAFS    President
Least Cost Formulations, Ltd                   URL: lcfltd.com
824 Timberlake Dr                              Tel: 757-467-0954
Virginia Beach, VA 23464                       Fax: 757-467-2947


From blazej.mrozinski at gmail.com  Sun Jan 28 17:43:08 2018
From: blazej.mrozinski at gmail.com (Blazej Mrozinski)
Date: Sun, 28 Jan 2018 17:43:08 +0100
Subject: [R-sig-ME] How to compare two coefficent estimates in a multilevel
	model?
Message-ID: <CANAWZx-s0jdyB1GcGGYy6mJA71L42e9k-tKxi9cXZaVEM_XhoA@mail.gmail.com>

Greetings,

Could anyone help me in answering the following question:

How can I compare two coefficient estimates from a lme4 or nlme model?

In HLM7 (software I'm more familiar with) such comparisons are evaluated
with ?2 tests. I can't find out what function in lme4, nlme or just base
can do the same.

An imaginary example I'm working with, is a modified sleepstudy dataset -
with two score variables added at level 2. The model being tested is this:

Level1:
Reaction=?0+r

Level2:
?0=?00+?01(score1)+?02(score2)+u0j

I'm looking for a ?2 comparing both level 2 coefficients (or 3+ if there
are more of them)

Here is my modified dataset:

library(lme4)

set.seed(123)
score1=NULL
score2=NULLfor(i in 1:18) {
      x1 = rep(sample(1:5, size = 1), 10)
      score1 = c(score1, x1)
      x2 = rep(sample(1:5, size = 1), 10)
      score2 = c(score2, x2)}

sleepstudy$score1 <- score1
sleepstudy$score2 <- score2

model <-lmer(Reaction ~ score1 + score2 + (1|Subject), data=sleepstudy)

Best regards,
Blazej Mrozinski

ps. this question was posted on CrossValidated:
https://stats.stackexchange.com/questions/325302/how-to-compare-two-coefficent-estimates-in-a-multilevel-model

	[[alternative HTML version deleted]]


From aglowka at stanford.edu  Sun Jan 28 22:12:27 2018
From: aglowka at stanford.edu (=?UTF-8?Q?Aleksander_G=c5=82=c3=b3wka?=)
Date: Sun, 28 Jan 2018 13:12:27 -0800
Subject: [R-sig-ME] bootstrapping coefficient p-values under null
 hypothesis in case-resampling multiple linear mixed-effects regression
In-Reply-To: <136466f7-1d62-84c9-5c51-1d7bca790117@verizon.net>
References: <935f50d9-02d5-ddd9-c196-6989bc0d652b@stanford.edu>
 <136466f7-1d62-84c9-5c51-1d7bca790117@verizon.net>
Message-ID: <5948e795-c4bb-c570-5f1b-95697746cbe5@stanford.edu>

Ben and Robert, thank you for your suggestions! I was not aware of the 
sampling variables approach, but it seems like a very reasonable way to 
proceed. It seems quite similar to random forest and boosting.

In my search I found another strategy, outlined in Godfrey (2009): for 
(multiple) regression, the null hypothesis is that there is no 
relationship between the predictors and the response. This is the case 
when all of the ? coefficients are zero, which leads to the response y 
also being 0! So in practice, sampling under the null hypothesis can be 
implemented by centering all y in the original data around 0 and then 
resampling cases.

Source: Godfrey, Leslie (2009): /Bootstrap Tests for Regression Models/. 
New York: Palgrave Macmillan.

Thanks,

Aleksander G??wka
PhD Candidate in Linguistics
Stanford University

On 1/27/2018 7:20 PM, Robert LaBudde wrote:
> If your null hypothesis is that variable X has a coefficient of zero 
> in the model, would not sampling under the null hypothesis be done by 
> case resampling of every variable except X, and then resample X from 
> its set of values?
>
> It would appear wise to just do case resampling and construct a 
> confidence interval for the coefficient from the bootstrap. I avoid 
> statistical testing as completely as possible.
>
>
> On 1/27/2018 5:19 PM, Aleksander G??wka wrote:
>> Dear mixed-effects community,
>>
>> I am fitting a multiple linear mixed-effects regression model in 
>> lme4. The residual fit is near-linear, enough to warrant not assuming 
>> residual homoscedasticity. One way to model regression without 
>> explicitly making this assumption is to use case-resampling 
>> regression (Davison & Hinkley 1997), an application of the bootstrap 
>> (Efron & Tibshirani 1993).
>>
>> In case-resampling regression, rather than assuming a normal 
>> distribution for the T-statistic, we estimate the distribution of T 
>> empirically. We mimic sampling from the original population by 
>> treating the original sample as if it were the population: for each 
>> bootstrap sample of size n we randomly select n values with 
>> replacement from the original sample and then fit regression giving 
>> estimates, repeating this procedure R times.
>>
>> Having applied this procedure, I am trying to calculate empirical 
>> p-values for my regression coefficients. As in parametric regression, 
>> I want to conduct the two-tailed hypothesis test of significance for 
>> slope with test statistic T under the null hypothesis H0:?^1=0. Since 
>> we are treating the original sample as the population, our T=t is the 
>> observed value from the original sample. For ?^{0,1,?,p} We calculate 
>> the p-value as follows:
>>
>> (1) min(p=(1{T?t}/R),p=(1{T?t})/R)
>>
>> Davison and Hinkley take t=?^1
>>
>> so that, in practice
>>
>> (2) min(p=(1{??^1??^1}+1)/(R+1),p=(1{??^1??^1}+1)/(R+1))
>>
>> The major problem here is that the bootstrap samples were not sampled 
>> under the null hypothesis, so in (1) and (2) we are evaluating the 
>> alternative hypothesis rather than the null. Efron & Tibshirani 
>> (1993) indeed caution that all hypothesis testing must be performed 
>> by sampling under the null. This is relatively simple for, say, 
>> testing the difference between two means, where the null H0:?1=?2, 
>> and which requires a simple transformation of the data prior to 
>> sampling.
>>
>> So my question here is: how do I perform significance testing under 
>> the null hypothesis in case-resampling regression? As far as I could 
>> see, neither Davison & Hinkley (1997) nor Efron & Tibshirani (1993) 
>> seem to mention how to sample under the null. Is there some 
>> adjustment that I can introduce before (to the data) or after 
>> case-resampling (to the least-squares formula) in a way that is 
>> easily implementable in R and lme4? Any ideas and or algorithms would 
>> be greatly appreciated.
>>
>> N.B. With all due respect, please don?t advise me to fit a GLM 
>> instead or to talk directly with Rob Tibshirani.
>>
>> Thank you,
>>
>> Aleksander Glowka
>> PhD Candidate in Linguistics
>> Stanford University
>>
>> Works cited:
>>
>> Davison, A. C. and D. V. Hinkley (1997). Bootstrap Methods and their 
>> Applications. Cambridge, England: Cambridge University Press.
>>
>> Efron, B. and Tibshirani, R.J. (1993). An Introduction to the 
>> Bootstrap. New York: Champman & Hall.
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Mon Jan 29 09:40:34 2018
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Mon, 29 Jan 2018 09:40:34 +0100
Subject: [R-sig-ME] How to compare two coefficent estimates in a
 multilevel model?
In-Reply-To: <CANAWZx-s0jdyB1GcGGYy6mJA71L42e9k-tKxi9cXZaVEM_XhoA@mail.gmail.com>
References: <CANAWZx-s0jdyB1GcGGYy6mJA71L42e9k-tKxi9cXZaVEM_XhoA@mail.gmail.com>
Message-ID: <CAJuCY5yOaXhEiLPttnx498VKN5-1db=G_N3kFqGjXvhZ-5JYoA@mail.gmail.com>

Dear Blazej,

Your question is not clear to me. What is the hypothesis that you want
to test? H_0: \gamma_{01} = \gamma_{02} ?

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
AND FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////




2018-01-28 17:43 GMT+01:00 Blazej Mrozinski <blazej.mrozinski at gmail.com>:
> Greetings,
>
> Could anyone help me in answering the following question:
>
> How can I compare two coefficient estimates from a lme4 or nlme model?
>
> In HLM7 (software I'm more familiar with) such comparisons are evaluated
> with ?2 tests. I can't find out what function in lme4, nlme or just base
> can do the same.
>
> An imaginary example I'm working with, is a modified sleepstudy dataset -
> with two score variables added at level 2. The model being tested is this:
>
> Level1:
> Reaction=?0+r
>
> Level2:
> ?0=?00+?01(score1)+?02(score2)+u0j
>
> I'm looking for a ?2 comparing both level 2 coefficients (or 3+ if there
> are more of them)
>
> Here is my modified dataset:
>
> library(lme4)
>
> set.seed(123)
> score1=NULL
> score2=NULLfor(i in 1:18) {
>       x1 = rep(sample(1:5, size = 1), 10)
>       score1 = c(score1, x1)
>       x2 = rep(sample(1:5, size = 1), 10)
>       score2 = c(score2, x2)}
>
> sleepstudy$score1 <- score1
> sleepstudy$score2 <- score2
>
> model <-lmer(Reaction ~ score1 + score2 + (1|Subject), data=sleepstudy)
>
> Best regards,
> Blazej Mrozinski
>
> ps. this question was posted on CrossValidated:
> https://stats.stackexchange.com/questions/325302/how-to-compare-two-coefficent-estimates-in-a-multilevel-model
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From blazej.mrozinski at gmail.com  Mon Jan 29 09:47:08 2018
From: blazej.mrozinski at gmail.com (Blazej Mrozinski)
Date: Mon, 29 Jan 2018 09:47:08 +0100
Subject: [R-sig-ME] How to compare two coefficent estimates in a
 multilevel model?
In-Reply-To: <CAJuCY5yOaXhEiLPttnx498VKN5-1db=G_N3kFqGjXvhZ-5JYoA@mail.gmail.com>
References: <CANAWZx-s0jdyB1GcGGYy6mJA71L42e9k-tKxi9cXZaVEM_XhoA@mail.gmail.com>
 <CAJuCY5yOaXhEiLPttnx498VKN5-1db=G_N3kFqGjXvhZ-5JYoA@mail.gmail.com>
Message-ID: <CANAWZx8dq1BWx=+ZyJipj_0kr_AEGJCojNCFn_2RNnh8BFjr_Q@mail.gmail.com>

Good Morning Thierry,
yes - that was my goal in this example.
Although I'm not what should I do if there where mode (say 3 or 4) fixed
effect estimates. I'd be guessing (based on Ben Bolker suggestion given on
StackOverflow) that contrasts set by hand are the right approach.
I already sorted out how to do it (with 2 estimates), in order to match
results from HLM software - that is
by using linearHypothesis function from car package:

library(car)
linearHypothesis(model, "score1=score2")
Linear hypothesis test

Hypothesis:
score1 - score2 = 0

Model 1: restricted model
Model 2: Reaction ~ score1 + score2 + (1 | Subject)

  Df  Chisq Pr(>Chisq)  1                       2  1 2.8187    0.09317 .---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1


https://stats.stackexchange.com/a/325502/133561

Best Regards,
Blazej

Blazej Mrozinski

2018-01-29 9:40 GMT+01:00 Thierry Onkelinx <thierry.onkelinx at inbo.be>:

> Dear Blazej,
>
> Your question is not clear to me. What is the hypothesis that you want
> to test? H_0: \gamma_{01} = \gamma_{02} ?
>
> Best regards,
>
> ir. Thierry Onkelinx
> Statisticus / Statistician
>
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
> AND FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Havenlaan 88 bus 73, 1000 Brussel
> www.inbo.be
>
> ////////////////////////////////////////////////////////////
> ///////////////////////////////
> To call in the statistician after the experiment is done may be no
> more than asking him to perform a post-mortem examination: he may be
> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does
> not ensure that a reasonable answer can be extracted from a given body
> of data. ~ John Tukey
> ////////////////////////////////////////////////////////////
> ///////////////////////////////
>
>
>
>
> 2018-01-28 17:43 GMT+01:00 Blazej Mrozinski <blazej.mrozinski at gmail.com>:
> > Greetings,
> >
> > Could anyone help me in answering the following question:
> >
> > How can I compare two coefficient estimates from a lme4 or nlme model?
> >
> > In HLM7 (software I'm more familiar with) such comparisons are evaluated
> > with ?2 tests. I can't find out what function in lme4, nlme or just base
> > can do the same.
> >
> > An imaginary example I'm working with, is a modified sleepstudy dataset -
> > with two score variables added at level 2. The model being tested is
> this:
> >
> > Level1:
> > Reaction=?0+r
> >
> > Level2:
> > ?0=?00+?01(score1)+?02(score2)+u0j
> >
> > I'm looking for a ?2 comparing both level 2 coefficients (or 3+ if there
> > are more of them)
> >
> > Here is my modified dataset:
> >
> > library(lme4)
> >
> > set.seed(123)
> > score1=NULL
> > score2=NULLfor(i in 1:18) {
> >       x1 = rep(sample(1:5, size = 1), 10)
> >       score1 = c(score1, x1)
> >       x2 = rep(sample(1:5, size = 1), 10)
> >       score2 = c(score2, x2)}
> >
> > sleepstudy$score1 <- score1
> > sleepstudy$score2 <- score2
> >
> > model <-lmer(Reaction ~ score1 + score2 + (1|Subject), data=sleepstudy)
> >
> > Best regards,
> > Blazej Mrozinski
> >
> > ps. this question was posted on CrossValidated:
> > https://stats.stackexchange.com/questions/325302/how-to-
> compare-two-coefficent-estimates-in-a-multilevel-model
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Mon Jan 29 09:52:37 2018
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Mon, 29 Jan 2018 09:52:37 +0100
Subject: [R-sig-ME] How to compare two coefficent estimates in a
 multilevel model?
In-Reply-To: <CANAWZx8dq1BWx=+ZyJipj_0kr_AEGJCojNCFn_2RNnh8BFjr_Q@mail.gmail.com>
References: <CANAWZx-s0jdyB1GcGGYy6mJA71L42e9k-tKxi9cXZaVEM_XhoA@mail.gmail.com>
 <CAJuCY5yOaXhEiLPttnx498VKN5-1db=G_N3kFqGjXvhZ-5JYoA@mail.gmail.com>
 <CANAWZx8dq1BWx=+ZyJipj_0kr_AEGJCojNCFn_2RNnh8BFjr_Q@mail.gmail.com>
Message-ID: <CAJuCY5yxgz6QxQ382N8xRAQ+dTnxitjr1YDC+peGzGyjE9xq4A@mail.gmail.com>

Dear Blazej,

Yes, contrasts are what you are looking for.

And please only cross post if you don't get a reactie within a few days.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
AND FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////




2018-01-29 9:47 GMT+01:00 Blazej Mrozinski <blazej.mrozinski at gmail.com>:
> Good Morning Thierry,
> yes - that was my goal in this example.
> Although I'm not what should I do if there where mode (say 3 or 4) fixed
> effect estimates. I'd be guessing (based on Ben Bolker suggestion given on
> StackOverflow) that contrasts set by hand are the right approach.
> I already sorted out how to do it (with 2 estimates), in order to match
> results from HLM software - that is
> by using linearHypothesis function from car package:
>
> library(car)
> linearHypothesis(model, "score1=score2")
> Linear hypothesis test
>
> Hypothesis:
> score1 - score2 = 0
>
> Model 1: restricted model
> Model 2: Reaction ~ score1 + score2 + (1 | Subject)
>
>   Df  Chisq Pr(>Chisq)
> 1
> 2  1 2.8187    0.09317 .
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
>
> https://stats.stackexchange.com/a/325502/133561
>
> Best Regards,
> Blazej
>
> Blazej Mrozinski
>
> 2018-01-29 9:40 GMT+01:00 Thierry Onkelinx <thierry.onkelinx at inbo.be>:
>>
>> Dear Blazej,
>>
>> Your question is not clear to me. What is the hypothesis that you want
>> to test? H_0: \gamma_{01} = \gamma_{02} ?
>>
>> Best regards,
>>
>> ir. Thierry Onkelinx
>> Statisticus / Statistician
>>
>> Vlaamse Overheid / Government of Flanders
>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
>> AND FOREST
>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
>> thierry.onkelinx at inbo.be
>> Havenlaan 88 bus 73, 1000 Brussel
>> www.inbo.be
>>
>>
>> ///////////////////////////////////////////////////////////////////////////////////////////
>> To call in the statistician after the experiment is done may be no
>> more than asking him to perform a post-mortem examination: he may be
>> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does
>> not ensure that a reasonable answer can be extracted from a given body
>> of data. ~ John Tukey
>>
>> ///////////////////////////////////////////////////////////////////////////////////////////
>>
>>
>>
>>
>> 2018-01-28 17:43 GMT+01:00 Blazej Mrozinski <blazej.mrozinski at gmail.com>:
>> > Greetings,
>> >
>> > Could anyone help me in answering the following question:
>> >
>> > How can I compare two coefficient estimates from a lme4 or nlme model?
>> >
>> > In HLM7 (software I'm more familiar with) such comparisons are evaluated
>> > with ?2 tests. I can't find out what function in lme4, nlme or just base
>> > can do the same.
>> >
>> > An imaginary example I'm working with, is a modified sleepstudy dataset
>> > -
>> > with two score variables added at level 2. The model being tested is
>> > this:
>> >
>> > Level1:
>> > Reaction=?0+r
>> >
>> > Level2:
>> > ?0=?00+?01(score1)+?02(score2)+u0j
>> >
>> > I'm looking for a ?2 comparing both level 2 coefficients (or 3+ if there
>> > are more of them)
>> >
>> > Here is my modified dataset:
>> >
>> > library(lme4)
>> >
>> > set.seed(123)
>> > score1=NULL
>> > score2=NULLfor(i in 1:18) {
>> >       x1 = rep(sample(1:5, size = 1), 10)
>> >       score1 = c(score1, x1)
>> >       x2 = rep(sample(1:5, size = 1), 10)
>> >       score2 = c(score2, x2)}
>> >
>> > sleepstudy$score1 <- score1
>> > sleepstudy$score2 <- score2
>> >
>> > model <-lmer(Reaction ~ score1 + score2 + (1|Subject), data=sleepstudy)
>> >
>> > Best regards,
>> > Blazej Mrozinski
>> >
>> > ps. this question was posted on CrossValidated:
>> >
>> > https://stats.stackexchange.com/questions/325302/how-to-compare-two-coefficent-estimates-in-a-multilevel-model
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > _______________________________________________
>> > R-sig-mixed-models at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>


From blazej.mrozinski at gmail.com  Mon Jan 29 20:03:14 2018
From: blazej.mrozinski at gmail.com (Blazej Mrozinski)
Date: Mon, 29 Jan 2018 20:03:14 +0100
Subject: [R-sig-ME] Computing reliability for the least squares estimates of
 each level1 coefficient across the set of J level-2 units
Message-ID: <CANAWZx8w6jPX9Nw97VzZeZ1j28r0omGFKEyrZZA43CWAsausLw@mail.gmail.com>

Good evening,
Please accept my apology for cross-posting (I've been advised to avoid it)
but I can't find my answer anywhere.
4 days ago I posted my question to stackOverflow (with screenshots of
formulas, that are skipped here): https://stackoverflow.com/
questions/48438755/how-to-compute-reliability-estimates-
from-lmer-lme-results.
<https://stackoverflow.com/questions/48438755/how-to-compute-reliability-estimates-from-lmer-lme-results>

I'm coming from a commercial MLM (HLM7) software and would like to (...drop
it eventually) replicate some numbers in R.

Specifically I'm looking for a function or formula computing the
**reliability for the least squares estimates of each level1 coefficient
across the set of *J* level-2 units**

Below is an example based on the simple `sleepstudy` data. What I'm looking
for is a way to compute reliability values not only in this very example,
but also in situations where there are more level1 variables.

>From HLM7 manual (Raudenbush, Bryk (2002), p.11) a definition of
reliability is given:
Reliability Estimates (overall or average reliability for the least squares
estimates of each level 1 coefficent across the set of J level-2 units)
calculated according to
Equation 3.58 in Hierarchical Linear Models (2nd ed.)

I used the `sleepstudy` data from `lme4` package to compute a random
intercept and slope model with `lme4::lmer`:

    library(lme4)
    m <- lmer(Reaction ~ Days + (Days|Subject), data = sleepstudy)
    summary(m)

And with HLM7 software

Fixed and random effects estimates are pretty similar (differences in
rounding occur), but HLM7 will also provide it's reliability estimates:

     ----------------------------------------------------
      Random level-1 coefficient   Reliability estimate
     ----------------------------------------------------
      INTRCPT1, G0                        0.730
          DAYS, G1                        0.815
     ----------------------------------------------------

And this is something I'd like to be able to get from `lmer()` results.

Is this possible with a built-in formula? Some other package function?
Or maybe someone could help me in extracting appropriate values from lmer
result object and compute it "by hand" ?
Thank you very much!

Kind Regards,
Blazej Mrozinski

	[[alternative HTML version deleted]]


From HDoran at air.org  Mon Jan 29 20:12:15 2018
From: HDoran at air.org (Doran, Harold)
Date: Mon, 29 Jan 2018 19:12:15 +0000
Subject: [R-sig-ME] Computing reliability for the least squares
 estimates of each level1 coefficient across the set of J level-2 units
In-Reply-To: <CANAWZx8w6jPX9Nw97VzZeZ1j28r0omGFKEyrZZA43CWAsausLw@mail.gmail.com>
References: <CANAWZx8w6jPX9Nw97VzZeZ1j28r0omGFKEyrZZA43CWAsausLw@mail.gmail.com>
Message-ID: <DM2PR0501MB1280FB87F274CE1CEDE2681FCAE50@DM2PR0501MB1280.namprd05.prod.outlook.com>

The formulas you need are in the SO post you put up yourself. So, lmer gives you the output you need to do it, just follow those formulas you have already posted. An object of class mer does not provide the reliability (which I question in terms of usefulness, but that's another issue)

-----Original Message-----
From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Blazej Mrozinski
Sent: Monday, January 29, 2018 2:03 PM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] Computing reliability for the least squares estimates of each level1 coefficient across the set of J level-2 units

Good evening,
Please accept my apology for cross-posting (I've been advised to avoid it) but I can't find my answer anywhere.
4 days ago I posted my question to stackOverflow (with screenshots of formulas, that are skipped here): https://stackoverflow.com/
questions/48438755/how-to-compute-reliability-estimates-
from-lmer-lme-results.
<https://stackoverflow.com/questions/48438755/how-to-compute-reliability-estimates-from-lmer-lme-results>

I'm coming from a commercial MLM (HLM7) software and would like to (...drop it eventually) replicate some numbers in R.

Specifically I'm looking for a function or formula computing the **reliability for the least squares estimates of each level1 coefficient across the set of *J* level-2 units**

Below is an example based on the simple `sleepstudy` data. What I'm looking for is a way to compute reliability values not only in this very example, but also in situations where there are more level1 variables.

>From HLM7 manual (Raudenbush, Bryk (2002), p.11) a definition of reliability is given:
Reliability Estimates (overall or average reliability for the least squares estimates of each level 1 coefficent across the set of J level-2 units) calculated according to Equation 3.58 in Hierarchical Linear Models (2nd ed.)

I used the `sleepstudy` data from `lme4` package to compute a random intercept and slope model with `lme4::lmer`:

    library(lme4)
    m <- lmer(Reaction ~ Days + (Days|Subject), data = sleepstudy)
    summary(m)

And with HLM7 software

Fixed and random effects estimates are pretty similar (differences in rounding occur), but HLM7 will also provide it's reliability estimates:

     ----------------------------------------------------
      Random level-1 coefficient   Reliability estimate
     ----------------------------------------------------
      INTRCPT1, G0                        0.730
          DAYS, G1                        0.815
     ----------------------------------------------------

And this is something I'd like to be able to get from `lmer()` results.

Is this possible with a built-in formula? Some other package function?
Or maybe someone could help me in extracting appropriate values from lmer result object and compute it "by hand" ?
Thank you very much!

Kind Regards,
Blazej Mrozinski

	[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From blazej.mrozinski at gmail.com  Mon Jan 29 21:05:56 2018
From: blazej.mrozinski at gmail.com (Blazej Mrozinski)
Date: Mon, 29 Jan 2018 21:05:56 +0100
Subject: [R-sig-ME] Computing reliability for the least squares
 estimates of each level1 coefficient across the set of J level-2 units
In-Reply-To: <DM2PR0501MB1280FB87F274CE1CEDE2681FCAE50@DM2PR0501MB1280.namprd05.prod.outlook.com>
References: <CANAWZx8w6jPX9Nw97VzZeZ1j28r0omGFKEyrZZA43CWAsausLw@mail.gmail.com>
 <DM2PR0501MB1280FB87F274CE1CEDE2681FCAE50@DM2PR0501MB1280.namprd05.prod.outlook.com>
Message-ID: <CANAWZx8DC51EAyZjdH2x6B1_gJpuO-Bsgu4DN1Sb01VggC46nQ@mail.gmail.com>

Harold, thank you for your reply.
Problem is, if I knew where to find needed values for those formulas I
wouldn't bother anyone with this question.
I guess that `getME()` might be what I need to use, but that's it. I'm
stuck.

Blazej Mrozinski

2018-01-29 20:12 GMT+01:00 Doran, Harold <HDoran at air.org>:

> The formulas you need are in the SO post you put up yourself. So, lmer
> gives you the output you need to do it, just follow those formulas you have
> already posted. An object of class mer does not provide the reliability
> (which I question in terms of usefulness, but that's another issue)
>
>
>

	[[alternative HTML version deleted]]


From HDoran at air.org  Mon Jan 29 21:07:36 2018
From: HDoran at air.org (Doran, Harold)
Date: Mon, 29 Jan 2018 20:07:36 +0000
Subject: [R-sig-ME] Computing reliability for the least squares
 estimates of each level1 coefficient across the set of J level-2 units
In-Reply-To: <CANAWZx8DC51EAyZjdH2x6B1_gJpuO-Bsgu4DN1Sb01VggC46nQ@mail.gmail.com>
References: <CANAWZx8w6jPX9Nw97VzZeZ1j28r0omGFKEyrZZA43CWAsausLw@mail.gmail.com>
 <DM2PR0501MB1280FB87F274CE1CEDE2681FCAE50@DM2PR0501MB1280.namprd05.prod.outlook.com>
 <CANAWZx8DC51EAyZjdH2x6B1_gJpuO-Bsgu4DN1Sb01VggC46nQ@mail.gmail.com>
Message-ID: <DM2PR0501MB128009051303B351FDC88FDBCAE50@DM2PR0501MB1280.namprd05.prod.outlook.com>

No, just do summary() as it outputs the variances of the random effects

From: blazko at gmail.com [mailto:blazko at gmail.com] On Behalf Of Blazej Mrozinski
Sent: Monday, January 29, 2018 3:06 PM
To: Doran, Harold <HDoran at air.org>
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Computing reliability for the least squares estimates of each level1 coefficient across the set of J level-2 units

Harold, thank you for your reply.
Problem is, if I knew where to find needed values for those formulas I wouldn't bother anyone with this question.
I guess that `getME()` might be what I need to use, but that's it. I'm stuck.

Blazej Mrozinski

2018-01-29 20:12 GMT+01:00 Doran, Harold <HDoran at air.org<mailto:HDoran at air.org>>:
The formulas you need are in the SO post you put up yourself. So, lmer gives you the output you need to do it, just follow those formulas you have already posted. An object of class mer does not provide the reliability (which I question in terms of usefulness, but that's another issue)



	[[alternative HTML version deleted]]


From HDoran at air.org  Mon Jan 29 21:32:10 2018
From: HDoran at air.org (Doran, Harold)
Date: Mon, 29 Jan 2018 20:32:10 +0000
Subject: [R-sig-ME] Computing reliability for the least squares
 estimates of each level1 coefficient across the set of J level-2 units
In-Reply-To: <CANAWZx8ckN6uUGdT-23wW58fwUSvxCEHmi09af_8x417YoAMhQ@mail.gmail.com>
References: <CANAWZx8w6jPX9Nw97VzZeZ1j28r0omGFKEyrZZA43CWAsausLw@mail.gmail.com>
 <DM2PR0501MB1280FB87F274CE1CEDE2681FCAE50@DM2PR0501MB1280.namprd05.prod.outlook.com>
 <CANAWZx8DC51EAyZjdH2x6B1_gJpuO-Bsgu4DN1Sb01VggC46nQ@mail.gmail.com>
 <DM2PR0501MB128009051303B351FDC88FDBCAE50@DM2PR0501MB1280.namprd05.prod.outlook.com>
 <CANAWZx8ckN6uUGdT-23wW58fwUSvxCEHmi09af_8x417YoAMhQ@mail.gmail.com>
Message-ID: <DM2PR0501MB12806145E19CCA8888A93CC3CAE50@DM2PR0501MB1280.namprd05.prod.outlook.com>

Best to keep the sig on the email thread. Assuming HLM (the software) is actually computing the reliability in the way reported in the book by B & R, then just use the marginal reliabilities provided by lmer in your summary output and plug those into your formulas.

I think we?re deviating from the purpose of this list, however. We?re here to help you use R, not here to help you understand how to replicate what other software is doing. With that said, you can see in the output you?re providing from HLM and from lmer, the marginal variances are the same, and those are the inputs into the ?reliability? formula. So, why you?re not replicating HLM isn?t something we can (or should) go much further with on this list.



From: blazko at gmail.com [mailto:blazko at gmail.com] On Behalf Of Blazej Mrozinski
Sent: Monday, January 29, 2018 3:21 PM
To: Doran, Harold <HDoran at air.org>
Subject: Re: [R-sig-ME] Computing reliability for the least squares estimates of each level1 coefficient across the set of J level-2 units

Of course, I'm aware of the summary() function, but that won't get me the reliability I'm trying to match with HLM output.
I must be a special kind of stupid but still can't work it out.
For example -  an unconditional model of sleepstudy data gives the following numbers:
lmer(Reaction ~ 1 + (1|Subject), data = sleepstudy)


Random effects:

 Groups   Name        Variance Std.Dev.

 Subject  (Intercept) 1278     35.75

 Residual             1959     44.26

Number of obs: 180, groups:  Subject, 18

Same unconditional model in HLM replicates random effects estimates:
 Final estimation of variance components:
 -----------------------------------------------------------------------------
 Random Effect           Standard      Variance     df    Chi-square  P-value
                         Deviation     Component
 -----------------------------------------------------------------------------
 INTRCPT1,       u0       35.75385    1278.33765    17     127.94046    0.000
  level-1,       r        44.25907    1958.86519
 -----------------------------------------------------------------------------

and provides the reliability value:
 ----------------------------------------------------
  Random level-1 coefficient   Reliability estimate
 ----------------------------------------------------
  INTRCPT1, G0                        0.867
 ----------------------------------------------------

Blazej Mrozinski

2018-01-29 21:07 GMT+01:00 Doran, Harold <HDoran at air.org<mailto:HDoran at air.org>>:
No, just do summary() as it outputs the variances of the random effects

From: blazko at gmail.com<mailto:blazko at gmail.com> [mailto:blazko at gmail.com<mailto:blazko at gmail.com>] On Behalf Of Blazej Mrozinski
Sent: Monday, January 29, 2018 3:06 PM
To: Doran, Harold <HDoran at air.org<mailto:HDoran at air.org>>
Cc: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] Computing reliability for the least squares estimates of each level1 coefficient across the set of J level-2 units

Harold, thank you for your reply.
Problem is, if I knew where to find needed values for those formulas I wouldn't bother anyone with this question.
I guess that `getME()` might be what I need to use, but that's it. I'm stuck.

Blazej Mrozinski

2018-01-29 20:12 GMT+01:00 Doran, Harold <HDoran at air.org<mailto:HDoran at air.org>>:
The formulas you need are in the SO post you put up yourself. So, lmer gives you the output you need to do it, just follow those formulas you have already posted. An object of class mer does not provide the reliability (which I question in terms of usefulness, but that's another issue)



	[[alternative HTML version deleted]]


From HDoran at air.org  Mon Jan 29 21:35:24 2018
From: HDoran at air.org (Doran, Harold)
Date: Mon, 29 Jan 2018 20:35:24 +0000
Subject: [R-sig-ME] Computing reliability for the least squares
 estimates of each level1 coefficient across the set of J level-2 units
In-Reply-To: <DM2PR0501MB12806145E19CCA8888A93CC3CAE50@DM2PR0501MB1280.namprd05.prod.outlook.com>
References: <CANAWZx8w6jPX9Nw97VzZeZ1j28r0omGFKEyrZZA43CWAsausLw@mail.gmail.com>
 <DM2PR0501MB1280FB87F274CE1CEDE2681FCAE50@DM2PR0501MB1280.namprd05.prod.outlook.com>
 <CANAWZx8DC51EAyZjdH2x6B1_gJpuO-Bsgu4DN1Sb01VggC46nQ@mail.gmail.com>
 <DM2PR0501MB128009051303B351FDC88FDBCAE50@DM2PR0501MB1280.namprd05.prod.outlook.com>
 <CANAWZx8ckN6uUGdT-23wW58fwUSvxCEHmi09af_8x417YoAMhQ@mail.gmail.com>
 <DM2PR0501MB12806145E19CCA8888A93CC3CAE50@DM2PR0501MB1280.namprd05.prod.outlook.com>
Message-ID: <DM2PR0501MB1280FA0CC81EF71E1BA1989CCAE50@DM2PR0501MB1280.namprd05.prod.outlook.com>

Correction, I meant use the marginal variances (not marginal reliabilities)

-----Original Message-----
From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Doran, Harold
Sent: Monday, January 29, 2018 3:32 PM
To: Blazej Mrozinski <blazej.mrozinski at gmail.com>; 'r-sig-mixed-models at r-project.org' <r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] Computing reliability for the least squares estimates of each level1 coefficient across the set of J level-2 units

Best to keep the sig on the email thread. Assuming HLM (the software) is actually computing the reliability in the way reported in the book by B & R, then just use the marginal reliabilities provided by lmer in your summary output and plug those into your formulas.

I think we?re deviating from the purpose of this list, however. We?re here to help you use R, not here to help you understand how to replicate what other software is doing. With that said, you can see in the output you?re providing from HLM and from lmer, the marginal variances are the same, and those are the inputs into the ?reliability? formula. So, why you?re not replicating HLM isn?t something we can (or should) go much further with on this list.



From: blazko at gmail.com [mailto:blazko at gmail.com] On Behalf Of Blazej Mrozinski
Sent: Monday, January 29, 2018 3:21 PM
To: Doran, Harold <HDoran at air.org>
Subject: Re: [R-sig-ME] Computing reliability for the least squares estimates of each level1 coefficient across the set of J level-2 units

Of course, I'm aware of the summary() function, but that won't get me the reliability I'm trying to match with HLM output.
I must be a special kind of stupid but still can't work it out.
For example -  an unconditional model of sleepstudy data gives the following numbers:
lmer(Reaction ~ 1 + (1|Subject), data = sleepstudy)


Random effects:

 Groups   Name        Variance Std.Dev.

 Subject  (Intercept) 1278     35.75

 Residual             1959     44.26

Number of obs: 180, groups:  Subject, 18

Same unconditional model in HLM replicates random effects estimates:
 Final estimation of variance components:
 -----------------------------------------------------------------------------
 Random Effect           Standard      Variance     df    Chi-square  P-value
                         Deviation     Component
 -----------------------------------------------------------------------------
 INTRCPT1,       u0       35.75385    1278.33765    17     127.94046    0.000
  level-1,       r        44.25907    1958.86519
 -----------------------------------------------------------------------------

and provides the reliability value:
 ----------------------------------------------------
  Random level-1 coefficient   Reliability estimate
 ----------------------------------------------------
  INTRCPT1, G0                        0.867
 ----------------------------------------------------

Blazej Mrozinski

2018-01-29 21:07 GMT+01:00 Doran, Harold <HDoran at air.org<mailto:HDoran at air.org>>:
No, just do summary() as it outputs the variances of the random effects

From: blazko at gmail.com<mailto:blazko at gmail.com> [mailto:blazko at gmail.com<mailto:blazko at gmail.com>] On Behalf Of Blazej Mrozinski
Sent: Monday, January 29, 2018 3:06 PM
To: Doran, Harold <HDoran at air.org<mailto:HDoran at air.org>>
Cc: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] Computing reliability for the least squares estimates of each level1 coefficient across the set of J level-2 units

Harold, thank you for your reply.
Problem is, if I knew where to find needed values for those formulas I wouldn't bother anyone with this question.
I guess that `getME()` might be what I need to use, but that's it. I'm stuck.

Blazej Mrozinski

2018-01-29 20:12 GMT+01:00 Doran, Harold <HDoran at air.org<mailto:HDoran at air.org>>:
The formulas you need are in the SO post you put up yourself. So, lmer gives you the output you need to do it, just follow those formulas you have already posted. An object of class mer does not provide the reliability (which I question in terms of usefulness, but that's another issue)



	[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

From Maarten.Jung at mailbox.tu-dresden.de  Tue Jan 30 07:48:04 2018
From: Maarten.Jung at mailbox.tu-dresden.de (Maarten Jung)
Date: Tue, 30 Jan 2018 01:48:04 -0500
Subject: [R-sig-ME] gls() vs. lmer() random effects estimation
Message-ID: <CAHr4DyfqYUASQZVKtpR8VF7Pg3mKjh4fUkf03vY6GN4zQtbs2Q@mail.gmail.com>

Dear list,

Let x be a factor with k levels.
Why can m1 be estimated with only one data point per level of x for each
subject?
I know that the random slope variance is confounded with the residual
variance in m2 and thus m2 cannot be estimated in this case.
But how can m1 overcome this limitation whereas m3 (which I think is
equivalent to m4) is the maximal linear mixed model that can be estimated
with lmer? And is there a way to achieve the same with lmer?

m1 <- gls(y ~ x, correlation = corSymm(form = ~1|subject), data = d)
m2 <- lmer(y ~ x + (x|subject), data = d)
m3 <- lmer(y ~ x + (1|subject), data = d)
m4 <- gls(y ~ x, correlation = corCompSymm(form = ~1|subject), data = d)

Best,
Maarten

	[[alternative HTML version deleted]]


From p.geelan-small at unsw.edu.au  Tue Jan 30 05:16:41 2018
From: p.geelan-small at unsw.edu.au (Peter Geelan-Small)
Date: Tue, 30 Jan 2018 04:16:41 +0000
Subject: [R-sig-ME] Gaussian linear mixed model with non-constant variance
Message-ID: <F4812CEE-D9EA-4E48-83FD-E0AD08A6FFBB@unsw.edu.au>

Hello, Mixed Modellers.

I?m after some advice on incorporating non-constant variances into a Gaussian linear mixed model.

Here?s an outline of the experimental setup:

Eight experimental units are set up and each is randomly assigned a different treatment, namely, Control, A, B, C, D, E, F and G. Three subsamples are taken together from each experimental unit and the response variable measured for each subsample. The response variable is continuous and a model with the Normal assumption will be used. This results in 24 measurements. This entire process is repeated two more times, each with a new set of experimental units. The resulting data set has three sets of measurements at each level of the treatment, with nine observed values for each level.

The experimental design is, then, a randomised complete block design. There are no missing values.

The researchers are interested in the (fixed) effect of the treatment and, in particular, they want to compare the effect of treatments A to G relative to the control.

The data set is small but, ignoring that, I want to a allow for non-constant variance. I?m using the nlme package.

In the code below, ?obs? is the measured response, ?treatment? is a factorial treatment identfier, ?expt? is experimental run and ?unit? is experimental unit. ?expt? is factorial and coded 1 to 3. ?unit? is factorial and coded 1 to 24. The model syntax I?ve used, assuming constant variance, is:

Model 1: Y1.lme1 <- lme(obs ~ treatment, random = ~ 1 | expt / unit, data = Y1)

A residual vs. fitted value plot from the above model shows non-constant variance.

To allow for non-constant variance across experimental runs, I?ve fitted the model below:

Model 2: Y1.lme2 <- lme(obs ~ treatment, random = ~ 1 | expt / unit, weights = varIdent(form = ~ 1 | expt), data = Y1)

Taking an alternative tack, I averaged the observed subsampled values for each experimental unit, giving a data set with 24 observed (average) values. I then fitted similar models to the two above.

Model 3: Y1.lme3 <- lme(obs.avg ~ treatment, random = ~ 1 | expt, data = Y1.avg)

A residual vs. fitted value plot from the above model shows non-constant variance and I again allowed for variances to change across experimental runs in the model below.

Model 4: Y1.lme4 <- lme(obs.avg ~ treatment, random = ~ 1 | expt, weights = varIdent(form = ~ 1 | expt), data = Y1.avg)

The fixed effect parameter estimates and their standard errors from Models 1 and 3 are exactly the same.

However, the fixed effect parameter estimates and their standard errors from Models 2 and 4 are quite different.

I'd be very grateful to get some comments on the following three points:

(1) Given the equivalence of models 1 and 3, I've been thinking the variation at the subsample level doesn't need to be incorporated into a model with changing variances across experimental run.

(2) I think my model syntax for "weights" in model 2 is incorparating subsample-level variation when estimating variances (and if I'm right (!) in point (1) above, this isn't the way to go).

(3) What I need to know in the end is which of models 2 and 4 (or something with different syntax?) to use to correctly model changing variances across experimental run.

Thanks in advance,

Peter



From phillip.alday at mpi.nl  Tue Jan 30 19:45:49 2018
From: phillip.alday at mpi.nl (Phillip Alday)
Date: Tue, 30 Jan 2018 19:45:49 +0100
Subject: [R-sig-ME] subjects within groups and effects of group
In-Reply-To: <0DAB7B5E-3B2B-4077-A75B-70424EB71599@gmu.edu>
References: <CC4B04FD-6934-4E94-B9A6-8E7AA8FBA33A@gmu.edu>
 <CAJuCY5xjL6wb5MxQs=MMum9BcqK-2QD6YNuythpa0a23uknT6g@mail.gmail.com>
 <99620d09-4dd7-5dac-e46e-4eb205be9cf7@mpi.nl>
 <B9A8DD23-7CFB-4380-A6C0-22E35F661F6E@gmu.edu>
 <CB5DAA4D-57A8-45C5-948B-336B235350BF@gmu.edu>
 <CAJuCY5yPSDBrejqwNV=VO30yS30+1f+rzjDDUikOwE+QF6QoYQ@mail.gmail.com>
 <ca89fd98-0528-0777-7d54-ca59eebce535@mpi.nl>
 <0DAB7B5E-3B2B-4077-A75B-70424EB71599@gmu.edu>
Message-ID: <f38bf2c2-68a4-11fa-3380-02fb6854dd59@mpi.nl>

> However, I would like to know how effects of spectral power (Alpha)
> over Drive vary as a function of Condition.

I may have lost track of your experimental design by this point (I have
experiments of my own to keep track of :) ), but my point had more to do
with the symmetry of interactions -- it may be that the impact of
Condition is modulated by endogenous fluctuations in alpha power. Or
given that alpha power is related to certain aspects of attention, it
may be that alpha power interacts with / modulates the effect of
Condition simply because it serves as a decent proxy for aspects of
attention which are relevant. The same holds for a potential interaction
with Drive and especially with SeqNo (as you could expect attention to
vary somewhat over the course of an experiment).

In other words, because alpha correlates to some extent with attention
and level of attention of course impacts performance on cognitive tasks
(including operating complex machinery such as a car), I would expect to
find some interaction effects between alpha power and other aspects of
the experimental manipulations. This is more a experimental psychology
consideration and less-so a statistical one. On a related statistical
note, I wouldn't include any interactions with alpha power in the random
effects as I suspect that would unnecessarily overparameterize the model.

So I would probably start with a model like:

log(RT) ~ 1 + (PzAlpha + Condition + Drive + SeqNo)^3 + (1 + PzAlpha |
subject) + (1 | trial)

This includes main effects and two- and three-way interactions but
excludes four-way interactions, which are hard to interpret, hard to
compute and probably won't drastically improve your model fit anyway
(based on my experience with these types of data). I allow the effect of
alpha power to vary by subject, in case there are baseline differences
in alpha power that affect the correlation with attention, but I would
drop this effect immediately if the model doesn't converge. Condition is
between subjects, so allowing it to vary by subject doesn't make much
sense. Trial only gets a random intercept because it is just capturing
some notion of fixed repetition and I wouldn't expect the other effects
of the experimental manipulation to vary strongly by Trial.

I would then check the model fit (e.g. by plotting predictions vs.
observed data). If the fit is good enough, then I would try to make some
inferences based on it, even knowing the model isn't perfect -- after
all, "all models are wrong, but some models are useful". You could try
to add the four-way interaction back in or by-subject slopes for SeqNo,
etc. but I suspect you'll have trouble getting those models to converge
with only 1839 observations and they probably won't fit the data that
much better (based on my experience with this type of data).

For lmer() and car::Anova(), it doesn't really matter if your predictors
are between or within subjects / items /etc. Between-subjects
manipulations tend provide better estimates (Andrew Gelman frequently
brings this up on his blog), which in practical terms means that they
have better power, but that's about it.

For post-hoc tests, I would recommend the emmeans package (successor to
lsmeans). The documentation is rather extensive, including lots of notes
and examples on interactions.

This is slowly drifting away from statistical issues and more towards
neuro/psych issues -- if other people on the list feel like it's gone
too far away from mixed models, just let us know. :)

Best,
Phillip


On 26/01/18 23:37, P Greenwood wrote:
> Dear Dr. Alday
> 
> Could you elaborate a bit on your answer to my question in decomposing
> the effect of condition. Condition was randomly assigned to two groups
> of participants. I did include both levels of Condition in my analysis
> (the output I sent originally). One approach might be to use the Anova
> command to perform a likelihood ratio test to compare a model that
> includes condition with a model that does not include condition.
> (Perhaps that is what you mean by ?test the difference??)  However, I
> would like to know how effects of spectral power (Alpha) over Drive vary
> as a function of Condition. 
> 
> Thanks also for the information on sequence information. 
> 
> Thanks so much
> 
> Pam
> 
> 
> P.M. Greenwood, Ph.D.
> /Associate Professor of Psychology/
> /Editorial Board, NeuroImage/
> /David King Hall 2052/
> /George Mason University/
> /MSN 3F5, 4400 University Drive/
> /Fairfax, VA 22030-4444/
> 
> /Ph: /703 993-4268
> /fax/: 703 993-1359
> /email: Pgreenw1 at gmu.edu <mailto:Pgreenw1 at gmu.edu>/
> /http://psychology.gmu.edu/people/pgreenw1/
> 
>> On Jan 25, 2018, at 5:44 PM, Alday, Phillip <Phillip.Alday at mpi.nl
>> <mailto:Phillip.Alday at mpi.nl>> wrote:
>>
>> Completely agree with Thierry here.
>>
>> In addition to the usual considerations about the bias-variance
>> tradeoff and partial pooling, you need to have things in one model if
>> you really want to compare them. The Difference Between ?Significant?
>> and ?Not Significant? is not Itself Statistically Significant (Gelman
>> and Stern 2012, doi:10.1198/000313006X152649
>> <https://secure-web.cisco.com/1K0nLxMcHeaEQ3zltL5zGKV6Wf3PuASMvvhRXl8z8qKf_35cqaaAeKSo2Q9Jln-azfrr34PbzOOlzZaZYuDWxL5arm_4R9mtGR3Sfsj9-ShTlNCxMGN06gFN5920BieQ1AbiUfjBLRNCvTRcAUTTNlwGGWzVpfqdGudEkiQ-lN89uB95el2DuEfyJW_E5dtTTKpWwSEYaJQc-1ZqKU74d4imV2ENHCLwror_8EZuYaZ51caefF2SHC0JYTTA_uKYgP_FECA8Q_-j4IjYDn_ZmjdvhekseOw9ixb4f2uGavmMS9iVdBAbeqT7xIO8l66l4yZaRUC7isfxVvlhJDIVb4-gRWFgjzG6uSmMzHBhJL44Y26l0SXjQcNYytqFIhCBmM8ZP-SmusBWVAQAymVxHbPAYWXgqpQif7ESbchFfnl3NrBmMQzazxgNQt-ymStEY0d-GMFAIpZfZxFmXh9Y570HQn5LungV8fQy2VbMa-yw/https%3A%2F%2Fdoi.org%2F10.1198%2F000313006X152649>),
>> so if you care about the significance of the difference, then you need
>> to actually test the difference!
>>
>> For your other question
>>
>>
>>> Trial refers to stimulus events.  The stimuli are the same on each
>>> Trial, although the order of the Trials varies between Drives.   But,
>>> yes, Trial is a sequence number for the repetition so that there
>>> could be some adaptation or change in response related to number of
>>> exposures.  (Assuming that is what you meant).  How would I include
>>> Trial as a continuous fixed effect?
>>
>> I would use slightly different names to make things clear. Separate
>> 'Trial' (a fixed series of stimuli) from SeqNo (the sequential
>> position of a given Trial within a Drive).
>>
>> Then your model looks something like this:
>>
>> lmer(RT ~ 1 + Condition*PzAlpha + Drive + SeqNo + (1 | subject) + (1 |
>> trial)
>>
>> I've left out any interactions there, but I suspect you'll at least
>> have an interaction with alpha and sequence number -- I imagine that
>> later trials (i.e. higher sequence numbers) will have worse RTs
>> (exhaustion effects) as will trials with higher alpha power and that
>> this two effects will enhance each other.
>>
>> Including sequence information in the model has received some
>> attention in the psycholinguistic as well as the broader psychology
>> literature as a way of controlling for adapt ion effects. GAMMs have
>> been proposed for such cases to allow for non linear adaptation
>> effects, but I wouldn't mess around with that until you feel much more
>> comfortable with the standard LMMs.
>>
>> And of course, if SeqNo doesn't improve model fit, you can simply omit
>> it for parsimony and easy of both interpretation and fitting.
>>
>> Phillip
>>
>>
>> On 25/01/18 17:33, Thierry Onkelinx wrote:
>>> Dear Pam,
>>>
>>> I'd probably combine both datasets in a single analysis.
>>>
>>> Best regards,
>>>
>>> ir. Thierry Onkelinx
>>> Statisticus / Statistician
>>>
>>> Vlaamse Overheid / Government of Flanders
>>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
>>> AND FOREST
>>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
>>> thierry.onkelinx at inbo.be
>>> Havenlaan 88 bus 73, 1000 Brussel
>>> www.inbo.be
>>>
>>> ///////////////////////////////////////////////////////////////////////////////////////////
>>> To call in the statistician after the experiment is done may be no
>>> more than asking him to perform a post-mortem examination: he may be
>>> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
>>> The plural of anecdote is not data. ~ Roger Brinner
>>> The combination of some data and an aching desire for an answer does
>>> not ensure that a reasonable answer can be extracted from a given body
>>> of data. ~ John Tukey
>>> ///////////////////////////////////////////////////////////////////////////////////////////
>>>
>>>
>>>
>>>
>>> 2018-01-24 14:02 GMT+01:00 P Greenwood <pgreenw1 at gmu.edu>:
>>>> Dear Drs Alday and Onkelinx
>>>>
>>>> I wondered if you had thoughts on the best way to conduct followup analysis
>>>> of the between-subjects Condition to which people were randomly assigned.
>>>>
>>>> Pam Greenwood
>>>>
>>>> P.M. Greenwood, Ph.D.
>>>> Associate Professor of Psychology
>>>> Editorial Board, NeuroImage
>>>> David King Hall 2052
>>>> George Mason University
>>>> MSN 3F5, 4400 University Drive
>>>> Fairfax, VA 22030-4444
>>>>
>>>> Ph: 703 993-4268
>>>> fax: 703 993-1359
>>>> email: Pgreenw1 at gmu.edu
>>>> http://psychology.gmu.edu/people/pgreenw1
>>>>
>>>> On Jan 19, 2018, at 8:09 AM, P Greenwood <pgreenw1 at gmu.edu> wrote:
>>>>
>>>> Thanks to you both.
>>>>
>>>> Trial refers to stimulus events.  The stimuli are the same on each Trial,
>>>> although the order of the Trials varies between Drives.   But, yes, Trial is
>>>> a sequence number for the repetition so that there could be some adaptation
>>>> or change in response related to number of exposures.  (Assuming that is
>>>> what you meant).  How would I include Trial as a continuous fixed effect?
>>>>
>>>> If the effect of Condition were ?significant.? how would one decompose that
>>>> to examine each group (Condition) separately?
>>>>
>>>> Regards
>>>>
>>>> Pam
>>>>
>>>>
>>>> P.M. Greenwood, Ph.D.
>>>> Associate Professor of Psychology
>>>> Editorial Board, NeuroImage
>>>> David King Hall 2052
>>>> George Mason University
>>>> MSN 3F5, 4400 University Drive
>>>> Fairfax, VA 22030-4444
>>>>
>>>> Ph: 703 993-4268
>>>> fax: 703 993-1359
>>>> email: Pgreenw1 at gmu.edu
>>>> http://psychology.gmu.edu/people/pgreenw1
>>>>
>>>> On Jan 19, 2018, at 5:58 AM, Phillip Alday <phillip.alday at mpi.nl> wrote:
>>>>
>>>> Dear Pam, (dear Thierry,)
>>>>
>>>> if I'm reading the description correctly, Pam is conceiving of Trial as
>>>> being an "Item"-type factor (crossed with subject). To rephrase
>>>> Thierry's comment a bit -- if Trial corresponds to an Item (concrete
>>>> stimulus realization sampled from the population of possible stimuli for
>>>> this manipulation) that is the same across subjects, then this is a good
>>>> way to model that. If Trial doesn't correspond to an invariant set of
>>>> items, but is rather just repetitions of the same task (perhaps with
>>>> some random variation that isn't identical across subjects), then
>>>> modeling Trial as a random effect doesn't really help much. However, if
>>>> Trial is just a sequence number for the repetition, it might make sense
>>>> to instead include Trial as a continuous fixed effect in order to model
>>>> adaptation effects.
>>>>
>>>> Best,
>>>> Phillip
>>>>
>>>> On 19/01/18 10:44, Thierry Onkelinx wrote:
>>>>
>>>> Dear Pam,
>>>>
>>>> You are handling condition and subject correctly.
>>>>
>>>> There might be a problem with trial. Does trial indicates dependent
>>>> replication of the study? Is there a common effect of trial X for all
>>>> subjects? Because that is what your current model assumes. In case the
>>>> trials are independent, then you don't need to include it in the
>>>> model.
>>>>
>>>> Note that Condition + PzAlpha + PzAlpha*Condition is verbose. You can
>>>> write it as PzAlpha*Condition.
>>>>
>>>> Best regards,
>>>>
>>>> ir. Thierry Onkelinx
>>>> Statisticus / Statistician
>>>>
>>>> Vlaamse Overheid / Government of Flanders
>>>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
>>>> AND FOREST
>>>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
>>>> thierry.onkelinx at inbo.be
>>>> Havenlaan 88 bus 73, 1000 Brussel
>>>> www.inbo.be
>>>>
>>>> ///////////////////////////////////////////////////////////////////////////////////////////
>>>> To call in the statistician after the experiment is done may be no
>>>> more than asking him to perform a post-mortem examination: he may be
>>>> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
>>>> The plural of anecdote is not data. ~ Roger Brinner
>>>> The combination of some data and an aching desire for an answer does
>>>> not ensure that a reasonable answer can be extracted from a given body
>>>> of data. ~ John Tukey
>>>> ///////////////////////////////////////////////////////////////////////////////////////////
>>>>
>>>>
>>>>
>>>>
>>>> 2018-01-18 18:51 GMT+01:00 P Greenwood <pgreenw1 at gmu.edu>:
>>>>
>>>> Hello
>>>>
>>>> I wanted some advice about handling subjects within groups and effects of
>>>> group (randomly assigned).  I want to predict reaction time (RT) as a
>>>> function of  ?Condition,?  alpha band power (PzAlpha), and drive. People
>>>> (subjects) are randomly assigned to Condition, of which there are two. Each
>>>> person has data from 5 drives, and for each drive there are 10 trials.
>>>> There are 19 subjects in one group and 20 in the other.
>>>>
>>>> My question is this: Am I handling the ?between subjects? factor of
>>>> Condition correctly?  Also, am I treating subjects within group correctly?
>>>> I am pasting in some of my data.  The output is below.
>>>>
>>>> Regards
>>>>
>>>> Pam Greenwood
>>>>
>>>> library(lme4)
>>>> library(lmerTest)
>>>> INFAST_Behavioral <- read.csv(??.
>>>> na.omit(INFAST_Behavioral)
>>>> INFAST_Behavioral$RT = scale(INFAST_Behavioral$RT, center = TRUE, scale =
>>>> TRUE)
>>>> INFAST_Behavioral$PzAlpha = scale(INFAST_Behavioral$PzAlpha, center = TRUE,
>>>> scale = TRUE)
>>>> sumModelInteraction <- lmer(RT ~ 1 + (Condition + PzAlpha + Drive +
>>>> PzAlpha*Condition) + (1 | subject) + (1 | trial), data = INFAST_Behavioral)
>>>> summary(sumModelInteraction)
>>>>
>>>> subject Condition               Drive           trial   FzAlpha CzAlpha
>>>> PzAlpha FzTheta CzTheta PzTheta FzDelta CzDelta PzDelta         RT      ACC
>>>> 1       HumanLanguage   1       1       -1.41   -4.3585 -5.5431 6.1516
>>>> 1.5911  3.6247  22.38   18.181 13.812          1568.984857     1
>>>> 1       HumanLanguage   1       2       -7.8605 2.0156  4.7392  15.992
>>>> 12.122  6.9088  26.861 20.592  16.326  1721.359714     1
>>>> 1       HumanLanguage   1       3       -2.6982 -5.6067 -10.038 6.285
>>>> 5.5172  1.2894  13.565 12.981  11.63   1257.092571     1
>>>> 1       HumanLanguage   1       4       3.3975  4.8789  -1.3249 7.0177
>>>> 9.6703  6.1539  10.231 12.261  12.485  1559.461429     1
>>>> ?(skipping to Subject 2)
>>>> 2       HumanLanguage                   1       1       1.6791  2.8887
>>>> 0.28174 -11.387 -9.9352 3.5936 -1.5767 3.9401  6.7201          1302.328857
>>>> 1
>>>> 2       HumanLanguage   1       2       -13.284 -8.2603 -6.6124 -5.9373
>>>> -8.7551 0.10394 4.5621 10.204  12.261  969.0088571     1
>>>> 2       HumanLanguage   1       3       -0.048973       1.1329  0.67399
>>>> -2.1432 2.5077  -2.4641 9.4667 10.883  7.1396  721.3997143     1
>>>> 2       HumanLanguage   1       4       5.0779  6.8916  6.3892  -1.8682
>>>> 3.1637  7.9712  8.0994 10.883  10.975  707.1145714     1
>>>> 2       HumanLanguage   1       5       -7.0495 -2.782  3.1668  8.4332
>>>> 10.646  9.3726  -3.5937 -7.3769 5.4472  892.8214286     1
>>>> 2       HumanLanguage   1       6       -1.462  -8.1223 -6.5896 -10.895
>>>> -5.6311 0.39941 7.5473 12.783  14.698  611.8802857     1
>>>> 2       HumanLanguage   1       7       -2.6402 -5.1213 -3.7372 3.4542
>>>> 4.2234  -0.99898        1.4089 4.1976  0.56587 761.8742857     1
>>>> 2       HumanLanguage   1       8       3.4393  4.6302  1.5525  1.4604
>>>> 3.1716  3.1622  -2.3427 2.908 4.2259  680.9251429     1
>>>> 2       HumanLanguage   1       9       -0.81024        -0.21642
>>>> -2.3876 2.5839  4.7307  1.5441 3.3761  8.4485  12.02   769.0168571     1
>>>> 2       HumanLanguage   1       10      -6.4045 -4.4937 -2.2449 0.94456
>>>> 2.7048  0.65565 -1.9791 0.26436 1.8435  885.6788571     1
>>>>
>>>> Results:
>>>>
>>>> Linear mixed model fit by REML t-tests use Satterthwaite approximations to
>>>> degrees of freedom [
>>>> lmerMod]
>>>> Formula: RT ~ 1 + (Condition + PzAlpha + Drive + PzAlpha * Condition) +
>>>>    (1 | subject) + (1 | trial)
>>>>   Data: INFAST_Behavioral
>>>>
>>>> REML criterion at convergence: 3876.4
>>>>
>>>> Scaled residuals:
>>>>    Min      1Q  Median      3Q     Max
>>>> -3.4308 -0.5227 -0.1194  0.3547  8.4095
>>>>
>>>> Random effects:
>>>> Groups   Name        Variance Std.Dev.
>>>> subject  (Intercept) 0.580073 0.76163
>>>> trial    (Intercept) 0.004778 0.06912
>>>> Residual             0.434918 0.65948
>>>> Number of obs: 1839, groups:  subject, 39; trial, 10
>>>>
>>>> Fixed effects:
>>>>                                         Estimate               Std. Error
>>>> df t value Pr(>|t|)
>>>> (Intercept)                        -0.27054    0.17607   40.80000  -1.537
>>>> 0.13213
>>>> ConditionMachineLang 0.41644    0.24595   36.90000   1.693  0.09884 .
>>>> PzAlpha                             0.01192    0.02411 1797.40000   0.494
>>>> 0.62117
>>>> Drive                               0.02948    0.01083 1788.40000   2.722
>>>> 0.00655 **
>>>> ConditionMachineLanguage:PzAlpha   -0.01998    0.03476 1803.10000  -0.575
>>>> 0.56560
>>>> ---
>>>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>>> P.M. Greenwood, Ph.D.
>>>> Associate Professor of Psychology
>>>> Editorial Board, NeuroImage
>>>> David King Hall 2052
>>>> George Mason University
>>>> MSN 3F5, 4400 University Drive
>>>> Fairfax, VA 22030-4444
>>>>
>>>> Ph: 703 993-4268
>>>> fax: 703 993-1359
>>>> email: Pgreenw1 at gmu.edu
>>>> http://psychology.gmu.edu/people/pgreenw1
>>>>
>>>>
>>>>        [[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://secure-web.cisco.com/1joP--B1_xWT50x7mVQZsmihBAOqrRroakmdBR5MIMiOARC9Fd1hE1yw-1sCnwGxdnwBghNSYF9p3BRdhCaL0o-KBtN4F3VSOMBOaVY1oHIj6WYPh_sr8e-zRksQa9F4ECA_XGS2Afp73TF2WsPYwPhZh0vxQMs_BOy--csyKCdriarDzsvIs-lPMcfSch2Ym2oCTwBXQ_YkEWQehip65TFdXUagB8dg1r-d1G0r841y-84pF20_DPQ6J18R57bYFsQp5D34gsd2C2Jf6WMFXlHUZLbGyg7TV0F8CEvUF6vNcNdjIJTUSz79up7bz_iYDKOezABzwahOdHoC45jHqvTmDYhjaqzCkPsymio7HL4h8UlFKyj0xzrIe3rEFvRQsMaNQdctVCMacfdjj-nJiV9Ab0-aVDdezvOlj8IwbPCwr9QwTBeZzUqOwf5ENxq1r/https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models
>>>>
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://secure-web.cisco.com/1joP--B1_xWT50x7mVQZsmihBAOqrRroakmdBR5MIMiOARC9Fd1hE1yw-1sCnwGxdnwBghNSYF9p3BRdhCaL0o-KBtN4F3VSOMBOaVY1oHIj6WYPh_sr8e-zRksQa9F4ECA_XGS2Afp73TF2WsPYwPhZh0vxQMs_BOy--csyKCdriarDzsvIs-lPMcfSch2Ym2oCTwBXQ_YkEWQehip65TFdXUagB8dg1r-d1G0r841y-84pF20_DPQ6J18R57bYFsQp5D34gsd2C2Jf6WMFXlHUZLbGyg7TV0F8CEvUF6vNcNdjIJTUSz79up7bz_iYDKOezABzwahOdHoC45jHqvTmDYhjaqzCkPsymio7HL4h8UlFKyj0xzrIe3rEFvRQsMaNQdctVCMacfdjj-nJiV9Ab0-aVDdezvOlj8IwbPCwr9QwTBeZzUqOwf5ENxq1r/https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models
>>>>
>>>>
>>>>
>>
>


From phillip.alday at mpi.nl  Tue Jan 30 20:42:49 2018
From: phillip.alday at mpi.nl (Phillip Alday)
Date: Tue, 30 Jan 2018 20:42:49 +0100
Subject: [R-sig-ME] subjects within groups and effects of group
In-Reply-To: <f38bf2c2-68a4-11fa-3380-02fb6854dd59@mpi.nl>
References: <CC4B04FD-6934-4E94-B9A6-8E7AA8FBA33A@gmu.edu>
 <CAJuCY5xjL6wb5MxQs=MMum9BcqK-2QD6YNuythpa0a23uknT6g@mail.gmail.com>
 <99620d09-4dd7-5dac-e46e-4eb205be9cf7@mpi.nl>
 <B9A8DD23-7CFB-4380-A6C0-22E35F661F6E@gmu.edu>
 <CB5DAA4D-57A8-45C5-948B-336B235350BF@gmu.edu>
 <CAJuCY5yPSDBrejqwNV=VO30yS30+1f+rzjDDUikOwE+QF6QoYQ@mail.gmail.com>
 <ca89fd98-0528-0777-7d54-ca59eebce535@mpi.nl>
 <0DAB7B5E-3B2B-4077-A75B-70424EB71599@gmu.edu>
 <f38bf2c2-68a4-11fa-3380-02fb6854dd59@mpi.nl>
Message-ID: <a1a7eb96-0a7b-0019-7dd9-767a2643dbe5@mpi.nl>

Oops, as Dan Brooks was kind enough to point out to me, I meant and
wrote two different things regarding within vs between designs.

*within*-subjects manipulations are what provide more power / better
estimates because you have better estimates at the subject level. You
can better separate out the variation between subjects from the
experimental variation when the experimental variation occurs within
subjects.

(I really hope I didn't mess up the correction too.)

Phillip

On 30/01/18 19:45, Phillip Alday wrote:
>> However, I would like to know how effects of spectral power (Alpha)
>> over Drive vary as a function of Condition.
> 
> I may have lost track of your experimental design by this point (I have
> experiments of my own to keep track of :) ), but my point had more to do
> with the symmetry of interactions -- it may be that the impact of
> Condition is modulated by endogenous fluctuations in alpha power. Or
> given that alpha power is related to certain aspects of attention, it
> may be that alpha power interacts with / modulates the effect of
> Condition simply because it serves as a decent proxy for aspects of
> attention which are relevant. The same holds for a potential interaction
> with Drive and especially with SeqNo (as you could expect attention to
> vary somewhat over the course of an experiment).
> 
> In other words, because alpha correlates to some extent with attention
> and level of attention of course impacts performance on cognitive tasks
> (including operating complex machinery such as a car), I would expect to
> find some interaction effects between alpha power and other aspects of
> the experimental manipulations. This is more a experimental psychology
> consideration and less-so a statistical one. On a related statistical
> note, I wouldn't include any interactions with alpha power in the random
> effects as I suspect that would unnecessarily overparameterize the model.
> 
> So I would probably start with a model like:
> 
> log(RT) ~ 1 + (PzAlpha + Condition + Drive + SeqNo)^3 + (1 + PzAlpha |
> subject) + (1 | trial)
> 
> This includes main effects and two- and three-way interactions but
> excludes four-way interactions, which are hard to interpret, hard to
> compute and probably won't drastically improve your model fit anyway
> (based on my experience with these types of data). I allow the effect of
> alpha power to vary by subject, in case there are baseline differences
> in alpha power that affect the correlation with attention, but I would
> drop this effect immediately if the model doesn't converge. Condition is
> between subjects, so allowing it to vary by subject doesn't make much
> sense. Trial only gets a random intercept because it is just capturing
> some notion of fixed repetition and I wouldn't expect the other effects
> of the experimental manipulation to vary strongly by Trial.
> 
> I would then check the model fit (e.g. by plotting predictions vs.
> observed data). If the fit is good enough, then I would try to make some
> inferences based on it, even knowing the model isn't perfect -- after
> all, "all models are wrong, but some models are useful". You could try
> to add the four-way interaction back in or by-subject slopes for SeqNo,
> etc. but I suspect you'll have trouble getting those models to converge
> with only 1839 observations and they probably won't fit the data that
> much better (based on my experience with this type of data).
> 
> For lmer() and car::Anova(), it doesn't really matter if your predictors
> are between or within subjects / items /etc. Between-subjects
> manipulations tend provide better estimates (Andrew Gelman frequently
> brings this up on his blog), which in practical terms means that they
> have better power, but that's about it.
> 
> For post-hoc tests, I would recommend the emmeans package (successor to
> lsmeans). The documentation is rather extensive, including lots of notes
> and examples on interactions.
> 
> This is slowly drifting away from statistical issues and more towards
> neuro/psych issues -- if other people on the list feel like it's gone
> too far away from mixed models, just let us know. :)
> 
> Best,
> Phillip
> 
> 
> On 26/01/18 23:37, P Greenwood wrote:
>> Dear Dr. Alday
>>
>> Could you elaborate a bit on your answer to my question in decomposing
>> the effect of condition. Condition was randomly assigned to two groups
>> of participants. I did include both levels of Condition in my analysis
>> (the output I sent originally). One approach might be to use the Anova
>> command to perform a likelihood ratio test to compare a model that
>> includes condition with a model that does not include condition.
>> (Perhaps that is what you mean by ?test the difference??)  However, I
>> would like to know how effects of spectral power (Alpha) over Drive vary
>> as a function of Condition. 
>>
>> Thanks also for the information on sequence information. 
>>
>> Thanks so much
>>
>> Pam
>>
>>
>> P.M. Greenwood, Ph.D.
>> /Associate Professor of Psychology/
>> /Editorial Board, NeuroImage/
>> /David King Hall 2052/
>> /George Mason University/
>> /MSN 3F5, 4400 University Drive/
>> /Fairfax, VA 22030-4444/
>>
>> /Ph: /703 993-4268
>> /fax/: 703 993-1359
>> /email: Pgreenw1 at gmu.edu <mailto:Pgreenw1 at gmu.edu>/
>> /http://psychology.gmu.edu/people/pgreenw1/
>>
>>> On Jan 25, 2018, at 5:44 PM, Alday, Phillip <Phillip.Alday at mpi.nl
>>> <mailto:Phillip.Alday at mpi.nl>> wrote:
>>>
>>> Completely agree with Thierry here.
>>>
>>> In addition to the usual considerations about the bias-variance
>>> tradeoff and partial pooling, you need to have things in one model if
>>> you really want to compare them. The Difference Between ?Significant?
>>> and ?Not Significant? is not Itself Statistically Significant (Gelman
>>> and Stern 2012, doi:10.1198/000313006X152649
>>> <https://secure-web.cisco.com/1K0nLxMcHeaEQ3zltL5zGKV6Wf3PuASMvvhRXl8z8qKf_35cqaaAeKSo2Q9Jln-azfrr34PbzOOlzZaZYuDWxL5arm_4R9mtGR3Sfsj9-ShTlNCxMGN06gFN5920BieQ1AbiUfjBLRNCvTRcAUTTNlwGGWzVpfqdGudEkiQ-lN89uB95el2DuEfyJW_E5dtTTKpWwSEYaJQc-1ZqKU74d4imV2ENHCLwror_8EZuYaZ51caefF2SHC0JYTTA_uKYgP_FECA8Q_-j4IjYDn_ZmjdvhekseOw9ixb4f2uGavmMS9iVdBAbeqT7xIO8l66l4yZaRUC7isfxVvlhJDIVb4-gRWFgjzG6uSmMzHBhJL44Y26l0SXjQcNYytqFIhCBmM8ZP-SmusBWVAQAymVxHbPAYWXgqpQif7ESbchFfnl3NrBmMQzazxgNQt-ymStEY0d-GMFAIpZfZxFmXh9Y570HQn5LungV8fQy2VbMa-yw/https%3A%2F%2Fdoi.org%2F10.1198%2F000313006X152649>),
>>> so if you care about the significance of the difference, then you need
>>> to actually test the difference!
>>>
>>> For your other question
>>>
>>>
>>>> Trial refers to stimulus events.  The stimuli are the same on each
>>>> Trial, although the order of the Trials varies between Drives.   But,
>>>> yes, Trial is a sequence number for the repetition so that there
>>>> could be some adaptation or change in response related to number of
>>>> exposures.  (Assuming that is what you meant).  How would I include
>>>> Trial as a continuous fixed effect?
>>>
>>> I would use slightly different names to make things clear. Separate
>>> 'Trial' (a fixed series of stimuli) from SeqNo (the sequential
>>> position of a given Trial within a Drive).
>>>
>>> Then your model looks something like this:
>>>
>>> lmer(RT ~ 1 + Condition*PzAlpha + Drive + SeqNo + (1 | subject) + (1 |
>>> trial)
>>>
>>> I've left out any interactions there, but I suspect you'll at least
>>> have an interaction with alpha and sequence number -- I imagine that
>>> later trials (i.e. higher sequence numbers) will have worse RTs
>>> (exhaustion effects) as will trials with higher alpha power and that
>>> this two effects will enhance each other.
>>>
>>> Including sequence information in the model has received some
>>> attention in the psycholinguistic as well as the broader psychology
>>> literature as a way of controlling for adapt ion effects. GAMMs have
>>> been proposed for such cases to allow for non linear adaptation
>>> effects, but I wouldn't mess around with that until you feel much more
>>> comfortable with the standard LMMs.
>>>
>>> And of course, if SeqNo doesn't improve model fit, you can simply omit
>>> it for parsimony and easy of both interpretation and fitting.
>>>
>>> Phillip
>>>
>>>
>>> On 25/01/18 17:33, Thierry Onkelinx wrote:
>>>> Dear Pam,
>>>>
>>>> I'd probably combine both datasets in a single analysis.
>>>>
>>>> Best regards,
>>>>
>>>> ir. Thierry Onkelinx
>>>> Statisticus / Statistician
>>>>
>>>> Vlaamse Overheid / Government of Flanders
>>>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
>>>> AND FOREST
>>>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
>>>> thierry.onkelinx at inbo.be
>>>> Havenlaan 88 bus 73, 1000 Brussel
>>>> www.inbo.be
>>>>
>>>> ///////////////////////////////////////////////////////////////////////////////////////////
>>>> To call in the statistician after the experiment is done may be no
>>>> more than asking him to perform a post-mortem examination: he may be
>>>> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
>>>> The plural of anecdote is not data. ~ Roger Brinner
>>>> The combination of some data and an aching desire for an answer does
>>>> not ensure that a reasonable answer can be extracted from a given body
>>>> of data. ~ John Tukey
>>>> ///////////////////////////////////////////////////////////////////////////////////////////
>>>>
>>>>
>>>>
>>>>
>>>> 2018-01-24 14:02 GMT+01:00 P Greenwood <pgreenw1 at gmu.edu>:
>>>>> Dear Drs Alday and Onkelinx
>>>>>
>>>>> I wondered if you had thoughts on the best way to conduct followup analysis
>>>>> of the between-subjects Condition to which people were randomly assigned.
>>>>>
>>>>> Pam Greenwood
>>>>>
>>>>> P.M. Greenwood, Ph.D.
>>>>> Associate Professor of Psychology
>>>>> Editorial Board, NeuroImage
>>>>> David King Hall 2052
>>>>> George Mason University
>>>>> MSN 3F5, 4400 University Drive
>>>>> Fairfax, VA 22030-4444
>>>>>
>>>>> Ph: 703 993-4268
>>>>> fax: 703 993-1359
>>>>> email: Pgreenw1 at gmu.edu
>>>>> http://psychology.gmu.edu/people/pgreenw1
>>>>>
>>>>> On Jan 19, 2018, at 8:09 AM, P Greenwood <pgreenw1 at gmu.edu> wrote:
>>>>>
>>>>> Thanks to you both.
>>>>>
>>>>> Trial refers to stimulus events.  The stimuli are the same on each Trial,
>>>>> although the order of the Trials varies between Drives.   But, yes, Trial is
>>>>> a sequence number for the repetition so that there could be some adaptation
>>>>> or change in response related to number of exposures.  (Assuming that is
>>>>> what you meant).  How would I include Trial as a continuous fixed effect?
>>>>>
>>>>> If the effect of Condition were ?significant.? how would one decompose that
>>>>> to examine each group (Condition) separately?
>>>>>
>>>>> Regards
>>>>>
>>>>> Pam
>>>>>
>>>>>
>>>>> P.M. Greenwood, Ph.D.
>>>>> Associate Professor of Psychology
>>>>> Editorial Board, NeuroImage
>>>>> David King Hall 2052
>>>>> George Mason University
>>>>> MSN 3F5, 4400 University Drive
>>>>> Fairfax, VA 22030-4444
>>>>>
>>>>> Ph: 703 993-4268
>>>>> fax: 703 993-1359
>>>>> email: Pgreenw1 at gmu.edu
>>>>> http://psychology.gmu.edu/people/pgreenw1
>>>>>
>>>>> On Jan 19, 2018, at 5:58 AM, Phillip Alday <phillip.alday at mpi.nl> wrote:
>>>>>
>>>>> Dear Pam, (dear Thierry,)
>>>>>
>>>>> if I'm reading the description correctly, Pam is conceiving of Trial as
>>>>> being an "Item"-type factor (crossed with subject). To rephrase
>>>>> Thierry's comment a bit -- if Trial corresponds to an Item (concrete
>>>>> stimulus realization sampled from the population of possible stimuli for
>>>>> this manipulation) that is the same across subjects, then this is a good
>>>>> way to model that. If Trial doesn't correspond to an invariant set of
>>>>> items, but is rather just repetitions of the same task (perhaps with
>>>>> some random variation that isn't identical across subjects), then
>>>>> modeling Trial as a random effect doesn't really help much. However, if
>>>>> Trial is just a sequence number for the repetition, it might make sense
>>>>> to instead include Trial as a continuous fixed effect in order to model
>>>>> adaptation effects.
>>>>>
>>>>> Best,
>>>>> Phillip
>>>>>
>>>>> On 19/01/18 10:44, Thierry Onkelinx wrote:
>>>>>
>>>>> Dear Pam,
>>>>>
>>>>> You are handling condition and subject correctly.
>>>>>
>>>>> There might be a problem with trial. Does trial indicates dependent
>>>>> replication of the study? Is there a common effect of trial X for all
>>>>> subjects? Because that is what your current model assumes. In case the
>>>>> trials are independent, then you don't need to include it in the
>>>>> model.
>>>>>
>>>>> Note that Condition + PzAlpha + PzAlpha*Condition is verbose. You can
>>>>> write it as PzAlpha*Condition.
>>>>>
>>>>> Best regards,
>>>>>
>>>>> ir. Thierry Onkelinx
>>>>> Statisticus / Statistician
>>>>>
>>>>> Vlaamse Overheid / Government of Flanders
>>>>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
>>>>> AND FOREST
>>>>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
>>>>> thierry.onkelinx at inbo.be
>>>>> Havenlaan 88 bus 73, 1000 Brussel
>>>>> www.inbo.be
>>>>>
>>>>> ///////////////////////////////////////////////////////////////////////////////////////////
>>>>> To call in the statistician after the experiment is done may be no
>>>>> more than asking him to perform a post-mortem examination: he may be
>>>>> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
>>>>> The plural of anecdote is not data. ~ Roger Brinner
>>>>> The combination of some data and an aching desire for an answer does
>>>>> not ensure that a reasonable answer can be extracted from a given body
>>>>> of data. ~ John Tukey
>>>>> ///////////////////////////////////////////////////////////////////////////////////////////
>>>>>
>>>>>
>>>>>
>>>>>
>>>>> 2018-01-18 18:51 GMT+01:00 P Greenwood <pgreenw1 at gmu.edu>:
>>>>>
>>>>> Hello
>>>>>
>>>>> I wanted some advice about handling subjects within groups and effects of
>>>>> group (randomly assigned).  I want to predict reaction time (RT) as a
>>>>> function of  ?Condition,?  alpha band power (PzAlpha), and drive. People
>>>>> (subjects) are randomly assigned to Condition, of which there are two. Each
>>>>> person has data from 5 drives, and for each drive there are 10 trials.
>>>>> There are 19 subjects in one group and 20 in the other.
>>>>>
>>>>> My question is this: Am I handling the ?between subjects? factor of
>>>>> Condition correctly?  Also, am I treating subjects within group correctly?
>>>>> I am pasting in some of my data.  The output is below.
>>>>>
>>>>> Regards
>>>>>
>>>>> Pam Greenwood
>>>>>
>>>>> library(lme4)
>>>>> library(lmerTest)
>>>>> INFAST_Behavioral <- read.csv(??.
>>>>> na.omit(INFAST_Behavioral)
>>>>> INFAST_Behavioral$RT = scale(INFAST_Behavioral$RT, center = TRUE, scale =
>>>>> TRUE)
>>>>> INFAST_Behavioral$PzAlpha = scale(INFAST_Behavioral$PzAlpha, center = TRUE,
>>>>> scale = TRUE)
>>>>> sumModelInteraction <- lmer(RT ~ 1 + (Condition + PzAlpha + Drive +
>>>>> PzAlpha*Condition) + (1 | subject) + (1 | trial), data = INFAST_Behavioral)
>>>>> summary(sumModelInteraction)
>>>>>
>>>>> subject Condition               Drive           trial   FzAlpha CzAlpha
>>>>> PzAlpha FzTheta CzTheta PzTheta FzDelta CzDelta PzDelta         RT      ACC
>>>>> 1       HumanLanguage   1       1       -1.41   -4.3585 -5.5431 6.1516
>>>>> 1.5911  3.6247  22.38   18.181 13.812          1568.984857     1
>>>>> 1       HumanLanguage   1       2       -7.8605 2.0156  4.7392  15.992
>>>>> 12.122  6.9088  26.861 20.592  16.326  1721.359714     1
>>>>> 1       HumanLanguage   1       3       -2.6982 -5.6067 -10.038 6.285
>>>>> 5.5172  1.2894  13.565 12.981  11.63   1257.092571     1
>>>>> 1       HumanLanguage   1       4       3.3975  4.8789  -1.3249 7.0177
>>>>> 9.6703  6.1539  10.231 12.261  12.485  1559.461429     1
>>>>> ?(skipping to Subject 2)
>>>>> 2       HumanLanguage                   1       1       1.6791  2.8887
>>>>> 0.28174 -11.387 -9.9352 3.5936 -1.5767 3.9401  6.7201          1302.328857
>>>>> 1
>>>>> 2       HumanLanguage   1       2       -13.284 -8.2603 -6.6124 -5.9373
>>>>> -8.7551 0.10394 4.5621 10.204  12.261  969.0088571     1
>>>>> 2       HumanLanguage   1       3       -0.048973       1.1329  0.67399
>>>>> -2.1432 2.5077  -2.4641 9.4667 10.883  7.1396  721.3997143     1
>>>>> 2       HumanLanguage   1       4       5.0779  6.8916  6.3892  -1.8682
>>>>> 3.1637  7.9712  8.0994 10.883  10.975  707.1145714     1
>>>>> 2       HumanLanguage   1       5       -7.0495 -2.782  3.1668  8.4332
>>>>> 10.646  9.3726  -3.5937 -7.3769 5.4472  892.8214286     1
>>>>> 2       HumanLanguage   1       6       -1.462  -8.1223 -6.5896 -10.895
>>>>> -5.6311 0.39941 7.5473 12.783  14.698  611.8802857     1
>>>>> 2       HumanLanguage   1       7       -2.6402 -5.1213 -3.7372 3.4542
>>>>> 4.2234  -0.99898        1.4089 4.1976  0.56587 761.8742857     1
>>>>> 2       HumanLanguage   1       8       3.4393  4.6302  1.5525  1.4604
>>>>> 3.1716  3.1622  -2.3427 2.908 4.2259  680.9251429     1
>>>>> 2       HumanLanguage   1       9       -0.81024        -0.21642
>>>>> -2.3876 2.5839  4.7307  1.5441 3.3761  8.4485  12.02   769.0168571     1
>>>>> 2       HumanLanguage   1       10      -6.4045 -4.4937 -2.2449 0.94456
>>>>> 2.7048  0.65565 -1.9791 0.26436 1.8435  885.6788571     1
>>>>>
>>>>> Results:
>>>>>
>>>>> Linear mixed model fit by REML t-tests use Satterthwaite approximations to
>>>>> degrees of freedom [
>>>>> lmerMod]
>>>>> Formula: RT ~ 1 + (Condition + PzAlpha + Drive + PzAlpha * Condition) +
>>>>>    (1 | subject) + (1 | trial)
>>>>>   Data: INFAST_Behavioral
>>>>>
>>>>> REML criterion at convergence: 3876.4
>>>>>
>>>>> Scaled residuals:
>>>>>    Min      1Q  Median      3Q     Max
>>>>> -3.4308 -0.5227 -0.1194  0.3547  8.4095
>>>>>
>>>>> Random effects:
>>>>> Groups   Name        Variance Std.Dev.
>>>>> subject  (Intercept) 0.580073 0.76163
>>>>> trial    (Intercept) 0.004778 0.06912
>>>>> Residual             0.434918 0.65948
>>>>> Number of obs: 1839, groups:  subject, 39; trial, 10
>>>>>
>>>>> Fixed effects:
>>>>>                                         Estimate               Std. Error
>>>>> df t value Pr(>|t|)
>>>>> (Intercept)                        -0.27054    0.17607   40.80000  -1.537
>>>>> 0.13213
>>>>> ConditionMachineLang 0.41644    0.24595   36.90000   1.693  0.09884 .
>>>>> PzAlpha                             0.01192    0.02411 1797.40000   0.494
>>>>> 0.62117
>>>>> Drive                               0.02948    0.01083 1788.40000   2.722
>>>>> 0.00655 **
>>>>> ConditionMachineLanguage:PzAlpha   -0.01998    0.03476 1803.10000  -0.575
>>>>> 0.56560
>>>>> ---
>>>>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>>>> P.M. Greenwood, Ph.D.
>>>>> Associate Professor of Psychology
>>>>> Editorial Board, NeuroImage
>>>>> David King Hall 2052
>>>>> George Mason University
>>>>> MSN 3F5, 4400 University Drive
>>>>> Fairfax, VA 22030-4444
>>>>>
>>>>> Ph: 703 993-4268
>>>>> fax: 703 993-1359
>>>>> email: Pgreenw1 at gmu.edu
>>>>> http://psychology.gmu.edu/people/pgreenw1
>>>>>
>>>>>
>>>>>        [[alternative HTML version deleted]]
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>> https://secure-web.cisco.com/1joP--B1_xWT50x7mVQZsmihBAOqrRroakmdBR5MIMiOARC9Fd1hE1yw-1sCnwGxdnwBghNSYF9p3BRdhCaL0o-KBtN4F3VSOMBOaVY1oHIj6WYPh_sr8e-zRksQa9F4ECA_XGS2Afp73TF2WsPYwPhZh0vxQMs_BOy--csyKCdriarDzsvIs-lPMcfSch2Ym2oCTwBXQ_YkEWQehip65TFdXUagB8dg1r-d1G0r841y-84pF20_DPQ6J18R57bYFsQp5D34gsd2C2Jf6WMFXlHUZLbGyg7TV0F8CEvUF6vNcNdjIJTUSz79up7bz_iYDKOezABzwahOdHoC45jHqvTmDYhjaqzCkPsymio7HL4h8UlFKyj0xzrIe3rEFvRQsMaNQdctVCMacfdjj-nJiV9Ab0-aVDdezvOlj8IwbPCwr9QwTBeZzUqOwf5ENxq1r/https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models
>>>>>
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>> https://secure-web.cisco.com/1joP--B1_xWT50x7mVQZsmihBAOqrRroakmdBR5MIMiOARC9Fd1hE1yw-1sCnwGxdnwBghNSYF9p3BRdhCaL0o-KBtN4F3VSOMBOaVY1oHIj6WYPh_sr8e-zRksQa9F4ECA_XGS2Afp73TF2WsPYwPhZh0vxQMs_BOy--csyKCdriarDzsvIs-lPMcfSch2Ym2oCTwBXQ_YkEWQehip65TFdXUagB8dg1r-d1G0r841y-84pF20_DPQ6J18R57bYFsQp5D34gsd2C2Jf6WMFXlHUZLbGyg7TV0F8CEvUF6vNcNdjIJTUSz79up7bz_iYDKOezABzwahOdHoC45jHqvTmDYhjaqzCkPsymio7HL4h8UlFKyj0xzrIe3rEFvRQsMaNQdctVCMacfdjj-nJiV9Ab0-aVDdezvOlj8IwbPCwr9QwTBeZzUqOwf5ENxq1r/https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models
>>>>>
>>>>>
>>>>>
>>>
>>
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From n.mitsakakis at theta.utoronto.ca  Wed Jan 31 05:21:34 2018
From: n.mitsakakis at theta.utoronto.ca (Nicholas Mitsakakis)
Date: Tue, 30 Jan 2018 23:21:34 -0500
Subject: [R-sig-ME] question on glme
Message-ID: <CAJ4s-a5Q4yRhC1FduVN6t4CLGM_xnu++CnRw=ud6gPwMa5TGpw@mail.gmail.com>

Hello,

I was wondering if I could get some guidance/advice in using the glme
function for a problem of mine:

I have some continuous positive data C_ij representing accumulated
quantities, where i denotes subject and j a state. The assumption here is
that C_ij were accumulated at a constant rate within each state j, but
these rates were different across states. We have the times t_ij where
subjects spent in each state. We also have some other covariates, some time
dependent, some not. The interest here is to model the mean rate
conditional on state, as well as values of the other covariates.



I was thinking of fitting a mixed model, with the following characteristics:

-       time values t_ij can be used as offset

-       the model will be of the Gamma family with log link, for
convenience for the offset (log of times will be used)

-       the correlation between C_ij across j values within i will be
expressed with one random effect expressing the random intercept per
subject i

-       states will be categorical variable (choosing one of them as
baseline)

-       what I am not sure about is if I also need to use time as weights.
I want to model the fact that C_ij for longer times should have higher
?weight?, since the ?rate? is estimated over a longer period of
accumulation.

Any comment/suggestion would be greatly appreciated.


Thanks,


Nicholas

-- 

------------------------------
This e-mail may be confidential and/or privileged and is intended to be 
viewed only by the recipient(s) named above. If you are not the intended 
recipient, you are strictly prohibited from reading, using, disclosing, 
copying or distributing this e-mail. If you received this e-mail in error,
please immediately notify the sender, and permanently delete this e-mail 
and any attachments.

	[[alternative HTML version deleted]]


From haveaballphysio at gmail.com  Thu Feb  1 11:37:10 2018
From: haveaballphysio at gmail.com (Dot Dumuid)
Date: Thu, 1 Feb 2018 21:07:10 +1030
Subject: [R-sig-ME] model specification for repeated measure
Message-ID: <CA+GPHvPMywSR+vMRtNKvatnVA8bbx99_O5iUCxSZGcM5mCyQUQ@mail.gmail.com>

Dear mixed model experts,
We have a dataset of older adults. We measured their mental health (MH) 6
months before retirement and again 12 months post retirement.
At both of these time points we also measured their physical activity (PA)
(min/day), income (INC) and general health (GH).
We would like to create a model that tells us if change in physical
activity over the retirement threshold predicts change in mental health,
and we'd like to use the model to predict how much mental health is
predicted to change when physical activity is increased from perhaps 15
minutes to 60 minutes. We'd like to use a mixed model rather than just
using change (difference) scores. And we'd like to control for things like
change in general physical health and change in income.

This is what the data look like

*ID  time  MH    PA    GH    INC*
01  pre     4      15     56     560
02  pre     5      30     30    1200
..    .....     ..       ..       ..        ...
01  post   7      40     50      50
02  post   8      45     30      0

I'm not sure how best to build the model. Something like this?

model <- lmer (MH ~ PA * time + GH + INC + (1|participant.ID) )

Thank you in advance.
Dot

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Thu Feb  1 13:24:04 2018
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Thu, 1 Feb 2018 13:24:04 +0100
Subject: [R-sig-ME] model specification for repeated measure
In-Reply-To: <CA+GPHvPMywSR+vMRtNKvatnVA8bbx99_O5iUCxSZGcM5mCyQUQ@mail.gmail.com>
References: <CA+GPHvPMywSR+vMRtNKvatnVA8bbx99_O5iUCxSZGcM5mCyQUQ@mail.gmail.com>
Message-ID: <CAJuCY5wpJ5nwOkS+m2Pk9qxgygsJM+rxg+TD+ytSS-kYSXZpEw@mail.gmail.com>

Dear Dot,

The specification of your covariates seems reasonable to me. You need
to check if the Gaussian distribution is relevant for your
measurements on mental health.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
AND FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////




2018-02-01 11:37 GMT+01:00 Dot Dumuid <haveaballphysio at gmail.com>:
> Dear mixed model experts,
> We have a dataset of older adults. We measured their mental health (MH) 6
> months before retirement and again 12 months post retirement.
> At both of these time points we also measured their physical activity (PA)
> (min/day), income (INC) and general health (GH).
> We would like to create a model that tells us if change in physical
> activity over the retirement threshold predicts change in mental health,
> and we'd like to use the model to predict how much mental health is
> predicted to change when physical activity is increased from perhaps 15
> minutes to 60 minutes. We'd like to use a mixed model rather than just
> using change (difference) scores. And we'd like to control for things like
> change in general physical health and change in income.
>
> This is what the data look like
>
> *ID  time  MH    PA    GH    INC*
> 01  pre     4      15     56     560
> 02  pre     5      30     30    1200
> ..    .....     ..       ..       ..        ...
> 01  post   7      40     50      50
> 02  post   8      45     30      0
>
> I'm not sure how best to build the model. Something like this?
>
> model <- lmer (MH ~ PA * time + GH + INC + (1|participant.ID) )
>
> Thank you in advance.
> Dot
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From haveaballphysio at gmail.com  Thu Feb  1 15:49:58 2018
From: haveaballphysio at gmail.com (Dot Dumuid)
Date: Fri, 2 Feb 2018 01:19:58 +1030
Subject: [R-sig-ME] model specification for repeated measure
In-Reply-To: <CAJuCY5wpJ5nwOkS+m2Pk9qxgygsJM+rxg+TD+ytSS-kYSXZpEw@mail.gmail.com>
References: <CA+GPHvPMywSR+vMRtNKvatnVA8bbx99_O5iUCxSZGcM5mCyQUQ@mail.gmail.com>
 <CAJuCY5wpJ5nwOkS+m2Pk9qxgygsJM+rxg+TD+ytSS-kYSXZpEw@mail.gmail.com>
Message-ID: <CA+GPHvMisQPX9C0hNQn2P1gb7Ebqr7eXJ0PPjpj=qvk9dej8MQ@mail.gmail.com>

Thank you!

On Thu, Feb 1, 2018 at 10:54 PM, Thierry Onkelinx <thierry.onkelinx at inbo.be>
wrote:

> Dear Dot,
>
> The specification of your covariates seems reasonable to me. You need
> to check if the Gaussian distribution is relevant for your
> measurements on mental health.
>
> Best regards,
>
> ir. Thierry Onkelinx
> Statisticus / Statistician
>
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
> AND FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Havenlaan 88 bus 73, 1000 Brussel
> www.inbo.be
>
> ////////////////////////////////////////////////////////////
> ///////////////////////////////
> To call in the statistician after the experiment is done may be no
> more than asking him to perform a post-mortem examination: he may be
> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does
> not ensure that a reasonable answer can be extracted from a given body
> of data. ~ John Tukey
> ////////////////////////////////////////////////////////////
> ///////////////////////////////
>
>
>
>
> 2018-02-01 11:37 GMT+01:00 Dot Dumuid <haveaballphysio at gmail.com>:
> > Dear mixed model experts,
> > We have a dataset of older adults. We measured their mental health (MH) 6
> > months before retirement and again 12 months post retirement.
> > At both of these time points we also measured their physical activity
> (PA)
> > (min/day), income (INC) and general health (GH).
> > We would like to create a model that tells us if change in physical
> > activity over the retirement threshold predicts change in mental health,
> > and we'd like to use the model to predict how much mental health is
> > predicted to change when physical activity is increased from perhaps 15
> > minutes to 60 minutes. We'd like to use a mixed model rather than just
> > using change (difference) scores. And we'd like to control for things
> like
> > change in general physical health and change in income.
> >
> > This is what the data look like
> >
> > *ID  time  MH    PA    GH    INC*
> > 01  pre     4      15     56     560
> > 02  pre     5      30     30    1200
> > ..    .....     ..       ..       ..        ...
> > 01  post   7      40     50      50
> > 02  post   8      45     30      0
> >
> > I'm not sure how best to build the model. Something like this?
> >
> > model <- lmer (MH ~ PA * time + GH + INC + (1|participant.ID) )
> >
> > Thank you in advance.
> > Dot
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From malcolm.fairbrother at umu.se  Thu Feb  1 20:23:35 2018
From: malcolm.fairbrother at umu.se (Malcolm Fairbrother)
Date: Thu, 1 Feb 2018 19:23:35 +0000
Subject: [R-sig-ME] model specification for repeated measure
In-Reply-To: <mailman.13.1517482802.39054.r-sig-mixed-models@r-project.org>
References: <mailman.13.1517482802.39054.r-sig-mixed-models@r-project.org>
Message-ID: <A02520CC-A865-4775-9E8B-3D32B004D54A@umu.se>

Hi Dot,

This specification would yield a single coefficient for the between-individual and within-individual effects. That is, you?re assuming the association is the same over time as it is across individuals at a single point in time. I wouldn?t expect this to be a safe assumption, and there?s a pretty straightforward fix: centre your time-varying predictors by their mean for each person. That will yield within effects equivalent to what you?d get from a fixed effects model.

For more information about this, see:
https://www.cambridge.org/core/services/aop-cambridge-core/content/view/S2049847014000077
and/or
https://www.researchgate.net/publication/299604336_Fixed_and_Random_effects_models_making_an_informed_choice

Hope that?s useful,
Malcolm


Malcolm Fairbrother
Professor of Sociology
Ume? University<http://www.umu.se/english>
Sweden



Date: Thu, 1 Feb 2018 21:07:10 +1030
From: Dot Dumuid <haveaballphysio at gmail.com<mailto:haveaballphysio at gmail.com>>
To: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
Subject: [R-sig-ME] model specification for repeated measure

Dear mixed model experts,
We have a dataset of older adults. We measured their mental health (MH) 6
months before retirement and again 12 months post retirement.
At both of these time points we also measured their physical activity (PA)
(min/day), income (INC) and general health (GH).
We would like to create a model that tells us if change in physical
activity over the retirement threshold predicts change in mental health,
and we'd like to use the model to predict how much mental health is
predicted to change when physical activity is increased from perhaps 15
minutes to 60 minutes. We'd like to use a mixed model rather than just
using change (difference) scores. And we'd like to control for things like
change in general physical health and change in income.

This is what the data look like

*ID  time  MH    PA    GH    INC*
01  pre     4      15     56     560
02  pre     5      30     30    1200
..    .....     ..       ..       ..        ...
01  post   7      40     50      50
02  post   8      45     30      0

I'm not sure how best to build the model. Something like this?

model <- lmer (MH ~ PA * time + GH + INC + (1|participant.ID) )

Thank you in advance.
Dot


	[[alternative HTML version deleted]]


From haveaballphysio at gmail.com  Thu Feb  1 20:52:16 2018
From: haveaballphysio at gmail.com (Dot Dumuid)
Date: Fri, 2 Feb 2018 06:22:16 +1030
Subject: [R-sig-ME] model specification for repeated measure
In-Reply-To: <A02520CC-A865-4775-9E8B-3D32B004D54A@umu.se>
References: <mailman.13.1517482802.39054.r-sig-mixed-models@r-project.org>
 <A02520CC-A865-4775-9E8B-3D32B004D54A@umu.se>
Message-ID: <CA+GPHvOqXEx3L49ZVvZVgn4EfpTBn+ym0Csp1-+R-OXbMJ3e6g@mail.gmail.com>

Thanks for the suggestions. I greatly appreciate you taking the time, and I
look forward to trying out the ideas.
Thanks, Dot

On Fri, Feb 2, 2018 at 5:53 AM, Malcolm Fairbrother <
malcolm.fairbrother at umu.se> wrote:

> Hi Dot,
>
> This specification would yield a single coefficient for the
> between-individual and within-individual effects. That is, you?re assuming
> the association is the same over time as it is across individuals at a
> single point in time. I wouldn?t expect this to be a safe assumption, and
> there?s a pretty straightforward fix: centre your time-varying predictors
> by their mean for each person. That will yield within effects equivalent to
> what you?d get from a fixed effects model.
>
> For more information about this, see:
> https://www.cambridge.org/core/services/aop-cambridge-core/content/view/
> S2049847014000077
> and/or
> https://www.researchgate.net/publication/299604336_Fixed_
> and_Random_effects_models_making_an_informed_choice
>
> Hope that?s useful,
> Malcolm
>
>
> Malcolm Fairbrother
> Professor of Sociology
> Ume? University <http://www.umu.se/english>
> Sweden
>
>
>
> Date: Thu, 1 Feb 2018 21:07:10 +1030
> From: Dot Dumuid <haveaballphysio at gmail.com>
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] model specification for repeated measure
>
> Dear mixed model experts,
> We have a dataset of older adults. We measured their mental health (MH) 6
> months before retirement and again 12 months post retirement.
> At both of these time points we also measured their physical activity (PA)
> (min/day), income (INC) and general health (GH).
> We would like to create a model that tells us if change in physical
> activity over the retirement threshold predicts change in mental health,
> and we'd like to use the model to predict how much mental health is
> predicted to change when physical activity is increased from perhaps 15
> minutes to 60 minutes. We'd like to use a mixed model rather than just
> using change (difference) scores. And we'd like to control for things like
> change in general physical health and change in income.
>
> This is what the data look like
>
> *ID  time  MH    PA    GH    INC*
> 01  pre     4      15     56     560
> 02  pre     5      30     30    1200
> ..    .....     ..       ..       ..        ...
> 01  post   7      40     50      50
> 02  post   8      45     30      0
>
> I'm not sure how best to build the model. Something like this?
>
> model <- lmer (MH ~ PA * time + GH + INC + (1|participant.ID) )
>
> Thank you in advance.
> Dot
>
>
>

	[[alternative HTML version deleted]]


From gerdaboerner at gmx.de  Fri Feb  2 09:57:53 2018
From: gerdaboerner at gmx.de (=?UTF-8?Q?Gerda_B=c3=b6rner?=)
Date: Fri, 2 Feb 2018 09:57:53 +0100
Subject: [R-sig-ME] What is the default covariance structure in the glmmPQL
 function (MASS package)?
Message-ID: <07bc7747-9403-ab40-c9d2-c9536287632d@gmx.de>

Hello,

I sent my query to the r-project.org mailing list first where I got told to rather send it to the r-sig-mixed-models mailing list. I hope someone can help me with my question although the r-sig-mixed-models mailing list refers to issues with using lme4 rather than the glmmPQL function from the MASS package.

So here is my question:
Currently I am trying to fit a generalized linear mixed model with binary outcome using the
glmmPQL function in the MASS package.

I was wondering, which variance-covariance structure the glmmPQL function is
using by default and if it is possible to vary the variance-covariance
structure with the glmmPQL function. Unfortunately I couldn't manage to find
out myself.
If it is possible to change it, could someone tell me how to do so? I am
especially interested in a diagonal structure versus an unstructured
variance-covariance structure.

Thanks a lot in advance.

Gerda


From orchidn at live.com  Fri Feb  2 18:31:43 2018
From: orchidn at live.com (dani)
Date: Fri, 2 Feb 2018 17:31:43 +0000
Subject: [R-sig-ME] ICC for glmer Poisson
Message-ID: <MWHPR1201MB00295A42C657882F59370DC0D6F90@MWHPR1201MB0029.namprd12.prod.outlook.com>

Hello everyone,


I am looking for information regarding the calculation of the ICC for a Poisson Glmer model.

I remember seeing somewhere that the within group variance is considered to be 1 in the calculation of the ICC for Poisson, but I do not have a reference for that. I did some research online but I could not find much.

Any help would be very appreciated.


Also, is there a way to determine significance and CIs for variances? I was thinking that variance can be tested by comparing a Glm model (without random effects) and the Glmer model (with random effects) using anova(), but I have no idea how to calculate the CIs.


Thank you all!

MD

	[[alternative HTML version deleted]]


From paul.johnson at glasgow.ac.uk  Fri Feb  2 23:46:04 2018
From: paul.johnson at glasgow.ac.uk (Paul Johnson)
Date: Fri, 2 Feb 2018 22:46:04 +0000
Subject: [R-sig-ME] ICC for glmer Poisson
In-Reply-To: <MWHPR1201MB00295A42C657882F59370DC0D6F90@MWHPR1201MB0029.namprd12.prod.outlook.com>
References: <MWHPR1201MB00295A42C657882F59370DC0D6F90@MWHPR1201MB0029.namprd12.prod.outlook.com>
Message-ID: <E720FC07-D158-435E-83C3-3EC2D353BF38@glasgow.ac.uk>

Hi,

Have a look at 

Nakagawa, Shinichi, and Holger Schielzeth. 2010. ?Repeatability for Gaussian and Non-Gaussian Data: A Practical Guide for Biologists.? Biological Reviews of the Cambridge Philosophical Society 85 (4): 935?56. doi:10.1111/j.1469-185X.2010.00141.x.
dx.doi.org/10.1111/j.1469-185X.2010.00141.x

and the related rptR package:

Stoffel, M., Nakagawa, S. & Schielzeth, H. (2017) rptR: Repeatability estimation and variance decomposition by generalized linear mixed-effects models.. Methods Ecol Evol. Accepted Author Manuscript. doi:10.1111/2041-210X.12797

There are various ways to get CIs for variances, the easiest is applying confint() to a glmer fit (in fact I think this gives CIs for the SDs). For getting confidence (credible) intervals from variance estimates though I think MCMC (e.g. MCMCglmm) works best.
For testing random effects, see:
http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#testing-significance-of-random-effects

Good luck,
Paul


> On 2 Feb 2018, at 17:31, dani <orchidn at live.com> wrote:
> 
> Hello everyone,
> 
> 
> I am looking for information regarding the calculation of the ICC for a Poisson Glmer model.
> 
> I remember seeing somewhere that the within group variance is considered to be 1 in the calculation of the ICC for Poisson, but I do not have a reference for that. I did some research online but I could not find much.
> 
> Any help would be very appreciated.
> 
> 
> Also, is there a way to determine significance and CIs for variances? I was thinking that variance can be tested by comparing a Glm model (without random effects) and the Glmer model (with random effects) using anova(), but I have no idea how to calculate the CIs.
> 
> 
> Thank you all!
> 
> MD
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From burwood70 at gmail.com  Sat Feb  3 02:11:14 2018
From: burwood70 at gmail.com (Steve Candy)
Date: Sat, 3 Feb 2018 12:11:14 +1100
Subject: [R-sig-ME] model specification for repeated measure
Message-ID: <004701d39c8b$e68046f0$b380d4d0$@gmail.com>

This paper describes a similar problem with two time points and covariates
and random subject effects.

 

It was coded in both SPSS and R.

 

 

Attention bias to threat in mothers with emotional disorders predicts
increased offspring anxiety

symptoms: a joint cross-sectional and longitudinal analysis.

Allison M. Waters , Elise M. Candy & Steven G. Candy

To cite this article: Allison M. Waters , Elise M. Candy & Steven G. Candy
(2017): Attention

bias to threat in mothers with emotional disorders predicts increased
offspring anxiety

symptoms: a joint cross-sectional and longitudinal analysis, Cognition and
Emotion, DOI: 10.1080/02699931.2017.1349650

To link to this article:  http://dx.doi.org/10.1080/02699931.2017.1349650

 

Steve

 

Dr Steven G. Candy

Director/Consultant

SCANDY STATISTICAL MODELLING PTY LTD

(ABN: 83 601 268 419)

70 Burwood Drive

Blackmans Bay, TASMANIA, Australia 7052

Mobile: (61) 0439284983

 


	[[alternative HTML version deleted]]


From jrosen at msu.edu  Fri Feb  2 21:56:53 2018
From: jrosen at msu.edu (Joshua Rosenberg)
Date: Fri, 02 Feb 2018 20:56:53 +0000
Subject: [R-sig-ME] Empirical Bayes and mixed effects modeling - are these
	the same thing?
Message-ID: <CANYHYTRFVN2hdJLgJAM25SCpvbX0GELEz-mSbJPYPTHjizFUrg@mail.gmail.com>

Hi all, I have been curious about the similarities and differences between
Empirical Bayes and mixed effects modeling approaches. The Wikipedia page
<https://en.wikipedia.org/wiki/Empirical_Bayes_method> for Empirical Bayes,
for instance, says

"Empirical Bayes methods are procedures for statistical inference in which
the prior distribution is estimated from the data. This approach stands in
contrast to standard Bayesian methods, for which the prior distribution is
fixed before any data are observed. Despite this difference in perspective,
empirical Bayes may be viewed as an approximation to a fully Bayesian
treatment of a hierarchical model wherein the parameters at the highest
level of the hierarchy are set to their most likely values, instead of
being integrated out."

This sounds a lot like a mixed effects model, wherein the grand mean /
variance for the outcome represents the prior for the random effects
predictions. Are these the same thing? Just a curiosity and I had trouble
finding helpful answers after look elsewhere.

Josh
-- 
Joshua Rosenberg, Ph.D. Candidate
Educational Psychology ?&? Educational Technology
Michigan State University
http://jmichaelrosenberg.com

	[[alternative HTML version deleted]]


From jdpo223 at g.uky.edu  Sat Feb  3 15:47:11 2018
From: jdpo223 at g.uky.edu (Poe, John)
Date: Sat, 3 Feb 2018 09:47:11 -0500
Subject: [R-sig-ME] Empirical Bayes and mixed effects modeling - are
 these the same thing?
In-Reply-To: <CANYHYTRFVN2hdJLgJAM25SCpvbX0GELEz-mSbJPYPTHjizFUrg@mail.gmail.com>
References: <CANYHYTRFVN2hdJLgJAM25SCpvbX0GELEz-mSbJPYPTHjizFUrg@mail.gmail.com>
Message-ID: <CAFW8Byqoz4mPhkPzYFrnP-XUbi99Kuo9YKb_w=AH71N4iW-hBg@mail.gmail.com>

They are very related and, depending on how you were trained to view the
material, mixed effects models are a subset of EB. Random effects are
usually (almost always) estimated with shrinkage which is directly related
to EB. In a lot of the software the connection is made very explicit when
estimating random effects in nonlinear models because they are called
empirical bayes means or emperical bayes modes instead of BLUP's (which
don't exist in that context).

Richard McElreath does a great job in his book/lectures making these points
in terms of bayesian shrinkage but the logic holds here just the same.

https://youtu.be/yakg94HyWdE

On Feb 3, 2018 9:27 AM, "Joshua Rosenberg" <jrosen at msu.edu> wrote:

Hi all, I have been curious about the similarities and differences between
Empirical Bayes and mixed effects modeling approaches. The Wikipedia page
<https://en.wikipedia.org/wiki/Empirical_Bayes_method> for Empirical Bayes,
for instance, says

"Empirical Bayes methods are procedures for statistical inference in which
the prior distribution is estimated from the data. This approach stands in
contrast to standard Bayesian methods, for which the prior distribution is
fixed before any data are observed. Despite this difference in perspective,
empirical Bayes may be viewed as an approximation to a fully Bayesian
treatment of a hierarchical model wherein the parameters at the highest
level of the hierarchy are set to their most likely values, instead of
being integrated out."

This sounds a lot like a mixed effects model, wherein the grand mean /
variance for the outcome represents the prior for the random effects
predictions. Are these the same thing? Just a curiosity and I had trouble
finding helpful answers after look elsewhere.

Josh
--
Joshua Rosenberg, Ph.D. Candidate
Educational Psychology ?&? Educational Technology
Michigan State University
http://jmichaelrosenberg.com

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From escritor005 at gmail.com  Sat Feb  3 17:18:08 2018
From: escritor005 at gmail.com (Ambreen Hamadani)
Date: Sat, 3 Feb 2018 21:48:08 +0530
Subject: [R-sig-ME] MCMCglmm for Estimated Breeding Values
Message-ID: <CAPKEHw2m=uFmBqXFwMJT5WiJt2vA_ApctjMPEyDuEGJ0-t9_cw@mail.gmail.com>

Dear Dr. Hadfield,

I am writing in connection with the MCMCglmm package and the estimation of
Breeding Values. While I have successfully estimated heritability using
your package, I am not sure as to how to estimate breeding values. I
couldn't find much help in this regard.

I would be really grateful if you would be so kind as to help me in
understanding how to estimate the breeding values using your package.
Any document/ note regarding this would be a great help.

Thanking you in anticipation

Best regards,
Dr. Hamadani

	[[alternative HTML version deleted]]


From j.hadfield at ed.ac.uk  Sat Feb  3 20:39:28 2018
From: j.hadfield at ed.ac.uk (HADFIELD Jarrod)
Date: Sat, 3 Feb 2018 19:39:28 +0000
Subject: [R-sig-ME] MCMCglmm for Estimated Breeding Values
In-Reply-To: <CAPKEHw2m=uFmBqXFwMJT5WiJt2vA_ApctjMPEyDuEGJ0-t9_cw@mail.gmail.com>
References: <CAPKEHw2m=uFmBqXFwMJT5WiJt2vA_ApctjMPEyDuEGJ0-t9_cw@mail.gmail.com>
Message-ID: <VI1PR0502MB3821C769ACB7F1011C48B138ACF80@VI1PR0502MB3821.eurprd05.prod.outlook.com>

Hi,


If you pass pr=TRUE to MCMCglmm this will save the random effects including the breeding values. They are stored in $Sol.


Cheers,


Jarrod

________________________________
From: Ambreen Hamadani <escritor005 at gmail.com>
Sent: 03 February 2018 16:18:08
To: HADFIELD Jarrod; r-sig-mixed-models at r-project.org
Subject: MCMCglmm for Estimated Breeding Values

Dear Dr. Hadfield,

I am writing in connection with the MCMCglmm package and the estimation of Breeding Values. While I have successfully estimated heritability using your package, I am not sure as to how to estimate breeding values. I couldn't find much help in this regard.

I would be really grateful if you would be so kind as to help me in understanding how to estimate the breeding values using your package.
Any document/ note regarding this would be a great help.

Thanking you in anticipation

Best regards,
Dr. Hamadani


-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20180203/d2c4766f/attachment-0001.ksh>

From c.c.voeten at hum.leidenuniv.nl  Sun Feb  4 10:15:07 2018
From: c.c.voeten at hum.leidenuniv.nl (Voeten, C.C.)
Date: Sun, 4 Feb 2018 09:15:07 +0000
Subject: [R-sig-ME] What is the default covariance structure in the
 glmmPQL function (MASS package)?
In-Reply-To: <07bc7747-9403-ab40-c9d2-c9536287632d@gmx.de>
References: <07bc7747-9403-ab40-c9d2-c9536287632d@gmx.de>
Message-ID: <D14049CE02C4F54D95360EEC06CE45C50F801650@SPMXM08.VUW.leidenuniv.nl>

Hi Gerda,

Since glmmPQL works by repeated calls to lme, it should work the same as lme does, i.e. the default random-effects parameterization is log-Cholesky with an unstructured covariance matrix. Specifying other covariance structures should work the same as in lme, e.g. random=list(grouping=pdDiag(~covariates)) for diagonal; see ?pdClasses.

Good luck,
Cesko

-----Oorspronkelijk bericht-----
Van: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Gerda B?rner
Verzonden: vrijdag 2 februari 2018 9:58
Aan: r-sig-mixed-models at r-project.org
Onderwerp: [R-sig-ME] What is the default covariance structure in the glmmPQL function (MASS package)?

Hello,

I sent my query to the r-project.org mailing list first where I got told to rather send it to the r-sig-mixed-models mailing list. I hope someone can help me with my question although the r-sig-mixed-models mailing list refers to issues with using lme4 rather than the glmmPQL function from the MASS package.

So here is my question:
Currently I am trying to fit a generalized linear mixed model with binary outcome using the glmmPQL function in the MASS package.

I was wondering, which variance-covariance structure the glmmPQL function is using by default and if it is possible to vary the variance-covariance structure with the glmmPQL function. Unfortunately I couldn't manage to find out myself.
If it is possible to change it, could someone tell me how to do so? I am especially interested in a diagonal structure versus an unstructured variance-covariance structure.

Thanks a lot in advance.

Gerda

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From orchidn at live.com  Mon Feb  5 01:37:14 2018
From: orchidn at live.com (dani)
Date: Mon, 5 Feb 2018 00:37:14 +0000
Subject: [R-sig-ME] ICC for glmer Poisson
In-Reply-To: <E720FC07-D158-435E-83C3-3EC2D353BF38@glasgow.ac.uk>
References: <MWHPR1201MB00295A42C657882F59370DC0D6F90@MWHPR1201MB0029.namprd12.prod.outlook.com>,
 <E720FC07-D158-435E-83C3-3EC2D353BF38@glasgow.ac.uk>
Message-ID: <MWHPR1201MB002900BA8A31ED7A3881536ED6FE0@MWHPR1201MB0029.namprd12.prod.outlook.com>

Thank you so much for these great suggestions!


MD

________________________________
From: Paul Johnson <paul.johnson at glasgow.ac.uk>
Sent: Friday, February 2, 2018 2:46 PM
To: dani
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] ICC for glmer Poisson

Hi,

Have a look at

Nakagawa, Shinichi, and Holger Schielzeth. 2010. ?Repeatability for Gaussian and Non-Gaussian Data: A Practical Guide for Biologists.? Biological Reviews of the Cambridge Philosophical Society 85 (4): 935?56. doi:10.1111/j.1469-185X.2010.00141.x.
dx.doi.org/10.1111/j.1469-185X.2010.00141.x

and the related rptR package:

Stoffel, M., Nakagawa, S. & Schielzeth, H. (2017) rptR: Repeatability estimation and variance decomposition by generalized linear mixed-effects models.. Methods Ecol Evol. Accepted Author Manuscript. doi:10.1111/2041-210X.12797

There are various ways to get CIs for variances, the easiest is applying confint() to a glmer fit (in fact I think this gives CIs for the SDs). For getting confidence (credible) intervals from variance estimates though I think MCMC (e.g. MCMCglmm) works best.
For testing random effects, see:
http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#testing-significance-of-random-effects
GLMM FAQ - GitHub Pages<http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#testing-significance-of-random-effects>
bbolker.github.io
Introduction. This is an informal FAQ list for the r-sig-mixed-models mailing list. The most commonly used functions for mixed modeling in R are. linear mixed models ...




Good luck,
Paul


> On 2 Feb 2018, at 17:31, dani <orchidn at live.com> wrote:
>
> Hello everyone,
>
>
> I am looking for information regarding the calculation of the ICC for a Poisson Glmer model.
>
> I remember seeing somewhere that the within group variance is considered to be 1 in the calculation of the ICC for Poisson, but I do not have a reference for that. I did some research online but I could not find much.
>
> Any help would be very appreciated.
>
>
> Also, is there a way to determine significance and CIs for variances? I was thinking that variance can be tested by comparing a Glm model (without random effects) and the Glmer model (with random effects) using anova(), but I have no idea how to calculate the CIs.
>
>
> Thank you all!
>
> MD
>
>        [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
R-sig-mixed-models Info Page - ETH Zurich<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
stat.ethz.ch
Your email address: Your name (optional): You may enter a privacy password below. This provides only mild security, but should prevent others from messing ...





	[[alternative HTML version deleted]]


From alexandresantosbr at yahoo.com.br  Mon Feb  5 20:15:20 2018
From: alexandresantosbr at yahoo.com.br (ASANTOS)
Date: Mon, 5 Feb 2018 16:15:20 -0300
Subject: [R-sig-ME] R^2 for linear mixed effects models with glmer()
Message-ID: <e3dce7b1-f1a9-642d-2feb-a74512ee7d65@yahoo.com.br>

Dear Mix Models Members,

 ?????? I try to extract R^2 for linear mixed effects models with 
glmer() function with poisson distribution using r.squaredGLMM() in 
MuMIn package, but doesn't work. My output always show:

#Model ajusted > mT <-glmer(riqueza ~tipo_trat+(1|Ponto),data=d1, + 
family=poisson, control = glmerControl(check.conv.singular = 
"warning",optCtrl = list(maxfun=100000))) Warning messages: 1: In 
checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv, :Model 
failed to converge with max|grad| = 0.00894145 (tol = 0.001, component 
1) 2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = 
control$checkConv, :singular fit 3: In checkConv(attr(opt, "derivs"), 
opt$par, ctrl = control$checkConv, :Model is nearly unidentifiable: very 
large eigenvalue - Rescale variables?;Model is nearly unidentifiable: 
large eigenvalue ratio - Rescale variables? #R^2 conditional and 
marginal > r.squaredGLMM(mT) Error in glmer(formula = riqueza ~ 
tipo_trat + temp_final + temp_inici + : fitting model with the 
observation-level random effect term failed. Add the term manually In 
addition: Warning message: In value[[3L]](cond) :(p <- ncol(X)) == 
ncol(Y) is not TRUE

 ???? I change almost all parameters indicating by web posts like 
glmerControl, maxfun, etc. There are other approaches to calculate the 
conditional and marginal R^2 for my model with lme4 package?

Thanks in advance,

Alexandre

-- 
======================================================================
Alexandre dos Santos
Prote??o Florestal
IFMT - Instituto Federal de Educa??o, Ci?ncia e Tecnologia de Mato Grosso
Campus C?ceres
Caixa Postal 244
Avenida dos Ramires, s/n
Bairro: Distrito Industrial
C?ceres - MT                      CEP: 78.200-000
Fone: (+55) 65 99686-6970 (VIVO) (+55) 65 3221-2674 (FIXO)

         alexandre.santos at cas.ifmt.edu.br  
Lattes:http://lattes.cnpq.br/1360403201088680
OrcID: orcid.org/0000-0001-8232-6722
Researchgate:www.researchgate.net/profile/Alexandre_Santos10                        
LinkedIn: br.linkedin.com/in/alexandre-dos-santos-87961635
Mendeley:www.mendeley.com/profiles/alexandre-dos-santos6/
======================================================================


	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Tue Feb  6 10:15:29 2018
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Tue, 6 Feb 2018 10:15:29 +0100
Subject: [R-sig-ME] R^2 for linear mixed effects models with glmer()
In-Reply-To: <e3dce7b1-f1a9-642d-2feb-a74512ee7d65@yahoo.com.br>
References: <e3dce7b1-f1a9-642d-2feb-a74512ee7d65@yahoo.com.br>
Message-ID: <CAJuCY5wCPnLzZsFEx=jkpUqeOnx_cfZOzs=aEe5KHTvcUJwPRQ@mail.gmail.com>

Dear Alexandre,

First of all you need to get a stable model. Otherwise any number you
get from it is meaningless. Can you provide more detail on your model.
E.g. summary(mT), str(d1), ...

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
AND FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////




2018-02-05 20:15 GMT+01:00 ASANTOS via R-sig-mixed-models
<r-sig-mixed-models at r-project.org>:
> Dear Mix Models Members,
>
>         I try to extract R^2 for linear mixed effects models with
> glmer() function with poisson distribution using r.squaredGLMM() in
> MuMIn package, but doesn't work. My output always show:
>
> #Model ajusted > mT <-glmer(riqueza ~tipo_trat+(1|Ponto),data=d1, +
> family=poisson, control = glmerControl(check.conv.singular =
> "warning",optCtrl = list(maxfun=100000))) Warning messages: 1: In
> checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv, :Model
> failed to converge with max|grad| = 0.00894145 (tol = 0.001, component
> 1) 2: In checkConv(attr(opt, "derivs"), opt$par, ctrl =
> control$checkConv, :singular fit 3: In checkConv(attr(opt, "derivs"),
> opt$par, ctrl = control$checkConv, :Model is nearly unidentifiable: very
> large eigenvalue - Rescale variables?;Model is nearly unidentifiable:
> large eigenvalue ratio - Rescale variables? #R^2 conditional and
> marginal > r.squaredGLMM(mT) Error in glmer(formula = riqueza ~
> tipo_trat + temp_final + temp_inici + : fitting model with the
> observation-level random effect term failed. Add the term manually In
> addition: Warning message: In value[[3L]](cond) :(p <- ncol(X)) ==
> ncol(Y) is not TRUE
>
>       I change almost all parameters indicating by web posts like
> glmerControl, maxfun, etc. There are other approaches to calculate the
> conditional and marginal R^2 for my model with lme4 package?
>
> Thanks in advance,
>
> Alexandre
>
> --
> ======================================================================
> Alexandre dos Santos
> Prote??o Florestal
> IFMT - Instituto Federal de Educa??o, Ci?ncia e Tecnologia de Mato Grosso
> Campus C?ceres
> Caixa Postal 244
> Avenida dos Ramires, s/n
> Bairro: Distrito Industrial
> C?ceres - MT                      CEP: 78.200-000
> Fone: (+55) 65 99686-6970 (VIVO) (+55) 65 3221-2674 (FIXO)
>
>          alexandre.santos at cas.ifmt.edu.br
> Lattes:http://lattes.cnpq.br/1360403201088680
> OrcID: orcid.org/0000-0001-8232-6722
> Researchgate:www.researchgate.net/profile/Alexandre_Santos10
> LinkedIn: br.linkedin.com/in/alexandre-dos-santos-87961635
> Mendeley:www.mendeley.com/profiles/alexandre-dos-santos6/
> ======================================================================
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From altessedac2 at gmail.com  Tue Feb  6 15:29:55 2018
From: altessedac2 at gmail.com (C. AMAL D. GLELE)
Date: Tue, 6 Feb 2018 15:29:55 +0100
Subject: [R-sig-ME] =?utf-8?q?GoodnessOfFit-and-PseudoR=C2=B2computingFor?=
	=?utf-8?q?-glmmTMB-models?=
Message-ID: <CANrzCv1WFzqkREzOBh2TWRPQd-9oRx7u1vXZHfEFKsSUaB=jfg@mail.gmail.com>

Hi, dear all
Please, your help for the following problem:
when I fit a mixed model using glmmTMB (poisson family or others), how do I:
1) check, if the model fits well my data (goodness of fit)?
2) check if my model is overdisperced or not (by using sigma(model)?)
3) compute an pseudo R? to see the percentage of the variability of my
response which is explained by my model?
In advance, thanks for your answers.
Regards,

	[[alternative HTML version deleted]]


From paul.johnson at glasgow.ac.uk  Tue Feb  6 15:53:25 2018
From: paul.johnson at glasgow.ac.uk (Paul Johnson)
Date: Tue, 6 Feb 2018 14:53:25 +0000
Subject: [R-sig-ME] 
 =?utf-8?q?GoodnessOfFit-and-PseudoR=C2=B2computingFor?=
 =?utf-8?q?-glmmTMB-models?=
In-Reply-To: <CANrzCv1WFzqkREzOBh2TWRPQd-9oRx7u1vXZHfEFKsSUaB=jfg@mail.gmail.com>
References: <CANrzCv1WFzqkREzOBh2TWRPQd-9oRx7u1vXZHfEFKsSUaB=jfg@mail.gmail.com>
Message-ID: <D961F1DE-FCB2-4B31-9F56-F5E354A3129A@glasgow.ac.uk>

Hi,

My preferred approach to overdispersion is none of 1-3 but to assume it applies (it usually does, for biological data anyway), and make sure the model includes a parameter to model overdispersion. For binomial (except Bernoulli) and Poisson you can include an observation-level random effect (OLRE). You can then gauge the amount of overdispersion in the model from the size of the OLRE variance estimate. (Note the OLRE will mop up variation due to *all* sources of lack of fit, including poor model specification, e.g. fitting a straight line where a curve would fit better.)

Best wishes,
Paul


> On 6 Feb 2018, at 14:29, C. AMAL D. GLELE <altessedac2 at gmail.com> wrote:
> 
> Hi, dear all
> Please, your help for the following problem:
> when I fit a mixed model using glmmTMB (poisson family or others), how do I:
> 1) check, if the model fits well my data (goodness of fit)?
> 2) check if my model is overdisperced or not (by using sigma(model)?)
> 3) compute an pseudo R? to see the percentage of the variability of my
> response which is explained by my model?
> In advance, thanks for your answers.
> Regards,
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From n.mitsakakis at theta.utoronto.ca  Tue Feb  6 17:08:35 2018
From: n.mitsakakis at theta.utoronto.ca (Nicholas Mitsakakis)
Date: Tue, 6 Feb 2018 11:08:35 -0500
Subject: [R-sig-ME] glmer and weights
Message-ID: <CAJ4s-a6vB7NYpMfVeHbFEJgJAAasxUgbMc1nMrY_LbZYj9eeKg@mail.gmail.com>

Hello,

I am looking for more information on what the weights option is doing for
glmer, specifically when distribution is gamma and link is log. In my
specific case I also have offset, so I am not sure if weights can be used
and what exactly would do.

Any information would be greatly appreciated.


Thanks,
Nicholas

-- 

------------------------------
This e-mail may be confidential and/or privileged and is intended to be 
viewed only by the recipient(s) named above. If you are not the intended 
recipient, you are strictly prohibited from reading, using, disclosing, 
copying or distributing this e-mail. If you received this e-mail in error, 
please immediately notify the sender, and permanently delete this e-mail 
and any attachments.

	[[alternative HTML version deleted]]


From alexandresantosbr at yahoo.com.br  Tue Feb  6 20:33:57 2018
From: alexandresantosbr at yahoo.com.br (ASANTOS)
Date: Tue, 6 Feb 2018 16:33:57 -0300
Subject: [R-sig-ME] R^2 for linear mixed effects models with glmer()
In-Reply-To: <CAJuCY5wCPnLzZsFEx=jkpUqeOnx_cfZOzs=aEe5KHTvcUJwPRQ@mail.gmail.com>
References: <e3dce7b1-f1a9-642d-2feb-a74512ee7d65@yahoo.com.br>
 <CAJuCY5wCPnLzZsFEx=jkpUqeOnx_cfZOzs=aEe5KHTvcUJwPRQ@mail.gmail.com>
Message-ID: <250baba4-4f1f-4349-9191-460a5d32b7bc@yahoo.com.br>

Thanks Thierry,

 ?????? Sorry about my question, I start to use the mixed models 
approach recently. My structure of data was:

'data.frame':	288 obs. of  13 variables:
  $ Transecto        : int  2 2 2 2 2 2 3 3 3 3 ...
  $ Ponto            : int  1 2 3 4 5 6 1 2 3 4 ...
  $ Distancia        : int  160 120 80 40 20 0 160 120 80 40 ...
  $ tipo_trat        : Factor w/ 4 levels "","controle",..: 3 3 3 3 3 3 4 4 4 4 ...
  $ umid_inici       : num  81.3 84.1 81.3 83.9 81.9 ...
  $ umid_final       : num  63.7 68 66.2 66.8 66.4 ...
  $ temp_inici       : num  19.1 19.5 19.5 19.1 19.1 ...
  $ temp_final       : num  29.1 27.8 27.6 28 28.6 ...
  $ abertu_dossel    : num  35.6 20.8 28.9 30.6 27.1 ...
  $ delta.umidade    : num  -17.6 -16.1 -15.2 -17.1 -15.5 ...
  $ delta.temperatura: num  9.95 8.3 8.1 8.91 9.5 ...
  $ remocao          : num  0.02 0 0.1 0 0.08 0 1 0.04 0.08 0.42 ...
  $ riqueza          : int  3 9 3 3 4 5 4 3 2 5 ...


And the summary of model below. In my case is a adjustment problem or in 
r.squaredGLMM() function?

> summary(mT) Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) [
glmerMod]
  Family: poisson  ( log )
Formula: riqueza ~ tipo_trat + temp_final + temp_inici + umid_inici +
     umid_final + (1 | Ponto)
    Data: d1
Control:
glmerControl(check.conv.singular = "warning", optCtrl = list(maxfun = 1e+05))

      AIC      BIC   logLik deviance df.resid
    326.1    344.3   -155.0    310.1       64

Scaled residuals:
     Min      1Q  Median      3Q     Max
-1.8416 -0.7947 -0.2221  0.7253  2.4622

Random effects:
  Groups Name        Variance  Std.Dev.
  Ponto  (Intercept) 5.293e-17 7.275e-09
Number of obs: 72, groups:  Ponto, 6

Fixed effects:
                       Estimate Std. Error z value Pr(>|z|)
(Intercept)           -5.18941    3.18615  -1.629   0.1034
tipo_trattrat_euc     -0.51209    0.29360  -1.744   0.0811 .
tipo_trattrat_mat_euc -0.43877    0.25986  -1.688   0.0913 .
temp_final             0.06914    0.04144   1.669   0.0952 .
temp_inici             0.07176    0.05479   1.310   0.1903
umid_inici             0.03270    0.02543   1.286   0.1985
umid_final             0.01774    0.01660   1.069   0.2850
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Correlation of Fixed Effects:
             (Intr) tp_tr_ tp_t__ tmp_fn tmp_nc umd_nc
tp_trttrt_c  0.457
tp_trttrt__  0.525  0.358
temp_final  -0.546 -0.393 -0.143
temp_inici  -0.750 -0.557 -0.696  0.037
umid_inici  -0.755  0.028 -0.522 -0.020  0.667
umid_final  -0.287 -0.661  0.236  0.651  0.023 -0.352
convergence code: 0
Model failed to converge with max|grad| = 0.00894145 (tol = 0.001, component 1)
singular fit
Model is nearly unidentifiable: very large eigenvalue
  - Rescale variables?
Model is nearly unidentifiable: large eigenvalue ratio
  - Rescale variables?

-- 
======================================================================
Alexandre dos Santos
Prote??o Florestal
IFMT - Instituto Federal de Educa??o, Ci?ncia e Tecnologia de Mato Grosso
Campus C?ceres
Caixa Postal 244
Avenida dos Ramires, s/n
Bairro: Distrito Industrial
C?ceres - MT                      CEP: 78.200-000
Fone: (+55) 65 99686-6970 (VIVO) (+55) 65 3221-2674 (FIXO)

         alexandre.santos at cas.ifmt.edu.br
Lattes: http://lattes.cnpq.br/1360403201088680
OrcID: orcid.org/0000-0001-8232-6722
Researchgate: www.researchgate.net/profile/Alexandre_Santos10
LinkedIn: br.linkedin.com/in/alexandre-dos-santos-87961635
Mendeley:www.mendeley.com/profiles/alexandre-dos-santos6/
======================================================================

Em 06/02/2018 06:15, Thierry Onkelinx escreveu:
> Dear Alexandre,
>
> First of all you need to get a stable model. Otherwise any number you
> get from it is meaningless. Can you provide more detail on your model.
> E.g. summary(mT), str(d1), ...
>
> Best regards,
>
> ir. Thierry Onkelinx
> Statisticus / Statistician
>
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
> AND FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Havenlaan 88 bus 73, 1000 Brussel
> www.inbo.be
>
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no
> more than asking him to perform a post-mortem examination: he may be
> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does
> not ensure that a reasonable answer can be extracted from a given body
> of data. ~ John Tukey
> ///////////////////////////////////////////////////////////////////////////////////////////
>
>
>
>
> 2018-02-05 20:15 GMT+01:00 ASANTOS via R-sig-mixed-models
> <r-sig-mixed-models at r-project.org>:
>> Dear Mix Models Members,
>>
>>          I try to extract R^2 for linear mixed effects models with
>> glmer() function with poisson distribution using r.squaredGLMM() in
>> MuMIn package, but doesn't work. My output always show:
>>
>> #Model ajusted > mT <-glmer(riqueza ~tipo_trat+(1|Ponto),data=d1, +
>> family=poisson, control = glmerControl(check.conv.singular =
>> "warning",optCtrl = list(maxfun=100000))) Warning messages: 1: In
>> checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv, :Model
>> failed to converge with max|grad| = 0.00894145 (tol = 0.001, component
>> 1) 2: In checkConv(attr(opt, "derivs"), opt$par, ctrl =
>> control$checkConv, :singular fit 3: In checkConv(attr(opt, "derivs"),
>> opt$par, ctrl = control$checkConv, :Model is nearly unidentifiable: very
>> large eigenvalue - Rescale variables?;Model is nearly unidentifiable:
>> large eigenvalue ratio - Rescale variables? #R^2 conditional and
>> marginal > r.squaredGLMM(mT) Error in glmer(formula = riqueza ~
>> tipo_trat + temp_final + temp_inici + : fitting model with the
>> observation-level random effect term failed. Add the term manually In
>> addition: Warning message: In value[[3L]](cond) :(p <- ncol(X)) ==
>> ncol(Y) is not TRUE
>>
>>        I change almost all parameters indicating by web posts like
>> glmerControl, maxfun, etc. There are other approaches to calculate the
>> conditional and marginal R^2 for my model with lme4 package?
>>
>> Thanks in advance,
>>
>> Alexandre
>>
>> --
>> ======================================================================
>> Alexandre dos Santos
>> Prote??o Florestal
>> IFMT - Instituto Federal de Educa??o, Ci?ncia e Tecnologia de Mato Grosso
>> Campus C?ceres
>> Caixa Postal 244
>> Avenida dos Ramires, s/n
>> Bairro: Distrito Industrial
>> C?ceres - MT                      CEP: 78.200-000
>> Fone: (+55) 65 99686-6970 (VIVO) (+55) 65 3221-2674 (FIXO)
>>
>>           alexandre.santos at cas.ifmt.edu.br
>> Lattes:http://lattes.cnpq.br/1360403201088680
>> OrcID: orcid.org/0000-0001-8232-6722
>> Researchgate:www.researchgate.net/profile/Alexandre_Santos10
>> LinkedIn: br.linkedin.com/in/alexandre-dos-santos-87961635
>> Mendeley:www.mendeley.com/profiles/alexandre-dos-santos6/
>> ======================================================================
>>
>>
>>          [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


	[[alternative HTML version deleted]]


From alexandresantosbr at yahoo.com.br  Tue Feb  6 20:34:18 2018
From: alexandresantosbr at yahoo.com.br (ASANTOS)
Date: Tue, 6 Feb 2018 16:34:18 -0300
Subject: [R-sig-ME] R^2 for linear mixed effects models with glmer()
In-Reply-To: <CAJuCY5wCPnLzZsFEx=jkpUqeOnx_cfZOzs=aEe5KHTvcUJwPRQ@mail.gmail.com>
References: <e3dce7b1-f1a9-642d-2feb-a74512ee7d65@yahoo.com.br>
 <CAJuCY5wCPnLzZsFEx=jkpUqeOnx_cfZOzs=aEe5KHTvcUJwPRQ@mail.gmail.com>
Message-ID: <87624626-56b3-e0e2-6953-faa151d3cf00@yahoo.com.br>

Thanks Thierry,

 ?????? Sorry about my question, I start to use the mixed models 
approach recently. My structure of data was:

'data.frame':	288 obs. of  13 variables:
  $ Transecto        : int  2 2 2 2 2 2 3 3 3 3 ...
  $ Ponto            : int  1 2 3 4 5 6 1 2 3 4 ...
  $ Distancia        : int  160 120 80 40 20 0 160 120 80 40 ...
  $ tipo_trat        : Factor w/ 4 levels "","controle",..: 3 3 3 3 3 3 4 4 4 4 ...
  $ umid_inici       : num  81.3 84.1 81.3 83.9 81.9 ...
  $ umid_final       : num  63.7 68 66.2 66.8 66.4 ...
  $ temp_inici       : num  19.1 19.5 19.5 19.1 19.1 ...
  $ temp_final       : num  29.1 27.8 27.6 28 28.6 ...
  $ abertu_dossel    : num  35.6 20.8 28.9 30.6 27.1 ...
  $ delta.umidade    : num  -17.6 -16.1 -15.2 -17.1 -15.5 ...
  $ delta.temperatura: num  9.95 8.3 8.1 8.91 9.5 ...
  $ remocao          : num  0.02 0 0.1 0 0.08 0 1 0.04 0.08 0.42 ...
  $ riqueza          : int  3 9 3 3 4 5 4 3 2 5 ...


And the summary of model below. In my case is a adjustment problem or in 
r.squaredGLMM() function?

> summary(mT) Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) [
glmerMod]
  Family: poisson  ( log )
Formula: riqueza ~ tipo_trat + temp_final + temp_inici + umid_inici +
     umid_final + (1 | Ponto)
    Data: d1
Control:
glmerControl(check.conv.singular = "warning", optCtrl = list(maxfun = 1e+05))

      AIC      BIC   logLik deviance df.resid
    326.1    344.3   -155.0    310.1       64

Scaled residuals:
     Min      1Q  Median      3Q     Max
-1.8416 -0.7947 -0.2221  0.7253  2.4622

Random effects:
  Groups Name        Variance  Std.Dev.
  Ponto  (Intercept) 5.293e-17 7.275e-09
Number of obs: 72, groups:  Ponto, 6

Fixed effects:
                       Estimate Std. Error z value Pr(>|z|)
(Intercept)           -5.18941    3.18615  -1.629   0.1034
tipo_trattrat_euc     -0.51209    0.29360  -1.744   0.0811 .
tipo_trattrat_mat_euc -0.43877    0.25986  -1.688   0.0913 .
temp_final             0.06914    0.04144   1.669   0.0952 .
temp_inici             0.07176    0.05479   1.310   0.1903
umid_inici             0.03270    0.02543   1.286   0.1985
umid_final             0.01774    0.01660   1.069   0.2850
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Correlation of Fixed Effects:
             (Intr) tp_tr_ tp_t__ tmp_fn tmp_nc umd_nc
tp_trttrt_c  0.457
tp_trttrt__  0.525  0.358
temp_final  -0.546 -0.393 -0.143
temp_inici  -0.750 -0.557 -0.696  0.037
umid_inici  -0.755  0.028 -0.522 -0.020  0.667
umid_final  -0.287 -0.661  0.236  0.651  0.023 -0.352
convergence code: 0
Model failed to converge with max|grad| = 0.00894145 (tol = 0.001, component 1)
singular fit
Model is nearly unidentifiable: very large eigenvalue
  - Rescale variables?
Model is nearly unidentifiable: large eigenvalue ratio
  - Rescale variables?

-- 
======================================================================
Alexandre dos Santos
Prote??o Florestal
IFMT - Instituto Federal de Educa??o, Ci?ncia e Tecnologia de Mato Grosso
Campus C?ceres
Caixa Postal 244
Avenida dos Ramires, s/n
Bairro: Distrito Industrial
C?ceres - MT                      CEP: 78.200-000
Fone: (+55) 65 99686-6970 (VIVO) (+55) 65 3221-2674 (FIXO)

         alexandre.santos at cas.ifmt.edu.br
Lattes: http://lattes.cnpq.br/1360403201088680
OrcID: orcid.org/0000-0001-8232-6722
Researchgate: www.researchgate.net/profile/Alexandre_Santos10
LinkedIn: br.linkedin.com/in/alexandre-dos-santos-87961635
Mendeley:www.mendeley.com/profiles/alexandre-dos-santos6/
======================================================================

Em 06/02/2018 06:15, Thierry Onkelinx escreveu:
> Dear Alexandre,
>
> First of all you need to get a stable model. Otherwise any number you
> get from it is meaningless. Can you provide more detail on your model.
> E.g. summary(mT), str(d1), ...
>
> Best regards,
>
> ir. Thierry Onkelinx
> Statisticus / Statistician
>
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
> AND FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Havenlaan 88 bus 73, 1000 Brussel
> www.inbo.be
>
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no
> more than asking him to perform a post-mortem examination: he may be
> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does
> not ensure that a reasonable answer can be extracted from a given body
> of data. ~ John Tukey
> ///////////////////////////////////////////////////////////////////////////////////////////
>
>
>
>
> 2018-02-05 20:15 GMT+01:00 ASANTOS via R-sig-mixed-models
> <r-sig-mixed-models at r-project.org>:
>> Dear Mix Models Members,
>>
>>          I try to extract R^2 for linear mixed effects models with
>> glmer() function with poisson distribution using r.squaredGLMM() in
>> MuMIn package, but doesn't work. My output always show:
>>
>> #Model ajusted > mT <-glmer(riqueza ~tipo_trat+(1|Ponto),data=d1, +
>> family=poisson, control = glmerControl(check.conv.singular =
>> "warning",optCtrl = list(maxfun=100000))) Warning messages: 1: In
>> checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv, :Model
>> failed to converge with max|grad| = 0.00894145 (tol = 0.001, component
>> 1) 2: In checkConv(attr(opt, "derivs"), opt$par, ctrl =
>> control$checkConv, :singular fit 3: In checkConv(attr(opt, "derivs"),
>> opt$par, ctrl = control$checkConv, :Model is nearly unidentifiable: very
>> large eigenvalue - Rescale variables?;Model is nearly unidentifiable:
>> large eigenvalue ratio - Rescale variables? #R^2 conditional and
>> marginal > r.squaredGLMM(mT) Error in glmer(formula = riqueza ~
>> tipo_trat + temp_final + temp_inici + : fitting model with the
>> observation-level random effect term failed. Add the term manually In
>> addition: Warning message: In value[[3L]](cond) :(p <- ncol(X)) ==
>> ncol(Y) is not TRUE
>>
>>        I change almost all parameters indicating by web posts like
>> glmerControl, maxfun, etc. There are other approaches to calculate the
>> conditional and marginal R^2 for my model with lme4 package?
>>
>> Thanks in advance,
>>
>> Alexandre
>>
>> --
>> ======================================================================
>> Alexandre dos Santos
>> Prote??o Florestal
>> IFMT - Instituto Federal de Educa??o, Ci?ncia e Tecnologia de Mato Grosso
>> Campus C?ceres
>> Caixa Postal 244
>> Avenida dos Ramires, s/n
>> Bairro: Distrito Industrial
>> C?ceres - MT                      CEP: 78.200-000
>> Fone: (+55) 65 99686-6970 (VIVO) (+55) 65 3221-2674 (FIXO)
>>
>>           alexandre.santos at cas.ifmt.edu.br
>> Lattes:http://lattes.cnpq.br/1360403201088680
>> OrcID: orcid.org/0000-0001-8232-6722
>> Researchgate:www.researchgate.net/profile/Alexandre_Santos10
>> LinkedIn: br.linkedin.com/in/alexandre-dos-santos-87961635
>> Mendeley:www.mendeley.com/profiles/alexandre-dos-santos6/
>> ======================================================================
>>
>>
>>          [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


	[[alternative HTML version deleted]]


From altessedac2 at gmail.com  Tue Feb  6 23:13:30 2018
From: altessedac2 at gmail.com (C. AMAL D. GLELE)
Date: Tue, 6 Feb 2018 23:13:30 +0100
Subject: [R-sig-ME] 
	=?utf-8?q?GoodnessOfFit-and-PseudoR=C2=B2computingFor?=
	=?utf-8?q?-glmmTMB-models?=
In-Reply-To: <D961F1DE-FCB2-4B31-9F56-F5E354A3129A@glasgow.ac.uk>
References: <CANrzCv1WFzqkREzOBh2TWRPQd-9oRx7u1vXZHfEFKsSUaB=jfg@mail.gmail.com>
 <D961F1DE-FCB2-4B31-9F56-F5E354A3129A@glasgow.ac.uk>
Message-ID: <CANrzCv3pJyAAGyBb19Okjx=55P6Ek1afF3GbjWiDOk-wEMvyyA@mail.gmail.com>

Many thanks, Paul.
Regards,

2018-02-06 15:53 GMT+01:00 Paul Johnson <paul.johnson at glasgow.ac.uk>:

> Hi,
>
> My preferred approach to overdispersion is none of 1-3 but to assume it
> applies (it usually does, for biological data anyway), and make sure the
> model includes a parameter to model overdispersion. For binomial (except
> Bernoulli) and Poisson you can include an observation-level random effect
> (OLRE). You can then gauge the amount of overdispersion in the model from
> the size of the OLRE variance estimate. (Note the OLRE will mop up
> variation due to *all* sources of lack of fit, including poor model
> specification, e.g. fitting a straight line where a curve would fit better.)
>
> Best wishes,
> Paul
>
>
> > On 6 Feb 2018, at 14:29, C. AMAL D. GLELE <altessedac2 at gmail.com> wrote:
> >
> > Hi, dear all
> > Please, your help for the following problem:
> > when I fit a mixed model using glmmTMB (poisson family or others), how
> do I:
> > 1) check, if the model fits well my data (goodness of fit)?
> > 2) check if my model is overdisperced or not (by using sigma(model)?)
> > 3) compute an pseudo R? to see the percentage of the variability of my
> > response which is explained by my model?
> > In advance, thanks for your answers.
> > Regards,
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Wed Feb  7 09:38:17 2018
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Wed, 7 Feb 2018 09:38:17 +0100
Subject: [R-sig-ME] R^2 for linear mixed effects models with glmer()
In-Reply-To: <250baba4-4f1f-4349-9191-460a5d32b7bc@yahoo.com.br>
References: <e3dce7b1-f1a9-642d-2feb-a74512ee7d65@yahoo.com.br>
 <CAJuCY5wCPnLzZsFEx=jkpUqeOnx_cfZOzs=aEe5KHTvcUJwPRQ@mail.gmail.com>
 <250baba4-4f1f-4349-9191-460a5d32b7bc@yahoo.com.br>
Message-ID: <CAJuCY5xr5Tvyxw3EkexmG4BjE7u5BsTWSMtidwW0CrD39ce8oQ@mail.gmail.com>

Dear Alexandre,

The str() is not on the same dataset that is used in the model. One
has 288 observations, the other 72.

Furthermore look at the correlation among the covariates. I expect
that the issues are due to strong collinearity.

Best regards,


ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
AND FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////




2018-02-06 20:33 GMT+01:00 ASANTOS <alexandresantosbr at yahoo.com.br>:
> Thanks Thierry,
>
>        Sorry about my question, I start to use the mixed models approach
> recently. My structure of data was:
>
> 'data.frame':	288 obs. of  13 variables:
>  $ Transecto        : int  2 2 2 2 2 2 3 3 3 3 ...
>  $ Ponto            : int  1 2 3 4 5 6 1 2 3 4 ...
>  $ Distancia        : int  160 120 80 40 20 0 160 120 80 40 ...
>  $ tipo_trat        : Factor w/ 4 levels "","controle",..: 3 3 3 3 3 3 4 4 4
> 4 ...
>  $ umid_inici       : num  81.3 84.1 81.3 83.9 81.9 ...
>  $ umid_final       : num  63.7 68 66.2 66.8 66.4 ...
>  $ temp_inici       : num  19.1 19.5 19.5 19.1 19.1 ...
>  $ temp_final       : num  29.1 27.8 27.6 28 28.6 ...
>  $ abertu_dossel    : num  35.6 20.8 28.9 30.6 27.1 ...
>  $ delta.umidade    : num  -17.6 -16.1 -15.2 -17.1 -15.5 ...
>  $ delta.temperatura: num  9.95 8.3 8.1 8.91 9.5 ...
>  $ remocao          : num  0.02 0 0.1 0 0.08 0 1 0.04 0.08 0.42 ...
>  $ riqueza          : int  3 9 3 3 4 5 4 3 2 5 ...
>
>
> And the summary of model below. In my case is a adjustment problem or in
> r.squaredGLMM() function?
>
>> summary(mT)
> Generalized linear mixed model fit by maximum likelihood (Laplace
> Approximation) [
> glmerMod]
>  Family: poisson  ( log )
> Formula: riqueza ~ tipo_trat + temp_final + temp_inici + umid_inici +
>     umid_final + (1 | Ponto)
>    Data: d1
> Control:
> glmerControl(check.conv.singular = "warning", optCtrl = list(maxfun =
> 1e+05))
>
>      AIC      BIC   logLik deviance df.resid
>    326.1    344.3   -155.0    310.1       64
>
> Scaled residuals:
>     Min      1Q  Median      3Q     Max
> -1.8416 -0.7947 -0.2221  0.7253  2.4622
>
> Random effects:
>  Groups Name        Variance  Std.Dev.
>  Ponto  (Intercept) 5.293e-17 7.275e-09
> Number of obs: 72, groups:  Ponto, 6
>
> Fixed effects:
>                       Estimate Std. Error z value Pr(>|z|)
> (Intercept)           -5.18941    3.18615  -1.629   0.1034
> tipo_trattrat_euc     -0.51209    0.29360  -1.744   0.0811 .
> tipo_trattrat_mat_euc -0.43877    0.25986  -1.688   0.0913 .
> temp_final             0.06914    0.04144   1.669   0.0952 .
> temp_inici             0.07176    0.05479   1.310   0.1903
> umid_inici             0.03270    0.02543   1.286   0.1985
> umid_final             0.01774    0.01660   1.069   0.2850
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Correlation of Fixed Effects:
>             (Intr) tp_tr_ tp_t__ tmp_fn tmp_nc umd_nc
> tp_trttrt_c  0.457
> tp_trttrt__  0.525  0.358
> temp_final  -0.546 -0.393 -0.143
> temp_inici  -0.750 -0.557 -0.696  0.037
> umid_inici  -0.755  0.028 -0.522 -0.020  0.667
> umid_final  -0.287 -0.661  0.236  0.651  0.023 -0.352
> convergence code: 0
> Model failed to converge with max|grad| = 0.00894145 (tol = 0.001, component
> 1)
> singular fit
> Model is nearly unidentifiable: very large eigenvalue
>  - Rescale variables?
> Model is nearly unidentifiable: large eigenvalue ratio
>  - Rescale variables?
>
> --
> ======================================================================
> Alexandre dos Santos
> Prote??o Florestal
> IFMT - Instituto Federal de Educa??o, Ci?ncia e Tecnologia de Mato Grosso
> Campus C?ceres
> Caixa Postal 244
> Avenida dos Ramires, s/n
> Bairro: Distrito Industrial
> C?ceres - MT                      CEP: 78.200-000
> Fone: (+55) 65 99686-6970 (VIVO) (+55) 65 3221-2674 (FIXO)
> e-mails:alexandresantosbr at yahoo.com.br
>         alexandre.santos at cas.ifmt.edu.br
> Lattes: http://lattes.cnpq.br/1360403201088680
> OrcID: orcid.org/0000-0001-8232-6722
> Researchgate: www.researchgate.net/profile/Alexandre_Santos10
> LinkedIn: br.linkedin.com/in/alexandre-dos-santos-87961635
> Mendeley:www.mendeley.com/profiles/alexandre-dos-santos6/
> ======================================================================
>
> Em 06/02/2018 06:15, Thierry Onkelinx escreveu:
>
> Dear Alexandre,
>
> First of all you need to get a stable model. Otherwise any number you
> get from it is meaningless. Can you provide more detail on your model.
> E.g. summary(mT), str(d1), ...
>
> Best regards,
>
> ir. Thierry Onkelinx
> Statisticus / Statistician
>
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
> AND FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Havenlaan 88 bus 73, 1000 Brussel
> www.inbo.be
>
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no
> more than asking him to perform a post-mortem examination: he may be
> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does
> not ensure that a reasonable answer can be extracted from a given body
> of data. ~ John Tukey
> ///////////////////////////////////////////////////////////////////////////////////////////
>
>
>
>
> 2018-02-05 20:15 GMT+01:00 ASANTOS via R-sig-mixed-models
> <r-sig-mixed-models at r-project.org>:
>
> Dear Mix Models Members,
>
>         I try to extract R^2 for linear mixed effects models with
> glmer() function with poisson distribution using r.squaredGLMM() in
> MuMIn package, but doesn't work. My output always show:
>
> #Model ajusted > mT <-glmer(riqueza ~tipo_trat+(1|Ponto),data=d1, +
> family=poisson, control = glmerControl(check.conv.singular =
> "warning",optCtrl = list(maxfun=100000))) Warning messages: 1: In
> checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv, :Model
> failed to converge with max|grad| = 0.00894145 (tol = 0.001, component
> 1) 2: In checkConv(attr(opt, "derivs"), opt$par, ctrl =
> control$checkConv, :singular fit 3: In checkConv(attr(opt, "derivs"),
> opt$par, ctrl = control$checkConv, :Model is nearly unidentifiable: very
> large eigenvalue - Rescale variables?;Model is nearly unidentifiable:
> large eigenvalue ratio - Rescale variables? #R^2 conditional and
> marginal > r.squaredGLMM(mT) Error in glmer(formula = riqueza ~
> tipo_trat + temp_final + temp_inici + : fitting model with the
> observation-level random effect term failed. Add the term manually In
> addition: Warning message: In value[[3L]](cond) :(p <- ncol(X)) ==
> ncol(Y) is not TRUE
>
>       I change almost all parameters indicating by web posts like
> glmerControl, maxfun, etc. There are other approaches to calculate the
> conditional and marginal R^2 for my model with lme4 package?
>
> Thanks in advance,
>
> Alexandre
>
> --
> ======================================================================
> Alexandre dos Santos
> Prote??o Florestal
> IFMT - Instituto Federal de Educa??o, Ci?ncia e Tecnologia de Mato Grosso
> Campus C?ceres
> Caixa Postal 244
> Avenida dos Ramires, s/n
> Bairro: Distrito Industrial
> C?ceres - MT                      CEP: 78.200-000
> Fone: (+55) 65 99686-6970 (VIVO) (+55) 65 3221-2674 (FIXO)
>
>          alexandre.santos at cas.ifmt.edu.br
> Lattes:http://lattes.cnpq.br/1360403201088680
> OrcID: orcid.org/0000-0001-8232-6722
> Researchgate:www.researchgate.net/profile/Alexandre_Santos10
> LinkedIn: br.linkedin.com/in/alexandre-dos-santos-87961635
> Mendeley:www.mendeley.com/profiles/alexandre-dos-santos6/
> ======================================================================
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>


From alexandresantosbr at yahoo.com.br  Wed Feb  7 11:40:17 2018
From: alexandresantosbr at yahoo.com.br (ASANTOS)
Date: Wed, 7 Feb 2018 07:40:17 -0300
Subject: [R-sig-ME] R^2 for linear mixed effects models with glmer()
In-Reply-To: <CAJuCY5xr5Tvyxw3EkexmG4BjE7u5BsTWSMtidwW0CrD39ce8oQ@mail.gmail.com>
References: <e3dce7b1-f1a9-642d-2feb-a74512ee7d65@yahoo.com.br>
 <CAJuCY5wCPnLzZsFEx=jkpUqeOnx_cfZOzs=aEe5KHTvcUJwPRQ@mail.gmail.com>
 <250baba4-4f1f-4349-9191-460a5d32b7bc@yahoo.com.br>
 <CAJuCY5xr5Tvyxw3EkexmG4BjE7u5BsTWSMtidwW0CrD39ce8oQ@mail.gmail.com>
Message-ID: <5062ea45-4abb-387d-ca9f-5203fab28aa5@yahoo.com.br>

Thanks again Thierry,

 ???????? I will test a possible collinearity of my explained variables.

Best wishes,

Alexandre

-- 
======================================================================
Alexandre dos Santos
Prote??o Florestal
IFMT - Instituto Federal de Educa??o, Ci?ncia e Tecnologia de Mato Grosso
Campus C?ceres
Caixa Postal 244
Avenida dos Ramires, s/n
Bairro: Distrito Industrial
C?ceres - MT                      CEP: 78.200-000
Fone: (+55) 65 99686-6970 (VIVO) (+55) 65 3221-2674 (FIXO)

         alexandre.santos at cas.ifmt.edu.br
Lattes: http://lattes.cnpq.br/1360403201088680
OrcID: orcid.org/0000-0001-8232-6722
Researchgate: www.researchgate.net/profile/Alexandre_Santos10
LinkedIn: br.linkedin.com/in/alexandre-dos-santos-87961635
Mendeley:www.mendeley.com/profiles/alexandre-dos-santos6/
======================================================================

Em 07/02/2018 05:38, Thierry Onkelinx escreveu:
> Dear Alexandre,
>
> The str() is not on the same dataset that is used in the model. One
> has 288 observations, the other 72.
>
> Furthermore look at the correlation among the covariates. I expect
> that the issues are due to strong collinearity.
>
> Best regards,
>
>
> ir. Thierry Onkelinx
> Statisticus / Statistician
>
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
> AND FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Havenlaan 88 bus 73, 1000 Brussel
> www.inbo.be
>
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no
> more than asking him to perform a post-mortem examination: he may be
> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does
> not ensure that a reasonable answer can be extracted from a given body
> of data. ~ John Tukey
> ///////////////////////////////////////////////////////////////////////////////////////////
>
>
>
>

>> Thanks Thierry,
>>
>>         Sorry about my question, I start to use the mixed models approach
>> recently. My structure of data was:
>>
>> 'data.frame':	288 obs. of  13 variables:
>>   $ Transecto        : int  2 2 2 2 2 2 3 3 3 3 ...
>>   $ Ponto            : int  1 2 3 4 5 6 1 2 3 4 ...
>>   $ Distancia        : int  160 120 80 40 20 0 160 120 80 40 ...
>>   $ tipo_trat        : Factor w/ 4 levels "","controle",..: 3 3 3 3 3 3 4 4 4
>> 4 ...
>>   $ umid_inici       : num  81.3 84.1 81.3 83.9 81.9 ...
>>   $ umid_final       : num  63.7 68 66.2 66.8 66.4 ...
>>   $ temp_inici       : num  19.1 19.5 19.5 19.1 19.1 ...
>>   $ temp_final       : num  29.1 27.8 27.6 28 28.6 ...
>>   $ abertu_dossel    : num  35.6 20.8 28.9 30.6 27.1 ...
>>   $ delta.umidade    : num  -17.6 -16.1 -15.2 -17.1 -15.5 ...
>>   $ delta.temperatura: num  9.95 8.3 8.1 8.91 9.5 ...
>>   $ remocao          : num  0.02 0 0.1 0 0.08 0 1 0.04 0.08 0.42 ...
>>   $ riqueza          : int  3 9 3 3 4 5 4 3 2 5 ...
>>
>>
>> And the summary of model below. In my case is a adjustment problem or in
>> r.squaredGLMM() function?
>>
>>> summary(mT)
>> Generalized linear mixed model fit by maximum likelihood (Laplace
>> Approximation) [
>> glmerMod]
>>   Family: poisson  ( log )
>> Formula: riqueza ~ tipo_trat + temp_final + temp_inici + umid_inici +
>>      umid_final + (1 | Ponto)
>>     Data: d1
>> Control:
>> glmerControl(check.conv.singular = "warning", optCtrl = list(maxfun =
>> 1e+05))
>>
>>       AIC      BIC   logLik deviance df.resid
>>     326.1    344.3   -155.0    310.1       64
>>
>> Scaled residuals:
>>      Min      1Q  Median      3Q     Max
>> -1.8416 -0.7947 -0.2221  0.7253  2.4622
>>
>> Random effects:
>>   Groups Name        Variance  Std.Dev.
>>   Ponto  (Intercept) 5.293e-17 7.275e-09
>> Number of obs: 72, groups:  Ponto, 6
>>
>> Fixed effects:
>>                        Estimate Std. Error z value Pr(>|z|)
>> (Intercept)           -5.18941    3.18615  -1.629   0.1034
>> tipo_trattrat_euc     -0.51209    0.29360  -1.744   0.0811 .
>> tipo_trattrat_mat_euc -0.43877    0.25986  -1.688   0.0913 .
>> temp_final             0.06914    0.04144   1.669   0.0952 .
>> temp_inici             0.07176    0.05479   1.310   0.1903
>> umid_inici             0.03270    0.02543   1.286   0.1985
>> umid_final             0.01774    0.01660   1.069   0.2850
>> ---
>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>
>> Correlation of Fixed Effects:
>>              (Intr) tp_tr_ tp_t__ tmp_fn tmp_nc umd_nc
>> tp_trttrt_c  0.457
>> tp_trttrt__  0.525  0.358
>> temp_final  -0.546 -0.393 -0.143
>> temp_inici  -0.750 -0.557 -0.696  0.037
>> umid_inici  -0.755  0.028 -0.522 -0.020  0.667
>> umid_final  -0.287 -0.661  0.236  0.651  0.023 -0.352
>> convergence code: 0
>> Model failed to converge with max|grad| = 0.00894145 (tol = 0.001, component
>> 1)
>> singular fit
>> Model is nearly unidentifiable: very large eigenvalue
>>   - Rescale variables?
>> Model is nearly unidentifiable: large eigenvalue ratio
>>   - Rescale variables?
>>
>> --
>> ======================================================================
>> Alexandre dos Santos
>> Prote??o Florestal
>> IFMT - Instituto Federal de Educa??o, Ci?ncia e Tecnologia de Mato Grosso
>> Campus C?ceres
>> Caixa Postal 244
>> Avenida dos Ramires, s/n
>> Bairro: Distrito Industrial
>> C?ceres - MT                      CEP: 78.200-000
>> Fone: (+55) 65 99686-6970 (VIVO) (+55) 65 3221-2674 (FIXO)

>>          alexandre.santos at cas.ifmt.edu.br
>> Lattes: http://lattes.cnpq.br/1360403201088680
>> OrcID: orcid.org/0000-0001-8232-6722
>> Researchgate: www.researchgate.net/profile/Alexandre_Santos10
>> LinkedIn: br.linkedin.com/in/alexandre-dos-santos-87961635
>> Mendeley:www.mendeley.com/profiles/alexandre-dos-santos6/
>> ======================================================================
>>
>> Em 06/02/2018 06:15, Thierry Onkelinx escreveu:
>>
>> Dear Alexandre,
>>
>> First of all you need to get a stable model. Otherwise any number you
>> get from it is meaningless. Can you provide more detail on your model.
>> E.g. summary(mT), str(d1), ...
>>
>> Best regards,
>>
>> ir. Thierry Onkelinx
>> Statisticus / Statistician
>>
>> Vlaamse Overheid / Government of Flanders
>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
>> AND FOREST
>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
>> thierry.onkelinx at inbo.be
>> Havenlaan 88 bus 73, 1000 Brussel
>> www.inbo.be
>>
>> ///////////////////////////////////////////////////////////////////////////////////////////
>> To call in the statistician after the experiment is done may be no
>> more than asking him to perform a post-mortem examination: he may be
>> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does
>> not ensure that a reasonable answer can be extracted from a given body
>> of data. ~ John Tukey
>> ///////////////////////////////////////////////////////////////////////////////////////////
>>
>>
>>
>>
>> 2018-02-05 20:15 GMT+01:00 ASANTOS via R-sig-mixed-models
>> <r-sig-mixed-models at r-project.org>:
>>
>> Dear Mix Models Members,
>>
>>          I try to extract R^2 for linear mixed effects models with
>> glmer() function with poisson distribution using r.squaredGLMM() in
>> MuMIn package, but doesn't work. My output always show:
>>
>> #Model ajusted > mT <-glmer(riqueza ~tipo_trat+(1|Ponto),data=d1, +
>> family=poisson, control = glmerControl(check.conv.singular =
>> "warning",optCtrl = list(maxfun=100000))) Warning messages: 1: In
>> checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv, :Model
>> failed to converge with max|grad| = 0.00894145 (tol = 0.001, component
>> 1) 2: In checkConv(attr(opt, "derivs"), opt$par, ctrl =
>> control$checkConv, :singular fit 3: In checkConv(attr(opt, "derivs"),
>> opt$par, ctrl = control$checkConv, :Model is nearly unidentifiable: very
>> large eigenvalue - Rescale variables?;Model is nearly unidentifiable:
>> large eigenvalue ratio - Rescale variables? #R^2 conditional and
>> marginal > r.squaredGLMM(mT) Error in glmer(formula = riqueza ~
>> tipo_trat + temp_final + temp_inici + : fitting model with the
>> observation-level random effect term failed. Add the term manually In
>> addition: Warning message: In value[[3L]](cond) :(p <- ncol(X)) ==
>> ncol(Y) is not TRUE
>>
>>        I change almost all parameters indicating by web posts like
>> glmerControl, maxfun, etc. There are other approaches to calculate the
>> conditional and marginal R^2 for my model with lme4 package?
>>
>> Thanks in advance,
>>
>> Alexandre
>>
>> --
>> ======================================================================
>> Alexandre dos Santos
>> Prote??o Florestal
>> IFMT - Instituto Federal de Educa??o, Ci?ncia e Tecnologia de Mato Grosso
>> Campus C?ceres
>> Caixa Postal 244
>> Avenida dos Ramires, s/n
>> Bairro: Distrito Industrial
>> C?ceres - MT                      CEP: 78.200-000
>> Fone: (+55) 65 99686-6970 (VIVO) (+55) 65 3221-2674 (FIXO)
>>
>>           alexandre.santos at cas.ifmt.edu.br
>> Lattes:http://lattes.cnpq.br/1360403201088680
>> OrcID: orcid.org/0000-0001-8232-6722
>> Researchgate:www.researchgate.net/profile/Alexandre_Santos10
>> LinkedIn: br.linkedin.com/in/alexandre-dos-santos-87961635
>> Mendeley:www.mendeley.com/profiles/alexandre-dos-santos6/
>> ======================================================================
>>
>>
>>          [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>


From paul.johnson at glasgow.ac.uk  Wed Feb  7 14:46:42 2018
From: paul.johnson at glasgow.ac.uk (Paul Johnson)
Date: Wed, 7 Feb 2018 13:46:42 +0000
Subject: [R-sig-ME] 
 =?utf-8?q?GoodnessOfFit-and-PseudoR=C2=B2computingFor?=
 =?utf-8?q?-glmmTMB-models?=
In-Reply-To: <CANrzCv3pJyAAGyBb19Okjx=55P6Ek1afF3GbjWiDOk-wEMvyyA@mail.gmail.com>
References: <CANrzCv1WFzqkREzOBh2TWRPQd-9oRx7u1vXZHfEFKsSUaB=jfg@mail.gmail.com>
 <D961F1DE-FCB2-4B31-9F56-F5E354A3129A@glasgow.ac.uk>
 <CANrzCv3pJyAAGyBb19Okjx=55P6Ek1afF3GbjWiDOk-wEMvyyA@mail.gmail.com>
Message-ID: <380E4128-1FDC-4FF3-8D9F-51B76F687D57@glasgow.ac.uk>

No problem. I didn?t read your questions properly though, apologies if part of my reply didn?t make sense. I'll try to answer questions 1 and 3 as well:

Question 1. 
A good way is to plot your data over your predictions and visually assess fit. This isn?t always easy, especially if you have multiple continuous predictors, in which case you can produce multiple predicted lines conditioned on a few values. Another way is to plot the Pearson residuals against fitted values, and check for homoscedasticity along the fitted values axis, and absence of any nonlinear trend. A good way is to simulate response data from the fitted model (which must fit perfectly) a few times, and compare it with the real data using the methods above (plotting data vs predictions, residuals vs fitted values plot). If the real data fits the model well, it should look similar to the simulated data.

Question 3.
I?ve pasted below a script showing how to estimate R2 for a Poisson GLMM adapting one of the examples from glmmTMB, following this paper: 
"The coefficient of determination R2 and intra-class correlation coefficient from generalized linear mixed-effects models revisited and expanded"
http://rsif.royalsocietypublishing.org/content/14/134/20170213
which built on 
?A general and simple method for obtaining R2 from generalized linear mixed?effects models?
doi.org/10.1111/j.2041-210x.2012.00261.x

There are a couple of packages that have functions to do this (piecewiseSEM, MuMIn), but they don?t work on glmmTMB (yet ? piecewiseSEM is actively maintained so this might change).

All the best,
Paul

# add observation-level factor to Salamanders data
Salamanders$obs <- factor(1:nrow(Salamanders))
(m1 <- glmmTMB(count~ mined + (1|site) + (1|obs), 
               family=poisson, data=Salamanders))
summary(m1)

# fixed effects variance (manually - not sure how to get 
# predict.glmmTMB to do this)
linear.predictor <- model.matrix(m1) %*% fixef(m1)$cond
fixed.var <- var(linear.predictor)
# sum variance of all random effects ***excluding OLRE***
all.ranef.var <- unlist(VarCorr(m1)$cond)
ranef.var <- all.ranef.var[!names(all.ranef.var) %in% "obs"]
# OLRE (additive overdispersion variance)
olre.var <- all.ranef.var["obs"]

# now the observation-level variance 
# (distinct from the observation-level random effect [OLRE])
# here this is the variance added by the Poisson distribution 
# (aka distribution-specific variance)

# first we need to estimate lambda
# the Interface paper recommends calculating lambda as 
# exp(beta0 + total.re.var/2)   -- eqn. 5.8
# beta0 is the intercept from an intercept-only refit of the model
(beta0 <- fixef(update(m1, ~ . - mined))$cond)
lambda <- exp(beta0 + (ranef.var + olre.var)/2)

# observation-level variance (Table 1)
ol.var <- trigamma(lambda) 

# total variance
total.var <- fixed.var + ranef.var + olre.var + ol.var

# marginal R2glmm
fixed.var / total.var
# conditional R2glmm
(fixed.var + ranef.var) / total.var



> On 6 Feb 2018, at 22:13, C. AMAL D. GLELE <altessedac2 at gmail.com> wrote:
> 
> Many thanks, Paul.
> Regards,
> 
> 2018-02-06 15:53 GMT+01:00 Paul Johnson <paul.johnson at glasgow.ac.uk>:
> Hi,
> 
> My preferred approach to overdispersion is none of 1-3 but to assume it applies (it usually does, for biological data anyway), and make sure the model includes a parameter to model overdispersion. For binomial (except Bernoulli) and Poisson you can include an observation-level random effect (OLRE). You can then gauge the amount of overdispersion in the model from the size of the OLRE variance estimate. (Note the OLRE will mop up variation due to *all* sources of lack of fit, including poor model specification, e.g. fitting a straight line where a curve would fit better.)
> 
> Best wishes,
> Paul
> 
> 
> > On 6 Feb 2018, at 14:29, C. AMAL D. GLELE <altessedac2 at gmail.com> wrote:
> >
> > Hi, dear all
> > Please, your help for the following problem:
> > when I fit a mixed model using glmmTMB (poisson family or others), how do I:
> > 1) check, if the model fits well my data (goodness of fit)?
> > 2) check if my model is overdisperced or not (by using sigma(model)?)
> > 3) compute an pseudo R? to see the percentage of the variability of my
> > response which is explained by my model?
> > In advance, thanks for your answers.
> > Regards,
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 


From altessedac2 at gmail.com  Thu Feb  8 10:46:40 2018
From: altessedac2 at gmail.com (C. AMAL D. GLELE)
Date: Thu, 8 Feb 2018 10:46:40 +0100
Subject: [R-sig-ME] 
	=?utf-8?q?GoodnessOfFit-and-PseudoR=C2=B2computingFor?=
	=?utf-8?q?-glmmTMB-models?=
In-Reply-To: <380E4128-1FDC-4FF3-8D9F-51B76F687D57@glasgow.ac.uk>
References: <CANrzCv1WFzqkREzOBh2TWRPQd-9oRx7u1vXZHfEFKsSUaB=jfg@mail.gmail.com>
 <D961F1DE-FCB2-4B31-9F56-F5E354A3129A@glasgow.ac.uk>
 <CANrzCv3pJyAAGyBb19Okjx=55P6Ek1afF3GbjWiDOk-wEMvyyA@mail.gmail.com>
 <380E4128-1FDC-4FF3-8D9F-51B76F687D57@glasgow.ac.uk>
Message-ID: <CANrzCv1MXzS1u9FOh5kw8V5Tps7TdwApfNnFfidAOYA78YS0NA@mail.gmail.com>

Dear paul,
again, many thanks to you for your very helpful details,precions, links and
script.
I'll apply them to my data and let you know.
Best and regards,


2018-02-07 14:46 GMT+01:00 Paul Johnson <paul.johnson at glasgow.ac.uk>:

> No problem. I didn?t read your questions properly though, apologies if
> part of my reply didn?t make sense. I'll try to answer questions 1 and 3 as
> well:
>
> Question 1.
> A good way is to plot your data over your predictions and visually assess
> fit. This isn?t always easy, especially if you have multiple continuous
> predictors, in which case you can produce multiple predicted lines
> conditioned on a few values. Another way is to plot the Pearson residuals
> against fitted values, and check for homoscedasticity along the fitted
> values axis, and absence of any nonlinear trend. A good way is to simulate
> response data from the fitted model (which must fit perfectly) a few times,
> and compare it with the real data using the methods above (plotting data vs
> predictions, residuals vs fitted values plot). If the real data fits the
> model well, it should look similar to the simulated data.
>
> Question 3.
> I?ve pasted below a script showing how to estimate R2 for a Poisson GLMM
> adapting one of the examples from glmmTMB, following this paper:
> "The coefficient of determination R2 and intra-class correlation
> coefficient from generalized linear mixed-effects models revisited and
> expanded"
> http://rsif.royalsocietypublishing.org/content/14/134/20170213
> which built on
> ?A general and simple method for obtaining R2 from generalized linear
> mixed?effects models?
> doi.org/10.1111/j.2041-210x.2012.00261.x
>
> There are a couple of packages that have functions to do this
> (piecewiseSEM, MuMIn), but they don?t work on glmmTMB (yet ? piecewiseSEM
> is actively maintained so this might change).
>
> All the best,
> Paul
>
> # add observation-level factor to Salamanders data
> Salamanders$obs <- factor(1:nrow(Salamanders))
> (m1 <- glmmTMB(count~ mined + (1|site) + (1|obs),
>                family=poisson, data=Salamanders))
> summary(m1)
>
> # fixed effects variance (manually - not sure how to get
> # predict.glmmTMB to do this)
> linear.predictor <- model.matrix(m1) %*% fixef(m1)$cond
> fixed.var <- var(linear.predictor)
> # sum variance of all random effects ***excluding OLRE***
> all.ranef.var <- unlist(VarCorr(m1)$cond)
> ranef.var <- all.ranef.var[!names(all.ranef.var) %in% "obs"]
> # OLRE (additive overdispersion variance)
> olre.var <- all.ranef.var["obs"]
>
> # now the observation-level variance
> # (distinct from the observation-level random effect [OLRE])
> # here this is the variance added by the Poisson distribution
> # (aka distribution-specific variance)
>
> # first we need to estimate lambda
> # the Interface paper recommends calculating lambda as
> # exp(beta0 + total.re.var/2)   -- eqn. 5.8
> # beta0 is the intercept from an intercept-only refit of the model
> (beta0 <- fixef(update(m1, ~ . - mined))$cond)
> lambda <- exp(beta0 + (ranef.var + olre.var)/2)
>
> # observation-level variance (Table 1)
> ol.var <- trigamma(lambda)
>
> # total variance
> total.var <- fixed.var + ranef.var + olre.var + ol.var
>
> # marginal R2glmm
> fixed.var / total.var
> # conditional R2glmm
> (fixed.var + ranef.var) / total.var
>
>
>
> > On 6 Feb 2018, at 22:13, C. AMAL D. GLELE <altessedac2 at gmail.com> wrote:
> >
> > Many thanks, Paul.
> > Regards,
> >
> > 2018-02-06 15:53 GMT+01:00 Paul Johnson <paul.johnson at glasgow.ac.uk>:
> > Hi,
> >
> > My preferred approach to overdispersion is none of 1-3 but to assume it
> applies (it usually does, for biological data anyway), and make sure the
> model includes a parameter to model overdispersion. For binomial (except
> Bernoulli) and Poisson you can include an observation-level random effect
> (OLRE). You can then gauge the amount of overdispersion in the model from
> the size of the OLRE variance estimate. (Note the OLRE will mop up
> variation due to *all* sources of lack of fit, including poor model
> specification, e.g. fitting a straight line where a curve would fit better.)
> >
> > Best wishes,
> > Paul
> >
> >
> > > On 6 Feb 2018, at 14:29, C. AMAL D. GLELE <altessedac2 at gmail.com>
> wrote:
> > >
> > > Hi, dear all
> > > Please, your help for the following problem:
> > > when I fit a mixed model using glmmTMB (poisson family or others), how
> do I:
> > > 1) check, if the model fits well my data (goodness of fit)?
> > > 2) check if my model is overdisperced or not (by using sigma(model)?)
> > > 3) compute an pseudo R? to see the percentage of the variability of my
> > > response which is explained by my model?
> > > In advance, thanks for your answers.
> > > Regards,
> > >
> > >       [[alternative HTML version deleted]]
> > >
> > > _______________________________________________
> > > R-sig-mixed-models at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> >
>
>

	[[alternative HTML version deleted]]


From haveaballphysio at gmail.com  Thu Feb  8 14:26:32 2018
From: haveaballphysio at gmail.com (Dot Dumuid)
Date: Thu, 8 Feb 2018 23:56:32 +1030
Subject: [R-sig-ME] model specification for repeated measure
In-Reply-To: <CA+GPHvOqXEx3L49ZVvZVgn4EfpTBn+ym0Csp1-+R-OXbMJ3e6g@mail.gmail.com>
References: <mailman.13.1517482802.39054.r-sig-mixed-models@r-project.org>
 <A02520CC-A865-4775-9E8B-3D32B004D54A@umu.se>
 <CA+GPHvOqXEx3L49ZVvZVgn4EfpTBn+ym0Csp1-+R-OXbMJ3e6g@mail.gmail.com>
Message-ID: <CA+GPHvMWqvhtwVMcGne-P5cLLmsGWmFu9K8qJhzanzCRF669fg@mail.gmail.com>

I'm sorry to come back to this question (see below for original
question)... but I have one more thing to ask.

Because I am *not* interested in whether mental health *changes* between
the two time points, but I am only interested in whether physical activity
predicts mental health (when controlling for other things like general
health and income), is it true that I don't put "time" in the model as a
fixed effect?

By using a random intercept for ID, the model already caters for the fact
that observations are matched by ID.

So my model could just be:

model <- lmer (MH ~ PA + GH + INC + (1|participant.ID) )

(Assuming, off course, no assumptions are violated,...and I am ignoring
random slopes at the moment)
Then I can predict MH for various min/day of PA (e.g., mean baseline PA,
mean baseline PA+10, mean baseline PA+20... etc), keeping GH and INC
constant. Subtracting the new predicted MHs from the mean predicted MH
should tell me how MH is predicted to change when PA changes across the
retirement transition.

Does this sound OK?
Thank you,
Dot


(This is the original question....)

*Dear mixed model experts,*
*We have a dataset of older adults. We measured their mental health (MH) 6
months before retirement and again 12 months post retirement.*
*At both of these time points we also measured their physical activity (PA)
(min/day), income (INC) and general health (GH).*
*We would like to create a model that tells us if change in physical
activity over the retirement threshold predicts change in mental health,
and we'd like to use the model to predict how much mental health is
predicted to change when physical activity is increased from perhaps 15
minutes to 60 minutes. We'd like to use a mixed model rather than just
using change (difference) scores. And we'd like to control for things like
change in general physical health and change in income.*

*This is what the data look like*

*ID  time  MH    PA    GH    INC*
*01  pre     4      15     56     560*
*02  pre     5      30     30    1200*
*..    .....     ..       ..       ..        ...*
*01  post   7      40     50      50*
*02  post   8      45     30      0 *

*I'm not sure how best to build the model. Something like this?*

*model <- lmer (MH ~ PA * time + GH + INC + (1|participant.ID) )*

*Thank you in advance.*



On Fri, Feb 2, 2018 at 6:22 AM, Dot Dumuid <haveaballphysio at gmail.com>
wrote:

> Thanks for the suggestions. I greatly appreciate you taking the time, and
> I look forward to trying out the ideas.
> Thanks, Dot
>
> On Fri, Feb 2, 2018 at 5:53 AM, Malcolm Fairbrother <
> malcolm.fairbrother at umu.se> wrote:
>
>> Hi Dot,
>>
>> This specification would yield a single coefficient for the
>> between-individual and within-individual effects. That is, you?re assuming
>> the association is the same over time as it is across individuals at a
>> single point in time. I wouldn?t expect this to be a safe assumption, and
>> there?s a pretty straightforward fix: centre your time-varying predictors
>> by their mean for each person. That will yield within effects equivalent to
>> what you?d get from a fixed effects model.
>>
>> For more information about this, see:
>> https://www.cambridge.org/core/services/aop-cambridge-core/
>> content/view/S2049847014000077
>> and/or
>> https://www.researchgate.net/publication/299604336_Fixed_and
>> _Random_effects_models_making_an_informed_choice
>>
>> Hope that?s useful,
>> Malcolm
>>
>>
>> Malcolm Fairbrother
>> Professor of Sociology
>> Ume? University <http://www.umu.se/english>
>> Sweden
>>
>>
>>
>> Date: Thu, 1 Feb 2018 21:07:10 +1030
>> From: Dot Dumuid <haveaballphysio at gmail.com>
>> To: r-sig-mixed-models at r-project.org
>> Subject: [R-sig-ME] model specification for repeated measure
>>
>> Dear mixed model experts,
>> We have a dataset of older adults. We measured their mental health (MH) 6
>> months before retirement and again 12 months post retirement.
>> At both of these time points we also measured their physical activity (PA)
>> (min/day), income (INC) and general health (GH).
>> We would like to create a model that tells us if change in physical
>> activity over the retirement threshold predicts change in mental health,
>> and we'd like to use the model to predict how much mental health is
>> predicted to change when physical activity is increased from perhaps 15
>> minutes to 60 minutes. We'd like to use a mixed model rather than just
>> using change (difference) scores. And we'd like to control for things like
>> change in general physical health and change in income.
>>
>> This is what the data look like
>>
>> *ID  time  MH    PA    GH    INC*
>> 01  pre     4      15     56     560
>> 02  pre     5      30     30    1200
>> ..    .....     ..       ..       ..        ...
>> 01  post   7      40     50      50
>> 02  post   8      45     30      0
>>
>> I'm not sure how best to build the model. Something like this?
>>
>> model <- lmer (MH ~ PA * time + GH + INC + (1|participant.ID) )
>>
>> Thank you in advance.
>> Dot
>>
>>
>>
>

	[[alternative HTML version deleted]]


From jonnations at gmail.com  Fri Feb  9 21:26:02 2018
From: jonnations at gmail.com (jonnations)
Date: Fri, 9 Feb 2018 14:26:02 -0600
Subject: [R-sig-ME] Plotting MCMCglmm regression with credible intervals
Message-ID: <CAHta4sNmA_sOHY52wqNyAFgTCnBTZg3QkH_WXG2P3HJ-aUdMAQ@mail.gmail.com>

Hi all,

I am working on a logistic regression model using MCMCglmm. I would like to
plot the mean with 95% credible intervals on my regression plot, however
this is not so straightforward as the MCMCglmm output is in a very
different format than most software. I think I can manually bang it out
with a page of code, but I was curious if anyone knows of a simple, elegant
way to do this.

Below is a sample script. Imagine this plot with 2 additional lines (95%
CI's) on either side of the mean, shaded in between.

If r-sig-mixed-models is not the correct venue for this kind of question, I
apologize.

Best,
Jon

library(MCMCglmm)
#generate binary data
intercept1 = -6.0
b      = 2.75
x     = rnorm(100, 1, 3)
linpred   = intercept1 + x * b
prob1      = exp(linpred) / (1 + exp(linpred))
run1     = runif(100, 0, 1)
y     = ifelse(run1 < prob1, 1, 0)
df <- data.frame(y = y, x = x)

model1<-MCMCglmm(y ~ x, data = df, family = "categorical",
                 verbose = F, nitt  =2000, burnin = 500, thin = 1)

x <- df$x
y <- df$y
mod.x <- mean(model1$Sol[,1])
mod.y <- mean(model1$Sol[,2])
plot(x,y)
curve(plogis(mod.x+mod.y*x),col="red",add=TRUE)

-- 
Jonathan A. Nations
PhD Candidate
Esselstyn Lab <http://www.museum.lsu.edu/esselstyn>
Museum of Natural Sciences <http://sites01.lsu.edu/wp/mns>
Louisiana State University

	[[alternative HTML version deleted]]


From j.hadfield at ed.ac.uk  Sat Feb 10 10:14:37 2018
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Sat, 10 Feb 2018 09:14:37 +0000
Subject: [R-sig-ME] Plotting MCMCglmm regression with credible intervals
In-Reply-To: <CAHta4sNmA_sOHY52wqNyAFgTCnBTZg3QkH_WXG2P3HJ-aUdMAQ@mail.gmail.com>
References: <CAHta4sNmA_sOHY52wqNyAFgTCnBTZg3QkH_WXG2P3HJ-aUdMAQ@mail.gmail.com>
Message-ID: <cdc4d945-dacb-35cc-abba-e51b96e46b81@ed.ac.uk>

Hi Jon,

You can use predict on newdata:

newdata<-df
newdata$x<-seq(min(df$x), max(df$x), length=100)

p1<-predict(model1, newdata=newdata, interval="confidence")

plot(df$x,df$y)
lines(p1[,1]~newdata$x,col="red")
lines(p1[,2]~newdata$x,col="red",lty=2)
lines(p1[,3]~newdata$x,col="red", lty=2)

The predict function with default arguments is quite slow with 
non-Gaussian data because it uses numerical integration to integrate 
over the random effects (if they are to be marginalised). However, the 
integrals can be approximated using Taylor expansion (approx="taylor") 
or if the response involves a logit link (as here) it can be approximate 
using approx="diggle" or approx="mculloch". These are much faster, and 
the latter two especially can be very accurate. However, if you try to 
use these approximations on your model MCMCglmm will tell you they are 
not implemented for this distribution.? This isn't true, and I will put 
a new version on CRAN ASAP that allows you to use these approximations. 
I can also send you a version in the mean time if you let me know your OS.

Cheers,

Jarrod



On 09/02/2018 20:26, jonnations wrote:
> Hi all,
>
> I am working on a logistic regression model using MCMCglmm. I would like to
> plot the mean with 95% credible intervals on my regression plot, however
> this is not so straightforward as the MCMCglmm output is in a very
> different format than most software. I think I can manually bang it out
> with a page of code, but I was curious if anyone knows of a simple, elegant
> way to do this.
>
> Below is a sample script. Imagine this plot with 2 additional lines (95%
> CI's) on either side of the mean, shaded in between.
>
> If r-sig-mixed-models is not the correct venue for this kind of question, I
> apologize.
>
> Best,
> Jon
>
> library(MCMCglmm)
> #generate binary data
> intercept1 = -6.0
> b      = 2.75
> x     = rnorm(100, 1, 3)
> linpred   = intercept1 + x * b
> prob1      = exp(linpred) / (1 + exp(linpred))
> run1     = runif(100, 0, 1)
> y     = ifelse(run1 < prob1, 1, 0)
> df <- data.frame(y = y, x = x)
>
> model1<-MCMCglmm(y ~ x, data = df, family = "categorical",
>                   verbose = F, nitt  =2000, burnin = 500, thin = 1)
>
> x <- df$x
> y <- df$y
> mod.x <- mean(model1$Sol[,1])
> mod.y <- mean(model1$Sol[,2])
> plot(x,y)
> curve(plogis(mod.x+mod.y*x),col="red",add=TRUE)
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From telli at bu.edu  Sat Feb 10 21:59:30 2018
From: telli at bu.edu (Telli Davoodi)
Date: Sat, 10 Feb 2018 15:59:30 -0500
Subject: [R-sig-ME] Repeated Measures Design With lme Function
Message-ID: <CAAN3=Difb-VbEi4RaWcpixfnNiyLLnkmPP9fGr1WQ2N4DYkcEg@mail.gmail.com>

Hi all,

I'm having a hard time defining a model with my repeated measures design
(explained below). This is an experimental design and it is fully balanced.
I would really appreciate it if you have any feedback.

Thanks,
Telli

Here's the design of my experiment: I have 72 children (Subject ID) answer
five questions (Question) about five different categories (Category).
Basically, the same five questions repeat for each category. So, in long
format, every participant has 25 rows (five for each level of category and
within each level of category, question has five levels).

Now, I want to fit a mixed-effects regression model on this data, using the
lme function from the nmle package, but I'm not sure how to account for the
fact that Category repeats with Subject ID and Question repeats with
Category. This is what I have so far, but I'm not sure if I'm specifying
the random part of the model correctly:

summary(Qs <- lme(Essen ~ Question * AgeinYears * Category,
random = ~1|SubjectID/Category/Question, data = Q, na.action = na.omit))

I just want to make sure that I am allowing Category to vary within
SubjectID and Question to vary within Category.

Also, is it correct to say that Category is "nested" under Subject ID and
Question is nested under Category?

	[[alternative HTML version deleted]]


From diego.pavonjordan at gmail.com  Mon Feb 12 09:04:49 2018
From: diego.pavonjordan at gmail.com (Diego Pavon)
Date: Mon, 12 Feb 2018 10:04:49 +0200
Subject: [R-sig-ME] error in glmmTMB when adding glmmTMBControl: unused
 arguments
Message-ID: <CAD93_Fp1DRT3M_Sgh10UFUMrVcizrK0uAXx4hKpvimUKT0RRwg@mail.gmail.com>

Dear list

I am trying to run this model

M1.zi <- glmmTMB(Abundance ~ Temp_std + NEness_std + WithinNatura +
Winter_std
                 + WithinNatura * Winter_std + NEness_std * Winter_std +
Temp_std * WithinNatura
                 + WithinNatura * Winter_std  * NEness_std
                 + (1|fWinter/site) + (1|species),
                 family = poisson,
                 ziformula = ~ 1,
                 data = AllSpecies)

but after a couple of days (I have 3.5 million data points), I finally got
an error:

Error in optimHess(par.fixed, obj$fn, obj$gr) :
  gradient in optim evaluated to length 1 not 14
In addition: There were 11 warnings (use warnings() to see them)


Then I tried to add the CONTROL argument following
https://cran.r-project.org/web/packages/glmmTMB/glmmTMB.pdf:

M1.zi <- glmmTMB(Abundance ~ Temp_std + NEness_std + WithinNatura +
Winter_std
                 + WithinNatura * Winter_std + NEness_std * Winter_std +
Temp_std * WithinNatura
                 + WithinNatura * Winter_std  * NEness_std
                 + (1|fWinter/site) + (1|species),
                 family = poisson,
                 control = glmmTMBControl(optCtrl = list(iter.max = 1000,
eval.max = 1000), profile = TRUE, collect = FALSE),
                 ziformula = ~ 1,
                 data = AllSpecies)


For some reason, I get this error message:

Error in glmmTMB(Abundance ~ Temp_std + NEness_std + WithinNatura +
Winter_std +  :
  unused argument (control = glmmTMBControl(optCtrl = list(iter.max = 1000,
eval.max = 1000), profile = TRUE, collect = FALSE))


Does anyone have an idea how to specify the control arguments? I suspect
this is some small thing I am missing but I can't see it anymore...

Thank you very much for your time and help.

Best

Diego



-- 
*Diego Pav?n Jord?n*

*Finnish Museum of Natural History*
*PO BOX 17 *

*Helsinki. Finland*

*0445061210https://www.researchgate.net/profile/Diego_Pavon-jordan
<https://www.researchgate.net/profile/Diego_Pavon-jordan>*

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Mon Feb 12 13:48:46 2018
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 12 Feb 2018 07:48:46 -0500
Subject: [R-sig-ME] error in glmmTMB when adding glmmTMBControl: unused
 arguments
In-Reply-To: <CAD93_Fp1DRT3M_Sgh10UFUMrVcizrK0uAXx4hKpvimUKT0RRwg@mail.gmail.com>
References: <CAD93_Fp1DRT3M_Sgh10UFUMrVcizrK0uAXx4hKpvimUKT0RRwg@mail.gmail.com>
Message-ID: <CABghstTD86Fv14L9B28FQQxrGc8x6ycLs8mpj_RejpO56yhwTg@mail.gmail.com>

A reproducible example would be useful.  This works (with the
development version
of glmmTMB, but I'd be surprised if it broke since the last CRAN release ...)

library(glmmTMB)

m1 <- glmmTMB(count~ mined + (1|site),
              zi=~mined,
              family=poisson, data=Salamanders,
  control=glmmTMBControl(optCtrl=list(iter.max=1e3,
                                      eval.max=1e3),
                         profile=TRUE))

what's your sessionInfo()?

Maybe obvious, but it would probably be efficient to do some
troubleshooting/model-checking on a
smaller subset of your data, if you haven't already ...

On Mon, Feb 12, 2018 at 3:04 AM, Diego Pavon
<diego.pavonjordan at gmail.com> wrote:
> Dear list
>
> I am trying to run this model
>
> M1.zi <- glmmTMB(Abundance ~ Temp_std + NEness_std + WithinNatura +
> Winter_std
>                  + WithinNatura * Winter_std + NEness_std * Winter_std +
> Temp_std * WithinNatura
>                  + WithinNatura * Winter_std  * NEness_std
>                  + (1|fWinter/site) + (1|species),
>                  family = poisson,
>                  ziformula = ~ 1,
>                  data = AllSpecies)
>
> but after a couple of days (I have 3.5 million data points), I finally got
> an error:
>
> Error in optimHess(par.fixed, obj$fn, obj$gr) :
>   gradient in optim evaluated to length 1 not 14
> In addition: There were 11 warnings (use warnings() to see them)
>
>
> Then I tried to add the CONTROL argument following
> https://cran.r-project.org/web/packages/glmmTMB/glmmTMB.pdf:
>
> M1.zi <- glmmTMB(Abundance ~ Temp_std + NEness_std + WithinNatura +
> Winter_std
>                  + WithinNatura * Winter_std + NEness_std * Winter_std +
> Temp_std * WithinNatura
>                  + WithinNatura * Winter_std  * NEness_std
>                  + (1|fWinter/site) + (1|species),
>                  family = poisson,
>                  control = glmmTMBControl(optCtrl = list(iter.max = 1000,
> eval.max = 1000), profile = TRUE, collect = FALSE),
>                  ziformula = ~ 1,
>                  data = AllSpecies)
>
>
> For some reason, I get this error message:
>
> Error in glmmTMB(Abundance ~ Temp_std + NEness_std + WithinNatura +
> Winter_std +  :
>   unused argument (control = glmmTMBControl(optCtrl = list(iter.max = 1000,
> eval.max = 1000), profile = TRUE, collect = FALSE))
>
>
> Does anyone have an idea how to specify the control arguments? I suspect
> this is some small thing I am missing but I can't see it anymore...
>
> Thank you very much for your time and help.
>
> Best
>
> Diego
>
>
>
> --
> *Diego Pav?n Jord?n*
>
> *Finnish Museum of Natural History*
> *PO BOX 17 *
>
> *Helsinki. Finland*
>
> *0445061210https://www.researchgate.net/profile/Diego_Pavon-jordan
> <https://www.researchgate.net/profile/Diego_Pavon-jordan>*
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From mollieebrooks at gmail.com  Mon Feb 12 14:07:39 2018
From: mollieebrooks at gmail.com (Mollie Brooks)
Date: Mon, 12 Feb 2018 14:07:39 +0100
Subject: [R-sig-ME] error in glmmTMB when adding glmmTMBControl: unused
 arguments
In-Reply-To: <CABghstTD86Fv14L9B28FQQxrGc8x6ycLs8mpj_RejpO56yhwTg@mail.gmail.com>
References: <CAD93_Fp1DRT3M_Sgh10UFUMrVcizrK0uAXx4hKpvimUKT0RRwg@mail.gmail.com>
 <CABghstTD86Fv14L9B28FQQxrGc8x6ycLs8mpj_RejpO56yhwTg@mail.gmail.com>
Message-ID: <6FC2B039-A16D-47FA-8037-A1A40265BED1@gmail.com>

Yes, I agree that the control argument (as you specified it) appears to be working on the development version of glmmTMB.
For example
(m3 <- glmmTMB(count~spp + mined + (1|site), 
  zi=~spp + mined, 
  family=nbinom2, Salamanders, control = glmmTMBControl(optCtrl = list(iter.max = 1000,
eval.max = 1000), profile = TRUE, collect = FALSE)))

The error you get 
>> 
>> Error in optimHess(par.fixed, obj$fn, obj$gr) :
>>  gradient in optim evaluated to length 1 not 14
>> In addition: There were 11 warnings (use warnings() to see them)
>> 

should have produced a message including "See vignette('troubleshooting')". If it didn?t, then something is broken, so please report it in the issue tracker on GitHub or let me know.

thanks,
Mollie

???????????
Mollie E. Brooks, Ph.D.
Research Scientist
National Institute of Aquatic Resources
Technical University of Denmark

> On 12Feb 2018, at 13:48, Ben Bolker <bbolker at gmail.com> wrote:
> 
> A reproducible example would be useful.  This works (with the
> development version
> of glmmTMB, but I'd be surprised if it broke since the last CRAN release ...)
> 
> library(glmmTMB)
> 
> m1 <- glmmTMB(count~ mined + (1|site),
>              zi=~mined,
>              family=poisson, data=Salamanders,
>  control=glmmTMBControl(optCtrl=list(iter.max=1e3,
>                                      eval.max=1e3),
>                         profile=TRUE))
> 
> what's your sessionInfo()?
> 
> Maybe obvious, but it would probably be efficient to do some
> troubleshooting/model-checking on a
> smaller subset of your data, if you haven't already ...
> 
> On Mon, Feb 12, 2018 at 3:04 AM, Diego Pavon
> <diego.pavonjordan at gmail.com> wrote:
>> Dear list
>> 
>> I am trying to run this model
>> 
>> M1.zi <- glmmTMB(Abundance ~ Temp_std + NEness_std + WithinNatura +
>> Winter_std
>>                 + WithinNatura * Winter_std + NEness_std * Winter_std +
>> Temp_std * WithinNatura
>>                 + WithinNatura * Winter_std  * NEness_std
>>                 + (1|fWinter/site) + (1|species),
>>                 family = poisson,
>>                 ziformula = ~ 1,
>>                 data = AllSpecies)
>> 
>> but after a couple of days (I have 3.5 million data points), I finally got
>> an error:
>> 
>> Error in optimHess(par.fixed, obj$fn, obj$gr) :
>>  gradient in optim evaluated to length 1 not 14
>> In addition: There were 11 warnings (use warnings() to see them)
>> 
>> 
>> Then I tried to add the CONTROL argument following
>> https://cran.r-project.org/web/packages/glmmTMB/glmmTMB.pdf:
>> 
>> M1.zi <- glmmTMB(Abundance ~ Temp_std + NEness_std + WithinNatura +
>> Winter_std
>>                 + WithinNatura * Winter_std + NEness_std * Winter_std +
>> Temp_std * WithinNatura
>>                 + WithinNatura * Winter_std  * NEness_std
>>                 + (1|fWinter/site) + (1|species),
>>                 family = poisson,
>>                 control = glmmTMBControl(optCtrl = list(iter.max = 1000,
>> eval.max = 1000), profile = TRUE, collect = FALSE),
>>                 ziformula = ~ 1,
>>                 data = AllSpecies)
>> 
>> 
>> For some reason, I get this error message:
>> 
>> Error in glmmTMB(Abundance ~ Temp_std + NEness_std + WithinNatura +
>> Winter_std +  :
>>  unused argument (control = glmmTMBControl(optCtrl = list(iter.max = 1000,
>> eval.max = 1000), profile = TRUE, collect = FALSE))
>> 
>> 
>> Does anyone have an idea how to specify the control arguments? I suspect
>> this is some small thing I am missing but I can't see it anymore...
>> 
>> Thank you very much for your time and help.
>> 
>> Best
>> 
>> Diego
>> 
>> 
>> 
>> --
>> *Diego Pav?n Jord?n*
>> 
>> *Finnish Museum of Natural History*
>> *PO BOX 17 *
>> 
>> *Helsinki. Finland*
>> 
>> *0445061210https://www.researchgate.net/profile/Diego_Pavon-jordan
>> <https://www.researchgate.net/profile/Diego_Pavon-jordan>*
>> 
>>        [[alternative HTML version deleted]]
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Mon Feb 12 17:18:38 2018
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Mon, 12 Feb 2018 17:18:38 +0100
Subject: [R-sig-ME] Repeated Measures Design With lme Function
In-Reply-To: <CAAN3=Difb-VbEi4RaWcpixfnNiyLLnkmPP9fGr1WQ2N4DYkcEg@mail.gmail.com>
References: <CAAN3=Difb-VbEi4RaWcpixfnNiyLLnkmPP9fGr1WQ2N4DYkcEg@mail.gmail.com>
Message-ID: <CAJuCY5zF05G_sKhjG1KJO_SKwo23NzLqzJ4wqwEGM+BRZMQXdg@mail.gmail.com>

Dear Telli,

When you nest question in category, you assume that you have 25 (= 5 x
5) different question which are grouped into 5 categories.

In lme4 notation the random effects (1|SubjectID/Category/Question)
translate more verbose into (1|SubjectID) + (1|SubjectID:Category) +
(1|SubjectID:Category:Question). This make it more clear that you have
3 random intercepts: one per SubjectID, one per combination of
SubjectID and Category and one per combination of SubjectID, Category
and Question. That last random intercept has only one observation per
level and thus doesn't make sense. So I'd go for lme(Essen ~
AgeinYears * Category * Question, random = ~1|SubjectID/Category) Note
that I've rearraged the order of the fixed effects. This is yield a
different parametrisation which seems a bit more appropriate for this
case.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
AND FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////




2018-02-10 21:59 GMT+01:00 Telli Davoodi <telli at bu.edu>:
> Hi all,
>
> I'm having a hard time defining a model with my repeated measures design
> (explained below). This is an experimental design and it is fully balanced.
> I would really appreciate it if you have any feedback.
>
> Thanks,
> Telli
>
> Here's the design of my experiment: I have 72 children (Subject ID) answer
> five questions (Question) about five different categories (Category).
> Basically, the same five questions repeat for each category. So, in long
> format, every participant has 25 rows (five for each level of category and
> within each level of category, question has five levels).
>
> Now, I want to fit a mixed-effects regression model on this data, using the
> lme function from the nmle package, but I'm not sure how to account for the
> fact that Category repeats with Subject ID and Question repeats with
> Category. This is what I have so far, but I'm not sure if I'm specifying
> the random part of the model correctly:
>
> summary(Qs <- lme(Essen ~ Question * AgeinYears * Category,
> random = ~1|SubjectID/Category/Question, data = Q, na.action = na.omit))
>
> I just want to make sure that I am allowing Category to vary within
> SubjectID and Question to vary within Category.
>
> Also, is it correct to say that Category is "nested" under Subject ID and
> Question is nested under Category?
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From n.bedere at gmail.com  Tue Feb 13 09:15:24 2018
From: n.bedere at gmail.com (=?UTF-8?B?Tmljb2xhcyBCw6lkw6hyZQ==?=)
Date: Tue, 13 Feb 2018 09:15:24 +0100
Subject: [R-sig-ME] 
 How can I make R using more than 1 core (8 available) on
 a Ubuntu Rstudio server ?
In-Reply-To: <20180120232415.fpynz3y2vqvgr76w@hans>
References: <CALFoxB9zy7mXDRj8Ub+9M_ZVFK-8Cgk1Q7AvFG2dDAUT4oBQAQ@mail.gmail.com>
 <CAO7JsnSPPbk_rqZiCkkuQGQRMRHFE3c5RmAYGdees=qPZTDQ_Q@mail.gmail.com>
 <CABghstSjmPLxA9VnQNdaZ7gQX3e-jwO9bKAqMrS-+v2YdT5Z8g@mail.gmail.com>
 <20180120232415.fpynz3y2vqvgr76w@hans>
Message-ID: <CALFoxB91GtOVtX8op8RJf6_xbRAg19RGRYbO6+c9d8jSq6wR7w@mail.gmail.com>

Dear glmmTMB users,

I have tried the solution proposed by Ben Bolker since our serveur is a
R-studio serveur, I could not try Julia.
It runs faster indeed, thanks ! I don't want to put on a scene an old
fight... but to publish in animal science we need P-values, whatever are
the good reasons for not getting some... our community is not ready yet !
with the lmer packages I used to get the global effects with Anova:car. The
glmmTMB objects are not supported by this function. Do you know any
solution to get the global effect of the factor instead of the effect of
each levels ?

Many thanks,
Nicolas

2018-01-21 0:24 GMT+01:00 Hans Ekbrand <hans.ekbrand at gmail.com>:

> On Thu, Jan 18, 2018 at 03:36:08PM -0500, Ben Bolker wrote:
> >   Explaining a little bit more; unlike a lot of informatics/machine
> > learning procedures, the algorithm underlying lme4 is not naturally
> > parallelizable. There are components that *could* be done in parallel,
> > but it's not simple.
> >
> >   If you need faster computation, you could either try Doug's
> > MixedModels.jl package for Julia, or the glmmTMB package (on CRAN),
> > which may scale better than glmer for problems with large numbers of
> > fixed-effect parameters (although my guess is that it's close to a tie
> > for the problem specs you quote below, unless your fixed effects are
> > factors with several levels).
>
> I'm currently analysing a few huge datasets and in one of the cases
> the outcome was binary (in the other cases, the outcome was count data
> so I used negative binomial in glmmTMB), so I tried both glmer and
> glmmTMB and glmmTMB was faster. My model included about 11 fixed
> effects without interactions and three random intercept terms.
>
> However, I had problem getting a clean convergence when I tried to fit
> the model to the complete dataset, both with glmer and glmmTMB, and
> what I did might help Nicolas B?d?re too. I think the convergence
> problems in my case was related to the fact that the outcome was very
> rare, only 11.221 cases had the outcome (death), while 5.674.928
> didn't have the outcome (the were alive).
>
> Anyway, I divided the dataset into 8 bins, and fitted the same model
> to each dataset, and since I had a 4 core CPU, 4 datasets could be
> independently fitted in parallel. Then I took the estimates and
> applied Rubin's Rule on them, to get pooled results.
>
> (In my particular case, I left all 11.221 positive cases in each of
> the 8 datasets, while each negative case only appeared in one of the 8
> datasets.)
>
> I consider what I did as a kind of poor-man's-bootstrapping, but I
> would like to have some feedback on the valididity of results one gets
> with the method I used. If it is valid, then it is one way of
> parallelising glmer.
>
> --
> Hans Ekbrand, Fil Dr
> Epost/email: <hans.ekbrand at gu.se>
> Telefon/phone: +46-31 786 47 73
> Institutionen f?r sociologi och arbetsvetenskap, G?teborgs universitet
> Department of sociology and work science, Gothenburg university
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From jana.dlouha at inra.fr  Tue Feb 13 10:00:39 2018
From: jana.dlouha at inra.fr (Jana Dlouha)
Date: Tue, 13 Feb 2018 09:00:39 +0000
Subject: [R-sig-ME] correlation between random effects
Message-ID: <5e1a81d3edd04e9c9716da7166b07533@TLSDCPRIPEXMU05.inra.local>

Hi all,

I have a problem with a correlation between random effects. I have tested several models on my data:
m0<-lm(MCs~ dB1, data)
m1<- lmer(MCs~ dB1 + (1|Species), data, REML=FALSE)
m2 <- lmer(MCs~ dB1 + (-1+dB1|Species), data, REML=FALSE)
m3<- lmer(MCs~ dB1 + (1|Species)+(0+dB1|Species), data, REML=FALSE)
m4<- lmer(MCs ~ dB1 + (1+dB1 |Species), data,REML=FALSE)

and when I compare the AIC criterion, the lowest one is for the model m4:
     m0              m1           m2            m3            m4
11086.51 10948.72 10828.75 10830.75 10720.43

However, in the summary I see that there is a strong correlation between random effects and associated variances are huge:
Random effects:
Groups   Name        Variance Std.Dev. Corr
 Species  (Intercept) 21.48    4.635
          dB1         11.25    3.355    -1.00
Residual              6.19    2.488
Number of obs: 2221, groups:  Species, 598

For m3, random effect associated with  intercept has very low variance and residual variance is only  a bit higher:
Random effects:
Groups    Name        Variance  Std.Dev.
 Species   (Intercept) 3.419e-14 1.849e-07
Species.1 dB1         7.968e-01 8.927e-01
Residual              6.327e+00 2.515e+00
Number of obs: 2221, groups:  Species, 598

I am tempted to take into account only the randon effect associated with the slope however I don't know if i can do this considering that the AIC is not the lowest one for this model and how to justify it in my paper?
By the way, I don't really understand why the variances associated with the random effects change so much.
I have tried to center the regressor dB1 which removed the correlation between fixed effects and changed the sign of correlation but random effects remain strongly correlated and variances large:

Random effects:
Groups   Name        Variance Std.Dev. Corr
Species  (Intercept)  1.109   1.053
          dB1c        11.255   3.355    0.94
Residual              6.190   2.488
Number of obs: 2221, groups:  Species, 598

Could you please give me some hint to solve my problem? Thanks a lot in advance

Jana



	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Tue Feb 13 10:25:46 2018
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Tue, 13 Feb 2018 10:25:46 +0100
Subject: [R-sig-ME] correlation between random effects
In-Reply-To: <5e1a81d3edd04e9c9716da7166b07533@TLSDCPRIPEXMU05.inra.local>
References: <5e1a81d3edd04e9c9716da7166b07533@TLSDCPRIPEXMU05.inra.local>
Message-ID: <CAJuCY5z5mfud3-if8YLQ_Zs9Lxr=OzHU9oY2tvjazKaCn8RjmA@mail.gmail.com>

Dear Jana,

I assume that you uses the centered dB1c both in the random and the
fixed effects? Another thing you can try is to scale dB1c. Using
sensible units is often sufficient. Don't use large units (e.g.
kilometers) when you are measuring small things (e.g. millimeters).

You'll need to provide more information when you need more feedback.
At least the summary of the data and the model.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
AND FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////




2018-02-13 10:00 GMT+01:00 Jana Dlouha <jana.dlouha at inra.fr>:
> Hi all,
>
> I have a problem with a correlation between random effects. I have tested several models on my data:
> m0<-lm(MCs~ dB1, data)
> m1<- lmer(MCs~ dB1 + (1|Species), data, REML=FALSE)
> m2 <- lmer(MCs~ dB1 + (-1+dB1|Species), data, REML=FALSE)
> m3<- lmer(MCs~ dB1 + (1|Species)+(0+dB1|Species), data, REML=FALSE)
> m4<- lmer(MCs ~ dB1 + (1+dB1 |Species), data,REML=FALSE)
>
> and when I compare the AIC criterion, the lowest one is for the model m4:
>      m0              m1           m2            m3            m4
> 11086.51 10948.72 10828.75 10830.75 10720.43
>
> However, in the summary I see that there is a strong correlation between random effects and associated variances are huge:
> Random effects:
> Groups   Name        Variance Std.Dev. Corr
>  Species  (Intercept) 21.48    4.635
>           dB1         11.25    3.355    -1.00
> Residual              6.19    2.488
> Number of obs: 2221, groups:  Species, 598
>
> For m3, random effect associated with  intercept has very low variance and residual variance is only  a bit higher:
> Random effects:
> Groups    Name        Variance  Std.Dev.
>  Species   (Intercept) 3.419e-14 1.849e-07
> Species.1 dB1         7.968e-01 8.927e-01
> Residual              6.327e+00 2.515e+00
> Number of obs: 2221, groups:  Species, 598
>
> I am tempted to take into account only the randon effect associated with the slope however I don't know if i can do this considering that the AIC is not the lowest one for this model and how to justify it in my paper?
> By the way, I don't really understand why the variances associated with the random effects change so much.
> I have tried to center the regressor dB1 which removed the correlation between fixed effects and changed the sign of correlation but random effects remain strongly correlated and variances large:
>
> Random effects:
> Groups   Name        Variance Std.Dev. Corr
> Species  (Intercept)  1.109   1.053
>           dB1c        11.255   3.355    0.94
> Residual              6.190   2.488
> Number of obs: 2221, groups:  Species, 598
>
> Could you please give me some hint to solve my problem? Thanks a lot in advance
>
> Jana
>
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From thierry.onkelinx at inbo.be  Tue Feb 13 11:28:28 2018
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Tue, 13 Feb 2018 11:28:28 +0100
Subject: [R-sig-ME] Repeated Measures Design With lme Function
In-Reply-To: <CAAN3=DgRT3OUFgjy2YEk0Q8W-qMhPPU+UKydbQpCALxyfsem-Q@mail.gmail.com>
References: <CAAN3=Difb-VbEi4RaWcpixfnNiyLLnkmPP9fGr1WQ2N4DYkcEg@mail.gmail.com>
 <CAJuCY5zF05G_sKhjG1KJO_SKwo23NzLqzJ4wqwEGM+BRZMQXdg@mail.gmail.com>
 <CAAN3=DgRT3OUFgjy2YEk0Q8W-qMhPPU+UKydbQpCALxyfsem-Q@mail.gmail.com>
Message-ID: <CAJuCY5wEOa+khcMC==S-sonQ1tuZ3xkbR876V+mhn4OL5FqF5Q@mail.gmail.com>

Dear Telli,

Your nlme syntax assumes nested random effects. Crossed random effects
are hard (but doable) with nlme. They are straightforward with lme4.
So go for lme4, useless you really need something that nlme provides
but lme4 doesn't.

Best regards,

Thierry



ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
AND FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////




2018-02-12 18:53 GMT+01:00 Telli Davoodi <telli at bu.edu>:
> Dear Thierry,
>
> Thank you for the reply. Just to make sure, after I did a little more
> research on my design, I concluded that in my design, Question and Category
> are crossed (maybe you have already figured this our from my original
> explanation). So, with this in mind, does the syntax you suggest still make
> sense with the lme function? Or do I have to run my model with lmer?
>
> Thanks again,
> Telli
>
> On Mon, Feb 12, 2018 at 11:18 AM, Thierry Onkelinx
> <thierry.onkelinx at inbo.be> wrote:
>>
>> Dear Telli,
>>
>> When you nest question in category, you assume that you have 25 (= 5 x
>> 5) different question which are grouped into 5 categories.
>>
>> In lme4 notation the random effects (1|SubjectID/Category/Question)
>> translate more verbose into (1|SubjectID) + (1|SubjectID:Category) +
>> (1|SubjectID:Category:Question). This make it more clear that you have
>> 3 random intercepts: one per SubjectID, one per combination of
>> SubjectID and Category and one per combination of SubjectID, Category
>> and Question. That last random intercept has only one observation per
>> level and thus doesn't make sense. So I'd go for lme(Essen ~
>> AgeinYears * Category * Question, random = ~1|SubjectID/Category) Note
>> that I've rearraged the order of the fixed effects. This is yield a
>> different parametrisation which seems a bit more appropriate for this
>> case.
>>
>> Best regards,
>>
>> ir. Thierry Onkelinx
>> Statisticus / Statistician
>>
>> Vlaamse Overheid / Government of Flanders
>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
>> AND FOREST
>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
>> thierry.onkelinx at inbo.be
>> Havenlaan 88 bus 73, 1000 Brussel
>> www.inbo.be
>>
>>
>> ///////////////////////////////////////////////////////////////////////////////////////////
>> To call in the statistician after the experiment is done may be no
>> more than asking him to perform a post-mortem examination: he may be
>> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does
>> not ensure that a reasonable answer can be extracted from a given body
>> of data. ~ John Tukey
>>
>> ///////////////////////////////////////////////////////////////////////////////////////////
>>
>>
>>
>>
>> 2018-02-10 21:59 GMT+01:00 Telli Davoodi <telli at bu.edu>:
>> > Hi all,
>> >
>> > I'm having a hard time defining a model with my repeated measures design
>> > (explained below). This is an experimental design and it is fully
>> > balanced.
>> > I would really appreciate it if you have any feedback.
>> >
>> > Thanks,
>> > Telli
>> >
>> > Here's the design of my experiment: I have 72 children (Subject ID)
>> > answer
>> > five questions (Question) about five different categories (Category).
>> > Basically, the same five questions repeat for each category. So, in long
>> > format, every participant has 25 rows (five for each level of category
>> > and
>> > within each level of category, question has five levels).
>> >
>> > Now, I want to fit a mixed-effects regression model on this data, using
>> > the
>> > lme function from the nmle package, but I'm not sure how to account for
>> > the
>> > fact that Category repeats with Subject ID and Question repeats with
>> > Category. This is what I have so far, but I'm not sure if I'm specifying
>> > the random part of the model correctly:
>> >
>> > summary(Qs <- lme(Essen ~ Question * AgeinYears * Category,
>> > random = ~1|SubjectID/Category/Question, data = Q, na.action = na.omit))
>> >
>> > I just want to make sure that I am allowing Category to vary within
>> > SubjectID and Question to vary within Category.
>> >
>> > Also, is it correct to say that Category is "nested" under Subject ID
>> > and
>> > Question is nested under Category?
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > _______________________________________________
>> > R-sig-mixed-models at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>


From thierry.onkelinx at inbo.be  Tue Feb 13 11:43:55 2018
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Tue, 13 Feb 2018 11:43:55 +0100
Subject: [R-sig-ME] correlation between random effects
In-Reply-To: <e3a2a5b71ef54555a92876aa1803f501@TLSDCPRIPEXMU05.inra.local>
References: <5e1a81d3edd04e9c9716da7166b07533@TLSDCPRIPEXMU05.inra.local>
 <CAJuCY5z5mfud3-if8YLQ_Zs9Lxr=OzHU9oY2tvjazKaCn8RjmA@mail.gmail.com>
 <e3a2a5b71ef54555a92876aa1803f501@TLSDCPRIPEXMU05.inra.local>
Message-ID: <CAJuCY5zGnWGw4Ls_Tv8xG0bxspdj3B-qJ8MrTvXn6aQ_zsrCTA@mail.gmail.com>

Dear Jana,

Please keep the mailing list in cc.

I meant both centering and scaling.

Based on the summary of the model, you have on average 3.7
observations per species, which is a bit small for a random slope
model. What worries me is that the summary of the data indicates
several species with > 20 observation. Hence you will have lot of
species with only 1 or 2 observations. A species with only 2
observations, a small difference in dB1 and a large difference in MC
will likely result in a large random slope for dB1. You'll need to
investigate which species have a strong random slope and why. Most of
the time that is obvious once you plotted the data for that species.
Tip: plot the observations, the fitted values of the model and the
predictions using only the fixed effects.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
AND FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////




2018-02-13 11:23 GMT+01:00 Jana Dlouha <jana.dlouha at inra.fr>:
> Dear Thierry,
>
> Thanks a lot for your reply. Yes, I have used dB1c also in the random effect.
> I have just tried to scale dB1 but I have still the same problem. However, it is possible that I am not doing things well, I am not a statistician and moreover I am just discovering R...
> You say that I should provide more information so here is the summary of my data for the two columns I am using in this model:
> Species         MCs             dB1
> 327     :43     Min.    40.05   Min.    :1.050
> 135     :35     1st Qu. 72.53   1st Qu. :1.400
> 307     :24     Median  89.11   Median  :1.560
> 146     :23     Mean    99.56   Mean    :1.671
> 328     :23     3rd Qu. 116.23  3rd Qu. :1.840
> 341     :22     Max.    351.49  Max.    :4.220
> (Other):2051
>
> How I centered and scaled dB1:
> dB1c<-scale(data$dB1,center=TRUE)
> dB1s<-scale(data$dB1,center=FALSE, scale=TRUE)
>
> summary of the model without centering or scaling dB1:
> Linear mixed model fit by maximum likelihood t-tests use Satterthwaite approximations to
>   degrees of freedom [lmerMod]
> Formula: MCs ~ dB1 + (1 + dB1 | Species)
>    Data: data
>
>      AIC      BIC   logLik deviance df.resid
>  10720.4  10754.7  -5354.2  10708.4     2215
>
> Scaled residuals:
>     Min      1Q  Median      3Q     Max
> -8.7305 -0.3491  0.0651  0.4508  6.6068
>
> Random effects:
>  Groups   Name        Variance Std.Dev. Corr
>  Species  (Intercept) 21.48    4.635
>           dB1         11.25    3.355    -1.00
>  Residual              6.19    2.488
> Number of obs: 2221, groups:  Species, 598
>
> Fixed effects:
>             Estimate Std. Error       df t value Pr(>|t|)
> (Intercept) -64.2618     0.4249 273.4200  -151.2   <2e-16 ***
> dB1          98.0060     0.2800 271.1900   350.0   <2e-16 ***
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Correlation of Fixed Effects:
>     (Intr)
> dB1 -0.987
>
> summary of the centered model m4c:
>> summary(m4c)
> Linear mixed model fit by maximum likelihood t-tests use Satterthwaite approximations to
>   degrees of freedom [lmerMod]
> Formula: MCs ~ dB1c + (1 + dB1c | Species)
>    Data: data
>
>      AIC      BIC   logLik deviance df.resid
>  10720.4  10754.7  -5354.2  10708.4     2215
>
> Scaled residuals:
>     Min      1Q  Median      3Q     Max
> -8.7305 -0.3491  0.0651  0.4508  6.6068
>
> Random effects:
>  Groups   Name        Variance Std.Dev. Corr
>  Species  (Intercept) 1.109    1.053
>           dB1c        1.763    1.328    0.94
>  Residual             6.190    2.488
> Number of obs: 2221, groups:  Species, 598
>
> Fixed effects:
>              Estimate Std. Error        df t value Pr(>|t|)
> (Intercept)  99.54109    0.08466 290.67000    1176   <2e-16 ***
> dB1c         38.78838    0.11081 271.18000     350   <2e-16 ***
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Correlation of Fixed Effects:
>      (Intr)
> dB1c 0.575
>
> and summary of the scaled model m4s:
>> summary(m4s)
> Linear mixed model fit by maximum likelihood t-tests use Satterthwaite approximations to
>   degrees of freedom [lmerMod]
> Formula: MCs ~ dB1s + (1 + dB1s | Species)
>    Data: data
>
>      AIC      BIC   logLik deviance df.resid
>  10720.4  10754.7  -5354.2  10708.4     2215
>
> Scaled residuals:
>     Min      1Q  Median      3Q     Max
> -8.7305 -0.3491  0.0651  0.4508  6.6068
>
> Random effects:
>  Groups   Name        Variance Std.Dev. Corr
>  Species  (Intercept) 21.48    4.635
>           dB1s        33.22    5.763    -1.00
>  Residual              6.19    2.488
> Number of obs: 2221, groups:  Species, 598
>
> Fixed effects:
>             Estimate Std. Error       df t value Pr(>|t|)
> (Intercept) -64.2618     0.4249 273.4100  -151.2   <2e-16 ***
> dB1s        168.3687     0.4810 271.1800   350.0   <2e-16 ***
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Correlation of Fixed Effects:
>      (Intr)
> dB1s -0.987
>
> Thanks in advance for your help!
> Best regards
> Jana
>
> -----Message d'origine-----
> De : Thierry Onkelinx [mailto:thierry.onkelinx at inbo.be]
> Envoy? : mardi 13 f?vrier 2018 10:26
> ? : Jana Dlouha <jana.dlouha at inra.fr>
> Cc : r-sig-mixed-models at r-project.org
> Objet : Re: [R-sig-ME] correlation between random effects
>
> Dear Jana,
>
> I assume that you uses the centered dB1c both in the random and the fixed effects? Another thing you can try is to scale dB1c. Using sensible units is often sufficient. Don't use large units (e.g.
> kilometers) when you are measuring small things (e.g. millimeters).
>
> You'll need to provide more information when you need more feedback.
> At least the summary of the data and the model.
>
> Best regards,
>
> ir. Thierry Onkelinx
> Statisticus / Statistician
>
> Vlaamse Overheid / Government of Flanders INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND FOREST Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance thierry.onkelinx at inbo.be Havenlaan 88 bus 73, 1000 Brussel www.inbo.be
>
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher The plural of anecdote is not data. ~ Roger Brinner The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey ///////////////////////////////////////////////////////////////////////////////////////////
>
>
>
>
> 2018-02-13 10:00 GMT+01:00 Jana Dlouha <jana.dlouha at inra.fr>:
>> Hi all,
>>
>> I have a problem with a correlation between random effects. I have tested several models on my data:
>> m0<-lm(MCs~ dB1, data)
>> m1<- lmer(MCs~ dB1 + (1|Species), data, REML=FALSE)
>> m2 <- lmer(MCs~ dB1 + (-1+dB1|Species), data, REML=FALSE)
>> m3<- lmer(MCs~ dB1 + (1|Species)+(0+dB1|Species), data, REML=FALSE)
>> m4<- lmer(MCs ~ dB1 + (1+dB1 |Species), data,REML=FALSE)
>>
>> and when I compare the AIC criterion, the lowest one is for the model m4:
>>      m0              m1           m2            m3            m4
>> 11086.51 10948.72 10828.75 10830.75 10720.43
>>
>> However, in the summary I see that there is a strong correlation between random effects and associated variances are huge:
>> Random effects:
>> Groups   Name        Variance Std.Dev. Corr
>>  Species  (Intercept) 21.48    4.635
>>           dB1         11.25    3.355    -1.00
>> Residual              6.19    2.488
>> Number of obs: 2221, groups:  Species, 598
>>
>> For m3, random effect associated with  intercept has very low variance and residual variance is only  a bit higher:
>> Random effects:
>> Groups    Name        Variance  Std.Dev.
>>  Species   (Intercept) 3.419e-14 1.849e-07
>> Species.1 dB1         7.968e-01 8.927e-01
>> Residual              6.327e+00 2.515e+00
>> Number of obs: 2221, groups:  Species, 598
>>
>> I am tempted to take into account only the randon effect associated with the slope however I don't know if i can do this considering that the AIC is not the lowest one for this model and how to justify it in my paper?
>> By the way, I don't really understand why the variances associated with the random effects change so much.
>> I have tried to center the regressor dB1 which removed the correlation between fixed effects and changed the sign of correlation but random effects remain strongly correlated and variances large:
>>
>> Random effects:
>> Groups   Name        Variance Std.Dev. Corr
>> Species  (Intercept)  1.109   1.053
>>           dB1c        11.255   3.355    0.94
>> Residual              6.190   2.488
>> Number of obs: 2221, groups:  Species, 598
>>
>> Could you please give me some hint to solve my problem? Thanks a lot
>> in advance
>>
>> Jana
>>
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From diego.pavonjordan at gmail.com  Tue Feb 13 11:43:51 2018
From: diego.pavonjordan at gmail.com (Diego Pavon)
Date: Tue, 13 Feb 2018 12:43:51 +0200
Subject: [R-sig-ME] error in glmmTMB when adding glmmTMBControl: unused
 arguments
In-Reply-To: <6FC2B039-A16D-47FA-8037-A1A40265BED1@gmail.com>
References: <CAD93_Fp1DRT3M_Sgh10UFUMrVcizrK0uAXx4hKpvimUKT0RRwg@mail.gmail.com>
 <CABghstTD86Fv14L9B28FQQxrGc8x6ycLs8mpj_RejpO56yhwTg@mail.gmail.com>
 <6FC2B039-A16D-47FA-8037-A1A40265BED1@gmail.com>
Message-ID: <CAD93_FpXNNLZks9JKVZBRRAjgnTojun0+C8E32YhydPqAv3_Gg@mail.gmail.com>

Dear Mollie and Ben

After getting admin rights to my laptop, I managed to update glmmTMB from
0.1.0 to the latest 0.2.0 and the error message disappeared.

@Mollie, I will report to you if after running the model, the error message
I showed above still shows.

Cheers

Diego

On 12 February 2018 at 15:07, Mollie Brooks <mollieebrooks at gmail.com> wrote:

> Yes, I agree that the control argument (as you specified it) appears to be
> working on the development version of glmmTMB.
> For example
> (m3 <- glmmTMB(count~spp + mined + (1|site),
>   zi=~spp + mined,
>   family=nbinom2, Salamanders, control = glmmTMBControl(optCtrl =
> list(iter.max = 1000,
> eval.max = 1000), profile = TRUE, collect = FALSE)))
>
> The error you get
>
>
> Error in optimHess(par.fixed, obj$fn, obj$gr) :
>  gradient in optim evaluated to length 1 not 14
> In addition: There were 11 warnings (use warnings() to see them)
>
> should have produced a message including "See
> vignette('troubleshooting')". If it didn?t, then something is broken, so
> please report it in the issue tracker on GitHub or let me know.
>
> thanks,
> Mollie
>
> ???????????
> Mollie E. Brooks, Ph.D.
> Research Scientist
> National Institute of Aquatic Resources
> Technical University of Denmark
>
> On 12Feb 2018, at 13:48, Ben Bolker <bbolker at gmail.com> wrote:
>
> A reproducible example would be useful.  This works (with the
> development version
> of glmmTMB, but I'd be surprised if it broke since the last CRAN release
> ...)
>
> library(glmmTMB)
>
> m1 <- glmmTMB(count~ mined + (1|site),
>              zi=~mined,
>              family=poisson, data=Salamanders,
>  control=glmmTMBControl(optCtrl=list(iter.max=1e3,
>                                      eval.max=1e3),
>                         profile=TRUE))
>
> what's your sessionInfo()?
>
> Maybe obvious, but it would probably be efficient to do some
> troubleshooting/model-checking on a
> smaller subset of your data, if you haven't already ...
>
> On Mon, Feb 12, 2018 at 3:04 AM, Diego Pavon
> <diego.pavonjordan at gmail.com> wrote:
>
> Dear list
>
> I am trying to run this model
>
> M1.zi <- glmmTMB(Abundance ~ Temp_std + NEness_std + WithinNatura +
> Winter_std
>                 + WithinNatura * Winter_std + NEness_std * Winter_std +
> Temp_std * WithinNatura
>                 + WithinNatura * Winter_std  * NEness_std
>                 + (1|fWinter/site) + (1|species),
>                 family = poisson,
>                 ziformula = ~ 1,
>                 data = AllSpecies)
>
> but after a couple of days (I have 3.5 million data points), I finally got
> an error:
>
> Error in optimHess(par.fixed, obj$fn, obj$gr) :
>  gradient in optim evaluated to length 1 not 14
> In addition: There were 11 warnings (use warnings() to see them)
>
>
> Then I tried to add the CONTROL argument following
> https://cran.r-project.org/web/packages/glmmTMB/glmmTMB.pdf:
>
> M1.zi <- glmmTMB(Abundance ~ Temp_std + NEness_std + WithinNatura +
> Winter_std
>                 + WithinNatura * Winter_std + NEness_std * Winter_std +
> Temp_std * WithinNatura
>                 + WithinNatura * Winter_std  * NEness_std
>                 + (1|fWinter/site) + (1|species),
>                 family = poisson,
>                 control = glmmTMBControl(optCtrl = list(iter.max = 1000,
> eval.max = 1000), profile = TRUE, collect = FALSE),
>                 ziformula = ~ 1,
>                 data = AllSpecies)
>
>
> For some reason, I get this error message:
>
> Error in glmmTMB(Abundance ~ Temp_std + NEness_std + WithinNatura +
> Winter_std +  :
>  unused argument (control = glmmTMBControl(optCtrl = list(iter.max = 1000,
> eval.max = 1000), profile = TRUE, collect = FALSE))
>
>
> Does anyone have an idea how to specify the control arguments? I suspect
> this is some small thing I am missing but I can't see it anymore...
>
> Thank you very much for your time and help.
>
> Best
>
> Diego
>
>
>
> --
> *Diego Pav?n Jord?n*
>
> *Finnish Museum of Natural History*
> *PO BOX 17 *
>
> *Helsinki. Finland*
>
> *0445061210https://www.researchgate.net/profile/Diego_Pavon-jordan
> <https://www.researchgate.net/profile/Diego_Pavon-jordan>*
>
>        [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>


-- 
*Diego Pav?n Jord?n*

*Finnish Museum of Natural History*
*PO BOX 17 *

*Helsinki. Finland*

*0445061210https://www.researchgate.net/profile/Diego_Pavon-jordan
<https://www.researchgate.net/profile/Diego_Pavon-jordan>*

	[[alternative HTML version deleted]]


From paul.johnson at glasgow.ac.uk  Tue Feb 13 13:23:59 2018
From: paul.johnson at glasgow.ac.uk (Paul Johnson)
Date: Tue, 13 Feb 2018 12:23:59 +0000
Subject: [R-sig-ME] 
 How can I make R using more than 1 core (8 available) on
 a Ubuntu Rstudio server ?
In-Reply-To: <CALFoxB91GtOVtX8op8RJf6_xbRAg19RGRYbO6+c9d8jSq6wR7w@mail.gmail.com>
References: <CALFoxB9zy7mXDRj8Ub+9M_ZVFK-8Cgk1Q7AvFG2dDAUT4oBQAQ@mail.gmail.com>
 <CAO7JsnSPPbk_rqZiCkkuQGQRMRHFE3c5RmAYGdees=qPZTDQ_Q@mail.gmail.com>
 <CABghstSjmPLxA9VnQNdaZ7gQX3e-jwO9bKAqMrS-+v2YdT5Z8g@mail.gmail.com>
 <20180120232415.fpynz3y2vqvgr76w@hans>
 <CALFoxB91GtOVtX8op8RJf6_xbRAg19RGRYbO6+c9d8jSq6wR7w@mail.gmail.com>
Message-ID: <32096AD6-B3F7-48B3-B73A-1B65D212BFB3@glasgow.ac.uk>

You can use anova(fit1, fit2) to compare nested models fitted using glmmTMB. However given that you have a large data set you might want to avoid refitting the model, in which case you could use a Wald z test (this ignores the residual df ? i.e. assumes it?s infinite ? but probably fine with big data). This test uses a restriction matrix to test the global null hypothesis that all the k-1 factor level effects are zero. In fact it can be used more flexibly than this, but mainly that?s how I use it: for getting p-values for factors and splines from models that would be slow to refit. Here?s some example code (which is probably not very general but works for me).

# Wald z-test function 
# (adapted from http://stijnruiter.nl/blog/?p=309 - now a broken link)
# this Wald test method is dubious at low n because it doesn't take account of the 
# degrees of freedom.
# (see Bolker et al. Trends in Ecology & Evolution, Volume 24, Issue 3, 127-135, 29 January 2009).
# 2017-07-02: adapted to take glmmTMB fits

Wald<-
  function(object, R, q = NULL, gmmTMB.model = "cond")
  {
    if (!is.matrix(R)) stop("Restrictions must be a matrix")
    if(is.null(q)) q <- rep(0, nrow(R))
    b <- fixef(object)
    if(class(b) == "fixef.glmmTMB") b <- b[[gmmTMB.model]]
    vc <- vcov(object)
    if("vcov.glmmTMB" %in% class(vc)) vc <- vc[[gmmTMB.model]]
    w <- t(R %*% b - q) %*% solve(R %*% vc %*% t(R)) %*% (R %*% b - q)
    pw <- pchisq(w[1], length(q), lower.tail = FALSE)
    cat("*************\n* Wald Test *\n*************\n")
    cat("lme4 fixed effects:\n")
    print(fixef(object))
    cat("\nRestrictions:\n")
    print(R)
    cat("\nq = ",q)
    cat("\nChi-square:", round(w[1],3), " df = ", length(q))
    cat("\nProb x>chisq:", round(pw, 5), "\n")
    pw
  }

library(glmmTMB)

# example from ?glmmTMB
data(cbpp, package="lme4")
(tmbm1 <- glmmTMB(cbind(incidence, size-incidence) ~ period + (1 | herd),
                  data=cbpp, family=binomial))

# LRT
anova(update(tmbm1, ~ . - period), tmbm1)

# Wald z test
# quick and dirty way to construct the R matrix
# (is there a way to extract this directly from the fitted model?)
eff.names <- names(fixef(tmbm1)$cond)
p.names <- grep("period", eff.names, value = TRUE, fixed = TRUE)
R <- 
  t(sapply(p.names, 
           function(en) 
             grep(en, eff.names, value = TRUE, fixed = TRUE) == eff.names)) + 0

# p-value
Wald(tmbm1, R = R)





> On 13 Feb 2018, at 08:15, Nicolas B?d?re <n.bedere at gmail.com> wrote:
> 
> Dear glmmTMB users,
> 
> I have tried the solution proposed by Ben Bolker since our serveur is a
> R-studio serveur, I could not try Julia.
> It runs faster indeed, thanks ! I don't want to put on a scene an old
> fight... but to publish in animal science we need P-values, whatever are
> the good reasons for not getting some... our community is not ready yet !
> with the lmer packages I used to get the global effects with Anova:car. The
> glmmTMB objects are not supported by this function. Do you know any
> solution to get the global effect of the factor instead of the effect of
> each levels ?
> 
> Many thanks,
> Nicolas
> 
> 2018-01-21 0:24 GMT+01:00 Hans Ekbrand <hans.ekbrand at gmail.com>:
> 
>> On Thu, Jan 18, 2018 at 03:36:08PM -0500, Ben Bolker wrote:
>>>  Explaining a little bit more; unlike a lot of informatics/machine
>>> learning procedures, the algorithm underlying lme4 is not naturally
>>> parallelizable. There are components that *could* be done in parallel,
>>> but it's not simple.
>>> 
>>>  If you need faster computation, you could either try Doug's
>>> MixedModels.jl package for Julia, or the glmmTMB package (on CRAN),
>>> which may scale better than glmer for problems with large numbers of
>>> fixed-effect parameters (although my guess is that it's close to a tie
>>> for the problem specs you quote below, unless your fixed effects are
>>> factors with several levels).
>> 
>> I'm currently analysing a few huge datasets and in one of the cases
>> the outcome was binary (in the other cases, the outcome was count data
>> so I used negative binomial in glmmTMB), so I tried both glmer and
>> glmmTMB and glmmTMB was faster. My model included about 11 fixed
>> effects without interactions and three random intercept terms.
>> 
>> However, I had problem getting a clean convergence when I tried to fit
>> the model to the complete dataset, both with glmer and glmmTMB, and
>> what I did might help Nicolas B?d?re too. I think the convergence
>> problems in my case was related to the fact that the outcome was very
>> rare, only 11.221 cases had the outcome (death), while 5.674.928
>> didn't have the outcome (the were alive).
>> 
>> Anyway, I divided the dataset into 8 bins, and fitted the same model
>> to each dataset, and since I had a 4 core CPU, 4 datasets could be
>> independently fitted in parallel. Then I took the estimates and
>> applied Rubin's Rule on them, to get pooled results.
>> 
>> (In my particular case, I left all 11.221 positive cases in each of
>> the 8 datasets, while each negative case only appeared in one of the 8
>> datasets.)
>> 
>> I consider what I did as a kind of poor-man's-bootstrapping, but I
>> would like to have some feedback on the valididity of results one gets
>> with the method I used. If it is valid, then it is one way of
>> parallelising glmer.
>> 
>> --
>> Hans Ekbrand, Fil Dr
>> Epost/email: <hans.ekbrand at gu.se>
>> Telefon/phone: +46-31 786 47 73
>> Institutionen f?r sociologi och arbetsvetenskap, G?teborgs universitet
>> Department of sociology and work science, Gothenburg university
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From jana.dlouha at inra.fr  Tue Feb 13 16:29:01 2018
From: jana.dlouha at inra.fr (Jana Dlouha)
Date: Tue, 13 Feb 2018 15:29:01 +0000
Subject: [R-sig-ME] correlation between random effects
In-Reply-To: <CAJuCY5zGnWGw4Ls_Tv8xG0bxspdj3B-qJ8MrTvXn6aQ_zsrCTA@mail.gmail.com>
References: <5e1a81d3edd04e9c9716da7166b07533@TLSDCPRIPEXMU05.inra.local>
 <CAJuCY5z5mfud3-if8YLQ_Zs9Lxr=OzHU9oY2tvjazKaCn8RjmA@mail.gmail.com>
 <e3a2a5b71ef54555a92876aa1803f501@TLSDCPRIPEXMU05.inra.local>
 <CAJuCY5zGnWGw4Ls_Tv8xG0bxspdj3B-qJ8MrTvXn6aQ_zsrCTA@mail.gmail.com>
Message-ID: <d735ee9a169f43498ff56799a767ddf8@TLSDCPRIPEXMU05.inra.local>

Dear Thierry,

You are right, some species are represented only by one or two specimens, actually we did not want to use the mixed-effect models but the reviewers of our paper asked us to do that - but if I understand well from what you say, it is maybe not very smart considering the structure of our sample?
I am struggling to know which species is behaving differently - is there any efficient method to visualize that? I have plotted the random effects using plot_model function but not able to change the y_axis in order to be able to read it, with 600 Species everything is overlapped...
Thanks in advance

Jana

-----Message d'origine-----
De?: Thierry Onkelinx [mailto:thierry.onkelinx at inbo.be] 
Envoy??: mardi 13 f?vrier 2018 11:44
??: Jana Dlouha <jana.dlouha at inra.fr>
Cc?: r-sig-mixed-models at r-project.org
Objet?: Re: [R-sig-ME] correlation between random effects

Dear Jana,

Please keep the mailing list in cc.

I meant both centering and scaling.

Based on the summary of the model, you have on average 3.7 observations per species, which is a bit small for a random slope model. What worries me is that the summary of the data indicates several species with > 20 observation. Hence you will have lot of species with only 1 or 2 observations. A species with only 2 observations, a small difference in dB1 and a large difference in MC will likely result in a large random slope for dB1. You'll need to investigate which species have a strong random slope and why. Most of the time that is obvious once you plotted the data for that species.
Tip: plot the observations, the fitted values of the model and the predictions using only the fixed effects.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND FOREST Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance thierry.onkelinx at inbo.be Havenlaan 88 bus 73, 1000 Brussel www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher The plural of anecdote is not data. ~ Roger Brinner The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey ///////////////////////////////////////////////////////////////////////////////////////////




2018-02-13 11:23 GMT+01:00 Jana Dlouha <jana.dlouha at inra.fr>:
> Dear Thierry,
>
> Thanks a lot for your reply. Yes, I have used dB1c also in the random effect.
> I have just tried to scale dB1 but I have still the same problem. However, it is possible that I am not doing things well, I am not a statistician and moreover I am just discovering R...
> You say that I should provide more information so here is the summary of my data for the two columns I am using in this model:
> Species         MCs             dB1
> 327     :43     Min.    40.05   Min.    :1.050
> 135     :35     1st Qu. 72.53   1st Qu. :1.400
> 307     :24     Median  89.11   Median  :1.560
> 146     :23     Mean    99.56   Mean    :1.671
> 328     :23     3rd Qu. 116.23  3rd Qu. :1.840
> 341     :22     Max.    351.49  Max.    :4.220
> (Other):2051
>
> How I centered and scaled dB1:
> dB1c<-scale(data$dB1,center=TRUE)
> dB1s<-scale(data$dB1,center=FALSE, scale=TRUE)
>
> summary of the model without centering or scaling dB1:
> Linear mixed model fit by maximum likelihood t-tests use Satterthwaite approximations to
>   degrees of freedom [lmerMod]
> Formula: MCs ~ dB1 + (1 + dB1 | Species)
>    Data: data
>
>      AIC      BIC   logLik deviance df.resid
>  10720.4  10754.7  -5354.2  10708.4     2215
>
> Scaled residuals:
>     Min      1Q  Median      3Q     Max
> -8.7305 -0.3491  0.0651  0.4508  6.6068
>
> Random effects:
>  Groups   Name        Variance Std.Dev. Corr
>  Species  (Intercept) 21.48    4.635
>           dB1         11.25    3.355    -1.00
>  Residual              6.19    2.488
> Number of obs: 2221, groups:  Species, 598
>
> Fixed effects:
>             Estimate Std. Error       df t value Pr(>|t|)
> (Intercept) -64.2618     0.4249 273.4200  -151.2   <2e-16 ***
> dB1          98.0060     0.2800 271.1900   350.0   <2e-16 ***
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Correlation of Fixed Effects:
>     (Intr)
> dB1 -0.987
>
> summary of the centered model m4c:
>> summary(m4c)
> Linear mixed model fit by maximum likelihood t-tests use Satterthwaite approximations to
>   degrees of freedom [lmerMod]
> Formula: MCs ~ dB1c + (1 + dB1c | Species)
>    Data: data
>
>      AIC      BIC   logLik deviance df.resid
>  10720.4  10754.7  -5354.2  10708.4     2215
>
> Scaled residuals:
>     Min      1Q  Median      3Q     Max
> -8.7305 -0.3491  0.0651  0.4508  6.6068
>
> Random effects:
>  Groups   Name        Variance Std.Dev. Corr
>  Species  (Intercept) 1.109    1.053
>           dB1c        1.763    1.328    0.94
>  Residual             6.190    2.488
> Number of obs: 2221, groups:  Species, 598
>
> Fixed effects:
>              Estimate Std. Error        df t value Pr(>|t|)
> (Intercept)  99.54109    0.08466 290.67000    1176   <2e-16 ***
> dB1c         38.78838    0.11081 271.18000     350   <2e-16 ***
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Correlation of Fixed Effects:
>      (Intr)
> dB1c 0.575
>
> and summary of the scaled model m4s:
>> summary(m4s)
> Linear mixed model fit by maximum likelihood t-tests use Satterthwaite approximations to
>   degrees of freedom [lmerMod]
> Formula: MCs ~ dB1s + (1 + dB1s | Species)
>    Data: data
>
>      AIC      BIC   logLik deviance df.resid
>  10720.4  10754.7  -5354.2  10708.4     2215
>
> Scaled residuals:
>     Min      1Q  Median      3Q     Max
> -8.7305 -0.3491  0.0651  0.4508  6.6068
>
> Random effects:
>  Groups   Name        Variance Std.Dev. Corr
>  Species  (Intercept) 21.48    4.635
>           dB1s        33.22    5.763    -1.00
>  Residual              6.19    2.488
> Number of obs: 2221, groups:  Species, 598
>
> Fixed effects:
>             Estimate Std. Error       df t value Pr(>|t|)
> (Intercept) -64.2618     0.4249 273.4100  -151.2   <2e-16 ***
> dB1s        168.3687     0.4810 271.1800   350.0   <2e-16 ***
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Correlation of Fixed Effects:
>      (Intr)
> dB1s -0.987
>
> Thanks in advance for your help!
> Best regards
> Jana
>
> -----Message d'origine-----
> De : Thierry Onkelinx [mailto:thierry.onkelinx at inbo.be] Envoy? : mardi 
> 13 f?vrier 2018 10:26 ? : Jana Dlouha <jana.dlouha at inra.fr> Cc : 
> r-sig-mixed-models at r-project.org Objet : Re: [R-sig-ME] correlation 
> between random effects
>
> Dear Jana,
>
> I assume that you uses the centered dB1c both in the random and the fixed effects? Another thing you can try is to scale dB1c. Using sensible units is often sufficient. Don't use large units (e.g.
> kilometers) when you are measuring small things (e.g. millimeters).
>
> You'll need to provide more information when you need more feedback.
> At least the summary of the data and the model.
>
> Best regards,
>
> ir. Thierry Onkelinx
> Statisticus / Statistician
>
> Vlaamse Overheid / Government of Flanders INSTITUUT VOOR NATUUR- EN 
> BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND FOREST Team Biometrie 
> & Kwaliteitszorg / Team Biometrics & Quality Assurance 
> thierry.onkelinx at inbo.be Havenlaan 88 bus 73, 1000 Brussel www.inbo.be
>
> //////////////////////////////////////////////////////////////////////
> ///////////////////// To call in the statistician after the experiment 
> is done may be no more than asking him to perform a post-mortem 
> examination: he may be able to say what the experiment died of. ~ Sir 
> Ronald Aylmer Fisher The plural of anecdote is not data. ~ Roger 
> Brinner The combination of some data and an aching desire for an 
> answer does not ensure that a reasonable answer can be extracted from 
> a given body of data. ~ John Tukey 
> //////////////////////////////////////////////////////////////////////
> /////////////////////
>
>
>
>
> 2018-02-13 10:00 GMT+01:00 Jana Dlouha <jana.dlouha at inra.fr>:
>> Hi all,
>>
>> I have a problem with a correlation between random effects. I have tested several models on my data:
>> m0<-lm(MCs~ dB1, data)
>> m1<- lmer(MCs~ dB1 + (1|Species), data, REML=FALSE)
>> m2 <- lmer(MCs~ dB1 + (-1+dB1|Species), data, REML=FALSE)
>> m3<- lmer(MCs~ dB1 + (1|Species)+(0+dB1|Species), data, REML=FALSE)
>> m4<- lmer(MCs ~ dB1 + (1+dB1 |Species), data,REML=FALSE)
>>
>> and when I compare the AIC criterion, the lowest one is for the model m4:
>>      m0              m1           m2            m3            m4
>> 11086.51 10948.72 10828.75 10830.75 10720.43
>>
>> However, in the summary I see that there is a strong correlation between random effects and associated variances are huge:
>> Random effects:
>> Groups   Name        Variance Std.Dev. Corr
>>  Species  (Intercept) 21.48    4.635
>>           dB1         11.25    3.355    -1.00
>> Residual              6.19    2.488
>> Number of obs: 2221, groups:  Species, 598
>>
>> For m3, random effect associated with  intercept has very low variance and residual variance is only  a bit higher:
>> Random effects:
>> Groups    Name        Variance  Std.Dev.
>>  Species   (Intercept) 3.419e-14 1.849e-07
>> Species.1 dB1         7.968e-01 8.927e-01
>> Residual              6.327e+00 2.515e+00
>> Number of obs: 2221, groups:  Species, 598
>>
>> I am tempted to take into account only the randon effect associated with the slope however I don't know if i can do this considering that the AIC is not the lowest one for this model and how to justify it in my paper?
>> By the way, I don't really understand why the variances associated with the random effects change so much.
>> I have tried to center the regressor dB1 which removed the correlation between fixed effects and changed the sign of correlation but random effects remain strongly correlated and variances large:
>>
>> Random effects:
>> Groups   Name        Variance Std.Dev. Corr
>> Species  (Intercept)  1.109   1.053
>>           dB1c        11.255   3.355    0.94
>> Residual              6.190   2.488
>> Number of obs: 2221, groups:  Species, 598
>>
>> Could you please give me some hint to solve my problem? Thanks a lot 
>> in advance
>>
>> Jana
>>
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list 
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

From bbolker at gmail.com  Tue Feb 13 18:34:27 2018
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 13 Feb 2018 12:34:27 -0500
Subject: [R-sig-ME] correlation between random effects
In-Reply-To: <d735ee9a169f43498ff56799a767ddf8@TLSDCPRIPEXMU05.inra.local>
References: <5e1a81d3edd04e9c9716da7166b07533@TLSDCPRIPEXMU05.inra.local>
 <CAJuCY5z5mfud3-if8YLQ_Zs9Lxr=OzHU9oY2tvjazKaCn8RjmA@mail.gmail.com>
 <e3a2a5b71ef54555a92876aa1803f501@TLSDCPRIPEXMU05.inra.local>
 <CAJuCY5zGnWGw4Ls_Tv8xG0bxspdj3B-qJ8MrTvXn6aQ_zsrCTA@mail.gmail.com>
 <d735ee9a169f43498ff56799a767ddf8@TLSDCPRIPEXMU05.inra.local>
Message-ID: <CABghstTj2icDc0WirH-M4DzCxf7K2qGtQirqkP4fdqFxAKcjhA@mail.gmail.com>

  you can use as.data.frame(ranef(fitted_model)) to extract the random
effects as a data frame, then do anything you want to look at the most
extreme species ...

On Tue, Feb 13, 2018 at 10:29 AM, Jana Dlouha <jana.dlouha at inra.fr> wrote:
> Dear Thierry,
>
> You are right, some species are represented only by one or two specimens, actually we did not want to use the mixed-effect models but the reviewers of our paper asked us to do that - but if I understand well from what you say, it is maybe not very smart considering the structure of our sample?
> I am struggling to know which species is behaving differently - is there any efficient method to visualize that? I have plotted the random effects using plot_model function but not able to change the y_axis in order to be able to read it, with 600 Species everything is overlapped...
> Thanks in advance
>
> Jana
>
> -----Message d'origine-----
> De : Thierry Onkelinx [mailto:thierry.onkelinx at inbo.be]
> Envoy? : mardi 13 f?vrier 2018 11:44
> ? : Jana Dlouha <jana.dlouha at inra.fr>
> Cc : r-sig-mixed-models at r-project.org
> Objet : Re: [R-sig-ME] correlation between random effects
>
> Dear Jana,
>
> Please keep the mailing list in cc.
>
> I meant both centering and scaling.
>
> Based on the summary of the model, you have on average 3.7 observations per species, which is a bit small for a random slope model. What worries me is that the summary of the data indicates several species with > 20 observation. Hence you will have lot of species with only 1 or 2 observations. A species with only 2 observations, a small difference in dB1 and a large difference in MC will likely result in a large random slope for dB1. You'll need to investigate which species have a strong random slope and why. Most of the time that is obvious once you plotted the data for that species.
> Tip: plot the observations, the fitted values of the model and the predictions using only the fixed effects.
>
> Best regards,
>
> ir. Thierry Onkelinx
> Statisticus / Statistician
>
> Vlaamse Overheid / Government of Flanders INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND FOREST Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance thierry.onkelinx at inbo.be Havenlaan 88 bus 73, 1000 Brussel www.inbo.be
>
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher The plural of anecdote is not data. ~ Roger Brinner The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey ///////////////////////////////////////////////////////////////////////////////////////////
>
>
>
>
> 2018-02-13 11:23 GMT+01:00 Jana Dlouha <jana.dlouha at inra.fr>:
>> Dear Thierry,
>>
>> Thanks a lot for your reply. Yes, I have used dB1c also in the random effect.
>> I have just tried to scale dB1 but I have still the same problem. However, it is possible that I am not doing things well, I am not a statistician and moreover I am just discovering R...
>> You say that I should provide more information so here is the summary of my data for the two columns I am using in this model:
>> Species         MCs             dB1
>> 327     :43     Min.    40.05   Min.    :1.050
>> 135     :35     1st Qu. 72.53   1st Qu. :1.400
>> 307     :24     Median  89.11   Median  :1.560
>> 146     :23     Mean    99.56   Mean    :1.671
>> 328     :23     3rd Qu. 116.23  3rd Qu. :1.840
>> 341     :22     Max.    351.49  Max.    :4.220
>> (Other):2051
>>
>> How I centered and scaled dB1:
>> dB1c<-scale(data$dB1,center=TRUE)
>> dB1s<-scale(data$dB1,center=FALSE, scale=TRUE)
>>
>> summary of the model without centering or scaling dB1:
>> Linear mixed model fit by maximum likelihood t-tests use Satterthwaite approximations to
>>   degrees of freedom [lmerMod]
>> Formula: MCs ~ dB1 + (1 + dB1 | Species)
>>    Data: data
>>
>>      AIC      BIC   logLik deviance df.resid
>>  10720.4  10754.7  -5354.2  10708.4     2215
>>
>> Scaled residuals:
>>     Min      1Q  Median      3Q     Max
>> -8.7305 -0.3491  0.0651  0.4508  6.6068
>>
>> Random effects:
>>  Groups   Name        Variance Std.Dev. Corr
>>  Species  (Intercept) 21.48    4.635
>>           dB1         11.25    3.355    -1.00
>>  Residual              6.19    2.488
>> Number of obs: 2221, groups:  Species, 598
>>
>> Fixed effects:
>>             Estimate Std. Error       df t value Pr(>|t|)
>> (Intercept) -64.2618     0.4249 273.4200  -151.2   <2e-16 ***
>> dB1          98.0060     0.2800 271.1900   350.0   <2e-16 ***
>> ---
>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>
>> Correlation of Fixed Effects:
>>     (Intr)
>> dB1 -0.987
>>
>> summary of the centered model m4c:
>>> summary(m4c)
>> Linear mixed model fit by maximum likelihood t-tests use Satterthwaite approximations to
>>   degrees of freedom [lmerMod]
>> Formula: MCs ~ dB1c + (1 + dB1c | Species)
>>    Data: data
>>
>>      AIC      BIC   logLik deviance df.resid
>>  10720.4  10754.7  -5354.2  10708.4     2215
>>
>> Scaled residuals:
>>     Min      1Q  Median      3Q     Max
>> -8.7305 -0.3491  0.0651  0.4508  6.6068
>>
>> Random effects:
>>  Groups   Name        Variance Std.Dev. Corr
>>  Species  (Intercept) 1.109    1.053
>>           dB1c        1.763    1.328    0.94
>>  Residual             6.190    2.488
>> Number of obs: 2221, groups:  Species, 598
>>
>> Fixed effects:
>>              Estimate Std. Error        df t value Pr(>|t|)
>> (Intercept)  99.54109    0.08466 290.67000    1176   <2e-16 ***
>> dB1c         38.78838    0.11081 271.18000     350   <2e-16 ***
>> ---
>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>
>> Correlation of Fixed Effects:
>>      (Intr)
>> dB1c 0.575
>>
>> and summary of the scaled model m4s:
>>> summary(m4s)
>> Linear mixed model fit by maximum likelihood t-tests use Satterthwaite approximations to
>>   degrees of freedom [lmerMod]
>> Formula: MCs ~ dB1s + (1 + dB1s | Species)
>>    Data: data
>>
>>      AIC      BIC   logLik deviance df.resid
>>  10720.4  10754.7  -5354.2  10708.4     2215
>>
>> Scaled residuals:
>>     Min      1Q  Median      3Q     Max
>> -8.7305 -0.3491  0.0651  0.4508  6.6068
>>
>> Random effects:
>>  Groups   Name        Variance Std.Dev. Corr
>>  Species  (Intercept) 21.48    4.635
>>           dB1s        33.22    5.763    -1.00
>>  Residual              6.19    2.488
>> Number of obs: 2221, groups:  Species, 598
>>
>> Fixed effects:
>>             Estimate Std. Error       df t value Pr(>|t|)
>> (Intercept) -64.2618     0.4249 273.4100  -151.2   <2e-16 ***
>> dB1s        168.3687     0.4810 271.1800   350.0   <2e-16 ***
>> ---
>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>
>> Correlation of Fixed Effects:
>>      (Intr)
>> dB1s -0.987
>>
>> Thanks in advance for your help!
>> Best regards
>> Jana
>>
>> -----Message d'origine-----
>> De : Thierry Onkelinx [mailto:thierry.onkelinx at inbo.be] Envoy? : mardi
>> 13 f?vrier 2018 10:26 ? : Jana Dlouha <jana.dlouha at inra.fr> Cc :
>> r-sig-mixed-models at r-project.org Objet : Re: [R-sig-ME] correlation
>> between random effects
>>
>> Dear Jana,
>>
>> I assume that you uses the centered dB1c both in the random and the fixed effects? Another thing you can try is to scale dB1c. Using sensible units is often sufficient. Don't use large units (e.g.
>> kilometers) when you are measuring small things (e.g. millimeters).
>>
>> You'll need to provide more information when you need more feedback.
>> At least the summary of the data and the model.
>>
>> Best regards,
>>
>> ir. Thierry Onkelinx
>> Statisticus / Statistician
>>
>> Vlaamse Overheid / Government of Flanders INSTITUUT VOOR NATUUR- EN
>> BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND FOREST Team Biometrie
>> & Kwaliteitszorg / Team Biometrics & Quality Assurance
>> thierry.onkelinx at inbo.be Havenlaan 88 bus 73, 1000 Brussel www.inbo.be
>>
>> //////////////////////////////////////////////////////////////////////
>> ///////////////////// To call in the statistician after the experiment
>> is done may be no more than asking him to perform a post-mortem
>> examination: he may be able to say what the experiment died of. ~ Sir
>> Ronald Aylmer Fisher The plural of anecdote is not data. ~ Roger
>> Brinner The combination of some data and an aching desire for an
>> answer does not ensure that a reasonable answer can be extracted from
>> a given body of data. ~ John Tukey
>> //////////////////////////////////////////////////////////////////////
>> /////////////////////
>>
>>
>>
>>
>> 2018-02-13 10:00 GMT+01:00 Jana Dlouha <jana.dlouha at inra.fr>:
>>> Hi all,
>>>
>>> I have a problem with a correlation between random effects. I have tested several models on my data:
>>> m0<-lm(MCs~ dB1, data)
>>> m1<- lmer(MCs~ dB1 + (1|Species), data, REML=FALSE)
>>> m2 <- lmer(MCs~ dB1 + (-1+dB1|Species), data, REML=FALSE)
>>> m3<- lmer(MCs~ dB1 + (1|Species)+(0+dB1|Species), data, REML=FALSE)
>>> m4<- lmer(MCs ~ dB1 + (1+dB1 |Species), data,REML=FALSE)
>>>
>>> and when I compare the AIC criterion, the lowest one is for the model m4:
>>>      m0              m1           m2            m3            m4
>>> 11086.51 10948.72 10828.75 10830.75 10720.43
>>>
>>> However, in the summary I see that there is a strong correlation between random effects and associated variances are huge:
>>> Random effects:
>>> Groups   Name        Variance Std.Dev. Corr
>>>  Species  (Intercept) 21.48    4.635
>>>           dB1         11.25    3.355    -1.00
>>> Residual              6.19    2.488
>>> Number of obs: 2221, groups:  Species, 598
>>>
>>> For m3, random effect associated with  intercept has very low variance and residual variance is only  a bit higher:
>>> Random effects:
>>> Groups    Name        Variance  Std.Dev.
>>>  Species   (Intercept) 3.419e-14 1.849e-07
>>> Species.1 dB1         7.968e-01 8.927e-01
>>> Residual              6.327e+00 2.515e+00
>>> Number of obs: 2221, groups:  Species, 598
>>>
>>> I am tempted to take into account only the randon effect associated with the slope however I don't know if i can do this considering that the AIC is not the lowest one for this model and how to justify it in my paper?
>>> By the way, I don't really understand why the variances associated with the random effects change so much.
>>> I have tried to center the regressor dB1 which removed the correlation between fixed effects and changed the sign of correlation but random effects remain strongly correlated and variances large:
>>>
>>> Random effects:
>>> Groups   Name        Variance Std.Dev. Corr
>>> Species  (Intercept)  1.109   1.053
>>>           dB1c        11.255   3.355    0.94
>>> Residual              6.190   2.488
>>> Number of obs: 2221, groups:  Species, 598
>>>
>>> Could you please give me some hint to solve my problem? Thanks a lot
>>> in advance
>>>
>>> Jana
>>>
>>>
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From thierry.onkelinx at inbo.be  Wed Feb 14 09:46:46 2018
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Wed, 14 Feb 2018 09:46:46 +0100
Subject: [R-sig-ME] correlation between random effects
In-Reply-To: <CABghstTj2icDc0WirH-M4DzCxf7K2qGtQirqkP4fdqFxAKcjhA@mail.gmail.com>
References: <5e1a81d3edd04e9c9716da7166b07533@TLSDCPRIPEXMU05.inra.local>
 <CAJuCY5z5mfud3-if8YLQ_Zs9Lxr=OzHU9oY2tvjazKaCn8RjmA@mail.gmail.com>
 <e3a2a5b71ef54555a92876aa1803f501@TLSDCPRIPEXMU05.inra.local>
 <CAJuCY5zGnWGw4Ls_Tv8xG0bxspdj3B-qJ8MrTvXn6aQ_zsrCTA@mail.gmail.com>
 <d735ee9a169f43498ff56799a767ddf8@TLSDCPRIPEXMU05.inra.local>
 <CABghstTj2icDc0WirH-M4DzCxf7K2qGtQirqkP4fdqFxAKcjhA@mail.gmail.com>
Message-ID: <CAJuCY5x2uGe+Szn1oDhE1RNhPSrs3HNi0hmvhtYNUEbNjtU4vQ@mail.gmail.com>

I agree with Ben. Look at 20 species with the most extreme random
effects. Plot those, one at a time. See what is happening for those
and decide what would be a sensible way to deal with it. That could be
to alter the model or to remove data which doesn't contain the
information needed by the model. E.g. all species with less than x
observations.

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
AND FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////




2018-02-13 18:34 GMT+01:00 Ben Bolker <bbolker at gmail.com>:
>   you can use as.data.frame(ranef(fitted_model)) to extract the random
> effects as a data frame, then do anything you want to look at the most
> extreme species ...
>
> On Tue, Feb 13, 2018 at 10:29 AM, Jana Dlouha <jana.dlouha at inra.fr> wrote:
>> Dear Thierry,
>>
>> You are right, some species are represented only by one or two specimens, actually we did not want to use the mixed-effect models but the reviewers of our paper asked us to do that - but if I understand well from what you say, it is maybe not very smart considering the structure of our sample?
>> I am struggling to know which species is behaving differently - is there any efficient method to visualize that? I have plotted the random effects using plot_model function but not able to change the y_axis in order to be able to read it, with 600 Species everything is overlapped...
>> Thanks in advance
>>
>> Jana
>>
>> -----Message d'origine-----
>> De : Thierry Onkelinx [mailto:thierry.onkelinx at inbo.be]
>> Envoy? : mardi 13 f?vrier 2018 11:44
>> ? : Jana Dlouha <jana.dlouha at inra.fr>
>> Cc : r-sig-mixed-models at r-project.org
>> Objet : Re: [R-sig-ME] correlation between random effects
>>
>> Dear Jana,
>>
>> Please keep the mailing list in cc.
>>
>> I meant both centering and scaling.
>>
>> Based on the summary of the model, you have on average 3.7 observations per species, which is a bit small for a random slope model. What worries me is that the summary of the data indicates several species with > 20 observation. Hence you will have lot of species with only 1 or 2 observations. A species with only 2 observations, a small difference in dB1 and a large difference in MC will likely result in a large random slope for dB1. You'll need to investigate which species have a strong random slope and why. Most of the time that is obvious once you plotted the data for that species.
>> Tip: plot the observations, the fitted values of the model and the predictions using only the fixed effects.
>>
>> Best regards,
>>
>> ir. Thierry Onkelinx
>> Statisticus / Statistician
>>
>> Vlaamse Overheid / Government of Flanders INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND FOREST Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance thierry.onkelinx at inbo.be Havenlaan 88 bus 73, 1000 Brussel www.inbo.be
>>
>> ///////////////////////////////////////////////////////////////////////////////////////////
>> To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher The plural of anecdote is not data. ~ Roger Brinner The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey ///////////////////////////////////////////////////////////////////////////////////////////
>>
>>
>>
>>
>> 2018-02-13 11:23 GMT+01:00 Jana Dlouha <jana.dlouha at inra.fr>:
>>> Dear Thierry,
>>>
>>> Thanks a lot for your reply. Yes, I have used dB1c also in the random effect.
>>> I have just tried to scale dB1 but I have still the same problem. However, it is possible that I am not doing things well, I am not a statistician and moreover I am just discovering R...
>>> You say that I should provide more information so here is the summary of my data for the two columns I am using in this model:
>>> Species         MCs             dB1
>>> 327     :43     Min.    40.05   Min.    :1.050
>>> 135     :35     1st Qu. 72.53   1st Qu. :1.400
>>> 307     :24     Median  89.11   Median  :1.560
>>> 146     :23     Mean    99.56   Mean    :1.671
>>> 328     :23     3rd Qu. 116.23  3rd Qu. :1.840
>>> 341     :22     Max.    351.49  Max.    :4.220
>>> (Other):2051
>>>
>>> How I centered and scaled dB1:
>>> dB1c<-scale(data$dB1,center=TRUE)
>>> dB1s<-scale(data$dB1,center=FALSE, scale=TRUE)
>>>
>>> summary of the model without centering or scaling dB1:
>>> Linear mixed model fit by maximum likelihood t-tests use Satterthwaite approximations to
>>>   degrees of freedom [lmerMod]
>>> Formula: MCs ~ dB1 + (1 + dB1 | Species)
>>>    Data: data
>>>
>>>      AIC      BIC   logLik deviance df.resid
>>>  10720.4  10754.7  -5354.2  10708.4     2215
>>>
>>> Scaled residuals:
>>>     Min      1Q  Median      3Q     Max
>>> -8.7305 -0.3491  0.0651  0.4508  6.6068
>>>
>>> Random effects:
>>>  Groups   Name        Variance Std.Dev. Corr
>>>  Species  (Intercept) 21.48    4.635
>>>           dB1         11.25    3.355    -1.00
>>>  Residual              6.19    2.488
>>> Number of obs: 2221, groups:  Species, 598
>>>
>>> Fixed effects:
>>>             Estimate Std. Error       df t value Pr(>|t|)
>>> (Intercept) -64.2618     0.4249 273.4200  -151.2   <2e-16 ***
>>> dB1          98.0060     0.2800 271.1900   350.0   <2e-16 ***
>>> ---
>>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>>
>>> Correlation of Fixed Effects:
>>>     (Intr)
>>> dB1 -0.987
>>>
>>> summary of the centered model m4c:
>>>> summary(m4c)
>>> Linear mixed model fit by maximum likelihood t-tests use Satterthwaite approximations to
>>>   degrees of freedom [lmerMod]
>>> Formula: MCs ~ dB1c + (1 + dB1c | Species)
>>>    Data: data
>>>
>>>      AIC      BIC   logLik deviance df.resid
>>>  10720.4  10754.7  -5354.2  10708.4     2215
>>>
>>> Scaled residuals:
>>>     Min      1Q  Median      3Q     Max
>>> -8.7305 -0.3491  0.0651  0.4508  6.6068
>>>
>>> Random effects:
>>>  Groups   Name        Variance Std.Dev. Corr
>>>  Species  (Intercept) 1.109    1.053
>>>           dB1c        1.763    1.328    0.94
>>>  Residual             6.190    2.488
>>> Number of obs: 2221, groups:  Species, 598
>>>
>>> Fixed effects:
>>>              Estimate Std. Error        df t value Pr(>|t|)
>>> (Intercept)  99.54109    0.08466 290.67000    1176   <2e-16 ***
>>> dB1c         38.78838    0.11081 271.18000     350   <2e-16 ***
>>> ---
>>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>>
>>> Correlation of Fixed Effects:
>>>      (Intr)
>>> dB1c 0.575
>>>
>>> and summary of the scaled model m4s:
>>>> summary(m4s)
>>> Linear mixed model fit by maximum likelihood t-tests use Satterthwaite approximations to
>>>   degrees of freedom [lmerMod]
>>> Formula: MCs ~ dB1s + (1 + dB1s | Species)
>>>    Data: data
>>>
>>>      AIC      BIC   logLik deviance df.resid
>>>  10720.4  10754.7  -5354.2  10708.4     2215
>>>
>>> Scaled residuals:
>>>     Min      1Q  Median      3Q     Max
>>> -8.7305 -0.3491  0.0651  0.4508  6.6068
>>>
>>> Random effects:
>>>  Groups   Name        Variance Std.Dev. Corr
>>>  Species  (Intercept) 21.48    4.635
>>>           dB1s        33.22    5.763    -1.00
>>>  Residual              6.19    2.488
>>> Number of obs: 2221, groups:  Species, 598
>>>
>>> Fixed effects:
>>>             Estimate Std. Error       df t value Pr(>|t|)
>>> (Intercept) -64.2618     0.4249 273.4100  -151.2   <2e-16 ***
>>> dB1s        168.3687     0.4810 271.1800   350.0   <2e-16 ***
>>> ---
>>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>>
>>> Correlation of Fixed Effects:
>>>      (Intr)
>>> dB1s -0.987
>>>
>>> Thanks in advance for your help!
>>> Best regards
>>> Jana
>>>
>>> -----Message d'origine-----
>>> De : Thierry Onkelinx [mailto:thierry.onkelinx at inbo.be] Envoy? : mardi
>>> 13 f?vrier 2018 10:26 ? : Jana Dlouha <jana.dlouha at inra.fr> Cc :
>>> r-sig-mixed-models at r-project.org Objet : Re: [R-sig-ME] correlation
>>> between random effects
>>>
>>> Dear Jana,
>>>
>>> I assume that you uses the centered dB1c both in the random and the fixed effects? Another thing you can try is to scale dB1c. Using sensible units is often sufficient. Don't use large units (e.g.
>>> kilometers) when you are measuring small things (e.g. millimeters).
>>>
>>> You'll need to provide more information when you need more feedback.
>>> At least the summary of the data and the model.
>>>
>>> Best regards,
>>>
>>> ir. Thierry Onkelinx
>>> Statisticus / Statistician
>>>
>>> Vlaamse Overheid / Government of Flanders INSTITUUT VOOR NATUUR- EN
>>> BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND FOREST Team Biometrie
>>> & Kwaliteitszorg / Team Biometrics & Quality Assurance
>>> thierry.onkelinx at inbo.be Havenlaan 88 bus 73, 1000 Brussel www.inbo.be
>>>
>>> //////////////////////////////////////////////////////////////////////
>>> ///////////////////// To call in the statistician after the experiment
>>> is done may be no more than asking him to perform a post-mortem
>>> examination: he may be able to say what the experiment died of. ~ Sir
>>> Ronald Aylmer Fisher The plural of anecdote is not data. ~ Roger
>>> Brinner The combination of some data and an aching desire for an
>>> answer does not ensure that a reasonable answer can be extracted from
>>> a given body of data. ~ John Tukey
>>> //////////////////////////////////////////////////////////////////////
>>> /////////////////////
>>>
>>>
>>>
>>>
>>> 2018-02-13 10:00 GMT+01:00 Jana Dlouha <jana.dlouha at inra.fr>:
>>>> Hi all,
>>>>
>>>> I have a problem with a correlation between random effects. I have tested several models on my data:
>>>> m0<-lm(MCs~ dB1, data)
>>>> m1<- lmer(MCs~ dB1 + (1|Species), data, REML=FALSE)
>>>> m2 <- lmer(MCs~ dB1 + (-1+dB1|Species), data, REML=FALSE)
>>>> m3<- lmer(MCs~ dB1 + (1|Species)+(0+dB1|Species), data, REML=FALSE)
>>>> m4<- lmer(MCs ~ dB1 + (1+dB1 |Species), data,REML=FALSE)
>>>>
>>>> and when I compare the AIC criterion, the lowest one is for the model m4:
>>>>      m0              m1           m2            m3            m4
>>>> 11086.51 10948.72 10828.75 10830.75 10720.43
>>>>
>>>> However, in the summary I see that there is a strong correlation between random effects and associated variances are huge:
>>>> Random effects:
>>>> Groups   Name        Variance Std.Dev. Corr
>>>>  Species  (Intercept) 21.48    4.635
>>>>           dB1         11.25    3.355    -1.00
>>>> Residual              6.19    2.488
>>>> Number of obs: 2221, groups:  Species, 598
>>>>
>>>> For m3, random effect associated with  intercept has very low variance and residual variance is only  a bit higher:
>>>> Random effects:
>>>> Groups    Name        Variance  Std.Dev.
>>>>  Species   (Intercept) 3.419e-14 1.849e-07
>>>> Species.1 dB1         7.968e-01 8.927e-01
>>>> Residual              6.327e+00 2.515e+00
>>>> Number of obs: 2221, groups:  Species, 598
>>>>
>>>> I am tempted to take into account only the randon effect associated with the slope however I don't know if i can do this considering that the AIC is not the lowest one for this model and how to justify it in my paper?
>>>> By the way, I don't really understand why the variances associated with the random effects change so much.
>>>> I have tried to center the regressor dB1 which removed the correlation between fixed effects and changed the sign of correlation but random effects remain strongly correlated and variances large:
>>>>
>>>> Random effects:
>>>> Groups   Name        Variance Std.Dev. Corr
>>>> Species  (Intercept)  1.109   1.053
>>>>           dB1c        11.255   3.355    0.94
>>>> Residual              6.190   2.488
>>>> Number of obs: 2221, groups:  Species, 598
>>>>
>>>> Could you please give me some hint to solve my problem? Thanks a lot
>>>> in advance
>>>>
>>>> Jana
>>>>
>>>>
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From inh4 at cdc.gov  Wed Feb 14 17:07:34 2018
From: inh4 at cdc.gov (Bertke, Stephen (CDC/NIOSH/DSHEFS))
Date: Wed, 14 Feb 2018 16:07:34 +0000
Subject: [R-sig-ME] Mixed Models in SAS and R
Message-ID: <f1d15f0590834749893b287bb5063489@cdc.gov>

Hello everyone. I have just joined this mailing list so I wanted to introduce myself as well as ask a question.

My name is Steve Bertke and I am a researcher at the National Institute for Occupational Safety and Health (NIOSH) which is one of the centers within the Centers for Disease Control and Prevention (CDC). I am a long-time SAS user but have been slowly finding myself using and liking R. I have found the support community for R very helpful and rewarding and am looking forward to contributing my part.

On to my question.

I have ran the same model (I think) in both SAS (proc mixed) and R (lmer) but have gotten different results for the random terms.

A quick background, we took 2 personal air samples for 127 people at 15 different factories for a total of 252 samples (after dropping 2 samples). We are trying to model various factors of the factory on the air samples. To do so, we need to control for the repeated measure of the person (nested within factory) as well as the random factory effect.

You can see below for the exact code and exact results, but in short, when I run the models in R and SAS without any fixed effects, I get the same results for the random effects. When I enter in the fixed effects, I get a different result for the Site variance...but all other results are the same (both the fixed effects and the other random effects).

There is another methodological issue with the model I am running. I am entering in 17 fixed effects that describe the 15 sites. Therefore, the model is over-specified. As a result, SAS gives a variance estimate of 0 for site (which, in hindsight, makes sense) however, R does not. That is a separate issue that we are dealing with, but I would expect that R and SAS would give the same result. Or maybe at least a warning.

Below is my code and output. I hope the formatting remains so that it is easily readable for everyone. I may also be able to share the data too, but I need to get some approval for that first.

Details
I ran the following code in SAS and R without any fixed effects and both give the same results:

proc mixed data=dat;
class NewSiteID NIOSHID;
model ln_i = ;
random NewSiteID NIOSHID(NewSiteID);
run;

Covariance Parameter Estimates

Cov Parm

Estimate

NewSiteID

6.3433

NIOSHID(NewSiteID)

0.7465

Residual

2.5256


mixedidsite <- lmer(ln_i ~ (1 | NewSiteID/NIOSHID),
                    data = Modeling_Database_Final)
summary(mixedidsite)

Random effects:
Groups                              Name        Variance Std.Dev.
NIOSHID:NewSiteID       (Intercept) 0.7465   0.864
 NewSiteID                        (Intercept) 6.3434   2.519
 Residual                                                 2.5256   1.589

However, when I add in the fixed effects, I get different results. SAS gives an estimate of 0 for Site while R does not. All other results are the same:

proc mixed data=dat;
class NewSiteID NIOSHID F_mass_handled_or (ref=first);
model ln_i = F_High_Exp
F_Mat_Type_SW
F_Mat_Type_CNF
F_Mat_Form_Dry
F_Mat_Form_Liq
F_Mat_Form_Comp
F_Hybrid
F_Primary
F_Coatings
F_mass_handled_or
F_adequate
F_inadequate
F_emp_sc
F_diam_sc/solution;
random NewSiteID NIOSHID(NewSiteID);
run;

Covariance Parameter Estimates

Cov Parm

Estimate

NewSiteID

0

NIOSHID(NewSiteID)

0.6954

Residual

2.5372


Fit Statistics

-2 Res Log Likelihood

961.8

AIC (Smaller is Better)

965.8

AICC (Smaller is Better)

965.9

BIC (Smaller is Better)

967.3


Solution for Fixed Effects

Effect

F_mass_handled_or

Estimate

Standard
Error

DF

t Value

Pr > |t|

Intercept



-139.29

83.6162

92.1

-1.67

0.0991

F_High_Exp



-180.24

102.72

92.6

-1.75

0.0826

F_Mat_Type_SW



470.30

261.53

92.1

1.80

0.0754

F_Mat_Type_CNF



-636.35

347.99

92.1

-1.83

0.0707

F_Mat_Form_Dry



662.26

368.75

92

1.80

0.0758

F_Mat_Form_Liq



-583.14

318.54

92

-1.83

0.0704

F_Mat_Form_Comp



598.77

331.85

92

1.80

0.0745

F_Hybrid



-1197.69

658.23

92

-1.82

0.0721

F_Primary



-639.93

352.80

92

-1.81

0.0730

F_Coatings



92.7949

50.7416

92.1

1.83

0.0707

F_mass_handled_or

F2

134.91

77.2496

92

1.75

0.0841

F_mass_handled_or

F3

-1235.37

677.42

92

-1.82

0.0715

F_mass_handled_or

F4

137.71

75.9370

92

1.81

0.0730

F_mass_handled_or

F1

0

.

.

.

.

F_adequate



139.45

76.5607

92

1.82

0.0718

F_inadequate



1395.04

767.40

92

1.82

0.0723

F_emp_sc



-1259.21

691.98

92

-1.82

0.0721

F_diam_sc



-20.1875

9.9710

89.5

-2.02

0.0459


mixedidsite <- lmer(ln_i ~ (1 | NewSiteID/NIOSHID)  + F_High_Exp + F_Mat_Type_SW +
                      F_Mat_Type_CNF + F_Mat_Form_Dry + F_Mat_Form_Liq + F_Mat_Form_Comp +
                      F_Hybrid + F_Primary + F_Coatings + F_adequate +
                      F_inadequate + F_emp_sc + F_diam_sc,
                    data = Modeling_Database_Final)
summary(mixedidsite)

REML criterion at convergence: 961.8

Scaled residuals:
    Min      1Q  Median      3Q     Max
-2.3019 -0.5248 -0.1668  0.3511  4.7091

Random effects:
Groups                              Name        Variance Std.Dev.
NIOSHID:NewSiteID       (Intercept) 0.6954   0.8339
 NewSiteID                        (Intercept) 1.5932   1.2622
 Residual                                                2.5372   1.5929
Number of obs: 252, groups:  NIOSHID:NewSiteID, 127; NewSiteID, 15

Fixed effects:
                                                           Estimate Std. Error t value
(Intercept)                                       -139.292     83.702  -1.664
F_High_Exp                                      -180.239    102.778  -1.754
F_Mat_Type_SW                            470.297    261.537   1.798
F_Mat_Type_CNF                           -636.352    347.993  -1.829
F_Mat_Form_Dry                            662.263    368.761   1.796
F_Mat_Form_Liq                            -583.142    318.541  -1.831
F_Mat_Form_Comp                       598.774    331.856   1.804
F_Hybrid                                           -1197.691    658.229  -1.820
F_Primary                                        -639.928    352.811  -1.814
F_Coatings                                       92.795     50.804   1.826
F_mass_handled_orF2: 10 -         134.912     77.291   1.746
F_mass_handled_orF3: 101         -1235.372    677.423  -1.824
F_mass_handled_orF4: >1 k        137.714     75.958   1.813
F_adequate                                     139.446     76.582   1.821
F_inadequate                                  1395.036    767.413   1.818
F_emp_sc                                         -1259.213    691.979  -1.820
F_diam_sc                                        -20.188      9.971  -2.025

Again, the SAS results make sense...that there is 0 variance left over from the fully specified fixed effects. I am fairly certain the combination of the fixed effects uniquely identifies each facility. However, why doesn't R give a 0 variance? What is different between the two methods?


	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Wed Feb 14 17:38:41 2018
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Wed, 14 Feb 2018 17:38:41 +0100
Subject: [R-sig-ME] Mixed Models in SAS and R
In-Reply-To: <f1d15f0590834749893b287bb5063489@cdc.gov>
References: <f1d15f0590834749893b287bb5063489@cdc.gov>
Message-ID: <CAJuCY5xAZ-tdBJEKQ3mcapX7k+U1FpTUA=7NU199udOyy0km-g@mail.gmail.com>

Dear Stephen,

The list removes all HTML formating, making your post hard to read.
Please use only plain text when posting.

You'll need to make sure that you fit exactly the same model in SAS as
in R. Not everyone here speaks SAS. Providing the math equation for
the SAS model would help.

Also please elaborate why it makes sense that the variance of site
should be zero. We cannot verify that statement based on the
information you provide.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
AND FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////




2018-02-14 17:07 GMT+01:00 Bertke, Stephen (CDC/NIOSH/DSHEFS) <inh4 at cdc.gov>:
> Hello everyone. I have just joined this mailing list so I wanted to introduce myself as well as ask a question.
>
> My name is Steve Bertke and I am a researcher at the National Institute for Occupational Safety and Health (NIOSH) which is one of the centers within the Centers for Disease Control and Prevention (CDC). I am a long-time SAS user but have been slowly finding myself using and liking R. I have found the support community for R very helpful and rewarding and am looking forward to contributing my part.
>
> On to my question.
>
> I have ran the same model (I think) in both SAS (proc mixed) and R (lmer) but have gotten different results for the random terms.
>
> A quick background, we took 2 personal air samples for 127 people at 15 different factories for a total of 252 samples (after dropping 2 samples). We are trying to model various factors of the factory on the air samples. To do so, we need to control for the repeated measure of the person (nested within factory) as well as the random factory effect.
>
> You can see below for the exact code and exact results, but in short, when I run the models in R and SAS without any fixed effects, I get the same results for the random effects. When I enter in the fixed effects, I get a different result for the Site variance...but all other results are the same (both the fixed effects and the other random effects).
>
> There is another methodological issue with the model I am running. I am entering in 17 fixed effects that describe the 15 sites. Therefore, the model is over-specified. As a result, SAS gives a variance estimate of 0 for site (which, in hindsight, makes sense) however, R does not. That is a separate issue that we are dealing with, but I would expect that R and SAS would give the same result. Or maybe at least a warning.
>
> Below is my code and output. I hope the formatting remains so that it is easily readable for everyone. I may also be able to share the data too, but I need to get some approval for that first.
>
> Details
> I ran the following code in SAS and R without any fixed effects and both give the same results:
>
> proc mixed data=dat;
> class NewSiteID NIOSHID;
> model ln_i = ;
> random NewSiteID NIOSHID(NewSiteID);
> run;
>
> Covariance Parameter Estimates
>
> Cov Parm
>
> Estimate
>
> NewSiteID
>
> 6.3433
>
> NIOSHID(NewSiteID)
>
> 0.7465
>
> Residual
>
> 2.5256
>
>
> mixedidsite <- lmer(ln_i ~ (1 | NewSiteID/NIOSHID),
>                     data = Modeling_Database_Final)
> summary(mixedidsite)
>
> Random effects:
> Groups                              Name        Variance Std.Dev.
> NIOSHID:NewSiteID       (Intercept) 0.7465   0.864
>  NewSiteID                        (Intercept) 6.3434   2.519
>  Residual                                                 2.5256   1.589
>
> However, when I add in the fixed effects, I get different results. SAS gives an estimate of 0 for Site while R does not. All other results are the same:
>
> proc mixed data=dat;
> class NewSiteID NIOSHID F_mass_handled_or (ref=first);
> model ln_i = F_High_Exp
> F_Mat_Type_SW
> F_Mat_Type_CNF
> F_Mat_Form_Dry
> F_Mat_Form_Liq
> F_Mat_Form_Comp
> F_Hybrid
> F_Primary
> F_Coatings
> F_mass_handled_or
> F_adequate
> F_inadequate
> F_emp_sc
> F_diam_sc/solution;
> random NewSiteID NIOSHID(NewSiteID);
> run;
>
> Covariance Parameter Estimates
>
> Cov Parm
>
> Estimate
>
> NewSiteID
>
> 0
>
> NIOSHID(NewSiteID)
>
> 0.6954
>
> Residual
>
> 2.5372
>
>
> Fit Statistics
>
> -2 Res Log Likelihood
>
> 961.8
>
> AIC (Smaller is Better)
>
> 965.8
>
> AICC (Smaller is Better)
>
> 965.9
>
> BIC (Smaller is Better)
>
> 967.3
>
>
> Solution for Fixed Effects
>
> Effect
>
> F_mass_handled_or
>
> Estimate
>
> Standard
> Error
>
> DF
>
> t Value
>
> Pr > |t|
>
> Intercept
>
>
>
> -139.29
>
> 83.6162
>
> 92.1
>
> -1.67
>
> 0.0991
>
> F_High_Exp
>
>
>
> -180.24
>
> 102.72
>
> 92.6
>
> -1.75
>
> 0.0826
>
> F_Mat_Type_SW
>
>
>
> 470.30
>
> 261.53
>
> 92.1
>
> 1.80
>
> 0.0754
>
> F_Mat_Type_CNF
>
>
>
> -636.35
>
> 347.99
>
> 92.1
>
> -1.83
>
> 0.0707
>
> F_Mat_Form_Dry
>
>
>
> 662.26
>
> 368.75
>
> 92
>
> 1.80
>
> 0.0758
>
> F_Mat_Form_Liq
>
>
>
> -583.14
>
> 318.54
>
> 92
>
> -1.83
>
> 0.0704
>
> F_Mat_Form_Comp
>
>
>
> 598.77
>
> 331.85
>
> 92
>
> 1.80
>
> 0.0745
>
> F_Hybrid
>
>
>
> -1197.69
>
> 658.23
>
> 92
>
> -1.82
>
> 0.0721
>
> F_Primary
>
>
>
> -639.93
>
> 352.80
>
> 92
>
> -1.81
>
> 0.0730
>
> F_Coatings
>
>
>
> 92.7949
>
> 50.7416
>
> 92.1
>
> 1.83
>
> 0.0707
>
> F_mass_handled_or
>
> F2
>
> 134.91
>
> 77.2496
>
> 92
>
> 1.75
>
> 0.0841
>
> F_mass_handled_or
>
> F3
>
> -1235.37
>
> 677.42
>
> 92
>
> -1.82
>
> 0.0715
>
> F_mass_handled_or
>
> F4
>
> 137.71
>
> 75.9370
>
> 92
>
> 1.81
>
> 0.0730
>
> F_mass_handled_or
>
> F1
>
> 0
>
> .
>
> .
>
> .
>
> .
>
> F_adequate
>
>
>
> 139.45
>
> 76.5607
>
> 92
>
> 1.82
>
> 0.0718
>
> F_inadequate
>
>
>
> 1395.04
>
> 767.40
>
> 92
>
> 1.82
>
> 0.0723
>
> F_emp_sc
>
>
>
> -1259.21
>
> 691.98
>
> 92
>
> -1.82
>
> 0.0721
>
> F_diam_sc
>
>
>
> -20.1875
>
> 9.9710
>
> 89.5
>
> -2.02
>
> 0.0459
>
>
> mixedidsite <- lmer(ln_i ~ (1 | NewSiteID/NIOSHID)  + F_High_Exp + F_Mat_Type_SW +
>                       F_Mat_Type_CNF + F_Mat_Form_Dry + F_Mat_Form_Liq + F_Mat_Form_Comp +
>                       F_Hybrid + F_Primary + F_Coatings + F_adequate +
>                       F_inadequate + F_emp_sc + F_diam_sc,
>                     data = Modeling_Database_Final)
> summary(mixedidsite)
>
> REML criterion at convergence: 961.8
>
> Scaled residuals:
>     Min      1Q  Median      3Q     Max
> -2.3019 -0.5248 -0.1668  0.3511  4.7091
>
> Random effects:
> Groups                              Name        Variance Std.Dev.
> NIOSHID:NewSiteID       (Intercept) 0.6954   0.8339
>  NewSiteID                        (Intercept) 1.5932   1.2622
>  Residual                                                2.5372   1.5929
> Number of obs: 252, groups:  NIOSHID:NewSiteID, 127; NewSiteID, 15
>
> Fixed effects:
>                                                            Estimate Std. Error t value
> (Intercept)                                       -139.292     83.702  -1.664
> F_High_Exp                                      -180.239    102.778  -1.754
> F_Mat_Type_SW                            470.297    261.537   1.798
> F_Mat_Type_CNF                           -636.352    347.993  -1.829
> F_Mat_Form_Dry                            662.263    368.761   1.796
> F_Mat_Form_Liq                            -583.142    318.541  -1.831
> F_Mat_Form_Comp                       598.774    331.856   1.804
> F_Hybrid                                           -1197.691    658.229  -1.820
> F_Primary                                        -639.928    352.811  -1.814
> F_Coatings                                       92.795     50.804   1.826
> F_mass_handled_orF2: 10 -         134.912     77.291   1.746
> F_mass_handled_orF3: 101         -1235.372    677.423  -1.824
> F_mass_handled_orF4: >1 k        137.714     75.958   1.813
> F_adequate                                     139.446     76.582   1.821
> F_inadequate                                  1395.036    767.413   1.818
> F_emp_sc                                         -1259.213    691.979  -1.820
> F_diam_sc                                        -20.188      9.971  -2.025
>
> Again, the SAS results make sense...that there is 0 variance left over from the fully specified fixed effects. I am fairly certain the combination of the fixed effects uniquely identifies each facility. However, why doesn't R give a 0 variance? What is different between the two methods?
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From telli at bu.edu  Mon Feb 12 18:53:17 2018
From: telli at bu.edu (Telli Davoodi)
Date: Mon, 12 Feb 2018 12:53:17 -0500
Subject: [R-sig-ME] Repeated Measures Design With lme Function
In-Reply-To: <CAJuCY5zF05G_sKhjG1KJO_SKwo23NzLqzJ4wqwEGM+BRZMQXdg@mail.gmail.com>
References: <CAAN3=Difb-VbEi4RaWcpixfnNiyLLnkmPP9fGr1WQ2N4DYkcEg@mail.gmail.com>
 <CAJuCY5zF05G_sKhjG1KJO_SKwo23NzLqzJ4wqwEGM+BRZMQXdg@mail.gmail.com>
Message-ID: <CAAN3=DgRT3OUFgjy2YEk0Q8W-qMhPPU+UKydbQpCALxyfsem-Q@mail.gmail.com>

Dear Thierry,

Thank you for the reply. Just to make sure, after I did a little more
research on my design, I concluded that in my design, Question and Category
are crossed (maybe you have already figured this our from my original
explanation). So, with this in mind, does the syntax you suggest still make
sense with the lme function? Or do I have to run my model with lmer?

Thanks again,
Telli

On Mon, Feb 12, 2018 at 11:18 AM, Thierry Onkelinx <thierry.onkelinx at inbo.be
> wrote:

> Dear Telli,
>
> When you nest question in category, you assume that you have 25 (= 5 x
> 5) different question which are grouped into 5 categories.
>
> In lme4 notation the random effects (1|SubjectID/Category/Question)
> translate more verbose into (1|SubjectID) + (1|SubjectID:Category) +
> (1|SubjectID:Category:Question). This make it more clear that you have
> 3 random intercepts: one per SubjectID, one per combination of
> SubjectID and Category and one per combination of SubjectID, Category
> and Question. That last random intercept has only one observation per
> level and thus doesn't make sense. So I'd go for lme(Essen ~
> AgeinYears * Category * Question, random = ~1|SubjectID/Category) Note
> that I've rearraged the order of the fixed effects. This is yield a
> different parametrisation which seems a bit more appropriate for this
> case.
>
> Best regards,
>
> ir. Thierry Onkelinx
> Statisticus / Statistician
>
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
> AND FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Havenlaan 88 bus 73, 1000 Brussel
> www.inbo.be
>
> ////////////////////////////////////////////////////////////
> ///////////////////////////////
> To call in the statistician after the experiment is done may be no
> more than asking him to perform a post-mortem examination: he may be
> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does
> not ensure that a reasonable answer can be extracted from a given body
> of data. ~ John Tukey
> ////////////////////////////////////////////////////////////
> ///////////////////////////////
>
>
>
>
> 2018-02-10 21:59 GMT+01:00 Telli Davoodi <telli at bu.edu>:
> > Hi all,
> >
> > I'm having a hard time defining a model with my repeated measures design
> > (explained below). This is an experimental design and it is fully
> balanced.
> > I would really appreciate it if you have any feedback.
> >
> > Thanks,
> > Telli
> >
> > Here's the design of my experiment: I have 72 children (Subject ID)
> answer
> > five questions (Question) about five different categories (Category).
> > Basically, the same five questions repeat for each category. So, in long
> > format, every participant has 25 rows (five for each level of category
> and
> > within each level of category, question has five levels).
> >
> > Now, I want to fit a mixed-effects regression model on this data, using
> the
> > lme function from the nmle package, but I'm not sure how to account for
> the
> > fact that Category repeats with Subject ID and Question repeats with
> > Category. This is what I have so far, but I'm not sure if I'm specifying
> > the random part of the model correctly:
> >
> > summary(Qs <- lme(Essen ~ Question * AgeinYears * Category,
> > random = ~1|SubjectID/Category/Question, data = Q, na.action = na.omit))
> >
> > I just want to make sure that I am allowing Category to vary within
> > SubjectID and Question to vary within Category.
> >
> > Also, is it correct to say that Category is "nested" under Subject ID and
> > Question is nested under Category?
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From inh4 at cdc.gov  Wed Feb 14 20:25:26 2018
From: inh4 at cdc.gov (Bertke, Stephen (CDC/NIOSH/DSHEFS))
Date: Wed, 14 Feb 2018 19:25:26 +0000
Subject: [R-sig-ME] Mixed Models in SAS and R
In-Reply-To: <CAJuCY5xAZ-tdBJEKQ3mcapX7k+U1FpTUA=7NU199udOyy0km-g@mail.gmail.com>
References: <f1d15f0590834749893b287bb5063489@cdc.gov>
 <CAJuCY5xAZ-tdBJEKQ3mcapX7k+U1FpTUA=7NU199udOyy0km-g@mail.gmail.com>
Message-ID: <44c63c17ed8d4ea8b51050667eb2a4bd@cdc.gov>

I posted the question on stackoverflow here:
https://stackoverflow.com/questions/48794651/lmer-vs-proc-mixed-output

This will hopefully make reading my code and output easier. 

I would expect a 0 variance since I am in essence fitting a model with both the site variable in the fixed and random part of the model. I actually went ahead and fit that "dumb" model in both SAS and R and once again, all results are nearly identical except SAS estimates a 0 variance and R estimates a relatively large positive variance. However, R now gives an error/warning at the bottom of the results indicating an issue with this very dumb model. Again, those results are in the above link. 




-----Original Message-----
From: Thierry Onkelinx [mailto:thierry.onkelinx at inbo.be] 
Sent: Wednesday, February 14, 2018 11:39 AM
To: Bertke, Stephen (CDC/NIOSH/DSHEFS) <inh4 at cdc.gov>
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Mixed Models in SAS and R

Dear Stephen,

The list removes all HTML formating, making your post hard to read.
Please use only plain text when posting.

You'll need to make sure that you fit exactly the same model in SAS as in R. Not everyone here speaks SAS. Providing the math equation for the SAS model would help.

Also please elaborate why it makes sense that the variance of site should be zero. We cannot verify that statement based on the information you provide.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND FOREST Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance thierry.onkelinx at inbo.be Havenlaan 88 bus 73, 1000 Brussel www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher The plural of anecdote is not data. ~ Roger Brinner The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey ///////////////////////////////////////////////////////////////////////////////////////////




2018-02-14 17:07 GMT+01:00 Bertke, Stephen (CDC/NIOSH/DSHEFS) <inh4 at cdc.gov>:
> Hello everyone. I have just joined this mailing list so I wanted to introduce myself as well as ask a question.
>
> My name is Steve Bertke and I am a researcher at the National Institute for Occupational Safety and Health (NIOSH) which is one of the centers within the Centers for Disease Control and Prevention (CDC). I am a long-time SAS user but have been slowly finding myself using and liking R. I have found the support community for R very helpful and rewarding and am looking forward to contributing my part.
>
> On to my question.
>
> I have ran the same model (I think) in both SAS (proc mixed) and R (lmer) but have gotten different results for the random terms.
>
> A quick background, we took 2 personal air samples for 127 people at 15 different factories for a total of 252 samples (after dropping 2 samples). We are trying to model various factors of the factory on the air samples. To do so, we need to control for the repeated measure of the person (nested within factory) as well as the random factory effect.
>
> You can see below for the exact code and exact results, but in short, when I run the models in R and SAS without any fixed effects, I get the same results for the random effects. When I enter in the fixed effects, I get a different result for the Site variance...but all other results are the same (both the fixed effects and the other random effects).
>
> There is another methodological issue with the model I am running. I am entering in 17 fixed effects that describe the 15 sites. Therefore, the model is over-specified. As a result, SAS gives a variance estimate of 0 for site (which, in hindsight, makes sense) however, R does not. That is a separate issue that we are dealing with, but I would expect that R and SAS would give the same result. Or maybe at least a warning.
>
> Below is my code and output. I hope the formatting remains so that it is easily readable for everyone. I may also be able to share the data too, but I need to get some approval for that first.
>
> Details
> I ran the following code in SAS and R without any fixed effects and both give the same results:
>
> proc mixed data=dat;
> class NewSiteID NIOSHID;
> model ln_i = ;
> random NewSiteID NIOSHID(NewSiteID);
> run;
>
> Covariance Parameter Estimates
>
> Cov Parm
>
> Estimate
>
> NewSiteID
>
> 6.3433
>
> NIOSHID(NewSiteID)
>
> 0.7465
>
> Residual
>
> 2.5256
>
>
> mixedidsite <- lmer(ln_i ~ (1 | NewSiteID/NIOSHID),
>                     data = Modeling_Database_Final)
> summary(mixedidsite)
>
> Random effects:
> Groups                              Name        Variance Std.Dev.
> NIOSHID:NewSiteID       (Intercept) 0.7465   0.864
>  NewSiteID                        (Intercept) 6.3434   2.519
>  Residual                                                 2.5256   1.589
>
> However, when I add in the fixed effects, I get different results. SAS gives an estimate of 0 for Site while R does not. All other results are the same:
>
> proc mixed data=dat;
> class NewSiteID NIOSHID F_mass_handled_or (ref=first); model ln_i = 
> F_High_Exp F_Mat_Type_SW F_Mat_Type_CNF F_Mat_Form_Dry F_Mat_Form_Liq 
> F_Mat_Form_Comp F_Hybrid F_Primary F_Coatings F_mass_handled_or 
> F_adequate F_inadequate F_emp_sc F_diam_sc/solution; random NewSiteID 
> NIOSHID(NewSiteID); run;
>
> Covariance Parameter Estimates
>
> Cov Parm
>
> Estimate
>
> NewSiteID
>
> 0
>
> NIOSHID(NewSiteID)
>
> 0.6954
>
> Residual
>
> 2.5372
>
>
> Fit Statistics
>
> -2 Res Log Likelihood
>
> 961.8
>
> AIC (Smaller is Better)
>
> 965.8
>
> AICC (Smaller is Better)
>
> 965.9
>
> BIC (Smaller is Better)
>
> 967.3
>
>
> Solution for Fixed Effects
>
> Effect
>
> F_mass_handled_or
>
> Estimate
>
> Standard
> Error
>
> DF
>
> t Value
>
> Pr > |t|
>
> Intercept
>
>
>
> -139.29
>
> 83.6162
>
> 92.1
>
> -1.67
>
> 0.0991
>
> F_High_Exp
>
>
>
> -180.24
>
> 102.72
>
> 92.6
>
> -1.75
>
> 0.0826
>
> F_Mat_Type_SW
>
>
>
> 470.30
>
> 261.53
>
> 92.1
>
> 1.80
>
> 0.0754
>
> F_Mat_Type_CNF
>
>
>
> -636.35
>
> 347.99
>
> 92.1
>
> -1.83
>
> 0.0707
>
> F_Mat_Form_Dry
>
>
>
> 662.26
>
> 368.75
>
> 92
>
> 1.80
>
> 0.0758
>
> F_Mat_Form_Liq
>
>
>
> -583.14
>
> 318.54
>
> 92
>
> -1.83
>
> 0.0704
>
> F_Mat_Form_Comp
>
>
>
> 598.77
>
> 331.85
>
> 92
>
> 1.80
>
> 0.0745
>
> F_Hybrid
>
>
>
> -1197.69
>
> 658.23
>
> 92
>
> -1.82
>
> 0.0721
>
> F_Primary
>
>
>
> -639.93
>
> 352.80
>
> 92
>
> -1.81
>
> 0.0730
>
> F_Coatings
>
>
>
> 92.7949
>
> 50.7416
>
> 92.1
>
> 1.83
>
> 0.0707
>
> F_mass_handled_or
>
> F2
>
> 134.91
>
> 77.2496
>
> 92
>
> 1.75
>
> 0.0841
>
> F_mass_handled_or
>
> F3
>
> -1235.37
>
> 677.42
>
> 92
>
> -1.82
>
> 0.0715
>
> F_mass_handled_or
>
> F4
>
> 137.71
>
> 75.9370
>
> 92
>
> 1.81
>
> 0.0730
>
> F_mass_handled_or
>
> F1
>
> 0
>
> .
>
> .
>
> .
>
> .
>
> F_adequate
>
>
>
> 139.45
>
> 76.5607
>
> 92
>
> 1.82
>
> 0.0718
>
> F_inadequate
>
>
>
> 1395.04
>
> 767.40
>
> 92
>
> 1.82
>
> 0.0723
>
> F_emp_sc
>
>
>
> -1259.21
>
> 691.98
>
> 92
>
> -1.82
>
> 0.0721
>
> F_diam_sc
>
>
>
> -20.1875
>
> 9.9710
>
> 89.5
>
> -2.02
>
> 0.0459
>
>
> mixedidsite <- lmer(ln_i ~ (1 | NewSiteID/NIOSHID)  + F_High_Exp + F_Mat_Type_SW +
>                       F_Mat_Type_CNF + F_Mat_Form_Dry + F_Mat_Form_Liq + F_Mat_Form_Comp +
>                       F_Hybrid + F_Primary + F_Coatings + F_adequate +
>                       F_inadequate + F_emp_sc + F_diam_sc,
>                     data = Modeling_Database_Final)
> summary(mixedidsite)
>
> REML criterion at convergence: 961.8
>
> Scaled residuals:
>     Min      1Q  Median      3Q     Max
> -2.3019 -0.5248 -0.1668  0.3511  4.7091
>
> Random effects:
> Groups                              Name        Variance Std.Dev.
> NIOSHID:NewSiteID       (Intercept) 0.6954   0.8339
>  NewSiteID                        (Intercept) 1.5932   1.2622
>  Residual                                                2.5372   1.5929
> Number of obs: 252, groups:  NIOSHID:NewSiteID, 127; NewSiteID, 15
>
> Fixed effects:
>                                                            Estimate Std. Error t value
> (Intercept)                                       -139.292     83.702  -1.664
> F_High_Exp                                      -180.239    102.778  -1.754
> F_Mat_Type_SW                            470.297    261.537   1.798
> F_Mat_Type_CNF                           -636.352    347.993  -1.829
> F_Mat_Form_Dry                            662.263    368.761   1.796
> F_Mat_Form_Liq                            -583.142    318.541  -1.831
> F_Mat_Form_Comp                       598.774    331.856   1.804
> F_Hybrid                                           -1197.691    658.229  -1.820
> F_Primary                                        -639.928    352.811  -1.814
> F_Coatings                                       92.795     50.804   1.826
> F_mass_handled_orF2: 10 -         134.912     77.291   1.746
> F_mass_handled_orF3: 101         -1235.372    677.423  -1.824
> F_mass_handled_orF4: >1 k        137.714     75.958   1.813
> F_adequate                                     139.446     76.582   1.821
> F_inadequate                                  1395.036    767.413   1.818
> F_emp_sc                                         -1259.213    691.979  -1.820
> F_diam_sc                                        -20.188      9.971  -2.025
>
> Again, the SAS results make sense...that there is 0 variance left over from the fully specified fixed effects. I am fairly certain the combination of the fixed effects uniquely identifies each facility. However, why doesn't R give a 0 variance? What is different between the two methods?
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

From jana.dlouha at inra.fr  Thu Feb 15 13:48:29 2018
From: jana.dlouha at inra.fr (Jana Dlouha)
Date: Thu, 15 Feb 2018 12:48:29 +0000
Subject: [R-sig-ME] correlation between random effects
In-Reply-To: <CAJuCY5x2uGe+Szn1oDhE1RNhPSrs3HNi0hmvhtYNUEbNjtU4vQ@mail.gmail.com>
References: <5e1a81d3edd04e9c9716da7166b07533@TLSDCPRIPEXMU05.inra.local>
 <CAJuCY5z5mfud3-if8YLQ_Zs9Lxr=OzHU9oY2tvjazKaCn8RjmA@mail.gmail.com>
 <e3a2a5b71ef54555a92876aa1803f501@TLSDCPRIPEXMU05.inra.local>
 <CAJuCY5zGnWGw4Ls_Tv8xG0bxspdj3B-qJ8MrTvXn6aQ_zsrCTA@mail.gmail.com>
 <d735ee9a169f43498ff56799a767ddf8@TLSDCPRIPEXMU05.inra.local>
 <CABghstTj2icDc0WirH-M4DzCxf7K2qGtQirqkP4fdqFxAKcjhA@mail.gmail.com>
 <CAJuCY5x2uGe+Szn1oDhE1RNhPSrs3HNi0hmvhtYNUEbNjtU4vQ@mail.gmail.com>
Message-ID: <b1c54b2ac85044a499dfed823d12c7b4@TLSDCPRIPEXMU05.inra.local>

Hi all again,

Thanks to Thierry and Ben for their advices and sorry to answer so late, I was out of the lab yesterday.

I looked at the 20 species with the most extreme random effects and unfortunately, it is not systematically the least represented species, one has 13 repetitions so I think it is not possible to exclude them based on the quantitative criterion. There are probably some measurement problems but not related specifically to some species or families so...is there any way to handle it? What did you mean by altering the model?

Best regards
Jana


-----Message d'origine-----
De?: Thierry Onkelinx [mailto:thierry.onkelinx at inbo.be] 
Envoy??: mercredi 14 f?vrier 2018 09:47
??: Ben Bolker <bbolker at gmail.com>
Cc?: Jana Dlouha <jana.dlouha at inra.fr>; r-sig-mixed-models at r-project.org
Objet?: Re: [R-sig-ME] correlation between random effects

I agree with Ben. Look at 20 species with the most extreme random effects. Plot those, one at a time. See what is happening for those and decide what would be a sensible way to deal with it. That could be to alter the model or to remove data which doesn't contain the information needed by the model. E.g. all species with less than x observations.

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND FOREST Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance thierry.onkelinx at inbo.be Havenlaan 88 bus 73, 1000 Brussel www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher The plural of anecdote is not data. ~ Roger Brinner The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey ///////////////////////////////////////////////////////////////////////////////////////////




2018-02-13 18:34 GMT+01:00 Ben Bolker <bbolker at gmail.com>:
>   you can use as.data.frame(ranef(fitted_model)) to extract the random 
> effects as a data frame, then do anything you want to look at the most 
> extreme species ...
>
> On Tue, Feb 13, 2018 at 10:29 AM, Jana Dlouha <jana.dlouha at inra.fr> wrote:
>> Dear Thierry,
>>
>> You are right, some species are represented only by one or two specimens, actually we did not want to use the mixed-effect models but the reviewers of our paper asked us to do that - but if I understand well from what you say, it is maybe not very smart considering the structure of our sample?
>> I am struggling to know which species is behaving differently - is there any efficient method to visualize that? I have plotted the random effects using plot_model function but not able to change the y_axis in order to be able to read it, with 600 Species everything is overlapped...
>> Thanks in advance
>>
>> Jana
>>
>> -----Message d'origine-----
>> De : Thierry Onkelinx [mailto:thierry.onkelinx at inbo.be] Envoy? : 
>> mardi 13 f?vrier 2018 11:44 ? : Jana Dlouha <jana.dlouha at inra.fr> Cc 
>> : r-sig-mixed-models at r-project.org Objet : Re: [R-sig-ME] correlation 
>> between random effects
>>
>> Dear Jana,
>>
>> Please keep the mailing list in cc.
>>
>> I meant both centering and scaling.
>>
>> Based on the summary of the model, you have on average 3.7 observations per species, which is a bit small for a random slope model. What worries me is that the summary of the data indicates several species with > 20 observation. Hence you will have lot of species with only 1 or 2 observations. A species with only 2 observations, a small difference in dB1 and a large difference in MC will likely result in a large random slope for dB1. You'll need to investigate which species have a strong random slope and why. Most of the time that is obvious once you plotted the data for that species.
>> Tip: plot the observations, the fitted values of the model and the predictions using only the fixed effects.
>>
>> Best regards,
>>
>> ir. Thierry Onkelinx
>> Statisticus / Statistician
>>
>> Vlaamse Overheid / Government of Flanders INSTITUUT VOOR NATUUR- EN 
>> BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND FOREST Team 
>> Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance 
>> thierry.onkelinx at inbo.be Havenlaan 88 bus 73, 1000 Brussel 
>> www.inbo.be
>>
>> /////////////////////////////////////////////////////////////////////
>> ////////////////////// To call in the statistician after the 
>> experiment is done may be no more than asking him to perform a 
>> post-mortem examination: he may be able to say what the experiment 
>> died of. ~ Sir Ronald Aylmer Fisher The plural of anecdote is not 
>> data. ~ Roger Brinner The combination of some data and an aching 
>> desire for an answer does not ensure that a reasonable answer can be 
>> extracted from a given body of data. ~ John Tukey 
>> /////////////////////////////////////////////////////////////////////
>> //////////////////////
>>
>>
>>
>>
>> 2018-02-13 11:23 GMT+01:00 Jana Dlouha <jana.dlouha at inra.fr>:
>>> Dear Thierry,
>>>
>>> Thanks a lot for your reply. Yes, I have used dB1c also in the random effect.
>>> I have just tried to scale dB1 but I have still the same problem. However, it is possible that I am not doing things well, I am not a statistician and moreover I am just discovering R...
>>> You say that I should provide more information so here is the summary of my data for the two columns I am using in this model:
>>> Species         MCs             dB1
>>> 327     :43     Min.    40.05   Min.    :1.050
>>> 135     :35     1st Qu. 72.53   1st Qu. :1.400
>>> 307     :24     Median  89.11   Median  :1.560
>>> 146     :23     Mean    99.56   Mean    :1.671
>>> 328     :23     3rd Qu. 116.23  3rd Qu. :1.840
>>> 341     :22     Max.    351.49  Max.    :4.220
>>> (Other):2051
>>>
>>> How I centered and scaled dB1:
>>> dB1c<-scale(data$dB1,center=TRUE)
>>> dB1s<-scale(data$dB1,center=FALSE, scale=TRUE)
>>>
>>> summary of the model without centering or scaling dB1:
>>> Linear mixed model fit by maximum likelihood t-tests use Satterthwaite approximations to
>>>   degrees of freedom [lmerMod]
>>> Formula: MCs ~ dB1 + (1 + dB1 | Species)
>>>    Data: data
>>>
>>>      AIC      BIC   logLik deviance df.resid
>>>  10720.4  10754.7  -5354.2  10708.4     2215
>>>
>>> Scaled residuals:
>>>     Min      1Q  Median      3Q     Max
>>> -8.7305 -0.3491  0.0651  0.4508  6.6068
>>>
>>> Random effects:
>>>  Groups   Name        Variance Std.Dev. Corr
>>>  Species  (Intercept) 21.48    4.635
>>>           dB1         11.25    3.355    -1.00
>>>  Residual              6.19    2.488
>>> Number of obs: 2221, groups:  Species, 598
>>>
>>> Fixed effects:
>>>             Estimate Std. Error       df t value Pr(>|t|)
>>> (Intercept) -64.2618     0.4249 273.4200  -151.2   <2e-16 ***
>>> dB1          98.0060     0.2800 271.1900   350.0   <2e-16 ***
>>> ---
>>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>>
>>> Correlation of Fixed Effects:
>>>     (Intr)
>>> dB1 -0.987
>>>
>>> summary of the centered model m4c:
>>>> summary(m4c)
>>> Linear mixed model fit by maximum likelihood t-tests use Satterthwaite approximations to
>>>   degrees of freedom [lmerMod]
>>> Formula: MCs ~ dB1c + (1 + dB1c | Species)
>>>    Data: data
>>>
>>>      AIC      BIC   logLik deviance df.resid
>>>  10720.4  10754.7  -5354.2  10708.4     2215
>>>
>>> Scaled residuals:
>>>     Min      1Q  Median      3Q     Max
>>> -8.7305 -0.3491  0.0651  0.4508  6.6068
>>>
>>> Random effects:
>>>  Groups   Name        Variance Std.Dev. Corr
>>>  Species  (Intercept) 1.109    1.053
>>>           dB1c        1.763    1.328    0.94
>>>  Residual             6.190    2.488
>>> Number of obs: 2221, groups:  Species, 598
>>>
>>> Fixed effects:
>>>              Estimate Std. Error        df t value Pr(>|t|)
>>> (Intercept)  99.54109    0.08466 290.67000    1176   <2e-16 ***
>>> dB1c         38.78838    0.11081 271.18000     350   <2e-16 ***
>>> ---
>>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>>
>>> Correlation of Fixed Effects:
>>>      (Intr)
>>> dB1c 0.575
>>>
>>> and summary of the scaled model m4s:
>>>> summary(m4s)
>>> Linear mixed model fit by maximum likelihood t-tests use Satterthwaite approximations to
>>>   degrees of freedom [lmerMod]
>>> Formula: MCs ~ dB1s + (1 + dB1s | Species)
>>>    Data: data
>>>
>>>      AIC      BIC   logLik deviance df.resid
>>>  10720.4  10754.7  -5354.2  10708.4     2215
>>>
>>> Scaled residuals:
>>>     Min      1Q  Median      3Q     Max
>>> -8.7305 -0.3491  0.0651  0.4508  6.6068
>>>
>>> Random effects:
>>>  Groups   Name        Variance Std.Dev. Corr
>>>  Species  (Intercept) 21.48    4.635
>>>           dB1s        33.22    5.763    -1.00
>>>  Residual              6.19    2.488
>>> Number of obs: 2221, groups:  Species, 598
>>>
>>> Fixed effects:
>>>             Estimate Std. Error       df t value Pr(>|t|)
>>> (Intercept) -64.2618     0.4249 273.4100  -151.2   <2e-16 ***
>>> dB1s        168.3687     0.4810 271.1800   350.0   <2e-16 ***
>>> ---
>>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>>
>>> Correlation of Fixed Effects:
>>>      (Intr)
>>> dB1s -0.987
>>>
>>> Thanks in advance for your help!
>>> Best regards
>>> Jana
>>>
>>> -----Message d'origine-----
>>> De : Thierry Onkelinx [mailto:thierry.onkelinx at inbo.be] Envoy? : 
>>> mardi
>>> 13 f?vrier 2018 10:26 ? : Jana Dlouha <jana.dlouha at inra.fr> Cc :
>>> r-sig-mixed-models at r-project.org Objet : Re: [R-sig-ME] correlation 
>>> between random effects
>>>
>>> Dear Jana,
>>>
>>> I assume that you uses the centered dB1c both in the random and the fixed effects? Another thing you can try is to scale dB1c. Using sensible units is often sufficient. Don't use large units (e.g.
>>> kilometers) when you are measuring small things (e.g. millimeters).
>>>
>>> You'll need to provide more information when you need more feedback.
>>> At least the summary of the data and the model.
>>>
>>> Best regards,
>>>
>>> ir. Thierry Onkelinx
>>> Statisticus / Statistician
>>>
>>> Vlaamse Overheid / Government of Flanders INSTITUUT VOOR NATUUR- EN 
>>> BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND FOREST Team 
>>> Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance 
>>> thierry.onkelinx at inbo.be Havenlaan 88 bus 73, 1000 Brussel 
>>> www.inbo.be
>>>
>>> ////////////////////////////////////////////////////////////////////
>>> // ///////////////////// To call in the statistician after the 
>>> experiment is done may be no more than asking him to perform a 
>>> post-mortem
>>> examination: he may be able to say what the experiment died of. ~ 
>>> Sir Ronald Aylmer Fisher The plural of anecdote is not data. ~ Roger 
>>> Brinner The combination of some data and an aching desire for an 
>>> answer does not ensure that a reasonable answer can be extracted 
>>> from a given body of data. ~ John Tukey 
>>> ////////////////////////////////////////////////////////////////////
>>> //
>>> /////////////////////
>>>
>>>
>>>
>>>
>>> 2018-02-13 10:00 GMT+01:00 Jana Dlouha <jana.dlouha at inra.fr>:
>>>> Hi all,
>>>>
>>>> I have a problem with a correlation between random effects. I have tested several models on my data:
>>>> m0<-lm(MCs~ dB1, data)
>>>> m1<- lmer(MCs~ dB1 + (1|Species), data, REML=FALSE)
>>>> m2 <- lmer(MCs~ dB1 + (-1+dB1|Species), data, REML=FALSE)
>>>> m3<- lmer(MCs~ dB1 + (1|Species)+(0+dB1|Species), data, REML=FALSE)
>>>> m4<- lmer(MCs ~ dB1 + (1+dB1 |Species), data,REML=FALSE)
>>>>
>>>> and when I compare the AIC criterion, the lowest one is for the model m4:
>>>>      m0              m1           m2            m3            m4
>>>> 11086.51 10948.72 10828.75 10830.75 10720.43
>>>>
>>>> However, in the summary I see that there is a strong correlation between random effects and associated variances are huge:
>>>> Random effects:
>>>> Groups   Name        Variance Std.Dev. Corr
>>>>  Species  (Intercept) 21.48    4.635
>>>>           dB1         11.25    3.355    -1.00
>>>> Residual              6.19    2.488
>>>> Number of obs: 2221, groups:  Species, 598
>>>>
>>>> For m3, random effect associated with  intercept has very low variance and residual variance is only  a bit higher:
>>>> Random effects:
>>>> Groups    Name        Variance  Std.Dev.
>>>>  Species   (Intercept) 3.419e-14 1.849e-07
>>>> Species.1 dB1         7.968e-01 8.927e-01
>>>> Residual              6.327e+00 2.515e+00
>>>> Number of obs: 2221, groups:  Species, 598
>>>>
>>>> I am tempted to take into account only the randon effect associated with the slope however I don't know if i can do this considering that the AIC is not the lowest one for this model and how to justify it in my paper?
>>>> By the way, I don't really understand why the variances associated with the random effects change so much.
>>>> I have tried to center the regressor dB1 which removed the correlation between fixed effects and changed the sign of correlation but random effects remain strongly correlated and variances large:
>>>>
>>>> Random effects:
>>>> Groups   Name        Variance Std.Dev. Corr
>>>> Species  (Intercept)  1.109   1.053
>>>>           dB1c        11.255   3.355    0.94
>>>> Residual              6.190   2.488
>>>> Number of obs: 2221, groups:  Species, 598
>>>>
>>>> Could you please give me some hint to solve my problem? Thanks a 
>>>> lot in advance
>>>>
>>>> Jana
>>>>
>>>>
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list 
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list 
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

From thierry.onkelinx at inbo.be  Thu Feb 15 14:38:01 2018
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Thu, 15 Feb 2018 14:38:01 +0100
Subject: [R-sig-ME] correlation between random effects
In-Reply-To: <b1c54b2ac85044a499dfed823d12c7b4@TLSDCPRIPEXMU05.inra.local>
References: <5e1a81d3edd04e9c9716da7166b07533@TLSDCPRIPEXMU05.inra.local>
 <CAJuCY5z5mfud3-if8YLQ_Zs9Lxr=OzHU9oY2tvjazKaCn8RjmA@mail.gmail.com>
 <e3a2a5b71ef54555a92876aa1803f501@TLSDCPRIPEXMU05.inra.local>
 <CAJuCY5zGnWGw4Ls_Tv8xG0bxspdj3B-qJ8MrTvXn6aQ_zsrCTA@mail.gmail.com>
 <d735ee9a169f43498ff56799a767ddf8@TLSDCPRIPEXMU05.inra.local>
 <CABghstTj2icDc0WirH-M4DzCxf7K2qGtQirqkP4fdqFxAKcjhA@mail.gmail.com>
 <CAJuCY5x2uGe+Szn1oDhE1RNhPSrs3HNi0hmvhtYNUEbNjtU4vQ@mail.gmail.com>
 <b1c54b2ac85044a499dfed823d12c7b4@TLSDCPRIPEXMU05.inra.local>
Message-ID: <CAJuCY5xXPCMCi2EekZu+7r9-php7t3U89y-FrCyUJ7Qcg2Uimw@mail.gmail.com>

Dear Jana,

Can you provide the data? Without the data we can only hypothesise on
what might be wrong. It will be a lot easier when we can look at the
data ourselves. It is OK to anonymize the data. Or send it privately.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
AND FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////




2018-02-15 13:48 GMT+01:00 Jana Dlouha <jana.dlouha at inra.fr>:
> Hi all again,
>
> Thanks to Thierry and Ben for their advices and sorry to answer so late, I was out of the lab yesterday.
>
> I looked at the 20 species with the most extreme random effects and unfortunately, it is not systematically the least represented species, one has 13 repetitions so I think it is not possible to exclude them based on the quantitative criterion. There are probably some measurement problems but not related specifically to some species or families so...is there any way to handle it? What did you mean by altering the model?
>
> Best regards
> Jana
>
>
> -----Message d'origine-----
> De : Thierry Onkelinx [mailto:thierry.onkelinx at inbo.be]
> Envoy? : mercredi 14 f?vrier 2018 09:47
> ? : Ben Bolker <bbolker at gmail.com>
> Cc : Jana Dlouha <jana.dlouha at inra.fr>; r-sig-mixed-models at r-project.org
> Objet : Re: [R-sig-ME] correlation between random effects
>
> I agree with Ben. Look at 20 species with the most extreme random effects. Plot those, one at a time. See what is happening for those and decide what would be a sensible way to deal with it. That could be to alter the model or to remove data which doesn't contain the information needed by the model. E.g. all species with less than x observations.
>
> ir. Thierry Onkelinx
> Statisticus / Statistician
>
> Vlaamse Overheid / Government of Flanders INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND FOREST Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance thierry.onkelinx at inbo.be Havenlaan 88 bus 73, 1000 Brussel www.inbo.be
>
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher The plural of anecdote is not data. ~ Roger Brinner The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey ///////////////////////////////////////////////////////////////////////////////////////////
>
>
>
>
> 2018-02-13 18:34 GMT+01:00 Ben Bolker <bbolker at gmail.com>:
>>   you can use as.data.frame(ranef(fitted_model)) to extract the random
>> effects as a data frame, then do anything you want to look at the most
>> extreme species ...
>>
>> On Tue, Feb 13, 2018 at 10:29 AM, Jana Dlouha <jana.dlouha at inra.fr> wrote:
>>> Dear Thierry,
>>>
>>> You are right, some species are represented only by one or two specimens, actually we did not want to use the mixed-effect models but the reviewers of our paper asked us to do that - but if I understand well from what you say, it is maybe not very smart considering the structure of our sample?
>>> I am struggling to know which species is behaving differently - is there any efficient method to visualize that? I have plotted the random effects using plot_model function but not able to change the y_axis in order to be able to read it, with 600 Species everything is overlapped...
>>> Thanks in advance
>>>
>>> Jana
>>>
>>> -----Message d'origine-----
>>> De : Thierry Onkelinx [mailto:thierry.onkelinx at inbo.be] Envoy? :
>>> mardi 13 f?vrier 2018 11:44 ? : Jana Dlouha <jana.dlouha at inra.fr> Cc
>>> : r-sig-mixed-models at r-project.org Objet : Re: [R-sig-ME] correlation
>>> between random effects
>>>
>>> Dear Jana,
>>>
>>> Please keep the mailing list in cc.
>>>
>>> I meant both centering and scaling.
>>>
>>> Based on the summary of the model, you have on average 3.7 observations per species, which is a bit small for a random slope model. What worries me is that the summary of the data indicates several species with > 20 observation. Hence you will have lot of species with only 1 or 2 observations. A species with only 2 observations, a small difference in dB1 and a large difference in MC will likely result in a large random slope for dB1. You'll need to investigate which species have a strong random slope and why. Most of the time that is obvious once you plotted the data for that species.
>>> Tip: plot the observations, the fitted values of the model and the predictions using only the fixed effects.
>>>
>>> Best regards,
>>>
>>> ir. Thierry Onkelinx
>>> Statisticus / Statistician
>>>
>>> Vlaamse Overheid / Government of Flanders INSTITUUT VOOR NATUUR- EN
>>> BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND FOREST Team
>>> Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
>>> thierry.onkelinx at inbo.be Havenlaan 88 bus 73, 1000 Brussel
>>> www.inbo.be
>>>
>>> /////////////////////////////////////////////////////////////////////
>>> ////////////////////// To call in the statistician after the
>>> experiment is done may be no more than asking him to perform a
>>> post-mortem examination: he may be able to say what the experiment
>>> died of. ~ Sir Ronald Aylmer Fisher The plural of anecdote is not
>>> data. ~ Roger Brinner The combination of some data and an aching
>>> desire for an answer does not ensure that a reasonable answer can be
>>> extracted from a given body of data. ~ John Tukey
>>> /////////////////////////////////////////////////////////////////////
>>> //////////////////////
>>>
>>>
>>>
>>>
>>> 2018-02-13 11:23 GMT+01:00 Jana Dlouha <jana.dlouha at inra.fr>:
>>>> Dear Thierry,
>>>>
>>>> Thanks a lot for your reply. Yes, I have used dB1c also in the random effect.
>>>> I have just tried to scale dB1 but I have still the same problem. However, it is possible that I am not doing things well, I am not a statistician and moreover I am just discovering R...
>>>> You say that I should provide more information so here is the summary of my data for the two columns I am using in this model:
>>>> Species         MCs             dB1
>>>> 327     :43     Min.    40.05   Min.    :1.050
>>>> 135     :35     1st Qu. 72.53   1st Qu. :1.400
>>>> 307     :24     Median  89.11   Median  :1.560
>>>> 146     :23     Mean    99.56   Mean    :1.671
>>>> 328     :23     3rd Qu. 116.23  3rd Qu. :1.840
>>>> 341     :22     Max.    351.49  Max.    :4.220
>>>> (Other):2051
>>>>
>>>> How I centered and scaled dB1:
>>>> dB1c<-scale(data$dB1,center=TRUE)
>>>> dB1s<-scale(data$dB1,center=FALSE, scale=TRUE)
>>>>
>>>> summary of the model without centering or scaling dB1:
>>>> Linear mixed model fit by maximum likelihood t-tests use Satterthwaite approximations to
>>>>   degrees of freedom [lmerMod]
>>>> Formula: MCs ~ dB1 + (1 + dB1 | Species)
>>>>    Data: data
>>>>
>>>>      AIC      BIC   logLik deviance df.resid
>>>>  10720.4  10754.7  -5354.2  10708.4     2215
>>>>
>>>> Scaled residuals:
>>>>     Min      1Q  Median      3Q     Max
>>>> -8.7305 -0.3491  0.0651  0.4508  6.6068
>>>>
>>>> Random effects:
>>>>  Groups   Name        Variance Std.Dev. Corr
>>>>  Species  (Intercept) 21.48    4.635
>>>>           dB1         11.25    3.355    -1.00
>>>>  Residual              6.19    2.488
>>>> Number of obs: 2221, groups:  Species, 598
>>>>
>>>> Fixed effects:
>>>>             Estimate Std. Error       df t value Pr(>|t|)
>>>> (Intercept) -64.2618     0.4249 273.4200  -151.2   <2e-16 ***
>>>> dB1          98.0060     0.2800 271.1900   350.0   <2e-16 ***
>>>> ---
>>>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>>>
>>>> Correlation of Fixed Effects:
>>>>     (Intr)
>>>> dB1 -0.987
>>>>
>>>> summary of the centered model m4c:
>>>>> summary(m4c)
>>>> Linear mixed model fit by maximum likelihood t-tests use Satterthwaite approximations to
>>>>   degrees of freedom [lmerMod]
>>>> Formula: MCs ~ dB1c + (1 + dB1c | Species)
>>>>    Data: data
>>>>
>>>>      AIC      BIC   logLik deviance df.resid
>>>>  10720.4  10754.7  -5354.2  10708.4     2215
>>>>
>>>> Scaled residuals:
>>>>     Min      1Q  Median      3Q     Max
>>>> -8.7305 -0.3491  0.0651  0.4508  6.6068
>>>>
>>>> Random effects:
>>>>  Groups   Name        Variance Std.Dev. Corr
>>>>  Species  (Intercept) 1.109    1.053
>>>>           dB1c        1.763    1.328    0.94
>>>>  Residual             6.190    2.488
>>>> Number of obs: 2221, groups:  Species, 598
>>>>
>>>> Fixed effects:
>>>>              Estimate Std. Error        df t value Pr(>|t|)
>>>> (Intercept)  99.54109    0.08466 290.67000    1176   <2e-16 ***
>>>> dB1c         38.78838    0.11081 271.18000     350   <2e-16 ***
>>>> ---
>>>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>>>
>>>> Correlation of Fixed Effects:
>>>>      (Intr)
>>>> dB1c 0.575
>>>>
>>>> and summary of the scaled model m4s:
>>>>> summary(m4s)
>>>> Linear mixed model fit by maximum likelihood t-tests use Satterthwaite approximations to
>>>>   degrees of freedom [lmerMod]
>>>> Formula: MCs ~ dB1s + (1 + dB1s | Species)
>>>>    Data: data
>>>>
>>>>      AIC      BIC   logLik deviance df.resid
>>>>  10720.4  10754.7  -5354.2  10708.4     2215
>>>>
>>>> Scaled residuals:
>>>>     Min      1Q  Median      3Q     Max
>>>> -8.7305 -0.3491  0.0651  0.4508  6.6068
>>>>
>>>> Random effects:
>>>>  Groups   Name        Variance Std.Dev. Corr
>>>>  Species  (Intercept) 21.48    4.635
>>>>           dB1s        33.22    5.763    -1.00
>>>>  Residual              6.19    2.488
>>>> Number of obs: 2221, groups:  Species, 598
>>>>
>>>> Fixed effects:
>>>>             Estimate Std. Error       df t value Pr(>|t|)
>>>> (Intercept) -64.2618     0.4249 273.4100  -151.2   <2e-16 ***
>>>> dB1s        168.3687     0.4810 271.1800   350.0   <2e-16 ***
>>>> ---
>>>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>>>
>>>> Correlation of Fixed Effects:
>>>>      (Intr)
>>>> dB1s -0.987
>>>>
>>>> Thanks in advance for your help!
>>>> Best regards
>>>> Jana
>>>>
>>>> -----Message d'origine-----
>>>> De : Thierry Onkelinx [mailto:thierry.onkelinx at inbo.be] Envoy? :
>>>> mardi
>>>> 13 f?vrier 2018 10:26 ? : Jana Dlouha <jana.dlouha at inra.fr> Cc :
>>>> r-sig-mixed-models at r-project.org Objet : Re: [R-sig-ME] correlation
>>>> between random effects
>>>>
>>>> Dear Jana,
>>>>
>>>> I assume that you uses the centered dB1c both in the random and the fixed effects? Another thing you can try is to scale dB1c. Using sensible units is often sufficient. Don't use large units (e.g.
>>>> kilometers) when you are measuring small things (e.g. millimeters).
>>>>
>>>> You'll need to provide more information when you need more feedback.
>>>> At least the summary of the data and the model.
>>>>
>>>> Best regards,
>>>>
>>>> ir. Thierry Onkelinx
>>>> Statisticus / Statistician
>>>>
>>>> Vlaamse Overheid / Government of Flanders INSTITUUT VOOR NATUUR- EN
>>>> BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND FOREST Team
>>>> Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
>>>> thierry.onkelinx at inbo.be Havenlaan 88 bus 73, 1000 Brussel
>>>> www.inbo.be
>>>>
>>>> ////////////////////////////////////////////////////////////////////
>>>> // ///////////////////// To call in the statistician after the
>>>> experiment is done may be no more than asking him to perform a
>>>> post-mortem
>>>> examination: he may be able to say what the experiment died of. ~
>>>> Sir Ronald Aylmer Fisher The plural of anecdote is not data. ~ Roger
>>>> Brinner The combination of some data and an aching desire for an
>>>> answer does not ensure that a reasonable answer can be extracted
>>>> from a given body of data. ~ John Tukey
>>>> ////////////////////////////////////////////////////////////////////
>>>> //
>>>> /////////////////////
>>>>
>>>>
>>>>
>>>>
>>>> 2018-02-13 10:00 GMT+01:00 Jana Dlouha <jana.dlouha at inra.fr>:
>>>>> Hi all,
>>>>>
>>>>> I have a problem with a correlation between random effects. I have tested several models on my data:
>>>>> m0<-lm(MCs~ dB1, data)
>>>>> m1<- lmer(MCs~ dB1 + (1|Species), data, REML=FALSE)
>>>>> m2 <- lmer(MCs~ dB1 + (-1+dB1|Species), data, REML=FALSE)
>>>>> m3<- lmer(MCs~ dB1 + (1|Species)+(0+dB1|Species), data, REML=FALSE)
>>>>> m4<- lmer(MCs ~ dB1 + (1+dB1 |Species), data,REML=FALSE)
>>>>>
>>>>> and when I compare the AIC criterion, the lowest one is for the model m4:
>>>>>      m0              m1           m2            m3            m4
>>>>> 11086.51 10948.72 10828.75 10830.75 10720.43
>>>>>
>>>>> However, in the summary I see that there is a strong correlation between random effects and associated variances are huge:
>>>>> Random effects:
>>>>> Groups   Name        Variance Std.Dev. Corr
>>>>>  Species  (Intercept) 21.48    4.635
>>>>>           dB1         11.25    3.355    -1.00
>>>>> Residual              6.19    2.488
>>>>> Number of obs: 2221, groups:  Species, 598
>>>>>
>>>>> For m3, random effect associated with  intercept has very low variance and residual variance is only  a bit higher:
>>>>> Random effects:
>>>>> Groups    Name        Variance  Std.Dev.
>>>>>  Species   (Intercept) 3.419e-14 1.849e-07
>>>>> Species.1 dB1         7.968e-01 8.927e-01
>>>>> Residual              6.327e+00 2.515e+00
>>>>> Number of obs: 2221, groups:  Species, 598
>>>>>
>>>>> I am tempted to take into account only the randon effect associated with the slope however I don't know if i can do this considering that the AIC is not the lowest one for this model and how to justify it in my paper?
>>>>> By the way, I don't really understand why the variances associated with the random effects change so much.
>>>>> I have tried to center the regressor dB1 which removed the correlation between fixed effects and changed the sign of correlation but random effects remain strongly correlated and variances large:
>>>>>
>>>>> Random effects:
>>>>> Groups   Name        Variance Std.Dev. Corr
>>>>> Species  (Intercept)  1.109   1.053
>>>>>           dB1c        11.255   3.355    0.94
>>>>> Residual              6.190   2.488
>>>>> Number of obs: 2221, groups:  Species, 598
>>>>>
>>>>> Could you please give me some hint to solve my problem? Thanks a
>>>>> lot in advance
>>>>>
>>>>> Jana
>>>>>
>>>>>
>>>>>
>>>>>         [[alternative HTML version deleted]]
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From inh4 at cdc.gov  Thu Feb 15 16:56:59 2018
From: inh4 at cdc.gov (Bertke, Stephen (CDC/NIOSH/DSHEFS))
Date: Thu, 15 Feb 2018 15:56:59 +0000
Subject: [R-sig-ME] Mixed Models in SAS and R
References: <f1d15f0590834749893b287bb5063489@cdc.gov>
 <CAJuCY5xAZ-tdBJEKQ3mcapX7k+U1FpTUA=7NU199udOyy0km-g@mail.gmail.com> 
Message-ID: <dee7ea0144f44c368d860229d8557aa7@cdc.gov>

Sorry for all the emails, but I have edited/simplified my question to what I believe is the root issue as well as posted simulated data to test with:

https://stats.stackexchange.com/questions/328712/lmer-vs-proc-mixed-output



-----Original Message-----
From: Bertke, Stephen (CDC/NIOSH/DSHEFS) 
Sent: Wednesday, February 14, 2018 2:25 PM
To: 'Thierry Onkelinx' <thierry.onkelinx at inbo.be>
Cc: r-sig-mixed-models at r-project.org
Subject: RE: [R-sig-ME] Mixed Models in SAS and R

I posted the question on stackoverflow here:
https://stackoverflow.com/questions/48794651/lmer-vs-proc-mixed-output

This will hopefully make reading my code and output easier. 

I would expect a 0 variance since I am in essence fitting a model with both the site variable in the fixed and random part of the model. I actually went ahead and fit that "dumb" model in both SAS and R and once again, all results are nearly identical except SAS estimates a 0 variance and R estimates a relatively large positive variance. However, R now gives an error/warning at the bottom of the results indicating an issue with this very dumb model. Again, those results are in the above link. 




-----Original Message-----
From: Thierry Onkelinx [mailto:thierry.onkelinx at inbo.be]
Sent: Wednesday, February 14, 2018 11:39 AM
To: Bertke, Stephen (CDC/NIOSH/DSHEFS) <inh4 at cdc.gov>
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Mixed Models in SAS and R

Dear Stephen,

The list removes all HTML formating, making your post hard to read.
Please use only plain text when posting.

You'll need to make sure that you fit exactly the same model in SAS as in R. Not everyone here speaks SAS. Providing the math equation for the SAS model would help.

Also please elaborate why it makes sense that the variance of site should be zero. We cannot verify that statement based on the information you provide.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND FOREST Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance thierry.onkelinx at inbo.be Havenlaan 88 bus 73, 1000 Brussel www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher The plural of anecdote is not data. ~ Roger Brinner The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey ///////////////////////////////////////////////////////////////////////////////////////////




2018-02-14 17:07 GMT+01:00 Bertke, Stephen (CDC/NIOSH/DSHEFS) <inh4 at cdc.gov>:
> Hello everyone. I have just joined this mailing list so I wanted to introduce myself as well as ask a question.
>
> My name is Steve Bertke and I am a researcher at the National Institute for Occupational Safety and Health (NIOSH) which is one of the centers within the Centers for Disease Control and Prevention (CDC). I am a long-time SAS user but have been slowly finding myself using and liking R. I have found the support community for R very helpful and rewarding and am looking forward to contributing my part.
>
> On to my question.
>
> I have ran the same model (I think) in both SAS (proc mixed) and R (lmer) but have gotten different results for the random terms.
>
> A quick background, we took 2 personal air samples for 127 people at 15 different factories for a total of 252 samples (after dropping 2 samples). We are trying to model various factors of the factory on the air samples. To do so, we need to control for the repeated measure of the person (nested within factory) as well as the random factory effect.
>
> You can see below for the exact code and exact results, but in short, when I run the models in R and SAS without any fixed effects, I get the same results for the random effects. When I enter in the fixed effects, I get a different result for the Site variance...but all other results are the same (both the fixed effects and the other random effects).
>
> There is another methodological issue with the model I am running. I am entering in 17 fixed effects that describe the 15 sites. Therefore, the model is over-specified. As a result, SAS gives a variance estimate of 0 for site (which, in hindsight, makes sense) however, R does not. That is a separate issue that we are dealing with, but I would expect that R and SAS would give the same result. Or maybe at least a warning.
>
> Below is my code and output. I hope the formatting remains so that it is easily readable for everyone. I may also be able to share the data too, but I need to get some approval for that first.
>
> Details
> I ran the following code in SAS and R without any fixed effects and both give the same results:
>
> proc mixed data=dat;
> class NewSiteID NIOSHID;
> model ln_i = ;
> random NewSiteID NIOSHID(NewSiteID);
> run;
>
> Covariance Parameter Estimates
>
> Cov Parm
>
> Estimate
>
> NewSiteID
>
> 6.3433
>
> NIOSHID(NewSiteID)
>
> 0.7465
>
> Residual
>
> 2.5256
>
>
> mixedidsite <- lmer(ln_i ~ (1 | NewSiteID/NIOSHID),
>                     data = Modeling_Database_Final)
> summary(mixedidsite)
>
> Random effects:
> Groups                              Name        Variance Std.Dev.
> NIOSHID:NewSiteID       (Intercept) 0.7465   0.864
>  NewSiteID                        (Intercept) 6.3434   2.519
>  Residual                                                 2.5256   1.589
>
> However, when I add in the fixed effects, I get different results. SAS gives an estimate of 0 for Site while R does not. All other results are the same:
>
> proc mixed data=dat;
> class NewSiteID NIOSHID F_mass_handled_or (ref=first); model ln_i = 
> F_High_Exp F_Mat_Type_SW F_Mat_Type_CNF F_Mat_Form_Dry F_Mat_Form_Liq 
> F_Mat_Form_Comp F_Hybrid F_Primary F_Coatings F_mass_handled_or 
> F_adequate F_inadequate F_emp_sc F_diam_sc/solution; random NewSiteID 
> NIOSHID(NewSiteID); run;
>
> Covariance Parameter Estimates
>
> Cov Parm
>
> Estimate
>
> NewSiteID
>
> 0
>
> NIOSHID(NewSiteID)
>
> 0.6954
>
> Residual
>
> 2.5372
>
>
> Fit Statistics
>
> -2 Res Log Likelihood
>
> 961.8
>
> AIC (Smaller is Better)
>
> 965.8
>
> AICC (Smaller is Better)
>
> 965.9
>
> BIC (Smaller is Better)
>
> 967.3
>
>
> Solution for Fixed Effects
>
> Effect
>
> F_mass_handled_or
>
> Estimate
>
> Standard
> Error
>
> DF
>
> t Value
>
> Pr > |t|
>
> Intercept
>
>
>
> -139.29
>
> 83.6162
>
> 92.1
>
> -1.67
>
> 0.0991
>
> F_High_Exp
>
>
>
> -180.24
>
> 102.72
>
> 92.6
>
> -1.75
>
> 0.0826
>
> F_Mat_Type_SW
>
>
>
> 470.30
>
> 261.53
>
> 92.1
>
> 1.80
>
> 0.0754
>
> F_Mat_Type_CNF
>
>
>
> -636.35
>
> 347.99
>
> 92.1
>
> -1.83
>
> 0.0707
>
> F_Mat_Form_Dry
>
>
>
> 662.26
>
> 368.75
>
> 92
>
> 1.80
>
> 0.0758
>
> F_Mat_Form_Liq
>
>
>
> -583.14
>
> 318.54
>
> 92
>
> -1.83
>
> 0.0704
>
> F_Mat_Form_Comp
>
>
>
> 598.77
>
> 331.85
>
> 92
>
> 1.80
>
> 0.0745
>
> F_Hybrid
>
>
>
> -1197.69
>
> 658.23
>
> 92
>
> -1.82
>
> 0.0721
>
> F_Primary
>
>
>
> -639.93
>
> 352.80
>
> 92
>
> -1.81
>
> 0.0730
>
> F_Coatings
>
>
>
> 92.7949
>
> 50.7416
>
> 92.1
>
> 1.83
>
> 0.0707
>
> F_mass_handled_or
>
> F2
>
> 134.91
>
> 77.2496
>
> 92
>
> 1.75
>
> 0.0841
>
> F_mass_handled_or
>
> F3
>
> -1235.37
>
> 677.42
>
> 92
>
> -1.82
>
> 0.0715
>
> F_mass_handled_or
>
> F4
>
> 137.71
>
> 75.9370
>
> 92
>
> 1.81
>
> 0.0730
>
> F_mass_handled_or
>
> F1
>
> 0
>
> .
>
> .
>
> .
>
> .
>
> F_adequate
>
>
>
> 139.45
>
> 76.5607
>
> 92
>
> 1.82
>
> 0.0718
>
> F_inadequate
>
>
>
> 1395.04
>
> 767.40
>
> 92
>
> 1.82
>
> 0.0723
>
> F_emp_sc
>
>
>
> -1259.21
>
> 691.98
>
> 92
>
> -1.82
>
> 0.0721
>
> F_diam_sc
>
>
>
> -20.1875
>
> 9.9710
>
> 89.5
>
> -2.02
>
> 0.0459
>
>
> mixedidsite <- lmer(ln_i ~ (1 | NewSiteID/NIOSHID)  + F_High_Exp + F_Mat_Type_SW +
>                       F_Mat_Type_CNF + F_Mat_Form_Dry + F_Mat_Form_Liq + F_Mat_Form_Comp +
>                       F_Hybrid + F_Primary + F_Coatings + F_adequate +
>                       F_inadequate + F_emp_sc + F_diam_sc,
>                     data = Modeling_Database_Final)
> summary(mixedidsite)
>
> REML criterion at convergence: 961.8
>
> Scaled residuals:
>     Min      1Q  Median      3Q     Max
> -2.3019 -0.5248 -0.1668  0.3511  4.7091
>
> Random effects:
> Groups                              Name        Variance Std.Dev.
> NIOSHID:NewSiteID       (Intercept) 0.6954   0.8339
>  NewSiteID                        (Intercept) 1.5932   1.2622
>  Residual                                                2.5372   1.5929
> Number of obs: 252, groups:  NIOSHID:NewSiteID, 127; NewSiteID, 15
>
> Fixed effects:
>                                                            Estimate Std. Error t value
> (Intercept)                                       -139.292     83.702  -1.664
> F_High_Exp                                      -180.239    102.778  -1.754
> F_Mat_Type_SW                            470.297    261.537   1.798
> F_Mat_Type_CNF                           -636.352    347.993  -1.829
> F_Mat_Form_Dry                            662.263    368.761   1.796
> F_Mat_Form_Liq                            -583.142    318.541  -1.831
> F_Mat_Form_Comp                       598.774    331.856   1.804
> F_Hybrid                                           -1197.691    658.229  -1.820
> F_Primary                                        -639.928    352.811  -1.814
> F_Coatings                                       92.795     50.804   1.826
> F_mass_handled_orF2: 10 -         134.912     77.291   1.746
> F_mass_handled_orF3: 101         -1235.372    677.423  -1.824
> F_mass_handled_orF4: >1 k        137.714     75.958   1.813
> F_adequate                                     139.446     76.582   1.821
> F_inadequate                                  1395.036    767.413   1.818
> F_emp_sc                                         -1259.213    691.979  -1.820
> F_diam_sc                                        -20.188      9.971  -2.025
>
> Again, the SAS results make sense...that there is 0 variance left over from the fully specified fixed effects. I am fairly certain the combination of the fixed effects uniquely identifies each facility. However, why doesn't R give a 0 variance? What is different between the two methods?
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

From dakotajudo at mac.com  Thu Feb 15 17:15:06 2018
From: dakotajudo at mac.com (Peter Claussen)
Date: Thu, 15 Feb 2018 10:15:06 -0600
Subject: [R-sig-ME] Mixed Models in SAS and R
In-Reply-To: <dee7ea0144f44c368d860229d8557aa7@cdc.gov>
References: <f1d15f0590834749893b287bb5063489@cdc.gov>
 <CAJuCY5xAZ-tdBJEKQ3mcapX7k+U1FpTUA=7NU199udOyy0km-g@mail.gmail.com>
 <dee7ea0144f44c368d860229d8557aa7@cdc.gov>
Message-ID: <19AD1067-DC95-41F3-8533-1DAAA5038329@mac.com>

I posted a response on stackexchange; I don?t think this is an R specific issue - SAS reports the same problem for your test data.

R is reporting a "degenerate Hessian with 1 negative eigenvalue", SAS reports that "final Hessian is not positive definite? - by definition, a positive definite matrix is a symmetric matrix with all positive eigenvalues.

Cheers,


> On Feb 15, 2018, at 9:56 AM, Bertke, Stephen (CDC/NIOSH/DSHEFS) <inh4 at cdc.gov> wrote:
> 
> Sorry for all the emails, but I have edited/simplified my question to what I believe is the root issue as well as posted simulated data to test with:
> 
> https://stats.stackexchange.com/questions/328712/lmer-vs-proc-mixed-output
> 
> 
> 
> -----Original Message-----
> From: Bertke, Stephen (CDC/NIOSH/DSHEFS) 
> Sent: Wednesday, February 14, 2018 2:25 PM
> To: 'Thierry Onkelinx' <thierry.onkelinx at inbo.be>
> Cc: r-sig-mixed-models at r-project.org
> Subject: RE: [R-sig-ME] Mixed Models in SAS and R
> 
> I posted the question on stackoverflow here:
> https://stackoverflow.com/questions/48794651/lmer-vs-proc-mixed-output
> 
> This will hopefully make reading my code and output easier. 
> 
> I would expect a 0 variance since I am in essence fitting a model with both the site variable in the fixed and random part of the model. I actually went ahead and fit that "dumb" model in both SAS and R and once again, all results are nearly identical except SAS estimates a 0 variance and R estimates a relatively large positive variance. However, R now gives an error/warning at the bottom of the results indicating an issue with this very dumb model. Again, those results are in the above link. 
> 
> 
> 
> 
> -----Original Message-----
> From: Thierry Onkelinx [mailto:thierry.onkelinx at inbo.be]
> Sent: Wednesday, February 14, 2018 11:39 AM
> To: Bertke, Stephen (CDC/NIOSH/DSHEFS) <inh4 at cdc.gov>
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Mixed Models in SAS and R
> 
> Dear Stephen,
> 
> The list removes all HTML formating, making your post hard to read.
> Please use only plain text when posting.
> 
> You'll need to make sure that you fit exactly the same model in SAS as in R. Not everyone here speaks SAS. Providing the math equation for the SAS model would help.
> 
> Also please elaborate why it makes sense that the variance of site should be zero. We cannot verify that statement based on the information you provide.
> 
> Best regards,
> 
> ir. Thierry Onkelinx
> Statisticus / Statistician
> 
> Vlaamse Overheid / Government of Flanders INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND FOREST Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance thierry.onkelinx at inbo.be Havenlaan 88 bus 73, 1000 Brussel www.inbo.be
> 
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher The plural of anecdote is not data. ~ Roger Brinner The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey ///////////////////////////////////////////////////////////////////////////////////////////
> 
> 
> 
> 
> 2018-02-14 17:07 GMT+01:00 Bertke, Stephen (CDC/NIOSH/DSHEFS) <inh4 at cdc.gov>:
>> Hello everyone. I have just joined this mailing list so I wanted to introduce myself as well as ask a question.
>> 
>> My name is Steve Bertke and I am a researcher at the National Institute for Occupational Safety and Health (NIOSH) which is one of the centers within the Centers for Disease Control and Prevention (CDC). I am a long-time SAS user but have been slowly finding myself using and liking R. I have found the support community for R very helpful and rewarding and am looking forward to contributing my part.
>> 
>> On to my question.
>> 
>> I have ran the same model (I think) in both SAS (proc mixed) and R (lmer) but have gotten different results for the random terms.
>> 
>> A quick background, we took 2 personal air samples for 127 people at 15 different factories for a total of 252 samples (after dropping 2 samples). We are trying to model various factors of the factory on the air samples. To do so, we need to control for the repeated measure of the person (nested within factory) as well as the random factory effect.
>> 
>> You can see below for the exact code and exact results, but in short, when I run the models in R and SAS without any fixed effects, I get the same results for the random effects. When I enter in the fixed effects, I get a different result for the Site variance...but all other results are the same (both the fixed effects and the other random effects).
>> 
>> There is another methodological issue with the model I am running. I am entering in 17 fixed effects that describe the 15 sites. Therefore, the model is over-specified. As a result, SAS gives a variance estimate of 0 for site (which, in hindsight, makes sense) however, R does not. That is a separate issue that we are dealing with, but I would expect that R and SAS would give the same result. Or maybe at least a warning.
>> 
>> Below is my code and output. I hope the formatting remains so that it is easily readable for everyone. I may also be able to share the data too, but I need to get some approval for that first.
>> 
>> Details
>> I ran the following code in SAS and R without any fixed effects and both give the same results:
>> 
>> proc mixed data=dat;
>> class NewSiteID NIOSHID;
>> model ln_i = ;
>> random NewSiteID NIOSHID(NewSiteID);
>> run;
>> 
>> Covariance Parameter Estimates
>> 
>> Cov Parm
>> 
>> Estimate
>> 
>> NewSiteID
>> 
>> 6.3433
>> 
>> NIOSHID(NewSiteID)
>> 
>> 0.7465
>> 
>> Residual
>> 
>> 2.5256
>> 
>> 
>> mixedidsite <- lmer(ln_i ~ (1 | NewSiteID/NIOSHID),
>>                    data = Modeling_Database_Final)
>> summary(mixedidsite)
>> 
>> Random effects:
>> Groups                              Name        Variance Std.Dev.
>> NIOSHID:NewSiteID       (Intercept) 0.7465   0.864
>> NewSiteID                        (Intercept) 6.3434   2.519
>> Residual                                                 2.5256   1.589
>> 
>> However, when I add in the fixed effects, I get different results. SAS gives an estimate of 0 for Site while R does not. All other results are the same:
>> 
>> proc mixed data=dat;
>> class NewSiteID NIOSHID F_mass_handled_or (ref=first); model ln_i =
>> F_High_Exp F_Mat_Type_SW F_Mat_Type_CNF F_Mat_Form_Dry F_Mat_Form_Liq 
>> F_Mat_Form_Comp F_Hybrid F_Primary F_Coatings F_mass_handled_or 
>> F_adequate F_inadequate F_emp_sc F_diam_sc/solution; random NewSiteID 
>> NIOSHID(NewSiteID); run;
>> 
>> Covariance Parameter Estimates
>> 
>> Cov Parm
>> 
>> Estimate
>> 
>> NewSiteID
>> 
>> 0
>> 
>> NIOSHID(NewSiteID)
>> 
>> 0.6954
>> 
>> Residual
>> 
>> 2.5372
>> 
>> 
>> Fit Statistics
>> 
>> -2 Res Log Likelihood
>> 
>> 961.8
>> 
>> AIC (Smaller is Better)
>> 
>> 965.8
>> 
>> AICC (Smaller is Better)
>> 
>> 965.9
>> 
>> BIC (Smaller is Better)
>> 
>> 967.3
>> 
>> 
>> Solution for Fixed Effects
>> 
>> Effect
>> 
>> F_mass_handled_or
>> 
>> Estimate
>> 
>> Standard
>> Error
>> 
>> DF
>> 
>> t Value
>> 
>> Pr > |t|
>> 
>> Intercept
>> 
>> 
>> 
>> -139.29
>> 
>> 83.6162
>> 
>> 92.1
>> 
>> -1.67
>> 
>> 0.0991
>> 
>> F_High_Exp
>> 
>> 
>> 
>> -180.24
>> 
>> 102.72
>> 
>> 92.6
>> 
>> -1.75
>> 
>> 0.0826
>> 
>> F_Mat_Type_SW
>> 
>> 
>> 
>> 470.30
>> 
>> 261.53
>> 
>> 92.1
>> 
>> 1.80
>> 
>> 0.0754
>> 
>> F_Mat_Type_CNF
>> 
>> 
>> 
>> -636.35
>> 
>> 347.99
>> 
>> 92.1
>> 
>> -1.83
>> 
>> 0.0707
>> 
>> F_Mat_Form_Dry
>> 
>> 
>> 
>> 662.26
>> 
>> 368.75
>> 
>> 92
>> 
>> 1.80
>> 
>> 0.0758
>> 
>> F_Mat_Form_Liq
>> 
>> 
>> 
>> -583.14
>> 
>> 318.54
>> 
>> 92
>> 
>> -1.83
>> 
>> 0.0704
>> 
>> F_Mat_Form_Comp
>> 
>> 
>> 
>> 598.77
>> 
>> 331.85
>> 
>> 92
>> 
>> 1.80
>> 
>> 0.0745
>> 
>> F_Hybrid
>> 
>> 
>> 
>> -1197.69
>> 
>> 658.23
>> 
>> 92
>> 
>> -1.82
>> 
>> 0.0721
>> 
>> F_Primary
>> 
>> 
>> 
>> -639.93
>> 
>> 352.80
>> 
>> 92
>> 
>> -1.81
>> 
>> 0.0730
>> 
>> F_Coatings
>> 
>> 
>> 
>> 92.7949
>> 
>> 50.7416
>> 
>> 92.1
>> 
>> 1.83
>> 
>> 0.0707
>> 
>> F_mass_handled_or
>> 
>> F2
>> 
>> 134.91
>> 
>> 77.2496
>> 
>> 92
>> 
>> 1.75
>> 
>> 0.0841
>> 
>> F_mass_handled_or
>> 
>> F3
>> 
>> -1235.37
>> 
>> 677.42
>> 
>> 92
>> 
>> -1.82
>> 
>> 0.0715
>> 
>> F_mass_handled_or
>> 
>> F4
>> 
>> 137.71
>> 
>> 75.9370
>> 
>> 92
>> 
>> 1.81
>> 
>> 0.0730
>> 
>> F_mass_handled_or
>> 
>> F1
>> 
>> 0
>> 
>> .
>> 
>> .
>> 
>> .
>> 
>> .
>> 
>> F_adequate
>> 
>> 
>> 
>> 139.45
>> 
>> 76.5607
>> 
>> 92
>> 
>> 1.82
>> 
>> 0.0718
>> 
>> F_inadequate
>> 
>> 
>> 
>> 1395.04
>> 
>> 767.40
>> 
>> 92
>> 
>> 1.82
>> 
>> 0.0723
>> 
>> F_emp_sc
>> 
>> 
>> 
>> -1259.21
>> 
>> 691.98
>> 
>> 92
>> 
>> -1.82
>> 
>> 0.0721
>> 
>> F_diam_sc
>> 
>> 
>> 
>> -20.1875
>> 
>> 9.9710
>> 
>> 89.5
>> 
>> -2.02
>> 
>> 0.0459
>> 
>> 
>> mixedidsite <- lmer(ln_i ~ (1 | NewSiteID/NIOSHID)  + F_High_Exp + F_Mat_Type_SW +
>>                      F_Mat_Type_CNF + F_Mat_Form_Dry + F_Mat_Form_Liq + F_Mat_Form_Comp +
>>                      F_Hybrid + F_Primary + F_Coatings + F_adequate +
>>                      F_inadequate + F_emp_sc + F_diam_sc,
>>                    data = Modeling_Database_Final)
>> summary(mixedidsite)
>> 
>> REML criterion at convergence: 961.8
>> 
>> Scaled residuals:
>>    Min      1Q  Median      3Q     Max
>> -2.3019 -0.5248 -0.1668  0.3511  4.7091
>> 
>> Random effects:
>> Groups                              Name        Variance Std.Dev.
>> NIOSHID:NewSiteID       (Intercept) 0.6954   0.8339
>> NewSiteID                        (Intercept) 1.5932   1.2622
>> Residual                                                2.5372   1.5929
>> Number of obs: 252, groups:  NIOSHID:NewSiteID, 127; NewSiteID, 15
>> 
>> Fixed effects:
>>                                                           Estimate Std. Error t value
>> (Intercept)                                       -139.292     83.702  -1.664
>> F_High_Exp                                      -180.239    102.778  -1.754
>> F_Mat_Type_SW                            470.297    261.537   1.798
>> F_Mat_Type_CNF                           -636.352    347.993  -1.829
>> F_Mat_Form_Dry                            662.263    368.761   1.796
>> F_Mat_Form_Liq                            -583.142    318.541  -1.831
>> F_Mat_Form_Comp                       598.774    331.856   1.804
>> F_Hybrid                                           -1197.691    658.229  -1.820
>> F_Primary                                        -639.928    352.811  -1.814
>> F_Coatings                                       92.795     50.804   1.826
>> F_mass_handled_orF2: 10 -         134.912     77.291   1.746
>> F_mass_handled_orF3: 101         -1235.372    677.423  -1.824
>> F_mass_handled_orF4: >1 k        137.714     75.958   1.813
>> F_adequate                                     139.446     76.582   1.821
>> F_inadequate                                  1395.036    767.413   1.818
>> F_emp_sc                                         -1259.213    691.979  -1.820
>> F_diam_sc                                        -20.188      9.971  -2.025
>> 
>> Again, the SAS results make sense...that there is 0 variance left over from the fully specified fixed effects. I am fairly certain the combination of the fixed effects uniquely identifies each facility. However, why doesn't R give a 0 variance? What is different between the two methods?
>> 
>> 
>>        [[alternative HTML version deleted]]
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list 
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


	[[alternative HTML version deleted]]


From inh4 at cdc.gov  Thu Feb 15 17:46:11 2018
From: inh4 at cdc.gov (Bertke, Stephen (CDC/NIOSH/DSHEFS))
Date: Thu, 15 Feb 2018 16:46:11 +0000
Subject: [R-sig-ME] Mixed Models in SAS and R
In-Reply-To: <19AD1067-DC95-41F3-8533-1DAAA5038329@mac.com>
References: <f1d15f0590834749893b287bb5063489@cdc.gov>
 <CAJuCY5xAZ-tdBJEKQ3mcapX7k+U1FpTUA=7NU199udOyy0km-g@mail.gmail.com>
 <dee7ea0144f44c368d860229d8557aa7@cdc.gov>
 <19AD1067-DC95-41F3-8533-1DAAA5038329@mac.com>
Message-ID: <f525db1427114cec89448ff5f586c2ef@cdc.gov>

I do not see any errors in R. What I posted is the entire output from running summary(). Is there something else I should be asking for?

From: Peter Claussen [mailto:dakotajudo at mac.com]
Sent: Thursday, February 15, 2018 11:15 AM
To: Bertke, Stephen (CDC/NIOSH/DSHEFS) <inh4 at cdc.gov>
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Mixed Models in SAS and R

I posted a response on stackexchange; I don?t think this is an R specific issue - SAS reports the same problem for your test data.

R is reporting a "degenerate Hessian with 1 negative eigenvalue", SAS reports that "final Hessian is not positive definite? - by definition, a positive definite matrix is a symmetric matrix with all positive eigenvalues.

Cheers,



On Feb 15, 2018, at 9:56 AM, Bertke, Stephen (CDC/NIOSH/DSHEFS) <inh4 at cdc.gov<mailto:inh4 at cdc.gov>> wrote:

Sorry for all the emails, but I have edited/simplified my question to what I believe is the root issue as well as posted simulated data to test with:

https://stats.stackexchange.com/questions/328712/lmer-vs-proc-mixed-output



-----Original Message-----
From: Bertke, Stephen (CDC/NIOSH/DSHEFS)
Sent: Wednesday, February 14, 2018 2:25 PM
To: 'Thierry Onkelinx' <thierry.onkelinx at inbo.be<mailto:thierry.onkelinx at inbo.be>>
Cc: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
Subject: RE: [R-sig-ME] Mixed Models in SAS and R

I posted the question on stackoverflow here:
https://stackoverflow.com/questions/48794651/lmer-vs-proc-mixed-output

This will hopefully make reading my code and output easier.

I would expect a 0 variance since I am in essence fitting a model with both the site variable in the fixed and random part of the model. I actually went ahead and fit that "dumb" model in both SAS and R and once again, all results are nearly identical except SAS estimates a 0 variance and R estimates a relatively large positive variance. However, R now gives an error/warning at the bottom of the results indicating an issue with this very dumb model. Again, those results are in the above link.




-----Original Message-----
From: Thierry Onkelinx [mailto:thierry.onkelinx at inbo.be]
Sent: Wednesday, February 14, 2018 11:39 AM
To: Bertke, Stephen (CDC/NIOSH/DSHEFS) <inh4 at cdc.gov<mailto:inh4 at cdc.gov>>
Cc: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] Mixed Models in SAS and R

Dear Stephen,

The list removes all HTML formating, making your post hard to read.
Please use only plain text when posting.

You'll need to make sure that you fit exactly the same model in SAS as in R. Not everyone here speaks SAS. Providing the math equation for the SAS model would help.

Also please elaborate why it makes sense that the variance of site should be zero. We cannot verify that statement based on the information you provide.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND FOREST Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance thierry.onkelinx at inbo.be<mailto:thierry.onkelinx at inbo.be> Havenlaan 88 bus 73, 1000 Brussel www.inbo.be<http://www.inbo.be>

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher The plural of anecdote is not data. ~ Roger Brinner The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey ///////////////////////////////////////////////////////////////////////////////////////////




2018-02-14 17:07 GMT+01:00 Bertke, Stephen (CDC/NIOSH/DSHEFS) <inh4 at cdc.gov<mailto:inh4 at cdc.gov>>:

Hello everyone. I have just joined this mailing list so I wanted to introduce myself as well as ask a question.

My name is Steve Bertke and I am a researcher at the National Institute for Occupational Safety and Health (NIOSH) which is one of the centers within the Centers for Disease Control and Prevention (CDC). I am a long-time SAS user but have been slowly finding myself using and liking R. I have found the support community for R very helpful and rewarding and am looking forward to contributing my part.

On to my question.

I have ran the same model (I think) in both SAS (proc mixed) and R (lmer) but have gotten different results for the random terms.

A quick background, we took 2 personal air samples for 127 people at 15 different factories for a total of 252 samples (after dropping 2 samples). We are trying to model various factors of the factory on the air samples. To do so, we need to control for the repeated measure of the person (nested within factory) as well as the random factory effect.

You can see below for the exact code and exact results, but in short, when I run the models in R and SAS without any fixed effects, I get the same results for the random effects. When I enter in the fixed effects, I get a different result for the Site variance...but all other results are the same (both the fixed effects and the other random effects).

There is another methodological issue with the model I am running. I am entering in 17 fixed effects that describe the 15 sites. Therefore, the model is over-specified. As a result, SAS gives a variance estimate of 0 for site (which, in hindsight, makes sense) however, R does not. That is a separate issue that we are dealing with, but I would expect that R and SAS would give the same result. Or maybe at least a warning.

Below is my code and output. I hope the formatting remains so that it is easily readable for everyone. I may also be able to share the data too, but I need to get some approval for that first.

Details
I ran the following code in SAS and R without any fixed effects and both give the same results:

proc mixed data=dat;
class NewSiteID NIOSHID;
model ln_i = ;
random NewSiteID NIOSHID(NewSiteID);
run;

Covariance Parameter Estimates

Cov Parm

Estimate

NewSiteID

6.3433

NIOSHID(NewSiteID)

0.7465

Residual

2.5256


mixedidsite <- lmer(ln_i ~ (1 | NewSiteID/NIOSHID),
                   data = Modeling_Database_Final)
summary(mixedidsite)

Random effects:
Groups                              Name        Variance Std.Dev.
NIOSHID:NewSiteID       (Intercept) 0.7465   0.864
NewSiteID                        (Intercept) 6.3434   2.519
Residual                                                 2.5256   1.589

However, when I add in the fixed effects, I get different results. SAS gives an estimate of 0 for Site while R does not. All other results are the same:

proc mixed data=dat;
class NewSiteID NIOSHID F_mass_handled_or (ref=first); model ln_i =
F_High_Exp F_Mat_Type_SW F_Mat_Type_CNF F_Mat_Form_Dry F_Mat_Form_Liq
F_Mat_Form_Comp F_Hybrid F_Primary F_Coatings F_mass_handled_or
F_adequate F_inadequate F_emp_sc F_diam_sc/solution; random NewSiteID
NIOSHID(NewSiteID); run;

Covariance Parameter Estimates

Cov Parm

Estimate

NewSiteID

0

NIOSHID(NewSiteID)

0.6954

Residual

2.5372


Fit Statistics

-2 Res Log Likelihood

961.8

AIC (Smaller is Better)

965.8

AICC (Smaller is Better)

965.9

BIC (Smaller is Better)

967.3


Solution for Fixed Effects

Effect

F_mass_handled_or

Estimate

Standard
Error

DF

t Value

Pr > |t|

Intercept



-139.29

83.6162

92.1

-1.67

0.0991

F_High_Exp



-180.24

102.72

92.6

-1.75

0.0826

F_Mat_Type_SW



470.30

261.53

92.1

1.80

0.0754

F_Mat_Type_CNF



-636.35

347.99

92.1

-1.83

0.0707

F_Mat_Form_Dry



662.26

368.75

92

1.80

0.0758

F_Mat_Form_Liq



-583.14

318.54

92

-1.83

0.0704

F_Mat_Form_Comp



598.77

331.85

92

1.80

0.0745

F_Hybrid



-1197.69

658.23

92

-1.82

0.0721

F_Primary



-639.93

352.80

92

-1.81

0.0730

F_Coatings



92.7949

50.7416

92.1

1.83

0.0707

F_mass_handled_or

F2

134.91

77.2496

92

1.75

0.0841

F_mass_handled_or

F3

-1235.37

677.42

92

-1.82

0.0715

F_mass_handled_or

F4

137.71

75.9370

92

1.81

0.0730

F_mass_handled_or

F1

0

.

.

.

.

F_adequate



139.45

76.5607

92

1.82

0.0718

F_inadequate



1395.04

767.40

92

1.82

0.0723

F_emp_sc



-1259.21

691.98

92

-1.82

0.0721

F_diam_sc



-20.1875

9.9710

89.5

-2.02

0.0459


mixedidsite <- lmer(ln_i ~ (1 | NewSiteID/NIOSHID)  + F_High_Exp + F_Mat_Type_SW +
                     F_Mat_Type_CNF + F_Mat_Form_Dry + F_Mat_Form_Liq + F_Mat_Form_Comp +
                     F_Hybrid + F_Primary + F_Coatings + F_adequate +
                     F_inadequate + F_emp_sc + F_diam_sc,
                   data = Modeling_Database_Final)
summary(mixedidsite)

REML criterion at convergence: 961.8

Scaled residuals:
   Min      1Q  Median      3Q     Max
-2.3019 -0.5248 -0.1668  0.3511  4.7091

Random effects:
Groups                              Name        Variance Std.Dev.
NIOSHID:NewSiteID       (Intercept) 0.6954   0.8339
NewSiteID                        (Intercept) 1.5932   1.2622
Residual                                                2.5372   1.5929
Number of obs: 252, groups:  NIOSHID:NewSiteID, 127; NewSiteID, 15

Fixed effects:
                                                          Estimate Std. Error t value
(Intercept)                                       -139.292     83.702  -1.664
F_High_Exp                                      -180.239    102.778  -1.754
F_Mat_Type_SW                            470.297    261.537   1.798
F_Mat_Type_CNF                           -636.352    347.993  -1.829
F_Mat_Form_Dry                            662.263    368.761   1.796
F_Mat_Form_Liq                            -583.142    318.541  -1.831
F_Mat_Form_Comp                       598.774    331.856   1.804
F_Hybrid                                           -1197.691    658.229  -1.820
F_Primary                                        -639.928    352.811  -1.814
F_Coatings                                       92.795     50.804   1.826
F_mass_handled_orF2: 10 -         134.912     77.291   1.746
F_mass_handled_orF3: 101         -1235.372    677.423  -1.824
F_mass_handled_orF4: >1 k        137.714     75.958   1.813
F_adequate                                     139.446     76.582   1.821
F_inadequate                                  1395.036    767.413   1.818
F_emp_sc                                         -1259.213    691.979  -1.820
F_diam_sc                                        -20.188      9.971  -2.025

Again, the SAS results make sense...that there is 0 variance left over from the fully specified fixed effects. I am fairly certain the combination of the fixed effects uniquely identifies each facility. However, why doesn't R give a 0 variance? What is different between the two methods?


       [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


	[[alternative HTML version deleted]]


From jbaldwin at fs.fed.us  Thu Feb 15 17:49:43 2018
From: jbaldwin at fs.fed.us (Baldwin, Jim -FS)
Date: Thu, 15 Feb 2018 16:49:43 +0000
Subject: [R-sig-ME] Mixed Models in SAS and R
In-Reply-To: <f525db1427114cec89448ff5f586c2ef@cdc.gov>
References: <f1d15f0590834749893b287bb5063489@cdc.gov>
 <CAJuCY5xAZ-tdBJEKQ3mcapX7k+U1FpTUA=7NU199udOyy0km-g@mail.gmail.com>
 <dee7ea0144f44c368d860229d8557aa7@cdc.gov>
 <19AD1067-DC95-41F3-8533-1DAAA5038329@mac.com>
 <f525db1427114cec89448ff5f586c2ef@cdc.gov>
Message-ID: <e7c4f9a5e80147faa11a7028334680dc@DM2F00105MB0153.001f.mgd2.msft.net>

Shows up for me at the very end of the summary.  What version of R and lme4 are you using?

> summary(l)
Linear mixed model fit by REML ['lmerMod']
Formula: y ~ (1 | site) + site
   Data: fake_data

REML criterion at convergence: 49.7

Scaled residuals:
    Min      1Q  Median      3Q     Max
-1.8662 -0.5452 -0.1016  0.7029  1.8630

Random effects:
 Groups   Name        Variance Std.Dev.
 site     (Intercept) 4.5429   2.1314
 Residual             0.7182   0.8475
Number of obs: 20, groups:  site, 2

Fixed effects:
            Estimate Std. Error t value
(Intercept)    6.171      2.148   2.872
site2         -2.808      3.038  -0.924

Correlation of Fixed Effects:
      (Intr)
site2 -0.707
convergence code: 0
unable to evaluate scaled gradient
Model failed to converge: degenerate  Hessian with 1 negative eigenvalues




Jim Baldwin, PhD
Station Statistician
Forest Service
Pacific Southwest Research Station



-----Original Message-----
From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Bertke, Stephen (CDC/NIOSH/DSHEFS)
Sent: Thursday, February 15, 2018 8:46 AM
To: Peter Claussen <dakotajudo at mac.com>
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Mixed Models in SAS and R

I do not see any errors in R. What I posted is the entire output from running summary(). Is there something else I should be asking for?

From: Peter Claussen [mailto:dakotajudo at mac.com]
Sent: Thursday, February 15, 2018 11:15 AM
To: Bertke, Stephen (CDC/NIOSH/DSHEFS) <inh4 at cdc.gov>
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Mixed Models in SAS and R

I posted a response on stackexchange; I don?t think this is an R specific issue - SAS reports the same problem for your test data.

R is reporting a "degenerate Hessian with 1 negative eigenvalue", SAS reports that "final Hessian is not positive definite? - by definition, a positive definite matrix is a symmetric matrix with all positive eigenvalues.

Cheers,



On Feb 15, 2018, at 9:56 AM, Bertke, Stephen (CDC/NIOSH/DSHEFS) <inh4 at cdc.gov<mailto:inh4 at cdc.gov>> wrote:

Sorry for all the emails, but I have edited/simplified my question to what I believe is the root issue as well as posted simulated data to test with:

https://stats.stackexchange.com/questions/328712/lmer-vs-proc-mixed-output



-----Original Message-----
From: Bertke, Stephen (CDC/NIOSH/DSHEFS)
Sent: Wednesday, February 14, 2018 2:25 PM
To: 'Thierry Onkelinx' <thierry.onkelinx at inbo.be<mailto:thierry.onkelinx at inbo.be>>
Cc: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
Subject: RE: [R-sig-ME] Mixed Models in SAS and R

I posted the question on stackoverflow here:
https://stackoverflow.com/questions/48794651/lmer-vs-proc-mixed-output

This will hopefully make reading my code and output easier.

I would expect a 0 variance since I am in essence fitting a model with both the site variable in the fixed and random part of the model. I actually went ahead and fit that "dumb" model in both SAS and R and once again, all results are nearly identical except SAS estimates a 0 variance and R estimates a relatively large positive variance. However, R now gives an error/warning at the bottom of the results indicating an issue with this very dumb model. Again, those results are in the above link.




-----Original Message-----
From: Thierry Onkelinx [mailto:thierry.onkelinx at inbo.be]
Sent: Wednesday, February 14, 2018 11:39 AM
To: Bertke, Stephen (CDC/NIOSH/DSHEFS) <inh4 at cdc.gov<mailto:inh4 at cdc.gov>>
Cc: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] Mixed Models in SAS and R

Dear Stephen,

The list removes all HTML formating, making your post hard to read.
Please use only plain text when posting.

You'll need to make sure that you fit exactly the same model in SAS as in R. Not everyone here speaks SAS. Providing the math equation for the SAS model would help.

Also please elaborate why it makes sense that the variance of site should be zero. We cannot verify that statement based on the information you provide.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND FOREST Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance thierry.onkelinx at inbo.be<mailto:thierry.onkelinx at inbo.be> Havenlaan 88 bus 73, 1000 Brussel www.inbo.be<http://www.inbo.be>

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher The plural of anecdote is not data. ~ Roger Brinner The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey ///////////////////////////////////////////////////////////////////////////////////////////




2018-02-14 17:07 GMT+01:00 Bertke, Stephen (CDC/NIOSH/DSHEFS) <inh4 at cdc.gov<mailto:inh4 at cdc.gov>>:

Hello everyone. I have just joined this mailing list so I wanted to introduce myself as well as ask a question.

My name is Steve Bertke and I am a researcher at the National Institute for Occupational Safety and Health (NIOSH) which is one of the centers within the Centers for Disease Control and Prevention (CDC). I am a long-time SAS user but have been slowly finding myself using and liking R. I have found the support community for R very helpful and rewarding and am looking forward to contributing my part.

On to my question.

I have ran the same model (I think) in both SAS (proc mixed) and R (lmer) but have gotten different results for the random terms.

A quick background, we took 2 personal air samples for 127 people at 15 different factories for a total of 252 samples (after dropping 2 samples). We are trying to model various factors of the factory on the air samples. To do so, we need to control for the repeated measure of the person (nested within factory) as well as the random factory effect.

You can see below for the exact code and exact results, but in short, when I run the models in R and SAS without any fixed effects, I get the same results for the random effects. When I enter in the fixed effects, I get a different result for the Site variance...but all other results are the same (both the fixed effects and the other random effects).

There is another methodological issue with the model I am running. I am entering in 17 fixed effects that describe the 15 sites. Therefore, the model is over-specified. As a result, SAS gives a variance estimate of 0 for site (which, in hindsight, makes sense) however, R does not. That is a separate issue that we are dealing with, but I would expect that R and SAS would give the same result. Or maybe at least a warning.

Below is my code and output. I hope the formatting remains so that it is easily readable for everyone. I may also be able to share the data too, but I need to get some approval for that first.

Details
I ran the following code in SAS and R without any fixed effects and both give the same results:

proc mixed data=dat;
class NewSiteID NIOSHID;
model ln_i = ;
random NewSiteID NIOSHID(NewSiteID);
run;

Covariance Parameter Estimates

Cov Parm

Estimate

NewSiteID

6.3433

NIOSHID(NewSiteID)

0.7465

Residual

2.5256


mixedidsite <- lmer(ln_i ~ (1 | NewSiteID/NIOSHID),
                   data = Modeling_Database_Final)
summary(mixedidsite)

Random effects:
Groups                              Name        Variance Std.Dev.
NIOSHID:NewSiteID       (Intercept) 0.7465   0.864
NewSiteID                        (Intercept) 6.3434   2.519
Residual                                                 2.5256   1.589

However, when I add in the fixed effects, I get different results. SAS gives an estimate of 0 for Site while R does not. All other results are the same:

proc mixed data=dat;
class NewSiteID NIOSHID F_mass_handled_or (ref=first); model ln_i = F_High_Exp F_Mat_Type_SW F_Mat_Type_CNF F_Mat_Form_Dry F_Mat_Form_Liq F_Mat_Form_Comp F_Hybrid F_Primary F_Coatings F_mass_handled_or F_adequate F_inadequate F_emp_sc F_diam_sc/solution; random NewSiteID NIOSHID(NewSiteID); run;

Covariance Parameter Estimates

Cov Parm

Estimate

NewSiteID

0

NIOSHID(NewSiteID)

0.6954

Residual

2.5372


Fit Statistics

-2 Res Log Likelihood

961.8

AIC (Smaller is Better)

965.8

AICC (Smaller is Better)

965.9

BIC (Smaller is Better)

967.3


Solution for Fixed Effects

Effect

F_mass_handled_or

Estimate

Standard
Error

DF

t Value

Pr > |t|

Intercept



-139.29

83.6162

92.1

-1.67

0.0991

F_High_Exp



-180.24

102.72

92.6

-1.75

0.0826

F_Mat_Type_SW



470.30

261.53

92.1

1.80

0.0754

F_Mat_Type_CNF



-636.35

347.99

92.1

-1.83

0.0707

F_Mat_Form_Dry



662.26

368.75

92

1.80

0.0758

F_Mat_Form_Liq



-583.14

318.54

92

-1.83

0.0704

F_Mat_Form_Comp



598.77

331.85

92

1.80

0.0745

F_Hybrid



-1197.69

658.23

92

-1.82

0.0721

F_Primary



-639.93

352.80

92

-1.81

0.0730

F_Coatings



92.7949

50.7416

92.1

1.83

0.0707

F_mass_handled_or

F2

134.91

77.2496

92

1.75

0.0841

F_mass_handled_or

F3

-1235.37

677.42

92

-1.82

0.0715

F_mass_handled_or

F4

137.71

75.9370

92

1.81

0.0730

F_mass_handled_or

F1

0

.

.

.

.

F_adequate



139.45

76.5607

92

1.82

0.0718

F_inadequate



1395.04

767.40

92

1.82

0.0723

F_emp_sc



-1259.21

691.98

92

-1.82

0.0721

F_diam_sc



-20.1875

9.9710

89.5

-2.02

0.0459


mixedidsite <- lmer(ln_i ~ (1 | NewSiteID/NIOSHID)  + F_High_Exp + F_Mat_Type_SW +
                     F_Mat_Type_CNF + F_Mat_Form_Dry + F_Mat_Form_Liq + F_Mat_Form_Comp +
                     F_Hybrid + F_Primary + F_Coatings + F_adequate +
                     F_inadequate + F_emp_sc + F_diam_sc,
                   data = Modeling_Database_Final)
summary(mixedidsite)

REML criterion at convergence: 961.8

Scaled residuals:
   Min      1Q  Median      3Q     Max
-2.3019 -0.5248 -0.1668  0.3511  4.7091

Random effects:
Groups                              Name        Variance Std.Dev.
NIOSHID:NewSiteID       (Intercept) 0.6954   0.8339
NewSiteID                        (Intercept) 1.5932   1.2622
Residual                                                2.5372   1.5929
Number of obs: 252, groups:  NIOSHID:NewSiteID, 127; NewSiteID, 15

Fixed effects:
                                                          Estimate Std. Error t value
(Intercept)                                       -139.292     83.702  -1.664
F_High_Exp                                      -180.239    102.778  -1.754
F_Mat_Type_SW                            470.297    261.537   1.798
F_Mat_Type_CNF                           -636.352    347.993  -1.829
F_Mat_Form_Dry                            662.263    368.761   1.796
F_Mat_Form_Liq                            -583.142    318.541  -1.831
F_Mat_Form_Comp                       598.774    331.856   1.804
F_Hybrid                                           -1197.691    658.229  -1.820
F_Primary                                        -639.928    352.811  -1.814
F_Coatings                                       92.795     50.804   1.826
F_mass_handled_orF2: 10 -         134.912     77.291   1.746
F_mass_handled_orF3: 101         -1235.372    677.423  -1.824
F_mass_handled_orF4: >1 k        137.714     75.958   1.813
F_adequate                                     139.446     76.582   1.821
F_inadequate                                  1395.036    767.413   1.818
F_emp_sc                                         -1259.213    691.979  -1.820
F_diam_sc                                        -20.188      9.971  -2.025

Again, the SAS results make sense...that there is 0 variance left over from the fully specified fixed effects. I am fairly certain the combination of the fixed effects uniquely identifies each facility. However, why doesn't R give a 0 variance? What is different between the two methods?


       [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models




This electronic message contains information generated by the USDA solely for the intended recipients. Any unauthorized interception of this message or the use or disclosure of the information it contains may violate the law and subject the violator to civil or criminal penalties. If you believe you have received this message in error, please notify the sender and delete the email immediately.

From inh4 at cdc.gov  Thu Feb 15 19:14:58 2018
From: inh4 at cdc.gov (Bertke, Stephen (CDC/NIOSH/DSHEFS))
Date: Thu, 15 Feb 2018 18:14:58 +0000
Subject: [R-sig-ME] Mixed Models in SAS and R
In-Reply-To: <e7c4f9a5e80147faa11a7028334680dc@DM2F00105MB0153.001f.mgd2.msft.net>
References: <f1d15f0590834749893b287bb5063489@cdc.gov>
 <CAJuCY5xAZ-tdBJEKQ3mcapX7k+U1FpTUA=7NU199udOyy0km-g@mail.gmail.com>
 <dee7ea0144f44c368d860229d8557aa7@cdc.gov>
 <19AD1067-DC95-41F3-8533-1DAAA5038329@mac.com>
 <f525db1427114cec89448ff5f586c2ef@cdc.gov>
 <e7c4f9a5e80147faa11a7028334680dc@DM2F00105MB0153.001f.mgd2.msft.net>
Message-ID: <0857d30285844f39b825b2574fb0c209@cdc.gov>

Below is my full output using:
R version 3.4.3 (2017-11-30)
RStudio Version 1.0.143
lme4_1.1-15


> summary(l)
Linear mixed model fit by REML ['lmerMod']
Formula: y ~ (1 | site) + site
   Data: fake_data

REML criterion at convergence: 49.7

Scaled residuals: 
    Min      1Q  Median      3Q     Max 
-1.8662 -0.5452 -0.1016  0.7029  1.8630 

Random effects:
 Groups   Name        Variance Std.Dev.
 site     (Intercept) 3.7025   1.9242  
 Residual             0.7182   0.8475  
Number of obs: 20, groups:  site, 2

Fixed effects:
            Estimate Std. Error t value
(Intercept)    6.171      1.943   3.176
site2         -2.808      2.747  -1.022

Correlation of Fixed Effects:
      (Intr)
site2 -0.707
>

-----Original Message-----
From: Baldwin, Jim -FS [mailto:jbaldwin at fs.fed.us] 
Sent: Thursday, February 15, 2018 11:50 AM
To: Bertke, Stephen (CDC/NIOSH/DSHEFS) <inh4 at cdc.gov>; Peter Claussen <dakotajudo at mac.com>
Cc: r-sig-mixed-models at r-project.org
Subject: RE: [R-sig-ME] Mixed Models in SAS and R

Shows up for me at the very end of the summary.  What version of R and lme4 are you using?

> summary(l)
Linear mixed model fit by REML ['lmerMod']
Formula: y ~ (1 | site) + site
   Data: fake_data

REML criterion at convergence: 49.7

Scaled residuals:
    Min      1Q  Median      3Q     Max
-1.8662 -0.5452 -0.1016  0.7029  1.8630

Random effects:
 Groups   Name        Variance Std.Dev.
 site     (Intercept) 4.5429   2.1314
 Residual             0.7182   0.8475
Number of obs: 20, groups:  site, 2

Fixed effects:
            Estimate Std. Error t value
(Intercept)    6.171      2.148   2.872
site2         -2.808      3.038  -0.924

Correlation of Fixed Effects:
      (Intr)
site2 -0.707
convergence code: 0
unable to evaluate scaled gradient
Model failed to converge: degenerate  Hessian with 1 negative eigenvalues




Jim Baldwin, PhD
Station Statistician
Forest Service
Pacific Southwest Research Station



-----Original Message-----
From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Bertke, Stephen (CDC/NIOSH/DSHEFS)
Sent: Thursday, February 15, 2018 8:46 AM
To: Peter Claussen <dakotajudo at mac.com>
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Mixed Models in SAS and R

I do not see any errors in R. What I posted is the entire output from running summary(). Is there something else I should be asking for?

From: Peter Claussen [mailto:dakotajudo at mac.com]
Sent: Thursday, February 15, 2018 11:15 AM
To: Bertke, Stephen (CDC/NIOSH/DSHEFS) <inh4 at cdc.gov>
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Mixed Models in SAS and R

I posted a response on stackexchange; I don?t think this is an R specific issue - SAS reports the same problem for your test data.

R is reporting a "degenerate Hessian with 1 negative eigenvalue", SAS reports that "final Hessian is not positive definite? - by definition, a positive definite matrix is a symmetric matrix with all positive eigenvalues.

Cheers,



On Feb 15, 2018, at 9:56 AM, Bertke, Stephen (CDC/NIOSH/DSHEFS) <inh4 at cdc.gov<mailto:inh4 at cdc.gov>> wrote:

Sorry for all the emails, but I have edited/simplified my question to what I believe is the root issue as well as posted simulated data to test with:

https://stats.stackexchange.com/questions/328712/lmer-vs-proc-mixed-output



-----Original Message-----
From: Bertke, Stephen (CDC/NIOSH/DSHEFS)
Sent: Wednesday, February 14, 2018 2:25 PM
To: 'Thierry Onkelinx' <thierry.onkelinx at inbo.be<mailto:thierry.onkelinx at inbo.be>>
Cc: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
Subject: RE: [R-sig-ME] Mixed Models in SAS and R

I posted the question on stackoverflow here:
https://stackoverflow.com/questions/48794651/lmer-vs-proc-mixed-output

This will hopefully make reading my code and output easier.

I would expect a 0 variance since I am in essence fitting a model with both the site variable in the fixed and random part of the model. I actually went ahead and fit that "dumb" model in both SAS and R and once again, all results are nearly identical except SAS estimates a 0 variance and R estimates a relatively large positive variance. However, R now gives an error/warning at the bottom of the results indicating an issue with this very dumb model. Again, those results are in the above link.




-----Original Message-----
From: Thierry Onkelinx [mailto:thierry.onkelinx at inbo.be]
Sent: Wednesday, February 14, 2018 11:39 AM
To: Bertke, Stephen (CDC/NIOSH/DSHEFS) <inh4 at cdc.gov<mailto:inh4 at cdc.gov>>
Cc: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] Mixed Models in SAS and R

Dear Stephen,

The list removes all HTML formating, making your post hard to read.
Please use only plain text when posting.

You'll need to make sure that you fit exactly the same model in SAS as in R. Not everyone here speaks SAS. Providing the math equation for the SAS model would help.

Also please elaborate why it makes sense that the variance of site should be zero. We cannot verify that statement based on the information you provide.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND FOREST Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance thierry.onkelinx at inbo.be<mailto:thierry.onkelinx at inbo.be> Havenlaan 88 bus 73, 1000 Brussel www.inbo.be<http://www.inbo.be>

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher The plural of anecdote is not data. ~ Roger Brinner The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey ///////////////////////////////////////////////////////////////////////////////////////////




2018-02-14 17:07 GMT+01:00 Bertke, Stephen (CDC/NIOSH/DSHEFS) <inh4 at cdc.gov<mailto:inh4 at cdc.gov>>:

Hello everyone. I have just joined this mailing list so I wanted to introduce myself as well as ask a question.

My name is Steve Bertke and I am a researcher at the National Institute for Occupational Safety and Health (NIOSH) which is one of the centers within the Centers for Disease Control and Prevention (CDC). I am a long-time SAS user but have been slowly finding myself using and liking R. I have found the support community for R very helpful and rewarding and am looking forward to contributing my part.

On to my question.

I have ran the same model (I think) in both SAS (proc mixed) and R (lmer) but have gotten different results for the random terms.

A quick background, we took 2 personal air samples for 127 people at 15 different factories for a total of 252 samples (after dropping 2 samples). We are trying to model various factors of the factory on the air samples. To do so, we need to control for the repeated measure of the person (nested within factory) as well as the random factory effect.

You can see below for the exact code and exact results, but in short, when I run the models in R and SAS without any fixed effects, I get the same results for the random effects. When I enter in the fixed effects, I get a different result for the Site variance...but all other results are the same (both the fixed effects and the other random effects).

There is another methodological issue with the model I am running. I am entering in 17 fixed effects that describe the 15 sites. Therefore, the model is over-specified. As a result, SAS gives a variance estimate of 0 for site (which, in hindsight, makes sense) however, R does not. That is a separate issue that we are dealing with, but I would expect that R and SAS would give the same result. Or maybe at least a warning.

Below is my code and output. I hope the formatting remains so that it is easily readable for everyone. I may also be able to share the data too, but I need to get some approval for that first.

Details
I ran the following code in SAS and R without any fixed effects and both give the same results:

proc mixed data=dat;
class NewSiteID NIOSHID;
model ln_i = ;
random NewSiteID NIOSHID(NewSiteID);
run;

Covariance Parameter Estimates

Cov Parm

Estimate

NewSiteID

6.3433

NIOSHID(NewSiteID)

0.7465

Residual

2.5256


mixedidsite <- lmer(ln_i ~ (1 | NewSiteID/NIOSHID),
                   data = Modeling_Database_Final)
summary(mixedidsite)

Random effects:
Groups                              Name        Variance Std.Dev.
NIOSHID:NewSiteID       (Intercept) 0.7465   0.864
NewSiteID                        (Intercept) 6.3434   2.519
Residual                                                 2.5256   1.589

However, when I add in the fixed effects, I get different results. SAS gives an estimate of 0 for Site while R does not. All other results are the same:

proc mixed data=dat;
class NewSiteID NIOSHID F_mass_handled_or (ref=first); model ln_i = F_High_Exp F_Mat_Type_SW F_Mat_Type_CNF F_Mat_Form_Dry F_Mat_Form_Liq F_Mat_Form_Comp F_Hybrid F_Primary F_Coatings F_mass_handled_or F_adequate F_inadequate F_emp_sc F_diam_sc/solution; random NewSiteID NIOSHID(NewSiteID); run;

Covariance Parameter Estimates

Cov Parm

Estimate

NewSiteID

0

NIOSHID(NewSiteID)

0.6954

Residual

2.5372


Fit Statistics

-2 Res Log Likelihood

961.8

AIC (Smaller is Better)

965.8

AICC (Smaller is Better)

965.9

BIC (Smaller is Better)

967.3


Solution for Fixed Effects

Effect

F_mass_handled_or

Estimate

Standard
Error

DF

t Value

Pr > |t|

Intercept



-139.29

83.6162

92.1

-1.67

0.0991

F_High_Exp



-180.24

102.72

92.6

-1.75

0.0826

F_Mat_Type_SW



470.30

261.53

92.1

1.80

0.0754

F_Mat_Type_CNF



-636.35

347.99

92.1

-1.83

0.0707

F_Mat_Form_Dry



662.26

368.75

92

1.80

0.0758

F_Mat_Form_Liq



-583.14

318.54

92

-1.83

0.0704

F_Mat_Form_Comp



598.77

331.85

92

1.80

0.0745

F_Hybrid



-1197.69

658.23

92

-1.82

0.0721

F_Primary



-639.93

352.80

92

-1.81

0.0730

F_Coatings



92.7949

50.7416

92.1

1.83

0.0707

F_mass_handled_or

F2

134.91

77.2496

92

1.75

0.0841

F_mass_handled_or

F3

-1235.37

677.42

92

-1.82

0.0715

F_mass_handled_or

F4

137.71

75.9370

92

1.81

0.0730

F_mass_handled_or

F1

0

.

.

.

.

F_adequate



139.45

76.5607

92

1.82

0.0718

F_inadequate



1395.04

767.40

92

1.82

0.0723

F_emp_sc



-1259.21

691.98

92

-1.82

0.0721

F_diam_sc



-20.1875

9.9710

89.5

-2.02

0.0459


mixedidsite <- lmer(ln_i ~ (1 | NewSiteID/NIOSHID)  + F_High_Exp + F_Mat_Type_SW +
                     F_Mat_Type_CNF + F_Mat_Form_Dry + F_Mat_Form_Liq + F_Mat_Form_Comp +
                     F_Hybrid + F_Primary + F_Coatings + F_adequate +
                     F_inadequate + F_emp_sc + F_diam_sc,
                   data = Modeling_Database_Final)
summary(mixedidsite)

REML criterion at convergence: 961.8

Scaled residuals:
   Min      1Q  Median      3Q     Max
-2.3019 -0.5248 -0.1668  0.3511  4.7091

Random effects:
Groups                              Name        Variance Std.Dev.
NIOSHID:NewSiteID       (Intercept) 0.6954   0.8339
NewSiteID                        (Intercept) 1.5932   1.2622
Residual                                                2.5372   1.5929
Number of obs: 252, groups:  NIOSHID:NewSiteID, 127; NewSiteID, 15

Fixed effects:
                                                          Estimate Std. Error t value
(Intercept)                                       -139.292     83.702  -1.664
F_High_Exp                                      -180.239    102.778  -1.754
F_Mat_Type_SW                            470.297    261.537   1.798
F_Mat_Type_CNF                           -636.352    347.993  -1.829
F_Mat_Form_Dry                            662.263    368.761   1.796
F_Mat_Form_Liq                            -583.142    318.541  -1.831
F_Mat_Form_Comp                       598.774    331.856   1.804
F_Hybrid                                           -1197.691    658.229  -1.820
F_Primary                                        -639.928    352.811  -1.814
F_Coatings                                       92.795     50.804   1.826
F_mass_handled_orF2: 10 -         134.912     77.291   1.746
F_mass_handled_orF3: 101         -1235.372    677.423  -1.824
F_mass_handled_orF4: >1 k        137.714     75.958   1.813
F_adequate                                     139.446     76.582   1.821
F_inadequate                                  1395.036    767.413   1.818
F_emp_sc                                         -1259.213    691.979  -1.820
F_diam_sc                                        -20.188      9.971  -2.025

Again, the SAS results make sense...that there is 0 variance left over from the fully specified fixed effects. I am fairly certain the combination of the fixed effects uniquely identifies each facility. However, why doesn't R give a 0 variance? What is different between the two methods?


       [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models




This electronic message contains information generated by the USDA solely for the intended recipients. Any unauthorized interception of this message or the use or disclosure of the information it contains may violate the law and subject the violator to civil or criminal penalties. If you believe you have received this message in error, please notify the sender and delete the email immediately.

From inh4 at cdc.gov  Thu Feb 15 19:25:43 2018
From: inh4 at cdc.gov (Bertke, Stephen (CDC/NIOSH/DSHEFS))
Date: Thu, 15 Feb 2018 18:25:43 +0000
Subject: [R-sig-ME] Mixed Models in SAS and R
In-Reply-To: <e7c4f9a5e80147faa11a7028334680dc@DM2F00105MB0153.001f.mgd2.msft.net>
References: <f1d15f0590834749893b287bb5063489@cdc.gov>
 <CAJuCY5xAZ-tdBJEKQ3mcapX7k+U1FpTUA=7NU199udOyy0km-g@mail.gmail.com>
 <dee7ea0144f44c368d860229d8557aa7@cdc.gov>
 <19AD1067-DC95-41F3-8533-1DAAA5038329@mac.com>
 <f525db1427114cec89448ff5f586c2ef@cdc.gov>
 <e7c4f9a5e80147faa11a7028334680dc@DM2F00105MB0153.001f.mgd2.msft.net>
Message-ID: <7c1098f404f3469d9c9dfad96369dc85@cdc.gov>

And this might be a very dumb question, but I thought that the Hessian was related to the variance estimates. SO if the Hessian has a negative eigenvalue, wouldn?t one of the variance estimates be negative?.....I thought that is what happens in SAS, and instead of reporting a negative variance estimate it bounds the estimate at 0.

But it has been a while since I have gotten deep into the theory behind these models, so I may be completely wrong.....and if so, we can just leave it at that.  

-----Original Message-----
From: Baldwin, Jim -FS [mailto:jbaldwin at fs.fed.us] 
Sent: Thursday, February 15, 2018 11:50 AM
To: Bertke, Stephen (CDC/NIOSH/DSHEFS) <inh4 at cdc.gov>; Peter Claussen <dakotajudo at mac.com>
Cc: r-sig-mixed-models at r-project.org
Subject: RE: [R-sig-ME] Mixed Models in SAS and R

Shows up for me at the very end of the summary.  What version of R and lme4 are you using?

> summary(l)
Linear mixed model fit by REML ['lmerMod']
Formula: y ~ (1 | site) + site
   Data: fake_data

REML criterion at convergence: 49.7

Scaled residuals:
    Min      1Q  Median      3Q     Max
-1.8662 -0.5452 -0.1016  0.7029  1.8630

Random effects:
 Groups   Name        Variance Std.Dev.
 site     (Intercept) 4.5429   2.1314
 Residual             0.7182   0.8475
Number of obs: 20, groups:  site, 2

Fixed effects:
            Estimate Std. Error t value
(Intercept)    6.171      2.148   2.872
site2         -2.808      3.038  -0.924

Correlation of Fixed Effects:
      (Intr)
site2 -0.707
convergence code: 0
unable to evaluate scaled gradient
Model failed to converge: degenerate  Hessian with 1 negative eigenvalues




Jim Baldwin, PhD
Station Statistician
Forest Service
Pacific Southwest Research Station



-----Original Message-----
From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Bertke, Stephen (CDC/NIOSH/DSHEFS)
Sent: Thursday, February 15, 2018 8:46 AM
To: Peter Claussen <dakotajudo at mac.com>
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Mixed Models in SAS and R

I do not see any errors in R. What I posted is the entire output from running summary(). Is there something else I should be asking for?

From: Peter Claussen [mailto:dakotajudo at mac.com]
Sent: Thursday, February 15, 2018 11:15 AM
To: Bertke, Stephen (CDC/NIOSH/DSHEFS) <inh4 at cdc.gov>
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Mixed Models in SAS and R

I posted a response on stackexchange; I don?t think this is an R specific issue - SAS reports the same problem for your test data.

R is reporting a "degenerate Hessian with 1 negative eigenvalue", SAS reports that "final Hessian is not positive definite? - by definition, a positive definite matrix is a symmetric matrix with all positive eigenvalues.

Cheers,



On Feb 15, 2018, at 9:56 AM, Bertke, Stephen (CDC/NIOSH/DSHEFS) <inh4 at cdc.gov<mailto:inh4 at cdc.gov>> wrote:

Sorry for all the emails, but I have edited/simplified my question to what I believe is the root issue as well as posted simulated data to test with:

https://stats.stackexchange.com/questions/328712/lmer-vs-proc-mixed-output



-----Original Message-----
From: Bertke, Stephen (CDC/NIOSH/DSHEFS)
Sent: Wednesday, February 14, 2018 2:25 PM
To: 'Thierry Onkelinx' <thierry.onkelinx at inbo.be<mailto:thierry.onkelinx at inbo.be>>
Cc: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
Subject: RE: [R-sig-ME] Mixed Models in SAS and R

I posted the question on stackoverflow here:
https://stackoverflow.com/questions/48794651/lmer-vs-proc-mixed-output

This will hopefully make reading my code and output easier.

I would expect a 0 variance since I am in essence fitting a model with both the site variable in the fixed and random part of the model. I actually went ahead and fit that "dumb" model in both SAS and R and once again, all results are nearly identical except SAS estimates a 0 variance and R estimates a relatively large positive variance. However, R now gives an error/warning at the bottom of the results indicating an issue with this very dumb model. Again, those results are in the above link.




-----Original Message-----
From: Thierry Onkelinx [mailto:thierry.onkelinx at inbo.be]
Sent: Wednesday, February 14, 2018 11:39 AM
To: Bertke, Stephen (CDC/NIOSH/DSHEFS) <inh4 at cdc.gov<mailto:inh4 at cdc.gov>>
Cc: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] Mixed Models in SAS and R

Dear Stephen,

The list removes all HTML formating, making your post hard to read.
Please use only plain text when posting.

You'll need to make sure that you fit exactly the same model in SAS as in R. Not everyone here speaks SAS. Providing the math equation for the SAS model would help.

Also please elaborate why it makes sense that the variance of site should be zero. We cannot verify that statement based on the information you provide.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND FOREST Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance thierry.onkelinx at inbo.be<mailto:thierry.onkelinx at inbo.be> Havenlaan 88 bus 73, 1000 Brussel www.inbo.be<http://www.inbo.be>

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher The plural of anecdote is not data. ~ Roger Brinner The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey ///////////////////////////////////////////////////////////////////////////////////////////




2018-02-14 17:07 GMT+01:00 Bertke, Stephen (CDC/NIOSH/DSHEFS) <inh4 at cdc.gov<mailto:inh4 at cdc.gov>>:

Hello everyone. I have just joined this mailing list so I wanted to introduce myself as well as ask a question.

My name is Steve Bertke and I am a researcher at the National Institute for Occupational Safety and Health (NIOSH) which is one of the centers within the Centers for Disease Control and Prevention (CDC). I am a long-time SAS user but have been slowly finding myself using and liking R. I have found the support community for R very helpful and rewarding and am looking forward to contributing my part.

On to my question.

I have ran the same model (I think) in both SAS (proc mixed) and R (lmer) but have gotten different results for the random terms.

A quick background, we took 2 personal air samples for 127 people at 15 different factories for a total of 252 samples (after dropping 2 samples). We are trying to model various factors of the factory on the air samples. To do so, we need to control for the repeated measure of the person (nested within factory) as well as the random factory effect.

You can see below for the exact code and exact results, but in short, when I run the models in R and SAS without any fixed effects, I get the same results for the random effects. When I enter in the fixed effects, I get a different result for the Site variance...but all other results are the same (both the fixed effects and the other random effects).

There is another methodological issue with the model I am running. I am entering in 17 fixed effects that describe the 15 sites. Therefore, the model is over-specified. As a result, SAS gives a variance estimate of 0 for site (which, in hindsight, makes sense) however, R does not. That is a separate issue that we are dealing with, but I would expect that R and SAS would give the same result. Or maybe at least a warning.

Below is my code and output. I hope the formatting remains so that it is easily readable for everyone. I may also be able to share the data too, but I need to get some approval for that first.

Details
I ran the following code in SAS and R without any fixed effects and both give the same results:

proc mixed data=dat;
class NewSiteID NIOSHID;
model ln_i = ;
random NewSiteID NIOSHID(NewSiteID);
run;

Covariance Parameter Estimates

Cov Parm

Estimate

NewSiteID

6.3433

NIOSHID(NewSiteID)

0.7465

Residual

2.5256


mixedidsite <- lmer(ln_i ~ (1 | NewSiteID/NIOSHID),
                   data = Modeling_Database_Final)
summary(mixedidsite)

Random effects:
Groups                              Name        Variance Std.Dev.
NIOSHID:NewSiteID       (Intercept) 0.7465   0.864
NewSiteID                        (Intercept) 6.3434   2.519
Residual                                                 2.5256   1.589

However, when I add in the fixed effects, I get different results. SAS gives an estimate of 0 for Site while R does not. All other results are the same:

proc mixed data=dat;
class NewSiteID NIOSHID F_mass_handled_or (ref=first); model ln_i = F_High_Exp F_Mat_Type_SW F_Mat_Type_CNF F_Mat_Form_Dry F_Mat_Form_Liq F_Mat_Form_Comp F_Hybrid F_Primary F_Coatings F_mass_handled_or F_adequate F_inadequate F_emp_sc F_diam_sc/solution; random NewSiteID NIOSHID(NewSiteID); run;

Covariance Parameter Estimates

Cov Parm

Estimate

NewSiteID

0

NIOSHID(NewSiteID)

0.6954

Residual

2.5372


Fit Statistics

-2 Res Log Likelihood

961.8

AIC (Smaller is Better)

965.8

AICC (Smaller is Better)

965.9

BIC (Smaller is Better)

967.3


Solution for Fixed Effects

Effect

F_mass_handled_or

Estimate

Standard
Error

DF

t Value

Pr > |t|

Intercept



-139.29

83.6162

92.1

-1.67

0.0991

F_High_Exp



-180.24

102.72

92.6

-1.75

0.0826

F_Mat_Type_SW



470.30

261.53

92.1

1.80

0.0754

F_Mat_Type_CNF



-636.35

347.99

92.1

-1.83

0.0707

F_Mat_Form_Dry



662.26

368.75

92

1.80

0.0758

F_Mat_Form_Liq



-583.14

318.54

92

-1.83

0.0704

F_Mat_Form_Comp



598.77

331.85

92

1.80

0.0745

F_Hybrid



-1197.69

658.23

92

-1.82

0.0721

F_Primary



-639.93

352.80

92

-1.81

0.0730

F_Coatings



92.7949

50.7416

92.1

1.83

0.0707

F_mass_handled_or

F2

134.91

77.2496

92

1.75

0.0841

F_mass_handled_or

F3

-1235.37

677.42

92

-1.82

0.0715

F_mass_handled_or

F4

137.71

75.9370

92

1.81

0.0730

F_mass_handled_or

F1

0

.

.

.

.

F_adequate



139.45

76.5607

92

1.82

0.0718

F_inadequate



1395.04

767.40

92

1.82

0.0723

F_emp_sc



-1259.21

691.98

92

-1.82

0.0721

F_diam_sc



-20.1875

9.9710

89.5

-2.02

0.0459


mixedidsite <- lmer(ln_i ~ (1 | NewSiteID/NIOSHID)  + F_High_Exp + F_Mat_Type_SW +
                     F_Mat_Type_CNF + F_Mat_Form_Dry + F_Mat_Form_Liq + F_Mat_Form_Comp +
                     F_Hybrid + F_Primary + F_Coatings + F_adequate +
                     F_inadequate + F_emp_sc + F_diam_sc,
                   data = Modeling_Database_Final)
summary(mixedidsite)

REML criterion at convergence: 961.8

Scaled residuals:
   Min      1Q  Median      3Q     Max
-2.3019 -0.5248 -0.1668  0.3511  4.7091

Random effects:
Groups                              Name        Variance Std.Dev.
NIOSHID:NewSiteID       (Intercept) 0.6954   0.8339
NewSiteID                        (Intercept) 1.5932   1.2622
Residual                                                2.5372   1.5929
Number of obs: 252, groups:  NIOSHID:NewSiteID, 127; NewSiteID, 15

Fixed effects:
                                                          Estimate Std. Error t value
(Intercept)                                       -139.292     83.702  -1.664
F_High_Exp                                      -180.239    102.778  -1.754
F_Mat_Type_SW                            470.297    261.537   1.798
F_Mat_Type_CNF                           -636.352    347.993  -1.829
F_Mat_Form_Dry                            662.263    368.761   1.796
F_Mat_Form_Liq                            -583.142    318.541  -1.831
F_Mat_Form_Comp                       598.774    331.856   1.804
F_Hybrid                                           -1197.691    658.229  -1.820
F_Primary                                        -639.928    352.811  -1.814
F_Coatings                                       92.795     50.804   1.826
F_mass_handled_orF2: 10 -         134.912     77.291   1.746
F_mass_handled_orF3: 101         -1235.372    677.423  -1.824
F_mass_handled_orF4: >1 k        137.714     75.958   1.813
F_adequate                                     139.446     76.582   1.821
F_inadequate                                  1395.036    767.413   1.818
F_emp_sc                                         -1259.213    691.979  -1.820
F_diam_sc                                        -20.188      9.971  -2.025

Again, the SAS results make sense...that there is 0 variance left over from the fully specified fixed effects. I am fairly certain the combination of the fixed effects uniquely identifies each facility. However, why doesn't R give a 0 variance? What is different between the two methods?


       [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models




This electronic message contains information generated by the USDA solely for the intended recipients. Any unauthorized interception of this message or the use or disclosure of the information it contains may violate the law and subject the violator to civil or criminal penalties. If you believe you have received this message in error, please notify the sender and delete the email immediately.

From john.maindonald at anu.edu.au  Thu Feb 15 22:07:35 2018
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Thu, 15 Feb 2018 21:07:35 +0000
Subject: [R-sig-ME] Mixed Models in SAS and R
In-Reply-To: <7c1098f404f3469d9c9dfad96369dc85@cdc.gov>
References: <f1d15f0590834749893b287bb5063489@cdc.gov>
 <CAJuCY5xAZ-tdBJEKQ3mcapX7k+U1FpTUA=7NU199udOyy0km-g@mail.gmail.com>
 <dee7ea0144f44c368d860229d8557aa7@cdc.gov>
 <19AD1067-DC95-41F3-8533-1DAAA5038329@mac.com>
 <f525db1427114cec89448ff5f586c2ef@cdc.gov>
 <e7c4f9a5e80147faa11a7028334680dc@DM2F00105MB0153.001f.mgd2.msft.net>
 <7c1098f404f3469d9c9dfad96369dc85@cdc.gov>
Message-ID: <609AC930-FA1A-4802-8AFA-D736AC6E0516@anu.edu.au>

The lme4 code, in a practice designed to preserve its vision of mathematical purity,
constrains the variance estimates to be non-negative.  That makes sense if one
can be sure that the model is tuned to the circumstances that generated the data.

The negative variances that some of the other mixed modeling software allows can
be a useful diagnostic, indicating for example an inappropriate experimental design.
I have mentioned previously the example once mentioned to me, and which would
be easy to simulate, where blocks in a field block experimental design had been
laid out at right angles to a river bank.  A negative block variance estimate was
required to give a variance-covariance matrix which had all the mathematical
respectability that anyone might want.

There are circumstances where it is useful to constrain the variance estimates to
be non-negative ? it would be useful to have a choice.


John Maindonald             email: john.maindonald at anu.edu.au<mailto:john.maindonald at anu.edu.au>

On 16/02/2018, at 07:25, Bertke, Stephen (CDC/NIOSH/DSHEFS) <inh4 at cdc.gov<mailto:inh4 at cdc.gov>> wrote:

And this might be a very dumb question, but I thought that the Hessian was related to the variance estimates. SO if the Hessian has a negative eigenvalue, wouldn?t one of the variance estimates be negative?.....I thought that is what happens in SAS, and instead of reporting a negative variance estimate it bounds the estimate at 0.

But it has been a while since I have gotten deep into the theory behind these models, so I may be completely wrong.....and if so, we can just leave it at that.

-----Original Message-----
From: Baldwin, Jim -FS [mailto:jbaldwin at fs.fed.us]
Sent: Thursday, February 15, 2018 11:50 AM
To: Bertke, Stephen (CDC/NIOSH/DSHEFS) <inh4 at cdc.gov<mailto:inh4 at cdc.gov>>; Peter Claussen <dakotajudo at mac.com<mailto:dakotajudo at mac.com>>
Cc: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
Subject: RE: [R-sig-ME] Mixed Models in SAS and R

Shows up for me at the very end of the summary.  What version of R and lme4 are you using?

summary(l)
Linear mixed model fit by REML ['lmerMod']
Formula: y ~ (1 | site) + site
  Data: fake_data

REML criterion at convergence: 49.7

Scaled residuals:
   Min      1Q  Median      3Q     Max
-1.8662 -0.5452 -0.1016  0.7029  1.8630

Random effects:
Groups   Name        Variance Std.Dev.
site     (Intercept) 4.5429   2.1314
Residual             0.7182   0.8475
Number of obs: 20, groups:  site, 2

Fixed effects:
           Estimate Std. Error t value
(Intercept)    6.171      2.148   2.872
site2         -2.808      3.038  -0.924

Correlation of Fixed Effects:
     (Intr)
site2 -0.707
convergence code: 0
unable to evaluate scaled gradient
Model failed to converge: degenerate  Hessian with 1 negative eigenvalues




Jim Baldwin, PhD
Station Statistician
Forest Service
Pacific Southwest Research Station



-----Original Message-----
From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Bertke, Stephen (CDC/NIOSH/DSHEFS)
Sent: Thursday, February 15, 2018 8:46 AM
To: Peter Claussen <dakotajudo at mac.com<mailto:dakotajudo at mac.com>>
Cc: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] Mixed Models in SAS and R

I do not see any errors in R. What I posted is the entire output from running summary(). Is there something else I should be asking for?

From: Peter Claussen [mailto:dakotajudo at mac.com]
Sent: Thursday, February 15, 2018 11:15 AM
To: Bertke, Stephen (CDC/NIOSH/DSHEFS) <inh4 at cdc.gov<mailto:inh4 at cdc.gov>>
Cc: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] Mixed Models in SAS and R

I posted a response on stackexchange; I don?t think this is an R specific issue - SAS reports the same problem for your test data.

R is reporting a "degenerate Hessian with 1 negative eigenvalue", SAS reports that "final Hessian is not positive definite? - by definition, a positive definite matrix is a symmetric matrix with all positive eigenvalues.

Cheers,



On Feb 15, 2018, at 9:56 AM, Bertke, Stephen (CDC/NIOSH/DSHEFS) <inh4 at cdc.gov<mailto:inh4 at cdc.gov><mailto:inh4 at cdc.gov>> wrote:

Sorry for all the emails, but I have edited/simplified my question to what I believe is the root issue as well as posted simulated data to test with:

https://stats.stackexchange.com/questions/328712/lmer-vs-proc-mixed-output



-----Original Message-----
From: Bertke, Stephen (CDC/NIOSH/DSHEFS)
Sent: Wednesday, February 14, 2018 2:25 PM
To: 'Thierry Onkelinx' <thierry.onkelinx at inbo.be<mailto:thierry.onkelinx at inbo.be>>
Cc: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
Subject: RE: [R-sig-ME] Mixed Models in SAS and R

I posted the question on stackoverflow here:
https://stackoverflow.com/questions/48794651/lmer-vs-proc-mixed-output

This will hopefully make reading my code and output easier.

I would expect a 0 variance since I am in essence fitting a model with both the site variable in the fixed and random part of the model. I actually went ahead and fit that "dumb" model in both SAS and R and once again, all results are nearly identical except SAS estimates a 0 variance and R estimates a relatively large positive variance. However, R now gives an error/warning at the bottom of the results indicating an issue with this very dumb model. Again, those results are in the above link.




-----Original Message-----
From: Thierry Onkelinx [mailto:thierry.onkelinx at inbo.be]
Sent: Wednesday, February 14, 2018 11:39 AM
To: Bertke, Stephen (CDC/NIOSH/DSHEFS) <inh4 at cdc.gov<mailto:inh4 at cdc.gov>>
Cc: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] Mixed Models in SAS and R

Dear Stephen,

The list removes all HTML formating, making your post hard to read.
Please use only plain text when posting.

You'll need to make sure that you fit exactly the same model in SAS as in R. Not everyone here speaks SAS. Providing the math equation for the SAS model would help.

Also please elaborate why it makes sense that the variance of site should be zero. We cannot verify that statement based on the information you provide.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND FOREST Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance thierry.onkelinx at inbo.be<mailto:thierry.onkelinx at inbo.be> Havenlaan 88 bus 73, 1000 Brussel www.inbo.be<http://www.inbo.be>

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher The plural of anecdote is not data. ~ Roger Brinner The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey ///////////////////////////////////////////////////////////////////////////////////////////




2018-02-14 17:07 GMT+01:00 Bertke, Stephen (CDC/NIOSH/DSHEFS) <inh4 at cdc.gov<mailto:inh4 at cdc.gov>>:

Hello everyone. I have just joined this mailing list so I wanted to introduce myself as well as ask a question.

My name is Steve Bertke and I am a researcher at the National Institute for Occupational Safety and Health (NIOSH) which is one of the centers within the Centers for Disease Control and Prevention (CDC). I am a long-time SAS user but have been slowly finding myself using and liking R. I have found the support community for R very helpful and rewarding and am looking forward to contributing my part.

On to my question.

I have ran the same model (I think) in both SAS (proc mixed) and R (lmer) but have gotten different results for the random terms.

A quick background, we took 2 personal air samples for 127 people at 15 different factories for a total of 252 samples (after dropping 2 samples). We are trying to model various factors of the factory on the air samples. To do so, we need to control for the repeated measure of the person (nested within factory) as well as the random factory effect.

You can see below for the exact code and exact results, but in short, when I run the models in R and SAS without any fixed effects, I get the same results for the random effects. When I enter in the fixed effects, I get a different result for the Site variance...but all other results are the same (both the fixed effects and the other random effects).

There is another methodological issue with the model I am running. I am entering in 17 fixed effects that describe the 15 sites. Therefore, the model is over-specified. As a result, SAS gives a variance estimate of 0 for site (which, in hindsight, makes sense) however, R does not. That is a separate issue that we are dealing with, but I would expect that R and SAS would give the same result. Or maybe at least a warning.

Below is my code and output. I hope the formatting remains so that it is easily readable for everyone. I may also be able to share the data too, but I need to get some approval for that first.

Details
I ran the following code in SAS and R without any fixed effects and both give the same results:

proc mixed data=dat;
class NewSiteID NIOSHID;
model ln_i = ;
random NewSiteID NIOSHID(NewSiteID);
run;

Covariance Parameter Estimates

Cov Parm

Estimate

NewSiteID

6.3433

NIOSHID(NewSiteID)

0.7465

Residual

2.5256


mixedidsite <- lmer(ln_i ~ (1 | NewSiteID/NIOSHID),
                  data = Modeling_Database_Final)
summary(mixedidsite)

Random effects:
Groups                              Name        Variance Std.Dev.
NIOSHID:NewSiteID       (Intercept) 0.7465   0.864
NewSiteID                        (Intercept) 6.3434   2.519
Residual                                                 2.5256   1.589

However, when I add in the fixed effects, I get different results. SAS gives an estimate of 0 for Site while R does not. All other results are the same:

proc mixed data=dat;
class NewSiteID NIOSHID F_mass_handled_or (ref=first); model ln_i = F_High_Exp F_Mat_Type_SW F_Mat_Type_CNF F_Mat_Form_Dry F_Mat_Form_Liq F_Mat_Form_Comp F_Hybrid F_Primary F_Coatings F_mass_handled_or F_adequate F_inadequate F_emp_sc F_diam_sc/solution; random NewSiteID NIOSHID(NewSiteID); run;

Covariance Parameter Estimates

Cov Parm

Estimate

NewSiteID

0

NIOSHID(NewSiteID)

0.6954

Residual

2.5372


Fit Statistics

-2 Res Log Likelihood

961.8

AIC (Smaller is Better)

965.8

AICC (Smaller is Better)

965.9

BIC (Smaller is Better)

967.3


Solution for Fixed Effects

Effect

F_mass_handled_or

Estimate

Standard
Error

DF

t Value

Pr > |t|

Intercept



-139.29

83.6162

92.1

-1.67

0.0991

F_High_Exp



-180.24

102.72

92.6

-1.75

0.0826

F_Mat_Type_SW



470.30

261.53

92.1

1.80

0.0754

F_Mat_Type_CNF



-636.35

347.99

92.1

-1.83

0.0707

F_Mat_Form_Dry



662.26

368.75

92

1.80

0.0758

F_Mat_Form_Liq



-583.14

318.54

92

-1.83

0.0704

F_Mat_Form_Comp



598.77

331.85

92

1.80

0.0745

F_Hybrid



-1197.69

658.23

92

-1.82

0.0721

F_Primary



-639.93

352.80

92

-1.81

0.0730

F_Coatings



92.7949

50.7416

92.1

1.83

0.0707

F_mass_handled_or

F2

134.91

77.2496

92

1.75

0.0841

F_mass_handled_or

F3

-1235.37

677.42

92

-1.82

0.0715

F_mass_handled_or

F4

137.71

75.9370

92

1.81

0.0730

F_mass_handled_or

F1

0

.

.

.

.

F_adequate



139.45

76.5607

92

1.82

0.0718

F_inadequate



1395.04

767.40

92

1.82

0.0723

F_emp_sc



-1259.21

691.98

92

-1.82

0.0721

F_diam_sc



-20.1875

9.9710

89.5

-2.02

0.0459


mixedidsite <- lmer(ln_i ~ (1 | NewSiteID/NIOSHID)  + F_High_Exp + F_Mat_Type_SW +
                    F_Mat_Type_CNF + F_Mat_Form_Dry + F_Mat_Form_Liq + F_Mat_Form_Comp +
                    F_Hybrid + F_Primary + F_Coatings + F_adequate +
                    F_inadequate + F_emp_sc + F_diam_sc,
                  data = Modeling_Database_Final)
summary(mixedidsite)

REML criterion at convergence: 961.8

Scaled residuals:
  Min      1Q  Median      3Q     Max
-2.3019 -0.5248 -0.1668  0.3511  4.7091

Random effects:
Groups                              Name        Variance Std.Dev.
NIOSHID:NewSiteID       (Intercept) 0.6954   0.8339
NewSiteID                        (Intercept) 1.5932   1.2622
Residual                                                2.5372   1.5929
Number of obs: 252, groups:  NIOSHID:NewSiteID, 127; NewSiteID, 15

Fixed effects:
                                                         Estimate Std. Error t value
(Intercept)                                       -139.292     83.702  -1.664
F_High_Exp                                      -180.239    102.778  -1.754
F_Mat_Type_SW                            470.297    261.537   1.798
F_Mat_Type_CNF                           -636.352    347.993  -1.829
F_Mat_Form_Dry                            662.263    368.761   1.796
F_Mat_Form_Liq                            -583.142    318.541  -1.831
F_Mat_Form_Comp                       598.774    331.856   1.804
F_Hybrid                                           -1197.691    658.229  -1.820
F_Primary                                        -639.928    352.811  -1.814
F_Coatings                                       92.795     50.804   1.826
F_mass_handled_orF2: 10 -         134.912     77.291   1.746
F_mass_handled_orF3: 101         -1235.372    677.423  -1.824
F_mass_handled_orF4: >1 k        137.714     75.958   1.813
F_adequate                                     139.446     76.582   1.821
F_inadequate                                  1395.036    767.413   1.818
F_emp_sc                                         -1259.213    691.979  -1.820
F_diam_sc                                        -20.188      9.971  -2.025

Again, the SAS results make sense...that there is 0 variance left over from the fully specified fixed effects. I am fairly certain the combination of the fixed effects uniquely identifies each facility. However, why doesn't R give a 0 variance? What is different between the two methods?


      [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models




This electronic message contains information generated by the USDA solely for the intended recipients. Any unauthorized interception of this message or the use or disclosure of the information it contains may violate the law and subject the violator to civil or criminal penalties. If you believe you have received this message in error, please notify the sender and delete the email immediately.
_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


	[[alternative HTML version deleted]]


From bbolker at gmail.com  Thu Feb 15 23:21:29 2018
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 15 Feb 2018 17:21:29 -0500
Subject: [R-sig-ME] Mixed Models in SAS and R
In-Reply-To: <609AC930-FA1A-4802-8AFA-D736AC6E0516@anu.edu.au>
References: <f1d15f0590834749893b287bb5063489@cdc.gov>
 <CAJuCY5xAZ-tdBJEKQ3mcapX7k+U1FpTUA=7NU199udOyy0km-g@mail.gmail.com>
 <dee7ea0144f44c368d860229d8557aa7@cdc.gov>
 <19AD1067-DC95-41F3-8533-1DAAA5038329@mac.com>
 <f525db1427114cec89448ff5f586c2ef@cdc.gov>
 <e7c4f9a5e80147faa11a7028334680dc@DM2F00105MB0153.001f.mgd2.msft.net>
 <7c1098f404f3469d9c9dfad96369dc85@cdc.gov>
 <609AC930-FA1A-4802-8AFA-D736AC6E0516@anu.edu.au>
Message-ID: <00896cb3-18ae-f603-4873-f96c303eeaf5@gmail.com>


   Everything here is true, or at least reasonable, but not related to
the original question.

 1. I believe the original question has identified (1) a potentially
interesting question about differences between REML and ML estimation
for a poorly posed model [alternatively one could say "it's poorly
posed, I don't care how it works"] and (2) a potential
problem/bug/infelicity where lmer fails to warn of the ill-posedness _on
some platforms_. (The conversation is continuing on CrossValidated:
https://stats.stackexchange.com/questions/328712/why-does-lmer-unlike-sas-output-a-non-zero-variance-of-random-effect-if-it-is/328845
)

2. If you can figure out how to make lmer work with negative variances
without completely breaking the linear algebra, I'd be interested to
hear about it. (I don't think I can say for sure that I'd accept a pull
request -- Doug and Martin might have perfectly reasonable philosophical
reservations.)  I suspect it will be very hard or impossible, although
I'm happy to be proved wrong.

3. IMO the correct way to handle the case you've suggested is to allow
for compound symmetric variance structures.  I believe glmmTMB can do
this, and the flexLambda branch of lme4 can do this, and it can
certainly be hacked by someone who wants to do it. I would dearly like
to find the time and energy to make the production version of lme4
capable of this, but holding your breath is not recommended.

On 18-02-15 04:07 PM, John Maindonald wrote:
> The lme4 code, in a practice designed to preserve its vision of mathematical purity,
> constrains the variance estimates to be non-negative.  That makes sense if one
> can be sure that the model is tuned to the circumstances that generated the data.
> 
> The negative variances that some of the other mixed modeling software allows can
> be a useful diagnostic, indicating for example an inappropriate experimental design.
> I have mentioned previously the example once mentioned to me, and which would
> be easy to simulate, where blocks in a field block experimental design had been
> laid out at right angles to a river bank.  A negative block variance estimate was
> required to give a variance-covariance matrix which had all the mathematical
> respectability that anyone might want.
> 
> There are circumstances where it is useful to constrain the variance estimates to
> be non-negative ? it would be useful to have a choice.
> 
> 
> John Maindonald             email: john.maindonald at anu.edu.au<mailto:john.maindonald at anu.edu.au>
> 
> On 16/02/2018, at 07:25, Bertke, Stephen (CDC/NIOSH/DSHEFS) <inh4 at cdc.gov<mailto:inh4 at cdc.gov>> wrote:
> 
> And this might be a very dumb question, but I thought that the Hessian was related to the variance estimates. SO if the Hessian has a negative eigenvalue, wouldn?t one of the variance estimates be negative?.....I thought that is what happens in SAS, and instead of reporting a negative variance estimate it bounds the estimate at 0.
> 
> But it has been a while since I have gotten deep into the theory behind these models, so I may be completely wrong.....and if so, we can just leave it at that.
> 
> -----Original Message-----
> From: Baldwin, Jim -FS [mailto:jbaldwin at fs.fed.us]
> Sent: Thursday, February 15, 2018 11:50 AM
> To: Bertke, Stephen (CDC/NIOSH/DSHEFS) <inh4 at cdc.gov<mailto:inh4 at cdc.gov>>; Peter Claussen <dakotajudo at mac.com<mailto:dakotajudo at mac.com>>
> Cc: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
> Subject: RE: [R-sig-ME] Mixed Models in SAS and R
> 
> Shows up for me at the very end of the summary.  What version of R and lme4 are you using?
> 
> summary(l)
> Linear mixed model fit by REML ['lmerMod']
> Formula: y ~ (1 | site) + site
>   Data: fake_data
> 
> REML criterion at convergence: 49.7
> 
> Scaled residuals:
>    Min      1Q  Median      3Q     Max
> -1.8662 -0.5452 -0.1016  0.7029  1.8630
> 
> Random effects:
> Groups   Name        Variance Std.Dev.
> site     (Intercept) 4.5429   2.1314
> Residual             0.7182   0.8475
> Number of obs: 20, groups:  site, 2
> 
> Fixed effects:
>            Estimate Std. Error t value
> (Intercept)    6.171      2.148   2.872
> site2         -2.808      3.038  -0.924
> 
> Correlation of Fixed Effects:
>      (Intr)
> site2 -0.707
> convergence code: 0
> unable to evaluate scaled gradient
> Model failed to converge: degenerate  Hessian with 1 negative eigenvalues
> 
> 
> 
> 
> Jim Baldwin, PhD
> Station Statistician
> Forest Service
> Pacific Southwest Research Station
> 
> 
> 
> -----Original Message-----
> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Bertke, Stephen (CDC/NIOSH/DSHEFS)
> Sent: Thursday, February 15, 2018 8:46 AM
> To: Peter Claussen <dakotajudo at mac.com<mailto:dakotajudo at mac.com>>
> Cc: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
> Subject: Re: [R-sig-ME] Mixed Models in SAS and R
> 
> I do not see any errors in R. What I posted is the entire output from running summary(). Is there something else I should be asking for?
> 
> From: Peter Claussen [mailto:dakotajudo at mac.com]
> Sent: Thursday, February 15, 2018 11:15 AM
> To: Bertke, Stephen (CDC/NIOSH/DSHEFS) <inh4 at cdc.gov<mailto:inh4 at cdc.gov>>
> Cc: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
> Subject: Re: [R-sig-ME] Mixed Models in SAS and R
> 
> I posted a response on stackexchange; I don?t think this is an R specific issue - SAS reports the same problem for your test data.
> 
> R is reporting a "degenerate Hessian with 1 negative eigenvalue", SAS reports that "final Hessian is not positive definite? - by definition, a positive definite matrix is a symmetric matrix with all positive eigenvalues.
> 
> Cheers,
> 
> 
> 
> On Feb 15, 2018, at 9:56 AM, Bertke, Stephen (CDC/NIOSH/DSHEFS) <inh4 at cdc.gov<mailto:inh4 at cdc.gov><mailto:inh4 at cdc.gov>> wrote:
> 
> Sorry for all the emails, but I have edited/simplified my question to what I believe is the root issue as well as posted simulated data to test with:
> 
> https://stats.stackexchange.com/questions/328712/lmer-vs-proc-mixed-output
> 
> 
> 
> -----Original Message-----
> From: Bertke, Stephen (CDC/NIOSH/DSHEFS)
> Sent: Wednesday, February 14, 2018 2:25 PM
> To: 'Thierry Onkelinx' <thierry.onkelinx at inbo.be<mailto:thierry.onkelinx at inbo.be>>
> Cc: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
> Subject: RE: [R-sig-ME] Mixed Models in SAS and R
> 
> I posted the question on stackoverflow here:
> https://stackoverflow.com/questions/48794651/lmer-vs-proc-mixed-output
> 
> This will hopefully make reading my code and output easier.
> 
> I would expect a 0 variance since I am in essence fitting a model with both the site variable in the fixed and random part of the model. I actually went ahead and fit that "dumb" model in both SAS and R and once again, all results are nearly identical except SAS estimates a 0 variance and R estimates a relatively large positive variance. However, R now gives an error/warning at the bottom of the results indicating an issue with this very dumb model. Again, those results are in the above link.
> 
> 
> 
> 
> -----Original Message-----
> From: Thierry Onkelinx [mailto:thierry.onkelinx at inbo.be]
> Sent: Wednesday, February 14, 2018 11:39 AM
> To: Bertke, Stephen (CDC/NIOSH/DSHEFS) <inh4 at cdc.gov<mailto:inh4 at cdc.gov>>
> Cc: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
> Subject: Re: [R-sig-ME] Mixed Models in SAS and R
> 
> Dear Stephen,
> 
> The list removes all HTML formating, making your post hard to read.
> Please use only plain text when posting.
> 
> You'll need to make sure that you fit exactly the same model in SAS as in R. Not everyone here speaks SAS. Providing the math equation for the SAS model would help.
> 
> Also please elaborate why it makes sense that the variance of site should be zero. We cannot verify that statement based on the information you provide.
> 
> Best regards,
> 
> ir. Thierry Onkelinx
> Statisticus / Statistician
> 
> Vlaamse Overheid / Government of Flanders INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND FOREST Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance thierry.onkelinx at inbo.be<mailto:thierry.onkelinx at inbo.be> Havenlaan 88 bus 73, 1000 Brussel www.inbo.be<http://www.inbo.be>
> 
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher The plural of anecdote is not data. ~ Roger Brinner The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey ///////////////////////////////////////////////////////////////////////////////////////////
> 
> 
> 
> 
> 2018-02-14 17:07 GMT+01:00 Bertke, Stephen (CDC/NIOSH/DSHEFS) <inh4 at cdc.gov<mailto:inh4 at cdc.gov>>:
> 
> Hello everyone. I have just joined this mailing list so I wanted to introduce myself as well as ask a question.
> 
> My name is Steve Bertke and I am a researcher at the National Institute for Occupational Safety and Health (NIOSH) which is one of the centers within the Centers for Disease Control and Prevention (CDC). I am a long-time SAS user but have been slowly finding myself using and liking R. I have found the support community for R very helpful and rewarding and am looking forward to contributing my part.
> 
> On to my question.
> 
> I have ran the same model (I think) in both SAS (proc mixed) and R (lmer) but have gotten different results for the random terms.
> 
> A quick background, we took 2 personal air samples for 127 people at 15 different factories for a total of 252 samples (after dropping 2 samples). We are trying to model various factors of the factory on the air samples. To do so, we need to control for the repeated measure of the person (nested within factory) as well as the random factory effect.
> 
> You can see below for the exact code and exact results, but in short, when I run the models in R and SAS without any fixed effects, I get the same results for the random effects. When I enter in the fixed effects, I get a different result for the Site variance...but all other results are the same (both the fixed effects and the other random effects).
> 
> There is another methodological issue with the model I am running. I am entering in 17 fixed effects that describe the 15 sites. Therefore, the model is over-specified. As a result, SAS gives a variance estimate of 0 for site (which, in hindsight, makes sense) however, R does not. That is a separate issue that we are dealing with, but I would expect that R and SAS would give the same result. Or maybe at least a warning.
> 
> Below is my code and output. I hope the formatting remains so that it is easily readable for everyone. I may also be able to share the data too, but I need to get some approval for that first.
> 
> Details
> I ran the following code in SAS and R without any fixed effects and both give the same results:
> 
> proc mixed data=dat;
> class NewSiteID NIOSHID;
> model ln_i = ;
> random NewSiteID NIOSHID(NewSiteID);
> run;
> 
> Covariance Parameter Estimates
> 
> Cov Parm
> 
> Estimate
> 
> NewSiteID
> 
> 6.3433
> 
> NIOSHID(NewSiteID)
> 
> 0.7465
> 
> Residual
> 
> 2.5256
> 
> 
> mixedidsite <- lmer(ln_i ~ (1 | NewSiteID/NIOSHID),
>                   data = Modeling_Database_Final)
> summary(mixedidsite)
> 
> Random effects:
> Groups                              Name        Variance Std.Dev.
> NIOSHID:NewSiteID       (Intercept) 0.7465   0.864
> NewSiteID                        (Intercept) 6.3434   2.519
> Residual                                                 2.5256   1.589
> 
> However, when I add in the fixed effects, I get different results. SAS gives an estimate of 0 for Site while R does not. All other results are the same:
> 
> proc mixed data=dat;
> class NewSiteID NIOSHID F_mass_handled_or (ref=first); model ln_i = F_High_Exp F_Mat_Type_SW F_Mat_Type_CNF F_Mat_Form_Dry F_Mat_Form_Liq F_Mat_Form_Comp F_Hybrid F_Primary F_Coatings F_mass_handled_or F_adequate F_inadequate F_emp_sc F_diam_sc/solution; random NewSiteID NIOSHID(NewSiteID); run;
> 
> Covariance Parameter Estimates
> 
> Cov Parm
> 
> Estimate
> 
> NewSiteID
> 
> 0
> 
> NIOSHID(NewSiteID)
> 
> 0.6954
> 
> Residual
> 
> 2.5372
> 
> 
> Fit Statistics
> 
> -2 Res Log Likelihood
> 
> 961.8
> 
> AIC (Smaller is Better)
> 
> 965.8
> 
> AICC (Smaller is Better)
> 
> 965.9
> 
> BIC (Smaller is Better)
> 
> 967.3
> 
> 
> Solution for Fixed Effects
> 
> Effect
> 
> F_mass_handled_or
> 
> Estimate
> 
> Standard
> Error
> 
> DF
> 
> t Value
> 
> Pr > |t|
> 
> Intercept
> 
> 
> 
> -139.29
> 
> 83.6162
> 
> 92.1
> 
> -1.67
> 
> 0.0991
> 
> F_High_Exp
> 
> 
> 
> -180.24
> 
> 102.72
> 
> 92.6
> 
> -1.75
> 
> 0.0826
> 
> F_Mat_Type_SW
> 
> 
> 
> 470.30
> 
> 261.53
> 
> 92.1
> 
> 1.80
> 
> 0.0754
> 
> F_Mat_Type_CNF
> 
> 
> 
> -636.35
> 
> 347.99
> 
> 92.1
> 
> -1.83
> 
> 0.0707
> 
> F_Mat_Form_Dry
> 
> 
> 
> 662.26
> 
> 368.75
> 
> 92
> 
> 1.80
> 
> 0.0758
> 
> F_Mat_Form_Liq
> 
> 
> 
> -583.14
> 
> 318.54
> 
> 92
> 
> -1.83
> 
> 0.0704
> 
> F_Mat_Form_Comp
> 
> 
> 
> 598.77
> 
> 331.85
> 
> 92
> 
> 1.80
> 
> 0.0745
> 
> F_Hybrid
> 
> 
> 
> -1197.69
> 
> 658.23
> 
> 92
> 
> -1.82
> 
> 0.0721
> 
> F_Primary
> 
> 
> 
> -639.93
> 
> 352.80
> 
> 92
> 
> -1.81
> 
> 0.0730
> 
> F_Coatings
> 
> 
> 
> 92.7949
> 
> 50.7416
> 
> 92.1
> 
> 1.83
> 
> 0.0707
> 
> F_mass_handled_or
> 
> F2
> 
> 134.91
> 
> 77.2496
> 
> 92
> 
> 1.75
> 
> 0.0841
> 
> F_mass_handled_or
> 
> F3
> 
> -1235.37
> 
> 677.42
> 
> 92
> 
> -1.82
> 
> 0.0715
> 
> F_mass_handled_or
> 
> F4
> 
> 137.71
> 
> 75.9370
> 
> 92
> 
> 1.81
> 
> 0.0730
> 
> F_mass_handled_or
> 
> F1
> 
> 0
> 
> .
> 
> .
> 
> .
> 
> .
> 
> F_adequate
> 
> 
> 
> 139.45
> 
> 76.5607
> 
> 92
> 
> 1.82
> 
> 0.0718
> 
> F_inadequate
> 
> 
> 
> 1395.04
> 
> 767.40
> 
> 92
> 
> 1.82
> 
> 0.0723
> 
> F_emp_sc
> 
> 
> 
> -1259.21
> 
> 691.98
> 
> 92
> 
> -1.82
> 
> 0.0721
> 
> F_diam_sc
> 
> 
> 
> -20.1875
> 
> 9.9710
> 
> 89.5
> 
> -2.02
> 
> 0.0459
> 
> 
> mixedidsite <- lmer(ln_i ~ (1 | NewSiteID/NIOSHID)  + F_High_Exp + F_Mat_Type_SW +
>                     F_Mat_Type_CNF + F_Mat_Form_Dry + F_Mat_Form_Liq + F_Mat_Form_Comp +
>                     F_Hybrid + F_Primary + F_Coatings + F_adequate +
>                     F_inadequate + F_emp_sc + F_diam_sc,
>                   data = Modeling_Database_Final)
> summary(mixedidsite)
> 
> REML criterion at convergence: 961.8
> 
> Scaled residuals:
>   Min      1Q  Median      3Q     Max
> -2.3019 -0.5248 -0.1668  0.3511  4.7091
> 
> Random effects:
> Groups                              Name        Variance Std.Dev.
> NIOSHID:NewSiteID       (Intercept) 0.6954   0.8339
> NewSiteID                        (Intercept) 1.5932   1.2622
> Residual                                                2.5372   1.5929
> Number of obs: 252, groups:  NIOSHID:NewSiteID, 127; NewSiteID, 15
> 
> Fixed effects:
>                                                          Estimate Std. Error t value
> (Intercept)                                       -139.292     83.702  -1.664
> F_High_Exp                                      -180.239    102.778  -1.754
> F_Mat_Type_SW                            470.297    261.537   1.798
> F_Mat_Type_CNF                           -636.352    347.993  -1.829
> F_Mat_Form_Dry                            662.263    368.761   1.796
> F_Mat_Form_Liq                            -583.142    318.541  -1.831
> F_Mat_Form_Comp                       598.774    331.856   1.804
> F_Hybrid                                           -1197.691    658.229  -1.820
> F_Primary                                        -639.928    352.811  -1.814
> F_Coatings                                       92.795     50.804   1.826
> F_mass_handled_orF2: 10 -         134.912     77.291   1.746
> F_mass_handled_orF3: 101         -1235.372    677.423  -1.824
> F_mass_handled_orF4: >1 k        137.714     75.958   1.813
> F_adequate                                     139.446     76.582   1.821
> F_inadequate                                  1395.036    767.413   1.818
> F_emp_sc                                         -1259.213    691.979  -1.820
> F_diam_sc                                        -20.188      9.971  -2.025
> 
> Again, the SAS results make sense...that there is 0 variance left over from the fully specified fixed effects. I am fairly certain the combination of the fixed effects uniquely identifies each facility. However, why doesn't R give a 0 variance? What is different between the two methods?
> 
> 
>       [[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> _______________________________________________
> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
> [[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
> 
> 
> This electronic message contains information generated by the USDA solely for the intended recipients. Any unauthorized interception of this message or the use or disclosure of the information it contains may violate the law and subject the violator to civil or criminal penalties. If you believe you have received this message in error, please notify the sender and delete the email immediately.
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From juliachacon at gmail.com  Sat Feb 17 11:54:56 2018
From: juliachacon at gmail.com (Julia Chacon Labella)
Date: Sat, 17 Feb 2018 11:54:56 +0100
Subject: [R-sig-ME] random intercept or nested random?
Message-ID: <CAPsE2jxQhR=r5fMw1YuBziR-E+umbd75bQqWk0TgRQyXcRE4Hw@mail.gmail.com>

Hello to everybody,

I have read that in some cases the same variable could be consider either a
random or a fixed effect at the same time. But do not have any example for
this. Could someone explain me when is this the case? When there is a
justification to considered a variable in fixed effect term of the model
and also in the random part? I am quite interested on that.

I am thinking in the next example:

Imagine we are interested in knowing if the exam marks of pupils depends on
their Sex. So, you choose two different schools to check for this, but
School 1 is only for boys and School 2 is only for girls. Within each
school you sample many classes.

So, we would have ExamMarks as response variable.

SchoolSex as explanatory variable (in this given example would be the same
School or Sex), with two levels SchoolBoys and SchoolGirls

Class as explanatory variable, with many levels (8 per school), coded as
Class1, Class 2....up to Class16.

The model would be (lme4):

lmer(exammarks ~ Schoolsex + (1|Class), data=data)

So, we treat class as a random factor.

Should we consider in this case, the random part of the model as a nested
random and specify  it as (1|Class|Schoolsex) ?

In that case the model would be:
lmer(ExamMarks ~ Schoolsex + (1|Class|Schoolsex), data=data)

Thank you very much,
Julia

	[[alternative HTML version deleted]]


From j.klaus at donders.ru.nl  Mon Feb 19 10:25:25 2018
From: j.klaus at donders.ru.nl (Klaus, J. (Jana))
Date: Mon, 19 Feb 2018 10:25:25 +0100
Subject: [R-sig-ME] degrees of freedom in Gamma GLMMs
Message-ID: <003401d3a963$92e84b70$b8b8e250$@donders.ru.nl>

Hi all,

 

I have fitted a GLMM with a Gamma distribution with crossed random effects in lme4 for reaction times, like this:

 

model = glmer(RT~Factor1*Factor2+ (1+Factor1+Factor2|subj) + (1+Factor1|item), data=xdat, family = Gamma(link = "identity"), control=glmerControl(optimizer = "bobyqa"))

 

The editor now insists on reporting degrees of freedom. From what I have found online, this is not trivial, and potentially not at all possible with the design. I fit the same model with glmmPQL but I cannot reproduce the results, presumably because the random effects are treated as nested rather than crossed there. Also, as far as I can tell, all other workarounds to compute dfs do not apply to this specific design. Nevertheless, I?m afraid I might be overlooking something essential already implemented in lme4 (or any other package for that matter). If this is not the case, could you point me towards any work that explains *why* it can?t be done for GLMMs? Any help is greatly appreciated!

 

Cheers,

Jana


	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Mon Feb 19 10:53:03 2018
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Mon, 19 Feb 2018 10:53:03 +0100
Subject: [R-sig-ME] random intercept or nested random?
In-Reply-To: <CAPsE2jxQhR=r5fMw1YuBziR-E+umbd75bQqWk0TgRQyXcRE4Hw@mail.gmail.com>
References: <CAPsE2jxQhR=r5fMw1YuBziR-E+umbd75bQqWk0TgRQyXcRE4Hw@mail.gmail.com>
Message-ID: <CAJuCY5xfwxmsMfCJPLod=w=srqEKiTEFfu=5Ue57rS3rPFCc1g@mail.gmail.com>

Dear Julia,

I wrote a blogpost on this: https://www.muscardinus.be/2017/08/fixed-and-random/

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
AND FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////




2018-02-17 11:54 GMT+01:00 Julia Chacon Labella <juliachacon at gmail.com>:
> Hello to everybody,
>
> I have read that in some cases the same variable could be consider either a
> random or a fixed effect at the same time. But do not have any example for
> this. Could someone explain me when is this the case? When there is a
> justification to considered a variable in fixed effect term of the model
> and also in the random part? I am quite interested on that.
>
> I am thinking in the next example:
>
> Imagine we are interested in knowing if the exam marks of pupils depends on
> their Sex. So, you choose two different schools to check for this, but
> School 1 is only for boys and School 2 is only for girls. Within each
> school you sample many classes.
>
> So, we would have ExamMarks as response variable.
>
> SchoolSex as explanatory variable (in this given example would be the same
> School or Sex), with two levels SchoolBoys and SchoolGirls
>
> Class as explanatory variable, with many levels (8 per school), coded as
> Class1, Class 2....up to Class16.
>
> The model would be (lme4):
>
> lmer(exammarks ~ Schoolsex + (1|Class), data=data)
>
> So, we treat class as a random factor.
>
> Should we consider in this case, the random part of the model as a nested
> random and specify  it as (1|Class|Schoolsex) ?
>
> In that case the model would be:
> lmer(ExamMarks ~ Schoolsex + (1|Class|Schoolsex), data=data)
>
> Thank you very much,
> Julia
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From singmann at psychologie.uzh.ch  Mon Feb 19 11:27:00 2018
From: singmann at psychologie.uzh.ch (Henrik Singmann)
Date: Mon, 19 Feb 2018 11:27:00 +0100
Subject: [R-sig-ME] degrees of freedom in Gamma GLMMs
In-Reply-To: <003401d3a963$92e84b70$b8b8e250$@donders.ru.nl>
References: <003401d3a963$92e84b70$b8b8e250$@donders.ru.nl>
Message-ID: <66f37356-2d33-e06b-376c-c608b27efcaa@psychologie.uzh.ch>

Hi Jana,

If you want degrees of freedom, you could use package afex which allows 
you to calculate likelihood-ratio tests for the fixed effects. This way 
you can simply report chi-square tests with df equal to the number of 
omitted parameters for each test. For example:

library("afex")
data("fhch2010") # load Freeman, Heathcote, Chalmers, and Hockley (2010) 
data
fhch <- droplevels(fhch2010[ fhch2010$correct,]) # remove errors

m1s <- mixed(rt ~ task*stimulus + (stimulus|id) + (task|item),
              fhch, method = "LRT", family = Gamma(link = "identity"))
m1s
# Mixed Model Anova Table (Type 3 tests, LRT-method)
#
# Model: rt ~ task * stimulus + (stimulus | id) + (task | item)
# Data: fhch
# Df full model: 11
#          Effect df     Chisq p.value
# 1          task  1 14.43 ***   .0001
# 2      stimulus  1 28.37 ***  <.0001
# 3 task:stimulus  1 12.11 ***   .0005
# ---
# Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?+? 0.1 ? ? 1
(For simplicity I have omitted convergence warnings from the output.)

Note that the values of the test statistics reported can be different 
from the ones reported by glmer directly, because they are based on 
comparing a full model against a reduced model in which each effect is 
omitted. However, models are also estimated with lme4::glmer.

I would report the main effect of task as: chi^2(1) = 14.43, p = .0001 
(replace chi with the greek symbol and ^2 with power of two).

Hope that helps,
Henrik


Am 19.02.2018 um 10:25 schrieb Klaus, J. (Jana):
> Hi all,
> 
>   
> 
> I have fitted a GLMM with a Gamma distribution with crossed random effects in lme4 for reaction times, like this:
> 
>   
> 
> model = glmer(RT~Factor1*Factor2+ (1+Factor1+Factor2|subj) + (1+Factor1|item), data=xdat, family = Gamma(link = "identity"), control=glmerControl(optimizer = "bobyqa"))
> 
>   
> 
> The editor now insists on reporting degrees of freedom. From what I have found online, this is not trivial, and potentially not at all possible with the design. I fit the same model with glmmPQL but I cannot reproduce the results, presumably because the random effects are treated as nested rather than crossed there. Also, as far as I can tell, all other workarounds to compute dfs do not apply to this specific design. Nevertheless, I?m afraid I might be overlooking something essential already implemented in lme4 (or any other package for that matter). If this is not the case, could you point me towards any work that explains *why* it can?t be done for GLMMs? Any help is greatly appreciated!
> 
>   
> 
> Cheers,
> 
> Jana
> 
> 
> 	[[alternative HTML version deleted]]
>


From bbolker at gmail.com  Mon Feb 19 13:37:16 2018
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 19 Feb 2018 07:37:16 -0500
Subject: [R-sig-ME] degrees of freedom in Gamma GLMMs
In-Reply-To: <66f37356-2d33-e06b-376c-c608b27efcaa@psychologie.uzh.ch>
References: <003401d3a963$92e84b70$b8b8e250$@donders.ru.nl>
 <66f37356-2d33-e06b-376c-c608b27efcaa@psychologie.uzh.ch>
Message-ID: <CABghstRf=dyN47hK5q4ND7HPyhj7wCWhYKQhmm8ErB2TTQot=A@mail.gmail.com>

I wonder if the editor is asking for *denominator* degrees of freedom.

This is a tough one; if it were not a crossed-random-effects model you
could use classic parameter/level-counting approaches as in lme.
I believe SAS has Kenward-Roger implemented for GLMMs, but the only
published justification I know for this (K-R was derived for LMMs, not
GLMMs)
is a suggestion in Stroup's book that it seems to work reasonably well.

You (1) could ask the editor how they actually suggest you do this,
(2) report just the numerator/model-difference df and see if you get
away with it, (3) report the
*minimum* df (minimum number of groups involved in estimation of an effect)

https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#why-doesnt-lme4-display-denominator-degrees-of-freedomp-values-what-other-options-do-i-have


On Mon, Feb 19, 2018 at 5:27 AM, Henrik Singmann
<singmann at psychologie.uzh.ch> wrote:
> Hi Jana,
>
> If you want degrees of freedom, you could use package afex which allows you
> to calculate likelihood-ratio tests for the fixed effects. This way you can
> simply report chi-square tests with df equal to the number of omitted
> parameters for each test. For example:
>
> library("afex")
> data("fhch2010") # load Freeman, Heathcote, Chalmers, and Hockley (2010)
> data
> fhch <- droplevels(fhch2010[ fhch2010$correct,]) # remove errors
>
> m1s <- mixed(rt ~ task*stimulus + (stimulus|id) + (task|item),
>              fhch, method = "LRT", family = Gamma(link = "identity"))
> m1s
> # Mixed Model Anova Table (Type 3 tests, LRT-method)
> #
> # Model: rt ~ task * stimulus + (stimulus | id) + (task | item)
> # Data: fhch
> # Df full model: 11
> #          Effect df     Chisq p.value
> # 1          task  1 14.43 ***   .0001
> # 2      stimulus  1 28.37 ***  <.0001
> # 3 task:stimulus  1 12.11 ***   .0005
> # ---
> # Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?+? 0.1 ? ? 1
> (For simplicity I have omitted convergence warnings from the output.)
>
> Note that the values of the test statistics reported can be different from
> the ones reported by glmer directly, because they are based on comparing a
> full model against a reduced model in which each effect is omitted. However,
> models are also estimated with lme4::glmer.
>
> I would report the main effect of task as: chi^2(1) = 14.43, p = .0001
> (replace chi with the greek symbol and ^2 with power of two).
>
> Hope that helps,
> Henrik
>
>
>
> Am 19.02.2018 um 10:25 schrieb Klaus, J. (Jana):
>>
>> Hi all,
>>
>>
>> I have fitted a GLMM with a Gamma distribution with crossed random effects
>> in lme4 for reaction times, like this:
>>
>>
>> model = glmer(RT~Factor1*Factor2+ (1+Factor1+Factor2|subj) +
>> (1+Factor1|item), data=xdat, family = Gamma(link = "identity"),
>> control=glmerControl(optimizer = "bobyqa"))
>>
>>
>> The editor now insists on reporting degrees of freedom. From what I have
>> found online, this is not trivial, and potentially not at all possible with
>> the design. I fit the same model with glmmPQL but I cannot reproduce the
>> results, presumably because the random effects are treated as nested rather
>> than crossed there. Also, as far as I can tell, all other workarounds to
>> compute dfs do not apply to this specific design. Nevertheless, I?m afraid I
>> might be overlooking something essential already implemented in lme4 (or any
>> other package for that matter). If this is not the case, could you point me
>> towards any work that explains *why* it can?t be done for GLMMs? Any help is
>> greatly appreciated!
>>
>>
>> Cheers,
>>
>> Jana
>>
>>
>>         [[alternative HTML version deleted]]
>>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From singmann at psychologie.uzh.ch  Mon Feb 19 13:53:52 2018
From: singmann at psychologie.uzh.ch (Henrik Singmann)
Date: Mon, 19 Feb 2018 13:53:52 +0100
Subject: [R-sig-ME] degrees of freedom in Gamma GLMMs
In-Reply-To: <004a01d3a973$a513fc80$ef3bf580$@donders.ru.nl>
References: <004a01d3a973$a513fc80$ef3bf580$@donders.ru.nl>
Message-ID: <67733231-1519-6bd6-d1ed-8b7a3df13ccb@psychologie.uzh.ch>

Dear Julia, (please keep the list in CC)

 From your mail it was not clear you reported t-tests. And in fact, the 
tests reported by glmer() per default are not really t-test but rather 
z-tests. This can be seen by the header of the p-value column. Have a 
look at an example:

summary(m1s)
# [...]
# Fixed effects:
#???????????????? Estimate Std. Error t value Pr(>|z|)
# (Intercept)????? 1.05470??? 0.03709? 28.438? < 2e-16 ***
# task1?????????? -0.15399??? 0.03741? -4.116 3.86e-05 ***
# stimulus1?????? -0.08703??? 0.01325? -6.567 5.14e-11 ***
# task1:stimulus1 -0.05180??? 0.01385? -3.741 0.000184 ***

The p-values can be replicated via the normal distribution (pnorm):

2*pnorm(abs(fixef(m1s$full_model)) /
 ????????? sqrt(diag(vcov(m1s$full_model))), lower.tail = FALSE)
#?? (Intercept)?????????? task1?????? stimulus1 task1:stimulus1
# 6.837380e-178??? 3.858592e-05??? 5.141127e-11??? 1.835465e-04

So one option would be to tell the editors that you can use either 
z-tests or likelihood-ratio tests. In case they do not agree with this 
your best bet might be to follow Ben Bolker's advise and ask them how 
they suggest you calculate them (because it is not really clear how you 
could).

Hope that helps,
Henrik

Am 19.02.2018 um 12:20 schrieb Klaus, J. (Jana):
> Dear Henrik,
>
> Thanks a lot for your response. However, I'm not sure whether this is what the editor wants, as he requested " When you report t-tests, please add the df, using the following format: t(df) = x.xx, p = 0.xx." We responded that no consensus exists as of yet (as opposed to LMMs, even though I understand it is questionable there as well, but can at least be computed with lmerTest) and referenced the Lo & Andrews (2015) paper, to which they said " We found several citations, more recent than 2015,  to counter the Lo and Andrews (2015) position about degrees of freedom in generalized mixed models.  We think that Readers will appreciate knowing fuller details about your statistical approach.  We will also consult with statisticians about this matter, and we may correspond with you." Needless to say they haven't corresponded with me yet...
>
> Also, I'm not sure whether it is feasible to use afex for my dataset, as I only have 32 subjects and 6224 observations - from what I understand from the manual, LRT in afex are only useful with more Ns/observations, no?
>
> Thanks so much,
> Jana
>
> -----Original Message-----
> From: Henrik Singmann [mailto:singmann at psychologie.uzh.ch]
> Sent: maandag 19 februari 2018 11:27
> To: Klaus, J. (Jana) <J.Klaus at psych.ru.nl>
> Subject: !!!!!SPAM!!!!! Re: degrees of freedom in Gamma GLMMs
>
> Hi Jana,
>
> If you want degrees of freedom, you could use package afex which allows
> you to calculate likelihood-ratio tests for the fixed effects. This way
> you can simply report chi-square tests with df equal to the number of
> omitted parameters for each test. For example:
>
> library("afex")
> data("fhch2010") # load Freeman, Heathcote, Chalmers, and Hockley (2010)
> data
> fhch <- droplevels(fhch2010[ fhch2010$correct,]) # remove errors
>
> m1s <- mixed(rt ~ task*stimulus + (stimulus|id) + (task|item),
>                fhch, method = "LRT", family = Gamma(link = "identity"))
> m1s
> # Mixed Model Anova Table (Type 3 tests, LRT-method)
> #
> # Model: rt ~ task * stimulus + (stimulus | id) + (task | item)
> # Data: fhch
> # Df full model: 11
> #          Effect df     Chisq p.value
> # 1          task  1 14.43 ***   .0001
> # 2      stimulus  1 28.37 ***  <.0001
> # 3 task:stimulus  1 12.11 ***   .0005
> # ---
> # Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?+? 0.1 ? ? 1
> (For simplicity I have omitted convergence warnings from the output.)
>
> Note that the values of the test statistics reported can be different
> from the ones reported by glmer directly, because they are based on
> comparing a full model against a reduced model in which each effect is
> omitted. However, models are also estimated with lme4::glmer.
>
> I would report the main effect of task as: chi^2(1) = 14.43, p = .0001
> (replace chi with the greek symbol and ^2 with power of two).
>
> Hope that helps,
> Henrik
>
>
> Am 19.02.2018 um 10:25 schrieb Klaus, J. (Jana):
>> Hi all,
>>
>>    
>>
>> I have fitted a GLMM with a Gamma distribution with crossed random effects in lme4 for reaction times, like this:
>>
>>    
>>
>> model = glmer(RT~Factor1*Factor2+ (1+Factor1+Factor2|subj) + (1+Factor1|item), data=xdat, family = Gamma(link = "identity"), control=glmerControl(optimizer = "bobyqa"))
>>
>>    
>>
>> The editor now insists on reporting degrees of freedom. From what I have found online, this is not trivial, and potentially not at all possible with the design. I fit the same model with glmmPQL but I cannot reproduce the results, presumably because the random effects are treated as nested rather than crossed there. Also, as far as I can tell, all other workarounds to compute dfs do not apply to this specific design. Nevertheless, I?m afraid I might be overlooking something essential already implemented in lme4 (or any other package for that matter). If this is not the case, could you point me towards any work that explains *why* it can?t be done for GLMMs? Any help is greatly appreciated!
>>
>>    
>>
>> Cheers,
>>
>> Jana
>>
>>
>> 	[[alternative HTML version deleted]]
>>
>
>

-- 
Dr. Henrik Singmann
PostDoc
Universit?t Z?rich, Schweiz
http://singmann.org


From bbolker at gmail.com  Mon Feb 19 17:06:05 2018
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 19 Feb 2018 11:06:05 -0500
Subject: [R-sig-ME] degrees of freedom in Gamma GLMMs
In-Reply-To: <67733231-1519-6bd6-d1ed-8b7a3df13ccb@psychologie.uzh.ch>
References: <004a01d3a973$a513fc80$ef3bf580$@donders.ru.nl>
 <67733231-1519-6bd6-d1ed-8b7a3df13ccb@psychologie.uzh.ch>
Message-ID: <CABghstR9yCuNE9LQ_rvMBNDx200dJ2zYVacaG3vT9sZHD42SFQ@mail.gmail.com>

If/when you find out the contradictory citations from the editor,
please forward them to the mailing list -- many of us would be
interested!  From your design, I'm guessing that the "minimal" df
would be (n-1)=31 for Factor2 and min(# items - 1, 31) for Factor1
(that assumes Factor2, Factor1 are numeric or 2-level categorical
variables).



On Mon, Feb 19, 2018 at 7:53 AM, Henrik Singmann
<singmann at psychologie.uzh.ch> wrote:
> Dear Julia, (please keep the list in CC)
>
> From your mail it was not clear you reported t-tests. And in fact, the tests
> reported by glmer() per default are not really t-test but rather z-tests.
> This can be seen by the header of the p-value column. Have a look at an
> example:
>
> summary(m1s)
> # [...]
> # Fixed effects:
> #                 Estimate Std. Error t value Pr(>|z|)
> # (Intercept)      1.05470    0.03709  28.438  < 2e-16 ***
> # task1           -0.15399    0.03741  -4.116 3.86e-05 ***
> # stimulus1       -0.08703    0.01325  -6.567 5.14e-11 ***
> # task1:stimulus1 -0.05180    0.01385  -3.741 0.000184 ***
>
> The p-values can be replicated via the normal distribution (pnorm):
>
> 2*pnorm(abs(fixef(m1s$full_model)) /
>           sqrt(diag(vcov(m1s$full_model))), lower.tail = FALSE)
> #   (Intercept)           task1       stimulus1 task1:stimulus1
> # 6.837380e-178    3.858592e-05    5.141127e-11    1.835465e-04
>
> So one option would be to tell the editors that you can use either z-tests
> or likelihood-ratio tests. In case they do not agree with this your best bet
> might be to follow Ben Bolker's advise and ask them how they suggest you
> calculate them (because it is not really clear how you could).
>
> Hope that helps,
> Henrik
>
> Am 19.02.2018 um 12:20 schrieb Klaus, J. (Jana):
>>
>> Dear Henrik,
>>
>> Thanks a lot for your response. However, I'm not sure whether this is what
>> the editor wants, as he requested " When you report t-tests, please add the
>> df, using the following format: t(df) = x.xx, p = 0.xx." We responded that
>> no consensus exists as of yet (as opposed to LMMs, even though I understand
>> it is questionable there as well, but can at least be computed with
>> lmerTest) and referenced the Lo & Andrews (2015) paper, to which they said "
>> We found several citations, more recent than 2015,  to counter the Lo and
>> Andrews (2015) position about degrees of freedom in generalized mixed
>> models.  We think that Readers will appreciate knowing fuller details about
>> your statistical approach.  We will also consult with statisticians about
>> this matter, and we may correspond with you." Needless to say they haven't
>> corresponded with me yet...
>>
>> Also, I'm not sure whether it is feasible to use afex for my dataset, as I
>> only have 32 subjects and 6224 observations - from what I understand from
>> the manual, LRT in afex are only useful with more Ns/observations, no?
>>
>> Thanks so much,
>> Jana
>>
>>
>> -----Original Message-----
>> From: Henrik Singmann [mailto:singmann at psychologie.uzh.ch]
>> Sent: maandag 19 februari 2018 11:27
>> To: Klaus, J. (Jana) <J.Klaus at psych.ru.nl>
>> Subject: !!!!!SPAM!!!!! Re: degrees of freedom in Gamma GLMMs
>>
>> Hi Jana,
>>
>> If you want degrees of freedom, you could use package afex which allows
>> you to calculate likelihood-ratio tests for the fixed effects. This way
>> you can simply report chi-square tests with df equal to the number of
>> omitted parameters for each test. For example:
>>
>> library("afex")
>> data("fhch2010") # load Freeman, Heathcote, Chalmers, and Hockley (2010)
>> data
>> fhch <- droplevels(fhch2010[ fhch2010$correct,]) # remove errors
>>
>> m1s <- mixed(rt ~ task*stimulus + (stimulus|id) + (task|item),
>>                fhch, method = "LRT", family = Gamma(link = "identity"))
>> m1s
>> # Mixed Model Anova Table (Type 3 tests, LRT-method)
>> #
>> # Model: rt ~ task * stimulus + (stimulus | id) + (task | item)
>> # Data: fhch
>> # Df full model: 11
>> #          Effect df     Chisq p.value
>> # 1          task  1 14.43 ***   .0001
>> # 2      stimulus  1 28.37 ***  <.0001
>> # 3 task:stimulus  1 12.11 ***   .0005
>> # ---
>> # Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?+? 0.1 ? ? 1
>> (For simplicity I have omitted convergence warnings from the output.)
>>
>> Note that the values of the test statistics reported can be different
>> from the ones reported by glmer directly, because they are based on
>> comparing a full model against a reduced model in which each effect is
>> omitted. However, models are also estimated with lme4::glmer.
>>
>> I would report the main effect of task as: chi^2(1) = 14.43, p = .0001
>> (replace chi with the greek symbol and ^2 with power of two).
>>
>> Hope that helps,
>> Henrik
>>
>>
>> Am 19.02.2018 um 10:25 schrieb Klaus, J. (Jana):
>>>
>>> Hi all,
>>>
>>>
>>> I have fitted a GLMM with a Gamma distribution with crossed random
>>> effects in lme4 for reaction times, like this:
>>>
>>>
>>> model = glmer(RT~Factor1*Factor2+ (1+Factor1+Factor2|subj) +
>>> (1+Factor1|item), data=xdat, family = Gamma(link = "identity"),
>>> control=glmerControl(optimizer = "bobyqa"))
>>>
>>>
>>> The editor now insists on reporting degrees of freedom. From what I have
>>> found online, this is not trivial, and potentially not at all possible with
>>> the design. I fit the same model with glmmPQL but I cannot reproduce the
>>> results, presumably because the random effects are treated as nested rather
>>> than crossed there. Also, as far as I can tell, all other workarounds to
>>> compute dfs do not apply to this specific design. Nevertheless, I?m afraid I
>>> might be overlooking something essential already implemented in lme4 (or any
>>> other package for that matter). If this is not the case, could you point me
>>> towards any work that explains *why* it can?t be done for GLMMs? Any help is
>>> greatly appreciated!
>>>
>>>
>>> Cheers,
>>>
>>> Jana
>>>
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>
>>
>
> --
> Dr. Henrik Singmann
> PostDoc
> Universit?t Z?rich, Schweiz
> http://singmann.org
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From diego.pavonjordan at gmail.com  Tue Feb 20 13:05:20 2018
From: diego.pavonjordan at gmail.com (Diego Pavon)
Date: Tue, 20 Feb 2018 14:05:20 +0200
Subject: [R-sig-ME] specifying initial starting values in glmmTMB
Message-ID: <CAD93_FpkDVjjm8akRSZzirbe9BpTrXNz5+hWhh93butV61+-dw@mail.gmail.com>

Hello,

I am having convergence problems with the following model:

M2 <- glmmTMB(Abundance ~ Temp_std + WithinNatura + Winter_std
              + (1|site) + (1|species),
              family = nbinom2,
              control = glmmTMBControl(optCtrl = list(iter.max = 20000,
eval.max = 20000), profile = TRUE, collect = FALSE),
              ziformula = ~ Temp_std + WithinNatura + Winter_std,
              data = AllSpecies)


I have followed the recommendation in the troubleshooting vignette
(standardize covariates, simplify the model - can't get simpler than the
above-, increase iteractions...) and also in the pdf (
https://cran.r-project.org/web/packages/glmmTMB/glmmTMB.pdf) but it does
not seem to help.

I was wondering if there is a way to specify initial values, perhaps
similar to in lme4?

Thank you very much for your help.

> sessionInfo()
R version 3.3.2 (2016-10-31)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows >= 8 x64 (build 9200)

locale:
[1] LC_COLLATE=Finnish_Finland.1252  LC_CTYPE=Finnish_Finland.1252
LC_MONETARY=Finnish_Finland.1252 LC_NUMERIC=C
[5] LC_TIME=Finnish_Finland.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] glmmTMB_0.2.0

loaded via a namespace (and not attached):
 [1] Rcpp_0.12.11    lattice_0.20-35 reshape_0.8.6   unmarked_0.12-2
MASS_7.3-47     grid_3.3.2      plyr_1.8.4      nlme_3.1-131
 [9] minqa_1.2.4     nloptr_1.0.4    raster_2.5-8    sp_1.2-4
Matrix_1.2-10   splines_3.3.2   lme4_1.1-13     tools_3.3.2
[17] TMB_1.7.10      parallel_3.3.2


Best

Diego


-- 
*Diego Pav?n Jord?n*

*Finnish Museum of Natural History*
*PO BOX 17 *

*Helsinki. Finland*

*0445061210https://www.researchgate.net/profile/Diego_Pavon-jordan
<https://www.researchgate.net/profile/Diego_Pavon-jordan>*

	[[alternative HTML version deleted]]


From jmichaelrosenberg at gmail.com  Wed Feb 21 01:21:36 2018
From: jmichaelrosenberg at gmail.com (Joshua Rosenberg)
Date: Tue, 20 Feb 2018 19:21:36 -0500
Subject: [R-sig-ME] Specifying a (random effect for an) interaction among
 two level 1 variables?
Message-ID: <CANYHYTScTtnWU_uQfZsz7v4MwKFhJr_HsNBek+VoNxK6WCZ_OQ@mail.gmail.com>

Hi R-sig-mixed-models,

I have a question about specifying a random effect for the interaction
among two level 1 variables when there are random slopes for each of the
variables.

In short, *does specifying a random slope for both of the two variables
used in the interaction imply that the effect of the interaction is also
random across the level 2 units?*

Here's what the model (in lme4) looks like:

lmer(outcome ~ var1 + var2 + var1:var2 + (var1 | grouping_factor) + (var2 |
grouping_factor), data = d)


In the context of this model, I'm curious about whether the var1:var2
interaction term varies across the level 2 units. Intuitively, it makes
sense to me that it would, since the effects of its two components are
allowed to vary across the levels of the grouping factor, but I'm having
trouble thinking through it.

To give a bit more insight into my thinking, I tried something like the
following, but it didn't work (the model didn't converge):

lmer(outcome ~ var1 + var2 + var1:var2 + (var1 | grouping_factor) + (var2 |
grouping_factor) + (var1:var2 | grouping_factor), data = d)


Thank you in advance.

-Josh

-- 
Joshua Rosenberg, Ph.D. Candidate
Educational Psychology
&
 Educational Technology
Michigan State University
http://jmichaelrosenberg.com

	[[alternative HTML version deleted]]


From emmanuel.curis at parisdescartes.fr  Wed Feb 21 09:11:19 2018
From: emmanuel.curis at parisdescartes.fr (Emmanuel Curis)
Date: Wed, 21 Feb 2018 09:11:19 +0100
Subject: [R-sig-ME] 
 Specifying a (random effect for an) interaction among
 two level 1 variables?
In-Reply-To: <CANYHYTScTtnWU_uQfZsz7v4MwKFhJr_HsNBek+VoNxK6WCZ_OQ@mail.gmail.com>
References: <CANYHYTScTtnWU_uQfZsz7v4MwKFhJr_HsNBek+VoNxK6WCZ_OQ@mail.gmail.com>
Message-ID: <20180221081119.GA20316@info124.pharmacie.univ-paris5.fr>

Hello Joshua,

I think the answer depends on the interpretation of the underlying
model, which itself strongly depends on the nature of var1 and var2:
are they both quantitative (numeric), both qualitative (factors) or
one of each?

For the two numerics case, the fixed part model is
 ? = ?0 + a x + b y + c x y
not discussing the question of why assuming x? and y? do not act on ?,
 the interpretation of the random part is
 ( x | group ) -> random effect on ?0 and a
 ( y | group ) -> random effect on ?0 (again) and b
 ( x:y | group ) -> random effect on ?0 (again) and c

so having the three terms like it seems to make a difficult to
identify model (with three different random effects on ?0) with a
special covariance matrix between the random effects which is
block-diagonal.  The difficulty to identify may explain the problems
you have.

The more generic way to enter the model would be
     z ~ x + y + x:y + (x + y + x:y | g )
for a full covariance matrix between the 4 random effects (one for
each coefficient of the model), but you'll need to have plenty of
data for that.

A less generic model with independant random effects (but that's
questionnable, see previous discussions on this list) would be
     z ~ x + y + x:y + (x|g) + (0+y|g) + (0+x:y | g) )
that gives you 4 random effects with a diagonal covariane matrix.



For the one factor, one numeric case, assuming the factor has two
levels A1 and A2, then the model for the fixed part is
 ? = ?0(A1) + dA 1(A2) + [b(A1) + db 1(A2)] y
where 1(l) the indicator of level l, and x is the factor.

The interpretation of the random part is
 ( x | group )   -> random effect on ?0 and dA
 ( y | group )   -> random effect on ?0 and b
 ( x:y | group ) -> random effect on ?0, b, dA and db

so the situation is even worse than above when letting in the three
terms... The last one, ( x:y | group ), is enough to have random
effects on all coefficients of your model (with a full covariance
matrix between them)

The two factors case is similar, with the additional difficulty of
interpretating the meaning of these random effects in terms of inequal
variances of the random effect between the differents cells of your
table...

Hope this helps,
Best regards

On Tue, Feb 20, 2018 at 07:21:36PM -0500, Joshua Rosenberg wrote:
? Hi R-sig-mixed-models,
? 
? I have a question about specifying a random effect for the interaction
? among two level 1 variables when there are random slopes for each of the
? variables.
? 
? In short, *does specifying a random slope for both of the two variables
? used in the interaction imply that the effect of the interaction is also
? random across the level 2 units?*
? 
? Here's what the model (in lme4) looks like:
? 
? lmer(outcome ~ var1 + var2 + var1:var2 + (var1 | grouping_factor) + (var2 |
? grouping_factor), data = d)
? 
? 
? In the context of this model, I'm curious about whether the var1:var2
? interaction term varies across the level 2 units. Intuitively, it makes
? sense to me that it would, since the effects of its two components are
? allowed to vary across the levels of the grouping factor, but I'm having
? trouble thinking through it.
? 
? To give a bit more insight into my thinking, I tried something like the
? following, but it didn't work (the model didn't converge):
? 
? lmer(outcome ~ var1 + var2 + var1:var2 + (var1 | grouping_factor) + (var2 |
? grouping_factor) + (var1:var2 | grouping_factor), data = d)
? 
? 
? Thank you in advance.
? 
? -Josh
? 
? -- 
? Joshua Rosenberg, Ph.D. Candidate
? Educational Psychology
? &
?  Educational Technology
? Michigan State University
? http://jmichaelrosenberg.com
? 
? 	[[alternative HTML version deleted]]
? 
? _______________________________________________
? R-sig-mixed-models at r-project.org mailing list
? https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
                                Emmanuel CURIS
                                emmanuel.curis at parisdescartes.fr

Page WWW: http://emmanuel.curis.online.fr/index.html


From thierry.onkelinx at inbo.be  Wed Feb 21 09:54:39 2018
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Wed, 21 Feb 2018 09:54:39 +0100
Subject: [R-sig-ME] 
 Specifying a (random effect for an) interaction among
 two level 1 variables?
In-Reply-To: <20180221081119.GA20316@info124.pharmacie.univ-paris5.fr>
References: <CANYHYTScTtnWU_uQfZsz7v4MwKFhJr_HsNBek+VoNxK6WCZ_OQ@mail.gmail.com>
 <20180221081119.GA20316@info124.pharmacie.univ-paris5.fr>
Message-ID: <CAJuCY5yLnJKV66g0Ts0bMrWH7-2McT8+pv2Un45AsE-hGHcixA@mail.gmail.com>

Dear Emmanuel,

Four independent random effects is coded as (1|g) + (0 +x|g) + (0+y|g)
+ (0 + x:y|g). Your example still contains a covariance between the
random intercept and the random slope for x.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
AND FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////




2018-02-21 9:11 GMT+01:00 Emmanuel Curis <emmanuel.curis at parisdescartes.fr>:
> Hello Joshua,
>
> I think the answer depends on the interpretation of the underlying
> model, which itself strongly depends on the nature of var1 and var2:
> are they both quantitative (numeric), both qualitative (factors) or
> one of each?
>
> For the two numerics case, the fixed part model is
>  ? = ?0 + a x + b y + c x y
> not discussing the question of why assuming x? and y? do not act on ?,
>  the interpretation of the random part is
>  ( x | group ) -> random effect on ?0 and a
>  ( y | group ) -> random effect on ?0 (again) and b
>  ( x:y | group ) -> random effect on ?0 (again) and c
>
> so having the three terms like it seems to make a difficult to
> identify model (with three different random effects on ?0) with a
> special covariance matrix between the random effects which is
> block-diagonal.  The difficulty to identify may explain the problems
> you have.
>
> The more generic way to enter the model would be
>      z ~ x + y + x:y + (x + y + x:y | g )
> for a full covariance matrix between the 4 random effects (one for
> each coefficient of the model), but you'll need to have plenty of
> data for that.
>
> A less generic model with independant random effects (but that's
> questionnable, see previous discussions on this list) would be
>      z ~ x + y + x:y + (x|g) + (0+y|g) + (0+x:y | g) )
> that gives you 4 random effects with a diagonal covariane matrix.
>
>
>
> For the one factor, one numeric case, assuming the factor has two
> levels A1 and A2, then the model for the fixed part is
>  ? = ?0(A1) + dA 1(A2) + [b(A1) + db 1(A2)] y
> where 1(l) the indicator of level l, and x is the factor.
>
> The interpretation of the random part is
>  ( x | group )   -> random effect on ?0 and dA
>  ( y | group )   -> random effect on ?0 and b
>  ( x:y | group ) -> random effect on ?0, b, dA and db
>
> so the situation is even worse than above when letting in the three
> terms... The last one, ( x:y | group ), is enough to have random
> effects on all coefficients of your model (with a full covariance
> matrix between them)
>
> The two factors case is similar, with the additional difficulty of
> interpretating the meaning of these random effects in terms of inequal
> variances of the random effect between the differents cells of your
> table...
>
> Hope this helps,
> Best regards
>
> On Tue, Feb 20, 2018 at 07:21:36PM -0500, Joshua Rosenberg wrote:
> ? Hi R-sig-mixed-models,
> ?
> ? I have a question about specifying a random effect for the interaction
> ? among two level 1 variables when there are random slopes for each of the
> ? variables.
> ?
> ? In short, *does specifying a random slope for both of the two variables
> ? used in the interaction imply that the effect of the interaction is also
> ? random across the level 2 units?*
> ?
> ? Here's what the model (in lme4) looks like:
> ?
> ? lmer(outcome ~ var1 + var2 + var1:var2 + (var1 | grouping_factor) + (var2 |
> ? grouping_factor), data = d)
> ?
> ?
> ? In the context of this model, I'm curious about whether the var1:var2
> ? interaction term varies across the level 2 units. Intuitively, it makes
> ? sense to me that it would, since the effects of its two components are
> ? allowed to vary across the levels of the grouping factor, but I'm having
> ? trouble thinking through it.
> ?
> ? To give a bit more insight into my thinking, I tried something like the
> ? following, but it didn't work (the model didn't converge):
> ?
> ? lmer(outcome ~ var1 + var2 + var1:var2 + (var1 | grouping_factor) + (var2 |
> ? grouping_factor) + (var1:var2 | grouping_factor), data = d)
> ?
> ?
> ? Thank you in advance.
> ?
> ? -Josh
> ?
> ? --
> ? Joshua Rosenberg, Ph.D. Candidate
> ? Educational Psychology
> ? &
> ?  Educational Technology
> ? Michigan State University
> ? http://jmichaelrosenberg.com
> ?
> ?       [[alternative HTML version deleted]]
> ?
> ? _______________________________________________
> ? R-sig-mixed-models at r-project.org mailing list
> ? https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> --
>                                 Emmanuel CURIS
>                                 emmanuel.curis at parisdescartes.fr
>
> Page WWW: http://emmanuel.curis.online.fr/index.html
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From emmanuel.curis at parisdescartes.fr  Wed Feb 21 10:09:31 2018
From: emmanuel.curis at parisdescartes.fr (Emmanuel Curis)
Date: Wed, 21 Feb 2018 10:09:31 +0100
Subject: [R-sig-ME] 
 Specifying a (random effect for an) interaction among
 two level 1 variables?
In-Reply-To: <CAJuCY5yLnJKV66g0Ts0bMrWH7-2McT8+pv2Un45AsE-hGHcixA@mail.gmail.com>
References: <CANYHYTScTtnWU_uQfZsz7v4MwKFhJr_HsNBek+VoNxK6WCZ_OQ@mail.gmail.com>
 <20180221081119.GA20316@info124.pharmacie.univ-paris5.fr>
 <CAJuCY5yLnJKV66g0Ts0bMrWH7-2McT8+pv2Un45AsE-hGHcixA@mail.gmail.com>
Message-ID: <20180221090931.GA15610@info124.pharmacie.univ-paris5.fr>

Dear Thierry,

Yes indeed. Sorry for the mistake; I hope there is no other...
Thanks for the correction,

Best regards,

On Wed, Feb 21, 2018 at 09:54:39AM +0100, Thierry Onkelinx wrote:
? Dear Emmanuel,
? 
? Four independent random effects is coded as (1|g) + (0 +x|g) + (0+y|g)
? + (0 + x:y|g). Your example still contains a covariance between the
? random intercept and the random slope for x.
? 
? Best regards,
? 
? ir. Thierry Onkelinx
? Statisticus / Statistician
? 
? Vlaamse Overheid / Government of Flanders
? INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
? AND FOREST
? Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
? thierry.onkelinx at inbo.be
? Havenlaan 88 bus 73, 1000 Brussel
? www.inbo.be
? 
? ///////////////////////////////////////////////////////////////////////////////////////////
? To call in the statistician after the experiment is done may be no
? more than asking him to perform a post-mortem examination: he may be
? able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
? The plural of anecdote is not data. ~ Roger Brinner
? The combination of some data and an aching desire for an answer does
? not ensure that a reasonable answer can be extracted from a given body
? of data. ~ John Tukey
? ///////////////////////////////////////////////////////////////////////////////////////////
? 
? 
? 
? 
? 2018-02-21 9:11 GMT+01:00 Emmanuel Curis <emmanuel.curis at parisdescartes.fr>:
? > Hello Joshua,
? >
? > I think the answer depends on the interpretation of the underlying
? > model, which itself strongly depends on the nature of var1 and var2:
? > are they both quantitative (numeric), both qualitative (factors) or
? > one of each?
? >
? > For the two numerics case, the fixed part model is
? >  ? = ?0 + a x + b y + c x y
? > not discussing the question of why assuming x? and y? do not act on ?,
? >  the interpretation of the random part is
? >  ( x | group ) -> random effect on ?0 and a
? >  ( y | group ) -> random effect on ?0 (again) and b
? >  ( x:y | group ) -> random effect on ?0 (again) and c
? >
? > so having the three terms like it seems to make a difficult to
? > identify model (with three different random effects on ?0) with a
? > special covariance matrix between the random effects which is
? > block-diagonal.  The difficulty to identify may explain the problems
? > you have.
? >
? > The more generic way to enter the model would be
? >      z ~ x + y + x:y + (x + y + x:y | g )
? > for a full covariance matrix between the 4 random effects (one for
? > each coefficient of the model), but you'll need to have plenty of
? > data for that.
? >
? > A less generic model with independant random effects (but that's
? > questionnable, see previous discussions on this list) would be
? >      z ~ x + y + x:y + (x|g) + (0+y|g) + (0+x:y | g) )
? > that gives you 4 random effects with a diagonal covariane matrix.
? >
? >
? >
? > For the one factor, one numeric case, assuming the factor has two
? > levels A1 and A2, then the model for the fixed part is
? >  ? = ?0(A1) + dA 1(A2) + [b(A1) + db 1(A2)] y
? > where 1(l) the indicator of level l, and x is the factor.
? >
? > The interpretation of the random part is
? >  ( x | group )   -> random effect on ?0 and dA
? >  ( y | group )   -> random effect on ?0 and b
? >  ( x:y | group ) -> random effect on ?0, b, dA and db
? >
? > so the situation is even worse than above when letting in the three
? > terms... The last one, ( x:y | group ), is enough to have random
? > effects on all coefficients of your model (with a full covariance
? > matrix between them)
? >
? > The two factors case is similar, with the additional difficulty of
? > interpretating the meaning of these random effects in terms of inequal
? > variances of the random effect between the differents cells of your
? > table...
? >
? > Hope this helps,
? > Best regards
? >
? > On Tue, Feb 20, 2018 at 07:21:36PM -0500, Joshua Rosenberg wrote:
? > ? Hi R-sig-mixed-models,
? > ?
? > ? I have a question about specifying a random effect for the interaction
? > ? among two level 1 variables when there are random slopes for each of the
? > ? variables.
? > ?
? > ? In short, *does specifying a random slope for both of the two variables
? > ? used in the interaction imply that the effect of the interaction is also
? > ? random across the level 2 units?*
? > ?
? > ? Here's what the model (in lme4) looks like:
? > ?
? > ? lmer(outcome ~ var1 + var2 + var1:var2 + (var1 | grouping_factor) + (var2 |
? > ? grouping_factor), data = d)
? > ?
? > ?
? > ? In the context of this model, I'm curious about whether the var1:var2
? > ? interaction term varies across the level 2 units. Intuitively, it makes
? > ? sense to me that it would, since the effects of its two components are
? > ? allowed to vary across the levels of the grouping factor, but I'm having
? > ? trouble thinking through it.
? > ?
? > ? To give a bit more insight into my thinking, I tried something like the
? > ? following, but it didn't work (the model didn't converge):
? > ?
? > ? lmer(outcome ~ var1 + var2 + var1:var2 + (var1 | grouping_factor) + (var2 |
? > ? grouping_factor) + (var1:var2 | grouping_factor), data = d)
? > ?
? > ?
? > ? Thank you in advance.
? > ?
? > ? -Josh
? > ?
? > ? --
? > ? Joshua Rosenberg, Ph.D. Candidate
? > ? Educational Psychology
? > ? &
? > ?  Educational Technology
? > ? Michigan State University
? > ? http://jmichaelrosenberg.com
? > ?
? > ?       [[alternative HTML version deleted]]
? > ?
? > ? _______________________________________________
? > ? R-sig-mixed-models at r-project.org mailing list
? > ? https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
? >
? > --
? >                                 Emmanuel CURIS
? >                                 emmanuel.curis at parisdescartes.fr
? >
? > Page WWW: http://emmanuel.curis.online.fr/index.html
? >
? > _______________________________________________
? > R-sig-mixed-models at r-project.org mailing list
? > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
                                Emmanuel CURIS
                                emmanuel.curis at parisdescartes.fr

Page WWW: http://emmanuel.curis.online.fr/index.html


From surajkeshri at gmail.com  Wed Feb 21 19:25:48 2018
From: surajkeshri at gmail.com (suraj keshri)
Date: Wed, 21 Feb 2018 13:25:48 -0500
Subject: [R-sig-ME] Specify multiple nested random effects in lme with
 heteroskedastic variance across group
Message-ID: <CABkv+1e105qDMoM5D0crav+HWHq+6NkJ5Ox6-SwOi9gNKjxh3g@mail.gmail.com>

I want to fit a random effects model with two separate nested random
effects. I can easily do this using the `lmer` package in R. Here's how:

    model<-lmer(y ~ 1 + x + (1 | oid/gid) + (1 | did/gid), data=data)

Here, I'm fitting a random intercept for `oid` nested within `gid` and
`did` nested within `gid`. This works well. However, I want to fit a model
where the variance of the intercept changes across the `gid` for both the
random effects. `nlme` package is capable of doing that. However, it's not
clear how. The best I could do is like so:

    model <- lme(y ~ 1 + x, random=list(gid=~1, oid=~1, did=~1),
weights=varIdent(form=~1|gid), data = data)

but this nests the `did` within `oid` and `gid` nested together. I tried to
use the idea from a similar [question][1], which seems like a close problem
but the answer has not been explained well in that question. Thank you!

  [1]: https://stats.stackexchange.com/questions/58669/
specifying-multiple-separate-random-effects-in-lme

	[[alternative HTML version deleted]]


From peter.schlattmann at med.uni-jena.de  Thu Feb 22 11:43:41 2018
From: peter.schlattmann at med.uni-jena.de (Schlattmann, Peter)
Date: Thu, 22 Feb 2018 10:43:41 +0000
Subject: [R-sig-ME] prediction with glmer
Message-ID: <A606BAEE686DE4489CD1EA8399E87B6EA6CA8506@EXCHDB1.krz.uni-jena.de>

Dear all,

Apologies for a potential second post, I am not sure my first post came through.



I am fitting a generalized linear mixed model with lme4 using glmer

 with binomial errors and logit link. I am using the ?predict? function

 to obtain predicted values for the current model and data set.



 Here is some sample code



 m.age50<-glmer(ct_pos~cath_pos+(1+cath_pos|study_no),data=test, amily=binomial,na.action=na.omit)



 result.age50<-predict(m.age50)



My question is now: How exactly are the predictions calculated? I  could not find any details in the documentation.  Are these  just

 based on the fixed effects setting the random effects to zero? Or are  these empirical Bayes estimates?



Is there any documentation available?





Thank  you very much in advance.



Peter



Universit?tsklinikum Jena - Bachstrasse 18 - D-07743 Jena
Die gesetzlichen Pflichtangaben finden Sie unter http://www.uniklinikum-jena.de/Pflichtangaben.html

	[[alternative HTML version deleted]]


From phillip.alday at mpi.nl  Thu Feb 22 12:32:14 2018
From: phillip.alday at mpi.nl (Phillip Alday)
Date: Thu, 22 Feb 2018 12:32:14 +0100
Subject: [R-sig-ME] prediction with glmer
In-Reply-To: <A606BAEE686DE4489CD1EA8399E87B6EA6CA8506@EXCHDB1.krz.uni-jena.de>
References: <A606BAEE686DE4489CD1EA8399E87B6EA6CA8506@EXCHDB1.krz.uni-jena.de>
Message-ID: <483df98e-9255-7285-a538-9a225e70be7b@mpi.nl>

In terms of the random effects: it depends on the other arguments to
predict() (in particular re.form) as to whether they are marginalized
out or not (i.e. whether it's a pure fixed-effects prediction).


My understanding is:
If you only the same levels of your grouping variable occur in the new
data as occurred in the old data (i.e. the data used to fit the model),
then the conditional modes / BLUPs (BLUP is a bit of a misnomer in the
GLMM case, and conditional mode is a fairly Bayesian perspective in a
frequentist model) estimated for each level of the grouping variable
(study_no in your case) are used.
With new levels, predictions are made using the variance estimates and
not the particular offsets / conditional modes / BLUPs.

However, in your particular case, it's even easier: predict simply
returns the fitted values.

Phillip


On 22/02/18 11:43, Schlattmann, Peter wrote:
> Dear all,
> 
> Apologies for a potential second post, I am not sure my first post came through.
> 
> 
> 
> I am fitting a generalized linear mixed model with lme4 using glmer
> 
>  with binomial errors and logit link. I am using the ?predict? function
> 
>  to obtain predicted values for the current model and data set.
> 
> 
> 
>  Here is some sample code
> 
> 
> 
>  m.age50<-glmer(ct_pos~cath_pos+(1+cath_pos|study_no),data=test, amily=binomial,na.action=na.omit)
> 
> 
> 
>  result.age50<-predict(m.age50)
> 
> 
> 
> My question is now: How exactly are the predictions calculated? I  could not find any details in the documentation.  Are these  just
> 
>  based on the fixed effects setting the random effects to zero? Or are  these empirical Bayes estimates?
> 
> 
> 
> Is there any documentation available?
> 
> 
> 
> 
> 
> Thank  you very much in advance.
> 
> 
> 
> Peter
> 
> 
> 
> Universit?tsklinikum Jena - Bachstrasse 18 - D-07743 Jena
> Die gesetzlichen Pflichtangaben finden Sie unter http://www.uniklinikum-jena.de/Pflichtangaben.html
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From phillip.alday at mpi.nl  Thu Feb 22 13:10:43 2018
From: phillip.alday at mpi.nl (Phillip Alday)
Date: Thu, 22 Feb 2018 13:10:43 +0100
Subject: [R-sig-ME] prediction with glmer
In-Reply-To: <A606BAEE686DE4489CD1EA8399E87B6EA6CA8576@EXCHDB1.krz.uni-jena.de>
References: <A606BAEE686DE4489CD1EA8399E87B6EA6CA8506@EXCHDB1.krz.uni-jena.de>
 <483df98e-9255-7285-a538-9a225e70be7b@mpi.nl>
 <A606BAEE686DE4489CD1EA8399E87B6EA6CA8576@EXCHDB1.krz.uni-jena.de>
Message-ID: <0f440d57-56a8-85ba-7e18-9f711243781e@mpi.nl>

The fitted values include the random effects.

Phillip

On 22/02/18 12:57, Schlattmann, Peter wrote:
> Dear Philipp,
> 
> thank you so much.
> 
>> However, in your particular case, it's even easier: predict simply returns the fitted values.
> 
> Do these fitted values include the random effects or are they marginalized?
> 
> Thanks again
> 
> Peter
> 
> -----Urspr?ngliche Nachricht-----
> Von: Phillip Alday [mailto:phillip.alday at mpi.nl]
> Gesendet: Donnerstag, 22. Februar 2018 12:32
> An: Schlattmann, Peter; r-sig-mixed-models at r-project.org
> Betreff: Re: [R-sig-ME] prediction with glmer
> 
> In terms of the random effects: it depends on the other arguments to
> predict() (in particular re.form) as to whether they are marginalized out or not (i.e. whether it's a pure fixed-effects prediction).
> 
> 
> My understanding is:
> If you only the same levels of your grouping variable occur in the new data as occurred in the old data (i.e. the data used to fit the model), then the conditional modes / BLUPs (BLUP is a bit of a misnomer in the GLMM case, and conditional mode is a fairly Bayesian perspective in a frequentist model) estimated for each level of the grouping variable (study_no in your case) are used.
> With new levels, predictions are made using the variance estimates and not the particular offsets / conditional modes / BLUPs.
> 
> However, in your particular case, it's even easier: predict simply returns the fitted values.
> 
> Phillip
> 
> 
> On 22/02/18 11:43, Schlattmann, Peter wrote:
>> Dear all,
>>
>> Apologies for a potential second post, I am not sure my first post came through.
>>
>>
>>
>> I am fitting a generalized linear mixed model with lme4 using glmer
>>
>>  with binomial errors and logit link. I am using the ?predict?
>> function
>>
>>  to obtain predicted values for the current model and data set.
>>
>>
>>
>>  Here is some sample code
>>
>>
>>
>>  m.age50<-glmer(ct_pos~cath_pos+(1+cath_pos|study_no),data=test,
>> amily=binomial,na.action=na.omit)
>>
>>
>>
>>  result.age50<-predict(m.age50)
>>
>>
>>
>> My question is now: How exactly are the predictions calculated? I
>> could not find any details in the documentation.  Are these  just
>>
>>  based on the fixed effects setting the random effects to zero? Or are  these empirical Bayes estimates?
>>
>>
>>
>> Is there any documentation available?
>>
>>
>>
>>
>>
>> Thank  you very much in advance.
>>
>>
>>
>> Peter
>>
>>
>>
>> Universit?tsklinikum Jena - Bachstrasse 18 - D-07743 Jena Die
>> gesetzlichen Pflichtangaben finden Sie unter
>> http://www.uniklinikum-jena.de/Pflichtangaben.html
>>
>>       [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
> 
> Universit?tsklinikum Jena - Bachstrasse 18 - D-07743 Jena
> Die gesetzlichen Pflichtangaben finden Sie unter http://www.uniklinikum-jena.de/Pflichtangaben.html
>


From ahmatias at gmail.com  Thu Feb 22 13:28:16 2018
From: ahmatias at gmail.com (Toni Hernandez-Matias)
Date: Thu, 22 Feb 2018 13:28:16 +0100
Subject: [R-sig-ME] variance inflation factor
Message-ID: <CA+hwERmYk2AgLOqW0PusMgG29MmkN7JrnAZFtQFqzC6m4-80Rw@mail.gmail.com>

Dear all,

Could some help me to calculate Variance Inflation Factors of models fitted
with glmer and lmer ?

I found the method I copy below but I am not sure it is correct:

vif.lme <- function (fit) {
     ## adapted from rms::vif
     v <- vcov(fit)
     nam <- names(fixef(fit))
     ## exclude intercepts
     ns <- sum(1 * (nam == "Intercept" | nam == "(Intercept)"))
     if (ns > 0) {
         v <- v[-(1:ns), -(1:ns), drop = FALSE]
         nam <- nam[-(1:ns)] }
     d <- diag(v)^0.5
     v <- diag(solve(v/(d %o% d)))
     names(v) <- nam
     v }



##la estimamos para el modelo 1

vif.lme(mod1)


Thank you very much in advance,

Antonio


-- 
*********************************************************

Antonio Hernandez Matias

Equip de Biologia de la Conservaci?
Departament de Biologia Evolutiva, Ecolog?a i Ci?ncies Ambientals
Facultat de Biologia  i Institut de Recerca de la Biodiversitat (IRBio)
Universitat de Barcelona (UB)
Av. Diagonal, 643
Barcelona      08028
Spain
Telephone: +34-934035857 <+34%20934%2003%2058%2057>
FAX: +34-934035740 <+34%20934%2003%2057%2040>
e-mail: ahernandezmatias at ub.edu

***********************************************************

	[[alternative HTML version deleted]]


From jfox at mcmaster.ca  Thu Feb 22 15:51:46 2018
From: jfox at mcmaster.ca (Fox, John)
Date: Thu, 22 Feb 2018 14:51:46 +0000
Subject: [R-sig-ME] variance inflation factor
In-Reply-To: <16712_1519302508_w1MCSQRb026827_CA+hwERmYk2AgLOqW0PusMgG29MmkN7JrnAZFtQFqzC6m4-80Rw@mail.gmail.com>
References: <16712_1519302508_w1MCSQRb026827_CA+hwERmYk2AgLOqW0PusMgG29MmkN7JrnAZFtQFqzC6m4-80Rw@mail.gmail.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC8367833E8@FHSDB2D11-2.csu.mcmaster.ca>

Dear Toni,

Yes, that looks reasonable, although I'm not sure why it's necessary to test for more than one fixed-effect intercept at the beginning of the fixed-effect coefficient vector and how an intercept could be named "Intercept" rather than "(Intercept)". Assuming that there's a reason that escapes me, here's a simplified version:

vif.lme <- function (fit) {
  ## adapted from rms::vif
  v <- vcov(fit)
  nam <- names(fixef(fit))
  ## exclude intercepts
  ns <- sum(nam == "Intercept" | nam == "(Intercept)")
  if (ns > 0) v <- v[-(1:ns), -(1:ns), drop = FALSE]
  diag(solve(cov2cor(v)))
}

I hope this helps,
 John


-----------------------------
John Fox, Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
Web: socialsciences.mcmaster.ca/jfox/



> -----Original Message-----
> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-
> project.org] On Behalf Of Toni Hernandez-Matias
> Sent: Thursday, February 22, 2018 7:28 AM
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] variance inflation factor
> 
> Dear all,
> 
> Could some help me to calculate Variance Inflation Factors of models fitted
> with glmer and lmer ?
> 
> I found the method I copy below but I am not sure it is correct:
> 
> vif.lme <- function (fit) {
>      ## adapted from rms::vif
>      v <- vcov(fit)
>      nam <- names(fixef(fit))
>      ## exclude intercepts
>      ns <- sum(1 * (nam == "Intercept" | nam == "(Intercept)"))
>      if (ns > 0) {
>          v <- v[-(1:ns), -(1:ns), drop = FALSE]
>          nam <- nam[-(1:ns)] }
>      d <- diag(v)^0.5
>      v <- diag(solve(v/(d %o% d)))
>      names(v) <- nam
>      v }
> 
> 
> 
> ##la estimamos para el modelo 1
> 
> vif.lme(mod1)
> 
> 
> Thank you very much in advance,
> 
> Antonio
> 
> 
> --
> *********************************************************
> 
> Antonio Hernandez Matias
> 
> Equip de Biologia de la Conservaci?
> Departament de Biologia Evolutiva, Ecolog?a i Ci?ncies Ambientals Facultat de
> Biologia  i Institut de Recerca de la Biodiversitat (IRBio) Universitat de
> Barcelona (UB) Av. Diagonal, 643
> Barcelona      08028
> Spain
> Telephone: +34-934035857 <+34%20934%2003%2058%2057>
> FAX: +34-934035740 <+34%20934%2003%2057%2040>
> e-mail: ahernandezmatias at ub.edu
> 
> ***********************************************************
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

From ahmatias at gmail.com  Thu Feb 22 16:00:34 2018
From: ahmatias at gmail.com (Toni Hernandez-Matias)
Date: Thu, 22 Feb 2018 16:00:34 +0100
Subject: [R-sig-ME] variance inflation factor
In-Reply-To: <ACD1644AA6C67E4FBD0C350625508EC8367833E8@FHSDB2D11-2.csu.mcmaster.ca>
References: <16712_1519302508_w1MCSQRb026827_CA+hwERmYk2AgLOqW0PusMgG29MmkN7JrnAZFtQFqzC6m4-80Rw@mail.gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC8367833E8@FHSDB2D11-2.csu.mcmaster.ca>
Message-ID: <CA+hwERmdPZprwUMzEmxWtb+1kY5XLOdxrAmEwzXpgiukdbJbaA@mail.gmail.com>

Dear John,

Thank you very much for your message.

Did you know a bibliographic reference for this method, specifically in the
case of generalized linear mixed models?

Thank you again,

Antonio

On Thu, Feb 22, 2018 at 3:51 PM, Fox, John <jfox at mcmaster.ca> wrote:

> Dear Toni,
>
> Yes, that looks reasonable, although I'm not sure why it's necessary to
> test for more than one fixed-effect intercept at the beginning of the
> fixed-effect coefficient vector and how an intercept could be named
> "Intercept" rather than "(Intercept)". Assuming that there's a reason that
> escapes me, here's a simplified version:
>
> vif.lme <- function (fit) {
>   ## adapted from rms::vif
>   v <- vcov(fit)
>   nam <- names(fixef(fit))
>   ## exclude intercepts
>   ns <- sum(nam == "Intercept" | nam == "(Intercept)")
>   if (ns > 0) v <- v[-(1:ns), -(1:ns), drop = FALSE]
>   diag(solve(cov2cor(v)))
> }
>
> I hope this helps,
>  John
>
>
> -----------------------------
> John Fox, Professor Emeritus
> McMaster University
> Hamilton, Ontario, Canada
> Web: socialsciences.mcmaster.ca/jfox/
>
>
>
> > -----Original Message-----
> > From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-
> > project.org] On Behalf Of Toni Hernandez-Matias
> > Sent: Thursday, February 22, 2018 7:28 AM
> > To: r-sig-mixed-models at r-project.org
> > Subject: [R-sig-ME] variance inflation factor
> >
> > Dear all,
> >
> > Could some help me to calculate Variance Inflation Factors of models
> fitted
> > with glmer and lmer ?
> >
> > I found the method I copy below but I am not sure it is correct:
> >
> > vif.lme <- function (fit) {
> >      ## adapted from rms::vif
> >      v <- vcov(fit)
> >      nam <- names(fixef(fit))
> >      ## exclude intercepts
> >      ns <- sum(1 * (nam == "Intercept" | nam == "(Intercept)"))
> >      if (ns > 0) {
> >          v <- v[-(1:ns), -(1:ns), drop = FALSE]
> >          nam <- nam[-(1:ns)] }
> >      d <- diag(v)^0.5
> >      v <- diag(solve(v/(d %o% d)))
> >      names(v) <- nam
> >      v }
> >
> >
> >
> > ##la estimamos para el modelo 1
> >
> > vif.lme(mod1)
> >
> >
> > Thank you very much in advance,
> >
> > Antonio
> >
> >
> > --
> > *********************************************************
> >
> > Antonio Hernandez Matias
> >
> > Equip de Biologia de la Conservaci?
> > Departament de Biologia Evolutiva, Ecolog?a i Ci?ncies Ambientals
> Facultat de
> > Biologia  i Institut de Recerca de la Biodiversitat (IRBio) Universitat
> de
> > Barcelona (UB) Av. Diagonal, 643
> > Barcelona      08028
> > Spain
> > Telephone: +34-934035857 <+34%20934%2003%2058%2057>
> > FAX: +34-934035740 <+34%20934%2003%2057%2040>
> > e-mail: ahernandezmatias at ub.edu
> >
> > ***********************************************************
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
*********************************************************

Antonio Hernandez Matias

Equip de Biologia de la Conservaci?
Departament de Biologia Evolutiva, Ecolog?a i Ci?ncies Ambientals
Facultat de Biologia  i Institut de Recerca de la Biodiversitat (IRBio)
Universitat de Barcelona (UB)
Av. Diagonal, 643
Barcelona      08028
Spain
Telephone: +34-934035857
FAX: +34-934035740
e-mail: ahernandezmatias at ub.edu

***********************************************************

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Thu Feb 22 16:34:37 2018
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 22 Feb 2018 10:34:37 -0500
Subject: [R-sig-ME] variance inflation factor
In-Reply-To: <CA+hwERmdPZprwUMzEmxWtb+1kY5XLOdxrAmEwzXpgiukdbJbaA@mail.gmail.com>
References: <16712_1519302508_w1MCSQRb026827_CA+hwERmYk2AgLOqW0PusMgG29MmkN7JrnAZFtQFqzC6m4-80Rw@mail.gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC8367833E8@FHSDB2D11-2.csu.mcmaster.ca>
 <CA+hwERmdPZprwUMzEmxWtb+1kY5XLOdxrAmEwzXpgiukdbJbaA@mail.gmail.com>
Message-ID: <CABghstSMkHZys0xZf=Z7p-aAUPCyW4UuHzqpL8Q1FGhAejb73w@mail.gmail.com>

  I don't (John might), but note that the computation depends only on
the sampling variance-covariance matrix of the fixed effects
(i.e. none of the machinery that is specific to (G)LMMs comes into
it). You might look into one of the books by Zuur et al.

  John: the stuff about intercept names comes from Harrell's rms
package, so presumably he found some cases where the parentheses were
missing.
I'd probably use grepl("Intercept",nam) ...

On Thu, Feb 22, 2018 at 10:00 AM, Toni Hernandez-Matias
<ahmatias at gmail.com> wrote:
> Dear John,
>
> Thank you very much for your message.
>
> Did you know a bibliographic reference for this method, specifically in the
> case of generalized linear mixed models?
>
> Thank you again,
>
> Antonio
>
> On Thu, Feb 22, 2018 at 3:51 PM, Fox, John <jfox at mcmaster.ca> wrote:
>
>> Dear Toni,
>>
>> Yes, that looks reasonable, although I'm not sure why it's necessary to
>> test for more than one fixed-effect intercept at the beginning of the
>> fixed-effect coefficient vector and how an intercept could be named
>> "Intercept" rather than "(Intercept)". Assuming that there's a reason that
>> escapes me, here's a simplified version:
>>
>> vif.lme <- function (fit) {
>>   ## adapted from rms::vif
>>   v <- vcov(fit)
>>   nam <- names(fixef(fit))
>>   ## exclude intercepts
>>   ns <- sum(nam == "Intercept" | nam == "(Intercept)")
>>   if (ns > 0) v <- v[-(1:ns), -(1:ns), drop = FALSE]
>>   diag(solve(cov2cor(v)))
>> }
>>
>> I hope this helps,
>>  John
>>
>>
>> -----------------------------
>> John Fox, Professor Emeritus
>> McMaster University
>> Hamilton, Ontario, Canada
>> Web: socialsciences.mcmaster.ca/jfox/
>>
>>
>>
>> > -----Original Message-----
>> > From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-
>> > project.org] On Behalf Of Toni Hernandez-Matias
>> > Sent: Thursday, February 22, 2018 7:28 AM
>> > To: r-sig-mixed-models at r-project.org
>> > Subject: [R-sig-ME] variance inflation factor
>> >
>> > Dear all,
>> >
>> > Could some help me to calculate Variance Inflation Factors of models
>> fitted
>> > with glmer and lmer ?
>> >
>> > I found the method I copy below but I am not sure it is correct:
>> >
>> > vif.lme <- function (fit) {
>> >      ## adapted from rms::vif
>> >      v <- vcov(fit)
>> >      nam <- names(fixef(fit))
>> >      ## exclude intercepts
>> >      ns <- sum(1 * (nam == "Intercept" | nam == "(Intercept)"))
>> >      if (ns > 0) {
>> >          v <- v[-(1:ns), -(1:ns), drop = FALSE]
>> >          nam <- nam[-(1:ns)] }
>> >      d <- diag(v)^0.5
>> >      v <- diag(solve(v/(d %o% d)))
>> >      names(v) <- nam
>> >      v }
>> >
>> >
>> >
>> > ##la estimamos para el modelo 1
>> >
>> > vif.lme(mod1)
>> >
>> >
>> > Thank you very much in advance,
>> >
>> > Antonio
>> >
>> >
>> > --
>> > *********************************************************
>> >
>> > Antonio Hernandez Matias
>> >
>> > Equip de Biologia de la Conservaci?
>> > Departament de Biologia Evolutiva, Ecolog?a i Ci?ncies Ambientals
>> Facultat de
>> > Biologia  i Institut de Recerca de la Biodiversitat (IRBio) Universitat
>> de
>> > Barcelona (UB) Av. Diagonal, 643
>> > Barcelona      08028
>> > Spain
>> > Telephone: +34-934035857 <+34%20934%2003%2058%2057>
>> > FAX: +34-934035740 <+34%20934%2003%2057%2040>
>> > e-mail: ahernandezmatias at ub.edu
>> >
>> > ***********************************************************
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> > _______________________________________________
>> > R-sig-mixed-models at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>
>
> --
> *********************************************************
>
> Antonio Hernandez Matias
>
> Equip de Biologia de la Conservaci?
> Departament de Biologia Evolutiva, Ecolog?a i Ci?ncies Ambientals
> Facultat de Biologia  i Institut de Recerca de la Biodiversitat (IRBio)
> Universitat de Barcelona (UB)
> Av. Diagonal, 643
> Barcelona      08028
> Spain
> Telephone: +34-934035857
> FAX: +34-934035740
> e-mail: ahernandezmatias at ub.edu
>
> ***********************************************************
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From jfox at mcmaster.ca  Thu Feb 22 17:01:54 2018
From: jfox at mcmaster.ca (Fox, John)
Date: Thu, 22 Feb 2018 16:01:54 +0000
Subject: [R-sig-ME] variance inflation factor
In-Reply-To: <CA+hwERmdPZprwUMzEmxWtb+1kY5XLOdxrAmEwzXpgiukdbJbaA@mail.gmail.com>
References: <16712_1519302508_w1MCSQRb026827_CA+hwERmYk2AgLOqW0PusMgG29MmkN7JrnAZFtQFqzC6m4-80Rw@mail.gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC8367833E8@FHSDB2D11-2.csu.mcmaster.ca>
 <CA+hwERmdPZprwUMzEmxWtb+1kY5XLOdxrAmEwzXpgiukdbJbaA@mail.gmail.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC836783658@FHSDB2D11-2.csu.mcmaster.ca>

Dear Toni,

> -----Original Message-----
> From: Toni Hernandez-Matias [mailto:ahmatias at gmail.com]
> Sent: Thursday, February 22, 2018 10:01 AM
> To: Fox, John <jfox at mcmaster.ca>
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] variance inflation factor
> 
> Dear John,
> 
> Thank you very much for your message.
> 
> Did you know a bibliographic reference for this method, specifically in the case
> of generalized linear mixed models?

Sorry, I don't, but don't see why the general idea wouldn't apply here (as Ben mentioned in his response). By the way, the more general vif() function in the car package works for lme() in nlme but not for lmer() or glmer() in lme4 (because the result returned by vcov() for a "merMod" object isn't of class "matrix"). We should probably make it work.

Best,
 John

> 
> Thank you again,
> 
> Antonio
> 
> On Thu, Feb 22, 2018 at 3:51 PM, Fox, John <jfox at mcmaster.ca
> <mailto:jfox at mcmaster.ca> > wrote:
> 
> 
> 	Dear Toni,
> 
> 	Yes, that looks reasonable, although I'm not sure why it's necessary to
> test for more than one fixed-effect intercept at the beginning of the fixed-effect
> coefficient vector and how an intercept could be named "Intercept" rather than
> "(Intercept)". Assuming that there's a reason that escapes me, here's a simplified
> version:
> 
> 	vif.lme <- function (fit) {
> 	  ## adapted from rms::vif
> 	  v <- vcov(fit)
> 	  nam <- names(fixef(fit))
> 	  ## exclude intercepts
> 	  ns <- sum(nam == "Intercept" | nam == "(Intercept)")
> 	  if (ns > 0) v <- v[-(1:ns), -(1:ns), drop = FALSE]
> 	  diag(solve(cov2cor(v)))
> 	}
> 
> 	I hope this helps,
> 	 John
> 
> 
> 	-----------------------------
> 	John Fox, Professor Emeritus
> 	McMaster University
> 	Hamilton, Ontario, Canada
> 	Web: socialsciences.mcmaster.ca/jfox/
> <http://socialsciences.mcmaster.ca/jfox/>
> 
> 
> 
> 
> 	> -----Original Message-----
> 	> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-
> <mailto:r-sig-mixed-models-bounces at r->
> 	> project.org <http://project.org> ] On Behalf Of Toni Hernandez-
> Matias
> 	> Sent: Thursday, February 22, 2018 7:28 AM
> 	> To: r-sig-mixed-models at r-project.org <mailto:r-sig-mixed-models at r-
> project.org>
> 	> Subject: [R-sig-ME] variance inflation factor
> 	>
> 	> Dear all,
> 	>
> 	> Could some help me to calculate Variance Inflation Factors of models
> fitted
> 	> with glmer and lmer ?
> 	>
> 	> I found the method I copy below but I am not sure it is correct:
> 	>
> 	> vif.lme <- function (fit) {
> 	>      ## adapted from rms::vif
> 	>      v <- vcov(fit)
> 	>      nam <- names(fixef(fit))
> 	>      ## exclude intercepts
> 	>      ns <- sum(1 * (nam == "Intercept" | nam == "(Intercept)"))
> 	>      if (ns > 0) {
> 	>          v <- v[-(1:ns), -(1:ns), drop = FALSE]
> 	>          nam <- nam[-(1:ns)] }
> 	>      d <- diag(v)^0.5
> 	>      v <- diag(solve(v/(d %o% d)))
> 	>      names(v) <- nam
> 	>      v }
> 	>
> 	>
> 	>
> 	> ##la estimamos para el modelo 1
> 	>
> 	> vif.lme(mod1)
> 	>
> 	>
> 	> Thank you very much in advance,
> 	>
> 	> Antonio
> 	>
> 	>
> 	> --
> 	>
> *********************************************************
> 	>
> 	> Antonio Hernandez Matias
> 	>
> 	> Equip de Biologia de la Conservaci?
> 	> Departament de Biologia Evolutiva, Ecolog?a i Ci?ncies Ambientals
> Facultat de
> 	> Biologia  i Institut de Recerca de la Biodiversitat (IRBio) Universitat de
> 	> Barcelona (UB) Av. Diagonal, 643
> 	> Barcelona      08028
> 	> Spain
> 
> 	> Telephone: +34-934035857 <tel:%2B34-934035857>
> <+34%20934%2003%2058%2057>
> 	> FAX: +34-934035740 <tel:%2B34-934035740>
> <+34%20934%2003%2057%2040>
> 	> e-mail: ahernandezmatias at ub.edu
> <mailto:ahernandezmatias at ub.edu>
> 	>
> 	>
> ***********************************************************
> 	>
> 	>       [[alternative HTML version deleted]]
> 	>
> 	> _______________________________________________
> 	> R-sig-mixed-models at r-project.org <mailto:R-sig-mixed-models at r-
> project.org>  mailing list
> 	> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> 
> 
> 
> 
> 
> --
> 
> *********************************************************
> 
> Antonio Hernandez Matias
> 
> Equip de Biologia de la Conservaci?
> Departament de Biologia Evolutiva, Ecolog?a i Ci?ncies Ambientals Facultat de
> Biologia  i Institut de Recerca de la Biodiversitat (IRBio) Universitat de Barcelona
> (UB) Av. Diagonal, 643
> Barcelona      08028
> Spain
> Telephone: +34-934035857
> FAX: +34-934035740
> e-mail: ahernandezmatias at ub.edu <mailto:ahernandezmatias at ub.edu>
> 
> ***********************************************************

From ahmatias at gmail.com  Thu Feb 22 17:08:27 2018
From: ahmatias at gmail.com (Toni Hernandez-Matias)
Date: Thu, 22 Feb 2018 17:08:27 +0100
Subject: [R-sig-ME] variance inflation factor
In-Reply-To: <ACD1644AA6C67E4FBD0C350625508EC836783658@FHSDB2D11-2.csu.mcmaster.ca>
References: <16712_1519302508_w1MCSQRb026827_CA+hwERmYk2AgLOqW0PusMgG29MmkN7JrnAZFtQFqzC6m4-80Rw@mail.gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC8367833E8@FHSDB2D11-2.csu.mcmaster.ca>
 <CA+hwERmdPZprwUMzEmxWtb+1kY5XLOdxrAmEwzXpgiukdbJbaA@mail.gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC836783658@FHSDB2D11-2.csu.mcmaster.ca>
Message-ID: <CA+hwERnonduNRGNh+w8HdzD_tTmrS4J9G1c21rotP0mvkATGzw@mail.gmail.com>

Thank you very much John and Ben for your messages and the information that
really helps me.

Best regards,

Antonio

On Thu, Feb 22, 2018 at 5:01 PM, Fox, John <jfox at mcmaster.ca> wrote:

> Dear Toni,
>
> > -----Original Message-----
> > From: Toni Hernandez-Matias [mailto:ahmatias at gmail.com]
> > Sent: Thursday, February 22, 2018 10:01 AM
> > To: Fox, John <jfox at mcmaster.ca>
> > Cc: r-sig-mixed-models at r-project.org
> > Subject: Re: [R-sig-ME] variance inflation factor
> >
> > Dear John,
> >
> > Thank you very much for your message.
> >
> > Did you know a bibliographic reference for this method, specifically in
> the case
> > of generalized linear mixed models?
>
> Sorry, I don't, but don't see why the general idea wouldn't apply here (as
> Ben mentioned in his response). By the way, the more general vif() function
> in the car package works for lme() in nlme but not for lmer() or glmer() in
> lme4 (because the result returned by vcov() for a "merMod" object isn't of
> class "matrix"). We should probably make it work.
>
> Best,
>  John
>
> >
> > Thank you again,
> >
> > Antonio
> >
> > On Thu, Feb 22, 2018 at 3:51 PM, Fox, John <jfox at mcmaster.ca
> > <mailto:jfox at mcmaster.ca> > wrote:
> >
> >
> >       Dear Toni,
> >
> >       Yes, that looks reasonable, although I'm not sure why it's
> necessary to
> > test for more than one fixed-effect intercept at the beginning of the
> fixed-effect
> > coefficient vector and how an intercept could be named "Intercept"
> rather than
> > "(Intercept)". Assuming that there's a reason that escapes me, here's a
> simplified
> > version:
> >
> >       vif.lme <- function (fit) {
> >         ## adapted from rms::vif
> >         v <- vcov(fit)
> >         nam <- names(fixef(fit))
> >         ## exclude intercepts
> >         ns <- sum(nam == "Intercept" | nam == "(Intercept)")
> >         if (ns > 0) v <- v[-(1:ns), -(1:ns), drop = FALSE]
> >         diag(solve(cov2cor(v)))
> >       }
> >
> >       I hope this helps,
> >        John
> >
> >
> >       -----------------------------
> >       John Fox, Professor Emeritus
> >       McMaster University
> >       Hamilton, Ontario, Canada
> >       Web: socialsciences.mcmaster.ca/jfox/
> > <http://socialsciences.mcmaster.ca/jfox/>
> >
> >
> >
> >
> >       > -----Original Message-----
> >       > From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-
> > <mailto:r-sig-mixed-models-bounces at r->
> >       > project.org <http://project.org> ] On Behalf Of Toni Hernandez-
> > Matias
> >       > Sent: Thursday, February 22, 2018 7:28 AM
> >       > To: r-sig-mixed-models at r-project.org <mailto:
> r-sig-mixed-models at r-
> > project.org>
> >       > Subject: [R-sig-ME] variance inflation factor
> >       >
> >       > Dear all,
> >       >
> >       > Could some help me to calculate Variance Inflation Factors of
> models
> > fitted
> >       > with glmer and lmer ?
> >       >
> >       > I found the method I copy below but I am not sure it is correct:
> >       >
> >       > vif.lme <- function (fit) {
> >       >      ## adapted from rms::vif
> >       >      v <- vcov(fit)
> >       >      nam <- names(fixef(fit))
> >       >      ## exclude intercepts
> >       >      ns <- sum(1 * (nam == "Intercept" | nam == "(Intercept)"))
> >       >      if (ns > 0) {
> >       >          v <- v[-(1:ns), -(1:ns), drop = FALSE]
> >       >          nam <- nam[-(1:ns)] }
> >       >      d <- diag(v)^0.5
> >       >      v <- diag(solve(v/(d %o% d)))
> >       >      names(v) <- nam
> >       >      v }
> >       >
> >       >
> >       >
> >       > ##la estimamos para el modelo 1
> >       >
> >       > vif.lme(mod1)
> >       >
> >       >
> >       > Thank you very much in advance,
> >       >
> >       > Antonio
> >       >
> >       >
> >       > --
>

-- 
*********************************************************

Antonio Hernandez Matias

Equip de Biologia de la Conservaci?
Departament de Biologia Evolutiva, Ecolog?a i Ci?ncies Ambientals
Facultat de Biologia  i Institut de Recerca de la Biodiversitat (IRBio)
Universitat de Barcelona (UB)
Av. Diagonal, 643
Barcelona      08028
Spain
Telephone: +34-934035857
FAX: +34-934035740
e-mail: ahernandezmatias at ub.edu

***********************************************************

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Thu Feb 22 17:53:15 2018
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 22 Feb 2018 11:53:15 -0500
Subject: [R-sig-ME] variance inflation factor
In-Reply-To: <ACD1644AA6C67E4FBD0C350625508EC836783658@FHSDB2D11-2.csu.mcmaster.ca>
References: <16712_1519302508_w1MCSQRb026827_CA+hwERmYk2AgLOqW0PusMgG29MmkN7JrnAZFtQFqzC6m4-80Rw@mail.gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC8367833E8@FHSDB2D11-2.csu.mcmaster.ca>
 <CA+hwERmdPZprwUMzEmxWtb+1kY5XLOdxrAmEwzXpgiukdbJbaA@mail.gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC836783658@FHSDB2D11-2.csu.mcmaster.ca>
Message-ID: <CABghstRQTFV-DvrMWOzQfOXCQUf1Z11riPgCgHzj0dNSJ7WATg@mail.gmail.com>

  I don't know if there's a good reason that vcov() is a "dpoMatrix"
(from the Matrix package) rather than a plain old base-R matrix, but
as.matrix() converts it harmlessly (and shouldn't have any ill effects
on something that's already a matrix ...)

On Thu, Feb 22, 2018 at 11:01 AM, Fox, John <jfox at mcmaster.ca> wrote:
> Dear Toni,
>
>> -----Original Message-----
>> From: Toni Hernandez-Matias [mailto:ahmatias at gmail.com]
>> Sent: Thursday, February 22, 2018 10:01 AM
>> To: Fox, John <jfox at mcmaster.ca>
>> Cc: r-sig-mixed-models at r-project.org
>> Subject: Re: [R-sig-ME] variance inflation factor
>>
>> Dear John,
>>
>> Thank you very much for your message.
>>
>> Did you know a bibliographic reference for this method, specifically in the case
>> of generalized linear mixed models?
>
> Sorry, I don't, but don't see why the general idea wouldn't apply here (as Ben mentioned in his response). By the way, the more general vif() function in the car package works for lme() in nlme but not for lmer() or glmer() in lme4 (because the result returned by vcov() for a "merMod" object isn't of class "matrix"). We should probably make it work.
>
> Best,
>  John
>
>>
>> Thank you again,
>>
>> Antonio
>>
>> On Thu, Feb 22, 2018 at 3:51 PM, Fox, John <jfox at mcmaster.ca
>> <mailto:jfox at mcmaster.ca> > wrote:
>>
>>
>>       Dear Toni,
>>
>>       Yes, that looks reasonable, although I'm not sure why it's necessary to
>> test for more than one fixed-effect intercept at the beginning of the fixed-effect
>> coefficient vector and how an intercept could be named "Intercept" rather than
>> "(Intercept)". Assuming that there's a reason that escapes me, here's a simplified
>> version:
>>
>>       vif.lme <- function (fit) {
>>         ## adapted from rms::vif
>>         v <- vcov(fit)
>>         nam <- names(fixef(fit))
>>         ## exclude intercepts
>>         ns <- sum(nam == "Intercept" | nam == "(Intercept)")
>>         if (ns > 0) v <- v[-(1:ns), -(1:ns), drop = FALSE]
>>         diag(solve(cov2cor(v)))
>>       }
>>
>>       I hope this helps,
>>        John
>>
>>
>>       -----------------------------
>>       John Fox, Professor Emeritus
>>       McMaster University
>>       Hamilton, Ontario, Canada
>>       Web: socialsciences.mcmaster.ca/jfox/
>> <http://socialsciences.mcmaster.ca/jfox/>
>>
>>
>>
>>
>>       > -----Original Message-----
>>       > From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-
>> <mailto:r-sig-mixed-models-bounces at r->
>>       > project.org <http://project.org> ] On Behalf Of Toni Hernandez-
>> Matias
>>       > Sent: Thursday, February 22, 2018 7:28 AM
>>       > To: r-sig-mixed-models at r-project.org <mailto:r-sig-mixed-models at r-
>> project.org>
>>       > Subject: [R-sig-ME] variance inflation factor
>>       >
>>       > Dear all,
>>       >
>>       > Could some help me to calculate Variance Inflation Factors of models
>> fitted
>>       > with glmer and lmer ?
>>       >
>>       > I found the method I copy below but I am not sure it is correct:
>>       >
>>       > vif.lme <- function (fit) {
>>       >      ## adapted from rms::vif
>>       >      v <- vcov(fit)
>>       >      nam <- names(fixef(fit))
>>       >      ## exclude intercepts
>>       >      ns <- sum(1 * (nam == "Intercept" | nam == "(Intercept)"))
>>       >      if (ns > 0) {
>>       >          v <- v[-(1:ns), -(1:ns), drop = FALSE]
>>       >          nam <- nam[-(1:ns)] }
>>       >      d <- diag(v)^0.5
>>       >      v <- diag(solve(v/(d %o% d)))
>>       >      names(v) <- nam
>>       >      v }
>>       >
>>       >
>>       >
>>       > ##la estimamos para el modelo 1
>>       >
>>       > vif.lme(mod1)
>>       >
>>       >
>>       > Thank you very much in advance,
>>       >
>>       > Antonio
>>       >
>>       >
>>       > --
>>       >
>> *********************************************************
>>       >
>>       > Antonio Hernandez Matias
>>       >
>>       > Equip de Biologia de la Conservaci?
>>       > Departament de Biologia Evolutiva, Ecolog?a i Ci?ncies Ambientals
>> Facultat de
>>       > Biologia  i Institut de Recerca de la Biodiversitat (IRBio) Universitat de
>>       > Barcelona (UB) Av. Diagonal, 643
>>       > Barcelona      08028
>>       > Spain
>>
>>       > Telephone: +34-934035857 <tel:%2B34-934035857>
>> <+34%20934%2003%2058%2057>
>>       > FAX: +34-934035740 <tel:%2B34-934035740>
>> <+34%20934%2003%2057%2040>
>>       > e-mail: ahernandezmatias at ub.edu
>> <mailto:ahernandezmatias at ub.edu>
>>       >
>>       >
>> ***********************************************************
>>       >
>>       >       [[alternative HTML version deleted]]
>>       >
>>       > _______________________________________________
>>       > R-sig-mixed-models at r-project.org <mailto:R-sig-mixed-models at r-
>> project.org>  mailing list
>>       > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>
>>
>>
>>
>>
>> --
>>
>> *********************************************************
>>
>> Antonio Hernandez Matias
>>
>> Equip de Biologia de la Conservaci?
>> Departament de Biologia Evolutiva, Ecolog?a i Ci?ncies Ambientals Facultat de
>> Biologia  i Institut de Recerca de la Biodiversitat (IRBio) Universitat de Barcelona
>> (UB) Av. Diagonal, 643
>> Barcelona      08028
>> Spain
>> Telephone: +34-934035857
>> FAX: +34-934035740
>> e-mail: ahernandezmatias at ub.edu <mailto:ahernandezmatias at ub.edu>
>>
>> ***********************************************************


From jfox at mcmaster.ca  Thu Feb 22 18:24:00 2018
From: jfox at mcmaster.ca (Fox, John)
Date: Thu, 22 Feb 2018 17:24:00 +0000
Subject: [R-sig-ME] variance inflation factor
In-Reply-To: <CABghstRQTFV-DvrMWOzQfOXCQUf1Z11riPgCgHzj0dNSJ7WATg@mail.gmail.com>
References: <16712_1519302508_w1MCSQRb026827_CA+hwERmYk2AgLOqW0PusMgG29MmkN7JrnAZFtQFqzC6m4-80Rw@mail.gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC8367833E8@FHSDB2D11-2.csu.mcmaster.ca>
 <CA+hwERmdPZprwUMzEmxWtb+1kY5XLOdxrAmEwzXpgiukdbJbaA@mail.gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC836783658@FHSDB2D11-2.csu.mcmaster.ca>
 <CABghstRQTFV-DvrMWOzQfOXCQUf1Z11riPgCgHzj0dNSJ7WATg@mail.gmail.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC836783B86@FHSDB2D11-2.csu.mcmaster.ca>

Hi Ben,

> -----Original Message-----
> From: Ben Bolker [mailto:bbolker at gmail.com]
> Sent: Thursday, February 22, 2018 11:53 AM
> To: Fox, John <jfox at mcmaster.ca>
> Cc: Toni Hernandez-Matias <ahmatias at gmail.com>; r-sig-mixed-models at r-
> project.org
> Subject: Re: [R-sig-ME] variance inflation factor
> 
>   I don't know if there's a good reason that vcov() is a "dpoMatrix"
> (from the Matrix package) rather than a plain old base-R matrix, but
> as.matrix() converts it harmlessly (and shouldn't have any ill effects on
> something that's already a matrix ...)

Yes, I know that, but it prevents the default method for car::vif() from working because cov2cor() checks for a matrix:

> vif(mod)
Error in cov2cor(v) : 'V' is not a square numeric matrix
In addition: Warning message:
In vif.default(mod) :
Error in cov2cor(v) : 'V' is not a square numeric matrix  

It should be easy to get around this -- I'll probably just create a local, unexported version of cov2cor() in the car package, something like

cov2cor <- function(V) stats::cov2cor(as.matrix(V))

Best,
 John
 
> 
> On Thu, Feb 22, 2018 at 11:01 AM, Fox, John <jfox at mcmaster.ca> wrote:
> > Dear Toni,
> >
> >> -----Original Message-----
> >> From: Toni Hernandez-Matias [mailto:ahmatias at gmail.com]
> >> Sent: Thursday, February 22, 2018 10:01 AM
> >> To: Fox, John <jfox at mcmaster.ca>
> >> Cc: r-sig-mixed-models at r-project.org
> >> Subject: Re: [R-sig-ME] variance inflation factor
> >>
> >> Dear John,
> >>
> >> Thank you very much for your message.
> >>
> >> Did you know a bibliographic reference for this method, specifically
> >> in the case of generalized linear mixed models?
> >
> > Sorry, I don't, but don't see why the general idea wouldn't apply here (as Ben
> mentioned in his response). By the way, the more general vif() function in the
> car package works for lme() in nlme but not for lmer() or glmer() in lme4
> (because the result returned by vcov() for a "merMod" object isn't of class
> "matrix"). We should probably make it work.
> >
> > Best,
> >  John
> >
> >>
> >> Thank you again,
> >>
> >> Antonio
> >>
> >> On Thu, Feb 22, 2018 at 3:51 PM, Fox, John <jfox at mcmaster.ca
> >> <mailto:jfox at mcmaster.ca> > wrote:
> >>
> >>
> >>       Dear Toni,
> >>
> >>       Yes, that looks reasonable, although I'm not sure why it's
> >> necessary to test for more than one fixed-effect intercept at the
> >> beginning of the fixed-effect coefficient vector and how an intercept
> >> could be named "Intercept" rather than "(Intercept)". Assuming that
> >> there's a reason that escapes me, here's a simplified
> >> version:
> >>
> >>       vif.lme <- function (fit) {
> >>         ## adapted from rms::vif
> >>         v <- vcov(fit)
> >>         nam <- names(fixef(fit))
> >>         ## exclude intercepts
> >>         ns <- sum(nam == "Intercept" | nam == "(Intercept)")
> >>         if (ns > 0) v <- v[-(1:ns), -(1:ns), drop = FALSE]
> >>         diag(solve(cov2cor(v)))
> >>       }
> >>
> >>       I hope this helps,
> >>        John
> >>
> >>
> >>       -----------------------------
> >>       John Fox, Professor Emeritus
> >>       McMaster University
> >>       Hamilton, Ontario, Canada
> >>       Web: socialsciences.mcmaster.ca/jfox/
> >> <http://socialsciences.mcmaster.ca/jfox/>
> >>
> >>
> >>
> >>
> >>       > -----Original Message-----
> >>       > From: R-sig-mixed-models
> >> [mailto:r-sig-mixed-models-bounces at r-
> >> <mailto:r-sig-mixed-models-bounces at r->
> >>       > project.org <http://project.org> ] On Behalf Of Toni
> >> Hernandez- Matias
> >>       > Sent: Thursday, February 22, 2018 7:28 AM
> >>       > To: r-sig-mixed-models at r-project.org
> >> <mailto:r-sig-mixed-models at r- project.org>
> >>       > Subject: [R-sig-ME] variance inflation factor
> >>       >
> >>       > Dear all,
> >>       >
> >>       > Could some help me to calculate Variance Inflation Factors of
> >> models fitted
> >>       > with glmer and lmer ?
> >>       >
> >>       > I found the method I copy below but I am not sure it is correct:
> >>       >
> >>       > vif.lme <- function (fit) {
> >>       >      ## adapted from rms::vif
> >>       >      v <- vcov(fit)
> >>       >      nam <- names(fixef(fit))
> >>       >      ## exclude intercepts
> >>       >      ns <- sum(1 * (nam == "Intercept" | nam == "(Intercept)"))
> >>       >      if (ns > 0) {
> >>       >          v <- v[-(1:ns), -(1:ns), drop = FALSE]
> >>       >          nam <- nam[-(1:ns)] }
> >>       >      d <- diag(v)^0.5
> >>       >      v <- diag(solve(v/(d %o% d)))
> >>       >      names(v) <- nam
> >>       >      v }
> >>       >
> >>       >
> >>       >
> >>       > ##la estimamos para el modelo 1
> >>       >
> >>       > vif.lme(mod1)
> >>       >
> >>       >
> >>       > Thank you very much in advance,
> >>       >
> >>       > Antonio
> >>       >
> >>       >
> >>       > --
> >>       >
> >> *********************************************************
> >>       >
> >>       > Antonio Hernandez Matias
> >>       >
> >>       > Equip de Biologia de la Conservaci?
> >>       > Departament de Biologia Evolutiva, Ecolog?a i Ci?ncies
> >> Ambientals Facultat de
> >>       > Biologia  i Institut de Recerca de la Biodiversitat (IRBio) Universitat de
> >>       > Barcelona (UB) Av. Diagonal, 643
> >>       > Barcelona      08028
> >>       > Spain
> >>
> >>       > Telephone: +34-934035857 <tel:%2B34-934035857>
> >> <+34%20934%2003%2058%2057>
> >>       > FAX: +34-934035740 <tel:%2B34-934035740>
> >> <+34%20934%2003%2057%2040>
> >>       > e-mail: ahernandezmatias at ub.edu
> >> <mailto:ahernandezmatias at ub.edu>
> >>       >
> >>       >
> >>
> ***********************************************************
> >>       >
> >>       >       [[alternative HTML version deleted]]
> >>       >
> >>       > _______________________________________________
> >>       > R-sig-mixed-models at r-project.org
> >> <mailto:R-sig-mixed-models at r- project.org>  mailing list
> >>       > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >>
> >>
> >>
> >>
> >>
> >> --
> >>
> >> *********************************************************
> >>
> >> Antonio Hernandez Matias
> >>
> >> Equip de Biologia de la Conservaci?
> >> Departament de Biologia Evolutiva, Ecolog?a i Ci?ncies Ambientals
> >> Facultat de Biologia  i Institut de Recerca de la Biodiversitat
> >> (IRBio) Universitat de Barcelona
> >> (UB) Av. Diagonal, 643
> >> Barcelona      08028
> >> Spain
> >> Telephone: +34-934035857
> >> FAX: +34-934035740
> >> e-mail: ahernandezmatias at ub.edu <mailto:ahernandezmatias at ub.edu>
> >>
> >>
> ***********************************************************

From bbolker at gmail.com  Thu Feb 22 18:30:53 2018
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 22 Feb 2018 12:30:53 -0500
Subject: [R-sig-ME] variance inflation factor
In-Reply-To: <ACD1644AA6C67E4FBD0C350625508EC836783B86@FHSDB2D11-2.csu.mcmaster.ca>
References: <16712_1519302508_w1MCSQRb026827_CA+hwERmYk2AgLOqW0PusMgG29MmkN7JrnAZFtQFqzC6m4-80Rw@mail.gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC8367833E8@FHSDB2D11-2.csu.mcmaster.ca>
 <CA+hwERmdPZprwUMzEmxWtb+1kY5XLOdxrAmEwzXpgiukdbJbaA@mail.gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC836783658@FHSDB2D11-2.csu.mcmaster.ca>
 <CABghstRQTFV-DvrMWOzQfOXCQUf1Z11riPgCgHzj0dNSJ7WATg@mail.gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC836783B86@FHSDB2D11-2.csu.mcmaster.ca>
Message-ID: <CABghstQ0AZ4p3CUcYwTVaZGG7q4gUi4waFTs99Aa4UtttXVvPw@mail.gmail.com>

OK. I guess we could also change lme4 (hard to see why it would break
anything, and I can check downstream packages ...)

On Thu, Feb 22, 2018 at 12:24 PM, Fox, John <jfox at mcmaster.ca> wrote:
> Hi Ben,
>
>> -----Original Message-----
>> From: Ben Bolker [mailto:bbolker at gmail.com]
>> Sent: Thursday, February 22, 2018 11:53 AM
>> To: Fox, John <jfox at mcmaster.ca>
>> Cc: Toni Hernandez-Matias <ahmatias at gmail.com>; r-sig-mixed-models at r-
>> project.org
>> Subject: Re: [R-sig-ME] variance inflation factor
>>
>>   I don't know if there's a good reason that vcov() is a "dpoMatrix"
>> (from the Matrix package) rather than a plain old base-R matrix, but
>> as.matrix() converts it harmlessly (and shouldn't have any ill effects on
>> something that's already a matrix ...)
>
> Yes, I know that, but it prevents the default method for car::vif() from working because cov2cor() checks for a matrix:
>
>> vif(mod)
> Error in cov2cor(v) : 'V' is not a square numeric matrix
> In addition: Warning message:
> In vif.default(mod) :
> Error in cov2cor(v) : 'V' is not a square numeric matrix
>
> It should be easy to get around this -- I'll probably just create a local, unexported version of cov2cor() in the car package, something like
>
> cov2cor <- function(V) stats::cov2cor(as.matrix(V))
>
> Best,
>  John
>
>>
>> On Thu, Feb 22, 2018 at 11:01 AM, Fox, John <jfox at mcmaster.ca> wrote:
>> > Dear Toni,
>> >
>> >> -----Original Message-----
>> >> From: Toni Hernandez-Matias [mailto:ahmatias at gmail.com]
>> >> Sent: Thursday, February 22, 2018 10:01 AM
>> >> To: Fox, John <jfox at mcmaster.ca>
>> >> Cc: r-sig-mixed-models at r-project.org
>> >> Subject: Re: [R-sig-ME] variance inflation factor
>> >>
>> >> Dear John,
>> >>
>> >> Thank you very much for your message.
>> >>
>> >> Did you know a bibliographic reference for this method, specifically
>> >> in the case of generalized linear mixed models?
>> >
>> > Sorry, I don't, but don't see why the general idea wouldn't apply here (as Ben
>> mentioned in his response). By the way, the more general vif() function in the
>> car package works for lme() in nlme but not for lmer() or glmer() in lme4
>> (because the result returned by vcov() for a "merMod" object isn't of class
>> "matrix"). We should probably make it work.
>> >
>> > Best,
>> >  John
>> >
>> >>
>> >> Thank you again,
>> >>
>> >> Antonio
>> >>
>> >> On Thu, Feb 22, 2018 at 3:51 PM, Fox, John <jfox at mcmaster.ca
>> >> <mailto:jfox at mcmaster.ca> > wrote:
>> >>
>> >>
>> >>       Dear Toni,
>> >>
>> >>       Yes, that looks reasonable, although I'm not sure why it's
>> >> necessary to test for more than one fixed-effect intercept at the
>> >> beginning of the fixed-effect coefficient vector and how an intercept
>> >> could be named "Intercept" rather than "(Intercept)". Assuming that
>> >> there's a reason that escapes me, here's a simplified
>> >> version:
>> >>
>> >>       vif.lme <- function (fit) {
>> >>         ## adapted from rms::vif
>> >>         v <- vcov(fit)
>> >>         nam <- names(fixef(fit))
>> >>         ## exclude intercepts
>> >>         ns <- sum(nam == "Intercept" | nam == "(Intercept)")
>> >>         if (ns > 0) v <- v[-(1:ns), -(1:ns), drop = FALSE]
>> >>         diag(solve(cov2cor(v)))
>> >>       }
>> >>
>> >>       I hope this helps,
>> >>        John
>> >>
>> >>
>> >>       -----------------------------
>> >>       John Fox, Professor Emeritus
>> >>       McMaster University
>> >>       Hamilton, Ontario, Canada
>> >>       Web: socialsciences.mcmaster.ca/jfox/
>> >> <http://socialsciences.mcmaster.ca/jfox/>
>> >>
>> >>
>> >>
>> >>
>> >>       > -----Original Message-----
>> >>       > From: R-sig-mixed-models
>> >> [mailto:r-sig-mixed-models-bounces at r-
>> >> <mailto:r-sig-mixed-models-bounces at r->
>> >>       > project.org <http://project.org> ] On Behalf Of Toni
>> >> Hernandez- Matias
>> >>       > Sent: Thursday, February 22, 2018 7:28 AM
>> >>       > To: r-sig-mixed-models at r-project.org
>> >> <mailto:r-sig-mixed-models at r- project.org>
>> >>       > Subject: [R-sig-ME] variance inflation factor
>> >>       >
>> >>       > Dear all,
>> >>       >
>> >>       > Could some help me to calculate Variance Inflation Factors of
>> >> models fitted
>> >>       > with glmer and lmer ?
>> >>       >
>> >>       > I found the method I copy below but I am not sure it is correct:
>> >>       >
>> >>       > vif.lme <- function (fit) {
>> >>       >      ## adapted from rms::vif
>> >>       >      v <- vcov(fit)
>> >>       >      nam <- names(fixef(fit))
>> >>       >      ## exclude intercepts
>> >>       >      ns <- sum(1 * (nam == "Intercept" | nam == "(Intercept)"))
>> >>       >      if (ns > 0) {
>> >>       >          v <- v[-(1:ns), -(1:ns), drop = FALSE]
>> >>       >          nam <- nam[-(1:ns)] }
>> >>       >      d <- diag(v)^0.5
>> >>       >      v <- diag(solve(v/(d %o% d)))
>> >>       >      names(v) <- nam
>> >>       >      v }
>> >>       >
>> >>       >
>> >>       >
>> >>       > ##la estimamos para el modelo 1
>> >>       >
>> >>       > vif.lme(mod1)
>> >>       >
>> >>       >
>> >>       > Thank you very much in advance,
>> >>       >
>> >>       > Antonio
>> >>       >
>> >>       >
>> >>       > --
>> >>       >
>> >> *********************************************************
>> >>       >
>> >>       > Antonio Hernandez Matias
>> >>       >
>> >>       > Equip de Biologia de la Conservaci?
>> >>       > Departament de Biologia Evolutiva, Ecolog?a i Ci?ncies
>> >> Ambientals Facultat de
>> >>       > Biologia  i Institut de Recerca de la Biodiversitat (IRBio) Universitat de
>> >>       > Barcelona (UB) Av. Diagonal, 643
>> >>       > Barcelona      08028
>> >>       > Spain
>> >>
>> >>       > Telephone: +34-934035857 <tel:%2B34-934035857>
>> >> <+34%20934%2003%2058%2057>
>> >>       > FAX: +34-934035740 <tel:%2B34-934035740>
>> >> <+34%20934%2003%2057%2040>
>> >>       > e-mail: ahernandezmatias at ub.edu
>> >> <mailto:ahernandezmatias at ub.edu>
>> >>       >
>> >>       >
>> >>
>> ***********************************************************
>> >>       >
>> >>       >       [[alternative HTML version deleted]]
>> >>       >
>> >>       > _______________________________________________
>> >>       > R-sig-mixed-models at r-project.org
>> >> <mailto:R-sig-mixed-models at r- project.org>  mailing list
>> >>       > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>> >>
>> >>
>> >>
>> >>
>> >>
>> >> --
>> >>
>> >> *********************************************************
>> >>
>> >> Antonio Hernandez Matias
>> >>
>> >> Equip de Biologia de la Conservaci?
>> >> Departament de Biologia Evolutiva, Ecolog?a i Ci?ncies Ambientals
>> >> Facultat de Biologia  i Institut de Recerca de la Biodiversitat
>> >> (IRBio) Universitat de Barcelona
>> >> (UB) Av. Diagonal, 643
>> >> Barcelona      08028
>> >> Spain
>> >> Telephone: +34-934035857
>> >> FAX: +34-934035740
>> >> e-mail: ahernandezmatias at ub.edu <mailto:ahernandezmatias at ub.edu>
>> >>
>> >>
>> ***********************************************************


From jfox at mcmaster.ca  Thu Feb 22 18:34:59 2018
From: jfox at mcmaster.ca (Fox, John)
Date: Thu, 22 Feb 2018 17:34:59 +0000
Subject: [R-sig-ME] variance inflation factor
In-Reply-To: <CABghstQ0AZ4p3CUcYwTVaZGG7q4gUi4waFTs99Aa4UtttXVvPw@mail.gmail.com>
References: <16712_1519302508_w1MCSQRb026827_CA+hwERmYk2AgLOqW0PusMgG29MmkN7JrnAZFtQFqzC6m4-80Rw@mail.gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC8367833E8@FHSDB2D11-2.csu.mcmaster.ca>
 <CA+hwERmdPZprwUMzEmxWtb+1kY5XLOdxrAmEwzXpgiukdbJbaA@mail.gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC836783658@FHSDB2D11-2.csu.mcmaster.ca>
 <CABghstRQTFV-DvrMWOzQfOXCQUf1Z11riPgCgHzj0dNSJ7WATg@mail.gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC836783B86@FHSDB2D11-2.csu.mcmaster.ca>
 <CABghstQ0AZ4p3CUcYwTVaZGG7q4gUi4waFTs99Aa4UtttXVvPw@mail.gmail.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC836783BEB@FHSDB2D11-2.csu.mcmaster.ca>

Hi Ben,

> -----Original Message-----
> From: Ben Bolker [mailto:bbolker at gmail.com]
> Sent: Thursday, February 22, 2018 12:31 PM
> To: Fox, John <jfox at mcmaster.ca>
> Cc: Toni Hernandez-Matias <ahmatias at gmail.com>; r-sig-mixed-models at r-
> project.org
> Subject: Re: [R-sig-ME] variance inflation factor
> 
> OK. I guess we could also change lme4 (hard to see why it would break
> anything, and I can check downstream packages ...)

That's might open a can of worms. I suppose, alternatively, you could introduce a cov2cor() method for "dpoMatrix" objects, which probably would be safer.

Best,
 John

> 
> On Thu, Feb 22, 2018 at 12:24 PM, Fox, John <jfox at mcmaster.ca> wrote:
> > Hi Ben,
> >
> >> -----Original Message-----
> >> From: Ben Bolker [mailto:bbolker at gmail.com]
> >> Sent: Thursday, February 22, 2018 11:53 AM
> >> To: Fox, John <jfox at mcmaster.ca>
> >> Cc: Toni Hernandez-Matias <ahmatias at gmail.com>; r-sig-mixed-models at r-
> >> project.org
> >> Subject: Re: [R-sig-ME] variance inflation factor
> >>
> >>   I don't know if there's a good reason that vcov() is a "dpoMatrix"
> >> (from the Matrix package) rather than a plain old base-R matrix, but
> >> as.matrix() converts it harmlessly (and shouldn't have any ill
> >> effects on something that's already a matrix ...)
> >
> > Yes, I know that, but it prevents the default method for car::vif() from working
> because cov2cor() checks for a matrix:
> >
> >> vif(mod)
> > Error in cov2cor(v) : 'V' is not a square numeric matrix In addition:
> > Warning message:
> > In vif.default(mod) :
> > Error in cov2cor(v) : 'V' is not a square numeric matrix
> >
> > It should be easy to get around this -- I'll probably just create a
> > local, unexported version of cov2cor() in the car package, something
> > like
> >
> > cov2cor <- function(V) stats::cov2cor(as.matrix(V))
> >
> > Best,
> >  John
> >
> >>
> >> On Thu, Feb 22, 2018 at 11:01 AM, Fox, John <jfox at mcmaster.ca> wrote:
> >> > Dear Toni,
> >> >
> >> >> -----Original Message-----
> >> >> From: Toni Hernandez-Matias [mailto:ahmatias at gmail.com]
> >> >> Sent: Thursday, February 22, 2018 10:01 AM
> >> >> To: Fox, John <jfox at mcmaster.ca>
> >> >> Cc: r-sig-mixed-models at r-project.org
> >> >> Subject: Re: [R-sig-ME] variance inflation factor
> >> >>
> >> >> Dear John,
> >> >>
> >> >> Thank you very much for your message.
> >> >>
> >> >> Did you know a bibliographic reference for this method,
> >> >> specifically in the case of generalized linear mixed models?
> >> >
> >> > Sorry, I don't, but don't see why the general idea wouldn't apply
> >> > here (as Ben
> >> mentioned in his response). By the way, the more general vif()
> >> function in the car package works for lme() in nlme but not for
> >> lmer() or glmer() in lme4 (because the result returned by vcov() for
> >> a "merMod" object isn't of class "matrix"). We should probably make it
> work.
> >> >
> >> > Best,
> >> >  John
> >> >
> >> >>
> >> >> Thank you again,
> >> >>
> >> >> Antonio
> >> >>
> >> >> On Thu, Feb 22, 2018 at 3:51 PM, Fox, John <jfox at mcmaster.ca
> >> >> <mailto:jfox at mcmaster.ca> > wrote:
> >> >>
> >> >>
> >> >>       Dear Toni,
> >> >>
> >> >>       Yes, that looks reasonable, although I'm not sure why it's
> >> >> necessary to test for more than one fixed-effect intercept at the
> >> >> beginning of the fixed-effect coefficient vector and how an
> >> >> intercept could be named "Intercept" rather than "(Intercept)".
> >> >> Assuming that there's a reason that escapes me, here's a
> >> >> simplified
> >> >> version:
> >> >>
> >> >>       vif.lme <- function (fit) {
> >> >>         ## adapted from rms::vif
> >> >>         v <- vcov(fit)
> >> >>         nam <- names(fixef(fit))
> >> >>         ## exclude intercepts
> >> >>         ns <- sum(nam == "Intercept" | nam == "(Intercept)")
> >> >>         if (ns > 0) v <- v[-(1:ns), -(1:ns), drop = FALSE]
> >> >>         diag(solve(cov2cor(v)))
> >> >>       }
> >> >>
> >> >>       I hope this helps,
> >> >>        John
> >> >>
> >> >>
> >> >>       -----------------------------
> >> >>       John Fox, Professor Emeritus
> >> >>       McMaster University
> >> >>       Hamilton, Ontario, Canada
> >> >>       Web: socialsciences.mcmaster.ca/jfox/
> >> >> <http://socialsciences.mcmaster.ca/jfox/>
> >> >>
> >> >>
> >> >>
> >> >>
> >> >>       > -----Original Message-----
> >> >>       > From: R-sig-mixed-models
> >> >> [mailto:r-sig-mixed-models-bounces at r-
> >> >> <mailto:r-sig-mixed-models-bounces at r->
> >> >>       > project.org <http://project.org> ] On Behalf Of Toni
> >> >> Hernandez- Matias
> >> >>       > Sent: Thursday, February 22, 2018 7:28 AM
> >> >>       > To: r-sig-mixed-models at r-project.org
> >> >> <mailto:r-sig-mixed-models at r- project.org>
> >> >>       > Subject: [R-sig-ME] variance inflation factor
> >> >>       >
> >> >>       > Dear all,
> >> >>       >
> >> >>       > Could some help me to calculate Variance Inflation Factors
> >> >> of models fitted
> >> >>       > with glmer and lmer ?
> >> >>       >
> >> >>       > I found the method I copy below but I am not sure it is correct:
> >> >>       >
> >> >>       > vif.lme <- function (fit) {
> >> >>       >      ## adapted from rms::vif
> >> >>       >      v <- vcov(fit)
> >> >>       >      nam <- names(fixef(fit))
> >> >>       >      ## exclude intercepts
> >> >>       >      ns <- sum(1 * (nam == "Intercept" | nam == "(Intercept)"))
> >> >>       >      if (ns > 0) {
> >> >>       >          v <- v[-(1:ns), -(1:ns), drop = FALSE]
> >> >>       >          nam <- nam[-(1:ns)] }
> >> >>       >      d <- diag(v)^0.5
> >> >>       >      v <- diag(solve(v/(d %o% d)))
> >> >>       >      names(v) <- nam
> >> >>       >      v }
> >> >>       >
> >> >>       >
> >> >>       >
> >> >>       > ##la estimamos para el modelo 1
> >> >>       >
> >> >>       > vif.lme(mod1)
> >> >>       >
> >> >>       >
> >> >>       > Thank you very much in advance,
> >> >>       >
> >> >>       > Antonio
> >> >>       >
> >> >>       >
> >> >>       > --
> >> >>       >
> >> >>
> *********************************************************
> >> >>       >
> >> >>       > Antonio Hernandez Matias
> >> >>       >
> >> >>       > Equip de Biologia de la Conservaci?
> >> >>       > Departament de Biologia Evolutiva, Ecolog?a i Ci?ncies
> >> >> Ambientals Facultat de
> >> >>       > Biologia  i Institut de Recerca de la Biodiversitat (IRBio) Universitat de
> >> >>       > Barcelona (UB) Av. Diagonal, 643
> >> >>       > Barcelona      08028
> >> >>       > Spain
> >> >>
> >> >>       > Telephone: +34-934035857 <tel:%2B34-934035857>
> >> >> <+34%20934%2003%2058%2057>
> >> >>       > FAX: +34-934035740 <tel:%2B34-934035740>
> >> >> <+34%20934%2003%2057%2040>
> >> >>       > e-mail: ahernandezmatias at ub.edu
> >> >> <mailto:ahernandezmatias at ub.edu>
> >> >>       >
> >> >>       >
> >> >>
> >>
> ***********************************************************
> >> >>       >
> >> >>       >       [[alternative HTML version deleted]]
> >> >>       >
> >> >>       > _______________________________________________
> >> >>       > R-sig-mixed-models at r-project.org
> >> >> <mailto:R-sig-mixed-models at r- project.org>  mailing list
> >> >>       > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >> >> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >> >>
> >> >>
> >> >>
> >> >>
> >> >>
> >> >> --
> >> >>
> >> >>
> *********************************************************
> >> >>
> >> >> Antonio Hernandez Matias
> >> >>
> >> >> Equip de Biologia de la Conservaci? Departament de Biologia
> >> >> Evolutiva, Ecolog?a i Ci?ncies Ambientals Facultat de Biologia  i
> >> >> Institut de Recerca de la Biodiversitat
> >> >> (IRBio) Universitat de Barcelona
> >> >> (UB) Av. Diagonal, 643
> >> >> Barcelona      08028
> >> >> Spain
> >> >> Telephone: +34-934035857
> >> >> FAX: +34-934035740
> >> >> e-mail: ahernandezmatias at ub.edu <mailto:ahernandezmatias at ub.edu>
> >> >>
> >> >>
> >>
> ***********************************************************

From peter.schlattmann at med.uni-jena.de  Thu Feb 22 08:49:50 2018
From: peter.schlattmann at med.uni-jena.de (Schlattmann, Peter)
Date: Thu, 22 Feb 2018 07:49:50 +0000
Subject: [R-sig-ME] prediction in glmer
Message-ID: <A606BAEE686DE4489CD1EA8399E87B6EA6CA8481@EXCHDB1.krz.uni-jena.de>

Dear all,




I am fitting a generalized linear mixed model with lme4 using glmer

 with binomial errors and logit link. I am using the ?predict? function

 to obtain predicted values for the current model and data set.

 Here is some sample code

 m.age50<-glmer(ct_pos~cath_pos+(1+cath_pos|study_no),data=test, amily=binomial,na.action=na.omit)

 result.age50<-predict(m.age50)



My question is now: How exactly are the predictions calculated? I  could not find any details in the documentation.  Are these  just

 based on the fixed effects setting the random effects to zero? Or are  these empirical Bayes estimates?

Is there any documentation available?





Thank  you very much in advance.



Peter


Universit?tsklinikum Jena - Bachstrasse 18 - D-07743 Jena
Die gesetzlichen Pflichtangaben finden Sie unter http://www.uniklinikum-jena.de/Pflichtangaben.html

	[[alternative HTML version deleted]]


From maechler at stat.math.ethz.ch  Fri Feb 23 22:47:30 2018
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 23 Feb 2018 22:47:30 +0100
Subject: [R-sig-ME] variance inflation factor
In-Reply-To: <ACD1644AA6C67E4FBD0C350625508EC836783BEB@FHSDB2D11-2.csu.mcmaster.ca>
References: <16712_1519302508_w1MCSQRb026827_CA+hwERmYk2AgLOqW0PusMgG29MmkN7JrnAZFtQFqzC6m4-80Rw@mail.gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC8367833E8@FHSDB2D11-2.csu.mcmaster.ca>
 <CA+hwERmdPZprwUMzEmxWtb+1kY5XLOdxrAmEwzXpgiukdbJbaA@mail.gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC836783658@FHSDB2D11-2.csu.mcmaster.ca>
 <CABghstRQTFV-DvrMWOzQfOXCQUf1Z11riPgCgHzj0dNSJ7WATg@mail.gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC836783B86@FHSDB2D11-2.csu.mcmaster.ca>
 <CABghstQ0AZ4p3CUcYwTVaZGG7q4gUi4waFTs99Aa4UtttXVvPw@mail.gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC836783BEB@FHSDB2D11-2.csu.mcmaster.ca>
Message-ID: <23184.35826.783956.370260@stat.math.ethz.ch>

>>>>> Fox, John <jfox at mcmaster.ca>
>>>>>     on Thu, 22 Feb 2018 17:34:59 +0000 writes:

    > Hi Ben,
    >> -----Original Message----- From: Ben Bolker
    >> [mailto:bbolker at gmail.com] Sent: Thursday, February 22,
    >> 2018 12:31 PM To: Fox, John <jfox at mcmaster.ca> Cc: Toni
    >> Hernandez-Matias <ahmatias at gmail.com>;
    >> r-sig-mixed-models at r- project.org Subject: Re: [R-sig-ME]
    >> variance inflation factor
    >> 
    >> OK. I guess we could also change lme4 (hard to see why it
    >> would break anything, and I can check downstream packages
    >> ...)

    > That's might open a can of worms. I suppose,
    > alternatively, you could introduce a cov2cor() method for
    > "dpoMatrix" objects, which probably would be safer.

    > Best, John

I strongly agree with John here.

Initial note:
Look at the examples on the  ?lmer   help page, or just run
  example(lmer)

to see how things work already, basically

   V <- vcov( lmer(....)  )
   R <- as(V, "corMatrix")

Note that with a "dpoMatrix" it is implicitly known that you
have a positive (semi)definite symmetric matrix and that *is*
useful information for subsequent methods / algorithms... even
though that information may rarely be made used of in current R
code outside the Matrix package.

I did not look into 'car',  but just using lme4, cov2cor()  already works :

> require(lme4)

> (fm1 <- lmer(Reaction ~ Days + (Days | Subject), sleepstudy))
Linear mixed model fit by REML ['lmerMod']
Formula: Reaction ~ Days + (Days | Subject)
   Data: sleepstudy
REML criterion at convergence: 1743.628
Random effects:
 Groups   Name        Std.Dev. Corr
 Subject  (Intercept) 24.740       
          Days         5.922   0.07
 Residual             25.592       
Number of obs: 180, groups:  Subject, 18
Fixed Effects:
(Intercept)         Days  
     251.41        10.47  
> (V <- vcov(fm1))
2 x 2 Matrix of class "dpoMatrix"
            (Intercept)      Days
(Intercept)   46.574562 -1.451096
Days          -1.451096  2.389463
> cov2cor(V)
2 x 2 Matrix of class "dpoMatrix"
            (Intercept)       Days
(Intercept)   1.0000000 -0.1375534
Days         -0.1375534  1.0000000
> as(V, "corMatrix")
2 x 2 Matrix of class "corMatrix"
            (Intercept)       Days
(Intercept)   1.0000000 -0.1375534
Days         -0.1375534  1.0000000
> sessionInfo()
R version 3.4.3 Patched (2018-02-19 r74280)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Fedora 26 (Twenty Six)

[.........................]

attached base packages:
[1] graphics  grDevices datasets  stats     utils     methods   base     

other attached packages:
[1] lme4_1.1-16    Matrix_1.2-12  fortunes_1.5-4 sfsmisc_1.1-2 

loaded via a namespace (and not attached):
 [1] minqa_1.2.4     MASS_7.3-48     compiler_3.4.3  tools_3.4.3    
 [5] Rcpp_0.12.15    splines_3.4.3   nlme_3.1-131.1  grid_3.4.3     
 [9] nloptr_1.0.4    lattice_0.20-35
> 
----------------------

So, I remain a bit puzzled on why you observe the problems you observe.
May 'car' needs to import some stuff from Matrix or lme4  so these
methods do work there, too ?

Martin Maechler
ETH Zurich

    >> On Thu, Feb 22, 2018 at 12:24 PM, Fox, John <jfox at mcmaster.ca> wrote:
    >> > Hi Ben,
    >> >
    >> >> -----Original Message-----
    >> >> From: Ben Bolker [mailto:bbolker at gmail.com]
    >> >> Sent: Thursday, February 22, 2018 11:53 AM
    >> >> To: Fox, John <jfox at mcmaster.ca>
    >> >> Cc: Toni Hernandez-Matias <ahmatias at gmail.com>; r-sig-mixed-models at r-
    >> >> project.org
    >> >> Subject: Re: [R-sig-ME] variance inflation factor
    >> >>
    >> >>   I don't know if there's a good reason that vcov() is a "dpoMatrix"
    >> >> (from the Matrix package) rather than a plain old base-R matrix, but
    >> >> as.matrix() converts it harmlessly (and shouldn't have any ill
    >> >> effects on something that's already a matrix ...)
    >> >
    >> > Yes, I know that, but it prevents the default method for car::vif() from working
    >> because cov2cor() checks for a matrix:
    >> >
    >> >> vif(mod)
    >> > Error in cov2cor(v) : 'V' is not a square numeric matrix In addition:
    >> > Warning message:
    >> > In vif.default(mod) :
    >> > Error in cov2cor(v) : 'V' is not a square numeric matrix
    >> >
    >> > It should be easy to get around this -- I'll probably just create a
    >> > local, unexported version of cov2cor() in the car package, something
    >> > like
    >> >
    >> > cov2cor <- function(V) stats::cov2cor(as.matrix(V))
    >> >
    >> > Best,
    >> >  John
    >> >
    >> >>
    >> >> On Thu, Feb 22, 2018 at 11:01 AM, Fox, John <jfox at mcmaster.ca> wrote:
    >> >> > Dear Toni,
    >> >> >
    >> >> >> -----Original Message-----
    >> >> >> From: Toni Hernandez-Matias [mailto:ahmatias at gmail.com]
    >> >> >> Sent: Thursday, February 22, 2018 10:01 AM
    >> >> >> To: Fox, John <jfox at mcmaster.ca>
    >> >> >> Cc: r-sig-mixed-models at r-project.org
    >> >> >> Subject: Re: [R-sig-ME] variance inflation factor
    >> >> >>
    >> >> >> Dear John,
    >> >> >>
    >> >> >> Thank you very much for your message.
    >> >> >>
    >> >> >> Did you know a bibliographic reference for this method,
    >> >> >> specifically in the case of generalized linear mixed models?
    >> >> >
    >> >> > Sorry, I don't, but don't see why the general idea wouldn't apply
    >> >> > here (as Ben
    >> >> mentioned in his response). By the way, the more general vif()
    >> >> function in the car package works for lme() in nlme but not for
    >> >> lmer() or glmer() in lme4 (because the result returned by vcov() for
    >> >> a "merMod" object isn't of class "matrix"). We should probably make it
    >> work.
    >> >> >
    >> >> > Best,
    >> >> >  John
    >> >> >
    >> >> >>
    >> >> >> Thank you again,
    >> >> >>
    >> >> >> Antonio
    >> >> >>
    >> >> >> On Thu, Feb 22, 2018 at 3:51 PM, Fox, John <jfox at mcmaster.ca
    >> >> >> <mailto:jfox at mcmaster.ca> > wrote:
    >> >> >>
    >> >> >>
    >> >> >>       Dear Toni,
    >> >> >>
    >> >> >>       Yes, that looks reasonable, although I'm not sure why it's
    >> >> >> necessary to test for more than one fixed-effect intercept at the
    >> >> >> beginning of the fixed-effect coefficient vector and how an
    >> >> >> intercept could be named "Intercept" rather than "(Intercept)".
    >> >> >> Assuming that there's a reason that escapes me, here's a
    >> >> >> simplified
    >> >> >> version:
    >> >> >>
    >> >> >>       vif.lme <- function (fit) {
    >> >> >>         ## adapted from rms::vif
    >> >> >>         v <- vcov(fit)
    >> >> >>         nam <- names(fixef(fit))
    >> >> >>         ## exclude intercepts
    >> >> >>         ns <- sum(nam == "Intercept" | nam == "(Intercept)")
    >> >> >>         if (ns > 0) v <- v[-(1:ns), -(1:ns), drop = FALSE]
    >> >> >>         diag(solve(cov2cor(v)))
    >> >> >>       }
    >> >> >>
    >> >> >>       I hope this helps,
    >> >> >>        John
    >> >> >>
    >> >> >>
    >> >> >>       -----------------------------
    >> >> >>       John Fox, Professor Emeritus
    >> >> >>       McMaster University
    >> >> >>       Hamilton, Ontario, Canada
    >> >> >>       Web: socialsciences.mcmaster.ca/jfox/
    >> >> >> <http://socialsciences.mcmaster.ca/jfox/>
    >> >> >>
    >> >> >>
    >> >> >>
    >> >> >>
    >> >> >>       > -----Original Message-----
    >> >> >>       > From: R-sig-mixed-models
    >> >> >> [mailto:r-sig-mixed-models-bounces at r-
    >> >> >> <mailto:r-sig-mixed-models-bounces at r->
    >> >> >>       > project.org <http://project.org> ] On Behalf Of Toni
    >> >> >> Hernandez- Matias
    >> >> >>       > Sent: Thursday, February 22, 2018 7:28 AM
    >> >> >>       > To: r-sig-mixed-models at r-project.org
    >> >> >> <mailto:r-sig-mixed-models at r- project.org>
    >> >> >>       > Subject: [R-sig-ME] variance inflation factor
    >> >> >>       >
    >> >> >>       > Dear all,
    >> >> >>       >
    >> >> >>       > Could some help me to calculate Variance Inflation Factors
    >> >> >> of models fitted
    >> >> >>       > with glmer and lmer ?
    >> >> >>       >
    >> >> >>       > I found the method I copy below but I am not sure it is correct:
    >> >> >>       >
    >> >> >>       > vif.lme <- function (fit) {
    >> >> >>       >      ## adapted from rms::vif
    >> >> >>       >      v <- vcov(fit)
    >> >> >>       >      nam <- names(fixef(fit))
    >> >> >>       >      ## exclude intercepts
    >> >> >>       >      ns <- sum(1 * (nam == "Intercept" | nam == "(Intercept)"))
    >> >> >>       >      if (ns > 0) {
    >> >> >>       >          v <- v[-(1:ns), -(1:ns), drop = FALSE]
    >> >> >>       >          nam <- nam[-(1:ns)] }
    >> >> >>       >      d <- diag(v)^0.5
    >> >> >>       >      v <- diag(solve(v/(d %o% d)))
    >> >> >>       >      names(v) <- nam
    >> >> >>       >      v }
    >> >> >>       >
    >> >> >>       >
    >> >> >>       >
    >> >> >>       > ##la estimamos para el modelo 1
    >> >> >>       >
    >> >> >>       > vif.lme(mod1)
    >> >> >>       >
    >> >> >>       >
    >> >> >>       > Thank you very much in advance,
    >> >> >>       >
    >> >> >>       > Antonio
    >> >> >>       >
    >> >> >>       >
    >> >> >>       > --
    >> >> >>       >
    >> >> >>
    >> *********************************************************
    >> >> >>       >
    >> >> >>       > Antonio Hernandez Matias
    >> >> >>       >
    >> >> >>       > Equip de Biologia de la Conservaci?
    >> >> >>       > Departament de Biologia Evolutiva, Ecolog?a i Ci?ncies
    >> >> >> Ambientals Facultat de
    >> >> >>       > Biologia  i Institut de Recerca de la Biodiversitat (IRBio) Universitat de
    >> >> >>       > Barcelona (UB) Av. Diagonal, 643
    >> >> >>       > Barcelona      08028
    >> >> >>       > Spain
    >> >> >>
    >> >> >>       > Telephone: +34-934035857 <tel:%2B34-934035857>
    >> >> >> <+34%20934%2003%2058%2057>
    >> >> >>       > FAX: +34-934035740 <tel:%2B34-934035740>
    >> >> >> <+34%20934%2003%2057%2040>
    >> >> >>       > e-mail: ahernandezmatias at ub.edu
    >> >> >> <mailto:ahernandezmatias at ub.edu>

    > _______________________________________________
    > R-sig-mixed-models at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From istazahn at gmail.com  Fri Feb 23 23:22:03 2018
From: istazahn at gmail.com (Ista Zahn)
Date: Fri, 23 Feb 2018 17:22:03 -0500
Subject: [R-sig-ME] prediction in glmer
In-Reply-To: <A606BAEE686DE4489CD1EA8399E87B6EA6CA8481@EXCHDB1.krz.uni-jena.de>
References: <A606BAEE686DE4489CD1EA8399E87B6EA6CA8481@EXCHDB1.krz.uni-jena.de>
Message-ID: <CA+vqiLHfA=K-zQnsotJGQ5d-+-Lg9nNFXDY=F9rfdUNzbb-anA@mail.gmail.com>

Hi Peter,

Did you see

?predict.merMod

Best,
Ista

On Thu, Feb 22, 2018 at 2:49 AM, Schlattmann, Peter
<peter.schlattmann at med.uni-jena.de> wrote:
> Dear all,
>
>
>
>
> I am fitting a generalized linear mixed model with lme4 using glmer
>
>  with binomial errors and logit link. I am using the ?predict? function
>
>  to obtain predicted values for the current model and data set.
>
>  Here is some sample code
>
>  m.age50<-glmer(ct_pos~cath_pos+(1+cath_pos|study_no),data=test, amily=binomial,na.action=na.omit)
>
>  result.age50<-predict(m.age50)
>
>
>
> My question is now: How exactly are the predictions calculated? I  could not find any details in the documentation.  Are these  just
>
>  based on the fixed effects setting the random effects to zero? Or are  these empirical Bayes estimates?
>
> Is there any documentation available?
>
>
>
>
>
> Thank  you very much in advance.
>
>
>
> Peter
>
>
> Universit?tsklinikum Jena - Bachstrasse 18 - D-07743 Jena
> Die gesetzlichen Pflichtangaben finden Sie unter http://www.uniklinikum-jena.de/Pflichtangaben.html
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From jfox at mcmaster.ca  Sat Feb 24 01:17:18 2018
From: jfox at mcmaster.ca (Fox, John)
Date: Sat, 24 Feb 2018 00:17:18 +0000
Subject: [R-sig-ME] variance inflation factor
In-Reply-To: <23184.35826.783956.370260@stat.math.ethz.ch>
References: <16712_1519302508_w1MCSQRb026827_CA+hwERmYk2AgLOqW0PusMgG29MmkN7JrnAZFtQFqzC6m4-80Rw@mail.gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC8367833E8@FHSDB2D11-2.csu.mcmaster.ca>
 <CA+hwERmdPZprwUMzEmxWtb+1kY5XLOdxrAmEwzXpgiukdbJbaA@mail.gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC836783658@FHSDB2D11-2.csu.mcmaster.ca>
 <CABghstRQTFV-DvrMWOzQfOXCQUf1Z11riPgCgHzj0dNSJ7WATg@mail.gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC836783B86@FHSDB2D11-2.csu.mcmaster.ca>
 <CABghstQ0AZ4p3CUcYwTVaZGG7q4gUi4waFTs99Aa4UtttXVvPw@mail.gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC836783BEB@FHSDB2D11-2.csu.mcmaster.ca>
 <23184.35826.783956.370260@stat.math.ethz.ch>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC836785532@FHSDB2D11-2.csu.mcmaster.ca>

Dear Martin,

I've already handled this in the development version of car, where I introduced a vif.merMod() method. The general point may still be valid.

Best,
 John

> -----Original Message-----
> From: Martin Maechler [mailto:maechler at stat.math.ethz.ch]
> Sent: Friday, February 23, 2018 4:48 PM
> To: Fox, John <jfox at mcmaster.ca>
> Cc: Ben Bolker <bbolker at gmail.com>; r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] variance inflation factor
> 
> >>>>> Fox, John <jfox at mcmaster.ca>
> >>>>>     on Thu, 22 Feb 2018 17:34:59 +0000 writes:
> 
>     > Hi Ben,
>     >> -----Original Message----- From: Ben Bolker
>     >> [mailto:bbolker at gmail.com] Sent: Thursday, February 22,
>     >> 2018 12:31 PM To: Fox, John <jfox at mcmaster.ca> Cc: Toni
>     >> Hernandez-Matias <ahmatias at gmail.com>;
>     >> r-sig-mixed-models at r- project.org Subject: Re: [R-sig-ME]
>     >> variance inflation factor
>     >>
>     >> OK. I guess we could also change lme4 (hard to see why it
>     >> would break anything, and I can check downstream packages
>     >> ...)
> 
>     > That's might open a can of worms. I suppose,
>     > alternatively, you could introduce a cov2cor() method for
>     > "dpoMatrix" objects, which probably would be safer.
> 
>     > Best, John
> 
> I strongly agree with John here.
> 
> Initial note:
> Look at the examples on the  ?lmer   help page, or just run
>   example(lmer)
> 
> to see how things work already, basically
> 
>    V <- vcov( lmer(....)  )
>    R <- as(V, "corMatrix")
> 
> Note that with a "dpoMatrix" it is implicitly known that you have a positive
> (semi)definite symmetric matrix and that *is* useful information for subsequent
> methods / algorithms... even though that information may rarely be made used
> of in current R code outside the Matrix package.
> 
> I did not look into 'car',  but just using lme4, cov2cor()  already works :
> 
> > require(lme4)
> 
> > (fm1 <- lmer(Reaction ~ Days + (Days | Subject), sleepstudy))
> Linear mixed model fit by REML ['lmerMod']
> Formula: Reaction ~ Days + (Days | Subject)
>    Data: sleepstudy
> REML criterion at convergence: 1743.628
> Random effects:
>  Groups   Name        Std.Dev. Corr
>  Subject  (Intercept) 24.740
>           Days         5.922   0.07
>  Residual             25.592
> Number of obs: 180, groups:  Subject, 18 Fixed Effects:
> (Intercept)         Days
>      251.41        10.47
> > (V <- vcov(fm1))
> 2 x 2 Matrix of class "dpoMatrix"
>             (Intercept)      Days
> (Intercept)   46.574562 -1.451096
> Days          -1.451096  2.389463
> > cov2cor(V)
> 2 x 2 Matrix of class "dpoMatrix"
>             (Intercept)       Days
> (Intercept)   1.0000000 -0.1375534
> Days         -0.1375534  1.0000000
> > as(V, "corMatrix")
> 2 x 2 Matrix of class "corMatrix"
>             (Intercept)       Days
> (Intercept)   1.0000000 -0.1375534
> Days         -0.1375534  1.0000000
> > sessionInfo()
> R version 3.4.3 Patched (2018-02-19 r74280)
> Platform: x86_64-pc-linux-gnu (64-bit)
> Running under: Fedora 26 (Twenty Six)
> 
> [.........................]
> 
> attached base packages:
> [1] graphics  grDevices datasets  stats     utils     methods   base
> 
> other attached packages:
> [1] lme4_1.1-16    Matrix_1.2-12  fortunes_1.5-4 sfsmisc_1.1-2
> 
> loaded via a namespace (and not attached):
>  [1] minqa_1.2.4     MASS_7.3-48     compiler_3.4.3  tools_3.4.3
>  [5] Rcpp_0.12.15    splines_3.4.3   nlme_3.1-131.1  grid_3.4.3
>  [9] nloptr_1.0.4    lattice_0.20-35
> >
> ----------------------
> 
> So, I remain a bit puzzled on why you observe the problems you observe.
> May 'car' needs to import some stuff from Matrix or lme4  so these methods do
> work there, too ?
> 
> Martin Maechler
> ETH Zurich
> 
>     >> On Thu, Feb 22, 2018 at 12:24 PM, Fox, John <jfox at mcmaster.ca> wrote:
>     >> > Hi Ben,
>     >> >
>     >> >> -----Original Message-----
>     >> >> From: Ben Bolker [mailto:bbolker at gmail.com]
>     >> >> Sent: Thursday, February 22, 2018 11:53 AM
>     >> >> To: Fox, John <jfox at mcmaster.ca>
>     >> >> Cc: Toni Hernandez-Matias <ahmatias at gmail.com>; r-sig-mixed-
> models at r-
>     >> >> project.org
>     >> >> Subject: Re: [R-sig-ME] variance inflation factor
>     >> >>
>     >> >>   I don't know if there's a good reason that vcov() is a "dpoMatrix"
>     >> >> (from the Matrix package) rather than a plain old base-R matrix, but
>     >> >> as.matrix() converts it harmlessly (and shouldn't have any ill
>     >> >> effects on something that's already a matrix ...)
>     >> >
>     >> > Yes, I know that, but it prevents the default method for car::vif() from
> working
>     >> because cov2cor() checks for a matrix:
>     >> >
>     >> >> vif(mod)
>     >> > Error in cov2cor(v) : 'V' is not a square numeric matrix In addition:
>     >> > Warning message:
>     >> > In vif.default(mod) :
>     >> > Error in cov2cor(v) : 'V' is not a square numeric matrix
>     >> >
>     >> > It should be easy to get around this -- I'll probably just create a
>     >> > local, unexported version of cov2cor() in the car package, something
>     >> > like
>     >> >
>     >> > cov2cor <- function(V) stats::cov2cor(as.matrix(V))
>     >> >
>     >> > Best,
>     >> >  John
>     >> >
>     >> >>
>     >> >> On Thu, Feb 22, 2018 at 11:01 AM, Fox, John <jfox at mcmaster.ca>
> wrote:
>     >> >> > Dear Toni,
>     >> >> >
>     >> >> >> -----Original Message-----
>     >> >> >> From: Toni Hernandez-Matias [mailto:ahmatias at gmail.com]
>     >> >> >> Sent: Thursday, February 22, 2018 10:01 AM
>     >> >> >> To: Fox, John <jfox at mcmaster.ca>
>     >> >> >> Cc: r-sig-mixed-models at r-project.org
>     >> >> >> Subject: Re: [R-sig-ME] variance inflation factor
>     >> >> >>
>     >> >> >> Dear John,
>     >> >> >>
>     >> >> >> Thank you very much for your message.
>     >> >> >>
>     >> >> >> Did you know a bibliographic reference for this method,
>     >> >> >> specifically in the case of generalized linear mixed models?
>     >> >> >
>     >> >> > Sorry, I don't, but don't see why the general idea wouldn't apply
>     >> >> > here (as Ben
>     >> >> mentioned in his response). By the way, the more general vif()
>     >> >> function in the car package works for lme() in nlme but not for
>     >> >> lmer() or glmer() in lme4 (because the result returned by vcov() for
>     >> >> a "merMod" object isn't of class "matrix"). We should probably make it
>     >> work.
>     >> >> >
>     >> >> > Best,
>     >> >> >  John
>     >> >> >
>     >> >> >>
>     >> >> >> Thank you again,
>     >> >> >>
>     >> >> >> Antonio
>     >> >> >>
>     >> >> >> On Thu, Feb 22, 2018 at 3:51 PM, Fox, John <jfox at mcmaster.ca
>     >> >> >> <mailto:jfox at mcmaster.ca> > wrote:
>     >> >> >>
>     >> >> >>
>     >> >> >>       Dear Toni,
>     >> >> >>
>     >> >> >>       Yes, that looks reasonable, although I'm not sure why it's
>     >> >> >> necessary to test for more than one fixed-effect intercept at the
>     >> >> >> beginning of the fixed-effect coefficient vector and how an
>     >> >> >> intercept could be named "Intercept" rather than "(Intercept)".
>     >> >> >> Assuming that there's a reason that escapes me, here's a
>     >> >> >> simplified
>     >> >> >> version:
>     >> >> >>
>     >> >> >>       vif.lme <- function (fit) {
>     >> >> >>         ## adapted from rms::vif
>     >> >> >>         v <- vcov(fit)
>     >> >> >>         nam <- names(fixef(fit))
>     >> >> >>         ## exclude intercepts
>     >> >> >>         ns <- sum(nam == "Intercept" | nam == "(Intercept)")
>     >> >> >>         if (ns > 0) v <- v[-(1:ns), -(1:ns), drop = FALSE]
>     >> >> >>         diag(solve(cov2cor(v)))
>     >> >> >>       }
>     >> >> >>
>     >> >> >>       I hope this helps,
>     >> >> >>        John
>     >> >> >>
>     >> >> >>
>     >> >> >>       -----------------------------
>     >> >> >>       John Fox, Professor Emeritus
>     >> >> >>       McMaster University
>     >> >> >>       Hamilton, Ontario, Canada
>     >> >> >>       Web: socialsciences.mcmaster.ca/jfox/
>     >> >> >> <http://socialsciences.mcmaster.ca/jfox/>
>     >> >> >>
>     >> >> >>
>     >> >> >>
>     >> >> >>
>     >> >> >>       > -----Original Message-----
>     >> >> >>       > From: R-sig-mixed-models
>     >> >> >> [mailto:r-sig-mixed-models-bounces at r-
>     >> >> >> <mailto:r-sig-mixed-models-bounces at r->
>     >> >> >>       > project.org <http://project.org> ] On Behalf Of Toni
>     >> >> >> Hernandez- Matias
>     >> >> >>       > Sent: Thursday, February 22, 2018 7:28 AM
>     >> >> >>       > To: r-sig-mixed-models at r-project.org
>     >> >> >> <mailto:r-sig-mixed-models at r- project.org>
>     >> >> >>       > Subject: [R-sig-ME] variance inflation factor
>     >> >> >>       >
>     >> >> >>       > Dear all,
>     >> >> >>       >
>     >> >> >>       > Could some help me to calculate Variance Inflation Factors
>     >> >> >> of models fitted
>     >> >> >>       > with glmer and lmer ?
>     >> >> >>       >
>     >> >> >>       > I found the method I copy below but I am not sure it is correct:
>     >> >> >>       >
>     >> >> >>       > vif.lme <- function (fit) {
>     >> >> >>       >      ## adapted from rms::vif
>     >> >> >>       >      v <- vcov(fit)
>     >> >> >>       >      nam <- names(fixef(fit))
>     >> >> >>       >      ## exclude intercepts
>     >> >> >>       >      ns <- sum(1 * (nam == "Intercept" | nam == "(Intercept)"))
>     >> >> >>       >      if (ns > 0) {
>     >> >> >>       >          v <- v[-(1:ns), -(1:ns), drop = FALSE]
>     >> >> >>       >          nam <- nam[-(1:ns)] }
>     >> >> >>       >      d <- diag(v)^0.5
>     >> >> >>       >      v <- diag(solve(v/(d %o% d)))
>     >> >> >>       >      names(v) <- nam
>     >> >> >>       >      v }
>     >> >> >>       >
>     >> >> >>       >
>     >> >> >>       >
>     >> >> >>       > ##la estimamos para el modelo 1
>     >> >> >>       >
>     >> >> >>       > vif.lme(mod1)
>     >> >> >>       >
>     >> >> >>       >
>     >> >> >>       > Thank you very much in advance,
>     >> >> >>       >
>     >> >> >>       > Antonio
>     >> >> >>       >
>     >> >> >>       >
>     >> >> >>       > --
>     >> >> >>       >
>     >> >> >>
>     >> *********************************************************
>     >> >> >>       >
>     >> >> >>       > Antonio Hernandez Matias
>     >> >> >>       >
>     >> >> >>       > Equip de Biologia de la Conservaci?
>     >> >> >>       > Departament de Biologia Evolutiva, Ecolog?a i Ci?ncies
>     >> >> >> Ambientals Facultat de
>     >> >> >>       > Biologia  i Institut de Recerca de la Biodiversitat (IRBio)
> Universitat de
>     >> >> >>       > Barcelona (UB) Av. Diagonal, 643
>     >> >> >>       > Barcelona      08028
>     >> >> >>       > Spain
>     >> >> >>
>     >> >> >>       > Telephone: +34-934035857 <tel:%2B34-934035857>
>     >> >> >> <+34%20934%2003%2058%2057>
>     >> >> >>       > FAX: +34-934035740 <tel:%2B34-934035740>
>     >> >> >> <+34%20934%2003%2057%2040>
>     >> >> >>       > e-mail: ahernandezmatias at ub.edu
>     >> >> >> <mailto:ahernandezmatias at ub.edu>
> 
>     > _______________________________________________
>     > R-sig-mixed-models at r-project.org mailing list
>     > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From altessedac2 at gmail.com  Sun Feb 25 13:08:15 2018
From: altessedac2 at gmail.com (C. AMAL D. GLELE)
Date: Sun, 25 Feb 2018 13:08:15 +0100
Subject: [R-sig-ME] zero-inflated-count-data?
Message-ID: <CANrzCv3w4850Ofh3rULTEPKFAa0Ro6hrznss6Ax4tJypUN5VnQ@mail.gmail.com>

Hi, dear all.
>From which proportion of zero a count should be considered as zero-inflated
(in order to use a zero-inflated model for it's modelling)?
In advance, thanks for your replies.
Best,

<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
Garanti
sans virus. www.avast.com
<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
<#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Sun Feb 25 19:05:35 2018
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 25 Feb 2018 13:05:35 -0500
Subject: [R-sig-ME] zero-inflated-count-data?
In-Reply-To: <CANrzCv3w4850Ofh3rULTEPKFAa0Ro6hrznss6Ax4tJypUN5VnQ@mail.gmail.com>
References: <CANrzCv3w4850Ofh3rULTEPKFAa0Ro6hrznss6Ax4tJypUN5VnQ@mail.gmail.com>
Message-ID: <CABghstSMKH2VE3aPLi1xr+Z3Kyvj2txMP_ad9fvx=9YC76z9PA@mail.gmail.com>

There is no set proportion.  (For example, a Poisson distribution with
a mean of 0.01 is expected to be about 99% zeros, even without
zero-inflation.) There's a little bit of (bare-bones) discussion of
how to test for zero-inflation here:
https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#zero-inflation

On Sun, Feb 25, 2018 at 7:08 AM, C. AMAL D. GLELE <altessedac2 at gmail.com> wrote:
> Hi, dear all.
> From which proportion of zero a count should be considered as zero-inflated
> (in order to use a zero-inflated model for it's modelling)?
> In advance, thanks for your replies.
> Best,
>
> <https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
> Garanti
> sans virus. www.avast.com
> <https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
> <#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From altessedac2 at gmail.com  Sun Feb 25 22:45:40 2018
From: altessedac2 at gmail.com (C. AMAL D. GLELE)
Date: Sun, 25 Feb 2018 22:45:40 +0100
Subject: [R-sig-ME] zero-inflated-count-data?
In-Reply-To: <CABghstSMKH2VE3aPLi1xr+Z3Kyvj2txMP_ad9fvx=9YC76z9PA@mail.gmail.com>
References: <CANrzCv3w4850Ofh3rULTEPKFAa0Ro6hrznss6Ax4tJypUN5VnQ@mail.gmail.com>
 <CABghstSMKH2VE3aPLi1xr+Z3Kyvj2txMP_ad9fvx=9YC76z9PA@mail.gmail.com>
Message-ID: <CANrzCv3FY9CYYVcMxGbrKUV06QgxkyWFC9gNpTa8cAMEaGJWeA@mail.gmail.com>

Hi, Ben
Many thanks to you for your very helpful reply.
Best and regards,

2018-02-25 19:05 GMT+01:00 Ben Bolker <bbolker at gmail.com>:

> There is no set proportion.  (For example, a Poisson distribution with
> a mean of 0.01 is expected to be about 99% zeros, even without
> zero-inflation.) There's a little bit of (bare-bones) discussion of
> how to test for zero-inflation here:
> https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#zero-inflation
>
> On Sun, Feb 25, 2018 at 7:08 AM, C. AMAL D. GLELE <altessedac2 at gmail.com>
> wrote:
> > Hi, dear all.
> > From which proportion of zero a count should be considered as
> zero-inflated
> > (in order to use a zero-inflated model for it's modelling)?
> > In advance, thanks for your replies.
> > Best,
> >
> > <https://www.avast.com/sig-email?utm_medium=email&utm_
> source=link&utm_campaign=sig-email&utm_content=webmail>
> > Garanti
> > sans virus. www.avast.com
> > <https://www.avast.com/sig-email?utm_medium=email&utm_
> source=link&utm_campaign=sig-email&utm_content=webmail>
> > <#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From bachlaw01 at outlook.com  Sun Feb 25 23:55:51 2018
From: bachlaw01 at outlook.com (Jonathan Judge)
Date: Sun, 25 Feb 2018 22:55:51 +0000
Subject: [R-sig-ME] zero-inflated-count-data?
In-Reply-To: <CANrzCv3FY9CYYVcMxGbrKUV06QgxkyWFC9gNpTa8cAMEaGJWeA@mail.gmail.com>
References: <CANrzCv3w4850Ofh3rULTEPKFAa0Ro6hrznss6Ax4tJypUN5VnQ@mail.gmail.com>
 <CABghstSMKH2VE3aPLi1xr+Z3Kyvj2txMP_ad9fvx=9YC76z9PA@mail.gmail.com>,
 <CANrzCv3FY9CYYVcMxGbrKUV06QgxkyWFC9gNpTa8cAMEaGJWeA@mail.gmail.com>
Message-ID: <CY1PR16MB0796DDA32319B788611AC9A1AFC20@CY1PR16MB0796.namprd16.prod.outlook.com>

The pscl package offers the (somewhat controversial) Vuong test for this purpose and is a good ZI/hurdle resource in general. 

Jonathan 

> On Feb 25, 2018, at 3:45 PM, C. AMAL D. GLELE <altessedac2 at gmail.com> wrote:
> 
> Hi, Ben
> Many thanks to you for your very helpful reply.
> Best and regards,
> 
> 2018-02-25 19:05 GMT+01:00 Ben Bolker <bbolker at gmail.com>:
> 
>> There is no set proportion.  (For example, a Poisson distribution with
>> a mean of 0.01 is expected to be about 99% zeros, even without
>> zero-inflation.) There's a little bit of (bare-bones) discussion of
>> how to test for zero-inflation here:
>> https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#zero-inflation
>> 
>> On Sun, Feb 25, 2018 at 7:08 AM, C. AMAL D. GLELE <altessedac2 at gmail.com>
>> wrote:
>>> Hi, dear all.
>>> From which proportion of zero a count should be considered as
>> zero-inflated
>>> (in order to use a zero-inflated model for it's modelling)?
>>> In advance, thanks for your replies.
>>> Best,
>>> 
>>> <https://www.avast.com/sig-email?utm_medium=email&utm_
>> source=link&utm_campaign=sig-email&utm_content=webmail>
>>> Garanti
>>> sans virus. www.avast.com
>>> <https://www.avast.com/sig-email?utm_medium=email&utm_
>> source=link&utm_campaign=sig-email&utm_content=webmail>
>>> <#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>
>>> 
>>>        [[alternative HTML version deleted]]
>>> 
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
>    [[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From thierry.onkelinx at inbo.be  Mon Feb 26 09:16:55 2018
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Mon, 26 Feb 2018 09:16:55 +0100
Subject: [R-sig-ME] zero-inflated-count-data?
In-Reply-To: <CY1PR16MB0796DDA32319B788611AC9A1AFC20@CY1PR16MB0796.namprd16.prod.outlook.com>
References: <CANrzCv3w4850Ofh3rULTEPKFAa0Ro6hrznss6Ax4tJypUN5VnQ@mail.gmail.com>
 <CABghstSMKH2VE3aPLi1xr+Z3Kyvj2txMP_ad9fvx=9YC76z9PA@mail.gmail.com>
 <CANrzCv3FY9CYYVcMxGbrKUV06QgxkyWFC9gNpTa8cAMEaGJWeA@mail.gmail.com>
 <CY1PR16MB0796DDA32319B788611AC9A1AFC20@CY1PR16MB0796.namprd16.prod.outlook.com>
Message-ID: <CAJuCY5yAvWYG2YA8FgVV1urK7Q8E55eNuR=gYcKokxDBN9Jiog@mail.gmail.com>

Another option is the fit the model using a distribution without
zero-inflation. Then simulate data from that model and count the number of
zero's. Repeat this several times so that you get a distribution of the
number of zero's. In case of zero-inflation the number of zero's in the
data is much higher that those from the simulated data.

Best regards,


ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>

2018-02-25 23:55 GMT+01:00 Jonathan Judge <bachlaw01 at outlook.com>:

> The pscl package offers the (somewhat controversial) Vuong test for this
> purpose and is a good ZI/hurdle resource in general.
>
> Jonathan
>
> > On Feb 25, 2018, at 3:45 PM, C. AMAL D. GLELE <altessedac2 at gmail.com>
> wrote:
> >
> > Hi, Ben
> > Many thanks to you for your very helpful reply.
> > Best and regards,
> >
> > 2018-02-25 19:05 GMT+01:00 Ben Bolker <bbolker at gmail.com>:
> >
> >> There is no set proportion.  (For example, a Poisson distribution with
> >> a mean of 0.01 is expected to be about 99% zeros, even without
> >> zero-inflation.) There's a little bit of (bare-bones) discussion of
> >> how to test for zero-inflation here:
> >> https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#zero-inflation
> >>
> >> On Sun, Feb 25, 2018 at 7:08 AM, C. AMAL D. GLELE <
> altessedac2 at gmail.com>
> >> wrote:
> >>> Hi, dear all.
> >>> From which proportion of zero a count should be considered as
> >> zero-inflated
> >>> (in order to use a zero-inflated model for it's modelling)?
> >>> In advance, thanks for your replies.
> >>> Best,
> >>>
> >>> <https://www.avast.com/sig-email?utm_medium=email&utm_
> >> source=link&utm_campaign=sig-email&utm_content=webmail>
> >>> Garanti
> >>> sans virus. www.avast.com
> >>> <https://www.avast.com/sig-email?utm_medium=email&utm_
> >> source=link&utm_campaign=sig-email&utm_content=webmail>
> >>> <#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>
> >>>
> >>>        [[alternative HTML version deleted]]
> >>>
> >>> _______________________________________________
> >>> R-sig-mixed-models at r-project.org mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> >    [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From highstat at highstat.com  Mon Feb 26 11:25:50 2018
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Mon, 26 Feb 2018 10:25:50 +0000
Subject: [R-sig-ME] zero-inflated-count-data?
In-Reply-To: <mailman.16151.1234.1519633022.1673.r-sig-mixed-models@r-project.org>
References: <mailman.16151.1234.1519633022.1673.r-sig-mixed-models@r-project.org>
Message-ID: <3602e304-c27f-0b79-35fd-65268807a931@highstat.com>



------------------------------

Message: 5
Date: Mon, 26 Feb 2018 09:16:55 +0100
From: Thierry Onkelinx <thierry.onkelinx at inbo.be>
To: Jonathan Judge <bachlaw01 at outlook.com>
Cc: "C. AMAL D. GLELE" <altessedac2 at gmail.com>,  R SIG Mixed Models
	<r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] zero-inflated-count-data?
Message-ID:
	<CAJuCY5yAvWYG2YA8FgVV1urK7Q8E55eNuR=gYcKokxDBN9Jiog at mail.gmail.com>
Content-Type: text/plain; charset="utf-8"

Another option is the fit the model using a distribution without
zero-inflation. Then simulate data from that model and count the number of
zero's. Repeat this several times so that you get a distribution of the
number of zero's. In case of zero-inflation the number of zero's in the
data is much higher that those from the simulated data.





I think that Thierry's suggestion is indeed the best option. It not only allows you to check whether
the model can cope with the observed number of zeros, but it also shows you to check whether the model can cope with other
aspects of the observed data. For example, you can calculate the frequency table for each of the 1000 simulated data sets,
and calculate somehow and average frequency table. And the compare this with the frequency table of the observed data.

Kind regards,
Alain










Best regards,


ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


------------------------------

End of R-sig-mixed-models Digest, Vol 134, Issue 36
***************************************************

-- 

Dr. Alain F. Zuur
Highland Statistics Ltd.
9 St Clair Wynd
AB41 6DZ Newburgh, UK
Email: highstat at highstat.com
URL:   www.highstat.com

And:
NIOZ Royal Netherlands Institute for Sea Research,
Department of Coastal Systems, and Utrecht University,
P.O. Box 59, 1790 AB Den Burg,
Texel, The Netherlands



Author of:
1. Beginner's Guide to Spatial, Temporal and Spatial-Temporal Ecological Data Analysis with R-INLA. (2017).
2. Beginner's Guide to Zero-Inflated Models with R (2016).
3. Beginner's Guide to Data Exploration and Visualisation with R (2015).
4. Beginner's Guide to GAMM with R (2014).
5. Beginner's Guide to GLM and GLMM with R (2013).
6. Beginner's Guide to GAM with R (2012).
7. Zero Inflated Models and GLMM with R (2012).
8. A Beginner's Guide to R (2009).
9. Mixed effects models and extensions in ecology with R (2009).
10. Analysing Ecological Data (2007).


From altessedac2 at gmail.com  Mon Feb 26 14:57:00 2018
From: altessedac2 at gmail.com (C. AMAL D. GLELE)
Date: Mon, 26 Feb 2018 14:57:00 +0100
Subject: [R-sig-ME] zero-inflated-count-data?
In-Reply-To: <CY1PR16MB0796DDA32319B788611AC9A1AFC20@CY1PR16MB0796.namprd16.prod.outlook.com>
References: <CANrzCv3w4850Ofh3rULTEPKFAa0Ro6hrznss6Ax4tJypUN5VnQ@mail.gmail.com>
 <CABghstSMKH2VE3aPLi1xr+Z3Kyvj2txMP_ad9fvx=9YC76z9PA@mail.gmail.com>
 <CANrzCv3FY9CYYVcMxGbrKUV06QgxkyWFC9gNpTa8cAMEaGJWeA@mail.gmail.com>
 <CY1PR16MB0796DDA32319B788611AC9A1AFC20@CY1PR16MB0796.namprd16.prod.outlook.com>
Message-ID: <CANrzCv0SZxAXjoftdkN7v5M4g6wrd3GM7qx23dFB=fi7JHisCg@mail.gmail.com>

Hi, dear all.
Many thanks to you all for your very helpful answers.
Jonathan,
I've started fitting a model using zeroinfl function from pscl package, but
I'm having the following

difficulty according to one of my regressors, let be H_var (categorical
with 8 levels):
as regressors, I have 7 categorical variables (with a total of 26 levels)
and two numerical

variables;
1) when I fit the model like follows,
model1<-zeroinfl(countdata~var1+H_var+var3+var4+var5+var6+var7+var8num

+var9num,dist="negbin",data=mydata)
, I receive the error message below:
"Error in solve.default(as.matrix(fit$hessian)) :
  system is computationally singular: reciprocal condition number =
7.05621e-21
In addition: Warning message:
glm.fit: fitted probabilities numerically 0 or 1 occurred
"
2)
but, if I remove H_var from the count component and fits model2 loke
follows,
model2<-zeroinfl(countdata~var1+var3+var4+var5+var6+var7+var8num+
var9num|H_var,dist="negbin",data=mydata)
 the model fits well and I do not receive error message anymore.
3)
If use H_var in both component of the model, like follows,
model3<-zeroinfl(countdata~var1+var3+var4+var5+var6+var7+var8num+
var9num+H_var|H_var,dist="negbin",data=mydata)
I receive the following error message:
"Error in solve.default(as.matrix(fit$hessian)) :
  system is computationally singular: reciprocal condition number =
4.2618e-20
"
Question:
 Does someone have any idea about probables causes of the problems posed
at points 1) and 3) ?
   Thierry,
can you, please, provide me details (some ways to do it) and/or lead about
simulating data from a fitted model?

In advance, thanks for your answers.
Best,

2018-02-25 23:55 GMT+01:00 Jonathan Judge <bachlaw01 at outlook.com>:

> The pscl package offers the (somewhat controversial) Vuong test for this
> purpose and is a good ZI/hurdle resource in general.
>
> Jonathan
>
> > On Feb 25, 2018, at 3:45 PM, C. AMAL D. GLELE <altessedac2 at gmail.com>
> wrote:
> >
> > Hi, Ben
> > Many thanks to you for your very helpful reply.
> > Best and regards,
> >
> > 2018-02-25 19:05 GMT+01:00 Ben Bolker <bbolker at gmail.com>:
> >
> >> There is no set proportion.  (For example, a Poisson distribution with
> >> a mean of 0.01 is expected to be about 99% zeros, even without
> >> zero-inflation.) There's a little bit of (bare-bones) discussion of
> >> how to test for zero-inflation here:
> >> https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#zero-inflation
> >>
> >> On Sun, Feb 25, 2018 at 7:08 AM, C. AMAL D. GLELE <
> altessedac2 at gmail.com>
> >> wrote:
> >>> Hi, dear all.
> >>> From which proportion of zero a count should be considered as
> >> zero-inflated
> >>> (in order to use a zero-inflated model for it's modelling)?
> >>> In advance, thanks for your replies.
> >>> Best,
> >>>
> >>> <https://www.avast.com/sig-email?utm_medium=email&utm_
> >> source=link&utm_campaign=sig-email&utm_content=webmail>
> >>> Garanti
> >>> sans virus. www.avast.com
> >>> <https://www.avast.com/sig-email?utm_medium=email&utm_
> >> source=link&utm_campaign=sig-email&utm_content=webmail>
> >>> <#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>
> >>>
> >>>        [[alternative HTML version deleted]]
> >>>
> >>> _______________________________________________
> >>> R-sig-mixed-models at r-project.org mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> >    [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From davis.ozols at unifr.ch  Mon Feb 26 15:07:03 2018
From: davis.ozols at unifr.ch (OZOLS Davis)
Date: Mon, 26 Feb 2018 14:07:03 +0000
Subject: [R-sig-ME] Error message in running CLMM models from Ordinal
 package: "optimizer nlminb failed to converge"
Message-ID: <D6B9C505.C71F%davis.ozols@unifr.ch>

Dear list,

I have a question with regards to model convergence in CLMM function that is implemented in the Ordinal package. More specifically what might cause the error: "optimizer nlminb failed to converge message" in the CLMM function that I am getting.

I am new to mixed model analysis so I will try to explain all the steps I have taken in case there might be something wrong in my approach to the analysis.

I have data set of 2200 observations with 6 variables: 115 participants, 24 items and a design that has as a response variable an ordered scale from 1 to 10.

> head(data.ord)
id item value.statement quant preexisting.belief engagement
1 R_ysTGuC676siU2Pf   I1               3 Baseline                 low       high
2 R_ysTGuC676siU2Pf   I2               2 Baseline                 low       high
3 R_ysTGuC676siU2Pf   I26               2     Most               low       high
4 R_ysTGuC676siU2Pf   I40               3     Every               low       high
5 R_ysTGuC676siU2Pf   I4               7 Baseline           undecided     high
6 R_ysTGuC676siU2Pf   I10               4 Baseline           undecided     low

I investigate the interaction of three factors on the response variable:
quant(4 levels)* preexisting.belief(3 levels)* engagement(2 levels)


this is the summary of my data:

> str(data.ord)
'data.frame': 2200 obs. of  6 variables:
 $ id                 : Factor w/ 115 levels
 $ item               : Factor w/ 24 levels
 $ value.statement   : Ord.factor w/ 10 levels
 $ quant              : Factor w/ 4 levels
 $ preexisting.belief : Factor w/ 3 levels
 $ engagement         : Factor w/ 2 levels


I plan to do my analysis by fitting four clmm models with random intercept and random slope structures for both participants and items. I choose the exact random effect structure based on theoretical assumptions in my hypothesis as well as backward model selection criterion discussed by Matuschek, Kliegel, Vasishth, Baayen & Bates (2017) and Barr, Levy, Scheepers & Tily (2013). Due to the complexity of my design it is not possible to fit the full three way interaction as a random slope so I choose (1 + preexisting.belief*engagement |id) for participants and (1 + engagement |item) for items - the choice is motivated by theoretical assumptions as well as comparison of various random effect models (with full interaction in fixed effects) using the anova() function. I then proceed to fit the four clmm models to test my fixed effects, starting with the null model and then adding all the interaction terms in a step wise fashion.

While the more complex models like model 2 and 3 are able to converge:


> cm.2 <- clmm(value.statement~preexisting.belief*engagement +
+                       (1 + preexisting.belief*engagement |id) + (1 + engagement |item),
+                 data = ucl.ordered, Hess = TRUE)

running the summary() function gives me:
max.grad = 9.78e-03 and cond.H = 2.3e+04


> cm.3 <- clmm(value.statement~quant*preexisting.belief*engagement +
+                       (1 + preexisting.belief*engagement |id) + (1 + engagement |item),
+                 data = ucl.ordered, Hess = TRUE)

running the summary() function gives me:
max.grad = 1.28e-01 and cond.H = 1.7e+04


I find that the simpler model and even the null model show failures to converge:


> cm.null <- clmm(value.statement~1 +
+                        (1 + preexisting.belief*engagement |id) + (1 + engagement |item),
+                  data = ucl.ordered, Hess = TRUE)
Error: optimizer nlminb failed to converge

> cm.1 <- clmm(value.statement~quant +
+                        (1 + preexisting.belief*engagement |id) + (1 + engagement |item),
+                  data = ucl.ordered, Hess = TRUE)
Error: optimizer nlminb failed to converge


I have tried looking for potential solutions to this on the r-sig-mm list as well as other online resources and have tried some suggestions. Using the "ucminf" optimizer does not work and produces error message: "cannot use ucminf optimizer for this model, using nlminb instead". I have tried changing the maxIter and maxLineIter parameters under clmm.control to 200 and that has also resulted in no improvement. I am puzzled by the fact that the error persists only for the simpler models. My first guess was that the complexity of my design is too much for clmm to handle with only 2200 observations, however, if that were the case wouldn't models 3 and 4 also fail to converge?

I would greatly appreciate any help on these errors. I am also happy to share the full data (in private correspondence) if that might be of help here.

Thank you in advance,
Davis Ozols
PhD Student,
University of Fribourg
CH-1700 Fribourg, Switzerland

Tel: +41 26 300 79 09
Fax: +41 26 300 97 87



	[[alternative HTML version deleted]]


From sim.potier at gmail.com  Mon Feb 26 09:28:19 2018
From: sim.potier at gmail.com (Simon POTIER)
Date: Mon, 26 Feb 2018 09:28:19 +0100
Subject: [R-sig-ME] Mixed model on few individuals
Message-ID: <CANiGZfVq7zRwFnV1m2ggdLBQ1961mOHB4s4LC2LxSFoOdHPZJA@mail.gmail.com>

Dear all,

First, I will try to be the most comprehensible, if not, do not hesitate to
ask for more information.

I am working on a project with collaborators, and I am trying to analyse
the data. For one question, however, I do not feel confident with my
method, but I do not know how I can analyse the data in a different way.

We are working on visual fixation of a prey while hunting, with a new
method of high accuracy. This method is very interesting but implies that
we cannot use many individuals (because of different things that are not of
interest here I think).

My major problem here is that I have "only" 3 individuals and 51 trials
(almost equilibrate per individual).
I also have 3 different conditions (i.e. 3 types of prey). All these
conditions have been repeated for the 3 individuals.
In total, the dataset is relatively large as I have more than 6000 points
(large for behavioural study), but, as I wrote, with only 3 individuals.

Regarding this type of dataset, I am wondering whether I can use mixed
model to compare the visual fixation according to the different conditions.
So here are my two questions :

1) Can I use mixed models with only 3 individuals? If not, do you know if I
can use another model? Or should I compare each individual independently?

2) My data are spatio-temporal (visual fixation in times: One Azimuth and
one elevation every X sec). How can I implement this autocorrelation in my
model?

I am sincerely grateful if someone can be of any help. Sorry If similar
question has been posted before, I did not find it.

Best regards,

Simon Potier

	[[alternative HTML version deleted]]


From d.e.kornbrot at herts.ac.uk  Mon Feb 26 18:11:28 2018
From: d.e.kornbrot at herts.ac.uk (Kornbrot, Diana)
Date: Mon, 26 Feb 2018 17:11:28 +0000
Subject: [R-sig-ME] means , CIs from lmer, glmer
Message-ID: <62C83545-F497-4BAF-9599-8764F48E13C6@herts.ac.uk>

I am keen to promote the use of generalised mixed models for the analysis of proportions to psychologists
Have straight fowl code in SPSS [costly] and would like to supply equivalent R Code without ?tears?
Design is a follows raw frequencies are: FreqPos for ?success? and FreqNeg for ?failure?
Predictors are Rab with 4 levels, repeated over participants and Between with 2 separate groups of participants
Model is binomial with logit link

Require following output to correspond to SPSS output from code below
Descriptive: Means, se and 95% CIs  by Rab, by Between and by Rab*Between
Inferential: fo  Rab, Between and  Rab*Between: F value, MSE, numerator df, denominator df [this enables p-values]

Have tried

logit1 <- glmer(cbind(FreqPos,FreqNeg) ~ Rab + Between + Rab*Between + (1| Participant), family=binomial(link="logit"))
gives F and MSE no denominator df or MSE. Different results to SPSS
nb F=MSE - that can?t be right F is supposed to be ratio of chi-squares

summary (logit1)
gives coefficients  and SEs. Different results to SPSS
also tried predicted and fitted but still no means

have spent days searching internet for examples - but none of them seem to show how to get the output I need

All help greatly appreciated

____
Spss syntax

*Generalized Linear Mixed Models.
GENLINMIXED
  /DATA_STRUCTURE SUBJECTS=Participant REPEATED_MEASURES=Rab COVARIANCE_TYPE=UNSTRUCTURED
  /FIELDS TARGET=FreqPos TRIALS=FIELD(Nmax)  OFFSET=NONE
  /TARGET_OPTIONS DISTRIBUTION=BINOMIAL LINK=LOGIT
  /FIXED  EFFECTS=Rab Between Rab*Between USE_INTERCEPT=TRUE
  /BUILD_OPTIONS TARGET_CATEGORY_ORDER=DESCENDING INPUTS_CATEGORY_ORDER=DESCENDING MAX_ITERATIONS=100 CONFIDENCE_LEVEL=95 DF_METHOD=SATTERTHWAITE COVB=MODEL PCONVERGE=0.000001(ABSOLUTE) SCORING=0 SINGULAR=0.000000000001
  /EMMEANS TABLES=Rab COMPARE=Rab CONTRAST=DEVIATION
   /EMMEANS TABLES=Between CONTRAST=NONE
   /EMMEANS TABLES=Rab*Between CONTRAST=NONE
  /EMMEANS_OPTIONS SCALE=ORIGINAL PADJUST=LSD.

best
Diana


_____________________________________
Professor Diana Kornbrot
Mobile
+44 (0) 7403 18 16 12
Work
University of Hertfordshire
College Lane, Hatfield, Hertfordshire AL10 9AB, UK
+44 (0) 170 728 4626
d.e.kornbrot at herts.ac.uk<mailto:d.e.kornbrot at herts.ac.uk>
http://dianakornbrot.wordpress.com/
http://go.herts.ac.uk/Diana_Kornbrot
skype:  kornbrotme
Home
19 Elmhurst Avenue
London N2 0LT, UK
+44 (0) 208 444 2081
 ------------------------------------------------------------




	[[alternative HTML version deleted]]


From highstat at highstat.com  Mon Feb 26 18:26:02 2018
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Mon, 26 Feb 2018 17:26:02 +0000
Subject: [R-sig-ME] zero-inflated-count-data?
In-Reply-To: <mailman.16156.1280.1519665107.1673.r-sig-mixed-models@r-project.org>
References: <mailman.16156.1280.1519665107.1673.r-sig-mixed-models@r-project.org>
Message-ID: <d1db8134-8ae0-ff56-4622-02a909a2ff1b@highstat.com>


----------------------------------------------------------------------

Message: 1
Date: Mon, 26 Feb 2018 14:57:00 +0100
From: "C. AMAL D. GLELE" <altessedac2 at gmail.com>
To: Jonathan Judge <bachlaw01 at outlook.com>
Cc: Ben Bolker <bbolker at gmail.com>,  R SIG Mixed Models
	<r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] zero-inflated-count-data?
Message-ID:
	<CANrzCv0SZxAXjoftdkN7v5M4g6wrd3GM7qx23dFB=fi7JHisCg at mail.gmail.com>
Content-Type: text/plain; charset="utf-8"

Hi, dear all.
Many thanks to you all for your very helpful answers.
Jonathan,
I've started fitting a model using zeroinfl function from pscl package, but
I'm having the following

difficulty according to one of my regressors, let be H_var (categorical
with 8 levels):
as regressors, I have 7 categorical variables (with a total of 26 levels)
and two numerical

variables;
1) when I fit the model like follows,
model1<-zeroinfl(countdata~var1+H_var+var3+var4+var5+var6+var7+var8num

+var9num,dist="negbin",data=mydata)
, I receive the error message below:
"Error in solve.default(as.matrix(fit$hessian)) :
   system is computationally singular: reciprocal condition number =
7.05621e-21
In addition: Warning message:
glm.fit: fitted probabilities numerically 0 or 1 occurred
"
2)
but, if I remove H_var from the count component and fits model2 loke
follows,
model2<-zeroinfl(countdata~var1+var3+var4+var5+var6+var7+var8num+
var9num|H_var,dist="negbin",data=mydata)
  the model fits well and I do not receive error message anymore.
3)
If use H_var in both component of the model, like follows,
model3<-zeroinfl(countdata~var1+var3+var4+var5+var6+var7+var8num+
var9num+H_var|H_var,dist="negbin",data=mydata)
I receive the following error message:
"Error in solve.default(as.matrix(fit$hessian)) :
   system is computationally singular: reciprocal condition number =
4.2618e-20
"
Question:
  Does someone have any idea about probables causes of the problems posed
at points 1) and 3) ?






Without seeing the data......simplify your model? Collinearity? Start simple and build up the complexity of the model.
Maybe start with a Poisson GLM and figure out whether you really need a ZIP/ZINB? Why are you actually do a ZINB?






can you, please, provide me details (some ways to do it) and/or lead about
simulating data from a fitted model?





See step 10 in:

A protocol for conducting and presenting results of regression-type analyses (2016).
Zuur & Ieno.

http://onlinelibrary.wiley.com/doi/10.1111/2041-210X.12577/abstract

and see Figure 8 from that paper for an example. R code is somewhere online as well.


Alain







 ?In advance, thanks for your answers.
Best,

2018-02-25 23:55 GMT+01:00 Jonathan Judge <bachlaw01 at outlook.com>:
-- 

Dr. Alain F. Zuur
Highland Statistics Ltd.
9 St Clair Wynd
AB41 6DZ Newburgh, UK
Email: highstat at highstat.com
URL:   www.highstat.com

And:
NIOZ Royal Netherlands Institute for Sea Research,
Department of Coastal Systems, and Utrecht University,
P.O. Box 59, 1790 AB Den Burg,
Texel, The Netherlands



Author of:
1. Beginner's Guide to Spatial, Temporal and Spatial-Temporal Ecological Data Analysis with R-INLA. (2017).
2. Beginner's Guide to Zero-Inflated Models with R (2016).
3. Beginner's Guide to Data Exploration and Visualisation with R (2015).
4. Beginner's Guide to GAMM with R (2014).
5. Beginner's Guide to GLM and GLMM with R (2013).
6. Beginner's Guide to GAM with R (2012).
7. Zero Inflated Models and GLMM with R (2012).
8. A Beginner's Guide to R (2009).
9. Mixed effects models and extensions in ecology with R (2009).
10. Analysing Ecological Data (2007).


From bbolker at gmail.com  Tue Feb 27 02:02:57 2018
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 26 Feb 2018 20:02:57 -0500
Subject: [R-sig-ME] means , CIs from lmer, glmer
In-Reply-To: <62C83545-F497-4BAF-9599-8764F48E13C6@herts.ac.uk>
References: <62C83545-F497-4BAF-9599-8764F48E13C6@herts.ac.uk>
Message-ID: <CABghstTnvHcvQab_dH9j_BcfxvnbEREuHOkZaen9m_TmRLSovw@mail.gmail.com>

  Hi Diana,

A reproducible example is always helpful/increases your chances of
getting a useful answer ...
It might help if you included the SPSS output (or posted it somewhere
-- note that this list doesn't take HTML-formatted messages nor most
attachments), as many of us don't have access to it.

Look into the (very well-documented) emmeans package:
https://CRAN.R-project.org/package=emmeans
and the lmerTest package (for Satterthwaite df approximations)

On Mon, Feb 26, 2018 at 12:11 PM, Kornbrot, Diana
<d.e.kornbrot at herts.ac.uk> wrote:
> I am keen to promote the use of generalised mixed models for the analysis of proportions to psychologists
> Have straight fowl code in SPSS [costly] and would like to supply equivalent R Code without ?tears?
> Design is a follows raw frequencies are: FreqPos for ?success? and FreqNeg for ?failure?
> Predictors are Rab with 4 levels, repeated over participants and Between with 2 separate groups of participants
> Model is binomial with logit link
>
> Require following output to correspond to SPSS output from code below
> Descriptive: Means, se and 95% CIs  by Rab, by Between and by Rab*Between
> Inferential: fo  Rab, Between and  Rab*Between: F value, MSE, numerator df, denominator df [this enables p-values]
>
> Have tried
>
> logit1 <- glmer(cbind(FreqPos,FreqNeg) ~ Rab + Between + Rab*Between + (1| Participant), family=binomial(link="logit"))
> gives F and MSE no denominator df or MSE. Different results to SPSS
> nb F=MSE - that can?t be right F is supposed to be ratio of chi-squares
>
> summary (logit1)
> gives coefficients  and SEs. Different results to SPSS
> also tried predicted and fitted but still no means
>
> have spent days searching internet for examples - but none of them seem to show how to get the output I need
>
> All help greatly appreciated
>
> ____
> Spss syntax
>
> *Generalized Linear Mixed Models.
> GENLINMIXED
>   /DATA_STRUCTURE SUBJECTS=Participant REPEATED_MEASURES=Rab COVARIANCE_TYPE=UNSTRUCTURED
>   /FIELDS TARGET=FreqPos TRIALS=FIELD(Nmax)  OFFSET=NONE
>   /TARGET_OPTIONS DISTRIBUTION=BINOMIAL LINK=LOGIT
>   /FIXED  EFFECTS=Rab Between Rab*Between USE_INTERCEPT=TRUE
>   /BUILD_OPTIONS TARGET_CATEGORY_ORDER=DESCENDING INPUTS_CATEGORY_ORDER=DESCENDING MAX_ITERATIONS=100 CONFIDENCE_LEVEL=95 DF_METHOD=SATTERTHWAITE COVB=MODEL PCONVERGE=0.000001(ABSOLUTE) SCORING=0 SINGULAR=0.000000000001
>   /EMMEANS TABLES=Rab COMPARE=Rab CONTRAST=DEVIATION
>    /EMMEANS TABLES=Between CONTRAST=NONE
>    /EMMEANS TABLES=Rab*Between CONTRAST=NONE
>   /EMMEANS_OPTIONS SCALE=ORIGINAL PADJUST=LSD.
>
> best
> Diana
>
>
> _____________________________________
> Professor Diana Kornbrot
> Mobile
> +44 (0) 7403 18 16 12
> Work
> University of Hertfordshire
> College Lane, Hatfield, Hertfordshire AL10 9AB, UK
> +44 (0) 170 728 4626
> d.e.kornbrot at herts.ac.uk<mailto:d.e.kornbrot at herts.ac.uk>
> http://dianakornbrot.wordpress.com/
> http://go.herts.ac.uk/Diana_Kornbrot
> skype:  kornbrotme
> Home
> 19 Elmhurst Avenue
> London N2 0LT, UK
> +44 (0) 208 444 2081
>  ------------------------------------------------------------
>
>
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbolker at gmail.com  Tue Feb 27 02:17:14 2018
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 26 Feb 2018 20:17:14 -0500
Subject: [R-sig-ME] zero-inflated-count-data?
In-Reply-To: <d1db8134-8ae0-ff56-4622-02a909a2ff1b@highstat.com>
References: <mailman.16156.1280.1519665107.1673.r-sig-mixed-models@r-project.org>
 <d1db8134-8ae0-ff56-4622-02a909a2ff1b@highstat.com>
Message-ID: <CABghstRR41zVjimCX=Q3mc+AckchFOTc_8kb8ASfVb6pUSokyQ@mail.gmail.com>

 For some model types (unfortunately not pscl::zeroinlf(), it looks
like) you can just
use the simulate() method ...

By the way, Amal (hope that's a reasonable way to address you) - folks
are really helpful here (as
you will have noticed), but the list is primarily for questions about
*mixed* (hierarchical/multilevel/whatever) models.
At present your questions are more generic questions about
zero-inflation and generalized linear modeling.
I do recommend the books by Alain and his co-authors as a good way to
get started on the fairly
complex stuff you're attempting here.

On Mon, Feb 26, 2018 at 12:26 PM, Highland Statistics Ltd
<highstat at highstat.com> wrote:
>
> ----------------------------------------------------------------------
>
> Message: 1
> Date: Mon, 26 Feb 2018 14:57:00 +0100
> From: "C. AMAL D. GLELE" <altessedac2 at gmail.com>
> To: Jonathan Judge <bachlaw01 at outlook.com>
> Cc: Ben Bolker <bbolker at gmail.com>,  R SIG Mixed Models
>         <r-sig-mixed-models at r-project.org>
> Subject: Re: [R-sig-ME] zero-inflated-count-data?
> Message-ID:
>         <CANrzCv0SZxAXjoftdkN7v5M4g6wrd3GM7qx23dFB=fi7JHisCg at mail.gmail.com>
> Content-Type: text/plain; charset="utf-8"
>
>
> Hi, dear all.
> Many thanks to you all for your very helpful answers.
> Jonathan,
> I've started fitting a model using zeroinfl function from pscl package, but
> I'm having the following
>
> difficulty according to one of my regressors, let be H_var (categorical
> with 8 levels):
> as regressors, I have 7 categorical variables (with a total of 26 levels)
> and two numerical
>
> variables;
> 1) when I fit the model like follows,
> model1<-zeroinfl(countdata~var1+H_var+var3+var4+var5+var6+var7+var8num
>
> +var9num,dist="negbin",data=mydata)
> , I receive the error message below:
> "Error in solve.default(as.matrix(fit$hessian)) :
>   system is computationally singular: reciprocal condition number =
> 7.05621e-21
> In addition: Warning message:
> glm.fit: fitted probabilities numerically 0 or 1 occurred
> "
> 2)
> but, if I remove H_var from the count component and fits model2 loke
> follows,
> model2<-zeroinfl(countdata~var1+var3+var4+var5+var6+var7+var8num+
> var9num|H_var,dist="negbin",data=mydata)
>  the model fits well and I do not receive error message anymore.
> 3)
> If use H_var in both component of the model, like follows,
> model3<-zeroinfl(countdata~var1+var3+var4+var5+var6+var7+var8num+
> var9num+H_var|H_var,dist="negbin",data=mydata)
> I receive the following error message:
> "Error in solve.default(as.matrix(fit$hessian)) :
>   system is computationally singular: reciprocal condition number =
> 4.2618e-20
> "
> Question:
>  Does someone have any idea about probables causes of the problems posed
> at points 1) and 3) ?
>
>
>
>
>
>
> Without seeing the data......simplify your model? Collinearity? Start simple
> and build up the complexity of the model.
> Maybe start with a Poisson GLM and figure out whether you really need a
> ZIP/ZINB? Why are you actually do a ZINB?
>
>
>
>
>
>
> can you, please, provide me details (some ways to do it) and/or lead about
> simulating data from a fitted model?
>
>
>
>
>
> See step 10 in:
>
> A protocol for conducting and presenting results of regression-type analyses
> (2016).
> Zuur & Ieno.
>
> http://onlinelibrary.wiley.com/doi/10.1111/2041-210X.12577/abstract
>
> and see Figure 8 from that paper for an example. R code is somewhere online
> as well.
>
>
> Alain
>
>
>
>
>
>
>
>  In advance, thanks for your answers.
> Best,
>
> 2018-02-25 23:55 GMT+01:00 Jonathan Judge <bachlaw01 at outlook.com>:
> --
>
> Dr. Alain F. Zuur
> Highland Statistics Ltd.
> 9 St Clair Wynd
> AB41 6DZ Newburgh, UK
> Email: highstat at highstat.com
> URL:   www.highstat.com
>
> And:
> NIOZ Royal Netherlands Institute for Sea Research,
> Department of Coastal Systems, and Utrecht University,
> P.O. Box 59, 1790 AB Den Burg,
> Texel, The Netherlands
>
>
>
> Author of:
> 1. Beginner's Guide to Spatial, Temporal and Spatial-Temporal Ecological
> Data Analysis with R-INLA. (2017).
> 2. Beginner's Guide to Zero-Inflated Models with R (2016).
> 3. Beginner's Guide to Data Exploration and Visualisation with R (2015).
> 4. Beginner's Guide to GAMM with R (2014).
> 5. Beginner's Guide to GLM and GLMM with R (2013).
> 6. Beginner's Guide to GAM with R (2012).
> 7. Zero Inflated Models and GLMM with R (2012).
> 8. A Beginner's Guide to R (2009).
> 9. Mixed effects models and extensions in ecology with R (2009).
> 10. Analysing Ecological Data (2007).
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From dennis.ruenger at gmail.com  Tue Feb 27 07:22:17 2018
From: dennis.ruenger at gmail.com (Dennis Ruenger)
Date: Mon, 26 Feb 2018 22:22:17 -0800
Subject: [R-sig-ME] Longitudinal logistic regression with continuous-time
 first-order autocorrelation structure
Message-ID: <CAFvg1=vdVbz28pw9B6GrOXNsnceXK3UgXksMDwJUOQ9PYoLK_g@mail.gmail.com>

Dear All.

I need to analyze an intensive longitudinal data set with a binary outcome
variable. In the ?Ecological Momentary Assessment? (EMA) study,
participants received five random prompts per day for six weeks, asking
them (among other things) whether they were craving a particular drug
(yes/no). At the most basic level, I want to know whether the likelihood of
craving the drug changed across time.

Given the variable time intervals of measurement and many missing data
points, a continuous-time first-order autocorrelation model seems
necessary.

I found tutorials on how to allow for continuous-time autocorrelation and
missing data in an LMM, using nlme::lme and corCAR1, but I am at a loss as
to what to do in a GLMM.

I would be thankful for any suggestions on how to analyze this kind of data
in R.

Dennis

	[[alternative HTML version deleted]]


From highstat at highstat.com  Tue Feb 27 08:04:59 2018
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Tue, 27 Feb 2018 07:04:59 +0000
Subject: [R-sig-ME] Longitudinal logistic regression with,
 continuous-time first-order autocorrelation structure
In-Reply-To: <mailman.16160.1302.1519712545.1673.r-sig-mixed-models@r-project.org>
References: <mailman.16160.1302.1519712545.1673.r-sig-mixed-models@r-project.org>
Message-ID: <965222c6-b9f1-2f06-9643-3ae2dbb2b4c6@highstat.com>



------------------------------

Message: 4
Date: Mon, 26 Feb 2018 22:22:17 -0800
From: Dennis Ruenger <dennis.ruenger at gmail.com>
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] Longitudinal logistic regression with
	continuous-time first-order autocorrelation structure
Message-ID:
	<CAFvg1=vdVbz28pw9B6GrOXNsnceXK3UgXksMDwJUOQ9PYoLK_g at mail.gmail.com>
Content-Type: text/plain; charset="utf-8"

Dear All.

I need to analyze an intensive longitudinal data set with a binary outcome
variable. In the ?Ecological Momentary Assessment? (EMA) study,
participants received five random prompts per day for six weeks, asking
them (among other things) whether they were craving a particular drug
(yes/no). At the most basic level, I want to know whether the likelihood of
craving the drug changed across time.

Given the variable time intervals of measurement and many missing data
points, a continuous-time first-order autocorrelation model seems
necessary.

I found tutorials on how to allow for continuous-time autocorrelation and
missing data in an LMM, using nlme::lme and corCAR1, but I am at a loss as
to what to do in a GLMM.

I would be thankful for any suggestions on how to analyze this kind of data
in R.

Dennis





Dennis....try glmmTMB (and use gau() or exp())....or R-INLA to implement GLM(M)s with correlation.




Kind regards,

Alain



 ?[[alternative HTML version deleted]]




------------------------------

Subject: Digest Footer

_______________________________________________
R-sig-mixed-models mailing list
R-sig-mixed-models at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


------------------------------

End of R-sig-mixed-models Digest, Vol 134, Issue 39
***************************************************

-- 

Dr. Alain F. Zuur
Highland Statistics Ltd.
9 St Clair Wynd
AB41 6DZ Newburgh, UK
Email: highstat at highstat.com
URL:   www.highstat.com

And:
NIOZ Royal Netherlands Institute for Sea Research,
Department of Coastal Systems, and Utrecht University,
P.O. Box 59, 1790 AB Den Burg,
Texel, The Netherlands



Author of:
1. Beginner's Guide to Spatial, Temporal and Spatial-Temporal Ecological Data Analysis with R-INLA. (2017).
2. Beginner's Guide to Zero-Inflated Models with R (2016).
3. Beginner's Guide to Data Exploration and Visualisation with R (2015).
4. Beginner's Guide to GAMM with R (2014).
5. Beginner's Guide to GLM and GLMM with R (2013).
6. Beginner's Guide to GAM with R (2012).
7. Zero Inflated Models and GLMM with R (2012).
8. A Beginner's Guide to R (2009).
9. Mixed effects models and extensions in ecology with R (2009).
10. Analysing Ecological Data (2007).


From pierre.de.villemereuil at mailoo.org  Tue Feb 27 09:53:29 2018
From: pierre.de.villemereuil at mailoo.org (Pierre de Villemereuil)
Date: Tue, 27 Feb 2018 09:53:29 +0100
Subject: [R-sig-ME] Including random effects creates structure in the
 residuals
Message-ID: <3327781.mmodNga8li@flyosflip>

Dear all,

I have an issue that I can't get my head around. I am working on a human cohort dataset studying heart rate. We have repeated measures at several time points and a model with different slopes according to binned age categories (the variable called "broken" hereafter, for "broken lines").

My issue is that when I include an individual ID effect (to account for the repeated measures), I obtain structured residuals while this is not the case for a model without this effect.

Here are my models:
mod_withID <- lmer(cardfreq ~ sex + 
								broken + 
								age:broken + 
								betabloq + 
								cafethe + 
								tabac + 
								alcool +
								(1|visite) +
								(1|id),
				   data = sub)
mod_noID <- lmer(cardfreq ~ sex + 
								broken + 
								age:broken + 
								betabloq + 
								cafethe + 
								tabac + 
								alcool +
								(1|visite),
				  data = sub)

The AIC (computed with a fit with REML = FALSE) clearly favours the model including the ID effect:
AIC(mod_withID)
75184.51
AIC(mod_noID)
76942.09

Yet, the model including the ID effect suffers from a bad fit from the residuals point of view (structured residuals) as the plots below show:
- The residuals with the ID effect:
https://ibb.co/b6WsFx
- The residuals without the ID effect:
https://ibb.co/fFVDNc

>From this, I gather that the fixed effect part is good enough to provide a good fit, but there is a covariance from the residuals and the BLUPs from the ID effect (I've checked this). Especially, if we marginalise on the random effects to compute the residuals, then everything is fine, suggesting the issue lies in the random rather than the fixed part.

I'm a bit puzzled by this. Why would adding an individual effect would create such a structure in the residual part? Why does this covariance between the individual BLUPs and the residual arise?

I'd happily take anyone's input on this as I'm at a loss regarding what to do to solve this.

Cheers,
Pierre


From d.e.kornbrot at herts.ac.uk  Tue Feb 27 11:06:55 2018
From: d.e.kornbrot at herts.ac.uk (Kornbrot, Diana)
Date: Tue, 27 Feb 2018 10:06:55 +0000
Subject: [R-sig-ME] R-sig-mixed-models Digest, Vol 134, Issue 39
In-Reply-To: <mailman.16160.1302.1519712545.1673.r-sig-mixed-models@r-project.org>
References: <mailman.16160.1302.1519712545.1673.r-sig-mixed-models@r-project.org>
Message-ID: <2D7C990E-7A00-4755-8A4D-94A3B03B9A69@herts.ac.uk>

thanks to ben bolker

"Look into the (very well-documented) emmeans package:
https://CRAN.R-project.org/package=emmeans?

well documented? you cannot be serious - this is R

the install instructions are as follows

* To install the latest development version from Github, install the newest version of the **devtools** package; then run
```
devtools::install_github("rvlenth/emmeans", dependencies = TRUE,
                        build_vignettes = TRUE)
```

of course this requires a whole to of other stuff like rmarkdown with no idea as to where they may be found
yet to find ANY R documentation that simply lists ALL required packages and library items

for any help to be useful one needs to know
1. ALL the necessary  packages
2. all the necessary commands. ? libraries
meanwhile here is  super friendly SPSS output
SPSS

Model Summary

Target

Events

FreqPos

Trials

Nmax

Probability Distribution

Binomial

Link Function

Logit

Information Criterion

Akaike Corrected

1189.377

Bayesian

1227.957

Information criteria are based on the -2 log likelihood (1168.768) and are used to compare models. Models with smaller information criterion values fit better.




Fixed Effectsa

Source

F

df1

df2

Sig.

Corrected Model

30.641

7

101

.000

Rab

66.755

3

94

.000

Between

.379

1

93

.540

Rab * Between

5.312

3

94

.002

Probability distribution: Binomial
Link function: Logit

a. Target: FreqPos/Nmax


Fixed Coefficientsa

Model Term

Coefficient

Std. Error

t

Sig.

95% Confidence Interval

Exp(Coefficient)

95% Confidence Interval for Exp(Coefficient)

Lower

Upper

Lower

Upper

Intercept

-.267

.1484

-1.801

.075

-.562

.027

.765

.570

1.028

Rab=4

-1.901

.2332

-8.149

.000

-2.364

-1.438

.149

.094

.237

Rab=3

-1.282

.2151

-5.963

.000

-1.710

-.855

.277

.181

.425

Rab=2

-.420

.1477

-2.847

.005

-.714

-.127

.657

.490

.881

Rab=1

0b

.

.

.

.

.

.

.

.

Between=2

.564

.2069

2.727

.008

.153

.975

1.758

1.166

2.651

Between=1

0b

.

.

.

.

.

.

.

.

[Rab=4]*[Between=2]

-.895

.3438

-2.602

.011

-1.577

-.212

.409

.207

.809

[Rab=4]*[Between=1]

0b

.

.

.

.

.

.

.

.

[Rab=3]*[Between=2]

-1.253

.3296

-3.800

.000

-1.907

-.598

.286

.149

.550

[Rab=3]*[Between=1]

0b

.

.

.

.

.

.

.

.

[Rab=2]*[Between=2]

-.621

.2064

-3.010

.003

-1.031

-.211

.537

.357

.810

[Rab=2]*[Between=1]

0b

.

.

.

.

.

.

.

.

[Rab=1]*[Between=2]

0b

.

.

.

.

.

.

.

.

[Rab=1]*[Between=1]

0b

.

.

.

.

.

.

.

.

Probability distribution: Binomial
Link function: Logit

a. Target: FreqPos/Nmax

b. This coefficient is set to zero because it is redundant.

R output
Analysis of Variance Table
                     Df  Sum Sq Mean Sq     F value
Rab                  3 870.17   290.058     290.058
Between          1   0.12          0.122         0.122
Rab:Between  3  63.20        21.067      21.067
Notice that F = Mean Sq, which is a SURPRISE usually F = MSeffect/MSerror, so where is the MS error?

fixef(Logit1)
  (Intercept)          Rab2          Rab3                 Rab4           Between2     Rab2:Between2 Rab3:Between2 Rab4:Between2
   -0.3162873    -0.5033874    -1.5218751    -2.2416235     0.6735183    -0.7491242      -1.4426385       -1.0069334

Really do appreciate help
best
Diana

On 27 Feb 2018, at 06:22, r-sig-mixed-models-request at r-project.org<mailto:r-sig-mixed-models-request at r-project.org> wrote:

Send R-sig-mixed-models mailing list submissions to
r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>

To subscribe or unsubscribe via the World Wide Web, visit
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
or, via email, send a message with subject or body 'help' to
r-sig-mixed-models-request at r-project.org

You can reach the person managing the list at
r-sig-mixed-models-owner at r-project.org

When replying, please edit your Subject line so it is more specific
than "Re: Contents of R-sig-mixed-models digest..."


Today's Topics:

  1. Re: zero-inflated-count-data? (Highland Statistics Ltd)
  2. Re: means , CIs from lmer, glmer (Ben Bolker)
  3. Re: zero-inflated-count-data? (Ben Bolker)
  4. Longitudinal logistic regression with continuous-time
     first-order autocorrelation structure (Dennis Ruenger)

----------------------------------------------------------------------

Message: 1
Date: Mon, 26 Feb 2018 17:26:02 +0000
From: Highland Statistics Ltd <highstat at highstat.com>
To: "r-sig-mixed-models at r-project.org"
<r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] zero-inflated-count-data?
Message-ID: <d1db8134-8ae0-ff56-4622-02a909a2ff1b at highstat.com>
Content-Type: text/plain; charset="utf-8"; Format="flowed"


----------------------------------------------------------------------

Message: 1
Date: Mon, 26 Feb 2018 14:57:00 +0100
From: "C. AMAL D. GLELE" <altessedac2 at gmail.com>
To: Jonathan Judge <bachlaw01 at outlook.com>
Cc: Ben Bolker <bbolker at gmail.com>,  R SIG Mixed Models
<r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] zero-inflated-count-data?
Message-ID:
<CANrzCv0SZxAXjoftdkN7v5M4g6wrd3GM7qx23dFB=fi7JHisCg at mail.gmail.com>
Content-Type: text/plain; charset="utf-8"

Hi, dear all.
Many thanks to you all for your very helpful answers.
Jonathan,
I've started fitting a model using zeroinfl function from pscl package, but
I'm having the following

difficulty according to one of my regressors, let be H_var (categorical
with 8 levels):
as regressors, I have 7 categorical variables (with a total of 26 levels)
and two numerical

variables;
1) when I fit the model like follows,
model1<-zeroinfl(countdata~var1+H_var+var3+var4+var5+var6+var7+var8num

+var9num,dist="negbin",data=mydata)
, I receive the error message below:
"Error in solve.default(as.matrix(fit$hessian)) :
  system is computationally singular: reciprocal condition number =
7.05621e-21
In addition: Warning message:
glm.fit: fitted probabilities numerically 0 or 1 occurred
"
2)
but, if I remove H_var from the count component and fits model2 loke
follows,
model2<-zeroinfl(countdata~var1+var3+var4+var5+var6+var7+var8num+
var9num|H_var,dist="negbin",data=mydata)
 the model fits well and I do not receive error message anymore.
3)
If use H_var in both component of the model, like follows,
model3<-zeroinfl(countdata~var1+var3+var4+var5+var6+var7+var8num+
var9num+H_var|H_var,dist="negbin",data=mydata)
I receive the following error message:
"Error in solve.default(as.matrix(fit$hessian)) :
  system is computationally singular: reciprocal condition number =
4.2618e-20
"
Question:
 Does someone have any idea about probables causes of the problems posed
at points 1) and 3) ?






Without seeing the data......simplify your model? Collinearity? Start simple and build up the complexity of the model.
Maybe start with a Poisson GLM and figure out whether you really need a ZIP/ZINB? Why are you actually do a ZINB?






can you, please, provide me details (some ways to do it) and/or lead about
simulating data from a fitted model?





See step 10 in:

A protocol for conducting and presenting results of regression-type analyses (2016).
Zuur & Ieno.

http://onlinelibrary.wiley.com/doi/10.1111/2041-210X.12577/abstract

and see Figure 8 from that paper for an example. R code is somewhere online as well.


Alain







 In advance, thanks for your answers.
Best,

2018-02-25 23:55 GMT+01:00 Jonathan Judge <bachlaw01 at outlook.com>:
--

Dr. Alain F. Zuur
Highland Statistics Ltd.
9 St Clair Wynd
AB41 6DZ Newburgh, UK
Email: highstat at highstat.com
URL:   www.highstat.com

And:
NIOZ Royal Netherlands Institute for Sea Research,
Department of Coastal Systems, and Utrecht University,
P.O. Box 59, 1790 AB Den Burg,
Texel, The Netherlands



Author of:
1. Beginner's Guide to Spatial, Temporal and Spatial-Temporal Ecological Data Analysis with R-INLA. (2017).
2. Beginner's Guide to Zero-Inflated Models with R (2016).
3. Beginner's Guide to Data Exploration and Visualisation with R (2015).
4. Beginner's Guide to GAMM with R (2014).
5. Beginner's Guide to GLM and GLMM with R (2013).
6. Beginner's Guide to GAM with R (2012).
7. Zero Inflated Models and GLMM with R (2012).
8. A Beginner's Guide to R (2009).
9. Mixed effects models and extensions in ecology with R (2009).
10. Analysing Ecological Data (2007).




------------------------------

Message: 2
Date: Mon, 26 Feb 2018 20:02:57 -0500
From: Ben Bolker <bbolker at gmail.com>
To: "Kornbrot, Diana" <d.e.kornbrot at herts.ac.uk>
Cc: "r-sig-mixed-models at r-project.org"
<r-sig-mixed-models at r-project.org>, "Paice, Andrew"
<a.paice at herts.ac.uk>,  "Georgiou, George" <g.j.georgiou at herts.ac.uk>,
"Sullivan, Keith" <k.sullivan3 at herts.ac.uk>
Subject: Re: [R-sig-ME] means , CIs from lmer, glmer
Message-ID:
<CABghstTnvHcvQab_dH9j_BcfxvnbEREuHOkZaen9m_TmRLSovw at mail.gmail.com>
Content-Type: text/plain; charset="utf-8"

 Hi Diana,

A reproducible example is always helpful/increases your chances of
getting a useful answer ...
It might help if you included the SPSS output (or posted it somewhere
-- note that this list doesn't take HTML-formatted messages nor most
attachments), as many of us don't have access to it.

Look into the (very well-documented) emmeans package:
https://CRAN.R-project.org/package=emmeans
and the lmerTest package (for Satterthwaite df approximations)

On Mon, Feb 26, 2018 at 12:11 PM, Kornbrot, Diana
<d.e.kornbrot at herts.ac.uk> wrote:
I am keen to promote the use of generalised mixed models for the analysis of proportions to psychologists
Have straight fowl code in SPSS [costly] and would like to supply equivalent R Code without ?tears?
Design is a follows raw frequencies are: FreqPos for ?success? and FreqNeg for ?failure?
Predictors are Rab with 4 levels, repeated over participants and Between with 2 separate groups of participants
Model is binomial with logit link

Require following output to correspond to SPSS output from code below
Descriptive: Means, se and 95% CIs  by Rab, by Between and by Rab*Between
Inferential: fo  Rab, Between and  Rab*Between: F value, MSE, numerator df, denominator df [this enables p-values]

Have tried

logit1 <- glmer(cbind(FreqPos,FreqNeg) ~ Rab + Between + Rab*Between + (1| Participant), family=binomial(link="logit"))
gives F and MSE no denominator df or MSE. Different results to SPSS
nb F=MSE - that can?t be right F is supposed to be ratio of chi-squares

summary (logit1)
gives coefficients  and SEs. Different results to SPSS
also tried predicted and fitted but still no means

have spent days searching internet for examples - but none of them seem to show how to get the output I need

All help greatly appreciated

____
Spss syntax

*Generalized Linear Mixed Models.
GENLINMIXED
 /DATA_STRUCTURE SUBJECTS=Participant REPEATED_MEASURES=Rab COVARIANCE_TYPE=UNSTRUCTURED
 /FIELDS TARGET=FreqPos TRIALS=FIELD(Nmax)  OFFSET=NONE
 /TARGET_OPTIONS DISTRIBUTION=BINOMIAL LINK=LOGIT
 /FIXED  EFFECTS=Rab Between Rab*Between USE_INTERCEPT=TRUE
 /BUILD_OPTIONS TARGET_CATEGORY_ORDER=DESCENDING INPUTS_CATEGORY_ORDER=DESCENDING MAX_ITERATIONS=100 CONFIDENCE_LEVEL=95 DF_METHOD=SATTERTHWAITE COVB=MODEL PCONVERGE=0.000001(ABSOLUTE) SCORING=0 SINGULAR=0.000000000001
 /EMMEANS TABLES=Rab COMPARE=Rab CONTRAST=DEVIATION
  /EMMEANS TABLES=Between CONTRAST=NONE
  /EMMEANS TABLES=Rab*Between CONTRAST=NONE
 /EMMEANS_OPTIONS SCALE=ORIGINAL PADJUST=LSD.

best
Diana


_____________________________________
Professor Diana Kornbrot
Mobile
+44 (0) 7403 18 16 12
Work
University of Hertfordshire
College Lane, Hatfield, Hertfordshire AL10 9AB, UK
+44 (0) 170 728 4626
d.e.kornbrot at herts.ac.uk<mailto:d.e.kornbrot at herts.ac.uk>
http://dianakornbrot.wordpress.com/
http://go.herts.ac.uk/Diana_Kornbrot
skype:  kornbrotme
Home
19 Elmhurst Avenue
London N2 0LT, UK
+44 (0) 208 444 2081
------------------------------------------------------------




       [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models




------------------------------

Message: 3
Date: Mon, 26 Feb 2018 20:17:14 -0500
From: Ben Bolker <bbolker at gmail.com>
To: Highland Statistics Ltd <highstat at highstat.com>
Cc: "r-sig-mixed-models at r-project.org"
<r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] zero-inflated-count-data?
Message-ID:
<CABghstRR41zVjimCX=Q3mc+AckchFOTc_8kb8ASfVb6pUSokyQ at mail.gmail.com>
Content-Type: text/plain; charset="utf-8"

For some model types (unfortunately not pscl::zeroinlf(), it looks
like) you can just
use the simulate() method ...

By the way, Amal (hope that's a reasonable way to address you) - folks
are really helpful here (as
you will have noticed), but the list is primarily for questions about
*mixed* (hierarchical/multilevel/whatever) models.
At present your questions are more generic questions about
zero-inflation and generalized linear modeling.
I do recommend the books by Alain and his co-authors as a good way to
get started on the fairly
complex stuff you're attempting here.

On Mon, Feb 26, 2018 at 12:26 PM, Highland Statistics Ltd
<highstat at highstat.com> wrote:

----------------------------------------------------------------------

Message: 1
Date: Mon, 26 Feb 2018 14:57:00 +0100
From: "C. AMAL D. GLELE" <altessedac2 at gmail.com>
To: Jonathan Judge <bachlaw01 at outlook.com>
Cc: Ben Bolker <bbolker at gmail.com>,  R SIG Mixed Models
       <r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] zero-inflated-count-data?
Message-ID:
       <CANrzCv0SZxAXjoftdkN7v5M4g6wrd3GM7qx23dFB=fi7JHisCg at mail.gmail.com>
Content-Type: text/plain; charset="utf-8"


Hi, dear all.
Many thanks to you all for your very helpful answers.
Jonathan,
I've started fitting a model using zeroinfl function from pscl package, but
I'm having the following

difficulty according to one of my regressors, let be H_var (categorical
with 8 levels):
as regressors, I have 7 categorical variables (with a total of 26 levels)
and two numerical

variables;
1) when I fit the model like follows,
model1<-zeroinfl(countdata~var1+H_var+var3+var4+var5+var6+var7+var8num

+var9num,dist="negbin",data=mydata)
, I receive the error message below:
"Error in solve.default(as.matrix(fit$hessian)) :
 system is computationally singular: reciprocal condition number =
7.05621e-21
In addition: Warning message:
glm.fit: fitted probabilities numerically 0 or 1 occurred
"
2)
but, if I remove H_var from the count component and fits model2 loke
follows,
model2<-zeroinfl(countdata~var1+var3+var4+var5+var6+var7+var8num+
var9num|H_var,dist="negbin",data=mydata)
the model fits well and I do not receive error message anymore.
3)
If use H_var in both component of the model, like follows,
model3<-zeroinfl(countdata~var1+var3+var4+var5+var6+var7+var8num+
var9num+H_var|H_var,dist="negbin",data=mydata)
I receive the following error message:
"Error in solve.default(as.matrix(fit$hessian)) :
 system is computationally singular: reciprocal condition number =
4.2618e-20
"
Question:
Does someone have any idea about probables causes of the problems posed
at points 1) and 3) ?






Without seeing the data......simplify your model? Collinearity? Start simple
and build up the complexity of the model.
Maybe start with a Poisson GLM and figure out whether you really need a
ZIP/ZINB? Why are you actually do a ZINB?






can you, please, provide me details (some ways to do it) and/or lead about
simulating data from a fitted model?





See step 10 in:

A protocol for conducting and presenting results of regression-type analyses
(2016).
Zuur & Ieno.

http://onlinelibrary.wiley.com/doi/10.1111/2041-210X.12577/abstract

and see Figure 8 from that paper for an example. R code is somewhere online
as well.


Alain







In advance, thanks for your answers.
Best,

2018-02-25 23:55 GMT+01:00 Jonathan Judge <bachlaw01 at outlook.com>:
--

Dr. Alain F. Zuur
Highland Statistics Ltd.
9 St Clair Wynd
AB41 6DZ Newburgh, UK
Email: highstat at highstat.com
URL:   www.highstat.com

And:
NIOZ Royal Netherlands Institute for Sea Research,
Department of Coastal Systems, and Utrecht University,
P.O. Box 59, 1790 AB Den Burg,
Texel, The Netherlands



Author of:
1. Beginner's Guide to Spatial, Temporal and Spatial-Temporal Ecological
Data Analysis with R-INLA. (2017).
2. Beginner's Guide to Zero-Inflated Models with R (2016).
3. Beginner's Guide to Data Exploration and Visualisation with R (2015).
4. Beginner's Guide to GAMM with R (2014).
5. Beginner's Guide to GLM and GLMM with R (2013).
6. Beginner's Guide to GAM with R (2012).
7. Zero Inflated Models and GLMM with R (2012).
8. A Beginner's Guide to R (2009).
9. Mixed effects models and extensions in ecology with R (2009).
10. Analysing Ecological Data (2007).

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models




------------------------------

Message: 4
Date: Mon, 26 Feb 2018 22:22:17 -0800
From: Dennis Ruenger <dennis.ruenger at gmail.com>
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] Longitudinal logistic regression with
continuous-time first-order autocorrelation structure
Message-ID:
<CAFvg1=vdVbz28pw9B6GrOXNsnceXK3UgXksMDwJUOQ9PYoLK_g at mail.gmail.com>
Content-Type: text/plain; charset="utf-8"

Dear All.

I need to analyze an intensive longitudinal data set with a binary outcome
variable. In the ?Ecological Momentary Assessment? (EMA) study,
participants received five random prompts per day for six weeks, asking
them (among other things) whether they were craving a particular drug
(yes/no). At the most basic level, I want to know whether the likelihood of
craving the drug changed across time.

Given the variable time intervals of measurement and many missing data
points, a continuous-time first-order autocorrelation model seems
necessary.

I found tutorials on how to allow for continuous-time autocorrelation and
missing data in an LMM, using nlme::lme and corCAR1, but I am at a loss as
to what to do in a GLMM.

I would be thankful for any suggestions on how to analyze this kind of data
in R.

Dennis

[[alternative HTML version deleted]]




------------------------------

Subject: Digest Footer

_______________________________________________
R-sig-mixed-models mailing list
R-sig-mixed-models at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


------------------------------

End of R-sig-mixed-models Digest, Vol 134, Issue 39
***************************************************

_____________________________________
Professor Diana Kornbrot
Mobile
+44 (0) 7403 18 16 12
Work
University of Hertfordshire
College Lane, Hatfield, Hertfordshire AL10 9AB, UK
+44 (0) 170 728 4626
d.e.kornbrot at herts.ac.uk<mailto:d.e.kornbrot at herts.ac.uk>
http://dianakornbrot.wordpress.com/
http://go.herts.ac.uk/Diana_Kornbrot
skype:  kornbrotme
Home
19 Elmhurst Avenue
London N2 0LT, UK
+44 (0) 208 444 2081
 ------------------------------------------------------------




	[[alternative HTML version deleted]]


From rune.haubo at gmail.com  Tue Feb 27 11:15:46 2018
From: rune.haubo at gmail.com (Rune Haubo)
Date: Tue, 27 Feb 2018 11:15:46 +0100
Subject: [R-sig-ME] Error message in running CLMM models from Ordinal
 package: "optimizer nlminb failed to converge"
In-Reply-To: <D6B9C505.C71F%davis.ozols@unifr.ch>
References: <D6B9C505.C71F%davis.ozols@unifr.ch>
Message-ID: <CAG_uk93W5wPw66ASy03P3Kruc0zL4y-UfuEBaU2HkAAZXXeT_g@mail.gmail.com>

It is difficult to say why the bigger model converges while the
submodels do not. Perhaps the surprising part is why the bigger model
converges rather than why the simpler ones don't given the rather
complicated variance structure in the models.

I don't see how the design can demand a variance structure this
complicated and I would not assume that there is support in the data
for these complicated structures over simpler alternatives. With
models as (computationally) complicated as mixed models I think it is
good advice to start small and build on model structures until
additional structures are no longer supported by the data. This
doesn't mean that the inferential process has to run bottom-up as
well.

In a situation like this I would start with something like

fm1 <- clmm( value.statement ~ preexisting.belief * engagement + (1 |
id) + (1 | item), data=ucl.ordered)

or even simpler in both fixed and random structures if this gives rise
to any problems. Focusing on the random structure, I would expand with
additional _independent_ terms:

fm2 <- clmm( value.statement ~ preexisting.belief * engagement + (1 |
id) + (1 | item) + (1 | id:engagement) + (1 | item:engagement),
data=ucl.ordered)

continue to add terms like (1 | id:preexisting.belief) and (1 |
id:preexisting.belief:engagement) if these terms are necessary or
should be assessed (and if the model remains identifiable). Unless I
need random slopes I very rarely move on to
multivariate/vector-valued/correlated random-effect terms such as
'(engagement | item)', but some feel that such terms make a lot of
sense. But if you do want, vector-valued random effects, my suggestion
is to look at how much support the data offers for such structures (in
my experience they are usually not supported). For instance you could
compare (focusing on random structures for item):

fm3 <- clmm( value.statement ~ preexisting.belief * engagement + (1 |
item) + (1 | item:engagement)  + (1 | id), data=ucl.ordered)
fm4 <- clmm( value.statement ~ preexisting.belief * engagement +
(engagement | item)  + (1 | id), data=ucl.ordered)

fm1, fm3 and fm4 represents increasingly more complex random-effect
structures for item and my advice is to not work with models which are
more complex than what the data can reasonably support. In practice
this means that if I fit fm1 and fm3 and run anova(fm3, fm1) and the
p-value is not small-ish, I stick with fm1. If, instead there is
support for fm3 over fm1 it can make sense to move on to consider fm4.

Finally, let me digress momentarily on what fm3 and fm4 means:
Scientifically fm3 represents a random interaction between item and
engagement which means that random effects for item depend on the
level of engagement. This is classical design-of-experiments line of
thinking and a reasonable thing to consider. fm4 represents a
particular interaction between engagement and item in which the
_variance_ of the random effects for item (in addition to the
random-effects for item themselves) depend on the level of engagement,
but is there are particular scientific reason why the item-level
_variance_ should depend on engagement?

Hope this helps
Rune

On 26 February 2018 at 15:07, OZOLS Davis via R-sig-mixed-models
<r-sig-mixed-models at r-project.org> wrote:
> Dear list,
>
> I have a question with regards to model convergence in CLMM function that is implemented in the Ordinal package. More specifically what might cause the error: "optimizer nlminb failed to converge message" in the CLMM function that I am getting.
>
> I am new to mixed model analysis so I will try to explain all the steps I have taken in case there might be something wrong in my approach to the analysis.
>
> I have data set of 2200 observations with 6 variables: 115 participants, 24 items and a design that has as a response variable an ordered scale from 1 to 10.
>
>> head(data.ord)
> id item value.statement quant preexisting.belief engagement
> 1 R_ysTGuC676siU2Pf   I1               3 Baseline                 low       high
> 2 R_ysTGuC676siU2Pf   I2               2 Baseline                 low       high
> 3 R_ysTGuC676siU2Pf   I26               2     Most               low       high
> 4 R_ysTGuC676siU2Pf   I40               3     Every               low       high
> 5 R_ysTGuC676siU2Pf   I4               7 Baseline           undecided     high
> 6 R_ysTGuC676siU2Pf   I10               4 Baseline           undecided     low
>
> I investigate the interaction of three factors on the response variable:
> quant(4 levels)* preexisting.belief(3 levels)* engagement(2 levels)
>
>
> this is the summary of my data:
>
>> str(data.ord)
> 'data.frame': 2200 obs. of  6 variables:
>  $ id                 : Factor w/ 115 levels
>  $ item               : Factor w/ 24 levels
>  $ value.statement   : Ord.factor w/ 10 levels
>  $ quant              : Factor w/ 4 levels
>  $ preexisting.belief : Factor w/ 3 levels
>  $ engagement         : Factor w/ 2 levels
>
>
> I plan to do my analysis by fitting four clmm models with random intercept and random slope structures for both participants and items. I choose the exact random effect structure based on theoretical assumptions in my hypothesis as well as backward model selection criterion discussed by Matuschek, Kliegel, Vasishth, Baayen & Bates (2017) and Barr, Levy, Scheepers & Tily (2013). Due to the complexity of my design it is not possible to fit the full three way interaction as a random slope so I choose (1 + preexisting.belief*engagement |id) for participants and (1 + engagement |item) for items - the choice is motivated by theoretical assumptions as well as comparison of various random effect models (with full interaction in fixed effects) using the anova() function. I then proceed to fit the four clmm models to test my fixed effects, starting with the null model and then adding all the interaction terms in a step wise fashion.
>
> While the more complex models like model 2 and 3 are able to converge:
>
>
>> cm.2 <- clmm(value.statement~preexisting.belief*engagement +
> +                       (1 + preexisting.belief*engagement |id) + (1 + engagement |item),
> +                 data = ucl.ordered, Hess = TRUE)
>
> running the summary() function gives me:
> max.grad = 9.78e-03 and cond.H = 2.3e+04
>
>
>> cm.3 <- clmm(value.statement~quant*preexisting.belief*engagement +
> +                       (1 + preexisting.belief*engagement |id) + (1 + engagement |item),
> +                 data = ucl.ordered, Hess = TRUE)
>
> running the summary() function gives me:
> max.grad = 1.28e-01 and cond.H = 1.7e+04
>
>
> I find that the simpler model and even the null model show failures to converge:
>
>
>> cm.null <- clmm(value.statement~1 +
> +                        (1 + preexisting.belief*engagement |id) + (1 + engagement |item),
> +                  data = ucl.ordered, Hess = TRUE)
> Error: optimizer nlminb failed to converge
>
>> cm.1 <- clmm(value.statement~quant +
> +                        (1 + preexisting.belief*engagement |id) + (1 + engagement |item),
> +                  data = ucl.ordered, Hess = TRUE)
> Error: optimizer nlminb failed to converge
>
>
> I have tried looking for potential solutions to this on the r-sig-mm list as well as other online resources and have tried some suggestions. Using the "ucminf" optimizer does not work and produces error message: "cannot use ucminf optimizer for this model, using nlminb instead". I have tried changing the maxIter and maxLineIter parameters under clmm.control to 200 and that has also resulted in no improvement. I am puzzled by the fact that the error persists only for the simpler models. My first guess was that the complexity of my design is too much for clmm to handle with only 2200 observations, however, if that were the case wouldn't models 3 and 4 also fail to converge?
>
> I would greatly appreciate any help on these errors. I am also happy to share the full data (in private correspondence) if that might be of help here.
>
> Thank you in advance,
> Davis Ozols
> PhD Student,
> University of Fribourg
> CH-1700 Fribourg, Switzerland
>
> Tel: +41 26 300 79 09
> Fax: +41 26 300 97 87
>
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From rune.haubo at gmail.com  Tue Feb 27 11:22:06 2018
From: rune.haubo at gmail.com (Rune Haubo)
Date: Tue, 27 Feb 2018 11:22:06 +0100
Subject: [R-sig-ME] means , CIs from lmer, glmer
In-Reply-To: <CABghstTnvHcvQab_dH9j_BcfxvnbEREuHOkZaen9m_TmRLSovw@mail.gmail.com>
References: <62C83545-F497-4BAF-9599-8764F48E13C6@herts.ac.uk>
 <CABghstTnvHcvQab_dH9j_BcfxvnbEREuHOkZaen9m_TmRLSovw@mail.gmail.com>
Message-ID: <CAG_uk93LXzvp2ORp85-VYkYAm+JHrPOs45qDHtLxn9ozatPJjg@mail.gmail.com>

Just a small note that lmerTest (and the Satterthwaite method for
degrees of freedom) is only meaningful for _linear_ mixed models - not
for the generalized variants such as the one considered here for
proportions.

Best,
Rune

On 27 February 2018 at 02:02, Ben Bolker <bbolker at gmail.com> wrote:
>   Hi Diana,
>
> A reproducible example is always helpful/increases your chances of
> getting a useful answer ...
> It might help if you included the SPSS output (or posted it somewhere
> -- note that this list doesn't take HTML-formatted messages nor most
> attachments), as many of us don't have access to it.
>
> Look into the (very well-documented) emmeans package:
> https://CRAN.R-project.org/package=emmeans
> and the lmerTest package (for Satterthwaite df approximations)
>
> On Mon, Feb 26, 2018 at 12:11 PM, Kornbrot, Diana
> <d.e.kornbrot at herts.ac.uk> wrote:
>> I am keen to promote the use of generalised mixed models for the analysis of proportions to psychologists
>> Have straight fowl code in SPSS [costly] and would like to supply equivalent R Code without ?tears?
>> Design is a follows raw frequencies are: FreqPos for ?success? and FreqNeg for ?failure?
>> Predictors are Rab with 4 levels, repeated over participants and Between with 2 separate groups of participants
>> Model is binomial with logit link
>>
>> Require following output to correspond to SPSS output from code below
>> Descriptive: Means, se and 95% CIs  by Rab, by Between and by Rab*Between
>> Inferential: fo  Rab, Between and  Rab*Between: F value, MSE, numerator df, denominator df [this enables p-values]
>>
>> Have tried
>>
>> logit1 <- glmer(cbind(FreqPos,FreqNeg) ~ Rab + Between + Rab*Between + (1| Participant), family=binomial(link="logit"))
>> gives F and MSE no denominator df or MSE. Different results to SPSS
>> nb F=MSE - that can?t be right F is supposed to be ratio of chi-squares
>>
>> summary (logit1)
>> gives coefficients  and SEs. Different results to SPSS
>> also tried predicted and fitted but still no means
>>
>> have spent days searching internet for examples - but none of them seem to show how to get the output I need
>>
>> All help greatly appreciated
>>
>> ____
>> Spss syntax
>>
>> *Generalized Linear Mixed Models.
>> GENLINMIXED
>>   /DATA_STRUCTURE SUBJECTS=Participant REPEATED_MEASURES=Rab COVARIANCE_TYPE=UNSTRUCTURED
>>   /FIELDS TARGET=FreqPos TRIALS=FIELD(Nmax)  OFFSET=NONE
>>   /TARGET_OPTIONS DISTRIBUTION=BINOMIAL LINK=LOGIT
>>   /FIXED  EFFECTS=Rab Between Rab*Between USE_INTERCEPT=TRUE
>>   /BUILD_OPTIONS TARGET_CATEGORY_ORDER=DESCENDING INPUTS_CATEGORY_ORDER=DESCENDING MAX_ITERATIONS=100 CONFIDENCE_LEVEL=95 DF_METHOD=SATTERTHWAITE COVB=MODEL PCONVERGE=0.000001(ABSOLUTE) SCORING=0 SINGULAR=0.000000000001
>>   /EMMEANS TABLES=Rab COMPARE=Rab CONTRAST=DEVIATION
>>    /EMMEANS TABLES=Between CONTRAST=NONE
>>    /EMMEANS TABLES=Rab*Between CONTRAST=NONE
>>   /EMMEANS_OPTIONS SCALE=ORIGINAL PADJUST=LSD.
>>
>> best
>> Diana
>>
>>
>> _____________________________________
>> Professor Diana Kornbrot
>> Mobile
>> +44 (0) 7403 18 16 12
>> Work
>> University of Hertfordshire
>> College Lane, Hatfield, Hertfordshire AL10 9AB, UK
>> +44 (0) 170 728 4626
>> d.e.kornbrot at herts.ac.uk<mailto:d.e.kornbrot at herts.ac.uk>
>> http://dianakornbrot.wordpress.com/
>> http://go.herts.ac.uk/Diana_Kornbrot
>> skype:  kornbrotme
>> Home
>> 19 Elmhurst Avenue
>> London N2 0LT, UK
>> +44 (0) 208 444 2081
>>  ------------------------------------------------------------
>>
>>
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From paul.johnson at glasgow.ac.uk  Tue Feb 27 12:03:17 2018
From: paul.johnson at glasgow.ac.uk (Paul Johnson)
Date: Tue, 27 Feb 2018 11:03:17 +0000
Subject: [R-sig-ME] Including random effects creates structure in the
 residuals
In-Reply-To: <3327781.mmodNga8li@flyosflip>
References: <3327781.mmodNga8li@flyosflip>
Message-ID: <64A7142C-55FA-43E8-B457-8C80D8AA1DE4@glasgow.ac.uk>

Hi Pierre,

I don?t think there is a problem with the residuals. Just to check, the problem you see is that there?s a linear trend in the residuals vs fitted values plot when the ID random effect is included (which in a standard OLS LM would be impossible).

The reason for the correlation is that the fitted values contain the ID random effects, and these are inevitably correlated with the residuals. My intuitive understanding of this is as follows. Say some students sit a test twice, on two separate days. A student's score on a given day will be a combination of their ability (ID random effect) and unmeasured (i.e. noise) factors, like how the student was feeling on that day. Assuming that both ability and luck contribute substantially to the scores, it?s inevitable that the extreme upper end of the distribution will be populated by scores from students who are both able (high ID random effect) and were lucky on that day (high error residual). The same goes in the negative direction for the lower end of the distribution. This the basis of is regression to the mean - if we pick a student with an extreme score and re-test them, we expect their score to be less extreme. If I remember correctly it?s fairly straightforward to predict the correlation of the residuals and fitted values for a given model.

On the broader topic of checking residuals from GLMMs? 
I wrote a simple function to check residuals from lme4 fits by simulating residuals from the fitted model and plotting them on top of the real residuals. If they look similar on several simulated data sets them I?m reassured that the model fits well. This is particularly useful for non-normal GLMMs where (despite popular belief) there's no assumption of normality of the Pearson residuals.

library(devtools)
install_github("pcdjohnson/GLMMmisc") 
library(GLMMmisc)
library(lme4)
fm1 <- lmer(Reaction ~ Days + (Days | Subject), sleepstudy)
sim.residplot(fm1)
# note the correlation between the residuals and the fitted values

Florian Hartig has written a more sophisticated package that uses the same basic idea called DHARMa:
https://cran.r-project.org/web/packages/DHARMa/index.html
His blog post:
https://theoreticalecology.wordpress.com/2016/08/28/dharma-an-r-package-for-residual-diagnostics-of-glmms/

All the best,
Paul


> On 27 Feb 2018, at 08:53, Pierre de Villemereuil <pierre.de.villemereuil at mailoo.org> wrote:
> 
> Dear all,
> 
> I have an issue that I can't get my head around. I am working on a human cohort dataset studying heart rate. We have repeated measures at several time points and a model with different slopes according to binned age categories (the variable called "broken" hereafter, for "broken lines").
> 
> My issue is that when I include an individual ID effect (to account for the repeated measures), I obtain structured residuals while this is not the case for a model without this effect.
> 
> Here are my models:
> mod_withID <- lmer(cardfreq ~ sex + 
> 								broken + 
> 								age:broken + 
> 								betabloq + 
> 								cafethe + 
> 								tabac + 
> 								alcool +
> 								(1|visite) +
> 								(1|id),
> 				   data = sub)
> mod_noID <- lmer(cardfreq ~ sex + 
> 								broken + 
> 								age:broken + 
> 								betabloq + 
> 								cafethe + 
> 								tabac + 
> 								alcool +
> 								(1|visite),
> 				  data = sub)
> 
> The AIC (computed with a fit with REML = FALSE) clearly favours the model including the ID effect:
> AIC(mod_withID)
> 75184.51
> AIC(mod_noID)
> 76942.09
> 
> Yet, the model including the ID effect suffers from a bad fit from the residuals point of view (structured residuals) as the plots below show:
> - The residuals with the ID effect:
> https://ibb.co/b6WsFx
> - The residuals without the ID effect:
> https://ibb.co/fFVDNc
> 
> From this, I gather that the fixed effect part is good enough to provide a good fit, but there is a covariance from the residuals and the BLUPs from the ID effect (I've checked this). Especially, if we marginalise on the random effects to compute the residuals, then everything is fine, suggesting the issue lies in the random rather than the fixed part.
> 
> I'm a bit puzzled by this. Why would adding an individual effect would create such a structure in the residual part? Why does this covariance between the individual BLUPs and the residual arise?
> 
> I'd happily take anyone's input on this as I'm at a loss regarding what to do to solve this.
> 
> Cheers,
> Pierre
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbolker at gmail.com  Tue Feb 27 13:14:06 2018
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 27 Feb 2018 07:14:06 -0500
Subject: [R-sig-ME] means , CIs from lmer, glmer
In-Reply-To: <CAG_uk93LXzvp2ORp85-VYkYAm+JHrPOs45qDHtLxn9ozatPJjg@mail.gmail.com>
References: <62C83545-F497-4BAF-9599-8764F48E13C6@herts.ac.uk>
 <CABghstTnvHcvQab_dH9j_BcfxvnbEREuHOkZaen9m_TmRLSovw@mail.gmail.com>
 <CAG_uk93LXzvp2ORp85-VYkYAm+JHrPOs45qDHtLxn9ozatPJjg@mail.gmail.com>
Message-ID: <c900eade-264f-ca69-af18-2ec0f67d936b@gmail.com>


  Yes, that was a thinko on my part.  Thanks.

On 18-02-27 05:22 AM, Rune Haubo wrote:
> Just a small note that lmerTest (and the Satterthwaite method for
> degrees of freedom) is only meaningful for _linear_ mixed models - not
> for the generalized variants such as the one considered here for
> proportions.
> 
> Best,
> Rune
> 
> On 27 February 2018 at 02:02, Ben Bolker <bbolker at gmail.com> wrote:
>>   Hi Diana,
>>
>> A reproducible example is always helpful/increases your chances of
>> getting a useful answer ...
>> It might help if you included the SPSS output (or posted it somewhere
>> -- note that this list doesn't take HTML-formatted messages nor most
>> attachments), as many of us don't have access to it.
>>
>> Look into the (very well-documented) emmeans package:
>> https://CRAN.R-project.org/package=emmeans
>> and the lmerTest package (for Satterthwaite df approximations)
>>
>> On Mon, Feb 26, 2018 at 12:11 PM, Kornbrot, Diana
>> <d.e.kornbrot at herts.ac.uk> wrote:
>>> I am keen to promote the use of generalised mixed models for the analysis of proportions to psychologists
>>> Have straight fowl code in SPSS [costly] and would like to supply equivalent R Code without ?tears?
>>> Design is a follows raw frequencies are: FreqPos for ?success? and FreqNeg for ?failure?
>>> Predictors are Rab with 4 levels, repeated over participants and Between with 2 separate groups of participants
>>> Model is binomial with logit link
>>>
>>> Require following output to correspond to SPSS output from code below
>>> Descriptive: Means, se and 95% CIs  by Rab, by Between and by Rab*Between
>>> Inferential: fo  Rab, Between and  Rab*Between: F value, MSE, numerator df, denominator df [this enables p-values]
>>>
>>> Have tried
>>>
>>> logit1 <- glmer(cbind(FreqPos,FreqNeg) ~ Rab + Between + Rab*Between + (1| Participant), family=binomial(link="logit"))
>>> gives F and MSE no denominator df or MSE. Different results to SPSS
>>> nb F=MSE - that can?t be right F is supposed to be ratio of chi-squares
>>>
>>> summary (logit1)
>>> gives coefficients  and SEs. Different results to SPSS
>>> also tried predicted and fitted but still no means
>>>
>>> have spent days searching internet for examples - but none of them seem to show how to get the output I need
>>>
>>> All help greatly appreciated
>>>
>>> ____
>>> Spss syntax
>>>
>>> *Generalized Linear Mixed Models.
>>> GENLINMIXED
>>>   /DATA_STRUCTURE SUBJECTS=Participant REPEATED_MEASURES=Rab COVARIANCE_TYPE=UNSTRUCTURED
>>>   /FIELDS TARGET=FreqPos TRIALS=FIELD(Nmax)  OFFSET=NONE
>>>   /TARGET_OPTIONS DISTRIBUTION=BINOMIAL LINK=LOGIT
>>>   /FIXED  EFFECTS=Rab Between Rab*Between USE_INTERCEPT=TRUE
>>>   /BUILD_OPTIONS TARGET_CATEGORY_ORDER=DESCENDING INPUTS_CATEGORY_ORDER=DESCENDING MAX_ITERATIONS=100 CONFIDENCE_LEVEL=95 DF_METHOD=SATTERTHWAITE COVB=MODEL PCONVERGE=0.000001(ABSOLUTE) SCORING=0 SINGULAR=0.000000000001
>>>   /EMMEANS TABLES=Rab COMPARE=Rab CONTRAST=DEVIATION
>>>    /EMMEANS TABLES=Between CONTRAST=NONE
>>>    /EMMEANS TABLES=Rab*Between CONTRAST=NONE
>>>   /EMMEANS_OPTIONS SCALE=ORIGINAL PADJUST=LSD.
>>>
>>> best
>>> Diana
>>>
>>>
>>> _____________________________________
>>> Professor Diana Kornbrot
>>> Mobile
>>> +44 (0) 7403 18 16 12
>>> Work
>>> University of Hertfordshire
>>> College Lane, Hatfield, Hertfordshire AL10 9AB, UK
>>> +44 (0) 170 728 4626
>>> d.e.kornbrot at herts.ac.uk<mailto:d.e.kornbrot at herts.ac.uk>
>>> http://dianakornbrot.wordpress.com/
>>> http://go.herts.ac.uk/Diana_Kornbrot
>>> skype:  kornbrotme
>>> Home
>>> 19 Elmhurst Avenue
>>> London N2 0LT, UK
>>> +44 (0) 208 444 2081
>>>  ------------------------------------------------------------
>>>
>>>
>>>
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From pierre.de.villemereuil at mailoo.org  Tue Feb 27 14:06:20 2018
From: pierre.de.villemereuil at mailoo.org (Pierre de Villemereuil)
Date: Tue, 27 Feb 2018 14:06:20 +0100
Subject: [R-sig-ME] Including random effects creates structure in the
 residuals
In-Reply-To: <64A7142C-55FA-43E8-B457-8C80D8AA1DE4@glasgow.ac.uk>
References: <3327781.mmodNga8li@flyosflip>
 <64A7142C-55FA-43E8-B457-8C80D8AA1DE4@glasgow.ac.uk>
Message-ID: <1554686.l50GCRrqCa@flyosflip>

Hi Paul,

Thank you for your response and interest in my question. While I agree that regression to the mean does exist in these settings, I don't get why this should yield such a correlation between the BLUPs and the residuals (after all, assuming the two are totally independent, you'd still get the same phenomenon you're describing, wouldn't you?). Could you explain why this should be the case? Maybe I'm missing a big point in your explanation, if so, please forgive me.

It got me thinking however, that the correlation between the BLUPs and the residuals could arise from a fundamental constraint in the data as you suggested and I think I now understand what is going on (again, if this is what you suggested, please forgive me as I might have misunderstood your point). A short summary is that it arises from an unbalanced design in the repeated measures (as some individuals do not come back to complete the study).

This can be seen in the following graph, which shows the residuals (e) against the BLUPs (u, which also contains the effect of "visit", but it doesn't impact much the trend here), depending on whether we have 1, 2, 3 or 4 repeated measures for that individual:
https://ibb.co/dDgF3H

It should be expected that there is a perfect linear covariation for only 1 visit, because the BLUP and the residual are basically non identifiable, while this constraint is fading as more repeated measures are added to the data. Does this interpretation makes sense to you?

Thank you for your help! Also the bit about checking residuals in GLMMs, very much interesting, I'll think about DARHMa next time I'll have to do this for a GLMM!

Cheers,
Pierre

Le mardi 27 f?vrier 2018, 12:03:17 CET Paul Johnson a ?crit :
> Hi Pierre,
> 
> I don?t think there is a problem with the residuals. Just to check, the problem you see is that there?s a linear trend in the residuals vs fitted values plot when the ID random effect is included (which in a standard OLS LM would be impossible).
> 
> The reason for the correlation is that the fitted values contain the ID random effects, and these are inevitably correlated with the residuals. My intuitive understanding of this is as follows. Say some students sit a test twice, on two separate days. A student's score on a given day will be a combination of their ability (ID random effect) and unmeasured (i.e. noise) factors, like how the student was feeling on that day. Assuming that both ability and luck contribute substantially to the scores, it?s inevitable that the extreme upper end of the distribution will be populated by scores from students who are both able (high ID random effect) and were lucky on that day (high error residual). The same goes in the negative direction for the lower end of the distribution. This the basis of is regression to the mean - if we pick a student with an extreme score and re-test them, we expect their score to be less extreme. If I remember correctly it?s fairly straightforward to predict the correlation of the residuals and fitted values for a given model.
> 
> On the broader topic of checking residuals from GLMMs? 
> I wrote a simple function to check residuals from lme4 fits by simulating residuals from the fitted model and plotting them on top of the real residuals. If they look similar on several simulated data sets them I?m reassured that the model fits well. This is particularly useful for non-normal GLMMs where (despite popular belief) there's no assumption of normality of the Pearson residuals.
> 
> library(devtools)
> install_github("pcdjohnson/GLMMmisc") 
> library(GLMMmisc)
> library(lme4)
> fm1 <- lmer(Reaction ~ Days + (Days | Subject), sleepstudy)
> sim.residplot(fm1)
> # note the correlation between the residuals and the fitted values
> 
> Florian Hartig has written a more sophisticated package that uses the same basic idea called DHARMa:
> https://cran.r-project.org/web/packages/DHARMa/index.html
> His blog post:
> https://theoreticalecology.wordpress.com/2016/08/28/dharma-an-r-package-for-residual-diagnostics-of-glmms/
> 
> All the best,
> Paul
> 
> 
> > On 27 Feb 2018, at 08:53, Pierre de Villemereuil <pierre.de.villemereuil at mailoo.org> wrote:
> > 
> > Dear all,
> > 
> > I have an issue that I can't get my head around. I am working on a human cohort dataset studying heart rate. We have repeated measures at several time points and a model with different slopes according to binned age categories (the variable called "broken" hereafter, for "broken lines").
> > 
> > My issue is that when I include an individual ID effect (to account for the repeated measures), I obtain structured residuals while this is not the case for a model without this effect.
> > 
> > Here are my models:
> > mod_withID <- lmer(cardfreq ~ sex + 
> > 								broken + 
> > 								age:broken + 
> > 								betabloq + 
> > 								cafethe + 
> > 								tabac + 
> > 								alcool +
> > 								(1|visite) +
> > 								(1|id),
> > 				   data = sub)
> > mod_noID <- lmer(cardfreq ~ sex + 
> > 								broken + 
> > 								age:broken + 
> > 								betabloq + 
> > 								cafethe + 
> > 								tabac + 
> > 								alcool +
> > 								(1|visite),
> > 				  data = sub)
> > 
> > The AIC (computed with a fit with REML = FALSE) clearly favours the model including the ID effect:
> > AIC(mod_withID)
> > 75184.51
> > AIC(mod_noID)
> > 76942.09
> > 
> > Yet, the model including the ID effect suffers from a bad fit from the residuals point of view (structured residuals) as the plots below show:
> > - The residuals with the ID effect:
> > https://ibb.co/b6WsFx
> > - The residuals without the ID effect:
> > https://ibb.co/fFVDNc
> > 
> > From this, I gather that the fixed effect part is good enough to provide a good fit, but there is a covariance from the residuals and the BLUPs from the ID effect (I've checked this). Especially, if we marginalise on the random effects to compute the residuals, then everything is fine, suggesting the issue lies in the random rather than the fixed part.
> > 
> > I'm a bit puzzled by this. Why would adding an individual effect would create such a structure in the residual part? Why does this covariance between the individual BLUPs and the residual arise?
> > 
> > I'd happily take anyone's input on this as I'm at a loss regarding what to do to solve this.
> > 
> > Cheers,
> > Pierre
> > 
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 

From dakotajudo at mac.com  Tue Feb 27 15:40:27 2018
From: dakotajudo at mac.com (Peter Claussen)
Date: Tue, 27 Feb 2018 08:40:27 -0600
Subject: [R-sig-ME] Including random effects creates structure in the
 residuals
In-Reply-To: <3327781.mmodNga8li@flyosflip>
References: <3327781.mmodNga8li@flyosflip>
Message-ID: <5B7F35B9-B35D-4A44-8CD6-624097836E9C@mac.com>

PIerre,

I?m going to disagree that the residuals from the without id effect do not suffer from a bad fit.

There appear to be a series of bands in https://ibb.co/fFVDNc <https://ibb.co/fFVDNc> , on the left half of the graph. If you were to change the scale (say, focusing on the region at about 59, you might see these bands have a bias as well. My suspicion is that the location of each band represents the location of individual intercept, (1|id). 

You might remove the bias by including an individual random slope, i.e (age | id). The data might also be autocorrelated.

Cheers,
Peter


> On Feb 27, 2018, at 2:53 AM, Pierre de Villemereuil <pierre.de.villemereuil at mailoo.org> wrote:
> 
> Dear all,
> 
> I have an issue that I can't get my head around. I am working on a human cohort dataset studying heart rate. We have repeated measures at several time points and a model with different slopes according to binned age categories (the variable called "broken" hereafter, for "broken lines").
> 
> My issue is that when I include an individual ID effect (to account for the repeated measures), I obtain structured residuals while this is not the case for a model without this effect.
> 
> Here are my models:
> mod_withID <- lmer(cardfreq ~ sex + 
> 								broken + 
> 								age:broken + 
> 								betabloq + 
> 								cafethe + 
> 								tabac + 
> 								alcool +
> 								(1|visite) +
> 								(1|id),
> 				   data = sub)
> mod_noID <- lmer(cardfreq ~ sex + 
> 								broken + 
> 								age:broken + 
> 								betabloq + 
> 								cafethe + 
> 								tabac + 
> 								alcool +
> 								(1|visite),
> 				  data = sub)
> 
> The AIC (computed with a fit with REML = FALSE) clearly favours the model including the ID effect:
> AIC(mod_withID)
> 75184.51
> AIC(mod_noID)
> 76942.09
> 
> Yet, the model including the ID effect suffers from a bad fit from the residuals point of view (structured residuals) as the plots below show:
> - The residuals with the ID effect:
> https://ibb.co/b6WsFx
> - The residuals without the ID effect:
> https://ibb.co/fFVDNc
> 
> From this, I gather that the fixed effect part is good enough to provide a good fit, but there is a covariance from the residuals and the BLUPs from the ID effect (I've checked this). Especially, if we marginalise on the random effects to compute the residuals, then everything is fine, suggesting the issue lies in the random rather than the fixed part.
> 
> I'm a bit puzzled by this. Why would adding an individual effect would create such a structure in the residual part? Why does this covariance between the individual BLUPs and the residual arise?
> 
> I'd happily take anyone's input on this as I'm at a loss regarding what to do to solve this.
> 
> Cheers,
> Pierre
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


	[[alternative HTML version deleted]]


From rune.haubo at gmail.com  Tue Feb 27 15:53:42 2018
From: rune.haubo at gmail.com (Rune Haubo)
Date: Tue, 27 Feb 2018 15:53:42 +0100
Subject: [R-sig-ME] means , CIs from lmer, glmer
In-Reply-To: <B655BF85-EF71-4375-AC88-D545DA3387D5@herts.ac.uk>
References: <62C83545-F497-4BAF-9599-8764F48E13C6@herts.ac.uk>
 <CABghstTnvHcvQab_dH9j_BcfxvnbEREuHOkZaen9m_TmRLSovw@mail.gmail.com>
 <CAG_uk93LXzvp2ORp85-VYkYAm+JHrPOs45qDHtLxn9ozatPJjg@mail.gmail.com>
 <DDD5B06D-6808-478A-9475-FA79F2AFFF72@herts.ac.uk>
 <CAG_uk922R=RqGwYhEo3yTa76dbcv4sQ9B5f96Ruj3pR5wPSJdg@mail.gmail.com>
 <B655BF85-EF71-4375-AC88-D545DA3387D5@herts.ac.uk>
Message-ID: <CAG_uk92G+aQZ6mab+rd2zwD+h7Kymkv=gVPXFW23VkeaWTgHcQ@mail.gmail.com>

On 27 February 2018 at 15:27, Kornbrot, Diana <d.e.kornbrot at herts.ac.uk>
wrote:

> Thanks
> Am also replying to list, so excuse duplication
> used install packages followed by library
> though that was happening on 1st attempt - but sadly no
>
>
> On 27 Feb 2018, at 12:53, Rune Haubo <rune.haubo at gmail.com> wrote:
>
> Well, you could also just do a linear mixed model on the
> logit-transformed proportions, which would make the Satterthwaite
> F-tests via lmerTest available to you. This can be OK if all the
> proportions have (approximately) the same denominator but
>
>
>
> usually
>
> *ALWAYS*
>
No, not always, but usually. In 'regular' cases (designed experiment with
the same denominator) the anova F-test is superior to the asymptotic
chi-square tests in the 'right' model.

> is better to fit the 'correct' binomial mixed model with glmer - even
> when all the proportions have the same denominator. Using glmer leaves
> you with likelihood ratio tests which are matched against the
> chi-square distribution - use anova(model2, model1) to obtain these
> likelihood ratio tests.
>
> It would be helpful if glmer did not [rpobably incorrectly] label
> chi-square tests as ?F?
>

I don't think it does:

library(lme4)
gm1 <- glmer(cbind(incidence, size - incidence) ~ period + (1 | herd),
             cbpp, binomial)
anova(gm1, gm2 <- update(gm1a, ~.-period))

Data: cbpp
Models:
gm2 <- update(gm1a, ~. - period): cbind(incidence, size - incidence) ~ (1 |
herd)
gm1: cbind(incidence, size - incidence) ~ period + (1 | herd)
                                 Df    AIC    BIC   logLik deviance Chisq
Chi Df
gm2 <- update(gm1a, ~. - period)  2 213.66 217.71 -104.832   209.66

gm1                               5 194.05 204.18  -92.027   184.05 25.61
    3
                                 Pr(>Chisq)
gm2 <- update(gm1a, ~. - period)
gm1                               1.151e-05 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

[actually, and to my surprise, anova(gm1) prints something that looks like
an anova table with a column labeled 'F', but I don't know what that means
(if it has a meaning). Wiser heads than mine will have to chip in here...]


> But this is a generalised linear model and was hoping get a mean and sd
> for the random subject (Participant) effect
>

Just printing the object (e.g. gm1) does give you the standard deviations
for the random effects. The mean is zero per definition, but I suspect that
this is not what you are really asking for?


> Also really do want an F comparing the predictor effects with appropriate
> error effects
>

I personally think that is an odd thing to ask for and I have no clue how
it is reasonably defined. I suspect you may have to use SPSS. I don't
really know what SPSS is doing but if it is doing a PQL-kind of thing that
would explain why you are led in the direction of F-tests (but note that
PQL is much inferior to the Laplace and AGQ methods in glmer).

Best
Rune



> It seems the in spite of R supposedly being more sophisticated than
> standard packages like SPSS, it has fewer options on the crucial issue of
> specifying error variance
>
>
>
> And by the way: you probably want to install the emmeans package via
> 'install.packages("emmeans")' in R - not via gitHub using devtools.
> See https://github.com/runehaubo/lmerTest under 'Installation' for the
> advice we give on installing lmerTest. Short version is to install
> using install.packages() before thinking about installing from github.
>
> good advice
>
> results form SPSS and R are very different
> R glmer   MIXED
> Rab Between emmean SE df asymp.LCL asymp.UCL Rab Between Mean SE lcl ucl
> 1 1 -.316 .170 Inf -.650 .018 1 1 -.267 .148 -.562 .027
> 2 1 -.820 .172 Inf -1.158 -.482 2 1 -.688 .169 -1.023 -.352
> 3 1 -1.838 .183 Inf -2.196 -1.480 3 1 -1.550 .188 -1.924 -1.176
> 4 1 -2.558 .198 Inf -2.946 -2.170 4 1 -2.168 .230 -2.624 -1.712
> 1 2 .357 .165 Inf .034 .681 1 2 .297 .144 .011 .583
> 2 2 -.895 .167 Inf -1.223 -.567 2 2 -.745 .165 -1.073 -.417
> 3 2 -2.607 .192 Inf -2.984 -2.230 3 2 -2.238 .235 -2.705 -1.772
> 4 2 -2.891 .201 Inf -3.285 -2.497 4 2 -2.498 .255 -3.005 -1.992
>   Df SS MS F Source F df1 df2 Sig.
> Rab 3 870.17 290.06 290.06 Rab 66.76 3 94 .000000
> Between 1 .12 .12 .12 Between .38 1 93 .539643
> Rab:Between 3 63.20 21.07 21.07 Rab*Between 5.31 3 94 .001998
> Corrected 30.64 7 101 .000000
>
>
> best
> Diana
>
>
> Best regards,
>
> Rune Haubo B. Christensen, PhD, MSc.
> Director, Owner
>
> Christensen Statistics
> Bringetoften 7
> <https://maps.google.com/?q=Bringetoften+7&entry=gmail&source=g>
> 3500 V?rl?se - Denmark
> +45 3026 4554 <+45%2030%2026%2045%2054>
> Rune at ChristensenStatistics.dk
> www.ChristensenStatistics.dk
>
>
> On 27 February 2018 at 12:32, Kornbrot, Diana <d.e.kornbrot at herts.ac.uk>
> wrote:
>
> thanks
>
> do you have any suggestions for glmer?
> SPSS seems happy to do Sattherwaite, which seems to be  alogical approach
> for any model that is effectively doing a multivariate ANOVA on the logit
> transformed proportion
> best
> Diana
>
> On 27 Feb 2018, at 10:22, Rune Haubo <rune.haubo at gmail.com> wrote:
>
> Just a small note that lmerTest (and the Satterthwaite method for
> degrees of freedom) is only meaningful for _linear_ mixed models - not
> for the generalized variants such as the one considered here for
> proportions.
>
> Best,
> Rune
>
> On 27 February 2018 at 02:02, Ben Bolker <bbolker at gmail.com> wrote:
>
> Hi Diana,
>
> A reproducible example is always helpful/increases your chances of
> getting a useful answer ...
> It might help if you included the SPSS output (or posted it somewhere
> -- note that this list doesn't take HTML-formatted messages nor most
> attachments), as many of us don't have access to it.
>
> Look into the (very well-documented) emmeans package:
> https://CRAN.R-project.org/package=emmeans
> and the lmerTest package (for Satterthwaite df approximations)
>
> On Mon, Feb 26, 2018 at 12:11 PM, Kornbrot, Diana
> <d.e.kornbrot at herts.ac.uk> wrote:
>
> I am keen to promote the use of generalised mixed models for the analysis
> of
> proportions to psychologists
> Have straight fowl code in SPSS [costly] and would like to supply
> equivalent
> R Code without ?tears?
> Design is a follows raw frequencies are: FreqPos for ?success? and FreqNeg
> for ?failure?
> Predictors are Rab with 4 levels, repeated over participants and Between
> with 2 separate groups of participants
> Model is binomial with logit link
>
> Require following output to correspond to SPSS output from code below
> Descriptive: Means, se and 95% CIs  by Rab, by Between and by Rab*Between
> Inferential: fo  Rab, Between and  Rab*Between: F value, MSE, numerator df,
> denominator df [this enables p-values]
>
> Have tried
>
> logit1 <- glmer(cbind(FreqPos,FreqNeg) ~ Rab + Between + Rab*Between + (1|
> Participant), family=binomial(link="logit"))
> gives F and MSE no denominator df or MSE. Different results to SPSS
> nb F=MSE - that can?t be right F is supposed to be ratio of chi-squares
>
> summary (logit1)
> gives coefficients  and SEs. Different results to SPSS
> also tried predicted and fitted but still no means
>
> have spent days searching internet for examples - but none of them seem to
> show how to get the output I need
>
> All help greatly appreciated
>
> ____
> Spss syntax
>
> *Generalized Linear Mixed Models.
> GENLINMIXED
> /DATA_STRUCTURE SUBJECTS=Participant REPEATED_MEASURES=Rab
> COVARIANCE_TYPE=UNSTRUCTURED
> /FIELDS TARGET=FreqPos TRIALS=FIELD(Nmax)  OFFSET=NONE
> /TARGET_OPTIONS DISTRIBUTION=BINOMIAL LINK=LOGIT
> /FIXED  EFFECTS=Rab Between Rab*Between USE_INTERCEPT=TRUE
> /BUILD_OPTIONS TARGET_CATEGORY_ORDER=DESCENDING
> INPUTS_CATEGORY_ORDER=DESCENDING MAX_ITERATIONS=100 CONFIDENCE_LEVEL=95
> DF_METHOD=SATTERTHWAITE COVB=MODEL PCONVERGE=0.000001(ABSOLUTE) SCORING=0
> SINGULAR=0.000000000001
> /EMMEANS TABLES=Rab COMPARE=Rab CONTRAST=DEVIATION
>  /EMMEANS TABLES=Between CONTRAST=NONE
>  /EMMEANS TABLES=Rab*Between CONTRAST=NONE
> /EMMEANS_OPTIONS SCALE=ORIGINAL PADJUST=LSD.
>
> best
> Diana
>
>
> _____________________________________
> Professor Diana Kornbrot
> Mobile
> +44 (0) 7403 18 16 12
> Work
> University of Hertfordshire
> College Lane, Hatfield, Hertfordshire AL10 9AB, UK
> +44 (0) 170 728 4626 <+44%201707%20284626>
> d.e.kornbrot at herts.ac.uk<mailto:d.e.kornbrot at herts.ac.uk>
> http://dianakornbrot.wordpress.com/
> http://go.herts.ac.uk/Diana_Kornbrot
> skype:  kornbrotme
> Home
> 19 Elmhurst Avenue
> <https://maps.google.com/?q=19+Elmhurst+Avenue+%0D%0ALondon+N2&entry=gmail&source=g>
> London N2 0LT, UK
> +44 (0) 208 444 2081 <+44%2020%208444%202081>
> ------------------------------------------------------------
>
>
>
>
>       [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
> _____________________________________
> Professor Diana Kornbrot
> Mobile
> +44 (0) 7403 18 16 12
> Work
> University of Hertfordshire
> College Lane, Hatfield, Hertfordshire AL10 9AB, UK
> +44 (0) 170 728 4626 <+44%201707%20284626>
> d.e.kornbrot at herts.ac.uk
> http://dianakornbrot.wordpress.com/
> http://go.herts.ac.uk/Diana_Kornbrot
> skype:  kornbrotme
> Home
> 19 Elmhurst Avenue
> <https://maps.google.com/?q=19+Elmhurst+Avenue+%0D%0ALondon+N2&entry=gmail&source=g>
> London N2 0LT, UK
> +44 (0) 208 444 2081 <+44%2020%208444%202081>
> ------------------------------------------------------------
>
>
>
>
> _____________________________________
> Professor Diana Kornbrot
> *Mobile*
> +44 (0) 7403 18 16 12
> *Work*
> University of Hertfordshire
> College Lane, Hatfield, Hertfordshire AL10 9AB, UK
> +44 (0) 170 728 4626 <+44%201707%20284626>
> d.e.kornbrot at herts.ac.uk
> http://dianakornbrot.wordpress.com/
> http://go.herts.ac.uk/Diana_Kornbrot
> skype:  kornbrotme
> *Home*
> 19 Elmhurst Avenue
> <https://maps.google.com/?q=19+Elmhurst+Avenue+%0D%0ALondon+N2&entry=gmail&source=g>
> London N2 0LT, UK
> +44 (0) 208 444 2081 <+44%2020%208444%202081>
>
>  ------------------------------------------------------------
>
>
>
>
>

	[[alternative HTML version deleted]]


From pierre.de.villemereuil at mailoo.org  Tue Feb 27 17:00:34 2018
From: pierre.de.villemereuil at mailoo.org (Pierre de Villemereuil)
Date: Tue, 27 Feb 2018 17:00:34 +0100
Subject: [R-sig-ME] Including random effects creates structure in the
 residuals
In-Reply-To: <5B7F35B9-B35D-4A44-8CD6-624097836E9C@mac.com>
References: <3327781.mmodNga8li@flyosflip>
 <5B7F35B9-B35D-4A44-8CD6-624097836E9C@mac.com>
Message-ID: <3146867.hakbc9lQJt@ev8sa6>

Hi Peter,

That series of bands is most likely due to the discrete nature of all of the predictors (only "age" is quantitative here, but even then, it is a "count" predictor). This results in a "structure" in the fitted values, but as far as can tell, not in the residual values for this model without the ID effect.

Anyhow, there are not enough individual replicates (up to 4) to explain these bands with the individual effect alone.

Cheers,
Pierre

Le mardi 27 f?vrier 2018, 15:40:27 CET Peter Claussen a ?crit :
> PIerre,
> 
> I?m going to disagree that the residuals from the without id effect do not suffer from a bad fit.
> 
> There appear to be a series of bands in https://ibb.co/fFVDNc <https://ibb.co/fFVDNc> , on the left half of the graph. If you were to change the scale (say, focusing on the region at about 59, you might see these bands have a bias as well. My suspicion is that the location of each band represents the location of individual intercept, (1|id). 
> 
> You might remove the bias by including an individual random slope, i.e (age | id). The data might also be autocorrelated.
> 
> Cheers,
> Peter
> 
> 
> > On Feb 27, 2018, at 2:53 AM, Pierre de Villemereuil <pierre.de.villemereuil at mailoo.org> wrote:
> > 
> > Dear all,
> > 
> > I have an issue that I can't get my head around. I am working on a human cohort dataset studying heart rate. We have repeated measures at several time points and a model with different slopes according to binned age categories (the variable called "broken" hereafter, for "broken lines").
> > 
> > My issue is that when I include an individual ID effect (to account for the repeated measures), I obtain structured residuals while this is not the case for a model without this effect.
> > 
> > Here are my models:
> > mod_withID <- lmer(cardfreq ~ sex + 
> > 								broken + 
> > 								age:broken + 
> > 								betabloq + 
> > 								cafethe + 
> > 								tabac + 
> > 								alcool +
> > 								(1|visite) +
> > 								(1|id),
> > 				   data = sub)
> > mod_noID <- lmer(cardfreq ~ sex + 
> > 								broken + 
> > 								age:broken + 
> > 								betabloq + 
> > 								cafethe + 
> > 								tabac + 
> > 								alcool +
> > 								(1|visite),
> > 				  data = sub)
> > 
> > The AIC (computed with a fit with REML = FALSE) clearly favours the model including the ID effect:
> > AIC(mod_withID)
> > 75184.51
> > AIC(mod_noID)
> > 76942.09
> > 
> > Yet, the model including the ID effect suffers from a bad fit from the residuals point of view (structured residuals) as the plots below show:
> > - The residuals with the ID effect:
> > https://ibb.co/b6WsFx
> > - The residuals without the ID effect:
> > https://ibb.co/fFVDNc
> > 
> > From this, I gather that the fixed effect part is good enough to provide a good fit, but there is a covariance from the residuals and the BLUPs from the ID effect (I've checked this). Especially, if we marginalise on the random effects to compute the residuals, then everything is fine, suggesting the issue lies in the random rather than the fixed part.
> > 
> > I'm a bit puzzled by this. Why would adding an individual effect would create such a structure in the residual part? Why does this covariance between the individual BLUPs and the residual arise?
> > 
> > I'd happily take anyone's input on this as I'm at a loss regarding what to do to solve this.
> > 
> > Cheers,
> > Pierre
> > 
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 


From b.pelzer at maw.ru.nl  Wed Feb 28 11:03:28 2018
From: b.pelzer at maw.ru.nl (Ben Pelzer)
Date: Wed, 28 Feb 2018 11:03:28 +0100
Subject: [R-sig-ME] 
 Longitudinal logistic regression with continuous-time
 first-order autocorrelation structure
In-Reply-To: <CAFvg1=vdVbz28pw9B6GrOXNsnceXK3UgXksMDwJUOQ9PYoLK_g@mail.gmail.com>
References: <CAFvg1=vdVbz28pw9B6GrOXNsnceXK3UgXksMDwJUOQ9PYoLK_g@mail.gmail.com>
Message-ID: <5A967E70.7010609@maw.ru.nl>

Hi Dennis,

Another way to go would be to include a random intercept and a random 
time effect (both over persons) in the logit, much like is done in 
linear models. This creates correlation between logit values across 
successive time-points. This is e.g. explained in Snijders and Bosker's 
book  and in Singer and Willett. You can make the model increasingly 
more flexible (in terms of the correlation structure over time) by not 
only including a linear random time effect but also a quadratic, cubic 
etc. time-effect. This is a different approach than letting the error 
terms "e" correlate over time. But it serves the same end: correlation 
over time.

I think there's nothing wrong with this "multilevel growth model" 
approach for a glm, but anyone please correct me if  I'm wrong. Anyway, 
it can be carried with most multilevel or random effects software 
packages, like glmer in R.

Best regards, Ben.


On 27/02/2018 07:22, Dennis Ruenger wrote:
> Dear All.
>
> I need to analyze an intensive longitudinal data set with a binary outcome
> variable. In the ?Ecological Momentary Assessment? (EMA) study,
> participants received five random prompts per day for six weeks, asking
> them (among other things) whether they were craving a particular drug
> (yes/no). At the most basic level, I want to know whether the likelihood of
> craving the drug changed across time.
>
> Given the variable time intervals of measurement and many missing data
> points, a continuous-time first-order autocorrelation model seems
> necessary.
>
> I found tutorials on how to allow for continuous-time autocorrelation and
> missing data in an LMM, using nlme::lme and corCAR1, but I am at a loss as
> to what to do in a GLMM.
>
> I would be thankful for any suggestions on how to analyze this kind of data
> in R.
>
> Dennis
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From b.pelzer at maw.ru.nl  Wed Feb 28 11:09:12 2018
From: b.pelzer at maw.ru.nl (Ben Pelzer)
Date: Wed, 28 Feb 2018 11:09:12 +0100
Subject: [R-sig-ME] 
 Longitudinal logistic regression with continuous-time
 first-order autocorrelation structure
In-Reply-To: <5A967E70.7010609@maw.ru.nl>
References: <CAFvg1=vdVbz28pw9B6GrOXNsnceXK3UgXksMDwJUOQ9PYoLK_g@mail.gmail.com>
 <5A967E70.7010609@maw.ru.nl>
Message-ID: <5A967FC8.8040700@maw.ru.nl>

To be correct: Snijders and Bosker and Willett and Singer explain this 
multilevel growth model for linear models only, but my hunch is that it 
can be used for logistic models as well.

On 28/02/2018 11:03, Ben Pelzer wrote:
> Hi Dennis,
>
> Another way to go would be to include a random intercept and a random 
> time effect (both over persons) in the logit, much like is done in 
> linear models. This creates correlation between logit values across 
> successive time-points. This is e.g. explained in Snijders and 
> Bosker's book  and in Singer and Willett. You can make the model 
> increasingly more flexible (in terms of the correlation structure over 
> time) by not only including a linear random time effect but also a 
> quadratic, cubic etc. time-effect. This is a different approach than 
> letting the error terms "e" correlate over time. But it serves the 
> same end: correlation over time.
>
> I think there's nothing wrong with this "multilevel growth model" 
> approach for a glm, but anyone please correct me if  I'm wrong. 
> Anyway, it can be carried with most multilevel or random effects 
> software packages, like glmer in R.
>
> Best regards, Ben.
>
>
> On 27/02/2018 07:22, Dennis Ruenger wrote:
>> Dear All.
>>
>> I need to analyze an intensive longitudinal data set with a binary 
>> outcome
>> variable. In the ?Ecological Momentary Assessment? (EMA) study,
>> participants received five random prompts per day for six weeks, asking
>> them (among other things) whether they were craving a particular drug
>> (yes/no). At the most basic level, I want to know whether the 
>> likelihood of
>> craving the drug changed across time.
>>
>> Given the variable time intervals of measurement and many missing data
>> points, a continuous-time first-order autocorrelation model seems
>> necessary.
>>
>> I found tutorials on how to allow for continuous-time autocorrelation 
>> and
>> missing data in an LMM, using nlme::lme and corCAR1, but I am at a 
>> loss as
>> to what to do in a GLMM.
>>
>> I would be thankful for any suggestions on how to analyze this kind 
>> of data
>> in R.
>>
>> Dennis
>>
>>     [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From dennis.ruenger at gmail.com  Thu Mar  1 02:44:45 2018
From: dennis.ruenger at gmail.com (Dennis Ruenger)
Date: Wed, 28 Feb 2018 17:44:45 -0800
Subject: [R-sig-ME] 
 Longitudinal logistic regression with continuous-time
 first-order autocorrelation structure
Message-ID: <CAFvg1=tD0t0eH-ZpWc+qOVJ49RHZLHephSkjtGFYuWtTgVynjg@mail.gmail.com>

Thanks, Alain and Ben, for your replies.

My understanding is that for the kind of intensive longitudinal data I'm
dealing with, a mixed model with both random intercepts and slopes for the
time effect *and *autoregressive errors are recommended.

I'd like to follow Alain's suggestion and give glmmTMB a try. Based on a
description of the covariance structures available with glmmTMB (link
below), it looks like the Ornstein?Uhlenbeck covariance structure might be
what I'm looking for (i.e., something akin to corrCAR1() that works in a
GLMM).

So I tried:

df$time_hours <- numFactor(df$time_hours)
fit  <- glmmTMB(y ~ time_hours + (time_hours|id) + ou(time_hours-1|id),
family = binomial, data = df)

However, after about 10 minutes, I receive an error message about failed
memory allocation (on a laptop with a 7th gen Intel Core i5 processor and
8GB RAM). The data set includes 34 participants with up to 300 data points
per participants. Running the model for a subset of 5 participants also
resulted in memory allocation failure. The same was true for the spatial
Gaussian and spatial exponential covariance structures.

Does anyone see a way to make this work with glmmTMB?

Thanks a lot.

https://cran.r-project.org/web/packages/glmmTMB/vignettes/covstruct.html

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Thu Mar  1 13:33:41 2018
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 1 Mar 2018 07:33:41 -0500
Subject: [R-sig-ME] 
 Longitudinal logistic regression with continuous-time
 first-order autocorrelation structure
In-Reply-To: <CAFvg1=tD0t0eH-ZpWc+qOVJ49RHZLHephSkjtGFYuWtTgVynjg@mail.gmail.com>
References: <CAFvg1=tD0t0eH-ZpWc+qOVJ49RHZLHephSkjtGFYuWtTgVynjg@mail.gmail.com>
Message-ID: <CABghstRdYb3AQ0t4oKkGXmhhMEQ4hM8uArh9XyFQsOgB1xZGvg@mail.gmail.com>

Don't use (time_hours|id) ... that will expand to a random effect with
a full, unstructured covariance matrix term.
If you have t distinct times measured, you'll end up with t*(t+1)/2
parameters to estimate.  Try (1|time_hours)
(and probably also include (1|id))

On Wed, Feb 28, 2018 at 8:44 PM, Dennis Ruenger
<dennis.ruenger at gmail.com> wrote:
> Thanks, Alain and Ben, for your replies.
>
> My understanding is that for the kind of intensive longitudinal data I'm
> dealing with, a mixed model with both random intercepts and slopes for the
> time effect *and *autoregressive errors are recommended.
>
> I'd like to follow Alain's suggestion and give glmmTMB a try. Based on a
> description of the covariance structures available with glmmTMB (link
> below), it looks like the Ornstein?Uhlenbeck covariance structure might be
> what I'm looking for (i.e., something akin to corrCAR1() that works in a
> GLMM).
>
> So I tried:
>
> df$time_hours <- numFactor(df$time_hours)
> fit  <- glmmTMB(y ~ time_hours + (time_hours|id) + ou(time_hours-1|id),
> family = binomial, data = df)
>
> However, after about 10 minutes, I receive an error message about failed
> memory allocation (on a laptop with a 7th gen Intel Core i5 processor and
> 8GB RAM). The data set includes 34 participants with up to 300 data points
> per participants. Running the model for a subset of 5 participants also
> resulted in memory allocation failure. The same was true for the spatial
> Gaussian and spatial exponential covariance structures.
>
> Does anyone see a way to make this work with glmmTMB?
>
> Thanks a lot.
>
> https://cran.r-project.org/web/packages/glmmTMB/vignettes/covstruct.html
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From pierces1 at msu.edu  Thu Mar  1 14:45:45 2018
From: pierces1 at msu.edu (Steven J. Pierce)
Date: Thu, 1 Mar 2018 08:45:45 -0500
Subject: [R-sig-ME] 
 Longitudinal logistic regression with continuous-time
 first-order autocorrelation structure
In-Reply-To: <CAFvg1=tD0t0eH-ZpWc+qOVJ49RHZLHephSkjtGFYuWtTgVynjg@mail.gmail.com>
References: <CAFvg1=tD0t0eH-ZpWc+qOVJ49RHZLHephSkjtGFYuWtTgVynjg@mail.gmail.com>
Message-ID: <000201d3b163$9945e650$cbd1b2f0$@msu.edu>

Dennis,

With > 100 observations each person, you effectively have multilevel time series data. You may want to consider using Mplus (www.statmodel.com), which has some interesting features for modeling that via what they call dynamic structural equation models (DSEM). See the description of time series analysis at http://www.statmodel.com/verhistory.shtml and http://www.statmodel.com/TimeSeries.shtml . That last link also has citations for published DSEM papers, example scripts, plus videos and handouts from DSEM workshops and webinars. 

I think Mplus would give you the kind of sophisticated modeling options you need. It's not open-source, nor is it cheap software, but it has a very good reputation. I prefer R for most of my work (for lots of reasons), but what you're describing is an analysis where I would strongly consider using Mplus instead. It may well be that you can do the same things in R (with the right packages) but I suspect even then reading about the DSEM modeling framework could provide you with useful methodology ideas that are software independent. 

Disclaimer: I have no personal or financial stake whatsoever in the company that produces Mplus. I simply use that software for some of my own work.

Steven J. Pierce, PhD
Acting Director; Associate Director
Center for Statistical Training and Consulting 
Michigan State University
E-mail: pierces1 at msu.edu


-----Original Message-----
From: Dennis Ruenger [mailto:dennis.ruenger at gmail.com] 
Sent: Wednesday, February 28, 2018 8:45 PM
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Longitudinal logistic regression with continuous-time first-order autocorrelation structure

Thanks, Alain and Ben, for your replies.

My understanding is that for the kind of intensive longitudinal data I'm
dealing with, a mixed model with both random intercepts and slopes for the
time effect *and *autoregressive errors are recommended.

I'd like to follow Alain's suggestion and give glmmTMB a try. Based on a
description of the covariance structures available with glmmTMB (link
below), it looks like the Ornstein?Uhlenbeck covariance structure might be
what I'm looking for (i.e., something akin to corrCAR1() that works in a
GLMM).

So I tried:

df$time_hours <- numFactor(df$time_hours)
fit  <- glmmTMB(y ~ time_hours + (time_hours|id) + ou(time_hours-1|id),
family = binomial, data = df)

However, after about 10 minutes, I receive an error message about failed
memory allocation (on a laptop with a 7th gen Intel Core i5 processor and
8GB RAM). The data set includes 34 participants with up to 300 data points
per participants. Running the model for a subset of 5 participants also
resulted in memory allocation failure. The same was true for the spatial
Gaussian and spatial exponential covariance structures.

Does anyone see a way to make this work with glmmTMB?

Thanks a lot.

https://urldefense.proofpoint.com/v2/url?u=https-3A__cran.r-2Dproject.org_web_packages_glmmTMB_vignettes_covstruct.html&d=DwIFaQ&c=nE__W8dFE-shTxStwXtp0A&r=91SB6keVyEb7FtX7ZipxyQ&m=H751To_EJCmL5vo1euwDP8anr3fVV-MwcOxrn0pkOXk&s=XOAUd95vXnhgafGubFX6iz08DXWZS07rmk_f_IfhDo8&e=

	[[alternative HTML version deleted]]


From walidmawass10 at gmail.com  Thu Mar  1 17:04:58 2018
From: walidmawass10 at gmail.com (Walid Mawass)
Date: Thu, 1 Mar 2018 11:04:58 -0500
Subject: [R-sig-ME] QGglmm multivariate with fixed effects
Message-ID: <b1ed0d31-4b87-f8fc-5662-8c86b897d233@gmail.com>

Hello everyone,

I am working with the QGglmm package by Pierre de Villemereuil to 
calculate heritability and additive variance on the observable scale 
since my response variable is binomial and I am using MCMCglmm. I read 
his 'How to' pdf but it does not precisely say if the output represents 
the posterior mode or the mean for each parameter. Is it possible to 
compute the mode of the additive genetic variance and heritability 
instead of the mean if that is the case.

In addition, in his tutorial, he explains how to calculate the 
parameters if there are fixed effects in the model by using predict 
instead of calculating the mean of the trait. However that is only in 
the case of a univariate model, I was not successful in applying it for 
a multivariate model with fixed effects. I would appreciate it if I 
could get some help on how to proceed in this case.

Thank you

-- 
Walid Mawass

Ph.D. candidate in Cellular and Molecular Biology

Population Genetics Laboratory

University of Qu?bec at Trois-Rivi?res
3351, boul. des Forges, C.P. 500
Trois-Rivi?res (Qu?bec) G9A 5H7
Telephone: 819-376-5011 poste 3384


From pierre.de.villemereuil at mailoo.org  Thu Mar  1 17:34:33 2018
From: pierre.de.villemereuil at mailoo.org (Pierre de Villemereuil)
Date: Thu, 01 Mar 2018 17:34:33 +0100
Subject: [R-sig-ME] QGglmm multivariate with fixed effects
In-Reply-To: <b1ed0d31-4b87-f8fc-5662-8c86b897d233@gmail.com>
References: <b1ed0d31-4b87-f8fc-5662-8c86b897d233@gmail.com>
Message-ID: <2288001.CfNl7dgN9Q@flyosflip>

Hi Walid,

QGparams yields the point estimates corresponding to the point estimates it was given as input. But if you work with MCMCglmm, you might want to use to obtain the whole posterior distribution of the parameters on the observed data scale (see section 5.3 of the vignette "How To"), then take the point estimate you want to use (mode, mean, median, your choice). If your binomial model uses a logit link, it might be a bit slow, as there is no close formula for this model...

Running QGmvparams accounting for fixed effects is similar to the monovariate case, but you need to pass a matrix to "predict" rather than a vector. Quoting the help page of QGmvparams:
predict: Optional matrix of predicted values on the latent scale (each
          trait in each column). The latent predicted values must be
          computed while only accounting for the fixed effects
          (marginal to the random effects). (numeric)

I'd be happy to hear any feedback on how to make the package easier to use and the "How To" easier to understand (maybe outside of the mailing list). I have been thinking about a "wrapper" function to make the process of integrating over the posterior distribution easier but I haven't had the time to implement it.

Cheers,
Pierre

Le jeudi 1 mars 2018, 17:04:58 CET Walid Mawass a ?crit :
> Hello everyone,
> 
> I am working with the QGglmm package by Pierre de Villemereuil to 
> calculate heritability and additive variance on the observable scale 
> since my response variable is binomial and I am using MCMCglmm. I read 
> his 'How to' pdf but it does not precisely say if the output represents 
> the posterior mode or the mean for each parameter. Is it possible to 
> compute the mode of the additive genetic variance and heritability 
> instead of the mean if that is the case.
> 
> In addition, in his tutorial, he explains how to calculate the 
> parameters if there are fixed effects in the model by using predict 
> instead of calculating the mean of the trait. However that is only in 
> the case of a univariate model, I was not successful in applying it for 
> a multivariate model with fixed effects. I would appreciate it if I 
> could get some help on how to proceed in this case.
> 
> Thank you
> 
> -- 
> Walid Mawass
> 
> Ph.D. candidate in Cellular and Molecular Biology
> 
> Population Genetics Laboratory
> 
> University of Qu?bec at Trois-Rivi?res
> 3351, boul. des Forges, C.P. 500
> Trois-Rivi?res (Qu?bec) G9A 5H7
> Telephone: 819-376-5011 poste 3384
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 


From davis.ozols at unifr.ch  Wed Feb 28 11:11:36 2018
From: davis.ozols at unifr.ch (OZOLS Davis)
Date: Wed, 28 Feb 2018 10:11:36 +0000
Subject: [R-sig-ME] Error message in running CLMM models from Ordinal
 package: "optimizer nlminb failed to converge"
In-Reply-To: <CAG_uk93W5wPw66ASy03P3Kruc0zL4y-UfuEBaU2HkAAZXXeT_g@mail.gmail.com>
References: <D6B9C505.C71F%davis.ozols@unifr.ch>
 <CAG_uk93W5wPw66ASy03P3Kruc0zL4y-UfuEBaU2HkAAZXXeT_g@mail.gmail.com>
Message-ID: <D6BC1A1D.C86F%davis.ozols@unifr.ch>

Dear Rune, 

Thank you very much for your thorough answer this is of great help. I
realised that the random effect structure suggested in my models is very
complicated (model fm5 here) and could be the cause of all my problems:


>fm5 <- clmm(value.statement~preexisting.belief*engagement +
>(preexisting.belief*engagement |id) + (engagement |item), data =
>ucl.ordered, Hess = TRUE)


I think my reliance on such structures comes from my lack of fully
understanding the thinking behind random effects. When discussing it in
literature on linear mixed models people like Barr, Levy, Scheepers & Tily
(2013) and to some degree Matuschek, Kliegel, Vasishth, Baayen & Bates
(2017) argue that intercept only models increase the Type 1 error and as
such random slopes should be considered in building linear mixed models to
avoid the error inflation. This was the approach I took with my data. Of
course the authors there talk about linear mixed models while I am using
the CLMM framework and additionally I investigate interactions in my fixed
effects which tend to not be used as examples in mixed models (I assume
due to the complexity?).

My approach to choosing the random effect structure for my models starts
with assuming the maximal complexity of random effects that would make
sense for the design. For this experiment I investigate aspects of
confirmation bias and my hypothesis is that participants behave
differently based on their preexisting.beliefs and engagement with those
beliefs. Therefore I started with the random effect structure of
(preexisting.belief*engagement | id) and (engagement | item), however, I
would have also been happy with the random effect structure of
(preexisting.belief | id). I then compare the fm5 model with the anova()
function to the simplest alternative such as a random intercept model you
suggested in fm1:



fm1 <- clmm( value.statement ~ preexisting.belief * engagement + (1 |id) +
(1 | item), data=ucl.ordered)



This gives me the p-val of <2.2e-16 which I understood as a better fit for
the random slope model. I then move on to suggesting more complex
alternative models such as fm3 and fm4 and do the same comparison. In all
cases fm5 shows better fit: lower AIC, higher -LogLik and a small p-val. I
took this as an indication that in terms of model selection there is
enough evidence to prefer the random effect structure in fm5. Now it could
be the case that do to the complexity of the random structure in fm5 as
well as my fixed effects this might not be the best approach and could
actually provide me with misleading results. Is my approach flawed by
assuming such a complex random effect structure for this design (which in
itself is complex) and following the steps described? Is there a rule of
thumb on how complex one should go with these models?

Finally I am a bit confused about the difference between specifying: (1 |
item:engagement) and (engagement | item) as a random effect. If I assume
that the results of the experiment are affected by how engagement
functions with certain items (e.g. for some items engagement will vary
more and for some less and that will affect the behaviour of items)
wouldn't the (engagement | item) specification be more appropriate?


Once more thank you for your help and sorry for the long questions.
 
Best regards,
Davis

On 27/02/18 10:15, "Rune Haubo" <rune.haubo at gmail.com> wrote:

>It is difficult to say why the bigger model converges while the
>submodels do not. Perhaps the surprising part is why the bigger model
>converges rather than why the simpler ones don't given the rather
>complicated variance structure in the models.
>
>I don't see how the design can demand a variance structure this
>complicated and I would not assume that there is support in the data
>for these complicated structures over simpler alternatives. With
>models as (computationally) complicated as mixed models I think it is
>good advice to start small and build on model structures until
>additional structures are no longer supported by the data. This
>doesn't mean that the inferential process has to run bottom-up as
>well.
>
>In a situation like this I would start with something like
>
>fm1 <- clmm( value.statement ~ preexisting.belief * engagement + (1 |
>id) + (1 | item), data=ucl.ordered)
>
>or even simpler in both fixed and random structures if this gives rise
>to any problems. Focusing on the random structure, I would expand with
>additional _independent_ terms:
>
>fm2 <- clmm( value.statement ~ preexisting.belief * engagement + (1 |
>id) + (1 | item) + (1 | id:engagement) + (1 | item:engagement),
>data=ucl.ordered)
>
>continue to add terms like (1 | id:preexisting.belief) and (1 |
>id:preexisting.belief:engagement) if these terms are necessary or
>should be assessed (and if the model remains identifiable). Unless I
>need random slopes I very rarely move on to
>multivariate/vector-valued/correlated random-effect terms such as
>'(engagement | item)', but some feel that such terms make a lot of
>sense. But if you do want, vector-valued random effects, my suggestion
>is to look at how much support the data offers for such structures (in
>my experience they are usually not supported). For instance you could
>compare (focusing on random structures for item):
>
>fm3 <- clmm( value.statement ~ preexisting.belief * engagement + (1 |
>item) + (1 | item:engagement)  + (1 | id), data=ucl.ordered)
>fm4 <- clmm( value.statement ~ preexisting.belief * engagement +
>(engagement | item)  + (1 | id), data=ucl.ordered)
>
>fm1, fm3 and fm4 represents increasingly more complex random-effect
>structures for item and my advice is to not work with models which are
>more complex than what the data can reasonably support. In practice
>this means that if I fit fm1 and fm3 and run anova(fm3, fm1) and the
>p-value is not small-ish, I stick with fm1. If, instead there is
>support for fm3 over fm1 it can make sense to move on to consider fm4.
>
>Finally, let me digress momentarily on what fm3 and fm4 means:
>Scientifically fm3 represents a random interaction between item and
>engagement which means that random effects for item depend on the
>level of engagement. This is classical design-of-experiments line of
>thinking and a reasonable thing to consider. fm4 represents a
>particular interaction between engagement and item in which the
>_variance_ of the random effects for item (in addition to the
>random-effects for item themselves) depend on the level of engagement,
>but is there are particular scientific reason why the item-level
>_variance_ should depend on engagement?
>
>Hope this helps
>Rune
>
>On 26 February 2018 at 15:07, OZOLS Davis via R-sig-mixed-models
><r-sig-mixed-models at r-project.org> wrote:
>> Dear list,
>>
>> I have a question with regards to model convergence in CLMM function
>>that is implemented in the Ordinal package. More specifically what might
>>cause the error: "optimizer nlminb failed to converge message" in the
>>CLMM function that I am getting.
>>
>> I am new to mixed model analysis so I will try to explain all the steps
>>I have taken in case there might be something wrong in my approach to
>>the analysis.
>>
>> I have data set of 2200 observations with 6 variables: 115
>>participants, 24 items and a design that has as a response variable an
>>ordered scale from 1 to 10.
>>
>>> head(data.ord)
>> id item value.statement quant preexisting.belief engagement
>> 1 R_ysTGuC676siU2Pf   I1               3 Baseline                 low
>>    high
>> 2 R_ysTGuC676siU2Pf   I2               2 Baseline                 low
>>    high
>> 3 R_ysTGuC676siU2Pf   I26               2     Most               low
>>   high
>> 4 R_ysTGuC676siU2Pf   I40               3     Every               low
>>    high
>> 5 R_ysTGuC676siU2Pf   I4               7 Baseline           undecided
>>  high
>> 6 R_ysTGuC676siU2Pf   I10               4 Baseline           undecided
>>   low
>>
>> I investigate the interaction of three factors on the response variable:
>> quant(4 levels)* preexisting.belief(3 levels)* engagement(2 levels)
>>
>>
>> this is the summary of my data:
>>
>>> str(data.ord)
>> 'data.frame': 2200 obs. of  6 variables:
>>  $ id                 : Factor w/ 115 levels
>>  $ item               : Factor w/ 24 levels
>>  $ value.statement   : Ord.factor w/ 10 levels
>>  $ quant              : Factor w/ 4 levels
>>  $ preexisting.belief : Factor w/ 3 levels
>>  $ engagement         : Factor w/ 2 levels
>>
>>
>> I plan to do my analysis by fitting four clmm models with random
>>intercept and random slope structures for both participants and items. I
>>choose the exact random effect structure based on theoretical
>>assumptions in my hypothesis as well as backward model selection
>>criterion discussed by Matuschek, Kliegel, Vasishth, Baayen & Bates
>>(2017) and Barr, Levy, Scheepers & Tily (2013). Due to the complexity of
>>my design it is not possible to fit the full three way interaction as a
>>random slope so I choose (1 + preexisting.belief*engagement |id) for
>>participants and (1 + engagement |item) for items - the choice is
>>motivated by theoretical assumptions as well as comparison of various
>>random effect models (with full interaction in fixed effects) using the
>>anova() function. I then proceed to fit the four clmm models to test my
>>fixed effects, starting with the null model and then adding all the
>>interaction terms in a step wise fashion.
>>
>> While the more complex models like model 2 and 3 are able to converge:
>>
>>
>>> cm.2 <- clmm(value.statement~preexisting.belief*engagement +
>> +                       (1 + preexisting.belief*engagement |id) + (1 +
>>engagement |item),
>> +                 data = ucl.ordered, Hess = TRUE)
>>
>> running the summary() function gives me:
>> max.grad = 9.78e-03 and cond.H = 2.3e+04
>>
>>
>>> cm.3 <- clmm(value.statement~quant*preexisting.belief*engagement +
>> +                       (1 + preexisting.belief*engagement |id) + (1 +
>>engagement |item),
>> +                 data = ucl.ordered, Hess = TRUE)
>>
>> running the summary() function gives me:
>> max.grad = 1.28e-01 and cond.H = 1.7e+04
>>
>>
>> I find that the simpler model and even the null model show failures to
>>converge:
>>
>>
>>> cm.null <- clmm(value.statement~1 +
>> +                        (1 + preexisting.belief*engagement |id) + (1 +
>>engagement |item),
>> +                  data = ucl.ordered, Hess = TRUE)
>> Error: optimizer nlminb failed to converge
>>
>>> cm.1 <- clmm(value.statement~quant +
>> +                        (1 + preexisting.belief*engagement |id) + (1 +
>>engagement |item),
>> +                  data = ucl.ordered, Hess = TRUE)
>> Error: optimizer nlminb failed to converge
>>
>>
>> I have tried looking for potential solutions to this on the r-sig-mm
>>list as well as other online resources and have tried some suggestions.
>>Using the "ucminf" optimizer does not work and produces error message:
>>"cannot use ucminf optimizer for this model, using nlminb instead". I
>>have tried changing the maxIter and maxLineIter parameters under
>>clmm.control to 200 and that has also resulted in no improvement. I am
>>puzzled by the fact that the error persists only for the simpler models.
>>My first guess was that the complexity of my design is too much for clmm
>>to handle with only 2200 observations, however, if that were the case
>>wouldn't models 3 and 4 also fail to converge?
>>
>> I would greatly appreciate any help on these errors. I am also happy to
>>share the full data (in private correspondence) if that might be of help
>>here.
>>
>> Thank you in advance,
>> Davis Ozols
>> PhD Student,
>> University of Fribourg
>> CH-1700 Fribourg, Switzerland
>>
>> Tel: +41 26 300 79 09
>> Fax: +41 26 300 97 87
>>
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From profiack at gmail.com  Fri Mar  2 01:09:07 2018
From: profiack at gmail.com (Cleber Iack)
Date: Fri, 2 Mar 2018 00:09:07 +0000
Subject: [R-sig-ME] GLMM - Prediction
Message-ID: <CAM-sWA3hk7bBdi6De-b_EprpmDxGT2GKX74KBeOwyH2rqgTZmQ@mail.gmail.com>

Dear,

I have n different companies with different characteristics and each
company of this has the same positions
I selected data from several members of each position of each Company, and
there were behavioral variables ranging from 0 to 10, which to facilitate I
will call x1, x2, x3, these variables were collected more than once for
each person.

The objective is to predict the probability of occurrence of a fact, and
each person was also noted if this fact occurred or not. (0 or 1)

Using

formMod1= fato~  x1+x2+x3+(1 | company / position)
Mod1 <- glmer( formMod1 , data = dadosord , family = binomial,
                     control = glmerControl(optimizer="bobyqa"))

This model I can make a prediction without "problems"

n11 <-  data.frame(company =factor("M1", levels =
levels(dadosord$company ),ordered=FALSE),
                   position=factor("P1", levels =
levels(dadosord$position),ordered=FALSE),
                   x1=1, x2=7,x3=7)
predict( Mod1 , n11, type="response")

But I was worried because I have more than one observation of the
characteristics per individual, if I would not have to put it also as random
or somehow analyze this structure of possible correlation

Thinking about the first case I did

formMod2= fato~  x1+x2+x3+(1 | company / position) + (1 | ID)
Mod2 <- glmer( formMod2 , data = dadosord , family = binomial,
                     control = glmerControl(optimizer="bobyqa"))

But in this case when trying to predict the probability of the fact, the
function "predict" asks me who is the proposed id, which is out of
interest, since I must study for a random person who has the same features
x1, x2, x3, company and position.

And the second form, if any, I do not know how I would do

Thanks for the help of my friends.

Iack

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Fri Mar  2 10:46:20 2018
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Fri, 2 Mar 2018 10:46:20 +0100
Subject: [R-sig-ME] GLMM - Prediction
In-Reply-To: <CAM-sWA3hk7bBdi6De-b_EprpmDxGT2GKX74KBeOwyH2rqgTZmQ@mail.gmail.com>
References: <CAM-sWA3hk7bBdi6De-b_EprpmDxGT2GKX74KBeOwyH2rqgTZmQ@mail.gmail.com>
Message-ID: <CAJuCY5yqEQZm-mA=WUndbYdWUBok+fjgeEERJzPkcOcmnU1u6w@mail.gmail.com>

Dear Iack,

Look at the re.form argument of ?lme4::predict.merMod. This allows you the
make predictions without the ID random effect.

Best regards,


ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>

2018-03-02 1:09 GMT+01:00 Cleber Iack <profiack at gmail.com>:

> Dear,
>
> I have n different companies with different characteristics and each
> company of this has the same positions
> I selected data from several members of each position of each Company, and
> there were behavioral variables ranging from 0 to 10, which to facilitate I
> will call x1, x2, x3, these variables were collected more than once for
> each person.
>
> The objective is to predict the probability of occurrence of a fact, and
> each person was also noted if this fact occurred or not. (0 or 1)
>
> Using
>
> formMod1= fato~  x1+x2+x3+(1 | company / position)
> Mod1 <- glmer( formMod1 , data = dadosord , family = binomial,
>                      control = glmerControl(optimizer="bobyqa"))
>
> This model I can make a prediction without "problems"
>
> n11 <-  data.frame(company =factor("M1", levels =
> levels(dadosord$company ),ordered=FALSE),
>                    position=factor("P1", levels =
> levels(dadosord$position),ordered=FALSE),
>                    x1=1, x2=7,x3=7)
> predict( Mod1 , n11, type="response")
>
> But I was worried because I have more than one observation of the
> characteristics per individual, if I would not have to put it also as
> random
> or somehow analyze this structure of possible correlation
>
> Thinking about the first case I did
>
> formMod2= fato~  x1+x2+x3+(1 | company / position) + (1 | ID)
> Mod2 <- glmer( formMod2 , data = dadosord , family = binomial,
>                      control = glmerControl(optimizer="bobyqa"))
>
> But in this case when trying to predict the probability of the fact, the
> function "predict" asks me who is the proposed id, which is out of
> interest, since I must study for a random person who has the same features
> x1, x2, x3, company and position.
>
> And the second form, if any, I do not know how I would do
>
> Thanks for the help of my friends.
>
> Iack
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From manfrin at igb-berlin.de  Fri Mar  2 11:08:32 2018
From: manfrin at igb-berlin.de (=?utf-8?Q?Alessandro_Manfrin?=)
Date: Fri, 2 Mar 2018 11:08:32 +0100
Subject: [R-sig-ME] How do I account for Unbalanced Observation-per-group in
 Linear Mixed Effect Models?
Message-ID: <kcim.5a9922a0.4d0e.78d2ae430350469e@ucsmail01.ad.igb-berlin.de>

Dear all,

I have a dataset of fish collected in different rivers over different years each of them sampled a different number of times during different projects .
This different number of observations among rivers in some cases can be important:
For example:
River X = 1 project (1 observation=1 sampling x 1 year);
River Y = 5 projects (15 observations= 1 sampling x 3 years x 5 projects);
River Z= 15 projects (105 observations=1 sampling x 7 years x 15 projects);
I want to calculate in the all region (so not interested in specific rivers) how the abundance is related to Years, Latitude, Altitude and Anthopic pressures (APindex). I thought to use the following model:
?lme: Abu~Years+Latitude+Altitude+APindex + (1|river/project) + corrARMA (form = Years|River/project).
?-What is the influence of RiverZ with its 105 observation compared to the other rivers which have less number of observations?
-Am I accounting for this unbalanced observations in the random structure (1|river/project)?
-Do I have to account in the model for the different number of observations with (weight=1/n observation for each project?)
?Thank you



Dr. Alessandro Manfrin

University of Applied Sciences Trier, Umwelt Campus Birkenfeld/
University of Duisburg-Essen, Faculty of Biology

Working place:
Department of Aquatic Ecology
Room S05 T03 B02
Universit?tsstr. 5
45141 Essen (DE)
Tel.: +49 (0)201/183-3113
Fax: +49 (0)201/183-2179







?

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Fri Mar  2 11:36:24 2018
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Fri, 2 Mar 2018 11:36:24 +0100
Subject: [R-sig-ME] 
 Longitudinal logistic regression with continuous-time
 first-order autocorrelation structure
In-Reply-To: <CAFvg1=tD0t0eH-ZpWc+qOVJ49RHZLHephSkjtGFYuWtTgVynjg@mail.gmail.com>
References: <CAFvg1=tD0t0eH-ZpWc+qOVJ49RHZLHephSkjtGFYuWtTgVynjg@mail.gmail.com>
Message-ID: <CAJuCY5ykmYVVvKJfnDpK2_hYPrjP5iUK=xSTxZxzvThUj=HmAA@mail.gmail.com>

Dear Dennis,

Here is an example on how to run such a model with INLA. It took about 3.5
min on my laptop.

library(INLA)
library(ggplot2)
set.seed(20180302)
n_id <- 35
n_day <- 7 * 6
n_prompt <- 5
dataset <- expand.grid(
  ID = seq_len(n_id),
  Day = seq_len(n_day),
  Prompt = seq_len(n_prompt)
)
dataset$Hour <- sample(8:22, size = nrow(dataset), replace = TRUE)
p0 <- rnorm(n_id, mean = -21, sd = 0.5)
p1 <- rnorm(n_id, mean = 2.67, sd = 0.05)
p2 <- rnorm(n_id, mean = -0.08, sd = 0.002)
dataset$eta <-  p2[dataset$ID] * dataset$Hour ^ 2 + p1[dataset$ID] *
dataset$Hour + p0[dataset$ID]
dataset$mu <- plogis(dataset$eta)
ggplot(dataset, aes(x = Hour, y = mu, group = ID)) + geom_line()
dataset$noise <- rnorm(nrow(dataset), sd = 0.1)
dataset$prob <- plogis(dataset$eta + dataset$noise)
dataset$Craving <- rbinom(nrow(dataset), size = 1, prob = dataset$prob)

dataset$HourID <- dataset$Hour
model <- inla(
  Craving ~
    f(Hour, model = "rw1") +
    f(HourID, model = "rw1", replicate = ID),
  family = "binomial",
  data = dataset
)
plot(model)

Best regards,

Thierry


ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>

2018-03-01 2:44 GMT+01:00 Dennis Ruenger <dennis.ruenger at gmail.com>:

> Thanks, Alain and Ben, for your replies.
>
> My understanding is that for the kind of intensive longitudinal data I'm
> dealing with, a mixed model with both random intercepts and slopes for the
> time effect *and *autoregressive errors are recommended.
>
> I'd like to follow Alain's suggestion and give glmmTMB a try. Based on a
> description of the covariance structures available with glmmTMB (link
> below), it looks like the Ornstein?Uhlenbeck covariance structure might be
> what I'm looking for (i.e., something akin to corrCAR1() that works in a
> GLMM).
>
> So I tried:
>
> df$time_hours <- numFactor(df$time_hours)
> fit  <- glmmTMB(y ~ time_hours + (time_hours|id) + ou(time_hours-1|id),
> family = binomial, data = df)
>
> However, after about 10 minutes, I receive an error message about failed
> memory allocation (on a laptop with a 7th gen Intel Core i5 processor and
> 8GB RAM). The data set includes 34 participants with up to 300 data points
> per participants. Running the model for a subset of 5 participants also
> resulted in memory allocation failure. The same was true for the spatial
> Gaussian and spatial exponential covariance structures.
>
> Does anyone see a way to make this work with glmmTMB?
>
> Thanks a lot.
>
> https://cran.r-project.org/web/packages/glmmTMB/vignettes/covstruct.html
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From jdpo223 at g.uky.edu  Fri Mar  2 16:24:39 2018
From: jdpo223 at g.uky.edu (Poe, John)
Date: Fri, 2 Mar 2018 10:24:39 -0500
Subject: [R-sig-ME] priors in multilevel modeling
Message-ID: <CAFW8ByqAJgdzxxL_-im=NWYEV=VqS9JUyOK5GN=CNYnq6dR_Mw@mail.gmail.com>

Hello everyone,

I'm doing an independent study with a student on advanced topics in
multilevel modeling and we are going to be hitting Bayesian multilevel
modeling before long. I'm looking for papers that either make specific
recommendations for prior and hyperprior choices in Bayesian multilevel
models or that compare the effects of different types of priors. Note that
this isn't for a specific application. I'm just trying to put together a
comprehensive reading list that goes through the types of things you can do
with priors in multilevel models and the consequences and benefits of
certain kinds of priors.

Any additional suggestions, critiques, or general insights on this topic
are *extremely* welcome.

These are what I've already got for those interested

On general prior construction:

   - Gelman, A., et al. (2017). "The prior can often only be understood in
   the context of the likelihood." Entropy 19(10): 555.
   - Kass, R. E. and L. Wasserman (1996). "The selection of prior
   distributions by formal rules." Journal of the American Statistical
   Association 91(435): 1343-1370.
   - Savage, Jim (2017) Your model gives you a lot of information about
   what your prior should(n?t) be. Blog Pos
   <https://modernstatisticalworkflow.blogspot.com/search?updated-max=2017-11-26T20:23:00-08:00&max-results=20&start=1&by-date=false>
   t
   - McElreath, R. (2015). Big Entropy and the Generalized Linear Model.
   Statistical Rethinking, CRC Press.
   - Simpson, D., et al. (2017). "Penalising model component complexity: A
   principled, practical approach to constructing priors." Statistical Science
   32(1): 1-28.
   - Lopes, H. F. and J. L. Tobias (2011). "Confronting prior convictions:
   On issues of prior sensitivity and likelihood robustness in Bayesian
   analysis." Annu. Rev. Econ. 3(1): 107-131.
   - Betancourt, M. (2017) How the Shape of a Weakly Informative Prior
   Affects Inferences
   <http://mc-stan.org/users/documentation/case-studies/weakly_informative_shapes.html>
   - Seaman III, J. W., et al. (2012). "Hidden dangers of specifying
   noninformative priors." The American Statistician 66(2): 77-84.


On priors in multilevel models

   - Browne, W. J. and D. Draper (2006). ?A comparison of Bayesian and
   likelihood-based methods for fitting multilevel models.? Bayesian analysis
   1(3): 473-514.
   - Gelman, A. (2006). "Prior distributions for variance parameters in
   hierarchical models (comment on article by Browne and Draper)." Bayesian
   analysis 1(3): 515-534.
   - Kass, R. E. and R. Natarajan (2006). "A default conjugate prior for
   variance components in generalized linear mixed models (comment on article
   by Browne and Draper)." Bayesian analysis 1(3): 535-542.
   - Lambert, P. C. (2006). "Comment on article by Browne and Draper."
   Bayesian analysis 1(3): 543-546.
   - Browne, W. J. and D. Draper (2006). "Rejoinder." Bayesian analysis
   1(3): 547 - 550.
   - Congdon, P. D. (2010). Applied Bayesian hierarchical methods, CRC
   Press. Various chapters
   - Sun, D., et al. (2001). "Propriety of posteriors with improper priors
   in hierarchical linear mixed models." Statistica Sinica: 77-95.
   - Chung, Y., et al. (2015). "Weakly informative prior for point
   estimation of covariance matrices in hierarchical models." Journal of
   Educational and Behavioral Statistics 40(2): 136-157.
   - Piironen, J. and A. Vehtari (2016). "On the hyperprior choice for the
   global shrinkage parameter in the horseshoe prior." arXiv preprint
   arXiv:1610.05559.
   - Hobert, J. P. and G. Casella (1996). "The effect of improper priors on
   Gibbs sampling in hierarchical linear mixed models." Journal of the
   American Statistical Association 91(436): 1461-1473.




-- 




Thanks,
John


John Poe, Ph.D.
Postdoctoral Scholar / Research Methodologist
Center for Public Health Services & Systems Research
University of Kentucky
www.johndavidpoe.com

<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail&utm_term=icon>
Virus-free.
www.avast.com
<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail&utm_term=link>
<#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>

	[[alternative HTML version deleted]]


From dennis.ruenger at gmail.com  Sat Mar  3 08:44:29 2018
From: dennis.ruenger at gmail.com (Dennis Ruenger)
Date: Fri, 2 Mar 2018 23:44:29 -0800
Subject: [R-sig-ME] 
 Longitudinal logistic regression with continuous-time
 first-order autocorrelation structure
In-Reply-To: <CAJuCY5ykmYVVvKJfnDpK2_hYPrjP5iUK=xSTxZxzvThUj=HmAA@mail.gmail.com>
References: <CAFvg1=tD0t0eH-ZpWc+qOVJ49RHZLHephSkjtGFYuWtTgVynjg@mail.gmail.com>
 <CAJuCY5ykmYVVvKJfnDpK2_hYPrjP5iUK=xSTxZxzvThUj=HmAA@mail.gmail.com>
Message-ID: <CAFvg1=t0PeM+Yyv5BwKa8fPAyXBF_9MkX6b0TK90pLZCBz5QFg@mail.gmail.com>

 Thank you, Thierry, for the INLA model.

Can you tell me why you chose a random walk rather than, say, an
Ornstein-Uhlenbeck process, to model temporal autocorrelation? The INLA
documentation that I could find online is rather sparse, and I struggle
with how you model the hierarchical structure, that is f(HourID, model =
"rw1", replicate = ID). Lastly, can you tell me how you would incorporate
an effect of Day in the model? I?m expecting that the likelihood of craving
decreases across days, and that this trend varies between participants.

Dennis

On Mar 2, 2018 at 2:36 AM, Thierry Onkelinx <thierry.onkelinx at inbo.be>
wrote:


Dear Dennis,

Here is an example on how to run such a model with INLA. It took about 3.5
min on my laptop.

library(INLA)
library(ggplot2)
set.seed(20180302)
n_id <- 35
n_day <- 7 * 6
n_prompt <- 5
dataset <- expand.grid(
  ID = seq_len(n_id),
  Day = seq_len(n_day),
  Prompt = seq_len(n_prompt)
)
dataset$Hour <- sample(8:22, size = nrow(dataset), replace = TRUE)
p0 <- rnorm(n_id, mean = -21, sd = 0.5)
p1 <- rnorm(n_id, mean = 2.67, sd = 0.05)
p2 <- rnorm(n_id, mean = -0.08, sd = 0.002)
dataset$eta <-  p2[dataset$ID] * dataset$Hour ^ 2 + p1[dataset$ID] *
dataset$Hour + p0[dataset$ID]
dataset$mu <- plogis(dataset$eta)
ggplot(dataset, aes(x = Hour, y = mu, group = ID)) + geom_line()
dataset$noise <- rnorm(nrow(dataset), sd = 0.1)
dataset$prob <- plogis(dataset$eta + dataset$noise)
dataset$Craving <- rbinom(nrow(dataset), size = 1, prob = dataset$prob)

dataset$HourID <- dataset$Hour
model <- inla(
  Craving ~
    f(Hour, model = "rw1") +
    f(HourID, model = "rw1", replicate = ID),
  family = "binomial",
  data = dataset
)
plot(model)

Best regards,

Thierry


ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>

2018-03-01 2:44 GMT+01:00 Dennis Ruenger <dennis.ruenger at gmail.com>:

> Thanks, Alain and Ben, for your replies.
>
> My understanding is that for the kind of intensive longitudinal data I'm
> dealing with, a mixed model with both random intercepts and slopes for the
> time effect *and *autoregressive errors are recommended.
>
> I'd like to follow Alain's suggestion and give glmmTMB a try. Based on a
> description of the covariance structures available with glmmTMB (link
> below), it looks like the Ornstein?Uhlenbeck covariance structure might be
> what I'm looking for (i.e., something akin to corrCAR1() that works in a
> GLMM).
>
> So I tried:
>
> df$time_hours <- numFactor(df$time_hours)
> fit  <- glmmTMB(y ~ time_hours + (time_hours|id) + ou(time_hours-1|id),
> family = binomial, data = df)
>
> However, after about 10 minutes, I receive an error message about failed
> memory allocation (on a laptop with a 7th gen Intel Core i5 processor and
> 8GB RAM). The data set includes 34 participants with up to 300 data points
> per participants. Running the model for a subset of 5 participants also
> resulted in memory allocation failure. The same was true for the spatial
> Gaussian and spatial exponential covariance structures.
>
> Does anyone see a way to make this work with glmmTMB?
>
> Thanks a lot.
>
> https://cran.r-project.org/web/packages/glmmTMB/vignettes/covstruct.html
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From profiack at gmail.com  Sun Mar  4 01:06:35 2018
From: profiack at gmail.com (Cleber Iack)
Date: Sun, 4 Mar 2018 00:06:35 +0000
Subject: [R-sig-ME] GLMM - Prediction
In-Reply-To: <CAJuCY5yqEQZm-mA=WUndbYdWUBok+fjgeEERJzPkcOcmnU1u6w@mail.gmail.com>
References: <CAM-sWA3hk7bBdi6De-b_EprpmDxGT2GKX74KBeOwyH2rqgTZmQ@mail.gmail.com>
 <CAJuCY5yqEQZm-mA=WUndbYdWUBok+fjgeEERJzPkcOcmnU1u6w@mail.gmail.com>
Message-ID: <CAM-sWA3z42T7ZgvNB4=VOfN_ik1_qtYffjSEWY9o2UgWRf7ciw@mail.gmail.com>

Dear

First, thank you very much for your time in answering.

I'm sending a code that I tried not to inform the ID and I couldn't,

Displays the following error at the end

"Error in eval (predvars, date, env): object ID not found"

I'd appreciate it if you could give me some guidance

Thanks
####

library(plyr)

library(dplyr)

library(lme4)

n = 300

xx<-c("r1", "r2", "r3", "r4", "r5")

xxx<-c("e1", "e2", "e3")

p=0.3

School = factor(sample(xxx, n, replace=TRUE), levels=xxx, ordered=FALSE)

Rank = factor(sample(xx, n, replace=TRUE), levels=xx, ordered=FALSE)



df1 <- data_frame(

  ID = as.integer(runif(n, min = 1, max = n/7)),

  xx1 = runif(n, min = 0, max = 10),

  xx2 = runif(n, min = 0, max = 10),

  xx3 = runif(n, min = 0, max = 10),

  School = School,

  Rank = Rank,

  yx = as.factor(rbinom(n, size = 1, prob = p))

)

df1 = df1[order(df1$ID, decreasing=FALSE),]

library(lme4)

mm2 <- glmer(yx ~ xx1 + xx2 + xx3 + Rank +  (1 | ID) + (1 | School / Rank),
data = df1,

             family = "binomial",control = glmerControl(calc.derivs =
FALSE))



n11 <-  data.frame(School=factor("e1", levels =
levels(df1$School),ordered=FALSE),

                   Rank=factor("r1", levels =
levels(df1$Rank),ordered=FALSE),

                   xx1=8.58, xx2=8.75, xx3=7.92)

predict(mm2, n11, type="response",re.form= ~(1 | School / Rank))

##


2018-03-02 9:46 GMT+00:00 Thierry Onkelinx <thierry.onkelinx at inbo.be>:

> Dear Iack,
>
> Look at the re.form argument of ?lme4::predict.merMod. This allows you the
> make predictions without the ID random effect.
>
> Best regards,
>
>
> ir. Thierry Onkelinx
> Statisticus / Statistician
>
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
> FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Havenlaan 88
> <https://maps.google.com/?q=Havenlaan+88&entry=gmail&source=g> bus 73,
> 1000 Brussel
> www.inbo.be
>
> ////////////////////////////////////////////////////////////
> ///////////////////////////////
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
> ////////////////////////////////////////////////////////////
> ///////////////////////////////
>
> <https://www.inbo.be>
>
> 2018-03-02 1:09 GMT+01:00 Cleber Iack <profiack at gmail.com>:
>
>> Dear,
>>
>> I have n different companies with different characteristics and each
>> company of this has the same positions
>> I selected data from several members of each position of each Company, and
>> there were behavioral variables ranging from 0 to 10, which to facilitate
>> I
>> will call x1, x2, x3, these variables were collected more than once for
>> each person.
>>
>> The objective is to predict the probability of occurrence of a fact, and
>> each person was also noted if this fact occurred or not. (0 or 1)
>>
>> Using
>>
>> formMod1= fato~  x1+x2+x3+(1 | company / position)
>> Mod1 <- glmer( formMod1 , data = dadosord , family = binomial,
>>                      control = glmerControl(optimizer="bobyqa"))
>>
>> This model I can make a prediction without "problems"
>>
>> n11 <-  data.frame(company =factor("M1", levels =
>> levels(dadosord$company ),ordered=FALSE),
>>                    position=factor("P1", levels =
>> levels(dadosord$position),ordered=FALSE),
>>                    x1=1, x2=7,x3=7)
>> predict( Mod1 , n11, type="response")
>>
>> But I was worried because I have more than one observation of the
>> characteristics per individual, if I would not have to put it also as
>> random
>> or somehow analyze this structure of possible correlation
>>
>> Thinking about the first case I did
>>
>> formMod2= fato~  x1+x2+x3+(1 | company / position) + (1 | ID)
>> Mod2 <- glmer( formMod2 , data = dadosord , family = binomial,
>>                      control = glmerControl(optimizer="bobyqa"))
>>
>> But in this case when trying to predict the probability of the fact, the
>> function "predict" asks me who is the proposed id, which is out of
>> interest, since I must study for a random person who has the same features
>> x1, x2, x3, company and position.
>>
>> And the second form, if any, I do not know how I would do
>>
>> Thanks for the help of my friends.
>>
>> Iack
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Sun Mar  4 20:11:29 2018
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 4 Mar 2018 14:11:29 -0500
Subject: [R-sig-ME] GLMM - Prediction
In-Reply-To: <CAM-sWA3z42T7ZgvNB4=VOfN_ik1_qtYffjSEWY9o2UgWRf7ciw@mail.gmail.com>
References: <CAM-sWA3hk7bBdi6De-b_EprpmDxGT2GKX74KBeOwyH2rqgTZmQ@mail.gmail.com>
 <CAJuCY5yqEQZm-mA=WUndbYdWUBok+fjgeEERJzPkcOcmnU1u6w@mail.gmail.com>
 <CAM-sWA3z42T7ZgvNB4=VOfN_ik1_qtYffjSEWY9o2UgWRf7ciw@mail.gmail.com>
Message-ID: <CABghstSkHyGhPdXD1zi9LhZUgx3NuXCbZT8GHSu7AxcgM=nO-A@mail.gmail.com>

This looks like a bug in lme4: https://github.com/lme4/lme4/issues/457
. A simple workaround is to specify some value for `ID`
(which will be ignored).

On Sat, Mar 3, 2018 at 7:06 PM, Cleber Iack <profiack at gmail.com> wrote:
> Dear
>
> First, thank you very much for your time in answering.
>
> I'm sending a code that I tried not to inform the ID and I couldn't,
>
> Displays the following error at the end
>
> "Error in eval (predvars, date, env): object ID not found"
>
> I'd appreciate it if you could give me some guidance
>
> Thanks
> ####
>
> library(plyr)
>
> library(dplyr)
>
> library(lme4)
>
> n = 300
>
> xx<-c("r1", "r2", "r3", "r4", "r5")
>
> xxx<-c("e1", "e2", "e3")
>
> p=0.3
>
> School = factor(sample(xxx, n, replace=TRUE), levels=xxx, ordered=FALSE)
>
> Rank = factor(sample(xx, n, replace=TRUE), levels=xx, ordered=FALSE)
>
>
>
> df1 <- data_frame(
>
>   ID = as.integer(runif(n, min = 1, max = n/7)),
>
>   xx1 = runif(n, min = 0, max = 10),
>
>   xx2 = runif(n, min = 0, max = 10),
>
>   xx3 = runif(n, min = 0, max = 10),
>
>   School = School,
>
>   Rank = Rank,
>
>   yx = as.factor(rbinom(n, size = 1, prob = p))
>
> )
>
> df1 = df1[order(df1$ID, decreasing=FALSE),]
>
> library(lme4)
>
> mm2 <- glmer(yx ~ xx1 + xx2 + xx3 + Rank +  (1 | ID) + (1 | School / Rank),
> data = df1,
>
>              family = "binomial",control = glmerControl(calc.derivs =
> FALSE))
>
>
>
> n11 <-  data.frame(School=factor("e1", levels =
> levels(df1$School),ordered=FALSE),
>
>                    Rank=factor("r1", levels =
> levels(df1$Rank),ordered=FALSE),
>
>                    xx1=8.58, xx2=8.75, xx3=7.92)
>
> predict(mm2, n11, type="response",re.form= ~(1 | School / Rank))
>
> ##
>
>
> 2018-03-02 9:46 GMT+00:00 Thierry Onkelinx <thierry.onkelinx at inbo.be>:
>
>> Dear Iack,
>>
>> Look at the re.form argument of ?lme4::predict.merMod. This allows you the
>> make predictions without the ID random effect.
>>
>> Best regards,
>>
>>
>> ir. Thierry Onkelinx
>> Statisticus / Statistician
>>
>> Vlaamse Overheid / Government of Flanders
>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
>> FOREST
>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
>> thierry.onkelinx at inbo.be
>> Havenlaan 88
>> <https://maps.google.com/?q=Havenlaan+88&entry=gmail&source=g> bus 73,
>> 1000 Brussel
>> www.inbo.be
>>
>> ////////////////////////////////////////////////////////////
>> ///////////////////////////////
>> To call in the statistician after the experiment is done may be no more
>> than asking him to perform a post-mortem examination: he may be able to say
>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does not
>> ensure that a reasonable answer can be extracted from a given body of data.
>> ~ John Tukey
>> ////////////////////////////////////////////////////////////
>> ///////////////////////////////
>>
>> <https://www.inbo.be>
>>
>> 2018-03-02 1:09 GMT+01:00 Cleber Iack <profiack at gmail.com>:
>>
>>> Dear,
>>>
>>> I have n different companies with different characteristics and each
>>> company of this has the same positions
>>> I selected data from several members of each position of each Company, and
>>> there were behavioral variables ranging from 0 to 10, which to facilitate
>>> I
>>> will call x1, x2, x3, these variables were collected more than once for
>>> each person.
>>>
>>> The objective is to predict the probability of occurrence of a fact, and
>>> each person was also noted if this fact occurred or not. (0 or 1)
>>>
>>> Using
>>>
>>> formMod1= fato~  x1+x2+x3+(1 | company / position)
>>> Mod1 <- glmer( formMod1 , data = dadosord , family = binomial,
>>>                      control = glmerControl(optimizer="bobyqa"))
>>>
>>> This model I can make a prediction without "problems"
>>>
>>> n11 <-  data.frame(company =factor("M1", levels =
>>> levels(dadosord$company ),ordered=FALSE),
>>>                    position=factor("P1", levels =
>>> levels(dadosord$position),ordered=FALSE),
>>>                    x1=1, x2=7,x3=7)
>>> predict( Mod1 , n11, type="response")
>>>
>>> But I was worried because I have more than one observation of the
>>> characteristics per individual, if I would not have to put it also as
>>> random
>>> or somehow analyze this structure of possible correlation
>>>
>>> Thinking about the first case I did
>>>
>>> formMod2= fato~  x1+x2+x3+(1 | company / position) + (1 | ID)
>>> Mod2 <- glmer( formMod2 , data = dadosord , family = binomial,
>>>                      control = glmerControl(optimizer="bobyqa"))
>>>
>>> But in this case when trying to predict the probability of the fact, the
>>> function "predict" asks me who is the proposed id, which is out of
>>> interest, since I must study for a random person who has the same features
>>> x1, x2, x3, company and position.
>>>
>>> And the second form, if any, I do not know how I would do
>>>
>>> Thanks for the help of my friends.
>>>
>>> Iack
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From profiack at gmail.com  Sun Mar  4 21:28:55 2018
From: profiack at gmail.com (Cleber Iack)
Date: Sun, 4 Mar 2018 20:28:55 +0000
Subject: [R-sig-ME] GLMM - Prediction
In-Reply-To: <CABghstSkHyGhPdXD1zi9LhZUgx3NuXCbZT8GHSu7AxcgM=nO-A@mail.gmail.com>
References: <CAM-sWA3hk7bBdi6De-b_EprpmDxGT2GKX74KBeOwyH2rqgTZmQ@mail.gmail.com>
 <CAJuCY5yqEQZm-mA=WUndbYdWUBok+fjgeEERJzPkcOcmnU1u6w@mail.gmail.com>
 <CAM-sWA3z42T7ZgvNB4=VOfN_ik1_qtYffjSEWY9o2UgWRf7ciw@mail.gmail.com>
 <CABghstSkHyGhPdXD1zi9LhZUgx3NuXCbZT8GHSu7AxcgM=nO-A@mail.gmail.com>
Message-ID: <CAM-sWA2Y+0FodDADonW5kkVCJh-dNyRgyXt5z3_TvYEFz75Ofg@mail.gmail.com>

Thank you very much,

I tested, really is a bug.

God bless you.

2018-03-04 19:11 GMT+00:00 Ben Bolker <bbolker at gmail.com>:

> This looks like a bug in lme4: https://github.com/lme4/lme4/issues/457
> . A simple workaround is to specify some value for `ID`
> (which will be ignored).
>
> On Sat, Mar 3, 2018 at 7:06 PM, Cleber Iack <profiack at gmail.com> wrote:
> > Dear
> >
> > First, thank you very much for your time in answering.
> >
> > I'm sending a code that I tried not to inform the ID and I couldn't,
> >
> > Displays the following error at the end
> >
> > "Error in eval (predvars, date, env): object ID not found"
> >
> > I'd appreciate it if you could give me some guidance
> >
> > Thanks
> > ####
> >
> > library(plyr)
> >
> > library(dplyr)
> >
> > library(lme4)
> >
> > n = 300
> >
> > xx<-c("r1", "r2", "r3", "r4", "r5")
> >
> > xxx<-c("e1", "e2", "e3")
> >
> > p=0.3
> >
> > School = factor(sample(xxx, n, replace=TRUE), levels=xxx, ordered=FALSE)
> >
> > Rank = factor(sample(xx, n, replace=TRUE), levels=xx, ordered=FALSE)
> >
> >
> >
> > df1 <- data_frame(
> >
> >   ID = as.integer(runif(n, min = 1, max = n/7)),
> >
> >   xx1 = runif(n, min = 0, max = 10),
> >
> >   xx2 = runif(n, min = 0, max = 10),
> >
> >   xx3 = runif(n, min = 0, max = 10),
> >
> >   School = School,
> >
> >   Rank = Rank,
> >
> >   yx = as.factor(rbinom(n, size = 1, prob = p))
> >
> > )
> >
> > df1 = df1[order(df1$ID, decreasing=FALSE),]
> >
> > library(lme4)
> >
> > mm2 <- glmer(yx ~ xx1 + xx2 + xx3 + Rank +  (1 | ID) + (1 | School /
> Rank),
> > data = df1,
> >
> >              family = "binomial",control = glmerControl(calc.derivs =
> > FALSE))
> >
> >
> >
> > n11 <-  data.frame(School=factor("e1", levels =
> > levels(df1$School),ordered=FALSE),
> >
> >                    Rank=factor("r1", levels =
> > levels(df1$Rank),ordered=FALSE),
> >
> >                    xx1=8.58, xx2=8.75, xx3=7.92)
> >
> > predict(mm2, n11, type="response",re.form= ~(1 | School / Rank))
> >
> > ##
> >
> >
> > 2018-03-02 9:46 GMT+00:00 Thierry Onkelinx <thierry.onkelinx at inbo.be>:
> >
> >> Dear Iack,
> >>
> >> Look at the re.form argument of ?lme4::predict.merMod. This allows you
> the
> >> make predictions without the ID random effect.
> >>
> >> Best regards,
> >>
> >>
> >> ir. Thierry Onkelinx
> >> Statisticus / Statistician
> >>
> >> Vlaamse Overheid / Government of Flanders
> >> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
> AND
> >> FOREST
> >> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> >> thierry.onkelinx at inbo.be
> >> Havenlaan 88
> >> <https://maps.google.com/?q=Havenlaan+88&entry=gmail&source=g> bus 73,
> >> 1000 Brussel
> >> www.inbo.be
> >>
> >> ////////////////////////////////////////////////////////////
> >> ///////////////////////////////
> >> To call in the statistician after the experiment is done may be no more
> >> than asking him to perform a post-mortem examination: he may be able to
> say
> >> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> >> The plural of anecdote is not data. ~ Roger Brinner
> >> The combination of some data and an aching desire for an answer does not
> >> ensure that a reasonable answer can be extracted from a given body of
> data.
> >> ~ John Tukey
> >> ////////////////////////////////////////////////////////////
> >> ///////////////////////////////
> >>
> >> <https://www.inbo.be>
> >>
> >> 2018-03-02 1:09 GMT+01:00 Cleber Iack <profiack at gmail.com>:
> >>
> >>> Dear,
> >>>
> >>> I have n different companies with different characteristics and each
> >>> company of this has the same positions
> >>> I selected data from several members of each position of each Company,
> and
> >>> there were behavioral variables ranging from 0 to 10, which to
> facilitate
> >>> I
> >>> will call x1, x2, x3, these variables were collected more than once for
> >>> each person.
> >>>
> >>> The objective is to predict the probability of occurrence of a fact,
> and
> >>> each person was also noted if this fact occurred or not. (0 or 1)
> >>>
> >>> Using
> >>>
> >>> formMod1= fato~  x1+x2+x3+(1 | company / position)
> >>> Mod1 <- glmer( formMod1 , data = dadosord , family = binomial,
> >>>                      control = glmerControl(optimizer="bobyqa"))
> >>>
> >>> This model I can make a prediction without "problems"
> >>>
> >>> n11 <-  data.frame(company =factor("M1", levels =
> >>> levels(dadosord$company ),ordered=FALSE),
> >>>                    position=factor("P1", levels =
> >>> levels(dadosord$position),ordered=FALSE),
> >>>                    x1=1, x2=7,x3=7)
> >>> predict( Mod1 , n11, type="response")
> >>>
> >>> But I was worried because I have more than one observation of the
> >>> characteristics per individual, if I would not have to put it also as
> >>> random
> >>> or somehow analyze this structure of possible correlation
> >>>
> >>> Thinking about the first case I did
> >>>
> >>> formMod2= fato~  x1+x2+x3+(1 | company / position) + (1 | ID)
> >>> Mod2 <- glmer( formMod2 , data = dadosord , family = binomial,
> >>>                      control = glmerControl(optimizer="bobyqa"))
> >>>
> >>> But in this case when trying to predict the probability of the fact,
> the
> >>> function "predict" asks me who is the proposed id, which is out of
> >>> interest, since I must study for a random person who has the same
> features
> >>> x1, x2, x3, company and position.
> >>>
> >>> And the second form, if any, I do not know how I would do
> >>>
> >>> Thanks for the help of my friends.
> >>>
> >>> Iack
> >>>
> >>>         [[alternative HTML version deleted]]
> >>>
> >>> _______________________________________________
> >>> R-sig-mixed-models at r-project.org mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>>
> >>
> >>
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From thalkjelsvik at hotmail.com  Mon Mar  5 11:44:49 2018
From: thalkjelsvik at hotmail.com (Torleif Halkjelsvik)
Date: Mon, 5 Mar 2018 10:44:49 +0000
Subject: [R-sig-ME] factor-specific random-effects variance
Message-ID: <HE1PR0201MB2092211FA6812A46216C1EC0D1DA0@HE1PR0201MB2092.eurprd02.prod.outlook.com>

I found this blog post: https://rpubs.com/bbolker/factorvar and it looks rather difficult to obtain factor-specific random effects (without the extra correlations). What would be wrong with the simpler approach:

dependent~fixedeffects+(0+dummy1a|randomvar)+ (0+dummy1b|randomvar)

where dummy1a and dummy1b are the same variable but coded inversely 0-1 and 1-0?


Regards,

Torleif


	[[alternative HTML version deleted]]


From Daniel.Hammarstrom at inn.no  Mon Mar  5 16:39:45 2018
From: Daniel.Hammarstrom at inn.no (=?iso-8859-2?Q?Daniel_Hammarstr=F6m?=)
Date: Mon, 5 Mar 2018 15:39:45 +0000
Subject: [R-sig-ME] How to extract and understand heterogeneous variances in
 mixed-effects models
Message-ID: <7d1a1e0bde654a34a57a7fee3118f413@PR-EXCH02HV.hil.local>

Hi all!

Being my first question to the R-sig-mixed-models mailing list I'm hoping that it is not off-topic.   

I'm fitting a model where I want to allow for heterogeneous variances over a grouping variable in the data. The purpose of the model is to estimate the stability of gene expression and I'm planning to do this using the method described in Serrano et al. 2011. They propose modeling gene expression as the dependent variable, gene ID and experimental grouping variables as fixed effects and the interaction between gene ID and grouping as a random effect. Additional random-effect terms are added to the model to estimate random variation due to e.g. each biological sample etc. The random effect of each gene x grouping is regarded as "bias", deviation from the gene x group average. Additionally, residual variance is estimated and the stability measure is called mean square error (MSE). MSE is calculated as: MSE = bias^2 + variance. The maximum MSE for each gene is regarded as the gene-specific stability measure. A more stable gene would in theory deviate less and show less variance.

Serrano et al. 2011 fits models "using the MIXED procedure of the SAS/STAT statistical package". When trying to implement the method in R I've resorted to nlme::lme function as we can fit models with heterogeneous variances specifying this in varIdent(form = ~1|someGroup).  

I've formulated a model with (what I believe are) crossed random effects and heterogeneous variances over a grouping variable. The random effects are treatment X gene interaction  (a vector made with interaction() containing treatment and gene ID specified as INTERACT below) and subject representing the ID of participants in the study. The weights-argument is specified using the varIdent() function where the grouping variable is the same INTERACT-variable as in the random-effects part. 

The model: 

m1 <- lme(expression ~ gene + treatment, 
           random = list(one1 = pdIdent(~ INTERACT -1),  
                         one2 = pdIdent(~ subject -1)),
           weights = varIdent(form = ~ 1|INTERACT), 
           data = data, method = "ML")

To replicate the method proposed by Serrano et al., the method is set to maximum likelihood.

Reading the literature, the estimated variance parameters from the model "represent the ratio between the standard deviations of
the lth stratum and the first stratum" (Pinheiro & Bates 2000, p. 209). So here comes my questions regarding varIdent (1) and the crossed random effects (2):

1. Am I right when retrieving the group specific variances as:
`m1$sigma^2 * coef(m1$modelStruct$varStruct, uncons = FALSE)^2`    
with the variance for the reference level being `m1$sigma^2 * 1`?

And a follow up question, how are one to understand the group specific variances? Are they "estimated" or "observed"? I guess my question boils down to: what assumptions are made when accepting strata-specific variances?

2. Are my crossed random effects correct (forgive me! a classic question, I know)? My understanding of the method in Ga?ecki & Burzykowski 2013 (p. 478) is that n variables with all values set to 1 are added to the data.frame

`data <- within(data, one1 <- one2 <- (...) <- one_n <- 1L)`

"crossed" random intercepts can then be added to the model by

`random = list(one1 = pdIdent(~ RANDOMFACTOR1 -1), one2 = pdIdent(~ RANDOMFACTOR2 -1))`

Am I right to understand that this is the analog random-effects structure to lmer's:
`fixed-effect + (1|RANDOMFACTOR1) + (1|RANDOMFACTOR2)

Thanks in advance for all feedback!
Best regards, Daniel


Pinheiro, J. & Bates, D. 2000 Mixed-Effects Models in S and S-PLUS, Springer-Verlag New York
Ga?ecki, A. & Burzykowski, T. 2013 Linear Mixed-Effects Models Using R, Springer-Verlag New York 
Serrano et al. 2011 Use of Maximum Likelihood-Mixed Models to select stable reference genes: a case of heat stress response in sheep. BMC Molecular Biology 2011 12:36. https://doi.org/10.1186/1471-2199-12-36


From vanamelie at gmail.com  Sun Mar  4 18:54:43 2018
From: vanamelie at gmail.com (=?UTF-8?Q?Vaniscotte_Am=c3=a9lie?=)
Date: Sun, 4 Mar 2018 18:54:43 +0100
Subject: [R-sig-ME] Random effect in GAM
Message-ID: <35fc98da-a4fa-935b-adb4-935c5e40b8f1@gmail.com>

Dear R users,

I am using the mgcv package in R to model the ratio of damaged culture 
hectares by wild boar in each french department according to some 
environmental covariates(cf data attached). I used a using a Beta 
distribution for the response.

For each department, the damages are estimated in 3 different culture 
types (? Culture ?). Also, the department are clustered into landscape 
types (? Cluster ?). Since I wanted to get the effect of the Culture 
type and the Landscape, I keep those variables as fixed effects in the 
model.

Also, since we have 5 repetitions in time of the response and of some 
covariates measurement per department and culture type, I put a random 
effect on the Department per Culture type and put the year as fixed 
effect as well.

The model takes the form :

gam_tot <-gam(resp ~ Culture + Cluster:Culture + s(Year,k=4, by=Culture) 
+ s(X1, by=Culture) + s(X2, by=Culture) + s(Depts, bs="re", by=Culture) 
, family=betar(link="logit"),method="REML",data=data,select=FALSE)

Then, I estimated the part of the model explained deviance provided by 
each covariate. For that, I run the model without the given covariate 
(keeping smooth parameters constant between models), and compute the 
difference in deviance between the Full model (with the given covariate) 
and the penalized model (without the given covariate): (Full model 
Deviance ? Penalized model Deviance) / Full Model Deviance

 From that, I get a huge proportion of Deviance explained by the random 
effect (Department) of about 30 %, while the others covariates explained 
less than 1 %.

At this point, I have few questions :

     Do you think my model formula is correct regarding my data and 
questions ?

     Is my estimate of explained deviance correct ? In that case, how 
can I explain such a discrepancy between the part of explained deviance 
by random and fixed effects ?

Thanks for your help,

Am?lie

From andrea.p.drager at rice.edu  Mon Mar  5 18:08:38 2018
From: andrea.p.drager at rice.edu (Drager, Andrea Pilar)
Date: Mon, 05 Mar 2018 11:08:38 -0600
Subject: [R-sig-ME] Estimates for groups within fixed effects & also: enough
 info for estimating variance? MCMCglmm
Message-ID: <20180305110838.Horde.YjaNi7aLLjqURscO0WF4OQ3@webmail.rice.edu>


Hi all,

I've fitted a model with a binary response at the individual level,  
two continuous fixed effects (measured at the individual level but  
containing info on 23 species), and a single random effect of  
"species". My model is mixing well and the results fit the data, but  
what I am really interested in is getting estimates for the fixed  
effect by species, rather than globally.

It is my understanding (per a 2016 reply to a post to this list:  
parameter estimates for all factor levels MCMCglmm) that by  
suppressing the intercept here, I am estimating the first "level" (one  
species?) for each effect, and that the remaining effects are  
deviations from these levels.  How do I code random slopes and  
intercepts for species within each of the fixed effects, rather than  
deviations from a common distribution?

priorS = list(R = list(V = 1, nu = 0, fix = 1),  G = list(G1 = list(V  
= 1, nu = 0.002)))

smodel <-MCMCglmm(fl~  -1 + Zdbh + Znnd,
                   random = ~ species,
                   family = "categorical", verbose=F, pr = TRUE,  
start=list(QUASI=FALSE),
                   data=IHF,prior=priorS,
                   nitt=500000,burnin=5000,thin=100)


A second part of the question is that I would like to include a random  
effect to measure the influence of phylogenetic autocorrelation. I  
know how to code this using a distance matrix (see below), however, I  
am concerned that statistically, "species" and "phylo" may not have  
enough information to partition the variance in a meaningful way.  
Perhaps running three models (random=species, random=phylo,  
random=species + phylo) and comparing goodness-of-fit could be useful?  
I would greatly appreciate any insight. Many thanks!

prior = list(R = list(V = 1, nu = 0, fix = 1), G = list(G1 = list(V =  
1,nu = 0.002),
                                                           
G2=list(V=1,nu=0.002)))

model <-MCMCglmm(fl ~ Zdbh_mm + Znnd,
                  random = ~species + phylo,
                  family = "categorical", verbose=F, pr = TRUE,  
start=list(QUASI=FALSE),
                  ginverse=list(phylo=inv.phylo$Ainv),data=IHF,prior=prior,
                  nitt=500000,burnin=5000,thin=100)
Andrea Pilar Drager
PhD. student
Ecology and Evolutionary Biology, Rice University


From cumuluss at gmx.de  Mon Mar  5 20:24:00 2018
From: cumuluss at gmx.de (cumuluss)
Date: Mon, 05 Mar 2018 19:24:00 +0000
Subject: [R-sig-ME] Large variance and SD for random effects
In-Reply-To: <5A967FC8.8040700@maw.ru.nl>
References: <CAFvg1=vdVbz28pw9B6GrOXNsnceXK3UgXksMDwJUOQ9PYoLK_g@mail.gmail.com>
 <5A967E70.7010609@maw.ru.nl> <5A967FC8.8040700@maw.ru.nl>
Message-ID: <5A9D9972.7090204@gmx.de>

Hello,
the result of my GLMM with binomial error structure revealed for one of
the random intercepts and slopes variances and Sd's larger then 1

> Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) ['glmerMod']
>  Family: binomial  ( logit )
> Formula: obs.yn ~ z.lengthxyz + z.obsX + Spe_tr_subspecie + (1 | commu) +  
>     (1 + z.lengthxyz + z.obsX | Siteun) + (1 + z.lengthxyz +  
>     z.obsX + Spe_tr_subspecie_a.c + Spe_tr_subspecie_b.c +  
>     Spe_tr_subspecie_c.c | behavior)

> Random effects:
>  Groups   Name                  Variance Std.Dev. Corr                         
>  commu    (Intercept)           0.614004 0.78358                               
>  Siteun   (Intercept)           0.521198 0.72194                               
>           z.lengthxyz           0.001016 0.03188   1.00                        
>           z.obsX                0.306931 0.55401  -0.17 -0.19                  
>  behavior (Intercept)           2.966139 1.72225                               
>           z.lengthxyz           0.030171 0.17370   0.77                        
>           z.obsX                0.412169 0.64200   0.20 -0.36                  
>           Spe_tr_subspecie_a.c  1.853903 1.36158   0.58  0.62  0.11            
>           Spe_tr_subspecie_b.c  3.973439 1.99335   0.51  0.23  0.25  0.65      
>           Spe_tr_subspecie_c.c  7.401343 2.72054   0.39  0.30  0.47  0.79  0.60
> Number of obs: 4413, groups:  commu, 144; Siteun, 108; behavior, 31

Now I wonder, whether that is a reason to worry, that the result could
be not valid?
Thanks in advance for any comments!
Paul


From thierry.onkelinx at inbo.be  Mon Mar  5 21:57:49 2018
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Mon, 5 Mar 2018 21:57:49 +0100
Subject: [R-sig-ME] Large variance and SD for random effects
In-Reply-To: <5A9D9972.7090204@gmx.de>
References: <CAFvg1=vdVbz28pw9B6GrOXNsnceXK3UgXksMDwJUOQ9PYoLK_g@mail.gmail.com>
 <5A967E70.7010609@maw.ru.nl> <5A967FC8.8040700@maw.ru.nl>
 <5A9D9972.7090204@gmx.de>
Message-ID: <CAJuCY5zyjn5weaimxRU47jr8O0uBv5wdrPt4ctRzt=ri9j=W7w@mail.gmail.com>

Dear Paul,

Your random effect structure looks quite complicated. Maybe too complex for
the data. Your model is very likely suffering from (quasi) complete
separation.

Besides the large variances, you should also be alarmed by the near perfect
correlations among some random effects.

Best regards,



ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>

2018-03-05 20:24 GMT+01:00 cumuluss <cumuluss at gmx.de>:

> Hello,
> the result of my GLMM with binomial error structure revealed for one of
> the random intercepts and slopes variances and Sd's larger then 1
>
> > Generalized linear mixed model fit by maximum likelihood (Laplace
> Approximation) ['glmerMod']
> >  Family: binomial  ( logit )
> > Formula: obs.yn ~ z.lengthxyz + z.obsX + Spe_tr_subspecie + (1 | commu) +
> >     (1 + z.lengthxyz + z.obsX | Siteun) + (1 + z.lengthxyz +
> >     z.obsX + Spe_tr_subspecie_a.c + Spe_tr_subspecie_b.c +
> >     Spe_tr_subspecie_c.c | behavior)
>
> > Random effects:
> >  Groups   Name                  Variance Std.Dev. Corr
> >  commu    (Intercept)           0.614004 0.78358
> >  Siteun   (Intercept)           0.521198 0.72194
> >           z.lengthxyz           0.001016 0.03188   1.00
> >           z.obsX                0.306931 0.55401  -0.17 -0.19
> >  behavior (Intercept)           2.966139 1.72225
> >           z.lengthxyz           0.030171 0.17370   0.77
> >           z.obsX                0.412169 0.64200   0.20 -0.36
> >           Spe_tr_subspecie_a.c  1.853903 1.36158   0.58  0.62  0.11
> >           Spe_tr_subspecie_b.c  3.973439 1.99335   0.51  0.23  0.25  0.65
> >           Spe_tr_subspecie_c.c  7.401343 2.72054   0.39  0.30  0.47
> 0.79  0.60
> > Number of obs: 4413, groups:  commu, 144; Siteun, 108; behavior, 31
>
> Now I wonder, whether that is a reason to worry, that the result could
> be not valid?
> Thanks in advance for any comments!
> Paul
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Tue Mar  6 09:45:55 2018
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Tue, 6 Mar 2018 09:45:55 +0100
Subject: [R-sig-ME] 
 How do I account for Unbalanced Observation-per-group in
 Linear Mixed Effect Models?
In-Reply-To: <kcim.5a9922a0.4d0e.78d2ae430350469e@ucsmail01.ad.igb-berlin.de>
References: <kcim.5a9922a0.4d0e.78d2ae430350469e@ucsmail01.ad.igb-berlin.de>
Message-ID: <CAJuCY5yEQW9TD4HbQQs2PgM=8bCZfzFg8BKLv5XWR8iQV8fdkg@mail.gmail.com>

Dear Alessandro,

You don't have to account for the different number of observations. The
random effects structures takes into account that the observations are not
independent. A river with twice the number of  observations will have more
influence, but probably less than twice. How much will depend on the
variance of the random effect.

You might want to read Zuur et al (2009) Mixed Effects Models and
Extensions in Ecology with R

Best regards,


ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>

2018-03-02 11:08 GMT+01:00 Alessandro Manfrin <manfrin at igb-berlin.de>:

> Dear all,
>
> I have a dataset of fish collected in different rivers over different
> years each of them sampled a different number of times during different
> projects .
> This different number of observations among rivers in some cases can be
> important:
> For example:
> River X = 1 project (1 observation=1 sampling x 1 year);
> River Y = 5 projects (15 observations= 1 sampling x 3 years x 5 projects);
> River Z= 15 projects (105 observations=1 sampling x 7 years x 15 projects);
> I want to calculate in the all region (so not interested in specific
> rivers) how the abundance is related to Years, Latitude, Altitude and
> Anthopic pressures (APindex). I thought to use the following model:
>  lme: Abu~Years+Latitude+Altitude+APindex + (1|river/project) + corrARMA
> (form = Years|River/project).
>  -What is the influence of RiverZ with its 105 observation compared to the
> other rivers which have less number of observations?
> -Am I accounting for this unbalanced observations in the random structure
> (1|river/project)?
> -Do I have to account in the model for the different number of
> observations with (weight=1/n observation for each project?)
>  Thank you
>
>
>
> Dr. Alessandro Manfrin
>
> University of Applied Sciences Trier, Umwelt Campus Birkenfeld/
> University of Duisburg-Essen, Faculty of Biology
>
> Working place:
> Department of Aquatic Ecology
> Room S05 T03 B02
> Universit?tsstr. 5
> 45141 Essen (DE)
> Tel.: +49 (0)201/183-3113
> Fax: +49 (0)201/183-2179
>
>
>
>
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Tue Mar  6 10:20:08 2018
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Tue, 6 Mar 2018 10:20:08 +0100
Subject: [R-sig-ME] Mixed model on few individuals
In-Reply-To: <CANiGZfVq7zRwFnV1m2ggdLBQ1961mOHB4s4LC2LxSFoOdHPZJA@mail.gmail.com>
References: <CANiGZfVq7zRwFnV1m2ggdLBQ1961mOHB4s4LC2LxSFoOdHPZJA@mail.gmail.com>
Message-ID: <CAJuCY5wbf9ShpSXfN-d0Nu1uiWw4PPMbT1p12omfd+XBX7B4_g@mail.gmail.com>

Dear Simon,

Interesting problem. 3 individuals is too small for a random effect of
individual see
http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#should-i-treat-factor-xxx-as-fixed-or-random

However you still have 51 trials. So that would be relevant to include as a
random effect. The azimuth and elevation are your response variables? In
that case you rather have temporal autocorrelation. The nlme package has
several models for temporal autocorrelation among the residuals. The INLA
package provides models where the random effects have temporal
autocorrelation.

Best regards,


ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>

2018-02-26 9:28 GMT+01:00 Simon POTIER <sim.potier at gmail.com>:

> Dear all,
>
> First, I will try to be the most comprehensible, if not, do not hesitate to
> ask for more information.
>
> I am working on a project with collaborators, and I am trying to analyse
> the data. For one question, however, I do not feel confident with my
> method, but I do not know how I can analyse the data in a different way.
>
> We are working on visual fixation of a prey while hunting, with a new
> method of high accuracy. This method is very interesting but implies that
> we cannot use many individuals (because of different things that are not of
> interest here I think).
>
> My major problem here is that I have "only" 3 individuals and 51 trials
> (almost equilibrate per individual).
> I also have 3 different conditions (i.e. 3 types of prey). All these
> conditions have been repeated for the 3 individuals.
> In total, the dataset is relatively large as I have more than 6000 points
> (large for behavioural study), but, as I wrote, with only 3 individuals.
>
> Regarding this type of dataset, I am wondering whether I can use mixed
> model to compare the visual fixation according to the different conditions.
> So here are my two questions :
>
> 1) Can I use mixed models with only 3 individuals? If not, do you know if I
> can use another model? Or should I compare each individual independently?
>
> 2) My data are spatio-temporal (visual fixation in times: One Azimuth and
> one elevation every X sec). How can I implement this autocorrelation in my
> model?
>
> I am sincerely grateful if someone can be of any help. Sorry If similar
> question has been posted before, I did not find it.
>
> Best regards,
>
> Simon Potier
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From j.hadfield at ed.ac.uk  Tue Mar  6 10:49:19 2018
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Tue, 6 Mar 2018 09:49:19 +0000
Subject: [R-sig-ME] 
 Estimates for groups within fixed effects & also: enough
 info for estimating variance? MCMCglmm
In-Reply-To: <20180305110838.Horde.YjaNi7aLLjqURscO0WF4OQ3@webmail.rice.edu>
References: <20180305110838.Horde.YjaNi7aLLjqURscO0WF4OQ3@webmail.rice.edu>
Message-ID: <7b01f76c-18af-78b9-aec1-3287b9916006@ed.ac.uk>

Hi,

1/ It is not a good idea to remove the intercept in this instance. It is 
forcing the regressions to go through the origin so that when Zdbh and 
Znnd are zero the probability of being in either class is 50:50 (0 on 
the logit scale). The random effects are not deviations from the first 
species but deviations from the average species. Only with fixed effects 
are the contrasts (usually) with the first level. If you want random 
slopes you need to replace ~species with us(Znnd):species but with only 
23 species and a categorical response you will probably not get very 
precise estimates.

2/ i.i.d species effects are often hard to separate from 
phylogenetically correlated species effects, and the phylogenetic 
heritability (aka Pagel's lambda) is often poorly estimated. This is 
particularly the case with categorical response variables and you have 
the added difficulty that numerical issues are often encountered if 
there is support for heritabilities close to one. Presumably there is 
variation in the outcome within species? If you do encounter numerical 
problems then you can use trunc=TRUE in the call to MCMCglmm which keeps 
the latent variable from going into extreme-probability territory or you 
can assume the heritability=1 by using MCMCgmmRAM:

http://jarrod.bio.ed.ac.uk/MCMCglmmRAM_2.24.tar.gz

If you have a lot of replication within species (?) my feeling is that 
you can probably get away with fitting both terms.

Cheers,

Jarrod





On 05/03/2018 17:08, Drager, Andrea Pilar wrote:
>
> Hi all,
>
> I've fitted a model with a binary response at the individual level, 
> two continuous fixed effects (measured at the individual level but 
> containing info on 23 species), and a single random effect of 
> "species". My model is mixing well and the results fit the data, but 
> what I am really interested in is getting estimates for the fixed 
> effect by species, rather than globally.
>
> It is my understanding (per a 2016 reply to a post to this list: 
> parameter estimates for all factor levels MCMCglmm) that by 
> suppressing the intercept here, I am estimating the first "level" (one 
> species?) for each effect, and that the remaining effects are 
> deviations from these levels.? How do I code random slopes and 
> intercepts for species within each of the fixed effects, rather than 
> deviations from a common distribution?
>
> priorS = list(R = list(V = 1, nu = 0, fix = 1),? G = list(G1 = list(V 
> = 1, nu = 0.002)))
>
> smodel <-MCMCglmm(fl~? -1 + Zdbh + Znnd,
> ????????????????? random = ~ species,
> ????????????????? family = "categorical", verbose=F, pr = TRUE, 
> start=list(QUASI=FALSE),
> ????????????????? data=IHF,prior=priorS,
> ????????????????? nitt=500000,burnin=5000,thin=100)
>
>
> A second part of the question is that I would like to include a random 
> effect to measure the influence of phylogenetic autocorrelation. I 
> know how to code this using a distance matrix (see below), however, I 
> am concerned that statistically, "species" and "phylo" may not have 
> enough information to partition the variance in a meaningful way. 
> Perhaps running three models (random=species, random=phylo, 
> random=species + phylo) and comparing goodness-of-fit could be useful? 
> I would greatly appreciate any insight. Many thanks!
>
> prior = list(R = list(V = 1, nu = 0, fix = 1), G = list(G1 = list(V = 
> 1,nu = 0.002),
> G2=list(V=1,nu=0.002)))
>
> model <-MCMCglmm(fl ~ Zdbh_mm + Znnd,
> ???????????????? random = ~species + phylo,
> ???????????????? family = "categorical", verbose=F, pr = TRUE, 
> start=list(QUASI=FALSE),
> ginverse=list(phylo=inv.phylo$Ainv),data=IHF,prior=prior,
> ???????????????? nitt=500000,burnin=5000,thin=100)
> Andrea Pilar Drager
> PhD. student
> Ecology and Evolutionary Biology, Rice University
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From thierry.onkelinx at inbo.be  Tue Mar  6 11:19:36 2018
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Tue, 6 Mar 2018 11:19:36 +0100
Subject: [R-sig-ME] Large variance and SD for random effects
In-Reply-To: <5A9E672B.7070304@gmx.de>
References: <CAFvg1=vdVbz28pw9B6GrOXNsnceXK3UgXksMDwJUOQ9PYoLK_g@mail.gmail.com>
 <5A967E70.7010609@maw.ru.nl> <5A967FC8.8040700@maw.ru.nl>
 <5A9D9972.7090204@gmx.de>
 <CAJuCY5zyjn5weaimxRU47jr8O0uBv5wdrPt4ctRzt=ri9j=W7w@mail.gmail.com>
 <5A9E672B.7070304@gmx.de>
Message-ID: <CAJuCY5x36smmJmqgtHg+SE7e57cGp=gQy++SUzEc3uMk9gc+MQ@mail.gmail.com>

Dear Paul,

Yes, I see no point in keeping an unstable model. Remember "All models are
wrong but some are useful" (Box, 1979). I'd investigate where the complete
separation occurs and decide which random slope should be removed.

In case of the strong correlations among random effects see
https://www.muscardinus.be/2018/02/highly-correlated-random-effects/

Best regards,


ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>

2018-03-06 11:02 GMT+01:00 cumuluss <cumuluss at gmx.de>:

> Dear Thierry,
> sorry one more question. i would like to ask whether you could give me
> some recommendation for my model. Would you skip random effects (or
> slopes) even if you think they are necessary, as far as they lead to
> suffering models? It is maybe a more general question.
> Thank you!
>
>
>
>
> Dear Thierry,
> thank you for your answer!
> Ok then I have to rethink the model.
> Best regards
> Paul
>
>
>
> Thierry Onkelinx:
> > Dear Paul,
> >
> > Your random effect structure looks quite complicated. Maybe too complex
> for
> > the data. Your model is very likely suffering from (quasi) complete
> > separation.
> >
> > Besides the large variances, you should also be alarmed by the near
> perfect
> > correlations among some random effects.
> >
> > Best regards,
> >
> >
> >
> > ir. Thierry Onkelinx
> > Statisticus / Statistician
> >
> > Vlaamse Overheid / Government of Flanders
> > INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
> AND
> > FOREST
> > Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> > thierry.onkelinx at inbo.be
> > Havenlaan 88 bus 73, 1000 Brussel
> > www.inbo.be
> >
> > ////////////////////////////////////////////////////////////
> ///////////////////////////////
> > To call in the statistician after the experiment is done may be no more
> > than asking him to perform a post-mortem examination: he may be able to
> say
> > what the experiment died of. ~ Sir Ronald Aylmer Fisher
> > The plural of anecdote is not data. ~ Roger Brinner
> > The combination of some data and an aching desire for an answer does not
> > ensure that a reasonable answer can be extracted from a given body of
> data.
> > ~ John Tukey
> > ////////////////////////////////////////////////////////////
> ///////////////////////////////
> >
> > <https://www.inbo.be>
> >
> > 2018-03-05 20:24 GMT+01:00 cumuluss <cumuluss at gmx.de>:
> >
> >> Hello,
> >> the result of my GLMM with binomial error structure revealed for one of
> >> the random intercepts and slopes variances and Sd's larger then 1
> >>
> >>> Generalized linear mixed model fit by maximum likelihood (Laplace
> >> Approximation) ['glmerMod']
> >>>  Family: binomial  ( logit )
> >>> Formula: obs.yn ~ z.lengthxyz + z.obsX + Spe_tr_subspecie + (1 |
> commu) +
> >>>     (1 + z.lengthxyz + z.obsX | Siteun) + (1 + z.lengthxyz +
> >>>     z.obsX + Spe_tr_subspecie_a.c + Spe_tr_subspecie_b.c +
> >>>     Spe_tr_subspecie_c.c | behavior)
> >>
> >>> Random effects:
> >>>  Groups   Name                  Variance Std.Dev. Corr
> >>>  commu    (Intercept)           0.614004 0.78358
> >>>  Siteun   (Intercept)           0.521198 0.72194
> >>>           z.lengthxyz           0.001016 0.03188   1.00
> >>>           z.obsX                0.306931 0.55401  -0.17 -0.19
> >>>  behavior (Intercept)           2.966139 1.72225
> >>>           z.lengthxyz           0.030171 0.17370   0.77
> >>>           z.obsX                0.412169 0.64200   0.20 -0.36
> >>>           Spe_tr_subspecie_a.c  1.853903 1.36158   0.58  0.62  0.11
> >>>           Spe_tr_subspecie_b.c  3.973439 1.99335   0.51  0.23  0.25
> 0.65
> >>>           Spe_tr_subspecie_c.c  7.401343 2.72054   0.39  0.30  0.47
> >> 0.79  0.60
> >>> Number of obs: 4413, groups:  commu, 144; Siteun, 108; behavior, 31
> >>
> >> Now I wonder, whether that is a reason to worry, that the result could
> >> be not valid?
> >> Thanks in advance for any comments!
> >> Paul
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Tue Mar  6 16:37:57 2018
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Tue, 6 Mar 2018 16:37:57 +0100
Subject: [R-sig-ME] 
 Longitudinal logistic regression with continuous-time
 first-order autocorrelation structure
In-Reply-To: <CAFvg1=t0PeM+Yyv5BwKa8fPAyXBF_9MkX6b0TK90pLZCBz5QFg@mail.gmail.com>
References: <CAFvg1=tD0t0eH-ZpWc+qOVJ49RHZLHephSkjtGFYuWtTgVynjg@mail.gmail.com>
 <CAJuCY5ykmYVVvKJfnDpK2_hYPrjP5iUK=xSTxZxzvThUj=HmAA@mail.gmail.com>
 <CAFvg1=t0PeM+Yyv5BwKa8fPAyXBF_9MkX6b0TK90pLZCBz5QFg@mail.gmail.com>
Message-ID: <CAJuCY5yqKw8LxFrWnOXcTzqpcTMHg80c5+wdJivoC4bNVuAM2A@mail.gmail.com>

Dear Dennis,

You converted the time in factors, making it a discrete and regular spaced.
The Ornstein-Uhlenbeck process is the continuous version of 'ar1'. I'm more
familiar with `ar1` and `rw1`, so I didn't look at the Ornstein-Uhlenbeck
process. Note that INLA has an Ornstein-Uhlenbeck process ("ou"), so feel
free to try that as well.

f(Hour, model = "rw1") is the common pattern for all participants. f(HourID,
model = "rw1", replicate = ID) allows for a separate pattern for each
participant but with the same hyperparameters. When f(Hour, model = "rw1")
is the non-linear analogue for a fixed slope Hour, then f(HourID, model =
"rw1", replicate = ID) is then non-linear analogue for the random slope
(Hour|ID).

Several options to include the day effect. A simple one is to assume that
the between day effect is orthogonal to the within day effect. In that case
you simple at Day in some relevant form to the model e.g. Day, poly(Day,
2), f(Day, model = "rw1"), ... Another extreme is to use f(DayTime, model =
"rw1") with DayTime = Day + Hour / 24. This creates a smooth transition
between consecutive days but does not force a diurnal pattern.

Best regards,


ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>

2018-03-03 8:44 GMT+01:00 Dennis Ruenger <dennis.ruenger at gmail.com>:

> Thank you, Thierry, for the INLA model.
>
> Can you tell me why you chose a random walk rather than, say, an
> Ornstein-Uhlenbeck process, to model temporal autocorrelation? The INLA
> documentation that I could find online is rather sparse, and I struggle
> with how you model the hierarchical structure, that is f(HourID, model =
> "rw1", replicate = ID). Lastly, can you tell me how you would incorporate
> an effect of Day in the model? I?m expecting that the likelihood of craving
> decreases across days, and that this trend varies between participants.
>
> Dennis
>
> On Mar 2, 2018 at 2:36 AM, Thierry Onkelinx <thierry.onkelinx at inbo.be>
> wrote:
>
>
> Dear Dennis,
>
> Here is an example on how to run such a model with INLA. It took about 3.5
> min on my laptop.
>
> library(INLA)
> library(ggplot2)
> set.seed(20180302)
> n_id <- 35
> n_day <- 7 * 6
> n_prompt <- 5
> dataset <- expand.grid(
>   ID = seq_len(n_id),
>   Day = seq_len(n_day),
>   Prompt = seq_len(n_prompt)
> )
> dataset$Hour <- sample(8:22, size = nrow(dataset), replace = TRUE)
> p0 <- rnorm(n_id, mean = -21, sd = 0.5)
> p1 <- rnorm(n_id, mean = 2.67, sd = 0.05)
> p2 <- rnorm(n_id, mean = -0.08, sd = 0.002)
> dataset$eta <-  p2[dataset$ID] * dataset$Hour ^ 2 + p1[dataset$ID] *
> dataset$Hour + p0[dataset$ID]
> dataset$mu <- plogis(dataset$eta)
> ggplot(dataset, aes(x = Hour, y = mu, group = ID)) + geom_line()
> dataset$noise <- rnorm(nrow(dataset), sd = 0.1)
> dataset$prob <- plogis(dataset$eta + dataset$noise)
> dataset$Craving <- rbinom(nrow(dataset), size = 1, prob = dataset$prob)
>
> dataset$HourID <- dataset$Hour
> model <- inla(
>   Craving ~
>     f(Hour, model = "rw1") +
>     f(HourID, model = "rw1", replicate = ID),
>   family = "binomial",
>   data = dataset
> )
> plot(model)
>
> Best regards,
>
> Thierry
>
>
> ir. Thierry Onkelinx
> Statisticus / Statistician
>
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
> FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Havenlaan 88
> <https://maps.google.com/?q=Havenlaan+88&entry=gmail&source=g> bus 73,
> 1000 Brussel
> www.inbo.be
>
> ////////////////////////////////////////////////////////////
> ///////////////////////////////
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
> ////////////////////////////////////////////////////////////
> ///////////////////////////////
>
> <https://www.inbo.be>
>
> 2018-03-01 2:44 GMT+01:00 Dennis Ruenger <dennis.ruenger at gmail.com>:
>
>> Thanks, Alain and Ben, for your replies.
>>
>> My understanding is that for the kind of intensive longitudinal data I'm
>> dealing with, a mixed model with both random intercepts and slopes for the
>> time effect *and *autoregressive errors are recommended.
>>
>> I'd like to follow Alain's suggestion and give glmmTMB a try. Based on a
>> description of the covariance structures available with glmmTMB (link
>> below), it looks like the Ornstein?Uhlenbeck covariance structure might be
>> what I'm looking for (i.e., something akin to corrCAR1() that works in a
>> GLMM).
>>
>> So I tried:
>>
>> df$time_hours <- numFactor(df$time_hours)
>> fit  <- glmmTMB(y ~ time_hours + (time_hours|id) + ou(time_hours-1|id),
>> family = binomial, data = df)
>>
>> However, after about 10 minutes, I receive an error message about failed
>> memory allocation (on a laptop with a 7th gen Intel Core i5 processor and
>> 8GB RAM). The data set includes 34 participants with up to 300 data points
>> per participants. Running the model for a subset of 5 participants also
>> resulted in memory allocation failure. The same was true for the spatial
>> Gaussian and spatial exponential covariance structures.
>>
>> Does anyone see a way to make this work with glmmTMB?
>>
>> Thanks a lot.
>>
>> https://cran.r-project.org/web/packages/glmmTMB/vignettes/covstruct.html
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>

	[[alternative HTML version deleted]]


From cumuluss at gmx.de  Tue Mar  6 11:02:00 2018
From: cumuluss at gmx.de (cumuluss)
Date: Tue, 06 Mar 2018 10:02:00 +0000
Subject: [R-sig-ME] Large variance and SD for random effects
In-Reply-To: <CAJuCY5zyjn5weaimxRU47jr8O0uBv5wdrPt4ctRzt=ri9j=W7w@mail.gmail.com>
References: <CAFvg1=vdVbz28pw9B6GrOXNsnceXK3UgXksMDwJUOQ9PYoLK_g@mail.gmail.com>
 <5A967E70.7010609@maw.ru.nl> <5A967FC8.8040700@maw.ru.nl>
 <5A9D9972.7090204@gmx.de>
 <CAJuCY5zyjn5weaimxRU47jr8O0uBv5wdrPt4ctRzt=ri9j=W7w@mail.gmail.com>
Message-ID: <5A9E672B.7070304@gmx.de>

Dear Thierry,
sorry one more question. i would like to ask whether you could give me
some recommendation for my model. Would you skip random effects (or
slopes) even if you think they are necessary, as far as they lead to
suffering models? It is maybe a more general question.
Thank you!




Dear Thierry,
thank you for your answer!
Ok then I have to rethink the model.
Best regards
Paul



Thierry Onkelinx:
> Dear Paul,
> 
> Your random effect structure looks quite complicated. Maybe too complex for
> the data. Your model is very likely suffering from (quasi) complete
> separation.
> 
> Besides the large variances, you should also be alarmed by the near perfect
> correlations among some random effects.
> 
> Best regards,
> 
> 
> 
> ir. Thierry Onkelinx
> Statisticus / Statistician
> 
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
> FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Havenlaan 88 bus 73, 1000 Brussel
> www.inbo.be
> 
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
> ///////////////////////////////////////////////////////////////////////////////////////////
> 
> <https://www.inbo.be>
> 
> 2018-03-05 20:24 GMT+01:00 cumuluss <cumuluss at gmx.de>:
> 
>> Hello,
>> the result of my GLMM with binomial error structure revealed for one of
>> the random intercepts and slopes variances and Sd's larger then 1
>>
>>> Generalized linear mixed model fit by maximum likelihood (Laplace
>> Approximation) ['glmerMod']
>>>  Family: binomial  ( logit )
>>> Formula: obs.yn ~ z.lengthxyz + z.obsX + Spe_tr_subspecie + (1 | commu) +
>>>     (1 + z.lengthxyz + z.obsX | Siteun) + (1 + z.lengthxyz +
>>>     z.obsX + Spe_tr_subspecie_a.c + Spe_tr_subspecie_b.c +
>>>     Spe_tr_subspecie_c.c | behavior)
>>
>>> Random effects:
>>>  Groups   Name                  Variance Std.Dev. Corr
>>>  commu    (Intercept)           0.614004 0.78358
>>>  Siteun   (Intercept)           0.521198 0.72194
>>>           z.lengthxyz           0.001016 0.03188   1.00
>>>           z.obsX                0.306931 0.55401  -0.17 -0.19
>>>  behavior (Intercept)           2.966139 1.72225
>>>           z.lengthxyz           0.030171 0.17370   0.77
>>>           z.obsX                0.412169 0.64200   0.20 -0.36
>>>           Spe_tr_subspecie_a.c  1.853903 1.36158   0.58  0.62  0.11
>>>           Spe_tr_subspecie_b.c  3.973439 1.99335   0.51  0.23  0.25  0.65
>>>           Spe_tr_subspecie_c.c  7.401343 2.72054   0.39  0.30  0.47
>> 0.79  0.60
>>> Number of obs: 4413, groups:  commu, 144; Siteun, 108; behavior, 31
>>
>> Now I wonder, whether that is a reason to worry, that the result could
>> be not valid?
>> Thanks in advance for any comments!
>> Paul
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From cumuluss at gmx.de  Tue Mar  6 17:56:00 2018
From: cumuluss at gmx.de (cumuluss)
Date: Tue, 06 Mar 2018 16:56:00 +0000
Subject: [R-sig-ME] Large variance and SD for random effects
In-Reply-To: <CAJuCY5x36smmJmqgtHg+SE7e57cGp=gQy++SUzEc3uMk9gc+MQ@mail.gmail.com>
References: <CAFvg1=vdVbz28pw9B6GrOXNsnceXK3UgXksMDwJUOQ9PYoLK_g@mail.gmail.com>
 <5A967E70.7010609@maw.ru.nl> <5A967FC8.8040700@maw.ru.nl>
 <5A9D9972.7090204@gmx.de>
 <CAJuCY5zyjn5weaimxRU47jr8O0uBv5wdrPt4ctRzt=ri9j=W7w@mail.gmail.com>
 <5A9E672B.7070304@gmx.de>
 <CAJuCY5x36smmJmqgtHg+SE7e57cGp=gQy++SUzEc3uMk9gc+MQ@mail.gmail.com>
Message-ID: <5A9EC842.6010308@gmx.de>

Dear Thierry,
thank you for your answer and especially for the quotation.
I will follow your suggestion.
Best regards
Paul



Thierry Onkelinx:
> Dear Paul,
> 
> Yes, I see no point in keeping an unstable model. Remember "All models are
> wrong but some are useful" (Box, 1979). I'd investigate where the complete
> separation occurs and decide which random slope should be removed.
> 
> In case of the strong correlations among random effects see
> https://www.muscardinus.be/2018/02/highly-correlated-random-effects/
> 
> Best regards,
> 
> 
> ir. Thierry Onkelinx
> Statisticus / Statistician
> 
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
> FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Havenlaan 88 bus 73, 1000 Brussel
> www.inbo.be
> 
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
> ///////////////////////////////////////////////////////////////////////////////////////////
> 
> <https://www.inbo.be>
> 
> 2018-03-06 11:02 GMT+01:00 cumuluss <cumuluss at gmx.de>:
> 
>> Dear Thierry,
>> sorry one more question. i would like to ask whether you could give me
>> some recommendation for my model. Would you skip random effects (or
>> slopes) even if you think they are necessary, as far as they lead to
>> suffering models? It is maybe a more general question.
>> Thank you!
>>
>>
>>
>>
>> Dear Thierry,
>> thank you for your answer!
>> Ok then I have to rethink the model.
>> Best regards
>> Paul
>>
>>
>>
>> Thierry Onkelinx:
>>> Dear Paul,
>>>
>>> Your random effect structure looks quite complicated. Maybe too complex
>> for
>>> the data. Your model is very likely suffering from (quasi) complete
>>> separation.
>>>
>>> Besides the large variances, you should also be alarmed by the near
>> perfect
>>> correlations among some random effects.
>>>
>>> Best regards,
>>>
>>>
>>>
>>> ir. Thierry Onkelinx
>>> Statisticus / Statistician
>>>
>>> Vlaamse Overheid / Government of Flanders
>>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
>> AND
>>> FOREST
>>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
>>> thierry.onkelinx at inbo.be
>>> Havenlaan 88 bus 73, 1000 Brussel
>>> www.inbo.be
>>>
>>> ////////////////////////////////////////////////////////////
>> ///////////////////////////////
>>> To call in the statistician after the experiment is done may be no more
>>> than asking him to perform a post-mortem examination: he may be able to
>> say
>>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>>> The plural of anecdote is not data. ~ Roger Brinner
>>> The combination of some data and an aching desire for an answer does not
>>> ensure that a reasonable answer can be extracted from a given body of
>> data.
>>> ~ John Tukey
>>> ////////////////////////////////////////////////////////////
>> ///////////////////////////////
>>>
>>> <https://www.inbo.be>
>>>
>>> 2018-03-05 20:24 GMT+01:00 cumuluss <cumuluss at gmx.de>:
>>>
>>>> Hello,
>>>> the result of my GLMM with binomial error structure revealed for one of
>>>> the random intercepts and slopes variances and Sd's larger then 1
>>>>
>>>>> Generalized linear mixed model fit by maximum likelihood (Laplace
>>>> Approximation) ['glmerMod']
>>>>>  Family: binomial  ( logit )
>>>>> Formula: obs.yn ~ z.lengthxyz + z.obsX + Spe_tr_subspecie + (1 |
>> commu) +
>>>>>     (1 + z.lengthxyz + z.obsX | Siteun) + (1 + z.lengthxyz +
>>>>>     z.obsX + Spe_tr_subspecie_a.c + Spe_tr_subspecie_b.c +
>>>>>     Spe_tr_subspecie_c.c | behavior)
>>>>
>>>>> Random effects:
>>>>>  Groups   Name                  Variance Std.Dev. Corr
>>>>>  commu    (Intercept)           0.614004 0.78358
>>>>>  Siteun   (Intercept)           0.521198 0.72194
>>>>>           z.lengthxyz           0.001016 0.03188   1.00
>>>>>           z.obsX                0.306931 0.55401  -0.17 -0.19
>>>>>  behavior (Intercept)           2.966139 1.72225
>>>>>           z.lengthxyz           0.030171 0.17370   0.77
>>>>>           z.obsX                0.412169 0.64200   0.20 -0.36
>>>>>           Spe_tr_subspecie_a.c  1.853903 1.36158   0.58  0.62  0.11
>>>>>           Spe_tr_subspecie_b.c  3.973439 1.99335   0.51  0.23  0.25
>> 0.65
>>>>>           Spe_tr_subspecie_c.c  7.401343 2.72054   0.39  0.30  0.47
>>>> 0.79  0.60
>>>>> Number of obs: 4413, groups:  commu, 144; Siteun, 108; behavior, 31
>>>>
>>>> Now I wonder, whether that is a reason to worry, that the result could
>>>> be not valid?
>>>> Thanks in advance for any comments!
>>>> Paul
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>
>>>       [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From andrea.p.drager at rice.edu  Wed Mar  7 18:29:54 2018
From: andrea.p.drager at rice.edu (Drager, Andrea Pilar)
Date: Wed, 07 Mar 2018 11:29:54 -0600
Subject: [R-sig-ME] 
 Estimates for groups within fixed effects & also: enough
 info for estimating variance? MCMCglmm
In-Reply-To: <7b01f76c-18af-78b9-aec1-3287b9916006@ed.ac.uk>
References: <20180305110838.Horde.YjaNi7aLLjqURscO0WF4OQ3@webmail.rice.edu>
 <7b01f76c-18af-78b9-aec1-3287b9916006@ed.ac.uk>
Message-ID: <20180307112954.Horde.2GYMWm0805Ym5i_0SJYCwA2@webmail.rice.edu>

Hi Jarrod,

Thanks so much for your reply & patience with my lack of stats/math saavy.

If fitting the model to include us(Znnd):species, I'm unsure of how to  
specify the prior. Based on your Course Notes, I've tried:
priorI= list(R = list(V = 1, nu = 0, fix = 1), G = list(G1 = list(V =  
diag(2) * 0.02, nu = 2),
+                  G2 = list(V = 1,nu = 0.002)))


Where (G1 = list(V = diag(2) * 0.02, nu = 2) represents a 2 X 2 matrix  
of distances between individuals X species Is this the correct matrix  
size, since Znnd is continuous? It was hard to extrapolate from the  
us(1+time:chick) data as there were only two time points per  
chick...but I understand that with categorical predictors, you would  
have a matrix that is the size of the number of categories.

Would it be possible to walk me through how to specify nu? For  
example, the difference between specifying nu=dim(V)+1 vs nu=dim(V)? I  
see us() examples with both and am unclear as to their relative merits  
other than their both being attempting  to be uninformative?

Also, my response variable contains high replication (>1000) for the  
majority of species but very low replication for a few (16, 20, 24),  
and is very skewed towards having more zeroes than ones overall.

I have yet to follow up on your suggestions for part 2.

Many thanks,

Andrea



Quoting Jarrod Hadfield <j.hadfield at ed.ac.uk>:

> Hi,
>
> 1/ It is not a good idea to remove the intercept in this instance.  
> It is forcing the regressions to go through the origin so that when  
> Zdbh and Znnd are zero the probability of being in either class is  
> 50:50 (0 on the logit scale). The random effects are not deviations  
> from the first species but deviations from the average species. Only  
> with fixed effects are the contrasts (usually) with the first level.  
> If you want random slopes you need to replace ~species with  
> us(Znnd):species but with only 23 species and a categorical response  
> you will probably not get very precise estimates.
>
> 2/ i.i.d species effects are often hard to separate from  
> phylogenetically correlated species effects, and the phylogenetic  
> heritability (aka Pagel's lambda) is often poorly estimated. This is  
> particularly the case with categorical response variables and you  
> have the added difficulty that numerical issues are often  
> encountered if there is support for heritabilities close to one.  
> Presumably there is variation in the outcome within species? If you  
> do encounter numerical problems then you can use trunc=TRUE in the  
> call to MCMCglmm which keeps the latent variable from going into  
> extreme-probability territory or you can assume the heritability=1  
> by using MCMCgmmRAM:
>
> http://jarrod.bio.ed.ac.uk/MCMCglmmRAM_2.24.tar.gz
>
> If you have a lot of replication within species (?) my feeling is  
> that you can probably get away with fitting both terms.
>
> Cheers,
>
> Jarrod
>
>
>
>
>
> On 05/03/2018 17:08, Drager, Andrea Pilar wrote:
>>
>> Hi all,
>>
>> I've fitted a model with a binary response at the individual level,  
>> two continuous fixed effects (measured at the individual level but  
>> containing info on 23 species), and a single random effect of  
>> "species". My model is mixing well and the results fit the data,  
>> but what I am really interested in is getting estimates for the  
>> fixed effect by species, rather than globally.
>>
>> It is my understanding (per a 2016 reply to a post to this list:  
>> parameter estimates for all factor levels MCMCglmm) that by  
>> suppressing the intercept here, I am estimating the first "level"  
>> (one species?) for each effect, and that the remaining effects are  
>> deviations from these levels.? How do I code random slopes and  
>> intercepts for species within each of the fixed effects, rather  
>> than deviations from a common distribution?
>>
>> priorS = list(R = list(V = 1, nu = 0, fix = 1),? G = list(G1 =  
>> list(V = 1, nu = 0.002)))
>>
>> smodel <-MCMCglmm(fl~? -1 + Zdbh + Znnd,
>> ????????????????? random = ~ species,
>> ????????????????? family = "categorical", verbose=F, pr = TRUE,  
>> start=list(QUASI=FALSE),
>> ????????????????? data=IHF,prior=priorS,
>> ????????????????? nitt=500000,burnin=5000,thin=100)
>>
>>
>> A second part of the question is that I would like to include a  
>> random effect to measure the influence of phylogenetic  
>> autocorrelation. I know how to code this using a distance matrix  
>> (see below), however, I am concerned that statistically, "species"  
>> and "phylo" may not have enough information to partition the  
>> variance in a meaningful way. Perhaps running three models  
>> (random=species, random=phylo, random=species + phylo) and  
>> comparing goodness-of-fit could be useful? I would greatly  
>> appreciate any insight. Many thanks!
>>
>> prior = list(R = list(V = 1, nu = 0, fix = 1), G = list(G1 = list(V  
>> = 1,nu = 0.002),
>> G2=list(V=1,nu=0.002)))
>>
>> model <-MCMCglmm(fl ~ Zdbh_mm + Znnd,
>> ???????????????? random = ~species + phylo,
>> ???????????????? family = "categorical", verbose=F, pr = TRUE,  
>> start=list(QUASI=FALSE),
>> ginverse=list(phylo=inv.phylo$Ainv),data=IHF,prior=prior,
>> ???????????????? nitt=500000,burnin=5000,thin=100)
>> Andrea Pilar Drager
>> PhD. student
>> Ecology and Evolutionary Biology, Rice University
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
> -- 
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.


Andrea Pilar Drager
PhD. student
Ecology and Evolutionary Biology, Rice University


From sim.potier at gmail.com  Wed Mar  7 19:52:59 2018
From: sim.potier at gmail.com (Simon POTIER)
Date: Wed, 7 Mar 2018 19:52:59 +0100
Subject: [R-sig-ME] Mixed model on few individuals
In-Reply-To: <CAJuCY5wbf9ShpSXfN-d0Nu1uiWw4PPMbT1p12omfd+XBX7B4_g@mail.gmail.com>
References: <CANiGZfVq7zRwFnV1m2ggdLBQ1961mOHB4s4LC2LxSFoOdHPZJA@mail.gmail.com>
 <CAJuCY5wbf9ShpSXfN-d0Nu1uiWw4PPMbT1p12omfd+XBX7B4_g@mail.gmail.com>
Message-ID: <CANiGZfU0TV4SyjjQ-rnbGV1DRE2XbFx9K3S=6fAoR0wKyHg-ug@mail.gmail.com>

Dear Thierry,

Thank you very much for this answer.

I will go for it and see the output of the models.

All the best,

Simon

2018-03-06 10:20 GMT+01:00 Thierry Onkelinx <thierry.onkelinx at inbo.be>:

> Dear Simon,
>
> Interesting problem. 3 individuals is too small for a random effect of
> individual see http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#
> should-i-treat-factor-xxx-as-fixed-or-random
>
> However you still have 51 trials. So that would be relevant to include as
> a random effect. The azimuth and elevation are your response variables? In
> that case you rather have temporal autocorrelation. The nlme package has
> several models for temporal autocorrelation among the residuals. The INLA
> package provides models where the random effects have temporal
> autocorrelation.
>
> Best regards,
>
>
> ir. Thierry Onkelinx
> Statisticus / Statistician
>
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
> FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Havenlaan 88
> <https://maps.google.com/?q=Havenlaan+88&entry=gmail&source=g> bus 73,
> 1000 Brussel
> www.inbo.be
>
> ////////////////////////////////////////////////////////////
> ///////////////////////////////
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
> ////////////////////////////////////////////////////////////
> ///////////////////////////////
>
> <https://www.inbo.be>
>
> 2018-02-26 9:28 GMT+01:00 Simon POTIER <sim.potier at gmail.com>:
>
>> Dear all,
>>
>> First, I will try to be the most comprehensible, if not, do not hesitate
>> to
>> ask for more information.
>>
>> I am working on a project with collaborators, and I am trying to analyse
>> the data. For one question, however, I do not feel confident with my
>> method, but I do not know how I can analyse the data in a different way.
>>
>> We are working on visual fixation of a prey while hunting, with a new
>> method of high accuracy. This method is very interesting but implies that
>> we cannot use many individuals (because of different things that are not
>> of
>> interest here I think).
>>
>> My major problem here is that I have "only" 3 individuals and 51 trials
>> (almost equilibrate per individual).
>> I also have 3 different conditions (i.e. 3 types of prey). All these
>> conditions have been repeated for the 3 individuals.
>> In total, the dataset is relatively large as I have more than 6000 points
>> (large for behavioural study), but, as I wrote, with only 3 individuals.
>>
>> Regarding this type of dataset, I am wondering whether I can use mixed
>> model to compare the visual fixation according to the different
>> conditions.
>> So here are my two questions :
>>
>> 1) Can I use mixed models with only 3 individuals? If not, do you know if
>> I
>> can use another model? Or should I compare each individual independently?
>>
>> 2) My data are spatio-temporal (visual fixation in times: One Azimuth and
>> one elevation every X sec). How can I implement this autocorrelation in my
>> model?
>>
>> I am sincerely grateful if someone can be of any help. Sorry If similar
>> question has been posted before, I did not find it.
>>
>> Best regards,
>>
>> Simon Potier
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>


-- 
*******************************************************
Simon Potier
Department of Biology
Lund University
S?lvegatan 35
S-22362 Lund
Sweden
*******************************************************
phone +336 11 31 67 16
sim.potier at gmail.com
https://www.simonpotier.fr
*******************************************************

	[[alternative HTML version deleted]]


From j.hadfield at ed.ac.uk  Wed Mar  7 21:11:34 2018
From: j.hadfield at ed.ac.uk (HADFIELD Jarrod)
Date: Wed, 7 Mar 2018 20:11:34 +0000
Subject: [R-sig-ME] 
 Estimates for groups within fixed effects & also: enough
 info for estimating variance? MCMCglmm
In-Reply-To: <20180307112954.Horde.2GYMWm0805Ym5i_0SJYCwA2@webmail.rice.edu>
References: <20180305110838.Horde.YjaNi7aLLjqURscO0WF4OQ3@webmail.rice.edu>
 <7b01f76c-18af-78b9-aec1-3287b9916006@ed.ac.uk>,
 <20180307112954.Horde.2GYMWm0805Ym5i_0SJYCwA2@webmail.rice.edu>
Message-ID: <VI1PR0502MB3821F81EF9251DC5675A158FACD80@VI1PR0502MB3821.eurprd05.prod.outlook.com>

Hi Andrea,


Sorry - the confusion was my fault. The syntax should have been us(1+Znnd):species not  us(Znnd):species.


For covariance matrices I tend to use parameter expanded priors of the form


V=diag(k), nu=k, alpha.mu=rep(0,k), alpha.V=diag(k)*a


where k is the dimension of the covariance matrix and a is usually something large. With categorical response I usually set a to 100. I find this prior to be reasonably uninfluential for the standard deviations and the correlation. However, it can lead to problems especially for small data sets with categorical response.  See this paper by Pierre de Villemereuil:

http://onlinelibrary.wiley.com/doi/10.1111/2041-210X.12011/full


The unbalancedness with respect to within-sepcies replication is not a problem, and you probably do have enough replication to fit both types of species effects.


Cheers,


Jarrod

________________________________
From: Drager, Andrea Pilar <andrea.p.drager at rice.edu>
Sent: 07 March 2018 17:29:54
To: HADFIELD Jarrod
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Estimates for groups within fixed effects & also: enough info for estimating variance? MCMCglmm

Hi Jarrod,

Thanks so much for your reply & patience with my lack of stats/math saavy.

If fitting the model to include us(Znnd):species, I'm unsure of how to
specify the prior. Based on your Course Notes, I've tried:
priorI= list(R = list(V = 1, nu = 0, fix = 1), G = list(G1 = list(V =
diag(2) * 0.02, nu = 2),
+                  G2 = list(V = 1,nu = 0.002)))


Where (G1 = list(V = diag(2) * 0.02, nu = 2) represents a 2 X 2 matrix
of distances between individuals X species Is this the correct matrix
size, since Znnd is continuous? It was hard to extrapolate from the
us(1+time:chick) data as there were only two time points per
chick...but I understand that with categorical predictors, you would
have a matrix that is the size of the number of categories.

Would it be possible to walk me through how to specify nu? For
example, the difference between specifying nu=dim(V)+1 vs nu=dim(V)? I
see us() examples with both and am unclear as to their relative merits
other than their both being attempting  to be uninformative?

Also, my response variable contains high replication (>1000) for the
majority of species but very low replication for a few (16, 20, 24),
and is very skewed towards having more zeroes than ones overall.

I have yet to follow up on your suggestions for part 2.

Many thanks,

Andrea



Quoting Jarrod Hadfield <j.hadfield at ed.ac.uk>:

> Hi,
>
> 1/ It is not a good idea to remove the intercept in this instance.
> It is forcing the regressions to go through the origin so that when
> Zdbh and Znnd are zero the probability of being in either class is
> 50:50 (0 on the logit scale). The random effects are not deviations
> from the first species but deviations from the average species. Only
> with fixed effects are the contrasts (usually) with the first level.
> If you want random slopes you need to replace ~species with
> us(Znnd):species but with only 23 species and a categorical response
> you will probably not get very precise estimates.
>
> 2/ i.i.d species effects are often hard to separate from
> phylogenetically correlated species effects, and the phylogenetic
> heritability (aka Pagel's lambda) is often poorly estimated. This is
> particularly the case with categorical response variables and you
> have the added difficulty that numerical issues are often
> encountered if there is support for heritabilities close to one.
> Presumably there is variation in the outcome within species? If you
> do encounter numerical problems then you can use trunc=TRUE in the
> call to MCMCglmm which keeps the latent variable from going into
> extreme-probability territory or you can assume the heritability=1
> by using MCMCgmmRAM:
>
> http://jarrod.bio.ed.ac.uk/MCMCglmmRAM_2.24.tar.gz
>
> If you have a lot of replication within species (?) my feeling is
> that you can probably get away with fitting both terms.
>
> Cheers,
>
> Jarrod
>
>
>
>
>
> On 05/03/2018 17:08, Drager, Andrea Pilar wrote:
>>
>> Hi all,
>>
>> I've fitted a model with a binary response at the individual level,
>> two continuous fixed effects (measured at the individual level but
>> containing info on 23 species), and a single random effect of
>> "species". My model is mixing well and the results fit the data,
>> but what I am really interested in is getting estimates for the
>> fixed effect by species, rather than globally.
>>
>> It is my understanding (per a 2016 reply to a post to this list:
>> parameter estimates for all factor levels MCMCglmm) that by
>> suppressing the intercept here, I am estimating the first "level"
>> (one species?) for each effect, and that the remaining effects are
>> deviations from these levels.  How do I code random slopes and
>> intercepts for species within each of the fixed effects, rather
>> than deviations from a common distribution?
>>
>> priorS = list(R = list(V = 1, nu = 0, fix = 1),  G = list(G1 =
>> list(V = 1, nu = 0.002)))
>>
>> smodel <-MCMCglmm(fl~  -1 + Zdbh + Znnd,
>>                   random = ~ species,
>>                   family = "categorical", verbose=F, pr = TRUE,
>> start=list(QUASI=FALSE),
>>                   data=IHF,prior=priorS,
>>                   nitt=500000,burnin=5000,thin=100)
>>
>>
>> A second part of the question is that I would like to include a
>> random effect to measure the influence of phylogenetic
>> autocorrelation. I know how to code this using a distance matrix
>> (see below), however, I am concerned that statistically, "species"
>> and "phylo" may not have enough information to partition the
>> variance in a meaningful way. Perhaps running three models
>> (random=species, random=phylo, random=species + phylo) and
>> comparing goodness-of-fit could be useful? I would greatly
>> appreciate any insight. Many thanks!
>>
>> prior = list(R = list(V = 1, nu = 0, fix = 1), G = list(G1 = list(V
>> = 1,nu = 0.002),
>> G2=list(V=1,nu=0.002)))
>>
>> model <-MCMCglmm(fl ~ Zdbh_mm + Znnd,
>>                  random = ~species + phylo,
>>                  family = "categorical", verbose=F, pr = TRUE,
>> start=list(QUASI=FALSE),
>> ginverse=list(phylo=inv.phylo$Ainv),data=IHF,prior=prior,
>>                  nitt=500000,burnin=5000,thin=100)
>> Andrea Pilar Drager
>> PhD. student
>> Ecology and Evolutionary Biology, Rice University
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
R-sig-mixed-models Info Page - ETH Zurich<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
stat.ethz.ch
Your email address: Your name (optional): You may enter a privacy password below. This provides only mild security, but should prevent others from messing ...



>
>
> --
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.


Andrea Pilar Drager
PhD. student
Ecology and Evolutionary Biology, Rice University


-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20180307/d3cf5bc7/attachment-0001.ksh>

From djssmith at ucdavis.edu  Thu Mar  8 20:28:30 2018
From: djssmith at ucdavis.edu (Dan Smith)
Date: Thu, 8 Mar 2018 11:28:30 -0800
Subject: [R-sig-ME] Setting Theta for NB models
Message-ID: <CAO9XZwWVyoSr0xhnhxhi62KAMfJi=ETczYGcAwcqEnRwfDMZ_w@mail.gmail.com>

Hello,

I've been working on some data that has a negative binomial distribution
(seed count data) and have a question regarding how lme4 handles theta. I
have determined the data's theta value using the equation (mean^theta =
var). I have to run a few models with different link functions to satisfy
co-author curiosity (even after having them read O'hara & Kotze 2010). My
question is, does lme4 make a transformation to the theta value concordant
with the link function? My assumption is that it does not, and I need to
adjust the theta in accordance with any transformations applied within the
model.

wagr1 <- glmer(WAGRcount ~ treatment + (1|treatment:plot), family =
negative.binomial(*link = "identity", theta = 2.25232*), data = wagrcores)
summary(wagr1)

wagr2 <- glmer(WAGRcount ~ treatment + (1|treatment:plot), family =
negative.binomial(*link = "log", theta = 1.8173*), data = wagrcores,control
= glmerControl(optimizer = "nloptwrap", calc.derivs = FALSE))
summary(wagr2)

Thank you,
 -Dan

	[[alternative HTML version deleted]]


From jmichaelrosenberg at gmail.com  Fri Mar  9 16:52:55 2018
From: jmichaelrosenberg at gmail.com (Joshua Rosenberg)
Date: Fri, 9 Mar 2018 10:52:55 -0500
Subject: [R-sig-ME] Question about conditional R-squared values (and its
 relationship to the intra-class correlation)
Message-ID: <CANYHYTR9y__8WUhhxUZ-YL+a9wHMvb1F7Jgrr=bzVxsm74E73g@mail.gmail.com>

Hi all, I know that R-squared values for mixed effects models are an area
of active development / some controversy. I'm wondering if anyone could
help me to understand how *conditional R-squared values*, as described by
Nakagawa and Schielzeth (2013) and as implemented in the MuMIn (and
piecewiseSEM) packages. In particular, my (very naive) thought was that the
square root of the conditional r-squared value (my understanding: the
r-squared value for both together the fixed and random effects) minus the
marginal r-squared value (the r-squared value for only the fixed effects)
would / could equal the ICC. Please excuse me if this is completely belying
a very limited understanding.

For example, for this example using the sleepstudy data, the conditional
minus the marginal, or what I thought would represent something akin to the
proportion of variance explained only by the random effects, or, in this
example, .424. The intra-class correlation for the random intercept is
.483. Can anyone help me clear about how these two values can (or could /
whether they should) be related?

library(lme4)
library(MuMIn)
library(sjstats)

m1 <- lmer(Reaction ~ Days + (1 | Subject), sleepstudy)

r_squared_vals <- MuMIn::r.squaredGLMM(m1)
# Just the conditional r-squared value (conditional - marginal)
r_squared_vals[2] - r_squared_vals[1] # .424

ICC_val <- sjstats::icc(fm1)
# The intra-class correlation (ICC) for the
ICC_val # 0.483


I ask in part because I'm interested in calculating the partial r-squared
values using the r2glmm
<https://www.google.com/search?q=r2glmm&oq=r2glmm&aqs=chrome.0.69i59j69i60l3.1051j0j7&sourceid=chrome&ie=UTF-8>
package
(and the r2beta() function) and am curious if there can be some similar
proportion of variance explained interpretation for the random effects.
Again, I'm sorry if this is not clear, obvious, or not a direction worth
pursuing fo well-understood reasons.

Thanks for considering!
Josh

-- 
Joshua Rosenberg, Ph.D. Candidate
Educational Psychology
&
 Educational Technology
Michigan State University
http://jmichaelrosenberg.com

	[[alternative HTML version deleted]]


From saroman at vims.edu  Fri Mar  9 18:04:31 2018
From: saroman at vims.edu (Sally A. Roman)
Date: Fri, 9 Mar 2018 17:04:31 +0000
Subject: [R-sig-ME] question regarding predictor variable
Message-ID: <8df2dc986e2d445e8ee870ce41f6b8d3@vims.edu>

Hi -

I have a dataset I am working with to model the proportion of fish caught at length.  I have paired observations (n=96).  The paired observations consist of a 10 minute tow and a 15 minute tow.  Data collected are length measurements in 1 mm intervals, number of fish at length, and total catch (number of baskets) for each tow.

The traditional approach to model this type of data is to use a logistic regression to model the proportion caught at length in the 10 min to the total catch at length in both tows in a pair and then have the pair as the random effect.  Traditional fixed effects are length (L) and length^2 (L2).  I would like to include total catch in the model, but am struggling with how to include the variable because there is a total catch record for each tow.  I was hoping for some guidance on if it is appropriate to include total catch for both tows or for one of the tows, if total catch between both tows is correlated as a continuous variable.


Sally Roman
Fisheries Specialist
Virginia Institute of Marine Science
Marine Advisory Services

Phone: 804-684-7165
Fax: 804-684-7161

1375 Greate Road
Gloucester Point, VA 23062


	[[alternative HTML version deleted]]


From altessedac2 at gmail.com  Fri Mar  9 23:51:39 2018
From: altessedac2 at gmail.com (C. AMAL D. GLELE)
Date: Fri, 9 Mar 2018 23:51:39 +0100
Subject: [R-sig-ME] Mixed-Model-Accounting-Spatial_Correlation
Message-ID: <CANrzCv037Mi2hR6ziY8WmOiZbE1aYEHgVF_1sLVhkWnKg-R61Q@mail.gmail.com>

Hi, dear all.
Can someone please, tell me if  there is ways to fit models (with, or not)
random effects, accounting spatial correlation and accepting numerical
and/or categorical explanatories variables?
In advance, thanks for your helps.
Best and regards,
Amal

	[[alternative HTML version deleted]]


From highstat at highstat.com  Sat Mar 10 13:15:07 2018
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Sat, 10 Mar 2018 12:15:07 +0000
Subject: [R-sig-ME] Mixed-Model-Accounting-Spatial_Correlation
In-Reply-To: <mailman.16209.9.1520679602.6446.r-sig-mixed-models@r-project.org>
References: <mailman.16209.9.1520679602.6446.r-sig-mixed-models@r-project.org>
Message-ID: <fee9b4c9-bde5-9761-6558-a9564dcda921@highstat.com>


------------------------------

Message: 3
Date: Fri, 9 Mar 2018 23:51:39 +0100
From: "C. AMAL D. GLELE" <altessedac2 at gmail.com>
To: R SIG Mixed Models <R-sig-mixed-models at r-project.org>
Subject: [R-sig-ME] Mixed-Model-Accounting-Spatial_Correlation
Message-ID:
	<CANrzCv037Mi2hR6ziY8WmOiZbE1aYEHgVF_1sLVhkWnKg-R61Q at mail.gmail.com>
Content-Type: text/plain; charset="utf-8"

Hi, dear all.
Can someone please, tell me if  there is ways to fit models (with, or not)
random effects, accounting spatial correlation and accepting numerical
and/or categorical explanatories variables?
In advance, thanks for your helps.
Best and regards,
Amal

	[[alternative HTML version deleted]]





 ?------------------------------


Amal,

The answer is 'yes'. See


https://stat.ethz.ch/pipermail/r-sig-mixed-models/2018q1/date.html


You will see about 10 posts on this topic. And see also:

https://cran.r-project.org/web/packages/glmmTMB/vignettes/covstruct.html

Kind regards,

Alain



-- 

Dr. Alain F. Zuur
Highland Statistics Ltd.
9 St Clair Wynd
AB41 6DZ Newburgh, UK
Email: highstat at highstat.com
URL:   www.highstat.com

And:
NIOZ Royal Netherlands Institute for Sea Research,
Department of Coastal Systems, and Utrecht University,
P.O. Box 59, 1790 AB Den Burg,
Texel, The Netherlands



Author of:
1. Beginner's Guide to Spatial, Temporal and Spatial-Temporal Ecological Data Analysis with R-INLA. (2017).
2. Beginner's Guide to Zero-Inflated Models with R (2016).
3. Beginner's Guide to Data Exploration and Visualisation with R (2015).
4. Beginner's Guide to GAMM with R (2014).
5. Beginner's Guide to GLM and GLMM with R (2013).
6. Beginner's Guide to GAM with R (2012).
7. Zero Inflated Models and GLMM with R (2012).
8. A Beginner's Guide to R (2009).
9. Mixed effects models and extensions in ecology with R (2009).
10. Analysing Ecological Data (2007).


From altessedac2 at gmail.com  Sun Mar 11 12:54:11 2018
From: altessedac2 at gmail.com (C. AMAL D. GLELE)
Date: Sun, 11 Mar 2018 12:54:11 +0100
Subject: [R-sig-ME] R-sig-mixed-models Digest, Vol 135, Issue 14
In-Reply-To: <mailman.16210.7.1520766002.38671.r-sig-mixed-models@r-project.org>
References: <mailman.16210.7.1520766002.38671.r-sig-mixed-models@r-project.org>
Message-ID: <CANrzCv23N6qW-437s3fOdo6WErepK4N-xsZAZ+Dhdb7uBW4eFQ@mail.gmail.com>

Dear Alain,
thank you so much.
Best and regards,
Amal

<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
Garanti
sans virus. www.avast.com
<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
<#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>

2018-03-11 12:00 GMT+01:00 <r-sig-mixed-models-request at r-project.org>:

> Send R-sig-mixed-models mailing list submissions to
>         r-sig-mixed-models at r-project.org
>
> To subscribe or unsubscribe via the World Wide Web, visit
>         https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> or, via email, send a message with subject or body 'help' to
>         r-sig-mixed-models-request at r-project.org
>
> You can reach the person managing the list at
>         r-sig-mixed-models-owner at r-project.org
>
> When replying, please edit your Subject line so it is more specific
> than "Re: Contents of R-sig-mixed-models digest..."
>
>
> Today's Topics:
>
>    1. Re: Mixed-Model-Accounting-Spatial_Correlation
>       (Highland Statistics Ltd)
>
> ----------------------------------------------------------------------
>
> Message: 1
> Date: Sat, 10 Mar 2018 12:15:07 +0000
> From: Highland Statistics Ltd <highstat at highstat.com>
> To: "r-sig-mixed-models at r-project.org"
>         <r-sig-mixed-models at r-project.org>
> Subject: Re: [R-sig-ME] Mixed-Model-Accounting-Spatial_Correlation
> Message-ID: <fee9b4c9-bde5-9761-6558-a9564dcda921 at highstat.com>
> Content-Type: text/plain; charset="windows-1252"; Format="flowed"
>
>
> ------------------------------
>
> Message: 3
> Date: Fri, 9 Mar 2018 23:51:39 +0100
> From: "C. AMAL D. GLELE" <altessedac2 at gmail.com>
> To: R SIG Mixed Models <R-sig-mixed-models at r-project.org>
> Subject: [R-sig-ME] Mixed-Model-Accounting-Spatial_Correlation
> Message-ID:
>         <CANrzCv037Mi2hR6ziY8WmOiZbE1aYEHgVF_1sLVhkWnKg-R61Q at mail.
> gmail.com>
> Content-Type: text/plain; charset="utf-8"
>
> Hi, dear all.
> Can someone please, tell me if  there is ways to fit models (with, or not)
> random effects, accounting spatial correlation and accepting numerical
> and/or categorical explanatories variables?
> In advance, thanks for your helps.
> Best and regards,
> Amal
>
>         [[alternative HTML version deleted]]
>
>
>
>
>
>   ------------------------------
>
>
> Amal,
>
> The answer is 'yes'. See
>
>
> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2018q1/date.html
>
>
> You will see about 10 posts on this topic. And see also:
>
> https://cran.r-project.org/web/packages/glmmTMB/vignettes/covstruct.html
>
> Kind regards,
>
> Alain
>
>
>
> --
>
> Dr. Alain F. Zuur
> Highland Statistics Ltd.
> 9 St Clair Wynd
> AB41 6DZ Newburgh, UK
> Email: highstat at highstat.com
> URL:   www.highstat.com
>
> And:
> NIOZ Royal Netherlands Institute for Sea Research,
> Department of Coastal Systems, and Utrecht University,
> P.O. Box 59, 1790 AB Den Burg,
> Texel, The Netherlands
>
>
>
> Author of:
> 1. Beginner's Guide to Spatial, Temporal and Spatial-Temporal Ecological
> Data Analysis with R-INLA. (2017).
> 2. Beginner's Guide to Zero-Inflated Models with R (2016).
> 3. Beginner's Guide to Data Exploration and Visualisation with R (2015).
> 4. Beginner's Guide to GAMM with R (2014).
> 5. Beginner's Guide to GLM and GLMM with R (2013).
> 6. Beginner's Guide to GAM with R (2012).
> 7. Zero Inflated Models and GLMM with R (2012).
> 8. A Beginner's Guide to R (2009).
> 9. Mixed effects models and extensions in ecology with R (2009).
> 10. Analysing Ecological Data (2007).
>
>
>
>
> ------------------------------
>
> Subject: Digest Footer
>
> _______________________________________________
> R-sig-mixed-models mailing list
> R-sig-mixed-models at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
> ------------------------------
>
> End of R-sig-mixed-models Digest, Vol 135, Issue 14
> ***************************************************

	[[alternative HTML version deleted]]


From highstat at highstat.com  Sun Mar 11 17:18:51 2018
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Sun, 11 Mar 2018 16:18:51 +0000
Subject: [R-sig-ME] Response_type_and_distribution_in_gls
In-Reply-To: <CANrzCv026WqZccFHtv3B=iy6MGgD-cC7GwDFYrBzN+mvMSTVnw@mail.gmail.com>
References: <CANrzCv026WqZccFHtv3B=iy6MGgD-cC7GwDFYrBzN+mvMSTVnw@mail.gmail.com>
Message-ID: <7c7ed4fd-a1f3-b5bb-380c-11d1aa05f0bf@highstat.com>

Amal..please email the mixed modelling mailing list rather than me 
personally.


On 11/03/2018 15:40, C. AMAL D. GLELE wrote:
> Hi, dear Alain.
> I'm reading your book "Statistics of Biology and Health" and I would 
> like to ask you the two following questions regarding its chapter 7:
> 1)
> which types of response variable can be used in gls model?
> is there a way to specify the response distribution in gls?
Please have a look at Pinheiro and Bates (2000). They have a whole 
chapter on this topic. Our 2009 book also has a chapter on it.

> 2)
> I remark that there is no distribution specified (via family) for the 
> responses used: which distribution does the program takes in account 
> for the response variable?
See: ? ?gls

It is a linear model using generalized least squares. Hence...Gaussian.

If you want to use other distributions, then see the help file of 
glmmTMB. For example, you can model the theta of the negative binomial 
or Gamma distributions as functions of covariates.

Kind regards,
Alain


> In advance, thanks foe your answers.
> Best and regards,
> Amal
>
> <https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail> 
> 	Garanti sans virus. www.avast.com 
> <https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail> 
>
>

-- 

Dr. Alain F. Zuur
Highland Statistics Ltd.
9 St Clair Wynd
AB41 6DZ Newburgh, UK
Email: highstat at highstat.com
URL:   www.highstat.com

And:
NIOZ Royal Netherlands Institute for Sea Research,
Department of Coastal Systems, and Utrecht University,
P.O. Box 59, 1790 AB Den Burg,
Texel, The Netherlands



Author of:
1. Beginner's Guide to Spatial, Temporal and Spatial-Temporal Ecological Data Analysis with R-INLA. (2017).
2. Beginner's Guide to Zero-Inflated Models with R (2016).
3. Beginner's Guide to Data Exploration and Visualisation with R (2015).
4. Beginner's Guide to GAMM with R (2014).
5. Beginner's Guide to GLM and GLMM with R (2013).
6. Beginner's Guide to GAM with R (2012).
7. Zero Inflated Models and GLMM with R (2012).
8. A Beginner's Guide to R (2009).
9. Mixed effects models and extensions in ecology with R (2009).
10. Analysing Ecological Data (2007).


	[[alternative HTML version deleted]]


From altessedac2 at gmail.com  Sun Mar 11 18:22:27 2018
From: altessedac2 at gmail.com (C. AMAL D. GLELE)
Date: Sun, 11 Mar 2018 18:22:27 +0100
Subject: [R-sig-ME] Response_type_and_distribution_in_gls
In-Reply-To: <7c7ed4fd-a1f3-b5bb-380c-11d1aa05f0bf@highstat.com>
References: <CANrzCv026WqZccFHtv3B=iy6MGgD-cC7GwDFYrBzN+mvMSTVnw@mail.gmail.com>
 <7c7ed4fd-a1f3-b5bb-380c-11d1aa05f0bf@highstat.com>
Message-ID: <CANrzCv1BBepWz+j4wXHxMOBOv1khH4yuYCDVcgkiZDwf1qAabw@mail.gmail.com>

Dear Alain,
many thanks to you for your answers.
I apologie about emailing you in particular; but it is because I thought
such a post is off-topic here.
Again, thanks.
Best and regards,

2018-03-11 17:18 GMT+01:00 Highland Statistics Ltd <highstat at highstat.com>:

> Amal..please email the mixed modelling mailing list rather than me
> personally.
>
> On 11/03/2018 15:40, C. AMAL D. GLELE wrote:
>
> Hi, dear Alain.
> I'm reading your book "Statistics of Biology and Health" and I would like
> to ask you the two following questions regarding its chapter 7:
> 1)
> which types of response variable can be used in gls model?
> is there a way to specify the response distribution in gls?
>
> Please have a look at Pinheiro and Bates (2000). They have a whole chapter
> on this topic. Our 2009 book also has a chapter on it.
>
> 2)
> I remark that there is no distribution specified (via family) for the
> responses used: which distribution does the program takes in account for
> the response variable?
>
> See:   ?gls
>
> It is a linear model using generalized least squares. Hence...Gaussian.
>
> If you want to use other distributions, then see the help file of glmmTMB.
> For example, you can model the theta of the negative binomial or Gamma
> distributions as functions of covariates.
>
> Kind regards,
> Alain
>
>
> In advance, thanks foe your answers.
> Best and regards,
> Amal
>
>
> <https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail> Garanti
> sans virus. www.avast.com
> <https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
>
>
> --
>
> Dr. Alain F. Zuur
> Highland Statistics Ltd.
> 9 St Clair Wynd
> AB41 6DZ Newburgh, UK
> Email: highstat at highstat.com
> URL:   www.highstat.com
>
> And:
> NIOZ Royal Netherlands Institute for Sea Research,
> Department of Coastal Systems, and Utrecht University,
> P.O. Box 59, 1790 AB Den Burg,
> Texel, The Netherlands
>
>
>
> Author of:
> 1. Beginner's Guide to Spatial, Temporal and Spatial-Temporal Ecological Data Analysis with R-INLA. (2017).
> 2. Beginner's Guide to Zero-Inflated Models with R (2016).
> 3. Beginner's Guide to Data Exploration and Visualisation with R (2015).
> 4. Beginner's Guide to GAMM with R (2014).
> 5. Beginner's Guide to GLM and GLMM with R (2013).
> 6. Beginner's Guide to GAM with R (2012).
> 7. Zero Inflated Models and GLMM with R (2012).
> 8. A Beginner's Guide to R (2009).
> 9. Mixed effects models and extensions in ecology with R (2009).
> 10. Analysing Ecological Data (2007).
>
>
>

	[[alternative HTML version deleted]]


From burwood70 at gmail.com  Mon Mar 12 03:35:29 2018
From: burwood70 at gmail.com (Steve Candy)
Date: Mon, 12 Mar 2018 13:35:29 +1100
Subject: [R-sig-ME] question regarding predictor variable
Message-ID: <003701d3b9aa$cb49d9f0$61dd8dd0$@gmail.com>

You have conditioned on total of fish measured in each length bin across the
two tow type so you could analyse total catch as a loglinear GLMM
independently of the analysis of proportion in 10 min tows relative to 15
min tows. I gather you want to jointly analyse proportions and total catch
because of any possible dependency (e.g. indicated by a positive
correlation) between the pair random effects from each analysis. You could
estimate both sets of random effects and plot them one against the other to
see if there is a significant correlation. If there is its not easy to see
how you could do the appropriate MV GLMM analysis because of the different
lengths of the two DVs.

 

 

"Sally A. Roman" <saroman at vims.edu <mailto:saroman at vims.edu> > wrote:

 

 

I have a dataset I am working with to model the proportion of fish caught at
length.  I have paired observations (n=96).  The paired observations consist
of a 10 minute tow and a 15 minute tow.  Data collected are length
measurements in 1 mm intervals, number of fish at length, and total catch
(number of baskets) for each tow.

 

The traditional approach to model this type of data is to use a logistic
regression to model the proportion caught at length in the 10 min to the
total catch at length in both tows in a pair and then have the pair as the
random effect.  Traditional fixed effects are length (L) and length^2 (L2).
I would like to include total catch in the model, but am struggling with how
to include the variable because there is a total catch record for each tow.
I was hoping for some guidance on if it is appropriate to include total
catch for both tows or for one of the tows, if total catch between both tows
is correlated as a continuous variable.

 

 

 

Dr Steven G. Candy

Director/Consultant

SCANDY STATISTICAL MODELLING PTY LTD

(ABN: 83 601 268 419)

70 Burwood Drive

Blackmans Bay, TASMANIA, Australia 7052

Mobile: (61) 0439284983

 


	[[alternative HTML version deleted]]


From danielbartling at gmail.com  Mon Mar 12 15:50:09 2018
From: danielbartling at gmail.com (Daniel Bartling)
Date: Mon, 12 Mar 2018 15:50:09 +0100
Subject: [R-sig-ME] Serial correlation in random effects
In-Reply-To: <CAOx9ozFOutAcm5zdBDiTBVaO1wsgRTbMmWOYVz4Dcpqhfwg9sQ@mail.gmail.com>
References: <CAOx9ozFOutAcm5zdBDiTBVaO1wsgRTbMmWOYVz4Dcpqhfwg9sQ@mail.gmail.com>
Message-ID: <CAOx9ozEP6jhjRHCpsocitNHgTDLfAuCf6EPB2PgSt-oB2vVz4g@mail.gmail.com>

Hi all,



I would love to apply linear mixed models in Risk Management as they seem
to be tailor suited to many problems we face. We often assume that for
example credit default risk is driven by observable latent random factors
and we wish to understand the dynamics of these latent factors based on
repeated historical observations. Typically, these random factors consist
of different groups (e.g. credit defaults in different industry sectors
over different time periods). The industry sectors are correlated between
each other but that are also assumed to be serially correlated over time.
For example, the state of the industry sector ?telecommunication? in year t
is the result of both the auto correlation with ?telecommunication? in year
t-1 and the year t correlation with other industry sectors like
?information technology?.



I would use the representation (-1 + sector|time) to estimate the model.


I generated dummy data based on different modeling assumptions and I am
able to estimate successfully the parameters that were used in generating
the data.



However I have some questions:



First of all, if I estimate the variance of the BLUPs, I get different
values for the variance covariance matrix than if I look directly at the
estimated variance covariance matrix as an estimation output. I understand
that there is a methodological difference between the BLUPs and the
estimated variance covariance matrix, because one is focusing on the
realized sample while the other is focused on the specific realised sample
(I found the directly estimated variance covariance to be a better fit,
while the BLUPs underestimated the variance covariance matrix). So how
valid is inference based directly on the BLUPs?



More specifically, I wish to estimate AR1 parameters for the BLUPs in order
to model the serial correlation described above. Is there a way to
determine this serial correlation of random effects directly in the
estimation with any available r package? I found many options to model
autocorrelation in the residuals but not serial correlation in the random
effects, especially when there also exists correlation between different
random effects groups.



Thank you!


Regards

Daniel Bartling

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Mon Mar 12 16:25:38 2018
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Mon, 12 Mar 2018 16:25:38 +0100
Subject: [R-sig-ME] Serial correlation in random effects
In-Reply-To: <CAOx9ozEP6jhjRHCpsocitNHgTDLfAuCf6EPB2PgSt-oB2vVz4g@mail.gmail.com>
References: <CAOx9ozFOutAcm5zdBDiTBVaO1wsgRTbMmWOYVz4Dcpqhfwg9sQ@mail.gmail.com>
 <CAOx9ozEP6jhjRHCpsocitNHgTDLfAuCf6EPB2PgSt-oB2vVz4g@mail.gmail.com>
Message-ID: <CAJuCY5woS06VnsyVpUDtgf=J7HbLWMYK1bhwHebY2+6F=ZPN9Q@mail.gmail.com>

Dear Daniel,

Have a look at the INLA package (www.r-inla.org). It allows for several
types of correlated random effects. See
http://www.r-inla.org/models/latent-models

Best regards,


ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>

2018-03-12 15:50 GMT+01:00 Daniel Bartling <danielbartling at gmail.com>:

> Hi all,
>
>
>
> I would love to apply linear mixed models in Risk Management as they seem
> to be tailor suited to many problems we face. We often assume that for
> example credit default risk is driven by observable latent random factors
> and we wish to understand the dynamics of these latent factors based on
> repeated historical observations. Typically, these random factors consist
> of different groups (e.g. credit defaults in different industry sectors
> over different time periods). The industry sectors are correlated between
> each other but that are also assumed to be serially correlated over time.
> For example, the state of the industry sector ?telecommunication? in year t
> is the result of both the auto correlation with ?telecommunication? in year
> t-1 and the year t correlation with other industry sectors like
> ?information technology?.
>
>
>
> I would use the representation (-1 + sector|time) to estimate the model.
>
>
> I generated dummy data based on different modeling assumptions and I am
> able to estimate successfully the parameters that were used in generating
> the data.
>
>
>
> However I have some questions:
>
>
>
> First of all, if I estimate the variance of the BLUPs, I get different
> values for the variance covariance matrix than if I look directly at the
> estimated variance covariance matrix as an estimation output. I understand
> that there is a methodological difference between the BLUPs and the
> estimated variance covariance matrix, because one is focusing on the
> realized sample while the other is focused on the specific realised sample
> (I found the directly estimated variance covariance to be a better fit,
> while the BLUPs underestimated the variance covariance matrix). So how
> valid is inference based directly on the BLUPs?
>
>
>
> More specifically, I wish to estimate AR1 parameters for the BLUPs in order
> to model the serial correlation described above. Is there a way to
> determine this serial correlation of random effects directly in the
> estimation with any available r package? I found many options to model
> autocorrelation in the residuals but not serial correlation in the random
> effects, especially when there also exists correlation between different
> random effects groups.
>
>
>
> Thank you!
>
>
> Regards
>
> Daniel Bartling
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From danielbartling at gmail.com  Mon Mar 12 16:31:14 2018
From: danielbartling at gmail.com (Daniel Bartling)
Date: Mon, 12 Mar 2018 16:31:14 +0100
Subject: [R-sig-ME] Serial correlation in random effects
In-Reply-To: <CAJuCY5woS06VnsyVpUDtgf=J7HbLWMYK1bhwHebY2+6F=ZPN9Q@mail.gmail.com>
References: <CAOx9ozFOutAcm5zdBDiTBVaO1wsgRTbMmWOYVz4Dcpqhfwg9sQ@mail.gmail.com>
 <CAOx9ozEP6jhjRHCpsocitNHgTDLfAuCf6EPB2PgSt-oB2vVz4g@mail.gmail.com>
 <CAJuCY5woS06VnsyVpUDtgf=J7HbLWMYK1bhwHebY2+6F=ZPN9Q@mail.gmail.com>
Message-ID: <CAOx9ozF53aYq5bT=e9SYb00N8UR7=4CFHGcb4A-k=7nu2tHM0A@mail.gmail.com>

Hi Thierry,

Thank you I will take another look at it, but last time I did it seemed to
me that I could fit an AR1 for the temporal correlation for a single RE,
but could not fit the cross sectional correlation of different RE groups at
the same time. But I will try to dig out the code.

Regards Daniel

On 12 Mar 2018 4:25 PM, "Thierry Onkelinx" <thierry.onkelinx at inbo.be> wrote:

> Dear Daniel,
>
> Have a look at the INLA package (www.r-inla.org). It allows for several
> types of correlated random effects. See http://www.r-inla.org/
> models/latent-models
>
> Best regards,
>
>
> ir. Thierry Onkelinx
> Statisticus / Statistician
>
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
> FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Havenlaan 88
> <https://maps.google.com/?q=Havenlaan+88&entry=gmail&source=g> bus 73,
> 1000 Brussel
> www.inbo.be
>
> ////////////////////////////////////////////////////////////
> ///////////////////////////////
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
> ////////////////////////////////////////////////////////////
> ///////////////////////////////
>
> <https://www.inbo.be>
>
> 2018-03-12 15:50 GMT+01:00 Daniel Bartling <danielbartling at gmail.com>:
>
>> Hi all,
>>
>>
>>
>> I would love to apply linear mixed models in Risk Management as they seem
>> to be tailor suited to many problems we face. We often assume that for
>> example credit default risk is driven by observable latent random factors
>> and we wish to understand the dynamics of these latent factors based on
>> repeated historical observations. Typically, these random factors consist
>> of different groups (e.g. credit defaults in different industry sectors
>> over different time periods). The industry sectors are correlated between
>> each other but that are also assumed to be serially correlated over time.
>> For example, the state of the industry sector ?telecommunication? in year
>> t
>> is the result of both the auto correlation with ?telecommunication? in
>> year
>> t-1 and the year t correlation with other industry sectors like
>> ?information technology?.
>>
>>
>>
>> I would use the representation (-1 + sector|time) to estimate the model.
>>
>>
>> I generated dummy data based on different modeling assumptions and I am
>> able to estimate successfully the parameters that were used in generating
>> the data.
>>
>>
>>
>> However I have some questions:
>>
>>
>>
>> First of all, if I estimate the variance of the BLUPs, I get different
>> values for the variance covariance matrix than if I look directly at the
>> estimated variance covariance matrix as an estimation output. I understand
>> that there is a methodological difference between the BLUPs and the
>> estimated variance covariance matrix, because one is focusing on the
>> realized sample while the other is focused on the specific realised sample
>> (I found the directly estimated variance covariance to be a better fit,
>> while the BLUPs underestimated the variance covariance matrix). So how
>> valid is inference based directly on the BLUPs?
>>
>>
>>
>> More specifically, I wish to estimate AR1 parameters for the BLUPs in
>> order
>> to model the serial correlation described above. Is there a way to
>> determine this serial correlation of random effects directly in the
>> estimation with any available r package? I found many options to model
>> autocorrelation in the residuals but not serial correlation in the random
>> effects, especially when there also exists correlation between different
>> random effects groups.
>>
>>
>>
>> Thank you!
>>
>>
>> Regards
>>
>> Daniel Bartling
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Mon Mar 12 16:45:28 2018
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Mon, 12 Mar 2018 16:45:28 +0100
Subject: [R-sig-ME] Serial correlation in random effects
In-Reply-To: <CAOx9ozF53aYq5bT=e9SYb00N8UR7=4CFHGcb4A-k=7nu2tHM0A@mail.gmail.com>
References: <CAOx9ozFOutAcm5zdBDiTBVaO1wsgRTbMmWOYVz4Dcpqhfwg9sQ@mail.gmail.com>
 <CAOx9ozEP6jhjRHCpsocitNHgTDLfAuCf6EPB2PgSt-oB2vVz4g@mail.gmail.com>
 <CAJuCY5woS06VnsyVpUDtgf=J7HbLWMYK1bhwHebY2+6F=ZPN9Q@mail.gmail.com>
 <CAOx9ozF53aYq5bT=e9SYb00N8UR7=4CFHGcb4A-k=7nu2tHM0A@mail.gmail.com>
Message-ID: <CAJuCY5xpO7TOGycF2L_SjBNQ+DwX_6PmKaZhVcCyaeo7BVMJog@mail.gmail.com>

Dear Daniel,

You could combine an AR1 per sector along time and an iid along year. The
former creates the AR1 correlation with the sector. The latter induces a
compound symmetry correlation among year. Thus making observations from
different sector but within the same year more similar to each ofther.

f(time, model = "ar1", replicate = sector) + f(year, model = "iid")

You could post the question to the INLA mailing list. Adding the
mathematical equation for the model you want will help.

Best regards,


ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>

2018-03-12 16:31 GMT+01:00 Daniel Bartling <danielbartling at gmail.com>:

> Hi Thierry,
>
> Thank you I will take another look at it, but last time I did it seemed to
> me that I could fit an AR1 for the temporal correlation for a single RE,
> but could not fit the cross sectional correlation of different RE groups at
> the same time. But I will try to dig out the code.
>
> Regards Daniel
>
> On 12 Mar 2018 4:25 PM, "Thierry Onkelinx" <thierry.onkelinx at inbo.be>
> wrote:
>
>> Dear Daniel,
>>
>> Have a look at the INLA package (www.r-inla.org). It allows for several
>> types of correlated random effects. See http://www.r-inla.org/mode
>> ls/latent-models
>>
>> Best regards,
>>
>>
>> ir. Thierry Onkelinx
>> Statisticus / Statistician
>>
>> Vlaamse Overheid / Government of Flanders
>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
>> AND FOREST
>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
>> thierry.onkelinx at inbo.be
>> Havenlaan 88
>> <https://maps.google.com/?q=Havenlaan+88&entry=gmail&source=g> bus 73,
>> 1000 Brussel
>> www.inbo.be
>>
>> ////////////////////////////////////////////////////////////
>> ///////////////////////////////
>> To call in the statistician after the experiment is done may be no more
>> than asking him to perform a post-mortem examination: he may be able to say
>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does not
>> ensure that a reasonable answer can be extracted from a given body of data.
>> ~ John Tukey
>> ////////////////////////////////////////////////////////////
>> ///////////////////////////////
>>
>> <https://www.inbo.be>
>>
>> 2018-03-12 15:50 GMT+01:00 Daniel Bartling <danielbartling at gmail.com>:
>>
>>> Hi all,
>>>
>>>
>>>
>>> I would love to apply linear mixed models in Risk Management as they seem
>>> to be tailor suited to many problems we face. We often assume that for
>>> example credit default risk is driven by observable latent random factors
>>> and we wish to understand the dynamics of these latent factors based on
>>> repeated historical observations. Typically, these random factors consist
>>> of different groups (e.g. credit defaults in different industry sectors
>>> over different time periods). The industry sectors are correlated between
>>> each other but that are also assumed to be serially correlated over time.
>>> For example, the state of the industry sector ?telecommunication? in
>>> year t
>>> is the result of both the auto correlation with ?telecommunication? in
>>> year
>>> t-1 and the year t correlation with other industry sectors like
>>> ?information technology?.
>>>
>>>
>>>
>>> I would use the representation (-1 + sector|time) to estimate the model.
>>>
>>>
>>> I generated dummy data based on different modeling assumptions and I am
>>> able to estimate successfully the parameters that were used in generating
>>> the data.
>>>
>>>
>>>
>>> However I have some questions:
>>>
>>>
>>>
>>> First of all, if I estimate the variance of the BLUPs, I get different
>>> values for the variance covariance matrix than if I look directly at the
>>> estimated variance covariance matrix as an estimation output. I
>>> understand
>>> that there is a methodological difference between the BLUPs and the
>>> estimated variance covariance matrix, because one is focusing on the
>>> realized sample while the other is focused on the specific realised
>>> sample
>>> (I found the directly estimated variance covariance to be a better fit,
>>> while the BLUPs underestimated the variance covariance matrix). So how
>>> valid is inference based directly on the BLUPs?
>>>
>>>
>>>
>>> More specifically, I wish to estimate AR1 parameters for the BLUPs in
>>> order
>>> to model the serial correlation described above. Is there a way to
>>> determine this serial correlation of random effects directly in the
>>> estimation with any available r package? I found many options to model
>>> autocorrelation in the residuals but not serial correlation in the random
>>> effects, especially when there also exists correlation between different
>>> random effects groups.
>>>
>>>
>>>
>>> Thank you!
>>>
>>>
>>> Regards
>>>
>>> Daniel Bartling
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>>

	[[alternative HTML version deleted]]


From marie.rescan at cefe.cnrs.fr  Tue Mar 13 15:53:11 2018
From: marie.rescan at cefe.cnrs.fr (Marie RESCAN)
Date: Tue, 13 Mar 2018 15:53:11 +0100
Subject: [R-sig-ME] Data augmentation in TMB?
Message-ID: <8da9ca34-d3ce-aba4-7331-0f17ea3770ee@cefe.cnrs.fr>

Dear R-sig-mixed-model users,

I am currently fitting state space models using the TMB package and I 
would like to know if anyone have already implemented data augmentation 
in this package.

My data consist of time series of 3 simultaneous types of observations 
of latent processes (dynamics of experimental populations of microalgae 
replicated in batch). I would like to fit a state space model on this 
data set, but many observations are missing:

- For two observation methods, I cannot get population size estimation 
when the number of individuals is too low

- For the last observation method, I got data only half of the time.

I became aware that points in the latent process would not affect 
equally the when they do not have the same number of observations, which 
may be a problem to estimate process parameters.

I would appreciate any suggestions to deal with this problem.

Thanks,


Marie



-- 
Marie Rescan, PhD

Post doctorante
Centre d'?cologie fonctionnelle et ?volutive - CEFE
UMR 5175
Equipe G?n?tique & Ecologie ?volutive - GEE
1919, route de Mende
34 293 Montpellier Cedex 5
FRANCE


	[[alternative HTML version deleted]]


From mollieebrooks at gmail.com  Tue Mar 13 17:49:36 2018
From: mollieebrooks at gmail.com (Mollie Brooks)
Date: Tue, 13 Mar 2018 17:49:36 +0100
Subject: [R-sig-ME] Data augmentation in TMB?
In-Reply-To: <8da9ca34-d3ce-aba4-7331-0f17ea3770ee@cefe.cnrs.fr>
References: <8da9ca34-d3ce-aba4-7331-0f17ea3770ee@cefe.cnrs.fr>
Message-ID: <E6946101-AC38-4618-BCA7-5081B0056C95@gmail.com>

Hi Marie,

This question would probably be better for the TMB users list tmb-users at googlegroups.com <mailto:tmb-users at googlegroups.com>.  I just sent you an invitation to the group. If you are an absolute beginner with TMB, it may be more than the user list can help you with. Let me know and I?ll send you some resources.

You can fit the type of model you?re describing in TMB, but we will probably need more details. It?s fine that many observations are missing.  From your question, I can?t tell if you have mathematically formulated the model you want to fit (e.g. distributions, process model). Or do you have some code already?

You could look at my state-space model of sheep growth for an example. It can show you the outline of the structure. Ignore the random effects section to begin with. You might just need a process model and 3 sets of observations.
https://github.com/mebrooks/growmod/blob/master/growmod/src/growmod.cpp

cheers,
Mollie

???????????
Mollie E. Brooks, Ph.D.
Research Scientist
National Institute of Aquatic Resources
Technical University of Denmark

> On 13Mar 2018, at 15:53, Marie RESCAN <marie.rescan at cefe.cnrs.fr> wrote:
> 
> Dear R-sig-mixed-model users,
> 
> I am currently fitting state space models using the TMB package and I 
> would like to know if anyone have already implemented data augmentation 
> in this package.
> 
> My data consist of time series of 3 simultaneous types of observations 
> of latent processes (dynamics of experimental populations of microalgae 
> replicated in batch). I would like to fit a state space model on this 
> data set, but many observations are missing:
> 
> - For two observation methods, I cannot get population size estimation 
> when the number of individuals is too low
> 
> - For the last observation method, I got data only half of the time.
> 
> I became aware that points in the latent process would not affect 
> equally the when they do not have the same number of observations, which 
> may be a problem to estimate process parameters.
> 
> I would appreciate any suggestions to deal with this problem.
> 
> Thanks,
> 
> 
> Marie
> 
> 
> 
> -- 
> Marie Rescan, PhD
> 
> Post doctorante
> Centre d'?cologie fonctionnelle et ?volutive - CEFE
> UMR 5175
> Equipe G?n?tique & Ecologie ?volutive - GEE
> 1919, route de Mende
> 34 293 Montpellier Cedex 5
> FRANCE
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


	[[alternative HTML version deleted]]


From Ramgad82 at gmx.net  Wed Mar 14 10:50:58 2018
From: Ramgad82 at gmx.net (Tagmarie)
Date: Wed, 14 Mar 2018 10:50:58 +0100
Subject: [R-sig-ME] GAMM4: temporal autocorrelation? (GAM, binomial data,
 random effect)
Message-ID: <1ce57e0a-80e1-9c81-3e97-ad34c8649b35@gmx.net>

Dear all,

I am not a statistican but a biologist and I have a problem that I 
cannot solve. I guess more people must have that problem but I didn't 
find a solution online.

I want to to do a gam with random effects and my response variable has a 
binomial error structure. Reading through literature I found that gamm() 
doesn't perform very good with binomial error structures and gamm4 would 
be better.

So I did a gam using gamm4. My code is like this:

Mod1 <- gamm4(grooming ~s(time,bs = 
"cr"),random=~(1|animalID),data=mydata, family=binomial)

The result looks perfect! Unfortunately, when testing for temporal 
autocorrelation with

pacf(resid(Mod1$gam))

I do clearly have temporal autocorrelation in my data. I had also 
expected that because time is of course always leading to 
autocorrelation structures.
My problem:

How do I incorporate the temporal autocorrelation into my model? The 
usual part which works in gams (correlation=corAR1(0.71, form = ~ 1 | 
animalID) won't work in GAMM4 I know.

I followed an example from "?magic" (after loading mgcv) but that 
resulted in a crap looking result.

Does anyone know how to deal with that data structure? Help would be 
terribly much appreciated!


From highstat at highstat.com  Wed Mar 14 12:36:38 2018
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Wed, 14 Mar 2018 12:36:38 +0100
Subject: [R-sig-ME] GAMM4: temporal autocorrelation?
In-Reply-To: <mailman.16221.11.1521025202.41925.r-sig-mixed-models@r-project.org>
References: <mailman.16221.11.1521025202.41925.r-sig-mixed-models@r-project.org>
Message-ID: <1bd53924-1f8d-0959-1564-ee6dc66a6360@highstat.com>

Hello Ramgad82

Without providing data or/and scatterplots it is difficult to say 
anything sensible..but here are a few points to consider:

Problem 1: Applying the acf on the residuals assume that the residuals 
form a single time series. I guess you have multiple time series; one 
per animalID? In that case make an acf for each individual residual time 
series.

Problem 2. You are aiming for:? s(Time) + auto-correlated time

These two components might fight for the same information. The solution 
is to fix either the df of the smoother, or the auto-correlation parameters.

3. As to your specific question...you can either try glmmTMB or R-INLA.

Kind regards,

Alain


------------------------------

Message: 3
Date: Wed, 14 Mar 2018 10:50:58 +0100
From: Tagmarie <Ramgad82 at gmx.net>
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] GAMM4: temporal autocorrelation? (GAM, binomial
	data, random effect)
Message-ID: <1ce57e0a-80e1-9c81-3e97-ad34c8649b35 at gmx.net>
Content-Type: text/plain; charset="utf-8"; Format="flowed"

Dear all,

I am not a statistican but a biologist and I have a problem that I
cannot solve. I guess more people must have that problem but I didn't
find a solution online.

I want to to do a gam with random effects and my response variable has a
binomial error structure. Reading through literature I found that gamm()
doesn't perform very good with binomial error structures and gamm4 would
be better.

So I did a gam using gamm4. My code is like this:

Mod1 <- gamm4(grooming ~s(time,bs =
"cr"),random=~(1|animalID),data=mydata, family=binomial)

The result looks perfect! Unfortunately, when testing for temporal
autocorrelation with

pacf(resid(Mod1$gam))

I do clearly have temporal autocorrelation in my data. I had also
expected that because time is of course always leading to
autocorrelation structures.
My problem:

How do I incorporate the temporal autocorrelation into my model? The
usual part which works in gams (correlation=corAR1(0.71, form = ~ 1 |
animalID) won't work in GAMM4 I know.

I followed an example from "?magic" (after loading mgcv) but that
resulted in a crap looking result.

Does anyone know how to deal with that data structure? Help would be
terribly much appreciated!




------------------------------

Subject: Digest Footer

_______________________________________________
R-sig-mixed-models mailing list
R-sig-mixed-models at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


------------------------------

End of R-sig-mixed-models Digest, Vol 135, Issue 17
***************************************************

-- 

Dr. Alain F. Zuur
Highland Statistics Ltd.
9 St Clair Wynd
AB41 6DZ Newburgh, UK
Email: highstat at highstat.com
URL:   www.highstat.com

And:
NIOZ Royal Netherlands Institute for Sea Research,
Department of Coastal Systems, and Utrecht University,
P.O. Box 59, 1790 AB Den Burg,
Texel, The Netherlands



Author of:
1. Beginner's Guide to Spatial, Temporal and Spatial-Temporal Ecological Data Analysis with R-INLA. (2017).
2. Beginner's Guide to Zero-Inflated Models with R (2016).
3. Beginner's Guide to Data Exploration and Visualisation with R (2015).
4. Beginner's Guide to GAMM with R (2014).
5. Beginner's Guide to GLM and GLMM with R (2013).
6. Beginner's Guide to GAM with R (2012).
7. Zero Inflated Models and GLMM with R (2012).
8. A Beginner's Guide to R (2009).
9. Mixed effects models and extensions in ecology with R (2009).
10. Analysing Ecological Data (2007).


From thomasmerkling00 at gmail.com  Fri Mar 16 02:51:18 2018
From: thomasmerkling00 at gmail.com (Thomas Merkling)
Date: Thu, 15 Mar 2018 21:51:18 -0400
Subject: [R-sig-ME] different overdispersion parameter for binomial GLMM in
 lme4, glmmADMB and glmmTMB
Message-ID: <671e026c-b298-ed5e-8df3-3e69f697d80c@gmail.com>

Hi all,

I'm trying to model proportion data using a binomial GLMM. I first 
started with lme4 and saw that my data were overdispersed.

LME4Inter <- glmer(PropInter ~ Manip + Observer? +(1|Date), 
family=binomial, weights = NbAg, data = senior, 
control=glmerControl(optimizer="bobyqa",optCtrl = list(maxfun=100000)))

Using the dispersion_glmer (provided by Ben Bolker, see below for code), 
I got a dispersion parameter of 1.99 (as expected the outcome is the 
same with glmmADMB).

I then tried to add an observation level random effect, and the 
dispersion parameter dropped to 0.24. With such a small dispersion 
parameter, my model becomes overly conservative and I'll probably not be 
able to detect any (true) effect (if I understand correctly). Would you 
stick to this model anyways?

I started investigating beta-binomial models to see if they could better 
model overdispersion (and not be too conservative) and wanted to use 
glmmTMB to do that.

I first tried to refit the binomial GLMM with glmmTMB and calculate the 
dispersion parameter using the dispfun function (also provided by Ben 
Bolker, see below for code), and got a very different response: the 
dispersion parameter was 0.514. If this is correct, I wouldn't have to 
worry about overdispersion.

TMBInter <- glmmTMB(PropInter ~ Manip + Observer? +(1|Date), 
family=binomial, weights = NbAg, data = senior)

The estimates and SEs were identical between the 3 packages, so I am 
fitting correctly the exact same models. However, the residuals between 
glmer/glmmADMB and glmmTMB models were quite different. Is that expected?
I tried to run Poisson GLMMs with the 2 packages and got identical 
dispersion parameters, so the dispfun function works well for glmmTMB too.

Which dispersion parameter value should I trust for the binomial GLMM? 
Is there something specific about binomial GLMMs in glmmTMB?

Thanks in advance for your help!

Thomas Merkling


dispersion_glmer <- function(model) {
 ? ## number of variance parameters in
 ? ##?? an n-by-n variance-covariance matrix
 ? vpars <- function(m) {
 ??? nrow(m)*(nrow(m)+1)/2
 ? }
 ? model.df <- sum(sapply(VarCorr(model),vpars))+length(fixef(model))
 ? rdf <- nrow(model.frame(model))-model.df
 ? rp <- residuals(model,type="pearson")
 ? Pearson.chisq <- sum(rp^2)
 ? prat <- Pearson.chisq/rdf
 ? pval <- pchisq(Pearson.chisq, df=rdf, lower.tail=FALSE)
 ? c(chisq=Pearson.chisq,ratio=prat,rdf=rdf,p=pval)
}

dispfun <- function(m) {
 ? r <- residuals(m,type="pearson")
 ? n <- df.residual(m)
 ? dsq <- sum(r^2)
 ? c(dsq=dsq,n=n,disp=dsq/n)
}


From Ariel.Muldoon at oregonstate.edu  Fri Mar 16 17:31:59 2018
From: Ariel.Muldoon at oregonstate.edu (Muldoon, Ariel)
Date: Fri, 16 Mar 2018 16:31:59 +0000
Subject: [R-sig-ME] 
 different overdispersion parameter for binomial GLMM in
 lme4, glmmADMB and glmmTMB
In-Reply-To: <671e026c-b298-ed5e-8df3-3e69f697d80c@gmail.com>
References: <671e026c-b298-ed5e-8df3-3e69f697d80c@gmail.com>
Message-ID: <6057235ECEA65D4DBC2696B69BA378A6E87BDAE4@EX3.oregonstate.edu>

Hi, Thomas-

After doing a little poking around, my impression is that the glmmTMB model may not be returning the correct values for the residuals for a binomial model.

I fit the model from the "Examples" in both glmmTMB (development version) and lme4, using the two different coding approaches that are often used for fitting binomial models (one with a matrix response and one with a proportion plus number of trials as weights).

The two lme4 models return identical results, so there wasn't much reason to pursue them both.  The second model (tmbm2) is like the model you are fitting.

library(glmmTMB)
library(lme4)

tmbm1 = glmmTMB(cbind(incidence, size - incidence) ~ period + (1 | herd),
                  data = cbpp, family = binomial)

tmbm2 = glmmTMB(incidence/size ~ period + (1 | herd),
                  data = cbpp, weights = size, family = binomial)

tmbm3 = glmer(cbind(incidence, size - incidence) ~ period + (1 | herd),
                  data = cbpp, family = binomial)

tmbm4 = glmer(incidence/size ~ period + (1 | herd),
                data = cbpp, family = binomial, weights = size)

Drilling down for reasons for residuals to be different, I found that the second model returns different fitted values than the others.  

fitted(tmbm1)
fitted(tmbm2)
fitted(tmbm4)

I can't tell you why this is and I can't be certain the values from the other models are correct, but if I manually calculate the fitted values for the second model the results match the values from the other three models.  (You'll see slight differences between the lme4 and glmmTMB models due to slight differences in estimates of the conditional modes of the random effects.)

# Manual calculation of fitted values
plogis( (getME(tmbm2, "X") %*% fixef(tmbm2)$cond) + 
             rep(unlist(ranef(tmbm2)$cond),
                 times = c(4L, 3L, 4L, 4L, 4L, 4L, 4L, 1L, 4L, 4L, 4L, 4L, 4L, 4L, 4L)) )

A good approach then might be to use the matrix-style response variable in glmmTMB.  However, the residuals.glmmTMB function then uses the matrix response when calculating residuals instead of a proportion response.

# Calculate response residuals for matrix response
residuals(tmbm1)
model.response(tmbm1$frame) - fitted(tmbm1)
# Here is what these should be, which matches lme4
model.response(tmbm1$frame)[,1]/cbpp$size - fitted(tmbm1)
getME(tmbm4, "y") - fitted(tmbm4)

The last difference I found is in the calculation of the pearson residuals.  I believe glmmTMB uses mu*(1-mu) to calculate the variance that is used in the divisor (I base this on family(tmbm1)$variance).  However, I think lme4 uses the variance of a proportion, mu*(1-mu)/m (where m is the binomial sample size/number of trials). 

residuals(tmbm4, type = "pearson")
( getME(tmbm4, "y") - fitted(tmbm4) )/sqrt( fitted(tmbm3)*(1-fitted(tmbm3))/cbpp$size )

I'm not sure any of this helps you decide how to move forward, but I definitely wouldn't dismiss the overdispersion you are seeing in your lme4 model yet.

Ariel


-----Original Message-----
From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Thomas Merkling
Sent: Thursday, March 15, 2018 6:51 PM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] different overdispersion parameter for binomial GLMM in lme4, glmmADMB and glmmTMB

Hi all,

I'm trying to model proportion data using a binomial GLMM. I first started with lme4 and saw that my data were overdispersed.

LME4Inter <- glmer(PropInter ~ Manip + Observer? +(1|Date), family=binomial, weights = NbAg, data = senior, control=glmerControl(optimizer="bobyqa",optCtrl = list(maxfun=100000)))

Using the dispersion_glmer (provided by Ben Bolker, see below for code), I got a dispersion parameter of 1.99 (as expected the outcome is the same with glmmADMB).

I then tried to add an observation level random effect, and the dispersion parameter dropped to 0.24. With such a small dispersion parameter, my model becomes overly conservative and I'll probably not be able to detect any (true) effect (if I understand correctly). Would you stick to this model anyways?

I started investigating beta-binomial models to see if they could better model overdispersion (and not be too conservative) and wanted to use glmmTMB to do that.

I first tried to refit the binomial GLMM with glmmTMB and calculate the dispersion parameter using the dispfun function (also provided by Ben Bolker, see below for code), and got a very different response: the dispersion parameter was 0.514. If this is correct, I wouldn't have to worry about overdispersion.

TMBInter <- glmmTMB(PropInter ~ Manip + Observer? +(1|Date), family=binomial, weights = NbAg, data = senior)

The estimates and SEs were identical between the 3 packages, so I am fitting correctly the exact same models. However, the residuals between glmer/glmmADMB and glmmTMB models were quite different. Is that expected?
I tried to run Poisson GLMMs with the 2 packages and got identical dispersion parameters, so the dispfun function works well for glmmTMB too.

Which dispersion parameter value should I trust for the binomial GLMM? 
Is there something specific about binomial GLMMs in glmmTMB?

Thanks in advance for your help!

Thomas Merkling


dispersion_glmer <- function(model) {
 ? ## number of variance parameters in
 ? ##?? an n-by-n variance-covariance matrix
 ? vpars <- function(m) {
 ??? nrow(m)*(nrow(m)+1)/2
 ? }
 ? model.df <- sum(sapply(VarCorr(model),vpars))+length(fixef(model))
 ? rdf <- nrow(model.frame(model))-model.df
 ? rp <- residuals(model,type="pearson")
 ? Pearson.chisq <- sum(rp^2)
 ? prat <- Pearson.chisq/rdf
 ? pval <- pchisq(Pearson.chisq, df=rdf, lower.tail=FALSE)
 ? c(chisq=Pearson.chisq,ratio=prat,rdf=rdf,p=pval)
}

dispfun <- function(m) {
 ? r <- residuals(m,type="pearson")
 ? n <- df.residual(m)
 ? dsq <- sum(r^2)
 ? c(dsq=dsq,n=n,disp=dsq/n)
}

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

From bbolker at gmail.com  Fri Mar 16 19:19:09 2018
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 16 Mar 2018 14:19:09 -0400
Subject: [R-sig-ME] 
 different overdispersion parameter for binomial GLMM in
 lme4, glmmADMB and glmmTMB
In-Reply-To: <6057235ECEA65D4DBC2696B69BA378A6E87BDAE4@EX3.oregonstate.edu>
References: <671e026c-b298-ed5e-8df3-3e69f697d80c@gmail.com>
 <6057235ECEA65D4DBC2696B69BA378A6E87BDAE4@EX3.oregonstate.edu>
Message-ID: <CABghstRd=F59nYFwS3UZowJWwhpg_UOu=UHXQZxQQ8xkYW2RcQ@mail.gmail.com>

Ariel, can you post this as an issue at
https://github.com/glmmTMB/glmmTMB/issues ?  This stuff is really hard
to get right ...

  Thomas: I think an important point is that it really only makes much
sense to focus on the dispersion in a model that does *NOT* already
have a dispersion parameter estimated.  If you want to choose among
models with different forms of dispersion, I would probably suggest
AIC (which reduces to comparing log-likelihood for models with the
same number of parameters -- if the two models aren't nested, as they
probably aren't, you can't do a statistical test, but you can still
see which one fits the data better).



On Fri, Mar 16, 2018 at 12:31 PM, Muldoon, Ariel
<Ariel.Muldoon at oregonstate.edu> wrote:
> Hi, Thomas-
>
> After doing a little poking around, my impression is that the glmmTMB model may not be returning the correct values for the residuals for a binomial model.
>
> I fit the model from the "Examples" in both glmmTMB (development version) and lme4, using the two different coding approaches that are often used for fitting binomial models (one with a matrix response and one with a proportion plus number of trials as weights).
>
> The two lme4 models return identical results, so there wasn't much reason to pursue them both.  The second model (tmbm2) is like the model you are fitting.
>
> library(glmmTMB)
> library(lme4)
>
> tmbm1 = glmmTMB(cbind(incidence, size - incidence) ~ period + (1 | herd),
>                   data = cbpp, family = binomial)
>
> tmbm2 = glmmTMB(incidence/size ~ period + (1 | herd),
>                   data = cbpp, weights = size, family = binomial)
>
> tmbm3 = glmer(cbind(incidence, size - incidence) ~ period + (1 | herd),
>                   data = cbpp, family = binomial)
>
> tmbm4 = glmer(incidence/size ~ period + (1 | herd),
>                 data = cbpp, family = binomial, weights = size)
>
> Drilling down for reasons for residuals to be different, I found that the second model returns different fitted values than the others.
>
> fitted(tmbm1)
> fitted(tmbm2)
> fitted(tmbm4)
>
> I can't tell you why this is and I can't be certain the values from the other models are correct, but if I manually calculate the fitted values for the second model the results match the values from the other three models.  (You'll see slight differences between the lme4 and glmmTMB models due to slight differences in estimates of the conditional modes of the random effects.)
>
> # Manual calculation of fitted values
> plogis( (getME(tmbm2, "X") %*% fixef(tmbm2)$cond) +
>              rep(unlist(ranef(tmbm2)$cond),
>                  times = c(4L, 3L, 4L, 4L, 4L, 4L, 4L, 1L, 4L, 4L, 4L, 4L, 4L, 4L, 4L)) )
>
> A good approach then might be to use the matrix-style response variable in glmmTMB.  However, the residuals.glmmTMB function then uses the matrix response when calculating residuals instead of a proportion response.
>
> # Calculate response residuals for matrix response
> residuals(tmbm1)
> model.response(tmbm1$frame) - fitted(tmbm1)
> # Here is what these should be, which matches lme4
> model.response(tmbm1$frame)[,1]/cbpp$size - fitted(tmbm1)
> getME(tmbm4, "y") - fitted(tmbm4)
>
> The last difference I found is in the calculation of the pearson residuals.  I believe glmmTMB uses mu*(1-mu) to calculate the variance that is used in the divisor (I base this on family(tmbm1)$variance).  However, I think lme4 uses the variance of a proportion, mu*(1-mu)/m (where m is the binomial sample size/number of trials).
>
> residuals(tmbm4, type = "pearson")
> ( getME(tmbm4, "y") - fitted(tmbm4) )/sqrt( fitted(tmbm3)*(1-fitted(tmbm3))/cbpp$size )
>
> I'm not sure any of this helps you decide how to move forward, but I definitely wouldn't dismiss the overdispersion you are seeing in your lme4 model yet.
>
> Ariel
>
>
> -----Original Message-----
> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Thomas Merkling
> Sent: Thursday, March 15, 2018 6:51 PM
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] different overdispersion parameter for binomial GLMM in lme4, glmmADMB and glmmTMB
>
> Hi all,
>
> I'm trying to model proportion data using a binomial GLMM. I first started with lme4 and saw that my data were overdispersed.
>
> LME4Inter <- glmer(PropInter ~ Manip + Observer  +(1|Date), family=binomial, weights = NbAg, data = senior, control=glmerControl(optimizer="bobyqa",optCtrl = list(maxfun=100000)))
>
> Using the dispersion_glmer (provided by Ben Bolker, see below for code), I got a dispersion parameter of 1.99 (as expected the outcome is the same with glmmADMB).
>
> I then tried to add an observation level random effect, and the dispersion parameter dropped to 0.24. With such a small dispersion parameter, my model becomes overly conservative and I'll probably not be able to detect any (true) effect (if I understand correctly). Would you stick to this model anyways?
>
> I started investigating beta-binomial models to see if they could better model overdispersion (and not be too conservative) and wanted to use glmmTMB to do that.
>
> I first tried to refit the binomial GLMM with glmmTMB and calculate the dispersion parameter using the dispfun function (also provided by Ben Bolker, see below for code), and got a very different response: the dispersion parameter was 0.514. If this is correct, I wouldn't have to worry about overdispersion.
>
> TMBInter <- glmmTMB(PropInter ~ Manip + Observer  +(1|Date), family=binomial, weights = NbAg, data = senior)
>
> The estimates and SEs were identical between the 3 packages, so I am fitting correctly the exact same models. However, the residuals between glmer/glmmADMB and glmmTMB models were quite different. Is that expected?
> I tried to run Poisson GLMMs with the 2 packages and got identical dispersion parameters, so the dispfun function works well for glmmTMB too.
>
> Which dispersion parameter value should I trust for the binomial GLMM?
> Is there something specific about binomial GLMMs in glmmTMB?
>
> Thanks in advance for your help!
>
> Thomas Merkling
>
>
> dispersion_glmer <- function(model) {
>    ## number of variance parameters in
>    ##   an n-by-n variance-covariance matrix
>    vpars <- function(m) {
>      nrow(m)*(nrow(m)+1)/2
>    }
>    model.df <- sum(sapply(VarCorr(model),vpars))+length(fixef(model))
>    rdf <- nrow(model.frame(model))-model.df
>    rp <- residuals(model,type="pearson")
>    Pearson.chisq <- sum(rp^2)
>    prat <- Pearson.chisq/rdf
>    pval <- pchisq(Pearson.chisq, df=rdf, lower.tail=FALSE)
>    c(chisq=Pearson.chisq,ratio=prat,rdf=rdf,p=pval)
> }
>
> dispfun <- function(m) {
>    r <- residuals(m,type="pearson")
>    n <- df.residual(m)
>    dsq <- sum(r^2)
>    c(dsq=dsq,n=n,disp=dsq/n)
> }
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From thomasmerkling00 at gmail.com  Fri Mar 16 21:39:00 2018
From: thomasmerkling00 at gmail.com (Thomas Merkling)
Date: Fri, 16 Mar 2018 16:39:00 -0400
Subject: [R-sig-ME] 
 different overdispersion parameter for binomial GLMM in
 lme4, glmmADMB and glmmTMB
In-Reply-To: <CABghstRd=F59nYFwS3UZowJWwhpg_UOu=UHXQZxQQ8xkYW2RcQ@mail.gmail.com>
References: <671e026c-b298-ed5e-8df3-3e69f697d80c@gmail.com>
 <6057235ECEA65D4DBC2696B69BA378A6E87BDAE4@EX3.oregonstate.edu>
 <CABghstRd=F59nYFwS3UZowJWwhpg_UOu=UHXQZxQQ8xkYW2RcQ@mail.gmail.com>
Message-ID: <4f8be066-08f9-3b5c-2afd-86150c3c2b7e@gmail.com>

Thanks Ariel and Ben for your answers!

Following Ariel's troubleshooting, I managed to modify the function I 
was using to match the results from lme4:

dispfun <- function(m, trials) {
# where m is the glmmTMB model and trials a vector of number of trials 
for each observation
 ? r <- (model.response(m$frame)[,1]/trials - 
fitted(m))/sqrt(fitted(m)*(1-fitted(m))/trials)
 ? n <- df.residual(m)
 ? dsq <- sum(r^2)
 ? c(dsq=dsq,n=n,disp=dsq/n)
}

Ben, sorry but I am bit confused by your answer. If I understand 
correctly, the approach you would recommend is to calculate the 
dispersion parameter on the binomial model and if there is 
overdispersion compare models with different ways to deal with it (e.g 
observation-level random effects and beta-binomial) to the binomial one 
to find out which ones fits the data better. Is that correct? And so 
there would be no point in calculating the dispersion parameter for the 
OLRE and beta-binomial model and see how much it goes down?

Cheers,
Thomas


On 16/03/2018 14:19, Ben Bolker wrote:
> Ariel, can you post this as an issue at
> https://github.com/glmmTMB/glmmTMB/issues ?  This stuff is really hard
> to get right ...
>
>    Thomas: I think an important point is that it really only makes much
> sense to focus on the dispersion in a model that does *NOT* already
> have a dispersion parameter estimated.  If you want to choose among
> models with different forms of dispersion, I would probably suggest
> AIC (which reduces to comparing log-likelihood for models with the
> same number of parameters -- if the two models aren't nested, as they
> probably aren't, you can't do a statistical test, but you can still
> see which one fits the data better).
>
>
>
> On Fri, Mar 16, 2018 at 12:31 PM, Muldoon, Ariel
> <Ariel.Muldoon at oregonstate.edu> wrote:
>> Hi, Thomas-
>>
>> After doing a little poking around, my impression is that the glmmTMB model may not be returning the correct values for the residuals for a binomial model.
>>
>> I fit the model from the "Examples" in both glmmTMB (development version) and lme4, using the two different coding approaches that are often used for fitting binomial models (one with a matrix response and one with a proportion plus number of trials as weights).
>>
>> The two lme4 models return identical results, so there wasn't much reason to pursue them both.  The second model (tmbm2) is like the model you are fitting.
>>
>> library(glmmTMB)
>> library(lme4)
>>
>> tmbm1 = glmmTMB(cbind(incidence, size - incidence) ~ period + (1 | herd),
>>                    data = cbpp, family = binomial)
>>
>> tmbm2 = glmmTMB(incidence/size ~ period + (1 | herd),
>>                    data = cbpp, weights = size, family = binomial)
>>
>> tmbm3 = glmer(cbind(incidence, size - incidence) ~ period + (1 | herd),
>>                    data = cbpp, family = binomial)
>>
>> tmbm4 = glmer(incidence/size ~ period + (1 | herd),
>>                  data = cbpp, family = binomial, weights = size)
>>
>> Drilling down for reasons for residuals to be different, I found that the second model returns different fitted values than the others.
>>
>> fitted(tmbm1)
>> fitted(tmbm2)
>> fitted(tmbm4)
>>
>> I can't tell you why this is and I can't be certain the values from the other models are correct, but if I manually calculate the fitted values for the second model the results match the values from the other three models.  (You'll see slight differences between the lme4 and glmmTMB models due to slight differences in estimates of the conditional modes of the random effects.)
>>
>> # Manual calculation of fitted values
>> plogis( (getME(tmbm2, "X") %*% fixef(tmbm2)$cond) +
>>               rep(unlist(ranef(tmbm2)$cond),
>>                   times = c(4L, 3L, 4L, 4L, 4L, 4L, 4L, 1L, 4L, 4L, 4L, 4L, 4L, 4L, 4L)) )
>>
>> A good approach then might be to use the matrix-style response variable in glmmTMB.  However, the residuals.glmmTMB function then uses the matrix response when calculating residuals instead of a proportion response.
>>
>> # Calculate response residuals for matrix response
>> residuals(tmbm1)
>> model.response(tmbm1$frame) - fitted(tmbm1)
>> # Here is what these should be, which matches lme4
>> model.response(tmbm1$frame)[,1]/cbpp$size - fitted(tmbm1)
>> getME(tmbm4, "y") - fitted(tmbm4)
>>
>> The last difference I found is in the calculation of the pearson residuals.  I believe glmmTMB uses mu*(1-mu) to calculate the variance that is used in the divisor (I base this on family(tmbm1)$variance).  However, I think lme4 uses the variance of a proportion, mu*(1-mu)/m (where m is the binomial sample size/number of trials).
>>
>> residuals(tmbm4, type = "pearson")
>> ( getME(tmbm4, "y") - fitted(tmbm4) )/sqrt( fitted(tmbm3)*(1-fitted(tmbm3))/cbpp$size )
>>
>> I'm not sure any of this helps you decide how to move forward, but I definitely wouldn't dismiss the overdispersion you are seeing in your lme4 model yet.
>>
>> Ariel
>>
>>
>> -----Original Message-----
>> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Thomas Merkling
>> Sent: Thursday, March 15, 2018 6:51 PM
>> To: r-sig-mixed-models at r-project.org
>> Subject: [R-sig-ME] different overdispersion parameter for binomial GLMM in lme4, glmmADMB and glmmTMB
>>
>> Hi all,
>>
>> I'm trying to model proportion data using a binomial GLMM. I first started with lme4 and saw that my data were overdispersed.
>>
>> LME4Inter <- glmer(PropInter ~ Manip + Observer  +(1|Date), family=binomial, weights = NbAg, data = senior, control=glmerControl(optimizer="bobyqa",optCtrl = list(maxfun=100000)))
>>
>> Using the dispersion_glmer (provided by Ben Bolker, see below for code), I got a dispersion parameter of 1.99 (as expected the outcome is the same with glmmADMB).
>>
>> I then tried to add an observation level random effect, and the dispersion parameter dropped to 0.24. With such a small dispersion parameter, my model becomes overly conservative and I'll probably not be able to detect any (true) effect (if I understand correctly). Would you stick to this model anyways?
>>
>> I started investigating beta-binomial models to see if they could better model overdispersion (and not be too conservative) and wanted to use glmmTMB to do that.
>>
>> I first tried to refit the binomial GLMM with glmmTMB and calculate the dispersion parameter using the dispfun function (also provided by Ben Bolker, see below for code), and got a very different response: the dispersion parameter was 0.514. If this is correct, I wouldn't have to worry about overdispersion.
>>
>> TMBInter <- glmmTMB(PropInter ~ Manip + Observer  +(1|Date), family=binomial, weights = NbAg, data = senior)
>>
>> The estimates and SEs were identical between the 3 packages, so I am fitting correctly the exact same models. However, the residuals between glmer/glmmADMB and glmmTMB models were quite different. Is that expected?
>> I tried to run Poisson GLMMs with the 2 packages and got identical dispersion parameters, so the dispfun function works well for glmmTMB too.
>>
>> Which dispersion parameter value should I trust for the binomial GLMM?
>> Is there something specific about binomial GLMMs in glmmTMB?
>>
>> Thanks in advance for your help!
>>
>> Thomas Merkling
>>
>>
>> dispersion_glmer <- function(model) {
>>     ## number of variance parameters in
>>     ##   an n-by-n variance-covariance matrix
>>     vpars <- function(m) {
>>       nrow(m)*(nrow(m)+1)/2
>>     }
>>     model.df <- sum(sapply(VarCorr(model),vpars))+length(fixef(model))
>>     rdf <- nrow(model.frame(model))-model.df
>>     rp <- residuals(model,type="pearson")
>>     Pearson.chisq <- sum(rp^2)
>>     prat <- Pearson.chisq/rdf
>>     pval <- pchisq(Pearson.chisq, df=rdf, lower.tail=FALSE)
>>     c(chisq=Pearson.chisq,ratio=prat,rdf=rdf,p=pval)
>> }
>>
>> dispfun <- function(m) {
>>     r <- residuals(m,type="pearson")
>>     n <- df.residual(m)
>>     dsq <- sum(r^2)
>>     c(dsq=dsq,n=n,disp=dsq/n)
>> }
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbolker at gmail.com  Fri Mar 16 21:41:15 2018
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 16 Mar 2018 16:41:15 -0400
Subject: [R-sig-ME] 
 different overdispersion parameter for binomial GLMM in
 lme4, glmmADMB and glmmTMB
In-Reply-To: <4f8be066-08f9-3b5c-2afd-86150c3c2b7e@gmail.com>
References: <671e026c-b298-ed5e-8df3-3e69f697d80c@gmail.com>
 <6057235ECEA65D4DBC2696B69BA378A6E87BDAE4@EX3.oregonstate.edu>
 <CABghstRd=F59nYFwS3UZowJWwhpg_UOu=UHXQZxQQ8xkYW2RcQ@mail.gmail.com>
 <4f8be066-08f9-3b5c-2afd-86150c3c2b7e@gmail.com>
Message-ID: <CABghstSUCzWYWobGAG7TBV-L5pnP7kx=kkvX-izr_3e2RStK9A@mail.gmail.com>

On Fri, Mar 16, 2018 at 4:39 PM, Thomas Merkling
<thomasmerkling00 at gmail.com> wrote:
> Thanks Ariel and Ben for your answers!
>
> Following Ariel's troubleshooting, I managed to modify the function I was
> using to match the results from lme4:
>
> dispfun <- function(m, trials) {
> # where m is the glmmTMB model and trials a vector of number of trials for
> each observation
>   r <- (model.response(m$frame)[,1]/trials -
> fitted(m))/sqrt(fitted(m)*(1-fitted(m))/trials)
>   n <- df.residual(m)
>   dsq <- sum(r^2)
>   c(dsq=dsq,n=n,disp=dsq/n)
> }
>
> Ben, sorry but I am bit confused by your answer. If I understand correctly,
> the approach you would recommend is to calculate the dispersion parameter on
> the binomial model and if there is overdispersion compare models with
> different ways to deal with it (e.g observation-level random effects and
> beta-binomial) to the binomial one to find out which ones fits the data
> better. Is that correct? And so there would be no point in calculating the
> dispersion parameter for the OLRE and beta-binomial model and see how much
> it goes down?


  Yes, that's what I'm recommending.  ("If there is overdispersion" is
open to interpretation --
i.e. how much overdispersion makes it concerning/worth bothering to
move forward with
a model that takes overdispersion into account ...)

  As always, happy to hear other opinions.



>
> On 16/03/2018 14:19, Ben Bolker wrote:
>>
>> Ariel, can you post this as an issue at
>> https://github.com/glmmTMB/glmmTMB/issues ?  This stuff is really hard
>> to get right ...
>>
>>    Thomas: I think an important point is that it really only makes much
>> sense to focus on the dispersion in a model that does *NOT* already
>> have a dispersion parameter estimated.  If you want to choose among
>> models with different forms of dispersion, I would probably suggest
>> AIC (which reduces to comparing log-likelihood for models with the
>> same number of parameters -- if the two models aren't nested, as they
>> probably aren't, you can't do a statistical test, but you can still
>> see which one fits the data better).
>>
>>
>>
>> On Fri, Mar 16, 2018 at 12:31 PM, Muldoon, Ariel
>> <Ariel.Muldoon at oregonstate.edu> wrote:
>>>
>>> Hi, Thomas-
>>>
>>> After doing a little poking around, my impression is that the glmmTMB
>>> model may not be returning the correct values for the residuals for a
>>> binomial model.
>>>
>>> I fit the model from the "Examples" in both glmmTMB (development version)
>>> and lme4, using the two different coding approaches that are often used for
>>> fitting binomial models (one with a matrix response and one with a
>>> proportion plus number of trials as weights).
>>>
>>> The two lme4 models return identical results, so there wasn't much reason
>>> to pursue them both.  The second model (tmbm2) is like the model you are
>>> fitting.
>>>
>>> library(glmmTMB)
>>> library(lme4)
>>>
>>> tmbm1 = glmmTMB(cbind(incidence, size - incidence) ~ period + (1 | herd),
>>>                    data = cbpp, family = binomial)
>>>
>>> tmbm2 = glmmTMB(incidence/size ~ period + (1 | herd),
>>>                    data = cbpp, weights = size, family = binomial)
>>>
>>> tmbm3 = glmer(cbind(incidence, size - incidence) ~ period + (1 | herd),
>>>                    data = cbpp, family = binomial)
>>>
>>> tmbm4 = glmer(incidence/size ~ period + (1 | herd),
>>>                  data = cbpp, family = binomial, weights = size)
>>>
>>> Drilling down for reasons for residuals to be different, I found that the
>>> second model returns different fitted values than the others.
>>>
>>> fitted(tmbm1)
>>> fitted(tmbm2)
>>> fitted(tmbm4)
>>>
>>> I can't tell you why this is and I can't be certain the values from the
>>> other models are correct, but if I manually calculate the fitted values for
>>> the second model the results match the values from the other three models.
>>> (You'll see slight differences between the lme4 and glmmTMB models due to
>>> slight differences in estimates of the conditional modes of the random
>>> effects.)
>>>
>>> # Manual calculation of fitted values
>>> plogis( (getME(tmbm2, "X") %*% fixef(tmbm2)$cond) +
>>>               rep(unlist(ranef(tmbm2)$cond),
>>>                   times = c(4L, 3L, 4L, 4L, 4L, 4L, 4L, 1L, 4L, 4L, 4L,
>>> 4L, 4L, 4L, 4L)) )
>>>
>>> A good approach then might be to use the matrix-style response variable
>>> in glmmTMB.  However, the residuals.glmmTMB function then uses the matrix
>>> response when calculating residuals instead of a proportion response.
>>>
>>> # Calculate response residuals for matrix response
>>> residuals(tmbm1)
>>> model.response(tmbm1$frame) - fitted(tmbm1)
>>> # Here is what these should be, which matches lme4
>>> model.response(tmbm1$frame)[,1]/cbpp$size - fitted(tmbm1)
>>> getME(tmbm4, "y") - fitted(tmbm4)
>>>
>>> The last difference I found is in the calculation of the pearson
>>> residuals.  I believe glmmTMB uses mu*(1-mu) to calculate the variance that
>>> is used in the divisor (I base this on family(tmbm1)$variance).  However, I
>>> think lme4 uses the variance of a proportion, mu*(1-mu)/m (where m is the
>>> binomial sample size/number of trials).
>>>
>>> residuals(tmbm4, type = "pearson")
>>> ( getME(tmbm4, "y") - fitted(tmbm4) )/sqrt(
>>> fitted(tmbm3)*(1-fitted(tmbm3))/cbpp$size )
>>>
>>> I'm not sure any of this helps you decide how to move forward, but I
>>> definitely wouldn't dismiss the overdispersion you are seeing in your lme4
>>> model yet.
>>>
>>> Ariel
>>>
>>>
>>> -----Original Message-----
>>> From: R-sig-mixed-models
>>> [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Thomas
>>> Merkling
>>> Sent: Thursday, March 15, 2018 6:51 PM
>>> To: r-sig-mixed-models at r-project.org
>>> Subject: [R-sig-ME] different overdispersion parameter for binomial GLMM
>>> in lme4, glmmADMB and glmmTMB
>>>
>>> Hi all,
>>>
>>> I'm trying to model proportion data using a binomial GLMM. I first
>>> started with lme4 and saw that my data were overdispersed.
>>>
>>> LME4Inter <- glmer(PropInter ~ Manip + Observer  +(1|Date),
>>> family=binomial, weights = NbAg, data = senior,
>>> control=glmerControl(optimizer="bobyqa",optCtrl = list(maxfun=100000)))
>>>
>>> Using the dispersion_glmer (provided by Ben Bolker, see below for code),
>>> I got a dispersion parameter of 1.99 (as expected the outcome is the same
>>> with glmmADMB).
>>>
>>> I then tried to add an observation level random effect, and the
>>> dispersion parameter dropped to 0.24. With such a small dispersion
>>> parameter, my model becomes overly conservative and I'll probably not be
>>> able to detect any (true) effect (if I understand correctly). Would you
>>> stick to this model anyways?
>>>
>>> I started investigating beta-binomial models to see if they could better
>>> model overdispersion (and not be too conservative) and wanted to use glmmTMB
>>> to do that.
>>>
>>> I first tried to refit the binomial GLMM with glmmTMB and calculate the
>>> dispersion parameter using the dispfun function (also provided by Ben
>>> Bolker, see below for code), and got a very different response: the
>>> dispersion parameter was 0.514. If this is correct, I wouldn't have to worry
>>> about overdispersion.
>>>
>>> TMBInter <- glmmTMB(PropInter ~ Manip + Observer  +(1|Date),
>>> family=binomial, weights = NbAg, data = senior)
>>>
>>> The estimates and SEs were identical between the 3 packages, so I am
>>> fitting correctly the exact same models. However, the residuals between
>>> glmer/glmmADMB and glmmTMB models were quite different. Is that expected?
>>> I tried to run Poisson GLMMs with the 2 packages and got identical
>>> dispersion parameters, so the dispfun function works well for glmmTMB too.
>>>
>>> Which dispersion parameter value should I trust for the binomial GLMM?
>>> Is there something specific about binomial GLMMs in glmmTMB?
>>>
>>> Thanks in advance for your help!
>>>
>>> Thomas Merkling
>>>
>>>
>>> dispersion_glmer <- function(model) {
>>>     ## number of variance parameters in
>>>     ##   an n-by-n variance-covariance matrix
>>>     vpars <- function(m) {
>>>       nrow(m)*(nrow(m)+1)/2
>>>     }
>>>     model.df <- sum(sapply(VarCorr(model),vpars))+length(fixef(model))
>>>     rdf <- nrow(model.frame(model))-model.df
>>>     rp <- residuals(model,type="pearson")
>>>     Pearson.chisq <- sum(rp^2)
>>>     prat <- Pearson.chisq/rdf
>>>     pval <- pchisq(Pearson.chisq, df=rdf, lower.tail=FALSE)
>>>     c(chisq=Pearson.chisq,ratio=prat,rdf=rdf,p=pval)
>>> }
>>>
>>> dispfun <- function(m) {
>>>     r <- residuals(m,type="pearson")
>>>     n <- df.residual(m)
>>>     dsq <- sum(r^2)
>>>     c(dsq=dsq,n=n,disp=dsq/n)
>>> }
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>


From highstat at highstat.com  Fri Mar 16 22:04:14 2018
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Fri, 16 Mar 2018 22:04:14 +0100
Subject: [R-sig-ME] 
 different overdispersion parameter for binomial GLMM in,
 lme4, glmmADMB and glmmTMB (Muldoon, Ariel)
In-Reply-To: <mailman.16225.2244.1521232751.1673.r-sig-mixed-models@r-project.org>
References: <mailman.16225.2244.1521232751.1673.r-sig-mixed-models@r-project.org>
Message-ID: <3ba6300e-5116-a345-772f-1a6291f1143c@highstat.com>


> Ben, sorry but I am bit confused by your answer. If I understand
> correctly, the approach you would recommend is to calculate the
> dispersion parameter on the binomial model and if there is
> overdispersion compare models with different ways to deal with it (e.g
> observation-level random effects and beta-binomial) to the binomial one
> to find out which ones fits the data better. Is that correct? And so
> there would be no point in calculating the dispersion parameter for the
> OLRE and beta-binomial model and see how much it goes down?
>
> Cheers,

Correct. Overdispersion/underdispersion is only relevant for 
distributions in which the variance is determined by the mean. Like the 
Poisson: mean(Y) = var(Y)? and the binomial: E(Y) = N * pi and var(Y) = 
Pi * N * (1 - Pi).

No need to check for overdispersion for the normal, Gamma, inverse 
Gaussian, beta-binomial, and beta distributions. These distributions 
have an extra parameter (like the variance in the normal distribution) 
in the variance term. Having said that...I am still confused why the 
Negative binomial GLM can be overdispersed. I guess that is because the 
NB GLM is not a real GLM and iterates between two algorithms (when doing 
frequentist analysis). I guess (again) it is more about whether the 
functional form of the NB variance is correct...or not.

Instead of using a dispersion statistic based on Pearson residuals 
(coming from models with fancy random effects) it is perhaps better to 
simulate data from your model and compare the variation in the simulated 
data with the variation in the observed data. Or do what Ben Bolker 
suggested a few days/weeks ago...simulate data and compare the 
corresponding residuals with the original residuals.

Alain





-- 

Dr. Alain F. Zuur
Highland Statistics Ltd.
9 St Clair Wynd
AB41 6DZ Newburgh, UK
Email: highstat at highstat.com
URL:   www.highstat.com

And:
NIOZ Royal Netherlands Institute for Sea Research,
Department of Coastal Systems, and Utrecht University,
P.O. Box 59, 1790 AB Den Burg,
Texel, The Netherlands



Author of:
1. Beginner's Guide to Spatial, Temporal and Spatial-Temporal Ecological Data Analysis with R-INLA. (2017).
2. Beginner's Guide to Zero-Inflated Models with R (2016).
3. Beginner's Guide to Data Exploration and Visualisation with R (2015).
4. Beginner's Guide to GAMM with R (2014).
5. Beginner's Guide to GLM and GLMM with R (2013).
6. Beginner's Guide to GAM with R (2012).
7. Zero Inflated Models and GLMM with R (2012).
8. A Beginner's Guide to R (2009).
9. Mixed effects models and extensions in ecology with R (2009).
10. Analysing Ecological Data (2007).


From burwood70 at gmail.com  Mon Mar 19 07:43:24 2018
From: burwood70 at gmail.com (Steve Candy)
Date: Mon, 19 Mar 2018 17:43:24 +1100
Subject: [R-sig-ME] MCMCglmm solutions vs quantiles
Message-ID: <00b701d3bf4d$971aa850$c54ff8f0$@gmail.com>

Hi All

 

I am trying to replicate the summary statistics for an MCMCglmm object by
using the posterior samples directly (I want to do further manipulations of
these samples so thus my reason for doing this).

 

I have tried all 9 "types" for the quantile function applied to the
posterior sample but cannot replicate either l-95% CI or u-95% CI from
summary(m5d.1$Sol) using quantile(x=m5d.1$Sol[, 5], probs=c(0.025,0.975),
type=i) (see below). The results for one parameter and the l-95% CI are
close but not identical, whereas the means from the summary and the means of
the posterior samples are identical. I would also like to know how the
probability (pMCMC) is calculated. I did a simple two-sided test using the
posterior sample and get close to but not identical values. I looked through
the documentation but could not find any help on these two issues.

 

Thanks for any help

 

Steve

 

 

> m5d.1 <- MCMCglmm(OthSpecies_set ~ trait - 1 + at.level(trait,1):LnHooks +
at.level(trait,1):Device_fac, 

+     rcov = ~idh(trait):units, random=~idh(trait):Trip_fac,
data=data.counts.DevandNonD,

+      nitt=700000, thin=250, burnin=200000, prior = prior1, family =
"zipoisson", verbose = FALSE)

> summary(m5d.1)

.

> MCMC_Lq <- unlist(summary(m5d.1)["solutions"])[13]

 

> for (i in (1:9)) {

+   q25 <- quantile(x=m5d.1$Sol[, 5], probs=c(0.025), type=i)

+   qdif <- q25-MCMC_Lq

+   print(c(i,qdif,q25,MCMC_Lq)) }

                   2.5%        2.5% solutions13 

1.000000000 0.004817471 0.128636776 0.123819305 

                   2.5%        2.5% solutions13 

2.000000000 0.006845887 0.130665191 0.123819305 

                   2.5%        2.5% solutions13 

3.000000000 0.004817471 0.128636776 0.123819305 

                   2.5%        2.5% solutions13 

4.000000000 0.004817471 0.128636776 0.123819305 

                   2.5%        2.5% solutions13 

5.000000000 0.006845887 0.130665191 0.123819305 

                   2.5%        2.5% solutions13 

6.000000000 0.004918892 0.128738197 0.123819305 

                   2.5%        2.5% solutions13 

7.000000000 0.008772881 0.132592186 0.123819305 

                   2.5%        2.5% solutions13 

8.000000000 0.006203555 0.130022860 0.123819305 

                   2.5%        2.5% solutions13 

9.000000000 0.006364138 0.130183443 0.123819305

 

Dr Steven G. Candy

Director/Consultant

SCANDY STATISTICAL MODELLING PTY LTD

(ABN: 83 601 268 419)

70 Burwood Drive

Blackmans Bay, TASMANIA, Australia 7052

Mobile: (61) 0439284983

 


	[[alternative HTML version deleted]]


From mnkatie at gmail.com  Mon Mar 19 20:18:49 2018
From: mnkatie at gmail.com (Katherine Gordon)
Date: Mon, 19 Mar 2018 14:18:49 -0500
Subject: [R-sig-ME] Summing Across Items within a condition
Message-ID: <D1F43A87-217A-4A44-802B-56C2ADEC62D4@gmail.com>

Hello all,

I?m trying to restructure my data so that instead of each item having its own row, I have a sum of all of the responses per participant per condition appearing in each row. Basically, I want to create this new format because I want to compare and contrast what the analysis and results look like if you use linear mixed-models vs. traditional ANOVA analyses.

So currently I have the variables Participant, Item (1-6), Week (1,2), and Response (correct or incorrect).

The data is organized as below.

Participant

Item

Week

Response

1

1

1

1

1

2

1

0

1

3

1

1

1

4

1

0

1

5

1

0

1

6

1

0

2

1

1

0

2

2

1

1

2

3

1

1

2

4

1

1

2

5

1

1

2

6

1

0

etc

 

 

 


I would like the data to be organized as the following. Obviously the item column doesn?t need to exist, but wanted to show what I was going for.

Participant

Item

Week

Response

1

1-6

1

2

2

1-6

1

4

etc

 

 

 



Is there a way to create a new data file with the restructured format without having to add the responses for each participant within each condition myself?

Thanks,

Katie


	[[alternative HTML version deleted]]


From mnkatie at gmail.com  Mon Mar 19 20:51:47 2018
From: mnkatie at gmail.com (Katherine Gordon)
Date: Mon, 19 Mar 2018 14:51:47 -0500
Subject: [R-sig-ME] Summing Across Items within a condition
In-Reply-To: <CAET4i1drP6G7op8AwdFgv0taXO+T=0M7YpmnVpnpL-oMCQ-R6A@mail.gmail.com>
References: <D1F43A87-217A-4A44-802B-56C2ADEC62D4@gmail.com>
 <CAET4i1drP6G7op8AwdFgv0taXO+T=0M7YpmnVpnpL-oMCQ-R6A@mail.gmail.com>
Message-ID: <A5182B8B-B5E9-4567-90AC-F91CEFDD9FFD@gmail.com>

That worked! Thanks Dan.

Katie

> On Mar 19, 2018, at 2:26 PM, Dan Brooks <dan at brooksbaseball.net> wrote:
> 
> Your message formatting was lost when you sent to the list, but you can probably just 
> 
> >aggregate(Response~Participant+Week,data=mydata,FUN=sum)? 
> 
> -Dan 
> 
> On Mon, Mar 19, 2018 at 3:18 PM, Katherine Gordon <mnkatie at gmail.com <mailto:mnkatie at gmail.com>> wrote:
> Hello all,
> 
> I?m trying to restructure my data so that instead of each item having its own row, I have a sum of all of the responses per participant per condition appearing in each row. Basically, I want to create this new format because I want to compare and contrast what the analysis and results look like if you use linear mixed-models vs. traditional ANOVA analyses.
> 
> So currently I have the variables Participant, Item (1-6), Week (1,2), and Response (correct or incorrect).
> 
> The data is organized as below.
> 
> Participant
> 
> Item
> 
> Week
> 
> Response
> 
> 1
> 
> 1
> 
> 1
> 
> 1
> 
> 1
> 
> 2
> 
> 1
> 
> 0
> 
> 1
> 
> 3
> 
> 1
> 
> 1
> 
> 1
> 
> 4
> 
> 1
> 
> 0
> 
> 1
> 
> 5
> 
> 1
> 
> 0
> 
> 1
> 
> 6
> 
> 1
> 
> 0
> 
> 2
> 
> 1
> 
> 1
> 
> 0
> 
> 2
> 
> 2
> 
> 1
> 
> 1
> 
> 2
> 
> 3
> 
> 1
> 
> 1
> 
> 2
> 
> 4
> 
> 1
> 
> 1
> 
> 2
> 
> 5
> 
> 1
> 
> 1
> 
> 2
> 
> 6
> 
> 1
> 
> 0
> 
> etc
> 
> 
> 
> 
> 
> 
> 
> 
> I would like the data to be organized as the following. Obviously the item column doesn?t need to exist, but wanted to show what I was going for.
> 
> Participant
> 
> Item
> 
> Week
> 
> Response
> 
> 1
> 
> 1-6
> 
> 1
> 
> 2
> 
> 2
> 
> 1-6
> 
> 1
> 
> 4
> 
> etc
> 
> 
> 
> 
> 
> 
> 
> 
> 
> Is there a way to create a new data file with the restructured format without having to add the responses for each participant within each condition myself?
> 
> Thanks,
> 
> Katie
> 
> 
>         [[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org <mailto:R-sig-mixed-models at r-project.org> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> 


	[[alternative HTML version deleted]]


From dan at brooksbaseball.net  Mon Mar 19 20:26:52 2018
From: dan at brooksbaseball.net (Dan Brooks)
Date: Mon, 19 Mar 2018 15:26:52 -0400
Subject: [R-sig-ME] Summing Across Items within a condition
In-Reply-To: <D1F43A87-217A-4A44-802B-56C2ADEC62D4@gmail.com>
References: <D1F43A87-217A-4A44-802B-56C2ADEC62D4@gmail.com>
Message-ID: <CAET4i1drP6G7op8AwdFgv0taXO+T=0M7YpmnVpnpL-oMCQ-R6A@mail.gmail.com>

Your message formatting was lost when you sent to the list, but you can
probably just

>aggregate(Response~Participant+Week,data=mydata,FUN=sum)?

-Dan

On Mon, Mar 19, 2018 at 3:18 PM, Katherine Gordon <mnkatie at gmail.com> wrote:

> Hello all,
>
> I?m trying to restructure my data so that instead of each item having its
> own row, I have a sum of all of the responses per participant per condition
> appearing in each row. Basically, I want to create this new format because
> I want to compare and contrast what the analysis and results look like if
> you use linear mixed-models vs. traditional ANOVA analyses.
>
> So currently I have the variables Participant, Item (1-6), Week (1,2), and
> Response (correct or incorrect).
>
> The data is organized as below.
>
> Participant
>
> Item
>
> Week
>
> Response
>
> 1
>
> 1
>
> 1
>
> 1
>
> 1
>
> 2
>
> 1
>
> 0
>
> 1
>
> 3
>
> 1
>
> 1
>
> 1
>
> 4
>
> 1
>
> 0
>
> 1
>
> 5
>
> 1
>
> 0
>
> 1
>
> 6
>
> 1
>
> 0
>
> 2
>
> 1
>
> 1
>
> 0
>
> 2
>
> 2
>
> 1
>
> 1
>
> 2
>
> 3
>
> 1
>
> 1
>
> 2
>
> 4
>
> 1
>
> 1
>
> 2
>
> 5
>
> 1
>
> 1
>
> 2
>
> 6
>
> 1
>
> 0
>
> etc
>
>
>
>
>
>
>
>
> I would like the data to be organized as the following. Obviously the item
> column doesn?t need to exist, but wanted to show what I was going for.
>
> Participant
>
> Item
>
> Week
>
> Response
>
> 1
>
> 1-6
>
> 1
>
> 2
>
> 2
>
> 1-6
>
> 1
>
> 4
>
> etc
>
>
>
>
>
>
>
>
>
> Is there a way to create a new data file with the restructured format
> without having to add the responses for each participant within each
> condition myself?
>
> Thanks,
>
> Katie
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From c.c.voeten at hum.leidenuniv.nl  Mon Mar 19 21:52:00 2018
From: c.c.voeten at hum.leidenuniv.nl (Voeten, C.C.)
Date: Mon, 19 Mar 2018 20:52:00 +0000
Subject: [R-sig-ME] Refitting model with ML -- why search for optimal theta
 again?
Message-ID: <D14049CE02C4F54D95360EEC06CE45C50F83B5D8@SPMXM08.VUW.leidenuniv.nl>

Dear list,

I apologize in advance if this question is stupid; it's just that there's something that I do not understand and I would like to learn more. I know that for linear mixed models, optimizing via ML provides slightly anticonservative parameter estimates; as I understand it, this is because ML estimates ? without taking into account uncertainty in the estimates for ? (since the two are estimated simultaneously). This uncertainty can be taken into account by optimizing the REML criterion instead, which integrates out the unknown ?, and hence finds estimates for ? that should be appropriate for *any* value that ? could have had.

If this is correct, the REML criterion contains an added constant that varies depending on the provided fixed-effects structure, and hence REML fits with different fixed effects cannot be compared. When asking for the anova() of two REML-fitted lme4 objects, the package thus refits the models using ML:


> library(lme4)
Loading required package: Matrix
> big <- lmer(Reaction ~ Days + (1|Subject),sleepstudy)
> small <- lmer(Reaction ~ (1|Subject),sleepstudy)
> anova(small,big) # refits model
refitting model(s) with ML (instead of REML)
Data: sleepstudy
Models:
small: Reaction ~ (1 | Subject)
big: Reaction ~ Days + (1 | Subject)
      Df    AIC    BIC  logLik deviance  Chisq Chi Df Pr(>Chisq)    
small  3 1916.5 1926.1 -955.27   1910.5                             
big    4 1802.1 1814.8 -897.04   1794.1 116.46      1  < 2.2e-16 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1


This is what I do not understand: why do we need to re-optimize the (now ML) objective function, when we already have the optimal values in big at theta and small at theta? Starting from the REML criterion, we would only need to take out the integrated fixed effects, and then we end up with an ML likelihood, correct? But then, why can't I simply do:

> big.LLML <- update(big,REML=F,devFunOnly=T)(big at theta) #compute ML deviance based on optimal theta
> small.LLML <- update(small,REML=F,devFunOnly=T)(small at theta)
> small.LLML - big.LLML # same difference, without needing to re-fit!
[1] 116.4677

i.e. take the already-found optimal ? values and plug them into the ML formula? Why do we need to search for the optimal ? values again -- even if the values found by ML differ from those found by REML, shouldn't the REML values be preferred?

Thank you very much for any insights,
Cesko


From jake.a.westfall at gmail.com  Mon Mar 19 22:03:17 2018
From: jake.a.westfall at gmail.com (Jake Westfall)
Date: Mon, 19 Mar 2018 16:03:17 -0500
Subject: [R-sig-ME] 
 Refitting model with ML -- why search for optimal theta again?
In-Reply-To: <D14049CE02C4F54D95360EEC06CE45C50F83B5D8@SPMXM08.VUW.leidenuniv.nl>
References: <D14049CE02C4F54D95360EEC06CE45C50F83B5D8@SPMXM08.VUW.leidenuniv.nl>
Message-ID: <CAE9_Wg6mLTXFNkVp59FQbuaJEH5DWuHQNdsuuiQVYghyCDZ+7Q@mail.gmail.com>

Hi Cesko,

why can't I simply [...] take the already-found optimal ? values and plug
> them into the ML formula? Why do we need to search for the optimal ? values
> again? even if the values found by ML differ from those found by REML,
> shouldn't the REML values be preferred?


Optimizing the likelihood vs. the REML criterion leads to different ?
estimates. The statistical theory underlying the likelihood ratio test only
holds for ML estimates of ?, not REML estimates. You can compute the
likelihood value for the REML estimates, as you do in your code example,
but this doesn't change the fact that they are REML estimates and not ML
estimates.

Jake

On Mon, Mar 19, 2018 at 3:52 PM, Voeten, C.C. <c.c.voeten at hum.leidenuniv.nl>
wrote:

> Dear list,
>
> I apologize in advance if this question is stupid; it's just that there's
> something that I do not understand and I would like to learn more. I know
> that for linear mixed models, optimizing via ML provides slightly
> anticonservative parameter estimates; as I understand it, this is because
> ML estimates ? without taking into account uncertainty in the estimates for
> ? (since the two are estimated simultaneously). This uncertainty can be
> taken into account by optimizing the REML criterion instead, which
> integrates out the unknown ?, and hence finds estimates for ? that should
> be appropriate for *any* value that ? could have had.
>
> If this is correct, the REML criterion contains an added constant that
> varies depending on the provided fixed-effects structure, and hence REML
> fits with different fixed effects cannot be compared. When asking for the
> anova() of two REML-fitted lme4 objects, the package thus refits the models
> using ML:
>
>
> > library(lme4)
> Loading required package: Matrix
> > big <- lmer(Reaction ~ Days + (1|Subject),sleepstudy)
> > small <- lmer(Reaction ~ (1|Subject),sleepstudy)
> > anova(small,big) # refits model
> refitting model(s) with ML (instead of REML)
> Data: sleepstudy
> Models:
> small: Reaction ~ (1 | Subject)
> big: Reaction ~ Days + (1 | Subject)
>       Df    AIC    BIC  logLik deviance  Chisq Chi Df Pr(>Chisq)
> small  3 1916.5 1926.1 -955.27   1910.5
> big    4 1802.1 1814.8 -897.04   1794.1 116.46      1  < 2.2e-16 ***
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
>
> This is what I do not understand: why do we need to re-optimize the (now
> ML) objective function, when we already have the optimal values in big at theta
> and small at theta? Starting from the REML criterion, we would only need to
> take out the integrated fixed effects, and then we end up with an ML
> likelihood, correct? But then, why can't I simply do:
>
> > big.LLML <- update(big,REML=F,devFunOnly=T)(big at theta) #compute ML
> deviance based on optimal theta
> > small.LLML <- update(small,REML=F,devFunOnly=T)(small at theta)
> > small.LLML - big.LLML # same difference, without needing to re-fit!
> [1] 116.4677
>
> i.e. take the already-found optimal ? values and plug them into the ML
> formula? Why do we need to search for the optimal ? values again -- even if
> the values found by ML differ from those found by REML, shouldn't the REML
> values be preferred?
>
> Thank you very much for any insights,
> Cesko
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From john.maindonald at anu.edu.au  Tue Mar 20 00:32:12 2018
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Mon, 19 Mar 2018 23:32:12 +0000
Subject: [R-sig-ME] 
 different overdispersion parameter for binomial GLMM in,
 lme4, glmmADMB and glmmTMB (Muldoon, Ariel)
In-Reply-To: <3ba6300e-5116-a345-772f-1a6291f1143c@highstat.com>
References: <mailman.16225.2244.1521232751.1673.r-sig-mixed-models@r-project.org>
 <3ba6300e-5116-a345-772f-1a6291f1143c@highstat.com>
Message-ID: <90DB236D-89CB-4D0D-AA19-74EF17B1F353@anu.edu.au>

I have just now posted a document that bears on this at: https://rpubs.com/johnhm/Overdispersed

It explores, with a dataset that relates to work in which I have recently been involved,
the glmmTMB?s package recently added ability to use the betabinomial family to
model what is effectively dispersion, defined as the factor by which the variance
exceeds the binomial variance.  These abilities are clearly relatively undeveloped.
(I had to delve to discover how to extract the estimates of theta, for which see below.)
I was surprised at how easy it was to get models to converge that are some way
sensible.  What have others done to explore these abilities?  Comments will be very
welcome.

The betabinomial implies that the ?dispersion? increases with the binomial size n,
whereas quasibinomial models assume a ?dispersion" that is independent of n.

[The beta-binomial distribution accounts for a multiplier (effectively, a ?dispersion?
estimate) that is the ratio of the beta-binomial variance to the binomial variance.
It is (1 + rho*(n-1)).  In the what I take to be the glmmTMB parameterization,
the variance is n*Pi*(1-Pi)*(1+(n-1)/(theta+1))

NB: Using the notation at,
  https://en.wikipedia.org/wiki/Beta-binomial_distribution
but substituting a=alpha and b=beta

Pi=a/(a+b); rho = 1/(a+b+1); theta=a+b]

John Maindonald             email: john.maindonald at anu.edu.au<mailto:john.maindonald at anu.edu.au>

On 17/03/2018, at 10:04, Highland Statistics Ltd <highstat at highstat.com<mailto:highstat at highstat.com>> wrote:


Ben, sorry but I am bit confused by your answer. If I understand
correctly, the approach you would recommend is to calculate the
dispersion parameter on the binomial model and if there is
overdispersion compare models with different ways to deal with it (e.g
observation-level random effects and beta-binomial) to the binomial one
to find out which ones fits the data better. Is that correct? And so
there would be no point in calculating the dispersion parameter for the
OLRE and beta-binomial model and see how much it goes down?

Cheers,

Correct. Overdispersion/underdispersion is only relevant for distributions in which the variance is determined by the mean. Like the Poisson: mean(Y) = var(Y)  and the binomial: E(Y) = N * pi and var(Y) = Pi * N * (1 - Pi).

No need to check for overdispersion for the normal, Gamma, inverse Gaussian, beta-binomial, and beta distributions. These distributions have an extra parameter (like the variance in the normal distribution) in the variance term. Having said that...I am still confused why the Negative binomial GLM can be overdispersed. I guess that is because the NB GLM is not a real GLM and iterates between two algorithms (when doing frequentist analysis). I guess (again) it is more about whether the functional form of the NB variance is correct...or not.

Instead of using a dispersion statistic based on Pearson residuals (coming from models with fancy random effects) it is perhaps better to simulate data from your model and compare the variation in the simulated data with the variation in the observed data. Or do what Ben Bolker suggested a few days/weeks ago...simulate data and compare the corresponding residuals with the original residuals.

Alain





--

Dr. Alain F. Zuur
Highland Statistics Ltd.
9 St Clair Wynd
AB41 6DZ Newburgh, UK
Email: highstat at highstat.com<mailto:highstat at highstat.com>
URL:   www.highstat.com

And:
NIOZ Royal Netherlands Institute for Sea Research,
Department of Coastal Systems, and Utrecht University,
P.O. Box 59, 1790 AB Den Burg,
Texel, The Netherlands



Author of:
1. Beginner's Guide to Spatial, Temporal and Spatial-Temporal Ecological Data Analysis with R-INLA. (2017).
2. Beginner's Guide to Zero-Inflated Models with R (2016).
3. Beginner's Guide to Data Exploration and Visualisation with R (2015).
4. Beginner's Guide to GAMM with R (2014).
5. Beginner's Guide to GLM and GLMM with R (2013).
6. Beginner's Guide to GAM with R (2012).
7. Zero Inflated Models and GLMM with R (2012).
8. A Beginner's Guide to R (2009).
9. Mixed effects models and extensions in ecology with R (2009).
10. Analysing Ecological Data (2007).

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


	[[alternative HTML version deleted]]


From vincent.koppelmans at utah.edu  Tue Mar 20 06:58:22 2018
From: vincent.koppelmans at utah.edu (VINCENT KOPPELMANS)
Date: Tue, 20 Mar 2018 05:58:22 +0000
Subject: [R-sig-ME] Repeated-measures analysis with count data following a
 negative-binomial distribution
Message-ID: <D6D5FF1D.178E%u6012627@umail.utah.edu>

Dear all,

I am looking for advice on how to run a repeated analysis on count data.

My issue is as follows:

  *   We counted the number of carotid plaques from ultrasound images in a diseased population and a group of control subjects
  *   We have measured the plaques for all subjects in both the left and the right carotid artery during the same session
  *   The number of plaques is a count score ranging from 0 to 6
  *   The distributions look like this:
     *   Plaques in the left carotid artery: https://www.dropbox.com/s/t5tqh4wjrfc5eml/Left.png?dl=0
     *   Plaques in the right carotid artery: https://www.dropbox.com/s/nl5ezef145av2ae/Right.png?dl=0
     *   (Where NKI= the diseased population; RSS= the control subjects; (all)= the two groups combined. There are no numbers on the x-axis, but the 7 columns are the count scores 0-6 (left to right).)
  *   There is biological evidence that the distribution of plaques for left and right differ in the general population (i.e., our control subjects).
  *   I would like to test if the difference in distribution of plaque scores between the left and right carotid arteries is different between my two populations.
  *   Previous analyses (e.g., comparing a single side between groups) showed me that a negative binomial distribution is a better fit for my data than a Poisson distribution.

My idea is to run a repeated-measures negative binomial regression analysis where plaque score measures (left and right) would be the repeated measures. In this case I would be interested in the ?body side? by group interaction.

My questions are:

  *   Is a good and valid approach?
  *   I am thinking about using R?s GEE package (https://cran.r-project.org/web/packages/gee/index.html). Would that be the right tool for this job?

Thanks!

- Vincent

	[[alternative HTML version deleted]]


From Maarten.Jung at mailbox.tu-dresden.de  Tue Mar 20 09:00:30 2018
From: Maarten.Jung at mailbox.tu-dresden.de (Maarten Jung)
Date: Tue, 20 Mar 2018 09:00:30 +0100
Subject: [R-sig-ME] What is the lmer/nlme equivalent of the REPEATED
 subcommand in SPSS's MIXED procedure?
Message-ID: <CAHr4Dyep9JCDpNauViVf0MyeH-=p7k0fx3yXbMCL_b-9tLTMEQ@mail.gmail.com>

Dear list,
I came across a SPSS syntax like this

MIXED value BY factor1
    /CRITERIA=CIN(95) MXITER(100) MXSTEP(10) SCORING(1)
SINGULAR(0.000000000001)
    HCONVERGE(0, ABSOLUTE) LCONVERGE(0, ABSOLUTE) PCONVERGE(0.000001,
    ABSOLUTE)
    /FIXED=factor1 | SSTYPE(3)
    /METHOD=REML
    /REPEATED=factor1 | SUBJECT(participant) COVTYPE(UN).

and struggle to find an equivalent lmer/nlme (or R in general) formulation
for this kind of models.
Does anybody know how to convert the REPEATED subcommand into R code?

Please note that I asked the question on Stack Overflow about two month ago:
https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc

Best regards,
Maarten

	[[alternative HTML version deleted]]


From christoph.huber-huber at univie.ac.at  Tue Mar 20 10:59:55 2018
From: christoph.huber-huber at univie.ac.at (Christoph Huber)
Date: Tue, 20 Mar 2018 10:59:55 +0100
Subject: [R-sig-ME] Refitting model with ML -- why search for optimal theta
 again?
In-Reply-To: <mailman.16233.2351.1521493403.1673.r-sig-mixed-models@r-project.org>
References: <mailman.16233.2351.1521493403.1673.r-sig-mixed-models@r-project.org>
Message-ID: <8AC532B4-C885-4CF1-A8C6-4F7BF1F7F39D@univie.ac.at>

Hi Jake and Cesko,

You answer, Jake, triggered a follow-up question:

> 
>> why can't I simply [...] take the already-found optimal ? values and plug
>> them into the ML formula? Why do we need to search for the optimal ? values
>> again? even if the values found by ML differ from those found by REML,
>> shouldn't the REML values be preferred?
> 
> 
> Optimizing the likelihood vs. the REML criterion leads to different ?
> estimates. The statistical theory underlying the likelihood ratio test only
> holds for ML estimates of ?, not REML estimates. You can compute the
> likelihood value for the REML estimates, as you do in your code example,
> but this doesn't change the fact that they are REML estimates and not ML
> estimates.
> 

I thought it is valid to test for random slope correlations with the anova command while setting refit = F.
Say, we have two lmer models with a 2-level factor "a? and a random factor "A?. Say, these two models differ only in their random slope correlations, like that:
remlfit1 <- lmer(y ~ a + (1 | A) + (0 + a | A ), data = mydata)
remlfit2 <- lmer(y ~ a + (a | A ), data = mydata)

Is it then valid to test for the correlation parameter between "(Intercept)? and "a? with:
anova(remlfit1, remlfit2, refit = F)
?

The response to Cesko made me doubt this approach.

Many thanks,
Christoph


?
Dr. Christoph Huber-Huber
Center for Mind/Brain Sciences (CIMeC)
University of Trento
Corso Bettini 31
38068 Rovereto (TN), Italy

e-mail: christoph.huberhuber at unitn.it <mailto:christoph.huberhuber at unitn.it>



	[[alternative HTML version deleted]]


From phillip.alday at mpi.nl  Tue Mar 20 11:44:01 2018
From: phillip.alday at mpi.nl (Phillip Alday)
Date: Tue, 20 Mar 2018 11:44:01 +0100
Subject: [R-sig-ME] What is the lmer/nlme equivalent of the REPEATED
 subcommand in SPSS's MIXED procedure?
In-Reply-To: <CAHr4Dyep9JCDpNauViVf0MyeH-=p7k0fx3yXbMCL_b-9tLTMEQ@mail.gmail.com>
References: <CAHr4Dyep9JCDpNauViVf0MyeH-=p7k0fx3yXbMCL_b-9tLTMEQ@mail.gmail.com>
Message-ID: <88ca0109-4f98-7d87-35d4-5d4d95f8e13a@mpi.nl>

I suspect that /REPEATED is just the way to specify random effects, so

random=~factor1|participant in nlme.

(I'm also guessing that the intercept in both the fixed and the random
effects is implicit.)

Phillip



On 20/03/18 09:00, Maarten Jung wrote:
> Dear list,
> I came across a SPSS syntax like this
> 
> MIXED value BY factor1
>     /CRITERIA=CIN(95) MXITER(100) MXSTEP(10) SCORING(1)
> SINGULAR(0.000000000001)
>     HCONVERGE(0, ABSOLUTE) LCONVERGE(0, ABSOLUTE) PCONVERGE(0.000001,
>     ABSOLUTE)
>     /FIXED=factor1 | SSTYPE(3)
>     /METHOD=REML
>     /REPEATED=factor1 | SUBJECT(participant) COVTYPE(UN).
> 
> and struggle to find an equivalent lmer/nlme (or R in general) formulation
> for this kind of models.
> Does anybody know how to convert the REPEATED subcommand into R code?
> 
> Please note that I asked the question on Stack Overflow about two month ago:
> https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
> 
> Best regards,
> Maarten
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From thierry.onkelinx at inbo.be  Tue Mar 20 13:22:34 2018
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Tue, 20 Mar 2018 13:22:34 +0100
Subject: [R-sig-ME] 
 Repeated-measures analysis with count data following a
 negative-binomial distribution
In-Reply-To: <D6D5FF1D.178E%u6012627@umail.utah.edu>
References: <D6D5FF1D.178E%u6012627@umail.utah.edu>
Message-ID: <CAJuCY5xFQzE6aahNxpV_1y=gK7StavL4ikwtjRuzypnbP-R7RQ@mail.gmail.com>

Dear Vincent,

A mixed model with subject as random intercept is recommended. You need to
think about the counts. Are they really counts? Or are they an ordinal
factor? The negative binomial distribution is OK in case of counts.

GEE is valid in case you want the estimate the marginal effects. Use lme4
or similar when you want conditional effects.

Best regards,


ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>

2018-03-20 6:58 GMT+01:00 VINCENT KOPPELMANS <vincent.koppelmans at utah.edu>:

> Dear all,
>
> I am looking for advice on how to run a repeated analysis on count data.
>
> My issue is as follows:
>
>   *   We counted the number of carotid plaques from ultrasound images in a
> diseased population and a group of control subjects
>   *   We have measured the plaques for all subjects in both the left and
> the right carotid artery during the same session
>   *   The number of plaques is a count score ranging from 0 to 6
>   *   The distributions look like this:
>      *   Plaques in the left carotid artery: https://www.dropbox.com/s/
> t5tqh4wjrfc5eml/Left.png?dl=0
>      *   Plaques in the right carotid artery: https://www.dropbox.com/s/
> nl5ezef145av2ae/Right.png?dl=0
>      *   (Where NKI= the diseased population; RSS= the control subjects;
> (all)= the two groups combined. There are no numbers on the x-axis, but the
> 7 columns are the count scores 0-6 (left to right).)
>   *   There is biological evidence that the distribution of plaques for
> left and right differ in the general population (i.e., our control
> subjects).
>   *   I would like to test if the difference in distribution of plaque
> scores between the left and right carotid arteries is different between my
> two populations.
>   *   Previous analyses (e.g., comparing a single side between groups)
> showed me that a negative binomial distribution is a better fit for my data
> than a Poisson distribution.
>
> My idea is to run a repeated-measures negative binomial regression
> analysis where plaque score measures (left and right) would be the repeated
> measures. In this case I would be interested in the ?body side? by group
> interaction.
>
> My questions are:
>
>   *   Is a good and valid approach?
>   *   I am thinking about using R?s GEE package (
> https://cran.r-project.org/web/packages/gee/index.html). Would that be
> the right tool for this job?
>
> Thanks!
>
> - Vincent
>
>         [[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>

	[[alternative HTML version deleted]]


From b.pelzer at maw.ru.nl  Tue Mar 20 14:10:56 2018
From: b.pelzer at maw.ru.nl (Ben Pelzer)
Date: Tue, 20 Mar 2018 14:10:56 +0100
Subject: [R-sig-ME] What is the lmer/nlme equivalent of the REPEATED
 subcommand in SPSS's MIXED procedure?
In-Reply-To: <CAHr4Dyep9JCDpNauViVf0MyeH-=p7k0fx3yXbMCL_b-9tLTMEQ@mail.gmail.com>
References: <CAHr4Dyep9JCDpNauViVf0MyeH-=p7k0fx3yXbMCL_b-9tLTMEQ@mail.gmail.com>
Message-ID: <d67d36fb-1019-d878-794e-491c3a409f2a@maw.ru.nl>

Dear Maarten,

Take a look at

https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/

which shows you a number of covariance structures, among which is the 
unstructured matrix, for repeated measures in R with lme. It refers to 
chapter 7 of Singer and Willett where they discuss all these different 
structures and how to choose among them. Regards,

Ben.

On 20-3-2018 9:00, Maarten Jung wrote:
> Dear list,
> I came across a SPSS syntax like this
>
> MIXED value BY factor1
>      /CRITERIA=CIN(95) MXITER(100) MXSTEP(10) SCORING(1)
> SINGULAR(0.000000000001)
>      HCONVERGE(0, ABSOLUTE) LCONVERGE(0, ABSOLUTE) PCONVERGE(0.000001,
>      ABSOLUTE)
>      /FIXED=factor1 | SSTYPE(3)
>      /METHOD=REML
>      /REPEATED=factor1 | SUBJECT(participant) COVTYPE(UN).
>
> and struggle to find an equivalent lmer/nlme (or R in general) formulation
> for this kind of models.
> Does anybody know how to convert the REPEATED subcommand into R code?
>
> Please note that I asked the question on Stack Overflow about two month ago:
> https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
>
> Best regards,
> Maarten
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From louise.heitzmann at etu.umontpellier.fr  Tue Mar 20 15:24:19 2018
From: louise.heitzmann at etu.umontpellier.fr (Louise Heitzmann)
Date: Tue, 20 Mar 2018 15:24:19 +0100 (CET)
Subject: [R-sig-ME] GLMM power analysis
Message-ID: <639402477.2227340.1521555859965.JavaMail.zimbra@etu.umontpellier.fr>

Hi, 


I am working on seals' behaviour related to 6 treatments (2*3 treatments tested seperately over time). My response variable is a counting (number of nasal openings) which follow a Poisson Distribution. 

The experimental design is : 

2 seals' individuals in a box, there is 7 box, and experiments are repeated during 7 days. Each pair of individuals are tested in their specific box, but not all pairs are tested every day : sometimes only 5 pairs . Thus, I have between 6 and 10 repeated mesures per individual per treatment and I have a nested (Box,Individuals) and crossed (Days) design. 

My model looks like : y = ?0 + ? * Treatment + ( 1|Box/individus) +(1|Days) 

I want to do a power analysis to test the ability to detect a true effect. Thus, I was wondering how can I make a power analysis related to my model ? 

Thank you for considering my request, 
Louise heitzmann 

-- 
Master degree - Evolutionary Biology & Ecology - 2nd year 
Facult? des Sciences, Montpellier 
France 

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Tue Mar 20 16:33:57 2018
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 20 Mar 2018 11:33:57 -0400
Subject: [R-sig-ME] GLMM power analysis
In-Reply-To: <639402477.2227340.1521555859965.JavaMail.zimbra@etu.umontpellier.fr>
References: <639402477.2227340.1521555859965.JavaMail.zimbra@etu.umontpellier.fr>
Message-ID: <a9338a8a-1cbf-8841-bbba-b498ac15dd76@gmail.com>


  This is typically done by simulation.  Googling "glmm power
simulation" gives a lot of useful hits.  There are R packages:

library(sos)
sos::findFn("{power analysis} mixed simulation")

turns up the fullfact, pamm, simr, simglm packages ... or you can write
it yourself (the simulate() method.

There are a variety of publications on this subject, too:

Johnson, Paul C. D., Sarah J. E. Barry, Heather M. Ferguson, and Pie
M?ller. ?Power Analysis for Generalized Linear Mixed Models in Ecology
and Evolution.? Methods in Ecology and Evolution 6, no. 2 (February 1,
2015): 133?42. https://doi.org/10.1111/2041-210X.12306.


Kain, Morgan P., Ben M. Bolker, and Michael W. McCoy. ?A Practical Guide
and Power Analysis for GLMMs: Detecting among Treatment Variation in
Random Effects.? PeerJ 3 (September 17, 2015): e1226.
https://doi.org/10.7717/peerj.1226.

 working on updating the GLMM FAQ ...

On 18-03-20 10:24 AM, Louise Heitzmann wrote:
> Hi, 
> 
> 
> I am working on seals' behaviour related to 6 treatments (2*3 treatments tested seperately over time). My response variable is a counting (number of nasal openings) which follow a Poisson Distribution. 
> 
> The experimental design is : 
> 
> 2 seals' individuals in a box, there is 7 box, and experiments are repeated during 7 days. Each pair of individuals are tested in their specific box, but not all pairs are tested every day : sometimes only 5 pairs . Thus, I have between 6 and 10 repeated mesures per individual per treatment and I have a nested (Box,Individuals) and crossed (Days) design. 
> 
> My model looks like : y = ?0 + ? * Treatment + ( 1|Box/individus) +(1|Days) 
> 
> I want to do a power analysis to test the ability to detect a true effect. Thus, I was wondering how can I make a power analysis related to my model ? 
> 
> Thank you for considering my request, 
> Louise heitzmann 
>


From Maarten.Jung at mailbox.tu-dresden.de  Tue Mar 20 17:30:00 2018
From: Maarten.Jung at mailbox.tu-dresden.de (Maarten Jung)
Date: Tue, 20 Mar 2018 17:30:00 +0100
Subject: [R-sig-ME] What is the lmer/nlme equivalent of the REPEATED
 subcommand in SPSS's MIXED procedure?
In-Reply-To: <d67d36fb-1019-d878-794e-491c3a409f2a@maw.ru.nl>
References: <CAHr4Dyep9JCDpNauViVf0MyeH-=p7k0fx3yXbMCL_b-9tLTMEQ@mail.gmail.com>
 <d67d36fb-1019-d878-794e-491c3a409f2a@maw.ru.nl>
Message-ID: <CAHr4Dydq-SW_8aKUF=MFqnFpx6P36RSguP7gTF-6epZjMFWo3A@mail.gmail.com>

Dear Ben, dear Phillip,

comparing [1] with [2] I think the /REPEATED command specifies the error
(co)variance structure of the model. Would you agree with that?
If so, AFAIK this is not possible with lmer and thus the answer on Stack
Overflow [3] would be wrong.

[1]
https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/
[2]
https://stats.idre.ucla.edu/spss/examples/alda/chapter7/applied-longitudinal-data-analysis-modeling-change-and-event-occurrenceby-judith-d-singer-and-john-b-willett-chapter-7-examining-the-multilevel-model-s-erro/
[3]
https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc

Regards,
Maarten

On Tue, Mar 20, 2018 at 2:10 PM, Ben Pelzer <b.pelzer at maw.ru.nl> wrote:

> Dear Maarten,
>
> Take a look at
>
> https://stats.idre.ucla.edu/r/examples/alda/r-applied-longit
> udinal-data-analysis-ch-7/
>
> which shows you a number of covariance structures, among which is the
> unstructured matrix, for repeated measures in R with lme. It refers to
> chapter 7 of Singer and Willett where they discuss all these different
> structures and how to choose among them. Regards,
>
> Ben.
>
> On 20-3-2018 9:00, Maarten Jung wrote:
>
>> Dear list,
>> I came across a SPSS syntax like this
>>
>> MIXED value BY factor1
>>      /CRITERIA=CIN(95) MXITER(100) MXSTEP(10) SCORING(1)
>> SINGULAR(0.000000000001)
>>      HCONVERGE(0, ABSOLUTE) LCONVERGE(0, ABSOLUTE) PCONVERGE(0.000001,
>>      ABSOLUTE)
>>      /FIXED=factor1 | SSTYPE(3)
>>      /METHOD=REML
>>      /REPEATED=factor1 | SUBJECT(participant) COVTYPE(UN).
>>
>> and struggle to find an equivalent lmer/nlme (or R in general) formulation
>> for this kind of models.
>> Does anybody know how to convert the REPEATED subcommand into R code?
>>
>> Please note that I asked the question on Stack Overflow about two month
>> ago:
>> https://stackoverflow.com/questions/48518514/what-is-the-
>> lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
>>
>> Best regards,
>> Maarten
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From phillip.alday at mpi.nl  Tue Mar 20 17:48:20 2018
From: phillip.alday at mpi.nl (Phillip Alday)
Date: Tue, 20 Mar 2018 17:48:20 +0100
Subject: [R-sig-ME] What is the lmer/nlme equivalent of the REPEATED
 subcommand in SPSS's MIXED procedure?
In-Reply-To: <CAHr4Dydq-SW_8aKUF=MFqnFpx6P36RSguP7gTF-6epZjMFWo3A@mail.gmail.com>
References: <CAHr4Dyep9JCDpNauViVf0MyeH-=p7k0fx3yXbMCL_b-9tLTMEQ@mail.gmail.com>
 <d67d36fb-1019-d878-794e-491c3a409f2a@maw.ru.nl>
 <CAHr4Dydq-SW_8aKUF=MFqnFpx6P36RSguP7gTF-6epZjMFWo3A@mail.gmail.com>
Message-ID: <66fbb099-2bb8-9986-5d6d-5150d291d524@mpi.nl>

Perhaps somebody with a better understanding of the covariance structure
in lme4 can comment, but I thought that lmer used an unstructured
covariance structure.  This seems to be one of the "bigger" nlme
features missing from lme4 -- there's no way to specify a structured
covariance such as AR1, etc.

(If I'm wrong, I would love to be corrected as it will only help my own
understanding of these things!)

Phillip



On 20/03/18 17:30, Maarten Jung wrote:
> Dear Ben, dear Phillip,
> 
> comparing [1] with [2] I think the /REPEATED command specifies the error
> (co)variance structure of the model. Would you agree with that?
> If so, AFAIK this is not possible with lmer and thus the answer on Stack
> Overflow [3] would be wrong.
> 
> [1] https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/
> [2] https://stats.idre.ucla.edu/spss/examples/alda/chapter7/applied-longitudinal-data-analysis-modeling-change-and-event-occurrenceby-judith-d-singer-and-john-b-willett-chapter-7-examining-the-multilevel-model-s-erro/
> [3]
> https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
> 
> Regards,
> Maarten
> 
> On Tue, Mar 20, 2018 at 2:10 PM, Ben Pelzer <b.pelzer at maw.ru.nl
> <mailto:b.pelzer at maw.ru.nl>> wrote:
> 
>     Dear Maarten,
> 
>     Take a look at
> 
>     https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/
>     <https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/>
> 
>     which shows you a number of covariance structures, among which is
>     the unstructured matrix, for repeated measures in R with lme. It
>     refers to chapter 7 of Singer and Willett where they discuss all
>     these different structures and how to choose among them. Regards,
> 
>     Ben.
> 
>     On 20-3-2018 9:00, Maarten Jung wrote:
> 
>         Dear list,
>         I came across a SPSS syntax like this
> 
>         MIXED value BY factor1
>              /CRITERIA=CIN(95) MXITER(100) MXSTEP(10) SCORING(1)
>         SINGULAR(0.000000000001)
>              HCONVERGE(0, ABSOLUTE) LCONVERGE(0, ABSOLUTE)
>         PCONVERGE(0.000001,
>              ABSOLUTE)
>              /FIXED=factor1 | SSTYPE(3)
>              /METHOD=REML
>              /REPEATED=factor1 | SUBJECT(participant) COVTYPE(UN).
> 
>         and struggle to find an equivalent lmer/nlme (or R in general)
>         formulation
>         for this kind of models.
>         Does anybody know how to convert the REPEATED subcommand into R
>         code?
> 
>         Please note that I asked the question on Stack Overflow about
>         two month ago:
>         https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
>         <https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc>
> 
>         Best regards,
>         Maarten
> 
>                 [[alternative HTML version deleted]]
> 
>         _______________________________________________
>         R-sig-mixed-models at r-project.org
>         <mailto:R-sig-mixed-models at r-project.org> mailing list
>         https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>         <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> 
> 
>     _______________________________________________
>     R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> 
>


From paul.johnson at glasgow.ac.uk  Tue Mar 20 17:56:06 2018
From: paul.johnson at glasgow.ac.uk (Paul Johnson)
Date: Tue, 20 Mar 2018 16:56:06 +0000
Subject: [R-sig-ME] 
 Repeated-measures analysis with count data following a
 negative-binomial distribution
In-Reply-To: <D6D5FF1D.178E%u6012627@umail.utah.edu>
References: <D6D5FF1D.178E%u6012627@umail.utah.edu>
Message-ID: <DB9A707F-1D2D-45A4-9972-ED73EEC662BA@glasgow.ac.uk>

Just on the GEE vs GLMM question, this is a really nice clear article explaining the differences and how to choose:

Marginal or conditional regression models for correlated non?normal data?
Muff et al. 2016 MEE.
https://doi.org/10.1111/2041-210X.12623

Remarkably it has been cited only once in 2 years (Google Scholar).

To summarise their recommendations: in most cases you'll want a conditional (GLMM) model.



> On 20 Mar 2018, at 05:58, VINCENT KOPPELMANS <vincent.koppelmans at utah.edu> wrote:
> 
> Dear all,
> 
> I am looking for advice on how to run a repeated analysis on count data.
> 
> My issue is as follows:
> 
>  *   We counted the number of carotid plaques from ultrasound images in a diseased population and a group of control subjects
>  *   We have measured the plaques for all subjects in both the left and the right carotid artery during the same session
>  *   The number of plaques is a count score ranging from 0 to 6
>  *   The distributions look like this:
>     *   Plaques in the left carotid artery: https://www.dropbox.com/s/t5tqh4wjrfc5eml/Left.png?dl=0
>     *   Plaques in the right carotid artery: https://www.dropbox.com/s/nl5ezef145av2ae/Right.png?dl=0
>     *   (Where NKI= the diseased population; RSS= the control subjects; (all)= the two groups combined. There are no numbers on the x-axis, but the 7 columns are the count scores 0-6 (left to right).)
>  *   There is biological evidence that the distribution of plaques for left and right differ in the general population (i.e., our control subjects).
>  *   I would like to test if the difference in distribution of plaque scores between the left and right carotid arteries is different between my two populations.
>  *   Previous analyses (e.g., comparing a single side between groups) showed me that a negative binomial distribution is a better fit for my data than a Poisson distribution.
> 
> My idea is to run a repeated-measures negative binomial regression analysis where plaque score measures (left and right) would be the repeated measures. In this case I would be interested in the ?body side? by group interaction.
> 
> My questions are:
> 
>  *   Is a good and valid approach?
>  *   I am thinking about using R?s GEE package (https://cran.r-project.org/web/packages/gee/index.html). Would that be the right tool for this job?
> 
> Thanks!
> 
> - Vincent
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From b.pelzer at maw.ru.nl  Tue Mar 20 18:11:58 2018
From: b.pelzer at maw.ru.nl (Ben Pelzer)
Date: Tue, 20 Mar 2018 18:11:58 +0100
Subject: [R-sig-ME] What is the lmer/nlme equivalent of the REPEATED
 subcommand in SPSS's MIXED procedure?
In-Reply-To: <CAHr4Dydq-SW_8aKUF=MFqnFpx6P36RSguP7gTF-6epZjMFWo3A@mail.gmail.com>
References: <CAHr4Dyep9JCDpNauViVf0MyeH-=p7k0fx3yXbMCL_b-9tLTMEQ@mail.gmail.com>
 <d67d36fb-1019-d878-794e-491c3a409f2a@maw.ru.nl>
 <CAHr4Dydq-SW_8aKUF=MFqnFpx6P36RSguP7gTF-6epZjMFWo3A@mail.gmail.com>
Message-ID: <5AB140DE.5090705@maw.ru.nl>

Hi Maarten,

You are right: you need nlme and NOT lme4 to specify particular 
correlation structures. Also, in nlme you would need gls to make it 
similar to mixed in spss. The repeated command in spss gives the same 
results as gls does for any of the covariance structures.

Regards, Ben.


On 20/03/2018 17:30, Maarten Jung wrote:
> Dear Ben, dear Phillip,
>
> comparing [1] with [2] I think the /REPEATED command specifies 
> the error (co)variance structure of the model. Would you agree with that?
> If so, AFAIK this is not possible with lmer and thus the answer on 
> Stack Overflow [3] would be wrong.
>
> [1] 
> https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/
> [2] 
> https://stats.idre.ucla.edu/spss/examples/alda/chapter7/applied-longitudinal-data-analysis-modeling-change-and-event-occurrenceby-judith-d-singer-and-john-b-willett-chapter-7-examining-the-multilevel-model-s-erro/
> [3] 
> https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
>
> Regards,
> Maarten
>
> On Tue, Mar 20, 2018 at 2:10 PM, Ben Pelzer <b.pelzer at maw.ru.nl 
> <mailto:b.pelzer at maw.ru.nl>> wrote:
>
>     Dear Maarten,
>
>     Take a look at
>
>     https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/
>     <https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/>
>
>     which shows you a number of covariance structures, among which is
>     the unstructured matrix, for repeated measures in R with lme. It
>     refers to chapter 7 of Singer and Willett where they discuss all
>     these different structures and how to choose among them. Regards,
>
>     Ben.
>
>     On 20-3-2018 9:00, Maarten Jung wrote:
>
>         Dear list,
>         I came across a SPSS syntax like this
>
>         MIXED value BY factor1
>              /CRITERIA=CIN(95) MXITER(100) MXSTEP(10) SCORING(1)
>         SINGULAR(0.000000000001)
>              HCONVERGE(0, ABSOLUTE) LCONVERGE(0, ABSOLUTE)
>         PCONVERGE(0.000001,
>              ABSOLUTE)
>              /FIXED=factor1 | SSTYPE(3)
>              /METHOD=REML
>              /REPEATED=factor1 | SUBJECT(participant) COVTYPE(UN).
>
>         and struggle to find an equivalent lmer/nlme (or R in general)
>         formulation
>         for this kind of models.
>         Does anybody know how to convert the REPEATED subcommand into
>         R code?
>
>         Please note that I asked the question on Stack Overflow about
>         two month ago:
>         https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
>         <https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc>
>
>         Best regards,
>         Maarten
>
>                 [[alternative HTML version deleted]]
>
>         _______________________________________________
>         R-sig-mixed-models at r-project.org
>         <mailto:R-sig-mixed-models at r-project.org> mailing list
>         https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>         <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>
>
>     _______________________________________________
>     R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>
>


	[[alternative HTML version deleted]]


From mollieebrooks at gmail.com  Tue Mar 20 18:19:29 2018
From: mollieebrooks at gmail.com (Mollie Brooks)
Date: Tue, 20 Mar 2018 18:19:29 +0100
Subject: [R-sig-ME] What is the lmer/nlme equivalent of the REPEATED
 subcommand in SPSS's MIXED procedure?
In-Reply-To: <5AB140DE.5090705@maw.ru.nl>
References: <CAHr4Dyep9JCDpNauViVf0MyeH-=p7k0fx3yXbMCL_b-9tLTMEQ@mail.gmail.com>
 <d67d36fb-1019-d878-794e-491c3a409f2a@maw.ru.nl>
 <CAHr4Dydq-SW_8aKUF=MFqnFpx6P36RSguP7gTF-6epZjMFWo3A@mail.gmail.com>
 <5AB140DE.5090705@maw.ru.nl>
Message-ID: <9ECC9EC8-43DB-49AD-97E0-67E5E680460A@gmail.com>

I don?t know anything about spss, but if you basically want lme4 with more correlation structures, you could look at the structures available with glmmTMB. 
https://cran.r-project.org/web/packages/glmmTMB/vignettes/covstruct.html

cheers,
Mollie

> On 20Mar 2018, at 18:11, Ben Pelzer <b.pelzer at maw.ru.nl> wrote:
> 
> Hi Maarten,
> 
> You are right: you need nlme and NOT lme4 to specify particular 
> correlation structures. Also, in nlme you would need gls to make it 
> similar to mixed in spss. The repeated command in spss gives the same 
> results as gls does for any of the covariance structures.
> 
> Regards, Ben.
> 
> 
> On 20/03/2018 17:30, Maarten Jung wrote:
>> Dear Ben, dear Phillip,
>> 
>> comparing [1] with [2] I think the /REPEATED command specifies 
>> the error (co)variance structure of the model. Would you agree with that?
>> If so, AFAIK this is not possible with lmer and thus the answer on 
>> Stack Overflow [3] would be wrong.
>> 
>> [1] 
>> https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/
>> [2] 
>> https://stats.idre.ucla.edu/spss/examples/alda/chapter7/applied-longitudinal-data-analysis-modeling-change-and-event-occurrenceby-judith-d-singer-and-john-b-willett-chapter-7-examining-the-multilevel-model-s-erro/
>> [3] 
>> https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
>> 
>> Regards,
>> Maarten
>> 
>> On Tue, Mar 20, 2018 at 2:10 PM, Ben Pelzer <b.pelzer at maw.ru.nl 
>> <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>>> wrote:
>> 
>>    Dear Maarten,
>> 
>>    Take a look at
>> 
>>    https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/ <https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/>
>>    <https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/ <https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/>>
>> 
>>    which shows you a number of covariance structures, among which is
>>    the unstructured matrix, for repeated measures in R with lme. It
>>    refers to chapter 7 of Singer and Willett where they discuss all
>>    these different structures and how to choose among them. Regards,
>> 
>>    Ben.
>> 
>>    On 20-3-2018 9:00, Maarten Jung wrote:
>> 
>>        Dear list,
>>        I came across a SPSS syntax like this
>> 
>>        MIXED value BY factor1
>>             /CRITERIA=CIN(95) MXITER(100) MXSTEP(10) SCORING(1)
>>        SINGULAR(0.000000000001)
>>             HCONVERGE(0, ABSOLUTE) LCONVERGE(0, ABSOLUTE)
>>        PCONVERGE(0.000001,
>>             ABSOLUTE)
>>             /FIXED=factor1 | SSTYPE(3)
>>             /METHOD=REML
>>             /REPEATED=factor1 | SUBJECT(participant) COVTYPE(UN).
>> 
>>        and struggle to find an equivalent lmer/nlme (or R in general)
>>        formulation
>>        for this kind of models.
>>        Does anybody know how to convert the REPEATED subcommand into
>>        R code?
>> 
>>        Please note that I asked the question on Stack Overflow about
>>        two month ago:
>>        https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc <https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc>
>>        <https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc <https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc>>
>> 
>>        Best regards,
>>        Maarten
>> 
>>                [[alternative HTML version deleted]]
>> 
>>        _______________________________________________
>>        R-sig-mixed-models at r-project.org <mailto:R-sig-mixed-models at r-project.org>
>>        <mailto:R-sig-mixed-models at r-project.org <mailto:R-sig-mixed-models at r-project.org>> mailing list
>>        https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>        <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
>> 
>> 
>>    _______________________________________________
>>    R-sig-mixed-models at r-project.org <mailto:R-sig-mixed-models at r-project.org>
>>    <mailto:R-sig-mixed-models at r-project.org <mailto:R-sig-mixed-models at r-project.org>> mailing list
>>    https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>    <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
>> 
>> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org <mailto:R-sig-mixed-models at r-project.org> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>

	[[alternative HTML version deleted]]


From bates at stat.wisc.edu  Tue Mar 20 18:34:24 2018
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 20 Mar 2018 17:34:24 +0000
Subject: [R-sig-ME] What is the lmer/nlme equivalent of the REPEATED
 subcommand in SPSS's MIXED procedure?
In-Reply-To: <20732_1521566386_0P5W00D4NG4WVU20_9ECC9EC8-43DB-49AD-97E0-67E5E680460A@gmail.com>
References: <CAHr4Dyep9JCDpNauViVf0MyeH-=p7k0fx3yXbMCL_b-9tLTMEQ@mail.gmail.com>
 <d67d36fb-1019-d878-794e-491c3a409f2a@maw.ru.nl>
 <CAHr4Dydq-SW_8aKUF=MFqnFpx6P36RSguP7gTF-6epZjMFWo3A@mail.gmail.com>
 <5AB140DE.5090705@maw.ru.nl>
 <20732_1521566386_0P5W00D4NG4WVU20_9ECC9EC8-43DB-49AD-97E0-67E5E680460A@gmail.com>
Message-ID: <CAO7JsnTCenXXrrrfJthUz5aLv2wiubdrzOw30mFY5AdUBmF=ig@mail.gmail.com>

Kind of looks like SPSS went for bug-for-bug compatibility with SAS on this
one.  In SAS PROC MIXED, "REPEATED" and "RANDOM" are two ways of specifying
the random effects variance structure but they often boil down to the same
model.

I believe the model can be specified in lme4 as

    value ~ factor1 + (factor1 | participant)

This is what the mis-named* "UNSTRUCTURED" covariance type means

* Old-guy, get off my lawn rant about terminology *
As a recovering mathematician I find the name "unstructured" being used to
denote a positive-definite symmetric matrix to be, well, inaccurate.

On Tue, Mar 20, 2018 at 12:19 PM Mollie Brooks <mollieebrooks at gmail.com>
wrote:

> I don?t know anything about spss, but if you basically want lme4 with more
> correlation structures, you could look at the structures available with
> glmmTMB.
> https://cran.r-project.org/web/packages/glmmTMB/vignettes/covstruct.html
>
> cheers,
> Mollie
>
> > On 20Mar 2018, at 18:11, Ben Pelzer <b.pelzer at maw.ru.nl> wrote:
> >
> > Hi Maarten,
> >
> > You are right: you need nlme and NOT lme4 to specify particular
> > correlation structures. Also, in nlme you would need gls to make it
> > similar to mixed in spss. The repeated command in spss gives the same
> > results as gls does for any of the covariance structures.
> >
> > Regards, Ben.
> >
> >
> > On 20/03/2018 17:30, Maarten Jung wrote:
> >> Dear Ben, dear Phillip,
> >>
> >> comparing [1] with [2] I think the /REPEATED command specifies
> >> the error (co)variance structure of the model. Would you agree with
> that?
> >> If so, AFAIK this is not possible with lmer and thus the answer on
> >> Stack Overflow [3] would be wrong.
> >>
> >> [1]
> >>
> https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/
> >> [2]
> >>
> https://stats.idre.ucla.edu/spss/examples/alda/chapter7/applied-longitudinal-data-analysis-modeling-change-and-event-occurrenceby-judith-d-singer-and-john-b-willett-chapter-7-examining-the-multilevel-model-s-erro/
> >> [3]
> >>
> https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
> >>
> >> Regards,
> >> Maarten
> >>
> >> On Tue, Mar 20, 2018 at 2:10 PM, Ben Pelzer <b.pelzer at maw.ru.nl
> >> <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>>> wrote:
> >>
> >>    Dear Maarten,
> >>
> >>    Take a look at
> >>
> >>
> https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/
> <
> https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/
> >
> >>    <
> https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/
> <
> https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/
> >>
> >>
> >>    which shows you a number of covariance structures, among which is
> >>    the unstructured matrix, for repeated measures in R with lme. It
> >>    refers to chapter 7 of Singer and Willett where they discuss all
> >>    these different structures and how to choose among them. Regards,
> >>
> >>    Ben.
> >>
> >>    On 20-3-2018 9:00, Maarten Jung wrote:
> >>
> >>        Dear list,
> >>        I came across a SPSS syntax like this
> >>
> >>        MIXED value BY factor1
> >>             /CRITERIA=CIN(95) MXITER(100) MXSTEP(10) SCORING(1)
> >>        SINGULAR(0.000000000001)
> >>             HCONVERGE(0, ABSOLUTE) LCONVERGE(0, ABSOLUTE)
> >>        PCONVERGE(0.000001,
> >>             ABSOLUTE)
> >>             /FIXED=factor1 | SSTYPE(3)
> >>             /METHOD=REML
> >>             /REPEATED=factor1 | SUBJECT(participant) COVTYPE(UN).
> >>
> >>        and struggle to find an equivalent lmer/nlme (or R in general)
> >>        formulation
> >>        for this kind of models.
> >>        Does anybody know how to convert the REPEATED subcommand into
> >>        R code?
> >>
> >>        Please note that I asked the question on Stack Overflow about
> >>        two month ago:
> >>
> https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
> <
> https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
> >
> >>        <
> https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
> <
> https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
> >>
> >>
> >>        Best regards,
> >>        Maarten
> >>
> >>                [[alternative HTML version deleted]]
> >>
> >>        _______________________________________________
> >>        R-sig-mixed-models at r-project.org <mailto:
> R-sig-mixed-models at r-project.org>
> >>        <mailto:R-sig-mixed-models at r-project.org <mailto:
> R-sig-mixed-models at r-project.org>> mailing list
> >>        https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models <
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >>        <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models <
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
> >>
> >>
> >>    _______________________________________________
> >>    R-sig-mixed-models at r-project.org <mailto:
> R-sig-mixed-models at r-project.org>
> >>    <mailto:R-sig-mixed-models at r-project.org <mailto:
> R-sig-mixed-models at r-project.org>> mailing list
> >>    https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models <
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >>    <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models <
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
> >>
> >>
> >
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org <mailto:
> R-sig-mixed-models at r-project.org> mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models <
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From rune.haubo at gmail.com  Wed Mar 21 10:40:02 2018
From: rune.haubo at gmail.com (Rune Haubo)
Date: Wed, 21 Mar 2018 10:40:02 +0100
Subject: [R-sig-ME] What is the lmer/nlme equivalent of the REPEATED
 subcommand in SPSS's MIXED procedure?
In-Reply-To: <CAO7JsnTCenXXrrrfJthUz5aLv2wiubdrzOw30mFY5AdUBmF=ig@mail.gmail.com>
References: <CAHr4Dyep9JCDpNauViVf0MyeH-=p7k0fx3yXbMCL_b-9tLTMEQ@mail.gmail.com>
 <d67d36fb-1019-d878-794e-491c3a409f2a@maw.ru.nl>
 <CAHr4Dydq-SW_8aKUF=MFqnFpx6P36RSguP7gTF-6epZjMFWo3A@mail.gmail.com>
 <5AB140DE.5090705@maw.ru.nl>
 <20732_1521566386_0P5W00D4NG4WVU20_9ECC9EC8-43DB-49AD-97E0-67E5E680460A@gmail.com>
 <CAO7JsnTCenXXrrrfJthUz5aLv2wiubdrzOw30mFY5AdUBmF=ig@mail.gmail.com>
Message-ID: <CAG_uk91QV6Xa8b+tuW50j10bh9rV-N1fbYEe4mi1rLNv6oH_5A@mail.gmail.com>

On 20 March 2018 at 18:34, Douglas Bates <bates at stat.wisc.edu> wrote:
> Kind of looks like SPSS went for bug-for-bug compatibility with SAS on this
> one.  In SAS PROC MIXED, "REPEATED" and "RANDOM" are two ways of specifying
> the random effects variance structure but they often boil down to the same
> model.
>
> I believe the model can be specified in lme4 as
>
>     value ~ factor1 + (factor1 | participant)
>
> This is what the mis-named* "UNSTRUCTURED" covariance type means
>
> * Old-guy, get off my lawn rant about terminology *
> As a recovering mathematician I find the name "unstructured" being used to
> denote a positive-definite symmetric matrix to be, well, inaccurate.
>

The UN option (for "unstructured") in the SAS random statement is kind
of tricky as it actually does not restrict the variance-covariance
matrix to be positive definite (or even postive semidefinite). I have
previously obtained such "fits" and it took a while to figure out why
R and SAS gave different answers. I am quoting here because it is at
least debatable in what sense a negative definite symmetric matrix is
actually a valid variance-covariance matrix... There is another option
that you can use (if I recall correctly it is the FA option for factor
analysis) if you are so "picky" that you actually also want the
variance-covariance matrix to be positive (semi)definite. Intuitive,
right ;-)

Cheers
Rune


From b.pelzer at maw.ru.nl  Wed Mar 21 12:03:07 2018
From: b.pelzer at maw.ru.nl (Ben Pelzer)
Date: Wed, 21 Mar 2018 12:03:07 +0100
Subject: [R-sig-ME] What is the lmer/nlme equivalent of the REPEATED
 subcommand in SPSS's MIXED procedure?
In-Reply-To: <CAO7JsnTCenXXrrrfJthUz5aLv2wiubdrzOw30mFY5AdUBmF=ig@mail.gmail.com>
References: <CAHr4Dyep9JCDpNauViVf0MyeH-=p7k0fx3yXbMCL_b-9tLTMEQ@mail.gmail.com>
 <d67d36fb-1019-d878-794e-491c3a409f2a@maw.ru.nl>
 <CAHr4Dydq-SW_8aKUF=MFqnFpx6P36RSguP7gTF-6epZjMFWo3A@mail.gmail.com>
 <5AB140DE.5090705@maw.ru.nl>
 <20732_1521566386_0P5W00D4NG4WVU20_9ECC9EC8-43DB-49AD-97E0-67E5E680460A@gmail.com>
 <CAO7JsnTCenXXrrrfJthUz5aLv2wiubdrzOw30mFY5AdUBmF=ig@mail.gmail.com>
Message-ID: <42ce404b-af99-82c6-a2f6-482b9963da3a@maw.ru.nl>

Dear all,

As far as I know, the specification for lmer using

 ??? value ~ factor1 + (factor1 | participant)

causes an identification problem, because the residual variance is not 
excluded from the estimations. It would indeed work (e.g. in MlWin this 
can be done) if we could constrain that residual variance to zero. There 
have been some mails in this list about whether or not constraining 
residual variance to zero is possible in lmer, but I believe this is not 
possible. Would be nice if we could do this in lmer!

Best regards, Ben.


On 20-3-2018 18:34, Douglas Bates wrote:
> Kind of looks like SPSS went for bug-for-bug compatibility with SAS on 
> this one.? In SAS PROC MIXED, "REPEATED" and "RANDOM" are two ways of 
> specifying the random effects variance structure but they often boil 
> down to the same model.
>
> I believe the model can be specified in lme4 as
>
> ??? value ~ factor1 + (factor1 | participant)
>
> This is what the mis-named* "UNSTRUCTURED" covariance type means
>
> * Old-guy, get off my lawn rant about terminology *
> As a recovering mathematician I find the name "unstructured" being 
> used to denote a positive-definite symmetric matrix to be, well, 
> inaccurate.
>
> On Tue, Mar 20, 2018 at 12:19 PM Mollie Brooks 
> <mollieebrooks at gmail.com <mailto:mollieebrooks at gmail.com>> wrote:
>
>     I don?t know anything about spss, but if you basically want lme4
>     with more correlation structures, you could look at the structures
>     available with glmmTMB.
>     https://cran.r-project.org/web/packages/glmmTMB/vignettes/covstruct.html
>
>     cheers,
>     Mollie
>
>     > On 20Mar 2018, at 18:11, Ben Pelzer <b.pelzer at maw.ru.nl
>     <mailto:b.pelzer at maw.ru.nl>> wrote:
>     >
>     > Hi Maarten,
>     >
>     > You are right: you need nlme and NOT lme4 to specify particular
>     > correlation structures. Also, in nlme you would need gls to make it
>     > similar to mixed in spss. The repeated command in spss gives the
>     same
>     > results as gls does for any of the covariance structures.
>     >
>     > Regards, Ben.
>     >
>     >
>     > On 20/03/2018 17:30, Maarten Jung wrote:
>     >> Dear Ben, dear Phillip,
>     >>
>     >> comparing [1] with [2] I think the /REPEATED command specifies
>     >> the error (co)variance structure of the model. Would you agree
>     with that?
>     >> If so, AFAIK this is not possible with lmer and thus the answer on
>     >> Stack Overflow [3] would be wrong.
>     >>
>     >> [1]
>     >>
>     https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/
>     >> [2]
>     >>
>     https://stats.idre.ucla.edu/spss/examples/alda/chapter7/applied-longitudinal-data-analysis-modeling-change-and-event-occurrenceby-judith-d-singer-and-john-b-willett-chapter-7-examining-the-multilevel-model-s-erro/
>     >> [3]
>     >>
>     https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
>     >>
>     >> Regards,
>     >> Maarten
>     >>
>     >> On Tue, Mar 20, 2018 at 2:10 PM, Ben Pelzer <b.pelzer at maw.ru.nl
>     <mailto:b.pelzer at maw.ru.nl>
>     >> <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>
>     <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>>>> wrote:
>     >>
>     >>? ? Dear Maarten,
>     >>
>     >>? ? Take a look at
>     >>
>     >>
>     https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/
>     <https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/>
>     >>? ?
>     <https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/
>     <https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/>>
>     >>
>     >>? ? which shows you a number of covariance structures, among
>     which is
>     >>? ? the unstructured matrix, for repeated measures in R with lme. It
>     >>? ? refers to chapter 7 of Singer and Willett where they discuss all
>     >>? ? these different structures and how to choose among them.
>     Regards,
>     >>
>     >>? ? Ben.
>     >>
>     >>? ? On 20-3-2018 9:00, Maarten Jung wrote:
>     >>
>     >>? ? ? ? Dear list,
>     >>? ? ? ? I came across a SPSS syntax like this
>     >>
>     >>? ? ? ? MIXED value BY factor1
>     >>? ? ? ? ? ? ?/CRITERIA=CIN(95) MXITER(100) MXSTEP(10) SCORING(1)
>     >>? ? ? ? SINGULAR(0.000000000001)
>     >>? ? ? ? ? ? ?HCONVERGE(0, ABSOLUTE) LCONVERGE(0, ABSOLUTE)
>     >>? ? ? ? PCONVERGE(0.000001,
>     >>? ? ? ? ? ? ?ABSOLUTE)
>     >>? ? ? ? ? ? ?/FIXED=factor1 | SSTYPE(3)
>     >>? ? ? ? ? ? ?/METHOD=REML
>     >>? ? ? ? ? ? ?/REPEATED=factor1 | SUBJECT(participant) COVTYPE(UN).
>     >>
>     >>? ? ? ? and struggle to find an equivalent lmer/nlme (or R in
>     general)
>     >>? ? ? ? formulation
>     >>? ? ? ? for this kind of models.
>     >>? ? ? ? Does anybody know how to convert the REPEATED subcommand
>     into
>     >>? ? ? ? R code?
>     >>
>     >>? ? ? ? Please note that I asked the question on Stack Overflow
>     about
>     >>? ? ? ? two month ago:
>     >>
>     https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
>     <https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc>
>     >>? ? ? ?
>     <https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
>     <https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc>>
>     >>
>     >>? ? ? ? Best regards,
>     >>? ? ? ? Maarten
>     >>
>     >>? ? ? ? ? ? ? ? [[alternative HTML version deleted]]
>     >>
>     >> _______________________________________________
>     >> R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>
>     >>? ? ? ? <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>> mailing list
>     >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>     >>? ? ? ?
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
>     >>
>     >>
>     >>? ? _______________________________________________
>     >> R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>
>     >>? ? <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>> mailing list
>     >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>     >>? ? <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
>     >>
>     >>
>     >
>     >
>     >? ? ? ?[[alternative HTML version deleted]]
>     >
>     > _______________________________________________
>     > R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>> mailing list
>     > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>
>     ? ? ? ? [[alternative HTML version deleted]]
>
>     _______________________________________________
>     R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


	[[alternative HTML version deleted]]


From Maarten.Jung at mailbox.tu-dresden.de  Wed Mar 21 13:07:31 2018
From: Maarten.Jung at mailbox.tu-dresden.de (Maarten Jung)
Date: Wed, 21 Mar 2018 13:07:31 +0100
Subject: [R-sig-ME] What is the lmer/nlme equivalent of the REPEATED
 subcommand in SPSS's MIXED procedure?
In-Reply-To: <42ce404b-af99-82c6-a2f6-482b9963da3a@maw.ru.nl>
References: <CAHr4Dyep9JCDpNauViVf0MyeH-=p7k0fx3yXbMCL_b-9tLTMEQ@mail.gmail.com>
 <d67d36fb-1019-d878-794e-491c3a409f2a@maw.ru.nl>
 <CAHr4Dydq-SW_8aKUF=MFqnFpx6P36RSguP7gTF-6epZjMFWo3A@mail.gmail.com>
 <5AB140DE.5090705@maw.ru.nl>
 <20732_1521566386_0P5W00D4NG4WVU20_9ECC9EC8-43DB-49AD-97E0-67E5E680460A@gmail.com>
 <CAO7JsnTCenXXrrrfJthUz5aLv2wiubdrzOw30mFY5AdUBmF=ig@mail.gmail.com>
 <42ce404b-af99-82c6-a2f6-482b9963da3a@maw.ru.nl>
Message-ID: <CAHr4DyeaLCL_RxsjNnYb=L2pxo4r4+mcmsDF382x88UPoVYPaA@mail.gmail.com>

Dear Ben,

I am a bit puzzled.

Do you mean that

m1 <- gls(value ~ factor1, data, correlation = corSymm(form = ~
1|participant), weights = varIdent(form = ~ 1|factor))

would be equivalent to

m2 <- lmer(value ~ factor1 + (factor1|participant), data)

and one should use gls() because it allows for the same covariance
structures as /REPEATED does?

And, if so, why should m2 cause an identification problem and m1 doesn't?

Regards,
Maarten


On Wed, Mar 21, 2018 at 12:03 PM, Ben Pelzer <b.pelzer at maw.ru.nl> wrote:

> Dear all,
>
> As far as I know, the specification for lmer using
>
>      value ~ factor1 + (factor1 | participant)
>
> causes an identification problem, because the residual variance is not
> excluded from the estimations. It would indeed work (e.g. in MlWin this
> can be done) if we could constrain that residual variance to zero. There
> have been some mails in this list about whether or not constraining
> residual variance to zero is possible in lmer, but I believe this is not
> possible. Would be nice if we could do this in lmer!
>
> Best regards, Ben.
>
>
> On 20-3-2018 18:34, Douglas Bates wrote:
> > Kind of looks like SPSS went for bug-for-bug compatibility with SAS on
> > this one.  In SAS PROC MIXED, "REPEATED" and "RANDOM" are two ways of
> > specifying the random effects variance structure but they often boil
> > down to the same model.
> >
> > I believe the model can be specified in lme4 as
> >
> >     value ~ factor1 + (factor1 | participant)
> >
> > This is what the mis-named* "UNSTRUCTURED" covariance type means
> >
> > * Old-guy, get off my lawn rant about terminology *
> > As a recovering mathematician I find the name "unstructured" being
> > used to denote a positive-definite symmetric matrix to be, well,
> > inaccurate.
> >
> > On Tue, Mar 20, 2018 at 12:19 PM Mollie Brooks
> > <mollieebrooks at gmail.com <mailto:mollieebrooks at gmail.com>> wrote:
> >
> >     I don?t know anything about spss, but if you basically want lme4
> >     with more correlation structures, you could look at the structures
> >     available with glmmTMB.
> >     https://cran.r-project.org/web/packages/glmmTMB/
> vignettes/covstruct.html
> >
> >     cheers,
> >     Mollie
> >
> >     > On 20Mar 2018, at 18:11, Ben Pelzer <b.pelzer at maw.ru.nl
> >     <mailto:b.pelzer at maw.ru.nl>> wrote:
> >     >
> >     > Hi Maarten,
> >     >
> >     > You are right: you need nlme and NOT lme4 to specify particular
> >     > correlation structures. Also, in nlme you would need gls to make it
> >     > similar to mixed in spss. The repeated command in spss gives the
> >     same
> >     > results as gls does for any of the covariance structures.
> >     >
> >     > Regards, Ben.
> >     >
> >     >
> >     > On 20/03/2018 17:30, Maarten Jung wrote:
> >     >> Dear Ben, dear Phillip,
> >     >>
> >     >> comparing [1] with [2] I think the /REPEATED command specifies
> >     >> the error (co)variance structure of the model. Would you agree
> >     with that?
> >     >> If so, AFAIK this is not possible with lmer and thus the answer on
> >     >> Stack Overflow [3] would be wrong.
> >     >>
> >     >> [1]
> >     >>
> >     https://stats.idre.ucla.edu/r/examples/alda/r-applied-
> longitudinal-data-analysis-ch-7/
> >     >> [2]
> >     >>
> >     https://stats.idre.ucla.edu/spss/examples/alda/chapter7/
> applied-longitudinal-data-analysis-modeling-change-and-
> event-occurrenceby-judith-d-singer-and-john-b-willett-
> chapter-7-examining-the-multilevel-model-s-erro/
> >     >> [3]
> >     >>
> >     https://stackoverflow.com/questions/48518514/what-is-
> the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
> >     >>
> >     >> Regards,
> >     >> Maarten
> >     >>
> >     >> On Tue, Mar 20, 2018 at 2:10 PM, Ben Pelzer <b.pelzer at maw.ru.nl
> >     <mailto:b.pelzer at maw.ru.nl>
> >     >> <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>
> >     <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>>>> wrote:
> >     >>
> >     >>    Dear Maarten,
> >     >>
> >     >>    Take a look at
> >     >>
> >     >>
> >     https://stats.idre.ucla.edu/r/examples/alda/r-applied-
> longitudinal-data-analysis-ch-7/
> >     <https://stats.idre.ucla.edu/r/examples/alda/r-applied-
> longitudinal-data-analysis-ch-7/>
> >     >>
> >     <https://stats.idre.ucla.edu/r/examples/alda/r-applied-
> longitudinal-data-analysis-ch-7/
> >     <https://stats.idre.ucla.edu/r/examples/alda/r-applied-
> longitudinal-data-analysis-ch-7/>>
> >     >>
> >     >>    which shows you a number of covariance structures, among
> >     which is
> >     >>    the unstructured matrix, for repeated measures in R with lme.
> It
> >     >>    refers to chapter 7 of Singer and Willett where they discuss
> all
> >     >>    these different structures and how to choose among them.
> >     Regards,
> >     >>
> >     >>    Ben.
> >     >>
> >     >>    On 20-3-2018 9:00, Maarten Jung wrote:
> >     >>
> >     >>        Dear list,
> >     >>        I came across a SPSS syntax like this
> >     >>
> >     >>        MIXED value BY factor1
> >     >>             /CRITERIA=CIN(95) MXITER(100) MXSTEP(10) SCORING(1)
> >     >>        SINGULAR(0.000000000001)
> >     >>             HCONVERGE(0, ABSOLUTE) LCONVERGE(0, ABSOLUTE)
> >     >>        PCONVERGE(0.000001,
> >     >>             ABSOLUTE)
> >     >>             /FIXED=factor1 | SSTYPE(3)
> >     >>             /METHOD=REML
> >     >>             /REPEATED=factor1 | SUBJECT(participant) COVTYPE(UN).
> >     >>
> >     >>        and struggle to find an equivalent lmer/nlme (or R in
> >     general)
> >     >>        formulation
> >     >>        for this kind of models.
> >     >>        Does anybody know how to convert the REPEATED subcommand
> >     into
> >     >>        R code?
> >     >>
> >     >>        Please note that I asked the question on Stack Overflow
> >     about
> >     >>        two month ago:
> >     >>
> >     https://stackoverflow.com/questions/48518514/what-is-
> the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
> >     <https://stackoverflow.com/questions/48518514/what-is-
> the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc>
> >     >>
> >     <https://stackoverflow.com/questions/48518514/what-is-
> the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
> >     <https://stackoverflow.com/questions/48518514/what-is-
> the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc>>
> >     >>
> >     >>        Best regards,
> >     >>        Maarten
> >     >>
> >     >>                [[alternative HTML version deleted]]
> >     >>
> >     >> _______________________________________________
> >     >> R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>
> >     >>        <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>> mailing list
> >     >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >     >>
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
> >     >>
> >     >>
> >     >>    _______________________________________________
> >     >> R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>
> >     >>    <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>> mailing list
> >     >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >     >>    <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
> >     >>
> >     >>
> >     >
> >     >
> >     >       [[alternative HTML version deleted]]
> >     >
> >     > _______________________________________________
> >     > R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>> mailing list
> >     > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >
> >             [[alternative HTML version deleted]]
> >
> >     _______________________________________________
> >     R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org> mailing list
> >     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From b.pelzer at maw.ru.nl  Wed Mar 21 21:27:56 2018
From: b.pelzer at maw.ru.nl (Ben Pelzer)
Date: Wed, 21 Mar 2018 21:27:56 +0100
Subject: [R-sig-ME] What is the lmer/nlme equivalent of the REPEATED
 subcommand in SPSS's MIXED procedure?
In-Reply-To: <CAHr4DyeaLCL_RxsjNnYb=L2pxo4r4+mcmsDF382x88UPoVYPaA@mail.gmail.com>
References: <CAHr4Dyep9JCDpNauViVf0MyeH-=p7k0fx3yXbMCL_b-9tLTMEQ@mail.gmail.com>
 <d67d36fb-1019-d878-794e-491c3a409f2a@maw.ru.nl>
 <CAHr4Dydq-SW_8aKUF=MFqnFpx6P36RSguP7gTF-6epZjMFWo3A@mail.gmail.com>
 <5AB140DE.5090705@maw.ru.nl>
 <20732_1521566386_0P5W00D4NG4WVU20_9ECC9EC8-43DB-49AD-97E0-67E5E680460A@gmail.com>
 <CAO7JsnTCenXXrrrfJthUz5aLv2wiubdrzOw30mFY5AdUBmF=ig@mail.gmail.com>
 <42ce404b-af99-82c6-a2f6-482b9963da3a@maw.ru.nl>
 <CAHr4DyeaLCL_RxsjNnYb=L2pxo4r4+mcmsDF382x88UPoVYPaA@mail.gmail.com>
Message-ID: <5AB2C04C.6010707@maw.ru.nl>

Hi Maarten,

Here is an example which shows the unstructured model with gls and the 
not converging model with lmer. In this example, we have three occasions 
on which the dependent variable "test" was observed, for each of 20 
persons. In total then we have 60 observations, with the "occasion" 
variable taking values 1, 2, 3. The data also contain the person id 
variable "person" and dummy variables "occ1", "occ2", "occ3" as (0 or 1) 
indicators of the occasion.  In the syntax below, a factor variable 
"factor1" is created also, to be in line with your question.

I used two different specifications for the unstructured model with gls, 
depending on whether dummies or factor1 was used. For lmer, I used these 
three different specifications, none of which converges.

The lmer syntax was added only to show the problem which lmer has with 
estimating an unstructured correlation pattern.


#------------------------------------------------------------------------------------------------------------------------------------------------------------
mydata <- 
read.table(url("https://surfdrive.surf.nl/files/index.php/s/XfE3mtbFCTUejIz/download"), 
header=TRUE)


#-------------------  unstructured correlation matrix 
-----------------------


# Before applying a model, let's first examine the variances and 
correlations
# for the three occasions. We have a strong violation of the assumptions
# of homoscedasticity and compound symmetry.
test1 <- mydata[mydata$occasion==1,"test"]
test2 <- mydata[mydata$occasion==2,"test"]
test3 <- mydata[mydata$occasion==3,"test"]
cor(cbind(test1, test2, test3))
var(cbind(test1, test2, test3))

# Unstructured model using gls from package nlme and dummies for occasion.
# This model exactly reproduces the observed correlations between occasions.
unstruc.gls1 <- gls(test ~ 1+ occ2 + occ3,
                            method="REML", data=mydata,
                            correlation=corSymm(form = ~ 1 |person),
                            weights = varIdent(form = ~1|occasion))
summary(unstruc.gls1)


# Unstructured model using factor1 for occasion instead of dummies.
# The results are exactly the same as those above, as should be.
mydata$factor1 <- as.factor(mydata$occasion)
unstruc.gls2 <- gls(test ~ factor1,
                     method="REML", data=mydata,
                     correlation=corSymm(form = ~ 1|person),
                     weights = varIdent(form = ~1|factor1))
summary(unstruc.gls2)


# Unstructured model using lmer and dummies for occasion: does not 
converge.
unstruc.lmer <- lmer(test ~ 1+ occ2 + occ3 + (1+occ2+occ3|person),
                      data=mydata, REML=TRUE)
summary(unstruc.lmer)


# Unstructured model using lmer and factor1 for occasion: does not 
converge.
unstruc.lmer <- lmer(test ~ 1+ factor1 + (1+factor1|person),
                      data=mydata, REML=TRUE)
summary(unstruc.lmer)


# Unstructured model using lmer and factor1 for occasion, no intercept 
specified: does not converge.
unstruc.lmer <- lmer(test ~ factor1 + (factor1|person),
                      data=mydata, REML=TRUE)
summary(unstruc.lmer)



On 21/03/2018 13:07, Maarten Jung wrote:
> Dear Ben,
>
> I am a bit puzzled.
>
> Do you mean that
>
> m1 <- gls(value ~ factor1, data, correlation = corSymm(form = ~ 
> 1|participant), weights = varIdent(form = ~ 1|factor))
>
> would be equivalent to
>
> m2 <- lmer(value ~ factor1 + (factor1|participant), data)
>
> and one should use gls() because it allows for the same covariance 
> structures as /REPEATED does?
>


the two specifications are not equivalent in the sense that lmer also 
tries to estimate residual variance. However, with the given lmer model 
specification, the random factor1 effects capture all variance there is 
and no residual variance remains.


> And, if so, why should m2 cause an identification problem and m1 doesn't?
>
> Regards,
> Maarten
>
Regards, Ben.



>
> On Wed, Mar 21, 2018 at 12:03 PM, Ben Pelzer <b.pelzer at maw.ru.nl 
> <mailto:b.pelzer at maw.ru.nl>> wrote:
>
>     Dear all,
>
>     As far as I know, the specification for lmer using
>
>          value ~ factor1 + (factor1 | participant)
>
>     causes an identification problem, because the residual variance is not
>     excluded from the estimations. It would indeed work (e.g. in MlWin
>     this
>     can be done) if we could constrain that residual variance to zero.
>     There
>     have been some mails in this list about whether or not constraining
>     residual variance to zero is possible in lmer, but I believe this
>     is not
>     possible. Would be nice if we could do this in lmer!
>
>     Best regards, Ben.
>
>
>     On 20-3-2018 18:34, Douglas Bates wrote:
>     > Kind of looks like SPSS went for bug-for-bug compatibility with
>     SAS on
>     > this one.  In SAS PROC MIXED, "REPEATED" and "RANDOM" are two
>     ways of
>     > specifying the random effects variance structure but they often boil
>     > down to the same model.
>     >
>     > I believe the model can be specified in lme4 as
>     >
>     >     value ~ factor1 + (factor1 | participant)
>     >
>     > This is what the mis-named* "UNSTRUCTURED" covariance type means
>     >
>     > * Old-guy, get off my lawn rant about terminology *
>     > As a recovering mathematician I find the name "unstructured" being
>     > used to denote a positive-definite symmetric matrix to be, well,
>     > inaccurate.
>     >
>     > On Tue, Mar 20, 2018 at 12:19 PM Mollie Brooks
>     > <mollieebrooks at gmail.com <mailto:mollieebrooks at gmail.com>
>     <mailto:mollieebrooks at gmail.com <mailto:mollieebrooks at gmail.com>>>
>     wrote:
>     >
>     >     I don?t know anything about spss, but if you basically want lme4
>     >     with more correlation structures, you could look at the
>     structures
>     >     available with glmmTMB.
>     >
>     https://cran.r-project.org/web/packages/glmmTMB/vignettes/covstruct.html
>     <https://cran.r-project.org/web/packages/glmmTMB/vignettes/covstruct.html>
>     >
>     >     cheers,
>     >     Mollie
>     >
>     >     > On 20Mar 2018, at 18:11, Ben Pelzer <b.pelzer at maw.ru.nl
>     <mailto:b.pelzer at maw.ru.nl>
>     >     <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>>> wrote:
>     >     >
>     >     > Hi Maarten,
>     >     >
>     >     > You are right: you need nlme and NOT lme4 to specify
>     particular
>     >     > correlation structures. Also, in nlme you would need gls
>     to make it
>     >     > similar to mixed in spss. The repeated command in spss
>     gives the
>     >     same
>     >     > results as gls does for any of the covariance structures.
>     >     >
>     >     > Regards, Ben.
>     >     >
>     >     >
>     >     > On 20/03/2018 17:30, Maarten Jung wrote:
>     >     >> Dear Ben, dear Phillip,
>     >     >>
>     >     >> comparing [1] with [2] I think the /REPEATED command
>     specifies
>     >     >> the error (co)variance structure of the model. Would you
>     agree
>     >     with that?
>     >     >> If so, AFAIK this is not possible with lmer and thus the
>     answer on
>     >     >> Stack Overflow [3] would be wrong.
>     >     >>
>     >     >> [1]
>     >     >>
>     >
>     https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/
>     <https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/>
>     >     >> [2]
>     >     >>
>     >
>     https://stats.idre.ucla.edu/spss/examples/alda/chapter7/applied-longitudinal-data-analysis-modeling-change-and-event-occurrenceby-judith-d-singer-and-john-b-willett-chapter-7-examining-the-multilevel-model-s-erro/
>     <https://stats.idre.ucla.edu/spss/examples/alda/chapter7/applied-longitudinal-data-analysis-modeling-change-and-event-occurrenceby-judith-d-singer-and-john-b-willett-chapter-7-examining-the-multilevel-model-s-erro/>
>     >     >> [3]
>     >     >>
>     >
>     https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
>     <https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc>
>     >     >>
>     >     >> Regards,
>     >     >> Maarten
>     >     >>
>     >     >> On Tue, Mar 20, 2018 at 2:10 PM, Ben Pelzer
>     <b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>
>     >     <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>>
>     >     >> <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>
>     <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>>
>     >     <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>
>     <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>>>>> wrote:
>     >     >>
>     >     >>    Dear Maarten,
>     >     >>
>     >     >>    Take a look at
>     >     >>
>     >     >>
>     >
>     https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/
>     <https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/>
>     >   
>      <https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/
>     <https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/>>
>     >     >>
>     >   
>      <https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/
>     <https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/>
>     >   
>      <https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/
>     <https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/>>>
>     >     >>
>     >     >>    which shows you a number of covariance structures, among
>     >     which is
>     >     >>    the unstructured matrix, for repeated measures in R
>     with lme. It
>     >     >>    refers to chapter 7 of Singer and Willett where they
>     discuss all
>     >     >>    these different structures and how to choose among them.
>     >     Regards,
>     >     >>
>     >     >>    Ben.
>     >     >>
>     >     >>    On 20-3-2018 9:00, Maarten Jung wrote:
>     >     >>
>     >     >>        Dear list,
>     >     >>        I came across a SPSS syntax like this
>     >     >>
>     >     >>        MIXED value BY factor1
>     >     >>             /CRITERIA=CIN(95) MXITER(100) MXSTEP(10)
>     SCORING(1)
>     >     >>        SINGULAR(0.000000000001)
>     >     >>             HCONVERGE(0, ABSOLUTE) LCONVERGE(0, ABSOLUTE)
>     >     >>        PCONVERGE(0.000001,
>     >     >>             ABSOLUTE)
>     >     >>             /FIXED=factor1 | SSTYPE(3)
>     >     >>             /METHOD=REML
>     >     >>             /REPEATED=factor1 | SUBJECT(participant)
>     COVTYPE(UN).
>     >     >>
>     >     >>        and struggle to find an equivalent lmer/nlme (or R in
>     >     general)
>     >     >>        formulation
>     >     >>        for this kind of models.
>     >     >>        Does anybody know how to convert the REPEATED
>     subcommand
>     >     into
>     >     >>        R code?
>     >     >>
>     >     >>        Please note that I asked the question on Stack
>     Overflow
>     >     about
>     >     >>        two month ago:
>     >     >>
>     >
>     https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
>     <https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc>
>     >   
>      <https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
>     <https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc>>
>     >     >>
>     >   
>      <https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
>     <https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc>
>     >   
>      <https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
>     <https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc>>>
>     >     >>
>     >     >>        Best regards,
>     >     >>        Maarten
>     >     >>
>     >     >>                [[alternative HTML version deleted]]
>     >     >>
>     >     >> _______________________________________________
>     >     >> R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>
>     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>>
>     >     >>        <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>
>     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>>> mailing list
>     >     >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
>     >     >>
>     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>
>     >     >>
>     >     >>
>     >     >>    _______________________________________________
>     >     >> R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>
>     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>>
>     >     >>    <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>
>     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>>> mailing list
>     >     >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
>     >     >>   
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>
>     >     >>
>     >     >>
>     >     >
>     >     >
>     >     >       [[alternative HTML version deleted]]
>     >     >
>     >     > _______________________________________________
>     >     > R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>
>     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>> mailing list
>     >     > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
>     >
>     >             [[alternative HTML version deleted]]
>     >
>     >     _______________________________________________
>     > R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>> mailing list
>     > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>     >
>
>
>             [[alternative HTML version deleted]]
>
>     _______________________________________________
>     R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>
>


	[[alternative HTML version deleted]]


From Maarten.Jung at mailbox.tu-dresden.de  Thu Mar 22 10:05:34 2018
From: Maarten.Jung at mailbox.tu-dresden.de (Maarten Jung)
Date: Thu, 22 Mar 2018 10:05:34 +0100
Subject: [R-sig-ME] What is the lmer/nlme equivalent of the REPEATED
 subcommand in SPSS's MIXED procedure?
In-Reply-To: <5AB2C04C.6010707@maw.ru.nl>
References: <CAHr4Dyep9JCDpNauViVf0MyeH-=p7k0fx3yXbMCL_b-9tLTMEQ@mail.gmail.com>
 <d67d36fb-1019-d878-794e-491c3a409f2a@maw.ru.nl>
 <CAHr4Dydq-SW_8aKUF=MFqnFpx6P36RSguP7gTF-6epZjMFWo3A@mail.gmail.com>
 <5AB140DE.5090705@maw.ru.nl>
 <20732_1521566386_0P5W00D4NG4WVU20_9ECC9EC8-43DB-49AD-97E0-67E5E680460A@gmail.com>
 <CAO7JsnTCenXXrrrfJthUz5aLv2wiubdrzOw30mFY5AdUBmF=ig@mail.gmail.com>
 <42ce404b-af99-82c6-a2f6-482b9963da3a@maw.ru.nl>
 <CAHr4DyeaLCL_RxsjNnYb=L2pxo4r4+mcmsDF382x88UPoVYPaA@mail.gmail.com>
 <5AB2C04C.6010707@maw.ru.nl>
Message-ID: <CAHr4Dyfhcuh7cNqDCR8ghdHfu1mwhzW9MWMChnOTTsTD_nmo+A@mail.gmail.com>

I think the problem is that there is only one observation per
subject-occasion-combination in this example.
In this case the random slopes are confounded with the residual variation
(see [1]).

One *can* fit this model using lmer(test ~ 1 + occ2 + occ3 + (1 + occ2 +
occ3|person), data = mydata,  control = lmerControl(check.nobs.vs.nRE =
"ignore")) or
lme(test ~ 1 + occ2 + occ3, mydata, random = ~ occ2 + occ3|person).

However, I don't know if the gls() fit ist more trustworthy than the
lmer/lme fit here.
I would be grateful if somebody more experienced in mixed models could
comment on this.

Best regards,
Maarten

[1]
https://stackoverflow.com/questions/26465215/random-slope-for-time-in-subject-not-working-in-lme4?utm_medium=organic&utm_source=google_rich_qa&utm_campaign=google_rich_qa

On Wed, Mar 21, 2018 at 9:27 PM, Ben Pelzer <b.pelzer at maw.ru.nl> wrote:

> Hi Maarten,
>
> Here is an example which shows the unstructured model with gls and the
> not converging model with lmer. In this example, we have three occasions
> on which the dependent variable "test" was observed, for each of 20
> persons. In total then we have 60 observations, with the "occasion"
> variable taking values 1, 2, 3. The data also contain the person id
> variable "person" and dummy variables "occ1", "occ2", "occ3" as (0 or 1)
> indicators of the occasion.  In the syntax below, a factor variable
> "factor1" is created also, to be in line with your question.
>
> I used two different specifications for the unstructured model with gls,
> depending on whether dummies or factor1 was used. For lmer, I used these
> three different specifications, none of which converges.
>
> The lmer syntax was added only to show the problem which lmer has with
> estimating an unstructured correlation pattern.
>
>
> #-----------------------------------------------------------
> ------------------------------------------------------------
> -------------------------------------
> mydata <-
> read.table(url("https://surfdrive.surf.nl/files/index.
> php/s/XfE3mtbFCTUejIz/download"),
> header=TRUE)
>
>
> #-------------------  unstructured correlation matrix
> -----------------------
>
>
> # Before applying a model, let's first examine the variances and
> correlations
> # for the three occasions. We have a strong violation of the assumptions
> # of homoscedasticity and compound symmetry.
> test1 <- mydata[mydata$occasion==1,"test"]
> test2 <- mydata[mydata$occasion==2,"test"]
> test3 <- mydata[mydata$occasion==3,"test"]
> cor(cbind(test1, test2, test3))
> var(cbind(test1, test2, test3))
>
> # Unstructured model using gls from package nlme and dummies for occasion.
> # This model exactly reproduces the observed correlations between
> occasions.
> unstruc.gls1 <- gls(test ~ 1+ occ2 + occ3,
>                             method="REML", data=mydata,
>                             correlation=corSymm(form = ~ 1 |person),
>                             weights = varIdent(form = ~1|occasion))
> summary(unstruc.gls1)
>
>
> # Unstructured model using factor1 for occasion instead of dummies.
> # The results are exactly the same as those above, as should be.
> mydata$factor1 <- as.factor(mydata$occasion)
> unstruc.gls2 <- gls(test ~ factor1,
>                      method="REML", data=mydata,
>                      correlation=corSymm(form = ~ 1|person),
>                      weights = varIdent(form = ~1|factor1))
> summary(unstruc.gls2)
>
>
> # Unstructured model using lmer and dummies for occasion: does not
> converge.
> unstruc.lmer <- lmer(test ~ 1+ occ2 + occ3 + (1+occ2+occ3|person),
>                       data=mydata, REML=TRUE)
> summary(unstruc.lmer)
>
>
> # Unstructured model using lmer and factor1 for occasion: does not
> converge.
> unstruc.lmer <- lmer(test ~ 1+ factor1 + (1+factor1|person),
>                       data=mydata, REML=TRUE)
> summary(unstruc.lmer)
>
>
> # Unstructured model using lmer and factor1 for occasion, no intercept
> specified: does not converge.
> unstruc.lmer <- lmer(test ~ factor1 + (factor1|person),
>                       data=mydata, REML=TRUE)
> summary(unstruc.lmer)
>
>
>
> On 21/03/2018 13:07, Maarten Jung wrote:
> > Dear Ben,
> >
> > I am a bit puzzled.
> >
> > Do you mean that
> >
> > m1 <- gls(value ~ factor1, data, correlation = corSymm(form = ~
> > 1|participant), weights = varIdent(form = ~ 1|factor))
> >
> > would be equivalent to
> >
> > m2 <- lmer(value ~ factor1 + (factor1|participant), data)
> >
> > and one should use gls() because it allows for the same covariance
> > structures as /REPEATED does?
> >
>
>
> the two specifications are not equivalent in the sense that lmer also
> tries to estimate residual variance. However, with the given lmer model
> specification, the random factor1 effects capture all variance there is
> and no residual variance remains.
>
>
> > And, if so, why should m2 cause an identification problem and m1 doesn't?
> >
> > Regards,
> > Maarten
> >
> Regards, Ben.
>
>
>
> >
> > On Wed, Mar 21, 2018 at 12:03 PM, Ben Pelzer <b.pelzer at maw.ru.nl
> > <mailto:b.pelzer at maw.ru.nl>> wrote:
> >
> >     Dear all,
> >
> >     As far as I know, the specification for lmer using
> >
> >          value ~ factor1 + (factor1 | participant)
> >
> >     causes an identification problem, because the residual variance is
> not
> >     excluded from the estimations. It would indeed work (e.g. in MlWin
> >     this
> >     can be done) if we could constrain that residual variance to zero.
> >     There
> >     have been some mails in this list about whether or not constraining
> >     residual variance to zero is possible in lmer, but I believe this
> >     is not
> >     possible. Would be nice if we could do this in lmer!
> >
> >     Best regards, Ben.
> >
> >
> >     On 20-3-2018 18:34, Douglas Bates wrote:
> >     > Kind of looks like SPSS went for bug-for-bug compatibility with
> >     SAS on
> >     > this one.  In SAS PROC MIXED, "REPEATED" and "RANDOM" are two
> >     ways of
> >     > specifying the random effects variance structure but they often
> boil
> >     > down to the same model.
> >     >
> >     > I believe the model can be specified in lme4 as
> >     >
> >     >     value ~ factor1 + (factor1 | participant)
> >     >
> >     > This is what the mis-named* "UNSTRUCTURED" covariance type means
> >     >
> >     > * Old-guy, get off my lawn rant about terminology *
> >     > As a recovering mathematician I find the name "unstructured" being
> >     > used to denote a positive-definite symmetric matrix to be, well,
> >     > inaccurate.
> >     >
> >     > On Tue, Mar 20, 2018 at 12:19 PM Mollie Brooks
> >     > <mollieebrooks at gmail.com <mailto:mollieebrooks at gmail.com>
> >     <mailto:mollieebrooks at gmail.com <mailto:mollieebrooks at gmail.com>>>
> >     wrote:
> >     >
> >     >     I don?t know anything about spss, but if you basically want
> lme4
> >     >     with more correlation structures, you could look at the
> >     structures
> >     >     available with glmmTMB.
> >     >
> >     https://cran.r-project.org/web/packages/glmmTMB/
> vignettes/covstruct.html
> >     <https://cran.r-project.org/web/packages/glmmTMB/
> vignettes/covstruct.html>
> >     >
> >     >     cheers,
> >     >     Mollie
> >     >
> >     >     > On 20Mar 2018, at 18:11, Ben Pelzer <b.pelzer at maw.ru.nl
> >     <mailto:b.pelzer at maw.ru.nl>
> >     >     <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>>>
> wrote:
> >     >     >
> >     >     > Hi Maarten,
> >     >     >
> >     >     > You are right: you need nlme and NOT lme4 to specify
> >     particular
> >     >     > correlation structures. Also, in nlme you would need gls
> >     to make it
> >     >     > similar to mixed in spss. The repeated command in spss
> >     gives the
> >     >     same
> >     >     > results as gls does for any of the covariance structures.
> >     >     >
> >     >     > Regards, Ben.
> >     >     >
> >     >     >
> >     >     > On 20/03/2018 17:30, Maarten Jung wrote:
> >     >     >> Dear Ben, dear Phillip,
> >     >     >>
> >     >     >> comparing [1] with [2] I think the /REPEATED command
> >     specifies
> >     >     >> the error (co)variance structure of the model. Would you
> >     agree
> >     >     with that?
> >     >     >> If so, AFAIK this is not possible with lmer and thus the
> >     answer on
> >     >     >> Stack Overflow [3] would be wrong.
> >     >     >>
> >     >     >> [1]
> >     >     >>
> >     >
> >     https://stats.idre.ucla.edu/r/examples/alda/r-applied-
> longitudinal-data-analysis-ch-7/
> >     <https://stats.idre.ucla.edu/r/examples/alda/r-applied-
> longitudinal-data-analysis-ch-7/>
> >     >     >> [2]
> >     >     >>
> >     >
> >     https://stats.idre.ucla.edu/spss/examples/alda/chapter7/
> applied-longitudinal-data-analysis-modeling-change-and-
> event-occurrenceby-judith-d-singer-and-john-b-willett-
> chapter-7-examining-the-multilevel-model-s-erro/
> >     <https://stats.idre.ucla.edu/spss/examples/alda/chapter7/
> applied-longitudinal-data-analysis-modeling-change-and-
> event-occurrenceby-judith-d-singer-and-john-b-willett-
> chapter-7-examining-the-multilevel-model-s-erro/>
> >     >     >> [3]
> >     >     >>
> >     >
> >     https://stackoverflow.com/questions/48518514/what-is-
> the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
> >     <https://stackoverflow.com/questions/48518514/what-is-
> the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc>
> >     >     >>
> >     >     >> Regards,
> >     >     >> Maarten
> >     >     >>
> >     >     >> On Tue, Mar 20, 2018 at 2:10 PM, Ben Pelzer
> >     <b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>
> >     >     <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>>
> >     >     >> <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>
> >     <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>>
> >     >     <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>
> >     <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>>>>> wrote:
> >     >     >>
> >     >     >>    Dear Maarten,
> >     >     >>
> >     >     >>    Take a look at
> >     >     >>
> >     >     >>
> >     >
> >     https://stats.idre.ucla.edu/r/examples/alda/r-applied-
> longitudinal-data-analysis-ch-7/
> >     <https://stats.idre.ucla.edu/r/examples/alda/r-applied-
> longitudinal-data-analysis-ch-7/>
> >     >
> >      <https://stats.idre.ucla.edu/r/examples/alda/r-applied-
> longitudinal-data-analysis-ch-7/
> >     <https://stats.idre.ucla.edu/r/examples/alda/r-applied-
> longitudinal-data-analysis-ch-7/>>
> >     >     >>
> >     >
> >      <https://stats.idre.ucla.edu/r/examples/alda/r-applied-
> longitudinal-data-analysis-ch-7/
> >     <https://stats.idre.ucla.edu/r/examples/alda/r-applied-
> longitudinal-data-analysis-ch-7/>
> >     >
> >      <https://stats.idre.ucla.edu/r/examples/alda/r-applied-
> longitudinal-data-analysis-ch-7/
> >     <https://stats.idre.ucla.edu/r/examples/alda/r-applied-
> longitudinal-data-analysis-ch-7/>>>
> >     >     >>
> >     >     >>    which shows you a number of covariance structures, among
> >     >     which is
> >     >     >>    the unstructured matrix, for repeated measures in R
> >     with lme. It
> >     >     >>    refers to chapter 7 of Singer and Willett where they
> >     discuss all
> >     >     >>    these different structures and how to choose among them.
> >     >     Regards,
> >     >     >>
> >     >     >>    Ben.
> >     >     >>
> >     >     >>    On 20-3-2018 9:00, Maarten Jung wrote:
> >     >     >>
> >     >     >>        Dear list,
> >     >     >>        I came across a SPSS syntax like this
> >     >     >>
> >     >     >>        MIXED value BY factor1
> >     >     >>             /CRITERIA=CIN(95) MXITER(100) MXSTEP(10)
> >     SCORING(1)
> >     >     >>        SINGULAR(0.000000000001)
> >     >     >>             HCONVERGE(0, ABSOLUTE) LCONVERGE(0, ABSOLUTE)
> >     >     >>        PCONVERGE(0.000001,
> >     >     >>             ABSOLUTE)
> >     >     >>             /FIXED=factor1 | SSTYPE(3)
> >     >     >>             /METHOD=REML
> >     >     >>             /REPEATED=factor1 | SUBJECT(participant)
> >     COVTYPE(UN).
> >     >     >>
> >     >     >>        and struggle to find an equivalent lmer/nlme (or R in
> >     >     general)
> >     >     >>        formulation
> >     >     >>        for this kind of models.
> >     >     >>        Does anybody know how to convert the REPEATED
> >     subcommand
> >     >     into
> >     >     >>        R code?
> >     >     >>
> >     >     >>        Please note that I asked the question on Stack
> >     Overflow
> >     >     about
> >     >     >>        two month ago:
> >     >     >>
> >     >
> >     https://stackoverflow.com/questions/48518514/what-is-
> the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
> >     <https://stackoverflow.com/questions/48518514/what-is-
> the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc>
> >     >
> >      <https://stackoverflow.com/questions/48518514/what-is-
> the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
> >     <https://stackoverflow.com/questions/48518514/what-is-
> the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc>>
> >     >     >>
> >     >
> >      <https://stackoverflow.com/questions/48518514/what-is-
> the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
> >     <https://stackoverflow.com/questions/48518514/what-is-
> the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc>
> >     >
> >      <https://stackoverflow.com/questions/48518514/what-is-
> the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
> >     <https://stackoverflow.com/questions/48518514/what-is-
> the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc>>>
> >     >     >>
> >     >     >>        Best regards,
> >     >     >>        Maarten
> >     >     >>
> >     >     >>                [[alternative HTML version deleted]]
> >     >     >>
> >     >     >> _______________________________________________
> >     >     >> R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >     >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>
> >     >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >     >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>>
> >     >     >>        <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >     >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>
> >     >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >     >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>>> mailing list
> >     >     >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
> >     >     >>
> >     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>
> >     >     >>
> >     >     >>
> >     >     >>    _______________________________________________
> >     >     >> R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >     >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>
> >     >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >     >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>>
> >     >     >>    <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >     >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>
> >     >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >     >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>>> mailing list
> >     >     >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
> >     >     >>
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>
> >     >     >>
> >     >     >>
> >     >     >
> >     >     >
> >     >     >       [[alternative HTML version deleted]]
> >     >     >
> >     >     > _______________________________________________
> >     >     > R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >     >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>
> >     >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >     >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>> mailing list
> >     >     > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
> >     >
> >     >             [[alternative HTML version deleted]]
> >     >
> >     >     _______________________________________________
> >     > R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >     >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>> mailing list
> >     > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >     >
> >
> >
> >             [[alternative HTML version deleted]]
> >
> >     _______________________________________________
> >     R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org> mailing list
> >     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >
> >
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From b.pelzer at maw.ru.nl  Thu Mar 22 10:43:42 2018
From: b.pelzer at maw.ru.nl (Ben Pelzer)
Date: Thu, 22 Mar 2018 10:43:42 +0100
Subject: [R-sig-ME] What is the lmer/nlme equivalent of the REPEATED
 subcommand in SPSS's MIXED procedure?
In-Reply-To: <CAHr4Dyfhcuh7cNqDCR8ghdHfu1mwhzW9MWMChnOTTsTD_nmo+A@mail.gmail.com>
References: <CAHr4Dyep9JCDpNauViVf0MyeH-=p7k0fx3yXbMCL_b-9tLTMEQ@mail.gmail.com>
 <d67d36fb-1019-d878-794e-491c3a409f2a@maw.ru.nl>
 <CAHr4Dydq-SW_8aKUF=MFqnFpx6P36RSguP7gTF-6epZjMFWo3A@mail.gmail.com>
 <5AB140DE.5090705@maw.ru.nl>
 <20732_1521566386_0P5W00D4NG4WVU20_9ECC9EC8-43DB-49AD-97E0-67E5E680460A@gmail.com>
 <CAO7JsnTCenXXrrrfJthUz5aLv2wiubdrzOw30mFY5AdUBmF=ig@mail.gmail.com>
 <42ce404b-af99-82c6-a2f6-482b9963da3a@maw.ru.nl>
 <CAHr4DyeaLCL_RxsjNnYb=L2pxo4r4+mcmsDF382x88UPoVYPaA@mail.gmail.com>
 <5AB2C04C.6010707@maw.ru.nl>
 <CAHr4Dyfhcuh7cNqDCR8ghdHfu1mwhzW9MWMChnOTTsTD_nmo+A@mail.gmail.com>
Message-ID: <5AB37ACE.90002@maw.ru.nl>

Hi Maarten,

Notice that with the syntax for lmer, 6 random-effect (co)variances must 
be estimated and 1 residual variance, so in total 7 
(co)variance-parameters. However, there are only 6 observed covariances, 
meaning that the model is over-specified. Many solutions are possible 
all having the same loglikelihood. Ignoring the nobs.vs.nRE rule leads 
to just one of the many solutions. I would not be surprised if you would 
find another solution after manipulating the starting values for the 
covariances or other criteria for convergence. Best regards,

Ben.


On 22/03/2018 10:05, Maarten Jung wrote:
> I think the problem is that there is only one observation per 
> subject-occasion-combination in this example.
> In this case the random slopes are confounded with the residual 
> variation (see [1]).
>
> One *can* fit this model using lmer(test ~ 1 + occ2 + occ3 + (1 + occ2 
> + occ3|person), data = mydata,  control = 
> lmerControl(check.nobs.vs.nRE = "ignore")) or
> lme(test ~ 1 + occ2 + occ3, mydata, random = ~ occ2 + occ3|person).
>
> However, I don't know if the gls() fit ist more trustworthy than the 
> lmer/lme fit here.
> I would be grateful if somebody more experienced in mixed models could 
> comment on this.
>
> Best regards,
> Maarten
>
> [1] 
> https://stackoverflow.com/questions/26465215/random-slope-for-time-in-subject-not-working-in-lme4?utm_medium=organic&utm_source=google_rich_qa&utm_campaign=google_rich_qa
>
> On Wed, Mar 21, 2018 at 9:27 PM, Ben Pelzer <b.pelzer at maw.ru.nl 
> <mailto:b.pelzer at maw.ru.nl>> wrote:
>
>     Hi Maarten,
>
>     Here is an example which shows the unstructured model with gls and the
>     not converging model with lmer. In this example, we have three
>     occasions
>     on which the dependent variable "test" was observed, for each of 20
>     persons. In total then we have 60 observations, with the "occasion"
>     variable taking values 1, 2, 3. The data also contain the person id
>     variable "person" and dummy variables "occ1", "occ2", "occ3" as (0
>     or 1)
>     indicators of the occasion.  In the syntax below, a factor variable
>     "factor1" is created also, to be in line with your question.
>
>     I used two different specifications for the unstructured model
>     with gls,
>     depending on whether dummies or factor1 was used. For lmer, I used
>     these
>     three different specifications, none of which converges.
>
>     The lmer syntax was added only to show the problem which lmer has with
>     estimating an unstructured correlation pattern.
>
>
>     #------------------------------------------------------------------------------------------------------------------------------------------------------------
>     mydata <-
>     read.table(url("https://surfdrive.surf.nl/files/index.php/s/XfE3mtbFCTUejIz/download
>     <https://surfdrive.surf.nl/files/index.php/s/XfE3mtbFCTUejIz/download>"),
>     header=TRUE)
>
>
>     #-------------------  unstructured correlation matrix
>     -----------------------
>
>
>     # Before applying a model, let's first examine the variances and
>     correlations
>     # for the three occasions. We have a strong violation of the
>     assumptions
>     # of homoscedasticity and compound symmetry.
>     test1 <- mydata[mydata$occasion==1,"test"]
>     test2 <- mydata[mydata$occasion==2,"test"]
>     test3 <- mydata[mydata$occasion==3,"test"]
>     cor(cbind(test1, test2, test3))
>     var(cbind(test1, test2, test3))
>
>     # Unstructured model using gls from package nlme and dummies for
>     occasion.
>     # This model exactly reproduces the observed correlations between
>     occasions.
>     unstruc.gls1 <- gls(test ~ 1+ occ2 + occ3,
>                                 method="REML", data=mydata,
>                                 correlation=corSymm(form = ~ 1 |person),
>                                 weights = varIdent(form = ~1|occasion))
>     summary(unstruc.gls1)
>
>
>     # Unstructured model using factor1 for occasion instead of dummies.
>     # The results are exactly the same as those above, as should be.
>     mydata$factor1 <- as.factor(mydata$occasion)
>     unstruc.gls2 <- gls(test ~ factor1,
>                          method="REML", data=mydata,
>                          correlation=corSymm(form = ~ 1|person),
>                          weights = varIdent(form = ~1|factor1))
>     summary(unstruc.gls2)
>
>
>     # Unstructured model using lmer and dummies for occasion: does not
>     converge.
>     unstruc.lmer <- lmer(test ~ 1+ occ2 + occ3 + (1+occ2+occ3|person),
>                           data=mydata, REML=TRUE)
>     summary(unstruc.lmer)
>
>
>     # Unstructured model using lmer and factor1 for occasion: does not
>     converge.
>     unstruc.lmer <- lmer(test ~ 1+ factor1 + (1+factor1|person),
>                           data=mydata, REML=TRUE)
>     summary(unstruc.lmer)
>
>
>     # Unstructured model using lmer and factor1 for occasion, no intercept
>     specified: does not converge.
>     unstruc.lmer <- lmer(test ~ factor1 + (factor1|person),
>                           data=mydata, REML=TRUE)
>     summary(unstruc.lmer)
>
>
>
>     On 21/03/2018 13:07, Maarten Jung wrote:
>     > Dear Ben,
>     >
>     > I am a bit puzzled.
>     >
>     > Do you mean that
>     >
>     > m1 <- gls(value ~ factor1, data, correlation = corSymm(form = ~
>     > 1|participant), weights = varIdent(form = ~ 1|factor))
>     >
>     > would be equivalent to
>     >
>     > m2 <- lmer(value ~ factor1 + (factor1|participant), data)
>     >
>     > and one should use gls() because it allows for the same covariance
>     > structures as /REPEATED does?
>     >
>
>
>     the two specifications are not equivalent in the sense that lmer also
>     tries to estimate residual variance. However, with the given lmer
>     model
>     specification, the random factor1 effects capture all variance
>     there is
>     and no residual variance remains.
>
>
>     > And, if so, why should m2 cause an identification problem and m1
>     doesn't?
>     >
>     > Regards,
>     > Maarten
>     >
>     Regards, Ben.
>
>
>
>     >
>     > On Wed, Mar 21, 2018 at 12:03 PM, Ben Pelzer <b.pelzer at maw.ru.nl
>     <mailto:b.pelzer at maw.ru.nl>
>     > <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>>> wrote:
>     >
>     >     Dear all,
>     >
>     >     As far as I know, the specification for lmer using
>     >
>     >          value ~ factor1 + (factor1 | participant)
>     >
>     >     causes an identification problem, because the residual
>     variance is not
>     >     excluded from the estimations. It would indeed work (e.g. in
>     MlWin
>     >     this
>     >     can be done) if we could constrain that residual variance to
>     zero.
>     >     There
>     >     have been some mails in this list about whether or not
>     constraining
>     >     residual variance to zero is possible in lmer, but I believe
>     this
>     >     is not
>     >     possible. Would be nice if we could do this in lmer!
>     >
>     >     Best regards, Ben.
>     >
>     >
>     >     On 20-3-2018 18:34, Douglas Bates wrote:
>     >     > Kind of looks like SPSS went for bug-for-bug compatibility
>     with
>     >     SAS on
>     >     > this one.  In SAS PROC MIXED, "REPEATED" and "RANDOM" are two
>     >     ways of
>     >     > specifying the random effects variance structure but they
>     often boil
>     >     > down to the same model.
>     >     >
>     >     > I believe the model can be specified in lme4 as
>     >     >
>     >     >     value ~ factor1 + (factor1 | participant)
>     >     >
>     >     > This is what the mis-named* "UNSTRUCTURED" covariance type
>     means
>     >     >
>     >     > * Old-guy, get off my lawn rant about terminology *
>     >     > As a recovering mathematician I find the name
>     "unstructured" being
>     >     > used to denote a positive-definite symmetric matrix to be,
>     well,
>     >     > inaccurate.
>     >     >
>     >     > On Tue, Mar 20, 2018 at 12:19 PM Mollie Brooks
>     >     > <mollieebrooks at gmail.com <mailto:mollieebrooks at gmail.com>
>     <mailto:mollieebrooks at gmail.com <mailto:mollieebrooks at gmail.com>>
>     >     <mailto:mollieebrooks at gmail.com
>     <mailto:mollieebrooks at gmail.com> <mailto:mollieebrooks at gmail.com
>     <mailto:mollieebrooks at gmail.com>>>>
>     >     wrote:
>     >     >
>     >     >     I don?t know anything about spss, but if you basically
>     want lme4
>     >     >     with more correlation structures, you could look at the
>     >     structures
>     >     >     available with glmmTMB.
>     >     >
>     >
>     https://cran.r-project.org/web/packages/glmmTMB/vignettes/covstruct.html
>     <https://cran.r-project.org/web/packages/glmmTMB/vignettes/covstruct.html>
>     >   
>      <https://cran.r-project.org/web/packages/glmmTMB/vignettes/covstruct.html
>     <https://cran.r-project.org/web/packages/glmmTMB/vignettes/covstruct.html>>
>     >     >
>     >     >     cheers,
>     >     >     Mollie
>     >     >
>     >     >     > On 20Mar 2018, at 18:11, Ben Pelzer
>     <b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>
>     >     <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>>
>     >     >     <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>
>     <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>>>> wrote:
>     >     >     >
>     >     >     > Hi Maarten,
>     >     >     >
>     >     >     > You are right: you need nlme and NOT lme4 to specify
>     >     particular
>     >     >     > correlation structures. Also, in nlme you would need gls
>     >     to make it
>     >     >     > similar to mixed in spss. The repeated command in spss
>     >     gives the
>     >     >     same
>     >     >     > results as gls does for any of the covariance
>     structures.
>     >     >     >
>     >     >     > Regards, Ben.
>     >     >     >
>     >     >     >
>     >     >     > On 20/03/2018 17:30, Maarten Jung wrote:
>     >     >     >> Dear Ben, dear Phillip,
>     >     >     >>
>     >     >     >> comparing [1] with [2] I think the /REPEATED command
>     >     specifies
>     >     >     >> the error (co)variance structure of the model.
>     Would you
>     >     agree
>     >     >     with that?
>     >     >     >> If so, AFAIK this is not possible with lmer and
>     thus the
>     >     answer on
>     >     >     >> Stack Overflow [3] would be wrong.
>     >     >     >>
>     >     >     >> [1]
>     >     >     >>
>     >     >
>     >
>     https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/
>     <https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/>
>     >   
>      <https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/
>     <https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/>>
>     >     >     >> [2]
>     >     >     >>
>     >     >
>     >
>     https://stats.idre.ucla.edu/spss/examples/alda/chapter7/applied-longitudinal-data-analysis-modeling-change-and-event-occurrenceby-judith-d-singer-and-john-b-willett-chapter-7-examining-the-multilevel-model-s-erro/
>     <https://stats.idre.ucla.edu/spss/examples/alda/chapter7/applied-longitudinal-data-analysis-modeling-change-and-event-occurrenceby-judith-d-singer-and-john-b-willett-chapter-7-examining-the-multilevel-model-s-erro/>
>     >   
>      <https://stats.idre.ucla.edu/spss/examples/alda/chapter7/applied-longitudinal-data-analysis-modeling-change-and-event-occurrenceby-judith-d-singer-and-john-b-willett-chapter-7-examining-the-multilevel-model-s-erro/
>     <https://stats.idre.ucla.edu/spss/examples/alda/chapter7/applied-longitudinal-data-analysis-modeling-change-and-event-occurrenceby-judith-d-singer-and-john-b-willett-chapter-7-examining-the-multilevel-model-s-erro/>>
>     >     >     >> [3]
>     >     >     >>
>     >     >
>     >
>     https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
>     <https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc>
>     >   
>      <https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
>     <https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc>>
>     >     >     >>
>     >     >     >> Regards,
>     >     >     >> Maarten
>     >     >     >>
>     >     >     >> On Tue, Mar 20, 2018 at 2:10 PM, Ben Pelzer
>     >     <b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>
>     <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>>
>     >     >     <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>
>     <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>>>
>     >     >     >> <mailto:b.pelzer at maw.ru.nl
>     <mailto:b.pelzer at maw.ru.nl> <mailto:b.pelzer at maw.ru.nl
>     <mailto:b.pelzer at maw.ru.nl>>
>     >     <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>
>     <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>>>
>     >     >     <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>
>     <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>>
>     >     <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>
>     <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>>>>>> wrote:
>     >     >     >>
>     >     >     >>    Dear Maarten,
>     >     >     >>
>     >     >     >>    Take a look at
>     >     >     >>
>     >     >     >>
>     >     >
>     >
>     https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/
>     <https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/>
>     >   
>      <https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/
>     <https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/>>
>     >     >
>     >     
>     <https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/
>     <https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/>
>     >   
>      <https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/
>     <https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/>>>
>     >     >     >>
>     >     >
>     >     
>     <https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/
>     <https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/>
>     >   
>      <https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/
>     <https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/>>
>     >     >
>     >     
>     <https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/
>     <https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/>
>     >   
>      <https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/
>     <https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/>>>>
>     >     >     >>
>     >     >     >>    which shows you a number of covariance
>     structures, among
>     >     >     which is
>     >     >     >>    the unstructured matrix, for repeated measures in R
>     >     with lme. It
>     >     >     >>    refers to chapter 7 of Singer and Willett where they
>     >     discuss all
>     >     >     >>    these different structures and how to choose
>     among them.
>     >     >     Regards,
>     >     >     >>
>     >     >     >>    Ben.
>     >     >     >>
>     >     >     >>    On 20-3-2018 9:00, Maarten Jung wrote:
>     >     >     >>
>     >     >     >>        Dear list,
>     >     >     >>        I came across a SPSS syntax like this
>     >     >     >>
>     >     >     >>        MIXED value BY factor1
>     >     >     >>  /CRITERIA=CIN(95) MXITER(100) MXSTEP(10)
>     >     SCORING(1)
>     >     >     >> SINGULAR(0.000000000001)
>     >     >     >>             HCONVERGE(0, ABSOLUTE) LCONVERGE(0,
>     ABSOLUTE)
>     >     >     >>        PCONVERGE(0.000001,
>     >     >     >>             ABSOLUTE)
>     >     >     >>             /FIXED=factor1 | SSTYPE(3)
>     >     >     >>             /METHOD=REML
>     >     >     >>  /REPEATED=factor1 | SUBJECT(participant)
>     >     COVTYPE(UN).
>     >     >     >>
>     >     >     >>        and struggle to find an equivalent lmer/nlme
>     (or R in
>     >     >     general)
>     >     >     >>        formulation
>     >     >     >>        for this kind of models.
>     >     >     >>        Does anybody know how to convert the REPEATED
>     >     subcommand
>     >     >     into
>     >     >     >>        R code?
>     >     >     >>
>     >     >     >>        Please note that I asked the question on Stack
>     >     Overflow
>     >     >     about
>     >     >     >>        two month ago:
>     >     >     >>
>     >     >
>     >
>     https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
>     <https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc>
>     >   
>      <https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
>     <https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc>>
>     >     >
>     >     
>     <https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
>     <https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc>
>     >   
>      <https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
>     <https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc>>>
>     >     >     >>
>     >     >
>     >     
>     <https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
>     <https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc>
>     >   
>      <https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
>     <https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc>>
>     >     >
>     >     
>     <https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
>     <https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc>
>     >   
>      <https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
>     <https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc>>>>
>     >     >     >>
>     >     >     >>        Best regards,
>     >     >     >>        Maarten
>     >     >     >>
>     >     >     >> [[alternative HTML version deleted]]
>     >     >     >>
>     >     >     >> _______________________________________________
>     >     >     >> R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>
>     >     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>>
>     >     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>
>     >     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>>>
>     >     >     >>        <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>
>     >     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>>
>     >     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>
>     >     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>>>> mailing list
>     >     >     >>
>     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
>     >     >   
>      <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>
>     >     >     >>
>     >     >   
>      <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
>     >     >   
>      <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>>
>     >     >     >>
>     >     >     >>
>     >     >     >> _______________________________________________
>     >     >     >> R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>
>     >     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>>
>     >     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>
>     >     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>>>
>     >     >     >>    <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>
>     >     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>>
>     >     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>
>     >     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>>>> mailing list
>     >     >     >>
>     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
>     >     >   
>      <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>
>     >     >     >>
>     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
>     >     >   
>      <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>>
>     >     >     >>
>     >     >     >>
>     >     >     >
>     >     >     >
>     >     >     >       [[alternative HTML version deleted]]
>     >     >     >
>     >     >     > _______________________________________________
>     >     >     > R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>
>     >     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>>
>     >     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>
>     >     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>>> mailing list
>     >     >     >
>     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
>     >     >   
>      <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>
>     >     >
>     >     >             [[alternative HTML version deleted]]
>     >     >
>     >     >     _______________________________________________
>     >     > R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>
>     >     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>> mailing list
>     >     > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
>     >     >
>     >
>     >
>     >             [[alternative HTML version deleted]]
>     >
>     >     _______________________________________________
>     > R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>> mailing list
>     > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
>     >
>     >
>
>
>             [[alternative HTML version deleted]]
>
>     _______________________________________________
>     R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>
>


	[[alternative HTML version deleted]]


From Maarten.Jung at mailbox.tu-dresden.de  Thu Mar 22 11:03:37 2018
From: Maarten.Jung at mailbox.tu-dresden.de (Maarten Jung)
Date: Thu, 22 Mar 2018 10:03:37 +0000
Subject: [R-sig-ME] What is the lmer/nlme equivalent of the REPEATED
 subcommand in SPSS's MIXED procedure?
In-Reply-To: <5AB37ACE.90002@maw.ru.nl>
References: <CAHr4Dyep9JCDpNauViVf0MyeH-=p7k0fx3yXbMCL_b-9tLTMEQ@mail.gmail.com>
 <d67d36fb-1019-d878-794e-491c3a409f2a@maw.ru.nl>
 <CAHr4Dydq-SW_8aKUF=MFqnFpx6P36RSguP7gTF-6epZjMFWo3A@mail.gmail.com>
 <5AB140DE.5090705@maw.ru.nl>
 <20732_1521566386_0P5W00D4NG4WVU20_9ECC9EC8-43DB-49AD-97E0-67E5E680460A@gmail.com>
 <CAO7JsnTCenXXrrrfJthUz5aLv2wiubdrzOw30mFY5AdUBmF=ig@mail.gmail.com>
 <42ce404b-af99-82c6-a2f6-482b9963da3a@maw.ru.nl>
 <CAHr4DyeaLCL_RxsjNnYb=L2pxo4r4+mcmsDF382x88UPoVYPaA@mail.gmail.com>
 <5AB2C04C.6010707@maw.ru.nl>
 <CAHr4Dyfhcuh7cNqDCR8ghdHfu1mwhzW9MWMChnOTTsTD_nmo+A@mail.gmail.com>
 <5AB37ACE.90002@maw.ru.nl>
Message-ID: <CAHr4DyfSeCvhkFmcRTYW-eejLgmUHAj4PCD2L6D+NM+zpp42KQ@mail.gmail.com>

Hi Ben,

I'm aware of this problem for lmer.
But how does gls() overcome the problem?

Regards,
Maarten

On Thu, Mar 22, 2018, 10:44 Ben Pelzer <b.pelzer at maw.ru.nl> wrote:

> Hi Maarten,
>
> Notice that with the syntax for lmer, 6 random-effect (co)variances must
> be estimated and 1 residual variance, so in total 7
> (co)variance-parameters. However, there are only 6 observed covariances,
> meaning that the model is over-specified. Many solutions are possible
> all having the same loglikelihood. Ignoring the nobs.vs.nRE rule leads
> to just one of the many solutions. I would not be surprised if you would
> find another solution after manipulating the starting values for the
> covariances or other criteria for convergence. Best regards,
>
> Ben.
>
>
> On 22/03/2018 10:05, Maarten Jung wrote:
> > I think the problem is that there is only one observation per
> > subject-occasion-combination in this example.
> > In this case the random slopes are confounded with the residual
> > variation (see [1]).
> >
> > One *can* fit this model using lmer(test ~ 1 + occ2 + occ3 + (1 + occ2
> > + occ3|person), data = mydata,  control =
> > lmerControl(check.nobs.vs.nRE = "ignore")) or
> > lme(test ~ 1 + occ2 + occ3, mydata, random = ~ occ2 + occ3|person).
> >
> > However, I don't know if the gls() fit ist more trustworthy than the
> > lmer/lme fit here.
> > I would be grateful if somebody more experienced in mixed models could
> > comment on this.
> >
> > Best regards,
> > Maarten
> >
> > [1]
> >
> https://stackoverflow.com/questions/26465215/random-slope-for-time-in-subject-not-working-in-lme4?utm_medium=organic&utm_source=google_rich_qa&utm_campaign=google_rich_qa
> >
> > On Wed, Mar 21, 2018 at 9:27 PM, Ben Pelzer <b.pelzer at maw.ru.nl
> > <mailto:b.pelzer at maw.ru.nl>> wrote:
> >
> >     Hi Maarten,
> >
> >     Here is an example which shows the unstructured model with gls and
> the
> >     not converging model with lmer. In this example, we have three
> >     occasions
> >     on which the dependent variable "test" was observed, for each of 20
> >     persons. In total then we have 60 observations, with the "occasion"
> >     variable taking values 1, 2, 3. The data also contain the person id
> >     variable "person" and dummy variables "occ1", "occ2", "occ3" as (0
> >     or 1)
> >     indicators of the occasion.  In the syntax below, a factor variable
> >     "factor1" is created also, to be in line with your question.
> >
> >     I used two different specifications for the unstructured model
> >     with gls,
> >     depending on whether dummies or factor1 was used. For lmer, I used
> >     these
> >     three different specifications, none of which converges.
> >
> >     The lmer syntax was added only to show the problem which lmer has
> with
> >     estimating an unstructured correlation pattern.
> >
> >
> >
>  #------------------------------------------------------------------------------------------------------------------------------------------------------------
> >     mydata <-
> >     read.table(url("
> https://surfdrive.surf.nl/files/index.php/s/XfE3mtbFCTUejIz/download
> >     <
> https://surfdrive.surf.nl/files/index.php/s/XfE3mtbFCTUejIz/download>"),
> >     header=TRUE)
> >
> >
> >     #-------------------  unstructured correlation matrix
> >     -----------------------
> >
> >
> >     # Before applying a model, let's first examine the variances and
> >     correlations
> >     # for the three occasions. We have a strong violation of the
> >     assumptions
> >     # of homoscedasticity and compound symmetry.
> >     test1 <- mydata[mydata$occasion==1,"test"]
> >     test2 <- mydata[mydata$occasion==2,"test"]
> >     test3 <- mydata[mydata$occasion==3,"test"]
> >     cor(cbind(test1, test2, test3))
> >     var(cbind(test1, test2, test3))
> >
> >     # Unstructured model using gls from package nlme and dummies for
> >     occasion.
> >     # This model exactly reproduces the observed correlations between
> >     occasions.
> >     unstruc.gls1 <- gls(test ~ 1+ occ2 + occ3,
> >                                 method="REML", data=mydata,
> >                                 correlation=corSymm(form = ~ 1 |person),
> >                                 weights = varIdent(form = ~1|occasion))
> >     summary(unstruc.gls1)
> >
> >
> >     # Unstructured model using factor1 for occasion instead of dummies.
> >     # The results are exactly the same as those above, as should be.
> >     mydata$factor1 <- as.factor(mydata$occasion)
> >     unstruc.gls2 <- gls(test ~ factor1,
> >                          method="REML", data=mydata,
> >                          correlation=corSymm(form = ~ 1|person),
> >                          weights = varIdent(form = ~1|factor1))
> >     summary(unstruc.gls2)
> >
> >
> >     # Unstructured model using lmer and dummies for occasion: does not
> >     converge.
> >     unstruc.lmer <- lmer(test ~ 1+ occ2 + occ3 + (1+occ2+occ3|person),
> >                           data=mydata, REML=TRUE)
> >     summary(unstruc.lmer)
> >
> >
> >     # Unstructured model using lmer and factor1 for occasion: does not
> >     converge.
> >     unstruc.lmer <- lmer(test ~ 1+ factor1 + (1+factor1|person),
> >                           data=mydata, REML=TRUE)
> >     summary(unstruc.lmer)
> >
> >
> >     # Unstructured model using lmer and factor1 for occasion, no
> intercept
> >     specified: does not converge.
> >     unstruc.lmer <- lmer(test ~ factor1 + (factor1|person),
> >                           data=mydata, REML=TRUE)
> >     summary(unstruc.lmer)
> >
> >
> >
> >     On 21/03/2018 13:07, Maarten Jung wrote:
> >     > Dear Ben,
> >     >
> >     > I am a bit puzzled.
> >     >
> >     > Do you mean that
> >     >
> >     > m1 <- gls(value ~ factor1, data, correlation = corSymm(form = ~
> >     > 1|participant), weights = varIdent(form = ~ 1|factor))
> >     >
> >     > would be equivalent to
> >     >
> >     > m2 <- lmer(value ~ factor1 + (factor1|participant), data)
> >     >
> >     > and one should use gls() because it allows for the same covariance
> >     > structures as /REPEATED does?
> >     >
> >
> >
> >     the two specifications are not equivalent in the sense that lmer also
> >     tries to estimate residual variance. However, with the given lmer
> >     model
> >     specification, the random factor1 effects capture all variance
> >     there is
> >     and no residual variance remains.
> >
> >
> >     > And, if so, why should m2 cause an identification problem and m1
> >     doesn't?
> >     >
> >     > Regards,
> >     > Maarten
> >     >
> >     Regards, Ben.
> >
> >
> >
> >     >
> >     > On Wed, Mar 21, 2018 at 12:03 PM, Ben Pelzer <b.pelzer at maw.ru.nl
> >     <mailto:b.pelzer at maw.ru.nl>
> >     > <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>>> wrote:
> >     >
> >     >     Dear all,
> >     >
> >     >     As far as I know, the specification for lmer using
> >     >
> >     >          value ~ factor1 + (factor1 | participant)
> >     >
> >     >     causes an identification problem, because the residual
> >     variance is not
> >     >     excluded from the estimations. It would indeed work (e.g. in
> >     MlWin
> >     >     this
> >     >     can be done) if we could constrain that residual variance to
> >     zero.
> >     >     There
> >     >     have been some mails in this list about whether or not
> >     constraining
> >     >     residual variance to zero is possible in lmer, but I believe
> >     this
> >     >     is not
> >     >     possible. Would be nice if we could do this in lmer!
> >     >
> >     >     Best regards, Ben.
> >     >
> >     >
> >     >     On 20-3-2018 18:34, Douglas Bates wrote:
> >     >     > Kind of looks like SPSS went for bug-for-bug compatibility
> >     with
> >     >     SAS on
> >     >     > this one.  In SAS PROC MIXED, "REPEATED" and "RANDOM" are two
> >     >     ways of
> >     >     > specifying the random effects variance structure but they
> >     often boil
> >     >     > down to the same model.
> >     >     >
> >     >     > I believe the model can be specified in lme4 as
> >     >     >
> >     >     >     value ~ factor1 + (factor1 | participant)
> >     >     >
> >     >     > This is what the mis-named* "UNSTRUCTURED" covariance type
> >     means
> >     >     >
> >     >     > * Old-guy, get off my lawn rant about terminology *
> >     >     > As a recovering mathematician I find the name
> >     "unstructured" being
> >     >     > used to denote a positive-definite symmetric matrix to be,
> >     well,
> >     >     > inaccurate.
> >     >     >
> >     >     > On Tue, Mar 20, 2018 at 12:19 PM Mollie Brooks
> >     >     > <mollieebrooks at gmail.com <mailto:mollieebrooks at gmail.com>
> >     <mailto:mollieebrooks at gmail.com <mailto:mollieebrooks at gmail.com>>
> >     >     <mailto:mollieebrooks at gmail.com
> >     <mailto:mollieebrooks at gmail.com> <mailto:mollieebrooks at gmail.com
> >     <mailto:mollieebrooks at gmail.com>>>>
> >     >     wrote:
> >     >     >
> >     >     >     I don?t know anything about spss, but if you basically
> >     want lme4
> >     >     >     with more correlation structures, you could look at the
> >     >     structures
> >     >     >     available with glmmTMB.
> >     >     >
> >     >
> >
> https://cran.r-project.org/web/packages/glmmTMB/vignettes/covstruct.html
> >     <
> https://cran.r-project.org/web/packages/glmmTMB/vignettes/covstruct.html>
> >     >
> >      <
> https://cran.r-project.org/web/packages/glmmTMB/vignettes/covstruct.html
> >     <
> https://cran.r-project.org/web/packages/glmmTMB/vignettes/covstruct.html>>
> >     >     >
> >     >     >     cheers,
> >     >     >     Mollie
> >     >     >
> >     >     >     > On 20Mar 2018, at 18:11, Ben Pelzer
> >     <b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>
> >     >     <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>>
> >     >     >     <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>
> >     <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>>>> wrote:
> >     >     >     >
> >     >     >     > Hi Maarten,
> >     >     >     >
> >     >     >     > You are right: you need nlme and NOT lme4 to specify
> >     >     particular
> >     >     >     > correlation structures. Also, in nlme you would need
> gls
> >     >     to make it
> >     >     >     > similar to mixed in spss. The repeated command in spss
> >     >     gives the
> >     >     >     same
> >     >     >     > results as gls does for any of the covariance
> >     structures.
> >     >     >     >
> >     >     >     > Regards, Ben.
> >     >     >     >
> >     >     >     >
> >     >     >     > On 20/03/2018 17:30, Maarten Jung wrote:
> >     >     >     >> Dear Ben, dear Phillip,
> >     >     >     >>
> >     >     >     >> comparing [1] with [2] I think the /REPEATED command
> >     >     specifies
> >     >     >     >> the error (co)variance structure of the model.
> >     Would you
> >     >     agree
> >     >     >     with that?
> >     >     >     >> If so, AFAIK this is not possible with lmer and
> >     thus the
> >     >     answer on
> >     >     >     >> Stack Overflow [3] would be wrong.
> >     >     >     >>
> >     >     >     >> [1]
> >     >     >     >>
> >     >     >
> >     >
> >
> https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/
> >     <
> https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/
> >
> >     >
> >      <
> https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/
> >     <
> https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/
> >>
> >     >     >     >> [2]
> >     >     >     >>
> >     >     >
> >     >
> >
> https://stats.idre.ucla.edu/spss/examples/alda/chapter7/applied-longitudinal-data-analysis-modeling-change-and-event-occurrenceby-judith-d-singer-and-john-b-willett-chapter-7-examining-the-multilevel-model-s-erro/
> >     <
> https://stats.idre.ucla.edu/spss/examples/alda/chapter7/applied-longitudinal-data-analysis-modeling-change-and-event-occurrenceby-judith-d-singer-and-john-b-willett-chapter-7-examining-the-multilevel-model-s-erro/
> >
> >     >
> >      <
> https://stats.idre.ucla.edu/spss/examples/alda/chapter7/applied-longitudinal-data-analysis-modeling-change-and-event-occurrenceby-judith-d-singer-and-john-b-willett-chapter-7-examining-the-multilevel-model-s-erro/
> >     <
> https://stats.idre.ucla.edu/spss/examples/alda/chapter7/applied-longitudinal-data-analysis-modeling-change-and-event-occurrenceby-judith-d-singer-and-john-b-willett-chapter-7-examining-the-multilevel-model-s-erro/
> >>
> >     >     >     >> [3]
> >     >     >     >>
> >     >     >
> >     >
> >
> https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
> >     <
> https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
> >
> >     >
> >      <
> https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
> >     <
> https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
> >>
> >     >     >     >>
> >     >     >     >> Regards,
> >     >     >     >> Maarten
> >     >     >     >>
> >     >     >     >> On Tue, Mar 20, 2018 at 2:10 PM, Ben Pelzer
> >     >     <b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>
> >     <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>>
> >     >     >     <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>
> >     <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>>>
> >     >     >     >> <mailto:b.pelzer at maw.ru.nl
> >     <mailto:b.pelzer at maw.ru.nl> <mailto:b.pelzer at maw.ru.nl
> >     <mailto:b.pelzer at maw.ru.nl>>
> >     >     <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>
> >     <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>>>
> >     >     >     <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>
> >     <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>>
> >     >     <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>
> >     <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>>>>>> wrote:
> >     >     >     >>
> >     >     >     >>    Dear Maarten,
> >     >     >     >>
> >     >     >     >>    Take a look at
> >     >     >     >>
> >     >     >     >>
> >     >     >
> >     >
> >
> https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/
> >     <
> https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/
> >
> >     >
> >      <
> https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/
> >     <
> https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/
> >>
> >     >     >
> >     >
> >     <
> https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/
> >     <
> https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/
> >
> >     >
> >      <
> https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/
> >     <
> https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/
> >>>
> >     >     >     >>
> >     >     >
> >     >
> >     <
> https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/
> >     <
> https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/
> >
> >     >
> >      <
> https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/
> >     <
> https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/
> >>
> >     >     >
> >     >
> >     <
> https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/
> >     <
> https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/
> >
> >     >
> >      <
> https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/
> >     <
> https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/
> >>>>
> >     >     >     >>
> >     >     >     >>    which shows you a number of covariance
> >     structures, among
> >     >     >     which is
> >     >     >     >>    the unstructured matrix, for repeated measures in R
> >     >     with lme. It
> >     >     >     >>    refers to chapter 7 of Singer and Willett where
> they
> >     >     discuss all
> >     >     >     >>    these different structures and how to choose
> >     among them.
> >     >     >     Regards,
> >     >     >     >>
> >     >     >     >>    Ben.
> >     >     >     >>
> >     >     >     >>    On 20-3-2018 9:00, Maarten Jung wrote:
> >     >     >     >>
> >     >     >     >>        Dear list,
> >     >     >     >>        I came across a SPSS syntax like this
> >     >     >     >>
> >     >     >     >>        MIXED value BY factor1
> >     >     >     >>  /CRITERIA=CIN(95) MXITER(100) MXSTEP(10)
> >     >     SCORING(1)
> >     >     >     >> SINGULAR(0.000000000001)
> >     >     >     >>             HCONVERGE(0, ABSOLUTE) LCONVERGE(0,
> >     ABSOLUTE)
> >     >     >     >>        PCONVERGE(0.000001,
> >     >     >     >>             ABSOLUTE)
> >     >     >     >>             /FIXED=factor1 | SSTYPE(3)
> >     >     >     >>             /METHOD=REML
> >     >     >     >>  /REPEATED=factor1 | SUBJECT(participant)
> >     >     COVTYPE(UN).
> >     >     >     >>
> >     >     >     >>        and struggle to find an equivalent lmer/nlme
> >     (or R in
> >     >     >     general)
> >     >     >     >>        formulation
> >     >     >     >>        for this kind of models.
> >     >     >     >>        Does anybody know how to convert the REPEATED
> >     >     subcommand
> >     >     >     into
> >     >     >     >>        R code?
> >     >     >     >>
> >     >     >     >>        Please note that I asked the question on Stack
> >     >     Overflow
> >     >     >     about
> >     >     >     >>        two month ago:
> >     >     >     >>
> >     >     >
> >     >
> >
> https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
> >     <
> https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
> >
> >     >
> >      <
> https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
> >     <
> https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
> >>
> >     >     >
> >     >
> >     <
> https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
> >     <
> https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
> >
> >     >
> >      <
> https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
> >     <
> https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
> >>>
> >     >     >     >>
> >     >     >
> >     >
> >     <
> https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
> >     <
> https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
> >
> >     >
> >      <
> https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
> >     <
> https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
> >>
> >     >     >
> >     >
> >     <
> https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
> >     <
> https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
> >
> >     >
> >      <
> https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
> >     <
> https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
> >>>>
> >     >     >     >>
> >     >     >     >>        Best regards,
> >     >     >     >>        Maarten
> >     >     >     >>
> >     >     >     >> [[alternative HTML version deleted]]
> >     >     >     >>
> >     >     >     >> _______________________________________________
> >     >     >     >> R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >     >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>
> >     >     >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >     >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>>
> >     >     >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >     >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>
> >     >     >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >     >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>>>
> >     >     >     >>        <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >     >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>
> >     >     >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >     >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>>
> >     >     >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >     >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>
> >     >     >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >     >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>>>> mailing list
> >     >     >     >>
> >     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
> >     >     >
> >      <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>
> >     >     >     >>
> >     >     >
> >      <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
> >     >     >
> >      <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>>
> >     >     >     >>
> >     >     >     >>
> >     >     >     >> _______________________________________________
> >     >     >     >> R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >     >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>
> >     >     >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >     >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>>
> >     >     >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >     >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>
> >     >     >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >     >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>>>
> >     >     >     >>    <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >     >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>
> >     >     >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >     >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>>
> >     >     >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >     >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>
> >     >     >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >     >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>>>> mailing list
> >     >     >     >>
> >     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
> >     >     >
> >      <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>
> >     >     >     >>
> >     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
> >     >     >
> >      <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>>
> >     >     >     >>
> >     >     >     >>
> >     >     >     >
> >     >     >     >
> >     >     >     >       [[alternative HTML version deleted]]
> >     >     >     >
> >     >     >     > _______________________________________________
> >     >     >     > R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >     >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>
> >     >     >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >     >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>>
> >     >     >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >     >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>
> >     >     >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >     >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>>> mailing list
> >     >     >     >
> >     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
> >     >     >
> >      <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>
> >     >     >
> >     >     >             [[alternative HTML version deleted]]
> >     >     >
> >     >     >     _______________________________________________
> >     >     > R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >     >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>
> >     >     >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >     >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>>> mailing list
> >     >     > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
> >     >     >
> >     >
> >     >
> >     >             [[alternative HTML version deleted]]
> >     >
> >     >     _______________________________________________
> >     > R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >     >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>> mailing list
> >     > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
> >     >
> >     >
> >
> >
> >             [[alternative HTML version deleted]]
> >
> >     _______________________________________________
> >     R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org> mailing list
> >     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >
> >
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From phillip.alday at mpi.nl  Thu Mar 22 11:35:56 2018
From: phillip.alday at mpi.nl (Phillip Alday)
Date: Thu, 22 Mar 2018 11:35:56 +0100
Subject: [R-sig-ME] What is the lmer/nlme equivalent of the REPEATED
 subcommand in SPSS's MIXED procedure?
In-Reply-To: <CAHr4DyfSeCvhkFmcRTYW-eejLgmUHAj4PCD2L6D+NM+zpp42KQ@mail.gmail.com>
References: <CAHr4Dyep9JCDpNauViVf0MyeH-=p7k0fx3yXbMCL_b-9tLTMEQ@mail.gmail.com>
 <d67d36fb-1019-d878-794e-491c3a409f2a@maw.ru.nl>
 <CAHr4Dydq-SW_8aKUF=MFqnFpx6P36RSguP7gTF-6epZjMFWo3A@mail.gmail.com>
 <5AB140DE.5090705@maw.ru.nl>
 <20732_1521566386_0P5W00D4NG4WVU20_9ECC9EC8-43DB-49AD-97E0-67E5E680460A@gmail.com>
 <CAO7JsnTCenXXrrrfJthUz5aLv2wiubdrzOw30mFY5AdUBmF=ig@mail.gmail.com>
 <42ce404b-af99-82c6-a2f6-482b9963da3a@maw.ru.nl>
 <CAHr4DyeaLCL_RxsjNnYb=L2pxo4r4+mcmsDF382x88UPoVYPaA@mail.gmail.com>
 <5AB2C04C.6010707@maw.ru.nl>
 <CAHr4Dyfhcuh7cNqDCR8ghdHfu1mwhzW9MWMChnOTTsTD_nmo+A@mail.gmail.com>
 <5AB37ACE.90002@maw.ru.nl>
 <CAHr4DyfSeCvhkFmcRTYW-eejLgmUHAj4PCD2L6D+NM+zpp42KQ@mail.gmail.com>
Message-ID: <539e7739-bff0-057e-6d95-23befdcfe835@mpi.nl>

I'm also somewhat curious whether these really count as "unstructured"
(subject to the terminological issues pointed out by D. Bates)
covariance matrices. The gls examples seem to be imposing additional
constraints (such as setting the residual variance to 0 via varIdent())
to overcome these issues.

(As a sidebar, I'm not sure replicating pairwise correlation is what we
should aim for in the covariance structure of mixed-effects models.
Forcing us to match pairwise correlation/regression structure seems to
be forcing us to reduce a lot of the advantages of things like partial
pooling, shrinkage, etc. in mixed-effects models.)

Going back to the original question, is this really the same thing as
the "unstructured" covariance in SPSS? If so, how does SPSS allow for
"unstructured" covariance that has non-zero residual variance? Or in
terms of R, how would one distinguish terminologically between the lme4
"unstructured" and the gls "unstructured but residual constrained to zero"?

Best,
Phillip

On 22/03/18 11:03, Maarten Jung wrote:
> Hi Ben,
> 
> I'm aware of this problem for lmer.
> But how does gls() overcome the problem?
> 
> Regards,
> Maarten
> 
> On Thu, Mar 22, 2018, 10:44 Ben Pelzer <b.pelzer at maw.ru.nl> wrote:
> 
>> Hi Maarten,
>>
>> Notice that with the syntax for lmer, 6 random-effect (co)variances must
>> be estimated and 1 residual variance, so in total 7
>> (co)variance-parameters. However, there are only 6 observed covariances,
>> meaning that the model is over-specified. Many solutions are possible
>> all having the same loglikelihood. Ignoring the nobs.vs.nRE rule leads
>> to just one of the many solutions. I would not be surprised if you would
>> find another solution after manipulating the starting values for the
>> covariances or other criteria for convergence. Best regards,
>>
>> Ben.
>>
>>
>> On 22/03/2018 10:05, Maarten Jung wrote:
>>> I think the problem is that there is only one observation per
>>> subject-occasion-combination in this example.
>>> In this case the random slopes are confounded with the residual
>>> variation (see [1]).
>>>
>>> One *can* fit this model using lmer(test ~ 1 + occ2 + occ3 + (1 + occ2
>>> + occ3|person), data = mydata,  control =
>>> lmerControl(check.nobs.vs.nRE = "ignore")) or
>>> lme(test ~ 1 + occ2 + occ3, mydata, random = ~ occ2 + occ3|person).
>>>
>>> However, I don't know if the gls() fit ist more trustworthy than the
>>> lmer/lme fit here.
>>> I would be grateful if somebody more experienced in mixed models could
>>> comment on this.
>>>
>>> Best regards,
>>> Maarten
>>>
>>> [1]
>>>
>> https://stackoverflow.com/questions/26465215/random-slope-for-time-in-subject-not-working-in-lme4?utm_medium=organic&utm_source=google_rich_qa&utm_campaign=google_rich_qa
>>>
>>> On Wed, Mar 21, 2018 at 9:27 PM, Ben Pelzer <b.pelzer at maw.ru.nl
>>> <mailto:b.pelzer at maw.ru.nl>> wrote:
>>>
>>>     Hi Maarten,
>>>
>>>     Here is an example which shows the unstructured model with gls and
>> the
>>>     not converging model with lmer. In this example, we have three
>>>     occasions
>>>     on which the dependent variable "test" was observed, for each of 20
>>>     persons. In total then we have 60 observations, with the "occasion"
>>>     variable taking values 1, 2, 3. The data also contain the person id
>>>     variable "person" and dummy variables "occ1", "occ2", "occ3" as (0
>>>     or 1)
>>>     indicators of the occasion.  In the syntax below, a factor variable
>>>     "factor1" is created also, to be in line with your question.
>>>
>>>     I used two different specifications for the unstructured model
>>>     with gls,
>>>     depending on whether dummies or factor1 was used. For lmer, I used
>>>     these
>>>     three different specifications, none of which converges.
>>>
>>>     The lmer syntax was added only to show the problem which lmer has
>> with
>>>     estimating an unstructured correlation pattern.
>>>
>>>
>>>
>>  #------------------------------------------------------------------------------------------------------------------------------------------------------------
>>>     mydata <-
>>>     read.table(url("
>> https://surfdrive.surf.nl/files/index.php/s/XfE3mtbFCTUejIz/download
>>>     <
>> https://surfdrive.surf.nl/files/index.php/s/XfE3mtbFCTUejIz/download>"),
>>>     header=TRUE)
>>>
>>>
>>>     #-------------------  unstructured correlation matrix
>>>     -----------------------
>>>
>>>
>>>     # Before applying a model, let's first examine the variances and
>>>     correlations
>>>     # for the three occasions. We have a strong violation of the
>>>     assumptions
>>>     # of homoscedasticity and compound symmetry.
>>>     test1 <- mydata[mydata$occasion==1,"test"]
>>>     test2 <- mydata[mydata$occasion==2,"test"]
>>>     test3 <- mydata[mydata$occasion==3,"test"]
>>>     cor(cbind(test1, test2, test3))
>>>     var(cbind(test1, test2, test3))
>>>
>>>     # Unstructured model using gls from package nlme and dummies for
>>>     occasion.
>>>     # This model exactly reproduces the observed correlations between
>>>     occasions.
>>>     unstruc.gls1 <- gls(test ~ 1+ occ2 + occ3,
>>>                                 method="REML", data=mydata,
>>>                                 correlation=corSymm(form = ~ 1 |person),
>>>                                 weights = varIdent(form = ~1|occasion))
>>>     summary(unstruc.gls1)
>>>
>>>
>>>     # Unstructured model using factor1 for occasion instead of dummies.
>>>     # The results are exactly the same as those above, as should be.
>>>     mydata$factor1 <- as.factor(mydata$occasion)
>>>     unstruc.gls2 <- gls(test ~ factor1,
>>>                          method="REML", data=mydata,
>>>                          correlation=corSymm(form = ~ 1|person),
>>>                          weights = varIdent(form = ~1|factor1))
>>>     summary(unstruc.gls2)
>>>
>>>
>>>     # Unstructured model using lmer and dummies for occasion: does not
>>>     converge.
>>>     unstruc.lmer <- lmer(test ~ 1+ occ2 + occ3 + (1+occ2+occ3|person),
>>>                           data=mydata, REML=TRUE)
>>>     summary(unstruc.lmer)
>>>
>>>
>>>     # Unstructured model using lmer and factor1 for occasion: does not
>>>     converge.
>>>     unstruc.lmer <- lmer(test ~ 1+ factor1 + (1+factor1|person),
>>>                           data=mydata, REML=TRUE)
>>>     summary(unstruc.lmer)
>>>
>>>
>>>     # Unstructured model using lmer and factor1 for occasion, no
>> intercept
>>>     specified: does not converge.
>>>     unstruc.lmer <- lmer(test ~ factor1 + (factor1|person),
>>>                           data=mydata, REML=TRUE)
>>>     summary(unstruc.lmer)
>>>
>>>
>>>
>>>     On 21/03/2018 13:07, Maarten Jung wrote:
>>>     > Dear Ben,
>>>     >
>>>     > I am a bit puzzled.
>>>     >
>>>     > Do you mean that
>>>     >
>>>     > m1 <- gls(value ~ factor1, data, correlation = corSymm(form = ~
>>>     > 1|participant), weights = varIdent(form = ~ 1|factor))
>>>     >
>>>     > would be equivalent to
>>>     >
>>>     > m2 <- lmer(value ~ factor1 + (factor1|participant), data)
>>>     >
>>>     > and one should use gls() because it allows for the same covariance
>>>     > structures as /REPEATED does?
>>>     >
>>>
>>>
>>>     the two specifications are not equivalent in the sense that lmer also
>>>     tries to estimate residual variance. However, with the given lmer
>>>     model
>>>     specification, the random factor1 effects capture all variance
>>>     there is
>>>     and no residual variance remains.
>>>
>>>
>>>     > And, if so, why should m2 cause an identification problem and m1
>>>     doesn't?
>>>     >
>>>     > Regards,
>>>     > Maarten
>>>     >
>>>     Regards, Ben.
>>>
>>>
>>>
>>>     >
>>>     > On Wed, Mar 21, 2018 at 12:03 PM, Ben Pelzer <b.pelzer at maw.ru.nl
>>>     <mailto:b.pelzer at maw.ru.nl>
>>>     > <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>>> wrote:
>>>     >
>>>     >     Dear all,
>>>     >
>>>     >     As far as I know, the specification for lmer using
>>>     >
>>>     >          value ~ factor1 + (factor1 | participant)
>>>     >
>>>     >     causes an identification problem, because the residual
>>>     variance is not
>>>     >     excluded from the estimations. It would indeed work (e.g. in
>>>     MlWin
>>>     >     this
>>>     >     can be done) if we could constrain that residual variance to
>>>     zero.
>>>     >     There
>>>     >     have been some mails in this list about whether or not
>>>     constraining
>>>     >     residual variance to zero is possible in lmer, but I believe
>>>     this
>>>     >     is not
>>>     >     possible. Would be nice if we could do this in lmer!
>>>     >
>>>     >     Best regards, Ben.
>>>     >
>>>     >
>>>     >     On 20-3-2018 18:34, Douglas Bates wrote:
>>>     >     > Kind of looks like SPSS went for bug-for-bug compatibility
>>>     with
>>>     >     SAS on
>>>     >     > this one.  In SAS PROC MIXED, "REPEATED" and "RANDOM" are two
>>>     >     ways of
>>>     >     > specifying the random effects variance structure but they
>>>     often boil
>>>     >     > down to the same model.
>>>     >     >
>>>     >     > I believe the model can be specified in lme4 as
>>>     >     >
>>>     >     >     value ~ factor1 + (factor1 | participant)
>>>     >     >
>>>     >     > This is what the mis-named* "UNSTRUCTURED" covariance type
>>>     means
>>>     >     >
>>>     >     > * Old-guy, get off my lawn rant about terminology *
>>>     >     > As a recovering mathematician I find the name
>>>     "unstructured" being
>>>     >     > used to denote a positive-definite symmetric matrix to be,
>>>     well,
>>>     >     > inaccurate.
>>>     >     >
>>>     >     > On Tue, Mar 20, 2018 at 12:19 PM Mollie Brooks
>>>     >     > <mollieebrooks at gmail.com <mailto:mollieebrooks at gmail.com>
>>>     <mailto:mollieebrooks at gmail.com <mailto:mollieebrooks at gmail.com>>
>>>     >     <mailto:mollieebrooks at gmail.com
>>>     <mailto:mollieebrooks at gmail.com> <mailto:mollieebrooks at gmail.com
>>>     <mailto:mollieebrooks at gmail.com>>>>
>>>     >     wrote:
>>>     >     >
>>>     >     >     I don?t know anything about spss, but if you basically
>>>     want lme4
>>>     >     >     with more correlation structures, you could look at the
>>>     >     structures
>>>     >     >     available with glmmTMB.
>>>     >     >
>>>     >
>>>
>> https://cran.r-project.org/web/packages/glmmTMB/vignettes/covstruct.html
>>>     <
>> https://cran.r-project.org/web/packages/glmmTMB/vignettes/covstruct.html>
>>>     >
>>>      <
>> https://cran.r-project.org/web/packages/glmmTMB/vignettes/covstruct.html
>>>     <
>> https://cran.r-project.org/web/packages/glmmTMB/vignettes/covstruct.html>>
>>>     >     >
>>>     >     >     cheers,
>>>     >     >     Mollie
>>>     >     >
>>>     >     >     > On 20Mar 2018, at 18:11, Ben Pelzer
>>>     <b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>
>>>     >     <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>>
>>>     >     >     <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>
>>>     <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>>>> wrote:
>>>     >     >     >
>>>     >     >     > Hi Maarten,
>>>     >     >     >
>>>     >     >     > You are right: you need nlme and NOT lme4 to specify
>>>     >     particular
>>>     >     >     > correlation structures. Also, in nlme you would need
>> gls
>>>     >     to make it
>>>     >     >     > similar to mixed in spss. The repeated command in spss
>>>     >     gives the
>>>     >     >     same
>>>     >     >     > results as gls does for any of the covariance
>>>     structures.
>>>     >     >     >
>>>     >     >     > Regards, Ben.
>>>     >     >     >
>>>     >     >     >
>>>     >     >     > On 20/03/2018 17:30, Maarten Jung wrote:
>>>     >     >     >> Dear Ben, dear Phillip,
>>>     >     >     >>
>>>     >     >     >> comparing [1] with [2] I think the /REPEATED command
>>>     >     specifies
>>>     >     >     >> the error (co)variance structure of the model.
>>>     Would you
>>>     >     agree
>>>     >     >     with that?
>>>     >     >     >> If so, AFAIK this is not possible with lmer and
>>>     thus the
>>>     >     answer on
>>>     >     >     >> Stack Overflow [3] would be wrong.
>>>     >     >     >>
>>>     >     >     >> [1]
>>>     >     >     >>
>>>     >     >
>>>     >
>>>
>> https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/
>>>     <
>> https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/
>>>
>>>     >
>>>      <
>> https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/
>>>     <
>> https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/
>>>>
>>>     >     >     >> [2]
>>>     >     >     >>
>>>     >     >
>>>     >
>>>
>> https://stats.idre.ucla.edu/spss/examples/alda/chapter7/applied-longitudinal-data-analysis-modeling-change-and-event-occurrenceby-judith-d-singer-and-john-b-willett-chapter-7-examining-the-multilevel-model-s-erro/
>>>     <
>> https://stats.idre.ucla.edu/spss/examples/alda/chapter7/applied-longitudinal-data-analysis-modeling-change-and-event-occurrenceby-judith-d-singer-and-john-b-willett-chapter-7-examining-the-multilevel-model-s-erro/
>>>
>>>     >
>>>      <
>> https://stats.idre.ucla.edu/spss/examples/alda/chapter7/applied-longitudinal-data-analysis-modeling-change-and-event-occurrenceby-judith-d-singer-and-john-b-willett-chapter-7-examining-the-multilevel-model-s-erro/
>>>     <
>> https://stats.idre.ucla.edu/spss/examples/alda/chapter7/applied-longitudinal-data-analysis-modeling-change-and-event-occurrenceby-judith-d-singer-and-john-b-willett-chapter-7-examining-the-multilevel-model-s-erro/
>>>>
>>>     >     >     >> [3]
>>>     >     >     >>
>>>     >     >
>>>     >
>>>
>> https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
>>>     <
>> https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
>>>
>>>     >
>>>      <
>> https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
>>>     <
>> https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
>>>>
>>>     >     >     >>
>>>     >     >     >> Regards,
>>>     >     >     >> Maarten
>>>     >     >     >>
>>>     >     >     >> On Tue, Mar 20, 2018 at 2:10 PM, Ben Pelzer
>>>     >     <b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>
>>>     <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>>
>>>     >     >     <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>
>>>     <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>>>
>>>     >     >     >> <mailto:b.pelzer at maw.ru.nl
>>>     <mailto:b.pelzer at maw.ru.nl> <mailto:b.pelzer at maw.ru.nl
>>>     <mailto:b.pelzer at maw.ru.nl>>
>>>     >     <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>
>>>     <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>>>
>>>     >     >     <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>
>>>     <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>>
>>>     >     <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>
>>>     <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>>>>>> wrote:
>>>     >     >     >>
>>>     >     >     >>    Dear Maarten,
>>>     >     >     >>
>>>     >     >     >>    Take a look at
>>>     >     >     >>
>>>     >     >     >>
>>>     >     >
>>>     >
>>>
>> https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/
>>>     <
>> https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/
>>>
>>>     >
>>>      <
>> https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/
>>>     <
>> https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/
>>>>
>>>     >     >
>>>     >
>>>     <
>> https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/
>>>     <
>> https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/
>>>
>>>     >
>>>      <
>> https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/
>>>     <
>> https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/
>>>>>
>>>     >     >     >>
>>>     >     >
>>>     >
>>>     <
>> https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/
>>>     <
>> https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/
>>>
>>>     >
>>>      <
>> https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/
>>>     <
>> https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/
>>>>
>>>     >     >
>>>     >
>>>     <
>> https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/
>>>     <
>> https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/
>>>
>>>     >
>>>      <
>> https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/
>>>     <
>> https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/
>>>>>>
>>>     >     >     >>
>>>     >     >     >>    which shows you a number of covariance
>>>     structures, among
>>>     >     >     which is
>>>     >     >     >>    the unstructured matrix, for repeated measures in R
>>>     >     with lme. It
>>>     >     >     >>    refers to chapter 7 of Singer and Willett where
>> they
>>>     >     discuss all
>>>     >     >     >>    these different structures and how to choose
>>>     among them.
>>>     >     >     Regards,
>>>     >     >     >>
>>>     >     >     >>    Ben.
>>>     >     >     >>
>>>     >     >     >>    On 20-3-2018 9:00, Maarten Jung wrote:
>>>     >     >     >>
>>>     >     >     >>        Dear list,
>>>     >     >     >>        I came across a SPSS syntax like this
>>>     >     >     >>
>>>     >     >     >>        MIXED value BY factor1
>>>     >     >     >>  /CRITERIA=CIN(95) MXITER(100) MXSTEP(10)
>>>     >     SCORING(1)
>>>     >     >     >> SINGULAR(0.000000000001)
>>>     >     >     >>             HCONVERGE(0, ABSOLUTE) LCONVERGE(0,
>>>     ABSOLUTE)
>>>     >     >     >>        PCONVERGE(0.000001,
>>>     >     >     >>             ABSOLUTE)
>>>     >     >     >>             /FIXED=factor1 | SSTYPE(3)
>>>     >     >     >>             /METHOD=REML
>>>     >     >     >>  /REPEATED=factor1 | SUBJECT(participant)
>>>     >     COVTYPE(UN).
>>>     >     >     >>
>>>     >     >     >>        and struggle to find an equivalent lmer/nlme
>>>     (or R in
>>>     >     >     general)
>>>     >     >     >>        formulation
>>>     >     >     >>        for this kind of models.
>>>     >     >     >>        Does anybody know how to convert the REPEATED
>>>     >     subcommand
>>>     >     >     into
>>>     >     >     >>        R code?
>>>     >     >     >>
>>>     >     >     >>        Please note that I asked the question on Stack
>>>     >     Overflow
>>>     >     >     about
>>>     >     >     >>        two month ago:
>>>     >     >     >>
>>>     >     >
>>>     >
>>>
>> https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
>>>     <
>> https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
>>>
>>>     >
>>>      <
>> https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
>>>     <
>> https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
>>>>
>>>     >     >
>>>     >
>>>     <
>> https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
>>>     <
>> https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
>>>
>>>     >
>>>      <
>> https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
>>>     <
>> https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
>>>>>
>>>     >     >     >>
>>>     >     >
>>>     >
>>>     <
>> https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
>>>     <
>> https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
>>>
>>>     >
>>>      <
>> https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
>>>     <
>> https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
>>>>
>>>     >     >
>>>     >
>>>     <
>> https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
>>>     <
>> https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
>>>
>>>     >
>>>      <
>> https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
>>>     <
>> https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
>>>>>>
>>>     >     >     >>
>>>     >     >     >>        Best regards,
>>>     >     >     >>        Maarten
>>>     >     >     >>
>>>     >     >     >> [[alternative HTML version deleted]]
>>>     >     >     >>
>>>     >     >     >> _______________________________________________
>>>     >     >     >> R-sig-mixed-models at r-project.org
>>>     <mailto:R-sig-mixed-models at r-project.org>
>>>     >     <mailto:R-sig-mixed-models at r-project.org
>>>     <mailto:R-sig-mixed-models at r-project.org>>
>>>     >     >     <mailto:R-sig-mixed-models at r-project.org
>>>     <mailto:R-sig-mixed-models at r-project.org>
>>>     >     <mailto:R-sig-mixed-models at r-project.org
>>>     <mailto:R-sig-mixed-models at r-project.org>>>
>>>     >     >     <mailto:R-sig-mixed-models at r-project.org
>>>     <mailto:R-sig-mixed-models at r-project.org>
>>>     >     <mailto:R-sig-mixed-models at r-project.org
>>>     <mailto:R-sig-mixed-models at r-project.org>>
>>>     >     >     <mailto:R-sig-mixed-models at r-project.org
>>>     <mailto:R-sig-mixed-models at r-project.org>
>>>     >     <mailto:R-sig-mixed-models at r-project.org
>>>     <mailto:R-sig-mixed-models at r-project.org>>>>
>>>     >     >     >>        <mailto:R-sig-mixed-models at r-project.org
>>>     <mailto:R-sig-mixed-models at r-project.org>
>>>     >     <mailto:R-sig-mixed-models at r-project.org
>>>     <mailto:R-sig-mixed-models at r-project.org>>
>>>     >     >     <mailto:R-sig-mixed-models at r-project.org
>>>     <mailto:R-sig-mixed-models at r-project.org>
>>>     >     <mailto:R-sig-mixed-models at r-project.org
>>>     <mailto:R-sig-mixed-models at r-project.org>>>
>>>     >     >     <mailto:R-sig-mixed-models at r-project.org
>>>     <mailto:R-sig-mixed-models at r-project.org>
>>>     >     <mailto:R-sig-mixed-models at r-project.org
>>>     <mailto:R-sig-mixed-models at r-project.org>>
>>>     >     >     <mailto:R-sig-mixed-models at r-project.org
>>>     <mailto:R-sig-mixed-models at r-project.org>
>>>     >     <mailto:R-sig-mixed-models at r-project.org
>>>     <mailto:R-sig-mixed-models at r-project.org>>>>> mailing list
>>>     >     >     >>
>>>     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
>>>     >     >
>>>      <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>
>>>     >     >     >>
>>>     >     >
>>>      <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
>>>     >     >
>>>      <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>>
>>>     >     >     >>
>>>     >     >     >>
>>>     >     >     >> _______________________________________________
>>>     >     >     >> R-sig-mixed-models at r-project.org
>>>     <mailto:R-sig-mixed-models at r-project.org>
>>>     >     <mailto:R-sig-mixed-models at r-project.org
>>>     <mailto:R-sig-mixed-models at r-project.org>>
>>>     >     >     <mailto:R-sig-mixed-models at r-project.org
>>>     <mailto:R-sig-mixed-models at r-project.org>
>>>     >     <mailto:R-sig-mixed-models at r-project.org
>>>     <mailto:R-sig-mixed-models at r-project.org>>>
>>>     >     >     <mailto:R-sig-mixed-models at r-project.org
>>>     <mailto:R-sig-mixed-models at r-project.org>
>>>     >     <mailto:R-sig-mixed-models at r-project.org
>>>     <mailto:R-sig-mixed-models at r-project.org>>
>>>     >     >     <mailto:R-sig-mixed-models at r-project.org
>>>     <mailto:R-sig-mixed-models at r-project.org>
>>>     >     <mailto:R-sig-mixed-models at r-project.org
>>>     <mailto:R-sig-mixed-models at r-project.org>>>>
>>>     >     >     >>    <mailto:R-sig-mixed-models at r-project.org
>>>     <mailto:R-sig-mixed-models at r-project.org>
>>>     >     <mailto:R-sig-mixed-models at r-project.org
>>>     <mailto:R-sig-mixed-models at r-project.org>>
>>>     >     >     <mailto:R-sig-mixed-models at r-project.org
>>>     <mailto:R-sig-mixed-models at r-project.org>
>>>     >     <mailto:R-sig-mixed-models at r-project.org
>>>     <mailto:R-sig-mixed-models at r-project.org>>>
>>>     >     >     <mailto:R-sig-mixed-models at r-project.org
>>>     <mailto:R-sig-mixed-models at r-project.org>
>>>     >     <mailto:R-sig-mixed-models at r-project.org
>>>     <mailto:R-sig-mixed-models at r-project.org>>
>>>     >     >     <mailto:R-sig-mixed-models at r-project.org
>>>     <mailto:R-sig-mixed-models at r-project.org>
>>>     >     <mailto:R-sig-mixed-models at r-project.org
>>>     <mailto:R-sig-mixed-models at r-project.org>>>>> mailing list
>>>     >     >     >>
>>>     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
>>>     >     >
>>>      <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>
>>>     >     >     >>
>>>     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
>>>     >     >
>>>      <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>>
>>>     >     >     >>
>>>     >     >     >>
>>>     >     >     >
>>>     >     >     >
>>>     >     >     >       [[alternative HTML version deleted]]
>>>     >     >     >
>>>     >     >     > _______________________________________________
>>>     >     >     > R-sig-mixed-models at r-project.org
>>>     <mailto:R-sig-mixed-models at r-project.org>
>>>     >     <mailto:R-sig-mixed-models at r-project.org
>>>     <mailto:R-sig-mixed-models at r-project.org>>
>>>     >     >     <mailto:R-sig-mixed-models at r-project.org
>>>     <mailto:R-sig-mixed-models at r-project.org>
>>>     >     <mailto:R-sig-mixed-models at r-project.org
>>>     <mailto:R-sig-mixed-models at r-project.org>>>
>>>     >     >     <mailto:R-sig-mixed-models at r-project.org
>>>     <mailto:R-sig-mixed-models at r-project.org>
>>>     >     <mailto:R-sig-mixed-models at r-project.org
>>>     <mailto:R-sig-mixed-models at r-project.org>>
>>>     >     >     <mailto:R-sig-mixed-models at r-project.org
>>>     <mailto:R-sig-mixed-models at r-project.org>
>>>     >     <mailto:R-sig-mixed-models at r-project.org
>>>     <mailto:R-sig-mixed-models at r-project.org>>>> mailing list
>>>     >     >     >
>>>     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
>>>     >     >
>>>      <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>
>>>     >     >
>>>     >     >             [[alternative HTML version deleted]]
>>>     >     >
>>>     >     >     _______________________________________________
>>>     >     > R-sig-mixed-models at r-project.org
>>>     <mailto:R-sig-mixed-models at r-project.org>
>>>     >     <mailto:R-sig-mixed-models at r-project.org
>>>     <mailto:R-sig-mixed-models at r-project.org>>
>>>     >     >     <mailto:R-sig-mixed-models at r-project.org
>>>     <mailto:R-sig-mixed-models at r-project.org>
>>>     >     <mailto:R-sig-mixed-models at r-project.org
>>>     <mailto:R-sig-mixed-models at r-project.org>>> mailing list
>>>     >     > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
>>>     >     >
>>>     >
>>>     >
>>>     >             [[alternative HTML version deleted]]
>>>     >
>>>     >     _______________________________________________
>>>     > R-sig-mixed-models at r-project.org
>>>     <mailto:R-sig-mixed-models at r-project.org>
>>>     >     <mailto:R-sig-mixed-models at r-project.org
>>>     <mailto:R-sig-mixed-models at r-project.org>> mailing list
>>>     > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
>>>     >
>>>     >
>>>
>>>
>>>             [[alternative HTML version deleted]]
>>>
>>>     _______________________________________________
>>>     R-sig-mixed-models at r-project.org
>>>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>>>     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>
>>>
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From b.pelzer at maw.ru.nl  Thu Mar 22 11:36:29 2018
From: b.pelzer at maw.ru.nl (Ben Pelzer)
Date: Thu, 22 Mar 2018 11:36:29 +0100
Subject: [R-sig-ME] What is the lmer/nlme equivalent of the REPEATED
 subcommand in SPSS's MIXED procedure?
In-Reply-To: <CAHr4DyfSeCvhkFmcRTYW-eejLgmUHAj4PCD2L6D+NM+zpp42KQ@mail.gmail.com>
References: <CAHr4Dyep9JCDpNauViVf0MyeH-=p7k0fx3yXbMCL_b-9tLTMEQ@mail.gmail.com>
 <d67d36fb-1019-d878-794e-491c3a409f2a@maw.ru.nl>
 <CAHr4Dydq-SW_8aKUF=MFqnFpx6P36RSguP7gTF-6epZjMFWo3A@mail.gmail.com>
 <5AB140DE.5090705@maw.ru.nl>
 <20732_1521566386_0P5W00D4NG4WVU20_9ECC9EC8-43DB-49AD-97E0-67E5E680460A@gmail.com>
 <CAO7JsnTCenXXrrrfJthUz5aLv2wiubdrzOw30mFY5AdUBmF=ig@mail.gmail.com>
 <42ce404b-af99-82c6-a2f6-482b9963da3a@maw.ru.nl>
 <CAHr4DyeaLCL_RxsjNnYb=L2pxo4r4+mcmsDF382x88UPoVYPaA@mail.gmail.com>
 <5AB2C04C.6010707@maw.ru.nl>
 <CAHr4Dyfhcuh7cNqDCR8ghdHfu1mwhzW9MWMChnOTTsTD_nmo+A@mail.gmail.com>
 <5AB37ACE.90002@maw.ru.nl>
 <CAHr4DyfSeCvhkFmcRTYW-eejLgmUHAj4PCD2L6D+NM+zpp42KQ@mail.gmail.com>
Message-ID: <5AB3872D.5000301@maw.ru.nl>

Hi Maarten,

In gls there are no (three) random intercepts for the occasions, there 
are only "residuals" which are allowed to correlate. Singer and Willett 
call these residuals "composite" residuals. For the observations on 
occasion 1 the model equations are:

lmer model: test1 = b0 + b1*occ1 + uj + eij
gls model: test1 = b0 + b1*occ1 + residual

This shows that uj+eij in lmer is replaced by just one term "residual" 
in gls. Hence  the term "composite residuals".

Returning to ignoring the nobs.vs.nRE rule, we could also specify this 
model with three dummies and no intercept:

# Unstructured model using lmer and dummies for occasion: does not 
converge.
unstruc.lmer <- lmer(test ~ -1+occ1+ occ2 + occ3 + 
(-1+occ1+occ2+occ3|person),
                      data=mydata, REML=TRUE,
                      control = lmerControl(check.nobs.vs.nRE = "ignore"),
                      )
summary(unstruc.lmer)

You will see in the results that the sum of each random occasion 
variance PLUS the residual variance exactly equals the observed 
variance. This implies that the unidentifiability of this model with 
lmer is caused by the fact that the 3 observed variances must be 
estimated with 4 parameters. Increasing the estimated value of the 
residual variance with a constant, A, means that for the 3 occasion 
random effect variances, the estimated values must be decreased by A to 
end up with the same estimates of the variances in the dependent 
variable at all three timepoints. And the fit in terms of loglikelihood 
would be equal.

Regards, Ben.




, relates to the also probably may have noticed that in the "solution" 
you obtained by ignoring the nobs.vs.nRE rule, the sum of the random 
occasion effect for time=1

On 22/03/2018 11:03, Maarten Jung wrote:
> Hi Ben,
>
> I'm aware of this problem for lmer.
> But how does gls() overcome the problem?
>
> Regards,
> Maarten
>
> On Thu, Mar 22, 2018, 10:44 Ben Pelzer <b.pelzer at maw.ru.nl 
> <mailto:b.pelzer at maw.ru.nl>> wrote:
>
>     Hi Maarten,
>
>     Notice that with the syntax for lmer, 6 random-effect
>     (co)variances must
>     be estimated and 1 residual variance, so in total 7
>     (co)variance-parameters. However, there are only 6 observed
>     covariances,
>     meaning that the model is over-specified. Many solutions are possible
>     all having the same loglikelihood. Ignoring the nobs.vs.nRE rule leads
>     to just one of the many solutions. I would not be surprised if you
>     would
>     find another solution after manipulating the starting values for the
>     covariances or other criteria for convergence. Best regards,
>
>     Ben.
>
>
>     On 22/03/2018 10:05, Maarten Jung wrote:
>     > I think the problem is that there is only one observation per
>     > subject-occasion-combination in this example.
>     > In this case the random slopes are confounded with the residual
>     > variation (see [1]).
>     >
>     > One *can* fit this model using lmer(test ~ 1 + occ2 + occ3 + (1
>     + occ2
>     > + occ3|person), data = mydata,  control =
>     > lmerControl(check.nobs.vs.nRE = "ignore")) or
>     > lme(test ~ 1 + occ2 + occ3, mydata, random = ~ occ2 + occ3|person).
>     >
>     > However, I don't know if the gls() fit ist more trustworthy than the
>     > lmer/lme fit here.
>     > I would be grateful if somebody more experienced in mixed models
>     could
>     > comment on this.
>     >
>     > Best regards,
>     > Maarten
>     >
>     > [1]
>     >
>     https://stackoverflow.com/questions/26465215/random-slope-for-time-in-subject-not-working-in-lme4?utm_medium=organic&utm_source=google_rich_qa&utm_campaign=google_rich_qa
>     >
>     > On Wed, Mar 21, 2018 at 9:27 PM, Ben Pelzer <b.pelzer at maw.ru.nl
>     <mailto:b.pelzer at maw.ru.nl>
>     > <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>>> wrote:
>     >
>     >     Hi Maarten,
>     >
>     >     Here is an example which shows the unstructured model with
>     gls and the
>     >     not converging model with lmer. In this example, we have three
>     >     occasions
>     >     on which the dependent variable "test" was observed, for
>     each of 20
>     >     persons. In total then we have 60 observations, with the
>     "occasion"
>     >     variable taking values 1, 2, 3. The data also contain the
>     person id
>     >     variable "person" and dummy variables "occ1", "occ2", "occ3"
>     as (0
>     >     or 1)
>     >     indicators of the occasion.  In the syntax below, a factor
>     variable
>     >     "factor1" is created also, to be in line with your question.
>     >
>     >     I used two different specifications for the unstructured model
>     >     with gls,
>     >     depending on whether dummies or factor1 was used. For lmer,
>     I used
>     >     these
>     >     three different specifications, none of which converges.
>     >
>     >     The lmer syntax was added only to show the problem which
>     lmer has with
>     >     estimating an unstructured correlation pattern.
>     >
>     >
>     >
>      #------------------------------------------------------------------------------------------------------------------------------------------------------------
>     >     mydata <-
>     >   
>      read.table(url("https://surfdrive.surf.nl/files/index.php/s/XfE3mtbFCTUejIz/download
>     >   
>      <https://surfdrive.surf.nl/files/index.php/s/XfE3mtbFCTUejIz/download>"),
>     >     header=TRUE)
>     >
>     >
>     >     #-------------------  unstructured correlation matrix
>     >     -----------------------
>     >
>     >
>     >     # Before applying a model, let's first examine the variances and
>     >     correlations
>     >     # for the three occasions. We have a strong violation of the
>     >     assumptions
>     >     # of homoscedasticity and compound symmetry.
>     >     test1 <- mydata[mydata$occasion==1,"test"]
>     >     test2 <- mydata[mydata$occasion==2,"test"]
>     >     test3 <- mydata[mydata$occasion==3,"test"]
>     >     cor(cbind(test1, test2, test3))
>     >     var(cbind(test1, test2, test3))
>     >
>     >     # Unstructured model using gls from package nlme and dummies for
>     >     occasion.
>     >     # This model exactly reproduces the observed correlations
>     between
>     >     occasions.
>     >     unstruc.gls1 <- gls(test ~ 1+ occ2 + occ3,
>     >                                 method="REML", data=mydata,
>     >  correlation=corSymm(form = ~ 1 |person),
>     >                                 weights = varIdent(form =
>     ~1|occasion))
>     >     summary(unstruc.gls1)
>     >
>     >
>     >     # Unstructured model using factor1 for occasion instead of
>     dummies.
>     >     # The results are exactly the same as those above, as should be.
>     >     mydata$factor1 <- as.factor(mydata$occasion)
>     >     unstruc.gls2 <- gls(test ~ factor1,
>     >                          method="REML", data=mydata,
>     >                          correlation=corSymm(form = ~ 1|person),
>     >                          weights = varIdent(form = ~1|factor1))
>     >     summary(unstruc.gls2)
>     >
>     >
>     >     # Unstructured model using lmer and dummies for occasion:
>     does not
>     >     converge.
>     >     unstruc.lmer <- lmer(test ~ 1+ occ2 + occ3 +
>     (1+occ2+occ3|person),
>     >                           data=mydata, REML=TRUE)
>     >     summary(unstruc.lmer)
>     >
>     >
>     >     # Unstructured model using lmer and factor1 for occasion:
>     does not
>     >     converge.
>     >     unstruc.lmer <- lmer(test ~ 1+ factor1 + (1+factor1|person),
>     >                           data=mydata, REML=TRUE)
>     >     summary(unstruc.lmer)
>     >
>     >
>     >     # Unstructured model using lmer and factor1 for occasion, no
>     intercept
>     >     specified: does not converge.
>     >     unstruc.lmer <- lmer(test ~ factor1 + (factor1|person),
>     >                           data=mydata, REML=TRUE)
>     >     summary(unstruc.lmer)
>     >
>     >
>     >
>     >     On 21/03/2018 13:07, Maarten Jung wrote:
>     >     > Dear Ben,
>     >     >
>     >     > I am a bit puzzled.
>     >     >
>     >     > Do you mean that
>     >     >
>     >     > m1 <- gls(value ~ factor1, data, correlation =
>     corSymm(form = ~
>     >     > 1|participant), weights = varIdent(form = ~ 1|factor))
>     >     >
>     >     > would be equivalent to
>     >     >
>     >     > m2 <- lmer(value ~ factor1 + (factor1|participant), data)
>     >     >
>     >     > and one should use gls() because it allows for the same
>     covariance
>     >     > structures as /REPEATED does?
>     >     >
>     >
>     >
>     >     the two specifications are not equivalent in the sense that
>     lmer also
>     >     tries to estimate residual variance. However, with the given
>     lmer
>     >     model
>     >     specification, the random factor1 effects capture all variance
>     >     there is
>     >     and no residual variance remains.
>     >
>     >
>     >     > And, if so, why should m2 cause an identification problem
>     and m1
>     >     doesn't?
>     >     >
>     >     > Regards,
>     >     > Maarten
>     >     >
>     >     Regards, Ben.
>     >
>     >
>     >
>     >     >
>     >     > On Wed, Mar 21, 2018 at 12:03 PM, Ben Pelzer
>     <b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>
>     >     <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>>
>     >     > <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>
>     <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>>>> wrote:
>     >     >
>     >     >     Dear all,
>     >     >
>     >     >     As far as I know, the specification for lmer using
>     >     >
>     >     >          value ~ factor1 + (factor1 | participant)
>     >     >
>     >     >     causes an identification problem, because the residual
>     >     variance is not
>     >     >     excluded from the estimations. It would indeed work
>     (e.g. in
>     >     MlWin
>     >     >     this
>     >     >     can be done) if we could constrain that residual
>     variance to
>     >     zero.
>     >     >     There
>     >     >     have been some mails in this list about whether or not
>     >     constraining
>     >     >     residual variance to zero is possible in lmer, but I
>     believe
>     >     this
>     >     >     is not
>     >     >     possible. Would be nice if we could do this in lmer!
>     >     >
>     >     >     Best regards, Ben.
>     >     >
>     >     >
>     >     >     On 20-3-2018 18:34, Douglas Bates wrote:
>     >     >     > Kind of looks like SPSS went for bug-for-bug
>     compatibility
>     >     with
>     >     >     SAS on
>     >     >     > this one.  In SAS PROC MIXED, "REPEATED" and
>     "RANDOM" are two
>     >     >     ways of
>     >     >     > specifying the random effects variance structure but
>     they
>     >     often boil
>     >     >     > down to the same model.
>     >     >     >
>     >     >     > I believe the model can be specified in lme4 as
>     >     >     >
>     >     >     >     value ~ factor1 + (factor1 | participant)
>     >     >     >
>     >     >     > This is what the mis-named* "UNSTRUCTURED"
>     covariance type
>     >     means
>     >     >     >
>     >     >     > * Old-guy, get off my lawn rant about terminology *
>     >     >     > As a recovering mathematician I find the name
>     >     "unstructured" being
>     >     >     > used to denote a positive-definite symmetric matrix
>     to be,
>     >     well,
>     >     >     > inaccurate.
>     >     >     >
>     >     >     > On Tue, Mar 20, 2018 at 12:19 PM Mollie Brooks
>     >     >     > <mollieebrooks at gmail.com
>     <mailto:mollieebrooks at gmail.com> <mailto:mollieebrooks at gmail.com
>     <mailto:mollieebrooks at gmail.com>>
>     >     <mailto:mollieebrooks at gmail.com
>     <mailto:mollieebrooks at gmail.com> <mailto:mollieebrooks at gmail.com
>     <mailto:mollieebrooks at gmail.com>>>
>     >     >     <mailto:mollieebrooks at gmail.com
>     <mailto:mollieebrooks at gmail.com>
>     >     <mailto:mollieebrooks at gmail.com
>     <mailto:mollieebrooks at gmail.com>> <mailto:mollieebrooks at gmail.com
>     <mailto:mollieebrooks at gmail.com>
>     >     <mailto:mollieebrooks at gmail.com
>     <mailto:mollieebrooks at gmail.com>>>>>
>     >     >     wrote:
>     >     >     >
>     >     >     >     I don?t know anything about spss, but if you
>     basically
>     >     want lme4
>     >     >     >     with more correlation structures, you could look
>     at the
>     >     >     structures
>     >     >     >     available with glmmTMB.
>     >     >     >
>     >     >
>     >
>     https://cran.r-project.org/web/packages/glmmTMB/vignettes/covstruct.html
>     >   
>      <https://cran.r-project.org/web/packages/glmmTMB/vignettes/covstruct.html>
>     >     >
>     >     
>     <https://cran.r-project.org/web/packages/glmmTMB/vignettes/covstruct.html
>     >   
>      <https://cran.r-project.org/web/packages/glmmTMB/vignettes/covstruct.html>>
>     >     >     >
>     >     >     >     cheers,
>     >     >     >     Mollie
>     >     >     >
>     >     >     >     > On 20Mar 2018, at 18:11, Ben Pelzer
>     >     <b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>
>     <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>>
>     >     >     <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>
>     <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>>>
>     >     >     >     <mailto:b.pelzer at maw.ru.nl
>     <mailto:b.pelzer at maw.ru.nl> <mailto:b.pelzer at maw.ru.nl
>     <mailto:b.pelzer at maw.ru.nl>>
>     >     <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>
>     <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>>>>> wrote:
>     >     >     >     >
>     >     >     >     > Hi Maarten,
>     >     >     >     >
>     >     >     >     > You are right: you need nlme and NOT lme4 to
>     specify
>     >     >     particular
>     >     >     >     > correlation structures. Also, in nlme you
>     would need gls
>     >     >     to make it
>     >     >     >     > similar to mixed in spss. The repeated command
>     in spss
>     >     >     gives the
>     >     >     >     same
>     >     >     >     > results as gls does for any of the covariance
>     >     structures.
>     >     >     >     >
>     >     >     >     > Regards, Ben.
>     >     >     >     >
>     >     >     >     >
>     >     >     >     > On 20/03/2018 17:30, Maarten Jung wrote:
>     >     >     >     >> Dear Ben, dear Phillip,
>     >     >     >     >>
>     >     >     >     >> comparing [1] with [2] I think the /REPEATED
>     command
>     >     >     specifies
>     >     >     >     >> the error (co)variance structure of the model.
>     >     Would you
>     >     >     agree
>     >     >     >     with that?
>     >     >     >     >> If so, AFAIK this is not possible with lmer and
>     >     thus the
>     >     >     answer on
>     >     >     >     >> Stack Overflow [3] would be wrong.
>     >     >     >     >>
>     >     >     >     >> [1]
>     >     >     >     >>
>     >     >     >
>     >     >
>     >
>     https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/
>     >   
>      <https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/>
>     >     >
>     >     
>     <https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/
>     >   
>      <https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/>>
>     >     >     >     >> [2]
>     >     >     >     >>
>     >     >     >
>     >     >
>     >
>     https://stats.idre.ucla.edu/spss/examples/alda/chapter7/applied-longitudinal-data-analysis-modeling-change-and-event-occurrenceby-judith-d-singer-and-john-b-willett-chapter-7-examining-the-multilevel-model-s-erro/
>     >   
>      <https://stats.idre.ucla.edu/spss/examples/alda/chapter7/applied-longitudinal-data-analysis-modeling-change-and-event-occurrenceby-judith-d-singer-and-john-b-willett-chapter-7-examining-the-multilevel-model-s-erro/>
>     >     >
>     >     
>     <https://stats.idre.ucla.edu/spss/examples/alda/chapter7/applied-longitudinal-data-analysis-modeling-change-and-event-occurrenceby-judith-d-singer-and-john-b-willett-chapter-7-examining-the-multilevel-model-s-erro/
>     >   
>      <https://stats.idre.ucla.edu/spss/examples/alda/chapter7/applied-longitudinal-data-analysis-modeling-change-and-event-occurrenceby-judith-d-singer-and-john-b-willett-chapter-7-examining-the-multilevel-model-s-erro/>>
>     >     >     >     >> [3]
>     >     >     >     >>
>     >     >     >
>     >     >
>     >
>     https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
>     >   
>      <https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc>
>     >     >
>     >     
>     <https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
>     >   
>      <https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc>>
>     >     >     >     >>
>     >     >     >     >> Regards,
>     >     >     >     >> Maarten
>     >     >     >     >>
>     >     >     >     >> On Tue, Mar 20, 2018 at 2:10 PM, Ben Pelzer
>     >     >     <b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>
>     <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>>
>     >     <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>
>     <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>>>
>     >     >     >     <mailto:b.pelzer at maw.ru.nl
>     <mailto:b.pelzer at maw.ru.nl> <mailto:b.pelzer at maw.ru.nl
>     <mailto:b.pelzer at maw.ru.nl>>
>     >     <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>
>     <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>>>>
>     >     >     >     >> <mailto:b.pelzer at maw.ru.nl
>     <mailto:b.pelzer at maw.ru.nl>
>     >     <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>>
>     <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>
>     >     <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>>>
>     >     >     <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>
>     <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>>
>     >     <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>
>     <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>>>>
>     >     >     >     <mailto:b.pelzer at maw.ru.nl
>     <mailto:b.pelzer at maw.ru.nl> <mailto:b.pelzer at maw.ru.nl
>     <mailto:b.pelzer at maw.ru.nl>>
>     >     <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>
>     <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>>>
>     >     >     <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>
>     <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>>
>     >     <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>
>     <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>>>>>>> wrote:
>     >     >     >     >>
>     >     >     >     >>    Dear Maarten,
>     >     >     >     >>
>     >     >     >     >>    Take a look at
>     >     >     >     >>
>     >     >     >     >>
>     >     >     >
>     >     >
>     >
>     https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/
>     >   
>      <https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/>
>     >     >
>     >     
>     <https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/
>     >   
>      <https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/>>
>     >     >     >
>     >     >
>     >   
>      <https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/
>     >   
>      <https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/>
>     >     >
>     >     
>     <https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/
>     >   
>      <https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/>>>
>     >     >     >     >>
>     >     >     >
>     >     >
>     >   
>      <https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/
>     >   
>      <https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/>
>     >     >
>     >     
>     <https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/
>     >   
>      <https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/>>
>     >     >     >
>     >     >
>     >   
>      <https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/
>     >   
>      <https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/>
>     >     >
>     >     
>     <https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/
>     >   
>      <https://stats.idre.ucla.edu/r/examples/alda/r-applied-longitudinal-data-analysis-ch-7/>>>>
>     >     >     >     >>
>     >     >     >     >>    which shows you a number of covariance
>     >     structures, among
>     >     >     >     which is
>     >     >     >     >>    the unstructured matrix, for repeated
>     measures in R
>     >     >     with lme. It
>     >     >     >     >>    refers to chapter 7 of Singer and Willett
>     where they
>     >     >     discuss all
>     >     >     >     >>    these different structures and how to choose
>     >     among them.
>     >     >     >     Regards,
>     >     >     >     >>
>     >     >     >     >>    Ben.
>     >     >     >     >>
>     >     >     >     >>    On 20-3-2018 9:00, Maarten Jung wrote:
>     >     >     >     >>
>     >     >     >     >>        Dear list,
>     >     >     >     >>        I came across a SPSS syntax like this
>     >     >     >     >>
>     >     >     >     >>        MIXED value BY factor1
>     >     >     >     >>  /CRITERIA=CIN(95) MXITER(100) MXSTEP(10)
>     >     >     SCORING(1)
>     >     >     >     >> SINGULAR(0.000000000001)
>     >     >     >     >>  HCONVERGE(0, ABSOLUTE) LCONVERGE(0,
>     >     ABSOLUTE)
>     >     >     >     >> PCONVERGE(0.000001,
>     >     >     >     >>             ABSOLUTE)
>     >     >     >     >>  /FIXED=factor1 | SSTYPE(3)
>     >     >     >     >>  /METHOD=REML
>     >     >     >     >>  /REPEATED=factor1 | SUBJECT(participant)
>     >     >     COVTYPE(UN).
>     >     >     >     >>
>     >     >     >     >>        and struggle to find an equivalent
>     lmer/nlme
>     >     (or R in
>     >     >     >     general)
>     >     >     >     >>        formulation
>     >     >     >     >>        for this kind of models.
>     >     >     >     >>        Does anybody know how to convert the
>     REPEATED
>     >     >     subcommand
>     >     >     >     into
>     >     >     >     >>        R code?
>     >     >     >     >>
>     >     >     >     >>        Please note that I asked the question
>     on Stack
>     >     >     Overflow
>     >     >     >     about
>     >     >     >     >>        two month ago:
>     >     >     >     >>
>     >     >     >
>     >     >
>     >
>     https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
>     >   
>      <https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc>
>     >     >
>     >     
>     <https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
>     >   
>      <https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc>>
>     >     >     >
>     >     >
>     >   
>      <https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
>     >   
>      <https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc>
>     >     >
>     >     
>     <https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
>     >   
>      <https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc>>>
>     >     >     >     >>
>     >     >     >
>     >     >
>     >   
>      <https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
>     >   
>      <https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc>
>     >     >
>     >     
>     <https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
>     >   
>      <https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc>>
>     >     >     >
>     >     >
>     >   
>      <https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
>     >   
>      <https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc>
>     >     >
>     >     
>     <https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
>     >   
>      <https://stackoverflow.com/questions/48518514/what-is-the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc>>>>
>     >     >     >     >>
>     >     >     >     >>        Best regards,
>     >     >     >     >>        Maarten
>     >     >     >     >>
>     >     >     >     >> [[alternative HTML version deleted]]
>     >     >     >     >>
>     >     >     >     >> _______________________________________________
>     >     >     >     >> R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>
>     >     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>>
>     >     >     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>
>     >     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>>>
>     >     >     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>
>     >     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>>
>     >     >     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>
>     >     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>>>>
>     >     >     >     >>       
>     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>
>     >     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>>
>     >     >     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>
>     >     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>>>
>     >     >     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>
>     >     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>>
>     >     >     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>
>     >     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>>>>> mailing list
>     >     >     >     >>
>     > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>     >     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
>     >     >     >
>     >      <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>     >     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>
>     >     >     >     >>
>     >     >     >
>     >      <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>     >     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
>     >     >     >
>     >      <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>     >     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>>
>     >     >     >     >>
>     >     >     >     >>
>     >     >     >     >> _______________________________________________
>     >     >     >     >> R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>
>     >     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>>
>     >     >     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>
>     >     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>>>
>     >     >     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>
>     >     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>>
>     >     >     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>
>     >     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>>>>
>     >     >     >     >>    <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>
>     >     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>>
>     >     >     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>
>     >     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>>>
>     >     >     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>
>     >     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>>
>     >     >     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>
>     >     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>>>>> mailing list
>     >     >     >     >>
>     > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>     >     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
>     >     >     >
>     >      <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>     >     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>
>     >     >     >     >>
>     >     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>     >     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
>     >     >     >
>     >      <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>     >     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>>
>     >     >     >     >>
>     >     >     >     >>
>     >     >     >     >
>     >     >     >     >
>     >     >     >     >       [[alternative HTML version deleted]]
>     >     >     >     >
>     >     >     >     > _______________________________________________
>     >     >     >     > R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>
>     >     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>>
>     >     >     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>
>     >     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>>>
>     >     >     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>
>     >     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>>
>     >     >     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>
>     >     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>>>> mailing list
>     >     >     >     >
>     > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>     >     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
>     >     >     >
>     >      <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>     >     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>
>     >     >     >
>     >     >     >             [[alternative HTML version deleted]]
>     >     >     >
>     >     >     >  _______________________________________________
>     >     >     > R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>
>     >     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>>
>     >     >     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>
>     >     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>>> mailing list
>     >     >     > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>     >     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
>     >     >     >
>     >     >
>     >     >
>     >     >             [[alternative HTML version deleted]]
>     >     >
>     >     >  _______________________________________________
>     >     > R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>
>     >     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>>> mailing list
>     >     > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>     >     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
>     >     >
>     >     >
>     >
>     >
>     >             [[alternative HTML version deleted]]
>     >
>     >     _______________________________________________
>     > R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>     >     <mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>> mailing list
>     > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>     >
>     >
>
>
>             [[alternative HTML version deleted]]
>
>     _______________________________________________
>     R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


	[[alternative HTML version deleted]]


From rune.haubo at gmail.com  Thu Mar 22 11:38:54 2018
From: rune.haubo at gmail.com (Rune Haubo)
Date: Thu, 22 Mar 2018 11:38:54 +0100
Subject: [R-sig-ME] What is the lmer/nlme equivalent of the REPEATED
 subcommand in SPSS's MIXED procedure?
In-Reply-To: <CAHr4Dyfhcuh7cNqDCR8ghdHfu1mwhzW9MWMChnOTTsTD_nmo+A@mail.gmail.com>
References: <CAHr4Dyep9JCDpNauViVf0MyeH-=p7k0fx3yXbMCL_b-9tLTMEQ@mail.gmail.com>
 <d67d36fb-1019-d878-794e-491c3a409f2a@maw.ru.nl>
 <CAHr4Dydq-SW_8aKUF=MFqnFpx6P36RSguP7gTF-6epZjMFWo3A@mail.gmail.com>
 <5AB140DE.5090705@maw.ru.nl>
 <20732_1521566386_0P5W00D4NG4WVU20_9ECC9EC8-43DB-49AD-97E0-67E5E680460A@gmail.com>
 <CAO7JsnTCenXXrrrfJthUz5aLv2wiubdrzOw30mFY5AdUBmF=ig@mail.gmail.com>
 <42ce404b-af99-82c6-a2f6-482b9963da3a@maw.ru.nl>
 <CAHr4DyeaLCL_RxsjNnYb=L2pxo4r4+mcmsDF382x88UPoVYPaA@mail.gmail.com>
 <5AB2C04C.6010707@maw.ru.nl>
 <CAHr4Dyfhcuh7cNqDCR8ghdHfu1mwhzW9MWMChnOTTsTD_nmo+A@mail.gmail.com>
Message-ID: <CAG_uk93v1bO48X2nOpuobS7qiqC20MNpJ_T5MKzcgWi89hunzw@mail.gmail.com>

On 22 March 2018 at 10:05, Maarten Jung
<Maarten.Jung at mailbox.tu-dresden.de> wrote:
> I think the problem is that there is only one observation per
> subject-occasion-combination in this example.
> In this case the random slopes are confounded with the residual variation
> (see [1]).

I agree.

>
> One *can* fit this model using lmer(test ~ 1 + occ2 + occ3 + (1 + occ2 +
> occ3|person), data = mydata,  control = lmerControl(check.nobs.vs.nRE =
> "ignore")) or
> lme(test ~ 1 + occ2 + occ3, mydata, random = ~ occ2 + occ3|person).
>
> However, I don't know if the gls() fit ist more trustworthy than the
> lmer/lme fit here.
> I would be grateful if somebody more experienced in mixed models could
> comment on this.

If you are trying to replicate a model that is specified with a
'repeated' statement (and 'repeated' in SPSS means the same as in SAS)
then we are talking about specifying a structure in the residual
variance-covariance matrix (cf.
https://support.sas.com/documentation/cdl/en/statug/63033/HTML/default/viewer.htm#statug_mixed_sect019.htm).
If we write the model as y = X beta + Z b + e with b ~ N(0, G) and e ~
N(0, R), then 'repeated' is specifying the structure in R. This is
exactly what nlme::gls and nlme::lme do via the weights and
correlation arguments; you need lme if you have 'true' random effects
on top of the structure in R.

If we write the marginal distribution of y as y ~ N(X beta, V), with V
= ZGZ' + R then the structure in V can be obtained by appropriate
specification of either Z and G or R, or both. This means that in some
cases there is more than one 'natural' way to specify the same
marginal model (compound symmetry is the classical example*). Now,
lmer has the structure of R fixed at sigma^2 I, i.e. a multiple of the
identity matrix, but with appropriate random-effect specification you
can sometimes obtain the same (marginal) likelihood as if the
structure was specified in the R matrix. My advice, is however, that
if you want to fit a model with a particular structure in R, then
don't use lmer; you really have to know all details of what is going
to be sure that it works as intended.

Cheers,
Rune

*Actually the compound symmetry and random intercept models are _not_
the same (though often claimed to be) because the parameter spaces
differ. This means that for some data sets the model fits are the same
(i.e. same likelihood) and for other data sets the model fits are
different.

>
> Best regards,
> Maarten
>
> [1]
> https://stackoverflow.com/questions/26465215/random-slope-for-time-in-subject-not-working-in-lme4?utm_medium=organic&utm_source=google_rich_qa&utm_campaign=google_rich_qa
>
> On Wed, Mar 21, 2018 at 9:27 PM, Ben Pelzer <b.pelzer at maw.ru.nl> wrote:
>
>> Hi Maarten,
>>
>> Here is an example which shows the unstructured model with gls and the
>> not converging model with lmer. In this example, we have three occasions
>> on which the dependent variable "test" was observed, for each of 20
>> persons. In total then we have 60 observations, with the "occasion"
>> variable taking values 1, 2, 3. The data also contain the person id
>> variable "person" and dummy variables "occ1", "occ2", "occ3" as (0 or 1)
>> indicators of the occasion.  In the syntax below, a factor variable
>> "factor1" is created also, to be in line with your question.
>>
>> I used two different specifications for the unstructured model with gls,
>> depending on whether dummies or factor1 was used. For lmer, I used these
>> three different specifications, none of which converges.
>>
>> The lmer syntax was added only to show the problem which lmer has with
>> estimating an unstructured correlation pattern.
>>
>>
>> #-----------------------------------------------------------
>> ------------------------------------------------------------
>> -------------------------------------
>> mydata <-
>> read.table(url("https://surfdrive.surf.nl/files/index.
>> php/s/XfE3mtbFCTUejIz/download"),
>> header=TRUE)
>>
>>
>> #-------------------  unstructured correlation matrix
>> -----------------------
>>
>>
>> # Before applying a model, let's first examine the variances and
>> correlations
>> # for the three occasions. We have a strong violation of the assumptions
>> # of homoscedasticity and compound symmetry.
>> test1 <- mydata[mydata$occasion==1,"test"]
>> test2 <- mydata[mydata$occasion==2,"test"]
>> test3 <- mydata[mydata$occasion==3,"test"]
>> cor(cbind(test1, test2, test3))
>> var(cbind(test1, test2, test3))
>>
>> # Unstructured model using gls from package nlme and dummies for occasion.
>> # This model exactly reproduces the observed correlations between
>> occasions.
>> unstruc.gls1 <- gls(test ~ 1+ occ2 + occ3,
>>                             method="REML", data=mydata,
>>                             correlation=corSymm(form = ~ 1 |person),
>>                             weights = varIdent(form = ~1|occasion))
>> summary(unstruc.gls1)
>>
>>
>> # Unstructured model using factor1 for occasion instead of dummies.
>> # The results are exactly the same as those above, as should be.
>> mydata$factor1 <- as.factor(mydata$occasion)
>> unstruc.gls2 <- gls(test ~ factor1,
>>                      method="REML", data=mydata,
>>                      correlation=corSymm(form = ~ 1|person),
>>                      weights = varIdent(form = ~1|factor1))
>> summary(unstruc.gls2)
>>
>>
>> # Unstructured model using lmer and dummies for occasion: does not
>> converge.
>> unstruc.lmer <- lmer(test ~ 1+ occ2 + occ3 + (1+occ2+occ3|person),
>>                       data=mydata, REML=TRUE)
>> summary(unstruc.lmer)
>>
>>
>> # Unstructured model using lmer and factor1 for occasion: does not
>> converge.
>> unstruc.lmer <- lmer(test ~ 1+ factor1 + (1+factor1|person),
>>                       data=mydata, REML=TRUE)
>> summary(unstruc.lmer)
>>
>>
>> # Unstructured model using lmer and factor1 for occasion, no intercept
>> specified: does not converge.
>> unstruc.lmer <- lmer(test ~ factor1 + (factor1|person),
>>                       data=mydata, REML=TRUE)
>> summary(unstruc.lmer)
>>
>>
>>
>> On 21/03/2018 13:07, Maarten Jung wrote:
>> > Dear Ben,
>> >
>> > I am a bit puzzled.
>> >
>> > Do you mean that
>> >
>> > m1 <- gls(value ~ factor1, data, correlation = corSymm(form = ~
>> > 1|participant), weights = varIdent(form = ~ 1|factor))
>> >
>> > would be equivalent to
>> >
>> > m2 <- lmer(value ~ factor1 + (factor1|participant), data)
>> >
>> > and one should use gls() because it allows for the same covariance
>> > structures as /REPEATED does?
>> >
>>
>>
>> the two specifications are not equivalent in the sense that lmer also
>> tries to estimate residual variance. However, with the given lmer model
>> specification, the random factor1 effects capture all variance there is
>> and no residual variance remains.
>>
>>
>> > And, if so, why should m2 cause an identification problem and m1 doesn't?
>> >
>> > Regards,
>> > Maarten
>> >
>> Regards, Ben.
>>
>>
>>
>> >
>> > On Wed, Mar 21, 2018 at 12:03 PM, Ben Pelzer <b.pelzer at maw.ru.nl
>> > <mailto:b.pelzer at maw.ru.nl>> wrote:
>> >
>> >     Dear all,
>> >
>> >     As far as I know, the specification for lmer using
>> >
>> >          value ~ factor1 + (factor1 | participant)
>> >
>> >     causes an identification problem, because the residual variance is
>> not
>> >     excluded from the estimations. It would indeed work (e.g. in MlWin
>> >     this
>> >     can be done) if we could constrain that residual variance to zero.
>> >     There
>> >     have been some mails in this list about whether or not constraining
>> >     residual variance to zero is possible in lmer, but I believe this
>> >     is not
>> >     possible. Would be nice if we could do this in lmer!
>> >
>> >     Best regards, Ben.
>> >
>> >
>> >     On 20-3-2018 18:34, Douglas Bates wrote:
>> >     > Kind of looks like SPSS went for bug-for-bug compatibility with
>> >     SAS on
>> >     > this one.  In SAS PROC MIXED, "REPEATED" and "RANDOM" are two
>> >     ways of
>> >     > specifying the random effects variance structure but they often
>> boil
>> >     > down to the same model.
>> >     >
>> >     > I believe the model can be specified in lme4 as
>> >     >
>> >     >     value ~ factor1 + (factor1 | participant)
>> >     >
>> >     > This is what the mis-named* "UNSTRUCTURED" covariance type means
>> >     >
>> >     > * Old-guy, get off my lawn rant about terminology *
>> >     > As a recovering mathematician I find the name "unstructured" being
>> >     > used to denote a positive-definite symmetric matrix to be, well,
>> >     > inaccurate.
>> >     >
>> >     > On Tue, Mar 20, 2018 at 12:19 PM Mollie Brooks
>> >     > <mollieebrooks at gmail.com <mailto:mollieebrooks at gmail.com>
>> >     <mailto:mollieebrooks at gmail.com <mailto:mollieebrooks at gmail.com>>>
>> >     wrote:
>> >     >
>> >     >     I don?t know anything about spss, but if you basically want
>> lme4
>> >     >     with more correlation structures, you could look at the
>> >     structures
>> >     >     available with glmmTMB.
>> >     >
>> >     https://cran.r-project.org/web/packages/glmmTMB/
>> vignettes/covstruct.html
>> >     <https://cran.r-project.org/web/packages/glmmTMB/
>> vignettes/covstruct.html>
>> >     >
>> >     >     cheers,
>> >     >     Mollie
>> >     >
>> >     >     > On 20Mar 2018, at 18:11, Ben Pelzer <b.pelzer at maw.ru.nl
>> >     <mailto:b.pelzer at maw.ru.nl>
>> >     >     <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>>>
>> wrote:
>> >     >     >
>> >     >     > Hi Maarten,
>> >     >     >
>> >     >     > You are right: you need nlme and NOT lme4 to specify
>> >     particular
>> >     >     > correlation structures. Also, in nlme you would need gls
>> >     to make it
>> >     >     > similar to mixed in spss. The repeated command in spss
>> >     gives the
>> >     >     same
>> >     >     > results as gls does for any of the covariance structures.
>> >     >     >
>> >     >     > Regards, Ben.
>> >     >     >
>> >     >     >
>> >     >     > On 20/03/2018 17:30, Maarten Jung wrote:
>> >     >     >> Dear Ben, dear Phillip,
>> >     >     >>
>> >     >     >> comparing [1] with [2] I think the /REPEATED command
>> >     specifies
>> >     >     >> the error (co)variance structure of the model. Would you
>> >     agree
>> >     >     with that?
>> >     >     >> If so, AFAIK this is not possible with lmer and thus the
>> >     answer on
>> >     >     >> Stack Overflow [3] would be wrong.
>> >     >     >>
>> >     >     >> [1]
>> >     >     >>
>> >     >
>> >     https://stats.idre.ucla.edu/r/examples/alda/r-applied-
>> longitudinal-data-analysis-ch-7/
>> >     <https://stats.idre.ucla.edu/r/examples/alda/r-applied-
>> longitudinal-data-analysis-ch-7/>
>> >     >     >> [2]
>> >     >     >>
>> >     >
>> >     https://stats.idre.ucla.edu/spss/examples/alda/chapter7/
>> applied-longitudinal-data-analysis-modeling-change-and-
>> event-occurrenceby-judith-d-singer-and-john-b-willett-
>> chapter-7-examining-the-multilevel-model-s-erro/
>> >     <https://stats.idre.ucla.edu/spss/examples/alda/chapter7/
>> applied-longitudinal-data-analysis-modeling-change-and-
>> event-occurrenceby-judith-d-singer-and-john-b-willett-
>> chapter-7-examining-the-multilevel-model-s-erro/>
>> >     >     >> [3]
>> >     >     >>
>> >     >
>> >     https://stackoverflow.com/questions/48518514/what-is-
>> the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
>> >     <https://stackoverflow.com/questions/48518514/what-is-
>> the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc>
>> >     >     >>
>> >     >     >> Regards,
>> >     >     >> Maarten
>> >     >     >>
>> >     >     >> On Tue, Mar 20, 2018 at 2:10 PM, Ben Pelzer
>> >     <b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>
>> >     >     <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>>
>> >     >     >> <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>
>> >     <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>>
>> >     >     <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>
>> >     <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>>>>> wrote:
>> >     >     >>
>> >     >     >>    Dear Maarten,
>> >     >     >>
>> >     >     >>    Take a look at
>> >     >     >>
>> >     >     >>
>> >     >
>> >     https://stats.idre.ucla.edu/r/examples/alda/r-applied-
>> longitudinal-data-analysis-ch-7/
>> >     <https://stats.idre.ucla.edu/r/examples/alda/r-applied-
>> longitudinal-data-analysis-ch-7/>
>> >     >
>> >      <https://stats.idre.ucla.edu/r/examples/alda/r-applied-
>> longitudinal-data-analysis-ch-7/
>> >     <https://stats.idre.ucla.edu/r/examples/alda/r-applied-
>> longitudinal-data-analysis-ch-7/>>
>> >     >     >>
>> >     >
>> >      <https://stats.idre.ucla.edu/r/examples/alda/r-applied-
>> longitudinal-data-analysis-ch-7/
>> >     <https://stats.idre.ucla.edu/r/examples/alda/r-applied-
>> longitudinal-data-analysis-ch-7/>
>> >     >
>> >      <https://stats.idre.ucla.edu/r/examples/alda/r-applied-
>> longitudinal-data-analysis-ch-7/
>> >     <https://stats.idre.ucla.edu/r/examples/alda/r-applied-
>> longitudinal-data-analysis-ch-7/>>>
>> >     >     >>
>> >     >     >>    which shows you a number of covariance structures, among
>> >     >     which is
>> >     >     >>    the unstructured matrix, for repeated measures in R
>> >     with lme. It
>> >     >     >>    refers to chapter 7 of Singer and Willett where they
>> >     discuss all
>> >     >     >>    these different structures and how to choose among them.
>> >     >     Regards,
>> >     >     >>
>> >     >     >>    Ben.
>> >     >     >>
>> >     >     >>    On 20-3-2018 9:00, Maarten Jung wrote:
>> >     >     >>
>> >     >     >>        Dear list,
>> >     >     >>        I came across a SPSS syntax like this
>> >     >     >>
>> >     >     >>        MIXED value BY factor1
>> >     >     >>             /CRITERIA=CIN(95) MXITER(100) MXSTEP(10)
>> >     SCORING(1)
>> >     >     >>        SINGULAR(0.000000000001)
>> >     >     >>             HCONVERGE(0, ABSOLUTE) LCONVERGE(0, ABSOLUTE)
>> >     >     >>        PCONVERGE(0.000001,
>> >     >     >>             ABSOLUTE)
>> >     >     >>             /FIXED=factor1 | SSTYPE(3)
>> >     >     >>             /METHOD=REML
>> >     >     >>             /REPEATED=factor1 | SUBJECT(participant)
>> >     COVTYPE(UN).
>> >     >     >>
>> >     >     >>        and struggle to find an equivalent lmer/nlme (or R in
>> >     >     general)
>> >     >     >>        formulation
>> >     >     >>        for this kind of models.
>> >     >     >>        Does anybody know how to convert the REPEATED
>> >     subcommand
>> >     >     into
>> >     >     >>        R code?
>> >     >     >>
>> >     >     >>        Please note that I asked the question on Stack
>> >     Overflow
>> >     >     about
>> >     >     >>        two month ago:
>> >     >     >>
>> >     >
>> >     https://stackoverflow.com/questions/48518514/what-is-
>> the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
>> >     <https://stackoverflow.com/questions/48518514/what-is-
>> the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc>
>> >     >
>> >      <https://stackoverflow.com/questions/48518514/what-is-
>> the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
>> >     <https://stackoverflow.com/questions/48518514/what-is-
>> the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc>>
>> >     >     >>
>> >     >
>> >      <https://stackoverflow.com/questions/48518514/what-is-
>> the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
>> >     <https://stackoverflow.com/questions/48518514/what-is-
>> the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc>
>> >     >
>> >      <https://stackoverflow.com/questions/48518514/what-is-
>> the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
>> >     <https://stackoverflow.com/questions/48518514/what-is-
>> the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc>>>
>> >     >     >>
>> >     >     >>        Best regards,
>> >     >     >>        Maarten
>> >     >     >>
>> >     >     >>                [[alternative HTML version deleted]]
>> >     >     >>
>> >     >     >> _______________________________________________
>> >     >     >> R-sig-mixed-models at r-project.org
>> >     <mailto:R-sig-mixed-models at r-project.org>
>> >     >     <mailto:R-sig-mixed-models at r-project.org
>> >     <mailto:R-sig-mixed-models at r-project.org>>
>> >     >     <mailto:R-sig-mixed-models at r-project.org
>> >     <mailto:R-sig-mixed-models at r-project.org>
>> >     >     <mailto:R-sig-mixed-models at r-project.org
>> >     <mailto:R-sig-mixed-models at r-project.org>>>
>> >     >     >>        <mailto:R-sig-mixed-models at r-project.org
>> >     <mailto:R-sig-mixed-models at r-project.org>
>> >     >     <mailto:R-sig-mixed-models at r-project.org
>> >     <mailto:R-sig-mixed-models at r-project.org>>
>> >     >     <mailto:R-sig-mixed-models at r-project.org
>> >     <mailto:R-sig-mixed-models at r-project.org>
>> >     >     <mailto:R-sig-mixed-models at r-project.org
>> >     <mailto:R-sig-mixed-models at r-project.org>>>> mailing list
>> >     >     >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>> >     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
>> >     >     >>
>> >     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>> >     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>
>> >     >     >>
>> >     >     >>
>> >     >     >>    _______________________________________________
>> >     >     >> R-sig-mixed-models at r-project.org
>> >     <mailto:R-sig-mixed-models at r-project.org>
>> >     >     <mailto:R-sig-mixed-models at r-project.org
>> >     <mailto:R-sig-mixed-models at r-project.org>>
>> >     >     <mailto:R-sig-mixed-models at r-project.org
>> >     <mailto:R-sig-mixed-models at r-project.org>
>> >     >     <mailto:R-sig-mixed-models at r-project.org
>> >     <mailto:R-sig-mixed-models at r-project.org>>>
>> >     >     >>    <mailto:R-sig-mixed-models at r-project.org
>> >     <mailto:R-sig-mixed-models at r-project.org>
>> >     >     <mailto:R-sig-mixed-models at r-project.org
>> >     <mailto:R-sig-mixed-models at r-project.org>>
>> >     >     <mailto:R-sig-mixed-models at r-project.org
>> >     <mailto:R-sig-mixed-models at r-project.org>
>> >     >     <mailto:R-sig-mixed-models at r-project.org
>> >     <mailto:R-sig-mixed-models at r-project.org>>>> mailing list
>> >     >     >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>> >     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
>> >     >     >>
>> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>> >     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>
>> >     >     >>
>> >     >     >>
>> >     >     >
>> >     >     >
>> >     >     >       [[alternative HTML version deleted]]
>> >     >     >
>> >     >     > _______________________________________________
>> >     >     > R-sig-mixed-models at r-project.org
>> >     <mailto:R-sig-mixed-models at r-project.org>
>> >     >     <mailto:R-sig-mixed-models at r-project.org
>> >     <mailto:R-sig-mixed-models at r-project.org>>
>> >     >     <mailto:R-sig-mixed-models at r-project.org
>> >     <mailto:R-sig-mixed-models at r-project.org>
>> >     >     <mailto:R-sig-mixed-models at r-project.org
>> >     <mailto:R-sig-mixed-models at r-project.org>>> mailing list
>> >     >     > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>> >     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
>> >     >
>> >     >             [[alternative HTML version deleted]]
>> >     >
>> >     >     _______________________________________________
>> >     > R-sig-mixed-models at r-project.org
>> >     <mailto:R-sig-mixed-models at r-project.org>
>> >     >     <mailto:R-sig-mixed-models at r-project.org
>> >     <mailto:R-sig-mixed-models at r-project.org>> mailing list
>> >     > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>> >     >
>> >
>> >
>> >             [[alternative HTML version deleted]]
>> >
>> >     _______________________________________________
>> >     R-sig-mixed-models at r-project.org
>> >     <mailto:R-sig-mixed-models at r-project.org> mailing list
>> >     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>> >
>> >
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From jsorkin at som.umaryland.edu  Thu Mar 22 16:02:55 2018
From: jsorkin at som.umaryland.edu (Sorkin, John)
Date: Thu, 22 Mar 2018 15:02:55 +0000
Subject: [R-sig-ME] How does one include a factor in a groupedData object;
 What is the meaning and use of inner and outer
 parameters of groupedData object?
Message-ID: <BN6PR03MB2705B7C23D6AB7C0B9186306E2A90@BN6PR03MB2705.namprd03.prod.outlook.com>

Several questions relating to groupedData:

(1) I am trying to create a groupedData object that can be used to run an analysis that I have been able to urn using lmer. When I include the interaction terms in the groupedData opbject I get an error message stating that + is not meaningful for factors. How do I include factors in my model? See code and error below.

(2) I have read the help file for groupedData multiple times. I am unable to understand the meaning or, or the use for the inner= and outer= parameters in the call to groupedData. Can someone either explain the meaning of these parameters or refer me to a source that give a clear explanation?


> fit0 <- lmer(THmean~INTRVNTN+factor(TimePtID)+INTRVNTN*factor(TimePtID)+(1|PatientID),data=smalldata)
> sdgd <- groupedData(THmean~INTRVNTN+TimePtID+INTRVNTN*TimePtID|PatientID,data=smalldata)
Warning messages:
1: In Ops.factor(INTRVNTN, TimePtID) : ?+? not meaningful for factors
2: In Ops.factor(INTRVNTN, TimePtID) : ?*? not meaningful for factors


Thank you,

John




John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing)


	[[alternative HTML version deleted]]


From jsorkin at som.umaryland.edu  Thu Mar 22 16:07:09 2018
From: jsorkin at som.umaryland.edu (Sorkin, John)
Date: Thu, 22 Mar 2018 15:07:09 +0000
Subject: [R-sig-ME] 
 How does one include a factor in a groupedData object;
 What is the meaning and use of inner and outer
 parameters of groupedData object?
In-Reply-To: <BN6PR03MB2705B7C23D6AB7C0B9186306E2A90@BN6PR03MB2705.namprd03.prod.outlook.com>
References: <BN6PR03MB2705B7C23D6AB7C0B9186306E2A90@BN6PR03MB2705.namprd03.prod.outlook.com>
Message-ID: <BN6PR03MB270573E95B305B3EE1D8EF28E2A90@BN6PR03MB2705.namprd03.prod.outlook.com>

Forgive my resending the message. I believe my last email was sent as HTML. I am sending this again in, what I hope will be plain text format.


Several questions relating to groupedData:

(1) I am trying to create a groupedData object that can be used to run an analysis that I have been able to urn using lmer. When I include the interaction terms in the groupedData opbject I get an error message stating that + is not meaningful for factors. How do I include factors in my model? See code and error below.

(2) I have read the help file for groupedData multiple times. I am unable to understand the meaning or, or the use for the inner= and outer= parameters in the call to groupedData. Can someone either explain the meaning of these parameters or refer me to a source that give a clear explanation?


> fit0 <- lmer(THmean~INTRVNTN+factor(TimePtID)+INTRVNTN*factor(TimePtID)+(1|PatientID),data=smalldata)
> sdgd <- groupedData(THmean~INTRVNTN+TimePtID+INTRVNTN*TimePtID|PatientID,data=smalldata)
Warning messages:
1: In Ops.factor(INTRVNTN, TimePtID) : ?+? not meaningful for factors
2: In Ops.factor(INTRVNTN, TimePtID) : ?*? not meaningful for factors


Thank you,

John


John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing)


________________________________________
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of Sorkin, John <jsorkin at som.umaryland.edu>
Sent: Thursday, March 22, 2018 11:02 AM
To:  R-mixed models mailing list
Subject: [R-sig-ME] How does one include a factor in a groupedData object; What is the meaning and use of inner and outer parameters of groupedData object?

[This sender failed our fraud detection checks and may not be who they appear to be. Learn about spoofing at http://aka.ms/LearnAboutSpoofing]

Several questions relating to groupedData:

(1) I am trying to create a groupedData object that can be used to run an analysis that I have been able to urn using lmer. When I include the interaction terms in the groupedData opbject I get an error message stating that + is not meaningful for factors. How do I include factors in my model? See code and error below.

(2) I have read the help file for groupedData multiple times. I am unable to understand the meaning or, or the use for the inner= and outer= parameters in the call to groupedData. Can someone either explain the meaning of these parameters or refer me to a source that give a clear explanation?


> fit0 <- lmer(THmean~INTRVNTN+factor(TimePtID)+INTRVNTN*factor(TimePtID)+(1|PatientID),data=smalldata)
> sdgd <- groupedData(THmean~INTRVNTN+TimePtID+INTRVNTN*TimePtID|PatientID,data=smalldata)
Warning messages:
1: In Ops.factor(INTRVNTN, TimePtID) : ?+? not meaningful for factors
2: In Ops.factor(INTRVNTN, TimePtID) : ?*? not meaningful for factors


Thank you,

John




John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing)


        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

From Maarten.Jung at mailbox.tu-dresden.de  Thu Mar 22 16:11:21 2018
From: Maarten.Jung at mailbox.tu-dresden.de (Maarten Jung)
Date: Thu, 22 Mar 2018 16:11:21 +0100
Subject: [R-sig-ME] What is the lmer/nlme equivalent of the REPEATED
 subcommand in SPSS's MIXED procedure?
In-Reply-To: <CAG_uk93v1bO48X2nOpuobS7qiqC20MNpJ_T5MKzcgWi89hunzw@mail.gmail.com>
References: <CAHr4Dyep9JCDpNauViVf0MyeH-=p7k0fx3yXbMCL_b-9tLTMEQ@mail.gmail.com>
 <d67d36fb-1019-d878-794e-491c3a409f2a@maw.ru.nl>
 <CAHr4Dydq-SW_8aKUF=MFqnFpx6P36RSguP7gTF-6epZjMFWo3A@mail.gmail.com>
 <5AB140DE.5090705@maw.ru.nl>
 <20732_1521566386_0P5W00D4NG4WVU20_9ECC9EC8-43DB-49AD-97E0-67E5E680460A@gmail.com>
 <CAO7JsnTCenXXrrrfJthUz5aLv2wiubdrzOw30mFY5AdUBmF=ig@mail.gmail.com>
 <42ce404b-af99-82c6-a2f6-482b9963da3a@maw.ru.nl>
 <CAHr4DyeaLCL_RxsjNnYb=L2pxo4r4+mcmsDF382x88UPoVYPaA@mail.gmail.com>
 <5AB2C04C.6010707@maw.ru.nl>
 <CAHr4Dyfhcuh7cNqDCR8ghdHfu1mwhzW9MWMChnOTTsTD_nmo+A@mail.gmail.com>
 <CAG_uk93v1bO48X2nOpuobS7qiqC20MNpJ_T5MKzcgWi89hunzw@mail.gmail.com>
Message-ID: <CAHr4Dyf6H08wyeCMf3_GCzSGKvD484bPd03RQ70ShwTofq7yXg@mail.gmail.com>

Dear Rune,

thanks for making clear what /REPEATED stands for!

Independently, does it make sense to fit a model via

gls(value ~ factor1, data, correlation = corSymm(form = ~ 1|person), weights
= varIdent(form = ~1|factor1))

when there is only one observation per subject-factor1-combination?

Regards,
Maarten

On Thu, Mar 22, 2018 at 11:38 AM, Rune Haubo <rune.haubo at gmail.com> wrote:

> On 22 March 2018 at 10:05, Maarten Jung
> <Maarten.Jung at mailbox.tu-dresden.de> wrote:
> > I think the problem is that there is only one observation per
> > subject-occasion-combination in this example.
> > In this case the random slopes are confounded with the residual variation
> > (see [1]).
>
> I agree.
>
> >
> > One *can* fit this model using lmer(test ~ 1 + occ2 + occ3 + (1 + occ2 +
> > occ3|person), data = mydata,  control = lmerControl(check.nobs.vs.nRE =
> > "ignore")) or
> > lme(test ~ 1 + occ2 + occ3, mydata, random = ~ occ2 + occ3|person).
> >
> > However, I don't know if the gls() fit ist more trustworthy than the
> > lmer/lme fit here.
> > I would be grateful if somebody more experienced in mixed models could
> > comment on this.
>
> If you are trying to replicate a model that is specified with a
> 'repeated' statement (and 'repeated' in SPSS means the same as in SAS)
> then we are talking about specifying a structure in the residual
> variance-covariance matrix (cf.
> https://support.sas.com/documentation/cdl/en/statug/
> 63033/HTML/default/viewer.htm#statug_mixed_sect019.htm).
> If we write the model as y = X beta + Z b + e with b ~ N(0, G) and e ~
> N(0, R), then 'repeated' is specifying the structure in R. This is
> exactly what nlme::gls and nlme::lme do via the weights and
> correlation arguments; you need lme if you have 'true' random effects
> on top of the structure in R.
>
> If we write the marginal distribution of y as y ~ N(X beta, V), with V
> = ZGZ' + R then the structure in V can be obtained by appropriate
> specification of either Z and G or R, or both. This means that in some
> cases there is more than one 'natural' way to specify the same
> marginal model (compound symmetry is the classical example*). Now,
> lmer has the structure of R fixed at sigma^2 I, i.e. a multiple of the
> identity matrix, but with appropriate random-effect specification you
> can sometimes obtain the same (marginal) likelihood as if the
> structure was specified in the R matrix. My advice, is however, that
> if you want to fit a model with a particular structure in R, then
> don't use lmer; you really have to know all details of what is going
> to be sure that it works as intended.
>
> Cheers,
> Rune
>
> *Actually the compound symmetry and random intercept models are _not_
> the same (though often claimed to be) because the parameter spaces
> differ. This means that for some data sets the model fits are the same
> (i.e. same likelihood) and for other data sets the model fits are
> different.
>
> >
> > Best regards,
> > Maarten
> >
> > [1]
> > https://stackoverflow.com/questions/26465215/random-
> slope-for-time-in-subject-not-working-in-lme4?utm_medium=
> organic&utm_source=google_rich_qa&utm_campaign=google_rich_qa
> >
> > On Wed, Mar 21, 2018 at 9:27 PM, Ben Pelzer <b.pelzer at maw.ru.nl> wrote:
> >
> >> Hi Maarten,
> >>
> >> Here is an example which shows the unstructured model with gls and the
> >> not converging model with lmer. In this example, we have three occasions
> >> on which the dependent variable "test" was observed, for each of 20
> >> persons. In total then we have 60 observations, with the "occasion"
> >> variable taking values 1, 2, 3. The data also contain the person id
> >> variable "person" and dummy variables "occ1", "occ2", "occ3" as (0 or 1)
> >> indicators of the occasion.  In the syntax below, a factor variable
> >> "factor1" is created also, to be in line with your question.
> >>
> >> I used two different specifications for the unstructured model with gls,
> >> depending on whether dummies or factor1 was used. For lmer, I used these
> >> three different specifications, none of which converges.
> >>
> >> The lmer syntax was added only to show the problem which lmer has with
> >> estimating an unstructured correlation pattern.
> >>
> >>
> >> #-----------------------------------------------------------
> >> ------------------------------------------------------------
> >> -------------------------------------
> >> mydata <-
> >> read.table(url("https://surfdrive.surf.nl/files/index.
> >> php/s/XfE3mtbFCTUejIz/download"),
> >> header=TRUE)
> >>
> >>
> >> #-------------------  unstructured correlation matrix
> >> -----------------------
> >>
> >>
> >> # Before applying a model, let's first examine the variances and
> >> correlations
> >> # for the three occasions. We have a strong violation of the assumptions
> >> # of homoscedasticity and compound symmetry.
> >> test1 <- mydata[mydata$occasion==1,"test"]
> >> test2 <- mydata[mydata$occasion==2,"test"]
> >> test3 <- mydata[mydata$occasion==3,"test"]
> >> cor(cbind(test1, test2, test3))
> >> var(cbind(test1, test2, test3))
> >>
> >> # Unstructured model using gls from package nlme and dummies for
> occasion.
> >> # This model exactly reproduces the observed correlations between
> >> occasions.
> >> unstruc.gls1 <- gls(test ~ 1+ occ2 + occ3,
> >>                             method="REML", data=mydata,
> >>                             correlation=corSymm(form = ~ 1 |person),
> >>                             weights = varIdent(form = ~1|occasion))
> >> summary(unstruc.gls1)
> >>
> >>
> >> # Unstructured model using factor1 for occasion instead of dummies.
> >> # The results are exactly the same as those above, as should be.
> >> mydata$factor1 <- as.factor(mydata$occasion)
> >> unstruc.gls2 <- gls(test ~ factor1,
> >>                      method="REML", data=mydata,
> >>                      correlation=corSymm(form = ~ 1|person),
> >>                      weights = varIdent(form = ~1|factor1))
> >> summary(unstruc.gls2)
> >>
> >>
> >> # Unstructured model using lmer and dummies for occasion: does not
> >> converge.
> >> unstruc.lmer <- lmer(test ~ 1+ occ2 + occ3 + (1+occ2+occ3|person),
> >>                       data=mydata, REML=TRUE)
> >> summary(unstruc.lmer)
> >>
> >>
> >> # Unstructured model using lmer and factor1 for occasion: does not
> >> converge.
> >> unstruc.lmer <- lmer(test ~ 1+ factor1 + (1+factor1|person),
> >>                       data=mydata, REML=TRUE)
> >> summary(unstruc.lmer)
> >>
> >>
> >> # Unstructured model using lmer and factor1 for occasion, no intercept
> >> specified: does not converge.
> >> unstruc.lmer <- lmer(test ~ factor1 + (factor1|person),
> >>                       data=mydata, REML=TRUE)
> >> summary(unstruc.lmer)
> >>
> >>
> >>
> >> On 21/03/2018 13:07, Maarten Jung wrote:
> >> > Dear Ben,
> >> >
> >> > I am a bit puzzled.
> >> >
> >> > Do you mean that
> >> >
> >> > m1 <- gls(value ~ factor1, data, correlation = corSymm(form = ~
> >> > 1|participant), weights = varIdent(form = ~ 1|factor))
> >> >
> >> > would be equivalent to
> >> >
> >> > m2 <- lmer(value ~ factor1 + (factor1|participant), data)
> >> >
> >> > and one should use gls() because it allows for the same covariance
> >> > structures as /REPEATED does?
> >> >
> >>
> >>
> >> the two specifications are not equivalent in the sense that lmer also
> >> tries to estimate residual variance. However, with the given lmer model
> >> specification, the random factor1 effects capture all variance there is
> >> and no residual variance remains.
> >>
> >>
> >> > And, if so, why should m2 cause an identification problem and m1
> doesn't?
> >> >
> >> > Regards,
> >> > Maarten
> >> >
> >> Regards, Ben.
> >>
> >>
> >>
> >> >
> >> > On Wed, Mar 21, 2018 at 12:03 PM, Ben Pelzer <b.pelzer at maw.ru.nl
> >> > <mailto:b.pelzer at maw.ru.nl>> wrote:
> >> >
> >> >     Dear all,
> >> >
> >> >     As far as I know, the specification for lmer using
> >> >
> >> >          value ~ factor1 + (factor1 | participant)
> >> >
> >> >     causes an identification problem, because the residual variance is
> >> not
> >> >     excluded from the estimations. It would indeed work (e.g. in MlWin
> >> >     this
> >> >     can be done) if we could constrain that residual variance to zero.
> >> >     There
> >> >     have been some mails in this list about whether or not
> constraining
> >> >     residual variance to zero is possible in lmer, but I believe this
> >> >     is not
> >> >     possible. Would be nice if we could do this in lmer!
> >> >
> >> >     Best regards, Ben.
> >> >
> >> >
> >> >     On 20-3-2018 18:34, Douglas Bates wrote:
> >> >     > Kind of looks like SPSS went for bug-for-bug compatibility with
> >> >     SAS on
> >> >     > this one.  In SAS PROC MIXED, "REPEATED" and "RANDOM" are two
> >> >     ways of
> >> >     > specifying the random effects variance structure but they often
> >> boil
> >> >     > down to the same model.
> >> >     >
> >> >     > I believe the model can be specified in lme4 as
> >> >     >
> >> >     >     value ~ factor1 + (factor1 | participant)
> >> >     >
> >> >     > This is what the mis-named* "UNSTRUCTURED" covariance type means
> >> >     >
> >> >     > * Old-guy, get off my lawn rant about terminology *
> >> >     > As a recovering mathematician I find the name "unstructured"
> being
> >> >     > used to denote a positive-definite symmetric matrix to be, well,
> >> >     > inaccurate.
> >> >     >
> >> >     > On Tue, Mar 20, 2018 at 12:19 PM Mollie Brooks
> >> >     > <mollieebrooks at gmail.com <mailto:mollieebrooks at gmail.com>
> >> >     <mailto:mollieebrooks at gmail.com <mailto:mollieebrooks at gmail.com
> >>>
> >> >     wrote:
> >> >     >
> >> >     >     I don?t know anything about spss, but if you basically want
> >> lme4
> >> >     >     with more correlation structures, you could look at the
> >> >     structures
> >> >     >     available with glmmTMB.
> >> >     >
> >> >     https://cran.r-project.org/web/packages/glmmTMB/
> >> vignettes/covstruct.html
> >> >     <https://cran.r-project.org/web/packages/glmmTMB/
> >> vignettes/covstruct.html>
> >> >     >
> >> >     >     cheers,
> >> >     >     Mollie
> >> >     >
> >> >     >     > On 20Mar 2018, at 18:11, Ben Pelzer <b.pelzer at maw.ru.nl
> >> >     <mailto:b.pelzer at maw.ru.nl>
> >> >     >     <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>>>
> >> wrote:
> >> >     >     >
> >> >     >     > Hi Maarten,
> >> >     >     >
> >> >     >     > You are right: you need nlme and NOT lme4 to specify
> >> >     particular
> >> >     >     > correlation structures. Also, in nlme you would need gls
> >> >     to make it
> >> >     >     > similar to mixed in spss. The repeated command in spss
> >> >     gives the
> >> >     >     same
> >> >     >     > results as gls does for any of the covariance structures.
> >> >     >     >
> >> >     >     > Regards, Ben.
> >> >     >     >
> >> >     >     >
> >> >     >     > On 20/03/2018 17:30, Maarten Jung wrote:
> >> >     >     >> Dear Ben, dear Phillip,
> >> >     >     >>
> >> >     >     >> comparing [1] with [2] I think the /REPEATED command
> >> >     specifies
> >> >     >     >> the error (co)variance structure of the model. Would you
> >> >     agree
> >> >     >     with that?
> >> >     >     >> If so, AFAIK this is not possible with lmer and thus the
> >> >     answer on
> >> >     >     >> Stack Overflow [3] would be wrong.
> >> >     >     >>
> >> >     >     >> [1]
> >> >     >     >>
> >> >     >
> >> >     https://stats.idre.ucla.edu/r/examples/alda/r-applied-
> >> longitudinal-data-analysis-ch-7/
> >> >     <https://stats.idre.ucla.edu/r/examples/alda/r-applied-
> >> longitudinal-data-analysis-ch-7/>
> >> >     >     >> [2]
> >> >     >     >>
> >> >     >
> >> >     https://stats.idre.ucla.edu/spss/examples/alda/chapter7/
> >> applied-longitudinal-data-analysis-modeling-change-and-
> >> event-occurrenceby-judith-d-singer-and-john-b-willett-
> >> chapter-7-examining-the-multilevel-model-s-erro/
> >> >     <https://stats.idre.ucla.edu/spss/examples/alda/chapter7/
> >> applied-longitudinal-data-analysis-modeling-change-and-
> >> event-occurrenceby-judith-d-singer-and-john-b-willett-
> >> chapter-7-examining-the-multilevel-model-s-erro/>
> >> >     >     >> [3]
> >> >     >     >>
> >> >     >
> >> >     https://stackoverflow.com/questions/48518514/what-is-
> >> the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
> >> >     <https://stackoverflow.com/questions/48518514/what-is-
> >> the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-
> spsss-mixed-proc>
> >> >     >     >>
> >> >     >     >> Regards,
> >> >     >     >> Maarten
> >> >     >     >>
> >> >     >     >> On Tue, Mar 20, 2018 at 2:10 PM, Ben Pelzer
> >> >     <b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>
> >> >     >     <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>>
> >> >     >     >> <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>
> >> >     <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>>
> >> >     >     <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>
> >> >     <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>>>>> wrote:
> >> >     >     >>
> >> >     >     >>    Dear Maarten,
> >> >     >     >>
> >> >     >     >>    Take a look at
> >> >     >     >>
> >> >     >     >>
> >> >     >
> >> >     https://stats.idre.ucla.edu/r/examples/alda/r-applied-
> >> longitudinal-data-analysis-ch-7/
> >> >     <https://stats.idre.ucla.edu/r/examples/alda/r-applied-
> >> longitudinal-data-analysis-ch-7/>
> >> >     >
> >> >      <https://stats.idre.ucla.edu/r/examples/alda/r-applied-
> >> longitudinal-data-analysis-ch-7/
> >> >     <https://stats.idre.ucla.edu/r/examples/alda/r-applied-
> >> longitudinal-data-analysis-ch-7/>>
> >> >     >     >>
> >> >     >
> >> >      <https://stats.idre.ucla.edu/r/examples/alda/r-applied-
> >> longitudinal-data-analysis-ch-7/
> >> >     <https://stats.idre.ucla.edu/r/examples/alda/r-applied-
> >> longitudinal-data-analysis-ch-7/>
> >> >     >
> >> >      <https://stats.idre.ucla.edu/r/examples/alda/r-applied-
> >> longitudinal-data-analysis-ch-7/
> >> >     <https://stats.idre.ucla.edu/r/examples/alda/r-applied-
> >> longitudinal-data-analysis-ch-7/>>>
> >> >     >     >>
> >> >     >     >>    which shows you a number of covariance structures,
> among
> >> >     >     which is
> >> >     >     >>    the unstructured matrix, for repeated measures in R
> >> >     with lme. It
> >> >     >     >>    refers to chapter 7 of Singer and Willett where they
> >> >     discuss all
> >> >     >     >>    these different structures and how to choose among
> them.
> >> >     >     Regards,
> >> >     >     >>
> >> >     >     >>    Ben.
> >> >     >     >>
> >> >     >     >>    On 20-3-2018 9:00, Maarten Jung wrote:
> >> >     >     >>
> >> >     >     >>        Dear list,
> >> >     >     >>        I came across a SPSS syntax like this
> >> >     >     >>
> >> >     >     >>        MIXED value BY factor1
> >> >     >     >>             /CRITERIA=CIN(95) MXITER(100) MXSTEP(10)
> >> >     SCORING(1)
> >> >     >     >>        SINGULAR(0.000000000001)
> >> >     >     >>             HCONVERGE(0, ABSOLUTE) LCONVERGE(0, ABSOLUTE)
> >> >     >     >>        PCONVERGE(0.000001,
> >> >     >     >>             ABSOLUTE)
> >> >     >     >>             /FIXED=factor1 | SSTYPE(3)
> >> >     >     >>             /METHOD=REML
> >> >     >     >>             /REPEATED=factor1 | SUBJECT(participant)
> >> >     COVTYPE(UN).
> >> >     >     >>
> >> >     >     >>        and struggle to find an equivalent lmer/nlme (or
> R in
> >> >     >     general)
> >> >     >     >>        formulation
> >> >     >     >>        for this kind of models.
> >> >     >     >>        Does anybody know how to convert the REPEATED
> >> >     subcommand
> >> >     >     into
> >> >     >     >>        R code?
> >> >     >     >>
> >> >     >     >>        Please note that I asked the question on Stack
> >> >     Overflow
> >> >     >     about
> >> >     >     >>        two month ago:
> >> >     >     >>
> >> >     >
> >> >     https://stackoverflow.com/questions/48518514/what-is-
> >> the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
> >> >     <https://stackoverflow.com/questions/48518514/what-is-
> >> the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-
> spsss-mixed-proc>
> >> >     >
> >> >      <https://stackoverflow.com/questions/48518514/what-is-
> >> the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
> >> >     <https://stackoverflow.com/questions/48518514/what-is-
> >> the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-
> spsss-mixed-proc>>
> >> >     >     >>
> >> >     >
> >> >      <https://stackoverflow.com/questions/48518514/what-is-
> >> the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
> >> >     <https://stackoverflow.com/questions/48518514/what-is-
> >> the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-
> spsss-mixed-proc>
> >> >     >
> >> >      <https://stackoverflow.com/questions/48518514/what-is-
> >> the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
> >> >     <https://stackoverflow.com/questions/48518514/what-is-
> >> the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-
> spsss-mixed-proc>>>
> >> >     >     >>
> >> >     >     >>        Best regards,
> >> >     >     >>        Maarten
> >> >     >     >>
> >> >     >     >>                [[alternative HTML version deleted]]
> >> >     >     >>
> >> >     >     >> _______________________________________________
> >> >     >     >> R-sig-mixed-models at r-project.org
> >> >     <mailto:R-sig-mixed-models at r-project.org>
> >> >     >     <mailto:R-sig-mixed-models at r-project.org
> >> >     <mailto:R-sig-mixed-models at r-project.org>>
> >> >     >     <mailto:R-sig-mixed-models at r-project.org
> >> >     <mailto:R-sig-mixed-models at r-project.org>
> >> >     >     <mailto:R-sig-mixed-models at r-project.org
> >> >     <mailto:R-sig-mixed-models at r-project.org>>>
> >> >     >     >>        <mailto:R-sig-mixed-models at r-project.org
> >> >     <mailto:R-sig-mixed-models at r-project.org>
> >> >     >     <mailto:R-sig-mixed-models at r-project.org
> >> >     <mailto:R-sig-mixed-models at r-project.org>>
> >> >     >     <mailto:R-sig-mixed-models at r-project.org
> >> >     <mailto:R-sig-mixed-models at r-project.org>
> >> >     >     <mailto:R-sig-mixed-models at r-project.org
> >> >     <mailto:R-sig-mixed-models at r-project.org>>>> mailing list
> >> >     >     >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >> >     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
> >> >     >     >>
> >> >     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >> >     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>
> >> >     >     >>
> >> >     >     >>
> >> >     >     >>    _______________________________________________
> >> >     >     >> R-sig-mixed-models at r-project.org
> >> >     <mailto:R-sig-mixed-models at r-project.org>
> >> >     >     <mailto:R-sig-mixed-models at r-project.org
> >> >     <mailto:R-sig-mixed-models at r-project.org>>
> >> >     >     <mailto:R-sig-mixed-models at r-project.org
> >> >     <mailto:R-sig-mixed-models at r-project.org>
> >> >     >     <mailto:R-sig-mixed-models at r-project.org
> >> >     <mailto:R-sig-mixed-models at r-project.org>>>
> >> >     >     >>    <mailto:R-sig-mixed-models at r-project.org
> >> >     <mailto:R-sig-mixed-models at r-project.org>
> >> >     >     <mailto:R-sig-mixed-models at r-project.org
> >> >     <mailto:R-sig-mixed-models at r-project.org>>
> >> >     >     <mailto:R-sig-mixed-models at r-project.org
> >> >     <mailto:R-sig-mixed-models at r-project.org>
> >> >     >     <mailto:R-sig-mixed-models at r-project.org
> >> >     <mailto:R-sig-mixed-models at r-project.org>>>> mailing list
> >> >     >     >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >> >     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
> >> >     >     >>
> >> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >> >     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>
> >> >     >     >>
> >> >     >     >>
> >> >     >     >
> >> >     >     >
> >> >     >     >       [[alternative HTML version deleted]]
> >> >     >     >
> >> >     >     > _______________________________________________
> >> >     >     > R-sig-mixed-models at r-project.org
> >> >     <mailto:R-sig-mixed-models at r-project.org>
> >> >     >     <mailto:R-sig-mixed-models at r-project.org
> >> >     <mailto:R-sig-mixed-models at r-project.org>>
> >> >     >     <mailto:R-sig-mixed-models at r-project.org
> >> >     <mailto:R-sig-mixed-models at r-project.org>
> >> >     >     <mailto:R-sig-mixed-models at r-project.org
> >> >     <mailto:R-sig-mixed-models at r-project.org>>> mailing list
> >> >     >     > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >> >     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
> >> >     >
> >> >     >             [[alternative HTML version deleted]]
> >> >     >
> >> >     >     _______________________________________________
> >> >     > R-sig-mixed-models at r-project.org
> >> >     <mailto:R-sig-mixed-models at r-project.org>
> >> >     >     <mailto:R-sig-mixed-models at r-project.org
> >> >     <mailto:R-sig-mixed-models at r-project.org>> mailing list
> >> >     > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >> >     >
> >> >
> >> >
> >> >             [[alternative HTML version deleted]]
> >> >
> >> >     _______________________________________________
> >> >     R-sig-mixed-models at r-project.org
> >> >     <mailto:R-sig-mixed-models at r-project.org> mailing list
> >> >     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >> >
> >> >
> >>
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From rune.haubo at gmail.com  Thu Mar 22 17:54:42 2018
From: rune.haubo at gmail.com (Rune Haubo)
Date: Thu, 22 Mar 2018 17:54:42 +0100
Subject: [R-sig-ME] What is the lmer/nlme equivalent of the REPEATED
 subcommand in SPSS's MIXED procedure?
In-Reply-To: <CAHr4Dyf6H08wyeCMf3_GCzSGKvD484bPd03RQ70ShwTofq7yXg@mail.gmail.com>
References: <CAHr4Dyep9JCDpNauViVf0MyeH-=p7k0fx3yXbMCL_b-9tLTMEQ@mail.gmail.com>
 <d67d36fb-1019-d878-794e-491c3a409f2a@maw.ru.nl>
 <CAHr4Dydq-SW_8aKUF=MFqnFpx6P36RSguP7gTF-6epZjMFWo3A@mail.gmail.com>
 <5AB140DE.5090705@maw.ru.nl>
 <20732_1521566386_0P5W00D4NG4WVU20_9ECC9EC8-43DB-49AD-97E0-67E5E680460A@gmail.com>
 <CAO7JsnTCenXXrrrfJthUz5aLv2wiubdrzOw30mFY5AdUBmF=ig@mail.gmail.com>
 <42ce404b-af99-82c6-a2f6-482b9963da3a@maw.ru.nl>
 <CAHr4DyeaLCL_RxsjNnYb=L2pxo4r4+mcmsDF382x88UPoVYPaA@mail.gmail.com>
 <5AB2C04C.6010707@maw.ru.nl>
 <CAHr4Dyfhcuh7cNqDCR8ghdHfu1mwhzW9MWMChnOTTsTD_nmo+A@mail.gmail.com>
 <CAG_uk93v1bO48X2nOpuobS7qiqC20MNpJ_T5MKzcgWi89hunzw@mail.gmail.com>
 <CAHr4Dyf6H08wyeCMf3_GCzSGKvD484bPd03RQ70ShwTofq7yXg@mail.gmail.com>
Message-ID: <CAG_uk90fyg_W9hXho1qQRaqCoYbN_oT8bqriXGuJq6khjFm=qQ@mail.gmail.com>

On 22 March 2018 at 16:11, Maarten Jung
<Maarten.Jung at mailbox.tu-dresden.de> wrote:
> Dear Rune,
>
> thanks for making clear what /REPEATED stands for!
>
> Independently, does it make sense to fit a model via
>
> gls(value ~ factor1, data, correlation = corSymm(form = ~ 1|person), weights
> = varIdent(form = ~1|factor1))
>
> when there is only one observation per subject-factor1-combination?

Yes, I'd say so. And Ben Pelzer's email from yesterday has a data+code
example of exactly that if I'm not mistaken.

If factor1 is 'time' this model is quite similar to the famous MMRM*
often used in pharma to model clinical trials (for purposes of
handling/'imputation' of missing values) in which measurements are
made on subjects at, say, a handful of timepoints over the trial
period. This model essentially specifies that each subject-profile
follows a multivariate normal distribution with the so-called
'unstructured' variance-covariance matrix with dimensions equal to the
number of timepoints, further, all the subject profiles are
independent. Differences between treatment groups are then estimated
at each timepoint and usually the differences at the last timepoint
are of primary interest. Long story short: Yes it makes sense and it's
done all the time in the pharmaceutical world.

Cheers
Rune

*The MMRM is a very specific model not just any 'mixed model for
repeated measurements', in fact, it is not really a mixed model (the
lack of random effects give it away...).

>
> Regards,
> Maarten
>
> On Thu, Mar 22, 2018 at 11:38 AM, Rune Haubo <rune.haubo at gmail.com> wrote:
>>
>> On 22 March 2018 at 10:05, Maarten Jung
>> <Maarten.Jung at mailbox.tu-dresden.de> wrote:
>> > I think the problem is that there is only one observation per
>> > subject-occasion-combination in this example.
>> > In this case the random slopes are confounded with the residual
>> > variation
>> > (see [1]).
>>
>> I agree.
>>
>> >
>> > One *can* fit this model using lmer(test ~ 1 + occ2 + occ3 + (1 + occ2 +
>> > occ3|person), data = mydata,  control = lmerControl(check.nobs.vs.nRE =
>> > "ignore")) or
>> > lme(test ~ 1 + occ2 + occ3, mydata, random = ~ occ2 + occ3|person).
>> >
>> > However, I don't know if the gls() fit ist more trustworthy than the
>> > lmer/lme fit here.
>> > I would be grateful if somebody more experienced in mixed models could
>> > comment on this.
>>
>> If you are trying to replicate a model that is specified with a
>> 'repeated' statement (and 'repeated' in SPSS means the same as in SAS)
>> then we are talking about specifying a structure in the residual
>> variance-covariance matrix (cf.
>>
>> https://support.sas.com/documentation/cdl/en/statug/63033/HTML/default/viewer.htm#statug_mixed_sect019.htm).
>> If we write the model as y = X beta + Z b + e with b ~ N(0, G) and e ~
>> N(0, R), then 'repeated' is specifying the structure in R. This is
>> exactly what nlme::gls and nlme::lme do via the weights and
>> correlation arguments; you need lme if you have 'true' random effects
>> on top of the structure in R.
>>
>> If we write the marginal distribution of y as y ~ N(X beta, V), with V
>> = ZGZ' + R then the structure in V can be obtained by appropriate
>> specification of either Z and G or R, or both. This means that in some
>> cases there is more than one 'natural' way to specify the same
>> marginal model (compound symmetry is the classical example*). Now,
>> lmer has the structure of R fixed at sigma^2 I, i.e. a multiple of the
>> identity matrix, but with appropriate random-effect specification you
>> can sometimes obtain the same (marginal) likelihood as if the
>> structure was specified in the R matrix. My advice, is however, that
>> if you want to fit a model with a particular structure in R, then
>> don't use lmer; you really have to know all details of what is going
>> to be sure that it works as intended.
>>
>> Cheers,
>> Rune
>>
>> *Actually the compound symmetry and random intercept models are _not_
>> the same (though often claimed to be) because the parameter spaces
>> differ. This means that for some data sets the model fits are the same
>> (i.e. same likelihood) and for other data sets the model fits are
>> different.
>>
>> >
>> > Best regards,
>> > Maarten
>> >
>> > [1]
>> >
>> > https://stackoverflow.com/questions/26465215/random-slope-for-time-in-subject-not-working-in-lme4?utm_medium=organic&utm_source=google_rich_qa&utm_campaign=google_rich_qa
>> >
>> > On Wed, Mar 21, 2018 at 9:27 PM, Ben Pelzer <b.pelzer at maw.ru.nl> wrote:
>> >
>> >> Hi Maarten,
>> >>
>> >> Here is an example which shows the unstructured model with gls and the
>> >> not converging model with lmer. In this example, we have three
>> >> occasions
>> >> on which the dependent variable "test" was observed, for each of 20
>> >> persons. In total then we have 60 observations, with the "occasion"
>> >> variable taking values 1, 2, 3. The data also contain the person id
>> >> variable "person" and dummy variables "occ1", "occ2", "occ3" as (0 or
>> >> 1)
>> >> indicators of the occasion.  In the syntax below, a factor variable
>> >> "factor1" is created also, to be in line with your question.
>> >>
>> >> I used two different specifications for the unstructured model with
>> >> gls,
>> >> depending on whether dummies or factor1 was used. For lmer, I used
>> >> these
>> >> three different specifications, none of which converges.
>> >>
>> >> The lmer syntax was added only to show the problem which lmer has with
>> >> estimating an unstructured correlation pattern.
>> >>
>> >>
>> >> #-----------------------------------------------------------
>> >> ------------------------------------------------------------
>> >> -------------------------------------
>> >> mydata <-
>> >> read.table(url("https://surfdrive.surf.nl/files/index.
>> >> php/s/XfE3mtbFCTUejIz/download"),
>> >> header=TRUE)
>> >>
>> >>
>> >> #-------------------  unstructured correlation matrix
>> >> -----------------------
>> >>
>> >>
>> >> # Before applying a model, let's first examine the variances and
>> >> correlations
>> >> # for the three occasions. We have a strong violation of the
>> >> assumptions
>> >> # of homoscedasticity and compound symmetry.
>> >> test1 <- mydata[mydata$occasion==1,"test"]
>> >> test2 <- mydata[mydata$occasion==2,"test"]
>> >> test3 <- mydata[mydata$occasion==3,"test"]
>> >> cor(cbind(test1, test2, test3))
>> >> var(cbind(test1, test2, test3))
>> >>
>> >> # Unstructured model using gls from package nlme and dummies for
>> >> occasion.
>> >> # This model exactly reproduces the observed correlations between
>> >> occasions.
>> >> unstruc.gls1 <- gls(test ~ 1+ occ2 + occ3,
>> >>                             method="REML", data=mydata,
>> >>                             correlation=corSymm(form = ~ 1 |person),
>> >>                             weights = varIdent(form = ~1|occasion))
>> >> summary(unstruc.gls1)
>> >>
>> >>
>> >> # Unstructured model using factor1 for occasion instead of dummies.
>> >> # The results are exactly the same as those above, as should be.
>> >> mydata$factor1 <- as.factor(mydata$occasion)
>> >> unstruc.gls2 <- gls(test ~ factor1,
>> >>                      method="REML", data=mydata,
>> >>                      correlation=corSymm(form = ~ 1|person),
>> >>                      weights = varIdent(form = ~1|factor1))
>> >> summary(unstruc.gls2)
>> >>
>> >>
>> >> # Unstructured model using lmer and dummies for occasion: does not
>> >> converge.
>> >> unstruc.lmer <- lmer(test ~ 1+ occ2 + occ3 + (1+occ2+occ3|person),
>> >>                       data=mydata, REML=TRUE)
>> >> summary(unstruc.lmer)
>> >>
>> >>
>> >> # Unstructured model using lmer and factor1 for occasion: does not
>> >> converge.
>> >> unstruc.lmer <- lmer(test ~ 1+ factor1 + (1+factor1|person),
>> >>                       data=mydata, REML=TRUE)
>> >> summary(unstruc.lmer)
>> >>
>> >>
>> >> # Unstructured model using lmer and factor1 for occasion, no intercept
>> >> specified: does not converge.
>> >> unstruc.lmer <- lmer(test ~ factor1 + (factor1|person),
>> >>                       data=mydata, REML=TRUE)
>> >> summary(unstruc.lmer)
>> >>
>> >>
>> >>
>> >> On 21/03/2018 13:07, Maarten Jung wrote:
>> >> > Dear Ben,
>> >> >
>> >> > I am a bit puzzled.
>> >> >
>> >> > Do you mean that
>> >> >
>> >> > m1 <- gls(value ~ factor1, data, correlation = corSymm(form = ~
>> >> > 1|participant), weights = varIdent(form = ~ 1|factor))
>> >> >
>> >> > would be equivalent to
>> >> >
>> >> > m2 <- lmer(value ~ factor1 + (factor1|participant), data)
>> >> >
>> >> > and one should use gls() because it allows for the same covariance
>> >> > structures as /REPEATED does?
>> >> >
>> >>
>> >>
>> >> the two specifications are not equivalent in the sense that lmer also
>> >> tries to estimate residual variance. However, with the given lmer model
>> >> specification, the random factor1 effects capture all variance there is
>> >> and no residual variance remains.
>> >>
>> >>
>> >> > And, if so, why should m2 cause an identification problem and m1
>> >> > doesn't?
>> >> >
>> >> > Regards,
>> >> > Maarten
>> >> >
>> >> Regards, Ben.
>> >>
>> >>
>> >>
>> >> >
>> >> > On Wed, Mar 21, 2018 at 12:03 PM, Ben Pelzer <b.pelzer at maw.ru.nl
>> >> > <mailto:b.pelzer at maw.ru.nl>> wrote:
>> >> >
>> >> >     Dear all,
>> >> >
>> >> >     As far as I know, the specification for lmer using
>> >> >
>> >> >          value ~ factor1 + (factor1 | participant)
>> >> >
>> >> >     causes an identification problem, because the residual variance
>> >> > is
>> >> not
>> >> >     excluded from the estimations. It would indeed work (e.g. in
>> >> > MlWin
>> >> >     this
>> >> >     can be done) if we could constrain that residual variance to
>> >> > zero.
>> >> >     There
>> >> >     have been some mails in this list about whether or not
>> >> > constraining
>> >> >     residual variance to zero is possible in lmer, but I believe this
>> >> >     is not
>> >> >     possible. Would be nice if we could do this in lmer!
>> >> >
>> >> >     Best regards, Ben.
>> >> >
>> >> >
>> >> >     On 20-3-2018 18:34, Douglas Bates wrote:
>> >> >     > Kind of looks like SPSS went for bug-for-bug compatibility with
>> >> >     SAS on
>> >> >     > this one.  In SAS PROC MIXED, "REPEATED" and "RANDOM" are two
>> >> >     ways of
>> >> >     > specifying the random effects variance structure but they often
>> >> boil
>> >> >     > down to the same model.
>> >> >     >
>> >> >     > I believe the model can be specified in lme4 as
>> >> >     >
>> >> >     >     value ~ factor1 + (factor1 | participant)
>> >> >     >
>> >> >     > This is what the mis-named* "UNSTRUCTURED" covariance type
>> >> > means
>> >> >     >
>> >> >     > * Old-guy, get off my lawn rant about terminology *
>> >> >     > As a recovering mathematician I find the name "unstructured"
>> >> > being
>> >> >     > used to denote a positive-definite symmetric matrix to be,
>> >> > well,
>> >> >     > inaccurate.
>> >> >     >
>> >> >     > On Tue, Mar 20, 2018 at 12:19 PM Mollie Brooks
>> >> >     > <mollieebrooks at gmail.com <mailto:mollieebrooks at gmail.com>
>> >> >     <mailto:mollieebrooks at gmail.com
>> >> > <mailto:mollieebrooks at gmail.com>>>
>> >> >     wrote:
>> >> >     >
>> >> >     >     I don?t know anything about spss, but if you basically want
>> >> lme4
>> >> >     >     with more correlation structures, you could look at the
>> >> >     structures
>> >> >     >     available with glmmTMB.
>> >> >     >
>> >> >     https://cran.r-project.org/web/packages/glmmTMB/
>> >> vignettes/covstruct.html
>> >> >     <https://cran.r-project.org/web/packages/glmmTMB/
>> >> vignettes/covstruct.html>
>> >> >     >
>> >> >     >     cheers,
>> >> >     >     Mollie
>> >> >     >
>> >> >     >     > On 20Mar 2018, at 18:11, Ben Pelzer <b.pelzer at maw.ru.nl
>> >> >     <mailto:b.pelzer at maw.ru.nl>
>> >> >     >     <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>>>
>> >> wrote:
>> >> >     >     >
>> >> >     >     > Hi Maarten,
>> >> >     >     >
>> >> >     >     > You are right: you need nlme and NOT lme4 to specify
>> >> >     particular
>> >> >     >     > correlation structures. Also, in nlme you would need gls
>> >> >     to make it
>> >> >     >     > similar to mixed in spss. The repeated command in spss
>> >> >     gives the
>> >> >     >     same
>> >> >     >     > results as gls does for any of the covariance structures.
>> >> >     >     >
>> >> >     >     > Regards, Ben.
>> >> >     >     >
>> >> >     >     >
>> >> >     >     > On 20/03/2018 17:30, Maarten Jung wrote:
>> >> >     >     >> Dear Ben, dear Phillip,
>> >> >     >     >>
>> >> >     >     >> comparing [1] with [2] I think the /REPEATED command
>> >> >     specifies
>> >> >     >     >> the error (co)variance structure of the model. Would you
>> >> >     agree
>> >> >     >     with that?
>> >> >     >     >> If so, AFAIK this is not possible with lmer and thus the
>> >> >     answer on
>> >> >     >     >> Stack Overflow [3] would be wrong.
>> >> >     >     >>
>> >> >     >     >> [1]
>> >> >     >     >>
>> >> >     >
>> >> >     https://stats.idre.ucla.edu/r/examples/alda/r-applied-
>> >> longitudinal-data-analysis-ch-7/
>> >> >     <https://stats.idre.ucla.edu/r/examples/alda/r-applied-
>> >> longitudinal-data-analysis-ch-7/>
>> >> >     >     >> [2]
>> >> >     >     >>
>> >> >     >
>> >> >     https://stats.idre.ucla.edu/spss/examples/alda/chapter7/
>> >> applied-longitudinal-data-analysis-modeling-change-and-
>> >> event-occurrenceby-judith-d-singer-and-john-b-willett-
>> >> chapter-7-examining-the-multilevel-model-s-erro/
>> >> >     <https://stats.idre.ucla.edu/spss/examples/alda/chapter7/
>> >> applied-longitudinal-data-analysis-modeling-change-and-
>> >> event-occurrenceby-judith-d-singer-and-john-b-willett-
>> >> chapter-7-examining-the-multilevel-model-s-erro/>
>> >> >     >     >> [3]
>> >> >     >     >>
>> >> >     >
>> >> >     https://stackoverflow.com/questions/48518514/what-is-
>> >> the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
>> >> >     <https://stackoverflow.com/questions/48518514/what-is-
>> >>
>> >> the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc>
>> >> >     >     >>
>> >> >     >     >> Regards,
>> >> >     >     >> Maarten
>> >> >     >     >>
>> >> >     >     >> On Tue, Mar 20, 2018 at 2:10 PM, Ben Pelzer
>> >> >     <b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>
>> >> >     >     <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>>
>> >> >     >     >> <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>
>> >> >     <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>>
>> >> >     >     <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>
>> >> >     <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>>>>> wrote:
>> >> >     >     >>
>> >> >     >     >>    Dear Maarten,
>> >> >     >     >>
>> >> >     >     >>    Take a look at
>> >> >     >     >>
>> >> >     >     >>
>> >> >     >
>> >> >     https://stats.idre.ucla.edu/r/examples/alda/r-applied-
>> >> longitudinal-data-analysis-ch-7/
>> >> >     <https://stats.idre.ucla.edu/r/examples/alda/r-applied-
>> >> longitudinal-data-analysis-ch-7/>
>> >> >     >
>> >> >      <https://stats.idre.ucla.edu/r/examples/alda/r-applied-
>> >> longitudinal-data-analysis-ch-7/
>> >> >     <https://stats.idre.ucla.edu/r/examples/alda/r-applied-
>> >> longitudinal-data-analysis-ch-7/>>
>> >> >     >     >>
>> >> >     >
>> >> >      <https://stats.idre.ucla.edu/r/examples/alda/r-applied-
>> >> longitudinal-data-analysis-ch-7/
>> >> >     <https://stats.idre.ucla.edu/r/examples/alda/r-applied-
>> >> longitudinal-data-analysis-ch-7/>
>> >> >     >
>> >> >      <https://stats.idre.ucla.edu/r/examples/alda/r-applied-
>> >> longitudinal-data-analysis-ch-7/
>> >> >     <https://stats.idre.ucla.edu/r/examples/alda/r-applied-
>> >> longitudinal-data-analysis-ch-7/>>>
>> >> >     >     >>
>> >> >     >     >>    which shows you a number of covariance structures,
>> >> > among
>> >> >     >     which is
>> >> >     >     >>    the unstructured matrix, for repeated measures in R
>> >> >     with lme. It
>> >> >     >     >>    refers to chapter 7 of Singer and Willett where they
>> >> >     discuss all
>> >> >     >     >>    these different structures and how to choose among
>> >> > them.
>> >> >     >     Regards,
>> >> >     >     >>
>> >> >     >     >>    Ben.
>> >> >     >     >>
>> >> >     >     >>    On 20-3-2018 9:00, Maarten Jung wrote:
>> >> >     >     >>
>> >> >     >     >>        Dear list,
>> >> >     >     >>        I came across a SPSS syntax like this
>> >> >     >     >>
>> >> >     >     >>        MIXED value BY factor1
>> >> >     >     >>             /CRITERIA=CIN(95) MXITER(100) MXSTEP(10)
>> >> >     SCORING(1)
>> >> >     >     >>        SINGULAR(0.000000000001)
>> >> >     >     >>             HCONVERGE(0, ABSOLUTE) LCONVERGE(0,
>> >> > ABSOLUTE)
>> >> >     >     >>        PCONVERGE(0.000001,
>> >> >     >     >>             ABSOLUTE)
>> >> >     >     >>             /FIXED=factor1 | SSTYPE(3)
>> >> >     >     >>             /METHOD=REML
>> >> >     >     >>             /REPEATED=factor1 | SUBJECT(participant)
>> >> >     COVTYPE(UN).
>> >> >     >     >>
>> >> >     >     >>        and struggle to find an equivalent lmer/nlme (or
>> >> > R in
>> >> >     >     general)
>> >> >     >     >>        formulation
>> >> >     >     >>        for this kind of models.
>> >> >     >     >>        Does anybody know how to convert the REPEATED
>> >> >     subcommand
>> >> >     >     into
>> >> >     >     >>        R code?
>> >> >     >     >>
>> >> >     >     >>        Please note that I asked the question on Stack
>> >> >     Overflow
>> >> >     >     about
>> >> >     >     >>        two month ago:
>> >> >     >     >>
>> >> >     >
>> >> >     https://stackoverflow.com/questions/48518514/what-is-
>> >> the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
>> >> >     <https://stackoverflow.com/questions/48518514/what-is-
>> >>
>> >> the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc>
>> >> >     >
>> >> >      <https://stackoverflow.com/questions/48518514/what-is-
>> >> the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
>> >> >     <https://stackoverflow.com/questions/48518514/what-is-
>> >>
>> >> the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc>>
>> >> >     >     >>
>> >> >     >
>> >> >      <https://stackoverflow.com/questions/48518514/what-is-
>> >> the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
>> >> >     <https://stackoverflow.com/questions/48518514/what-is-
>> >>
>> >> the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc>
>> >> >     >
>> >> >      <https://stackoverflow.com/questions/48518514/what-is-
>> >> the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
>> >> >     <https://stackoverflow.com/questions/48518514/what-is-
>> >>
>> >> the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc>>>
>> >> >     >     >>
>> >> >     >     >>        Best regards,
>> >> >     >     >>        Maarten
>> >> >     >     >>
>> >> >     >     >>                [[alternative HTML version deleted]]
>> >> >     >     >>
>> >> >     >     >> _______________________________________________
>> >> >     >     >> R-sig-mixed-models at r-project.org
>> >> >     <mailto:R-sig-mixed-models at r-project.org>
>> >> >     >     <mailto:R-sig-mixed-models at r-project.org
>> >> >     <mailto:R-sig-mixed-models at r-project.org>>
>> >> >     >     <mailto:R-sig-mixed-models at r-project.org
>> >> >     <mailto:R-sig-mixed-models at r-project.org>
>> >> >     >     <mailto:R-sig-mixed-models at r-project.org
>> >> >     <mailto:R-sig-mixed-models at r-project.org>>>
>> >> >     >     >>        <mailto:R-sig-mixed-models at r-project.org
>> >> >     <mailto:R-sig-mixed-models at r-project.org>
>> >> >     >     <mailto:R-sig-mixed-models at r-project.org
>> >> >     <mailto:R-sig-mixed-models at r-project.org>>
>> >> >     >     <mailto:R-sig-mixed-models at r-project.org
>> >> >     <mailto:R-sig-mixed-models at r-project.org>
>> >> >     >     <mailto:R-sig-mixed-models at r-project.org
>> >> >     <mailto:R-sig-mixed-models at r-project.org>>>> mailing list
>> >> >     >     >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>> >> >     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
>> >> >     >     >>
>> >> >     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>> >> >     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>
>> >> >     >     >>
>> >> >     >     >>
>> >> >     >     >>    _______________________________________________
>> >> >     >     >> R-sig-mixed-models at r-project.org
>> >> >     <mailto:R-sig-mixed-models at r-project.org>
>> >> >     >     <mailto:R-sig-mixed-models at r-project.org
>> >> >     <mailto:R-sig-mixed-models at r-project.org>>
>> >> >     >     <mailto:R-sig-mixed-models at r-project.org
>> >> >     <mailto:R-sig-mixed-models at r-project.org>
>> >> >     >     <mailto:R-sig-mixed-models at r-project.org
>> >> >     <mailto:R-sig-mixed-models at r-project.org>>>
>> >> >     >     >>    <mailto:R-sig-mixed-models at r-project.org
>> >> >     <mailto:R-sig-mixed-models at r-project.org>
>> >> >     >     <mailto:R-sig-mixed-models at r-project.org
>> >> >     <mailto:R-sig-mixed-models at r-project.org>>
>> >> >     >     <mailto:R-sig-mixed-models at r-project.org
>> >> >     <mailto:R-sig-mixed-models at r-project.org>
>> >> >     >     <mailto:R-sig-mixed-models at r-project.org
>> >> >     <mailto:R-sig-mixed-models at r-project.org>>>> mailing list
>> >> >     >     >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>> >> >     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
>> >> >     >     >>
>> >> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>> >> >     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>
>> >> >     >     >>
>> >> >     >     >>
>> >> >     >     >
>> >> >     >     >
>> >> >     >     >       [[alternative HTML version deleted]]
>> >> >     >     >
>> >> >     >     > _______________________________________________
>> >> >     >     > R-sig-mixed-models at r-project.org
>> >> >     <mailto:R-sig-mixed-models at r-project.org>
>> >> >     >     <mailto:R-sig-mixed-models at r-project.org
>> >> >     <mailto:R-sig-mixed-models at r-project.org>>
>> >> >     >     <mailto:R-sig-mixed-models at r-project.org
>> >> >     <mailto:R-sig-mixed-models at r-project.org>
>> >> >     >     <mailto:R-sig-mixed-models at r-project.org
>> >> >     <mailto:R-sig-mixed-models at r-project.org>>> mailing list
>> >> >     >     > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>> >> >     >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
>> >> >     >
>> >> >     >             [[alternative HTML version deleted]]
>> >> >     >
>> >> >     >     _______________________________________________
>> >> >     > R-sig-mixed-models at r-project.org
>> >> >     <mailto:R-sig-mixed-models at r-project.org>
>> >> >     >     <mailto:R-sig-mixed-models at r-project.org
>> >> >     <mailto:R-sig-mixed-models at r-project.org>> mailing list
>> >> >     > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>> >> >     >
>> >> >
>> >> >
>> >> >             [[alternative HTML version deleted]]
>> >> >
>> >> >     _______________________________________________
>> >> >     R-sig-mixed-models at r-project.org
>> >> >     <mailto:R-sig-mixed-models at r-project.org> mailing list
>> >> >     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>> >> >
>> >> >
>> >>
>> >>
>> >>         [[alternative HTML version deleted]]
>> >>
>> >> _______________________________________________
>> >> R-sig-mixed-models at r-project.org mailing list
>> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >>
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > _______________________________________________
>> > R-sig-mixed-models at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>


From cri.alessandro at gmail.com  Thu Mar 22 18:28:30 2018
From: cri.alessandro at gmail.com (Cristiano Alessandro)
Date: Thu, 22 Mar 2018 12:28:30 -0500
Subject: [R-sig-ME] adjusted values
Message-ID: <CAHhX7WiN98iuXNvurH+J8WHUw5or5yQhec6C78FrdWyvNVeShA@mail.gmail.com>

Hi all,

I am fitting a linear mixed model with lme4 in R. The model has a single
factor (des_days) with 4 levels (-1,1,14,48), and I am using random
intercept and slopes.

Fixed effects: data ~ des_days
                 Value   Std.Error  DF   t-value p-value
(Intercept)  0.8274313 0.007937938 962 104.23757  0.0000
des_days1   -0.0026322 0.007443294 962  -0.35363  0.7237
des_days14  -0.0011319 0.006635512 962  -0.17058  0.8646
des_days48   0.0112579 0.005452614 962   2.06469  0.0392

I can clearly use the previous results to compare the estimations of each
"des_day" to the intercept, using the provided t-statistics. Alternatively,
I could use post-hoc tests (z-statistics):

> ph_conditional <- c("des_days1  = 0",
                      "des_days14  = 0",
                      "des_days48 = 0");
> lev.ph <- glht(lev.lm, linfct = ph_conditional);
> summary(lev.ph)

Simultaneous Tests for General Linear Hypotheses

Fit: lme.formula(fixed = data ~ des_days, data = data_red_trf, random
= ~des_days |
    ratID, method = "ML", na.action = na.omit, control = lCtr)

Linear Hypotheses:
                 Estimate Std. Error z value Pr(>|z|)
des_days1 == 0  -0.002632   0.007428  -0.354    0.971
des_days14 == 0 -0.001132   0.006622  -0.171    0.996
des_days48 == 0  0.011258   0.005441   2.069    0.101
(Adjusted p values reported -- single-step method)


The p-values of the coefficient estimates and those of the post-hoc tests
differ because the latter are adjusted with Bonferroni correction. I wonder
whether there is any form of correction in the coefficient estimated of the
LMM, and which p-values are more appropriate to use.

Thanks
Cristiano

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Thu Mar 22 19:08:38 2018
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 22 Mar 2018 14:08:38 -0400
Subject: [R-sig-ME] adjusted values
In-Reply-To: <CAHhX7WiN98iuXNvurH+J8WHUw5or5yQhec6C78FrdWyvNVeShA@mail.gmail.com>
References: <CAHhX7WiN98iuXNvurH+J8WHUw5or5yQhec6C78FrdWyvNVeShA@mail.gmail.com>
Message-ID: <1d58bc54-63c3-20eb-396e-c21233487645@gmail.com>


  summary() via lmerTest incorporates finite-size corrections, but not
multiple-comparisons corrections.  glht does the opposite.  In this case
your finite-size corrections are pretty much irrelevant though (in this
context 962 \approx infinity).

  By convention, people don't usually bother with MC corrections when
they're testing pre-defined contrasts from a single model, but I don't
know that there's hard-and-fast rule (if I were testing the effects of a
large number of treatments within a single model I might indeed use MC;
I probably wouldn't bother for n=4).

  I don't know exactly what kind of MC correction glht does, but it
probably shouldn't be Bonferroni (which is very conservative, and
ignores correlations among the tests).

On 18-03-22 01:28 PM, Cristiano Alessandro wrote:
> Hi all,
> 
> I am fitting a linear mixed model with lme4 in R. The model has a single
> factor (des_days) with 4 levels (-1,1,14,48), and I am using random
> intercept and slopes.
> 
> Fixed effects: data ~ des_days
>                  Value   Std.Error  DF   t-value p-value
> (Intercept)  0.8274313 0.007937938 962 104.23757  0.0000
> des_days1   -0.0026322 0.007443294 962  -0.35363  0.7237
> des_days14  -0.0011319 0.006635512 962  -0.17058  0.8646
> des_days48   0.0112579 0.005452614 962   2.06469  0.0392
> 
> I can clearly use the previous results to compare the estimations of each
> "des_day" to the intercept, using the provided t-statistics. Alternatively,
> I could use post-hoc tests (z-statistics):
> 
>> ph_conditional <- c("des_days1  = 0",
>                       "des_days14  = 0",
>                       "des_days48 = 0");
>> lev.ph <- glht(lev.lm, linfct = ph_conditional);
>> summary(lev.ph)
> 
> Simultaneous Tests for General Linear Hypotheses
> 
> Fit: lme.formula(fixed = data ~ des_days, data = data_red_trf, random
> = ~des_days |
>     ratID, method = "ML", na.action = na.omit, control = lCtr)
> 
> Linear Hypotheses:
>                  Estimate Std. Error z value Pr(>|z|)
> des_days1 == 0  -0.002632   0.007428  -0.354    0.971
> des_days14 == 0 -0.001132   0.006622  -0.171    0.996
> des_days48 == 0  0.011258   0.005441   2.069    0.101
> (Adjusted p values reported -- single-step method)
> 
> 
> The p-values of the coefficient estimates and those of the post-hoc tests
> differ because the latter are adjusted with Bonferroni correction. I wonder
> whether there is any form of correction in the coefficient estimated of the
> LMM, and which p-values are more appropriate to use.
> 
> Thanks
> Cristiano
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From bbolker at gmail.com  Thu Mar 22 19:52:50 2018
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 22 Mar 2018 14:52:50 -0400
Subject: [R-sig-ME] 
 How does one include a factor in a groupedData object;
 What is the meaning and use of inner and outer
 parameters of groupedData object?
In-Reply-To: <BN6PR03MB2705B7C23D6AB7C0B9186306E2A90@BN6PR03MB2705.namprd03.prod.outlook.com>
References: <BN6PR03MB2705B7C23D6AB7C0B9186306E2A90@BN6PR03MB2705.namprd03.prod.outlook.com>
Message-ID: <CABghstSreLDLj83bjcqBnH-ch7Wz0=5kKZ0ovY5LfyH1AbGq9g@mail.gmail.com>

  lme4 essentially ignores groupedData information, so I'm not sure
what the goal is here. (Full disclosure:
groupedData was invented for/used in nlme, in principle I think it's a
great idea to incorporate this kind of
metadata system for mixed models, but I've never been able to use it
very effectively myself.)  Are you
trying to run the equivalent model in nlme?  I don't think groupedData
is *necessary* for running an (n)lme model ...

On Thu, Mar 22, 2018 at 11:02 AM, Sorkin, John
<jsorkin at som.umaryland.edu> wrote:
> Several questions relating to groupedData:
>
> (1) I am trying to create a groupedData object that can be used to run an analysis that I have been able to urn using lmer. When I include the interaction terms in the groupedData opbject I get an error message stating that + is not meaningful for factors. How do I include factors in my model? See code and error below.
>
> (2) I have read the help file for groupedData multiple times. I am unable to understand the meaning or, or the use for the inner= and outer= parameters in the call to groupedData. Can someone either explain the meaning of these parameters or refer me to a source that give a clear explanation?
>
>
>> fit0 <- lmer(THmean~INTRVNTN+factor(TimePtID)+INTRVNTN*factor(TimePtID)+(1|PatientID),data=smalldata)
>> sdgd <- groupedData(THmean~INTRVNTN+TimePtID+INTRVNTN*TimePtID|PatientID,data=smalldata)
> Warning messages:
> 1: In Ops.factor(INTRVNTN, TimePtID) : ?+? not meaningful for factors
> 2: In Ops.factor(INTRVNTN, TimePtID) : ?*? not meaningful for factors
>
>
> Thank you,
>
> John
>
>
>
>
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From Maarten.Jung at mailbox.tu-dresden.de  Thu Mar 22 20:16:36 2018
From: Maarten.Jung at mailbox.tu-dresden.de (Maarten Jung)
Date: Thu, 22 Mar 2018 19:16:36 +0000
Subject: [R-sig-ME] What is the lmer/nlme equivalent of the REPEATED
 subcommand in SPSS's MIXED procedure?
In-Reply-To: <CAG_uk90fyg_W9hXho1qQRaqCoYbN_oT8bqriXGuJq6khjFm=qQ@mail.gmail.com>
References: <CAHr4Dyep9JCDpNauViVf0MyeH-=p7k0fx3yXbMCL_b-9tLTMEQ@mail.gmail.com>
 <d67d36fb-1019-d878-794e-491c3a409f2a@maw.ru.nl>
 <CAHr4Dydq-SW_8aKUF=MFqnFpx6P36RSguP7gTF-6epZjMFWo3A@mail.gmail.com>
 <5AB140DE.5090705@maw.ru.nl>
 <20732_1521566386_0P5W00D4NG4WVU20_9ECC9EC8-43DB-49AD-97E0-67E5E680460A@gmail.com>
 <CAO7JsnTCenXXrrrfJthUz5aLv2wiubdrzOw30mFY5AdUBmF=ig@mail.gmail.com>
 <42ce404b-af99-82c6-a2f6-482b9963da3a@maw.ru.nl>
 <CAHr4DyeaLCL_RxsjNnYb=L2pxo4r4+mcmsDF382x88UPoVYPaA@mail.gmail.com>
 <5AB2C04C.6010707@maw.ru.nl>
 <CAHr4Dyfhcuh7cNqDCR8ghdHfu1mwhzW9MWMChnOTTsTD_nmo+A@mail.gmail.com>
 <CAG_uk93v1bO48X2nOpuobS7qiqC20MNpJ_T5MKzcgWi89hunzw@mail.gmail.com>
 <CAHr4Dyf6H08wyeCMf3_GCzSGKvD484bPd03RQ70ShwTofq7yXg@mail.gmail.com>
 <CAG_uk90fyg_W9hXho1qQRaqCoYbN_oT8bqriXGuJq6khjFm=qQ@mail.gmail.com>
Message-ID: <CAHr4DyeSUrhgkLSAV=psjzkpgvUvGJZCstpvtnYqHtwWZHGydQ@mail.gmail.com>

Thanks for giving this nice example - it makes perfect sense! I'll have a
closer look at these models.

Regards,
Maarten

On Thu, Mar 22, 2018, 17:54 Rune Haubo <rune.haubo at gmail.com> wrote:

> On 22 March 2018 at 16:11, Maarten Jung
> <Maarten.Jung at mailbox.tu-dresden.de> wrote:
> > Dear Rune,
> >
> > thanks for making clear what /REPEATED stands for!
> >
> > Independently, does it make sense to fit a model via
> >
> > gls(value ~ factor1, data, correlation = corSymm(form = ~ 1|person),
> weights
> > = varIdent(form = ~1|factor1))
> >
> > when there is only one observation per subject-factor1-combination?
>
> Yes, I'd say so. And Ben Pelzer's email from yesterday has a data+code
> example of exactly that if I'm not mistaken.
>
> If factor1 is 'time' this model is quite similar to the famous MMRM*
> often used in pharma to model clinical trials (for purposes of
> handling/'imputation' of missing values) in which measurements are
> made on subjects at, say, a handful of timepoints over the trial
> period. This model essentially specifies that each subject-profile
> follows a multivariate normal distribution with the so-called
> 'unstructured' variance-covariance matrix with dimensions equal to the
> number of timepoints, further, all the subject profiles are
> independent. Differences between treatment groups are then estimated
> at each timepoint and usually the differences at the last timepoint
> are of primary interest. Long story short: Yes it makes sense and it's
> done all the time in the pharmaceutical world.
>
> Cheers
> Rune
>
> *The MMRM is a very specific model not just any 'mixed model for
> repeated measurements', in fact, it is not really a mixed model (the
> lack of random effects give it away...).
>
> >
> > Regards,
> > Maarten
> >
> > On Thu, Mar 22, 2018 at 11:38 AM, Rune Haubo <rune.haubo at gmail.com>
> wrote:
> >>
> >> On 22 March 2018 at 10:05, Maarten Jung
> >> <Maarten.Jung at mailbox.tu-dresden.de> wrote:
> >> > I think the problem is that there is only one observation per
> >> > subject-occasion-combination in this example.
> >> > In this case the random slopes are confounded with the residual
> >> > variation
> >> > (see [1]).
> >>
> >> I agree.
> >>
> >> >
> >> > One *can* fit this model using lmer(test ~ 1 + occ2 + occ3 + (1 +
> occ2 +
> >> > occ3|person), data = mydata,  control = lmerControl(check.nobs.vs.nRE
> =
> >> > "ignore")) or
> >> > lme(test ~ 1 + occ2 + occ3, mydata, random = ~ occ2 + occ3|person).
> >> >
> >> > However, I don't know if the gls() fit ist more trustworthy than the
> >> > lmer/lme fit here.
> >> > I would be grateful if somebody more experienced in mixed models could
> >> > comment on this.
> >>
> >> If you are trying to replicate a model that is specified with a
> >> 'repeated' statement (and 'repeated' in SPSS means the same as in SAS)
> >> then we are talking about specifying a structure in the residual
> >> variance-covariance matrix (cf.
> >>
> >>
> https://support.sas.com/documentation/cdl/en/statug/63033/HTML/default/viewer.htm#statug_mixed_sect019.htm
> ).
> >> If we write the model as y = X beta + Z b + e with b ~ N(0, G) and e ~
> >> N(0, R), then 'repeated' is specifying the structure in R. This is
> >> exactly what nlme::gls and nlme::lme do via the weights and
> >> correlation arguments; you need lme if you have 'true' random effects
> >> on top of the structure in R.
> >>
> >> If we write the marginal distribution of y as y ~ N(X beta, V), with V
> >> = ZGZ' + R then the structure in V can be obtained by appropriate
> >> specification of either Z and G or R, or both. This means that in some
> >> cases there is more than one 'natural' way to specify the same
> >> marginal model (compound symmetry is the classical example*). Now,
> >> lmer has the structure of R fixed at sigma^2 I, i.e. a multiple of the
> >> identity matrix, but with appropriate random-effect specification you
> >> can sometimes obtain the same (marginal) likelihood as if the
> >> structure was specified in the R matrix. My advice, is however, that
> >> if you want to fit a model with a particular structure in R, then
> >> don't use lmer; you really have to know all details of what is going
> >> to be sure that it works as intended.
> >>
> >> Cheers,
> >> Rune
> >>
> >> *Actually the compound symmetry and random intercept models are _not_
> >> the same (though often claimed to be) because the parameter spaces
> >> differ. This means that for some data sets the model fits are the same
> >> (i.e. same likelihood) and for other data sets the model fits are
> >> different.
> >>
> >> >
> >> > Best regards,
> >> > Maarten
> >> >
> >> > [1]
> >> >
> >> >
> https://stackoverflow.com/questions/26465215/random-slope-for-time-in-subject-not-working-in-lme4?utm_medium=organic&utm_source=google_rich_qa&utm_campaign=google_rich_qa
> >> >
> >> > On Wed, Mar 21, 2018 at 9:27 PM, Ben Pelzer <b.pelzer at maw.ru.nl>
> wrote:
> >> >
> >> >> Hi Maarten,
> >> >>
> >> >> Here is an example which shows the unstructured model with gls and
> the
> >> >> not converging model with lmer. In this example, we have three
> >> >> occasions
> >> >> on which the dependent variable "test" was observed, for each of 20
> >> >> persons. In total then we have 60 observations, with the "occasion"
> >> >> variable taking values 1, 2, 3. The data also contain the person id
> >> >> variable "person" and dummy variables "occ1", "occ2", "occ3" as (0 or
> >> >> 1)
> >> >> indicators of the occasion.  In the syntax below, a factor variable
> >> >> "factor1" is created also, to be in line with your question.
> >> >>
> >> >> I used two different specifications for the unstructured model with
> >> >> gls,
> >> >> depending on whether dummies or factor1 was used. For lmer, I used
> >> >> these
> >> >> three different specifications, none of which converges.
> >> >>
> >> >> The lmer syntax was added only to show the problem which lmer has
> with
> >> >> estimating an unstructured correlation pattern.
> >> >>
> >> >>
> >> >> #-----------------------------------------------------------
> >> >> ------------------------------------------------------------
> >> >> -------------------------------------
> >> >> mydata <-
> >> >> read.table(url("https://surfdrive.surf.nl/files/index.
> >> >> php/s/XfE3mtbFCTUejIz/download"),
> >> >> header=TRUE)
> >> >>
> >> >>
> >> >> #-------------------  unstructured correlation matrix
> >> >> -----------------------
> >> >>
> >> >>
> >> >> # Before applying a model, let's first examine the variances and
> >> >> correlations
> >> >> # for the three occasions. We have a strong violation of the
> >> >> assumptions
> >> >> # of homoscedasticity and compound symmetry.
> >> >> test1 <- mydata[mydata$occasion==1,"test"]
> >> >> test2 <- mydata[mydata$occasion==2,"test"]
> >> >> test3 <- mydata[mydata$occasion==3,"test"]
> >> >> cor(cbind(test1, test2, test3))
> >> >> var(cbind(test1, test2, test3))
> >> >>
> >> >> # Unstructured model using gls from package nlme and dummies for
> >> >> occasion.
> >> >> # This model exactly reproduces the observed correlations between
> >> >> occasions.
> >> >> unstruc.gls1 <- gls(test ~ 1+ occ2 + occ3,
> >> >>                             method="REML", data=mydata,
> >> >>                             correlation=corSymm(form = ~ 1 |person),
> >> >>                             weights = varIdent(form = ~1|occasion))
> >> >> summary(unstruc.gls1)
> >> >>
> >> >>
> >> >> # Unstructured model using factor1 for occasion instead of dummies.
> >> >> # The results are exactly the same as those above, as should be.
> >> >> mydata$factor1 <- as.factor(mydata$occasion)
> >> >> unstruc.gls2 <- gls(test ~ factor1,
> >> >>                      method="REML", data=mydata,
> >> >>                      correlation=corSymm(form = ~ 1|person),
> >> >>                      weights = varIdent(form = ~1|factor1))
> >> >> summary(unstruc.gls2)
> >> >>
> >> >>
> >> >> # Unstructured model using lmer and dummies for occasion: does not
> >> >> converge.
> >> >> unstruc.lmer <- lmer(test ~ 1+ occ2 + occ3 + (1+occ2+occ3|person),
> >> >>                       data=mydata, REML=TRUE)
> >> >> summary(unstruc.lmer)
> >> >>
> >> >>
> >> >> # Unstructured model using lmer and factor1 for occasion: does not
> >> >> converge.
> >> >> unstruc.lmer <- lmer(test ~ 1+ factor1 + (1+factor1|person),
> >> >>                       data=mydata, REML=TRUE)
> >> >> summary(unstruc.lmer)
> >> >>
> >> >>
> >> >> # Unstructured model using lmer and factor1 for occasion, no
> intercept
> >> >> specified: does not converge.
> >> >> unstruc.lmer <- lmer(test ~ factor1 + (factor1|person),
> >> >>                       data=mydata, REML=TRUE)
> >> >> summary(unstruc.lmer)
> >> >>
> >> >>
> >> >>
> >> >> On 21/03/2018 13:07, Maarten Jung wrote:
> >> >> > Dear Ben,
> >> >> >
> >> >> > I am a bit puzzled.
> >> >> >
> >> >> > Do you mean that
> >> >> >
> >> >> > m1 <- gls(value ~ factor1, data, correlation = corSymm(form = ~
> >> >> > 1|participant), weights = varIdent(form = ~ 1|factor))
> >> >> >
> >> >> > would be equivalent to
> >> >> >
> >> >> > m2 <- lmer(value ~ factor1 + (factor1|participant), data)
> >> >> >
> >> >> > and one should use gls() because it allows for the same covariance
> >> >> > structures as /REPEATED does?
> >> >> >
> >> >>
> >> >>
> >> >> the two specifications are not equivalent in the sense that lmer also
> >> >> tries to estimate residual variance. However, with the given lmer
> model
> >> >> specification, the random factor1 effects capture all variance there
> is
> >> >> and no residual variance remains.
> >> >>
> >> >>
> >> >> > And, if so, why should m2 cause an identification problem and m1
> >> >> > doesn't?
> >> >> >
> >> >> > Regards,
> >> >> > Maarten
> >> >> >
> >> >> Regards, Ben.
> >> >>
> >> >>
> >> >>
> >> >> >
> >> >> > On Wed, Mar 21, 2018 at 12:03 PM, Ben Pelzer <b.pelzer at maw.ru.nl
> >> >> > <mailto:b.pelzer at maw.ru.nl>> wrote:
> >> >> >
> >> >> >     Dear all,
> >> >> >
> >> >> >     As far as I know, the specification for lmer using
> >> >> >
> >> >> >          value ~ factor1 + (factor1 | participant)
> >> >> >
> >> >> >     causes an identification problem, because the residual variance
> >> >> > is
> >> >> not
> >> >> >     excluded from the estimations. It would indeed work (e.g. in
> >> >> > MlWin
> >> >> >     this
> >> >> >     can be done) if we could constrain that residual variance to
> >> >> > zero.
> >> >> >     There
> >> >> >     have been some mails in this list about whether or not
> >> >> > constraining
> >> >> >     residual variance to zero is possible in lmer, but I believe
> this
> >> >> >     is not
> >> >> >     possible. Would be nice if we could do this in lmer!
> >> >> >
> >> >> >     Best regards, Ben.
> >> >> >
> >> >> >
> >> >> >     On 20-3-2018 18:34, Douglas Bates wrote:
> >> >> >     > Kind of looks like SPSS went for bug-for-bug compatibility
> with
> >> >> >     SAS on
> >> >> >     > this one.  In SAS PROC MIXED, "REPEATED" and "RANDOM" are two
> >> >> >     ways of
> >> >> >     > specifying the random effects variance structure but they
> often
> >> >> boil
> >> >> >     > down to the same model.
> >> >> >     >
> >> >> >     > I believe the model can be specified in lme4 as
> >> >> >     >
> >> >> >     >     value ~ factor1 + (factor1 | participant)
> >> >> >     >
> >> >> >     > This is what the mis-named* "UNSTRUCTURED" covariance type
> >> >> > means
> >> >> >     >
> >> >> >     > * Old-guy, get off my lawn rant about terminology *
> >> >> >     > As a recovering mathematician I find the name "unstructured"
> >> >> > being
> >> >> >     > used to denote a positive-definite symmetric matrix to be,
> >> >> > well,
> >> >> >     > inaccurate.
> >> >> >     >
> >> >> >     > On Tue, Mar 20, 2018 at 12:19 PM Mollie Brooks
> >> >> >     > <mollieebrooks at gmail.com <mailto:mollieebrooks at gmail.com>
> >> >> >     <mailto:mollieebrooks at gmail.com
> >> >> > <mailto:mollieebrooks at gmail.com>>>
> >> >> >     wrote:
> >> >> >     >
> >> >> >     >     I don?t know anything about spss, but if you basically
> want
> >> >> lme4
> >> >> >     >     with more correlation structures, you could look at the
> >> >> >     structures
> >> >> >     >     available with glmmTMB.
> >> >> >     >
> >> >> >     https://cran.r-project.org/web/packages/glmmTMB/
> >> >> vignettes/covstruct.html
> >> >> >     <https://cran.r-project.org/web/packages/glmmTMB/
> >> >> vignettes/covstruct.html>
> >> >> >     >
> >> >> >     >     cheers,
> >> >> >     >     Mollie
> >> >> >     >
> >> >> >     >     > On 20Mar 2018, at 18:11, Ben Pelzer <
> b.pelzer at maw.ru.nl
> >> >> >     <mailto:b.pelzer at maw.ru.nl>
> >> >> >     >     <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>>>
> >> >> wrote:
> >> >> >     >     >
> >> >> >     >     > Hi Maarten,
> >> >> >     >     >
> >> >> >     >     > You are right: you need nlme and NOT lme4 to specify
> >> >> >     particular
> >> >> >     >     > correlation structures. Also, in nlme you would need
> gls
> >> >> >     to make it
> >> >> >     >     > similar to mixed in spss. The repeated command in spss
> >> >> >     gives the
> >> >> >     >     same
> >> >> >     >     > results as gls does for any of the covariance
> structures.
> >> >> >     >     >
> >> >> >     >     > Regards, Ben.
> >> >> >     >     >
> >> >> >     >     >
> >> >> >     >     > On 20/03/2018 17:30, Maarten Jung wrote:
> >> >> >     >     >> Dear Ben, dear Phillip,
> >> >> >     >     >>
> >> >> >     >     >> comparing [1] with [2] I think the /REPEATED command
> >> >> >     specifies
> >> >> >     >     >> the error (co)variance structure of the model. Would
> you
> >> >> >     agree
> >> >> >     >     with that?
> >> >> >     >     >> If so, AFAIK this is not possible with lmer and thus
> the
> >> >> >     answer on
> >> >> >     >     >> Stack Overflow [3] would be wrong.
> >> >> >     >     >>
> >> >> >     >     >> [1]
> >> >> >     >     >>
> >> >> >     >
> >> >> >     https://stats.idre.ucla.edu/r/examples/alda/r-applied-
> >> >> longitudinal-data-analysis-ch-7/
> >> >> >     <https://stats.idre.ucla.edu/r/examples/alda/r-applied-
> >> >> longitudinal-data-analysis-ch-7/>
> >> >> >     >     >> [2]
> >> >> >     >     >>
> >> >> >     >
> >> >> >     https://stats.idre.ucla.edu/spss/examples/alda/chapter7/
> >> >> applied-longitudinal-data-analysis-modeling-change-and-
> >> >> event-occurrenceby-judith-d-singer-and-john-b-willett-
> >> >> chapter-7-examining-the-multilevel-model-s-erro/
> >> >> >     <https://stats.idre.ucla.edu/spss/examples/alda/chapter7/
> >> >> applied-longitudinal-data-analysis-modeling-change-and-
> >> >> event-occurrenceby-judith-d-singer-and-john-b-willett-
> >> >> chapter-7-examining-the-multilevel-model-s-erro/>
> >> >> >     >     >> [3]
> >> >> >     >     >>
> >> >> >     >
> >> >> >     https://stackoverflow.com/questions/48518514/what-is-
> >> >>
> the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
> >> >> >     <https://stackoverflow.com/questions/48518514/what-is-
> >> >>
> >> >>
> the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc>
> >> >> >     >     >>
> >> >> >     >     >> Regards,
> >> >> >     >     >> Maarten
> >> >> >     >     >>
> >> >> >     >     >> On Tue, Mar 20, 2018 at 2:10 PM, Ben Pelzer
> >> >> >     <b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>
> >> >> >     >     <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>>
> >> >> >     >     >> <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl
> >
> >> >> >     <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>>
> >> >> >     >     <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>
> >> >> >     <mailto:b.pelzer at maw.ru.nl <mailto:b.pelzer at maw.ru.nl>>>>>
> wrote:
> >> >> >     >     >>
> >> >> >     >     >>    Dear Maarten,
> >> >> >     >     >>
> >> >> >     >     >>    Take a look at
> >> >> >     >     >>
> >> >> >     >     >>
> >> >> >     >
> >> >> >     https://stats.idre.ucla.edu/r/examples/alda/r-applied-
> >> >> longitudinal-data-analysis-ch-7/
> >> >> >     <https://stats.idre.ucla.edu/r/examples/alda/r-applied-
> >> >> longitudinal-data-analysis-ch-7/>
> >> >> >     >
> >> >> >      <https://stats.idre.ucla.edu/r/examples/alda/r-applied-
> >> >> longitudinal-data-analysis-ch-7/
> >> >> >     <https://stats.idre.ucla.edu/r/examples/alda/r-applied-
> >> >> longitudinal-data-analysis-ch-7/>>
> >> >> >     >     >>
> >> >> >     >
> >> >> >      <https://stats.idre.ucla.edu/r/examples/alda/r-applied-
> >> >> longitudinal-data-analysis-ch-7/
> >> >> >     <https://stats.idre.ucla.edu/r/examples/alda/r-applied-
> >> >> longitudinal-data-analysis-ch-7/>
> >> >> >     >
> >> >> >      <https://stats.idre.ucla.edu/r/examples/alda/r-applied-
> >> >> longitudinal-data-analysis-ch-7/
> >> >> >     <https://stats.idre.ucla.edu/r/examples/alda/r-applied-
> >> >> longitudinal-data-analysis-ch-7/>>>
> >> >> >     >     >>
> >> >> >     >     >>    which shows you a number of covariance structures,
> >> >> > among
> >> >> >     >     which is
> >> >> >     >     >>    the unstructured matrix, for repeated measures in R
> >> >> >     with lme. It
> >> >> >     >     >>    refers to chapter 7 of Singer and Willett where
> they
> >> >> >     discuss all
> >> >> >     >     >>    these different structures and how to choose among
> >> >> > them.
> >> >> >     >     Regards,
> >> >> >     >     >>
> >> >> >     >     >>    Ben.
> >> >> >     >     >>
> >> >> >     >     >>    On 20-3-2018 9:00, Maarten Jung wrote:
> >> >> >     >     >>
> >> >> >     >     >>        Dear list,
> >> >> >     >     >>        I came across a SPSS syntax like this
> >> >> >     >     >>
> >> >> >     >     >>        MIXED value BY factor1
> >> >> >     >     >>             /CRITERIA=CIN(95) MXITER(100) MXSTEP(10)
> >> >> >     SCORING(1)
> >> >> >     >     >>        SINGULAR(0.000000000001)
> >> >> >     >     >>             HCONVERGE(0, ABSOLUTE) LCONVERGE(0,
> >> >> > ABSOLUTE)
> >> >> >     >     >>        PCONVERGE(0.000001,
> >> >> >     >     >>             ABSOLUTE)
> >> >> >     >     >>             /FIXED=factor1 | SSTYPE(3)
> >> >> >     >     >>             /METHOD=REML
> >> >> >     >     >>             /REPEATED=factor1 | SUBJECT(participant)
> >> >> >     COVTYPE(UN).
> >> >> >     >     >>
> >> >> >     >     >>        and struggle to find an equivalent lmer/nlme
> (or
> >> >> > R in
> >> >> >     >     general)
> >> >> >     >     >>        formulation
> >> >> >     >     >>        for this kind of models.
> >> >> >     >     >>        Does anybody know how to convert the REPEATED
> >> >> >     subcommand
> >> >> >     >     into
> >> >> >     >     >>        R code?
> >> >> >     >     >>
> >> >> >     >     >>        Please note that I asked the question on Stack
> >> >> >     Overflow
> >> >> >     >     about
> >> >> >     >     >>        two month ago:
> >> >> >     >     >>
> >> >> >     >
> >> >> >     https://stackoverflow.com/questions/48518514/what-is-
> >> >>
> the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
> >> >> >     <https://stackoverflow.com/questions/48518514/what-is-
> >> >>
> >> >>
> the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc>
> >> >> >     >
> >> >> >      <https://stackoverflow.com/questions/48518514/what-is-
> >> >>
> the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
> >> >> >     <https://stackoverflow.com/questions/48518514/what-is-
> >> >>
> >> >>
> the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc>>
> >> >> >     >     >>
> >> >> >     >
> >> >> >      <https://stackoverflow.com/questions/48518514/what-is-
> >> >>
> the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
> >> >> >     <https://stackoverflow.com/questions/48518514/what-is-
> >> >>
> >> >>
> the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc>
> >> >> >     >
> >> >> >      <https://stackoverflow.com/questions/48518514/what-is-
> >> >>
> the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc
> >> >> >     <https://stackoverflow.com/questions/48518514/what-is-
> >> >>
> >> >>
> the-lmer-nlme-equivalent-of-the-repeated-subcommand-in-spsss-mixed-proc>>>
> >> >> >     >     >>
> >> >> >     >     >>        Best regards,
> >> >> >     >     >>        Maarten
> >> >> >     >     >>
> >> >> >     >     >>                [[alternative HTML version deleted]]
> >> >> >     >     >>
> >> >> >     >     >> _______________________________________________
> >> >> >     >     >> R-sig-mixed-models at r-project.org
> >> >> >     <mailto:R-sig-mixed-models at r-project.org>
> >> >> >     >     <mailto:R-sig-mixed-models at r-project.org
> >> >> >     <mailto:R-sig-mixed-models at r-project.org>>
> >> >> >     >     <mailto:R-sig-mixed-models at r-project.org
> >> >> >     <mailto:R-sig-mixed-models at r-project.org>
> >> >> >     >     <mailto:R-sig-mixed-models at r-project.org
> >> >> >     <mailto:R-sig-mixed-models at r-project.org>>>
> >> >> >     >     >>        <mailto:R-sig-mixed-models at r-project.org
> >> >> >     <mailto:R-sig-mixed-models at r-project.org>
> >> >> >     >     <mailto:R-sig-mixed-models at r-project.org
> >> >> >     <mailto:R-sig-mixed-models at r-project.org>>
> >> >> >     >     <mailto:R-sig-mixed-models at r-project.org
> >> >> >     <mailto:R-sig-mixed-models at r-project.org>
> >> >> >     >     <mailto:R-sig-mixed-models at r-project.org
> >> >> >     <mailto:R-sig-mixed-models at r-project.org>>>> mailing list
> >> >> >     >     >>
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >> >> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >> >> >     >     <
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >> >> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
> >> >> >     >     >>
> >> >> >     >     <
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >> >> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >> >> >     >     <
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >> >> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>
> >> >> >     >     >>
> >> >> >     >     >>
> >> >> >     >     >>    _______________________________________________
> >> >> >     >     >> R-sig-mixed-models at r-project.org
> >> >> >     <mailto:R-sig-mixed-models at r-project.org>
> >> >> >     >     <mailto:R-sig-mixed-models at r-project.org
> >> >> >     <mailto:R-sig-mixed-models at r-project.org>>
> >> >> >     >     <mailto:R-sig-mixed-models at r-project.org
> >> >> >     <mailto:R-sig-mixed-models at r-project.org>
> >> >> >     >     <mailto:R-sig-mixed-models at r-project.org
> >> >> >     <mailto:R-sig-mixed-models at r-project.org>>>
> >> >> >     >     >>    <mailto:R-sig-mixed-models at r-project.org
> >> >> >     <mailto:R-sig-mixed-models at r-project.org>
> >> >> >     >     <mailto:R-sig-mixed-models at r-project.org
> >> >> >     <mailto:R-sig-mixed-models at r-project.org>>
> >> >> >     >     <mailto:R-sig-mixed-models at r-project.org
> >> >> >     <mailto:R-sig-mixed-models at r-project.org>
> >> >> >     >     <mailto:R-sig-mixed-models at r-project.org
> >> >> >     <mailto:R-sig-mixed-models at r-project.org>>>> mailing list
> >> >> >     >     >>
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >> >> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >> >> >     >     <
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >> >> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
> >> >> >     >     >>
> >> >> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >> >> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >> >> >     >     <
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >> >> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>>
> >> >> >     >     >>
> >> >> >     >     >>
> >> >> >     >     >
> >> >> >     >     >
> >> >> >     >     >       [[alternative HTML version deleted]]
> >> >> >     >     >
> >> >> >     >     > _______________________________________________
> >> >> >     >     > R-sig-mixed-models at r-project.org
> >> >> >     <mailto:R-sig-mixed-models at r-project.org>
> >> >> >     >     <mailto:R-sig-mixed-models at r-project.org
> >> >> >     <mailto:R-sig-mixed-models at r-project.org>>
> >> >> >     >     <mailto:R-sig-mixed-models at r-project.org
> >> >> >     <mailto:R-sig-mixed-models at r-project.org>
> >> >> >     >     <mailto:R-sig-mixed-models at r-project.org
> >> >> >     <mailto:R-sig-mixed-models at r-project.org>>> mailing list
> >> >> >     >     >
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >> >> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >> >> >     >     <
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >> >> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
> >> >> >     >
> >> >> >     >             [[alternative HTML version deleted]]
> >> >> >     >
> >> >> >     >     _______________________________________________
> >> >> >     > R-sig-mixed-models at r-project.org
> >> >> >     <mailto:R-sig-mixed-models at r-project.org>
> >> >> >     >     <mailto:R-sig-mixed-models at r-project.org
> >> >> >     <mailto:R-sig-mixed-models at r-project.org>> mailing list
> >> >> >     > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >> >> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >> >> >     >
> >> >> >
> >> >> >
> >> >> >             [[alternative HTML version deleted]]
> >> >> >
> >> >> >     _______________________________________________
> >> >> >     R-sig-mixed-models at r-project.org
> >> >> >     <mailto:R-sig-mixed-models at r-project.org> mailing list
> >> >> >     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >> >> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >> >> >
> >> >> >
> >> >>
> >> >>
> >> >>         [[alternative HTML version deleted]]
> >> >>
> >> >> _______________________________________________
> >> >> R-sig-mixed-models at r-project.org mailing list
> >> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >> >>
> >> >
> >> >         [[alternative HTML version deleted]]
> >> >
> >> > _______________________________________________
> >> > R-sig-mixed-models at r-project.org mailing list
> >> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> >
>

	[[alternative HTML version deleted]]


From aglowka at stanford.edu  Thu Mar 22 20:18:29 2018
From: aglowka at stanford.edu (Aleksander Adam Glowka)
Date: Thu, 22 Mar 2018 19:18:29 +0000
Subject: [R-sig-ME] prevent for-loop from stopping after an lmer
 warning/error
Message-ID: <BLUPR02MB12173138867AC360232C8F11CFA90@BLUPR02MB1217.namprd02.prod.outlook.com>

Hi all,

I'm fitting mixed-effects regression models to bootstrap samples in a for-loop and writing a subset of model results to file. I diverted the stream from the console to a text file so I can keep track any warnings or errors. For some samples the model does not converge and a warning is issued. For other samples there is an error in calculation of the Satterthwaite's approximation. The problem is that my loop iteration is aborted for some reason after a warning is issued. Do you know why this might be happening and how I can make the loops continue to the next iteration after an error or a warning?

Below I've included an abridged version of my script and the warnings and errors I get. I'd be grateful for any advice you may have!

Thank you,

Aleksander Glowka
PhD Candidate
Department of Linguistics
Stanford University

#packages
require(lme4)
require(lmerTest)

setwd(path0)
source("lmer-data-extract-boot-fnc.R") #selected lmer results extractor

# divert messages stream to file, so you can log warnings and errors
options(warn=1)
wngs=file("warnings_log.txt",open="w+",blocking=TRUE)
sink(wngs,type="message")

for(iter in 1:2000){

  setwd(path1)

  data = read.csv(paste("sample", iter,".csv", sep=""), header=TRUE)

  #log model number to file so that any potential warnings/errors appear underneath
  message(paste("holistic model #", iter, sep=""))

  mod = lmer(y ~ x1 +
            x2 +
            x3 +
            (1|ranef1) +
            (x1|ranef2),
            data = data,
            REML = FALSE)

  #write model results to file
  setwd(path2)
  write.csv(lmer.data.extract.boot(mod, iter), paste("mod.fixef_", iter, ".csv", sep=""), row.names=TRUE) #fixed effects
  write.csv(lmer.ranef.data.extract.boot(holistic.mod, iter), paste("mod.ranef_", iter, ".csv", sep=""), row.names=FALSE)
  write.csv(lmer.optim.data.extract.boot(holistic.mod, iter), paste("mod.optim_", iter, ".csv", sep=""), row.names=TRUE)
  write.csv(as.data.frame(holistic.mod at optinfo$derivs$Hessian), paste("mod.hessian_", iter, ".csv", sep=""))
  write.csv(summary(holistic.mod)$resid, paste("mod.resid_", iter, ".csv", sep=""), row.names=FALSE)
  write(unlist(holistic.mod at optinfo$conv$lme4$messages), paste("mod.warnings_", iter, ".txt", sep=""))

  cat("Iteration", iter, "completed!\n")

}

#close log file & restore warnings stream to console
closeAllConnections()

Errors:

Warning in checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
  unable to evaluate scaled gradient
Warning in checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
  Model failed to converge: degenerate  Hessian with 1 negative eigenvalues

Error in calculation of the Satterthwaite's approximation. The output of lme4 package is returned
summary from lme4 is returned
some computational error has occurred in lmerTest




	[[alternative HTML version deleted]]


From diogro at gmail.com  Thu Mar 22 20:43:37 2018
From: diogro at gmail.com (Diogo Melo)
Date: Thu, 22 Mar 2018 16:43:37 -0300
Subject: [R-sig-ME] prevent for-loop from stopping after an lmer
 warning/error
In-Reply-To: <BLUPR02MB12173138867AC360232C8F11CFA90@BLUPR02MB1217.namprd02.prod.outlook.com>
References: <BLUPR02MB12173138867AC360232C8F11CFA90@BLUPR02MB1217.namprd02.prod.outlook.com>
Message-ID: <CALKSUOkb-90QO-QizY4LNuAPKt2Kr2MFO-B1kOHk4oJ0gKjkqg@mail.gmail.com>

You can use the try() or a try-catch block.
See here: http://adv-r.had.co.nz/Exceptions-Debugging.html


On Thu, Mar 22, 2018 at 4:18 PM, Aleksander Adam Glowka <
aglowka at stanford.edu> wrote:

> Hi all,
>
> I'm fitting mixed-effects regression models to bootstrap samples in a
> for-loop and writing a subset of model results to file. I diverted the
> stream from the console to a text file so I can keep track any warnings or
> errors. For some samples the model does not converge and a warning is
> issued. For other samples there is an error in calculation of the
> Satterthwaite's approximation. The problem is that my loop iteration is
> aborted for some reason after a warning is issued. Do you know why this
> might be happening and how I can make the loops continue to the next
> iteration after an error or a warning?
>
> Below I've included an abridged version of my script and the warnings and
> errors I get. I'd be grateful for any advice you may have!
>
> Thank you,
>
> Aleksander Glowka
> PhD Candidate
> Department of Linguistics
> Stanford University
>
> #packages
> require(lme4)
> require(lmerTest)
>
> setwd(path0)
> source("lmer-data-extract-boot-fnc.R") #selected lmer results extractor
>
> # divert messages stream to file, so you can log warnings and errors
> options(warn=1)
> wngs=file("warnings_log.txt",open="w+",blocking=TRUE)
> sink(wngs,type="message")
>
> for(iter in 1:2000){
>
>   setwd(path1)
>
>   data = read.csv(paste("sample", iter,".csv", sep=""), header=TRUE)
>
>   #log model number to file so that any potential warnings/errors appear
> underneath
>   message(paste("holistic model #", iter, sep=""))
>
>   mod = lmer(y ~ x1 +
>             x2 +
>             x3 +
>             (1|ranef1) +
>             (x1|ranef2),
>             data = data,
>             REML = FALSE)
>
>   #write model results to file
>   setwd(path2)
>   write.csv(lmer.data.extract.boot(mod, iter), paste("mod.fixef_", iter,
> ".csv", sep=""), row.names=TRUE) #fixed effects
>   write.csv(lmer.ranef.data.extract.boot(holistic.mod, iter),
> paste("mod.ranef_", iter, ".csv", sep=""), row.names=FALSE)
>   write.csv(lmer.optim.data.extract.boot(holistic.mod, iter),
> paste("mod.optim_", iter, ".csv", sep=""), row.names=TRUE)
>   write.csv(as.data.frame(holistic.mod at optinfo$derivs$Hessian),
> paste("mod.hessian_", iter, ".csv", sep=""))
>   write.csv(summary(holistic.mod)$resid, paste("mod.resid_", iter,
> ".csv", sep=""), row.names=FALSE)
>   write(unlist(holistic.mod at optinfo$conv$lme4$messages),
> paste("mod.warnings_", iter, ".txt", sep=""))
>
>   cat("Iteration", iter, "completed!\n")
>
> }
>
> #close log file & restore warnings stream to console
> closeAllConnections()
>
> Errors:
>
> Warning in checkConv(attr(opt, "derivs"), opt$par, ctrl =
> control$checkConv,  :
>   unable to evaluate scaled gradient
> Warning in checkConv(attr(opt, "derivs"), opt$par, ctrl =
> control$checkConv,  :
>   Model failed to converge: degenerate  Hessian with 1 negative eigenvalues
>
> Error in calculation of the Satterthwaite's approximation. The output of
> lme4 package is returned
> summary from lme4 is returned
> some computational error has occurred in lmerTest
>
>
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From myoung3 at uw.edu  Thu Mar 22 21:03:57 2018
From: myoung3 at uw.edu (Michael Young)
Date: Thu, 22 Mar 2018 13:03:57 -0700
Subject: [R-sig-ME] Crossover design, degrees of freedom for t test
Message-ID: <CAE9VtGiVFdJoirg7CmhGjCTKCxw01zp1VtsDVnMYH5FvvdFc5w@mail.gmail.com>

Hello,
I'm fitting a model for a crossover trial and I'm concerned that the
degrees of freedom given by lme4/lmer/lmerTest and also by nlme/lme
are wrong, or else I'm fitting the model incorrectly.

There are two treatments (U or F). Each participant was treated with
the U treatment twice on two separate days and the F treatment once on
another day. Order was randomized, and only one participant was
treated per day (so there's no overall random effect for day, but
possibly a random effect for the replicated days of the U treatment
*within* participant).

The outcome was measured on each day, immediately prior to treatment
then at a few time points after treatment. The pre-treatment
measurement allows the removal of a participant's daily variation in
that measure.

I've created a toy dataset to represent this design. This dataset has
10 participants, each observed on three different days (day A,B, C).
Within each day there were four measurements (time0,time1,time2,time3)
where time0 is the baseline (pre-treatment) measurement. Note that day
A corresponds to the F treatment and day B and C correspond to the U
treatment.

x <- structure(list(time = c("time0", "time1", "time2", "time3", "time0",
"time1", "time2", "time3", "time0", "time1", "time2", "time3",
"time0", "time1", "time2", "time3", "time0", "time1", "time2",
"time3", "time0", "time1", "time2", "time3", "time0", "time1",
"time2", "time3", "time0", "time1", "time2", "time3", "time0",
"time1", "time2", "time3", "time0", "time1", "time2", "time3",
"time0", "time1", "time2", "time3", "time0", "time1", "time2",
"time3", "time0", "time1", "time2", "time3", "time0", "time1",
"time2", "time3", "time0", "time1", "time2", "time3", "time0",
"time1", "time2", "time3", "time0", "time1", "time2", "time3",
"time0", "time1", "time2", "time3", "time0", "time1", "time2",
"time3", "time0", "time1", "time2", "time3", "time0", "time1",
"time2", "time3", "time0", "time1", "time2", "time3", "time0",
"time1", "time2", "time3", "time0", "time1", "time2", "time3",
"time0", "time1", "time2", "time3", "time0", "time1", "time2",
"time3", "time0", "time1", "time2", "time3", "time0", "time1",
"time2", "time3", "time0", "time1", "time2", "time3", "time0",
"time1", "time2", "time3"), day = c("A", "A", "A", "A", "B",
"B", "B", "B", "C", "C", "C", "C", "A", "A", "A", "A", "B", "B",
"B", "B", "C", "C", "C", "C", "A", "A", "A", "A", "B", "B", "B",
"B", "C", "C", "C", "C", "A", "A", "A", "A", "B", "B", "B", "B",
"C", "C", "C", "C", "A", "A", "A", "A", "B", "B", "B", "B", "C",
"C", "C", "C", "A", "A", "A", "A", "B", "B", "B", "B", "C", "C",
"C", "C", "A", "A", "A", "A", "B", "B", "B", "B", "C", "C", "C",
"C", "A", "A", "A", "A", "B", "B", "B", "B", "C", "C", "C", "C",
"A", "A", "A", "A", "B", "B", "B", "B", "C", "C", "C", "C", "A",
"A", "A", "A", "B", "B", "B", "B", "C", "C", "C", "C"), ID = c(1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 5L,
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 6L, 6L, 6L, 6L, 6L,
6L, 6L, 6L, 6L, 6L, 6L, 6L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L,
7L, 7L, 7L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 9L,
9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 10L, 10L, 10L, 10L,
10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L), treat = c("F", "F",
"F", "F", "U", "U", "U", "U", "U", "U", "U", "U", "F", "F", "F",
"F", "U", "U", "U", "U", "U", "U", "U", "U", "F", "F", "F", "F",
"U", "U", "U", "U", "U", "U", "U", "U", "F", "F", "F", "F", "U",
"U", "U", "U", "U", "U", "U", "U", "F", "F", "F", "F", "U", "U",
"U", "U", "U", "U", "U", "U", "F", "F", "F", "F", "U", "U", "U",
"U", "U", "U", "U", "U", "F", "F", "F", "F", "U", "U", "U", "U",
"U", "U", "U", "U", "F", "F", "F", "F", "U", "U", "U", "U", "U",
"U", "U", "U", "F", "F", "F", "F", "U", "U", "U", "U", "U", "U",
"U", "U", "F", "F", "F", "F", "U", "U", "U", "U", "U", "U", "U",
"U"), outcome = c(96.5, 94.7, 77.4, 92.4, 98.1, 102.2, 104.8,
100.9, 106, 104.8, 105.7, 114.5, 78.2, 81.1, 72.8, 82.3, 88.6,
82.1, 80.2, 79.3, 64.6, 69, 72, 75.4, 98.8, 92.7, 79.9, 82.5,
76.8, 75.9, 82.9, 86.7, 89.1, 89.1, 85.9, 82.7, 93.3, 83, 94.6,
85, 72.6, 83.1, 90.3, 94.5, 93.1, 76.4, 76.5, 81.5, 97.7, 88.9,
76.4, 81.8, 96.6, 93.5, 99.2, 97.7, 103.9, 100.6, 87.5, 86.2,
77.5, 84.7, 85.2, 89.9, 84.6, 74.6, 81.8, 86.8, 71, 75.3, 85.6,
85.1, 80.9, 80.8, 70.3, 72.3, 79.1, 67.2, 71.6, 75.7, 82.8, 74.2,
76.8, 76.1, 101, 104.5, 95.1, 105.7, 81.9, 83.3, 88.3, 92.5,
102.5, 92.6, 94, 92.6, 105.8, 103.4, 79.4, 84.9, 103.2, 100.4,
103.1, 107.6, 92.7, 90.8, 95.1, 104.6, 78.1, 96.5, 97.3, 99.7,
64.1, 73.2, 86.7, 83.2, 80.1, 78.4, 107.3, 100.5)), .Names = c("time",
"day", "ID", "treat", "outcome"), class = "data.frame", row.names = c(NA,
-120L))

#I've fit this model:
library(lme4)
library(lmerTest)
m1 <- lmer(outcome~treat*time + (1|ID/day),data=x)
summary(m1)

#or in nlme:
library(nlme)
m1_nlme <- lme(outcome~treat*time, random=~1|ID/day,data=x)
summary(m1_nlme)

I'm confused by the degrees of freedom indicated here for the t test
corresponding to the interaction effect of any specific timepoint.
This interaction is the causal effect of treatment relative to
baseline comparing treatment F with treatment U. It seems to me that
there are truly only 10 participants, so I'm not sure why lmerTest (as
well as nlme) is indicating there are 84 degrees of freedom for this
test.  At most, there are 20*3 observations for any specific
time-point by exposure interaction (because each of the 10
participants each received one baseline and one specific
post-treatment observation on three separate days).

There should be a rough correspondence here to a difference in
difference t test (which requires averaging across replicated days of
the U treatment), and that difference in difference t test has 9
degrees of freedom:

###subtract time0 (baseline) from a specific timepoint eg time2
seperately for treatments
time2F <- x[time=="time2"&treat=="F",][order(ID),]$outcome -
x[time=="time0"&treat=="F",][order(ID),]$outcome

#Since U is replicated, do this seperately for each replicate then average.
time2U_B <- x[time=="time2"&treat=="U"&day=="B",][order(ID),]$outcome -
  x[time=="time0"&treat=="U"&day=="B",][order(ID),]$outcome

time2U_C <- x[time=="time2"&treat=="U"&day=="C",][order(ID),]$outcome -
  x[time=="time0"&treat=="U"&day=="C",][order(ID),]$outcome

time2U <- rowMeans(cbind(time2U_B,time2U_C))

t.test(time2F,time2U,paired=TRUE)

The p values are different in part because the standard errors are
different but also because of the substantially different degrees of
freedom being used values.

Note that in my actual data I have even more timepoints--ie I actually
measure the outcome about 10 times after treatment on each day. This
leads to very large degrees of freedom in the mixed effects model
despite the fact that this is really only 10 participants. Does
measuring the outcome more times in the same people really increase
our ability to estimate the distribution of the test statistic for a
specific time by exposure interaction? I'm not convinced that really
makes sense, because if I had measured the outcome 1000 times after
treatment in just three individuals I would probably find a
significant effect even if just one of the participants responded to
treatment. I have no way of accounting for the fact that most
individuals might not have a different response between treatments but
I just "got lucky" and selected a single individual who does respond.


It seems like I'm implying that I'm concerned there might be
participant-specific effects. So to allow participant-specific effects
of treatment on change from baseline measurement, how would I do that?

The following gives me a warning message:

m2 <- lmer(outcome~treat*time + (1 + treat|ID/day),data=x)
#Warning message:
#In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
#  Model is nearly unidentifiable: large eigenvalue ratio
 #- Rescale variables?

summary(m2)
#Error in calculation of the Satterthwaite's approximation. The output
of lme4 package is returned
#summary from lme4 is returned
#some computational error has occurred in lmerTest

This fits in nlme, but still gives the same degrees of freedom (84, in
this case)

m2_nlme <- lme(outcome~treat*time, random=~treat|ID/day,data=x)
summary(m2_nlme)


In any case, I'm not convinced this random slope is even allowing a
participant specific effect of treatment on change from baseline so
much as a participant-specific effect of treatment day (including
observations on the treatment day which preceded treatment).


It seems that I actually want something like this, but this doesn't fit:
m3 <- lmer(outcome~treat*time + (1 + time:treat|ID/day),data=x)

I'm wondering if it's even possible to estimate participant-specific
time by treatment effects without replicates measures within each
day's timepoint?

That's as far as I've gotten. If anyone could shed some light it would
be much appreciated.

Thanks,
Michael


From rune.haubo at gmail.com  Thu Mar 22 21:16:59 2018
From: rune.haubo at gmail.com (Rune Haubo)
Date: Thu, 22 Mar 2018 21:16:59 +0100
Subject: [R-sig-ME] adjusted values
In-Reply-To: <1d58bc54-63c3-20eb-396e-c21233487645@gmail.com>
References: <CAHhX7WiN98iuXNvurH+J8WHUw5or5yQhec6C78FrdWyvNVeShA@mail.gmail.com>
 <1d58bc54-63c3-20eb-396e-c21233487645@gmail.com>
Message-ID: <CAG_uk90zQMrfquQ8PRNycdfT8iaqSKTqy+EnczKfLNSE08eY3A@mail.gmail.com>

Maybe we are confusing ourselves here. Christiano, you say that you
are using lme4, but the output looks more like that from lme (nlme
package). If the latter is the case, the lmerTest package is not
directly related to your situation.

Otherwise I agree with Ben that whether MC corrections are appropriate
depends on the context. And about the coefficients: they are not
adjusted or corrected.

Cheers
Rune

On 22 March 2018 at 19:08, Ben Bolker <bbolker at gmail.com> wrote:
>
>   summary() via lmerTest incorporates finite-size corrections, but not
> multiple-comparisons corrections.  glht does the opposite.  In this case
> your finite-size corrections are pretty much irrelevant though (in this
> context 962 \approx infinity).
>
>   By convention, people don't usually bother with MC corrections when
> they're testing pre-defined contrasts from a single model, but I don't
> know that there's hard-and-fast rule (if I were testing the effects of a
> large number of treatments within a single model I might indeed use MC;
> I probably wouldn't bother for n=4).
>
>   I don't know exactly what kind of MC correction glht does, but it
> probably shouldn't be Bonferroni (which is very conservative, and
> ignores correlations among the tests).
>
> On 18-03-22 01:28 PM, Cristiano Alessandro wrote:
>> Hi all,
>>
>> I am fitting a linear mixed model with lme4 in R. The model has a single
>> factor (des_days) with 4 levels (-1,1,14,48), and I am using random
>> intercept and slopes.
>>
>> Fixed effects: data ~ des_days
>>                  Value   Std.Error  DF   t-value p-value
>> (Intercept)  0.8274313 0.007937938 962 104.23757  0.0000
>> des_days1   -0.0026322 0.007443294 962  -0.35363  0.7237
>> des_days14  -0.0011319 0.006635512 962  -0.17058  0.8646
>> des_days48   0.0112579 0.005452614 962   2.06469  0.0392
>>
>> I can clearly use the previous results to compare the estimations of each
>> "des_day" to the intercept, using the provided t-statistics. Alternatively,
>> I could use post-hoc tests (z-statistics):
>>
>>> ph_conditional <- c("des_days1  = 0",
>>                       "des_days14  = 0",
>>                       "des_days48 = 0");
>>> lev.ph <- glht(lev.lm, linfct = ph_conditional);
>>> summary(lev.ph)
>>
>> Simultaneous Tests for General Linear Hypotheses
>>
>> Fit: lme.formula(fixed = data ~ des_days, data = data_red_trf, random
>> = ~des_days |
>>     ratID, method = "ML", na.action = na.omit, control = lCtr)
>>
>> Linear Hypotheses:
>>                  Estimate Std. Error z value Pr(>|z|)
>> des_days1 == 0  -0.002632   0.007428  -0.354    0.971
>> des_days14 == 0 -0.001132   0.006622  -0.171    0.996
>> des_days48 == 0  0.011258   0.005441   2.069    0.101
>> (Adjusted p values reported -- single-step method)
>>
>>
>> The p-values of the coefficient estimates and those of the post-hoc tests
>> differ because the latter are adjusted with Bonferroni correction. I wonder
>> whether there is any form of correction in the coefficient estimated of the
>> LMM, and which p-values are more appropriate to use.
>>
>> Thanks
>> Cristiano
>>
>>       [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From russell-lenth at uiowa.edu  Thu Mar 22 22:05:03 2018
From: russell-lenth at uiowa.edu (Lenth, Russell V)
Date: Thu, 22 Mar 2018 21:05:03 +0000
Subject: [R-sig-ME] adjusted values
Message-ID: <DM5PR04MB07624A8184B2F57AB2CAAE3EF1A90@DM5PR04MB0762.namprd04.prod.outlook.com>

Cristiano,

First, I want to make clear that you understand that (1) the intercept is really the estimate of the mean when des_days = -1, and that (2) the multiplicity correction used in the test is based on the multivariate t distribution (not Bonferroni). As such, it is less conservative than Bonferroni, and is "exact" in that if the underlying assumptions are exactly true, the probability of at least one type-I error is controlled at the desired level. (That said, the P values are actually computed using a simulation method, so they will vary a bit if you call glht again).

If you really only care about comparisons with the -1 level, I think what you have is a good solution. Some people want to use weaker control of the error rate. In that case, you can use 

   summary(glht(...), test = adjusted("desired choice")) 

(see the help file for summary.glht), which gives you other choices besides the single-step method that it defaults to. You could in fact specify adjusted("none") to get no adjustments, or adjusted("bonferroni"), adjusted("fdr"), etc. if you want to use one of the standard methods in stats::p.adjust.methods.

Often, people want to compare *all* pairs of treatments; and if that's the case, you can specify that using a call to mcp() in the linfct argument of glht.

Russ

Russell V. Lenth? -? Professor Emeritus
Department of Statistics and Actuarial Science?? 
The University of Iowa ?-? Iowa City, IA 52242? USA?? 
Voice (319)335-0712 (Dept. office)? -? FAX (319)335-3017



On 18-03-22 01:28 PM, Cristiano Alessandro wrote:
> Hi all,
> 
> I am fitting a linear mixed model with lme4 in R. The model has a 
> single factor (des_days) with 4 levels (-1,1,14,48), and I am using 
> random intercept and slopes.
> 
> Fixed effects: data ~ des_days
>                  Value   Std.Error  DF   t-value p-value
> (Intercept)  0.8274313 0.007937938 962 104.23757  0.0000
> des_days1   -0.0026322 0.007443294 962  -0.35363  0.7237
> des_days14  -0.0011319 0.006635512 962  -0.17058  0.8646
> des_days48   0.0112579 0.005452614 962   2.06469  0.0392
> 
> I can clearly use the previous results to compare the estimations of 
> each "des_day" to the intercept, using the provided t-statistics. 
> Alternatively, I could use post-hoc tests (z-statistics):
> 
>> ph_conditional <- c("des_days1  = 0",
>                       "des_days14  = 0",
>                       "des_days48 = 0");
>> lev.ph <- glht(lev.lm, linfct = ph_conditional);
>> summary(lev.ph)
> 
> Simultaneous Tests for General Linear Hypotheses
> 
> Fit: lme.formula(fixed = data ~ des_days, data = data_red_trf, random 
> = ~des_days |
>     ratID, method = "ML", na.action = na.omit, control = lCtr)
> 
> Linear Hypotheses:
>                  Estimate Std. Error z value Pr(>|z|)
> des_days1 == 0  -0.002632   0.007428  -0.354    0.971
> des_days14 == 0 -0.001132   0.006622  -0.171    0.996
> des_days48 == 0  0.011258   0.005441   2.069    0.101
> (Adjusted p values reported -- single-step method)
> 
> 
> The p-values of the coefficient estimates and those of the post-hoc 
> tests differ because the latter are adjusted with Bonferroni 
> correction. I wonder whether there is any form of correction in the 
> coefficient estimated of the LMM, and which p-values are more appropriate to use.
> 
> Thanks
> Cristiano


From cri.alessandro at gmail.com  Thu Mar 22 22:12:15 2018
From: cri.alessandro at gmail.com (Cristiano Alessandro)
Date: Thu, 22 Mar 2018 16:12:15 -0500
Subject: [R-sig-ME] adjusted values
In-Reply-To: <CAG_uk90zQMrfquQ8PRNycdfT8iaqSKTqy+EnczKfLNSE08eY3A@mail.gmail.com>
References: <CAHhX7WiN98iuXNvurH+J8WHUw5or5yQhec6C78FrdWyvNVeShA@mail.gmail.com>
 <1d58bc54-63c3-20eb-396e-c21233487645@gmail.com>
 <CAG_uk90zQMrfquQ8PRNycdfT8iaqSKTqy+EnczKfLNSE08eY3A@mail.gmail.com>
Message-ID: <CAHhX7WgFWWGqUauxY0Uo7=L59+wsZTnKBvynLD-882yiPogrJA@mail.gmail.com>

Thanks for the help, and sorry for the mix-up. Rune you are right, I am
using nlme. T

he summary of glht can do various kind of correction: the one I used to
produce the posted results is called "single-step", but I can also use
"Shaffer" and "Westfall" and other (including Bonferroni), if necessary.
The real question is whether, in this case, I should perform MC corrections
(i.e. post-hoc with glht), or I can directly take the p-values associated
the the pre-defined contrasts. I read somewhere that there are statistical
reasons for not trusting the latter. In fact, some packages for LMM do not
even provide such p-values.

Do you have suggestions here? And if I went for MC, what correction would
you use?

Thanks again
Cristiano



On Thu, Mar 22, 2018 at 3:16 PM, Rune Haubo <rune.haubo at gmail.com> wrote:

> Maybe we are confusing ourselves here. Christiano, you say that you
> are using lme4, but the output looks more like that from lme (nlme
> package). If the latter is the case, the lmerTest package is not
> directly related to your situation.
>
> Otherwise I agree with Ben that whether MC corrections are appropriate
> depends on the context. And about the coefficients: they are not
> adjusted or corrected.
>
> Cheers
> Rune
>
> On 22 March 2018 at 19:08, Ben Bolker <bbolker at gmail.com> wrote:
> >
> >   summary() via lmerTest incorporates finite-size corrections, but not
> > multiple-comparisons corrections.  glht does the opposite.  In this case
> > your finite-size corrections are pretty much irrelevant though (in this
> > context 962 \approx infinity).
> >
> >   By convention, people don't usually bother with MC corrections when
> > they're testing pre-defined contrasts from a single model, but I don't
> > know that there's hard-and-fast rule (if I were testing the effects of a
> > large number of treatments within a single model I might indeed use MC;
> > I probably wouldn't bother for n=4).
> >
> >   I don't know exactly what kind of MC correction glht does, but it
> > probably shouldn't be Bonferroni (which is very conservative, and
> > ignores correlations among the tests).
> >
> > On 18-03-22 01:28 PM, Cristiano Alessandro wrote:
> >> Hi all,
> >>
> >> I am fitting a linear mixed model with lme4 in R. The model has a single
> >> factor (des_days) with 4 levels (-1,1,14,48), and I am using random
> >> intercept and slopes.
> >>
> >> Fixed effects: data ~ des_days
> >>                  Value   Std.Error  DF   t-value p-value
> >> (Intercept)  0.8274313 0.007937938 962 104.23757  0.0000
> >> des_days1   -0.0026322 0.007443294 962  -0.35363  0.7237
> >> des_days14  -0.0011319 0.006635512 962  -0.17058  0.8646
> >> des_days48   0.0112579 0.005452614 962   2.06469  0.0392
> >>
> >> I can clearly use the previous results to compare the estimations of
> each
> >> "des_day" to the intercept, using the provided t-statistics.
> Alternatively,
> >> I could use post-hoc tests (z-statistics):
> >>
> >>> ph_conditional <- c("des_days1  = 0",
> >>                       "des_days14  = 0",
> >>                       "des_days48 = 0");
> >>> lev.ph <- glht(lev.lm, linfct = ph_conditional);
> >>> summary(lev.ph)
> >>
> >> Simultaneous Tests for General Linear Hypotheses
> >>
> >> Fit: lme.formula(fixed = data ~ des_days, data = data_red_trf, random
> >> = ~des_days |
> >>     ratID, method = "ML", na.action = na.omit, control = lCtr)
> >>
> >> Linear Hypotheses:
> >>                  Estimate Std. Error z value Pr(>|z|)
> >> des_days1 == 0  -0.002632   0.007428  -0.354    0.971
> >> des_days14 == 0 -0.001132   0.006622  -0.171    0.996
> >> des_days48 == 0  0.011258   0.005441   2.069    0.101
> >> (Adjusted p values reported -- single-step method)
> >>
> >>
> >> The p-values of the coefficient estimates and those of the post-hoc
> tests
> >> differ because the latter are adjusted with Bonferroni correction. I
> wonder
> >> whether there is any form of correction in the coefficient estimated of
> the
> >> LMM, and which p-values are more appropriate to use.
> >>
> >> Thanks
> >> Cristiano
> >>
> >>       [[alternative HTML version deleted]]
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From cri.alessandro at gmail.com  Thu Mar 22 22:18:35 2018
From: cri.alessandro at gmail.com (Cristiano Alessandro)
Date: Thu, 22 Mar 2018 16:18:35 -0500
Subject: [R-sig-ME] adjusted values
In-Reply-To: <DM5PR04MB07624A8184B2F57AB2CAAE3EF1A90@DM5PR04MB0762.namprd04.prod.outlook.com>
References: <DM5PR04MB07624A8184B2F57AB2CAAE3EF1A90@DM5PR04MB0762.namprd04.prod.outlook.com>
Message-ID: <CAHhX7Wj07C_eTW=1NfqAPwJqodLd+HdFkLw5DuFr__CkyVchZQ@mail.gmail.com>

Thanks Russ,

point (1) was clear to me; point (2) a bit less, so thanks for the hint. I
do only care about comparing with the -1 level. The question is whether I
should do multiple comparison corrections with glht (as I did so far), or
take the p-values of the estimated coefficients. Do you have suggestions
here?

Best
Cristiano

On Thu, Mar 22, 2018 at 4:05 PM, Lenth, Russell V <russell-lenth at uiowa.edu>
wrote:

> Cristiano,
>
> First, I want to make clear that you understand that (1) the intercept is
> really the estimate of the mean when des_days = -1, and that (2) the
> multiplicity correction used in the test is based on the multivariate t
> distribution (not Bonferroni). As such, it is less conservative than
> Bonferroni, and is "exact" in that if the underlying assumptions are
> exactly true, the probability of at least one type-I error is controlled at
> the desired level. (That said, the P values are actually computed using a
> simulation method, so they will vary a bit if you call glht again).
>
> If you really only care about comparisons with the -1 level, I think what
> you have is a good solution. Some people want to use weaker control of the
> error rate. In that case, you can use
>
>    summary(glht(...), test = adjusted("desired choice"))
>
> (see the help file for summary.glht), which gives you other choices
> besides the single-step method that it defaults to. You could in fact
> specify adjusted("none") to get no adjustments, or adjusted("bonferroni"),
> adjusted("fdr"), etc. if you want to use one of the standard methods in
> stats::p.adjust.methods.
>
> Often, people want to compare *all* pairs of treatments; and if that's the
> case, you can specify that using a call to mcp() in the linfct argument of
> glht.
>
> Russ
>
> Russell V. Lenth  -  Professor Emeritus
> Department of Statistics and Actuarial Science
> The University of Iowa  -  Iowa City, IA 52242  USA
> Voice (319)335-0712 (Dept. office)  -  FAX (319)335-3017
>
>
>
> On 18-03-22 01:28 PM, Cristiano Alessandro wrote:
> > Hi all,
> >
> > I am fitting a linear mixed model with lme4 in R. The model has a
> > single factor (des_days) with 4 levels (-1,1,14,48), and I am using
> > random intercept and slopes.
> >
> > Fixed effects: data ~ des_days
> >                  Value   Std.Error  DF   t-value p-value
> > (Intercept)  0.8274313 0.007937938 962 104.23757  0.0000
> > des_days1   -0.0026322 0.007443294 962  -0.35363  0.7237
> > des_days14  -0.0011319 0.006635512 962  -0.17058  0.8646
> > des_days48   0.0112579 0.005452614 962   2.06469  0.0392
> >
> > I can clearly use the previous results to compare the estimations of
> > each "des_day" to the intercept, using the provided t-statistics.
> > Alternatively, I could use post-hoc tests (z-statistics):
> >
> >> ph_conditional <- c("des_days1  = 0",
> >                       "des_days14  = 0",
> >                       "des_days48 = 0");
> >> lev.ph <- glht(lev.lm, linfct = ph_conditional);
> >> summary(lev.ph)
> >
> > Simultaneous Tests for General Linear Hypotheses
> >
> > Fit: lme.formula(fixed = data ~ des_days, data = data_red_trf, random
> > = ~des_days |
> >     ratID, method = "ML", na.action = na.omit, control = lCtr)
> >
> > Linear Hypotheses:
> >                  Estimate Std. Error z value Pr(>|z|)
> > des_days1 == 0  -0.002632   0.007428  -0.354    0.971
> > des_days14 == 0 -0.001132   0.006622  -0.171    0.996
> > des_days48 == 0  0.011258   0.005441   2.069    0.101
> > (Adjusted p values reported -- single-step method)
> >
> >
> > The p-values of the coefficient estimates and those of the post-hoc
> > tests differ because the latter are adjusted with Bonferroni
> > correction. I wonder whether there is any form of correction in the
> > coefficient estimated of the LMM, and which p-values are more
> appropriate to use.
> >
> > Thanks
> > Cristiano
>
>

	[[alternative HTML version deleted]]


From russell-lenth at uiowa.edu  Thu Mar 22 22:36:02 2018
From: russell-lenth at uiowa.edu (Lenth, Russell V)
Date: Thu, 22 Mar 2018 21:36:02 +0000
Subject: [R-sig-ME] adjusted values
In-Reply-To: <CAHhX7Wj07C_eTW=1NfqAPwJqodLd+HdFkLw5DuFr__CkyVchZQ@mail.gmail.com>
References: <DM5PR04MB07624A8184B2F57AB2CAAE3EF1A90@DM5PR04MB0762.namprd04.prod.outlook.com>
 <CAHhX7Wj07C_eTW=1NfqAPwJqodLd+HdFkLw5DuFr__CkyVchZQ@mail.gmail.com>
Message-ID: <DM5PR04MB07629D563B267E21D512BC76F1A90@DM5PR04MB0762.namprd04.prod.outlook.com>

Cristiano,

The unadjusted P values in the model summary are appropriate for model selection, but post-hoc comparisons are another objective. I, personally, would report the single-step adjusted P values that you already have obtained. In another context such as testing the contributions of massive numbers of contributors to an effect, I?d use an FDR method, because there the goal is not to avoid all type-I errors, but rather to keep from making too many false identifications.

But I know there are people who would disagree with me. In fact, I was recently kind of flamed in another forum for expressing a similar view on such issues.

Russ


From: Cristiano Alessandro <cri.alessandro at gmail.com>
Sent: Thursday, March 22, 2018 4:19 PM
To: Lenth, Russell V <russell-lenth at uiowa.edu>
Cc: r-sig-mixed-models at r-project.org
Subject: Re: adjusted values

Thanks Russ,
point (1) was clear to me; point (2) a bit less, so thanks for the hint. I do only care about comparing with the -1 level. The question is whether I should do multiple comparison corrections with glht (as I did so far), or take the p-values of the estimated coefficients. Do you have suggestions here?
Best
Cristiano

On Thu, Mar 22, 2018 at 4:05 PM, Lenth, Russell V <russell-lenth at uiowa.edu<mailto:russell-lenth at uiowa.edu>> wrote:
Cristiano,

First, I want to make clear that you understand that (1) the intercept is really the estimate of the mean when des_days = -1, and that (2) the multiplicity correction used in the test is based on the multivariate t distribution (not Bonferroni). As such, it is less conservative than Bonferroni, and is "exact" in that if the underlying assumptions are exactly true, the probability of at least one type-I error is controlled at the desired level. (That said, the P values are actually computed using a simulation method, so they will vary a bit if you call glht again).

If you really only care about comparisons with the -1 level, I think what you have is a good solution. Some people want to use weaker control of the error rate. In that case, you can use

   summary(glht(...), test = adjusted("desired choice"))

(see the help file for summary.glht), which gives you other choices besides the single-step method that it defaults to. You could in fact specify adjusted("none") to get no adjustments, or adjusted("bonferroni"), adjusted("fdr"), etc. if you want to use one of the standard methods in stats::p.adjust.methods.

Often, people want to compare *all* pairs of treatments; and if that's the case, you can specify that using a call to mcp() in the linfct argument of glht.

Russ

Russell V. Lenth  -  Professor Emeritus
Department of Statistics and Actuarial Science
The University of Iowa  -  Iowa City, IA 52242  USA
Voice (319)335-0712<tel:%28319%29335-0712> (Dept. office)  -  FAX (319)335-3017<tel:%28319%29335-3017>



On 18-03-22 01:28 PM, Cristiano Alessandro wrote:
> Hi all,
>
> I am fitting a linear mixed model with lme4 in R. The model has a
> single factor (des_days) with 4 levels (-1,1,14,48), and I am using
> random intercept and slopes.
>
> Fixed effects: data ~ des_days
>                  Value   Std.Error  DF   t-value p-value
> (Intercept)  0.8274313 0.007937938 962 104.23757  0.0000
> des_days1   -0.0026322 0.007443294 962  -0.35363  0.7237
> des_days14  -0.0011319 0.006635512 962  -0.17058  0.8646
> des_days48   0.0112579 0.005452614 962   2.06469  0.0392
>
> I can clearly use the previous results to compare the estimations of
> each "des_day" to the intercept, using the provided t-statistics.
> Alternatively, I could use post-hoc tests (z-statistics):
>
>> ph_conditional <- c("des_days1  = 0",
>                       "des_days14  = 0",
>                       "des_days48 = 0");
>> lev.ph<http://lev.ph> <- glht(lev.lm, linfct = ph_conditional);
>> summary(lev.ph<http://lev.ph>)
>
> Simultaneous Tests for General Linear Hypotheses
>
> Fit: lme.formula(fixed = data ~ des_days, data = data_red_trf, random
> = ~des_days |
>     ratID, method = "ML", na.action = na.omit, control = lCtr)
>
> Linear Hypotheses:
>                  Estimate Std. Error z value Pr(>|z|)
> des_days1 == 0  -0.002632   0.007428  -0.354    0.971
> des_days14 == 0 -0.001132   0.006622  -0.171    0.996
> des_days48 == 0  0.011258   0.005441   2.069    0.101
> (Adjusted p values reported -- single-step method)
>
>
> The p-values of the coefficient estimates and those of the post-hoc
> tests differ because the latter are adjusted with Bonferroni
> correction. I wonder whether there is any form of correction in the
> coefficient estimated of the LMM, and which p-values are more appropriate to use.
>
> Thanks
> Cristiano


	[[alternative HTML version deleted]]


From rune.haubo at gmail.com  Fri Mar 23 12:53:18 2018
From: rune.haubo at gmail.com (Rune Haubo)
Date: Fri, 23 Mar 2018 12:53:18 +0100
Subject: [R-sig-ME] New re-written version of lmerTest will soon be released
 - please test, use and comment
Message-ID: <CAG_uk91knXnCOmTGpidnpOL5X7u8hEsALXH9LdpQe-10FPFQQA@mail.gmail.com>

Dear mixed-modellers!

The lmerTest package has been re-written and the new version will soon
be released as package version ? 3.0.

The lmerTest package provides p-values in type I, II or III anova and
summary tables for linear mixed models (lmer model fits cf. lme4) via
Satterthwaite?s degrees of freedom method; a Kenward-Roger method is
also available via the pbkrtest package. Model selection and
assessment methods include step, drop1, anova-like tables for random
effects (ranova), least-square means (LS-means; lsmeans) and tests of
linear contrasts of fixed effects (contest).

The most important changes for end-users are:

1. More robust and less error-prone implementation with much better
test coverage
2. Faster evaluation of summary and anova tables - much faster for
time-consuming model fits
3. New functions include drop1(), contest(), as_lmerModLmerTest(),
show_test(), and ranova() ? see details below.

Given that the codebase has been rewritten completely from scratch it
is not unlikely that a few ?childhood diseases? are lurking in the
details. Please help us cure out such maladies by installing and
testing the new package and report bugs if you see them at
https://github.com/runehaubo/lmerTestR/issues. Comments and
suggestions are most welcome.

The new lmerTest package can be installed with
# install.packages("devtools") # run if you don't have devtools installed.
library("devtools")
install_github("runehaubo/lmerTestR")

The new user interface is almost 100% backward compatible with
previous versions (see details below).

Details of "New features" and "Changes to the user interface" are
given below -- full details are available at

https://github.com/runehaubo/lmerTestR/blob/master/pkg_notes/new_lmerTest.pdf

That document also contains technical details relevant for packages
that depend on lmerTest. We will be reaching out to the maintainers of
packages that depend on lmerTest in a separate email since a couple of
packages needs to be tweaked.


New features:


1. ranova() - ANOVA-like table of random effects via likelihood ratio
tests with methods for both lmerMod and lmerModLmerTest objects.
ranova() is similar to the old rand() and essentially produces a
drop1() table for random-effect terms. ranova() can either test
reduction of random-effect terms to simpler structures or it can test
removal of entire random-effect terms; the rules for how complex
random-effect terms are reduced is described in help(ranova).

2. drop1() - F-tests of fixed-effect terms using Satterthwaite or
Kenward-Roger methods for denominator degrees of freedom. These
?single term deletion? tables are useful for model selection and tests
of marginal terms. Compared to the likelihood ratio tests of
lme4::drop1 the F-tests and p-values of lmerTest::drop1 are more
accurate and considerably faster since no additional model fitting is
required.

3. as_lmerModLmerTest() - an explicit coerce function from class
'lmerMod' to 'lmerModLmerTest'.

4. contest() - tests of contrasts, i.e. tests of linear functions of
the fixed-effect coefficients. A user-friendly interface for tests of
contrasts with outputs either as a summary-like table of t-tests or an
anova-like table of F-tests (or a list of either). Contrasts can
optionally be tested for estimability. Contrasts are allowed to be
rank-deficient as the rank is automatically detected and appropriate
adjustments made. Methods for 'lmerModLmerTest' as well as 'lmerMod'
objects ? the latter avoids the Satterthwaite specific computations
when the Kenward-Roger method is used.

5. A show_test() function which operates on anova tables and LS-means
tables (produced by ls_means) makes it possible to see exactly which
functions of the coefficients are being tested. This is very helpful
when differences between type I, II and III anova tables are being
considered and discussed.

6. An ls_means() functions is provided as an alias for lsmeansLT. As
the name implies the function computes the so-called least-squares
means (classical Yates contrasts) as well as pairwise differences of
these.

7. lmerTest::lmer returns an object of class 'lmerModLmerTest'
(previously 'merModLmerTest') to clarify that 'lmerModLmerTest'
extends 'lmerMod' ? not 'merMod'. The merMod class includes
generalized and nonlinear mixed models and lmerTest is only designed
for linear mixed models.

8. Test coverage has been greatly improved providing confidence that
lmerTest functionality works as expected even in boundary situations
(e.g. such that anova and summary tables have the expected format even
if there are no fixed effects - and even if the intercept has been
suppressed as well.)

9. The computational approach is to let lmerTest::lmer compute the
required Hessian and derivatives needed for evaluation of degrees of
freedom and t- and F -tests. Previously these quantities were computed
following calls to anova and summary methods which meant that the
computationally intensive parts had to be evaluated anew with each
summary or anova table; the model even had to be refitted as well.
With the new implementation refitting the model is avoided and the
required Hessian and derivaties have to be computed only once per
model fit.


Changes to the user interface:


The user interface has been updated with new functionality and extra
features as described above. We have tried our best to keep the new
version backward compatible, but a few things from the old API have
been changed out of necessity:

1. In step() the argument type is now being ignored as drop1() is
always used for reduction of the fixed-effect structure. type used to
indicate the type of anova table to use for tests of fixed-effect
terms, but since it only makes sense to remove marginal terms and
drop1() provides the test of these terms it does not make sense to use
anything but drop1() to test the fixed-effect terms. Furthermore type
II and III anova tables provide identical tests of marginal terms.
Additionally, the arguments fixed.calc, lsmeans.calc,
difflsmeans.calc, and test.effs are deprecated and attempts to set
them leads to a warning; also keep.effs has been reduced to keep.

2. The documented behavior of rand/ranova has not changed, but being a
new implementation it may behave differently in ?corner? cases.

3. anova tables have a column 'F value' (previously 'F.value') being
consistent with anova.lm and anova.merMod.

4. The headers for summary and anova tables have been modernized.


Other Changes:


1. lmerTest::lmer produces an object of (S4) class 'lmerModLmerTest'
(previously 'merModLmerTest') which extends the 'lmerMod' class -
objects of class 'lmerMod' are produced by lme4::lmer.

2. anova and summary methods for objects of class 'lmerModLmerTest'
are S3 and should only be called using method dispatch, i.e. they
should be called with objects of class 'lmerModLmerTest' as the first
argument. If you have an object of class 'lmerMod' and want to compute
p-values use anova(as_lmerModLmerTest(object)) or
summary(as_lmerModLmerTest(object)). (The previous lmerTest package
defined S4 anova and summary methods.)


Rune Haubo B. Christensen
for the lmerTest authors:
Alexandra Kuznetsova, Per Bruun Brockhoff, and Rune Haubo Bojesen Christensen


From apro at unimelb.edu.au  Thu Mar 22 20:42:40 2018
From: apro at unimelb.edu.au (Andrew Robinson)
Date: Fri, 23 Mar 2018 06:42:40 +1100
Subject: [R-sig-ME] prevent for-loop from stopping after an lmer
 warning/error
In-Reply-To: <cb09672eae034f1bb91f1ba43a478485@MEXPR01MB1909.ausprd01.prod.outlook.com>
References: <cb09672eae034f1bb91f1ba43a478485@MEXPR01MB1909.ausprd01.prod.outlook.com>
Message-ID: <CAHyGmd4yKjbxG2UMnDukDMasbv1LUQ1dtoYaFKOaJ6HEUk1wHg@mail.gmail.com>

?try

?tryCatch

Cheers,

Andrew


On 23 March 2018 at 06:18, Aleksander Adam Glowka <aglowka at stanford.edu>
wrote:

> Hi all,
>
> I'm fitting mixed-effects regression models to bootstrap samples in a
> for-loop and writing a subset of model results to file. I diverted the
> stream from the console to a text file so I can keep track any warnings or
> errors. For some samples the model does not converge and a warning is
> issued. For other samples there is an error in calculation of the
> Satterthwaite's approximation. The problem is that my loop iteration is
> aborted for some reason after a warning is issued. Do you know why this
> might be happening and how I can make the loops continue to the next
> iteration after an error or a warning?
>
> Below I've included an abridged version of my script and the warnings and
> errors I get. I'd be grateful for any advice you may have!
>
> Thank you,
>
> Aleksander Glowka
> PhD Candidate
> Department of Linguistics
> Stanford University
>
> #packages
> require(lme4)
> require(lmerTest)
>
> setwd(path0)
> source("lmer-data-extract-boot-fnc.R") #selected lmer results extractor
>
> # divert messages stream to file, so you can log warnings and errors
> options(warn=1)
> wngs=file("warnings_log.txt",open="w+",blocking=TRUE)
> sink(wngs,type="message")
>
> for(iter in 1:2000){
>
>   setwd(path1)
>
>   data = read.csv(paste("sample", iter,".csv", sep=""), header=TRUE)
>
>   #log model number to file so that any potential warnings/errors appear
> underneath
>   message(paste("holistic model #", iter, sep=""))
>
>   mod = lmer(y ~ x1 +
>             x2 +
>             x3 +
>             (1|ranef1) +
>             (x1|ranef2),
>             data = data,
>             REML = FALSE)
>
>   #write model results to file
>   setwd(path2)
>   write.csv(lmer.data.extract.boot(mod, iter), paste("mod.fixef_", iter,
> ".csv", sep=""), row.names=TRUE) #fixed effects
>   write.csv(lmer.ranef.data.extract.boot(holistic.mod, iter),
> paste("mod.ranef_", iter, ".csv", sep=""), row.names=FALSE)
>   write.csv(lmer.optim.data.extract.boot(holistic.mod, iter),
> paste("mod.optim_", iter, ".csv", sep=""), row.names=TRUE)
>   write.csv(as.data.frame(holistic.mod at optinfo$derivs$Hessian),
> paste("mod.hessian_", iter, ".csv", sep=""))
>   write.csv(summary(holistic.mod)$resid, paste("mod.resid_", iter,
> ".csv", sep=""), row.names=FALSE)
>   write(unlist(holistic.mod at optinfo$conv$lme4$messages),
> paste("mod.warnings_", iter, ".txt", sep=""))
>
>   cat("Iteration", iter, "completed!\n")
>
> }
>
> #close log file & restore warnings stream to console
> closeAllConnections()
>
> Errors:
>
> Warning in checkConv(attr(opt, "derivs"), opt$par, ctrl =
> control$checkConv,  :
>   unable to evaluate scaled gradient
> Warning in checkConv(attr(opt, "derivs"), opt$par, ctrl =
> control$checkConv,  :
>   Model failed to converge: degenerate  Hessian with 1 negative eigenvalues
>
> Error in calculation of the Satterthwaite's approximation. The output of
> lme4 package is returned
> summary from lme4 is returned
> some computational error has occurred in lmerTest
>
>
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>


-- 
Andrew Robinson
Director, CEBRA, School of BioSciences
Reader & Associate Professor in Applied Statistics  Tel: (+61) 0403 138 955
School of Mathematics and Statistics                        Fax: (+61) 03
8344 4599
University of Melbourne, VIC 3010 Australia
Email: apro at unimelb.edu.au
Website: http://www.ms.unimelb.edu.au/~andrewpr

	[[alternative HTML version deleted]]


From dampfschlaghammer at gmail.com  Fri Mar 23 15:49:05 2018
From: dampfschlaghammer at gmail.com (Daniel B)
Date: Fri, 23 Mar 2018 14:49:05 +0000
Subject: [R-sig-ME] glmmTMB: model forumlation and prediction questions
In-Reply-To: <e55bd77c96d24093bb482a7802190776@DE35S004EXC1B.wp.corpintra.net>
References: <e55bd77c96d24093bb482a7802190776@DE35S004EXC1B.wp.corpintra.net>
Message-ID: <CACc9hROE4XvA40LrEAe4W8JfLb4aAuiXyfmxr28URWL3ytP44A@mail.gmail.com>

Hi,

I am trying to estimate a mixed effects model based on the assumption that
a dependent variable y is determined by a random effect x. The random
effects x exists for "groupcount" different groups (with cross correlation
between groups)

and across "n" time periods (with autocorrelation to its own lagged
values). I have included some R code, maybe this also helps in
understanding the model.



The formulation I found for glmmTMB is:



model_with_ar <- glmmTMB(y ~ ar1(timestep+0|group), data=outcome_table)

 For  comparison, I have included an alternative formulation that
disregards the AR1.

I have three important questions:



?         Does the formulation of the model ?model_with_ar? correspond to
the problem I described in the text?



?         How can I do prediction that takes into account the AR1 nature of
the process and therefore?

This means the prediction for the next, unobservd time period should not
assume that all random effects are 0, but instead take into account the
latest realization of the random effects process (given by the BLUP for the
latest time period), the AR1 parameter and the estimated process variance
and covariance. I can of course just manually extract this information, but
is there a more elegant way to do that (especially when I want to apply
this dummy model to real data with many fixed and random effects)?



?         How can I correctly identify the cross correlation between the
groups at a certain time period?

The identification of the auto correlation is easy as it is reported in the
model output. Should I do the estimation for the cross correlaton directly
based on the BLUPs for the random effects (as done in the R code)?

Thank you very much!



Regards





require(glmmTMB);require(lme4);require(tsDyn);require(data.table);require(ggplot2)



#Initialize parameters

n <- 1000  #time periods

groupcount <- 10 #number of groups

members_in_group <- 20   #members per group

epsilon_std <- 2  #Random Noise Standard Deviation



#Cross Sectional Variance Covariance Matrix

covariance <- 0.7 #Cross Sectional covariance

variance_per_group <- runif(1,0,1) #Different variance of random effect per
group

varcovmatrix <-
diag(groupcount)+covariance-covariance*diag(groupcount)+diag(groupcount)*variance_per_group



#AR1 Process Matrix (no off-diagonal elements, i.e. no correlation with
lags of other random effects)

arparameter <- 0.9 #Ar Parameter, identical per group

ar_corrmatrix <- diag(groupcount)*arparameter



#Draw realization of random effects over time and groups

re_table <-
data.table(group=as.factor(rep(1:groupcount,each=n)),timestep=as.factor(1:n),


x=as.vector(VAR.sim(B=ar_corrmatrix,n=n,include="none",varcov=varcovmatrix)))



#Draw members in group (maximum of) and select randomly  80% of portfolio
(in order to get unbalanced portfolios)

for (i in 1:members_in_group){

  if (i==1) outcome_table <- re_table[sample(1:.N,0.8*.N)]

  if (i>1) outcome_table <-
rbind(outcome_table,re_table[sample(1:.N,0.8*.N)])

}



#Add random noise

outcome_table[,y:=x+rnorm(.N)*epsilon_std]



#Old model without ar 1 random effects specification

model_old <- glmmTMB(y ~ (-1+group|timestep),
data=outcome_table,control=glmmTMBControl(optCtrl =
list(iter.max=1e4,eval.max=1e4)))



#New model with ar 1 random effects specification

model_with_ar <- glmmTMB(y ~ ar1(timestep+0|group), data=outcome_table)



#Extract random effects for both models

re_model_with_ar <- t(ranef(model_with_ar)$cond$group)

re_model_old <- ranef(model_old)$cond$timestep



#Derive "empiric" correlation matrix based on simulation

simulated_re_values <-
cor(dcast(re_table,timestep~group,value.var="x")[,!"timestep"])



#Differnce between correlation matrix based on extracted random effects and
"empiric" correlation matrix

delta_with_ar <- cor(re_model_with_ar)-simulated_re_values

delta_old <- cor(re_model_old)-simulated_re_values





sum(delta_with_ar);sum(delta_old)

sum(abs(delta_with_ar));sum(abs(delta_old))

sum(delta_with_ar^2);sum(delta_old^2)

	[[alternative HTML version deleted]]


From ijs5089 at psu.edu  Fri Mar 23 16:40:24 2018
From: ijs5089 at psu.edu (Isaac Salfer)
Date: Fri, 23 Mar 2018 11:40:24 -0400
Subject: [R-sig-ME] Setting DDFM and Covariance Structure for Mixed Models
 in R
Message-ID: <CAPzjhykF3Kbnhg=ut6pP-Rjn=+fYYtbL_FqUbknSwOLzOkwG_A@mail.gmail.com>

Hello,

I was wondering if anyone could help solve a problem I am having with
repeated measures mixed models in R.

In our field, we frequently use repeated measures analysis and tend to use
latin-square and crossover designs often.  I have been trying to find a way
to run repeated measures mixed models that use both an autoregressive
covariance structure and Kenward-Roger denominator degrees of freedom
estimates. Unfortunately, I cannot find an R function that will allow me to
do this.  The lmer function with the lmerTest function will allow me to
adjust ddfm using the Kenward-Roger method, and the lme function (nlme
package) will let me set a correlation structure, but I have not found a
way to do both in the same model. Do you have any potential solutions for
this.

Thank you,

Isaac
---
Isaac Salfer, M.S.
Graduate Assistant
The Pennsylvania State University
(320) 296-1357

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Fri Mar 23 18:42:47 2018
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 23 Mar 2018 13:42:47 -0400
Subject: [R-sig-ME] prevent for-loop from stopping after an lmer
 warning/error
In-Reply-To: <CAHyGmd4yKjbxG2UMnDukDMasbv1LUQ1dtoYaFKOaJ6HEUk1wHg@mail.gmail.com>
References: <cb09672eae034f1bb91f1ba43a478485@MEXPR01MB1909.ausprd01.prod.outlook.com>
 <CAHyGmd4yKjbxG2UMnDukDMasbv1LUQ1dtoYaFKOaJ6HEUk1wHg@mail.gmail.com>
Message-ID: <CABghstRoZ=BkUzrvLJgv+yEZzF6x5GJdDVN9+VVjroMhu9JXqw@mail.gmail.com>

Is your loop really stopping after warnings (that would be
surprising), not just after errors?

On Thu, Mar 22, 2018 at 3:42 PM, Andrew Robinson <apro at unimelb.edu.au> wrote:
> ?try
>
> ?tryCatch
>
> Cheers,
>
> Andrew
>
>
> On 23 March 2018 at 06:18, Aleksander Adam Glowka <aglowka at stanford.edu>
> wrote:
>
>> Hi all,
>>
>> I'm fitting mixed-effects regression models to bootstrap samples in a
>> for-loop and writing a subset of model results to file. I diverted the
>> stream from the console to a text file so I can keep track any warnings or
>> errors. For some samples the model does not converge and a warning is
>> issued. For other samples there is an error in calculation of the
>> Satterthwaite's approximation. The problem is that my loop iteration is
>> aborted for some reason after a warning is issued. Do you know why this
>> might be happening and how I can make the loops continue to the next
>> iteration after an error or a warning?
>>
>> Below I've included an abridged version of my script and the warnings and
>> errors I get. I'd be grateful for any advice you may have!
>>
>> Thank you,
>>
>> Aleksander Glowka
>> PhD Candidate
>> Department of Linguistics
>> Stanford University
>>
>> #packages
>> require(lme4)
>> require(lmerTest)
>>
>> setwd(path0)
>> source("lmer-data-extract-boot-fnc.R") #selected lmer results extractor
>>
>> # divert messages stream to file, so you can log warnings and errors
>> options(warn=1)
>> wngs=file("warnings_log.txt",open="w+",blocking=TRUE)
>> sink(wngs,type="message")
>>
>> for(iter in 1:2000){
>>
>>   setwd(path1)
>>
>>   data = read.csv(paste("sample", iter,".csv", sep=""), header=TRUE)
>>
>>   #log model number to file so that any potential warnings/errors appear
>> underneath
>>   message(paste("holistic model #", iter, sep=""))
>>
>>   mod = lmer(y ~ x1 +
>>             x2 +
>>             x3 +
>>             (1|ranef1) +
>>             (x1|ranef2),
>>             data = data,
>>             REML = FALSE)
>>
>>   #write model results to file
>>   setwd(path2)
>>   write.csv(lmer.data.extract.boot(mod, iter), paste("mod.fixef_", iter,
>> ".csv", sep=""), row.names=TRUE) #fixed effects
>>   write.csv(lmer.ranef.data.extract.boot(holistic.mod, iter),
>> paste("mod.ranef_", iter, ".csv", sep=""), row.names=FALSE)
>>   write.csv(lmer.optim.data.extract.boot(holistic.mod, iter),
>> paste("mod.optim_", iter, ".csv", sep=""), row.names=TRUE)
>>   write.csv(as.data.frame(holistic.mod at optinfo$derivs$Hessian),
>> paste("mod.hessian_", iter, ".csv", sep=""))
>>   write.csv(summary(holistic.mod)$resid, paste("mod.resid_", iter,
>> ".csv", sep=""), row.names=FALSE)
>>   write(unlist(holistic.mod at optinfo$conv$lme4$messages),
>> paste("mod.warnings_", iter, ".txt", sep=""))
>>
>>   cat("Iteration", iter, "completed!\n")
>>
>> }
>>
>> #close log file & restore warnings stream to console
>> closeAllConnections()
>>
>> Errors:
>>
>> Warning in checkConv(attr(opt, "derivs"), opt$par, ctrl =
>> control$checkConv,  :
>>   unable to evaluate scaled gradient
>> Warning in checkConv(attr(opt, "derivs"), opt$par, ctrl =
>> control$checkConv,  :
>>   Model failed to converge: degenerate  Hessian with 1 negative eigenvalues
>>
>> Error in calculation of the Satterthwaite's approximation. The output of
>> lme4 package is returned
>> summary from lme4 is returned
>> some computational error has occurred in lmerTest
>>
>>
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>
>
> --
> Andrew Robinson
> Director, CEBRA, School of BioSciences
> Reader & Associate Professor in Applied Statistics  Tel: (+61) 0403 138 955
> School of Mathematics and Statistics                        Fax: (+61) 03
> 8344 4599
> University of Melbourne, VIC 3010 Australia
> Email: apro at unimelb.edu.au
> Website: http://www.ms.unimelb.edu.au/~andrewpr
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From Louise.M.Ryan at uts.edu.au  Fri Mar 23 20:27:46 2018
From: Louise.M.Ryan at uts.edu.au (Louise Ryan)
Date: Fri, 23 Mar 2018 19:27:46 +0000
Subject: [R-sig-ME] Question about gls
Message-ID: <4EC216B1-608B-48D3-86E1-9CF1756275F5@uts.edu.au>

Hi there,

I am using your function gls in R to fit some AR models (it is part of a larger thing I am trying to do). I can see from the printed output that the function is estimating the AR parameter.  But I CANNOT for the life of me figure out how to extract this parameter so I can use it for something else.

Here?s a bit of code that simulates some data and runs the model.

#####
# Set true parameter values:
beta0True <- 0.3
beta1True <- 1.6
sigmaTrue <- 0.5
rhoTrue <- 0.2

# Generate data:
set.seed(1)
n <- 500
x <- seq(0,1,length=n)
epsilon <- rep(NA,n)
epsilon[1] <- sigmaTrue*rnorm(1)
for (i in 2:n) {epsilon[i] <- rhoTrue*epsilon[i-1] + sigmaTrue*rnorm(1)}
y <- beta0True + beta1True*x + epsilon

fit.gls <- gls(y~x,  correlation=corAR1())
print(summary(fit.gls))
###########################

For my little simulation, the parameter Phi is being estimated as .1748786.

I have looked at attributes(fit.gls) and just cannot figure out where this estimate is stored!

I?d appreciate your help!

Louise
UTS CRICOS Provider Code: 00099F DISCLAIMER: This email message and any accompanying attachments may contain confidential information. If you are not the intended recipient, do not read, use, disseminate, distribute or copy this message or attachments. If you have received this message in error, please notify the sender immediately and delete this message. Any views expressed in this message are those of the individual sender, except where the sender expressly, and with authority, states them to be the views of the University of Technology Sydney. Before opening any attachments, please check them for viruses and defects. Think. Green. Do. Please consider the environment before printing this email.

From agalecki at umich.edu  Fri Mar 23 20:58:11 2018
From: agalecki at umich.edu (Andrzej Galecki)
Date: Fri, 23 Mar 2018 15:58:11 -0400
Subject: [R-sig-ME] Question about gls
In-Reply-To: <4EC216B1-608B-48D3-86E1-9CF1756275F5@uts.edu.au>
References: <4EC216B1-608B-48D3-86E1-9CF1756275F5@uts.edu.au>
Message-ID: <CA+XOvOTtW8L_yVpteRdsVg0iPS1v902jwYAf1TiR95H4Pt=azA@mail.gmail.com>

Hi Louise,

One possible way ...

mSt <- fit.gls$modelStruct
cSt <- mSt$corStruct
coef(cSt, unconstrained = FALSE)

#       Phi
# 0.1748786

Best wishes

Andrzej




On Fri, Mar 23, 2018 at 3:27 PM, Louise Ryan <Louise.M.Ryan at uts.edu.au>
wrote:

> Hi there,
>
> I am using your function gls in R to fit some AR models (it is part of a
> larger thing I am trying to do). I can see from the printed output that the
> function is estimating the AR parameter.  But I CANNOT for the life of me
> figure out how to extract this parameter so I can use it for something else.
>
> Here?s a bit of code that simulates some data and runs the model.
>
> #####
> # Set true parameter values:
> beta0True <- 0.3
> beta1True <- 1.6
> sigmaTrue <- 0.5
> rhoTrue <- 0.2
>
> # Generate data:
> set.seed(1)
> n <- 500
> x <- seq(0,1,length=n)
> epsilon <- rep(NA,n)
> epsilon[1] <- sigmaTrue*rnorm(1)
> for (i in 2:n) {epsilon[i] <- rhoTrue*epsilon[i-1] + sigmaTrue*rnorm(1)}
> y <- beta0True + beta1True*x + epsilon
>
> fit.gls <- gls(y~x,  correlation=corAR1())
> print(summary(fit.gls))
> ###########################
>
> For my little simulation, the parameter Phi is being estimated as .1748786.
>
> I have looked at attributes(fit.gls) and just cannot figure out where this
> estimate is stored!
>
> I?d appreciate your help!
>
> Louise
> UTS CRICOS Provider Code: 00099F DISCLAIMER: This email message and any
> accompanying attachments may contain confidential information. If you are
> not the intended recipient, do not read, use, disseminate, distribute or
> copy this message or attachments. If you have received this message in
> error, please notify the sender immediately and delete this message. Any
> views expressed in this message are those of the individual sender, except
> where the sender expressly, and with authority, states them to be the views
> of the University of Technology Sydney. Before opening any attachments,
> please check them for viruses and defects. Think. Green. Do. Please
> consider the environment before printing this email.
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Fri Mar 23 22:52:34 2018
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sat, 24 Mar 2018 10:52:34 +1300
Subject: [R-sig-ME] [FORGED] Re:  Question about gls
In-Reply-To: <CA+XOvOTtW8L_yVpteRdsVg0iPS1v902jwYAf1TiR95H4Pt=azA@mail.gmail.com>
References: <4EC216B1-608B-48D3-86E1-9CF1756275F5@uts.edu.au>
 <CA+XOvOTtW8L_yVpteRdsVg0iPS1v902jwYAf1TiR95H4Pt=azA@mail.gmail.com>
Message-ID: <ff98e7c6-0b02-fa91-6e47-26773eb743e4@auckland.ac.nz>


On 24/03/18 08:58, Andrzej Galecki wrote:

> Hi Louise,
> 
> One possible way ...
> 
> mSt <- fit.gls$modelStruct
> cSt <- mSt$corStruct
> coef(cSt, unconstrained = FALSE)
> 
> #       Phi
> # 0.1748786

Not exactly obvious, but, is it?  How on earth would one ever figure 
this out, except by appealing to r-sig-mixed-models?

Looking at str(fit.gls) one sees that there is a (list) component 
"modelStruct" and that this component in turn has a component 
"corStruct".  If one is an optimist, one might try

     fit.gls$modelStruct$corStruct

which (mirabile dictu!) gives:

Correlation structure of class corAR1 representing
       Phi
0.1748786

Again if one is an optimist, one might try stripping away all the 
unwanted baggage by doing

     as.vector(fit.gls$modelStruct$corStruct)

giving:

[1] 0.3533897

Bingo.

Still it's all pretty obscure.  And typical of the obfuscation that 
results from using S4 classes and methods.

cheers,

Rolf

> 
> On Fri, Mar 23, 2018 at 3:27 PM, Louise Ryan <Louise.M.Ryan at uts.edu.au>
> wrote:
> 
>> Hi there,
>>
>> I am using your function gls in R to fit some AR models (it is part of a
>> larger thing I am trying to do). I can see from the printed output that the
>> function is estimating the AR parameter.  But I CANNOT for the life of me
>> figure out how to extract this parameter so I can use it for something else.
>>
>> Here?s a bit of code that simulates some data and runs the model.
>>
>> #####
>> # Set true parameter values:
>> beta0True <- 0.3
>> beta1True <- 1.6
>> sigmaTrue <- 0.5
>> rhoTrue <- 0.2
>>
>> # Generate data:
>> set.seed(1)
>> n <- 500
>> x <- seq(0,1,length=n)
>> epsilon <- rep(NA,n)
>> epsilon[1] <- sigmaTrue*rnorm(1)
>> for (i in 2:n) {epsilon[i] <- rhoTrue*epsilon[i-1] + sigmaTrue*rnorm(1)}
>> y <- beta0True + beta1True*x + epsilon
>>
>> fit.gls <- gls(y~x,  correlation=corAR1())
>> print(summary(fit.gls))
>> ###########################
>>
>> For my little simulation, the parameter Phi is being estimated as .1748786.
>>
>> I have looked at attributes(fit.gls) and just cannot figure out where this
>> estimate is stored!
>>
>> I?d appreciate your help!


From aglowka at stanford.edu  Fri Mar 23 22:57:53 2018
From: aglowka at stanford.edu (Aleksander Adam Glowka)
Date: Fri, 23 Mar 2018 21:57:53 +0000
Subject: [R-sig-ME] prevent for-loop from stopping after an lmer
 warning/error
In-Reply-To: <CABghstRoZ=BkUzrvLJgv+yEZzF6x5GJdDVN9+VVjroMhu9JXqw@mail.gmail.com>
References: <cb09672eae034f1bb91f1ba43a478485@MEXPR01MB1909.ausprd01.prod.outlook.com>
 <CAHyGmd4yKjbxG2UMnDukDMasbv1LUQ1dtoYaFKOaJ6HEUk1wHg@mail.gmail.com>,
 <CABghstRoZ=BkUzrvLJgv+yEZzF6x5GJdDVN9+VVjroMhu9JXqw@mail.gmail.com>
Message-ID: <BLUPR02MB12170598732C3E9863431B11CFA80@BLUPR02MB1217.namprd02.prod.outlook.com>

Hi Ben,


Thank you for pointing this out. Indeed the loops only stops after errors, not warnings.


By the way, I am still stuck with my issue. I've made some progress with using tryCatch() as suggested, but still have not resolved my issue. As far as I can tell, currently there are two issues with my code. First, when I query the returned exception in `tryCatch()`, e.g. `poss.err.mod1` I get the following error:

    <simpleError in tryCatchList(expr, classes, parentenv, handlers): argument "expr" is missing, with no default>

Still, the warnings are correctly written to file, which is puzzling. Second, when no error is detected, the code seems to be ignored (i.e. no model summaries are written to file). So the loop is running vacuously, skipping errors but apparently handling them and doing nothing else. If anyone has any advice on how to debug this, please let me know!

    # divert console stream to file
    options(warn=1)
    wngs=file("warnings_log.txt",open="w+",blocking=TRUE)
    sink(wngs,type="message")

    for(iter in 1:1000){

      data = read.csv(paste("sample", iter,".csv", sep=""), header=TRUE)

      #error handling case #1
      poss.err.mod1 = tryCatch(

        lmer(y ~ x1 + (1|ranef), data = data, REML = FALSE), #try part
        error=function(e) e #catch part
      )

      #error handling case #2
      poss.err.mod2 = tryCatch(

        lmer(y ~ x1 + x2 + (1|ranef), data = data, REML = FALSE), #try part
        error=function(e) e #catch part
      )

      #real work #1
      if(!inherits(poss.err.mod1, "error")){

        mod1 = lmer(y ~ x1 + (1|ranef1), data = data, REML = FALSE)
        write.csv(summmary$mod2, paste("mod2.sum_", iter, ".csv", sep="")

      }else{

        write(unlist(mod1 at optinfo$conv$lme4$messages), paste("mod1.errors_", iter, ".txt", sep=""))
      }

      #real work #2
      if(!inherits(poss.err.mod2, "error")){

        mod2 = lmer(y ~ x1 + x2 + (1|ranef1), data = data, REML = FALSE)
        write.csv(summmary$mod2, paste("mod2.sum_", iter, ".csv",)

      }else{

        write(unlist(mod2 at optinfo$conv$lme4$messages), paste("mod1.errors_", iter, ".txt", sep=""))
      }

      cat("Iteration", iter, "completed!\n")
    }

    #close log file & restore warnings stream to console
    closeAllConnections()

________________________________
From: Ben Bolker <bbolker at gmail.com>
Sent: Friday, March 23, 2018 10:42:47 AM
To: Andrew Robinson
Cc: Aleksander Adam Glowka; Help Mixed Models
Subject: Re: [R-sig-ME] prevent for-loop from stopping after an lmer warning/error

Is your loop really stopping after warnings (that would be
surprising), not just after errors?

On Thu, Mar 22, 2018 at 3:42 PM, Andrew Robinson <apro at unimelb.edu.au> wrote:
> ?try
>
> ?tryCatch
>
> Cheers,
>
> Andrew
>
>
> On 23 March 2018 at 06:18, Aleksander Adam Glowka <aglowka at stanford.edu>
> wrote:
>
>> Hi all,
>>
>> I'm fitting mixed-effects regression models to bootstrap samples in a
>> for-loop and writing a subset of model results to file. I diverted the
>> stream from the console to a text file so I can keep track any warnings or
>> errors. For some samples the model does not converge and a warning is
>> issued. For other samples there is an error in calculation of the
>> Satterthwaite's approximation. The problem is that my loop iteration is
>> aborted for some reason after a warning is issued. Do you know why this
>> might be happening and how I can make the loops continue to the next
>> iteration after an error or a warning?
>>
>> Below I've included an abridged version of my script and the warnings and
>> errors I get. I'd be grateful for any advice you may have!
>>
>> Thank you,
>>
>> Aleksander Glowka
>> PhD Candidate
>> Department of Linguistics
>> Stanford University
>>
>> #packages
>> require(lme4)
>> require(lmerTest)
>>
>> setwd(path0)
>> source("lmer-data-extract-boot-fnc.R") #selected lmer results extractor
>>
>> # divert messages stream to file, so you can log warnings and errors
>> options(warn=1)
>> wngs=file("warnings_log.txt",open="w+",blocking=TRUE)
>> sink(wngs,type="message")
>>
>> for(iter in 1:2000){
>>
>>   setwd(path1)
>>
>>   data = read.csv(paste("sample", iter,".csv", sep=""), header=TRUE)
>>
>>   #log model number to file so that any potential warnings/errors appear
>> underneath
>>   message(paste("holistic model #", iter, sep=""))
>>
>>   mod = lmer(y ~ x1 +
>>             x2 +
>>             x3 +
>>             (1|ranef1) +
>>             (x1|ranef2),
>>             data = data,
>>             REML = FALSE)
>>
>>   #write model results to file
>>   setwd(path2)
>>   write.csv(lmer.data.extract.boot(mod, iter), paste("mod.fixef_", iter,
>> ".csv", sep=""), row.names=TRUE) #fixed effects
>>   write.csv(lmer.ranef.data.extract.boot(holistic.mod, iter),
>> paste("mod.ranef_", iter, ".csv", sep=""), row.names=FALSE)
>>   write.csv(lmer.optim.data.extract.boot(holistic.mod, iter),
>> paste("mod.optim_", iter, ".csv", sep=""), row.names=TRUE)
>>   write.csv(as.data.frame(holistic.mod at optinfo$derivs$Hessian),
>> paste("mod.hessian_", iter, ".csv", sep=""))
>>   write.csv(summary(holistic.mod)$resid, paste("mod.resid_", iter,
>> ".csv", sep=""), row.names=FALSE)
>>   write(unlist(holistic.mod at optinfo$conv$lme4$messages),
>> paste("mod.warnings_", iter, ".txt", sep=""))
>>
>>   cat("Iteration", iter, "completed!\n")
>>
>> }
>>
>> #close log file & restore warnings stream to console
>> closeAllConnections()
>>
>> Errors:
>>
>> Warning in checkConv(attr(opt, "derivs"), opt$par, ctrl =
>> control$checkConv,  :
>>   unable to evaluate scaled gradient
>> Warning in checkConv(attr(opt, "derivs"), opt$par, ctrl =
>> control$checkConv,  :
>>   Model failed to converge: degenerate  Hessian with 1 negative eigenvalues
>>
>> Error in calculation of the Satterthwaite's approximation. The output of
>> lme4 package is returned
>> summary from lme4 is returned
>> some computational error has occurred in lmerTest
>>
>>
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>
>
> --
> Andrew Robinson
> Director, CEBRA, School of BioSciences
> Reader & Associate Professor in Applied Statistics  Tel: (+61) 0403 138 955
> School of Mathematics and Statistics                        Fax: (+61) 03
> 8344 4599
> University of Melbourne, VIC 3010 Australia
> Email: apro at unimelb.edu.au
> Website: http://www.ms.unimelb.edu.au/~andrewpr
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Fri Mar 23 23:30:17 2018
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sat, 24 Mar 2018 11:30:17 +1300
Subject: [R-sig-ME] [FORGED] Re:  Question about gls --- whoops!!!
In-Reply-To: <ff98e7c6-0b02-fa91-6e47-26773eb743e4@auckland.ac.nz>
References: <4EC216B1-608B-48D3-86E1-9CF1756275F5@uts.edu.au>
 <CA+XOvOTtW8L_yVpteRdsVg0iPS1v902jwYAf1TiR95H4Pt=azA@mail.gmail.com>
 <ff98e7c6-0b02-fa91-6e47-26773eb743e4@auckland.ac.nz>
Message-ID: <dcc27775-14d3-ca0e-e380-3ed09060d909@auckland.ac.nz>

On 24/03/18 10:52, Rolf Turner wrote:
> 
> On 24/03/18 08:58, Andrzej Galecki wrote:
> 
>> Hi Louise,
>>
>> One possible way ...
>>
>> mSt <- fit.gls$modelStruct
>> cSt <- mSt$corStruct
>> coef(cSt, unconstrained = FALSE)
>>
>> #?????? Phi
>> # 0.1748786
> 
> Not exactly obvious, but, is it?? How on earth would one ever figure 
> this out, except by appealing to r-sig-mixed-models?
> 
> Looking at str(fit.gls) one sees that there is a (list) component 
> "modelStruct" and that this component in turn has a component 
> "corStruct".? If one is an optimist, one might try
> 
>  ??? fit.gls$modelStruct$corStruct
> 
> which (mirabile dictu!) gives:
> 
> Correlation structure of class corAR1 representing
>  ????? Phi
> 0.1748786
> 
> Again if one is an optimist, one might try stripping away all the 
> unwanted baggage by doing
> 
>  ??? as.vector(fit.gls$modelStruct$corStruct)
> 
> giving:
> 
> [1] 0.3533897
> 
> Bingo.

Nope!  ***NOT*** bingo!!!  Louise just pointed out to me that what I got 
by applying as.vector(), i.e. 0.3533897, is not the same as the number 
one gets by just typing fit.gls$modelStruct$corStruct, which is 
0.1748786 --- which is what Andrzej's approach gives (and which would
appear to be the right answer).  Bit of a duhhh on my part.

Setting unconstrained=FALSE as in Andrzej's approach seems to be 
crucial.  I missed that bit ....

But it still mystifies me why as.vector() doesn't give the same numeric 
value as is obtained from just printing the object in question.  Also
looking at the code of nlme:::coef.corStruct I would have thought that
this function would simply throw an error when unconstrained is set to 
FALSE.  (Just type "nlme:::coef.corStruct" and you'll see what I mean.)

If I set foo <- nlme:::coef.corStruct and then do

     foo(fit.gls$modelStruct$corStruct)

I do indeed get an error.  WTF?

There would appear to be no way for the results to be different (look
at the code) --- but different they are.

But that sort of nonsense is to be expected when S4 classes and methods 
are involved in any way.

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From bates at stat.wisc.edu  Sat Mar 24 00:21:07 2018
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 23 Mar 2018 23:21:07 +0000
Subject: [R-sig-ME] [FORGED] Re: Question about gls --- whoops!!!
In-Reply-To: <16098_1521844237_0P6200HQXEIYCT60_dcc27775-14d3-ca0e-e380-3ed09060d909@auckland.ac.nz>
References: <4EC216B1-608B-48D3-86E1-9CF1756275F5@uts.edu.au>
 <CA+XOvOTtW8L_yVpteRdsVg0iPS1v902jwYAf1TiR95H4Pt=azA@mail.gmail.com>
 <ff98e7c6-0b02-fa91-6e47-26773eb743e4@auckland.ac.nz>
 <16098_1521844237_0P6200HQXEIYCT60_dcc27775-14d3-ca0e-e380-3ed09060d909@auckland.ac.nz>
Message-ID: <CAO7JsnQneUgAt=Xxzc4evS1G129u3e00OZoUWke_hb=a6Vj3dQ@mail.gmail.com>

Your comment about S4 classes and methods is misdirected. The gls function
is in the nlme package which uses S3 only.

On Fri, Mar 23, 2018, 17:30 Rolf Turner <r.turner at auckland.ac.nz> wrote:

> On 24/03/18 10:52, Rolf Turner wrote:
> >
> > On 24/03/18 08:58, Andrzej Galecki wrote:
> >
> >> Hi Louise,
> >>
> >> One possible way ...
> >>
> >> mSt <- fit.gls$modelStruct
> >> cSt <- mSt$corStruct
> >> coef(cSt, unconstrained = FALSE)
> >>
> >> #       Phi
> >> # 0.1748786
> >
> > Not exactly obvious, but, is it?  How on earth would one ever figure
> > this out, except by appealing to r-sig-mixed-models?
> >
> > Looking at str(fit.gls) one sees that there is a (list) component
> > "modelStruct" and that this component in turn has a component
> > "corStruct".  If one is an optimist, one might try
> >
> >      fit.gls$modelStruct$corStruct
> >
> > which (mirabile dictu!) gives:
> >
> > Correlation structure of class corAR1 representing
> >        Phi
> > 0.1748786
> >
> > Again if one is an optimist, one might try stripping away all the
> > unwanted baggage by doing
> >
> >      as.vector(fit.gls$modelStruct$corStruct)
> >
> > giving:
> >
> > [1] 0.3533897
> >
> > Bingo.
>
> Nope!  ***NOT*** bingo!!!  Louise just pointed out to me that what I got
> by applying as.vector(), i.e. 0.3533897, is not the same as the number
> one gets by just typing fit.gls$modelStruct$corStruct, which is
> 0.1748786 --- which is what Andrzej's approach gives (and which would
> appear to be the right answer).  Bit of a duhhh on my part.
>
> Setting unconstrained=FALSE as in Andrzej's approach seems to be
> crucial.  I missed that bit ....
>
> But it still mystifies me why as.vector() doesn't give the same numeric
> value as is obtained from just printing the object in question.  Also
> looking at the code of nlme:::coef.corStruct I would have thought that
> this function would simply throw an error when unconstrained is set to
> FALSE.  (Just type "nlme:::coef.corStruct" and you'll see what I mean.)
>
> If I set foo <- nlme:::coef.corStruct and then do
>
>      foo(fit.gls$modelStruct$corStruct)
>
> I do indeed get an error.  WTF?
>
> There would appear to be no way for the results to be different (look
> at the code) --- but different they are.
>
> But that sort of nonsense is to be expected when S4 classes and methods
> are involved in any way.
>
> cheers,
>
> Rolf
>
> --
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Sat Mar 24 00:39:20 2018
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sat, 24 Mar 2018 12:39:20 +1300
Subject: [R-sig-ME] [FORGED] Re: Question about gls --- whoops!!!
In-Reply-To: <CAO7JsnQneUgAt=Xxzc4evS1G129u3e00OZoUWke_hb=a6Vj3dQ@mail.gmail.com>
References: <4EC216B1-608B-48D3-86E1-9CF1756275F5@uts.edu.au>
 <CA+XOvOTtW8L_yVpteRdsVg0iPS1v902jwYAf1TiR95H4Pt=azA@mail.gmail.com>
 <ff98e7c6-0b02-fa91-6e47-26773eb743e4@auckland.ac.nz>
 <16098_1521844237_0P6200HQXEIYCT60_dcc27775-14d3-ca0e-e380-3ed09060d909@auckland.ac.nz>
 <CAO7JsnQneUgAt=Xxzc4evS1G129u3e00OZoUWke_hb=a6Vj3dQ@mail.gmail.com>
Message-ID: <3c5ff855-7c36-1b41-a8e0-1f1becc9c003@auckland.ac.nz>


On 24/03/18 12:21, Douglas Bates wrote:

> Your comment about S4 classes and methods is misdirected. The gls 
> function is in the nlme package which uses S3 only.

Okay Doug; mea culpa.

But then I must say that you have succeeded in obfuscating your code to 
a degree that I would not have thought possible without the assistance 
of S4 classes and methods! :-)

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From bbolker at gmail.com  Sat Mar 24 02:56:54 2018
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 23 Mar 2018 21:56:54 -0400
Subject: [R-sig-ME] prevent for-loop from stopping after an lmer
 warning/error
In-Reply-To: <BLUPR02MB12170598732C3E9863431B11CFA80@BLUPR02MB1217.namprd02.prod.outlook.com>
References: <cb09672eae034f1bb91f1ba43a478485@MEXPR01MB1909.ausprd01.prod.outlook.com>
 <CAHyGmd4yKjbxG2UMnDukDMasbv1LUQ1dtoYaFKOaJ6HEUk1wHg@mail.gmail.com>
 <CABghstRoZ=BkUzrvLJgv+yEZzF6x5GJdDVN9+VVjroMhu9JXqw@mail.gmail.com>
 <BLUPR02MB12170598732C3E9863431B11CFA80@BLUPR02MB1217.namprd02.prod.outlook.com>
Message-ID: <CABghstRC8SXCCsZ5VcrF1OBNq=4RE_C7_kiGuEOXLNsf9obFcQ@mail.gmail.com>

It's possible that lmerTest is doing slightly weird things with trying
to catch the errors itself.

Rune Haubo is working on a revamped version of lmerTest
(https://rdrr.io/github/runehaubo/lmerTestR/); it *might* be worth
taking a try at installing that to see if it behaves better?

On Fri, Mar 23, 2018 at 5:57 PM, Aleksander Adam Glowka
<aglowka at stanford.edu> wrote:
> Hi Ben,
>
>
> Thank you for pointing this out. Indeed the loops only stops after errors, not warnings.
>
>
> By the way, I am still stuck with my issue. I've made some progress with using tryCatch() as suggested, but still have not resolved my issue. As far as I can tell, currently there are two issues with my code. First, when I query the returned exception in `tryCatch()`, e.g. `poss.err.mod1` I get the following error:
>
>     <simpleError in tryCatchList(expr, classes, parentenv, handlers): argument "expr" is missing, with no default>
>
> Still, the warnings are correctly written to file, which is puzzling. Second, when no error is detected, the code seems to be ignored (i.e. no model summaries are written to file). So the loop is running vacuously, skipping errors but apparently handling them and doing nothing else. If anyone has any advice on how to debug this, please let me know!
>
>     # divert console stream to file
>     options(warn=1)
>     wngs=file("warnings_log.txt",open="w+",blocking=TRUE)
>     sink(wngs,type="message")
>
>     for(iter in 1:1000){
>
>       data = read.csv(paste("sample", iter,".csv", sep=""), header=TRUE)
>
>       #error handling case #1
>       poss.err.mod1 = tryCatch(
>
>         lmer(y ~ x1 + (1|ranef), data = data, REML = FALSE), #try part
>         error=function(e) e #catch part
>       )
>
>       #error handling case #2
>       poss.err.mod2 = tryCatch(
>
>         lmer(y ~ x1 + x2 + (1|ranef), data = data, REML = FALSE), #try part
>         error=function(e) e #catch part
>       )
>
>       #real work #1
>       if(!inherits(poss.err.mod1, "error")){
>
>         mod1 = lmer(y ~ x1 + (1|ranef1), data = data, REML = FALSE)
>         write.csv(summmary$mod2, paste("mod2.sum_", iter, ".csv", sep="")
>
>       }else{
>
>         write(unlist(mod1 at optinfo$conv$lme4$messages), paste("mod1.errors_", iter, ".txt", sep=""))
>       }
>
>       #real work #2
>       if(!inherits(poss.err.mod2, "error")){
>
>         mod2 = lmer(y ~ x1 + x2 + (1|ranef1), data = data, REML = FALSE)
>         write.csv(summmary$mod2, paste("mod2.sum_", iter, ".csv",)
>
>       }else{
>
>         write(unlist(mod2 at optinfo$conv$lme4$messages), paste("mod1.errors_", iter, ".txt", sep=""))
>       }
>
>       cat("Iteration", iter, "completed!\n")
>     }
>
>     #close log file & restore warnings stream to console
>     closeAllConnections()
>
> ________________________________
> From: Ben Bolker <bbolker at gmail.com>
> Sent: Friday, March 23, 2018 10:42:47 AM
> To: Andrew Robinson
> Cc: Aleksander Adam Glowka; Help Mixed Models
> Subject: Re: [R-sig-ME] prevent for-loop from stopping after an lmer warning/error
>
> Is your loop really stopping after warnings (that would be
> surprising), not just after errors?
>
> On Thu, Mar 22, 2018 at 3:42 PM, Andrew Robinson <apro at unimelb.edu.au> wrote:
>> ?try
>>
>> ?tryCatch
>>
>> Cheers,
>>
>> Andrew
>>
>>
>> On 23 March 2018 at 06:18, Aleksander Adam Glowka <aglowka at stanford.edu>
>> wrote:
>>
>>> Hi all,
>>>
>>> I'm fitting mixed-effects regression models to bootstrap samples in a
>>> for-loop and writing a subset of model results to file. I diverted the
>>> stream from the console to a text file so I can keep track any warnings or
>>> errors. For some samples the model does not converge and a warning is
>>> issued. For other samples there is an error in calculation of the
>>> Satterthwaite's approximation. The problem is that my loop iteration is
>>> aborted for some reason after a warning is issued. Do you know why this
>>> might be happening and how I can make the loops continue to the next
>>> iteration after an error or a warning?
>>>
>>> Below I've included an abridged version of my script and the warnings and
>>> errors I get. I'd be grateful for any advice you may have!
>>>
>>> Thank you,
>>>
>>> Aleksander Glowka
>>> PhD Candidate
>>> Department of Linguistics
>>> Stanford University
>>>
>>> #packages
>>> require(lme4)
>>> require(lmerTest)
>>>
>>> setwd(path0)
>>> source("lmer-data-extract-boot-fnc.R") #selected lmer results extractor
>>>
>>> # divert messages stream to file, so you can log warnings and errors
>>> options(warn=1)
>>> wngs=file("warnings_log.txt",open="w+",blocking=TRUE)
>>> sink(wngs,type="message")
>>>
>>> for(iter in 1:2000){
>>>
>>>   setwd(path1)
>>>
>>>   data = read.csv(paste("sample", iter,".csv", sep=""), header=TRUE)
>>>
>>>   #log model number to file so that any potential warnings/errors appear
>>> underneath
>>>   message(paste("holistic model #", iter, sep=""))
>>>
>>>   mod = lmer(y ~ x1 +
>>>             x2 +
>>>             x3 +
>>>             (1|ranef1) +
>>>             (x1|ranef2),
>>>             data = data,
>>>             REML = FALSE)
>>>
>>>   #write model results to file
>>>   setwd(path2)
>>>   write.csv(lmer.data.extract.boot(mod, iter), paste("mod.fixef_", iter,
>>> ".csv", sep=""), row.names=TRUE) #fixed effects
>>>   write.csv(lmer.ranef.data.extract.boot(holistic.mod, iter),
>>> paste("mod.ranef_", iter, ".csv", sep=""), row.names=FALSE)
>>>   write.csv(lmer.optim.data.extract.boot(holistic.mod, iter),
>>> paste("mod.optim_", iter, ".csv", sep=""), row.names=TRUE)
>>>   write.csv(as.data.frame(holistic.mod at optinfo$derivs$Hessian),
>>> paste("mod.hessian_", iter, ".csv", sep=""))
>>>   write.csv(summary(holistic.mod)$resid, paste("mod.resid_", iter,
>>> ".csv", sep=""), row.names=FALSE)
>>>   write(unlist(holistic.mod at optinfo$conv$lme4$messages),
>>> paste("mod.warnings_", iter, ".txt", sep=""))
>>>
>>>   cat("Iteration", iter, "completed!\n")
>>>
>>> }
>>>
>>> #close log file & restore warnings stream to console
>>> closeAllConnections()
>>>
>>> Errors:
>>>
>>> Warning in checkConv(attr(opt, "derivs"), opt$par, ctrl =
>>> control$checkConv,  :
>>>   unable to evaluate scaled gradient
>>> Warning in checkConv(attr(opt, "derivs"), opt$par, ctrl =
>>> control$checkConv,  :
>>>   Model failed to converge: degenerate  Hessian with 1 negative eigenvalues
>>>
>>> Error in calculation of the Satterthwaite's approximation. The output of
>>> lme4 package is returned
>>> summary from lme4 is returned
>>> some computational error has occurred in lmerTest
>>>
>>>
>>>
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>>
>>
>>
>> --
>> Andrew Robinson
>> Director, CEBRA, School of BioSciences
>> Reader & Associate Professor in Applied Statistics  Tel: (+61) 0403 138 955
>> School of Mathematics and Statistics                        Fax: (+61) 03
>> 8344 4599
>> University of Melbourne, VIC 3010 Australia
>> Email: apro at unimelb.edu.au
>> Website: http://www.ms.unimelb.edu.au/~andrewpr
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From berwin.turlach at gmail.com  Sat Mar 24 07:26:25 2018
From: berwin.turlach at gmail.com (Berwin A Turlach)
Date: Sat, 24 Mar 2018 14:26:25 +0800
Subject: [R-sig-ME] Question about gls
In-Reply-To: <CA+XOvOTtW8L_yVpteRdsVg0iPS1v902jwYAf1TiR95H4Pt=azA@mail.gmail.com>
References: <4EC216B1-608B-48D3-86E1-9CF1756275F5@uts.edu.au>
 <CA+XOvOTtW8L_yVpteRdsVg0iPS1v902jwYAf1TiR95H4Pt=azA@mail.gmail.com>
Message-ID: <20180324142625.63291098@ECM-DTC-716.uniwa.uwa.edu.au>

G'day all,

On Fri, 23 Mar 2018 15:58:11 -0400
Andrzej Galecki <agalecki at umich.edu> wrote:

> One possible way ...
> 
> mSt <- fit.gls$modelStruct
> cSt <- mSt$corStruct
> coef(cSt, unconstrained = FALSE)
> 
> #       Phi
> # 0.1748786

Another possible way:


R> (tmp <- intervals(fit.gls, which="var-cov"))
Approximate 95% confidence intervals

 Correlation structure:
         lower      est.     upper
Phi 0.08692388 0.1748786 0.2601282
attr(,"label")
[1] "Correlation structure:"

 Residual standard error:
    lower      est.     upper 
0.4820339 0.5139672 0.5480159 
R> tmp$corStruct[2]
[1] 0.1748786

Cheers,

	Berwin


From berwin.turlach at gmail.com  Sat Mar 24 07:36:33 2018
From: berwin.turlach at gmail.com (Berwin A Turlach)
Date: Sat, 24 Mar 2018 14:36:33 +0800
Subject: [R-sig-ME] [FORGED] Re:  Question about gls
In-Reply-To: <ff98e7c6-0b02-fa91-6e47-26773eb743e4@auckland.ac.nz>
References: <4EC216B1-608B-48D3-86E1-9CF1756275F5@uts.edu.au>
 <CA+XOvOTtW8L_yVpteRdsVg0iPS1v902jwYAf1TiR95H4Pt=azA@mail.gmail.com>
 <ff98e7c6-0b02-fa91-6e47-26773eb743e4@auckland.ac.nz>
Message-ID: <20180324143633.4772d2b9@ECM-DTC-716.uniwa.uwa.edu.au>

G'day Rolf,

On Sat, 24 Mar 2018 10:52:34 +1300
Rolf Turner <r.turner at auckland.ac.nz> wrote:

> On 24/03/18 08:58, Andrzej Galecki wrote:
> 
> > Hi Louise,
> > 
> > One possible way ...
[...]
> 
> Not exactly obvious, but, is it?  How on earth would one ever figure 
> this out, except by appealing to r-sig-mixed-models?

Well, in the good old days, over on r-help, whenever people complained
that it was not obvious how to do something using the MASS package they
were gently but firmly reminded by a certain person that the MASS
package is support software for a certain book and that they should
read the fine book (RTFB). :)

I believe Doug Bates is far to polite to point out the the nlme package
is also support software for a certain book and that you need to RTFB
for the gory details.....

> Looking at str(fit.gls) one sees that there is a (list) component 
> "modelStruct" and that this component in turn has a component 
> "corStruct".  If one is an optimist, one might try
> 
>      fit.gls$modelStruct$corStruct
> 
> which (mirabile dictu!) gives:
[...]
> Again if one is an optimist, one might try stripping away all the 
> unwanted baggage by doing
> 
>      as.vector(fit.gls$modelStruct$corStruct)
[...]

> Still it's all pretty obscure.  And typical of the obfuscation that 
> results from using S4 classes and methods.

I see that Doug has corrected you already, but the fact that you are
typing `$` all the time instead of `@` should have been a dead give
away that this is S3, not S4.  Of course, the length of time that the
nlme package is around is another give away....

Cheers,

	Berwin


From berwin.turlach at gmail.com  Sat Mar 24 07:58:29 2018
From: berwin.turlach at gmail.com (Berwin A Turlach)
Date: Sat, 24 Mar 2018 14:58:29 +0800
Subject: [R-sig-ME] [FORGED] Re:  Question about gls --- whoops!!!
In-Reply-To: <dcc27775-14d3-ca0e-e380-3ed09060d909@auckland.ac.nz>
References: <4EC216B1-608B-48D3-86E1-9CF1756275F5@uts.edu.au>
 <CA+XOvOTtW8L_yVpteRdsVg0iPS1v902jwYAf1TiR95H4Pt=azA@mail.gmail.com>
 <ff98e7c6-0b02-fa91-6e47-26773eb743e4@auckland.ac.nz>
 <dcc27775-14d3-ca0e-e380-3ed09060d909@auckland.ac.nz>
Message-ID: <20180324145829.46d15c3d@ECM-DTC-716.uniwa.uwa.edu.au>

G'day Rolf,

On Sat, 24 Mar 2018 11:30:17 +1300
Rolf Turner <r.turner at auckland.ac.nz> wrote:

> Nope!  ***NOT*** bingo!!!  Louise just pointed out to me that what I
> got by applying as.vector(), i.e. 0.3533897, is not the same as
> [...] 0.1748786 [...] Bit of a duhhh on my part.

:-)

> But it still mystifies me why as.vector() doesn't give the same
> numeric value as is obtained from just printing the object in
> question.  

Because, as you said, you are printing the object. Essentially,
as.vector() just returns the value stored in the object will all
attributes stripped.  Printing on the other hand might call some
function, and here it does:

R> class(fit.gls$modelStruct$corStruct)
[1] "corAR1"    "corStruct"
R> getAnywhere("print.corAR1")
no object named ?print.corAR1? was found
R> getAnywhere("print.corStruct")
A single object matching ?print.corStruct? was found
It was found in the following places
  registered S3 method for print from namespace nlme
  namespace:nlme
with value
[...]

> Also looking at the code of nlme:::coef.corStruct I would
> have thought that this function would simply throw an error when
> unconstrained is set to FALSE.  (Just type "nlme:::coef.corStruct"
> and you'll see what I mean.)
> 
> If I set foo <- nlme:::coef.corStruct and then do
> 
>      foo(fit.gls$modelStruct$corStruct)
> 
> I do indeed get an error.  WTF?

What error did you get?  I do not get an error:

R> foo <- nlme:::coef.corStruct
R> foo(fit.gls$modelStruct$corStruct)
[1] 0.3533897

Or did you mean

R> foo(fit.gls$modelStruct$corStruct, unconstrained=FALSE)
Error in foo(fit.gls$modelStruct$corStruct, unconstrained = FALSE) : 
  do not know how to obtain parameters of ?corAR1? object
>
 There would appear to be no way for the results to be different (look
> at the code) --- but different they are.

Well, you are missing that 

R> class(fit.gls$modelStruct$corStruct)
[1] "corAR1"    "corStruct"

And S3 will try to dispatch initially on the first class, then the
second class, and so forth...

And coef.corAR1 exists in the nlme package:

R> nlme:::coef.corAR1
function (object, unconstrained = TRUE, ...) 
{
    if (unconstrained) {
        if (attr(object, "fixed")) {
            return(numeric(0))
        }
        else {
            return(as.vector(object))
        }
    }
    aux <- exp(as.vector(object))
    aux <- c((aux - 1)/(aux + 1))
    names(aux) <- "Phi"
    aux
}
<bytecode: 0x2935e60>
<environment: namespace:nlme>

From this code it should now be clear how one can change from the
unconstrained parameter formulation used when fitting the model to the
parameter one is actually interested in for an AR1 error model:

R> (tmp <- as.numeric( fit.gls$modelStruct$corStruct))
[1] 0.3533897
R> (tmp <- exp(tmp))
[1] 1.423886
R> (tmp-1)/(tmp+1)
[1] 0.1748786
 
Cheers,

	Berwin


From berwin.turlach at gmail.com  Sat Mar 24 09:06:17 2018
From: berwin.turlach at gmail.com (Berwin A Turlach)
Date: Sat, 24 Mar 2018 16:06:17 +0800
Subject: [R-sig-ME] [FORGED] Re: Question about gls --- whoops!!!
In-Reply-To: <3c5ff855-7c36-1b41-a8e0-1f1becc9c003@auckland.ac.nz>
References: <4EC216B1-608B-48D3-86E1-9CF1756275F5@uts.edu.au>
 <CA+XOvOTtW8L_yVpteRdsVg0iPS1v902jwYAf1TiR95H4Pt=azA@mail.gmail.com>
 <ff98e7c6-0b02-fa91-6e47-26773eb743e4@auckland.ac.nz>
 <16098_1521844237_0P6200HQXEIYCT60_dcc27775-14d3-ca0e-e380-3ed09060d909@auckland.ac.nz>
 <CAO7JsnQneUgAt=Xxzc4evS1G129u3e00OZoUWke_hb=a6Vj3dQ@mail.gmail.com>
 <3c5ff855-7c36-1b41-a8e0-1f1becc9c003@auckland.ac.nz>
Message-ID: <20180324160617.624b696b@ECM-DTC-716.uniwa.uwa.edu.au>

G'day Rolf,

On Sat, 24 Mar 2018 12:39:20 +1300
Rolf Turner <r.turner at auckland.ac.nz> wrote:

> On 24/03/18 12:21, Douglas Bates wrote:
> 
> > Your comment about S4 classes and methods is misdirected. The gls 
> > function is in the nlme package which uses S3 only.  
> 
> Okay Doug; mea culpa.
> 
> But then I must say that you have succeeded in obfuscating your code
> to a degree that I would not have thought possible without the
> assistance of S4 classes and methods! :-)

Even if this statement is spoken in jest, I think I have to disagree
with it.  The code just requires one to diligently follow the way S3
dispatches to figure out what is going on.

Actually, once you realise the rich class of models that the nlme
package supports via gls() and lme() (Pinheiro and Bates, 2000,
Springer-Verlag), will still allowing for extensions (see Galecki, 1994,
Communications in Statistics-Theory and Methods, 23(11): 3105-3119, or
Galecki and Burzykowski, 2012, Springer-Verlag), you will appreciate
that it cannot be a trivial piece of code.

Moreover, the variance parameters in these models have constraints on
them, variance matrices have to be positive semi-definite, the
correlation parameter in an AR(1) model has to be between -1 and 1, and
so forth.  Constrained optimisation is not trivial at the best of time,
non-linear optimisation under constraints is a real pain.  Thus,
reparametrisations that allow for unconstrained estimation are often
employed (see, among others, Bates and Watts, 1988, Wiley & Sons).
Such reparameterisations are widely used by the nlme package.

To figure out how to get from the unconstrained parameterisation which
was used to fit the model, and for which the values are stored in the
object returned by the fitting function, to the parametrisation of
interest, one just has to diligently follow the path that S3 uses when
dispatching to generic functions.  And, typically, it does not take to
long to figure out how to change from one parameterisation to another.
Though, to find out what the parameterisation is used as the
unconstrained parameterisation, one might have to dig quite deep, just
to be faced with a .C() call at the end and the realisation that it is
also necessary to reverse-engineer some C code.

Once you follow the path of how the print() or coef() functions obtain
the values that they return from those stored in the fitted model
object, you will start to appreciate how much thought went into the
design of nlme, how object oriented the design is, how it is
ensured that the various generics play nicely and correctly with
each other, which parts of the code are responsible for what action and
so forth....

Cheers,

	Berwin


From Maarten.Jung at mailbox.tu-dresden.de  Sat Mar 24 11:54:56 2018
From: Maarten.Jung at mailbox.tu-dresden.de (Maarten Jung)
Date: Sat, 24 Mar 2018 10:54:56 +0000
Subject: [R-sig-ME] Simulating linear mixed model data for factorial design
 with 3 levels
Message-ID: <CAHr4Dyc_=ZEs2H-Pu0qmHK4opwUb4eAMDwZbm+4HL9r7_LxcaQ@mail.gmail.com>

Dear list,

I struggle to simulate linear mixed model data for a within-subject
within-item factorial design (with crossed participant and item effects)
where the categorical independent variable has three levels.

The default parameters correspond to the estimates I got from an analysis
of previous data.
As I am using the mvrnorm() function with empirical = TRUE I expected that
the estimated parameters from lmer and my specified parameters for the
simulation would match closely.
However, they differ more than I expected.

I would be grateful if somebody more experienced in mixed model simulations
could have a look at my R code on Cross Validate:
https://stats.stackexchange.com/q/335643/136579


Best Regards,

Maarten

	[[alternative HTML version deleted]]


From Louise.M.Ryan at uts.edu.au  Fri Mar 23 23:57:50 2018
From: Louise.M.Ryan at uts.edu.au (Louise Ryan)
Date: Fri, 23 Mar 2018 22:57:50 +0000
Subject: [R-sig-ME] [FORGED] Re:  Question about gls --- whoops!!!
In-Reply-To: <dcc27775-14d3-ca0e-e380-3ed09060d909@auckland.ac.nz>
References: <4EC216B1-608B-48D3-86E1-9CF1756275F5@uts.edu.au>
 <CA+XOvOTtW8L_yVpteRdsVg0iPS1v902jwYAf1TiR95H4Pt=azA@mail.gmail.com>
 <ff98e7c6-0b02-fa91-6e47-26773eb743e4@auckland.ac.nz>,
 <dcc27775-14d3-ca0e-e380-3ed09060d909@auckland.ac.nz>
Message-ID: <14FE64CA-1DF2-4961-8F87-9781039AC740@uts.edu.au>

Yes, it is very weird. I tried all sorts of things and many gave me that strange second number.

But the good news is that I now have a solution that works!!  Thank you so much :)

Louise

Sent from my iPhone

> On 24 Mar 2018, at 8:30 am, Rolf Turner <r.turner at auckland.ac.nz> wrote:
>
>> On 24/03/18 10:52, Rolf Turner wrote:
>>> On 24/03/18 08:58, Andrzej Galecki wrote:
>>> Hi Louise,
>>>
>>> One possible way ...
>>>
>>> mSt <- fit.gls$modelStruct
>>> cSt <- mSt$corStruct
>>> coef(cSt, unconstrained = FALSE)
>>>
>>> #       Phi
>>> # 0.1748786
>> Not exactly obvious, but, is it?  How on earth would one ever figure this out, except by appealing to r-sig-mixed-models?
>> Looking at str(fit.gls) one sees that there is a (list) component "modelStruct" and that this component in turn has a component "corStruct".  If one is an optimist, one might try
>>     fit.gls$modelStruct$corStruct
>> which (mirabile dictu!) gives:
>> Correlation structure of class corAR1 representing
>>       Phi
>> 0.1748786
>> Again if one is an optimist, one might try stripping away all the unwanted baggage by doing
>>     as.vector(fit.gls$modelStruct$corStruct)
>> giving:
>> [1] 0.3533897
>> Bingo.
>
> Nope!  ***NOT*** bingo!!!  Louise just pointed out to me that what I got by applying as.vector(), i.e. 0.3533897, is not the same as the number one gets by just typing fit.gls$modelStruct$corStruct, which is 0.1748786 --- which is what Andrzej's approach gives (and which would
> appear to be the right answer).  Bit of a duhhh on my part.
>
> Setting unconstrained=FALSE as in Andrzej's approach seems to be crucial.  I missed that bit ....
>
> But it still mystifies me why as.vector() doesn't give the same numeric value as is obtained from just printing the object in question.  Also
> looking at the code of nlme:::coef.corStruct I would have thought that
> this function would simply throw an error when unconstrained is set to FALSE.  (Just type "nlme:::coef.corStruct" and you'll see what I mean.)
>
> If I set foo <- nlme:::coef.corStruct and then do
>
>    foo(fit.gls$modelStruct$corStruct)
>
> I do indeed get an error.  WTF?
>
> There would appear to be no way for the results to be different (look
> at the code) --- but different they are.
>
> But that sort of nonsense is to be expected when S4 classes and methods are involved in any way.
>
> cheers,
>
> Rolf
>
> --
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276

ompanying attachments may contain confidential information. If you are not the intended recipient, do not read, use, disseminate, distribute or copy this message or attachments. If you have received this message in error, please notify the sender immediately and delete this message. Any views expressed in this message are those of the individual sender, except where the sender expressly, and with authority, states them to be the views of the University of Technology Sydney. Before opening any attachments, please check them for viruses and defects. Think. Green. Do. Please consider the environment before printing this email.


From dan at brooksbaseball.net  Fri Mar 23 20:52:15 2018
From: dan at brooksbaseball.net (Dan Brooks)
Date: Fri, 23 Mar 2018 15:52:15 -0400
Subject: [R-sig-ME] Question about gls
In-Reply-To: <4EC216B1-608B-48D3-86E1-9CF1756275F5@uts.edu.au>
References: <4EC216B1-608B-48D3-86E1-9CF1756275F5@uts.edu.au>
Message-ID: <CAET4i1d-oidn-z1u_9EMzF=oRo7Tk84K+hbL1RwfzWLMQSuFrw@mail.gmail.com>

Hi Louise:

Perhaps try what seems to be suggested here?
http://r.789695.n4.nabble.com/Extracting-Phi-from-gls-lme-td803811.html

coef(fit.gls$modelStruct$corStruct,unconstrained = FALSE)

Best-
Dan

On Fri, Mar 23, 2018 at 3:27 PM, Louise Ryan <Louise.M.Ryan at uts.edu.au>
wrote:

> Hi there,
>
> I am using your function gls in R to fit some AR models (it is part of a
> larger thing I am trying to do). I can see from the printed output that the
> function is estimating the AR parameter.  But I CANNOT for the life of me
> figure out how to extract this parameter so I can use it for something else.
>
> Here?s a bit of code that simulates some data and runs the model.
>
> #####
> # Set true parameter values:
> beta0True <- 0.3
> beta1True <- 1.6
> sigmaTrue <- 0.5
> rhoTrue <- 0.2
>
> # Generate data:
> set.seed(1)
> n <- 500
> x <- seq(0,1,length=n)
> epsilon <- rep(NA,n)
> epsilon[1] <- sigmaTrue*rnorm(1)
> for (i in 2:n) {epsilon[i] <- rhoTrue*epsilon[i-1] + sigmaTrue*rnorm(1)}
> y <- beta0True + beta1True*x + epsilon
>
> fit.gls <- gls(y~x,  correlation=corAR1())
> print(summary(fit.gls))
> ###########################
>
> For my little simulation, the parameter Phi is being estimated as .1748786.
>
> I have looked at attributes(fit.gls) and just cannot figure out where this
> estimate is stored!
>
> I?d appreciate your help!
>
> Louise
> UTS CRICOS Provider Code: 00099F DISCLAIMER: This email message and any
> accompanying attachments may contain confidential information. If you are
> not the intended recipient, do not read, use, disseminate, distribute or
> copy this message or attachments. If you have received this message in
> error, please notify the sender immediately and delete this message. Any
> views expressed in this message are those of the individual sender, except
> where the sender expressly, and with authority, states them to be the views
> of the University of Technology Sydney. Before opening any attachments,
> please check them for viruses and defects. Think. Green. Do. Please
> consider the environment before printing this email.
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Sun Mar 25 00:40:17 2018
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sun, 25 Mar 2018 12:40:17 +1300
Subject: [R-sig-ME] Constraining error variance to 0 in an lmer() model.
Message-ID: <be62e3f2-f810-7257-b995-bc2da0c82ae6@auckland.ac.nz>


In a longish thread that he initiated ("What is the lmer/nlme equivalent 
of the REPEATED subcommand in SPSS's MIXED procedure?") Maarten Jung
answered a question that has long been bothering me.

Using an example data set provided by Ben Pelzer he showed how to fit
a model in which in effect the error variance is 0.  Many years ago I 
was struggling to analyse a data set which in its simplest form had
exactly the same structure as Ben Pelzer's data, essentially repeated 
measures for each of a number of subjects, the number of repetitions
("occasions" in Ben Pelzer's data) being the same for each subject 
("person").

I asked for help with this problem, but got no really satisfactory answer.

The model that I wanted to fit was (adapting Maarten Jung's notation 
slightly to suit my own tastes):

     (*) lmer(test ~ 0+person + (0+person | occasion),data=Dat)

The reason that I wanted to fit this model was to try to verify that I 
understood what was going on (in this minimal instance) before 
proceeding to deal with more complicated models).  The point is that the
foregoing model can be "fitted" without recourse to lmer() simply by
thinking of the data as being multivariate (normal).  I.e. each "person"
has an associated tri-variate vector of observations, assumed to be 
independent from person to person.  If we form the data matrix, say "X" 
(with 20 rows and 3 columns) and calculate the column means and
var(X)/20 we should get the same results as would be produced by lmer(),
or so I thought (given that I understood correctly what lmer() was doing.)

The problem that I encountered (back in the dim dark past) was that the 
code in (*) falls over.  This is understandable since there is 
redundancy in the model, as Maarten Jung explained.  He also explained
how to get around the problem by adding a control argument:

     lmer(test ~ 0+person + (0+person | occasion),data=Dat,
                 control=lmerControl(check.nobs.vs.nRE = "ignore"))

does not fall over.  And it indeed gives the same results as does the 
multivariate analysis, to at least 5 decimal places in all instances:

> lmer results:
> fixef(fit): > occasion1 occasion2 occasion3
>     29.80     30.05     33.30
>
> vcov(fit):
> 3 x 3 Matrix of class "dpoMatrix"
>           occasion1 occasion2 occasion3
> occasion1 1.7821054  1.150526 0.5768422
> occasion2 1.1505265  2.249868 3.0623683
> occasion3 0.5768422  3.062368 5.8531577
> 
> Multivariate normal results:
> column means: >
> occasion1 occasion2 occasion3 
>     29.80     30.05     33.30
>
> var(X)/20:
>           occasion1 occasion2 occasion3
> occasion1 1.7821053  1.150526 0.5768421
> occasion2 1.1505263  2.249868 3.0623684
> occasion3 0.5768421  3.062368 5.8531579

Unfortunately lmer() still gives an off-putting warning message:

> Warning message:
> In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>   Model is nearly unidentifiable: large eigenvalue ratio
>  - Rescale variables?

I have no idea what is actually going on here, but it seems to me that 
this should not be happening.  The setting is dead simple, and the 
answer that lmer() obtains is "exactly" correct, as we can check in this 
instance by other means.

What we have here is a "boundary" or "edge" or "corner" case, and I have 
heard it asserted by someone knowledgeable and respected (can't remember 
who, it was a long while ago) that in testing your software it is 
crucial to see how it behaves with such "boundary" cases.  In the 
current instance lmer() is handling this boundary case alright, but 
perhaps worrying the user unnecessarily.

Can anything be done?  I would judge by the reactions to my previous 
enquiries on this matter that the answer is "no", but I thought I'd 
throw the question out to the cognoscenti again, prompted by being shown 
by Maarten Jung how to at least get an answer out of lmer().

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From r.turner at auckland.ac.nz  Sun Mar 25 00:49:47 2018
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sun, 25 Mar 2018 12:49:47 +1300
Subject: [R-sig-ME] [FORGED] Re: Question about gls --- whoops!!!
In-Reply-To: <20180324145829.46d15c3d@ECM-DTC-716.uniwa.uwa.edu.au>
References: <4EC216B1-608B-48D3-86E1-9CF1756275F5@uts.edu.au>
 <CA+XOvOTtW8L_yVpteRdsVg0iPS1v902jwYAf1TiR95H4Pt=azA@mail.gmail.com>
 <ff98e7c6-0b02-fa91-6e47-26773eb743e4@auckland.ac.nz>
 <dcc27775-14d3-ca0e-e380-3ed09060d909@auckland.ac.nz>
 <20180324145829.46d15c3d@ECM-DTC-716.uniwa.uwa.edu.au>
Message-ID: <da71b5f5-d6e1-dce8-68b6-c65cdbd23776@auckland.ac.nz>

On 24/03/18 19:58, Berwin A Turlach wrote:

<SNIP>

Berwin, old boy.  I don't have the time, patience or energy to respond 
to your (IMHO) totally misplaced comments.  I would just like to point 
out that although I cheerfully admit to being far from the sharpest tool 
in the shed, this issue arose in response to an enquiry from Louise Ryan
who *is* one of the sharpest tools in the shed.  If *she* couldn't 
figure out how to accomplish the task (which ought to be bog-simple) of 
extracting an AR(1) coefficient from a model, then the code suffers from 
extreme obfuscation.

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From r.turner at auckland.ac.nz  Sun Mar 25 10:39:27 2018
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sun, 25 Mar 2018 21:39:27 +1300
Subject: [R-sig-ME] Constraining error variance to 0 in an lmer() model.
In-Reply-To: <be62e3f2-f810-7257-b995-bc2da0c82ae6@auckland.ac.nz>
References: <be62e3f2-f810-7257-b995-bc2da0c82ae6@auckland.ac.nz>
Message-ID: <5478889e-3c7d-a774-51c8-60e28262cf93@auckland.ac.nz>


On 25/03/18 12:40, Rolf Turner wrote:

<SNIP>

> 
> The model that I wanted to fit was (adapting Maarten Jung's notation 
> slightly to suit my own tastes):
> 
>  ??? (*) lmer(test ~ 0+person + (0+person | occasion),data=Dat)

<SNIP>

Berwin Turlach has just pointed out to me that I got the preceding 
expression arse-backwards, as is so often my propensity.  It should
be:

     (*) lmer(test ~ 0+occasion + (0+occasion | person),data=Dat)

The fixed effect is *occasion* and the random effect is *person*.

Likewise

>  ??? lmer(test ~ 0+person + (0+person | occasion),data=Dat,
>  ??????????????? control=lmerControl(check.nobs.vs.nRE = "ignore"))

should be

       lmer(test ~ 0+occasion + (0+occasion | person),data=Dat,
                   control=lmerControl(check.nobs.vs.nRE = "ignore"))

Psigh!  Sorry for the confusion, everybody.

<SNIP>

cheers,

Rolf Turner

P.S.  Berwin also asked me to provide the data I used.  I simply took 
the data provided by Ben Pelzer, in a posting in the relevant thread, 
just before the posting in which Maarten Jung explained how to get the 
fit to run, by setting the appropriate control variable.

For the record, Ben Pelzer provided the data through a URL:

> Dat <-
> read.table(url("https://surfdrive.surf.nl/files/index.php/s/XfE3mtbFCTUejIz/download"),
> header=TRUE)

(Actually Ben Pelzer wrote "mydata" where I have written "Dat" above.  I 
*refuse* to use this "mydata" construction since it is *so*
Micro$oft! :-) )

R. T.

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From bates at stat.wisc.edu  Sun Mar 25 15:08:08 2018
From: bates at stat.wisc.edu (Douglas Bates)
Date: Sun, 25 Mar 2018 13:08:08 +0000
Subject: [R-sig-ME] Constraining error variance to 0 in an lmer() model.
In-Reply-To: <28559_1521967201_0P6500JHP1ENJR10_5478889e-3c7d-a774-51c8-60e28262cf93@auckland.ac.nz>
References: <be62e3f2-f810-7257-b995-bc2da0c82ae6@auckland.ac.nz>
 <28559_1521967201_0P6500JHP1ENJR10_5478889e-3c7d-a774-51c8-60e28262cf93@auckland.ac.nz>
Message-ID: <CAO7JsnTESUdcr6pjVXAoefkAoEiOtYJKRAoNiep4X7JVsD=fBg@mail.gmail.com>

In https://www.jstatsoft.org/index.php/jss/article/view/v067i01 the lme4
authors describe in some detail the numerical methods used in lmer.  You
will see that one of the transformations used to profile the log-likelihood
is working with the relative covariance factor.  This is the Cholesky
factor of the ratio of the covariance matrix of the random effects to the
variance of the per-observation noise.  It is assumed that that variance is
greater than zero.

The model that you wish to fit is not within the scope of models lme4 is
designed to fit.

On Sun, Mar 25, 2018 at 3:40 AM Rolf Turner <r.turner at auckland.ac.nz> wrote:

>
> On 25/03/18 12:40, Rolf Turner wrote:
>
> <SNIP>
>
> >
> > The model that I wanted to fit was (adapting Maarten Jung's notation
> > slightly to suit my own tastes):
> >
> >      (*) lmer(test ~ 0+person + (0+person | occasion),data=Dat)
>
> <SNIP>
>
> Berwin Turlach has just pointed out to me that I got the preceding
> expression arse-backwards, as is so often my propensity.  It should
> be:
>
>      (*) lmer(test ~ 0+occasion + (0+occasion | person),data=Dat)
>
> The fixed effect is *occasion* and the random effect is *person*.
>
> Likewise
>
> >      lmer(test ~ 0+person + (0+person | occasion),data=Dat,
> >                  control=lmerControl(check.nobs.vs.nRE = "ignore"))
>
> should be
>
>        lmer(test ~ 0+occasion + (0+occasion | person),data=Dat,
>                    control=lmerControl(check.nobs.vs.nRE = "ignore"))
>
> Psigh!  Sorry for the confusion, everybody.
>
> <SNIP>
>
> cheers,
>
> Rolf Turner
>
> P.S.  Berwin also asked me to provide the data I used.  I simply took
> the data provided by Ben Pelzer, in a posting in the relevant thread,
> just before the posting in which Maarten Jung explained how to get the
> fit to run, by setting the appropriate control variable.
>
> For the record, Ben Pelzer provided the data through a URL:
>
> > Dat <-
> > read.table(url("
> https://surfdrive.surf.nl/files/index.php/s/XfE3mtbFCTUejIz/download"),
> > header=TRUE)
>
> (Actually Ben Pelzer wrote "mydata" where I have written "Dat" above.  I
> *refuse* to use this "mydata" construction since it is *so*
> Micro$oft! :-) )
>
> R. T.
>
> --
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276 <+64%209-373%207599>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From Farrar.David at epa.gov  Mon Mar 26 14:34:35 2018
From: Farrar.David at epa.gov (Farrar, David)
Date: Mon, 26 Mar 2018 12:34:35 +0000
Subject: [R-sig-ME] thoughts on variable importance
Message-ID: <BL0PR0901MB2291312B994721158D052EBA9AAD0@BL0PR0901MB2291.namprd09.prod.outlook.com>

There is probably some tendency for studies to be planned so that the variables thought to be most important can be evaluated as fixed effects, as I did.
For analysis of a small field environmental field study, I eyeballed the BLUPs for a few nuisance variables, and noted that they did not suggest effects as large as for those variables that interested us most.   Thoughts?
My apology if a methodology question is not favored here.   I did not think it was a question about introductory mixed models.
Regards,
David

David Farrar, Ph.D., Biostatistician
USEPA ORD NCEA BRAB Cincinnati, OH


	[[alternative HTML version deleted]]


From bbolker at gmail.com  Mon Mar 26 14:54:28 2018
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 26 Mar 2018 08:54:28 -0400
Subject: [R-sig-ME] thoughts on variable importance
In-Reply-To: <BL0PR0901MB2291312B994721158D052EBA9AAD0@BL0PR0901MB2291.namprd09.prod.outlook.com>
References: <BL0PR0901MB2291312B994721158D052EBA9AAD0@BL0PR0901MB2291.namprd09.prod.outlook.com>
Message-ID: <CABghstQX_LR_869uic32g83WMAQFoEfghgTL6xFvr9-aSTRBhw@mail.gmail.com>

Methodology questions are fine, but can you spell out your question a bit more?

On Mon, Mar 26, 2018 at 8:34 AM, Farrar, David <Farrar.David at epa.gov> wrote:
> There is probably some tendency for studies to be planned so that the variables thought to be most important can be evaluated as fixed effects, as I did.
> For analysis of a small field environmental field study, I eyeballed the BLUPs for a few nuisance variables, and noted that they did not suggest effects as large as for those variables that interested us most.   Thoughts?
> My apology if a methodology question is not favored here.   I did not think it was a question about introductory mixed models.
> Regards,
> David
>
> David Farrar, Ph.D., Biostatistician
> USEPA ORD NCEA BRAB Cincinnati, OH
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From Farrar.David at epa.gov  Mon Mar 26 15:07:53 2018
From: Farrar.David at epa.gov (Farrar, David)
Date: Mon, 26 Mar 2018 13:07:53 +0000
Subject: [R-sig-ME] thoughts on variable importance
In-Reply-To: <CABghstQX_LR_869uic32g83WMAQFoEfghgTL6xFvr9-aSTRBhw@mail.gmail.com>
References: <BL0PR0901MB2291312B994721158D052EBA9AAD0@BL0PR0901MB2291.namprd09.prod.outlook.com>
 <CABghstQX_LR_869uic32g83WMAQFoEfghgTL6xFvr9-aSTRBhw@mail.gmail.com>
Message-ID: <BL0PR0901MB229199C8EFFFF349B6842B779AAD0@BL0PR0901MB2291.namprd09.prod.outlook.com>


Sorry yes.   I think my coffee had not taken effect.  The broad issue is comparison of variable importance when some variables have been modeled as fixed and others as random.   In my case the variables of most interest were modeled as fixed and some nuisance variables (as I saw them) were modeled as random.   I thought this was crude but possibly good enough for the situation, but I wondered if there was an interest in discussing this, or there are some more refined methods that I might have considered.  The actual analysis is already done and published some time ago.   I didn't want to go into more detail because I did not want to focus on the modeling.   I intended to be a little vague in order to cast a wide net.  

-----Original Message-----
From: Ben Bolker [mailto:bbolker at gmail.com] 
Sent: Monday, March 26, 2018 8:54 AM
To: Farrar, David <Farrar.David at epa.gov>
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] thoughts on variable importance

Methodology questions are fine, but can you spell out your question a bit more?

On Mon, Mar 26, 2018 at 8:34 AM, Farrar, David <Farrar.David at epa.gov> wrote:
> There is probably some tendency for studies to be planned so that the variables thought to be most important can be evaluated as fixed effects, as I did.
> For analysis of a small field environmental field study, I eyeballed the BLUPs for a few nuisance variables, and noted that they did not suggest effects as large as for those variables that interested us most.   Thoughts?
> My apology if a methodology question is not favored here.   I did not think it was a question about introductory mixed models.
> Regards,
> David
>
> David Farrar, Ph.D., Biostatistician
> USEPA ORD NCEA BRAB Cincinnati, OH
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

From thierry.onkelinx at inbo.be  Mon Mar 26 15:42:05 2018
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Mon, 26 Mar 2018 15:42:05 +0200
Subject: [R-sig-ME] thoughts on variable importance
In-Reply-To: <BL0PR0901MB229199C8EFFFF349B6842B779AAD0@BL0PR0901MB2291.namprd09.prod.outlook.com>
References: <BL0PR0901MB2291312B994721158D052EBA9AAD0@BL0PR0901MB2291.namprd09.prod.outlook.com>
 <CABghstQX_LR_869uic32g83WMAQFoEfghgTL6xFvr9-aSTRBhw@mail.gmail.com>
 <BL0PR0901MB229199C8EFFFF349B6842B779AAD0@BL0PR0901MB2291.namprd09.prod.outlook.com>
Message-ID: <CAJuCY5woVqyfiLuOyFZ4Kti57c1+Ma75hV57bQ02g-T104rDfA@mail.gmail.com>

Dear David,

You are still very vague on the design. Which makes it much harder to
answer your question. Can you please give us a more focused question? And
provide some dummy data and a model?

Best regards,


ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>

2018-03-26 15:07 GMT+02:00 Farrar, David <Farrar.David at epa.gov>:

>
> Sorry yes.   I think my coffee had not taken effect.  The broad issue is
> comparison of variable importance when some variables have been modeled as
> fixed and others as random.   In my case the variables of most interest
> were modeled as fixed and some nuisance variables (as I saw them) were
> modeled as random.   I thought this was crude but possibly good enough for
> the situation, but I wondered if there was an interest in discussing this,
> or there are some more refined methods that I might have considered.  The
> actual analysis is already done and published some time ago.   I didn't
> want to go into more detail because I did not want to focus on the
> modeling.   I intended to be a little vague in order to cast a wide net.
>
> -----Original Message-----
> From: Ben Bolker [mailto:bbolker at gmail.com]
> Sent: Monday, March 26, 2018 8:54 AM
> To: Farrar, David <Farrar.David at epa.gov>
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] thoughts on variable importance
>
> Methodology questions are fine, but can you spell out your question a bit
> more?
>
> On Mon, Mar 26, 2018 at 8:34 AM, Farrar, David <Farrar.David at epa.gov>
> wrote:
> > There is probably some tendency for studies to be planned so that the
> variables thought to be most important can be evaluated as fixed effects,
> as I did.
> > For analysis of a small field environmental field study, I eyeballed the
> BLUPs for a few nuisance variables, and noted that they did not suggest
> effects as large as for those variables that interested us most.   Thoughts?
> > My apology if a methodology question is not favored here.   I did not
> think it was a question about introductory mixed models.
> > Regards,
> > David
> >
> > David Farrar, Ph.D., Biostatistician
> > USEPA ORD NCEA BRAB Cincinnati, OH
> >
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From Farrar.David at epa.gov  Mon Mar 26 21:31:21 2018
From: Farrar.David at epa.gov (Farrar, David)
Date: Mon, 26 Mar 2018 19:31:21 +0000
Subject: [R-sig-ME] thoughts on variable importance
In-Reply-To: <CAJuCY5woVqyfiLuOyFZ4Kti57c1+Ma75hV57bQ02g-T104rDfA@mail.gmail.com>
References: <BL0PR0901MB2291312B994721158D052EBA9AAD0@BL0PR0901MB2291.namprd09.prod.outlook.com>
 <CABghstQX_LR_869uic32g83WMAQFoEfghgTL6xFvr9-aSTRBhw@mail.gmail.com>
 <BL0PR0901MB229199C8EFFFF349B6842B779AAD0@BL0PR0901MB2291.namprd09.prod.outlook.com>
 <CAJuCY5woVqyfiLuOyFZ4Kti57c1+Ma75hV57bQ02g-T104rDfA@mail.gmail.com>
Message-ID: <BL0PR0901MB229115B3A158E05D83C0E4B59AAD0@BL0PR0901MB2291.namprd09.prod.outlook.com>

Design is too complicated for purposes here (BTW I didn?t design the study).   For simplicity let?s say you obtain samples of ?material? from several ?sources,? and you measure ?something? on the these samples at two facilities.   Each ?source? is measured multiple times at a single facility.  The sources can differ in some identifiable aspects of their procedures for generating material.   There is a continuous variable which varies in an uncontrolled manner across measurements from a given source, modelled as a fixed  effects regressor.   It cannot assumed that one can account for all variation among the sources, therefore there is a random factor for ?source,?   in addition to fixed effects for identified difference in procedure.

In the event, ?material? is treated sewage.  The regressor is wind speed in a field study of aerosolizing of bacterial endotoxins.

This is kind of messy for those variables but the study is actually pretty good for another purpose, namely comparing measurement devices.  These are paired in particular for wind speed.   However, we tried to characterize the importance of other variables, in relative terms.  It appeared to me that under the conditions of the study wind speed was more important than variation among sources.

R. F. Herrmann, R. J. Grosser, D. Farrar, R. B. Brobst.   2017.   Field studies measuring the aerosolization of endotoxin during the land application of Class B biosolids.
Aerobiologia (2017) 33:417?434.

From: Thierry Onkelinx [mailto:thierry.onkelinx at inbo.be]
Sent: Monday, March 26, 2018 9:42 AM
To: Farrar, David <Farrar.David at epa.gov>
Cc: Ben Bolker <bbolker at gmail.com>; r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] thoughts on variable importance

Dear David,

You are still very vague on the design. Which makes it much harder to answer your question. Can you please give us a more focused question? And provide some dummy data and a model?

Best regards,


ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be<mailto:thierry.onkelinx at inbo.be>
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be<http://www.inbo.be>
///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

[https://inbo-website-prd-532750756126.s3-eu-west-1.amazonaws.com/inbologoleeuw_nl.png]<https://www.inbo.be>

2018-03-26 15:07 GMT+02:00 Farrar, David <Farrar.David at epa.gov<mailto:Farrar.David at epa.gov>>:

Sorry yes.   I think my coffee had not taken effect.  The broad issue is comparison of variable importance when some variables have been modeled as fixed and others as random.   In my case the variables of most interest were modeled as fixed and some nuisance variables (as I saw them) were modeled as random.   I thought this was crude but possibly good enough for the situation, but I wondered if there was an interest in discussing this, or there are some more refined methods that I might have considered.  The actual analysis is already done and published some time ago.   I didn't want to go into more detail because I did not want to focus on the modeling.   I intended to be a little vague in order to cast a wide net.

-----Original Message-----
From: Ben Bolker [mailto:bbolker at gmail.com<mailto:bbolker at gmail.com>]
Sent: Monday, March 26, 2018 8:54 AM
To: Farrar, David <Farrar.David at epa.gov<mailto:Farrar.David at epa.gov>>
Cc: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] thoughts on variable importance

Methodology questions are fine, but can you spell out your question a bit more?

On Mon, Mar 26, 2018 at 8:34 AM, Farrar, David <Farrar.David at epa.gov<mailto:Farrar.David at epa.gov>> wrote:
> There is probably some tendency for studies to be planned so that the variables thought to be most important can be evaluated as fixed effects, as I did.
> For analysis of a small field environmental field study, I eyeballed the BLUPs for a few nuisance variables, and noted that they did not suggest effects as large as for those variables that interested us most.   Thoughts?
> My apology if a methodology question is not favored here.   I did not think it was a question about introductory mixed models.
> Regards,
> David
>
> David Farrar, Ph.D., Biostatistician
> USEPA ORD NCEA BRAB Cincinnati, OH
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


	[[alternative HTML version deleted]]


From oliverhooker at prstatistics.com  Tue Mar 27 20:27:37 2018
From: oliverhooker at prstatistics.com (Oliver Hooker)
Date: Tue, 27 Mar 2018 19:27:37 +0100
Subject: [R-sig-ME] COURSE - Introduction to Mixed (Hierarchical) models for
 biologists using R
Message-ID: <ce7e3bd223a4f83eeeddcc627ab4325f@prstatistics.com>

Introduction to Mixed (Hierarchical) models for biologists using R 
(IMBR01)

This is just a gentle reminder that we still have a few places left on 
this course.

Deliver by Prof Subhash Lele form 14th - 18th May 2018 in Quebec Canada.

Course overview:
Mixed models, also known as hierarchical models and multilevel models, 
is a useful class of models for many applied sciences, including 
biology, ecology and evolution. The goal of this course is to give a 
thorough introduction to the logic, theory and most importantly 
implementation of these models to solve practical problems in ecology. 
Participants are not expected to know mathematics beyond the basic 
algebra and calculus. Participants are expected to know some R 
programming and to be familiar with the linear and generalized linear 
regression. We will be using JAGS (Just Another Gibbs Sampler) for 
Markov Chain Monte Carlo (MCMC) simulations for analyzing mixed models. 
The course will be conducted so that participants have substantial 
hands-on experience.

Email oliverhooker at prstatistics.com with any questions

Check out our sister sites,
www.PRstatistics.com (Ecology and Life Sciences)
www.PRinformatics.com (Bioinformatics and data science)
www.PSstatsistics.com (Behaviour and cognition)

1.	March 19th ? 23rd 2018
BEHAVIOURAL DATA ANALYSIS USING MAXIMUM LIKLIHOOD IN R (BDML01)
Glasgow, Scotland, Dr William Hoppitt
http://www.psstatistics.com/course/behavioural-data-analysis-using-maximum-likelihood-bdml01/

2.	April 9th ? 13th 2018
NETWORK ANAYLSIS FOR ECOLOGISTS USING R (NTWA02
Glasgow, Scotland, Dr. Marco Scotti
www.prstatistics.com/course/network-analysis-ecologists-ntwa02/

3.	April 16th ? 20th 2018
INTRODUCTION TO STATISTICAL MODELLING FOR PSYCHOLOGISTS USING R (IPSY01)
Glasgow, Scotland, Dr. Dale Barr, Dr Luc Bussierre
http://www.psstatistics.com/course/introduction-to-statistics-using-r-for-psychologists-ipsy01/

4.	April 23rd ? 27th 2018
MULTIVARIATE ANALYSIS OF ECOLOGICAL COMMUNITIES USING THE VEGAN PACKAGE 
(VGNR01)
Glasgow, Scotland, Dr. Peter Solymos, Dr. Guillaume Blanchet
www.prstatistics.com/course/multivariate-analysis-of-ecological-communities-in-r-with-the-vegan-package-vgnr01/

5.	April 30th ? 4th May 2018
QUANTITATIVE GEOGRAPHIC ECOLOGY: MODELING GENOMES, NICHES, AND 
COMMUNITIES (QGER01)
Glasgow, Scotland, Dr. Dan Warren, Dr. Matt Fitzpatrick
www.prstatistics.com/course/quantitative-geographic-ecology-using-r-modelling-genomes-niches-and-communities-qger01/

6.	May 7th ? 11th 2018 ADVANCES IN MULTIVARIATE ANALYSIS OF SPATIAL 
ECOLOGICAL DATA USING R (MVSP02)
CANADA (QUEBEC), Prof. Pierre Legendre, Dr. Guillaume Blanchet
www.prstatistics.com/course/advances-in-spatial-analysis-of-multivariate-ecological-data-theory-and-practice-mvsp03/
7.	May 14th - 18th 2018
INTRODUCTION TO MIXED (HIERARCHICAL) MODELS FOR BIOLOGISTS (IMBR01)
CANADA (QUEBEC), Prof Subhash Lele
www.prstatistics.com/course/introduction-to-mixed-hierarchical-models-for-biologists-using-r-imbr01/

8.	May 21st - 25th 2018
INTRODUCTION TO PYTHON FOR BIOLOGISTS (IPYB05)
SCENE, Scotland, Dr. Martin Jones
http://www.prinformatics.com/course/introduction-to-python-for-biologists-ipyb05/

9.	May 21st - 25th 2018
INTRODUCTION TO REMOTE SENISNG AND GIS FOR ECOLOGICAL APPLICATIONS 
(IRMS01)
Glasgow, Scotland, Prof. Duccio Rocchini, Dr. Luca Delucchi
www.prinformatics.com/course/introduction-to-remote-sensing-and-gis-for-ecological-applications-irms01/

10.	May 28th ? 31st 2018
STABLE ISOTOPE MIXING MODELS USING SIAR, SIBER AND MIXSIAR (SIMM04)
CANADA (QUEBEC) Dr. Andrew Parnell, Dr. Andrew Jackson
www.prstatistics.com/course/stable-isotope-mixing-models-using-r-simm04/

11.	May 28th ? June 1st 2018
ADVANCED PYTHON FOR BIOLOGISTS (APYB02)
SCENE, Scotland, Dr. Martin Jones
www.prinformatics.com/course/advanced-python-biologists-apyb02/

12.	June 12th - 15th 2018
SPECIES DISTRIBUTION MODELLING (DBMR01)
Myuna Bay sport and recreation, Australia, Prof. Jane Elith, Dr. 
Gurutzeta Guillera
www.prstatistics.com/course/species-distribution-models-using-r-sdmr01/

13.	June 18th ? 22nd 2018
STRUCTURAL EQUATION MODELLING FOR ECOLOGISTS AND EVOLUTIONARY BIOLOGISTS 
USING R (SEMR02)
Myuna Bay sport and recreation, Australia, Dr. Jon Lefcheck
www.prstatistics.com/course/structural-equation-modelling-for-ecologists-and-evolutionary-biologists-semr02/

14.	June 25th ? 29th 2018
SPECIES DISTRIBUTION/OCCUPANCY MODELLING USING R (OCCU01)
Glasgow, Scotland, Dr. Darryl McKenzie
www.prstatistics.com/course/species-distributionoccupancy-modelling-using-r-occu01/

15.	July 2nd - 5th 2018
SOCIAL NETWORK ANALYSIS FOR BEHAVIOURAL SCIENTISTS USING R (SNAR01)
Glasgow, Scotland, Prof James Curley
http://www.psstatistics.com/course/social-network-analysis-for-behavioral-scientists-snar01/

16.	July 8th ? 12th 2018
MODEL BASE MULTIVARIATE ANALYSIS OF ABUNDANCE DATA USING R (MBMV02)
Glasgow, Scotland, Prof David Warton
www.prstatistics.com/course/model-base-multivariate-analysis-of-abundance-data-using-r-mbmv02/

17.	July 16th ? 20th 2018
PRECISION MEDICINE BIOINFORMATICS: FROM RAW GENOME AND TRANSCRIPTOME 
DATA TO CLINICAL INTERPRETATION (PMBI01)
Glasgow, Scotland, Dr Malachi Griffith, Dr. Obi Griffith
www.prinformatics.com/course/precision-medicine-bioinformatics-from-raw-genome-and-transcriptome-data-to-clinical-interpretation-pmbi01/

18.	July 23rd ? 27th 2018
EUKARYOTIC METABARCODING (EUKB01)
Glasgow, Scotland, Dr. Owen Wangensteen
http://www.prinformatics.com/course/eukaryotic-metabarcoding-eukb01/

19.	October 8th ? 12th 2018
INTRODUCTION TO SPATIAL ANALYSIS OF ECOLOGICAL DATA USING R (ISAE01)
Glasgow, Scotland, Prof. Subhash Lele
https://www.prstatistics.com/course/introduction-to-spatial-analysis-of-ecological-data-using-r-isae01/

20.	October 15th ? 19th 2018
APPLIED BAYESIAN MODELLING FOR ECOLOGISTS AND EPIDEMIOLOGISTS (ABME
Glasgow, Scotland, Dr. Matt Denwood, Emma Howard
http://www.prstatistics.com/course/applied-bayesian-modelling-ecologists-epidemiologists-abme04/

21.	October 29th ? November 2nd 2018
PHYLOGENETIC COMPARATIVE METHODS FOR STUDYING DIVERSIFICATION AND 
PHENOTYPIC EVOLUTION (PCME01)
Glasgow, Scotland, Prof. Subhash Lele
Dr. Antigoni Kaliontzopoulou
https://www.prstatistics.com/course/phylogenetic-comparative-methods-for-studying-diversification-and-phenotypic-evolution-pcme01/

22.	November 26th ? 30th 2018
FUNCTIONAL ECOLOGY FROM ORGANISM TO ECOSYSTEM: THEORY AND COMPUTATION 
(FEER
Glasgow, Scotland, Dr. Francesco de Bello, Dr. Lars G?tzenberger, Dr. 
Carlos Carmona
http://www.prstatistics.com/course/functional-ecology-from-organism-to-ecosystem-theory-and-computation-feer01/

23.	February 2018 TBC
MOVEMENT ECOLOGY (MOVE02)
Margam Discovery Centre, Wales, Dr Luca Borger, Dr Ronny Wilson, Dr 
Jonathan Potts
www.prstatistics.com/course/movement-ecology-move01/


-- 
Oliver Hooker PhD.
PR statistics

2017 publications -

Ecosystem size predicts eco-morphological variability in post-glacial 
diversification. Ecology and Evolution. In press.

The physiological costs of prey switching reinforce foraging 
specialization. Journal of animal ecology.

prstatistics.com
facebook.com/prstatistics/
twitter.com/PRstatistics
groups.google.com/d/forum/pr-statistics-post-course-forum
prstatistics.com/organiser/oliver-hooker/

6 Hope Park Crescent
Edinburgh
EH8 9NA

+44 (0) 7966500340


From stephan.lehner at wu.ac.at  Wed Mar 28 17:09:18 2018
From: stephan.lehner at wu.ac.at (Lehner, Stephan)
Date: Wed, 28 Mar 2018 15:09:18 +0000
Subject: [R-sig-ME] FW: Estimating an "unbalanced" SUR with gls
In-Reply-To: <CAO7JsnSRZhrMtHm+qi1kOhmbV0WCKfOU0WhxLRRu1+Jvya86bw@mail.gmail.com>
References: <5105_1522151078_0P68009VAZACKP10_ed0286151be0474fb53b0fb0cc67e7d7@wu.ac.at>
 <CAO7JsnSRZhrMtHm+qi1kOhmbV0WCKfOU0WhxLRRu1+Jvya86bw@mail.gmail.com>
Message-ID: <40849cdeed7d4b2dab80c790bb279b83@wu.ac.at>

Dear Sir or Madam!

I was asked to forward my message to this mailing list (see below). For replication purposes I can share the dataset, if needed.

All the best,
Stephan Lehner

From: Douglas Bates <bates at stat.wisc.edu>
Sent: Dienstag, 27. M?rz 2018 17:36
To: Lehner, Stephan <stephan.lehner at wu.ac.at>
Cc: Peer, Stefanie <stefanie.peer at wu.ac.at>
Subject: Re: Estimating an "unbalanced" SUR with gls

It is best to send questions like this to the R-SIG-Mixed-Models at R-project.org<mailto:R-SIG-Mixed-Models at R-project.org> mailing list. See https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models for details.

On Tue, Mar 27, 2018 at 6:44 AM Lehner, Stephan <stephan.lehner at wu.ac.at<mailto:stephan.lehner at wu.ac.at>> wrote:
Dear Prof. Bates,

I am writing you concerning some issues, I have with the correlation option in gls. For a meta-analysis about parking prices, I am trying to estimate an ?unbalanced? SUR model using the gls function in R.  I estimated the SUR-model with Stata using the following approach: http://ageconsearch.umn.edu/bitstream/116272/2/sjart_st0079.pdf.

I tried the same with R using the following code lines. The data is the same. This means that the data is already ?prepaired? i. e.  (just the fifth step ?Fitting the SUR model? is different) .
---
id ? the time covariate
id2 ? the group covariate
---
Code in R:
cs1CompSymm <- corSymm(form = ~ id | id2)
cs1CompSymm <- Initialize(cs1CompSymm, data = MySUR)
gls_meta.fit.mC1 <- gls(elasticity ~ 0 + consO + consD + consQ + ? , data = MySUR, method="REML", correlation=cs1CompSymm)
---
Code in Stata:
tsset  id2 id
xtgee  elasticity conso consd consq ?, family(gaussian) link(identity) corr(unstructured) noconstant
xtcorr

Problem 1:
The estimated correlation matrix within-id2 in R is completely different to the correlation matrix in Stata. Hence, I am asking myself if the two methods are comparable or if I am missing something.

Stata:
Estimated within-id2 correlation matrix R:

         c1       c2       c3
r1   1.0000
r2   0.4941   1.0000
r3  -0.0289  -0.1557   1.0000

R:
Correlation Structure: General
Formula: ~id | id2
 Parameter estimate(s):
Correlation:
                1              2
2             0.647
3             0.655     0.066

Problem 2:
The results in R change, whether I am using id2 (an integer variable) or id22 (a String variable). Id22 is the integer variable plus a prefix ?ID:?.
cs1CompSymm <- corSymm(form = ~ id | id2)
cs1CompSymm <- corSymm(form = ~ id | id22)

My data is highly unbalanced (just 8 out of 199 observations have a complete group). If is of any help, I am happy to share my dataset with you. I can also send you more information If needed.

Sincerely,

Stephan Lehner, MSc
Research Assistant | PhD candidate
Department for Multi-Level Governance and Development
Vienna University of Economics and Business
Welthandelsplatz 1, D4, Room 2.216
1020 Vienna

+43-1-313 36-5938<tel:+43%201%20313365938>
www.wu.ac.at/mlgd/staff/lehner-stephan-msc/<http://www.wu.ac.at/mlgd/staff/lehner-stephan-msc/>


	[[alternative HTML version deleted]]


From ahmadr215 at tpg.com.au  Thu Mar 29 14:25:14 2018
From: ahmadr215 at tpg.com.au (Ahmad)
Date: Thu, 29 Mar 2018 23:25:14 +1100
Subject: [R-sig-ME] geometric mean regression
Message-ID: <001201d3c758$ff12d4b0$fd387e10$@tpg.com.au>

Hi All

 

I have a dataset and I have been asked to generate geometric means from the
linear regression for different groups (2 groups). 

In fact my data is repeated measures, and I intend to use a mixed-effects
regression model with repeated measures. But I thought I can learn how to do
this for a simple geometric mean regression, I should be able to translate
this into a mixed model.

 

Any help would be greatly appreciated!

 

Thanks

 

Ahmad

 

 


	[[alternative HTML version deleted]]


From d.e.kornbrot at herts.ac.uk  Fri Mar 30 10:28:08 2018
From: d.e.kornbrot at herts.ac.uk (Kornbrot, Diana)
Date: Fri, 30 Mar 2018 08:28:08 +0000
Subject: [R-sig-ME] R-sig-mixed-models Digest, Vol 134, Issue 42
In-Reply-To: <mailman.16168.1318.1519736793.1673.r-sig-mixed-models@r-project.org>
References: <mailman.16168.1318.1519736793.1673.r-sig-mixed-models@r-project.org>
Message-ID: <1A419614-C610-464B-9343-2B284C2DBD75@herts.ac.uk>

Thanks for help

Have now successfully installed emmeans
Now have to figure out why SPSS and R do not agree, and why R thinks df =Inf
________
R       glmer                                                   MIXED
Rab     Between emmean  SE      df      asymp.LCL       asymp.UCL       Rab     Between Mean    SE      lcl     ucl
1       1       -.316   .170    Inf     -.650   .018    1       1       -.267   .148    -.562   .027
2       1       -.820   .172    Inf     -1.158  -.482   2       1       -.688   .169    -1.023  -.352
3       1       -1.838  .183    Inf     -2.196  -1.480  3       1       -1.550  .188    -1.924  -1.176
4       1       -2.558  .198    Inf     -2.946  -2.170  4       1       -2.168  .230    -2.624  -1.712
1       2       .357    .165    Inf     .034    .681    1       2       .297    .144    .011    .583
2       2       -.895   .167    Inf     -1.223  -.567   2       2       -.745   .165    -1.073  -.417
3       2       -2.607  .192    Inf     -2.984  -2.230  3       2       -2.238  .235    -2.705  -1.772
4       2       -2.891  .201    Inf     -3.285  -2.497  4       2       -2.498  .255    -3.005  -1.992
        Df      SS      MS      F                       Source  F       df1     df2     Sig.
Rab     3       870.17  290.06  290.06                  Rab     66.76   3       94      .000000
Between 1       .12     .12     .12                     Between .38     1       93      .539643
Rab:Between     3       63.20   21.07   21.07                   Rab*Between     5.31    3       94      .001998
                                                        Corrected       30.64   7       101     .000000
Somehow need to tell R about the error structure

NB lmer on logit (FreqPos/Nmax) is not the correct binomial model, because it does not take into account the binomial variability inherent in measuring any binary proportion
see Jaeger, T. F. (2008). Categorical Data Analysis: Away from ANOVAs (transformation or not) and towards Logit Mixed Models. J Mem Lang, 59(4), 434-446.
whats more I have tested that there are differences on 17 empirical data sets



On 27 Feb 2018, at 13:06, r-sig-mixed-models-request at r-project.org<mailto:r-sig-mixed-models-request at r-project.org> wrote:

Send R-sig-mixed-models mailing list submissions to
r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>

To subscribe or unsubscribe via the World Wide Web, visit
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
or, via email, send a message with subject or body 'help' to
r-sig-mixed-models-request at r-project.org

You can reach the person managing the list at
r-sig-mixed-models-owner at r-project.org

When replying, please edit your Subject line so it is more specific
than "Re: Contents of R-sig-mixed-models digest..."


Today's Topics:

  1. Re: Including random effects creates structure in the
     residuals (Paul Johnson)
  2. Re: means , CIs from lmer, glmer (Ben Bolker)
  3. Re: Including random effects creates structure in the
     residuals (Pierre de Villemereuil)

----------------------------------------------------------------------

Message: 1
Date: Tue, 27 Feb 2018 11:03:17 +0000
From: Paul Johnson <paul.johnson at glasgow.ac.uk>
To: Pierre de Villemereuil <pierre.de.villemereuil at mailoo.org>
Cc: R SIG Mixed Models <r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] Including random effects creates structure in
the residuals
Message-ID: <64A7142C-55FA-43E8-B457-8C80D8AA1DE4 at glasgow.ac.uk>
Content-Type: text/plain; charset="utf-8"

Hi Pierre,

I don?t think there is a problem with the residuals. Just to check, the problem you see is that there?s a linear trend in the residuals vs fitted values plot when the ID random effect is included (which in a standard OLS LM would be impossible).

The reason for the correlation is that the fitted values contain the ID random effects, and these are inevitably correlated with the residuals. My intuitive understanding of this is as follows. Say some students sit a test twice, on two separate days. A student's score on a given day will be a combination of their ability (ID random effect) and unmeasured (i.e. noise) factors, like how the student was feeling on that day. Assuming that both ability and luck contribute substantially to the scores, it?s inevitable that the extreme upper end of the distribution will be populated by scores from students who are both able (high ID random effect) and were lucky on that day (high error residual). The same goes in the negative direction for the lower end of the distribution. This the basis of is regression to the mean - if we pick a student with an extreme score and re-test them, we expect their score to be less extreme. If I remember correctly it?s fairly straightforward to predict the correlation of the residuals and fitted values for a given model.

On the broader topic of checking residuals from GLMMs?
I wrote a simple function to check residuals from lme4 fits by simulating residuals from the fitted model and plotting them on top of the real residuals. If they look similar on several simulated data sets them I?m reassured that the model fits well. This is particularly useful for non-normal GLMMs where (despite popular belief) there's no assumption of normality of the Pearson residuals.

library(devtools)
install_github("pcdjohnson/GLMMmisc")
library(GLMMmisc)
library(lme4)
fm1 <- lmer(Reaction ~ Days + (Days | Subject), sleepstudy)
sim.residplot(fm1)
# note the correlation between the residuals and the fitted values

Florian Hartig has written a more sophisticated package that uses the same basic idea called DHARMa:
https://cran.r-project.org/web/packages/DHARMa/index.html
His blog post:
https://theoreticalecology.wordpress.com/2016/08/28/dharma-an-r-package-for-residual-diagnostics-of-glmms/

All the best,
Paul


On 27 Feb 2018, at 08:53, Pierre de Villemereuil <pierre.de.villemereuil at mailoo.org> wrote:

Dear all,

I have an issue that I can't get my head around. I am working on a human cohort dataset studying heart rate. We have repeated measures at several time points and a model with different slopes according to binned age categories (the variable called "broken" hereafter, for "broken lines").

My issue is that when I include an individual ID effect (to account for the repeated measures), I obtain structured residuals while this is not the case for a model without this effect.

Here are my models:
mod_withID <- lmer(cardfreq ~ sex +
broken +
age:broken +
betabloq +
cafethe +
tabac +
alcool +
(1|visite) +
(1|id),
  data = sub)
mod_noID <- lmer(cardfreq ~ sex +
broken +
age:broken +
betabloq +
cafethe +
tabac +
alcool +
(1|visite),
 data = sub)

The AIC (computed with a fit with REML = FALSE) clearly favours the model including the ID effect:
AIC(mod_withID)
75184.51
AIC(mod_noID)
76942.09

Yet, the model including the ID effect suffers from a bad fit from the residuals point of view (structured residuals) as the plots below show:
- The residuals with the ID effect:
https://ibb.co/b6WsFx
- The residuals without the ID effect:
https://ibb.co/fFVDNc

From this, I gather that the fixed effect part is good enough to provide a good fit, but there is a covariance from the residuals and the BLUPs from the ID effect (I've checked this). Especially, if we marginalise on the random effects to compute the residuals, then everything is fine, suggesting the issue lies in the random rather than the fixed part.

I'm a bit puzzled by this. Why would adding an individual effect would create such a structure in the residual part? Why does this covariance between the individual BLUPs and the residual arise?

I'd happily take anyone's input on this as I'm at a loss regarding what to do to solve this.

Cheers,
Pierre

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



------------------------------

Message: 2
Date: Tue, 27 Feb 2018 07:14:06 -0500
From: Ben Bolker <bbolker at gmail.com>
To: Rune Haubo <rune.haubo at gmail.com>
Cc: "Kornbrot, Diana" <d.e.kornbrot at herts.ac.uk>, "Paice, Andrew"
<a.paice at herts.ac.uk>, "r-sig-mixed-models at r-project.org"
<r-sig-mixed-models at r-project.org>, "Georgiou, George"
<g.j.georgiou at herts.ac.uk>, "Sullivan, Keith"
<k.sullivan3 at herts.ac.uk>
Subject: Re: [R-sig-ME] means , CIs from lmer, glmer
Message-ID: <c900eade-264f-ca69-af18-2ec0f67d936b at gmail.com>
Content-Type: text/plain; charset="utf-8"


 Yes, that was a thinko on my part.  Thanks.

On 18-02-27 05:22 AM, Rune Haubo wrote:
Just a small note that lmerTest (and the Satterthwaite method for
degrees of freedom) is only meaningful for _linear_ mixed models - not
for the generalized variants such as the one considered here for
proportions.

Best,
Rune

On 27 February 2018 at 02:02, Ben Bolker <bbolker at gmail.com> wrote:
 Hi Diana,

A reproducible example is always helpful/increases your chances of
getting a useful answer ...
It might help if you included the SPSS output (or posted it somewhere
-- note that this list doesn't take HTML-formatted messages nor most
attachments), as many of us don't have access to it.

Look into the (very well-documented) emmeans package:
https://CRAN.R-project.org/package=emmeans
and the lmerTest package (for Satterthwaite df approximations)

On Mon, Feb 26, 2018 at 12:11 PM, Kornbrot, Diana
<d.e.kornbrot at herts.ac.uk> wrote:
I am keen to promote the use of generalised mixed models for the analysis of proportions to psychologists
Have straight fowl code in SPSS [costly] and would like to supply equivalent R Code without ?tears?
Design is a follows raw frequencies are: FreqPos for ?success? and FreqNeg for ?failure?
Predictors are Rab with 4 levels, repeated over participants and Between with 2 separate groups of participants
Model is binomial with logit link

Require following output to correspond to SPSS output from code below
Descriptive: Means, se and 95% CIs  by Rab, by Between and by Rab*Between
Inferential: fo  Rab, Between and  Rab*Between: F value, MSE, numerator df, denominator df [this enables p-values]

Have tried

logit1 <- glmer(cbind(FreqPos,FreqNeg) ~ Rab + Between + Rab*Between + (1| Participant), family=binomial(link="logit"))
gives F and MSE no denominator df or MSE. Different results to SPSS
nb F=MSE - that can?t be right F is supposed to be ratio of chi-squares

summary (logit1)
gives coefficients  and SEs. Different results to SPSS
also tried predicted and fitted but still no means

have spent days searching internet for examples - but none of them seem to show how to get the output I need

All help greatly appreciated

____
Spss syntax

*Generalized Linear Mixed Models.
GENLINMIXED
 /DATA_STRUCTURE SUBJECTS=Participant REPEATED_MEASURES=Rab COVARIANCE_TYPE=UNSTRUCTURED
 /FIELDS TARGET=FreqPos TRIALS=FIELD(Nmax)  OFFSET=NONE
 /TARGET_OPTIONS DISTRIBUTION=BINOMIAL LINK=LOGIT
 /FIXED  EFFECTS=Rab Between Rab*Between USE_INTERCEPT=TRUE
 /BUILD_OPTIONS TARGET_CATEGORY_ORDER=DESCENDING INPUTS_CATEGORY_ORDER=DESCENDING MAX_ITERATIONS=100 CONFIDENCE_LEVEL=95 DF_METHOD=SATTERTHWAITE COVB=MODEL PCONVERGE=0.000001(ABSOLUTE) SCORING=0 SINGULAR=0.000000000001
 /EMMEANS TABLES=Rab COMPARE=Rab CONTRAST=DEVIATION
  /EMMEANS TABLES=Between CONTRAST=NONE
  /EMMEANS TABLES=Rab*Between CONTRAST=NONE
 /EMMEANS_OPTIONS SCALE=ORIGINAL PADJUST=LSD.

best
Diana


_____________________________________
Professor Diana Kornbrot
Mobile
+44 (0) 7403 18 16 12
Work
University of Hertfordshire
College Lane, Hatfield, Hertfordshire AL10 9AB, UK
+44 (0) 170 728 4626
d.e.kornbrot at herts.ac.uk<mailto:d.e.kornbrot at herts.ac.uk>
http://dianakornbrot.wordpress.com/
http://go.herts.ac.uk/Diana_Kornbrot
skype:  kornbrotme
Home
19 Elmhurst Avenue
London N2 0LT, UK
+44 (0) 208 444 2081
------------------------------------------------------------




       [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models




------------------------------

Message: 3
Date: Tue, 27 Feb 2018 14:06:20 +0100
From: Pierre de Villemereuil <pierre.de.villemereuil at mailoo.org>
To: Paul Johnson <paul.johnson at glasgow.ac.uk>
Cc: R SIG Mixed Models <r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] Including random effects creates structure in
the residuals
Message-ID: <1554686.l50GCRrqCa at flyosflip>
Content-Type: text/plain; charset="utf-8"

Hi Paul,

Thank you for your response and interest in my question. While I agree that regression to the mean does exist in these settings, I don't get why this should yield such a correlation between the BLUPs and the residuals (after all, assuming the two are totally independent, you'd still get the same phenomenon you're describing, wouldn't you?). Could you explain why this should be the case? Maybe I'm missing a big point in your explanation, if so, please forgive me.

It got me thinking however, that the correlation between the BLUPs and the residuals could arise from a fundamental constraint in the data as you suggested and I think I now understand what is going on (again, if this is what you suggested, please forgive me as I might have misunderstood your point). A short summary is that it arises from an unbalanced design in the repeated measures (as some individuals do not come back to complete the study).

This can be seen in the following graph, which shows the residuals (e) against the BLUPs (u, which also contains the effect of "visit", but it doesn't impact much the trend here), depending on whether we have 1, 2, 3 or 4 repeated measures for that individual:
https://ibb.co/dDgF3H

It should be expected that there is a perfect linear covariation for only 1 visit, because the BLUP and the residual are basically non identifiable, while this constraint is fading as more repeated measures are added to the data. Does this interpretation makes sense to you?

Thank you for your help! Also the bit about checking residuals in GLMMs, very much interesting, I'll think about DARHMa next time I'll have to do this for a GLMM!

Cheers,
Pierre

Le mardi 27 f?vrier 2018, 12:03:17 CET Paul Johnson a ?crit :
Hi Pierre,

I don?t think there is a problem with the residuals. Just to check, the problem you see is that there?s a linear trend in the residuals vs fitted values plot when the ID random effect is included (which in a standard OLS LM would be impossible).

The reason for the correlation is that the fitted values contain the ID random effects, and these are inevitably correlated with the residuals. My intuitive understanding of this is as follows. Say some students sit a test twice, on two separate days. A student's score on a given day will be a combination of their ability (ID random effect) and unmeasured (i.e. noise) factors, like how the student was feeling on that day. Assuming that both ability and luck contribute substantially to the scores, it?s inevitable that the extreme upper end of the distribution will be populated by scores from students who are both able (high ID random effect) and were lucky on that day (high error residual). The same goes in the negative direction for the lower end of the distribution. This the basis of is regression to the mean - if we pick a student with an extreme score and re-test them, we expect their score to be less extreme. If I remember correctly it?s fairly straightforward to predict the correlation of the residuals and fitted values for a given model.

On the broader topic of checking residuals from GLMMs?
I wrote a simple function to check residuals from lme4 fits by simulating residuals from the fitted model and plotting them on top of the real residuals. If they look similar on several simulated data sets them I?m reassured that the model fits well. This is particularly useful for non-normal GLMMs where (despite popular belief) there's no assumption of normality of the Pearson residuals.

library(devtools)
install_github("pcdjohnson/GLMMmisc")
library(GLMMmisc)
library(lme4)
fm1 <- lmer(Reaction ~ Days + (Days | Subject), sleepstudy)
sim.residplot(fm1)
# note the correlation between the residuals and the fitted values

Florian Hartig has written a more sophisticated package that uses the same basic idea called DHARMa:
https://cran.r-project.org/web/packages/DHARMa/index.html
His blog post:
https://theoreticalecology.wordpress.com/2016/08/28/dharma-an-r-package-for-residual-diagnostics-of-glmms/

All the best,
Paul


On 27 Feb 2018, at 08:53, Pierre de Villemereuil <pierre.de.villemereuil at mailoo.org> wrote:

Dear all,

I have an issue that I can't get my head around. I am working on a human cohort dataset studying heart rate. We have repeated measures at several time points and a model with different slopes according to binned age categories (the variable called "broken" hereafter, for "broken lines").

My issue is that when I include an individual ID effect (to account for the repeated measures), I obtain structured residuals while this is not the case for a model without this effect.

Here are my models:
mod_withID <- lmer(cardfreq ~ sex +
broken +
age:broken +
betabloq +
cafethe +
tabac +
alcool +
(1|visite) +
(1|id),
  data = sub)
mod_noID <- lmer(cardfreq ~ sex +
broken +
age:broken +
betabloq +
cafethe +
tabac +
alcool +
(1|visite),
 data = sub)

The AIC (computed with a fit with REML = FALSE) clearly favours the model including the ID effect:
AIC(mod_withID)
75184.51
AIC(mod_noID)
76942.09

Yet, the model including the ID effect suffers from a bad fit from the residuals point of view (structured residuals) as the plots below show:
- The residuals with the ID effect:
https://ibb.co/b6WsFx
- The residuals without the ID effect:
https://ibb.co/fFVDNc

From this, I gather that the fixed effect part is good enough to provide a good fit, but there is a covariance from the residuals and the BLUPs from the ID effect (I've checked this). Especially, if we marginalise on the random effects to compute the residuals, then everything is fine, suggesting the issue lies in the random rather than the fixed part.

I'm a bit puzzled by this. Why would adding an individual effect would create such a structure in the residual part? Why does this covariance between the individual BLUPs and the residual arise?

I'd happily take anyone's input on this as I'm at a loss regarding what to do to solve this.

Cheers,
Pierre

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



------------------------------

Subject: Digest Footer

_______________________________________________
R-sig-mixed-models mailing list
R-sig-mixed-models at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


------------------------------

End of R-sig-mixed-models Digest, Vol 134, Issue 42
***************************************************

_____________________________________
Professor Diana Kornbrot
Mobile
+44 (0) 7403 18 16 12
Work
University of Hertfordshire
College Lane, Hatfield, Hertfordshire AL10 9AB, UK
+44 (0) 170 728 4626
d.e.kornbrot at herts.ac.uk<mailto:d.e.kornbrot at herts.ac.uk>
http://dianakornbrot.wordpress.com/
http://go.herts.ac.uk/Diana_Kornbrot
skype:  kornbrotme
Home
19 Elmhurst Avenue
London N2 0LT, UK
+44 (0) 208 444 2081
 ------------------------------------------------------------




	[[alternative HTML version deleted]]


From mauriziomarchi85 at gmail.com  Fri Mar 30 10:59:26 2018
From: mauriziomarchi85 at gmail.com (Maurizio Marchi)
Date: Fri, 30 Mar 2018 10:59:26 +0200
Subject: [R-sig-ME] gamm4 package plot and confidence intervals
Message-ID: <CANJhsN0GEHkYotKySEsRK8F8QSMPZkb=6DtTeGN=Qs=EggZg5w@mail.gmail.com>

?Dear List,
I'm working with GAMM models using the gamm4 package and I would like to
plot the ?fitted line with confidence interval (something similar to what
I'm doing con be found at http://dx.doi.org/10.1016/j.scitotenv.2017.09.133
as FIg.1) but I'm having some troubles. Does anybody have any suggestion?
Thanks

-- 
Maurizio Marchi
Skype ID: maurizioxyz
linux user 552742

	[[alternative HTML version deleted]]


From Maarten.Jung at mailbox.tu-dresden.de  Fri Mar 30 11:16:38 2018
From: Maarten.Jung at mailbox.tu-dresden.de (Maarten Jung)
Date: Fri, 30 Mar 2018 09:16:38 +0000
Subject: [R-sig-ME] 
 Simulating linear mixed model data for factorial design
 with 3 levels
In-Reply-To: <CAHr4Dyc_=ZEs2H-Pu0qmHK4opwUb4eAMDwZbm+4HL9r7_LxcaQ@mail.gmail.com>
References: <CAHr4Dyc_=ZEs2H-Pu0qmHK4opwUb4eAMDwZbm+4HL9r7_LxcaQ@mail.gmail.com>
Message-ID: <CAHr4DyedWeNZ4nMtHGQFpRTYBMr52LcO_umEH94iwQormkr0Gg@mail.gmail.com>

It would be really helpful if anyone could give a hint.
I also added the exact model definition to make clear what I am trying to
simulate.
https://stats.stackexchange.com/q/335643/136579

Regards,
Maarten

On Sat, Mar 24, 2018, 11:54 Maarten Jung <Maarten.Jung at mailbox.tu-dresden.de>
wrote:

> Dear list,
>
> I struggle to simulate linear mixed model data for a within-subject
> within-item factorial design (with crossed participant and item effects)
> where the categorical independent variable has three levels.
>
> The default parameters correspond to the estimates I got from an analysis
> of previous data.
> As I am using the mvrnorm() function with empirical = TRUE I expected
> that the estimated parameters from lmer and my specified parameters for
> the simulation would match closely.
> However, they differ more than I expected.
>
> I would be grateful if somebody more experienced in mixed model
> simulations could have a look at my R code on Cross Validate:
> https://stats.stackexchange.com/q/335643/136579
>
>
> Best Regards,
>
> Maarten
>

	[[alternative HTML version deleted]]


From jl.verissimo at gmail.com  Fri Mar 30 11:34:07 2018
From: jl.verissimo at gmail.com (=?ISO-8859-1?Q?Jo=E3o_Ver=EDssimo?=)
Date: Fri, 30 Mar 2018 11:34:07 +0200
Subject: [R-sig-ME] gamm4 package plot and confidence intervals
In-Reply-To: <CANJhsN0GEHkYotKySEsRK8F8QSMPZkb=6DtTeGN=Qs=EggZg5w@mail.gmail.com>
References: <CANJhsN0GEHkYotKySEsRK8F8QSMPZkb=6DtTeGN=Qs=EggZg5w@mail.gmail.com>
Message-ID: <1522402447.11489.1.camel@gmail.com>

Perhaps the 'plotfunctions' package will help:
https://cran.r-project.org/web/packages/plotfunctions/index.html

(its GAMM plot functions were previously in the 'itsadug' package)

Jo?o

On Fri, 2018-03-30 at 10:59 +0200, Maurizio Marchi wrote:
> Dear List,
> I'm working with GAMM models using the gamm4 package and I would like to
> plot the fitted line with confidence interval (something similar to what
> I'm doing con be found at http://dx.doi.org/10.1016/j.scitotenv.2017.09.133
> as FIg.1) but I'm having some troubles. Does anybody have any suggestion?
> Thanks
>


From chirleu at gmail.com  Fri Mar 30 22:53:15 2018
From: chirleu at gmail.com (=?UTF-8?Q?David_Villegas_R=C3=ADos?=)
Date: Fri, 30 Mar 2018 22:53:15 +0200
Subject: [R-sig-ME] use a posterior distribution from one model as fixed
 effect in another model
Message-ID: <CALC46t9kBoNXgB=6D7VhZJ29b84Zc5eFy_+TbympC4+JEeqRyw@mail.gmail.com>

Dear list
I have a conceptual question.

I run a MCMCglmm model (model 1) and extracted the posterior distribution
of the random effects. This is a matrix of 75 (number of individuals) x
5000 (number of iteractions of the model).

Now I'd like to use that posterior distribution (75x5000) as a explanatory
variable X (fixed effect) in another mixed-effect model (model 2). I have
thought of two options:
- Run model 2, 5000 times, one with each of the values of the distribution
of variable X, and then get a distribution of responses
- Run model two, e.g. 1000 times randomly picking one value for the
distribution of variable X on each run,  and then get a distribution of
responses

Could you please give me some advise on how to proceed, and if my thoughts
are correct?
I'd like to know how to do it both with MCMCglmm (Bayesian) and lme or lme4
(frequentist).

Thanks!

David

	[[alternative HTML version deleted]]


From kevin.thorpe at utoronto.ca  Sat Mar 31 15:20:00 2018
From: kevin.thorpe at utoronto.ca (Kevin E. Thorpe)
Date: Sat, 31 Mar 2018 09:20:00 -0400
Subject: [R-sig-ME] geometric mean regression
In-Reply-To: <001201d3c758$ff12d4b0$fd387e10$@tpg.com.au>
References: <001201d3c758$ff12d4b0$fd387e10$@tpg.com.au>
Message-ID: <7ba2186d-8e50-b818-7c94-8bbb4307cca0@utoronto.ca>

Maybe I'm missing something, but doesn't linear regression on log(y) 
accomplish this?

Kevin

On 03/29/2018 08:25 AM, Ahmad wrote:
> Hi All
> 
>   
> 
> I have a dataset and I have been asked to generate geometric means from the
> linear regression for different groups (2 groups).
> 
> In fact my data is repeated measures, and I intend to use a mixed-effects
> regression model with repeated measures. But I thought I can learn how to do
> this for a simple geometric mean regression, I should be able to translate
> this into a mixed model.
> 
>   
> 
> Any help would be greatly appreciated!
> 
>   
> 
> Thanks
> 
>   
> 
> Ahmad
> 


-- 
Kevin E. Thorpe
Head of Biostatistics,  Applied Health Research Centre (AHRC)
Li Ka Shing Knowledge Institute of St. Michael's Hospital
Assistant Professor, Dalla Lana School of Public Health
University of Toronto
email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016


