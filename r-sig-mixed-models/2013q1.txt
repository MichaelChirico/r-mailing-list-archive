From reinhold.kliegl at gmail.com  Tue Jan  1 11:17:25 2013
From: reinhold.kliegl at gmail.com (Reinhold Kliegl)
Date: Tue, 1 Jan 2013 11:17:25 +0100
Subject: [R-sig-ME] algal nonlinear mixed effects problem
In-Reply-To: <loom.20121231T220104-102@post.gmane.org>
References: <50E11123.6090807@mcmaster.ca>
	<loom.20121231T220104-102@post.gmane.org>
Message-ID: <CAG+WrExXMYLA+2YKT0QXbo5TFQkGTRMGe5hJQHB-FivcD22h3Q@mail.gmail.com>

Thanks, Ben, for the illustration of how to use derive(), deparse(),
and eval() for setting up such functions. The following is based on
lme4_0.999999-0.

I modified Ben's attempt at a fit in two ways to get convergence.
(1) The start argument threw an Error; I provide the values in a
vector rather than a list. This might be related to differences
between nlmer implementations.
(2) The start value for asymp.R2 had to be moved away from 0.

The result suggests that there is no reliable evidence for the
variance component associated with "Individual asymp.R1"

A part of the protocol is listed below.
Happy New Year to everyone.

Reinhold Kliegl

Here is the protocol:
> # 4. Attempt the fit
> nlmerfit2 <- nlmer(
+   X ~ fpl(Day, asymp.L, asymp.R1, asymp.R2, asymp.R3, xmid, scale) ~
+          asymp.R1|Individual,
+      start =  list(nlpars=c(asymp.L=0.7,
+      asymp.R1=0.6,asymp.R2=0,asymp.R3=0,xmid=5,scale=1)),data=d)
Fehler: length(start$fixef) > 0 is not TRUE
> # ERROR: length(start$fixef) > 0 is not TRUE
>
> nlmerfit2a <- nlmer(
+   X ~ fpl(Day, asymp.L, asymp.R1, asymp.R2, asymp.R3, xmid, scale) ~
+          asymp.R1|Individual,
+      start =  c(asymp.L=0.6,
asymp.R1=0,asymp.R2=0,asymp.R3=0,xmid=5,scale=1),data=d)
Fehler in mer_finalize(ans) : Downdated X'X is not positive definite, 5.
> # Fehler in mer_finalize(ans) : Downdated X'X is not positive definite, 5.
>
> nlmerfit2b <- nlmer(
+   X ~ fpl(Day, asymp.L, asymp.R1, asymp.R2, asymp.R3, xmid, scale) ~
+          asymp.R1|Individual,
+      start =  c(asymp.L=0.6,
asymp.R1=.1,asymp.R2=0,asymp.R3=0,xmid=5,scale=1),data=d)
> nlmerfit2b
Nonlinear mixed model fit by the Laplace approximation
Formula: X ~ fpl(Day, asymp.L, asymp.R1, asymp.R2, asymp.R3, xmid,
scale) ~      asymp.R1 | Individual
   Data: d
   AIC   BIC   logLik deviance
 16.11 32.02 -0.05555   0.1111
Random effects:
 Groups     Name     Variance   Std.Dev.
 Individual asymp.R1 8.9101e-22 2.985e-11
 Residual            2.0575e-03 4.536e-02
Number of obs: 54, groups: Individual, 9

Fixed effects:
           Estimate Std. Error t value
asymp.L  -2.173e+02  2.187e+05  -0.001
asymp.R1  6.140e+01  5.002e+04   0.001
asymp.R2 -1.917e-02  4.370e+00  -0.004
asymp.R3 -1.207e-01  2.752e+01  -0.004
xmid      6.152e+03  6.167e+06   0.001
scale     4.807e+03  3.610e+06   0.001

Correlation of Fixed Effects:
         asym.L asy.R1 asy.R2 asy.R3 xmid
asymp.R1 -0.357
asymp.R2 -0.677 -0.446
asymp.R3 -0.677 -0.446  1.000
xmid     -1.000  0.357  0.677  0.677
scale    -0.597  0.962 -0.185 -0.185  0.597


On Mon, Dec 31, 2012 at 10:09 PM, Ben Bolker <bbolker at gmail.com> wrote:
> Ben Bolker <bbolker at ...> writes:
>
>>
>>
>>   Inspired by a recent question of Diego Pujoni's on the list
>> ( http://article.gmane.org/gmane.comp.lang.r.lme4.devel/9363/match= ),
>> I started working on the problem, with two realizations:
>>
>>  1. the problem really needs a nonlinear fit: see
>> http://rpubs.com/bbolker/3363
>>
>>  2.  I have no idea how to do an nlmer fit with a non-trivial
>> fixed-effects model (e.g. in nlme we could do
>>
>> nlmefit1 <- nlme(model = X ~ SSfpl(Day, asymp.L, asymp.R,
>>                                    xmid, scale),
>>    fixed = list(asymp.R ~ Group, xmid + scale + asymp.L ~ 1),
>>    random = asymp.R ~ 1 | Individual, ...)
>>
>>   This was raised earlier on stack overflow:
>>
>>
> http://stackoverflow.com/questions/11056625/how-to-add-fixed-effect-to-four-parameter-logistic-model-in-nlmer
>>
>
>   Reinhold Kliegl e-mailed off-list to say that he was able to do
> it / had to do it by hacking up an objective function that accounts
> for the grouping (i.e., more or less doing it by hand).  I have
> implemented this and updated http://rpubs.com/bbolker/3363 , which
> also shows a solution with AD Model Builder; it turns out that at
> least the development version of nlmer is a little too fragile to
> fit the model I wanted to fit (I haven't tested with the stable
> version).
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From reinhold.kliegl at gmail.com  Tue Jan  1 13:49:00 2013
From: reinhold.kliegl at gmail.com (Reinhold Kliegl)
Date: Tue, 1 Jan 2013 13:49:00 +0100
Subject: [R-sig-ME] algal nonlinear mixed effects problem
In-Reply-To: <CAG+WrExXMYLA+2YKT0QXbo5TFQkGTRMGe5hJQHB-FivcD22h3Q@mail.gmail.com>
References: <50E11123.6090807@mcmaster.ca>
	<loom.20121231T220104-102@post.gmane.org>
	<CAG+WrExXMYLA+2YKT0QXbo5TFQkGTRMGe5hJQHB-FivcD22h3Q@mail.gmail.com>
Message-ID: <CAG+WrEzReNrPC+QT7ATJy_LtNzspxv3W2hhwwk6kAkMQ81_QfQ@mail.gmail.com>

I put up an example data set from modeling working-memory accuracy as
a negative exponential function of presentation time and
working-memory load with nlme() and nlmer() at the Potsdam Mind
Research Repository (http://read.psych.uni-potsdam.de/pmr2/ ) under "R
Playground"; click at: Modeling Time-Accuracy Functions with nlmer().
(I still have to graduate to RPubs.)

Finally, a small correction of a typo in my previous post: I changed
the start value of "asymp.R1" (not of "asymp.R2"), as shown in the
protocol.

On Tue, Jan 1, 2013 at 11:17 AM, Reinhold Kliegl
<reinhold.kliegl at gmail.com> wrote:
> Thanks, Ben, for the illustration of how to use derive(), deparse(),
> and eval() for setting up such functions. The following is based on
> lme4_0.999999-0.
>
> I modified Ben's attempt at a fit in two ways to get convergence.
> (1) The start argument threw an Error; I provide the values in a
> vector rather than a list. This might be related to differences
> between nlmer implementations.
> (2) The start value for asymp.R2 had to be moved away from 0.
>
> The result suggests that there is no reliable evidence for the
> variance component associated with "asymp.R1"
>
> A part of the protocol is listed below.
> Happy New Year to everyone.
>
> Reinhold Kliegl
>
> Here is the protocol:
>> # 4. Attempt the fit
>> nlmerfit2 <- nlmer(
> +   X ~ fpl(Day, asymp.L, asymp.R1, asymp.R2, asymp.R3, xmid, scale) ~
> +          asymp.R1|Individual,
> +      start =  list(nlpars=c(asymp.L=0.7,
> +      asymp.R1=0.6,asymp.R2=0,asymp.R3=0,xmid=5,scale=1)),data=d)
> Fehler: length(start$fixef) > 0 is not TRUE
>>
>> nlmerfit2a <- nlmer(
> +   X ~ fpl(Day, asymp.L, asymp.R1, asymp.R2, asymp.R3, xmid, scale) ~
> +          asymp.R1|Individual,
> +      start =  c(asymp.L=0.6,
> asymp.R1=0,asymp.R2=0,asymp.R3=0,xmid=5,scale=1),data=d)
> Fehler in mer_finalize(ans) : Downdated X'X is not positive definite, 5.
>>
>> nlmerfit2b <- nlmer(
> +   X ~ fpl(Day, asymp.L, asymp.R1, asymp.R2, asymp.R3, xmid, scale) ~
> +          asymp.R1|Individual,
> +      start =  c(asymp.L=0.6,
> asymp.R1=.1,asymp.R2=0,asymp.R3=0,xmid=5,scale=1),data=d)
>> nlmerfit2b
> Nonlinear mixed model fit by the Laplace approximation
> Formula: X ~ fpl(Day, asymp.L, asymp.R1, asymp.R2, asymp.R3, xmid,
> scale) ~      asymp.R1 | Individual
>    Data: d
>    AIC   BIC   logLik deviance
>  16.11 32.02 -0.05555   0.1111
> Random effects:
>  Groups     Name     Variance   Std.Dev.
>  Individual asymp.R1 8.9101e-22 2.985e-11
>  Residual            2.0575e-03 4.536e-02
> Number of obs: 54, groups: Individual, 9
>
> Fixed effects:
>            Estimate Std. Error t value
> asymp.L  -2.173e+02  2.187e+05  -0.001
> asymp.R1  6.140e+01  5.002e+04   0.001
> asymp.R2 -1.917e-02  4.370e+00  -0.004
> asymp.R3 -1.207e-01  2.752e+01  -0.004
> xmid      6.152e+03  6.167e+06   0.001
> scale     4.807e+03  3.610e+06   0.001
>
> Correlation of Fixed Effects:
>          asym.L asy.R1 asy.R2 asy.R3 xmid
> asymp.R1 -0.357
> asymp.R2 -0.677 -0.446
> asymp.R3 -0.677 -0.446  1.000
> xmid     -1.000  0.357  0.677  0.677
> scale    -0.597  0.962 -0.185 -0.185  0.597
>
>
> On Mon, Dec 31, 2012 at 10:09 PM, Ben Bolker <bbolker at gmail.com> wrote:
>> Ben Bolker <bbolker at ...> writes:
>>
>>>
>>>
>>>   Inspired by a recent question of Diego Pujoni's on the list
>>> ( http://article.gmane.org/gmane.comp.lang.r.lme4.devel/9363/match= ),
>>> I started working on the problem, with two realizations:
>>>
>>>  1. the problem really needs a nonlinear fit: see
>>> http://rpubs.com/bbolker/3363
>>>
>>>  2.  I have no idea how to do an nlmer fit with a non-trivial
>>> fixed-effects model (e.g. in nlme we could do
>>>
>>> nlmefit1 <- nlme(model = X ~ SSfpl(Day, asymp.L, asymp.R,
>>>                                    xmid, scale),
>>>    fixed = list(asymp.R ~ Group, xmid + scale + asymp.L ~ 1),
>>>    random = asymp.R ~ 1 | Individual, ...)
>>>
>>>   This was raised earlier on stack overflow:
>>>
>>>
>> http://stackoverflow.com/questions/11056625/how-to-add-fixed-effect-to-four-parameter-logistic-model-in-nlmer
>>>
>>
>>   Reinhold Kliegl e-mailed off-list to say that he was able to do
>> it / had to do it by hacking up an objective function that accounts
>> for the grouping (i.e., more or less doing it by hand).  I have
>> implemented this and updated http://rpubs.com/bbolker/3363 , which
>> also shows a solution with AD Model Builder; it turns out that at
>> least the development version of nlmer is a little too fragile to
>> fit the model I wanted to fit (I haven't tested with the stable
>> version).
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbolker at gmail.com  Tue Jan  1 20:30:58 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 01 Jan 2013 14:30:58 -0500
Subject: [R-sig-ME] algal nonlinear mixed effects problem
In-Reply-To: <CAG+WrExXMYLA+2YKT0QXbo5TFQkGTRMGe5hJQHB-FivcD22h3Q@mail.gmail.com>
References: <50E11123.6090807@mcmaster.ca>
	<loom.20121231T220104-102@post.gmane.org>
	<CAG+WrExXMYLA+2YKT0QXbo5TFQkGTRMGe5hJQHB-FivcD22h3Q@mail.gmail.com>
Message-ID: <50E33972.5000500@gmail.com>

On 13-01-01 05:17 AM, Reinhold Kliegl wrote:
> Thanks, Ben, for the illustration of how to use derive(), deparse(),
> and eval() for setting up such functions. The following is based on
> lme4_0.999999-0.
> 
> I modified Ben's attempt at a fit in two ways to get convergence.
> (1) The start argument threw an Error; I provide the values in a
> vector rather than a list. This might be related to differences
> between nlmer implementations.
> (2) The start value for asymp.R2 had to be moved away from 0.
> 
> The result suggests that there is no reliable evidence for the
> variance component associated with "Individual asymp.R1"

  The results are crazy, though -- take a look at the fixed effect
coefficients, or the predicted values ...

> 
> A part of the protocol is listed below.
> Happy New Year to everyone.
> 
> Reinhold Kliegl
> 
> Here is the protocol:
>> # 4. Attempt the fit
>> nlmerfit2 <- nlmer(
> +   X ~ fpl(Day, asymp.L, asymp.R1, asymp.R2, asymp.R3, xmid, scale) ~
> +          asymp.R1|Individual,
> +      start =  list(nlpars=c(asymp.L=0.7,
> +      asymp.R1=0.6,asymp.R2=0,asymp.R3=0,xmid=5,scale=1)),data=d)
> Fehler: length(start$fixef) > 0 is not TRUE
>> # ERROR: length(start$fixef) > 0 is not TRUE
>>
>> nlmerfit2a <- nlmer(
> +   X ~ fpl(Day, asymp.L, asymp.R1, asymp.R2, asymp.R3, xmid, scale) ~
> +          asymp.R1|Individual,
> +      start =  c(asymp.L=0.6,
> asymp.R1=0,asymp.R2=0,asymp.R3=0,xmid=5,scale=1),data=d)
> Fehler in mer_finalize(ans) : Downdated X'X is not positive definite, 5.
>> # Fehler in mer_finalize(ans) : Downdated X'X is not positive definite, 5.
>>
>> nlmerfit2b <- nlmer(
> +   X ~ fpl(Day, asymp.L, asymp.R1, asymp.R2, asymp.R3, xmid, scale) ~
> +          asymp.R1|Individual,
> +      start =  c(asymp.L=0.6,
> asymp.R1=.1,asymp.R2=0,asymp.R3=0,xmid=5,scale=1),data=d)
>> nlmerfit2b
> Nonlinear mixed model fit by the Laplace approximation
> Formula: X ~ fpl(Day, asymp.L, asymp.R1, asymp.R2, asymp.R3, xmid,
> scale) ~      asymp.R1 | Individual
>    Data: d
>    AIC   BIC   logLik deviance
>  16.11 32.02 -0.05555   0.1111
> Random effects:
>  Groups     Name     Variance   Std.Dev.
>  Individual asymp.R1 8.9101e-22 2.985e-11
>  Residual            2.0575e-03 4.536e-02
> Number of obs: 54, groups: Individual, 9
> 
> Fixed effects:
>            Estimate Std. Error t value
> asymp.L  -2.173e+02  2.187e+05  -0.001
> asymp.R1  6.140e+01  5.002e+04   0.001
> asymp.R2 -1.917e-02  4.370e+00  -0.004
> asymp.R3 -1.207e-01  2.752e+01  -0.004
> xmid      6.152e+03  6.167e+06   0.001
> scale     4.807e+03  3.610e+06   0.001
> 
> Correlation of Fixed Effects:
>          asym.L asy.R1 asy.R2 asy.R3 xmid
> asymp.R1 -0.357
> asymp.R2 -0.677 -0.446
> asymp.R3 -0.677 -0.446  1.000
> xmid     -1.000  0.357  0.677  0.677
> scale    -0.597  0.962 -0.185 -0.185  0.597
> 
> 
> On Mon, Dec 31, 2012 at 10:09 PM, Ben Bolker <bbolker at gmail.com> wrote:
>> Ben Bolker <bbolker at ...> writes:
>>
>>>
>>>
>>>   Inspired by a recent question of Diego Pujoni's on the list
>>> ( http://article.gmane.org/gmane.comp.lang.r.lme4.devel/9363/match= ),
>>> I started working on the problem, with two realizations:
>>>
>>>  1. the problem really needs a nonlinear fit: see
>>> http://rpubs.com/bbolker/3363
>>>
>>>  2.  I have no idea how to do an nlmer fit with a non-trivial
>>> fixed-effects model (e.g. in nlme we could do
>>>
>>> nlmefit1 <- nlme(model = X ~ SSfpl(Day, asymp.L, asymp.R,
>>>                                    xmid, scale),
>>>    fixed = list(asymp.R ~ Group, xmid + scale + asymp.L ~ 1),
>>>    random = asymp.R ~ 1 | Individual, ...)
>>>
>>>   This was raised earlier on stack overflow:
>>>
>>>
>> http://stackoverflow.com/questions/11056625/how-to-add-fixed-effect-to-four-parameter-logistic-model-in-nlmer
>>>
>>
>>   Reinhold Kliegl e-mailed off-list to say that he was able to do
>> it / had to do it by hacking up an objective function that accounts
>> for the grouping (i.e., more or less doing it by hand).  I have
>> implemented this and updated http://rpubs.com/bbolker/3363 , which
>> also shows a solution with AD Model Builder; it turns out that at
>> least the development version of nlmer is a little too fragile to
>> fit the model I wanted to fit (I haven't tested with the stable
>> version).
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From reinhold.kliegl at gmail.com  Tue Jan  1 21:26:11 2013
From: reinhold.kliegl at gmail.com (Reinhold Kliegl)
Date: Tue, 1 Jan 2013 21:26:11 +0100
Subject: [R-sig-ME] algal nonlinear mixed effects problem
In-Reply-To: <50E33972.5000500@gmail.com>
References: <50E11123.6090807@mcmaster.ca>
	<loom.20121231T220104-102@post.gmane.org>
	<CAG+WrExXMYLA+2YKT0QXbo5TFQkGTRMGe5hJQHB-FivcD22h3Q@mail.gmail.com>
	<50E33972.5000500@gmail.com>
Message-ID: <CAG+WrEw2z2+MSOb58kGkVa4YEwVjAwPx3QZJBEfZcfX49J4D=Q@mail.gmail.com>

I agree that the estimates are not acceptable; I was just trying to
show that one can get rid of the nlmer() error messages. I also put up
data to show that, in principle, one can get interpretable results
with nlmer() for "well-behaved" data, but apparently the program is
not quite ready for prime time.

As far as the present set of data is concerned, first I would probably
remove the asymp.R1 variance component, but I am not sure in which
direction to take the model from there. I doubt that the logistic
function is a good reference for all three groups; I only see the
logistic function justified for the t2-group. I know about "borrowing
strength", but in this case, I would probably rather borrow strength
to fit the t2-group to the other two. I did not study your ADMB
results in detail, but if your happy with them, this probably is a
defensible solution.


On Tue, Jan 1, 2013 at 8:30 PM, Ben Bolker <bbolker at gmail.com> wrote:
> On 13-01-01 05:17 AM, Reinhold Kliegl wrote:
>> Thanks, Ben, for the illustration of how to use derive(), deparse(),
>> and eval() for setting up such functions. The following is based on
>> lme4_0.999999-0.
>>
>> I modified Ben's attempt at a fit in two ways to get convergence.
>> (1) The start argument threw an Error; I provide the values in a
>> vector rather than a list. This might be related to differences
>> between nlmer implementations.
>> (2) The start value for asymp.R2 had to be moved away from 0.
>>
>> The result suggests that there is no reliable evidence for the
>> variance component associated with "Individual asymp.R1"
>
>   The results are crazy, though -- take a look at the fixed effect
> coefficients, or the predicted values ...
>
>>
>> A part of the protocol is listed below.
>> Happy New Year to everyone.
>>
>> Reinhold Kliegl
>>
>> Here is the protocol:
>>> # 4. Attempt the fit
>>> nlmerfit2 <- nlmer(
>> +   X ~ fpl(Day, asymp.L, asymp.R1, asymp.R2, asymp.R3, xmid, scale) ~
>> +          asymp.R1|Individual,
>> +      start =  list(nlpars=c(asymp.L=0.7,
>> +      asymp.R1=0.6,asymp.R2=0,asymp.R3=0,xmid=5,scale=1)),data=d)
>> Fehler: length(start$fixef) > 0 is not TRUE
>>> # ERROR: length(start$fixef) > 0 is not TRUE
>>>
>>> nlmerfit2a <- nlmer(
>> +   X ~ fpl(Day, asymp.L, asymp.R1, asymp.R2, asymp.R3, xmid, scale) ~
>> +          asymp.R1|Individual,
>> +      start =  c(asymp.L=0.6,
>> asymp.R1=0,asymp.R2=0,asymp.R3=0,xmid=5,scale=1),data=d)
>> Fehler in mer_finalize(ans) : Downdated X'X is not positive definite, 5.
>>> # Fehler in mer_finalize(ans) : Downdated X'X is not positive definite, 5.
>>>
>>> nlmerfit2b <- nlmer(
>> +   X ~ fpl(Day, asymp.L, asymp.R1, asymp.R2, asymp.R3, xmid, scale) ~
>> +          asymp.R1|Individual,
>> +      start =  c(asymp.L=0.6,
>> asymp.R1=.1,asymp.R2=0,asymp.R3=0,xmid=5,scale=1),data=d)
>>> nlmerfit2b
>> Nonlinear mixed model fit by the Laplace approximation
>> Formula: X ~ fpl(Day, asymp.L, asymp.R1, asymp.R2, asymp.R3, xmid,
>> scale) ~      asymp.R1 | Individual
>>    Data: d
>>    AIC   BIC   logLik deviance
>>  16.11 32.02 -0.05555   0.1111
>> Random effects:
>>  Groups     Name     Variance   Std.Dev.
>>  Individual asymp.R1 8.9101e-22 2.985e-11
>>  Residual            2.0575e-03 4.536e-02
>> Number of obs: 54, groups: Individual, 9
>>
>> Fixed effects:
>>            Estimate Std. Error t value
>> asymp.L  -2.173e+02  2.187e+05  -0.001
>> asymp.R1  6.140e+01  5.002e+04   0.001
>> asymp.R2 -1.917e-02  4.370e+00  -0.004
>> asymp.R3 -1.207e-01  2.752e+01  -0.004
>> xmid      6.152e+03  6.167e+06   0.001
>> scale     4.807e+03  3.610e+06   0.001
>>
>> Correlation of Fixed Effects:
>>          asym.L asy.R1 asy.R2 asy.R3 xmid
>> asymp.R1 -0.357
>> asymp.R2 -0.677 -0.446
>> asymp.R3 -0.677 -0.446  1.000
>> xmid     -1.000  0.357  0.677  0.677
>> scale    -0.597  0.962 -0.185 -0.185  0.597
>>
>>
>> On Mon, Dec 31, 2012 at 10:09 PM, Ben Bolker <bbolker at gmail.com> wrote:
>>> Ben Bolker <bbolker at ...> writes:
>>>
>>>>
>>>>
>>>>   Inspired by a recent question of Diego Pujoni's on the list
>>>> ( http://article.gmane.org/gmane.comp.lang.r.lme4.devel/9363/match= ),
>>>> I started working on the problem, with two realizations:
>>>>
>>>>  1. the problem really needs a nonlinear fit: see
>>>> http://rpubs.com/bbolker/3363
>>>>
>>>>  2.  I have no idea how to do an nlmer fit with a non-trivial
>>>> fixed-effects model (e.g. in nlme we could do
>>>>
>>>> nlmefit1 <- nlme(model = X ~ SSfpl(Day, asymp.L, asymp.R,
>>>>                                    xmid, scale),
>>>>    fixed = list(asymp.R ~ Group, xmid + scale + asymp.L ~ 1),
>>>>    random = asymp.R ~ 1 | Individual, ...)
>>>>
>>>>   This was raised earlier on stack overflow:
>>>>
>>>>
>>> http://stackoverflow.com/questions/11056625/how-to-add-fixed-effect-to-four-parameter-logistic-model-in-nlmer
>>>>
>>>
>>>   Reinhold Kliegl e-mailed off-list to say that he was able to do
>>> it / had to do it by hacking up an objective function that accounts
>>> for the grouping (i.e., more or less doing it by hand).  I have
>>> implemented this and updated http://rpubs.com/bbolker/3363 , which
>>> also shows a solution with AD Model Builder; it turns out that at
>>> least the development version of nlmer is a little too fragile to
>>> fit the model I wanted to fit (I haven't tested with the stable
>>> version).
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From sarah.emily.jamieson at gmail.com  Wed Jan  2 05:16:38 2013
From: sarah.emily.jamieson at gmail.com (Sarah Jamieson)
Date: Wed, 2 Jan 2013 17:16:38 +1300
Subject: [R-sig-ME] mixed manova?
Message-ID: <CAGFDZ5JS4XPTuO9Y8zvWEj7YDxnadepjcV5iXpdhvV1S7XyKfA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130102/e391ebac/attachment.pl>

From j.hadfield at ed.ac.uk  Wed Jan  2 06:55:45 2013
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Wed, 02 Jan 2013 05:55:45 +0000
Subject: [R-sig-ME] mixed manova?
In-Reply-To: <CAGFDZ5JS4XPTuO9Y8zvWEj7YDxnadepjcV5iXpdhvV1S7XyKfA@mail.gmail.com>
References: <CAGFDZ5JS4XPTuO9Y8zvWEj7YDxnadepjcV5iXpdhvV1S7XyKfA@mail.gmail.com>
Message-ID: <20130102055545.61921qx0yg4uh0pw@www.staffmail.ed.ac.uk>

Hi,

If there is no natural ordering to the habitats you could use a  
multinomial mixed model, if there is you could use an ordinal mixed  
model. There are various libraries that have functions for fitting  
such models, for example mlogit, mixcat, ordinal & MCMCglmm. It might  
prove tricky with small samples sizes particularly if the number of  
observations per individual is small.

Cheers,

Jarrod

Quoting Sarah Jamieson <sarah.emily.jamieson at gmail.com> on Wed, 2 Jan  
2013 17:16:38 +1300:

> Hi.
>
> I am trying to determine whether habitat usage in birds varies between sex
> (male/female) or among seasons (summer, autumn, winter, spring).  I tracked
> 40 individual birds but my success locating each bird each season varied
> (e.g., in summer I only have data for 33 birds, while in winter I have data
> for all 40).
>
> I think I need to run a mixed manova model      habitat1 habitat2 habitat3
> = sex + season + sex*season + birdID  (birdID as the random factor)
>
> I am VERY new to R and have been flailing for 2 days trying to figure this
> out.  Can anyone help me with codes?
>
> Sarah
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From cargias at yahoo.co.uk  Wed Jan  2 13:47:44 2013
From: cargias at yahoo.co.uk (Carlos Gias)
Date: Wed, 2 Jan 2013 12:47:44 +0000 (GMT)
Subject: [R-sig-ME] nested mixed model with covariate and missing data
Message-ID: <1357130864.63654.YahooMailNeo@web133101.mail.ir2.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130102/d633ddbc/attachment.pl>

From Thierry.ONKELINX at inbo.be  Wed Jan  2 15:44:30 2013
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Wed, 2 Jan 2013 14:44:30 +0000
Subject: [R-sig-ME] nested mixed model with covariate and missing data
In-Reply-To: <1357130864.63654.YahooMailNeo@web133101.mail.ir2.yahoo.com>
References: <1357130864.63654.YahooMailNeo@web133101.mail.ir2.yahoo.com>
Message-ID: <AA818EAD2576BC488B4F623941DA742794783947@inbomail.inbo.be>

Dear Carlos,

Use baseline as an offset factor. That is equivalent of subtracting the baseline from the activity prior to analysis.
(1|subject/neuron) gives you a random effect for both the subject level as the neuron within subject level.
Don't use (1|time) in combination with time as a fixed effect unless time is continuous and you have a fairly large number of different timepoints.
Missing data is not a problem as long as it is missing at random.

So your model looks like this
activity ~ offset(baseline) + treatment*time + (1|subject/neuron)

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey


-----Oorspronkelijk bericht-----
Van: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Carlos Gias
Verzonden: woensdag 2 januari 2013 13:48
Aan: r-sig-mixed-models at r-project.org
Onderwerp: [R-sig-ME] nested mixed model with covariate and missing data

Hi,

I am new to mixed models and not sure how to design a model for my data to use with the lmer function.


I am trying to study the effect of a drug (treatment) in subjects along time. For every subject we measure activity from a (variable) number of neurons at different time points. Therefore, the neuron measurement is nested within subject. I would also like to use the baseline activity measurement as a covariate for each neuron. This is a small sample of the dataset:

subject treatment neuron baseline time activity
1 1 1 3.06 1 7.02
1 1 1 3.06 2 6
1 1 1 3.06 3 9
1 1 2 3 1 5
1 1 2 3 2 6
1 1 2 3 3 9
2 2 3 4.77 1 3
2 2 3 4.77 2 2
2 2 3 4.77 3 1
3 2 3 2.14 1 2.03
3 2 3 2.14 2 2
3 2 3 2.14 3 1.5

I was wondering if the following would be an appropriate model.

activity ~ baseline + treatment*time + (1|subject:neuron) + (1|time)


I am also wondering how I could deal with the problem of missing data. Is there a function/package that could be helpful in this design?

I hope you can help.

Best regards,

Carlos
        [[alternative HTML version deleted]]

* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.


From bburan at galenea.com  Thu Jan  3 16:37:35 2013
From: bburan at galenea.com (Brad Buran)
Date: Thu, 3 Jan 2013 15:37:35 +0000
Subject: [R-sig-ME] linear mixed model with non-monotonic longitudinal
 data
In-Reply-To: <50DDD554.2080003@gmail.com>
References: <3A447989F1B70245B88AF76E028FF8604D541A@DAGN01A-E6.exg6.exghost.com>,
	<50DDD554.2080003@gmail.com>
Message-ID: <3A447989F1B70245B88AF76E028FF8604D5CA5@DAGN01A-E6.exg6.exghost.com>

Hi Ben et al.:

Thanks for the great suggestions.  I tried the models you suggested (e.g. ~genotype*time+(1|subject_id)).  I think it's clear that the dataset I'm trying to fit is not well-described by any of these models.  At least one of the models I tested is probably very similar to how SPSS implements it, so it's probably a safe bet that I'm using the wrong approach.  

We set genotype as a fixed effect because it appears (based on some literature I read) that it is the appropriate approach (i.e. we are interested comparing the two genotypes tested).

Thanks again for all your help,
Brad

________________________________________
From: Ben Bolker [bbolker at gmail.com]
Sent: Friday, December 28, 2012 12:22 PM
To: Brad Buran
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] linear mixed model with non-monotonic longitudinal data

On 12-12-27 05:31 PM, Brad Buran wrote:

> That was very helpful.  It didn't occur to me that it was possible
  to use functions such as poly in the equation.  That said, it seems
  that none of the models (i.e. the ones I mentioned nor the ones you
  suggested) seem to be a good fit for the data based on the
  residuals.  Since the original model was defined in SPSS (using the
  genlinmixed function), I want to try to determine the actual model
  that SPSS uses (they make you step through a GUI to define your
  model rather than defining an equation like R does).  I haven't been
  able to find any documentation on how the inputs to the genlinmixed
  command are transformed into a model that I could try to create in R
  (so I can check it's validity).

> Is anyone aware of how SPSS model GENLINMIXED with
  SUBJECTS=subject_id, REPEATED_MEASURES=time, FIXED_EFFECTS=genotype
  time genotype*time would translate to a R formula?

   I *think* this would be something like

 ~ genotype+time+genotype:time + (1|subject_id)

or equivalently

 ~ genotype*time + (1|subject_id)

  I assume that (1) there are multiple subjects per genotype
(otherwise subject_id and genotype would be confounded) and
perhaps only one sample per subject -- otherwise it would make
more sense to use (time|subject_id) to allow a time-by-subject
interaction.

  In the R specification it seems one doesn't need both
SUBJECTS and REPEATED_MEASURES (although maybe SPSS does
something else with the REPEATED_MEASURES specification, such
as allowing an R-side autoregressive model to be specified?)
Or else I'm missing something (quite likely).

  I'm also a little surprised that genotype is a fixed effect,
unless the sample size is small (or SPSS doesn't allow multiple,
nested random effects ...)  I would think a model like

 ~ time + (time|genotype/subject_id)

would be best in general?

  Re: time signal -- did you try a GAM? It's a little hard to
see how that could fail to fit a reasonably smooth signal, unless
the shape was really weird ... I can appreciate that quadratics
wouldn't do the job (there are more exotic options like Ricker,
power = a*time*exp(-b*time), which can be done if you are allowed
a logarithmic link and an offset:

  log(power) ~ offset(log(time)) + time



> Thanks!
> Brad
> ________________________________________
> From: r-sig-mixed-models-bounces at r-project.org [r-sig-mixed-models-bounces at r-project.org] on behalf of Ben Bolker [bbolker at gmail.com]
> Sent: Thursday, December 27, 2012 10:49 AM
> To: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] linear mixed model with non-monotonic longitudinal      data
>
> Brad Buran <bburan at ...> writes:
>
>>  I'm attempting to fit a linear mixed model to my dataset.  This
>> data is the measure of stimulus-evoked power as a function of time.
>> We have 32 subjects from two populations (broken down by genotype).
>> The stimulus-evoked power is sampled at a high rate (one data-point
>> every 5 msec) and reflects the "longitudinal" or "within-subjects"
>> measure in my study.
>
>> Right now I've defined the model as:
>>
>> power ~ genotype * time + (1|subject_id)
>>
>> I understand that one must also test additional models such as:
>>
>> power ~ genotype * time + (time|subject_id)
>> power ~ genotype * time + (1|subject_id) + (0+time|subject_id)
>
>> However, power is not a linear function of time (i.e. it is
>> non-monotonic).  Power rapidly increases over a few hundred
>> milliseconds to a peak value then gradually declines afterwards.  In
>> this situation, would it be inappropriate to use time for
>> determining a slope for the random effect?
>
>> I'm actually not even sure whether a linear mixed model is
>> appropriate for this type of data (considering the power response is
>> non-monotonic with respect to time).  However, this is how the
>> original analysis was set up by a predecessor and I am currently
>> trying to determine the validity of this approach.  Thanks, Brad
>
>   Hard to answer completely in general.  The simplest approach
> would probably be to make the response a quadratic function of
> time; there are a few slightly complicating issues (whether to
> use a boneheaded approach such as (genotype * (time + I(time^2))) or
> to use poly(time,2) , which constructs orthogonal polynomials
> by default, and how to get the time*subject interactions specified
> correctly), but it's pretty easy and if it looks like it fits
> your data well I might be satisfied with it.
>   You could also fit generalized additive mixed
> models (see the mgcv and gamm4 packages), again I'm not 100%
> sure how to incorporate the time*subject interactions.
>
>   The bottom line is that linear models are actually pretty
> flexible for modeling continuous, not necessarily linear,
> responses (the assumption is that the model is a linear function
> of the parameters, not necessarily that (e.g.) power is
> a linear function of time).
>
>   Ben Bolker
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From matthew.r.robinson at sheffield.ac.uk  Fri Jan  4 11:38:23 2013
From: matthew.r.robinson at sheffield.ac.uk (Matthew Robinson)
Date: Fri, 4 Jan 2013 10:38:23 +0000
Subject: [R-sig-ME] Meta-analysis in MCMCglmm
Message-ID: <260BC615-2814-4A81-9F80-2921D0DCFA16@sheffield.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130104/3d733fe4/attachment.pl>

From j.hadfield at ed.ac.uk  Fri Jan  4 12:17:56 2013
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Fri, 04 Jan 2013 11:17:56 +0000
Subject: [R-sig-ME] Meta-analysis in MCMCglmm
In-Reply-To: <260BC615-2814-4A81-9F80-2921D0DCFA16@sheffield.ac.uk>
References: <260BC615-2814-4A81-9F80-2921D0DCFA16@sheffield.ac.uk>
Message-ID: <20130104111756.16101ithfxbcb90g@www.staffmail.ed.ac.uk>

Hi Matt,

You're Z matrix after svd is diagonal with entries equal to the  
square-root of the standard error. i.e:

diag(sqrt(data$SE))

This is incorrect because it would imply the sampling variance is  
equal to the standard error. This is correct:

diag(data$SE)

Note that with idh structure nu=7  is very very informative, because  
it is equivalent to 7 degrees of freedom on a single variance.

Multiplying the effect and the SE by a constant should make little  
difference if the analysis is set up correctly, but because the  
sqrt(SE) was used rather than the SE you should expect large  
differences that do not make sense.

Cheers,

Jarrod








Quoting Matthew Robinson <matthew.r.robinson at sheffield.ac.uk> on Fri,  
4 Jan 2013 10:38:23 +0000:

> Dear list,
> I am trying to run a random effects meta-analysis in MCMCglmm. I  
> have a data set of 960 effect size estimates and their standard  
> errors for eight traits (120 estimates per trait).
> What I want to know is if there are any differences among traits in  
> both mean effect size and in the variance of their effect sizes.
> So I have created a diagonal matrix of the standard errors (SE) and  
> used singular value decomposition to create a model matrix (Z) which  
> I have then fit using idv(Z) whilst fixing the variance to 1. I have  
> also estimated an effect of trait as random, and then estimated a  
> separate residual variance for each trait. My coding is below:
>
> Rmat<-matrix(0,nrow(data),nrow(data))
> diag(Rmat)<-data$SE
> Rsvd<-svd(Rmat)
> Rsvd<-Rsvd$v%*%(t(Rsvd$u)*sqrt(Rsvd$d))
> data$row<-1:nrow(data)
> data$row<-factor(data$row)
> Z<-model.matrix(~row-1, data)%*%Rsvd
> data$Z<-Z
> prior=list(R=list(V=diag(8), nu=7),  
> G=list(G1=list(V=diag(1),nu=1,alpha.mu=rep(0,1),alpha.V=diag(1)*1000),G2=list(V=1,  
> fix=1)))
> m1<-MCMCglmm(estimate ~ 1, random=~Trait + idv(Z), rcov=~  
> idh(Trait):units, data=data, prior=prior, family="gaussian",  
> pr=TRUE, burnin=40000, thin=100, nitt=140000)
>
>
> I first wanted to check if this seemed sensible to people?
>
> One issue is that all of the estimates are quite small numbers,  
> ranging from 0 to 0.14. I have tried multiplying all of my data  
> (effect sizes and their SE) by 10 and then re-running the exact same  
> model and this seems to make the posterior traces look much better.  
> So secondly I wanted to get an opinion on whether this is a sensible  
> thing to do?
>
> Many thanks in advance for any advice anyone can provide.
>
> Best wishes,
> Matt
>
>
> ------------------------------------------------------
> Dr. Matt Robinson
> NERC Research Fellow
> Department of Animal and Plant Science
> University of Sheffield
> Alfred Denny Building, Western Bank
> Sheffield, S10 2TN, UK
>
> matthew.r.robinson at sheffield.ac.uk
>
> tel:  +44 (0)114 222 4707
> fax: +44 (0)114 222 0002
> ------------------------------------------------------
>
>
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From theoni.photopoulou at gmail.com  Fri Jan  4 12:58:24 2013
From: theoni.photopoulou at gmail.com (Theoni Photopoulou)
Date: Fri, 4 Jan 2013 11:58:24 +0000
Subject: [R-sig-ME] Error using dredge with an MCMCglmm object
Message-ID: <CAOjPYTTD0pi4mc8mvQEEsgc-Yj85zdQ6bLXXyhU_C9YdQmf2eg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130104/8decbf7d/attachment.pl>

From leanneheisler at hotmail.com  Fri Jan  4 22:40:34 2013
From: leanneheisler at hotmail.com (leanne heisler)
Date: Fri, 4 Jan 2013 15:40:34 -0600
Subject: [R-sig-ME] Cholmod warning with glmer
Message-ID: <COL120-W6C93C31483FCB431B6AA9AE200@phx.gbl>


Hi All,
I am running a generalized linear mixed effects model with lme4 and am getting an error I have not been able to decipher. I was hoping for some guidance. I am using the following code:

> glmer(DM~PREC+(1|NEST)+(1|NG)+(1|LONG),data=data,family=poisson,verbose=TRUE)
 0: 6107.8287: 1.34084 1.29515 0.532795 3.23218 -0.00145626
 1: 6107.8287: 1.34084 1.29515 0.532795 3.23218 -0.00145626
Error in mer_finalize(ans) : Downdated X'X is not positive definite, 1.
In addition: Warning messages:
1: In mer_finalize(ans) :
 Cholmod warning 'not positive definite' at file:../Cholesky/t_cholmod_rowfac.c, line 431
2: In mer_finalize(ans) :
 Cholmod warning 'not positive definite' at file:../Cholesky/t_cholmod_rowfac.c, line 431
All fixed and random effects are continuous variables (DM is counts of deer mice) except for the random effect 'NEST', which is categorical. The model runs fine when the random effects NEST and LONG are removed.

I feel I am doing something wrong here and would greatly appreciate any help from this mailing list.

Thank you in advance.
---------------
 Leanne Heisler
 Graduate Student
 Department of Biology
 University of Regina 		 	   		  

From bates at stat.wisc.edu  Fri Jan  4 23:33:51 2013
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 4 Jan 2013 16:33:51 -0600
Subject: [R-sig-ME] Cholmod warning with glmer
In-Reply-To: <COL120-W6C93C31483FCB431B6AA9AE200@phx.gbl>
References: <COL120-W6C93C31483FCB431B6AA9AE200@phx.gbl>
Message-ID: <CAO7JsnSm9KWRYfer==V3_9vjvWtN3skaE8P1fE9PB86t2xG-+A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130104/6fa400e9/attachment.pl>

From leanneheisler at hotmail.com  Sat Jan  5 01:02:30 2013
From: leanneheisler at hotmail.com (leanne heisler)
Date: Fri, 4 Jan 2013 18:02:30 -0600
Subject: [R-sig-ME] Cholmod warning with glmer
Message-ID: <COL120-W51810A3D0E1A1B681A009AE270@phx.gbl>


The results of str(data) are:

> str(data)
'data.frame': 930 obs. of 14 variables:
 $ NEST : Factor w/ 627 levels "#10 Treesbank",..: 2 7 9 42 43 45 48 67 73 81 ...
$ LONG : num -101 -111 -111 -112 -112 ...
 $ NG : num 0.34 0.8 0.82 0.6 0.7 0.54 0.05 0 0.95 0.3 ...
$ DM : int 1 1 1 1 1 1 1 1 1 1 ...
 $ GDD : num 752 758 715 639 639 ...
 $ PREC : num 221.3 142.9 68.7 186.9 185.9 ...
 $ SNOW : num 27.8 14.1 35 19.2 19.2 ...
 $ GDDT1 : num 2201 2278 2206 2106 2105 ...
 $ PRECT1: num 271 249 276 222 221 ...
 $ SNOWT1: num 36.7 17.2 14.1 34.3 34.2 ...

---------------
 Leanne Heisler
 Graduate Student
 Department of Biology
 University of Regina 		 	   		  

From dwinsemius at comcast.net  Sun Jan  6 02:22:26 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 5 Jan 2013 17:22:26 -0800
Subject: [R-sig-ME] Cholmod warning with glmer
In-Reply-To: <COL120-W6C93C31483FCB431B6AA9AE200@phx.gbl>
References: <COL120-W6C93C31483FCB431B6AA9AE200@phx.gbl>
Message-ID: <60680F04-E7EA-4CEF-9293-7752444FFF1E@comcast.net>


On Jan 4, 2013, at 1:40 PM, leanne heisler wrote:

> 
> Hi All,
> I am running a generalized linear mixed effects model with lme4 and am getting an error I have not been able to decipher. I was hoping for some guidance. I am using the following code:
> 
>> glmer(DM~PREC+(1|NEST)+(1|NG)+(1|LONG),data=data,family=poisson,verbose=TRUE)
> 0: 6107.8287: 1.34084 1.29515 0.532795 3.23218 -0.00145626
> 1: 6107.8287: 1.34084 1.29515 0.532795 3.23218 -0.00145626
> Error in mer_finalize(ans) : Downdated X'X is not positive definite, 1.
> In addition: Warning messages:
> 1: In mer_finalize(ans) :
> Cholmod warning 'not positive definite' at file:../Cholesky/t_cholmod_rowfac.c, line 431
> 2: In mer_finalize(ans) :
> Cholmod warning 'not positive definite' at file:../Cholesky/t_cholmod_rowfac.c, line 431
> All fixed and random effects are continuous variables (DM is counts of deer mice) except for the random effect 'NEST', which is categorical. The model runs fine when the random effects NEST and LONG are removed.

LONG appears to be integer and it might be useful to look at table(data$LONG) and table(data$NG). 

> 
> I feel I am doing something wrong here and would greatly appreciate any help from this mailing list.
> 
Pasting in your other message:

> The results of str(data) are:
> 
>> str(data)
> 'data.frame': 930 obs. of 14 variables:
> $ NEST : Factor w/ 627 levels "#10 Treesbank",..: 2 7 9 42 43 45 48 67 73 81 ...
> $ LONG : num -101 -111 -111 -112 -112 ...
> $ NG : num 0.34 0.8 0.82 0.6 0.7 0.54 0.05 0 0.95 0.3 ...
> $ DM : int 1 1 1 1 1 1 1 1 1 1 ...
> $ GDD : num 752 758 715 639 639 ...
> $ PREC : num 221.3 142.9 68.7 186.9 185.9 ...
> $ SNOW : num 27.8 14.1 35 19.2 19.2 ...
> $ GDDT1 : num 2201 2278 2206 2106 2105 ...
> $ PRECT1: num 271 249 276 222 221 ...
> $ SNOWT1: num 36.7 17.2 14.1 34.3 34.2 ...

You are of necessity going to have quite a few levels where NEST has only one value since 627 values are distributed of 930 rows. I think a cross-tabulation of those random effects will build a fairly sparse data object.

-- 

David Winsemius
Alameda, CA, USA


From bbolker at gmail.com  Sun Jan  6 03:52:37 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 6 Jan 2013 02:52:37 +0000 (UTC)
Subject: [R-sig-ME] Cholmod warning with glmer
References: <COL120-W6C93C31483FCB431B6AA9AE200@phx.gbl>
	<60680F04-E7EA-4CEF-9293-7752444FFF1E@comcast.net>
Message-ID: <loom.20130106T034805-132@post.gmane.org>

David Winsemius <dwinsemius at ...> writes:

> On Jan 4, 2013, at 1:40 PM, leanne heisler wrote:

> > I am running a generalized linear mixed effects model with lme4
> and am getting an error I have not been able to decipher. I was
> hoping for some guidance. I am using the following code:

> >> glmer(DM~PREC+(1|NEST)+(1|NG)+(1|LONG),data=data,
>> family=poisson,verbose=TRUE)
> > 0: 6107.8287: 1.34084 1.29515 0.532795 3.23218 -0.00145626
> > 1: 6107.8287: 1.34084 1.29515 0.532795 3.23218 -0.00145626
> > Error in mer_finalize(ans) : Downdated X'X is not positive definite, 1.
> > In addition: Warning messages:

 [snip]

> > All fixed and random effects are continuous variables (DM is
> counts of deer mice) except for the random effect 'NEST', which is
> categorical. The model runs fine when the random effects NEST and
> LONG are removed.
 
> LONG appears to be integer and it might be useful to look at
>  table(data$LONG) and table(data$NG).
> 
> > The results of str(data) are:
> > 
> >> str(data)
> > 'data.frame': 930 obs. of 14 variables:
> > $ NEST : Factor w/ 627 levels "#10 Treesbank",..: 2 7 9 42 [snip]
> > $ LONG : num -101 -111 -111 -112 -112 ...
> > $ DM : int 1 1 1 1 1 1 1 1 1 1 ...
> > $ PREC : num 221.3 142.9 68.7 186.9 185.9 ...

> You are of necessity going to have quite a few levels where NEST has
> only one value since 627 values are distributed of 930 rows. I think
> a cross-tabulation of those random effects will build a fairly
> sparse data object.

  I don't think that will matter that much, but it may matter how
many distinct values of LONG there are (impossible to tell from
this summary, as David said you should try table(data$LONG) ...)

  This doesn't normally matter much, but glmer can be finicky so
I would take a shot at scaling and centering PREC:

data$scPREC <- scale(data$PREC)

and then continue with scPREC as the predictor (the reason this
matters is that the variance components are often fairly small
(on the order of 1 or less), while your precipitation is measured
in the hundreds -- this difference in scales can cause problems
for the numerical optimization algorithm used.

  Ben Bolker


From j.hadfield at ed.ac.uk  Sun Jan  6 17:00:00 2013
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Sun, 06 Jan 2013 16:00:00 +0000
Subject: [R-sig-ME] Error using dredge with an MCMCglmm object
In-Reply-To: <CAOjPYTTD0pi4mc8mvQEEsgc-Yj85zdQ6bLXXyhU_C9YdQmf2eg@mail.gmail.com>
References: <CAOjPYTTD0pi4mc8mvQEEsgc-Yj85zdQ6bLXXyhU_C9YdQmf2eg@mail.gmail.com>
Message-ID: <20130106160000.45972tjy5n1txyuc@www.staffmail.ed.ac.uk>

Dear Theoni,

I'm not familiar with MuMIn so can't comment on the error. However, I  
would not advocate DIC for model comparison; see:  
https://stat.ethz.ch/pipermail/r-sig-mixed-models/2012q2/018096.html

Cheers,

Jarrod








Quoting Theoni Photopoulou <theoni.photopoulou at gmail.com> on Fri, 4  
Jan 2013 11:58:24 +0000:

> Dear list,
>
> I am using MCMCglmm to fit a model to metadata on learning in animals. The
> response is the proportion of animals in a group that solve a task, the
> random effects are the species and the study, and I have eight fixed
> effects. The dataset is quite small, at 62 observations. The model
> specification
> is as follows:
>
> # setting up the prior
>
> p.var <- var(I(subdata2$n_solve/subdata2$group_size), na.rm=TRUE)
>
> b <- 1e+08
>
> B1_V <- diag(9)*b; B1_mu <- rep(0,9); B1_V; B1_mu
>
> prior <- list(R=list(V=diag(1)*p.var*0.1, n=1, nu=0.002), G=list(G1=list(V
> =diag(1)*p.var*0.6, n=Gn1), G2=list(V=diag(1)*p.var*0.2, n=Gn2)), B=list(V=
> B1_V, mu=B1_mu))
>
>
> # fitting the model
>
> model <- MCMCglmm(cbind(n_solve, group_size-n_solve) ~ var1 + var2 + var3 +
> var4 + var5 + var6 + var7 + var8,
>
> family="multinomial2", random= ~animal + study,
>
> start=list(QUASI=TRUE),
>
> prior=prior, data=subdata2, pedigree=myreducedtree_3,
>
> thin=100, nitt=150000, burnin=50000, verbose=F, pr=T, pl=T, nodes="TIPS")
> The model converges and everything looks ok so I now want to do model
> selection. I read in the help file for the MuMIn package that it now
> accepts MCMCglmm objects with DIC as the rank function but I get an error
> message when I run the following code:
>
> model.dredge <- dredge(model, rank="DIC")
>
> Error in dredge(model, rank = "DIC") :
>
>   could not retrieve the call to 'global.model'
>
> I will do model selection manually if needs be, but it would be good not to
> have to. I also looked for a generic implementation of RJMCMC in R but
> didn't come up with anything. Any pointers or ideas on why this might not
> be working will be very much appreciated.
>
> Thanks in advance,
> Theoni
>
> --
> Theoni Photopoulou, Research Fellow
> Centre for Social Learning and Cognitive Evolution
> Bute Medical Building, University of St Andrews, Scotland KY16 9TS, UK
> tel. +44 1334 467230 / skype. theoni_p / email. tp14 at st-andrews.ac.uk
>
> The University of St Andrews is a charity registered in Scotland : No
> SC013532
> " Be silly. Be honest. Be kind " Ralph Waldo Emerson
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From leanneheisler at hotmail.com  Sun Jan  6 04:19:19 2013
From: leanneheisler at hotmail.com (leanne heisler)
Date: Sat, 5 Jan 2013 21:19:19 -0600
Subject: [R-sig-ME] Cholmod warning with glmer
Message-ID: <COL120-W568300CAD1C685CDBF589AE260@phx.gbl>


Thank you Dr. Winsemius, when I converted the LONG values to positives the first error does not occur ( Error in mer_finalize(ans) : Downdated X'X is not positive definite, 1.). Would you be able to explain why this is, just curious!
 
LONG is actually the longitude at which samples were collected.
> table(data$LONG)
100 101 102 103 104 105 106 107 108 109 110 111 112 113 
2 9 3 1 106 304 40 5 69 78 114 122 106 7 
NG is a proportion between 0 and 1
> table(data$NG)
 0 0.01 0.02 0.03 0.04 0.05 0.06 0.07 0.08 0.09 0.1 0.11 0.12 0.13 0.14 0.15 0.16 0.17 0.18 0.19 0.2 0.21 0.22 0.23 
94 27 35 33 28 22 60 23 14 7 6 13 10 14 1 3 3 4 4 7 5 3 19 7 
0.24 0.25 0.26 0.27 0.28 0.29 0.3 0.31 0.32 0.33 0.34 0.35 0.36 0.37 0.38 0.39 0.4 0.41 0.42 0.43 0.44 0.45 0.46 0.47 
4 4 3 11 5 8 7 10 8 8 11 4 6 7 8 12 17 7 6 8 7 10 10 6 
0.48 0.49 0.5 0.51 0.52 0.53 0.54 0.55 0.56 0.57 0.58 0.59 0.6 0.61 0.62 0.63 0.64 0.65 0.66 0.67 0.68 0.69 0.7 0.71 
12 18 15 8 4 6 19 5 7 7 2 7 5 4 5 2 3 4 3 9 1 7 15 7 
0.72 0.73 0.74 0.75 0.76 0.77 0.78 0.79 0.8 0.81 0.82 0.83 0.84 0.85 0.86 0.87 0.88 0.89 0.9 0.91 0.92 0.93 0.94 0.95 
6 4 2 1 6 3 6 1 5 7 9 4 7 7 2 5 2 6 13 7 2 8 7 6 
0.96 0.97 0.98 0.99 1 
7 9 6 13 1 
However, the last two warnings remain:
 
> dm=glmer(DM~PREC+(1|NEST)+(1|NG)+(1|LONG),data=data,family=poisson,REML=FALSE)
Warning messages:
1: In mer_finalize(ans) :
 Cholmod warning 'not positive definite' at file:../Cholesky/t_cholmod_rowfac.c, line 432
2: In mer_finalize(ans) :
 Cholmod warning 'not positive definite' at file:../Cholesky/t_cholmod_rowfac.c, line 432
3: In mer_finalize(ans) : singular convergence (7)
 
I've tried removing each random effect, and it works (with false convergence though) when LONG is removed (code below), so I think the problem lies with this random effect. If anyone has any suggestions as to why this variable is problematic in my model, it would be greatly appreciated!
 
> dm=glmer(DM~PREC+(1|NEST)+(1|NG),data=data,family=poisson,REML=FALSE,verbose=TRUE)
 0: 6240.2919: 1.34570 0.528027 3.19617 -0.00146991
 1: 6240.1850: 1.34569 0.528031 3.19616 -0.00156918
 2: 6240.1850: 1.34569 0.528031 3.19616 -0.00156918
Warning message:
In mer_finalize(ans) : false convergence (8)
 
Thank you,
 Leanne Heisler
 Graduate Student
 Department of Biology
 University of Regina 		 	   		  

From bbolker at gmail.com  Mon Jan  7 01:54:22 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 7 Jan 2013 00:54:22 +0000 (UTC)
Subject: [R-sig-ME] Cholmod warning with glmer
References: <COL120-W568300CAD1C685CDBF589AE260@phx.gbl>
Message-ID: <loom.20130107T013958-997@post.gmane.org>

leanne heisler <leanneheisler at ...> writes:


> Thank you Dr. Winsemius, when I converted the LONG values to
> positives the first error does not occur ( Error in
> mer_finalize(ans) : Downdated X'X is not positive definite,
> 1.). Would you be able to explain why this is, just curious!

  Meaning you took the absolute value?  Were all the longitudes
negative and you flipped the sign?  This makes not much sense
to me ...
 
> LONG is actually the longitude at which samples were collected.
> > table(data$LONG)
> 100 101 102 103 104 105 106 107 108 109 110 111 112 113 
> 2 9 3 1 106 304 40 5 69 78 114 122 106 7 

> NG is a proportion between 0 and 1
> > table(data$NG)

[snip]

It rarely (although I wouldn't say never) makes sense to treat
continuous predictor variables as random effects: the main reason
would be if there were multiple samples per value, and if the
continuous predictor were *also* included as a fixed effect,
then the random effect would capture deviations from the overall
smooth (fixed-effect) trend.

> However, the last two warnings remain:
> 
>  dm=glmer(DM~PREC+(1|NEST)+(1|NG)+(1|LONG),
>     data=data,family=poisson,REML=FALSE)
> Warning messages:
> 1: In mer_finalize(ans) :
>  Cholmod warning 'not positive definite' at
file:../Cholesky/t_cholmod_rowfac.c, line 432
> 2: In mer_finalize(ans) :
>  Cholmod warning 'not positive definite' at
file:../Cholesky/t_cholmod_rowfac.c, line 432
> 3: In mer_finalize(ans) : singular convergence (7)
 
> I've tried removing each random effect, and it works (with false
> convergence though) when LONG is removed (code below), so I think
> the problem lies with this random effect. If anyone has any
> suggestions as to why this variable is problematic in my model, it
> would be greatly appreciated!
 
> > dm=glmer(DM~PREC+(1|NEST)+(1|NG),data=data,
>  family=poisson,REML=FALSE,verbose=TRUE)
>  0: 6240.2919: 1.34570 0.528027 3.19617 -0.00146991
>  1: 6240.1850: 1.34569 0.528031 3.19616 -0.00156918
>  2: 6240.1850: 1.34569 0.528031 3.19616 -0.00156918
> Warning message:
> In mer_finalize(ans) : false convergence (8)

  It's hard to debug in this iterative way.  Are you willing
to post the data somewhere, or e-mail it?

 Ben Bolker


From steve.taylor at aut.ac.nz  Mon Jan  7 02:33:52 2013
From: steve.taylor at aut.ac.nz (Steve Taylor)
Date: Mon, 7 Jan 2013 01:33:52 +0000
Subject: [R-sig-ME] stepwise model selection (of fixed effects only) using
	AIC?
Message-ID: <CCE952776B6679469977532BD863C39C356711C8@Lewis.autuni.aut.ac.nz>

Hello mixed modellers,

I note that one can fit mixed models and compare them by AIC using anova(), as in example(glmer).

But step() doesn't work on the models produced by glmer() - evidently because they are S4 objects, rather than some more philosophical objection to doing so.

I want to select among combinations of fixed effect components only, as one would do with step(glm()).

My data set consists of two repeated measurements (say, at age 9 and age 11) on each of about 900 people. There are about 8 potential fixed effect covariates that I wish to evaluate, including interaction terms with Age (as a two-level factor).  The only random effect I'm assuming is an intercept per participant.

Can anyone help with a way to do this?

Here's my attempt, ignoring the random effect during model selection.  Is this a reasonable thing to do?

modeldata1 = subset(modeldata, select= -Participant)
glm0 = glm(Outcome ~ Age, data=modeldata1, family=binomial)
glm1 = glm(Outcome ~ .*Age, data=modeldata1, family=binomial)
scope = list(lower=formula(glm0), upper=formula(glm1))
glm2 = step(glm0, scope, direction='forward')
mm0 = glmer(Outcome ~ (1|Participant) + Age, data=modeldata, family=binomial)
mm2 = update(mm0, formula=update(formula(glm2),'. ~ (1|Participant) + .'))

Interestingly, the results are pretty much the same, from:
library(effects)
plot(allEffects(glm2))
plot(allEffects(mm2))

cheers,
    Steve


From bbolker at gmail.com  Mon Jan  7 05:25:36 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 7 Jan 2013 04:25:36 +0000 (UTC)
Subject: [R-sig-ME]
	=?utf-8?q?stepwise_model_selection_=28of_fixed_effects?=
	=?utf-8?q?_only=29_using=09AIC=3F?=
References: <CCE952776B6679469977532BD863C39C356711C8@Lewis.autuni.aut.ac.nz>
Message-ID: <loom.20130107T051809-731@post.gmane.org>

Steve Taylor <steve.taylor at ...> writes:

> 
> Hello mixed modellers,
 
> I note that one can fit mixed models and compare them by AIC using
>  anova(), as in example(glmer).
 
> But step() doesn't work on the models produced by glmer() -
> evidently because they are S4 objects, rather than some more
> philosophical objection to doing so.

It's sort of a combination, I think: on the one hand I wouldn't
stop someone who *really* wanted to from doing stepwise model
selection; (1) it's a free country and (2) there are *occasionally*
good reasons to do so.  On the other hand, I don't feel particularly
inspired to put a lot of effort into implementing this capability,
because it's so rarely a good idea.

> I want to select among combinations of fixed effect components only,
>  as one would do with step(glm()).
 
> My data set consists of two repeated measurements (say, at age 9 and
> age 11) on each of about 900 people. There are about 8 potential
> fixed effect covariates that I wish to evaluate, including
> interaction terms with Age (as a two-level factor).  The only random
> effect I'm assuming is an intercept per participant.

  I *think* that drop1() should work; this will allow you to do
stepwise regression in not more than 8 steps or so.  That is, at
each stage drop1() will tell you which of the remaining terms
in the model will most improve the model.  At worst, you will
have to run drop1(); update(model, . ~ . - worstpredictor) 8
times before you end up at the intercept-only model.  (Hopefully
you will get to stop before then, as none of the dropped-predictor
models will have a lower AIC than the full model.)
 
> Can anyone help with a way to do this?
> 
> Here's my attempt, ignoring the random effect during model selection.  
> Is this a reasonable thing to do?
> 
> modeldata1 = subset(modeldata, select= -Participant)
> glm0 = glm(Outcome ~ Age, data=modeldata1, family=binomial)
> glm1 = glm(Outcome ~ .*Age, data=modeldata1, family=binomial)
> scope = list(lower=formula(glm0), upper=formula(glm1))
> glm2 = step(glm0, scope, direction='forward')

  I generally prefer backward to forward selection ...

> mm0 = glmer(Outcome ~ (1|Participant) + Age, 
>       data=modeldata, family=binomial)
> mm2 = update(mm0, formula=update(formula(glm2),'. ~ (1|Participant) + .'))
> 
> Interestingly, the results are pretty much the same, from:
> library(effects)
> plot(allEffects(glm2))
> plot(allEffects(mm2))


From theoni.photopoulou at gmail.com  Mon Jan  7 12:36:19 2013
From: theoni.photopoulou at gmail.com (Theoni Photopoulou)
Date: Mon, 7 Jan 2013 11:36:19 +0000
Subject: [R-sig-ME] Error using dredge with an MCMCglmm object
Message-ID: <CAOjPYTRtrJ4eUP=+ABbb6aRDiDBWN0wL=-QBPNrzJe0wbJr3aQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130107/0370aa04/attachment.pl>

From diegopujoni at gmail.com  Mon Jan  7 14:04:08 2013
From: diegopujoni at gmail.com (Diego Pujoni)
Date: Mon, 7 Jan 2013 11:04:08 -0200
Subject: [R-sig-ME] stepwise model selection (of fixed effects only)
	using AIC?
Message-ID: <CANmSXjQ9aO_xuFNvrdJ09hwuc9SegbtAfycv4ifXDaynwjh8sA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130107/0538b7a3/attachment.pl>

From f.calboli at imperial.ac.uk  Mon Jan  7 15:31:24 2013
From: f.calboli at imperial.ac.uk (Federico Calboli)
Date: Mon, 7 Jan 2013 14:31:24 +0000
Subject: [R-sig-ME] lme4 and r-forge
Message-ID: <985B103D-F0F5-4B97-B9AC-6F236612AC28@imperial.ac.uk>

Hi All,

I am running lme4 version 0.99999911-0, installed (as a binary) from http://r-forge.r-project.org.  I cannot find binaries or sources of lme4 on R forge anymore -- suggestions on how to keep up to date with the development branch of lme4 (not lme4a or lme4.0)?  Ideally I'd prefer a binary (for OSX), but obviously I'd take what's available.

Best wishes

Federico

--
Federico C. F. Calboli
Neuroepidemiology and Ageing Research
Imperial College, St. Mary's Campus
Norfolk Place, London W2 1PG

Tel +44 (0)20 75941602   Fax +44 (0)20 75943193

f.calboli [.a.t] imperial.ac.uk
f.calboli [.a.t] gmail.com


From nathan.rutenbeck at maine.edu  Mon Jan  7 17:09:21 2013
From: nathan.rutenbeck at maine.edu (Nathan Eustis Rutenbeck)
Date: Mon, 7 Jan 2013 11:09:21 -0500
Subject: [R-sig-ME] Assigning random effects
Message-ID: <CAOho3ae9z44ZBv-bi5Z6FPNWLy-L3Q8BK5g-0CAV+sW+Xo=DkQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130107/4f8a2604/attachment.pl>

From nathan.rutenbeck at maine.edu  Mon Jan  7 18:14:14 2013
From: nathan.rutenbeck at maine.edu (Nathan Eustis Rutenbeck)
Date: Mon, 7 Jan 2013 12:14:14 -0500
Subject: [R-sig-ME] Fwd: Assigning random effects
In-Reply-To: <CAOho3ae9z44ZBv-bi5Z6FPNWLy-L3Q8BK5g-0CAV+sW+Xo=DkQ@mail.gmail.com>
References: <CAOho3ae9z44ZBv-bi5Z6FPNWLy-L3Q8BK5g-0CAV+sW+Xo=DkQ@mail.gmail.com>
Message-ID: <CAOho3adOeqk2hd8pvZht6=DFZ5hAHZH0=mEOV2aavpH8FO8Nsg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130107/66a96729/attachment.pl>

From m.fairbrother at bristol.ac.uk  Mon Jan  7 20:56:20 2013
From: m.fairbrother at bristol.ac.uk (Malcolm Fairbrother)
Date: Mon, 7 Jan 2013 19:56:20 +0000
Subject: [R-sig-ME] ordinal regression with MCMCglmm
In-Reply-To: <mailman.1345.1271262437.4213.r-sig-mixed-models@r-project.org>
References: <mailman.1345.1271262437.4213.r-sig-mixed-models@r-project.org>
Message-ID: <9FF35CC0-60F0-4C35-AE34-58FD35572A0A@bristol.ac.uk>

Dear list,

I'm picking up on a thread from 2010 (https://stat.ethz.ch/pipermail/r-sig-mixed-models/2010q2/003678.html), about ordinal mixed models, fitted with clmm (from the ordinal package) and MCMCglmm.

I would like to fit an ordinal mixed model, with random slopes. Since clmm doesn't do random slopes, I'm trying with MCMCglmm, but I'm not sure I understand how MCMCglmm handles ordinal data.

To illustrate, I'll use the "wine" data from the ordinal package, and a model with only random intercepts.

library(ordinal)
library(MCMCglmm)

data(wine)
str(wine)
summary(fm2 <- clmm2(rating ~ temp + contact, random=judge, data=wine, Hess=TRUE, nAGQ=10))

# to get predicted probabilities for each possible of the five possible responses, for two combinations of covariates:
diff(plogis(c(-Inf,fm2$Theta, Inf) - fm2$beta %*% c(0,0))) # for tempcold and contactno
diff(plogis(c(-Inf,fm2$Theta, Inf) - fm2$beta %*% c(1,1))) # for tempwarm and contactyes

# compare with the raw data (seems to make sense...):
table(wine$rating[wine$temp=="cold" & wine$contact=="no"])
table(wine$rating[wine$temp=="warm" & wine$contact=="yes"])

# now fit the same model, using MCMCglmm:
prior1 <- list(R = list(V = 1, nu = 0.002, fix=1), G = list(G1 = list(V = 1, nu = 0.002)))
MC1 <- MCMCglmm(rating ~ temp + contact, random=~judge, data=wine, family="ordinal", prior=prior1, nitt=130000, thin=100, verbose=F)

# and get predicted probabilities, using the results from MCMCglmm, and the "hunch" approach Jarrod mentioned in the thread above:
diff(pnorm(c(-Inf, 0, colMeans(MC1$CP), Inf)-colMeans(MC1$Sol) %*% c(1,0,0), 0, sqrt(1+sum(colMeans(MC1$VCV))))) # for tempcold and contactno
diff(pnorm(c(-Inf, 0, colMeans(MC1$CP), Inf)-colMeans(MC1$Sol) %*% c(1,1,1), 0, sqrt(1+sum(colMeans(MC1$VCV))))) # for tempwarm and contactyes

The predicted probabilities are similar, but not similar enough that I'm sure this is right. Are the differences due to MCMC error, inappropriate priors, or the way I'm predicting probabilities based on one (or both?) model(s)?

If anyone can offer any clarifications/suggestions, I'd be grateful. (Maybe Thierry figured this out?)

Cheers,
Malcolm



> Date: Wed, 14 Apr 2010 15:41:45 +0100
> From: Jarrod Hadfield <j.hadfield at ed.ac.uk>
> To: "ONKELINX, Thierry" <Thierry.ONKELINX at inbo.be>
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] ordinal regression with MCMCglmm
> Message-ID: <2FE797FF-C1EC-4CA2-8275-C3B0AA9243BE at ed.ac.uk>
> Content-Type: text/plain; charset=US-ASCII; format=flowed; delsp=yes
> 
> Dear Thierry,
> 
> I think (but you had better check) that it would actually be something  
> like
> 
> pnorm(-Xb, 0, sqrt(1+v)),
> pnorm(cp[1] - Xb,0, sqrt(1+v)) - pnorm(Xb,0, sqrt(1+v))
> pnorm(cp[2] - Xb,0, sqrt(1+v)) - pnorm(cp[1] - Xb,0, sqrt(1+v))
> 1- pnorm(cp[2] - Xb,0, sqrt(1+v))
> 
> where v is  the sum of the variance components for the residual and  
> random effects.
> 
> Alternatively, if the residual variance is set to one and there are no  
> random effects
> 
> pnorm(-Xb, 0, sqrt(2)),
> pnorm(cp[1] - Xb,0, sqrt(2)) - pnorm(Xb,0, sqrt(2))
> pnorm(cp[2] - Xb,0, sqrt(2)) - pnorm(cp[1] - Xb,0, sqrt(2))
> 1- pnorm(cp[2] - Xb,0, sqrt(2))
> 
> or if the prediction includes random effects:
> 
> pnorm(-(Xb+Zu), 0, sqrt(2)),
> pnorm(cp[1] - (Xb+Zu),0, sqrt(2)) - pnorm((Xb+Zu),0, sqrt(2))
> pnorm(cp[2] - (Xb+Zu),0, sqrt(2)) - pnorm(cp[1] - (Xb+Zu),0, sqrt(2))
> 1- pnorm(cp[2] - (Xb+Zu),0, sqrt(2))
> 
> Please, do not take this as gospel. I have not got time to check these  
> results, they are a hunch.
> 
> Cheers,
> 
> Jarrod
> 
> 
> On 14 Apr 2010, at 15:25, ONKELINX, Thierry wrote:
> 
>> Dear Jarrod,
>> 
>> I'm working on a similar problem. Does it makes sense to calculate  
>> that
>> for the fixed effects only? Something like this:
>> pnorm(-Xb),
>> pnorm(cp[1] - Xb) - pnorm(Xb)
>> pnorm(cp[2] - Xb) - pnorm(cp[1] - Xb)
>> 1 - pnorm(cp[2] - Xb)
>> 
>> Best regards,
>> 
>> Thierry
>> ------------------------------------------------------------------------
>> ----
>> ir. Thierry Onkelinx
>> Instituut voor natuur- en bosonderzoek
>> team Biometrie & Kwaliteitszorg
>> Gaverstraat 4
>> 9500 Geraardsbergen
>> Belgium
>> 
>> Research Institute for Nature and Forest
>> team Biometrics & Quality Assurance
>> Gaverstraat 4
>> 9500 Geraardsbergen
>> Belgium
>> 
>> tel. + 32 54/436 185
>> Thierry.Onkelinx at inbo.be
>> www.inbo.be
>> 
>> To call in the statistician after the experiment is done may be no  
>> more
>> than asking him to perform a post-mortem examination: he may be able  
>> to
>> say what the experiment died of.
>> ~ Sir Ronald Aylmer Fisher
>> 
>> The plural of anecdote is not data.
>> ~ Roger Brinner
>> 
>> The combination of some data and an aching desire for an answer does  
>> not
>> ensure that a reasonable answer can be extracted from a given body of
>> data.
>> ~ John Tukey
>> 
>> 
>>> -----Oorspronkelijk bericht-----
>>> Van: r-sig-mixed-models-bounces at r-project.org
>>> [mailto:r-sig-mixed-models-bounces at r-project.org] Namens
>>> Jarrod Hadfield
>>> Verzonden: woensdag 14 april 2010 15:35
>>> Aan: Kari Ruohonen
>>> CC: Kari Ruohonen; r-sig-mixed-models at r-project.org
>>> Onderwerp: Re: [R-sig-ME] ordinal regression with MCMCglmm
>>> 
>>> Hi,
>>> 
>>> Imagine a latent variable (l) that conforms to the  standard
>>> linear model.
>>> 
>>> l = Xb+Zu+e
>>> 
>>> The probabilities of falling into each of the four categories are:
>>> 
>>> 
>>> pnorm(-l)
>>> 
>>> pnorm(cp[1]-l)-pnorm(-l)
>>> 
>>> pnorm(cp[2]-l)-pnorm(cp[1]-l)
>>> 
>>> 1-pnorm(cp[2]-l)
>>> 
>>> where cp is the vector of cut-points with 2 elements. A 3
>>> cut-point model would be over-parameterised (unless the
>>> intercept is zero, which I presume is what polr does (?).
>>> 
>>> The factors don't need to be ordered, the order is obtained
>>> from levels(resp).  In the future, I may only allowed ordered
>>> factors to stop any accidents.
>>> 
>>> Cheers,
>>> 
>>> Jarrod
>>> 
>>> 
>>> 
>>> 
>>> 
>>> On 14 Apr 2010, at 08:07, Kari Ruohonen wrote:
>>> 
>>>> Hi and thanks for the answer. I tried exactly that model
>>> syntax before
>>>> posting but the output of the "fixed" part had an unexpected
>>>> parameterisation and I thought I misspecified the model
>>> somehow. The
>>>> parameters I got with the above model are
>>>> - two cutpoints
>>>> - intercept
>>>> - effect of group B
>>>> 
>>>> I would have expected that instead of the intercept and two
>>> cutpoints
>>>> I would have had three cutpoints as given by polr (MASS
>>> package), for
>>>> example. Can you explain me the parameterisation in
>>> MCMCglmm and how
>>>> it connects to the one in polr that uses J-1 ordered cutpoints
>>>> (J=number of score classes) without an intercept?
>>>> 
>>>> Also, I am uncertain do I need to convert the "resp" before
>>> MCMCglmm
>>>> to an ordered factor (with "ordered")?
>>>> 
>>>> Many thanks,
>>>> 
>>>> Kari
>>>> 
>>>> On Tue, 2010-04-13 at 17:41 +0100, Jarrod Hadfield wrote:
>>>>> Hi Kari,
>>>>> 
>>>>> The simplest model is
>>>>> 
>>>>> 
>>>>> m1<-MCMCglmm(resp~treat, random=~group, family="ordinal",
>>>>> data=your.data, prior=prior)
>>>>> 
>>>>> as with multinomial data with a single realisation, the residual
>>>>> variance cannot be estimated from the data. The best
>>> option is to fix
>>>>> it at some value. most programs fix it at zero but
>>> MCMCglmm will fail
>>>>> to mix if this is done, so I usually fix it at 1:
>>>>> 
>>>>> 
>>>>> prior=list(R=list(V=1, fix=1), G=list(G1=list(V=1, nu=0)))
>>>>> 
>>>>> I have left the default prior for the fixed effects (not
>>> explicitly
>>>>> specified above), and the default prior random effect variance
>>>>> structure (G) which has a zero degree of belief parameter.
>>> Often this
>>>>> requires some/more thought, especially if there are few groups or
>>>>> replication within groups is low. Sections 1.2, 1.5 & 8.2 in the
>>>>> CourseNotes cover priors for variances.
>>>>> 
>>>>> 
>>>>> Currently there is no option for specifying priors on the
>>> cut- points
>>>>> - the prior is flat and improper. The posterior in virtually all
>>>>> cases will be proper though.
>>>>> 
>>>>> Cheers,
>>>>> 
>>>>> Jarrod
>>>>> 
>>>>> Quoting Kari Ruohonen <kari.ruohonen at utu.fi>:
>>>>> 
>>>>>> Hi,
>>>>>> I am trying to figure out how to fit an ordinal regression model
>>>>>> with MCMCglmm. The "MCMCglmm Course notes" has a section on
>>>>>> multinomial models but no example of ordinal models.
>>> Suppose I have
>>>>>> the following data
>>>>>> 
>>>>>>> data
>>>>>> resp treat group
>>>>>> 1     4     A    1
>>>>>> 2     4     A    1
>>>>>> 3     3     A    2
>>>>>> 4     4     A    2
>>>>>> 5     2     A    3
>>>>>> 6     4     A    3
>>>>>> 7     2     A    4
>>>>>> 8     2     A    4
>>>>>> 9     3     A    5
>>>>>> 10    2     A    5
>>>>>> 11    1     B    6
>>>>>> 12    1     B    6
>>>>>> 13    1     B    7
>>>>>> 14    2     B    7
>>>>>> 15    2     B    8
>>>>>> 16    3     B    8
>>>>>> 17    2     B    9
>>>>>> 18    1     B    9
>>>>>> 19    2     B   10
>>>>>> 20    2     B   10
>>>>>> 
>>>>>> and the "resp" is an ordinal response, "treat" is a treatment and
>>>>>> "group" is membership to a group. Assume I would like to fit an
>>>>>> ordinal model between "resp" and "treat" by having
>>> "group" effects
>>>>>> as random effects. How would I specify such a model in
>>> MCMCglmm? And
>>>>>> how would I specify the prior distributions?
>>>>>> 
>>>>>> All help is greatly appreciated.
>>>>>> 
>>>>>> regards, Kari


From steve.taylor at aut.ac.nz  Mon Jan  7 21:46:38 2013
From: steve.taylor at aut.ac.nz (Steve Taylor)
Date: Mon, 7 Jan 2013 20:46:38 +0000
Subject: [R-sig-ME] stepwise model selection (of fixed effects only)
 using	AIC?
In-Reply-To: <loom.20130107T051809-731@post.gmane.org>
References: <CCE952776B6679469977532BD863C39C356711C8@Lewis.autuni.aut.ac.nz>
	<loom.20130107T051809-731@post.gmane.org>
Message-ID: <CCE952776B6679469977532BD863C39C3567168A@Lewis.autuni.aut.ac.nz>

Thanks Ben.  

No, drop1 doesn't work:
Error: $ operator not defined for this S4 class

OK, I'll use the backward direction in preference.  

The fixed effect covariates were all selected because there is some evidence in the literature that they may be associated or confounding.  So, I could declare, a priori, that my hypothesised model includes all my hypothesised covariates and their Age interaction terms.  

Would it then be acceptable to the detractors for me to start from that model and simplify it via backwards stepwise model selection to settle on a simpler model?

S

-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Ben Bolker
Sent: Monday, 7 January 2013 5:26p
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] stepwise model selection (of fixed effects only) using AIC?

Steve Taylor <steve.taylor at ...> writes:

> 
> Hello mixed modellers,
 
> I note that one can fit mixed models and compare them by AIC using
>  anova(), as in example(glmer).
 
> But step() doesn't work on the models produced by glmer() -
> evidently because they are S4 objects, rather than some more
> philosophical objection to doing so.

It's sort of a combination, I think: on the one hand I wouldn't
stop someone who *really* wanted to from doing stepwise model
selection; (1) it's a free country and (2) there are *occasionally*
good reasons to do so.  On the other hand, I don't feel particularly
inspired to put a lot of effort into implementing this capability,
because it's so rarely a good idea.

> I want to select among combinations of fixed effect components only,
>  as one would do with step(glm()).
 
> My data set consists of two repeated measurements (say, at age 9 and
> age 11) on each of about 900 people. There are about 8 potential
> fixed effect covariates that I wish to evaluate, including
> interaction terms with Age (as a two-level factor).  The only random
> effect I'm assuming is an intercept per participant.

  I *think* that drop1() should work; this will allow you to do
stepwise regression in not more than 8 steps or so.  That is, at
each stage drop1() will tell you which of the remaining terms
in the model will most improve the model.  At worst, you will
have to run drop1(); update(model, . ~ . - worstpredictor) 8
times before you end up at the intercept-only model.  (Hopefully
you will get to stop before then, as none of the dropped-predictor
models will have a lower AIC than the full model.)
 
> Can anyone help with a way to do this?
> 
> Here's my attempt, ignoring the random effect during model selection.  
> Is this a reasonable thing to do?
> 
> modeldata1 = subset(modeldata, select= -Participant)
> glm0 = glm(Outcome ~ Age, data=modeldata1, family=binomial)
> glm1 = glm(Outcome ~ .*Age, data=modeldata1, family=binomial)
> scope = list(lower=formula(glm0), upper=formula(glm1))
> glm2 = step(glm0, scope, direction='forward')

  I generally prefer backward to forward selection ...

> mm0 = glmer(Outcome ~ (1|Participant) + Age, 
>       data=modeldata, family=binomial)
> mm2 = update(mm0, formula=update(formula(glm2),'. ~ (1|Participant) + .'))
> 
> Interestingly, the results are pretty much the same, from:
> library(effects)
> plot(allEffects(glm2))
> plot(allEffects(mm2))

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From steve.taylor at aut.ac.nz  Mon Jan  7 21:49:42 2013
From: steve.taylor at aut.ac.nz (Steve Taylor)
Date: Mon, 7 Jan 2013 20:49:42 +0000
Subject: [R-sig-ME] stepwise model selection (of fixed effects
	only)	using AIC?
In-Reply-To: <CANmSXjQ9aO_xuFNvrdJ09hwuc9SegbtAfycv4ifXDaynwjh8sA@mail.gmail.com>
References: <CANmSXjQ9aO_xuFNvrdJ09hwuc9SegbtAfycv4ifXDaynwjh8sA@mail.gmail.com>
Message-ID: <CCE952776B6679469977532BD863C39C3567169B@Lewis.autuni.aut.ac.nz>

Obrigado, Diego.  Yes I have studied a little bit of information theory, tho my recollections are hazy.

> you can not compare combinations of fixed effects of class "mer" with REML = TRUE.
Curious then, that that's the default value, and that the default anova() does precisely that by comparing two models differing only in the fixed effects included.

I'm aware of the objections, such as the danger of spurious relations.  But I cannot see why they prevent step(glmer()) when step(glm()) has been a standard feature in R for many years.  The real reason seems to be the fact that methods in package:stats don't work with S4 objects.

With my sample size, I think the difference between AIC and AICc is negligible.

cheers,
    Steve

-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Diego Pujoni
Sent: Tuesday, 8 January 2013 2:04a
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] stepwise model selection (of fixed effects only) using AIC?

Hi Steve, have you heard about Information-Theoretic Approach? It uses the
value of AIC (or AICc) to choose the best hypothesis among many a priori
hypothesis. In Anderson (2008) "Model Based Inference in the Life Sciences"
we see recomendations against stepwise (or all possible models) because
this can lead easily to spurious relations. The author recommend to create
several a priori hypothesis (models), using knowledge about the system and
then use the AICc to look for the best of them. Another thing that you have
to pay attention is the fact that you can not compare combinations of fixed
effects of class "mer" with REML = TRUE.

A hug

-- 
                                               Diego PJ

	[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From j.hadfield at ed.ac.uk  Mon Jan  7 22:07:35 2013
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Mon, 07 Jan 2013 21:07:35 +0000
Subject: [R-sig-ME] ordinal regression with MCMCglmm
In-Reply-To: <9FF35CC0-60F0-4C35-AE34-58FD35572A0A@bristol.ac.uk>
References: <mailman.1345.1271262437.4213.r-sig-mixed-models@r-project.org>
	<9FF35CC0-60F0-4C35-AE34-58FD35572A0A@bristol.ac.uk>
Message-ID: <20130107210735.559320w69jt6651c@www.staffmail.ed.ac.uk>

Hi Malcolm,

Your way of obtaining the predicted probability of falling into a  
class from the MCMCglmm output is correct.  The method you use for the  
clmm output is not the expected value over random effects (as you've  
calculated for the MCMCglmm model), but the expected value for a  
random effect of zero.  If you use probit link in clmm, and  
marginalise the random effects you will find the clmm and MCMCglmm  
estimates to be identical:

summary(fm2 <- clmm2(rating ~ temp + contact, random=judge, data=wine,  
Hess=TRUE, nAGQ=10, link="probit"))

diff(pnorm(c(-Inf,fm2$Theta, Inf) - fm2$beta %*% c(0,0), 0,  
sqrt(1+fm2$stDev)))
diff(pnorm(c(-Inf,fm2$Theta, Inf) - fm2$beta %*% c(1,1), 0,  
sqrt(1+fm2$stDev))) # for tempwarm and contactyes

Cheers,

Jarrod






Quoting Malcolm Fairbrother <m.fairbrother at bristol.ac.uk> on Mon, 7  
Jan 2013 19:56:20 +0000:

> Dear list,
>
> I'm picking up on a thread from 2010  
> (https://stat.ethz.ch/pipermail/r-sig-mixed-models/2010q2/003678.html),  
> about ordinal mixed models, fitted with clmm (from the ordinal  
> package) and MCMCglmm.
>
> I would like to fit an ordinal mixed model, with random slopes.  
> Since clmm doesn't do random slopes, I'm trying with MCMCglmm, but  
> I'm not sure I understand how MCMCglmm handles ordinal data.
>
> To illustrate, I'll use the "wine" data from the ordinal package,  
> and a model with only random intercepts.
>
> library(ordinal)
> library(MCMCglmm)
>
> data(wine)
> str(wine)
> summary(fm2 <- clmm2(rating ~ temp + contact, random=judge,  
> data=wine, Hess=TRUE, nAGQ=10))
>
> # to get predicted probabilities for each possible of the five  
> possible responses, for two combinations of covariates:
> diff(plogis(c(-Inf,fm2$Theta, Inf) - fm2$beta %*% c(0,0))) # for  
> tempcold and contactno
> diff(plogis(c(-Inf,fm2$Theta, Inf) - fm2$beta %*% c(1,1))) # for  
> tempwarm and contactyes
>
> # compare with the raw data (seems to make sense...):
> table(wine$rating[wine$temp=="cold" & wine$contact=="no"])
> table(wine$rating[wine$temp=="warm" & wine$contact=="yes"])
>
> # now fit the same model, using MCMCglmm:
> prior1 <- list(R = list(V = 1, nu = 0.002, fix=1), G = list(G1 =  
> list(V = 1, nu = 0.002)))
> MC1 <- MCMCglmm(rating ~ temp + contact, random=~judge, data=wine,  
> family="ordinal", prior=prior1, nitt=130000, thin=100, verbose=F)
>
> # and get predicted probabilities, using the results from MCMCglmm,  
> and the "hunch" approach Jarrod mentioned in the thread above:
> diff(pnorm(c(-Inf, 0, colMeans(MC1$CP), Inf)-colMeans(MC1$Sol) %*%  
> c(1,0,0), 0, sqrt(1+sum(colMeans(MC1$VCV))))) # for tempcold and  
> contactno
> diff(pnorm(c(-Inf, 0, colMeans(MC1$CP), Inf)-colMeans(MC1$Sol) %*%  
> c(1,1,1), 0, sqrt(1+sum(colMeans(MC1$VCV))))) # for tempwarm and  
> contactyes
>
> The predicted probabilities are similar, but not similar enough that  
> I'm sure this is right. Are the differences due to MCMC error,  
> inappropriate priors, or the way I'm predicting probabilities based  
> on one (or both?) model(s)?
>
> If anyone can offer any clarifications/suggestions, I'd be grateful.  
> (Maybe Thierry figured this out?)
>
> Cheers,
> Malcolm
>
>
>
>> Date: Wed, 14 Apr 2010 15:41:45 +0100
>> From: Jarrod Hadfield <j.hadfield at ed.ac.uk>
>> To: "ONKELINX, Thierry" <Thierry.ONKELINX at inbo.be>
>> Cc: r-sig-mixed-models at r-project.org
>> Subject: Re: [R-sig-ME] ordinal regression with MCMCglmm
>> Message-ID: <2FE797FF-C1EC-4CA2-8275-C3B0AA9243BE at ed.ac.uk>
>> Content-Type: text/plain; charset=US-ASCII; format=flowed; delsp=yes
>>
>> Dear Thierry,
>>
>> I think (but you had better check) that it would actually be something
>> like
>>
>> pnorm(-Xb, 0, sqrt(1+v)),
>> pnorm(cp[1] - Xb,0, sqrt(1+v)) - pnorm(Xb,0, sqrt(1+v))
>> pnorm(cp[2] - Xb,0, sqrt(1+v)) - pnorm(cp[1] - Xb,0, sqrt(1+v))
>> 1- pnorm(cp[2] - Xb,0, sqrt(1+v))
>>
>> where v is  the sum of the variance components for the residual and
>> random effects.
>>
>> Alternatively, if the residual variance is set to one and there are no
>> random effects
>>
>> pnorm(-Xb, 0, sqrt(2)),
>> pnorm(cp[1] - Xb,0, sqrt(2)) - pnorm(Xb,0, sqrt(2))
>> pnorm(cp[2] - Xb,0, sqrt(2)) - pnorm(cp[1] - Xb,0, sqrt(2))
>> 1- pnorm(cp[2] - Xb,0, sqrt(2))
>>
>> or if the prediction includes random effects:
>>
>> pnorm(-(Xb+Zu), 0, sqrt(2)),
>> pnorm(cp[1] - (Xb+Zu),0, sqrt(2)) - pnorm((Xb+Zu),0, sqrt(2))
>> pnorm(cp[2] - (Xb+Zu),0, sqrt(2)) - pnorm(cp[1] - (Xb+Zu),0, sqrt(2))
>> 1- pnorm(cp[2] - (Xb+Zu),0, sqrt(2))
>>
>> Please, do not take this as gospel. I have not got time to check these
>> results, they are a hunch.
>>
>> Cheers,
>>
>> Jarrod
>>
>>
>> On 14 Apr 2010, at 15:25, ONKELINX, Thierry wrote:
>>
>>> Dear Jarrod,
>>>
>>> I'm working on a similar problem. Does it makes sense to calculate
>>> that
>>> for the fixed effects only? Something like this:
>>> pnorm(-Xb),
>>> pnorm(cp[1] - Xb) - pnorm(Xb)
>>> pnorm(cp[2] - Xb) - pnorm(cp[1] - Xb)
>>> 1 - pnorm(cp[2] - Xb)
>>>
>>> Best regards,
>>>
>>> Thierry
>>> ------------------------------------------------------------------------
>>> ----
>>> ir. Thierry Onkelinx
>>> Instituut voor natuur- en bosonderzoek
>>> team Biometrie & Kwaliteitszorg
>>> Gaverstraat 4
>>> 9500 Geraardsbergen
>>> Belgium
>>>
>>> Research Institute for Nature and Forest
>>> team Biometrics & Quality Assurance
>>> Gaverstraat 4
>>> 9500 Geraardsbergen
>>> Belgium
>>>
>>> tel. + 32 54/436 185
>>> Thierry.Onkelinx at inbo.be
>>> www.inbo.be
>>>
>>> To call in the statistician after the experiment is done may be no
>>> more
>>> than asking him to perform a post-mortem examination: he may be able
>>> to
>>> say what the experiment died of.
>>> ~ Sir Ronald Aylmer Fisher
>>>
>>> The plural of anecdote is not data.
>>> ~ Roger Brinner
>>>
>>> The combination of some data and an aching desire for an answer does
>>> not
>>> ensure that a reasonable answer can be extracted from a given body of
>>> data.
>>> ~ John Tukey
>>>
>>>
>>>> -----Oorspronkelijk bericht-----
>>>> Van: r-sig-mixed-models-bounces at r-project.org
>>>> [mailto:r-sig-mixed-models-bounces at r-project.org] Namens
>>>> Jarrod Hadfield
>>>> Verzonden: woensdag 14 april 2010 15:35
>>>> Aan: Kari Ruohonen
>>>> CC: Kari Ruohonen; r-sig-mixed-models at r-project.org
>>>> Onderwerp: Re: [R-sig-ME] ordinal regression with MCMCglmm
>>>>
>>>> Hi,
>>>>
>>>> Imagine a latent variable (l) that conforms to the  standard
>>>> linear model.
>>>>
>>>> l = Xb+Zu+e
>>>>
>>>> The probabilities of falling into each of the four categories are:
>>>>
>>>>
>>>> pnorm(-l)
>>>>
>>>> pnorm(cp[1]-l)-pnorm(-l)
>>>>
>>>> pnorm(cp[2]-l)-pnorm(cp[1]-l)
>>>>
>>>> 1-pnorm(cp[2]-l)
>>>>
>>>> where cp is the vector of cut-points with 2 elements. A 3
>>>> cut-point model would be over-parameterised (unless the
>>>> intercept is zero, which I presume is what polr does (?).
>>>>
>>>> The factors don't need to be ordered, the order is obtained
>>>> from levels(resp).  In the future, I may only allowed ordered
>>>> factors to stop any accidents.
>>>>
>>>> Cheers,
>>>>
>>>> Jarrod
>>>>
>>>>
>>>>
>>>>
>>>>
>>>> On 14 Apr 2010, at 08:07, Kari Ruohonen wrote:
>>>>
>>>>> Hi and thanks for the answer. I tried exactly that model
>>>> syntax before
>>>>> posting but the output of the "fixed" part had an unexpected
>>>>> parameterisation and I thought I misspecified the model
>>>> somehow. The
>>>>> parameters I got with the above model are
>>>>> - two cutpoints
>>>>> - intercept
>>>>> - effect of group B
>>>>>
>>>>> I would have expected that instead of the intercept and two
>>>> cutpoints
>>>>> I would have had three cutpoints as given by polr (MASS
>>>> package), for
>>>>> example. Can you explain me the parameterisation in
>>>> MCMCglmm and how
>>>>> it connects to the one in polr that uses J-1 ordered cutpoints
>>>>> (J=number of score classes) without an intercept?
>>>>>
>>>>> Also, I am uncertain do I need to convert the "resp" before
>>>> MCMCglmm
>>>>> to an ordered factor (with "ordered")?
>>>>>
>>>>> Many thanks,
>>>>>
>>>>> Kari
>>>>>
>>>>> On Tue, 2010-04-13 at 17:41 +0100, Jarrod Hadfield wrote:
>>>>>> Hi Kari,
>>>>>>
>>>>>> The simplest model is
>>>>>>
>>>>>>
>>>>>> m1<-MCMCglmm(resp~treat, random=~group, family="ordinal",
>>>>>> data=your.data, prior=prior)
>>>>>>
>>>>>> as with multinomial data with a single realisation, the residual
>>>>>> variance cannot be estimated from the data. The best
>>>> option is to fix
>>>>>> it at some value. most programs fix it at zero but
>>>> MCMCglmm will fail
>>>>>> to mix if this is done, so I usually fix it at 1:
>>>>>>
>>>>>>
>>>>>> prior=list(R=list(V=1, fix=1), G=list(G1=list(V=1, nu=0)))
>>>>>>
>>>>>> I have left the default prior for the fixed effects (not
>>>> explicitly
>>>>>> specified above), and the default prior random effect variance
>>>>>> structure (G) which has a zero degree of belief parameter.
>>>> Often this
>>>>>> requires some/more thought, especially if there are few groups or
>>>>>> replication within groups is low. Sections 1.2, 1.5 & 8.2 in the
>>>>>> CourseNotes cover priors for variances.
>>>>>>
>>>>>>
>>>>>> Currently there is no option for specifying priors on the
>>>> cut- points
>>>>>> - the prior is flat and improper. The posterior in virtually all
>>>>>> cases will be proper though.
>>>>>>
>>>>>> Cheers,
>>>>>>
>>>>>> Jarrod
>>>>>>
>>>>>> Quoting Kari Ruohonen <kari.ruohonen at utu.fi>:
>>>>>>
>>>>>>> Hi,
>>>>>>> I am trying to figure out how to fit an ordinal regression model
>>>>>>> with MCMCglmm. The "MCMCglmm Course notes" has a section on
>>>>>>> multinomial models but no example of ordinal models.
>>>> Suppose I have
>>>>>>> the following data
>>>>>>>
>>>>>>>> data
>>>>>>> resp treat group
>>>>>>> 1     4     A    1
>>>>>>> 2     4     A    1
>>>>>>> 3     3     A    2
>>>>>>> 4     4     A    2
>>>>>>> 5     2     A    3
>>>>>>> 6     4     A    3
>>>>>>> 7     2     A    4
>>>>>>> 8     2     A    4
>>>>>>> 9     3     A    5
>>>>>>> 10    2     A    5
>>>>>>> 11    1     B    6
>>>>>>> 12    1     B    6
>>>>>>> 13    1     B    7
>>>>>>> 14    2     B    7
>>>>>>> 15    2     B    8
>>>>>>> 16    3     B    8
>>>>>>> 17    2     B    9
>>>>>>> 18    1     B    9
>>>>>>> 19    2     B   10
>>>>>>> 20    2     B   10
>>>>>>>
>>>>>>> and the "resp" is an ordinal response, "treat" is a treatment and
>>>>>>> "group" is membership to a group. Assume I would like to fit an
>>>>>>> ordinal model between "resp" and "treat" by having
>>>> "group" effects
>>>>>>> as random effects. How would I specify such a model in
>>>> MCMCglmm? And
>>>>>>> how would I specify the prior distributions?
>>>>>>>
>>>>>>> All help is greatly appreciated.
>>>>>>>
>>>>>>> regards, Kari
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From diegopujoni at gmail.com  Mon Jan  7 22:31:30 2013
From: diegopujoni at gmail.com (Diego Pujoni)
Date: Mon, 7 Jan 2013 19:31:30 -0200
Subject: [R-sig-ME] stepwise model selection (of fixed effects only)
	using AIC?
In-Reply-To: <CCE952776B6679469977532BD863C39C3567169B@Lewis.autuni.aut.ac.nz>
References: <CANmSXjQ9aO_xuFNvrdJ09hwuc9SegbtAfycv4ifXDaynwjh8sA@mail.gmail.com>
	<CCE952776B6679469977532BD863C39C3567169B@Lewis.autuni.aut.ac.nz>
Message-ID: <CANmSXjQEiz-yzm5dR644gdM-9g=Cb7-cXu8t3vndhBHQccjToQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130107/18fd26f1/attachment.pl>

From tom_philippi at nps.gov  Mon Jan  7 22:46:03 2013
From: tom_philippi at nps.gov (Philippi, Tom)
Date: Mon, 7 Jan 2013 13:46:03 -0800
Subject: [R-sig-ME] stepwise model selection (of fixed effects only)
	using AIC?
In-Reply-To: <CCE952776B6679469977532BD863C39C3567169B@Lewis.autuni.aut.ac.nz>
References: <CANmSXjQ9aO_xuFNvrdJ09hwuc9SegbtAfycv4ifXDaynwjh8sA@mail.gmail.com>
	<CCE952776B6679469977532BD863C39C3567169B@Lewis.autuni.aut.ac.nz>
Message-ID: <CAM9kYqj3AGwmdVHZOwYgh-3mQUQMYgb8FoopEX-BMwB4qAc3WA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130107/2fd5ab8e/attachment.pl>

From steve.taylor at aut.ac.nz  Mon Jan  7 22:56:09 2013
From: steve.taylor at aut.ac.nz (Steve Taylor)
Date: Mon, 7 Jan 2013 21:56:09 +0000
Subject: [R-sig-ME] stepwise model selection (of fixed effects only)
 using AIC?
In-Reply-To: <CANmSXjQEiz-yzm5dR644gdM-9g=Cb7-cXu8t3vndhBHQccjToQ@mail.gmail.com>
References: <CANmSXjQ9aO_xuFNvrdJ09hwuc9SegbtAfycv4ifXDaynwjh8sA@mail.gmail.com>
	<CCE952776B6679469977532BD863C39C3567169B@Lewis.autuni.aut.ac.nz>
	<CANmSXjQEiz-yzm5dR644gdM-9g=Cb7-cXu8t3vndhBHQccjToQ@mail.gmail.com>
Message-ID: <CCE952776B6679469977532BD863C39C3567170C@Lewis.autuni.aut.ac.nz>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130107/ecdf9dba/attachment.pl>

From m.fairbrother at bristol.ac.uk  Tue Jan  8 01:35:24 2013
From: m.fairbrother at bristol.ac.uk (Malcolm Fairbrother)
Date: Tue, 8 Jan 2013 00:35:24 +0000
Subject: [R-sig-ME] ordinal regression with MCMCglmm
In-Reply-To: <20130107210735.559320w69jt6651c@www.staffmail.ed.ac.uk>
References: <mailman.1345.1271262437.4213.r-sig-mixed-models@r-project.org>
	<9FF35CC0-60F0-4C35-AE34-58FD35572A0A@bristol.ac.uk>
	<20130107210735.559320w69jt6651c@www.staffmail.ed.ac.uk>
Message-ID: <C06A341C-5938-4075-9E88-3CAB63E7884D@bristol.ac.uk>

Dear Jarrod,

Thanks a lot for this -- very helpful.

OK, so since I DO want to marginalise the random effects (I'm interested in predicted probabilities for a hypothetical/typical judge rather than an actually observed one), I think the code I want is:

diff(pnorm(c(-Inf, 0, colMeans(MC1$CP), Inf)-colMeans(MC1$Sol) %*% c(1,0,0), 0, sqrt(1+1))) # MCMCglmm
diff(pnorm(c(-Inf,fm2$Theta, Inf) - fm2$beta %*% c(0,0), 0, 1)) # clmm

And these two approaches do indeed yield very consistent results. I guess I need to set slightly different SDs for pnorm because clmm assumes the residual variance is 0, whereas with MCMCglmm (and given the prior I used, as recommended in the CourseNotes) it's set to 1?

Much appreciated,
Malcolm



On 7 Jan 2013, at 21:07, Jarrod Hadfield wrote:

> Hi Malcolm,
> 
> Your way of obtaining the predicted probability of falling into a class from the MCMCglmm output is correct.  The method you use for the clmm output is not the expected value over random effects (as you've calculated for the MCMCglmm model), but the expected value for a random effect of zero.  If you use probit link in clmm, and marginalise the random effects you will find the clmm and MCMCglmm estimates to be identical:
> 
> summary(fm2 <- clmm2(rating ~ temp + contact, random=judge, data=wine, Hess=TRUE, nAGQ=10, link="probit"))
> 
> diff(pnorm(c(-Inf,fm2$Theta, Inf) - fm2$beta %*% c(0,0), 0, sqrt(1+fm2$stDev)))
> diff(pnorm(c(-Inf,fm2$Theta, Inf) - fm2$beta %*% c(1,1), 0, sqrt(1+fm2$stDev))) # for tempwarm and contactyes
> 
> Cheers,
> 
> Jarrod
> 
> 
> 
> 
> 
> 
> Quoting Malcolm Fairbrother <m.fairbrother at bristol.ac.uk> on Mon, 7 Jan 2013 19:56:20 +0000:
> 
>> Dear list,
>> 
>> I'm picking up on a thread from 2010 (https://stat.ethz.ch/pipermail/r-sig-mixed-models/2010q2/003678.html), about ordinal mixed models, fitted with clmm (from the ordinal package) and MCMCglmm.
>> 
>> I would like to fit an ordinal mixed model, with random slopes. Since clmm doesn't do random slopes, I'm trying with MCMCglmm, but I'm not sure I understand how MCMCglmm handles ordinal data.
>> 
>> To illustrate, I'll use the "wine" data from the ordinal package, and a model with only random intercepts.
>> 
>> library(ordinal)
>> library(MCMCglmm)
>> 
>> data(wine)
>> str(wine)
>> summary(fm2 <- clmm2(rating ~ temp + contact, random=judge, data=wine, Hess=TRUE, nAGQ=10))
>> 
>> # to get predicted probabilities for each possible of the five possible responses, for two combinations of covariates:
>> diff(plogis(c(-Inf,fm2$Theta, Inf) - fm2$beta %*% c(0,0))) # for tempcold and contactno
>> diff(plogis(c(-Inf,fm2$Theta, Inf) - fm2$beta %*% c(1,1))) # for tempwarm and contactyes
>> 
>> # compare with the raw data (seems to make sense...):
>> table(wine$rating[wine$temp=="cold" & wine$contact=="no"])
>> table(wine$rating[wine$temp=="warm" & wine$contact=="yes"])
>> 
>> # now fit the same model, using MCMCglmm:
>> prior1 <- list(R = list(V = 1, nu = 0.002, fix=1), G = list(G1 = list(V = 1, nu = 0.002)))
>> MC1 <- MCMCglmm(rating ~ temp + contact, random=~judge, data=wine, family="ordinal", prior=prior1, nitt=130000, thin=100, verbose=F)
>> 
>> # and get predicted probabilities, using the results from MCMCglmm, and the "hunch" approach Jarrod mentioned in the thread above:
>> diff(pnorm(c(-Inf, 0, colMeans(MC1$CP), Inf)-colMeans(MC1$Sol) %*% c(1,0,0), 0, sqrt(1+sum(colMeans(MC1$VCV))))) # for tempcold and contactno
>> diff(pnorm(c(-Inf, 0, colMeans(MC1$CP), Inf)-colMeans(MC1$Sol) %*% c(1,1,1), 0, sqrt(1+sum(colMeans(MC1$VCV))))) # for tempwarm and contactyes
>> 
>> The predicted probabilities are similar, but not similar enough that I'm sure this is right. Are the differences due to MCMC error, inappropriate priors, or the way I'm predicting probabilities based on one (or both?) model(s)?
>> 
>> If anyone can offer any clarifications/suggestions, I'd be grateful. (Maybe Thierry figured this out?)
>> 
>> Cheers,
>> Malcolm
>> 
>> 
>> 
>>> Date: Wed, 14 Apr 2010 15:41:45 +0100
>>> From: Jarrod Hadfield <j.hadfield at ed.ac.uk>
>>> To: "ONKELINX, Thierry" <Thierry.ONKELINX at inbo.be>
>>> Cc: r-sig-mixed-models at r-project.org
>>> Subject: Re: [R-sig-ME] ordinal regression with MCMCglmm
>>> Message-ID: <2FE797FF-C1EC-4CA2-8275-C3B0AA9243BE at ed.ac.uk>
>>> Content-Type: text/plain; charset=US-ASCII; format=flowed; delsp=yes
>>> 
>>> Dear Thierry,
>>> 
>>> I think (but you had better check) that it would actually be something
>>> like
>>> 
>>> pnorm(-Xb, 0, sqrt(1+v)),
>>> pnorm(cp[1] - Xb,0, sqrt(1+v)) - pnorm(Xb,0, sqrt(1+v))
>>> pnorm(cp[2] - Xb,0, sqrt(1+v)) - pnorm(cp[1] - Xb,0, sqrt(1+v))
>>> 1- pnorm(cp[2] - Xb,0, sqrt(1+v))
>>> 
>>> where v is  the sum of the variance components for the residual and
>>> random effects.
>>> 
>>> Alternatively, if the residual variance is set to one and there are no
>>> random effects
>>> 
>>> pnorm(-Xb, 0, sqrt(2)),
>>> pnorm(cp[1] - Xb,0, sqrt(2)) - pnorm(Xb,0, sqrt(2))
>>> pnorm(cp[2] - Xb,0, sqrt(2)) - pnorm(cp[1] - Xb,0, sqrt(2))
>>> 1- pnorm(cp[2] - Xb,0, sqrt(2))
>>> 
>>> or if the prediction includes random effects:
>>> 
>>> pnorm(-(Xb+Zu), 0, sqrt(2)),
>>> pnorm(cp[1] - (Xb+Zu),0, sqrt(2)) - pnorm((Xb+Zu),0, sqrt(2))
>>> pnorm(cp[2] - (Xb+Zu),0, sqrt(2)) - pnorm(cp[1] - (Xb+Zu),0, sqrt(2))
>>> 1- pnorm(cp[2] - (Xb+Zu),0, sqrt(2))
>>> 
>>> Please, do not take this as gospel. I have not got time to check these
>>> results, they are a hunch.
>>> 
>>> Cheers,
>>> 
>>> Jarrod
>>> 
>>> 
>>> On 14 Apr 2010, at 15:25, ONKELINX, Thierry wrote:
>>> 
>>>> Dear Jarrod,
>>>> 
>>>> I'm working on a similar problem. Does it makes sense to calculate
>>>> that
>>>> for the fixed effects only? Something like this:
>>>> pnorm(-Xb),
>>>> pnorm(cp[1] - Xb) - pnorm(Xb)
>>>> pnorm(cp[2] - Xb) - pnorm(cp[1] - Xb)
>>>> 1 - pnorm(cp[2] - Xb)
>>>> 
>>>> Best regards,
>>>> 
>>>> Thierry
>>>> ------------------------------------------------------------------------
>>>> ----
>>>> ir. Thierry Onkelinx
>>>> Instituut voor natuur- en bosonderzoek
>>>> team Biometrie & Kwaliteitszorg
>>>> Gaverstraat 4
>>>> 9500 Geraardsbergen
>>>> Belgium
>>>> 
>>>> Research Institute for Nature and Forest
>>>> team Biometrics & Quality Assurance
>>>> Gaverstraat 4
>>>> 9500 Geraardsbergen
>>>> Belgium
>>>> 
>>>> tel. + 32 54/436 185
>>>> Thierry.Onkelinx at inbo.be
>>>> www.inbo.be
>>>> 
>>>> To call in the statistician after the experiment is done may be no
>>>> more
>>>> than asking him to perform a post-mortem examination: he may be able
>>>> to
>>>> say what the experiment died of.
>>>> ~ Sir Ronald Aylmer Fisher
>>>> 
>>>> The plural of anecdote is not data.
>>>> ~ Roger Brinner
>>>> 
>>>> The combination of some data and an aching desire for an answer does
>>>> not
>>>> ensure that a reasonable answer can be extracted from a given body of
>>>> data.
>>>> ~ John Tukey
>>>> 
>>>> 
>>>>> -----Oorspronkelijk bericht-----
>>>>> Van: r-sig-mixed-models-bounces at r-project.org
>>>>> [mailto:r-sig-mixed-models-bounces at r-project.org] Namens
>>>>> Jarrod Hadfield
>>>>> Verzonden: woensdag 14 april 2010 15:35
>>>>> Aan: Kari Ruohonen
>>>>> CC: Kari Ruohonen; r-sig-mixed-models at r-project.org
>>>>> Onderwerp: Re: [R-sig-ME] ordinal regression with MCMCglmm
>>>>> 
>>>>> Hi,
>>>>> 
>>>>> Imagine a latent variable (l) that conforms to the  standard
>>>>> linear model.
>>>>> 
>>>>> l = Xb+Zu+e
>>>>> 
>>>>> The probabilities of falling into each of the four categories are:
>>>>> 
>>>>> 
>>>>> pnorm(-l)
>>>>> 
>>>>> pnorm(cp[1]-l)-pnorm(-l)
>>>>> 
>>>>> pnorm(cp[2]-l)-pnorm(cp[1]-l)
>>>>> 
>>>>> 1-pnorm(cp[2]-l)
>>>>> 
>>>>> where cp is the vector of cut-points with 2 elements. A 3
>>>>> cut-point model would be over-parameterised (unless the
>>>>> intercept is zero, which I presume is what polr does (?).
>>>>> 
>>>>> The factors don't need to be ordered, the order is obtained
>>>>> from levels(resp).  In the future, I may only allowed ordered
>>>>> factors to stop any accidents.
>>>>> 
>>>>> Cheers,
>>>>> 
>>>>> Jarrod
>>>>> 
>>>>> 
>>>>> 
>>>>> 
>>>>> 
>>>>> On 14 Apr 2010, at 08:07, Kari Ruohonen wrote:
>>>>> 
>>>>>> Hi and thanks for the answer. I tried exactly that model
>>>>> syntax before
>>>>>> posting but the output of the "fixed" part had an unexpected
>>>>>> parameterisation and I thought I misspecified the model
>>>>> somehow. The
>>>>>> parameters I got with the above model are
>>>>>> - two cutpoints
>>>>>> - intercept
>>>>>> - effect of group B
>>>>>> 
>>>>>> I would have expected that instead of the intercept and two
>>>>> cutpoints
>>>>>> I would have had three cutpoints as given by polr (MASS
>>>>> package), for
>>>>>> example. Can you explain me the parameterisation in
>>>>> MCMCglmm and how
>>>>>> it connects to the one in polr that uses J-1 ordered cutpoints
>>>>>> (J=number of score classes) without an intercept?
>>>>>> 
>>>>>> Also, I am uncertain do I need to convert the "resp" before
>>>>> MCMCglmm
>>>>>> to an ordered factor (with "ordered")?
>>>>>> 
>>>>>> Many thanks,
>>>>>> 
>>>>>> Kari
>>>>>> 
>>>>>> On Tue, 2010-04-13 at 17:41 +0100, Jarrod Hadfield wrote:
>>>>>>> Hi Kari,
>>>>>>> 
>>>>>>> The simplest model is
>>>>>>> 
>>>>>>> 
>>>>>>> m1<-MCMCglmm(resp~treat, random=~group, family="ordinal",
>>>>>>> data=your.data, prior=prior)
>>>>>>> 
>>>>>>> as with multinomial data with a single realisation, the residual
>>>>>>> variance cannot be estimated from the data. The best
>>>>> option is to fix
>>>>>>> it at some value. most programs fix it at zero but
>>>>> MCMCglmm will fail
>>>>>>> to mix if this is done, so I usually fix it at 1:
>>>>>>> 
>>>>>>> 
>>>>>>> prior=list(R=list(V=1, fix=1), G=list(G1=list(V=1, nu=0)))
>>>>>>> 
>>>>>>> I have left the default prior for the fixed effects (not
>>>>> explicitly
>>>>>>> specified above), and the default prior random effect variance
>>>>>>> structure (G) which has a zero degree of belief parameter.
>>>>> Often this
>>>>>>> requires some/more thought, especially if there are few groups or
>>>>>>> replication within groups is low. Sections 1.2, 1.5 & 8.2 in the
>>>>>>> CourseNotes cover priors for variances.
>>>>>>> 
>>>>>>> 
>>>>>>> Currently there is no option for specifying priors on the
>>>>> cut- points
>>>>>>> - the prior is flat and improper. The posterior in virtually all
>>>>>>> cases will be proper though.
>>>>>>> 
>>>>>>> Cheers,
>>>>>>> 
>>>>>>> Jarrod
>>>>>>> 
>>>>>>> Quoting Kari Ruohonen <kari.ruohonen at utu.fi>:
>>>>>>> 
>>>>>>>> Hi,
>>>>>>>> I am trying to figure out how to fit an ordinal regression model
>>>>>>>> with MCMCglmm. The "MCMCglmm Course notes" has a section on
>>>>>>>> multinomial models but no example of ordinal models.
>>>>> Suppose I have
>>>>>>>> the following data
>>>>>>>> 
>>>>>>>>> data
>>>>>>>> resp treat group
>>>>>>>> 1     4     A    1
>>>>>>>> 2     4     A    1
>>>>>>>> 3     3     A    2
>>>>>>>> 4     4     A    2
>>>>>>>> 5     2     A    3
>>>>>>>> 6     4     A    3
>>>>>>>> 7     2     A    4
>>>>>>>> 8     2     A    4
>>>>>>>> 9     3     A    5
>>>>>>>> 10    2     A    5
>>>>>>>> 11    1     B    6
>>>>>>>> 12    1     B    6
>>>>>>>> 13    1     B    7
>>>>>>>> 14    2     B    7
>>>>>>>> 15    2     B    8
>>>>>>>> 16    3     B    8
>>>>>>>> 17    2     B    9
>>>>>>>> 18    1     B    9
>>>>>>>> 19    2     B   10
>>>>>>>> 20    2     B   10
>>>>>>>> 
>>>>>>>> and the "resp" is an ordinal response, "treat" is a treatment and
>>>>>>>> "group" is membership to a group. Assume I would like to fit an
>>>>>>>> ordinal model between "resp" and "treat" by having
>>>>> "group" effects
>>>>>>>> as random effects. How would I specify such a model in
>>>>> MCMCglmm? And
>>>>>>>> how would I specify the prior distributions?
>>>>>>>> 
>>>>>>>> All help is greatly appreciated.
>>>>>>>> 
>>>>>>>> regards, Kari
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 
>> 
> 
> 
> -- 
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
> 
> 


From john.maindonald at anu.edu.au  Tue Jan  8 03:16:20 2013
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Tue, 8 Jan 2013 15:16:20 +1300
Subject: [R-sig-ME] stepwise model selection (of fixed effects
	only)	using AIC?
In-Reply-To: <CANmSXjQEiz-yzm5dR644gdM-9g=Cb7-cXu8t3vndhBHQccjToQ@mail.gmail.com>
References: <CANmSXjQ9aO_xuFNvrdJ09hwuc9SegbtAfycv4ifXDaynwjh8sA@mail.gmail.com>
	<CCE952776B6679469977532BD863C39C3567169B@Lewis.autuni.aut.ac.nz>
	<CANmSXjQEiz-yzm5dR644gdM-9g=Cb7-cXu8t3vndhBHQccjToQ@mail.gmail.com>
Message-ID: <2A290180-D052-4181-8E19-B5D83B1D31FA@anu.edu.au>

Re stepwise or other variable selection approaches with lm()
[but the same issues arise more generally, including with
multi-level models), the function bsnVaryNvar() that is in more
recent versions of our DAAG package may be of some interest.
Just try running 

bsnVaryNvar(method='forward')
bsnVaryNvar(method='backward')
bsnVaryNvar()   ## Exhaustive selection

The default is to select the 'best' 3 variables from a number of
predictors that is varied between 3 and 50, with data in which
the predictors are independent gaussian noise, as is the outcome
variable.  When the best 3 variables are selected out of a number
that is in the region of 15 to 20 or so, the averaging method used 
by our function is likely to give an 'average' notional p-value that
has dropped below 0.05   There are of course ways to account
for the selection bias, but they are non-trivial. 

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.
http://www.maths.anu.edu.au/~johnm

On 08/01/2013, at 10:31 AM, Diego Pujoni <diegopujoni at gmail.com> wrote:

> The default of the lmer is REML=TRUE, but the anova default is REML=FALSE
> see
> http://tolstoy.newcastle.edu.au/R/e6/help/09/04/11789.html
> 
> The author prevents not only step(glmer()), but any type of stepwise
> selection, including step(glm()). For the author the model has to come
> before the data (a priori hypothesis) and the data has to bring evidence to
> accept or refuse this a priori hypothesis. Look for the best model that
> fits the data is considered "data dredging" by the author and do not agree
> with the "phylosophy" of the AIC (the existence of an infinite dimensional
> real model).
> 
> Please, this is not my opinion, but the author's. I'm still studing if I
> agree or not with it. But as I see in the papers, this kind of analysis are
> becoming more and more used.
> 
> A hug
> 
> 
> 2013/1/7 Steve Taylor <steve.taylor at aut.ac.nz>
> 
>> Obrigado, Diego.  Yes I have studied a little bit of information theory,
>> tho my recollections are hazy.
>> 
>>> you can not compare combinations of fixed effects of class "mer" with
>> REML = TRUE.
>> Curious then, that that's the default value, and that the default anova()
>> does precisely that by comparing two models differing only in the fixed
>> effects included.
>> 
>> I'm aware of the objections, such as the danger of spurious relations.
>> But I cannot see why they prevent step(glmer()) when step(glm()) has been
>> a standard feature in R for many years.  The real reason seems to be the
>> fact that methods in package:stats don't work with S4 objects.
>> 
>> With my sample size, I think the difference between AIC and AICc is
>> negligible.
>> 
>> cheers,
>>    Steve
>> 
>> -----Original Message-----
>> From: r-sig-mixed-models-bounces at r-project.org [mailto:
>> r-sig-mixed-models-bounces at r-project.org] On Behalf Of Diego Pujoni
>> Sent: Tuesday, 8 January 2013 2:04a
>> To: r-sig-mixed-models at r-project.org
>> Subject: Re: [R-sig-ME] stepwise model selection (of fixed effects only)
>> using AIC?
>> 
>> Hi Steve, have you heard about Information-Theoretic Approach? It uses the
>> value of AIC (or AICc) to choose the best hypothesis among many a priori
>> hypothesis. In Anderson (2008) "Model Based Inference in the Life Sciences"
>> we see recomendations against stepwise (or all possible models) because
>> this can lead easily to spurious relations. The author recommend to create
>> several a priori hypothesis (models), using knowledge about the system and
>> then use the AICc to look for the best of them. Another thing that you have
>> to pay attention is the fact that you can not compare combinations of fixed
>> effects of class "mer" with REML = TRUE.
>> 
>> A hug
>> 
>> --
>>                                               Diego PJ
>> 
>>        [[alternative HTML version deleted]]
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 
> 
> 
> 
> -- 
>                                               Diego PJ
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From jwiley.psych at gmail.com  Tue Jan  8 03:18:41 2013
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Mon, 7 Jan 2013 18:18:41 -0800
Subject: [R-sig-ME] ordinal regression with MCMCglmm
In-Reply-To: <C06A341C-5938-4075-9E88-3CAB63E7884D@bristol.ac.uk>
References: <mailman.1345.1271262437.4213.r-sig-mixed-models@r-project.org>
	<9FF35CC0-60F0-4C35-AE34-58FD35572A0A@bristol.ac.uk>
	<20130107210735.559320w69jt6651c@www.staffmail.ed.ac.uk>
	<C06A341C-5938-4075-9E88-3CAB63E7884D@bristol.ac.uk>
Message-ID: <CANz9Z_KEqBfM8QfAM5KjiK7TqKRcwNAsfSWv9FVG=34+Vczuvg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130107/5a7f4fd4/attachment.pl>

From seth at swbigelow.net  Tue Jan  8 04:17:13 2013
From: seth at swbigelow.net (Seth W. Bigelow)
Date: Mon, 7 Jan 2013 22:17:13 -0500
Subject: [R-sig-ME] Fwd: Assigning random effects
In-Reply-To: <CAOho3adOeqk2hd8pvZht6=DFZ5hAHZH0=mEOV2aavpH8FO8Nsg@mail.gmail.com>
References: <CAOho3ae9z44ZBv-bi5Z6FPNWLy-L3Q8BK5g-0CAV+sW+Xo=DkQ@mail.gmail.com>
	<CAOho3adOeqk2hd8pvZht6=DFZ5hAHZH0=mEOV2aavpH8FO8Nsg@mail.gmail.com>
Message-ID: <001601cded4e$ab0361d0$010a2570$@net>

Nathan, 

I am no mixed model master but a humble R-using ecologist. Nevertheless I
will make a few observations regarding your question and allow the true
masters to correct me if I err. The first observation is that it takes a lot
of data points in order to estimate a random effect properly, far more that
it would appear you have for most of your effects. Think of estimating a
random effect like estimating variance for a group of data points. You can't
do a very good job estimating variance for two data points. Therefore, I
don't think it is desirable to treat your two blocks or three gaps as random
effects. As for transects, you only have one transect for each combination
of block X treatment (Ok, you have two transects for one treatment in block
B), so there's no way transect can be a random effect. On the other hand,
you probably have enough observations on different individuals at each
combination of block X treatment to make a decent estimate of variance. A
model like 'lmer(response ~ vegtreat * gappos2 + (Block|TreeId))' might be a
good place to start, though I make no guarantees here, particularly since I
am more familiar with nlme, being somewhat of a beginner myself with mixed
models. Perhaps an even better place to start would be to take the mean
response at each combination of Treatment X GapPosition X Block, and play
with the simple linear model lm(Treatment * gappos2).  

Good luck,
-Seth W. Bigelow





    

-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org
[mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Nathan Eustis
Rutenbeck
Sent: Monday, January 07, 2013 12:14 PM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] Fwd: Assigning random effects

My apologies, I am forwarding this corrected message:


Hi mixed model masters,

Forgive what may be a relatively elementary, yet overly detailed question
regarding model specification. I am attempting to use lmer() to model
photosynthetic gas exchange data for two tree species, white spruce and
trembling aspen across forest gap positions and for two vegetation
treatments. The experimental design is a replicated block design as
follows:

-In each of two blocks (A and B) there are four experimental harvest gaps.
Three gaps were used for this study, one in the B block and two in the A
block.

-Within each gap there are nine transects. Five of these transects were
chosen for this study, three in the block B gap and one in each of the gap A
blocks. One of two vegetation management treatments were randomly assigned
to each transect, a release and a sprout treatment. As I understand it,
there are therefore replications of vegetation treatment within each block,
but not within each gap.

-Within each transect, four positions within the gap were delineated
(understory, southern edge, center, northern edge) and at each gap position
6 individuals of each species were sampled. Because of data logging errors,
however, in actuality there are between 2 and 12 samples at each gap
position (originally there were five gap positions, but two were combined in
order to avoid cell-values of zero in the experimental design).

-For each individual, a series of gas exchange measurements were made (net
assimilation, evapotranspiration, and water-use efficiency) at two different
light levels. Note that I transformed the response variables in order to
improve normality of residual error.

I am therefore building a series of models - for each gas exchange
measurement, for each of the two species, for each of the two light levels.
For each model, I wish to perform hypothesis tests on the significance of
fixed-effects *vegetation treatment *and *gap position *for the mean of the
response variable (e.g. net assimilation). My question regards the correct
method of assigning random effects within these models. From my perspective,
there are several levels of random effects that could potentially be
included: block, gap, transect, gap position, and individual tree, since
each of these levels represents some component of additional environmental
or genetic variability that I am not modelling explicitly with the
fixed-effects. An example of what I have been doing follows:

>(fm1<-lmer(log(photo)~vegtrt+gappos2+(1|block),data=subset(m1200,specie
>s=="PIGL")))
>(fm2<-lmer(log(photo)~vegtrt+gappos2+(1|block/gap),data=subset(m1200,sp
>ecies=="PIGL")))
>(fm3<-lmer(log(photo)~vegtrt+gappos2+
(1|block/gap/transect/gappos2),data=subset(m1200,species=="PIGL")))
>(fm4<-lmer(log(photo)~vegtrt+gappos2+(1|block/gap/transect/gappos2/ind)
>,data=subset(m1200,species=="PIGL")))
>anova(fm1,fm2,fm3,fm4)


Which generates this output:

Models:
fm1: log(photo) ~ vegtrt + gappos2 + (1 | block)
fm2: log(photo) ~ vegtrt + gappos2 + (1 | block/gap)
fm3: log(photo) ~ vegtrt + gappos2 + (1 | block/gap/transect/gappos2)
fm4: log(photo) ~ vegtrt + gappos2 + (1 | block/gap/transect/gappos2/ind)
           Df    AIC         BIC          logLik       Chisq      Chi Df
 Pr(>Chisq)
fm1     7     137.10    155.62    -61.552
fm2     8     122.03    143.19    -53.016    17.072     1
 3.598e-05
fm3    10    126.81    153.25    -53.406     0.000      2            1
fm4    11    128.81    157.90    -53.406     0.000      1            1


As I understand, based on AIC, BIC, and log-likelihood tests, the best model
for this particular response variable is the fm2 object. When I call the
summary() function, however, I get the following output for the random
effects portion:

...
Random effects:
 Groups         Name           Variance        Std.Dev.
 gap:block     (Intercept)    1.7856e-01    4.2257e-01
 block            (Intercept)    2.7164e-18    1.6482e-09
 Residual                           1.5357e-01    3.9188e-01
Number of obs: 104, groups: gap:block, 3; block, 2 ...

The variance components are so small for the random effects (and the sd for
them so large in comparison), though, that it makes me wonder if this is
not, in actuality, over-fitting the model and there is some other
(superior) method for deciding which random effects to include in a designed
experiment like this. Does the structure of the replication make a
difference to how I must specify the random effects within the model (i.e.,
can I even include 'gap' because it is just an arbitrary, unreplicated
division of the block level)? I also wonder if I should perform similar
model selection procedures for each of my (many) models, or decide on a
sensible random effects structure for all of them and stick with it.

I also, like many people, am still wondering how to properly assess and
report the significance of the fixed effects for these models
(log-likelihood tests versus a null or alternative model?) and whether
multiple comparisons using glht() are valid for these objects given Douglas
Bates' comments regarding denominator degrees of freedom, but am more than
happy to leave these questions aside for now.

Thanks for your time,

-Nathan

--
*Nathan E. Rutenbeck*
PhD Student
Silviculture and Forest Ecology

231 Nutting Hall
School of Forest Resources
University of Maine

207.664.9581 (cell)



--
*Nathan E. Rutenbeck*
Research Assistant
Silviculture and Forest Ecology

231 Nutting Hall
School of Forest Resources
University of Maine

207.664.9581 (cell)

	[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From j.hadfield at ed.ac.uk  Tue Jan  8 08:48:36 2013
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Tue, 08 Jan 2013 07:48:36 +0000
Subject: [R-sig-ME] ordinal regression with MCMCglmm
In-Reply-To: <C06A341C-5938-4075-9E88-3CAB63E7884D@bristol.ac.uk>
References: <mailman.1345.1271262437.4213.r-sig-mixed-models@r-project.org>
	<9FF35CC0-60F0-4C35-AE34-58FD35572A0A@bristol.ac.uk>
	<20130107210735.559320w69jt6651c@www.staffmail.ed.ac.uk>
	<C06A341C-5938-4075-9E88-3CAB63E7884D@bristol.ac.uk>
Message-ID: <20130108074836.30711a8chm117ipw@www.staffmail.ed.ac.uk>

Hi Malcolm,


That makes sense. The next version of MCMCglmm will have a  
family="threshold" that fits a probit link but allowing the `extra'  
residual component to be set to zero. Its not that useful for  
univariate analyses, but for multivariate analyses it will allow  
(polychoric) residual correlations greater in magnitude. Currently  
they are limited to <0.5 (if the residual variance is fixed at one,  
more if it is fixed higher).

Cheers,

Jarrod




Quoting Malcolm Fairbrother <m.fairbrother at bristol.ac.uk> on Tue, 8  
Jan 2013 00:35:24 +0000:

> Dear Jarrod,
>
> Thanks a lot for this -- very helpful.
>
> OK, so since I DO want to marginalise the random effects (I'm  
> interested in predicted probabilities for a hypothetical/typical  
> judge rather than an actually observed one), I think the code I want  
> is:
>
> diff(pnorm(c(-Inf, 0, colMeans(MC1$CP), Inf)-colMeans(MC1$Sol) %*%  
> c(1,0,0), 0, sqrt(1+1))) # MCMCglmm
> diff(pnorm(c(-Inf,fm2$Theta, Inf) - fm2$beta %*% c(0,0), 0, 1)) # clmm
>
> And these two approaches do indeed yield very consistent results. I  
> guess I need to set slightly different SDs for pnorm because clmm  
> assumes the residual variance is 0, whereas with MCMCglmm (and given  
> the prior I used, as recommended in the CourseNotes) it's set to 1?
>
> Much appreciated,
> Malcolm
>
>
>
> On 7 Jan 2013, at 21:07, Jarrod Hadfield wrote:
>
>> Hi Malcolm,
>>
>> Your way of obtaining the predicted probability of falling into a  
>> class from the MCMCglmm output is correct.  The method you use for  
>> the clmm output is not the expected value over random effects (as  
>> you've calculated for the MCMCglmm model), but the expected value  
>> for a random effect of zero.  If you use probit link in clmm, and  
>> marginalise the random effects you will find the clmm and MCMCglmm  
>> estimates to be identical:
>>
>> summary(fm2 <- clmm2(rating ~ temp + contact, random=judge,  
>> data=wine, Hess=TRUE, nAGQ=10, link="probit"))
>>
>> diff(pnorm(c(-Inf,fm2$Theta, Inf) - fm2$beta %*% c(0,0), 0,  
>> sqrt(1+fm2$stDev)))
>> diff(pnorm(c(-Inf,fm2$Theta, Inf) - fm2$beta %*% c(1,1), 0,  
>> sqrt(1+fm2$stDev))) # for tempwarm and contactyes
>>
>> Cheers,
>>
>> Jarrod
>>
>>
>>
>>
>>
>>
>> Quoting Malcolm Fairbrother <m.fairbrother at bristol.ac.uk> on Mon, 7  
>> Jan 2013 19:56:20 +0000:
>>
>>> Dear list,
>>>
>>> I'm picking up on a thread from 2010  
>>> (https://stat.ethz.ch/pipermail/r-sig-mixed-models/2010q2/003678.html),  
>>> about ordinal mixed models, fitted with clmm (from the ordinal  
>>> package) and MCMCglmm.
>>>
>>> I would like to fit an ordinal mixed model, with random slopes.  
>>> Since clmm doesn't do random slopes, I'm trying with MCMCglmm, but  
>>> I'm not sure I understand how MCMCglmm handles ordinal data.
>>>
>>> To illustrate, I'll use the "wine" data from the ordinal package,  
>>> and a model with only random intercepts.
>>>
>>> library(ordinal)
>>> library(MCMCglmm)
>>>
>>> data(wine)
>>> str(wine)
>>> summary(fm2 <- clmm2(rating ~ temp + contact, random=judge,  
>>> data=wine, Hess=TRUE, nAGQ=10))
>>>
>>> # to get predicted probabilities for each possible of the five  
>>> possible responses, for two combinations of covariates:
>>> diff(plogis(c(-Inf,fm2$Theta, Inf) - fm2$beta %*% c(0,0))) # for  
>>> tempcold and contactno
>>> diff(plogis(c(-Inf,fm2$Theta, Inf) - fm2$beta %*% c(1,1))) # for  
>>> tempwarm and contactyes
>>>
>>> # compare with the raw data (seems to make sense...):
>>> table(wine$rating[wine$temp=="cold" & wine$contact=="no"])
>>> table(wine$rating[wine$temp=="warm" & wine$contact=="yes"])
>>>
>>> # now fit the same model, using MCMCglmm:
>>> prior1 <- list(R = list(V = 1, nu = 0.002, fix=1), G = list(G1 =  
>>> list(V = 1, nu = 0.002)))
>>> MC1 <- MCMCglmm(rating ~ temp + contact, random=~judge, data=wine,  
>>> family="ordinal", prior=prior1, nitt=130000, thin=100, verbose=F)
>>>
>>> # and get predicted probabilities, using the results from  
>>> MCMCglmm, and the "hunch" approach Jarrod mentioned in the thread  
>>> above:
>>> diff(pnorm(c(-Inf, 0, colMeans(MC1$CP), Inf)-colMeans(MC1$Sol) %*%  
>>> c(1,0,0), 0, sqrt(1+sum(colMeans(MC1$VCV))))) # for tempcold and  
>>> contactno
>>> diff(pnorm(c(-Inf, 0, colMeans(MC1$CP), Inf)-colMeans(MC1$Sol) %*%  
>>> c(1,1,1), 0, sqrt(1+sum(colMeans(MC1$VCV))))) # for tempwarm and  
>>> contactyes
>>>
>>> The predicted probabilities are similar, but not similar enough  
>>> that I'm sure this is right. Are the differences due to MCMC  
>>> error, inappropriate priors, or the way I'm predicting  
>>> probabilities based on one (or both?) model(s)?
>>>
>>> If anyone can offer any clarifications/suggestions, I'd be  
>>> grateful. (Maybe Thierry figured this out?)
>>>
>>> Cheers,
>>> Malcolm
>>>
>>>
>>>
>>>> Date: Wed, 14 Apr 2010 15:41:45 +0100
>>>> From: Jarrod Hadfield <j.hadfield at ed.ac.uk>
>>>> To: "ONKELINX, Thierry" <Thierry.ONKELINX at inbo.be>
>>>> Cc: r-sig-mixed-models at r-project.org
>>>> Subject: Re: [R-sig-ME] ordinal regression with MCMCglmm
>>>> Message-ID: <2FE797FF-C1EC-4CA2-8275-C3B0AA9243BE at ed.ac.uk>
>>>> Content-Type: text/plain; charset=US-ASCII; format=flowed; delsp=yes
>>>>
>>>> Dear Thierry,
>>>>
>>>> I think (but you had better check) that it would actually be something
>>>> like
>>>>
>>>> pnorm(-Xb, 0, sqrt(1+v)),
>>>> pnorm(cp[1] - Xb,0, sqrt(1+v)) - pnorm(Xb,0, sqrt(1+v))
>>>> pnorm(cp[2] - Xb,0, sqrt(1+v)) - pnorm(cp[1] - Xb,0, sqrt(1+v))
>>>> 1- pnorm(cp[2] - Xb,0, sqrt(1+v))
>>>>
>>>> where v is  the sum of the variance components for the residual and
>>>> random effects.
>>>>
>>>> Alternatively, if the residual variance is set to one and there are no
>>>> random effects
>>>>
>>>> pnorm(-Xb, 0, sqrt(2)),
>>>> pnorm(cp[1] - Xb,0, sqrt(2)) - pnorm(Xb,0, sqrt(2))
>>>> pnorm(cp[2] - Xb,0, sqrt(2)) - pnorm(cp[1] - Xb,0, sqrt(2))
>>>> 1- pnorm(cp[2] - Xb,0, sqrt(2))
>>>>
>>>> or if the prediction includes random effects:
>>>>
>>>> pnorm(-(Xb+Zu), 0, sqrt(2)),
>>>> pnorm(cp[1] - (Xb+Zu),0, sqrt(2)) - pnorm((Xb+Zu),0, sqrt(2))
>>>> pnorm(cp[2] - (Xb+Zu),0, sqrt(2)) - pnorm(cp[1] - (Xb+Zu),0, sqrt(2))
>>>> 1- pnorm(cp[2] - (Xb+Zu),0, sqrt(2))
>>>>
>>>> Please, do not take this as gospel. I have not got time to check these
>>>> results, they are a hunch.
>>>>
>>>> Cheers,
>>>>
>>>> Jarrod
>>>>
>>>>
>>>> On 14 Apr 2010, at 15:25, ONKELINX, Thierry wrote:
>>>>
>>>>> Dear Jarrod,
>>>>>
>>>>> I'm working on a similar problem. Does it makes sense to calculate
>>>>> that
>>>>> for the fixed effects only? Something like this:
>>>>> pnorm(-Xb),
>>>>> pnorm(cp[1] - Xb) - pnorm(Xb)
>>>>> pnorm(cp[2] - Xb) - pnorm(cp[1] - Xb)
>>>>> 1 - pnorm(cp[2] - Xb)
>>>>>
>>>>> Best regards,
>>>>>
>>>>> Thierry
>>>>> ------------------------------------------------------------------------
>>>>> ----
>>>>> ir. Thierry Onkelinx
>>>>> Instituut voor natuur- en bosonderzoek
>>>>> team Biometrie & Kwaliteitszorg
>>>>> Gaverstraat 4
>>>>> 9500 Geraardsbergen
>>>>> Belgium
>>>>>
>>>>> Research Institute for Nature and Forest
>>>>> team Biometrics & Quality Assurance
>>>>> Gaverstraat 4
>>>>> 9500 Geraardsbergen
>>>>> Belgium
>>>>>
>>>>> tel. + 32 54/436 185
>>>>> Thierry.Onkelinx at inbo.be
>>>>> www.inbo.be
>>>>>
>>>>> To call in the statistician after the experiment is done may be no
>>>>> more
>>>>> than asking him to perform a post-mortem examination: he may be able
>>>>> to
>>>>> say what the experiment died of.
>>>>> ~ Sir Ronald Aylmer Fisher
>>>>>
>>>>> The plural of anecdote is not data.
>>>>> ~ Roger Brinner
>>>>>
>>>>> The combination of some data and an aching desire for an answer does
>>>>> not
>>>>> ensure that a reasonable answer can be extracted from a given body of
>>>>> data.
>>>>> ~ John Tukey
>>>>>
>>>>>
>>>>>> -----Oorspronkelijk bericht-----
>>>>>> Van: r-sig-mixed-models-bounces at r-project.org
>>>>>> [mailto:r-sig-mixed-models-bounces at r-project.org] Namens
>>>>>> Jarrod Hadfield
>>>>>> Verzonden: woensdag 14 april 2010 15:35
>>>>>> Aan: Kari Ruohonen
>>>>>> CC: Kari Ruohonen; r-sig-mixed-models at r-project.org
>>>>>> Onderwerp: Re: [R-sig-ME] ordinal regression with MCMCglmm
>>>>>>
>>>>>> Hi,
>>>>>>
>>>>>> Imagine a latent variable (l) that conforms to the  standard
>>>>>> linear model.
>>>>>>
>>>>>> l = Xb+Zu+e
>>>>>>
>>>>>> The probabilities of falling into each of the four categories are:
>>>>>>
>>>>>>
>>>>>> pnorm(-l)
>>>>>>
>>>>>> pnorm(cp[1]-l)-pnorm(-l)
>>>>>>
>>>>>> pnorm(cp[2]-l)-pnorm(cp[1]-l)
>>>>>>
>>>>>> 1-pnorm(cp[2]-l)
>>>>>>
>>>>>> where cp is the vector of cut-points with 2 elements. A 3
>>>>>> cut-point model would be over-parameterised (unless the
>>>>>> intercept is zero, which I presume is what polr does (?).
>>>>>>
>>>>>> The factors don't need to be ordered, the order is obtained
>>>>>> from levels(resp).  In the future, I may only allowed ordered
>>>>>> factors to stop any accidents.
>>>>>>
>>>>>> Cheers,
>>>>>>
>>>>>> Jarrod
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>> On 14 Apr 2010, at 08:07, Kari Ruohonen wrote:
>>>>>>
>>>>>>> Hi and thanks for the answer. I tried exactly that model
>>>>>> syntax before
>>>>>>> posting but the output of the "fixed" part had an unexpected
>>>>>>> parameterisation and I thought I misspecified the model
>>>>>> somehow. The
>>>>>>> parameters I got with the above model are
>>>>>>> - two cutpoints
>>>>>>> - intercept
>>>>>>> - effect of group B
>>>>>>>
>>>>>>> I would have expected that instead of the intercept and two
>>>>>> cutpoints
>>>>>>> I would have had three cutpoints as given by polr (MASS
>>>>>> package), for
>>>>>>> example. Can you explain me the parameterisation in
>>>>>> MCMCglmm and how
>>>>>>> it connects to the one in polr that uses J-1 ordered cutpoints
>>>>>>> (J=number of score classes) without an intercept?
>>>>>>>
>>>>>>> Also, I am uncertain do I need to convert the "resp" before
>>>>>> MCMCglmm
>>>>>>> to an ordered factor (with "ordered")?
>>>>>>>
>>>>>>> Many thanks,
>>>>>>>
>>>>>>> Kari
>>>>>>>
>>>>>>> On Tue, 2010-04-13 at 17:41 +0100, Jarrod Hadfield wrote:
>>>>>>>> Hi Kari,
>>>>>>>>
>>>>>>>> The simplest model is
>>>>>>>>
>>>>>>>>
>>>>>>>> m1<-MCMCglmm(resp~treat, random=~group, family="ordinal",
>>>>>>>> data=your.data, prior=prior)
>>>>>>>>
>>>>>>>> as with multinomial data with a single realisation, the residual
>>>>>>>> variance cannot be estimated from the data. The best
>>>>>> option is to fix
>>>>>>>> it at some value. most programs fix it at zero but
>>>>>> MCMCglmm will fail
>>>>>>>> to mix if this is done, so I usually fix it at 1:
>>>>>>>>
>>>>>>>>
>>>>>>>> prior=list(R=list(V=1, fix=1), G=list(G1=list(V=1, nu=0)))
>>>>>>>>
>>>>>>>> I have left the default prior for the fixed effects (not
>>>>>> explicitly
>>>>>>>> specified above), and the default prior random effect variance
>>>>>>>> structure (G) which has a zero degree of belief parameter.
>>>>>> Often this
>>>>>>>> requires some/more thought, especially if there are few groups or
>>>>>>>> replication within groups is low. Sections 1.2, 1.5 & 8.2 in the
>>>>>>>> CourseNotes cover priors for variances.
>>>>>>>>
>>>>>>>>
>>>>>>>> Currently there is no option for specifying priors on the
>>>>>> cut- points
>>>>>>>> - the prior is flat and improper. The posterior in virtually all
>>>>>>>> cases will be proper though.
>>>>>>>>
>>>>>>>> Cheers,
>>>>>>>>
>>>>>>>> Jarrod
>>>>>>>>
>>>>>>>> Quoting Kari Ruohonen <kari.ruohonen at utu.fi>:
>>>>>>>>
>>>>>>>>> Hi,
>>>>>>>>> I am trying to figure out how to fit an ordinal regression model
>>>>>>>>> with MCMCglmm. The "MCMCglmm Course notes" has a section on
>>>>>>>>> multinomial models but no example of ordinal models.
>>>>>> Suppose I have
>>>>>>>>> the following data
>>>>>>>>>
>>>>>>>>>> data
>>>>>>>>> resp treat group
>>>>>>>>> 1     4     A    1
>>>>>>>>> 2     4     A    1
>>>>>>>>> 3     3     A    2
>>>>>>>>> 4     4     A    2
>>>>>>>>> 5     2     A    3
>>>>>>>>> 6     4     A    3
>>>>>>>>> 7     2     A    4
>>>>>>>>> 8     2     A    4
>>>>>>>>> 9     3     A    5
>>>>>>>>> 10    2     A    5
>>>>>>>>> 11    1     B    6
>>>>>>>>> 12    1     B    6
>>>>>>>>> 13    1     B    7
>>>>>>>>> 14    2     B    7
>>>>>>>>> 15    2     B    8
>>>>>>>>> 16    3     B    8
>>>>>>>>> 17    2     B    9
>>>>>>>>> 18    1     B    9
>>>>>>>>> 19    2     B   10
>>>>>>>>> 20    2     B   10
>>>>>>>>>
>>>>>>>>> and the "resp" is an ordinal response, "treat" is a treatment and
>>>>>>>>> "group" is membership to a group. Assume I would like to fit an
>>>>>>>>> ordinal model between "resp" and "treat" by having
>>>>>> "group" effects
>>>>>>>>> as random effects. How would I specify such a model in
>>>>>> MCMCglmm? And
>>>>>>>>> how would I specify the prior distributions?
>>>>>>>>>
>>>>>>>>> All help is greatly appreciated.
>>>>>>>>>
>>>>>>>>> regards, Kari
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>>
>>
>>
>> --
>> The University of Edinburgh is a charitable body, registered in
>> Scotland, with registration number SC005336.
>>
>>
>
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From geralttee at gmail.com  Tue Jan  8 13:33:49 2013
From: geralttee at gmail.com (Szymek Drobniak)
Date: Tue, 8 Jan 2013 13:33:49 +0100
Subject: [R-sig-ME] Complex random regression structure in ASREML-R
Message-ID: <CANXb-o7a8koqhrwizwBFO83yuEvqurVdzuu67vjQiA+0Rue3jg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130108/03bb139c/attachment.pl>

From highstat at highstat.com  Tue Jan  8 13:11:15 2013
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Tue, 08 Jan 2013 08:11:15 -0400
Subject: [R-sig-ME] New book: Beginner's Guide to GAM with R
Message-ID: <50EC0CE3.9080603@highstat.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130108/e7ca05c6/attachment.pl>

From i.m.s.white at ed.ac.uk  Tue Jan  8 14:57:04 2013
From: i.m.s.white at ed.ac.uk (i white)
Date: Tue, 08 Jan 2013 13:57:04 +0000
Subject: [R-sig-ME] Complex random regression structure in ASREML-R
In-Reply-To: <CANXb-o7a8koqhrwizwBFO83yuEvqurVdzuu67vjQiA+0Rue3jg@mail.gmail.com>
References: <CANXb-o7a8koqhrwizwBFO83yuEvqurVdzuu67vjQiA+0Rue3jg@mail.gmail.com>
Message-ID: <50EC25B0.5050606@ed.ac.uk>

How about

~str(~F1:family + F1:family:time, ~us(4):id(90))

I think this will give an unstructured 4x4 for the 2 intercepts and two 
slopes. If you really want zero covariance between intercept in one 
group and slope in the other, you have to impose constraints and set 
initial values as described in the asreml-R manual.

On 01/08/2013 12:33 PM, Szymek Drobniak wrote:
> Hi all,
> I'm currently analyzing data using random regression and I'm a bit puzzled
> how to fit a more complex covariance structure. In my data I have one
> two-level fixed factor (say F1), one random effect of "family" with 90
> families and another fixed effect with 3 levels (say F2). All families have
> individuals found in all combinations of F1 and F2. I also have a
> continuous variable Time.
>
> If I get it right - the simplest random regression model would look like
> this (only the random part):
> ~str(~family+family:time, ~us(2):id(90))
>
> Also - if I understand correctly - if I wanted to add F1 to the structure I
> could fit
> ~at(F1):str(~family+family:time, ~us(2):id(90)) which would give me a
> covariance structure of (sorry for sloppy matrices, each row represents 4
> elements of a 4 rows matrix):
>
>
> V.F1a(intercept)        COV.F1a         0               0
> COV.F1a                 V.F1a(slope)    0               0
> 0                       0               V.F1b(int)      COV.F1b
> 0                       0               COV.F1b         V.F1b(slope)
>
> And now the tricky part: how I can specify that (if its possible) to
> estimate also covariances between intercepts and slopes in different F1
> groups? i.e.
>
>
> V.F1a(intercept)        COV.F1a         COV.Fab(i)      0
> COV.F1a                 V.F1a(slope)    0               COV.Fab(s)
> COV.Fab(i)              0               V.F1b(int)      COV.F1b
> 0                       COV.Fab(s)      COV.F1b         V.F1b(slope)
>
>
> Of course there's yet another level for this complexity (it's the F2 factor
> but this one could be incorporated by creating an additional F3 with levels
> being combinations of F1 and F2.
>
> Cheers,
> szymek
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From bbolker at gmail.com  Tue Jan  8 15:20:57 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 8 Jan 2013 14:20:57 +0000 (UTC)
Subject: [R-sig-ME] lme4 and r-forge
References: <985B103D-F0F5-4B97-B9AC-6F236612AC28@imperial.ac.uk>
Message-ID: <loom.20130108T150910-49@post.gmane.org>

Federico Calboli <f.calboli at ...> writes:

> Hi All, I am running lme4 version 0.99999911-0, installed (as a
> binary) from http://r-forge.r-project.org.  I cannot find binaries
> or sources of lme4 on R forge anymore -- suggestions on how to keep
> up to date with the development branch of lme4 (not lme4a or
> lme4.0)?  Ideally I'd prefer a binary (for OSX), but obviously I'd
> take what's available.

   The development version is not building on R forge at the moment 
apparently due to some small Rcpp/minqa glitch (sigh). However ...
the very latest development version is now hosted on github:

library(devtools)
install_github("lme4",user="lme4")

should work, *if* you have installed (1) the necessary dependencies
(Rcpp, RcppEigen, Matrix, minqa) (2) the necessary tools for
building a package from source [which are typically present
on MacOS machines, I think?]

  Ben Bolker


From paulsendj at upmc.edu  Mon Jan  7 18:38:01 2013
From: paulsendj at upmc.edu (Paulsen, David)
Date: Mon, 7 Jan 2013 17:38:01 +0000
Subject: [R-sig-ME] weighted vs unweighted GLMER variance estimates
Message-ID: <26ECEEF4230B3342A097C24284B91CF1019AC99D@MSXMBXNSPRD11.acct.upmchs.net>

Dear Users,

I've recently been working on analyzing a longitudinal & cross-sectional fMRI data set of unbalanced design consisting of approx 160 participants. Consistent with multilevel modeling often used in fMRI analysis, I've been using parameter and variance estimates in neural response from each subject as my data, with Age and Age^2 as predictor variables. I've also been checking to see how the results from weighted GLMs (wGLM), weighted GLMER (wGLMER), and unweighted GLMs, compare to a standard fMRI analysis package (FSL) with a subset of the data. In doing so, I've found that the weighted GLMER produces more similar variance estimates than the unweighted GLMER, provided I make an adjustment to output provided by lme4.

Essentially, the fixed effects error variance for the wGLMER appears to be larger than the error variance for the GLMER on an order proportional to error of the between-subjects residuals. This adjustment appears to be reliable across the 1900 regressions I ran my tests on.

I'm unsure of why using weights should so drastically affect the Fixed Effects variance, why dividing the wGLMER variance estimates by the residual variance achieves similarity to the unweighted GLMER variance estimates, and if I am justified in using these adjusted amounts to calculate t-values. I am including data from my full sample for an example, but am printing only some output here for immediate observation.

Help on this matter would be very much appreciated.

Regards,
David Paulsen



> # DISPLAY RESULTS
> summary(glmer_out)
Linear mixed model fit by REML
Formula: yhat ~ Age_adj + I(Age_adj^2) + (1 | subjectID)
  AIC  BIC logLik deviance REMLdev
 2714 2731  -1352     2710    2704
Random effects:
 Groups    Name        Variance Std.Dev.
 subjectID (Intercept)  325.64  18.045
 Residual              2846.26  53.350
Number of obs: 249, groups: subjectID, 137

Fixed effects:
             Estimate Std. Error t value
(Intercept)   31.8412     4.7634   6.685
Age_adj        2.7313     1.4915   1.831
I(Age_adj^2)  -0.4337     0.3100  -1.399

Correlation of Fixed Effects:
            (Intr) Age_dj
Age_adj      0.039
I(Age_dj^2) -0.507 -0.615
> summary(wglmer_out)
Linear mixed model fit by REML
Formula: yhat ~ Age_adj + I(Age_adj^2) + (1 | subjectID)
   AIC   BIC logLik deviance REMLdev
 751.9 769.4 -370.9    747.5   741.9
Random effects:
 Groups    Name        Variance Std.Dev.
 subjectID (Intercept) 818725.8 904.835
 Residual                2400.1  48.991
Number of obs: 249, groups: subjectID, 137

Fixed effects:
             Estimate Std. Error t value
(Intercept)   30.1223   215.3330   0.140
Age_adj        2.8065    66.2379   0.042
I(Age_adj^2)  -0.4986    13.2487  -0.038

Correlation of Fixed Effects:
            (Intr) Age_dj
Age_adj      0.056
I(Age_dj^2) -0.506 -0.626
>
> # COMPARE GLMER SE, wGLMER SE, & wGLMER ADJUSTED SE
> glmer_stderr
 (Intercept)      Age_adj I(Age_adj^2)
   4.7634370    1.4914602    0.3099561
> wglmer_stderr
 (Intercept)      Age_adj I(Age_adj^2)
   215.33304     66.23788     13.24866
> wglmer_stderr_adj
 (Intercept)      Age_adj I(Age_adj^2)
   4.3953591    1.3520419    0.2704305



# DATA & CODE
yhat <- c(-17.86383, -67.93507, 62.77558, -25.00129, 8.600049, 19.74757, 36.35019, 19.78256, 63.44397, 187.6141, 39.21401, -32.13604, 112.21, 99.78252, 52.1128, 8.983917, -0.2228356, 45.04539, 152.8446, 69.4516, -17.09545, 33.01205, 11.79658, 236.2675, 59.41111, 48.96542, -28.8011, 8.018624, -80.94499, 61.5362, 122.6593, 26.82249, 137.6959, 13.70128, 153.4673, 88.05206, 12.78811, 9.1956, 19.80628, 38.78817, 54.4374, -26.908, -17.47678, -12.40804, -33.34377, -12.54371, -29.12496, 29.89239, 76.09109, -1.456215, -42.91579, -35.48977, 40.3413, 96.75193, -26.20043, 72.88014, -4.498486, 44.04082, 120.6856, 36.17123, -36.29802, 53.01909, -51.50906, -22.85605, 49.57092, 120.6811, 114.3392, -2.821136, 81.09837, -55.07222, 73.61099, 47.53521, 49.42628, 145.0036, 40.72733, 2.6586, -23.1839, 74.15407, 34.09974, 43.26672, 34.73029, -43.57184, -19.39236, 99.23603, -8.092349, -9.658018, 46.68232, 18.92779, 60.55532, 67.58183, 70.43863, -66.24371, 30.25297, 63.24903, -44.24773, 110.2207, 51.43445, 34.92665, -9.43949, 33.45405, 31.89272, 14.7246, -37.78331, 101.5455, -6.926058, 15.54408, 200.0708, 49.00461, 8.489271, 15.56577, 18.82096, 79.90823, -33.52191, 65.90131, -41.56767, 41.44206, 17.85847, -0.7615868, -17.49322, 21.56572, -55.35418, -96.07809, -33.83941, 20.94368, 94.30896, 82.08093, -30.9233, 28.62884, -9.951429, 80.26689, 101.3565, 57.31608, 33.58985, 6.77054, 67.09788, -8.760614, -6.980731, -5.862709, 54.40738, 43.92796, 39.94324, 4.664509, 27.7117, 9.358894, 25.28339, -15.61768, 86.86378, 83.1256, -21.28656, -72.29863, 9.106373, 35.14648, 25.62542, 91.91111, 51.71715, 62.60024, 261.3518, 51.44857, -23.74933, 81.17366, -0.2988409, 25.64609, 0.03400882, -33.95691, 37.02612, 50.46914, -24.85151, 27.13361, 48.47046, 40.92603, 68.63319, 49.97451, -2.729544, -76.28941, 64.21523, -39.13202, 106.9234, 69.32959, 55.89867, 85.48119, 51.0333, -12.99842, 46.53439, 49.33897, -3.042722, 110.3458, 65.66805, 119.5013, -56.69803, 36.52827, -20.95306, 37.66682, -7.274448, 90.77976, 55.46455, -50.28808, 59.24579, 50.87093, -34.55978, 46.75426, -4.968956, -58.17086, 21.63069, 23.14527, -8.624804, 130.3394, 25.99968, 26.47401, 9.909436, -42.20339, 33.77307, -42.8187, -33.09747, -4.354581, 19.64606, 49.20227, 27.82024, 25.82506, 110.3884, 110.5982, 185.3917, -75.21708, 40.95378, 51.64703, -67.93621, 95.71213, 32.24789, 3.461251, -37.93186, -25.56975, 41.39754, 69.54233, 50.13354, -39.70442, 56.94862, -27.39709, 96.96685, 74.49326, 16.48888, -13.52116, 3.87862, 105.7628, -70.72237, 35.75502, 77.68787, 102.3832, -40.57845, 104.7736, 12.21588)

Age_adj <- c(5.78, 10.55, 0.41, 2.01, -1.67, -0.01, 0.69, 2.16, 1.09, 2.58, 4.02, 0.56, 2.03, -0.25, 1.16, 5.11, 5.45, 0.59, 2.12, 3.86, 8.65, 1.6, -4.51, -2.83, 1.32, 5.07, 4.21, 3.72, 5.29, 3.48, 4.91, 6.47, 3.93, 5.79, 7.12, 8.62, 1.86, 3.43, 5.78, 3.09, 4.66, 6.15, 8.55, -3.59, -2.09, 2.03, 3.52, 4.38, 7.91, 2.53, 4.22, 5.66, -0.18, 1.41, 3.01, 3.8, 6.79, 6.79, 3.96, -2.35, -0.76, 1.3, -0.15, 1.62, 5.5, 0.65, 3.85, -1.13, 0.35, -3.29, -1.81, 0.39, -3.94, -2.53, -1.01, -4.43, -2.79, -1.28, -4.89, -2.12, -0.85, 0.65, 2.37, 3.98, -0.43, 1.45, 2.49, -3.47, -1.92, -0.55, 2.91, -1.47, 1.68, -1.03, 0.73, 4.18, 5.58, -2.53, -0.87, 2.46, 5.72, -0.76, 3.31, -0.16, 1.83, 3, 1.16, 2.69, 0.69, 2.2, 3.68, 1.1, 3.17, 4.92, 6.45, 0.56, 2.13, 3.79, 5.25, 0.41, 1.96, 3.51, -0.11, 1.44, 2.9, -3.76, -2.12, -0.66, 1.68, 3.2, 3.6, 3.14, 5.17, 2.86, 4.89, 2.44, -0.26, 1.52, -4.28, -2.73, -1.18, -0.39, 0.9, -3.88, -2.09, 2.88, 2.96, 4.58, 5.9, -2.88, -1.35, 0.12, 3.39, 4.88, 6.25, 3.57, 5.33, 3.49, 5.31, 6.43, 3.9, 5.69, 3.33, -3.97, -1.62, -0.78, -1.32, 0.2, -1.56, -3.23, -2.59, -1.19, 3.86, 3.88, 5.59, -3.31, 3.74, 5.47, -3.85, 0.88, 2.64, 1.28, -2.77, -1.19, -3.24, 3.54, 3.81, -1.35, 0.17, 3.86, 5.42, -4.54, -2.85, -3.72, 1.69, -2.22, -3.3, -1.7, -1.06, 0.52, -0.88, -2.84, -1.13, 2.65, -4.12, -2.07, 1.2, -4.84, -3.1, -4.87, -3.18, -1.41, -1.95, 0.18, -1.62, 1.67, 3.15, 0.07, 1.53, 3.65, 5.48, 0.04, -4.08, -2.44, 0.74, -0.23, 1.44, 1.94, 3.68, -1.19, 3.11, 4.9, 3.95, 5.73, 0.6, 2.31, 3.9, 3.86, 5.57, -0.78, 0.71, 1.21, 3.32, 0.97, 1.29, 2.91, 0.3, 1.74, -1.86)

subjectID <- c(10128, 10134, 10152, 10152, 10153, 10153, 10156, 10156, 10173, 10173, 10173, 10181, 10181, 10300, 10300, 10315, 10385, 10406, 10406, 10406, 10431, 10451, 10466, 10466, 10529, 10558, 10565, 10567, 10567, 10568, 10568, 10568, 10572, 10572, 10572, 10574, 10585, 10585, 10585, 10589, 10589, 10589, 10594, 10599, 10599, 10604, 10604, 10604, 10605, 10608, 10608, 10608, 10616, 10616, 10616, 10623, 10623, 10623, 10625, 10626, 10626, 10626, 10627, 10627, 10629, 10633, 10635, 10636, 10636, 10637, 10637, 10637, 10638, 10638, 10638, 10644, 10644, 10644, 10646, 10652, 10653, 10653, 10654, 10654, 10661, 10661, 10661, 10662, 10662, 10662, 10664, 10665, 10665, 10666, 10666, 10667, 10667, 10671, 10671, 10673, 10673, 10674, 10675, 10677, 10677, 10677, 10678, 10678, 10680, 10680, 10680, 10686, 10689, 10689, 10689, 10696, 10697, 10697, 10697, 10699, 10699, 10699, 10700, 10700, 10700, 10701, 10701, 10701, 10703, 10703, 10707, 10708, 10708, 10709, 10709, 10710, 10711, 10711, 10717, 10717, 10717, 10747, 10747, 10749, 10749, 10757, 10758, 10758, 10758, 10760, 10760, 10760, 10761, 10761, 10761, 10762, 10762, 10765, 10765, 10765, 10766, 10766, 10768, 10772, 10772, 10773, 10774, 10774, 10778, 10779, 10780, 10780, 10782, 10786, 10786, 10787, 10788, 10788, 10790, 10796, 10796, 10797, 10798, 10798, 10800, 10802, 10803, 10804, 10804, 10805, 10805, 10806, 10806, 10807, 10808, 10809, 10811, 10811, 10812, 10812, 10813, 10814, 10814, 10817, 10818, 10818, 10820, 10821, 10821, 10822, 10822, 10824, 10826, 10826, 10836, 10839, 10839, 10840, 10840, 10841, 10841, 10842, 10843, 10843, 10845, 10847, 10847, 10849, 10849, 10850, 10851, 10851, 10852, 10852, 10869, 10869, 10870, 10872, 10872, 10873, 10873, 10874, 10875, 10877, 10879, 10879, 10887, 10887, 10888)

var_est <- c(2117.232, 1856.527, 2752.249, 1364.204, 1195.229, 4033.198, 6462.032, 1612.014, 2854.178, 3227.569, 2090.262, 2407.377, 2311.557, 3347.094, 2348.126, 1691.455, 3862.144, 1361.611, 5045.376, 2004.46, 2111.046, 1531.715, 4047.582, 4162.438, 1782.844, 2445.805, 4974.277, 972.256, 2732.625, 3149.915, 4282.503, 1667, 3445.044, 3929.609, 1857.306, 1929.016, 1806.192, 1350.487, 2163.956, 1382.237, 2105.488, 2425.088, 1585.392, 1284.99, 1839.946, 1783.923, 3088.686, 1905.855, 1395.401, 3912.845, 1873.235, 2499.939, 1997.997, 3953.164, 1110.427, 2128.916, 1421.97, 2578.543, 2438.239, 2143.414, 5448.135, 895.8371, 3876.441, 2454.641, 1266.05, 1286.321, 2371.491, 1845.233, 948.009, 2334.511, 1238.893, 2484.186, 2104.395, 1628.669, 3306.381, 1225.193, 2251.642, 2629.077, 2847.037, 3861.317, 2171.143, 1803.323, 4486.976, 3057.108, 1319.224, 2902.172, 2046.981, 2164.243, 3769.546, 1308.071, 2630.981, 1733.245, 1859.789, 2422.816, 5358.247, 5088.674, 1326.271, 2338.529, 1818.681, 1583.202, 1830.168, 2420.32, 1737.724, 2471.06, 1173.188, 2552.61, 3719.981, 1856.206, 1467.039, 4748.495, 2014.772, 1903.904, 1797.682, 2616.952, 2618.1, 2875.845, 1561.778, 2121.504, 3907.931, 1736.165, 5158.229, 2934.292, 2275.788, 2782.14, 7164.727, 3635.709, 3204.541, 3073.852, 1856.379, 2473.882, 4525.398, 2001.25, 2475.327, 2637.609, 7965.129, 5800.15, 3788.97, 3192.963, 1291.541, 6677.519, 2196.154, 2828.934, 2965.4, 3243.802, 3391.377, 2682.823, 1832.081, 2508.383, 3403.081, 2939.152, 3820.748, 2516.928, 2568.668, 5601.77, 2319.515, 3408.002, 7352.196, 3070.829, 1270.897, 2475.052, 2129.083, 3462.514, 2968.115, 1359.369, 2687.299, 2150.726, 1933.411, 1238.447, 4716.554, 3671.501, 4155.547, 2423.732, 1733.876, 2068.158, 2195.333, 1946.794, 3901.803, 1843.907, 2325.319, 3433.175, 2690.929, 2712.109, 3240.584, 2034.036, 814.4943, 4247.212, 4431.068, 1880.548, 1985.781, 2672.374, 2516.915, 8474.012, 2994.591, 3063.671, 3094.606, 1464.994, 1020.753, 3616.184, 1180.809, 3700.844, 2663.671, 2229.899, 1616.548, 2157.592, 2610.113, 5337.962, 1900.459, 1621.1, 2519.966, 1817.123, 2161.079, 5065.147, 1928.294, 2759.455, 2299.465, 2884.927, 3980.114, 5071.609, 2488.129, 2993.238, 1656.281, 2927.721, 2920.717, 1268.808, 3921.836, 2113.641, 4456.005, 3496.747, 3684.217, 2233.274, 2769.909, 1703.298, 11747.37, 1467.061, 3739.88, 4333.55, 4014.81, 2267.72, 1952.689, 2909.576, 4136.469, 4080.664, 3515.684, 1847.262, 2734.856, 4158.62, 6032.312, 2431.275, 2705.765)

# RUN GLMER, SAVING STD.ERR.
glmer_out <- glmer(yhat ~ Age_adj + I(Age_adj^2) + (1|subjectID))
glmer_stderr <- coef(summary(glmer_out))[,"Std. Error"]

# RUN wGLMER, SAVING STD.ERR.
wglmer_out <- glmer(yhat ~ Age_adj + I(Age_adj^2) + (1|subjectID), weights=1/var_est)
rand_resid_sd <- as.numeric(summary(wglmer_out)@REmat[2,"Std.Dev."])


wglmer_stderr <- coef(summary(wglmer_out))[,"Std. Error"]
wglmer_stderr_adj <- wglmer_stderr/rand_resid_sd

# DISPLAY RESULTS
summary(glmer_out)
summary(wglmer_out)

# COMPARE GLMER SE, wGLMER SE, & wGLMER ADJUSTED SE
glmer_stderr
wglmer_stderr
wglmer_stderr_adj









David J. Paulsen, Ph.D.
Laboratory of Neurocognitive Development
Western Psychiatric Institute and Clinic
University of Pittsburgh Medical Center
Loeffler Building
121 Meyran Avenue
Pittsburgh, PA 15213
412.383.8168


From nathan.rutenbeck at maine.edu  Wed Jan  9 16:26:37 2013
From: nathan.rutenbeck at maine.edu (Nathan Eustis Rutenbeck)
Date: Wed, 9 Jan 2013 10:26:37 -0500
Subject: [R-sig-ME] Fwd: Assigning random effects
In-Reply-To: <001601cded4e$ab0361d0$010a2570$@net>
References: <CAOho3ae9z44ZBv-bi5Z6FPNWLy-L3Q8BK5g-0CAV+sW+Xo=DkQ@mail.gmail.com>
	<CAOho3adOeqk2hd8pvZht6=DFZ5hAHZH0=mEOV2aavpH8FO8Nsg@mail.gmail.com>
	<001601cded4e$ab0361d0$010a2570$@net>
Message-ID: <CAOho3adjF4iatSRPFk5iUGCnXDKcDrOj1BgJnTt5m8Dz5dNHJA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130109/53710d33/attachment.pl>

From seth at swbigelow.net  Wed Jan  9 23:02:08 2013
From: seth at swbigelow.net (Seth W. Bigelow)
Date: Wed, 9 Jan 2013 17:02:08 -0500
Subject: [R-sig-ME] Fwd: Assigning random effects
In-Reply-To: <CAOho3adjF4iatSRPFk5iUGCnXDKcDrOj1BgJnTt5m8Dz5dNHJA@mail.gmail.com>
References: <CAOho3ae9z44ZBv-bi5Z6FPNWLy-L3Q8BK5g-0CAV+sW+Xo=DkQ@mail.gmail.com>	<CAOho3adOeqk2hd8pvZht6=DFZ5hAHZH0=mEOV2aavpH8FO8Nsg@mail.gmail.com>	<001601cded4e$ab0361d0$010a2570$@net>
	<CAOho3adjF4iatSRPFk5iUGCnXDKcDrOj1BgJnTt5m8Dz5dNHJA@mail.gmail.com>
Message-ID: <000901cdeeb4$f9810a80$ec831f80$@net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130109/8952c418/attachment.pl>

From bergh.thijsvanden at gmail.com  Thu Jan 10 15:16:55 2013
From: bergh.thijsvanden at gmail.com (Thijs vanden Bergh)
Date: Thu, 10 Jan 2013 15:16:55 +0100
Subject: [R-sig-ME] mixed effect model with repeated measures in R
Message-ID: <CAJkOg=wQfrFSh5MUcz74BStirdCb2SMGDGQHmizVLThf9N61wg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130110/6feb215c/attachment.pl>

From billy.requena at gmail.com  Thu Jan 10 15:40:08 2013
From: billy.requena at gmail.com (Billy)
Date: Thu, 10 Jan 2013 09:40:08 -0500
Subject: [R-sig-ME] mixed effect model with repeated measures in R
In-Reply-To: <CAJkOg=wQfrFSh5MUcz74BStirdCb2SMGDGQHmizVLThf9N61wg@mail.gmail.com>
References: <CAJkOg=wQfrFSh5MUcz74BStirdCb2SMGDGQHmizVLThf9N61wg@mail.gmail.com>
Message-ID: <CAC7gwMmrBi_uQXh5GKeEWNH4crFhVvp4ULbhumq=jir5aOnk0Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130110/e4edaf45/attachment.pl>

From bergh.thijsvanden at gmail.com  Thu Jan 10 16:12:12 2013
From: bergh.thijsvanden at gmail.com (Thijs vanden Bergh)
Date: Thu, 10 Jan 2013 16:12:12 +0100
Subject: [R-sig-ME] mixed effect model with repeated measures in R
In-Reply-To: <CAC7gwMmrBi_uQXh5GKeEWNH4crFhVvp4ULbhumq=jir5aOnk0Q@mail.gmail.com>
References: <CAJkOg=wQfrFSh5MUcz74BStirdCb2SMGDGQHmizVLThf9N61wg@mail.gmail.com>
	<CAC7gwMmrBi_uQXh5GKeEWNH4crFhVvp4ULbhumq=jir5aOnk0Q@mail.gmail.com>
Message-ID: <CAJkOg=xCGeCgs9xQZemgcL-DnAovDEpgdxAL_JL_kQM183vNCw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130110/2656efcf/attachment.pl>

From nathan.rutenbeck at maine.edu  Thu Jan 10 17:55:18 2013
From: nathan.rutenbeck at maine.edu (Nathan Eustis Rutenbeck)
Date: Thu, 10 Jan 2013 11:55:18 -0500
Subject: [R-sig-ME] Fwd: Assigning random effects
In-Reply-To: <000901cdeeb4$f9810a80$ec831f80$@net>
References: <CAOho3ae9z44ZBv-bi5Z6FPNWLy-L3Q8BK5g-0CAV+sW+Xo=DkQ@mail.gmail.com>
	<CAOho3adOeqk2hd8pvZht6=DFZ5hAHZH0=mEOV2aavpH8FO8Nsg@mail.gmail.com>
	<001601cded4e$ab0361d0$010a2570$@net>
	<CAOho3adjF4iatSRPFk5iUGCnXDKcDrOj1BgJnTt5m8Dz5dNHJA@mail.gmail.com>
	<000901cdeeb4$f9810a80$ec831f80$@net>
Message-ID: <CAOho3aeSP8LAYafrYTXH+VMdiFXmpUSQ-6zmTJ+F5F5jYUPbxA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130110/97c95a8d/attachment.pl>

From laurent_step at yahoo.fr  Thu Jan 10 19:18:22 2013
From: laurent_step at yahoo.fr (laurent stephane)
Date: Thu, 10 Jan 2013 18:18:22 +0000 (GMT)
Subject: [R-sig-ME] profiled deviance components
Message-ID: <1357841902.56655.YahooMailNeo@web171701.mail.ir2.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130110/aa2d1efe/attachment.pl>

From ned.dochtermann at gmail.com  Thu Jan 10 20:51:42 2013
From: ned.dochtermann at gmail.com (Ned Dochtermann)
Date: Thu, 10 Jan 2013 13:51:42 -0600
Subject: [R-sig-ME] mixed effect model with repeated measures in R
In-Reply-To: <mailman.2683.1357841917.4600.r-sig-mixed-models@r-project.org>
References: <mailman.2683.1357841917.4600.r-sig-mixed-models@r-project.org>
Message-ID: <50EF1BCE.6090609@gmail.com>

In regards to degrees of freedom, the difficulty is that there won't 
often be clear (or correct) methods to calculate degrees of freedom. 
While other software packages and libraries may present estimates of 
df's, that doesn't mean they're correct.

If I recall correctly, this article mentions some of the problems with 
df's from mixed-effects models:
Baayen, R. H., D. J. Davidson, and D. M. Bates. 2008. Mixed-effects 
modeling with crossed random effects for subjects and items. Journal of 
Memory and Language 59:390-412.

Having asked about the same sort of issue I've learned that the choice 
the lme4 developers had was to either present what are necessarily 
incorrect estimates of df's or present none. They decided to present none.
For those of us working in fields where df's and p-values are de rigueur 
this can be frustrating but I understand why they made that choice. You 
can, of course, determine what the range of df's would be for yourself 
and work within that. This approach, which is what I'd guess SAS, JMP, 
ASReml, and other tools do.

Good luck.
Ned



On 1/10/2013 12:18 PM, r-sig-mixed-models-request at r-project.org wrote:
 > Message: 3
 > Date: Thu, 10 Jan 2013 16:12:12 +0100
 > From: Thijs vanden Bergh <bergh.thijsvanden at gmail.com>
 > To: Billy <billy.requena at gmail.com>
 > Cc: r-sig-mixed-models at r-project.org
 > Subject: Re: [R-sig-ME] mixed effect model with repeated measures in R
 > Message-ID:
 > <CAJkOg=xCGeCgs9xQZemgcL-DnAovDEpgdxAL_JL_kQM183vNCw at mail.gmail.com>
 > Content-Type: text/plain
 >
 > I did try lmer from lme4 and indeed came to the same coding
 >
 > However, I  abandoned lmer for two reasons:
 > 1) I prefer to be able to present degrees of freedom and
 > 2)  the design i have is a bit more complicated than what i presented 
as it
 > actually is a 3*3 design.
 > Getting pairwise contrasts from LanguageR > pvals.fnc costs a lot of time
 > (the function itself and recoding the contrasts)
 >
 > The bit of code i presented largely exagerates differences in Met among
 > days (I used it to verify how the random effect for Date was working 
out).
 > Generally Met levels decrease slowly through time (they depend 
strongly on
 > the amount of solar radiation and the experiment runs from high summer to
 > autumn) but early in the season there are some bad weather days where
 > levels of Met are much reduced
 > Therefore i wanted to model them using a random effect rather than a 
fixed
 > factor which would assume a linear relationship with the progressing 
of the
 > season.
 >
 > Concerning the normality problem that you bring up: should data not 
just be
 > normally distributed within one day?
 >
 > thanks for all help,
 >
 > Th


-- 
Ned A. Dochtermann
Assistant Professor / Department of Biological Sciences
NORTH DAKOTA STATE UNIVERSITY
p: 701.231.7353 / f: 701.231.7149 / www.ndsu.edu

https://sites.google.com/site/neddochtermann/
ned.dochtermann at ndsu.edu


From curis at pharmacie.univ-paris5.fr  Thu Jan 10 18:32:50 2013
From: curis at pharmacie.univ-paris5.fr (Emmanuel Curis)
Date: Thu, 10 Jan 2013 18:32:50 +0100
Subject: [R-sig-ME] Fwd: Assigning random effects
In-Reply-To: <CAOho3aeSP8LAYafrYTXH+VMdiFXmpUSQ-6zmTJ+F5F5jYUPbxA@mail.gmail.com>
References: <CAOho3ae9z44ZBv-bi5Z6FPNWLy-L3Q8BK5g-0CAV+sW+Xo=DkQ@mail.gmail.com>
	<CAOho3adOeqk2hd8pvZht6=DFZ5hAHZH0=mEOV2aavpH8FO8Nsg@mail.gmail.com>
	<001601cded4e$ab0361d0$010a2570$@net>
	<CAOho3adjF4iatSRPFk5iUGCnXDKcDrOj1BgJnTt5m8Dz5dNHJA@mail.gmail.com>
	<000901cdeeb4$f9810a80$ec831f80$@net>
	<CAOho3aeSP8LAYafrYTXH+VMdiFXmpUSQ-6zmTJ+F5F5jYUPbxA@mail.gmail.com>
Message-ID: <20130110173250.GA6246@info124.pharmacie.univ-paris5.fr>

Hello,

On Thu, Jan 10, 2013 at 11:55:18AM -0500, Nathan Eustis Rutenbeck
wrote:

? I still am left with the question as to whether to alter the random-effects
? structure for each gas-exchange response variable of interest (Anet, WUE,
? etc.), or whether to develop a random-effects structure that is sensible
? based on experimental design and stick to it? In other words, because of
? experimental design, is there potentially an argument for maintaining the
? more complex random effects structure of fm4 above through all my models,
? even though it does not necessarily provide the best fits in a given model?
? Does it even matter if I am mostly concerned with hypothesis testing of
? fixed-effects?

It may be a very (too much?) pragmatic point of view, but why not test
your fixed effects with both models and see if conclusions are the
same (or, for estimates, close enough for your usage)? If so, and if
really only fixed effects are of interest, may be it does not really
matter which one is used --- but I agree that on an understanding
point-of-view, it may be unsatisfactory.

NB: I'm also somehow a beginner in this field, so do not hesitate to
correct this if there are some traps or misconceptions in this idea...

-- 
                                Emmanuel CURIS
                                emmanuel.curis at univ-paris5.fr

Page WWW: http://emmanuel.curis.online.fr/index.html


From chris.brien at iinet.net.au  Fri Jan 11 00:24:54 2013
From: chris.brien at iinet.net.au (chris.brien at iinet.net.au)
Date: Fri, 11 Jan 2013 09:54:54 +1030
Subject: [R-sig-ME] Fwd: Assigning random effects
In-Reply-To: <20130110173250.GA6246@info124.pharmacie.univ-paris5.fr>
Message-ID: <59e9b00d5c4cd3d13c7df13c084191074347fd43@webmail.iinet.net.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130111/f8b4ee08/attachment.pl>

From David-Bard at ouhsc.edu  Fri Jan 11 05:56:29 2013
From: David-Bard at ouhsc.edu (Bard, David E. (HSC))
Date: Thu, 10 Jan 2013 22:56:29 -0600
Subject: [R-sig-ME] confint() and intervals() do not agree for lmList
	objects?
Message-ID: <5F184ACED9D16349BD4CB65C33933F1B77D8518C25@VEYRON.hsc.net.ou.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130110/21e0597f/attachment.pl>

From agimenez at agro.uba.ar  Sat Jan 12 09:28:18 2013
From: agimenez at agro.uba.ar (GIMENEZ ANALIA VERONICA)
Date: Sat, 12 Jan 2013 05:28:18 -0300
Subject: [R-sig-ME] effects package with glmer function
Message-ID: <CAF2oYWqZn6yYVZ1Wr8EyVeQ3cYcbJ_LKfP=0WhR9fa09ZNdyNw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: no disponible
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130112/086c8dcb/attachment.pl>

From steve.taylor at aut.ac.nz  Mon Jan 14 02:16:32 2013
From: steve.taylor at aut.ac.nz (Steve Taylor)
Date: Mon, 14 Jan 2013 01:16:32 +0000
Subject: [R-sig-ME] effects package with glmer function
In-Reply-To: <CAF2oYWqZn6yYVZ1Wr8EyVeQ3cYcbJ_LKfP=0WhR9fa09ZNdyNw@mail.gmail.com>
References: <CAF2oYWqZn6yYVZ1Wr8EyVeQ3cYcbJ_LKfP=0WhR9fa09ZNdyNw@mail.gmail.com>
Message-ID: <CCE952776B6679469977532BD863C39C35673EDE@Lewis.autuni.aut.ac.nz>

Are you using the latest version of R and those packages?  The output of sessionInfo() would be helpful to check that.

When I run glmer() I get an object of class="mer" for which there is an effect method.  It works fine for me.

This might also be enlightening...
> methods(class='mer')
 [1] allEffects.mer* drop1.mer*      effect.mer*     extractAIC.mer* isGLMM.mer*     isLMM.mer*      isNLMM.mer*    
 [8] isREML.mer*     plot.mer        terms.mer*     

   Non-visible functions are asterisked
> methods(class='glmerMod')
no methods were found


cheers,
    Steve


-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of GIMENEZ ANALIA VERONICA
Sent: Saturday, 12 January 2013 9:28p
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] effects package with glmer function

Hi, I?m running a model with glmer function of the lme4 package and I found
that the effect package could help me with the fixed effects graph, but I
get an error message: UseMethod("effect", mod) :  no applicable method for
'effect' applied to an object of class "c('glmerMod', 'merMod')"  I thought
that effect function could work fine with glmer function as it?s a function
from the lme4 package. Maybe I misunderstood something. Is there any other
option to get fixed effects graphs from glmer function? Maybe I should run
my model with another function? I have a nested design with a count
response variable, that?s why I choose glmer for my dataset.

Thanks in advance for your help and I apologise for my poor English
-- 
Lic. Anal?a V. Gim?nez
IFEVA-CONICET
Facultad de Agronom?a.
Av. San Mart?n 4453 C1417DSE
Bs. As. Argentina

	[[alternative HTML version deleted]]


From Adriaan.de.Jong at slu.se  Mon Jan 14 10:04:16 2013
From: Adriaan.de.Jong at slu.se (Adriaan De Jong)
Date: Mon, 14 Jan 2013 09:04:16 +0000
Subject: [R-sig-ME] Analysis of unbalanced design data from a
 before-during-after control-impact study of breeding birds and railway
 construction
Message-ID: <4A3F286665AD3D488D56FDFAC7D8CE430C1E6BF6@exchange2-1>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130114/6791999e/attachment.pl>

From Thierry.ONKELINX at inbo.be  Mon Jan 14 10:30:08 2013
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Mon, 14 Jan 2013 09:30:08 +0000
Subject: [R-sig-ME] Analysis of unbalanced design data from a
 before-during-after control-impact study of breeding birds and railway
 construction
In-Reply-To: <4A3F286665AD3D488D56FDFAC7D8CE430C1E6BF6@exchange2-1>
References: <4A3F286665AD3D488D56FDFAC7D8CE430C1E6BF6@exchange2-1>
Message-ID: <AA818EAD2576BC488B4F623941DA74279479CAFE@inbomail.inbo.be>

Dear Adriaan,

See my inline comments.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

-----Oorspronkelijk bericht-----
Van: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Adriaan De Jong
Verzonden: maandag 14 januari 2013 10:04
Aan: r-sig-mixed-models at r-project.org
CC: nils.bunnefeld at stir.ac.uk
Onderwerp: [R-sig-ME] Analysis of unbalanced design data from a before-during-after control-impact study of breeding birds and railway construction

{snip}

The questions/doubts

?         What are the effects of the transformation from numbers of territories to densities (per site) on the analyses and the conclusions? (the sites vary a lot in size!)

Use a generalised linear mixed model with poisson or negative binomial family on the number of territories and use the log acreage as an offset factor. This is equivalent to modeling the density but takes into account the fact that the number of territories is discrete.

?         Did I choose the right model approach, or are there better ways to do it? (most likely there are, probably in the realm of medical statistics)

I would refrain from (stepwise) model selection. Just construct the models that you need to test your hypotheses. E.g.
M0 <- glmer(resp ~ treatment * year + (year|site), data=bot, family = poisson)
M1 <- glmer(resp~ year + (year|site), data=bot, family = poisson)
anova(M0, M1)

?         Should sites where the species never occurred during the study period be excluded from the model selection process? (non-existing birds cannot be affected)
Yes. Including those sites will a) dampen trends and b) cause numerical problems in glmm models.
Still check for zero inflation after removing the sites.

?         Did I use the right random effect alternatives?
You used a random slope along year per site. Not year nested in site.

?         Should/can I include a treatment-duration trend in the random effect part (time nested within treatment within site)?
You probably lack data to do that. Note that adding only treatment as a random 'slope' requires 6 parameters to be estimated instead of 1 for only the random intercept. Adding both treatment and year as a random slope is problematic as they are collinear.

?         Does the absence of treatment effect in the most parsimonious model mean that there was no significant effect of railway construction? (again: all impact sites were included)
See question two.

?         Is there a multivariate (multi-species) alternative?

Thanks a lot in advance for giving this a thought.
Cheers,

Adriaan ?Adjan? de Jong
Wildlife, Fish, and Environmental Studies Swedish University of Agricultural Sciences

PS. We will continue the studies in 2013-2015 to monitor the possible effects of train traffic. Train traffic started with a limited timetable on parts of the track in autumn 2010, but full scale traffic has only recently begun. After that we will have four treatment classes.




        [[alternative HTML version deleted]]

* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.

From Adriaan.de.Jong at slu.se  Mon Jan 14 13:13:17 2013
From: Adriaan.de.Jong at slu.se (Adriaan De Jong)
Date: Mon, 14 Jan 2013 12:13:17 +0000
Subject: [R-sig-ME] Analysis of unbalanced design data from a
 before-during-after control-impact study of breeding birds and railway
 construction
In-Reply-To: <AA818EAD2576BC488B4F623941DA74279479CAFE@inbomail.inbo.be>
References: <4A3F286665AD3D488D56FDFAC7D8CE430C1E6BF6@exchange2-1>
	<AA818EAD2576BC488B4F623941DA74279479CAFE@inbomail.inbo.be>
Message-ID: <4A3F286665AD3D488D56FDFAC7D8CE430C1E7C75@exchange2-1>

Dear Thierry,
Thanks for your answer. I'll use your suggestions to improve the analyses.
Cheers,
Adjan 

PS. Regarding the quotes: I agree to a large extend, but sorry, I haven't found that perfect world, yet ;)


-----Ursprungligt meddelande-----
Fr?n: ONKELINX, Thierry [mailto:Thierry.ONKELINX at inbo.be] 
Skickat: den 14 januari 2013 10:30
Till: Adriaan De Jong; r-sig-mixed-models at r-project.org
Kopia: nils.bunnefeld at stir.ac.uk
?mne: RE: [R-sig-ME] Analysis of unbalanced design data from a before-during-after control-impact study of breeding birds and railway construction

Dear Adriaan,

See my inline comments.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

-----Oorspronkelijk bericht-----
Van: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Adriaan De Jong
Verzonden: maandag 14 januari 2013 10:04
Aan: r-sig-mixed-models at r-project.org
CC: nils.bunnefeld at stir.ac.uk
Onderwerp: [R-sig-ME] Analysis of unbalanced design data from a before-during-after control-impact study of breeding birds and railway construction

{snip}

The questions/doubts

?         What are the effects of the transformation from numbers of territories to densities (per site) on the analyses and the conclusions? (the sites vary a lot in size!)

Use a generalised linear mixed model with poisson or negative binomial family on the number of territories and use the log acreage as an offset factor. This is equivalent to modeling the density but takes into account the fact that the number of territories is discrete.

?         Did I choose the right model approach, or are there better ways to do it? (most likely there are, probably in the realm of medical statistics)

I would refrain from (stepwise) model selection. Just construct the models that you need to test your hypotheses. E.g.
M0 <- glmer(resp ~ treatment * year + (year|site), data=bot, family = poisson)
M1 <- glmer(resp~ year + (year|site), data=bot, family = poisson) anova(M0, M1)

?         Should sites where the species never occurred during the study period be excluded from the model selection process? (non-existing birds cannot be affected)
Yes. Including those sites will a) dampen trends and b) cause numerical problems in glmm models.
Still check for zero inflation after removing the sites.

?         Did I use the right random effect alternatives?
You used a random slope along year per site. Not year nested in site.

?         Should/can I include a treatment-duration trend in the random effect part (time nested within treatment within site)?
You probably lack data to do that. Note that adding only treatment as a random 'slope' requires 6 parameters to be estimated instead of 1 for only the random intercept. Adding both treatment and year as a random slope is problematic as they are collinear.


?         Does the absence of treatment effect in the most parsimonious model mean that there was no significant effect of railway construction? (again: all impact sites were included)
See question two.

?         Is there a multivariate (multi-species) alternative?

Thanks a lot in advance for giving this a thought.
Cheers,

Adriaan ?Adjan? de Jong
Wildlife, Fish, and Environmental Studies Swedish University of Agricultural Sciences

PS. We will continue the studies in 2013-2015 to monitor the possible effects of train traffic. Train traffic started with a limited timetable on parts of the track in autumn 2010, but full scale traffic has only recently begun. After that we will have four treatment classes.




        [[alternative HTML version deleted]]

* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * * Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.

From bbolker at gmail.com  Mon Jan 14 14:34:25 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 14 Jan 2013 13:34:25 +0000 (UTC)
Subject: [R-sig-ME] effects package with glmer function
References: <CAF2oYWqZn6yYVZ1Wr8EyVeQ3cYcbJ_LKfP=0WhR9fa09ZNdyNw@mail.gmail.com>
	<CCE952776B6679469977532BD863C39C35673EDE@Lewis.autuni.aut.ac.nz>
Message-ID: <loom.20130114T141724-578@post.gmane.org>

Steve Taylor <steve.taylor at ...> writes:

>  Are you using the latest version of R and those packages?  The
> output of sessionInfo() would be helpful to check that.
 
> When I run glmer() I get an object of class="mer" for which there is
>  an effect method.  It works fine for me.
 
> This might also be enlightening...
> > methods(class='mer')

>  [1] allEffects.mer* drop1.mer* effect.mer* extractAIC.mer*
>  isGLMM.mer* isLMM.mer* isNLMM.mer* [8] isREML.mer* plot.mer
>  terms.mer*
 
>    Non-visible functions are asterisked
> > methods(class='glmerMod')
> no methods were found

  It looks as though Analia is using the development version
of lme4, for which the effects package does not (yet) work.


From highstat at highstat.com  Mon Jan 14 16:39:54 2013
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Mon, 14 Jan 2013 11:39:54 -0400
Subject: [R-sig-ME] Course: Introduction to zero inflated models and GLMM
Message-ID: <50F426CA.8020800@highstat.com>

We would like to announce the following statistics course:

Introduction to zero inflated models and GLMM
13 - 16 May 2013. Elche, Spain.


For details, see: http://www.highstat.com/statscourse.htm
Course flyer: http://www.highstat.com/Courses/Flyer2013_05Elche_ZIP.pdf



Kind regards,

Alain Zuur

-- 

Dr. Alain F. Zuur
First author of:

1. Analysing Ecological Data (2007).
Zuur, AF, Ieno, EN and Smith, GM. Springer. 680 p.
URL: www.springer.com/0-387-45967-7


2. Mixed effects models and extensions in ecology with R. (2009).
Zuur, AF, Ieno, EN, Walker, N, Saveliev, AA, and Smith, GM. Springer.
http://www.springer.com/life+sci/ecology/book/978-0-387-87457-9


3. A Beginner's Guide to R (2009).
Zuur, AF, Ieno, EN, Meesters, EHWG. Springer
http://www.springer.com/statistics/computational/book/978-0-387-93836-3


4. Zero Inflated Models and Generalized Linear Mixed Models with R. (2012) Zuur, Saveliev, Ieno.
http://www.highstat.com/book4.htm

Other books: http://www.highstat.com/books.htm


Statistical consultancy, courses, data analysis and software
Highland Statistics Ltd.
6 Laverock road
UK - AB41 6FN Newburgh
Tel: 0044 1358 788177
Email: highstat at highstat.com
URL: www.highstat.com
URL: www.brodgar.com


From d.afshartous at vanderbilt.edu  Mon Jan 14 21:11:05 2013
From: d.afshartous at vanderbilt.edu (Afshartous, David)
Date: Mon, 14 Jan 2013 20:11:05 +0000
Subject: [R-sig-ME] nlme, self-start, IV bolus
Message-ID: <E7DFC74ED2DEAD47AFD38124459241CB1C79C9BE@ITS-HCWNEM108.ds.vanderbilt.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130114/51d5c1b6/attachment.pl>

From 10517197 at student.uwa.edu.au  Mon Jan 14 08:11:54 2013
From: 10517197 at student.uwa.edu.au (Belinda Burns)
Date: Mon, 14 Jan 2013 15:11:54 +0800
Subject: [R-sig-ME] combining varIdent variance function with mixed effects
	model
Message-ID: <CAAOSGQ7m1pX4spx+OiZz-RaUB+mOMi+jkNCgYtGw7D_Jcj8Rdw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130114/3404a49c/attachment.pl>

From smartpink111 at yahoo.com  Thu Jan 17 03:04:50 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 16 Jan 2013 18:04:50 -0800 (PST)
Subject: [R-sig-ME] [R] random effects model
In-Reply-To: <CAPgEEyhP6Biv8DKo=2A7eijpmHWump98M53EP0p9Z=hPwUhBTg@mail.gmail.com>
References: <1357967501.19341.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<CAPgEEyhT6vh9eTGFxW-auX0zaEDZKNGp_GK4b-sC8LNMYH_9vA@mail.gmail.com>
	<1358011717.24665.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<CAPgEEygW8zwJWgLeFKgRd+xr14e=Ve5s6c4xqNj0ApLjofB7FQ@mail.gmail.com>
	<1358032677.13900.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<1358102023.72326.YahooMailNeo@web142605.mail.bf1.yahoo.com>
	<CAPgEEygcKk+62u+mAzWcSfeEs8zvrcKaJFuR_YhXkR+EvaQW7A@mail.gmail.com>
	<1358204050.70607.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<CAPgEEyim2+QLRLWAF23JH9nDO6CxbhcOmUcemGpBdrMgGMkR4g@mail.gmail.com>
	<1358256129.41250.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<CAPgEEyhP6Biv8DKo=2A7eijpmHWump98M53EP0p9Z=hPwUhBTg@mail.gmail.com>
Message-ID: <1358388290.884.YahooMailNeo@web142606.mail.bf1.yahoo.com>

HI,

In the same link at the bottom of the page,

"

All is well now after updating all packages with the following:
update.packages()"

It may or may not solve your problem.

I got your attachments.  You should post those questions in (r-sig-mixed-models at r-project.org).  I suggest you to read lme4 book (http://lme4.r-forge.r-project.org/lMMwR/)
#lrgprt.pdf

A.K.







----- Original Message -----
From: rex2013 <usha.nathan at gmail.com>
To: r-help at r-project.org
Cc: 
Sent: Wednesday, January 16, 2013 5:06 AM
Subject: Re: [R] random effects model

Hi

I tried removing the missing values and installing "plyr". Still error
message appears with ggplot2

Btw, did you get the attachments with my earlier mail?

Ta.

On Wed, Jan 16, 2013 at 3:16 AM, arun kirshna [via R] <
ml-node+s789695n4655612h99 at n4.nabble.com> wrote:

>
>
> Hi,
> Check these links:
> http://comments.gmane.org/gmane.comp.lang.r.ggplot2/6527
> https://groups.google.com/forum/#!msg/ggplot2/nfVjxL0DXnY/5zf50zCeZuMJ
> A.K.
>
> ________________________________
> From: Usha Gurunathan <[hidden email]<http://user/SendEmail.jtp?type=node&node=4655612&i=0>>
>
> To: arun <[hidden email]<http://user/SendEmail.jtp?type=node&node=4655612&i=1>>
>
> Cc: R help <[hidden email]<http://user/SendEmail.jtp?type=node&node=4655612&i=2>>
>
> Sent: Tuesday, January 15, 2013 6:31 AM
> Subject: Re: [R] random effects model
>
>
> Hi AK
>
> Got an error message with
> library(ggplot2) >
> ggplot(BP.stack1,aes(x=factor(HiBP),fill=Obese))+geom_bar(position="fill")
> Error in rename(x, .base_to_ggplot, warn_missing = FALSE) :? could not find
> function "revalue" >
> ggplot(BP.stack1,aes(x=factor(HiBP),fill=Overweight))+geom_bar(position="fill")
> Error in rename(x, .base_to_ggplot, warn_missing = FALSE) :? could not find
> function "revalue"
> I got the dot plot, thanks for that.
>
> I have attached some plots, not sure how to interpret, they had unusual
> patterns.Is it because of missing data? I tried removing the missing data
> too. They still appeared the same. Do I need to transform the data?
>
>
> Thanks in advance.
>
>
>
>
>
> On Tue, Jan 15, 2013 at 8:54 AM, arun <[hidden email]<http://user/SendEmail.jtp?type=node&node=4655612&i=3>>
> wrote:
>
> HI,
>
> >
> >
> >BP_2b<-read.csv("BP_2b.csv",sep="\t")
> >BP_2bNM<-na.omit(BP_2b)
> >
> >BP.stack3 <-
> reshape(BP_2bNM,idvar="CODEA",timevar="time",sep="",varying=list(c("Obese14","Obese21"),c("Overweight14","Overweight21"),c("hibp14","hibp21")),v.names=c("Obese","Overweight","HiBP"),times=factor(c(1,2)),direction="long")
>
> >library(car)
> >BP.stack3$Obese<- recode(BP.stack3$Obese,"1='Obese';0='Not Obese'")
> >BP.stack3$Overweight<- recode(BP.stack3$Overweight,"1='Overweight';0='Not
> Overweight'")
> >
> >library(ggplot2)
> >ggplot(BP.stack3,aes(x=factor(HiBP),fill=Obese))+geom_bar(position="fill")
>
> >ggplot(BP.stack3,aes(x=factor(HiBP),fill=Overweight))+geom_bar(position="fill")
>
> >
> >You could try lmer() from lme4.
> >library(lme4)
> >fm1<-lmer(HiBP~time+(1|CODEA), family=binomial,data=BP.stack3) #check
> codes, not sure
> >print(dotplot(ranef(fm1,post=TRUE),
> >? ? ? ? ? ? ? scales = list(x = list(relation = "free")))[[1]])
> >qmt1<- qqmath(ranef(fm1, postVar=TRUE))
> >print(qmt1[[1]])
> >
> >
> >A.K.
> >
> >
> >
> >
> >
> >________________________________
> >From: Usha Gurunathan <[hidden email]<http://user/SendEmail.jtp?type=node&node=4655612&i=4>>
>
> >To: arun <[hidden email]<http://user/SendEmail.jtp?type=node&node=4655612&i=5>>
>
> >Cc: R help <[hidden email]<http://user/SendEmail.jtp?type=node&node=4655612&i=6>>
>
> >Sent: Monday, January 14, 2013 6:32 AM
> >
> >Subject: Re: [R] random effects model
> >
> >
> >Hi AK
> >
> >I have been trying to create some plots. All being categorical variables,
> I am not getting any luck with plots. The few ones that have worked are
> below:
> >
> >barchart(~table(HiBP)|Obese,data=BP.sub3) ## BP.sub3 is the stacked data
> without missing values
> >
> >barchart(~table(HiBP)|Overweight,data=BP.sub3)
> >
> >plot(jitter(hibp14,factor=2)~jitter(Obese14,factor=2),col="gray",cex=0.7,
> data=Copy.of.BP_2)? ## Copy.of.BP_2 is the original wide format
> >
> >## not producing any good plots with mixed models as well.
> >summary(lme.3 <- lme(HiBP~time, data=BP.sub3,random=~1|CODEA,
> na.action=na.omit))
> >anova(lme.3)
> >head(ranef(lme.3))
> >print(plot(ranef(lme.3))) ##
> >
> >Thanks for any help.
> >
> >
> >
> >
> >
> >On Mon, Jan 14, 2013 at 4:33 AM, arun <[hidden email]<http://user/SendEmail.jtp?type=node&node=4655612&i=7>>
> wrote:
> >
> >
> >>
> >>
> >>HI,
> >>
> >>I think I mentioned to you before that when you reshape the
> >>columns excluding the response variable, response variable gets repeated
> >>(in this case hibp14 or hibp21) and creates the error"
> >>
> >>
> >>I run your code, there are obvious problems in the code so I didn't
> reach up to BP.gee
> >>
> >>
> >>BP_2b<-read.csv("BP_2b.csv",sep="\t")
> >>BP.stack3 <-
> reshape(BP_2b,idvar="CODEA",timevar="time",sep="_",varying=list(c("Obese14","Obese21"),c("Overweight14","Overweight21")),v.names=c("Obese","Overweight"),times=factor(c(1,2)),direction="long")
>
> >>
> >>
> >>BP.stack3 <-
> transform(BP.stack3,CODEA=factor(CODEA),Sex=factor(Sex,labels=c("Male","Female")),MaternalAge=factor(MaternalAge,labels=c("39years
> or less","40-49 years","50 years or
> older")),Education=factor(Education,labels=c("Primary/special","Started
> secondary","Completed grade10", "Completed grade12",
> "College","University")),Birthplace=factor(Birthplace,labels=c("Australia","Other
> English-speaking","Other")))
> >>
> >> BP.stack3$Sex <-
> factor(BP.stack3$Sex,levels=levels(BP.stack3$Sex)[c(2,1)])
> >>
> >> BP.sub3a <-? subset(BP.stack3,subset=!(is.na(Sex)| is.na(Education)|
> is.na(Birthplace)|is.na(Education)|is.na(hibp14)| is.na(hibp21)))
> >> nrow(BP.sub3a)
> >>#[1] 3364
> >> BP.sub5a <- BP.sub3a[order(BP.sub3a$CODEA),] # your code was BP.sub5a
> <- BP.sub3a[order(BP.sub5a$CODEA),]
> >>
> ^^^^^ was not defined before
> >>#Next line
> >>BPsub3$Categ[BPsub6$Overweight==1&BPsub3$time==1&BPsub3$Obese==0]<-
> "Overweight14"? #It should be BP.sub3 and what is BPsub6, it was not
> defined previously.
> >>#Error in BPsub3$Categ[BPsub6$Overweight == 1 & BPsub3$time == 1 &
> BPsub3$Obese ==? :
> >>? #object 'BPsub3' not found
> >>
> >>
> >>
> >>
> >>
> >>
> >>
> >>A.K.
> >>
> >>
> >>________________________________
> >>From: Usha Gurunathan <[hidden email]<http://user/SendEmail.jtp?type=node&node=4655612&i=8>>
>
> >>To: arun <[hidden email]<http://user/SendEmail.jtp?type=node&node=4655612&i=9>>
>
> >>
> >>Sent: Sunday, January 13, 2013 1:51 AM
> >>
> >>Subject: Re: [R] random effects model
> >>
> >>
> >>
> >>HI AK
> >>
> >>Thanks a lot? for explaining that.
> >>
> >>1. With the chi sq. ( in order to find out if the diffce is significant
> between groups) do I have create a separate excel file and make a
> dataframe.How do I go about it?
> >>
> >>I have resent a mail to Jun Yan at a difft email ad( first add.didn't
> work, mail not delivered).
> >>
> >>2. With my previous query ( reg. Obese/Overweight/ Normal at age 14 Vs
> change of blood pressure status at 21), even though I had compromised
> without the age-specific regression, but I am still keen to explore why the
> age-specific regression didn't work despite it looking okay. I have given
> below the syntax. If you get time, could you kindly look at it and see if
> it could work by any chance? Apologies for persisting with this query.
> >>
> >>
> >>BP.stack3 <-
> >>reshape(Copy.of.BP_2,idvar="CODEA",timevar="time",sep="_",varying=list(c("Obese14","Obese21"),c("Overweight14","Overweight21")),v.names=c("Obese","Overweight"),times=factor(c(1,2)),direction="long
>
> >>BP.stack3
> >>head(BP.stack3)
> >>tail(BP.stack3)
> >>
> >> names(BP.stack3)[c(2,3,4,5,6,7)] <-
> >>c("Sex","MaternalAge","Education","Birthplace","AggScore","IntScore")
> >>
> >>BP.stack3 <-
> >>transform(BP.stack3,CODEA=factor(CODEA),Sex=factor(Sex,labels=c("Male","Female")),MaternalAge=factor(MaternalAge,labels=c("39years
>
> >>or less","40-49 years","50 years or
> >>older")),Education=factor(Education,labels=c("Primary/special","Started
> >>secondary","Completed grade10", "Completed grade12",
> >>"College","University")),Birthplace=factor(Birthplace,labels=c("Australia","Other
>
> >>English-speaking","Other")))
> >>
> >>table(BP.stack3$Sex)
> >>BP.stack3$Sex <-
> >>factor(BP.stack3$Sex,levels=levels(BP.stack3$Sex)[c(2,1)])
> >>
> >>levels(BP.stack3$Sex)
> >>BP.sub3a <-? subset(BP.stack3,subset=!(is.na(Sex)| is.na(Education)|
> is.na(Birthplace)|is.na(Education)|is.na(hibp14)| is.na(hibp21)))
> >>summary(BP.sub3a)
> >>BP.sub5a <- BP.sub3a[order(BP.sub5a$CODEA),]
> >> BPsub3$Categ[BPsub6$Overweight==1&BPsub3$time==1&BPsub3$Obese==0]
> >><- "Overweight14"
> >>BPsub3$Categ[BPsub6$Overweight==1&BPsub3$time==2&BPsub3$Obese==0]
> >><- "Overweight21"
> >>BPsub3$Categ[BPsub3$Obese==1&BPsub3$time==1&BPsub3$Overweight==0|BPsub3$Obese==1&BPsub3$time==1&BPsub3$Overweight==1
>
> >>] <- "Obese14"
> >>BPsub3$Categ[BPsub3$Obese==0&BPsub3$time==1&BPsub3
> BPsub3$Categ[BPsub6$Overweight==1&BPsub3$time==1&BPsub3$Obese==0]
> >><- "Overweight14"$Overweight==0]
> >>
> >><- "Normal14"
> >>BPsub3$Categ[BPsub3$Obese==0&BPsub3$time==2&BPsub3$Overweight==0]
> >><- "Normal21"
> >>BPsub3$Categ[BPsub3$Obese==1&BPsub3$time==2&BPsub3$Overweight==0|BPsub3$Obese==1&BPsub3$time==2&BPsub3$Overweight==1]
>
> >><- "Obese21"
> >>
> >>
> >>
> >>BPsub3$Categ <- factor(BPsub3$Categ)
> >>BPsub3$time <- factor(BPsub3$time)
> >>summary(BPsub3$Categ)
> >>BPsub7 <- subset(BPsub6,subset=!(is.na(Categ)))
> >>BPsub7$time <-
> >>recode(BPsub7$time,"1=14;2=21")
> >>BPsub7$hibp14 <- factor(BPsub7$hibp14)
> >>levels(BPsub7$hibp14)
> >>levels(BPsub7$Categ)
> >>names(BPsub7)
> >>head(BPsub7)? ? ### this was looking quite okay.
> >>
> >>tail(BPsub7)
> >>str(BPsub7)
> >>
> >>library(gee)
> >>
> >>BP.gee <- geese(hibp14~ time*Categ,
> >>data=BPsub7,id=CODEA,family=binomial,
> >>corstr="exchangeable",na.action=na.omit)
> >>
> >>Thanks again.
> >>
> >>
> >>
> >>On Sun, Jan 13, 2013 at 1:22 PM, arun <[hidden email]<http://user/SendEmail.jtp?type=node&node=4655612&i=10>>
> wrote:
> >>
> >>HI,
> >>>
> >>>table(BP_2b$Sex) #original dataset
> >>>#?  1? ? 2
> >>>#3232 3028
> >>> nrow(BP_2b)
> >>>#[1] 6898
> >>> nrow(BP_2bSexNoMV)
> >>>#[1] 6260
> >>> 6898-6260
> >>>#[1] 638 #these rows were removed from the BP_2b to create BP_2bSexNoMV
> >>>BP_2bSexMale<-BP_2bSexNoMV[BP_2bSexNoMV$Sex=="Male",]
> >>> nrow(BP_2bSexMale)
> >>>#[1] 3232
> >>> nrow(BP_2bSexMale[!complete.cases(BP_2bSexMale),]) #Missing rows with
> Male
> >>>#[1] 2407
> >>> nrow(BP_2bSexMale[complete.cases(BP_2bSexMale),]) #Non missing rows
> with Male
> >>>#[1] 825
> >>>
> >>>
> >>>You did the chisquare test on the new dataset with 6260 rows, right.
> >>>I removed those 638 rows because these doesn't belong to either male or
> female, but you want the % of missing value per male or female.? So, I
> thought this will bias the results.? If you want to include the missing
> values, you could do it, but I don't know where you would put that missing
> values as it cannot be classified as belonging specifically to males or
> females.? I hope you understand it.
> >>>
> >>>Sometimes, the maintainer's respond a bit slow.? You have to sent an
> email reminding him again.
> >>>
> >>>Regarding the vmv package, you could email Waqas Ahmed Malik ([hidden
> email] <http://user/SendEmail.jtp?type=node&node=4655612&i=11>) regarding
> options for changing the title and the the font etc.
> >>>You could also use this link (
> http://www.r-bloggers.com/visualizing-missing-data-2/ ) to plot missing
> value (?plot.missing()).? I never used that package, but you could try.
> Looks like it gives more information.
> >>>
> >>>A.K.
> >>>
> >>>
> >>>
> >>>
> >>>
> >>>
> >>>
> >>>
> >>>________________________________
> >>>From: Usha Gurunathan <[hidden email]<http://user/SendEmail.jtp?type=node&node=4655612&i=12>>
>
> >>>To: arun <[hidden email]<http://user/SendEmail.jtp?type=node&node=4655612&i=13>>
>
> >>>Sent: Saturday, January 12, 2013 9:05 PM
> >>>
> >>>Subject: Re: [R] random effects model
> >>>
> >>>
> >>>Hi A.K
> >>>
> >>>So it is number of females missing/total female participants enrolled:
> 72.65%
> >>>Number of females missing/total (of males+ females)? participants
> enrolled : 35.14%
> >>>
> >>>The total no. with the master data: Males: 3232, females: 3028 ( I got
> this before removing any missing values)
> >>>
> >>>with table(Copy.of.BP_2$ Sex)? ## BP
> >>>
> >>>
> >>>If I were to write a table (? and do a chi sq. later),
> >>>
> >>>as Gender? ? ? ? ? ? Study? ? ? ? ? ? ? ? ? ? Non study/missing
> Total
> >>>? ? ? Male? ? ? ? ? ? ? 825 (25.53%)? ? ? ? ? ?  2407 (74.47%)
> 3232 (100%)
> >>>? ? Female? ? ? ? ?  828 (27.35%)? ? ? ? ? ?  2200 (72.65%)? ? ?  3028
> ( 100%)
> >>>? ?  Total? ? ? ? ? ? ? 1653? ? ? ? ? ? ? ? ? ? ? ? ? 4607
>? ? ? ? ? 6260
> >>>
> >>>
> >>>The problem is when I did
> >>>>colSums(is.na(Copy.of.BP_2), the sex category showed N=638.
> >>>
> >>>I cannot understand the discrepancy.Also, when you have mentioned to
> remove NA, is that not a missing value that needs to be included in the
> total number missing. I am a bit confused. Can you help?
> >>>
> >>>## I tried sending email to gee pack maintainer at the ID with R site,
> mail didn't go through??
> >>>
> >>>Many thanks
> >>>
> >>>
> >>>
> >>>
> >>>
> >>>
> >>>On Sun, Jan 13, 2013 at 9:17 AM, arun <[hidden email]<http://user/SendEmail.jtp?type=node&node=4655612&i=14>>
> wrote:
> >>>
> >>>Hi,
> >>>>Yes, you are right.? 72.655222% was those missing among females.
>? 35.14377% of values in females are missing from among the whole dataset
> (combined total of Males+Females data after removing the NAs from the
> variable "Sex").
> >>>>
> >>>>A.K.
> >>>>
> >>>>
> >>>>
> >>>>________________________________
> >>>>From: Usha Gurunathan <[hidden email]<http://user/SendEmail.jtp?type=node&node=4655612&i=15>>
>
> >>>>To: arun <[hidden email]<http://user/SendEmail.jtp?type=node&node=4655612&i=16>>
>
> >>>>Cc: R help <[hidden email]<http://user/SendEmail.jtp?type=node&node=4655612&i=17>>
>
> >>>>Sent: Saturday, January 12, 2013 5:59 PM
> >>>>
> >>>>Subject: Re: [R] random effects model
> >>>>
> >>>>
> >>>>
> >>>>Hi AK
> >>>>That works. I was trying to get? similar results from any other
> package. Being a beginner, I was not sure how to modify the syntax to get
> my output.
> >>>>
> >>>>lapply(split(BP_2bSexNoMV,BP_
> >>>>2bSexNoMV$Sex),function(x)
> (nrow(x[!complete.cases(x[,-2]),])/nrow(x))*100) #gives the percentage of
> rows of missing #values from the overall rows for Males and Females
> >>>>#$Female
> >>>>#[1] 72.65522
> >>>>#
> >>>>#$Male
> >>>>#[1] 74.47401
> >>>>
> >>>>#iF you want the percentage from the total number rows in Males and
> Females (without NA's in the the Sex column)
> >>>> lapply(split(BP_2bSexNoMV,BP_2bSexNoMV$Sex),function(x)
> (nrow(x[!complete.cases(x[,-2]),])/nrow(BP_2bSexNoMV))*100)
> >>>>#$Female
> >>>>#[1] 35.14377
> >>>>#
> >>>>#$Male
> >>>>#[1] 38.45048
> >>>>
> >>>>How do I interpret the above 2 difft results? 72.66% of values were
> missing among female participants?? Can you pl. clarify.
> >>>>
> >>>>Many thanks.
> >>>>
> >>>>
> >>>>On Sun, Jan 13, 2013 at 3:28 AM, arun <[hidden email]<http://user/SendEmail.jtp?type=node&node=4655612&i=18>>
> wrote:
> >>>>
> >>>>lapply(split(BP_2bSexNoMV,BP_2bSexNoMV$Sex),function(x)
> (nrow(x[!complete.cases(x[,-2]),])/nrow(x))*100) #gives the percentage of
> rows of missing #values from the overall rows for Males and Females
> >>>>>#$Female
> >>>>>#[1] 72.65522
> >>>>>#
> >>>>>#$Male
> >>>>>#[1] 74.47401
> >>>>>
> >>>>>#iF you want the percentage from the total number rows in Males and
> Females (without NA's in the the Sex column)
> >>>>> lapply(split(BP_2bSexNoMV,BP_2bSexNoMV$Sex),function(x)
> (nrow(x[!complete.cases(x[,-2]),])/nrow(BP_2bSexNoMV))*100)
> >>>>>#$Female
> >>>>>#[1] 35.14377
> >>>>>#
> >>>>>#$Male
> >>>>>#[1] 38.45048
> >>>>
> >>>
> >>
> >
>
> ______________________________________________
> [hidden email] <http://user/SendEmail.jtp?type=node&node=4655612&i=19>mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
> ------------------------------
>? If you reply to this email, your message will be added to the discussion
> below:
> http://r.789695.n4.nabble.com/random-effects-model-tp4654346p4655612.html
>? To unsubscribe from random effects model, click here<http://r.789695.n4.nabble.com/template/NamlServlet.jtp?macro=unsubscribe_by_code&node=4654346&code=dXNoYS5uYXRoYW5AZ21haWwuY29tfDQ2NTQzNDZ8MjAyMjE1NDI0>
> .
> NAML<http://r.789695.n4.nabble.com/template/NamlServlet.jtp?macro=macro_viewer&id=instant_html%21nabble%3Aemail.naml&base=nabble.naml.namespaces.BasicNamespace-nabble.view.web.template.NabbleNamespace-nabble.view.web.template.NodeNamespace&breadcrumbs=notify_subscribers%21nabble%3Aemail.naml-instant_emails%21nabble%3Aemail.naml-send_instant_email%21nabble%3Aemail.naml>
>




--
View this message in context: http://r.789695.n4.nabble.com/random-effects-model-tp4654346p4655704.html
Sent from the R help mailing list archive at Nabble.com.
??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From agimenez at agro.uba.ar  Thu Jan 17 10:55:04 2013
From: agimenez at agro.uba.ar (GIMENEZ ANALIA VERONICA)
Date: Thu, 17 Jan 2013 06:55:04 -0300
Subject: [R-sig-ME] (sin asunto)
Message-ID: <CAF2oYWqdFDJcEKKCBQp2TSrMZGA2n1KOU5r2BDemPQWKg+ZsmQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: no disponible
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130117/ca7323aa/attachment.pl>

From v_coudrain at voila.fr  Thu Jan 17 11:08:51 2013
From: v_coudrain at voila.fr (v_coudrain at voila.fr)
Date: Thu, 17 Jan 2013 11:08:51 +0100 (CET)
Subject: [R-sig-ME] Offset vs fixed factor in a mixed poisson model
Message-ID: <436652575.252611358417331707.JavaMail.www@wwinf7130>

Dear subscribers, 
I am tested the effect of a factor on a count variable using a poisson mixed model. I know that my response variable is linearly influenced by an other variable so 
that I would like to remove the effect of this second variable to see the true effect of my factor. In an anova, it is usual to enter the covariable first in the model and 
use a sequential test (type I SS). However I am a bit confused how to control for this covariable in my mixed-poisson model. If I just give the covariable as an 
additional fixed variable, my factor is highly significant. If I put it instead as an offset, the factor is not significant at all. I think that it is better to use offset, but I must 
admit that the underlying "theory" is not clear for me. I was also wondering if we can specify multiple offsets and if there was some "rule of thumb" in the maximal 
number that can be included. Thank you very much. 
Best,
Valerie
___________________________________________________________
Envie de changer de frigo ou de gazini?re ? Les soldes ?lectrom?nager sont sur Voila.fr http://shopping.voila.fr/vitrine/electromenager


From bbolker at gmail.com  Thu Jan 17 17:15:57 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 17 Jan 2013 16:15:57 +0000 (UTC)
Subject: [R-sig-ME] Offset vs fixed factor in a mixed poisson model
References: <436652575.252611358417331707.JavaMail.www@wwinf7130>
Message-ID: <loom.20130117T170922-533@post.gmane.org>

 <v_coudrain at ...> writes:


> I am tested the effect of a factor on a count variable using a
> poisson mixed model. I know that my response variable is linearly
> influenced by an other variable so that I would like to remove the
> effect of this second variable to see the true effect of my
> factor. In an anova, it is usual to enter the covariable first in
> the model and use a sequential test (type I SS). However I am a bit
> confused how to control for this covariable in my mixed-poisson
> model. If I just give the covariable as an additional fixed
> variable, my factor is highly significant. If I put it instead as an
> offset, the factor is not significant at all. I think that it is
> better to use offset, but I must admit that the underlying "theory"
> is not clear for me. I was also wondering if we can specify multiple
> offsets and if there was some "rule of thumb" in the maximal number
> that can be included. Thank you very much.  Best, Valerie

  You can specify as many offsets as you want.  The distinction
between an offset and a covariate is that an offset is entered
in the equation *exactly as is*, while a covariate has an estimated
parameter associated with it.  For example,

  y ~ x1 + offset(log(x2))

would fit the model

  y ~ Poisson(lambda=exp(b_1*x1+log(x2))) = 
         Poisson(lambda=x2*exp(b_1*x1))

whereas

  y ~ x1 + log(x2)

would fit the model

  y ~ Poisson(lambda=exp(b_1*x1+b_2*log(x2))) = 
         Poisson(lambda=exp(b_1*x1+b_2*log(x2)) =
            Poisson(lambda=x2^b_2*exp(b_1*x1))

(the log() are not required but are quite common when
specifying offsets, because that's the way to correct
for a scaling that is known to be proportional; using
y ~ x1 + offset(x2) would give lambda=exp(x2)*exp(b_1*x1)
which is not usually what's desired).

In your case, if the estimated parameter b_2 for the covariate
would be nowhere near 1.0, then your offset version is probably
not accounting properly for the effects of the covariate.

  Ben Bolker


From bbolker at gmail.com  Thu Jan 17 17:21:39 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 17 Jan 2013 16:21:39 +0000 (UTC)
Subject: [R-sig-ME]
	=?utf-8?q?combining_varIdent_variance_function_with_mi?=
	=?utf-8?q?xed_effects=09model?=
References: <CAAOSGQ7m1pX4spx+OiZz-RaUB+mOMi+jkNCgYtGw7D_Jcj8Rdw@mail.gmail.com>
Message-ID: <loom.20130117T171623-532@post.gmane.org>

Belinda Burns <10517197 at ...> writes:

> Dear all,
> 
> I hope this is the correct place for my question, if not, my apologies! I
> am analysing several behaviour variables obtained by observing captive
> gibbons. The raw values are in the form proportion of ten minutes spent
> doing the behaviour, and most of the behaviours are zero-inflated and
> negatively skewed.
> 
> At the moment I am interested in modelling the proportion of time that
> adult gibbons spend grooming their mates, such that the models take the
> form:
> 
> Grooms_mate~Age+Species*Sex+Family_composition+Repro_phase*Sex
> 
> where species is a factor with 3 levels, family composition is a binary
> variable (they either have offspring or not) and repro_phase is the
> reproductive phase of the female (4 levels).
 
> Ideally I should be including individual and group as random effects
> (individuals are nested within groups) and so I would like to use a
> mixed model approach; however, diagnostic plots of residuals vs
> fitted values show heteroscedasticity (increasing spread with
> increasing fitted values) and plots of residuals vs predictors
> suggests that one species is less variable than the other two and
> gibbons with offspring are more variable than those without. The
> inclusion of a species*family_composition weighted variance function
> (using the weights= varIdent(form~1|Species*Family_composition) in a
> gls model) seems to improve the homogeneity of the residuals...
 
> I therefore have two questions (among a million others!): Can I
> include the two random effects in gls, or, vice versa, a varIdent
> structure in lmer? (the only contact I know doing mixed modelling in
> R uses lmer with MCMC estimation of p-values and so I am most
> comfortable using that to include the random effects) How do I write
> individual and group in as random effects considering individual is
> nested in group?

lmer does not handle "R-side" effects (heteroscedasticity/varStruct/etc.)
at present.  You should be able to use random=~1|group/individual
in lme to account for individuals nested in groups.  However,
heteroscedasticity is also a common feature of lognormal data: could
you get away with some transformation of the form log(small_number+proportion)
(realizing that picking small_number is a bit of a can of worms)?
Or plogis(small_number+proportion)? (Should be roughly equivalent if
the proportions are typically small.)

  Ben Bolker


From agimenez at agro.uba.ar  Thu Jan 17 18:35:10 2013
From: agimenez at agro.uba.ar (GIMENEZ ANALIA VERONICA)
Date: Thu, 17 Jan 2013 14:35:10 -0300
Subject: [R-sig-ME] Not the correct model?
Message-ID: <CAF2oYWq=ueCdgqja=k=bjNTvoye=k-vS8tB+3SZn-fq6K5fNeA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: no disponible
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130117/1403defe/attachment.pl>

From bbolker at gmail.com  Thu Jan 17 18:34:54 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 17 Jan 2013 17:34:54 +0000 (UTC)
Subject: [R-sig-ME]
	=?utf-8?q?confint=28=29_and_intervals=28=29_do_not_agr?=
	=?utf-8?q?ee_for_lmList=09objects=3F?=
References: <5F184ACED9D16349BD4CB65C33933F1B77D8518C25@VEYRON.hsc.net.ou.edu>
Message-ID: <loom.20130117T172507-280@post.gmane.org>

Bard, David E. (HSC <David-Bard at ...> writes:

>  I've been an lme4 user for a while but recently tried to pick up
> nlme to gain more flexibility and wean myself off of other
> commercial competitors.  As part of the transition, I've enjoyed
> reading through Pinheiro & Bates (2000) and digging out unknown (to
> me) pearls like lmList and nlsList objects.  For better or for
> worse, I've been trying to run P&B models in both lme4 and nlme for
> comparison, and this has led to the quandary below:
 
> When plotting confidence intervals for lmList objects, I've noticed
> a transition among lme4 users from the older nlme intervals function
> to the newer lme4 confint method.  Peculiarly, these two do not play
> nice with each other, and I'm having difficulty understanding why.
> Here is an example:
 
> > library(lme4)
> > library(nlme)
> > fm1 <- lme4:::lmList(Reaction ~ Days | Subject, sleepstudy)

> > ci1 <- confint(fm1,pool=T) #get low and high CI estimates and pooled sd
> > ci2 <- nlme:::intervals(fm1,pool=T) 
##get low and high CI estimates, coef estimates and pooled sd

> > all.equal(unname(ci2[,c(1,3),1]),unname(ci1[,,1])) #compare intercept CIs
> [1] "Mean relative difference: 0.06869956"
> > all.equal(unname(ci2[,c(1,3),2]),unname(ci1[,,2])) #compare slope CIs
> [1] "Mean relative difference: 0.2868216"

> Even more strange, the boundaries from confint do not always
>  encapsulate the actual lmList estimate.

> Perhaps I'm misunderstanding the pool option of confint?
> 
> > apply(merge(ci1[,,1],ci2[,2,1],by=0),1,
> function(x) x[4] > x[2] && x[4] < x[3]) #intercept within
> confint bounds?
>  [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
> [13] FALSE FALSE FALSE FALSE FALSE FALSE
> > apply(merge(ci1[,,2],ci2[,2,2],by=0),1,
>  function(x) x[4] > x[2] && x[4] < x[3]) #slope within
> confint bounds?
> [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
> [13] FALSE FALSE FALSE FALSE FALSE FALSE
> 

 Thank you for the careful examples, and my apologies for this
short reply.  I believe confint completely *ignores* the pool argument
at this point.  I'm kind of surprised that `intervals` works at
all on `lmList` ... in general mixing nlme and lme4 has unpredictable
(=dangerous) results.  I will have a deeper look at this shortly/when
I get a chance: I've added it to the issues list on github:

https://github.com/lme4/lme4/issues/26

thanks
   Ben Bolker


From seth at swbigelow.net  Thu Jan 17 19:30:38 2013
From: seth at swbigelow.net (Seth W. Bigelow)
Date: Thu, 17 Jan 2013 13:30:38 -0500
Subject: [R-sig-ME] Not the correct model?
In-Reply-To: <CAF2oYWq=ueCdgqja=k=bjNTvoye=k-vS8tB+3SZn-fq6K5fNeA@mail.gmail.com>
References: <CAF2oYWq=ueCdgqja=k=bjNTvoye=k-vS8tB+3SZn-fq6K5fNeA@mail.gmail.com>
Message-ID: <000901cdf4e0$c1b8fc70$452af550$@net>

A couple of questions:

Are you sure that Substrate should be modeled as a random factor? It seems
that you used 12 substrates (citric acid, etc) as some kind of standard
protocol for testing respiration, rather than selecting the 12 substrates
from among a population  of possible substrates.

Are you sure that Pesticides should be nested within block? Have you tried a
simpler model, in which Pesticides are not nested within Block but are only
treated as fixed effects, and then used the usual model adequacy checking
methods (examination of residuals, etc) to determine whether nesting is
warranted? 

--Seth


-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org
[mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of GIMENEZ
ANALIA VERONICA
Sent: Thursday, January 17, 2013 12:35 PM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] Not the correct model?

anyone who can help me with this?
I have one fixed (PESTICIDES) factor nested in (5) block factor and one
random factor (SUBSTRATES) nested in the fixed factor. I think it4s the
correct model. (Four pesticides (including control) were randomly assign
into the five blocks and then a soil sample were taken and treated with 12
substrates to evaluate respiration rate).
Firs, I fit my model with lme() function like this
> lme09<-lme (RESPIRACION~PESTICIDA, random=~1| BLOQUE/PESTICIDA, 
> weights =
varIdent(form = ~1|SUSTRATO), data=RESP09, na.action=na.omit,
control=lmeControl(maxIter=200, msMaxIter=200, niterEM=100))
> summary(lme09)
Linear mixed-effects model fit by REML
 Data: RESP09
       AIC      BIC    logLik
  111.7775 166.4314 -38.88874

Random effects:
 Formula: ~1 | BLOQUE
         (Intercept)
StdDev: 3.086521e-08

 Formula: ~1 | PESTICIDA %in% BLOQUE
        (Intercept)     Residual
StdDev:   0.1366234 7.911512e-07

Variance function:
 Structure: Different standard deviations per stratum
 Formula: ~1 | SUSTRATO
 Parameter estimates:
AC CITRICO    AC GLUT  AC MALICO    AC OXAL     ASPARR    FENILAL
 GLUCOSA  HISTIDINA
       1.0   704328.3   675541.5   186809.3   380757.2   410564.8
370571.6   441234.7
    MANOSA     LISINA   ARGININA
  338306.9   257493.9   330352.4
Fixed effects: RESPIRACION ~ PESTICIDA
                     Value  Std.Error  DF   t-value p-value
(Intercept)     0.13914000 0.06109982 168  2.277257  0.0240
PESTICIDACIP    0.02539722 0.08762818  12  0.289829  0.7769
PESTICIDAGLIF  -0.14447975 0.09004731  12 -1.604487  0.1346 PESTICIDASEC 1
-0.29229772 0.08990939  12 -3.251026  0.0069
 Correlation:
               (Intr) PESTICIDAC PESTICIDAG
PESTICIDACIP   -0.697
PESTICIDAGLIF  -0.679  0.473
PESTICIDASEC 1 -0.680  0.474      0.461

Standardized Within-Group Residuals:
          Min            Q1           Med            Q3           Max
-1.983260e+00 -5.103333e-01  1.970778e-06  7.050516e-01  2.783527e+00

Number of Observations: 188
Number of Groups:
               BLOQUE PESTICIDA %in% BLOQUE
                    5                    20

When I tried to make a barchart with the mean and standard errors of the
fixed effects (I used the model without the intercept) I realized that these
ES are not the correct ones because I had a non-significant p-value and the
ES didn4t reflect that. Then I tried to get the confidence intervals of the
fixed effects mean and I got these error message:

> intervals (lme09)

Error in intervals.lme(lme09) :

  cannot get confidence intervals on var-cov components: Non-positive
definite approximate variance-covariance

I googled what this error means and I found that these message could be an
advise that the model may be wrong. At this point, I don4t know how to fit
my model correctly.

Then I tried to fit the model with lmer() function but I don4t know if the
syntax is the correct one and when I run the lmer model i get a warning
message

> lmer093<-lmer (RESPIRACION~PESTICIDA+(0+SUSTRATO|BLOQUE/PESTICIDA),
data=RESP09, na.action=na.omit)

Warning message:

In mer_finalize(ans) : iteration limit reached without convergence (9)

I think this is the same message as before with the lme model and so, my
model is wrong.

So, I couldn4t get the confidence intervals to make a barchart and now I 4m
in doubt with the model.

I4m doing something wrong. I tried other models but the degrees of freedoms
were pseudoreplicated.

Thanks

--
Lic. Analma V. Giminez
IFEVA-CONICET
Facultad de Agronomma.
Av. San Martmn 4453 C1417DSE
Bs. As. Argentina

	[[alternative HTML version deleted]]


From v_coudrain at voila.fr  Thu Jan 17 19:31:26 2013
From: v_coudrain at voila.fr (v_coudrain at voila.fr)
Date: Thu, 17 Jan 2013 19:31:26 +0100 (CET)
Subject: [R-sig-ME] Offset vs fixed factor in a mixed poisson model
Message-ID: <633924035.76241358447486825.JavaMail.www@wwinf7130>

Thank you for the explanation. Si I should estimate the parameter for my covariable. Is it correct to run the model with only the log-transformed parameter as an 
explanatory variable and look at the estimate? I come to an estimated parameter of 0.8, which is quite close to 1. Is there any threshold, under which it is not 
recommanded to use the variable as an offset? How can I control for my covariable if not as an offset since mixed-models are not performing sequential tests 
(right?), such as in an anova?
Best,
Valerie
___________________________________________________________
Envie de changer de frigo ou de gazini?re ? Les soldes ?lectrom?nager sont sur Voila.fr http://shopping.voila.fr/vitrine/electromenager


From highstat at highstat.com  Thu Jan 17 19:50:22 2013
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Thu, 17 Jan 2013 14:50:22 -0400
Subject: [R-sig-ME] Offset vs fixed factor in a mixed poisson model
In-Reply-To: <mailman.3.1358420402.19168.r-sig-mixed-models@r-project.org>
References: <mailman.3.1358420402.19168.r-sig-mixed-models@r-project.org>
Message-ID: <50F847EE.7060901@highstat.com>

On 17/01/2013 07:00, r-sig-mixed-models-request at r-project.org wrote:
> Send R-sig-mixed-models mailing list submissions to
> 	r-sig-mixed-models at r-project.org
>
> To subscribe or unsubscribe via the World Wide Web, visit
> 	https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> or, via email, send a message with subject or body 'help' to
> 	r-sig-mixed-models-request at r-project.org
>
> You can reach the person managing the list at
> 	r-sig-mixed-models-owner at r-project.org
>
> When replying, please edit your Subject line so it is more specific
> than "Re: Contents of R-sig-mixed-models digest..."
>
>
> Today's Topics:
>
>     1. Offset vs fixed factor in a mixed poisson model
>        (v_coudrain at voila.fr)
>
>
> ----------------------------------------------------------------------
>
> Message: 1
> Date: Thu, 17 Jan 2013 11:08:51 +0100 (CET)
> From: v_coudrain at voila.fr
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] Offset vs fixed factor in a mixed poisson model
> Message-ID: <436652575.252611358417331707.JavaMail.www at wwinf7130>
> Content-Type: text/plain; charset=UTF-8
>
> Dear subscribers,

Valerie,
>   
> I am tested the effect of a factor on a count variable using a poisson mixed model. I know that my response variable is linearly influenced by an other variable so
Keep in mind that you are using an exponential relationship in a 
GLM...at least if you use the log link.
> that I would like to remove the effect of this second variable to see the true effect of my factor. In an anova, it is usual to enter the covariable first in the model and
> use a sequential test (type I SS). However I am a bit confused how to control for this covariable in my mixed-poisson model. If I just give the covariable as an
> additional fixed variable, my factor is highly significant. If I put it instead as an offset, the factor is not significant at all. I think that it is better to use offset, but I must

If you use a covariate as an offset then you essentially saying: double 
the value of the variable used for the offset, double the numbers 
(strictly speaking: the expected value). Quite often sampling effort is 
used as an offset as it is not really interesting to model a 
cause-effect relationship between sampling effort and your response.

If you have a model with:

glm(y ~ x, family = poisson)
glm(y ~ x + offset(z), family = poisson)

and x is significant in the first model...but not in the second, then 
either the offset explains most variation, or x and the offset are 
highly correlated? Plot x versus z...and plot x versus log(z)...

Alain


> admit that the underlying "theory" is not clear for me. I was also wondering if we can specify multiple offsets and if there was some "rule of thumb" in the maximal
> number that can be included. Thank you very much.
> Best,
> Valerie
> ___________________________________________________________
> Envie de changer de frigo ou de gazini?re ? Les soldes ?lectrom?nager sont sur Voila.fr http://shopping.voila.fr/vitrine/electromenager
>
>
>
> ------------------------------
>
> _______________________________________________
> R-sig-mixed-models mailing list
> R-sig-mixed-models at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
> End of R-sig-mixed-models Digest, Vol 73, Issue 21
> **************************************************
>


-- 

Dr. Alain F. Zuur
First author of:

1. Analysing Ecological Data (2007).
Zuur, AF, Ieno, EN and Smith, GM. Springer. 680 p.
URL: www.springer.com/0-387-45967-7


2. Mixed effects models and extensions in ecology with R. (2009).
Zuur, AF, Ieno, EN, Walker, N, Saveliev, AA, and Smith, GM. Springer.
http://www.springer.com/life+sci/ecology/book/978-0-387-87457-9


3. A Beginner's Guide to R (2009).
Zuur, AF, Ieno, EN, Meesters, EHWG. Springer
http://www.springer.com/statistics/computational/book/978-0-387-93836-3


4. Zero Inflated Models and Generalized Linear Mixed Models with R. (2012) Zuur, Saveliev, Ieno.
http://www.highstat.com/book4.htm

Other books: http://www.highstat.com/books.htm


Statistical consultancy, courses, data analysis and software
Highland Statistics Ltd.
6 Laverock road
UK - AB41 6FN Newburgh
Tel: 0044 1358 788177
Email: highstat at highstat.com
URL: www.highstat.com
URL: www.brodgar.com


From v_coudrain at voila.fr  Fri Jan 18 21:09:50 2013
From: v_coudrain at voila.fr (v_coudrain at voila.fr)
Date: Fri, 18 Jan 2013 21:09:50 +0100 (CET)
Subject: [R-sig-ME] Offset vs fixed factor in a mixed poisson model
Message-ID: <845233790.160811358539790807.JavaMail.www@wwinf7130>

Dear Alain,

Thank you for your reply. I tried to understand what you said, but have some difficulties:

> If you use a covariate as an offset then you essentially saying: double 
> the value of the variable used for the offset, double the numbers 
> (strictly speaking: the expected value). 

What do you mean wirh "double the value"? Does it mean that if the value of the offset double, then the expected value of my response variable should double? 
And if I have offset(logx), then doubling the log of my variable will double the estimate of the response variable?

> Quite often sampling effort is used as an offset as it is not really interesting to model a 
> cause-effect relationship between sampling effort and your response.

Indeed I don't directly have different sampling effort, but I am testing species richness in 3 years in a growing population, such that the abundance of individuals 
strongly increased between the year. The situation is quite similar as if we had increased the sampling effort over the years.

> If you have a model with:
> glm(y ~ x, family = poisson)
> glm(y ~ x + offset(z), family = poisson)

> and x is significant in the first model...but not in the second, then 
> either the offset explains most variation, or x and the offset are 
> highly correlated? Plot x versus z...and plot x versus log(z)...

x and z are indeed quite correlated, but it would be "nice" to see if x still explains some variation in my data independently of z. 

Ben Bolker suggested that the parameter estimate for using a variable as an offset should be about one. What is your opinion on this?

Best,
Val?rie

___________________________________________________________
Envie de changer de frigo ou de gazini?re ? Les soldes ?lectrom?nager sont sur Voila.fr http://shopping.voila.fr/vitrine/electromenager


From highstat at highstat.com  Fri Jan 18 21:29:34 2013
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Fri, 18 Jan 2013 16:29:34 -0400
Subject: [R-sig-ME] Offset vs fixed factor in a mixed poisson model
In-Reply-To: <845233790.160811358539790807.JavaMail.www@wwinf7130>
References: <845233790.160811358539790807.JavaMail.www@wwinf7130>
Message-ID: <50F9B0AE.20300@highstat.com>

On 18/01/2013 16:09, v_coudrain at voila.fr wrote:
> Dear Alain,
>
> Thank you for your reply. I tried to understand what you said, but have some difficulties:
>
>> If you use a covariate as an offset then you essentially saying: double
>> the value of the variable used for the offset, double the numbers
>> (strictly speaking: the expected value).
> What do you mean wirh "double the value"? Does it mean that if the value of the offset double, then the expected value of my response variable should double?
> And if I have offset(logx), then doubling the log of my variable will double the estimate of the response variable?

Valerie,
Yes...indeed that is what the offset is doing. Double the value of the 
x....you assume that the expected value of your response also doubles. 
Just write out the equation for a Poisson and you will see:

Y_i ~ Poisson(mu_i)
E(Y_i) = mu_i
mu_i = exp(alpha + beta * z + 1 * log(x))
         =  x* exp(alpha + beta * z)

Double x....double mu


Keep in mind that when you analyse a ratio you implicitly do the same; 
1/2 = 100/ 200 = 0.5

>> Quite often sampling effort is used as an offset as it is not really interesting to model a
>> cause-effect relationship between sampling effort and your response.
> Indeed I don't directly have different sampling effort, but I am testing species richness in 3 years in a growing population, such that the abundance of individuals
> strongly increased between the year. The situation is quite similar as if we had increased the sampling effort over the years.
>
>> If you have a model with:
>> glm(y ~ x, family = poisson)
>> glm(y ~ x + offset(z), family = poisson)
>> and x is significant in the first model...but not in the second, then
>> either the offset explains most variation, or x and the offset are
>> highly correlated? Plot x versus z...and plot x versus log(z)...
> x and z are indeed quite correlated, but it would be "nice" to see if x still explains some variation in my data independently of z.

'would be nice' and collinearity don't go together very well.

> Ben Bolker suggested that the parameter estimate for using a variable as an offset should be about one. What is your opinion on this?

Ben is a clever cookie....and he is right.

Alain


> Best,
> Val?rie
>
> ___________________________________________________________
> Envie de changer de frigo ou de gazini?re ? Les soldes ?lectrom?nager sont sur Voila.fr http://shopping.voila.fr/vitrine/electromenager
>


-- 

Dr. Alain F. Zuur
First author of:

1. Analysing Ecological Data (2007).
Zuur, AF, Ieno, EN and Smith, GM. Springer. 680 p.
URL: www.springer.com/0-387-45967-7


2. Mixed effects models and extensions in ecology with R. (2009).
Zuur, AF, Ieno, EN, Walker, N, Saveliev, AA, and Smith, GM. Springer.
http://www.springer.com/life+sci/ecology/book/978-0-387-87457-9


3. A Beginner's Guide to R (2009).
Zuur, AF, Ieno, EN, Meesters, EHWG. Springer
http://www.springer.com/statistics/computational/book/978-0-387-93836-3


4. Zero Inflated Models and Generalized Linear Mixed Models with R. (2012) Zuur, Saveliev, Ieno.
http://www.highstat.com/book4.htm

Other books: http://www.highstat.com/books.htm


Statistical consultancy, courses, data analysis and software
Highland Statistics Ltd.
6 Laverock road
UK - AB41 6FN Newburgh
Tel: 0044 1358 788177
Email: highstat at highstat.com
URL: www.highstat.com
URL: www.brodgar.com


From v_coudrain at voila.fr  Fri Jan 18 21:34:44 2013
From: v_coudrain at voila.fr (v_coudrain at voila.fr)
Date: Fri, 18 Jan 2013 21:34:44 +0100 (CET)
Subject: [R-sig-ME] Offset vs fixed factor in a mixed poisson model
In-Reply-To: <50F9B0AE.20300@highstat.com>
Message-ID: <469946777.163781358541284183.JavaMail.www@wwinf7130>

Thank you very much. There is still a "small" problem. If then the estimate of the variable to be set as an offset is not around 1, I should not put it as an offset. 
How do I then can control for its effect? 

Best,
Val?rie


> Message du 18/01/13 ? 21h29
> De : "Highland Statistics Ltd" 
> A : v_coudrain at voila.fr
> Copie ? : r-sig-mixed-models at r-project.org
> Objet : Re: Offset vs fixed factor in a mixed poisson model
> 
> On 18/01/2013 16:09, v_coudrain at voila.fr wrote:
> > Dear Alain,
> >
> > Thank you for your reply. I tried to understand what you said, but have some difficulties:
> >
> >> If you use a covariate as an offset then you essentially saying: double
> >> the value of the variable used for the offset, double the numbers
> >> (strictly speaking: the expected value).
> > What do you mean wirh "double the value"? Does it mean that if the value of the offset double, then the expected value of my response variable should 
double?
> > And if I have offset(logx), then doubling the log of my variable will double the estimate of the response variable?
> 
> Valerie,
> Yes...indeed that is what the offset is doing. Double the value of the 
> x....you assume that the expected value of your response also doubles. 
> Just write out the equation for a Poisson and you will see:
> 
> Y_i ~ Poisson(mu_i)
> E(Y_i) = mu_i
> mu_i = exp(alpha + beta * z + 1 * log(x))
> = x* exp(alpha + beta * z)
> 
> Double x....double mu
> 
> 
> Keep in mind that when you analyse a ratio you implicitly do the same; 
> 1/2 = 100/ 200 = 0.5
> 
> >> Quite often sampling effort is used as an offset as it is not really interesting to model a
> >> cause-effect relationship between sampling effort and your response.
> > Indeed I don't directly have different sampling effort, but I am testing species richness in 3 years in a growing population, such that the abundance of 
individuals
> > strongly increased between the year. The situation is quite similar as if we had increased the sampling effort over the years.
> >
> >> If you have a model with:
> >> glm(y ~ x, family = poisson)
> >> glm(y ~ x + offset(z), family = poisson)
> >> and x is significant in the first model...but not in the second, then
> >> either the offset explains most variation, or x and the offset are
> >> highly correlated? Plot x versus z...and plot x versus log(z)...
> > x and z are indeed quite correlated, but it would be "nice" to see if x still explains some variation in my data independently of z.
> 
> 'would be nice' and collinearity don't go together very well.
> 
> > Ben Bolker suggested that the parameter estimate for using a variable as an offset should be about one. What is your opinion on this?
> 
> Ben is a clever cookie....and he is right.
> 
> Alain
> 
> 
> > Best,
> > Val?rie
> >
> > ___________________________________________________________
> > Envie de changer de frigo ou de gazini?re ? Les soldes ?lectrom?nager sont sur Voila.fr http://shopping.voila.fr/vitrine/electromenager
> >
> 
> 
> -- 
> 
> Dr. Alain F. Zuur
> First author of:
> 
> 1. Analysing Ecological Data (2007).
> Zuur, AF, Ieno, EN and Smith, GM. Springer. 680 p.
> URL: www.springer.com/0-387-45967-7
> 
> 
> 2. Mixed effects models and extensions in ecology with R. (2009).
> Zuur, AF, Ieno, EN, Walker, N, Saveliev, AA, and Smith, GM. Springer.
> http://www.springer.com/life+sci/ecology/book/978-0-387-87457-9
> 
> 
> 3. A Beginner's Guide to R (2009).
> Zuur, AF, Ieno, EN, Meesters, EHWG. Springer
> http://www.springer.com/statistics/computational/book/978-0-387-93836-3
> 
> 
> 4. Zero Inflated Models and Generalized Linear Mixed Models with R. (2012) Zuur, Saveliev, Ieno.
> http://www.highstat.com/book4.htm
> 
> Other books: http://www.highstat.com/books.htm
> 
> 
> Statistical consultancy, courses, data analysis and software
> Highland Statistics Ltd.
> 6 Laverock road
> UK - AB41 6FN Newburgh
> Tel: 0044 1358 788177
> Email: highstat at highstat.com
> URL: www.highstat.com
> URL: www.brodgar.com
> 
> 

___________________________________________________________
Envie de changer de frigo ou de gazini?re ? Les soldes ?lectrom?nager sont sur Voila.fr http://shopping.voila.fr/vitrine/electromenager


From highstat at highstat.com  Fri Jan 18 21:55:15 2013
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Fri, 18 Jan 2013 16:55:15 -0400
Subject: [R-sig-ME] Offset vs fixed factor in a mixed poisson model
In-Reply-To: <469946777.163781358541284183.JavaMail.www@wwinf7130>
References: <469946777.163781358541284183.JavaMail.www@wwinf7130>
Message-ID: <50F9B6B3.3030205@highstat.com>

On 18/01/2013 16:34, v_coudrain at voila.fr wrote:
> Thank you very much. There is still a "small" problem. If then the estimate of the variable to be set as an offset is not around 1, I should not put it as an offset.
> How do I then can control for its effect?
What about:

Y_i ~Poisson(mu_i)
log(mu_i) = alpha + beta_1 * x_i + beta_2 * z_i

That's a model where beta_1 shows the partial effect of x_i.....which 
means...the effect of x_i while taking into account z_i..and vice versa.

But now your collinearity is going to cause some trouble. I am not sure 
whether the partial linear regression equivalent for a Poisson GLMM 
exists.....

Alain


> Best,
> Val?rie
>
>
>> Message du 18/01/13 ? 21h29
>> De : "Highland Statistics Ltd"
>> A : v_coudrain at voila.fr
>> Copie ? : r-sig-mixed-models at r-project.org
>> Objet : Re: Offset vs fixed factor in a mixed poisson model
>>
>> On 18/01/2013 16:09, v_coudrain at voila.fr wrote:
>>> Dear Alain,
>>>
>>> Thank you for your reply. I tried to understand what you said, but have some difficulties:
>>>
>>>> If you use a covariate as an offset then you essentially saying: double
>>>> the value of the variable used for the offset, double the numbers
>>>> (strictly speaking: the expected value).
>>> What do you mean wirh "double the value"? Does it mean that if the value of the offset double, then the expected value of my response variable should
> double?
>>> And if I have offset(logx), then doubling the log of my variable will double the estimate of the response variable?
>> Valerie,
>> Yes...indeed that is what the offset is doing. Double the value of the
>> x....you assume that the expected value of your response also doubles.
>> Just write out the equation for a Poisson and you will see:
>>
>> Y_i ~ Poisson(mu_i)
>> E(Y_i) = mu_i
>> mu_i = exp(alpha + beta * z + 1 * log(x))
>> = x* exp(alpha + beta * z)
>>
>> Double x....double mu
>>
>>
>> Keep in mind that when you analyse a ratio you implicitly do the same;
>> 1/2 = 100/ 200 = 0.5
>>
>>>> Quite often sampling effort is used as an offset as it is not really interesting to model a
>>>> cause-effect relationship between sampling effort and your response.
>>> Indeed I don't directly have different sampling effort, but I am testing species richness in 3 years in a growing population, such that the abundance of
> individuals
>>> strongly increased between the year. The situation is quite similar as if we had increased the sampling effort over the years.
>>>
>>>> If you have a model with:
>>>> glm(y ~ x, family = poisson)
>>>> glm(y ~ x + offset(z), family = poisson)
>>>> and x is significant in the first model...but not in the second, then
>>>> either the offset explains most variation, or x and the offset are
>>>> highly correlated? Plot x versus z...and plot x versus log(z)...
>>> x and z are indeed quite correlated, but it would be "nice" to see if x still explains some variation in my data independently of z.
>> 'would be nice' and collinearity don't go together very well.
>>
>>> Ben Bolker suggested that the parameter estimate for using a variable as an offset should be about one. What is your opinion on this?
>> Ben is a clever cookie....and he is right.
>>
>> Alain
>>
>>
>>> Best,
>>> Val?rie
>>>
>>> ___________________________________________________________
>>> Envie de changer de frigo ou de gazini?re ? Les soldes ?lectrom?nager sont sur Voila.fr http://shopping.voila.fr/vitrine/electromenager
>>>
>>
>> -- 
>>
>> Dr. Alain F. Zuur
>> First author of:
>>
>> 1. Analysing Ecological Data (2007).
>> Zuur, AF, Ieno, EN and Smith, GM. Springer. 680 p.
>> URL: www.springer.com/0-387-45967-7
>>
>>
>> 2. Mixed effects models and extensions in ecology with R. (2009).
>> Zuur, AF, Ieno, EN, Walker, N, Saveliev, AA, and Smith, GM. Springer.
>> http://www.springer.com/life+sci/ecology/book/978-0-387-87457-9
>>
>>
>> 3. A Beginner's Guide to R (2009).
>> Zuur, AF, Ieno, EN, Meesters, EHWG. Springer
>> http://www.springer.com/statistics/computational/book/978-0-387-93836-3
>>
>>
>> 4. Zero Inflated Models and Generalized Linear Mixed Models with R. (2012) Zuur, Saveliev, Ieno.
>> http://www.highstat.com/book4.htm
>>
>> Other books: http://www.highstat.com/books.htm
>>
>>
>> Statistical consultancy, courses, data analysis and software
>> Highland Statistics Ltd.
>> 6 Laverock road
>> UK - AB41 6FN Newburgh
>> Tel: 0044 1358 788177
>> Email: highstat at highstat.com
>> URL: www.highstat.com
>> URL: www.brodgar.com
>>
>>
> ___________________________________________________________
> Envie de changer de frigo ou de gazini?re ? Les soldes ?lectrom?nager sont sur Voila.fr http://shopping.voila.fr/vitrine/electromenager
>


-- 

Dr. Alain F. Zuur
First author of:

1. Analysing Ecological Data (2007).
Zuur, AF, Ieno, EN and Smith, GM. Springer. 680 p.
URL: www.springer.com/0-387-45967-7


2. Mixed effects models and extensions in ecology with R. (2009).
Zuur, AF, Ieno, EN, Walker, N, Saveliev, AA, and Smith, GM. Springer.
http://www.springer.com/life+sci/ecology/book/978-0-387-87457-9


3. A Beginner's Guide to R (2009).
Zuur, AF, Ieno, EN, Meesters, EHWG. Springer
http://www.springer.com/statistics/computational/book/978-0-387-93836-3


4. Zero Inflated Models and Generalized Linear Mixed Models with R. (2012) Zuur, Saveliev, Ieno.
http://www.highstat.com/book4.htm

Other books: http://www.highstat.com/books.htm


Statistical consultancy, courses, data analysis and software
Highland Statistics Ltd.
6 Laverock road
UK - AB41 6FN Newburgh
Tel: 0044 1358 788177
Email: highstat at highstat.com
URL: www.highstat.com
URL: www.brodgar.com


From slu at ccsr.uchicago.edu  Fri Jan 18 22:55:46 2013
From: slu at ccsr.uchicago.edu (Stuart Luppescu)
Date: Fri, 18 Jan 2013 15:55:46 -0600
Subject: [R-sig-ME] Data frame size limits in MCMCglmm?
Message-ID: <1358546146.11821.40.camel@musuko.uchicago.edu>

Hello, I'm having problems running a simple ordinal outcome mixed
effects model, and I'm thinking it may be because of the size of the
dataset (or, it very may well be that I'm not specifying the model
correctly). I must confess to insecurity about how to specify the
priors. Here is the structure of the data frame (with columns not in
this model omitted). Note that there are more than 2.4 million rows. Is
that a problem?

 str(all.subj)
'data.frame':	2438922 obs. of  112 variables:
 $ gr10                  : num  0 0 0 0 0 0 1 0 1 0 ...
 $ gr11                  : num  0 0 0 1 1 1 0 0 0 0 ...
 $ gr12                  : num  1 1 1 0 0 0 0 1 0 0 ...
 $ tid                   : Factor w/ 14982 levels "........","A.D46607",..: 2 2 2 2 2 2 2 2 2 2 ...
 $ final.points          : Ord.factor w/ 5 levels "0"<"1"<"2"<"3"<..: 4 4 4 2 3 3 2 2 3 2 ...

Here are two attempts and their results:

glmm.uncond <- MCMCglmm(final.points ~ gr10 + gr11 + gr12,
                         prior=list(R=list(V=1, fix=1), G=list(G1=list(V=1, nu=0))),
                         random = ~tid ,
                         family = "ordinal",
                         nitt=100000,
                         data = all.subj)

Error: segfault from C stack overflow


 glmm.uncond <- MCMCglmm(final.points ~ gr10 + gr11 + gr12,
                         prior=list(R=list(V=1, nu=0), G=list(G1=list(V=1, nu=0))),
                         random = ~tid ,
                         family = "ordinal",
                         nitt=100000,
                         data = all.subj)


Process R segmentation fault (core dumped) at Fri Jan 18 12:53:49 2013

Here is my sessionInfo
R version 2.15.1 (2012-06-22)
Platform: x86_64-redhat-linux-gnu (64-bit)

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   
 [7] LC_PAPER=C                 LC_NAME=C                 
 [9] LC_ADDRESS=C               LC_TELEPHONE=C            
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] foreign_0.8-52  MCMCglmm_2.17   corpcor_1.6.4   ape_3.0-6      
[5] coda_0.16-1     Matrix_1.0-10   lattice_0.20-13 tensorA_0.36   

loaded via a namespace (and not attached):
[1] compiler_2.15.1 gee_4.13-18     grid_2.15.1     nlme_3.1-107   
[5] tools_2.15.1   

and memory info.

 gc()
            used   (Mb) gc trigger    (Mb)   max used    (Mb)
Ncells   1196029   63.9    1835812    98.1    1710298    91.4
Vcells 678385919 5175.7 1777423119 13560.7 2114537169 16132.7

Any help will be appreciated.


-- 
Stuart Luppescu <slu at ccsr.uchicago.edu>
University of Chicago


From jwiley.psych at gmail.com  Sat Jan 19 05:28:33 2013
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Fri, 18 Jan 2013 20:28:33 -0800
Subject: [R-sig-ME] Data frame size limits in MCMCglmm?
In-Reply-To: <1358546146.11821.40.camel@musuko.uchicago.edu>
References: <1358546146.11821.40.camel@musuko.uchicago.edu>
Message-ID: <CANz9Z_+5BDbVWxUcv8y-bG9YtwB0593eNUREy=UMyBmHUOcivA@mail.gmail.com>

Hi Stuart,

How many (if any) iterations completed before you got the seg fault?
Also, how much memory does your system have?

Currently at 4000 iterations, I have not reproduced the error so far
with this made up example (although I have practically finished an
algorithm to sort any array in O(log log n) while waiting to get this
far ~1 hour per thousand iterations on a 6 core 3.9GHZ machine).

require(MCMCglmm)
require(MASS)
set.seed(10)
rint <- rep(rnorm(14982, 0, 4), each = floor(2.44e6/14982))
ID <- factor(rep(1:14982,  each = floor(2.44e6/14982)))
X <- MASS::mvrnorm(length(rint), mu = c(0, 0, 0),
  Sigma = matrix(c(1, .3, .3, .3, 1, .3, .3, .3, 1), 3))
b <- matrix(c(1.2, -.5, 2))
ycont <- rnorm(length(ID), mean = 2 + rint + X %*% b)
yord <- cut(ycont, breaks = quantile(ycont, c(0, .2, .4, .6, .8, 1)),
  include.lowest=TRUE, ordered_result=TRUE)
testdat <- data.frame(yord, ID, x1 = X[,1], x2 = X[, 2], x3 = X[, 3])
## > gc()
##            used  (Mb) gc trigger  (Mb) max used  (Mb)
## Ncells  1117490  59.7    1710298  91.4  1368491  73.1
## Vcells 25878798 197.5   47836772 365.0 47753473 364.4
m <- MCMCglmm(yord ~ x1 + x2 + x3, random = ~ ID,
  family = "ordinal", data = testdat,
  prior = list(
    R = list(V = 1, fix = 1),
    G = list(
      G1 = list(V = 1, nu = 0))),
  nitt = 13000, thin = 10, burnin = 3000)

on a Win 8 pro x64 system with 32GB of memory and

R version 2.15.2 (2012-10-26)
Platform: x86_64-w64-mingw32/x64 (64-bit)
attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
 [1] MASS_7.3-22        ggplot2_0.9.3      MCMCglmm_2.17
 [4] corpcor_1.6.4      ape_3.0-6          coda_0.16-1        Matrix_1.0-10
 [8] lattice_0.20-10    tensorA_0.36




On Fri, Jan 18, 2013 at 1:55 PM, Stuart Luppescu <slu at ccsr.uchicago.edu> wrote:
> Hello, I'm having problems running a simple ordinal outcome mixed
> effects model, and I'm thinking it may be because of the size of the
> dataset (or, it very may well be that I'm not specifying the model
> correctly). I must confess to insecurity about how to specify the
> priors. Here is the structure of the data frame (with columns not in
> this model omitted). Note that there are more than 2.4 million rows. Is
> that a problem?
>
>  str(all.subj)
> 'data.frame':   2438922 obs. of  112 variables:
>  $ gr10                  : num  0 0 0 0 0 0 1 0 1 0 ...
>  $ gr11                  : num  0 0 0 1 1 1 0 0 0 0 ...
>  $ gr12                  : num  1 1 1 0 0 0 0 1 0 0 ...
>  $ tid                   : Factor w/ 14982 levels "........","A.D46607",..: 2 2 2 2 2 2 2 2 2 2 ...
>  $ final.points          : Ord.factor w/ 5 levels "0"<"1"<"2"<"3"<..: 4 4 4 2 3 3 2 2 3 2 ...
>
> Here are two attempts and their results:
>
> glmm.uncond <- MCMCglmm(final.points ~ gr10 + gr11 + gr12,
>                          prior=list(R=list(V=1, fix=1), G=list(G1=list(V=1, nu=0))),
>                          random = ~tid ,
>                          family = "ordinal",
>                          nitt=100000,
>                          data = all.subj)
>
> Error: segfault from C stack overflow
>
>
>  glmm.uncond <- MCMCglmm(final.points ~ gr10 + gr11 + gr12,
>                          prior=list(R=list(V=1, nu=0), G=list(G1=list(V=1, nu=0))),
>                          random = ~tid ,
>                          family = "ordinal",
>                          nitt=100000,
>                          data = all.subj)
>
>
> Process R segmentation fault (core dumped) at Fri Jan 18 12:53:49 2013
>
> Here is my sessionInfo
> R version 2.15.1 (2012-06-22)
> Platform: x86_64-redhat-linux-gnu (64-bit)
>
> locale:
>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>  [7] LC_PAPER=C                 LC_NAME=C
>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] foreign_0.8-52  MCMCglmm_2.17   corpcor_1.6.4   ape_3.0-6
> [5] coda_0.16-1     Matrix_1.0-10   lattice_0.20-13 tensorA_0.36
>
> loaded via a namespace (and not attached):
> [1] compiler_2.15.1 gee_4.13-18     grid_2.15.1     nlme_3.1-107
> [5] tools_2.15.1
>
> and memory info.
>
>  gc()
>             used   (Mb) gc trigger    (Mb)   max used    (Mb)
> Ncells   1196029   63.9    1835812    98.1    1710298    91.4
> Vcells 678385919 5175.7 1777423119 13560.7 2114537169 16132.7
>
> Any help will be appreciated.
>
>
> --
> Stuart Luppescu <slu at ccsr.uchicago.edu>
> University of Chicago
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



--
Joshua Wiley
Ph.D. Student, Health Psychology
Programmer Analyst II, Statistical Consulting Group
University of California, Los Angeles
https://joshuawiley.com/


From v_coudrain at voila.fr  Sat Jan 19 11:21:48 2013
From: v_coudrain at voila.fr (v_coudrain at voila.fr)
Date: Sat, 19 Jan 2013 11:21:48 +0100 (CET)
Subject: [R-sig-ME] Partialing out the effect of a covariable in a Poisson
	GLMM
Message-ID: <1741932476.209931358590908592.JavaMail.www@wwinf7130>

Dear all,
I recenly asked a question about the use of an offset in a Poisson GLMM and it came out that an ofset would be reasonable if the estimate of the covariable to be put 
as an offset is about 1. However if this estimate is not close to one, does anybody know about a partial linear regression equivalent for a Poisson GLMM? Or what 
are your method to control for the effect of a covariable in a Poisson GLMM?
Best wishes,
Valerie
___________________________________________________________
Envie de changer de frigo ou de gazini?re ? Les soldes ?lectrom?nager sont sur Voila.fr http://shopping.voila.fr/vitrine/electromenager


From maj at waikato.ac.nz  Sat Jan 19 12:07:05 2013
From: maj at waikato.ac.nz (Murray Jorgensen)
Date: Sun, 20 Jan 2013 00:07:05 +1300
Subject: [R-sig-ME] R-sig-mixed-models Digest, Vol 73, Issue 25
In-Reply-To: <mailman.3.1358593202.20462.r-sig-mixed-models@r-project.org>
References: <mailman.3.1358593202.20462.r-sig-mixed-models@r-project.org>
Message-ID: <CAE85cPnv6tPz3akbweF2iSiJ8i6KJYuOhymMOd4NMLwPT_fKYQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130120/1d63fdf9/attachment.pl>

From usha.nathan at gmail.com  Sat Jan 19 02:04:08 2013
From: usha.nathan at gmail.com (Usha Gurunathan)
Date: Sat, 19 Jan 2013 11:04:08 +1000
Subject: [R-sig-ME] Interpretation of the plots
Message-ID: <CAPgEEyiPEL60ZX10H6AfJ795YUP2OadVXExT6F5vzAaAcjtM+w@mail.gmail.com>

Hi anyone,

I am getting these unusual plot patterns with my data using random effects
models. Can you help find the mistake in plots? Do I have to transform the
data?

Thanks for the help in advance..
-------------- next part --------------
A non-text attachment was scrubbed...
Name: QQ plot hibp21 BP.sub4.png
Type: image/png
Size: 1883 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130119/7c06e77a/attachment.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Fitted vs residuals HiBP ~time+Sex+Maternal Age, random intercept.png
Type: image/png
Size: 3470 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130119/7c06e77a/attachment-0001.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: HiBP ~Overweight qq plots residuals,random effects.png
Type: image/png
Size: 3425 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130119/7c06e77a/attachment-0002.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: QQ plot HIBP ~Overweight.png
Type: image/png
Size: 3452 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130119/7c06e77a/attachment-0003.png>

From jbaldwin at fs.fed.us  Sat Jan 19 17:59:44 2013
From: jbaldwin at fs.fed.us (Baldwin, Jim -FS)
Date: Sat, 19 Jan 2013 16:59:44 +0000
Subject: [R-sig-ME] Interpretation of the plots
In-Reply-To: <CAPgEEyiPEL60ZX10H6AfJ795YUP2OadVXExT6F5vzAaAcjtM+w@mail.gmail.com>
References: <CAPgEEyiPEL60ZX10H6AfJ795YUP2OadVXExT6F5vzAaAcjtM+w@mail.gmail.com>
Message-ID: <DDC5EC9B78340042B0D5A0C3789D45691999DCC5@001FSN2MPN1-061.001f.mgd2.msft.net>

Given that it appears that your dependent variable (HiBP) only takes on two values (0 and 1), the appearance of the residual plots is not unexpected.  But you shouldn't expect a binary dependent variable to have residual plots that look like residual plots from normally distributed continuous dependent variables.

Jim Baldwin


-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Usha Gurunathan
Sent: Friday, January 18, 2013 5:04 PM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] Interpretation of the plots

Hi anyone,

I am getting these unusual plot patterns with my data using random effects models. Can you help find the mistake in plots? Do I have to transform the data?

Thanks for the help in advance..




This electronic message contains information generated by the USDA solely for the intended recipients. Any unauthorized interception of this message or the use or disclosure of the information it contains may violate the law and subject the violator to civil or criminal penalties. If you believe you have received this message in error, please notify the sender and delete the email immediately.


From bbolker at gmail.com  Sat Jan 19 22:11:36 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 19 Jan 2013 21:11:36 +0000 (UTC)
Subject: [R-sig-ME]
	=?utf-8?q?Partialing_out_the_effect_of_a_covariable_in?=
	=?utf-8?q?_a_Poisson=09GLMM?=
References: <1741932476.209931358590908592.JavaMail.www@wwinf7130>
Message-ID: <loom.20130119T220937-320@post.gmane.org>

 <v_coudrain at ...> writes:

> 
> Dear all,
> I recenly asked a question about the use of an offset in a Poisson GLMM 
> and it came out that an ofset would be
> reasonable if the estimate of the covariable to be put 
> as an offset is about 1. However if this estimate is not close 
> to one, does anybody know about a partial linear
> regression equivalent for a Poisson GLMM? Or what 
> are your method to control for the effect of a covariable in a Poisson GLMM?

   Don't know exactly what you want to do, but presumably fitting
a "null model" with the covariate and then building more complex models
on top of this -- adding the other covariates -- and doing sequential testing
(anova(full_model,model_with_only_first_covariate)).  The linear models
idea of partialing out one variable and running a model on the residuals
doesn't work as well, unfortunately.

  Ben Bolker


From v_coudrain at voila.fr  Mon Jan 21 08:51:46 2013
From: v_coudrain at voila.fr (v_coudrain at voila.fr)
Date: Mon, 21 Jan 2013 08:51:46 +0100 (CET)
Subject: [R-sig-ME] Partialing out the effect of a covariable in a
	Poisson GLMM
Message-ID: <1542428178.462981358754706436.JavaMail.www@wwinf7130>

Ben Bolker writes: 

>Don't know exactly what you want to do, but presumably fitting
> a "null model" with the covariate and then building more complex models
> on top of this -- adding the other covariates -- and doing sequential testing
> (anova(full_model,model_with_only_first_covariate)). The linear models
> idea of partialing out one variable and running a model on the residuals
> doesn't work as well, unfortunately.

Oh yes, thank you I can do it this way. Sould I turn REML to FALSE for model comparison? 
Best,
Val?rie
___________________________________________________________
Envie de changer de frigo ou de gazini?re ? Les soldes ?lectrom?nager sont sur Voila.fr http://shopping.voila.fr/vitrine/electromenager


From larodwyer at gmail.com  Mon Jan 21 13:28:33 2013
From: larodwyer at gmail.com (Laurence O'Dwyer)
Date: Mon, 21 Jan 2013 13:28:33 +0100
Subject: [R-sig-ME] familial relatedness in MCMCglmm
Message-ID: <CACp2W9CjMGs_q2EoUORsG5G4fn=ib1csn-G6sH7F4SfMVtb9jA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130121/a8af4c36/attachment.pl>

From bbolker at gmail.com  Mon Jan 21 15:16:41 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 21 Jan 2013 09:16:41 -0500
Subject: [R-sig-ME] Partialing out the effect of a covariable in a
	Poisson GLMM
In-Reply-To: <1542428178.462981358754706436.JavaMail.www@wwinf7130>
References: <1542428178.462981358754706436.JavaMail.www@wwinf7130>
Message-ID: <50FD4DC9.2020401@gmail.com>

On 13-01-21 02:51 AM, v_coudrain at voila.fr wrote:
> Ben Bolker writes: 
> 
>> Don't know exactly what you want to do, but presumably fitting
>> a "null model" with the covariate and then building more complex models
>> on top of this -- adding the other covariates -- and doing sequential testing
>> (anova(full_model,model_with_only_first_covariate)). The linear models
>> idea of partialing out one variable and running a model on the residuals
>> doesn't work as well, unfortunately.
> 
> Oh yes, thank you I can do it this way. Sould I turn REML to FALSE for model comparison? 
> Best,
> Val?rie

   REML is *ignored* when running glmer() [or lmer() with a 'family'
argument]; as discussed at http://glmm.wikidot.com/faq , REML is
somewhat poorly defined for GLMMs.  (The development version of lme4 at
least warns that the REML argument is ignored; the CRAN version just
silently ignores it.)

  Ben Bolker


From bbolker at gmail.com  Mon Jan 21 15:24:52 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 21 Jan 2013 09:24:52 -0500
Subject: [R-sig-ME] r-sig mixed models mailing list response
In-Reply-To: <CAAOSGQ417O0fwpGmqGVsnLU=S5W-BL32mmoG-3mNmks_GmCcqg@mail.gmail.com>
References: <CAAOSGQ417O0fwpGmqGVsnLU=S5W-BL32mmoG-3mNmks_GmCcqg@mail.gmail.com>
Message-ID: <50FD4FB4.8040209@gmail.com>

On 13-01-20 10:22 PM, Belinda Burns wrote:
> Dear Ben,
> 

[cc'ing to r-sig-mixed-models]

> Thank you for your response to my question to the mixed models mailing
> list (see below). I wasn't sure if I could just reply directly to the
> mailing list request email so I thought I'd email you directly.
> Your comment on the heteroscedasticity makes some sense to me - however,
> a log transformation (of proportions + 1) does little to improve the
> distribution of the data.

   OK.

> I have thought long and hard about the data
> and they would seem to me best modelled using the negative binomial glmm
> but now I am getting further into realms for which I have very little
> support and I really like to know what I'm doing with my data!

  It might be a good idea to look at the books by Zuur and co-authors,
which are fairly ecologist-friendly. While I don't agree with everything
in them, they generally exhibit common sense and give good general
descriptions.

> If I transform the proportions into "count" data (#seconds spent
> grooming/ten minutes - hence with a ceiling of 600s) and model using a
> mixed effects negative binomial with zero inflation = false, the
> dispersion parameter is 0.205, indicating that it is underdispersed (?).

  Transformation of this sort doesn't make sense.  NB models
must be run on *count* data.  It sounds like your data act more
like a Beta distribution (used to model proportions), since
"number of seconds" isn't really that likely to act like a count.

> If I run the same model with zeroInflation=TRUE, then the dispersion
> parameter is 1.02...[see code and some output below] but I am unsure how
> exactly this model is dealing with the zero-inflation and what the
> Zero-inflation estimate means. Either way the residuals are not normally
> distributed. I have also thought about using a hurdle-style model (or
> rather, running separate analyses on a binary response [groomed mate or
> didn't] and truncated "count" response [if they groomed, how long did
> they spend grooming], since I am unsure if I can include random
> variables in the hurdle function in pscl). I sense that I may be trying
> to analyse variation that is just not there, with too few observations
> per individual, particularly if most of the time they are not doing the
> behaviour in question. If I try to run a zi-poisson glmm, I get an error
> message: " The function maximizer failed (couldn't find STD file). In
> addition: Warning message:running command 'C:\Windows\system32\cmd.exe
> /c "C:/.......glmmadmb.exe" -maxfn 500 -maxph 5' had status 1".
> 
> 
> glmmadmb(formula = Count_Grooms_Mate ~ Age_years_mean + Sex +
>     FamComp_Offspring + Species + Repro_phase_original + Sex *
>     Repro_phase_original + (1 | Group_no/Individual_no), data = adult3,
>     family = "nbinom", zeroInflation = TRUE)
> Number of observations: total=416, Group_no=13, Group_no:Individual_no=26
> Random effect variance(s):
> Group=Group_no
>              Variance    StdDev
> (Intercept) 2.994e-09 5.472e-05
> Group=Group_no:Individual_no
>              Variance   StdDev
> (Intercept) 2.673e-09 5.17e-05

Note that the random effects are extremely small, suggesting that
the amount of noise at the observation level (within the individual
counts) is big enough to swamp any observable effects of Group or
Individual within group.

  I would consider trying this with family="beta" and zero-inflation,
although admittedly that's a combination I have never tested.

Make sure to plot your data and make sure that the estimates
make sense!

> Negative binomial dispersion parameter: 1.0235 (std. err.: 0.15743)
> Zero-inflation: 0.48117  (std. err.:  0.03323 )
> 
> Log-likelihood: -1089.92
> 
> 
> Thank you for reading,
> 
> Belinda Burns
> 
> -------------------------------------------------------------------------------------------------------------------------------------------------
> 
> Belinda Burns <10517197 at ...> writes:
> 
>> Dear all,
>>
>> I hope this is the correct place for my question, if not, my apologies! I
>> am analysing several behaviour variables obtained by observing captive
>> gibbons. The raw values are in the form proportion of ten minutes spent
>> doing the behaviour, and most of the behaviours are zero-inflated and
>> negatively skewed.
>>
>> At the moment I am interested in modelling the proportion of time that
>> adult gibbons spend grooming their mates, such that the models take the
>> form:
>>
>> Grooms_mate~Age+Species*Sex+
> Family_composition+Repro_phase*Sex
>>
>> where species is a factor with 3 levels, family composition is a binary
>> variable (they either have offspring or not) and repro_phase is the
>> reproductive phase of the female (4 levels).
> 
>> Ideally I should be including individual and group as random effects
>> (individuals are nested within groups) and so I would like to use a
>> mixed model approach; however, diagnostic plots of residuals vs
>> fitted values show heteroscedasticity (increasing spread with
>> increasing fitted values) and plots of residuals vs predictors
>> suggests that one species is less variable than the other two and
>> gibbons with offspring are more variable than those without. The
>> inclusion of a species*family_composition weighted variance function
>> (using the weights= varIdent(form~1|Species*Family_composition) in a
>> gls model) seems to improve the homogeneity of the residuals...
> 
>> I therefore have two questions (among a million others!): Can I
>> include the two random effects in gls, or, vice versa, a varIdent
>> structure in lmer? (the only contact I know doing mixed modelling in
>> R uses lmer with MCMC estimation of p-values and so I am most
>> comfortable using that to include the random effects) How do I write
>> individual and group in as random effects considering individual is
>> nested in group?
> 
> lmer does not handle "R-side" effects (heteroscedasticity/varStruct/etc.)
> at present.  You should be able to use random=~1|group/individual
> in lme to account for individuals nested in groups.  However,
> heteroscedasticity is also a common feature of lognormal data: could
> you get away with some transformation of the form
> log(small_number+proportion)
> (realizing that picking small_number is a bit of a can of worms)?
> Or plogis(small_number+proportion)? (Should be roughly equivalent if
> the proportions are typically small.)
> 
>   Ben Bolker
> 
> 
> -- 
> Belinda Lee Burns, BSc(Hons)
> PhD student
> Email: burnsb02 at student.uwa.edu.au <mailto:burnsb02 at student.uwa.edu.au>


From v_coudrain at voila.fr  Mon Jan 21 15:43:02 2013
From: v_coudrain at voila.fr (v_coudrain at voila.fr)
Date: Mon, 21 Jan 2013 15:43:02 +0100 (CET)
Subject: [R-sig-ME] Partialing out the effect of a covariable in a
	Poisson GLMM
In-Reply-To: <50FD4DC9.2020401@gmail.com>
Message-ID: <1092667107.553011358779382207.JavaMail.www@wwinf7130>

Thank you for this information. 
Best,
Val?rie


> Message du 21/01/13 ? 15h22
> De : "Ben Bolker" 
> A : v_coudrain at voila.fr
> Copie ? : r-sig-mixed-models at r-project.org
> Objet : Re: Partialing out the effect of a covariable in a Poisson GLMM
> 
> On 13-01-21 02:51 AM, v_coudrain at voila.fr wrote:
> > Ben Bolker writes: 
> > 
> >> Don't know exactly what you want to do, but presumably fitting
> >> a "null model" with the covariate and then building more complex models
> >> on top of this -- adding the other covariates -- and doing sequential testing
> >> (anova(full_model,model_with_only_first_covariate)). The linear models
> >> idea of partialing out one variable and running a model on the residuals
> >> doesn't work as well, unfortunately.
> > 
> > Oh yes, thank you I can do it this way. Sould I turn REML to FALSE for model comparison? 
> > Best,
> > Val?rie
> 
> REML is *ignored* when running glmer() [or lmer() with a 'family'
> argument]; as discussed at http://glmm.wikidot.com/faq , REML is
> somewhat poorly defined for GLMMs. (The development version of lme4 at
> least warns that the REML argument is ignored; the CRAN version just
> silently ignores it.)
> 
> Ben Bolker
> 
> 
> 

___________________________________________________________
Envie de changer de frigo ou de gazini?re ? Les soldes ?lectrom?nager sont sur Voila.fr http://shopping.voila.fr/vitrine/electromenager


From andreas.karpf at malix.univ-paris1.fr  Mon Jan 21 02:33:10 2013
From: andreas.karpf at malix.univ-paris1.fr (Andreas Karpf)
Date: Mon, 21 Jan 2013 02:33:10 +0100
Subject: [R-sig-ME] Ordered Probit/Logit with random coefficients
Message-ID: <CAKA9Mw4NcxZbRDKmu9N2G1W03qLWYBFY4Pzdm3_1cajcNKQuZg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130121/cd1c007c/attachment.pl>

From vincent.philion at irda.qc.ca  Mon Jan 21 16:40:27 2013
From: vincent.philion at irda.qc.ca (Vincent Philion)
Date: Mon, 21 Jan 2013 08:40:27 -0700
Subject: [R-sig-ME] Ordered Probit/Logit with random coefficients
In-Reply-To: <CAKA9Mw4NcxZbRDKmu9N2G1W03qLWYBFY4Pzdm3_1cajcNKQuZg@mail.gmail.com>
References: <CAKA9Mw4NcxZbRDKmu9N2G1W03qLWYBFY4Pzdm3_1cajcNKQuZg@mail.gmail.com>
Message-ID: <DC8B3B80-EE7E-4B6A-A352-73F05E58CA27@irda.qc.ca>

Hi! I'm a newbie here, but would vglm from VGAM work? 

library(VGAM)
summary(m.vglm <- vglm(Y ~ x, data = data, family = cumulative (link="logit",
 parallel=TRUE)))
summary(m.vglm)

Vincent

On 2013-01-21, at 02:33, Andreas Karpf <andreas.karpf at malix.univ-paris1.fr> wrote:

> Hello,
> 
> I searched everywhere but I didn't find what I want, that is why I as the
> question here. Does anybody know of a function in R which allows to
> estimate ordered probit/logit model with random coefficients.
> 
> The only mixed effect model I found was clmm of the ordinal package but it
> only provides random intercepts. I am grateful for every hint!
> 
> Best regards,
> 
> AK
> <andreas.karpf at malix.univ-paris.fr>
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-------------- section suivante --------------
Un texte encapsul? et encod? dans un jeu de caract?res inconnu a ?t? nettoy?...
Nom : ATT00001.txt
URL : <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130121/bb82ce2a/attachment-0002.txt>
-------------- section suivante --------------
Un texte encapsul? et encod? dans un jeu de caract?res inconnu a ?t? nettoy?...
Nom : ATT00002.txt
URL : <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130121/bb82ce2a/attachment-0003.txt>

From maciej.swat at gmail.com  Mon Jan 21 16:41:09 2013
From: maciej.swat at gmail.com (Maciej Swat)
Date: Mon, 21 Jan 2013 15:41:09 +0000
Subject: [R-sig-ME] Ordered Probit/Logit with random coefficients
In-Reply-To: <CAKA9Mw4NcxZbRDKmu9N2G1W03qLWYBFY4Pzdm3_1cajcNKQuZg@mail.gmail.com>
References: <CAKA9Mw4NcxZbRDKmu9N2G1W03qLWYBFY4Pzdm3_1cajcNKQuZg@mail.gmail.com>
Message-ID: <498AA3D6-67FC-49E5-8815-624D05134229@gmail.com>


Hi Andreas,

I think this R/Splus computing guide to Agresti textbook, chapter 7, will be very useful for you:

http://www-stat.stanford.edu/~owen/courses/306a/Splusdiscrete2.pdf

Cheers, Maciej


On 21 Jan 2013, at 01:33, Andreas Karpf wrote:

> Hello,
> 
> I searched everywhere but I didn't find what I want, that is why I as the
> question here. Does anybody know of a function in R which allows to
> estimate ordered probit/logit model with random coefficients.
> 
> The only mixed effect model I found was clmm of the ordinal package but it
> only provides random intercepts. I am grateful for every hint!
> 
> Best regards,
> 
> AK
> <andreas.karpf at malix.univ-paris.fr>
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From vincent.philion at irda.qc.ca  Mon Jan 21 16:50:32 2013
From: vincent.philion at irda.qc.ca (Vincent Philion)
Date: Mon, 21 Jan 2013 08:50:32 -0700
Subject: [R-sig-ME] Ordered Probit/Logit with random coefficients
In-Reply-To: <DC8B3B80-EE7E-4B6A-A352-73F05E58CA27@irda.qc.ca>
References: <CAKA9Mw4NcxZbRDKmu9N2G1W03qLWYBFY4Pzdm3_1cajcNKQuZg@mail.gmail.com>
	<DC8B3B80-EE7E-4B6A-A352-73F05E58CA27@irda.qc.ca>
Message-ID: <A8EE5CEF-C55D-4A1E-AB16-949D14E38C7E@irda.qc.ca>

Sorry, no random effects. Misread your post.

This could be of help possibly:

http://www.stat.ufl.edu/~aa/ordinal/R_examples.pdf


On 2013-01-21, at 16:40, Vincent Philion <vincent.philion at irda.qc.ca> wrote:

> Hi! I'm a newbie here, but would vglm from VGAM work? 
> 
> library(VGAM)
> summary(m.vglm <- vglm(Y ~ x, data = data, family = cumulative (link="logit",
> parallel=TRUE)))
> summary(m.vglm)
> 
> Vincent
> 
> On 2013-01-21, at 02:33, Andreas Karpf <andreas.karpf at malix.univ-paris1.fr> wrote:
> 
>> Hello,
>> 
>> I searched everywhere but I didn't find what I want, that is why I as the
>> question here. Does anybody know of a function in R which allows to
>> estimate ordered probit/logit model with random coefficients.
>> 
>> The only mixed effect model I found was clmm of the ordinal package but it
>> only provides random intercepts. I am grateful for every hint!
>> 
>> Best regards,
>> 
>> AK
>> <andreas.karpf at malix.univ-paris.fr>
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
> Vincent Philion, agr., M.Sc.
> Microbiologiste/Phytopathologiste
> 
> Institut de recherche et de d?veloppement en agro-environnement
> Research and Development Institute for the Agri-Environment
> 
> www.irda.qc.ca
> 
> 335, Rang des vingt-cinq Est
> Saint-Bruno-de-Montarville (Qu?bec)  J3V 0G7
> 
> vincent.philion at irda.qc.ca
> 
> Bureau: 450 653-7368 poste 224
> Laboratoire: 450 653-7368 poste 229
> Cellulaire: 514-623-8275
> Skype: VENTURIA
> T?l?copie: 450 653-1927 
> 
> Verger du parc national du Mont-Saint-Bruno
> 330, Rang des vingt-cinq Est
> Saint-Bruno-de-Montarville (Qu?bec)  J3V 4P6
> T?l?phone et t?l?copieur : 450 653-8375
> 
> 
> Pour nous trouver, cliquer sur le lien:
> Laboratoire
> Verger
> 
> Fiers h?ritiers du travail des fr?res Saint-Gabriel: http://arboretum8gabrielis.wordpress.com
> 
> Un expert est une personne qui a fait toutes les erreurs qui peuvent ?tre faites dans un domaine tr?s ?troit. 
> ~ Niels Bohr
> 
> C'est pas parce qu'ils sont nombreux ? avoir tort qu'ils ont raison?
> ~ Coluche
> 
> To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
> ~ Sir Ronald Aylmer Fisher
> 
> Like most of the data I deal with, I'm best described as either "zero inflated Poisson", or "zero inflated negative binomial". Anything but "Normal".
> 
> The plural of anecdote is not data.
> ~ Roger Brinner
> 
> The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
> 
> Prediction is difficult, especially of the future. 
> ~ Mark Twain (also attributed to Niels Bohr and Yogi Berra) 
> 
> There are three kinds of lies: lies, damned lies, and statistics.
> ~ Mark Twain or Disraeli
> 
> Poor, but proudly at the highest step I'm qualified for.
> http://en.wikipedia.org/wiki/Peter_Principle
> 
> Cent fois sur le m?tier remettez votre ouvrage?
> ~ Nicolas Boileau
> 
> Keep your stick on the ice
> ~ The Red & Green show
> 
> Audi alteram partem
> Qui potest capere capiat,
> 
> AVIS DE CONFIDENTIALIT?
> Ce message peut contenir de l'information de nature privil?gi?e et confidentielle. Si vous n'?tes pas le destinataire vis? ou croyez l'avoir re?u par erreur, nous vous saurions gr? d'en aviser l'?metteur. Si ce message vous a ?t? transmis par erreur, veuillez le d?truire sans en communiquer le contenu ? d'autres personnes ou le reproduire.
> 
> 
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-------------- section suivante --------------
Un texte encapsul? et encod? dans un jeu de caract?res inconnu a ?t? nettoy?...
Nom : ATT00001.txt
URL : <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130121/f945fdba/attachment.txt>
-------------- section suivante --------------
Un texte encapsul? et encod? dans un jeu de caract?res inconnu a ?t? nettoy?...
Nom : ATT00002.txt
URL : <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130121/f945fdba/attachment-0001.txt>

From David.Duffy at qimr.edu.au  Mon Jan 21 21:41:31 2013
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Tue, 22 Jan 2013 06:41:31 +1000
Subject: [R-sig-ME] Ordered Probit/Logit with random coefficients
In-Reply-To: <CAKA9Mw4NcxZbRDKmu9N2G1W03qLWYBFY4Pzdm3_1cajcNKQuZg@mail.gmail.com>
References: <CAKA9Mw4NcxZbRDKmu9N2G1W03qLWYBFY4Pzdm3_1cajcNKQuZg@mail.gmail.com>
Message-ID: <alpine.LMD.2.00.1301220639091.4754@orpheus.qimr.edu.au>

On Mon, 21 Jan 2013, Andreas Karpf wrote:

> I searched everywhere but I didn't find what I want, that is why I as the
> question here. Does anybody know of a function in R which allows to
> estimate ordered probit/logit model with random coefficients.

Eventually, someone will mention MCMCglmm with family="ordinal"


From jwiley.psych at gmail.com  Tue Jan 22 00:18:18 2013
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Mon, 21 Jan 2013 15:18:18 -0800
Subject: [R-sig-ME] Ordered Probit/Logit with random coefficients
In-Reply-To: <alpine.LMD.2.00.1301220639091.4754@orpheus.qimr.edu.au>
References: <CAKA9Mw4NcxZbRDKmu9N2G1W03qLWYBFY4Pzdm3_1cajcNKQuZg@mail.gmail.com>
	<alpine.LMD.2.00.1301220639091.4754@orpheus.qimr.edu.au>
Message-ID: <CANz9Z_LEt6+_ULW2LaLkxmm8nxy+T1MCho32iA6=5tJZKC4cdw@mail.gmail.com>

Hi Andreas,

I agree with David---you may have best results with a Bayesian
approach, such as in
MCMCglmm.  The package author, Jarrod Hadfield, has a great set of
course note available online:
http://cran.r-project.org/web/packages/MCMCglmm/vignettes/CourseNotes.pdf

You may also find this package or at least some of the examples useful:

https://github.com/JWiley/postMCMCglmm

I wrote it specifically after doing a bunch of work with ordinal
models in MCMCglmm.  If you install it, you can run:

demo("randomMCMCglmm", package="postMCMCglmm")

to see an example of a three level ordered outcome with a random
intercept.  The (not run) examples in

?predict2.MCMCglmm

may also be useful to you.

If you do not want to install the package, you can get the compiled
PDF of the manual here:
https://github.com/JWiley/postMCMCglmm/blob/master/inst/doc/postMCMCglmm-manual.pdf
with the examples I mentioned, and the demonstrations in the "demo"
folder: https://github.com/JWiley/postMCMCglmm/tree/master/demo


More examples and a vignette should be coming at some point.

Cheers,

Josh


On Mon, Jan 21, 2013 at 12:41 PM, David Duffy <David.Duffy at qimr.edu.au> wrote:
> On Mon, 21 Jan 2013, Andreas Karpf wrote:
>
>> I searched everywhere but I didn't find what I want, that is why I as the
>> question here. Does anybody know of a function in R which allows to
>> estimate ordered probit/logit model with random coefficients.
>
>
> Eventually, someone will mention MCMCglmm with family="ordinal"
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



--
Joshua Wiley
Ph.D. Student, Health Psychology
Programmer Analyst II, Statistical Consulting Group
University of California, Los Angeles
https://joshuawiley.com/


From ramos.grad.student at gmail.com  Tue Jan 22 04:36:07 2013
From: ramos.grad.student at gmail.com (Antonio P. Ramos)
Date: Mon, 21 Jan 2013 19:36:07 -0800
Subject: [R-sig-ME] testing for overdispersion in the mixed effects logistic
	regression
Message-ID: <CAHawB9siiH=k_FQu4TgSv_-Vf9ZNiuABngLm8_GPOcb=i0QX3Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130121/4be742e2/attachment.pl>

From ramos.grad.student at gmail.com  Tue Jan 22 04:45:54 2013
From: ramos.grad.student at gmail.com (Antonio P. Ramos)
Date: Mon, 21 Jan 2013 19:45:54 -0800
Subject: [R-sig-ME] testing for overdispersion in the mixed effects
	logistic regression
In-Reply-To: <CAHawB9siiH=k_FQu4TgSv_-Vf9ZNiuABngLm8_GPOcb=i0QX3Q@mail.gmail.com>
References: <CAHawB9siiH=k_FQu4TgSv_-Vf9ZNiuABngLm8_GPOcb=i0QX3Q@mail.gmail.com>
Message-ID: <CAHawB9vJrzX-2WjCBGj4A+37pcr+gSkiY=Te4_YJhK4sqO2PQw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130121/986fbdcd/attachment.pl>

From gabrielaagostini18 at gmail.com  Wed Jan 23 15:33:30 2013
From: gabrielaagostini18 at gmail.com (Gabriela Agostini)
Date: Wed, 23 Jan 2013 11:33:30 -0300
Subject: [R-sig-ME] Evaluating the significance of the random effects in GLMM
Message-ID: <CALNBOCO0Yc9=nYY9EKXz3HW4KLkE5FPjqEGh5_GO9dNagBja4w@mail.gmail.com>

Hi all!

I am working with GLMM using the binomial family
I use the following codes

I dropped no significant terms, refitting the model and comparing the
changes with likelihood:

G.1<-lmer(data$Ymat~stu+spi+stu*sp1+(1|ber),data=data,family="binomial")

G.1b<-lmer(data$Ymat~stu+spi+(1|ber),data=data,family="binomial")

anova (G.1,G.2)

But, when I want to evaluate the significance of random effect (1|ber)
I cannot use a likelihood-ratio test, probably because the link
function of both models is different.

Can anyone help me?
I recently started using GLM language R. Sorry if my terms are not adequate.


Thanks!


From bbolker at gmail.com  Wed Jan 23 16:13:09 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 23 Jan 2013 15:13:09 +0000 (UTC)
Subject: [R-sig-ME] Evaluating the significance of the random effects in
	GLMM
References: <CALNBOCO0Yc9=nYY9EKXz3HW4KLkE5FPjqEGh5_GO9dNagBja4w@mail.gmail.com>
Message-ID: <loom.20130123T161155-775@post.gmane.org>

Gabriela Agostini <gabrielaagostini18 at ...> writes:

> 
> Hi all!
> 
> I am working with GLMM using the binomial family
> I use the following codes
> 
> I dropped no significant terms, refitting the model and comparing the
> changes with likelihood:
> 
> G.1<-lmer(data$Ymat~stu+spi+stu*sp1+(1|ber),data=data,family="binomial")
> 
> G.1b<-lmer(data$Ymat~stu+spi+(1|ber),data=data,family="binomial")
> 
> anova (G.1,G.2)
> 
> But, when I want to evaluate the significance of random effect (1|ber)
> I cannot use a likelihood-ratio test, probably because the link
> function of both models is different.
> 

  Please don't cross-post between r-help and r-sig-mixed-models ...
I gave a partial answer to your question on r-help
( http://article.gmane.org/gmane.comp.lang.r.general/285341 )
but indicated that we need more information before we can answer.

  Follow-up here, not on r-help.

 Ben Bolker


From bbolker at gmail.com  Wed Jan 23 17:40:56 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 23 Jan 2013 16:40:56 +0000 (UTC)
Subject: [R-sig-ME]
	=?utf-8?q?testing_for_overdispersion_in_the_mixed_effe?=
	=?utf-8?q?cts_logistic=09regression?=
References: <CAHawB9siiH=k_FQu4TgSv_-Vf9ZNiuABngLm8_GPOcb=i0QX3Q@mail.gmail.com>
Message-ID: <loom.20130123T173054-218@post.gmane.org>

Antonio P. Ramos <ramos.grad.student at ...> writes:

> 
> Hi all,
> 
> I would like to check whether I am properly checking for overdispersion in
> a mixed effects logistic regression. Here is the code:
> 
> m1 <- lmer(mortality.under.2 ~ maternal_age_d +B0 + B4 + V102 + BORD +
> WLTHIND5+ time +                       new_time + democracy + V106 +
>  WLTHIND5*time + WLTHIND5*new_time +      democracy*WLTHIND5 +
>              (1 |CASEID)-1,data=brazil1,family=binomial(link="logit"))
> 
> # testing for overdispersion
> n <- length(residuals(m1)) # the number of obs
> k <- length(unique(brazil1$CASEID)) # the number of random effects
> z <- sum(residuals(m1,type=standardize)^2) # squared, standardize residuals
> cat("the overdispersion factor is",z/(n-k),"\n")
> cat("the p-value of the overdispersion test is", pchisq(z,n-k))
> 

  If your response variable is binary (as I'm guessing it is since
you appear to have a single response and not something of the form
cbind(success,failure), but I can't be sure), then testing for
overdispersion doesn't make any sense -- any among-observation
variance is unidentifiable.

  In any case:

* type=standardize is unlikely to work, the normal expectation 
is that type should be a string (e.g. see ?residuals.lme in the nlme
package); however, the residuals method
in the stable version of lme4 doesn't even take a "type" argument

 getMethod("residuals","mer")@.Data
function (object, ...) 
napredict(attr(object at frame, "na.action"), object at resid)
<environment: namespace:lme4.0>

-- yes, this should be better documented!

help("residuals,mer-method") [ugh] tells you that residuals() returns
the Pearson residuals by default:

 ?resid?: The residuals, y-mu, weighted by the ?sqrtrWt? slot (when
          its length is >0).

The last comments are that (1) you should be using lower.tail=FALSE
in your pchisq() call; (2) it's not clear what the "residual df" really
are for random effects models (subtracting the number of random effects
estimates is probably conservative --- but why aren't you subtracting
the fixed effect parameter df too?); (3) the Pearson residuals are
a fairly poor estimate of the scale parameter/overdispersion when the
data are far from conditionally normal (e.g. binomial or Poisson with
small numbers of counts) -- see Venables and Ripley; (4) there's more
information on all of this at http://glmm.wikidot.com/faq#overdispersion.

  Ben Bolker



 (Yes, this should be better documented!)


From matthew.r.robinson at sheffield.ac.uk  Thu Jan 24 14:21:36 2013
From: matthew.r.robinson at sheffield.ac.uk (Matthew Robinson)
Date: Thu, 24 Jan 2013 13:21:36 +0000
Subject: [R-sig-ME] multi-trait model in MCMCglmm
Message-ID: <DD6CFB46-8C7F-469D-B497-F18FA4419850@sheffield.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130124/833bce15/attachment.pl>

From elebrija at hotmail.com  Thu Jan 24 20:13:09 2013
From: elebrija at hotmail.com (Edwin Lebrija Trejos)
Date: Thu, 24 Jan 2013 19:13:09 +0000
Subject: [R-sig-ME] what about "zero-inflated" predictors (Ben Bolker)
In-Reply-To: <mailman.3.1356865202.10593.r-sig-mixed-models@r-project.org>
References: <mailman.3.1356865202.10593.r-sig-mixed-models@r-project.org>
Message-ID: <DUB108-W588EA8DC6D8E96A10E9BFED1140@phx.gbl>


Dear Ben,
sorry for not replying and thanking you for your answer before. I was relocating. 
> 
> The reason that there's very little attention given to the
> distribution of the predictors is that in general the definition
> of standard statistical models such as GLMMs **does not say anything
> about the distribution of the predictors**. In particular, as far
> as I am aware your statement that "in classic regression my data
> would certainly invalidate the analysis" is not true -- at least
> if we're only talking about the distribution of the predictor.
> 
> The main importance of the distribution of the predictor is that
> it affects the power of the test -- obviously if most of your
> predictor data are zeros, they won't give you very much information
> about how the response changes as a function of the response.
 
I went too far on the generalization of my thought. I was thinking on a related problem that was commonly addressed during my statistical training: that a few extreme values of the predictor accompanied by a very different response (considered outliers) could falsely imply a linear relationship. The point you raise is clear and simple (yet I had not thought about it).

> I haven't read Sheater's book, but the purpose of transforming the
> predictor in this context is to take a response that is *not*
> log-odds-linear on the original scale of the predictor, but (e.g.)
> might be log-odds-linear when the predictor is on a log scale.

Yes, this is the way to express it.

> Thus the transformation is *not* fixing a problem with the
> distribution of the predictor, but rather with the linearity
> of the response.
Even if not as crucial as the assumptions on the distribution of the response variable (or rather the model residuals), I beleive this is an important correction to come-up with an appropriate model and, therefore, study conclusions. I "discovered" this in Sheater?s book by looking for something else.

> As always I'm happy to be corrected by others on the list ...

Thanks again for your helpful response. It?s so important to backup the level of science we (non-statistitians) are doing.

> 
> 
> ------------------------------
> 
> _______________________________________________
> R-sig-mixed-models mailing list
> R-sig-mixed-models at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
> End of R-sig-mixed-models Digest, Vol 72, Issue 35
> ************************************************** 		 	   		  

From j.hadfield at ed.ac.uk  Fri Jan 25 11:36:05 2013
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Fri, 25 Jan 2013 10:36:05 +0000
Subject: [R-sig-ME] Data frame size limits in MCMCglmm?
In-Reply-To: <CANz9Z_+5BDbVWxUcv8y-bG9YtwB0593eNUREy=UMyBmHUOcivA@mail.gmail.com>
References: <1358546146.11821.40.camel@musuko.uchicago.edu>
	<CANz9Z_+5BDbVWxUcv8y-bG9YtwB0593eNUREy=UMyBmHUOcivA@mail.gmail.com>
Message-ID: <20130125103605.16911d1gwewajp5w@www.staffmail.ed.ac.uk>

Hi Stuart,

2.4 million records is bigger than anything I've tried but in theory  
it should run, or return an error if it can't allocate enough memory.  
It definitely shouldn't be seg-faulting.  If you could send a  
reproducible example (preferably one where it fails quickly) I will  
take a look into it.

Cheers,

Jarrod.






Quoting Joshua Wiley <jwiley.psych at gmail.com> on Fri, 18 Jan 2013  
20:28:33 -0800:

> Hi Stuart,
>
> How many (if any) iterations completed before you got the seg fault?
> Also, how much memory does your system have?
>
> Currently at 4000 iterations, I have not reproduced the error so far
> with this made up example (although I have practically finished an
> algorithm to sort any array in O(log log n) while waiting to get this
> far ~1 hour per thousand iterations on a 6 core 3.9GHZ machine).
>
> require(MCMCglmm)
> require(MASS)
> set.seed(10)
> rint <- rep(rnorm(14982, 0, 4), each = floor(2.44e6/14982))
> ID <- factor(rep(1:14982,  each = floor(2.44e6/14982)))
> X <- MASS::mvrnorm(length(rint), mu = c(0, 0, 0),
>   Sigma = matrix(c(1, .3, .3, .3, 1, .3, .3, .3, 1), 3))
> b <- matrix(c(1.2, -.5, 2))
> ycont <- rnorm(length(ID), mean = 2 + rint + X %*% b)
> yord <- cut(ycont, breaks = quantile(ycont, c(0, .2, .4, .6, .8, 1)),
>   include.lowest=TRUE, ordered_result=TRUE)
> testdat <- data.frame(yord, ID, x1 = X[,1], x2 = X[, 2], x3 = X[, 3])
> ## > gc()
> ##            used  (Mb) gc trigger  (Mb) max used  (Mb)
> ## Ncells  1117490  59.7    1710298  91.4  1368491  73.1
> ## Vcells 25878798 197.5   47836772 365.0 47753473 364.4
> m <- MCMCglmm(yord ~ x1 + x2 + x3, random = ~ ID,
>   family = "ordinal", data = testdat,
>   prior = list(
>     R = list(V = 1, fix = 1),
>     G = list(
>       G1 = list(V = 1, nu = 0))),
>   nitt = 13000, thin = 10, burnin = 3000)
>
> on a Win 8 pro x64 system with 32GB of memory and
>
> R version 2.15.2 (2012-10-26)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
>  [1] MASS_7.3-22        ggplot2_0.9.3      MCMCglmm_2.17
>  [4] corpcor_1.6.4      ape_3.0-6          coda_0.16-1        Matrix_1.0-10
>  [8] lattice_0.20-10    tensorA_0.36
>
>
>
>
> On Fri, Jan 18, 2013 at 1:55 PM, Stuart Luppescu  
> <slu at ccsr.uchicago.edu> wrote:
>> Hello, I'm having problems running a simple ordinal outcome mixed
>> effects model, and I'm thinking it may be because of the size of the
>> dataset (or, it very may well be that I'm not specifying the model
>> correctly). I must confess to insecurity about how to specify the
>> priors. Here is the structure of the data frame (with columns not in
>> this model omitted). Note that there are more than 2.4 million rows. Is
>> that a problem?
>>
>>  str(all.subj)
>> 'data.frame':   2438922 obs. of  112 variables:
>>  $ gr10                  : num  0 0 0 0 0 0 1 0 1 0 ...
>>  $ gr11                  : num  0 0 0 1 1 1 0 0 0 0 ...
>>  $ gr12                  : num  1 1 1 0 0 0 0 1 0 0 ...
>>  $ tid                   : Factor w/ 14982 levels  
>> "........","A.D46607",..: 2 2 2 2 2 2 2 2 2 2 ...
>>  $ final.points          : Ord.factor w/ 5 levels  
>> "0"<"1"<"2"<"3"<..: 4 4 4 2 3 3 2 2 3 2 ...
>>
>> Here are two attempts and their results:
>>
>> glmm.uncond <- MCMCglmm(final.points ~ gr10 + gr11 + gr12,
>>                          prior=list(R=list(V=1, fix=1),  
>> G=list(G1=list(V=1, nu=0))),
>>                          random = ~tid ,
>>                          family = "ordinal",
>>                          nitt=100000,
>>                          data = all.subj)
>>
>> Error: segfault from C stack overflow
>>
>>
>>  glmm.uncond <- MCMCglmm(final.points ~ gr10 + gr11 + gr12,
>>                          prior=list(R=list(V=1, nu=0),  
>> G=list(G1=list(V=1, nu=0))),
>>                          random = ~tid ,
>>                          family = "ordinal",
>>                          nitt=100000,
>>                          data = all.subj)
>>
>>
>> Process R segmentation fault (core dumped) at Fri Jan 18 12:53:49 2013
>>
>> Here is my sessionInfo
>> R version 2.15.1 (2012-06-22)
>> Platform: x86_64-redhat-linux-gnu (64-bit)
>>
>> locale:
>>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>>  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>>  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>>  [7] LC_PAPER=C                 LC_NAME=C
>>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
>> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> other attached packages:
>> [1] foreign_0.8-52  MCMCglmm_2.17   corpcor_1.6.4   ape_3.0-6
>> [5] coda_0.16-1     Matrix_1.0-10   lattice_0.20-13 tensorA_0.36
>>
>> loaded via a namespace (and not attached):
>> [1] compiler_2.15.1 gee_4.13-18     grid_2.15.1     nlme_3.1-107
>> [5] tools_2.15.1
>>
>> and memory info.
>>
>>  gc()
>>             used   (Mb) gc trigger    (Mb)   max used    (Mb)
>> Ncells   1196029   63.9    1835812    98.1    1710298    91.4
>> Vcells 678385919 5175.7 1777423119 13560.7 2114537169 16132.7
>>
>> Any help will be appreciated.
>>
>>
>> --
>> Stuart Luppescu <slu at ccsr.uchicago.edu>
>> University of Chicago
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>
> --
> Joshua Wiley
> Ph.D. Student, Health Psychology
> Programmer Analyst II, Statistical Consulting Group
> University of California, Los Angeles
> https://joshuawiley.com/
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From j.hadfield at ed.ac.uk  Fri Jan 25 11:41:29 2013
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Fri, 25 Jan 2013 10:41:29 +0000
Subject: [R-sig-ME] multi-trait model in MCMCglmm
In-Reply-To: <DD6CFB46-8C7F-469D-B497-F18FA4419850@sheffield.ac.uk>
References: <DD6CFB46-8C7F-469D-B497-F18FA4419850@sheffield.ac.uk>
Message-ID: <20130125104129.15873wwp4rj6asmc@www.staffmail.ed.ac.uk>

Hi Matt,

Invert the relationship matrix, pass it to ginverse, and use random =  
~us(trait):random.factor  where random.factor contains levels in the  
rownames of the inverse relationship matrix. Make sure the  
relationship matrix is positive definite and coerce the inverse to  
sparse format using as(myinverse, "dgCMatrix").

Cheers,

Jarrod

Quoting Matthew Robinson <matthew.r.robinson at sheffield.ac.uk> on Thu,  
24 Jan 2013 13:21:36 +0000:

> Hi,
>
> I was wondering if it was possible run a bivariate version of the  
> following model in MCMCglmm?
> m1<-MCMCglmm(y~1, random=~idv(Z), data=data, prior=prior)
> Here, Z is a model matrix gained from singular value decomposition  
> of a relationship matrix, and I have used idv to fit a common  
> variance to all terms in Z.
> What I want is to estimate the covariance of the Z effects between  
> two traits. Despite numerous attempts and searching I can't code a  
> model that can do it and any help would be greatly appreciated.
> Many thanks in advance.
> Best wishes,
> Matt
> ------------------------------------------------------
> Dr. Matt Robinson
> NERC Research Fellow
> Department of Animal and Plant Science
> University of Sheffield
> Alfred Denny Building, Western Bank
> Sheffield, S10 2TN, UK
>
> matthew.r.robinson at sheffield.ac.uk
>
> tel:  +44 (0)114 222 4707
> fax: +44 (0)114 222 0002
> ------------------------------------------------------
>
>
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From ned.dochtermann at gmail.com  Fri Jan 25 22:24:10 2013
From: ned.dochtermann at gmail.com (Ned Dochtermann)
Date: Fri, 25 Jan 2013 15:24:10 -0600
Subject: [R-sig-ME] bivariate-response mixed model (MCMCglmm) versus
 mixed-RMA regression options
Message-ID: <5102F7FA.8010404@gmail.com>

Hello all,
I'm currently working on a project where I'm interested in the 
relationship between two variables that are measured with error, 
suggesting the need for reduced major axis regression. However, the data 
structure also necessitates the inclusion of random effects for both 
variables so I initially thought to use a bivariate-response mixed 
model. Unfortunately the relevant covariance/correlation isn't quite 
what I'm interested in for the biological question of interest.

The tentative solution I've come up with is to use the variances and 
covariances to estimate a slope (COVx,y/VARx) and the slope and variable 
means to calculate the intercept. Since I'm doing this on the posteriors 
I'm able to get credibility intervals and mode estimates and not have to 
run a regression on the BLUPs. This gets directly at the question in 
which I'm interested and does so at the level that is relevant.

Does this seem like an appropriate approach? Are there mixed versions of 
RMA (google didn't reveal anything to me) or other alternatives that 
seem preferable?

Thanks for any feedback and sorry for a bit of rambling and the open 
ended nature of the query,
Ned


(slope.me<-posterior.mode(ests.trunc$VCV[,2]/ests.trunc$VCV[,4]))
HPDinterval(ests.trunc$VCV[,2]/ests.trunc$VCV[,4])
intercept.me<-ests.trunc$Sol[,1]-slope.me*ests.trunc$Sol[,2]
posterior.mode(intercept.me)
HPDinterval(intercept.me)





-- 
Ned A. Dochtermann
Assistant Professor / Department of Biological Sciences
NORTH DAKOTA STATE UNIVERSITY
p: 701.231.7353 / f: 701.231.7149 / www.ndsu.edu

https://sites.google.com/site/neddochtermann/
ned.dochtermann at ndsu.edu
--


From ronstone1980 at gmail.com  Sat Jan 26 16:24:37 2013
From: ronstone1980 at gmail.com (Ron Stone)
Date: Sat, 26 Jan 2013 16:24:37 +0100
Subject: [R-sig-ME] Comparing two models using anova () (lmer, lme4),
 get Chisq = 0, Pr(>Chisq) = 1, error or not?
Message-ID: <CAMqQQP3DoaPrgHAqbTqn-mVYtvyae0+2P5r2D1+ko=WgDgNeHw@mail.gmail.com>

Dear all,

I've tried to search to solve my issue, but without any success.

I run two models in lmer (lme4), one with two random effects "Year"
and "ID" (mod1) and one model with only "ID". I compare mod1 (with
both random effects) and mod2 (with only ID) to see if "Year"
significant.

I get Chisq = 0, Pr(>Chisq) = 1, see below. I find it a bit strange to
get this value, is this an error? Or does not "Year" contribute at all
and could I state that "Year" is not significant?

mod1<-lmer(a~ b +(1|Year)+(1|ID))
mod2<-lmer(a ~ b+(1|ID))


library(Matrix)
library(lattice)
options(show.signif.stars = FALSE)
anova(mod1,mod2)

              Df         AIC        BIC       logLik    Chisq    Chi
Df       Pr(>Chisq)
mod1       8    29.394   53.426    -6.6971
mod2       9    31.537   58.573    -6.7685           0         1
           1

Regards,
Ron


From bates at stat.wisc.edu  Sat Jan 26 18:04:50 2013
From: bates at stat.wisc.edu (Douglas Bates)
Date: Sat, 26 Jan 2013 11:04:50 -0600
Subject: [R-sig-ME] Comparing two models using anova () (lmer, lme4),
 get Chisq = 0, Pr(>Chisq) = 1, error or not?
In-Reply-To: <CAMqQQP3DoaPrgHAqbTqn-mVYtvyae0+2P5r2D1+ko=WgDgNeHw@mail.gmail.com>
References: <CAMqQQP3DoaPrgHAqbTqn-mVYtvyae0+2P5r2D1+ko=WgDgNeHw@mail.gmail.com>
Message-ID: <CAO7JsnT2Vb=9iqJ8puzL41SsMjA9FD_Vn=6W14NGYvXXuCL7FA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130126/c7a07a1a/attachment.pl>

From v_coudrain at voila.fr  Sat Jan 26 19:02:21 2013
From: v_coudrain at voila.fr (v_coudrain at voila.fr)
Date: Sat, 26 Jan 2013 19:02:21 +0100 (CET)
Subject: [R-sig-ME] GLMM with binomial error and individual-level random term
Message-ID: <1672117723.263581359223341080.JavaMail.www@wwinf7130>

Dear all,

I performed a GLMM with binomial error and individual-level random term to account for overdispersion. I If I understood it correctly on http://glmm.wikidot.com/faq, 
denominator df are not defined for such models and the significance of the parameters should be tested using Chi-square tests. Is this correct? In F-test, results are 
generally reported by giving the numerator and denominator df, the F value and the p value. Hiw should I report the results of my model? Additionally I would like to 
ask if somebody has relevant literature associated to the addition of an individual-level randorm term to account for overdispersion. 
Thank you very much,
Best wishes
Val?rie
___________________________________________________________
Ils nous ont quitt?s en 2012. Voir le diaporama de nos chers disparus sur Voila.fr http://people.voila.fr/people/mediatheque/dossiers/ils-nous-ont-quittes-en-2012/


From jesper at u.washington.edu  Sun Jan 27 00:58:45 2013
From: jesper at u.washington.edu (Gus Jespersen)
Date: Sat, 26 Jan 2013 15:58:45 -0800
Subject: [R-sig-ME] model selection process
Message-ID: <CAL9m74YvkvGAMJH_qcXsCufqSqiQYJra99j=+_Ny=APWYdzNTQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130126/355c027b/attachment.pl>

From lamprianou at yahoo.com  Sun Jan 27 12:56:27 2013
From: lamprianou at yahoo.com (Iasonas Lamprianou)
Date: Sun, 27 Jan 2013 03:56:27 -0800 (PST)
Subject: [R-sig-ME] non-normal dependent variable
In-Reply-To: <mailman.3.1359284401.27367.r-sig-mixed-models@r-project.org>
References: <mailman.3.1359284401.27367.r-sig-mixed-models@r-project.org>
Message-ID: <1359287787.15207.YahooMailNeo@web160102.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130127/e32b586d/attachment.pl>

From bbolker at gmail.com  Sun Jan 27 19:13:11 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 27 Jan 2013 18:13:11 +0000 (UTC)
Subject: [R-sig-ME] GLMM with binomial error and individual-level random
	term
References: <1672117723.263581359223341080.JavaMail.www@wwinf7130>
Message-ID: <loom.20130127T190508-104@post.gmane.org>

 <v_coudrain at ...> writes:


> I performed a GLMM with binomial error and individual-level random
> term to account for overdispersion. I If I understood it correctly
> on http://glmm.wikidot.com/faq, denominator df are not defined for
> such models and the significance of the parameters should be tested
> using Chi-square tests. Is this correct? In F-test, results are
> generally reported by giving the numerator and denominator df, the F
> value and the p value. Hiw should I report the results of my model?

   You can report the likelihood ratio test and hope for the best
(it assumes a 'large' data set, i.e. the effective residual degrees
of freedom are large).  Otherwise, keep reading the GLMM FAQ.  Also
consider reading various books by Highland Statistics (Alain Zuur
and co-authors).

> Additionally I would like to ask if somebody has relevant literature
> associated to the addition of an individual-level randorm term to
> account for overdispersion.

  Have you looked at the (many) references provided in the "overdispersion"
section of the FAQ?

Quoting (see the page for the actual bib references):

If you want to a citation for this approach, try Elston et al 2001
[11], who cite Lawson et al [16]; apparently there is also an example
in section 10.5 of Maindonald and Braun 3d ed. [18], and (according to
an R-sig-mixed-models post) this also discussed by Rabe-Hesketh and
Skrondal 2008 [21]. Also see Browne et al 2005 [9] for an example in
the binomial context (i.e. logit-normal-binomial rather than
lognormal-Poisson). Agresti's excellent (2002) book [1] also discusses
this (section 13.5), referring back to Breslow (1984, Appl Stat
33:38-44) and Hinde (1982, pp. 109-121 in GLIM82: Proc. Int. Conf. on
GLMs, ed. R Gilchrist, Springer). [Notes: (a) I haven't checked all
these references myself, (b) I can't find the reference any more, but
I have seen it stated that individual-level random effect estimation
is probably dodgy for PQL approaches as used in Elston et al 2001]


From highstat at highstat.com  Sun Jan 27 20:52:10 2013
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Sun, 27 Jan 2013 20:52:10 +0100
Subject: [R-sig-ME] GLMM with binomial error and individual-level,
	random term
In-Reply-To: <mailman.3.1359284401.27367.r-sig-mixed-models@r-project.org>
References: <mailman.3.1359284401.27367.r-sig-mixed-models@r-project.org>
Message-ID: <5105856A.3060904@highstat.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130127/c7350edd/attachment.pl>

From bbolker at gmail.com  Sun Jan 27 22:34:22 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 27 Jan 2013 21:34:22 +0000 (UTC)
Subject: [R-sig-ME]
	=?utf-8?q?GLMM_with_binomial_error_and_individual-leve?=
	=?utf-8?q?l=2C=09random_term?=
References: <mailman.3.1359284401.27367.r-sig-mixed-models@r-project.org>
	<5105856A.3060904@highstat.com>
Message-ID: <loom.20130127T223020-821@post.gmane.org>

Highland Statistics Ltd <highstat at ...> writes:

> > Message: 3
> > Date: Sat, 26 Jan 2013 19:02:21 +0100 (CET)
> > From: v_coudrain at ...
> > Subject: [R-sig-ME] GLMM with binomial error and individual-level
> > 	random term

> > I performed a GLMM with binomial error and individual-level random
> term to account for overdispersion. I If I understood it correctly
> on http://glmm.wikidot.com/faq, > denominator df are not defined for
> such models and the significance of the parameters should be tested
> using Chi-square tests. Is this correct? In F-test, results are >
> generally reported by giving the numerator and denominator df, the F
> value and the p value. Hiw should I report the results of my model?
> Additionally I would like to > ask if somebody has relevant
> literature associated to the addition of an individual-level randorm
> term to account for overdispersion.

> Have a look at a paper from Dave Elston:

 [snip]  [also referenced from the http://glmm.wikidot.com/faq
page, along with other refs, as previously described]

> It is also in Chapter 2 in Zuur et al. (2012)...sorry for self-citing. I 
> think I would try a beta binomial GLMM in JAGS. I believe Ben has 
> written a package for beta binomial GLM. Not sure whether it can do 
> GLMM. I think gamlss can also do beta binomial GLMM...not sure. 

  There are a number of packages that can do beta-binomial GLM --
bbmle makes it fairly straightforward, although it's not specifically
for beta-binomial GLMs.  Probably also the VGAM and aod packages.

  glmmADMB doesn't do beta-binomial GLMMs, but could fairly
easily be extended to do so.  I'd be happy to accept high-quality
patches ... or a compelling reason to spend my time on it right
now ...

> We are 
> co-authoring a book with Joe Hilbe in which we have a 40 page chapter 
> where we compare binomial GLMM with the individual level random effect 
> and the beta binomial GLMM. ....... 'Beginner's Guide to GLM and GLMM 
> using R and JAGS'. Comes out in 2-3 months....sorry for 
> self-advertising...

  Seems reasonable if it answers the question.


From David.Duffy at qimr.edu.au  Mon Jan 28 03:01:27 2013
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Mon, 28 Jan 2013 12:01:27 +1000
Subject: [R-sig-ME] non-normal dependent variable
In-Reply-To: <1359287787.15207.YahooMailNeo@web160102.mail.bf1.yahoo.com>
References: <mailman.3.1359284401.27367.r-sig-mixed-models@r-project.org>
	<1359287787.15207.YahooMailNeo@web160102.mail.bf1.yahoo.com>
Message-ID: <alpine.LMD.2.00.1301281200280.25393@orpheus.qimr.edu.au>

On Sun, 27 Jan 2013, Iasonas Lamprianou wrote:

> Dear all, I am running an lmer model using repeated measures (scores on 
> various school subjects) per student as a dependent variable. The 
> students are a random effect. My problem is that the dependent variable 
> is not beatifully normal (there seems to be a ceiling effect).

The lmec package may do the trick.


From logodall at yahoo.fr  Mon Jan 28 09:07:10 2013
From: logodall at yahoo.fr (logodall)
Date: Mon, 28 Jan 2013 08:07:10 +0000 (GMT)
Subject: [R-sig-ME] 0
Message-ID: <1359360430.19713.BPMail_high_noncarrier@web133001.mail.ir2.yahoo.com>


http://www.sylvain-soff.fr/weight.drop.easy.php?SID=688


From v_coudrain at voila.fr  Mon Jan 28 09:09:53 2013
From: v_coudrain at voila.fr (v_coudrain at voila.fr)
Date: Mon, 28 Jan 2013 09:09:53 +0100 (CET)
Subject: [R-sig-ME] GLMM with binomial error and individual-level random term
Message-ID: <948750677.16261359360593495.JavaMail.www@wwinf7132>

Thank you very much Ben and Alain for your helpful comments. No problem with the self-citing, your books are really very good! I've never used beta-binomial 
models. I am investigating sex-ratio in different sites, with site as a random factor. I will have a look at the different R packages and the examples provided.
Best wishes
Val?rie
___________________________________________________________
Ils nous ont quitt?s en 2012. Voir le diaporama de nos chers disparus sur Voila.fr http://people.voila.fr/people/mediatheque/dossiers/ils-nous-ont-quittes-en-2012/


From lamprianou at yahoo.com  Mon Jan 28 10:35:25 2013
From: lamprianou at yahoo.com (Iasonas Lamprianou)
Date: Mon, 28 Jan 2013 01:35:25 -0800 (PST)
Subject: [R-sig-ME] non-normal dependent variable
In-Reply-To: <alpine.LMD.2.00.1301281200280.25393@orpheus.qimr.edu.au>
References: <mailman.3.1359284401.27367.r-sig-mixed-models@r-project.org>
	<1359287787.15207.YahooMailNeo@web160102.mail.bf1.yahoo.com>
	<alpine.LMD.2.00.1301281200280.25393@orpheus.qimr.edu.au>
Message-ID: <1359365725.1992.YahooMailNeo@web160101.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130128/d70dc0c9/attachment.pl>

From leverkus at ugr.es  Mon Jan 28 14:57:07 2013
From: leverkus at ugr.es (leverkus)
Date: Mon, 28 Jan 2013 14:57:07 +0100
Subject: [R-sig-ME] Generalized randomized block design
Message-ID: <443e6ebc71147a65202e10be49f512e5@ugr.es>

Dear R users,

I am struggling with the formulation in lme of a generalized randomized 
block design with subsampling, and I would very much appreciate some 
help. The experiment consists of 3 plots (of ca. 20 ha each) located at 
different altitudes on a mountain slope. In each plot there are 9 
subplots, which are 3 replicates of 3 post-fire wood management 
treatments. In each subplot we sampled 8 transects for plants (except in 
one subplot, where only 5 transects were sampled), and my response 
variable is species diversity. In order to take account for the 
experimental design and get the correct number of denominator degrees of 
freedom, I am using (1|Plot/Subplot) in the random effects. Subplot is a 
categorical variable which joins treatment names (treatments are "SL", 
"NI", "PCL") and replicates (1,2,3): SL1, SL2, SL3, NI1... This gives me 
the correct replication: 3 plots and 27 subplots. As for now, my model 
looks like this:

lme(diversity~Treatment,random=~1|Plot/Subplot)

However, treatment effects are likely to vary with altitude, so I wish 
to test for the treatment x plot interaction. This is where I am stuck. 
By including plot as a fixed effect (diversity~Treatment*Plot) I have no 
df to calculate the plot effect and this looks weird to me. Besides, I 
want to have plot as a random effect. Could anyone give me some 
suggestions? (I don?t mind using lmer instead.)

Thanks in advance,

alex


From leverkus at ugr.es  Mon Jan 28 21:08:32 2013
From: leverkus at ugr.es (leverkus)
Date: Mon, 28 Jan 2013 21:08:32 +0100
Subject: [R-sig-ME] Generalized randomized block design
In-Reply-To: <51069193.5030805@oakland.edu>
References: <443e6ebc71147a65202e10be49f512e5@ugr.es>
	<51069193.5030805@oakland.edu>
Message-ID: <2fc725cbe54f97dccbad516a5106b6e8@ugr.es>

Thanks for your reply, Rob,

I guess you are right about not modeling plot as a random effect. In 
any case, if I formulate it this way (as I understand you suggest):

lme(diversity~Treatment*Plot,random=~1|Plot/Subplot)

I don?t have enough df to calculate a Plot (altitude) main effect but 
only treatment and the treatment*Plot interaction. The summary of the 
fixed effects looks like this:

Fixed effects: diversity ~ Treatment * Plot
                     Value  Std.Error  DF   t-value p-value
(Intercept)     0.8332827 0.03153322 186 26.425551  0.0000
TreatPCL        0.0250449 0.04557570  18  0.549524  0.5894
TreatSL        -0.1618297 0.04459471  18 -3.628898  0.0019
Plot2           0.1346471 0.04459471   0  3.019351     NaN # where 
these results with 0 df look like they shouldn?t be in the model.
Plot3           0.0561054 0.04459471   0  1.258118     NaN
TreatPCL:Plot2 -0.0617449 0.06376388  18 -0.968337  0.3457
TreatSL:Plot2  -0.0339678 0.06306644  18 -0.538603  0.5968
TreatPCL:Plot3  0.0217470 0.06376388  18  0.341054  0.7370
TreatSL:Plot3   0.1790523 0.06306644  18  2.839106  0.0109

My questions here are: 1) is it ok to include a Plot main effect in the 
model (as above) even though I don?t have df for it? 2) Would it be 
"allowed" instead to use diversity~Treatment+Treatment:Plot as fixed 
effects, without a Plot main effect? Or otherwise, 3) How wrong would it 
be in the random term to place plot at the level of subplots, so that 
random=~1|Plot:Subplot? I understand in this latter way I would be 
pseudoreplicating plot.

I guess the main issue is that it annoys me to have a term in the model 
which tells me nothing, and not knowing which values to report for 
altitude (the fixed effects with 0 df or the random term resulting from 
the specification of the experimental structure).

Thanks again,

alex





El 2013-01-28 15:56, Robert Kushler escribi?:
> Since Plot is confounded with "Altitude" I suggest you treat Altitude
> as a fixed effect
> and give up on trying to estimate a Plot variance component (2 df is
> not enough info
> for that).
>
> Regards,   Rob Kushler
>
>
> On 1/28/2013 8:57 AM, leverkus wrote:
>> Dear R users,
>>
>> I am struggling with the formulation in lme of a generalized 
>> randomized block design with subsampling, and I would very
>> much appreciate some help. The experiment consists of 3 plots (of 
>> ca. 20 ha each) located at different altitudes on a
>> mountain slope. In each plot there are 9 subplots, which are 3 
>> replicates of 3 post-fire wood management treatments. In
>> each subplot we sampled 8 transects for plants (except in one 
>> subplot, where only 5 transects were sampled), and my
>> response variable is species diversity. In order to take account for 
>> the experimental design and get the correct number
>> of denominator degrees of freedom, I am using (1|Plot/Subplot) in 
>> the random effects. Subplot is a categorical variable
>> which joins treatment names (treatments are "SL", "NI", "PCL") and 
>> replicates (1,2,3): SL1, SL2, SL3, NI1... This gives
>> me the correct replication: 3 plots and 27 subplots. As for now, my 
>> model looks like this:
>>
>> lme(diversity~Treatment,random=~1|Plot/Subplot)
>>
>> However, treatment effects are likely to vary with altitude, so I 
>> wish to test for the treatment x plot interaction.
>> This is where I am stuck. By including plot as a fixed effect 
>> (diversity~Treatment*Plot) I have no df to calculate the
>> plot effect and this looks weird to me. Besides, I want to have plot 
>> as a random effect. Could anyone give me some
>> suggestions? (I don?t mind using lmer instead.)
>>
>> Thanks in advance,
>>
>> alex
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From sgleason at siu.edu  Mon Jan 28 23:32:27 2013
From: sgleason at siu.edu (Shane Gleason)
Date: Mon, 28 Jan 2013 16:32:27 -0600
Subject: [R-sig-ME] Graphing interaction terms in LME4, glmer
Message-ID: <5106FC7B.6070601@siu.edu>

Hello everyone,

I am working with lme4, specifically the glmer command.  In a multilevel 
model I have an interaction term which is significant. However, with my 
discipline we stress that an interaction term cannot be evaluated by p 
value alone and one must reference a graphical display of the 
interaction, with confidence intervals drawn around it.

That is to say if the interaction is X*Z then the interaction might be 
significant when X=1 and Z=3, but may not be significant if X=4 and Z=9.

I have searched around and I can't seem to find any indication of how to 
graph out the interaction (though I see some references to it for lmer 
(but never glmer)).  So, my question is two-part- 1: Does this 
assumption about how interaction terms work hold for MLMs?  2: If the 
answer to 1 is yes, does anyone know of software I can use to graph out 
these interactions?

Thanks,

Shane

-- 
Shane Gleason
Doctoral Candidate
Southern Illinois University:Carbondale
Department of Political Science
Faner 3172


From jesper at u.washington.edu  Mon Jan 28 23:55:36 2013
From: jesper at u.washington.edu (Gus Jespersen)
Date: Mon, 28 Jan 2013 14:55:36 -0800
Subject: [R-sig-ME] Model selection process and fixed effect reporting with
 three candidate models
Message-ID: <CAL9m74ZeLDadZgxT2ZjdQSBQLfZa-QNV9LX78tJwWhNayUasTg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130128/3a2c9241/attachment.pl>

From istazahn at gmail.com  Tue Jan 29 00:13:49 2013
From: istazahn at gmail.com (Ista Zahn)
Date: Mon, 28 Jan 2013 18:13:49 -0500
Subject: [R-sig-ME] Graphing interaction terms in LME4, glmer
In-Reply-To: <5106FC7B.6070601@siu.edu>
References: <5106FC7B.6070601@siu.edu>
Message-ID: <CA+vqiLHna1nX05R=-HHdgrk1O_ovKjh6EqY0DNv+Cx8UgiNgDA@mail.gmail.com>

Hi Shane,

Take a look at the effects package, I believe it has what you are
looking for. Here is a modified example from ?effect

library(lme4)

data(cake, package="lme4")
cake$a2 <- ifelse(cake$angle < mean(cake$angle, na.rm=TRUE), 0, 1)

fm1 <- lmer(a2 ~ recipe * temp + (1|recipe:replicate),
            data = cake,
            family = "binomial",
            REML = FALSE)

library(effects)
plot(effect("recipe:temp", fm1), grid=TRUE)


HTH,
Ista

On Mon, Jan 28, 2013 at 5:32 PM, Shane Gleason <sgleason at siu.edu> wrote:
> Hello everyone,
>
> I am working with lme4, specifically the glmer command.  In a multilevel
> model I have an interaction term which is significant. However, with my
> discipline we stress that an interaction term cannot be evaluated by p value
> alone and one must reference a graphical display of the interaction, with
> confidence intervals drawn around it.
>
> That is to say if the interaction is X*Z then the interaction might be
> significant when X=1 and Z=3, but may not be significant if X=4 and Z=9.
>
> I have searched around and I can't seem to find any indication of how to
> graph out the interaction (though I see some references to it for lmer (but
> never glmer)).  So, my question is two-part- 1: Does this assumption about
> how interaction terms work hold for MLMs?  2: If the answer to 1 is yes,
> does anyone know of software I can use to graph out these interactions?
>
> Thanks,
>
> Shane
>
> --
> Shane Gleason
> Doctoral Candidate
> Southern Illinois University:Carbondale
> Department of Political Science
> Faner 3172
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From sgleason at siu.edu  Tue Jan 29 01:29:51 2013
From: sgleason at siu.edu (Shane Gleason)
Date: Mon, 28 Jan 2013 18:29:51 -0600
Subject: [R-sig-ME] Graphing interaction terms in LME4, glmer
In-Reply-To: <CA+vqiLHna1nX05R=-HHdgrk1O_ovKjh6EqY0DNv+Cx8UgiNgDA@mail.gmail.com>
References: <5106FC7B.6070601@siu.edu>
	<CA+vqiLHna1nX05R=-HHdgrk1O_ovKjh6EqY0DNv+Cx8UgiNgDA@mail.gmail.com>
Message-ID: <510717FF.2090701@siu.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130128/2430b1db/attachment.pl>

From istazahn at gmail.com  Tue Jan 29 03:11:31 2013
From: istazahn at gmail.com (Ista Zahn)
Date: Mon, 28 Jan 2013 21:11:31 -0500
Subject: [R-sig-ME] Graphing interaction terms in LME4, glmer
In-Reply-To: <510717FF.2090701@siu.edu>
References: <5106FC7B.6070601@siu.edu>
	<CA+vqiLHna1nX05R=-HHdgrk1O_ovKjh6EqY0DNv+Cx8UgiNgDA@mail.gmail.com>
	<510717FF.2090701@siu.edu>
Message-ID: <CA+vqiLH+ND6_c-Bohcw+wMcSVw2jMDPLGyBt=U-Yxvq1uvd-SA@mail.gmail.com>

Hi Shane,

I think there may be some version issues here: on my system my example
worked fine.

I have

R version 2.15.2 (2012-10-26)
Platform: x86_64-unknown-linux-gnu (64-bit)

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=C
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
 [7] LC_PAPER=C                 LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] grid      stats     graphics  grDevices utils     datasets  methods
[8] base

other attached packages:
[1] effects_2.2-3    colorspace_1.2-0 nnet_7.3-5       MASS_7.3-23
[5] lme4_0.999999-0  Matrix_1.0-10    lattice_0.20-13

loaded via a namespace (and not attached):
[1] compiler_2.15.2 nlme_3.1-107    stats4_2.15.2   tools_2.15.2
Best,
Ista
On Mon, Jan 28, 2013 at 7:29 PM, Shane Gleason <sgleason at siu.edu> wrote:
> Hello everyone,
>
> Thank you kindly to everyone who replied.  Ista's comment was the one that
> had exactly what I needed- though it did take some tinkering.  For the
> benefit of the next person who comes along, I'm adding the changes I needed
> to make to Ista's code:
>
> Running the code Ista initially provided, the following error in bold comes
> up
>
>
>> data(cake, package="lme4")
>> cake$a2 <- ifelse(cake$angle < mean(cake$angle, na.rm=TRUE), 0, 1)
>>
>> fm1 <- lmer(a2 ~ recipe * temp + (1|recipe:replicate),
> +             data = cake,
> +             family = "binomial",
> +             REML = FALSE)
>>
>> library(effects)
>> plot(effect("recipe:temp", fm1), grid=TRUE)
> Error in plot(effect("recipe:temp", fm1), grid = TRUE) :
>   error in evaluating the argument 'x' in selecting a method for function
> 'plot': Error: $ operator not defined for this S4 class
>
> The solution to this is to follow on to the next line in the example in the
> effects display from John Fox's JSS paper http://www.jstatsoft.org/v08/i15:
>
> detach(package:lme4) # if previously attached
> library(nlme)
> data(cake, package="lme4")
>
> cake$rep <- with(cake, paste( as.character(recipe), as.character(replicate),
> sep=""))
> fm2 <- lme(angle ~ recipe * temperature, data=cake,
>            random = ~ 1 | rep, method="ML")
> plot(effect("recipe", "temperature", fm2), grid=TRUE)
>
> However, this produces a heck of a lot of panels, which are kind of
> difficult to interpret.... so we force everything onto one graph- which is
> accomplished by adding the following line (also from John Fox's working
> paper (pg 14): (note, I haven't updated this to reflect the cake example
>
>> plot(effect("recipeism*extraversion", cowles.mod,
> +
> xlevels=list(neuroticism=0:24, extraversion=seq(0, 24, 6))),
> +
> multiline=TRUE, ylab="Probability(Volunteer)")
>
> You all have been a great help.  I hope this summary e-mail helps others in
> the future.
>
> Shane
>
>
>
>
> On 01/28/2013 05:13 PM, Ista Zahn wrote:
>
> Hi Shane,
>
> Take a look at the effects package, I believe it has what you are
> looking for. Here is a modified example from ?effect
>
> library(lme4)
>
> data(cake, package="lme4")
> cake$a2 <- ifelse(cake$angle < mean(cake$angle, na.rm=TRUE), 0, 1)
>
> fm1 <- lmer(a2 ~ recipe * temp + (1|recipe:replicate),
>             data = cake,
>             family = "binomial",
>             REML = FALSE)
>
> library(effects)
> plot(effect("recipe:temp", fm1), grid=TRUE)
>
>
> HTH,
> Ista
>
> On Mon, Jan 28, 2013 at 5:32 PM, Shane Gleason <sgleason at siu.edu> wrote:
>
> Hello everyone,
>
> I am working with lme4, specifically the glmer command.  In a multilevel
> model I have an interaction term which is significant. However, with my
> discipline we stress that an interaction term cannot be evaluated by p value
> alone and one must reference a graphical display of the interaction, with
> confidence intervals drawn around it.
>
> That is to say if the interaction is X*Z then the interaction might be
> significant when X=1 and Z=3, but may not be significant if X=4 and Z=9.
>
> I have searched around and I can't seem to find any indication of how to
> graph out the interaction (though I see some references to it for lmer (but
> never glmer)).  So, my question is two-part- 1: Does this assumption about
> how interaction terms work hold for MLMs?  2: If the answer to 1 is yes,
> does anyone know of software I can use to graph out these interactions?
>
> Thanks,
>
> Shane
>
> --
> Shane Gleason
> Doctoral Candidate
> Southern Illinois University:Carbondale
> Department of Political Science
> Faner 3172
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
> --
> Shane Gleason
> Doctoral Candidate
> Southern Illinois University:Carbondale
> Department of Political Science
> Faner 3172


From seth at swbigelow.net  Tue Jan 29 13:52:53 2013
From: seth at swbigelow.net (seth at swbigelow.net)
Date: Tue, 29 Jan 2013 06:52:53 -0600
Subject: [R-sig-ME] Generalized randomized block design
In-Reply-To: <2fc725cbe54f97dccbad516a5106b6e8@ugr.es>
Message-ID: <f71de277f8ac6cc2ecd11d327b65aa4a83c796b1@sitemail.hostway.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130129/72dbd420/attachment.pl>

From andrew.close at newcastle.ac.uk  Tue Jan 29 14:31:36 2013
From: andrew.close at newcastle.ac.uk (Andrew Close)
Date: Tue, 29 Jan 2013 13:31:36 +0000
Subject: [R-sig-ME] Help: Error message in nlme
Message-ID: <D891D3A75E959E428CFDFBD258C1621E0A927690@EXMBCT01.campus.ncl.ac.uk>

Dear List,

I am trying to fit a non-linear mixed model using nlme library and to include a four-level factor as a covariate.

The model works perfectly well until I attempt to include the covariate- I then receive the following error message:


"Error in nlme.formula(model = cfu ~ SSasymp(Time, Asym, R0, lrc), data = PH64G, :  starting values for the fixed component are not the correct length"


This would suggest that I have included the correct number of starting parameters for the specified model, but I cannot see anything obviously wrong with the code that I am using.

I have attached the data set I am using and  the code below.

library(nlme)

PH64G<-read.csv("PH64G.csv",header=TRUE,row.names=1)
PH64G$Isolate<-factor(PH64G$Isolate)
PH64G$pH<-factor(PH64G$pH)

summary(PH64G)

PH64G<-groupedData(cfu ~ Time | Isolate/Replicate, inner = ~ pH,
labels = list(x="Time Heated (minutes)", y="Cell Counts Log10 CFU/ml"),
data = PH64G)

##############################
## Non-linear Least Squares Models ##
##############################
## Generic model using nls
mod1 <- nlsList(cfu ~ SSasymp(Time, Asym, R0, lrc) | Isolate/Replicate, PH64G)
mod1

########################
## Non-linear Mixed Model  ##
########################
mod2 <- nlme(mod1, random = pdDiag(Asym + R0 + lrc ~ 1), groups = ~ Isolate)

##

It is at the point of running model 3 to include the covariate that I receive the error message. From my understanding, I am attempting to estimate five random-effects parameters; Asym and R0 are allowed to vary according to pH (four-level factor) while lrc is estimated using only the intercept.

mod3 <- update(mod2, fixed = list(Asym ~ pH, R0 ~ pH, lrc ~ 1),
start=c(2.6442, 0, 7.9493, 0, -0.0985))
##

Any suggestions would be gratefully received.

With thanks

Andrew



From sgleason at siu.edu  Tue Jan 29 17:09:40 2013
From: sgleason at siu.edu (Shane Gleason)
Date: Tue, 29 Jan 2013 10:09:40 -0600
Subject: [R-sig-ME] Graphing interaction terms in LME4, glmer
In-Reply-To: <CA+vqiLH+ND6_c-Bohcw+wMcSVw2jMDPLGyBt=U-Yxvq1uvd-SA@mail.gmail.com>
References: <5106FC7B.6070601@siu.edu>
	<CA+vqiLHna1nX05R=-HHdgrk1O_ovKjh6EqY0DNv+Cx8UgiNgDA@mail.gmail.com>
	<510717FF.2090701@siu.edu>
	<CA+vqiLH+ND6_c-Bohcw+wMcSVw2jMDPLGyBt=U-Yxvq1uvd-SA@mail.gmail.com>
Message-ID: <5107F444.7020806@siu.edu>

Hi Ista,

It was a version problem.  After upgrading to 2.15.2 your solution 
worked like a charm.  However, for those that have older systems or just 
want to jazz it up the documentation on the effects package 
(particularly Fox (2003- JSS) and the CRAN help file are wonderful and 
cover almost every eventuality.

Take care everyone,

Shane

On 01/28/2013 08:11 PM, Ista Zahn wrote:
> Hi Shane,
>
> I think there may be some version issues here: on my system my example
> worked fine.
>
> I have
>
> R version 2.15.2 (2012-10-26)
> Platform: x86_64-unknown-linux-gnu (64-bit)
>
> locale:
>   [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>   [3] LC_TIME=en_US.UTF-8        LC_COLLATE=C
>   [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>   [7] LC_PAPER=C                 LC_NAME=C
>   [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] grid      stats     graphics  grDevices utils     datasets  methods
> [8] base
>
> other attached packages:
> [1] effects_2.2-3    colorspace_1.2-0 nnet_7.3-5       MASS_7.3-23
> [5] lme4_0.999999-0  Matrix_1.0-10    lattice_0.20-13
>
> loaded via a namespace (and not attached):
> [1] compiler_2.15.2 nlme_3.1-107    stats4_2.15.2   tools_2.15.2
> Best,
> Ista
> On Mon, Jan 28, 2013 at 7:29 PM, Shane Gleason <sgleason at siu.edu> wrote:
>> Hello everyone,
>>
>> Thank you kindly to everyone who replied.  Ista's comment was the one that
>> had exactly what I needed- though it did take some tinkering.  For the
>> benefit of the next person who comes along, I'm adding the changes I needed
>> to make to Ista's code:
>>
>> Running the code Ista initially provided, the following error in bold comes
>> up
>>
>>
>>> data(cake, package="lme4")
>>> cake$a2 <- ifelse(cake$angle < mean(cake$angle, na.rm=TRUE), 0, 1)
>>>
>>> fm1 <- lmer(a2 ~ recipe * temp + (1|recipe:replicate),
>> +             data = cake,
>> +             family = "binomial",
>> +             REML = FALSE)
>>> library(effects)
>>> plot(effect("recipe:temp", fm1), grid=TRUE)
>> Error in plot(effect("recipe:temp", fm1), grid = TRUE) :
>>    error in evaluating the argument 'x' in selecting a method for function
>> 'plot': Error: $ operator not defined for this S4 class
>>
>> The solution to this is to follow on to the next line in the example in the
>> effects display from John Fox's JSS paper http://www.jstatsoft.org/v08/i15:
>>
>> detach(package:lme4) # if previously attached
>> library(nlme)
>> data(cake, package="lme4")
>>
>> cake$rep <- with(cake, paste( as.character(recipe), as.character(replicate),
>> sep=""))
>> fm2 <- lme(angle ~ recipe * temperature, data=cake,
>>             random = ~ 1 | rep, method="ML")
>> plot(effect("recipe", "temperature", fm2), grid=TRUE)
>>
>> However, this produces a heck of a lot of panels, which are kind of
>> difficult to interpret.... so we force everything onto one graph- which is
>> accomplished by adding the following line (also from John Fox's working
>> paper (pg 14): (note, I haven't updated this to reflect the cake example
>>
>>> plot(effect("recipeism*extraversion", cowles.mod,
>> +
>> xlevels=list(neuroticism=0:24, extraversion=seq(0, 24, 6))),
>> +
>> multiline=TRUE, ylab="Probability(Volunteer)")
>>
>> You all have been a great help.  I hope this summary e-mail helps others in
>> the future.
>>
>> Shane
>>
>>
>>
>>
>> On 01/28/2013 05:13 PM, Ista Zahn wrote:
>>
>> Hi Shane,
>>
>> Take a look at the effects package, I believe it has what you are
>> looking for. Here is a modified example from ?effect
>>
>> library(lme4)
>>
>> data(cake, package="lme4")
>> cake$a2 <- ifelse(cake$angle < mean(cake$angle, na.rm=TRUE), 0, 1)
>>
>> fm1 <- lmer(a2 ~ recipe * temp + (1|recipe:replicate),
>>              data = cake,
>>              family = "binomial",
>>              REML = FALSE)
>>
>> library(effects)
>> plot(effect("recipe:temp", fm1), grid=TRUE)
>>
>>
>> HTH,
>> Ista
>>
>> On Mon, Jan 28, 2013 at 5:32 PM, Shane Gleason <sgleason at siu.edu> wrote:
>>
>> Hello everyone,
>>
>> I am working with lme4, specifically the glmer command.  In a multilevel
>> model I have an interaction term which is significant. However, with my
>> discipline we stress that an interaction term cannot be evaluated by p value
>> alone and one must reference a graphical display of the interaction, with
>> confidence intervals drawn around it.
>>
>> That is to say if the interaction is X*Z then the interaction might be
>> significant when X=1 and Z=3, but may not be significant if X=4 and Z=9.
>>
>> I have searched around and I can't seem to find any indication of how to
>> graph out the interaction (though I see some references to it for lmer (but
>> never glmer)).  So, my question is two-part- 1: Does this assumption about
>> how interaction terms work hold for MLMs?  2: If the answer to 1 is yes,
>> does anyone know of software I can use to graph out these interactions?
>>
>> Thanks,
>>
>> Shane
>>
>> --
>> Shane Gleason
>> Doctoral Candidate
>> Southern Illinois University:Carbondale
>> Department of Political Science
>> Faner 3172
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>> --
>> Shane Gleason
>> Doctoral Candidate
>> Southern Illinois University:Carbondale
>> Department of Political Science
>> Faner 3172

-- 
Shane Gleason
Doctoral Candidate
Southern Illinois University:Carbondale
Department of Political Science
Faner 3172


From sheryn.olson at maine.edu  Tue Jan 29 00:59:05 2013
From: sheryn.olson at maine.edu (Sheryn Olson)
Date: Mon, 28 Jan 2013 18:59:05 -0500
Subject: [R-sig-ME] Coefplot2 availability? or How to interpret?
Message-ID: <CAATUFed8ZWm=dYNnUepZsPy80RwG6H=2uwJ9OGKyo0VKLr9T-g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130128/bb174938/attachment.pl>

From seth at swbigelow.net  Tue Jan 29 19:38:40 2013
From: seth at swbigelow.net (seth at swbigelow.net)
Date: Tue, 29 Jan 2013 12:38:40 -0600
Subject: [R-sig-ME] Model selection process and fixed effect reporting
	with three candidate models
In-Reply-To: <CAL9m74ZeLDadZgxT2ZjdQSBQLfZa-QNV9LX78tJwWhNayUasTg@mail.gmail.com>
Message-ID: <768ead4c48db7a624670c2d8255834a0b333f290@sitemail.hostway.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130129/19b33237/attachment.pl>

From bbolker at gmail.com  Tue Jan 29 23:31:37 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 29 Jan 2013 22:31:37 +0000 (UTC)
Subject: [R-sig-ME] Coefplot2 availability? or How to interpret?
References: <CAATUFed8ZWm=dYNnUepZsPy80RwG6H=2uwJ9OGKyo0VKLr9T-g@mail.gmail.com>
Message-ID: <loom.20130129T230812-393@post.gmane.org>

Sheryn Olson <sheryn.olson at ...> writes:

> 
> Hello all,
> 
> I need to correctly(!) interpret and graphically present a negative
> binomial mixed model generated with glmmADMB.   Is the coefplot2 package
> working as of Jan, 2013?   Is there an alternative if not?   Is there an
> "extraction" package to provide confidence intervals around the
> exponentiated coefficients?   I ran an mcmc approximation to get confidence
> intervals, but I'm not sure how to present them graphically.  Is there
> ggplot code that might work?
> 
> The study system: What are the effects of season and forest stand types on
> snowshoe hare pellet densities.  Do snowshoe hares move more seasonally in
> some forest stands than in others?  Year is a random (nuisance) variable.
>  Each stand type (treatment) has unequal sample sizes that vary by year.
> The count data are constrained at zero, residuals are overdispersed.

The error message is giving you a hint that you should try installing
from the source package:

install.packages("coefplot2",repos="http://www.math.mcmaster.ca/bolker/R",
    type="source")

  That should work even if you don't have the tools installed for compiling
packages from source, because the coefplot2 package doesn't require any
binary compilation (all R has to do is unpack an archive file and put the
bits in the right places, which it shouldn't need any external tools to do).

   Your MCMC results might be more conservative/robust than the default
confidence intervals.

  I haven't otherwise looked at your model/results etc. posted below to see
if they're sensible ...


From kurbyc at gvsu.edu  Wed Jan 30 03:27:36 2013
From: kurbyc at gvsu.edu (Christopher Kurby)
Date: Wed, 30 Jan 2013 02:27:36 +0000
Subject: [R-sig-ME] follow up test on interaction from mixed effect model
Message-ID: <FE8EFD00-7D62-482C-82D1-BBD84BB08E74@gvsu.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130130/ffadaab6/attachment.pl>

From sgleason at siu.edu  Wed Jan 30 03:45:18 2013
From: sgleason at siu.edu (Shane Gleason)
Date: Tue, 29 Jan 2013 20:45:18 -0600
Subject: [R-sig-ME] follow up test on interaction from mixed effect model
In-Reply-To: <FE8EFD00-7D62-482C-82D1-BBD84BB08E74@gvsu.edu>
References: <FE8EFD00-7D62-482C-82D1-BBD84BB08E74@gvsu.edu>
Message-ID: <5108893E.10503@siu.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130129/64acce10/attachment.pl>

From leverkus at ugr.es  Wed Jan 30 07:20:31 2013
From: leverkus at ugr.es (leverkus)
Date: Wed, 30 Jan 2013 07:20:31 +0100
Subject: [R-sig-ME] Generalized randomized block design
In-Reply-To: <f71de277f8ac6cc2ecd11d327b65aa4a83c796b1@sitemail.hostway.com>
References: <f71de277f8ac6cc2ecd11d327b65aa4a83c796b1@sitemail.hostway.com>
Message-ID: <0fe0fb5439fddf6d401ca1ea9890991c@ugr.es>

Thanks for clarifying that, Seth. I just tried using altitude instead 
of plot as suggested, and only subplot as a random term. However, 
substituting altitude by the categorical Plot seems to work way better 
(now I?m using the cover of annuals as response):

> 
> model<-lme(asin(sqrt(annualcov))~Treat*altitude,random=~1|Subplot,method="ML",data=na.omit(divers))
> model1<-update(model,~.-Treat:altitude)
> anova(model,model1)
        Model df       AIC       BIC  logLik   Test  L.Ratio p-value
model      1  8 -247.3299 -220.4396 131.665
model1     2  6 -245.9759 -225.8082 128.988 1 vs 2 5.353978  0.0688     
# for the interaction using altitude

> 
> modela<-lme(asin(sqrt(annualcov))~Treat*Plot,random=~1|Subplot,method="ML",data=na.omit(divers))
> model1a<-update(model,~.-Treat:Plot)
> anova(modela,model1a)
        Model df       AIC       BIC   logLik   Test  L.Ratio p-value
model      1 11 -255.4568 -218.4826 138.7284
model1     2  7 -244.6295 -221.1004 129.3147 1 vs 2 18.82735   8e-04    
# for the interaction using plot

 From plotting the data I can see there is definitely an interaction 
here, so I would trust the version with Plot more than with altitude 
(Residuals in both cases look centered around 0). But I have this issue 
of not knowing whether it is wrong to pseudoreplicate in this way. In 
any case, if my plots were not located at different altitudes there 
would still have to be a way of testing this basic design, right? Could 
my modela be considered correct?

Thank you,

alex






El 2013-01-29 13:52, seth at swbigelow.net escribi?:
> Have you tried?specifying altitude (ie., as numeric), rather than?a
> plot identifier, as a main effect? This may be what Rob was
> suggesting.?Since altitute is a numeric gradient, and you seem to be
> suspecting that something is going on that is related to that
> gradient, this would seem worth a try -- implemented as an 
> interaction
> model, and as a non-interaction model, and then comparing with
> likelihood ratio test. I would try just specifying 'subplot' as a
> random effect, then examining the residuals as in the 'rails'l 
> example
> in Pinheiro & Bates
>
> -Seth
>
> ?
>
>> ----- Original Message -----
>>
>> From: leverkus <leverkus at ugr.es>
>>
>> To:"Robert Kushler" <kushler at oakland.edu>,
>> <r-sig-mixed-models at r-project.org>
>>
>> Cc:
>>
>> Sent:Mon, 28 Jan 2013 21:08:32 +0100
>>
>> Subject:Re: [R-sig-ME] Generalized randomized block design
>>
>> Thanks for your reply, Rob,
>>
>> I guess you are right about not modeling plot as a random effect.
>> In
>> any case, if I formulate it this way (as I understand you suggest):
>>
>> lme(diversity~Treatment*Plot,random=~1|Plot/Subplot)
>>
>> I don?t have enough df to calculate a Plot (altitude) main effect
>> but
>> only treatment and the treatment*Plot interaction. The summary of
>> the
>> fixed effects looks like this:
>>
>> Fixed effects: diversity ~ Treatment * Plot
>> Value Std.Error [1] DF t-value p-value
>> (Intercept) 0.8332827 0.03153322 186 26.425551 0.0000
>> TreatPCL 0.0250449 0.04557570 18 0.549524 0.5894
>> TreatSL -0.1618297 0.04459471 18 -3.628898 0.0019
>> Plot2 0.1346471 0.04459471 0 3.019351 NaN # where
>> these results with 0 df look like they shouldn?t be in the model.
>> Plot3 0.0561054 0.04459471 0 1.258118 NaN
>> TreatPCL:Plot2 -0.0617449 0.06376388 18 -0968337 0.3457
>> TreatSL:Plot2 -0.0339678 0.06306644 18 -0.538603 0.5968
>> TreatPCL:Plot3 0.0217470 0.06376388 18 0.341054 07370
>> TreatSL:Plot3 0.1790523 0.06306644 18 2.839106 0.0109
>>
>> My questions here are: 1) is it ok to include a Plot main effect in
>> the
>> model (as above) even though I don?t have df for it? 2) Would it
>> be
>> "allowed" instead to use diversity~Treatment+Treatment:Plot as
>> fixed
>> effects, without a Plot main effect? Or otherwise, 3) How wrong
>> would it
>> be in the random term to place plot at the level of subplots, so
>> that
>> random=~1|Plot:Subplot? I understand in this latter way I would be
>> pseudoreplicating plot.
>>
>> I guess the main issue is that it annoys me to have a term in the
>> model
>> which tells me nothing, and not knowing which values to report for
>> altitude (the fixed effects with 0 df or the random term resulting
>> from
>> the specification of the experimental structure).
>>
>> Thanks again,
>>
>> alex
>>
>> El 2013-01-28 15:56, Robert Kushler escribi?:
>> > Since Plot is confounded with "Altitude" I suggest you treat
>> Altitude
>> > as a fixed effect
>> > and give up on trying to estimate a Plot variance component (2 df
>> is
>> > not enough info
>> > for that).
>> >
>> > Regards, Rob Kushler
>> >
>> >
>> > On 1/28/2013 8:57 AM, leverkus wrote:
>> >> Dear R users,
>> >>
>> >> I am struggling with the formulation in lme of a generalized
>> >> randomized block design with subsampling, and I would very
>> >> much appreciate some help. The experiment consists of 3 plots
>> (of
>> >> ca. 20 ha each) located at different altitudes on a
>> >> mountain slope. In each plot there are 9 subplots, which are 3
>> >> replicates of 3 post-fire wood management treatments. In
>> >> each subplot we sampled 8 transects for plants (except in one
>> >> subplot, where only 5 transects were sampled), and my
>> >> response variable is species diversity. In order to take account
>> for
>> >> the experimental design and get the correct number
>> >> of denominator degrees of freedom, I am using (1|Plot/Subplot)
>> in
>> >> the random effects. Subplot is a categorical variable
>> >> which joins treatment names (treatments are "SL", "NI", "PCL")
>> and
>> >> replicates (1,2,3): SL1, SL2, SL3, NI1.. This gives
>> >> me the correct replication: 3 plots and 27 subplots. As for now,
>> my
>> >> model looks like this:
>> >>
>> >> lme(diversity~Treatment,random=~1|Plot/Subplot)
>> >>
>> >> However, treatment effects are likely to vary with altitude, so
>> I
>> >> wish to test for the treatment x plot interaction.
>> >> This is where I am stuck. By including plot as a fixed effect
>> >> (diversity~Treatment*Plot) I have no df to calculate the
>> >> plot effect and this looks weird to me. Besides, I want to have
>> plot
>> >> as a random effect. Could anyone give me some
>> >> suggestions? (I don?t mind using lmer instead.)
>> >>
>> >> Thanks in advance,
>> >>
>> >> alex
>> >>
>> >> _______________________________________________
>> >> R-sig-mixed-models at r-project.org [2] mailing list
>> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models [3]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org [4] mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models [5]
>
>
> Links:
> ------
> [1] http://Std.Error
> [2] mailto:R-sig-mixed-models at r-project.org
> [3] https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> [4] mailto:R-sig-mixed-models at r-project.org
> [5] https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From emmanuel.curis at parisdescartes.fr  Wed Jan 30 10:01:40 2013
From: emmanuel.curis at parisdescartes.fr (Emmanuel Curis)
Date: Wed, 30 Jan 2013 10:01:40 +0100
Subject: [R-sig-ME] follow up test on interaction from mixed effect	model
In-Reply-To: <FE8EFD00-7D62-482C-82D1-BBD84BB08E74@gvsu.edu>
References: <FE8EFD00-7D62-482C-82D1-BBD84BB08E74@gvsu.edu>
Message-ID: <20130130090140.GA19414@info124.pharmacie.univ-paris5.fr>

Hi,

This is not really an answer, but I remember a text from Venables
about regression and interactions, and if I remember correctly, it was
said that for two continuous variables x & y (quantitative variables
in general I guess), using an interaction x*y without using x^2 and
y^2 was somehow meaningless.

http://www.stats.ox.ac.uk/pub/MASS3/Exegeses.pdf

The main idea was, IIRC, that the linear regression equation is a Taylor
expansion at first order, and for adding interactions one must
consider a second-order expansion, which gives the x*y term but also
the x^2 and y^2 terms... Which sounds quite sensible.

But with this idea in mind, I wonder how it would make sense to ?
tease apart ? the interaction for continuous variables. Instead,
presence and interaction would suggest that a linear relationship
between the dependant variable and the predictors is not suited, but
it gives another equation which may be useful by itself...

This is quite a different interpretation from the case of categorical
variables, in fact, even if the linear model formalism is the same...

Would be pleased to have comments on these ideas by more experimented
statisticians, by the way...

Best regards

On Wed, Jan 30, 2013 at 02:27:36AM +0000, Christopher Kurby wrote:
? Hello everyone,
? 
? I have a mixed effect model in which I am modeling an interaction between two continuous variables. The interaction between them is significant. Can anyone recommend a method to tease apart this interaction? For standard multiple regression, one would compute simple slopes from the regression equation. Is the same done for mixed effect models? Just for the sake of argument, let's say my model is below. In case it is important to know, I also have some covariates in the model, but I'm modeling only the main effect of the covariate. Again, I am interested in teasing apart the interaction between the two continuous predictors:
? 
? lmer(DV ~ var1 * var2 + cov1 + (1|Subject) + (1|item), data=dat)
? 
? Thank you in advance.
? 
? Chris
? 
? Christopher A. Kurby
? Assistant Professor of Psychology
? Grand Valley State University
? Allendale, MI 49401
? phone: 616-331-2418
? email: kurbyc at gvsu.edu<mailto:kurbyc at gvsu.edu>
? 
? 
? 
? 
? 	[[alternative HTML version deleted]]
? 
? _______________________________________________
? R-sig-mixed-models at r-project.org mailing list
? https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
                                Emmanuel CURIS
                                emmanuel.curis at univ-paris5.fr

Page WWW: http://emmanuel.curis.online.fr/index.html


From kurbyc at gvsu.edu  Wed Jan 30 15:46:07 2013
From: kurbyc at gvsu.edu (Christopher Kurby)
Date: Wed, 30 Jan 2013 14:46:07 +0000
Subject: [R-sig-ME] follow up test on interaction from mixed effect	model
In-Reply-To: <9B75E7CF385CB94EAD6587DD96AC2D974AF3002A@SFSMCEXMBX3.sanfordhealth.org>
References: <FE8EFD00-7D62-482C-82D1-BBD84BB08E74@gvsu.edu>
	<20130130090140.GA19414@info124.pharmacie.univ-paris5.fr>
	<9B75E7CF385CB94EAD6587DD96AC2D974AF3002A@SFSMCEXMBX3.sanfordhealth.org>
Message-ID: <83FADD86-8632-427B-B564-2D681B568D79@gvsu.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130130/73cc8532/attachment.pl>

From teplitsky at mnhn.fr  Wed Jan 30 19:09:57 2013
From: teplitsky at mnhn.fr (Celine Teplitsky)
Date: Wed, 30 Jan 2013 19:09:57 +0100
Subject: [R-sig-ME] fixing covariances to 0 in MCMCglmm
Message-ID: <510961F5.6080101@mnhn.fr>

Dear all,

I would like to run an animal model in MCMCglmm with 3 traits, 2 male 
traits and one female trait, but I do not know how to fix the 
covariances between sexes for Vpe and Vr to 0. From what I understood 
from an earlier post by Jarrod, it was not possible 2 years ago, but any 
chance it is now?
Many thanks in advance for help,

All the best

Celine

-- 

Celine Teplitsky
D?partement Ecologie et Gestion de la Biodiversit? UMR 7204
Unit? Conservation des Esp?ces, Restauration et Suivi des Populations
Case Postale 51
55 rue Buffon 75005 Paris

Webpage :http://www2.mnhn.fr/cersp/spip.php?rubrique96
Fax : (33-1)-4079-3835
Phone: (33-1)-4079-3443


From j.hadfield at ed.ac.uk  Thu Jan 31 11:05:25 2013
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Thu, 31 Jan 2013 10:05:25 +0000
Subject: [R-sig-ME] fixing covariances to 0 in MCMCglmm
In-Reply-To: <510961F5.6080101@mnhn.fr>
References: <510961F5.6080101@mnhn.fr>
Message-ID: <20130131100525.1167524c0x4rxnwo@www.staffmail.ed.ac.uk>

Hi Celine,

Sorry, this is still not available. Given that there is no information  
in the data to estimate the covariances you want to set to zero, I  
wonder whether there is anything wrong with just having a fully  
unstructured matrix and then ignoring the covariances? The information  
for those covariances will come solely from the prior, but I would  
expect that the posteriors for those (co)variances that can be  
estimated would remain valid. It may reduce mixing, but would be one  
solution.

Cheers,

Jarrod




Quoting Celine Teplitsky <teplitsky at mnhn.fr> on Wed, 30 Jan 2013  
19:09:57 +0100:

> Dear all,
>
> I would like to run an animal model in MCMCglmm with 3 traits, 2  
> male traits and one female trait, but I do not know how to fix the  
> covariances between sexes for Vpe and Vr to 0. From what I  
> understood from an earlier post by Jarrod, it was not possible 2  
> years ago, but any chance it is now?
> Many thanks in advance for help,
>
> All the best
>
> Celine
>
> -- 
>
> Celine Teplitsky
> D?partement Ecologie et Gestion de la Biodiversit? UMR 7204
> Unit? Conservation des Esp?ces, Restauration et Suivi des Populations
> Case Postale 51
> 55 rue Buffon 75005 Paris
>
> Webpage :http://www2.mnhn.fr/cersp/spip.php?rubrique96
> Fax : (33-1)-4079-3835
> Phone: (33-1)-4079-3443
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From bonamy at horus.ens.fr  Thu Jan 31 11:07:34 2013
From: bonamy at horus.ens.fr (Pierre B. de Villemereuil)
Date: Thu, 31 Jan 2013 11:07:34 +0100
Subject: [R-sig-ME] fixing covariances to 0 in MCMCglmm
In-Reply-To: <510961F5.6080101@mnhn.fr>
References: <510961F5.6080101@mnhn.fr>
Message-ID: <510A4266.2050606@horus.ens.fr>

Hi !

What about the following :
random = ~idh(sex):PE + us(sex):animal, rcov=idh(sex):units

I did not test it though, so I'm not sure it will work, but I see no 
reason why not ! ;)

Cheers,
Pierre.


Le 30/01/2013 19:09, Celine Teplitsky a ?crit :
> Dear all,
>
> I would like to run an animal model in MCMCglmm with 3 traits, 2 male 
> traits and one female trait, but I do not know how to fix the 
> covariances between sexes for Vpe and Vr to 0. From what I understood 
> from an earlier post by Jarrod, it was not possible 2 years ago, but 
> any chance it is now?
> Many thanks in advance for help,
>
> All the best
>
> Celine
>


From j.hadfield at ed.ac.uk  Thu Jan 31 11:19:50 2013
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Thu, 31 Jan 2013 10:19:50 +0000
Subject: [R-sig-ME] fixing covariances to 0 in MCMCglmm
In-Reply-To: <510A4266.2050606@horus.ens.fr>
References: <510961F5.6080101@mnhn.fr> <510A4266.2050606@horus.ens.fr>
Message-ID: <20130131101950.19868akg10s5w1mw@www.staffmail.ed.ac.uk>

Hi Pierre,

I think Celine wants matrices of the form

  V1 C12 0
C12 V2  0
  0   0   V3

it could be done for the PE term. I think this should work:

random =  
~us(at.level(sex,"Male"):at.level(trait,1:2)):PE+us(at.level(sex,"Female"):at.level(trait,3)):PE

where traits 1 and 2 are measured on males, and trait 3 on females.

The R-structure however cannot yet have multiple terms.

Cheers,

Jarrod






Quoting "Pierre B. de Villemereuil" <bonamy at horus.ens.fr> on Thu, 31  
Jan 2013 11:07:34 +0100:

> Hi !
>
> What about the following :
> random = ~idh(sex):PE + us(sex):animal, rcov=idh(sex):units
>
> I did not test it though, so I'm not sure it will work, but I see no  
> reason why not ! ;)
>
> Cheers,
> Pierre.
>
>
> Le 30/01/2013 19:09, Celine Teplitsky a ?crit :
>> Dear all,
>>
>> I would like to run an animal model in MCMCglmm with 3 traits, 2  
>> male traits and one female trait, but I do not know how to fix the  
>> covariances between sexes for Vpe and Vr to 0. From what I  
>> understood from an earlier post by Jarrod, it was not possible 2  
>> years ago, but any chance it is now?
>> Many thanks in advance for help,
>>
>> All the best
>>
>> Celine
>>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From teplitsky at mnhn.fr  Thu Jan 31 11:47:03 2013
From: teplitsky at mnhn.fr (Celine Teplitsky)
Date: Thu, 31 Jan 2013 11:47:03 +0100
Subject: [R-sig-ME] fixing covariances to 0 in MCMCglmm
In-Reply-To: <20130131101950.19868akg10s5w1mw@www.staffmail.ed.ac.uk>
References: <510961F5.6080101@mnhn.fr> <510A4266.2050606@horus.ens.fr>
	<20130131101950.19868akg10s5w1mw@www.staffmail.ed.ac.uk>
Message-ID: <510A4BA7.3000501@mnhn.fr>

Hi Jarrod and Pierre,

thanks a lot for the help!

Cheers

Celine

> Hi Pierre,
>
> I think Celine wants matrices of the form
>
>  V1 C12 0
> C12 V2  0
>  0   0   V3
>
> it could be done for the PE term. I think this should work:
>
> random = 
> ~us(at.level(sex,"Male"):at.level(trait,1:2)):PE+us(at.level(sex,"Female"):at.level(trait,3)):PE
>
> where traits 1 and 2 are measured on males, and trait 3 on females.
>
> The R-structure however cannot yet have multiple terms.
>
> Cheers,
>
> Jarrod
>
>
>
>
>
>
> Quoting "Pierre B. de Villemereuil" <bonamy at horus.ens.fr> on Thu, 31 
> Jan 2013 11:07:34 +0100:
>
>> Hi !
>>
>> What about the following :
>> random = ~idh(sex):PE + us(sex):animal, rcov=idh(sex):units
>>
>> I did not test it though, so I'm not sure it will work, but I see no 
>> reason why not ! ;)
>>
>> Cheers,
>> Pierre.
>>
>>
>> Le 30/01/2013 19:09, Celine Teplitsky a ?crit :
>>> Dear all,
>>>
>>> I would like to run an animal model in MCMCglmm with 3 traits, 2 
>>> male traits and one female trait, but I do not know how to fix the 
>>> covariances between sexes for Vpe and Vr to 0. From what I 
>>> understood from an earlier post by Jarrod, it was not possible 2 
>>> years ago, but any chance it is now?
>>> Many thanks in advance for help,
>>>
>>> All the best
>>>
>>> Celine
>>>
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>
>
>


-- 

Celine Teplitsky
D?partement Ecologie et Gestion de la Biodiversit? UMR 7204
Unit? Conservation des Esp?ces, Restauration et Suivi des Populations
Case Postale 51
55 rue Buffon 75005 Paris

Webpage : http://www2.mnhn.fr/cersp/spip.php?rubrique96
Fax : (33-1)-4079-3835
Phone: (33-1)-4079-3443


From nelize35 at gmail.com  Thu Jan 31 14:48:28 2013
From: nelize35 at gmail.com (=?ISO-8859-1?Q?Elise_Maz=E9?=)
Date: Thu, 31 Jan 2013 14:48:28 +0100
Subject: [R-sig-ME] ziPoisson heritability MCMCglmm
Message-ID: <CAB4iCRF=_EEYeKYo=_6S5es8Yoc1tQnqjY+CcT5hDBG+vFtcnA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130131/4d6c4bd6/attachment.pl>

From camille.madec at ebc.uu.se  Thu Jan 31 15:21:12 2013
From: camille.madec at ebc.uu.se (Camille Madec)
Date: Thu, 31 Jan 2013 15:21:12 +0100
Subject: [R-sig-ME] MCMCglmm, priorR and binomial distribution
Message-ID: <20130131152112.11477kt575w0ykt4@webmail.uu.se>

Dear everyone,

I have a model with 2 fixed factors, 1 random factor and a binary  
response variable. I ran a MCMCglmm with family=?categorical? and the  
prior for the residual being R=list(V=1, nu=0.002). In the summary of  
the model I got high post.mean values (around 50 for fixed effects and  
 >1000 for random effects and sometimes up to 14000).
I ran the same model with R=list(V=1, fix=1) which means that the  
variance of the residual is fixed to 1, so the residual becomes a  
fixed factor (if I understand correctly). In that case my post.mean  
values are smaller (between zero and 24).

My questions are:
1) Are the large values in the first case normal?
2) How do I know which prior is the more appropriate for the residual?

Bests,
Camille

-----
Camille Madec
PhD student
Plant Ecology and Evolution
Uppsala University
Sweden


From a.haffenden at keele.ac.uk  Thu Jan 31 14:03:06 2013
From: a.haffenden at keele.ac.uk (Austin Haffenden)
Date: Thu, 31 Jan 2013 13:03:06 +0000
Subject: [R-sig-ME] Standardising means of data
Message-ID: <CAL78zvNqCgFHzCfajiuqb4W7Yr7DQfeFqWFyZ5Y2xifEc0QNHg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130131/4f91becd/attachment.pl>

From nelize35 at gmail.com  Thu Jan 31 14:22:50 2013
From: nelize35 at gmail.com (=?utf-8?b?TWF6w6k=?= E)
Date: Thu, 31 Jan 2013 13:22:50 +0000 (UTC)
Subject: [R-sig-ME] ziPoisson heritability MCMCglmm
Message-ID: <loom.20130131T124854-716@post.gmane.org>

Hi,
I am currently trying to fit a quasi-poisson distribution with my data (counts
variable, which contains 50% of zero) with MCMCglmm so as to estimate the
heritability of a morphological trait. Previously I used a "Poisson"
distribution, but to be more exact I have to use a ziP distribution. However, I
am not comfortable with bayesian priors and  the syntax of the models in
MCMCglmm, and I don't understand all the terms of the outputs
("summary.MCMCglmm(object)").
Can someone help me to 
1)asses if the prior used is non-informative?
2)if the ziP model syntax have the same signification as the Poisson model?
3)explain which terms I have to use so as to calculate the heritability?

My codes are

#Poisson model

prior1.7 <- list(G = list(G1 = list(V = 1, n = 1.002), G2 = list(V = 1,n =
1.002), G3 = list(V = 1, n = 1.002),G4 = list(V = 1, n = 1.002),
 G5 = list(V = 1, n = 1.002)), R = list(V = 1, n = 1.002))

modelDEG <- MCMCglmm(DEG ~ PAR +SIZE, random = ~ animal + ANNEE + STATION +
ANNEE:STATION , pedigree = Ped, data = Data, nitt = 1000000, thin = 1000, burnin
=  50000,prior = prior1.7, verbose = FALSE,family="poisson")

Heritability=mean(modelDEG$VCV[, "animal"] / (modelDEG$VCV[, "animal"] +
modelDEG$VCV[, "units"] + modelDEG$VCV[, "STATION"]+ modelDEG$DVCV[, "ANNEE"]+
modelDEG$VCV[, "ANNEE:STATION"]))

#ziPoisson model

zi.prior <-  list(R = list(V = diag(2), n = 1.002, fix = 2),
 G = list(G1 = list(V = 1, n = 0.002),
 G2 = list(V = 1, n = 0.002),
 G3 = list(V = 1, n = 0.002),
G4=list(V=1,n=0.002)))

model1 <- MCMCglmm(DEG ~ trait+trait: PAR +trait:SIZE, 
random = ~ animal + ANNEE + STATION + ANNEE:STATION,
rcov=~us(trait):units,
pedigree = Ped, data = Data, 
prior=zi.prior,
nitt = 1000000, thin = 1000, burnin =  50000,
verbose = FALSE,family="zipoisson")

Heritability= ????


Many Thanks in advance


From rpfigueira at gmail.com  Wed Jan 30 12:31:08 2013
From: rpfigueira at gmail.com (Rui Figueira)
Date: Wed, 30 Jan 2013 11:31:08 +0000
Subject: [R-sig-ME] contribution of random variables to final estimate
Message-ID: <CANKTuwbGW79ZXSWS_us06sbsRV-zCqNmdBEkQoB5=yPPKWY-TQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130130/1f15d0b1/attachment.pl>

From aghaynes at gmail.com  Thu Jan 31 16:19:06 2013
From: aghaynes at gmail.com (Alan Haynes)
Date: Thu, 31 Jan 2013 16:19:06 +0100
Subject: [R-sig-ME] contribution of random variables to final estimate
In-Reply-To: <CANKTuwbGW79ZXSWS_us06sbsRV-zCqNmdBEkQoB5=yPPKWY-TQ@mail.gmail.com>
References: <CANKTuwbGW79ZXSWS_us06sbsRV-zCqNmdBEkQoB5=yPPKWY-TQ@mail.gmail.com>
Message-ID: <CAPdSD+5_q0-uD3jKpADpq_EcHYx7RyPBrm4X2AV7t4x7RfJduQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130131/beea7f7b/attachment.pl>

From j.hadfield at ed.ac.uk  Thu Jan 31 16:46:19 2013
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Thu, 31 Jan 2013 15:46:19 +0000
Subject: [R-sig-ME] MCMCglmm, priorR and binomial distribution
In-Reply-To: <20130131152112.11477kt575w0ykt4@webmail.uu.se>
References: <20130131152112.11477kt575w0ykt4@webmail.uu.se>
Message-ID: <20130131154619.94987qht70vq1alw@www.staffmail.ed.ac.uk>

Hi Camille,

The second prior is the correct one. The residual variance is not  
identifiable in the likelihood for binary data: I have tried to  
explain this intuitively in Section 2.6 of the CourseNotes using a  
tasteless example of hospital deaths.

Cheers,

Jarrod



Quoting Camille Madec <camille.madec at ebc.uu.se> on Thu, 31 Jan 2013  
15:21:12 +0100:

> Dear everyone,
>
> I have a model with 2 fixed factors, 1 random factor and a binary  
> response variable. I ran a MCMCglmm with family=?categorical? and  
> the prior for the residual being R=list(V=1, nu=0.002). In the  
> summary of the model I got high post.mean values (around 50 for  
> fixed effects and >1000 for random effects and sometimes up to 14000).
> I ran the same model with R=list(V=1, fix=1) which means that the  
> variance of the residual is fixed to 1, so the residual becomes a  
> fixed factor (if I understand correctly). In that case my post.mean  
> values are smaller (between zero and 24).
>
> My questions are:
> 1) Are the large values in the first case normal?
> 2) How do I know which prior is the more appropriate for the residual?
>
> Bests,
> Camille
>
> -----
> Camille Madec
> PhD student
> Plant Ecology and Evolution
> Uppsala University
> Sweden
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From seth at swbigelow.net  Thu Jan 31 19:24:10 2013
From: seth at swbigelow.net (seth at swbigelow.net)
Date: Thu, 31 Jan 2013 12:24:10 -0600
Subject: [R-sig-ME] Generalized randomized block design
In-Reply-To: <0fe0fb5439fddf6d401ca1ea9890991c@ugr.es>
Message-ID: <5e842525cd0ba9942cad4e9b8ce0f64e83a858e6@sitemail.hostway.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130131/65f3fea0/attachment.pl>

From neilandertal at gmail.com  Fri Feb  1 02:23:37 2013
From: neilandertal at gmail.com (Neil Collier)
Date: Fri, 1 Feb 2013 09:23:37 +0800
Subject: [R-sig-ME] Standardising means of data
In-Reply-To: <CAL78zvNqCgFHzCfajiuqb4W7Yr7DQfeFqWFyZ5Y2xifEc0QNHg@mail.gmail.com>
References: <CAL78zvNqCgFHzCfajiuqb4W7Yr7DQfeFqWFyZ5Y2xifEc0QNHg@mail.gmail.com>
Message-ID: <CAOVghqoVvWjuoQOsMeDQtfh++em+HzL_sJEM17ijKA2AkdQe8A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130201/a96a27aa/attachment.pl>

From bbolker at gmail.com  Sat Feb  2 19:08:33 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 2 Feb 2013 18:08:33 +0000 (UTC)
Subject: [R-sig-ME] contribution of random variables to final estimate
References: <CANKTuwbGW79ZXSWS_us06sbsRV-zCqNmdBEkQoB5=yPPKWY-TQ@mail.gmail.com>
Message-ID: <loom.20130202T190730-181@post.gmane.org>

Rui Figueira <rpfigueira at ...> writes:

> 
> Dear all,
> We want to test if the invasiveStatus is predicted by the amount
> (quant) of animals arriving to a country of a certain species
> (taxonid). We are using lmer to perform the model.
> The model is:lmer(invasiveStatus~I(log(quant+1))+
>     I(log(inDegree+1))+(1|taxonid)+(1|country),
> family=binomial,data=td),
> where invasiveStatus is a binary variable, quant and inDegree are
> integer variables, and taxonid and country are factor variables.
> 

 *Please* don't cross-post on R lists, it fosters confusion and wasted
effort. I saw this first on R-help and gave an answer there.

For reference:

http://article.gmane.org/gmane.comp.lang.r.general/286108

 Follow-ups here.

  Ben Bolker


From gleighton at bio.miami.edu  Sat Feb  2 21:07:21 2013
From: gleighton at bio.miami.edu (Gavin Leighton)
Date: Sat, 2 Feb 2013 15:07:21 -0500
Subject: [R-sig-ME] GLMM using cplm package in R
Message-ID: <74bb5fbe5c395c0adeae3b32381ed9e0.squirrel@rna.bio.miami.edu>

Hi all,

I've been trying to build a glmm using cplm with a tweedie distribution. 
I tried to follow the cran specifications but can not get the following
code to run (all prereq packages have been successfully installed):

TweedieGLMM.M1 = cpglmm(COOPPERMIN ~ fSEX + fAGE + (1 | fISIS), data =
SDdata, link = 2)

The error I receive is:

Error: no valid set of coefficients has been found, please supply starting
values.

Do I need to specify an additional value in the "link" argument?  Or does
this have something to do with specifying the initial values for the
different chains?

Any insight would be appreciated.

-Gavin


-- 
Gavin Leighton
PhD. Candidate
University of Miami
1301 Memorial Drive
Coral Gables, FL
http://gavinmleighton.wix.com/gmleighton#!home/mainPage


From gabrielaagostini18 at gmail.com  Sun Feb  3 01:33:03 2013
From: gabrielaagostini18 at gmail.com (Gabriela Agostini)
Date: Sat, 2 Feb 2013 21:33:03 -0300
Subject: [R-sig-ME] Unbalance design in GLMM
Message-ID: <CALNBOCNYOawvNZZfzoLEg-YDFxDzW3qe7ffzv7RQHMvN9Sga2w@mail.gmail.com>

Hello!

I am working with GLMM using the binomial family for testing
differences in amphibian malformations that occur in several ponds
located in two different areas.
The random effects are sampled day (samplday) and pond identity
(pondident).The fixed effects are area (studyarea) and species (sp).
Ymat is the response variable.


> class(data$pondident)
[1] "factor
> class(data$samplday)
[1] "integer"

> levels(data$pondident)
 [1] "A"     "arro"  "B"     "C"     "campo" "D"     "E"     "F"     "G"
[10] "hum"
>levels(data$samplday)
NULL

> library(biology)
> is.balanced(Ymat~pondident,data=data)
[1] FALSE
> is.balanced(Ymat~pondident+samplday,data=data)
[1] FALSE

as you notice, it is an unbalanced design, so When I run the model

> GLMM.c<-lmer(Ymat~studyarea+sp+studyarea*sp+(1|samplday/pondident),data=data,family="binomial")
Error: length(f1) == length(f2) is not TRUE
Adem?s: Mensajes de aviso perdidos
1: In pondident:samplday :
  expresi?n num?rica tiene 400 elementos: solo el primero es utilizado
2: In pondident:samplday :
  expresi?n num?rica tiene 400 elementos: solo el primero es utilizado

You can help me? I could not find the solution for unbalanced designs
applied to generalized models

Gracias!
Gabriela










-- 
Lic. Mar?a Gabriela Agostini


CIMA. Centro de Investigaciones del Medio Ambiente.

Facultad de Ciencias Exactas. UNLP

47 y 115 s/n (1900) La Plata. Argentina


Conservaci?n de Anfibios en Agroecosistemas

Sapos y Ranas del Fondo de tu Casa

http://www.facebook.com/saposyranasdelfondodetucasa


From bbolker at gmail.com  Sun Feb  3 06:04:24 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 3 Feb 2013 05:04:24 +0000 (UTC)
Subject: [R-sig-ME] Unbalance design in GLMM
References: <CALNBOCNYOawvNZZfzoLEg-YDFxDzW3qe7ffzv7RQHMvN9Sga2w@mail.gmail.com>
Message-ID: <loom.20130203T055828-335@post.gmane.org>

Gabriela Agostini <gabrielaagostini18 at ...> writes:

> differences in amphibian malformations that occur in several ponds
> located in two different areas.
> The random effects are sampled day (samplday) and pond identity
> (pondident).The fixed effects are area (studyarea) and species (sp).
> Ymat is the response variable.
> 
> > class(data$pondident)
> [1] "factor
> > class(data$samplday)
> [1] "integer"

 Try making samplday a factor ... In fact, your error is the
second one listed under http://glmm.wikidot.com/faq#errors , and
making the grouping variables a factor is the suggested remedy.
> 
> > levels(data$pondident)
>  [1] "A"     "arro"  "B"     "C"     "campo" "D"     "E"     "F"     "G"
> [10] "hum"
> >levels(data$samplday)
> NULL

 [snip]

 Lack of balance should not be a problem for GLMMs, unless it's
extreme (e.g. some completely missing combinations of fixed effects,
or all zeros or ones in some random-effect levels, i.e. 
complete separation).  In fact, unbalanced designs are one 
reason that people use 'modern' mixed models rather than
classical method-of-moments ANOVA (which has a hard time
with lack of balance).
 
> as you notice, it is an unbalanced design, so When I run the model
> 
> > GLMM.c<-lmer(Ymat~studyarea+sp+studyarea*sp+(1|samplday/pondident),
>   data=data,family="binomial")

 By the way, studyarea+sp+studyarea*sp is redundant (although
harmless).   Either

studyarea+sp+studyarea:sp  (main effects + interaction) or
studyarea*sp               (ditto, shorthand) 

should be sufficient

> Error: length(f1) == length(f2) is not TRUE
> Adem?s: Mensajes de aviso perdidos
> 1: In pondident:samplday :
>   expresi?n num?rica tiene 400 elementos: solo el primero es utilizado
> 2: In pondident:samplday :
>   expresi?n num?rica tiene 400 elementos: solo el primero es utilizado


From jwiley.psych at gmail.com  Mon Feb  4 01:30:48 2013
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Sun, 3 Feb 2013 16:30:48 -0800
Subject: [R-sig-ME] SEs for prediction?
Message-ID: <CANz9Z_K1OZj7sAwt_paS3_LEsHRY3k_qYrQV6n_ZVa10cPg5nw@mail.gmail.com>

Hi All,

I have some LMMs fit with lme  (EEG measures on different brain
regions which require a non independent residual covariance structure,
on kids, nested within families).  The random effects are just
nuisance effects in this case.  The study PI would like adjusted means
for different conditions and standard errors.

Now I know that there is not a simple way of calculating accurate SEs
for prediction, but before I roll my own code to draw from the
posterior, bootstrap, or just move the whole analysis to a Bayesian
framework, I wondered if others had crossed this bridge and had a any
suggestions for a quick and dirty approach.  The SEs are just being
used in presentation with the adjusted means, not really the model or
inference, so I am not terribly concerned about them being optimal.

Thanks as always for input,

Josh


--
Joshua Wiley
Ph.D. Student, Health Psychology
Programmer Analyst II, Statistical Consulting Group
University of California, Los Angeles
https://joshuawiley.com/


From torvon at gmail.com  Mon Feb  4 14:09:48 2013
From: torvon at gmail.com (Torvon)
Date: Mon, 4 Feb 2013 14:09:48 +0100
Subject: [R-sig-ME] Standard Errors and Confidence Intervals
Message-ID: <CACm_P7qHDoxF6=uHbBOG_ckPUK9S91_DK+qwth8ReJBG2GqN2g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130204/1c7dc88b/attachment.pl>

From laurent_step at yahoo.fr  Mon Feb  4 15:42:53 2013
From: laurent_step at yahoo.fr (laurent stephane)
Date: Mon, 4 Feb 2013 14:42:53 +0000 (GMT)
Subject: [R-sig-ME] Standard Errors and Confidence Intervals
In-Reply-To: <CACm_P7qHDoxF6=uHbBOG_ckPUK9S91_DK+qwth8ReJBG2GqN2g@mail.gmail.com>
References: <CACm_P7qHDoxF6=uHbBOG_ckPUK9S91_DK+qwth8ReJBG2GqN2g@mail.gmail.com>
Message-ID: <1359988973.2659.YahooMailNeo@web171706.mail.ir2.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130204/6345dde5/attachment.pl>

From highstat at highstat.com  Mon Feb  4 23:45:09 2013
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Mon, 04 Feb 2013 22:45:09 +0000
Subject: [R-sig-ME] Banff Canada: Mixed modelling course
Message-ID: <511039F5.2010306@highstat.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130204/03a9b0ec/attachment.pl>

From gabrielaagostini18 at gmail.com  Tue Feb  5 17:58:36 2013
From: gabrielaagostini18 at gmail.com (Gabriela Agostini)
Date: Tue, 5 Feb 2013 13:58:36 -0300
Subject: [R-sig-ME] interactions in fixed effects
Message-ID: <CALNBOCP4W8hZapNLz28_9PFo8_fvAEiy9+uCZtm2T+zMi7b3yg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130205/d4991d26/attachment.pl>

From jwiley.psych at gmail.com  Tue Feb  5 19:37:03 2013
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Tue, 5 Feb 2013 10:37:03 -0800
Subject: [R-sig-ME] interactions in fixed effects
In-Reply-To: <CALNBOCP4W8hZapNLz28_9PFo8_fvAEiy9+uCZtm2T+zMi7b3yg@mail.gmail.com>
References: <CALNBOCP4W8hZapNLz28_9PFo8_fvAEiy9+uCZtm2T+zMi7b3yg@mail.gmail.com>
Message-ID: <CANz9Z_JFmZ_S+Pv+HFSB9+JLz809T5_ESuHycKE52364x848jg@mail.gmail.com>

Tests of the significance of random effects are notoriously
problematic, but for your question on glm(), try:

anova(GLM0, GLM1, test="LRT")

see the docs for anova for more details.

Cheers,

Josh

On Tue, Feb 5, 2013 at 8:58 AM, Gabriela Agostini
<gabrielaagostini18 at gmail.com> wrote:
> Hello
>
> I am working whit GLMM (binomial family) in lme4. In order to test
> differences between amphibian parasitic infections in two study sites, I am
> using a model consisting of two fixed effects ("sa" and "sp" ) and a random
> effects ("sdy"). After testing the significance of the random effect, I
> chose to use GLM  based on the same error structure and variables. My
> problem is: when I try to explore the interaction between two fixed
> effects, anova () does not show the values of Chi and the probability value.
>
> I am sorry for my question, maybe this is a bit basic. But I could not get
> these results.
>
> Thanks!
>
>  names(data)
> [1] "sa"  "sdy"  "sp"  "inf"  "noinf"
>> ### sa(study area)
>> ### ps(species)
>> ### sdy(sample day)
>> ### inf(individual infected)
>> ### noinf(individual non infected)
>
>> class(data$sa)
> [1] "factor"
>> levels(data$sa)
> [1] "cult" "ref"
>> class(data$sp)
> [1] "factor"
>> levels(data$sp)
> [1] "hpa" "lla" "llj" "rfa"
>
>> library(lme4)
>
>> data$Ymat<-cbind(data$inf,data$noinf-data$inf)
>> GLM0<-glm(Ymat~sa+sp+sa*sp,data=data,family=binomial)
>> summary(GLM0)
>
> Call:
> glm(formula = Ymat ~ sa + sp + sa * sp, family = binomial, data = data)
>
> Deviance Residuals:
>     Min       1Q   Median       3Q      Max
> -2.2910  -0.8011   0.0000   0.6543   2.5593
>
> Coefficients:
>             Estimate Std. Error z value Pr(>|z|)
> (Intercept) -2.18122    0.19937 -10.941  < 2e-16 ***
> saref       -1.43460    0.36483  -3.932 8.42e-05 ***
> splla        1.82021    0.33694   5.402 6.58e-08 ***
> spllj        2.09878    0.20676  10.151  < 2e-16 ***
> sprfa        2.10572    0.24216   8.696  < 2e-16 ***
> saref:splla -0.08470    0.57874  -0.146    0.884
> saref:spllj -0.01143    0.37498  -0.030    0.976
> saref:sprfa -0.47644    0.43437  -1.097    0.273
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> (Dispersion parameter for binomial family taken to be 1)
>
>     Null deviance: 1013.00  on 363  degrees of freedom
> Residual deviance:  355.21  on 356  degrees of freedom
> AIC: 935.48
>
> Number of Fisher Scoring iterations: 5
>
>> GLM1<-glm(Ymat~sa+sp,data=data,family=binomial)
>> anova(GLM0,GLM1)
> Analysis of Deviance Table
>
> Model 1: Ymat ~ sa + sp
> Model 2: Ymat ~ sa + sp + sa * sp
>   Resid. Df Resid. Dev Df Deviance
> 1       359     358.80
> 2       356     355.21  3   3.5908
>
>
> Thanks!!!
>
>         [[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
Joshua Wiley
Ph.D. Student, Health Psychology
Programmer Analyst II, Statistical Consulting Group
University of California, Los Angeles
https://joshuawiley.com/


From dcarov at gmail.com  Tue Feb  5 19:38:26 2013
From: dcarov at gmail.com (Daniel Caro)
Date: Tue, 5 Feb 2013 18:38:26 +0000
Subject: [R-sig-ME] lmer - BLUP prediction intervals
In-Reply-To: <CAMeQTh3WwXvEGoeUEPS8ZXbbBWHMA57b9otav5WsQYQ+my6u-g@mail.gmail.com>
References: <CAMeQTh3WwXvEGoeUEPS8ZXbbBWHMA57b9otav5WsQYQ+my6u-g@mail.gmail.com>
Message-ID: <CAMeQTh01tx3XtqdeNYh8=gcwvPh4PVw+=Qrju-bmvg=TkcONdg@mail.gmail.com>

Dear all

I have a model that looks like this:

m1 <- lmer(Difference ~ 1+  (1|Examiner) + (1|Item), data=englisho.data)

I know it is not possible to estimate random effects but one can
obtain BLUPs of the conditional modes with

re1 <- ranef(m1, postVar=T)

And then dotplot(re1) for the examiner and item levels gives me a nice
prediction interval. But I would like to have the prediction interval
for the individual intercepts, not the conditional modes of the random
effects, that is, the fixed effect (overall estimated intercept) + the
conditional mode of the random effect (examiner or item level). Does
this make sense? And if so, how would I calculate this? I'd like to do
the same thing to obtain prediction intervals of individual growth
rates in longitudinal models (i.e., overall growth rate + random
effect).

Many thanks for your help,
Daniel


From HDoran at air.org  Tue Feb  5 19:49:09 2013
From: HDoran at air.org (Doran, Harold)
Date: Tue, 5 Feb 2013 13:49:09 -0500
Subject: [R-sig-ME] [R] lmer - BLUP prediction intervals
In-Reply-To: <loom.20130205T192133-238@post.gmane.org>
References: <CAMeQTh3WwXvEGoeUEPS8ZXbbBWHMA57b9otav5WsQYQ+my6u-g@mail.gmail.com>
	<loom.20130205T192133-238@post.gmane.org>
Message-ID: <686DF18D10EF1C428C2760321FB5B69E07733386F6@DC1VEX07MB001.air.org>

Ben,

I'm not sure the predictions of the conditional modes and the estimates of the fixed effects are orthogonal. I don't think it's possible to spit out that covariance from lmer(), though I could be wrong. 

My own software for fitting mixed models uses henderson's method. Under this framework, I output the matrix giving the covariance between the fixed effects and the BLUPs.
The easiest way to see thi is to go to this wiki page and look at the eqn under estimation. 

The matrix in the upper right block (X'R^{-1}Z) is the one giving those covariances.

http://en.wikipedia.org/wiki/Mixed_model

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
> On Behalf Of Ben Bolker
> Sent: Tuesday, February 05, 2013 1:31 PM
> To: r-help at stat.math.ethz.ch
> Subject: Re: [R] lmer - BLUP prediction intervals
> 
> Daniel Caro <dcarov <at> gmail.com> writes:
> 
> >
> > Dear all
> >
> > I have a model that looks like this:
> >
> > m1 <- lmer(Difference ~ 1+  (1|Examiner) + (1|Item),
> > data=englisho.data)
> >
> > I know it is not possible to estimate random effects but one can
> > obtain BLUPs of the conditional modes with
> >
> > re1 <- ranef(m1, postVar=T)
> >
> > And then dotplot(re1) for the examiner and item levels gives me a nice
> > prediction interval. But I would like to have the prediction interval
> > for the individual intercepts, not the conditional modes of the random
> > effects, that is, the fixed effect (overall estimated intercept) + the
> > conditional mode of the random effect (examiner or item level). Does
> > this make sense? And if so, how would I calculate this? I'd like to do
> > the same thing to obtain prediction intervals of individual growth
> > rates in longitudinal models (i.e., overall growth rate + random
> > effect).
> 
>   I think this belongs on the r-sig-mixed-models at r-project.org list.
> Could you please re-post it there?  (I would redirect it myself but am reading
> via gmane ...)  For a start, I would probably assume independence of the
> uncertainty in the conditional modes and in the overall slope parameter and
> compute the overall variance by adding the variances ... ?  (Not sure that's
> right.)
> 
>   Ben Bolker
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bates at stat.wisc.edu  Tue Feb  5 20:34:39 2013
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 5 Feb 2013 13:34:39 -0600
Subject: [R-sig-ME] [R] lmer - BLUP prediction intervals
In-Reply-To: <686DF18D10EF1C428C2760321FB5B69E07733386F6@DC1VEX07MB001.air.org>
References: <CAMeQTh3WwXvEGoeUEPS8ZXbbBWHMA57b9otav5WsQYQ+my6u-g@mail.gmail.com>
	<loom.20130205T192133-238@post.gmane.org>
	<686DF18D10EF1C428C2760321FB5B69E07733386F6@DC1VEX07MB001.air.org>
Message-ID: <CAO7JsnSYu3hmgoS-dFE9+SVpH1LBuNcDnauyTi3KDJwApisung@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130205/5f7052e2/attachment.pl>

From A.Robinson at ms.unimelb.edu.au  Tue Feb  5 21:14:54 2013
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Wed, 6 Feb 2013 07:14:54 +1100
Subject: [R-sig-ME] [R] lmer - BLUP prediction intervals
In-Reply-To: <CAO7JsnSYu3hmgoS-dFE9+SVpH1LBuNcDnauyTi3KDJwApisung@mail.gmail.com>
References: <CAMeQTh3WwXvEGoeUEPS8ZXbbBWHMA57b9otav5WsQYQ+my6u-g@mail.gmail.com>
	<loom.20130205T192133-238@post.gmane.org>
	<686DF18D10EF1C428C2760321FB5B69E07733386F6@DC1VEX07MB001.air.org>
	<CAO7JsnSYu3hmgoS-dFE9+SVpH1LBuNcDnauyTi3KDJwApisung@mail.gmail.com>
Message-ID: <CAHyGmd7xA4auGOq5wtvwvGRDzkxetGU70retwGR5=KG-3g6BwQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130206/9e543ece/attachment.pl>

From bates at stat.wisc.edu  Tue Feb  5 21:54:54 2013
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 5 Feb 2013 14:54:54 -0600
Subject: [R-sig-ME] [R] lmer - BLUP prediction intervals
In-Reply-To: <CAHyGmd7xA4auGOq5wtvwvGRDzkxetGU70retwGR5=KG-3g6BwQ@mail.gmail.com>
References: <CAMeQTh3WwXvEGoeUEPS8ZXbbBWHMA57b9otav5WsQYQ+my6u-g@mail.gmail.com>
	<loom.20130205T192133-238@post.gmane.org>
	<686DF18D10EF1C428C2760321FB5B69E07733386F6@DC1VEX07MB001.air.org>
	<CAO7JsnSYu3hmgoS-dFE9+SVpH1LBuNcDnauyTi3KDJwApisung@mail.gmail.com>
	<CAHyGmd7xA4auGOq5wtvwvGRDzkxetGU70retwGR5=KG-3g6BwQ@mail.gmail.com>
Message-ID: <CAO7JsnRKB+EoHPSY7GoQk7-6qAgL0+8tH43x5Si2Ex2Nd0QXDQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130205/85bc5095/attachment.pl>

From dcarov at gmail.com  Wed Feb  6 00:54:15 2013
From: dcarov at gmail.com (Daniel Caro)
Date: Tue, 5 Feb 2013 23:54:15 +0000
Subject: [R-sig-ME] [R] lmer - BLUP prediction intervals
In-Reply-To: <CAO7JsnRKB+EoHPSY7GoQk7-6qAgL0+8tH43x5Si2Ex2Nd0QXDQ@mail.gmail.com>
References: <CAMeQTh3WwXvEGoeUEPS8ZXbbBWHMA57b9otav5WsQYQ+my6u-g@mail.gmail.com>
	<loom.20130205T192133-238@post.gmane.org>
	<686DF18D10EF1C428C2760321FB5B69E07733386F6@DC1VEX07MB001.air.org>
	<CAO7JsnSYu3hmgoS-dFE9+SVpH1LBuNcDnauyTi3KDJwApisung@mail.gmail.com>
	<CAHyGmd7xA4auGOq5wtvwvGRDzkxetGU70retwGR5=KG-3g6BwQ@mail.gmail.com>
	<CAO7JsnRKB+EoHPSY7GoQk7-6qAgL0+8tH43x5Si2Ex2Nd0QXDQ@mail.gmail.com>
Message-ID: <CAMeQTh1LKvnEdiM8NKe37KAtQ=pC4NWrTSPNvRx_R97Exk6RzA@mail.gmail.com>

Dear all

I have not been able to follow the discussion. But I would like to
know if it makes sense to calculate prediction intervals like this:

var(fixed effect+random effect)= var(fixed effect) + var(random
effect) + 0 (i.e., the cov is zero)

and based on this create the prediction intervals. Does this make sense?

All the best,
Daniel

On Tue, Feb 5, 2013 at 8:54 PM, Douglas Bates <bates at stat.wisc.edu> wrote:
> On Tue, Feb 5, 2013 at 2:14 PM, Andrew Robinson <
> A.Robinson at ms.unimelb.edu.au> wrote:
>
>> I'd have thought that the joint correlation matrix would be of the
>> estimates of the fixed effects and the random effects, rather than the
>> things themselves.
>>
>
> Well, it may be because I have turned into a grumpy old man but I get picky
> about terminology and the random effects are not parameters - they are
> unobserved random variables.  They don't have "estimates" in the sense of
> parameter estimates.  The quantities returned by the ranef function are the
> conditional means (in the case of a linear mixed model, conditional modes
> in general) of the random effects given the observed data evaluated with
> the parameters at their estimated values. In the Bayesian point of view
> none of this is problematic because they're all random variables but
> otherwise I struggle with the interpretation of how these can be considered
> jointly.   If you want to consider the distribution of the random effects
> you need to have known values of the parameters.
>
>
>> The estimates are statistical quantities, with specified distributions,
>> under the model.  The model posits these different roles (parameter, random
>> variable) for the quantities that are the targets of the estimates, but the
>> estimates are just estimates, and as such, they have a correlation
>> structure under the model, and that correlation structure can be estimated.
>>
>> An imperfect analogy from least-squares regression is the correlation
>> structure of residual estimates, induced by the model.  We say that the
>> errors are independent, but the model creates a (modest) correlation
>> structure than can be measured, again, conditional on the model.
>>
>
> Well the residuals are random variables and we can show that at the least
> squares estimates of the parameters they will have a known Gaussian
> distribution which, it turns out, doesn't depend on the values of the
> coefficients.  But those are the easy cases.  In the linear mixed model we
> still have a Gaussian distribution and a linear predictor but that is for
> the conditional distribution of the response given the random effects.  For
> the complete model things get much messier.
>
> I'm not making these points just to be difficult.  I have spent a lot of
> time thinking about these models and trying to come up with a coherent way
> of describing them.  Along the way I have come to the conclusion that the
> way these models are often described is, well, wrong.  And those
> descriptions include some that I have written.  For example, you often see
> the model described as the linear predictor for an observation plus a
> "noise" term, epsilon, and the statement that the distribution of the
> random effects is independent of the distribution of the noise term.  I now
> view the linear predictor as a part of the conditional distribution of the
> response given the random effects so it wouldn't make sense to talk about
> these distributions being independent.  The biggest pitfall in transferring
> your thinking from a linear model to any other kind (GLM, LMM, GLMM) is the
> fact that we can make sense of a Gaussian distribution minus its mean so we
> write the linear model in the "signal plus noise" form as Y = X\beta +
> \epsilon where Y is an n-dimensional random variable, X is the n by p model
> matrix, \beta is the p-dimensional vector of coefficients and \epsilon is
> an n-dimensional Gaussian with mean zero.  That doesn't work in the other
> cases, despite the heroic attempts of many people to write things in that
> way.
>
> Here endeth the sermon.
>
>
>> On Wed, Feb 6, 2013 at 6:34 AM, Douglas Bates <bates at stat.wisc.edu> wrote:
>>
>>> It is possible to create the correlation matrix of the fixed effects and
>>> the random effects jointly using the results from lmer but I have
>>> difficulty deciding what this would represent statistically.  If you adopt
>>> a Bayesian approach then everything works because the fixed effects and
>>> the
>>> random effects are both random variables.  In the classical statistical
>>> approach (i.e. sampling theory), however, I haven't been able to make
>>> sense
>>> of the relationship between a model parameter and an unobserved random
>>> variable.  They exist in different worlds.  You can talk about the
>>> probability model for the random effects and describe the conditional
>>> distribution of the random effects given the observed data and assumed
>>> values of the parameters.  Remember that in probability land the
>>> parameters
>>> are known.  You can also talk about the distribution of the estimators of
>>> the parameters given the observed data.  But I am at a loss to describe a
>>> combination of parameter estimators and a conditional distribution given
>>> the observed data with known parameters.
>>>
>>> I appreciate that people want to know these quantities but without a
>>> Bayesian model I can't think of what they are.
>>>
>>>
>>> On Tue, Feb 5, 2013 at 12:49 PM, Doran, Harold <HDoran at air.org> wrote:
>>>
>>> > Ben,
>>> >
>>> > I'm not sure the predictions of the conditional modes and the estimates
>>> of
>>> > the fixed effects are orthogonal. I don't think it's possible to spit
>>> out
>>> > that covariance from lmer(), though I could be wrong.
>>> >
>>> > My own software for fitting mixed models uses henderson's method. Under
>>> > this framework, I output the matrix giving the covariance between the
>>> fixed
>>> > effects and the BLUPs.
>>> > The easiest way to see thi is to go to this wiki page and look at the
>>> eqn
>>> > under estimation.
>>> >
>>> > The matrix in the upper right block (X'R^{-1}Z) is the one giving those
>>> > covariances.
>>> >
>>> > http://en.wikipedia.org/wiki/Mixed_model
>>> >
>>> > > -----Original Message-----
>>> > > From: r-help-bounces at r-project.org [mailto:
>>> r-help-bounces at r-project.org]
>>> > > On Behalf Of Ben Bolker
>>> > > Sent: Tuesday, February 05, 2013 1:31 PM
>>> > > To: r-help at stat.math.ethz.ch
>>> > > Subject: Re: [R] lmer - BLUP prediction intervals
>>> > >
>>> > > Daniel Caro <dcarov <at> gmail.com> writes:
>>> > >
>>> > > >
>>> > > > Dear all
>>> > > >
>>> > > > I have a model that looks like this:
>>> > > >
>>> > > > m1 <- lmer(Difference ~ 1+  (1|Examiner) + (1|Item),
>>> > > > data=englisho.data)
>>> > > >
>>> > > > I know it is not possible to estimate random effects but one can
>>> > > > obtain BLUPs of the conditional modes with
>>> > > >
>>> > > > re1 <- ranef(m1, postVar=T)
>>> > > >
>>> > > > And then dotplot(re1) for the examiner and item levels gives me a
>>> nice
>>> > > > prediction interval. But I would like to have the prediction
>>> interval
>>> > > > for the individual intercepts, not the conditional modes of the
>>> random
>>> > > > effects, that is, the fixed effect (overall estimated intercept) +
>>> the
>>> > > > conditional mode of the random effect (examiner or item level). Does
>>> > > > this make sense? And if so, how would I calculate this? I'd like to
>>> do
>>> > > > the same thing to obtain prediction intervals of individual growth
>>> > > > rates in longitudinal models (i.e., overall growth rate + random
>>> > > > effect).
>>> > >
>>> > >   I think this belongs on the r-sig-mixed-models at r-project.org list.
>>> > > Could you please re-post it there?  (I would redirect it myself but am
>>> > reading
>>> > > via gmane ...)  For a start, I would probably assume independence of
>>> the
>>> > > uncertainty in the conditional modes and in the overall slope
>>> parameter
>>> > and
>>> > > compute the overall variance by adding the variances ... ?  (Not sure
>>> > that's
>>> > > right.)
>>> > >
>>> > >   Ben Bolker
>>> > >
>>> > > ______________________________________________
>>> > > R-help at r-project.org mailing list
>>> > > https://stat.ethz.ch/mailman/listinfo/r-help
>>> > > PLEASE do read the posting guide http://www.R-project.org/posting-
>>> > > guide.html
>>> > > and provide commented, minimal, self-contained, reproducible code.
>>> >
>>> > _______________________________________________
>>> > R-sig-mixed-models at r-project.org mailing list
>>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> >
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>>
>>
>> --
>> Andrew Robinson
>> Director (A/g), ACERA
>> Senior Lecturer in Applied Statistics                      Tel:
>> +61-3-8344-6410
>> Department of Mathematics and Statistics            Fax: +61-3-8344 4599
>> University of Melbourne, VIC 3010 Australia
>> Email: a.robinson at ms.unimelb.edu.au    Website:
>> http://www.ms.unimelb.edu.au
>>
>> FAwR: http://www.ms.unimelb.edu.au/~andrewpr/FAwR/
>> SPuR: http://www.ms.unimelb.edu.au/spuRs/
>>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From A.Robinson at ms.unimelb.edu.au  Wed Feb  6 03:15:17 2013
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Wed, 6 Feb 2013 13:15:17 +1100
Subject: [R-sig-ME] [R] lmer - BLUP prediction intervals
In-Reply-To: <CAMeQTh1LKvnEdiM8NKe37KAtQ=pC4NWrTSPNvRx_R97Exk6RzA@mail.gmail.com>
References: <CAMeQTh3WwXvEGoeUEPS8ZXbbBWHMA57b9otav5WsQYQ+my6u-g@mail.gmail.com>
	<loom.20130205T192133-238@post.gmane.org>
	<686DF18D10EF1C428C2760321FB5B69E07733386F6@DC1VEX07MB001.air.org>
	<CAO7JsnSYu3hmgoS-dFE9+SVpH1LBuNcDnauyTi3KDJwApisung@mail.gmail.com>
	<CAHyGmd7xA4auGOq5wtvwvGRDzkxetGU70retwGR5=KG-3g6BwQ@mail.gmail.com>
	<CAO7JsnRKB+EoHPSY7GoQk7-6qAgL0+8tH43x5Si2Ex2Nd0QXDQ@mail.gmail.com>
	<CAMeQTh1LKvnEdiM8NKe37KAtQ=pC4NWrTSPNvRx_R97Exk6RzA@mail.gmail.com>
Message-ID: <CAHyGmd5GhyA8yf8SkK-i=H=5QWxYNTeXDFxxiGoz3H+qB+TR8g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130206/b37bac34/attachment.pl>

From A.Robinson at ms.unimelb.edu.au  Wed Feb  6 03:25:05 2013
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Wed, 6 Feb 2013 13:25:05 +1100
Subject: [R-sig-ME] [R] lmer - BLUP prediction intervals
In-Reply-To: <CAO7JsnRKB+EoHPSY7GoQk7-6qAgL0+8tH43x5Si2Ex2Nd0QXDQ@mail.gmail.com>
References: <CAMeQTh3WwXvEGoeUEPS8ZXbbBWHMA57b9otav5WsQYQ+my6u-g@mail.gmail.com>
	<loom.20130205T192133-238@post.gmane.org>
	<686DF18D10EF1C428C2760321FB5B69E07733386F6@DC1VEX07MB001.air.org>
	<CAO7JsnSYu3hmgoS-dFE9+SVpH1LBuNcDnauyTi3KDJwApisung@mail.gmail.com>
	<CAHyGmd7xA4auGOq5wtvwvGRDzkxetGU70retwGR5=KG-3g6BwQ@mail.gmail.com>
	<CAO7JsnRKB+EoHPSY7GoQk7-6qAgL0+8tH43x5Si2Ex2Nd0QXDQ@mail.gmail.com>
Message-ID: <CAHyGmd4u8hSsOpO=AjdetZKyhG744VJuwH3PDy0N+_OMvXsZOA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130206/c4938fc6/attachment.pl>

From Adriaan.de.Jong at slu.se  Wed Feb  6 13:49:50 2013
From: Adriaan.de.Jong at slu.se (Adriaan De Jong)
Date: Wed, 6 Feb 2013 12:49:50 +0000
Subject: [R-sig-ME] AIC(c) tables from a set of glmer (lme4) models
Message-ID: <4A3F286665AD3D488D56FDFAC7D8CE430C1F1D94@exchange2-1>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130206/7eb2170a/attachment.pl>

From curis at pharmacie.univ-paris5.fr  Wed Feb  6 09:39:24 2013
From: curis at pharmacie.univ-paris5.fr (Emmanuel Curis)
Date: Wed, 6 Feb 2013 09:39:24 +0100
Subject: [R-sig-ME] [R] lmer - BLUP prediction intervals
In-Reply-To: <CAHyGmd5GhyA8yf8SkK-i=H=5QWxYNTeXDFxxiGoz3H+qB+TR8g@mail.gmail.com>
References: <CAMeQTh3WwXvEGoeUEPS8ZXbbBWHMA57b9otav5WsQYQ+my6u-g@mail.gmail.com>
	<loom.20130205T192133-238@post.gmane.org>
	<686DF18D10EF1C428C2760321FB5B69E07733386F6@DC1VEX07MB001.air.org>
	<CAO7JsnSYu3hmgoS-dFE9+SVpH1LBuNcDnauyTi3KDJwApisung@mail.gmail.com>
	<CAHyGmd7xA4auGOq5wtvwvGRDzkxetGU70retwGR5=KG-3g6BwQ@mail.gmail.com>
	<CAO7JsnRKB+EoHPSY7GoQk7-6qAgL0+8tH43x5Si2Ex2Nd0QXDQ@mail.gmail.com>
	<CAMeQTh1LKvnEdiM8NKe37KAtQ=pC4NWrTSPNvRx_R97Exk6RzA@mail.gmail.com>
	<CAHyGmd5GhyA8yf8SkK-i=H=5QWxYNTeXDFxxiGoz3H+qB+TR8g@mail.gmail.com>
Message-ID: <20130206083924.GA18993@laboinfo-063.pharmacie.univ-paris5.fr>

Hello,

I think it also depends on what kind of prediction you want to make,
assuming continuous predictors --- at least if I well understood the
mixed effect models ideas...

For instance, imagine you fit a model on several patients for let's
say drug concentration with time, assuming patient as a random effect
on concentration.

If you want to use the model to predict for a new patient, the
approach of adding the variance component of the patient random effect
to the variance of the residuals should work, I guess.

However, if you want to use the model to predict concentrations for
one of the patients already in the model, for a new administration for
instance or intermediate times or..., I think the use of its random
effect ? estimate ? would be more suited. I think this is more in this
second case that the concern between ranef outputs and estimates ?
correlations ? occurs, no? In the previous one, this would be the
correlation between the estimate of the residual & random effect
variances and the fixed effects estimates that would matter --- Am I
wrong saying that all of these are estimates, including the variance
and eventually covariance terms?

Best regards,

On Wed, Feb 06, 2013 at 01:15:17PM +1100, Andrew Robinson wrote:
? I think that it is a reasonable way to proceed just so long as you
? interpret the intervals guardedly and document your assumptions carefully.
? 
? Cheers
? 
? Andrew
? 
? On Wednesday, February 6, 2013, Daniel Caro wrote:
? 
? > Dear all
? >
? > I have not been able to follow the discussion. But I would like to
? > know if it makes sense to calculate prediction intervals like this:
? >
? > var(fixed effect+random effect)= var(fixed effect) + var(random
? > effect) + 0 (i.e., the cov is zero)
? >
? > and based on this create the prediction intervals. Does this make sense?
? >
? > All the best,
? > Daniel
? >
? > On Tue, Feb 5, 2013 at 8:54 PM, Douglas Bates <bates at stat.wisc.edu> wrote:
? > > On Tue, Feb 5, 2013 at 2:14 PM, Andrew Robinson <
? > > A.Robinson at ms.unimelb.edu.au> wrote:
? > >
? > >> I'd have thought that the joint correlation matrix would be of the
? > >> estimates of the fixed effects and the random effects, rather than the
? > >> things themselves.
? > >>
? > >
? > > Well, it may be because I have turned into a grumpy old man but I get
? > picky
? > > about terminology and the random effects are not parameters - they are
? > > unobserved random variables.  They don't have "estimates" in the sense of
? > > parameter estimates.  The quantities returned by the ranef function are
? > the
? > > conditional means (in the case of a linear mixed model, conditional modes
? > > in general) of the random effects given the observed data evaluated with
? > > the parameters at their estimated values. In the Bayesian point of view
? > > none of this is problematic because they're all random variables but
? > > otherwise I struggle with the interpretation of how these can be
? > considered
? > > jointly.   If you want to consider the distribution of the random effects
? > > you need to have known values of the parameters.
? > >
? > >
? > >> The estimates are statistical quantities, with specified distributions,
? > >> under the model.  The model posits these different roles (parameter,
? > random
? > >> variable) for the quantities that are the targets of the estimates, but
? > the
? > >> estimates are just estimates, and as such, they have a correlation
? > >> structure under the model, and that correlation structure can be
? > estimated.
? > >>
? > >> An imperfect analogy from least-squares regression is the correlation
? > >> structure of residual estimates, induced by the model.  We say that the
? > >> errors are independent, but the model creates a (modest) correlation
? > >> structure than can be measured, again, conditional on the model.
? > >>
? > >
? > > Well the residuals are random variables and we can show that at the least
? > > squares estimates of the parameters they will have a known Gaussian
? > > distribution which, it turns out, doesn't depend on the values of the
? > > coefficients.  But those are the easy cases.  In the linear mixed model
? > we
? > > still have a Gaussian distribution and a linear predictor but that is for
? > > the conditional distribution of the response given the random effects.
? >  For
? > > the complete model things get much messier.
? > >
? > > I'm not making these points just to be difficult.  I have spent a lot of
? > > time thinking about these models and trying to come up with a coherent
? > way
? > > of describing them.  Along the way I have come to the conclusion that the
? > > way these models are often described is, well, wrong.  And those
? > > descriptions include some that I have written.  For example, you often
? > see
? > > the model described as the linear predictor for an observation plus a
? > > "noise" term, epsilon, and the statement that the distribution of the
? > > random effects is independent of the distribution of the noise term.  I
? > now
? > > view the linear predictor as a part of the conditional distribution of
? > the
? > > response given the random effects so it wouldn't make sense to talk about
? > > these distributions being independent.  The biggest pitfall in
? > transferring
? > > your thinking from a linear model to any other kind (GLM, LMM, GLMM) is
? > the
? > > fact that we can make sense of a Gaussian distribution minus its mean so
? > we
? > > write the linear model in the "signal plus noise" form as Y = X\beta +
? > > \epsilon where Y is an n-dimensional random variable, X is the n by p
? > model
? > > matrix, \beta is the p-dimensional vector of coefficients and \epsilon is
? > > an n-dimensional Gaussian with mean zero.  That doesn't work in the other
? > > cases, despite the heroic attempts of many people to write things in that
? > > way.
? > >
? > > Here endeth the sermon.
? > >
? > >
? > >> On Wed, Feb 6, 2013 at 6:34 AM, Douglas Bates <bates at stat.wisc.edu>
? > wrote:
? > >>
? > >>> It is possible to create the correlation matrix of the fixed effects
? > and
? > >>> the random effects jointly using the results from lmer but I have
? > >>> difficulty deciding what this would represent statistically.  If you
? > adopt
? > >>> a B
? 
? 
? 
? -- 
? Andrew Robinson
? Director (A/g), ACERA
? Senior Lecturer in Applied Statistics                      Tel:
? +61-3-8344-6410
? Department of Mathematics and Statistics            Fax: +61-3-8344 4599
? University of Melbourne, VIC 3010 Australia
? Email: a.robinson at ms.unimelb.edu.au    Website: http://www.ms.unimelb.edu.au
? 
? FAwR: http://www.ms.unimelb.edu.au/~andrewpr/FAwR/
? SPuR: http://www.ms.unimelb.edu.au/spuRs/
? 
? 	[[alternative HTML version deleted]]
? 
? _______________________________________________
? R-sig-mixed-models at r-project.org mailing list
? https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
                                Emmanuel CURIS
                                emmanuel.curis at parisdescartes.fr

Page WWW: http://emmanuel.curis.online.fr/index.html


From HDoran at air.org  Wed Feb  6 16:36:40 2013
From: HDoran at air.org (Doran, Harold)
Date: Wed, 6 Feb 2013 10:36:40 -0500
Subject: [R-sig-ME] [R] lmer - BLUP prediction intervals
In-Reply-To: <CAHyGmd5GhyA8yf8SkK-i=H=5QWxYNTeXDFxxiGoz3H+qB+TR8g@mail.gmail.com>
References: <CAMeQTh3WwXvEGoeUEPS8ZXbbBWHMA57b9otav5WsQYQ+my6u-g@mail.gmail.com>
	<loom.20130205T192133-238@post.gmane.org>
	<686DF18D10EF1C428C2760321FB5B69E07733386F6@DC1VEX07MB001.air.org>
	<CAO7JsnSYu3hmgoS-dFE9+SVpH1LBuNcDnauyTi3KDJwApisung@mail.gmail.com>
	<CAHyGmd7xA4auGOq5wtvwvGRDzkxetGU70retwGR5=KG-3g6BwQ@mail.gmail.com>
	<CAO7JsnRKB+EoHPSY7GoQk7-6qAgL0+8tH43x5Si2Ex2Nd0QXDQ@mail.gmail.com>
	<CAMeQTh1LKvnEdiM8NKe37KAtQ=pC4NWrTSPNvRx_R97Exk6RzA@mail.gmail.com>
	<CAHyGmd5GhyA8yf8SkK-i=H=5QWxYNTeXDFxxiGoz3H+qB+TR8g@mail.gmail.com>
Message-ID: <686DF18D10EF1C428C2760321FB5B69E0773338B06@DC1VEX07MB001.air.org>

Andrew

Ignoring the important theoretical question for just a moment on whether it is sensible to do this, there is a covariance term between the BLUPs and the fixed effects. 

If that term exists under the model, but it is ignored for purposes of variance estimation, what would be the reason for doing so?

> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-
> models-bounces at r-project.org] On Behalf Of Andrew Robinson
> Sent: Tuesday, February 05, 2013 9:15 PM
> To: dcarov at gmail.com
> Cc: r-sig-mixed-models at r-project.org; Ben Bolker
> Subject: Re: [R-sig-ME] [R] lmer - BLUP prediction intervals
> 
> I think that it is a reasonable way to proceed just so long as you interpret the
> intervals guardedly and document your assumptions carefully.
> 
> Cheers
> 
> Andrew
> 
> On Wednesday, February 6, 2013, Daniel Caro wrote:
> 
> > Dear all
> >
> > I have not been able to follow the discussion. But I would like to
> > know if it makes sense to calculate prediction intervals like this:
> >
> > var(fixed effect+random effect)= var(fixed effect) + var(random
> > effect) + 0 (i.e., the cov is zero)
> >
> > and based on this create the prediction intervals. Does this make sense?
> >
> > All the best,
> > Daniel
> >
> > On Tue, Feb 5, 2013 at 8:54 PM, Douglas Bates <bates at stat.wisc.edu>
> wrote:
> > > On Tue, Feb 5, 2013 at 2:14 PM, Andrew Robinson <
> > > A.Robinson at ms.unimelb.edu.au> wrote:
> > >
> > >> I'd have thought that the joint correlation matrix would be of the
> > >> estimates of the fixed effects and the random effects, rather than
> > >> the things themselves.
> > >>
> > >
> > > Well, it may be because I have turned into a grumpy old man but I
> > > get
> > picky
> > > about terminology and the random effects are not parameters - they
> > > are unobserved random variables.  They don't have "estimates" in the
> > > sense of parameter estimates.  The quantities returned by the ranef
> > > function are
> > the
> > > conditional means (in the case of a linear mixed model, conditional
> > > modes in general) of the random effects given the observed data
> > > evaluated with the parameters at their estimated values. In the
> > > Bayesian point of view none of this is problematic because they're
> > > all random variables but otherwise I struggle with the
> > > interpretation of how these can be
> > considered
> > > jointly.   If you want to consider the distribution of the random effects
> > > you need to have known values of the parameters.
> > >
> > >
> > >> The estimates are statistical quantities, with specified
> > >> distributions, under the model.  The model posits these different
> > >> roles (parameter,
> > random
> > >> variable) for the quantities that are the targets of the estimates,
> > >> but
> > the
> > >> estimates are just estimates, and as such, they have a correlation
> > >> structure under the model, and that correlation structure can be
> > estimated.
> > >>
> > >> An imperfect analogy from least-squares regression is the
> > >> correlation structure of residual estimates, induced by the model.
> > >> We say that the errors are independent, but the model creates a
> > >> (modest) correlation structure than can be measured, again, conditional
> on the model.
> > >>
> > >
> > > Well the residuals are random variables and we can show that at the
> > > least squares estimates of the parameters they will have a known
> > > Gaussian distribution which, it turns out, doesn't depend on the
> > > values of the coefficients.  But those are the easy cases.  In the
> > > linear mixed model
> > we
> > > still have a Gaussian distribution and a linear predictor but that
> > > is for the conditional distribution of the response given the random
> effects.
> >  For
> > > the complete model things get much messier.
> > >
> > > I'm not making these points just to be difficult.  I have spent a
> > > lot of time thinking about these models and trying to come up with a
> > > coherent
> > way
> > > of describing them.  Along the way I have come to the conclusion
> > > that the way these models are often described is, well, wrong.  And
> > > those descriptions include some that I have written.  For example,
> > > you often
> > see
> > > the model described as the linear predictor for an observation plus
> > > a "noise" term, epsilon, and the statement that the distribution of
> > > the random effects is independent of the distribution of the noise
> > > term.  I
> > now
> > > view the linear predictor as a part of the conditional distribution
> > > of
> > the
> > > response given the random effects so it wouldn't make sense to talk
> > > about these distributions being independent.  The biggest pitfall in
> > transferring
> > > your thinking from a linear model to any other kind (GLM, LMM, GLMM)
> > > is
> > the
> > > fact that we can make sense of a Gaussian distribution minus its
> > > mean so
> > we
> > > write the linear model in the "signal plus noise" form as Y = X\beta
> > > + \epsilon where Y is an n-dimensional random variable, X is the n
> > > by p
> > model
> > > matrix, \beta is the p-dimensional vector of coefficients and
> > > \epsilon is an n-dimensional Gaussian with mean zero.  That doesn't
> > > work in the other cases, despite the heroic attempts of many people
> > > to write things in that way.
> > >
> > > Here endeth the sermon.
> > >
> > >
> > >> On Wed, Feb 6, 2013 at 6:34 AM, Douglas Bates <bates at stat.wisc.edu>
> > wrote:
> > >>
> > >>> It is possible to create the correlation matrix of the fixed
> > >>> effects
> > and
> > >>> the random effects jointly using the results from lmer but I have
> > >>> difficulty deciding what this would represent statistically.  If
> > >>> you
> > adopt
> > >>> a B
> 
> 
> 
> --
> Andrew Robinson
> Director (A/g), ACERA
> Senior Lecturer in Applied Statistics                      Tel:
> +61-3-8344-6410
> Department of Mathematics and Statistics            Fax: +61-3-8344 4599
> University of Melbourne, VIC 3010 Australia
> Email: a.robinson at ms.unimelb.edu.au    Website:
> http://www.ms.unimelb.edu.au
> 
> FAwR: http://www.ms.unimelb.edu.au/~andrewpr/FAwR/
> SPuR: http://www.ms.unimelb.edu.au/spuRs/
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From tom.harris at market6.com  Wed Feb  6 18:00:07 2013
From: tom.harris at market6.com (Tom Harris)
Date: Wed, 6 Feb 2013 11:00:07 -0600
Subject: [R-sig-ME] Is there a way to input a covariance matrix (or some
 similar type of data structure) into lme4 in R?
Message-ID: <24ADA2E05DBF4248A5C8A8C7531077812D0098793F@AUSP01VMBX26.collaborationhost.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130206/be2c1625/attachment.pl>

From nrm2010 at zoho.com  Wed Feb  6 18:34:57 2013
From: nrm2010 at zoho.com (nrm2010)
Date: Wed, 06 Feb 2013 10:34:57 -0700
Subject: [R-sig-ME] Minimum number of levels for mixed model
Message-ID: <1211943845.40727.1360172097299.JavaMail.sas1@[172.29.251.236]>

Dear Mixed Modelers:

The oft-mentioned glmm wiki FAQ recommends a minimum of 5 or 6 levels
 when using a mixed model. I am not sure how to interpret this statement.  
I have 4 experimental treatments, each with 3 replicates, for a total of 12 plots.
  Measurements were made over 4 years and there are thousands of individual
 data points within each of the 12 plots.  I was planning to use nested random
 effects of plot within treatment within year. So I would have 3 replicate plots 
within each of 4 treatments within each of 4 years. 

My questions:
For nested effects, at what level does the recommendation pertain? Is it only
the lowest level?  Would 5 or 6 plots within 3 treatments within 3 years be acceptable?
Or should one have 5 or 6 plots within 5 or 6 treatments within 5 or 6 years? Is the
amount of data within plot irrelevant to this issue? 

If 4 treatments are insufficient for a mixed model, is treatment as fixed effect
the only alternative?  I need an approach for which there is a method for multiple
comparison of means.  I believe lm, lme, lme4 are the only options since the aov 
methods do not accept an Error term.

Thank you for your thoughts.

Toby Gass


From A.Robinson at ms.unimelb.edu.au  Thu Feb  7 00:28:42 2013
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Thu, 7 Feb 2013 10:28:42 +1100
Subject: [R-sig-ME] [R] lmer - BLUP prediction intervals
In-Reply-To: <686DF18D10EF1C428C2760321FB5B69E0773338B06@DC1VEX07MB001.air.org>
References: <CAMeQTh3WwXvEGoeUEPS8ZXbbBWHMA57b9otav5WsQYQ+my6u-g@mail.gmail.com>
	<loom.20130205T192133-238@post.gmane.org>
	<686DF18D10EF1C428C2760321FB5B69E07733386F6@DC1VEX07MB001.air.org>
	<CAO7JsnSYu3hmgoS-dFE9+SVpH1LBuNcDnauyTi3KDJwApisung@mail.gmail.com>
	<CAHyGmd7xA4auGOq5wtvwvGRDzkxetGU70retwGR5=KG-3g6BwQ@mail.gmail.com>
	<CAO7JsnRKB+EoHPSY7GoQk7-6qAgL0+8tH43x5Si2Ex2Nd0QXDQ@mail.gmail.com>
	<CAMeQTh1LKvnEdiM8NKe37KAtQ=pC4NWrTSPNvRx_R97Exk6RzA@mail.gmail.com>
	<CAHyGmd5GhyA8yf8SkK-i=H=5QWxYNTeXDFxxiGoz3H+qB+TR8g@mail.gmail.com>
	<686DF18D10EF1C428C2760321FB5B69E0773338B06@DC1VEX07MB001.air.org>
Message-ID: <20130206232842.GG2026@ms.unimelb.edu.au>

Hi Harold,

just pragmatism.  If the model says that there's a quantity but it's
hard to estimate, eg the software doesn't provide it, then I wouild
contend that - so long as one is honest - it's reasonable to ignore
it.

Intuitively I would expect that the correlation between the fixed
estimates and random predictions would be negative.  This is because,
in a sense, they're trying to rerepsent the same variation. I know
that you have a lot of experience and a lot of time thinking about
these models.  How does that conjecture sound to you?  If that were
the case then ignoring the correlation between them when computing a
prediction interval would be conservative.

Best wishes

Andrew



On Wed, Feb 06, 2013 at 10:36:40AM -0500, Doran, Harold wrote:
> Andrew
> 
> Ignoring the important theoretical question for just a moment on whether it is sensible to do this, there is a covariance term between the BLUPs and the fixed effects. 
> 
> If that term exists under the model, but it is ignored for purposes of variance estimation, what would be the reason for doing so?
> 
> > -----Original Message-----
> > From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-
> > models-bounces at r-project.org] On Behalf Of Andrew Robinson
> > Sent: Tuesday, February 05, 2013 9:15 PM
> > To: dcarov at gmail.com
> > Cc: r-sig-mixed-models at r-project.org; Ben Bolker
> > Subject: Re: [R-sig-ME] [R] lmer - BLUP prediction intervals
> > 
> > I think that it is a reasonable way to proceed just so long as you interpret the
> > intervals guardedly and document your assumptions carefully.
> > 
> > Cheers
> > 
> > Andrew
> > 
> > On Wednesday, February 6, 2013, Daniel Caro wrote:
> > 
> > > Dear all
> > >
> > > I have not been able to follow the discussion. But I would like to
> > > know if it makes sense to calculate prediction intervals like this:
> > >
> > > var(fixed effect+random effect)= var(fixed effect) + var(random
> > > effect) + 0 (i.e., the cov is zero)
> > >
> > > and based on this create the prediction intervals. Does this make sense?
> > >
> > > All the best,
> > > Daniel
> > >
> > > On Tue, Feb 5, 2013 at 8:54 PM, Douglas Bates <bates at stat.wisc.edu>
> > wrote:
> > > > On Tue, Feb 5, 2013 at 2:14 PM, Andrew Robinson <
> > > > A.Robinson at ms.unimelb.edu.au> wrote:
> > > >
> > > >> I'd have thought that the joint correlation matrix would be of the
> > > >> estimates of the fixed effects and the random effects, rather than
> > > >> the things themselves.
> > > >>
> > > >
> > > > Well, it may be because I have turned into a grumpy old man but I
> > > > get
> > > picky
> > > > about terminology and the random effects are not parameters - they
> > > > are unobserved random variables.  They don't have "estimates" in the
> > > > sense of parameter estimates.  The quantities returned by the ranef
> > > > function are
> > > the
> > > > conditional means (in the case of a linear mixed model, conditional
> > > > modes in general) of the random effects given the observed data
> > > > evaluated with the parameters at their estimated values. In the
> > > > Bayesian point of view none of this is problematic because they're
> > > > all random variables but otherwise I struggle with the
> > > > interpretation of how these can be
> > > considered
> > > > jointly.   If you want to consider the distribution of the random effects
> > > > you need to have known values of the parameters.
> > > >
> > > >
> > > >> The estimates are statistical quantities, with specified
> > > >> distributions, under the model.  The model posits these different
> > > >> roles (parameter,
> > > random
> > > >> variable) for the quantities that are the targets of the estimates,
> > > >> but
> > > the
> > > >> estimates are just estimates, and as such, they have a correlation
> > > >> structure under the model, and that correlation structure can be
> > > estimated.
> > > >>
> > > >> An imperfect analogy from least-squares regression is the
> > > >> correlation structure of residual estimates, induced by the model.
> > > >> We say that the errors are independent, but the model creates a
> > > >> (modest) correlation structure than can be measured, again, conditional
> > on the model.
> > > >>
> > > >
> > > > Well the residuals are random variables and we can show that at the
> > > > least squares estimates of the parameters they will have a known
> > > > Gaussian distribution which, it turns out, doesn't depend on the
> > > > values of the coefficients.  But those are the easy cases.  In the
> > > > linear mixed model
> > > we
> > > > still have a Gaussian distribution and a linear predictor but that
> > > > is for the conditional distribution of the response given the random
> > effects.
> > >  For
> > > > the complete model things get much messier.
> > > >
> > > > I'm not making these points just to be difficult.  I have spent a
> > > > lot of time thinking about these models and trying to come up with a
> > > > coherent
> > > way
> > > > of describing them.  Along the way I have come to the conclusion
> > > > that the way these models are often described is, well, wrong.  And
> > > > those descriptions include some that I have written.  For example,
> > > > you often
> > > see
> > > > the model described as the linear predictor for an observation plus
> > > > a "noise" term, epsilon, and the statement that the distribution of
> > > > the random effects is independent of the distribution of the noise
> > > > term.  I
> > > now
> > > > view the linear predictor as a part of the conditional distribution
> > > > of
> > > the
> > > > response given the random effects so it wouldn't make sense to talk
> > > > about these distributions being independent.  The biggest pitfall in
> > > transferring
> > > > your thinking from a linear model to any other kind (GLM, LMM, GLMM)
> > > > is
> > > the
> > > > fact that we can make sense of a Gaussian distribution minus its
> > > > mean so
> > > we
> > > > write the linear model in the "signal plus noise" form as Y = X\beta
> > > > + \epsilon where Y is an n-dimensional random variable, X is the n
> > > > by p
> > > model
> > > > matrix, \beta is the p-dimensional vector of coefficients and
> > > > \epsilon is an n-dimensional Gaussian with mean zero.  That doesn't
> > > > work in the other cases, despite the heroic attempts of many people
> > > > to write things in that way.
> > > >
> > > > Here endeth the sermon.
> > > >
> > > >
> > > >> On Wed, Feb 6, 2013 at 6:34 AM, Douglas Bates <bates at stat.wisc.edu>
> > > wrote:
> > > >>
> > > >>> It is possible to create the correlation matrix of the fixed
> > > >>> effects
> > > and
> > > >>> the random effects jointly using the results from lmer but I have
> > > >>> difficulty deciding what this would represent statistically.  If
> > > >>> you
> > > adopt
> > > >>> a B
> > 
> > 
> > 
> > --
> > Andrew Robinson
> > Director (A/g), ACERA
> > Senior Lecturer in Applied Statistics                      Tel:
> > +61-3-8344-6410
> > Department of Mathematics and Statistics            Fax: +61-3-8344 4599
> > University of Melbourne, VIC 3010 Australia
> > Email: a.robinson at ms.unimelb.edu.au    Website:
> > http://www.ms.unimelb.edu.au
> > 
> > FAwR: http://www.ms.unimelb.edu.au/~andrewpr/FAwR/
> > SPuR: http://www.ms.unimelb.edu.au/spuRs/
> > 
> > 	[[alternative HTML version deleted]]
> > 
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Andrew Robinson  
Director (A/g), ACERA 
Department of Mathematics and Statistics            Tel: +61-3-8344-6410
University of Melbourne, VIC 3010 Australia               (prefer email)
http://www.ms.unimelb.edu.au/~andrewpr              Fax: +61-3-8344-4599
http://www.acera.unimelb.edu.au/

Forest Analytics with R (Springer, 2011) 
http://www.ms.unimelb.edu.au/FAwR/
Introduction to Scientific Programming and Simulation using R (CRC, 2009): 
http://www.ms.unimelb.edu.au/spuRs/


From HDoran at air.org  Thu Feb  7 15:45:38 2013
From: HDoran at air.org (Doran, Harold)
Date: Thu, 7 Feb 2013 09:45:38 -0500
Subject: [R-sig-ME] [R] lmer - BLUP prediction intervals
In-Reply-To: <20130206232842.GG2026@ms.unimelb.edu.au>
References: <CAMeQTh3WwXvEGoeUEPS8ZXbbBWHMA57b9otav5WsQYQ+my6u-g@mail.gmail.com>
	<loom.20130205T192133-238@post.gmane.org>
	<686DF18D10EF1C428C2760321FB5B69E07733386F6@DC1VEX07MB001.air.org>
	<CAO7JsnSYu3hmgoS-dFE9+SVpH1LBuNcDnauyTi3KDJwApisung@mail.gmail.com>
	<CAHyGmd7xA4auGOq5wtvwvGRDzkxetGU70retwGR5=KG-3g6BwQ@mail.gmail.com>
	<CAO7JsnRKB+EoHPSY7GoQk7-6qAgL0+8tH43x5Si2Ex2Nd0QXDQ@mail.gmail.com>
	<CAMeQTh1LKvnEdiM8NKe37KAtQ=pC4NWrTSPNvRx_R97Exk6RzA@mail.gmail.com>
	<CAHyGmd5GhyA8yf8SkK-i=H=5QWxYNTeXDFxxiGoz3H+qB+TR8g@mail.gmail.com>
	<686DF18D10EF1C428C2760321FB5B69E0773338B06@DC1VEX07MB001.air.org>
	<20130206232842.GG2026@ms.unimelb.edu.au>
Message-ID: <686DF18D10EF1C428C2760321FB5B69E077390C799@DC1VEX07MB001.air.org>

Andrew:

I agree with you and think that is reasonable too, but would offer the following thoughts. Doug and I have talked about this for a while. As usual, he makes excellent points and I've struggled with this specific issue. 

In the end, I have found myself taking the position that you argued. It remains uncontroversial to add the estimate of the fixed effects with the BLUPs. Doug noted one is _estimated_ as a parameter (i.e., the fixed effect) and the BLUP is not estimated in the same way the fixed effect is as a model parameter.

But, it is _kind of_ an estimate. It is predicted conditional on the variance components and the fixed effects themselves and it has a sampling distribution.

So, I've taken the position that these are two statistical "things" both with model-based sampling distributions and a covariance term. 

In my world, there are often stakes associated with the use of the data and if I were to ignore the covariance term between the BLUPs and the fixed effects I could risk underestimating the true sampling variance of that linear combination.

So, in my world, I view them as a linear combination with a covariance term and represent the variance of them as such. 




> -----Original Message-----
> From: Andrew Robinson [mailto:A.Robinson at ms.unimelb.edu.au]
> Sent: Wednesday, February 06, 2013 6:29 PM
> To: Doran, Harold
> Cc: dcarov at gmail.com; r-sig-mixed-models at r-project.org; Ben Bolker
> Subject: Re: [R-sig-ME] [R] lmer - BLUP prediction intervals
> 
> Hi Harold,
> 
> just pragmatism.  If the model says that there's a quantity but it's hard to
> estimate, eg the software doesn't provide it, then I wouild contend that - so
> long as one is honest - it's reasonable to ignore it.
> 
> Intuitively I would expect that the correlation between the fixed estimates
> and random predictions would be negative.  This is because, in a sense,
> they're trying to rerepsent the same variation. I know that you have a lot of
> experience and a lot of time thinking about these models.  How does that
> conjecture sound to you?  If that were the case then ignoring the correlation
> between them when computing a prediction interval would be conservative.
> 
> Best wishes
> 
> Andrew
> 
> 
> 
> On Wed, Feb 06, 2013 at 10:36:40AM -0500, Doran, Harold wrote:
> > Andrew
> >
> > Ignoring the important theoretical question for just a moment on whether
> it is sensible to do this, there is a covariance term between the BLUPs and
> the fixed effects.
> >
> > If that term exists under the model, but it is ignored for purposes of
> variance estimation, what would be the reason for doing so?
> >
> > > -----Original Message-----
> > > From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-
> > > models-bounces at r-project.org] On Behalf Of Andrew Robinson
> > > Sent: Tuesday, February 05, 2013 9:15 PM
> > > To: dcarov at gmail.com
> > > Cc: r-sig-mixed-models at r-project.org; Ben Bolker
> > > Subject: Re: [R-sig-ME] [R] lmer - BLUP prediction intervals
> > >
> > > I think that it is a reasonable way to proceed just so long as you
> > > interpret the intervals guardedly and document your assumptions
> carefully.
> > >
> > > Cheers
> > >
> > > Andrew
> > >
> > > On Wednesday, February 6, 2013, Daniel Caro wrote:
> > >
> > > > Dear all
> > > >
> > > > I have not been able to follow the discussion. But I would like to
> > > > know if it makes sense to calculate prediction intervals like this:
> > > >
> > > > var(fixed effect+random effect)= var(fixed effect) + var(random
> > > > effect) + 0 (i.e., the cov is zero)
> > > >
> > > > and based on this create the prediction intervals. Does this make
> sense?
> > > >
> > > > All the best,
> > > > Daniel
> > > >
> > > > On Tue, Feb 5, 2013 at 8:54 PM, Douglas Bates
> > > > <bates at stat.wisc.edu>
> > > wrote:
> > > > > On Tue, Feb 5, 2013 at 2:14 PM, Andrew Robinson <
> > > > > A.Robinson at ms.unimelb.edu.au> wrote:
> > > > >
> > > > >> I'd have thought that the joint correlation matrix would be of
> > > > >> the estimates of the fixed effects and the random effects,
> > > > >> rather than the things themselves.
> > > > >>
> > > > >
> > > > > Well, it may be because I have turned into a grumpy old man but
> > > > > I get
> > > > picky
> > > > > about terminology and the random effects are not parameters -
> > > > > they are unobserved random variables.  They don't have
> > > > > "estimates" in the sense of parameter estimates.  The quantities
> > > > > returned by the ranef function are
> > > > the
> > > > > conditional means (in the case of a linear mixed model,
> > > > > conditional modes in general) of the random effects given the
> > > > > observed data evaluated with the parameters at their estimated
> > > > > values. In the Bayesian point of view none of this is
> > > > > problematic because they're all random variables but otherwise I
> > > > > struggle with the interpretation of how these can be
> > > > considered
> > > > > jointly.   If you want to consider the distribution of the random effects
> > > > > you need to have known values of the parameters.
> > > > >
> > > > >
> > > > >> The estimates are statistical quantities, with specified
> > > > >> distributions, under the model.  The model posits these
> > > > >> different roles (parameter,
> > > > random
> > > > >> variable) for the quantities that are the targets of the
> > > > >> estimates, but
> > > > the
> > > > >> estimates are just estimates, and as such, they have a
> > > > >> correlation structure under the model, and that correlation
> > > > >> structure can be
> > > > estimated.
> > > > >>
> > > > >> An imperfect analogy from least-squares regression is the
> > > > >> correlation structure of residual estimates, induced by the model.
> > > > >> We say that the errors are independent, but the model creates a
> > > > >> (modest) correlation structure than can be measured, again,
> > > > >> conditional
> > > on the model.
> > > > >>
> > > > >
> > > > > Well the residuals are random variables and we can show that at
> > > > > the least squares estimates of the parameters they will have a
> > > > > known Gaussian distribution which, it turns out, doesn't depend
> > > > > on the values of the coefficients.  But those are the easy
> > > > > cases.  In the linear mixed model
> > > > we
> > > > > still have a Gaussian distribution and a linear predictor but
> > > > > that is for the conditional distribution of the response given
> > > > > the random
> > > effects.
> > > >  For
> > > > > the complete model things get much messier.
> > > > >
> > > > > I'm not making these points just to be difficult.  I have spent
> > > > > a lot of time thinking about these models and trying to come up
> > > > > with a coherent
> > > > way
> > > > > of describing them.  Along the way I have come to the conclusion
> > > > > that the way these models are often described is, well, wrong.
> > > > > And those descriptions include some that I have written.  For
> > > > > example, you often
> > > > see
> > > > > the model described as the linear predictor for an observation
> > > > > plus a "noise" term, epsilon, and the statement that the
> > > > > distribution of the random effects is independent of the
> > > > > distribution of the noise term.  I
> > > > now
> > > > > view the linear predictor as a part of the conditional
> > > > > distribution of
> > > > the
> > > > > response given the random effects so it wouldn't make sense to
> > > > > talk about these distributions being independent.  The biggest
> > > > > pitfall in
> > > > transferring
> > > > > your thinking from a linear model to any other kind (GLM, LMM,
> > > > > GLMM) is
> > > > the
> > > > > fact that we can make sense of a Gaussian distribution minus its
> > > > > mean so
> > > > we
> > > > > write the linear model in the "signal plus noise" form as Y =
> > > > > X\beta
> > > > > + \epsilon where Y is an n-dimensional random variable, X is the
> > > > > + n
> > > > > by p
> > > > model
> > > > > matrix, \beta is the p-dimensional vector of coefficients and
> > > > > \epsilon is an n-dimensional Gaussian with mean zero.  That
> > > > > doesn't work in the other cases, despite the heroic attempts of
> > > > > many people to write things in that way.
> > > > >
> > > > > Here endeth the sermon.
> > > > >
> > > > >
> > > > >> On Wed, Feb 6, 2013 at 6:34 AM, Douglas Bates
> > > > >> <bates at stat.wisc.edu>
> > > > wrote:
> > > > >>
> > > > >>> It is possible to create the correlation matrix of the fixed
> > > > >>> effects
> > > > and
> > > > >>> the random effects jointly using the results from lmer but I
> > > > >>> have difficulty deciding what this would represent
> > > > >>> statistically.  If you
> > > > adopt
> > > > >>> a B
> > >
> > >
> > >
> > > --
> > > Andrew Robinson
> > > Director (A/g), ACERA
> > > Senior Lecturer in Applied Statistics                      Tel:
> > > +61-3-8344-6410
> > > Department of Mathematics and Statistics            Fax: +61-3-8344 4599
> > > University of Melbourne, VIC 3010 Australia
> > > Email: a.robinson at ms.unimelb.edu.au    Website:
> > > http://www.ms.unimelb.edu.au
> > >
> > > FAwR: http://www.ms.unimelb.edu.au/~andrewpr/FAwR/
> > > SPuR: http://www.ms.unimelb.edu.au/spuRs/
> > >
> > > 	[[alternative HTML version deleted]]
> > >
> > > _______________________________________________
> > > R-sig-mixed-models at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> --
> Andrew Robinson
> Director (A/g), ACERA
> Department of Mathematics and Statistics            Tel: +61-3-8344-6410
> University of Melbourne, VIC 3010 Australia               (prefer email)
> http://www.ms.unimelb.edu.au/~andrewpr              Fax: +61-3-8344-4599
> http://www.acera.unimelb.edu.au/
> 
> Forest Analytics with R (Springer, 2011)
> http://www.ms.unimelb.edu.au/FAwR/
> Introduction to Scientific Programming and Simulation using R (CRC, 2009):
> http://www.ms.unimelb.edu.au/spuRs/


From bates at stat.wisc.edu  Thu Feb  7 15:57:28 2013
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 7 Feb 2013 08:57:28 -0600
Subject: [R-sig-ME] [R] lmer - BLUP prediction intervals
In-Reply-To: <686DF18D10EF1C428C2760321FB5B69E0773338B06@DC1VEX07MB001.air.org>
References: <CAMeQTh3WwXvEGoeUEPS8ZXbbBWHMA57b9otav5WsQYQ+my6u-g@mail.gmail.com>
	<loom.20130205T192133-238@post.gmane.org>
	<686DF18D10EF1C428C2760321FB5B69E07733386F6@DC1VEX07MB001.air.org>
	<CAO7JsnSYu3hmgoS-dFE9+SVpH1LBuNcDnauyTi3KDJwApisung@mail.gmail.com>
	<CAHyGmd7xA4auGOq5wtvwvGRDzkxetGU70retwGR5=KG-3g6BwQ@mail.gmail.com>
	<CAO7JsnRKB+EoHPSY7GoQk7-6qAgL0+8tH43x5Si2Ex2Nd0QXDQ@mail.gmail.com>
	<CAMeQTh1LKvnEdiM8NKe37KAtQ=pC4NWrTSPNvRx_R97Exk6RzA@mail.gmail.com>
	<CAHyGmd5GhyA8yf8SkK-i=H=5QWxYNTeXDFxxiGoz3H+qB+TR8g@mail.gmail.com>
	<686DF18D10EF1C428C2760321FB5B69E0773338B06@DC1VEX07MB001.air.org>
Message-ID: <CAO7JsnRmjhZNWYsV6EfOE5ERTJRmQ6DBXtksxGaT50WLrtqvHg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130207/d1a339d7/attachment.pl>

From HDoran at air.org  Thu Feb  7 16:02:49 2013
From: HDoran at air.org (Doran, Harold)
Date: Thu, 7 Feb 2013 10:02:49 -0500
Subject: [R-sig-ME] [R] lmer - BLUP prediction intervals
In-Reply-To: <CAO7JsnRmjhZNWYsV6EfOE5ERTJRmQ6DBXtksxGaT50WLrtqvHg@mail.gmail.com>
References: <CAMeQTh3WwXvEGoeUEPS8ZXbbBWHMA57b9otav5WsQYQ+my6u-g@mail.gmail.com>
	<loom.20130205T192133-238@post.gmane.org>
	<686DF18D10EF1C428C2760321FB5B69E07733386F6@DC1VEX07MB001.air.org>
	<CAO7JsnSYu3hmgoS-dFE9+SVpH1LBuNcDnauyTi3KDJwApisung@mail.gmail.com>
	<CAHyGmd7xA4auGOq5wtvwvGRDzkxetGU70retwGR5=KG-3g6BwQ@mail.gmail.com>
	<CAO7JsnRKB+EoHPSY7GoQk7-6qAgL0+8tH43x5Si2Ex2Nd0QXDQ@mail.gmail.com>
	<CAMeQTh1LKvnEdiM8NKe37KAtQ=pC4NWrTSPNvRx_R97Exk6RzA@mail.gmail.com>
	<CAHyGmd5GhyA8yf8SkK-i=H=5QWxYNTeXDFxxiGoz3H+qB+TR8g@mail.gmail.com>
	<686DF18D10EF1C428C2760321FB5B69E0773338B06@DC1VEX07MB001.air.org>
	<CAO7JsnRmjhZNWYsV6EfOE5ERTJRmQ6DBXtksxGaT50WLrtqvHg@mail.gmail.com>
Message-ID: <686DF18D10EF1C428C2760321FB5B69E077390C7CE@DC1VEX07MB001.air.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130207/333f6c11/attachment.pl>

From bates at stat.wisc.edu  Thu Feb  7 16:32:43 2013
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 7 Feb 2013 09:32:43 -0600
Subject: [R-sig-ME] [R] lmer - BLUP prediction intervals
In-Reply-To: <CAHyGmd4u8hSsOpO=AjdetZKyhG744VJuwH3PDy0N+_OMvXsZOA@mail.gmail.com>
References: <CAMeQTh3WwXvEGoeUEPS8ZXbbBWHMA57b9otav5WsQYQ+my6u-g@mail.gmail.com>
	<loom.20130205T192133-238@post.gmane.org>
	<686DF18D10EF1C428C2760321FB5B69E07733386F6@DC1VEX07MB001.air.org>
	<CAO7JsnSYu3hmgoS-dFE9+SVpH1LBuNcDnauyTi3KDJwApisung@mail.gmail.com>
	<CAHyGmd7xA4auGOq5wtvwvGRDzkxetGU70retwGR5=KG-3g6BwQ@mail.gmail.com>
	<CAO7JsnRKB+EoHPSY7GoQk7-6qAgL0+8tH43x5Si2Ex2Nd0QXDQ@mail.gmail.com>
	<CAHyGmd4u8hSsOpO=AjdetZKyhG744VJuwH3PDy0N+_OMvXsZOA@mail.gmail.com>
Message-ID: <CAO7JsnS14FbK6L17g_EDwe7v-ZMNiOFzYbejrQxFzEnft7VKGQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130207/49672c5a/attachment.pl>

From curis at pharmacie.univ-paris5.fr  Thu Feb  7 16:36:49 2013
From: curis at pharmacie.univ-paris5.fr (Emmanuel Curis)
Date: Thu, 7 Feb 2013 16:36:49 +0100
Subject: [R-sig-ME] [R] lmer - BLUP prediction intervals
In-Reply-To: <686DF18D10EF1C428C2760321FB5B69E077390C7CE@DC1VEX07MB001.air.org>
References: <loom.20130205T192133-238@post.gmane.org>
	<686DF18D10EF1C428C2760321FB5B69E07733386F6@DC1VEX07MB001.air.org>
	<CAO7JsnSYu3hmgoS-dFE9+SVpH1LBuNcDnauyTi3KDJwApisung@mail.gmail.com>
	<CAHyGmd7xA4auGOq5wtvwvGRDzkxetGU70retwGR5=KG-3g6BwQ@mail.gmail.com>
	<CAO7JsnRKB+EoHPSY7GoQk7-6qAgL0+8tH43x5Si2Ex2Nd0QXDQ@mail.gmail.com>
	<CAMeQTh1LKvnEdiM8NKe37KAtQ=pC4NWrTSPNvRx_R97Exk6RzA@mail.gmail.com>
	<CAHyGmd5GhyA8yf8SkK-i=H=5QWxYNTeXDFxxiGoz3H+qB+TR8g@mail.gmail.com>
	<686DF18D10EF1C428C2760321FB5B69E0773338B06@DC1VEX07MB001.air.org>
	<CAO7JsnRmjhZNWYsV6EfOE5ERTJRmQ6DBXtksxGaT50WLrtqvHg@mail.gmail.com>
	<686DF18D10EF1C428C2760321FB5B69E077390C7CE@DC1VEX07MB001.air.org>
Message-ID: <20130207153649.GA10996@laboinfo-063.pharmacie.univ-paris5.fr>

Hi,

Sorry to interfer with my ideas despite I am not a specialist, I try
it to check if I understood things properly or not, I would be
grateful to be corrected if I say uncorrect things.

May be the reason lies in the somehow ? hierarchical ? structure of
the mixed effects model.

I mean, in such a model, you select a set of patients (let's say) in a
whole population - the B random vector (?) - : first random
space. Then, you measure the value you're interested in - the Y random
vector : second random space.

After that, you use Y values (conditionned on the B values you
sampled) to determine the fixed effects estimations and BLUPs for b
values (if I am still correct) ==> these values are a function of Y
hence are themselves random variables, whose law depends on both Y and
B laws --- hence, is valid on the whole population and not only on the
subset of patients you sampled.

In this population, it is then possible to use a kind of covariance between
fixed values and BLUPs to calculate things. But adding them is then
strange, because you are working for "any patient" and add a term, the
BLUP, constructed for a specific patient: it makes no real sense, and
directly using the estimated variances value for B would be more
logical, I think.

Conversely, in the case you want to use really the BLUP for a given
patient, it means you assume you have already done the first step of
randomisation, and are working only within the second subset. But in
this case, the common law for fixed effects and BLUPs estimates does
not hold any more (since it is based on the two randomisation stages),
hence the impossibilty of formalizing covariances between them...

Hope this is not too far from the real problem behind all of this!

Best regards,

On Thu, Feb 07, 2013 at 10:02:49AM -0500, Doran, Harold wrote:
? Doug:
? 
? Sorry if this is too simple a question. Call \hat{\beta}} the estimate of a fixed parameter and \hat{b_i}  the BLUP for unit i.
? 
? If the following exists
? 
? \hat{\theta} = \hat{\beta}} + \hat{b_i}
? 
? Then, does var(\hat{\theta}) also exist?
? 
? 
? From: dmbates at gmail.com [mailto:dmbates at gmail.com] On Behalf Of Douglas Bates
? Sent: Thursday, February 07, 2013 9:57 AM
? To: Doran, Harold
? Cc: Andrew Robinson; dcarov at gmail.com; r-sig-mixed-models at r-project.org; Ben Bolker
? Subject: Re: [R-sig-ME] [R] lmer - BLUP prediction intervals
? 
? On Wed, Feb 6, 2013 at 9:36 AM, Doran, Harold <HDoran at air.org<mailto:HDoran at air.org>> wrote:
? Andrew
? 
? Ignoring the important theoretical question for just a moment on whether it is sensible to do this, there is a covariance term between the BLUPs and the fixed effects.
? 
? But the picky mathematician in me can't understand in what distribution this covariance occurs.  It makes sense in the Bayesian formulation but not in a classical (sampling theory) formulation.  The distribution of the estimator of the fixed effects for known values of the parameters is a multivariate normal that depends on \beta, \sigma^2 and \Sigma, the model matrices X and Z being known.  The random variable B doesn't enter into it.  (One way of writing this variance-covariance of this multivariate normal is X'V^{-1}X where V is that matrix that involves Z and Sigma^{-1} - I have forgotten the exact form).
? 
? I know these considerations sound like needless theoretical niceties but to me they're not. I have to be able to formulate the theoretical basis before I can make sense of the computational results and, after 20 years or so, I'm still having trouble making sense of this.
? 
? 
? If that term exists under the model, but it is ignored for purposes of variance estimation, what would be the reason for doing so?
? 
? > -----Original Message-----
? > From: r-sig-mixed-models-bounces at r-project.org<mailto:r-sig-mixed-models-bounces at r-project.org> [mailto:r-sig-mixed-<mailto:r-sig-mixed->
? > models-bounces at r-project.org<mailto:models-bounces at r-project.org>] On Behalf Of Andrew Robinson
? > Sent: Tuesday, February 05, 2013 9:15 PM
? > To: dcarov at gmail.com<mailto:dcarov at gmail.com>
? > Cc: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>; Ben Bolker
? > Subject: Re: [R-sig-ME] [R] lmer - BLUP prediction intervals
? >
? > I think that it is a reasonable way to proceed just so long as you interpret the
? > intervals guardedly and document your assumptions carefully.
? >
? > Cheers
? >
? > Andrew
? >
? > On Wednesday, February 6, 2013, Daniel Caro wrote:
? >
? > > Dear all
? > >
? > > I have not been able to follow the discussion. But I would like to
? > > know if it makes sense to calculate prediction intervals like this:
? > >
? > > var(fixed effect+random effect)= var(fixed effect) + var(random
? > > effect) + 0 (i.e., the cov is zero)
? > >
? > > and based on this create the prediction intervals. Does this make sense?
? > >
? > > All the best,
? > > Daniel
? > >
? > > On Tue, Feb 5, 2013 at 8:54 PM, Douglas Bates <bates at stat.wisc.edu<mailto:bates at stat.wisc.edu>>
? > wrote:
? > > > On Tue, Feb 5, 2013 at 2:14 PM, Andrew Robinson <
? > > > A.Robinson at ms.unimelb.edu.au<mailto:A.Robinson at ms.unimelb.edu.au>> wrote:
? > > >
? > > >> I'd have thought that the joint correlation matrix would be of the
? > > >> estimates of the fixed effects and the random effects, rather than
? > > >> the things themselves.
? > > >>
? > > >
? > > > Well, it may be because I have turned into a grumpy old man but I
? > > > get
? > > picky
? > > > about terminology and the random effects are not parameters - they
? > > > are unobserved random variables.  They don't have "estimates" in the
? > > > sense of parameter estimates.  The quantities returned by the ranef
? > > > function are
? > > the
? > > > conditional means (in the case of a linear mixed model, conditional
? > > > modes in general) of the random effects given the observed data
? > > > evaluated with the parameters at their estimated values. In the
? > > > Bayesian point of view none of this is problematic because they're
? > > > all random variables but otherwise I struggle with the
? > > > interpretation of how these can be
? > > considered
? > > > jointly.   If you want to consider the distribution of the random effects
? > > > you need to have known values of the parameters.
? > > >
? > > >
? > > >> The estimates are statistical quantities, with specified
? > > >> distributions, under the model.  The model posits these different
? > > >> roles (parameter,
? > > random
? > > >> variable) for the quantities that are the targets of the estimates,
? > > >> but
? > > the
? > > >> estimates are just estimates, and as such, they have a correlation
? > > >> structure under the model, and that correlation structure can be
? > > estimated.
? > > >>
? > > >> An imperfect analogy from least-squares regression is the
? > > >> correlation structure of residual estimates, induced by the model.
? > > >> We say that the errors are independent, but the model creates a
? > > >> (modest) correlation structure than can be measured, again, conditional
? > on the model.
? > > >>
? > > >
? > > > Well the residuals are random variables and we can show that at the
? > > > least squares estimates of the parameters they will have a known
? > > > Gaussian distribution which, it turns out, doesn't depend on the
? > > > values of the coefficients.  But those are the easy cases.  In the
? > > > linear mixed model
? > > we
? > > > still have a Gaussian distribution and a linear predictor but that
? > > > is for the conditional distribution of the response given the random
? > effects.
? > >  For
? > > > the complete model things get much messier.
? > > >
? > > > I'm not making these points just to be difficult.  I have spent a
? > > > lot of time thinking about these models and trying to come up with a
? > > > coherent
? > > way
? > > > of describing them.  Along the way I have come to the conclusion
? > > > that the way these models are often described is, well, wrong.  And
? > > > those descriptions include some that I have written.  For example,
? > > > you often
? > > see
? > > > the model described as the linear predictor for an observation plus
? > > > a "noise" term, epsilon, and the statement that the distribution of
? > > > the random effects is independent of the distribution of the noise
? > > > term.  I
? > > now
? > > > view the linear predictor as a part of the conditional distribution
? > > > of
? > > the
? > > > response given the random effects so it wouldn't make sense to talk
? > > > about these distributions being independent.  The biggest pitfall in
? > > transferring
? > > > your thinking from a linear model to any other kind (GLM, LMM, GLMM)
? > > > is
? > > the
? > > > fact that we can make sense of a Gaussian distribution minus its
? > > > mean so
? > > we
? > > > write the linear model in the "signal plus noise" form as Y = X\beta
? > > > + \epsilon where Y is an n-dimensional random variable, X is the n
? > > > by p
? > > model
? > > > matrix, \beta is the p-dimensional vector of coefficients and
? > > > \epsilon is an n-dimensional Gaussian with mean zero.  That doesn't
? > > > work in the other cases, despite the heroic attempts of many people
? > > > to write things in that way.
? > > >
? > > > Here endeth the sermon.
? > > >
? > > >
? > > >> On Wed, Feb 6, 2013 at 6:34 AM, Douglas Bates <bates at stat.wisc.edu<mailto:bates at stat.wisc.edu>>
? > > wrote:
? > > >>
? > > >>> It is possible to create the correlation matrix of the fixed
? > > >>> effects
? > > and
? > > >>> the random effects jointly using the results from lmer but I have
? > > >>> difficulty deciding what this would represent statistically.  If
? > > >>> you
? > > adopt
? > > >>> a B
? >
? >
? >
? > --
? > Andrew Robinson
? > Director (A/g), ACERA
? > Senior Lecturer in Applied Statistics                      Tel:
? > +61-3-8344-6410<tel:%2B61-3-8344-6410>
? > Department of Mathematics and Statistics            Fax: +61-3-8344 4599<tel:%2B61-3-8344%204599>
? > University of Melbourne, VIC 3010 Australia
? > Email: a.robinson at ms.unimelb.edu.au<mailto:a.robinson at ms.unimelb.edu.au>    Website:
? > http://www.ms.unimelb.edu.au
? >
? > FAwR: http://www.ms.unimelb.edu.au/~andrewpr/FAwR/
? > SPuR: http://www.ms.unimelb.edu.au/spuRs/
? >
? >       [[alternative HTML version deleted]]
? >
? > _______________________________________________
? > R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
? > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
? 
? _______________________________________________
? R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
? https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
? 
? 
? 	[[alternative HTML version deleted]]
? 
? _______________________________________________
? R-sig-mixed-models at r-project.org mailing list
? https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
                                Emmanuel CURIS
                                emmanuel.curis at parisdescartes.fr

Page WWW: http://emmanuel.curis.online.fr/index.html


From emuiruri25 at gmail.com  Thu Feb  7 12:55:23 2013
From: emuiruri25 at gmail.com (Eva Muiruri)
Date: Thu, 7 Feb 2013 11:55:23 +0000
Subject: [R-sig-ME] Modelling zero-inflated count data in nested experiments
Message-ID: <CAFcdEfNTU7cxoPjUuoaZQZ8qwWQf3C_-_f7+Q-FWn8984j79AA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130207/c73bbf8f/attachment.pl>

From sven.gastauer at wur.nl  Thu Feb  7 17:11:49 2013
From: sven.gastauer at wur.nl (Gastauer, Sven)
Date: Thu, 7 Feb 2013 16:11:49 +0000
Subject: [R-sig-ME] MCMCglmm - ZIP model for mackerel egg data
Message-ID: <DB34604B7AC0314895201BE4BE40103808093F68@SCOMP0934.wurnet.nl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130207/0c0ff7fd/attachment.pl>

From highstat at highstat.com  Thu Feb  7 17:56:43 2013
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Thu, 07 Feb 2013 16:56:43 +0000
Subject: [R-sig-ME] Modelling zero-inflated count data in nested,
	experiments
In-Reply-To: <mailman.6414.1360254355.4600.r-sig-mixed-models@r-project.org>
References: <mailman.6414.1360254355.4600.r-sig-mixed-models@r-project.org>
Message-ID: <5113DCCB.6040108@highstat.com>



------------------------------

Message: 3
Date: Thu, 7 Feb 2013 11:55:23 +0000
From: Eva Muiruri <emuiruri25 at gmail.com>
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] Modelling zero-inflated count data in nested
	experiments
Message-ID:
	<CAFcdEfNTU7cxoPjUuoaZQZ8qwWQf3C_-_f7+Q-FWn8984j79AA at mail.gmail.com>
Content-Type: text/plain

Hello,

I'm trying to analyse the effect of tree species richness within a plot on
the number of insect herbivores per tree.
Unfortunately, a huge proportion of the herbivore count data has zero
values. I have tried all the transformations I have come across in the
literature and have even tried ranking the data but to no avail.

Due to the nested nature of our experiment, I initially ran models using
lmer and the poisson family, specifying AREA and PLOT as random effects.
> m1 <- lmer(HERBIVORE ~ RICHNESS, (1|AREA/PLOT), family="poisson")

The residuals were not normally distributed so I tried to run the same
model using the AD model builder, accounting for zero inflation and trying
both the poisson family or the negative binomial family but still, there is
decreasing variance in the residuals for higher fitted values.
>m2 <- glmmadmb(HERBIVORE ~ RICHNESS, (1|AREA/PLOT), family="nbinom",
zeroInflation=TRUE)

My only other option, as far as I can see, would be to report analysis
based on the presence/absence of herbivores on each tree (using a binomial
error distribution in lmer) but I would be unable to discuss any effect of
tree species richness on herbivore densities.

Is there a further method of analysis I can try in R?







Just fit a zero inflated GLMM in JAGS, WinBUGS or OpenBUGS. I would use JAGS.
Not sure what you mean with more than 3 random effects.
You need plenty of plots and plenty of areas.
Yes..that is MCMC....

Residuals do not need to be normally distributed. It is lack of fit you need to investigate. Because
you used a negative binomial distribution (or Poisson) for small values, the distribution is likely to be skewed...hence the
reason you have more negative than positive residuals....

zero inflated negative binomial is quite a complicated distribution.
Try a ZIP GLMM..assuming your data is large enough, and you have enough levels for the plots and areas.

Alain







  Could the MCMC method be used with this dataset? (From what I understand,
it is only to be used when you have 3 or more random effects but, as I am
new to this, I may be wrong.)

Thanks, in advance.

Eva

	[[alternative HTML version deleted]]



------------------------------

_______________________________________________
R-sig-mixed-models mailing list
R-sig-mixed-models at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


End of R-sig-mixed-models Digest, Vol 74, Issue 11


From j.hadfield at ed.ac.uk  Fri Feb  8 00:01:50 2013
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Thu, 07 Feb 2013 23:01:50 +0000
Subject: [R-sig-ME] [R] lmer - BLUP prediction intervals
In-Reply-To: <686DF18D10EF1C428C2760321FB5B69E077390C7CE@DC1VEX07MB001.air.org>
References: <CAMeQTh3WwXvEGoeUEPS8ZXbbBWHMA57b9otav5WsQYQ+my6u-g@mail.gmail.com>
	<loom.20130205T192133-238@post.gmane.org>
	<686DF18D10EF1C428C2760321FB5B69E07733386F6@DC1VEX07MB001.air.org>
	<CAO7JsnSYu3hmgoS-dFE9+SVpH1LBuNcDnauyTi3KDJwApisung@mail.gmail.com>
	<CAHyGmd7xA4auGOq5wtvwvGRDzkxetGU70retwGR5=KG-3g6BwQ@mail.gmail.com>
	<CAO7JsnRKB+EoHPSY7GoQk7-6qAgL0+8tH43x5Si2Ex2Nd0QXDQ@mail.gmail.com>
	<CAMeQTh1LKvnEdiM8NKe37KAtQ=pC4NWrTSPNvRx_R97Exk6RzA@mail.gmail.com>
	<CAHyGmd5GhyA8yf8SkK-i=H=5QWxYNTeXDFxxiGoz3H+qB+TR8g@mail.gmail.com>
	<686DF18D10EF1C428C2760321FB5B69E0773338B06@DC1VEX07MB001.air.org>
	<CAO7JsnRmjhZNWYsV6EfOE5ERTJRmQ6DBXtksxGaT50WLrtqvHg@mail.gmail.com>
	<686DF18D10EF1C428C2760321FB5B69E077390C7CE@DC1VEX07MB001.air.org>
Message-ID: <20130207230150.21303s3q5f55hs8w@www.staffmail.ed.ac.uk>

Dear Daniel,

To give a practical, rather than philosophical, solution to your  
problem you could perhaps try this....

W<-cBind(X,Z)

Cinv =  
solve(t(W)%*%W/Vr+bdiag(Diagonal(nb)*0,Diagonal(ne)/Ve,Diagonal(ni)/Vi))


where Vr is the residual variance, nb is the number of fixed effects,  
ne is the number of examiners and Ve the examiner variance estimate  
and ni is the number of items and Vi the item variance estimate.

Cinv is the (co)variance matrix of the fixed and random effects  
(stacked on top of each other).  If you take the sub-matrix of Cinv  
that pertains to the effects in your prediction, then summing the  
elements of that sub-matrix will give you something that is close to  
the prediction variance. In general the sub-matrix will not be  
diagonal (i.e. there are covariances between the random effects and  
the things we are *calling* fixed effects). Vr, Ve and Vn are assumed  
known. If you want to include their uncertainty in the prediction  
interval you will probably have to wear the B-badge more visibly on  
your sleeve I'm afraid.

Cheers,

Jarrod

















Quoting "Doran, Harold" <HDoran at air.org> on Thu, 7 Feb 2013 10:02:49 -0500:

> Doug:
>
> Sorry if this is too simple a question. Call \hat{\beta}} the  
> estimate of a fixed parameter and \hat{b_i}  the BLUP for unit i.
>
> If the following exists
>
> \hat{\theta} = \hat{\beta}} + \hat{b_i}
>
> Then, does var(\hat{\theta}) also exist?
>
>
> From: dmbates at gmail.com [mailto:dmbates at gmail.com] On Behalf Of Douglas Bates
> Sent: Thursday, February 07, 2013 9:57 AM
> To: Doran, Harold
> Cc: Andrew Robinson; dcarov at gmail.com;  
> r-sig-mixed-models at r-project.org; Ben Bolker
> Subject: Re: [R-sig-ME] [R] lmer - BLUP prediction intervals
>
> On Wed, Feb 6, 2013 at 9:36 AM, Doran, Harold  
> <HDoran at air.org<mailto:HDoran at air.org>> wrote:
> Andrew
>
> Ignoring the important theoretical question for just a moment on  
> whether it is sensible to do this, there is a covariance term  
> between the BLUPs and the fixed effects.
>
> But the picky mathematician in me can't understand in what  
> distribution this covariance occurs.  It makes sense in the Bayesian  
> formulation but not in a classical (sampling theory) formulation.   
> The distribution of the estimator of the fixed effects for known  
> values of the parameters is a multivariate normal that depends on  
> \beta, \sigma^2 and \Sigma, the model matrices X and Z being known.   
> The random variable B doesn't enter into it.  (One way of writing  
> this variance-covariance of this multivariate normal is X'V^{-1}X  
> where V is that matrix that involves Z and Sigma^{-1} - I have  
> forgotten the exact form).
>
> I know these considerations sound like needless theoretical niceties  
> but to me they're not. I have to be able to formulate the  
> theoretical basis before I can make sense of the computational  
> results and, after 20 years or so, I'm still having trouble making  
> sense of this.
>
>
> If that term exists under the model, but it is ignored for purposes  
> of variance estimation, what would be the reason for doing so?
>
>> -----Original Message-----
>> From:  
>> r-sig-mixed-models-bounces at r-project.org<mailto:r-sig-mixed-models-bounces at r-project.org>  
>> [mailto:r-sig-mixed-<mailto:r-sig-mixed->
>> models-bounces at r-project.org<mailto:models-bounces at r-project.org>]  
>> On Behalf Of Andrew Robinson
>> Sent: Tuesday, February 05, 2013 9:15 PM
>> To: dcarov at gmail.com<mailto:dcarov at gmail.com>
>> Cc:  
>> r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>;  
>> Ben Bolker
>> Subject: Re: [R-sig-ME] [R] lmer - BLUP prediction intervals
>>
>> I think that it is a reasonable way to proceed just so long as you  
>> interpret the
>> intervals guardedly and document your assumptions carefully.
>>
>> Cheers
>>
>> Andrew
>>
>> On Wednesday, February 6, 2013, Daniel Caro wrote:
>>
>> > Dear all
>> >
>> > I have not been able to follow the discussion. But I would like to
>> > know if it makes sense to calculate prediction intervals like this:
>> >
>> > var(fixed effect+random effect)= var(fixed effect) + var(random
>> > effect) + 0 (i.e., the cov is zero)
>> >
>> > and based on this create the prediction intervals. Does this make sense?
>> >
>> > All the best,
>> > Daniel
>> >
>> > On Tue, Feb 5, 2013 at 8:54 PM, Douglas Bates  
>> <bates at stat.wisc.edu<mailto:bates at stat.wisc.edu>>
>> wrote:
>> > > On Tue, Feb 5, 2013 at 2:14 PM, Andrew Robinson <
>> > >  
>> A.Robinson at ms.unimelb.edu.au<mailto:A.Robinson at ms.unimelb.edu.au>>  
>> wrote:
>> > >
>> > >> I'd have thought that the joint correlation matrix would be of the
>> > >> estimates of the fixed effects and the random effects, rather than
>> > >> the things themselves.
>> > >>
>> > >
>> > > Well, it may be because I have turned into a grumpy old man but I
>> > > get
>> > picky
>> > > about terminology and the random effects are not parameters - they
>> > > are unobserved random variables.  They don't have "estimates" in the
>> > > sense of parameter estimates.  The quantities returned by the ranef
>> > > function are
>> > the
>> > > conditional means (in the case of a linear mixed model, conditional
>> > > modes in general) of the random effects given the observed data
>> > > evaluated with the parameters at their estimated values. In the
>> > > Bayesian point of view none of this is problematic because they're
>> > > all random variables but otherwise I struggle with the
>> > > interpretation of how these can be
>> > considered
>> > > jointly.   If you want to consider the distribution of the  
>> random effects
>> > > you need to have known values of the parameters.
>> > >
>> > >
>> > >> The estimates are statistical quantities, with specified
>> > >> distributions, under the model.  The model posits these different
>> > >> roles (parameter,
>> > random
>> > >> variable) for the quantities that are the targets of the estimates,
>> > >> but
>> > the
>> > >> estimates are just estimates, and as such, they have a correlation
>> > >> structure under the model, and that correlation structure can be
>> > estimated.
>> > >>
>> > >> An imperfect analogy from least-squares regression is the
>> > >> correlation structure of residual estimates, induced by the model.
>> > >> We say that the errors are independent, but the model creates a
>> > >> (modest) correlation structure than can be measured, again, conditional
>> on the model.
>> > >>
>> > >
>> > > Well the residuals are random variables and we can show that at the
>> > > least squares estimates of the parameters they will have a known
>> > > Gaussian distribution which, it turns out, doesn't depend on the
>> > > values of the coefficients.  But those are the easy cases.  In the
>> > > linear mixed model
>> > we
>> > > still have a Gaussian distribution and a linear predictor but that
>> > > is for the conditional distribution of the response given the random
>> effects.
>> >  For
>> > > the complete model things get much messier.
>> > >
>> > > I'm not making these points just to be difficult.  I have spent a
>> > > lot of time thinking about these models and trying to come up with a
>> > > coherent
>> > way
>> > > of describing them.  Along the way I have come to the conclusion
>> > > that the way these models are often described is, well, wrong.  And
>> > > those descriptions include some that I have written.  For example,
>> > > you often
>> > see
>> > > the model described as the linear predictor for an observation plus
>> > > a "noise" term, epsilon, and the statement that the distribution of
>> > > the random effects is independent of the distribution of the noise
>> > > term.  I
>> > now
>> > > view the linear predictor as a part of the conditional distribution
>> > > of
>> > the
>> > > response given the random effects so it wouldn't make sense to talk
>> > > about these distributions being independent.  The biggest pitfall in
>> > transferring
>> > > your thinking from a linear model to any other kind (GLM, LMM, GLMM)
>> > > is
>> > the
>> > > fact that we can make sense of a Gaussian distribution minus its
>> > > mean so
>> > we
>> > > write the linear model in the "signal plus noise" form as Y = X\beta
>> > > + \epsilon where Y is an n-dimensional random variable, X is the n
>> > > by p
>> > model
>> > > matrix, \beta is the p-dimensional vector of coefficients and
>> > > \epsilon is an n-dimensional Gaussian with mean zero.  That doesn't
>> > > work in the other cases, despite the heroic attempts of many people
>> > > to write things in that way.
>> > >
>> > > Here endeth the sermon.
>> > >
>> > >
>> > >> On Wed, Feb 6, 2013 at 6:34 AM, Douglas Bates  
>> <bates at stat.wisc.edu<mailto:bates at stat.wisc.edu>>
>> > wrote:
>> > >>
>> > >>> It is possible to create the correlation matrix of the fixed
>> > >>> effects
>> > and
>> > >>> the random effects jointly using the results from lmer but I have
>> > >>> difficulty deciding what this would represent statistically.  If
>> > >>> you
>> > adopt
>> > >>> a B
>>
>>
>>
>> --
>> Andrew Robinson
>> Director (A/g), ACERA
>> Senior Lecturer in Applied Statistics                      Tel:
>> +61-3-8344-6410<tel:%2B61-3-8344-6410>
>> Department of Mathematics and Statistics            Fax: +61-3-8344  
>> 4599<tel:%2B61-3-8344%204599>
>> University of Melbourne, VIC 3010 Australia
>> Email:  
>> a.robinson at ms.unimelb.edu.au<mailto:a.robinson at ms.unimelb.edu.au>    
>>  Website:
>> http://www.ms.unimelb.edu.au
>>
>> FAwR: http://www.ms.unimelb.edu.au/~andrewpr/FAwR/
>> SPuR: http://www.ms.unimelb.edu.au/spuRs/
>>
>>       [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org>  
>> mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org>  
> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From j.hadfield at ed.ac.uk  Fri Feb  8 00:01:57 2013
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Thu, 07 Feb 2013 23:01:57 +0000
Subject: [R-sig-ME] [R] lmer - BLUP prediction intervals
In-Reply-To: <686DF18D10EF1C428C2760321FB5B69E077390C7CE@DC1VEX07MB001.air.org>
References: <CAMeQTh3WwXvEGoeUEPS8ZXbbBWHMA57b9otav5WsQYQ+my6u-g@mail.gmail.com>
	<loom.20130205T192133-238@post.gmane.org>
	<686DF18D10EF1C428C2760321FB5B69E07733386F6@DC1VEX07MB001.air.org>
	<CAO7JsnSYu3hmgoS-dFE9+SVpH1LBuNcDnauyTi3KDJwApisung@mail.gmail.com>
	<CAHyGmd7xA4auGOq5wtvwvGRDzkxetGU70retwGR5=KG-3g6BwQ@mail.gmail.com>
	<CAO7JsnRKB+EoHPSY7GoQk7-6qAgL0+8tH43x5Si2Ex2Nd0QXDQ@mail.gmail.com>
	<CAMeQTh1LKvnEdiM8NKe37KAtQ=pC4NWrTSPNvRx_R97Exk6RzA@mail.gmail.com>
	<CAHyGmd5GhyA8yf8SkK-i=H=5QWxYNTeXDFxxiGoz3H+qB+TR8g@mail.gmail.com>
	<686DF18D10EF1C428C2760321FB5B69E0773338B06@DC1VEX07MB001.air.org>
	<CAO7JsnRmjhZNWYsV6EfOE5ERTJRmQ6DBXtksxGaT50WLrtqvHg@mail.gmail.com>
	<686DF18D10EF1C428C2760321FB5B69E077390C7CE@DC1VEX07MB001.air.org>
Message-ID: <20130207230157.85172inmzpjbdo4k@www.staffmail.ed.ac.uk>

Dear Daniel,

To give a practical, rather than philosophical, solution to your  
problem you could perhaps try this....

W<-cBind(X,Z)

Cinv =  
solve(t(W)%*%W/Vr+bdiag(Diagonal(nb)*0,Diagonal(ne)/Ve,Diagonal(ni)/Vi))


where Vr is the residual variance, nb is the number of fixed effects,  
ne is the number of examiners and Ve the examiner variance estimate  
and ni is the number of items and Vi the item variance estimate.

Cinv is the (co)variance matrix of the fixed and random effects  
(stacked on top of each other).  If you take the sub-matrix of Cinv  
that pertains to the effects in your prediction, then summing the  
elements of that sub-matrix will give you something that is close to  
the prediction variance. In general the sub-matrix will not be  
diagonal (i.e. there are covariances between the random effects and  
the things we are *calling* fixed effects). Vr, Ve and Vn are assumed  
known. If you want to include their uncertainty in the prediction  
interval you will probably have to wear the B-badge more visibly on  
your sleeve I'm afraid.

Cheers,

Jarrod

















Quoting "Doran, Harold" <HDoran at air.org> on Thu, 7 Feb 2013 10:02:49 -0500:

> Doug:
>
> Sorry if this is too simple a question. Call \hat{\beta}} the  
> estimate of a fixed parameter and \hat{b_i}  the BLUP for unit i.
>
> If the following exists
>
> \hat{\theta} = \hat{\beta}} + \hat{b_i}
>
> Then, does var(\hat{\theta}) also exist?
>
>
> From: dmbates at gmail.com [mailto:dmbates at gmail.com] On Behalf Of Douglas Bates
> Sent: Thursday, February 07, 2013 9:57 AM
> To: Doran, Harold
> Cc: Andrew Robinson; dcarov at gmail.com;  
> r-sig-mixed-models at r-project.org; Ben Bolker
> Subject: Re: [R-sig-ME] [R] lmer - BLUP prediction intervals
>
> On Wed, Feb 6, 2013 at 9:36 AM, Doran, Harold  
> <HDoran at air.org<mailto:HDoran at air.org>> wrote:
> Andrew
>
> Ignoring the important theoretical question for just a moment on  
> whether it is sensible to do this, there is a covariance term  
> between the BLUPs and the fixed effects.
>
> But the picky mathematician in me can't understand in what  
> distribution this covariance occurs.  It makes sense in the Bayesian  
> formulation but not in a classical (sampling theory) formulation.   
> The distribution of the estimator of the fixed effects for known  
> values of the parameters is a multivariate normal that depends on  
> \beta, \sigma^2 and \Sigma, the model matrices X and Z being known.   
> The random variable B doesn't enter into it.  (One way of writing  
> this variance-covariance of this multivariate normal is X'V^{-1}X  
> where V is that matrix that involves Z and Sigma^{-1} - I have  
> forgotten the exact form).
>
> I know these considerations sound like needless theoretical niceties  
> but to me they're not. I have to be able to formulate the  
> theoretical basis before I can make sense of the computational  
> results and, after 20 years or so, I'm still having trouble making  
> sense of this.
>
>
> If that term exists under the model, but it is ignored for purposes  
> of variance estimation, what would be the reason for doing so?
>
>> -----Original Message-----
>> From:  
>> r-sig-mixed-models-bounces at r-project.org<mailto:r-sig-mixed-models-bounces at r-project.org>  
>> [mailto:r-sig-mixed-<mailto:r-sig-mixed->
>> models-bounces at r-project.org<mailto:models-bounces at r-project.org>]  
>> On Behalf Of Andrew Robinson
>> Sent: Tuesday, February 05, 2013 9:15 PM
>> To: dcarov at gmail.com<mailto:dcarov at gmail.com>
>> Cc:  
>> r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>;  
>> Ben Bolker
>> Subject: Re: [R-sig-ME] [R] lmer - BLUP prediction intervals
>>
>> I think that it is a reasonable way to proceed just so long as you  
>> interpret the
>> intervals guardedly and document your assumptions carefully.
>>
>> Cheers
>>
>> Andrew
>>
>> On Wednesday, February 6, 2013, Daniel Caro wrote:
>>
>> > Dear all
>> >
>> > I have not been able to follow the discussion. But I would like to
>> > know if it makes sense to calculate prediction intervals like this:
>> >
>> > var(fixed effect+random effect)= var(fixed effect) + var(random
>> > effect) + 0 (i.e., the cov is zero)
>> >
>> > and based on this create the prediction intervals. Does this make sense?
>> >
>> > All the best,
>> > Daniel
>> >
>> > On Tue, Feb 5, 2013 at 8:54 PM, Douglas Bates  
>> <bates at stat.wisc.edu<mailto:bates at stat.wisc.edu>>
>> wrote:
>> > > On Tue, Feb 5, 2013 at 2:14 PM, Andrew Robinson <
>> > >  
>> A.Robinson at ms.unimelb.edu.au<mailto:A.Robinson at ms.unimelb.edu.au>>  
>> wrote:
>> > >
>> > >> I'd have thought that the joint correlation matrix would be of the
>> > >> estimates of the fixed effects and the random effects, rather than
>> > >> the things themselves.
>> > >>
>> > >
>> > > Well, it may be because I have turned into a grumpy old man but I
>> > > get
>> > picky
>> > > about terminology and the random effects are not parameters - they
>> > > are unobserved random variables.  They don't have "estimates" in the
>> > > sense of parameter estimates.  The quantities returned by the ranef
>> > > function are
>> > the
>> > > conditional means (in the case of a linear mixed model, conditional
>> > > modes in general) of the random effects given the observed data
>> > > evaluated with the parameters at their estimated values. In the
>> > > Bayesian point of view none of this is problematic because they're
>> > > all random variables but otherwise I struggle with the
>> > > interpretation of how these can be
>> > considered
>> > > jointly.   If you want to consider the distribution of the  
>> random effects
>> > > you need to have known values of the parameters.
>> > >
>> > >
>> > >> The estimates are statistical quantities, with specified
>> > >> distributions, under the model.  The model posits these different
>> > >> roles (parameter,
>> > random
>> > >> variable) for the quantities that are the targets of the estimates,
>> > >> but
>> > the
>> > >> estimates are just estimates, and as such, they have a correlation
>> > >> structure under the model, and that correlation structure can be
>> > estimated.
>> > >>
>> > >> An imperfect analogy from least-squares regression is the
>> > >> correlation structure of residual estimates, induced by the model.
>> > >> We say that the errors are independent, but the model creates a
>> > >> (modest) correlation structure than can be measured, again, conditional
>> on the model.
>> > >>
>> > >
>> > > Well the residuals are random variables and we can show that at the
>> > > least squares estimates of the parameters they will have a known
>> > > Gaussian distribution which, it turns out, doesn't depend on the
>> > > values of the coefficients.  But those are the easy cases.  In the
>> > > linear mixed model
>> > we
>> > > still have a Gaussian distribution and a linear predictor but that
>> > > is for the conditional distribution of the response given the random
>> effects.
>> >  For
>> > > the complete model things get much messier.
>> > >
>> > > I'm not making these points just to be difficult.  I have spent a
>> > > lot of time thinking about these models and trying to come up with a
>> > > coherent
>> > way
>> > > of describing them.  Along the way I have come to the conclusion
>> > > that the way these models are often described is, well, wrong.  And
>> > > those descriptions include some that I have written.  For example,
>> > > you often
>> > see
>> > > the model described as the linear predictor for an observation plus
>> > > a "noise" term, epsilon, and the statement that the distribution of
>> > > the random effects is independent of the distribution of the noise
>> > > term.  I
>> > now
>> > > view the linear predictor as a part of the conditional distribution
>> > > of
>> > the
>> > > response given the random effects so it wouldn't make sense to talk
>> > > about these distributions being independent.  The biggest pitfall in
>> > transferring
>> > > your thinking from a linear model to any other kind (GLM, LMM, GLMM)
>> > > is
>> > the
>> > > fact that we can make sense of a Gaussian distribution minus its
>> > > mean so
>> > we
>> > > write the linear model in the "signal plus noise" form as Y = X\beta
>> > > + \epsilon where Y is an n-dimensional random variable, X is the n
>> > > by p
>> > model
>> > > matrix, \beta is the p-dimensional vector of coefficients and
>> > > \epsilon is an n-dimensional Gaussian with mean zero.  That doesn't
>> > > work in the other cases, despite the heroic attempts of many people
>> > > to write things in that way.
>> > >
>> > > Here endeth the sermon.
>> > >
>> > >
>> > >> On Wed, Feb 6, 2013 at 6:34 AM, Douglas Bates  
>> <bates at stat.wisc.edu<mailto:bates at stat.wisc.edu>>
>> > wrote:
>> > >>
>> > >>> It is possible to create the correlation matrix of the fixed
>> > >>> effects
>> > and
>> > >>> the random effects jointly using the results from lmer but I have
>> > >>> difficulty deciding what this would represent statistically.  If
>> > >>> you
>> > adopt
>> > >>> a B
>>
>>
>>
>> --
>> Andrew Robinson
>> Director (A/g), ACERA
>> Senior Lecturer in Applied Statistics                      Tel:
>> +61-3-8344-6410<tel:%2B61-3-8344-6410>
>> Department of Mathematics and Statistics            Fax: +61-3-8344  
>> 4599<tel:%2B61-3-8344%204599>
>> University of Melbourne, VIC 3010 Australia
>> Email:  
>> a.robinson at ms.unimelb.edu.au<mailto:a.robinson at ms.unimelb.edu.au>    
>>  Website:
>> http://www.ms.unimelb.edu.au
>>
>> FAwR: http://www.ms.unimelb.edu.au/~andrewpr/FAwR/
>> SPuR: http://www.ms.unimelb.edu.au/spuRs/
>>
>>       [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org>  
>> mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org>  
> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From bbolker at gmail.com  Fri Feb  8 04:30:32 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 8 Feb 2013 03:30:32 +0000 (UTC)
Subject: [R-sig-ME] AIC(c) tables from a set of glmer (lme4) models
References: <4A3F286665AD3D488D56FDFAC7D8CE430C1F1D94@exchange2-1>
Message-ID: <loom.20130208T042602-377@post.gmane.org>

Adriaan De Jong <Adriaan.de.Jong at ...> writes:

> 
> Hi,
> Is there a way to create AICc tables from a set of glmer
> poisson models created under lme4? The AICcmodavg
> package description doesn't include references to glmer. 
> Or is the AICc.mer function applicable on glmer's?
> Thanks in advance for any suggestions/hints.
> Cheers,
> Adjan


  I can't see why AICc.mer shouldn't be applicable to
GLMM fits (except for the fundamental objection that AICc
was developed in the context of linear models and might
not actually be appropriate for GLM[M]s at all -- see Richards
(2005) Ecology "Testing ecological theory using the information-theoretic
approach" for some relevant simulation results -- but this is a
theoretical issue, not one that can be fixed by using different
software ...)

library(lme4.0)  ## I'm using lme4.0, should be equiv to lme4 from CRAN
library(AICcmodavg)
example(glmer)
AICc(gm1)

seems to work fine.


From bbolker at gmail.com  Fri Feb  8 04:46:38 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 8 Feb 2013 03:46:38 +0000 (UTC)
Subject: [R-sig-ME] Minimum number of levels for mixed model
References: <1211943845.40727.1360172097299.JavaMail.sas1@[172.29.251.236]>
Message-ID: <loom.20130208T043613-17@post.gmane.org>

nrm2010 <nrm2010 at ...> writes:

> 
> Dear Mixed Modelers:
 
> The oft-mentioned glmm wiki FAQ recommends a minimum of 5 or 6
>  levels when using a mixed model. I am not sure how to interpret
>  this statement.  I have 4 experimental treatments, each with 3
>  replicates, for a total of 12 plots.  Measurements were made over 4
>  years and there are thousands of individual data points within each
>  of the 12 plots.  I was planning to use nested random effects of
>  plot within treatment within year. So I would have 3 replicate
>  plots within each of 4 treatments within each of 4 years.
 
> My questions:

> For nested effects, at what level does the recommendation pertain?
> Is it only the lowest level?  Would 5 or 6 plots within 3 treatments
> within 3 years be acceptable?  Or should one have 5 or 6 plots
> within 5 or 6 treatments within 5 or 6 years? Is the amount of data
> within plot irrelevant to this issue?


> If 4 treatments are insufficient for a mixed model, is treatment as
> fixed effect the only alternative?  I need an approach for which
> there is a method for multiple comparison of means.  I believe lm,
> lme, lme4 are the only options since the aov methods do not accept
> an Error term.

   I would suggest

 ~ treat*year + [other covariates] + (1|treat:year:rep)

It's hard to imagine why you wouldn't want to model treatment
as a fixed effect in any case.  It might be nice to model
year as a fixed effect, but it's not practical (unless you want
to do something fancy like putting a Bayesian prior on the
variance).

You might consider adding a term (1|treat:rep) as well (this
would have an effective sample size of 12), to model persistent
differences among plots within treatments.

  It might be a good idea to follow the advice of Murtaugh 2007
(Ecology), and aggregate (take the mean of) all the points within
each treat:year:rep combination.  Your model will simplify to

 ~ treat*year + ... + (1|treat:rep)

because the (1|year:treat:rep) term will be equivalent to
the residual error term.  All you will lose will be the estimate
of the variance within (1|treat:rep:year) combinations.


From richard.asturia at gmail.com  Fri Feb  8 06:02:36 2013
From: richard.asturia at gmail.com (Richard Asturia)
Date: Fri, 8 Feb 2013 03:02:36 -0200
Subject: [R-sig-ME] Details on specifying random parameters in 3-level HLM
	with lme
Message-ID: <CA+xNL7rpixTqDAHeF5UPRYgKF_oKC9nNuWhX5NFLtS+yoxLtjg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130208/55bc2b82/attachment.pl>

From A.Robinson at ms.unimelb.edu.au  Fri Feb  8 06:24:00 2013
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Fri, 8 Feb 2013 16:24:00 +1100
Subject: [R-sig-ME] [R] lmer - BLUP prediction intervals
In-Reply-To: <686DF18D10EF1C428C2760321FB5B69E077390C799@DC1VEX07MB001.air.org>
References: <loom.20130205T192133-238@post.gmane.org>
	<686DF18D10EF1C428C2760321FB5B69E07733386F6@DC1VEX07MB001.air.org>
	<CAO7JsnSYu3hmgoS-dFE9+SVpH1LBuNcDnauyTi3KDJwApisung@mail.gmail.com>
	<CAHyGmd7xA4auGOq5wtvwvGRDzkxetGU70retwGR5=KG-3g6BwQ@mail.gmail.com>
	<CAO7JsnRKB+EoHPSY7GoQk7-6qAgL0+8tH43x5Si2Ex2Nd0QXDQ@mail.gmail.com>
	<CAMeQTh1LKvnEdiM8NKe37KAtQ=pC4NWrTSPNvRx_R97Exk6RzA@mail.gmail.com>
	<CAHyGmd5GhyA8yf8SkK-i=H=5QWxYNTeXDFxxiGoz3H+qB+TR8g@mail.gmail.com>
	<686DF18D10EF1C428C2760321FB5B69E0773338B06@DC1VEX07MB001.air.org>
	<20130206232842.GG2026@ms.unimelb.edu.au>
	<686DF18D10EF1C428C2760321FB5B69E077390C799@DC1VEX07MB001.air.org>
Message-ID: <20130208052400.GK2026@ms.unimelb.edu.au>

Hi Harold,

I think that we're on the same page.  My opinion is that the estimates
and the predictions are both random variables.  They have a joint
distribution under the model, and it is possible to estimate the
parameters of that joint distribution, under the model.  

I tend to think that if I can't write down their joint distribution
then I'm not sure what are the grounds for taking any linear
combination - including the very useful adding of them - either.

If obtaining the covariance term is reasonable within epsilon time and
effort, then I would advocate doing that and following your
prescription.

Andrew.

On Thu, Feb 07, 2013 at 09:45:38AM -0500, Doran, Harold wrote:
> Andrew:
> 
> I agree with you and think that is reasonable too, but would offer the following thoughts. Doug and I have talked about this for a while. As usual, he makes excellent points and I've struggled with this specific issue. 
> 
> In the end, I have found myself taking the position that you argued. It remains uncontroversial to add the estimate of the fixed effects with the BLUPs. Doug noted one is _estimated_ as a parameter (i.e., the fixed effect) and the BLUP is not estimated in the same way the fixed effect is as a model parameter.
> 
> But, it is _kind of_ an estimate. It is predicted conditional on the variance components and the fixed effects themselves and it has a sampling distribution.
> 
> So, I've taken the position that these are two statistical "things" both with model-based sampling distributions and a covariance term. 
> 
> In my world, there are often stakes associated with the use of the data and if I were to ignore the covariance term between the BLUPs and the fixed effects I could risk underestimating the true sampling variance of that linear combination.
> 
> So, in my world, I view them as a linear combination with a covariance term and represent the variance of them as such. 
> 
> 
> 
> 
> > -----Original Message-----
> > From: Andrew Robinson [mailto:A.Robinson at ms.unimelb.edu.au]
> > Sent: Wednesday, February 06, 2013 6:29 PM
> > To: Doran, Harold
> > Cc: dcarov at gmail.com; r-sig-mixed-models at r-project.org; Ben Bolker
> > Subject: Re: [R-sig-ME] [R] lmer - BLUP prediction intervals
> > 
> > Hi Harold,
> > 
> > just pragmatism.  If the model says that there's a quantity but it's hard to
> > estimate, eg the software doesn't provide it, then I wouild contend that - so
> > long as one is honest - it's reasonable to ignore it.
> > 
> > Intuitively I would expect that the correlation between the fixed estimates
> > and random predictions would be negative.  This is because, in a sense,
> > they're trying to rerepsent the same variation. I know that you have a lot of
> > experience and a lot of time thinking about these models.  How does that
> > conjecture sound to you?  If that were the case then ignoring the correlation
> > between them when computing a prediction interval would be conservative.
> > 
> > Best wishes
> > 
> > Andrew
> > 
> > 
> > 
> > On Wed, Feb 06, 2013 at 10:36:40AM -0500, Doran, Harold wrote:
> > > Andrew
> > >
> > > Ignoring the important theoretical question for just a moment on whether
> > it is sensible to do this, there is a covariance term between the BLUPs and
> > the fixed effects.
> > >
> > > If that term exists under the model, but it is ignored for purposes of
> > variance estimation, what would be the reason for doing so?
> > >
> > > > -----Original Message-----
> > > > From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-
> > > > models-bounces at r-project.org] On Behalf Of Andrew Robinson
> > > > Sent: Tuesday, February 05, 2013 9:15 PM
> > > > To: dcarov at gmail.com
> > > > Cc: r-sig-mixed-models at r-project.org; Ben Bolker
> > > > Subject: Re: [R-sig-ME] [R] lmer - BLUP prediction intervals
> > > >
> > > > I think that it is a reasonable way to proceed just so long as you
> > > > interpret the intervals guardedly and document your assumptions
> > carefully.
> > > >
> > > > Cheers
> > > >
> > > > Andrew
> > > >
> > > > On Wednesday, February 6, 2013, Daniel Caro wrote:
> > > >
> > > > > Dear all
> > > > >
> > > > > I have not been able to follow the discussion. But I would like to
> > > > > know if it makes sense to calculate prediction intervals like this:
> > > > >
> > > > > var(fixed effect+random effect)= var(fixed effect) + var(random
> > > > > effect) + 0 (i.e., the cov is zero)
> > > > >
> > > > > and based on this create the prediction intervals. Does this make
> > sense?
> > > > >
> > > > > All the best,
> > > > > Daniel
> > > > >
> > > > > On Tue, Feb 5, 2013 at 8:54 PM, Douglas Bates
> > > > > <bates at stat.wisc.edu>
> > > > wrote:
> > > > > > On Tue, Feb 5, 2013 at 2:14 PM, Andrew Robinson <
> > > > > > A.Robinson at ms.unimelb.edu.au> wrote:
> > > > > >
> > > > > >> I'd have thought that the joint correlation matrix would be of
> > > > > >> the estimates of the fixed effects and the random effects,
> > > > > >> rather than the things themselves.
> > > > > >>
> > > > > >
> > > > > > Well, it may be because I have turned into a grumpy old man but
> > > > > > I get
> > > > > picky
> > > > > > about terminology and the random effects are not parameters -
> > > > > > they are unobserved random variables.  They don't have
> > > > > > "estimates" in the sense of parameter estimates.  The quantities
> > > > > > returned by the ranef function are
> > > > > the
> > > > > > conditional means (in the case of a linear mixed model,
> > > > > > conditional modes in general) of the random effects given the
> > > > > > observed data evaluated with the parameters at their estimated
> > > > > > values. In the Bayesian point of view none of this is
> > > > > > problematic because they're all random variables but otherwise I
> > > > > > struggle with the interpretation of how these can be
> > > > > considered
> > > > > > jointly.   If you want to consider the distribution of the random effects
> > > > > > you need to have known values of the parameters.
> > > > > >
> > > > > >
> > > > > >> The estimates are statistical quantities, with specified
> > > > > >> distributions, under the model.  The model posits these
> > > > > >> different roles (parameter,
> > > > > random
> > > > > >> variable) for the quantities that are the targets of the
> > > > > >> estimates, but
> > > > > the
> > > > > >> estimates are just estimates, and as such, they have a
> > > > > >> correlation structure under the model, and that correlation
> > > > > >> structure can be
> > > > > estimated.
> > > > > >>
> > > > > >> An imperfect analogy from least-squares regression is the
> > > > > >> correlation structure of residual estimates, induced by the model.
> > > > > >> We say that the errors are independent, but the model creates a
> > > > > >> (modest) correlation structure than can be measured, again,
> > > > > >> conditional
> > > > on the model.
> > > > > >>
> > > > > >
> > > > > > Well the residuals are random variables and we can show that at
> > > > > > the least squares estimates of the parameters they will have a
> > > > > > known Gaussian distribution which, it turns out, doesn't depend
> > > > > > on the values of the coefficients.  But those are the easy
> > > > > > cases.  In the linear mixed model
> > > > > we
> > > > > > still have a Gaussian distribution and a linear predictor but
> > > > > > that is for the conditional distribution of the response given
> > > > > > the random
> > > > effects.
> > > > >  For
> > > > > > the complete model things get much messier.
> > > > > >
> > > > > > I'm not making these points just to be difficult.  I have spent
> > > > > > a lot of time thinking about these models and trying to come up
> > > > > > with a coherent
> > > > > way
> > > > > > of describing them.  Along the way I have come to the conclusion
> > > > > > that the way these models are often described is, well, wrong.
> > > > > > And those descriptions include some that I have written.  For
> > > > > > example, you often
> > > > > see
> > > > > > the model described as the linear predictor for an observation
> > > > > > plus a "noise" term, epsilon, and the statement that the
> > > > > > distribution of the random effects is independent of the
> > > > > > distribution of the noise term.  I
> > > > > now
> > > > > > view the linear predictor as a part of the conditional
> > > > > > distribution of
> > > > > the
> > > > > > response given the random effects so it wouldn't make sense to
> > > > > > talk about these distributions being independent.  The biggest
> > > > > > pitfall in
> > > > > transferring
> > > > > > your thinking from a linear model to any other kind (GLM, LMM,
> > > > > > GLMM) is
> > > > > the
> > > > > > fact that we can make sense of a Gaussian distribution minus its
> > > > > > mean so
> > > > > we
> > > > > > write the linear model in the "signal plus noise" form as Y =
> > > > > > X\beta
> > > > > > + \epsilon where Y is an n-dimensional random variable, X is the
> > > > > > + n
> > > > > > by p
> > > > > model
> > > > > > matrix, \beta is the p-dimensional vector of coefficients and
> > > > > > \epsilon is an n-dimensional Gaussian with mean zero.  That
> > > > > > doesn't work in the other cases, despite the heroic attempts of
> > > > > > many people to write things in that way.
> > > > > >
> > > > > > Here endeth the sermon.
> > > > > >
> > > > > >
> > > > > >> On Wed, Feb 6, 2013 at 6:34 AM, Douglas Bates
> > > > > >> <bates at stat.wisc.edu>
> > > > > wrote:
> > > > > >>
> > > > > >>> It is possible to create the correlation matrix of the fixed
> > > > > >>> effects
> > > > > and
> > > > > >>> the random effects jointly using the results from lmer but I
> > > > > >>> have difficulty deciding what this would represent
> > > > > >>> statistically.  If you
> > > > > adopt
> > > > > >>> a B
> > > >
> > > >
> > > >
> > > > --
> > > > Andrew Robinson
> > > > Director (A/g), ACERA
> > > > Senior Lecturer in Applied Statistics                      Tel:
> > > > +61-3-8344-6410
> > > > Department of Mathematics and Statistics            Fax: +61-3-8344 4599
> > > > University of Melbourne, VIC 3010 Australia
> > > > Email: a.robinson at ms.unimelb.edu.au    Website:
> > > > http://www.ms.unimelb.edu.au
> > > >
> > > > FAwR: http://www.ms.unimelb.edu.au/~andrewpr/FAwR/
> > > > SPuR: http://www.ms.unimelb.edu.au/spuRs/
> > > >
> > > > 	[[alternative HTML version deleted]]
> > > >
> > > > _______________________________________________
> > > > R-sig-mixed-models at r-project.org mailing list
> > > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > 
> > --
> > Andrew Robinson
> > Director (A/g), ACERA
> > Department of Mathematics and Statistics            Tel: +61-3-8344-6410
> > University of Melbourne, VIC 3010 Australia               (prefer email)
> > http://www.ms.unimelb.edu.au/~andrewpr              Fax: +61-3-8344-4599
> > http://www.acera.unimelb.edu.au/
> > 
> > Forest Analytics with R (Springer, 2011)
> > http://www.ms.unimelb.edu.au/FAwR/
> > Introduction to Scientific Programming and Simulation using R (CRC, 2009):
> > http://www.ms.unimelb.edu.au/spuRs/

-- 
Andrew Robinson  
Director (A/g), ACERA 
Department of Mathematics and Statistics            Tel: +61-3-8344-6410
University of Melbourne, VIC 3010 Australia               (prefer email)
http://www.ms.unimelb.edu.au/~andrewpr              Fax: +61-3-8344-4599
http://www.acera.unimelb.edu.au/

Forest Analytics with R (Springer, 2011) 
http://www.ms.unimelb.edu.au/FAwR/
Introduction to Scientific Programming and Simulation using R (CRC, 2009): 
http://www.ms.unimelb.edu.au/spuRs/


From A.Robinson at ms.unimelb.edu.au  Fri Feb  8 06:31:12 2013
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Fri, 8 Feb 2013 16:31:12 +1100
Subject: [R-sig-ME] [R] lmer - BLUP prediction intervals
In-Reply-To: <20130207153649.GA10996@laboinfo-063.pharmacie.univ-paris5.fr>
References: <686DF18D10EF1C428C2760321FB5B69E07733386F6@DC1VEX07MB001.air.org>
	<CAO7JsnSYu3hmgoS-dFE9+SVpH1LBuNcDnauyTi3KDJwApisung@mail.gmail.com>
	<CAHyGmd7xA4auGOq5wtvwvGRDzkxetGU70retwGR5=KG-3g6BwQ@mail.gmail.com>
	<CAO7JsnRKB+EoHPSY7GoQk7-6qAgL0+8tH43x5Si2Ex2Nd0QXDQ@mail.gmail.com>
	<CAMeQTh1LKvnEdiM8NKe37KAtQ=pC4NWrTSPNvRx_R97Exk6RzA@mail.gmail.com>
	<CAHyGmd5GhyA8yf8SkK-i=H=5QWxYNTeXDFxxiGoz3H+qB+TR8g@mail.gmail.com>
	<686DF18D10EF1C428C2760321FB5B69E0773338B06@DC1VEX07MB001.air.org>
	<CAO7JsnRmjhZNWYsV6EfOE5ERTJRmQ6DBXtksxGaT50WLrtqvHg@mail.gmail.com>
	<686DF18D10EF1C428C2760321FB5B69E077390C7CE@DC1VEX07MB001.air.org>
	<20130207153649.GA10996@laboinfo-063.pharmacie.univ-paris5.fr>
Message-ID: <20130208053112.GL2026@ms.unimelb.edu.au>

Hi Emmanuel,

in my opinion, you have framed the problem correctly and helpfully
with one modest caveat: it's not only the hierarchical nature of the
model that induces the problem, as we also have a simpler version of
it for GLM.

On Thu, Feb 07, 2013 at 04:36:49PM +0100, Emmanuel Curis wrote:
> Hi,
> 
> Sorry to interfer with my ideas despite I am not a specialist, I try
> it to check if I understood things properly or not, I would be
> grateful to be corrected if I say uncorrect things.
> 
> May be the reason lies in the somehow ? hierarchical ? structure of
> the mixed effects model.
> 
> I mean, in such a model, you select a set of patients (let's say) in
> a whole population - the B random vector (?) - : first random
> space. Then, you measure the value you're interested in - the Y
> random vector : second random space.
> 
> After that, you use Y values (conditionned on the B values you
> sampled) to determine the fixed effects estimations and BLUPs for b
> values (if I am still correct) ==> these values are a function of Y
> hence are themselves random variables, whose law depends on both Y and
> B laws --- hence, is valid on the whole population and not only on the
> subset of patients you sampled.
> 
> In this population, it is then possible to use a kind of covariance
> between fixed values and BLUPs to calculate things. But adding them
> is then strange, because you are working for "any patient" and add a
> term, the BLUP, constructed for a specific patient: it makes no real
> sense, and directly using the estimated variances value for B would
> be more logical, I think.

Agreed.

> Conversely, in the case you want to use really the BLUP for a given
> patient, it means you assume you have already done the first step of
> randomisation, and are working only within the second subset. But in
> this case, the common law for fixed effects and BLUPs estimates does
> not hold any more (since it is based on the two randomisation
> stages), hence the impossibilty of formalizing covariances between
> them...

I'm not sure that I follow your reasoning here. If I want to make a
prediction for a patient then it seems natural to me to add the fixed
effect to the BLUP, yes.  Both of these are random variables, with
known distributions (under the model) and estimated parameters.  I
feel that I should be able to use a standard method to estimate the
distribution of the sum.  

Best wishes

Andrew

> Hope this is not too far from the real problem behind all of this!
> 
> Best regards,
> 
> On Thu, Feb 07, 2013 at 10:02:49AM -0500, Doran, Harold wrote:
> ? Doug:
> ? 
> ? Sorry if this is too simple a question. Call \hat{\beta}} the estimate of a fixed parameter and \hat{b_i}  the BLUP for unit i.
> ? 
> ? If the following exists
> ? 
> ? \hat{\theta} = \hat{\beta}} + \hat{b_i}
> ? 
> ? Then, does var(\hat{\theta}) also exist?
> ? 
> ? 
> ? From: dmbates at gmail.com [mailto:dmbates at gmail.com] On Behalf Of Douglas Bates
> ? Sent: Thursday, February 07, 2013 9:57 AM
> ? To: Doran, Harold
> ? Cc: Andrew Robinson; dcarov at gmail.com; r-sig-mixed-models at r-project.org; Ben Bolker
> ? Subject: Re: [R-sig-ME] [R] lmer - BLUP prediction intervals
> ? 
> ? On Wed, Feb 6, 2013 at 9:36 AM, Doran, Harold <HDoran at air.org<mailto:HDoran at air.org>> wrote:
> ? Andrew
> ? 
> ? Ignoring the important theoretical question for just a moment on whether it is sensible to do this, there is a covariance term between the BLUPs and the fixed effects.
> ? 
> ? But the picky mathematician in me can't understand in what distribution this covariance occurs.  It makes sense in the Bayesian formulation but not in a classical (sampling theory) formulation.  The distribution of the estimator of the fixed effects for known values of the parameters is a multivariate normal that depends on \beta, \sigma^2 and \Sigma, the model matrices X and Z being known.  The random variable B doesn't enter into it.  (One way of writing this variance-covariance of this multivariate normal is X'V^{-1}X where V is that matrix that involves Z and Sigma^{-1} - I have forgotten the exact form).
> ? 
> ? I know these considerations sound like needless theoretical niceties but to me they're not. I have to be able to formulate the theoretical basis before I can make sense of the computational results and, after 20 years or so, I'm still having trouble making sense of this.
> ? 
> ? 
> ? If that term exists under the model, but it is ignored for purposes of variance estimation, what would be the reason for doing so?
> ? 
> ? > -----Original Message-----
> ? > From: r-sig-mixed-models-bounces at r-project.org<mailto:r-sig-mixed-models-bounces at r-project.org> [mailto:r-sig-mixed-<mailto:r-sig-mixed->
> ? > models-bounces at r-project.org<mailto:models-bounces at r-project.org>] On Behalf Of Andrew Robinson
> ? > Sent: Tuesday, February 05, 2013 9:15 PM
> ? > To: dcarov at gmail.com<mailto:dcarov at gmail.com>
> ? > Cc: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>; Ben Bolker
> ? > Subject: Re: [R-sig-ME] [R] lmer - BLUP prediction intervals
> ? >
> ? > I think that it is a reasonable way to proceed just so long as you interpret the
> ? > intervals guardedly and document your assumptions carefully.
> ? >
> ? > Cheers
> ? >
> ? > Andrew
> ? >
> ? > On Wednesday, February 6, 2013, Daniel Caro wrote:
> ? >
> ? > > Dear all
> ? > >
> ? > > I have not been able to follow the discussion. But I would like to
> ? > > know if it makes sense to calculate prediction intervals like this:
> ? > >
> ? > > var(fixed effect+random effect)= var(fixed effect) + var(random
> ? > > effect) + 0 (i.e., the cov is zero)
> ? > >
> ? > > and based on this create the prediction intervals. Does this make sense?
> ? > >
> ? > > All the best,
> ? > > Daniel
> ? > >
> ? > > On Tue, Feb 5, 2013 at 8:54 PM, Douglas Bates <bates at stat.wisc.edu<mailto:bates at stat.wisc.edu>>
> ? > wrote:
> ? > > > On Tue, Feb 5, 2013 at 2:14 PM, Andrew Robinson <
> ? > > > A.Robinson at ms.unimelb.edu.au<mailto:A.Robinson at ms.unimelb.edu.au>> wrote:
> ? > > >
> ? > > >> I'd have thought that the joint correlation matrix would be of the
> ? > > >> estimates of the fixed effects and the random effects, rather than
> ? > > >> the things themselves.
> ? > > >>
> ? > > >
> ? > > > Well, it may be because I have turned into a grumpy old man but I
> ? > > > get
> ? > > picky
> ? > > > about terminology and the random effects are not parameters - they
> ? > > > are unobserved random variables.  They don't have "estimates" in the
> ? > > > sense of parameter estimates.  The quantities returned by the ranef
> ? > > > function are
> ? > > the
> ? > > > conditional means (in the case of a linear mixed model, conditional
> ? > > > modes in general) of the random effects given the observed data
> ? > > > evaluated with the parameters at their estimated values. In the
> ? > > > Bayesian point of view none of this is problematic because they're
> ? > > > all random variables but otherwise I struggle with the
> ? > > > interpretation of how these can be
> ? > > considered
> ? > > > jointly.   If you want to consider the distribution of the random effects
> ? > > > you need to have known values of the parameters.
> ? > > >
> ? > > >
> ? > > >> The estimates are statistical quantities, with specified
> ? > > >> distributions, under the model.  The model posits these different
> ? > > >> roles (parameter,
> ? > > random
> ? > > >> variable) for the quantities that are the targets of the estimates,
> ? > > >> but
> ? > > the
> ? > > >> estimates are just estimates, and as such, they have a correlation
> ? > > >> structure under the model, and that correlation structure can be
> ? > > estimated.
> ? > > >>
> ? > > >> An imperfect analogy from least-squares regression is the
> ? > > >> correlation structure of residual estimates, induced by the model.
> ? > > >> We say that the errors are independent, but the model creates a
> ? > > >> (modest) correlation structure than can be measured, again, conditional
> ? > on the model.
> ? > > >>
> ? > > >
> ? > > > Well the residuals are random variables and we can show that at the
> ? > > > least squares estimates of the parameters they will have a known
> ? > > > Gaussian distribution which, it turns out, doesn't depend on the
> ? > > > values of the coefficients.  But those are the easy cases.  In the
> ? > > > linear mixed model
> ? > > we
> ? > > > still have a Gaussian distribution and a linear predictor but that
> ? > > > is for the conditional distribution of the response given the random
> ? > effects.
> ? > >  For
> ? > > > the complete model things get much messier.
> ? > > >
> ? > > > I'm not making these points just to be difficult.  I have spent a
> ? > > > lot of time thinking about these models and trying to come up with a
> ? > > > coherent
> ? > > way
> ? > > > of describing them.  Along the way I have come to the conclusion
> ? > > > that the way these models are often described is, well, wrong.  And
> ? > > > those descriptions include some that I have written.  For example,
> ? > > > you often
> ? > > see
> ? > > > the model described as the linear predictor for an observation plus
> ? > > > a "noise" term, epsilon, and the statement that the distribution of
> ? > > > the random effects is independent of the distribution of the noise
> ? > > > term.  I
> ? > > now
> ? > > > view the linear predictor as a part of the conditional distribution
> ? > > > of
> ? > > the
> ? > > > response given the random effects so it wouldn't make sense to talk
> ? > > > about these distributions being independent.  The biggest pitfall in
> ? > > transferring
> ? > > > your thinking from a linear model to any other kind (GLM, LMM, GLMM)
> ? > > > is
> ? > > the
> ? > > > fact that we can make sense of a Gaussian distribution minus its
> ? > > > mean so
> ? > > we
> ? > > > write the linear model in the "signal plus noise" form as Y = X\beta
> ? > > > + \epsilon where Y is an n-dimensional random variable, X is the n
> ? > > > by p
> ? > > model
> ? > > > matrix, \beta is the p-dimensional vector of coefficients and
> ? > > > \epsilon is an n-dimensional Gaussian with mean zero.  That doesn't
> ? > > > work in the other cases, despite the heroic attempts of many people
> ? > > > to write things in that way.
> ? > > >
> ? > > > Here endeth the sermon.
> ? > > >
> ? > > >
> ? > > >> On Wed, Feb 6, 2013 at 6:34 AM, Douglas Bates <bates at stat.wisc.edu<mailto:bates at stat.wisc.edu>>
> ? > > wrote:
> ? > > >>
> ? > > >>> It is possible to create the correlation matrix of the fixed
> ? > > >>> effects
> ? > > and
> ? > > >>> the random effects jointly using the results from lmer but I have
> ? > > >>> difficulty deciding what this would represent statistically.  If
> ? > > >>> you
> ? > > adopt
> ? > > >>> a B
> ? >
> ? >
> ? >
> ? > --
> ? > Andrew Robinson
> ? > Director (A/g), ACERA
> ? > Senior Lecturer in Applied Statistics                      Tel:
> ? > +61-3-8344-6410<tel:%2B61-3-8344-6410>
> ? > Department of Mathematics and Statistics            Fax: +61-3-8344 4599<tel:%2B61-3-8344%204599>
> ? > University of Melbourne, VIC 3010 Australia
> ? > Email: a.robinson at ms.unimelb.edu.au<mailto:a.robinson at ms.unimelb.edu.au>    Website:
> ? > http://www.ms.unimelb.edu.au
> ? >
> ? > FAwR: http://www.ms.unimelb.edu.au/~andrewpr/FAwR/
> ? > SPuR: http://www.ms.unimelb.edu.au/spuRs/
> ? >
> ? >       [[alternative HTML version deleted]]
> ? >
> ? > _______________________________________________
> ? > R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
> ? > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> ? 
> ? _______________________________________________
> ? R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
> ? https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> ? 
> ? 
> ? 	[[alternative HTML version deleted]]
> ? 
> ? _______________________________________________
> ? R-sig-mixed-models at r-project.org mailing list
> ? https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> -- 
>                                 Emmanuel CURIS
>                                 emmanuel.curis at parisdescartes.fr
> 
> Page WWW: http://emmanuel.curis.online.fr/index.html
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Andrew Robinson  
Director (A/g), ACERA 
Department of Mathematics and Statistics            Tel: +61-3-8344-6410
University of Melbourne, VIC 3010 Australia               (prefer email)
http://www.ms.unimelb.edu.au/~andrewpr              Fax: +61-3-8344-4599
http://www.acera.unimelb.edu.au/

Forest Analytics with R (Springer, 2011) 
http://www.ms.unimelb.edu.au/FAwR/
Introduction to Scientific Programming and Simulation using R (CRC, 2009): 
http://www.ms.unimelb.edu.au/spuRs/


From A.Robinson at ms.unimelb.edu.au  Fri Feb  8 06:51:17 2013
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Fri, 8 Feb 2013 16:51:17 +1100
Subject: [R-sig-ME] [R] lmer - BLUP prediction intervals
In-Reply-To: <CAO7JsnRmjhZNWYsV6EfOE5ERTJRmQ6DBXtksxGaT50WLrtqvHg@mail.gmail.com>
References: <CAMeQTh3WwXvEGoeUEPS8ZXbbBWHMA57b9otav5WsQYQ+my6u-g@mail.gmail.com>
	<loom.20130205T192133-238@post.gmane.org>
	<686DF18D10EF1C428C2760321FB5B69E07733386F6@DC1VEX07MB001.air.org>
	<CAO7JsnSYu3hmgoS-dFE9+SVpH1LBuNcDnauyTi3KDJwApisung@mail.gmail.com>
	<CAHyGmd7xA4auGOq5wtvwvGRDzkxetGU70retwGR5=KG-3g6BwQ@mail.gmail.com>
	<CAO7JsnRKB+EoHPSY7GoQk7-6qAgL0+8tH43x5Si2Ex2Nd0QXDQ@mail.gmail.com>
	<CAMeQTh1LKvnEdiM8NKe37KAtQ=pC4NWrTSPNvRx_R97Exk6RzA@mail.gmail.com>
	<CAHyGmd5GhyA8yf8SkK-i=H=5QWxYNTeXDFxxiGoz3H+qB+TR8g@mail.gmail.com>
	<686DF18D10EF1C428C2760321FB5B69E0773338B06@DC1VEX07MB001.air.org>
	<CAO7JsnRmjhZNWYsV6EfOE5ERTJRmQ6DBXtksxGaT50WLrtqvHg@mail.gmail.com>
Message-ID: <20130208055117.GP2026@ms.unimelb.edu.au>

On Thu, Feb 07, 2013 at 08:57:28AM -0600, Douglas Bates wrote:
>    On Wed, Feb 6, 2013 at 9:36 AM, Doran, Harold <[1]HDoran at air.org> wrote:
> 
>      Andrew
> 
>      Ignoring the important theoretical question for just a moment on whether
>      it is sensible to do this, there is a covariance term between the BLUPs
>      and the fixed effects.
> 
> But the picky mathematician in me can't understand in what
> distribution this covariance occurs. It makes sense in the Bayesian
> formulation but not in a classical (sampling theory)
> formulation. 

Not to sound glib or flip, but might it make sense in the
likelihood-based formulation of estimation?

> The distribution of the estimator of the fixed effects for known
> values of the parameters is a multivariate normal that depends on
> \beta, \sigma^2 and \Sigma, the model matrices X and Z being
> known. The random variable B doesn't enter into it.  

I'm sorry to draw this out but I'm not seeing the point right here. If
I've interpreted your model appropriately, I'm now wondering about how
to add the random variable B (a BLUP?) to X \beta.

> (One way of writing this variance-covariance of this multivariate
> normal is X'V^{-1}X where V is that matrix that involves Z and
> Sigma^{-1} - I have forgotten the exact form).  I know these
> considerations sound like needless theoretical niceties but to me
> they're not. I have to be able to formulate the theoretical basis
> before I can make sense of the computational results and, after 20
> years or so, I'm still having trouble making sense of this.

-- 
Andrew Robinson  
Director (A/g), ACERA 
Department of Mathematics and Statistics            Tel: +61-3-8344-6410
University of Melbourne, VIC 3010 Australia               (prefer email)
http://www.ms.unimelb.edu.au/~andrewpr              Fax: +61-3-8344-4599
http://www.acera.unimelb.edu.au/

Forest Analytics with R (Springer, 2011) 
http://www.ms.unimelb.edu.au/FAwR/
Introduction to Scientific Programming and Simulation using R (CRC, 2009): 
http://www.ms.unimelb.edu.au/spuRs/


From dcarov at gmail.com  Fri Feb  8 15:32:53 2013
From: dcarov at gmail.com (Daniel Caro)
Date: Fri, 8 Feb 2013 14:32:53 +0000
Subject: [R-sig-ME] [R] lmer - BLUP prediction intervals
In-Reply-To: <20130207230157.85172inmzpjbdo4k@www.staffmail.ed.ac.uk>
References: <CAMeQTh3WwXvEGoeUEPS8ZXbbBWHMA57b9otav5WsQYQ+my6u-g@mail.gmail.com>
	<loom.20130205T192133-238@post.gmane.org>
	<686DF18D10EF1C428C2760321FB5B69E07733386F6@DC1VEX07MB001.air.org>
	<CAO7JsnSYu3hmgoS-dFE9+SVpH1LBuNcDnauyTi3KDJwApisung@mail.gmail.com>
	<CAHyGmd7xA4auGOq5wtvwvGRDzkxetGU70retwGR5=KG-3g6BwQ@mail.gmail.com>
	<CAO7JsnRKB+EoHPSY7GoQk7-6qAgL0+8tH43x5Si2Ex2Nd0QXDQ@mail.gmail.com>
	<CAMeQTh1LKvnEdiM8NKe37KAtQ=pC4NWrTSPNvRx_R97Exk6RzA@mail.gmail.com>
	<CAHyGmd5GhyA8yf8SkK-i=H=5QWxYNTeXDFxxiGoz3H+qB+TR8g@mail.gmail.com>
	<686DF18D10EF1C428C2760321FB5B69E0773338B06@DC1VEX07MB001.air.org>
	<CAO7JsnRmjhZNWYsV6EfOE5ERTJRmQ6DBXtksxGaT50WLrtqvHg@mail.gmail.com>
	<686DF18D10EF1C428C2760321FB5B69E077390C7CE@DC1VEX07MB001.air.org>
	<20130207230157.85172inmzpjbdo4k@www.staffmail.ed.ac.uk>
Message-ID: <CAMeQTh27HcpOH2cdeqvYnVF+QkeSvi-ZV1O29=WS6VL-7Fy8Mg@mail.gmail.com>

Dear Jarrod

Thank you for the practical advice and thank you all for the
interesting comments.

I was able to calculate Cinv. In my model,

m1 <- lmer(Difference ~ 1+ (1|Item) + (1|Examiner), data=englisho.data)

this matrix is of size 47x47, which is equal to the number of Items
(ni=24) + number of Examiners (ne=22) + number of fixed effects
(nb=1). Or p (1)+q (46) in the lme4 manual. Cinv is not symmetric and
I am wondering how to interpret the position of covariances in the
matrix. I thought the row/columns would be: [overall intercept,
uitem1...uitem24, uexaminer1...uexaminer22]. But it seems not? And is
the diagonal for the random effects for the examiners, for example,
comparable with the results of

attr(ranef(m1, postVar=T)[["Examiner"]], "postVar")[1,1,]

?

Again, thank you for your help.

All the best,
Daniel

On Thu, Feb 7, 2013 at 11:01 PM, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:
> Dear Daniel,
>
> To give a practical, rather than philosophical, solution to your problem you
> could perhaps try this....
>
> W<-cBind(X,Z)
>
> Cinv =
> solve(t(W)%*%W/Vr+bdiag(Diagonal(nb)*0,Diagonal(ne)/Ve,Diagonal(ni)/Vi))
>
>
> where Vr is the residual variance, nb is the number of fixed effects, ne is
> the number of examiners and Ve the examiner variance estimate and ni is the
> number of items and Vi the item variance estimate.
>
> Cinv is the (co)variance matrix of the fixed and random effects (stacked on
> top of each other).  If you take the sub-matrix of Cinv that pertains to the
> effects in your prediction, then summing the elements of that sub-matrix
> will give you something that is close to the prediction variance. In general
> the sub-matrix will not be diagonal (i.e. there are covariances between the
> random effects and the things we are *calling* fixed effects). Vr, Ve and Vn
> are assumed known. If you want to include their uncertainty in the
> prediction interval you will probably have to wear the B-badge more visibly
> on your sleeve I'm afraid.
>
> Cheers,
>
> Jarrod
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
> Quoting "Doran, Harold" <HDoran at air.org> on Thu, 7 Feb 2013 10:02:49 -0500:
>
>> Doug:
>>
>> Sorry if this is too simple a question. Call \hat{\beta}} the estimate of
>> a fixed parameter and \hat{b_i}  the BLUP for unit i.
>>
>> If the following exists
>>
>> \hat{\theta} = \hat{\beta}} + \hat{b_i}
>>
>> Then, does var(\hat{\theta}) also exist?
>>
>>
>> From: dmbates at gmail.com [mailto:dmbates at gmail.com] On Behalf Of Douglas
>> Bates
>> Sent: Thursday, February 07, 2013 9:57 AM
>> To: Doran, Harold
>> Cc: Andrew Robinson; dcarov at gmail.com; r-sig-mixed-models at r-project.org;
>> Ben Bolker
>> Subject: Re: [R-sig-ME] [R] lmer - BLUP prediction intervals
>>
>> On Wed, Feb 6, 2013 at 9:36 AM, Doran, Harold
>> <HDoran at air.org<mailto:HDoran at air.org>> wrote:
>> Andrew
>>
>> Ignoring the important theoretical question for just a moment on whether
>> it is sensible to do this, there is a covariance term between the BLUPs and
>> the fixed effects.
>>
>> But the picky mathematician in me can't understand in what distribution
>> this covariance occurs.  It makes sense in the Bayesian formulation but not
>> in a classical (sampling theory) formulation.  The distribution of the
>> estimator of the fixed effects for known values of the parameters is a
>> multivariate normal that depends on \beta, \sigma^2 and \Sigma, the model
>> matrices X and Z being known.  The random variable B doesn't enter into it.
>> (One way of writing this variance-covariance of this multivariate normal is
>> X'V^{-1}X where V is that matrix that involves Z and Sigma^{-1} - I have
>> forgotten the exact form).
>>
>> I know these considerations sound like needless theoretical niceties but
>> to me they're not. I have to be able to formulate the theoretical basis
>> before I can make sense of the computational results and, after 20 years or
>> so, I'm still having trouble making sense of this.
>>
>>
>> If that term exists under the model, but it is ignored for purposes of
>> variance estimation, what would be the reason for doing so?
>>
>>> -----Original Message-----
>>> From:
>>> r-sig-mixed-models-bounces at r-project.org<mailto:r-sig-mixed-models-bounces at r-project.org>
>>> [mailto:r-sig-mixed-<mailto:r-sig-mixed->
>>> models-bounces at r-project.org<mailto:models-bounces at r-project.org>] On
>>> Behalf Of Andrew Robinson
>>> Sent: Tuesday, February 05, 2013 9:15 PM
>>> To: dcarov at gmail.com<mailto:dcarov at gmail.com>
>>> Cc:
>>> r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>;
>>> Ben Bolker
>>> Subject: Re: [R-sig-ME] [R] lmer - BLUP prediction intervals
>>>
>>> I think that it is a reasonable way to proceed just so long as you
>>> interpret the
>>> intervals guardedly and document your assumptions carefully.
>>>
>>> Cheers
>>>
>>> Andrew
>>>
>>> On Wednesday, February 6, 2013, Daniel Caro wrote:
>>>
>>> > Dear all
>>> >
>>> > I have not been able to follow the discussion. But I would like to
>>> > know if it makes sense to calculate prediction intervals like this:
>>> >
>>> > var(fixed effect+random effect)= var(fixed effect) + var(random
>>> > effect) + 0 (i.e., the cov is zero)
>>> >
>>> > and based on this create the prediction intervals. Does this make
>>> > sense?
>>> >
>>> > All the best,
>>> > Daniel
>>> >
>>> > On Tue, Feb 5, 2013 at 8:54 PM, Douglas Bates
>>> > <bates at stat.wisc.edu<mailto:bates at stat.wisc.edu>>
>>>
>>> wrote:
>>> > > On Tue, Feb 5, 2013 at 2:14 PM, Andrew Robinson <
>>> > > A.Robinson at ms.unimelb.edu.au<mailto:A.Robinson at ms.unimelb.edu.au>>
>>> > > wrote:
>>> > >
>>> > >> I'd have thought that the joint correlation matrix would be of the
>>> > >> estimates of the fixed effects and the random effects, rather than
>>> > >> the things themselves.
>>> > >>
>>> > >
>>> > > Well, it may be because I have turned into a grumpy old man but I
>>> > > get
>>> > picky
>>> > > about terminology and the random effects are not parameters - they
>>> > > are unobserved random variables.  They don't have "estimates" in the
>>> > > sense of parameter estimates.  The quantities returned by the ranef
>>> > > function are
>>> > the
>>> > > conditional means (in the case of a linear mixed model, conditional
>>> > > modes in general) of the random effects given the observed data
>>> > > evaluated with the parameters at their estimated values. In the
>>> > > Bayesian point of view none of this is problematic because they're
>>> > > all random variables but otherwise I struggle with the
>>> > > interpretation of how these can be
>>> > considered
>>> > > jointly.   If you want to consider the distribution of the random
>>> > > effects
>>> > > you need to have known values of the parameters.
>>> > >
>>> > >
>>> > >> The estimates are statistical quantities, with specified
>>> > >> distributions, under the model.  The model posits these different
>>> > >> roles (parameter,
>>> > random
>>> > >> variable) for the quantities that are the targets of the estimates,
>>> > >> but
>>> > the
>>> > >> estimates are just estimates, and as such, they have a correlation
>>> > >> structure under the model, and that correlation structure can be
>>> > estimated.
>>> > >>
>>> > >> An imperfect analogy from least-squares regression is the
>>> > >> correlation structure of residual estimates, induced by the model.
>>> > >> We say that the errors are independent, but the model creates a
>>> > >> (modest) correlation structure than can be measured, again,
>>> > >> conditional
>>> on the model.
>>> > >>
>>> > >
>>> > > Well the residuals are random variables and we can show that at the
>>> > > least squares estimates of the parameters they will have a known
>>> > > Gaussian distribution which, it turns out, doesn't depend on the
>>> > > values of the coefficients.  But those are the easy cases.  In the
>>> > > linear mixed model
>>> > we
>>> > > still have a Gaussian distribution and a linear predictor but that
>>> > > is for the conditional distribution of the response given the random
>>> effects.
>>> >  For
>>> > > the complete model things get much messier.
>>> > >
>>> > > I'm not making these points just to be difficult.  I have spent a
>>> > > lot of time thinking about these models and trying to come up with a
>>> > > coherent
>>> > way
>>> > > of describing them.  Along the way I have come to the conclusion
>>> > > that the way these models are often described is, well, wrong.  And
>>> > > those descriptions include some that I have written.  For example,
>>> > > you often
>>> > see
>>> > > the model described as the linear predictor for an observation plus
>>> > > a "noise" term, epsilon, and the statement that the distribution of
>>> > > the random effects is independent of the distribution of the noise
>>> > > term.  I
>>> > now
>>> > > view the linear predictor as a part of the conditional distribution
>>> > > of
>>> > the
>>> > > response given the random effects so it wouldn't make sense to talk
>>> > > about these distributions being independent.  The biggest pitfall in
>>> > transferring
>>> > > your thinking from a linear model to any other kind (GLM, LMM, GLMM)
>>> > > is
>>> > the
>>> > > fact that we can make sense of a Gaussian distribution minus its
>>> > > mean so
>>> > we
>>> > > write the linear model in the "signal plus noise" form as Y = X\beta
>>> > > + \epsilon where Y is an n-dimensional random variable, X is the n
>>> > > by p
>>> > model
>>> > > matrix, \beta is the p-dimensional vector of coefficients and
>>> > > \epsilon is an n-dimensional Gaussian with mean zero.  That doesn't
>>> > > work in the other cases, despite the heroic attempts of many people
>>> > > to write things in that way.
>>> > >
>>> > > Here endeth the sermon.
>>> > >
>>> > >
>>> > >> On Wed, Feb 6, 2013 at 6:34 AM, Douglas Bates
>>> > >> <bates at stat.wisc.edu<mailto:bates at stat.wisc.edu>>
>>>
>>> > wrote:
>>> > >>
>>> > >>> It is possible to create the correlation matrix of the fixed
>>> > >>> effects
>>> > and
>>> > >>> the random effects jointly using the results from lmer but I have
>>> > >>> difficulty deciding what this would represent statistically.  If
>>> > >>> you
>>> > adopt
>>> > >>> a B
>>>
>>>
>>>
>>> --
>>> Andrew Robinson
>>> Director (A/g), ACERA
>>> Senior Lecturer in Applied Statistics                      Tel:
>>> +61-3-8344-6410<tel:%2B61-3-8344-6410>
>>> Department of Mathematics and Statistics            Fax: +61-3-8344
>>> 4599<tel:%2B61-3-8344%204599>
>>>
>>> University of Melbourne, VIC 3010 Australia
>>> Email: a.robinson at ms.unimelb.edu.au<mailto:a.robinson at ms.unimelb.edu.au>
>>> Website:
>>>
>>> http://www.ms.unimelb.edu.au
>>>
>>> FAwR: http://www.ms.unimelb.edu.au/~andrewpr/FAwR/
>>> SPuR: http://www.ms.unimelb.edu.au/spuRs/
>>>
>>>       [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org>
>>> mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org>
>> mailing list
>>
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>
>
> --
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
>
>


From j.hadfield at ed.ac.uk  Fri Feb  8 16:18:30 2013
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Fri, 08 Feb 2013 15:18:30 +0000
Subject: [R-sig-ME] [R] lmer - BLUP prediction intervals
In-Reply-To: <CAMeQTh27HcpOH2cdeqvYnVF+QkeSvi-ZV1O29=WS6VL-7Fy8Mg@mail.gmail.com>
References: <CAMeQTh3WwXvEGoeUEPS8ZXbbBWHMA57b9otav5WsQYQ+my6u-g@mail.gmail.com>
	<loom.20130205T192133-238@post.gmane.org>
	<686DF18D10EF1C428C2760321FB5B69E07733386F6@DC1VEX07MB001.air.org>
	<CAO7JsnSYu3hmgoS-dFE9+SVpH1LBuNcDnauyTi3KDJwApisung@mail.gmail.com>
	<CAHyGmd7xA4auGOq5wtvwvGRDzkxetGU70retwGR5=KG-3g6BwQ@mail.gmail.com>
	<CAO7JsnRKB+EoHPSY7GoQk7-6qAgL0+8tH43x5Si2Ex2Nd0QXDQ@mail.gmail.com>
	<CAMeQTh1LKvnEdiM8NKe37KAtQ=pC4NWrTSPNvRx_R97Exk6RzA@mail.gmail.com>
	<CAHyGmd5GhyA8yf8SkK-i=H=5QWxYNTeXDFxxiGoz3H+qB+TR8g@mail.gmail.com>
	<686DF18D10EF1C428C2760321FB5B69E0773338B06@DC1VEX07MB001.air.org>
	<CAO7JsnRmjhZNWYsV6EfOE5ERTJRmQ6DBXtksxGaT50WLrtqvHg@mail.gmail.com>
	<686DF18D10EF1C428C2760321FB5B69E077390C7CE@DC1VEX07MB001.air.org>
	<20130207230157.85172inmzpjbdo4k@www.staffmail.ed.ac.uk>
	<CAMeQTh27HcpOH2cdeqvYnVF+QkeSvi-ZV1O29=WS6VL-7Fy8Mg@mail.gmail.com>
Message-ID: <20130208151830.101760jpxbnhmj48@www.staffmail.ed.ac.uk>

Dear Daniel,

Cinv should be symmetrical (although it might differ slightly because  
of rounding errors when inverting). The row/columns should be   
[overall intercept,
,uitem1...uitem24, uexaminer1...uexaminer22] for your m1 model in this  
posting. However, in your original posting you fitted item/examiner in  
a different order:

m1 <- lmer(Difference ~ 1+  (1|Examiner) + (1|Item), data=englisho.data)

and it was for this model for which my Cinv code would work.

I thought

attr(ranef(m1, postVar=T)[["Examiner"]], "postVar")[1,1,]

would be equal to diag(Cinv[1+1:ne]) (from the original specification:  
Examiner before Item) but actually it seems closer to something like  
this:

  C = t(W)%*%W/Vr+bdiag(Diagonal(nb)*0,Diagonal(ne)/Ve,Diagonal(ni)/Vi)

  Cinv = solve(C[-c(1:nb),-c(1:nb)])

  diag(Cinv)[1:ne]

I don't think this is a good thing - it assumes the fixed effects, as  
well as the variance parameters, are known without error.

Cheers,

Jarrod









Quoting Daniel Caro <dcarov at gmail.com> on Fri, 8 Feb 2013 14:32:53 +0000:

> Dear Jarrod
>
> Thank you for the practical advice and thank you all for the
> interesting comments.
>
> I was able to calculate Cinv. In my model,
>
> m1 <- lmer(Difference ~ 1+ (1|Item) + (1|Examiner), data=englisho.data)
>
> this matrix is of size 47x47, which is equal to the number of Items
> (ni=24) + number of Examiners (ne=22) + number of fixed effects
> (nb=1). Or p (1)+q (46) in the lme4 manual. Cinv is not symmetric and
> I am wondering how to interpret the position of covariances in the
> matrix. I thought the row/columns would be: [overall intercept,
> uitem1...uitem24, uexaminer1...uexaminer22]. But it seems not? And is
> the diagonal for the random effects for the examiners, for example,
> comparable with the results of
>
> attr(ranef(m1, postVar=T)[["Examiner"]], "postVar")[1,1,]
>
> ?
>
> Again, thank you for your help.
>
> All the best,
> Daniel
>
> On Thu, Feb 7, 2013 at 11:01 PM, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:
>> Dear Daniel,
>>
>> To give a practical, rather than philosophical, solution to your problem you
>> could perhaps try this....
>>
>> W<-cBind(X,Z)
>>
>> Cinv =
>> solve(t(W)%*%W/Vr+bdiag(Diagonal(nb)*0,Diagonal(ne)/Ve,Diagonal(ni)/Vi))
>>
>>
>> where Vr is the residual variance, nb is the number of fixed effects, ne is
>> the number of examiners and Ve the examiner variance estimate and ni is the
>> number of items and Vi the item variance estimate.
>>
>> Cinv is the (co)variance matrix of the fixed and random effects (stacked on
>> top of each other).  If you take the sub-matrix of Cinv that pertains to the
>> effects in your prediction, then summing the elements of that sub-matrix
>> will give you something that is close to the prediction variance. In general
>> the sub-matrix will not be diagonal (i.e. there are covariances between the
>> random effects and the things we are *calling* fixed effects). Vr, Ve and Vn
>> are assumed known. If you want to include their uncertainty in the
>> prediction interval you will probably have to wear the B-badge more visibly
>> on your sleeve I'm afraid.
>>
>> Cheers,
>>
>> Jarrod
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>> Quoting "Doran, Harold" <HDoran at air.org> on Thu, 7 Feb 2013 10:02:49 -0500:
>>
>>> Doug:
>>>
>>> Sorry if this is too simple a question. Call \hat{\beta}} the estimate of
>>> a fixed parameter and \hat{b_i}  the BLUP for unit i.
>>>
>>> If the following exists
>>>
>>> \hat{\theta} = \hat{\beta}} + \hat{b_i}
>>>
>>> Then, does var(\hat{\theta}) also exist?
>>>
>>>
>>> From: dmbates at gmail.com [mailto:dmbates at gmail.com] On Behalf Of Douglas
>>> Bates
>>> Sent: Thursday, February 07, 2013 9:57 AM
>>> To: Doran, Harold
>>> Cc: Andrew Robinson; dcarov at gmail.com; r-sig-mixed-models at r-project.org;
>>> Ben Bolker
>>> Subject: Re: [R-sig-ME] [R] lmer - BLUP prediction intervals
>>>
>>> On Wed, Feb 6, 2013 at 9:36 AM, Doran, Harold
>>> <HDoran at air.org<mailto:HDoran at air.org>> wrote:
>>> Andrew
>>>
>>> Ignoring the important theoretical question for just a moment on whether
>>> it is sensible to do this, there is a covariance term between the BLUPs and
>>> the fixed effects.
>>>
>>> But the picky mathematician in me can't understand in what distribution
>>> this covariance occurs.  It makes sense in the Bayesian formulation but not
>>> in a classical (sampling theory) formulation.  The distribution of the
>>> estimator of the fixed effects for known values of the parameters is a
>>> multivariate normal that depends on \beta, \sigma^2 and \Sigma, the model
>>> matrices X and Z being known.  The random variable B doesn't enter into it.
>>> (One way of writing this variance-covariance of this multivariate normal is
>>> X'V^{-1}X where V is that matrix that involves Z and Sigma^{-1} - I have
>>> forgotten the exact form).
>>>
>>> I know these considerations sound like needless theoretical niceties but
>>> to me they're not. I have to be able to formulate the theoretical basis
>>> before I can make sense of the computational results and, after 20 years or
>>> so, I'm still having trouble making sense of this.
>>>
>>>
>>> If that term exists under the model, but it is ignored for purposes of
>>> variance estimation, what would be the reason for doing so?
>>>
>>>> -----Original Message-----
>>>> From:
>>>> r-sig-mixed-models-bounces at r-project.org<mailto:r-sig-mixed-models-bounces at r-project.org>
>>>> [mailto:r-sig-mixed-<mailto:r-sig-mixed->
>>>> models-bounces at r-project.org<mailto:models-bounces at r-project.org>] On
>>>> Behalf Of Andrew Robinson
>>>> Sent: Tuesday, February 05, 2013 9:15 PM
>>>> To: dcarov at gmail.com<mailto:dcarov at gmail.com>
>>>> Cc:
>>>> r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>;
>>>> Ben Bolker
>>>> Subject: Re: [R-sig-ME] [R] lmer - BLUP prediction intervals
>>>>
>>>> I think that it is a reasonable way to proceed just so long as you
>>>> interpret the
>>>> intervals guardedly and document your assumptions carefully.
>>>>
>>>> Cheers
>>>>
>>>> Andrew
>>>>
>>>> On Wednesday, February 6, 2013, Daniel Caro wrote:
>>>>
>>>> > Dear all
>>>> >
>>>> > I have not been able to follow the discussion. But I would like to
>>>> > know if it makes sense to calculate prediction intervals like this:
>>>> >
>>>> > var(fixed effect+random effect)= var(fixed effect) + var(random
>>>> > effect) + 0 (i.e., the cov is zero)
>>>> >
>>>> > and based on this create the prediction intervals. Does this make
>>>> > sense?
>>>> >
>>>> > All the best,
>>>> > Daniel
>>>> >
>>>> > On Tue, Feb 5, 2013 at 8:54 PM, Douglas Bates
>>>> > <bates at stat.wisc.edu<mailto:bates at stat.wisc.edu>>
>>>>
>>>> wrote:
>>>> > > On Tue, Feb 5, 2013 at 2:14 PM, Andrew Robinson <
>>>> > > A.Robinson at ms.unimelb.edu.au<mailto:A.Robinson at ms.unimelb.edu.au>>
>>>> > > wrote:
>>>> > >
>>>> > >> I'd have thought that the joint correlation matrix would be of the
>>>> > >> estimates of the fixed effects and the random effects, rather than
>>>> > >> the things themselves.
>>>> > >>
>>>> > >
>>>> > > Well, it may be because I have turned into a grumpy old man but I
>>>> > > get
>>>> > picky
>>>> > > about terminology and the random effects are not parameters - they
>>>> > > are unobserved random variables.  They don't have "estimates" in the
>>>> > > sense of parameter estimates.  The quantities returned by the ranef
>>>> > > function are
>>>> > the
>>>> > > conditional means (in the case of a linear mixed model, conditional
>>>> > > modes in general) of the random effects given the observed data
>>>> > > evaluated with the parameters at their estimated values. In the
>>>> > > Bayesian point of view none of this is problematic because they're
>>>> > > all random variables but otherwise I struggle with the
>>>> > > interpretation of how these can be
>>>> > considered
>>>> > > jointly.   If you want to consider the distribution of the random
>>>> > > effects
>>>> > > you need to have known values of the parameters.
>>>> > >
>>>> > >
>>>> > >> The estimates are statistical quantities, with specified
>>>> > >> distributions, under the model.  The model posits these different
>>>> > >> roles (parameter,
>>>> > random
>>>> > >> variable) for the quantities that are the targets of the estimates,
>>>> > >> but
>>>> > the
>>>> > >> estimates are just estimates, and as such, they have a correlation
>>>> > >> structure under the model, and that correlation structure can be
>>>> > estimated.
>>>> > >>
>>>> > >> An imperfect analogy from least-squares regression is the
>>>> > >> correlation structure of residual estimates, induced by the model.
>>>> > >> We say that the errors are independent, but the model creates a
>>>> > >> (modest) correlation structure than can be measured, again,
>>>> > >> conditional
>>>> on the model.
>>>> > >>
>>>> > >
>>>> > > Well the residuals are random variables and we can show that at the
>>>> > > least squares estimates of the parameters they will have a known
>>>> > > Gaussian distribution which, it turns out, doesn't depend on the
>>>> > > values of the coefficients.  But those are the easy cases.  In the
>>>> > > linear mixed model
>>>> > we
>>>> > > still have a Gaussian distribution and a linear predictor but that
>>>> > > is for the conditional distribution of the response given the random
>>>> effects.
>>>> >  For
>>>> > > the complete model things get much messier.
>>>> > >
>>>> > > I'm not making these points just to be difficult.  I have spent a
>>>> > > lot of time thinking about these models and trying to come up with a
>>>> > > coherent
>>>> > way
>>>> > > of describing them.  Along the way I have come to the conclusion
>>>> > > that the way these models are often described is, well, wrong.  And
>>>> > > those descriptions include some that I have written.  For example,
>>>> > > you often
>>>> > see
>>>> > > the model described as the linear predictor for an observation plus
>>>> > > a "noise" term, epsilon, and the statement that the distribution of
>>>> > > the random effects is independent of the distribution of the noise
>>>> > > term.  I
>>>> > now
>>>> > > view the linear predictor as a part of the conditional distribution
>>>> > > of
>>>> > the
>>>> > > response given the random effects so it wouldn't make sense to talk
>>>> > > about these distributions being independent.  The biggest pitfall in
>>>> > transferring
>>>> > > your thinking from a linear model to any other kind (GLM, LMM, GLMM)
>>>> > > is
>>>> > the
>>>> > > fact that we can make sense of a Gaussian distribution minus its
>>>> > > mean so
>>>> > we
>>>> > > write the linear model in the "signal plus noise" form as Y = X\beta
>>>> > > + \epsilon where Y is an n-dimensional random variable, X is the n
>>>> > > by p
>>>> > model
>>>> > > matrix, \beta is the p-dimensional vector of coefficients and
>>>> > > \epsilon is an n-dimensional Gaussian with mean zero.  That doesn't
>>>> > > work in the other cases, despite the heroic attempts of many people
>>>> > > to write things in that way.
>>>> > >
>>>> > > Here endeth the sermon.
>>>> > >
>>>> > >
>>>> > >> On Wed, Feb 6, 2013 at 6:34 AM, Douglas Bates
>>>> > >> <bates at stat.wisc.edu<mailto:bates at stat.wisc.edu>>
>>>>
>>>> > wrote:
>>>> > >>
>>>> > >>> It is possible to create the correlation matrix of the fixed
>>>> > >>> effects
>>>> > and
>>>> > >>> the random effects jointly using the results from lmer but I have
>>>> > >>> difficulty deciding what this would represent statistically.  If
>>>> > >>> you
>>>> > adopt
>>>> > >>> a B
>>>>
>>>>
>>>>
>>>> --
>>>> Andrew Robinson
>>>> Director (A/g), ACERA
>>>> Senior Lecturer in Applied Statistics                      Tel:
>>>> +61-3-8344-6410<tel:%2B61-3-8344-6410>
>>>> Department of Mathematics and Statistics            Fax: +61-3-8344
>>>> 4599<tel:%2B61-3-8344%204599>
>>>>
>>>> University of Melbourne, VIC 3010 Australia
>>>> Email: a.robinson at ms.unimelb.edu.au<mailto:a.robinson at ms.unimelb.edu.au>
>>>> Website:
>>>>
>>>> http://www.ms.unimelb.edu.au
>>>>
>>>> FAwR: http://www.ms.unimelb.edu.au/~andrewpr/FAwR/
>>>> SPuR: http://www.ms.unimelb.edu.au/spuRs/
>>>>
>>>>       [[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org>
>>>> mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org>
>>> mailing list
>>>
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>>
>>
>>
>> --
>> The University of Edinburgh is a charitable body, registered in
>> Scotland, with registration number SC005336.
>>
>>
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From dcarov at gmail.com  Fri Feb  8 16:32:17 2013
From: dcarov at gmail.com (Daniel Caro)
Date: Fri, 8 Feb 2013 15:32:17 +0000
Subject: [R-sig-ME] [R] lmer - BLUP prediction intervals
In-Reply-To: <20130208151830.101760jpxbnhmj48@www.staffmail.ed.ac.uk>
References: <CAMeQTh3WwXvEGoeUEPS8ZXbbBWHMA57b9otav5WsQYQ+my6u-g@mail.gmail.com>
	<loom.20130205T192133-238@post.gmane.org>
	<686DF18D10EF1C428C2760321FB5B69E07733386F6@DC1VEX07MB001.air.org>
	<CAO7JsnSYu3hmgoS-dFE9+SVpH1LBuNcDnauyTi3KDJwApisung@mail.gmail.com>
	<CAHyGmd7xA4auGOq5wtvwvGRDzkxetGU70retwGR5=KG-3g6BwQ@mail.gmail.com>
	<CAO7JsnRKB+EoHPSY7GoQk7-6qAgL0+8tH43x5Si2Ex2Nd0QXDQ@mail.gmail.com>
	<CAMeQTh1LKvnEdiM8NKe37KAtQ=pC4NWrTSPNvRx_R97Exk6RzA@mail.gmail.com>
	<CAHyGmd5GhyA8yf8SkK-i=H=5QWxYNTeXDFxxiGoz3H+qB+TR8g@mail.gmail.com>
	<686DF18D10EF1C428C2760321FB5B69E0773338B06@DC1VEX07MB001.air.org>
	<CAO7JsnRmjhZNWYsV6EfOE5ERTJRmQ6DBXtksxGaT50WLrtqvHg@mail.gmail.com>
	<686DF18D10EF1C428C2760321FB5B69E077390C7CE@DC1VEX07MB001.air.org>
	<20130207230157.85172inmzpjbdo4k@www.staffmail.ed.ac.uk>
	<CAMeQTh27HcpOH2cdeqvYnVF+QkeSvi-ZV1O29=WS6VL-7Fy8Mg@mail.gmail.com>
	<20130208151830.101760jpxbnhmj48@www.staffmail.ed.ac.uk>
Message-ID: <CAMeQTh0HRUw0qMnvHsEAPcv+n6EX2V+mEFTEWZ5Q-ZX=ngs7VA@mail.gmail.com>

Dear Jarrod

Thank you so much and sorry for the confusion. I recalculated Cinv
with the original specification

m1 <- lmer(Difference ~ 1+  (1|Examiner) + (1|Item), data=englisho.data)

and it is now symmetrical. I will assume the following ordering
[overall intercept, uexaminer1...uexaminer22, uitem1...uitem24] and
will use attr(ranef(m1, postVar=T)[["Examiner"]], "postVar")[1,1,] for
the variances of random effects and Cinv for the covariances with
fixed effects.

All the best,
Daniel

On Fri, Feb 8, 2013 at 3:18 PM, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:
> Dear Daniel,
>
> Cinv should be symmetrical (although it might differ slightly because of
> rounding errors when inverting). The row/columns should be  [overall
> intercept,
> ,uitem1...uitem24, uexaminer1...uexaminer22] for your m1 model in this
> posting. However, in your original posting you fitted item/examiner in a
> different order:
>
>
> m1 <- lmer(Difference ~ 1+  (1|Examiner) + (1|Item), data=englisho.data)
>
> and it was for this model for which my Cinv code would work.
>
> I thought
>
>
> attr(ranef(m1, postVar=T)[["Examiner"]], "postVar")[1,1,]
>
> would be equal to diag(Cinv[1+1:ne]) (from the original specification:
> Examiner before Item) but actually it seems closer to something like this:
>
>  C = t(W)%*%W/Vr+bdiag(Diagonal(nb)*0,Diagonal(ne)/Ve,Diagonal(ni)/Vi)
>
>  Cinv = solve(C[-c(1:nb),-c(1:nb)])
>
>  diag(Cinv)[1:ne]
>
> I don't think this is a good thing - it assumes the fixed effects, as well
> as the variance parameters, are known without error.
>
> Cheers,
>
> Jarrod
>
>
>
>
>
>
>
>
>
>
> Quoting Daniel Caro <dcarov at gmail.com> on Fri, 8 Feb 2013 14:32:53 +0000:
>
>> Dear Jarrod
>>
>> Thank you for the practical advice and thank you all for the
>> interesting comments.
>>
>> I was able to calculate Cinv. In my model,
>>
>> m1 <- lmer(Difference ~ 1+ (1|Item) + (1|Examiner), data=englisho.data)
>>
>> this matrix is of size 47x47, which is equal to the number of Items
>> (ni=24) + number of Examiners (ne=22) + number of fixed effects
>> (nb=1). Or p (1)+q (46) in the lme4 manual. Cinv is not symmetric and
>> I am wondering how to interpret the position of covariances in the
>> matrix. I thought the row/columns would be: [overall intercept,
>> uitem1...uitem24, uexaminer1...uexaminer22]. But it seems not? And is
>> the diagonal for the random effects for the examiners, for example,
>> comparable with the results of
>>
>> attr(ranef(m1, postVar=T)[["Examiner"]], "postVar")[1,1,]
>>
>> ?
>>
>> Again, thank you for your help.
>>
>> All the best,
>> Daniel
>>
>> On Thu, Feb 7, 2013 at 11:01 PM, Jarrod Hadfield <j.hadfield at ed.ac.uk>
>> wrote:
>>>
>>> Dear Daniel,
>>>
>>> To give a practical, rather than philosophical, solution to your problem
>>> you
>>> could perhaps try this....
>>>
>>> W<-cBind(X,Z)
>>>
>>> Cinv =
>>> solve(t(W)%*%W/Vr+bdiag(Diagonal(nb)*0,Diagonal(ne)/Ve,Diagonal(ni)/Vi))
>>>
>>>
>>> where Vr is the residual variance, nb is the number of fixed effects, ne
>>> is
>>> the number of examiners and Ve the examiner variance estimate and ni is
>>> the
>>> number of items and Vi the item variance estimate.
>>>
>>> Cinv is the (co)variance matrix of the fixed and random effects (stacked
>>> on
>>> top of each other).  If you take the sub-matrix of Cinv that pertains to
>>> the
>>> effects in your prediction, then summing the elements of that sub-matrix
>>> will give you something that is close to the prediction variance. In
>>> general
>>> the sub-matrix will not be diagonal (i.e. there are covariances between
>>> the
>>> random effects and the things we are *calling* fixed effects). Vr, Ve and
>>> Vn
>>> are assumed known. If you want to include their uncertainty in the
>>> prediction interval you will probably have to wear the B-badge more
>>> visibly
>>> on your sleeve I'm afraid.
>>>
>>> Cheers,
>>>
>>> Jarrod
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>> Quoting "Doran, Harold" <HDoran at air.org> on Thu, 7 Feb 2013 10:02:49
>>> -0500:
>>>
>>>> Doug:
>>>>
>>>> Sorry if this is too simple a question. Call \hat{\beta}} the estimate
>>>> of
>>>> a fixed parameter and \hat{b_i}  the BLUP for unit i.
>>>>
>>>> If the following exists
>>>>
>>>> \hat{\theta} = \hat{\beta}} + \hat{b_i}
>>>>
>>>> Then, does var(\hat{\theta}) also exist?
>>>>
>>>>
>>>> From: dmbates at gmail.com [mailto:dmbates at gmail.com] On Behalf Of Douglas
>>>> Bates
>>>> Sent: Thursday, February 07, 2013 9:57 AM
>>>> To: Doran, Harold
>>>> Cc: Andrew Robinson; dcarov at gmail.com; r-sig-mixed-models at r-project.org;
>>>> Ben Bolker
>>>> Subject: Re: [R-sig-ME] [R] lmer - BLUP prediction intervals
>>>>
>>>> On Wed, Feb 6, 2013 at 9:36 AM, Doran, Harold
>>>> <HDoran at air.org<mailto:HDoran at air.org>> wrote:
>>>> Andrew
>>>>
>>>> Ignoring the important theoretical question for just a moment on whether
>>>> it is sensible to do this, there is a covariance term between the BLUPs
>>>> and
>>>> the fixed effects.
>>>>
>>>> But the picky mathematician in me can't understand in what distribution
>>>> this covariance occurs.  It makes sense in the Bayesian formulation but
>>>> not
>>>> in a classical (sampling theory) formulation.  The distribution of the
>>>> estimator of the fixed effects for known values of the parameters is a
>>>> multivariate normal that depends on \beta, \sigma^2 and \Sigma, the
>>>> model
>>>> matrices X and Z being known.  The random variable B doesn't enter into
>>>> it.
>>>> (One way of writing this variance-covariance of this multivariate normal
>>>> is
>>>> X'V^{-1}X where V is that matrix that involves Z and Sigma^{-1} - I have
>>>> forgotten the exact form).
>>>>
>>>> I know these considerations sound like needless theoretical niceties but
>>>> to me they're not. I have to be able to formulate the theoretical basis
>>>> before I can make sense of the computational results and, after 20 years
>>>> or
>>>> so, I'm still having trouble making sense of this.
>>>>
>>>>
>>>> If that term exists under the model, but it is ignored for purposes of
>>>> variance estimation, what would be the reason for doing so?
>>>>
>>>>> -----Original Message-----
>>>>> From:
>>>>>
>>>>> r-sig-mixed-models-bounces at r-project.org<mailto:r-sig-mixed-models-bounces at r-project.org>
>>>>> [mailto:r-sig-mixed-<mailto:r-sig-mixed->
>>>>> models-bounces at r-project.org<mailto:models-bounces at r-project.org>] On
>>>>> Behalf Of Andrew Robinson
>>>>> Sent: Tuesday, February 05, 2013 9:15 PM
>>>>> To: dcarov at gmail.com<mailto:dcarov at gmail.com>
>>>>> Cc:
>>>>>
>>>>> r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>;
>>>>> Ben Bolker
>>>>> Subject: Re: [R-sig-ME] [R] lmer - BLUP prediction intervals
>>>>>
>>>>> I think that it is a reasonable way to proceed just so long as you
>>>>> interpret the
>>>>> intervals guardedly and document your assumptions carefully.
>>>>>
>>>>> Cheers
>>>>>
>>>>> Andrew
>>>>>
>>>>> On Wednesday, February 6, 2013, Daniel Caro wrote:
>>>>>
>>>>> > Dear all
>>>>> >
>>>>> > I have not been able to follow the discussion. But I would like to
>>>>> > know if it makes sense to calculate prediction intervals like this:
>>>>> >
>>>>> > var(fixed effect+random effect)= var(fixed effect) + var(random
>>>>> > effect) + 0 (i.e., the cov is zero)
>>>>> >
>>>>> > and based on this create the prediction intervals. Does this make
>>>>> > sense?
>>>>> >
>>>>> > All the best,
>>>>> > Daniel
>>>>> >
>>>>> > On Tue, Feb 5, 2013 at 8:54 PM, Douglas Bates
>>>>> > <bates at stat.wisc.edu<mailto:bates at stat.wisc.edu>>
>>>>>
>>>>> wrote:
>>>>> > > On Tue, Feb 5, 2013 at 2:14 PM, Andrew Robinson <
>>>>> > > A.Robinson at ms.unimelb.edu.au<mailto:A.Robinson at ms.unimelb.edu.au>>
>>>>> > > wrote:
>>>>> > >
>>>>> > >> I'd have thought that the joint correlation matrix would be of the
>>>>> > >> estimates of the fixed effects and the random effects, rather than
>>>>> > >> the things themselves.
>>>>> > >>
>>>>> > >
>>>>> > > Well, it may be because I have turned into a grumpy old man but I
>>>>> > > get
>>>>> > picky
>>>>> > > about terminology and the random effects are not parameters - they
>>>>> > > are unobserved random variables.  They don't have "estimates" in
>>>>> > > the
>>>>> > > sense of parameter estimates.  The quantities returned by the ranef
>>>>> > > function are
>>>>> > the
>>>>> > > conditional means (in the case of a linear mixed model, conditional
>>>>> > > modes in general) of the random effects given the observed data
>>>>> > > evaluated with the parameters at their estimated values. In the
>>>>> > > Bayesian point of view none of this is problematic because they're
>>>>> > > all random variables but otherwise I struggle with the
>>>>> > > interpretation of how these can be
>>>>> > considered
>>>>> > > jointly.   If you want to consider the distribution of the random
>>>>> > > effects
>>>>> > > you need to have known values of the parameters.
>>>>> > >
>>>>> > >
>>>>> > >> The estimates are statistical quantities, with specified
>>>>> > >> distributions, under the model.  The model posits these different
>>>>> > >> roles (parameter,
>>>>> > random
>>>>> > >> variable) for the quantities that are the targets of the
>>>>> > >> estimates,
>>>>> > >> but
>>>>> > the
>>>>> > >> estimates are just estimates, and as such, they have a correlation
>>>>> > >> structure under the model, and that correlation structure can be
>>>>> > estimated.
>>>>> > >>
>>>>> > >> An imperfect analogy from least-squares regression is the
>>>>> > >> correlation structure of residual estimates, induced by the model.
>>>>> > >> We say that the errors are independent, but the model creates a
>>>>> > >> (modest) correlation structure than can be measured, again,
>>>>> > >> conditional
>>>>> on the model.
>>>>> > >>
>>>>> > >
>>>>> > > Well the residuals are random variables and we can show that at the
>>>>> > > least squares estimates of the parameters they will have a known
>>>>> > > Gaussian distribution which, it turns out, doesn't depend on the
>>>>> > > values of the coefficients.  But those are the easy cases.  In the
>>>>> > > linear mixed model
>>>>> > we
>>>>> > > still have a Gaussian distribution and a linear predictor but that
>>>>> > > is for the conditional distribution of the response given the
>>>>> > > random
>>>>> effects.
>>>>> >  For
>>>>> > > the complete model things get much messier.
>>>>> > >
>>>>> > > I'm not making these points just to be difficult.  I have spent a
>>>>> > > lot of time thinking about these models and trying to come up with
>>>>> > > a
>>>>> > > coherent
>>>>> > way
>>>>> > > of describing them.  Along the way I have come to the conclusion
>>>>> > > that the way these models are often described is, well, wrong.  And
>>>>> > > those descriptions include some that I have written.  For example,
>>>>> > > you often
>>>>> > see
>>>>> > > the model described as the linear predictor for an observation plus
>>>>> > > a "noise" term, epsilon, and the statement that the distribution of
>>>>> > > the random effects is independent of the distribution of the noise
>>>>> > > term.  I
>>>>> > now
>>>>> > > view the linear predictor as a part of the conditional distribution
>>>>> > > of
>>>>> > the
>>>>> > > response given the random effects so it wouldn't make sense to talk
>>>>> > > about these distributions being independent.  The biggest pitfall
>>>>> > > in
>>>>> > transferring
>>>>> > > your thinking from a linear model to any other kind (GLM, LMM,
>>>>> > > GLMM)
>>>>> > > is
>>>>> > the
>>>>> > > fact that we can make sense of a Gaussian distribution minus its
>>>>> > > mean so
>>>>> > we
>>>>> > > write the linear model in the "signal plus noise" form as Y =
>>>>> > > X\beta
>>>>> > > + \epsilon where Y is an n-dimensional random variable, X is the n
>>>>> > > by p
>>>>> > model
>>>>> > > matrix, \beta is the p-dimensional vector of coefficients and
>>>>> > > \epsilon is an n-dimensional Gaussian with mean zero.  That doesn't
>>>>> > > work in the other cases, despite the heroic attempts of many people
>>>>> > > to write things in that way.
>>>>> > >
>>>>> > > Here endeth the sermon.
>>>>> > >
>>>>> > >
>>>>> > >> On Wed, Feb 6, 2013 at 6:34 AM, Douglas Bates
>>>>> > >> <bates at stat.wisc.edu<mailto:bates at stat.wisc.edu>>
>>>>>
>>>>> > wrote:
>>>>> > >>
>>>>> > >>> It is possible to create the correlation matrix of the fixed
>>>>> > >>> effects
>>>>> > and
>>>>> > >>> the random effects jointly using the results from lmer but I have
>>>>> > >>> difficulty deciding what this would represent statistically.  If
>>>>> > >>> you
>>>>> > adopt
>>>>> > >>> a B
>>>>>
>>>>>
>>>>>
>>>>> --
>>>>> Andrew Robinson
>>>>> Director (A/g), ACERA
>>>>> Senior Lecturer in Applied Statistics                      Tel:
>>>>> +61-3-8344-6410<tel:%2B61-3-8344-6410>
>>>>> Department of Mathematics and Statistics            Fax: +61-3-8344
>>>>> 4599<tel:%2B61-3-8344%204599>
>>>>>
>>>>> University of Melbourne, VIC 3010 Australia
>>>>> Email:
>>>>> a.robinson at ms.unimelb.edu.au<mailto:a.robinson at ms.unimelb.edu.au>
>>>>> Website:
>>>>>
>>>>> http://www.ms.unimelb.edu.au
>>>>>
>>>>> FAwR: http://www.ms.unimelb.edu.au/~andrewpr/FAwR/
>>>>> SPuR: http://www.ms.unimelb.edu.au/spuRs/
>>>>>
>>>>>       [[alternative HTML version deleted]]
>>>>>
>>>>> _______________________________________________
>>>>>
>>>>> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org>
>>>>> mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>>
>>>>
>>>> _______________________________________________
>>>>
>>>> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org>
>>>> mailing list
>>>>
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>>
>>>
>>>
>>> --
>>> The University of Edinburgh is a charitable body, registered in
>>> Scotland, with registration number SC005336.
>>>
>>>
>>
>>
>
>
>
> --
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
>
>


From Adriaan.de.Jong at slu.se  Fri Feb  8 17:44:29 2013
From: Adriaan.de.Jong at slu.se (Adriaan De Jong)
Date: Fri, 8 Feb 2013 16:44:29 +0000
Subject: [R-sig-ME] Zero inflation on-off in glmmADMB
Message-ID: <4A3F286665AD3D488D56FDFAC7D8CE430C1F20C9@exchange2-1>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130208/5b000743/attachment.pl>

From billy.requena at gmail.com  Fri Feb  8 17:55:01 2013
From: billy.requena at gmail.com (Billy)
Date: Fri, 8 Feb 2013 11:55:01 -0500
Subject: [R-sig-ME] Zero inflation on-off in glmmADMB
In-Reply-To: <4A3F286665AD3D488D56FDFAC7D8CE430C1F20C9@exchange2-1>
References: <4A3F286665AD3D488D56FDFAC7D8CE430C1F20C9@exchange2-1>
Message-ID: <CAC7gwM=3PUfarUR_M+doBC7GLDSpFYCmO+fv5aej6uRhk+1t7g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130208/6e4b4c4a/attachment.pl>

From j.hadfield at ed.ac.uk  Fri Feb  8 18:31:22 2013
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Fri, 08 Feb 2013 17:31:22 +0000
Subject: [R-sig-ME] [R] lmer - BLUP prediction intervals
In-Reply-To: <CAMeQTh0HRUw0qMnvHsEAPcv+n6EX2V+mEFTEWZ5Q-ZX=ngs7VA@mail.gmail.com>
References: <CAMeQTh3WwXvEGoeUEPS8ZXbbBWHMA57b9otav5WsQYQ+my6u-g@mail.gmail.com>
	<loom.20130205T192133-238@post.gmane.org>
	<686DF18D10EF1C428C2760321FB5B69E07733386F6@DC1VEX07MB001.air.org>
	<CAO7JsnSYu3hmgoS-dFE9+SVpH1LBuNcDnauyTi3KDJwApisung@mail.gmail.com>
	<CAHyGmd7xA4auGOq5wtvwvGRDzkxetGU70retwGR5=KG-3g6BwQ@mail.gmail.com>
	<CAO7JsnRKB+EoHPSY7GoQk7-6qAgL0+8tH43x5Si2Ex2Nd0QXDQ@mail.gmail.com>
	<CAMeQTh1LKvnEdiM8NKe37KAtQ=pC4NWrTSPNvRx_R97Exk6RzA@mail.gmail.com>
	<CAHyGmd5GhyA8yf8SkK-i=H=5QWxYNTeXDFxxiGoz3H+qB+TR8g@mail.gmail.com>
	<686DF18D10EF1C428C2760321FB5B69E0773338B06@DC1VEX07MB001.air.org>
	<CAO7JsnRmjhZNWYsV6EfOE5ERTJRmQ6DBXtksxGaT50WLrtqvHg@mail.gmail.com>
	<686DF18D10EF1C428C2760321FB5B69E077390C7CE@DC1VEX07MB001.air.org>
	<20130207230157.85172inmzpjbdo4k@www.staffmail.ed.ac.uk>
	<CAMeQTh27HcpOH2cdeqvYnVF+QkeSvi-ZV1O29=WS6VL-7Fy8Mg@mail.gmail.com>
	<20130208151830.101760jpxbnhmj48@www.staffmail.ed.ac.uk>
	<CAMeQTh0HRUw0qMnvHsEAPcv+n6EX2V+mEFTEWZ5Q-ZX=ngs7VA@mail.gmail.com>
Message-ID: <20130208173122.10682qcd686shkkg@www.staffmail.ed.ac.uk>

Hi Daniel,

I think

attr(ranef(m1, postVar=T)[["Examiner"]], "postVar")[1,1,]

will be smaller than it should be. I haven't got Mrode's book to hand  
but I presume the prediction error variance of the random effects from  
the (REML-based) animal breeding literature would calculate it as I  
have done.  The differences may be large.

Cheers,

Jarrod

Quoting Daniel Caro <dcarov at gmail.com> on Fri, 8 Feb 2013 15:32:17 +0000:

> Dear Jarrod
>
> Thank you so much and sorry for the confusion. I recalculated Cinv
> with the original specification
>
> m1 <- lmer(Difference ~ 1+  (1|Examiner) + (1|Item), data=englisho.data)
>
> and it is now symmetrical. I will assume the following ordering
> [overall intercept, uexaminer1...uexaminer22, uitem1...uitem24] and
> will use attr(ranef(m1, postVar=T)[["Examiner"]], "postVar")[1,1,] for
> the variances of random effects and Cinv for the covariances with
> fixed effects.
>
> All the best,
> Daniel
>
> On Fri, Feb 8, 2013 at 3:18 PM, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:
>> Dear Daniel,
>>
>> Cinv should be symmetrical (although it might differ slightly because of
>> rounding errors when inverting). The row/columns should be  [overall
>> intercept,
>> ,uitem1...uitem24, uexaminer1...uexaminer22] for your m1 model in this
>> posting. However, in your original posting you fitted item/examiner in a
>> different order:
>>
>>
>> m1 <- lmer(Difference ~ 1+  (1|Examiner) + (1|Item), data=englisho.data)
>>
>> and it was for this model for which my Cinv code would work.
>>
>> I thought
>>
>>
>> attr(ranef(m1, postVar=T)[["Examiner"]], "postVar")[1,1,]
>>
>> would be equal to diag(Cinv[1+1:ne]) (from the original specification:
>> Examiner before Item) but actually it seems closer to something like this:
>>
>>  C = t(W)%*%W/Vr+bdiag(Diagonal(nb)*0,Diagonal(ne)/Ve,Diagonal(ni)/Vi)
>>
>>  Cinv = solve(C[-c(1:nb),-c(1:nb)])
>>
>>  diag(Cinv)[1:ne]
>>
>> I don't think this is a good thing - it assumes the fixed effects, as well
>> as the variance parameters, are known without error.
>>
>> Cheers,
>>
>> Jarrod
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>> Quoting Daniel Caro <dcarov at gmail.com> on Fri, 8 Feb 2013 14:32:53 +0000:
>>
>>> Dear Jarrod
>>>
>>> Thank you for the practical advice and thank you all for the
>>> interesting comments.
>>>
>>> I was able to calculate Cinv. In my model,
>>>
>>> m1 <- lmer(Difference ~ 1+ (1|Item) + (1|Examiner), data=englisho.data)
>>>
>>> this matrix is of size 47x47, which is equal to the number of Items
>>> (ni=24) + number of Examiners (ne=22) + number of fixed effects
>>> (nb=1). Or p (1)+q (46) in the lme4 manual. Cinv is not symmetric and
>>> I am wondering how to interpret the position of covariances in the
>>> matrix. I thought the row/columns would be: [overall intercept,
>>> uitem1...uitem24, uexaminer1...uexaminer22]. But it seems not? And is
>>> the diagonal for the random effects for the examiners, for example,
>>> comparable with the results of
>>>
>>> attr(ranef(m1, postVar=T)[["Examiner"]], "postVar")[1,1,]
>>>
>>> ?
>>>
>>> Again, thank you for your help.
>>>
>>> All the best,
>>> Daniel
>>>
>>> On Thu, Feb 7, 2013 at 11:01 PM, Jarrod Hadfield <j.hadfield at ed.ac.uk>
>>> wrote:
>>>>
>>>> Dear Daniel,
>>>>
>>>> To give a practical, rather than philosophical, solution to your problem
>>>> you
>>>> could perhaps try this....
>>>>
>>>> W<-cBind(X,Z)
>>>>
>>>> Cinv =
>>>> solve(t(W)%*%W/Vr+bdiag(Diagonal(nb)*0,Diagonal(ne)/Ve,Diagonal(ni)/Vi))
>>>>
>>>>
>>>> where Vr is the residual variance, nb is the number of fixed effects, ne
>>>> is
>>>> the number of examiners and Ve the examiner variance estimate and ni is
>>>> the
>>>> number of items and Vi the item variance estimate.
>>>>
>>>> Cinv is the (co)variance matrix of the fixed and random effects (stacked
>>>> on
>>>> top of each other).  If you take the sub-matrix of Cinv that pertains to
>>>> the
>>>> effects in your prediction, then summing the elements of that sub-matrix
>>>> will give you something that is close to the prediction variance. In
>>>> general
>>>> the sub-matrix will not be diagonal (i.e. there are covariances between
>>>> the
>>>> random effects and the things we are *calling* fixed effects). Vr, Ve and
>>>> Vn
>>>> are assumed known. If you want to include their uncertainty in the
>>>> prediction interval you will probably have to wear the B-badge more
>>>> visibly
>>>> on your sleeve I'm afraid.
>>>>
>>>> Cheers,
>>>>
>>>> Jarrod
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>> Quoting "Doran, Harold" <HDoran at air.org> on Thu, 7 Feb 2013 10:02:49
>>>> -0500:
>>>>
>>>>> Doug:
>>>>>
>>>>> Sorry if this is too simple a question. Call \hat{\beta}} the estimate
>>>>> of
>>>>> a fixed parameter and \hat{b_i}  the BLUP for unit i.
>>>>>
>>>>> If the following exists
>>>>>
>>>>> \hat{\theta} = \hat{\beta}} + \hat{b_i}
>>>>>
>>>>> Then, does var(\hat{\theta}) also exist?
>>>>>
>>>>>
>>>>> From: dmbates at gmail.com [mailto:dmbates at gmail.com] On Behalf Of Douglas
>>>>> Bates
>>>>> Sent: Thursday, February 07, 2013 9:57 AM
>>>>> To: Doran, Harold
>>>>> Cc: Andrew Robinson; dcarov at gmail.com; r-sig-mixed-models at r-project.org;
>>>>> Ben Bolker
>>>>> Subject: Re: [R-sig-ME] [R] lmer - BLUP prediction intervals
>>>>>
>>>>> On Wed, Feb 6, 2013 at 9:36 AM, Doran, Harold
>>>>> <HDoran at air.org<mailto:HDoran at air.org>> wrote:
>>>>> Andrew
>>>>>
>>>>> Ignoring the important theoretical question for just a moment on whether
>>>>> it is sensible to do this, there is a covariance term between the BLUPs
>>>>> and
>>>>> the fixed effects.
>>>>>
>>>>> But the picky mathematician in me can't understand in what distribution
>>>>> this covariance occurs.  It makes sense in the Bayesian formulation but
>>>>> not
>>>>> in a classical (sampling theory) formulation.  The distribution of the
>>>>> estimator of the fixed effects for known values of the parameters is a
>>>>> multivariate normal that depends on \beta, \sigma^2 and \Sigma, the
>>>>> model
>>>>> matrices X and Z being known.  The random variable B doesn't enter into
>>>>> it.
>>>>> (One way of writing this variance-covariance of this multivariate normal
>>>>> is
>>>>> X'V^{-1}X where V is that matrix that involves Z and Sigma^{-1} - I have
>>>>> forgotten the exact form).
>>>>>
>>>>> I know these considerations sound like needless theoretical niceties but
>>>>> to me they're not. I have to be able to formulate the theoretical basis
>>>>> before I can make sense of the computational results and, after 20 years
>>>>> or
>>>>> so, I'm still having trouble making sense of this.
>>>>>
>>>>>
>>>>> If that term exists under the model, but it is ignored for purposes of
>>>>> variance estimation, what would be the reason for doing so?
>>>>>
>>>>>> -----Original Message-----
>>>>>> From:
>>>>>>
>>>>>> r-sig-mixed-models-bounces at r-project.org<mailto:r-sig-mixed-models-bounces at r-project.org>
>>>>>> [mailto:r-sig-mixed-<mailto:r-sig-mixed->
>>>>>> models-bounces at r-project.org<mailto:models-bounces at r-project.org>] On
>>>>>> Behalf Of Andrew Robinson
>>>>>> Sent: Tuesday, February 05, 2013 9:15 PM
>>>>>> To: dcarov at gmail.com<mailto:dcarov at gmail.com>
>>>>>> Cc:
>>>>>>
>>>>>> r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>;
>>>>>> Ben Bolker
>>>>>> Subject: Re: [R-sig-ME] [R] lmer - BLUP prediction intervals
>>>>>>
>>>>>> I think that it is a reasonable way to proceed just so long as you
>>>>>> interpret the
>>>>>> intervals guardedly and document your assumptions carefully.
>>>>>>
>>>>>> Cheers
>>>>>>
>>>>>> Andrew
>>>>>>
>>>>>> On Wednesday, February 6, 2013, Daniel Caro wrote:
>>>>>>
>>>>>> > Dear all
>>>>>> >
>>>>>> > I have not been able to follow the discussion. But I would like to
>>>>>> > know if it makes sense to calculate prediction intervals like this:
>>>>>> >
>>>>>> > var(fixed effect+random effect)= var(fixed effect) + var(random
>>>>>> > effect) + 0 (i.e., the cov is zero)
>>>>>> >
>>>>>> > and based on this create the prediction intervals. Does this make
>>>>>> > sense?
>>>>>> >
>>>>>> > All the best,
>>>>>> > Daniel
>>>>>> >
>>>>>> > On Tue, Feb 5, 2013 at 8:54 PM, Douglas Bates
>>>>>> > <bates at stat.wisc.edu<mailto:bates at stat.wisc.edu>>
>>>>>>
>>>>>> wrote:
>>>>>> > > On Tue, Feb 5, 2013 at 2:14 PM, Andrew Robinson <
>>>>>> > > A.Robinson at ms.unimelb.edu.au<mailto:A.Robinson at ms.unimelb.edu.au>>
>>>>>> > > wrote:
>>>>>> > >
>>>>>> > >> I'd have thought that the joint correlation matrix would be of the
>>>>>> > >> estimates of the fixed effects and the random effects, rather than
>>>>>> > >> the things themselves.
>>>>>> > >>
>>>>>> > >
>>>>>> > > Well, it may be because I have turned into a grumpy old man but I
>>>>>> > > get
>>>>>> > picky
>>>>>> > > about terminology and the random effects are not parameters - they
>>>>>> > > are unobserved random variables.  They don't have "estimates" in
>>>>>> > > the
>>>>>> > > sense of parameter estimates.  The quantities returned by the ranef
>>>>>> > > function are
>>>>>> > the
>>>>>> > > conditional means (in the case of a linear mixed model, conditional
>>>>>> > > modes in general) of the random effects given the observed data
>>>>>> > > evaluated with the parameters at their estimated values. In the
>>>>>> > > Bayesian point of view none of this is problematic because they're
>>>>>> > > all random variables but otherwise I struggle with the
>>>>>> > > interpretation of how these can be
>>>>>> > considered
>>>>>> > > jointly.   If you want to consider the distribution of the random
>>>>>> > > effects
>>>>>> > > you need to have known values of the parameters.
>>>>>> > >
>>>>>> > >
>>>>>> > >> The estimates are statistical quantities, with specified
>>>>>> > >> distributions, under the model.  The model posits these different
>>>>>> > >> roles (parameter,
>>>>>> > random
>>>>>> > >> variable) for the quantities that are the targets of the
>>>>>> > >> estimates,
>>>>>> > >> but
>>>>>> > the
>>>>>> > >> estimates are just estimates, and as such, they have a correlation
>>>>>> > >> structure under the model, and that correlation structure can be
>>>>>> > estimated.
>>>>>> > >>
>>>>>> > >> An imperfect analogy from least-squares regression is the
>>>>>> > >> correlation structure of residual estimates, induced by the model.
>>>>>> > >> We say that the errors are independent, but the model creates a
>>>>>> > >> (modest) correlation structure than can be measured, again,
>>>>>> > >> conditional
>>>>>> on the model.
>>>>>> > >>
>>>>>> > >
>>>>>> > > Well the residuals are random variables and we can show that at the
>>>>>> > > least squares estimates of the parameters they will have a known
>>>>>> > > Gaussian distribution which, it turns out, doesn't depend on the
>>>>>> > > values of the coefficients.  But those are the easy cases.  In the
>>>>>> > > linear mixed model
>>>>>> > we
>>>>>> > > still have a Gaussian distribution and a linear predictor but that
>>>>>> > > is for the conditional distribution of the response given the
>>>>>> > > random
>>>>>> effects.
>>>>>> >  For
>>>>>> > > the complete model things get much messier.
>>>>>> > >
>>>>>> > > I'm not making these points just to be difficult.  I have spent a
>>>>>> > > lot of time thinking about these models and trying to come up with
>>>>>> > > a
>>>>>> > > coherent
>>>>>> > way
>>>>>> > > of describing them.  Along the way I have come to the conclusion
>>>>>> > > that the way these models are often described is, well, wrong.  And
>>>>>> > > those descriptions include some that I have written.  For example,
>>>>>> > > you often
>>>>>> > see
>>>>>> > > the model described as the linear predictor for an observation plus
>>>>>> > > a "noise" term, epsilon, and the statement that the distribution of
>>>>>> > > the random effects is independent of the distribution of the noise
>>>>>> > > term.  I
>>>>>> > now
>>>>>> > > view the linear predictor as a part of the conditional distribution
>>>>>> > > of
>>>>>> > the
>>>>>> > > response given the random effects so it wouldn't make sense to talk
>>>>>> > > about these distributions being independent.  The biggest pitfall
>>>>>> > > in
>>>>>> > transferring
>>>>>> > > your thinking from a linear model to any other kind (GLM, LMM,
>>>>>> > > GLMM)
>>>>>> > > is
>>>>>> > the
>>>>>> > > fact that we can make sense of a Gaussian distribution minus its
>>>>>> > > mean so
>>>>>> > we
>>>>>> > > write the linear model in the "signal plus noise" form as Y =
>>>>>> > > X\beta
>>>>>> > > + \epsilon where Y is an n-dimensional random variable, X is the n
>>>>>> > > by p
>>>>>> > model
>>>>>> > > matrix, \beta is the p-dimensional vector of coefficients and
>>>>>> > > \epsilon is an n-dimensional Gaussian with mean zero.  That doesn't
>>>>>> > > work in the other cases, despite the heroic attempts of many people
>>>>>> > > to write things in that way.
>>>>>> > >
>>>>>> > > Here endeth the sermon.
>>>>>> > >
>>>>>> > >
>>>>>> > >> On Wed, Feb 6, 2013 at 6:34 AM, Douglas Bates
>>>>>> > >> <bates at stat.wisc.edu<mailto:bates at stat.wisc.edu>>
>>>>>>
>>>>>> > wrote:
>>>>>> > >>
>>>>>> > >>> It is possible to create the correlation matrix of the fixed
>>>>>> > >>> effects
>>>>>> > and
>>>>>> > >>> the random effects jointly using the results from lmer but I have
>>>>>> > >>> difficulty deciding what this would represent statistically.  If
>>>>>> > >>> you
>>>>>> > adopt
>>>>>> > >>> a B
>>>>>>
>>>>>>
>>>>>>
>>>>>> --
>>>>>> Andrew Robinson
>>>>>> Director (A/g), ACERA
>>>>>> Senior Lecturer in Applied Statistics                      Tel:
>>>>>> +61-3-8344-6410<tel:%2B61-3-8344-6410>
>>>>>> Department of Mathematics and Statistics            Fax: +61-3-8344
>>>>>> 4599<tel:%2B61-3-8344%204599>
>>>>>>
>>>>>> University of Melbourne, VIC 3010 Australia
>>>>>> Email:
>>>>>> a.robinson at ms.unimelb.edu.au<mailto:a.robinson at ms.unimelb.edu.au>
>>>>>> Website:
>>>>>>
>>>>>> http://www.ms.unimelb.edu.au
>>>>>>
>>>>>> FAwR: http://www.ms.unimelb.edu.au/~andrewpr/FAwR/
>>>>>> SPuR: http://www.ms.unimelb.edu.au/spuRs/
>>>>>>
>>>>>>       [[alternative HTML version deleted]]
>>>>>>
>>>>>> _______________________________________________
>>>>>>
>>>>>> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org>
>>>>>> mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>
>>>>>
>>>>>
>>>>> _______________________________________________
>>>>>
>>>>> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org>
>>>>> mailing list
>>>>>
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>
>>>>>
>>>>>         [[alternative HTML version deleted]]
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>
>>>>>
>>>>
>>>>
>>>> --
>>>> The University of Edinburgh is a charitable body, registered in
>>>> Scotland, with registration number SC005336.
>>>>
>>>>
>>>
>>>
>>
>>
>>
>> --
>> The University of Edinburgh is a charitable body, registered in
>> Scotland, with registration number SC005336.
>>
>>
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From bates at stat.wisc.edu  Fri Feb  8 20:09:28 2013
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 8 Feb 2013 13:09:28 -0600
Subject: [R-sig-ME] [R] lmer - BLUP prediction intervals
In-Reply-To: <686DF18D10EF1C428C2760321FB5B69E077390C7CE@DC1VEX07MB001.air.org>
References: <CAMeQTh3WwXvEGoeUEPS8ZXbbBWHMA57b9otav5WsQYQ+my6u-g@mail.gmail.com>
	<loom.20130205T192133-238@post.gmane.org>
	<686DF18D10EF1C428C2760321FB5B69E07733386F6@DC1VEX07MB001.air.org>
	<CAO7JsnSYu3hmgoS-dFE9+SVpH1LBuNcDnauyTi3KDJwApisung@mail.gmail.com>
	<CAHyGmd7xA4auGOq5wtvwvGRDzkxetGU70retwGR5=KG-3g6BwQ@mail.gmail.com>
	<CAO7JsnRKB+EoHPSY7GoQk7-6qAgL0+8tH43x5Si2Ex2Nd0QXDQ@mail.gmail.com>
	<CAMeQTh1LKvnEdiM8NKe37KAtQ=pC4NWrTSPNvRx_R97Exk6RzA@mail.gmail.com>
	<CAHyGmd5GhyA8yf8SkK-i=H=5QWxYNTeXDFxxiGoz3H+qB+TR8g@mail.gmail.com>
	<686DF18D10EF1C428C2760321FB5B69E0773338B06@DC1VEX07MB001.air.org>
	<CAO7JsnRmjhZNWYsV6EfOE5ERTJRmQ6DBXtksxGaT50WLrtqvHg@mail.gmail.com>
	<686DF18D10EF1C428C2760321FB5B69E077390C7CE@DC1VEX07MB001.air.org>
Message-ID: <CAO7JsnSc2uOOjGbxitJXwyvOFsUtieyYgqi6akgTuddyxnrpqw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130208/f6c1de63/attachment.pl>

From nrm2010 at zoho.com  Fri Feb  8 21:39:48 2013
From: nrm2010 at zoho.com (nrm2010)
Date: Fri, 08 Feb 2013 13:39:48 -0700
Subject: [R-sig-ME] Minimum number of levels for mixed model
Message-ID: <2017179353.179363.1360355988075.JavaMail.sas1@[172.29.251.236]>



Hello, Ben,


Thank you for the response.  I created some confusion by stating treatment (trt)
instead of the treatment blocks, of which there are 3.
The Murtaugh paper seems to take one position on the perhaps philosophical issue previously
discussed on the forum concerning whether or not the model design has to be faithful
to the experimental design. 
 
My larger question is how often it will be feasible to use mixed models
with nested effects if we require a minimum of  5^n samples for n levels and we try
to be faithful to the experimental design.

Thinking of the adage that all models are wrong and some are useful, how wrong
 are we if the random variable has 3 or 4 levels rather than 5, and how useful are we
if we require 5^n samples?

Thank you for your assistance.

Toby Gass


From bbolker at gmail.com  Sat Feb  9 02:23:51 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 9 Feb 2013 01:23:51 +0000 (UTC)
Subject: [R-sig-ME] Minimum number of levels for mixed model
References: <2017179353.179363.1360355988075.JavaMail.sas1@[172.29.251.236]>
Message-ID: <loom.20130209T013405-765@post.gmane.org>

nrm2010 <nrm2010 at ...> writes:

>  Hello, Ben, Thank you for the response.  I created some confusion
> by stating treatment (trt) instead of the treatment blocks, of which
> there are 3.  The Murtaugh paper seems to take one position on the
> perhaps philosophical issue previously discussed on the forum
> concerning whether or not the model design has to be faithful to the
> experimental design.

  It's not going to work very well to take treatment (blocks)
as a random effects, for the various reasons enumerated in the
FAQ.  I would strongly advise modeling them as fixed effects.
 
> My larger question is how often it will be feasible to use mixed
> models with nested effects if we require a minimum of 5^n samples
> for n levels and we try to be faithful to the experimental design.

  It took me a minute, but I guess by "n" here you mean the number
of *hierarchical* levels?  (I initially took it as the number of
levels of each random factor ... one of the difficulties with
mixed models is the terminology ...)
 
> Thinking of the adage that all models are wrong and some are useful,
>  how wrong are we if the random variable has 3 or 4 levels rather
>  than 5, and how useful are we if we require 5^n samples?  

Again, this is discussed at some length in the FAQ; my personal
philosophical point of view probably comes through there.  I can say from
a basis of experience and guessing (very few rigorous proofs, sorry)
that if you try to fit multilevel models with fewer than 5 :

* sometimes the model will produce an error
* lots of times you will get estimates of zero variance.  
  * this _might_ represent bias in the estimator, or it might 
represent a weird distribution of the estimator, which might have
the right mean but a big spike at zero and a long tail.
* I don't have strong evidence for this, but it seems much
more likely that the optimization will fail *silently* and
give you wonky answers

125 samples is a big number in some fields, it's a small number
in other fields.  Maybe mixed models _aren't_ useful in your field ...
The fundamental problem, which I think you're going to have trouble
getting around, is that it's very hard to estimate variances reliably
from that few samples.  An analogy would be complaining that you're
having a hard time estimating population means reliably from samples
of size 2 or 3 ...

Remember, also, that the problem is primarily with the top level.
As I hope I made clear previously, the number of 'samples' we
are referring to for nested models is the total number of exchangeable
levels -- for a three level nested 5/5/5 model, we will have 5
top-level, 25 middle-level, and 125 bottom-level units.  Of course,
if you want to use crossed random effects, you tend to have more
"top-level" units (i.e. more variances to estimate from small
samples -- e.g. 5 plots x 5 years x 10 samples per year =
5 samples for among-plot variance, 5 for among-year variance,
25 for the plot-year interaction, and 250 overall ...)

I put together some little sims illustrating the issue: 
http://rpubs.com/bbolker/4187


From j.hadfield at ed.ac.uk  Sat Feb  9 15:21:47 2013
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Sat, 09 Feb 2013 14:21:47 +0000
Subject: [R-sig-ME] MCMCglmm - ZIP model for mackerel egg data
In-Reply-To: <DB34604B7AC0314895201BE4BE40103808093F68@SCOMP0934.wurnet.nl>
References: <DB34604B7AC0314895201BE4BE40103808093F68@SCOMP0934.wurnet.nl>
Message-ID: <20130209142147.136663nwrezpb9ss@www.staffmail.ed.ac.uk>

Hi Sven,

Quoting "Gastauer, Sven" <sven.gastauer at wur.nl> on Thu, 7 Feb 2013  
16:11:49 +0000:

> Dear all,
>
> I am trying to model mackerel egg abundance in the North Sea. The  
> egg abundance information comes from triennial surveys and contains  
> a lot of 0 values (e.g. samples without any mackerel eggs). The idea  
> was hence to build a zero-inflated or a zero-altered model using  
> MCMCglmm. Fixed terms should be Sea Surface Temperature (sst),  
> Longitude, Latitude and years as random factor.
>
> The first problem or question I ran into is that of course the  
> number of eggs within a sample is a simple integer, although  
> normally I would define an offset : Egg abundance = Counted Eggs x  
> Correction Factor x Sampling Depth / Filtered Volume  
> (Ce*R*SD/VolFilt), but as far as I understand it this is not an  
> option in MCMCglmm? My easy solution for now was to simply round  
> volume the corrected  egg counts, which introduces a minor error.

You can fit an offset by fixing the regression coefficient at 1 in the  
prior. For example if the offset variable is associated with the 2nd  
fixed effect out of 3 then:

prior<-list(B=list(V=diag(3)*1e+8, mu=c(0,1,0)), ...)
prior$B$V[2,2]<-1e-8

or something similar, achieves this.


>
> Based on some online readings etc. I came up with a model and a  
> prior, but I am not feeling very confident about it, could you  
> please indicate if this model makes sense?
>
> prior0 <- list(B=list(mu = matrix(0,10,2),
> V  = diag(10)*1e+6),
>                             R  = list(V=diag(2),n=2,fix=2),
>                             G  = list(G1=list(V=diag(c(1,  
> 1e-6)),n=2, fix=2)))
>
> m.zip <-  MCMCglmm(AE ~ trait + trait:(LONGITUDE*LATITUDE) + trait:sst,
>                             random = ~idh(trait):YEAR,
> family = "zipoisson",
> rcov = ~ idh(trait):units,
>                             prior = prior0,
> nitt = 100000,
> burnin = 10000,
> thin = 25,
> data = eggs)
>
> m.zap <-MCMCglmm(AE ~ trait + trait:(LONGITUDE*LATITUDE) + trait:sst,
>                             random = ~idh(trait):YEAR,
> family = "zapoisson",
> rcov = ~ idh(trait):units,
>                             prior = prior0,
> nitt = 100000,
> burnin = 10000,
> thin = 25, data = eggs)
>
>

If you only want to fit random effects for the count process

random = ~idh(at.level(trait,1)):YEAR

is probably a better way of doing it. This just fits a single variance  
rather than a 2x2 covariance matrix.

Your prior degrees of freedom are large. With idh structures you have  
nu=2 on a single variance. I would use something smaller (e.g. 0.002)  
or preferably parameter expanded priors.

> Plotting and looking at the summary both models works fine, but I  
> cannot figure out how to predict the data. I tried the following,  
> but get an Error message (which I do not understand):
> predict(m.zip, marginal = ~idh(trait):YEAR, type = "response",  
> interval = "confidence")
> Error in M[, which(rm.v), ] <- 0 : incorrect number of subscripts

the predict method does not work with ZIP models yet, so you will have  
to do it by hand I'm afraid. The expected value is (1-pi)*lambda where  
pi is the probability of being zero from the zero-inflation part of  
the model, and lambda is the Poisson rate (in the CourseNotes  
notation: (1-plogis(l_2))*exp(l_2)).

I am not sure what the expectation would be after marginalising the  
random effects/overdispersion, particularly if the two processes are  
correlated (which they are not in your model).

Cheers,

Jarrod






>
> Any help is greatly appreciated and many thanks in advance,
>
> Sven Gastauer
>
> IMARES
> Fisheries Acoustician
> Email: sven.gastauer at wur.nl<mailto:sven.gastauer at wur.nl>
> Mobile: +31 (0)61 005 71 03
>
> P.O. Box 68
> Haringkade, 1 (0.23)
> 1970AB IJMUIDEN
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From d.afshartous at vanderbilt.edu  Sat Feb  9 23:14:35 2013
From: d.afshartous at vanderbilt.edu (Afshartous, David)
Date: Sat, 9 Feb 2013 22:14:35 +0000
Subject: [R-sig-ME] nlme, augPred, IV infusion
Message-ID: <E7DFC74ED2DEAD47AFD38124459241CB1C7D26E7@ITS-HCWNEM108.ds.vanderbilt.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130209/6c135539/attachment.pl>

From d.afshartous at vanderbilt.edu  Sat Feb  9 23:20:32 2013
From: d.afshartous at vanderbilt.edu (Afshartous, David)
Date: Sat, 9 Feb 2013 22:20:32 +0000
Subject: [R-sig-ME] nlme, augPred, IV infusion
In-Reply-To: <E7DFC74ED2DEAD47AFD38124459241CB1C7D26E7@ITS-HCWNEM108.ds.vanderbilt.edu>
References: <E7DFC74ED2DEAD47AFD38124459241CB1C7D26E7@ITS-HCWNEM108.ds.vanderbilt.edu>
Message-ID: <E7DFC74ED2DEAD47AFD38124459241CB1C7D2709@ITS-HCWNEM108.ds.vanderbilt.edu>


PS: slight correction to below: the fixed effects curve will not be constant since there will be a dependence on covariates, but the overall shape from plotting the augPred is still way off

--
David Afshartous, Ph.D.
Research Associate Professor
PSTAT?: ASA Accredited Professional Statistician
Department of Biostatistics
Vanderbilt University Medical Center
________________________________________
From: r-sig-mixed-models-bounces at r-project.org [r-sig-mixed-models-bounces at r-project.org] on behalf of Afshartous, David [d.afshartous at vanderbilt.edu]
Sent: Saturday, February 09, 2013 4:14 PM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] nlme, augPred, IV infusion

All,

I'm using nlme to estimate a nonlinear mixed-efffects model for pharmacokinetic data resulting from an IV infusion.   The fixed-effects form is a hard-coded equation used for IV infusions (open compartment, linear elimination).  The estimates seem to be okay, and a manual plot of the fixed effects curve is also okay, but the usual plot of the augPred does not seem to work.  Specifically, the fixed effects curve is not constant across subjects and the curve doesn't correspond to the estimated fixed effects; the EB estimated curves are also off.   Any suggestions much appreciated. Reproducible example below.

Cheers,
David



--
David Afshartous, Ph.D.
Research Associate Professor
PSTAT?: ASA Accredited Professional Statistician
Department of Biostatistics
Vanderbilt University Medical Center


library(nlme)
conc <- c(32.04, 50.82, 40.2, 53.12, 38.37, 61.36, 143.8, 27.42, 51.13, 37.14, 27.99, 136.4, 34.36, 135, 156.9, 52.92, 62.57, 56.02, 98.66, 76.36, 64.07, 47.92, 23.99, 93.42, 43.22, 41.45, 107.6, 79.74, 81.21, 49.09, 47.94, 108, 29.04, 32.56, 64.4, 28, 67.39, 60.24, 38.68, 33.4, 104.3, 48.14, 24.29, 10.7, 12.8, 156.8, 119.4, 51.23, 15.61, 16.75, 26.26, 58.16, 65.2, 57.65, 105.1, 104.2, 111.4, 125.1, 96, 94.1, 272.2, 153.8, 87.51, 74.75, 115.6, 253, 75.22, 229.2, 295.5, 129.9, 210.3, 124.8, 153.7, 142.9, 117.8, 99.37, 106.5, 162.6, 65.8, 105.6, 138.3, 151.7, 220.9, 93.46, 117.9, 152.7, 98.63, 130.3, 115.7, 66.49, 109, 90.64, 68.2, 55.67, 149.4, 100.5, 73.34, 48.35, 75.8, 172.6, 157.6, 129.6, 56.63, 77.57, 89.74, 204.2, 145.8, 107.7, 63.74, 45.59, 48.06, 63.76, 104.8, 44.84, 49.91, 177.5, 91.75, 150.6, 69.72, 48.21, 53.71, 16.51, 83.85, 43.39, 98.15, 65.3, 70.5, 45.15, 52.6, 81.9, 25.08, 32.37, 45.75, 61.8, 47, 34.78, 32.02, 85.34, 55.24, 17.73, 15.34, 14.53, 130.1, 96.41, 78.6, 16.93, 40.98, 68.38, 68.93, 68, 54.83)
Tinf.ind <- c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1)
Dose <- c(3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 3000, 2000, 3000, 2000, 2000, 3000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 3000, 2000, 3000, 2000, 2000, 3000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 3000, 2000, 3000, 2000, 2000, 3000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 3000)
Time <- c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 8, 8, 12, 8, 8, 8, 12, 8, 8, 8, 8, 12, 8, 8, 8, 8, 6, 8, 8, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 8, 6, 6, 6, 6)
ID <- c(19, 18, 25, 29, 39, 24, 53, 43, 17, 8, 28, 52, 10, 51, 54, 32, 49, 34, 42, 35, 36, 45, 21, 46, 11, 20, 33, 40, 50, 14, 27, 41, 15, 31, 26, 4, 23, 13, 5, 2, 38, 16, 6, 1, 7, 47, 44, 30, 3, 9, 12, 48, 37, 22, 19, 18, 25, 29, 39, 24, 53, 43, 17, 8, 28, 52, 10, 51, 54, 32, 49, 34, 42, 35, 36, 45, 21, 46, 11, 20, 33, 40, 50, 14, 27, 41, 15, 31, 26, 4, 23, 13, 5, 2, 38, 16, 6, 1, 7, 47, 44, 30, 3, 9, 12, 48, 37, 22, 18, 25, 29, 24, 53, 17, 28, 52, 51, 54, 32, 34, 45, 21, 46, 11, 33, 40, 50, 14, 27, 41, 15, 31, 26, 23, 13, 5, 2, 38, 16, 6, 1, 7, 47, 44, 30, 3, 9, 12, 48, 37, 22)
dat <- data.frame(ID, conc, Time, Tinf.ind, Dose)
dat <- groupedData(conc ~ Time | ID, data = dat,
       labels = list(x = "Time (hours)", y = "Concentration"))

## uses hard-coded functional form for IV infusion where Tinf.ind is indicator variable that
## determines which part of the function corresponds to the data point, pre versus post infusion:
mod1  <- nlme(conc ~ (1 - Tinf.ind) * (0 + (Dose/0.5) * (1/ (k*V)) * (1 - exp(- k * Time) ) )
           + (Tinf.ind) * (0 + (Dose/0.5) * (1/ (k*V)) * (1 - exp(- k * 0.5) ) * exp(-k* (Time - 0.5))),
      fixed = c(k + V  ~ 1),
     random = pdDiag(V~ 1),
     start = c(.3, 30),
     data = dat)
summary(mod1)

k <- fixef(mod1)[1]; V <- fixef(mod1)[2];
## manual plot of resulting fixed effects curve:
IV.function <- function(t)
  {
    (1 - (t >=.5 )) * (D/Tinf)*(1/(k*V)) * (1 - exp(-k * t)) + (t >=.5)*(D/Tinf)*(1/(k*V))*(1 - exp(-k*Tinf))*exp(-k*(t-Tinf))
  }
curve(IV.function, 0, 8)

## this does not seem to work:
plot(augPred(mod1, level=0:1),
     main = "IV infusion, nonlinear mixed-effects model")



        [[alternative HTML version deleted]]



From d.afshartous at vanderbilt.edu  Sat Feb  9 23:25:36 2013
From: d.afshartous at vanderbilt.edu (Afshartous, David)
Date: Sat, 9 Feb 2013 22:25:36 +0000
Subject: [R-sig-ME] nlme, augPred, IV infusion
In-Reply-To: <E7DFC74ED2DEAD47AFD38124459241CB1C7D2709@ITS-HCWNEM108.ds.vanderbilt.edu>
References: <E7DFC74ED2DEAD47AFD38124459241CB1C7D26E7@ITS-HCWNEM108.ds.vanderbilt.edu>,
	<E7DFC74ED2DEAD47AFD38124459241CB1C7D2709@ITS-HCWNEM108.ds.vanderbilt.edu>
Message-ID: <E7DFC74ED2DEAD47AFD38124459241CB1C7D2730@ITS-HCWNEM108.ds.vanderbilt.edu>

PPS: need the following update to original code (sorry for multiple e-mails)

k <- fixef(mod1)[1]; V <- fixef(mod1)[2];  ## changed to:
k <- fixef(mod1)[1]; V <- fixef(mod1)[2]; D <- 3000; Tinf <- 0.5


________________________________________
From: r-sig-mixed-models-bounces at r-project.org [r-sig-mixed-models-bounces at r-project.org] on behalf of Afshartous, David [d.afshartous at vanderbilt.edu]
Sent: Saturday, February 09, 2013 4:20 PM
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] nlme, augPred, IV infusion

PS: slight correction to below: the fixed effects curve will not be constant since there will be a dependence on covariates, but the overall shape from plotting the augPred is still way off

--
David Afshartous, Ph.D.
Research Associate Professor
PSTAT?: ASA Accredited Professional Statistician
Department of Biostatistics
Vanderbilt University Medical Center
________________________________________
From: r-sig-mixed-models-bounces at r-project.org [r-sig-mixed-models-bounces at r-project.org] on behalf of Afshartous, David [d.afshartous at vanderbilt.edu]
Sent: Saturday, February 09, 2013 4:14 PM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] nlme, augPred, IV infusion

All,

I'm using nlme to estimate a nonlinear mixed-efffects model for pharmacokinetic data resulting from an IV infusion.   The fixed-effects form is a hard-coded equation used for IV infusions (open compartment, linear elimination).  The estimates seem to be okay, and a manual plot of the fixed effects curve is also okay, but the usual plot of the augPred does not seem to work.  Specifically, the fixed effects curve is not constant across subjects and the curve doesn't correspond to the estimated fixed effects; the EB estimated curves are also off.   Any suggestions much appreciated. Reproducible example below.

Cheers,
David



--
David Afshartous, Ph.D.
Research Associate Professor
PSTAT?: ASA Accredited Professional Statistician
Department of Biostatistics
Vanderbilt University Medical Center


library(nlme)
conc <- c(32.04, 50.82, 40.2, 53.12, 38.37, 61.36, 143.8, 27.42, 51.13, 37.14, 27.99, 136.4, 34.36, 135, 156.9, 52.92, 62.57, 56.02, 98.66, 76.36, 64.07, 47.92, 23.99, 93.42, 43.22, 41.45, 107.6, 79.74, 81.21, 49.09, 47.94, 108, 29.04, 32.56, 64.4, 28, 67.39, 60.24, 38.68, 33.4, 104.3, 48.14, 24.29, 10.7, 12.8, 156.8, 119.4, 51.23, 15.61, 16.75, 26.26, 58.16, 65.2, 57.65, 105.1, 104.2, 111.4, 125.1, 96, 94.1, 272.2, 153.8, 87.51, 74.75, 115.6, 253, 75.22, 229.2, 295.5, 129.9, 210.3, 124.8, 153.7, 142.9, 117.8, 99.37, 106.5, 162.6, 65.8, 105.6, 138.3, 151.7, 220.9, 93.46, 117.9, 152.7, 98.63, 130.3, 115.7, 66.49, 109, 90.64, 68.2, 55.67, 149.4, 100.5, 73.34, 48.35, 75.8, 172.6, 157.6, 129.6, 56.63, 77.57, 89.74, 204.2, 145.8, 107.7, 63.74, 45.59, 48.06, 63.76, 104.8, 44.84, 49.91, 177.5, 91.75, 150.6, 69.72, 48.21, 53.71, 16.51, 83.85, 43.39, 98.15, 65.3, 70.5, 45.15, 52.6, 81.9, 25.08, 32.37, 45.75, 61.8, 47, 34.78, 32.02, 85.34, 55.24, 17.73, 15.34, 14.53, 130.1, 96.41, 78.6, 16.93, 40.98, 68.38, 68.93, 68, 54.83)
Tinf.ind <- c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1)
Dose <- c(3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 3000, 2000, 3000, 2000, 2000, 3000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 3000, 2000, 3000, 2000, 2000, 3000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 3000, 2000, 3000, 2000, 2000, 3000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 3000)
Time <- c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 8, 8, 12, 8, 8, 8, 12, 8, 8, 8, 8, 12, 8, 8, 8, 8, 6, 8, 8, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 8, 6, 6, 6, 6)
ID <- c(19, 18, 25, 29, 39, 24, 53, 43, 17, 8, 28, 52, 10, 51, 54, 32, 49, 34, 42, 35, 36, 45, 21, 46, 11, 20, 33, 40, 50, 14, 27, 41, 15, 31, 26, 4, 23, 13, 5, 2, 38, 16, 6, 1, 7, 47, 44, 30, 3, 9, 12, 48, 37, 22, 19, 18, 25, 29, 39, 24, 53, 43, 17, 8, 28, 52, 10, 51, 54, 32, 49, 34, 42, 35, 36, 45, 21, 46, 11, 20, 33, 40, 50, 14, 27, 41, 15, 31, 26, 4, 23, 13, 5, 2, 38, 16, 6, 1, 7, 47, 44, 30, 3, 9, 12, 48, 37, 22, 18, 25, 29, 24, 53, 17, 28, 52, 51, 54, 32, 34, 45, 21, 46, 11, 33, 40, 50, 14, 27, 41, 15, 31, 26, 23, 13, 5, 2, 38, 16, 6, 1, 7, 47, 44, 30, 3, 9, 12, 48, 37, 22)
dat <- data.frame(ID, conc, Time, Tinf.ind, Dose)
dat <- groupedData(conc ~ Time | ID, data = dat,
       labels = list(x = "Time (hours)", y = "Concentration"))

## uses hard-coded functional form for IV infusion where Tinf.ind is indicator variable that
## determines which part of the function corresponds to the data point, pre versus post infusion:
mod1  <- nlme(conc ~ (1 - Tinf.ind) * (0 + (Dose/0.5) * (1/ (k*V)) * (1 - exp(- k * Time) ) )
           + (Tinf.ind) * (0 + (Dose/0.5) * (1/ (k*V)) * (1 - exp(- k * 0.5) ) * exp(-k* (Time - 0.5))),
      fixed = c(k + V  ~ 1),
     random = pdDiag(V~ 1),
     start = c(.3, 30),
     data = dat)
summary(mod1)

k <- fixef(mod1)[1]; V <- fixef(mod1)[2];
## manual plot of resulting fixed effects curve:
IV.function <- function(t)
  {
    (1 - (t >=.5 )) * (D/Tinf)*(1/(k*V)) * (1 - exp(-k * t)) + (t >=.5)*(D/Tinf)*(1/(k*V))*(1 - exp(-k*Tinf))*exp(-k*(t-Tinf))
  }
curve(IV.function, 0, 8)

## this does not seem to work:
plot(augPred(mod1, level=0:1),
     main = "IV infusion, nonlinear mixed-effects model")



        [[alternative HTML version deleted]]


_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From d.afshartous at vanderbilt.edu  Sat Feb  9 23:34:03 2013
From: d.afshartous at vanderbilt.edu (Afshartous, David)
Date: Sat, 9 Feb 2013 22:34:03 +0000
Subject: [R-sig-ME] nlme, augPred, IV infusion
In-Reply-To: <E7DFC74ED2DEAD47AFD38124459241CB1C7D2730@ITS-HCWNEM108.ds.vanderbilt.edu>
References: <E7DFC74ED2DEAD47AFD38124459241CB1C7D26E7@ITS-HCWNEM108.ds.vanderbilt.edu>,
	<E7DFC74ED2DEAD47AFD38124459241CB1C7D2709@ITS-HCWNEM108.ds.vanderbilt.edu>,
	<E7DFC74ED2DEAD47AFD38124459241CB1C7D2730@ITS-HCWNEM108.ds.vanderbilt.edu>
Message-ID: <E7DFC74ED2DEAD47AFD38124459241CB1C7D2751@ITS-HCWNEM108.ds.vanderbilt.edu>

I found the problem:

In the nlme function call I was using a dummy variable to sort out which part of the function corresponded to each data point.   This produced the correct parameter estimates but created problems elsewhere.  It is fixed by making the following change:

mod1  <- nlme(conc ~ (1 - (Time >= .5)) * (0 + (Dose/0.5) * (1/ (k*V)) * (1 - exp(- k * Time) ) ) 
           + (Time >= .5) * (0 + (Dose/0.5) * (1/ (k*V)) * (1 - exp(- k * 0.5) ) * exp(-k* (Time - 0.5))),
      fixed = c(k + V  ~ 1), 
     random = pdDiag(V +k  ~ 1), 
     start = c(.3, 30),
     data = dat)







________________________________________
From: r-sig-mixed-models-bounces at r-project.org [r-sig-mixed-models-bounces at r-project.org] on behalf of Afshartous, David [d.afshartous at vanderbilt.edu]
Sent: Saturday, February 09, 2013 4:25 PM
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] nlme, augPred, IV infusion

PPS: need the following update to original code (sorry for multiple e-mails)

k <- fixef(mod1)[1]; V <- fixef(mod1)[2];  ## changed to:
k <- fixef(mod1)[1]; V <- fixef(mod1)[2]; D <- 3000; Tinf <- 0.5


________________________________________
From: r-sig-mixed-models-bounces at r-project.org [r-sig-mixed-models-bounces at r-project.org] on behalf of Afshartous, David [d.afshartous at vanderbilt.edu]
Sent: Saturday, February 09, 2013 4:20 PM
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] nlme, augPred, IV infusion

PS: slight correction to below: the fixed effects curve will not be constant since there will be a dependence on covariates, but the overall shape from plotting the augPred is still way off

--
David Afshartous, Ph.D.
Research Associate Professor
PSTAT?: ASA Accredited Professional Statistician
Department of Biostatistics
Vanderbilt University Medical Center
________________________________________
From: r-sig-mixed-models-bounces at r-project.org [r-sig-mixed-models-bounces at r-project.org] on behalf of Afshartous, David [d.afshartous at vanderbilt.edu]
Sent: Saturday, February 09, 2013 4:14 PM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] nlme, augPred, IV infusion

All,

I'm using nlme to estimate a nonlinear mixed-efffects model for pharmacokinetic data resulting from an IV infusion.   The fixed-effects form is a hard-coded equation used for IV infusions (open compartment, linear elimination).  The estimates seem to be okay, and a manual plot of the fixed effects curve is also okay, but the usual plot of the augPred does not seem to work.  Specifically, the fixed effects curve is not constant across subjects and the curve doesn't correspond to the estimated fixed effects; the EB estimated curves are also off.   Any suggestions much appreciated. Reproducible example below.

Cheers,
David



--
David Afshartous, Ph.D.
Research Associate Professor
PSTAT?: ASA Accredited Professional Statistician
Department of Biostatistics
Vanderbilt University Medical Center


library(nlme)
conc <- c(32.04, 50.82, 40.2, 53.12, 38.37, 61.36, 143.8, 27.42, 51.13, 37.14, 27.99, 136.4, 34.36, 135, 156.9, 52.92, 62.57, 56.02, 98.66, 76.36, 64.07, 47.92, 23.99, 93.42, 43.22, 41.45, 107.6, 79.74, 81.21, 49.09, 47.94, 108, 29.04, 32.56, 64.4, 28, 67.39, 60.24, 38.68, 33.4, 104.3, 48.14, 24.29, 10.7, 12.8, 156.8, 119.4, 51.23, 15.61, 16.75, 26.26, 58.16, 65.2, 57.65, 105.1, 104.2, 111.4, 125.1, 96, 94.1, 272.2, 153.8, 87.51, 74.75, 115.6, 253, 75.22, 229.2, 295.5, 129.9, 210.3, 124.8, 153.7, 142.9, 117.8, 99.37, 106.5, 162.6, 65.8, 105.6, 138.3, 151.7, 220.9, 93.46, 117.9, 152.7, 98.63, 130.3, 115.7, 66.49, 109, 90.64, 68.2, 55.67, 149.4, 100.5, 73.34, 48.35, 75.8, 172.6, 157.6, 129.6, 56.63, 77.57, 89.74, 204.2, 145.8, 107.7, 63.74, 45.59, 48.06, 63.76, 104.8, 44.84, 49.91, 177.5, 91.75, 150.6, 69.72, 48.21, 53.71, 16.51, 83.85, 43.39, 98.15, 65.3, 70.5, 45.15, 52.6, 81.9, 25.08, 32.37, 45.75, 61.8, 47, 34.78, 32.02, 85.34, 55.24, 17.73, 15.34, 14.53, 130.1, 96.41, 78.6, 16.93, 40.98, 68.38, 68.93, 68, 54.83)
Tinf.ind <- c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1)
Dose <- c(3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 3000, 2000, 3000, 2000, 2000, 3000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 3000, 2000, 3000, 2000, 2000, 3000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 3000, 2000, 3000, 2000, 2000, 3000, 2000, 2000, 2000, 2000, 2000, 2000, 2000, 3000)
Time <- c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 8, 8, 12, 8, 8, 8, 12, 8, 8, 8, 8, 12, 8, 8, 8, 8, 6, 8, 8, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 8, 6, 6, 6, 6)
ID <- c(19, 18, 25, 29, 39, 24, 53, 43, 17, 8, 28, 52, 10, 51, 54, 32, 49, 34, 42, 35, 36, 45, 21, 46, 11, 20, 33, 40, 50, 14, 27, 41, 15, 31, 26, 4, 23, 13, 5, 2, 38, 16, 6, 1, 7, 47, 44, 30, 3, 9, 12, 48, 37, 22, 19, 18, 25, 29, 39, 24, 53, 43, 17, 8, 28, 52, 10, 51, 54, 32, 49, 34, 42, 35, 36, 45, 21, 46, 11, 20, 33, 40, 50, 14, 27, 41, 15, 31, 26, 4, 23, 13, 5, 2, 38, 16, 6, 1, 7, 47, 44, 30, 3, 9, 12, 48, 37, 22, 18, 25, 29, 24, 53, 17, 28, 52, 51, 54, 32, 34, 45, 21, 46, 11, 33, 40, 50, 14, 27, 41, 15, 31, 26, 23, 13, 5, 2, 38, 16, 6, 1, 7, 47, 44, 30, 3, 9, 12, 48, 37, 22)
dat <- data.frame(ID, conc, Time, Tinf.ind, Dose)
dat <- groupedData(conc ~ Time | ID, data = dat,
       labels = list(x = "Time (hours)", y = "Concentration"))

## uses hard-coded functional form for IV infusion where Tinf.ind is indicator variable that
## determines which part of the function corresponds to the data point, pre versus post infusion:
mod1  <- nlme(conc ~ (1 - Tinf.ind) * (0 + (Dose/0.5) * (1/ (k*V)) * (1 - exp(- k * Time) ) )
           + (Tinf.ind) * (0 + (Dose/0.5) * (1/ (k*V)) * (1 - exp(- k * 0.5) ) * exp(-k* (Time - 0.5))),
      fixed = c(k + V  ~ 1),
     random = pdDiag(V~ 1),
     start = c(.3, 30),
     data = dat)
summary(mod1)

k <- fixef(mod1)[1]; V <- fixef(mod1)[2];
## manual plot of resulting fixed effects curve:
IV.function <- function(t)
  {
    (1 - (t >=.5 )) * (D/Tinf)*(1/(k*V)) * (1 - exp(-k * t)) + (t >=.5)*(D/Tinf)*(1/(k*V))*(1 - exp(-k*Tinf))*exp(-k*(t-Tinf))
  }
curve(IV.function, 0, 8)

## this does not seem to work:
plot(augPred(mod1, level=0:1),
     main = "IV infusion, nonlinear mixed-effects model")



        [[alternative HTML version deleted]]


_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From bbolker at gmail.com  Sun Feb 10 17:03:54 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 10 Feb 2013 16:03:54 +0000 (UTC)
Subject: [R-sig-ME]
	=?utf-8?q?Details_on_specifying_random_parameters_in_3?=
	=?utf-8?q?-level_HLM=09with_lme?=
References: <CA+xNL7rpixTqDAHeF5UPRYgKF_oKC9nNuWhX5NFLtS+yoxLtjg@mail.gmail.com>
Message-ID: <loom.20130210T170034-701@post.gmane.org>

Richard Asturia <richard.asturia at ...> writes:

> 
> Dears,
> 
> I am used to fit 3-level HLM with Stata or HLM software, but now I have to
> do it with lme, from package nlme. Unfortunatelly, though, I am struggling
> with basic things and I could use any tips or suggestions.
> 
> What I am trying to do is to estimate a 3-level linear model where some of
> random effects are in the 2nd level, some are in the 3rd. The specification
> equations and the R code I was thinking of are as follows:
> 
> *Y* = b0 + b1**X1* + b2**X2* + e
> 
>       b0 = a00 + a01**X3* + r0
>       b1 = a10 + a11**X4* + r1
>       b2 = a20 + r2
> 
>               a00 = c00
>               a01 = c10 + u1
>               a10 = c20 + u2
>               a11 = c30
>               a20 = c40
> 
> *Y* = a00 + a01**X3* + r0 + a10**X1* + a11**X4***X1* + r1**X1* + a20**X2* +
> r2**X2* + e
> 
> *Y* = c00 +c10**X3* + u1**X3* + r0 + c20**X1* + u2**X1* + c30**X4***X1* + r1
> **X1* + c40**X2* + r2**X2* + e
> 
> *Y* = c00 + c20**X1* + c40**X2* + c10**X3* + c30**X4***X1* + r0 + r1**X1* +
> r2**X2* + u2**X1* + u1**X3* + e
> 
> So far, I could only wonder this code:
> lme(Y ~ X1 + X2 + X3 + X1:X4, random= ~ X1 + X2 + X3 | level3 / level2,
> data=mydataset)
> 
> But I feel this is somewhat wrong, as it estimates the random parameters of
> X1, X2 and X3 both in level 2 and in level 3, while the correct would be to
> put the random compenents of X1 and x2 in level 2 and of X1 and X3 in level
> 3. Which is something I don't know how to separate in the "random"
> parameter of the lme function and I couldn't find out anywhere so far.

  I haven't actually tried this out (I would be more likely to
test it before answering if you gave a reproducible example),
but have you noticed that under the
description of the 'random' argument, ?lme says

(ii) a list of one-sided formulas of the
form ?~x1+...+xn | g?, with possibly different random effects
models for each grouping level. The order of nesting will be
assumed the same as the order of the elements in the list;

  So I would think that something like

  random = list( ~ X1 + X2 | level2, ~ X1 + X3 | level3:level2 )

might work?
  
  Ben Bolker


From jcgordon at rvc.ac.uk  Sun Feb 10 21:40:26 2013
From: jcgordon at rvc.ac.uk (Gordon, Joanne)
Date: Sun, 10 Feb 2013 20:40:26 +0000
Subject: [R-sig-ME] What is the difference between Matlab Anovan and R mixed
	Model?
Message-ID: <A0F8B2630FD7CF49BF735F47FA25AA831A1E2B5A@HHSRVMB01.rvc.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130210/d577efb1/attachment.pl>

From bbolker at gmail.com  Sun Feb 10 23:31:02 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 10 Feb 2013 22:31:02 +0000 (UTC)
Subject: [R-sig-ME]
	=?utf-8?q?What_is_the_difference_between_Matlab_Anovan?=
	=?utf-8?q?_and_R_mixed=09Model=3F?=
References: <A0F8B2630FD7CF49BF735F47FA25AA831A1E2B5A@HHSRVMB01.rvc.ac.uk>
Message-ID: <loom.20130210T232641-205@post.gmane.org>

Gordon, Joanne <jcgordon at ...> writes:

> 
> Dear all,

> I would really like to perform a linear mixed effects model in R but
> have limited maths and computational skill.  I have a matlab Anovan
> function that does the job but I like doing basic things in R and
> would like to try the analysis there.
 
> I believe my data is unbalanced and that I would like to perform a
> crossed analysis (if my self teaching is correct).  My dependent
> variable ( A) is continuous.  I then have three independent
> categorical variables (B, C- fixed) (D= random) My random variable
> pertains to 'Individual'.

  so D is 'individual'?
 
> Several people have advised my that the main important thing is that
> I have included the effects of the random factor interactions with
> the other fixed factors- for example the advice was "try adding the
> first level interaction terms?  Of particular importance is the
> interaction between the fixed effect and random effect (BirdNo),
> because the correct calculation of the F-statistic for a mixed model
> should be the MSE of the fixed effect (e.g.  A) over the MSE for the
> interaction term (e.g.  A*D).  It looks like R doesn't automatically
> do this if the model doesn't include the interaction terms."

  see e.g. Schielzeth and Nakagawa _Methods in Ecology and Evolution_
on this topic.
 
> And someone who uses R suggested:
> lmer(A ~ B + C + (1|D), data=emgDat)
> lmer(A ~ B + C + (1|D) + (1|D*B*C),data=emgDat)

  I think you want

 lmer(A ~ B*C + (B*C|D), data=emgDat)

 **BUT** this only makes sense if the treatments B and C vary within
individuals, or at least within some individuals.  Otherwise you
can't estimate the interaction between B and C (and their interaction)
and D , which is what that last term does ...

   Hope that helps.


From theoni.photopoulou at gmail.com  Mon Feb 11 14:56:29 2013
From: theoni.photopoulou at gmail.com (Theoni Photopoulou)
Date: Mon, 11 Feb 2013 13:56:29 +0000
Subject: [R-sig-ME] Prior structure for fixed and random effects
Message-ID: <CAOjPYTS+DC7VvLpAQFmRcgKrBmdA_SF4aKy+9=g+XyoYnHg5Yg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130211/1c230869/attachment.pl>

From John.Morrongiello at csiro.au  Tue Feb 12 02:16:00 2013
From: John.Morrongiello at csiro.au (John.Morrongiello at csiro.au)
Date: Tue, 12 Feb 2013 12:16:00 +1100
Subject: [R-sig-ME] interpreting random intercepts when no fixed intercept
	present
Message-ID: <D7383CD4D59FEA4DA879EF5096A5A8CB180CA71A8A@exvic-mbx03.nexus.csiro.au>

Hi list

I was wondering how I interpret random effect intercepts in a model with no fixed intercept? Take for example the following model, based on those presented in Weisberg etal (2010):

M1<-lmer(growth~0+Age+(1|ID)+(1|Year)

Where growth is a repeatedly measured continuous variable, Age is a factor with 10 ordered levels (2:11) corresponding to each growth observation, ID and year are crossed random effects and represent individual animals (100) and the years in which they were sampled. This model provides a separate coefficient for each age; are the random effects deviations from just the Age2 (first) coefficient, or from the Age term in general? Each ID random effect has only one value, so they are obviously not unique deviations from each level of Age. Or are the random intercepts reflective of differences in average growth among individuals and years after the effect of age is 'accounted' for (i.e. not Age dependent)?

Furthermore, if M1 was extended to include harvest (factor with three levels) to which the population was exposed (some to just one level, others all three):

M2<-lmer(growth~0+Age+harvest+(1|ID)+(1|Year)

Is the interpretation of random effects now different to that in M1 in that they now include some harvest 'information'?

Thank you

John

Weisberg, S., Spangler, G., and Richmond, L.S. (2010). Mixed effects models for fish growth. Canadian Journal of Fisheries and Aquatic Sciences 67, 269-277.


From bbolker at gmail.com  Tue Feb 12 17:10:59 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 12 Feb 2013 16:10:59 +0000 (UTC)
Subject: [R-sig-ME]
	=?utf-8?q?interpreting_random_intercepts_when_no_fixed?=
	=?utf-8?q?_intercept=09present?=
References: <D7383CD4D59FEA4DA879EF5096A5A8CB180CA71A8A@exvic-mbx03.nexus.csiro.au>
Message-ID: <loom.20130212T150103-919@post.gmane.org>

 <John.Morrongiello at ...> writes:

> 
> Hi list
 
> I was wondering how I interpret random effect intercepts in a model
> with no fixed intercept? Take for example the following model, based
> on those presented in Weisberg etal (2010):

> M1<-lmer(growth~0+Age+(1|ID)+(1|Year)
 
> Where growth is a repeatedly measured continuous variable, Age is a
> factor with 10 ordered levels (2:11) corresponding to each growth
> observation, 
  
  Hmm.  It would generally seem to make more sense to treat
age as numeric, since I would expect some sort of smooth, systematic
(linear/quadratic/spline) relationship between growth and age.
(Although I guess using an ordered factor does in some way allow
you to separate linear, quadratic, higher-order contributions
to the growth-age relationship)

>  ID and year are crossed random effects and represent
> individual animals (100) and the years in which they were
> sampled. This model provides a separate coefficient for each age;
> are the random effects deviations from just the Age2 (first)
> coefficient, or from the Age term in general? Each ID random effect
> has only one value, so they are obviously not unique deviations from
> each level of Age. Or are the random intercepts reflective of
> differences in average growth among individuals and years after the
> effect of age is 'accounted' for (i.e. not Age dependent)?

  Hmmm.  I think in order to answer this question I'd have to
figure out what model.matrix() is doing when we use
[ordered factor]+0 in a formula.  I thought I knew but now
I don't think I do ...

> d <- data.frame(f=ordered(rep(1:5,10)),y=runif(50))
> options(digits=3)
> coef(lm(y~f,data=d))
(Intercept)         f.L         f.Q         f.C         f^4 
      0.525      -0.064       0.154       0.144      -0.116 
> coef(lm(y~f+0,data=d))
   f1    f2    f3    f4    f5 
0.589 0.651 0.360 0.428 0.599 
> coef(lm(y~f,data=d,contrasts=list(f=contr.treatment)))
(Intercept)          f2          f3          f4          f5 
     0.5885      0.0625     -0.2286     -0.1602      0.0101 

 (It would probably be better to use an example with a clear
linear and quadratic term and nothing else, for clarity)
 
> Furthermore, if M1 was extended to include harvest (factor with
> three levels) to which the population was exposed (some to just one
> level, others all three):
 
> M2<-lmer(growth~0+Age+harvest+(1|ID)+(1|Year)
 
> Is the interpretation of random effects now different to that in M1
> in that they now include some harvest 'information'?

  I think the answer to this is going to have to involve more
searching into how model.matrix() parameterizes these models.
Basically, once you know how the fixed effects are parameterized,
you can interpret what it means to add a zero-mean random-effects
offset to it ...   
 
 
> Weisberg, S., Spangler, G., and Richmond, L.S. (2010). Mixed effects
> models for fish growth. Canadian Journal of Fisheries and Aquatic
> Sciences 67, 269-277.


From andrea.cantieni at phsz.ch  Wed Feb 13 10:00:49 2013
From: andrea.cantieni at phsz.ch (Andrea Cantieni)
Date: Wed, 13 Feb 2013 09:00:49 +0000
Subject: [R-sig-ME] goodness-of-fit tests on mcmc objects
Message-ID: <F4A166428041EA44893A6FF6AAC1AA36518A56@ex01.phsz.loc>

Ein eingebundener Text mit undefiniertem Zeichensatz wurde abgetrennt.
Name: nicht verf?gbar
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130213/631034f3/attachment.pl>

From John.Morrongiello at csiro.au  Thu Feb 14 01:24:19 2013
From: John.Morrongiello at csiro.au (John.Morrongiello at csiro.au)
Date: Thu, 14 Feb 2013 11:24:19 +1100
Subject: [R-sig-ME] interpreting random intercepts when no fixed
	intercept present
In-Reply-To: <mailman.5.1360753201.31801.r-sig-mixed-models@r-project.org>
References: <mailman.5.1360753201.31801.r-sig-mixed-models@r-project.org>
Message-ID: <D7383CD4D59FEA4DA879EF5096A5A8CB180CA71A9B@exvic-mbx03.nexus.csiro.au>

Hi Ben

Thanks for your response. 

In these kind of models I have normally treated age as numeric, and log transformed both growth and age to 'linearise' the relationship. However, this doesn't always work, especially when the growth~age relationship displays an initial steep decline followed by a period of relatively constant growth (think indeterminate growth in fish that nonetheless markedly declines at maturity). Obviously a smoothing spline for age could fit this kind of data better but I'm developing some quite complex models that don't seem to be fit easily/ possible with GAMM. A quadratic or even cubic age term doesn't always fit the data well. 

I decided to have a look at treating age as a factor as it allows for greater flexibility in the growth~age relationship (each age is free to respond in its own way) and the data set I have can cope with estimating quite a few additional parameters (1 linear parameter vs. 10 fixed age parameters). I believe having no fixed intercept in the model allows for direct comparison of parameters amongst models developed for different species/ locations. I'll have a look into how model.matrix() parameterizes models with ordered fixed effects. Just quickly, would you expect there to be any difference in how random intercepts are interpreted in a model with no fixed intercept and un-ordered fixed effects?

Thank you

John


> Hi list
 
> I was wondering how I interpret random effect intercepts in a model 
> with no fixed intercept? Take for example the following model, based 
> on those presented in Weisberg etal (2010):

> M1<-lmer(growth~0+Age+(1|ID)+(1|Year)
 
> Where growth is a repeatedly measured continuous variable, Age is a 
> factor with 10 ordered levels (2:11) corresponding to each growth 
> observation,
  
  Hmm.  It would generally seem to make more sense to treat age as numeric, since I would expect some sort of smooth, systematic
(linear/quadratic/spline) relationship between growth and age.
(Although I guess using an ordered factor does in some way allow you to separate linear, quadratic, higher-order contributions to the growth-age relationship)

>  ID and year are crossed random effects and represent individual 
> animals (100) and the years in which they were sampled. This model 
> provides a separate coefficient for each age; are the random effects 
> deviations from just the Age2 (first) coefficient, or from the Age 
> term in general? Each ID random effect has only one value, so they are 
> obviously not unique deviations from each level of Age. Or are the 
> random intercepts reflective of differences in average growth among 
> individuals and years after the effect of age is 'accounted' for (i.e. 
> not Age dependent)?

  Hmmm.  I think in order to answer this question I'd have to figure out what model.matrix() is doing when we use [ordered factor]+0 in a formula.  I thought I knew but now I don't think I do ...

> d <- data.frame(f=ordered(rep(1:5,10)),y=runif(50))
> options(digits=3)
> coef(lm(y~f,data=d))
(Intercept)         f.L         f.Q         f.C         f^4 
      0.525      -0.064       0.154       0.144      -0.116 
> coef(lm(y~f+0,data=d))
   f1    f2    f3    f4    f5 
0.589 0.651 0.360 0.428 0.599 
> coef(lm(y~f,data=d,contrasts=list(f=contr.treatment)))
(Intercept)          f2          f3          f4          f5 
     0.5885      0.0625     -0.2286     -0.1602      0.0101 

 (It would probably be better to use an example with a clear linear and quadratic term and nothing else, for clarity)
 
> Furthermore, if M1 was extended to include harvest (factor with three 
> levels) to which the population was exposed (some to just one level, 
> others all three):
 
> M2<-lmer(growth~0+Age+harvest+(1|ID)+(1|Year)
 
> Is the interpretation of random effects now different to that in M1 in 
> that they now include some harvest 'information'?

  I think the answer to this is going to have to involve more searching into how model.matrix() parameterizes these models.
Basically, once you know how the fixed effects are parameterized, you can interpret what it means to add a zero-mean random-effects
offset to it ...   
 
 
> Weisberg, S., Spangler, G., and Richmond, L.S. (2010). Mixed effects 
> models for fish growth. Canadian Journal of Fisheries and Aquatic 
> Sciences 67, 269-277.



------------------------------

Message: 2
Date: Wed, 13 Feb 2013 09:00:49 +0000
From: Andrea Cantieni <andrea.cantieni at phsz.ch>
To: "R-sig-mixed-models at r-project.org"
	<R-sig-mixed-models at r-project.org>
Subject: [R-sig-ME] goodness-of-fit tests on mcmc objects
Message-ID: <F4A166428041EA44893A6FF6AAC1AA36518A56 at ex01.phsz.loc>
Content-Type: text/plain

Dear all,

I am fitting an hierarchical model with MCMChregress() in MCMCpack package.

I want to do some goodness-of-fit tests, e.g. posterior predictive checks, that are suitable for hierarchical models.

Has anyone suggestions how I can do that?

Thanks!

Best,
Andrea
........................................................................

Andrea Cantieni
Research Assistant

University of Teacher Education Central Switzerland Campus Schwyz Institute for Media and Schools Zaystrasse 42
6410 Goldau
Switzerland

Tel. +41 41 859 05 72
andrea.cantieni at phsz.ch<mailto:andrea.cantieni at phsz.ch>
www.phsz.ch<http://www.phsz.ch>

........................................................................
Please take note of our new email address (@phsz.ch<http://phsz.ch>).
........................................................................





	[[alternative HTML version deleted]]



------------------------------

_______________________________________________
R-sig-mixed-models mailing list
R-sig-mixed-models at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


End of R-sig-mixed-models Digest, Vol 74, Issue 22


From curis at pharmacie.univ-paris5.fr  Tue Feb 12 17:30:06 2013
From: curis at pharmacie.univ-paris5.fr (Emmanuel Curis)
Date: Tue, 12 Feb 2013 17:30:06 +0100
Subject: [R-sig-ME] interpreting random intercepts when no fixed
 intercept?present
In-Reply-To: <loom.20130212T150103-919@post.gmane.org>
References: <D7383CD4D59FEA4DA879EF5096A5A8CB180CA71A8A@exvic-mbx03.nexus.csiro.au>
	<loom.20130212T150103-919@post.gmane.org>
Message-ID: <20130212163006.GC21617@laboinfo-063.pharmacie.univ-paris5.fr>

Hello,

On Tue, Feb 12, 2013 at 04:10:59PM +0000, Ben Bolker wrote:

?   Hmmm.  I think in order to answer this question I'd have to
? figure out what model.matrix() is doing when we use
? [ordered factor]+0 in a formula.  I thought I knew but now
? I don't think I do ...

According to its code, it also uses the default contrasts, but for
ordered factor it is contr.poly and not contr.treatment.

? > d <- data.frame(f=ordered(rep(1:5,10)),y=runif(50))
? > options(digits=3)
? > coef(lm(y~f,data=d))
? (Intercept)         f.L         f.Q         f.C         f^4 
?       0.525      -0.064       0.154       0.144      -0.116 
? > coef(lm(y~f+0,data=d))
?    f1    f2    f3    f4    f5 
? 0.589 0.651 0.360 0.428 0.599 
? > coef(lm(y~f,data=d,contrasts=list(f=contr.treatment)))
? (Intercept)          f2          f3          f4          f5 
?      0.5885      0.0625     -0.2286     -0.1602      0.0101 

With your example:

>  d <- data.frame(f=ordered(rep(1:5,10)),y=runif(50))
> options(digits=3)
>  coef(lm(y~f,data=d))
(Intercept)         f.L         f.Q         f.C         f^4 
     0.4936     -0.0775     -0.1209      0.0614     -0.0233 
> coef(lm(y~f+0,data=d))
   f1    f2    f3    f4    f5 
0.456 0.600 0.542 0.474 0.397 
> coef(lm(y~f,data=d,contrasts=list(f=contr.poly)))
(Intercept)         f.L         f.Q         f.C         f^4 
     0.4936     -0.0775     -0.1209      0.0614     -0.0233 
> coef(lm(y~f+0,data=d,contrasts=list(f=contr.poly)))
   f1    f2    f3    f4    f5 
0.456 0.600 0.542 0.474 0.397 

I imagine the default choice of contr.poly is to have this separation
between linear, quadratic... terms (orthogonal polynomials?), building
contrasts assuming equally-spaced X values...

?  (It would probably be better to use an example with a clear
? linear and quadratic term and nothing else, for clarity)

?   I think the answer to this is going to have to involve more
? searching into how model.matrix() parameterizes these models.
? Basically, once you know how the fixed effects are parameterized,
? you can interpret what it means to add a zero-mean random-effects
? offset to it ...   

Generally, would it mean by forcing a null fixed intercept means that
we assume that the population average is 0 for the intercept, but vary
from a patient to another?

Of course, assuming a null (mean) intercept strongly depends on the
coding of the quantitative (or ordered) predictor, so can be easily
misleading I guess...

Hope this help,

-- 
                                Emmanuel CURIS
                                emmanuel.curis at parisdescartes.fr

Page WWW: http://emmanuel.curis.online.fr/index.html


From John.Morrongiello at csiro.au  Thu Feb 14 06:10:31 2013
From: John.Morrongiello at csiro.au (John.Morrongiello at csiro.au)
Date: Thu, 14 Feb 2013 16:10:31 +1100
Subject: [R-sig-ME] random effect syntax
Message-ID: <D7383CD4D59FEA4DA879EF5096A5A8CB180CA71A9D@exvic-mbx03.nexus.csiro.au>

Hi list

I was wondering if someone could explain to me the difference between two models in terms of their random effect structure? We have a datatset of repeated growth observations within 400 individuals (ID) from three sites. The growth of these individuals corresponds to different years and is thus a crossed random effect with ID. As we only have three sites, we are not treating it as a random effect, although we'd like to test whether the year-to-year growth variation is dependent on the site it comes from. We'd also like to test whether the growth~age relationship varies among years. Hence we have fit the following models:

M1<-lmer(growth~Age*site+(Age|ID)+(Age+site|Year))
M2<-lmer(growth~age*site+(Age|ID)+(Age|site:Year))

I think that M2 is maybe nesting Year within site, whereas M1 is just allowing for by year adjustments to each site, but I'm not sure! Below is the random effects tables from the two models. 

*Random effects output from M1:
AIC BIC logLik deviance REMLdev
 105 322  -16.4     -139    32.8
Random effects:
 Groups   Name         Variance Std.Dev. Corr               
 FishID   (Intercept)  0.012636 0.1124                      
          c.(log(age)) 0.016178 0.1272   -0.052             
 fYear    (Intercept)  0.000234 0.0153                      
          c.(log(age)) 0.011124 0.1055   0.494              
          sitehcr      0.006363 0.0798   0.546  0.998       
          sitepb       0.005130 0.0716   0.755  0.943 0.962 
 Residual              0.044675 0.2114                      
Number of obs: 3115, groups: FishID, 392; fYear, 21

*Random effects output from M2:
AIC BIC logLik deviance REMLdev
 133 308  -37.6    -87.4    75.1
Random effects:
 Groups     Name         Variance Std.Dev. Corr   
 FishID     (Intercept)  0.01249  0.1117          
            c.(log(age)) 0.01641  0.1281   -0.058 
 site:fYear (Intercept)  0.00314  0.0560          
            c.(log(age)) 0.00979  0.0989   0.826  
 Residual                0.04478  0.2116          
Number of obs: 3115, groups: FishID, 392; site:fYear, 57

When I print the random effects, I get different values. For M1, there is a random intercept for each year and a corresponding 'adjustment' for each site. When plotted, there is very little difference among years for each site. For M2, I get a unique intercept for each year by site combination. When plotted, these show considerable among-site variation through time (which I think is a better reflection of the underlying data). However, a likelihood ratio test prefers M1, so a bit confused.

Thank you for your time

John


From Thierry.ONKELINX at inbo.be  Thu Feb 14 12:03:12 2013
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Thu, 14 Feb 2013 11:03:12 +0000
Subject: [R-sig-ME] random effect syntax
In-Reply-To: <D7383CD4D59FEA4DA879EF5096A5A8CB180CA71A9D@exvic-mbx03.nexus.csiro.au>
References: <D7383CD4D59FEA4DA879EF5096A5A8CB180CA71A9D@exvic-mbx03.nexus.csiro.au>
Message-ID: <AA818EAD2576BC488B4F623941DA7427A7A62477@inbomail.inbo.be>

Dear John,

Let's consider first the difference between (site|year) and (1|year:site). Both define an effect for each site-year combination. But with (site|year) the effects of site can be correlated whereas (1|site:year) assumes that they are independent.

It's a bit more complicated when you add a random slope along age. In (age|year:site) the random slope along age and the random intercept are correlated with each other but not with site. With (age + site|year) now age and site are correlated and the correlation between age and the intercept is at the level of year instead of year:site. So you assume a different slope per year instead of per year:site combination.

Best regards,

Thierry

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey


-----Oorspronkelijk bericht-----
Van: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] Namens John.Morrongiello at csiro.au
Verzonden: donderdag 14 februari 2013 6:11
Aan: r-sig-mixed-models at r-project.org
Onderwerp: [R-sig-ME] random effect syntax

Hi list

I was wondering if someone could explain to me the difference between two models in terms of their random effect structure? We have a datatset of repeated growth observations within 400 individuals (ID) from three sites. The growth of these individuals corresponds to different years and is thus a crossed random effect with ID. As we only have three sites, we are not treating it as a random effect, although we'd like to test whether the year-to-year growth variation is dependent on the site it comes from. We'd also like to test whether the growth~age relationship varies among years. Hence we have fit the following models:

M1<-lmer(growth~Age*site+(Age|ID)+(Age+site|Year))
M2<-lmer(growth~age*site+(Age|ID)+(Age|site:Year))

I think that M2 is maybe nesting Year within site, whereas M1 is just allowing for by year adjustments to each site, but I'm not sure! Below is the random effects tables from the two models.

*Random effects output from M1:
AIC BIC logLik deviance REMLdev
 105 322  -16.4     -139    32.8
Random effects:
 Groups   Name         Variance Std.Dev. Corr
 FishID   (Intercept)  0.012636 0.1124
          c.(log(age)) 0.016178 0.1272   -0.052
 fYear    (Intercept)  0.000234 0.0153
          c.(log(age)) 0.011124 0.1055   0.494
          sitehcr      0.006363 0.0798   0.546  0.998
          sitepb       0.005130 0.0716   0.755  0.943 0.962
 Residual              0.044675 0.2114
Number of obs: 3115, groups: FishID, 392; fYear, 21

*Random effects output from M2:
AIC BIC logLik deviance REMLdev
 133 308  -37.6    -87.4    75.1
Random effects:
 Groups     Name         Variance Std.Dev. Corr
 FishID     (Intercept)  0.01249  0.1117
            c.(log(age)) 0.01641  0.1281   -0.058
 site:fYear (Intercept)  0.00314  0.0560
            c.(log(age)) 0.00979  0.0989   0.826
 Residual                0.04478  0.2116
Number of obs: 3115, groups: FishID, 392; site:fYear, 57

When I print the random effects, I get different values. For M1, there is a random intercept for each year and a corresponding 'adjustment' for each site. When plotted, there is very little difference among years for each site. For M2, I get a unique intercept for each year by site combination. When plotted, these show considerable among-site variation through time (which I think is a better reflection of the underlying data). However, a likelihood ratio test prefers M1, so a bit confused.

Thank you for your time

John

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.


From John.Morrongiello at csiro.au  Thu Feb 14 23:27:33 2013
From: John.Morrongiello at csiro.au (John.Morrongiello at csiro.au)
Date: Fri, 15 Feb 2013 09:27:33 +1100
Subject: [R-sig-ME] random effect syntax
In-Reply-To: <AA818EAD2576BC488B4F623941DA7427A7A62477@inbomail.inbo.be>
References: <D7383CD4D59FEA4DA879EF5096A5A8CB180CA71A9D@exvic-mbx03.nexus.csiro.au>
	<AA818EAD2576BC488B4F623941DA7427A7A62477@inbomail.inbo.be>
Message-ID: <D7383CD4D59FEA4DA879EF5096A5A8CB180CA71AA2@exvic-mbx03.nexus.csiro.au>

Dear Thierry
Thank you very much for this clear explanation of the differences between the two random effect structures. Much appreciated!

John

-----Original Message-----
From: ONKELINX, Thierry [mailto:Thierry.ONKELINX at inbo.be] 
Sent: Thursday, 14 February 2013 10:03 PM
To: Morrongiello, John (CMAR, Hobart); r-sig-mixed-models at r-project.org
Subject: RE: random effect syntax

Dear John,

Let's consider first the difference between (site|year) and (1|year:site). Both define an effect for each site-year combination. But with (site|year) the effects of site can be correlated whereas (1|site:year) assumes that they are independent.

It's a bit more complicated when you add a random slope along age. In (age|year:site) the random slope along age and the random intercept are correlated with each other but not with site. With (age + site|year) now age and site are correlated and the correlation between age and the intercept is at the level of year instead of year:site. So you assume a different slope per year instead of per year:site combination.

Best regards,

Thierry

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey


-----Oorspronkelijk bericht-----
Van: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] Namens John.Morrongiello at csiro.au
Verzonden: donderdag 14 februari 2013 6:11
Aan: r-sig-mixed-models at r-project.org
Onderwerp: [R-sig-ME] random effect syntax

Hi list

I was wondering if someone could explain to me the difference between two models in terms of their random effect structure? We have a datatset of repeated growth observations within 400 individuals (ID) from three sites. The growth of these individuals corresponds to different years and is thus a crossed random effect with ID. As we only have three sites, we are not treating it as a random effect, although we'd like to test whether the year-to-year growth variation is dependent on the site it comes from. We'd also like to test whether the growth~age relationship varies among years. Hence we have fit the following models:

M1<-lmer(growth~Age*site+(Age|ID)+(Age+site|Year))
M2<-lmer(growth~age*site+(Age|ID)+(Age|site:Year))

I think that M2 is maybe nesting Year within site, whereas M1 is just allowing for by year adjustments to each site, but I'm not sure! Below is the random effects tables from the two models.

*Random effects output from M1:
AIC BIC logLik deviance REMLdev
 105 322  -16.4     -139    32.8
Random effects:
 Groups   Name         Variance Std.Dev. Corr
 FishID   (Intercept)  0.012636 0.1124
          c.(log(age)) 0.016178 0.1272   -0.052
 fYear    (Intercept)  0.000234 0.0153
          c.(log(age)) 0.011124 0.1055   0.494
          sitehcr      0.006363 0.0798   0.546  0.998
          sitepb       0.005130 0.0716   0.755  0.943 0.962
 Residual              0.044675 0.2114
Number of obs: 3115, groups: FishID, 392; fYear, 21

*Random effects output from M2:
AIC BIC logLik deviance REMLdev
 133 308  -37.6    -87.4    75.1
Random effects:
 Groups     Name         Variance Std.Dev. Corr
 FishID     (Intercept)  0.01249  0.1117
            c.(log(age)) 0.01641  0.1281   -0.058
 site:fYear (Intercept)  0.00314  0.0560
            c.(log(age)) 0.00979  0.0989   0.826
 Residual                0.04478  0.2116
Number of obs: 3115, groups: FishID, 392; site:fYear, 57

When I print the random effects, I get different values. For M1, there is a random intercept for each year and a corresponding 'adjustment' for each site. When plotted, there is very little difference among years for each site. For M2, I get a unique intercept for each year by site combination. When plotted, these show considerable among-site variation through time (which I think is a better reflection of the underlying data). However, a likelihood ratio test prefers M1, so a bit confused.

Thank you for your time

John

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * * Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.


From anton.wasson at gmail.com  Fri Feb 15 04:43:37 2013
From: anton.wasson at gmail.com (Anton Wasson)
Date: Fri, 15 Feb 2013 14:43:37 +1100
Subject: [R-sig-ME] Incorrect output when applying lmer within a loop.
Message-ID: <51CEEF2C-CC16-43F5-B167-0043BE116C52@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130215/e3db9f19/attachment.pl>

From bbolker at gmail.com  Sat Feb 16 04:32:54 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 16 Feb 2013 03:32:54 +0000 (UTC)
Subject: [R-sig-ME] Incorrect output when applying lmer within a loop.
References: <51CEEF2C-CC16-43F5-B167-0043BE116C52@gmail.com>
Message-ID: <loom.20130216T041651-835@post.gmane.org>

Anton Wasson <anton.wasson at ...> writes:

>  Hello All, I am a novice user of R and LME4 - I hope I am sending
> this query to an appropriate forum. I am generating erroneous data,
> but I don't know if the reason is misuse of LME4 or the loop
> function.

As it turns out, it's more of an R issue than an lme4 issue.

[snip]
 
> I wrote a loop to run a model (VAR ~ (1|GEN) + (1|OPR) + (1|ROW) +
> (1|RAN)) on each response variable, to extract the variance for each
> factor (and the residual) and to build a dataframe of the variances
> across all the response variables. The names of the variables were
> in the vector "nam".
 
> > nam [1] "X20" "X30" "X40" "X50" "X60" "X70" "X80" "X90" "X100"
>  "X110" "X120" "X130" "X140" "X150" "X160" "X170" 
 "X180" "X190"
>  "X200" "md" "tc" "md90"

Or 

nam <- c(paste0(X,(2:20)*10),c("md","tc","md90"))

[snip]

> x<-1
> for(i in nam) {
>   d<-r[,c("REP","ROW","RAN","GEN","OPR",i)]
>   colnames(d)<-c("REP","ROW","RAN","GEN","OPR","VAR")
>   r.mer<-lmer(VAR ~ (1|GEN) + (1|OPR) + (1|ROW) + (1|RAN), data=d)
>   r.var <- data.frame(summary(r.mer)@REmat)
>   V1[x]<-as.numeric(as.character(r.var[r.var$Groups=="GEN",'Variance']))
>   V2[x]<-as.numeric(as.character(r.var[r.var$Groups=="OPR",'Variance']))
>   V3[x]<-as.numeric(as.character(r.var[r.var$Groups=="RAN",'Variance']))
>   V4[x]<-as.numeric(as.character(r.var[r.var$Groups=="ROW",'Variance']))
>   V5[x]<-as.numeric(as.character(r.var[r.var$Groups=="Residual",'Variance']))
>   x<-x+1
>   }

 It would be cleaner and safer to use unlist(VarCorr(r.mer)) to access the RE
variances,
and sigma(fm1)^2 to get the residual variance.

  You can use 

    reformulate(paste0("(1|",c("GEN","OPR","ROW","RAN"),")"),response="V1")

## V1 ~ (1 | GEN) + (1 | OPR) + (1 | ROW) + (1 | RAN)

to generate formulae with different reponse variables, and use the same
input data set every time.

> df<-data.frame(nam,V1,V2,V3,V4,V5)
> colnames(df)<-c("DEP", "GEN", "OPR", "RAN", "ROW","Residual")
> 
> That script gave the following output for the variances for the factors
> 

[snip]

Your problem is that R stops running the code when you try to run the
example with the error, leaving the last four rows equal to zero as
they were initialized.  It is generally safer to fill in NA in the
data frame that will hold the results, so that you can see what hasn't
been computed.

d <- as.data.frame(matrix(NA,nrow=length(nam),ncol=6),
                   dimnames=list(nam,c("REP","ROW","RAN","GEN","OPR","VAR")))

You could use try() to intercept errors, but you would still have to
check the results (if inherits(model_results,"try-error")) to skip
the row appropriately


From bbolker at gmail.com  Sat Feb 16 18:19:35 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 16 Feb 2013 12:19:35 -0500
Subject: [R-sig-ME] glmmADMB function maximizer failure
In-Reply-To: <4A3F286665AD3D488D56FDFAC7D8CE430C1F2624@exchange2-1>
References: <4A3F286665AD3D488D56FDFAC7D8CE430C1F2624@exchange2-1>
Message-ID: <511FBFA7.4030208@gmail.com>


    [cc'ing back to r-sig-mixed]

On 13-02-16 08:33 AM, Adriaan De Jong wrote:
> Hi,
> 
> Some time ago I posted a question to the r-sig-mixed-models forum (copy
> below), but, much to my surprise, received no answer yet (although the
> R-sig-mixed-models Archives
> <https://stat.ethz.ch/pipermail/r-sig-mixed-models/> stored an answer to
> another question under this question?s header).

  I saw the response from Billy Requena at <
http://article.gmane.org/gmane.comp.lang.r.lme4.devel/9591 >
recommending that you try admbControl(shess=FALSE,noinit=FALSE) ; I had
hoped that might work for you in some cases.

> Since I posted my question, I found that others have encountered this
> error and that the issue has been discussed by you and others on the
> r-sig-mixed-models forum. From what I?ve seen in the archives and from
> the results of further web-searches, I?ve come to the conclusion that
> this matter is not finally settled. Am I wrong? If not, I hope this
> e-mail can contribute to the solution.

 This matter is certainly not finally settled.

 Apologies in advance if I sound a bit defensive about this, but:
nonlinear modeling is *hard*, and especially hard on small, noisy data
sets that are so common in ecology. (I'm tempted to go back
and italicize/boldface/uppercase that a few times.)
Just because more sophisticated models exist and we'd like to use
them (of course I would like to allow for all of the realistic
complications that I know are out there), doesn't mean it's
practical to fit them to data, no matter how slick the computational
tools are.

I'm not trying to blame the data or make light of the difficulty
of gathering it -- just saying that it's really hard to
fit a complicated model to a sparse data set.

glmmADMB attempts to be a black-box, one-size-fits-all solution.
It is often possible to do a bit better by hand-tuning the model in
AD Model Builder, but this requires quite a bit of expertise and
knowledge about how the model-fitting procedure works.
  Furthermore, glmmADMB errs a tiny bit on the side of caution by
refusing to give an answer when the estimated Hessian matrix
(the matrix of second derivatives of the log-likelihood with respect
to the parameters, which when inverted gives an estimate of the
variances/standard) is not well-behaved (positive definite). *Sometimes*
the answers might be reasonable even when the Hessian is bad, but
it's not possible to know without checking carefully, and it would
be very easy to get nonsensical answers this way.  I've considered
adding an option to allow fits to be retrieved even when the Hessian
is bad, but I'm afraid it would be badly misused ...
  It's sometimes the case that exactly the same glmmADMB fit behaves
differently on different platforms (Windows, MacOS, Linux, 32 vs
64-bit).  This is frustrating, but it generally means that the model
is very close to the edge of stability in any case ...

  More generally, I'm not entirely enamored of the AIC-inspired
"run all possible cases" scenario.  I can appreciate wanting to
make a reasonable job estimating an appropriate place in the bias-variance
tradeoff curve, or get good model-averaged predictions, but I
wonder what your goal is here.  Are you trying to test hypotheses
about the effect of the treatment?  Are you trying to figure out
the best predictive model for management purposes?  Admittedly it
would be nice if there were good, flexible penalized regression models
(IMO a better way to do good estimation when the appropriate variables
are unknown than AIC-based model averaging) that could handle the
things ecologists like to do (negative binomial models,
random effects, etc.)).

  The bottom line is that I'm sorry that glmmADMB doesn't work
better than it does, but it's very hard to give any general prescriptions
other than (1) accept that some data are too sparse to fit some models;
(2) work up your own models from scratch using WinBUGS/JAGS or
AD Model Builder, so you have more control to tweak settings

  Depending on what I was doing with this problem, I would try:

* check whether the among-site variances seem large in general;
if not (I bet they're not), simplify life by dropping the random
effects and just fitting Poisson or NB GLMs
* use permutation tests to allow for hypothesis testing with
fewer distributional assumptions
* rather than fitting each species separately, try modeling all
the data together, with a random effect of species (and
species-by-treatment).
[This may sound contradictory since I'm encouraging you to simplify
your models, but this would have the advantage of allowing the
rarer species to "share strength" from the commoner species ...]

> I also continued my tests of glmmADMB. The data I use are of 13 species
> from the very same investigation (nine years of territory mapping of
> breeding birds in 19 different sites), but because I?ve excluded sites
> without any observation during the nine year?s period from the analysis
> of that species

  This seems reasonable, as those territories can't contribute
any information about the dynamics of that bird through time
or with respect to treatment,s although I would be very careful with it.

> the numbers of cases varies among species, and of
> course, species range from rare to common (all data files attached).
> 
> The pass/fail pattern of the six models over the species was as follows:
> 
> Spec.     m100     m200     m300     m400     m500     m600     (models
> described in the copy of my forum posting below)
> Aa           x              +             +             +            
> x              x
> 
> Ap          +             x              +             x             
> x              x
> 
> Cd           +             x              +             x             
> +             +
> 
> Ce           +             x              +             +            
> +             x
> 
> Gg          x              x              +             x             
> x              x
> 
> Hr           +             x              +             x             
> +             +
> 
> Lc            +             x              +             x             
> +             +
> 
> Mf          x              x              x              +            
> x              x
> 
> Na          +             x              +             x             
> +             x
> 
> Sr            x              x              +             x             
> +             x
> 
> Sv           x              x              +             +            
> x              x
> 
> To           +             x              +             x             
> x              +
> 
> Vv           x              +             +             x             
> +             +            
> 
> Clearly, the negative binomial model without zeroinflation correction
> (m300) worked fine for most species. Unfortunately, all the failing
> models made the use of AICctab and the graphs presented in the ?Getting
> started with the glmmADMB package? rather meaningless.
> 
> After scrutinizing the data further, I concluded that the Cd, Ce, Gg, Lc
> and To data had few >1 observations, and thus were better treated with
> binomial glmer models.
> 
> The distribution of the data also ?explained? why the Mf data could be
> fitted with zeroInflation = TRUE but not with zeroInflation = FALSE.
> This was the only (non-binomial) dataset with obvious zero inflation.
> 
> From there I ran ?nbinom? models for the eight non-binomial species
> (with zeroInflation = TRUE for the Mf data) with the following
> combinations of fixed and random factors:
> 
> treatment * year + (year|site)
> treatment + year + (year|site)
> year + (year|site)
> treatment + (year|site)
> 1 + (year|site)
> treatment * year + (1|site)
> treatment + year + (1|site)
> year + (1|site)
> treatment + (1|site)
> 1 + (1|site)
> 
> This worked fine in all species except Ap. Here, the 1 + year|site model
> produced the ?The function maximizer failed (couldn't find STD file)?
> error, while the 1|site, the model ran fine. This seems to contradict
> the suggestion by Joshua Wiley (?What happens if you try a simpler
> model?) when answering Melanie Browne (Jun 24, 2012). Here the next
> simplest model produced the error while the more complex models didn?t.
> 
> Basically, I?m fairly satisfied with the model selection process I?ve
> been able to conduct, but I would have preferred to test each treatment
> * year + (year|site) model under m100 ? m600 conditions and choose the
> optimal one before further comparisons (with simpler model versions).
> The current ad hoc solution is reasonable given the distribution of the
> data, but a true AICc based selection would be easier to ?sell? to
> editors, reviewers and readers.
> 
> Thanks in advance for any comments or suggestions.
> 
> Cheers,
> 
> Adjan
> 
> PS. I?ve been unable to find a full documentation of the glmmADMB
> package. Only found ?Getting started with the glmmADMB package? dated
> Jan. 2, 2012.

   I guess I'm wondering what other kind of documentation you
would like other than the help pages in the package (which should
provide a complete, if terse, description of all available options)
and the vignette you describe (which also comes with the package,
and can be accessed via vignette("glmmadmb") when the package is loaded).
I'm open to suggestions about what is missing, and especially open
to contributions!

> Copy of the 8 Feb. posting:
> 
> Hi,
> 
> I try to evaluate models with various families, with and without zero
> inflation.
> 
> This is the set of models I?ve tried so far:

    [snip]

> For species A, m100, m300 and m600 run smoothly, but the others all
> return the same error message:
> 
>  
> 
> Error in glmmadmb(resp ~ treatment * year + (year | site) +
> offset(log(bot$area)),  :
> 
>   The function maximizer failed (couldn't find STD file)
> 
>  
> 
> although I try to follow the ?Getting started with the glmmADMB package?
> as closely as possible.

> The error message always comes with an additional warning:
> 
> In addition: Warning message:
> 
> running command 'C:\Windows\system32\cmd.exe /c "C:/Program
> Files/R/R-2.15.2/library/glmmADMB/bin/windows64/glmmadmb.exe" -maxfn 500
> -maxph 5 -noinit -shess' had status 1
> 
>  
> 
> For other  species, other models produce this error while models not
> working for species A work fine  (each species has the same
> data-structure, but with different amounts and distributions of the
> zeros, and different number of cases).
> 
>  
> 
> The glmmADMB package was downloaded today from
> http://glmmadmb.r-forge.r-project.org/ and I run  R x64 2.15.2
> (2012-10-26) under Windows 7 in a university network.
> 
> Grateful for any hints or comments that can lead me out of this trench.
> 
> Have a nice weekend!
> 
> Adjan
> 
>  

Here's my R code:

## read in files and merge them:

dfiles <-  list.files(pattern="[A-Za-z]{2}.txt")
dfiles <- setdiff(dfiles,"Eh.txt") ## leave out Eh (too rare)
spnames <- gsub("\\.txt","",dfiles)
datlist <- lapply(dfiles,read.table,header=TRUE)
datlist2 <- lapply(datlist,
                   function(x) {
                       names(x)[ncol(x)] <- "number"
                       x
                   })
alldat <- do.call(rbind,datlist2)
alldat$sp <- rep(spnames,sapply(datlist,nrow))
alldat <- transform(alldat,sp=reorder(sp,number/area))

library("plyr")
library("reshape2")
ddply(alldat,"sp",summarise,tot=sum(number))
dcast(ddply(alldat,c("sp","treatment"),summarise,tot=sum(number)),
     sp~treatment,value=tot)

library("ggplot2")
theme_set(theme_bw())
library("grid")
zm <- theme(panel.margin=unit(0,"line"))
ggplot(alldat,aes(x=year,y=number/area,colour=treatment))+
    geom_line(aes(group=site))+
    facet_wrap(~sp)+zm +
    scale_y_sqrt() ## expand axes a bit: would like to use log,
                   ## but too many zeroes to make it worth it

## collapse to boxplots (ignore sites/years since it
## sort of looks like noise anyway
ggplot(alldat,aes(x=treatment,y=number/area,colour=treatment))+
    geom_boxplot(outlier.colour=NULL)+
    facet_wrap(~sp)+zm+scale_y_sqrt()

## "beeswarm" plot for more detail
ggplot(alldat,aes(x=treatment,y=number/area,
                  fill=treatment,color=treatment))+
    geom_dotplot(stackdir="center",binaxis="y",alpha=0.8)+
    facet_wrap(~sp)+zm

## look at raw numbers rather than densities, to get a better
## sense of the Poisson/NB issue
ggplot(alldat,aes(x=treatment,y=number,
                  fill=treatment,color=treatment))+
    geom_dotplot(stackdir="center",binaxis="y",alpha=0.8)+
    facet_wrap(~sp)+zm

## Based on these pictures and summaries, (a) I see very little
## pattern overall (b) some of the data sets are pretty clearly too
## small to do much with (e.g. in the first 7 species, there are
## at most 7 non-zero observations in the "During" phase); but
## let's see how far we can get anyway.

## Try each species with all three families, with/without zero inflation,
## with/without the shess/noninit trick

form <- number ~ treatment * year + (year|site)+ offset(log(area))
library("glmmADMB")
fvec <- c("poisson","nbinom","nbinom1")
params <- expand.grid(family=fvec,zi=c(FALSE,TRUE),sp=levels(alldat$sp),
                      shess=c(TRUE,FALSE))
nmodels <- nrow(params)
mresults <- vector(nmodels,mode="list")

i <- 1
for (sp in levels(alldat$sp)) {
    for (zi in c(FALSE,TRUE)) {
       for (fam in fvec) {
           for (shess in c(TRUE,FALSE)) {
              cat(i,fam,zi,sp,shess,"\n")
              mresults[[i]] <-
               try(glmmadmb(form,family=fam,zeroInflation=zi,
                       data=alldat[alldat$sp==sp,], ## watch out for
subset()!
                       admb.opts=if (shess) admbControl() else
                            admbControl(shess=FALSE,noinit=FALSE)),
                   silent=TRUE)
           i <- i+1
          }
      }
   }
}
save("mresults",file="mresults.RData")
params$OK <- sapply(mresults,inherits,"try-error")

## whether we succeed
ggplot(params,aes(x=family,y=sp,fill=OK))+geom_tile()+
                                   facet_grid(zi~shess,
                                              labeller=label_both)

## whether they can be made to work with either 'shess/noinit' setting
params2 <- dcast(params,family+zi+sp~.,fun.aggregate=any,value.var="OK")
names(params2)[4] <- "OK"
ggplot(params,aes(x=family,y=sp,fill=OK))+geom_tile()+
                                   facet_grid(zi~.,
                                              labeller=label_both)


From richard.asturia at gmail.com  Sun Feb 17 06:03:18 2013
From: richard.asturia at gmail.com (Richard Asturia)
Date: Sun, 17 Feb 2013 02:03:18 -0300
Subject: [R-sig-ME] Extracting higher level coefficients to replicate
	Douglas Luke's table
Message-ID: <CA+xNL7qxpC=_XPHyZwDk_K3kHCjWbrRKHd+1V_6rp4hodfKz_g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130217/d7855a16/attachment.pl>

From cen.zop at gmail.com  Sun Feb 17 07:09:28 2013
From: cen.zop at gmail.com (=?UTF-8?Q?Cengiz_Zopluo=C4=9Flu?=)
Date: Sun, 17 Feb 2013 00:09:28 -0600
Subject: [R-sig-ME] Fitting different error structures with lme()
Message-ID: <CAGMyHZRMmd4QAZTx02Z1P35hup4UmjpiXKkWyyOtSQWZJ2fK+g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130217/b571fe00/attachment.pl>

From napo_v at hotmail.com  Sun Feb 17 18:28:35 2013
From: napo_v at hotmail.com (Napo Vargas)
Date: Sun, 17 Feb 2013 17:28:35 +0000
Subject: [R-sig-ME] Error message in Pedigreemm
Message-ID: <BAY147-W38B1E933190BC7918637B6F60C0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130217/f9d1cb2f/attachment.pl>

From pierces1 at msu.edu  Sun Feb 17 18:43:41 2013
From: pierces1 at msu.edu (Steven J. Pierce)
Date: Sun, 17 Feb 2013 12:43:41 -0500
Subject: [R-sig-ME] Extracting higher level coefficients to
	replicate	Douglas Luke's table
In-Reply-To: <CA+xNL7qxpC=_XPHyZwDk_K3kHCjWbrRKHd+1V_6rp4hodfKz_g@mail.gmail.com>
References: <CA+xNL7qxpC=_XPHyZwDk_K3kHCjWbrRKHd+1V_6rp4hodfKz_g@mail.gmail.com>
Message-ID: <001101ce0d36$5371b900$fa552b00$@msu.edu>

Richard,

Perhaps you can directly contact Douglas Luke to inquire about obtaining the
supporting materials. Here's a link to his webpage at his university:
http://publichealth.wustl.edu/people/scholardatabase/Pages/Luke.aspx 


Steven J. Pierce, Ph.D. 
Associate Director 
Center for Statistical Training & Consulting (CSTAT) 
Michigan State University 
E-mail: pierces1 at msu.edu 
Web: http://www.cstat.msu.edu 

-----Original Message-----
From: Richard Asturia [mailto:richard.asturia at gmail.com] 
Sent: Sunday, February 17, 2013 12:03 AM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] Extracting higher level coefficients to replicate
Douglas Luke's table

Dears, I have a very newby problem as I am migrating to lme4.

I am trying to replicate Douglas Luke's "Multilevel Modelling", table 2.9
(p.30-31) but using lmer and I don't know how to extract the coeficients of
the impact of variables in the 2nd level on betas.

Let me make it clearer by describing the situation. In the model number 3
in that table, the author models the following equations:

VotePct = b0 + b1 Party + b2 Money + r

                 b0 = y00 + y01 Acres + u0
                 b1 = y10 + y11 Acres + u1
                 b2 = y20 + y21 Acres + u2


The results are:

#Fixed Effects

For Intercept (b0)
Intercept (y00)           .1828  (.0205)
Acres (y01)                .0027  (.0005)

For Party slope (b1)
Party (y10)                 .5066   (.0215)
Acres (y11)                .-.0016   (.0004)

For Money slope (b2)
Money (y20)               .0049   (.0005)
Acres (y21)                 -.00002   (.0000)


But lmer only gives me the main coeficients, not for instance the specific
coeficient that for Acres on each beta.

Please, any tips on how to get that kind of results will be very welcome!

Richard

PS: btw, if someone can locate the support material of that book, it would
help a lot. The link provided in the book is broken.

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Sun Feb 17 18:55:07 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 17 Feb 2013 17:55:07 +0000 (UTC)
Subject: [R-sig-ME]
	=?utf-8?q?Extracting_higher_level_coefficients_to=09re?=
	=?utf-8?q?plicate=09Douglas_Luke=27s_table?=
References: <CA+xNL7qxpC=_XPHyZwDk_K3kHCjWbrRKHd+1V_6rp4hodfKz_g@mail.gmail.com>
	<001101ce0d36$5371b900$fa552b00$@msu.edu>
Message-ID: <loom.20130217T185423-951@post.gmane.org>

Steven J. Pierce <pierces1 at ...> writes:

> 
> Richard,
> 
> Perhaps you can directly contact Douglas Luke to inquire about obtaining the
> supporting materials. Here's a link to his webpage at his university:
> http://publichealth.wustl.edu/people/scholardatabase/Pages/Luke.aspx 
> 
> Steven J. Pierce, Ph.D. 
> Associate Director 
> Center for Statistical Training & Consulting (CSTAT) 
> Michigan State University 
> E-mail: pierces1 at ... 
> Web: http://www.cstat.msu.edu 

  And maybe try coef() ?

  fixef() = fixed effects parameters only
  ranef() = random effects parameters only (zero-mean)
  coef() = combined effects


From David.Duffy at qimr.edu.au  Mon Feb 18 02:08:11 2013
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Mon, 18 Feb 2013 11:08:11 +1000
Subject: [R-sig-ME] Error message in Pedigreemm
In-Reply-To: <BAY147-W38B1E933190BC7918637B6F60C0@phx.gbl>
References: <BAY147-W38B1E933190BC7918637B6F60C0@phx.gbl>
Message-ID: <alpine.LMD.2.00.1302181051160.26507@orpheus.qimr.edu.au>

On Mon, 18 Feb 2013, Napo Vargas wrote:

> Error in function (fr, FL, start, REML, verbose)  :
>  Number of levels of a grouping factor for the random effects
> must be less than the number of observations

Whether you see this (in your case, spurious) error message depends on 
what version of lme4 you have installed.  A quick hack is

my_lmer_finalize <- edit(lme4:::lmer_finalize)

change

     if (!(length(levels(dm$flist[[1]])) < length(Y)))
         stop(paste("Number of levels of a grouping factor for the random effects",
             "must be less than the number of observations", sep = "\n"))

to

     if (!(length(levels(dm$flist[[1]])) <= length(Y)))
         stop(paste("Number of levels of a grouping factor for the random effects",
             "must be less or equal to the number of observations", sep = "\n"))

and save.  Then

my_pedigreemm <- edit(pedigreemm)

and change the fifth last line from

    else lmer_finalize, lmf)

to

    else my_lmer_finalize, lmf)

Now,

system.time(AM1 <-
my_pedigreemm(WS~WT+Sex+(1|ID),data=cdata, pedigree=list(ID=ped1)))

should work.  You could alter this check permanently when you install 
lme4 by editing the appropriate file.

BTW, with lme4, you can leave all your variables of interest in cdata 
eg cdata$Sex <- factor(cdata$Sex).


David Duffy,


From Steve.Candy at aad.gov.au  Mon Feb 18 03:29:19 2013
From: Steve.Candy at aad.gov.au (Steve Candy)
Date: Mon, 18 Feb 2013 13:29:19 +1100
Subject: [R-sig-ME] lmer residual variance estimate with prior weights
 [SEC=UNCLASSIFIED]
Message-ID: <410C0E47580EB147811BB64E83936A3F68E046ABAC@EX2K7-CCR.AAD.GOV.AU>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130218/fc09c410/attachment.pl>

From Thierry.ONKELINX at inbo.be  Mon Feb 18 10:17:38 2013
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Mon, 18 Feb 2013 09:17:38 +0000
Subject: [R-sig-ME] Fitting different error structures with lme()
In-Reply-To: <CAGMyHZRMmd4QAZTx02Z1P35hup4UmjpiXKkWyyOtSQWZJ2fK+g@mail.gmail.com>
References: <CAGMyHZRMmd4QAZTx02Z1P35hup4UmjpiXKkWyyOtSQWZJ2fK+g@mail.gmail.com>
Message-ID: <AA818EAD2576BC488B4F623941DA7427A7A6663F@inbomail.inbo.be>

Dear Cengiz,

IMHO you are overfitting the model. You have only 3 occasions per person? Note that a model with a random intercept and correlated random slope requires 3 parameters to be fit.

The first argument of corAR1() and corCompSymm() is value. It is used a starting values for the parameters. Unless use add fixed = TRUE, then it fixed at the those values. This is described in ?corAR1

You might want to look at the dataset shipped with nlme. Have a look at the examples in the helpfiles.

Best regards,

Thierry

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey


-----Oorspronkelijk bericht-----
Van: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] Namens Cengiz Zopluoglu
Verzonden: zondag 17 februari 2013 7:09
Aan: r-sig-mixed-models at r-project.org
Onderwerp: [R-sig-ME] Fitting different error structures with lme()

Hi,

I have a question about fitting a random coefficients model with different error structures in lme() function. The data I have in the long format as the following:

     id gender Occasion Strength
1.0   1   Male        0      161
1.1   1   Male        1      210
1.2   1   Male        2      230
2.0   2   Male        0      215
2.1   2   Male        1      245
2.2   2   Male        2      265
3.0   3   Male        0      134
3.1   3   Male        1      215
................................................................
................................................................

When I fit the following model by imposing a compound symmetry structure on the error var-cov matrix:

fit <- lme(Strength ~ 1 + Occasion,
           random = ~ 1 + Occasion | id,
           data = grip.L,
           correlation=corCompSymm(),
           control=list(maxIter=1000,msMaxIter=1000, niterEM=1000)
           )

Linear mixed-effects model fit by REML
  Data: grip.L
  Log-restricted-likelihood: -873.9892
  Fixed: Strength ~ 1 + Occasion
(Intercept)    Occasion
144.8304598  -0.6637931

Random effects:
 Formula: ~1 + Occasion | id
 Structure: General positive-definite, Log-Cholesky parametrization
            StdDev   Corr
(Intercept) 72.69465 (Intr)
Occasion    16.14353 -0.366
Residual    16.45378

Correlation Structure: Compound symmetry
 Formula: ~1 | id
 Parameter estimate(s):
Rho
  0
Number of Observations: 174
Number of Groups: 58

The "Rho" is estimated as zero. When I specify corCompSymm(.3), the output
is:

Linear mixed-effects model fit by REML
  Data: grip.L
  Log-restricted-likelihood: -873.9892
  Fixed: Strength ~ 1 + Occasion
(Intercept)    Occasion
144.8304598  -0.6637931

Random effects:
 Formula: ~1 + Occasion | id
 Structure: General positive-definite, Log-Cholesky parametrization
            StdDev   Corr
(Intercept) 72.02091 (Intr)
Occasion    16.14343 -0.369
Residual    19.18853

Correlation Structure: Compound symmetry
 Formula: ~1 | id
 Parameter estimate(s):
      Rho
0.2647256
Number of Observations: 174
Number of Groups: 58

The rho is estimated .264. In this case, I am wondering what really .3 within
corCompSymm(.3) represents. Or, when I say corCompSymm(.3) , what does it me an?

Also, when I specify corAR1(), I am getting an error message about convergence.

fit <- lme(Strength ~ 1 + Occasion,
           random = ~ 1 + Occasion | id,
           data = grip.L,
           correlation=corAR1(),
           control=list(maxIter=1000,msMaxIter=1000, niterEM=1000)
           )

Error in lme.formula(Strength ~ 1 + Occasion, random = ~1 + Occasion |  :
  nlminb problem, convergence error code = 1
  message = singular convergence (7)

After a trial-error process, I was able to fit the model by specifying
corAR1(.05):

Linear mixed-effects model fit by REML
 Data: grip.L
       AIC      BIC    logLik
  1761.052 1783.084 -873.5258

Random effects:
 Formula: ~1 + Occasion | id
 Structure: General positive-definite, Log-Cholesky parametrization
            StdDev    Corr
(Intercept) 39.491786 (Intr)
Occasion     5.554041 -0.999
Residual    62.765655

Correlation Structure: AR(1)
 Formula: ~1 | id
 Parameter estimate(s):
      Phi
0.9021773
Fixed effects: Strength ~ 1 + Occasion
                Value Std.Error  DF   t-value p-value
(Intercept) 143.52300  9.736396 115 14.740875  0.0000
Occasion     -0.66379  2.617492 115 -0.253599  0.8003
 Correlation:
         (Intr)
Occasion -0.396

Standardized Within-Group Residuals:
       Min         Q1        Med         Q3        Max
-1.4632691 -0.6942647 -0.1709512  0.4677042  2.0371593

Number of Observations: 174
Number of Groups: 58

Here, the estimated Phi is .9021. I have the same question again. What (.05)represents within corAR1(.05)? How is it related to the estimated phi .9021? Should I always do a trial-error process to figure out what value I should put in paranthesis to be able fit a model?

I also tried other error structures for the same dataset, but none of them converged. I used a different larger dataset, but I always get convergence error when I try to fit different error structures. Any suggestions?

This is for didactic purposes. We would like to teach students how to fit different error structures for mixed effects models using lme() function, and I can't get it worked until now for none of the datasets I have.

Thanks in advance.

--

Cengiz Zopluoglu

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.


From jwmichel at loyola.edu  Mon Feb 18 17:13:07 2013
From: jwmichel at loyola.edu (John Michel)
Date: Mon, 18 Feb 2013 16:13:07 +0000
Subject: [R-sig-ME] LME Question
Message-ID: <3E57D1D301AC8C4BAC8DC4363C4BE1DA05737F2D@EX2010NODE1.ad.loyola.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130218/ad11599a/attachment.pl>

From Hugo.Mildenberger at web.de  Mon Feb 18 18:26:14 2013
From: Hugo.Mildenberger at web.de (Hugo.Mildenberger at web.de)
Date: Mon, 18 Feb 2013 18:26:14 +0100
Subject: [R-sig-ME] LME Question
In-Reply-To: <3E57D1D301AC8C4BAC8DC4363C4BE1DA05737F2D@EX2010NODE1.ad.loyola.edu>
References: <3E57D1D301AC8C4BAC8DC4363C4BE1DA05737F2D@EX2010NODE1.ad.loyola.edu>
Message-ID: <20130218182614.ba783b7fbd323f926b1f2cd1@zotac.lan>


On Mon, 18 Feb 2013 16:13:07 +0000 John Michel <jwmichel at loyola.edu> wrote:
> I am trying to run a linear mixed effects model on some data I have. My participants are nested within 27 organizations so I have to control for this group. I have  three dependent variables (sales, tips, and employee performance) when I attempt to calculate the null model for these three DVs I get the following error message below:
 
> > Null.SALES<-lme(SALES~1,random=~1|GROUP,data=tccbtips)
> Error in `rownames<-`(`*tmp*`, value = rownames(Fitted) <- origOrder) :
>   attempt to set rownames on object with no dimensions
> In addition: Warning message:
> In Ops.factor(y[revOrder], Fitted) : - not meaningful for factors

Is SALES possibly also a factor?


From h.morgan at har.mrc.ac.uk  Mon Feb 18 20:35:15 2013
From: h.morgan at har.mrc.ac.uk (Hugh Morgan)
Date: Mon, 18 Feb 2013 19:35:15 +0000
Subject: [R-sig-ME] Predicted density function from mixed model?
Message-ID: <42B19B067F9EA04E97360886E6276913057ADA@PEGASUS.mrch.har.mrc.ac.uk>

Dear All,

I want to plot the predicted probability density function derived from a model fitted with lme or gls next to the actual density function. I hope to be able to use this to present to the user, having the double function of helping to explain what statistics I am performing and some estimation of the model fit. I can get the actual density distribution (using the function density(x, ...)) but is there an easy way of getting the one predicted by the model? I expect I could derive it in code, by feeding the actual numbers for the various parameters used in the model, but I am hoping someone has done it for me.


For an example, using the attached csv file:


library(nlme)

# Note, 8.5k test file, I have also tried attaching it
testDataset <- read.csv("http://sanger_impc.drivehq.com/exampleDataset.csv")

model <- lme(Weight~Genotype+Gender+Genotype*Gender, random=~1|Batch, testDataset, na.action="na.omit", method="ML")


I get the density distribution with:


testDensity <- density(testDataset$Weight)


And then plot it


plot(testDensity)


and add the predicted density:


# Does not work

plot(density(model))


In the end of the day I would like to split the plots into control and test group, like :


plot(density(subset(testDataset, Genotype=="mutant")$Weight))

plot(density(subset(testDataset, Genotype=="control")$Weight))


I really appreciate any help, and I will understand if the answer is I have to write it myself.


Thanks in advance,


Hugh



This email may have a PROTECTIVE MARKING, for an explanation please see: http://www.mrc.ac.uk/About/Informationandstandards/Documentmarking/index.htm


This email may have a PROTECTIVE MARKING, for an explanation please see:
http://www.mrc.ac.uk/About/Informationandstandards/Documentmarking/index.htm



From bbolker at gmail.com  Tue Feb 19 03:52:45 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 19 Feb 2013 02:52:45 +0000 (UTC)
Subject: [R-sig-ME] lmer residual variance estimate with prior weights
	[SEC=UNCLASSIFIED]
References: <410C0E47580EB147811BB64E83936A3F68E046ABAC@EX2K7-CCR.AAD.GOV.AU>
Message-ID: <loom.20130219T035106-107@post.gmane.org>

Steve Candy <Steve.Candy at ...> writes:

> 
> Hi mixed-modellers
 
> I am fitting a simple linear mixed model to some abundance data
> which are mean densities on the log10 scale for a set of spatial
> cells with sample sizes used as prior weights. I define a random
> cell intercept model and fit a linear year trend. I get very similar
> estimates of the intercept and slope when using each of lmer(.) and
> asreml(.) but get much smaller estimates of the SEs of these
> parameters for lmer(.). This is due to a much smaller estimate of
> the residual standard error with estimate of 0.534 for lmer and
> 3.016 for asreml with corresponding estimates of the cell-level
> standard deviation of 0.0014 for lmer and 0.2151 (=0.04626^0.5) for
> asreml. Comparing these to a simple lm(.) fit gives a similar but
> slightly higher estimate of the residual standard error compared to
> the asreml estimate with the a value of 3.116. The lmer estimate
> appears to be orders of magnitude out. Am I interpreting these
> results correctly? Has it something to do with how the weighting is
> done!

[context snipped because gmane hates me]

I have a sneaking suspicion that lmer doesn't scale the sum of
the weights to 1 before doing calculations, as it arguably should.
What happens if you manually scale the weights to 1 (which seems
appropriate in this case)?

  Ben Bolker


From napo_v at hotmail.com  Tue Feb 19 06:22:29 2013
From: napo_v at hotmail.com (Napo Vargas)
Date: Tue, 19 Feb 2013 05:22:29 +0000
Subject: [R-sig-ME] Error message in Pedigreemm
In-Reply-To: <alpine.LMD.2.00.1302181051160.26507@orpheus.qimr.edu.au>
References: <BAY147-W38B1E933190BC7918637B6F60C0@phx.gbl>,
	<alpine.LMD.2.00.1302181051160.26507@orpheus.qimr.edu.au>
Message-ID: <BAY147-W469A6A784B28EFFCE3C71BF6F50@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130219/bd86e6c8/attachment.pl>

From aghaynes at gmail.com  Tue Feb 19 08:27:03 2013
From: aghaynes at gmail.com (Alan Haynes)
Date: Tue, 19 Feb 2013 08:27:03 +0100
Subject: [R-sig-ME] Predicted density function from mixed model?
In-Reply-To: <42B19B067F9EA04E97360886E6276913057ADA@PEGASUS.mrch.har.mrc.ac.uk>
References: <42B19B067F9EA04E97360886E6276913057ADA@PEGASUS.mrch.har.mrc.ac.uk>
Message-ID: <CAPdSD+6xG5tLYHKAygDNQVxmuH7JS_Rs9mzprGdF+abnWmD=5g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130219/d2236300/attachment.pl>

From h.morgan at har.mrc.ac.uk  Tue Feb 19 09:38:00 2013
From: h.morgan at har.mrc.ac.uk (Hugh Morgan)
Date: Tue, 19 Feb 2013 08:38:00 +0000
Subject: [R-sig-ME] Predicted density function from mixed model?
In-Reply-To: <CAPdSD+6xG5tLYHKAygDNQVxmuH7JS_Rs9mzprGdF+abnWmD=5g@mail.gmail.com>
References: <42B19B067F9EA04E97360886E6276913057ADA@PEGASUS.mrch.har.mrc.ac.uk>,
	<CAPdSD+6xG5tLYHKAygDNQVxmuH7JS_Rs9mzprGdF+abnWmD=5g@mail.gmail.com>
Message-ID: <42B19B067F9EA04E97360886E6276913057BB0@PEGASUS.mrch.har.mrc.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130219/65b6ac6e/attachment.pl>

From aghaynes at gmail.com  Tue Feb 19 10:39:38 2013
From: aghaynes at gmail.com (Alan Haynes)
Date: Tue, 19 Feb 2013 10:39:38 +0100
Subject: [R-sig-ME] Fwd:  Predicted density function from mixed model?
In-Reply-To: <CAPdSD+6FC0xx1H-SF9GTz85yE-NUK4vSJmpNmdwdTGhe2907Gg@mail.gmail.com>
References: <42B19B067F9EA04E97360886E6276913057ADA@PEGASUS.mrch.har.mrc.ac.uk>
	<CAPdSD+6xG5tLYHKAygDNQVxmuH7JS_Rs9mzprGdF+abnWmD=5g@mail.gmail.com>
	<42B19B067F9EA04E97360886E6276913057BB0@PEGASUS.mrch.har.mrc.ac.uk>
	<CAPdSD+6FC0xx1H-SF9GTz85yE-NUK4vSJmpNmdwdTGhe2907Gg@mail.gmail.com>
Message-ID: <CAPdSD+5Tika03i78vQcU1noJGE0r+UNefcAhp=+2GVV2mquXmA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130219/3ba4b209/attachment.pl>

From h.morgan at har.mrc.ac.uk  Tue Feb 19 15:12:48 2013
From: h.morgan at har.mrc.ac.uk (Hugh Morgan)
Date: Tue, 19 Feb 2013 14:12:48 +0000
Subject: [R-sig-ME] Fwd:  Predicted density function from mixed model?
In-Reply-To: <CAPdSD+5Tika03i78vQcU1noJGE0r+UNefcAhp=+2GVV2mquXmA@mail.gmail.com>
References: <42B19B067F9EA04E97360886E6276913057ADA@PEGASUS.mrch.har.mrc.ac.uk>
	<CAPdSD+6xG5tLYHKAygDNQVxmuH7JS_Rs9mzprGdF+abnWmD=5g@mail.gmail.com>
	<42B19B067F9EA04E97360886E6276913057BB0@PEGASUS.mrch.har.mrc.ac.uk>
	<CAPdSD+6FC0xx1H-SF9GTz85yE-NUK4vSJmpNmdwdTGhe2907Gg@mail.gmail.com>,
	<CAPdSD+5Tika03i78vQcU1noJGE0r+UNefcAhp=+2GVV2mquXmA@mail.gmail.com>
Message-ID: <42B19B067F9EA04E97360886E62769130583E8@PEGASUS.mrch.har.mrc.ac.uk>

Thanks for this, but predict(model, newdata=nd, level=1) seems to be exactly the same as predict(model, newdata=nd, level=0).  predict(model, newdata=nd, level=0:1) (from ?predict.lme) just adds more columns (1 replicating the batch column, 2 with the same values you get with either level=0 or level=1.

Hugh

________________________________________
From: r-sig-mixed-models-bounces at r-project.org [r-sig-mixed-models-bounces at r-project.org] on behalf of Alan Haynes [aghaynes at gmail.com]
Sent: Tuesday, February 19, 2013 9:39 AM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] Fwd:  Predicted density function from mixed model?

And to the list...

Hi Hugh,

If you want the individual level predictions then you could include the
individual (Batch) in the nd dataframe and use

predict(model, newdata=nd, level=1)

that might be more meaningful than using rnorm. If i remember correctly,
you can get SE estimates for the values too...see ?predict.lme

HTH

Alan

--------------------------------------------------
Email: aghaynes at gmail.com
Mobile: +41763389128
Skype: aghaynes


On 19 February 2013 09:38, Hugh Morgan <h.morgan at har.mrc.ac.uk> wrote:

>  Hi Alan,
>
> Thank you very much for this.  The pred function is what I was looking
> for.  I THINK what I actually want I can get with:
>
> > summary(model)
> Linear mixed-effects model fit by maximum likelihood
> ...
> Random effects:
>  Formula: ~1 | Batch
>         (Intercept)  Residual
> StdDev:  0.09476296 0.1319891
>
> Fixed effects: Weight ~ Genotype + Gender + Genotype * Gender
>                               Value  Std.Error  DF   t-value p-value
> (Intercept)               0.5628385 0.02804277 159 20.070716  0.0000
> ...
>
> Taking:
> Random effects StdDev:  0.09476296
> Fixed effects Intercept Std.Error: 0.02804277
>
> I can then randomly generate these effects:
>
> nd$batchEffect <- rnorm(nrow(nd), mean = 0, sd = 0.09476296)
> nd$randomEffect <- rnorm(nrow(nd), mean = 0, sd = 0.02804277)
>
> And add them to the single values generated by pred:
>
> nd$predicedDistribution <- (nd$pred + nd$batchEffect + nd$randomEffect)
>
> Plotting these gives something like the real distribution, so it is
> possible I am right:
>
> plot(density(subset(nd, Genotype=="mutant")$predicedDistribution))
> plot(density(subset(nd, Genotype=="control")$predicedDistribution))
>
>
>  Incidentally, for your model, Weight ~ Genotype + Gender + Genotype*Gender is identical to Weight ~ Genotype*Gender because the * includes both main effects and interaction. If you want to specify just an interaction use : (e.g. Genotype:Gender)
>
>
> Thank you for this.  As is obvious I am just learning this.
>
> Hugh
>
>  ------------------------------
> *From:* Alan Haynes [aghaynes at gmail.com]
> *Sent:* Tuesday, February 19, 2013 7:27 AM
> *To:* Hugh Morgan
> *Cc:* r-sig-mixed-models at r-project.org
> *Subject:* Re: [R-sig-ME] Predicted density function from mixed model?
>
>   Hi Hugh,
>
>  I *think* this is probably what youre referring to:
>
>  # set up a new data frame with
> nd <- data.frame(Genotype=testDataset$Genotype, Gender=testDataset$Gender)
>  # predict new values omitting the random effect (pop. level)
>  nd$pred <- predict(model, newdata=nd, level=0)
>
> plot(density(subset(nd, Genotype=="mutant")$pred))
> plot(density(subset(nd, Genotype=="control")$pred))
>
>  However it doesn't mean much because the predicted values only take one
> of 4 numbers depending on male/female/ & control/mutant:
>
> unique(nd$pred)
> #0.6441061 0.5628385 0.6422222 0.7777778
>
>
> plot(density(subset(nd, Genotype=="mutant")$pred))
>
>
> stripchart(subset(nd, Genotype=="mutant")$pred, method="jitter", add=TRUE)
>
>
> plot(density(subset(nd, Genotype=="control")$pred))
>
>
> stripchart(subset(nd, Genotype=="control")$pred, method="jitter", add=TRUE)
>
>
> Did you perhaps mean the residuals? These are accessed via the residuals(model) command which you can then run density on.
>
>
>
>
>
>
>
>
>
> Incidentally, for your model, Weight ~ Genotype + Gender + Genotype*Gender is identical to Weight ~ Genotype*Gender because the * includes both main effects and interaction. If you want to specify just an interaction use : (e.g. Genotype:Gender)
>
>
>
>
>
>
>
>
>
>
> HTH
>
> Alan
>
>
>  --------------------------------------------------
> Email: aghaynes at gmail.com
> Mobile: +41763389128
> Skype: aghaynes
>
>
> On 18 February 2013 20:35, Hugh Morgan <h.morgan at har.mrc.ac.uk> wrote:
>
>> Dear All,
>>
>> I want to plot the predicted probability density function derived from a
>> model fitted with lme or gls next to the actual density function. I hope to
>> be able to use this to present to the user, having the double function of
>> helping to explain what statistics I am performing and some estimation of
>> the model fit. I can get the actual density distribution (using the
>> function density(x, ...)) but is there an easy way of getting the one
>> predicted by the model? I expect I could derive it in code, by feeding the
>> actual numbers for the various parameters used in the model, but I am
>> hoping someone has done it for me.
>>
>>
>> For an example, using the attached csv file:
>>
>>
>> library(nlme)
>>
>> # Note, 8.5k test file, I have also tried attaching it
>> testDataset <- read.csv("
>> http://sanger_impc.drivehq.com/exampleDataset.csv")
>>
>> model <- lme(Weight~Genotype+Gender+Genotype*Gender, random=~1|Batch,
>> testDataset, na.action="na.omit", method="ML")
>>
>>
>> I get the density distribution with:
>>
>>
>> testDensity <- density(testDataset$Weight)
>>
>>
>> And then plot it
>>
>>
>> plot(testDensity)
>>
>>
>> and add the predicted density:
>>
>>
>> # Does not work
>>
>> plot(density(model))
>>
>>
>> In the end of the day I would like to split the plots into control and
>> test group, like :
>>
>>
>> plot(density(subset(testDataset, Genotype=="mutant")$Weight))
>>
>> plot(density(subset(testDataset, Genotype=="control")$Weight))
>>
>>
>> I really appreciate any help, and I will understand if the answer is I
>> have to write it myself.
>>
>>
>> Thanks in advance,
>>
>>
>> Hugh
>>
>>
>>
>> This email may have a PROTECTIVE MARKING, for an explanation please see:
>> http://www.mrc.ac.uk/About/Informationandstandards/Documentmarking/index.htm
>>
>>
>> This email may have a PROTECTIVE MARKING, for an explanation please see:
>>
>> http://www.mrc.ac.uk/About/Informationandstandards/Documentmarking/index.htm
>>
>>
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>
> This email may have a PROTECTIVE MARKING, for an explanation please see: http://www.mrc.ac.uk/About/Informationandstandards/Documentmarking/index.htm
>
>
>
> This email may have a PROTECTIVE MARKING, for an explanation please see:
>
> http://www.mrc.ac.uk/About/Informationandstandards/Documentmarking/index.htm
>

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

This email may have a PROTECTIVE MARKING, for an explanation please see: http://www.mrc.ac.uk/About/Informationandstandards/Documentmarking/index.htm

This email may have a PROTECTIVE MARKING, for an explanation please see:
http://www.mrc.ac.uk/About/Informationandstandards/Documentmarking/index.htm


From aghaynes at gmail.com  Tue Feb 19 17:25:12 2013
From: aghaynes at gmail.com (Alan Haynes)
Date: Tue, 19 Feb 2013 17:25:12 +0100
Subject: [R-sig-ME] Fwd: Predicted density function from mixed model?
In-Reply-To: <42B19B067F9EA04E97360886E62769130583E8@PEGASUS.mrch.har.mrc.ac.uk>
References: <42B19B067F9EA04E97360886E6276913057ADA@PEGASUS.mrch.har.mrc.ac.uk>
	<CAPdSD+6xG5tLYHKAygDNQVxmuH7JS_Rs9mzprGdF+abnWmD=5g@mail.gmail.com>
	<42B19B067F9EA04E97360886E6276913057BB0@PEGASUS.mrch.har.mrc.ac.uk>
	<CAPdSD+6FC0xx1H-SF9GTz85yE-NUK4vSJmpNmdwdTGhe2907Gg@mail.gmail.com>
	<CAPdSD+5Tika03i78vQcU1noJGE0r+UNefcAhp=+2GVV2mquXmA@mail.gmail.com>
	<42B19B067F9EA04E97360886E62769130583E8@PEGASUS.mrch.har.mrc.ac.uk>
Message-ID: <CAPdSD+5cB7Bqtd5=LvsZXs+2-PwBMDuLc0Qh26R3cE33uGS3Bw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130219/67ec9c97/attachment.pl>

From h.morgan at har.mrc.ac.uk  Tue Feb 19 21:54:42 2013
From: h.morgan at har.mrc.ac.uk (Hugh Morgan)
Date: Tue, 19 Feb 2013 20:54:42 +0000
Subject: [R-sig-ME] Fwd: Predicted density function from mixed model?
In-Reply-To: <CAPdSD+5cB7Bqtd5=LvsZXs+2-PwBMDuLc0Qh26R3cE33uGS3Bw@mail.gmail.com>
References: <42B19B067F9EA04E97360886E6276913057ADA@PEGASUS.mrch.har.mrc.ac.uk>
	<CAPdSD+6xG5tLYHKAygDNQVxmuH7JS_Rs9mzprGdF+abnWmD=5g@mail.gmail.com>
	<42B19B067F9EA04E97360886E6276913057BB0@PEGASUS.mrch.har.mrc.ac.uk>
	<CAPdSD+6FC0xx1H-SF9GTz85yE-NUK4vSJmpNmdwdTGhe2907Gg@mail.gmail.com>
	<CAPdSD+5Tika03i78vQcU1noJGE0r+UNefcAhp=+2GVV2mquXmA@mail.gmail.com>
	<42B19B067F9EA04E97360886E62769130583E8@PEGASUS.mrch.har.mrc.ac.uk>,
	<CAPdSD+5cB7Bqtd5=LvsZXs+2-PwBMDuLc0Qh26R3cE33uGS3Bw@mail.gmail.com>
Message-ID: <42B19B067F9EA04E97360886E627691305856F@PEGASUS.mrch.har.mrc.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130219/811d0ff4/attachment.pl>

From psunthud at gmail.com  Tue Feb 19 22:11:33 2013
From: psunthud at gmail.com (Sunthud Pornprasertmanit)
Date: Tue, 19 Feb 2013 15:11:33 -0600
Subject: [R-sig-ME] Problem with the categorical predictor in the factor
	format at level 1
Message-ID: <CAAKAB8XBwHrXPC5HcT1q9h5AKqvboZb2=eqr_7VBHgBVyM7DjQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130219/33267cfc/attachment.pl>

From Steve.Candy at aad.gov.au  Wed Feb 20 02:29:32 2013
From: Steve.Candy at aad.gov.au (Steve Candy)
Date: Wed, 20 Feb 2013 12:29:32 +1100
Subject: [R-sig-ME] lmer residual variance estimate with prior weights
 [SEC=UNCLASSIFIED]
Message-ID: <410C0E47580EB147811BB64E83936A3F68E046AD6A@EX2K7-CCR.AAD.GOV.AU>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130220/0b57bf7f/attachment.pl>

From bbolker at gmail.com  Wed Feb 20 03:18:21 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 20 Feb 2013 02:18:21 +0000 (UTC)
Subject: [R-sig-ME]
	=?utf-8?q?Problem_with_the_categorical_predictor_in_th?=
	=?utf-8?q?e_factor=09format_at_level_1?=
References: <CAAKAB8XBwHrXPC5HcT1q9h5AKqvboZb2=eqr_7VBHgBVyM7DjQ@mail.gmail.com>
Message-ID: <loom.20130220T021208-828@post.gmane.org>

Sunthud Pornprasertmanit <psunthud at ...> writes:

> 
> Dear all,
> 
> I have run a model with fixed intercepts but random slopes on categorical
> predictors by the following command:
> 
> FixedIntRandomSlope <- lmer(POPULAR ~ 1 + SEX + (0 + SEX|SCHOOL), data =
> popular, REML = FALSE)
> summary(FixedIntRandomSlope)
> 
> I got the different results in the random effect when I treated SEX as
> dummy variable manually or treated SEX as factor.
> 
> Here is the result for the dummy-variable predictor:
> 
> Random effects:
>  Groups   Name Variance Std.Dev.
>  SCHOOL   SEX  0.87531  0.93558
>  Residual      0.87053  0.93302
> 
> Here is the result for the variable transformed into factor format:
> 
> Random effects:
>  Groups   Name Variance Std.Dev. Corr
>  SCHOOL   SEX0 0.93044  0.96459
>           SEX1 0.92104  0.95971  0.855
>  Residual      0.39244  0.62645
> 
> I think SEX0 and SEX1 should not be both random effects.
> 
> I have checked predictor and found that the variable really have two
> categories:
> 
> > summary(popular$SEX)
>    0    1
> 1026  974
> 
> I use lme4 version lme4_0.999999-0.
> 
> Please teach me what is going on in this case. Thank you very much.
> 

I believe this is a weakness in the way that lme4 constructs
random effects.  The problem is that it falls back on R's standard
model-matrix constructor (model.matrix()); in this case the formula
~0+SEX considered by itself gives rise to a "no-intercept" matrix,
which is *not* a one-column model matrix, but rather two columns 
each corresponding to a dummy variable for the corresponding factor level.

For example:

d <- data.frame(SEX=factor(0:1))
model.matrix(~SEX,data=d)
##   (Intercept) SEX1
## 1           1    0
## 2           1    1

model.matrix(~0+SEX,data=d)
##   SEX0 SEX1
## 1    1    0
## 2    0    1

rather than the model matrix you want, which is just

##    SEX1
## 1     0
## 2     1

The workaround is (as you have done) to create your own dummy
variable.

The other disturbing part of this is that the model with (~0+SEX|SCHOOL)
is actually unidentifiable (I think), but lmer goes ahead and fits
something for you anyway, without warning you.

This will definitely be worth posting an issue at
https://github.com/lme4/lme4/issues?state=open : if I get a
chance I will do it, but you are encouraged to do so ...


From ellen.pape at gmail.com  Wed Feb 20 08:39:28 2013
From: ellen.pape at gmail.com (Ellen Pape)
Date: Wed, 20 Feb 2013 08:39:28 +0100
Subject: [R-sig-ME] variance explained by fixed effects in mixed model
Message-ID: <CANW5OGCWZYBvpUYTVBOvTXDu1Xf+z=Bzd49_tn6=J26C+7ybrg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130220/d80fa546/attachment.pl>

From xav.harrison at gmail.com  Wed Feb 20 09:44:28 2013
From: xav.harrison at gmail.com (Xavier Harrison)
Date: Wed, 20 Feb 2013 08:44:28 +0000
Subject: [R-sig-ME] variance explained by fixed effects in mixed model
Message-ID: <66B4F20B-D4C2-442F-A46B-2E16B9AE2321@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130220/0058c778/attachment.pl>

From aghaynes at gmail.com  Wed Feb 20 10:01:23 2013
From: aghaynes at gmail.com (Alan Haynes)
Date: Wed, 20 Feb 2013 10:01:23 +0100
Subject: [R-sig-ME] variance explained by fixed effects in mixed model
In-Reply-To: <66B4F20B-D4C2-442F-A46B-2E16B9AE2321@gmail.com>
References: <66B4F20B-D4C2-442F-A46B-2E16B9AE2321@gmail.com>
Message-ID: <CAPdSD+640aVPFcGSbn+3VHQZbB7mYJwn94hMRSLWtdXWBEiBCw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130220/f8d5b3f9/attachment.pl>

From ellen.pape at gmail.com  Wed Feb 20 14:35:00 2013
From: ellen.pape at gmail.com (Ellen Pape)
Date: Wed, 20 Feb 2013 14:35:00 +0100
Subject: [R-sig-ME] variance explained by fixed effects in mixed model
In-Reply-To: <CAPdSD+640aVPFcGSbn+3VHQZbB7mYJwn94hMRSLWtdXWBEiBCw@mail.gmail.com>
References: <66B4F20B-D4C2-442F-A46B-2E16B9AE2321@gmail.com>
	<CAPdSD+640aVPFcGSbn+3VHQZbB7mYJwn94hMRSLWtdXWBEiBCw@mail.gmail.com>
Message-ID: <CANW5OGDM0mvJrfAi8wX0o_ZfTRqcX2n+swRZiheNXr8ptcpJyg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130220/6a2ef1b9/attachment.pl>

From pierces1 at msu.edu  Wed Feb 20 19:40:57 2013
From: pierces1 at msu.edu (Steven J. Pierce)
Date: Wed, 20 Feb 2013 13:40:57 -0500
Subject: [R-sig-ME] variance explained by fixed effects in mixed model
In-Reply-To: <CANW5OGCWZYBvpUYTVBOvTXDu1Xf+z=Bzd49_tn6=J26C+7ybrg@mail.gmail.com>
References: <CANW5OGCWZYBvpUYTVBOvTXDu1Xf+z=Bzd49_tn6=J26C+7ybrg@mail.gmail.com>
Message-ID: <004f01ce0f99$d2f88b80$78e9a280$@msu.edu>

Ellen,

My take on this is that the plethora of competing formulas intended to
compute some analogue of R-square for mixed models (or even more
problematically, for generalized linear mixed models) is a sign that finding
such a measure is not simple. I have informally compared the results of
using various formulas on a set of models (fitted to the same data) and
found that they don?t all agree, and sometimes some of them yield results
that seem inconsistent with other ways of examining model fit, quality, or
comparisons between models. I'm not convinced there is a consensus that
looking for such a measure that generalizes to mixed and generalized mixed
models is even the right thing to do in the first place. 

Perhaps you could tell us what you would actually use the R-square for and
see if the folks on the list can suggest better methods to accomplish the
same goal. 

Steven J. Pierce, Ph.D. 
Associate Director 
Center for Statistical Training & Consulting (CSTAT) 
Michigan State University 
E-mail: pierces1 at msu.edu 
Web: http://www.cstat.msu.edu 

-----Original Message-----
From: Ellen Pape [mailto:ellen.pape at gmail.com] 
Sent: Wednesday, February 20, 2013 2:39 AM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] variance explained by fixed effects in mixed model

Dear all,

What is the best and easiest way to calculate an R? to indicate the
variance explained by the fixed effects in a mixed model? I have read some
papers with a lot of seemingly complicated formulas, but I just want to
know how to do it in R? (because that is not always clear to me :s)

Thanks!
Ellen

	[[alternative HTML version deleted]]


From ellen.pape at gmail.com  Thu Feb 21 10:31:17 2013
From: ellen.pape at gmail.com (Ellen Pape)
Date: Thu, 21 Feb 2013 10:31:17 +0100
Subject: [R-sig-ME] variance explained by fixed effects in mixed model
In-Reply-To: <004f01ce0f99$d2f88b80$78e9a280$@msu.edu>
References: <CANW5OGCWZYBvpUYTVBOvTXDu1Xf+z=Bzd49_tn6=J26C+7ybrg@mail.gmail.com>
	<004f01ce0f99$d2f88b80$78e9a280$@msu.edu>
Message-ID: <CANW5OGCu6NR59VrdomxDk_CN7KaEM0ZvjX39o750j6DPhM0mDw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130221/2d00bcd1/attachment.pl>

From n.djallil at gmail.com  Thu Feb 21 18:04:31 2013
From: n.djallil at gmail.com (Abdeldjallil)
Date: Thu, 21 Feb 2013 18:04:31 +0100
Subject: [R-sig-ME] Different AICs values in lmer and anova
Message-ID: <0AF391EC-BEE4-48F5-80BA-DB68F62651B6@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130221/a9b8756a/attachment.pl>

From bbolker at gmail.com  Fri Feb 22 00:28:54 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 21 Feb 2013 23:28:54 +0000 (UTC)
Subject: [R-sig-ME] Different AICs values in lmer and anova
References: <0AF391EC-BEE4-48F5-80BA-DB68F62651B6@gmail.com>
Message-ID: <loom.20130222T002549-97@post.gmane.org>

Abdeldjallil <n.djallil at ...> writes:


[snip]

> I am using linear mixed model package "lmer" version 0.999999-0  (R for mac
version 2.15.2) for my data
> analysis and 
> I am facing an issue of getting different  values of (AIC, BIC and logLik) 
> in the "lmer" and "anova" summaries. The same issue can be found in the >
provided example of sleep study:

This is a FAQ and as such is listed in the glmm.wikidot FAQ:

http://glmm.wikidot.com/faq#error_anova_lmer_AIC


From aadams26 at uwo.ca  Fri Feb 22 08:18:49 2013
From: aadams26 at uwo.ca (Amanda Adams)
Date: Fri, 22 Feb 2013 02:18:49 -0500
Subject: [R-sig-ME] multiple nested random factors
Message-ID: <51271BD9.9080806@uwo.ca>

Hello!
I have been having a heck of a time figuring out how to estimate the 
proportion of variance from several random factors. I have a count data 
of the number of bat calls recorded at 3 sites, on 6 detectors, over 12 
nights. Detectors were at 2 heights.
If I understand nested factors correctly, Detectors are nested in Site 
and Night is nested in Site. Site/Detector and Site/Night are random 
factors and Height is a fixed factor.
Also, data is overdispersed so I am transforming number of calls as 
log(Calls+1).

'data.frame':   249 obs. of  11 variables:
  $ Night     : int  1 3 5 11 12 1 3 5 11 12 ...
  $ Night2    : int  1 2 3 4 5 1 2 3 4 5 ...
  $ Site      : int  1 1 1 1 1 1 1 1 1 1 ...
  $ Species   : int  1 1 1 1 1 1 1 1 1 1 ...
  $ Detector  : int  1 1 1 1 1 2 2 2 2 2 ...
  $ Height    : int  1 1 1 1 1 2 2 2 2 2 ...
  $ Calls     : int  6 444 236 12 143 5 815 712 30 142 ...
  $ f.Night   : Factor w/ 12 levels "1","2","3","4",..: 1 2 3 4 5 1 2 3 
4 5 ...
  $ f.Site    : Factor w/ 4 levels "1","2","3","4": 1 1 1 1 1 1 1 1 1 1 ...
  $ f.Detector: Factor w/ 6 levels "1","2","3","4",..: 1 1 1 1 1 2 2 2 2 
2 ...
  $ f.Height  : Factor w/ 2 levels "1","2": 1 1 1 1 1 2 2 2 2 2 ...

I then coded for the nested variables:
data$detector <- with(data, factor(f.Site:f.Detector))
data$night <- with(data, factor(f.Site:f.Night))

trans.log <- log(data$Calls+1)

model <- glmer(round(trans.log,digits=0)~ f.Height + (1|night) + 
(1|detector) +
     (1|f.Site) , data = data, family=poisson)

I am uncertain on a couple things. Are my nested variables correct? Can 
I correct for overdispersion with a transformation?

I was also wondering if there is a reference explaining why there is no 
residual variance term for the Poisson distribution. I saw the 
explanation on a forum, but was hoping there was something I could cite.

Any help or advice would be appreciated.
Thank you!
Amanda

-- 
Amanda Adams, MSc
PhD Candidate
Department of Biology
Western University
London, ON
Canada
N6A 5B7
Work (519) 661-2111 Ext: 81349


From maurice.francois at ymail.com  Fri Feb 22 14:30:19 2013
From: maurice.francois at ymail.com (Francois Maurice)
Date: Fri, 22 Feb 2013 05:30:19 -0800 (PST)
Subject: [R-sig-ME] Francois Maurice
Message-ID: <1361539819.1219.YahooMailNeo@web122305.mail.ne1.yahoo.com>

Un texte encapsul? et encod? dans un jeu de caract?res inconnu a ?t? nettoy?...
Nom : non disponible
URL : <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130222/20a74c15/attachment.pl>

From Giovanni.Mancuso at iit.it  Fri Feb 22 15:04:51 2013
From: Giovanni.Mancuso at iit.it (Giovanni Mancuso)
Date: Fri, 22 Feb 2013 14:04:51 +0000
Subject: [R-sig-ME] lmer probit fit
Message-ID: <5A9D7CD8AA3C174FB330AB0125CCEA630105B7@IITMXWGE012.iit.local>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130222/3fb639c1/attachment.pl>

From bbolker at gmail.com  Fri Feb 22 15:05:43 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 22 Feb 2013 14:05:43 +0000 (UTC)
Subject: [R-sig-ME] multiple nested random factors
References: <51271BD9.9080806@uwo.ca>
Message-ID: <loom.20130222T145036-925@post.gmane.org>

Amanda Adams <aadams26 at ...> writes:

> I have been having a heck of a time figuring out how to estimate the 
> proportion of variance from several random factors. I have a count data 
> of the number of bat calls recorded at 3 sites, on 6 detectors, over 12 
> nights. Detectors were at 2 heights.
> If I understand nested factors correctly, Detectors are nested in Site 
> and Night is nested in Site. 
> Site/Detector and Site/Night are random 
> factors and Height is a fixed factor.

  It's still not entirely clear to me from this description how
your data are structured.  You have an average of about 249/12 ~ 21
observations per night, so I'm going to assume you have 6 detectors
*at each site*.  Detector will be nested in site (because it doesn't
make any sense to analyze what happens at "detector number 1" unless
the detectors are somehow arranged so that the set of (d1:site1,
d1:site2, d1:site3, ... has something in common).  You *may* want
a night:site interaction (if you have enough data), but in principle
you also want a site factor (probably fixed, since there are only
three levels) and a night factor.  This would be

  ~ height + f.Site + (1|f.Night/f.Site) + (1|f.Site:f.Detector)

  It is quite likely that you will find some of these variance
components estimated as zero ...
  
> Also, data is overdispersed so I am transforming number of calls as 
> log(Calls+1).

  This makes no sense (sorry).  Poisson models must have a response
variable that is a raw count value (integer).  How do you know the
data are overdispersed before you fit a model ???  (Although I do see
that you have widely varying values in your 'Calls' variable, so
you may be right ...)

  For various ways of handling overdispersion in GLMMs see
http://glmm.wikidot.com/faq

  I don't know if it's helpful, but Bolker et al. 2009 _Trends
in Ecology and Evolution_ might be a citeable source for GLMMs.
It doesn't really say anything specific about Poisson variables
and why a Poisson model doesn't include a residual variance; for
that you should probably cite (after reading!) a basic book
on generalized linear models.

> 'data.frame':   249 obs. of  11 variables:
>   $ Night     : int  1 3 5 11 12 1 3 5 11 12 ...
>   $ Night2    : int  1 2 3 4 5 1 2 3 4 5 ...
>   $ Site      : int  1 1 1 1 1 1 1 1 1 1 ...
>   $ Species   : int  1 1 1 1 1 1 1 1 1 1 ...
>   $ Detector  : int  1 1 1 1 1 2 2 2 2 2 ...
>   $ Height    : int  1 1 1 1 1 2 2 2 2 2 ...
>   $ Calls     : int  6 444 236 12 143 5 815 712 30 142 ...
>   $ f.Night   : Factor w/ 12 levels "1","2","3","4",..: 1 2 3 4 5 1 2 3 
> 4 5 ...
>   $ f.Site    : Factor w/ 4 levels "1","2","3","4": 1 1 1 1 1 1 1 1 1 1 ...
>   $ f.Detector: Factor w/ 6 levels "1","2","3","4",..: 1 1 1 1 1 2 2 2 2 
> 2 ...
>   $ f.Height  : Factor w/ 2 levels "1","2": 1 1 1 1 1 2 2 2 2 2 ...

  By the way, you said you have three sites, but the data have four
levels for f.Site?  Did you drop one site from the data and not
use droplevels() ?


> 
> I then coded for the nested variables:
> data$detector <- with(data, factor(f.Site:f.Detector))
> data$night <- with(data, factor(f.Site:f.Night))
> 
> trans.log <- log(data$Calls+1)
> 
> model <- glmer(round(trans.log,digits=0)~ f.Height + (1|night) + 
> (1|detector) +
>      (1|f.Site) , data = data, family=poisson)
> 
> I am uncertain on a couple things. Are my nested variables correct? Can 
> I correct for overdispersion with a transformation?
> 
> I was also wondering if there is a reference explaining why there is no 
> residual variance term for the Poisson distribution. I saw the 
> explanation on a forum, but was hoping there was something I could cite.
> 
> Any help or advice would be appreciated.
> Thank you!
> Amanda


From ken.knoblauch at inserm.fr  Fri Feb 22 17:00:04 2013
From: ken.knoblauch at inserm.fr (Ken Knoblauch)
Date: Fri, 22 Feb 2013 16:00:04 +0000 (UTC)
Subject: [R-sig-ME] lmer probit fit
References: <5A9D7CD8AA3C174FB330AB0125CCEA630105B7@IITMXWGE012.iit.local>
Message-ID: <loom.20130222T165621-657@post.gmane.org>

> I have a question concerning lme4 library and 
probit function fitting:
> 
> Would it be possible to write custom-defined sigmoid 
link functions to use in combination with lmer?
> Specifically, is it possbile to
> write a sigmoid function (probit, for instance) that has 
2 more parameters that control the lower and the
> upper asymptote?
> 
> Attached below is an example that generates a 
synthetic dataset and approaches the problem from the glm
> standpoint. I wonder whether
> it is possible to do the same thing within the 
framework of lmer.
> 
> The question refers to the fact that in cognitive 
sciences we are often interest in modeling binary
> outcomes (for instance: YES/NO in
> a computerized task); however, in many experimental 
designs, the observer's response at chance will not
> asymptote at 0. Similarly
> the maximal performance is occasionally contaminated 
by errors (will not asymptote at 1). Therefore, it
> is necessary to model the
> asymptotes along with the other parameters.
> 
> Thank you very much
> best ragards
> Giovanni Mancuso
> 
> # The function 'psyfun.2asym', wrote by Dr Kenneth Knoblauch, 
estimates a best ?t to the data by
> alternating between calls to 'glm' for current best estimates 
of arguments to the link function and calls
> to optim to
> # estimate the values of the lower and upper asymptote.
> # 'psyfun.2asym' takes as a link function a user defined 
probit function with 4 free parameters (center and
> scale, and the upper and lower asymptote)
> 
> 	[[alternative HTML version deleted]]
> 
> 

Hi Giovanni,

 I would add that IMHO
the psyfun.2asym function is a bit of a kludge.  At some point,
I have a project to clean it up and have it estimate all parameters
by directly maximizing the likelihood.  I wrote psyfun.2asym in
order to take advantage of the fitting by glm and in order to
be able to take advantage with little extra programming of
using formula objects.  My goal, when I have more time,
is to write a more robust version that allows a lot more
flexibility in modeling the different parameters, a bit along
the lines of some of things that we did in the Yssaad & Knoblauch paper,
if you have seen that, but without resorting to Lindsey's packages.

( http://www.sbri.fr/files/publications/yssad%2006%20instrcomp.pdf )

THat doesn't answer your questions about lme4 and link functions.
As I said, I think that custom links will work (they used to) in
the development version, which means that they will at some future
time when the development version becomes the real one.  
I'm, of course, interested to know where the developers are
with that, though I understand perfectly that these things
do take time.  I don't think that you will be able to use glmer 
to estimate the asymptote parameters,
however, as these are outside the linear predictor.

best,

Ken

-- 
Kenneth Knoblauch
Inserm U846
Stem-cell and Brain Research Institute
Department of Integrative Neurosciences
18 avenue du Doyen L?pine
69500 Bron
France
tel: +33 (0)4 72 91 34 77
fax: +33 (0)4 72 91 34 61
portable: +33 (0)6 84 10 64 10
http://www.sbri.fr/members/kenneth-knoblauch.html


From aadams26 at uwo.ca  Fri Feb 22 18:23:24 2013
From: aadams26 at uwo.ca (Amanda Adams)
Date: Fri, 22 Feb 2013 12:23:24 -0500
Subject: [R-sig-ME] multiple nested random factors
In-Reply-To: <loom.20130222T145036-925@post.gmane.org>
References: <51271BD9.9080806@uwo.ca> <loom.20130222T145036-925@post.gmane.org>
Message-ID: <5127A98C.8050408@uwo.ca>

Thank you for the response Dr. Bolker.

On 22/02/2013 9:05 AM, Ben Bolker wrote:
> Amanda Adams <aadams26 at ...> writes:
>
>> I have been having a heck of a time figuring out how to estimate the
>> proportion of variance from several random factors. I have a count data
>> of the number of bat calls recorded at 3 sites, on 6 detectors, over 12
>> nights. Detectors were at 2 heights.
>> If I understand nested factors correctly, Detectors are nested in Site
>> and Night is nested in Site.
>> Site/Detector and Site/Night are random
>> factors and Height is a fixed factor.
>    It's still not entirely clear to me from this description how
> your data are structured.  You have an average of about 249/12 ~ 21
> observations per night, so I'm going to assume you have 6 detectors
> *at each site*.  Detector will be nested in site (because it doesn't
> make any sense to analyze what happens at "detector number 1" unless
> the detectors are somehow arranged so that the set of (d1:site1,
> d1:site2, d1:site3, ... has something in common).  You *may* want
> a night:site interaction (if you have enough data), but in principle
> you also want a site factor (probably fixed, since there are only
> three levels) and a night factor.  This would be
>
>    ~ height + f.Site + (1|f.Night/f.Site) + (1|f.Site:f.Detector)
>
>    It is quite likely that you will find some of these variance
> components estimated as zero ...
>    
Yes, I have 6 detectors at each site.
>
>> Also, data is overdispersed so I am transforming number of calls as
>> log(Calls+1).
>    This makes no sense (sorry).  Poisson models must have a response
> variable that is a raw count value (integer).  How do you know the
> data are overdispersed before you fit a model ???  (Although I do see
> that you have widely varying values in your 'Calls' variable, so
> you may be right ...)
>
>    For various ways of handling overdispersion in GLMMs see
> http://glmm.wikidot.com/faq
I had tested for overdispersion with qcc.overdispersion.test in qcc 
package.  I had tried using an individual-level random effect to capture 
overdispersion, but was not sure how to interpret the data once that was 
included.
>    I don't know if it's helpful, but Bolker et al. 2009 _Trends
> in Ecology and Evolution_ might be a citeable source for GLMMs.
> It doesn't really say anything specific about Poisson variables
> and why a Poisson model doesn't include a residual variance; for
> that you should probably cite (after reading!) a basic book
> on generalized linear models.
This paper has been very helpful and was the reason I was initially 
using glmer. Thanks! I will do some more reading.
>
>> 'data.frame':   249 obs. of  11 variables:
>>    $ Night     : int  1 3 5 11 12 1 3 5 11 12 ...
>>    $ Night2    : int  1 2 3 4 5 1 2 3 4 5 ...
>>    $ Site      : int  1 1 1 1 1 1 1 1 1 1 ...
>>    $ Species   : int  1 1 1 1 1 1 1 1 1 1 ...
>>    $ Detector  : int  1 1 1 1 1 2 2 2 2 2 ...
>>    $ Height    : int  1 1 1 1 1 2 2 2 2 2 ...
>>    $ Calls     : int  6 444 236 12 143 5 815 712 30 142 ...
>>    $ f.Night   : Factor w/ 12 levels "1","2","3","4",..: 1 2 3 4 5 1 2 3
>> 4 5 ...
>>    $ f.Site    : Factor w/ 4 levels "1","2","3","4": 1 1 1 1 1 1 1 1 1 1 ...
>>    $ f.Detector: Factor w/ 6 levels "1","2","3","4",..: 1 1 1 1 1 2 2 2 2
>> 2 ...
>>    $ f.Height  : Factor w/ 2 levels "1","2": 1 1 1 1 1 2 2 2 2 2 ...
>    By the way, you said you have three sites, but the data have four
> levels for f.Site?  Did you drop one site from the data and not
> use droplevels() ?
I do have four sites, but only include three for some of my analysis. Sorry.
>
>> I then coded for the nested variables:
>> data$detector <- with(data, factor(f.Site:f.Detector))
>> data$night <- with(data, factor(f.Site:f.Night))
>>
>> trans.log <- log(data$Calls+1)
>>
>> model <- glmer(round(trans.log,digits=0)~ f.Height + (1|night) +
>> (1|detector) +
>>       (1|f.Site) , data = data, family=poisson)
>>
>> I am uncertain on a couple things. Are my nested variables correct? Can
>> I correct for overdispersion with a transformation?
>>
>> I was also wondering if there is a reference explaining why there is no
>> residual variance term for the Poisson distribution. I saw the
>> explanation on a forum, but was hoping there was something I could cite.
>>
>> Any help or advice would be appreciated.
>> Thank you!
>> Amanda
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
I applied the individual-level random effect, but how do I interpret the 
proportion of variation from each factor once it is included?

 > model <- glmer(Calls ~ f.Height + f.Site + (1|f.Site/f.Night) +
+ (1|f.Site:f.Detector), data = data, family=poisson)
 >
 > data$ID <- 1:nrow(data)
 > model1 <- glmer(Calls ~ f.Height + f.Site + (1|f.Night/f.Site) + 
(1|f.Site:f.Detector)
+ + (1|ID), data = data, family = poisson)
Number of levels of a grouping factor for the random effects
is *equal* to n, the number of observations
 >
 > anova(model, model1)
Data: data
Models:
model: Calls ~ f.Height + f.Site + (1 | f.Site/f.Night) + (1 | 
f.Site:f.Detector)
model1: Calls ~ f.Height + f.Site + (1 | f.Night/f.Site) + (1 | 
f.Site:f.Detector) +
model1:     (1 | ID)
        Df   AIC   BIC   logLik Chisq Chi Df Pr(>Chisq)
model   8 49163 49191 -24573.4
model1  9  1615  1647   -798.6 47550      1  < 2.2e-16 ***

 > model1
Generalized linear mixed model fit by the Laplace approximation
Formula: Calls ~ f.Height + f.Site + (1 | f.Night/f.Site) + 
(1|f.Site:f.Detector) + (1 | ID)
    Data: data
   AIC  BIC logLik deviance
  1615 1647 -798.6     1597
Random effects:
  Groups            Name        Variance Std.Dev.
  ID                (Intercept) 1.07827  1.03840
  f.Site:f.Night    (Intercept) 1.90958  1.38187
  f.Site:f.Detector (Intercept) 2.32948  1.52626
  f.Night           (Intercept) 0.65313  0.80817
Number of obs: 249, groups: ID, 249; f.Site:f.Night, 47; 
f.Site:f.Detector, 24; f.Night, 12

Fixed effects:
             Estimate Std. Error z value Pr(>|z|)
(Intercept)  2.59535    0.86051   3.016 0.002561 **
f.Height2   -0.05362    0.64015  -0.084 0.933245
f.Site2      1.01975    1.07455   0.949 0.342619
f.Site3      0.73546    1.08115   0.680 0.496343
f.Site4      4.15381    1.07196   3.875 0.000107 ***

Does this mean: Site has a significant effect on bat activity and
44% of the variation in bat activity levels can be explained by detector 
placement within sites
36% by an interaction between Site and Night
12% by temporal effects (night)
20% by individual variation
Does the individual variation essentially mean the variation from not 
explained by temporal and spatial effects?


From jdsalerno at ucdavis.edu  Fri Feb 22 22:05:51 2013
From: jdsalerno at ucdavis.edu (Jonathan Salerno)
Date: Fri, 22 Feb 2013 13:05:51 -0800
Subject: [R-sig-ME] Varying intercepts vs. varying slopes in MCMCglmm
	ordinal models
Message-ID: <CAAVN0J_mHrFH3CZo4JYAJxx0d2=j5TsXbn6EW9CU5HcsvPMt1A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130222/07d8c9c9/attachment.pl>

From bbolker at gmail.com  Fri Feb 22 23:37:43 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 22 Feb 2013 22:37:43 +0000 (UTC)
Subject: [R-sig-ME] lmer probit fit
References: <5A9D7CD8AA3C174FB330AB0125CCEA630105B7@IITMXWGE012.iit.local>
	<loom.20130222T165621-657@post.gmane.org>
Message-ID: <loom.20130222T233417-297@post.gmane.org>

Ken Knoblauch <ken.knoblauch at ...> writes:

> 
  [snip snip]

> Hi Giovanni,
> 
>  I would add that IMHO
> the psyfun.2asym function is a bit of a kludge.  At some point,
> I have a project to clean it up and have it estimate all parameters
> by directly maximizing the likelihood.  I wrote psyfun.2asym in
> order to take advantage of the fitting by glm and in order to
> be able to take advantage with little extra programming of
> using formula objects.  My goal, when I have more time,
> is to write a more robust version that allows a lot more
> flexibility in modeling the different parameters, a bit along
> the lines of some of things that we did in the Yssaad & Knoblauch paper,
> if you have seen that, but without resorting to Lindsey's packages.
> 
> ( http://www.sbri.fr/files/publications/yssad%2006%20instrcomp.pdf )
> 
> THat doesn't answer your questions about lme4 and link functions.
> As I said, I think that custom links will work (they used to) in
> the development version, which means that they will at some future
> time when the development version becomes the real one.  
> I'm, of course, interested to know where the developers are
> with that, though I understand perfectly that these things
> do take time.  I don't think that you will be able to use glmer 
> to estimate the asymptote parameters,
> however, as these are outside the linear predictor.

 As I answered off-list, the development version does still allow
custom link functions (and should continue to).  I have an example
posted at http://rpubs.com/bbolker/4082 that uses a custom link function
to fit a model with a link function of the form

?=(plogis(?)^e,

where e is an exposure time.

As Ken says, you would have to fit the asymptote parameters by setting up
an "outer loop" that fits a glmer model for specified values of the
asymptote parameters and does optimization over that space.  With the
development version, it *might* be possible (I'm not sure) to extract
a deviance function and optimize over the variance-covariance and
link-function parameters in one go, although now that I think about it
I'm not sure whether that will really work ....


From bbolker at gmail.com  Sat Feb 23 01:28:07 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 23 Feb 2013 00:28:07 +0000 (UTC)
Subject: [R-sig-ME] multiple nested random factors
References: <51271BD9.9080806@uwo.ca> <loom.20130222T145036-925@post.gmane.org>
	<5127A98C.8050408@uwo.ca>
Message-ID: <loom.20130223T011602-43@post.gmane.org>

Amanda Adams <aadams26 at ...> writes:

> On 22/02/2013 9:05 AM, Ben Bolker wrote:
> > Amanda Adams <aadams26 at ...> writes:
> >
> >> I have been having a heck of a time figuring out how to estimate the
> >> proportion of variance from several random factors. I have a count data
> >> of the number of bat calls recorded at 3 sites, on 6 detectors, over 12
> >> nights. Detectors were at 2 heights.
> >> If I understand nested factors correctly, Detectors are nested in Site
> >> and Night is nested in Site.
> >> Site/Detector and Site/Night are random
> >> factors and Height is a fixed factor.

> >    It's still not entirely clear to me from this description how
> > your data are structured.  You have an average of about 249/12 ~ 21
> > observations per night, so I'm going to assume you have 6 detectors
> > *at each site*.  Detector will be nested in site (because it doesn't
> > make any sense to analyze what happens at "detector number 1" unless
> > the detectors are somehow arranged so that the set of (d1:site1,
> > d1:site2, d1:site3, ... has something in common).  You *may* want
> > a night:site interaction (if you have enough data), but in principle
> > you also want a site factor (probably fixed, since there are only
> > three levels) and a night factor.  This would be
> >
> >    ~ height + f.Site + (1|f.Night/f.Site) + (1|f.Site:f.Detector)
> >
> >    It is quite likely that you will find some of these variance
> > components estimated as zero ...
> >    
> Yes, I have 6 detectors at each site.

  OK

> >
> >> Also, data is overdispersed so I am transforming number of calls as
> >> log(Calls+1).
> >    This makes no sense (sorry).  Poisson models must have a response
> > variable that is a raw count value (integer).  How do you know the
> > data are overdispersed before you fit a model ???  (Although I do see
> > that you have widely varying values in your 'Calls' variable, so
> > you may be right ...)
> >
> >    For various ways of handling overdispersion in GLMMs see
> > http://glmm.wikidot.com/faq
> I had tested for overdispersion with qcc.overdispersion.test in qcc 
> package.  I had tried using an individual-level random effect to capture 
> overdispersion, but was not sure how to interpret the data once that was 
> included.

  Testing the _marginal_ distribution of the data for anything
(normality, overdispersion, etc.) is very rarely a sensible thing
to do.  You need to test for overdispersion in the _residuals_
of your fit.  It's likely though that you do need an individual-level
random effect.  Have you read the references in http://glmm.wikidot.com/faq
that discuss individual-level random effects?

> >    I don't know if it's helpful, but Bolker et al. 2009 _Trends
> > in Ecology and Evolution_ might be a citeable source for GLMMs.
> > It doesn't really say anything specific about Poisson variables
> > and why a Poisson model doesn't include a residual variance; for
> > that you should probably cite (after reading!) a basic book
> > on generalized linear models.
> This paper has been very helpful and was the reason I was initially 
> using glmer. Thanks! I will do some more reading.
> >

 [snip snip snip]

> I applied the individual-level random effect, but how do I interpret the 
> proportion of variation from each factor once it is included?
> 
>  > model <- glmer(Calls ~ f.Height + f.Site + (1|f.Site/f.Night) +
> + (1|f.Site:f.Detector), data = data, family=poisson)
>  >
>  > data$ID <- 1:nrow(data)
>  > model1 <- glmer(Calls ~ f.Height + f.Site + (1|f.Night/f.Site) + 
> (1|f.Site:f.Detector)
> + + (1|ID), data = data, family = poisson)
> Number of levels of a grouping factor for the random effects
> is *equal* to n, the number of observations
>  >
>  > anova(model, model1)
> Data: data
> Models:
> model: Calls ~ f.Height + f.Site + (1 | f.Site/f.Night) + (1 | 
> f.Site:f.Detector)
> model1: Calls ~ f.Height + f.Site + (1 | f.Night/f.Site) + (1 | 
> f.Site:f.Detector) +
> model1:     (1 | ID)
>         Df   AIC   BIC   logLik Chisq Chi Df Pr(>Chisq)
> model   8 49163 49191 -24573.4
> model1  9  1615  1647   -798.6 47550      1  < 2.2e-16 ***
> 
>  > model1
> Generalized linear mixed model fit by the Laplace approximation
> Formula: Calls ~ f.Height + f.Site + (1 | f.Night/f.Site) + 
> (1|f.Site:f.Detector) + (1 | ID)
>     Data: data
>    AIC  BIC logLik deviance
>   1615 1647 -798.6     1597
> Random effects:
>   Groups            Name        Variance Std.Dev.
>   ID                (Intercept) 1.07827  1.03840
>   f.Site:f.Night    (Intercept) 1.90958  1.38187
>   f.Site:f.Detector (Intercept) 2.32948  1.52626
>   f.Night           (Intercept) 0.65313  0.80817
> Number of obs: 249, groups: ID, 249; f.Site:f.Night, 47; 
> f.Site:f.Detector, 24; f.Night, 12
> 
> Fixed effects:
>              Estimate Std. Error z value Pr(>|z|)
> (Intercept)  2.59535    0.86051   3.016 0.002561 **
> f.Height2   -0.05362    0.64015  -0.084 0.933245
> f.Site2      1.01975    1.07455   0.949 0.342619
> f.Site3      0.73546    1.08115   0.680 0.496343
> f.Site4      4.15381    1.07196   3.875 0.000107 ***
> 
> Does this mean: Site has a significant effect on bat activity and
> 44% of the variation in bat activity levels can be explained by detector 
> placement within sites
> 36% by an interaction between Site and Night
> 12% by temporal effects (night)
> 20% by individual variation
> Does the individual variation essentially mean the variation from not 
> explained by temporal and spatial effects?

  Site 4 is significantly different from site 1 (and probably
different from the other sites as well, although that isn't
explicitly tested here).

  It's somewhat harder to do "variance decomposition" in a
GLMM (or a complex/modern LMM) than in classic models.
The 'variance components' would include the four components
listed above as well as the Poisson variance term.  Depending
on how you were thinking about it you might also include the
differences among sites and the difference in height as
'variance components'.  If you look at 'variance' narrowly
enough, then you _could_ state things the way you have above.
I don't know that much about variance partitioning; in GLMMs
it may be a bit of a research topic ...

  It may have come up on this list before, but I can't put
my finger on a thread right now.  Perhaps someone else
can.

Goldstein H, Browne W, Rasbash J (2002) Partitioning Variation in
Multilevel Models.  Understanding Statistics 1: 223--231.

Browne WJ, Subramanian SV, Jones K (2005) Variance partitioning in
multilevel logistic models that exhibit overdispersion. Journal Royal
Statistical Society. Series A 168: 599--613.


From sgleason at siu.edu  Sat Feb 23 05:39:06 2013
From: sgleason at siu.edu (Shane Gleason)
Date: Fri, 22 Feb 2013 22:39:06 -0600
Subject: [R-sig-ME] graphically plotting glmer results with coefplot2
Message-ID: <512847EA.3080908@siu.edu>

Hi everyone,

I am trying to graph out glmer results and am doing so with the 
coefplot2 package.  I can get graphs to display correctly, though I am 
not sure how to interpret the confidence intervals.  Looking at my graph 
(as well as plot1 in the example on the help page) there appears to be 
two confidence intervals on top of each other.  This may be very basic 
but the archive and Google come up empty on why there are two 
(seemingly) separate confidence intervals there.

Thanks in advance everyone,

Shane

ps:  reproduction code here:

> set.seed(1001)
> y1 <- rnorm(1000,50,23)
> y2 <- rbinom(1000,1,prob=0.72)
> x1 <- rnorm(1000,50,2)
> x2 <- rbinom(1000,1,prob=0.63)
> x3 <- rpois(1000, 2)
> x4 <- runif(1000,40,100)
> x5 <- rbeta(1000,2,2)
>
> longnames <- c("a long name01","a long name02","a long name03",
+                "a long name04","a long name05")
>
> fit1 <- lm(y1 ~ x1 + x2 + x3 + x4 + x5)
> fit2 <- glm(y2 ~ x1 + x2 + x3 + x4 + x5,
+             family=binomial(link="logit"))
> op <- par()
> # plot 1
> par (mfrow=c(2,2))
> coefplot2(fit1)
> coefplot2(fit2, col.pts="blue")

-- 
Shane Gleason
Doctoral Candidate
Southern Illinois University:Carbondale
Department of Political Science
Faner 3172


From bbolker at gmail.com  Sat Feb 23 15:57:46 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 23 Feb 2013 14:57:46 +0000 (UTC)
Subject: [R-sig-ME] graphically plotting glmer results with coefplot2
References: <512847EA.3080908@siu.edu>
Message-ID: <loom.20130223T155534-1@post.gmane.org>

Shane Gleason <sgleason at ...> writes:

> I am trying to graph out glmer results and am doing so with the 
> coefplot2 package.  I can get graphs to display correctly, though I am 
> not sure how to interpret the confidence intervals.  Looking at my graph 
> (as well as plot1 in the example on the help page) there appears to be 
> two confidence intervals on top of each other.  This may be very basic 
> but the archive and Google come up empty on why there are two 
> (seemingly) separate confidence intervals there.


>From "Details:" in the help page:
This function plots coefficients from bugs, lm, glm and polr with
1 sd and 2 sd interval bars. 

  In other words, the thick (inner) bars represent +/- 1 standard error,
while the thin (outer) bars represent +/- 2 standard errors.


From doggene at earthlink.net  Sat Feb 23 16:37:39 2013
From: doggene at earthlink.net (Liz Hare)
Date: Sat, 23 Feb 2013 10:37:39 -0500
Subject: [R-sig-ME] Glmulti, clm, computationally singular system
Message-ID: <5128E243.2030807@earthlink.net>

Hello,

I am using glmulti with clm. I get an error that "system is 
computationally singlar: reciprocal condition number = 2.100..."

I've searched the web for this kind of problem and found suggestions to 
use other methods (QR decomposition, Cholesky) to find the inverse, but 
the only option in clm is NR.

Is there anything else I can change about the clm runs or glmulti before 
I start taking variables out?

Thanks,

-- 
Liz Hare PhD
Dog Genetics LLC
doggene at earthlink.net
http://www.doggenetics.com


From ross at biostat.ucsf.edu  Sat Feb 23 00:08:55 2013
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Fri, 22 Feb 2013 15:08:55 -0800
Subject: [R-sig-ME] glmer:  Downdated X'X is not positive definite
Message-ID: <5127FA87.9030707@biostat.ucsf.edu>

 > r2 <- glmer(sa~(1|id), data=sexpartner, family=poisson(), nAGQ=6)
Error in mer_finalize(ans) : Downdated X'X is not positive definite, 1.
Running a closely related (specifically, the outcome variables match on 
missings)
 > r <- glmer(pAnyUAVI~pIsMale+pEthnic+(1|studyidx), data=sexpartner,
   family=binomial, nAGQ=6)
produces no error.

I trimmed the covariates until only the intercept was left.  I used id 
<- factor(studyidx) in case the fact that studyidx was a character was a 
problem (the archive had a statement that it needed to be a factor).  
The original count data had a minimum of 1; sa was the count -1 so that 
it would look more as expected.  At every step along the way I got the 
same error.

My searches suggested the message usually indicates a colinearity 
problem, but I can't see how it could be, or why it wouldn't have shown 
up for the binomial as well as the poisson.

My data are unusual; cluster size varies widely and there are lots of 
singleton clusters.  I tried simulating data with lots of singletons; 
the poisson fit them fine.  As mentioned the counts have no zeros 
(though the sa outcome above does).

Can anyone suggest steps to diagnose or fix the problem?

R 2.15.2; lme4 Version: 0.999999-0, Date: 2012-06-22 from CRAN.

Ross Boylan

P.S.   Would extending the model to a poisson distribution conditional 
on the value being greater than 0 be hard?


From j.hadfield at ed.ac.uk  Sat Feb 23 17:25:31 2013
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Sat, 23 Feb 2013 16:25:31 +0000
Subject: [R-sig-ME] Varying intercepts vs. varying slopes in MCMCglmm
 ordinal models
In-Reply-To: <CAAVN0J_mHrFH3CZo4JYAJxx0d2=j5TsXbn6EW9CU5HcsvPMt1A@mail.gmail.com>
References: <CAAVN0J_mHrFH3CZo4JYAJxx0d2=j5TsXbn6EW9CU5HcsvPMt1A@mail.gmail.com>
Message-ID: <20130223162531.17536f7w2mv0tlc8@www.staffmail.ed.ac.uk>

Hi,

Quoting Jonathan Salerno <jdsalerno at ucdavis.edu> on Fri, 22 Feb 2013  
13:05:51 -0800:

> These are very simple questions which I think will be most easily answered
> conceptually and without any data.
>
> First, does MCMCglmm allow for specification of varying slopes vs. varying
> intercepts?  In the call's most basic form,
>
> m<-MCMCglmm(outcome~fixed_effect, random=~cluster, family="ordinal",
> data=data, prior=prior),
>
>
> is the outcome 'intercept' or the slope of 'fixed_effect' varying by
> 'cluster'?

The intercept is varying by cluster.   
random=~us(1+fixed_effect):cluster gives a random intercept/slope  
model with estimated covariance, and  
random=~idh(1+fixed_effect):cluster is the same but with the  
covariance set to 0.

>
> Second, as I understand it the model cannot be fit with a nested data
> structure (ie, varying at multiple levels e.g. modeling child test scores
> within schools within districts).  However, can effects vary across two
> clustering levels if they are not nested (e.g., modeling tests within
> schools and by religion)?  If so, how is the model specified?

MCMCglmm does not require effects to be nested:  
random=~school+religion fits two (cross-classified) sets of random  
effects.

Jarrod

>
> Thanks very much in advance.
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From bbolker at gmail.com  Sat Feb 23 18:04:54 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 23 Feb 2013 17:04:54 +0000 (UTC)
Subject: [R-sig-ME] glmer:  Downdated X'X is not positive definite
References: <5127FA87.9030707@biostat.ucsf.edu>
Message-ID: <loom.20130223T175740-186@post.gmane.org>

Ross Boylan <ross at ...> writes:

> 
>  > r2 <- glmer(sa~(1|id), data=sexpartner, family=poisson(), nAGQ=6)
> Error in mer_finalize(ans) : Downdated X'X is not positive definite, 1.
> Running a closely related (specifically, the outcome variables match on 
> missings)
>  > r <- glmer(pAnyUAVI~pIsMale+pEthnic+(1|studyidx), data=sexpartner,
>    family=binomial, nAGQ=6)
> produces no error.
> 
> I trimmed the covariates until only the intercept was left.  I used id 
> <- factor(studyidx) in case the fact that studyidx was a character was a 
> problem (the archive had a statement that it needed to be a factor).  
> The original count data had a minimum of 1; sa was the count -1 so that 
> it would look more as expected.  At every step along the way I got the 
> same error.
> 
> My searches suggested the message usually indicates a colinearity 
> problem, but I can't see how it could be, or why it wouldn't have shown 
> up for the binomial as well as the poisson.
> 
> My data are unusual; cluster size varies widely and there are lots of 
> singleton clusters.  I tried simulating data with lots of singletons; 
> the poisson fit them fine.  As mentioned the counts have no zeros 
> (though the sa outcome above does).
> 
> Can anyone suggest steps to diagnose or fix the problem?
> 
> R 2.15.2; lme4 Version: 0.999999-0, Date: 2012-06-22 from CRAN.
> 
> Ross Boylan
> 
> P.S.   Would extending the model to a poisson distribution conditional 
> on the value being greater than 0 be hard?

  It is indeed a little surprising (to me) that you're getting 
downdating problems with an intercept-only model.
   Hard to say without a closer look at the data.
   I know it won't solve your problem, but does fitting the model
_without_ the singleton clusters work?
   Do you have a very small number of values >0?
   I don't see any obvious way to adapt glmer to doing truncated Poisson
fits, but glmmADMB has a "truncpoiss" family that would be worth trying.
(Right now glmmADMB is unavailable from r-forge, may be available shortly,
if you have trouble let me know.)


  Ben Bolker


From jdforest at umn.edu  Sat Feb 23 20:14:28 2013
From: jdforest at umn.edu (James Forester)
Date: Sat, 23 Feb 2013 13:14:28 -0600
Subject: [R-sig-ME] lmer update environment: Bug?
Message-ID: <CA+3WCZtDaT2-aieDH-8hy2Guu=XVemkO=qABi1i=ymCkSpmfpg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130223/eee489c3/attachment.pl>

From bbolker at gmail.com  Sat Feb 23 20:57:50 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 23 Feb 2013 19:57:50 +0000 (UTC)
Subject: [R-sig-ME] lmer update environment: Bug?
References: <CA+3WCZtDaT2-aieDH-8hy2Guu=XVemkO=qABi1i=ymCkSpmfpg@mail.gmail.com>
Message-ID: <loom.20130223T203528-696@post.gmane.org>

James Forester <jdforest at ...> writes:

> While attempting to re-run some previously working code this morning, I
> seem to have stumbled upon a bug in how lmer() works with update(). For
> some reason, when I try to update a glmer or lmer model within a function,
> lmer() or update() can only see a dataframe if it is in the global
> environment. I have included an example below (a similar script written for
> glm works fine). Any ideas on how to correctly specify the environment so I
> can get around this?
> 
> Thanks for your help
> 
> James Forester

  It turns out that this stuff is really, really, really, hard to get right.
I've been able to get it to work reliably (in almost all permutations)
in the development version of lme4, but I can't easily come up with
a better workaround/hack than the one you have.

  The problem is that the update method is looking in its parent
environment for the objects in the call.  'dat1' doesn't live in
the frame of testlmer, it lives in the global environment ...

   If you're willing/able to install the development version from
github

library("devtools")
install_github("lme4",user="lme4")

(you'll need to have installed RcppEigen etc.)
that should work.  However, we're still having some fragility
issues with GLMMs.  However, if you're using LMMs (lmer) only,
as far as we know the development version will do everything the
stable version can do ... (and more)

  Ben Bolker




> 
> Platform: x86_64-pc-linux-gnu
> R version: 2.15.2 (2012-10-26)
> lme4 version: 0.999999-0
> 
###########################
## Test function
###########################

testlmer<-function(dat1, test.update=TRUE, save.global=FALSE){

    if(save.global){
        dat1<<-dat1
    }

    ##This model borrowed from the examples in ?lmer
    basemod=glmer(cbind(incidence, size - incidence) ~ period + (1 | herd),
    family = binomial, data = dat1)

    if(test.update){
        ##This is where the problem seems to be
        update.mod=eval.parent(update(basemod,.~. + rand.dat))
        return(update.mod)
    } else return(basemod)
}

###########################
## Test script
###########################
library(lme4.0)

##add a spurious column of data
cbpp$rand.dat = rnorm(nrow(cbpp))

## this works: a glmer model is fit within the function
##   and is then updated in the global environment
testmod = testlmer(cbpp, test.update=FALSE, save.global=FALSE)
testmod = update(testmod,.~. + rand.dat,data=cbpp)

## this fails: attempting to update the base model,
##   the function fails with "object 'dat1' not found"
##   In this case 'dat1' is only within the function environment
testmod = testlmer(cbpp, test.update=TRUE, save.global=FALSE)

## this works: here the data are saved to the global environment
##    before the model update
testmod = testlmer(cbpp, test.update=TRUE, save.global=TRUE)
rm("dat1")


From iskanderdun at gmail.com  Sat Feb 23 23:21:21 2013
From: iskanderdun at gmail.com (Erica Newman)
Date: Sat, 23 Feb 2013 14:21:21 -0800
Subject: [R-sig-ME] Nested error term and unbalanced design
Message-ID: <CAOpAxwZcbjnkfEGz1z-YnnHSUE8JFrG9d0tVH_fxLKPZ8PP93Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130223/5f1ee0c5/attachment.pl>

From jbaldwin at fs.fed.us  Sun Feb 24 00:18:20 2013
From: jbaldwin at fs.fed.us (Baldwin, Jim -FS)
Date: Sat, 23 Feb 2013 23:18:20 +0000
Subject: [R-sig-ME] Nested error term and unbalanced design
In-Reply-To: <CAOpAxwZcbjnkfEGz1z-YnnHSUE8JFrG9d0tVH_fxLKPZ8PP93Q@mail.gmail.com>
References: <CAOpAxwZcbjnkfEGz1z-YnnHSUE8JFrG9d0tVH_fxLKPZ8PP93Q@mail.gmail.com>
Message-ID: <DDC5EC9B78340042B0D5A0C3789D4569199AA224@001FSN2MPN1-061.001f.mgd2.msft.net>

While there is a definite order to family, genus, and species (no pun intended), I think that the "nestedness" (if any) would be related to how you selected your sampling units rather than the fixed effects of family, genus, and species.  (I admit bias in rarely if ever considering species as a random effect.)

Jim

-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Erica Newman
Sent: Saturday, February 23, 2013 2:21 PM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] Nested error term and unbalanced design

I am trying to run a model that incorporates both environmental variables and taxonomic relationships, and I am unsure if I am 1) specifying the error term correctly, and 2) accounting for unbalanced data correctly. I would appreciate any guidance you can provide.

As a simplified example, I want to ask if a bird is more likely to be carrying ticks based on the habitat it was caught in, and what kind of bird it is (my actual model has many more environmental variables). We have many related species in multiple genera in multiple families, but all in the same order. Species is nested within genus, and genus is nested within family. I want to estimate a fixed effect for both habitat and species, while accounting for the nestedness of the relationships of the birds, and I also want to account for the fact that we caught more of certain species than others.

My simplified model looks like this:

M1 <- lmer(y ~ HABITAT + SPECIES + (1|FAMILY/GENUS/SPECIES),
family=binomial(link="logit"))

where y is a column vector of (tick presence, tick absence)


So my questions are: is this the correct "grammar" for the nested error?
and does the nested error structure by itself take into account the unbalanced data structure?

Thank you in advance for your time.

Sincerely,

Erica Newman

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models





This electronic message contains information generated by the USDA solely for the intended recipients. Any unauthorized interception of this message or the use or disclosure of the information it contains may violate the law and subject the violator to civil or criminal penalties. If you believe you have received this message in error, please notify the sender and delete the email immediately.


From dhapop at googlemail.com  Sun Feb 24 16:15:58 2013
From: dhapop at googlemail.com (Sai)
Date: Sun, 24 Feb 2013 16:15:58 +0100
Subject: [R-sig-ME] lmer within family mixed model question.
Message-ID: <CACWtO9MkOV+UPjzRV+AaQfhM55hnQFi-=Xs0-z2AQ8OWVficSw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130224/fa3d12de/attachment.pl>

From ross at biostat.ucsf.edu  Sun Feb 24 22:26:50 2013
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Sun, 24 Feb 2013 13:26:50 -0800
Subject: [R-sig-ME] glmer:  Downdated X'X is not positive definite
Message-ID: <5127FA87.9030707@biostat.ucsf.edu>

 > r2 <- glmer(sa~(1|id), data=sexpartner, family=poisson(), nAGQ=6)
Error in mer_finalize(ans) : Downdated X'X is not positive definite, 1.
Running a closely related (specifically, the outcome variables match on 
missings)
 > r <- glmer(pAnyUAVI~pIsMale+pEthnic+(1|studyidx), data=sexpartner,
   family=binomial, nAGQ=6)
produces no error.

I trimmed the covariates until only the intercept was left.  I used id 
<- factor(studyidx) in case the fact that studyidx was a character was a 
problem (the archive had a statement that it needed to be a factor).  
The original count data had a minimum of 1; sa was the count -1 so that 
it would look more as expected.  At every step along the way I got the 
same error.

My searches suggested the message usually indicates a colinearity 
problem, but I can't see how it could be, or why it wouldn't have shown 
up for the binomial as well as the poisson.

My data are unusual; cluster size varies widely and there are lots of 
singleton clusters.  I tried simulating data with lots of singletons; 
the poisson fit them fine.  As mentioned the counts have no zeros 
(though the sa outcome above does).

Can anyone suggest steps to diagnose or fix the problem?

R 2.15.2; lme4 Version: 0.999999-0, Date: 2012-06-22 from CRAN.

Ross Boylan

P.S.   Would extending the model to a poisson distribution conditional 
on the value being greater than 0 be hard?


From ross at biostat.ucsf.edu  Sun Feb 24 22:49:02 2013
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Sun, 24 Feb 2013 13:49:02 -0800
Subject: [R-sig-ME] glmer:  Downdated X'X is not positive definite
In-Reply-To: <5127FA87.9030707@biostat.ucsf.edu>
References: <5127FA87.9030707@biostat.ucsf.edu>
Message-ID: <1361742542.25712.30.camel@corn.betterworld.us>

[Sorry about the recent double-post; you can ignore the second message.]

Ben Bolker wrote
> It is indeed a little surprising (to me) that you're getting 
> downdating problems with an intercept-only model.
>    Hard to say without a closer look at the data.
>    I know it won't solve your problem, but does fitting the model
> _without_ the singleton clusters work?
glmer complained that there were no random terms, as I recall (not at the system now).
glm fit it without complaints.

SAS GLIMMIX fit a poisson with random intercepts to the data without incident.

OTOH, glmer did manage to fit poisson random intercept model to toy
simulated data I constructed, even though the simulated data had lots of
singleton "clusters".

>    Do you have a very small number of values >0?
No.  N > 2,000 and c 1/3 are 1's.

>    I don't see any obvious way to adapt glmer to doing truncated Poisson
> fits, but glmmADMB has a "truncpoiss" family that would be worth trying.
> (Right now glmmADMB is unavailable from r-forge, may be available shortly,
> if you have trouble let me know.)
Thanks for the tip.

My ultimate goal, by the way, is to use the model as part of a chained
equation multiple imputation.  That means it needs to work reliably
without human intervention.

Ross


From David.Duffy at qimr.edu.au  Mon Feb 25 00:31:27 2013
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Mon, 25 Feb 2013 09:31:27 +1000
Subject: [R-sig-ME] lmer within family mixed model question.
In-Reply-To: <CACWtO9MkOV+UPjzRV+AaQfhM55hnQFi-=Xs0-z2AQ8OWVficSw@mail.gmail.com>
References: <CACWtO9MkOV+UPjzRV+AaQfhM55hnQFi-=Xs0-z2AQ8OWVficSw@mail.gmail.com>
Message-ID: <alpine.LMD.2.00.1302250924360.23584@orpheus.qimr.edu.au>

On Mon, 25 Feb 2013, Sai wrote:

> Dear all,
>
> I am currently using lmer from lme4 package to check for family effect for
> a phenotype. Since Family has a genetic as well as environment component, I
> would like to look for environment component. For this I would like to look
> for phenotypic differences within siblings (which share 50% of genes from
> common parents). For example
>
>
> MourseID    Phenotype    Cage    Family
> 1    2.1    A       F1
> 2    4.0    A    F1
> 3. 1.0    B    F1
> 4    1.3    C    F2
> 5    1.9    C    F2
> 6    4.3    D    F2
> 7    2.2    D    F2
> 8    3.4    E    F2
> 9    3.5    E    F2
>
> Model1 <- lmer(Phenotype ~ 1+ (1|Cage)+(1+Cage/Family)
>
> The model would treat Cage as a separate random variable and Family nested
> within Cage (to check for difference between same family from different
> cages). I do not know how to formulate the above model to find the
> difference within F1 and F2 family mice?

So F1 and F2 are inter and back crosses?  Something like

Model1 <- lmer(Phenotype ~ 1+ (1|Cage)+(1|Family)) 
Model2 <- lmer(Phenotype ~ 1+ (1|Cage)+(1|Family)+(1|Family=="F2"))


From Steve.Candy at aad.gov.au  Mon Feb 25 02:10:16 2013
From: Steve.Candy at aad.gov.au (Steve Candy)
Date: Mon, 25 Feb 2013 12:10:16 +1100
Subject: [R-sig-ME] lmer residual variance estimate with prior weights
 (lmer wrong, lme and asreml correct) [SEC=UNCLASSIFIED]
Message-ID: <410C0E47580EB147811BB64E83936A3F68E046AF80@EX2K7-CCR.AAD.GOV.AU>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130225/e74c00d0/attachment.pl>

From bbolker at gmail.com  Mon Feb 25 03:20:36 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 25 Feb 2013 02:20:36 +0000 (UTC)
Subject: [R-sig-ME] glmer:  Downdated X'X is not positive definite
References: <5127FA87.9030707@biostat.ucsf.edu>
	<1361742542.25712.30.camel@corn.betterworld.us>
Message-ID: <loom.20130225T031849-152@post.gmane.org>

Ross Boylan <ross at ...> writes:

 [snip]

> Ben Bolker wrote
> > It is indeed a little surprising (to me) that you're getting 
> > downdating problems with an intercept-only model.
> >    Hard to say without a closer look at the data.
> >    I know it won't solve your problem, but does fitting the model
> > _without_ the singleton clusters work?

  I didn't mean without the clusters, I meant dropping the singleton
clusters from the data ...

> glmer complained that there were no random terms, as I recall (not at the
system now).
> glm fit it without complaints.
> 
> SAS GLIMMIX fit a poisson with random intercepts to the data without incident.

  You could try glmmPQL if you like ... (it's not clear whether you
used PQL or Laplace approximation within GLIMMIX ...)

> OTOH, glmer did manage to fit poisson random intercept model to toy
> simulated data I constructed, even though the simulated data had lots of
> singleton "clusters".
> 
> >    Do you have a very small number of values >0?
> No.  N > 2,000 and c 1/3 are 1's.
> 

  [snip]

  Did you try with development lme4?  Does it make a difference?


From Paul.Thompson at SanfordHealth.org  Mon Feb 25 03:55:58 2013
From: Paul.Thompson at SanfordHealth.org (Thompson,Paul)
Date: Mon, 25 Feb 2013 02:55:58 +0000
Subject: [R-sig-ME] glmer:  Downdated X'X is not positive definite
In-Reply-To: <loom.20130225T031849-152@post.gmane.org>
References: <5127FA87.9030707@biostat.ucsf.edu>
	<1361742542.25712.30.camel@corn.betterworld.us>
	<loom.20130225T031849-152@post.gmane.org>
Message-ID: <9B75E7CF385CB94EAD6587DD96AC2D977F075282@SFSMCEXMBX3.sanfordhealth.org>

Another approach might be to add an additional observation to each singleton cluster, making them doubletons. You could do so by incorporating a known amount of variance, and accounting for that variance in any variance estimate by subtraction from appropriate terms.

-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Ben Bolker
Sent: Sunday, February 24, 2013 8:21 PM
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] glmer: Downdated X'X is not positive definite

Ross Boylan <ross at ...> writes:

 [snip]

> Ben Bolker wrote
> > It is indeed a little surprising (to me) that you're getting 
> > downdating problems with an intercept-only model.
> >    Hard to say without a closer look at the data.
> >    I know it won't solve your problem, but does fitting the model 
> > _without_ the singleton clusters work?

  I didn't mean without the clusters, I meant dropping the singleton clusters from the data ...

> glmer complained that there were no random terms, as I recall (not at 
> the
system now).
> glm fit it without complaints.
> 
> SAS GLIMMIX fit a poisson with random intercepts to the data without incident.

  You could try glmmPQL if you like ... (it's not clear whether you used PQL or Laplace approximation within GLIMMIX ...)

> OTOH, glmer did manage to fit poisson random intercept model to toy 
> simulated data I constructed, even though the simulated data had lots 
> of singleton "clusters".
> 
> >    Do you have a very small number of values >0?
> No.  N > 2,000 and c 1/3 are 1's.
> 

  [snip]

  Did you try with development lme4?  Does it make a difference?

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
-----------------------------------------------------------------------
Confidentiality Notice: This e-mail message, including any attachments,
is for the sole use of the intended recipient(s) and may contain
privileged and confidential information.  Any unauthorized review, use,
disclosure or distribution is prohibited.  If you are not the intended
recipient, please contact the sender by reply e-mail and destroy
all copies of the original message.



From bbolker at gmail.com  Mon Feb 25 16:27:13 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 25 Feb 2013 15:27:13 +0000 (UTC)
Subject: [R-sig-ME] Nested error term and unbalanced design
References: <CAOpAxwZcbjnkfEGz1z-YnnHSUE8JFrG9d0tVH_fxLKPZ8PP93Q@mail.gmail.com>
	<DDC5EC9B78340042B0D5A0C3789D4569199AA224@001FSN2MPN1-061.001f.mgd2.msft.net>
Message-ID: <loom.20130225T152410-700@post.gmane.org>

Baldwin, Jim -FS <jbaldwin at ...> writes:

>  While there is a definite order to family, genus, and species (no
> pun intended), I think that the "nestedness" (if any) would be
> related to how you selected your sampling units rather than the
> fixed effects of family, genus, and species.  (I admit bias in
> rarely if ever considering species as a random effect.)
 
> Jim

  I think I respectfully disagree ... see below ...

> I am trying to run a model that incorporates both environmental
> variables and taxonomic relationships, and I am unsure if I am 1)
> specifying the error term correctly, and 2) accounting for
> unbalanced data correctly. I would appreciate any guidance you can
> provide.
 
> As a simplified example, I want to ask if a bird is more likely to
> be carrying ticks based on the habitat it was caught in, and what
> kind of bird it is (my actual model has many more environmental
> variables). We have many related species in multiple genera in
> multiple families, but all in the same order. Species is nested
> within genus, and genus is nested within family. I want to estimate
> a fixed effect for both habitat and species, while accounting for
> the nestedness of the relationships of the birds, and I also want to
> account for the fact that we caught more of certain species than
> others.
 
> My simplified model looks like this:
> 
> M1 <- lmer(y ~ HABITAT + SPECIES + (1|FAMILY/GENUS/SPECIES),
> family=binomial(link="logit"))
> 
> where y is a column vector of (tick presence, tick absence)
> 
> So my questions are: is this the correct "grammar" for the nested error?
> and does the nested error structure by itself take into account the
>  unbalanced data structure?

   Generally you don't have to worry about lack of balance in
'modern' mixed models unless it's really extreme.

  I'm having a little bit of a hard time conceptually with the
idea of having species as a fixed effect _and_ having the 
variances of family and genus be random.  You certainly
shouldn't have a categorical predictor (SPECIES) appear as both 
a random and a fixed effect, though.

M1 <- lmer(y ~ HABITAT + SPECIES + (1|FAMILY/GENUS),
     family=binomial(link="logit"))

*might* work (I would give it a try and see if the results are sensible).
I would also consider

M1 <- lmer(y ~ HABITAT + (HABITAT|FAMILY/GENUS/SPECIES),
     family=binomial(link="logit"))

if your data set is big enough to support it.  This allows for habitat
to have different effects on different species ... (see a paper
by Schielzeth and Forstmeier on the importance of including interactions
between fixed and random effects:
http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2657178/ )


From jbaldwin at fs.fed.us  Mon Feb 25 18:55:34 2013
From: jbaldwin at fs.fed.us (Baldwin, Jim -FS)
Date: Mon, 25 Feb 2013 17:55:34 +0000
Subject: [R-sig-ME] Nested error term and unbalanced design
In-Reply-To: <loom.20130225T152410-700@post.gmane.org>
References: <CAOpAxwZcbjnkfEGz1z-YnnHSUE8JFrG9d0tVH_fxLKPZ8PP93Q@mail.gmail.com>
	<DDC5EC9B78340042B0D5A0C3789D4569199AA224@001FSN2MPN1-061.001f.mgd2.msft.net>
	<loom.20130225T152410-700@post.gmane.org>
Message-ID: <DDC5EC9B78340042B0D5A0C3789D4569199AB3BD@001FSN2MPN1-061.001f.mgd2.msft.net>

I think someone wise said "When you find yourself in a hole, first put down the shovel."  Someday I'll learn that.  (Maybe today.)  What follows is likely from my lack of biological (and maybe statistical) knowledge.

The setup seems to be that individual birds (classified as to their species and habitat) are checked for the presence of ticks.  For each species and habitat combination there is a proportion of birds with ticks.  Each species is also classified as to genus and family.  It is of interest to see if there are differences among genus and family classifications.  I see everything as a fixed effect in this case.

I see no random effects or a relevant variance component as I can't imagine that for any genus and family that there is actually a random sample from all species within that family (especially if there are only a small number of species within a particular family to select from).

If a family (either within a habitat type or across habitat types) is to be compared to another family, it would seem that the first comparison would be among the mean of the species proportions (or maybe the mean of the logits or probits) for each family).

Next it is conceivable that one might want to know if the variability of the species within a family varies among families.  That could be done by defining/declaring the summary statistic of interest to be the variance of the "true" proportions within a family and one would use the sample data to estimate those variances.  But these variances would be as summary statistics rather than a variance component essential to the definition of the model.  The underlying model would simply be the number of birds with ticks following a binomial distribution with the proportion of birds with ticks being a function of species and habitat.

I agree with the article you mentioned concerning the use of random coefficient models.  I just don't see treating species as a randomly selected subject from a family of species.  (Maybe treating insect species as a randomly selected species within a family where there are zillions of species but not for critters much higher up the food chain.)

Jim

-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Ben Bolker
Sent: Monday, February 25, 2013 7:27 AM
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Nested error term and unbalanced design

Baldwin, Jim -FS <jbaldwin at ...> writes:

>  While there is a definite order to family, genus, and species (no pun
> intended), I think that the "nestedness" (if any) would be related to
> how you selected your sampling units rather than the fixed effects of
> family, genus, and species.  (I admit bias in rarely if ever
> considering species as a random effect.)

> Jim

  I think I respectfully disagree ... see below ...

> I am trying to run a model that incorporates both environmental
> variables and taxonomic relationships, and I am unsure if I am 1)
> specifying the error term correctly, and 2) accounting for unbalanced
> data correctly. I would appreciate any guidance you can provide.

> As a simplified example, I want to ask if a bird is more likely to be
> carrying ticks based on the habitat it was caught in, and what kind of
> bird it is (my actual model has many more environmental variables). We
> have many related species in multiple genera in multiple families, but
> all in the same order. Species is nested within genus, and genus is
> nested within family. I want to estimate a fixed effect for both
> habitat and species, while accounting for the nestedness of the
> relationships of the birds, and I also want to account for the fact
> that we caught more of certain species than others.

> My simplified model looks like this:
>
> M1 <- lmer(y ~ HABITAT + SPECIES + (1|FAMILY/GENUS/SPECIES),
> family=binomial(link="logit"))
>
> where y is a column vector of (tick presence, tick absence)
>
> So my questions are: is this the correct "grammar" for the nested error?
> and does the nested error structure by itself take into account the
> unbalanced data structure?

   Generally you don't have to worry about lack of balance in 'modern' mixed models unless it's really extreme.

  I'm having a little bit of a hard time conceptually with the idea of having species as a fixed effect _and_ having the variances of family and genus be random.  You certainly shouldn't have a categorical predictor (SPECIES) appear as both a random and a fixed effect, though.

M1 <- lmer(y ~ HABITAT + SPECIES + (1|FAMILY/GENUS),
     family=binomial(link="logit"))

*might* work (I would give it a try and see if the results are sensible).
I would also consider

M1 <- lmer(y ~ HABITAT + (HABITAT|FAMILY/GENUS/SPECIES),
     family=binomial(link="logit"))

if your data set is big enough to support it.  This allows for habitat to have different effects on different species ... (see a paper by Schielzeth and Forstmeier on the importance of including interactions between fixed and random effects:
http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2657178/ )

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models





This electronic message contains information generated by the USDA solely for the intended recipients. Any unauthorized interception of this message or the use or disclosure of the information it contains may violate the law and subject the violator to civil or criminal penalties. If you believe you have received this message in error, please notify the sender and delete the email immediately.


From bbolker at gmail.com  Mon Feb 25 23:48:36 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 25 Feb 2013 17:48:36 -0500
Subject: [R-sig-ME] Nested error term and unbalanced design
In-Reply-To: <DDC5EC9B78340042B0D5A0C3789D4569199AB3BD@001FSN2MPN1-061.001f.mgd2.msft.net>
References: <CAOpAxwZcbjnkfEGz1z-YnnHSUE8JFrG9d0tVH_fxLKPZ8PP93Q@mail.gmail.com>
	<DDC5EC9B78340042B0D5A0C3789D4569199AA224@001FSN2MPN1-061.001f.mgd2.msft.net>
	<loom.20130225T152410-700@post.gmane.org>
	<DDC5EC9B78340042B0D5A0C3789D4569199AB3BD@001FSN2MPN1-061.001f.mgd2.msft.net>
Message-ID: <512BEA44.1020101@gmail.com>

On 13-02-25 12:55 PM, Baldwin, Jim -FS wrote:
> I think someone wise said "When you find yourself in a hole, first
> put down the shovel."  Someday I'll learn that.  (Maybe today.)  What
> follows is likely from my lack of biological (and maybe statistical)
> knowledge.
> 
> The setup seems to be that individual birds (classified as to their
> species and habitat) are checked for the presence of ticks.  For each
> species and habitat combination there is a proportion of birds with
> ticks.  Each species is also classified as to genus and family.  It
> is of interest to see if there are differences among genus and family
> classifications.  I see everything as a fixed effect in this case.
> 
> I see no random effects or a relevant variance component as I can't
> imagine that for any genus and family that there is actually a random
> sample from all species within that family (especially if there are
> only a small number of species within a particular family to select
> from).

  I have a different definition of random effects, more along the
pragmatic/Bayesian than the philosophical/frequentist (this is discussed
at more length at http://glmm.wikidot.com/faq ).  In essence, I make the
distinction between fixed and random effects more on the criteria

 * is it useful to estimate these parameters with shrinkage? (yes=random)

and

 * would I rather have the ability to extrapolate to unmeasured
units/make inferences about the variation among units (random) or to
make inferential statements about differences between particular sets of
units (fixed)?

 I do *not* make much use of the experimental-design criterion (were
these units selected randomly, or could they have been selected
randomly, from a larger set of values)?

  So I see no problem in treating family/genus/species as random
effects.  Opinions differ, though.

> If a family (either within a habitat type or across habitat types) is
> to be compared to another family, it would seem that the first
> comparison would be among the mean of the species proportions (or
> maybe the mean of the logits or probits) for each family).
> 
> Next it is conceivable that one might want to know if the variability
> of the species within a family varies among families.  That could be
> done by defining/declaring the summary statistic of interest to be
> the variance of the "true" proportions within a family and one would
> use the sample data to estimate those variances.  But these variances
> would be as summary statistics rather than a variance component
> essential to the definition of the model.  The underlying model would
> simply be the number of birds with ticks following a binomial
> distribution with the proportion of birds with ticks being a function
> of species and habitat.

  This is a sensible question, but hard to set up within lme4.  The
random effects coded in lme4 (and in most GLMMs) quantify whether the
mean (on the link scale = logit/probit/etc.) differs among units, not
whether the variation differs.  You could do this in AD Model
Builder/WinBUGS/Stan/etc.  (I think this has been discussed before on
the list.)
> 
> I agree with the article you mentioned concerning the use of random
> coefficient models.  I just don't see treating species as a randomly
> selected subject from a family of species.  (Maybe treating insect
> species as a randomly selected species within a family where there
> are zillions of species but not for critters much higher up the food
> chain.)
> 
> Jim
> 
> -----Original Message----- From:
> r-sig-mixed-models-bounces at r-project.org
> [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Ben
> Bolker Sent: Monday, February 25, 2013 7:27 AM To:
> r-sig-mixed-models at r-project.org Subject: Re: [R-sig-ME] Nested error
> term and unbalanced design
> 
> Baldwin, Jim -FS <jbaldwin at ...> writes:
> 
>> While there is a definite order to family, genus, and species (no
>> pun intended), I think that the "nestedness" (if any) would be
>> related to how you selected your sampling units rather than the
>> fixed effects of family, genus, and species.  (I admit bias in
>> rarely if ever considering species as a random effect.)
> 
>> Jim
> 
> I think I respectfully disagree ... see below ...
> 
>> I am trying to run a model that incorporates both environmental 
>> variables and taxonomic relationships, and I am unsure if I am 1) 
>> specifying the error term correctly, and 2) accounting for
>> unbalanced data correctly. I would appreciate any guidance you can
>> provide.
> 
>> As a simplified example, I want to ask if a bird is more likely to
>> be carrying ticks based on the habitat it was caught in, and what
>> kind of bird it is (my actual model has many more environmental
>> variables). We have many related species in multiple genera in
>> multiple families, but all in the same order. Species is nested
>> within genus, and genus is nested within family. I want to estimate
>> a fixed effect for both habitat and species, while accounting for
>> the nestedness of the relationships of the birds, and I also want
>> to account for the fact that we caught more of certain species than
>> others.
> 
>> My simplified model looks like this:
>> 
>> M1 <- lmer(y ~ HABITAT + SPECIES + (1|FAMILY/GENUS/SPECIES), 
>> family=binomial(link="logit"))
>> 
>> where y is a column vector of (tick presence, tick absence)
>> 
>> So my questions are: is this the correct "grammar" for the nested
>> error? and does the nested error structure by itself take into
>> account the unbalanced data structure?
> 
> Generally you don't have to worry about lack of balance in 'modern'
> mixed models unless it's really extreme.
> 

> I'm having a little bit of a hard time conceptually with the idea of
> having species as a fixed effect _and_ having the variances of family
> and genus be random.  You certainly shouldn't have a categorical
> predictor (SPECIES) appear as both a random and a fixed effect,
> though.

> M1 <- lmer(y ~ HABITAT + SPECIES + (1|FAMILY/GENUS), 
> family=binomial(link="logit"))
> 
> *might* work (I would give it a try and see if the results are
> sensible). I would also consider
> 
> M1 <- lmer(y ~ HABITAT + (HABITAT|FAMILY/GENUS/SPECIES), 
> family=binomial(link="logit"))
> 
> if your data set is big enough to support it.  This allows for
> habitat to have different effects on different species ... (see a
> paper by Schielzeth and Forstmeier on the importance of including
> interactions between fixed and random effects: 
> http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2657178/ )
> 
> _______________________________________________ 
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
> 
> 
> 
> This electronic message contains information generated by the USDA
> solely for the intended recipients. Any unauthorized interception of
> this message or the use or disclosure of the information it contains
> may violate the law and subject the violator to civil or criminal
> penalties. If you believe you have received this message in error,
> please notify the sender and delete the email immediately.
>


From asafw.at.wharton at gmail.com  Tue Feb 26 16:52:04 2013
From: asafw.at.wharton at gmail.com (Asaf Weinstein)
Date: Tue, 26 Feb 2013 10:52:04 -0500
Subject: [R-sig-ME] Extracting model matrices used by lmer
In-Reply-To: <loom.20121116T050335-45@post.gmane.org>
References: <CAGG0PdAHnSG0_E+B2KYEtZE5Lzu-W=X5mjYaMz91hmT+VgsN9g@mail.gmail.com>
	<loom.20121116T050335-45@post.gmane.org>
Message-ID: <CAGG0PdAcYaN+8DrKhhrqa+x_jYMkA5HVvi9sJfue_n_jV5fJug@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130226/86e8a278/attachment.pl>

From maggenga at libero.it  Tue Feb 26 22:46:08 2013
From: maggenga at libero.it (maggenga at libero.it)
Date: Tue, 26 Feb 2013 22:46:08 +0100 (CET)
Subject: [R-sig-ME] GLMM family=binomial, link identity
Message-ID: <21731936.16250111361915168178.JavaMail.defaultUser@defaultHost>

? stato filtrato un testo allegato il cui set di caratteri non era
indicato...
Nome: non disponibile
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130226/c3d5adaa/attachment.pl>

From bbolker at gmail.com  Tue Feb 26 23:20:28 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 26 Feb 2013 17:20:28 -0500
Subject: [R-sig-ME] Extracting model matrices used by lmer
In-Reply-To: <CAGG0PdAcYaN+8DrKhhrqa+x_jYMkA5HVvi9sJfue_n_jV5fJug@mail.gmail.com>
References: <CAGG0PdAHnSG0_E+B2KYEtZE5Lzu-W=X5mjYaMz91hmT+VgsN9g@mail.gmail.com>
	<loom.20121116T050335-45@post.gmane.org>
	<CAGG0PdAcYaN+8DrKhhrqa+x_jYMkA5HVvi9sJfue_n_jV5fJug@mail.gmail.com>
Message-ID: <512D352C.9010702@gmail.com>

On 13-02-26 10:52 AM, Asaf Weinstein wrote:
> Thank you very much, Ben, for your useful answer from long ago.
> I still can't figure out a way to extract the Residual variance (sigma^2)
> estimate using getME()?
> 
> Thanks again,
> Asaf

  I think sigma(model)^2 should do it -- apparently works for stable as
well as development lme4.

> 
> 
> On 15 November 2012 23:04, Ben Bolker <bbolker at gmail.com> wrote:
> 
>> Asaf Weinstein <asafw.at.wharton at ...> writes:
>>
>>>
>>> Hello again,
>>>
>>> Is there an easy way of obtaining the X and Z model matrices in
>>>
>>> *y = X*Beta + Z*u + eps*
>>>
>>> with the lmer function? I am trying to extract these because I want to
>>> obtain maximum likelihood estimates for the case where sigma sq (error
>>> variance) is known.
>>
>>
>> See
>>
>> ?getME
>>
>> As shown in the examples:
>>
>>    (nmME <- eval(formals(getME)$name))
>>  [1] "X"       "Z"       "Zt"      "u"       "Gp"      "L"       "Lambda"
>>  [8] "Lambdat" "A"       "flist"   "RX"      "RZX"     "beta"    "theta"
>> [15] "REML"    "n_rtrms" "is_REML"
>>
>>
>> so getME(model,"X") and getME(model,"Z") should do what you want.
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>


From bbolker at gmail.com  Tue Feb 26 23:27:40 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 26 Feb 2013 22:27:40 +0000 (UTC)
Subject: [R-sig-ME] Glmulti, clm, computationally singular system
References: <5128E243.2030807@earthlink.net>
Message-ID: <loom.20130226T232304-192@post.gmane.org>

Liz Hare <doggene at ...> writes:

> 
> Hello,
> 
> I am using glmulti with clm. I get an error that "system is 
> computationally singlar: reciprocal condition number = 2.100..."
> 
> I've searched the web for this kind of problem and found suggestions to 
> use other methods (QR decomposition, Cholesky) to find the inverse, but 
> the only option in clm is NR.
> 
> Is there anything else I can change about the clm runs or glmulti before 
> I start taking variables out?

  Any chance of a reproducible example? http://tinyurl.com/reproducible-000
  (It would be helpful to tell us that clm is in the ordinal package
and that "glmulti" has its own package.)

  Can you expand on "the only option in clm is NR"?  I assume "NR"
means Newton-Raphson, which puzzles me a bit since that's not really
want lme4 is doing anyway, and I thought clm was built on lme4 ...
Are your failures coming from clm or from glmulti?  I assume what's
happening is that glmulti is trying to fit a submodel that's failing
within clm.  It would be helpful to isolate the particular submodel
that's failing (if that's the case).

  I may be totally off here, just trying to guess -- please correct
any misconceptions.


From bbolker at gmail.com  Tue Feb 26 23:40:54 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 26 Feb 2013 22:40:54 +0000 (UTC)
Subject: [R-sig-ME] GLMM family=binomial, link identity
References: <21731936.16250111361915168178.JavaMail.defaultUser@defaultHost>
Message-ID: <loom.20130226T233956-298@post.gmane.org>

maggenga at ... <maggenga at ...> writes:

> 
> Hi,
> I'm phd student in medical statistics.
> I would like know the R-way to perform the identity link (family=binomial) in
lmer (ade4 package).

  How about

glmer(...,family=binomial(link="identity")) 

?

See ?family in base R.

Warning: this is likely to be fragile (as fitting with non-standard
link functions often is).


From maggenga at libero.it  Wed Feb 27 00:14:26 2013
From: maggenga at libero.it (maggenga at libero.it)
Date: Wed, 27 Feb 2013 00:14:26 +0100 (CET)
Subject: [R-sig-ME] GLMM family=binomial: link identity vs link logit
Message-ID: <1764524.16267831361920466884.JavaMail.defaultUser@defaultHost>



Sorry, i was wrong. I want say lme4 package.


But "glmer(...,family=binomial(link="identity")) " give me same results

as

"glmer(...,family=binomial(link="logit")) "

Why?

I want interpret the coefficients as risk difference and not OR

Thank you very much

Davide



>>----Messaggio originale----
>>Da: bbolker at gmail.com
>>Data: 26/02/2013 23.40
>>A: <r-sig-mixed-models at r-project.org>
>>Ogg: Re: [R-sig-ME] GLMM family=binomial, link identity
>>
>>maggenga at ... <maggenga at ...> writes:
>>
>>> 
>>> Hi,
>>> I'm phd student in medical statistics.
>>> I would like know the R-way to perform the identity link 
(family=binomial) 
>in
>>lmer (ade4 package).
>>
>>  How about
>>
>>glmer(...,family=binomial(link="identity")) 
>>
>>?
>>
>>See ?family in base R.
>>
>>Warning: this is likely to be fragile (as fitting with non-standard
>>link functions often is).
>>
>>_______________________________________________
>>R-sig-mixed-models at r-project.org mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>


From bbolker at gmail.com  Wed Feb 27 01:55:53 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 26 Feb 2013 19:55:53 -0500
Subject: [R-sig-ME] R: Re:  GLMM family=binomial, link identity
In-Reply-To: <6753109.16265201361919439233.JavaMail.defaultUser@defaultHost>
References: <6753109.16265201361919439233.JavaMail.defaultUser@defaultHost>
Message-ID: <512D5999.3000504@gmail.com>

On 13-02-26 05:57 PM, maggenga at libero.it wrote:
> Sorry, i was wrong. I want say lme4 package.
> 
> 
> But "glmer(...,family=binomial(link="identity")) " give me same results
> 
> as
> 
> "glmer(...,family=binomial(link="logit")) "
> 
> Why?
> 
> I want interpret the coefficients as risk difference and not OR
> 
> Thank you very much
> 
> Davide

[cc'ing back to r-sig-mixed-models: it's best to keep these
conversations on-list]

  It's hard to say without a reproducible example
<http://tinyurl.com/reproducible-000>.  I made up an example that seemed
to work, sort of -- at least it showed that I do *not* get the same
results.  With the stable version of lme4, the fit worked with the
default (logit) link and failed with the identity link (although
apparently for reasons of numerical instability, not because it's
impossible to fit such models).  With the development version (latest
version from github), both worked, and the identity link results seem to
have correctly estimated the parameters (I can tell because the data
were simulated).

See

http://rpubs.com/bbolker/4671

> 
> 
> 
>> ----Messaggio originale----
>> Da: bbolker at gmail.com
>> Data: 26/02/2013 23.40
>> A: <r-sig-mixed-models at r-project.org>
>> Ogg: Re: [R-sig-ME] GLMM family=binomial, link identity
>>
>> maggenga at ... <maggenga at ...> writes:
>>
>>>
>>> Hi,
>>> I'm phd student in medical statistics.
>>> I would like know the R-way to perform the identity link (family=binomial) 
> in
>> lmer (ade4 package).
>>
>>  How about
>>
>> glmer(...,family=binomial(link="identity")) 
>>
>> ?
>>
>> See ?family in base R.
>>
>> Warning: this is likely to be fragile (as fitting with non-standard
>> link functions often is).
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
> 
>


From s.palacio at ipe.csic.es  Wed Feb 27 12:48:48 2013
From: s.palacio at ipe.csic.es (PALACIO BLASCO, SARA)
Date: Wed, 27 Feb 2013 12:48:48 +0100
Subject: [R-sig-ME] lme4,
	error inserting nested structure of fixed factors in glmer
Message-ID: <20130227124848.Horde.77icNzp6yHZRLfKgDUv1ELA@webmail.csic.es>


Dear List Members,

I do not know how to specify a nested structure of fixed factors in  
glmer. All the previous help messages I have found about nested  
factors in lme4 relate to ?random? factors, but I need my ?fixed?  
terms to be nested. I have a data set of 1386 observations with the  
following structure:
-	binary response variable: ?Dead? = bud survival, either dead (1) or  
alive (0)
-	Fixed factor: ?fTreatment?, numerical factor with 9 different levels
-	Fixed factor: ?fBud_type?, categorical factor with 3 levels
-	Fixed factor ?Species? (categorical) nested within ?fBud_type?, with  
9 levels
-	Random factor ?fRep?, numerical, nested within ?Species?, with 24  
levels (i.e. coded sequentially to avoid confusion).

The model I want to run is:

M_bud_type1=glmer(Dead~fTreatment* fBud_type * fBud_type|Species +  
(1|fRep), family=binomial, data=species)

Note I do not know how to specify the nested nature of ?Species?  
within ?Bud_type? in glmer so I have used the notation that I would  
use for random models but it may not be valid.

Trying to run this model produces the following error:

Error in mer_finalize(ans) : Downdated X'X is not positive definite, 1.

I have read in previous help messages from R lists that this error is  
related to fixed-effects specification being rank deficient. I  
understand such rank deficiencies are due to singularities in the  
fixed effects matrix, i.e. the fact that since ?species? is nested  
within ?bud_type?, not all species show all bud_types. I presume that  
the way to solve this issue may be specifying the nested nature of  
?species? but none of the codes I try seem to work, i.e. I have  
unsuccessfully tried the following:

M_bud_type1=glmer(Dead~fTreatment* fBud_type * fBud_type:Species +  
(1|fRep), family=binomial, data=species)

M_bud_type1=glmer(Dead~fTreatment* fBud_type * fBud_type/Species +  
(1|fRep), family=binomial, data=species)

M_bud_type1=glmer(Dead~fTreatment* fBud_type * Species%in%fBud_type +  
(1|fRep), family=binomial, data=species)

I know the issue is with the combination of ?fBud_type? and ?Species?  
as fixed factors, since when I run the model with each of the two  
factors alone or with ?Species? as a random factor it works fine.  
However, this does not solve my problems since I am interested in the  
significance of ?Species? as a factor.

Any indications as to how to proceed will be deeply appreciated

Sara Palacio


From s.palacio at ipe.csic.es  Wed Feb 27 14:49:01 2013
From: s.palacio at ipe.csic.es (PALACIO BLASCO, SARA)
Date: Wed, 27 Feb 2013 14:49:01 +0100
Subject: [R-sig-ME] lme4,
 error inserting nested structure of fixed factors in glmer
In-Reply-To: <20130227133221.GA14908@laboinfo-063.pharmacie.univ-paris5.fr>
References: <20130227124848.Horde.77icNzp6yHZRLfKgDUv1ELA@webmail.csic.es>
	<20130227133221.GA14908@laboinfo-063.pharmacie.univ-paris5.fr>
Message-ID: <20130227144901.Horde.whrwJjp6yHZRLg7NGv9TyZA@webmail.csic.es>


Dear Emmanuel,

Thanks a lot for your response. I, however, do not think the full  
model (i.e. "*" instead of "+") is the issue here, since I tried with  
the simplified model before and it rendered the same error message as  
the full factorial one...

Thanks in any case for your help!

Best regards,

Sara

> Dear Sara,
>
> ? -	binary response variable: ?Dead? = bud survival, either dead (1)
> ? or alive (0)
> ? -	Fixed factor: ?fTreatment?, numerical factor with 9 different levels
> ? -	Fixed factor: ?fBud_type?, categorical factor with 3 levels
> ? -	Fixed factor ?Species? (categorical) nested within ?fBud_type?,
> ? with 9 levels
> ? -	Random factor ?fRep?, numerical, nested within ?Species?, with 24
> ? levels (i.e. coded sequentially to avoid confusion).
> ?
> ? The model I want to run is:
> ?
> ? M_bud_type1=glmer(Dead~fTreatment* fBud_type * fBud_type|Species +
> ? (1|fRep), family=binomial, data=species)
>
> Are you sure you want this model and not
>
> M_bud_type1=glmer(Dead~fTreatment + fBud_type + fBud_type|Species +
> 		  (1|fRep), family=binomial, data=species)
>
> I guess you're problem comes from the a*b which stands for a+b+a:b,
> then coupling with more than two variables and interaction/nesting
> terms makes a not very clear formula.
>
> Try specifying only main effects and suited interactions, using either
> of the three syntaxes, and it my work better.
>
> Hope this helps,
>
> Best regards
>
> PS: this issue exists in all kinds of models, including
> lm/glm/lmer/lme...
>
>
> --
>                                 Emmanuel CURIS
>                                 emmanuel.curis at parisdescartes.fr
>
> Page WWW: http://emmanuel.curis.online.fr/index.html


From juwb08 at hampshire.edu  Wed Feb 27 20:30:08 2013
From: juwb08 at hampshire.edu (juwb08 at hampshire.edu)
Date: Wed, 27 Feb 2013 14:30:08 -0500
Subject: [R-sig-ME] Dispersion parameter calculation for Poisson glmer
Message-ID: <20130227143008.Horde.uJUIDfrBk2lRLl7AdskxMcA@webmail.hampshire.edu>

Hi All,

I would like to calculate a dispersion parameter for a glmer with a  
Poisson family (in lme4). I found a function posted on this mailing  
list that had been suggested to use for calculating a dispersion  
parameter for a glmer with a binomial family. (Found on   
https://stat.ethz.ch/pipermail/r-sig-mixed-models/2011q1/015383.html )

dispersion_glmer <- function(modelglmer)
	{n <- length(modelglmer at resid)
	return(sqrt( sum(c(modelglmer at resid, modelglmer at u)^2)/n))
	}

Am I allowed to use this for a Poisson glmer as well?

Thanks a bunch,

Justin Baldwin


From bbolker at gmail.com  Wed Feb 27 23:31:16 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 27 Feb 2013 22:31:16 +0000 (UTC)
Subject: [R-sig-ME] Dispersion parameter calculation for Poisson glmer
References: <20130227143008.Horde.uJUIDfrBk2lRLl7AdskxMcA@webmail.hampshire.edu>
Message-ID: <loom.20130227T232852-438@post.gmane.org>

 <juwb08 at ...> writes:

> 
> Hi All,
> 
> I would like to calculate a dispersion parameter for a glmer with a  
> Poisson family (in lme4). I found a function posted on this mailing  
> list that had been suggested to use for calculating a dispersion  
> parameter for a glmer with a binomial family. (Found on   
> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2011q1/015383.html )
> 

 [snip]

  Please see slightly more robust code at

http://glmm.wikidot.com/faq#overdispersion_est

It should be applicable to GLMMs generally, although please note all the
boldface warnings about this being a crude approximation of the
overdispersion parameter.


From bates at stat.wisc.edu  Wed Feb 27 23:57:58 2013
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 27 Feb 2013 16:57:58 -0600
Subject: [R-sig-ME] Dispersion parameter calculation for Poisson glmer
In-Reply-To: <loom.20130227T232852-438@post.gmane.org>
References: <20130227143008.Horde.uJUIDfrBk2lRLl7AdskxMcA@webmail.hampshire.edu>
	<loom.20130227T232852-438@post.gmane.org>
Message-ID: <CAO7JsnQQgFfECL7RkiBcWfsXaj--2E7Y8RanAxcpbXA-TSwofw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130227/514d72a4/attachment.pl>

From r.turner at auckland.ac.nz  Thu Feb 28 00:18:26 2013
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Thu, 28 Feb 2013 12:18:26 +1300
Subject: [R-sig-ME] Dispersion parameter calculation for Poisson glmer
In-Reply-To: <CAO7JsnQQgFfECL7RkiBcWfsXaj--2E7Y8RanAxcpbXA-TSwofw@mail.gmail.com>
References: <20130227143008.Horde.uJUIDfrBk2lRLl7AdskxMcA@webmail.hampshire.edu>
	<loom.20130227T232852-438@post.gmane.org>
	<CAO7JsnQQgFfECL7RkiBcWfsXaj--2E7Y8RanAxcpbXA-TSwofw@mail.gmail.com>
Message-ID: <512E9442.2000609@auckland.ac.nz>

On 02/28/2013 11:57 AM, Douglas Bates wrote:
>
> As you know, my opinion is that you can approximate it [the overdispersion parameter] however you want
> because it doesn't exist :-)
>

I would like to nominate this as a fortune!

     cheers,

         Rolf


From ross at biostat.ucsf.edu  Thu Feb 28 00:31:26 2013
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Wed, 27 Feb 2013 15:31:26 -0800
Subject: [R-sig-ME] glmer:  Downdated X'X is not positive definite
In-Reply-To: <loom.20130225T031849-152@post.gmane.org>
References: <5127FA87.9030707@biostat.ucsf.edu>
	<1361742542.25712.30.camel@corn.betterworld.us>
	<loom.20130225T031849-152@post.gmane.org>
Message-ID: <512E974E.8010105@biostat.ucsf.edu>

On 2/24/2013 6:20 PM, Ben Bolker wrote:
> Ross Boylan <ross at ...> writes:
>
>   [snip]
>
>> Ben Bolker wrote
>>> It is indeed a little surprising (to me) that you're getting
>>> downdating problems with an intercept-only model.
>>>     Hard to say without a closer look at the data.
>>>     I know it won't solve your problem, but does fitting the model
>>> _without_ the singleton clusters work?
>    I didn't mean without the clusters, I meant dropping the singleton
> clusters from the data ...
>
Oops.  Good question.  No, it didn't help.  I had trouble getting the 
development version, detailed in a separate message.
Ross


From ross at biostat.ucsf.edu  Thu Feb 28 00:48:21 2013
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Wed, 27 Feb 2013 15:48:21 -0800
Subject: [R-sig-ME] Trouble getting development version of lme4
Message-ID: <512E9B45.6080802@biostat.ucsf.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130227/84c83b2d/attachment.pl>

From ross at biostat.ucsf.edu  Thu Feb 28 02:01:08 2013
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Wed, 27 Feb 2013 17:01:08 -0800
Subject: [R-sig-ME] Trouble getting development version of lme4/problem
	w/CRAN version
In-Reply-To: <512E9B45.6080802@biostat.ucsf.edu>
References: <512E9B45.6080802@biostat.ucsf.edu>
Message-ID: <512EAC54.1090007@biostat.ucsf.edu>

On 2/27/2013 3:48 PM, Ross Boylan wrote:
> it appears lme4 was mostly removed, but there is still a dll there.  I 
> thought detach  unload was supposed to take care of that.
I guess the unload didn't succeed:
 > detach(unload=TRUE)
Warning message:
In .removeSuperclassBackRefs(cl, cldef, searchWhere) :
   could not find superclass "mMatrix" to clean up when removing 
subclass references to class "lmList.confint"

Is that a bug?
Ross


From ross at biostat.ucsf.edu  Thu Feb 28 02:32:04 2013
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Wed, 27 Feb 2013 17:32:04 -0800
Subject: [R-sig-ME] glmmADMB troubles
Message-ID: <512EB394.6070601@biostat.ucsf.edu>

It seems it's one thing after another.  Ben suggested glmmADMB for 
poisson--actually for truncated poisson, but for now I'm just trying to 
get anything going.  Some of my count variables have 1, not 0 as a 
minimum, and some have a maximum too, e.g., all values >10 are reported 
as 10.

I was able to install it from r-forge, with a warning that it was build 
for 2.15.3.  But ...

> r <- glmmadmb(sexActs~(1|id), sexpartner)
Error in II[, ii] = II[, ii] + REmat$codes[[i]] :
   number of items to replace is not a multiple of replacement length
In addition: Warning messages:
1: In glmmadmb(sexActs ~ (1 | id), sexpartner) :
   NAs removed in constructing fixed-effect model frame: you should probably remove them manually, e.g. with na.omit()
2: In II[, ii] + REmat$codes[[i]] :
   longer object length is not a multiple of shorter object length

Figuring that its missing value handling might be off, I tried removing the missing values:
> r <- glmmadmb(sexActs~(1|id), sexpartner[!is.na(sexpartner$sexActs),])
Error in system(cmd, intern = intern, wait = wait | intern, show.output.on.console = wait,  :
   'C:/Program' not found
> traceback()
4: system(cmd, intern = intern, wait = wait | intern, show.output.on.console = wait,
        ...)
3: shell(cmd, invisible = TRUE, intern = !verbose)
2: run_bin(platform, bin_loc, file_name, cmdoptions, run, rm_binary = !use_tmp_dir,
        debug = debug, verbose = verbose)
1: glmmadmb(sexActs ~ (1 | id), sexpartner[!is.na(sexpartner$sexActs),
        ])
>

So that may have worked except for some problem with spaces in path names.


From ross at biostat.ucsf.edu  Thu Feb 28 02:37:39 2013
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Wed, 27 Feb 2013 17:37:39 -0800
Subject: [R-sig-ME] glmer: Downdated X'X is not positive definite
 [related to nAGQ]
In-Reply-To: <512E974E.8010105@biostat.ucsf.edu>
References: <5127FA87.9030707@biostat.ucsf.edu>
	<1361742542.25712.30.camel@corn.betterworld.us>
	<loom.20130225T031849-152@post.gmane.org>
	<512E974E.8010105@biostat.ucsf.edu>
Message-ID: <512EB4E3.8080705@biostat.ucsf.edu>

On 2/27/2013 3:31 PM, Ross Boylan wrote:
> On 2/24/2013 6:20 PM, Ben Bolker wrote:
>> Ross Boylan <ross at ...> writes:
>>
>>   [snip]
>>
>>> Ben Bolker wrote
>>>> It is indeed a little surprising (to me) that you're getting
>>>> downdating problems with an intercept-only model.
>>>>     Hard to say without a closer look at the data.
>>>>     I know it won't solve your problem, but does fitting the model
>>>> _without_ the singleton clusters work?
>>    I didn't mean without the clusters, I meant dropping the singleton
>> clusters from the data ...
>>
> Oops.  Good question.  No, it didn't help.  I had trouble getting the 
> development version, detailed in a separate message.
> Ross
I discovered that omitting the nAGQ argument is sufficient to avoid the 
error.  I also tried nAGQ=5 and removing the missing data in advance; 
neither eliminated the downdating error.

> r2 <- glmer(sexActs~(1|id), data=sexpartner, family=poisson())

> r2 <- glmer(sexActs~(1|id), data=sexpartner, family=poisson(), nAGQ=5)

Error in mer_finalize(ans) : Downdated X'X is not positive definite, 1.

The error message sounds as if it is just a function of the input 
covariates, which obviously don't change when I change nAGQ.  My 
interpretation of X in the error message may be wrong.

This is with the version of lme4 from CRAN.

Ross


From bbolker at gmail.com  Thu Feb 28 04:41:10 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 28 Feb 2013 03:41:10 +0000 (UTC)
Subject: [R-sig-ME]
	=?utf-8?q?Trouble_getting_development_version_of_lme4/?=
	=?utf-8?q?problem=09w/CRAN_version?=
References: <512E9B45.6080802@biostat.ucsf.edu>
	<512EAC54.1090007@biostat.ucsf.edu>
Message-ID: <loom.20130228T043754-747@post.gmane.org>

Ross Boylan <ross at ...> writes:

> 
> On 2/27/2013 3:48 PM, Ross Boylan wrote:
> > it appears lme4 was mostly removed, but there is still a dll there.  I 
> > thought detach  unload was supposed to take care of that.
> I guess the unload didn't succeed:
>  > detach(unload=TRUE)
> Warning message:
> In .removeSuperclassBackRefs(cl, cldef, searchWhere) :
>    could not find superclass "mMatrix" to clean up when removing 
> subclass references to class "lmList.confint"
> 
> Is that a bug?
> Ross
> 

  You mean detach("package:lme4",unload=TRUE) ?

This is a known issue:

https://github.com/lme4/lme4/issues/16

 As far as I know, this is simply an annoying warning -- I have
never noticed any substantive side effects.  If you have anything
to add (e.g. if it does have side effects for you), please feel
free to comment on the issue at the URL above.

  Ben Bolker


From bbolker at gmail.com  Thu Feb 28 04:42:41 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 28 Feb 2013 03:42:41 +0000 (UTC)
Subject: [R-sig-ME] Dispersion parameter calculation for Poisson glmer
References: <20130227143008.Horde.uJUIDfrBk2lRLl7AdskxMcA@webmail.hampshire.edu>
	<loom.20130227T232852-438@post.gmane.org>
	<CAO7JsnQQgFfECL7RkiBcWfsXaj--2E7Y8RanAxcpbXA-TSwofw@mail.gmail.com>
	<512E9442.2000609@auckland.ac.nz>
Message-ID: <loom.20130228T044138-833@post.gmane.org>

Rolf Turner <r.turner at ...> writes:

> 
> On 02/28/2013 11:57 AM, Douglas Bates wrote:
> >
> > As you know, my opinion is that you can approximate it [the overdispersion
parameter] however you want
> > because it doesn't exist 
> >
> 
> I would like to nominate this as a fortune!

  It's more likely to happen if you contact Achim Zeleis,
the maintainer of the fortunes package ... I don't think
he follows this list.

  Ben Bolker


From bbolker at gmail.com  Thu Feb 28 04:59:47 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 28 Feb 2013 03:59:47 +0000 (UTC)
Subject: [R-sig-ME] Trouble getting development version of lme4
References: <512E9B45.6080802@biostat.ucsf.edu>
Message-ID: <loom.20130228T045225-394@post.gmane.org>

Ross Boylan <ross at ...> writes:

> 
> Running on Windows 7, R 2.15.2, I have been unable to get the 
> development version of lme4 working.  I'd appreciate any assistance.
> 
> Following the instructions at http://lme4.r-forge.r-project.org/
> 
>  1.
> 
>     install.packages("lme4",repos="http://r-forge.r-project.org")
>     Installing package(s) into
'c:/Users/rdboylan/Documents/R/R-2.15.2/site-library'
>     (as 'lib' is unspecified)
>     Warning message:
>     package 'lme4' is not available (for R version 2.15.2)
> 
>  2.
> 
>     install.packages("lme4",repos="http://lme4.r-forge.r-project.org/repos")

 [snip] 
>     Warning: dependencies 'minqa', 'Rcpp', 'RcppEigen' are not available
> 
>        There is a binary version available (and will be installed) but the
>        source version is later:
>                  binary        source
>     lme4 0.999902344-0 0.999902345-0
> 
>     Warning: dependencies 'minqa', 'Rcpp', 'RcppEigen' are not available

 [snip]

>     Content type 'application/zip' length 2027695 bytes (1.9 Mb)
>     opened URL
>     downloaded 1.9 Mb
> 
>     package 'lme4' successfully unpacked and MD5 sums checked
>     Warning: cannot remove prior installation of package 'lme4
> ## I had installed the one from CRAN, but detached and unloaded 
> it before attempting installation
>     # Do I need to manually delete the existing install?

  You shouldn't need to.  Normally this happens when the package
is still loaded while you're trying to install, but ...

> 
>  3. Then I tried to get the dependencies listed above from CRAN. This
>     mostly worked, but
> 
>     package 'minga' is not available (for R version 2.15.2)
> 
>  4. The end result:
> 
>     > library(lme4)
>     Error in library(lme4) : there is no package called 'lme4'
> 
>     Despite the message in 2, it appears lme4 was mostly removed, but
>     there is still a dll there.  I thought detach  unload was supposed
>     to take care of that.
> 
> My guess is exiting ESS and deleting the installed lme4 files will fix 
> some of the problems, but it looks as if one required package, minga, is 
> unavailable.

   Well, the major problem with this is that the package is called
'minqa', not 'minga'.

  I do apologize that things are a bit of a mess right now; we've
been having trouble with the R-forge build because of some version/
dependency problems with Rcpp.

  A couple of general thoughts:

 * development is now happening on github.  If you want to install
the very latest version, and have the tools for compiling for source,
try

install.packages(c("Rcpp","RcppEigen","minqa","devtools"))
library("devtools")
install_github("lme4",user="lme4")

  Do please let us/me know, if you try it, whether that works
and/or whether you encounter problems. 

  In general for installing from R-forge but wanting to be
able to get the dependencies from CRAN as well:

 install.packages("lme4",repos=c("http://r-forge.r-project.org",
      getOption("repos")))

  In the very near future we hope to 
(1) build some updated binaries and put them up at 
http://lme4.r-forge.r-project.org/repos
(2) update the installation instructions (we may stop referring
to the automatically built r-forge binaries, since these will
start falling behind the version on github)

  Ben Bolker


From bbolker at gmail.com  Thu Feb 28 05:05:16 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 28 Feb 2013 04:05:16 +0000 (UTC)
Subject: [R-sig-ME] glmmADMB troubles
References: <512EB394.6070601@biostat.ucsf.edu>
Message-ID: <loom.20130228T050019-868@post.gmane.org>

Ross Boylan <ross at ...> writes:

> 
> It seems it's one thing after another.  Ben suggested glmmADMB for 
> poisson--actually for truncated poisson, but for now I'm just trying to 
> get anything going.  Some of my count variables have 1, not 0 as a 
> minimum, and some have a maximum too, e.g., all values >10 are reported 
> as 10.

  If you have enough data to make it worthwhile, you might try the
'ordinal' package ...

> 
> I was able to install it from r-forge, with a warning that it was build 
> for 2.15.3.  But ...
> 
> > r <- glmmadmb(sexActs~(1|id), sexpartner)
> Error in II[, ii] = II[, ii] + REmat$codes[[i]] :
>    number of items to replace is not a multiple of replacement length
> In addition: Warning messages:
> 1: In glmmadmb(sexActs ~ (1 | id), sexpartner) :
>    NAs removed in constructing fixed-effect model frame: you should probably
remove them manually, e.g.
> with na.omit()
> 2: In II[, ii] + REmat$codes[[i]] :
>    longer object length is not a multiple of shorter object length
> 
> Figuring that its missing value handling might be off, I tried removing the
missing values:
> > r <- glmmadmb(sexActs~(1|id), sexpartner[!is.na(sexpartner$sexActs),])
> Error in system(cmd, intern = intern, wait = wait | intern,
show.output.on.console = wait,  :
>    'C:/Program' not found
> > traceback()
> 4: system(cmd, intern = intern, wait = wait | intern, show.output.on.console =
wait,
>         ...)
> 3: shell(cmd, invisible = TRUE, intern = !verbose)
> 2: run_bin(platform, bin_loc, file_name, cmdoptions, run, rm_binary =
!use_tmp_dir,
>         debug = debug, verbose = verbose)
> 1: glmmadmb(sexActs ~ (1 | id), sexpartner[!is.na(sexpartner$sexActs),
>         ])

   Hmmm.  Can you give

* the results of sessionInfo()
* the results of trying your command with debug=TRUE ?
* the results of glmmADMB:::get_bin_loc() ?

 Ben Bolker


  Ben


From r.turner at auckland.ac.nz  Thu Feb 28 05:30:27 2013
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Thu, 28 Feb 2013 17:30:27 +1300
Subject: [R-sig-ME] Dispersion parameter calculation for Poisson glmer
In-Reply-To: <loom.20130228T044138-833@post.gmane.org>
References: <20130227143008.Horde.uJUIDfrBk2lRLl7AdskxMcA@webmail.hampshire.edu>
	<loom.20130227T232852-438@post.gmane.org>
	<CAO7JsnQQgFfECL7RkiBcWfsXaj--2E7Y8RanAxcpbXA-TSwofw@mail.gmail.com>
	<512E9442.2000609@auckland.ac.nz>
	<loom.20130228T044138-833@post.gmane.org>
Message-ID: <512EDD63.2050303@auckland.ac.nz>


Please see end of post.

On 02/28/2013 04:42 PM, Ben Bolker wrote:
> Rolf Turner <r.turner at ...> writes:
>
>> On 02/28/2013 11:57 AM, Douglas Bates wrote:
>>> As you know, my opinion is that you can approximate it [the overdispersion
> parameter] however you want
>>> because it doesn't exist
>>>
>> I would like to nominate this as a fortune!
>    It's more likely to happen if you contact Achim Zeleis,
> the maintainer of the fortunes package ... I don't think
> he follows this list.

If you check my email I believe that you will find that I cc-ed Achim 
Zeleis.

     cheers,

         Rolf


From john.maindonald at anu.edu.au  Thu Feb 28 01:52:23 2013
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Thu, 28 Feb 2013 11:52:23 +1100
Subject: [R-sig-ME] Dispersion parameter calculation for Poisson glmer;
	PS
In-Reply-To: <CAO7JsnQQgFfECL7RkiBcWfsXaj--2E7Y8RanAxcpbXA-TSwofw@mail.gmail.com>
References: <20130227143008.Horde.uJUIDfrBk2lRLl7AdskxMcA@webmail.hampshire.edu>
	<loom.20130227T232852-438@post.gmane.org>
	<CAO7JsnQQgFfECL7RkiBcWfsXaj--2E7Y8RanAxcpbXA-TSwofw@mail.gmail.com>
Message-ID: <7A4C9200-C0AA-427D-B834-54F6D71DE36B@anu.edu.au>

I do have a more cryptic response!  On most days, I do not believe that binomial
and poisson errors exist!

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.
http://www.maths.anu.edu.au/~johnm

On 28/02/2013, at 9:57 AM, Douglas Bates <bates at stat.wisc.edu> wrote:

> On Wed, Feb 27, 2013 at 4:31 PM, Ben Bolker <bbolker at gmail.com> wrote:
> 
>> <juwb08 at ...> writes:
>> 
>>> 
>>> Hi All,
>>> 
>>> I would like to calculate a dispersion parameter for a glmer with a
>>> Poisson family (in lme4). I found a function posted on this mailing
>>> list that had been suggested to use for calculating a dispersion
>>> parameter for a glmer with a binomial family. (Found on
>>> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2011q1/015383.html )
>>> 
>> 
>> [snip]
>> 
>>  Please see slightly more robust code at
>> 
>> http://glmm.wikidot.com/faq#overdispersion_est
>> 
>> It should be applicable to GLMMs generally, although please note all the
>> boldface warnings about this being a crude approximation of the
>> overdispersion parameter.
>> 
> 
> As you know, my opinion is that you can approximate it however you want
> because it doesn't exist :-)
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From john.maindonald at anu.edu.au  Thu Feb 28 01:45:19 2013
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Thu, 28 Feb 2013 11:45:19 +1100
Subject: [R-sig-ME] Dispersion parameter calculation for Poisson glmer
In-Reply-To: <CAO7JsnQQgFfECL7RkiBcWfsXaj--2E7Y8RanAxcpbXA-TSwofw@mail.gmail.com>
References: <20130227143008.Horde.uJUIDfrBk2lRLl7AdskxMcA@webmail.hampshire.edu>
	<loom.20130227T232852-438@post.gmane.org>
	<CAO7JsnQQgFfECL7RkiBcWfsXaj--2E7Y8RanAxcpbXA-TSwofw@mail.gmail.com>
Message-ID: <A560F1BC-8AB4-499F-8789-BA8BF01F2F3C@anu.edu.au>

I think a response is in order!

Whether one believes in it or not, the variance ratio that the dispersion
estimate is designed to accommodate is, probably more often than not
with allegedly binomial or poisson errors, real.  The dispersion estimate
that can be obtained from glm() fits provides important clues, that users
ignore at peril to the credibility of the analysis.  In the common
situation where a dispersion substantially greater than 1 is identified,
the variance adjustment is a simple ad hoc recourse that generally
does a good job in allowing calculation of SEs that are plausible.  One
can set down models for which the dispersion variance correction is
pretty much right.  Sussing out the details of models that would lead
to something very close to the dispersion correction would surely be
a good PhD project.  

As an aside, I do not myself find what comes out of the magic world of 
negative binomial distributions more plausible than the way that I
understand the dispersion "correction". 

GLMMs with observation level random effects are another way to
handle the matter -- albeit the dispersion correction is different.
I have data where results for most species (there were quite a
number of species) suggested to me that a GLM type dispersion
correction did a better job than observation level random effects
in a GLMM.  This tentative conclusion does though need careful
checking.  If I live to be 99 with my faculties pretty much intact, 
maybe I will sometime make a stab at investigating further and 
writing it up.

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.
http://www.maths.anu.edu.au/~johnm

On 28/02/2013, at 9:57 AM, Douglas Bates <bates at stat.wisc.edu> wrote:

> On Wed, Feb 27, 2013 at 4:31 PM, Ben Bolker <bbolker at gmail.com> wrote:
> 
>> <juwb08 at ...> writes:
>> 
>>> 
>>> Hi All,
>>> 
>>> I would like to calculate a dispersion parameter for a glmer with a
>>> Poisson family (in lme4). I found a function posted on this mailing
>>> list that had been suggested to use for calculating a dispersion
>>> parameter for a glmer with a binomial family. (Found on
>>> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2011q1/015383.html )
>>> 
>> 
>> [snip]
>> 
>>  Please see slightly more robust code at
>> 
>> http://glmm.wikidot.com/faq#overdispersion_est
>> 
>> It should be applicable to GLMMs generally, although please note all the
>> boldface warnings about this being a crude approximation of the
>> overdispersion parameter.
>> 
> 
> As you know, my opinion is that you can approximate it however you want
> because it doesn't exist :-)
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From s.palacio at ipe.csic.es  Thu Feb 28 14:27:36 2013
From: s.palacio at ipe.csic.es (PALACIO BLASCO, SARA)
Date: Thu, 28 Feb 2013 14:27:36 +0100
Subject: [R-sig-ME] Nested fixed factors in glmer: Error in
 mer_finalize(ans) : Downdated X'X is not positive definite, 1.
Message-ID: <20130228142736.Horde._I9sMTp6yHZRL1tIEiZn86A@webmail.csic.es>


Dear All,

Maybe this is a trivial question but: how can I specify a nested  
structured of fixed factors in glmer?

I still haven't found a way to solve the issues explained in my  
previous e-mail.

Thanks for your help,

Sara Palacio


From Hugo.Mildenberger at web.de  Thu Feb 28 14:46:46 2013
From: Hugo.Mildenberger at web.de (Hugo.Mildenberger at web.de)
Date: Thu, 28 Feb 2013 14:46:46 +0100
Subject: [R-sig-ME] Nested fixed factors in glmer: Error in
 mer_finalize(ans) : Downdated X'X is not positive definite, 1.
In-Reply-To: <20130228142736.Horde._I9sMTp6yHZRL1tIEiZn86A@webmail.csic.es>
References: <20130228142736.Horde._I9sMTp6yHZRL1tIEiZn86A@webmail.csic.es>
Message-ID: <20130228144646.1e56cff2963d8b48ea65f74b@zotac.lan>

On Thu, 28 Feb 2013 14:27:36 +0100
"PALACIO BLASCO, SARA" <s.palacio at ipe.csic.es> wrote:

> Maybe this is a trivial question but: how can I specify a nested  
> structured of fixed factors in glmer?
> 
> I still haven't found a way to solve the issues explained in my  
> previous e-mail.


Sara,

may be this fits your needs?

> a<-factor(c('a','b','c','d'))
> b<-factor(c('1','2'))
> interaction(a,b)
[1] a.1 b.2 c.1 d.2
Levels: a.1 b.1 c.1 d.1 a.2 b.2 c.2 d.2


Best


From s.palacio at ipe.csic.es  Thu Feb 28 15:27:48 2013
From: s.palacio at ipe.csic.es (PALACIO BLASCO, SARA)
Date: Thu, 28 Feb 2013 15:27:48 +0100
Subject: [R-sig-ME] Nested fixed factors in glmer: Error in
 mer_finalize(ans) : Downdated X'X is not positive definite, 1.
In-Reply-To: <20130228144646.1e56cff2963d8b48ea65f74b@zotac.lan>
References: <20130228142736.Horde._I9sMTp6yHZRL1tIEiZn86A@webmail.csic.es>
	<20130228144646.1e56cff2963d8b48ea65f74b@zotac.lan>
Message-ID: <20130228152748.Horde.sahtazp6yHZRL2lkutZl4nA@webmail.csic.es>

Hi Hugo,

Thanks for your e-mails. The structure of my data is not the one in  
your examples but:

Factor 1: a,b,c
factor 2: 1,2,3,4,5,6

combination:
a.1, a.2, b.3, b.4, c.5, c.6

note factor 2 is nested within factor 1, so that not all levels of  
factor 2 are in every level of factor 1.
Hence I do not have a full factorial or crossed design but a hierarchical one.

My question: How can I include such a design in glmer?

Cheers,

Sara

Hugo.Mildenberger at web.de escribi?:

> On Thu, 28 Feb 2013 14:27:36 +0100
> "PALACIO BLASCO, SARA" <s.palacio at ipe.csic.es> wrote:
>
>> Maybe this is a trivial question but: how can I specify a nested
>> structured of fixed factors in glmer?
>>
>> I still haven't found a way to solve the issues explained in my
>> previous e-mail.
>
>
> Sara,
>
> may be this fits your needs?
>
>> a<-factor(c('a','b','c','d'))
>> b<-factor(c('1','2'))
>> interaction(a,b)
> [1] a.1 b.2 c.1 d.2
> Levels: a.1 b.1 c.1 d.1 a.2 b.2 c.2 d.2
>
>
> Best


From bates at stat.wisc.edu  Thu Feb 28 16:12:26 2013
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 28 Feb 2013 09:12:26 -0600
Subject: [R-sig-ME] Dispersion parameter calculation for Poisson glmer
In-Reply-To: <A560F1BC-8AB4-499F-8789-BA8BF01F2F3C@anu.edu.au>
References: <20130227143008.Horde.uJUIDfrBk2lRLl7AdskxMcA@webmail.hampshire.edu>
	<loom.20130227T232852-438@post.gmane.org>
	<CAO7JsnQQgFfECL7RkiBcWfsXaj--2E7Y8RanAxcpbXA-TSwofw@mail.gmail.com>
	<A560F1BC-8AB4-499F-8789-BA8BF01F2F3C@anu.edu.au>
Message-ID: <CAO7JsnSn2wkbtcrgdaOkEFZx=9_4NQkVfa=aNKKS9X+L4WB+uw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130228/f2b90354/attachment.pl>

From bates at stat.wisc.edu  Thu Feb 28 16:37:14 2013
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 28 Feb 2013 09:37:14 -0600
Subject: [R-sig-ME] Nested fixed factors in glmer: Error in
 mer_finalize(ans) : Downdated X'X is not positive definite, 1.
In-Reply-To: <20130228152748.Horde.sahtazp6yHZRL2lkutZl4nA@webmail.csic.es>
References: <20130228142736.Horde._I9sMTp6yHZRL1tIEiZn86A@webmail.csic.es>
	<20130228144646.1e56cff2963d8b48ea65f74b@zotac.lan>
	<20130228152748.Horde.sahtazp6yHZRL2lkutZl4nA@webmail.csic.es>
Message-ID: <CAO7JsnRygbwtpx=ok2193PwoyhvHNLWt-R=-DwKKc75AmrzB5Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130228/043635d6/attachment.pl>

From v_coudrain at voila.fr  Thu Feb 28 17:24:35 2013
From: v_coudrain at voila.fr (v_coudrain at voila.fr)
Date: Thu, 28 Feb 2013 17:24:35 +0100 (CET)
Subject: [R-sig-ME] Partial effects in mixed models
Message-ID: <1833112284.279581362068675542.JavaMail.www@wwinf7139>

Dear all,

I would like to test the effect of an explanatory variable after removing the effect of another one. I thought about calculating the model with the first explanatory 
variable only, then take the model residuals and use the residuals as response variable to test the effect of the second explanatory variable. However, I do not 
know if this is possible for a model containing random effects. Maybe it doesn't make sense anyway, but if it is possible, should I include the random effects in the 
second model (residuals as response variable) or not, since variance explained by random effects should also have been accounted for in the first model?

Thank you for your help

Val?rie
___________________________________________________________
Alain Delon horrifi? et d?vast? de tristesse ! Mais pour quelle raison ? ? lire sur Voila.fr http://people.voila.fr/people/actu-stars/tv-cine-musique/alain-delon-horrifie-et-devaste-de-tristesse-repond-a-son-fils-people_9663.html


From ross at biostat.ucsf.edu  Thu Feb 28 19:15:41 2013
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Thu, 28 Feb 2013 10:15:41 -0800
Subject: [R-sig-ME] glmmADMB troubles
In-Reply-To: <loom.20130228T050019-868@post.gmane.org>
References: <512EB394.6070601@biostat.ucsf.edu>
	<loom.20130228T050019-868@post.gmane.org>
Message-ID: <512F9ECD.2090905@biostat.ucsf.edu>

On 2/27/2013 8:05 PM, Ben Bolker wrote:
> Ross Boylan <ross at ...> writes:
>
>> It seems it's one thing after another.  Ben suggested glmmADMB for
>> poisson--actually for truncated poisson, but for now I'm just trying to
>> get anything going.  Some of my count variables have 1, not 0 as a
>> minimum, and some have a maximum too, e.g., all values >10 are reported
>> as 10.
>    If you have enough data to make it worthwhile, you might try the
> 'ordinal' package ...
Thanks for the pointer.  Does it make the proportional odds assumption?
>
>> I was able to install it from r-forge, with a warning that it was build
>> for 2.15.3.  But ...
>>
>>> r <- glmmadmb(sexActs~(1|id), sexpartner)
>> Error in II[, ii] = II[, ii] + REmat$codes[[i]] :
>>     number of items to replace is not a multiple of replacement length
>> In addition: Warning messages:
>> 1: In glmmadmb(sexActs ~ (1 | id), sexpartner) :
>>     NAs removed in constructing fixed-effect model frame: you should probably
> remove them manually, e.g.
>> with na.omit()
>> 2: In II[, ii] + REmat$codes[[i]] :
>>     longer object length is not a multiple of shorter object length
>>
>> Figuring that its missing value handling might be off, I tried removing the
> missing values:
>>> r <- glmmadmb(sexActs~(1|id), sexpartner[!is.na(sexpartner$sexActs),])
>> Error in system(cmd, intern = intern, wait = wait | intern,
> show.output.on.console = wait,  :
>>     'C:/Program' not found
>>> traceback()
>> 4: system(cmd, intern = intern, wait = wait | intern, show.output.on.console =
> wait,
>>          ...)
>> 3: shell(cmd, invisible = TRUE, intern = !verbose)
>> 2: run_bin(platform, bin_loc, file_name, cmdoptions, run, rm_binary =
> !use_tmp_dir,
>>          debug = debug, verbose = verbose)
>> 1: glmmadmb(sexActs ~ (1 | id), sexpartner[!is.na(sexpartner$sexActs),
>>          ])
>     Hmmm.  Can you give
>
> * the results of sessionInfo()
> * the results of trying your command with debug=TRUE ?
> * the results of glmmADMB:::get_bin_loc() ?
>
>   Ben Bolker
>
>
I wasn't sure which command you wanted trace, and so I did both:

> library(glmmADMB)
Loading required package: MASS
Loading required package: R2admb

Attaching package: 'glmmADMB'

The following object(s) are masked from 'package:MASS':

     stepAIC

The following object(s) are masked from 'package:lme4':

     fixef, ranef

The following object(s) are masked from 'package:stats':

     step

Warning message:
package 'glmmADMB' was built under R version 2.15.3
> sessionInfo()
R version 2.15.2 (2012-10-26)
Platform: i386-w64-mingw32/i386 (32-bit)

locale:
[1] LC_COLLATE=English_United States.1252
[2] LC_CTYPE=English_United States.1252
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C
[5] LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] glmmADMB_0.7.4  R2admb_0.7.5.3  MASS_7.3-22     lme4_0.999999-0
[5] Matrix_1.0-10   lattice_0.20-10

loaded via a namespace (and not attached):
  [1] colorspace_1.2-0   compiler_2.15.2    dichromat_1.2-4    digest_0.6.0
  [5] ggplot2_0.9.3      grid_2.15.2        gtable_0.1.2       labeling_0.1
  [9] munsell_0.4        nlme_3.1-106       plyr_1.8           proto_0.3-10
[13] RColorBrewer_1.0-5 reshape2_1.2.2     scales_0.2.3       stats4_2.15.2
[17] stringr_0.6.2      tools_2.15.2
> r <- glmmadmb(sexActs~(1|id), sexpartner, debug=TRUE)
platform: windows 32
executable name: glmmadmb.exe
bin_loc: c:/Users/rdboylan/Documents/R/R-2.15.2/site-library/glmmADMB/bin/windows32/glmmadmb.exe
using temp directory C:\Users\rdboylan\AppData\Local\Temp\Rtmpy2JsMY\glmmADMB1708678a587a
creating temp directory
changed working directory to C:/Users/rdboylan/AppData/Local/Temp/Rtmpy2JsMY/glmmADMB1708678a587a
Error in II[, ii] = II[, ii] + REmat$codes[[i]] :
   number of items to replace is not a multiple of replacement length
In addition: Warning messages:
1: In glmmadmb(sexActs ~ (1 | id), sexpartner, debug = TRUE) :
   NAs removed in constructing fixed-effect model frame: you should probably remove them manually, e.g. with na.omit()
2: In II[, ii] + REmat$codes[[i]] :
   longer object length is not a multiple of shorter object length
# The previous message suggests to me that the NA was not systematically removed from the data, so
# different columns have different lengths
changed working directory to i:/LAMOC/Ross
removed temp directory C:\Users\rdboylan\AppData\Local\Temp\Rtmpy2JsMY\glmmADMB1708678a587a
> r <- glmmadmb(sexActs~(1|id), sexpartner[!is.na(sexpartner$sexActs),], debug=TRUE)
platform: windows 32
executable name: glmmadmb.exe
bin_loc: c:/Users/rdboylan/Documents/R/R-2.15.2/site-library/glmmADMB/bin/windows32/glmmadmb.exe
using temp directory C:\Users\rdboylan\AppData\Local\Temp\Rtmpy2JsMY\glmmADMB17085c19f4d
creating temp directory
changed working directory to C:/Users/rdboylan/AppData/Local/Temp/Rtmpy2JsMY/glmmADMB17085c19f4d
Command line: "c:/Users/rdboylan/Documents/R/R-2.15.2/site-library/glmmADMB/bin/windows32/glmmadmb.exe" -maxfn 500 -maxph 5 -noinit -shess
Error in system(cmd, intern = intern, wait = wait | intern, show.output.on.console = wait,  :
   'C:/Program' not found
changed working directory to i:/LAMOC/Ross
removed temp directory C:\Users\rdboylan\AppData\Local\Temp\Rtmpy2JsMY\glmmADMB17085c19f4d
> glmmADMB:::get_bin_loc()
$bin_loc
[1] "c:/Users/rdboylan/Documents/R/R-2.15.2/site-library/glmmADMB/bin/windows32/glmmadmb.exe"

$platform
[1] "windows"

P.S. about lme4; I don't have a build environment and so trying the 
github version will not be my first move.
Although perhaps lack of a build environment is why the second version 
is failing.  I do have cygwin installed, althoughI would not expect R to 
know how to find it.


From ross at biostat.ucsf.edu  Thu Feb 28 19:53:13 2013
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Thu, 28 Feb 2013 10:53:13 -0800
Subject: [R-sig-ME] Trouble getting development version of lme4
In-Reply-To: <loom.20130228T045225-394@post.gmane.org>
References: <512E9B45.6080802@biostat.ucsf.edu>
	<loom.20130228T045225-394@post.gmane.org>
Message-ID: <512FA799.4080308@biostat.ucsf.edu>

On 2/27/2013 7:59 PM, Ben Bolker wrote:
> Ross Boylan <ross at ...> writes:
>
>> Running on Windows 7, R 2.15.2, I have been unable to get the
>> development version of lme4 working.  I'd appreciate any assistance.
>>
>> Following the instructions at http://lme4.r-forge.r-project.org/
>>
>>   1.
>>
>>      install.packages("lme4",repos="http://r-forge.r-project.org")
>>      Installing package(s) into
> 'c:/Users/rdboylan/Documents/R/R-2.15.2/site-library'
>>      (as 'lib' is unspecified)
>>      Warning message:
>>      package 'lme4' is not available (for R version 2.15.2)
>>
>>   2.
>>
>>      install.packages("lme4",repos="http://lme4.r-forge.r-project.org/repos")
>   [snip]
>>      Warning: dependencies 'minqa', 'Rcpp', 'RcppEigen' are not available
>>
>>         There is a binary version available (and will be installed) but the
>>         source version is later:
>>                   binary        source
>>      lme4 0.999902344-0 0.999902345-0
>>
>>      Warning: dependencies 'minqa', 'Rcpp', 'RcppEigen' are not available
>   [snip]
>
>>      Content type 'application/zip' length 2027695 bytes (1.9 Mb)
>>      opened URL
>>      downloaded 1.9 Mb
>>
>>      package 'lme4' successfully unpacked and MD5 sums checked
>>      Warning: cannot remove prior installation of package 'lme4
>> ## I had installed the one from CRAN, but detached and unloaded
>> it before attempting installation
>>      # Do I need to manually delete the existing install?
>    You shouldn't need to.  Normally this happens when the package
> is still loaded while you're trying to install, but ...
>
>>   3. Then I tried to get the dependencies listed above from CRAN. This
>>      mostly worked, but
>>
>>      package 'minga' is not available (for R version 2.15.2)
>>
>>   4. The end result:
>>
>>      > library(lme4)
>>      Error in library(lme4) : there is no package called 'lme4'
>>
>>      Despite the message in 2, it appears lme4 was mostly removed, but
>>      there is still a dll there.  I thought detach  unload was supposed
>>      to take care of that.
>>
>> My guess is exiting ESS and deleting the installed lme4 files will fix
>> some of the problems, but it looks as if one required package, minga, is
>> unavailable.
>     Well, the major problem with this is that the package is called
> 'minqa', not 'minga'.
Well, that's a  good reason it didn't work!  Unfortunately, I still have 
problems with it, perhaps because minqa and lme4 are coming from 
different sources built against different versions of R.
I got minqa from
'http://r-forge.r-project.org/bin/windows/contrib/2.15/minqa_1.2.1.zip'
and lme4 from
'http://lme4.r-forge.r-project.org/repos/bin/windows/contrib/2.15/lme4_0.999902344-0.zip'
Neither is available on the other's repository.
Then
 > library(lme4)
Loading required package: lattice
Loading required package: Matrix
Error in inDL(x, as.logical(local), as.logical(now), ...) :
   unable to load shared object 
'c:/Users/rdboylan/Documents/R/R-2.15.2/site-library/minqa/libs/i386/minqa.dll':
   LoadLibrary failure:  Invalid access to memory location.

Error: package/namespace load failed for 'lme4'

BTW, ending the R session and exiting ess (but not emacs) did allow me 
to delete the residual old dll and install the new package.
>
>    I do apologize that things are a bit of a mess right now; we've
> been having trouble with the R-forge build because of some version/
> dependency problems with Rcpp.
>
>    A couple of general thoughts:
>
>   * development is now happening on github.  If you want to install
> the very latest version, and have the tools for compiling for source,
> try
>
> install.packages(c("Rcpp","RcppEigen","minqa","devtools"))
> library("devtools")
> install_github("lme4",user="lme4")
>
>    Do please let us/me know, if you try it, whether that works
> and/or whether you encounter problems.
>
>    In general for installing from R-forge but wanting to be
> able to get the dependencies from CRAN as well:
>
>   install.packages("lme4",repos=c("http://r-forge.r-project.org",
>        getOption("repos")))
>
>    In the very near future we hope to
> (1) build some updated binaries and put them up at
> http://lme4.r-forge.r-project.org/repos
That would be great.
> (2) update the installation instructions (we may stop referring
> to the automatically built r-forge binaries, since these will
> start falling behind the version on github)
The binaries are a great convenience.

The best news is that the CRAN version of lme4 seems able to do the 
poisson with my data as long as I don't specify nAGQ=.  Since my 
immediate concern is using this inside an imputation procedure, great 
precision is probably not that important.


From henrik.singmann at psychologie.uni-freiburg.de  Thu Feb 28 22:06:55 2013
From: henrik.singmann at psychologie.uni-freiburg.de (Henrik Singmann)
Date: Thu, 28 Feb 2013 22:06:55 +0100
Subject: [R-sig-ME] Nested fixed factors in glmer: Error in
 mer_finalize(ans) : Downdated X'X is not positive definite, 1.
In-Reply-To: <CAO7JsnRygbwtpx=ok2193PwoyhvHNLWt-R=-DwKKc75AmrzB5Q@mail.gmail.com>
References: <20130228142736.Horde._I9sMTp6yHZRL1tIEiZn86A@webmail.csic.es>
	<20130228144646.1e56cff2963d8b48ea65f74b@zotac.lan>
	<20130228152748.Horde.sahtazp6yHZRL2lkutZl4nA@webmail.csic.es>
	<CAO7JsnRygbwtpx=ok2193PwoyhvHNLWt-R=-DwKKc75AmrzB5Q@mail.gmail.com>
Message-ID: <512FC6EF.1000304@psychologie.uni-freiburg.de>

The gem below will be in the next version of the fortunes package (already in the R-Forge version, thanks to Achim Zeileis).

Cheers,
Henrik


Am 28.02.2013 16:37, schrieb Douglas Bates:
> I think that the formula language does allow expressions with '/' to
> represent nested factors but I can't check right now as there is a fire in
> the building where my office is located.  I prefer to simply write nested
> factors as
>
> factor1 + factor1:factor2

-- 
Dipl. Psych. Henrik Singmann
PhD Student
Albert-Ludwigs-Universit?t Freiburg, Germany
http://www.psychologie.uni-freiburg.de/Members/singmann


From slu at ccsr.uchicago.edu  Thu Feb 28 23:07:18 2013
From: slu at ccsr.uchicago.edu (Stuart Luppescu)
Date: Thu, 28 Feb 2013 16:07:18 -0600
Subject: [R-sig-ME] Data frame size limits in MCMCglmm?
In-Reply-To: <20130125103605.16911d1gwewajp5w@www.staffmail.ed.ac.uk>
References: <1358546146.11821.40.camel@musuko.uchicago.edu>
	<CANz9Z_+5BDbVWxUcv8y-bG9YtwB0593eNUREy=UMyBmHUOcivA@mail.gmail.com>
	<20130125103605.16911d1gwewajp5w@www.staffmail.ed.ac.uk>
Message-ID: <1362089238.14071.9.camel@musuko.uchicago.edu>

On Fri, 2013-01-25 at 10:36 +0000, Jarrod Hadfield wrote:
> Hi Stuart,
> 
> 2.4 million records is bigger than anything I've tried but in theory  
> it should run, or return an error if it can't allocate enough memory.
> It definitely shouldn't be seg-faulting.  If you could send a  
> reproducible example (preferably one where it fails quickly) I will  
> take a look into it.

I finally got around to doing this analysis on a 25% random sample. It
ran but took about 25 hours for 100,000 iterations. (Was that too many?)

Here are the results:

 Iterations = 3001:99991
 Thinning interval  = 10
 Sample size  = 9700 

 DIC: 1739944 

 G-structure:  ~tid

    post.mean l-95% CI u-95% CI eff.samp
tid    0.4597   0.4426   0.4754     7732

 R-structure:  ~units

      post.mean l-95% CI u-95% CI eff.samp
units         1        1        1        0

 Location effects: final.points ~ gr10 + gr11 + gr12 

            post.mean l-95% CI u-95% CI eff.samp  pMCMC    
(Intercept)    1.0179   1.0007   1.0347     6334 <1e-04 ***
gr10           0.3155   0.3033   0.3278     7514 <1e-04 ***
gr11           0.5825   0.5686   0.5959     7728 <1e-04 ***
gr12           0.7262   0.7121   0.7412     7390 <1e-04 ***
---
Signif. codes:  0 ????**??? 0.001 ????*??? 0.01 ??????? 0.05 ??????? 0.1
??? ??? 1 

 Cutpoints: 
                             post.mean l-95% CI u-95% CI eff.samp
cutpoint.traitfinal.points.1    0.9506   0.9459   0.9552     1458
cutpoint.traitfinal.points.2    1.9154   1.9097   1.9216     1092
cutpoint.traitfinal.points.3    2.9882   2.9807   2.9956     1096


The main reason I'm doing this analysis is to see if the results are
different with ordered category outcomes as opposed to treating the
outcome as numbers (which I've done with lmer). Does the fact that the
posterior means for the cutpoints are very close to the numerical values
mean that I am not gaining much by treating outcome as ordered
categories (and I can just use the results from lmer)?

Thanks.



-- 
Stuart Luppescu <slu at ccsr.uchicago.edu>
University of Chicago


From john.maindonald at anu.edu.au  Thu Feb 28 23:23:37 2013
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Fri, 1 Mar 2013 09:23:37 +1100
Subject: [R-sig-ME] Dispersion parameter calculation for Poisson glmer
In-Reply-To: <CAO7JsnSn2wkbtcrgdaOkEFZx=9_4NQkVfa=aNKKS9X+L4WB+uw@mail.gmail.com>
References: <20130227143008.Horde.uJUIDfrBk2lRLl7AdskxMcA@webmail.hampshire.edu>
	<loom.20130227T232852-438@post.gmane.org>
	<CAO7JsnQQgFfECL7RkiBcWfsXaj--2E7Y8RanAxcpbXA-TSwofw@mail.gmail.com>
	<A560F1BC-8AB4-499F-8789-BA8BF01F2F3C@anu.edu.au>
	<CAO7JsnSn2wkbtcrgdaOkEFZx=9_4NQkVfa=aNKKS9X+L4WB+uw@mail.gmail.com>
Message-ID: <AE8A2FAA-C8A4-4960-AD48-41D57DCEAFEA@anu.edu.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130301/15337805/attachment.pl>

From r.turner at auckland.ac.nz  Fri Mar  1 02:04:26 2013
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Fri, 01 Mar 2013 14:04:26 +1300
Subject: [R-sig-ME] Nested fixed factors in glmer: Error in
 mer_finalize(ans) : Downdated X'X is not positive definite, 1.
In-Reply-To: <20130228152748.Horde.sahtazp6yHZRL2lkutZl4nA@webmail.csic.es>
References: <20130228142736.Horde._I9sMTp6yHZRL1tIEiZn86A@webmail.csic.es>
	<20130228144646.1e56cff2963d8b48ea65f74b@zotac.lan>
	<20130228152748.Horde.sahtazp6yHZRL2lkutZl4nA@webmail.csic.es>
Message-ID: <512FFE9A.6050304@auckland.ac.nz>


Perhaps I am just obtuse (there are those who would say there is
no "perhaps" about it) but it seems to me that nesting of fixed effects
makes no sense.

In the example given below you have in effect a ***single*** factor
with six levels: a.1, a.2, b.3, b.4, c.5, c.6.  This really means that
you just have the second "nested" factor with levels 1, 2, 3, 4, 5, 6.
So just supply the second factor to the formula in the call to glmer()
and forget about the first factor entirely.  It is redundant when the
second factor is supplied.

You *can* use the formula y ~ f1/f2 or equivalently y ~ f1 + f1:f2
but you'll find that you wind up getting 12 coefficient estimates, six
of which are "NA".  The values of the six non-NA coefficients will
be identical with values of the six coefficient estimate that you get
from y ~ f2.

     cheers,

         Rolf Turner

On 03/01/2013 03:27 AM, PALACIO BLASCO, SARA wrote:
> Hi Hugo,
>
> Thanks for your e-mails. The structure of my data is not the one in 
> your examples but:
>
> Factor 1: a,b,c
> factor 2: 1,2,3,4,5,6
>
> combination:
> a.1, a.2, b.3, b.4, c.5, c.6
>
> note factor 2 is nested within factor 1, so that not all levels of 
> factor 2 are in every level of factor 1.
> Hence I do not have a full factorial or crossed design but a 
> hierarchical one.
>
> My question: How can I include such a design in glmer?
>
> Cheers,
>
> Sara
>
> Hugo.Mildenberger at web.de escribi?:
>
>> On Thu, 28 Feb 2013 14:27:36 +0100
>> "PALACIO BLASCO, SARA" <s.palacio at ipe.csic.es> wrote:
>>
>>> Maybe this is a trivial question but: how can I specify a nested
>>> structured of fixed factors in glmer?
>>>
>>> I still haven't found a way to solve the issues explained in my
>>> previous e-mail.
>>
>>
>> Sara,
>>
>> may be this fits your needs?
>>
>>> a<-factor(c('a','b','c','d'))
>>> b<-factor(c('1','2'))
>>> interaction(a,b)
>> [1] a.1 b.2 c.1 d.2
>> Levels: a.1 b.1 c.1 d.1 a.2 b.2 c.2 d.2
>>
>>
>> Best
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From r.turner at auckland.ac.nz  Fri Mar  1 02:02:07 2013
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Fri, 01 Mar 2013 14:02:07 +1300
Subject: [R-sig-ME] Nested fixed factors in glmer: Error in
 mer_finalize(ans) : Downdated X'X is not positive definite, 1.
In-Reply-To: <20130228152748.Horde.sahtazp6yHZRL2lkutZl4nA@webmail.csic.es>
References: <20130228142736.Horde._I9sMTp6yHZRL1tIEiZn86A@webmail.csic.es>
	<20130228144646.1e56cff2963d8b48ea65f74b@zotac.lan>
	<20130228152748.Horde.sahtazp6yHZRL2lkutZl4nA@webmail.csic.es>
Message-ID: <512FFE0F.7020809@auckland.ac.nz>


Perhaps I am just obtuse (there are those who would say there is
no "perhaps" about it) but it seems to me that nesting of fixed effects
makes no sense.

In the example given below you have in effect a ***single*** factor
with six levels: a.1, a.2, b.3, b.4, c.5, c.6.  This really means that
you just have the second "nested" factor with levels 1, 2, 3, 4, 5, 6.
So just supply the second factor to the formula in the call to glmer()
and forget about the first factor entirely.  It is redundant when the
second factor is supplied.

You *can* use the formula y ~ f1/f2 or equivalently y ~ f1 + f1:f2
but you'll find that you wind up getting 12 coefficient estimates, six
of which are "NA".  The values of the six non-NA coefficients will
be indentical with values of the six coefficient estimate that you get
from y ~ f2.

     cheers,

         Rolf Turner

On 03/01/2013 03:27 AM, PALACIO BLASCO, SARA wrote:
> Hi Hugo,
>
> Thanks for your e-mails. The structure of my data is not the one in 
> your examples but:
>
> Factor 1: a,b,c
> factor 2: 1,2,3,4,5,6
>
> combination:
> a.1, a.2, b.3, b.4, c.5, c.6
>
> note factor 2 is nested within factor 1, so that not all levels of 
> factor 2 are in every level of factor 1.
> Hence I do not have a full factorial or crossed design but a 
> hierarchical one.
>
> My question: How can I include such a design in glmer?
>
> Cheers,
>
> Sara
>
> Hugo.Mildenberger at web.de escribi?:
>
>> On Thu, 28 Feb 2013 14:27:36 +0100
>> "PALACIO BLASCO, SARA" <s.palacio at ipe.csic.es> wrote:
>>
>>> Maybe this is a trivial question but: how can I specify a nested
>>> structured of fixed factors in glmer?
>>>
>>> I still haven't found a way to solve the issues explained in my
>>> previous e-mail.
>>
>>
>> Sara,
>>
>> may be this fits your needs?
>>
>>> a<-factor(c('a','b','c','d'))
>>> b<-factor(c('1','2'))
>>> interaction(a,b)
>> [1] a.1 b.2 c.1 d.2
>> Levels: a.1 b.1 c.1 d.1 a.2 b.2 c.2 d.2
>>
>>
>> Best
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From A.Robinson at ms.unimelb.edu.au  Fri Mar  1 02:26:46 2013
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Fri, 1 Mar 2013 12:26:46 +1100
Subject: [R-sig-ME] Nested fixed factors in glmer: Error in
 mer_finalize(ans) : Downdated X'X is not positive definite, 1.
In-Reply-To: <512FFE0F.7020809@auckland.ac.nz>
References: <20130228142736.Horde._I9sMTp6yHZRL1tIEiZn86A@webmail.csic.es>
	<20130228144646.1e56cff2963d8b48ea65f74b@zotac.lan>
	<20130228152748.Horde.sahtazp6yHZRL2lkutZl4nA@webmail.csic.es>
	<512FFE0F.7020809@auckland.ac.nz>
Message-ID: <CAHyGmd5xD21a8B0Q7bgygWe4y4hnaF0xwXcEHDkMZy7Deaz4kA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130301/a530e752/attachment.pl>

From r.turner at auckland.ac.nz  Thu Feb 28 14:05:45 2013
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Fri, 01 Mar 2013 02:05:45 +1300
Subject: [R-sig-ME] Nested fixed factors in glmer: Error in
 mer_finalize(ans) : Downdated X'X is not positive definite, 1.
In-Reply-To: <CAHyGmd5xD21a8B0Q7bgygWe4y4hnaF0xwXcEHDkMZy7Deaz4kA@mail.gmail.com>
References: <20130228142736.Horde._I9sMTp6yHZRL1tIEiZn86A@webmail.csic.es>
	<20130228144646.1e56cff2963d8b48ea65f74b@zotac.lan>
	<20130228152748.Horde.sahtazp6yHZRL2lkutZl4nA@webmail.csic.es>
	<512FFE0F.7020809@auckland.ac.nz>
	<CAHyGmd5xD21a8B0Q7bgygWe4y4hnaF0xwXcEHDkMZy7Deaz4kA@mail.gmail.com>
Message-ID: <512F5629.8080609@auckland.ac.nz>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130301/dda90c76/attachment.pl>

From A.Robinson at ms.unimelb.edu.au  Fri Mar  1 03:09:33 2013
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Fri, 1 Mar 2013 13:09:33 +1100
Subject: [R-sig-ME] Nested fixed factors in glmer: Error in
 mer_finalize(ans) : Downdated X'X is not positive definite, 1.
In-Reply-To: <512F5629.8080609@auckland.ac.nz>
References: <20130228142736.Horde._I9sMTp6yHZRL1tIEiZn86A@webmail.csic.es>
	<20130228144646.1e56cff2963d8b48ea65f74b@zotac.lan>
	<20130228152748.Horde.sahtazp6yHZRL2lkutZl4nA@webmail.csic.es>
	<512FFE0F.7020809@auckland.ac.nz>
	<CAHyGmd5xD21a8B0Q7bgygWe4y4hnaF0xwXcEHDkMZy7Deaz4kA@mail.gmail.com>
	<512F5629.8080609@auckland.ac.nz>
Message-ID: <CAHyGmd6FJjWobtAsgtDiddfBUNK_F+up=cSVyg1AQpaVovnYtg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130301/ff273aa3/attachment.pl>

From pierces1 at msu.edu  Fri Mar  1 03:23:33 2013
From: pierces1 at msu.edu (Steven J. Pierce)
Date: Thu, 28 Feb 2013 21:23:33 -0500
Subject: [R-sig-ME] Partial effects in mixed models
In-Reply-To: <1833112284.279581362068675542.JavaMail.www@wwinf7139>
References: <1833112284.279581362068675542.JavaMail.www@wwinf7139>
Message-ID: <001201ce1623$c6b462a0$541d27e0$@msu.edu>

Why not just run a model with both predictors instead? See King (1986) for one perspective on why extracting the residuals to use as the dependent variable in another model is sub-optimal. That paper is about plain old OLS regression, but I suspect it still is applicable logic. 

King, G. (1986). How not to lie with statistics: Avoiding common mistakes in quantitative political science. American Journal of Political Science, 30(3), 666-687.


Steven J. Pierce, Ph.D. 
Associate Director 
Center for Statistical Training & Consulting (CSTAT) 
Michigan State University 
E-mail: pierces1 at msu.edu 
Web: http://www.cstat.msu.edu 


-----Original Message-----
From: v_coudrain at voila.fr [mailto:v_coudrain at voila.fr] 
Sent: Thursday, February 28, 2013 11:25 AM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] Partial effects in mixed models

Dear all,

I would like to test the effect of an explanatory variable after removing the effect of another one. I thought about calculating the model with the first explanatory 
variable only, then take the model residuals and use the residuals as response variable to test the effect of the second explanatory variable. However, I do not 
know if this is possible for a model containing random effects. Maybe it doesn't make sense anyway, but if it is possible, should I include the random effects in the 
second model (residuals as response variable) or not, since variance explained by random effects should also have been accounted for in the first model?

Thank you for your help

Val?rie
___________________________________________________________
Alain Delon horrifi? et d?vast? de tristesse ! Mais pour quelle raison ? ? lire sur Voila.fr http://people.voila.fr/people/actu-stars/tv-cine-musique/alain-delon-horrifie-et-devaste-de-tristesse-repond-a-son-fils-people_9663.html


From chris at trickysolutions.com.au  Fri Mar  1 08:30:53 2013
From: chris at trickysolutions.com.au (Chris Howden)
Date: Fri, 1 Mar 2013 18:30:53 +1100
Subject: [R-sig-ME] Can AIC be approximated by -2ln(L) i.e. the deviance,
 at very large sample size?
Message-ID: <d6ba819f99e6538a1df99da8d2250e0d@mail.gmail.com>

Hi everyone,

Although not strictly an R issue there often seems to be discussions along
these lines on this list, so I hope no one minds me posting this. If U do
please let me know. (and just for the record I am applying this in R)

I'm trying to get my head around AIC and sample size.

Now if AIC = -2ln(L) + 2K = Deviance + 2K

Am I right in thinking that as the Likelihood is the product of
probabilities then (all else being equal) the larger the sample size the
smaller the Likelihood?
Which means that if we have very large sample sizes we expect the -2ln(L)
term to be a very large number?
Which would reduce the effect of the parameter correction term 2K?


Chris Howden B.Sc. (Hons) GStat.
Founding Partner
Evidence Based Strategic Development, IP Commercialisation and Innovation,
Data Analysis, Modelling and Training
(mobile) 0410 689 945
(fax) +612 4782 9023
chris at trickysolutions.com.au


From emmanuel.curis at parisdescartes.fr  Fri Mar  1 09:12:03 2013
From: emmanuel.curis at parisdescartes.fr (Emmanuel Curis)
Date: Fri, 1 Mar 2013 09:12:03 +0100
Subject: [R-sig-ME] Nested fixed factors in glmer: Error in
 mer_finalize(ans) : Downdated X'X is not positive definite, 1.
In-Reply-To: <512FFE0F.7020809@auckland.ac.nz>
References: <20130228142736.Horde._I9sMTp6yHZRL1tIEiZn86A@webmail.csic.es>
	<20130228144646.1e56cff2963d8b48ea65f74b@zotac.lan>
	<20130228152748.Horde.sahtazp6yHZRL2lkutZl4nA@webmail.csic.es>
	<512FFE0F.7020809@auckland.ac.nz>
Message-ID: <20130301081203.GA7102@laboinfo-063.pharmacie.univ-paris5.fr>

Hello,

I think I would state the question a little bit differently.

Let's consider for instance that you compare a control group to a
treated group on rats, and rats are not the same in the two
groups. The ? rat ? factor is obviously nested in the ? group ? one,
there certainly will be a ? rat ? factor effect, but what I am
interested in is the ? treatment ? factor. If I assume ? rat ? factor
as fixed, then nesting fixed factors makes senses

But, rat factor could be considered as random or fixed. So my way to
reformulate the question would be ? is it possible to imagine an
interesting design in which a ? real ? fixed factor can be nested in
another one ?, the ? real ? fixed factor meaning there is no
alternative to consider it as random --- like if in a group you would
have only male and in the other only female rats. I guess in such a
case, this instead introduces a strong confusion between the two
factors, which is I guess what you meant?

No, going back to the rat: considered as fixed or random for analysis?
IIRC, there is on the FAQ several points of view consider.

Beside the practical one (? is there enough levels to fit a random
effect? ?), the philosophical one is interesting: am I interested in
all rats or only in the one used for the experiment? During one
discussion with one of my masters, he explained to me that if the
experiment is only a proof of concept experiment, one is really
interested in these rats, not all the population, but if one tries to
develop a treatment for curing rats, then one is interested in all
rats. I found this convincing, but I'm open to other points of view to
think further about this.

If accepting that, this would mean that in some cases, nesting fixed
effects makes sense...

And, last, if the coefficients are the same in the two models, the sum
of square decomposition changes. Of course, since they use the same
coefficients, both are obtainable from both models, but with much
efforts...

Best regards,

On Fri, Mar 01, 2013 at 02:02:07PM +1300, Rolf Turner wrote:
? 
? Perhaps I am just obtuse (there are those who would say there is
? no "perhaps" about it) but it seems to me that nesting of fixed effects
? makes no sense.
? 
? In the example given below you have in effect a ***single*** factor
? with six levels: a.1, a.2, b.3, b.4, c.5, c.6.  This really means that
? you just have the second "nested" factor with levels 1, 2, 3, 4, 5, 6.
? So just supply the second factor to the formula in the call to glmer()
? and forget about the first factor entirely.  It is redundant when the
? second factor is supplied.
? 
? You *can* use the formula y ~ f1/f2 or equivalently y ~ f1 + f1:f2
? but you'll find that you wind up getting 12 coefficient estimates, six
? of which are "NA".  The values of the six non-NA coefficients will
? be indentical with values of the six coefficient estimate that you get
? from y ~ f2.
? 
?     cheers,
? 
?         Rolf Turner

-- 
                                Emmanuel CURIS
                                emmanuel.curis at parisdescartes.fr

Page WWW: http://emmanuel.curis.online.fr/index.html


From emmanuel.curis at parisdescartes.fr  Fri Mar  1 09:17:42 2013
From: emmanuel.curis at parisdescartes.fr (Emmanuel Curis)
Date: Fri, 1 Mar 2013 09:17:42 +0100
Subject: [R-sig-ME] Can AIC be approximated by -2ln(L) i.e. the deviance,
 at very large sample size?
In-Reply-To: <d6ba819f99e6538a1df99da8d2250e0d@mail.gmail.com>
References: <d6ba819f99e6538a1df99da8d2250e0d@mail.gmail.com>
Message-ID: <20130301081742.GB7102@laboinfo-063.pharmacie.univ-paris5.fr>

Hi,

I may be wrong, but I understood that AIC in itself is not as
important as changes in AIC between models, and some authors says that
changes in AIC in the order of more than 10 are enough to favor a
model on another.

And changes in the 2*k term should be in this order of magnitude when
comparing different models.

So my guess would be that it remains important.

On the other hand, if a set of parameters will remain in all models,
it probably can be safely ignored in the 2*k term for all models.

Hope this helps,

On Fri, Mar 01, 2013 at 06:30:53PM +1100, Chris Howden wrote:
? Hi everyone,
? 
? Although not strictly an R issue there often seems to be discussions along
? these lines on this list, so I hope no one minds me posting this. If U do
? please let me know. (and just for the record I am applying this in R)
? 
? I'm trying to get my head around AIC and sample size.
? 
? Now if AIC = -2ln(L) + 2K = Deviance + 2K
? 
? Am I right in thinking that as the Likelihood is the product of
? probabilities then (all else being equal) the larger the sample size the
? smaller the Likelihood?
? Which means that if we have very large sample sizes we expect the -2ln(L)
? term to be a very large number?
? Which would reduce the effect of the parameter correction term 2K?
? 
? 
? Chris Howden B.Sc. (Hons) GStat.
? Founding Partner
? Evidence Based Strategic Development, IP Commercialisation and Innovation,
? Data Analysis, Modelling and Training
? (mobile) 0410 689 945
? (fax) +612 4782 9023
? chris at trickysolutions.com.au
? 
? _______________________________________________
? R-sig-mixed-models at r-project.org mailing list
? https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
                                Emmanuel CURIS
                                emmanuel.curis at parisdescartes.fr

Page WWW: http://emmanuel.curis.online.fr/index.html


From maggenga at libero.it  Fri Mar  1 10:00:31 2013
From: maggenga at libero.it (maggenga at libero.it)
Date: Fri, 1 Mar 2013 10:00:31 +0100 (CET)
Subject: [R-sig-ME] R: Re: R: Re:  GLMM family=binomial, link identity
Message-ID: <16376908.17355201362128431821.JavaMail.root@wmail31>


I dont'know where I take new lme4 version '0.99999911.1'

Where do I search it ?

My problem is this:


###start script

library(lme4)

packageVersion("lme4")  # ?0.999999.0?

set.seed(101)
win=rbinom(50,20,0.6)
lost=rbinom(50,20,0.4)
x1=rbinom(50,1,0.3)


# my data (endogenous variable = matrix with "win and lost counts" for each 
row)

f <- factor(sample(LETTERS[1:26], size = 50, replace = TRUE))

m1OR <- glmer(cbind(win,lost) ~ x1 + (1 | f), family = binomial(link = 
"logit"))
summary(m1OR)
m1RD <- glmer(cbind(win,lost) ~ x1 + (1 | f), family = binomial(link = 
"identity")) # ERROR
summary(m1RD) # ERROR


# trial with endogenous = binary vector 

a=rbinom(50,1,0.3)

m2OR <- glmer(a ~ x1 + (1 | f), family = binomial(link = "logit"))
summary(m2OR)
m2RD <- glmer(a ~ x1 + (1 | f), family = binomial(link = "identity")) # ERROR
summary(m2RD) # ERROR


###end script

Thank you very much for our help and time.

Davide

>----Messaggio originale----
>Da: bbolker at gmail.com
>Data: 27/02/2013 1.55
>A: "maggenga at libero.it"<maggenga at libero.it>, "r-sig-mixed-models at r-project.
org"<r-sig-mixed-models at r-project.org>
>Ogg: Re: R: Re: [R-sig-ME] GLMM family=binomial, link identity
>
>On 13-02-26 05:57 PM, maggenga at libero.it wrote:
>> Sorry, i was wrong. I want say lme4 package.
>> 
>> 
>> But "glmer(...,family=binomial(link="identity")) " give me same results
>> 
>> as
>> 
>> "glmer(...,family=binomial(link="logit")) "
>> 
>> Why?
>> 
>> I want interpret the coefficients as risk difference and not OR
>> 
>> Thank you very much
>> 
>> Davide
>
>[cc'ing back to r-sig-mixed-models: it's best to keep these
>conversations on-list]
>
>  It's hard to say without a reproducible example
><http://tinyurl.com/reproducible-000>.  I made up an example that seemed
>to work, sort of -- at least it showed that I do *not* get the same
>results.  With the stable version of lme4, the fit worked with the
>default (logit) link and failed with the identity link (although
>apparently for reasons of numerical instability, not because it's
>impossible to fit such models).  With the development version (latest
>version from github), both worked, and the identity link results seem to
>have correctly estimated the parameters (I can tell because the data
>were simulated).
>
>See
>
>http://rpubs.com/bbolker/4671
>
>> 
>> 
>> 
>>> ----Messaggio originale----
>>> Da: bbolker at gmail.com
>>> Data: 26/02/2013 23.40
>>> A: <r-sig-mixed-models at r-project.org>
>>> Ogg: Re: [R-sig-ME] GLMM family=binomial, link identity
>>>
>>> maggenga at ... <maggenga at ...> writes:
>>>
>>>>
>>>> Hi,
>>>> I'm phd student in medical statistics.
>>>> I would like know the R-way to perform the identity link 
(family=binomial) 
>> in
>>> lmer (ade4 package).
>>>
>>>  How about
>>>
>>> glmer(...,family=binomial(link="identity")) 
>>>
>>> ?
>>>
>>> See ?family in base R.
>>>
>>> Warning: this is likely to be fragile (as fitting with non-standard
>>> link functions often is).
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>> 
>> 
>
>


From v_coudrain at voila.fr  Fri Mar  1 12:34:54 2013
From: v_coudrain at voila.fr (v_coudrain at voila.fr)
Date: Fri, 1 Mar 2013 12:34:54 +0100 (CET)
Subject: [R-sig-ME] Partial effects in mixed models
In-Reply-To: <001201ce1623$c6b462a0$541d27e0$@msu.edu>
Message-ID: <1943922804.59141362137694733.JavaMail.www@wwinf7145>

Thank you. My concern was that the model with both variables within may not be optimal because both variables are correlated and I would like to know if the 
second variable has a "pure" effect on the response variable that is independent from the effect of the first variable. Since I have a generalized mixed model with 
poisson distribution, the statistics are based on Chi test and not F tests and I think that these tests are not sequential like in anova. Am I correct? 

Best


> Message du 01/03/13 ? 03h23
> De : "Steven J. Pierce" 

> A : v_coudrain at voila.fr, r-sig-mixed-models at r-project.org
> Copie ? : 
> Objet : RE: [R-sig-ME] Partial effects in mixed models
> 
> Why not just run a model with both predictors instead? See King (1986) for one perspective on why extracting the residuals to use as the dependent variable in 
another model is sub-optimal. That paper is about plain old OLS regression, but I suspect it still is applicable logic. 
> 
> King, G. (1986). How not to lie with statistics: Avoiding common mistakes in quantitative political science. American Journal of Political Science, 30(3), 666-687.
> 
> 
> Steven J. Pierce, Ph.D. 
> Associate Director 
> Center for Statistical Training & Consulting (CSTAT) 
> Michigan State University 
> E-mail: pierces1 at msu.edu 
> Web: http://www.cstat.msu.edu 
> 
> 
> -----Original Message-----
> From: v_coudrain at voila.fr [mailto:v_coudrain at voila.fr] 
> Sent: Thursday, February 28, 2013 11:25 AM
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] Partial effects in mixed models
> 
> Dear all,
> 
> I would like to test the effect of an explanatory variable after removing the effect of another one. I thought about calculating the model with the first explanatory 
> variable only, then take the model residuals and use the residuals as response variable to test the effect of the second explanatory variable. However, I do not 
> know if this is possible for a model containing random effects. Maybe it doesn't make sense anyway, but if it is possible, should I include the random effects in 
the 
> second model (residuals as response variable) or not, since variance explained by random effects should also have been accounted for in the first model?
> 
> Thank you for your help
> 
> Val?rie
> ___________________________________________________________
> Alain Delon horrifi? et d?vast? de tristesse ! Mais pour quelle raison ? ? lire sur Voila.fr http://people.voila.fr/people/actu-stars/tv-cine-musique/alain-delon-
horrifie-et-devaste-de-tristesse-repond-a-son-fils-people_9663.html
> 
> 
> 
> 

___________________________________________________________
News TV : Val?rie Damidot annonce la fin de son ?mission D&Co ! ? lire sur Voila.fr http://people.voila.fr/people/actu-stars/personnalites/valerie-damidot-annonce-la-fin-de-d-co-people_9679.html


From pierces1 at msu.edu  Fri Mar  1 14:33:56 2013
From: pierces1 at msu.edu (Steven J. Pierce)
Date: Fri, 1 Mar 2013 08:33:56 -0500
Subject: [R-sig-ME] Partial effects in mixed models
In-Reply-To: <1943922804.59141362137694733.JavaMail.www@wwinf7145>
References: <001201ce1623$c6b462a0$541d27e0$@msu.edu>
	<1943922804.59141362137694733.JavaMail.www@wwinf7145>
Message-ID: <003701ce1681$6cd00f10$46702d30$@msu.edu>

It is my understanding that each coefficient in a model with multiple predictors reflects the effect of that predictor conditional on the set of other predictors included in the model. Isn't that exactly what you're trying to obtain? 

If you want to explicitly model the effects of both predictors on the response and simultaneously model the correlation between those predictors, you could switch over to using a multilevel structural equation model. Mplus (a commercial software package) allows you to use Poisson response variables in such models. There may also be R packages that also allow such models, but I have not really looked to verify that.


Steven J. Pierce, Ph.D. 
Associate Director 
Center for Statistical Training & Consulting (CSTAT) 
Michigan State University 
E-mail: pierces1 at msu.edu 
Web: http://www.cstat.msu.edu 

-----Original Message-----
From: v_coudrain at voila.fr [mailto:v_coudrain at voila.fr] 
Sent: Friday, March 01, 2013 6:35 AM
To: Steven J. Pierce; r-sig-mixed-models at r-project.org
Subject: RE: [R-sig-ME] Partial effects in mixed models

Thank you. My concern was that the model with both variables within may not be optimal because both variables are correlated and I would like to know if the 
second variable has a "pure" effect on the response variable that is independent from the effect of the first variable. Since I have a generalized mixed model with 
poisson distribution, the statistics are based on Chi test and not F tests and I think that these tests are not sequential like in anova. Am I correct? 

Best


> Message du 01/03/13 ? 03h23
> De : "Steven J. Pierce" 

> A : v_coudrain at voila.fr, r-sig-mixed-models at r-project.org
> Copie ? : 
> Objet : RE: [R-sig-ME] Partial effects in mixed models
> 
> Why not just run a model with both predictors instead? See King (1986) for one perspective on why extracting the residuals to use as the dependent variable in 
another model is sub-optimal. That paper is about plain old OLS regression, but I suspect it still is applicable logic. 
> 
> King, G. (1986). How not to lie with statistics: Avoiding common mistakes in quantitative political science. American Journal of Political Science, 30(3), 666-687.
> 
> 
> Steven J. Pierce, Ph.D. 
> Associate Director 
> Center for Statistical Training & Consulting (CSTAT) 
> Michigan State University 
> E-mail: pierces1 at msu.edu 
> Web: http://www.cstat.msu.edu 
> 
> 
> -----Original Message-----
> From: v_coudrain at voila.fr [mailto:v_coudrain at voila.fr] 
> Sent: Thursday, February 28, 2013 11:25 AM
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] Partial effects in mixed models
> 
> Dear all,
> 
> I would like to test the effect of an explanatory variable after removing the effect of another one. I thought about calculating the model with the first explanatory 
> variable only, then take the model residuals and use the residuals as response variable to test the effect of the second explanatory variable. However, I do not 
> know if this is possible for a model containing random effects. Maybe it doesn't make sense anyway, but if it is possible, should I include the random effects in 
the 
> second model (residuals as response variable) or not, since variance explained by random effects should also have been accounted for in the first model?
> 
> Thank you for your help
> 
> Val?rie
> ___________________________________________________________
> Alain Delon horrifi? et d?vast? de tristesse ! Mais pour quelle raison ? ? lire sur Voila.fr http://people.voila.fr/people/actu-stars/tv-cine-musique/alain-delon-
horrifie-et-devaste-de-tristesse-repond-a-son-fils-people_9663.html
> 
> 
> 
> 

___________________________________________________________
News TV : Val?rie Damidot annonce la fin de son ?mission D&Co ! ? lire sur Voila.fr http://people.voila.fr/people/actu-stars/personnalites/valerie-damidot-annonce-la-fin-de-d-co-people_9679.html


From bbolker at gmail.com  Fri Mar  1 15:03:33 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 1 Mar 2013 14:03:33 +0000 (UTC)
Subject: [R-sig-ME] Can AIC be approximated by -2ln(L) i.e. the deviance,
	at very large sample size?
References: <d6ba819f99e6538a1df99da8d2250e0d@mail.gmail.com>
	<20130301081742.GB7102@laboinfo-063.pharmacie.univ-paris5.fr>
Message-ID: <loom.20130301T145725-285@post.gmane.org>

Emmanuel Curis <emmanuel.curis at ...> writes:

> 
> Hi,
> 
> I may be wrong, but I understood that AIC in itself is not as
> important as changes in AIC between models, and some authors says that
> changes in AIC in the order of more than 10 are enough to favor a
> model on another.
> 
> And changes in the 2*k term should be in this order of magnitude when
> comparing different models.
> 
> So my guess would be that it remains important.

  You are exactly right.

  This is exactly equivalent to the initially surprising result
that the maximum (log-)likelihood *decreases* when the sample size 
increases: the probability of any *particular* outcome goes down.
Generally in likelihood-based statistical approaches (including AIC)
we only look at the differences in (log-)likelihood/AIC, not the absolute
number.

  I've started a campaign to try to get people _never_ to produce tables
of raw AIC values; only the delta-AIC values should be presented (if
necessary the minimum AIC value can be put in a footnote somewhere so
people can check for reproducibility of the results, but that's the only
reason one should ever care about the raw value).

  That's not to downplay the issues with AIC in the mixed model context:
http://glmm.wikidot.com/faq#aic


From Paul.Thompson at SanfordHealth.org  Fri Mar  1 15:30:44 2013
From: Paul.Thompson at SanfordHealth.org (Thompson,Paul)
Date: Fri, 1 Mar 2013 14:30:44 +0000
Subject: [R-sig-ME] Partial effects in mixed models
In-Reply-To: <003701ce1681$6cd00f10$46702d30$@msu.edu>
References: <001201ce1623$c6b462a0$541d27e0$@msu.edu>
	<1943922804.59141362137694733.JavaMail.www@wwinf7145>
	<003701ce1681$6cd00f10$46702d30$@msu.edu>
Message-ID: <9B75E7CF385CB94EAD6587DD96AC2D977F077E3F@SFSMCEXMBX3.sanfordhealth.org>

Take a look at

@ARTICLE{Nakagawa-2012-1,
  author = {Nakagawa, S. and Schielzeth, H.},
  title = {A general and simple method for obtaining R$^2$ from generalized
	linear mixed-effects models},
  journal = {Meth. Ecol. Evol.},
  year = {2012},
  pages = {1-120},
  doi = {10.1111/j.2041-210x.2012.00251.x},
  owner = {THOMPSOP},
  timestamp = {2012.12.16}
}
They discuss using residuals.

-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Steven J. Pierce
Sent: Friday, March 01, 2013 7:34 AM
To: v_coudrain at voila.fr; r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Partial effects in mixed models

It is my understanding that each coefficient in a model with multiple predictors reflects the effect of that predictor conditional on the set of other predictors included in the model. Isn't that exactly what you're trying to obtain? 

If you want to explicitly model the effects of both predictors on the response and simultaneously model the correlation between those predictors, you could switch over to using a multilevel structural equation model. Mplus (a commercial software package) allows you to use Poisson response variables in such models. There may also be R packages that also allow such models, but I have not really looked to verify that.


Steven J. Pierce, Ph.D. 
Associate Director
Center for Statistical Training & Consulting (CSTAT) Michigan State University
E-mail: pierces1 at msu.edu
Web: http://www.cstat.msu.edu 

-----Original Message-----
From: v_coudrain at voila.fr [mailto:v_coudrain at voila.fr]
Sent: Friday, March 01, 2013 6:35 AM
To: Steven J. Pierce; r-sig-mixed-models at r-project.org
Subject: RE: [R-sig-ME] Partial effects in mixed models

Thank you. My concern was that the model with both variables within may not be optimal because both variables are correlated and I would like to know if the second variable has a "pure" effect on the response variable that is independent from the effect of the first variable. Since I have a generalized mixed model with poisson distribution, the statistics are based on Chi test and not F tests and I think that these tests are not sequential like in anova. Am I correct? 

Best


> Message du 01/03/13 ? 03h23
> De : "Steven J. Pierce" 

> A : v_coudrain at voila.fr, r-sig-mixed-models at r-project.org Copie ? :
> Objet : RE: [R-sig-ME] Partial effects in mixed models
> 
> Why not just run a model with both predictors instead? See King (1986) 
> for one perspective on why extracting the residuals to use as the 
> dependent variable in
another model is sub-optimal. That paper is about plain old OLS regression, but I suspect it still is applicable logic. 
> 
> King, G. (1986). How not to lie with statistics: Avoiding common mistakes in quantitative political science. American Journal of Political Science, 30(3), 666-687.
> 
> 
> Steven J. Pierce, Ph.D. 
> Associate Director
> Center for Statistical Training & Consulting (CSTAT) Michigan State 
> University
> E-mail: pierces1 at msu.edu
> Web: http://www.cstat.msu.edu
> 
> 
> -----Original Message-----
> From: v_coudrain at voila.fr [mailto:v_coudrain at voila.fr]
> Sent: Thursday, February 28, 2013 11:25 AM
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] Partial effects in mixed models
> 
> Dear all,
> 
> I would like to test the effect of an explanatory variable after 
> removing the effect of another one. I thought about calculating the 
> model with the first explanatory variable only, then take the model 
> residuals and use the residuals as response variable to test the 
> effect of the second explanatory variable. However, I do not know if 
> this is possible for a model containing random effects. Maybe it 
> doesn't make sense anyway, but if it is possible, should I include the 
> random effects in
the 
> second model (residuals as response variable) or not, since variance explained by random effects should also have been accounted for in the first model?
> 
> Thank you for your help
> 
> Val?rie
> ___________________________________________________________
> Alain Delon horrifi? et d?vast? de tristesse ! Mais pour quelle raison 
> ? ? lire sur Voila.fr 
> http://people.voila.fr/people/actu-stars/tv-cine-musique/alain-delon-
horrifie-et-devaste-de-tristesse-repond-a-son-fils-people_9663.html
> 
> 
> 
> 

___________________________________________________________
News TV : Val?rie Damidot annonce la fin de son ?mission D&Co ! ? lire sur Voila.fr http://people.voila.fr/people/actu-stars/personnalites/valerie-damidot-annonce-la-fin-de-d-co-people_9679.html

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
-----------------------------------------------------------------------
Confidentiality Notice: This e-mail message, including any attachments,
is for the sole use of the intended recipient(s) and may contain
privileged and confidential information.  Any unauthorized review, use,
disclosure or distribution is prohibited.  If you are not the intended
recipient, please contact the sender by reply e-mail and destroy
all copies of the original message.

From nm180 at leicester.ac.uk  Fri Mar  1 10:14:12 2013
From: nm180 at leicester.ac.uk (Masca, Nicholas)
Date: Fri, 1 Mar 2013 09:14:12 +0000
Subject: [R-sig-ME] Nested random effects meta-analysis using nlme?
Message-ID: <886BDAB6B7439441BBE3DB5288B39180012D1D018344@EXC-MBX3.cfs.le.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130301/1a3ce8f2/attachment.pl>

From v_coudrain at voila.fr  Fri Mar  1 20:45:11 2013
From: v_coudrain at voila.fr (v_coudrain at voila.fr)
Date: Fri, 1 Mar 2013 20:45:11 +0100 (CET)
Subject: [R-sig-ME] Partial effects in mixed models
In-Reply-To: <9B75E7CF385CB94EAD6587DD96AC2D977F077E3F@SFSMCEXMBX3.sanfordhealth.org>
Message-ID: <2022287568.143711362167111473.JavaMail.www@wwinf7130>

Thank you very much, I'll read the article. I knew about structural equation modelling in the software AMOS (SPSS) but it is not very flexible regarding 
distributions.
Best wishes


> Message du 01/03/13 ? 15h32
> De : "Thompson,Paul" 

> A : "Steven J. Pierce" 
, "v_coudrain at voila.fr" , "r-sig-mixed-models at r-project.org" 
> Copie ? : 
> Objet : RE: [R-sig-ME] Partial effects in mixed models
> 
> Take a look at
> 
> @ARTICLE{Nakagawa-2012-1,
> author = {Nakagawa, S. and Schielzeth, H.},
> title = {A general and simple method for obtaining R$^2$ from generalized
> linear mixed-effects models},
> journal = {Meth. Ecol. Evol.},
> year = {2012},
> pages = {1-120},
> doi = {10.1111/j.2041-210x.2012.00251.x},
> owner = {THOMPSOP},
> timestamp = {2012.12.16}
> }
> They discuss using residuals.
> 
> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Steven J. Pierce
> Sent: Friday, March 01, 2013 7:34 AM
> To: v_coudrain at voila.fr; r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Partial effects in mixed models
> 
> It is my understanding that each coefficient in a model with multiple predictors reflects the effect of that predictor conditional on the set of other predictors 
included in the model. Isn't that exactly what you're trying to obtain? 
> 
> If you want to explicitly model the effects of both predictors on the response and simultaneously model the correlation between those predictors, you could 
switch over to using a multilevel structural equation model. Mplus (a commercial software package) allows you to use Poisson response variables in such 
models. There may also be R packages that also allow such models, but I have not really looked to verify that.
> 
> 
> Steven J. Pierce, Ph.D. 
> Associate Director
> Center for Statistical Training & Consulting (CSTAT) Michigan State University
> E-mail: pierces1 at msu.edu
> Web: http://www.cstat.msu.edu 
> 
> -----Original Message-----
> From: v_coudrain at voila.fr [mailto:v_coudrain at voila.fr]
> Sent: Friday, March 01, 2013 6:35 AM
> To: Steven J. Pierce; r-sig-mixed-models at r-project.org
> Subject: RE: [R-sig-ME] Partial effects in mixed models
> 
> Thank you. My concern was that the model with both variables within may not be optimal because both variables are correlated and I would like to know if the 
second variable has a "pure" effect on the response variable that is independent from the effect of the first variable. Since I have a generalized mixed model 
with poisson distribution, the statistics are based on Chi test and not F tests and I think that these tests are not sequential like in anova. Am I correct? 
> 
> Best
> 
> 
> > Message du 01/03/13 ? 03h23
> > De : "Steven J. Pierce" 
> 
> > A : v_coudrain at voila.fr, r-sig-mixed-models at r-project.org Copie ? :
> > Objet : RE: [R-sig-ME] Partial effects in mixed models
> > 
> > Why not just run a model with both predictors instead? See King (1986) 
> > for one perspective on why extracting the residuals to use as the 
> > dependent variable in
> another model is sub-optimal. That paper is about plain old OLS regression, but I suspect it still is applicable logic. 
> > 
> > King, G. (1986). How not to lie with statistics: Avoiding common mistakes in quantitative political science. American Journal of Political Science, 30(3), 666-
687.
> > 
> > 
> > Steven J. Pierce, Ph.D. 
> > Associate Director
> > Center for Statistical Training & Consulting (CSTAT) Michigan State 
> > University
> > E-mail: pierces1 at msu.edu
> > Web: http://www.cstat.msu.edu
> > 
> > 
> > -----Original Message-----
> > From: v_coudrain at voila.fr [mailto:v_coudrain at voila.fr]
> > Sent: Thursday, February 28, 2013 11:25 AM
> > To: r-sig-mixed-models at r-project.org
> > Subject: [R-sig-ME] Partial effects in mixed models
> > 
> > Dear all,
> > 
> > I would like to test the effect of an explanatory variable after 
> > removing the effect of another one. I thought about calculating the 
> > model with the first explanatory variable only, then take the model 
> > residuals and use the residuals as response variable to test the 
> > effect of the second explanatory variable. However, I do not know if 
> > this is possible for a model containing random effects. Maybe it 
> > doesn't make sense anyway, but if it is possible, should I include the 
> > random effects in
> the 
> > second model (residuals as response variable) or not, since variance explained by random effects should also have been accounted for in the first model?
> > 
> > Thank you for your help
> > 
> > Val?rie
> > ___________________________________________________________
> > Alain Delon horrifi? et d?vast? de tristesse ! Mais pour quelle raison 
> > ? ? lire sur Voila.fr 
> > http://people.voila.fr/people/actu-stars/tv-cine-musique/alain-delon-
> horrifie-et-devaste-de-tristesse-repond-a-son-fils-people_9663.html
> > 
> > 
> > 
> > 
> 
> ___________________________________________________________
> News TV : Val?rie Damidot annonce la fin de son ?mission D&Co ! ? lire sur Voila.fr http://people.voila.fr/people/actu-stars/personnalites/valerie-damidot-
annonce-la-fin-de-d-co-people_9679.html
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> -----------------------------------------------------------------------
> Confidentiality Notice: This e-mail message, including any attachments,
> is for the sole use of the intended recipient(s) and may contain
> privileged and confidential information. Any unauthorized review, use,
> disclosure or distribution is prohibited. If you are not the intended
> recipient, please contact the sender by reply e-mail and destroy
> all copies of the original message.
> 

___________________________________________________________
News TV : Val?rie Damidot annonce la fin de son ?mission D&Co ! ? lire sur Voila.fr http://people.voila.fr/people/actu-stars/personnalites/valerie-damidot-annonce-la-fin-de-d-co-people_9679.html


From shinichi.nakagawa at otago.ac.nz  Fri Mar  1 22:00:29 2013
From: shinichi.nakagawa at otago.ac.nz (Shinichi Nakagawa)
Date: Fri, 1 Mar 2013 21:00:29 +0000
Subject: [R-sig-ME] Nested random effects meta-analysis using nlme?
In-Reply-To: <886BDAB6B7439441BBE3DB5288B39180012D1D018344@EXC-MBX3.cfs.le.ac.uk>
References: <886BDAB6B7439441BBE3DB5288B39180012D1D018344@EXC-MBX3.cfs.le.ac.uk>
Message-ID: <38FDD670-2842-4AD8-9800-67AC6B04B34A@otago.ac.nz>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130301/877ae150/attachment.pl>

From njbisaac at gmail.com  Fri Mar  1 21:48:39 2013
From: njbisaac at gmail.com (Nick Isaac)
Date: Fri, 1 Mar 2013 20:48:39 +0000
Subject: [R-sig-ME] False convergence
Message-ID: <CAMab-EySLkdhwa_MkiCYn-sqa=xeYVq0yN2WS08scTcdw_1GHg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130301/ac3ec699/attachment.pl>

From bates at stat.wisc.edu  Sat Mar  2 17:51:38 2013
From: bates at stat.wisc.edu (Douglas Bates)
Date: Sat, 2 Mar 2013 10:51:38 -0600
Subject: [R-sig-ME] New book "Generalized Linear Mixed Models" by Walter
	Stroup
Message-ID: <CAO7JsnQ4Xqu7YL8jsZ650YofeyJ7koPA_Uwyj=2F=j6MYjMH9Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130302/2c92b0c0/attachment.pl>

From bbolker at gmail.com  Sat Mar  2 19:15:21 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 02 Mar 2013 13:15:21 -0500
Subject: [R-sig-ME] updated sourceforge repository
Message-ID: <513241B9.3020404@mcmaster.ca>

I have just pushed updated source, Windows 64-bit binary, and MacOS
binaries of the very most current development version of lme4,
0.99999911-1, to the repository at

 http://lme4.r-forge.r-project.org/repos/src/contrib/ ;

**however, it will take up to 24 hours for the web pages to update (so
you won't see the new version right away**.

  You should thereafter be able to

install.packages("lme4",
 repos=c("http://lme4.r-forge.r-project.org/repos",
         getOption("repos")))

Please e-mail lme4-authors at R-forge.wu-wien.ac.at if you have problems
with this.

 To install the most recent version directly from github (where
development is now proceeding),

library("devtools")
install_github("lme4",user="lme4")

(you will need the Rcpp, RcppEigen, and minqa packages installed first)

  Ben Bolker


From bbolker at gmail.com  Sat Mar  2 22:34:59 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 2 Mar 2013 21:34:59 +0000 (UTC)
Subject: [R-sig-ME] False convergence
References: <CAMab-EySLkdhwa_MkiCYn-sqa=xeYVq0yN2WS08scTcdw_1GHg@mail.gmail.com>
Message-ID: <loom.20130302T220905-476@post.gmane.org>

Nick Isaac <njbisaac at ...> writes:

> Dear list,
> 
> I'm running a set of models in glmer(), some of which return the 'false
> convergence' error (cvg=8). I'm trying to understand why.
> 
> My models all have the same basic structure: glmer(P ~ Year + (1|Site),
> binomial), where P is a vector of 0s and 1s. The Year is centered on zero,
> which I've found to greatly reduce the incidence of false convergences in
> the past. There are ~100,000 observations and 9000 sites.
> 
> I've tried a couple of fixes, including the .Call("mer_optimize",...) hack
> as well as an observation-level random effect. the former has no impact on
> the parameter estimates and the latter still returns the false convergence
> warning.
> 
> I'm using verbose=T argument. I've noticed previously that false
> convergence is characterised by just 1 or 2 iterations being completed and
> variances on the random effects that are either close to zero or
> astronomically huge. But my models are running to dozens of iterations with
> sensible looking variances that change moderately among iterations but then
> stabilise during the last few iterations. And the parameter estimates look
> sensible.
> 
> In other words, the models do not show any evidence of failure, except the
> warning message. So which should I believe: the verbose trace or the
> warning message?
> 
> Perhaps someone can give me further insight into why glmer() thinks the
> model has not properly converged

  In general I would believe the verbose trace ...

  The stable version of lme4 is using the nlminb() optimizer internally,
which in turn is based on the PORT libraries

The docs linked from ?nlminb:

http://netlib.bell-labs.com/cm/cs/cstr/153.pdf

The only useful material I could find in these docs was:

------------
p. 5: false convergence: the gradient ?f(x) may be computed
incorrectly, the other stopping tolerances may be too tight, or either
f or ?f may be discontinuous near the current iterate x.

p. 9: V(XFTOL) ? V(34) is the false-convergence tolerance. A return
with IV(1) = 8 occurs if a more favorable stopping test is not
satisfied and if a step of scaled length at most V(XFTOL) is tried but
not accepted. ??Scaled length?? is in the sense of (5.1). Such a
return generally means there is an error in computing ?f(x), or
the favorable convergence tolerances (V(RFCTOL), V(XCTOL), and
perhaps V(AFCTOL)) are too tight for the accuracy to which f(x) is
computed (see ?9), or ?f (or f itself) is discontinuous near x . An
error in computing ?f(x) usually leads to false convergence after
only a few iterations ? often in the first.  Default = 100*MACHEP.

p. 13: Sometimes evaluating f(x) involves an extensive computation,
such as performing a simulation or adaptive numerical quadrature or
integrating an ordinary or partial differential equation. In such
cases the value computed for f (x), say f?( x ), may involve
substantial error (in the eyes of the optimization algorithm).  To
eliminate some ??false convergence?? messages and useless function
evaluations, it is necessary to increase the stopping tolerances and,
when finite-difference derivative approximations are used, to increase
the step-sizes used in estimating derivatives.
----------

"evaluating f(x) involves an extensive computation" is a reasonably
good description of what's going on inside lme4 (although I think the
internal computations are _slightly_ less involved/noisy than a
typical ODE solution or generic integration by quadrature).

Are all of your covariates (year, site) unique, or can you collapse
the data to a binomial variable?  That might help a lot with both
speed and stability, and should be functionally equivalent ...

Observation-level random effects should have essentially no effect
for a Bernoulli variable.

nlminb() is notoriously cryptic/sensitive: it might be worth
checking the development version of lme4, which uses a more
robust optimizer by default (although you can also use nlminb(),
for backward comparison) and allows more control/investigation
of the optimization.

  Ben Bolker


From bbolker at gmail.com  Sun Mar  3 00:04:15 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 02 Mar 2013 18:04:15 -0500
Subject: [R-sig-ME] glmmADMB troubles
In-Reply-To: <512F9ECD.2090905@biostat.ucsf.edu>
References: <512EB394.6070601@biostat.ucsf.edu>
	<loom.20130228T050019-868@post.gmane.org>
	<512F9ECD.2090905@biostat.ucsf.edu>
Message-ID: <5132856F.4080805@gmail.com>

On 13-02-28 01:15 PM, Ross Boylan wrote:
> On 2/27/2013 8:05 PM, Ben Bolker wrote:
>> Ross Boylan <ross at ...> writes:
>>
>>> It seems it's one thing after another.  Ben suggested glmmADMB for
>>> poisson--actually for truncated poisson, but for now I'm just trying to
>>> get anything going.  Some of my count variables have 1, not 0 as a
>>> minimum, and some have a maximum too, e.g., all values >10 are reported
>>> as 10.
>>    If you have enough data to make it worthwhile, you might try the
>> 'ordinal' package ...
> Thanks for the pointer.  Does it make the proportional odds assumption?
>>
>>> I was able to install it from r-forge, with a warning that it was build
>>> for 2.15.3.  But ...
>>>

  [snip]

>>> Figuring that its missing value handling might be off,

  Yes. I might be able to fix the NA-handling, but given that I am
fairly sure that this error means an NA problem, I have taken the lazy
way out and advised the user that this means they have to deal with NAs
themselves.

>> I tried
>>> removing the
>> missing values:
>>>> r <- glmmadmb(sexActs~(1|id), sexpartner[!is.na(sexpartner$sexActs),])
>>> Error in system(cmd, intern = intern, wait = wait | intern,
>> show.output.on.console = wait,  :
>>>     'C:/Program' not found
>>>> traceback()
>>> 4: system(cmd, intern = intern, wait = wait | intern,
>>> show.output.on.console =
>> wait,
>>>          ...)
>>> 3: shell(cmd, invisible = TRUE, intern = !verbose)
>>> 2: run_bin(platform, bin_loc, file_name, cmdoptions, run, rm_binary =
>> !use_tmp_dir,
>>>          debug = debug, verbose = verbose)
>>> 1: glmmadmb(sexActs ~ (1 | id), sexpartner[!is.na(sexpartner$sexActs),
>>>          ])
>>     Hmmm.  Can you give
>>
>> * the results of sessionInfo()
>> * the results of trying your command with debug=TRUE ?
>> * the results of glmmADMB:::get_bin_loc() ?
>>
>>   Ben Bolker
>>
>>
> I wasn't sure which command you wanted trace, and so I did both:
> 
>> library(glmmADMB)
> Loading required package: MASS
> Loading required package: R2admb
> 
> Attaching package: 'glmmADMB'
> 
> The following object(s) are masked from 'package:MASS':
> 
>     stepAIC
> 
> The following object(s) are masked from 'package:lme4':
> 
>     fixef, ranef
> 
> The following object(s) are masked from 'package:stats':
> 
>     step
> 
> Warning message:
> package 'glmmADMB' was built under R version 2.15.3
>> sessionInfo()
> R version 2.15.2 (2012-10-26)
> Platform: i386-w64-mingw32/i386 (32-bit)
> 
> locale:
> [1] LC_COLLATE=English_United States.1252
> [2] LC_CTYPE=English_United States.1252
> [3] LC_MONETARY=English_United States.1252
> [4] LC_NUMERIC=C
> [5] LC_TIME=English_United States.1252
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> other attached packages:
> [1] glmmADMB_0.7.4  R2admb_0.7.5.3  MASS_7.3-22     lme4_0.999999-0
> [5] Matrix_1.0-10   lattice_0.20-10
> 
> loaded via a namespace (and not attached):
>  [1] colorspace_1.2-0   compiler_2.15.2    dichromat_1.2-4    digest_0.6.0
>  [5] ggplot2_0.9.3      grid_2.15.2        gtable_0.1.2       labeling_0.1
>  [9] munsell_0.4        nlme_3.1-106       plyr_1.8           proto_0.3-10
> [13] RColorBrewer_1.0-5 reshape2_1.2.2     scales_0.2.3       stats4_2.15.2
> [17] stringr_0.6.2      tools_2.15.2

  [snip: not including version without NAs removed, since we already
know what the issue is there]

>> r <- glmmadmb(sexActs~(1|id), sexpartner[!is.na(sexpartner$sexActs),],
>> debug=TRUE)
> platform: windows 32
> executable name: glmmadmb.exe
> bin_loc:
> c:/Users/rdboylan/Documents/R/R-2.15.2/site-library/glmmADMB/bin/windows32/glmmadmb.exe
> 
> using temp directory
> C:\Users\rdboylan\AppData\Local\Temp\Rtmpy2JsMY\glmmADMB17085c19f4d
> creating temp directory
> changed working directory to
> C:/Users/rdboylan/AppData/Local/Temp/Rtmpy2JsMY/glmmADMB17085c19f4d
> Command line:
> "c:/Users/rdboylan/Documents/R/R-2.15.2/site-library/glmmADMB/bin/windows32/glmmadmb.exe"
> -maxfn 500 -maxph 5 -noinit -shess
> Error in system(cmd, intern = intern, wait = wait | intern,
> show.output.on.console = wait,  :
>   'C:/Program' not found

  I'm a little bit baffled here.  What happens if you use save.dir to
save the input files to a temporary directory and run

"c:/Users/rdboylan/Documents/R/R-2.15.2/site-library/glmmADMB/bin/windows32/glmmadmb.exe"
-maxfn 500 -maxph 5 -noinit -shess

from the command line?

 What is the result of .Platform (and .Platform$OS in particular)

 It looks conceivably like R is misdiagnosing your system as *not* being
windows, as that's the only way system() should be running.  Are you
running under Cygwin (you say it's installed below) ...  ?

> changed working directory to i:/LAMOC/Ross
> removed temp directory
> C:\Users\rdboylan\AppData\Local\Temp\Rtmpy2JsMY\glmmADMB17085c19f4d
>> glmmADMB:::get_bin_loc()
> $bin_loc
> [1]
> "c:/Users/rdboylan/Documents/R/R-2.15.2/site-library/glmmADMB/bin/windows32/glmmadmb.exe"
> 
> 
> $platform
> [1] "windows"
> 
> P.S. about lme4; I don't have a build environment and so trying the
> github version will not be my first move.
> Although perhaps lack of a build environment is why the second version
> is failing.  I do have cygwin installed, althoughI would not expect R to
> know how to find it.

  lme4 should be installable from lme4.r-forge.r-project.org/repos now,
as stated in a message earlier today.


From s_a_kayis at yahoo.com  Sun Mar  3 04:00:26 2013
From: s_a_kayis at yahoo.com (KAYIS Seyit Ali)
Date: Sat, 2 Mar 2013 19:00:26 -0800 (PST)
Subject: [R-sig-ME] data grouping and fitting mixed model with lme function
In-Reply-To: <1362084961.32249.YahooMailNeo@web160103.mail.bf1.yahoo.com>
References: <mailman.0.1362082796.8720.r-help@r-project.org>
	<1362084961.32249.YahooMailNeo@web160103.mail.bf1.yahoo.com>
Message-ID: <1362279626.41184.YahooMailNeo@web160102.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130302/0d65aa00/attachment.pl>

From cvonende at niu.edu  Sun Mar  3 06:32:46 2013
From: cvonende at niu.edu (Carl Von Ende)
Date: Sat, 02 Mar 2013 23:32:46 -0600
Subject: [R-sig-ME] new "Generalized Linear Mixed Models" book - #2
In-Reply-To: <mailman.2329.1362279636.4638.r-sig-mixed-models@r-project.org>
References: <mailman.2329.1362279636.4638.r-sig-mixed-models@r-project.org>
Message-ID: <51328C1E0200005F00035AB1@smtp2.gw.niu.edu>


A 2nd new GLMM book, in fact, Walter Stroup is 2nd author; haven't
examined other than Table of Contents, on Amazon. 

Analysis of Generalized Linear Mixed Models in the Agricultural and
Natural Resources Sciences (Edward G. Gbur, et al.; ISBN-10:
0891181822). 

Carl von Ende

>>> <r-sig-mixed-models-request at r-project.org> 3/2/2013 9:00 PM >>>
Send R-sig-mixed-models mailing list submissions to
r-sig-mixed-models at r-project.org

To subscribe or unsubscribe via the World Wide Web, visit
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
or, via email, send a message with subject or body 'help' to
r-sig-mixed-models-request at r-project.org

You can reach the person managing the list at
r-sig-mixed-models-owner at r-project.org

When replying, please edit your Subject line so it is more specific
than "Re: Contents of R-sig-mixed-models digest..."


Today's Topics:

   1. New book "Generalized Linear Mixed Models" by WalterStroup
      (Douglas Bates)
   2. updated sourceforge repository (Ben Bolker)
   3. Re: False convergence (Ben Bolker)
   4. Re: glmmADMB troubles (Ben Bolker)
   5. data grouping and fitting mixed model with lme function
      (KAYIS Seyit Ali)


----------------------------------------------------------------------

Message: 1
Date: Sat, 2 Mar 2013 10:51:38 -0600
From: Douglas Bates <bates at stat.wisc.edu>
To: R-mixed models mailing list  
 [R-sig-ME] New book "Generalized Linear Mixed Models" by
WalterStroup
Message-ID:
<CAO7JsnQ4Xqu7YL8jsZ650YofeyJ7koPA_Uwyj=2F=j6MYjMH9Q at mail.gmail.com>
Content-Type: text/plain

I just received a copy of this book (ISBN: 978-1-4398-1512-0) and am
very
favorably impressed - except for his using SAS PROC GLMMIX and for
writing
really long tedious equations for calculations that can be much more
succinctly expressed.

I would recommend to those subscribed to this list to read at least
the
preface and the introductory chapters 1 and 2.   He is quite eloquent
about
the harm caused by teaching the "X\beta + e" mindset that causes so
much
confusion as one tries to extend the linear regression model to other
forms.  His idea of starting with the generalized linear mixed model
framework and showing how it specializes to other forms is absolutely
the
way to go.  One of his suggestions is to start statistics graduate
students
on the general form so that you don't teach them concepts they will
later
need to unlearn and, again, I agree wholeheartedly with him.

I have only skimmed a few chapters and am quite confident that I will
find
parts with which I disagree but on balance I think it is a big step
forward.

[[alternative HTML version deleted]]



------------------------------

Message: 2
Date: Sat, 02 Mar 2013 13:15:21 -0500
From: Ben Bolker <bbolker at gmail.com>
To: "r-sig-mixed-models at r-project.org"
<r-sig-mixed-models at r-project.org>
Subject: [R-sig-ME] updated sourceforge repository
Message-ID: <513241B9.3020404 at mcmaster.ca>
Content-Type: text/plain; charset=ISO-8859-1

I have just pushed updated source, Windows 64-bit binary, and MacOS
binaries of the very most current development version of lme4,
0.99999911-1, to the repository at

http://lme4.r-forge.r-project.org/repos/src/contrib/ ;

**however, it will take up to 24 hours for the web pages to update (so
you won't see the new version right away**.

  You should thereafter be able to

install.packages("lme4",
repos=c("http://lme4.r-forge.r-project.org/repos",
         getOption("repos")))

Please e-mail lme4-authors at R-forge.wu-wien.ac.at if you have problems
with this.

To install the most recent version directly from github (where
development is now proceeding),

library("devtools")
install_github("lme4",user="lme4")

(you will need the Rcpp, RcppEigen, and minqa packages installed
first)

  Ben Bolker



------------------------------

Message: 3
Date: Sat, 2 Mar 2013 21:34:59 +0000 (UTC)
From: Ben Bolker <bbolker at gmail.com>
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] False convergence
Message-ID: <loom.20130302T220905-476 at post.gmane.org>
Content-Type: text/plain; charset=utf-8

Nick Isaac <njbisaac at ...> writes:

> Dear list,
>
> I'm running a set of models in glmer(), some of which return the
'false
> convergence' error (cvg=8). I'm trying to understand why.
>
> My models all have the same basic structure: glmer(P ~ Year +
(1|Site),
> binomial), where P is a vector of 0s and 1s. The Year is centered on
zero,
> which I've found to greatly reduce the incidence of false
convergences in
> the past. There are ~100,000 observations and 9000 sites.
>
> I've tried a couple of fixes, including the .Call("mer_optimize",...)
hack
> as well as an observation-level random effect. the former has no
impact on
> the parameter estimates and the latter still returns the false
convergence
> warning.
>
> I'm using verbose=T argument. I've noticed previously that false
> convergence is characterised by just 1 or 2 iterations being
completed and
> variances on the random effects that are either close to zero or
> astronomically huge. But my models are running to dozens of
iterations with
> sensible looking variances that change moderately among iterations
but then
> stabilise during the last few iterations. And the parameter estimates
look
> sensible.
>
> In other words, the models do not show any evidence of failure,
except the
> warning message. So which should I believe: the verbose trace or the
> warning message?
>
> Perhaps someone can give me further insight into why glmer() thinks
the
> model has not properly converged

  In general I would believe the verbose trace ...

  The stable version of lme4 is using the nlminb() optimizer
internally,
which in turn is based on the PORT libraries

The docs linked from ?nlminb:

http://netlib.bell-labs.com/cm/cs/cstr/153.pdf

The only useful material I could find in these docs was:

------------
p. 5: false convergence: the gradient ?f(x) may be computed
incorrectly, the other stopping tolerances may be too tight, or either
f or ?f may be discontinuous near the current iterate x.

p. 9: V(XFTOL) ? V(34) is the false-convergence tolerance. A return
with IV(1) = 8 occurs if a more favorable stopping test is not
satisfied and if a step of scaled length at most V(XFTOL) is tried but
not accepted. ??Scaled length?? is in the sense of (5.1). Such a
return generally means there is an error in computing ?f(x), or
the favorable convergence tolerances (V(RFCTOL), V(XCTOL), and
perhaps V(AFCTOL)) are too tight for the accuracy to which f(x) is
computed (see ?9), or ?f (or f itself) is discontinuous near x . An
error in computing ?f(x) usually leads to false convergence after
only a few iterations ? often in the first.  Default = 100*MACHEP.

p. 13: Sometimes evaluating f(x) involves an extensive computation,
such as performing a simulation or adaptive numerical quadrature or
integrating an ordinary or partial differential equation. In such
cases the value computed for f (x), say f?( x ), may involve
substantial error (in the eyes of the optimization algorithm).  To
eliminate some ??false convergence?? messages and useless function
evaluations, it is necessary to increase the stopping tolerances and,
when finite-difference derivative approximations are used, to increase
the step-sizes used in estimating derivatives.
----------

"evaluating f(x) involves an extensive computation" is a reasonably
good description of what's going on inside lme4 (although I think the
internal computations are _slightly_ less involved/noisy than a
typical ODE solution or generic integration by quadrature).

Are all of your covariates (year, site) unique, or can you collapse
the data to a binomial variable?  That might help a lot with both
speed and stability, and should be functionally equivalent ...

Observation-level random effects should have essentially no effect
for a Bernoulli variable.

nlminb() is notoriously cryptic/sensitive: it might be worth
checking the development version of lme4, which uses a more
robust optimizer by default (although you can also use nlminb(),
for backward comparison) and allows more control/investigation
of the optimization.

  Ben Bolker



------------------------------

Message: 4
Date: Sat, 02 Mar 2013 18:04:15 -0500
From: Ben Bolker <bbolker at gmail.com>
To: Ross Boylan <ross at biostat.ucsf.edu>
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] glmmADMB troubles
Message-ID: <5132856F.4080805 at gmail.com>
Content-Type: text/plain; charset=ISO-8859-1

On 13-02-28 01:15 PM, Ross Boylan wrote:
> On 2/27/2013 8:05 PM, Ben Bolker wrote:
>> Ross Boylan <ross at ...> writes:
>>
>>> It seems it's one thing after another.  Ben suggested glmmADMB for
>>> poisson--actually for truncated poisson, but for now I'm just
trying to
>>> get anything going.  Some of my count variables have 1, not 0 as a
>>> minimum, and some have a maximum too, e.g., all values >10 are
reported
>>> as 10.
>>    If you have enough data to make it worthwhile, you might try the
>> 'ordinal' package ...
> Thanks for the pointer.  Does it make the proportional odds
assumption?
>>
>>> I was able to install it from r-forge, with a warning that it was
build
>>> for 2.15.3.  But ...
>>>

  [snip]

>>> Figuring that its missing value handling might be off,

  Yes. I might be able to fix the NA-handling, but given that I am
fairly sure that this error means an NA problem, I have taken the lazy
way out and advised the user that this means they have to deal with
NAs
themselves.

>> I tried
>>> removing the
>> missing values:
>>>> r <- glmmadmb(sexActs~(1|id),
sexpartner[!is.na(sexpartner$sexActs),])
>>> Error in system(cmd, intern = intern, wait = wait | intern,
>> show.output.on.console = wait,  :
>>>     'C:/Program' not found
>>>> traceback()
>>> 4: system(cmd, intern = intern, wait = wait | intern,
>>> show.output.on.console =
>> wait,
>>>          ...)
>>> 3: shell(cmd, invisible = TRUE, intern = !verbose)
>>> 2: run_bin(platform, bin_loc, file_name, cmdoptions, run, rm_binary
=
>> !use_tmp_dir,
>>>          debug = debug, verbose = verbose)
>>> 1: glmmadmb(sexActs ~ (1 | id),
sexpartner[!is.na(sexpartner$sexActs),
>>>          ])
>>     Hmmm.  Can you give
>>
>> * the results of sessionInfo()
>> * the results of trying your command with debug=TRUE ?
>> * the results of glmmADMB:::get_bin_loc() ?
>>
>>   Ben Bolker
>>
>>
> I wasn't sure which command you wanted trace, and so I did both:
>
>> library(glmmADMB)
> Loading required package: MASS
> Loading required package: R2admb
>
> Attaching package: 'glmmADMB'
>
> The following object(s) are masked from 'package:MASS':
>
>     stepAIC
>
> The following object(s) are masked from 'package:lme4':
>
>     fixef, ranef
>
> The following object(s) are masked from 'package:stats':
>
>     step
>
> Warning message:
> package 'glmmADMB' was built under R version 2.15.3
>> sessionInfo()
> R version 2.15.2 (2012-10-26)
> Platform: i386-w64-mingw32/i386 (32-bit)
>
> locale:
> [1] LC_COLLATE=English_United States.1252
> [2] LC_CTYPE=English_United States.1252
> [3] LC_MONETARY=English_United States.1252
> [4] LC_NUMERIC=C
> [5] LC_TIME=English_United States.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] glmmADMB_0.7.4  R2admb_0.7.5.3  MASS_7.3-22     lme4_0.999999-0
> [5] Matrix_1.0-10   lattice_0.20-10
>
> loaded via a namespace (and not attached):
>  [1] colorspace_1.2-0   compiler_2.15.2    dichromat_1.2-4   
digest_0.6.0
>  [5] ggplot2_0.9.3      grid_2.15.2        gtable_0.1.2      
labeling_0.1
>  [9] munsell_0.4        nlme_3.1-106       plyr_1.8          
proto_0.3-10
> [13] RColorBrewer_1.0-5 reshape2_1.2.2     scales_0.2.3      
stats4_2.15.2
> [17] stringr_0.6.2      tools_2.15.2

  [snip: not including version without NAs removed, since we already
know what the issue is there]

>> r <- glmmadmb(sexActs~(1|id),
sexpartner[!is.na(sexpartner$sexActs),],
>> debug=TRUE)
> platform: windows 32
> executable name: glmmadmb.exe
> bin_loc:
>
c:/Users/rdboylan/Documents/R/R-2.15.2/site-library/glmmADMB/bin/windows32/glmmadmb.exe
>
> using temp directory
> C:\Users\rdboylan\AppData\Local\Temp\Rtmpy2JsMY\glmmADMB17085c19f4d
> creating temp directory
> changed working directory to
> C:/Users/rdboylan/AppData/Local/Temp/Rtmpy2JsMY/glmmADMB17085c19f4d
> Command line:
>
"c:/Users/rdboylan/Documents/R/R-2.15.2/site-library/glmmADMB/bin/windows32/glmmadmb.exe"
> -maxfn 500 -maxph 5 -noinit -shess
> Error in system(cmd, intern = intern, wait = wait | intern,
> show.output.on.console = wait,  :
>   'C:/Program' not found

  I'm a little bit baffled here.  What happens if you use save.dir to
save the input files to a temporary directory and run

"c:/Users/rdboylan/Documents/R/R-2.15.2/site-library/glmmADMB/bin/windows32/glmmadmb.exe"
-maxfn 500 -maxph 5 -noinit -shess

from the command line?

What is the result of .Platform (and .Platform$OS in particular)

It looks conceivably like R is misdiagnosing your system as *not*
being
windows, as that's the only way system() should be running.  Are you
running under Cygwin (you say it's installed below) ...  ?

> changed working directory to i:/LAMOC/Ross
> removed temp directory
> C:\Users\rdboylan\AppData\Local\Temp\Rtmpy2JsMY\glmmADMB17085c19f4d
>> glmmADMB:::get_bin_loc()
> $bin_loc
> [1]
>
"c:/Users/rdboylan/Documents/R/R-2.15.2/site-library/glmmADMB/bin/windows32/glmmadmb.exe"
>
>
> $platform
> [1] "windows"
>
> P.S. about lme4; I don't have a build environment and so trying the
> github version will not be my first move.
> Although perhaps lack of a build environment is why the second
version
> is failing.  I do have cygwin installed, althoughI would not expect R
to
> know how to find it.

  lme4 should be installable from lme4.r-forge.r-project.org/repos
now,
as stated in a message earlier today.



------------------------------

Message: 5
Date: Sat, 2 Mar 2013 19:00:26 -0800 (PST)
From: KAYIS Seyit Ali <s_a_kayis at yahoo.com>
To: "r-sig-mixed-models at r-project.org"
<r-sig-mixed-models at r-project.org>
Subject: [R-sig-ME] data grouping and fitting mixed model with lme
function
Message-ID:
<1362279626.41184.YahooMailNeo at web160102.mail.bf1.yahoo.com>
Content-Type: text/plain

Dear all,
? 
I have data from the following experimental design and trying to fit a
mixed model with lme function according to following steps but
struggling. Any help is deeply appreciated.
? 
1) Experimental design: I have 40 plants each of which has 4 clones.
Each clone planted to one of 4 blocks. Phenotypes were collected from
each clone for 3 consecutive years. I have genotypes of plants. I need
to relate phenotype to genotype.
? 
2) I am reading data from a file with ???read.table??  function. Then
grouping data as: my.Data<-groupedData( phenotype ~ Block | PlantID,
data = as.data.frame( Data ) )
? 
3) I want to fit Genotype + Year + Genotype:Year as fixed effect. Block
+ PlantID + Block.PlantID as random effect.
? 
I feel? my data grouping is incorrect? as model fitting do? not work
properly.
? 
Some part of my data was added below in case it would help to
understand the structure.
? 
Any help regarding data grouping and model fitting is deeply
appreciated.
? 
Kind Regards
? 
Seyit Ali
? 
? 
PlantID Block Year Diameter Genotype
1 1 1 170 0
1 2 1 166 0
1 3 1 168 0
1 4 1 169 0
1 1 2 142 0
1 2 2 115 0
1 3 2 131 0
1 4 2 129 0
1 1 3 138 0
1 2 3 142 0
1 3 3 139 0
1 4 3 135 0
2 1 1 155 1
2 2 1 168 1
2 3 1 158 1
2 4 1 145 1
2 1 2 131 1
2 2 2 150 1
2 3 2 130 1
2 4 2 130 1
2 1 3 123 1
2 2 3 125 1
2 3 3 126 1
2 4 3 129 1
3 1 1 142 0
3 2 1 155 0
3 3 1 150 0
3 4 1 149 0
3 1 2 123 0
3 2 2 129 0
3 3 2 134 0
3 4 2 131 0
3 1 3 126 0
3 2 3 117 0
3 3 3 123 0
3 4 3 126 0
4 1 1 167 0
4 2 1 156 0
4 3 1 161 0
4 4 1 164 0
4 1 2 148 0
4 2 2 133 0
4 3 2 144 0
4 4 2 127 0
4 1 3 137 0
4 2 3 134 0
4 3 3 135 0
4 4 3 135 0
5 1 1 146 1
5 2 1 156 1
5 3 1 152 1
5 4 1 147 1
5 1 2 122 1
5 2 2 131 1
5 3 2 132 1
5 4 2 130 1
5 1 3 127 1
5 2 3 126 1
5 3 3 130 1
5 4 3 136 1
6 1 1 148 0
6 2 1 161 0
6 3 1 140 0
6 4 1 150 0
6 1 2 123 0
6 2 2 130 0
6 3 2 120 0
6 4 2 134 0
6 1 3 123 0
6 2 3 132 0
6 3 3 128 0
6 4 3 128 0
7 1 1 152 1
7 2 1 147 1
7 3 1 153 1
7 4 1 170 1
7 1 2 124 1
7 2 2 130 1
7 3 2 135 1
7 4 2 128 1
7 1 3 128 1
7 2 3 129 1
7 3 3 129 1
7 4 3 129 1
8 1 1 141 0
8 2 1 129 0
8 3 1 135 0
8 4 1 138 0
8 1 2 117 0
8 2 2 124 0
8 3 2 121 0
8 4 2 127 0
8 1 3 124 0
8 2 3 125 0
8 3 3 123 0
8 4 3 121 0
9 1 1 150 1
9 2 1 153 1
9 3 1 147 1
9 4 1 148 1
9 1 2 135 1
9 2 2 131 1
9 3 2 133 1
9 4 2 135 1
9 1 3 130 1
9 2 3 130 1
9 3 3 129 1
9 4 3 128 1
10 1 1 152 1
10 2 1 143 1
10 3 1 148 1
10 4 1 150 1
10 1 2 134 1
10 2 2 128 1
10 3 2 133 1
10 4 2 132 1
10 1 3 129 1
10 2 3 133 1
10 3 3 129 1
10 4 3 130 1


------------------------------------------------------------------------
Dr. Seyit Ali KAYIS
Selcuk University, Faculty of Agriculture
Kampus/Konya, Turkey



Tel: +90 332 223 2830 Mobile: +90 535 587 1139


Greetings from Konya, Turkey
http://www.ziraat.selcuk.edu.tr/skayis/
------------------------------------------------------------------------


________________________________
[[alternative HTML version deleted]]



------------------------------

_______________________________________________
R-sig-mixed-models mailing list
R-sig-mixed-models at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


End of R-sig-mixed-models Digest, Vol 75, Issue 6
*************************************************

From steve.taylor at aut.ac.nz  Mon Mar  4 00:10:29 2013
From: steve.taylor at aut.ac.nz (Steve Taylor)
Date: Sun, 3 Mar 2013 23:10:29 +0000
Subject: [R-sig-ME] Can AIC be approximated by -2ln(L) i.e. the deviance,
 at very large sample size?
In-Reply-To: <20130301081742.GB7102@laboinfo-063.pharmacie.univ-paris5.fr>
References: <d6ba819f99e6538a1df99da8d2250e0d@mail.gmail.com>
	<20130301081742.GB7102@laboinfo-063.pharmacie.univ-paris5.fr>
Message-ID: <CCE952776B6679469977532BD863C39C3A8F552D@Lewis.autuni.aut.ac.nz>

I agree that it is changes in AIC that matter, not its absolute value.  

My understanding is that AIC is only useful for comparing two models fitted on the same data set, i.e. with the same sample size.  So the question of how AIC changes with sample size is of little use beyond curiosity.  

The change in AIC caused by adding a term to the model formula would be of interest.  But the change in AIC caused by adding cases to the sample size is pretty meaningless.

The 2K part is important because it provides a penalty for the change in the number of parameters between a simpler model and a more complex model.

I would advise against making any approximations when calculating AIC, especially considering its main use is in taking the difference between two close large numbers.

cheers,
    Steve


-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Emmanuel Curis
Sent: Friday, 1 March 2013 9:18p
To: Chris Howden
Cc: r-sig-mixed-models
Subject: Re: [R-sig-ME] Can AIC be approximated by -2ln(L) i.e. the deviance, at very large sample size?

Hi,

I may be wrong, but I understood that AIC in itself is not as
important as changes in AIC between models, and some authors says that
changes in AIC in the order of more than 10 are enough to favor a
model on another.

And changes in the 2*k term should be in this order of magnitude when
comparing different models.

So my guess would be that it remains important.

On the other hand, if a set of parameters will remain in all models,
it probably can be safely ignored in the 2*k term for all models.

Hope this helps,

On Fri, Mar 01, 2013 at 06:30:53PM +1100, Chris Howden wrote:
< Hi everyone,
< 
< Although not strictly an R issue there often seems to be discussions along
< these lines on this list, so I hope no one minds me posting this. If U do
< please let me know. (and just for the record I am applying this in R)
< 
< I'm trying to get my head around AIC and sample size.
< 
< Now if AIC = -2ln(L) + 2K = Deviance + 2K
< 
< Am I right in thinking that as the Likelihood is the product of
< probabilities then (all else being equal) the larger the sample size the
< smaller the Likelihood?
< Which means that if we have very large sample sizes we expect the -2ln(L)
< term to be a very large number?
< Which would reduce the effect of the parameter correction term 2K?
< 
< 
< Chris Howden B.Sc. (Hons) GStat.
< Founding Partner
< Evidence Based Strategic Development, IP Commercialisation and Innovation,
< Data Analysis, Modelling and Training
< (mobile) 0410 689 945
< (fax) +612 4782 9023
< chris at trickysolutions.com.au
< 
< _______________________________________________
< R-sig-mixed-models at r-project.org mailing list
< https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
                                Emmanuel CURIS
                                emmanuel.curis at parisdescartes.fr

Page WWW: http://emmanuel.curis.online.fr/index.html

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From chris at trickysolutions.com.au  Mon Mar  4 01:04:01 2013
From: chris at trickysolutions.com.au (Chris Howden)
Date: Mon, 4 Mar 2013 11:04:01 +1100
Subject: [R-sig-ME] Can AIC be approximated by -2ln(L) i.e. the deviance,
 at very large sample size?
In-Reply-To: <CCE952776B6679469977532BD863C39C3A8F552D@Lewis.autuni.aut.ac.nz>
References: <d6ba819f99e6538a1df99da8d2250e0d@mail.gmail.com>
	<20130301081742.GB7102@laboinfo-063.pharmacie.univ-paris5.fr>
	<CCE952776B6679469977532BD863C39C3A8F552D@Lewis.autuni.aut.ac.nz>
Message-ID: <c899be8250968a271a92b9040ef97665@mail.gmail.com>

Thanks for the responses everyone,

I agree that its changes of 'goodness of fit' Likelihood functions such as
AIC and deviance that matter, not their absolute size.

However I think the impact of sample size may be something we need to
consider, particularly when analysing "Big Data" sets.

I recently did some analysis on "Big Data", the number of rows was over
300 000. What I found was that the Full Model was always selected using
AIC, Deviance and LRT. However when I had a look at the effects of the
predictors I found some of them were negligible, to the point of not
really being worth including in the model. Despite what the AIC and LRT
say.

This seems to be the same sample size issue faced with simple Univariate
tests such as ANOVA i.e. large sample sizes give so much power that
statistically significant results may be of no/little practical value.


The reason I asked about the convergence of deviance and AIC at large
sample sizes was thus.

The LRT tests between the Full model and 1 less predictor all had
exceptionally small p-values, which meant that the difference in Ln(L) was
very large. So large that it appears that the difference in deviance and
AIC was essentially the same.

So although it?s the difference that matters, if they converge at large
sample sizes than a large difference in deviance means there will also be
a large difference in AIC and they will come to the same conclusion??

However as they don't converge at small sample sizes this effect is not as
relevant.

Chris Howden B.Sc. (Hons) GStat.
Founding Partner
Evidence Based Strategic Development, IP Commercialisation and Innovation,
Data Analysis, Modelling and Training
(mobile) 0410 689 945
(fax) +612 4782 9023
chris at trickysolutions.com.au




Disclaimer: The information in this email and any attachments to it are
confidential and may contain legally privileged information.?If you are
not the named or intended recipient, please delete this communication and
contact us immediately.?Please note you are not authorised to copy, use or
disclose this communication or any attachments without our consent.
Although this email has been checked by anti-virus software, there is a
risk that email messages may be corrupted or infected by viruses or other
interferences. No responsibility is accepted for such interference. Unless
expressly stated, the views of the writer are not those of the company.
Tricky Solutions always does our best to provide accurate forecasts and
analyses based on the data supplied, however it is possible that some
important predictors were not included in the data sent to us. Information
provided by us should not be solely relied upon when making decisions and
clients should use their own judgement.


-----Original Message-----
From: Steve Taylor [mailto:steve.taylor at aut.ac.nz]
Sent: Monday, 4 March 2013 10:10 AM
To: Emmanuel Curis; Chris Howden
Cc: r-sig-mixed-models
Subject: RE: [R-sig-ME] Can AIC be approximated by -2ln(L) i.e. the
deviance, at very large sample size?

I agree that it is changes in AIC that matter, not its absolute value.

My understanding is that AIC is only useful for comparing two models
fitted on the same data set, i.e. with the same sample size.  So the
question of how AIC changes with sample size is of little use beyond
curiosity.

The change in AIC caused by adding a term to the model formula would be of
interest.  But the change in AIC caused by adding cases to the sample size
is pretty meaningless.

The 2K part is important because it provides a penalty for the change in
the number of parameters between a simpler model and a more complex model.

I would advise against making any approximations when calculating AIC,
especially considering its main use is in taking the difference between
two close large numbers.

cheers,
    Steve


-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org
[mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Emmanuel
Curis
Sent: Friday, 1 March 2013 9:18p
To: Chris Howden
Cc: r-sig-mixed-models
Subject: Re: [R-sig-ME] Can AIC be approximated by -2ln(L) i.e. the
deviance, at very large sample size?

Hi,

I may be wrong, but I understood that AIC in itself is not as important as
changes in AIC between models, and some authors says that changes in AIC
in the order of more than 10 are enough to favor a model on another.

And changes in the 2*k term should be in this order of magnitude when
comparing different models.

So my guess would be that it remains important.

On the other hand, if a set of parameters will remain in all models, it
probably can be safely ignored in the 2*k term for all models.

Hope this helps,

On Fri, Mar 01, 2013 at 06:30:53PM +1100, Chris Howden wrote:
< Hi everyone,
<
< Although not strictly an R issue there often seems to be discussions
along < these lines on this list, so I hope no one minds me posting this.
If U do < please let me know. (and just for the record I am applying this
in R) < < I'm trying to get my head around AIC and sample size.
<
< Now if AIC = -2ln(L) + 2K = Deviance + 2K < < Am I right in thinking
that as the Likelihood is the product of < probabilities then (all else
being equal) the larger the sample size the < smaller the Likelihood?
< Which means that if we have very large sample sizes we expect the
-2ln(L) < term to be a very large number?
< Which would reduce the effect of the parameter correction term 2K?
<
<
< Chris Howden B.Sc. (Hons) GStat.
< Founding Partner
< Evidence Based Strategic Development, IP Commercialisation and
Innovation, < Data Analysis, Modelling and Training < (mobile) 0410 689
945 < (fax) +612 4782 9023 < chris at trickysolutions.com.au < <
_______________________________________________
< R-sig-mixed-models at r-project.org mailing list <
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

--
                                Emmanuel CURIS
                                emmanuel.curis at parisdescartes.fr

Page WWW: http://emmanuel.curis.online.fr/index.html

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From lborger at cebc.cnrs.fr  Mon Mar  4 01:29:56 2013
From: lborger at cebc.cnrs.fr (lborger)
Date: Mon, 04 Mar 2013 01:29:56 +0100
Subject: [R-sig-ME] Can AIC be approximated by -2ln(L) i.e. the deviance,
	at very large sample size?
In-Reply-To: <c899be8250968a271a92b9040ef97665@mail.gmail.com>
References: <d6ba819f99e6538a1df99da8d2250e0d@mail.gmail.com>
	<20130301081742.GB7102@laboinfo-063.pharmacie.univ-paris5.fr>
	<CCE952776B6679469977532BD863C39C3A8F552D@Lewis.autuni.aut.ac.nz>
	<c899be8250968a271a92b9040ef97665@mail.gmail.com>
Message-ID: <WC20130304002956.8303AE@cebc.cnrs.fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130304/a7c2d370/attachment.pl>

From bbolker at gmail.com  Mon Mar  4 01:37:23 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 03 Mar 2013 19:37:23 -0500
Subject: [R-sig-ME] Can AIC be approximated by -2ln(L) i.e. the deviance,
 at very large sample size?
In-Reply-To: <c899be8250968a271a92b9040ef97665@mail.gmail.com>
References: <d6ba819f99e6538a1df99da8d2250e0d@mail.gmail.com>
	<20130301081742.GB7102@laboinfo-063.pharmacie.univ-paris5.fr>
	<CCE952776B6679469977532BD863C39C3A8F552D@Lewis.autuni.aut.ac.nz>
	<c899be8250968a271a92b9040ef97665@mail.gmail.com>
Message-ID: <5133ECC3.3030106@gmail.com>

On 13-03-03 07:04 PM, Chris Howden wrote:
> Thanks for the responses everyone,
> 
> I agree that its changes of 'goodness of fit' Likelihood functions such as
> AIC and deviance that matter, not their absolute size.
> 
> However I think the impact of sample size may be something we need to
> consider, particularly when analysing "Big Data" sets.
> 
> I recently did some analysis on "Big Data", the number of rows was over
> 300 000. What I found was that the Full Model was always selected using
> AIC, Deviance and LRT. However when I had a look at the effects of the
> predictors I found some of them were negligible, to the point of not
> really being worth including in the model. Despite what the AIC and LRT
> say.

  Well, what do you mean by "not really worth including in the model"?
The AIC is telling you that they improve the expected predictive
accuracy.  "Too small to be interesting" is certainly possible, but it's
impossible for us to know (without the context of the question and
without knowing what question you're trying to answer with the model)
whether the effects are or aren't.

> 
> This seems to be the same sample size issue faced with simple Univariate
> tests such as ANOVA i.e. large sample sizes give so much power that
> statistically significant results may be of no/little practical value.
> 
> The reason I asked about the convergence of deviance and AIC at large
> sample sizes was thus.
> 
> The LRT tests between the Full model and 1 less predictor all had
> exceptionally small p-values, which meant that the difference in Ln(L) was
> very large. 

  (I would put this the other way around: deviance/log-likelihood
difference is more fundamental than p-value.)

> So large that it appears that the difference in deviance and
> AIC was essentially the same.

  Yes, it's true that for a fixed range of model sizes, model complexity
matters less and less for large samples.

> So although it?s the difference that matters, if they converge at large
> sample sizes then a large difference in deviance means there will also be
> a large difference in AIC and they will come to the same conclusion??
> 
> However as they don't converge at small sample sizes this effect is not as
> relevant.

  It's fairly well known, I think, that "everything is significant" for
sufficiently large sample sizes.  Arguably (e.g. according to Andrew
Gelman) we should be using hierarchical models to include more and more
structure in our models, so that we are always extracting as much
information as is in the data ...

  I'm not really clear on what your question is any more.  (And, these
are really general stats/modelling questions, not so much mixed modeling
questions ...)

  cheers
    Ben Bolker


> 
> Chris Howden B.Sc. (Hons) GStat.
> Founding Partner
> Evidence Based Strategic Development, IP Commercialisation and Innovation,
> Data Analysis, Modelling and Training
> (mobile) 0410 689 945
> (fax) +612 4782 9023
> chris at trickysolutions.com.au
> 
> 
> 
> 
> Disclaimer: The information in this email and any attachments to it are
> confidential and may contain legally privileged information. If you are
> not the named or intended recipient, please delete this communication and
> contact us immediately. Please note you are not authorised to copy, use or
> disclose this communication or any attachments without our consent.
> Although this email has been checked by anti-virus software, there is a
> risk that email messages may be corrupted or infected by viruses or other
> interferences. No responsibility is accepted for such interference. Unless
> expressly stated, the views of the writer are not those of the company.
> Tricky Solutions always does our best to provide accurate forecasts and
> analyses based on the data supplied, however it is possible that some
> important predictors were not included in the data sent to us. Information
> provided by us should not be solely relied upon when making decisions and
> clients should use their own judgement.
> 
> 
> -----Original Message-----
> From: Steve Taylor [mailto:steve.taylor at aut.ac.nz]
> Sent: Monday, 4 March 2013 10:10 AM
> To: Emmanuel Curis; Chris Howden
> Cc: r-sig-mixed-models
> Subject: RE: [R-sig-ME] Can AIC be approximated by -2ln(L) i.e. the
> deviance, at very large sample size?
> 
> I agree that it is changes in AIC that matter, not its absolute value.
> 
> My understanding is that AIC is only useful for comparing two models
> fitted on the same data set, i.e. with the same sample size.  So the
> question of how AIC changes with sample size is of little use beyond
> curiosity.
> 
> The change in AIC caused by adding a term to the model formula would be of
> interest.  But the change in AIC caused by adding cases to the sample size
> is pretty meaningless.
> 
> The 2K part is important because it provides a penalty for the change in
> the number of parameters between a simpler model and a more complex model.
> 
> I would advise against making any approximations when calculating AIC,
> especially considering its main use is in taking the difference between
> two close large numbers.
> 
> cheers,
>     Steve
> 
> 
> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org
> [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Emmanuel
> Curis
> Sent: Friday, 1 March 2013 9:18p
> To: Chris Howden
> Cc: r-sig-mixed-models
> Subject: Re: [R-sig-ME] Can AIC be approximated by -2ln(L) i.e. the
> deviance, at very large sample size?
> 
> Hi,
> 
> I may be wrong, but I understood that AIC in itself is not as important as
> changes in AIC between models, and some authors says that changes in AIC
> in the order of more than 10 are enough to favor a model on another.
> 
> And changes in the 2*k term should be in this order of magnitude when
> comparing different models.
> 
> So my guess would be that it remains important.
> 
> On the other hand, if a set of parameters will remain in all models, it
> probably can be safely ignored in the 2*k term for all models.
> 
> Hope this helps,
> 
> On Fri, Mar 01, 2013 at 06:30:53PM +1100, Chris Howden wrote:
> < Hi everyone,
> <
> < Although not strictly an R issue there often seems to be discussions
> along < these lines on this list, so I hope no one minds me posting this.
> If U do < please let me know. (and just for the record I am applying this
> in R) < < I'm trying to get my head around AIC and sample size.
> <
> < Now if AIC = -2ln(L) + 2K = Deviance + 2K < < Am I right in thinking
> that as the Likelihood is the product of < probabilities then (all else
> being equal) the larger the sample size the < smaller the Likelihood?
> < Which means that if we have very large sample sizes we expect the
> -2ln(L) < term to be a very large number?
> < Which would reduce the effect of the parameter correction term 2K?
> <
> <
> < Chris Howden B.Sc. (Hons) GStat.
> < Founding Partner
> < Evidence Based Strategic Development, IP Commercialisation and
> Innovation, < Data Analysis, Modelling and Training < (mobile) 0410 689
> 945 < (fax) +612 4782 9023 < chris at trickysolutions.com.au < <
> _______________________________________________
> < R-sig-mixed-models at r-project.org mailing list <
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> --
>                                 Emmanuel CURIS
>                                 emmanuel.curis at parisdescartes.fr
> 
> Page WWW: http://emmanuel.curis.online.fr/index.html
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From ross at biostat.ucsf.edu  Mon Mar  4 01:47:56 2013
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Sun, 03 Mar 2013 16:47:56 -0800
Subject: [R-sig-ME] glmmADMB troubles
In-Reply-To: <5132856F.4080805@gmail.com>
References: <512EB394.6070601@biostat.ucsf.edu>
	<loom.20130228T050019-868@post.gmane.org>
	<512F9ECD.2090905@biostat.ucsf.edu>  <5132856F.4080805@gmail.com>
Message-ID: <1362358076.16392.16.camel@corn.betterworld.us>

On Sat, 2013-03-02 at 18:04 -0500, Ben Bolker wrote:
> 
> >> r <- glmmadmb(sexActs~(1|id), sexpartner[!is.na(sexpartner
> $sexActs),],
> >> debug=TRUE)
> > platform: windows 32
> > executable name: glmmadmb.exe
> > bin_loc:
> >
> c:/Users/rdboylan/Documents/R/R-2.15.2/site-library/glmmADMB/bin/windows32/glmmadmb.exe
> > 
> > using temp directory
> > C:\Users\rdboylan\AppData\Local\Temp\Rtmpy2JsMY\glmmADMB17085c19f4d
> > creating temp directory
> > changed working directory to
> > C:/Users/rdboylan/AppData/Local/Temp/Rtmpy2JsMY/glmmADMB17085c19f4d
> > Command line:
> >
> "c:/Users/rdboylan/Documents/R/R-2.15.2/site-library/glmmADMB/bin/windows32/glmmadmb.exe"
> > -maxfn 500 -maxph 5 -noinit -shess
> > Error in system(cmd, intern = intern, wait = wait | intern,
> > show.output.on.console = wait,  :
> >   'C:/Program' not found
> 
>   I'm a little bit baffled here.  What happens if you use save.dir to
> save the input files to a temporary directory and run
I'll try when I'm at the machine (later in the week).
> 
> "c:/Users/rdboylan/Documents/R/R-2.15.2/site-library/glmmADMB/bin/windows32/glmmadmb.exe"
> -maxfn 500 -maxph 5 -noinit -shess
> 
> from the command line?
> 
>  What is the result of .Platform (and .Platform$OS in particular)
> 
>  It looks conceivably like R is misdiagnosing your system as *not*
> being
> windows, as that's the only way system() should be running.  Are you
> running under Cygwin (you say it's installed below) ...  ?
I am not running under cygwin, at least not knowingly.

I may have set up emacs to try to use cygwin; maybe that leaked into R
running under ESS.  My emacs is the Windows version.

I took the "C:/Program" reference to mean that it was trying to execute
"C:/Program Files/...." but couldn't deal with the space.  If it's
trying to execute glmmadb.exe then the problem is that it has looked up
a system path while the program (R and packages) is installed at the
user level.

Ross
>


From chris at trickysolutions.com.au  Mon Mar  4 02:18:49 2013
From: chris at trickysolutions.com.au (Chris Howden)
Date: Mon, 4 Mar 2013 12:18:49 +1100
Subject: [R-sig-ME] Can AIC be approximated by -2ln(L) i.e. the deviance,
 at very large sample size?
In-Reply-To: <5133ECC3.3030106@gmail.com>
References: <d6ba819f99e6538a1df99da8d2250e0d@mail.gmail.com>
	<20130301081742.GB7102@laboinfo-063.pharmacie.univ-paris5.fr>
	<CCE952776B6679469977532BD863C39C3A8F552D@Lewis.autuni.aut.ac.nz>
	<c899be8250968a271a92b9040ef97665@mail.gmail.com>
	<5133ECC3.3030106@gmail.com>
Message-ID: <af5c027989e5cfd81c4ee79f6c1479b6@mail.gmail.com>

Thanks for the reply Ben,

In response to your specific points

>>  Well, what do you mean by "not really worth including in the model"?
1) In terms of "too small to be interesting" I mean an Odds Ratio of 1.02
(from a GLMM with binomial family and random intercept based on the
individuals, each individual having 100's of data points)


>>  It's fairly well known, I think, that "everything is significant" for
sufficiently large sample sizes.  Arguably (e.g. according to Andrew
>> Gelman) we should be using hierarchical models to include more and more
structure in our models, so that we are always extracting as much
information as is >> in the data ...
I wish it was well known, but I'm not so sure. One of the reasons I'm
asking this is that we are trying to publish our results and the reviewers
keep saying things like "If U had used AIC U wouldn't have this problem,
so go back and reanalyse it using AIC". We have stated that we have a
"ubiquitous significance" problem partially due to sample size and have
suggested a way around it that involves interpreting the effect sizes at
different spatial scales in order to find those that are useful. But I'm
having a hard time convincing people, so I'm trying to put together a
mathematical reason, which leads into your next point.


>>  I'm not really clear on what your question is any more.  (And, these
are really general stats/modelling questions, not so much mixed modeling
questions ...)

Yes, I suppose it was more of a general stats/modelling questions, I was
trying to get my head around the math of ln(L) functions such as AIC and
deviance and how it behaves at large sample sizes. I posted it here since
I fit a GLMM in R and also because of all the lists I'm on this one seemed
to be the only one where such matters are discussed at any level of
expertise or interest. I hope it's OK that I did. I work from home in a
remote area, and unfortunately don't have the benefit of having
statistical colleagues I can discuss these things with. I wish I did!!! It
gets rather lonely being the only statistician in town, I tend to get a
lot of good natured "there he goes again" looks whenever I get a bit too
excited about something statistical and try to share  :(




Chris Howden B.Sc. (Hons) GStat.
Founding Partner
Evidence Based Strategic Development, IP Commercialisation and Innovation,
Data Analysis, Modelling and Training
(mobile) 0410 689 945
(fax) +612 4782 9023
chris at trickysolutions.com.au




Disclaimer: The information in this email and any attachments to it are
confidential and may contain legally privileged information.?If you are
not the named or intended recipient, please delete this communication and
contact us immediately.?Please note you are not authorised to copy, use or
disclose this communication or any attachments without our consent.
Although this email has been checked by anti-virus software, there is a
risk that email messages may be corrupted or infected by viruses or other
interferences. No responsibility is accepted for such interference. Unless
expressly stated, the views of the writer are not those of the company.
Tricky Solutions always does our best to provide accurate forecasts and
analyses based on the data supplied, however it is possible that some
important predictors were not included in the data sent to us. Information
provided by us should not be solely relied upon when making decisions and
clients should use their own judgement.


-----Original Message-----
From: Ben Bolker [mailto:bbolker at gmail.com]
Sent: Monday, 4 March 2013 11:37 AM
To: Chris Howden
Cc: Steve Taylor; Emmanuel Curis; r-sig-mixed-models
Subject: Re: [R-sig-ME] Can AIC be approximated by -2ln(L) i.e. the
deviance, at very large sample size?

On 13-03-03 07:04 PM, Chris Howden wrote:
> Thanks for the responses everyone,
>
> I agree that its changes of 'goodness of fit' Likelihood functions
> such as AIC and deviance that matter, not their absolute size.
>
> However I think the impact of sample size may be something we need to
> consider, particularly when analysing "Big Data" sets.
>
> I recently did some analysis on "Big Data", the number of rows was
> over
> 300 000. What I found was that the Full Model was always selected
> using AIC, Deviance and LRT. However when I had a look at the effects
> of the predictors I found some of them were negligible, to the point
> of not really being worth including in the model. Despite what the AIC
> and LRT say.

  Well, what do you mean by "not really worth including in the model"?
The AIC is telling you that they improve the expected predictive accuracy.
"Too small to be interesting" is certainly possible, but it's impossible
for us to know (without the context of the question and without knowing
what question you're trying to answer with the model) whether the effects
are or aren't.

>
> This seems to be the same sample size issue faced with simple
> Univariate tests such as ANOVA i.e. large sample sizes give so much
> power that statistically significant results may be of no/little
practical value.
>
> The reason I asked about the convergence of deviance and AIC at large
> sample sizes was thus.
>
> The LRT tests between the Full model and 1 less predictor all had
> exceptionally small p-values, which meant that the difference in Ln(L)
> was very large.

  (I would put this the other way around: deviance/log-likelihood
difference is more fundamental than p-value.)

> So large that it appears that the difference in deviance and AIC was
> essentially the same.

  Yes, it's true that for a fixed range of model sizes, model complexity
matters less and less for large samples.

> So although it?s the difference that matters, if they converge at
> large sample sizes then a large difference in deviance means there
> will also be a large difference in AIC and they will come to the same
conclusion??
>
> However as they don't converge at small sample sizes this effect is
> not as relevant.

  It's fairly well known, I think, that "everything is significant" for
sufficiently large sample sizes.  Arguably (e.g. according to Andrew
Gelman) we should be using hierarchical models to include more and more
structure in our models, so that we are always extracting as much
information as is in the data ...

  I'm not really clear on what your question is any more.  (And, these are
really general stats/modelling questions, not so much mixed modeling
questions ...)

  cheers
    Ben Bolker


>
> Chris Howden B.Sc. (Hons) GStat.
> Founding Partner
> Evidence Based Strategic Development, IP Commercialisation and
> Innovation, Data Analysis, Modelling and Training
> (mobile) 0410 689 945
> (fax) +612 4782 9023
> chris at trickysolutions.com.au
>
>
>
>
> Disclaimer: The information in this email and any attachments to it
> are confidential and may contain legally privileged information. If
> you are not the named or intended recipient, please delete this
> communication and contact us immediately. Please note you are not
> authorised to copy, use or disclose this communication or any
attachments without our consent.
> Although this email has been checked by anti-virus software, there is
> a risk that email messages may be corrupted or infected by viruses or
> other interferences. No responsibility is accepted for such
> interference. Unless expressly stated, the views of the writer are not
those of the company.
> Tricky Solutions always does our best to provide accurate forecasts
> and analyses based on the data supplied, however it is possible that
> some important predictors were not included in the data sent to us.
> Information provided by us should not be solely relied upon when
> making decisions and clients should use their own judgement.
>
>
> -----Original Message-----
> From: Steve Taylor [mailto:steve.taylor at aut.ac.nz]
> Sent: Monday, 4 March 2013 10:10 AM
> To: Emmanuel Curis; Chris Howden
> Cc: r-sig-mixed-models
> Subject: RE: [R-sig-ME] Can AIC be approximated by -2ln(L) i.e. the
> deviance, at very large sample size?
>
> I agree that it is changes in AIC that matter, not its absolute value.
>
> My understanding is that AIC is only useful for comparing two models
> fitted on the same data set, i.e. with the same sample size.  So the
> question of how AIC changes with sample size is of little use beyond
> curiosity.
>
> The change in AIC caused by adding a term to the model formula would
> be of interest.  But the change in AIC caused by adding cases to the
> sample size is pretty meaningless.
>
> The 2K part is important because it provides a penalty for the change
> in the number of parameters between a simpler model and a more complex
model.
>
> I would advise against making any approximations when calculating AIC,
> especially considering its main use is in taking the difference
> between two close large numbers.
>
> cheers,
>     Steve
>
>
> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org
> [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of
> Emmanuel Curis
> Sent: Friday, 1 March 2013 9:18p
> To: Chris Howden
> Cc: r-sig-mixed-models
> Subject: Re: [R-sig-ME] Can AIC be approximated by -2ln(L) i.e. the
> deviance, at very large sample size?
>
> Hi,
>
> I may be wrong, but I understood that AIC in itself is not as
> important as changes in AIC between models, and some authors says that
> changes in AIC in the order of more than 10 are enough to favor a model
on another.
>
> And changes in the 2*k term should be in this order of magnitude when
> comparing different models.
>
> So my guess would be that it remains important.
>
> On the other hand, if a set of parameters will remain in all models,
> it probably can be safely ignored in the 2*k term for all models.
>
> Hope this helps,
>
> On Fri, Mar 01, 2013 at 06:30:53PM +1100, Chris Howden wrote:
> < Hi everyone,
> <
> < Although not strictly an R issue there often seems to be discussions
> along < these lines on this list, so I hope no one minds me posting
this.
> If U do < please let me know. (and just for the record I am applying
> this in R) < < I'm trying to get my head around AIC and sample size.
> <
> < Now if AIC = -2ln(L) + 2K = Deviance + 2K < < Am I right in thinking
> that as the Likelihood is the product of < probabilities then (all
> else being equal) the larger the sample size the < smaller the
Likelihood?
> < Which means that if we have very large sample sizes we expect the
> -2ln(L) < term to be a very large number?
> < Which would reduce the effect of the parameter correction term 2K?
> <
> <
> < Chris Howden B.Sc. (Hons) GStat.
> < Founding Partner
> < Evidence Based Strategic Development, IP Commercialisation and
> Innovation, < Data Analysis, Modelling and Training < (mobile) 0410
> 689
> 945 < (fax) +612 4782 9023 < chris at trickysolutions.com.au < <
> _______________________________________________
> < R-sig-mixed-models at r-project.org mailing list <
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> --
>                                 Emmanuel CURIS
>                                 emmanuel.curis at parisdescartes.fr
>
> Page WWW: http://emmanuel.curis.online.fr/index.html
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From chris at trickysolutions.com.au  Mon Mar  4 02:59:05 2013
From: chris at trickysolutions.com.au (Chris Howden)
Date: Mon, 4 Mar 2013 12:59:05 +1100
Subject: [R-sig-ME] Can AIC be approximated by -2ln(L) i.e. the deviance,
 at very large sample size?
In-Reply-To: af5c027989e5cfd81c4ee79f6c1479b6@mail.gmail.com
References: <d6ba819f99e6538a1df99da8d2250e0d@mail.gmail.com>
	<20130301081742.GB7102@laboinfo-063.pharmacie.univ-paris5.fr>
	<CCE952776B6679469977532BD863C39C3A8F552D@Lewis.autuni.aut.ac.nz>
	<c899be8250968a271a92b9040ef97665@mail.gmail.com>
	<5133ECC3.3030106@gmail.com>
	af5c027989e5cfd81c4ee79f6c1479b6@mail.gmail.com
Message-ID: <3e3e098e072587d71ff1bc5c2dd9e91e@mail.gmail.com>

I probably should have pointed out that we had other OR's that ranged from
approx. 0.5 or 1.5. So in that context 1.02 isn't very strong!!

Chris Howden B.Sc. (Hons) GStat.
Founding Partner
Evidence Based Strategic Development, IP Commercialisation and Innovation,
Data Analysis, Modelling and Training
(mobile) 0410 689 945
(fax) +612 4782 9023
chris at trickysolutions.com.au




Disclaimer: The information in this email and any attachments to it are
confidential and may contain legally privileged information.?If you are
not the named or intended recipient, please delete this communication and
contact us immediately.?Please note you are not authorised to copy, use or
disclose this communication or any attachments without our consent.
Although this email has been checked by anti-virus software, there is a
risk that email messages may be corrupted or infected by viruses or other
interferences. No responsibility is accepted for such interference. Unless
expressly stated, the views of the writer are not those of the company.
Tricky Solutions always does our best to provide accurate forecasts and
analyses based on the data supplied, however it is possible that some
important predictors were not included in the data sent to us. Information
provided by us should not be solely relied upon when making decisions and
clients should use their own judgement.


-----Original Message-----
From: Chris Howden [mailto:chris at trickysolutions.com.au]
Sent: Monday, 4 March 2013 12:19 PM
To: 'Ben Bolker'
Cc: 'Steve Taylor'; 'Emmanuel Curis'; 'r-sig-mixed-models'
Subject: RE: [R-sig-ME] Can AIC be approximated by -2ln(L) i.e. the
deviance, at very large sample size?

Thanks for the reply Ben,

In response to your specific points

>>  Well, what do you mean by "not really worth including in the model"?
1) In terms of "too small to be interesting" I mean an Odds Ratio of 1.02
(from a GLMM with binomial family and random intercept based on the
individuals, each individual having 100's of data points)


>>  It's fairly well known, I think, that "everything is significant"
>> for sufficiently large sample sizes.  Arguably (e.g. according to
>> Andrew
>> Gelman) we should be using hierarchical models to include more and more
structure in our models, so that we are always extracting as much
information as is >> in the data ...
I wish it was well known, but I'm not so sure. One of the reasons I'm
asking this is that we are trying to publish our results and the reviewers
keep saying things like "If U had used AIC U wouldn't have this problem,
so go back and reanalyse it using AIC". We have stated that we have a
"ubiquitous significance" problem partially due to sample size and have
suggested a way around it that involves interpreting the effect sizes at
different spatial scales in order to find those that are useful. But I'm
having a hard time convincing people, so I'm trying to put together a
mathematical reason, which leads into your next point.


>>  I'm not really clear on what your question is any more.  (And, these
>> are really general stats/modelling questions, not so much mixed
>> modeling questions ...)

Yes, I suppose it was more of a general stats/modelling questions, I was
trying to get my head around the math of ln(L) functions such as AIC and
deviance and how it behaves at large sample sizes. I posted it here since
I fit a GLMM in R and also because of all the lists I'm on this one seemed
to be the only one where such matters are discussed at any level of
expertise or interest. I hope it's OK that I did. I work from home in a
remote area, and unfortunately don't have the benefit of having
statistical colleagues I can discuss these things with. I wish I did!!! It
gets rather lonely being the only statistician in town, I tend to get a
lot of good natured "there he goes again" looks whenever I get a bit too
excited about something statistical and try to share  :(




Chris Howden B.Sc. (Hons) GStat.
Founding Partner
Evidence Based Strategic Development, IP Commercialisation and Innovation,
Data Analysis, Modelling and Training
(mobile) 0410 689 945
(fax) +612 4782 9023
chris at trickysolutions.com.au




Disclaimer: The information in this email and any attachments to it are
confidential and may contain legally privileged information.?If you are
not the named or intended recipient, please delete this communication and
contact us immediately.?Please note you are not authorised to copy, use or
disclose this communication or any attachments without our consent.
Although this email has been checked by anti-virus software, there is a
risk that email messages may be corrupted or infected by viruses or other
interferences. No responsibility is accepted for such interference. Unless
expressly stated, the views of the writer are not those of the company.
Tricky Solutions always does our best to provide accurate forecasts and
analyses based on the data supplied, however it is possible that some
important predictors were not included in the data sent to us. Information
provided by us should not be solely relied upon when making decisions and
clients should use their own judgement.


-----Original Message-----
From: Ben Bolker [mailto:bbolker at gmail.com]
Sent: Monday, 4 March 2013 11:37 AM
To: Chris Howden
Cc: Steve Taylor; Emmanuel Curis; r-sig-mixed-models
Subject: Re: [R-sig-ME] Can AIC be approximated by -2ln(L) i.e. the
deviance, at very large sample size?

On 13-03-03 07:04 PM, Chris Howden wrote:
> Thanks for the responses everyone,
>
> I agree that its changes of 'goodness of fit' Likelihood functions
> such as AIC and deviance that matter, not their absolute size.
>
> However I think the impact of sample size may be something we need to
> consider, particularly when analysing "Big Data" sets.
>
> I recently did some analysis on "Big Data", the number of rows was
> over
> 300 000. What I found was that the Full Model was always selected
> using AIC, Deviance and LRT. However when I had a look at the effects
> of the predictors I found some of them were negligible, to the point
> of not really being worth including in the model. Despite what the AIC
> and LRT say.

  Well, what do you mean by "not really worth including in the model"?
The AIC is telling you that they improve the expected predictive accuracy.
"Too small to be interesting" is certainly possible, but it's impossible
for us to know (without the context of the question and without knowing
what question you're trying to answer with the model) whether the effects
are or aren't.

>
> This seems to be the same sample size issue faced with simple
> Univariate tests such as ANOVA i.e. large sample sizes give so much
> power that statistically significant results may be of no/little
practical value.
>
> The reason I asked about the convergence of deviance and AIC at large
> sample sizes was thus.
>
> The LRT tests between the Full model and 1 less predictor all had
> exceptionally small p-values, which meant that the difference in Ln(L)
> was very large.

  (I would put this the other way around: deviance/log-likelihood
difference is more fundamental than p-value.)

> So large that it appears that the difference in deviance and AIC was
> essentially the same.

  Yes, it's true that for a fixed range of model sizes, model complexity
matters less and less for large samples.

> So although it?s the difference that matters, if they converge at
> large sample sizes then a large difference in deviance means there
> will also be a large difference in AIC and they will come to the same
conclusion??
>
> However as they don't converge at small sample sizes this effect is
> not as relevant.

  It's fairly well known, I think, that "everything is significant" for
sufficiently large sample sizes.  Arguably (e.g. according to Andrew
Gelman) we should be using hierarchical models to include more and more
structure in our models, so that we are always extracting as much
information as is in the data ...

  I'm not really clear on what your question is any more.  (And, these are
really general stats/modelling questions, not so much mixed modeling
questions ...)

  cheers
    Ben Bolker


>
> Chris Howden B.Sc. (Hons) GStat.
> Founding Partner
> Evidence Based Strategic Development, IP Commercialisation and
> Innovation, Data Analysis, Modelling and Training
> (mobile) 0410 689 945
> (fax) +612 4782 9023
> chris at trickysolutions.com.au
>
>
>
>
> Disclaimer: The information in this email and any attachments to it
> are confidential and may contain legally privileged information. If
> you are not the named or intended recipient, please delete this
> communication and contact us immediately. Please note you are not
> authorised to copy, use or disclose this communication or any
attachments without our consent.
> Although this email has been checked by anti-virus software, there is
> a risk that email messages may be corrupted or infected by viruses or
> other interferences. No responsibility is accepted for such
> interference. Unless expressly stated, the views of the writer are not
those of the company.
> Tricky Solutions always does our best to provide accurate forecasts
> and analyses based on the data supplied, however it is possible that
> some important predictors were not included in the data sent to us.
> Information provided by us should not be solely relied upon when
> making decisions and clients should use their own judgement.
>
>
> -----Original Message-----
> From: Steve Taylor [mailto:steve.taylor at aut.ac.nz]
> Sent: Monday, 4 March 2013 10:10 AM
> To: Emmanuel Curis; Chris Howden
> Cc: r-sig-mixed-models
> Subject: RE: [R-sig-ME] Can AIC be approximated by -2ln(L) i.e. the
> deviance, at very large sample size?
>
> I agree that it is changes in AIC that matter, not its absolute value.
>
> My understanding is that AIC is only useful for comparing two models
> fitted on the same data set, i.e. with the same sample size.  So the
> question of how AIC changes with sample size is of little use beyond
> curiosity.
>
> The change in AIC caused by adding a term to the model formula would
> be of interest.  But the change in AIC caused by adding cases to the
> sample size is pretty meaningless.
>
> The 2K part is important because it provides a penalty for the change
> in the number of parameters between a simpler model and a more complex
model.
>
> I would advise against making any approximations when calculating AIC,
> especially considering its main use is in taking the difference
> between two close large numbers.
>
> cheers,
>     Steve
>
>
> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org
> [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of
> Emmanuel Curis
> Sent: Friday, 1 March 2013 9:18p
> To: Chris Howden
> Cc: r-sig-mixed-models
> Subject: Re: [R-sig-ME] Can AIC be approximated by -2ln(L) i.e. the
> deviance, at very large sample size?
>
> Hi,
>
> I may be wrong, but I understood that AIC in itself is not as
> important as changes in AIC between models, and some authors says that
> changes in AIC in the order of more than 10 are enough to favor a model
on another.
>
> And changes in the 2*k term should be in this order of magnitude when
> comparing different models.
>
> So my guess would be that it remains important.
>
> On the other hand, if a set of parameters will remain in all models,
> it probably can be safely ignored in the 2*k term for all models.
>
> Hope this helps,
>
> On Fri, Mar 01, 2013 at 06:30:53PM +1100, Chris Howden wrote:
> < Hi everyone,
> <
> < Although not strictly an R issue there often seems to be discussions
> along < these lines on this list, so I hope no one minds me posting
this.
> If U do < please let me know. (and just for the record I am applying
> this in R) < < I'm trying to get my head around AIC and sample size.
> <
> < Now if AIC = -2ln(L) + 2K = Deviance + 2K < < Am I right in thinking
> that as the Likelihood is the product of < probabilities then (all
> else being equal) the larger the sample size the < smaller the
Likelihood?
> < Which means that if we have very large sample sizes we expect the
> -2ln(L) < term to be a very large number?
> < Which would reduce the effect of the parameter correction term 2K?
> <
> <
> < Chris Howden B.Sc. (Hons) GStat.
> < Founding Partner
> < Evidence Based Strategic Development, IP Commercialisation and
> Innovation, < Data Analysis, Modelling and Training < (mobile) 0410
> 689
> 945 < (fax) +612 4782 9023 < chris at trickysolutions.com.au < <
> _______________________________________________
> < R-sig-mixed-models at r-project.org mailing list <
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> --
>                                 Emmanuel CURIS
>                                 emmanuel.curis at parisdescartes.fr
>
> Page WWW: http://emmanuel.curis.online.fr/index.html
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From chris at trickysolutions.com.au  Mon Mar  4 03:07:27 2013
From: chris at trickysolutions.com.au (Chris Howden)
Date: Mon, 4 Mar 2013 13:07:27 +1100
Subject: [R-sig-ME] Can AIC be approximated by -2ln(L) i.e. the deviance,
 at very large sample size?
In-Reply-To: <WC20130304002956.8303AE@cebc.cnrs.fr>
References: <d6ba819f99e6538a1df99da8d2250e0d@mail.gmail.com>
	<20130301081742.GB7102@laboinfo-063.pharmacie.univ-paris5.fr>
	<CCE952776B6679469977532BD863C39C3A8F552D@Lewis.autuni.aut.ac.nz>
	<c899be8250968a271a92b9040ef97665@mail.gmail.com>
	<WC20130304002956.8303AE@cebc.cnrs.fr>
Message-ID: <84f45613d4449a54b0c2dd0ea80999e4@mail.gmail.com>

Thanks Luca,

A quick look at some of my results suggests that that the same ?large sample
size? effects carry through to BIC, with it still selecting the full model.


Chris Howden B.Sc. (Hons) GStat.
Founding Partner
Evidence Based Strategic Development, IP Commercialisation and Innovation,
Data Analysis, Modelling and Training
(mobile) 0410 689 945
(fax) +612 4782 9023
chris at trickysolutions.com.au




Disclaimer: The information in this email and any attachments to it are
confidential and may contain legally privileged information. If you are not
the named or intended recipient, please delete this communication and
contact us immediately. Please note you are not authorised to copy, use or
disclose this communication or any attachments without our consent. Although
this email has been checked by anti-virus software, there is a risk that
email messages may be corrupted or infected by viruses or other
interferences. No responsibility is accepted for such interference. Unless
expressly stated, the views of the writer are not those of the company.
Tricky Solutions always does our best to provide accurate forecasts and
analyses based on the data supplied, however it is possible that some
important predictors were not included in the data sent to us. Information
provided by us should not be solely relied upon when making decisions and
clients should use their own judgement.

From: lborger [mailto:lborger at cebc.cnrs.fr]
Sent: Monday, 4 March 2013 11:30 AM
To: Chris Howden; Steve Taylor; Emmanuel Curis; Ben Bolker
Cc: r-sig-mixed-models
Subject: Re: [R-sig-ME] Can AIC be approximated by -2ln(L) i.e. the
deviance, at very large sample size?

Hello,

>I recently did some analysis on "Big Data", the number of rows was over 300
>000. What I found was that the Full Model was always selected using AIC,
>Deviance and LRT. However when I had a look at the effects of the
>predictors I found some of them were negligible, to the point of not really
>being worth including in the model.


You might find this one interesting: Link, W. A., and R. J. Barker. 2006.
Model weights and the foundations of multimodel inference. Ecology
87:2626-2635.


Cheers,
Luca



------------------------------------------------------------------
Luca Borger (PhD, MSc, BMus)
Centre d'Etudes Biologiques de Chize
CNRS (U.P.R. 1934) & INRA (USC 1339)
79360 Villiers-en-Bois, France
*****
email: lborger at cebc.cnrs.fr
Skype: luca.borger | Tel: +33 (0)549 099613
http://cnrs.academia.edu/LucaBorger
http://www.researcherid.com/rid/C-6003-2008
http://www.cebc.cnrs.fr/Fidentite/borger/borger.htm
------------------------------------------------------------------
* new book chapter:
Borger & Fryxell (2012) Quantifying individual differences in dispersal
using the net squared displacement statistics.
Ch. 17 In: Dispersal Ecology and Evolution. Editors: Clobert J., Baguette
M., Benton T., Bullock J.
Oxford University Press, Oxford (UK).
-

-----Original Message-----
From: Chris Howden <chris at trickysolutions.com.au>
To: Steve Taylor <steve.taylor at aut.ac.nz>, Emmanuel Curis
<emmanuel.curis at parisdescartes.fr>, Ben Bolker <bbolker at gmail.com>
Cc: r-sig-mixed-models <r-sig-mixed-models at r-project.org>
Date: Mon, 4 Mar 2013 11:04:01 +1100
Subject: Re: [R-sig-ME] Can AIC be approximated by -2ln(L) i.e. the
deviance, at very large sample size?
Thanks for the responses everyone,

I agree that its changes of 'goodness of fit' Likelihood functions such as
AIC and deviance that matter, not their absolute size.

However I think the impact of sample size may be something we need to
consider, particularly when analysing "Big Data" sets.

I recently did some analysis on "Big Data", the number of rows was over
300 000. What I found was that the Full Model was always selected using
AIC, Deviance and LRT. However when I had a look at the effects of the
predictors I found some of them were negligible, to the point of not
really being worth including in the model. Despite what the AIC and LRT
say.

This seems to be the same sample size issue faced with simple Univariate
tests such as ANOVA i.e. large sample sizes give so much power that
statistically significant results may be of no/little practical value.


The reason I asked about the convergence of deviance and AIC at large
sample sizes was thus.

The LRT tests between the Full model and 1 less predictor all had
exceptionally small p-values, which meant that the difference in Ln(L) was
very large. So large that it appears that the difference in deviance and
AIC was essentially the same.

So although it?s the difference that matters, if they converge at large
sample sizes than a large difference in deviance means there will also be
a large difference in AIC and they will come to the same conclusion??

However as they don't converge at small sample sizes this effect is not as
relevant.

Chris Howden B.Sc. (Hons) GStat.
Founding Partner
Evidence Based Strategic Development, IP Commercialisation and Innovation,
Data Analysis, Modelling and Training
(mobile) 0410 689 945
(fax) +612 4782 9023
chris at trickysolutions.com.au




Disclaimer: The information in this email and any attachments to it are
confidential and may contain legally privileged information. If you are
not the named or intended recipient, please delete this communication and
contact us immediately. Please note you are not authorised to copy, use or
disclose this communication or any attachments without our consent.
Although this email has been checked by anti-virus software, there is a
risk that email messages may be corrupted or infected by viruses or other
interferences. No responsibility is accepted for such interference. Unless
expressly stated, the views of the writer are not those of the company.
Tricky Solutions always does our best to provide accurate forecasts and
analyses based on the data supplied, however it is possible that some
important predictors were not included in the data sent to us. Information
provided by us should not be solely relied upon when making decisions and
clients should use their own judgement.


-----Original Message-----
From: Steve Taylor [mailto:steve.taylor at aut.ac.nz]
Sent: Monday, 4 March 2013 10:10 AM
To: Emmanuel Curis; Chris Howden
Cc: r-sig-mixed-models
Subject: RE: [R-sig-ME] Can AIC be approximated by -2ln(L) i.e. the
deviance, at very large sample size?

I agree that it is changes in AIC that matter, not its absolute value.

My understanding is that AIC is only useful for comparing two models
fitted on the same data set, i.e. with the same sample size.  So the
question of how AIC changes with sample size is of little use beyond
curiosity.

The change in AIC caused by adding a term to the model formula would be of
interest.  But the change in AIC caused by adding cases to the sample size
is pretty meaningless.

The 2K part is important because it provides a penalty for the change in
the number of parameters between a simpler model and a more complex model.

I would advise against making any approximations when calculating AIC,
especially considering its main use is in taking the difference between
two close large numbers.

cheers,
    Steve


-----Original Message-----
From: r-sig-mixed-models-bounces at r-project.org
[mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Emmanuel
Curis
Sent: Friday, 1 March 2013 9:18p
To: Chris Howden
Cc: r-sig-mixed-models
Subject: Re: [R-sig-ME] Can AIC be approximated by -2ln(L) i.e. the
deviance, at very large sample size?

Hi,

I may be wrong, but I understood that AIC in itself is not as important as
changes in AIC between models, and some authors says that changes in AIC
in the order of more than 10 are enough to favor a model on another.

And changes in the 2*k term should be in this order of magnitude when
comparing different models.

So my guess would be that it remains important.

On the other hand, if a set of parameters will remain in all models, it
probably can be safely ignored in the 2*k term for all models.

Hope this helps,

On Fri, Mar 01, 2013 at 06:30:53PM +1100, Chris Howden wrote:
< Hi everyone,
<
< Although not strictly an R issue there often seems to be discussions
along < these lines on this list, so I hope no one minds me posting this.
If U do < please let me know. (and just for the record I am applying this
in R) < < I'm trying to get my head around AIC and sample size.
<
< Now if AIC = -2ln(L) + 2K = Deviance + 2K < < Am I right in thinking
that as the Likelihood is the product of < probabilities then (all else
being equal) the larger the sample size the < smaller the Likelihood?
< Which means that if we have very large sample sizes we expect the
-2ln(L) < term to be a very large number?
< Which would reduce the effect of the parameter correction term 2K?
<
<
< Chris Howden B.Sc. (Hons) GStat.
< Founding Partner
< Evidence Based Strategic Development, IP Commercialisation and
Innovation, < Data Analysis, Modelling and Training < (mobile) 0410 689
945 < (fax) +612 4782 9023 < chris at trickysolutions.com.au < <
_______________________________________________
< R-sig-mixed-models at r-project.org mailing list <
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

--
                                Emmanuel CURIS
                                emmanuel.curis at parisdescartes.fr

Page WWW: http://emmanuel.curis.online.fr/index.html

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From emmanuel.curis at parisdescartes.fr  Mon Mar  4 09:21:39 2013
From: emmanuel.curis at parisdescartes.fr (Emmanuel Curis)
Date: Mon, 4 Mar 2013 09:21:39 +0100
Subject: [R-sig-ME] Can AIC be approximated by -2ln(L) i.e. the deviance,
 at very large sample size?
In-Reply-To: <3e3e098e072587d71ff1bc5c2dd9e91e@mail.gmail.com>
References: <d6ba819f99e6538a1df99da8d2250e0d@mail.gmail.com>
	<20130301081742.GB7102@laboinfo-063.pharmacie.univ-paris5.fr>
	<CCE952776B6679469977532BD863C39C3A8F552D@Lewis.autuni.aut.ac.nz>
	<c899be8250968a271a92b9040ef97665@mail.gmail.com>
	<5133ECC3.3030106@gmail.com>
	<3e3e098e072587d71ff1bc5c2dd9e91e@mail.gmail.com>
Message-ID: <20130304082139.GC19875@laboinfo-063.pharmacie.univ-paris5.fr>

Hi,

It is probably a pointless remark, but if for instance your 1.02 OR is
for age expressed in years, then a 10-year older individual will have
an OR of 1.02^10 = 1.2 and a 20 years older one an OR of 1.49, which
is not so negligible compared to your 1.5 OR for, let's say, sex...

In other words, difficult to judge on only the values not knowing the
context and the variables...

But that certainly does not help for your matter. May be, by trying to
generalize the "equivalence tests", you may construct a kind of test
to select OR only if proven of higher importance than a given cutoff,
based on clinical/practical considerations (or, conversingly, to prove
that this OR is of not practical importance) --- but may be also
methodologically difficult if the cutoff is selected after analysis.

In other words, may be the question is not well translated as a
question on significance/difference tests?

Hope this hints may help...

On Mon, Mar 04, 2013 at 12:59:05PM +1100, Chris Howden wrote:
? I probably should have pointed out that we had other OR's that ranged from
? approx. 0.5 or 1.5. So in that context 1.02 isn't very strong!!

-- 
                                Emmanuel CURIS
                                emmanuel.curis at parisdescartes.fr

Page WWW: http://emmanuel.curis.online.fr/index.html


From s.palacio at ipe.csic.es  Mon Mar  4 11:09:28 2013
From: s.palacio at ipe.csic.es (PALACIO BLASCO, SARA)
Date: Mon, 04 Mar 2013 11:09:28 +0100
Subject: [R-sig-ME] Error en mer_finalize(ans) : Downdated X'X is not
 positive definite, 1. What is wrong with my model?
Message-ID: <20130304110928.Horde.7qeKdvMXqRJRNHLYoAdnKgA@webmail.csic.es>

Dear List Members,

I am trying to run the following model in glmer:

> M_bud_type1=glmer(Dead~Treatment* fBud_type + fBud_type:Species +  
> (1|fRep), family=binomial, data=species)

where:
- Dead is a binomial response variable
- fBud_type is a fixed factor with 3 levels
- Species is a fixed factor with 9 levels nested within fBud_type and
- fRep is a random factor with 27 levels nested within Species

I have 1386 observations.
The error message I receive reads:

Error en mer_finalize(ans) : Downdated X'X is not positive definite, 1.

Any suggestions as to what can be wrong?

Thanks for your help,

Cheers!

Sara


From bbolker at gmail.com  Mon Mar  4 14:24:19 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 4 Mar 2013 13:24:19 +0000 (UTC)
Subject: [R-sig-ME]
	=?utf-8?q?Error_en_mer=5Ffinalize=28ans=29_=3A_Downdat?=
	=?utf-8?q?ed_X=27X_is_not_positive_definite=2C_1=2E_What_is_wrong_?=
	=?utf-8?q?with_my_model=3F?=
References: <20130304110928.Horde.7qeKdvMXqRJRNHLYoAdnKgA@webmail.csic.es>
Message-ID: <loom.20130304T141627-598@post.gmane.org>

PALACIO BLASCO, SARA <s.palacio at ...> writes:

[snip]

> I am trying to run the following model in glmer:
> 
> > M_bud_type1=glmer(Dead~Treatment* fBud_type + fBud_type:Species +  
> > (1|fRep), family=binomial, data=species)
> 
> where:
> - Dead is a binomial response variable
> - fBud_type is a fixed factor with 3 levels
> - Species is a fixed factor with 9 levels nested within fBud_type and
> - fRep is a random factor with 27 levels nested within Species
> 
> I have 1386 observations.
> The error message I receive reads:
> 
> Error en mer_finalize(ans) : Downdated X'X is not positive definite, 1.
> 

  Did you already read the http://glmm.wikidot.com/faq#errors section?

  It sounds like all your predictors are categorical (although we don't
know about Treatment), so centering isn't really as important/as practical
an option (you can use sum-to-zero contrasts, but it probably won't
make a big difference).

  Ben Bolker


From s.palacio at ipe.csic.es  Mon Mar  4 14:58:12 2013
From: s.palacio at ipe.csic.es (PALACIO BLASCO, SARA)
Date: Mon, 04 Mar 2013 14:58:12 +0100
Subject: [R-sig-ME] Error en mer_finalize(ans) : Downdated X'X is not
 positive definite, 1. What is wrong with my model?
In-Reply-To: <loom.20130304T141627-598@post.gmane.org>
References: <20130304110928.Horde.7qeKdvMXqRJRNHLYoAdnKgA@webmail.csic.es>
	<loom.20130304T141627-598@post.gmane.org>
Message-ID: <20130304145812.Horde.4lsfEPMXqRJRNKh0UcLReDA@webmail.csic.es>

Dear Ben,

Thanks for your response. I had read a very similar response to FAQs  
explaining why the error relates to rank deficient models. I have  
tried to center Treatment (a continuous variable, sorry I didn't  
specify this!) but this does not remove the error.

I think the problem comes with the nested nature of "Species" within  
"Bud_type", since not all species are in all Bud_types, I have a rank  
deficient design and lme4 cannot cope with it. I  do not think there  
is a solution to this problem other than including "Species" as a  
random effect, but then I will not be able to know its effect...

Cheers,

Sara Palacio

Quoting Ben Bolker <bbolker at gmail.com>:

> PALACIO BLASCO, SARA <s.palacio at ...> writes:
>
> [snip]
>
>> I am trying to run the following model in glmer:
>>
>> > M_bud_type1=glmer(Dead~Treatment* fBud_type + fBud_type:Species +
>> > (1|fRep), family=binomial, data=species)
>>
>> where:
>> - Dead is a binomial response variable
>> - fBud_type is a fixed factor with 3 levels
>> - Species is a fixed factor with 9 levels nested within fBud_type and
>> - fRep is a random factor with 27 levels nested within Species
>>
>> I have 1386 observations.
>> The error message I receive reads:
>>
>> Error en mer_finalize(ans) : Downdated X'X is not positive definite, 1.
>>
>
>   Did you already read the http://glmm.wikidot.com/faq#errors section?
>
>   It sounds like all your predictors are categorical (although we don't
> know about Treatment), so centering isn't really as important/as practical
> an option (you can use sum-to-zero contrasts, but it probably won't
> make a big difference).
>
>   Ben Bolker
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbolker at gmail.com  Mon Mar  4 15:06:05 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 04 Mar 2013 09:06:05 -0500
Subject: [R-sig-ME] Error en mer_finalize(ans) : Downdated X'X is not
 positive definite, 1. What is wrong with my model?
In-Reply-To: <20130304145812.Horde.4lsfEPMXqRJRNKh0UcLReDA@webmail.csic.es>
References: <20130304110928.Horde.7qeKdvMXqRJRNHLYoAdnKgA@webmail.csic.es>
	<loom.20130304T141627-598@post.gmane.org>
	<20130304145812.Horde.4lsfEPMXqRJRNKh0UcLReDA@webmail.csic.es>
Message-ID: <5134AA4D.2010408@gmail.com>

On 13-03-04 08:58 AM, PALACIO BLASCO, SARA wrote:
> Dear Ben,
> 
> Thanks for your response. I had read a very similar response to FAQs
> explaining why the error relates to rank deficient models. I have tried
> to center Treatment (a continuous variable, sorry I didn't specify
> this!) but this does not remove the error.
> 
> I think the problem comes with the nested nature of "Species" within
> "Bud_type", since not all species are in all Bud_types, I have a rank
> deficient design and lme4 cannot cope with it. I  do not think there is
> a solution to this problem other than including "Species" as a random
> effect, but then I will not be able to know its effect...
> 
> Cheers,
> 
> Sara Palacio

  Did you try to fit

M_bud_type0 = glm(Dead~Treatment* fBud_type +
   fBud_type:Species, family=binomial, data=species)

as suggested in the FAQ to see where the rank-deficiencies are
(i.e. are there NA-valued coefficients?)

  It's not immediately obvious to me that the fBud_type:Species
interaction should be causing trouble, because lme4 internally
drops unused levels of factors. You could *try*

species$budspecies <- with(species,
   droplevels(interaction(fBud_type,Species)))

just to check that, but I don't think it will help.

  Using Species as a random effect does *not* mean you "will not be able
to know its effect" -- you just won't be able to test hypotheses about
differences between particular species/combinations of species.
You can still use ranef() to get a value (technically not an "estimate")
for the conditional mode of each species.


> 
> Quoting Ben Bolker <bbolker at gmail.com>:
> 
>> PALACIO BLASCO, SARA <s.palacio at ...> writes:
>>
>> [snip]
>>
>>> I am trying to run the following model in glmer:
>>>
>>> > M_bud_type1=glmer(Dead~Treatment* fBud_type + fBud_type:Species +
>>> > (1|fRep), family=binomial, data=species)
>>>
>>> where:
>>> - Dead is a binomial response variable
>>> - fBud_type is a fixed factor with 3 levels
>>> - Species is a fixed factor with 9 levels nested within fBud_type and
>>> - fRep is a random factor with 27 levels nested within Species
>>>
>>> I have 1386 observations.
>>> The error message I receive reads:
>>>
>>> Error en mer_finalize(ans) : Downdated X'X is not positive definite, 1.
>>>
>>
>>   Did you already read the http://glmm.wikidot.com/faq#errors section?
>>
>>   It sounds like all your predictors are categorical (although we don't
>> know about Treatment), so centering isn't really as important/as
>> practical
>> an option (you can use sum-to-zero contrasts, but it probably won't
>> make a big difference).
>>
>>   Ben Bolker
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
>


From bates at stat.wisc.edu  Mon Mar  4 21:19:39 2013
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 4 Mar 2013 14:19:39 -0600
Subject: [R-sig-ME] Question about gls R function
In-Reply-To: <54482.137.110.136.169.1362427688.squirrel@acs-webmail.ucsd.edu>
References: <54482.137.110.136.169.1362427688.squirrel@acs-webmail.ucsd.edu>
Message-ID: <CAO7JsnSEL+EvYS8qdTALxnYXm7fLwmWwZy=cQZJEuukxpUK1Gg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130304/b618fe84/attachment.pl>

From njbisaac at gmail.com  Mon Mar  4 21:33:40 2013
From: njbisaac at gmail.com (Nick Isaac)
Date: Mon, 4 Mar 2013 20:33:40 +0000
Subject: [R-sig-ME] False convergence
In-Reply-To: <loom.20130302T220905-476@post.gmane.org>
References: <CAMab-EySLkdhwa_MkiCYn-sqa=xeYVq0yN2WS08scTcdw_1GHg@mail.gmail.com>
	<loom.20130302T220905-476@post.gmane.org>
Message-ID: <CAMab-EyHR_LezigNyjnHEotJGbNDO=LWk+sq3Fiy5yHUqBnGpQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130304/4f525306/attachment.pl>

From s.palacio at ipe.csic.es  Tue Mar  5 08:29:45 2013
From: s.palacio at ipe.csic.es (PALACIO BLASCO, SARA)
Date: Tue, 05 Mar 2013 08:29:45 +0100
Subject: [R-sig-ME] Error en mer_finalize(ans) : Downdated X'X is not
 positive definite, 1. What is wrong with my model?
In-Reply-To: <5134AA4D.2010408@gmail.com>
References: <20130304110928.Horde.7qeKdvMXqRJRNHLYoAdnKgA@webmail.csic.es>
	<loom.20130304T141627-598@post.gmane.org>
	<20130304145812.Horde.4lsfEPMXqRJRNKh0UcLReDA@webmail.csic.es>
	<5134AA4D.2010408@gmail.com>
Message-ID: <20130305082945.Horde.8a5MM-MXqRJRNZ7pTgVj0XA@webmail.csic.es>

Dear Ben

This is what the summary(M_bud_type0) says. As expected, there are  
plenty of NAs in the interactions between (uncrossed) levels of the  
interaction between the nested factors (fBud_type:Species):


Call:
glm(formula = Dead ~ Treatment * fBud_type + fBud_type:Species,
     family = binomial, data = species)

Deviance Residuals:
     Min       1Q   Median       3Q      Max
-5.8281  -0.2220   0.0703   0.3323   2.3882

Coefficients: (18 not defined because of singularities)
                       Estimate Std. Error z value Pr(>|z|)
(Intercept)           -7.77657    0.85126  -9.135  < 2e-16 ***
Treatment             -0.31190    0.03200  -9.747  < 2e-16 ***
fBud_typena            0.19449    1.38718   0.140  0.88850
fBud_typesc            5.36751    0.91869   5.843 5.14e-09 ***
Treatment:fBud_typena -0.05374    0.05892  -0.912  0.36172
Treatment:fBud_typesc  0.06949    0.03837   1.811  0.07012 .
fBud_typehy:SpeciesEc  3.96261    0.52793   7.506 6.10e-14 ***
fBud_typena:SpeciesEc       NA         NA      NA       NA
fBud_typesc:SpeciesEc       NA         NA      NA       NA
fBud_typehy:SpeciesEn  3.01308    0.48926   6.158 7.35e-10 ***
fBud_typena:SpeciesEn       NA         NA      NA       NA
fBud_typesc:SpeciesEn       NA         NA      NA       NA
fBud_typehy:SpeciesLp       NA         NA      NA       NA
fBud_typena:SpeciesLp  1.21835    0.49753   2.449  0.01433 *
fBud_typesc:SpeciesLp       NA         NA      NA       NA
fBud_typehy:SpeciesRf       NA         NA      NA       NA
fBud_typena:SpeciesRf       NA         NA      NA       NA
fBud_typesc:SpeciesRf  0.14214    0.39921   0.356  0.72180
fBud_typehy:SpeciesRh       NA         NA      NA       NA
fBud_typena:SpeciesRh       NA         NA      NA       NA
fBud_typesc:SpeciesRh -1.18370    0.37535  -3.154  0.00161 **
fBud_typehy:SpeciesVm       NA         NA      NA       NA
fBud_typena:SpeciesVm       NA         NA      NA       NA
fBud_typesc:SpeciesVm -1.09756    0.37513  -2.926  0.00344 **
fBud_typehy:SpeciesVu       NA         NA      NA       NA
fBud_typena:SpeciesVu       NA         NA      NA       NA
fBud_typesc:SpeciesVu       NA         NA      NA       NA
fBud_typehy:SpeciesVv       NA         NA      NA       NA
fBud_typena:SpeciesVv       NA         NA      NA       NA
fBud_typesc:SpeciesVv       NA         NA      NA       NA
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

(Dispersion parameter for binomial family taken to be 1)

     Null deviance: 1797.06  on 1385  degrees of freedom
Residual deviance:  736.43  on 1374  degrees of freedom
AIC: 760.43

Number of Fisher Scoring iterations: 7


### If I try your second suggestion and run the model in glm, the  
number of NAs goes down, but there are still a few:

Call:
glm(formula = Dead ~ Treatment * fBud_type + budspecies, family = binomial,
     data = species)

Deviance Residuals:
     Min       1Q   Median       3Q      Max
-5.8281  -0.2220   0.0703   0.3323   2.3882

Coefficients: (2 not defined because of singularities)
                       Estimate Std. Error z value Pr(>|z|)
(Intercept)           -7.77657    0.85126  -9.135  < 2e-16 ***
Treatment             -0.31190    0.03200  -9.747  < 2e-16 ***
fBud_typena            0.19449    1.38718   0.140  0.88850
fBud_typesc            5.36751    0.91869   5.843 5.14e-09 ***
budspecieshy.Ec        3.96261    0.52793   7.506 6.10e-14 ***
budspecieshy.En        3.01308    0.48926   6.158 7.35e-10 ***
budspeciesna.Lp        1.21835    0.49753   2.449  0.01433 *
budspeciessc.Rf        0.14214    0.39921   0.356  0.72180
budspeciessc.Rh       -1.18370    0.37535  -3.154  0.00161 **
budspeciessc.Vm       -1.09756    0.37513  -2.926  0.00344 **
budspeciessc.Vu             NA         NA      NA       NA
budspecieshy.Vv             NA         NA      NA       NA
Treatment:fBud_typena -0.05374    0.05892  -0.912  0.36172
Treatment:fBud_typesc  0.06949    0.03837   1.811  0.07012 .
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

(Dispersion parameter for binomial family taken to be 1)

     Null deviance: 1797.06  on 1385  degrees of freedom
Residual deviance:  736.43  on 1374  degrees of freedom
AIC: 760.43

Number of Fisher Scoring iterations: 7

I also don't know how to include the new factor with droplevels in the  
glmer model... should this new factor replace the nested one?

Cheers,

Sara




Quoting Ben Bolker <bbolker at gmail.com>:


>
>   Did you try to fit
>
> M_bud_type0 = glm(Dead~Treatment* fBud_type +
>    fBud_type:Species, family=binomial, data=species)
>
> as suggested in the FAQ to see where the rank-deficiencies are
> (i.e. are there NA-valued coefficients?)
>
>   It's not immediately obvious to me that the fBud_type:Species
> interaction should be causing trouble, because lme4 internally
> drops unused levels of factors. You could *try*
>
> species$budspecies <- with(species,
>    droplevels(interaction(fBud_type,Species)))
>
> just to check that, but I don't think it will help.
>
>   Using Species as a random effect does *not* mean you "will not be able
> to know its effect" -- you just won't be able to test hypotheses about
> differences between particular species/combinations of species.
> You can still use ranef() to get a value (technically not an "estimate")
> for the conditional mode of each species.
>
>
>>
>> Quoting Ben Bolker <bbolker at gmail.com>:
>>
>>> PALACIO BLASCO, SARA <s.palacio at ...> writes:
>>>
>>> [snip]
>>>
>>>> I am trying to run the following model in glmer:
>>>>
>>>> > M_bud_type1=glmer(Dead~Treatment* fBud_type + fBud_type:Species +
>>>> > (1|fRep), family=binomial, data=species)
>>>>
>>>> where:
>>>> - Dead is a binomial response variable
>>>> - fBud_type is a fixed factor with 3 levels
>>>> - Species is a fixed factor with 9 levels nested within fBud_type and
>>>> - fRep is a random factor with 27 levels nested within Species
>>>>
>>>> I have 1386 observations.
>>>> The error message I receive reads:
>>>>
>>>> Error en mer_finalize(ans) : Downdated X'X is not positive definite, 1.
>>>>
>>>
>>>   Did you already read the http://glmm.wikidot.com/faq#errors section?
>>>
>>>   It sounds like all your predictors are categorical (although we don't
>>> know about Treatment), so centering isn't really as important/as
>>> practical
>>> an option (you can use sum-to-zero contrasts, but it probably won't
>>> make a big difference).
>>>
>>>   Ben Bolker
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>>


From emmanuel.curis at parisdescartes.fr  Tue Mar  5 08:47:43 2013
From: emmanuel.curis at parisdescartes.fr (Emmanuel Curis)
Date: Tue, 5 Mar 2013 08:47:43 +0100
Subject: [R-sig-ME] Error en mer_finalize(ans) : Downdated X'X is not
 positive definite, 1. What is wrong with my model?
In-Reply-To: <20130305082945.Horde.8a5MM-MXqRJRNZ7pTgVj0XA@webmail.csic.es>
References: <20130304110928.Horde.7qeKdvMXqRJRNHLYoAdnKgA@webmail.csic.es>
	<loom.20130304T141627-598@post.gmane.org>
	<20130304145812.Horde.4lsfEPMXqRJRNKh0UcLReDA@webmail.csic.es>
	<5134AA4D.2010408@gmail.com>
	<20130305082945.Horde.8a5MM-MXqRJRNZ7pTgVj0XA@webmail.csic.es>
Message-ID: <20130305074743.GA30217@laboinfo-063.pharmacie.univ-paris5.fr>

Just looking quickly, is seems strange that for the last two species
(Vu and Vv), _all_ coefficients are to NA? If you try without these
two species, does it work better?

After that, I'm not specialist enough to traceback why for these two
species there are only NAs --- may be only one observation only for
each of them? or associated to another fBud_type not used in the
analysis for some reason? --- if unused levels have been removed...

Hope this helps,

Best regards,

On Tue, Mar 05, 2013 at 08:29:45AM +0100, PALACIO BLASCO, SARA wrote:
? Dear Ben
? 
? This is what the summary(M_bud_type0) says. As expected, there are
? plenty of NAs in the interactions between (uncrossed) levels of the
? interaction between the nested factors (fBud_type:Species):
? 
? 
? Call:
? glm(formula = Dead ~ Treatment * fBud_type + fBud_type:Species,
?     family = binomial, data = species)
? 
? Deviance Residuals:
?     Min       1Q   Median       3Q      Max
? -5.8281  -0.2220   0.0703   0.3323   2.3882
? 
? Coefficients: (18 not defined because of singularities)
?                       Estimate Std. Error z value Pr(>|z|)
? (Intercept)           -7.77657    0.85126  -9.135  < 2e-16 ***
? Treatment             -0.31190    0.03200  -9.747  < 2e-16 ***
? fBud_typena            0.19449    1.38718   0.140  0.88850
? fBud_typesc            5.36751    0.91869   5.843 5.14e-09 ***
? Treatment:fBud_typena -0.05374    0.05892  -0.912  0.36172
? Treatment:fBud_typesc  0.06949    0.03837   1.811  0.07012 .
? fBud_typehy:SpeciesEc  3.96261    0.52793   7.506 6.10e-14 ***
? fBud_typena:SpeciesEc       NA         NA      NA       NA
? fBud_typesc:SpeciesEc       NA         NA      NA       NA
? fBud_typehy:SpeciesEn  3.01308    0.48926   6.158 7.35e-10 ***
? fBud_typena:SpeciesEn       NA         NA      NA       NA
? fBud_typesc:SpeciesEn       NA         NA      NA       NA
? fBud_typehy:SpeciesLp       NA         NA      NA       NA
? fBud_typena:SpeciesLp  1.21835    0.49753   2.449  0.01433 *
? fBud_typesc:SpeciesLp       NA         NA      NA       NA
? fBud_typehy:SpeciesRf       NA         NA      NA       NA
? fBud_typena:SpeciesRf       NA         NA      NA       NA
? fBud_typesc:SpeciesRf  0.14214    0.39921   0.356  0.72180
? fBud_typehy:SpeciesRh       NA         NA      NA       NA
? fBud_typena:SpeciesRh       NA         NA      NA       NA
? fBud_typesc:SpeciesRh -1.18370    0.37535  -3.154  0.00161 **
? fBud_typehy:SpeciesVm       NA         NA      NA       NA
? fBud_typena:SpeciesVm       NA         NA      NA       NA
? fBud_typesc:SpeciesVm -1.09756    0.37513  -2.926  0.00344 **
? fBud_typehy:SpeciesVu       NA         NA      NA       NA
? fBud_typena:SpeciesVu       NA         NA      NA       NA
? fBud_typesc:SpeciesVu       NA         NA      NA       NA
? fBud_typehy:SpeciesVv       NA         NA      NA       NA
? fBud_typena:SpeciesVv       NA         NA      NA       NA
? fBud_typesc:SpeciesVv       NA         NA      NA       NA
? ---
? Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
? 
? (Dispersion parameter for binomial family taken to be 1)
? 
?     Null deviance: 1797.06  on 1385  degrees of freedom
? Residual deviance:  736.43  on 1374  degrees of freedom
? AIC: 760.43
? 
? Number of Fisher Scoring iterations: 7
? 
? 
? ### If I try your second suggestion and run the model in glm, the
? number of NAs goes down, but there are still a few:
? 
? Call:
? glm(formula = Dead ~ Treatment * fBud_type + budspecies, family = binomial,
?     data = species)
? 
? Deviance Residuals:
?     Min       1Q   Median       3Q      Max
? -5.8281  -0.2220   0.0703   0.3323   2.3882
? 
? Coefficients: (2 not defined because of singularities)
?                       Estimate Std. Error z value Pr(>|z|)
? (Intercept)           -7.77657    0.85126  -9.135  < 2e-16 ***
? Treatment             -0.31190    0.03200  -9.747  < 2e-16 ***
? fBud_typena            0.19449    1.38718   0.140  0.88850
? fBud_typesc            5.36751    0.91869   5.843 5.14e-09 ***
? budspecieshy.Ec        3.96261    0.52793   7.506 6.10e-14 ***
? budspecieshy.En        3.01308    0.48926   6.158 7.35e-10 ***
? budspeciesna.Lp        1.21835    0.49753   2.449  0.01433 *
? budspeciessc.Rf        0.14214    0.39921   0.356  0.72180
? budspeciessc.Rh       -1.18370    0.37535  -3.154  0.00161 **
? budspeciessc.Vm       -1.09756    0.37513  -2.926  0.00344 **
? budspeciessc.Vu             NA         NA      NA       NA
? budspecieshy.Vv             NA         NA      NA       NA
? Treatment:fBud_typena -0.05374    0.05892  -0.912  0.36172
? Treatment:fBud_typesc  0.06949    0.03837   1.811  0.07012 .
? ---
? Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
? 
? (Dispersion parameter for binomial family taken to be 1)
? 
?     Null deviance: 1797.06  on 1385  degrees of freedom
? Residual deviance:  736.43  on 1374  degrees of freedom
? AIC: 760.43
? 
? Number of Fisher Scoring iterations: 7
? 
? I also don't know how to include the new factor with droplevels in
? the glmer model... should this new factor replace the nested one?
? 
? Cheers,
? 
? Sara
? 
? 
? 
? 
? Quoting Ben Bolker <bbolker at gmail.com>:
? 
? 
? >
? >  Did you try to fit
? >
? >M_bud_type0 = glm(Dead~Treatment* fBud_type +
? >   fBud_type:Species, family=binomial, data=species)
? >
? >as suggested in the FAQ to see where the rank-deficiencies are
? >(i.e. are there NA-valued coefficients?)
? >
? >  It's not immediately obvious to me that the fBud_type:Species
? >interaction should be causing trouble, because lme4 internally
? >drops unused levels of factors. You could *try*
? >
? >species$budspecies <- with(species,
? >   droplevels(interaction(fBud_type,Species)))
? >
? >just to check that, but I don't think it will help.
? >
? >  Using Species as a random effect does *not* mean you "will not be able
? >to know its effect" -- you just won't be able to test hypotheses about
? >differences between particular species/combinations of species.
? >You can still use ranef() to get a value (technically not an "estimate")
? >for the conditional mode of each species.
? >
? >
? >>
? >>Quoting Ben Bolker <bbolker at gmail.com>:
? >>
? >>>PALACIO BLASCO, SARA <s.palacio at ...> writes:
? >>>
? >>>[snip]
? >>>
? >>>>I am trying to run the following model in glmer:
? >>>>
? >>>>> M_bud_type1=glmer(Dead~Treatment* fBud_type + fBud_type:Species +
? >>>>> (1|fRep), family=binomial, data=species)
? >>>>
? >>>>where:
? >>>>- Dead is a binomial response variable
? >>>>- fBud_type is a fixed factor with 3 levels
? >>>>- Species is a fixed factor with 9 levels nested within fBud_type and
? >>>>- fRep is a random factor with 27 levels nested within Species
? >>>>
? >>>>I have 1386 observations.
? >>>>The error message I receive reads:
? >>>>
? >>>>Error en mer_finalize(ans) : Downdated X'X is not positive definite, 1.
? >>>>
? >>>
? >>>  Did you already read the http://glmm.wikidot.com/faq#errors section?
? >>>
? >>>  It sounds like all your predictors are categorical (although we don't
? >>>know about Treatment), so centering isn't really as important/as
? >>>practical
? >>>an option (you can use sum-to-zero contrasts, but it probably won't
? >>>make a big difference).
? >>>
? >>>  Ben Bolker
? >>>
? >>>_______________________________________________
? >>>R-sig-mixed-models at r-project.org mailing list
? >>>https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
? >>
? >>
? >>
? 
? _______________________________________________
? R-sig-mixed-models at r-project.org mailing list
? https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
                                Emmanuel CURIS
                                emmanuel.curis at parisdescartes.fr

Page WWW: http://emmanuel.curis.online.fr/index.html


From s.palacio at ipe.csic.es  Tue Mar  5 09:47:50 2013
From: s.palacio at ipe.csic.es (PALACIO BLASCO, SARA)
Date: Tue, 05 Mar 2013 09:47:50 +0100
Subject: [R-sig-ME] Error en mer_finalize(ans) : Downdated X'X is not
 positive definite, 1. What is wrong with my model?
In-Reply-To: <20130305074743.GA30217@laboinfo-063.pharmacie.univ-paris5.fr>
References: <20130304110928.Horde.7qeKdvMXqRJRNHLYoAdnKgA@webmail.csic.es>
	<loom.20130304T141627-598@post.gmane.org>
	<20130304145812.Horde.4lsfEPMXqRJRNKh0UcLReDA@webmail.csic.es>
	<5134AA4D.2010408@gmail.com>
	<20130305082945.Horde.8a5MM-MXqRJRNZ7pTgVj0XA@webmail.csic.es>
	<20130305074743.GA30217@laboinfo-063.pharmacie.univ-paris5.fr>
Message-ID: <20130305094750.Horde.35eCEvMXqRJRNbE2QRelFbA@webmail.csic.es>

You are right! This is weird since when I check the data table  
"species" I can see values of the variable Bud_type for both  
species... Vu has "sc" and Vv has "hy"...

Then, if I follow your suggestion and try to run the model in glmer  
without these two species it still gives the same error:

Error en mer_finalize(ans) : Downdated X'X is not positive definite, 1.

If I then run the model in glm to see where the NAs are, I get this  
output, where, surprisingly, the species "En" that in the previous run  
had But_type=hy, now has NAs for all the levels of Bud_type!:

Call:
glm(formula = Dead ~ Treatment * fBud_type + fBud_type:Species,
     family = binomial, data = species)

Deviance Residuals:
     Min       1Q   Median       3Q      Max
-5.4628  -0.1953   0.0599   0.3561   2.6043

Coefficients: (14 not defined because of singularities)
                       Estimate Std. Error z value Pr(>|z|)
(Intercept)           -5.89770    0.81116  -7.271 3.58e-13 ***
Treatment             -0.38498    0.04952  -7.774 7.63e-15 ***
fBud_typena           -1.68437    1.36330  -1.236  0.21664
fBud_typesc            2.61123    0.94512   2.763  0.00573 **
Treatment:fBud_typena  0.01934    0.07001   0.276  0.78234
Treatment:fBud_typesc  0.15635    0.05528   2.828  0.00468 **
fBud_typehy:SpeciesEc  1.08250    0.38154   2.837  0.00455 **
fBud_typena:SpeciesEc       NA         NA      NA       NA
fBud_typesc:SpeciesEc       NA         NA      NA       NA
fBud_typehy:SpeciesEn       NA         NA      NA       NA
fBud_typena:SpeciesEn       NA         NA      NA       NA
fBud_typesc:SpeciesEn       NA         NA      NA       NA
fBud_typehy:SpeciesLp       NA         NA      NA       NA
fBud_typena:SpeciesLp  1.21835    0.49763   2.448  0.01435 *
fBud_typesc:SpeciesLp       NA         NA      NA       NA
fBud_typehy:SpeciesRf       NA         NA      NA       NA
fBud_typena:SpeciesRf       NA         NA      NA       NA
fBud_typesc:SpeciesRf  1.18017    0.44178   2.671  0.00755 **
fBud_typehy:SpeciesRh       NA         NA      NA       NA
fBud_typena:SpeciesRh       NA         NA      NA       NA
fBud_typesc:SpeciesRh -0.08258    0.40105  -0.206  0.83686
fBud_typehy:SpeciesVm       NA         NA      NA       NA
fBud_typena:SpeciesVm       NA         NA      NA       NA
fBud_typesc:SpeciesVm       NA         NA      NA       NA
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

(Dispersion parameter for binomial family taken to be 1)

     Null deviance: 1313.62  on 1015  degrees of freedom
Residual deviance:  522.38  on 1006  degrees of freedom
AIC: 542.38

Number of Fisher Scoring iterations: 8

I really don't know what is going on, but thanks heaps for your help!!

Sara Palacio

Quoting Emmanuel Curis <emmanuel.curis at parisdescartes.fr>:

> Just looking quickly, is seems strange that for the last two species
> (Vu and Vv), _all_ coefficients are to NA? If you try without these
> two species, does it work better?
>
> After that, I'm not specialist enough to traceback why for these two
> species there are only NAs --- may be only one observation only for
> each of them? or associated to another fBud_type not used in the
> analysis for some reason? --- if unused levels have been removed...
>
> Hope this helps,
>
> Best regards,
>
> On Tue, Mar 05, 2013 at 08:29:45AM +0100, PALACIO BLASCO, SARA wrote:
> ? Dear Ben
> ?
> ? This is what the summary(M_bud_type0) says. As expected, there are
> ? plenty of NAs in the interactions between (uncrossed) levels of the
> ? interaction between the nested factors (fBud_type:Species):
> ?
> ?
> ? Call:
> ? glm(formula = Dead ~ Treatment * fBud_type + fBud_type:Species,
> ?     family = binomial, data = species)
> ?
> ? Deviance Residuals:
> ?     Min       1Q   Median       3Q      Max
> ? -5.8281  -0.2220   0.0703   0.3323   2.3882
> ?
> ? Coefficients: (18 not defined because of singularities)
> ?                       Estimate Std. Error z value Pr(>|z|)
> ? (Intercept)           -7.77657    0.85126  -9.135  < 2e-16 ***
> ? Treatment             -0.31190    0.03200  -9.747  < 2e-16 ***
> ? fBud_typena            0.19449    1.38718   0.140  0.88850
> ? fBud_typesc            5.36751    0.91869   5.843 5.14e-09 ***
> ? Treatment:fBud_typena -0.05374    0.05892  -0.912  0.36172
> ? Treatment:fBud_typesc  0.06949    0.03837   1.811  0.07012 .
> ? fBud_typehy:SpeciesEc  3.96261    0.52793   7.506 6.10e-14 ***
> ? fBud_typena:SpeciesEc       NA         NA      NA       NA
> ? fBud_typesc:SpeciesEc       NA         NA      NA       NA
> ? fBud_typehy:SpeciesEn  3.01308    0.48926   6.158 7.35e-10 ***
> ? fBud_typena:SpeciesEn       NA         NA      NA       NA
> ? fBud_typesc:SpeciesEn       NA         NA      NA       NA
> ? fBud_typehy:SpeciesLp       NA         NA      NA       NA
> ? fBud_typena:SpeciesLp  1.21835    0.49753   2.449  0.01433 *
> ? fBud_typesc:SpeciesLp       NA         NA      NA       NA
> ? fBud_typehy:SpeciesRf       NA         NA      NA       NA
> ? fBud_typena:SpeciesRf       NA         NA      NA       NA
> ? fBud_typesc:SpeciesRf  0.14214    0.39921   0.356  0.72180
> ? fBud_typehy:SpeciesRh       NA         NA      NA       NA
> ? fBud_typena:SpeciesRh       NA         NA      NA       NA
> ? fBud_typesc:SpeciesRh -1.18370    0.37535  -3.154  0.00161 **
> ? fBud_typehy:SpeciesVm       NA         NA      NA       NA
> ? fBud_typena:SpeciesVm       NA         NA      NA       NA
> ? fBud_typesc:SpeciesVm -1.09756    0.37513  -2.926  0.00344 **
> ? fBud_typehy:SpeciesVu       NA         NA      NA       NA
> ? fBud_typena:SpeciesVu       NA         NA      NA       NA
> ? fBud_typesc:SpeciesVu       NA         NA      NA       NA
> ? fBud_typehy:SpeciesVv       NA         NA      NA       NA
> ? fBud_typena:SpeciesVv       NA         NA      NA       NA
> ? fBud_typesc:SpeciesVv       NA         NA      NA       NA
> ? ---
> ? Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> ?
> ? (Dispersion parameter for binomial family taken to be 1)
> ?
> ?     Null deviance: 1797.06  on 1385  degrees of freedom
> ? Residual deviance:  736.43  on 1374  degrees of freedom
> ? AIC: 760.43
> ?
> ? Number of Fisher Scoring iterations: 7
> ?
> ?
> ? ### If I try your second suggestion and run the model in glm, the
> ? number of NAs goes down, but there are still a few:
> ?
> ? Call:
> ? glm(formula = Dead ~ Treatment * fBud_type + budspecies, family = binomial,
> ?     data = species)
> ?
> ? Deviance Residuals:
> ?     Min       1Q   Median       3Q      Max
> ? -5.8281  -0.2220   0.0703   0.3323   2.3882
> ?
> ? Coefficients: (2 not defined because of singularities)
> ?                       Estimate Std. Error z value Pr(>|z|)
> ? (Intercept)           -7.77657    0.85126  -9.135  < 2e-16 ***
> ? Treatment             -0.31190    0.03200  -9.747  < 2e-16 ***
> ? fBud_typena            0.19449    1.38718   0.140  0.88850
> ? fBud_typesc            5.36751    0.91869   5.843 5.14e-09 ***
> ? budspecieshy.Ec        3.96261    0.52793   7.506 6.10e-14 ***
> ? budspecieshy.En        3.01308    0.48926   6.158 7.35e-10 ***
> ? budspeciesna.Lp        1.21835    0.49753   2.449  0.01433 *
> ? budspeciessc.Rf        0.14214    0.39921   0.356  0.72180
> ? budspeciessc.Rh       -1.18370    0.37535  -3.154  0.00161 **
> ? budspeciessc.Vm       -1.09756    0.37513  -2.926  0.00344 **
> ? budspeciessc.Vu             NA         NA      NA       NA
> ? budspecieshy.Vv             NA         NA      NA       NA
> ? Treatment:fBud_typena -0.05374    0.05892  -0.912  0.36172
> ? Treatment:fBud_typesc  0.06949    0.03837   1.811  0.07012 .
> ? ---
> ? Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> ?
> ? (Dispersion parameter for binomial family taken to be 1)
> ?
> ?     Null deviance: 1797.06  on 1385  degrees of freedom
> ? Residual deviance:  736.43  on 1374  degrees of freedom
> ? AIC: 760.43
> ?
> ? Number of Fisher Scoring iterations: 7
> ?
> ? I also don't know how to include the new factor with droplevels in
> ? the glmer model... should this new factor replace the nested one?
> ?
> ? Cheers,
> ?
> ? Sara
> ?
> ?
> ?
> ?
> ? Quoting Ben Bolker <bbolker at gmail.com>:
> ?
> ?
> ? >
> ? >  Did you try to fit
> ? >
> ? >M_bud_type0 = glm(Dead~Treatment* fBud_type +
> ? >   fBud_type:Species, family=binomial, data=species)
> ? >
> ? >as suggested in the FAQ to see where the rank-deficiencies are
> ? >(i.e. are there NA-valued coefficients?)
> ? >
> ? >  It's not immediately obvious to me that the fBud_type:Species
> ? >interaction should be causing trouble, because lme4 internally
> ? >drops unused levels of factors. You could *try*
> ? >
> ? >species$budspecies <- with(species,
> ? >   droplevels(interaction(fBud_type,Species)))
> ? >
> ? >just to check that, but I don't think it will help.
> ? >
> ? >  Using Species as a random effect does *not* mean you "will not be able
> ? >to know its effect" -- you just won't be able to test hypotheses about
> ? >differences between particular species/combinations of species.
> ? >You can still use ranef() to get a value (technically not an "estimate")
> ? >for the conditional mode of each species.
> ? >
> ? >
> ? >>
> ? >>Quoting Ben Bolker <bbolker at gmail.com>:
> ? >>
> ? >>>PALACIO BLASCO, SARA <s.palacio at ...> writes:
> ? >>>
> ? >>>[snip]
> ? >>>
> ? >>>>I am trying to run the following model in glmer:
> ? >>>>
> ? >>>>> M_bud_type1=glmer(Dead~Treatment* fBud_type + fBud_type:Species +
> ? >>>>> (1|fRep), family=binomial, data=species)
> ? >>>>
> ? >>>>where:
> ? >>>>- Dead is a binomial response variable
> ? >>>>- fBud_type is a fixed factor with 3 levels
> ? >>>>- Species is a fixed factor with 9 levels nested within fBud_type and
> ? >>>>- fRep is a random factor with 27 levels nested within Species
> ? >>>>
> ? >>>>I have 1386 observations.
> ? >>>>The error message I receive reads:
> ? >>>>
> ? >>>>Error en mer_finalize(ans) : Downdated X'X is not positive definite, 1.
> ? >>>>
> ? >>>
> ? >>>  Did you already read the http://glmm.wikidot.com/faq#errors section?
> ? >>>
> ? >>>  It sounds like all your predictors are categorical (although we don't
> ? >>>know about Treatment), so centering isn't really as important/as
> ? >>>practical
> ? >>>an option (you can use sum-to-zero contrasts, but it probably won't
> ? >>>make a big difference).
> ? >>>
> ? >>>  Ben Bolker
> ? >>>
> ? >>>_______________________________________________
> ? >>>R-sig-mixed-models at r-project.org mailing list
> ? >>>https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> ? >>
> ? >>
> ? >>
> ?
> ? _______________________________________________
> ? R-sig-mixed-models at r-project.org mailing list
> ? https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> --
>                                 Emmanuel CURIS
>                                 emmanuel.curis at parisdescartes.fr
>
> Page WWW: http://emmanuel.curis.online.fr/index.html


From emmanuel.curis at parisdescartes.fr  Tue Mar  5 10:57:19 2013
From: emmanuel.curis at parisdescartes.fr (Emmanuel Curis)
Date: Tue, 5 Mar 2013 10:57:19 +0100
Subject: [R-sig-ME] Error en mer_finalize(ans) : Downdated X'X is not
 positive definite, 1. What is wrong with my model?
In-Reply-To: <20130305094750.Horde.35eCEvMXqRJRNbE2QRelFbA@webmail.csic.es>
References: <20130304110928.Horde.7qeKdvMXqRJRNHLYoAdnKgA@webmail.csic.es>
	<loom.20130304T141627-598@post.gmane.org>
	<20130304145812.Horde.4lsfEPMXqRJRNKh0UcLReDA@webmail.csic.es>
	<5134AA4D.2010408@gmail.com>
	<20130305082945.Horde.8a5MM-MXqRJRNZ7pTgVj0XA@webmail.csic.es>
	<20130305074743.GA30217@laboinfo-063.pharmacie.univ-paris5.fr>
	<20130305094750.Horde.35eCEvMXqRJRNbE2QRelFbA@webmail.csic.es>
Message-ID: <20130305095719.GG30217@laboinfo-063.pharmacie.univ-paris5.fr>

Then my hint is that you are missing some combinations with for
instance some species not having some values for the treatment or
something like that. If this is the cause, the model without treatment
or without the treatment:fBud_type interaction may not have the
message. And to adjust the treatment*fBud_type part of the model, some
coefficients are ? stolen ? from the fBud_type:Species term, hence the
NA appearing on last species (and when removing these species,
appearing on other species).

To check this, you can also build contingency tables
with treatment and fBud_type, and see if some combinations have only a
few values, less than the species in the corresponding fBud_type for
instance... Or 3-D contingency tables, but more difficult to read...

Best regards,

On Tue, Mar 05, 2013 at 09:47:50AM +0100, PALACIO BLASCO, SARA wrote:
? You are right! This is weird since when I check the data table
? "species" I can see values of the variable Bud_type for both
? species... Vu has "sc" and Vv has "hy"...
? 
? Then, if I follow your suggestion and try to run the model in glmer
? without these two species it still gives the same error:
? 
? Error en mer_finalize(ans) : Downdated X'X is not positive definite, 1.
? 
? If I then run the model in glm to see where the NAs are, I get this
? output, where, surprisingly, the species "En" that in the previous
? run had But_type=hy, now has NAs for all the levels of Bud_type!:
? 
? Call:
? glm(formula = Dead ~ Treatment * fBud_type + fBud_type:Species,
?     family = binomial, data = species)
? 
? Deviance Residuals:
?     Min       1Q   Median       3Q      Max
? -5.4628  -0.1953   0.0599   0.3561   2.6043
? 
? Coefficients: (14 not defined because of singularities)
?                       Estimate Std. Error z value Pr(>|z|)
? (Intercept)           -5.89770    0.81116  -7.271 3.58e-13 ***
? Treatment             -0.38498    0.04952  -7.774 7.63e-15 ***
? fBud_typena           -1.68437    1.36330  -1.236  0.21664
? fBud_typesc            2.61123    0.94512   2.763  0.00573 **
? Treatment:fBud_typena  0.01934    0.07001   0.276  0.78234
? Treatment:fBud_typesc  0.15635    0.05528   2.828  0.00468 **
? fBud_typehy:SpeciesEc  1.08250    0.38154   2.837  0.00455 **
? fBud_typena:SpeciesEc       NA         NA      NA       NA
? fBud_typesc:SpeciesEc       NA         NA      NA       NA
? fBud_typehy:SpeciesEn       NA         NA      NA       NA
? fBud_typena:SpeciesEn       NA         NA      NA       NA
? fBud_typesc:SpeciesEn       NA         NA      NA       NA
? fBud_typehy:SpeciesLp       NA         NA      NA       NA
? fBud_typena:SpeciesLp  1.21835    0.49763   2.448  0.01435 *
? fBud_typesc:SpeciesLp       NA         NA      NA       NA
? fBud_typehy:SpeciesRf       NA         NA      NA       NA
? fBud_typena:SpeciesRf       NA         NA      NA       NA
? fBud_typesc:SpeciesRf  1.18017    0.44178   2.671  0.00755 **
? fBud_typehy:SpeciesRh       NA         NA      NA       NA
? fBud_typena:SpeciesRh       NA         NA      NA       NA
? fBud_typesc:SpeciesRh -0.08258    0.40105  -0.206  0.83686
? fBud_typehy:SpeciesVm       NA         NA      NA       NA
? fBud_typena:SpeciesVm       NA         NA      NA       NA
? fBud_typesc:SpeciesVm       NA         NA      NA       NA
? ---
? Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
? 
? (Dispersion parameter for binomial family taken to be 1)
? 
?     Null deviance: 1313.62  on 1015  degrees of freedom
? Residual deviance:  522.38  on 1006  degrees of freedom
? AIC: 542.38
? 
? Number of Fisher Scoring iterations: 8
? 
? I really don't know what is going on, but thanks heaps for your help!!
? 
? Sara Palacio
? 
? Quoting Emmanuel Curis <emmanuel.curis at parisdescartes.fr>:
? 
? >Just looking quickly, is seems strange that for the last two species
? >(Vu and Vv), _all_ coefficients are to NA? If you try without these
? >two species, does it work better?
? >
? >After that, I'm not specialist enough to traceback why for these two
? >species there are only NAs --- may be only one observation only for
? >each of them? or associated to another fBud_type not used in the
? >analysis for some reason? --- if unused levels have been removed...
? >
? >Hope this helps,
? >
? >Best regards,
? >
? >On Tue, Mar 05, 2013 at 08:29:45AM +0100, PALACIO BLASCO, SARA wrote:
? >? Dear Ben
? >?
? >? This is what the summary(M_bud_type0) says. As expected, there are
? >? plenty of NAs in the interactions between (uncrossed) levels of the
? >? interaction between the nested factors (fBud_type:Species):
? >?
? >?
? >? Call:
? >? glm(formula = Dead ~ Treatment * fBud_type + fBud_type:Species,
? >?     family = binomial, data = species)
? >?
? >? Deviance Residuals:
? >?     Min       1Q   Median       3Q      Max
? >? -5.8281  -0.2220   0.0703   0.3323   2.3882
? >?
? >? Coefficients: (18 not defined because of singularities)
? >?                       Estimate Std. Error z value Pr(>|z|)
? >? (Intercept)           -7.77657    0.85126  -9.135  < 2e-16 ***
? >? Treatment             -0.31190    0.03200  -9.747  < 2e-16 ***
? >? fBud_typena            0.19449    1.38718   0.140  0.88850
? >? fBud_typesc            5.36751    0.91869   5.843 5.14e-09 ***
? >? Treatment:fBud_typena -0.05374    0.05892  -0.912  0.36172
? >? Treatment:fBud_typesc  0.06949    0.03837   1.811  0.07012 .
? >? fBud_typehy:SpeciesEc  3.96261    0.52793   7.506 6.10e-14 ***
? >? fBud_typena:SpeciesEc       NA         NA      NA       NA
? >? fBud_typesc:SpeciesEc       NA         NA      NA       NA
? >? fBud_typehy:SpeciesEn  3.01308    0.48926   6.158 7.35e-10 ***
? >? fBud_typena:SpeciesEn       NA         NA      NA       NA
? >? fBud_typesc:SpeciesEn       NA         NA      NA       NA
? >? fBud_typehy:SpeciesLp       NA         NA      NA       NA
? >? fBud_typena:SpeciesLp  1.21835    0.49753   2.449  0.01433 *
? >? fBud_typesc:SpeciesLp       NA         NA      NA       NA
? >? fBud_typehy:SpeciesRf       NA         NA      NA       NA
? >? fBud_typena:SpeciesRf       NA         NA      NA       NA
? >? fBud_typesc:SpeciesRf  0.14214    0.39921   0.356  0.72180
? >? fBud_typehy:SpeciesRh       NA         NA      NA       NA
? >? fBud_typena:SpeciesRh       NA         NA      NA       NA
? >? fBud_typesc:SpeciesRh -1.18370    0.37535  -3.154  0.00161 **
? >? fBud_typehy:SpeciesVm       NA         NA      NA       NA
? >? fBud_typena:SpeciesVm       NA         NA      NA       NA
? >? fBud_typesc:SpeciesVm -1.09756    0.37513  -2.926  0.00344 **
? >? fBud_typehy:SpeciesVu       NA         NA      NA       NA
? >? fBud_typena:SpeciesVu       NA         NA      NA       NA
? >? fBud_typesc:SpeciesVu       NA         NA      NA       NA
? >? fBud_typehy:SpeciesVv       NA         NA      NA       NA
? >? fBud_typena:SpeciesVv       NA         NA      NA       NA
? >? fBud_typesc:SpeciesVv       NA         NA      NA       NA
? >? ---
? >? Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
? >?
? >? (Dispersion parameter for binomial family taken to be 1)
? >?
? >?     Null deviance: 1797.06  on 1385  degrees of freedom
? >? Residual deviance:  736.43  on 1374  degrees of freedom
? >? AIC: 760.43
? >?
? >? Number of Fisher Scoring iterations: 7
? >?
? >?
? >? ### If I try your second suggestion and run the model in glm, the
? >? number of NAs goes down, but there are still a few:
? >?
? >? Call:
? >? glm(formula = Dead ~ Treatment * fBud_type + budspecies, family = binomial,
? >?     data = species)
? >?
? >? Deviance Residuals:
? >?     Min       1Q   Median       3Q      Max
? >? -5.8281  -0.2220   0.0703   0.3323   2.3882
? >?
? >? Coefficients: (2 not defined because of singularities)
? >?                       Estimate Std. Error z value Pr(>|z|)
? >? (Intercept)           -7.77657    0.85126  -9.135  < 2e-16 ***
? >? Treatment             -0.31190    0.03200  -9.747  < 2e-16 ***
? >? fBud_typena            0.19449    1.38718   0.140  0.88850
? >? fBud_typesc            5.36751    0.91869   5.843 5.14e-09 ***
? >? budspecieshy.Ec        3.96261    0.52793   7.506 6.10e-14 ***
? >? budspecieshy.En        3.01308    0.48926   6.158 7.35e-10 ***
? >? budspeciesna.Lp        1.21835    0.49753   2.449  0.01433 *
? >? budspeciessc.Rf        0.14214    0.39921   0.356  0.72180
? >? budspeciessc.Rh       -1.18370    0.37535  -3.154  0.00161 **
? >? budspeciessc.Vm       -1.09756    0.37513  -2.926  0.00344 **
? >? budspeciessc.Vu             NA         NA      NA       NA
? >? budspecieshy.Vv             NA         NA      NA       NA
? >? Treatment:fBud_typena -0.05374    0.05892  -0.912  0.36172
? >? Treatment:fBud_typesc  0.06949    0.03837   1.811  0.07012 .
? >? ---
? >? Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
? >?
? >? (Dispersion parameter for binomial family taken to be 1)
? >?
? >?     Null deviance: 1797.06  on 1385  degrees of freedom
? >? Residual deviance:  736.43  on 1374  degrees of freedom
? >? AIC: 760.43
? >?
? >? Number of Fisher Scoring iterations: 7
? >?
? >? I also don't know how to include the new factor with droplevels in
? >? the glmer model... should this new factor replace the nested one?
? >?
? >? Cheers,
? >?
? >? Sara
? >?
? >?
? >?
? >?
? >? Quoting Ben Bolker <bbolker at gmail.com>:
? >?
? >?
? >? >
? >? >  Did you try to fit
? >? >
? >? >M_bud_type0 = glm(Dead~Treatment* fBud_type +
? >? >   fBud_type:Species, family=binomial, data=species)
? >? >
? >? >as suggested in the FAQ to see where the rank-deficiencies are
? >? >(i.e. are there NA-valued coefficients?)
? >? >
? >? >  It's not immediately obvious to me that the fBud_type:Species
? >? >interaction should be causing trouble, because lme4 internally
? >? >drops unused levels of factors. You could *try*
? >? >
? >? >species$budspecies <- with(species,
? >? >   droplevels(interaction(fBud_type,Species)))
? >? >
? >? >just to check that, but I don't think it will help.
? >? >
? >? >  Using Species as a random effect does *not* mean you "will not be able
? >? >to know its effect" -- you just won't be able to test hypotheses about
? >? >differences between particular species/combinations of species.
? >? >You can still use ranef() to get a value (technically not an "estimate")
? >? >for the conditional mode of each species.
? >? >
? >? >
? >? >>
? >? >>Quoting Ben Bolker <bbolker at gmail.com>:
? >? >>
? >? >>>PALACIO BLASCO, SARA <s.palacio at ...> writes:
? >? >>>
? >? >>>[snip]
? >? >>>
? >? >>>>I am trying to run the following model in glmer:
? >? >>>>
? >? >>>>> M_bud_type1=glmer(Dead~Treatment* fBud_type + fBud_type:Species +
? >? >>>>> (1|fRep), family=binomial, data=species)
? >? >>>>
? >? >>>>where:
? >? >>>>- Dead is a binomial response variable
? >? >>>>- fBud_type is a fixed factor with 3 levels
? >? >>>>- Species is a fixed factor with 9 levels nested within fBud_type and
? >? >>>>- fRep is a random factor with 27 levels nested within Species
? >? >>>>
? >? >>>>I have 1386 observations.
? >? >>>>The error message I receive reads:
? >? >>>>
? >? >>>>Error en mer_finalize(ans) : Downdated X'X is not positive definite, 1.
? >? >>>>
? >? >>>
? >? >>>  Did you already read the http://glmm.wikidot.com/faq#errors section?
? >? >>>
? >? >>>  It sounds like all your predictors are categorical (although we don't
? >? >>>know about Treatment), so centering isn't really as important/as
? >? >>>practical
? >? >>>an option (you can use sum-to-zero contrasts, but it probably won't
? >? >>>make a big difference).
? >? >>>
? >? >>>  Ben Bolker
? >? >>>
? >? >>>_______________________________________________
? >? >>>R-sig-mixed-models at r-project.org mailing list
? >? >>>https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
? >? >>
? >? >>
? >? >>
? >?
? >? _______________________________________________
? >? R-sig-mixed-models at r-project.org mailing list
? >? https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
? >
? >--
? >                                Emmanuel CURIS
? >                                emmanuel.curis at parisdescartes.fr
? >
? >Page WWW: http://emmanuel.curis.online.fr/index.html
? 
? 

-- 
                                Emmanuel CURIS
                                emmanuel.curis at parisdescartes.fr

Page WWW: http://emmanuel.curis.online.fr/index.html


From s.palacio at ipe.csic.es  Tue Mar  5 12:05:32 2013
From: s.palacio at ipe.csic.es (PALACIO BLASCO, SARA)
Date: Tue, 05 Mar 2013 12:05:32 +0100
Subject: [R-sig-ME] Error en mer_finalize(ans) : Downdated X'X is not
 positive definite, 1. What is wrong with my model?
In-Reply-To: <20130305095719.GG30217@laboinfo-063.pharmacie.univ-paris5.fr>
References: <20130304110928.Horde.7qeKdvMXqRJRNHLYoAdnKgA@webmail.csic.es>
	<loom.20130304T141627-598@post.gmane.org>
	<20130304145812.Horde.4lsfEPMXqRJRNKh0UcLReDA@webmail.csic.es>
	<5134AA4D.2010408@gmail.com>
	<20130305082945.Horde.8a5MM-MXqRJRNZ7pTgVj0XA@webmail.csic.es>
	<20130305074743.GA30217@laboinfo-063.pharmacie.univ-paris5.fr>
	<20130305094750.Horde.35eCEvMXqRJRNbE2QRelFbA@webmail.csic.es>
	<20130305095719.GG30217@laboinfo-063.pharmacie.univ-paris5.fr>
Message-ID: <20130305120532.Horde.9F7KVfMXqRJRNdF8fWjCNSA@webmail.csic.es>


Below you can see the contingency table for Treatment*Bud_type with  
the observations in each combination. As you can see the design is not  
balanced but there are no combinations with particularly few  
observations. I have checked this table per species and (taking into  
account that each species only has one Bud_type), all treatment levels  
have a representative number of observations...

	Treatment
Bud_type-80	-34.7	-30.2	-26.3	-22.1	-17.2	-13.1	-6.6	4	Total
hy	42	45	47	47	54	71	79	64	39	488
na	24	31	30	34	30	30	30	30	24	263
sc	62	71	72	68	71	82	69	78	62	635
Total  128	147	149	149	155	183	178	172	125	1386


The only issue I can see is that of each species only having one Bud_type...

Thanks for your help!

sara palacio


Quoting Emmanuel Curis <emmanuel.curis at parisdescartes.fr>:

> Then my hint is that you are missing some combinations with for
> instance some species not having some values for the treatment or
> something like that. If this is the cause, the model without treatment
> or without the treatment:fBud_type interaction may not have the
> message. And to adjust the treatment*fBud_type part of the model, some
> coefficients are ? stolen ? from the fBud_type:Species term, hence the
> NA appearing on last species (and when removing these species,
> appearing on other species).
>
> To check this, you can also build contingency tables
> with treatment and fBud_type, and see if some combinations have only a
> few values, less than the species in the corresponding fBud_type for
> instance... Or 3-D contingency tables, but more difficult to read...
>
> Best regards,
>
> On Tue, Mar 05, 2013 at 09:47:50AM +0100, PALACIO BLASCO, SARA wrote:
> ? You are right! This is weird since when I check the data table
> ? "species" I can see values of the variable Bud_type for both
> ? species... Vu has "sc" and Vv has "hy"...
> ?
> ? Then, if I follow your suggestion and try to run the model in glmer
> ? without these two species it still gives the same error:
> ?
> ? Error en mer_finalize(ans) : Downdated X'X is not positive definite, 1.
> ?
> ? If I then run the model in glm to see where the NAs are, I get this
> ? output, where, surprisingly, the species "En" that in the previous
> ? run had But_type=hy, now has NAs for all the levels of Bud_type!:
> ?
> ? Call:
> ? glm(formula = Dead ~ Treatment * fBud_type + fBud_type:Species,
> ?     family = binomial, data = species)
> ?
> ? Deviance Residuals:
> ?     Min       1Q   Median       3Q      Max
> ? -5.4628  -0.1953   0.0599   0.3561   2.6043
> ?
> ? Coefficients: (14 not defined because of singularities)
> ?                       Estimate Std. Error z value Pr(>|z|)
> ? (Intercept)           -5.89770    0.81116  -7.271 3.58e-13 ***
> ? Treatment             -0.38498    0.04952  -7.774 7.63e-15 ***
> ? fBud_typena           -1.68437    1.36330  -1.236  0.21664
> ? fBud_typesc            2.61123    0.94512   2.763  0.00573 **
> ? Treatment:fBud_typena  0.01934    0.07001   0.276  0.78234
> ? Treatment:fBud_typesc  0.15635    0.05528   2.828  0.00468 **
> ? fBud_typehy:SpeciesEc  1.08250    0.38154   2.837  0.00455 **
> ? fBud_typena:SpeciesEc       NA         NA      NA       NA
> ? fBud_typesc:SpeciesEc       NA         NA      NA       NA
> ? fBud_typehy:SpeciesEn       NA         NA      NA       NA
> ? fBud_typena:SpeciesEn       NA         NA      NA       NA
> ? fBud_typesc:SpeciesEn       NA         NA      NA       NA
> ? fBud_typehy:SpeciesLp       NA         NA      NA       NA
> ? fBud_typena:SpeciesLp  1.21835    0.49763   2.448  0.01435 *
> ? fBud_typesc:SpeciesLp       NA         NA      NA       NA
> ? fBud_typehy:SpeciesRf       NA         NA      NA       NA
> ? fBud_typena:SpeciesRf       NA         NA      NA       NA
> ? fBud_typesc:SpeciesRf  1.18017    0.44178   2.671  0.00755 **
> ? fBud_typehy:SpeciesRh       NA         NA      NA       NA
> ? fBud_typena:SpeciesRh       NA         NA      NA       NA
> ? fBud_typesc:SpeciesRh -0.08258    0.40105  -0.206  0.83686
> ? fBud_typehy:SpeciesVm       NA         NA      NA       NA
> ? fBud_typena:SpeciesVm       NA         NA      NA       NA
> ? fBud_typesc:SpeciesVm       NA         NA      NA       NA
> ? ---
> ? Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> ?
> ? (Dispersion parameter for binomial family taken to be 1)
> ?
> ?     Null deviance: 1313.62  on 1015  degrees of freedom
> ? Residual deviance:  522.38  on 1006  degrees of freedom
> ? AIC: 542.38
> ?
> ? Number of Fisher Scoring iterations: 8
> ?
> ? I really don't know what is going on, but thanks heaps for your help!!
> ?
> ? Sara Palacio
> ?
> ? Quoting Emmanuel Curis <emmanuel.curis at parisdescartes.fr>:
> ?
> ? >Just looking quickly, is seems strange that for the last two species
> ? >(Vu and Vv), _all_ coefficients are to NA? If you try without these
> ? >two species, does it work better?
> ? >
> ? >After that, I'm not specialist enough to traceback why for these two
> ? >species there are only NAs --- may be only one observation only for
> ? >each of them? or associated to another fBud_type not used in the
> ? >analysis for some reason? --- if unused levels have been removed...
> ? >
> ? >Hope this helps,
> ? >
> ? >Best regards,
> ? >
> ? >On Tue, Mar 05, 2013 at 08:29:45AM +0100, PALACIO BLASCO, SARA wrote:
> ? >? Dear Ben
> ? >?
> ? >? This is what the summary(M_bud_type0) says. As expected, there are
> ? >? plenty of NAs in the interactions between (uncrossed) levels of the
> ? >? interaction between the nested factors (fBud_type:Species):
> ? >?
> ? >?
> ? >? Call:
> ? >? glm(formula = Dead ~ Treatment * fBud_type + fBud_type:Species,
> ? >?     family = binomial, data = species)
> ? >?
> ? >? Deviance Residuals:
> ? >?     Min       1Q   Median       3Q      Max
> ? >? -5.8281  -0.2220   0.0703   0.3323   2.3882
> ? >?
> ? >? Coefficients: (18 not defined because of singularities)
> ? >?                       Estimate Std. Error z value Pr(>|z|)
> ? >? (Intercept)           -7.77657    0.85126  -9.135  < 2e-16 ***
> ? >? Treatment             -0.31190    0.03200  -9.747  < 2e-16 ***
> ? >? fBud_typena            0.19449    1.38718   0.140  0.88850
> ? >? fBud_typesc            5.36751    0.91869   5.843 5.14e-09 ***
> ? >? Treatment:fBud_typena -0.05374    0.05892  -0.912  0.36172
> ? >? Treatment:fBud_typesc  0.06949    0.03837   1.811  0.07012 .
> ? >? fBud_typehy:SpeciesEc  3.96261    0.52793   7.506 6.10e-14 ***
> ? >? fBud_typena:SpeciesEc       NA         NA      NA       NA
> ? >? fBud_typesc:SpeciesEc       NA         NA      NA       NA
> ? >? fBud_typehy:SpeciesEn  3.01308    0.48926   6.158 7.35e-10 ***
> ? >? fBud_typena:SpeciesEn       NA         NA      NA       NA
> ? >? fBud_typesc:SpeciesEn       NA         NA      NA       NA
> ? >? fBud_typehy:SpeciesLp       NA         NA      NA       NA
> ? >? fBud_typena:SpeciesLp  1.21835    0.49753   2.449  0.01433 *
> ? >? fBud_typesc:SpeciesLp       NA         NA      NA       NA
> ? >? fBud_typehy:SpeciesRf       NA         NA      NA       NA
> ? >? fBud_typena:SpeciesRf       NA         NA      NA       NA
> ? >? fBud_typesc:SpeciesRf  0.14214    0.39921   0.356  0.72180
> ? >? fBud_typehy:SpeciesRh       NA         NA      NA       NA
> ? >? fBud_typena:SpeciesRh       NA         NA      NA       NA
> ? >? fBud_typesc:SpeciesRh -1.18370    0.37535  -3.154  0.00161 **
> ? >? fBud_typehy:SpeciesVm       NA         NA      NA       NA
> ? >? fBud_typena:SpeciesVm       NA         NA      NA       NA
> ? >? fBud_typesc:SpeciesVm -1.09756    0.37513  -2.926  0.00344 **
> ? >? fBud_typehy:SpeciesVu       NA         NA      NA       NA
> ? >? fBud_typena:SpeciesVu       NA         NA      NA       NA
> ? >? fBud_typesc:SpeciesVu       NA         NA      NA       NA
> ? >? fBud_typehy:SpeciesVv       NA         NA      NA       NA
> ? >? fBud_typena:SpeciesVv       NA         NA      NA       NA
> ? >? fBud_typesc:SpeciesVv       NA         NA      NA       NA
> ? >? ---
> ? >? Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> ? >?
> ? >? (Dispersion parameter for binomial family taken to be 1)
> ? >?
> ? >?     Null deviance: 1797.06  on 1385  degrees of freedom
> ? >? Residual deviance:  736.43  on 1374  degrees of freedom
> ? >? AIC: 760.43
> ? >?
> ? >? Number of Fisher Scoring iterations: 7
> ? >?
> ? >?
> ? >? ### If I try your second suggestion and run the model in glm, the
> ? >? number of NAs goes down, but there are still a few:
> ? >?
> ? >? Call:
> ? >? glm(formula = Dead ~ Treatment * fBud_type + budspecies, family  
> = binomial,
> ? >?     data = species)
> ? >?
> ? >? Deviance Residuals:
> ? >?     Min       1Q   Median       3Q      Max
> ? >? -5.8281  -0.2220   0.0703   0.3323   2.3882
> ? >?
> ? >? Coefficients: (2 not defined because of singularities)
> ? >?                       Estimate Std. Error z value Pr(>|z|)
> ? >? (Intercept)           -7.77657    0.85126  -9.135  < 2e-16 ***
> ? >? Treatment             -0.31190    0.03200  -9.747  < 2e-16 ***
> ? >? fBud_typena            0.19449    1.38718   0.140  0.88850
> ? >? fBud_typesc            5.36751    0.91869   5.843 5.14e-09 ***
> ? >? budspecieshy.Ec        3.96261    0.52793   7.506 6.10e-14 ***
> ? >? budspecieshy.En        3.01308    0.48926   6.158 7.35e-10 ***
> ? >? budspeciesna.Lp        1.21835    0.49753   2.449  0.01433 *
> ? >? budspeciessc.Rf        0.14214    0.39921   0.356  0.72180
> ? >? budspeciessc.Rh       -1.18370    0.37535  -3.154  0.00161 **
> ? >? budspeciessc.Vm       -1.09756    0.37513  -2.926  0.00344 **
> ? >? budspeciessc.Vu             NA         NA      NA       NA
> ? >? budspecieshy.Vv             NA         NA      NA       NA
> ? >? Treatment:fBud_typena -0.05374    0.05892  -0.912  0.36172
> ? >? Treatment:fBud_typesc  0.06949    0.03837   1.811  0.07012 .
> ? >? ---
> ? >? Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> ? >?
> ? >? (Dispersion parameter for binomial family taken to be 1)
> ? >?
> ? >?     Null deviance: 1797.06  on 1385  degrees of freedom
> ? >? Residual deviance:  736.43  on 1374  degrees of freedom
> ? >? AIC: 760.43
> ? >?
> ? >? Number of Fisher Scoring iterations: 7
> ? >?
> ? >? I also don't know how to include the new factor with droplevels in
> ? >? the glmer model... should this new factor replace the nested one?
> ? >?
> ? >? Cheers,
> ? >?
> ? >? Sara
> ? >?
> ? >?
> ? >?
> ? >?
> ? >? Quoting Ben Bolker <bbolker at gmail.com>:
> ? >?
> ? >?
> ? >? >
> ? >? >  Did you try to fit
> ? >? >
> ? >? >M_bud_type0 = glm(Dead~Treatment* fBud_type +
> ? >? >   fBud_type:Species, family=binomial, data=species)
> ? >? >
> ? >? >as suggested in the FAQ to see where the rank-deficiencies are
> ? >? >(i.e. are there NA-valued coefficients?)
> ? >? >
> ? >? >  It's not immediately obvious to me that the fBud_type:Species
> ? >? >interaction should be causing trouble, because lme4 internally
> ? >? >drops unused levels of factors. You could *try*
> ? >? >
> ? >? >species$budspecies <- with(species,
> ? >? >   droplevels(interaction(fBud_type,Species)))
> ? >? >
> ? >? >just to check that, but I don't think it will help.
> ? >? >
> ? >? >  Using Species as a random effect does *not* mean you "will  
> not be able
> ? >? >to know its effect" -- you just won't be able to test hypotheses about
> ? >? >differences between particular species/combinations of species.
> ? >? >You can still use ranef() to get a value (technically not an  
> "estimate")
> ? >? >for the conditional mode of each species.
> ? >? >
> ? >? >
> ? >? >>
> ? >? >>Quoting Ben Bolker <bbolker at gmail.com>:
> ? >? >>
> ? >? >>>PALACIO BLASCO, SARA <s.palacio at ...> writes:
> ? >? >>>
> ? >? >>>[snip]
> ? >? >>>
> ? >? >>>>I am trying to run the following model in glmer:
> ? >? >>>>
> ? >? >>>>> M_bud_type1=glmer(Dead~Treatment* fBud_type + fBud_type:Species +
> ? >? >>>>> (1|fRep), family=binomial, data=species)
> ? >? >>>>
> ? >? >>>>where:
> ? >? >>>>- Dead is a binomial response variable
> ? >? >>>>- fBud_type is a fixed factor with 3 levels
> ? >? >>>>- Species is a fixed factor with 9 levels nested within  
> fBud_type and
> ? >? >>>>- fRep is a random factor with 27 levels nested within Species
> ? >? >>>>
> ? >? >>>>I have 1386 observations.
> ? >? >>>>The error message I receive reads:
> ? >? >>>>
> ? >? >>>>Error en mer_finalize(ans) : Downdated X'X is not positive  
> definite, 1.
> ? >? >>>>
> ? >? >>>
> ? >? >>>  Did you already read the  
> http://glmm.wikidot.com/faq#errors section?
> ? >? >>>
> ? >? >>>  It sounds like all your predictors are categorical  
> (although we don't
> ? >? >>>know about Treatment), so centering isn't really as important/as
> ? >? >>>practical
> ? >? >>>an option (you can use sum-to-zero contrasts, but it probably won't
> ? >? >>>make a big difference).
> ? >? >>>
> ? >? >>>  Ben Bolker
> ? >? >>>
> ? >? >>>_______________________________________________
> ? >? >>>R-sig-mixed-models at r-project.org mailing list
> ? >? >>>https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> ? >? >>
> ? >? >>
> ? >? >>
> ? >?
> ? >? _______________________________________________
> ? >? R-sig-mixed-models at r-project.org mailing list
> ? >? https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> ? >
> ? >--
> ? >                                Emmanuel CURIS
> ? >                                emmanuel.curis at parisdescartes.fr
> ? >
> ? >Page WWW: http://emmanuel.curis.online.fr/index.html
> ?
> ?
>
> --
>                                 Emmanuel CURIS
>                                 emmanuel.curis at parisdescartes.fr
>
> Page WWW: http://emmanuel.curis.online.fr/index.html


From filipescpcarvalho at yahoo.com  Tue Mar  5 16:56:01 2013
From: filipescpcarvalho at yahoo.com (Filipe Carvalho)
Date: Tue, 5 Mar 2013 07:56:01 -0800 (PST)
Subject: [R-sig-ME] Choosing nlme or lme4?
Message-ID: <1362498961.75551.YahooMailNeo@web161404.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130305/2c7bf346/attachment.pl>

From tmoranlopez at mncn.csic.es  Tue Mar  5 18:56:07 2013
From: tmoranlopez at mncn.csic.es (MORAN LOPEZ, TERESA)
Date: Tue, 05 Mar 2013 18:56:07 +0100
Subject: [R-sig-ME] Changes of estimate sign when interaction effects are
 highly significant
Message-ID: <20130305185607.Horde.3WcCDfMXqRJRNjG3SIvD-mA@webmail.csic.es>

Hi everyone,
I am trying to evaluate the effects of WUE and drought on trees  
growth. I am running a mixed model in which my dependent variable is  
growth and my fixed effects are WUE, drought and their interaction. My  
random variables treeID nested in year. When the interaction among the  
two variables is not included, the effects of WUE on growth is  
negative and the effects of drought negative which is very intuitive.  
However, the best model includes the interaction (which is highly  
significant), and then the sign of the main effects change, now both  
drought and WUE have a positive effect on growth! And the sign of the  
interaction is negative...
Does anyone know what could be happening? Does this mean that when we  
have a very significant interaction between two fixed effects they  
cannot be interpreted separately?
Thanks


From raptorbio at hotmail.com  Tue Mar  5 19:06:58 2013
From: raptorbio at hotmail.com (Adam Smith)
Date: Tue, 5 Mar 2013 13:06:58 -0500
Subject: [R-sig-ME] Changes of estimate sign when interaction effects
 are highly significant
In-Reply-To: <20130305185607.Horde.3WcCDfMXqRJRNjG3SIvD-mA@webmail.csic.es>
References: <20130305185607.Horde.3WcCDfMXqRJRNjG3SIvD-mA@webmail.csic.es>
Message-ID: <BAY158-W517E4385928F2F2D53F46A1FB0@phx.gbl>

Teresa,

Correct, main effects cannot be interpreted in the presence of an interaction, unless the main effect input variables are centered...

See, for example:

Engqvist, L. (2005) The mistreatment of covariate interaction terms in linear?model analyses of behavioural and evolutionary ecology studies. Animal?Behaviour, 70, 967?971.?

(free pdf here:?http://pub.uni-bielefeld.de/download/2395676/2496935)

Schielzeth H (2010) Simple means to improve the?interpretability of regression coefficients. Methods in Ecology?and Evolution, 1, 103?113.?

(http://onlinelibrary.wiley.com/doi/10.1111/j.2041-210X.2010.00012.x/full)


Cheers,

Adam?Smith


> Date: Tue, 5 Mar 2013 18:56:07 +0100
> From: tmoranlopez at mncn.csic.es
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] Changes of estimate sign when interaction effects are highly significant
> 
> Hi everyone,
> I am trying to evaluate the effects of WUE and drought on trees 
> growth. I am running a mixed model in which my dependent variable is 
> growth and my fixed effects are WUE, drought and their interaction. My 
> random variables treeID nested in year. When the interaction among the 
> two variables is not included, the effects of WUE on growth is 
> negative and the effects of drought negative which is very intuitive. 
> However, the best model includes the interaction (which is highly 
> significant), and then the sign of the main effects change, now both 
> drought and WUE have a positive effect on growth! And the sign of the 
> interaction is negative...
> Does anyone know what could be happening? Does this mean that when we 
> have a very significant interaction between two fixed effects they 
> cannot be interpreted separately?
> Thanks
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models 		 	   		  

From bbolker at gmail.com  Tue Mar  5 19:37:08 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 5 Mar 2013 18:37:08 +0000 (UTC)
Subject: [R-sig-ME] Changes of estimate sign when interaction effects
	are highly significant
References: <20130305185607.Horde.3WcCDfMXqRJRNjG3SIvD-mA@webmail.csic.es>
	<BAY158-W517E4385928F2F2D53F46A1FB0@phx.gbl>
Message-ID: <loom.20130305T193215-743@post.gmane.org>

Adam Smith <raptorbio at ...> writes:

> 
> Teresa,
> 
> Correct, main effects cannot be interpreted in the 
> presence of an interaction, unless the main effect
> input variables are centered...

  More precisely, with R's default treatment contrasts,
the main effects parameters in a model with interactions
refer to the expected change when the other continuous
predictors in the interaction are at zero and the other
categorical predictors are at their baseline level.

  The best thing to do is often to draw a graph so
you can see visually what's going on.  For two continuous
covariates it may be a good idea to use cut() [or
cut_interval() or cut_number() from the ggplot2 package]
to subdivide one of the covariates into range.
 
> See, for example: Engqvist, L. (2005) The mistreatment of covariate
> interaction terms in linear?model analyses of behavioural and
> evolutionary ecology studies. Animal?Behaviour, 70, 967?971.?
 
> (free pdf here:?http://pub.uni-bielefeld.de/download/2395676/2496935)
 
> Schielzeth H (2010) Simple means to improve the?interpretability of
> regression coefficients. Methods in Ecology?and Evolution, 1,
> 103?113.?

> (http://onlinelibrary.wiley.com/doi/10.1111/j.2041-210X.2010.00012.x/full)
> 
> Cheers,
> 
> Adam?Smith
> 
> > Date: Tue, 5 Mar 2013 18:56:07 +0100
> > From: tmoranlopez at ...
> > To: r-sig-mixed-models at ...
> > 
> > Hi everyone,
> > I am trying to evaluate the effects of WUE and drought on trees 
> > growth. I am running a mixed model in which my dependent variable is 
> > growth and my fixed effects are WUE, drought and their interaction. My 
> > random variables treeID nested in year. When the interaction among the 
> > two variables is not included, the effects of WUE on growth is 
> > negative and the effects of drought negative which is very intuitive. 
> > However, the best model includes the interaction (which is highly 
> > significant), and then the sign of the main effects change, now both 
> > drought and WUE have a positive effect on growth! And the sign of the 
> > interaction is negative...
> > Does anyone know what could be happening? Does this mean that when we 
> > have a very significant interaction between two fixed effects they 
> > cannot be interpreted separately?
> > Thanks


From jdsalerno at ucdavis.edu  Tue Mar  5 21:32:54 2013
From: jdsalerno at ucdavis.edu (Jonathan Salerno)
Date: Tue, 5 Mar 2013 12:32:54 -0800
Subject: [R-sig-ME] Is it possible to run MCMCglmm without varying effects?
Message-ID: <CAAVN0J_PMbQKjye=794VO3vKBKbkg_M2aZi5nSuQjD2fJ-5V5A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130305/b171571b/attachment.pl>

From bbolker at gmail.com  Wed Mar  6 04:33:27 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 6 Mar 2013 03:33:27 +0000 (UTC)
Subject: [R-sig-ME] Choosing nlme or lme4?
References: <1362498961.75551.YahooMailNeo@web161404.mail.bf1.yahoo.com>
Message-ID: <loom.20130306T042952-26@post.gmane.org>

Filipe Carvalho <filipescpcarvalho at ...> writes:

> I'm analysing the selectivity of resting site use by forest
> carnivores through mixed modelling techniques and I wonder which
> will be the best r package to deal with several aspects
> simultaneously:

> binomial variable response;
> possible spatial and/or temporal correlation;

> I have tried nlme (lme function) and lme4 (lmer function) packages,
> however I realize that the results were different concerning
> regression coefficients estimates and p-values!
 
> In nlme package, despite I can add easily a variance structure
> and/or temporal and spatial correlations structures, the choice of
> family = binomial not allowed. On the other hand, with lme4 I can
> choose the binomial family, but no structures can be added!
 
> Am I wrong with these statements? Zuur et al. 2009 always used lme4
> (Mass or glmmML) with binomial data but never nlme!

 Unfortunately, you are correct.

 See

http://glmm.wikidot.com/faq#spatiotemporal

for some of your options (MASS::glmmPQL, AD Model Builder,
INLA, ...).  glmmPQL is one of the suggestions of Dormann et al
(Ecography 2007) I wish this were easier.


From s.palacio at ipe.csic.es  Wed Mar  6 16:43:39 2013
From: s.palacio at ipe.csic.es (PALACIO BLASCO, SARA)
Date: Wed, 06 Mar 2013 16:43:39 +0100
Subject: [R-sig-ME] Error en mer_finalize(ans) : Downdated X'X is not
 positive definite, 1. What is wrong with my model?
In-Reply-To: <20130306104859.GG12721@laboinfo-063.pharmacie.univ-paris5.fr>
References: <20130304110928.Horde.7qeKdvMXqRJRNHLYoAdnKgA@webmail.csic.es>
	<loom.20130304T141627-598@post.gmane.org>
	<20130304145812.Horde.4lsfEPMXqRJRNKh0UcLReDA@webmail.csic.es>
	<5134AA4D.2010408@gmail.com>
	<20130305082945.Horde.8a5MM-MXqRJRNZ7pTgVj0XA@webmail.csic.es>
	<20130305074743.GA30217@laboinfo-063.pharmacie.univ-paris5.fr>
	<20130305094750.Horde.35eCEvMXqRJRNbE2QRelFbA@webmail.csic.es>
	<20130305095719.GG30217@laboinfo-063.pharmacie.univ-paris5.fr>
	<20130305120532.Horde.9F7KVfMXqRJRNdF8fWjCNSA@webmail.csic.es>
	<20130306104859.GG12721@laboinfo-063.pharmacie.univ-paris5.fr>
Message-ID: <20130306164339.Horde.K-xaDvMXqRJRN2QreNFytAA@webmail.csic.es>

Hi Emmanuel,

Yes, I have the same problem when using treatment + Bud_type.

And yes, I produced a contingency table for each species...

My conclusion is that glmer can not handle designs with nested fixed  
factors since it is not suitable to work with rank deficient designs.  
This might be the downside of using cutting-edge models!

Thanks a lot for your help,

Best wishes,

Sara
Quoting Emmanuel Curis <emmanuel.curis at parisdescartes.fr>:

> Hi Sara,
>
> If this is the case, you should have the same problem when using
> Treatment + Bud_Type instead of Treatment * Bud_Type. Is it the case ?
>
> When ? checking per species ?, you mean you studied each row of this
> table separatly and for each of them, constructed the
> species:treatment contingency table and saw that in each cell there
> were several observations (at least 3 or 4)?
>
> something like by( Bud_type, table( Species, Treatment ) )...
>
> After that... I must say I have no further idea.
>
> Best regards,
>
> On Tue, Mar 05, 2013 at 12:05:32PM +0100, PALACIO BLASCO, SARA wrote:
> ?
> ? Below you can see the contingency table for Treatment*Bud_type with
> ? the observations in each combination. As you can see the design is
> ? not balanced but there are no combinations with particularly few
> ? observations. I have checked this table per species and (taking into
> ? account that each species only has one Bud_type), all treatment
> ? levels have a representative number of observations...
> ?
> ? 	Treatment
> ? Bud_type-80	-34.7	-30.2	-26.3	-22.1	-17.2	-13.1	-6.6	4	Total
> ? hy	42	45	47	47	54	71	79	64	39	488
> ? na	24	31	30	34	30	30	30	30	24	263
> ? sc	62	71	72	68	71	82	69	78	62	635
> ? Total  128	147	149	149	155	183	178	172	125	1386
> ?
> ?
> ? The only issue I can see is that of each species only having one  
> Bud_type...
> ?
> ? Thanks for your help!
> ?
> ? sara palacio
>
> --
>                                 Emmanuel CURIS
>                                 emmanuel.curis at parisdescartes.fr
>
> Page WWW: http://emmanuel.curis.online.fr/index.html


From j.hadfield at ed.ac.uk  Wed Mar  6 21:47:18 2013
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Wed, 06 Mar 2013 20:47:18 +0000
Subject: [R-sig-ME] Data frame size limits in MCMCglmm?
In-Reply-To: <1362089238.14071.9.camel@musuko.uchicago.edu>
References: <1358546146.11821.40.camel@musuko.uchicago.edu>
	<CANz9Z_+5BDbVWxUcv8y-bG9YtwB0593eNUREy=UMyBmHUOcivA@mail.gmail.com>
	<20130125103605.16911d1gwewajp5w@www.staffmail.ed.ac.uk>
	<1362089238.14071.9.camel@musuko.uchicago.edu>
Message-ID: <20130306204718.17103xiuc3vcx46c@www.staffmail.ed.ac.uk>

Dear Stuart,

I think your are right that because the cutpoints and intercept are  
evenly spaced the data are consistent with discretised gaussian data.  
I think it is the even spacing that is important not that they  
correspond numerically with the ordinal categories. After all the  
scale is arbitrary. Whether a model assuming the data are continuous  
when in fact they are discrete would be robust, I'm not sure.  
Regarding your off-list questions tid is a variance rather than a  
standard deviation and the units are probits.

Cheers,

Jarrod





Quoting Stuart Luppescu <slu at ccsr.uchicago.edu> on Thu, 28 Feb 2013  
16:07:18 -0600:

> On Fri, 2013-01-25 at 10:36 +0000, Jarrod Hadfield wrote:
>> Hi Stuart,
>>
>> 2.4 million records is bigger than anything I've tried but in theory
>> it should run, or return an error if it can't allocate enough memory.
>> It definitely shouldn't be seg-faulting.  If you could send a
>> reproducible example (preferably one where it fails quickly) I will
>> take a look into it.
>
> I finally got around to doing this analysis on a 25% random sample. It
> ran but took about 25 hours for 100,000 iterations. (Was that too many?)
>
> Here are the results:
>
>  Iterations = 3001:99991
>  Thinning interval  = 10
>  Sample size  = 9700
>
>  DIC: 1739944
>
>  G-structure:  ~tid
>
>     post.mean l-95% CI u-95% CI eff.samp
> tid    0.4597   0.4426   0.4754     7732
>
>  R-structure:  ~units
>
>       post.mean l-95% CI u-95% CI eff.samp
> units         1        1        1        0
>
>  Location effects: final.points ~ gr10 + gr11 + gr12
>
>             post.mean l-95% CI u-95% CI eff.samp  pMCMC
> (Intercept)    1.0179   1.0007   1.0347     6334 <1e-04 ***
> gr10           0.3155   0.3033   0.3278     7514 <1e-04 ***
> gr11           0.5825   0.5686   0.5959     7728 <1e-04 ***
> gr12           0.7262   0.7121   0.7412     7390 <1e-04 ***
> ---
> Signif. codes:  0 ????**??? 0.001 ????*??? 0.01 ??????? 0.05 ??????? 0.1
> ??? ??? 1
>
>  Cutpoints:
>                              post.mean l-95% CI u-95% CI eff.samp
> cutpoint.traitfinal.points.1    0.9506   0.9459   0.9552     1458
> cutpoint.traitfinal.points.2    1.9154   1.9097   1.9216     1092
> cutpoint.traitfinal.points.3    2.9882   2.9807   2.9956     1096
>
>
> The main reason I'm doing this analysis is to see if the results are
> different with ordered category outcomes as opposed to treating the
> outcome as numbers (which I've done with lmer). Does the fact that the
> posterior means for the cutpoints are very close to the numerical values
> mean that I am not gaining much by treating outcome as ordered
> categories (and I can just use the results from lmer)?
>
> Thanks.
>
>
>
> --
> Stuart Luppescu <slu at ccsr.uchicago.edu>
> University of Chicago
>
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From j.hadfield at ed.ac.uk  Wed Mar  6 21:48:55 2013
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Wed, 06 Mar 2013 20:48:55 +0000
Subject: [R-sig-ME] Is it possible to run MCMCglmm without varying
 effects?
In-Reply-To: <CAAVN0J_PMbQKjye=794VO3vKBKbkg_M2aZi5nSuQjD2fJ-5V5A@mail.gmail.com>
References: <CAAVN0J_PMbQKjye=794VO3vKBKbkg_M2aZi5nSuQjD2fJ-5V5A@mail.gmail.com>
Message-ID: <20130306204855.12365283scwkxu8s@www.staffmail.ed.ac.uk>

Hi Jon,

I don't really understand the question and what is meant by varying  
effects. Perhaps you could write down the model formula, or provide an  
example?

Cheers,

Jarrod



Quoting Jonathan Salerno <jdsalerno at ucdavis.edu> on Tue, 5 Mar 2013  
12:32:54 -0800:

> I'm trying to reproduce results from polr (method="probit") using MCMCglmm-
> initially a simple ordinal outcome from a single predictor fixed effect.  I
> gather that this is not possible (if so, then it's a simple syntax
> question), but can MCMCglmm be manipulated in some way to approximate an an
> output without varying effects?  Thanks in advance for any help.
>
> jon
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From ross at biostat.ucsf.edu  Thu Mar  7 03:37:30 2013
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Wed, 06 Mar 2013 18:37:30 -0800
Subject: [R-sig-ME] glmmADMB troubles
In-Reply-To: <5132856F.4080805@gmail.com>
References: <512EB394.6070601@biostat.ucsf.edu>
	<loom.20130228T050019-868@post.gmane.org>
	<512F9ECD.2090905@biostat.ucsf.edu> <5132856F.4080805@gmail.com>
Message-ID: <5137FD6A.4060608@biostat.ucsf.edu>

On 3/2/2013 3:04 PM, Ben Bolker wrote:
> On 13-02-28 01:15 PM, Ross Boylan wrote:
>> On 2/27/2013 8:05 PM, Ben Bolker wrote:
>>> Ross Boylan <ross at ...> writes:
>    [snip: not including version without NAs removed, since we already
> know what the issue is there]
>
>>> r <- glmmadmb(sexActs~(1|id), sexpartner[!is.na(sexpartner$sexActs),],
>>> debug=TRUE)
>> platform: windows 32
>> executable name: glmmadmb.exe
>> bin_loc:
>> c:/Users/rdboylan/Documents/R/R-2.15.2/site-library/glmmADMB/bin/windows32/glmmadmb.exe
>>
>> using temp directory
>> C:\Users\rdboylan\AppData\Local\Temp\Rtmpy2JsMY\glmmADMB17085c19f4d
>> creating temp directory
>> changed working directory to
>> C:/Users/rdboylan/AppData/Local/Temp/Rtmpy2JsMY/glmmADMB17085c19f4d
>> Command line:
>> "c:/Users/rdboylan/Documents/R/R-2.15.2/site-library/glmmADMB/bin/windows32/glmmadmb.exe"
>> -maxfn 500 -maxph 5 -noinit -shess
>> Error in system(cmd, intern = intern, wait = wait | intern,
>> show.output.on.console = wait,  :
>>    'C:/Program' not found
>    I'm a little bit baffled here.  What happens if you use save.dir to
> save the input files to a temporary directory and run
>
> "c:/Users/rdboylan/Documents/R/R-2.15.2/site-library/glmmADMB/bin/windows32/glmmadmb.exe"
> -maxfn 500 -maxph 5 -noinit -shess
>
> from the command line?

> r <- glmmadmb(sexActs~(1|id), sexpartner[!is.na(sexpartner$sexActs),], debug=TRUE, save.dir="I:/LAMOC/Ross/")
platform: windows 32
executable name: glmmadmb.exe
bin_loc: c:/Users/rdboylan/Documents/R/R-2.15.2/site-library/glmmADMB/bin/windows32/glmmadmb.exe
changed working directory to I:/LAMOC/Ross
Command line: "c:/Users/rdboylan/Documents/R/R-2.15.2/site-library/glmmADMB/bin/windows32/glmmadmb.exe" -maxfn 500 -maxph 5 -noinit -shess
Error in system(cmd, intern = intern, wait = wait | intern, show.output.on.console = wait,  :
   'C:/Program' not found

Then from a Windows Command Prompt (not cygwin)
H:\> "c:/Users/rdboylan/Documents/R/R-2.15.2/site-library/glmmADMB/bin/windows32
/glmmadmb.exe" -maxfn 500 -maxph 5 -noinit -shess
Error trying to open data input file glmmadmb.dat
  Error trying to read in model data
  This is usual caused by a missing DAT file
H:\>I:

I:\>cd LAMOC/Ross

I:\LAMOC\Ross> "c:/Users/rdboylan/Documents/R/R-2.15.2/site-library/glmmADMB/b
/windows32/glmmadmb.exe" -maxfn 500 -maxph 5 -noinit -shess

Initial statistics: 1 variables; iteration 0; function evaluation 0; phase 1
Function value   8.9003579e+04; maximum gradient component mag  -5.3609e+02
Var   Value    Gradient   |Var   Value    Gradient   |Var   Value    Gradient

   1  0.00000 -5.36095e+02 |

  - final statistics:
1 variables; iteration 8; function evaluation 14
Function value   5.0576e+04; maximum gradient component mag   6.2393e-08
Exit code = 1;  converg criter   1.0000e-04
Var   Value    Gradient   |Var   Value    Gradient   |Var   Value    Gradient

   1 112.5711  6.23928e-08 |
etc

So it seems to work, provided I start in the save.dir. Note that is the 
directory that R is running in.
glmmadmb.exe is still running as I hit send.

>
>   What is the result of .Platform (and .Platform$OS in particular)

> .Platform
$OS.type
[1] "windows"

$file.sep
[1] "/"

$dynlib.ext
[1] ".dll"

$GUI
[1] "RTerm"

$endian
[1] "little"

$pkgType
[1] "win.binary"

$path.sep
[1] ";"

$r_arch
[1] "i386"

Ross

>
>   It looks conceivably like R is misdiagnosing your system as *not* being
> windows, as that's the only way system() should be running.  Are you
> running under Cygwin (you say it's installed below) ...  ?
>
>> changed working directory to i:/LAMOC/Ross
>> removed temp directory
>> C:\Users\rdboylan\AppData\Local\Temp\Rtmpy2JsMY\glmmADMB17085c19f4d
>>> glmmADMB:::get_bin_loc()
>> $bin_loc
>> [1]
>> "c:/Users/rdboylan/Documents/R/R-2.15.2/site-library/glmmADMB/bin/windows32/glmmadmb.exe"
>>
>>
>> $platform
>> [1] "windows"
>>
>> P.S. about lme4; I don't have a build environment and so trying the
>> github version will not be my first move.
>> Although perhaps lack of a build environment is why the second version
>> is failing.  I do have cygwin installed, althoughI would not expect R to
>> know how to find it.
>    lme4 should be installable from lme4.r-forge.r-project.org/repos now,
> as stated in a message earlier today.
>


From m1mathew at ucsd.edu  Thu Mar  7 21:49:38 2013
From: m1mathew at ucsd.edu (Margie Mathewson)
Date: Thu, 7 Mar 2013 12:49:38 -0800 (PST)
Subject: [R-sig-ME] Finding r^2 value and plotting regression lines and CIs
	from gls
Message-ID: <54431.137.110.136.169.1362689378.squirrel@acs-webmail.ucsd.edu>

I'm a new R user who has been using the gls function to analyze scaling
relationships in mammals while considering phylogenetic similarity. I'm
having trouble with a few things, though.

1) For my project, I need to know the r or r^2 value of my scaling line,
and I'm having trouble figuring out how to find it in R. Is there an easy
way to get gls function to spit out this value?

2) Is there a way to plot the regression line and confidence intervals
calculated by the program onto the data sets I'm analyzing in R? I've been
able to plot residuals, but not the regression line and data.

Thanks for any suggestions you can offer!
Margie


From kalakouentin at gmail.com  Fri Mar  8 02:06:42 2013
From: kalakouentin at gmail.com (Pantelis H)
Date: Fri, 8 Mar 2013 01:06:42 +0000
Subject: [R-sig-ME] Nested Effects and Correlation
Message-ID: <CAH2DVQFj9s1hNbVz=PPDKt40ggP-qEQNi-0h_GE_+KcUzoNiWw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130308/a808d3d1/attachment.pl>

From slu at ccsr.uchicago.edu  Fri Mar  8 20:42:55 2013
From: slu at ccsr.uchicago.edu (Stuart Luppescu)
Date: Fri, 08 Mar 2013 13:42:55 -0600
Subject: [R-sig-ME] Comparing linear and ordinal model random effects
Message-ID: <1362771775.23834.16.camel@musuko.uchicago.edu>

Hello, I have a dataset with outcomes (student grades, A, B, C, D, F)
coded as 4, 3, 2, 1, 0. I did a linear mixed model, and a non-linear
model with ordered categorical outcomes (using MCMCglmm), with teacher
as the random effect.

For the linear model, the random effects were:

Random effects:
 Formula: ~1 | tid
        (Intercept) Residual
StdDev:   0.5644021 1.215661

(or 0.3185 and 1.4778 in squared units)

For the model with ordered categories, the variances were:

G-structure:  ~tid

    post.mean l-95% CI u-95% CI eff.samp
tid    0.4597   0.4426   0.4754     7732

 R-structure:  ~units

      post.mean l-95% CI u-95% CI eff.samp
units         1        1        1        0

The thresholds are:

 Cutpoints: 
                             post.mean l-95% CI u-95% CI eff.samp
cutpoint.traitfinal.points.1    0.9506   0.9459   0.9552     1458
cutpoint.traitfinal.points.2    1.9154   1.9097   1.9216     1092
cutpoint.traitfinal.points.3    2.9882   2.9807   2.9956     1096

It is much more convenient to use the linear model. (I can't even get
MCMCglmm to run with the complete dataset - 2.4 million observations.)
For the linear model the variances are in original score points; the
ordinal model the variances are in probits. I don't know how to convert
from probits to original score points.

Do I have any justification to say that both models result in similar
values for the variances and so it's OK to use the linear model?

-- 
Stuart Luppescu <slu at ccsr.uchicago.edu>
University of Chicago


From asiren at wildcats.unh.edu  Fri Mar  8 23:31:16 2013
From: asiren at wildcats.unh.edu (Alexej Siren)
Date: Fri, 8 Mar 2013 22:31:16 +0000
Subject: [R-sig-ME] syntax for partially crossed model
Message-ID: <A12C2B4E09B51F41AFBE49CF0EFEE92346575064@BY2PRD0412MB670.namprd04.prod.outlook.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130308/15c83a91/attachment.pl>

From jsorkin at grecc.umaryland.edu  Sun Mar 10 22:10:52 2013
From: jsorkin at grecc.umaryland.edu (John Sorkin)
Date: Sun, 10 Mar 2013 17:10:52 -0400
Subject: [R-sig-ME] Cluster analysis in the setting of repeated measures
Message-ID: <513CBEAB020000CB000DBD3F@smtp.medicine.umaryland.edu>

At the suggestion of Ben Bolker I am sending this message to r-sig-mixed-models after previously sending it to r-help
Does R have any function for performing cluster analysis when each subject contributes more than one observation to the analysis, i.e. a repeated measures cluster analysis? I prefer an agglomerative clustering, but would certainly be happy with a K-mean or other clustering technique. To the best of my knowledge, the "standard" R clustering functions (e.g. kmeans, hclust, pvclust) all assume that each subject contributes a single line of data to the analyses.
Thanks,
John
Sent from my iPhone
Confidentiality Statement:
This email message, including any attachments, is for th...{{dropped:6}}


From bbolker at gmail.com  Mon Mar 11 04:44:25 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 11 Mar 2013 03:44:25 +0000 (UTC)
Subject: [R-sig-ME]
	=?utf-8?q?Finding_r=5E2_value_and_plotting_regression_?=
	=?utf-8?q?lines_and_CIs=09from_gls?=
References: <54431.137.110.136.169.1362689378.squirrel@acs-webmail.ucsd.edu>
Message-ID: <loom.20130311T044024-8@post.gmane.org>

Margie Mathewson <m1mathew at ...> writes:

> 
> I'm a new R user who has been using the gls function to analyze scaling
> relationships in mammals while considering phylogenetic similarity. I'm
> having trouble with a few things, though.
> 
> 1) For my project, I need to know the r or r^2 value of my scaling line,
> and I'm having trouble figuring out how to find it in R. Is there an easy
> way to get gls function to spit out this value?

   R and R^2 are a little bit complicated once one gets beyond simple
linear models -- you have to decide exactly what you mean by "variance
explained"; you can search for R^2 or pseudo-R^2 on this list or elsewhere
for excruciating details.   In the meantime, methods(class="gls") tells
you what you can do with a gls fit, and the correlation between predicted
and observed values is a reasonable **CRUDE** approximation of R:

example(gls)
cor(predict(fm1),Ovary$follicles)

predict() is also what you need to draw a regression line 
(see ?predict.gls)

> 
> 2) Is there a way to plot the regression line and confidence intervals
> calculated by the program onto the data sets I'm analyzing in R? I've been
> able to plot residuals, but not the regression line and data.

confidence intervals are probably pretty tricky for the aforementioned
reasons ...

> 
> Thanks for any suggestions you can offer!
> Margie
> 
>


From bbolker at gmail.com  Mon Mar 11 04:57:36 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 11 Mar 2013 03:57:36 +0000 (UTC)
Subject: [R-sig-ME] Nested Effects and Correlation
References: <CAH2DVQFj9s1hNbVz=PPDKt40ggP-qEQNi-0h_GE_+KcUzoNiWw@mail.gmail.com>
Message-ID: <loom.20130311T044440-959@post.gmane.org>

Pantelis H <kalakouentin at ...> writes:

> 
> Hello,
> 
> I have a question:
> In the case of multiple nested effects one can be provided with
> correlations for a grouping's subgroups; how are these correlations
> computed? 
  
  I'm not quite sure what you mean here.


library(lme4)
example(Pastes)
fm2

gives an example of a model with nested grouping factors.
I see a variance and a (redundant) standard deviation for
each random component (cask within batch, batch, residual error),
but no correlations.
  Looking at the Oats example in the Implementation vignette
http://cran.r-project.org/web/packages/lme4/vignettes/Implementation.pdf
shows the same thing.

> What is the correct reference for the computational calculation
> of the nested random effects and their correlation in lmer()?
> I believe an LDL^t decomposition of a scaled precision matrix might be
> involved but I looked in the three lme4 vignettes, Bates & DebRoy (2004) in
> J. of Multivariate Analysis as well as the DebRoy & Bates' Technical Report
> No. 1076 but none mentions something explicitly (eg. the Implementation.pdf
> vignette specifically sets "corr = FALSE" in the case of nested factors
> actually). Could someone please suggest to me references in regard with
> that?

   Usually corr=FALSE refers to suppressing the printing of
the correlations among _fixed_ effect parameters ... where else are
you looking?

> Only indirect references I could find was: 1. subsection 2.2.7 on Pinheiro
> & Bates "Mixed-Effects Models in S and S-Plus" but even there nothing is
> stated specifically for correlation calculations and 2. the Bell Labs
> Technical Memorandum "Computational Methods for Multilevel Modelling" by
> Bates & Pinheiro that mentions correlations in regard with the Nonlinear
> multilevel model. Additionally both references are mostly referring on
> lme().
> Finally, the "lme4: Mixed-effects modeling with R" book in subsection 3.2.1
> while looking at nested effect correlations it does not provide
> computational aspects of it.

  I can see that you've tried to be very specific (thank you), but
I'm still not sure what you're referring to.  Here are some thoughts:

 * the correlation between _variance estimates_ is not explicitly modeled
in lme4: one might be able to extract them from the Hessian matrix, but
it would be a bit challenging
 * correlations are modeled, by default, among random effects within
the same grouping factor.  For example, on p 17 of the implementation
vignette a correlation is given between the intercept and nitrogen
random effects at the Block level -- it happens to be 1.0 (suggesting
the model is overfitted).  These correlations are directly modeled as
part of the 'theta' vector which contains the elements of the lower
triangle of the Cholesky factor of the relevant L matrix (which is
described on pp. 5-6 of the same vignette).

  Ben Bolker


From bbolker at gmail.com  Mon Mar 11 13:00:33 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 11 Mar 2013 08:00:33 -0400
Subject: [R-sig-ME] Nested Effects and Correlation
In-Reply-To: <CAH2DVQFE4=UCwM3nXd9CY2QcOFcJb9maHu2wzLS2S7uUVLbYgg@mail.gmail.com>
References: <CAH2DVQFj9s1hNbVz=PPDKt40ggP-qEQNi-0h_GE_+KcUzoNiWw@mail.gmail.com>
	<loom.20130311T044440-959@post.gmane.org>
	<CAH2DVQFE4=UCwM3nXd9CY2QcOFcJb9maHu2wzLS2S7uUVLbYgg@mail.gmail.com>
Message-ID: <513DC761.2000307@gmail.com>

On 13-03-11 01:36 AM, Pantelis Hadjipantelis wrote:
> On Mon, Mar 11, 2013 at 3:57 AM, Ben Bolker <bbolker at gmail.com
> <mailto:bbolker at gmail.com>> wrote:
> 
>     Pantelis H <kalakouentin at ...> writes:
> 
>     >
>     > Hello,
>     >
>     > I have a question:
>     > In the case of multiple nested effects one can be provided with
>     > correlations for a grouping's subgroups; how are these correlations
>     > computed?
> 
>       I'm not quite sure what you mean here.
> 
> 
>     library(lme4)
>     example(Pastes)
>     fm2
> 
>     gives an example of a model with nested grouping factors.
>     I see a variance and a (redundant) standard deviation for
>     each random component (cask within batch, batch, residual error),
>     but no correlations.
>       Looking at the Oats example in the Implementation vignette
>     http://cran.r-project.org/web/packages/lme4/vignettes/Implementation.pdf
>     shows the same thing.
> 
>     > What is the correct reference for the computational calculation
>     > of the nested random effects and their correlation in lmer()?
>     > I believe an LDL^t decomposition of a scaled precision matrix might be
>     > involved but I looked in the three lme4 vignettes, Bates & DebRoy
>     (2004) in
>     > J. of Multivariate Analysis as well as the DebRoy & Bates'
>     Technical Report
>     > No. 1076 but none mentions something explicitly (eg. the
>     Implementation.pdf
>     > vignette specifically sets "corr = FALSE" in the case of nested
>     factors
>     > actually). Could someone please suggest to me references in regard
>     with
>     > that?
> 
>        Usually corr=FALSE refers to suppressing the printing of
>     the correlations among _fixed_ effect parameters ... where else are
>     you looking?
> 
>     > Only indirect references I could find was: 1. subsection 2.2.7 on
>     Pinheiro
>     > & Bates "Mixed-Effects Models in S and S-Plus" but even there
>     nothing is
>     > stated specifically for correlation calculations and 2. the Bell Labs
>     > Technical Memorandum "Computational Methods for Multilevel
>     Modelling" by
>     > Bates & Pinheiro that mentions correlations in regard with the
>     Nonlinear
>     > multilevel model. Additionally both references are mostly referring on
>     > lme().
>     > Finally, the "lme4: Mixed-effects modeling with R" book in
>     subsection 3.2.1
>     > while looking at nested effect correlations it does not provide
>     > computational aspects of it.
> 
>       I can see that you've tried to be very specific (thank you), but
>     I'm still not sure what you're referring to.  Here are some thoughts:
> 
>      * the correlation between _variance estimates_ is not explicitly
>     modeled
>     in lme4: one might be able to extract them from the Hessian matrix, but
>     it would be a bit challenging
>      * correlations are modeled, by default, among random effects within
>     the same grouping factor.  For example, on p 17 of the implementation
>     vignette a correlation is given between the intercept and nitrogen
>     random effects at the Block level -- it happens to be 1.0 (suggesting
>     the model is overfitted).  These correlations are directly modeled as
>     part of the 'theta' vector which contains the elements of the lower
>     triangle of the Cholesky factor of the relevant L matrix (which is
>     described on pp. 5-6 of the same vignette).
> 
> 
> That was exactly the clarification I needed. I could "see" (using
> verbose=T) that the "theta" vector contained elements regarding the
> correlations of random effects within the same grouping but I was not
> entirely sure that their final values were directly modeled and
> estimated from matrix L. Thank you.

  I think it of as the other way around (although this may be just a
difference in the way we're describing the same thing).  The theta
vector represents the primary model parameters; L is derived from theta
when computing likelihoods etc..


From sh.chunxuan at gmail.com  Mon Mar 11 18:47:12 2013
From: sh.chunxuan at gmail.com (shao chunxuan)
Date: Mon, 11 Mar 2013 18:47:12 +0100
Subject: [R-sig-ME] Error : "contrasts apply only to factors" in post-hoc
 analysis afer lmer fitting.
Message-ID: <CA+PUQOuSg6Wk16=zh2Z-0B05tg5M6kBmmm+USC=2REVDRcEXRw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130311/ed82f503/attachment.pl>

From ross at biostat.ucsf.edu  Mon Mar 11 18:59:05 2013
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Mon, 11 Mar 2013 10:59:05 -0700
Subject: [R-sig-ME] lme4 versions
Message-ID: <1363024745.10433.19.camel@corn.betterworld.us>

Running from Debian Squeeze with R 2.15.3 I tried
install.packages("lme4",repos="http://r-forge.r-project.org")
but got
package ?lme4? is not available (for R version 2.15.3)

Then I got the latest svn from r-forge (only later realizing I didn't
need the whole thing) and built pkg/lme4.  Is that an appropriate
version?

Then I recalled Ben's instructions that git has the latest version, but
I need some Debian packages installed before that will work
(libcurl-devel; I'm guessing I'll need some git stuff too).

BTW, I'm using lme4 in 2 separate projects, one on MS Windows and one on
Linux.  Unfortunately I don't have admin rights for either.

Ross Boylan


From ross at biostat.ucsf.edu  Mon Mar 11 20:25:56 2013
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Mon, 11 Mar 2013 12:25:56 -0700
Subject: [R-sig-ME] lme4 versions
In-Reply-To: <1363024745.10433.19.camel@corn.betterworld.us>
References: <1363024745.10433.19.camel@corn.betterworld.us>
Message-ID: <1363029956.10433.40.camel@corn.betterworld.us>

On Mon, 2013-03-11 at 10:59 -0700, Ross Boylan wrote:
> Running from Debian Squeeze with R 2.15.3 I tried
> install.packages("lme4",repos="http://r-forge.r-project.org")
> but got
> package ?lme4? is not available (for R version 2.15.3)
> 
> Then I got the latest svn from r-forge (only later realizing I didn't
> need the whole thing) and built pkg/lme4.  Is that an appropriate
> version?
> 
> Then I recalled Ben's instructions that git has the latest version, but
> I need some Debian packages installed before that will work
> (libcurl-devel; I'm guessing I'll need some git stuff too).
I got the installation from git working.  It seems to be the same
version either way, since the git install got lme4_0.99999911-0.tar.gz.
> 
> BTW, I'm using lme4 in 2 separate projects, one on MS Windows and one on
> Linux.  Unfortunately I don't have admin rights for either.
> 
> Ross Boylan
> 


From ross at biostat.ucsf.edu  Mon Mar 11 21:25:29 2013
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Mon, 11 Mar 2013 13:25:29 -0700
Subject: [R-sig-ME] 2 correlated random effects with quadrature?
Message-ID: <1363033529.10433.47.camel@corn.betterworld.us>

Is there a way to fit generalized linear mixed model with 2 correlated
random effects in R, using quadrature?  At the moment, I'm only
concerned with binary outcomes.

When I try glmer from lme4 with the quadrature argument I get
Error: AGQ only defined for a single scalar random-effects term

Yes, I know 2 dimensional quadrature is slow.

Ross Boylaln


From bbolker at gmail.com  Mon Mar 11 23:28:18 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 11 Mar 2013 22:28:18 +0000 (UTC)
Subject: [R-sig-ME] lme4 versions
References: <1363024745.10433.19.camel@corn.betterworld.us>
	<1363029956.10433.40.camel@corn.betterworld.us>
Message-ID: <loom.20130311T232600-6@post.gmane.org>

Ross Boylan <ross at ...> writes:

> 
> On Mon, 2013-03-11 at 10:59 -0700, Ross Boylan wrote:
> > Running from Debian Squeeze with R 2.15.3 I tried
> > install.packages("lme4",repos="http://r-forge.r-project.org")
> > but got
> > package ?lme4? is not available (for R version 2.15.3)
> > 
> > Then I got the latest svn from r-forge (only later realizing I didn't
> > need the whole thing) and built pkg/lme4.  Is that an appropriate
> > version?
> > 
> > Then I recalled Ben's instructions that git has the latest version, but
> > I need some Debian packages installed before that will work
> > (libcurl-devel; I'm guessing I'll need some git stuff too).
> I got the installation from git working.  It seems to be the same
> version either way, since the git install got lme4_0.99999911-0.tar.gz.
> > 
> > BTW, I'm using lme4 in 2 separate projects, one on MS Windows and one on
> > Linux.  Unfortunately I don't have admin rights for either.

  I need to update the installation instructions on R-forge, but for right now
your choices are:

 1. stable lme4: install from CRAN.
 2. development lme4:
    * install binaries from http://lme4.r-forge.r-project.org/repos
      OR
    * install via devtools::install_github.  Right now the modular branch
install_github("lme4","lme4","modular") is slightly ahead of the
main branch (install_github("lme4","lme4")

  cheers
   Ben Bolker


From bbolker at gmail.com  Tue Mar 12 22:18:45 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 12 Mar 2013 21:18:45 +0000 (UTC)
Subject: [R-sig-ME] 2 correlated random effects with quadrature?
References: <1363033529.10433.47.camel@corn.betterworld.us>
Message-ID: <loom.20130312T215032-974@post.gmane.org>

Ross Boylan <ross at ...> writes:

> 
> Is there a way to fit generalized linear mixed model with 2 correlated
> random effects in R, using quadrature?  At the moment, I'm only
> concerned with binary outcomes.
> 
> When I try glmer from lme4 with the quadrature argument I get
> Error: AGQ only defined for a single scalar random-effects term
> 
> Yes, I know 2 dimensional quadrature is slow.
> 
> Ross Boylaln

  I don't know offhand of an R package that will do this.  I'm pretty
sure AS-REML uses PQL (not even Laplace approximation): AD Model Builder can 
only do GHQ for nested/grouped models (i.e. not crossed) with a single
random effect per block.  As far as I know you're simply out of luck:
both GHQ and the ability to handle crossed random effects are fairly
rare among GLMM platforms, and the combination seems even rarer.
I presume you've (1) compared Laplace approximation to GHQ with simpler
examples and (2) compared Laplace approximation to 'truth' in simulations
and found it wanting in one or both cases?  One alternativepossibility 
for improving the quality of the approximation would be to use importance
sampling in AD Model Builder ...


From jwiley.psych at gmail.com  Tue Mar 12 22:47:50 2013
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Tue, 12 Mar 2013 14:47:50 -0700
Subject: [R-sig-ME] 2 correlated random effects with quadrature?
In-Reply-To: <1363033529.10433.47.camel@corn.betterworld.us>
References: <1363033529.10433.47.camel@corn.betterworld.us>
Message-ID: <CANz9Z_JUimMYfydE6yAfV_nBuvZ2iuqF5N8N8gd7G-dUvjAGhg@mail.gmail.com>

Hi Ross,

I do not know any functionality for GHQ, but you already acknowledged
you were okay with slow, at which point, you can probably do better
with MCMC.  If you're not feeling like rolling your own, the MCMCglmm
package makes it quite easy.

Here is a (not particularly sensible) example:

require(MCMCglmm)
set.seed(1234)
dat <- mtcars[sample(1:32, 1000, replace = TRUE), ]
dat <- within(dat, {
  qsec <- scale(qsec)
  hp <- scale(hp)
  mpg <- scale(mpg)
  disp <- scale(disp)
})
dat$ID <- factor(rep(letters, length.out = 1000))
dat$cyl <- factor(dat$cyl)
# set seed and estimate model
set.seed(10)
m <- MCMCglmm(vs ~ qsec + mpg + drat, random = ~ us(1 + mpg):ID,
family = "categorical",
  data = dat, prior = list(
  B = list(mu = c(0, 0, 0, 0), V = diag(4) * 1e2),
  R = list(V = 1, fix = 1),
  G = list(G1 = list(V = diag(2), nu = 2))), pr=TRUE,
  nitt = 55000, thin = 20, burnin = 5000, verbose=FALSE)

# print a summary
summary(m)


 Iterations = 5001:54981
 Thinning interval  = 20
 Sample size  = 2500
 DIC: 22.87558
 G-structure:  ~us(1 + mpg):ID
                           post.mean l-95% CI u-95% CI eff.samp
(Intercept):(Intercept).ID   0.75374   0.1228    1.754   217.21
mpg:(Intercept).ID          -0.03048  -1.1675    0.922   108.96
(Intercept):mpg.ID          -0.03048  -1.1675    0.922   108.96
mpg:mpg.ID                   0.97473   0.1383    2.644    41.16
 R-structure:  ~units
      post.mean l-95% CI u-95% CI eff.samp
units         1        1        1        0
 Location effects: vs ~ qsec + mpg + drat
            post.mean l-95% CI u-95% CI eff.samp  pMCMC
(Intercept)    2.4890  -8.4259  11.9981   40.374  0.652
qsec          18.9466  13.3597  23.8444    2.672 <4e-04 ***
mpg            8.2778   5.6246  11.2228    9.550 <4e-04 ***
drat          -0.3849  -2.9258   2.3827   40.419  0.800
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1


Now of course I did not run enough iterations, and probably have a low
thinning interval, you may want better priors, and if you are looking
to compare to standard logistic models, don't forget to rescale the
estimates (note the non zero variance used to improve mixing).

Still, it is relatively straightforward, highly stable given enough
time, flexible to have many effects, and gives you posteriors which
are great for inference.

Cheers,

Josh



On Mon, Mar 11, 2013 at 1:25 PM, Ross Boylan <ross at biostat.ucsf.edu> wrote:
> Is there a way to fit generalized linear mixed model with 2 correlated
> random effects in R, using quadrature?  At the moment, I'm only
> concerned with binary outcomes.
>
> When I try glmer from lme4 with the quadrature argument I get
> Error: AGQ only defined for a single scalar random-effects term
>
> Yes, I know 2 dimensional quadrature is slow.
>
> Ross Boylaln
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



-- 
Joshua Wiley
Ph.D. Student, Health Psychology
University of California, Los Angeles
http://joshuawiley.com/
Senior Analyst - Elkhart Group Ltd.
http://elkhartgroup.com


From David.Duffy at qimr.edu.au  Wed Mar 13 02:34:03 2013
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Wed, 13 Mar 2013 11:34:03 +1000
Subject: [R-sig-ME] 2 correlated random effects with quadrature?
In-Reply-To: <loom.20130312T215032-974@post.gmane.org>
References: <1363033529.10433.47.camel@corn.betterworld.us>
	<loom.20130312T215032-974@post.gmane.org>
Message-ID: <alpine.LMD.2.00.1303131057060.398@orpheus.qimr.edu.au>

On Wed, 13 Mar 2013, Ben Bolker wrote:

> Ross Boylan <ross at ...> writes:
>
>>
>> Is there a way to fit generalized linear mixed model with 2 correlated
>> random effects in R, using quadrature?  At the moment, I'm only
>> concerned with binary outcomes.
>>
>> When I try glmer from lme4 with the quadrature argument I get
>> Error: AGQ only defined for a single scalar random-effects term
>>
>> Yes, I know 2 dimensional quadrature is slow.
>>
>> Ross Boylaln
>
>  I don't know offhand of an R package that will do this.

If you're happy with a probit link, it is pretty straightforward to hook 
mvtnorm up to a maximizer, especially if you have just the one problem to 
fit.  Your groups can't be too large unfortunately.

If you look in 
http://genepi.qimr.edu.au/staff/davidD/Sib-pair/Src/sib-pair.R

under varcomp.mft(), there is an example of two*N crossed correlated 
random effects in a standard genetics variance components model:

lik.mft.fam <- function(vc.data, m, va, vq, nthresh) {
   ln <- function(x) ifelse(x>0, log(x), 0)
   ndata <- length(vc.data$y)
   thresh <- matrix(NA, nr=ndata, nc=(nthresh+2))
   thresh[,1] <- -Inf
   thresh[,ncol(thresh)] <- Inf
   thresh[, -c(1, ncol(thresh))] <- vc.data$covariates %*% matrix(m, nr=1)
   S <- va*vc.data$rel + vq*vc.data$ibd + diag(1-va-vq,nrow(vc.data$rel))
   res <- ln(pmvnorm(lower=thresh[cbind(1:ndata,vc.data$y+1)],
                     upper=thresh[cbind(1:ndata,vc.data$y+2)],
                     corr=S))

where va and vq are the variance components for two classes of random 
effects (additive genetic and QTL, one each for each individual 
observation), and rel and ibd are the correlation matrices for the random 
effects (which we can specify using the pedigree structure and 
observed sharing of genetic markers).  This likelihood is maximized 
using optim().  For high dimensional integration, you need to tweak abseps 
and releps of the Quasi-Monte-Carlo algorithm.  It can do up to 1000 
dimensions, but your likelihood can bounce around a fair bit (because it 
is MC), which upsets your maximizer, but you'll get the right answer 
eventually.

Cheers, David Duffy.




| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v


From gybrg at leeds.ac.uk  Wed Mar 13 10:14:14 2013
From: gybrg at leeds.ac.uk (Benjamin Gillespie)
Date: Wed, 13 Mar 2013 09:14:14 +0000
Subject: [R-sig-ME] gls error
Message-ID: <894643FDEA3A854A89B3E828737E2B1FFC6F5F0C88@HERMES8.ds.leeds.ac.uk>

Morning all,

I wonder if anyone could shed some light on a problem I am receiving in R when I try to fit a model:

I'm attempting to follow the 'Protocol' as in Chapters 4 & 5 of Zuur et al 2009 for some data I have for a number of river sites, sampled once for macroinvertebrates. Each site has been graded into 1 of 3 groups dependent on it's characteristics. I want to find out whether the factor: "group" is significant.

I have a response variable: "simp" (simpsons diversity index) and a number of fixed factors that I would like to include in my model.

In R, this is the code I use:

f1=formula(simp~group+date+altitude+data_source+catchment_size+g1+g2+g3+g4+g5+g6+lc1+lc2+lc3+lc4+lc5)
s1.gls=gls(f1,data=env.sp)

Please note: g1...gX are %cover of geology types for each site and lc1...lcX are % land cover types for each site.

The following is the error I receive:

Error in glsEstimate(glsSt, control = glsEstControl) : computed "gls" fit is singular, rank 16

>From what I've read, it looks like I'm using too many explanatory factors. I have tested for colinearity between all factors, but none look like obvious candidates for removal.

What would you suggest one should do in this instance?

Many thanks in advance for your advice,
		
Ben Gillespie
Research Postgraduate
 


From bbolker at gmail.com  Wed Mar 13 16:37:35 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 13 Mar 2013 15:37:35 +0000 (UTC)
Subject: [R-sig-ME] gls error
References: <894643FDEA3A854A89B3E828737E2B1FFC6F5F0C88@HERMES8.ds.leeds.ac.uk>
Message-ID: <loom.20130313T161523-457@post.gmane.org>

Benjamin Gillespie <gybrg at ...> writes:

> 
> Morning all,
 
> I wonder if anyone could shed some light on a problem I am receiving
>  in R when I try to fit a model:
 
> I'm attempting to follow the 'Protocol' as in Chapters 4 & 5 of Zuur
> et al 2009 for some data I have for a number of river sites, sampled
> once for macroinvertebrates. Each site has been graded into 1 of 3
> groups dependent on it's characteristics. I want to find out whether
> the factor: "group" is significant.
 
> I have a response variable: "simp" (simpsons diversity index) and a
> number of fixed factors that I would like to include in my model.
 
> In R, this is the code I use:
 
> f1=formula(simp~group+date+altitude+data_source+catchment_size+
  g1+g2+g3+g4+g5+g6+lc1+lc2+lc3+lc4+lc5)

> s1.gls=gls(f1,data=env.sp)
 
> Please note: g1...gX are %cover of geology types for each site and 
  lc1...lcX are % land cover types for each site.
> 
> The following is the error I receive:
 
> Error in glsEstimate(glsSt, control = glsEstControl) : computed
  "gls" fit is singular, rank 16
 
> From what I've read, it looks like I'm using too many explanatory
> factors. I have tested for colinearity between all factors, but none
> look like obvious candidates for removal.

  If you use a full set of compositional data as predictors (i.e. A,
B, C, D such that A+B+C+D=1) then you will necessarily have a
multicollinearity problem, even if the pairwise correlations between
the components aren't that high.  The correlation between any
component and the sum of all of the other components is exactly -1 (as
A+B+C increases, D must decrease).  You should leave one out
(preferably not a rare component, because if you leave a rare
component the remaining components will still be pretty strongly
multicollinear).  Alternatively, you could use something like
a log-ratio transform (see Aitchison and others) to transform
the n-dimensional compositional predictor to an (n-1)-dimensional
set of variables.

  (This isn't really a mixed model question ...)


From asiren at wildcats.unh.edu  Wed Mar 13 16:59:34 2013
From: asiren at wildcats.unh.edu (Alexej Siren)
Date: Wed, 13 Mar 2013 15:59:34 +0000
Subject: [R-sig-ME] partially crossed model
Message-ID: <A12C2B4E09B51F41AFBE49CF0EFEE9234658604C@BY2PRD0412MB670.namprd04.prod.outlook.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130313/9a3fe3fa/attachment.pl>

From angela.boag at alumni.ubc.ca  Wed Mar 13 17:33:17 2013
From: angela.boag at alumni.ubc.ca (angela.boag at alumni.ubc.ca)
Date: Wed, 13 Mar 2013 16:33:17 +0000
Subject: [R-sig-ME] glmmADMB Warning: Estimated covariance matrix may not be
 positive definite
Message-ID: <42B14BA341B0694198E11BF5C18865E9E25608@sam-mbx01.ead.ubc.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130313/73df69b1/attachment.pl>

From filipescpcarvalho at yahoo.com  Wed Mar 13 19:23:45 2013
From: filipescpcarvalho at yahoo.com (Filipe Carvalho)
Date: Wed, 13 Mar 2013 11:23:45 -0700 (PDT)
Subject: [R-sig-ME] spatial/temporal correlation in gamm with binomial data
Message-ID: <1363199025.79971.YahooMailNeo@web161403.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130313/72cd2572/attachment.pl>

From ramos.grad.student at gmail.com  Wed Mar 13 23:57:46 2013
From: ramos.grad.student at gmail.com (Antonio P. Ramos)
Date: Wed, 13 Mar 2013 15:57:46 -0700
Subject: [R-sig-ME] Can I compare different models - with and without random
 effects - across different packages?
Message-ID: <CAHawB9v8HtMmjqTEyZjtseb92DEPJXfDozpnaxz9CsNAcekGyQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130313/76c9b55d/attachment.pl>

From ramos.grad.student at gmail.com  Thu Mar 14 01:08:06 2013
From: ramos.grad.student at gmail.com (Antonio P. Ramos)
Date: Wed, 13 Mar 2013 17:08:06 -0700
Subject: [R-sig-ME] Can I compare different models - with and without
 random effects - across different packages?
In-Reply-To: <CAM9kYqjXHQFn_s6m8QqC=S1gJdOup3n=dHxHXhVC8x9ymgmNAw@mail.gmail.com>
References: <CAHawB9v8HtMmjqTEyZjtseb92DEPJXfDozpnaxz9CsNAcekGyQ@mail.gmail.com>
	<CAM9kYqjXHQFn_s6m8QqC=S1gJdOup3n=dHxHXhVC8x9ymgmNAw@mail.gmail.com>
Message-ID: <CAHawB9sAxnQnsoQU1_TwJJnWsc0Rw4HBkD7xWHyC1wB7DGq+RQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130313/740b7ef7/attachment.pl>

From ross at biostat.ucsf.edu  Thu Mar 14 01:22:59 2013
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Wed, 13 Mar 2013 17:22:59 -0700
Subject: [R-sig-ME] glmer: Downdated X'X is not positive definite
 [related to nAGQ] fixed?
In-Reply-To: <512EB4E3.8080705@biostat.ucsf.edu>
References: <5127FA87.9030707@biostat.ucsf.edu>
	<1361742542.25712.30.camel@corn.betterworld.us>
	<loom.20130225T031849-152@post.gmane.org>
	<512E974E.8010105@biostat.ucsf.edu>
	<512EB4E3.8080705@biostat.ucsf.edu>
Message-ID: <51411863.5040805@biostat.ucsf.edu>

On 2/27/2013 5:37 PM, Ross Boylan wrote:
> On 2/27/2013 3:31 PM, Ross Boylan wrote:
>
> I discovered that omitting the nAGQ argument is sufficient to avoid 
> the error.  I also tried nAGQ=5 and removing the missing data in 
> advance; neither eliminated the downdating error.
>
>> r2 <- glmer(sexActs~(1|id), data=sexpartner, family=poisson())
>
>> r2 <- glmer(sexActs~(1|id), data=sexpartner, family=poisson(), nAGQ=5)
>
> Error in mer_finalize(ans) : Downdated X'X is not positive definite, 1.
>
> The error message sounds as if it is just a function of the input 
> covariates, which obviously don't change when I change nAGQ.  My 
> interpretation of X in the error message may be wrong.
>
> This is with the version of lme4 from CRAN.
>
I have some notes that was with lme4 0.999999-0.

I do not get the error when I use MS Windows version 0.999902344-0 (more 
recent, but a lower version number?):

   There is a binary version available (and will be installed) but the
   source version is later:
             binary        source
lme4 0.999902344-0 0.999902345-0

trying URL 'http://cran.cnr.berkeley.edu/bin/windows/contrib/2.15/minqa_1.2.1.zip'
Content type 'application/zip' length 606807 bytes (592 Kb)
opened URL
downloaded 592 Kb

trying URL 'http://lme4.r-forge.r-project.org/repos/bin/windows/contrib/2.15/lme4_0.999902344-0.zip'
Content type 'application/zip' length 2027695 bytes (1.9 Mb)
opened URL

The problem may have had more to do with minqa.  Even after updating 
lme4 only, I got

> library(lme4)
Loading required package: lattice
Loading required package: Matrix
r2 <- glmer(sexActs~(1|id), data=sexpartner, family=poisson(), nAGQ=5)
Error in inDL(x, as.logical(local), as.logical(now), ...) :
   unable to load shared object 'c:/Users/rdboylan/Documents/R/R-2.15.2/site-library/minqa/libs/i386/minqa.dll':
   LoadLibrary failure:  Invalid access to memory location.

Error: package/namespace load failed for 'lme4'
> Error: could not find function "glmer"

It was only after I removed both packages (lme4 and minqa) and 
reinstalled that I was able to run the analysis.

The March 2 announcement said:
> I have just pushed updated source, Windows 64-bit binary, and MacOS
> binaries of the very most current development version of lme4,
> 0.99999911-1, to the repository at
>
>   http://lme4.r-forge.r-project.org/repos/src/contrib/  ;
apparently that needs to be read literally, since I did not pick up a 32 
bit windows binary for that version.


From ross at biostat.ucsf.edu  Thu Mar 14 01:34:26 2013
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Wed, 13 Mar 2013 17:34:26 -0700
Subject: [R-sig-ME] 2 correlated random effects with quadrature?
In-Reply-To: <loom.20130312T215032-974@post.gmane.org>
References: <1363033529.10433.47.camel@corn.betterworld.us>
	<loom.20130312T215032-974@post.gmane.org>
Message-ID: <51411B12.4050305@biostat.ucsf.edu>

On 3/12/2013 2:18 PM, Ben Bolker wrote:
> Ross Boylan <ross at ...> writes:
>
>> Is there a way to fit generalized linear mixed model with 2 correlated
>> random effects in R, using quadrature?  At the moment, I'm only
>> concerned with binary outcomes.
>>
>> When I try glmer from lme4 with the quadrature argument I get
>> Error: AGQ only defined for a single scalar random-effects term
>>
>> Yes, I know 2 dimensional quadrature is slow.
>>
>> Ross Boylaln
>    I don't know offhand of an R package that will do this.  I'm pretty
> sure AS-REML uses PQL (not even Laplace approximation): AD Model Builder can
> only do GHQ for nested/grouped models (i.e. not crossed) with a single
> random effect per block.
I'm not sure if it matters, but the 2 random effects are both within the 
same cluster; they are for intercepts and slopes.  The clusters 
themselves are not crossed or nested.
>   As far as I know you're simply out of luck:
Back to SAS nlmixed...  For some reason I'm having trouble piping 
results from R to SAS on Linux.
> both GHQ and the ability to handle crossed random effects are fairly
> rare among GLMM platforms, and the combination seems even rarer.
> I presume you've (1) compared Laplace approximation to GHQ with simpler
> examples and (2) compared Laplace approximation to 'truth' in simulations
> and found it wanting in one or both cases?
The main reason is that we want to compare the results with a more 
complicated model fit using 2-dimensional quadrature.  The more 
complicated model, in R, takes into account the sampling scheme that 
generated the data, which we are simulating.
>   One alternativepossibility
> for improving the quality of the approximation would be to use importance
> sampling in AD Model Builder ...
>
Ross


From ross at biostat.ucsf.edu  Thu Mar 14 01:52:05 2013
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Wed, 13 Mar 2013 17:52:05 -0700
Subject: [R-sig-ME] optimizers for mixed models
Message-ID: <51411F35.6070808@biostat.ucsf.edu>

lme4 appears to use Nelder Mead for the final stage of its 
optimization.  The archives show various concerns about stability, but 
it looks as if even the prior optimizer was in the simplex class.

This surprised me, since I have found Nelder Mead to be relatively slow 
and imprecise, and in a more complex mixed model with sampling I've been 
using optim with L-BFGS-B, which is quasi-newton.  One of the parameter 
estimates kept creeping up over iterations; the bounds were necessary to 
cut it off.

If anyone can give me more insight into why Nelder Mead is in use, and 
perhaps whether I should be using it myself, I'd appreciate it.

The current behavior, in which about 10% of the simulated datasets have 
convergence problems, with one of the parameters heading toward an 
implausible value (a correlation of 1.0, where atanh(rho) is the actual 
parameter being estimated) is certainly not ideal.  I tried simulated 
annealing to see if the algorithm had wandered mistakenly toward a local 
rather than global optimum; there was no evidence that it had (the SA 
ended up in the same neighborhood as BFGS, and when that point was the 
starting value for BFGS it ended on essentially the same point as before).

Ross Boylan


From jdsalerno at ucdavis.edu  Thu Mar 14 02:14:30 2013
From: jdsalerno at ucdavis.edu (Jonathan Salerno)
Date: Wed, 13 Mar 2013 18:14:30 -0700
Subject: [R-sig-ME] MCMCglmm ordinal: clarification on estimating an
 intercepts only model and interpreting cutpoints
Message-ID: <CAAVN0J8wAsfZdQ71SnRANV0mBtg5kNY3G+VLfEgyshJAc9g_CQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130313/60c88680/attachment.pl>

From David.Duffy at qimr.edu.au  Thu Mar 14 05:42:23 2013
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Thu, 14 Mar 2013 14:42:23 +1000
Subject: [R-sig-ME] Can I compare different models - with and without
 random effects - across different packages?
In-Reply-To: <CAHawB9sAxnQnsoQU1_TwJJnWsc0Rw4HBkD7xWHyC1wB7DGq+RQ@mail.gmail.com>
References: <CAHawB9v8HtMmjqTEyZjtseb92DEPJXfDozpnaxz9CsNAcekGyQ@mail.gmail.com><CAM9kYqjXHQFn_s6m8QqC=S1gJdOup3n=dHxHXhVC8x9ymgmNAw@mail.gmail.com>
	<CAHawB9sAxnQnsoQU1_TwJJnWsc0Rw4HBkD7xWHyC1wB7DGq+RQ@mail.gmail.com>
Message-ID: <alpine.LMD.2.00.1303141436350.6583@orpheus.qimr.edu.au>

On Thu, 14 Mar 2013, Antonio P. Ramos wrote:

> I see:  perhaps should just keep it there. the problem is that random
> effects makes the computation more complex so that I have less options to
> explore time trends. thanks
>
>
> On Wed, Mar 13, 2013 at 4:45 PM, Philippi, Tom <tom_philippi at nps.gov> wrote:
>
>> The short answer is no, at least for the with & without random effects.
>>
>> On Wed, Mar 13, 2013 at 3:57 PM, Antonio P. Ramos <
>> ramos.grad.student at gmail.com> wrote:
>>
>>> I am trying to see whether I should include a random effects in my models.
>>> I am trying to predict child mortality based on a buch of covariates.

Since your families are small, you can compare results to those from 
a vector glm (VGAM package), as well as the marginal GEE models (gee 
package).

Personally, I test if the within-cluster correlation is zero on a regular 
basis ;).  It's just the distribution of the test that is confusing.

| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v


From j.hadfield at ed.ac.uk  Thu Mar 14 11:09:15 2013
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Thu, 14 Mar 2013 10:09:15 +0000
Subject: [R-sig-ME] MCMCglmm ordinal: clarification on estimating an
 intercepts only model and interpreting cutpoints
In-Reply-To: <CAAVN0J8wAsfZdQ71SnRANV0mBtg5kNY3G+VLfEgyshJAc9g_CQ@mail.gmail.com>
References: <CAAVN0J8wAsfZdQ71SnRANV0mBtg5kNY3G+VLfEgyshJAc9g_CQ@mail.gmail.com>
Message-ID: <20130314100915.14416418pq07r9ss@www.staffmail.ed.ac.uk>

Hi,

The polr and MCMCglmm models you have fitted are equivalent.  If you  
have a look at (m2$CP-m2$Sol)/sqrt(2) you will find them to be  
identical to the cutpoints estimates from polr. The sqrt(2) comes from  
the fact that there is the probit variance and the `residual' variance  
as specified in the R element of the prior.

The probability of observing an outcome in category k is

pnorm(eta, CP[k-1], 1)-pnorm(est, CP[k], 1)

where in your case the latent variable eta is Gaussian with mean equal  
to the Intercept estimate and a variance of 1.  One cutpoint is not  
identifiable from the intercept so CP[1] is set to zero. Therefore  
-m2$Sol/sqrt(2) is equal to the first cutpoint in polr.

Cheers,

Jarrod





Quoting Jonathan Salerno <jdsalerno at ucdavis.edu> on Wed, 13 Mar 2013  
18:14:30 -0700:

> I posted a confusing version of this question a few weeks ago, so here's an
> attempt at clarifying:
>
> In short, I'm trying to replicate an intercept-only (ie, no predictors)
> model output of polr() using MCMCglmm as an initial step before building up
> a more complex model family that includes varying intercept and slope
> effects (ie, random, clustering, multi-level effects) and multiple
> predictors.
>
> To estimate the intercepts of an ordinal model with no predictors, lets say
> it's specified as follows in polr():
>
> m1 <- polr( as.ordered(h) ~ 1, data=d1, Hess=T, method="probit"),
>
> where h is a 7 category response for household hunger.  Before building in
> predictors, I wish to compare the cumulative link estimation of intercepts.
>  My question is whether the following specification in MCMCglmm will
> approximate the above polr fit:
>
> prior <- list(R=list(V=1, fix=1))
> m2 <- MCMCglmm( as.ordered(h)
> ~ 1, family="ordinal", pl=F, pr=F, data=d1,prior=prior).
>
> The second part of this question regards how to interpret the MCMCglmm
> cutpoints in terms of intercepts.  I've read the few posts from you and Ben
> Bolker answering similar questions, but I'm not following the process.
>  Specifically, I don't understand which value of a latent variable used in
> the cumulative probability distribution function is used to compute the k-1
> intercepts from the cutpoint outputs of MCMCglmm.
>
> Apologies for my difficulty, but your help is much appreciated.  Thanks
> very much, and good day.
>
> jon
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From asafw.at.wharton at gmail.com  Thu Mar 14 16:13:47 2013
From: asafw.at.wharton at gmail.com (Asaf Weinstein)
Date: Thu, 14 Mar 2013 11:13:47 -0400
Subject: [R-sig-ME] How does lmer obtain ML estimates that are not
	stationary points?
Message-ID: <CAGG0PdBTG0ozrVj=H_BPLy8hr3QdVrYGeB77xJDXQ8k=QhFkTg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130314/44451fe7/attachment.pl>

From bbolker at gmail.com  Thu Mar 14 18:08:18 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 14 Mar 2013 17:08:18 +0000 (UTC)
Subject: [R-sig-ME] optimizers for mixed models
References: <51411F35.6070808@biostat.ucsf.edu>
Message-ID: <loom.20130314T150520-774@post.gmane.org>

Ross Boylan <ross at ...> writes:

> 
> lme4 appears to use Nelder Mead for the final stage of its 
> optimization.  The archives show various concerns about stability, but 
> it looks as if even the prior optimizer was in the simplex class.

  Depends how far you go back.  nlme and older versions of lme4 used
nlminb.  This is derivative-based, but you'd have to look at the guts
of nlminb and at the PORT documentation for a detailed description ...

 http://netlib.bell-labs.com/cm/cs/cstr/153.pdf

I think it's quasi-Newton ... digging around more in the R code
guts shows it's NL2SOL -- you could dig some more on Netlib to
find the details 

> This surprised me, since I have found Nelder Mead to be relatively slow 
> and imprecise, and in a more complex mixed model with sampling I've been 
> using optim with L-BFGS-B, which is quasi-newton.  One of the parameter 
> estimates kept creeping up over iterations; the bounds were necessary to 
> cut it off.

  Not quite sure what you mean here.  I have personally found L-BFGS-B
to be somewhat unstable in my experience ...  The optimplus package
on R-forge gives a lot more optimizer choices ...
  
> If anyone can give me more insight into why Nelder Mead is in use, and 
> perhaps whether I should be using it myself, I'd appreciate it.

  Nelder-Mead *is* fairly slow, but it tends to be slightly more robust
over a broad class of problems.  The current development version of lme4
lets you pick your own optimizer, so you can make the speed vs
robustness tradeoff however you like ...
 
> The current behavior, in which about 10% of the simulated datasets have 
> convergence problems, with one of the parameters heading toward an 
> implausible value (a correlation of 1.0, where atanh(rho) is the actual 
> parameter being estimated) is certainly not ideal.  I tried simulated 
> annealing to see if the algorithm had wandered mistakenly toward a local 
> rather than global optimum; there was no evidence that it had (the SA 
> ended up in the same neighborhood as BFGS, and when that point was the 
> starting value for BFGS it ended on essentially the same point as before).

   Can you send me a simulated example that experiences this problem?

  I can't tell at the moment whether you are using lme4 or your
own hand-rolled solution to the problem.

  There are two possibilities here: (1) the best-fit solution really
is in the limit as rho -> Inf / correlation -> 1.0; this is similar to
the case where the MLE variance of a random effect is zero, even when
the true model (from which the data were simulated) has a non-zero
variance; (2) the best-fit solution is very close to +/- 1.0.

  It's going to be tough either way, but in case #1 you would
definitely be better off with a parameter space in which the
singular cases corresponded to _simple_ box constraints on the
parameters.   For the Cholesky parameterization this is true
for the variances (for a 2-by-2 matrix, theta_1=0 and theta_2=theta_3=0
are the conditions for the variances to be 0), and (mostly) for
the correlations -- the correlations go to +/- 1 when theta_3=0
*or* when theta_2 -> infinity, but in the latter case the variance
will blow up to infinity as well (so probably not a case worth
worrying about).


From bbolker at gmail.com  Thu Mar 14 18:17:55 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 14 Mar 2013 17:17:55 +0000 (UTC)
Subject: [R-sig-ME] partially crossed model
References: <A12C2B4E09B51F41AFBE49CF0EFEE9234658604C@BY2PRD0412MB670.namprd04.prod.outlook.com>
Message-ID: <loom.20130314T180859-706@post.gmane.org>

Alexej Siren <asiren at ...> writes:

> 
> Hello,
 
> I'll try to make this more succinct.  

  Thanks ...

> I'm working with longitudinal
> data and having difficulty understanding the correct formulation for
> a partially crossed random effects model.


> 
> I'm evaluating 2 competing hypotheses.

> 1) marten use (detections/day) of high elevation habitat is seasonal
> and/or 2) construction and wind farm operation affects marten use of
> high elevation habitat.

  These aren't really competing, are they ("and/or")?  Although
I guess they might be 'competing' in the sense that they each
produce similar patterns in the data ... so the parameters that
describe each phenomenon are negatively correlated ...

> -These time periods overlap i.e., construction activities occurred
> in winter and summer and vary in length (42 - 163 days).  

> -Marten come in and out of the study but need to be monitored for at
> least 2 seasons/3 construction periods.  Also, marten contribute
> differently depending on the amount of high elevation habitat within
> their home range.
 
> So far my formula has been:
> 
> fm1 <- lmer(detections ~ localseason + constructionperiod2 +  (1|marten), 
>   data_std, family=poisson(log))
 
> How would I change this to account for the partial crossing that
> occurred between marten and periods?  Would it look like this?

  You mean the fact that some martens are not measured in some
periods?  I don't think that would necessarily be a problem.

> fm1 <- lmer(detections ~ localseason + constructionperiod2 + 
> (1|localseason:marten) +
> (1|constructionperiod2:marten) + (1|marten), data_std, family=poisson(log))

  What you are doing here is effectively allowing the number of
detections of each individual to vary according to season and
construction period.  It is in principle reasonable (you are right to
use interactions rather than nesting as in (1|localseason/marten),
because that would add a random effect of localseason to the existing
fixed effect of localseason, which would be a bad idea), but you must
generally have a response for each individuals more than once per
localseason and more than once per construction period (it's OK if
_some_ individuals have zero or one responses [by "response" I mean a
Poisson-distributed observation] in order for the model to be
sensible.

  Don't forget to check for overdispersion.


From bbolker at gmail.com  Thu Mar 14 18:24:26 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 14 Mar 2013 17:24:26 +0000 (UTC)
Subject: [R-sig-ME] glmmADMB Warning: Estimated covariance matrix may
	not be positive definite
References: <42B14BA341B0694198E11BF5C18865E9E25608@sam-mbx01.ead.ubc.ca>
Message-ID: <loom.20130314T181808-948@post.gmane.org>

angela.boag at ... <angela.boag at ...> writes:

> 
> Hi everyone,
 
> I'm developing predictive maps of plant species diversity using a
> data set of richness counts from 668 quadrats divided amongst 109
> sites (number of quadrats per site is variable, and depends on site
> size).
 
> I am modelling richness counts of native and nonnative species using
> a combination of geoclimatic and air photo-derived land use types,
> with the hypothesis that higher nonnative species richness will be
> associated with higher levels of human disturbance, agriculture
> etc., while the opposite is true for native species richness. Site
> is used as a random effect to deal with some of the spatial
> autocorrelation.
 
> >From an original candidate set of 22 predictor variables I kicked
> out those causing correlations of >0.7 (Spearman), then kicked out a
> further set that had VIFs >5 (after Zuur 2009), leaving 11 predictor
> variables which I standardized using z-scores. 

  I'm a little bit nervous about dropping predictor variables on
the basis of correlations -- I'd prefer PCA or a penalized approach --
but I agree that this is sometimes a necessary evil.  Can you
construct anthropogenic-impact indices that collapse your predictor
into a smaller set?

> I found both the native and nonnative count data was better
> described by a negative binomial distribution than Poisson, and so
> created a global model using glmmADMB, to which I then applied the
> Dredge function form MuMIn to get a model set for averaging:
 
> #native sp richness
> admb_nr <- glmmadmb(formula=nat_r ~ NR_RD + AG_AR + NR_AG + DEV_AR + SEI_AR + 
> NR_SEI + SLP + NOR + EAST + PA_AR +
> TMP_RG +  (1|site_code), data=meadow, family="nbinom", zeroInflation = FALSE)
> best_subs_n <- dredge(admb_nr, rank = "AIC", trace = TRUE)
 
> Dredge runs fine and yields a model list with coefficients and
> standard errors that makes sense, but in my R console (I did trace =
> TRUE and therefore can see each model from Dredge, 2^11 = 2048
> models) the warning "Estimated covariance matrix may not be positive
> definite" appears. The first instance is after the 26th model, then
> it reappears after every 2 or 3 models from then on. For example:
 
> 233 : glmmadmb(formula = nat_r ~ NOR + NR_RD + NR_SEI + PA_AR + 1,
>     data = meadow, family = "nbinom", zeroInflation = FALSE)
> Estimated covariance matrix may not be positive definite
>  0.00017891 0.355147 0.361441 0.37348 0.386851 0.401956 0.446906 0.519341
> 234 : glmmadmb(formula = nat_r ~ AG_AR + NOR + NR_RD + NR_SEI + PA_AR +
>     1, data = meadow, family = "nbinom", zeroInflation = FALSE)
> Estimated covariance matrix may not be positive definite
>  0.000144364 0.405747 0.412888 0.432029 0.452005 0.493285
> Estimated covariance matrix may not be positive definite
>  0.000145352 0.403984 0.411032 0.426545 0.432984 0.460366 0.49558
 
> I've read that collinearity can cause this, though I feel like I've
> addressed that. Though, as Ben discussed in a reply to one of
> today's messages could it happen if you have variables that are
> derived from the same layer that could sum to 1? Indeed, AG_AR and
> DEV_AR are both derived from the same GIS layer, but there are
> several other polygon types not included in this model so it
> shouldn't be the problem.
 
> Any insight into what else may cause this warning and what it means
> for my analysis would me much appreciated. Interestingly, when I run
> the model and Dredge for the nonnative richness count data I don't
> get the warning interspersed with each iterative model, but rather
> it appears after the 2048th about 8 times.
 
  It basically means that the likelihood surface is nearly flat
in some direction, i.e. that some combination of parameter effects
is nearly collinear.  It's very hard to say in general, but it basically
means you are still overfitting the model somewhat.  It also
doesn't mean the model is _necessarily_ wrong, just that you ought
to be suspicious. I think my recommendation would be to try to boil
the model down farther (e.g. by collapsing to indices as suggested above)
and make sure that the _qualitative_ conclusions don't change once
you collapse things to the point where you know you are reliably
fitting the model.

  I'm also not entirely happy about dredging, although I can appreciate
that it is essentially a route to penalized regression ...


From bbolker at gmail.com  Thu Mar 14 18:27:31 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 14 Mar 2013 17:27:31 +0000 (UTC)
Subject: [R-sig-ME]
	=?utf-8?q?How_does_lmer_obtain_ML_estimates_that_are_n?=
	=?utf-8?q?ot=09stationary_points=3F?=
References: <CAGG0PdBTG0ozrVj=H_BPLy8hr3QdVrYGeB77xJDXQ8k=QhFkTg@mail.gmail.com>
Message-ID: <loom.20130314T182439-831@post.gmane.org>

Asaf Weinstein <asafw.at.wharton at ...> writes:

> 
> Hi,
> 
> I am looking at a two-way random-effects ANOVA layout as a particular case
> of the general mixed-model,
> 
> y|b ~ N(X beta + Zb, sigsq I)
> b ~ N(0,sigsq Gamma_theta )    [Gamma diagonal],
> 
> I am trying to compute ML estimates for theta under a KNOWN sigsq (i.e.,
> error variance is known). I derived my own ML estimates since lmer()
> estimates sigsq rather than assuming it is known.
> As long as the variance components (or theta's) are "big" (far from zero),
> the output of my algorithm is consistent with the output of lmer (when
> plugging in the estimated sigsq into my functions); but I run into problems
> when the ML estimates for at least one of the theta's is close zero.
> 
> Before i roll up my sleeves, I would like to know how lmer handles the case
> in which the value of theta which nullifies the derivative is negative (or
> does not exist at all), i.e., the ML estimate cannot be obtained by
> searching for a root of the derivative of the profile likelihood.
> 
> (If my point was not clear, I refer to the case similar to what happens in
> the balanced two-way ANOVA when the row (or column) sum of squares minus
> the estimated error component is negative..).

  lmer fits models on a constrained space where the variances are not
allowed to be negative.  So it would give the best fit on the boundary
of the feasible space (although I would be very slightly suspicious of
the results in this case; it is easy to misconverge / run into
optimization difficulties when the results are on the boundary,
although I don't have any concrete examples of where lmer gets this 
wrong).

  With the development version of R, you can get the deviance function
and evaluate it yourself over a range of parameter values to see what
it does.


From bates at stat.wisc.edu  Thu Mar 14 18:38:27 2013
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 14 Mar 2013 12:38:27 -0500
Subject: [R-sig-ME] optimizers for mixed models
In-Reply-To: <loom.20130314T150520-774@post.gmane.org>
References: <51411F35.6070808@biostat.ucsf.edu>
	<loom.20130314T150520-774@post.gmane.org>
Message-ID: <CAO7JsnR1U-sCNm3Q=76AAvSqj86yLP64oGgACX=p+g+bqmTuNA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130314/b39f4467/attachment.pl>

From ross at biostat.ucsf.edu  Thu Mar 14 18:55:37 2013
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Thu, 14 Mar 2013 10:55:37 -0700
Subject: [R-sig-ME] optimizers for mixed models
In-Reply-To: <loom.20130314T150520-774@post.gmane.org>
References: <51411F35.6070808@biostat.ucsf.edu>
	<loom.20130314T150520-774@post.gmane.org>
Message-ID: <51420F19.9020205@biostat.ucsf.edu>

On 3/14/2013 10:08 AM, Ben Bolker wrote:
> Ross Boylan <ross at ...> writes:
>
>> lme4 appears to use Nelder Mead for the final stage of its
>> optimization.  The archives show various concerns about stability, but
>> it looks as if even the prior optimizer was in the simplex class.
>    Depends how far you go back.  nlme and older versions of lme4 used
> nlminb.  This is derivative-based, but you'd have to look at the guts
> of nlminb and at the PORT documentation for a detailed description ...
>
>   http://netlib.bell-labs.com/cm/cs/cstr/153.pdf
>
> I think it's quasi-Newton ... digging around more in the R code
> guts shows it's NL2SOL -- you could dig some more on Netlib to
> find the details
>
>> This surprised me, since I have found Nelder Mead to be relatively slow
>> and imprecise, and in a more complex mixed model with sampling I've been
>> using optim with L-BFGS-B, which is quasi-newton.  One of the parameter
>> estimates kept creeping up over iterations; the bounds were necessary to
>> cut it off.
>    Not quite sure what you mean here.  I have personally found L-BFGS-B
> to be somewhat unstable in my experience ...  The optimplus package
> on R-forge gives a lot more optimizer choices ...
>    
I'll give that a try.
>> If anyone can give me more insight into why Nelder Mead is in use, and
>> perhaps whether I should be using it myself, I'd appreciate it.
>    Nelder-Mead *is* fairly slow, but it tends to be slightly more robust
> over a broad class of problems.  The current development version of lme4
> lets you pick your own optimizer, so you can make the speed vs
> robustness tradeoff however you like ...
>   
>> The current behavior, in which about 10% of the simulated datasets have
>> convergence problems, with one of the parameters heading toward an
>> implausible value (a correlation of 1.0, where atanh(rho) is the actual
>> parameter being estimated) is certainly not ideal.  I tried simulated
>> annealing to see if the algorithm had wandered mistakenly toward a local
>> rather than global optimum; there was no evidence that it had (the SA
>> ended up in the same neighborhood as BFGS, and when that point was the
>> starting value for BFGS it ended on essentially the same point as before).
>     Can you send me a simulated example that experiences this problem?
>
>    I can't tell at the moment whether you are using lme4 or your
> own hand-rolled solution to the problem.
I'm not sure you want it, since it does involve our hand-rolled 
solution.  You'd have to deal with the code as well as the data.
>
>    There are two possibilities here: (1) the best-fit solution really
> is in the limit as rho -> Inf / correlation -> 1.0; this is similar to
> the case where the MLE variance of a random effect is zero, even when
> the true model (from which the data were simulated) has a non-zero
> variance; (2) the best-fit solution is very close to +/- 1.0.
It got really, really close (e.g., tanh(7) -> rho= 0.9999983), so it's 
probably (1), even though that's hard to believe.  I wish I could 
identify exactly what about the data and the model are driving that.  
The data gave some of the standard mixed effects model (SAS glimmix) 
some trouble, but others (SAS nlmixed) were OK.
>
>    It's going to be tough either way, but in case #1 you would
> definitely be better off with a parameter space in which the
> singular cases corresponded to _simple_ box constraints on the
> parameters.
Optimization was originally via a custom optimizer using rho.  The 
custom optimizer did not incorporate bounds, and blew up when it got rho 
outside of [-1, 1].  So we switched to atanh(rho) as the target of 
optimization.  However, for some simulated datasets that failed to 
converge, as atanh(rho) marched slowly off toward infinity.  We switched 
to optim with bounds to cut that process off.

So perhaps we should go back to rho, but using optim or the other 
bounded optimizers you suggested.

So the fact that atanh(rho) is unbounded is a feature from some 
perspectives, but a bug from others.
>    For the Cholesky parameterization this is true
> for the variances (for a 2-by-2 matrix, theta_1=0 and theta_2=theta_3=0
> are the conditions for the variances to be 0), and (mostly) for
> the correlations -- the correlations go to +/- 1 when theta_3=0
> *or* when theta_2 -> infinity, but in the latter case the variance
> will blow up to infinity as well (so probably not a case worth
> worrying about).
>
Variances going to zero could also screw up estimates of the 
correlation, but the problem cases I've examined don't seem to have that 
particular problem.


From ross at biostat.ucsf.edu  Thu Mar 14 19:08:40 2013
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Thu, 14 Mar 2013 11:08:40 -0700
Subject: [R-sig-ME] optimizers for mixed models
In-Reply-To: <51420F19.9020205@biostat.ucsf.edu>
References: <51411F35.6070808@biostat.ucsf.edu>
	<loom.20130314T150520-774@post.gmane.org>
	<51420F19.9020205@biostat.ucsf.edu>
Message-ID: <51421228.2080909@biostat.ucsf.edu>

On 3/14/2013 10:55 AM, Ross Boylan wrote:
> Optimization was originally via a custom optimizer using rho.  The 
> custom optimizer did not incorporate bounds, and blew up when it got 
> rho outside of [-1, 1].  So we switched to atanh(rho) as the target of 
> optimization.  However, for some simulated datasets that failed to 
> converge, as atanh(rho) marched slowly off toward infinity.  We 
> switched to optim with bounds to cut that process off.
>
> So perhaps we should go back to rho, but using optim or the other 
> bounded optimizers you suggested.
>
> So the fact that atanh(rho) is unbounded is a feature from some 
> perspectives, but a bug from others. 
I forgot to mention that we actually have analytic second (and first) 
derivatives.  Switching to optim from the packages internal optimizer 
meant we're no longer using the analytic 2nd derivative.

Ross


From ross at biostat.ucsf.edu  Thu Mar 14 20:27:24 2013
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Thu, 14 Mar 2013 12:27:24 -0700
Subject: [R-sig-ME] optimplus? (was Re:  optimizers for mixed models)
In-Reply-To: <loom.20130314T150520-774@post.gmane.org>
References: <51411F35.6070808@biostat.ucsf.edu>
	<loom.20130314T150520-774@post.gmane.org>
Message-ID: <5142249C.8000906@biostat.ucsf.edu>

On 3/14/2013 10:08 AM, Ben Bolker wrote:
> The optimplus package
> on R-forge gives a lot more optimizer choices ...
I don't see such a package on r-forge or elsewhere.
Did you mean http://optimizer.r-forge.r-project.org/?
Ross


From kalakouentin at gmail.com  Thu Mar 14 21:04:44 2013
From: kalakouentin at gmail.com (Pantelis Hadjipantelis)
Date: Thu, 14 Mar 2013 20:04:44 +0000
Subject: [R-sig-ME] Evaluating Z matrix
Message-ID: <CAH2DVQGaFAv0YTGqJsWmsfJ8MHd759_Fr-nZExv8CwCGxW2rNw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130314/609d261e/attachment.pl>

From bbolker at gmail.com  Thu Mar 14 23:48:55 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 14 Mar 2013 22:48:55 +0000 (UTC)
Subject: [R-sig-ME] optimplus? (was Re:  optimizers for mixed models)
References: <51411F35.6070808@biostat.ucsf.edu>
	<loom.20130314T150520-774@post.gmane.org>
	<5142249C.8000906@biostat.ucsf.edu>
Message-ID: <loom.20130314T234650-936@post.gmane.org>

Ross Boylan <ross at ...> writes:

> 
> On 3/14/2013 10:08 AM, Ben Bolker wrote:
> > The optimplus package
> > on R-forge gives a lot more optimizer choices ...
> I don't see such a package on r-forge or elsewhere.
> Did you mean http://optimizer.r-forge.r-project.org/?
> Ross
> 
> 

  The project on r-forge is called optimizer ; it
contains multiple packages, one of which is optimplus.
  Most or all of the following packages are from the optimizer
project:

  a1 <- available.packages(contriburl=
    contrib.url("http://www.r-forge.r-project.org"))
  grep("^opt",rownames(a1),value=TRUE)
 ## [1] "optextras"  "optfntools" "optimgui"   "optimx"     "optparse"  
 ## [6] "optplus"    "optreplace"


From bbolker at gmail.com  Sat Mar 16 03:58:04 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 16 Mar 2013 02:58:04 +0000 (UTC)
Subject: [R-sig-ME] Evaluating Z matrix
References: <CAH2DVQGaFAv0YTGqJsWmsfJ8MHd759_Fr-nZExv8CwCGxW2rNw@mail.gmail.com>
Message-ID: <loom.20130316T021120-651@post.gmane.org>

Pantelis Hadjipantelis <kalakouentin at ...> writes:

> 
> Hello,
> 
> I am going through lme4's book chapters and among the things that are
> slightly in disparity with the current state of things is the structure of
> Zt. Namely in chapter 3, section 2, Fig 3.4 presents the images of the Z^T
> matrices for the models:
> (fm06 <- lmer(Reaction ~ 1 + Days + (1 + Days|Subject), sleepstudy,
> REML=FALSE)); image(fm06 <at> Zt)
> (fm07 <- lmer(Reaction ~ 1 + Days + (1|Subject) + (0+Days|Subject),
> sleepstudy, REML=FALSE)); image(fm07 <at> Zt)
> and while in the book they appear different now they appear the same.
> I understand that the "important bit" is the L matrix that does remain
> "unchanged" but getting a different Z matrix than before does seem odd.
> What is the reason of this change in the generation of Z and ?? from the
> random-effects terms?

  There have been several major changes in the internal structures
of the lme4 package in the last couple of years. The structure
of Z has simply changed as a side effect. In fact, the
development version of lme4 has reverted to a behaviour more like
the version from 2010, where (x|grp) and (1|grp)+(0+x|grp) give
differently structured Z matrices.

> If lme4 book is not the most update to date reference about the generation
> of Z in lme4, what resource is?

   Unfortunately, the code -- specifically the lme4:::mkReTrms function.
But you should feel free to keep asking questions here.


> Just to clarifty I am using: MEMSS_0.9-0, lme4_0.999999-0, Matrix_1.0-11.
> lme4's book version is that of June 25, 2010.
> 
> Thank you in advance.
> 
> All best,
> Pantelis Hadjipantelis


From osoong+r at gmail.com  Sat Mar 16 06:12:13 2013
From: osoong+r at gmail.com (Oliver Soong)
Date: Fri, 15 Mar 2013 22:12:13 -0700
Subject: [R-sig-ME] cAIC
Message-ID: <CAPQ=hVJts=tELGnFFHTV08ORRNFYG=Wt7jyr4mK3CLkFEb_nNw@mail.gmail.com>

Hi,

I'm using a linear mixed effects model on estimates of plant cover in
different years in plots situated along transects within different
zones.  The full set of random effects is (1 | year) + (1 |
zone/transect/plot), where each term is treated categorically.  I'm
interested in determining whether the plot-level random effect is
worth including in the model, and of course, that's where the trouble
begins.

I'm thinking in terms of AIC.  Of course, the problem with AIC is
determining the d.f. of random effects.  As I've read a number of
times, the appropriate d.f. lies somewhere between 1 and the number of
random effect groups/clusters, depending on the random effect variance
lying somewhere in (0,Inf).

In my naive view of things, then, the true AIC lies somewhere between
AIC1 based on 1 d.f. per random effect and AICn based on the number of
random effect groups.  Dangerously pursuing this naive train of
thought, given two nested models in which the additional random
effects is itself nested (e.g., zone/transect vs. zone/transect/plot),
there is some d.f. per random effect at which the AIC differ by 2.
I'm ignoring the case in which the additional random effect improves
model fit by so much that comparison is trivial (which is not my
case).

I looked into Vaida & Blanchard (2005) and Greven & Kneib (2010).  I
won't pretend to understand everything they're doing, but I did dig up
the code used by G&K.  I think I managed to adapt it to work with lme4
in addition to nlme (through RLRsim), and I deleted their rescaling
code (which was buggy) and simplified the calculation of the
conditional log-likelihood (which had broken).  I've appended that
code, and would definitely appreciate if anybody who might understand
conditional AIC (cAIC) and/or corrected conditional AIC (ccAIC) could
take a look.  My apologies for the line breaks that e-mail will
butcher.

At the presumption of trying to use this code, I noticed something
surprising.  I'm comparing my zone/transect model against my
zone/transect/plot model.  The difference in log-likelihood is ~0.2.
Even using AIC1, I would conclude that adding the plot-level random
effects does not significantly improve the model fit, although I can
only claim that the simpler model with only the transect-level random
effect is significantly better if the plot-level random effect
represents at least ~1.1 degree of freedom.  cAIC favors the model
with plot-level random effects (the difference in cAIC is ~1.5), which
is the bias G&K address.  However, their ccAIC also favors the model
with plot-level random effects, and the difference in ccAIC is even
larger (~4.8).  Given the very modest improvement in log-likelihood
afforded by the plot-level random effects, I'm surprised by these
results, although given my general ignorance, I wouldn't be surprised
if I've grossly misunderstood something.

I have 1863 observations and 21 fixed effects (including intercept).
Except for the additional plot-level random effect, the two fitted
fitted models are essentially identical (differences in coefficients
for terms shared between the zone/transect and zone/transect/plot
models are less than 1% of the corresponding estimated variances).
I'm using R 2.15.2 and lme4 0.999999.0.

Oliver

PS: The code borks when any random effect variance is 0.


tr <- function (x, na.rm = FALSE) {
    sum(diag(x), na.rm = na.rm)
}
cAIC <- function(m) {
    require(RLRsim)
    if(class(m) == "lme") {
        design <- extract.lmeDesign(m)
        method <- m$method
    } else if(class(m) == "mer") {
        require(lme4)
        design <- extract.lmerDesign(m)
        method <- if(isREML(m)) "REML" else "ML"
    } else stop("m must be of class lme or mer")

    X <- design$X
    Z <- design$Z
    y <- design$y
    lambda <- design$lambda
    sigmasq <- design$sigmasq

    n <- nrow(X)
    tausq <- sigmasq * lambda
    lambda <- 1 / lambda
    dvr <- diag(design$Vr)
    dvrFactor <- factor(dvr, levels = unique(dvr))
    repseq <- table(dvrFactor)

    V <- diag(rep(sigmasq, n)) + Z %*% diag(rep(tausq, repseq)) %*% t(Z)
    H <- cbind(X, Z)
    H <- t(H) %*% H
    H1 <- solve(H + diag(c(rep(0, ncol(X)), rep(lambda, repseq))))
    V0 <- diag(rep(1, n)) + Z %*% diag(rep(tausq, repseq)) %*% t(Z)
    V0inv <- diag(rep(1, n)) - Z %*% solve(t(Z) %*% Z +
diag(rep(lambda, repseq))) %*% t(Z)
    P <- diag(rep(1, n)) - X %*% solve(t(X) %*% V0inv %*% X) %*% t(X) %*% V0inv
    A <- t(P) %*% V0inv

    B <- matrix(0, length(tausq), length(tausq))
    C <- matrix(0, length(tausq), n)
    tyAy <- as.numeric(t(y) %*% A %*% y)
    for (j in 1:nlevels(dvrFactor)) {
        Zj <- Z[, dvrFactor == levels(dvrFactor)[j]]
        AZjtZjA <- A %*% Zj %*% t(Zj) %*% A
        tyAZjtZjAy <- as.numeric(t(y) %*% AZjtZjA %*% y)
        C[j, ] <- 2 * (tyAy * t(y) %*% AZjtZjA - tyAZjtZjAy * t(y) %*% A)
        for (k in j:nlevels(dvrFactor)) {
            Zk <- Z[, dvrFactor == levels(dvrFactor)[k]]
            AZktZkA <- A %*% Zk %*% t(Zk) %*% A
            tyAZktZkAy <- as.numeric(t(y) %*% AZktZkA %*% y)
            if(method == "ML") {
                B[j, k] <- B[k, j] <- -tyAy ^ 2 * tr((t(Zk) %*% V0inv
%*% Zj) %*% (t(Zj) %*% V0inv %*% Zk)) / n - tyAZjtZjAy * tyAZktZkAy +
2 * tyAZktZkAy * tyAy
            } else {
                B[j, k] <- B[k, j] <- -tyAy ^ 2 * tr((t(Zk) %*% A %*%
Zj) %*% (t(Zj) %*% A %*% Zk)) / (n - ncol(X)) - tyAZjtZjAy *
tyAZktZkAy + 2 * tyAZktZkAy * tyAy
            }
        }
    }
    Binv <- solve(B)

    rho <- n - tr(A)
    Phi0 <- rho + sum(sapply(levels(dvrFactor), function(j) {
        Zj <- Z[, dvrFactor == j]
        sum(Binv %*% C %*% A %*% Zj %*% t(Zj) %*% A %*% y)
    }))

    ll <- sum(dnorm(y - fitted(m), 0, sqrt(sigmasq), log = TRUE))
    caic <- -2 * ll + 2 * (rho + 1)
    ccaic <- -2 * ll + 2 * (Phi0 + 1)

    list(cAIC = caic, ccAIC = ccaic, cLogLik = ll, rho = rho, Phi0 = Phi0)
}


From rossahmed at googlemail.com  Sat Mar 16 18:51:43 2013
From: rossahmed at googlemail.com (Ross Ahmed)
Date: Sat, 16 Mar 2013 17:51:43 +0000
Subject: [R-sig-ME] Is a mixed effects appropriate?
Message-ID: <CD6A61AF.41E6%rossahmed@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130316/bde7c307/attachment.pl>

From bbolker at gmail.com  Sat Mar 16 19:02:36 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 16 Mar 2013 18:02:36 +0000 (UTC)
Subject: [R-sig-ME] cAIC
References: <CAPQ=hVJts=tELGnFFHTV08ORRNFYG=Wt7jyr4mK3CLkFEb_nNw@mail.gmail.com>
Message-ID: <loom.20130316T185159-10@post.gmane.org>

Oliver Soong <osoong+r at ...> writes:

> 
> Hi,
> 
> I'm using a linear mixed effects model on estimates of plant cover in
> different years in plots situated along transects within different
> zones.  The full set of random effects is (1 | year) + (1 |
> zone/transect/plot), where each term is treated categorically.  I'm
> interested in determining whether the plot-level random effect is
> worth including in the model, and of course, that's where the trouble
> begins.
> 
> I'm thinking in terms of AIC.  Of course, the problem with AIC is
> determining the d.f. of random effects.  As I've read a number of
> times, the appropriate d.f. lies somewhere between 1 and the number of
> random effect groups/clusters, depending on the random effect variance
> lying somewhere in (0,Inf).
> 
> In my naive view of things, then, the true AIC lies somewhere between
> AIC1 based on 1 d.f. per random effect and AICn based on the number of
> random effect groups.  Dangerously pursuing this naive train of
> thought, given two nested models in which the additional random
> effects is itself nested (e.g., zone/transect vs. zone/transect/plot),
> there is some d.f. per random effect at which the AIC differ by 2.

 [snip]

> I looked into Vaida & Blanchard (2005) and Greven & Kneib (2010).  I
> won't pretend to understand everything they're doing, but I did dig up
> the code used by G&K.  I think I managed to adapt it to work with lme4
> in addition to nlme (through RLRsim) ... [snip]

> At the presumption of trying to use this code, I noticed something
> surprising.  I'm comparing my zone/transect model against my
> zone/transect/plot model.  The difference in log-likelihood is ~0.2.
> Even using AIC1, I would conclude that adding the plot-level random
> effects does not significantly improve the model fit, although I can
> only claim that the simpler model with only the transect-level random
> effect is significantly better if the plot-level random effect
> represents at least ~1.1 degree of freedom.  cAIC favors the model
> with plot-level random effects (the difference in cAIC is ~1.5), which
> is the bias G&K address.  However, their ccAIC also favors the model
> with plot-level random effects, and the difference in ccAIC is even
> larger (~4.8).  

[snip]

> I have 1863 observations and 21 fixed effects (including intercept).
> Except for the additional plot-level random effect, the two fitted
> fitted models are essentially identical (differences in coefficients
> for terms shared between the zone/transect and zone/transect/plot
> models are less than 1% of the corresponding estimated variances).
> I'm using R 2.15.2 and lme4 0.999999.0.

  I'm not going to review the code (sorry), although it seems
potentially very useful.  I have one general comment and one code
comment.

  General comment: the log-likelihood that you're comparing is the
marginal log-likelihood (i.e. the likelihood at the whole population
level), where as [c]cAIC is trying to assess the predictive accuracy
at the plot-level, so it may sometimes surprise you by choosing what
seem to be overly complex models ... this is closely related to the
issue of "level of focus" that's frequently discussed in the context
of DIC (the deviance information criterion, for multilevel Bayesian
models).

  Code comment: I think you can get a lot of what you need
directly from lme4 via the getME() function: getME(m,"X"),
getME(m,"Z"), getME(m,"y"), lme4::sigma(m)^2; you can get
the random-effects variance with VarCorr(m) ... of course, the
RLRsim approach does let you handle nlme and lme4 together more
easily ...

  Ben Bolker

 [code snipped to make gmane happy -- sorry]


From bbolker at gmail.com  Sat Mar 16 19:08:25 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 16 Mar 2013 18:08:25 +0000 (UTC)
Subject: [R-sig-ME] Is a mixed effects appropriate?
References: <CD6A61AF.41E6%rossahmed@gmail.com>
Message-ID: <loom.20130316T190527-250@post.gmane.org>

Ross Ahmed <rossahmed at ...> writes:

> 
> I am looking at differences in dates of maximum counts of geese at 3 sites
> in the UK. I am testing to see if the date of maximum count is different
> between 3 sites.
> 
> My data look like these created in R:
> 
>   df <- data.frame(day=c(sample(70:80, 10), sample(75:85, 10), sample(80:90,
> 10)),
>                    year=rep(2000:2009, 3),
>                    site=paste('site', sort(rep(1:3, 10))))
> 
> Head of dataframe:
> 
>   day year   site
> 1  78 2000 site 1
> 2  76 2001 site 1
> 3  71 2002 site 1
> 4  73 2003 site 1
> 5  75 2004 site 1
> 6  74 2005 site 1
> 
> The variable 'day' is the day number on which the maximum count of geese was
> recorded in that year. So in rows 1, the the maximum count was recorded 78
> days from the 1st Jan in that year.
> 
> I considered carrying out a simple ANOVA with day as response variable and
> site as predictor variable. However I've become aware that this would
> violate the assumption of independence. Is there a mixed effects model that
> is able to handle the dependence of the data? Alternatively, would some sort
> of time series analysis be more appropriate here?
> 

 I would say that 

anova(lme(day~site, random=~1|year,data=df))

would be a reasonable model, allowing for random variation among years.

I do think it would make sense to look for trends across time

anova(lme(day~site*year, random=~1|year,data=df))

  (there is a fixed effect and a random effect of year in this
model, but it should be OK because the random effect treats year
as a categorical variable ... as long as the fixed effect is
a numeric (continuous) variable)

You should definitely make sure to look at graphical representations
of the data! But obviously your made-up data set doesn't
have anything to see in it ...


From bbolker at gmail.com  Sat Mar 16 20:48:46 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 16 Mar 2013 19:48:46 +0000 (UTC)
Subject: [R-sig-ME] optimizers for mixed models
References: <51411F35.6070808@biostat.ucsf.edu>
	<loom.20130314T150520-774@post.gmane.org>
	<51420F19.9020205@biostat.ucsf.edu>
	<51421228.2080909@biostat.ucsf.edu>
Message-ID: <loom.20130316T204142-287@post.gmane.org>

Ross Boylan <ross at ...> writes:

> 
> On 3/14/2013 10:55 AM, Ross Boylan wrote:
> > Optimization was originally via a custom optimizer using rho.  The 
> > custom optimizer did not incorporate bounds, and blew up when it got 
> > rho outside of [-1, 1].  So we switched to atanh(rho) as the target of 
> > optimization.  However, for some simulated datasets that failed to 
> > converge, as atanh(rho) marched slowly off toward infinity.  We 
> > switched to optim with bounds to cut that process off.
> >
> > So perhaps we should go back to rho, but using optim or the other 
> > bounded optimizers you suggested.
> >
> > So the fact that atanh(rho) is unbounded is a feature from some 
> > perspectives, but a bug from others. 
> I forgot to mention that we actually have analytic second (and first) 
> derivatives.  Switching to optim from the packages internal optimizer 
> meant we're no longer using the analytic 2nd derivative.

  Which package?

 A couple more points:

 * I don't know offhand which optimizing tools in R (1) allow for
box constraints and (2) can take both a user-specified gradient
and a user-specified hessian (there are several that take user-specified
gradients); I think there may be some in optreplace/optimx, but I'm not
sure.

 * according to Dave Fournier, AD Model Builder actually can do GH
quadrature with multiple terms per random effect (the documentation
is wrong/out of date), so you might look into that ...  (as I recall
this is a single RE with multiple terms, not crossed RE -- right?)

  Ben


From kalakouentin at gmail.com  Sat Mar 16 21:48:18 2013
From: kalakouentin at gmail.com (Pantelis Hadjipantelis)
Date: Sat, 16 Mar 2013 20:48:18 +0000
Subject: [R-sig-ME] optimizers for mixed models
In-Reply-To: <CAH2DVQHz3c_OmxxjZH-a7+n6JzcFuQcSuUd7wuo4-rpzDEaQJA@mail.gmail.com>
References: <51411F35.6070808@biostat.ucsf.edu>
	<loom.20130314T150520-774@post.gmane.org>
	<51420F19.9020205@biostat.ucsf.edu>
	<51421228.2080909@biostat.ucsf.edu>
	<loom.20130316T204142-287@post.gmane.org>
	<CAH2DVQHz3c_OmxxjZH-a7+n6JzcFuQcSuUd7wuo4-rpzDEaQJA@mail.gmail.com>
Message-ID: <CAH2DVQFYVt2xikEMaFHCEwY9+9YV+CXWb-AENhbJnO0+GwDyKQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130316/df49980c/attachment.pl>

From kalakouentin at gmail.com  Sat Mar 16 21:59:56 2013
From: kalakouentin at gmail.com (Pantelis Hadjipantelis)
Date: Sat, 16 Mar 2013 20:59:56 +0000
Subject: [R-sig-ME] Evaluating Z matrix
In-Reply-To: <loom.20130316T021120-651@post.gmane.org>
References: <CAH2DVQGaFAv0YTGqJsWmsfJ8MHd759_Fr-nZExv8CwCGxW2rNw@mail.gmail.com>
	<loom.20130316T021120-651@post.gmane.org>
Message-ID: <CAH2DVQH62YanjDqWx8uF1b-CSnyvJX00cOvEUWumR_sW4K1y4Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130316/4c386c75/attachment.pl>

From fvargas.reeve at gmail.com  Sat Mar 16 00:27:07 2013
From: fvargas.reeve at gmail.com (Felipe Vargas Reeve)
Date: Fri, 15 Mar 2013 20:27:07 -0300
Subject: [R-sig-ME] Breeding Values of Parentals (pedigreemm)
Message-ID: <CABFQCKmnLteoBpS2GS+MUir6s5jivSQC1dMsM3wuRajNghATag@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130315/9b24e46a/attachment.pl>

From David.Duffy at qimr.edu.au  Sun Mar 17 06:49:05 2013
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Sun, 17 Mar 2013 15:49:05 +1000
Subject: [R-sig-ME] Breeding Values of Parentals (pedigreemm)
In-Reply-To: <CABFQCKmnLteoBpS2GS+MUir6s5jivSQC1dMsM3wuRajNghATag@mail.gmail.com>
References: <CABFQCKmnLteoBpS2GS+MUir6s5jivSQC1dMsM3wuRajNghATag@mail.gmail.com>
Message-ID: <alpine.LMD.2.00.1303171542500.16733@orpheus.qimr.edu.au>

On Sat, 16 Mar 2013, Felipe Vargas Reeve wrote:

> The results that the process give me is perfect, also the pedigreemm
> complement works very well but I couldn't obtain the genetic values of the
> parentals. Only I could obtain the genetic values of the progeny.

Are you fitting a LMM or GLMM?  If the former, then you can use the 
usual matrix formula - eg implemented in packages pedigree and rrBLUP.

| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v


From mslain at utu.fi  Sun Mar 17 11:58:45 2013
From: mslain at utu.fi (Mari Laine)
Date: Sun, 17 Mar 2013 10:58:45 +0000
Subject: [R-sig-ME] Model selection in GAMM
Message-ID: <3C72E5613CEAC64D9CBCF9CB60442D6C3AB0FFDE@exch-mbx-01.utu.fi>

Hi!

I'm using GAMM (mgcv::gamm) to fit non-Gaussian models with several fixed factors and also a temporal structure. Additionally, I'm fitting non-linearity with smoothers. I have several correlated main effect candidates, and I would like to compare their GAMMs and see, which one of the models best fits the data. I would also need to tune the models via dropping unnecessary smoothers (linear ones) and non-significant fixed variables.

After going through some statistical books, I'm under the impression that one should not use AIC comparison of $lme's for GAMM models - is this correct? Could someone give instruction on the model selection in GAMM or refer me to a book / some other source of information on this matter?

Thanks,

   Mari Laine

From bbolker at gmail.com  Sun Mar 17 20:44:28 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 17 Mar 2013 19:44:28 +0000 (UTC)
Subject: [R-sig-ME] Model selection in GAMM
References: <3C72E5613CEAC64D9CBCF9CB60442D6C3AB0FFDE@exch-mbx-01.utu.fi>
Message-ID: <loom.20130317T203811-130@post.gmane.org>

Mari Laine <mslain at ...> writes:


> I'm using GAMM (mgcv::gamm) to fit non-Gaussian models with several
> fixed factors and also a temporal structure. Additionally, I'm
> fitting non-linearity with smoothers. I have several correlated main
> effect candidates, and I would like to compare their GAMMs and see,
> which one of the models best fits the data. I would also need to
> tune the models via dropping unnecessary smoothers (linear ones) and
> non-significant fixed variables.
 
> After going through some statistical books, I'm under the impression
> that one should not use AIC comparison of $lme's for GAMM models -
> is this correct? Could someone give instruction on the model
> selection in GAMM or refer me to a book / some other source of
> information on this matter?

  To my knowledge there are two issues here:

(1) GAMM uses penalized quasi-likelihood.  According to some statisticians
(including Brian Ripley, who wrote the original PQL code in 
MASS::glmmPQL, which might be what GAMM relies on -- I don't remember,
it might incorporate its own PQL code), one shouldn't use likelihood-based
approaches (including AIC) with PQL algorithms, because they don't
estimate a true likelihood (others say it's OK as long as you
make sure to scale the likelihood to get a quasi-likelihood before
combining it with the penalty term to get a QIC).

(2) As I recall it's a little tricky to figure out which components
of a GAMM call contain which kinds of information about the fit.
In particular it's not clear whether the likelihood/AIC reported
in the lme component of the fit really reflect an appropriate
(quasi)likelihood/IC of the full model; I believe there's a lot
of detail on this in the ?gamm help page: in particular,

> For example,
> unlike ?glmmPQL? from ?MASS? it will return the complete ?lme?
> object from the working model at convergence of the PQL iteration,
> including the `log likelihood', even though this is not the
> likelihood of the fitted GAMM.

which suggests you shouldn't use that log-likelihood ...

  I would look for further information in Simon Wood's excellent book on 
generalized additive models.


From A.Robinson at ms.unimelb.edu.au  Sun Mar 17 21:47:53 2013
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Mon, 18 Mar 2013 07:47:53 +1100
Subject: [R-sig-ME] Model selection in GAMM
In-Reply-To: <loom.20130317T203811-130@post.gmane.org>
References: <3C72E5613CEAC64D9CBCF9CB60442D6C3AB0FFDE@exch-mbx-01.utu.fi>
	<loom.20130317T203811-130@post.gmane.org>
Message-ID: <20130317204753.GH18302@ms.unimelb.edu.au>

On Sun, Mar 17, 2013 at 07:44:28PM +0000, Ben Bolker wrote:
> Mari Laine <mslain at ...> writes:
> 
> 
> > I'm using GAMM (mgcv::gamm) to fit non-Gaussian models with several
> > fixed factors and also a temporal structure. Additionally, I'm
> > fitting non-linearity with smoothers. I have several correlated main
> > effect candidates, and I would like to compare their GAMMs and see,
> > which one of the models best fits the data. I would also need to
> > tune the models via dropping unnecessary smoothers (linear ones) and
> > non-significant fixed variables.
>  
> > After going through some statistical books, I'm under the impression
> > that one should not use AIC comparison of $lme's for GAMM models -
> > is this correct? Could someone give instruction on the model
> > selection in GAMM or refer me to a book / some other source of
> > information on this matter?
> 
>   To my knowledge there are two issues here:
> 
> (1) GAMM uses penalized quasi-likelihood.  According to some
> statisticians (including Brian Ripley, who wrote the original PQL
> code in MASS::glmmPQL, which might be what GAMM relies on -- I don't
> remember, it might incorporate its own PQL code), one shouldn't use
> likelihood-based approaches (including AIC) with PQL algorithms,
> because they don't estimate a true likelihood (others say it's OK as
> long as you make sure to scale the likelihood to get a
> quasi-likelihood before combining it with the penalty term to get a
> QIC).

Hi Ben,

I know that you're reporting third-party opinions, and you're not
necessarily advocating this position yourself, but I wonder if you can
provide some more information - even a link or a citation to them?

I'm a bit confused about how scaling the maximized penalized
likelihood (MPL) can deliver something that can be treated as though
it were a maximized likelihood.

To my way of thinking, a point of maximizing the penalized likelihood
is that you get an estimate with better statistical properties than
the MLE.  

It is overwhelmingly likely that this MPL estimate will be different
from the MLE.  It's hard for me to imagine a way that the PL function
can be scaled so that the MPLE can be treated as though it were an
MLE.  If the MPLE won't be the same as the MLE, then the L can't be
maximized at the MPLE.  Further, the PL function will be a different
shape at the optimum (I intuit) than the L would be at its optimum.  

So, is there theory to suggest that the properties of the MLE that are
relied upon by the various measures of information are retained by the
MPLE?  And if so, even then, wouldn't those properties depend on the
nature of the penalization?

Best wishes

Andrew

> (2) As I recall it's a little tricky to figure out which components
> of a GAMM call contain which kinds of information about the fit.
> In particular it's not clear whether the likelihood/AIC reported
> in the lme component of the fit really reflect an appropriate
> (quasi)likelihood/IC of the full model; I believe there's a lot
> of detail on this in the ?gamm help page: in particular,
> 
> > For example,
> > unlike ?glmmPQL? from ?MASS? it will return the complete ?lme?
> > object from the working model at convergence of the PQL iteration,
> > including the `log likelihood', even though this is not the
> > likelihood of the fitted GAMM.
> 
> which suggests you shouldn't use that log-likelihood ...
> 
>   I would look for further information in Simon Wood's excellent book on 
> generalized additive models.
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Andrew Robinson  
Director (A/g), ACERA 
Department of Mathematics and Statistics            Tel: +61-3-8344-6410
University of Melbourne, VIC 3010 Australia               (prefer email)
http://www.ms.unimelb.edu.au/~andrewpr              Fax: +61-3-8344-4599
http://www.acera.unimelb.edu.au/

Forest Analytics with R (Springer, 2011) 
http://www.ms.unimelb.edu.au/FAwR/
Introduction to Scientific Programming and Simulation using R (CRC, 2009): 
http://www.ms.unimelb.edu.au/spuRs/


From bbolker at gmail.com  Mon Mar 18 14:29:30 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 18 Mar 2013 13:29:30 +0000 (UTC)
Subject: [R-sig-ME] Model selection in GAMM
References: <3C72E5613CEAC64D9CBCF9CB60442D6C3AB0FFDE@exch-mbx-01.utu.fi>
	<loom.20130317T203811-130@post.gmane.org>
	<20130317204753.GH18302@ms.unimelb.edu.au>
Message-ID: <loom.20130318T141400-390@post.gmane.org>

Andrew Robinson <A.Robinson at ...> writes:

> 
> On Sun, Mar 17, 2013 at 07:44:28PM +0000, Ben Bolker wrote:
> > Mari Laine <mslain at ...> writes:
> > 
> > 
> > > I'm using GAMM (mgcv::gamm) to fit non-Gaussian models with several
> > > fixed factors and also a temporal structure. Additionally, I'm
> > > fitting non-linearity with smoothers. I have several correlated main
> > > effect candidates, and I would like to compare their GAMMs and see,
> > > which one of the models best fits the data. I would also need to
> > > tune the models via dropping unnecessary smoothers (linear ones) and
> > > non-significant fixed variables.
> >  
> > > After going through some statistical books, I'm under the impression
> > > that one should not use AIC comparison of $lme's for GAMM models -
> > > is this correct? Could someone give instruction on the model
> > > selection in GAMM or refer me to a book / some other source of
> > > information on this matter?
> > 
> >   To my knowledge there are two issues here:
> > 
> > (1) GAMM uses penalized quasi-likelihood.  According to some
> > statisticians (including Brian Ripley, who wrote the original PQL
> > code in MASS::glmmPQL, which might be what GAMM relies on -- I don't
> > remember, it might incorporate its own PQL code), one shouldn't use
> > likelihood-based approaches (including AIC) with PQL algorithms,
> > because they don't estimate a true likelihood (others say it's OK as
> > long as you make sure to scale the likelihood to get a
> > quasi-likelihood before combining it with the penalty term to get a
> > QIC).
> 
> Hi Ben,
> 
> I know that you're reporting third-party opinions, and you're not
> necessarily advocating this position yourself, but I wonder if you can
> provide some more information - even a link or a citation to them?

  Hmm.  I may be in over my head here, so *please* treat anything
I say below as false until proven true ...

> 
> I'm a bit confused about how scaling the maximized penalized
> likelihood (MPL) can deliver something that can be treated as though
> it were a maximized likelihood.
> 
> To my way of thinking, a point of maximizing the penalized likelihood
> is that you get an estimate with better statistical properties than
> the MLE.  

  It's been a long time since I looked at this, and I don't understand
it well enough, but it was my understanding that the quantity maximized
by PQL is an *approximation* to the marginal likelihood used in all
other GLMM applications (i.e. the conditional likelihood of the data
given fixed values of the random effects, weighted by the probability
of those RE values given the distribution of the REs, integrated over
all possible values of the REs) -- one that is less accurate than
Laplace approximation and Gauss-Hermite quadrature, but an approximation
to the same quantity nevertheless.

  So I thought the idea was not (in this case) to get an estimate
with better properties than the MLE, but to get an estimate of the
marginal likelihood at all ...

> It is overwhelmingly likely that this MPL estimate will be different
> from the MLE.  It's hard for me to imagine a way that the PL function
> can be scaled so that the MPLE can be treated as though it were an
> MLE.  If the MPLE won't be the same as the MLE, then the L can't be
> maximized at the MPLE.  Further, the PL function will be a different
> shape at the optimum (I intuit) than the L would be at its optimum.  

    For one quick practical counterexample, glmmPQL generally gives
_similar_ answers to glmer/glmmADMB etc. (i.e. methods based on
Laplace or better approximations) for large data sets and those
where the counts per individual sample are large ...
> 
> So, is there theory to suggest that the properties of the MLE that are
> relied upon by the various measures of information are retained by the
> MPLE?  And if so, even then, wouldn't those properties depend on the
> nature of the penalization?

   I would love to know the answer.  I hope someone more knowledgeable,
or with much more time to spend figuring this out, comes forward.

  Ben


> 
> > (2) As I recall it's a little tricky to figure out which components
> > of a GAMM call contain which kinds of information about the fit.
> > In particular it's not clear whether the likelihood/AIC reported
> > in the lme component of the fit really reflect an appropriate
> > (quasi)likelihood/IC of the full model; I believe there's a lot
> > of detail on this in the ?gamm help page: in particular,
> > 
> > > For example,
> > > unlike ?glmmPQL? from ?MASS? it will return the complete ?lme?
> > > object from the working model at convergence of the PQL iteration,
> > > including the `log likelihood', even though this is not the
> > > likelihood of the fitted GAMM.
> > 
> > which suggests you shouldn't use that log-likelihood ...
> > 
> >   I would look for further information in Simon Wood's excellent book on 
> > generalized additive models.
> > 
> > _______________________________________________
> > R-sig-mixed-models <at> r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From bbolker at gmail.com  Mon Mar 18 15:12:47 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 18 Mar 2013 14:12:47 +0000 (UTC)
Subject: [R-sig-ME] Error :
References: <CA+PUQOuSg6Wk16=zh2Z-0B05tg5M6kBmmm+USC=2REVDRcEXRw@mail.gmail.com>
Message-ID: <loom.20130318T143218-390@post.gmane.org>

shao chunxuan <sh.chunxuan at ...> writes:

> 
> Hi everyone,
> 
> I am applying  generalized linear mixed model to RNA-seq data under
> quasi-poisson distribution. Here is the an example:

  Please don't call the observation-level random effect approach
a "quasi-Poisson distribution" -- it's kind of confusing with
quasilikelihood.  If you want a technical term, I would say
"observation-level random effects", or possibly a "logit-normal
binomial model" ...

> > ts.da
>    value tp tpf  treat cellline obs_effect
> 1     73  6  T6   ETOH        A          1
> 2     54  6  T6   ETOH        B          2
> 3     62 12 T12   ETOH        A          3
> 4     54 12 T12   ETOH        B          4
> 5     54 24 T24   ETOH        A          5
> 6     56 24 T24   ETOH        B          6
> 7     31 48 T48   ETOH        A          7
> 8     82 48 T48   ETOH        B          8
> 9     72  6  T6 shMYCN        C          9
> 10    95  6  T6 shMYCN        D         10
> 11    64 12 T12 shMYCN        C         11
> 12    90 12 T12 shMYCN        D         12
> 13    51 24 T24 shMYCN        C         13
> 14    64 24 T24 shMYCN        D         14
> 15    46 48 T48 shMYCN        C         15
> 16    63 48 T48 shMYCN        D         16
> 
> > str(ts.da)
> 'data.frame': 16 obs. of  6 variables:
>  $ value     : num  73 54 62 54 54 56 31 82 72 95 ...
>  $ tp        : num  6 6 12 12 24 24 48 48 6 6 ...
>  $ tpf       : Factor w/ 4 levels "T6","T12","T24",..: 1 1 2 2 3 3 4 4 1 1
> ...
>  $ treat     : Factor w/ 2 levels "ETOH","shMYCN": 1 1 1 1 1 1 1 1 2 2 ...
>  $ cellline  : Factor w/ 4 levels "A","B","C","D": 1 2 1 2 1 2 1 2 3 4 ...
>  $ obs_effect: int  1 2 3 4 5 6 7 8 9 10 ...
> 
> The specified model worked fine:
> possionmix.full <- lmer(value ~ tpf * treat + (1|cellline) +(1|obs_effect)
> ,data=ts.da, family=poisson)

  (It's a little confusing that this is misspelled -- poissonmix.full
would be a more sensible)

> > possionmix.full
> Generalized linear mixed model fit by the Laplace approximation
> Formula: value ~ tpf * treat + (1 | cellline) + (1 | obs_effect)
>    Data: ts.da
>    AIC   BIC logLik deviance
>  50.72 58.45 -15.36    30.72
> Random effects:
>  Groups     Name        Variance  Std.Dev.
>  obs_effect (Intercept) 0.0185506 0.136201
>  cellline   (Intercept) 0.0041093 0.064104
> Number of obs: 16, groups: obs_effect, 16; cellline, 4
> 

 [snip]
 
> Then I tried to to post-hoc analysis with "phia":
> > testInteractions(possionmix.full)
> Error in `contrasts<-`(`*tmp*`, value = "contr.treatment") : contrasts
> apply only to factors
> 
> I am pretty sure that tpf and treat are factors:
> 
> > ts.da$tpf
>  [1] T6  T6  T12 T12 T24 T24 T48 T48 T6  T6  T12 T12 T24 T24 T48 T48
> Levels: T6 T12 T24 T48
> 
> > ts.da$treat
>  [1] ETOH   ETOH   ETOH   ETOH   ETOH   ETOH   ETOH   ETOH   shMYCN shMYCN
> [11] shMYCN shMYCN shMYCN shMYCN shMYCN shMYCN
> Levels: ETOH shMYCN
> 
> In the note of "testInteractions", it says "The tests of mixed models are
> done under the assumption that the
> estimation of the random part of the model is exact",  the model is fitted
> by "Laplace approximation".
> Could this be the problem? How to force the mixed model to use "REML" in
> generalized linear mixed model ?

  glmer won't let you use REML ... you could follow Dave Fournier's
suggestions (see also http://glmm.wikidot.com/faq) about how to use
REML with GLMMs.

  I don't actually know what phia's author means by "the tests
of the mixed models are done ..." -- it may mean that the tests
are done conditional on the random effects conditional modes,
i.e. assuming that we know the values of each random effect
exactly (which isn't something you could fix by changing estimation
approaches).

  I did manage to replicate your error message, but I didn't
manage to debug it yet.


From fvargas.reeve at gmail.com  Mon Mar 18 17:05:08 2013
From: fvargas.reeve at gmail.com (Felipe Vargas Reeve)
Date: Mon, 18 Mar 2013 13:05:08 -0300
Subject: [R-sig-ME] Breeding Values of Parentals (pedigreemm)
In-Reply-To: <alpine.LMD.2.00.1303171542500.16733@orpheus.qimr.edu.au>
References: <CABFQCKmnLteoBpS2GS+MUir6s5jivSQC1dMsM3wuRajNghATag@mail.gmail.com>
	<alpine.LMD.2.00.1303171542500.16733@orpheus.qimr.edu.au>
Message-ID: <CABFQCKmvThg_tn5RnXV-pBLwb2Or4r6fpQT5_y+ws780MkiQpg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130318/023428c0/attachment.pl>

From GodinA at Dal.Ca  Mon Mar 18 17:50:40 2013
From: GodinA at Dal.Ca (Aurelie Cosandey Godin)
Date: Mon, 18 Mar 2013 13:50:40 -0300
Subject: [R-sig-ME] semicontinuous variables: what likelihoods are available?
Message-ID: <4AA39F79-84C9-4A35-8EF2-5176A9A1F1A1@Dal.Ca>

Dear list,

I need to run spatio-temporal models for a semicontinuous response variable (weight in kg). 
I am not familiar with the available semicontinuous likelihood functions available in R and was wondering if some of you may be able to point me in the right direction for information.

Many thanks in advance!
Aurelie


From bbolker at gmail.com  Mon Mar 18 20:30:45 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 18 Mar 2013 19:30:45 +0000 (UTC)
Subject: [R-sig-ME] semicontinuous variables: what likelihoods are
	available?
References: <4AA39F79-84C9-4A35-8EF2-5176A9A1F1A1@Dal.Ca>
Message-ID: <loom.20130318T200115-984@post.gmane.org>

Aurelie Cosandey Godin <GodinA at ...> writes:


[snip]

> I need to run spatio-temporal models for a semicontinuous response
> variable (weight in kg).  I am not familiar with the available
> semicontinuous likelihood functions available in R and was wondering
> if some of you may be able to point me in the right direction for
> information.


Can you say any more about exactly what a semicontinuous response variable
is?  Poking around (e.g <http://lpsolve.sourceforge.net/4.0/semi-cont.htm>)
doesn't make it entirely clear: are these data that are

truncated, i.e. values <= a lower threshold are absent from the data set;
censored, i.e. values <= a lower threshold are recorded as 
   "less than threshold"?
positive, i.e. values <0 don't even exist?
are the data non-negative (i.e. >=0) or are they positive (>0)?

  The simplest of these cases is positive data, which you
can model fairly easily by log transformation (i.e. assume
a lognormal distribution), or with slightly more difficulty
using a Gamma distribution ...  if you have censored or truncated
data, or data that include zeros, it gets a little harder ...


From GodinA at dal.ca  Mon Mar 18 21:25:23 2013
From: GodinA at dal.ca (Aurelie Cosandey Godin)
Date: Mon, 18 Mar 2013 17:25:23 -0300
Subject: [R-sig-ME] semicontinuous variables: what likelihoods are
	available?
In-Reply-To: <loom.20130318T200115-984@post.gmane.org>
References: <4AA39F79-84C9-4A35-8EF2-5176A9A1F1A1@Dal.Ca>
	<loom.20130318T200115-984@post.gmane.org>
Message-ID: <6C2212B9-FD5C-4D0A-955B-CCEDE36BFA6B@Dal.Ca>

Thank you Ben and others,

Apologize for not being very precise!
My response variable is measured both in weight (kg) and counts and is very zero-inflated i.e., 91% of my data.
I previously ran models on the count data using a suit of  likelihoods: 2-parts zero inflated poisson & 2-parts zero inflated negative binomial. The latter were the best.
Now I would like to run the same models but with my response variable in kg, but I don't know how to model my positive (truncated or just positive weight data?). See  figure attached of the distribution of my weight data.

Many thanks in advance!!
Aurelie






On 2013-03-18, at 4:30 PM, Ben Bolker wrote:

> Aurelie Cosandey Godin <GodinA at ...> writes:
> 
> 
> [snip]
> 
>> I need to run spatio-temporal models for a semicontinuous response
>> variable (weight in kg).  I am not familiar with the available
>> semicontinuous likelihood functions available in R and was wondering
>> if some of you may be able to point me in the right direction for
>> information.
> 
> 
> Can you say any more about exactly what a semicontinuous response variable
> is?  Poking around (e.g <http://lpsolve.sourceforge.net/4.0/semi-cont.htm>)
> doesn't make it entirely clear: are these data that are
> 
> truncated, i.e. values <= a lower threshold are absent from the data set;
> censored, i.e. values <= a lower threshold are recorded as 
>   "less than threshold"?
> positive, i.e. values <0 don't even exist?
> are the data non-negative (i.e. >=0) or are they positive (>0)?
> 
>  The simplest of these cases is positive data, which you
> can model fairly easily by log transformation (i.e. assume
> a lognormal distribution), or with slightly more difficulty
> using a Gamma distribution ...  if you have censored or truncated
> data, or data that include zeros, it gets a little harder ...
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 


From jwiley.psych at gmail.com  Tue Mar 19 00:46:09 2013
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Mon, 18 Mar 2013 16:46:09 -0700
Subject: [R-sig-ME] Model selection in GAMM
In-Reply-To: <loom.20130318T141400-390@post.gmane.org>
References: <3C72E5613CEAC64D9CBCF9CB60442D6C3AB0FFDE@exch-mbx-01.utu.fi>
	<loom.20130317T203811-130@post.gmane.org>
	<20130317204753.GH18302@ms.unimelb.edu.au>
	<loom.20130318T141400-390@post.gmane.org>
Message-ID: <CANz9Z_K7axOzLRMtWXPVps=5AFPSXF6QoNi_3uEE3uEJfQjpVA@mail.gmail.com>

A bit off from the other topics, but back to the original, if you use
gamm4, it uses lme4 (lmer/glmer) for the mixed model.  One implication
is that you can get true likelihoods using the Laplace approximation
or numerical integration.  So at least for comparing models with
different parametric effects, it would seem you could use that
approach.  I am uncertain for the overall model, because you get both
a gam and mer object.

On Mon, Mar 18, 2013 at 6:29 AM, Ben Bolker <bbolker at gmail.com> wrote:
> Andrew Robinson <A.Robinson at ...> writes:
>
>>
>> On Sun, Mar 17, 2013 at 07:44:28PM +0000, Ben Bolker wrote:
>> > Mari Laine <mslain at ...> writes:
>> >
>> >
>> > > I'm using GAMM (mgcv::gamm) to fit non-Gaussian models with several
>> > > fixed factors and also a temporal structure. Additionally, I'm
>> > > fitting non-linearity with smoothers. I have several correlated main
>> > > effect candidates, and I would like to compare their GAMMs and see,
>> > > which one of the models best fits the data. I would also need to
>> > > tune the models via dropping unnecessary smoothers (linear ones) and
>> > > non-significant fixed variables.
>> >
>> > > After going through some statistical books, I'm under the impression
>> > > that one should not use AIC comparison of $lme's for GAMM models -
>> > > is this correct? Could someone give instruction on the model
>> > > selection in GAMM or refer me to a book / some other source of
>> > > information on this matter?
>> >
>> >   To my knowledge there are two issues here:
>> >
>> > (1) GAMM uses penalized quasi-likelihood.  According to some
>> > statisticians (including Brian Ripley, who wrote the original PQL
>> > code in MASS::glmmPQL, which might be what GAMM relies on -- I don't
>> > remember, it might incorporate its own PQL code), one shouldn't use
>> > likelihood-based approaches (including AIC) with PQL algorithms,
>> > because they don't estimate a true likelihood (others say it's OK as
>> > long as you make sure to scale the likelihood to get a
>> > quasi-likelihood before combining it with the penalty term to get a
>> > QIC).
>>
>> Hi Ben,
>>
>> I know that you're reporting third-party opinions, and you're not
>> necessarily advocating this position yourself, but I wonder if you can
>> provide some more information - even a link or a citation to them?
>
>   Hmm.  I may be in over my head here, so *please* treat anything
> I say below as false until proven true ...
>
>>
>> I'm a bit confused about how scaling the maximized penalized
>> likelihood (MPL) can deliver something that can be treated as though
>> it were a maximized likelihood.
>>
>> To my way of thinking, a point of maximizing the penalized likelihood
>> is that you get an estimate with better statistical properties than
>> the MLE.
>
>   It's been a long time since I looked at this, and I don't understand
> it well enough, but it was my understanding that the quantity maximized
> by PQL is an *approximation* to the marginal likelihood used in all
> other GLMM applications (i.e. the conditional likelihood of the data
> given fixed values of the random effects, weighted by the probability
> of those RE values given the distribution of the REs, integrated over
> all possible values of the REs) -- one that is less accurate than
> Laplace approximation and Gauss-Hermite quadrature, but an approximation
> to the same quantity nevertheless.
>
>   So I thought the idea was not (in this case) to get an estimate
> with better properties than the MLE, but to get an estimate of the
> marginal likelihood at all ...
>
>> It is overwhelmingly likely that this MPL estimate will be different
>> from the MLE.  It's hard for me to imagine a way that the PL function
>> can be scaled so that the MPLE can be treated as though it were an
>> MLE.  If the MPLE won't be the same as the MLE, then the L can't be
>> maximized at the MPLE.  Further, the PL function will be a different
>> shape at the optimum (I intuit) than the L would be at its optimum.
>
>     For one quick practical counterexample, glmmPQL generally gives
> _similar_ answers to glmer/glmmADMB etc. (i.e. methods based on
> Laplace or better approximations) for large data sets and those
> where the counts per individual sample are large ...
>>
>> So, is there theory to suggest that the properties of the MLE that are
>> relied upon by the various measures of information are retained by the
>> MPLE?  And if so, even then, wouldn't those properties depend on the
>> nature of the penalization?
>
>    I would love to know the answer.  I hope someone more knowledgeable,
> or with much more time to spend figuring this out, comes forward.
>
>   Ben
>
>
>>
>> > (2) As I recall it's a little tricky to figure out which components
>> > of a GAMM call contain which kinds of information about the fit.
>> > In particular it's not clear whether the likelihood/AIC reported
>> > in the lme component of the fit really reflect an appropriate
>> > (quasi)likelihood/IC of the full model; I believe there's a lot
>> > of detail on this in the ?gamm help page: in particular,
>> >
>> > > For example,
>> > > unlike ?glmmPQL? from ?MASS? it will return the complete ?lme?
>> > > object from the working model at convergence of the PQL iteration,
>> > > including the `log likelihood', even though this is not the
>> > > likelihood of the fitted GAMM.
>> >
>> > which suggests you shouldn't use that log-likelihood ...
>> >
>> >   I would look for further information in Simon Wood's excellent book on
>> > generalized additive models.
>> >
>> > _______________________________________________
>> > R-sig-mixed-models <at> r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



--
Joshua Wiley
Ph.D. Student, Health Psychology
University of California, Los Angeles
http://joshuawiley.com/
Senior Analyst - Elkhart Group Ltd.
http://elkhartgroup.com


From jwiley.psych at gmail.com  Tue Mar 19 00:47:00 2013
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Mon, 18 Mar 2013 16:47:00 -0700
Subject: [R-sig-ME] Model selection in GAMM
In-Reply-To: <CANz9Z_K7axOzLRMtWXPVps=5AFPSXF6QoNi_3uEE3uEJfQjpVA@mail.gmail.com>
References: <3C72E5613CEAC64D9CBCF9CB60442D6C3AB0FFDE@exch-mbx-01.utu.fi>
	<loom.20130317T203811-130@post.gmane.org>
	<20130317204753.GH18302@ms.unimelb.edu.au>
	<loom.20130318T141400-390@post.gmane.org>
	<CANz9Z_K7axOzLRMtWXPVps=5AFPSXF6QoNi_3uEE3uEJfQjpVA@mail.gmail.com>
Message-ID: <CANz9Z_JWfp84PcuFZf19r6KEw+ohQH8YmNdD8xSnJ_bHQRgkHg@mail.gmail.com>

 Sorry, I missed the "temporal structures" bit from the OP.  Apologies
for the noise.

On Mon, Mar 18, 2013 at 4:46 PM, Joshua Wiley <jwiley.psych at gmail.com> wrote:
> A bit off from the other topics, but back to the original, if you use
> gamm4, it uses lme4 (lmer/glmer) for the mixed model.  One implication
> is that you can get true likelihoods using the Laplace approximation
> or numerical integration.  So at least for comparing models with
> different parametric effects, it would seem you could use that
> approach.  I am uncertain for the overall model, because you get both
> a gam and mer object.
>
> On Mon, Mar 18, 2013 at 6:29 AM, Ben Bolker <bbolker at gmail.com> wrote:
>> Andrew Robinson <A.Robinson at ...> writes:
>>
>>>
>>> On Sun, Mar 17, 2013 at 07:44:28PM +0000, Ben Bolker wrote:
>>> > Mari Laine <mslain at ...> writes:
>>> >
>>> >
>>> > > I'm using GAMM (mgcv::gamm) to fit non-Gaussian models with several
>>> > > fixed factors and also a temporal structure. Additionally, I'm
>>> > > fitting non-linearity with smoothers. I have several correlated main
>>> > > effect candidates, and I would like to compare their GAMMs and see,
>>> > > which one of the models best fits the data. I would also need to
>>> > > tune the models via dropping unnecessary smoothers (linear ones) and
>>> > > non-significant fixed variables.
>>> >
>>> > > After going through some statistical books, I'm under the impression
>>> > > that one should not use AIC comparison of $lme's for GAMM models -
>>> > > is this correct? Could someone give instruction on the model
>>> > > selection in GAMM or refer me to a book / some other source of
>>> > > information on this matter?
>>> >
>>> >   To my knowledge there are two issues here:
>>> >
>>> > (1) GAMM uses penalized quasi-likelihood.  According to some
>>> > statisticians (including Brian Ripley, who wrote the original PQL
>>> > code in MASS::glmmPQL, which might be what GAMM relies on -- I don't
>>> > remember, it might incorporate its own PQL code), one shouldn't use
>>> > likelihood-based approaches (including AIC) with PQL algorithms,
>>> > because they don't estimate a true likelihood (others say it's OK as
>>> > long as you make sure to scale the likelihood to get a
>>> > quasi-likelihood before combining it with the penalty term to get a
>>> > QIC).
>>>
>>> Hi Ben,
>>>
>>> I know that you're reporting third-party opinions, and you're not
>>> necessarily advocating this position yourself, but I wonder if you can
>>> provide some more information - even a link or a citation to them?
>>
>>   Hmm.  I may be in over my head here, so *please* treat anything
>> I say below as false until proven true ...
>>
>>>
>>> I'm a bit confused about how scaling the maximized penalized
>>> likelihood (MPL) can deliver something that can be treated as though
>>> it were a maximized likelihood.
>>>
>>> To my way of thinking, a point of maximizing the penalized likelihood
>>> is that you get an estimate with better statistical properties than
>>> the MLE.
>>
>>   It's been a long time since I looked at this, and I don't understand
>> it well enough, but it was my understanding that the quantity maximized
>> by PQL is an *approximation* to the marginal likelihood used in all
>> other GLMM applications (i.e. the conditional likelihood of the data
>> given fixed values of the random effects, weighted by the probability
>> of those RE values given the distribution of the REs, integrated over
>> all possible values of the REs) -- one that is less accurate than
>> Laplace approximation and Gauss-Hermite quadrature, but an approximation
>> to the same quantity nevertheless.
>>
>>   So I thought the idea was not (in this case) to get an estimate
>> with better properties than the MLE, but to get an estimate of the
>> marginal likelihood at all ...
>>
>>> It is overwhelmingly likely that this MPL estimate will be different
>>> from the MLE.  It's hard for me to imagine a way that the PL function
>>> can be scaled so that the MPLE can be treated as though it were an
>>> MLE.  If the MPLE won't be the same as the MLE, then the L can't be
>>> maximized at the MPLE.  Further, the PL function will be a different
>>> shape at the optimum (I intuit) than the L would be at its optimum.
>>
>>     For one quick practical counterexample, glmmPQL generally gives
>> _similar_ answers to glmer/glmmADMB etc. (i.e. methods based on
>> Laplace or better approximations) for large data sets and those
>> where the counts per individual sample are large ...
>>>
>>> So, is there theory to suggest that the properties of the MLE that are
>>> relied upon by the various measures of information are retained by the
>>> MPLE?  And if so, even then, wouldn't those properties depend on the
>>> nature of the penalization?
>>
>>    I would love to know the answer.  I hope someone more knowledgeable,
>> or with much more time to spend figuring this out, comes forward.
>>
>>   Ben
>>
>>
>>>
>>> > (2) As I recall it's a little tricky to figure out which components
>>> > of a GAMM call contain which kinds of information about the fit.
>>> > In particular it's not clear whether the likelihood/AIC reported
>>> > in the lme component of the fit really reflect an appropriate
>>> > (quasi)likelihood/IC of the full model; I believe there's a lot
>>> > of detail on this in the ?gamm help page: in particular,
>>> >
>>> > > For example,
>>> > > unlike ?glmmPQL? from ?MASS? it will return the complete ?lme?
>>> > > object from the working model at convergence of the PQL iteration,
>>> > > including the `log likelihood', even though this is not the
>>> > > likelihood of the fitted GAMM.
>>> >
>>> > which suggests you shouldn't use that log-likelihood ...
>>> >
>>> >   I would look for further information in Simon Wood's excellent book on
>>> > generalized additive models.
>>> >
>>> > _______________________________________________
>>> > R-sig-mixed-models <at> r-project.org mailing list
>>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>
> --
> Joshua Wiley
> Ph.D. Student, Health Psychology
> University of California, Los Angeles
> http://joshuawiley.com/
> Senior Analyst - Elkhart Group Ltd.
> http://elkhartgroup.com



--
Joshua Wiley
Ph.D. Student, Health Psychology
University of California, Los Angeles
http://joshuawiley.com/
Senior Analyst - Elkhart Group Ltd.
http://elkhartgroup.com


From pseudotelphusa at gmail.com  Tue Mar 19 01:00:55 2013
From: pseudotelphusa at gmail.com (George Wang)
Date: Mon, 18 Mar 2013 20:00:55 -0400
Subject: [R-sig-ME] semicontinuous variables: what likelihoods are
	available?
In-Reply-To: <6C2212B9-FD5C-4D0A-955B-CCEDE36BFA6B@Dal.Ca>
References: <4AA39F79-84C9-4A35-8EF2-5176A9A1F1A1@Dal.Ca>
	<loom.20130318T200115-984@post.gmane.org>
	<6C2212B9-FD5C-4D0A-955B-CCEDE36BFA6B@Dal.Ca>
Message-ID: <CAGNXmpMbmgtdvWythH6q_SssKtmBo5PfrUhzOCStnDs3PfRgVA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130318/d245d8c5/attachment.pl>

From ramos.grad.student at gmail.com  Tue Mar 19 04:04:07 2013
From: ramos.grad.student at gmail.com (Antonio P. Ramos)
Date: Mon, 18 Mar 2013 20:04:07 -0700
Subject: [R-sig-ME] predictions for MCMCglmm
Message-ID: <CAHawB9uJp2hh-ezB2c=iMC=UH1DJuhQfvOxwMETNrnZ2zO4OUg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130318/fca5eb30/attachment.pl>

From j.hadfield at ed.ac.uk  Tue Mar 19 10:27:26 2013
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Tue, 19 Mar 2013 09:27:26 +0000
Subject: [R-sig-ME] predictions for MCMCglmm
In-Reply-To: <CAHawB9uJp2hh-ezB2c=iMC=UH1DJuhQfvOxwMETNrnZ2zO4OUg@mail.gmail.com>
References: <CAHawB9uJp2hh-ezB2c=iMC=UH1DJuhQfvOxwMETNrnZ2zO4OUg@mail.gmail.com>
Message-ID: <20130319092726.19104l37v0u6gv40@www.staffmail.ed.ac.uk>

Hi Antonio,

With (simple) random effects marginalised:

X<-model.matrix(~ maternal_age_c + I(maternal_age_c^2)  +  
as.factor(birth_year) + residence + sex + wealth, data=newdata)

V<-rowSums(glm.MC.2$VCV)

beta<-glm.MC.2$Sol

c2 <- (16 * sqrt(3)/(15 * pi))^2

pred<-t(plogis(t(beta%*%t(X)/sqrt(1+c2*V))))

pred[i,j] is the prediction for the jth new data point for the ith  
MCMC sample. colSums(pred)  should be equivalent to the output from  
predict.MCMCglmm.

Cheers,

Jarrod



Quoting "Antonio P. Ramos" <ramos.grad.student at gmail.com> on Mon, 18  
Mar 2013 20:04:07 -0700:

> Hi all.
>
> As far as I can tell newdata is still not implemented for this nice
> package. Thus I wonder what would be the best way to get predictions "by
> hand". My model is actually very simple. Still I need to marginalize the
> random effects. Any hints? Thanks in advance, Antonio Pedro.
>
>
> glm.MC.2 <- MCMCglmm(mortality.under.2 ~ maternal_age_c +
> I(maternal_age_c^2)  +
>                        as.factor(birth_year) + residence +
>                        sex + wealth,
>                      nitt=20000, thin=10, burnin=1000,
>                      random= ~CASEID, prior=prior.2,data=egypt2,
> family='categorical')
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From GodinA at dal.ca  Tue Mar 19 12:15:48 2013
From: GodinA at dal.ca (Aurelie Cosandey Godin)
Date: Tue, 19 Mar 2013 08:15:48 -0300
Subject: [R-sig-ME] semicontinuous variables: what likelihoods are
	available?
In-Reply-To: <CAGNXmpMbmgtdvWythH6q_SssKtmBo5PfrUhzOCStnDs3PfRgVA@mail.gmail.com>
References: <4AA39F79-84C9-4A35-8EF2-5176A9A1F1A1@Dal.Ca>
	<loom.20130318T200115-984@post.gmane.org>
	<6C2212B9-FD5C-4D0A-955B-CCEDE36BFA6B@Dal.Ca>
	<CAGNXmpMbmgtdvWythH6q_SssKtmBo5PfrUhzOCStnDs3PfRgVA@mail.gmail.com>
Message-ID: <48F18129-80DB-4A72-8AA7-2812901DA231@dal.ca>

Many thanks George!
Attached figures.
I will look into your suggestion. 

Thank you!
Aurelie

 

On 2013-03-18, at 9:00 PM, George Wang wrote:

> Hi Aurelie,
> 
> I am probably more seeking assurance from the gurus than trying to answer your question, as I'm also playing with a data set in a similar situation. (I am looking at area of leaf consumed by insect herbivores.) Can you use a delta-distribution/approach for your data? That is, run binomial models on the presence-absence data of your response variable, and log-normal models on the positive (non-zero) portion of your continuous data. 
> 
> I know this approach is fairly common for linear models, e.g.
> http://r-project.markmail.org/search/?q=delta%20Tweedie#query:delta%20Tweedie+page:1+mid:gnzpixld5zkl5sig+state:results
> 
> and I imagine it's equally applicable for (G)LMM's. I'll let the more knowledgeable members of this list correct me if not. I didn't see any attachment in your last message, so I don't know how your data are distributed, but this approach seemed to work well for my data (with ~70% zeros).
> 
> HTH,
> 
> George
> 
> 
> On Mon, Mar 18, 2013 at 4:25 PM, Aurelie Cosandey Godin <GodinA at dal.ca> wrote:
> Thank you Ben and others,
> 
> Apologize for not being very precise!
> My response variable is measured both in weight (kg) and counts and is very zero-inflated i.e., 91% of my data.
> I previously ran models on the count data using a suit of  likelihoods: 2-parts zero inflated poisson & 2-parts zero inflated negative binomial. The latter were the best.
> Now I would like to run the same models but with my response variable in kg, but I don't know how to model my positive (truncated or just positive weight data?). See  figure attached of the distribution of my weight data.
> 
> Many thanks in advance!!
> Aurelie
> 
> 
> 
> 
> 
> 
> On 2013-03-18, at 4:30 PM, Ben Bolker wrote:
> 
> > Aurelie Cosandey Godin <GodinA at ...> writes:
> >
> >
> > [snip]
> >
> >> I need to run spatio-temporal models for a semicontinuous response
> >> variable (weight in kg).  I am not familiar with the available
> >> semicontinuous likelihood functions available in R and was wondering
> >> if some of you may be able to point me in the right direction for
> >> information.
> >
> >
> > Can you say any more about exactly what a semicontinuous response variable
> > is?  Poking around (e.g <http://lpsolve.sourceforge.net/4.0/semi-cont.htm>)
> > doesn't make it entirely clear: are these data that are
> >
> > truncated, i.e. values <= a lower threshold are absent from the data set;
> > censored, i.e. values <= a lower threshold are recorded as
> >   "less than threshold"?
> > positive, i.e. values <0 don't even exist?
> > are the data non-negative (i.e. >=0) or are they positive (>0)?
> >
> >  The simplest of these cases is positive data, which you
> > can model fairly easily by log transformation (i.e. assume
> > a lognormal distribution), or with slightly more difficulty
> > using a Gamma distribution ...  if you have censored or truncated
> > data, or data that include zeros, it gets a little harder ...
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 


From patriciamexico at ebd.csic.es  Tue Mar 19 12:32:05 2013
From: patriciamexico at ebd.csic.es (MARTINEZ GUTIERREZ, PATRICIA GUADALUPE)
Date: Tue, 19 Mar 2013 12:32:05 +0100
Subject: [R-sig-ME] About glmmADMB Control Options...
In-Reply-To: <51471FB8.6090703@mcmaster.ca>
References: <10973_1363607131_r2IBjUGJ007498_20130318124441.Horde.mO0Kazp6yHZRRv4pfuelbNA@webmail.csic.es>
	<51471FB8.6090703@mcmaster.ca>
Message-ID: <20130319123205.Horde.BGExD3U-XzxRSEy1cF6EdYA@webmail.csic.es>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130319/facf2381/attachment.pl>

From ramos.grad.student at gmail.com  Tue Mar 19 19:35:00 2013
From: ramos.grad.student at gmail.com (Antonio P. Ramos)
Date: Tue, 19 Mar 2013 11:35:00 -0700
Subject: [R-sig-ME] predictions for MCMCglmm
In-Reply-To: <20130319092726.19104l37v0u6gv40@www.staffmail.ed.ac.uk>
References: <CAHawB9uJp2hh-ezB2c=iMC=UH1DJuhQfvOxwMETNrnZ2zO4OUg@mail.gmail.com>
	<20130319092726.19104l37v0u6gv40@www.staffmail.ed.ac.uk>
Message-ID: <CAHawB9vReTUcsxMsVKwcmRFxEJ29uDsTayL3jK1bQrd5JXRyng@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130319/f175423f/attachment.pl>

From ramos.grad.student at gmail.com  Tue Mar 19 19:35:48 2013
From: ramos.grad.student at gmail.com (Antonio P. Ramos)
Date: Tue, 19 Mar 2013 11:35:48 -0700
Subject: [R-sig-ME] predictions for MCMCglmm
In-Reply-To: <CAHawB9vReTUcsxMsVKwcmRFxEJ29uDsTayL3jK1bQrd5JXRyng@mail.gmail.com>
References: <CAHawB9uJp2hh-ezB2c=iMC=UH1DJuhQfvOxwMETNrnZ2zO4OUg@mail.gmail.com>
	<20130319092726.19104l37v0u6gv40@www.staffmail.ed.ac.uk>
	<CAHawB9vReTUcsxMsVKwcmRFxEJ29uDsTayL3jK1bQrd5JXRyng@mail.gmail.com>
Message-ID: <CAHawB9uVvpLL_P+NvVhpJN+vYiOgPO3SnpS83X7WPq=_SbOWWw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130319/b2f10728/attachment.pl>

From kalakouentin at gmail.com  Tue Mar 19 20:30:07 2013
From: kalakouentin at gmail.com (Pantelis Hadjipantelis)
Date: Tue, 19 Mar 2013 19:30:07 +0000
Subject: [R-sig-ME] Cholesky factor discrepancy
Message-ID: <CAH2DVQEaOY9ymcWTOx4XWC93jAaRpzwYFaPE+WTVPJUv44rRHg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130319/4153d9f9/attachment.pl>

From jwiley.psych at gmail.com  Tue Mar 19 20:40:18 2013
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Tue, 19 Mar 2013 12:40:18 -0700
Subject: [R-sig-ME] predictions for MCMCglmm
In-Reply-To: <CAHawB9uVvpLL_P+NvVhpJN+vYiOgPO3SnpS83X7WPq=_SbOWWw@mail.gmail.com>
References: <CAHawB9uJp2hh-ezB2c=iMC=UH1DJuhQfvOxwMETNrnZ2zO4OUg@mail.gmail.com>
	<20130319092726.19104l37v0u6gv40@www.staffmail.ed.ac.uk>
	<CAHawB9vReTUcsxMsVKwcmRFxEJ29uDsTayL3jK1bQrd5JXRyng@mail.gmail.com>
	<CAHawB9uVvpLL_P+NvVhpJN+vYiOgPO3SnpS83X7WPq=_SbOWWw@mail.gmail.com>
Message-ID: <CANz9Z_JNwUBF3T_ABd4xzBtSgxHaovODH7QFdzJvzgwW+Wef5A@mail.gmail.com>

Hi Antonio,

You need to add both levels to the factor; however, both need not be
represented in your particular model matrix.  To do this, construct a
data frame where all the variables math your original data, but have
different values, a l?
data.frame(x = factor(1, levels = c(1, 2), labels = c("a", "b")))
b does not exist in that particular set of the data, but because the
factor has both levels, model matrix will work okay.

For a research project I was on, I developed a set of prediction
methods for MCMCglmm in the package postMCMCglmm that includes new
predictions and marginalizing random effects, with the ability to
handle new data.  That package is limited to the case I was working
with---a single ordinal outcome---but you may find the code and
documentation useful for examples.  Here is the main relevant code:

https://github.com/JWiley/postMCMCglmm/blob/master/R/prediction.R


I also defined extraction methods (e.g., fixef, ranef, etc.) elsewhere
in the package which you can lean on.  Actually, the code _may_ even
work for other families besides ordinal, as long as you stay on the
linear predictor metric---the back transformations definitely are not
implemented generally.

Cheers,

Josh



On Tue, Mar 19, 2013 at 11:35 AM, Antonio P. Ramos
<ramos.grad.student at gmail.com> wrote:
> sorry: the full code here
>> pred.data.pred <- data.frame(maternal_age_c=rep(20,25),wealth=rep("Lowest
> quintile",25),
> +
>  birth_year=1971:1995,birth_order=rep(1,25),
> +
>  sex=rep("Female",25),residence=rep("Rural",25),
> +                                    maternal_educ=rep("Primary",25))
>> # creating predictions "by hand"
>> X <- model.matrix(~ maternal_age_c + I(maternal_age_c^2)  +
> as.factor(birth_year) +
> +                   as.factor(birth_order) + residence + sex + wealth,
> data=pred.data.pred)
> Error in `contrasts<-`(`*tmp*`, value = contr.funs[1 + isOF[nn]]) :
>   contrasts can be applied only to factors with 2 or more levels
>
>
>
>
> On Tue, Mar 19, 2013 at 11:35 AM, Antonio P. Ramos <
> ramos.grad.student at gmail.com> wrote:
>
>> Thanks for you reply Jarrod. The problem is that model.matrix doesn't
>> allow me to created the predication I need as factors cannot have just one
>> level. Any ways around data? thanks a bunch
>>
>>
>> pred.data.pred <- data.frame(maternal_age_c=rep(20,25),wealth=rep("Lowest
>> quintile",25),
>>
>>  birth_year=1971:1995,birth_order=rep(1,25),
>>
>>  sex=rep("Female",25),residence=rep("Rural",25),
>>                                    maternal_educ=rep("Primary",25))
>> # creating predictions "by hand"
>> X <- model.matrix(~ maternal_age_c + I(maternal_age_c^2)  +
>> as.factor(birth_year) +
>>                   as.factor(birth_order) + residence + sex + wealth,
>> data=pred.data.pred)
>>
>>
>>
>> On Tue, Mar 19, 2013 at 2:27 AM, Jarrod Hadfield <j.hadfield at ed.ac.uk>wrote:
>>
>>> Hi Antonio,
>>>
>>> With (simple) random effects marginalised:
>>>
>>> X<-model.matrix(~ maternal_age_c + I(maternal_age_c^2)  +
>>> as.factor(birth_year) + residence + sex + wealth, data=newdata)
>>>
>>> V<-rowSums(glm.MC.2$VCV)
>>>
>>> beta<-glm.MC.2$Sol
>>>
>>> c2 <- (16 * sqrt(3)/(15 * pi))^2
>>>
>>> pred<-t(plogis(t(beta%*%t(X)/**sqrt(1+c2*V))))
>>>
>>> pred[i,j] is the prediction for the jth new data point for the ith MCMC
>>> sample. colSums(pred)  should be equivalent to the output from
>>> predict.MCMCglmm.
>>>
>>> Cheers,
>>>
>>> Jarrod
>>>
>>>
>>>
>>>
>>> Quoting "Antonio P. Ramos" <ramos.grad.student at gmail.com> on Mon, 18 Mar
>>> 2013 20:04:07 -0700:
>>>
>>>  Hi all.
>>>>
>>>> As far as I can tell newdata is still not implemented for this nice
>>>> package. Thus I wonder what would be the best way to get predictions "by
>>>> hand". My model is actually very simple. Still I need to marginalize the
>>>> random effects. Any hints? Thanks in advance, Antonio Pedro.
>>>>
>>>>
>>>> glm.MC.2 <- MCMCglmm(mortality.under.2 ~ maternal_age_c +
>>>> I(maternal_age_c^2)  +
>>>>                        as.factor(birth_year) + residence +
>>>>                        sex + wealth,
>>>>                      nitt=20000, thin=10, burnin=1000,
>>>>                      random= ~CASEID, prior=prior.2,data=egypt2,
>>>> family='categorical')
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> ______________________________**_________________
>>>> R-sig-mixed-models at r-project.**org <R-sig-mixed-models at r-project.org>mailing list
>>>> https://stat.ethz.ch/mailman/**listinfo/r-sig-mixed-models<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>>
>>>>
>>>>
>>>
>>>
>>> --
>>> The University of Edinburgh is a charitable body, registered in
>>> Scotland, with registration number SC005336.
>>>
>>>
>>>
>>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



--
Joshua Wiley
Ph.D. Student, Health Psychology
University of California, Los Angeles
http://joshuawiley.com/
Senior Analyst - Elkhart Group Ltd.
http://elkhartgroup.com


From aghaynes at gmail.com  Thu Mar 21 18:19:02 2013
From: aghaynes at gmail.com (Alan Haynes)
Date: Thu, 21 Mar 2013 18:19:02 +0100
Subject: [R-sig-ME] R2 from mixed models
Message-ID: <CAPdSD+6FaqUxMQgH_MgL1Dha643CtaWWTj7waL3gh6=sPAJ4Lw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130321/fa4931fe/attachment.pl>

From kevin.thorpe at utoronto.ca  Thu Mar 21 19:23:34 2013
From: kevin.thorpe at utoronto.ca (Kevin E. Thorpe)
Date: Thu, 21 Mar 2013 14:23:34 -0400
Subject: [R-sig-ME] Random Effect Variance of Zero
Message-ID: <514B5026.3080107@utoronto.ca>

Hello.

I'm posting this for a colleague since I subscribe to this list.  He fit 
a lme4::lmer model on a data set and got a variance of zero on the RE 
intercept.  He fit what appears to be the same model with nlme::lme and 
obtained a non-zero value for the same terms.

I re-ran on my system, since I just updated this week and here are my 
results.  If requested, I will send the data off-list.

Any idea why this happens or how to make it not happen?

Many thanks.

=== lme4::lmer ===

 > lmer(zbmi ~ (1|DA) , data = ra.subset)
Linear mixed model fit by REML ['lmerMod']
Formula: zbmi ~ (1 | DA)
    Data: ra.subset

REML criterion at convergence: 10474.66

Random effects:
  Groups   Name        Variance Std.Dev.
  DA       (Intercept) 0.000    0.000
  Residual             1.129    1.063
Number of obs: 3538, groups: DA, 1603

Fixed effects:
             Estimate Std. Error t value
(Intercept)  0.15347    0.01787   8.591
 > sessionInfo()
R version 2.15.3 Patched (2013-03-13 r62256)
Platform: x86_64-unknown-linux-gnu (64-bit)

locale:
  [1] LC_CTYPE=en_US       LC_NUMERIC=C         LC_TIME=en_US
  [4] LC_COLLATE=C         LC_MONETARY=en_US    LC_MESSAGES=en_US
  [7] LC_PAPER=C           LC_NAME=C            LC_ADDRESS=C
[10] LC_TELEPHONE=C       LC_MEASUREMENT=en_US LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] lme4_0.999902345-0 Matrix_1.0-11      lattice_0.20-14

loaded via a namespace (and not attached):
[1] MASS_7.3-23    grid_2.15.3    minqa_1.2.1    nlme_3.1-108 
splines_2.15.3
[6] tools_2.15.3

=== nlme::lme ===

 > lme(zbmi ~ 1 , data = ra.subset, random = ~ 1 | DA,na.action=na.omit)
Linear mixed-effects model fit by REML
   Data: ra.subset
   Log-restricted-likelihood: -5236.905
   Fixed: zbmi ~ 1
(Intercept)
   0.1537825

Random effects:
  Formula: ~1 | DA
         (Intercept) Residual
StdDev:   0.1564781 1.051139

Number of Observations: 3538
Number of Groups: 1603
 > sessionInfo()
R version 2.15.3 Patched (2013-03-13 r62256)
Platform: x86_64-unknown-linux-gnu (64-bit)

locale:
  [1] LC_CTYPE=en_US       LC_NUMERIC=C         LC_TIME=en_US
  [4] LC_COLLATE=C         LC_MONETARY=en_US    LC_MESSAGES=en_US
  [7] LC_PAPER=C           LC_NAME=C            LC_ADDRESS=C
[10] LC_TELEPHONE=C       LC_MEASUREMENT=en_US LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] nlme_3.1-108

loaded via a namespace (and not attached):
[1] grid_2.15.3     lattice_0.20-14

-- 
Kevin E. Thorpe
Head of Biostatistics,  Applied Health Research Centre (AHRC)
Li Ka Shing Knowledge Institute of St. Michael's
Assistant Professor, Dalla Lana School of Public Health
University of Toronto
email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016


From bbolker at gmail.com  Thu Mar 21 23:42:29 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 21 Mar 2013 22:42:29 +0000 (UTC)
Subject: [R-sig-ME] Random Effect Variance of Zero
References: <514B5026.3080107@utoronto.ca>
Message-ID: <loom.20130321T232822-373@post.gmane.org>

Kevin E. Thorpe <kevin.thorpe at ...> writes:

> I'm posting this for a colleague since I subscribe to this list.  He fit 
> a lme4::lmer model on a data set and got a variance of zero on the RE 
> intercept.  He fit what appears to be the same model with nlme::lme and 
> obtained a non-zero value for the same terms.
> 
> I re-ran on my system, since I just updated this week and here are my 
> results.  If requested, I will send the data off-list.
> 
> Any idea why this happens or how to make it not happen?

   We (lme4 developers) are aware of couple of examples of this
type of behaviour.  Optimizers that allow for box constraints do
sometimes get stuck on the boundary even when they shouldn't ...
I don't know that I have a really good, detailed/principled
explanation of what happens in this situation.

https://github.com/lme4/lme4/issues/17
https://github.com/lme4/lme4/blob/master/tests/boundary.R

represent some of the examples we're aware of, contributed by
Manuel Koller, Stephane Laurent, and Vincent Dorie.

  As far as we know the development version of lme4 doesn't have
any of these problems, and for LMMs (again as far as we know)
it is never worse than stable lme4 (alas, still not entirely
true for GLMMs).  It would also allow you to swap nlminb in 
for Nelder-Mead if you wanted.

  It may not be the appropriate strategy, but rather than
putting the effort into fixing the stable version of lme4
we have been investing our effort in fixing the GLMM issues
in development lme4 (the code bases are sufficiently different
that it requires a separate effort to fix the stable
version ...)

  Have you tried with development lme4?

  I wouldn't mind seeing the data off-list.

> === lme4::lmer ===
> 
>  > lmer(zbmi ~ (1|DA) , data = ra.subset)
> Linear mixed model fit by REML ['lmerMod']
> Formula: zbmi ~ (1 | DA)
>     Data: ra.subset
> 
> REML criterion at convergence: 10474.66
> 
> Random effects:
>   Groups   Name        Variance Std.Dev.
>   DA       (Intercept) 0.000    0.000
>   Residual             1.129    1.063
> Number of obs: 3538, groups: DA, 1603
> 
> Fixed effects:
>              Estimate Std. Error t value
> (Intercept)  0.15347    0.01787   8.591
>  > sessionInfo()
> R version 2.15.3 Patched (2013-03-13 r62256)
> Platform: x86_64-unknown-linux-gnu (64-bit)

[snip]
 
> other attached packages:
> [1] lme4_0.999902345-0 Matrix_1.0-11      lattice_0.20-14
> 
> === nlme::lme ===
> 
>  > lme(zbmi ~ 1 , data = ra.subset, random = ~ 1 | DA,na.action=na.omit)
> Linear mixed-effects model fit by REML
>    Data: ra.subset
>    Log-restricted-likelihood: -5236.905
>    Fixed: zbmi ~ 1
> (Intercept)
>    0.1537825
> 
> Random effects:
>   Formula: ~1 | DA
>          (Intercept) Residual
> StdDev:   0.1564781 1.051139
> 
> Number of Observations: 3538
> Number of Groups: 1603
>  > sessionInfo()
> R version 2.15.3 Patched (2013-03-13 r62256)
> Platform: x86_64-unknown-linux-gnu (64-bit)
> 
 [snip]
 
> other attached packages:
> [1] nlme_3.1-108


From bbolker at gmail.com  Fri Mar 22 02:47:07 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 22 Mar 2013 01:47:07 +0000 (UTC)
Subject: [R-sig-ME] optimizers for mixed models
References: <51411F35.6070808@biostat.ucsf.edu>
	<loom.20130314T150520-774@post.gmane.org>
	<51420F19.9020205@biostat.ucsf.edu>
	<51421228.2080909@biostat.ucsf.edu>
	<loom.20130316T204142-287@post.gmane.org>
	<CAH2DVQHz3c_OmxxjZH-a7+n6JzcFuQcSuUd7wuo4-rpzDEaQJA@mail.gmail.com>
	<CAH2DVQFYVt2xikEMaFHCEwY9+9YV+CXWb-AENhbJnO0+GwDyKQ@mail.gmail.com>
Message-ID: <loom.20130322T024326-870@post.gmane.org>

Pantelis Hadjipantelis <kalakouentin at ...> writes:

> 
> I have personally used uobyqa() from minqa package (not bobyqa()) with
> success as a fast way to optimize the log-restricted-deviance without using
> derivatives. I had to move the optimization constraints within the function
> evaluation (ie. exponentiating everything before being used so I make sure
> they appear positive, taking cosines to bound parameters with [-1,1]). It
> appeared rather robust in cases that gradient-assisted BFGS seemed to
> converge to local minima's.

  Good to know.  Just to repeat: in many cases the best-fitting model
is singular, i.e. located on the constraint boundary of one or more of
the theta parameters -- in which case transforming to remove
constraints isn't a great idea -- but maybe "the gradient-assisted
BFGS seemed to converge to [a] local [minimum]" means precisely that
the solution was *not* on this boundary ... this ability to handle
singular cases is very convenient, and is in IMO one of lme4's
strengths.

  Ben Bolker
 
> >
> > On Sat, Mar 16, 2013 at 7:48 PM, Ben Bolker <bbolker at ...> wrote:
> >> >
> >> > On 3/14/2013 10:55 AM, Ross Boylan wrote:
> >> > > Optimization was originally via a custom optimizer using rho.  The
> >> > > custom optimizer did not incorporate bounds, and blew up when it got
> >> > > rho outside of [-1, 1].  So we switched to atanh(rho) as the target of
> >> > > optimization.  However, for some simulated datasets that failed to
> >> > > converge, as atanh(rho) marched slowly off toward infinity.  We
> >> > > switched to optim with bounds to cut that process off.
> >> > >
> >> > > So perhaps we should go back to rho, but using optim or the other
> >> > > bounded optimizers you suggested.
> >> > >
> >> > > So the fact that atanh(rho) is unbounded is a feature from some
> >> > > perspectives, but a bug from others.
> >> > I forgot to mention that we actually have analytic second (and first)
> >> > derivatives.  Switching to optim from the packages internal optimizer
> >> > meant we're no longer using the analytic 2nd derivative.
> >>

 [snip]


From j.hadfield at ed.ac.uk  Fri Mar 22 10:54:07 2013
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Fri, 22 Mar 2013 09:54:07 +0000
Subject: [R-sig-ME] predictions for MCMCglmm
In-Reply-To: <CAHawB9tg4B+UYCYk0eMA5V4XU7k6-bAsSzc+EQAGpchuthzH2A@mail.gmail.com>
References: <CAHawB9uJp2hh-ezB2c=iMC=UH1DJuhQfvOxwMETNrnZ2zO4OUg@mail.gmail.com>
	<20130319092726.19104l37v0u6gv40@www.staffmail.ed.ac.uk>
	<CAHawB9vReTUcsxMsVKwcmRFxEJ29uDsTayL3jK1bQrd5JXRyng@mail.gmail.com>
	<CAHawB9uVvpLL_P+NvVhpJN+vYiOgPO3SnpS83X7WPq=_SbOWWw@mail.gmail.com>
	<CAHawB9tg4B+UYCYk0eMA5V4XU7k6-bAsSzc+EQAGpchuthzH2A@mail.gmail.com>
Message-ID: <20130322095407.14612jw0y05cgaqs@www.staffmail.ed.ac.uk>

cc-ing back to the list ...

Hi,

Yes you can do it that way, and it should give the same answer.  It  
will slow down the MCMCing in terms of time per iteration and mixing  
though.

Cheers,

Jarrod


Quoting "Antonio P. Ramos" <ramos.grad.student at gmail.com> on Thu, 21  
Mar 2013 18:18:41 -0700:

>  Hi all,
>
> I have a follow up question: what is different between getting predictions
> used this code - which works fine - or, instead, by adding rows in the data
> matrix with NA values in the response and the desired covariates in the X
> matrix, such as often done by people using JAGS/BUGS? I am not sure at all,
> but it seems to be that by running this code, I am assuming that the
> predictions I want have some kind of random structure that might not be the
> case - by marginalizing over them all. Thanks for any further
> clarification. Antonio Pedro.
>
>
> On Tue, Mar 19, 2013 at 11:35 AM, Antonio P. Ramos <
> ramos.grad.student at gmail.com> wrote:
>
>> sorry: the full code here
>> > pred.data.pred <-
>> data.frame(maternal_age_c=rep(20,25),wealth=rep("Lowest quintile",25),
>> +
>>  birth_year=1971:1995,birth_order=rep(1,25),
>> +
>>  sex=rep("Female",25),residence=rep("Rural",25),
>> +                                    maternal_educ=rep("Primary",25))
>> > # creating predictions "by hand"
>> > X <- model.matrix(~ maternal_age_c + I(maternal_age_c^2)  +
>> as.factor(birth_year) +
>> +                   as.factor(birth_order) + residence + sex + wealth,
>> data=pred.data.pred)
>> Error in `contrasts<-`(`*tmp*`, value = contr.funs[1 + isOF[nn]]) :
>>   contrasts can be applied only to factors with 2 or more levels
>>
>>
>>
>>
>> On Tue, Mar 19, 2013 at 11:35 AM, Antonio P. Ramos <
>> ramos.grad.student at gmail.com> wrote:
>>
>>> Thanks for you reply Jarrod. The problem is that model.matrix doesn't
>>> allow me to created the predication I need as factors cannot have just one
>>> level. Any ways around data? thanks a bunch
>>>
>>>
>>> pred.data.pred <- data.frame(maternal_age_c=rep(20,25),wealth=rep("Lowest
>>> quintile",25),
>>>
>>>  birth_year=1971:1995,birth_order=rep(1,25),
>>>
>>>  sex=rep("Female",25),residence=rep("Rural",25),
>>>                                    maternal_educ=rep("Primary",25))
>>> # creating predictions "by hand"
>>> X <- model.matrix(~ maternal_age_c + I(maternal_age_c^2)  +
>>> as.factor(birth_year) +
>>>                   as.factor(birth_order) + residence + sex + wealth,
>>> data=pred.data.pred)
>>>
>>>
>>>
>>> On Tue, Mar 19, 2013 at 2:27 AM, Jarrod Hadfield  
>>> <j.hadfield at ed.ac.uk>wrote:
>>>
>>>> Hi Antonio,
>>>>
>>>> With (simple) random effects marginalised:
>>>>
>>>> X<-model.matrix(~ maternal_age_c + I(maternal_age_c^2)  +
>>>> as.factor(birth_year) + residence + sex + wealth, data=newdata)
>>>>
>>>> V<-rowSums(glm.MC.2$VCV)
>>>>
>>>> beta<-glm.MC.2$Sol
>>>>
>>>> c2 <- (16 * sqrt(3)/(15 * pi))^2
>>>>
>>>> pred<-t(plogis(t(beta%*%t(X)/**sqrt(1+c2*V))))
>>>>
>>>> pred[i,j] is the prediction for the jth new data point for the ith MCMC
>>>> sample. colSums(pred)  should be equivalent to the output from
>>>> predict.MCMCglmm.
>>>>
>>>> Cheers,
>>>>
>>>> Jarrod
>>>>
>>>>
>>>>
>>>>
>>>> Quoting "Antonio P. Ramos" <ramos.grad.student at gmail.com> on Mon, 18
>>>> Mar 2013 20:04:07 -0700:
>>>>
>>>>  Hi all.
>>>>>
>>>>> As far as I can tell newdata is still not implemented for this nice
>>>>> package. Thus I wonder what would be the best way to get predictions "by
>>>>> hand". My model is actually very simple. Still I need to marginalize the
>>>>> random effects. Any hints? Thanks in advance, Antonio Pedro.
>>>>>
>>>>>
>>>>> glm.MC.2 <- MCMCglmm(mortality.under.2 ~ maternal_age_c +
>>>>> I(maternal_age_c^2)  +
>>>>>                        as.factor(birth_year) + residence +
>>>>>                        sex + wealth,
>>>>>                      nitt=20000, thin=10, burnin=1000,
>>>>>                      random= ~CASEID, prior=prior.2,data=egypt2,
>>>>> family='categorical')
>>>>>
>>>>>         [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________**_________________
>>>>> R-sig-mixed-models at r-project.**org  
>>>>> <R-sig-mixed-models at r-project.org>mailing list
>>>>> https://stat.ethz.ch/mailman/**listinfo/r-sig-mixed-models<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>>>
>>>>>
>>>>>
>>>>
>>>>
>>>> --
>>>> The University of Edinburgh is a charitable body, registered in
>>>> Scotland, with registration number SC005336.
>>>>
>>>>
>>>>
>>>
>>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From s_a_kayis at yahoo.com  Fri Mar 22 12:44:04 2013
From: s_a_kayis at yahoo.com (KAYIS Seyit Ali)
Date: Fri, 22 Mar 2013 04:44:04 -0700 (PDT)
Subject: [R-sig-ME] profile
Message-ID: <1363952644.41109.YahooMailNeo@web160105.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130322/d4a76f96/attachment.pl>

From ramos.grad.student at gmail.com  Fri Mar 22 17:00:56 2013
From: ramos.grad.student at gmail.com (Antonio P. Ramos)
Date: Fri, 22 Mar 2013 09:00:56 -0700
Subject: [R-sig-ME] predictions for MCMCglmm
In-Reply-To: <20130322095407.14612jw0y05cgaqs@www.staffmail.ed.ac.uk>
References: <CAHawB9uJp2hh-ezB2c=iMC=UH1DJuhQfvOxwMETNrnZ2zO4OUg@mail.gmail.com>
	<20130319092726.19104l37v0u6gv40@www.staffmail.ed.ac.uk>
	<CAHawB9vReTUcsxMsVKwcmRFxEJ29uDsTayL3jK1bQrd5JXRyng@mail.gmail.com>
	<CAHawB9uVvpLL_P+NvVhpJN+vYiOgPO3SnpS83X7WPq=_SbOWWw@mail.gmail.com>
	<CAHawB9tg4B+UYCYk0eMA5V4XU7k6-bAsSzc+EQAGpchuthzH2A@mail.gmail.com>
	<20130322095407.14612jw0y05cgaqs@www.staffmail.ed.ac.uk>
Message-ID: <CAHawB9uDJf-En3JhO8zeV5oq5eFnVgP88wKsbWvCLduc03A4hw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130322/a5d970ef/attachment.pl>

From j.hadfield at ed.ac.uk  Fri Mar 22 18:54:56 2013
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Fri, 22 Mar 2013 17:54:56 +0000
Subject: [R-sig-ME] predictions for MCMCglmm
In-Reply-To: <CAHawB9uDJf-En3JhO8zeV5oq5eFnVgP88wKsbWvCLduc03A4hw@mail.gmail.com>
References: <CAHawB9uJp2hh-ezB2c=iMC=UH1DJuhQfvOxwMETNrnZ2zO4OUg@mail.gmail.com>
	<20130319092726.19104l37v0u6gv40@www.staffmail.ed.ac.uk>
	<CAHawB9vReTUcsxMsVKwcmRFxEJ29uDsTayL3jK1bQrd5JXRyng@mail.gmail.com>
	<CAHawB9uVvpLL_P+NvVhpJN+vYiOgPO3SnpS83X7WPq=_SbOWWw@mail.gmail.com>
	<CAHawB9tg4B+UYCYk0eMA5V4XU7k6-bAsSzc+EQAGpchuthzH2A@mail.gmail.com>
	<20130322095407.14612jw0y05cgaqs@www.staffmail.ed.ac.uk>
	<CAHawB9uDJf-En3JhO8zeV5oq5eFnVgP88wKsbWvCLduc03A4hw@mail.gmail.com>
Message-ID: <20130322175456.12603np9np08n3sw@www.staffmail.ed.ac.uk>

Hi,

In the original code I sent you I marginalised the random effects. If  
you use predict on your new model with the missing data you should get  
the same answer if you have marginal=your_model$Random$formula.

Cheers,

Jarrod



Quoting "Antonio P. Ramos" <ramos.grad.student at gmail.com> on Fri, 22  
Mar 2013 09:00:56 -0700:

> Thanks Jarrod, but isn't it true that the random effects I get for
> predictions will be different in each scenario?
>
>
> On Fri, Mar 22, 2013 at 2:54 AM, Jarrod Hadfield <j.hadfield at ed.ac.uk>wrote:
>
>> cc-ing back to the list ...
>>
>> Hi,
>>
>> Yes you can do it that way, and it should give the same answer.  It will
>> slow down the MCMCing in terms of time per iteration and mixing though.
>>
>> Cheers,
>>
>> Jarrod
>>
>>
>>
>> Quoting "Antonio P. Ramos" <ramos.grad.student at gmail.com> on Thu, 21 Mar
>> 2013 18:18:41 -0700:
>>
>>   Hi all,
>>>
>>> I have a follow up question: what is different between getting predictions
>>> used this code - which works fine - or, instead, by adding rows in the
>>> data
>>> matrix with NA values in the response and the desired covariates in the X
>>> matrix, such as often done by people using JAGS/BUGS? I am not sure at
>>> all,
>>> but it seems to be that by running this code, I am assuming that the
>>> predictions I want have some kind of random structure that might not be
>>> the
>>> case - by marginalizing over them all. Thanks for any further
>>> clarification. Antonio Pedro.
>>>
>>>
>>> On Tue, Mar 19, 2013 at 11:35 AM, Antonio P. Ramos <
>>> ramos.grad.student at gmail.com> wrote:
>>>
>>>  sorry: the full code here
>>>> > pred.data.pred <-
>>>> data.frame(maternal_age_c=rep(**20,25),wealth=rep("Lowest quintile",25),
>>>> +
>>>>  birth_year=1971:1995,birth_**order=rep(1,25),
>>>> +
>>>>  sex=rep("Female",25),**residence=rep("Rural",25),
>>>> +                                    maternal_educ=rep("Primary",**25))
>>>> > # creating predictions "by hand"
>>>> > X <- model.matrix(~ maternal_age_c + I(maternal_age_c^2)  +
>>>> as.factor(birth_year) +
>>>> +                   as.factor(birth_order) + residence + sex + wealth,
>>>> data=pred.data.pred)
>>>> Error in `contrasts<-`(`*tmp*`, value = contr.funs[1 + isOF[nn]]) :
>>>>   contrasts can be applied only to factors with 2 or more levels
>>>>
>>>>
>>>>
>>>>
>>>> On Tue, Mar 19, 2013 at 11:35 AM, Antonio P. Ramos <
>>>> ramos.grad.student at gmail.com> wrote:
>>>>
>>>>  Thanks for you reply Jarrod. The problem is that model.matrix doesn't
>>>>> allow me to created the predication I need as factors cannot have just
>>>>> one
>>>>> level. Any ways around data? thanks a bunch
>>>>>
>>>>>
>>>>> pred.data.pred <- data.frame(maternal_age_c=rep(**
>>>>> 20,25),wealth=rep("Lowest
>>>>> quintile",25),
>>>>>
>>>>>  birth_year=1971:1995,birth_**order=rep(1,25),
>>>>>
>>>>>  sex=rep("Female",25),**residence=rep("Rural",25),
>>>>>                                    maternal_educ=rep("Primary",**25))
>>>>> # creating predictions "by hand"
>>>>> X <- model.matrix(~ maternal_age_c + I(maternal_age_c^2)  +
>>>>> as.factor(birth_year) +
>>>>>                   as.factor(birth_order) + residence + sex + wealth,
>>>>> data=pred.data.pred)
>>>>>
>>>>>
>>>>>
>>>>> On Tue, Mar 19, 2013 at 2:27 AM, Jarrod Hadfield <j.hadfield at ed.ac.uk
>>>>> >wrote:
>>>>>
>>>>>  Hi Antonio,
>>>>>>
>>>>>> With (simple) random effects marginalised:
>>>>>>
>>>>>> X<-model.matrix(~ maternal_age_c + I(maternal_age_c^2)  +
>>>>>> as.factor(birth_year) + residence + sex + wealth, data=newdata)
>>>>>>
>>>>>> V<-rowSums(glm.MC.2$VCV)
>>>>>>
>>>>>> beta<-glm.MC.2$Sol
>>>>>>
>>>>>> c2 <- (16 * sqrt(3)/(15 * pi))^2
>>>>>>
>>>>>> pred<-t(plogis(t(beta%*%t(X)/****sqrt(1+c2*V))))
>>>>>>
>>>>>>
>>>>>> pred[i,j] is the prediction for the jth new data point for the ith MCMC
>>>>>> sample. colSums(pred)  should be equivalent to the output from
>>>>>> predict.MCMCglmm.
>>>>>>
>>>>>> Cheers,
>>>>>>
>>>>>> Jarrod
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>> Quoting "Antonio P. Ramos" <ramos.grad.student at gmail.com> on Mon, 18
>>>>>> Mar 2013 20:04:07 -0700:
>>>>>>
>>>>>>  Hi all.
>>>>>>
>>>>>>>
>>>>>>> As far as I can tell newdata is still not implemented for this nice
>>>>>>> package. Thus I wonder what would be the best way to get predictions
>>>>>>> "by
>>>>>>> hand". My model is actually very simple. Still I need to marginalize
>>>>>>> the
>>>>>>> random effects. Any hints? Thanks in advance, Antonio Pedro.
>>>>>>>
>>>>>>>
>>>>>>> glm.MC.2 <- MCMCglmm(mortality.under.2 ~ maternal_age_c +
>>>>>>> I(maternal_age_c^2)  +
>>>>>>>                        as.factor(birth_year) + residence +
>>>>>>>                        sex + wealth,
>>>>>>>                      nitt=20000, thin=10, burnin=1000,
>>>>>>>                      random= ~CASEID, prior=prior.2,data=egypt2,
>>>>>>> family='categorical')
>>>>>>>
>>>>>>>         [[alternative HTML version deleted]]
>>>>>>>
>>>>>>> ______________________________****_________________
>>>>>>> R-sig-mixed-models at r-project.****org <R-sig-mixed-models at r-project.**
>>>>>>> org <R-sig-mixed-models at r-project.org>>mailing list
>>>>>>> https://stat.ethz.ch/mailman/****listinfo/r-sig-mixed-models<https://stat.ethz.ch/mailman/**listinfo/r-sig-mixed-models>
>>>>>>> <h**ttps://stat.ethz.ch/mailman/**listinfo/r-sig-mixed-models<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>>>>> >
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>
>>>>>> --
>>>>>> The University of Edinburgh is a charitable body, registered in
>>>>>> Scotland, with registration number SC005336.
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>
>>>>
>>>
>>
>>
>> --
>> The University of Edinburgh is a charitable body, registered in
>> Scotland, with registration number SC005336.
>>
>>
>>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From bbolker at gmail.com  Fri Mar 22 20:02:04 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 22 Mar 2013 19:02:04 +0000 (UTC)
Subject: [R-sig-ME] profile
References: <1363952644.41109.YahooMailNeo@web160105.mail.bf1.yahoo.com>
Message-ID: <loom.20130322T193824-276@post.gmane.org>

KAYIS Seyit Ali <s_a_kayis at ...> writes:


> In the?manual of lme4 (lme4t.pdf) library,?"profile" and "confint"
> functions are?used in page 12. I am trying to repeat the example but
> I can not. Is it necessary?to call any library before using them?
> Any info is deeply appreciated. ?  Kind Regards? Seyit Ali?

 Where are you finding lme4t.pdf ... ? 

 I'm pretty sure that confint() and profile() are only available in
the development version of lme4, available from
http://lme4.r-forge.r-project.org/repos and github ... this will be
fine (I think) as long as you're doing LMMs -- you may encounter
some issues with 'fragile' GLMMs


From leanna_jones at hotmail.com  Sat Mar 23 23:45:30 2013
From: leanna_jones at hotmail.com (Leanna Jones)
Date: Sat, 23 Mar 2013 15:45:30 -0700
Subject: [R-sig-ME] Non-convergence error for GLMM with LME4?
In-Reply-To: <BLU173-W46D655AA645DFB20C393F4E4D50@phx.gbl>
References: <BLU173-W46D655AA645DFB20C393F4E4D50@phx.gbl>
Message-ID: <BLU173-W3B82EF2DC99F17E85C060E4D50@phx.gbl>

From: leanna_jones at hotmail.com
To: r-help at r-project.org
Subject: Non-convergence error for GLMM with LME4?
Date: Sat, 23 Mar 2013 13:47:47 -0700

Hello! ?I am trying to run a GLMM using LME4, and keep getting the warning message: "In mer_finalize(ans) : false convergence (8)" ?I am quite new to R, and in looking into this thus far, it appears that there are a variety of reasons why this might occur, such as needing to standardize some parameters or if all subjects in one combination of parameters all have the same outcome. ?I also understand that the warning does not necessarily mean that the model results are invalid, but they might be...however, I am unsure how to interpret this in my own situation.

I started with a somewhat more complex model, but kept simplifying it to see if I could get the warning to go away (so it might indicate which predictor variable was the problem...). However, even when using a single fixed effect variable (just sex, for instance), I continue to have the problem, which makes me think the issue may be with my random effect. ?Here is the model I would like to run:

mm1=lmer(BinomialOutcome~AgeGroup+Sex+Study.Site+(1|BearID.reformatted),family=binomial)

The study is based on bear captures over a period of time, such that some bears are captured only once, while others many times (in a very unbalanced fashion); I would like to use all the data, but want to account for resampling of specific individuals. ?However, this means that there are nearly 600 different bear IDs, and I am wondering if this is the reason why the model will not converge? ?If so, what is the best way to address this? ?Or other ideas as to what might be going on?

When I run the line above with verbose on, I get the following:?
?> mm1=lmer(BinomialOutcome~AgeGroup+Sex+Study.Site+(1|BearID.reformatted),family=binomial) ? ?#random effect: Ind with intercept of 1, correcting for the intercept/variation btw individuals
? 0: ? ? 805.13676: ?1.12717 -0.556586 ?1.85210 ?2.38794 ?2.36938 ?2.35604 -2.22337 ?1.30764 ?1.34134 -2.47444 -1.63320
? 1: ? ? 748.91032: ?2.05259 -0.834683 ?1.81369 ?2.42567 ?2.40069 ?2.38217 -2.31535 ?1.22744 ?1.26468 -2.64606 -1.74027
? 2: ? ? 723.97734: ?2.74220 -1.05673 ?2.00374 ?2.71876 ?2.57376 ?2.50128 -2.73578 ?1.23505 ?1.35678 -2.98235 -1.63736
? 3: ? ? 715.51275: ?2.92015 -1.58830 ?2.15652 ?3.03669 ?2.81316 ?2.67649 -3.28992 ?1.30372 ?1.36311 -3.32467 -1.84785
? 4: ? ? 696.36424: ?3.21244 -1.51265 ?2.41407 ?3.41250 ?3.22182 ?2.99137 -3.54075 ?1.68499 ?1.83767 -3.33953 -1.80989
? 5: ? ? 672.69327: ?4.20847 -2.35950 ?3.26463 ?4.32168 ?4.39792 ?4.00460 -3.72829 ?1.41841 ?2.56574 -4.27911 -1.86318
? 6: ? ? 664.48332: ?4.37811 -2.58726 ?3.01153 ?4.60841 ?4.65061 ?4.30175 -4.11225 ?2.30181 ?2.55998 -4.38222 -2.02300
? 7: ? ? 625.68427: ?7.31164 -4.89788 ?5.63003 ?7.04671 ?7.95742 ?8.12903 -4.86511 ?3.64151 ?3.86169 -6.33864 -2.89485
? 8: ? ? 619.38278: ?9.39340 -7.21835 ?5.63590 ?11.1393 ?10.6331 ?11.5975 -4.65786 ?3.81066 ?6.58406 -9.13652 -2.96142
? 9: ? ? 613.14410: ?9.53164 -7.17298 ?6.01739 ?10.8896 ?10.7209 ?11.6709 -4.81531 ?4.06987 ?6.53556 -9.01013 -3.05630
?10: ? ? 600.31130: ?10.0557 -7.29631 ?7.68818 ?10.1017 ?11.1766 ?12.1945 -5.40073 ?5.30987 ?6.73629 -8.62503 -3.67308
?11: ? ? 589.17852: ?11.9972 -9.32646 ?9.77915 ?13.1274 ?13.2796 ?14.9828 -6.09763 ?6.80325 ?9.19492 -9.58777 -5.25910
?12: ? ? 586.76154: ?12.3176 -9.61034 ?9.97050 ?13.3227 ?13.7241 ?15.3584 -6.13498 ?7.19387 ?9.59990 -9.83274 -5.36590
?13: ? ? 586.09051: ?12.3760 -9.59270 ?9.95463 ?13.2692 ?13.7816 ?15.3696 -6.14017 ?7.35785 ?9.64404 -9.83450 -5.34840
?14: ? ? 585.97813: ?12.3886 -9.59431 ?9.95680 ?13.2579 ?13.7946 ?15.3724 -6.14235 ?7.38957 ?9.65379 -9.83525 -5.34966
?15: ? ? 585.77123: ?12.4143 -9.59929 ?9.96353 ?13.2359 ?13.8209 ?15.3784 -6.14715 ?7.45208 ?9.67407 -9.83681 -5.35395
?16: ? ? 585.69436: ?12.4251 -9.60281 ?9.96832 ?13.2277 ?13.8318 ?15.3810 -6.14945 ?7.47605 ?9.68290 -9.83747 -5.35717
?17: ? ? 585.54933: ?12.4469 -9.61094 ?9.97946 ?13.2122 ?13.8536 ?15.3863 -6.15434 ?7.52306 ?9.70121 -9.83879 -5.36474
?18: ? ? 585.49415: ?12.4558 -9.61507 ?9.98519 ?13.2068 ?13.8624 ?15.3886 -6.15653 ?7.54097 ?9.70908 -9.83931 -5.36868
?19: ? ? 585.38801: ?12.4740 -9.62396 ?9.99753 ?13.1967 ?13.8800 ?15.3933 -6.16106 ?7.57607 ?9.72529 -9.84034 -5.37720
?20: ? ? 585.38387: ?12.4748 -9.62436 ?9.99809 ?13.1963 ?13.8807 ?15.3935 -6.16126 ?7.57741 ?9.72597 -9.84038 -5.37759
?21: ? ? 585.35100: ?12.4807 -9.62760 ?10.0026 ?13.1936 ?13.8863 ?15.3951 -6.16281 ?7.58812 ?9.73146 -9.84070 -5.38074
?22: ? ? 585.35042: ?12.4807 -9.62760 ?10.0026 ?13.1936 ?13.8863 ?15.3951 -6.16281 ?7.58812 ?9.73146 -9.87324 -5.38074
?23: ? ? 585.22373: ?12.5045 -9.64059 ?10.0207 ?13.1830 ?13.9088 ?15.4016 -6.16903 ?7.63092 ?9.75346 -9.87324 -5.39333
?24: ? ? 585.21879: ?12.5055 -9.64113 ?10.0216 ?13.1827 ?13.9097 ?15.4018 -6.16930 ?7.63249 ?9.75441 -9.87323 -5.39392
?25: ? ? 585.20893: ?12.5075 -9.64224 ?10.0233 ?13.1822 ?13.9114 ?15.4024 -6.16984 ?7.63564 ?9.75632 -9.87322 -5.39512
?26: ? ? 585.20499: ?12.5083 -9.64268 ?10.0240 ?13.1820 ?13.9121 ?15.4026 -6.17006 ?7.63689 ?9.75709 -9.87321 -5.39560
?27: ? ? 585.20420: ?12.5085 -9.64277 ?10.0241 ?13.1820 ?13.9123 ?15.4027 -6.17011 ?7.63714 ?9.75724 -9.87321 -5.39570
?28: ? ? 585.19792: ?12.5098 -9.64349 ?10.0252 ?13.1817 ?13.9134 ?15.4030 -6.17046 ?7.63914 ?9.75847 -9.87320 -5.39647
?29: ? ? 585.19767: ?12.5098 -9.64351 ?10.0253 ?13.1817 ?13.9134 ?15.4030 -6.17047 ?7.63922 ?9.75852 -9.87320 -5.39650
?30: ? ? 585.19762: ?12.5098 -9.64352 ?10.0253 ?13.1817 ?13.9135 ?15.4030 -6.17047 ?7.63923 ?9.75853 -9.87320 -5.39651
?31: ? ? 585.19752: ?12.5099 -9.64353 ?10.0253 ?13.1817 ?13.9135 ?15.4030 -6.17048 ?7.63926 ?9.75855 -9.87320 -5.39652
?32: ? ? 585.19748: ?12.5099 -9.64354 ?10.0253 ?13.1817 ?13.9135 ?15.4030 -6.17048 ?7.63928 ?9.75856 -9.87320 -5.39653
?33: ? ? 585.19740: ?12.5099 -9.64355 ?10.0253 ?13.1817 ?13.9135 ?15.4031 -6.17049 ?7.63930 ?9.75857 -9.87320 -5.39654
?34: ? ? 585.19736: ?12.5099 -9.64355 ?10.0253 ?13.1817 ?13.9135 ?15.4031 -6.17049 ?7.63931 ?9.75858 -9.87320 -5.39654
?35: ? ? 585.19730: ?12.5099 -9.64356 ?10.0253 ?13.1817 ?13.9135 ?15.4031 -6.17049 ?7.63933 ?9.75859 -9.87320 -5.39655
?36: ? ? 585.19727: ?12.5099 -9.64356 ?10.0253 ?13.1817 ?13.9135 ?15.4031 -6.17049 ?7.63934 ?9.75860 -9.87320 -5.39655
?37: ? ? 585.19722: ?12.5099 -9.64356 ?10.0253 ?13.1817 ?13.9135 ?15.4031 -6.17050 ?7.63936 ?9.75861 -9.87320 -5.39656
?38: ? ? 585.19719: ?12.5099 -9.64363 ?10.0253 ?13.1817 ?13.9135 ?15.4031 -6.17050 ?7.63936 ?9.75861 -9.87329 -5.39656
?39: ? ? 585.19679: ?12.5100 -9.64367 ?10.0254 ?13.1817 ?13.9136 ?15.4031 -6.17052 ?7.63949 ?9.75869 -9.87326 -5.39661
?40: ? ? 585.19677: ?12.5100 -9.64367 ?10.0254 ?13.1817 ?13.9136 ?15.4031 -6.17052 ?7.63949 ?9.75869 -9.87326 -5.39661
?41: ? ? 585.19677: ?12.5100 -9.64367 ?10.0254 ?13.1817 ?13.9136 ?15.4031 -6.17052 ?7.63949 ?9.75869 -9.87326 -5.39661
?42: ? ? 585.19677: ?12.5100 -9.64367 ?10.0254 ?13.1817 ?13.9136 ?15.4031 -6.17052 ?7.63949 ?9.75870 -9.87326 -5.39661
?43: ? ? 585.19676: ?12.5100 -9.64367 ?10.0254 ?13.1817 ?13.9136 ?15.4031 -6.17052 ?7.63949 ?9.75870 -9.87326 -5.39661
?44: ? ? 585.19676: ?12.5100 -9.64367 ?10.0254 ?13.1817 ?13.9136 ?15.4031 -6.17052 ?7.63949 ?9.75870 -9.87326 -5.39661
?45: ? ? 585.19676: ?12.5100 -9.64367 ?10.0254 ?13.1817 ?13.9136 ?15.4031 -6.17052 ?7.63949 ?9.75870 -9.87326 -5.39661
?46: ? ? 585.19676: ?12.5100 -9.64367 ?10.0254 ?13.1817 ?13.9136 ?15.4031 -6.17052 ?7.63949 ?9.75870 -9.87326 -5.39661
?47: ? ? 585.19676: ?12.5100 -9.64367 ?10.0254 ?13.1817 ?13.9136 ?15.4031 -6.17052 ?7.63949 ?9.75870 -9.87326 -5.39661
?48: ? ? 585.19676: ?12.5100 -9.64367 ?10.0254 ?13.1817 ?13.9136 ?15.4031 -6.17052 ?7.63949 ?9.75870 -9.87326 -5.39661
?49: ? ? 585.19676: ?12.5100 -9.64367 ?10.0254 ?13.1817 ?13.9136 ?15.4031 -6.17052 ?7.63949 ?9.75870 -9.87326 -5.39661
?50: ? ? 585.19676: ?12.5100 -9.64367 ?10.0254 ?13.1817 ?13.9136 ?15.4031 -6.17052 ?7.63949 ?9.75870 -9.87326 -5.39661
?51: ? ? 585.19676: ?12.5100 -9.64367 ?10.0254 ?13.1817 ?13.9136 ?15.4031 -6.17052 ?7.63949 ?9.75870 -9.87326 -5.39661
?52: ? ? 585.19676: ?12.5100 -9.64367 ?10.0254 ?13.1817 ?13.9136 ?15.4031 -6.17052 ?7.63949 ?9.75870 -9.87326 -5.39661
Warning message:
In mer_finalize(ans) : false convergence (8)

I read something on another thread about high values (like the -9.6) being a problem here, but I do not completely understand how to interpret or address it. The model will run, and the results appear highly significant, but I do not know to what extent they can be trusted...in case it is relevant, I am using the 64-bit version of R 2.15.1. ?(I also tried running it in the 32-bit version, with the same outcome.) ?On another thread I also saw a suggestion about maybe trying a development version of R with updates using lme4a(?), but I am not sure where/how I would access that. ?Would this be similar to using the pre-release version of R 3.0?

Any help is greatly appreciated! ?Thank you!! 		 	   		  

From vanni.rovera at gmail.com  Sun Mar 24 09:56:11 2013
From: vanni.rovera at gmail.com (Vanni Rovera)
Date: Sun, 24 Mar 2013 09:56:11 +0100
Subject: [R-sig-ME] Make a 'between-and-within-factors' ANOVA with lmer
	function
Message-ID: <CACd0PJxKXymxieWZtocJ_bHeKQcWk_BBUseWD+jtXAqjTWrjcQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130324/6dcbc5b2/attachment.pl>

From bbolker at gmail.com  Sun Mar 24 17:28:11 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 24 Mar 2013 12:28:11 -0400
Subject: [R-sig-ME] Non-convergence error for GLMM with LME4?
Message-ID: <514F299B.8050604@mcmaster.ca>

[forwarding to r-sig-mixed-models at r-project.org, a more appropriate venue]

Leanna Jones <leanna_jones <at> hotmail.com> writes:

> Hello!  I am trying to run a GLMM using LME4, and keep getting the 
> warning message: "In mer_finalize(ans) : false convergence (8)" I
> am quite new to R, and in looking into this thus far, it appears
> that there are a variety of reasons why this might occur, such as
> needing to standardize some parameters or if all subjects in one
> combination of parameters all have the same outcome.  I also
> understand that the warning does not necessarily mean that the
> model results are invalid, but they might be...however, I am unsure
> how to interpret this in my own situation.  I started with a
> somewhat more complex model, but kept simplifying it to see if I
> could get the warning to go away (so it might indicate which
> predictor variable was the problem...). However, even when using a
> single fixed effect variable (just sex, for instance), I continue
> to have the problem, which makes me think the issue may be with my
> random effect.  Here is the model I would like to run:


mm1=lmer(BinomialOutcome~AgeGroup+Sex+Study.Site+(1|BearID.reformatted),
      family=binomial)

> The study is based on bear captures over a period of time, such
> that some bears are captured only once, while others many times (in
> a very unbalanced fashion); I would like to use all the data, but
> want to account for resampling of specific individuals.  However,
> this means that there are nearly 600 different bear IDs, and I am 
> wondering if this is the reason why the model will not converge?
> If so, what is the best way to address this?  Or other ideas as to
> what might be going on?

Are the covariates distinct for each bear, or do bears change
age group and/or study site over the course of the study?  (Presumably
their sex is fixed ...)  If the former, then you could collapse
the data set to fraction of 'successes' (BinomialOutcome) per bear,
as in

library("plyr")
ddply(dataset,c("AgeGroup","Sex","Study.Site","BearID"),
    summarise, n = length(BinomialOutcome),
    p = mean(BinomialOutcome))

[snip]

Warning message:In mer_finalize(ans) : false convergence (8)

> I read something on another thread about high values (like the
> -9.6) being a problem here, but I do not completely understand how
> to interpret or address it.

> The model will run (those results pasted below), and appear highly
> significant, but I do not know to what extent they can be
> trusted...in case it is relevant, I am using the 64-bit version of
> R 2.15.1.  Any help is greatly appreciated!  Thank you!!

>> summary(mm1)
> Generalized linear mixed model fit by the Laplace approximation 
> Formula: BinomialOutcome ~ AgeGroup + Sex + Study.Site + (1 |
> BearID.reformatted)
  AIC   BIC logLik deviance 607.2 662.7 -292.6    585.2

Random effects: Groups             Name        Variance Std.Dev.
BearID.reformatted (Intercept) 156.5    12.51
Number of obs: 1146, groups: BearID.reformatted, 546
 Fixed effects:       Estimate Std. Error z value Pr(>|z|)
(Intercept)             -9.644     18.171  -0.531  0.59562
AgeGroupMiddle(6-9)     10.025      1.901   5.273 1.34e-07 ***
AgeGroupOld(10-14)      13.182      2.124   6.207 5.38e-10 ***
AgeGroupOlder(15-19)    13.914      2.270   6.129 8.82e-10 ***
AgeGroupOldest(20-29)   15.403      2.553   6.033 1.61e-09 ***
AgeGroupYearling(0-1)   -6.171      2.136  -2.889  0.00387 **
AgeGroupYoung(4-5)       7.639      1.837   4.159 3.20e-05 ***
SexM                     9.759      2.077   4.700 2.61e-06 ***
Study.SiteNorth         -9.873     18.211  -0.542  0.58770
Study.SiteSouth         -5.397     18.120  -0.298  0.76584

The large-magnitude estimates are mostly due to the fact that
your baseline group (which is presumably the 2-3 year old, female
individuals) has a very low success probability, and that there
are very wide differences in success overall --  from a probability
of 0.0001 in the baseline group (1/(1+exp(9)))= plogis(-9)
to perhaps 99% in the oldest group (plogis(-9+15)). The large
standard errors (18 for the intercept and study site effects)
also indicate that the Hauck-Donner effect, where extreme values
are poorly tested by the default Wald test, is operating.

It would probably be easier to interpret your results if you
reorder the AgeGroup factor so that the order actually corresponds
to age, rather than alphabetical ... then you might want to use
contr.sum (or contr.Sum from the car package) to set the baseline
to the mean across treatments, which will make the effects _slightly_
less extreme (although not much less, since there is a difference
of 21 logit units between the youngest and oldest groups).  (With
about 1200 observations, you must have perfect separation, with
zero successes in the younger groups and 100% in the older groups.)

drop1(mm1,test="Chi")
Single term deletions
Model:BinomialOutcome ~ AgeGroup + Sex + Study.Site +
  (1 | BearID.reformatted)
           Df    AIC    LRT   Pr(Chi)
<none>        607.20
AgeGroup    6 992.46 397.27 < 2.2e-16 ***
Sex         1 643.17  37.97 7.190e-10 ***
Study.Site  2 626.79  23.60 7.522e-06 ***

So the basic story here (which should be backed up by looking
at your data) is that you have very

If you want to try this out with the development version of lme4,

install.packages("lme4",repos="http://lme4.r-forge.r-project.org")

should work ...

  It would be nice to use some form of regularization on this
(e.g. set some priors or penalization on the parameters) -- you
can do this via AD Model Builder or WinBUGS, or possibly via
the blme package ....)

  good luck,
   Ben Bolker


From i.m.s.white at ed.ac.uk  Sun Mar 24 18:12:58 2013
From: i.m.s.white at ed.ac.uk (ian m s white)
Date: Sun, 24 Mar 2013 17:12:58 +0000
Subject: [R-sig-ME] Make a 'between-and-within-factors' ANOVA with lmer
	function
In-Reply-To: <CACd0PJxKXymxieWZtocJ_bHeKQcWk_BBUseWD+jtXAqjTWrjcQ@mail.gmail.com>
References: <CACd0PJxKXymxieWZtocJ_bHeKQcWk_BBUseWD+jtXAqjTWrjcQ@mail.gmail.com>
Message-ID: <DA60DB44-8E80-46DB-B43B-EB00EF638F2E@ed.ac.uk>

I reckon lmer can figure out for itself what is between and what is within subjects, so

lmer(DV ~ IV1*IV2*IV3*IV4 + (1|Subject))

should fit the same model as your ANOVA.


On 24 Mar 2013, at 08:56, Vanni Rovera <vanni.rovera at gmail.com> wrote:

> Hi there,
> 
> I'm trying to understand how to use the function lmer in order to do a
> 'between-and-within-factors' ANOVA, but without any success. I know about
> the usage of the function aov, but this holds only for balanced designs;
> its documentation say to use lme function (package nlme) for unbalanced
> designs. Furthermore I found the lmer function (package lme4) is an
> evolution of lme, so I wish to use this last function in order to perform
> my ANOVA. But I'm not able to understand how to do this.
> 
> More precisely, imagine you have a dependent variable DV and four
> independent variables IV1, IV2, IV3, IV4, where IV1, IV2 are
> between-factors and IV3, IV4 are within-factors. Moreover you have a
> variable called Subject in order to identify the subject on which
> measurements are done (like for example this dataset:
> http://personality-project.org/r/datasets/R.appendix5.data). If I use the
> aov function, my 'between-and-within-factors' ANOVA would stand as follows:
> 
> aov(DV~(IV1*IV2*IV3*IV4)+Error(Subject/(IV3*IV4))).
> 
> Now can you write me the precise syntax in order to obtain the same result
> with the lmer function?
> 
> Thanks a lot in advance!
> Vanni Rovera
> 
> 
> 
> *Additional details:* The problem is that no one seems to be interested in
> explain the relations of 'within-factor' and 'between-factor' concepts with
> those of 'fixed-effect' and 'random-effect'. Textbooks and papers about
> ANOVA talk about between and within factors, while documentations and
> papers about lmer function talk about mixed-effects models, i.e. they talk
> about fixed and random effects, without mentioning between and within
> factors. *Thus I am not able to understand the relations between the two,
> since I think they are completely uncorrelated each others, and hence I am
> not able to use the syntax in lmer in order to distinguish between factors
> from within factors.*
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From bbolker at gmail.com  Sun Mar 24 23:02:16 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 24 Mar 2013 22:02:16 +0000 (UTC)
Subject: [R-sig-ME]
	=?utf-8?q?Make_a_=27between-and-within-factors=27_ANOV?=
	=?utf-8?q?A_with_lmer=09function?=
References: <CACd0PJxKXymxieWZtocJ_bHeKQcWk_BBUseWD+jtXAqjTWrjcQ@mail.gmail.com>
	<DA60DB44-8E80-46DB-B43B-EB00EF638F2E@ed.ac.uk>
Message-ID: <loom.20130324T204802-986@post.gmane.org>

ian m s white <i.m.s.white at ...> writes:

> 
> I reckon lmer can figure out for itself what is between and what is within
subjects, so
> 
> lmer(DV ~ IV1*IV2*IV3*IV4 + (1|Subject))
> 
> should fit the same model as your ANOVA.

  If you want to allow for variation in the IV3 and IV4 effects among
subjects you might want

lmer(DV ~ IV1*IV2*IV3*IV4 + (IV3*IV4|Subject))

  You might want to use lme rather than lme4 for the purposes of
getting calculated denominator df and p-values, which lmer won't
give you ...
 
> On 24 Mar 2013, at 08:56, Vanni Rovera <vanni.rovera at ...> wrote:
> 
> > Hi there,
> > 
> > I'm trying to understand how to use the function lmer in order to do a
> > 'between-and-within-factors' ANOVA, but without any success. I know about
> > the usage of the function aov, but this holds only for balanced designs;
> > its documentation say to use lme function (package nlme) for unbalanced
> > designs. Furthermore I found the lmer function (package lme4) is an
> > evolution of lme, so I wish to use this last function in order to perform
> > my ANOVA. But I'm not able to understand how to do this.
> > 
> > More precisely, imagine you have a dependent variable DV and four
> > independent variables IV1, IV2, IV3, IV4, where IV1, IV2 are
> > between-factors and IV3, IV4 are within-factors. Moreover you have a
> > variable called Subject in order to identify the subject on which
> > measurements are done (like for example this dataset:
> > http://personality-project.org/r/datasets/R.appendix5.data). If I use the
> > aov function, my 'between-and-within-factors' ANOVA would stand as follows:
> > 
> > aov(DV~(IV1*IV2*IV3*IV4)+Error(Subject/(IV3*IV4))).
> > 
> > Now can you write me the precise syntax in order to obtain the same result
> > with the lmer function?

  [snip]

> > 
> > *Additional details:* The problem is that no one seems to be interested in
> > explain the relations of 'within-factor' and 'between-factor' concepts with
> > those of 'fixed-effect' and 'random-effect'. Textbooks and papers about
> > ANOVA talk about between and within factors, while documentations and
> > papers about lmer function talk about mixed-effects models, i.e. they talk
> > about fixed and random effects, without mentioning between and within
> > factors. *Thus I am not able to understand the relations between the two,
> > since I think they are completely uncorrelated each others, and hence I am
> > not able to use the syntax in lmer in order to distinguish between factors
> > from within factors.*

   I would like to understand this better too.  I started to work
on an example but haven't finished.

lmer/ANOVA comparison
========================================================

```{r}
dat <-
read.table(url("http://personality-project.org/r/datasets/R.appendix5.data"),header=TRUE)
```

```{r}
library("ggplot2")
ggplot(dat,aes(x=Valence,y=Recall,colour=Dosage))+geom_point()+
  facet_grid(Gender~Task,labeller=label_both)+geom_line(aes(group=Subject))
```

```{r}
a1 <- aov(Recall~Task*Gender*Valence*Dosage+
             Error(Subject/(Task*Valence)),
    data=dat)
summary(a1)
```


```{r}
with(dat,table(Task,Valence,Dosage,Subject))
```{r}
library("nlme")
dat <- transform(dat,TaskValence=interaction(Task,Valence))
anova(lme(Recall~Task*Gender*Valence*Dosage,
       random=~1|Subject/TaskValence,
       data=dat))
```


From kburls at unr.edu  Mon Mar 25 04:27:00 2013
From: kburls at unr.edu (Kevin Burls)
Date: Mon, 25 Mar 2013 03:27:00 +0000
Subject: [R-sig-ME] glmmadmb
Message-ID: <A7D56774-B1CF-4AC6-ACA3-5F8E4C1170E7@unr.edu>

Hi all-
I am comparing dispersal distributions from an artificial selection experiment on movement that contains replicated lines within two treatments over many generations. I'm actually not measuring movement in this particular case, but the placement of eggs by the organism as it moved within a generation. Thus, the (discrete) response data are the distance of eggs from a starting location. The dataset is fairly large (207,753 rows).  The data appear approximately poisson-distributed, and I am concerned about overdispersion as I am I was specifically selecting on the tail of the curve. I have already done a glmm with a poisson distribution but would like to try using the negative binomial. I have read glmmadmb is the way to model this but I run into the following error:

> dist.glmer<-glmmadmb(distance~treatment*generation,data=fullexpansion,family="nbinom",link="log",random=~1|line)
Need to increase the maximum number of separable calls allowed to at least 20001
Current value is 20000
Use the -ndi N command line option
Error in glmmadmb(distance ~ treatment * generation, data = fullexpansion,  : 
  The function maximizer failed (couldn't find STD file) Troubleshooting steps include (1) run with 'save.dir' set and inspect output files; (2) change run parameters: see '?admbControl'
In addition: Warning message:
running command './glmmadmb -maxfn 500 -maxph 5 -noinit -shess' had status 1 

This seems to be a size issue but perhaps it is something else? Is there a workaround for this or should I just attempt another method like quasilikelihood estimation?

Thanks for your help-
Kevin Burls


Kevin Burls
Ph.D. candidate
EECB Program
University of Nevada, Reno
kburls at unr.edu
http://wolfweb.unr.edu/~kburls


From bburan at galenea.com  Mon Mar 25 15:11:19 2013
From: bburan at galenea.com (Brad Buran)
Date: Mon, 25 Mar 2013 14:11:19 +0000
Subject: [R-sig-ME] determining whether factor is significant in linear
	mixed models
Message-ID: <3A447989F1B70245B88AF76E028FF860503181@DAGN01A-E6.exg6.exghost.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130325/04a1c97c/attachment.pl>

From davef at otter-rsch.com  Mon Mar 25 05:32:27 2013
From: davef at otter-rsch.com (dave fournier)
Date: Sun, 24 Mar 2013 21:32:27 -0700
Subject: [R-sig-ME] glmmadmb
In-Reply-To: <A7D56774-B1CF-4AC6-ACA3-5F8E4C1170E7@unr.edu>
References: <A7D56774-B1CF-4AC6-ACA3-5F8E4C1170E7@unr.edu>
Message-ID: <514FD35B.5050808@otter-rsch.com>

As it says run it with a custom command line option like

  -ndi 40000

increase until it is happy


From ludovicofrate at hotmail.it  Mon Mar 25 12:26:37 2013
From: ludovicofrate at hotmail.it (Ludovico Frate)
Date: Mon, 25 Mar 2013 12:26:37 +0100
Subject: [R-sig-ME] lme4 help
Message-ID: <DUB002-W1557291C400C373E9501455D6D70@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130325/a9482e8a/attachment.pl>

From lborger at cebc.cnrs.fr  Mon Mar 25 15:44:37 2013
From: lborger at cebc.cnrs.fr (lborger)
Date: Mon, 25 Mar 2013 15:44:37 +0100
Subject: [R-sig-ME] determining whether factor is significant in
	linear	mixed models
In-Reply-To: <3A447989F1B70245B88AF76E028FF860503181@DAGN01A-E6.exg6.exghost.com>
References: <3A447989F1B70245B88AF76E028FF860503181@DAGN01A-E6.exg6.exghost.com>
Message-ID: <WC20130325144437.86027B@cebc.cnrs.fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130325/a79d8426/attachment.pl>

From brady.steven at gmail.com  Mon Mar 25 16:03:11 2013
From: brady.steven at gmail.com (Steven Brady)
Date: Mon, 25 Mar 2013 11:03:11 -0400
Subject: [R-sig-ME] determining whether factor is significant in linear
 mixed models
In-Reply-To: <WC20130325144437.86027B@cebc.cnrs.fr>
References: <3A447989F1B70245B88AF76E028FF860503181@DAGN01A-E6.exg6.exghost.com>
	<WC20130325144437.86027B@cebc.cnrs.fr>
Message-ID: <CANAi2WJHnfh9jKGHH=OBRUbgFfVbRR+we87o4sV68D-VGAO17A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130325/b52a92ac/attachment.pl>

From Giovanni.Mancuso at iit.it  Mon Mar 25 17:43:26 2013
From: Giovanni.Mancuso at iit.it (Giovanni Mancuso)
Date: Mon, 25 Mar 2013 16:43:26 +0000
Subject: [R-sig-ME] complete separation problem lmer
Message-ID: <5A9D7CD8AA3C174FB330AB0125CCEA63012176@IITMXWGE012.iit.local>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130325/08fe55cb/attachment.pl>

From bates at stat.wisc.edu  Mon Mar 25 18:23:28 2013
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 25 Mar 2013 12:23:28 -0500
Subject: [R-sig-ME] Request for large data sets for linear mixed models
Message-ID: <CAO7JsnRMwSRRs-iYDjwB-=5OvgdbM7=1_H9vY65R2gb_a3xzxw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130325/e4207162/attachment.pl>

From kw.stat at gmail.com  Mon Mar 25 18:35:29 2013
From: kw.stat at gmail.com (Kevin Wright)
Date: Mon, 25 Mar 2013 12:35:29 -0500
Subject: [R-sig-ME] Request for large data sets for linear mixed models
In-Reply-To: <CAO7JsnRMwSRRs-iYDjwB-=5OvgdbM7=1_H9vY65R2gb_a3xzxw@mail.gmail.com>
References: <CAO7JsnRMwSRRs-iYDjwB-=5OvgdbM7=1_H9vY65R2gb_a3xzxw@mail.gmail.com>
Message-ID: <CAKFxdiRkCOxnyOe8R93RBe_xLuSWNvddBT9Or=1WgPQg_F-GwQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130325/9e74c24d/attachment.pl>

From bates at stat.wisc.edu  Mon Mar 25 18:55:31 2013
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 25 Mar 2013 12:55:31 -0500
Subject: [R-sig-ME] Request for large data sets for linear mixed models
In-Reply-To: <CAKFxdiRkCOxnyOe8R93RBe_xLuSWNvddBT9Or=1WgPQg_F-GwQ@mail.gmail.com>
References: <CAO7JsnRMwSRRs-iYDjwB-=5OvgdbM7=1_H9vY65R2gb_a3xzxw@mail.gmail.com>
	<CAKFxdiRkCOxnyOe8R93RBe_xLuSWNvddBT9Or=1WgPQg_F-GwQ@mail.gmail.com>
Message-ID: <CAO7JsnTn0LL_nsE+51OS2Pf83hQm3r_+mPDhKfooE3FTu4D_Qg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130325/31d12c57/attachment.pl>

From steve.walker at utoronto.ca  Mon Mar 25 20:17:26 2013
From: steve.walker at utoronto.ca (Steve Walker)
Date: Mon, 25 Mar 2013 15:17:26 -0400
Subject: [R-sig-ME] complete separation problem lmer
In-Reply-To: <5A9D7CD8AA3C174FB330AB0125CCEA63012176@IITMXWGE012.iit.local>
References: <5A9D7CD8AA3C174FB330AB0125CCEA63012176@IITMXWGE012.iit.local>
Message-ID: <5150A2C6.5070806@utoronto.ca>

Vincent Dorie's blme package is an extension of lme4, with Bayesian 
point estimation.  It should be able to help with complete separation, 
if you are willing to use weakly-informative prior distributions.

Steve.

On 2013-03-25 12:43 PM, Giovanni Mancuso wrote:
> Hello Everybody,
>
> I'm dealing with the complete separation problem in a probit regression model.
> As I understand there's an R package (brglm) that implements a bias-reduced estimate for GLMs.
>
> Is there anything similar that works with lmer() function?
> I wish to use lmer() function instead of glm(), but I'm not quite sure if it's possible and how to do it.
>
> Many thanks
> Giovanni
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From ramos.grad.student at gmail.com  Tue Mar 26 01:12:56 2013
From: ramos.grad.student at gmail.com (Antonio P. Ramos)
Date: Mon, 25 Mar 2013 17:12:56 -0700
Subject: [R-sig-ME] MCMCglmm predictions with fixed effects Splines
Message-ID: <CAHawB9t4oo-ZkN0a-W2BW9hELcsdP+HvKxvsMo1TEqu7nYqhjg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130325/b1ff9074/attachment.pl>

From ramos.grad.student at gmail.com  Tue Mar 26 01:14:53 2013
From: ramos.grad.student at gmail.com (Antonio P. Ramos)
Date: Mon, 25 Mar 2013 17:14:53 -0700
Subject: [R-sig-ME] MCMCglmm predictions with fixed effects Splines
In-Reply-To: <CAHawB9t4oo-ZkN0a-W2BW9hELcsdP+HvKxvsMo1TEqu7nYqhjg@mail.gmail.com>
References: <CAHawB9t4oo-ZkN0a-W2BW9hELcsdP+HvKxvsMo1TEqu7nYqhjg@mail.gmail.com>
Message-ID: <CAHawB9vaomkazoVRdO2RsZzQLDkDdEa6FBCcD7bzEqeXL66r+Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130325/c1cce567/attachment.pl>

From jwiley.psych at gmail.com  Tue Mar 26 02:30:53 2013
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Mon, 25 Mar 2013 18:30:53 -0700
Subject: [R-sig-ME] MCMCglmm predictions with fixed effects Splines
In-Reply-To: <CANz9Z_KwmqmNkrG4fCLr_CEtrRFqySaxO-Nhd9HZNFAJLFxmiw@mail.gmail.com>
References: <CAHawB9t4oo-ZkN0a-W2BW9hELcsdP+HvKxvsMo1TEqu7nYqhjg@mail.gmail.com>
	<CAHawB9vaomkazoVRdO2RsZzQLDkDdEa6FBCcD7bzEqeXL66r+Q@mail.gmail.com>
	<CANz9Z_KwmqmNkrG4fCLr_CEtrRFqySaxO-Nhd9HZNFAJLFxmiw@mail.gmail.com>
Message-ID: <CANz9Z_LjxJfpidzkG5cPnZfsB=Gx5Zr0XsC-f1jbMb7bAF9iSA@mail.gmail.com>

 Realized it may not be clear how to extract the design matrix:

model$X

it is stored in the X element of the model

On Mon, Mar 25, 2013 at 6:25 PM, Joshua Wiley <jwiley.psych at gmail.com> wrote:
> Hi Antonio,
>
> Have you looked at the documentation for spl?  The default is quantile
> smooths.  If you read Simon Wood's book, it provides much more detail
> on how smooths are constructed from basis functions.
>
> In particular, from the docs, that is not functioning as a smooth term
> in gam (which you recently posted about on Rhelp so I assume you are
> familiar with), where the approximate df are estimated using thin
> plate splines, but it is fixed at 10, (the default k parameter).
> Anyway, you cannot simply feed the same birth year values to every one
> of the smooth parameters and use those.  You need to create the proper
> model matrix based on the data to be predicted from.  Extract the
> design matrix from your MCMCglmm object, and you may find that
> instructive.
>
> After you have tried that, if you are still struggling, email back or
> since you are at UCLA, you can come to the UCLA IDRE statistical
> consulting group where I or Neal can help you set it up :)
>
> Cheers,
>
> Josh
>
>
> On Mon, Mar 25, 2013 at 5:14 PM, Antonio P. Ramos
> <ramos.grad.student at gmail.com> wrote:
>> maybe the model's summary would also help:
>>
>>> summary(glm.MC.2)
>>
>>  Iterations = 1001:19991
>>  Thinning interval  = 10
>>  Sample size  = 1900
>>
>>  DIC: 23202.78
>>
>>  G-structure:  ~CASEID
>>
>>        post.mean l-95% CI u-95% CI eff.samp
>> CASEID     1.008   0.8508    1.139    73.88
>>
>>  R-structure:  ~units
>>
>>       post.mean l-95% CI u-95% CI eff.samp
>> units         1        1        1        0
>>
>>  Location effects: mortality.under.2 ~ maternal_age_c + I(maternal_age_c^2)
>> + spl(birth_year) + residence + maternal_educ + sex + wealth
>>
>>                            post.mean   l-95% CI   u-95% CI eff.samp   pMCMC
>>
>> (Intercept)               -2.2844882 -4.0378822 -0.5243228    270.8 0.00947
>> **
>> maternal_age_c            -0.0278874 -0.0396679 -0.0169772    409.5 < 5e-04
>> ***
>> I(maternal_age_c^2)        0.0067512  0.0040534  0.0096366    369.2 < 5e-04
>> ***
>> spl(birth_year)1          -0.0069841 -0.0172375  0.0024631    387.8 0.15789
>>
>> spl(birth_year)2           0.0257588  0.0003497  0.0511228    425.9 0.05474
>> .
>> spl(birth_year)3          -0.0251424 -0.0871379  0.0381827    376.8 0.41368
>>
>> spl(birth_year)4          -0.0451816 -0.1068456  0.0188489    315.1 0.17895
>>
>> spl(birth_year)5          -0.0506369 -0.1256510  0.0256118    325.8 0.20737
>>
>> spl(birth_year)6           0.0571108 -0.0450529  0.1564138    229.7 0.25368
>>
>> spl(birth_year)7          -0.0993668 -0.1830175 -0.0135886    275.6 0.01474
>> *
>> spl(birth_year)8          -0.0812237 -0.1417047 -0.0322527    273.6 0.00316
>> **
>> spl(birth_year)9           0.0626604  0.0448635  0.0797381    300.8 < 5e-04
>> ***
>> spl(birth_year)10         -0.0148629 -0.0234434 -0.0054245    387.5 0.00105
>> **
>> residenceUrban            -0.2141484 -0.3716601 -0.0511390    280.1 0.00947
>> **
>> maternal_educNo education  1.0334332  0.1228220  2.0524150    207.8 0.03263
>> *
>> maternal_educPrimary       0.7954471 -0.1554284  1.7616937    206.3 0.10316
>>
>> maternal_educSecondary    -0.0083354 -0.9622503  1.0182426    195.0 0.98000
>>
>> sexMale                    0.1893753  0.1072094  0.2710264    275.2 < 5e-04
>> ***
>> wealthSecond quintile      0.1773074  0.0444755  0.3283123    398.4 0.01368
>> *
>> wealthMiddle quintile     -0.0667648 -0.2060366  0.0676636    376.9 0.34316
>>
>> wealthFourth quintile      0.0485797 -0.0913787  0.1942995    416.2 0.47579
>>
>> wealthHighest quintile    -0.1339028 -0.3017483  0.0077947    338.2 0.08000
>> .
>> ---
>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>
>>
>>
>>
>>
>> On Mon, Mar 25, 2013 at 5:12 PM, Antonio P. Ramos <
>> ramos.grad.student at gmail.com> wrote:
>>
>>> Hi all,
>>>
>>> I am trying to get some predictions from a MCMCglmm model but it is not
>>> working. I guess I don't really following what the model is doing with tje
>>> spl() command. Here is an example of the issue.
>>>
>>> Thanks a bunch
>>>
>>>
>>>
>>> # inve.wishart(V=1,nu=4) is equivalent to inv-gamma(shape=2,scale=2) for
>>> mothers random effects
>>> prior.2 <- list(R = list(V = 1, fix = 1), G = list(G1 = list(V = 1,nu =
>>> 4)))
>>> glm.MC.2 <- MCMCglmm(mortality.under.2 ~ maternal_age_c +
>>> I(maternal_age_c^2)  +
>>>                        spl(birth_year) + residence + maternal_educ +
>>>                        sex + wealth,
>>>                      nitt=20000, thin=10, burnin=1000,
>>>                      random= ~CASEID, prior=prior.2,data=rwanda2,
>>> family='categorical')
>>>
>>>
>>> > # creating new data for the poor
>>> > pred.data <- data.frame(maternal_age_c=rep(18,25),wealth=rep("Lowest
>>> quintile",25),
>>> +                         sex=rep("Female",25),residence=rep("Rural",25),
>>> +                         "spl(birth_year)1"=1971:1995,
>>> +                         "spl(birth_year)2"=1971:1995,
>>> +                         "spl(birth_year)3"=1971:1995,
>>> +                         "spl(birth_year)4"=1971:1995,
>>> +                         "spl(birth_year)5"=1971:1995,
>>> +                         "spl(birth_year)6"=1971:1995,
>>> +                         "spl(birth_year)7"=1971:1995,
>>> +                         "spl(birth_year)8"=1971:1995,
>>> +                         "spl(birth_year)9"=1971:1995,
>>> +                         "spl(birth_year)10"=1971:1995,
>>> +                         birth_order=rep(1,25),
>>> +                         maternal_educ=rep("No education",25))
>>> >
>>> > pred.data$wealth <- factor(pred.data$wealth,
>>> +                            levels=c("Lowest quintile", "Second
>>> quintile","Middle quintile","Fourth quintile","Highest quintile"))
>>> > pred.data$sex <- factor(pred.data$sex, levels=c("Male","Female"))
>>> > pred.data$residence <-
>>> factor(pred.data$residence,levels=c("Rural","Urban"))
>>> > # pred.data$birth_year <- factor(pred.data$birth_year, levels=1970:1997)
>>> > pred.data$maternal_educ <- factor(pred.data$maternal_educ,
>>> +                                   levels=c("No education", "Primary",
>>> "Secondary","Higher"))
>>> >
>>> >
>>> > # design matrix
>>> > X <- model.matrix(~ maternal_age_c + I(maternal_age_c^2) + residence +
>>> +                       + maternal_educ +
>>> +                       birth_order +  wealth +
>>> +                       spl.birth_year.1  +
>>> +                       spl.birth_year.2  +
>>> +                       spl.birth_year.3  +
>>> +                       spl.birth_year.4  +
>>> +                       spl.birth_year.5  +
>>> +                       spl.birth_year.6  +
>>> +                       spl.birth_year.7  +
>>> +                       spl.birth_year.8  +
>>> +                       spl.birth_year.9  +
>>> +                       spl.birth_year.10, data=pred.data)
>>> >
>>> >
>>> > V <- rowSums(glm.MC.2$VCV) # marginalizing over random effects
>>> > beta <- glm.MC.2$Sol # fixed effects
>>> > c2 <- (16*sqrt(3)/(15*pi))^2 # alterative parametrization for the
>>> logistic distribution
>>> > pred<- t(plogis(t(beta%*%t(X)/sqrt(1+c2*V))))
>>> > pred <- as.data.frame(pred)
>>> > colnames(pred) <- 1971:1995 # predictions for the poor for every year
>>> > colSums(pred)
>>>     1971     1972     1973     1974     1975     1976     1977     1978
>>>   1979     1980     1981     1982     1983
>>> 1677.094 1677.093 1677.093 1677.093 1677.093 1677.093 1677.093 1677.093
>>> 1677.093 1677.093 1677.093 1677.093 1677.093
>>>     1984     1985     1986     1987     1988     1989     1990     1991
>>>   1992     1993     1994     1995
>>> 1677.092 1677.092 1677.092 1677.092 1677.092 1677.092 1677.092 1677.092
>>> 1677.092 1677.092 1677.092 1677.092
>>> >
>>>
>>
>>         [[alternative HTML version deleted]]
>>
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>
>
> --
> Joshua Wiley
> Ph.D. Student, Health Psychology
> University of California, Los Angeles
> http://joshuawiley.com/
> Senior Analyst - Elkhart Group Ltd.
> http://elkhartgroup.com



-- 
Joshua Wiley
Ph.D. Student, Health Psychology
University of California, Los Angeles
http://joshuawiley.com/
Senior Analyst - Elkhart Group Ltd.
http://elkhartgroup.com


From ramos.grad.student at gmail.com  Tue Mar 26 03:57:51 2013
From: ramos.grad.student at gmail.com (Antonio P. Ramos)
Date: Mon, 25 Mar 2013 19:57:51 -0700
Subject: [R-sig-ME] MCMCglmm predictions with fixed effects Splines
In-Reply-To: <CAHawB9vaomkazoVRdO2RsZzQLDkDdEa6FBCcD7bzEqeXL66r+Q@mail.gmail.com>
References: <CAHawB9t4oo-ZkN0a-W2BW9hELcsdP+HvKxvsMo1TEqu7nYqhjg@mail.gmail.com>
	<CAHawB9vaomkazoVRdO2RsZzQLDkDdEa6FBCcD7bzEqeXL66r+Q@mail.gmail.com>
Message-ID: <CAHawB9t8TFxJuw+_1O4XXKzkWHT-hSxpDWGq3LBwRQtQLORG3Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130325/2a5daa7f/attachment.pl>

From Andrew.McFadden at mpi.govt.nz  Tue Mar 26 04:29:10 2013
From: Andrew.McFadden at mpi.govt.nz (Andrew McFadden (Andy))
Date: Tue, 26 Mar 2013 03:29:10 +0000
Subject: [R-sig-ME] mixed model negative bionomial
Message-ID: <59311B7BAD60F14E99B53F85C5413E221CE38A24@WDCWASP435.network.maf.govt.nz>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130326/2f6982ee/attachment.pl>

From j.hadfield at ed.ac.uk  Tue Mar 26 10:38:24 2013
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Tue, 26 Mar 2013 09:38:24 +0000
Subject: [R-sig-ME] MCMCglmm predictions with fixed effects Splines
In-Reply-To: <CAHawB9t8TFxJuw+_1O4XXKzkWHT-hSxpDWGq3LBwRQtQLORG3Q@mail.gmail.com>
References: <CAHawB9t4oo-ZkN0a-W2BW9hELcsdP+HvKxvsMo1TEqu7nYqhjg@mail.gmail.com>
	<CAHawB9vaomkazoVRdO2RsZzQLDkDdEa6FBCcD7bzEqeXL66r+Q@mail.gmail.com>
	<CAHawB9t8TFxJuw+_1O4XXKzkWHT-hSxpDWGq3LBwRQtQLORG3Q@mail.gmail.com>
Message-ID: <20130326093824.200412s3nglul7rk@www.staffmail.ed.ac.uk>

Hi,

Check out the examples in ?spl: you haven't fitted a penalised spline.  
You probably want something like:

glm.MC.2 <- MCMCglmm(mortality.under.2 ~ maternal_age_c +  
I(maternal_age_c^2)  + birth_year + residence + maternal_educ +
sex + wealth, nitt=20000, thin=10, burnin=1000,random=  
~idv(spl(birdth_year))+CASEID,  
prior=prior.2,data=rwanda2,family='categorical', pr=TRUE)

Note that I have saved the random effects (pr=TRUE) because the first  
k random effects are the spline coefficients. You will need to  
associate these with the relevant columns of Z (rather than X) to get  
predictions. Remember to include the fixed birth_year effect too.

Cheers,

Jarrod


Quoting "Antonio P. Ramos" <ramos.grad.student at gmail.com> on Mon, 25  
Mar 2013 19:57:51 -0700:

> I think I get what is going on a little better now. Does it make sense?
>
> # getting the predictions
> # where the nots are?
> k <- 10
> x <- quantile(rwanda2$birth_year, 1:k/(k + 1), na.rm = T)
> y <- unique(rwanda2$birth_year)
>
> # creating new data for the poor
> pred.data <- data.frame(maternal_age_c=rep(0,28),wealth=rep("Lowest
> quintile",28),
>                         sex=rep("Female",28),residence=rep("Rural",28),
>                         "spl(birth_year)1"=ifelse(y<1976,1,0),
>                         "spl(birth_year)2"=ifelse(y>1975&y<1979,1,0),
>                         "spl(birth_year)3"=ifelse(y>1978&y<1981,1,0),
>                         "spl(birth_year)4"=ifelse(y>1980&y<1983,1,0),
>                         "spl(birth_year)5"=ifelse(y>1982&y<1985,1,0),
>                         "spl(birth_year)6"=ifelse(y>=1984&y<1988,1,0),
>                         "spl(birth_year)7"=ifelse(y>=1987&y<=1990,1,0),
>                         "spl(birth_year)8"=ifelse(y>1989&y<1993,1,0),
>                         "spl(birth_year)9"=ifelse(y>1993&y<1996,1,0),
>                         "spl(birth_year)10"=ifelse(y>1995,1,0),
>                         birth_order=rep(1,28),
>                         maternal_educ=rep("No education",28))
>
> pred.data$wealth <- factor(pred.data$wealth,
>                            levels=c("Lowest quintile", "Second
> quintile","Middle quintile","Fourth quintile","Highest quintile"))
> pred.data$sex <- factor(pred.data$sex, levels=c("Male","Female"))
> pred.data$residence <- factor(pred.data$residence,levels=c("Rural","Urban"))
> pred.data$maternal_educ <- factor(pred.data$maternal_educ,
>                                   levels=c("No education", "Primary",
> "Secondary","Higher"))
>
>
> # design matrix
> X <- model.matrix(~ maternal_age_c + I(maternal_age_c^2) + residence +
>                      + maternal_educ +
>                     birth_order +  wealth +
>                     spl.birth_year.1  +
>                     spl.birth_year.2  +
>                     spl.birth_year.3  +
>                     spl.birth_year.4  +
>                     spl.birth_year.5  +
>                     spl.birth_year.6  +
>                     spl.birth_year.7  +
>                     spl.birth_year.8  +
>                     spl.birth_year.9  +
>                     spl.birth_year.10, data=pred.data)
>
>
> V <- rowSums(glm.MC.2$VCV) # marginalizing over random effects
> beta <- glm.MC.2$Sol # fixed effects
> c2 <- (16*sqrt(3)/(15*pi))^2 # alterative parametrization for the logistic
> distribution
> pred<- t(plogis(t(beta%*%t(X)/sqrt(1+c2*V))))
> pred <- as.data.frame(pred)
> colnames(pred) <- 1970:1997 # predictions for the poor for every year
> colSums(pred)
> pred.poor <- pred
>
>
>
> On Mon, Mar 25, 2013 at 5:14 PM, Antonio P. Ramos <
> ramos.grad.student at gmail.com> wrote:
>
>> maybe the model's summary would also help:
>>
>> > summary(glm.MC.2)
>>
>>  Iterations = 1001:19991
>>  Thinning interval  = 10
>>  Sample size  = 1900
>>
>>  DIC: 23202.78
>>
>>  G-structure:  ~CASEID
>>
>>        post.mean l-95% CI u-95% CI eff.samp
>> CASEID     1.008   0.8508    1.139    73.88
>>
>>  R-structure:  ~units
>>
>>       post.mean l-95% CI u-95% CI eff.samp
>> units         1        1        1        0
>>
>>  Location effects: mortality.under.2 ~ maternal_age_c +
>> I(maternal_age_c^2) + spl(birth_year) + residence + maternal_educ + sex +
>> wealth
>>
>>                            post.mean   l-95% CI   u-95% CI eff.samp
>> pMCMC
>> (Intercept)               -2.2844882 -4.0378822 -0.5243228    270.8
>> 0.00947 **
>> maternal_age_c            -0.0278874 -0.0396679 -0.0169772    409.5 <
>> 5e-04 ***
>> I(maternal_age_c^2)        0.0067512  0.0040534  0.0096366    369.2 <
>> 5e-04 ***
>> spl(birth_year)1          -0.0069841 -0.0172375  0.0024631    387.8
>> 0.15789
>> spl(birth_year)2           0.0257588  0.0003497  0.0511228    425.9
>> 0.05474 .
>> spl(birth_year)3          -0.0251424 -0.0871379  0.0381827    376.8
>> 0.41368
>> spl(birth_year)4          -0.0451816 -0.1068456  0.0188489    315.1
>> 0.17895
>> spl(birth_year)5          -0.0506369 -0.1256510  0.0256118    325.8
>> 0.20737
>> spl(birth_year)6           0.0571108 -0.0450529  0.1564138    229.7
>> 0.25368
>> spl(birth_year)7          -0.0993668 -0.1830175 -0.0135886    275.6
>> 0.01474 *
>> spl(birth_year)8          -0.0812237 -0.1417047 -0.0322527    273.6
>> 0.00316 **
>> spl(birth_year)9           0.0626604  0.0448635  0.0797381    300.8 <
>> 5e-04 ***
>> spl(birth_year)10         -0.0148629 -0.0234434 -0.0054245    387.5
>> 0.00105 **
>> residenceUrban            -0.2141484 -0.3716601 -0.0511390    280.1
>> 0.00947 **
>> maternal_educNo education  1.0334332  0.1228220  2.0524150    207.8
>> 0.03263 *
>> maternal_educPrimary       0.7954471 -0.1554284  1.7616937    206.3
>> 0.10316
>> maternal_educSecondary    -0.0083354 -0.9622503  1.0182426    195.0
>> 0.98000
>> sexMale                    0.1893753  0.1072094  0.2710264    275.2 <
>> 5e-04 ***
>> wealthSecond quintile      0.1773074  0.0444755  0.3283123    398.4
>> 0.01368 *
>> wealthMiddle quintile     -0.0667648 -0.2060366  0.0676636    376.9
>> 0.34316
>> wealthFourth quintile      0.0485797 -0.0913787  0.1942995    416.2
>> 0.47579
>> wealthHighest quintile    -0.1339028 -0.3017483  0.0077947    338.2
>> 0.08000 .
>> ---
>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>
>>
>>
>>
>>
>> On Mon, Mar 25, 2013 at 5:12 PM, Antonio P. Ramos <
>> ramos.grad.student at gmail.com> wrote:
>>
>>> Hi all,
>>>
>>> I am trying to get some predictions from a MCMCglmm model but it is not
>>> working. I guess I don't really following what the model is doing with tje
>>> spl() command. Here is an example of the issue.
>>>
>>> Thanks a bunch
>>>
>>>
>>>
>>> # inve.wishart(V=1,nu=4) is equivalent to inv-gamma(shape=2,scale=2) for
>>> mothers random effects
>>> prior.2 <- list(R = list(V = 1, fix = 1), G = list(G1 = list(V = 1,nu =
>>> 4)))
>>> glm.MC.2 <- MCMCglmm(mortality.under.2 ~ maternal_age_c +
>>> I(maternal_age_c^2)  +
>>>                        spl(birth_year) + residence + maternal_educ +
>>>                        sex + wealth,
>>>                      nitt=20000, thin=10, burnin=1000,
>>>                      random= ~CASEID, prior=prior.2,data=rwanda2,
>>> family='categorical')
>>>
>>>
>>> > # creating new data for the poor
>>> > pred.data <- data.frame(maternal_age_c=rep(18,25),wealth=rep("Lowest
>>> quintile",25),
>>> +                         sex=rep("Female",25),residence=rep("Rural",25),
>>> +                         "spl(birth_year)1"=1971:1995,
>>> +                         "spl(birth_year)2"=1971:1995,
>>> +                         "spl(birth_year)3"=1971:1995,
>>> +                         "spl(birth_year)4"=1971:1995,
>>> +                         "spl(birth_year)5"=1971:1995,
>>> +                         "spl(birth_year)6"=1971:1995,
>>> +                         "spl(birth_year)7"=1971:1995,
>>> +                         "spl(birth_year)8"=1971:1995,
>>> +                         "spl(birth_year)9"=1971:1995,
>>> +                         "spl(birth_year)10"=1971:1995,
>>> +                         birth_order=rep(1,25),
>>> +                         maternal_educ=rep("No education",25))
>>> >
>>> > pred.data$wealth <- factor(pred.data$wealth,
>>> +                            levels=c("Lowest quintile", "Second
>>> quintile","Middle quintile","Fourth quintile","Highest quintile"))
>>> > pred.data$sex <- factor(pred.data$sex, levels=c("Male","Female"))
>>> > pred.data$residence <-
>>> factor(pred.data$residence,levels=c("Rural","Urban"))
>>> > # pred.data$birth_year <- factor(pred.data$birth_year, levels=1970:1997)
>>> > pred.data$maternal_educ <- factor(pred.data$maternal_educ,
>>> +                                   levels=c("No education", "Primary",
>>> "Secondary","Higher"))
>>> >
>>> >
>>> > # design matrix
>>> > X <- model.matrix(~ maternal_age_c + I(maternal_age_c^2) + residence +
>>> +                       + maternal_educ +
>>> +                       birth_order +  wealth +
>>> +                       spl.birth_year.1  +
>>> +                       spl.birth_year.2  +
>>> +                       spl.birth_year.3  +
>>> +                       spl.birth_year.4  +
>>> +                       spl.birth_year.5  +
>>> +                       spl.birth_year.6  +
>>> +                       spl.birth_year.7  +
>>> +                       spl.birth_year.8  +
>>> +                       spl.birth_year.9  +
>>> +                       spl.birth_year.10, data=pred.data)
>>> >
>>> >
>>> > V <- rowSums(glm.MC.2$VCV) # marginalizing over random effects
>>> > beta <- glm.MC.2$Sol # fixed effects
>>> > c2 <- (16*sqrt(3)/(15*pi))^2 # alterative parametrization for the
>>> logistic distribution
>>> > pred<- t(plogis(t(beta%*%t(X)/sqrt(1+c2*V))))
>>> > pred <- as.data.frame(pred)
>>> > colnames(pred) <- 1971:1995 # predictions for the poor for every year
>>> > colSums(pred)
>>>     1971     1972     1973     1974     1975     1976     1977     1978
>>>   1979     1980     1981     1982     1983
>>> 1677.094 1677.093 1677.093 1677.093 1677.093 1677.093 1677.093 1677.093
>>> 1677.093 1677.093 1677.093 1677.093 1677.093
>>>     1984     1985     1986     1987     1988     1989     1990     1991
>>>   1992     1993     1994     1995
>>> 1677.092 1677.092 1677.092 1677.092 1677.092 1677.092 1677.092 1677.092
>>> 1677.092 1677.092 1677.092 1677.092
>>> >
>>>
>>
>>
>
> 	[[alternative HTML version deleted]]
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From ramos.grad.student at gmail.com  Tue Mar 26 18:06:57 2013
From: ramos.grad.student at gmail.com (Antonio P. Ramos)
Date: Tue, 26 Mar 2013 10:06:57 -0700
Subject: [R-sig-ME] MCMCglmm predictions with fixed effects Splines
In-Reply-To: <20130326093824.200412s3nglul7rk@www.staffmail.ed.ac.uk>
References: <CAHawB9t4oo-ZkN0a-W2BW9hELcsdP+HvKxvsMo1TEqu7nYqhjg@mail.gmail.com>
	<CAHawB9vaomkazoVRdO2RsZzQLDkDdEa6FBCcD7bzEqeXL66r+Q@mail.gmail.com>
	<CAHawB9t8TFxJuw+_1O4XXKzkWHT-hSxpDWGq3LBwRQtQLORG3Q@mail.gmail.com>
	<20130326093824.200412s3nglul7rk@www.staffmail.ed.ac.uk>
Message-ID: <CAHawB9vRV=1Uo4DzxUtn1N2AQ_8xbC=-d3OVS8YGhLg+uF5j9w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130326/37125685/attachment.pl>

From j.hadfield at ed.ac.uk  Tue Mar 26 18:38:58 2013
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Tue, 26 Mar 2013 17:38:58 +0000
Subject: [R-sig-ME] MCMCglmm predictions with fixed effects Splines
In-Reply-To: <CAHawB9vRV=1Uo4DzxUtn1N2AQ_8xbC=-d3OVS8YGhLg+uF5j9w@mail.gmail.com>
References: <CAHawB9t4oo-ZkN0a-W2BW9hELcsdP+HvKxvsMo1TEqu7nYqhjg@mail.gmail.com>
	<CAHawB9vaomkazoVRdO2RsZzQLDkDdEa6FBCcD7bzEqeXL66r+Q@mail.gmail.com>
	<CAHawB9t8TFxJuw+_1O4XXKzkWHT-hSxpDWGq3LBwRQtQLORG3Q@mail.gmail.com>
	<20130326093824.200412s3nglul7rk@www.staffmail.ed.ac.uk>
	<CAHawB9vRV=1Uo4DzxUtn1N2AQ_8xbC=-d3OVS8YGhLg+uF5j9w@mail.gmail.com>
Message-ID: <20130326173858.14081hjevie4oxus@www.staffmail.ed.ac.uk>

Hi Antonio,

The penalised bit of a penalised spline is achieved by having the  
spline coefficients as random effects rather than fixed.

Cheers,

Jarrod

Quoting "Antonio P. Ramos" <ramos.grad.student at gmail.com> on Tue, 26  
Mar 2013 10:06:57 -0700:

> Hi Jarrod,
>
> Thanks for your reply.
>
> I think I need a spline as a fixed effect only - time doesn't vary by
> CASEID and all observations are subjects for the same time trends. I would
> be nice to have a cubic spline though. Thanks
>
>
> On Tue, Mar 26, 2013 at 2:38 AM, Jarrod Hadfield <j.hadfield at ed.ac.uk>wrote:
>
>> Hi,
>>
>> Check out the examples in ?spl: you haven't fitted a penalised spline. You
>> probably want something like:
>>
>> glm.MC.2 <- MCMCglmm(mortality.under.2 ~ maternal_age_c +
>> I(maternal_age_c^2)  + birth_year + residence + maternal_educ +
>> sex + wealth, nitt=20000, thin=10, burnin=1000,random=
>> ~idv(spl(birdth_year))+CASEID,  
>> prior=prior.2,data=rwanda2,**family='categorical',
>> pr=TRUE)
>>
>> Note that I have saved the random effects (pr=TRUE) because the first k
>> random effects are the spline coefficients. You will need to associate
>> these with the relevant columns of Z (rather than X) to get predictions.
>> Remember to include the fixed birth_year effect too.
>>
>> Cheers,
>>
>> Jarrod
>>
>>
>>
>> Quoting "Antonio P. Ramos" <ramos.grad.student at gmail.com> on Mon, 25 Mar
>> 2013 19:57:51 -0700:
>>
>>  I think I get what is going on a little better now. Does it make sense?
>>>
>>> # getting the predictions
>>> # where the nots are?
>>> k <- 10
>>> x <- quantile(rwanda2$birth_year, 1:k/(k + 1), na.rm = T)
>>> y <- unique(rwanda2$birth_year)
>>>
>>> # creating new data for the poor
>>> pred.data <- data.frame(maternal_age_c=rep(**0,28),wealth=rep("Lowest
>>> quintile",28),
>>>                         sex=rep("Female",28),**residence=rep("Rural",28),
>>>                         "spl(birth_year)1"=ifelse(y<**1976,1,0),
>>>                         "spl(birth_year)2"=ifelse(y>**1975&y<1979,1,0),
>>>                         "spl(birth_year)3"=ifelse(y>**1978&y<1981,1,0),
>>>                         "spl(birth_year)4"=ifelse(y>**1980&y<1983,1,0),
>>>                         "spl(birth_year)5"=ifelse(y>**1982&y<1985,1,0),
>>>                         "spl(birth_year)6"=ifelse(y>=**1984&y<1988,1,0),
>>>                         "spl(birth_year)7"=ifelse(y>=**1987&y<=1990,1,0),
>>>                         "spl(birth_year)8"=ifelse(y>**1989&y<1993,1,0),
>>>                         "spl(birth_year)9"=ifelse(y>**1993&y<1996,1,0),
>>>                         "spl(birth_year)10"=ifelse(y>**1995,1,0),
>>>                         birth_order=rep(1,28),
>>>                         maternal_educ=rep("No education",28))
>>>
>>> pred.data$wealth <- factor(pred.data$wealth,
>>>                            levels=c("Lowest quintile", "Second
>>> quintile","Middle quintile","Fourth quintile","Highest quintile"))
>>> pred.data$sex <- factor(pred.data$sex, levels=c("Male","Female"))
>>> pred.data$residence <- factor(pred.data$residence,**
>>> levels=c("Rural","Urban"))
>>> pred.data$maternal_educ <- factor(pred.data$maternal_**educ,
>>>                                   levels=c("No education", "Primary",
>>> "Secondary","Higher"))
>>>
>>>
>>> # design matrix
>>> X <- model.matrix(~ maternal_age_c + I(maternal_age_c^2) + residence +
>>>                      + maternal_educ +
>>>                     birth_order +  wealth +
>>>                     spl.birth_year.1  +
>>>                     spl.birth_year.2  +
>>>                     spl.birth_year.3  +
>>>                     spl.birth_year.4  +
>>>                     spl.birth_year.5  +
>>>                     spl.birth_year.6  +
>>>                     spl.birth_year.7  +
>>>                     spl.birth_year.8  +
>>>                     spl.birth_year.9  +
>>>                     spl.birth_year.10, data=pred.data)
>>>
>>>
>>> V <- rowSums(glm.MC.2$VCV) # marginalizing over random effects
>>> beta <- glm.MC.2$Sol # fixed effects
>>> c2 <- (16*sqrt(3)/(15*pi))^2 # alterative parametrization for the logistic
>>> distribution
>>> pred<- t(plogis(t(beta%*%t(X)/sqrt(1+**c2*V))))
>>> pred <- as.data.frame(pred)
>>> colnames(pred) <- 1970:1997 # predictions for the poor for every year
>>> colSums(pred)
>>> pred.poor <- pred
>>>
>>>
>>>
>>> On Mon, Mar 25, 2013 at 5:14 PM, Antonio P. Ramos <
>>> ramos.grad.student at gmail.com> wrote:
>>>
>>>  maybe the model's summary would also help:
>>>>
>>>> > summary(glm.MC.2)
>>>>
>>>>  Iterations = 1001:19991
>>>>  Thinning interval  = 10
>>>>  Sample size  = 1900
>>>>
>>>>  DIC: 23202.78
>>>>
>>>>  G-structure:  ~CASEID
>>>>
>>>>        post.mean l-95% CI u-95% CI eff.samp
>>>> CASEID     1.008   0.8508    1.139    73.88
>>>>
>>>>  R-structure:  ~units
>>>>
>>>>       post.mean l-95% CI u-95% CI eff.samp
>>>> units         1        1        1        0
>>>>
>>>>  Location effects: mortality.under.2 ~ maternal_age_c +
>>>> I(maternal_age_c^2) + spl(birth_year) + residence + maternal_educ + sex +
>>>> wealth
>>>>
>>>>                            post.mean   l-95% CI   u-95% CI eff.samp
>>>> pMCMC
>>>> (Intercept)               -2.2844882 -4.0378822 -0.5243228    270.8
>>>> 0.00947 **
>>>> maternal_age_c            -0.0278874 -0.0396679 -0.0169772    409.5 <
>>>> 5e-04 ***
>>>> I(maternal_age_c^2)        0.0067512  0.0040534  0.0096366    369.2 <
>>>> 5e-04 ***
>>>> spl(birth_year)1          -0.0069841 -0.0172375  0.0024631    387.8
>>>> 0.15789
>>>> spl(birth_year)2           0.0257588  0.0003497  0.0511228    425.9
>>>> 0.05474 .
>>>> spl(birth_year)3          -0.0251424 -0.0871379  0.0381827    376.8
>>>> 0.41368
>>>> spl(birth_year)4          -0.0451816 -0.1068456  0.0188489    315.1
>>>> 0.17895
>>>> spl(birth_year)5          -0.0506369 -0.1256510  0.0256118    325.8
>>>> 0.20737
>>>> spl(birth_year)6           0.0571108 -0.0450529  0.1564138    229.7
>>>> 0.25368
>>>> spl(birth_year)7          -0.0993668 -0.1830175 -0.0135886    275.6
>>>> 0.01474 *
>>>> spl(birth_year)8          -0.0812237 -0.1417047 -0.0322527    273.6
>>>> 0.00316 **
>>>> spl(birth_year)9           0.0626604  0.0448635  0.0797381    300.8 <
>>>> 5e-04 ***
>>>> spl(birth_year)10         -0.0148629 -0.0234434 -0.0054245    387.5
>>>> 0.00105 **
>>>> residenceUrban            -0.2141484 -0.3716601 -0.0511390    280.1
>>>> 0.00947 **
>>>> maternal_educNo education  1.0334332  0.1228220  2.0524150    207.8
>>>> 0.03263 *
>>>> maternal_educPrimary       0.7954471 -0.1554284  1.7616937    206.3
>>>> 0.10316
>>>> maternal_educSecondary    -0.0083354 -0.9622503  1.0182426    195.0
>>>> 0.98000
>>>> sexMale                    0.1893753  0.1072094  0.2710264    275.2 <
>>>> 5e-04 ***
>>>> wealthSecond quintile      0.1773074  0.0444755  0.3283123    398.4
>>>> 0.01368 *
>>>> wealthMiddle quintile     -0.0667648 -0.2060366  0.0676636    376.9
>>>> 0.34316
>>>> wealthFourth quintile      0.0485797 -0.0913787  0.1942995    416.2
>>>> 0.47579
>>>> wealthHighest quintile    -0.1339028 -0.3017483  0.0077947    338.2
>>>> 0.08000 .
>>>> ---
>>>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>>>
>>>>
>>>>
>>>>
>>>>
>>>> On Mon, Mar 25, 2013 at 5:12 PM, Antonio P. Ramos <
>>>> ramos.grad.student at gmail.com> wrote:
>>>>
>>>>  Hi all,
>>>>>
>>>>> I am trying to get some predictions from a MCMCglmm model but it is not
>>>>> working. I guess I don't really following what the model is doing with
>>>>> tje
>>>>> spl() command. Here is an example of the issue.
>>>>>
>>>>> Thanks a bunch
>>>>>
>>>>>
>>>>>
>>>>> # inve.wishart(V=1,nu=4) is equivalent to inv-gamma(shape=2,scale=2) for
>>>>> mothers random effects
>>>>> prior.2 <- list(R = list(V = 1, fix = 1), G = list(G1 = list(V = 1,nu =
>>>>> 4)))
>>>>> glm.MC.2 <- MCMCglmm(mortality.under.2 ~ maternal_age_c +
>>>>> I(maternal_age_c^2)  +
>>>>>                        spl(birth_year) + residence + maternal_educ +
>>>>>                        sex + wealth,
>>>>>                      nitt=20000, thin=10, burnin=1000,
>>>>>                      random= ~CASEID, prior=prior.2,data=rwanda2,
>>>>> family='categorical')
>>>>>
>>>>>
>>>>> > # creating new data for the poor
>>>>> > pred.data <- data.frame(maternal_age_c=rep(**
>>>>> 18,25),wealth=rep("Lowest
>>>>> quintile",25),
>>>>> +                         sex=rep("Female",25),**
>>>>> residence=rep("Rural",25),
>>>>> +                         "spl(birth_year)1"=1971:1995,
>>>>> +                         "spl(birth_year)2"=1971:1995,
>>>>> +                         "spl(birth_year)3"=1971:1995,
>>>>> +                         "spl(birth_year)4"=1971:1995,
>>>>> +                         "spl(birth_year)5"=1971:1995,
>>>>> +                         "spl(birth_year)6"=1971:1995,
>>>>> +                         "spl(birth_year)7"=1971:1995,
>>>>> +                         "spl(birth_year)8"=1971:1995,
>>>>> +                         "spl(birth_year)9"=1971:1995,
>>>>> +                         "spl(birth_year)10"=1971:1995,
>>>>> +                         birth_order=rep(1,25),
>>>>> +                         maternal_educ=rep("No education",25))
>>>>> >
>>>>> > pred.data$wealth <- factor(pred.data$wealth,
>>>>> +                            levels=c("Lowest quintile", "Second
>>>>> quintile","Middle quintile","Fourth quintile","Highest quintile"))
>>>>> > pred.data$sex <- factor(pred.data$sex, levels=c("Male","Female"))
>>>>> > pred.data$residence <-
>>>>> factor(pred.data$residence,**levels=c("Rural","Urban"))
>>>>> > # pred.data$birth_year <- factor(pred.data$birth_year,
>>>>> levels=1970:1997)
>>>>> > pred.data$maternal_educ <- factor(pred.data$maternal_**educ,
>>>>> +                                   levels=c("No education", "Primary",
>>>>> "Secondary","Higher"))
>>>>> >
>>>>> >
>>>>> > # design matrix
>>>>> > X <- model.matrix(~ maternal_age_c + I(maternal_age_c^2) + residence +
>>>>> +                       + maternal_educ +
>>>>> +                       birth_order +  wealth +
>>>>> +                       spl.birth_year.1  +
>>>>> +                       spl.birth_year.2  +
>>>>> +                       spl.birth_year.3  +
>>>>> +                       spl.birth_year.4  +
>>>>> +                       spl.birth_year.5  +
>>>>> +                       spl.birth_year.6  +
>>>>> +                       spl.birth_year.7  +
>>>>> +                       spl.birth_year.8  +
>>>>> +                       spl.birth_year.9  +
>>>>> +                       spl.birth_year.10, data=pred.data)
>>>>> >
>>>>> >
>>>>> > V <- rowSums(glm.MC.2$VCV) # marginalizing over random effects
>>>>> > beta <- glm.MC.2$Sol # fixed effects
>>>>> > c2 <- (16*sqrt(3)/(15*pi))^2 # alterative parametrization for the
>>>>> logistic distribution
>>>>> > pred<- t(plogis(t(beta%*%t(X)/sqrt(1+**c2*V))))
>>>>> > pred <- as.data.frame(pred)
>>>>> > colnames(pred) <- 1971:1995 # predictions for the poor for every year
>>>>> > colSums(pred)
>>>>>     1971     1972     1973     1974     1975     1976     1977     1978
>>>>>   1979     1980     1981     1982     1983
>>>>> 1677.094 1677.093 1677.093 1677.093 1677.093 1677.093 1677.093 1677.093
>>>>> 1677.093 1677.093 1677.093 1677.093 1677.093
>>>>>     1984     1985     1986     1987     1988     1989     1990     1991
>>>>>   1992     1993     1994     1995
>>>>> 1677.092 1677.092 1677.092 1677.092 1677.092 1677.092 1677.092 1677.092
>>>>> 1677.092 1677.092 1677.092 1677.092
>>>>> >
>>>>>
>>>>>
>>>>
>>>>
>>>         [[alternative HTML version deleted]]
>>>
>>>
>>>
>>
>>
>> --
>> The University of Edinburgh is a charitable body, registered in
>> Scotland, with registration number SC005336.
>>
>>
>>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From vanni.rovera at gmail.com  Tue Mar 26 23:06:44 2013
From: vanni.rovera at gmail.com (Vanni Rovera)
Date: Tue, 26 Mar 2013 23:06:44 +0100
Subject: [R-sig-ME] Make a 'between-and-within-factors' ANOVA with lmer
	function
In-Reply-To: <DA60DB44-8E80-46DB-B43B-EB00EF638F2E@ed.ac.uk>
References: <CACd0PJxKXymxieWZtocJ_bHeKQcWk_BBUseWD+jtXAqjTWrjcQ@mail.gmail.com>
	<DA60DB44-8E80-46DB-B43B-EB00EF638F2E@ed.ac.uk>
Message-ID: <CACd0PJxOsMBku4bmberEs-3vLcqBsy_8+yB21Vj--G2r7eG7GQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130326/221fffed/attachment.pl>

From jwiley.psych at gmail.com  Wed Mar 27 08:10:35 2013
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Wed, 27 Mar 2013 00:10:35 -0700
Subject: [R-sig-ME] MCMCglmm predictions with fixed effects Splines
In-Reply-To: <20130326173858.14081hjevie4oxus@www.staffmail.ed.ac.uk>
References: <CAHawB9t4oo-ZkN0a-W2BW9hELcsdP+HvKxvsMo1TEqu7nYqhjg@mail.gmail.com>
	<CAHawB9vaomkazoVRdO2RsZzQLDkDdEa6FBCcD7bzEqeXL66r+Q@mail.gmail.com>
	<CAHawB9t8TFxJuw+_1O4XXKzkWHT-hSxpDWGq3LBwRQtQLORG3Q@mail.gmail.com>
	<20130326093824.200412s3nglul7rk@www.staffmail.ed.ac.uk>
	<CAHawB9vRV=1Uo4DzxUtn1N2AQ_8xbC=-d3OVS8YGhLg+uF5j9w@mail.gmail.com>
	<20130326173858.14081hjevie4oxus@www.staffmail.ed.ac.uk>
Message-ID: <CANz9Z_+7XbVNJBY_eEAoD9JwSHa7SuHNa8W_HXi32k0JMmwM-A@mail.gmail.com>

I do not think the ifelse statements you have are what you want
either.  Look at how this simple example is expanded with only three
knots:

> spl(1:3, k = 3)
           [,1]       [,2]       [,3]
[1,] 3.80521304 -2.7748166 0.55521304
[2,] 0.09910059  0.1982012 0.09910059
[3,] 0.55521304 -2.7748166 3.80521304


simply cutting the data is not sufficient (FYI a more efficient way to
do that if you were would be with ?cut).  Have you looked at the
source code for spl?  It is short and readable.  Essentially taking
the outer product of the data  and knot arrays (determined as you
said), by cubing the absolute deviations, and then post multiplies
that using the singular value decomposition of it (X = UDV'), V
sqrt(D^-1) U'

Anyway, to make the new appropriate matrix for prediction, rather than
rolling your own, probably easiest to pass in your own knot values.
So:

knots <- quantile(1:10, 1:3/(3+1))
> knots
 25%  50%  75%
3.25 5.50 7.75

## imaginary "real" use
> spl(1:10, knots = knots)
            [,1]        [,2]       [,3]
 [1,] 36.3243413 -26.4882371  5.3000313
 [2,] 21.3916729  -8.9747525  1.6810714
 [3,] 11.3613809  -0.1816752  0.1360608
 [4,]  5.2276907   2.4526145 -0.2523869
 [5,]  1.9051290   2.0996457  0.2879496
 [6,]  0.2879496   2.0996457  1.9051290
 [7,] -0.2523869   2.4526145  5.2276907
 [8,]  0.1360608  -0.1816752 11.3613809
 [9,]  1.6810714  -8.9747525 21.3916729
[10,]  5.3000313 -26.4882371 36.3243413

## now for the prediction data
> spl(1:3, knots = knots)
         [,1]        [,2]      [,3]
[1,] 36.32434 -26.4882371 5.3000313
[2,] 21.39167  -8.9747525 1.6810714
[3,] 11.36138  -0.1816752 0.1360608

## what happens if you do not use the same knots

> spl(1:3, k=3)
           [,1]       [,2]       [,3]
[1,] 3.80521304 -2.7748166 0.55521304
[2,] 0.09910059  0.1982012 0.09910059
[3,] 0.55521304 -2.7748166 3.80521304


Agree with Jarrod that a penalized spline model is more typical.
Since you're Bayesian, you could also shrink them using stronger
priors on those terms in the fixed effects region.  Not really the
same thing, but could help reign in the effects if you want to leave
them as fixed effects.

Cheers,

Josh





On Tue, Mar 26, 2013 at 10:38 AM, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:
> Hi Antonio,
>
> The penalised bit of a penalised spline is achieved by having the spline
> coefficients as random effects rather than fixed.
>
> Cheers,
>
> Jarrod
>
>
> Quoting "Antonio P. Ramos" <ramos.grad.student at gmail.com> on Tue, 26 Mar
> 2013 10:06:57 -0700:
>
>> Hi Jarrod,
>>
>> Thanks for your reply.
>>
>> I think I need a spline as a fixed effect only - time doesn't vary by
>> CASEID and all observations are subjects for the same time trends. I would
>> be nice to have a cubic spline though. Thanks
>>
>>
>> On Tue, Mar 26, 2013 at 2:38 AM, Jarrod Hadfield
>> <j.hadfield at ed.ac.uk>wrote:
>>
>>> Hi,
>>>
>>> Check out the examples in ?spl: you haven't fitted a penalised spline.
>>> You
>>> probably want something like:
>>>
>>> glm.MC.2 <- MCMCglmm(mortality.under.2 ~ maternal_age_c +
>>> I(maternal_age_c^2)  + birth_year + residence + maternal_educ +
>>> sex + wealth, nitt=20000, thin=10, burnin=1000,random=
>>> ~idv(spl(birdth_year))+CASEID,
>>> prior=prior.2,data=rwanda2,**family='categorical',
>>> pr=TRUE)
>>>
>>> Note that I have saved the random effects (pr=TRUE) because the first k
>>> random effects are the spline coefficients. You will need to associate
>>> these with the relevant columns of Z (rather than X) to get predictions.
>>> Remember to include the fixed birth_year effect too.
>>>
>>> Cheers,
>>>
>>> Jarrod
>>>
>>>
>>>
>>> Quoting "Antonio P. Ramos" <ramos.grad.student at gmail.com> on Mon, 25 Mar
>>> 2013 19:57:51 -0700:
>>>
>>>  I think I get what is going on a little better now. Does it make sense?
>>>>
>>>>
>>>> # getting the predictions
>>>> # where the nots are?
>>>> k <- 10
>>>> x <- quantile(rwanda2$birth_year, 1:k/(k + 1), na.rm = T)
>>>> y <- unique(rwanda2$birth_year)
>>>>
>>>> # creating new data for the poor
>>>> pred.data <- data.frame(maternal_age_c=rep(**0,28),wealth=rep("Lowest
>>>> quintile",28),
>>>>
>>>> sex=rep("Female",28),**residence=rep("Rural",28),
>>>>                         "spl(birth_year)1"=ifelse(y<**1976,1,0),
>>>>                         "spl(birth_year)2"=ifelse(y>**1975&y<1979,1,0),
>>>>                         "spl(birth_year)3"=ifelse(y>**1978&y<1981,1,0),
>>>>                         "spl(birth_year)4"=ifelse(y>**1980&y<1983,1,0),
>>>>                         "spl(birth_year)5"=ifelse(y>**1982&y<1985,1,0),
>>>>                         "spl(birth_year)6"=ifelse(y>=**1984&y<1988,1,0),
>>>>
>>>> "spl(birth_year)7"=ifelse(y>=**1987&y<=1990,1,0),
>>>>                         "spl(birth_year)8"=ifelse(y>**1989&y<1993,1,0),
>>>>                         "spl(birth_year)9"=ifelse(y>**1993&y<1996,1,0),
>>>>                         "spl(birth_year)10"=ifelse(y>**1995,1,0),
>>>>                         birth_order=rep(1,28),
>>>>                         maternal_educ=rep("No education",28))
>>>>
>>>> pred.data$wealth <- factor(pred.data$wealth,
>>>>                            levels=c("Lowest quintile", "Second
>>>> quintile","Middle quintile","Fourth quintile","Highest quintile"))
>>>> pred.data$sex <- factor(pred.data$sex, levels=c("Male","Female"))
>>>> pred.data$residence <- factor(pred.data$residence,**
>>>> levels=c("Rural","Urban"))
>>>> pred.data$maternal_educ <- factor(pred.data$maternal_**educ,
>>>>                                   levels=c("No education", "Primary",
>>>> "Secondary","Higher"))
>>>>
>>>>
>>>> # design matrix
>>>> X <- model.matrix(~ maternal_age_c + I(maternal_age_c^2) + residence +
>>>>                      + maternal_educ +
>>>>                     birth_order +  wealth +
>>>>                     spl.birth_year.1  +
>>>>                     spl.birth_year.2  +
>>>>                     spl.birth_year.3  +
>>>>                     spl.birth_year.4  +
>>>>                     spl.birth_year.5  +
>>>>                     spl.birth_year.6  +
>>>>                     spl.birth_year.7  +
>>>>                     spl.birth_year.8  +
>>>>                     spl.birth_year.9  +
>>>>                     spl.birth_year.10, data=pred.data)
>>>>
>>>>
>>>> V <- rowSums(glm.MC.2$VCV) # marginalizing over random effects
>>>> beta <- glm.MC.2$Sol # fixed effects
>>>> c2 <- (16*sqrt(3)/(15*pi))^2 # alterative parametrization for the
>>>> logistic
>>>> distribution
>>>> pred<- t(plogis(t(beta%*%t(X)/sqrt(1+**c2*V))))
>>>> pred <- as.data.frame(pred)
>>>> colnames(pred) <- 1970:1997 # predictions for the poor for every year
>>>> colSums(pred)
>>>> pred.poor <- pred
>>>>
>>>>
>>>>
>>>> On Mon, Mar 25, 2013 at 5:14 PM, Antonio P. Ramos <
>>>> ramos.grad.student at gmail.com> wrote:
>>>>
>>>>  maybe the model's summary would also help:
>>>>>
>>>>>
>>>>> > summary(glm.MC.2)
>>>>>
>>>>>  Iterations = 1001:19991
>>>>>  Thinning interval  = 10
>>>>>  Sample size  = 1900
>>>>>
>>>>>  DIC: 23202.78
>>>>>
>>>>>  G-structure:  ~CASEID
>>>>>
>>>>>        post.mean l-95% CI u-95% CI eff.samp
>>>>> CASEID     1.008   0.8508    1.139    73.88
>>>>>
>>>>>  R-structure:  ~units
>>>>>
>>>>>       post.mean l-95% CI u-95% CI eff.samp
>>>>> units         1        1        1        0
>>>>>
>>>>>  Location effects: mortality.under.2 ~ maternal_age_c +
>>>>> I(maternal_age_c^2) + spl(birth_year) + residence + maternal_educ + sex
>>>>> +
>>>>> wealth
>>>>>
>>>>>                            post.mean   l-95% CI   u-95% CI eff.samp
>>>>> pMCMC
>>>>> (Intercept)               -2.2844882 -4.0378822 -0.5243228    270.8
>>>>> 0.00947 **
>>>>> maternal_age_c            -0.0278874 -0.0396679 -0.0169772    409.5 <
>>>>> 5e-04 ***
>>>>> I(maternal_age_c^2)        0.0067512  0.0040534  0.0096366    369.2 <
>>>>> 5e-04 ***
>>>>> spl(birth_year)1          -0.0069841 -0.0172375  0.0024631    387.8
>>>>> 0.15789
>>>>> spl(birth_year)2           0.0257588  0.0003497  0.0511228    425.9
>>>>> 0.05474 .
>>>>> spl(birth_year)3          -0.0251424 -0.0871379  0.0381827    376.8
>>>>> 0.41368
>>>>> spl(birth_year)4          -0.0451816 -0.1068456  0.0188489    315.1
>>>>> 0.17895
>>>>> spl(birth_year)5          -0.0506369 -0.1256510  0.0256118    325.8
>>>>> 0.20737
>>>>> spl(birth_year)6           0.0571108 -0.0450529  0.1564138    229.7
>>>>> 0.25368
>>>>> spl(birth_year)7          -0.0993668 -0.1830175 -0.0135886    275.6
>>>>> 0.01474 *
>>>>> spl(birth_year)8          -0.0812237 -0.1417047 -0.0322527    273.6
>>>>> 0.00316 **
>>>>> spl(birth_year)9           0.0626604  0.0448635  0.0797381    300.8 <
>>>>> 5e-04 ***
>>>>> spl(birth_year)10         -0.0148629 -0.0234434 -0.0054245    387.5
>>>>> 0.00105 **
>>>>> residenceUrban            -0.2141484 -0.3716601 -0.0511390    280.1
>>>>> 0.00947 **
>>>>> maternal_educNo education  1.0334332  0.1228220  2.0524150    207.8
>>>>> 0.03263 *
>>>>> maternal_educPrimary       0.7954471 -0.1554284  1.7616937    206.3
>>>>> 0.10316
>>>>> maternal_educSecondary    -0.0083354 -0.9622503  1.0182426    195.0
>>>>> 0.98000
>>>>> sexMale                    0.1893753  0.1072094  0.2710264    275.2 <
>>>>> 5e-04 ***
>>>>> wealthSecond quintile      0.1773074  0.0444755  0.3283123    398.4
>>>>> 0.01368 *
>>>>> wealthMiddle quintile     -0.0667648 -0.2060366  0.0676636    376.9
>>>>> 0.34316
>>>>> wealthFourth quintile      0.0485797 -0.0913787  0.1942995    416.2
>>>>> 0.47579
>>>>> wealthHighest quintile    -0.1339028 -0.3017483  0.0077947    338.2
>>>>> 0.08000 .
>>>>> ---
>>>>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>> On Mon, Mar 25, 2013 at 5:12 PM, Antonio P. Ramos <
>>>>> ramos.grad.student at gmail.com> wrote:
>>>>>
>>>>>  Hi all,
>>>>>>
>>>>>>
>>>>>> I am trying to get some predictions from a MCMCglmm model but it is
>>>>>> not
>>>>>> working. I guess I don't really following what the model is doing with
>>>>>> tje
>>>>>> spl() command. Here is an example of the issue.
>>>>>>
>>>>>> Thanks a bunch
>>>>>>
>>>>>>
>>>>>>
>>>>>> # inve.wishart(V=1,nu=4) is equivalent to inv-gamma(shape=2,scale=2)
>>>>>> for
>>>>>> mothers random effects
>>>>>> prior.2 <- list(R = list(V = 1, fix = 1), G = list(G1 = list(V = 1,nu
>>>>>> =
>>>>>> 4)))
>>>>>> glm.MC.2 <- MCMCglmm(mortality.under.2 ~ maternal_age_c +
>>>>>> I(maternal_age_c^2)  +
>>>>>>                        spl(birth_year) + residence + maternal_educ +
>>>>>>                        sex + wealth,
>>>>>>                      nitt=20000, thin=10, burnin=1000,
>>>>>>                      random= ~CASEID, prior=prior.2,data=rwanda2,
>>>>>> family='categorical')
>>>>>>
>>>>>>
>>>>>> > # creating new data for the poor
>>>>>> > pred.data <- data.frame(maternal_age_c=rep(**
>>>>>> 18,25),wealth=rep("Lowest
>>>>>> quintile",25),
>>>>>> +                         sex=rep("Female",25),**
>>>>>> residence=rep("Rural",25),
>>>>>> +                         "spl(birth_year)1"=1971:1995,
>>>>>> +                         "spl(birth_year)2"=1971:1995,
>>>>>> +                         "spl(birth_year)3"=1971:1995,
>>>>>> +                         "spl(birth_year)4"=1971:1995,
>>>>>> +                         "spl(birth_year)5"=1971:1995,
>>>>>> +                         "spl(birth_year)6"=1971:1995,
>>>>>> +                         "spl(birth_year)7"=1971:1995,
>>>>>> +                         "spl(birth_year)8"=1971:1995,
>>>>>> +                         "spl(birth_year)9"=1971:1995,
>>>>>> +                         "spl(birth_year)10"=1971:1995,
>>>>>> +                         birth_order=rep(1,25),
>>>>>> +                         maternal_educ=rep("No education",25))
>>>>>> >
>>>>>> > pred.data$wealth <- factor(pred.data$wealth,
>>>>>> +                            levels=c("Lowest quintile", "Second
>>>>>> quintile","Middle quintile","Fourth quintile","Highest quintile"))
>>>>>> > pred.data$sex <- factor(pred.data$sex, levels=c("Male","Female"))
>>>>>> > pred.data$residence <-
>>>>>> factor(pred.data$residence,**levels=c("Rural","Urban"))
>>>>>> > # pred.data$birth_year <- factor(pred.data$birth_year,
>>>>>> levels=1970:1997)
>>>>>> > pred.data$maternal_educ <- factor(pred.data$maternal_**educ,
>>>>>> +                                   levels=c("No education",
>>>>>> "Primary",
>>>>>> "Secondary","Higher"))
>>>>>> >
>>>>>> >
>>>>>> > # design matrix
>>>>>> > X <- model.matrix(~ maternal_age_c + I(maternal_age_c^2) + residence
>>>>>> > +
>>>>>> +                       + maternal_educ +
>>>>>> +                       birth_order +  wealth +
>>>>>> +                       spl.birth_year.1  +
>>>>>> +                       spl.birth_year.2  +
>>>>>> +                       spl.birth_year.3  +
>>>>>> +                       spl.birth_year.4  +
>>>>>> +                       spl.birth_year.5  +
>>>>>> +                       spl.birth_year.6  +
>>>>>> +                       spl.birth_year.7  +
>>>>>> +                       spl.birth_year.8  +
>>>>>> +                       spl.birth_year.9  +
>>>>>> +                       spl.birth_year.10, data=pred.data)
>>>>>> >
>>>>>> >
>>>>>> > V <- rowSums(glm.MC.2$VCV) # marginalizing over random effects
>>>>>> > beta <- glm.MC.2$Sol # fixed effects
>>>>>> > c2 <- (16*sqrt(3)/(15*pi))^2 # alterative parametrization for the
>>>>>> logistic distribution
>>>>>> > pred<- t(plogis(t(beta%*%t(X)/sqrt(1+**c2*V))))
>>>>>> > pred <- as.data.frame(pred)
>>>>>> > colnames(pred) <- 1971:1995 # predictions for the poor for every
>>>>>> > year
>>>>>> > colSums(pred)
>>>>>>     1971     1972     1973     1974     1975     1976     1977
>>>>>> 1978
>>>>>>   1979     1980     1981     1982     1983
>>>>>> 1677.094 1677.093 1677.093 1677.093 1677.093 1677.093 1677.093
>>>>>> 1677.093
>>>>>> 1677.093 1677.093 1677.093 1677.093 1677.093
>>>>>>     1984     1985     1986     1987     1988     1989     1990
>>>>>> 1991
>>>>>>   1992     1993     1994     1995
>>>>>> 1677.092 1677.092 1677.092 1677.092 1677.092 1677.092 1677.092
>>>>>> 1677.092
>>>>>> 1677.092 1677.092 1677.092 1677.092
>>>>>> >
>>>>>>
>>>>>>
>>>>>
>>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>>
>>>>
>>>
>>>
>>> --
>>> The University of Edinburgh is a charitable body, registered in
>>> Scotland, with registration number SC005336.
>>>
>>>
>>>
>>
>
>
>
> --
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



-- 
Joshua Wiley
Ph.D. Student, Health Psychology
University of California, Los Angeles
http://joshuawiley.com/
Senior Analyst - Elkhart Group Ltd.
http://elkhartgroup.com


From guillaumechaumet at gmail.com  Wed Mar 27 11:20:35 2013
From: guillaumechaumet at gmail.com (guillaume chaumet)
Date: Wed, 27 Mar 2013 11:20:35 +0100
Subject: [R-sig-ME] Make a 'between-and-within-factors' ANOVA with lmer
	function
In-Reply-To: <CAGg8SkLmiWYHRQt_vL35MuciYQP7Awaor07fkWKjdzMAs8cFrg@mail.gmail.com>
References: <CACd0PJxKXymxieWZtocJ_bHeKQcWk_BBUseWD+jtXAqjTWrjcQ@mail.gmail.com>
	<DA60DB44-8E80-46DB-B43B-EB00EF638F2E@ed.ac.uk>
	<CACd0PJxOsMBku4bmberEs-3vLcqBsy_8+yB21Vj--G2r7eG7GQ@mail.gmail.com>
	<CAGg8SkLmiWYHRQt_vL35MuciYQP7Awaor07fkWKjdzMAs8cFrg@mail.gmail.com>
Message-ID: <CAGg8SkJQULqObAVZ0um6vwOm9ZKf1aBcFE1pL=RMQtbbHYe=rg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130327/d89dfc0b/attachment.pl>

From i.m.s.white at ed.ac.uk  Wed Mar 27 12:16:14 2013
From: i.m.s.white at ed.ac.uk (i white)
Date: Wed, 27 Mar 2013 11:16:14 +0000
Subject: [R-sig-ME] Make a 'between-and-within-factors' ANOVA with lmer
 function
In-Reply-To: <CACd0PJxOsMBku4bmberEs-3vLcqBsy_8+yB21Vj--G2r7eG7GQ@mail.gmail.com>
References: <CACd0PJxKXymxieWZtocJ_bHeKQcWk_BBUseWD+jtXAqjTWrjcQ@mail.gmail.com>
	<DA60DB44-8E80-46DB-B43B-EB00EF638F2E@ed.ac.uk>
	<CACd0PJxOsMBku4bmberEs-3vLcqBsy_8+yB21Vj--G2r7eG7GQ@mail.gmail.com>
Message-ID: <5152D4FE.9090105@ed.ac.uk>

Vanni, Ben,

You get identical results with aov and lme:

 > foo <- read.table("aov.dat", header = T)
 > aovfit <- aov(Recall ~ Gender*Dosage*Task*Valence + Error(Subject),
+ data = foo)
 > summary(aovfit)

Error: Subject
               Df Sum Sq Mean Sq F value Pr(>F)
Gender         1  542.3   542.3   5.685 0.0345 *
Dosage         2  694.9   347.5   3.643 0.0580 .
Gender:Dosage  2   70.8    35.4   0.371 0.6976
Residuals     12 1144.6    95.4
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Error: Within
                            Df Sum Sq Mean Sq F value   Pr(>F)
Task                        1  96.33   96.33  42.258 1.77e-08 ***
Valence                     2  14.69    7.34   3.221   0.0469 *
Gender:Task                 1   1.33    1.33   0.585   0.4474
Dosage:Task                 2   8.17    4.08   1.791   0.1756
Gender:Valence              2   3.91    1.95   0.857   0.4296
Dosage:Valence              4  20.26    5.06   2.222   0.0773 .
Task:Valence                2   5.39    2.69   1.182   0.3137
Gender:Dosage:Task          2   3.17    1.58   0.695   0.5033
Gender:Dosage:Valence       4   1.04    0.26   0.114   0.9772
Gender:Task:Valence         2   2.17    1.08   0.475   0.6241
Dosage:Task:Valence         4   2.78    0.69   0.305   0.8738
Gender:Dosage:Task:Valence  4   2.67    0.67   0.292   0.8818
Residuals                  60 136.78    2.28
---

 > library(nlme)
 > lmefit <- lme(Recall ~ Gender*Dosage*Task*Valence, random = 
~1|Subject, data = foo)
 > anova(lmefit)
                            numDF denDF   F-value p-value
(Intercept)                    1    60 276.60849  <.0001
Gender                         1    12   5.68527  0.0345
Dosage                         2    12   3.64285  0.0580
Task                           1    60  42.25833  <.0001
Valence                        2    60   3.22096  0.0469
Gender:Dosage                  2    12   0.37113  0.6976
Gender:Task                    1    60   0.58489  0.4474
Dosage:Task                    2    60   1.79123  0.1756
Gender:Valence                 2    60   0.85703  0.4296
Dosage:Valence                 4    60   2.22177  0.0773
Task:Valence                   2    60   1.18197  0.3137
Gender:Dosage:Task             2    60   0.69456  0.5033
Gender:Dosage:Valence          4    60   0.11373  0.9772
Gender:Task:Valence            2    60   0.47522  0.6241
Dosage:Task:Valence            4    60   0.30463  0.8738
Gender:Dosage:Task:Valence     4    60   0.29245  0.8818



On 03/26/2013 10:06 PM, Vanni Rovera wrote:
> Hi Ian, hi Ben,
>
>
> first of all many thanks for your answers. I tested your proposals and I
> will report you the results in a moment. But first let me say that I
> used the dataset linked above, in which we have:
>
>
> DV = Recall
>
> IV1 = Gender (between-factor)
>
> IV2 = Dosage (between-factor)
>
> IV3 = Valence (within-factor)
>
> IV4 = Task (within-factor)
>
>
> The ANOVA fitted with the aov function is the following:
>
>
>> aovRecall<-aov(Recall~(Gender*Dosage*Valence*Task)+Error(Subject/(Valence*Task)))
>
>  > summary(aovRecall)
>
>
> Error: Subject
>
>                Df Sum Sq Mean Sq F value Pr(>F)
>
> Gender         1  542.3   542.3   5.685 0.0345 *
>
> Dosage         2  694.9   347.5   3.643 0.0580 .
>
> Gender:Dosage  2   70.8    35.4   0.371 0.6976
>
> Residuals     12 1144.6    95.4
>
> ---
>
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
>
> Error: Subject:Valence
>
>                        Df Sum Sq Mean Sq F value Pr(>F)
>
> Valence                2  14.69   7.343   2.998 0.0688 .
>
> Gender:Valence         2   3.91   1.954   0.798 0.4619
>
> Dosage:Valence         4  20.26   5.065   2.068 0.1166
>
> Gender:Dosage:Valence  4   1.04   0.259   0.106 0.9793
>
> Residuals             24  58.78   2.449
>
> ---
>
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
>
> Error: Subject:Task
>
>                     Df Sum Sq Mean Sq F value   Pr(>F)
>
> Task                1  96.33   96.33  39.862 3.87e-05 ***
>
> Gender:Task         1   1.33    1.33   0.552    0.472
>
> Dosage:Task         2   8.17    4.08   1.690    0.226
>
> Gender:Dosage:Task  2   3.17    1.58   0.655    0.537
>
> Residuals          12  29.00    2.42
>
> ---
>
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
>
> Error: Subject:Valence:Task
>
>                             Df Sum Sq Mean Sq F value Pr(>F)
>
> Valence:Task                2   5.39  2.6944   1.320  0.286
>
> Gender:Valence:Task         2   2.17  1.0833   0.531  0.595
>
> Dosage:Valence:Task         4   2.78  0.6944   0.340  0.848
>
> Gender:Dosage:Valence:Task  4   2.67  0.6667   0.327  0.857
>
> Residuals                  24  49.00  2.0417
>
>
> Then I tried with your proposals:
>
>
>  > testIan
>
>
> Linear mixed model fit by REML
>
> Formula: Recall ~ (Gender * Dosage * Valence * Task) + (1 | Subject)
>
>   AIC   BIC logLik deviance REMLdev
>
>   424 525.9   -174    418.9     348
>
> Random effects:
>
>   Groups   Name        Variance Std.Dev.
>
>   Subject  (Intercept) 15.5167  3.9391
>
>   Residual              2.2796  1.5098
>
> Number of obs: 108, groups: Subject, 18
>
>
> Fixed effects:
>
>                                     Estimate Std. Error t value
>
> (Intercept)                       1.733e+01  2.435e+00   7.117
>
> GenderM                          -4.667e+00  3.444e+00  -1.355
>
> DosageB                           1.324e-12  3.444e+00   0.000
>
> DosageC                           3.333e+00  3.444e+00   0.968
>
> ValenceNeu                        2.330e-13  1.233e+00   0.000
>
> ValencePos                       -3.333e-01  1.233e+00  -0.270
>
> TaskF                            -1.333e+00  1.233e+00  -1.082
>
> GenderM:DosageB                  -2.667e+00  4.871e+00  -0.547
>
> GenderM:DosageC                   2.000e+00  4.871e+00   0.411
>
> GenderM:ValenceNeu               -2.225e-13  1.743e+00   0.000
>
> GenderM:ValencePos                3.333e-01  1.743e+00   0.191
>
> DosageB:ValenceNeu                6.667e-01  1.743e+00   0.382
>
> DosageC:ValenceNeu                1.000e+00  1.743e+00   0.574
>
> DosageB:ValencePos                2.667e+00  1.743e+00   1.530
>
> DosageC:ValencePos                1.000e+00  1.743e+00   0.574
>
> GenderM:TaskF                    -3.333e-01  1.743e+00  -0.191
>
> DosageB:TaskF                    -1.000e+00  1.743e+00  -0.574
>
> DosageC:TaskF                     3.333e-01  1.743e+00   0.191
>
> ValenceNeu:TaskF                 -6.667e-01  1.743e+00  -0.382
>
> ValencePos:TaskF                  6.667e-01  1.743e+00   0.382
>
> GenderM:DosageB:ValenceNeu        1.000e+00  2.466e+00   0.406
>
> GenderM:DosageC:ValenceNeu        2.372e-13  2.466e+00   0.000
>
> GenderM:DosageB:ValencePos       -3.333e-01  2.466e+00  -0.135
>
> GenderM:DosageC:ValencePos        2.340e-13  2.466e+00   0.000
>
> GenderM:DosageB:TaskF             1.000e+00  2.466e+00   0.406
>
> GenderM:DosageC:TaskF             6.667e-01  2.466e+00   0.270
>
> GenderM:ValenceNeu:TaskF          1.333e+00  2.466e+00   0.541
>
> GenderM:ValencePos:TaskF         -1.333e+00  2.466e+00  -0.541
>
> DosageB:ValenceNeu:TaskF         -1.333e+00  2.466e+00  -0.541
>
> DosageC:ValenceNeu:TaskF         -1.333e+00  2.466e+00  -0.541
>
> DosageB:ValencePos:TaskF         -1.667e+00  2.466e+00  -0.676
>
> DosageC:ValencePos:TaskF         -6.667e-01  2.466e+00  -0.270
>
> GenderM:DosageB:ValenceNeu:TaskF -6.667e-01  3.487e+00  -0.191
>
> GenderM:DosageC:ValenceNeu:TaskF -3.333e-01  3.487e+00  -0.096
>
> GenderM:DosageB:ValencePos:TaskF  2.667e+00  3.487e+00   0.765
>
> GenderM:DosageC:ValencePos:TaskF  3.333e-01  3.487e+00   0.096
>
>
>  > testBen
>
>
> Linear mixed model fit by REML
>
> Formula: Recall ~ (Gender * Dosage * Valence * Task) + (Valence * Task
> |      Subject)
>
>     AIC   BIC logLik deviance REMLdev
>
>   413.5 569.1 -148.8    343.2   297.5
>
> Random effects:
>
>   Groups   Name             Variance Std.Dev. Corr
>
>   Subject  (Intercept)      29.38096 5.4204
>
>            ValenceNeu        6.92965 2.6324   -0.710
>
>            ValencePos       10.70611 3.2720   -0.729  0.915
>
>            TaskF             5.92752 2.4347   -0.820  0.857  0.759
>
>            ValenceNeu:TaskF  3.63960 1.9078    0.832 -0.932 -0.778 -0.930
>
>            ValencePos:TaskF 13.78699 3.7131    0.785 -0.951 -0.950 -0.809
>
>   Residual                   0.17464 0.4179
>
>    0.879
>
> Number of obs: 108, groups: Subject, 18
>
>
> Fixed effects:
>
>                                     Estimate Std. Error t value
>
> (Intercept)                       1.733e+01  3.139e+00   5.522
>
> GenderM                          -4.667e+00  4.439e+00  -1.051
>
> DosageB                           1.562e-11  4.439e+00   0.000
>
> DosageC                           3.333e+00  4.439e+00   0.751
>
> ValenceNeu                        5.690e-12  1.558e+00   0.000
>
> ValencePos                       -3.333e-01  1.920e+00  -0.174
>
> TaskF                            -1.333e+00  1.446e+00  -0.922
>
> GenderM:DosageB                  -2.667e+00  6.278e+00  -0.425
>
> GenderM:DosageC                   2.000e+00  6.278e+00   0.319
>
> GenderM:ValenceNeu               -5.003e-12  2.203e+00   0.000
>
> GenderM:ValencePos                3.333e-01  2.715e+00   0.123
>
> DosageB:ValenceNeu                6.667e-01  2.203e+00   0.303
>
> DosageC:ValenceNeu                1.000e+00  2.203e+00   0.454
>
> DosageB:ValencePos                2.667e+00  2.715e+00   0.982
>
> DosageC:ValencePos                1.000e+00  2.715e+00   0.368
>
> GenderM:TaskF                    -3.333e-01  2.046e+00  -0.163
>
> DosageB:TaskF                    -1.000e+00  2.046e+00  -0.489
>
> DosageC:TaskF                     3.333e-01  2.046e+00   0.163
>
> ValenceNeu:TaskF                 -6.667e-01  1.203e+00  -0.554
>
> ValencePos:TaskF                  6.667e-01  2.197e+00   0.303
>
> GenderM:DosageB:ValenceNeu        1.000e+00  3.115e+00   0.321
>
> GenderM:DosageC:ValenceNeu        5.803e-12  3.115e+00   0.000
>
> GenderM:DosageB:ValencePos       -3.333e-01  3.839e+00  -0.087
>
> GenderM:DosageC:ValencePos        6.274e-12  3.839e+00   0.000
>
> GenderM:DosageB:TaskF             1.000e+00  2.893e+00   0.346
>
> GenderM:DosageC:TaskF             6.667e-01  2.893e+00   0.230
>
> GenderM:ValenceNeu:TaskF          1.333e+00  1.701e+00   0.784
>
> GenderM:ValencePos:TaskF         -1.333e+00  3.108e+00  -0.429
>
> DosageB:ValenceNeu:TaskF         -1.333e+00  1.701e+00  -0.784
>
> DosageC:ValenceNeu:TaskF         -1.333e+00  1.701e+00  -0.784
>
> DosageB:ValencePos:TaskF         -1.667e+00  3.108e+00  -0.536
>
> DosageC:ValencePos:TaskF         -6.667e-01  3.108e+00  -0.215
>
> GenderM:DosageB:ValenceNeu:TaskF -6.667e-01  2.405e+00  -0.277
>
> GenderM:DosageC:ValenceNeu:TaskF -3.333e-01  2.405e+00  -0.139
>
> GenderM:DosageB:ValencePos:TaskF  2.667e+00  4.395e+00   0.607
>
> GenderM:DosageC:ValencePos:TaskF  3.333e-01  4.395e+00   0.076
>
>
> First of all, I have some difficulties in matching these two models with
> the aov one, since these two obtained with lmer function display the
> estimates for the levels of each factor, whereas the aov one displays
> the estimates for the factors themselves.
>
>
> Anyway, the main problem is that none of the two lmer models seems to
> distinguish from between and within factors. The solutions you suggested
> me seems to deal only with the concepts of fixed and random effects.
> Moreover the aov function doesn't make this distinction. I'm beginning
> to think that lmer can't perform an ANOVA.
>
>
> I need to think more about this.
>
>
>
>
> On Sun, Mar 24, 2013 at 6:12 PM, ian m s white <i.m.s.white at ed.ac.uk
> <mailto:i.m.s.white at ed.ac.uk>> wrote:
>
>     I reckon lmer can figure out for itself what is between and what is
>     within subjects, so
>
>     lmer(DV ~ IV1*IV2*IV3*IV4 + (1|Subject))
>
>     should fit the same model as your ANOVA.
>
>
>     On 24 Mar 2013, at 08:56, Vanni Rovera <vanni.rovera at gmail.com
>     <mailto:vanni.rovera at gmail.com>> wrote:
>
>      > Hi there,
>      >
>      > I'm trying to understand how to use the function lmer in order to
>     do a
>      > 'between-and-within-factors' ANOVA, but without any success. I
>     know about
>      > the usage of the function aov, but this holds only for balanced
>     designs;
>      > its documentation say to use lme function (package nlme) for
>     unbalanced
>      > designs. Furthermore I found the lmer function (package lme4) is an
>      > evolution of lme, so I wish to use this last function in order to
>     perform
>      > my ANOVA. But I'm not able to understand how to do this.
>      >
>      > More precisely, imagine you have a dependent variable DV and four
>      > independent variables IV1, IV2, IV3, IV4, where IV1, IV2 are
>      > between-factors and IV3, IV4 are within-factors. Moreover you have a
>      > variable called Subject in order to identify the subject on which
>      > measurements are done (like for example this dataset:
>      > http://personality-project.org/r/datasets/R.appendix5.data). If I
>     use the
>      > aov function, my 'between-and-within-factors' ANOVA would stand
>     as follows:
>      >
>      > aov(DV~(IV1*IV2*IV3*IV4)+Error(Subject/(IV3*IV4))).
>      >
>      > Now can you write me the precise syntax in order to obtain the
>     same result
>      > with the lmer function?
>      >
>      > Thanks a lot in advance!
>      > Vanni Rovera
>      >
>      >
>      >
>      > *Additional details:* The problem is that no one seems to be
>     interested in
>      > explain the relations of 'within-factor' and 'between-factor'
>     concepts with
>      > those of 'fixed-effect' and 'random-effect'. Textbooks and papers
>     about
>      > ANOVA talk about between and within factors, while documentations and
>      > papers about lmer function talk about mixed-effects models, i.e.
>     they talk
>      > about fixed and random effects, without mentioning between and within
>      > factors. *Thus I am not able to understand the relations between
>     the two,
>      > since I think they are completely uncorrelated each others, and
>     hence I am
>      > not able to use the syntax in lmer in order to distinguish
>     between factors
>      > from within factors.*
>      >
>      >       [[alternative HTML version deleted]]
>      >
>      > _______________________________________________
>      > R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>      > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>      >
>
>
>     --
>     The University of Edinburgh is a charitable body, registered in
>     Scotland, with registration number SC005336.
>
>

-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From mslain at utu.fi  Wed Mar 27 13:00:32 2013
From: mslain at utu.fi (Mari Laine)
Date: Wed, 27 Mar 2013 12:00:32 +0000
Subject: [R-sig-ME] Model selection in GAMM
Message-ID: <3C72E5613CEAC64D9CBCF9CB60442D6C3AC5B1C5@exch-mbx-01.utu.fi>

Hi to all,

thanks for your help, I think I'll try to avoid AIC comparison then.

   - Mari Laine -


> On Mon, Mar 18, 2013 at 4:47 PM, Joshua Wiley <jwiley.psych at
> gmail.com> wrote:
> 
> Sorry, I missed the "temporal structures" bit from the OP.  Apologies
> for the noise.
> 
> On Mon, Mar 18, 2013 at 4:46 PM, Joshua Wiley <jwiley.psych at
> gmail.com> wrote:
> > A bit off from the other topics, but back to the original, if you use
> > gamm4, it uses lme4 (lmer/glmer) for the mixed model.  One implication
> > is that you can get true likelihoods using the Laplace approximation
> > or numerical integration.  So at least for comparing models with
> > different parametric effects, it would seem you could use that
> > approach.  I am uncertain for the overall model, because you get both
> > a gam and mer object.
> >
> > On Mon, Mar 18, 2013 at 6:29 AM, Ben Bolker <bbolker at gmail.com>
> wrote:
> >> Andrew Robinson <A.Robinson at ...> writes:
> >>
> >>>
> >>> On Sun, Mar 17, 2013 at 07:44:28PM +0000, Ben Bolker wrote:
> >>> > Mari Laine <mslain at ...> writes:
> >>> >
> >>> >
> >>> > > I'm using GAMM (mgcv::gamm) to fit non-Gaussian models with
> several
> >>> > > fixed factors and also a temporal structure. Additionally, I'm
> >>> > > fitting non-linearity with smoothers. I have several correlated main
> >>> > > effect candidates, and I would like to compare their GAMMs and
> see,
> >>> > > which one of the models best fits the data. I would also need to
> >>> > > tune the models via dropping unnecessary smoothers (linear ones)
> and
> >>> > > non-significant fixed variables.
> >>> >
> >>> > > After going through some statistical books, I'm under the impression
> >>> > > that one should not use AIC comparison of $lme's for GAMM models
> -
> >>> > > is this correct? Could someone give instruction on the model
> >>> > > selection in GAMM or refer me to a book / some other source of
> >>> > > information on this matter?
> >>> >
> >>> >   To my knowledge there are two issues here:
> >>> >
> >>> > (1) GAMM uses penalized quasi-likelihood.  According to some
> >>> > statisticians (including Brian Ripley, who wrote the original PQL
> >>> > code in MASS::glmmPQL, which might be what GAMM relies on -- I
> don't
> >>> > remember, it might incorporate its own PQL code), one shouldn't use
> >>> > likelihood-based approaches (including AIC) with PQL algorithms,
> >>> > because they don't estimate a true likelihood (others say it's OK as
> >>> > long as you make sure to scale the likelihood to get a
> >>> > quasi-likelihood before combining it with the penalty term to get a
> >>> > QIC).
> >>>
> >>> Hi Ben,
> >>>
> >>> I know that you're reporting third-party opinions, and you're not
> >>> necessarily advocating this position yourself, but I wonder if you can
> >>> provide some more information - even a link or a citation to them?
> >>
> >>   Hmm.  I may be in over my head here, so *please* treat anything
> >> I say below as false until proven true ...
> >>
> >>>
> >>> I'm a bit confused about how scaling the maximized penalized
> >>> likelihood (MPL) can deliver something that can be treated as though
> >>> it were a maximized likelihood.
> >>>
> >>> To my way of thinking, a point of maximizing the penalized likelihood
> >>> is that you get an estimate with better statistical properties than
> >>> the MLE.
> >>
> >>   It's been a long time since I looked at this, and I don't understand
> >> it well enough, but it was my understanding that the quantity maximized
> >> by PQL is an *approximation* to the marginal likelihood used in all
> >> other GLMM applications (i.e. the conditional likelihood of the data
> >> given fixed values of the random effects, weighted by the probability
> >> of those RE values given the distribution of the REs, integrated over
> >> all possible values of the REs) -- one that is less accurate than
> >> Laplace approximation and Gauss-Hermite quadrature, but an
> approximation
> >> to the same quantity nevertheless.
> >>
> >>   So I thought the idea was not (in this case) to get an estimate
> >> with better properties than the MLE, but to get an estimate of the
> >> marginal likelihood at all ...
> >>
> >>> It is overwhelmingly likely that this MPL estimate will be different
> >>> from the MLE.  It's hard for me to imagine a way that the PL function
> >>> can be scaled so that the MPLE can be treated as though it were an
> >>> MLE.  If the MPLE won't be the same as the MLE, then the L can't be
> >>> maximized at the MPLE.  Further, the PL function will be a different
> >>> shape at the optimum (I intuit) than the L would be at its optimum.
> >>
> >>     For one quick practical counterexample, glmmPQL generally gives
> >> _similar_ answers to glmer/glmmADMB etc. (i.e. methods based on
> >> Laplace or better approximations) for large data sets and those
> >> where the counts per individual sample are large ...
> >>>
> >>> So, is there theory to suggest that the properties of the MLE that are
> >>> relied upon by the various measures of information are retained by the
> >>> MPLE?  And if so, even then, wouldn't those properties depend on the
> >>> nature of the penalization?
> >>
> >>    I would love to know the answer.  I hope someone more
> knowledgeable,
> >> or with much more time to spend figuring this out, comes forward.
> >>
> >>   Ben
> >>
> >>
> >>>
> >>> > (2) As I recall it's a little tricky to figure out which components
> >>> > of a GAMM call contain which kinds of information about the fit.
> >>> > In particular it's not clear whether the likelihood/AIC reported
> >>> > in the lme component of the fit really reflect an appropriate
> >>> > (quasi)likelihood/IC of the full model; I believe there's a lot
> >>> > of detail on this in the ?gamm help page: in particular,
> >>> >
> >>> > > For example,
> >>> > > unlike 'glmmPQL' from 'MASS' it will return the complete 'lme'
> >>> > > object from the working model at convergence of the PQL iteration,
> >>> > > including the `log likelihood', even though this is not the
> >>> > > likelihood of the fitted GAMM.
> >>> >
> >>> > which suggests you shouldn't use that log-likelihood ...
> >>> >
> >>> >   I would look for further information in Simon Wood's excellent book
> on
> >>> > generalized additive models.
> >>> >
> >>> > _______________________________________________
> >>> > R-sig-mixed-models <at> r-project.org mailing list
> >>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>>
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> >
> >
> > --
> > Joshua Wiley
> > Ph.D. Student, Health Psychology
> > University of California, Los Angeles
> > http://joshuawiley.com/
> > Senior Analyst - Elkhart Group Ltd.
> > http://elkhartgroup.com
> 
> 
> 
> --
> Joshua Wiley
> Ph.D. Student, Health Psychology
> University of California, Los Angeles
> http://joshuawiley.com/
> Senior Analyst - Elkhart Group Ltd.
> http://elkhartgroup.com


From baud-bovy.gabriel at hsr.it  Wed Mar 27 22:25:12 2013
From: baud-bovy.gabriel at hsr.it (Gabriel Baud-Bovy)
Date: Wed, 27 Mar 2013 22:25:12 +0100
Subject: [R-sig-ME] random effects with covariance matrix depending on a
	group characteristic
Message-ID: <515363B8.7040503@hsr.it>

Dear all,

I am trying to define a new covariance structure  for the random effects 
in lme
but I don't know if it is possible.

Let's assume that I have always two experimental units S (j=1,2) nested
inside a grouping variable G (n groups, i=1,..,n) and a third factor D that
takes the value  1 or 2 depending on some group-level characteristic.

For example,D=1 for group 1 and 3 and D=2 for group 2:

G    A    D    Y
1    1    1    y_11
1    2    1    y_12
2    1    2    y_21
2    2    2 y_22
3    1    1    y_31
3    2    1    y_32

I would like to define the following mixed-effect model

y_ij = mu  + a_ij  + e_ij

where y_ij is the observation for on unit j in group i, mu is the intercept,
a_ij the random effect and e_ij the residuals. The random effect a_ij 
must have
a covariance structure that dependson the variable D

1. random effects between two different groups are not correlated:
cov([bi1 bi'2]) = 0        if i != i'

2. correlation between the experimental units inside each group
depend on the group characteristic D:
cov([bi1 bi2])  = var_A*P  if D_i = 1
cov([bi1 bi2])  = var_A*Q  if D_i = 2

where P and Q are two different 2x2 correlation matrices with fixed 
coefficients.
Note that only the correlation pattern change, not the variance var_A.

The covariance structure for the residuals is standard

cov(e) = sigma2*diag(n)


I know that I have to define a new pdMat class but I have two questions:

1) how to speficify the model? This is how I would do it if the covariance
matrix did not depend on the group characteristic D:

lme(Y ~ 1 , random = list(G=pdNew(~A)), data )

but I don't know how to make it depend on group characteristic D.
Is it possible and how would you specify the dependency of D?

2) what is the unconstrained matrix-logarithm parametrization for
acovariance matrix sigma2*A where M is a fixed pattern?

Is the solution simply log(sigma2*A) = log(sigma2) + log(A) with
log(A) = Ulog(L)U' where ULU is the eigenvalue decomposition?


Thank you,

Gabriel


-- 
---------------------------------------------------------------------
Gabriel Baud-Bovy                     email:gabriel.baud-bovy at iit.it  
RBCS, Italian Institute of Technology     tel.: (+39) 010 71781 (822)
via Morego 30, 16163 Genovahttp://www.iit.it


From bbolker at gmail.com  Thu Mar 28 02:58:25 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 28 Mar 2013 01:58:25 +0000 (UTC)
Subject: [R-sig-ME] mixed model negative bionomial
References: <59311B7BAD60F14E99B53F85C5413E221CE38A24@WDCWASP435.network.maf.govt.nz>
Message-ID: <loom.20130328T025435-767@post.gmane.org>

Andrew McFadden (Andy <Andrew.McFadden at ...> writes:

> 
> Hi all
 
> Really appreciate a hand here. I am trying to model some data with a
> bionomial outcome. I believe that I need to use a negative bionomial
> distribution as there were a lot of samples where a large number of
> zeros were present i.e. none sick and when modelled using a
> bionomial distribution in the lme4 package the residuals were
> extremely high. Hence the attempted use of gamlss package.

  I can't help with gamlss at the moment, but: the negative binomial
is *not* an appropriate generalization of the binomial (unless you
have low probabilities everywhere and want to approximate the binomial
by a Poisson, in which case you would then get a NB).  Beta-binomial
is to binomial and NB is to Poisson.  You can model overdispersion
(which is *one* route to many zeros -- another is simply very low
overall prevalence, and a third is zero-inflation) in various ways:
see http://glmm.wikidot.com/faq ...
 
> I have had difficulty coding the model for the gamlss package,
> perhaps I have done something wrong. Also I would like to include
> the denominator in the outcome as the sample size varied per group
> i.e. in the lme4 package I coded it as:
> glmer(cbind(dat$NSick,dat$Ntest); but couldn't seem to do this in
> gamlss.

> The data below is "made up data", but reflects the analysis I am
> doing i.e. data clustered within farm (hence the need for a random
> effect), Lots of zero outcome (and the need to use a negative
> bionomial equation).

 Overdispersion can be modeled in various packages; glmmADMB handles
zero-inflation (although it's not well tested for binomial models,
so check your results especially carefully).

  Ben Bolker


From tpd502 at york.ac.uk  Thu Mar 28 17:15:32 2013
From: tpd502 at york.ac.uk (Thomas Devlin)
Date: Thu, 28 Mar 2013 16:15:32 +0000
Subject: [R-sig-ME] mixed effects model - log likelihood test
Message-ID: <CA+cEKWdhb-q6aqSBFue+Yhg3Vv8G00ahgMVLZdYJrEmPU1x6_g@mail.gmail.com>

Hi

I am trying to investigate the effect of topic (conversational context - 3
variants) on the linguistic production (code - 4 variants) of 16 speakers.
I want to run a mixed effects model with (speaker - 16 variants) and (word
500+ variants) as random effects to see whether they improve the model's
ability to predict the linguistic production (code). I also want to include
the fixed effects of speaker occupation (2 variants: miner/non-miner) and
speaker location (4 variants). I want to use log-likelihood tests on a
model including topic (conversational context) vs a model discounting topic
to gauge significance. Can anyone tell me where to start? I have tried
using functions lme, lmer and lrtest, and the multinomial logit model but
I'm not sure whether they are right for my data. Any help would be greatly
appreciated (data attached).

Thanks

-- 
Thomas Devlin
PhD candidate, Department of Language and Linguistic Science,
University of York, York, YO10 5DD, UK
tpd502 at york.ac.uk
-------------- next part --------------
speaker	word	age	f1 on	f1 off	code	conv cont	miner	location
D70	down	70	535	520	a	word list	y	dawdon
D70	surrounded	70	535	450	a	word list	y	dawdon
D70	downstairs	70	500	520	a	word list	y	dawdon
D70	shouted	70	550	520	a	word list	y	dawdon
D70	proud	70	535	500	a	word list	y	dawdon
D70	about	70	585	515	a	general	y	dawdon
D70	down	70	565	485	a	general	y	dawdon
D70	about	70	510	535	a	general	y	dawdon
D70	now	70	620	565	a	general	y	dawdon
D70	round	70	515	645	a	general	y	dawdon
D70	now	70	520	535	a	general	y	dawdon
D70	now	70	555	500	a	general	y	dawdon
D70	about	70	535	510	a	general	y	dawdon
D70	houses	70	660	560	a	general	y	dawdon
D70	out	70	705	550	a	general	y	dawdon
D70	out	70	650	520	a	general	y	dawdon
D70	about	70	550	525	a	general	y	dawdon
D70	now	70	535	500	a	general	y	dawdon
D70	now	70	580	530	a	general	y	dawdon
D70	round	70	535	450	a	mining	y	dawdon
D70	out	70	585	470	a	mining	y	dawdon
D70	out	70	565	470	a	mining	y	dawdon
D70	trousers	70	550	485	a	mining	y	dawdon
D70	now	70	635	560	a	mining	y	dawdon
D70	down	70	540	480	a	mining	y	dawdon
D70	down	70	530	450	a	mining	y	dawdon
D70	underground	70	535	460	a	mining	y	dawdon
D70	down	70	540	435	a	mining	y	dawdon
D70	out	70	565	460	a	mining	y	dawdon
D72	out	72	540	490	a	word list	y	dawdon
D72	outside	72	520	450	a	word list	y	dawdon
D72	down	72	500	440	a	word list	y	dawdon
D72	south	72	565	515	a	word list	y	dawdon
D72	farmhouse	72	550	485	a	word list	y	dawdon
D72	surrounded	72	500	435	a	word list	y	dawdon
D72	downstairs	72	580	435	a	word list	y	dawdon
D72	shouted	72	515	500	a	word list	y	dawdon
D72	house	72	580	525	a	word list	y	dawdon
D72	out	72	550	520	a	word list	y	dawdon
D72	found	72	575	475	a	word list	y	dawdon
D72	about	72	550	485	a	general	y	dawdon
D72	house	72	585	515	a	general	y	dawdon
D72	out	72	620	465	a	general	y	dawdon
D72	about	72	585	520	a	general	y	dawdon
D72	roundness	72	570	550	a	general	y	dawdon
D72	grounds	72	535	470	a	general	y	dawdon
D72	town	72	615	490	a	general	y	dawdon
D72	council	72	585	500	a	general	y	dawdon
D72	down	72	600	570	a	general	y	dawdon
D72	town	72	550	480	a	general	y	dawdon
D72	council	72	575	500	a	general	y	dawdon
D72	how	72	600	525	a	general	y	dawdon
D72	now	72	630	530	a	general	y	dawdon
D72	house	72	620	495	a	general	y	dawdon
D72	council	72	650	515	a	general	y	dawdon
D72	out	72	585	535	a	general	y	dawdon
D72	out	72	600	470	a	general	y	dawdon
D72	round	72	540	490	a	general	y	dawdon
D72	about	72	585	515	a	general	y	dawdon
D72	found	72	635	600	a	mining	y	dawdon
D72	out	72	580	550	a	mining	y	dawdon
D72	about	72	530	495	a	mining	y	dawdon
D72	out	72	530	495	a	mining	y	dawdon
D72	output	72	580	510	a	mining	y	dawdon
D72	round	72	520	430	a	mining	y	dawdon
D72	houses	72	650	505	a	mining	y	dawdon
D72	house	72	700	480	a	mining	y	dawdon
D72	house	72	680	500	a	mining	y	dawdon
D72	council	72	635	480	a	mining	y	dawdon
D72	house	72	530	480	a	mining	y	dawdon
D72	houses	72	565	540	a	mining	y	dawdon
D72	house	72	540	520	a	mining	y	dawdon
D72	housing	72	680	560	a	mining	y	dawdon
D72	down	72	650	530	a	mining	y	dawdon
D72	allowed	72	640	530	a	mining	y	dawdon
D72	how	72	615	500	a	mining	y	dawdon
D72	how	72	630	495	a	mining	y	dawdon
D72	around	72	525	530	a	mining	y	dawdon
D72	round	72	560	445	a	mining	y	dawdon
D72	out	72	595	510	a	mining	y	dawdon
D72	down	72	600	495	a	mining	y	dawdon
D72	about	72	525	455	a	mining	y	dawdon
D72	about	72	575	515	a	mining	y	dawdon
D85	farmhouse	85	535	470	a	word list	y	dawdon
D85	downstairs	85	485	535	a	word list	y	dawdon
D85	now if (Disc)	85	540	480	a	mining	y	dawdon
D85	gan down the	85	555	520	a	mining	y	dawdon
D85	now # (Disc)	85	490	485	a	mining	y	dawdon
D85	gannin down the	85	520	520	a	mining	y	dawdon
D85	go down the	85	555	455	a	mining	y	dawdon
D85	go down the	85	535	505	a	mining	y	dawdon
D85	gan down the	85	535	540	a	mining	y	dawdon
D85	cottages out there	85	520	500	a	mining	y	dawdon
D85	colliery houses cos	85	575	520	a	mining	y	dawdon
D85	colliery house Dawdon	85	530	500	a	mining	y	dawdon
D85	colliery houses aye	85	500	485	a	mining	y	dawdon
D85	colliery houses	85	535	500	a	mining	y	dawdon
D85	colliery house he	85	570	520	a	mining	y	dawdon
D85	but down the	85	555	525	a	mining	y	dawdon
D85	at now I	85	500	465	a	mining	y	dawdon
D85	yes down the	85	545	575	a	mining	y	dawdon
D85	men down the	85	500	500	a	mining	y	dawdon
D85	clout them	85	515	425	a	general	y	dawdon
D85	them down the	85	430	510	a	general	y	dawdon
D85	the councillors all	85	575	575	a	general	y	dawdon
D85	the outcome came	85	570	485	a	general	y	dawdon
D85	messes about with	85	430	500	a	general	y	dawdon
D85	home now aye	85	610	595	a	general	y	dawdon
D85	Bill down London	85	555	500	a	general	y	dawdon
D85	football now #	85	595	620	a	general	y	dawdon
D85	here how many	85	610	555	a	general	y	dawdon
D85	many how many	85	555	490	a	general	y	dawdon
D85	England now belong	85	520	470	a	general	y	dawdon
D85	them out the	85	485	520	a	general	y	dawdon
D73	down	73	485	550	a	word list	n	dawdon
D73	south	73	540	480	a	word list	n	dawdon
D73	surrounded	73	485	470	a	word list	n	dawdon
D73	downstairs	73	520	550	a	word list	n	dawdon
D73	shouted	73	520	485	a	word list	n	dawdon
D73	house	73	470	430	a	word list	n	dawdon
D73	out	73	600	500	a	word list	n	dawdon
D73	pulled down Camden	73	555	610	a	general	n	dawdon
D73	school down where	73	575	550	a	general	n	dawdon
D73	come out the	73	560	520	a	general	n	dawdon
D73	dunno how long	73	540	520	a	general	n	dawdon
D73	words out and	73	540	550	a	general	n	dawdon
D73	it South Africa	73	575	520	a	general	n	dawdon
D73	Australia South America	73	540	505	a	general	n	dawdon
D73	it down #	73	590	450	a	general	n	dawdon
D73	right down #	73	575	575	a	general	n	dawdon
D73	cricket now I	73	575	535	a	general	n	dawdon
D73	football now #	73	590	575	a	general	n	dawdon
D73	players around the 	73	575	555	a	general	n	dawdon
D73	in about ten	73	600	525	a	general	n	dawdon
D73	money out of	73	645	520	a	general	n	dawdon
D73	go out the	73	505	485	a	general	n	dawdon
D73	wireless now I (disc)	73	465	520	a	general	n	dawdon
D73	turned round he	73	540	520	a	general	n	dawdon
D73	wasn't out actually	73	575	520	a	general	n	dawdon
D73	standing shouting it	73	530	520	a	general	n	dawdon
D73	walking down the 	73	555	520	a	general	n	dawdon
D73	the house school	73	540	500	a	general	n	dawdon
D73	were out nine	73	500	450	a	general	n	dawdon
D73	maybes about twenty	73	485	485	a	general	n	dawdon
D73	with about six	73	540	465	a	general	n	dawdon
D73	were outside mostly	73	570	465	a	mining	n	dawdon
D73	Jack out and	73	645	485	a	mining	n	dawdon
D73	Les out and	73	560	500	a	mining	n	dawdon
D73	me out cos	73	585	490	a	mining	n	dawdon
D73	staff down #	73	575	520	a	mining	n	dawdon
D73	had showers at	73	555	520	a	mining	n	dawdon
D73	the house they	73	680	470	a	mining	n	dawdon
D73	modern house with	73	590	465	a	mining	n	dawdon
D73	bathroom downstairs in	73	465	465	a	mining	n	dawdon
D73	plugs downstairs one	73	540	520	a	mining	n	dawdon
D73	the house washing	73	495	440	a	mining	n	dawdon
D73	go out and	73	580	535	a	mining	n	dawdon
D73	rail round the	73	500	485	a	mining	n	dawdon
D73	the house for	73	610	570	a	mining	n	dawdon
D73	person now you've	73	575	555	a	mining	n	dawdon
D73	people now living	73	590	520	a	mining	n	dawdon
D73	it now Monday	73	640	550	a	mining	n	dawdon
D73	was about forty	73	555	465	a	mining	n	dawdon
D73	side now where	73	590	470	a	mining	n	dawdon
D73	is now that	73	470	570	a	mining	n	dawdon
D73	is now the	73	575	550	a	mining	n	dawdon
D73	space now with	73	540	465	a	mining	n	dawdon
D73	pictures now you're	73	590	555	a	mining	n	dawdon
D73	not allowed to	73	465	585	a	mining	n	dawdon
D73	cinema now you	73	610	520	a	mining	n	dawdon
D73	raised about two	73	540	470	a	mining	n	dawdon
D73	goin out to	73	595	540	a	mining	n	dawdon
D73	a crowd of	73	575	520	a	mining	n	dawdon
E64	out	64	540	475	a	word list	y	easington
E64	out	64	545	505	a	word list	y	easington
E64	down	64	535	500	a	general	y	easington
E64	about	64	525	525	a	general	y	easington
E64	about	64	500	450	a	mining	y	easington
E64	out	64	590	515	a	mining	y	easington
E64	turnout	64	600	465	a	mining	y	easington
E64	about	64	500	520	a	mining	y	easington
E64	out	64	570	500	a	mining	y	easington
E64	about	64	515	500	a	mining	y	easington
E64	around	64	535	495	a	mining	y	easington
E71	down	71	520	485	a	word list	y	easington
E71	town	71	550	500	a	word list	y	easington
E71	down	71	535	500	a	word list	y	easington
E71	south	71	550	485	a	word list	y	easington
E71	out	71	515	500	a	word list	y	easington
E71	about	71	465	450	a	general	y	easington
E71	now	71	665	535	a	general	y	easington
E71	south	71	570	535	a	general	y	easington
E71	down	71	615	605	a	general	y	easington
E71	out	71	565	510	a	general	y	easington
E71	outweigh	71	550	500	a	general	y	easington
E71	out	71	525	500	a	general	y	easington
E71	how	71	640	505	a	general	y	easington
E71	how	71	650	500	a	general	y	easington
E71	councils	71	635	500	a	general	y	easington
E71	about	71	540	480	a	general	y	easington
E71	south	71	630	480	a	general	y	easington
E71	pounds	71	660	605	a	general	y	easington
E71	down	71	550	505	a	general	y	easington
E71	pound	71	655	585	a	general	y	easington
E71	pound	71	610	585	a	general	y	easington
E71	down	71	580	515	a	general	y	easington
E71	out	71	610	480	a	general	y	easington
E71	thousand	71	600	550	a	general	y	easington
E71	about	71	520	495	a	general	y	easington
E71	thousand	71	565	500	a	general	y	easington
E71	how	71	550	550	a	general	y	easington
E71	out	71	635	540	a	general	y	easington
E71	now	71	640	580	a	general	y	easington
E71	out	71	605	500	a	general	y	easington
E71	aboutN	71	530	515	a	mining	y	easington
E71	downN	71	570	500	a	mining	y	easington
E71	nowN	71	565	550	a	mining	y	easington
E71	outN	71	585	515	a	mining	y	easington
E71	undergroundN	71	635	500	a	mining	y	easington
E71	undergroundN	71	540	475	a	mining	y	easington
E71	outN	71	610	495	a	mining	y	easington
E71	howN	71	585	470	a	mining	y	easington
E71	undergroundN	71	560	505	a	mining	y	easington
E71	Doughty'sN	71	650	510	a	mining	y	easington
E71	roundN	71	600	540	a	mining	y	easington
E71	outN	71	550	495	a	mining	y	easington
E71	groundN	71	570	500	a	mining	y	easington
E71	aboutN	71	535	510	a	mining	y	easington
E71	now	71	535	500	a	mining	y	easington
E71	housesN	71	560	490	a	mining	y	easington
E71	downN	71	530	520	a	mining	y	easington
E71	downN	71	550	485	a	mining	y	easington
E71	nowN	71	570	535	a	mining	y	easington
E71	outN	71	635	475	a	mining	y	easington
E71	allowN	71	585	500	a	mining	y	easington
E71	downN	71	550	520	a	mining	y	easington
E71	aboutN	71	505	485	a	mining	y	easington
E61	unfortunately around what	61	650	720	a	mining	y	easington
E78	chat about things	78	450	520	a	general	n	easington
E78	laptop out and	78	520	550	a	general	n	easington
E78	everybody down to	78	465	520	a	general	n	easington
E78	build houses # cos	78	595	575	a	general	n	easington
E78	tulips # now this (disc)	78	485	485	a	general	n	easington
E78	look round the	78	580	484	a	mining	n	easington
E78	loosed out yeah	78	645	520	a	mining	n	easington
E78	the house # cos	78	590	520	a	mining	n	easington
E78	colliery house aye	78	645	495	a	mining	n	easington
E78	pattern out on	78	555	520	a	mining	n	easington
E78	flappin about #	78	575	550	a	mining	n	easington
H77	house	77	665	535	a	word list	y	horden
H77	the house there	77	610	485	a	general	y	horden
H77	missin now # I	77	665	555	a	general	y	horden
H77	much now I	77	650	520	a	general	y	horden
H77	was about # labour	77	555	500	a	general	y	horden
H77	together now bury	77	645	595	a	general	y	horden
H77	to shout er	77	575	515	a	general	y	horden
H77	life now that's	77	595	555	a	general	y	horden
H77	their house in 	77	610	520	a	general	y	horden
H77	numbers now it	77	630	500	a	mining	y	horden
H77	worked out when	77	555	450	a	mining	y	horden
H77	and out then	77	630	550	a	mining	y	horden
H77	them out and	77	590	1100	a	mining	y	horden
H77	It out to 	77	610	500	a	mining	y	horden
H77	pit out the	77	575	480	a	mining	y	horden
H77	80 now # 	77	530	500	a	mining	y	horden
H77	back now you'd	77	640	520	a	mining	y	horden
H77	been down the	77	600	590	a	mining	y	horden
H77	go down the 	77	540	520	a	mining	y	horden
H77	go down the 	77	575	555	a	mining	y	horden
H77	goin down the	77	555	575	a	mining	y	horden
H70	four thousand men	70	635	465	a	mining	y	horden
H70	back down the	70	610	520	a	mining	y	horden
H75	I # how can	75	570	480	a	general	n	horden
H75	every house had	75	590	485	a	mining	n	horden
B68	shouted	68	470	500	a	word list	y	blackhall
B68	out	68	520	485	a	word list	y	blackhall
B68	about	68	630	535	a	general	y	blackhall
B68	proud	68	620	515	a	general	y	blackhall
B68	how	68	575	500	a	mining	y	blackhall
B69	we down in	69	500	430	a	general	y	blackhall
B69	went down the	69	520	465	a	mining	y	blackhall
B69	# now when (disc)	69	520	430	a	mining	y	blackhall
B69	area # now there's (disc)	69	540	480	a	mining	y	blackhall
B69	erm now some (disc)	69	525	450	a	mining	y	blackhall
D70	mouth	70	595	545	b	word list	y	dawdon
D70	outside	70	530	495	b	word list	y	dawdon
D70	south	70	560	485	b	word list	y	dawdon
D70	out	70	580	515	b	word list	y	dawdon
D70	house	70	590	535	b	word list	y	dawdon
D70	down	70	550	450	b	general	y	dawdon
D70	out	70	550	580	b	general	y	dawdon
D70	out	70	685	535	b	general	y	dawdon
D70	out	70	570	515	b	general	y	dawdon
D70	round	70	615	550	b	general	y	dawdon
D70	round	70	535	515	b	general	y	dawdon
D70	round	70	635	550	b	mining	y	dawdon
D70	roundie	70	535	500	b	mining	y	dawdon
D70	out	70	560	435	b	mining	y	dawdon
D70	out	70	635	510	b	mining	y	dawdon
D70	out	70	560	495	b	mining	y	dawdon
D70	out	70	650	500	b	mining	y	dawdon
D70	down	70	575	535	b	mining	y	dawdon
D72	proud	72	500	510	b	word list	y	dawdon
D72	round	72	585	520	b	general	y	dawdon
D72	council	72	655	655	b	general	y	dawdon
D72	town	72	565	515	b	general	y	dawdon
D72	about	72	540	510	b	general	y	dawdon
D72	about	72	520	485	b	general	y	dawdon
D72	about	72	570	510	b	general	y	dawdon
D72	about	72	580	545	b	mining	y	dawdon
D85	house	85	485	450	b	word list	y	dawdon
D85	south	85	535	500	b	word list	y	dawdon
D85	out	85	520	520	b	word list	y	dawdon
D85	shouted	85	505	470	b	word list	y	dawdon
D85	gannin down the	85	610	540	b	mining	y	dawdon
D85	pit about our	85	570	485	b	mining	y	dawdon
D85	his house and	85	595	535	b	mining	y	dawdon
D85	why down the	85	520	430	b	mining	y	dawdon
D85	clout them	85	480	520	b	general	y	dawdon
D85	breaking down an' all	85	610	575	b	general	y	dawdon
D85	goes round the	85	555	520	b	general	y	dawdon
D85	come down here	85	520	540	b	general	y	dawdon
D85	him out the	85	515	465	b	general	y	dawdon
D85	turned round to	85	610	520	b	general	y	dawdon
D85	come down from	85	535	500	b	general	y	dawdon
D85	it down for	85	540	430	b	general	y	dawdon
D85	# now in (disc)	85	495	450	b	general	y	dawdon
D73	out	73	570	520	b	word list	n	dawdon
D73	farmhouse	73	600	520	b	word list	n	dawdon
D73	found	73	590	500	b	word list	n	dawdon
D73	thousand	73	600	470	b	word list	n	dawdon
D73	security now I (disc)	73	540	500	b	general	n	dawdon
D73	given out you	73	665	555	b	general	n	dawdon
D73	day's out the	73	570	540	b	general	n	dawdon
D73	that's how we	73	465	465	b	general	n	dawdon
E64	out	64	570	480	b	word list	y	easington
E64	outside	64	500	450	b	word list	y	easington
E64	surrounded	64	560	500	b	word list	y	easington
E64	shouted	64	585	490	b	word list	y	easington
E64	house	64	520	455	b	word list	y	easington
E64	however	64	550	495	b	word list	y	easington
E64	proud	64	555	520	b	word list	y	easington
E64	about	64	485	485	b	general	y	easington
E64	down	64	570	465	b	general	y	easington
E64	outlet	64	570	510	b	general	y	easington
E64	out	64	590	520	b	general	y	easington
E64	about	64	580	500	b	general	y	easington
E64	down	64	585	550	b	general	y	easington
E64	powder	64	520	495	b	mining	y	easington
E64	out	64	500	475	b	mining	y	easington
E64	out	64	600	530	b	mining	y	easington
E64	down	64	535	510	b	mining	y	easington
E64	out	64	550	500	b	mining	y	easington
E71	house	71	520	500	b	word list	y	easington
E71	out	71	550	515	b	word list	y	easington
E71	down	71	605	525	b	general	y	easington
E71	undergroundN	71	600	585	b	mining	y	easington
E71	allowedN	71	545	460	b	mining	y	easington
E78	offices now they're	78	575	540	b	general	n	easington
E78	areas now up	78	525	465	b	general	n	easington
E78	come out you	78	575	515	b	mining	n	easington
E78	come out #	78	625	575	b	mining	n	easington
E78	like about about	78	480	500	b	mining	n	easington
E78	them out the	78	665	610	b	mining	n	easington
H77	exodus out of	77	540	450	b	general	y	horden
H77	to shout back	77	500	575	b	general	y	horden
H77	come down to	77	555	520	b	general	y	horden
H77	down south 	77	630	500	b	general	y	horden
H77	ponies out and	77	520	520	b	mining	y	horden
H77	on about child	77	550	465	b	mining	y	horden
H77	he's about 80	77	500	460	b	mining	y	horden
H77	was about 80	77	465	440	b	mining	y	horden
H77	be about 20	77	450	450	b	mining	y	horden
H77	goin down the	77	540	520	b	mining	y	horden
H77	it down in 	77	595	540	b	mining	y	horden
H77	it down again	77	540	590	b	mining	y	horden
H77	go down the 	77	520	520	b	mining	y	horden
H77	straight down the	77	540	520	b	mining	y	horden
H70	time now a 	70	645	520	b	general	y	horden
H70	worked outside	70	645	510	b	mining	y	horden
H75	one now # when	75	520	570	b	general	n	horden
B68	surrounded	68	485	450	b	word list	y	blackhall
B68	about	68	420	490	b	mining	y	blackhall
B68	how	68	500	535	b	mining	y	blackhall
B68	thousand	68	585	465	b	mining	y	blackhall
B69	think now that	69	540	430	b	general	y	blackhall
B69	goin down the	69	545	485	b	mining	y	blackhall
B69	went down the	69	555	470	b	mining	y	blackhall
B69	pits round there	69	535	430	b	mining	y	blackhall
B69	# now...now the (disc)	69	520	415	b	mining	y	blackhall
B69	# now...now the (disc)	69	500	415	b	mining	y	blackhall
B86	went down this	86	640	550	b	general	y	blackhall
B86	scrapers # now they (disc)	86	500	430	b	mining	y	blackhall
B86	times out of	86	520	485	b	mining	y	blackhall
B86	was about twelve	86	575	500	b	mining	y	blackhall
D70	house	70	635	470	c	word list	y	dawdon
D70	out	70	645	550	c	word list	y	dawdon
D70	town	70	635	510	c	general	y	dawdon
D70	now	70	685	545	c	general	y	dawdon
D70	roundies	70	620	520	c	mining	y	dawdon
D70	out	70	520	500	c	mining	y	dawdon
D70	out	70	625	525	c	mining	y	dawdon
D72	house	72	635	535	c	word list	y	dawdon
D72	council	72	705	535	c	general	y	dawdon
D72	round	72	600	445	c	mining	y	dawdon
D72	amount	72	660	455	c	mining	y	dawdon
D72	round	72	565	430	c	mining	y	dawdon
D85	outside	85	535	500	c	word list	y	dawdon
D85	down	85	570	525	c	word list	y	dawdon
D85	house	85	615	525	c	word list	y	dawdon
D85	out	85	560	495	c	word list	y	dawdon
D85	thousand	85	600	500	c	word list	y	dawdon
D85	and down	85	455	465	c	mining	y	dawdon
D85	stuff down the	85	455	460	c	mining	y	dawdon
D85	tons down the	85	450	445	c	mining	y	dawdon
D85	work underground Vane	85	555	520	c	mining	y	dawdon
D85	the round shovels	85	540	560	c	mining	y	dawdon
D85	get round so	85	555	665	c	general	y	dawdon
D85	broken down things	85	540	555	c	general	y	dawdon
D85	talkin about you're	85	500	535	c	general	y	dawdon
D85	flee down the 	85	540	500	c	general	y	dawdon
D85	it down for	85	540	465	c	general	y	dawdon
D73	mouth	73	635	560	c	word list	n	dawdon
D73	down	73	590	550	c	word list	n	dawdon
D73	town	73	685	500	c	word list	n	dawdon
D73	outside	73	600	520	c	word list	n	dawdon
D73	proud	73	500	600	c	word list	n	dawdon
D73	gone now like	73	680	625	c	general	n	dawdon
D73	by about four	73	535	500	c	general	n	dawdon
D73	go out on	73	450	465	c	mining	n	dawdon
D73	be about where	73	575	520	c	mining	n	dawdon
E64	down	64	570	550	c	word list	y	easington
E64	south	64	615	525	c	word list	y	easington
E64	farmhouse	64	490	460	c	word list	y	easington
E64	downstairs	64	560	535	c	word list	y	easington
E64	found	64	590	520	c	word list	y	easington
E64	thousand	64	590	525	c	word list	y	easington
E64	down	64	565	535	c	general	y	easington
E64	now	64	615	560	c	general	y	easington
E64	down	64	585	480	c	general	y	easington
E64	scousers	64	615	540	c	general	y	easington
E64	proud	64	585	490	c	general	y	easington
E64	scouse	64	600	500	c	general	y	easington
E64	down	64	635	600	c	general	y	easington
E64	out	64	625	500	c	general	y	easington
E64	out	64	530	505	c	general	y	easington
E64	down	64	560	585	c	general	y	easington
E64	shout	64	570	510	c	mining	y	easington
E64	down	64	555	460	c	mining	y	easington
E64	roundies	64	515	485	c	mining	y	easington
E64	roundies	64	515	485	c	mining	y	easington
E64	out	64	585	540	c	mining	y	easington
E64	down	64	550	515	c	mining	y	easington
E64	out	64	605	460	c	mining	y	easington
E64	out	64	635	540	c	mining	y	easington
E64	household	64	580	465	c	mining	y	easington
E71	mouth	71	535	450	c	word list	y	easington
E71	outside	71	520	520	c	word list	y	easington
E71	farmhouse	71	520	460	c	word list	y	easington
E71	surrounded	71	515	495	c	word list	y	easington
E71	town	71	615	535	c	general	y	easington
E71	underground	71	600	540	c	general	y	easington
E71	aboutN	71	450	515	c	mining	y	easington
E61	downstairs	61	630	555	c	word list	y	easington
E61	killed down the	61	630	555	c	mining	y	easington
E61	work down the	61	665	555	c	mining	y	easington
E61	knocked out and	61	665	540	c	mining	y	easington
E61	dams sounds a	61	560	440	c	mining	y	easington
E78	proud	78	540	470	c	word list	n	easington
E78	went down to	78	630	485	c	general	n	easington
E78	exactly down to	78	575	465	c	general	n	easington
E78	she found time	78	575	485	c	general	n	easington
E78	get out the	78	540	500	c	mining	n	easington
E78	come out the	78	645	575	c	mining	n	easington
E78	still down the	78	520	480	c	mining	n	easington
E78	iz down to	78	555	450	c	mining	n	easington
E78	iz down to	78	570	520	c	mining	n	easington
H65	greenhouse	65	595	560	c	general	n	horden
H65	thousand	65	670	550	c	mining	n	horden
H65	out	65	670	485	c	mining	n	horden
H65	out	65	735	490	c	mining	n	horden
H77	out	77	630	490	c	word list	y	horden
H77	out	77	595	520	c	word list	y	horden
H77	proud	77	680	590	c	word list	y	horden
H77	all towns there's	77	645	575	c	general	y	horden
H77	they're down in 	77	510	555	c	general	y	horden
H77	places down  # multinational	77	575	610	c	general	y	horden
H77	sittin outside in	77	685	485	c	general	y	horden
H77	that how bad	77	555	465	c	mining	y	horden
H77	went down the	77	540	595	c	mining	y	horden
H70	were down there	70	590	500	c	general	y	horden
H70	dozen out of	70	630	500	c	mining	y	horden
H70	of about thirty	70	450	465	c	mining	y	horden
H70	went down there	70	575	535	c	mining	y	horden
H75	comin out with	75	665	585	c	mining	n	horden
H75	street # now before (disc)	75	665	520	c	mining	n	horden
H75	for # now they (disc)	75	575	465	c	mining	n	horden
B65	mouth	65	535	485	c	word list	n	blackhall
B65	down	65	575	500	c	word list	n	blackhall
B65	south	65	560	500	c	word list	n	blackhall
B65	out	65	520	450	c	word list	n	blackhall
B65	downstairs	65	560	480	c	word list	n	blackhall
B65	out	65	600	435	c	word list	n	blackhall
B65	about	65	570	525	c	general	n	blackhall
B65	out	65	615	525	c	general	n	blackhall
B65	about	65	550	505	c	general	n	blackhall
B65	about	65	600	495	c	general	n	blackhall
B65	about	65	565	485	c	general	n	blackhall
B65	pounds	65	650	505	c	general	n	blackhall
B65	house	65	605	510	c	mining	n	blackhall
B65	background	65	520	500	c	mining	n	blackhall
B65	about	65	465	435	c	mining	n	blackhall
B65	pound	65	545	460	c	mining	n	blackhall
B68	house	68	535	420	c	word list	y	blackhall
B68	outside	68	550	490	c	word list	y	blackhall
B68	farmhouse	68	530	460	c	word list	y	blackhall
B68	out	68	550	460	c	word list	y	blackhall
B68	proud	68	570	465	c	word list	y	blackhall
B68	out	68	610	500	c	general	y	blackhall
B68	pronounced	68	665	565	c	general	y	blackhall
B68	Wearmouth	68	585	585	c	general	y	blackhall
B68	thousand	68	575	490	c	general	y	blackhall
B68	pound	68	565	515	c	general	y	blackhall
B68	out	68	595	460	c	general	y	blackhall
B68	out	68	650	515	c	general	y	blackhall
B68	announcement	68	580	470	c	general	y	blackhall
B68	proud	68	580	540	c	general	y	blackhall
B68	out	68	615	535	c	mining	y	blackhall
B68	houses	68	650	505	c	mining	y	blackhall
B68	out	68	570	520	c	mining	y	blackhall
B68	about	68	500	485	c	mining	y	blackhall
B68	found	68	520	400	c	mining	y	blackhall
B69	farmhouse	69	500	480	c	word list	y	blackhall
B69	downstairs	69	520	480	c	word list	y	blackhall
B69	been wound up	69	520	450	c	general	y	blackhall
B69	think now # we	69	555	485	c	mining	y	blackhall
B69	used down the	69	550	475	c	mining	y	blackhall
B69	come down # let's	69	555	490	c	mining	y	blackhall
B86	was about a 	86	575	465	c	mining	y	blackhall
B86	tales about the	86	565	500	c	mining	y	blackhall
D70	down	70	665	595	d	word list	y	dawdon
D70	town	70	655	565	d	word list	y	dawdon
D70	farmhouse	70	680	540	d	word list	y	dawdon
D70	out	70	650	520	d	word list	y	dawdon
D70	found	70	585	520	d	word list	y	dawdon
D70	however	70	555	485	d	word list	y	dawdon
D70	thousand	70	605	545	d	word list	y	dawdon
D70	town	70	685	615	d	general	y	dawdon
D70	out	70	700	550	d	general	y	dawdon
D70	down	70	620	530	d	general	y	dawdon
D70	now	70	735	590	d	general	y	dawdon
D70	town	70	685	770	d	mining	y	dawdon
D70	roundies	70	620	570	d	mining	y	dawdon
D72	mouth	72	615	550	d	word list	y	dawdon
D72	down	72	665	520	d	word list	y	dawdon
D72	town	72	650	560	d	word list	y	dawdon
D72	out	72	655	485	d	word list	y	dawdon
D72	however	72	520	470	d	word list	y	dawdon
D72	thousand	72	655	570	d	word list	y	dawdon
D85	mouth	85	520	535	d	word list	y	dawdon
D85	down	85	650	635	d	word list	y	dawdon
D85	town	85	565	505	d	word list	y	dawdon
D85	out	85	620	1110	d	word list	y	dawdon
D85	surrounded	85	535	550	d	word list	y	dawdon
D85	found	85	620	630	d	word list	y	dawdon
D85	however	85	500	1045	d	word list	y	dawdon
D85	proud	85	550	500	d	word list	y	dawdon
D85	the council you	85	575	540	d	mining	y	dawdon
D85	the council but	85	540	440	d	mining	y	dawdon
D85	and how close	85	485	465	d	mining	y	dawdon
D85	they're round though	85	680	575	d	mining	y	dawdon
D85	it down #	85	570	500	d	general	y	dawdon
D85	come out	85	610	590	d	general	y	dawdon
D85	the county areas	85	500	575	d	general	y	dawdon
D85	up now I	85	610	510	d	general	y	dawdon
D73	house	73	670	485	d	word list	n	dawdon
D73	however	73	615	495	d	word list	n	dawdon
E64	mouth	64	665	530	d	word list	y	easington
E64	house	64	695	545	d	word list	y	easington
E64	down	64	620	550	d	word list	y	easington
E64	town	64	625	585	d	word list	y	easington
E64	now	64	500	485	d	general	y	easington
E64	now	64	630	535	d	general	y	easington
E64	now	64	650	550	d	general	y	easington
E64	underground	64	540	515	d	general	y	easington
E64	now	64	575	505	d	general	y	easington
E64	house	64	570	540	d	general	y	easington
E64	found	64	590	550	d	general	y	easington
E64	down	64	560	550	d	general	y	easington
E64	pound	64	635	500	d	mining	y	easington
E64	down	64	600	540	d	mining	y	easington
E64	merry-go-round	64	500	450	d	mining	y	easington
E64	down	64	550	500	d	mining	y	easington
E61	mouth	61	720	595	d	word list	y	easington
E61	house	61	570	485	d	word list	y	easington
E61	down	61	640	595	d	word list	y	easington
E61	town	61	715	610	d	word list	y	easington
E61	out	61	650	575	d	word list	y	easington
E61	outside	61	595	555	d	word list	y	easington
E61	down	61	610	560	d	word list	y	easington
E61	south	61	700	590	d	word list	y	easington
E61	farmhouse	61	700	630	d	word list	y	easington
E61	surrounded	61	645	645	d	word list	y	easington
E61	shouted	61	630	590	d	word list	y	easington
E61	house	61	715	715	d	word list	y	easington
E61	out	61	680	630	d	word list	y	easington
E61	found	61	610	600	d	word list	y	easington
E61	however	61	575	550	d	word list	y	easington
E61	thousand	61	625	600	d	word list	y	easington
E61	proud	61	665	610	d	word list	y	easington
E61	money around with	61	610	555	d	general	y	easington
E61	their houses new	61	610	520	d	general	y	easington
E61	unemployed now with	61	720	630	d	general	y	easington
E61	to sound like	61	630	575	d	general	y	easington
E61	do now but	61	555	500	d	general	y	easington
E61	is now the	61	700	610	d	general	y	easington
E61	service now is	61	610	540	d	general	y	easington
E61	goin down there	61	520	610	d	general	y	easington
E61	coming round there	61	610	610	d	general	y	easington
E61	well how do	61	485	440	d	general	y	easington
E61	people round here	61	600	570	d	general	y	easington
E61	the town #	61	665	530	d	general	y	easington
E61	walk round the	61	595	500	d	general	y	easington
E61	further south you	61	575	520	d	general	y	easington
E61	mile down the	61	665	610	d	general	y	easington
E61	and down the	61	665	645	d	general	y	easington
E61	come out mobile	61	575	520	d	general	y	easington
E61	the house he	61	500	430	d	general	y	easington
E61	the house do you	61	610	520	d	general	y	easington
E61	off out of	61	540	500	d	general	y	easington
E61	changing # however as	61	575	450	d	general	y	easington
E61	moment now you	61	610	500	d	general	y	easington
E61	it down here	61	645	575	d	general	y	easington
E61	lads how do you	61	465	500	d	general	y	easington
E61	from outside the	61	650	505	d	general	y	easington
E61	just out of	61	700	500	d	general	y	easington
E61	anybody around you	61	555	610	d	general	y	easington
E61	come out that	61	525	570	d	general	y	easington
E61	where now we'll	61	720	580	d	general	y	easington
E61	?? However that's	61	720	600	d	general	y	easington
E61	world down there	61	595	680	d	mining	y	easington
E61	cars down there	61	625	540	d	mining	y	easington
E61	colliery houses it's	61	595	530	d	mining	y	easington
E61	men sounds a	61	560	505	d	mining	y	easington
E61	come down the	61	650	590	d	mining	y	easington
E61	of pounds worth	61	640	520	d	mining	y	easington
E61	got round all	61	655	565	d	mining	y	easington
E61	# allowances aye	61	630	620	d	mining	y	easington
E61	come out and	61	665	540	d	mining	y	easington
E61	come out when	61	610	510	d	mining	y	easington
E61	together # out # could	61	590	520	d	mining	y	easington
E78	mouth	78	555	510	d	word list	n	easington
E78	house	78	600	535	d	word list	n	easington
E78	down	78	650	540	d	word list	n	easington
E78	town	78	620	500	d	word list	n	easington
E78	out	78	640	570	d	word list	n	easington
E78	outside	78	630	550	d	word list	n	easington
E78	down	78	700	575	d	word list	n	easington
E78	south	78	650	555	d	word list	n	easington
E78	farmhouse	78	580	465	d	word list	n	easington
E78	surrounded	78	540	485	d	word list	n	easington
E78	downstairs	78	630	590	d	word list	n	easington
E78	shouted	78	650	555	d	word list	n	easington
E78	house	78	665	540	d	word list	n	easington
E78	out	78	575	490	d	word list	n	easington
E78	found	78	500	485	d	word list	n	easington
E78	however	78	680	580	d	word list	n	easington
E78	thousand	78	720	520	d	word list	n	easington
E78	the county he's	78	615	500	d	general	n	easington
E78	way down on	78	600	495	d	general	n	easington
E78	went down there	78	610	500	d	general	n	easington
E78	came out there's	78	610	510	d	general	n	easington
E78	went down to	78	570	600	d	general	n	easington
E78	Grosvenor House Hotel	78	575	470	d	general	n	easington
E78	Square down that	78	605	520	d	general	n	easington
E78	of thousand or	78	630	535	d	general	n	easington
E78	the county kicked	78	590	500	d	general	n	easington
E78	busy now destroying	78	645	555	d	general	n	easington
E78	timber houses and	78	540	430	d	general	n	easington
E78	offices down the	78	605	540	d	general	n	easington
E78	first found #	78	540	485	d	general	n	easington
E78	actually how it	78	560	970	d	general	n	easington
E78	waste ground outside	78	465	520	d	general	n	easington
E78	ground outside and	78	550	520	d	general	n	easington
E78	them out and	78	525	500	d	general	n	easington
E78	a councillor so	78	700	550	d	general	n	easington
E78	so now I'm	78	610	520	d	general	n	easington
E78	was down in	78	700	470	d	general	n	easington
E78	come round and	78	485	500	d	mining	n	easington
E78	and shout you	78	520	465	d	mining	n	easington
E78	clothes out # aye	78	650	520	d	mining	n	easington
E78	used round the	78	535	520	d	mining	n	easington
E78	comin out of	78	485	500	d	mining	n	easington
E78	agreement around here	78	540	485	d	mining	n	easington
E78	it sounds that	78	715	665	d	mining	n	easington
E78	it sounds that	78	700	645	d	mining	n	easington
E78	stables down below	78	615	465	d	mining	n	easington
E78	his house and	78	690	580	d	mining	n	easington
E78	end house next	78	610	515	d	mining	n	easington
E78	didn't count # do you	78	650	500	d	mining	n	easington
E78	killed down the	78	605	490	d	mining	n	easington
E78	for nowt # and	78	630	630	d	mining	n	easington
E78	went down to	78	590	480	d	mining	n	easington
H65	mouth	65	575	635	d	word list	n	horden
H65	house	65	700	600	d	word list	n	horden
H65	down	65	645	520	d	word list	n	horden
H65	town	65	655	525	d	word list	n	horden
H65	councillor	65	610	410	d	general	n	horden
H65	councillor	65	615	425	d	general	n	horden
H65	county	65	680	365	d	general	n	horden
H65	council	65	700	395	d	general	n	horden
H65	thousand	65	670	550	d	general	n	horden
H65	pounds	65	680	610	d	general	n	horden
H65	house	65	635	630	d	general	n	horden
H65	rowdy	65	720	520	d	general	n	horden
H65	around	65	650	560	d	general	n	horden
H65	thousand	65	635	550	d	general	n	horden
H65	pounds	65	700	535	d	general	n	horden
H65	summerhouse	65	665	560	d	general	n	horden
H65	out	65	665	520	d	general	n	horden
H65	council	65	730	505	d	general	n	horden
H65	greenhouse	65	645	550	d	general	n	horden
H65	now	65	650	620	d	general	n	horden
H65	now	65	600	560	d	general	n	horden
H65	out	65	680	515	d	general	n	horden
H65	out	65	645	535	d	general	n	horden
H65	now	65	600	530	d	general	n	horden
H65	how	65	715	590	d	general	n	horden
H65	councillor	65	675	540	d	general	n	horden
H65	out	65	640	460	d	general	n	horden
H65	around	65	620	550	d	general	n	horden
H65	couch	65	715	520	d	general	n	horden
H65	out	65	590	485	d	general	n	horden
H65	around	65	680	490	d	general	n	horden
H65	about	65	610	520	d	general	n	horden
H65	around	65	635	585	d	mining	n	horden
H65	around	65	630	475	d	mining	n	horden
H65	found	65	660	500	d	mining	n	horden
H65	allowed	65	720	500	d	mining	n	horden
H65	around	65	680	500	d	mining	n	horden
H65	about	65	680	530	d	mining	n	horden
H65	now (dscrse)	65	590	500	d	mining	n	horden
H65	down	65	650	500	d	mining	n	horden
H65	down	65	620	540	d	mining	n	horden
H65	now	65	710	570	d	mining	n	horden
H65	house	65	635	500	d	mining	n	horden
H65	cloud	65	740	665	d	mining	n	horden
H65	house	65	655	440	d	mining	n	horden
H65	house	65	635	455	d	mining	n	horden
H65	out	65	790	445	d	mining	n	horden
H65	housing	65	700	450	d	mining	n	horden
H65	house	65	715	475	d	mining	n	horden
H65	how	65	700	495	d	mining	n	horden
H65	around	65	695	505	d	mining	n	horden
H65	around	65	655	470	d	mining	n	horden
H65	now (dscrse)	65	685	485	d	mining	n	horden
H65	houses	65	760	500	d	mining	n	horden
H65	council	65	730	500	d	mining	n	horden
H65	town	65	700	400	d	mining	n	horden
H65	out	65	730	470	d	mining	n	horden
H65	down	65	690	515	d	mining	n	horden
H77	mouth	77	700	555	d	word list	y	horden
H77	house	77	680	540	d	word list	y	horden
H77	down	77	610	700	d	word list	y	horden
H77	town	77	630	700	d	word list	y	horden
H77	outside	77	665	575	d	word list	y	horden
H77	down	77	610	590	d	word list	y	horden
H77	south	77	645	555	d	word list	y	horden
H77	farmhouse	77	700	500	d	word list	y	horden
H77	surrounded	77	645	645	d	word list	y	horden
H77	downstairs	77	590	610	d	word list	y	horden
H77	shouted	77	645	540	d	word list	y	horden
H77	out	77	610	590	d	word list	y	horden
H77	found	77	630	640	d	word list	y	horden
H77	however	77	680	520	d	word list	y	horden
H77	thousand	77	680	540	d	word list	y	horden
H77	the council a 	77	645	645	d	general	y	horden
H77	the vowels and	77	665	630	d	general	y	horden
H77	five vowels aha	77	590	540	d	general	y	horden
H77	empty houses # next	77	610	520	d	general	y	horden
H77	own house up	77	610	485	d	general	y	horden
H77	ago now #	77	680	665	d	general	y	horden
H77	get down that	77	610	625	d	general	y	horden
H77	funeral down there	77	585	575	d	general	y	horden
H77	lads now and	77	575	520	d	general	y	horden
H77	bit scouseish must	77	595	540	d	general	y	horden
H77	swearin now ha (laughs)	77	645	665	d	general	y	horden
H77	an accountant went	77	650	575	d	general	y	horden
H77	the 'ouse of	77	610	535	d	general	y	horden
H77	went down south	77	630	590	d	general	y	horden
H77	blown out to	77	650	520	d	mining	y	horden
H77	these workhouses that	77	645	520	d	mining	y	horden
H77	of roundies comin	77	595	625	d	mining	y	horden
H77	comin down ha ha	77	630	685	d	mining	y	horden
H77	me down the	77	555	575	d	mining	y	horden
H77	was nowt else	77	640	555	d	mining	y	horden
H70	mouth	70	575	490	d	word list	y	horden
H70	house	70	630	575	d	word list	y	horden
H70	down	70	665	575	d	word list	y	horden
H70	town	70	590	540	d	word list	y	horden
H70	town	70	570	520	d	word list	y	horden
H70	gan down here	70	630	575	d	general	y	horden
H70	gan down I	70	630	630	d	general	y	horden
H70	schoolin now aye	70	665	575	d	general	y	horden
H70	you now do	70	595	540	d	general	y	horden
H70	once down she	70	645	520	d	general	y	horden
H70	from round here	70	555	520	d	general	y	horden
H70	er Wearmouth #	70	575	520	d	general	y	horden
H70	the town's area	70	610	515	d	general	y	horden
H70	area # southwick area	70	575	515	d	general	y	horden
H70	was down Basingstoke	70	700	540	d	general	y	horden
H70	Basingstoke down there	70	630	520	d	general	y	horden
H70	big 'ouse and	70	555	590	d	general	y	horden
H70	come out this	70	560	540	d	general	y	horden
H70	force down there	70	590	620	d	general	y	horden
H70	came out and	70	630	550	d	general	y	horden
H70	down the	70	610	535	d	general	y	horden
H70	gan down there	70	590	495	d	general	y	horden
H70	tak down the	70	575	500	d	general	y	horden
H70	the town	70	590	535	d	general	y	horden
H70	look around all	70	500	500	d	general	y	horden
H70	villages round here	70	540	500	d	general	y	horden
H70	unbelievable down there	70	560	505	d	general	y	horden
H70	Peterlee now to	70	645	580	d	general	y	horden
H70	gan down the	70	665	630	d	general	y	horden
H70	the town things	70	665	580	d	general	y	horden
H70	Sunderland now if	70	650	625	d	general	y	horden
H70	phased out # as	70	665	520	d	mining	y	horden
H70	phased out #	70	610	460	d	mining	y	horden
H70	all about the	70	595	550	d	mining	y	horden
H70	years how they	70	600	485	d	mining	y	horden
H70	park how that	70	650	485	d	mining	y	horden
H70	the housin situation	70	595	520	d	mining	y	horden
H70	the house for	70	610	530	d	mining	y	horden
H70	lived down Leicester	70	550	540	d	mining	y	horden
H70	was about jobs	70	555	465	d	mining	y	horden
H70	people out of	70	610	520	d	mining	y	horden
H70	move out of 	70	575	550	d	mining	y	horden
H75	mouth	75	720	520	d	word list	n	horden
H75	house	75	755	555	d	word list	n	horden
H75	down	75	680	575	d	word list	n	horden
H75	town	75	755	600	d	word list	n	horden
H75	out	75	680	575	d	word list	n	horden
H75	outside	75	630	555	d	word list	n	horden
H75	down	75	610	550	d	word list	n	horden
H75	south	75	735	590	d	word list	n	horden
H75	farmhouse	75	665	555	d	word list	n	horden
H75	surrounded	75	610	665	d	word list	n	horden
H75	downstairs	75	665	540	d	word list	n	horden
H75	shouted	75	650	610	d	word list	n	horden
H75	house	75	700	625	d	word list	n	horden
H75	out	75	680	575	d	word list	n	horden
H75	found	75	700	575	d	word list	n	horden
H75	however	75	630	555	d	word list	n	horden
H75	thousand	75	700	555	d	word list	n	horden
H75	proud	75	740	700	d	word list	n	horden
H75	certain amount of 	75	660	580	d	general	n	horden
H75	certain amount of 	75	630	595	d	general	n	horden
H75	Horden now it's	75	555	555	d	general	n	horden
H75	need housin well	75	630	520	d	general	n	horden
H75	difficult now compared	75	640	550	d	general	n	horden
H75	standards now I	75	710	580	d	general	n	horden
H75	local council was	75	750	625	d	general	n	horden
H75	people now are	75	610	540	d	general	n	horden
H75	the town Hartlepool	75	695	540	d	general	n	horden
H75	certain amount of 	75	595	520	d	general	n	horden
H75	your boundaries and	75	700	555	d	general	n	horden
H75	family # now all (disc)	75	630	590	d	general	n	horden
H75	moved about like	75	685	540	d	general	n	horden
H75	from County Durham	75	685	560	d	general	n	horden
H75	from County Durham	75	630	560	d	general	n	horden
H75	much now #	75	590	680	d	general	n	horden
H75	is how it's	75	710	610	d	general	n	horden
H75	comes out normally	75	630	520	d	general	n	horden
H75	came out they	75	635	590	d	general	n	horden
H75	there now you	75	645	540	d	general	n	horden
H75	and outs and	75	595	540	d	general	n	horden
H75	and how to	75	610	520	d	general	n	horden
H75	so how can	75	665	555	d	general	n	horden
H75	day # now at	75	665	575	d	general	n	horden
H75	whereas nowadays I'm	75	630	540	d	general	n	horden
H75	it down but	75	615	560	d	general	n	horden
H75	whole outlook changes	75	680	540	d	general	n	horden
H75	do nowadays and	75	575	510	d	general	n	horden
H75	tie around his	75	700	610	d	mining	n	horden
H75	went down pit	75	700	575	d	mining	n	horden
H75	all out at	75	645	540	d	mining	n	horden
H75	miles out you're	75	645	555	d	mining	n	horden
H75	mile out at	75	575	575	d	mining	n	horden
H75	railways out cos	75	680	640	d	mining	n	horden
H75	talkin about the	75	630	555	d	mining	n	horden
H75	nights # now in (disc)	75	755	540	d	mining	n	horden
H75	hewn out during	75	680	575	d	mining	n	horden
H75	worked down pit	75	645	550	d	mining	n	horden
H75	you found that	75	665	610	d	mining	n	horden
H75	colliery house #	75	665	555	d	mining	n	horden
H75	be about ten	75	555	535	d	mining	n	horden
H75	never encountered any	75	665	510	d	mining	n	horden
H75	farm # now when (disc)	75	595	545	d	mining	n	horden
H75	every now and	75	575	575	d	mining	n	horden
H75	comin down from	75	715	550	d	mining	n	horden
H75	*splutters* down the	75	645	665	d	mining	n	horden
H75	gate now # every (disc)	75	680	555	d	mining	n	horden
H75	a coalhouse and	75	680	645	d	mining	n	horden
H75	a coalhouse and	75	640	540	d	mining	n	horden
H75	nineteen houses from	75	665	580	d	mining	n	horden
H75	his house after	75	665	555	d	mining	n	horden
H75	his house his	75	725	565	d	mining	n	horden
H75	were houses	75	675	555	d	mining	n	horden
H75	sunk around about	75	665	555	d	mining	n	horden
B65	house	65	685	535	d	word list	n	blackhall
B65	down	65	595	530	d	word list	n	blackhall
B65	town	65	635	490	d	word list	n	blackhall
B65	out	65	590	500	d	word list	n	blackhall
B65	outside	65	540	485	d	word list	n	blackhall
B65	farmhouse	65	500	470	d	word list	n	blackhall
B65	surrounded	65	580	460	d	word list	n	blackhall
B65	shouted	65	545	515	d	word list	n	blackhall
B65	house	65	620	535	d	word list	n	blackhall
B65	found	65	535	490	d	word list	n	blackhall
B65	however	65	585	520	d	word list	n	blackhall
B65	thousand	65	625	490	d	word list	n	blackhall
B65	proud	65	595	510	d	word list	n	blackhall
B65	now	65	540	500	d	general	n	blackhall
B65	out	65	655	500	d	general	n	blackhall
B65	out	65	665	500	d	general	n	blackhall
B65	now	65	670	535	d	general	n	blackhall
B65	down	65	620	530	d	general	n	blackhall
B65	down	65	625	550	d	general	n	blackhall
B65	down	65	605	500	d	general	n	blackhall
B65	now	65	600	515	d	general	n	blackhall
B65	council	65	640	475	d	general	n	blackhall
B65	houses	65	615	570	d	general	n	blackhall
B65	house	65	670	515	d	general	n	blackhall
B65	housing	65	640	545	d	general	n	blackhall
B65	house	65	655	470	d	general	n	blackhall
B65	sound	65	580	500	d	general	n	blackhall
B65	town	65	660	550	d	general	n	blackhall
B65	now	65	670	535	d	general	n	blackhall
B65	south	65	600	520	d	general	n	blackhall
B65	house	65	585	500	d	mining	n	blackhall
B65	council	65	620	520	d	mining	n	blackhall
B65	down	65	625	520	d	mining	n	blackhall
B65	down	65	600	485	d	mining	n	blackhall
B65	out	65	550	550	d	mining	n	blackhall
B65	round	65	560	520	d	mining	n	blackhall
B65	down	65	615	485	d	mining	n	blackhall
B65	down	65	645	470	d	mining	n	blackhall
B65	now	65	620	460	d	mining	n	blackhall
B65	houses	65	630	460	d	mining	n	blackhall
B65	out	65	635	475	d	mining	n	blackhall
B65	round	65	520	460	d	mining	n	blackhall
B65	round	65	545	485	d	mining	n	blackhall
B65	out	65	635	515	d	mining	n	blackhall
B65	pound	65	620	470	d	mining	n	blackhall
B65	pound	65	610	450	d	mining	n	blackhall
B65	thousand	65	620	520	d	mining	n	blackhall
B65	houses	65	650	550	d	mining	n	blackhall
B65	thousand	65	615	535	d	mining	n	blackhall
B65	town	65	605	470	d	mining	n	blackhall
B65	town	65	595	470	d	mining	n	blackhall
B65	town	65	610	500	d	mining	n	blackhall
B65	round	65	540	485	d	mining	n	blackhall
B65	thousand	65	645	515	d	mining	n	blackhall
B68	mouth	68	570	570	d	word list	y	blackhall
B68	down	68	535	520	d	word list	y	blackhall
B68	town	68	760	750	d	word list	y	blackhall
B68	out	68	540	500	d	word list	y	blackhall
B68	down	68	610	580	d	word list	y	blackhall
B68	south	68	630	590	d	word list	y	blackhall
B68	downstairs	68	635	635	d	word list	y	blackhall
B68	house	68	620	550	d	word list	y	blackhall
B68	found	68	580	535	d	word list	y	blackhall
B68	however	68	630	505	d	word list	y	blackhall
B68	thousand	68	605	540	d	word list	y	blackhall
B68	scouse	68	650	600	d	general	y	blackhall
B68	sound	68	665	700	d	general	y	blackhall
B68	sounds	68	580	515	d	general	y	blackhall
B68	now	68	765	720	d	general	y	blackhall
B68	boundaries	68	635	600	d	general	y	blackhall
B68	now	68	620	615	d	general	y	blackhall
B68	councillor	68	665	485	d	general	y	blackhall
B68	downsizing	68	565	450	d	general	y	blackhall
B68	down	68	685	535	d	general	y	blackhall
B68	now	68	730	550	d	general	y	blackhall
B68	now	68	720	470	d	general	y	blackhall
B68	county	68	660	600	d	general	y	blackhall
B68	council	68	680	570	d	general	y	blackhall
B68	down	68	685	550	d	general	y	blackhall
B68	now	68	620	485	d	general	y	blackhall
B68	county	68	615	525	d	general	y	blackhall
B68	about	68	570	530	d	general	y	blackhall
B68	down	68	620	530	d	mining	y	blackhall
B68	down	68	620	550	d	mining	y	blackhall
B68	underground	68	620	510	d	mining	y	blackhall
B68	house	68	550	495	d	mining	y	blackhall
B68	allowances	68	580	515	d	mining	y	blackhall
B68	allowance	68	610	465	d	mining	y	blackhall
B68	how	68	615	470	d	mining	y	blackhall
B68	house	68	680	580	d	mining	y	blackhall
B68	plough	68	800	550	d	mining	y	blackhall
B68	plough	68	650	570	d	mining	y	blackhall
B68	nowadays	68	665	500	d	mining	y	blackhall
B68	mouse	68	570	550	d	mining	y	blackhall
B68	down	68	590	470	d	mining	y	blackhall
B69	mouth	69	555	500	d	word list	y	blackhall
B69	house	69	600	450	d	word list	y	blackhall
B69	down	69	610	540	d	word list	y	blackhall
B69	town	69	560	555	d	word list	y	blackhall
B69	out	69	625	540	d	word list	y	blackhall
B69	outside	69	520	450	d	word list	y	blackhall
B69	down	69	555	520	d	word list	y	blackhall
B69	south	69	595	540	d	word list	y	blackhall
B69	surrounded	69	520	490	d	word list	y	blackhall
B69	out	69	630	490	d	word list	y	blackhall
B69	shouted	69	595	505	d	word list	y	blackhall
B69	house	69	540	520	d	word list	y	blackhall
B69	out	69	575	535	d	word list	y	blackhall
B69	found	69	575	510	d	word list	y	blackhall
B69	however	69	630	500	d	word list	y	blackhall
B69	thousand	69	610	540	d	word list	y	blackhall
B69	proud	69	570	520	d	word list	y	blackhall
B69	district council at	69	580	555	d	general	y	blackhall
B69	council	69	555	540	d	general	y	blackhall
B69	council 	69	550	505	d	general	y	blackhall
B69	council	69	555	500	d	general	y	blackhall
B69	council	69	560	465	d	general	y	blackhall
B69	grouch	69	575	500	d	general	y	blackhall
B69	councillors	69	610	530	d	general	y	blackhall
B69	councillors	69	575	490	d	general	y	blackhall
B69	town	69	585	485	d	general	y	blackhall
B69	round	69	500	520	d	general	y	blackhall
B69	round	69	540	540	d	general	y	blackhall
B69	about	69	540	480	d	general	y	blackhall
B69	down 	69	540	540	d	general	y	blackhall
B69	down 	69	555	520	d	general	y	blackhall
B69	s out on	69	580	520	d	general	y	blackhall
B69	county	69	555	500	d	general	y	blackhall
B69	county	69	570	500	d	general	y	blackhall
B69	now you know	69	540	500	d	general	y	blackhall
B69	council	69	575	500	d	general	y	blackhall
B69	county	69	575	500	d	general	y	blackhall
B69	council	69	570	465	d	general	y	blackhall
B69	dunno 'ow	69	540	440	d	general	y	blackhall
B69	towns	69	580	500	d	general	y	blackhall
B69	councils	69	560	490	d	general	y	blackhall
B69	now #	69	585	540	d	general	y	blackhall
B69	county	69	595	475	d	general	y	blackhall
B69	council	69	625	540	d	general	y	blackhall
B69	come down here	69	610	485	d	mining	y	blackhall
B69	go down there	69	575	485	d	mining	y	blackhall
B69	come out and	69	560	520	d	mining	y	blackhall
B69	workin down the	69	575	480	d	mining	y	blackhall
B69	run down Blackhall	69	580	520	d	mining	y	blackhall
B69	it without the	69	640	470	d	mining	y	blackhall
B69	did now you're	69	575	470	d	mining	y	blackhall
B69	# roundie aye	69	605	490	d	mining	y	blackhall
B69	get round coal	69	625	500	d	mining	y	blackhall
B69	them out with	69	535	470	d	mining	y	blackhall
B69	come down we	69	590	520	d	mining	y	blackhall
B69	bein about as	69	535	520	d	mining	y	blackhall
B69	came down it	69	605	505	d	mining	y	blackhall
B69	came down with	69	555	505	d	mining	y	blackhall
B69	this county was	69	540	465	d	mining	y	blackhall
B69	erm down Yorkshire	69	610	465	d	mining	y	blackhall
B69	went out and	69	600	480	d	mining	y	blackhall
B86	mouth	86	775	535	d	word list	y	blackhall
B86	house	86	810	610	d	word list	y	blackhall
B86	down	86	810	500	d	word list	y	blackhall
B86	town	86	665	555	d	word list	y	blackhall
B86	pull out	86	735	590	d	word list	y	blackhall
B86	farm outside	86	700	585	d	word list	y	blackhall
B86	down	86	735	505	d	word list	y	blackhall
B86	south	86	680	540	d	word list	y	blackhall
B86	farmhouse	86	740	520	d	word list	y	blackhall
B86	surrounded	86	630	520	d	word list	y	blackhall
B86	served out	86	760	500	d	word list	y	blackhall
B86	downstairs	86	700	550	d	word list	y	blackhall
B86	shouted	86	680	500	d	word list	y	blackhall
B86	house	86	680	500	d	word list	y	blackhall
B86	were out	86	740	555	d	word list	y	blackhall
B86	found	86	720	490	d	word list	y	blackhall
B86	however	86	645	540	d	word list	y	blackhall
B86	thousand	86	680	550	d	word list	y	blackhall
B86	proud	86	695	530	d	word list	y	blackhall
B86	pulled down now	86	630	520	d	general	y	blackhall
B86	down now # it's	86	790	560	d	general	y	blackhall
B86	the flower show	86	680	580	d	general	y	blackhall
B86	the county # we	86	720	610	d	general	y	blackhall
B86	cricket ground # we've	86	610	520	d	general	y	blackhall
B86	was out the	86	610	515	d	general	y	blackhall
B86	the ground #	86	610	500	d	general	y	blackhall
B86	tremendous amount wasn't	86	660	645	d	general	y	blackhall
B86	the council used	86	700	595	d	general	y	blackhall
B86	weekend down at	86	680	575	d	general	y	blackhall
B86	there now it's	86	610	540	d	general	y	blackhall
B86	site now and	86	740	575	d	general	y	blackhall
B86	amazing amount of	86	610	555	d	general	y	blackhall
B86	I found this	86	610	530	d	general	y	blackhall
B86	police out cos	86	720	575	d	general	y	blackhall
B86	the council used	86	640	560	d	general	y	blackhall
B86	things down there	86	720	575	d	general	y	blackhall
B86	pitmatic now there	86	700	540	d	mining	y	blackhall
B86	the council houses	86	735	500	d	mining	y	blackhall
B86	council houses were	86	645	485	d	mining	y	blackhall
B86	and down and	86	700	500	d	mining	y	blackhall
B86	the south didn't	86	665	520	d	mining	y	blackhall
B86	the house and 	86	740	465	d	mining	y	blackhall
B86	doin round the	86	680	535	d	mining	y	blackhall
B86	off # now what (disc)	86	755	505	d	mining	y	blackhall
B86	the house # blew	86	680	540	d	mining	y	blackhall
B86	lived down the	86	610	535	d	mining	y	blackhall
B86	water down the	86	720	500	d	mining	y	blackhall
B86	belts now the (disc)	86	845	575	d	mining	y	blackhall
B86	went round and	86	645	550	d	mining	y	blackhall
B86	sorted out for 	86	720	500	d	mining	y	blackhall
B86	coal # now your (disc)	86	630	500	d	mining	y	blackhall
B86	graded out and	86	860	520	d	mining	y	blackhall
B86	stone out so	86	700	485	d	mining	y	blackhall
B86	telephones down the	86	670	540	d	mining	y	blackhall
B86	going out and	86	685	505	d	mining	y	blackhall
B86	telephones underground telephones	86	650	515	d	mining	y	blackhall
B86	broken down and	86	610	525	d	mining	y	blackhall
B86	them out put	86	700	530	d	mining	y	blackhall
B86	way throughout you	86	600	665	d	mining	y	blackhall
B86	tent south it	86	680	500	d	mining	y	blackhall
B86	straight out under	86	685	575	d	mining	y	blackhall

From baud-bovy.gabriel at hsr.it  Thu Mar 28 21:14:47 2013
From: baud-bovy.gabriel at hsr.it (Gabriel Baud-Bovy)
Date: Thu, 28 Mar 2013 21:14:47 +0100
Subject: [R-sig-ME] how to impose same variance for two random effects with
 fixed correlation patterns?
Message-ID: <5154A4B7.2070702@hsr.it>

Dear all,

Pinheiro & Bates (1996) give an example of use of pdBlocked to represent
a two-level mixed-effects model as a single-level model (p. 162):

# two-level model
lme(yield ~ nitro, data = Oats,   random = list(Block=pdIdent(~1), 
Variety=pdIdent(~1)) )

# single-level model
lme(yield ~ nitro, data = Oats,
      random = list(Block=pdBlocked(list(pdIdent(~1),pdIdent(~Variety-1))))

This yields a diagonal covariance matrix with variance sigma_1^2 in the 
first block
and variance sigma_2^2 in the second block.

I would like to have the SAME variance in both blocks (this would be a way
to impose that the two variances in the corresponding two-level model
are equal).

I have looked at pdConstruct.pdBlocked to see whether it was
possible to impose this restriction but the code is daunting and
I would appreciate any help about how to proceed.

Best,

Gabriel

P.S. Let me know if my question (or the previous one about
how to make the covariance matrix for random effects depend
on some characteristics of the grouping factor) is more
appropriate at R-help .



-- 
---------------------------------------------------------------------
Gabriel Baud-Bovy               tel.: (+39) 02 2643 4839 (office)
UHSR University                       (+39) 02 2643 3429 (laboratory)
via Olgettina, 58                     (+39) 02 2643 4891 (secretary)
20132 Milan, Italy               fax: (+39) 02 2643 4892


From ross at biostat.ucsf.edu  Thu Mar 28 23:22:35 2013
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Thu, 28 Mar 2013 15:22:35 -0700
Subject: [R-sig-ME] glmmADMB troubles [diagnosed + worked around]
In-Reply-To: <5137FD6A.4060608@biostat.ucsf.edu>
References: <512EB394.6070601@biostat.ucsf.edu>
	<loom.20130228T050019-868@post.gmane.org>
	<512F9ECD.2090905@biostat.ucsf.edu> <5132856F.4080805@gmail.com>
	<5137FD6A.4060608@biostat.ucsf.edu>
Message-ID: <5154C2AB.5000502@biostat.ucsf.edu>

I stepped through the code and think I found the problem.  Since I'm 
running under emacs/ESS the value of the environment variable SHELL is 
funny:

[context: run_bin does think it's in windows and invokes
  shell(cmd, invisible = TRUE, intern = !verbose)]

The relevant branch of shell() is (note it uses shell as a variable 
inside the function)
     if (missing(shell)) {
         shell <- Sys.getenv("R_SHELL")
         if (!nzchar(shell))
             shell <- Sys.getenv("SHELL")
         if (!nzchar(shell))
             shell <- Sys.getenv("COMSPEC")
R_SHELL is empty
SHELL is  "C:/Program Files/GNU Emacs 24.2/bin/cmdproxy.exe"
I believe that is where the "C:/Program" was coming from in the error 
messages.
COMSPEC is  "C:\\Windows\\system32\\cmd.exe".

I set R_SHELL to the value of COMSPEC and now the command runs.

Ross

P.S. shell() in trun invokes system(), which is why you were seeing it 
in the traceback.

On 3/6/2013 6:37 PM, Ross Boylan wrote:
> On 3/2/2013 3:04 PM, Ben Bolker wrote:
>> On 13-02-28 01:15 PM, Ross Boylan wrote:
>>> On 2/27/2013 8:05 PM, Ben Bolker wrote:
>>>> Ross Boylan <ross at ...> writes:
>>    [snip: not including version without NAs removed, since we already
>> know what the issue is there]
>>
>>>> r <- glmmadmb(sexActs~(1|id), sexpartner[!is.na(sexpartner$sexActs),],
>>>> debug=TRUE)
>>> platform: windows 32
>>> executable name: glmmadmb.exe
>>> bin_loc:
>>> c:/Users/rdboylan/Documents/R/R-2.15.2/site-library/glmmADMB/bin/windows32/glmmadmb.exe 
>>>
>>>
>>> using temp directory
>>> C:\Users\rdboylan\AppData\Local\Temp\Rtmpy2JsMY\glmmADMB17085c19f4d
>>> creating temp directory
>>> changed working directory to
>>> C:/Users/rdboylan/AppData/Local/Temp/Rtmpy2JsMY/glmmADMB17085c19f4d
>>> Command line:
>>> "c:/Users/rdboylan/Documents/R/R-2.15.2/site-library/glmmADMB/bin/windows32/glmmadmb.exe" 
>>>
>>> -maxfn 500 -maxph 5 -noinit -shess
>>> Error in system(cmd, intern = intern, wait = wait | intern,
>>> show.output.on.console = wait,  :
>>>    'C:/Program' not found
>>    I'm a little bit baffled here.  What happens if you use save.dir to
>> save the input files to a temporary directory and run
>>
>> "c:/Users/rdboylan/Documents/R/R-2.15.2/site-library/glmmADMB/bin/windows32/glmmadmb.exe" 
>>
>> -maxfn 500 -maxph 5 -noinit -shess
>>
>> from the command line?
>
>> r <- glmmadmb(sexActs~(1|id), 
>> sexpartner[!is.na(sexpartner$sexActs),], debug=TRUE, 
>> save.dir="I:/LAMOC/Ross/")
> platform: windows 32
> executable name: glmmadmb.exe
> bin_loc: 
> c:/Users/rdboylan/Documents/R/R-2.15.2/site-library/glmmADMB/bin/windows32/glmmadmb.exe
> changed working directory to I:/LAMOC/Ross
> Command line: 
> "c:/Users/rdboylan/Documents/R/R-2.15.2/site-library/glmmADMB/bin/windows32/glmmadmb.exe" 
> -maxfn 500 -maxph 5 -noinit -shess
> Error in system(cmd, intern = intern, wait = wait | intern, 
> show.output.on.console = wait,  :
>   'C:/Program' not found
>
> Then from a Windows Command Prompt (not cygwin)
> H:\> 
> "c:/Users/rdboylan/Documents/R/R-2.15.2/site-library/glmmADMB/bin/windows32
> /glmmadmb.exe" -maxfn 500 -maxph 5 -noinit -shess
> Error trying to open data input file glmmadmb.dat
>  Error trying to read in model data
>  This is usual caused by a missing DAT file
> H:\>I:
>
> I:\>cd LAMOC/Ross
>
> I:\LAMOC\Ross> 
> "c:/Users/rdboylan/Documents/R/R-2.15.2/site-library/glmmADMB/b
> /windows32/glmmadmb.exe" -maxfn 500 -maxph 5 -noinit -shess
>
> Initial statistics: 1 variables; iteration 0; function evaluation 0; 
> phase 1
> Function value   8.9003579e+04; maximum gradient component mag 
> -5.3609e+02
> Var   Value    Gradient   |Var   Value    Gradient   |Var Value    
> Gradient
>
>   1  0.00000 -5.36095e+02 |
>
>  - final statistics:
> 1 variables; iteration 8; function evaluation 14
> Function value   5.0576e+04; maximum gradient component mag 6.2393e-08
> Exit code = 1;  converg criter   1.0000e-04
> Var   Value    Gradient   |Var   Value    Gradient   |Var Value    
> Gradient
>
>   1 112.5711  6.23928e-08 |
> etc
>
> So it seems to work, provided I start in the save.dir. Note that is 
> the directory that R is running in.
> glmmadmb.exe is still running as I hit send.
>
>>
>>   What is the result of .Platform (and .Platform$OS in particular)
>
>> .Platform
> $OS.type
> [1] "windows"
>
> $file.sep
> [1] "/"
>
> $dynlib.ext
> [1] ".dll"
>
> $GUI
> [1] "RTerm"
>
> $endian
> [1] "little"
>
> $pkgType
> [1] "win.binary"
>
> $path.sep
> [1] ";"
>
> $r_arch
> [1] "i386"
>
> Ross
>
>>
>>   It looks conceivably like R is misdiagnosing your system as *not* 
>> being
>> windows, as that's the only way system() should be running.  Are you
>> running under Cygwin (you say it's installed below) ...  ?
>>
>>> changed working directory to i:/LAMOC/Ross
>>> removed temp directory
>>> C:\Users\rdboylan\AppData\Local\Temp\Rtmpy2JsMY\glmmADMB17085c19f4d
>>>> glmmADMB:::get_bin_loc()
>>> $bin_loc
>>> [1]
>>> "c:/Users/rdboylan/Documents/R/R-2.15.2/site-library/glmmADMB/bin/windows32/glmmadmb.exe" 
>>>
>>>
>>>
>>> $platform
>>> [1] "windows"
>>>
>>> P.S. about lme4; I don't have a build environment and so trying the
>>> github version will not be my first move.
>>> Although perhaps lack of a build environment is why the second version
>>> is failing.  I do have cygwin installed, althoughI would not expect 
>>> R to
>>> know how to find it.
>>    lme4 should be installable from lme4.r-forge.r-project.org/repos now,
>> as stated in a message earlier today.
>>
>


From ross at biostat.ucsf.edu  Thu Mar 28 23:39:07 2013
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Thu, 28 Mar 2013 15:39:07 -0700
Subject: [R-sig-ME] glmmADMB truncated distributions
Message-ID: <5154C68B.5090807@biostat.ucsf.edu>

How are they truncated?  I expected there might be a way to set the 
truncation threshhold, but I don't see it in the docs.
Ross Boylan


From bbolker at gmail.com  Fri Mar 29 04:39:53 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 29 Mar 2013 03:39:53 +0000 (UTC)
Subject: [R-sig-ME] glmmADMB truncated distributions
References: <5154C68B.5090807@biostat.ucsf.edu>
Message-ID: <loom.20130329T043015-425@post.gmane.org>

Ross Boylan <ross at ...> writes:

> 
> How are they truncated?  I expected there might be a way to set the 
> truncation threshhold, but I don't see it in the docs.
> Ross Boylan
> 

  They're truncated at zero.

  One of the problems with developing a flexible system is that everyone
comes up with new uses for it: the original intent of the truncated 
distributions was just to make hurdle models possible.

  It would be possible but not completely trivial to adapt glmmADMB
to handle other truncation points -- you would need a straightforward
way to compute the cumulative distribution function of the response up
to the truncation point. Probably the best thing for people who want
to extend glmmADMB in these various ways is to learn how to use the
full version of AD Model Builder ...

  Ben Bolker


From lamprianou at yahoo.com  Fri Mar 29 07:19:24 2013
From: lamprianou at yahoo.com (Iasonas Lamprianou)
Date: Thu, 28 Mar 2013 23:19:24 -0700 (PDT)
Subject: [R-sig-ME] confidence interval for the SD of random effects
In-Reply-To: <mailman.5.1364468402.2916.r-sig-mixed-models@r-project.org>
References: <mailman.5.1364468402.2916.r-sig-mixed-models@r-project.org>
Message-ID: <1364537964.28361.YahooMailNeo@web160104.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130328/eb628966/attachment.pl>

From lamprianou at yahoo.com  Fri Mar 29 07:23:05 2013
From: lamprianou at yahoo.com (Iasonas Lamprianou)
Date: Thu, 28 Mar 2013 23:23:05 -0700 (PDT)
Subject: [R-sig-ME] variance of fixed effects
In-Reply-To: <mailman.5.1364468402.2916.r-sig-mixed-models@r-project.org>
References: <mailman.5.1364468402.2916.r-sig-mixed-models@r-project.org>
Message-ID: <1364538185.83291.YahooMailNeo@web160102.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130328/16f0d5d3/attachment.pl>

From ivain.martinossi--allibert at agroparistech.fr  Fri Mar 29 16:20:50 2013
From: ivain.martinossi--allibert at agroparistech.fr (Ivain MARTINOSSI--ALLIBERT)
Date: Fri, 29 Mar 2013 16:20:50 +0100 (CET)
Subject: [R-sig-ME] Is there any way to model nested random effects in
	MCMCglmm?
Message-ID: <590244155.34888980.1364570450890.JavaMail.root@zmb2>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130329/18a3b795/attachment.pl>

From j.hadfield at ed.ac.uk  Fri Mar 29 17:49:25 2013
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Fri, 29 Mar 2013 16:49:25 +0000
Subject: [R-sig-ME] Is there any way to model nested random effects in
 MCMCglmm?
In-Reply-To: <590244155.34888980.1364570450890.JavaMail.root@zmb2>
References: <590244155.34888980.1364570450890.JavaMail.root@zmb2>
Message-ID: <20130329164925.19292nakbu80g6qs@www.staffmail.ed.ac.uk>

Hi,

Stating that terms are explicitly nested is not necessary as long as  
everything is given a unique identifier. For example, you don't have  
the same trait within a species. If you do, you can just relabel it.  
Then use:

random~Species+Population+Trait

Cheers,

Jarrod


Quoting Ivain MARTINOSSI--ALLIBERT  
<ivain.martinossi--allibert at agroparistech.fr> on Fri, 29 Mar 2013  
16:20:50 +0100 (CET):

> Hello,
> I have data of quantitative gentics composed of various traits  
> measurement for multiple population and multiple species.
> In each species one can find few populations and in each population  
> a few traits are measured, so I initially constructed a glmer model  
> as follows:
>
> model<-glmer(response~fixed effetcs+ (1|Species/Population/Trait) , data=a)
>
> I needed then to add phylogeny to my analysis and decided to use  
> MCMCglmm. I realised I was unable to take into account the nested  
> structure of the three random effects:
> Species, Population and Trait
> If anyone has an idea of how it should be done, I would be very  
> grateful for help.
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From rlevy at ucsd.edu  Fri Mar 29 19:24:26 2013
From: rlevy at ucsd.edu (Levy, Roger)
Date: Fri, 29 Mar 2013 18:24:26 +0000
Subject: [R-sig-ME] adjusting convergence tolerance
Message-ID: <9D7E8A35-FA5A-47D7-B82E-9C2AD4617EBC@ucsd.edu>

Hi all,

Is there "currently" (in version lme4_0.999999-0) any way of adjusting the convergence tolerance used in the backend fitter to lme4() for mixed logic models?

Many thanks in advance!

Roger Levy

--

Roger Levy                      Email: rlevy at ucsd.edu
Associate Professor             Phone: 858-534-7219
Department of Linguistics       Fax:   858-534-4789
UC San Diego                    Web:   http://idiom.ucsd.edu/~rlevy


From doggene at earthlink.net  Fri Mar 29 20:47:36 2013
From: doggene at earthlink.net (Liz Hare)
Date: Fri, 29 Mar 2013 15:47:36 -0400
Subject: [R-sig-ME] MCMCglmm error message - data.frame subscripts
Message-ID: <5155EFD8.8060508@earthlink.net>

Hello,

I'm getting an error message with MCMCglmm that I can't figure out.

The data:

Pedigree

> head(ped)
    animal sire dam
1 1001001   NA  NA
2 1001002   NA  NA
3 1001003   NA  NA
4 1001004   NA  NA
5 1001005   NA  NA
6 1001006   NA  NA

Phenotype

> head(pp9)
      animal  PP
36 20020999 4.0
38 20021000 2.5
43 20021001 3.5
46 20021002 3.5
52 20021003 4.0
53 20021004 5.0

(I have more animals in the pedigree than I have phenotypes for)


> m3 <- MCMCglmm(pp9$PP ~ 1, random=~animal, family="gaussian",
pedigree=ped, data=pp9, nitt=100000, burnin=10000, thin=10)
Error in `[<-.data.frame`(`*tmp*`, , response.names, value = c(4, 2.5,  :
   missing values are not allowed in subscripted assignments of data frames


Which data.frame subscripts does this refer to? Am I neglecting to set 
some parameter? I have removed all the NAs from the phenotype 
data.frame. I ran MCMCglmm with very small trial data, so I think the 
problem is with my data but I can't find where.



> sessionInfo()
R version 2.15.1 (2012-06-22)
Platform: x86_64-pc-linux-gnu (64-bit)

locale:
  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
  [7] LC_PAPER=C                 LC_NAME=C
  [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] MCMCglmm_2.17   corpcor_1.6.4   ape_3.0-7       coda_0.16-1
[5] Matrix_1.0-10   lattice_0.20-13 tensorA_0.36

loaded via a namespace (and not attached):
[1] compiler_2.15.1 gee_4.13-18     grid_2.15.1     nlme_3.1-108
[5] tools_2.15.1


I'd appreciate any suggestions,
Liz


-- 
Liz Hare PhD
Dog Genetics LLC
doggene at earthlink.net
http://www.doggenetics.com


From ramos.grad.student at gmail.com  Fri Mar 29 22:38:17 2013
From: ramos.grad.student at gmail.com (Antonio P. Ramos)
Date: Fri, 29 Mar 2013 14:38:17 -0700
Subject: [R-sig-ME] GAM and MCMCglmm - extracting splines from GAM to use in
	another package
Message-ID: <CAHawB9stv-1Fo56ZekMyHnWSZtskXyVgen2H9crbMPWewhgKEg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130329/bec5bbf5/attachment.pl>

From tom_philippi at nps.gov  Fri Mar 29 23:33:40 2013
From: tom_philippi at nps.gov (Philippi, Tom)
Date: Fri, 29 Mar 2013 15:33:40 -0700
Subject: [R-sig-ME] mixed model negative bionomial
In-Reply-To: <loom.20130328T025435-767@post.gmane.org>
References: <59311B7BAD60F14E99B53F85C5413E221CE38A24@WDCWASP435.network.maf.govt.nz>
	<loom.20130328T025435-767@post.gmane.org>
Message-ID: <CAM9kYqgF-D5QJDK3k1CEZ2NjsjweEHUjbswU6sErqhiLHhQf8w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130329/08565990/attachment.pl>

From j.hadfield at ed.ac.uk  Sat Mar 30 10:55:46 2013
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Sat, 30 Mar 2013 09:55:46 +0000
Subject: [R-sig-ME] MCMCglmm error message - data.frame subscripts
In-Reply-To: <5155EFD8.8060508@earthlink.net>
References: <5155EFD8.8060508@earthlink.net>
Message-ID: <20130330095546.179116out0y4tzus@www.staffmail.ed.ac.uk>

Hi,

Does

m3 <- MCMCglmm(PP ~ 1, random=~animal, family="gaussian",  
pedigree=ped, data=pp9, nitt=100000, burnin=10000, thin=10)

give you the same error?

Cheers,

Jarrod



Quoting Liz Hare <doggene at earthlink.net> on Fri, 29 Mar 2013 15:47:36 -0400:

> Hello,
>
> I'm getting an error message with MCMCglmm that I can't figure out.
>
> The data:
>
> Pedigree
>
>> head(ped)
>    animal sire dam
> 1 1001001   NA  NA
> 2 1001002   NA  NA
> 3 1001003   NA  NA
> 4 1001004   NA  NA
> 5 1001005   NA  NA
> 6 1001006   NA  NA
>
> Phenotype
>
>> head(pp9)
>      animal  PP
> 36 20020999 4.0
> 38 20021000 2.5
> 43 20021001 3.5
> 46 20021002 3.5
> 52 20021003 4.0
> 53 20021004 5.0
>
> (I have more animals in the pedigree than I have phenotypes for)
>
>
>> m3 <- MCMCglmm(pp9$PP ~ 1, random=~animal, family="gaussian",
> pedigree=ped, data=pp9, nitt=100000, burnin=10000, thin=10)
> Error in `[<-.data.frame`(`*tmp*`, , response.names, value = c(4, 2.5,  :
>   missing values are not allowed in subscripted assignments of data frames
>
>
> Which data.frame subscripts does this refer to? Am I neglecting to  
> set some parameter? I have removed all the NAs from the phenotype  
> data.frame. I ran MCMCglmm with very small trial data, so I think  
> the problem is with my data but I can't find where.
>
>
>
>> sessionInfo()
> R version 2.15.1 (2012-06-22)
> Platform: x86_64-pc-linux-gnu (64-bit)
>
> locale:
>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>  [7] LC_PAPER=C                 LC_NAME=C
>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] MCMCglmm_2.17   corpcor_1.6.4   ape_3.0-7       coda_0.16-1
> [5] Matrix_1.0-10   lattice_0.20-13 tensorA_0.36
>
> loaded via a namespace (and not attached):
> [1] compiler_2.15.1 gee_4.13-18     grid_2.15.1     nlme_3.1-108
> [5] tools_2.15.1
>
>
> I'd appreciate any suggestions,
> Liz
>
>
> -- 
> Liz Hare PhD
> Dog Genetics LLC
> doggene at earthlink.net
> http://www.doggenetics.com
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From robin.pritchard at manchester.ac.uk  Fri Mar 29 23:37:18 2013
From: robin.pritchard at manchester.ac.uk (Robin Pritchard)
Date: Fri, 29 Mar 2013 22:37:18 +0000
Subject: [R-sig-ME] Help needed: Fitting and Simulating multilevel model
 in R.
Message-ID: <1F0730D0D452224D96AC5B16EFF41EF436B5BB09@MBXP06.ds.man.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130329/cb93baf2/attachment.pl>

From lamprianou at yahoo.com  Sun Mar 31 10:07:59 2013
From: lamprianou at yahoo.com (Iasonas Lamprianou)
Date: Sun, 31 Mar 2013 01:07:59 -0700 (PDT)
Subject: [R-sig-ME] lme heteroscedasticity
In-Reply-To: <mailman.5818.1364538199.4638.r-sig-mixed-models@r-project.org>
References: <mailman.5818.1364538199.4638.r-sig-mixed-models@r-project.org>
Message-ID: <1364717279.98323.YahooMailNeo@web160102.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130331/333d934c/attachment.pl>

From smilodon2000 at hotmail.com  Sun Mar 31 22:32:12 2013
From: smilodon2000 at hotmail.com (john benson)
Date: Sun, 31 Mar 2013 20:32:12 +0000
Subject: [R-sig-ME] MCMCglmm:interaction bt continuous variable and
 categorical random effect
Message-ID: <BAY173-W242BAF93B79C0E73BC5F7BDCDD0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130331/f0fddcd2/attachment.pl>

From jwiley.psych at gmail.com  Sun Mar 31 22:59:20 2013
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Sun, 31 Mar 2013 13:59:20 -0700
Subject: [R-sig-ME] MCMCglmm:interaction bt continuous variable and
 categorical random effect
In-Reply-To: <BAY173-W242BAF93B79C0E73BC5F7BDCDD0@phx.gbl>
References: <BAY173-W242BAF93B79C0E73BC5F7BDCDD0@phx.gbl>
Message-ID: <CANz9Z_LkjvvPn+NVOvQD+t+7dP-=TG6W4Pj1ZQKnKho+SMJVUA@mail.gmail.com>

Hi John,

That is the basic idea, but I doubt you want to parameterize it quite
that way.  I would suggest:

Model1 <- MCMCglmm(used ~ slope + elevation + road,
  random = ~ us(1 + road):wolf + pack, family = "categorical",
  data = datum, prior = prior1, pr = TRUE)

which would fit a random intercept and slope by wolf, that are allowed
to be correlated, as well as a random intercept by pack (assumed
orthogonal to the others).

Having road in the fixed effects portion will give you the overall
effect, and then the random effects bit will be shrunken deviations
from that.

Cheers,

Joshua


On Sun, Mar 31, 2013 at 1:32 PM, john benson <smilodon2000 at hotmail.com> wrote:
>
>
>
>
>
>
> Hi,
> I am using MCMCglmm to fit resource selection models for wolves using logistic regression where the response variable is pixels on the landscape that are either used by, or available to, wolves.  I have named the response variable "used".  Observed locations of wolves are coded 1 and available locations for wolves (systematic locations across their home ranges) are coded 0.  My initial interest was to assess relative selection (in a use-available context) of various environmental variables which are things like slope, elevation, and distance to roads.  I'm including a random term for individual wolf to account for the unbalanced sample sizes (of observations) across individuals and a random term for pack to account for the fact that I have sampled multiple wolves within some packs.  Here is my code and prior:
>
> prior1<-list(R=list(V=1,fix=1),G=list(G1=list(V=1,nu=0.002),G2=list(V=1,nu=0.002)))Model1<-MCMCglmm(used~slope+elevation+road,random=~wolf+pack,family="categorical",data=datum,prior=prior1)
> This seems to have worked quite well and the various diagnostics indicate good chain mixing and low autocorrelation, as long as I used sufficient iterations, thinning, and burnin.  I am making population-level inference on the relative selection or avoidance of the fixed effects.  Although not my primary question, I'd be interested in confirmation that my code looks correct for the desired inference.
> My real question is that I'd like to derive individual selection coefficients for each wolf in relation to a given environmental variable (i.e. road). I would then use these coefficients in a separate analysis to see how selection of roads varies in relation to various things such as availability of roads, genetic ancestry, etc.  I have thought of 2 ways to derive the individual selection coefficients for roads for each wolf:
> 1. I could run a separate model for each wolf and simply use the fixed effect coefficient for road from each model.  This seems valid but would be time consuming (because I have ~70 wolves) and seems to fail to take advantage of the random effect of wolf in the overall model which presumably could be used to derive an estimate of individual selection of a given resource.
> 2. So alternatively, I wondered if I could run the overall model, but this time include an interaction between the random effect of wolf and road (which is continuous).  I'm not sure if this valid or the best way to structure the code but here is my first try:
> Model1<-MCMCglmm(used~slope+elevation,random=~wolf:road+pack,family="categorical",data=datum,prior=prior1, pr=TRUE)
>
> Again my goal is simply to derive a coefficient of selection of roads for each individual wolf from the overall model.  Any help with this would be greatly appreciated and if anything in my explanation or question is unclear please let me know and I will try to clarify.
> Many thanks in advance!
> John
>
>
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



-- 
Joshua Wiley
Ph.D. Student, Health Psychology
University of California, Los Angeles
http://joshuawiley.com/
Senior Analyst - Elkhart Group Ltd.
http://elkhartgroup.com


From jwiley.psych at gmail.com  Sun Mar 31 23:19:09 2013
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Sun, 31 Mar 2013 14:19:09 -0700
Subject: [R-sig-ME] lme heteroscedasticity
In-Reply-To: <1364717279.98323.YahooMailNeo@web160102.mail.bf1.yahoo.com>
References: <mailman.5818.1364538199.4638.r-sig-mixed-models@r-project.org>
	<1364717279.98323.YahooMailNeo@web160102.mail.bf1.yahoo.com>
Message-ID: <CANz9Z_KbiYQR4=SV13UPLqak-csA8yy_mDbD8BxCJchC_wT2ww@mail.gmail.com>

Dear Iasonas,

Consider this simple example:

mtcars <- mtcars
mtcars$weights <- sample(0:4, size = nrow(mtcars), replace=TRUE)
lme(mpg ~ 1, random = ~ 1 | cyl, weights = varFixed(~weights), data = mtcars)

which gives many errors.  But...

lme(mpg ~ 1, random = ~ 1 | cyl, weights = varFixed(~(weights+1)),
data = mtcars)

and even

lme(mpg ~ 1, random = ~ 1 | cyl, weights = varFixed(~(weights+.001)),
data = mtcars)

but not

lme(mpg ~ 1, random = ~ 1 | cyl, weights = varFixed(~(weights+0)),
data = mtcars)


Anyway, the short of it is that having 0 weights does not play well
with lme.  They do not have to be far away from zero, but it does not
like them to be exactly zero.

In your case, you have count of days absent, with most students having
zero.  If that is the baseline, and then there is more variability in
the students who are absent at least some days, since the weights are
a multiplier essentially of the residual variance, consider adding 1,
which then would make the residual variance for no absent, and then it
would increase based on number of days absent.

Does that make sense?

Cheers,

Joshua



On Sun, Mar 31, 2013 at 1:07 AM, Iasonas Lamprianou
<lamprianou at yahoo.com> wrote:
>
>
> Dear all, a few days ago I sent an email to this list and got some responses (I thank you all). This time, I am trying to fit an heteroscedastic model  on lme:
>
> model0<-lme(score ~ 1  + overallabs +PARENTALEDUCATIONALLEVEL + PARENTALOCCUPATIONALLEVEL + GENDER +  SUBJECT *  ETHNICITY   +  SCHOOL2 ,random=~1|id, weights=varFixed(~overallabs),  data=galatia.comb_small.vert)
>
> overallabs is the number of absences from school (which is a heavily skewed variable; most students have zero absences) and this causes some heteroscedasticity in the model. id is the id of the students (each one has scores on 4 subjects which is modelled as fixed effects)
>
>
> However, when I try this model, I get the result:
>
> Error in MEestimate(lmeSt, grps) :
>   NA/NaN/Inf in foreign function call (arg 1)
>
> Not sure why this is the case. Anyone any ideas? The internet cannot help me in this case....
>
> I am using the laterst nlme version on linux mint.
>
> Thanks
>
>
> Dr. Iasonas Lamprianou
> Department of Social and Political Sciences
> University of Cyprus
>
>
>>________________________________
>> From: "r-sig-mixed-models-request at r-project.org" <r-sig-mixed-models-request at r-project.org>
>>To: r-sig-mixed-models at r-project.org
>>Sent: Friday, 29 March 2013, 8:23
>>Subject: R-sig-mixed-models Digest, Vol 75, Issue 45
>>
>>Send R-sig-mixed-models mailing list submissions to
>>    r-sig-mixed-models at r-project.org
>>
>>To subscribe or unsubscribe via the World Wide Web, visit
>>    https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>or, via email, send a message with subject or body 'help' to
>>    r-sig-mixed-models-request at r-project.org
>>
>>You can reach the person managing the list at
>>    r-sig-mixed-models-owner at r-project.org
>>
>>When replying, please edit your Subject line so it is more specific
>>than "Re: Contents of R-sig-mixed-models digest..."
>>
>>
>>Today's Topics:
>>
>>   1. how to impose same variance for two random effects with fixed
>>      correlation patterns? (Gabriel Baud-Bovy)
>>   2. Re: glmmADMB troubles [diagnosed + worked around] (Ross Boylan)
>>   3. glmmADMB truncated distributions (Ross Boylan)
>>   4. Re: glmmADMB truncated distributions (Ben Bolker)
>>   5. confidence interval for the SD of random effects
>>      (Iasonas Lamprianou)
>>   6. variance of fixed effects (Iasonas Lamprianou)
>>
>>
>>----------------------------------------------------------------------
>>
>>Message: 1
>>Date: Thu, 28 Mar 2013 21:14:47 +0100
>>From: Gabriel Baud-Bovy <baud-bovy.gabriel at hsr.it>
>>To: r-sig-mixed-models at r-project.org
>>Subject: [R-sig-ME] how to impose same variance for two random effects
>>    with fixed correlation patterns?
>>Message-ID: <5154A4B7.2070702 at hsr.it>
>>Content-Type: text/plain; charset=ISO-8859-1; format=flowed
>>
>>Dear all,
>>
>>Pinheiro & Bates (1996) give an example of use of pdBlocked to represent
>>a two-level mixed-effects model as a single-level model (p. 162):
>>
>># two-level model
>>lme(yield ~ nitro, data = Oats,   random = list(Block=pdIdent(~1),
>>Variety=pdIdent(~1)) )
>>
>># single-level model
>>lme(yield ~ nitro, data = Oats,
>>      random = list(Block=pdBlocked(list(pdIdent(~1),pdIdent(~Variety-1))))
>>
>>This yields a diagonal covariance matrix with variance sigma_1^2 in the
>>first block
>>and variance sigma_2^2 in the second block.
>>
>>I would like to have the SAME variance in both blocks (this would be a way
>>to impose that the two variances in the corresponding two-level model
>>are equal).
>>
>>I have looked at pdConstruct.pdBlocked to see whether it was
>>possible to impose this restriction but the code is daunting and
>>I would appreciate any help about how to proceed.
>>
>>Best,
>>
>>Gabriel
>>
>>P.S. Let me know if my question (or the previous one about
>>how to make the covariance matrix for random effects depend
>>on some characteristics of the grouping factor) is more
>>appropriate at R-help .
>>
>>
>>
>>--
>>---------------------------------------------------------------------
>>Gabriel Baud-Bovy               tel.: (+39) 02 2643 4839 (office)
>>UHSR University                       (+39) 02 2643 3429 (laboratory)
>>via Olgettina, 58                     (+39) 02 2643 4891 (secretary)
>>20132 Milan, Italy               fax: (+39) 02 2643 4892
>>
>>
>>
>>------------------------------
>>
>>Message: 2
>>Date: Thu, 28 Mar 2013 15:22:35 -0700
>>From: Ross Boylan <ross at biostat.ucsf.edu>
>>To: Ben Bolker <bbolker at gmail.com>
>>Cc: r-sig-mixed-models at r-project.org
>>Subject: Re: [R-sig-ME] glmmADMB troubles [diagnosed + worked around]
>>Message-ID: <5154C2AB.5000502 at biostat.ucsf.edu>
>>Content-Type: text/plain; charset=ISO-8859-1; format=flowed
>>
>>I stepped through the code and think I found the problem.  Since I'm
>>running under emacs/ESS the value of the environment variable SHELL is
>>funny:
>>
>>[context: run_bin does think it's in windows and invokes
>>  shell(cmd, invisible = TRUE, intern = !verbose)]
>>
>>The relevant branch of shell() is (note it uses shell as a variable
>>inside the function)
>>     if (missing(shell)) {
>>         shell <- Sys.getenv("R_SHELL")
>>         if (!nzchar(shell))
>>             shell <- Sys.getenv("SHELL")
>>         if (!nzchar(shell))
>>             shell <- Sys.getenv("COMSPEC")
>>R_SHELL is empty
>>SHELL is  "C:/Program Files/GNU Emacs 24.2/bin/cmdproxy.exe"
>>I believe that is where the "C:/Program" was coming from in the error
>>messages.
>>COMSPEC is  "C:\\Windows\\system32\\cmd.exe".
>>
>>I set R_SHELL to the value of COMSPEC and now the command runs.
>>
>>Ross
>>
>>P.S. shell() in trun invokes system(), which is why you were seeing it
>>in the traceback.
>>
>>On 3/6/2013 6:37 PM, Ross Boylan wrote:
>>> On 3/2/2013 3:04 PM, Ben Bolker wrote:
>>>> On 13-02-28 01:15 PM, Ross Boylan wrote:
>>>>> On 2/27/2013 8:05 PM, Ben Bolker wrote:
>>>>>> Ross Boylan <ross at ...> writes:
>>>>    [snip: not including version without NAs removed, since we already
>>>> know what the issue is there]
>>>>
>>>>>> r <- glmmadmb(sexActs~(1|id), sexpartner[!is.na(sexpartner$sexActs),],
>>>>>> debug=TRUE)
>>>>> platform: windows 32
>>>>> executable name: glmmadmb.exe
>>>>> bin_loc:
>>>>> c:/Users/rdboylan/Documents/R/R-2.15.2/site-library/glmmADMB/bin/windows32/glmmadmb.exe
>>>>>
>>>>>
>>>>> using temp directory
>>>>> C:\Users\rdboylan\AppData\Local\Temp\Rtmpy2JsMY\glmmADMB17085c19f4d
>>>>> creating temp directory
>>>>> changed working directory to
>>>>> C:/Users/rdboylan/AppData/Local/Temp/Rtmpy2JsMY/glmmADMB17085c19f4d
>>>>> Command line:
>>>>> "c:/Users/rdboylan/Documents/R/R-2.15.2/site-library/glmmADMB/bin/windows32/glmmadmb.exe"
>>>>>
>>>>> -maxfn 500 -maxph 5 -noinit -shess
>>>>> Error in system(cmd, intern = intern, wait = wait | intern,
>>>>> show.output.on.console = wait,  :
>>>>>    'C:/Program' not found
>>>>    I'm a little bit baffled here.  What happens if you use save.dir to
>>>> save the input files to a temporary directory and run
>>>>
>>>> "c:/Users/rdboylan/Documents/R/R-2.15.2/site-library/glmmADMB/bin/windows32/glmmadmb.exe"
>>>>
>>>> -maxfn 500 -maxph 5 -noinit -shess
>>>>
>>>> from the command line?
>>>
>>>> r <- glmmadmb(sexActs~(1|id),
>>>> sexpartner[!is.na(sexpartner$sexActs),], debug=TRUE,
>>>> save.dir="I:/LAMOC/Ross/")
>>> platform: windows 32
>>> executable name: glmmadmb.exe
>>> bin_loc:
>>> c:/Users/rdboylan/Documents/R/R-2.15.2/site-library/glmmADMB/bin/windows32/glmmadmb.exe
>>> changed working directory to I:/LAMOC/Ross
>>> Command line:
>>> "c:/Users/rdboylan/Documents/R/R-2.15.2/site-library/glmmADMB/bin/windows32/glmmadmb.exe"
>>> -maxfn 500 -maxph 5 -noinit -shess
>>> Error in system(cmd, intern = intern, wait = wait | intern,
>>> show.output.on.console = wait,  :
>>>   'C:/Program' not found
>>>
>>> Then from a Windows Command Prompt (not cygwin)
>>> H:\>
>>> "c:/Users/rdboylan/Documents/R/R-2.15.2/site-library/glmmADMB/bin/windows32
>>> /glmmadmb.exe" -maxfn 500 -maxph 5 -noinit -shess
>>> Error trying to open data input file glmmadmb.dat
>>>  Error trying to read in model data
>>>  This is usual caused by a missing DAT file
>>> H:\>I:
>>>
>>> I:\>cd LAMOC/Ross
>>>
>>> I:\LAMOC\Ross>
>>> "c:/Users/rdboylan/Documents/R/R-2.15.2/site-library/glmmADMB/b
>>> /windows32/glmmadmb.exe" -maxfn 500 -maxph 5 -noinit -shess
>>>
>>> Initial statistics: 1 variables; iteration 0; function evaluation 0;
>>> phase 1
>>> Function value   8.9003579e+04; maximum gradient component mag
>>> -5.3609e+02
>>> Var   Value    Gradient   |Var   Value    Gradient   |Var Value
>>> Gradient
>>>
>>>   1  0.00000 -5.36095e+02 |
>>>
>>>  - final statistics:
>>> 1 variables; iteration 8; function evaluation 14
>>> Function value   5.0576e+04; maximum gradient component mag 6.2393e-08
>>> Exit code = 1;  converg criter   1.0000e-04
>>> Var   Value    Gradient   |Var   Value    Gradient   |Var Value
>>> Gradient
>>>
>>>   1 112.5711  6.23928e-08 |
>>> etc
>>>
>>> So it seems to work, provided I start in the save.dir. Note that is
>>> the directory that R is running in.
>>> glmmadmb.exe is still running as I hit send.
>>>
>>>>
>>>>   What is the result of .Platform (and .Platform$OS in particular)
>>>
>>>> .Platform
>>> $OS.type
>>> [1] "windows"
>>>
>>> $file.sep
>>> [1] "/"
>>>
>>> $dynlib.ext
>>> [1] ".dll"
>>>
>>> $GUI
>>> [1] "RTerm"
>>>
>>> $endian
>>> [1] "little"
>>>
>>> $pkgType
>>> [1] "win.binary"
>>>
>>> $path.sep
>>> [1] ";"
>>>
>>> $r_arch
>>> [1] "i386"
>>>
>>> Ross
>>>
>>>>
>>>>   It looks conceivably like R is misdiagnosing your system as *not*
>>>> being
>>>> windows, as that's the only way system() should be running.  Are you
>>>> running under Cygwin (you say it's installed below) ...  ?
>>>>
>>>>> changed working directory to i:/LAMOC/Ross
>>>>> removed temp directory
>>>>> C:\Users\rdboylan\AppData\Local\Temp\Rtmpy2JsMY\glmmADMB17085c19f4d
>>>>>> glmmADMB:::get_bin_loc()
>>>>> $bin_loc
>>>>> [1]
>>>>> "c:/Users/rdboylan/Documents/R/R-2.15.2/site-library/glmmADMB/bin/windows32/glmmadmb.exe"
>>>>>
>>>>>
>>>>>
>>>>> $platform
>>>>> [1] "windows"
>>>>>
>>>>> P.S. about lme4; I don't have a build environment and so trying the
>>>>> github version will not be my first move.
>>>>> Although perhaps lack of a build environment is why the second version
>>>>> is failing.  I do have cygwin installed, althoughI would not expect
>>>>> R to
>>>>> know how to find it.
>>>>    lme4 should be installable from lme4.r-forge.r-project.org/repos now,
>>>> as stated in a message earlier today.
>>>>
>>>
>>
>>
>>
>>------------------------------
>>
>>Message: 3
>>Date: Thu, 28 Mar 2013 15:39:07 -0700
>>From: Ross Boylan <ross at biostat.ucsf.edu>
>>To: r-sig-mixed-models at r-project.org
>>Subject: [R-sig-ME] glmmADMB truncated distributions
>>Message-ID: <5154C68B.5090807 at biostat.ucsf.edu>
>>Content-Type: text/plain; charset=ISO-8859-1; format=flowed
>>
>>How are they truncated?  I expected there might be a way to set the
>>truncation threshhold, but I don't see it in the docs.
>>Ross Boylan
>>
>>
>>
>>------------------------------
>>
>>Message: 4
>>Date: Fri, 29 Mar 2013 03:39:53 +0000 (UTC)
>>From: Ben Bolker <bbolker at gmail.com>
>>To: r-sig-mixed-models at r-project.org
>>Subject: Re: [R-sig-ME] glmmADMB truncated distributions
>>Message-ID: <loom.20130329T043015-425 at post.gmane.org>
>>Content-Type: text/plain; charset=us-ascii
>>
>>Ross Boylan <ross at ...> writes:
>>
>>>
>>> How are they truncated?  I expected there might be a way to set the
>>> truncation threshhold, but I don't see it in the docs.
>>> Ross Boylan
>>>
>>
>>  They're truncated at zero.
>>
>>  One of the problems with developing a flexible system is that everyone
>>comes up with new uses for it: the original intent of the truncated
>>distributions was just to make hurdle models possible.
>>
>>  It would be possible but not completely trivial to adapt glmmADMB
>>to handle other truncation points -- you would need a straightforward
>>way to compute the cumulative distribution function of the response up
>>to the truncation point. Probably the best thing for people who want
>>to extend glmmADMB in these various ways is to learn how to use the
>>full version of AD Model Builder ...
>>
>>  Ben Bolker
>>
>>
>>
>>------------------------------
>>
>>Message: 5
>>Date: Thu, 28 Mar 2013 23:19:24 -0700 (PDT)
>>From: Iasonas Lamprianou <lamprianou at yahoo.com>
>>To: "r-sig-mixed-models at r-project.org"
>>    <r-sig-mixed-models at r-project.org>
>>Subject: [R-sig-ME] confidence interval for the SD of random effects
>>Message-ID:
>>    <1364537964.28361.YahooMailNeo at web160104.mail.bf1.yahoo.com>
>>Content-Type: text/plain
>>
>>
>>
>>Dear all, I am running a very simple mixed effects model using lmer. I get the following results:
>>
>>Random effects: Groups   Name        Variance Std.Dev. id       (Intercept) 7.4223   2.7244   Residual             1.9767   1.4060
>>Number of obs: 8080, groups: id, 2020
>>
>>
>>Apparently, a very good question is whethe0r the estimate of the parameters of the random effect are indeed bigger than zero. So, I used the bootstrap method described by Faraway where the distribution of likelihood rations is built between a model with and withot the random effect. I get a probbility p<0.0001, so the random effect estimates are significant. I also confirmed these findings using the library("RLRsim").
>>
>>
>>So far so good, but one of the reviewers asked me to give 95% confidence intervals. I spent three hours on the internet searching for good solutions and decided that I should use the following:
>>
>>sm1 <- mcmcsamp(mlm.1.1g, n=1000, saveb = TRUE)
>>lme4::HPDinterval(sm1)
>>
>>
>>However, the 95% lower and upper bounds do not indclude the estimate!!!! See below:
>>
>>> r$sigma  lower    upper
>>[1,] 1.977582 2.058084
>>attr(,"Probability")
>>[1] 0.95
>>
>>How is this possible?
>>
>>Also, I assume that the ST shows the ratio of [random effect variance]/[total variance]. In this case, my ICC is 7.42/(7.42+1.97)=0.79 but see the foloowing:
>>
>>> r$ST  lower     upper
>>[1,] 0.6905202 0.7342866
>>attr(,"Probability")
>>[1] 0.95
>>My empirical ICC is not included in the confidence interval. Apparently, I am missing something but after spending a lot of time, I need to ask you offer me some of your experience.
>>Thank you for your time
>>
>>Jason
>>
>>
>>
>>
>>Dr. Iasonas Lamprianou
>>Department of Social and Political Sciences
>>University of Cyprus
>>
>>
>>
>>
>>>
>>    [[alternative HTML version deleted]]
>>
>>
>>
>>------------------------------
>>
>>Message: 6
>>Date: Thu, 28 Mar 2013 23:23:05 -0700 (PDT)
>>From: Iasonas Lamprianou <lamprianou at yahoo.com>
>>To: "r-sig-mixed-models at r-project.org"
>>    <r-sig-mixed-models at r-project.org>
>>Subject: [R-sig-ME] variance of fixed effects
>>Message-ID:
>>    <1364538185.83291.YahooMailNeo at web160102.mail.bf1.yahoo.com>
>>Content-Type: text/plain
>>
>>
>>Note: I am sending this again because I got an email saying that it was not delivered. In case it was delivered initially, I apologise for the double-posting.
>>
>>
>>
>>Dear all, I am running a very simple mixed effects model using lmer. I get the following results:
>>
>>Random
>>effects: Groups   Name        Variance Std.Dev. id       (Intercept)
>>7.4223   2.7244   Residual             1.9767   1.4060
>>Number of obs: 8080, groups: id, 2020
>>
>>
>>Apparently,
>>a very good question is whethe0r the estimate of the parameters of the
>>random effect are indeed bigger than zero. So, I used the bootstrap
>>method described by Faraway where the distribution of likelihood rations
>>is built between a model with and withot the random effect. I get a
>>probbility p<0.0001, so the random effect estimates are significant. I
>>also confirmed these findings using the library("RLRsim").
>>
>>
>>So
>>far so good, but one of the reviewers asked me to give 95% confidence
>>intervals. I spent three hours on the internet searching for good
>>solutions and decided that I should use the following:
>>
>>sm1 <- mcmcsamp(mlm.1.1g, n=1000, saveb = TRUE)
>>lme4::HPDinterval(sm1)
>>
>>
>>However, the 95% lower and upper bounds do not indclude the estimate!!!! See below:
>>
>>> r$sigma  lower    upper
>>[1,] 1.977582 2.058084
>>attr(,"Probability")
>>[1] 0.95
>>
>>How is this possible?
>>
>>Also,
>>I assume that the ST shows the ratio of [random effect variance]/[total
>>variance]. In this case, my ICC is 7.42/(7.42+1.97)=0.79 but see the
>>foloowing:
>>
>>> r$ST  lower     upper
>>[1,] 0.6905202 0.7342866
>>attr(,"Probability")
>>[1] 0.95
>>My
>>empirical ICC is not included in the confidence interval. Apparently, I
>>am missing something but after spending a lot of time, I need to ask
>>you offer me some of your experience.
>>Thank you for your time
>>
>>Jason
>>
>>
>>
>>Dr. Iasonas Lamprianou
>>Department of Social and Political Sciences
>>University of Cyprus
>>    [[alternative HTML version deleted]]
>>
>>
>>
>>------------------------------
>>
>>_______________________________________________
>>R-sig-mixed-models mailing list
>>R-sig-mixed-models at r-project.org
>>https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>>End of R-sig-mixed-models Digest, Vol 75, Issue 45
>>**************************************************
>>
>>
>>
>         [[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
Joshua Wiley
Ph.D. Student, Health Psychology
University of California, Los Angeles
http://joshuawiley.com/
Senior Analyst - Elkhart Group Ltd.
http://elkhartgroup.com


From smilodon2000 at hotmail.com  Sun Mar 31 23:20:23 2013
From: smilodon2000 at hotmail.com (john benson)
Date: Sun, 31 Mar 2013 21:20:23 +0000
Subject: [R-sig-ME] MCMCglmm:interaction bt continuous variable and
 categorical random effect
In-Reply-To: <CANz9Z_LkjvvPn+NVOvQD+t+7dP-=TG6W4Pj1ZQKnKho+SMJVUA@mail.gmail.com>
References: <BAY173-W242BAF93B79C0E73BC5F7BDCDD0@phx.gbl>,
	<CANz9Z_LkjvvPn+NVOvQD+t+7dP-=TG6W4Pj1ZQKnKho+SMJVUA@mail.gmail.com>
Message-ID: <BAY173-W3705F20844AD23327019D4DCDD0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130331/d18a83e8/attachment.pl>

From jwiley.psych at gmail.com  Sun Mar 31 23:39:25 2013
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Sun, 31 Mar 2013 14:39:25 -0700
Subject: [R-sig-ME] MCMCglmm:interaction bt continuous variable and
 categorical random effect
In-Reply-To: <BAY173-W3705F20844AD23327019D4DCDD0@phx.gbl>
References: <BAY173-W242BAF93B79C0E73BC5F7BDCDD0@phx.gbl>
	<CANz9Z_LkjvvPn+NVOvQD+t+7dP-=TG6W4Pj1ZQKnKho+SMJVUA@mail.gmail.com>
	<BAY173-W3705F20844AD23327019D4DCDD0@phx.gbl>
Message-ID: <CANz9Z_LuNsP5cfaZd2++p1+qSN7ECk6WB1t_+dMQ1tTvzF7xKA@mail.gmail.com>

 Hi John,

I am not quite sure what road is --- if it is continuous, then:

us(1 + road):wolf

will yield a 2 x 2 variance covariance matrix, so, you would need
something like:

G = list(
  G1 = list(V = diag(2), nu = 1.002),
  G2 = list(V = 1, nu = .002)
)

(set your own nu values).  diag(2) just gives an identity matrix, so
basically the prior has the intercept/slope uncorrelated, although in
the posterior they may be.  Specifying a sensible prior is a bit
outside the scope of this list serv, I think.

If road is categorical, it may be worth thinking more about.  If it
only has a few levels, probably not a big deal.  If you have, say, 20
different roads, interacting that with 70 wolves, may be more complex
than your dataset will reasonably support.

Cheers,

Joshua



On Sun, Mar 31, 2013 at 2:20 PM, john benson <smilodon2000 at hotmail.com> wrote:
> Hi Joshua,
>
> Thanks for the quick reply!  I tried the code you suggested, but I got an
> error message regarding my prior.
>
> Error in priorformat(if (NOpriorG) { :
>   V is the wrong dimension for some prior$G/prior$R elements
>
> Any thoughts on how to structure the prior for the code you suggested?
>
> Many thanks!
>
> John
>
>> Date: Sun, 31 Mar 2013 13:59:20 -0700
>> Subject: Re: [R-sig-ME] MCMCglmm:interaction bt continuous variable and
>> categorical random effect
>> From: jwiley.psych at gmail.com
>> To: smilodon2000 at hotmail.com
>> CC: r-sig-mixed-models at r-project.org
>
>>
>> Hi John,
>>
>> That is the basic idea, but I doubt you want to parameterize it quite
>> that way. I would suggest:
>>
>> Model1 <- MCMCglmm(used ~ slope + elevation + road,
>> random = ~ us(1 + road):wolf + pack, family = "categorical",
>> data = datum, prior = prior1, pr = TRUE)
>>
>> which would fit a random intercept and slope by wolf, that are allowed
>> to be correlated, as well as a random intercept by pack (assumed
>> orthogonal to the others).
>>
>> Having road in the fixed effects portion will give you the overall
>> effect, and then the random effects bit will be shrunken deviations
>> from that.
>>
>> Cheers,
>>
>> Joshua
>>
>>
>> On Sun, Mar 31, 2013 at 1:32 PM, john benson <smilodon2000 at hotmail.com>
>> wrote:
>> >
>> >
>> >
>> >
>> >
>> >
>> > Hi,
>> > I am using MCMCglmm to fit resource selection models for wolves using
>> > logistic regression where the response variable is pixels on the landscape
>> > that are either used by, or available to, wolves. I have named the response
>> > variable "used". Observed locations of wolves are coded 1 and available
>> > locations for wolves (systematic locations across their home ranges) are
>> > coded 0. My initial interest was to assess relative selection (in a
>> > use-available context) of various environmental variables which are things
>> > like slope, elevation, and distance to roads. I'm including a random term
>> > for individual wolf to account for the unbalanced sample sizes (of
>> > observations) across individuals and a random term for pack to account for
>> > the fact that I have sampled multiple wolves within some packs. Here is my
>> > code and prior:
>> >
>> >
>> > prior1<-list(R=list(V=1,fix=1),G=list(G1=list(V=1,nu=0.002),G2=list(V=1,nu=0.002)))Model1<-MCMCglmm(used~slope+elevation+road,random=~wolf+pack,family="categorical",data=datum,prior=prior1)
>> > This seems to have worked quite well and the various diagnostics
>> > indicate good chain mixing and low autocorrelation, as long as I used
>> > sufficient iterations, thinning, and burnin. I am making population-level
>> > inference on the relative selection or avoidance of the fixed effects.
>> > Although not my primary question, I'd be interested in confirmation that my
>> > code looks correct for the desired inference.
>> > My real question is that I'd like to derive individual selection
>> > coefficients for each wolf in relation to a given environmental variable
>> > (i.e. road). I would then use these coefficients in a separate analysis to
>> > see how selection of roads varies in relation to various things such as
>> > availability of roads, genetic ancestry, etc. I have thought of 2 ways to
>> > derive the individual selection coefficients for roads for each wolf:
>> > 1. I could run a separate model for each wolf and simply use the fixed
>> > effect coefficient for road from each model. This seems valid but would be
>> > time consuming (because I have ~70 wolves) and seems to fail to take
>> > advantage of the random effect of wolf in the overall model which presumably
>> > could be used to derive an estimate of individual selection of a given
>> > resource.
>> > 2. So alternatively, I wondered if I could run the overall model, but
>> > this time include an interaction between the random effect of wolf and road
>> > (which is continuous). I'm not sure if this valid or the best way to
>> > structure the code but here is my first try:
>> >
>> > Model1<-MCMCglmm(used~slope+elevation,random=~wolf:road+pack,family="categorical",data=datum,prior=prior1,
>> > pr=TRUE)
>> >
>> > Again my goal is simply to derive a coefficient of selection of roads
>> > for each individual wolf from the overall model. Any help with this would be
>> > greatly appreciated and if anything in my explanation or question is unclear
>> > please let me know and I will try to clarify.
>> > Many thanks in advance!
>> > John
>> >
>> >
>> >
>> >
>> > [[alternative HTML version deleted]]
>> >
>> > _______________________________________________
>> > R-sig-mixed-models at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>>
>> --
>> Joshua Wiley
>> Ph.D. Student, Health Psychology
>> University of California, Los Angeles
>> http://joshuawiley.com/
>> Senior Analyst - Elkhart Group Ltd.
>> http://elkhartgroup.com



-- 
Joshua Wiley
Ph.D. Student, Health Psychology
University of California, Los Angeles
http://joshuawiley.com/
Senior Analyst - Elkhart Group Ltd.
http://elkhartgroup.com


From lamprianou at yahoo.com  Sun Mar 31 23:42:11 2013
From: lamprianou at yahoo.com (Iasonas Lamprianou)
Date: Sun, 31 Mar 2013 14:42:11 -0700 (PDT)
Subject: [R-sig-ME] lme heteroscedasticity
In-Reply-To: <CANz9Z_KbiYQR4=SV13UPLqak-csA8yy_mDbD8BxCJchC_wT2ww@mail.gmail.com>
References: <mailman.5818.1364538199.4638.r-sig-mixed-models@r-project.org>
	<1364717279.98323.YahooMailNeo@web160102.mail.bf1.yahoo.com>
	<CANz9Z_KbiYQR4=SV13UPLqak-csA8yy_mDbD8BxCJchC_wT2ww@mail.gmail.com>
Message-ID: <1364766131.43332.YahooMailNeo@web160102.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130331/29751948/attachment.pl>

From smilodon2000 at hotmail.com  Sun Mar 31 23:45:31 2013
From: smilodon2000 at hotmail.com (john benson)
Date: Sun, 31 Mar 2013 21:45:31 +0000
Subject: [R-sig-ME] MCMCglmm:interaction bt continuous variable and
 categorical random effect
In-Reply-To: <CANz9Z_LuNsP5cfaZd2++p1+qSN7ECk6WB1t_+dMQ1tTvzF7xKA@mail.gmail.com>
References: <BAY173-W242BAF93B79C0E73BC5F7BDCDD0@phx.gbl>,
	<CANz9Z_LkjvvPn+NVOvQD+t+7dP-=TG6W4Pj1ZQKnKho+SMJVUA@mail.gmail.com>,
	<BAY173-W3705F20844AD23327019D4DCDD0@phx.gbl>,
	<CANz9Z_LuNsP5cfaZd2++p1+qSN7ECk6WB1t_+dMQ1tTvzF7xKA@mail.gmail.com>
Message-ID: <BAY173-W300EE2051E5D7384CC36EDCDD0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20130331/b538a491/attachment.pl>

