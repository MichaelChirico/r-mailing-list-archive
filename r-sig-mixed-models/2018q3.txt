From d@rizopoulo@ @ending from er@@mu@mc@nl  Wed Jul  4 10:43:57 2018
From: d@rizopoulo@ @ending from er@@mu@mc@nl (D. Rizopoulos)
Date: Wed, 4 Jul 2018 08:43:57 +0000
Subject: [R-sig-ME] GLMMs with Adaptive Gaussian Quadrature - GLMMadaptive
 0.2-0
Message-ID: <01448e3f-aa27-6638-acbd-b28190802c59@erasmusmc.nl>

Dear R mixed-model users,

A new version of GLMMadaptive (0.2-0) has been rolled out on CRAN.

Summary: GLMMadaptive can fit mixed effects models using adaptive 
Gaussian quadrature to approximate the integrals over the random 
effects, allowing also for user-specified models.

New features:

- Zero-inflated Poisson and negative binomial models are now implemented 
using the family objects zi.poisson() and zi.negative.binomial(), 
respectively. In addition, taking into advantage of the fact that users 
can specify their own log density functions for the outcome, two-part / 
hurdle model can also be implemented. For examples, check the vignette: 
https://goo.gl/PkpTr4

- The predict() method is now fully available. It calculates 
predictions, and standard errors for models returned by mixed_model() at 
three levels:

   o "mean subject": only the fixed effects part corresponding to 
predictions for the average subject (but not population averaged 
predictions in case of nonlinear link functions).

   o "marginal": predictions using the marginalized coefficients that 
correspond to population averaged predictions.

   o "subject specific": predictions at the subject level. These can be 
also calculated for subjects not originally in the dataset (i.e., 
estimates of the random effects are internally obtained).

- The simulate() method is available to simulate data from fitted mixed 
models. This can be used for instance to perform replication / posterior 
predictive checks. More info in the vignette: https://goo.gl/nKK8kt

As always, any kind of feedback is more than welcome.

Best,
Dimitris


-- 
Dimitris Rizopoulos
Professor of Biostatistics
Department of Biostatistics
Erasmus University Medical Center

Address: PO Box 2040, 3000 CA Rotterdam, the Netherlands
Tel: +31/(0)10/7043478
Fax: +31/(0)10/7043014
Web (personal): http://www.drizopoulos.com/
Web (work): http://www.erasmusmc.nl/biostatistiek/
Blog: http://iprogn.blogspot.nl/

From @t@nleychri@topher1 @ending from y@hoo@com  Wed Jul  4 10:48:21 2018
From: @t@nleychri@topher1 @ending from y@hoo@com (Christopher Stanley)
Date: Wed, 4 Jul 2018 08:48:21 +0000 (UTC)
Subject: [R-sig-ME] 
 GLMMs with Adaptive Gaussian Quadrature - GLMMadaptive 0.2-0
In-Reply-To: <01448e3f-aa27-6638-acbd-b28190802c59@erasmusmc.nl>
References: <01448e3f-aa27-6638-acbd-b28190802c59@erasmusmc.nl>
Message-ID: <663454840.2560297.1530694101738@mail.yahoo.com>

Wonderful Dimitris!
I can't wait to check flavors?of the new features.
RegardsChristopher.? 

    On Wednesday, July 4, 2018, 10:44:23 AM GMT+2, D. Rizopoulos <d.rizopoulos at erasmusmc.nl> wrote:  
 
 Dear R mixed-model users,

A new version of GLMMadaptive (0.2-0) has been rolled out on CRAN.

Summary: GLMMadaptive can fit mixed effects models using adaptive 
Gaussian quadrature to approximate the integrals over the random 
effects, allowing also for user-specified models.

New features:

- Zero-inflated Poisson and negative binomial models are now implemented 
using the family objects zi.poisson() and zi.negative.binomial(), 
respectively. In addition, taking into advantage of the fact that users 
can specify their own log density functions for the outcome, two-part / 
hurdle model can also be implemented. For examples, check the vignette: 
https://goo.gl/PkpTr4

- The predict() method is now fully available. It calculates 
predictions, and standard errors for models returned by mixed_model() at 
three levels:

? o "mean subject": only the fixed effects part corresponding to 
predictions for the average subject (but not population averaged 
predictions in case of nonlinear link functions).

? o "marginal": predictions using the marginalized coefficients that 
correspond to population averaged predictions.

? o "subject specific": predictions at the subject level. These can be 
also calculated for subjects not originally in the dataset (i.e., 
estimates of the random effects are internally obtained).

- The simulate() method is available to simulate data from fitted mixed 
models. This can be used for instance to perform replication / posterior 
predictive checks. More info in the vignette: https://goo.gl/nKK8kt

As always, any kind of feedback is more than welcome.

Best,
Dimitris


-- 
Dimitris Rizopoulos
Professor of Biostatistics
Department of Biostatistics
Erasmus University Medical Center

Address: PO Box 2040, 3000 CA Rotterdam, the Netherlands
Tel: +31/(0)10/7043478
Fax: +31/(0)10/7043014
Web (personal): http://www.drizopoulos.com/
Web (work): http://www.erasmusmc.nl/biostatistiek/
Blog: http://iprogn.blogspot.nl/
_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
  
	[[alternative HTML version deleted]]


From bd@r@t @ending from wi@c@edu  Thu Jul  5 16:10:41 2018
From: bd@r@t @ending from wi@c@edu (Burcu Darst)
Date: Thu, 5 Jul 2018 14:10:41 +0000
Subject: [R-sig-ME] Types of residuals in lme4
Message-ID: <9B0B3E54-D9A0-4FFC-850A-CE394F52A019@wisc.edu>

Dear All,

I am using lme4 to get residuals from a model that has two random intercepts, as shown below:

test = lmer(continuousOutcome ~ age + sex + (1|DBID) + (1|familyID), data, na.action = na.exclude)


I?ve tried extracting all of the following types of residuals, but the only differences I observe between these approaches are due to scaling; i.e., residuals do not differ by residual type.

resids = as.data.table(residuals(test,type = "pearson", scaled = TRUE))
resids = as.data.table(residuals(test,type = "working", scaled = TRUE))
resids = as.data.table(residuals(test,type = "response", scaled = TRUE))
resids = as.data.table(residuals(test,type = "deviance", scaled = TRUE))
resids = as.data.table(residuals(test,type = "pearson"))
resids = as.data.table(residuals(test,type = "working"))
resids = as.data.table(residuals(test,type = "response"))
resids = as.data.table(residuals(test,type = "deviance"))


Is this an expected result when using lme4 to obtain residuals from mixed models? I want to ensure that the residuals I am obtaining are observation level (which they appear to be) and that they account for the two random intercepts (which I believe they do, since they differ if I exclude one of the random intercepts). Also, is it possible to get higher level residuals from lme4, such as individual or family level residuals (which are the two random intercepts included in my model)? 

I would greatly appreciate any help!

Best,
Burcu

From r@turner @ending from @uckl@nd@@c@nz  Fri Jul  6 02:40:03 2018
From: r@turner @ending from @uckl@nd@@c@nz (Rolf Turner)
Date: Fri, 6 Jul 2018 12:40:03 +1200
Subject: [R-sig-ME] [FORGED]  Types of residuals in lme4
In-Reply-To: <9B0B3E54-D9A0-4FFC-850A-CE394F52A019@wisc.edu>
References: <9B0B3E54-D9A0-4FFC-850A-CE394F52A019@wisc.edu>
Message-ID: <68f9fdf0-03bf-1ce6-70b2-ebf8f146220a@auckland.ac.nz>

On 06/07/18 02:10, Burcu Darst via R-sig-mixed-models wrote:
> Dear All,
> 
> I am using lme4 to get residuals from a model that has two random intercepts, as shown below:
> 
> test = lmer(continuousOutcome ~ age + sex + (1|DBID) + (1|familyID), data, na.action = na.exclude)
> 
> 
> I?ve tried extracting all of the following types of residuals, but the only differences I observe between these approaches are due to scaling; i.e., residuals do not differ by residual type.
> 
> resids = as.data.table(residuals(test,type = "pearson", scaled = TRUE))
> resids = as.data.table(residuals(test,type = "working", scaled = TRUE))
> resids = as.data.table(residuals(test,type = "response", scaled = TRUE))
> resids = as.data.table(residuals(test,type = "deviance", scaled = TRUE))
> resids = as.data.table(residuals(test,type = "pearson"))
> resids = as.data.table(residuals(test,type = "working"))
> resids = as.data.table(residuals(test,type = "response"))
> resids = as.data.table(residuals(test,type = "deviance"))
> 
> 
> Is this an expected result when using lme4 to obtain residuals from mixed models? I want to ensure that the residuals I am obtaining are observation level (which they appear to be) and that they account for the two random intercepts (which I believe they do, since they differ if I exclude one of the random intercepts). Also, is it possible to get higher level residuals from lme4, such as individual or family level residuals (which are the two random intercepts included in my model)?
> 
> I would greatly appreciate any help!


I am no expert --- and younger and wiser heads may correct me --- but it 
is my understanding that "types" of residuals are relevant only in the 
context of *generalised* linear models (mixed or "straight").  For 
linear models (mixed or "straight") a residual is a residual is a 
residual.  (And a caterpillar is a tractor. :-) )

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From j@me@@u@nhoro @ending from gm@il@com  Fri Jul  6 03:39:50 2018
From: j@me@@u@nhoro @ending from gm@il@com (James Uanhoro)
Date: Thu, 5 Jul 2018 21:39:50 -0400
Subject: [R-sig-ME] [FORGED] Types of residuals in lme4
In-Reply-To: <68f9fdf0-03bf-1ce6-70b2-ebf8f146220a@auckland.ac.nz>
References: <9B0B3E54-D9A0-4FFC-850A-CE394F52A019@wisc.edu>
 <68f9fdf0-03bf-1ce6-70b2-ebf8f146220a@auckland.ac.nz>
Message-ID: <1dc29de0-8d85-0ec0-3d57-b5963ff644d9@gmail.com>

In addition to Rolf Turner's point, you can get the random effects using
the ranef() function.

ranef(test)$DBID and ranef(test)$familyID should do it.

James


On 07/05/2018 08:40 PM, Rolf Turner wrote:
> On 06/07/18 02:10, Burcu Darst via R-sig-mixed-models wrote:
>> Dear All,
>>
>> I am using lme4 to get residuals from a model that has two random
>> intercepts, as shown below:
>>
>> test = lmer(continuousOutcome ~ age + sex + (1|DBID) + (1|familyID),
>> data, na.action = na.exclude)
>>
>>
>> I?ve tried extracting all of the following types of residuals, but
>> the only differences I observe between these approaches are due to
>> scaling; i.e., residuals do not differ by residual type.
>>
>> resids = as.data.table(residuals(test,type = "pearson", scaled = TRUE))
>> resids = as.data.table(residuals(test,type = "working", scaled = TRUE))
>> resids = as.data.table(residuals(test,type = "response", scaled = TRUE))
>> resids = as.data.table(residuals(test,type = "deviance", scaled = TRUE))
>> resids = as.data.table(residuals(test,type = "pearson"))
>> resids = as.data.table(residuals(test,type = "working"))
>> resids = as.data.table(residuals(test,type = "response"))
>> resids = as.data.table(residuals(test,type = "deviance"))
>>
>>
>> Is this an expected result when using lme4 to obtain residuals from
>> mixed models? I want to ensure that the residuals I am obtaining are
>> observation level (which they appear to be) and that they account for
>> the two random intercepts (which I believe they do, since they differ
>> if I exclude one of the random intercepts). Also, is it possible to
>> get higher level residuals from lme4, such as individual or family
>> level residuals (which are the two random intercepts included in my
>> model)?
>>
>> I would greatly appreciate any help!
>
>
> I am no expert --- and younger and wiser heads may correct me --- but
> it is my understanding that "types" of residuals are relevant only in
> the context of *generalised* linear models (mixed or "straight").? For
> linear models (mixed or "straight") a residual is a residual is a
> residual.? (And a caterpillar is a tractor. :-) )
>
> cheers,
>
> Rolf Turner
>


From bd@r@t @ending from wi@c@edu  Fri Jul  6 19:02:08 2018
From: bd@r@t @ending from wi@c@edu (Burcu Darst)
Date: Fri, 6 Jul 2018 17:02:08 +0000
Subject: [R-sig-ME] [FORGED] Types of residuals in lme4
In-Reply-To: <1dc29de0-8d85-0ec0-3d57-b5963ff644d9@gmail.com>
References: <9B0B3E54-D9A0-4FFC-850A-CE394F52A019@wisc.edu>
 <68f9fdf0-03bf-1ce6-70b2-ebf8f146220a@auckland.ac.nz>
 <1dc29de0-8d85-0ec0-3d57-b5963ff644d9@gmail.com>
Message-ID: <959C97A0-0B7E-4938-B608-FE17D152D6A8@wisc.edu>

Thank you, Rolf and James! That is very helpful to know!

On Jul 5, 2018, at 8:39 PM, James Uanhoro <james.uanhoro at gmail.com<mailto:james.uanhoro at gmail.com>> wrote:

In addition to Rolf Turner's point, you can get the random effects using
the ranef() function.

ranef(test)$DBID and ranef(test)$familyID should do it.

James


On 07/05/2018 08:40 PM, Rolf Turner wrote:
On 06/07/18 02:10, Burcu Darst via R-sig-mixed-models wrote:
Dear All,

I am using lme4 to get residuals from a model that has two random
intercepts, as shown below:

test = lmer(continuousOutcome ~ age + sex + (1|DBID) + (1|familyID),
data, na.action = na.exclude)


I?ve tried extracting all of the following types of residuals, but
the only differences I observe between these approaches are due to
scaling; i.e., residuals do not differ by residual type.

resids = as.data.table(residuals(test,type = "pearson", scaled = TRUE))
resids = as.data.table(residuals(test,type = "working", scaled = TRUE))
resids = as.data.table(residuals(test,type = "response", scaled = TRUE))
resids = as.data.table(residuals(test,type = "deviance", scaled = TRUE))
resids = as.data.table(residuals(test,type = "pearson"))
resids = as.data.table(residuals(test,type = "working"))
resids = as.data.table(residuals(test,type = "response"))
resids = as.data.table(residuals(test,type = "deviance"))


Is this an expected result when using lme4 to obtain residuals from
mixed models? I want to ensure that the residuals I am obtaining are
observation level (which they appear to be) and that they account for
the two random intercepts (which I believe they do, since they differ
if I exclude one of the random intercepts). Also, is it possible to
get higher level residuals from lme4, such as individual or family
level residuals (which are the two random intercepts included in my
model)?

I would greatly appreciate any help!


I am no expert --- and younger and wiser heads may correct me --- but
it is my understanding that "types" of residuals are relevant only in
the context of *generalised* linear models (mixed or "straight").  For
linear models (mixed or "straight") a residual is a residual is a
residual.  (And a caterpillar is a tractor. :-) )

cheers,

Rolf Turner




	[[alternative HTML version deleted]]


From DSmith @ending from mednet@ucl@@edu  Mon Jul  9 02:03:05 2018
From: DSmith @ending from mednet@ucl@@edu (Smith, Desmond)
Date: Mon, 9 Jul 2018 00:03:05 +0000
Subject: [R-sig-ME] glmmTMB and post hoc testing
Message-ID: <E3E45272-3F34-486C-8FA5-A5018CAA4044@mednet.ucla.edu>

Dear All,

I have previously tested a mixed model using lmer. However, since the dependent variable is count data, which is over-dispersed, it seems that I should use a negative binomial generalized linear mixed model (GLMM), such as glmmTMB.

The full data frame is:


dim(example)

[1] 115   7


Here are the first six rows of the full 115 row data frame:


head(example)
     fixed1 fixed2 random nested_random counts id log_total_counts
1         0      0      1             1    643  1         12.89582
1001      0      0      2             6    585  1         13.67509
2001      0      0      3            11    846  1         13.94209
3001      0      0      4            16    755  1         13.93056
4001      0      0      5            21   1428  1         13.65672
5001      0      0      6            26   1566  1         13.64421

str(example)
'data.frame': 115 obs. of  7 variables:
$ fixed1          : num  0 0 0 0 0 0 1 1 1 1 ...
$ fixed2          : num  0 0 0 0 0 0 0 0 0 0 ...
$ random          : num  1 2 3 4 5 6 1 2 3 4 ...
$ nested_random   : num  1 6 11 16 21 26 2 7 12 17 ...
$ counts          : int  643 585 846 755 1428 1566 309 719 1542 1446 ...
$ id              : int  1 1 1 1 1 1 1 1 1 1 ...
$ log_total_counts: num  12.9 13.7 13.9 13.9 13.7 ...

There are six values of fixed1, plus a zero:

unique(example$fixed1)

[1] 0 1 2 3 4 6



The mean of the six values of fixed1 is

mean(c(1,2,3,4,6))
[1] 3.2

There are four values of fixed2, including zero:

unique(example$fixed2)

[1]  0 25 75  8

The mean of the four values of fixed1 is
mean(unique(example$fixed2))
[1] 27


Here is the lmer model I used:

library(lme4)

m1 <- lmer(counts ~ fixed1*fixed2 + (1|random/nested_random) + offset(log_total_counts), data = example, verbose=FALSE)

Followed by the use of glht for post-hoc analysis:

library(multcomp)

       glht_fixed1 <- glht(m1, linfct = c(
                           "fixed1 == 0",
                                  "fixed1 + 8*fixed1:fixed2 == 0",
                           "fixed1 + 25*fixed1:fixed2 == 0",
                                  "fixed1 + 75*fixed1:fixed2 == 0",
                                  "fixed1 + (27)*fixed1:fixed2 == 0"))

       glht_fixed2 <- glht(m1, linfct = c(
                           "fixed2 + 1*fixed1:fixed2 == 0",
                                  "fixed2 + 2*fixed1:fixed2 == 0",
                                  "fixed2 + 3*fixed1:fixed2 == 0",
                                  "fixed2 + 4*fixed1:fixed2 == 0",
                                  "fixed2 + 6*fixed1:fixed2 == 0",
                                  "fixed2 + (3.2)*fixed1:fixed2 == 0"))

              glht_omni <- glht(m1)

Here is the corresponding negative binomial glmmTMB model:

library(glmmTMB)

m2 <- glmmTMB(counts ~ fixed1*fixed2 + (1|random/nested_random) + offset(log_total_counts), data = example, verbose=FALSE, family="nbinom2")

According to this suggestion by Ben Bolker (https://stat.ethz.ch/pipermail/r-sig-mixed-models/2017q3/025813.html), the best approach to post hoc testing with glmmTMB is to use lsmeans (or its more recent equivalent, emmeans).

After running

source(system.file("other_methods","lsmeans_methods.R",package="glmmTMB"))

I can use lsmeans on the glmmTMB object. For example,

as.glht(emmeans(m1,~(week + 27*week:conc)))

                General Linear Hypotheses

Linear Hypotheses:
                          Estimate
3.11304347826087, 21 == 0   -8.813

But this does not seem correct. What I cannot figure out, for the life of me, is how to correctly carry over the use of linfct to the lsmeans scenario on the glmmTMB. I have read all the manuals and vignettes until I am blue in face (or it feels that way, at least), but I am still at a loss. In my defense (culpability?) I am a statistical tyro, so many apologies if I am asking a question with very obvious answers here.

The glht software and post hoc testing works easily with the glmmADMB package, but the glmmADMB software is 10x slower than glmmTMB. I need to perform multiple runs of this analysis, each with 300,000 examples of the mixed model, so speed is essential.

Many thanks for your suggestions or help!

Cheers,

Des



.

________________________________

UCLA HEALTH SCIENCES IMPORTANT WARNING: This email (and any attachments) is only intended for the use of the person or entity to which it is addressed, and may contain information that is privileged and confidential. You, the recipient, are obligated to maintain it in a safe, secure and confidential manner. Unauthorized redisclosure or failure to maintain confidentiality may subject you to federal and state penalties. If you are not the intended recipient, please immediately notify us by return email, and delete this message from your computer.

	[[alternative HTML version deleted]]


From luke@m@ng@li@o@dunc@n @ending from gm@il@com  Mon Jul  9 17:13:27 2018
From: luke@m@ng@li@o@dunc@n @ending from gm@il@com (Luke Duncan)
Date: Mon, 9 Jul 2018 17:13:27 +0200
Subject: [R-sig-ME] Fwd: glmer won't allow quasi- distribution mixed models
In-Reply-To: <CAE9UE+8urbm=Q559+OPw73H864Vb1Dy13Xc70H4SHfeVaduCnQ@mail.gmail.com>
References: <CAE9UE+8urbm=Q559+OPw73H864Vb1Dy13Xc70H4SHfeVaduCnQ@mail.gmail.com>
Message-ID: <CAE9UE+-FR7J43LzweA6z8BZ7QbMmvf2H39gvPEMuXC46tY6Mww@mail.gmail.com>

Dear R folk

I am trying to run a series of models on distance data for three different
species of animals. My data are not zero-inflated (distances were recorded
for locomotion only and so if the animal didn't move, it wasn't recorded)
and are Poisson distributed. However, all of the models that I run are
horrifically over-dispersed and based on what I read online I thought that
maybe I should consider using a quasi-Poisson distribution to attempt to
account for the over-dispersion. All the online posts of others show that
they do so successfully but for some reason, my lme4 package cannot use
quasi-distributions. I have uninstalled and reinstalled R and the packages
and I still get the same problem.

I am

a) at a loss as to how to deal with the over-dispersion I have and
b) baffled by the fact that lme4 everywhere else can cope with
quasi-distributions but mine can't.

Any help would be appreciated!

My code:

library(lme4)
woodlicedata<-read.csv("Woodlice.csv",header=T)
attach(woodlicedata)
names(woodlicedata)
> ### This set of models examine whether there are differences in distances
travelled.
>
distmodel<-glmer(Distance~Treatment*Sex+(1|ID)+(1|Path.set/ID),family=poisson(link='log'))
> summary(distmodel)  ### AIC= 42972.6
Generalized linear mixed model fit by maximum likelihood (Laplace
Approximation) [
glmerMod]
 Family: poisson  ( log )
Formula: Distance ~ Treatment * Sex + (1 | ID) + (1 | Path.set/ID)

     AIC      BIC   logLik deviance df.resid
 42972.6  43007.3 -21479.3  42958.6     1038

Scaled residuals:
    Min      1Q  Median      3Q     Max
-11.853  -4.074  -1.656   2.146  38.035

Random effects:
 Groups      Name        Variance  Std.Dev.
 ID:Path.set (Intercept) 6.485e-02 0.2546560
 ID          (Intercept) 6.906e-02 0.2627973
 Path.set    (Intercept) 1.368e-10 0.0000117
Number of obs: 1045, groups:  ID:Path.set, 104; ID, 52; Path.set, 2

Fixed effects:
                            Estimate Std. Error z value Pr(>|z|)
(Intercept)                  4.20814    0.07757  54.248  < 2e-16 ***
TreatmentRestricted          0.10843    0.14359   0.755  0.45015
SexMale                     -0.08408    0.11545  -0.728  0.46644
TreatmentRestricted:SexMale -0.49300    0.18781  -2.625  0.00866 **
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Correlation of Fixed Effects:
            (Intr) TrtmnR SexMal
TrtmntRstrc -0.540
SexMale     -0.672  0.363
TrtmntRs:SM  0.413 -0.765 -0.615

>
distmodel2<-glmer(Distance~Treatment*Sex+(1|ID)+(1|Path.set/ID),family=quasipoisson(link='log'))
Error in lme4::glFormula(formula = Distance ~ Treatment * Sex + (1 | ID) +
:
  "quasi" families cannot be used in glmer

	[[alternative HTML version deleted]]


From bbolker @ending from gm@il@com  Mon Jul  9 17:51:04 2018
From: bbolker @ending from gm@il@com (Ben Bolker)
Date: Mon, 9 Jul 2018 11:51:04 -0400
Subject: [R-sig-ME] glmmTMB and post hoc testing
In-Reply-To: <E3E45272-3F34-486C-8FA5-A5018CAA4044@mednet.ucla.edu>
References: <E3E45272-3F34-486C-8FA5-A5018CAA4044@mednet.ucla.edu>
Message-ID: <9aa69f3b-0de1-09b2-052e-035b52484cd7@gmail.com>



On 2018-07-08 08:03 PM, Smith, Desmond wrote:
> Dear All,
> 
> I have previously tested a mixed model using lmer. However, since the
> dependent variable is count data, which is over-dispersed, it seems
> that I should use a negative binomial generalized linear mixed model
> (GLMM), such as glmmTMB.

  That is certainly one possibility.
http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#overdispersion
offers a variety of other alternatives.

  I haven't had a chance to look into the details below yet, but you
could try updating to a development branch of `glmmTMB` that has more
integrated emmeans support:

install_github("glmmTMB/glmmTMB/glmmTMB at effects")

(you would need compilation tools etc. installed).  After that check the
vignette - it may not be built/installed properly, but you can find it here:

https://github.com/glmmTMB/glmmTMB/blob/effects/glmmTMB/vignettes/model_evaluation.rmd

> 
> The full data frame is:
> 
> 
> dim(example)
> 
> [1] 115   7
> 
> 
> Here are the first six rows of the full 115 row data frame:
> 
> 
> head(example) fixed1 fixed2 random nested_random counts id
> log_total_counts 1         0      0      1             1    643  1
> 12.89582 1001      0      0      2             6    585  1
> 13.67509 2001      0      0      3            11    846  1
> 13.94209 3001      0      0      4            16    755  1
> 13.93056 4001      0      0      5            21   1428  1
> 13.65672 5001      0      0      6            26   1566  1
> 13.64421
> 
> str(example) 'data.frame': 115 obs. of  7 variables: $ fixed1
> : num  0 0 0 0 0 0 1 1 1 1 ... $ fixed2          : num  0 0 0 0 0 0 0
> 0 0 0 ... $ random          : num  1 2 3 4 5 6 1 2 3 4 ... $
> nested_random   : num  1 6 11 16 21 26 2 7 12 17 ... $ counts
> : int  643 585 846 755 1428 1566 309 719 1542 1446 ... $ id
> : int  1 1 1 1 1 1 1 1 1 1 ... $ log_total_counts: num  12.9 13.7
> 13.9 13.9 13.7 ...
> 
> There are six values of fixed1, plus a zero:
> 
> unique(example$fixed1)
> 
> [1] 0 1 2 3 4 6
> 
> 
> 
> The mean of the six values of fixed1 is
> 
> mean(c(1,2,3,4,6)) [1] 3.2
> 
> There are four values of fixed2, including zero:
> 
> unique(example$fixed2)
> 
> [1]  0 25 75  8
> 
> The mean of the four values of fixed1 is 
> mean(unique(example$fixed2)) [1] 27
> 
> 
> Here is the lmer model I used:
> 
> library(lme4)
> 
> m1 <- lmer(counts ~ fixed1*fixed2 + (1|random/nested_random) +
> offset(log_total_counts), data = example, verbose=FALSE)
> 
> Followed by the use of glht for post-hoc analysis:
> 
> library(multcomp)
> 
> glht_fixed1 <- glht(m1, linfct = c( "fixed1 == 0", "fixed1 +
> 8*fixed1:fixed2 == 0", "fixed1 + 25*fixed1:fixed2 == 0", "fixed1 +
> 75*fixed1:fixed2 == 0", "fixed1 + (27)*fixed1:fixed2 == 0"))
> 
> glht_fixed2 <- glht(m1, linfct = c( "fixed2 + 1*fixed1:fixed2 == 0", 
> "fixed2 + 2*fixed1:fixed2 == 0", "fixed2 + 3*fixed1:fixed2 == 0", 
> "fixed2 + 4*fixed1:fixed2 == 0", "fixed2 + 6*fixed1:fixed2 == 0", 
> "fixed2 + (3.2)*fixed1:fixed2 == 0"))
> 
> glht_omni <- glht(m1)
> 
> Here is the corresponding negative binomial glmmTMB model:
> 
> library(glmmTMB)
> 
> m2 <- glmmTMB(counts ~ fixed1*fixed2 + (1|random/nested_random) +
> offset(log_total_counts), data = example, verbose=FALSE,
> family="nbinom2")
> 
> According to this suggestion by Ben Bolker
> (https://stat.ethz.ch/pipermail/r-sig-mixed-models/2017q3/025813.html),
> the best approach to post hoc testing with glmmTMB is to use lsmeans
> (or its more recent equivalent, emmeans).
> 
> After running
> 
> source(system.file("other_methods","lsmeans_methods.R",package="glmmTMB"))
>
>  I can use lsmeans on the glmmTMB object. For example,
> 
> as.glht(emmeans(m1,~(week + 27*week:conc)))
> 
> General Linear Hypotheses
> 
> Linear Hypotheses: Estimate 3.11304347826087, 21 == 0   -8.813
> 
> But this does not seem correct. What I cannot figure out, for the
> life of me, is how to correctly carry over the use of linfct to the
> lsmeans scenario on the glmmTMB. I have read all the manuals and
> vignettes until I am blue in face (or it feels that way, at least),
> but I am still at a loss. In my defense (culpability?) I am a
> statistical tyro, so many apologies if I am asking a question with
> very obvious answers here.
> 
> The glht software and post hoc testing works easily with the glmmADMB
> package, but the glmmADMB software is 10x slower than glmmTMB. I need
> to perform multiple runs of this analysis, each with 300,000 examples
> of the mixed model, so speed is essential.
> 
> Many thanks for your suggestions or help!
> 
> Cheers,
> 
> Des
> 
> 
> 
> .
> 
> ________________________________
> 
> UCLA HEALTH SCIENCES IMPORTANT WARNING: This email (and any
> attachments) is only intended for the use of the person or entity to
> which it is addressed, and may contain information that is privileged
> and confidential. You, the recipient, are obligated to maintain it in
> a safe, secure and confidential manner. Unauthorized redisclosure or
> failure to maintain confidentiality may subject you to federal and
> state penalties. If you are not the intended recipient, please
> immediately notify us by return email, and delete this message from
> your computer.
> 
> [[alternative HTML version deleted]]
> 
> _______________________________________________ 
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From bbolker @ending from gm@il@com  Mon Jul  9 17:58:39 2018
From: bbolker @ending from gm@il@com (Ben Bolker)
Date: Mon, 9 Jul 2018 11:58:39 -0400
Subject: [R-sig-ME] 
 Fwd: glmer won't allow quasi- distribution mixed models
In-Reply-To: <CAE9UE+-FR7J43LzweA6z8BZ7QbMmvf2H39gvPEMuXC46tY6Mww@mail.gmail.com>
References: <CAE9UE+8urbm=Q559+OPw73H864Vb1Dy13Xc70H4SHfeVaduCnQ@mail.gmail.com>
 <CAE9UE+-FR7J43LzweA6z8BZ7QbMmvf2H39gvPEMuXC46tY6Mww@mail.gmail.com>
Message-ID: <17b79c4d-3880-7066-28eb-4840d6c9d378@gmail.com>


  I don't know what examples you're looking at that show successful use
of quasilikelihood with lme4; it's been years since that option was
removed from the package ... (can you point me to those links? I would
be curious to see how old they are ...)

  You have a variety of other choices for handling overdispersion (see
the GLMM FAQ.  See
http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#overdispersion ,
which (as of 5 minutes ago) includes a quasi-likelihood hack for use
with glmer models ...

  A few other points from your code below:

- most folks now deprecate the use of attach() (even the manual page
?attach says not to, under "Good practice !) - it generally leads to
more confusion than it's worth
- Your overdispersion seems to be extreme (min/max of scaled residuals
from -12 to 38, deviance/resid df = 42958.6/1038  ~ 40); before you
paper over the cracks using an overdispersion model, it would be a good
to plot your data and model diagnostics and look for outliers and/or
severe violations of the model fit ...
 - it seems weird for movement distances to be count variables (suitable
for modeling via Poisson/NB).  I would expect them to be continuous and
positive, e.g. log-Normal or Gamma.  Can you explain how they come to be
counts in this case?

On 2018-07-09 11:13 AM, Luke Duncan wrote:
> Dear R folk
> 
> I am trying to run a series of models on distance data for three different
> species of animals. My data are not zero-inflated (distances were recorded
> for locomotion only and so if the animal didn't move, it wasn't recorded)
> and are Poisson distributed. However, all of the models that I run are
> horrifically over-dispersed and based on what I read online I thought that
> maybe I should consider using a quasi-Poisson distribution to attempt to
> account for the over-dispersion. All the online posts of others show that
> they do so successfully but for some reason, my lme4 package cannot use
> quasi-distributions. I have uninstalled and reinstalled R and the packages
> and I still get the same problem.
> 
> I am
> 
> a) at a loss as to how to deal with the over-dispersion I have and
> b) baffled by the fact that lme4 everywhere else can cope with
> quasi-distributions but mine can't.
> 
> Any help would be appreciated!
> 
> My code:
> 
> library(lme4)
> woodlicedata<-read.csv("Woodlice.csv",header=T)
> attach(woodlicedata)
> names(woodlicedata)
>> ### This set of models examine whether there are differences in distances
> travelled.
>>
> distmodel<-glmer(Distance~Treatment*Sex+(1|ID)+(1|Path.set/ID),family=poisson(link='log'))
>> summary(distmodel)  ### AIC= 42972.6
> Generalized linear mixed model fit by maximum likelihood (Laplace
> Approximation) [
> glmerMod]
>  Family: poisson  ( log )
> Formula: Distance ~ Treatment * Sex + (1 | ID) + (1 | Path.set/ID)
> 
>      AIC      BIC   logLik deviance df.resid
>  42972.6  43007.3 -21479.3  42958.6     1038
> 
> Scaled residuals:
>     Min      1Q  Median      3Q     Max
> -11.853  -4.074  -1.656   2.146  38.035
> 
> Random effects:
>  Groups      Name        Variance  Std.Dev.
>  ID:Path.set (Intercept) 6.485e-02 0.2546560
>  ID          (Intercept) 6.906e-02 0.2627973
>  Path.set    (Intercept) 1.368e-10 0.0000117
> Number of obs: 1045, groups:  ID:Path.set, 104; ID, 52; Path.set, 2
> 
> Fixed effects:
>                             Estimate Std. Error z value Pr(>|z|)
> (Intercept)                  4.20814    0.07757  54.248  < 2e-16 ***
> TreatmentRestricted          0.10843    0.14359   0.755  0.45015
> SexMale                     -0.08408    0.11545  -0.728  0.46644
> TreatmentRestricted:SexMale -0.49300    0.18781  -2.625  0.00866 **
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> 
> Correlation of Fixed Effects:
>             (Intr) TrtmnR SexMal
> TrtmntRstrc -0.540
> SexMale     -0.672  0.363
> TrtmntRs:SM  0.413 -0.765 -0.615
> 
>>
> distmodel2<-glmer(Distance~Treatment*Sex+(1|ID)+(1|Path.set/ID),family=quasipoisson(link='log'))
> Error in lme4::glFormula(formula = Distance ~ Treatment * Sex + (1 | ID) +
> :
>   "quasi" families cannot be used in glmer
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From helenmcc@llin @ending from hotm@il@com  Fri Jul 13 19:17:48 2018
From: helenmcc@llin @ending from hotm@il@com (Helen McCallin)
Date: Fri, 13 Jul 2018 17:17:48 +0000
Subject: [R-sig-ME] Questions regarding MODEL AVERAGING output
Message-ID: <DB6PR1001MB13825EF36BB655A86ACDFA63AE580@DB6PR1001MB1382.EURPRD10.PROD.OUTLOOK.COM>

Hi

I would like to post the following question to the forum please?


I am running a glmer model on a response variable with binomial distribution and random term. My data has 3 explanatory categorical variables and I have successfully run dredge() on them and their interactions to get AICc values.


I want model averaging to provide output with coefficients and an index of relative importance of fixed effects from those models; within a delta constraint that I specify.I can get this using the code below for alternative datasets but not for this dataset.

This is what I have input.

ae <- read.csv(file=file.choose())

options(na.action="na.fail")

global.model<-glmer(

     cbind(numerator,total-numerator)~d+s+t+d:s:t+d:s+d:t+s:t+(1|random),

     data=ae, family=binomial)

options(max.print=1000000)

dredge(global.model,beta=c("none"),evaluate=TRUE,rank="AICc")

ae.model <- glmer(

     cbind(numerator,total-numerator)~d+s+t+d:s:t+d:s+d:t+s:t+(1|random),

    data=ae,family=binomial)

models <- dredge(ae.model)

summary(model.avg(get.models(models,subset=delta<5)))

model.avg() produces this error message:

Error in model.avg.default(get.models(models, subset = delta < 5)) : models are not unique. Duplicates: '2 = 3 = 4' and '10 = 11'
This doesn't make sense, DREDGE does not (cannot) produce duplicate models ? each model is a unique iteration within the full model, yet the error message indicates that MODEL AVERAGE identified ?duplicate? models from within DREDGE output. R fails to run MODEL AVERAGE under these circumstances - producing no further output.
Has anyone else experienced similar problem (with 'not unique', duplicate models) via MODEL AVERAGE?
Is there a workaround for the error that prevents me running MODEL AVERAGE due to perceived ?duplicate? models in DREDGE?
I am happy to provide Dropbox link to data.

Thanks in advance for any help given. Summary of data below:

summary(ae)

  p                   t           day             hour            scan             random    behaviour

 ae:182   blood        :42   Min.   :1.000   Min.   :1.000   Min.   : 0   ae_blood_1_1:  7   alert:182

          egg          :35   1st Qu.:1.000   1st Qu.:1.000   1st Qu.:10   ae_blood_1_2:  7

          repellentfree:63   Median :2.000   Median :2.000   Median :30   ae_blood_1_3:  7

          wolf         :42   Mean   :1.654   Mean   :1.962   Mean   :30   ae_blood_2_1:  7

                             3rd Qu.:2.000   3rd Qu.:3.000   3rd Qu.:50   ae_blood_2_2:  7

                             Max.   :3.000   Max.   :3.000   Max.   :60   ae_blood_2_3:  7

                                                                          (Other)     :140

   numerator           total      proportion        percentage      d                        s

 Min.   : 0.0000   Min.   :17   Min.   :0.00000   Min.   : 0.000   E :14   1 - very light wind:21

 1st Qu.: 0.0000   1st Qu.:17   1st Qu.:0.00000   1st Qu.: 0.000   SE:84   2 - light wind     :70

 Median : 0.0000   Median :17   Median :0.00000   Median : 0.000   SW:35   3 - moderate wind  :77

 Mean   : 0.5824   Mean   :17   Mean   :0.03426   Mean   : 3.426   W :49   4 - heavy wind     :14

 3rd Qu.: 0.0000   3rd Qu.:17   3rd Qu.:0.00000   3rd Qu.: 0.000

 Max.   :16.0000   Max.   :17   Max.   :0.94118   Max.   :94.118


Many thanks for your help

Helen McCallin

	[[alternative HTML version deleted]]


From helenmcc@llin @ending from hotm@il@com  Fri Jul 13 19:35:02 2018
From: helenmcc@llin @ending from hotm@il@com (Helen McCallin)
Date: Fri, 13 Jul 2018 17:35:02 +0000
Subject: [R-sig-ME] Questions regarding MODEL AVERAGING output
In-Reply-To: <DB6PR1001MB13825EF36BB655A86ACDFA63AE580@DB6PR1001MB1382.EURPRD10.PROD.OUTLOOK.COM>
References: <DB6PR1001MB13825EF36BB655A86ACDFA63AE580@DB6PR1001MB1382.EURPRD10.PROD.OUTLOOK.COM>
Message-ID: <DB6PR1001MB138244D9A8A91B74C543EB63AE580@DB6PR1001MB1382.EURPRD10.PROD.OUTLOOK.COM>

Please find attached question in Notepad form.

Kind regards

Helen
From: Helen McCallin<mailto:helenmccallin at hotmail.com>
Sent: 13 July 2018 18:18
To: r-sig-mixed-models at r-project.org <mailto:r-sig-mixed-models at r-project.org>
Subject: [R-sig-ME] Questions regarding MODEL AVERAGING output

Hi

I would like to post the following question to the forum please?


I am running a glmer model on a response variable with binomial distribution and random term. My data has 3 explanatory categorical variables and I have successfully run dredge() on them and their interactions to get AICc values.


I want model averaging to provide output with coefficients and an index of relative importance of fixed effects from those models; within a delta constraint that I specify.I can get this using the code below for alternative datasets but not for this dataset.

This is what I have input.

ae <- read.csv(file=file.choose())

options(na.action="na.fail")

global.model<-glmer(

     cbind(numerator,total-numerator)~d+s+t+d:s:t+d:s+d:t+s:t+(1|random),

     data=ae, family=binomial)

options(max.print=1000000)

dredge(global.model,beta=c("none"),evaluate=TRUE,rank="AICc")

ae.model <- glmer(

     cbind(numerator,total-numerator)~d+s+t+d:s:t+d:s+d:t+s:t+(1|random),

    data=ae,family=binomial)

models <- dredge(ae.model)

summary(model.avg(get.models(models,subset=delta<5)))

model.avg() produces this error message:

Error in model.avg.default(get.models(models, subset = delta < 5)) : models are not unique. Duplicates: '2 = 3 = 4' and '10 = 11'
This doesn't make sense, DREDGE does not (cannot) produce duplicate models ? each model is a unique iteration within the full model, yet the error message indicates that MODEL AVERAGE identified ?duplicate? models from within DREDGE output. R fails to run MODEL AVERAGE under these circumstances - producing no further output.
Has anyone else experienced similar problem (with 'not unique', duplicate models) via MODEL AVERAGE?
Is there a workaround for the error that prevents me running MODEL AVERAGE due to perceived ?duplicate? models in DREDGE?
I am happy to provide Dropbox link to data.

Thanks in advance for any help given. Summary of data below:

summary(ae)

  p                   t           day             hour            scan             random    behaviour

 ae:182   blood        :42   Min.   :1.000   Min.   :1.000   Min.   : 0   ae_blood_1_1:  7   alert:182

          egg          :35   1st Qu.:1.000   1st Qu.:1.000   1st Qu.:10   ae_blood_1_2:  7

          repellentfree:63   Median :2.000   Median :2.000   Median :30   ae_blood_1_3:  7

          wolf         :42   Mean   :1.654   Mean   :1.962   Mean   :30   ae_blood_2_1:  7

                             3rd Qu.:2.000   3rd Qu.:3.000   3rd Qu.:50   ae_blood_2_2:  7

                             Max.   :3.000   Max.   :3.000   Max.   :60   ae_blood_2_3:  7

                                                                          (Other)     :140

   numerator           total      proportion        percentage      d                        s

 Min.   : 0.0000   Min.   :17   Min.   :0.00000   Min.   : 0.000   E :14   1 - very light wind:21

 1st Qu.: 0.0000   1st Qu.:17   1st Qu.:0.00000   1st Qu.: 0.000   SE:84   2 - light wind     :70

 Median : 0.0000   Median :17   Median :0.00000   Median : 0.000   SW:35   3 - moderate wind  :77

 Mean   : 0.5824   Mean   :17   Mean   :0.03426   Mean   : 3.426   W :49   4 - heavy wind     :14

 3rd Qu.: 0.0000   3rd Qu.:17   3rd Qu.:0.00000   3rd Qu.: 0.000

 Max.   :16.0000   Max.   :17   Max.   :0.94118   Max.   :94.118


Many thanks for your help

Helen McCallin

        [[alternative HTML version deleted]]


	[[alternative HTML version deleted]]


From @@uppe@@ @ending from gm@il@com  Mon Jul 16 09:20:26 2018
From: @@uppe@@ @ending from gm@il@com (Sebastian Sauppe)
Date: Mon, 16 Jul 2018 09:20:26 +0200
Subject: [R-sig-ME] GAMMs: difference smooths in itsadug
Message-ID: <BB3FC742-791E-4E08-AA2D-530F9D172CF9@gmail.com>

Dear list members,

I have a question on the treatment of random effects in plotting difference smooths for GAMMs with the package itsadug.

I am modelling the time course of binomial data with mgcv::bam. The simplified formula is: cbind(success, failure) ~ 1 + s(Time, by = Condition) + s(Subject, Time, bs = ?fs?) + s(Item, Time, bs = ?fs?). The two factor smooths are supposed to account for the random effects of participants and stimuli in my experiments.

I would like to use itsadug::plot_diff() to visualize how the two conditions differ over time. However, I am not quite sure what the rm.ranef argument argument of this function does. What I basically want to do is to look at the difference the way one would look at a fixed effect in an GLMER model, i.e., looking at the fixed effect of the interaction of Time:Condition after the variance that can be ascribed to random effects of subjects and items have been accounted for. Would for this rm.ranef=TRUE or rm.ranef=FALSE be the right option?

Kind regards,
Sebastian

-----------
Dr. Sebastian Sauppe
Department of Comparative Linguistics, University of Zurich
Homepage: https://sites.google.com/site/sauppes/ <https://sites.google.com/site/sauppes/>
Twitter: @SebastianSauppe <https://twitter.com/SebastianSauppe>
Google Scholar Citations: https://scholar.google.de/citations?user=wEtciKQAAAAJ <https://scholar.google.de/citations?user=wEtciKQAAAAJ> 
ResearchGate: http://www.researchgate.net/profile/Sebastian_Sauppe <http://www.researchgate.net/profile/Sebastian_Sauppe>
ORCID ID: http://orcid.org/0000-0001-8670-8197 <http://orcid.org/0000-0001-8670-8197>

	[[alternative HTML version deleted]]


From Phillip@Ald@y @ending from mpi@nl  Mon Jul 16 12:48:29 2018
From: Phillip@Ald@y @ending from mpi@nl (Alday, Phillip)
Date: Mon, 16 Jul 2018 10:48:29 +0000
Subject: [R-sig-ME] GAMMs: difference smooths in itsadug
In-Reply-To: <BB3FC742-791E-4E08-AA2D-530F9D172CF9@gmail.com>
References: <BB3FC742-791E-4E08-AA2D-530F9D172CF9@gmail.com>
Message-ID: <e1d985b6-8eaa-0ec3-df87-cd3521d5d008@mpi.nl>

Hi Sebastian,

are you using gamm4? If so, you can extract the GAM object, which if I'm
not mistaken is already marginalized over the random effects i.e. is
just fixed effects, and just use its plotting functions.

model <- gamm4(....)

plot(model$gam)

Best,
Phillip

On 16/07/18 09:20, Sebastian Sauppe wrote:
> Dear list members,
>
> I have a question on the treatment of random effects in plotting difference smooths for GAMMs with the package itsadug.
>
> I am modelling the time course of binomial data with mgcv::bam. The simplified formula is: cbind(success, failure) ~ 1 + s(Time, by = Condition) + s(Subject, Time, bs = ?fs?) + s(Item, Time, bs = ?fs?). The two factor smooths are supposed to account for the random effects of participants and stimuli in my experiments.
>
> I would like to use itsadug::plot_diff() to visualize how the two conditions differ over time. However, I am not quite sure what the rm.ranef argument argument of this function does. What I basically want to do is to look at the difference the way one would look at a fixed effect in an GLMER model, i.e., looking at the fixed effect of the interaction of Time:Condition after the variance that can be ascribed to random effects of subjects and items have been accounted for. Would for this rm.ranef=TRUE or rm.ranef=FALSE be the right option?
>
> Kind regards,
> Sebastian
>
> -----------
> Dr. Sebastian Sauppe
> Department of Comparative Linguistics, University of Zurich
> Homepage: https://sites.google.com/site/sauppes/ <https://sites.google.com/site/sauppes/>
> Twitter: @SebastianSauppe <https://twitter.com/SebastianSauppe>
> Google Scholar Citations: https://scholar.google.de/citations?user=wEtciKQAAAAJ <https://scholar.google.de/citations?user=wEtciKQAAAAJ> 
> ResearchGate: http://www.researchgate.net/profile/Sebastian_Sauppe <http://www.researchgate.net/profile/Sebastian_Sauppe>
> ORCID ID: http://orcid.org/0000-0001-8670-8197 <http://orcid.org/0000-0001-8670-8197>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From c@c@voeten @ending from hum@leidenuniv@nl  Mon Jul 16 15:26:34 2018
From: c@c@voeten @ending from hum@leidenuniv@nl (Voeten, C.C.)
Date: Mon, 16 Jul 2018 13:26:34 +0000
Subject: [R-sig-ME] GAMMs: difference smooths in itsadug
In-Reply-To: <BB3FC742-791E-4E08-AA2D-530F9D172CF9@gmail.com>
References: <BB3FC742-791E-4E08-AA2D-530F9D172CF9@gmail.com>
Message-ID: <D14049CE02C4F54D95360EEC06CE45C50F8D31E8@SPMXM08.VUW.leidenuniv.nl>

Hi Sebastian,

Yes, rm.ranef=TRUE will give you precisely this, assuming your random effects are all of the 'fs' and/or 're' category, which is the case for the model you describe.
With rm.ranef=FALSE, you would get the effects specifically for the first subject+item combination in your data set (or, more precisely, whichever of these happened to be the first level in your factor variables for these terms).

Best,
Cesko

> -----Oorspronkelijk bericht-----
> Van: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-
> project.org] Namens Sebastian Sauppe
> Verzonden: maandag 16 juli 2018 9:20
> Aan: r-sig-mixed-models at r-project.org
> Onderwerp: [R-sig-ME] GAMMs: difference smooths in itsadug
> 
> Dear list members,
> 
> I have a question on the treatment of random effects in plotting difference
> smooths for GAMMs with the package itsadug.
> 
> I am modelling the time course of binomial data with mgcv::bam. The
> simplified formula is: cbind(success, failure) ~ 1 + s(Time, by = Condition) +
> s(Subject, Time, bs = ?fs?) + s(Item, Time, bs = ?fs?). The two factor smooths
> are supposed to account for the random effects of participants and stimuli in
> my experiments.
> 
> I would like to use itsadug::plot_diff() to visualize how the two conditions
> differ over time. However, I am not quite sure what the rm.ranef argument
> argument of this function does. What I basically want to do is to look at the
> difference the way one would look at a fixed effect in an GLMER model, i.e.,
> looking at the fixed effect of the interaction of Time:Condition after the
> variance that can be ascribed to random effects of subjects and items have
> been accounted for. Would for this rm.ranef=TRUE or rm.ranef=FALSE be the
> right option?
> 
> Kind regards,
> Sebastian
> 
> -----------
> Dr. Sebastian Sauppe
> Department of Comparative Linguistics, University of Zurich
> Homepage: https://sites.google.com/site/sauppes/
> <https://sites.google.com/site/sauppes/>
> Twitter: @SebastianSauppe <https://twitter.com/SebastianSauppe>
> Google Scholar Citations:
> https://scholar.google.de/citations?user=wEtciKQAAAAJ
> <https://scholar.google.de/citations?user=wEtciKQAAAAJ>
> ResearchGate: http://www.researchgate.net/profile/Sebastian_Sauppe
> <http://www.researchgate.net/profile/Sebastian_Sauppe>
> ORCID ID: http://orcid.org/0000-0001-8670-8197 <http://orcid.org/0000-0001-
> 8670-8197>
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

From @@uppe@@ @ending from gm@il@com  Mon Jul 16 15:33:17 2018
From: @@uppe@@ @ending from gm@il@com (Sebastian Sauppe)
Date: Mon, 16 Jul 2018 15:33:17 +0200
Subject: [R-sig-ME] GAMMs: difference smooths in itsadug
In-Reply-To: <D14049CE02C4F54D95360EEC06CE45C50F8D31E8@SPMXM08.VUW.leidenuniv.nl>
References: <BB3FC742-791E-4E08-AA2D-530F9D172CF9@gmail.com>
 <D14049CE02C4F54D95360EEC06CE45C50F8D31E8@SPMXM08.VUW.leidenuniv.nl>
Message-ID: <A9410DFF-1578-4277-9FFD-9C3C8F3F5E3B@gmail.com>

Dear Cesko,

Thanks a lot, that was exactly the info I was looking for!

Regards,
Sebastian

-----------
Dr. Sebastian Sauppe
Department of Comparative Linguistics, University of Zurich
Homepage: https://sites.google.com/site/sauppes/ <https://sites.google.com/site/sauppes/>
Twitter: @SebastianSauppe <https://twitter.com/SebastianSauppe>
Google Scholar Citations: https://scholar.google.de/citations?user=wEtciKQAAAAJ <https://scholar.google.de/citations?user=wEtciKQAAAAJ> 
ResearchGate: http://www.researchgate.net/profile/Sebastian_Sauppe <http://www.researchgate.net/profile/Sebastian_Sauppe>
ORCID ID: http://orcid.org/0000-0001-8670-8197 <http://orcid.org/0000-0001-8670-8197>

> Am 16.07.2018 um 15:26 schrieb Voeten, C.C. <c.c.voeten at hum.leidenuniv.nl>:
> 
> Hi Sebastian,
> 
> Yes, rm.ranef=TRUE will give you precisely this, assuming your random effects are all of the 'fs' and/or 're' category, which is the case for the model you describe.
> With rm.ranef=FALSE, you would get the effects specifically for the first subject+item combination in your data set (or, more precisely, whichever of these happened to be the first level in your factor variables for these terms).
> 
> Best,
> Cesko
> 
>> -----Oorspronkelijk bericht-----
>> Van: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-
>> project.org] Namens Sebastian Sauppe
>> Verzonden: maandag 16 juli 2018 9:20
>> Aan: r-sig-mixed-models at r-project.org
>> Onderwerp: [R-sig-ME] GAMMs: difference smooths in itsadug
>> 
>> Dear list members,
>> 
>> I have a question on the treatment of random effects in plotting difference
>> smooths for GAMMs with the package itsadug.
>> 
>> I am modelling the time course of binomial data with mgcv::bam. The
>> simplified formula is: cbind(success, failure) ~ 1 + s(Time, by = Condition) +
>> s(Subject, Time, bs = ?fs?) + s(Item, Time, bs = ?fs?). The two factor smooths
>> are supposed to account for the random effects of participants and stimuli in
>> my experiments.
>> 
>> I would like to use itsadug::plot_diff() to visualize how the two conditions
>> differ over time. However, I am not quite sure what the rm.ranef argument
>> argument of this function does. What I basically want to do is to look at the
>> difference the way one would look at a fixed effect in an GLMER model, i.e.,
>> looking at the fixed effect of the interaction of Time:Condition after the
>> variance that can be ascribed to random effects of subjects and items have
>> been accounted for. Would for this rm.ranef=TRUE or rm.ranef=FALSE be the
>> right option?
>> 
>> Kind regards,
>> Sebastian
>> 
>> -----------
>> Dr. Sebastian Sauppe
>> Department of Comparative Linguistics, University of Zurich
>> Homepage: https://sites.google.com/site/sauppes/
>> <https://sites.google.com/site/sauppes/>
>> Twitter: @SebastianSauppe <https://twitter.com/SebastianSauppe>
>> Google Scholar Citations:
>> https://scholar.google.de/citations?user=wEtciKQAAAAJ
>> <https://scholar.google.de/citations?user=wEtciKQAAAAJ>
>> ResearchGate: http://www.researchgate.net/profile/Sebastian_Sauppe
>> <http://www.researchgate.net/profile/Sebastian_Sauppe>
>> ORCID ID: http://orcid.org/0000-0001-8670-8197 <http://orcid.org/0000-0001-
>> 8670-8197>
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


	[[alternative HTML version deleted]]


From me@tre@frederico @ending from gm@il@com  Wed Jul 18 16:23:36 2018
From: me@tre@frederico @ending from gm@il@com (Frederico Mestre)
Date: Wed, 18 Jul 2018 15:23:36 +0100
Subject: [R-sig-ME] Model fit with glmmadmb
Message-ID: <CAPfBvqzppWQ0rBaLoA_OrG4FWdCRCKmHNJbO68YQnJ=gDE4Huw@mail.gmail.com>

Hello everybody,

I've been using
?the ?
package glmmADMB and I wonder if I can get any information on the overall
fit of my models (
?some sort of ?
pseudo R^2?).

I ran the function glmmadmb with negative binomial.

?Cheers,?
-- 
?
?Frederico Mestre
?

	[[alternative HTML version deleted]]


From m@tthieu@re@che-rigon @ending from p@ri@7@ju@@ieu@fr  Thu Jul 19 12:03:19 2018
From: m@tthieu@re@che-rigon @ending from p@ri@7@ju@@ieu@fr (Resche Rigon Matthieu)
Date: Thu, 19 Jul 2018 12:03:19 +0200
Subject: [R-sig-ME] R-sig-mixed-models Digest, Vol 139, Issue 9
In-Reply-To: <mailman.16689.5.1531994402.15863.r-sig-mixed-models@r-project.org>
Message-ID: <react-211736846@univ-paris7.fr>

Bonjour,

Je suis actuellement en cong?, avec un acc?s restreint ? mes mails.
Je serai de retour le 6 ao?t.

Matthieu Resche-Rigon


From mollieebrook@ @ending from gm@il@com  Thu Jul 19 14:37:02 2018
From: mollieebrook@ @ending from gm@il@com (Mollie Brooks)
Date: Thu, 19 Jul 2018 14:37:02 +0200
Subject: [R-sig-ME] Model fit with glmmadmb
In-Reply-To: <CAPfBvqzppWQ0rBaLoA_OrG4FWdCRCKmHNJbO68YQnJ=gDE4Huw@mail.gmail.com>
References: <CAPfBvqzppWQ0rBaLoA_OrG4FWdCRCKmHNJbO68YQnJ=gDE4Huw@mail.gmail.com>
Message-ID: <268DDD0B-6AB2-45A8-A1D8-16A3C941C6F8@gmail.com>

Hi Frederico,

I don?t know about an R^2 with glmmadmb, but it is possible with glmmTMB for negative binomial GLMMs. I believe that glmmTMB has all the functionality of glmmadmb and more. 

The r2 function is implemented in the sjstats package version 0.16.0.
https://cran.r-project.org/web/packages/sjstats/index.html

If you want to know some details such as how it doesn?t work with zero-inflated models yet, there is a discussion here
https://github.com/glmmTMB/glmmTMB/issues/169

cheers,
Mollie


> On 18Jul 2018, at 16:23, Frederico Mestre <mestre.frederico at gmail.com> wrote:
> 
> Hello everybody,
> 
> I've been using
> ?the ?
> package glmmADMB and I wonder if I can get any information on the overall
> fit of my models (
> ?some sort of ?
> pseudo R^2?).
> 
> I ran the function glmmadmb with negative binomial.
> 
> ?Cheers,?
> -- 
> ?
> ?Frederico Mestre
> ?
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From p@ul@john@on @ending from gl@@gow@@c@uk  Thu Jul 19 14:37:50 2018
From: p@ul@john@on @ending from gl@@gow@@c@uk (Paul Johnson)
Date: Thu, 19 Jul 2018 12:37:50 +0000
Subject: [R-sig-ME] Model fit with glmmadmb
In-Reply-To: <CAPfBvqzppWQ0rBaLoA_OrG4FWdCRCKmHNJbO68YQnJ=gDE4Huw@mail.gmail.com>
References: <CAPfBvqzppWQ0rBaLoA_OrG4FWdCRCKmHNJbO68YQnJ=gDE4Huw@mail.gmail.com>
Message-ID: <57382230-A741-471F-AD98-EE15F6108A06@glasgow.ac.uk>

Hi, 

The rsquared function in the piecewiseSEM package will do this for negative binomial GLMMs fitted with glmer.nb, but not (AFAIK) with glmmADMB. If you can?t refit your model with glmer.nb then you could DIY, following the methods in this paper (which are the same methods used by piecewiseSEM):

The coefficient of determination R2 and intra-class correlation coefficient from generalized linear mixed-effects models revisited and expanded
Nakagawa et al.
doi.org/10.1098/rsif.2017.0213

Appendix S6 section 2 shows a worked example for glmmadmb with negative binomial (family = ?nbinom2?).

Best wishes,
Paul



> On 18 Jul 2018, at 15:23, Frederico Mestre <mestre.frederico at gmail.com> wrote:
> 
> Hello everybody,
> 
> I've been using
> ?the ?
> package glmmADMB and I wonder if I can get any information on the overall
> fit of my models (
> ?some sort of ?
> pseudo R^2?).
> 
> I ran the function glmmadmb with negative binomial.
> 
> ?Cheers,?
> -- 
> ?
> ?Frederico Mestre
> ?
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From @m@engwork @ending from gm@il@com  Thu Jul 19 21:14:34 2018
From: @m@engwork @ending from gm@il@com (Ahreum Maeng)
Date: Thu, 19 Jul 2018 14:14:34 -0500
Subject: [R-sig-ME] help: error in fn(x,
 ...): Downdated VtV is not positive definite
Message-ID: <CAGNwpw2Y4ePa9=T6uNoSFkuYpaze3wV9A3g4cf2GqHL5-R==eQ@mail.gmail.com>

Hello,

I got a following error message while running a MLM using lme4 package.

Error in fn(x, ...) : Downdated VtV is not positive definite


my model was as following:

out <- lmer(situ ~ cult*change + (change || id) + (0 + frace | type), data
= tidy.total, REML=FALSE)

where
situ:  numeric
change: numeric
cult: factor (coded in 1 and -1)


How could I fix this issue?

Thanks a lot,
Ahreum

	[[alternative HTML version deleted]]


From bbolker @ending from gm@il@com  Thu Jul 19 21:33:56 2018
From: bbolker @ending from gm@il@com (Ben Bolker)
Date: Thu, 19 Jul 2018 15:33:56 -0400
Subject: [R-sig-ME] help: error in fn(x,
 ...): Downdated VtV is not positive definite
In-Reply-To: <CAGNwpw2Y4ePa9=T6uNoSFkuYpaze3wV9A3g4cf2GqHL5-R==eQ@mail.gmail.com>
References: <CAGNwpw2Y4ePa9=T6uNoSFkuYpaze3wV9A3g4cf2GqHL5-R==eQ@mail.gmail.com>
Message-ID: <CABghstSQF2Emjx+Mj7XZkeAhbQjJO7hzWwy_T=56n-UShPSzyQ@mail.gmail.com>

 what is frace?

  This is a relatively rare error message.  It usually indicates a
strongly unbalanced/unstable model for some reason. Have you tried
rescaling parameters?  Do simpler versions of the model work?
On Thu, Jul 19, 2018 at 3:15 PM Ahreum Maeng <amaengwork at gmail.com> wrote:
>
> Hello,
>
> I got a following error message while running a MLM using lme4 package.
>
> Error in fn(x, ...) : Downdated VtV is not positive definite
>
>
> my model was as following:
>
> out <- lmer(situ ~ cult*change + (change || id) + (0 + frace | type), data
> = tidy.total, REML=FALSE)
>
> where
> situ:  numeric
> change: numeric
> cult: factor (coded in 1 and -1)
>
>
> How could I fix this issue?
>
> Thanks a lot,
> Ahreum
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbolker @ending from gm@il@com  Fri Jul 20 01:57:16 2018
From: bbolker @ending from gm@il@com (Ben Bolker)
Date: Thu, 19 Jul 2018 19:57:16 -0400
Subject: [R-sig-ME] help: error in fn(x,
 ...): Downdated VtV is not positive definite
In-Reply-To: <CAGNwpw26Vk7DOwwb7Fdub3rP44CO2aW6-crDsRWnX3Q--6c-bQ@mail.gmail.com>
References: <CAGNwpw2Y4ePa9=T6uNoSFkuYpaze3wV9A3g4cf2GqHL5-R==eQ@mail.gmail.com>
 <CABghstSQF2Emjx+Mj7XZkeAhbQjJO7hzWwy_T=56n-UShPSzyQ@mail.gmail.com>
 <CAGNwpw1q=UVA8Xm-7UkpwsC3vjnuL0ySXKuna70tRCyRCdXB8A@mail.gmail.com>
 <CAGNwpw26Vk7DOwwb7Fdub3rP44CO2aW6-crDsRWnX3Q--6c-bQ@mail.gmail.com>
Message-ID: <CABghstRd9xPRGoPPOiL2_MGtyHm0dceqxfpv_Wmju4CA12pgZw@mail.gmail.com>

(Please keep r-sig-mixed-models at r-project.org in the Cc: list ...)

On Thu, Jul 19, 2018 at 4:49 PM Ahreum Maeng <amaengwork at gmail.com> wrote:
>
> 1) Okay, I centered all the numeric variables and ran the model again. I did not get the error message and the model ran and I was able to get the summary results. However, I got the following warning message. Would this warning be a problem?
>
> med.fit <- lmer(situ.cent ~ cult.cont*change.cent + (change.cent || id), data = tidy.total, REML=FALSE)
> Warning messages:
> 1: In optwrap(optimizer, devfun, getStart(start, rho$lower, rho$pp),  :
>   convergence code 3 from bobyqa: bobyqa -- a trust region step failed to reduce q
> 2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>   unable to evaluate scaled gradient
> 3: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
>   Model failed to converge: degenerate  Hessian with 2 negative eigenvalues

   The bobyqa error means the model got stuck somewhere, this may or
may not be important (see
https://stats.stackexchange.com/questions/89945/meaning-of-a-convergence-warning-in-glmer
for more discussion). The standard suggestion is to try with another
optimizer and compare results (see `?troubleshooting` and
`?convergence`).
   The fact that the Hessian has negative eigenvalues probably means
the model is singular.  Are some of your estimated random-effects
standard deviations zero or very close to zero?  That may be ignorable
(see the GLMM FAQ), but in general means your model is more complex
than your data can support.

>
>
> 2) I ran another related model with the same data set using the following model. But I get the error message saying that the grouping factor specification is invalid. How could I fix this issue?
>
>  out.fit <- lmer(rating.cent ~ situ.cent*cult.cont*change.cent + (change.cent || id), data = tidy.total, REML=FALSE)
>
> Error: Invalid grouping factor specification, id

  Pretty much impossible to say without a reproducible example.  Is
'id' definitely a factor within tidy.total?  (It should work anyway if
it's (1) not a factor [it will be converted] and (2) not in tidy.total
[it will be taken from the environment], but both of these cases will
improve the chances of everything working OK.)

>
>
> Many thanks,
> Ahreum
>
> On Thu, Jul 19, 2018 at 2:37 PM, Ahreum Maeng <amaengwork at gmail.com> wrote:
>>
>> frace is a factor as well.  I still get the same error message after dropping (0 + frace | type) part.
>>
>> How can I do the resealing parameters?
>>
>>
>> On Thu, Jul 19, 2018 at 2:33 PM, Ben Bolker <bbolker at gmail.com> wrote:
>>>
>>>  what is frace?
>>>
>>>   This is a relatively rare error message.  It usually indicates a
>>> strongly unbalanced/unstable model for some reason. Have you tried
>>> rescaling parameters?  Do simpler versions of the model work?
>>> On Thu, Jul 19, 2018 at 3:15 PM Ahreum Maeng <amaengwork at gmail.com> wrote:
>>> >
>>> > Hello,
>>> >
>>> > I got a following error message while running a MLM using lme4 package.
>>> >
>>> > Error in fn(x, ...) : Downdated VtV is not positive definite
>>> >
>>> >
>>> > my model was as following:
>>> >
>>> > out <- lmer(situ ~ cult*change + (change || id) + (0 + frace | type), data
>>> > = tidy.total, REML=FALSE)
>>> >
>>> > where
>>> > situ:  numeric
>>> > change: numeric
>>> > cult: factor (coded in 1 and -1)
>>> >
>>> >
>>> > How could I fix this issue?
>>> >
>>> > Thanks a lot,
>>> > Ahreum
>>> >
>>> >         [[alternative HTML version deleted]]
>>> >
>>> > _______________________________________________
>>> > R-sig-mixed-models at r-project.org mailing list
>>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>>
>>
>> --
>>
>> --------------------------------
>>
>> Ahreum Maeng
>>
>> Assistant Professor in Marketing
>>
>> KU School of Business
>>
>> University of Kansas
>>
>> 1654 Naismith Dr. #2183
>>
>> Lawrence, KS 66045
>>
>> https://sites.google.com/site/ahreummaeng1/research
>>
>> ----------------------------------
>
>
>
>
> --
>
> --------------------------------
>
> Ahreum Maeng
>
> Assistant Professor in Marketing
>
> KU School of Business
>
> University of Kansas
>
> 1654 Naismith Dr. #2183
>
> Lawrence, KS 66045
>
> https://sites.google.com/site/ahreummaeng1/research
>
> ----------------------------------


From m@tthieu@re@che-rigon @ending from p@ri@7@ju@@ieu@fr  Fri Jul 20 01:57:59 2018
From: m@tthieu@re@che-rigon @ending from p@ri@7@ju@@ieu@fr (Resche Rigon Matthieu)
Date: Fri, 20 Jul 2018 01:57:59 +0200
Subject: [R-sig-ME] R-sig-mixed-models Digest, Vol 139, Issue 10
In-Reply-To: <mailman.16694.578.1532044655.1179.r-sig-mixed-models@r-project.org>
Message-ID: <react-211768427@univ-paris7.fr>

Bonjour,

Je suis actuellement en cong?, avec un acc?s restreint ? mes mails.
Je serai de retour le 6 ao?t.

Matthieu Resche-Rigon


From m@tthieu@re@che-rigon @ending from p@ri@7@ju@@ieu@fr  Fri Jul 20 12:03:15 2018
From: m@tthieu@re@che-rigon @ending from p@ri@7@ju@@ieu@fr (Resche Rigon Matthieu)
Date: Fri, 20 Jul 2018 12:03:15 +0200
Subject: [R-sig-ME] R-sig-mixed-models Digest, Vol 139, Issue 11
In-Reply-To: <mailman.16696.7.1532080802.61260.r-sig-mixed-models@r-project.org>
Message-ID: <react-211785599@univ-paris7.fr>

Bonjour,

Je suis actuellement en cong?, avec un acc?s restreint ? mes mails.
Je serai de retour le 6 ao?t.

Matthieu Resche-Rigon


From m@tthieu@re@che-rigon @ending from p@ri@7@ju@@ieu@fr  Sat Jul 21 12:02:58 2018
From: m@tthieu@re@che-rigon @ending from p@ri@7@ju@@ieu@fr (Resche Rigon Matthieu)
Date: Sat, 21 Jul 2018 12:02:58 +0200
Subject: [R-sig-ME] R-sig-mixed-models Digest, Vol 139, Issue 12
In-Reply-To: <mailman.16697.5.1532167202.39293.r-sig-mixed-models@r-project.org>
Message-ID: <react-211820305@univ-paris7.fr>

Bonjour,

Je suis actuellement en cong?, avec un acc?s restreint ? mes mails.
Je serai de retour le 6 ao?t.

Matthieu Resche-Rigon


From peter@p@przycki @ending from gm@il@com  Fri Jul 20 16:27:05 2018
From: peter@p@przycki @ending from gm@il@com (Peter Paprzycki)
Date: Fri, 20 Jul 2018 09:27:05 -0500
Subject: [R-sig-ME] cross-classified models
Message-ID: <CAM834XLfG5PVPyABwKX_41z2y3bXG2u0F98Dn575wEWHMkmY7g@mail.gmail.com>

I was wondering if the lme4 package can handle so called cross-classified
models. Let's say the hypothetical data set up is the following:

Level 1: observations/data at time 0,1,2
Level 2: students cross-classified by teachers (student has a different
teacher in each observation, 0,1,2). HLM 7 program follows the convention
of a row-by-column cross classification.

Would anyone hint to what the syntax in lme4 would look like (assuming
random-intercept model, no covariates/null model).

Peter

<http://www.avg.com/email-signature?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
Virus-free.
www.avg.com
<http://www.avg.com/email-signature?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
<#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>

	[[alternative HTML version deleted]]


From peter@p@przycki @ending from gm@il@com  Sun Jul 22 02:49:41 2018
From: peter@p@przycki @ending from gm@il@com (Peter Paprzycki)
Date: Sat, 21 Jul 2018 19:49:41 -0500
Subject: [R-sig-ME] graphics that accompany the Fitting Mixed-Effects Models
 Using the lme4 Package in R
Message-ID: <CAM834X+i6FZmqH0cZR4Xcw7_f9MvEYLZsSP7h_XMnG9Lp1AK4w@mail.gmail.com>

Can someone direct my to the R code to the cool graphics (I believe done in
lattice package) that accompany the pdf labeled "Fitting Mixed-Effects
Models Using the lme4 Package in R" prepared by Doug Bates and presented at
International Meeting of the Psychometric Society
June 29, 2008 accessed at at:
http://www.stat.wisc.edu/~bates/IMPS2008/lme4-4a4.pdf?

Thank you

Peter



<http://www.avg.com/email-signature?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
Virus-free.
www.avg.com
<http://www.avg.com/email-signature?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
<#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>

	[[alternative HTML version deleted]]


From m@tthieu@re@che-rigon @ending from p@ri@7@ju@@ieu@fr  Sun Jul 22 12:02:01 2018
From: m@tthieu@re@che-rigon @ending from p@ri@7@ju@@ieu@fr (Resche Rigon Matthieu)
Date: Sun, 22 Jul 2018 12:02:01 +0200
Subject: [R-sig-ME] R-sig-mixed-models Digest, Vol 139, Issue 13
In-Reply-To: <mailman.16700.5.1532253602.11178.r-sig-mixed-models@r-project.org>
Message-ID: <react-211837474@univ-paris7.fr>

Bonjour,

Je suis actuellement en cong?, avec un acc?s restreint ? mes mails.
Je serai de retour le 6 ao?t.

Matthieu Resche-Rigon


From m@lcolm@f@irbrother @ending from umu@@e  Sun Jul 22 13:40:57 2018
From: m@lcolm@f@irbrother @ending from umu@@e (Malcolm Fairbrother)
Date: Sun, 22 Jul 2018 11:40:57 +0000
Subject: [R-sig-ME] cross-classified models
In-Reply-To: <mailman.16700.5.1532253602.11178.r-sig-mixed-models@r-project.org>
References: <mailman.16700.5.1532253602.11178.r-sig-mixed-models@r-project.org>
Message-ID: <38BF53E7-D628-4A1C-836C-6CF685C6AC24@umu.se>

Hi Peter,

Yes, cross-classification is no problem for lme4. The package will determine automatically that your data are cross-classified, assuming you use unique identifiers for each classification. For a random intercept null model (with a normally distributed outcome), you might want something like:

mod1 <- lmer(y ~ 1 + (1 | student) + (1 | teacher), data = yourdataframe)

Hope that helps,

Malcolm



> Date: Fri, 20 Jul 2018 09:27:05 -0500
> From: Peter Paprzycki <peter.paprzycki at gmail.com>
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] cross-classified models
> 
> I was wondering if the lme4 package can handle so called cross-classified
> models. Let's say the hypothetical data set up is the following:
> 
> Level 1: observations/data at time 0,1,2
> Level 2: students cross-classified by teachers (student has a different
> teacher in each observation, 0,1,2). HLM 7 program follows the convention
> of a row-by-column cross classification.
> 
> Would anyone hint to what the syntax in lme4 would look like (assuming
> random-intercept model, no covariates/null model).
> 
> Peter


From m@k@im@rudnev @ending from gm@il@com  Sun Jul 22 15:16:07 2018
From: m@k@im@rudnev @ending from gm@il@com (Maksim Rudnev)
Date: Sun, 22 Jul 2018 14:16:07 +0100
Subject: [R-sig-ME] 
 graphics that accompany the Fitting Mixed-Effects Models
 Using the lme4 Package in R
In-Reply-To: <CAM834X+i6FZmqH0cZR4Xcw7_f9MvEYLZsSP7h_XMnG9Lp1AK4w@mail.gmail.com>
References: <CAM834X+i6FZmqH0cZR4Xcw7_f9MvEYLZsSP7h_XMnG9Lp1AK4w@mail.gmail.com>
Message-ID: <CAO73wK=tzHp5m0rVbEP4TY8HuE5RHdv-EaArYW-QfpfUZbFepQ@mail.gmail.com>

Hi Peter,

the handout says explicitly (p.2): "I will not show every piece of code
used to produce the data graphics. The code is available in the script
files for the slides (and sometimes in the example sections of the data
set?s documentation)."

I was able to find all the source codes in the same directory
http://www.stat.wisc.edu/~bates/IMPS2008/ See the .Rnw  files.

For example, the code for Figure "Reaction time versus days by subject" on
page 16 of the handout is in a file
http://www.stat.wisc.edu/~bates/IMPS2008/Longitudinal.Rnw, lines 54-58.

On Sun, Jul 22, 2018 at 1:49 AM Peter Paprzycki <peter.paprzycki at gmail.com>
wrote:

> Can someone direct my to the R code to the cool graphics (I believe done in
> lattice package) that accompany the pdf labeled "Fitting Mixed-Effects
> Models Using the lme4 Package in R" prepared by Doug Bates and presented at
> International Meeting of the Psychometric Society
> June 29, 2008 accessed at at:
> http://www.stat.wisc.edu/~bates/IMPS2008/lme4-4a4.pdf?
>
> Thank you
>
> Peter
>
>
>
> <
> http://www.avg.com/email-signature?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail
> >
> Virus-free.
> www.avg.com
> <
> http://www.avg.com/email-signature?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail
> >
> <#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


-- 
Best regards,
Maksim Rudnev

	[[alternative HTML version deleted]]


From peter@p@przycki @ending from gm@il@com  Sun Jul 22 16:51:44 2018
From: peter@p@przycki @ending from gm@il@com (Peter Paprzycki)
Date: Sun, 22 Jul 2018 09:51:44 -0500
Subject: [R-sig-ME] cumulative Z-structure
Message-ID: <CAM834XL1d0PMNmuH8Cur5Htxx4=SVi1ZFbACp2qcR1P2xjA+Kw@mail.gmail.com>

In longitudinal,  repeated-measure intervention research, the authors of
HLM 6.03 software recommend using a so called cumulative Z-structure to
reflect the carry-overs of intervention effects from one measurement
occasion to another. Is there an equivalent of this structure with the use
of the lme function? The data set up is annual observations nested in
students crossed by teachers and schools with intervention on and off
between years.



I appreciate guidance. Thank you.

Peter

<http://www.avg.com/email-signature?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
Virus-free.
www.avg.com
<http://www.avg.com/email-signature?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
<#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>

	[[alternative HTML version deleted]]


From helenmcc@llin @ending from me@com  Sun Jul 22 18:33:01 2018
From: helenmcc@llin @ending from me@com (Helen McCallin)
Date: Sun, 22 Jul 2018 17:33:01 +0100
Subject: [R-sig-ME] Error message in model average
Message-ID: <3C5D29F1-119D-4BBD-B4DA-ACCE48C60222@me.com>

Hi

Would anyone be aware of any reasons for error messages when running model average? I posted on 13/07/18 and would be really grateful if anyone may be able to provide any help with this.

Many thanks

Helen 

From trichter m@ili@g off u@i-breme@@de  Sun Jul 22 21:26:33 2018
From: trichter m@ili@g off u@i-breme@@de (trichter m@ili@g off u@i-breme@@de)
Date: Sun, 22 Jul 2018 21:26:33 +0200
Subject: [R-sig-ME] Is my model correct (1 random effect + spatially
 structured outcome) ?
Message-ID: <20180722212633.Horde.LNEC8aEodR-H-slUFtECQon@webmail.uni-bremen.de>


Dear list,

i have already posted once about this dataset, however now with a  
different approach.

My dataset consists of six sampling dates (several months apart) with  
60 sampling stations each (within 100 square meters).
Initially, i wondered if i can calculate Tukey contrasts by sampling  
dates if they are possibly both fixed and random.
This time, my approach is fairly basic. I would like to model the  
influence of some environmental predictors (e.g. pH) on my outcome.
I dont think my stations (specified with x,y coordinates) have random  
intercepts (as they are close to each other), but they likely feature  
spatial autocorrelation.
This time, i treat time as random, and since the sampling dates are  
months apart, and the sampling grid was always different, i assume  
there is no temporal autocorrelation or effects
of repeated measures.
So, i would then fit a model like this:

model1 <- lmer(Outcome ~ Var1+Var2+...+(1|sampling date),  
correlation=corXXXX(1,form=~x+y), data=data, REML=false)
(alternatively also as interaction between the fixed effect).

Assuming that i have normally distributed outcomes (which i dont), is  
this a proper approach?

Alternatively, i could fit a model for each of the six sampling dates  
independently, and not use random effects at all.

Thank you!


From m@tthieu@re@che-rigon @ending from p@ri@7@ju@@ieu@fr  Sun Jul 22 21:27:04 2018
From: m@tthieu@re@che-rigon @ending from p@ri@7@ju@@ieu@fr (Resche Rigon Matthieu)
Date: Sun, 22 Jul 2018 21:27:04 +0200
Subject: [R-sig-ME] R-sig-mixed-models Digest, Vol 139, Issue 14
In-Reply-To: <mailman.16705.689.1532287598.1179.r-sig-mixed-models@r-project.org>
Message-ID: <react-211845352@univ-paris7.fr>

Bonjour,

Je suis actuellement en cong?, avec un acc?s restreint ? mes mails.
Je serai de retour le 6 ao?t.

Matthieu Resche-Rigon


From thierry@onkelinx @ending from inbo@be  Mon Jul 23 09:02:43 2018
From: thierry@onkelinx @ending from inbo@be (Thierry Onkelinx)
Date: Mon, 23 Jul 2018 09:02:43 +0200
Subject: [R-sig-ME] Is my model correct (1 random effect + spatially
 structured outcome) ?
In-Reply-To: <20180722212633.Horde.LNEC8aEodR-H-slUFtECQon@webmail.uni-bremen.de>
References: <20180722212633.Horde.LNEC8aEodR-H-slUFtECQon@webmail.uni-bremen.de>
Message-ID: <CAJuCY5yo+chRn24SbssTkts3Hu8TS=fqno8UyjrFpgyov6Zv-Q@mail.gmail.com>

Dear Tim,

lmer() from lme4 cannot handle correlation functions. lme() form nlme
can. But there the correlation is only within the most detailed level
of the random effects. Observations from different levels (here
sampling dates) are assumed to be independent. However they will share
the same parameters for the correlation function.

Another option would be to fit the model without spatial correlation
structure and then make a variogram of the residuals. It might be
harder to get a stable variogram with only 60 locations. If the
variogram indicates spatial correlation, then you will have to model
it.

Also provide sensible starting values for the correlation function.
The default value for the range is very small, often resulting in a
very small fitted range.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
AND FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////




2018-07-22 21:26 GMT+02:00  <trichter at uni-bremen.de>:
>
> Dear list,
>
> i have already posted once about this dataset, however now with a different
> approach.
>
> My dataset consists of six sampling dates (several months apart) with 60
> sampling stations each (within 100 square meters).
> Initially, i wondered if i can calculate Tukey contrasts by sampling dates
> if they are possibly both fixed and random.
> This time, my approach is fairly basic. I would like to model the influence
> of some environmental predictors (e.g. pH) on my outcome.
> I dont think my stations (specified with x,y coordinates) have random
> intercepts (as they are close to each other), but they likely feature
> spatial autocorrelation.
> This time, i treat time as random, and since the sampling dates are months
> apart, and the sampling grid was always different, i assume there is no
> temporal autocorrelation or effects
> of repeated measures.
> So, i would then fit a model like this:
>
> model1 <- lmer(Outcome ~ Var1+Var2+...+(1|sampling date),
> correlation=corXXXX(1,form=~x+y), data=data, REML=false)
> (alternatively also as interaction between the fixed effect).
>
> Assuming that i have normally distributed outcomes (which i dont), is this a
> proper approach?
>
> Alternatively, i could fit a model for each of the six sampling dates
> independently, and not use random effects at all.
>
> Thank you!
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From helenmcc@llin @ending from hotm@il@com  Mon Jul 23 11:33:03 2018
From: helenmcc@llin @ending from hotm@il@com (Helen McCallin)
Date: Mon, 23 Jul 2018 09:33:03 +0000
Subject: [R-sig-ME] Model average error message
Message-ID: <DB6PR1001MB138280A451E5B703AB9BCE80AE560@DB6PR1001MB1382.EURPRD10.PROD.OUTLOOK.COM>

Hi


I am running a glmer model on a response variable with binomial distribution and random term. My data has 3 explanatory categorical variables and I have successfully run dredge() on them and their interactions to get AICc values.


I want model averaging to provide output with coefficients and an index of relative importance of fixed effects from those models; within a delta constraint that I specify.I can get this using the code below for alternative datasets but not for this dataset.


model.avg() produces this error message:

Error in model.avg.default(get.models(models, subset = delta < 5)) : models are not unique. Duplicates: '2 = 3 = 4' and '10 = 11'


This doesn't make sense, DREDGE does not (cannot) produce duplicate models ? each model is a unique iteration within the full model, yet the error message indicates that MODEL AVERAGE identified ?duplicate? models from within DREDGE output. R fails to run MODEL AVERAGE under these circumstances - producing no further output.


Has anyone else experienced similar problem (with 'not unique', duplicate models) via MODEL AVERAGE?


Is there a workaround for the error that prevents me running MODEL AVERAGE due to perceived ?duplicate? models in DREDGE?


Many thanks for any help anyone can provide.



	[[alternative HTML version deleted]]


From m@tthieu@re@che-rigon @ending from p@ri@7@ju@@ieu@fr  Mon Jul 23 12:02:27 2018
From: m@tthieu@re@che-rigon @ending from p@ri@7@ju@@ieu@fr (Resche Rigon Matthieu)
Date: Mon, 23 Jul 2018 12:02:27 +0200
Subject: [R-sig-ME] R-sig-mixed-models Digest, Vol 139, Issue 15
In-Reply-To: <mailman.16709.9.1532340002.53292.r-sig-mixed-models@r-project.org>
Message-ID: <react-211863153@univ-paris7.fr>

Bonjour,

Je suis actuellement en cong?, avec un acc?s restreint ? mes mails.
Je serai de retour le 6 ao?t.

Matthieu Resche-Rigon


From bbolker @ending from gm@il@com  Mon Jul 23 19:41:58 2018
From: bbolker @ending from gm@il@com (Ben Bolker)
Date: Mon, 23 Jul 2018 13:41:58 -0400
Subject: [R-sig-ME] cumulative Z-structure
In-Reply-To: <CAM834XL1d0PMNmuH8Cur5Htxx4=SVi1ZFbACp2qcR1P2xjA+Kw@mail.gmail.com>
References: <CAM834XL1d0PMNmuH8Cur5Htxx4=SVi1ZFbACp2qcR1P2xjA+Kw@mail.gmail.com>
Message-ID: <CABghstSzCwPxMEfpqt-f-gGQE8aWHVcYkffU=nfvd5XuVtPL-A@mail.gmail.com>

  Can you say a little more about how the cumulative Z-structure is
defined? I can see that it's defined on p. 390 of Raudenbush's HLM 6
book, but I can't get to that page on Google Books to see how it's
actually specified ...
On Sun, Jul 22, 2018 at 10:51 AM Peter Paprzycki
<peter.paprzycki at gmail.com> wrote:
>
> In longitudinal,  repeated-measure intervention research, the authors of
> HLM 6.03 software recommend using a so called cumulative Z-structure to
> reflect the carry-overs of intervention effects from one measurement
> occasion to another. Is there an equivalent of this structure with the use
> of the lme function? The data set up is annual observations nested in
> students crossed by teachers and schools with intervention on and off
> between years.
>
>
>
> I appreciate guidance. Thank you.
>
> Peter
>
> <http://www.avg.com/email-signature?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
> Virus-free.
> www.avg.com
> <http://www.avg.com/email-signature?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
> <#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From @eleb@t@om @ending from y@hoo@co@uk  Mon Jul 23 21:08:13 2018
From: @eleb@t@om @ending from y@hoo@co@uk (moses selebatso)
Date: Mon, 23 Jul 2018 19:08:13 +0000 (UTC)
Subject: [R-sig-ME] R Squared for GLMM with gamma distribution
References: <186158126.13744635.1532372893037.ref@mail.yahoo.com>
Message-ID: <186158126.13744635.1532372893037@mail.yahoo.com>

Dear R
I am trying to calculate the coefficient of determination, R2 for gamma distribution data, but I cant find the right r package or script for it. Any ideas?
Thank you, in advance
Mos
	[[alternative HTML version deleted]]


From dwin@emiu@ @ending from comc@@t@net  Mon Jul 23 23:38:30 2018
From: dwin@emiu@ @ending from comc@@t@net (David Winsemius)
Date: Mon, 23 Jul 2018 14:38:30 -0700
Subject: [R-sig-ME] R Squared for GLMM with gamma distribution
In-Reply-To: <186158126.13744635.1532372893037@mail.yahoo.com>
References: <186158126.13744635.1532372893037.ref@mail.yahoo.com>
 <186158126.13744635.1532372893037@mail.yahoo.com>
Message-ID: <DCA692A5-7D14-44E9-B5A3-E5EF45CD451D@comcast.net>


> On Jul 23, 2018, at 12:08 PM, moses selebatso via R-sig-mixed-models <r-sig-mixed-models at r-project.org> wrote:
> 
> Dear R
> I am trying to calculate the coefficient of determination, R2 for gamma distribution data, but I cant find the right r package or script for it. Any ideas?
> Thank you, in advance
> Mos
> 	[[alternative HTML version deleted]]

One clarifying question might be how do you know that the gamma distribution properly describes the errors of your data situation? The fact that a value appears to be "gamma" when viewed as a single value does not mean that the errors around a well-constructed model will have gamma-distributed errors.

Another clarifying question: What do you expect for a "coefficient of determination" if you were performing some sort of regression that was suited for data that remained gamma-error distributed? You might look at the multiple "R^2" variants that exist for models constructed with logistic regression. They all  fail in some manner or another to live up to the expectations generated by the "original" R^2 developed for linear models.

> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From m@tthieu@re@che-rigon @ending from p@ri@7@ju@@ieu@fr  Tue Jul 24 12:02:44 2018
From: m@tthieu@re@che-rigon @ending from p@ri@7@ju@@ieu@fr (Resche Rigon Matthieu)
Date: Tue, 24 Jul 2018 12:02:44 +0200
Subject: [R-sig-ME] R-sig-mixed-models Digest, Vol 139, Issue 16
In-Reply-To: <mailman.16713.7.1532426401.32312.r-sig-mixed-models@r-project.org>
Message-ID: <react-211906185@univ-paris7.fr>

Bonjour,

Je suis actuellement en cong?, avec un acc?s restreint ? mes mails.
Je serai de retour le 6 ao?t.

Matthieu Resche-Rigon


From @dl@point @ending from gm@il@com  Tue Jul 24 16:36:46 2018
From: @dl@point @ending from gm@il@com (Scott LaPoint)
Date: Tue, 24 Jul 2018 10:36:46 -0400
Subject: [R-sig-ME] seeking input lme4::glmer with a gamma family: link =
 log or identity?
Message-ID: <CA+SovpNT6Jq03oZJym=KQohFNoMjqW_FKvvTx6AjMzF+UFuQJQ@mail.gmail.com>

Hello all,

This is my first posting, so please correct me if I didn't follow all of
the rules. Apologies also for a long post...

I'm using lme4::glmer to explore the influence of several variables on the
distance traveled by birds during their migration. I have chosen a GLMM
because I have some repeated measures (some individuals make multiple
migrations during the study) and some of my potential response variables
are non-normally distributed (although I am only presenting one response
variable here for simplicity).

I have two larger questions/issues where input is welcomed:
1. Is a Gamma distribution best for my distance data? If so, which link
function is most appropriate? I explored two link functions: identity and
log. I have concerns and see potential issues with both (see my annotations
in the reproducible example below.

2.  If the log link is the best or most appropriate to use, then the
summary(mDist) produces a sd of the random effect = 0 with the bobyqa
optimizer. Switching to Nelder_Mead gives a reasonable sd, but throws a
convergence warning. What?s going on here and which would be the
appropriate way to move forward? I'm assuming (ick...) that it's because
the log link function is inappropriate, but I'm puzzled why the two
different optimizers produce different sd values.

My concern is not whether there is significance in any of the variables,
but my choice of link function obviously affects my interpretation of the
results!

Any and all help is welcomed! I'm teaching myself GLMMs and would be
thrilled to have input!

#Dataframe:
id <- "101146512 101146512 102057059 102057999 102058563 102058990
102069680 102073750 102073750 102075125 102075125 102075918 10481019
10481021 10481023 10481023 10481023 10481029 150128761 151009981 151010107
151012935 151013389 152198213 152494581 152494617 152494756 16849706
16849887 16849887 16849887 16849913 16849913 16849913 16849913 16849926
171331052 171331052 171331205 171331205 171331516 17750149 17750164
17750164 17750164 17750194 17750194 17750194 17750194 17750233 17750280
17750280 17750280 17750280 183004701 183004701 183004704 19195992 19195992
19196055 19196079 19196079 19196092 19196092 19196092 19196202 19196202
19196202 19196453 19196466 19196466 19196466 19196504 19196504 19196504
212421463 212421463 212421463 214073818 24026401 24026401 24026482 24026482
24026482 24026482 240944289 240944289 240944289 240944308 240944308
240944308 257224604 257224604 257224605 262963605 262963608 262963608
262963608 262963608 262963608 262963609 262963609 262963610 262963611
262963612 262963613 276594658 276594658 45205417 45205417 5009278 5009282
5010023 5010023 5010566 5010567 58674007 58675110 58675110 59530545
59530545 59530620 59530620 59530737 59531771 59533985 59533985 59534620
59534620 60978379 60978551 60978658 60978658 60978784 60978784 6861013
6861013"
id <- strsplit(id, " ")
id <- as.factor(unlist(id))
year <- "2015 2016 2016 2016 2017 2017 2016 2016 2017 2016 2017 2016 2015
2014 2013 2014 2015 2013 2017 2017 2017 2017 2017 2017 2017 2017 2017 2014
2014 2015 2016 2014 2015 2016 2017 2014 2016 2017 2016 2017 2016 2014 2014
2015 2016 2014 2015 2016 2017 2014 2014 2015 2016 2017 2012 2013 2012 2015
2016 2015 2015 2016 2015 2016 2017 2015 2016 2017 2015 2015 2016 2017 2015
2016 2017 2013 2014 2015 2017 2014 2015 2014 2015 2016 2017 2015 2016 2017
2015 2016 2017 2012 2013 2013 2013 2013 2014 2015 2016 2017 2013 2014 2014
2017 2017 2017 2016 2017 2016 2017 2012 2012 2012 2013 2012 2012 2017 2016
2017 2016 2017 2016 2017 2016 2016 2016 2017 2016 2017 2016 2016 2016 2017
2016 2017 2013 2014"
year <- strsplit(year, " ")
year <- as.factor(unlist(year))
age <- "A A SA SA SA SA A SA SA A A A SA SA A A A SA A A A SA A A A A SA SA
SA SA SA SA SA SA A SA SA SA SA A SA A A A A SA SA SA SA A SA SA SA SA SA
SA SA A A A A A A A A SA A A SA SA SA A SA SA SA A A A SA SA SA SA A A A SA
SA A SA SA A A A A SA A A A A A A A SA SA A SA SA SA SA SA SA SA SA SA SA
SA A SA A A A A A A A A A A A A A A A A A SA SA"
age <- strsplit(age, " ")
age <- as.factor(unlist(age))
sex <- "male male female male female male female male male female female
male female male male male male male female male female male female male
female male male female female female female female female female female
female male male female female male female female female female male male
male male female male male male male female female male male male male
female female male male male male male male male male male male female
female female female female female male female female female female female
female male male male female female female female female female male male
male male male male female female male male female male male male male male
female male male male male male male female female male male male male male
male female female female female female female male male male male male
male"
sex <- strsplit(sex, " ")
sex <- as.factor(unlist(sex))
distance <- "3063.84 3077.34 3083.48 2903.85 3385.56 2733.14 2532.30
3619.50 2641.76 3811.18 3626.81 3532.71 3729.12 2729.26 3248.75 3764.56
3397.22 3612.98 2314.65 3372.35 2282.25 2528.39 2218.65 2651.02 3048.75
3198.92 3342.30 2308.78 2766.83 2968.76 2987.37 3686.60 2935.58 2420.89
2314.12 2975.70 4353.93 3895.47 3207.48 2490.26 2816.65 2764.26 2546.95
2622.03 2467.63 3272.38 2819.35 2705.02 2575.35 2518.16 6541.20 6541.10
6562.60 6005.08 3175.18 3531.04 2751.19 2514.32 2762.74 2180.43 2852.11
2586.59 2682.96 2230.56 2019.84 3955.19 4015.25 4238.16 1836.63 4118.42
4059.42 3305.86 3040.52 2670.84 2695.07 3441.04 3350.64 3201.92 2690.18
2798.21 2956.70 2340.82 2571.44 2634.40 2669.62 2914.93 5223.85 2622.16
3644.97 3837.83 3730.73 2992.29 3185.07 3474.46 2904.41 2180.35 1725.05
2779.72 2704.79 2920.02 2702.10 2908.45 3161.65 2990.06 2964.83 2344.53
4519.13 4507.83 3464.48 2090.23 4283.90 5561.30 2364.21 2302.45 2262.61
4666.51 3173.38 2313.64 2470.99 3509.85 3168.33 3380.10 2750.41 2989.91
3451.81 2519.03 2678.53 2370.00 2394.06 1531.50 2339.34 2669.88 2263.27
2245.88 2327.00 3243.36 3859.24"
distance <- strsplit(distance, " ")
distance <- as.numeric(unlist(distance))
direct <- "0.908 0.920 0.891 0.879 0.738 0.929 0.951 0.907 0.914 0.907
0.907 0.918 0.898 0.729 0.868 0.805 0.874 0.839 0.952 0.925 0.943 0.927
0.928 0.938 0.929 0.908 0.911 0.875 0.812 0.775 0.854 0.637 0.750 0.842
0.872 0.810 0.875 0.890 0.802 0.938 0.913 0.943 0.931 0.904 0.878 0.845
0.854 0.859 0.980 0.876 0.849 0.858 0.858 0.899 0.964 0.943 0.948 0.910
0.918 0.896 0.859 0.892 0.857 0.854 0.895 0.902 0.897 0.893 0.910 0.854
0.858 0.898 0.803 0.908 0.886 0.904 0.928 0.944 0.939 0.906 0.878 0.920
0.914 0.923 0.902 0.742 0.407 0.807 0.914 0.895 0.920 0.943 0.944 0.904
0.809 0.731 0.871 0.902 0.926 0.832 0.949 0.926 0.895 0.902 0.913 0.913
0.872 0.863 0.598 0.818 0.736 0.839 0.910 0.883 0.812 0.878 0.810 0.906
0.902 0.877 0.928 0.759 0.868 0.925 0.906 0.912 0.906 0.905 0.901 0.927
0.937 0.893 0.918 0.959 0.943 0.755 0.761"
direct <- strsplit(direct, " ")
direct <- as.numeric(unlist(direct))
CSdirect <- "0.4234405616 0.584627508 0.195104602 0.033922710 -1.859964524
0.705513927 1.001014063 0.410013792 0.504036562 0.410013792 0.410013792
0.557763859 0.289127372 -1.980850943 -0.113827358 -0.960032292 -0.033236412
-0.503350264 1.014445887 0.651786630 0.893559468 0.678650279 0.692082103
0.826400346 0.705513927 0.423445616 0.463741089 -0.019804588 -0.866009522
-1.362987023 -0.301872899 -3.216578784 -1.698782632 -0.463054791
-0.060100061 -0.892873171 -0.019804588 0.181672778 -1.000327765 0.826400346
0.490604738 0.893559468 0.732377576 0.369718318 0.020490885 -0.422759318
-0.301872899 -0.234713777 1.390536969 -0.006372763 -0.369032021
-0.248145602 -0.248145602 0.302559197 1.175627780 0.893559468 0.960718590
0.450309265 0.557763859 0.262263724 -0.234713777 0.208536426 -0.261577426
-0.301872899 0.248831899 0.342854670 0.275695548 0.221968251 0.450309265
-0.301872899 -0.248145602 0.289127372 -0.986895941 0.423445616 0.127945480
0.369718318 0.692082103 0.906991293 0.839832171 0.396581967 0.020490885
0.584627508 0.504036562 0.624922981 0.342854670 -1.806237227 -6.305898385
-0.933168644 0.504036562 0.248831899 0.584627508 0.893559468 0.906991293
0.369718318 -0.906304995 -1.953987295 -0.073531885 0.342854670 0.665218454
-0.597373035 0.974150414 0.665218454 0.248831899 0.342854670 0.490604738
0.490604738 -0.060100061 -0.180986480 -3.740419933 -0.785418576
-1.886828173 -0.503350264 0.450309265 0.087650007 -0.866009522 0.020490885
-0.892873171 0.396581967 0.342854670 0.007059061 0.692082103 -1.577896213
-0.113827358 0.651786630 0.396581967 0.477172913 0.396581967 0.383150143
0.329422845 0.678650279 0.812968522 0.221968251 0.557763859 1.108468658
0.893559468 -1.631623510 -1.551032564"
CSdirect <- strsplit(CSdirect, " ")
CSdirect <- as.numeric(unlist(CSdirect))
start <- "68 59 77 67 94 111 69 79 70 70 73 70 105 107 83 89 90 116 72 75
76 75 67 70 77 73 69 113 120 98 94 104 94 85 92 84 72 70 81 75 91 93 76 68
70 106 87 69 73 82 66 59 69 63 87 89 85 65 65 73 70 69 67 64 71 61 66 61 79
78 76 78 67 65 74 88 87 82 99 76 70 87 78 80 77 74 58 61 83 73 74 87 79 61
76 52 89 69 68 73 66 71 98 103 73 76 92 93 105 121 64 57 54 59 67 70 55 63
73 72 70 62 70 83 67 61 76 65 73 77 75 58 73 68 66 91 89"
start <- strsplit(start, " ")
start <- as.numeric(unlist(start))
CSstart <- "-0.65033704 -1.28876505 -0.01190904 -0.72127349 1.19401052
2.39993009 -0.57940060 0.12996385 -0.50846415 -0.50846415 -0.29565482
-0.50846415 1.97431142 2.11618431 0.41370963 0.83932830 0.91026475
2.75461231 -0.36659126 -0.15378193 -0.08284548 -0.15378193 -0.72127349
-0.50846415 -0.01190904 -0.29565482 -0.57940060 2.54180298 3.03835809
1.47775630 1.19401052 1.90337497 1.19401052 0.55558252 1.05213763
0.48464608 -0.36659126 -0.50846415 0.27183674 -0.15378193 0.98120119
1.12307408 -0.08284548 -0.65033704 -0.50846415 2.04524786 0.69745541
-0.57940060 -0.29565482 0.34277319 -0.79220993 -1.28876505 -0.57940060
-1.00501927 0.69745541 0.83932830 0.55558252 -0.86314638 -0.86314638
-0.29565482 -0.50846415 -0.57940060 -0.72127349 -0.93408282 -0.43752771
-1.14689216 -0.79220993 -1.14689216 0.12996385 0.05902741 -0.08284548
0.05902741 -0.72127349 -0.86314638 -0.22471837 0.76839186 0.69745541
0.34277319 1.54869275 -0.08284548 -0.50846415 0.69745541 0.05902741
0.20090030 -0.01190904 -0.22471837 -1.35970149 -1.14689216 0.41370963
-0.29565482 -0.22471837 0.69745541 0.12996385 -1.14689216 -0.08284548
-1.78532016 0.83932830 -0.57940060 -0.65033704 -0.29565482 -0.79220993
-0.43752771 1.47775630 1.83243853 -0.29565482 -0.08284548 1.05213763
1.12307408 1.97431142 3.10929454 -0.93408282 -1.43063794 -1.64344727
-1.28876505 -0.72127349 -0.50846415 -1.57251083 -1.00501927 -0.29565482
-0.36659126 -0.50846415 -1.07595571 -0.50846415 0.41370963 -0.72127349
-1.14689216 -0.08284548 -0.86314638 -0.29565482 -0.01190904 -0.15378193
-1.35970149 -0.29565482 -0.65033704 -0.79220993 0.98120119 0.83932830"
CSstart <- strsplit(CSstart, " ")
CSstart <- as.numeric(unlist(CSstart))
slat <- "48.93600 48.57967 49.07217 46.62800 46.95150 49.18567 48.38617
42.13933 48.05850 40.65500 41.33650 42.48533 46.64300 47.20000 47.32800
47.67200 46.96500 46.87000 47.76017 48.70567 49.47750 50.51267 52.61100
47.78700 46.23717 47.47950 44.71100 48.23317 48.83300 46.74067 45.30517
47.11000 48.33283 48.97667 49.17733 45.32217 46.29067 48.29750 48.79200
49.32917 46.77550 46.90983 49.07300 48.63250 50.19333 49.04033 49.06967
48.37333 47.25467 48.80133 24.31717 23.90467 24.17783 24.34033 47.08720
44.56210 43.97460 50.48517 48.45483 56.23767 48.57283 50.10050 51.41217
52.84567 53.89317 38.39817 37.69600 37.63700 53.05467 41.47567 42.18283
44.02167 47.89700 48.10050 48.76883 46.12733 46.14600 47.46017 47.44533
50.68483 50.14600 49.12883 48.68533 47.27750 48.00733 33.38517 33.43367
33.40667 45.18433 43.59767 43.66150 49.05917 49.24700 49.96900 47.79283
48.10033 48.90667 41.39850 40.91933 42.05250 47.22350 47.04250 46.11183
50.82667 46.91883 49.67550 39.52133 40.21050 46.11000 46.64850 46.96400
35.70300 37.09417 38.00500 38.98317 34.37200 53.00350 50.92967 49.76167
43.71933 44.08267 48.20750 49.06733 47.95433 43.21917 47.05950 47.03233
49.14417 49.07650 57.30167 48.52517 48.78233 49.98250 51.49683 51.20550
48.39100 48.35700"
slat <- strsplit(slat, " ")
slat <- as.numeric(unlist(slat))
CSs.lat <- "0.50577104 0.44349457 0.52956973 0.10239749 0.15893620
0.54940634 0.40967620 -0.68209590 0.35240870 -0.94151507 -0.82240802
-0.62162482 0.10501907 0.20236702 0.22473782 0.28485936 0.16129562
0.14469229 0.30026899 0.46551583 0.60041002 0.78132865 1.14805777
0.30495812 0.03409139 0.25121577 -0.23264024 0.38293610 0.48776953
0.12208904 -0.12879602 0.18663755 0.40035387 0.51287901 0.54794874
-0.12582490 0.04344169 0.39417918 0.48060388 0.57448611 0.12817635
0.15165346 0.52971479 0.45272777 0.72551699 0.52400499 0.52913280
0.40743213 0.21192180 0.48223451 -3.79690867 -3.86900208 -3.82126139
-3.79286096 0.18265275 -0.25866378 -0.36134227 0.77652242 0.42167604
1.78189778 0.44229913 0.70929292 0.93853598 1.18907150 1.37214506
-1.33594554 -1.45866513 -1.46897667 1.22559882 -0.79808502 -0.67449332
-0.35311576 0.32418303 0.35974912 0.47655442 0.01489444 0.01815744
0.24783742 0.24524381 0.81141738 0.71724504 0.53947230 0.46196097
0.21591184 0.34346562 -2.21207708 -2.20360064 -2.20831948 -0.14991546
-0.42721904 -0.41606335 0.52729769 0.56012510 0.68631041 0.30597704
0.35971940 0.50064498 -0.81157216 -0.89531761 0.69727134 0.20647416
0.17484044 0.01218548 0.83620703 0.15322640 0.63501486 -1.13964873
-1.01920118 0.01186565 0.10598032 0.16112085 -1.80698552 -1.56384810
-1.40466061 -1.23370398 -2.03960692 1.21665574 0.85420853 0.65007495
-0.40595629 -0.34245467 0.37844971 0.52872383 0.33420271 -0.49337021
0.17781157 0.17306301 0.54215331 0.53032649 1.96785509 0.43396950
0.47891384 0.68866983 0.95333217 0.90241587 0.41052035 0.40457811"
CSs.lat <- strsplit(CSs.lat, " ")
CSs.lat <- as.numeric(unlist(CSs.lat))
birds <- data.frame(id = id, year = year, age = age, sex = sex,
                    distance = distance,
                    direct = direct, CSdirect = CSdirect,
                    start = start, CSstart = CSstart,
                    slat = slat, CSs.lat = CSs.lat)

### Variable definitions:
# id = bird individual id
# year = the year during which the migration took place
# age = age class of individual. Note: some birds transitioned from SA
(subadult) to A (adult) during their tracking lifetime
# sex = sex of the bird
# distance = total distance (km) traveled by bird.id during their spring
migration for that year
# direct = "straightness" index, 0 to 1 = random to straightline, a ratio
of straightline distance from migration start and end point to actual
distance traveled (or: straight/actual)
# CSdirect = centered and scaled 'direct', va base::scale()
# start = Julian day (numeric day of the year) when the migration began
# CSstart = centered and scaled 'start', va base::scale()
# slat = latitude for the start of migration
# CSs.lat = centered and scaled 'slat', va base::scale()

# Most of the continuous variables required scaling for the GLMM and so are
included in the birds dataframe along with the original values.

require(lme4)

# The following models includes the variables that I expect a priori to
influence migration distance.
# Note: the non-scaled variables of slat, direct, and start threw rescaling
warnings.
# First with a Gamma family and an identity link function:
IdB.dist <- glmer(distance ~ CSs.lat + CSdirect + CSstart + year + age*sex
+ (1|id), data = birds,
               family = Gamma(link = identity), nAGQ = 10, control =
glmerControl(optimizer = "bobyqa"))
summary(IdB.dist)
# Notes/concerns:
  # There are no AIC, etc. estimates provided. The warning messages give
some clues, but how do I address this?
    # "Warning messages:
    # 1: In vcov.merMod(object, use.hessian = use.hessian) :
    # variance-covariance matrix computed from finite-difference Hessian is
    # not positive definite or contains NA values: falling back to var-cov
estimated from RX
    # 2: In vcov.merMod(object, correlation = correlation, sigm = sig) :
    # variance-covariance matrix computed from finite-difference Hessian is
    # not positive definite or contains NA values: falling back to var-cov
estimated from RX"
  # In general, the estimates for the fixed and random effects look
reasonable. E.g., you might                 expect a straighter path (high
direct value) would decrease the distance traveled.
  # Changing the glmerControl optimizer from "bobyqa" to "Nelder_Mead"
produces similar                 # estimates and throws the same warnings,
but produces Inf values for AIC, etc. (rather than         # NaN):
IdNM.dist <- glmer(distance ~ CSs.lat + CSdirect + CSstart + year + age*sex
+ (1|id), data = birds,
                  family = Gamma(link = identity), nAGQ = 10, control =
glmerControl(optimizer = "Nelder_Mead", optCtrl=list(maxfun=100000)))
summary(IdNM.dist)

# Now, switching to the log link function:
LogB.dist <- glmer(distance ~ CSs.lat + CSdirect + CSstart + year + age*sex
+ (1|id), data = s,
               family = Gamma(link = log), nAGQ = 10, control =
glmerControl(optimizer = "bobyqa"))
summary(LogB.dist) # sd is 0 for id, so changing to Nelder_Mead produces
accurate random factor sd but a lack of convergence issue...
# Notes/concerns:
  # AIC, etc. estimates are now provided.
  # There are no warning messages :)
  # But, the std deviation for the id (random variable) is now = 0. That
seems highly unlikely.
  # Changing the glmerControl optimizer from "bobyqa" to "Nelder_Mead"
produces very different estimates
    # and does not converge (but does give a random effects std deviation >
0!):
LogNM.dist <- glmer(distance ~ CSs.lat + CSdirect + CSstart + year +
age*sex + (1|id), data = s,
               family = Gamma(link = log), nAGQ = 10, control =
glmerControl(optimizer = "Nelder_Mead", optCtrl=list(maxfun=100000)))
summary(LogNM.dist)

Scott LaPoint
Postdoctoral Researcher, Lamont-Doherty Earth Observatory, Columbia
University
Associate Scientist, Max-Planck Institute for Ornithology
skype: scott_lapoint
twitter @sdlapoint
scottlapoint.weebly.com

	[[alternative HTML version deleted]]


From p@ul@john@on @ending from gl@@gow@@c@uk  Tue Jul 24 19:25:07 2018
From: p@ul@john@on @ending from gl@@gow@@c@uk (Paul Johnson)
Date: Tue, 24 Jul 2018 17:25:07 +0000
Subject: [R-sig-ME] 
 seeking input lme4::glmer with a gamma family: link =
 log or identity?
In-Reply-To: <CA+SovpNT6Jq03oZJym=KQohFNoMjqW_FKvvTx6AjMzF+UFuQJQ@mail.gmail.com>
References: <CA+SovpNT6Jq03oZJym=KQohFNoMjqW_FKvvTx6AjMzF+UFuQJQ@mail.gmail.com>
Message-ID: <9D07599F-0EDD-4162-81A3-0C27E8814E3E@glasgow.ac.uk>

Hi Scott,

An incomplete answer?

> 1. Is a Gamma distribution best for my distance data? If so, which link
> function is most appropriate? I explored two link functions: identity and
> log. I have concerns and see potential issues with both (see my annotations
> in the reproducible example below.

I don?t know (I haven?t run your code) but I?ve always somehow managed to avoid gamma regression for strictly positive data by logging the response and fitting a model with normal errors. 

> 2.  If the log link is the best or most appropriate to use, then the
> summary(mDist) produces a sd of the random effect = 0 with the bobyqa
> optimizer. Switching to Nelder_Mead gives a reasonable sd, but throws a
> convergence warning.

(For clarity, I assume that by "sd of the random effect? you mean the square root of the variance parameter that gauges residual inter-bird variation in mean distance and not the SD of the estimate of that parameter, which anyway isn?t output by glmer.)

Why is a random effect variance estimate of zero implausible? I would trust a converged estimate over a non-converged estimate, regardless of whether the estimate is zero. Also? you could compare the log-likelihoods using logLik() ?  you?d expect the converged fit to have a higher LL. For more general troubleshooting of convergence warnings:
http://rpubs.com/bbolker/lme4trouble1
Another quick check I often do is to fit the non-converged model with glmmTMB (which appears to be more robust than lme4), and compare likelihoods and estimates with lme4.

A quick and dirty model fit assessment is to simulate from the fitted model (which is as easy as simulate(my.fit)), and see if the simulated responses look more or less like the real responses.

Good luck,
Paul


From phillip@@ld@y @ending from mpi@nl  Wed Jul 25 14:50:34 2018
From: phillip@@ld@y @ending from mpi@nl (Phillip Alday)
Date: Wed, 25 Jul 2018 14:50:34 +0200
Subject: [R-sig-ME] Model average error message
In-Reply-To: <DB6PR1001MB138280A451E5B703AB9BCE80AE560@DB6PR1001MB1382.EURPRD10.PROD.OUTLOOK.COM>
References: <DB6PR1001MB138280A451E5B703AB9BCE80AE560@DB6PR1001MB1382.EURPRD10.PROD.OUTLOOK.COM>
Message-ID: <e5c92d4e-400f-aaf4-01fd-5e41d14ecdaf@mpi.nl>

Hi Helen,

model.avg() tells you which models are duplicates. What do the formulas
look like for those models? Seeing the formulae may help identify what
model.avg() gets stuck on.

Best,
Phillip

On 07/23/2018 11:33 AM, Helen McCallin wrote:
> Hi
> 
> 
> I am running a glmer model on a response variable with binomial distribution and random term. My data has 3 explanatory categorical variables and I have successfully run dredge() on them and their interactions to get AICc values.
> 
> 
> I want model averaging to provide output with coefficients and an index of relative importance of fixed effects from those models; within a delta constraint that I specify.I can get this using the code below for alternative datasets but not for this dataset.
> 
> 
> model.avg() produces this error message:
> 
> Error in model.avg.default(get.models(models, subset = delta < 5)) : models are not unique. Duplicates: '2 = 3 = 4' and '10 = 11'
> 
> 
> This doesn't make sense, DREDGE does not (cannot) produce duplicate models ? each model is a unique iteration within the full model, yet the error message indicates that MODEL AVERAGE identified ?duplicate? models from within DREDGE output. R fails to run MODEL AVERAGE under these circumstances - producing no further output.
> 
> 
> Has anyone else experienced similar problem (with 'not unique', duplicate models) via MODEL AVERAGE?
> 
> 
> Is there a workaround for the error that prevents me running MODEL AVERAGE due to perceived ?duplicate? models in DREDGE?
> 
> 
> Many thanks for any help anyone can provide.
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From phillip@@ld@y @ending from mpi@nl  Wed Jul 25 17:09:17 2018
From: phillip@@ld@y @ending from mpi@nl (Phillip Alday)
Date: Wed, 25 Jul 2018 17:09:17 +0200
Subject: [R-sig-ME] Model average error message
In-Reply-To: <VI1PR1001MB1390F1430CCBE7C331E9E235AE540@VI1PR1001MB1390.EURPRD10.PROD.OUTLOOK.COM>
References: <DB6PR1001MB138280A451E5B703AB9BCE80AE560@DB6PR1001MB1382.EURPRD10.PROD.OUTLOOK.COM>
 <e5c92d4e-400f-aaf4-01fd-5e41d14ecdaf@mpi.nl>
 <VI1PR1001MB1390F1430CCBE7C331E9E235AE540@VI1PR1001MB1390.EURPRD10.PROD.OUTLOOK.COM>
Message-ID: <35689173-80dc-0cc6-e647-acd629107a85@mpi.nl>

(Please keep the list in CC.)

The output of

get.models(models,subset=delta<5)

would be more interesting. Or even better:

lapply(get.models(models,subset=delta<5), formula)

So that we see which formulas are being labelled as identical.

Phillip

On 07/25/2018 04:56 PM, Helen McCallin wrote:
> Hi Phil
> 
> Thank you so much for your reply. Please find the codes I am using
> below. Is this what you mean?
> 
> ae <- read.csv(file=file.choose())
> 
> options(na.action="na.fail")
> 
> global.model<-glmer(
> 
>     
> cbind(numerator,total-numerator)~d+s+t+p+d:s:t:p+d:s:t+d:s:p+d:t:p+s:t:p+d:t+d:s+d:p+s:t+s:p+t:p+(1|random), 
> 
>      data=ae, family=binomial)   
> 
> options(max.print=1000000)
> 
> dredge(global.model,beta=c("none"),evaluate=TRUE,rank="AICc") 
> 
> ae.model <- glmer(
> 
>     
> cbind(numerator,total-numerator)~d+s+t+p+d:s:t:p+d:s:t+d:s:p+d:t:p+s:t:p+d:t+d:s+d:p+s:t+s:p+t:p+(1|random),
> 
>     data=ae,family=binomial)
> 
> models <- dredge(ae.model)  
> 
> summary(model.avg(get.models(models,subset=delta<5)))
> 
> 
> Many thanks for any help.
> 
> Best wishes
> 
> Helen
> 
> On 25 Jul 2018, at 13:50, Phillip Alday <phillip.alday at mpi.nl
> <mailto:phillip.alday at mpi.nl>> wrote:
> 
>> Hi Helen,
>>
>> model.avg() tells you which models are duplicates. What do the formulas
>> look like for those models? Seeing the formulae may help identify what
>> model.avg() gets stuck on.
>>
>> Best,
>> Phillip
>>
>> On 07/23/2018 11:33 AM, Helen McCallin wrote:
>>> Hi
>>>
>>>
>>> I am running a glmer model on a response variable with binomial
>>> distribution and random term. My data has 3 explanatory categorical
>>> variables and I have successfully run dredge() on them and their
>>> interactions to get AICc values.
>>>
>>>
>>> I want model averaging to provide output with coefficients and an
>>> index of relative importance of fixed effects from those models;
>>> within a delta constraint that I specify.I can get this using the
>>> code below for alternative datasets but not for this dataset.
>>>
>>>
>>> model.avg() produces this error message:
>>>
>>> Error in model.avg.default(get.models(models, subset = delta < 5)) :
>>> models are not unique. Duplicates: '2 = 3 = 4' and '10 = 11'
>>>
>>>
>>> This doesn't make sense, DREDGE does not (cannot) produce duplicate
>>> models ? each model is a unique iteration within the full model, yet
>>> the error message indicates that MODEL AVERAGE identified ?duplicate?
>>> models from within DREDGE output. R fails to run MODEL AVERAGE under
>>> these circumstances - producing no further output.
>>>
>>>
>>> Has anyone else experienced similar problem (with 'not unique',
>>> duplicate models) via MODEL AVERAGE?
>>>
>>>
>>> Is there a workaround for the error that prevents me running MODEL
>>> AVERAGE due to perceived ?duplicate? models in DREDGE?
>>>
>>>
>>> Many thanks for any help anyone can provide.
>>>
>>>
>>>
>>>    [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org
>>> <mailto:R-sig-mixed-models at r-project.org> mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>


From helenmcc@llin @ending from hotm@il@com  Wed Jul 25 17:17:18 2018
From: helenmcc@llin @ending from hotm@il@com (Helen McCallin)
Date: Wed, 25 Jul 2018 15:17:18 +0000
Subject: [R-sig-ME] Model average error message
In-Reply-To: <35689173-80dc-0cc6-e647-acd629107a85@mpi.nl>
References: <DB6PR1001MB138280A451E5B703AB9BCE80AE560@DB6PR1001MB1382.EURPRD10.PROD.OUTLOOK.COM>
 <e5c92d4e-400f-aaf4-01fd-5e41d14ecdaf@mpi.nl>
 <VI1PR1001MB1390F1430CCBE7C331E9E235AE540@VI1PR1001MB1390.EURPRD10.PROD.OUTLOOK.COM>,
 <35689173-80dc-0cc6-e647-acd629107a85@mpi.nl>
Message-ID: <VI1PR1001MB1390468968C6E3AA04E05A4BAE540@VI1PR1001MB1390.EURPRD10.PROD.OUTLOOK.COM>

Apologies, very new to this! I am currently away from my computer but as soon as I am home (within the hour) I will get those for you. 

Many thanks again 

Helen

> On 25 Jul 2018, at 16:09, Phillip Alday <phillip.alday at mpi.nl> wrote:
> 
> (Please keep the list in CC.)
> 
> The output of
> 
> get.models(models,subset=delta<5)
> 
> would be more interesting. Or even better:
> 
> lapply(get.models(models,subset=delta<5), formula)
> 
> So that we see which formulas are being labelled as identical.
> 
> Phillip
> 
>> On 07/25/2018 04:56 PM, Helen McCallin wrote:
>> Hi Phil
>> 
>> Thank you so much for your reply. Please find the codes I am using
>> below. Is this what you mean?
>> 
>> ae <- read.csv(file=file.choose())
>> 
>> options(na.action="na.fail")
>> 
>> global.model<-glmer(
>> 
>> 
>> cbind(numerator,total-numerator)~d+s+t+p+d:s:t:p+d:s:t+d:s:p+d:t:p+s:t:p+d:t+d:s+d:p+s:t+s:p+t:p+(1|random), 
>> 
>>     data=ae, family=binomial)   
>> 
>> options(max.print=1000000)
>> 
>> dredge(global.model,beta=c("none"),evaluate=TRUE,rank="AICc") 
>> 
>> ae.model <- glmer(
>> 
>> 
>> cbind(numerator,total-numerator)~d+s+t+p+d:s:t:p+d:s:t+d:s:p+d:t:p+s:t:p+d:t+d:s+d:p+s:t+s:p+t:p+(1|random),
>> 
>>    data=ae,family=binomial)
>> 
>> models <- dredge(ae.model)  
>> 
>> summary(model.avg(get.models(models,subset=delta<5)))
>> 
>> 
>> Many thanks for any help.
>> 
>> Best wishes
>> 
>> Helen
>> 
>> On 25 Jul 2018, at 13:50, Phillip Alday <phillip.alday at mpi.nl
>> <mailto:phillip.alday at mpi.nl>> wrote:
>> 
>>> Hi Helen,
>>> 
>>> model.avg() tells you which models are duplicates. What do the formulas
>>> look like for those models? Seeing the formulae may help identify what
>>> model.avg() gets stuck on.
>>> 
>>> Best,
>>> Phillip
>>> 
>>>> On 07/23/2018 11:33 AM, Helen McCallin wrote:
>>>> Hi
>>>> 
>>>> 
>>>> I am running a glmer model on a response variable with binomial
>>>> distribution and random term. My data has 3 explanatory categorical
>>>> variables and I have successfully run dredge() on them and their
>>>> interactions to get AICc values.
>>>> 
>>>> 
>>>> I want model averaging to provide output with coefficients and an
>>>> index of relative importance of fixed effects from those models;
>>>> within a delta constraint that I specify.I can get this using the
>>>> code below for alternative datasets but not for this dataset.
>>>> 
>>>> 
>>>> model.avg() produces this error message:
>>>> 
>>>> Error in model.avg.default(get.models(models, subset = delta < 5)) :
>>>> models are not unique. Duplicates: '2 = 3 = 4' and '10 = 11'
>>>> 
>>>> 
>>>> This doesn't make sense, DREDGE does not (cannot) produce duplicate
>>>> models ? each model is a unique iteration within the full model, yet
>>>> the error message indicates that MODEL AVERAGE identified ?duplicate?
>>>> models from within DREDGE output. R fails to run MODEL AVERAGE under
>>>> these circumstances - producing no further output.
>>>> 
>>>> 
>>>> Has anyone else experienced similar problem (with 'not unique',
>>>> duplicate models) via MODEL AVERAGE?
>>>> 
>>>> 
>>>> Is there a workaround for the error that prevents me running MODEL
>>>> AVERAGE due to perceived ?duplicate? models in DREDGE?
>>>> 
>>>> 
>>>> Many thanks for any help anyone can provide.
>>>> 
>>>> 
>>>> 
>>>>   [[alternative HTML version deleted]]
>>>> 
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org
>>>> <mailto:R-sig-mixed-models at r-project.org> mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>> 

From helenmcc@llin @ending from hotm@il@com  Wed Jul 25 19:15:03 2018
From: helenmcc@llin @ending from hotm@il@com (Helen McCallin)
Date: Wed, 25 Jul 2018 17:15:03 +0000
Subject: [R-sig-ME] Model average error message
In-Reply-To: <VI1PR1001MB1390468968C6E3AA04E05A4BAE540@VI1PR1001MB1390.EURPRD10.PROD.OUTLOOK.COM>
References: <DB6PR1001MB138280A451E5B703AB9BCE80AE560@DB6PR1001MB1382.EURPRD10.PROD.OUTLOOK.COM>
 <e5c92d4e-400f-aaf4-01fd-5e41d14ecdaf@mpi.nl>
 <VI1PR1001MB1390F1430CCBE7C331E9E235AE540@VI1PR1001MB1390.EURPRD10.PROD.OUTLOOK.COM>,
 <35689173-80dc-0cc6-e647-acd629107a85@mpi.nl>,
 <VI1PR1001MB1390468968C6E3AA04E05A4BAE540@VI1PR1001MB1390.EURPRD10.PROD.OUTLOOK.COM>
Message-ID: <VI1PR1001MB1390B65BF59F52547F1F991DAE540@VI1PR1001MB1390.EURPRD10.PROD.OUTLOOK.COM>

Hi Phil

I have run the lapply code and this was the output


lapply(get.models(models,subset=delta<5),formula)

$`720`

cbind(numerator, total - numerator) ~ d + p + s + t + (1 | random) + d:t + p:s + s:t



$`976`

cbind(numerator, total - numerator) ~ d + p + s + t + (1 | random) + d:t + p:s + p:t + s:t



$`9168`

cbind(numerator, total - numerator) ~ d + p + s + t + (1 | random) + d:t + p:s + p:t + s:t + p:s:t



$`9120`

cbind(numerator, total - numerator) ~ d + p + s + t + (1 | random) + d:p + p:s + p:t + s:t + p:s:t



$`640`

cbind(numerator, total - numerator) ~ d + p + s + t + (1 | random) + d:p + d:s + d:t + s:t



$`768`

cbind(numerator, total - numerator) ~ d + p + s + t + (1 | random) + d:p + d:s + d:t + p:s + s:t



$`896`

cbind(numerator, total - numerator) ~ d + p + s + t + (1 | random) + d:p + d:s + d:t + p:t + s:t



$`1024`

cbind(numerator, total - numerator) ~ d + p + s + t + (1 | random) + d:p + d:s + d:t + p:s + p:t + s:t



$`1792`

cbind(numerator, total - numerator) ~ d + p + s + t + (1 | random) + d:p + d:s + d:t + p:s + s:t + d:p:s



$`2048`

cbind(numerator, total - numerator) ~ d + p + s + t + (1 | random) + d:p + d:s + d:t + p:s + p:t + s:t + d:p:s



$`2944`

cbind(numerator, total - numerator) ~ d + p + s + t + (1 | random) + d:p + d:s + d:t + p:t + s:t + d:p:t



$`3072`

cbind(numerator, total - numerator) ~ d + p + s + t + (1 | random) + d:p + d:s + d:t + p:s + p:t + s:t + d:p:t



$`4096`

cbind(numerator, total - numerator) ~ d + p + s + t + (1 | random) + d:p + d:s + d:t + p:s + p:t + s:t + d:p:s + d:p:t



$`4736`

cbind(numerator, total - numerator) ~ d + p + s + t + (1 | random) + d:p + d:s + d:t + s:t + d:s:t



$`4864`

cbind(numerator, total - numerator) ~ d + p + s + t + (1 | random) + d:p + d:s + d:t + p:s + s:t + d:s:t



$`4992`

cbind(numerator, total - numerator) ~ d + p + s + t + (1 | random) + d:p + d:s + d:t + p:t + s:t + d:s:t



$`5120`

cbind(numerator, total - numerator) ~ d + p + s + t + (1 | random) + d:p + d:s + d:t + p:s + p:t + s:t + d:s:t



$`5888`

cbind(numerator, total - numerator) ~ d + p + s + t + (1 | random) + d:p + d:s + d:t + p:s + s:t + d:p:s + d:s:t



$`6144`

cbind(numerator, total - numerator) ~ d + p + s + t + (1 | random) + d:p + d:s + d:t + p:s + p:t + s:t + d:p:s + d:s:t



$`7040`

cbind(numerator, total - numerator) ~ d + p + s + t + (1 | random) + d:p + d:s + d:t + p:t + s:t + d:p:t + d:s:t



$`7168`

cbind(numerator, total - numerator) ~ d + p + s + t + (1 | random) + d:p + d:s + d:t + p:s + p:t + s:t + d:p:t + d:s:t



$`8192`

cbind(numerator, total - numerator) ~ d + p + s + t + (1 | random) + d:p + d:s + d:t + p:s + p:t + s:t + d:p:s + d:p:t + d:s:t



$`9216`

cbind(numerator, total - numerator) ~ d + p + s + t + (1 | random) + d:p + d:s + d:t + p:s + p:t + s:t + p:s:t



$`10240`

cbind(numerator, total - numerator) ~ d + p + s + t + (1 | random) + d:p + d:s + d:t + p:s + p:t + s:t + d:p:s + p:s:t



$`11264`

cbind(numerator, total - numerator) ~ d + p + s + t + (1 | random) + d:p + d:s + d:t + p:s + p:t + s:t + d:p:t + p:s:t



$`12288`

cbind(numerator, total - numerator) ~ d + p + s + t + (1 | random) + d:p + d:s + d:t + p:s + p:t + s:t + d:p:s + d:p:t + p:s:t



$`13312`

cbind(numerator, total - numerator) ~ d + p + s + t + (1 | random) + d:p + d:s + d:t + p:s + p:t + s:t + d:s:t + p:s:t



$`14336`

cbind(numerator, total - numerator) ~ d + p + s + t + (1 | random) + d:p + d:s + d:t + p:s + p:t + s:t + d:p:s + d:s:t + p:s:t



$`15360`

cbind(numerator, total - numerator) ~ d + p + s + t + (1 | random) + d:p + d:s + d:t + p:s + p:t + s:t + d:p:t + d:s:t + p:s:t



$`16384`

cbind(numerator, total - numerator) ~ d + p + s + t + (1 | random) + d:p + d:s + d:t + p:s + p:t + s:t + d:p:s + d:p:t + d:s:t + p:s:t



$`32768`

cbind(numerator, total - numerator) ~ d + p + s + t + (1 | random) + d:p + d:s + d:t + p:s + p:t + s:t + d:p:s + d:p:t + d:s:t + p:s:t + d:p:s:t



$`960`

cbind(numerator, total - numerator) ~ d + p + s + t + (1 | random) + d:p + d:s + p:s + p:t + s:t



$`1984`

cbind(numerator, total - numerator) ~ d + p + s + t + (1 | random) + d:p + d:s + p:s + p:t + s:t + d:p:s



$`9152`

cbind(numerator, total - numerator) ~ d + p + s + t + (1 | random) + d:p + d:s + p:s + p:t + s:t + p:s:t



$`10176`

cbind(numerator, total - numerator) ~ d + p + s + t + (1 | random) + d:p + d:s + p:s + p:t + s:t + d:p:s + p:s:t



$`736`

cbind(numerator, total - numerator) ~ d + p + s + t + (1 | random) + d:p + d:t + p:s + s:t



$`992`

cbind(numerator, total - numerator) ~ d + p + s + t + (1 | random) + d:p + d:t + p:s + p:t + s:t



$`3040`

cbind(numerator, total - numerator) ~ d + p + s + t + (1 | random) + d:p + d:t + p:s + p:t + s:t + d:p:t



$`9184`

cbind(numerator, total - numerator) ~ d + p + s + t + (1 | random) + d:p + d:t + p:s + p:t + s:t + p:s:t



$`11232`

cbind(numerator, total - numerator) ~ d + p + s + t + (1 | random) + d:p + d:t + p:s + p:t + s:t + d:p:t + p:s:t



$`624`

cbind(numerator, total - numerator) ~ d + p + s + t + (1 | random) + d:s + d:t + s:t



$`752`

cbind(numerator, total - numerator) ~ d + p + s + t + (1 | random) + d:s + d:t + p:s + s:t



$`880`

cbind(numerator, total - numerator) ~ d + p + s + t + (1 | random) + d:s + d:t + p:t + s:t



$`1008`

cbind(numerator, total - numerator) ~ d + p + s + t + (1 | random) + d:s + d:t + p:s + p:t + s:t



$`4720`

cbind(numerator, total - numerator) ~ d + p + s + t + (1 | random) + d:s + d:t + s:t + d:s:t



$`4848`

cbind(numerator, total - numerator) ~ d + p + s + t + (1 | random) + d:s + d:t + p:s + s:t + d:s:t



$`4976`

cbind(numerator, total - numerator) ~ d + p + s + t + (1 | random) + d:s + d:t + p:t + s:t + d:s:t



$`5104`

cbind(numerator, total - numerator) ~ d + p + s + t + (1 | random) + d:s + d:t + p:s + p:t + s:t + d:s:t



$`9200`

cbind(numerator, total - numerator) ~ d + p + s + t + (1 | random) + d:s + d:t + p:s + p:t + s:t + p:s:t



$`13296`

cbind(numerator, total - numerator) ~ d + p + s + t + (1 | random) + d:s + d:t + p:s + p:t + s:t + d:s:t + p:s:t



$`622`

cbind(numerator, total - numerator) ~ d + s + t + (1 | random) + d:s + d:t + s:t



$`4718`

cbind(numerator, total - numerator) ~ d + s + t + (1 | random) + d:s + d:t + s:t + d:s:t



$`590`

cbind(numerator, total - numerator) ~ d + s + t + (1 | random) + d:t + s:t



$`608`

cbind(numerator, total - numerator) ~ d + p + s + t + (1 | random) + d:p + d:t + s:t



$`864`

cbind(numerator, total - numerator) ~ d + p + s + t + (1 | random) + d:p + d:t + p:t + s:t



$`2912`

cbind(numerator, total - numerator) ~ d + p + s + t + (1 | random) + d:p + d:t + p:t + s:t + d:p:t



$`592`

cbind(numerator, total - numerator) ~ d + p + s + t + (1 | random) + d:t + s:t



$`848`

cbind(numerator, total - numerator) ~ d + p + s + t + (1 | random) + d:t + p:t + s:t



$`704`

cbind(numerator, total - numerator) ~ d + p + s + t + (1 | random) + d:p + d:s + p:s + s:t



$`1728`

cbind(numerator, total - numerator) ~ d + p + s + t + (1 | random) + d:p + d:s + p:s + s:t + d:p:s



$`7`

cbind(numerator, total - numerator) ~ p + s + (1 | random)



$`76`

cbind(numerator, total - numerator) ~ d + p + t + (1 | random) + d:t



$`332`

cbind(numerator, total - numerator) ~ d + p + t + (1 | random) + d:t + p:t



$`92`

cbind(numerator, total - numerator) ~ d + p + t + (1 | random) + d:p + d:t



$`348`

cbind(numerator, total - numerator) ~ d + p + t + (1 | random) + d:p + d:t + p:t



$`2396`

cbind(numerator, total - numerator) ~ d + p + t + (1 | random) + d:p + d:t + p:t + d:p:t



$`5`

cbind(numerator, total - numerator) ~ s + (1 | random)



$`184`

cbind(numerator, total - numerator) ~ d + p + s + (1 | random) + d:p + d:s + p:s



$`1208`

cbind(numerator, total - numerator) ~ d + p + s + (1 | random) + d:p + d:s + p:s + d:p:s



$`928`

cbind(numerator, total - numerator) ~ d + p + s + t + (1 | random) + d:p + p:s + p:t + s:t



$`135`

cbind(numerator, total - numerator) ~ p + s + (1 | random) + p:s



$`152`

cbind(numerator, total - numerator) ~ d + p + s + (1 | random) + d:p + p:s



$`112`

cbind(numerator, total - numerator) ~ d + p + s + t + (1 | random) + d:s + d:t



$`240`

cbind(numerator, total - numerator) ~ d + p + s + t + (1 | random) + d:s + d:t + p:s



$`368`

cbind(numerator, total - numerator) ~ d + p + s + t + (1 | random) + d:s + d:t + p:t



$`496`

cbind(numerator, total - numerator) ~ d + p + s + t + (1 | random) + d:s + d:t + p:s + p:t



$`448`

cbind(numerator, total - numerator) ~ d + p + s + t + (1 | random) + d:p + d:s + p:s + p:t



$`1472`

cbind(numerator, total - numerator) ~ d + p + s + t + (1 | random) + d:p + d:s + p:s + p:t + d:p:s



$`128`

cbind(numerator, total - numerator) ~ d + p + s + t + (1 | random) + d:p + d:s + d:t



$`256`

cbind(numerator, total - numerator) ~ d + p + s + t + (1 | random) + d:p + d:s + d:t + p:s



$`384`

cbind(numerator, total - numerator) ~ d + p + s + t + (1 | random) + d:p + d:s + d:t + p:t



$`512`

cbind(numerator, total - numerator) ~ d + p + s + t + (1 | random) + d:p + d:s + d:t + p:s + p:t



$`1280`

cbind(numerator, total - numerator) ~ d + p + s + t + (1 | random) + d:p + d:s + d:t + p:s + d:p:s



$`1536`

cbind(numerator, total - numerator) ~ d + p + s + t + (1 | random) + d:p + d:s + d:t + p:s + p:t + d:p:s



$`2432`

cbind(numerator, total - numerator) ~ d + p + s + t + (1 | random) + d:p + d:s + d:t + p:t + d:p:t



$`2560`

cbind(numerator, total - numerator) ~ d + p + s + t + (1 | random) + d:p + d:s + d:t + p:s + p:t + d:p:t



$`3584`

cbind(numerator, total - numerator) ~ d + p + s + t + (1 | random) + d:p + d:s + d:t + p:s + p:t + d:p:s + d:p:t



$`78`

cbind(numerator, total - numerator) ~ d + s + t + (1 | random) + d:t



$`80`

cbind(numerator, total - numerator) ~ d + p + s + t + (1 | random) + d:t



$`336`

cbind(numerator, total - numerator) ~ d + p + s + t + (1 | random) + d:t + p:t



$`96`

cbind(numerator, total - numerator) ~ d + p + s + t + (1 | random) + d:p + d:t



$`352`

cbind(numerator, total - numerator) ~ d + p + s + t + (1 | random) + d:p + d:t + p:t



$`2400`

cbind(numerator, total - numerator) ~ d + p + s + t + (1 | random) + d:p + d:t + p:t + d:p:t


Does this help?

Many thanks

Helen


From: Helen McCallin<mailto:helenmccallin at hotmail.com>
Sent: 25 July 2018 16:17
To: Phillip Alday<mailto:phillip.alday at mpi.nl>
Cc: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] Model average error message

Apologies, very new to this! I am currently away from my computer but as soon as I am home (within the hour) I will get those for you.

Many thanks again

Helen

> On 25 Jul 2018, at 16:09, Phillip Alday <phillip.alday at mpi.nl> wrote:
>
> (Please keep the list in CC.)
>
> The output of
>
> get.models(models,subset=delta<5)
>
> would be more interesting. Or even better:
>
> lapply(get.models(models,subset=delta<5), formula)
>
> So that we see which formulas are being labelled as identical.
>
> Phillip
>
>> On 07/25/2018 04:56 PM, Helen McCallin wrote:
>> Hi Phil
>>
>> Thank you so much for your reply. Please find the codes I am using
>> below. Is this what you mean?
>>
>> ae <- read.csv(file=file.choose())
>>
>> options(na.action="na.fail")
>>
>> global.model<-glmer(
>>
>>
>> cbind(numerator,total-numerator)~d+s+t+p+d:s:t:p+d:s:t+d:s:p+d:t:p+s:t:p+d:t+d:s+d:p+s:t+s:p+t:p+(1|random),
>>
>>     data=ae, family=binomial)
>>
>> options(max.print=1000000)
>>
>> dredge(global.model,beta=c("none"),evaluate=TRUE,rank="AICc")
>>
>> ae.model <- glmer(
>>
>>
>> cbind(numerator,total-numerator)~d+s+t+p+d:s:t:p+d:s:t+d:s:p+d:t:p+s:t:p+d:t+d:s+d:p+s:t+s:p+t:p+(1|random),
>>
>>    data=ae,family=binomial)
>>
>> models <- dredge(ae.model)
>>
>> summary(model.avg(get.models(models,subset=delta<5)))
>>
>>
>> Many thanks for any help.
>>
>> Best wishes
>>
>> Helen
>>
>> On 25 Jul 2018, at 13:50, Phillip Alday <phillip.alday at mpi.nl
>> <mailto:phillip.alday at mpi.nl>> wrote:
>>
>>> Hi Helen,
>>>
>>> model.avg() tells you which models are duplicates. What do the formulas
>>> look like for those models? Seeing the formulae may help identify what
>>> model.avg() gets stuck on.
>>>
>>> Best,
>>> Phillip
>>>
>>>> On 07/23/2018 11:33 AM, Helen McCallin wrote:
>>>> Hi
>>>>
>>>>
>>>> I am running a glmer model on a response variable with binomial
>>>> distribution and random term. My data has 3 explanatory categorical
>>>> variables and I have successfully run dredge() on them and their
>>>> interactions to get AICc values.
>>>>
>>>>
>>>> I want model averaging to provide output with coefficients and an
>>>> index of relative importance of fixed effects from those models;
>>>> within a delta constraint that I specify.I can get this using the
>>>> code below for alternative datasets but not for this dataset.
>>>>
>>>>
>>>> model.avg() produces this error message:
>>>>
>>>> Error in model.avg.default(get.models(models, subset = delta < 5)) :
>>>> models are not unique. Duplicates: '2 = 3 = 4' and '10 = 11'
>>>>
>>>>
>>>> This doesn't make sense, DREDGE does not (cannot) produce duplicate
>>>> models ? each model is a unique iteration within the full model, yet
>>>> the error message indicates that MODEL AVERAGE identified ?duplicate?
>>>> models from within DREDGE output. R fails to run MODEL AVERAGE under
>>>> these circumstances - producing no further output.
>>>>
>>>>
>>>> Has anyone else experienced similar problem (with 'not unique',
>>>> duplicate models) via MODEL AVERAGE?
>>>>
>>>>
>>>> Is there a workaround for the error that prevents me running MODEL
>>>> AVERAGE due to perceived ?duplicate? models in DREDGE?
>>>>
>>>>
>>>> Many thanks for any help anyone can provide.
>>>>
>>>>
>>>>
>>>>   [[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org
>>>> <mailto:R-sig-mixed-models at r-project.org> mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


	[[alternative HTML version deleted]]


From @lte@@ed@c2 @ending from gm@il@com  Wed Jul 25 19:18:32 2018
From: @lte@@ed@c2 @ending from gm@il@com (C. AMAL D. GLELE)
Date: Wed, 25 Jul 2018 19:18:32 +0200
Subject: [R-sig-ME] Problems-running-glmmadmb
Message-ID: <CANrzCv0rU=JW_Xwi7vFhdNqWc2DZn9WLFUOinrMD6c_fqKdxvA@mail.gmail.com>

Hi, dear all.
when running the model
"mymodel<-glmmadmb(response~var1+var2+var3,random=~1|var3,family="nbinom",data=mydata)"
I'm getting the successives following error messages:
step1:
error message: cannot change the working directory
then, I've set save.dir to "tmp
step2:
I run again mymodel with the argument save.dir set to "tmp", I get the
error message
"Couldn't find STD file
...... maxfn 500 maxph 5 noinit had statut1
then, I navigate to admbControl page and rewrite mymodel as
mymodel<-glmmadmb(response~var1+var2+var3,random=~1|var3,family="nbinom",data=mydata,
admb.opts=admbControl(impSamp=0,maxfn=500,imaxfn=500,maxph=500,noinit=FALSE,shess=FALSE),data=transmpics_ext,save.dir="tmp")
after this, I still getting STD file not found message error like
"
Error in glmmadmb(response~var1+var2+var3,random=~1|  :
  The function maximizer failed (couldn't find STD file) Troubleshooting
steps include (1) run with 'save.dir' set and inspect output files; (2)
change run parameters:

see '?admbControl'
In addition: Warning message:
running command 'C:\Windows\system32\cmd.exe /c
"C:/Users/Coliasso/Documents/R/win-library/3.4/glmmADMB/bin/windows64/glmmadmb.exe"
-maxfn 500 -maxph 500' had status 1
"
Additional informations
1) I'm using R version 3.4.3
2) I've installed glmmADMB package from a Package archive File  on PC
In advance, many thanks for your helps.
Kind regards,

	[[alternative HTML version deleted]]


From bbolker @ending from gm@il@com  Wed Jul 25 19:41:00 2018
From: bbolker @ending from gm@il@com (Ben Bolker)
Date: Wed, 25 Jul 2018 13:41:00 -0400
Subject: [R-sig-ME] Problems-running-glmmadmb
In-Reply-To: <CANrzCv0rU=JW_Xwi7vFhdNqWc2DZn9WLFUOinrMD6c_fqKdxvA@mail.gmail.com>
References: <CANrzCv0rU=JW_Xwi7vFhdNqWc2DZn9WLFUOinrMD6c_fqKdxvA@mail.gmail.com>
Message-ID: <CABghstSjuOj74D+jEXf55cG6nB4NDZrFBnC2fPNKbNAS_K=jrw@mail.gmail.com>

It's hard to know without a reproducible example: the most likely
situation is that your data are a little more complex than your model
can handle, and that the optimizer is failing (or, more mildly, it's
finding a solution but the variance-covariance matrix is not positive
definite, meaning it can't reliably compute standard errors for the
parameters).  Your two choices:

(1) provide a lot more detail about your problem and see if you can
find someone with the time and energy to reproduce the problem and see
what's going wrong
(2) try using the glmmTMB package instead; it's faster, more stable,
and more or less does all the things that glmmADMB does. For the model
you have written above, glmer.nb from the lme4 package should also
work ...
On Wed, Jul 25, 2018 at 1:18 PM C. AMAL D. GLELE <altessedac2 at gmail.com> wrote:
>
> Hi, dear all.
> when running the model
> "mymodel<-glmmadmb(response~var1+var2+var3,random=~1|var3,family="nbinom",data=mydata)"
> I'm getting the successives following error messages:
> step1:
> error message: cannot change the working directory
> then, I've set save.dir to "tmp
> step2:
> I run again mymodel with the argument save.dir set to "tmp", I get the
> error message
> "Couldn't find STD file
> ...... maxfn 500 maxph 5 noinit had statut1
> then, I navigate to admbControl page and rewrite mymodel as
> mymodel<-glmmadmb(response~var1+var2+var3,random=~1|var3,family="nbinom",data=mydata,
> admb.opts=admbControl(impSamp=0,maxfn=500,imaxfn=500,maxph=500,noinit=FALSE,shess=FALSE),data=transmpics_ext,save.dir="tmp")
> after this, I still getting STD file not found message error like
> "
> Error in glmmadmb(response~var1+var2+var3,random=~1|  :
>   The function maximizer failed (couldn't find STD file) Troubleshooting
> steps include (1) run with 'save.dir' set and inspect output files; (2)
> change run parameters:
>
> see '?admbControl'
> In addition: Warning message:
> running command 'C:\Windows\system32\cmd.exe /c
> "C:/Users/Coliasso/Documents/R/win-library/3.4/glmmADMB/bin/windows64/glmmadmb.exe"
> -maxfn 500 -maxph 500' had status 1
> "
> Additional informations
> 1) I'm using R version 3.4.3
> 2) I've installed glmmADMB package from a Package archive File  on PC
> In advance, many thanks for your helps.
> Kind regards,
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From @dl@point @ending from gm@il@com  Wed Jul 25 22:05:44 2018
From: @dl@point @ending from gm@il@com (Scott LaPoint)
Date: Wed, 25 Jul 2018 16:05:44 -0400
Subject: [R-sig-ME] 
 seeking input lme4::glmer with a gamma family: link =
 log or identity?
In-Reply-To: <9D07599F-0EDD-4162-81A3-0C27E8814E3E@glasgow.ac.uk>
References: <CA+SovpNT6Jq03oZJym=KQohFNoMjqW_FKvvTx6AjMzF+UFuQJQ@mail.gmail.com>
 <9D07599F-0EDD-4162-81A3-0C27E8814E3E@glasgow.ac.uk>
Message-ID: <CA+SovpOZ12ed56-xmSRAo83dnHk=YH+3X-0kK-VJ9BZkVh6BGg@mail.gmail.com>

Thank you Paul, I appreciate your time. And, apologies if my understanding
is often incomplete.


Hi Scott,
>
> An incomplete answer?
>
> > 1. Is a Gamma distribution best for my distance data? If so, which link
> > function is most appropriate? I explored two link functions: identity and
> > log. I have concerns and see potential issues with both (see my
> annotations
> > in the reproducible example below.
>
> I don?t know (I haven?t run your code) but I?ve always somehow managed to
> avoid gamma regression for strictly positive data by logging the response
> and fitting a model with normal errors.
>

If possible, I'd rather not transform the raw data to facilitate
interpretation of the coefficient estimates. I'm likely naive or
misunderstanding something though. Log transforming the distance data does
produce a reasonably normal distribution. The following two models have
very similar AIC, BIC, LogLik, etc. estimates and the p-values of the fixed
effects produce similar interpretations. However, the fixed effects
estimates are quite different.

gammaDist <- glmer(distance ~ CSs.lat + CSdirect + CSstart + year + age*sex
+ (1|id), data = birds, family = Gamma(link = log), nAGQ = 10, control =
glmerControl(optimizer = "bobyqa"))
summary(gammaDist)

logGausDist <- glmer(log(distance) ~ CSs.lat + CSdirect + CSstart + year +
age*sex + (1|id), data = birds, family = gaussian(link = log), nAGQ = 10,
control = glmerControl(optimizer = "bobyqa"))
summary(logGausDist)

The interpretation from these two models are mostly the same: only starting
latitude is a marginally significant predictor of bird migration distance.
Correct?


> 2.  If the log link is the best or most appropriate to use, then the
> > summary(mDist) produces a sd of the random effect = 0 with the bobyqa
> > optimizer. Switching to Nelder_Mead gives a reasonable sd, but throws a
> > convergence warning.
>
> (For clarity, I assume that by "sd of the random effect? you mean the
> square root of the variance parameter that gauges residual inter-bird
> variation in mean distance and not the SD of the estimate of that
> parameter, which anyway isn?t output by glmer.)
>
> Why is a random effect variance estimate of zero implausible? I would
> trust a converged estimate over a non-converged estimate, regardless of
> whether the estimate is zero. Also? you could compare the log-likelihoods
> using logLik() ?  you?d expect the converged fit to have a higher LL. For
> more general troubleshooting of convergence warnings:
> http://rpubs.com/bbolker/lme4trouble1


Yes, I believe your assumption is correct. In case I am wrong, I'm
referring to these estimates from the summary(model) output:
Random effects:
 Groups   Name        Variance Std.Dev.
 id       (Intercept) 0.00000  0.0000
 Residual             0.02879  0.1697
Number of obs: 137, groups:  id, 79

The reason I said that a Std.Dev. = 0 is implausible is because the
ecologist in me says that there is no way that individual birds do not vary
between each other (or even within for birds with multiple migration route
data). Am I misunderstanding the meaning of the Std.Dev here?


> Another quick check I often do is to fit the non-converged model with
> glmmTMB (which appears to be more robust than lme4), and compare
> likelihoods and estimates with lme4.
>
> A quick and dirty model fit assessment is to simulate from the fitted
> model (which is as easy as simulate(my.fit)), and see if the simulated
> responses look more or less like the real responses.
>
> Good luck,
> Paul
>
>

	[[alternative HTML version deleted]]


From @m@l@d@hounto @ending from gm@il@com  Wed Jul 25 19:53:10 2018
From: @m@l@d@hounto @ending from gm@il@com (Amal Dahounto)
Date: Wed, 25 Jul 2018 19:53:10 +0200
Subject: [R-sig-ME] Problems-running-glmmadmb
In-Reply-To: <CABghstSjuOj74D+jEXf55cG6nB4NDZrFBnC2fPNKbNAS_K=jrw@mail.gmail.com>
References: <CANrzCv0rU=JW_Xwi7vFhdNqWc2DZn9WLFUOinrMD6c_fqKdxvA@mail.gmail.com>
 <CABghstSjuOj74D+jEXf55cG6nB4NDZrFBnC2fPNKbNAS_K=jrw@mail.gmail.com>
Message-ID: <CA+DVwCvk1pbM5KOSsrsgqZ5tFBmuw6Xb92RjSUiMFSc1gWjrrw@mail.gmail.com>

Dear Ben,
many thanks for your reply.
Kind regards,

2018-07-25 19:41 GMT+02:00 Ben Bolker <bbolker at gmail.com>:

> It's hard to know without a reproducible example: the most likely
> situation is that your data are a little more complex than your model
> can handle, and that the optimizer is failing (or, more mildly, it's
> finding a solution but the variance-covariance matrix is not positive
> definite, meaning it can't reliably compute standard errors for the
> parameters).  Your two choices:
>
> (1) provide a lot more detail about your problem and see if you can
> find someone with the time and energy to reproduce the problem and see
> what's going wrong
> (2) try using the glmmTMB package instead; it's faster, more stable,
> and more or less does all the things that glmmADMB does. For the model
> you have written above, glmer.nb from the lme4 package should also
> work ...
> On Wed, Jul 25, 2018 at 1:18 PM C. AMAL D. GLELE <altessedac2 at gmail.com>
> wrote:
> >
> > Hi, dear all.
> > when running the model
> > "mymodel<-glmmadmb(response~var1+var2+var3,random=~1|var3,
> family="nbinom",data=mydata)"
> > I'm getting the successives following error messages:
> > step1:
> > error message: cannot change the working directory
> > then, I've set save.dir to "tmp
> > step2:
> > I run again mymodel with the argument save.dir set to "tmp", I get the
> > error message
> > "Couldn't find STD file
> > ...... maxfn 500 maxph 5 noinit had statut1
> > then, I navigate to admbControl page and rewrite mymodel as
> > mymodel<-glmmadmb(response~var1+var2+var3,random=~1|var3,
> family="nbinom",data=mydata,
> > admb.opts=admbControl(impSamp=0,maxfn=500,imaxfn=500,maxph=
> 500,noinit=FALSE,shess=FALSE),data=transmpics_ext,save.dir="tmp")
> > after this, I still getting STD file not found message error like
> > "
> > Error in glmmadmb(response~var1+var2+var3,random=~1|  :
> >   The function maximizer failed (couldn't find STD file) Troubleshooting
> > steps include (1) run with 'save.dir' set and inspect output files; (2)
> > change run parameters:
> >
> > see '?admbControl'
> > In addition: Warning message:
> > running command 'C:\Windows\system32\cmd.exe /c
> > "C:/Users/Coliasso/Documents/R/win-library/3.4/glmmADMB/
> bin/windows64/glmmadmb.exe"
> > -maxfn 500 -maxph 500' had status 1
> > "
> > Additional informations
> > 1) I'm using R version 3.4.3
> > 2) I've installed glmmADMB package from a Package archive File  on PC
> > In advance, many thanks for your helps.
> > Kind regards,
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 


Amal DAHOUNTO GLELE C.


*Statistician, Data ManagerElectronicDataCapture(EDC) Systems Manager*Institut
de Recherche pour le D?veloppement (IRD)
MIVEGEC (UMR IRD 224 - CNRS 5290)
IRD-CREC (Cotonou, BENIN)
IRD-IRSS (Bobo, BURKINA FASO)

*T?l:(+229) 97 33 83 44 ; (+226) 60 96 23 74*

*Skype: coliasso*

	[[alternative HTML version deleted]]


From thierry@onkelinx @ending from inbo@be  Thu Jul 26 00:29:15 2018
From: thierry@onkelinx @ending from inbo@be (Thierry Onkelinx)
Date: Thu, 26 Jul 2018 00:29:15 +0200
Subject: [R-sig-ME] 
 seeking input lme4::glmer with a gamma family: link =
 log or identity?
In-Reply-To: <CA+SovpOZ12ed56-xmSRAo83dnHk=YH+3X-0kK-VJ9BZkVh6BGg@mail.gmail.com>
References: <CA+SovpNT6Jq03oZJym=KQohFNoMjqW_FKvvTx6AjMzF+UFuQJQ@mail.gmail.com>
 <9D07599F-0EDD-4162-81A3-0C27E8814E3E@glasgow.ac.uk>
 <CA+SovpOZ12ed56-xmSRAo83dnHk=YH+3X-0kK-VJ9BZkVh6BGg@mail.gmail.com>
Message-ID: <CAJuCY5y2meu9wn9xVtEKhx0iMJ0Ln5u=Zz5HrG9bB4071w2Ckw@mail.gmail.com>

Dear Scott,

Random effects model only information which is not captured by the fixed
effects. And the random effects are subject to shrinkage. Combine this with
a large number of fixed effect parameters, a small data set and unbalanced
repeated measurements. Then zero variance random effects and convergence
issues don't come as a surprise.

?Bottom line: ?your model is too complex for the data. You'll need to drop
variables or make more observations (often not feasible, I know). Using a
different transformation/link/distribution won't solve any of these issues.

Best regards,


ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>

2018-07-25 22:05 GMT+02:00 Scott LaPoint <sdlapoint at gmail.com>:

> Thank you Paul, I appreciate your time. And, apologies if my understanding
> is often incomplete.
>
>
> Hi Scott,
> >
> > An incomplete answer?
> >
> > > 1. Is a Gamma distribution best for my distance data? If so, which link
> > > function is most appropriate? I explored two link functions: identity
> and
> > > log. I have concerns and see potential issues with both (see my
> > annotations
> > > in the reproducible example below.
> >
> > I don?t know (I haven?t run your code) but I?ve always somehow managed to
> > avoid gamma regression for strictly positive data by logging the response
> > and fitting a model with normal errors.
> >
>
> If possible, I'd rather not transform the raw data to facilitate
> interpretation of the coefficient estimates. I'm likely naive or
> misunderstanding something though. Log transforming the distance data does
> produce a reasonably normal distribution. The following two models have
> very similar AIC, BIC, LogLik, etc. estimates and the p-values of the fixed
> effects produce similar interpretations. However, the fixed effects
> estimates are quite different.
>
> gammaDist <- glmer(distance ~ CSs.lat + CSdirect + CSstart + year + age*sex
> + (1|id), data = birds, family = Gamma(link = log), nAGQ = 10, control =
> glmerControl(optimizer = "bobyqa"))
> summary(gammaDist)
>
> logGausDist <- glmer(log(distance) ~ CSs.lat + CSdirect + CSstart + year +
> age*sex + (1|id), data = birds, family = gaussian(link = log), nAGQ = 10,
> control = glmerControl(optimizer = "bobyqa"))
> summary(logGausDist)
>
> The interpretation from these two models are mostly the same: only starting
> latitude is a marginally significant predictor of bird migration distance.
> Correct?
>
>
> > 2.  If the log link is the best or most appropriate to use, then the
> > > summary(mDist) produces a sd of the random effect = 0 with the bobyqa
> > > optimizer. Switching to Nelder_Mead gives a reasonable sd, but throws a
> > > convergence warning.
> >
> > (For clarity, I assume that by "sd of the random effect? you mean the
> > square root of the variance parameter that gauges residual inter-bird
> > variation in mean distance and not the SD of the estimate of that
> > parameter, which anyway isn?t output by glmer.)
> >
> > Why is a random effect variance estimate of zero implausible? I would
> > trust a converged estimate over a non-converged estimate, regardless of
> > whether the estimate is zero. Also? you could compare the log-likelihoods
> > using logLik() ?  you?d expect the converged fit to have a higher LL. For
> > more general troubleshooting of convergence warnings:
> > http://rpubs.com/bbolker/lme4trouble1
>
>
> Yes, I believe your assumption is correct. In case I am wrong, I'm
> referring to these estimates from the summary(model) output:
> Random effects:
>  Groups   Name        Variance Std.Dev.
>  id       (Intercept) 0.00000  0.0000
>  Residual             0.02879  0.1697
> Number of obs: 137, groups:  id, 79
>
> The reason I said that a Std.Dev. = 0 is implausible is because the
> ecologist in me says that there is no way that individual birds do not vary
> between each other (or even within for birds with multiple migration route
> data). Am I misunderstanding the meaning of the Std.Dev here?
>
>
> > Another quick check I often do is to fit the non-converged model with
> > glmmTMB (which appears to be more robust than lme4), and compare
> > likelihoods and estimates with lme4.
> >
> > A quick and dirty model fit assessment is to simulate from the fitted
> > model (which is as easy as simulate(my.fit)), and see if the simulated
> > responses look more or less like the real responses.
> >
> > Good luck,
> > Paul
> >
> >
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From @lte@@ed@c2 @ending from gm@il@com  Thu Jul 26 15:32:53 2018
From: @lte@@ed@c2 @ending from gm@il@com (C. AMAL D. GLELE)
Date: Thu, 26 Jul 2018 15:32:53 +0200
Subject: [R-sig-ME] Complete-separation-problem-resolution
Message-ID: <CANrzCv0_dAcwZQbJcdTAdTd-JmgFZpP+=MdG94HDJ6END4APrw@mail.gmail.com>

Hi, dear all.
Please, How do I solve  complete separation problem in binomial model built
with glmmTMB or glmer (or with any other mixed model builder)?
In advance, thanks foe your replies.
Kind regards,

	[[alternative HTML version deleted]]


From jdpo223 @ending from g@uky@edu  Thu Jul 26 15:43:05 2018
From: jdpo223 @ending from g@uky@edu (John Poe)
Date: Thu, 26 Jul 2018 09:43:05 -0400
Subject: [R-sig-ME] Complete-separation-problem-resolution
In-Reply-To: <CANrzCv0_dAcwZQbJcdTAdTd-JmgFZpP+=MdG94HDJ6END4APrw@mail.gmail.com>
References: <CANrzCv0_dAcwZQbJcdTAdTd-JmgFZpP+=MdG94HDJ6END4APrw@mail.gmail.com>
Message-ID: <CAFW8ByqAQNUbMfyp=4XPsk=CrcogY__h7_fKGj7y7B87+0VidA@mail.gmail.com>

The short answer is a bayesian hierarchical model.  See this paper from
political analysis

http://www.carlislerainey.com/papers/separation.pdf

On Thu, Jul 26, 2018, 9:33 AM C. AMAL D. GLELE <altessedac2 at gmail.com>
wrote:

> Hi, dear all.
> Please, How do I solve  complete separation problem in binomial model built
> with glmmTMB or glmer (or with any other mixed model builder)?
> In advance, thanks foe your replies.
> Kind regards,
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From bbolker @ending from gm@il@com  Thu Jul 26 15:59:48 2018
From: bbolker @ending from gm@il@com (Ben Bolker)
Date: Thu, 26 Jul 2018 09:59:48 -0400
Subject: [R-sig-ME] Complete-separation-problem-resolution
In-Reply-To: <CAFW8ByqAQNUbMfyp=4XPsk=CrcogY__h7_fKGj7y7B87+0VidA@mail.gmail.com>
References: <CANrzCv0_dAcwZQbJcdTAdTd-JmgFZpP+=MdG94HDJ6END4APrw@mail.gmail.com>
 <CAFW8ByqAQNUbMfyp=4XPsk=CrcogY__h7_fKGj7y7B87+0VidA@mail.gmail.com>
Message-ID: <8ec9427d-b94f-2e3f-46f4-e4138e1ca42d@gmail.com>


  See also

 http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#penalizationhandling-complete-separation

http://bbolker.github.io/mixedmodels-misc/ecostats_chap.html#digression-complete-separation

On 2018-07-26 09:43 AM, John Poe wrote:
> The short answer is a bayesian hierarchical model.  See this paper from
> political analysis
> 
> http://www.carlislerainey.com/papers/separation.pdf
> 
> On Thu, Jul 26, 2018, 9:33 AM C. AMAL D. GLELE <altessedac2 at gmail.com>
> wrote:
> 
>> Hi, dear all.
>> Please, How do I solve  complete separation problem in binomial model built
>> with glmmTMB or glmer (or with any other mixed model builder)?
>> In advance, thanks foe your replies.
>> Kind regards,
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From udit@@b@n@@l17 @ending from imperi@l@@c@uk  Thu Jul 26 18:57:30 2018
From: udit@@b@n@@l17 @ending from imperi@l@@c@uk (Bansal, Udita)
Date: Thu, 26 Jul 2018 16:57:30 +0000
Subject: [R-sig-ME] multiple errors when using glmmADMB
Message-ID: <8F918DAA-A9DB-47FD-AC0E-4C090E0B4E43@contoso.com>

Hi all,

I was trying to use the glmmADMB package but ran into some errors. I?ve
noticed that other people have run into similar errors but there doesn?t
seem to be a solution online. It would be great help if anyone could
provide any insights on it.

I am using it for running a zero-inflated mixed-effects binomial model.
The errors are as follows:

Parameters were estimated, but standard errors were not: the most likely
problem is that the curvature at MLE was zero or negative
Error in glmmadmb(breeding.success ~ laying.date.julian.day.zscale +
tmean.zscale +  :
  The function maximizer failed (couldn't find parameter file)
Troubleshooting steps include (1) run with 'save.dir' set and inspect
output files; (2) change run parameters: see '?admbControl';(3) re-run
with debug=TRUE for more information on failure mode
In addition: Warning messages:
1: In glmmadmb(breeding.success ~ laying.date.julian.day.zscale +
tmean.zscale +  :
  non-integer response values in discrete family
2: running command './glmmadmb -maxfn 500 -maxph 5 -noinit -shess' had
status 1

Any kind of help will be greatly appreciated.

Bests
Udita Bansal


	[[alternative HTML version deleted]]


From j@me@@u@nhoro @ending from gm@il@com  Thu Jul 26 15:47:04 2018
From: j@me@@u@nhoro @ending from gm@il@com (James Uanhoro)
Date: Thu, 26 Jul 2018 09:47:04 -0400
Subject: [R-sig-ME] Complete-separation-problem-resolution
In-Reply-To: <CANrzCv0_dAcwZQbJcdTAdTd-JmgFZpP+=MdG94HDJ6END4APrw@mail.gmail.com>
References: <CANrzCv0_dAcwZQbJcdTAdTd-JmgFZpP+=MdG94HDJ6END4APrw@mail.gmail.com>
Message-ID: <CAE8tRV_4ZE=y7Lh7QFq1Qmr5KGf-rGqSy9B1xbDw_zt4MR0MNA@mail.gmail.com>

Check out the blme package. You can specify priors for fixed effects; this
is one way of handling the complete separation problem.
For choice of prior, Greenland and Mansournia (
https://www.ncbi.nlm.nih.gov/pubmed/26011599) suggest using log-F(1, 1)
over other common suggestions like normal, or Jeffrey's or t-priors. But
blme provides a quick solution that limits you to normal or t.

On Thu, 26 Jul 2018 at 09:33, C. AMAL D. GLELE <altessedac2 at gmail.com>
wrote:

> Hi, dear all.
> Please, How do I solve  complete separation problem in binomial model built
> with glmmTMB or glmer (or with any other mixed model builder)?
> In advance, thanks foe your replies.
> Kind regards,
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From bbolker @ending from gm@il@com  Thu Jul 26 20:40:28 2018
From: bbolker @ending from gm@il@com (Ben Bolker)
Date: Thu, 26 Jul 2018 14:40:28 -0400
Subject: [R-sig-ME] multiple errors when using glmmADMB
In-Reply-To: <8F918DAA-A9DB-47FD-AC0E-4C090E0B4E43@contoso.com>
References: <8F918DAA-A9DB-47FD-AC0E-4C090E0B4E43@contoso.com>
Message-ID: <cfc67200-048e-5485-c6b6-6899f1b56d22@gmail.com>


  The first thing that pops  out is the "non-integer response values in
discrete family" warning.  How are you measuring breeding success?  Can
you show us your whole glmmadmb() statement, and maybe a summary() of
the relevant columns of your data set?

   I'll also make the now-blanket statement that you may have better
luck moving forward with glmmTMB.

  cheers
    Ben Bolker

On 2018-07-26 12:57 PM, Bansal, Udita wrote:
> Hi all,
> 
> I was trying to use the glmmADMB package but ran into some errors. I?ve
> noticed that other people have run into similar errors but there doesn?t
> seem to be a solution online. It would be great help if anyone could
> provide any insights on it.
> 
> I am using it for running a zero-inflated mixed-effects binomial model.
> The errors are as follows:
> 
> Parameters were estimated, but standard errors were not: the most likely
> problem is that the curvature at MLE was zero or negative
> Error in glmmadmb(breeding.success ~ laying.date.julian.day.zscale +
> tmean.zscale +  :
>   The function maximizer failed (couldn't find parameter file)
> Troubleshooting steps include (1) run with 'save.dir' set and inspect
> output files; (2) change run parameters: see '?admbControl';(3) re-run
> with debug=TRUE for more information on failure mode
> In addition: Warning messages:
> 1: In glmmadmb(breeding.success ~ laying.date.julian.day.zscale +
> tmean.zscale +  :
>   non-integer response values in discrete family
> 2: running command './glmmadmb -maxfn 500 -maxph 5 -noinit -shess' had
> status 1
> 
> Any kind of help will be greatly appreciated.
> 
> Bests
> Udita Bansal
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From @dl@point @ending from gm@il@com  Thu Jul 26 22:00:40 2018
From: @dl@point @ending from gm@il@com (Scott LaPoint)
Date: Thu, 26 Jul 2018 16:00:40 -0400
Subject: [R-sig-ME] 
 seeking input lme4::glmer with a gamma family: link =
 log or identity?
In-Reply-To: <CAJuCY5y2meu9wn9xVtEKhx0iMJ0Ln5u=Zz5HrG9bB4071w2Ckw@mail.gmail.com>
References: <CA+SovpNT6Jq03oZJym=KQohFNoMjqW_FKvvTx6AjMzF+UFuQJQ@mail.gmail.com>
 <9D07599F-0EDD-4162-81A3-0C27E8814E3E@glasgow.ac.uk>
 <CA+SovpOZ12ed56-xmSRAo83dnHk=YH+3X-0kK-VJ9BZkVh6BGg@mail.gmail.com>
 <CAJuCY5y2meu9wn9xVtEKhx0iMJ0Ln5u=Zz5HrG9bB4071w2Ckw@mail.gmail.com>
Message-ID: <CA+SovpP2LSZaS=wvaA6PeLBUkt4sY6SKC-6j=rrUoi+sMoyGUQ@mail.gmail.com>

Thank you Thierry,

The model below does converge and does not produce any warning messages,
but the random effect variance and std dev are both = 0:

mDist <- glmer(distance ~ CSs.lat + CSdirect + CSstart + year + age*sex +
(1|id), data = birds, family = Gamma(link = log), nAGQ = 10, control =
glmerControl(optimizer = "bobyqa"))

As I understand it, and please correct me if I'm wrong, it is possible (but
perhaps unlikely) to have these values = 0. If so, I believe this implies
that either the random effect variable is truly not variable or that the
variance of the random effect is being captured by the other fixed effects.
In my case, that might imply that any variation between birds is captured
by year, age, or sex. So, assuming that logic is correct (and it may not
be), then the following model would most likely show a variance and std dev
> 0:

mDist <- glmer(distance ~ CSs.lat + (1|id), data = birds,  family =
Gamma(link = log), nAGQ = 10, control = glmerControl(optimizer = "bobyqa"))

But, it does not, and still shows a variance and std dev of 0. A quick
boxplot of distance grouped by bird id shows both substantial variation
across birds and at times within birds.

Perhaps I'm still missing something? Is 137 observations really too few for
a model with 1 fixed and 1 random effect variable?

Apologies for my ignorance. I do appreciate the guidance while I learn to
swim in the GLMM sea.

scott

Scott LaPoint
Postdoctoral Researcher, Lamont-Doherty Earth Observatory, Columbia
University
Associate Scientist, Max-Planck Institute for Ornithology
skype: scott_lapoint
twitter @sdlapoint
scottlapoint.weebly.com

On Wed, Jul 25, 2018 at 6:29 PM, Thierry Onkelinx <thierry.onkelinx at inbo.be>
wrote:

> Dear Scott,
>
> Random effects model only information which is not captured by the fixed
> effects. And the random effects are subject to shrinkage. Combine this with
> a large number of fixed effect parameters, a small data set and unbalanced
> repeated measurements. Then zero variance random effects and convergence
> issues don't come as a surprise.
>
> ?Bottom line: ?your model is too complex for the data. You'll need to drop
> variables or make more observations (often not feasible, I know). Using a
> different transformation/link/distribution won't solve any of these
> issues.
>
> Best regards,
>
>
> ir. Thierry Onkelinx
> Statisticus / Statistician
>
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
> FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Havenlaan 88
> <https://maps.google.com/?q=Havenlaan+88&entry=gmail&source=g> bus 73,
> 1000 Brussel
> www.inbo.be
>
> ////////////////////////////////////////////////////////////
> ///////////////////////////////
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
> ////////////////////////////////////////////////////////////
> ///////////////////////////////
>
> <https://www.inbo.be>
>
> 2018-07-25 22:05 GMT+02:00 Scott LaPoint <sdlapoint at gmail.com>:
>
>> Thank you Paul, I appreciate your time. And, apologies if my understanding
>> is often incomplete.
>>
>>
>> Hi Scott,
>> >
>> > An incomplete answer?
>> >
>> > > 1. Is a Gamma distribution best for my distance data? If so, which
>> link
>> > > function is most appropriate? I explored two link functions: identity
>> and
>> > > log. I have concerns and see potential issues with both (see my
>> > annotations
>> > > in the reproducible example below.
>> >
>> > I don?t know (I haven?t run your code) but I?ve always somehow managed
>> to
>> > avoid gamma regression for strictly positive data by logging the
>> response
>> > and fitting a model with normal errors.
>> >
>>
>> If possible, I'd rather not transform the raw data to facilitate
>> interpretation of the coefficient estimates. I'm likely naive or
>> misunderstanding something though. Log transforming the distance data does
>> produce a reasonably normal distribution. The following two models have
>> very similar AIC, BIC, LogLik, etc. estimates and the p-values of the
>> fixed
>> effects produce similar interpretations. However, the fixed effects
>> estimates are quite different.
>>
>> gammaDist <- glmer(distance ~ CSs.lat + CSdirect + CSstart + year +
>> age*sex
>> + (1|id), data = birds, family = Gamma(link = log), nAGQ = 10, control =
>> glmerControl(optimizer = "bobyqa"))
>> summary(gammaDist)
>>
>> logGausDist <- glmer(log(distance) ~ CSs.lat + CSdirect + CSstart + year +
>> age*sex + (1|id), data = birds, family = gaussian(link = log), nAGQ = 10,
>> control = glmerControl(optimizer = "bobyqa"))
>> summary(logGausDist)
>>
>> The interpretation from these two models are mostly the same: only
>> starting
>> latitude is a marginally significant predictor of bird migration distance.
>> Correct?
>>
>>
>> > 2.  If the log link is the best or most appropriate to use, then the
>> > > summary(mDist) produces a sd of the random effect = 0 with the bobyqa
>> > > optimizer. Switching to Nelder_Mead gives a reasonable sd, but throws
>> a
>> > > convergence warning.
>> >
>> > (For clarity, I assume that by "sd of the random effect? you mean the
>> > square root of the variance parameter that gauges residual inter-bird
>> > variation in mean distance and not the SD of the estimate of that
>> > parameter, which anyway isn?t output by glmer.)
>> >
>> > Why is a random effect variance estimate of zero implausible? I would
>> > trust a converged estimate over a non-converged estimate, regardless of
>> > whether the estimate is zero. Also? you could compare the
>> log-likelihoods
>> > using logLik() ?  you?d expect the converged fit to have a higher LL.
>> For
>> > more general troubleshooting of convergence warnings:
>> > http://rpubs.com/bbolker/lme4trouble1
>>
>>
>> Yes, I believe your assumption is correct. In case I am wrong, I'm
>> referring to these estimates from the summary(model) output:
>> Random effects:
>>  Groups   Name        Variance Std.Dev.
>>  id       (Intercept) 0.00000  0.0000
>>  Residual             0.02879  0.1697
>> Number of obs: 137, groups:  id, 79
>>
>> The reason I said that a Std.Dev. = 0 is implausible is because the
>> ecologist in me says that there is no way that individual birds do not
>> vary
>> between each other (or even within for birds with multiple migration route
>> data). Am I misunderstanding the meaning of the Std.Dev here?
>>
>>
>> > Another quick check I often do is to fit the non-converged model with
>> > glmmTMB (which appears to be more robust than lme4), and compare
>> > likelihoods and estimates with lme4.
>> >
>> > A quick and dirty model fit assessment is to simulate from the fitted
>> > model (which is as easy as simulate(my.fit)), and see if the simulated
>> > responses look more or less like the real responses.
>> >
>> > Good luck,
>> > Paul
>> >
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>

	[[alternative HTML version deleted]]


From udit@@b@n@@l17 @ending from imperi@l@@c@uk  Thu Jul 26 22:03:12 2018
From: udit@@b@n@@l17 @ending from imperi@l@@c@uk (Bansal, Udita)
Date: Thu, 26 Jul 2018 20:03:12 +0000
Subject: [R-sig-ME] multiple errors when using glmmADMB
In-Reply-To: <cfc67200-048e-5485-c6b6-6899f1b56d22@gmail.com>
References: <8F918DAA-A9DB-47FD-AC0E-4C090E0B4E43@contoso.com>
 <cfc67200-048e-5485-c6b6-6899f1b56d22@gmail.com>
Message-ID: <AE9791A8-A8AA-49A9-9164-ECB0C0E6019D@ic.ac.uk>

I am measuring breeding success as number of chicks produced out of number of eggs laid. So, the values range from 0 to 1 including decimal values. Although, that was just a warning. Should I be too concerned about that?

My model statement is as follows: 
m_admb <- glmmadmb( breeding.success ~ laying.date.julian.day.zscale + tmean.zscale + (1|YEAR) , 
                    data = hungary_breeding, zeroInflation = TRUE, family = "nbinom", link = "logit")

Summary for relevant columns of my data: 

YEAR       No.of.chicks          Clutch.size        laying_date             tmean            prec       
 1988:16   Min.   :0.000   Min.   :2.000   Min.   :1988-04-22   Min.   : 3.45   Min.   : 0.000  
 1989:25   1st Qu.:0.000   1st Qu.:3.000   1st Qu.:1990-05-07   1st Qu.:11.35   1st Qu.: 0.000  
 1990:45   Median :0.000   Median :3.000   Median :1991-05-09   Median :15.12   Median : 0.000  
 1991:65   Mean   :1.021   Mean   :2.946   Mean   :1991-05-24   Mean   :14.62   Mean   : 2.285  
 1992:46   3rd Qu.:3.000   3rd Qu.:3.000   3rd Qu.:1992-05-15   3rd Qu.:17.95   3rd Qu.: 1.050  
 1993:24   Max.   :3.000   Max.   :3.000   Max.   :1994-06-16   Max.   :27.05   Max.   :55.200  
 1994:19                                                                                        
 breeding.success clutch.volume   laying.date.julian.day   tmean.zscale.V1      prec.zscale.V1   
 Min.   :0.0000   Min.   :15.82   Min.   : 82.0          Min.   :-2.5607265   Min.   :-0.559014  
 1st Qu.:0.0000   1st Qu.:24.60   1st Qu.:115.0          1st Qu.:-0.7638887   1st Qu.:-0.559014  
 Median :0.0000   Median :25.89   Median :129.0          Median : 0.0947269   Median :-0.559014  
 Mean   :0.3438   Mean   :25.52   Mean   :132.3          Mean   :-0.0190444   Mean   : 0.006583  
 3rd Qu.:1.0000   3rd Qu.:27.06   3rd Qu.:148.2          3rd Qu.: 0.7372670   3rd Qu.: 0.209975  
 Max.   :1.0000   Max.   :29.83   Max.   :186.0          Max.   : 2.8070422   Max.   : 3.762186  
                                                                                                 
 laying.date.julian.day.zscale.V1
 Min.   :-2.2850626              
 1st Qu.:-0.7846733              
 Median :-0.1481445              
 Mean   : 0.0000000              
 3rd Qu.: 0.7270826              
 Max.   : 2.4434370              

I will try glmmTMB as well now.

Thanks
Udita

On 26/07/18, 7:41 PM, "R-sig-mixed-models on behalf of Ben Bolker" <r-sig-mixed-models-bounces at r-project.org on behalf of bbolker at gmail.com> wrote:

    
      The first thing that pops  out is the "non-integer response values in
    discrete family" warning.  How are you measuring breeding success?  Can
    you show us your whole glmmadmb() statement, and maybe a summary() of
    the relevant columns of your data set?
    
       I'll also make the now-blanket statement that you may have better
    luck moving forward with glmmTMB.
    
      cheers
        Ben Bolker
    
    On 2018-07-26 12:57 PM, Bansal, Udita wrote:
    > Hi all,
    > 
    > I was trying to use the glmmADMB package but ran into some errors. I?ve
    > noticed that other people have run into similar errors but there doesn?t
    > seem to be a solution online. It would be great help if anyone could
    > provide any insights on it.
    > 
    > I am using it for running a zero-inflated mixed-effects binomial model.
    > The errors are as follows:
    > 
    > Parameters were estimated, but standard errors were not: the most likely
    > problem is that the curvature at MLE was zero or negative
    > Error in glmmadmb(breeding.success ~ laying.date.julian.day.zscale +
    > tmean.zscale +  :
    >   The function maximizer failed (couldn't find parameter file)
    > Troubleshooting steps include (1) run with 'save.dir' set and inspect
    > output files; (2) change run parameters: see '?admbControl';(3) re-run
    > with debug=TRUE for more information on failure mode
    > In addition: Warning messages:
    > 1: In glmmadmb(breeding.success ~ laying.date.julian.day.zscale +
    > tmean.zscale +  :
    >   non-integer response values in discrete family
    > 2: running command './glmmadmb -maxfn 500 -maxph 5 -noinit -shess' had
    > status 1
    > 
    > Any kind of help will be greatly appreciated.
    > 
    > Bests
    > Udita Bansal
    > 
    > 
    > 	[[alternative HTML version deleted]]
    > 
    > _______________________________________________
    > R-sig-mixed-models at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
    >
    
    _______________________________________________
    R-sig-mixed-models at r-project.org mailing list
    https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
    


From lpennington @ending from ucmerced@edu  Thu Jul 26 22:13:56 2018
From: lpennington @ending from ucmerced@edu (Lillie Pennington)
Date: Thu, 26 Jul 2018 20:13:56 +0000
Subject: [R-sig-ME] glmmTMB zero-inflated Poisson significant effects?
Message-ID: <SN6PR06MB449466B7CD7AE5F2EEB76EF0C22B0@SN6PR06MB4494.namprd06.prod.outlook.com>

Hello,


I'm attempting to determine significant effects for a model I am running using the glmmTMB package. I've been setting up the model and then testing effects by dropping terms from the model, and then using aov to compare the full model to the model with a term dropped. I'm wondering if there is a way to separate the count portion of the model from the zero inflated portion so I can compare them separately? That is, compare the full conditional model to the conditional model with a term dropped, and then compare the full zero-inflated model to the zero-inflated model with a term dropped.


Thanks!


Lillie Pennington
PhD Student, UC Merced
Environmental Systems


	[[alternative HTML version deleted]]


From bl@zej@mrozin@ki @ending from gm@il@com  Fri Jul 27 10:08:22 2018
From: bl@zej@mrozin@ki @ending from gm@il@com (Blazej Mrozinski)
Date: Fri, 27 Jul 2018 10:08:22 +0200
Subject: [R-sig-ME] Effect sizes (eta sqrt) for fixed effects anova table in
 lmer object - seeking help
Message-ID: <CANAWZx96DS4XRFGNQvThbiHihQstcdxWyFtpn6WCwX3PA4X1Pw@mail.gmail.com>

Greeting everyone,

Please note I posted this question to SO
https://stats.stackexchange.com/questions/358927/compute-partial-eta2-for-all-fixed-effects-anovas-from-a-lme4-model
but since it's been unanswered and I **honestly** don't know what to do, I
decided to re-post it here.

To make a longer story short (a full reproducible example is posted at SO
and I didn't want to use more space then necessary here):

I used lmer() (actually afex::mixed()) to fit a model for a full factorial
repeated measures experimental data. I'm not interested in random effects
per se - i defined a maximum justified by design structure of random
effects only to control more error variance and my only interest are the
fixed effects - namely Fs from the anova table and corresponding marginal
means.

I've been asked by a reviewer to add effects sizes (etas or omegas) for
each F or t test reported: anova F's from anova(lmer()) and F's and t's
from emmeans calls (pairs and joint_tests) used to explain some higher
order interactions.

I don't feel in a position to argue with the reviewer so I'd like to
provide what she / he wants without any discussion.

My question here is twofold:

   - If there is any citable way to produce eta2 for anovas F tests how can
   I do it? An R package / function / script would be great help.
   - If there is no way computing it - what paper can I cite when answering
   the reviewer why I insisted on skipping effect sizes.

I am aware that my question may sound basic to most of you but i'm really
lost here and would use any detailed help that will allow to produce the
numbers i'm being asked.

If more information is needed please ask here or at SO, time is of the
essence and this group is probably the last place I know of that might help
me.

Thanks for reading this and even a bigger thanks for taking the time to
help me out.
All the best,

Blazej Mrozinski

	[[alternative HTML version deleted]]


From thierry@onkelinx @ending from inbo@be  Fri Jul 27 10:19:14 2018
From: thierry@onkelinx @ending from inbo@be (Thierry Onkelinx)
Date: Fri, 27 Jul 2018 10:19:14 +0200
Subject: [R-sig-ME] 
 seeking input lme4::glmer with a gamma family: link =
 log or identity?
In-Reply-To: <CA+SovpP2LSZaS=wvaA6PeLBUkt4sY6SKC-6j=rrUoi+sMoyGUQ@mail.gmail.com>
References: <CA+SovpNT6Jq03oZJym=KQohFNoMjqW_FKvvTx6AjMzF+UFuQJQ@mail.gmail.com>
 <9D07599F-0EDD-4162-81A3-0C27E8814E3E@glasgow.ac.uk>
 <CA+SovpOZ12ed56-xmSRAo83dnHk=YH+3X-0kK-VJ9BZkVh6BGg@mail.gmail.com>
 <CAJuCY5y2meu9wn9xVtEKhx0iMJ0Ln5u=Zz5HrG9bB4071w2Ckw@mail.gmail.com>
 <CA+SovpP2LSZaS=wvaA6PeLBUkt4sY6SKC-6j=rrUoi+sMoyGUQ@mail.gmail.com>
Message-ID: <CAJuCY5yVDyPM+_2VLxkh-Z+O_OezLscsDntco3uRJdca-KY4CA@mail.gmail.com>

Dear Scott,

If you run the model with Laplace approximation instead of Adaptive
Gauss-Hermite Quadrature, then the random effect yields has sensible
variance estimate. Maybe someone else (Ben Bolker?) can chime in and
explain why.

Best regards,


ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>

2018-07-26 22:00 GMT+02:00 Scott LaPoint <sdlapoint at gmail.com>:

> Thank you Thierry,
>
> The model below does converge and does not produce any warning messages,
> but the random effect variance and std dev are both = 0:
>
> mDist <- glmer(distance ~ CSs.lat + CSdirect + CSstart + year + age*sex +
> (1|id), data = birds, family = Gamma(link = log), nAGQ = 10, control =
> glmerControl(optimizer = "bobyqa"))
>
> As I understand it, and please correct me if I'm wrong, it is possible
> (but perhaps unlikely) to have these values = 0. If so, I believe this
> implies that either the random effect variable is truly not variable or
> that the variance of the random effect is being captured by the other fixed
> effects. In my case, that might imply that any variation between birds is
> captured by year, age, or sex. So, assuming that logic is correct (and it
> may not be), then the following model would most likely show a variance and
> std dev > 0:
>
> mDist <- glmer(distance ~ CSs.lat + (1|id), data = birds,  family =
> Gamma(link = log), nAGQ = 10, control = glmerControl(optimizer = "bobyqa"))
>
> But, it does not, and still shows a variance and std dev of 0. A quick
> boxplot of distance grouped by bird id shows both substantial variation
> across birds and at times within birds.
>
> Perhaps I'm still missing something? Is 137 observations really too few
> for a model with 1 fixed and 1 random effect variable?
>
> Apologies for my ignorance. I do appreciate the guidance while I learn to
> swim in the GLMM sea.
>
> scott
>
> Scott LaPoint
> Postdoctoral Researcher, Lamont-Doherty Earth Observatory, Columbia
> University
> Associate Scientist, Max-Planck Institute for Ornithology
> skype: scott_lapoint
> twitter @sdlapoint
> scottlapoint.weebly.com
>
> On Wed, Jul 25, 2018 at 6:29 PM, Thierry Onkelinx <
> thierry.onkelinx at inbo.be> wrote:
>
>> Dear Scott,
>>
>> Random effects model only information which is not captured by the fixed
>> effects. And the random effects are subject to shrinkage. Combine this with
>> a large number of fixed effect parameters, a small data set and unbalanced
>> repeated measurements. Then zero variance random effects and convergence
>> issues don't come as a surprise.
>>
>> ?Bottom line: ?your model is too complex for the data. You'll need to
>> drop variables or make more observations (often not feasible, I know).
>> Using a different transformation/link/distribution won't solve any of
>> these issues.
>>
>> Best regards,
>>
>>
>> ir. Thierry Onkelinx
>> Statisticus / Statistician
>>
>> Vlaamse Overheid / Government of Flanders
>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
>> AND FOREST
>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
>> thierry.onkelinx at inbo.be
>> Havenlaan 88
>> <https://maps.google.com/?q=Havenlaan+88&entry=gmail&source=g> bus 73,
>> 1000 Brussel
>> www.inbo.be
>>
>> ////////////////////////////////////////////////////////////
>> ///////////////////////////////
>> To call in the statistician after the experiment is done may be no more
>> than asking him to perform a post-mortem examination: he may be able to say
>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does not
>> ensure that a reasonable answer can be extracted from a given body of data.
>> ~ John Tukey
>> ////////////////////////////////////////////////////////////
>> ///////////////////////////////
>>
>> <https://www.inbo.be>
>>
>> 2018-07-25 22:05 GMT+02:00 Scott LaPoint <sdlapoint at gmail.com>:
>>
>>> Thank you Paul, I appreciate your time. And, apologies if my
>>> understanding
>>> is often incomplete.
>>>
>>>
>>> Hi Scott,
>>> >
>>> > An incomplete answer?
>>> >
>>> > > 1. Is a Gamma distribution best for my distance data? If so, which
>>> link
>>> > > function is most appropriate? I explored two link functions:
>>> identity and
>>> > > log. I have concerns and see potential issues with both (see my
>>> > annotations
>>> > > in the reproducible example below.
>>> >
>>> > I don?t know (I haven?t run your code) but I?ve always somehow managed
>>> to
>>> > avoid gamma regression for strictly positive data by logging the
>>> response
>>> > and fitting a model with normal errors.
>>> >
>>>
>>> If possible, I'd rather not transform the raw data to facilitate
>>> interpretation of the coefficient estimates. I'm likely naive or
>>> misunderstanding something though. Log transforming the distance data
>>> does
>>> produce a reasonably normal distribution. The following two models have
>>> very similar AIC, BIC, LogLik, etc. estimates and the p-values of the
>>> fixed
>>> effects produce similar interpretations. However, the fixed effects
>>> estimates are quite different.
>>>
>>> gammaDist <- glmer(distance ~ CSs.lat + CSdirect + CSstart + year +
>>> age*sex
>>> + (1|id), data = birds, family = Gamma(link = log), nAGQ = 10, control =
>>> glmerControl(optimizer = "bobyqa"))
>>> summary(gammaDist)
>>>
>>> logGausDist <- glmer(log(distance) ~ CSs.lat + CSdirect + CSstart + year
>>> +
>>> age*sex + (1|id), data = birds, family = gaussian(link = log), nAGQ = 10,
>>> control = glmerControl(optimizer = "bobyqa"))
>>> summary(logGausDist)
>>>
>>> The interpretation from these two models are mostly the same: only
>>> starting
>>> latitude is a marginally significant predictor of bird migration
>>> distance.
>>> Correct?
>>>
>>>
>>> > 2.  If the log link is the best or most appropriate to use, then the
>>> > > summary(mDist) produces a sd of the random effect = 0 with the bobyqa
>>> > > optimizer. Switching to Nelder_Mead gives a reasonable sd, but
>>> throws a
>>> > > convergence warning.
>>> >
>>> > (For clarity, I assume that by "sd of the random effect? you mean the
>>> > square root of the variance parameter that gauges residual inter-bird
>>> > variation in mean distance and not the SD of the estimate of that
>>> > parameter, which anyway isn?t output by glmer.)
>>> >
>>> > Why is a random effect variance estimate of zero implausible? I would
>>> > trust a converged estimate over a non-converged estimate, regardless of
>>> > whether the estimate is zero. Also? you could compare the
>>> log-likelihoods
>>> > using logLik() ?  you?d expect the converged fit to have a higher LL.
>>> For
>>> > more general troubleshooting of convergence warnings:
>>> > http://rpubs.com/bbolker/lme4trouble1
>>>
>>>
>>> Yes, I believe your assumption is correct. In case I am wrong, I'm
>>> referring to these estimates from the summary(model) output:
>>> Random effects:
>>>  Groups   Name        Variance Std.Dev.
>>>  id       (Intercept) 0.00000  0.0000
>>>  Residual             0.02879  0.1697
>>> Number of obs: 137, groups:  id, 79
>>>
>>> The reason I said that a Std.Dev. = 0 is implausible is because the
>>> ecologist in me says that there is no way that individual birds do not
>>> vary
>>> between each other (or even within for birds with multiple migration
>>> route
>>> data). Am I misunderstanding the meaning of the Std.Dev here?
>>>
>>>
>>> > Another quick check I often do is to fit the non-converged model with
>>> > glmmTMB (which appears to be more robust than lme4), and compare
>>> > likelihoods and estimates with lme4.
>>> >
>>> > A quick and dirty model fit assessment is to simulate from the fitted
>>> > model (which is as easy as simulate(my.fit)), and see if the simulated
>>> > responses look more or less like the real responses.
>>> >
>>> > Good luck,
>>> > Paul
>>> >
>>> >
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>>
>

	[[alternative HTML version deleted]]


From mollieebrook@ @ending from gm@il@com  Fri Jul 27 10:46:55 2018
From: mollieebrook@ @ending from gm@il@com (Mollie Brooks)
Date: Fri, 27 Jul 2018 10:46:55 +0200
Subject: [R-sig-ME] multiple errors when using glmmADMB
In-Reply-To: <AE9791A8-A8AA-49A9-9164-ECB0C0E6019D@ic.ac.uk>
References: <8F918DAA-A9DB-47FD-AC0E-4C090E0B4E43@contoso.com>
 <cfc67200-048e-5485-c6b6-6899f1b56d22@gmail.com>
 <AE9791A8-A8AA-49A9-9164-ECB0C0E6019D@ic.ac.uk>
Message-ID: <6B8F4A91-F79C-418B-8556-9378D9F00072@gmail.com>

Hi Udita, 

It looks like this is binomial data. You probably want logistic regression like this

library(lme4)
m_glmer <- glmer(cbind(No.of.chicks, Clutch.size-No.of.chicks)~ laying.date.julian.day.zscale + tmean.zscale + (1|YEAR),  data = hungary_breeding, , family = binomial)

cheers,
Mollie

> On 26Jul 2018, at 22:03, Bansal, Udita <udita.bansal17 at imperial.ac.uk> wrote:
> 
> I am measuring breeding success as number of chicks produced out of number of eggs laid. So, the values range from 0 to 1 including decimal values. Although, that was just a warning. Should I be too concerned about that?
> 
> My model statement is as follows: 
> m_admb <- glmmadmb( breeding.success ~ laying.date.julian.day.zscale + tmean.zscale + (1|YEAR) , 
>                    data = hungary_breeding, zeroInflation = TRUE, family = "nbinom", link = "logit")
> 
> Summary for relevant columns of my data: 
> 
> YEAR       No.of.chicks          Clutch.size        laying_date             tmean            prec       
> 1988:16   Min.   :0.000   Min.   :2.000   Min.   :1988-04-22   Min.   : 3.45   Min.   : 0.000  
> 1989:25   1st Qu.:0.000   1st Qu.:3.000   1st Qu.:1990-05-07   1st Qu.:11.35   1st Qu.: 0.000  
> 1990:45   Median :0.000   Median :3.000   Median :1991-05-09   Median :15.12   Median : 0.000  
> 1991:65   Mean   :1.021   Mean   :2.946   Mean   :1991-05-24   Mean   :14.62   Mean   : 2.285  
> 1992:46   3rd Qu.:3.000   3rd Qu.:3.000   3rd Qu.:1992-05-15   3rd Qu.:17.95   3rd Qu.: 1.050  
> 1993:24   Max.   :3.000   Max.   :3.000   Max.   :1994-06-16   Max.   :27.05   Max.   :55.200  
> 1994:19                                                                                        
> breeding.success clutch.volume   laying.date.julian.day   tmean.zscale.V1      prec.zscale.V1   
> Min.   :0.0000   Min.   :15.82   Min.   : 82.0          Min.   :-2.5607265   Min.   :-0.559014  
> 1st Qu.:0.0000   1st Qu.:24.60   1st Qu.:115.0          1st Qu.:-0.7638887   1st Qu.:-0.559014  
> Median :0.0000   Median :25.89   Median :129.0          Median : 0.0947269   Median :-0.559014  
> Mean   :0.3438   Mean   :25.52   Mean   :132.3          Mean   :-0.0190444   Mean   : 0.006583  
> 3rd Qu.:1.0000   3rd Qu.:27.06   3rd Qu.:148.2          3rd Qu.: 0.7372670   3rd Qu.: 0.209975  
> Max.   :1.0000   Max.   :29.83   Max.   :186.0          Max.   : 2.8070422   Max.   : 3.762186  
> 
> laying.date.julian.day.zscale.V1
> Min.   :-2.2850626              
> 1st Qu.:-0.7846733              
> Median :-0.1481445              
> Mean   : 0.0000000              
> 3rd Qu.: 0.7270826              
> Max.   : 2.4434370              
> 
> I will try glmmTMB as well now.
> 
> Thanks
> Udita
> 
> On 26/07/18, 7:41 PM, "R-sig-mixed-models on behalf of Ben Bolker" <r-sig-mixed-models-bounces at r-project.org on behalf of bbolker at gmail.com> wrote:
> 
> 
>      The first thing that pops  out is the "non-integer response values in
>    discrete family" warning.  How are you measuring breeding success?  Can
>    you show us your whole glmmadmb() statement, and maybe a summary() of
>    the relevant columns of your data set?
> 
>       I'll also make the now-blanket statement that you may have better
>    luck moving forward with glmmTMB.
> 
>      cheers
>        Ben Bolker
> 
>    On 2018-07-26 12:57 PM, Bansal, Udita wrote:
>> Hi all,
>> 
>> I was trying to use the glmmADMB package but ran into some errors. I?ve
>> noticed that other people have run into similar errors but there doesn?t
>> seem to be a solution online. It would be great help if anyone could
>> provide any insights on it.
>> 
>> I am using it for running a zero-inflated mixed-effects binomial model.
>> The errors are as follows:
>> 
>> Parameters were estimated, but standard errors were not: the most likely
>> problem is that the curvature at MLE was zero or negative
>> Error in glmmadmb(breeding.success ~ laying.date.julian.day.zscale +
>> tmean.zscale +  :
>>  The function maximizer failed (couldn't find parameter file)
>> Troubleshooting steps include (1) run with 'save.dir' set and inspect
>> output files; (2) change run parameters: see '?admbControl';(3) re-run
>> with debug=TRUE for more information on failure mode
>> In addition: Warning messages:
>> 1: In glmmadmb(breeding.success ~ laying.date.julian.day.zscale +
>> tmean.zscale +  :
>>  non-integer response values in discrete family
>> 2: running command './glmmadmb -maxfn 500 -maxph 5 -noinit -shess' had
>> status 1
>> 
>> Any kind of help will be greatly appreciated.
>> 
>> Bests
>> Udita Bansal
>> 
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 
> 
>    _______________________________________________
>    R-sig-mixed-models at r-project.org mailing list
>    https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From udit@@b@n@@l17 @ending from imperi@l@@c@uk  Fri Jul 27 11:28:07 2018
From: udit@@b@n@@l17 @ending from imperi@l@@c@uk (Bansal, Udita)
Date: Fri, 27 Jul 2018 09:28:07 +0000
Subject: [R-sig-ME] multiple errors when using glmmADMB
In-Reply-To: <6B8F4A91-F79C-418B-8556-9378D9F00072@gmail.com>
References: <8F918DAA-A9DB-47FD-AC0E-4C090E0B4E43@contoso.com>
 <cfc67200-048e-5485-c6b6-6899f1b56d22@gmail.com>
 <AE9791A8-A8AA-49A9-9164-ECB0C0E6019D@ic.ac.uk>
 <6B8F4A91-F79C-418B-8556-9378D9F00072@gmail.com>
Message-ID: <3399BDF6-2FCD-454A-90EF-5BD389ECD7C8@ic.ac.uk>

Hi Mollie,

Thanks a lot, I have tried that and it runs the model. My concern is that I cannot include zero inflation of the data in this model. Any ideas for that?

Cheers
Udita

On 27/07/18, 9:47 AM, "Mollie Brooks" <mollieebrooks at gmail.com> wrote:

    Hi Udita, 
    
    It looks like this is binomial data. You probably want logistic regression like this
    
    library(lme4)
    m_glmer <- glmer(cbind(No.of.chicks, Clutch.size-No.of.chicks)~ laying.date.julian.day.zscale + tmean.zscale + (1|YEAR),  data = hungary_breeding, , family = binomial)
    
    cheers,
    Mollie
    
    > On 26Jul 2018, at 22:03, Bansal, Udita <udita.bansal17 at imperial.ac.uk> wrote:
    > 
    > I am measuring breeding success as number of chicks produced out of number of eggs laid. So, the values range from 0 to 1 including decimal values. Although, that was just a warning. Should I be too concerned about that?
    > 
    > My model statement is as follows: 
    > m_admb <- glmmadmb( breeding.success ~ laying.date.julian.day.zscale + tmean.zscale + (1|YEAR) , 
    >                    data = hungary_breeding, zeroInflation = TRUE, family = "nbinom", link = "logit")
    > 
    > Summary for relevant columns of my data: 
    > 
    > YEAR       No.of.chicks          Clutch.size        laying_date             tmean            prec       
    > 1988:16   Min.   :0.000   Min.   :2.000   Min.   :1988-04-22   Min.   : 3.45   Min.   : 0.000  
    > 1989:25   1st Qu.:0.000   1st Qu.:3.000   1st Qu.:1990-05-07   1st Qu.:11.35   1st Qu.: 0.000  
    > 1990:45   Median :0.000   Median :3.000   Median :1991-05-09   Median :15.12   Median : 0.000  
    > 1991:65   Mean   :1.021   Mean   :2.946   Mean   :1991-05-24   Mean   :14.62   Mean   : 2.285  
    > 1992:46   3rd Qu.:3.000   3rd Qu.:3.000   3rd Qu.:1992-05-15   3rd Qu.:17.95   3rd Qu.: 1.050  
    > 1993:24   Max.   :3.000   Max.   :3.000   Max.   :1994-06-16   Max.   :27.05   Max.   :55.200  
    > 1994:19                                                                                        
    > breeding.success clutch.volume   laying.date.julian.day   tmean.zscale.V1      prec.zscale.V1   
    > Min.   :0.0000   Min.   :15.82   Min.   : 82.0          Min.   :-2.5607265   Min.   :-0.559014  
    > 1st Qu.:0.0000   1st Qu.:24.60   1st Qu.:115.0          1st Qu.:-0.7638887   1st Qu.:-0.559014  
    > Median :0.0000   Median :25.89   Median :129.0          Median : 0.0947269   Median :-0.559014  
    > Mean   :0.3438   Mean   :25.52   Mean   :132.3          Mean   :-0.0190444   Mean   : 0.006583  
    > 3rd Qu.:1.0000   3rd Qu.:27.06   3rd Qu.:148.2          3rd Qu.: 0.7372670   3rd Qu.: 0.209975  
    > Max.   :1.0000   Max.   :29.83   Max.   :186.0          Max.   : 2.8070422   Max.   : 3.762186  
    > 
    > laying.date.julian.day.zscale.V1
    > Min.   :-2.2850626              
    > 1st Qu.:-0.7846733              
    > Median :-0.1481445              
    > Mean   : 0.0000000              
    > 3rd Qu.: 0.7270826              
    > Max.   : 2.4434370              
    > 
    > I will try glmmTMB as well now.
    > 
    > Thanks
    > Udita
    > 
    > On 26/07/18, 7:41 PM, "R-sig-mixed-models on behalf of Ben Bolker" <r-sig-mixed-models-bounces at r-project.org on behalf of bbolker at gmail.com> wrote:
    > 
    > 
    >      The first thing that pops  out is the "non-integer response values in
    >    discrete family" warning.  How are you measuring breeding success?  Can
    >    you show us your whole glmmadmb() statement, and maybe a summary() of
    >    the relevant columns of your data set?
    > 
    >       I'll also make the now-blanket statement that you may have better
    >    luck moving forward with glmmTMB.
    > 
    >      cheers
    >        Ben Bolker
    > 
    >    On 2018-07-26 12:57 PM, Bansal, Udita wrote:
    >> Hi all,
    >> 
    >> I was trying to use the glmmADMB package but ran into some errors. I?ve
    >> noticed that other people have run into similar errors but there doesn?t
    >> seem to be a solution online. It would be great help if anyone could
    >> provide any insights on it.
    >> 
    >> I am using it for running a zero-inflated mixed-effects binomial model.
    >> The errors are as follows:
    >> 
    >> Parameters were estimated, but standard errors were not: the most likely
    >> problem is that the curvature at MLE was zero or negative
    >> Error in glmmadmb(breeding.success ~ laying.date.julian.day.zscale +
    >> tmean.zscale +  :
    >>  The function maximizer failed (couldn't find parameter file)
    >> Troubleshooting steps include (1) run with 'save.dir' set and inspect
    >> output files; (2) change run parameters: see '?admbControl';(3) re-run
    >> with debug=TRUE for more information on failure mode
    >> In addition: Warning messages:
    >> 1: In glmmadmb(breeding.success ~ laying.date.julian.day.zscale +
    >> tmean.zscale +  :
    >>  non-integer response values in discrete family
    >> 2: running command './glmmadmb -maxfn 500 -maxph 5 -noinit -shess' had
    >> status 1
    >> 
    >> Any kind of help will be greatly appreciated.
    >> 
    >> Bests
    >> Udita Bansal
    >> 
    >> 
    >> 	[[alternative HTML version deleted]]
    >> 
    >> _______________________________________________
    >> R-sig-mixed-models at r-project.org mailing list
    >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
    >> 
    > 
    >    _______________________________________________
    >    R-sig-mixed-models at r-project.org mailing list
    >    https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
    > 
    > 
    > _______________________________________________
    > R-sig-mixed-models at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
    
    


From mollieebrook@ @ending from gm@il@com  Fri Jul 27 11:52:26 2018
From: mollieebrook@ @ending from gm@il@com (Mollie Brooks)
Date: Fri, 27 Jul 2018 11:52:26 +0200
Subject: [R-sig-ME] multiple errors when using glmmADMB
In-Reply-To: <3399BDF6-2FCD-454A-90EF-5BD389ECD7C8@ic.ac.uk>
References: <8F918DAA-A9DB-47FD-AC0E-4C090E0B4E43@contoso.com>
 <cfc67200-048e-5485-c6b6-6899f1b56d22@gmail.com>
 <AE9791A8-A8AA-49A9-9164-ECB0C0E6019D@ic.ac.uk>
 <6B8F4A91-F79C-418B-8556-9378D9F00072@gmail.com>
 <3399BDF6-2FCD-454A-90EF-5BD389ECD7C8@ic.ac.uk>
Message-ID: <EB77BAFB-8CDC-4487-9C66-F0AD6E808465@gmail.com>

Hi Udita,

It?s unlikely (but possible) that you?ll need to handle zero inflation. You could test for it using the DHARMa package. Here?s an example of doing that with binomial data.

library(DHARMa)
library(lme4)
gm1 <- glmer(cbind(incidence, size - incidence) ~ period + (1 | herd),
               data = cbpp, family = binomial)
simulationOutput <- simulateResiduals(fittedModel = gm1, n=1000)
testZeroInflation(simulationOutput)

If you do have zero-inflation, then you could use glmmTMB for models like this

#nest failure equally possible for all observations
m1 <- glmmTMB(cbind(No.of.chicks, Clutch.size-No.of.chicks)~ laying.date.julian.day.zscale + tmean.zscale + (1|YEAR),  zi=~1, data = hungary_breeding, , family = binomial)

#nest failure varies randomly by year
m2 <- glmmTMB(cbind(No.of.chicks, Clutch.size-No.of.chicks)~ laying.date.julian.day.zscale + tmean.zscale + (1|YEAR),  zi=~(1|YEAR), data = hungary_breeding, , family = binomial)

#nest failure varies with tmean.zscale
m3 <- glmmTMB(cbind(No.of.chicks, Clutch.size-No.of.chicks)~ laying.date.julian.day.zscale + tmean.zscale + (1|YEAR),  zi=~ tmean.zscale, data = hungary_breeding, , family = binomial)

cheers,
Mollie


> On 27Jul 2018, at 11:28, Bansal, Udita <udita.bansal17 at imperial.ac.uk> wrote:
> 
> Hi Mollie,
> 
> Thanks a lot, I have tried that and it runs the model. My concern is that I cannot include zero inflation of the data in this model. Any ideas for that?
> 
> Cheers
> Udita
> 
> On 27/07/18, 9:47 AM, "Mollie Brooks" <mollieebrooks at gmail.com> wrote:
> 
>    Hi Udita, 
> 
>    It looks like this is binomial data. You probably want logistic regression like this
> 
>    library(lme4)
>    m_glmer <- glmer(cbind(No.of.chicks, Clutch.size-No.of.chicks)~ laying.date.julian.day.zscale + tmean.zscale + (1|YEAR),  data = hungary_breeding, , family = binomial)
> 
>    cheers,
>    Mollie
> 
>> On 26Jul 2018, at 22:03, Bansal, Udita <udita.bansal17 at imperial.ac.uk> wrote:
>> 
>> I am measuring breeding success as number of chicks produced out of number of eggs laid. So, the values range from 0 to 1 including decimal values. Although, that was just a warning. Should I be too concerned about that?
>> 
>> My model statement is as follows: 
>> m_admb <- glmmadmb( breeding.success ~ laying.date.julian.day.zscale + tmean.zscale + (1|YEAR) , 
>>                   data = hungary_breeding, zeroInflation = TRUE, family = "nbinom", link = "logit")
>> 
>> Summary for relevant columns of my data: 
>> 
>> YEAR       No.of.chicks          Clutch.size        laying_date             tmean            prec       
>> 1988:16   Min.   :0.000   Min.   :2.000   Min.   :1988-04-22   Min.   : 3.45   Min.   : 0.000  
>> 1989:25   1st Qu.:0.000   1st Qu.:3.000   1st Qu.:1990-05-07   1st Qu.:11.35   1st Qu.: 0.000  
>> 1990:45   Median :0.000   Median :3.000   Median :1991-05-09   Median :15.12   Median : 0.000  
>> 1991:65   Mean   :1.021   Mean   :2.946   Mean   :1991-05-24   Mean   :14.62   Mean   : 2.285  
>> 1992:46   3rd Qu.:3.000   3rd Qu.:3.000   3rd Qu.:1992-05-15   3rd Qu.:17.95   3rd Qu.: 1.050  
>> 1993:24   Max.   :3.000   Max.   :3.000   Max.   :1994-06-16   Max.   :27.05   Max.   :55.200  
>> 1994:19                                                                                        
>> breeding.success clutch.volume   laying.date.julian.day   tmean.zscale.V1      prec.zscale.V1   
>> Min.   :0.0000   Min.   :15.82   Min.   : 82.0          Min.   :-2.5607265   Min.   :-0.559014  
>> 1st Qu.:0.0000   1st Qu.:24.60   1st Qu.:115.0          1st Qu.:-0.7638887   1st Qu.:-0.559014  
>> Median :0.0000   Median :25.89   Median :129.0          Median : 0.0947269   Median :-0.559014  
>> Mean   :0.3438   Mean   :25.52   Mean   :132.3          Mean   :-0.0190444   Mean   : 0.006583  
>> 3rd Qu.:1.0000   3rd Qu.:27.06   3rd Qu.:148.2          3rd Qu.: 0.7372670   3rd Qu.: 0.209975  
>> Max.   :1.0000   Max.   :29.83   Max.   :186.0          Max.   : 2.8070422   Max.   : 3.762186  
>> 
>> laying.date.julian.day.zscale.V1
>> Min.   :-2.2850626              
>> 1st Qu.:-0.7846733              
>> Median :-0.1481445              
>> Mean   : 0.0000000              
>> 3rd Qu.: 0.7270826              
>> Max.   : 2.4434370              
>> 
>> I will try glmmTMB as well now.
>> 
>> Thanks
>> Udita
>> 
>> On 26/07/18, 7:41 PM, "R-sig-mixed-models on behalf of Ben Bolker" <r-sig-mixed-models-bounces at r-project.org on behalf of bbolker at gmail.com> wrote:
>> 
>> 
>>     The first thing that pops  out is the "non-integer response values in
>>   discrete family" warning.  How are you measuring breeding success?  Can
>>   you show us your whole glmmadmb() statement, and maybe a summary() of
>>   the relevant columns of your data set?
>> 
>>      I'll also make the now-blanket statement that you may have better
>>   luck moving forward with glmmTMB.
>> 
>>     cheers
>>       Ben Bolker
>> 
>>   On 2018-07-26 12:57 PM, Bansal, Udita wrote:
>>> Hi all,
>>> 
>>> I was trying to use the glmmADMB package but ran into some errors. I?ve
>>> noticed that other people have run into similar errors but there doesn?t
>>> seem to be a solution online. It would be great help if anyone could
>>> provide any insights on it.
>>> 
>>> I am using it for running a zero-inflated mixed-effects binomial model.
>>> The errors are as follows:
>>> 
>>> Parameters were estimated, but standard errors were not: the most likely
>>> problem is that the curvature at MLE was zero or negative
>>> Error in glmmadmb(breeding.success ~ laying.date.julian.day.zscale +
>>> tmean.zscale +  :
>>> The function maximizer failed (couldn't find parameter file)
>>> Troubleshooting steps include (1) run with 'save.dir' set and inspect
>>> output files; (2) change run parameters: see '?admbControl';(3) re-run
>>> with debug=TRUE for more information on failure mode
>>> In addition: Warning messages:
>>> 1: In glmmadmb(breeding.success ~ laying.date.julian.day.zscale +
>>> tmean.zscale +  :
>>> non-integer response values in discrete family
>>> 2: running command './glmmadmb -maxfn 500 -maxph 5 -noinit -shess' had
>>> status 1
>>> 
>>> Any kind of help will be greatly appreciated.
>>> 
>>> Bests
>>> Udita Bansal
>>> 
>>> 
>>> 	[[alternative HTML version deleted]]
>>> 
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> 
>> 
>>   _______________________________________________
>>   R-sig-mixed-models at r-project.org mailing list
>>   https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
> 


From udit@@b@n@@l17 @ending from imperi@l@@c@uk  Fri Jul 27 12:41:15 2018
From: udit@@b@n@@l17 @ending from imperi@l@@c@uk (Bansal, Udita)
Date: Fri, 27 Jul 2018 10:41:15 +0000
Subject: [R-sig-ME] multiple errors when using glmmADMB
In-Reply-To: <EB77BAFB-8CDC-4487-9C66-F0AD6E808465@gmail.com>
References: <8F918DAA-A9DB-47FD-AC0E-4C090E0B4E43@contoso.com>
 <cfc67200-048e-5485-c6b6-6899f1b56d22@gmail.com>
 <AE9791A8-A8AA-49A9-9164-ECB0C0E6019D@ic.ac.uk>
 <6B8F4A91-F79C-418B-8556-9378D9F00072@gmail.com>
 <3399BDF6-2FCD-454A-90EF-5BD389ECD7C8@ic.ac.uk>
 <EB77BAFB-8CDC-4487-9C66-F0AD6E808465@gmail.com>
Message-ID: <8DB3E153-94E0-4423-83F9-BC27561A0F92@ic.ac.uk>

Hi Mollie,

Thanks again for the ideas and explanation. I am not sure about how to interpret the output from the DHARMa package. I got the graph attached herewith.

I had run a few models with glmmTMB and a simple one with glmer.

m_tmb <- glmmTMB(breeding.success ~ laying.date.julian.day.zscale + tmean.zscale + (1|YEAR) , 
                 data = hungary_breeding, ziformula = ~1, family = binomial, weights = CSIZE)

tmb_poisson <- glmmTMB(breeding.success ~ laying.date.julian.day.zscale + tmean.zscale + (1|YEAR) , 
                       data = hungary_breeding, ziformula = ~1, family = poisson)

tmb_nbinom1 <- glmmTMB(breeding.success ~ laying.date.julian.day.zscale + tmean.zscale + (1|YEAR) , 
                      data = hungary_breeding, ziformula = ~1, family = nbinom1)
 ## Warning message: In fitTMB(TMBStruc) : Model convergence problem; false convergence (8). See vignette('troubleshooting')

tmb_nbinom2 <- glmmTMB(breeding.success ~ laying.date.julian.day.zscale + tmean.zscale + (1|YEAR) , 
                       data = hungary_breeding, ziformula = ~1, family = nbinom2) ## same warning as above

gm1 <- glmer(breeding.success ~ laying.date.julian.day.zscale + tmean.zscale + (1|YEAR) , 
             data = hungary_breeding, family = binomial, weights = CSIZE)

The AIC looks as follows: 

AIC(m_tmb, tmb_poisson, tmb_nbinom1, tmb_nbinom2, gm1)
                  df      AIC
m_tmb            5   489.2653
tmb_poisson  5   333.4137
tmb_nbinom1  6 335.3694
tmb_nbinom2  6 335.4137
gm1                  4   764.4029

This makes me think it should one of the models with the lower AIC?

Thanks
Udita

On 27/07/18, 10:52 AM, "Mollie Brooks" <mollieebrooks at gmail.com> wrote:

    Hi Udita,
    
    It?s unlikely (but possible) that you?ll need to handle zero inflation. You could test for it using the DHARMa package. Here?s an example of doing that with binomial data.
    
    library(DHARMa)
    library(lme4)
    gm1 <- glmer(cbind(incidence, size - incidence) ~ period + (1 | herd),
                   data = cbpp, family = binomial)
    simulationOutput <- simulateResiduals(fittedModel = gm1, n=1000)
    testZeroInflation(simulationOutput)
    
    If you do have zero-inflation, then you could use glmmTMB for models like this
    
    #nest failure equally possible for all observations
    m1 <- glmmTMB(cbind(No.of.chicks, Clutch.size-No.of.chicks)~ laying.date.julian.day.zscale + tmean.zscale + (1|YEAR),  zi=~1, data = hungary_breeding, , family = binomial)
    
    #nest failure varies randomly by year
    m2 <- glmmTMB(cbind(No.of.chicks, Clutch.size-No.of.chicks)~ laying.date.julian.day.zscale + tmean.zscale + (1|YEAR),  zi=~(1|YEAR), data = hungary_breeding, , family = binomial)
    
    #nest failure varies with tmean.zscale
    m3 <- glmmTMB(cbind(No.of.chicks, Clutch.size-No.of.chicks)~ laying.date.julian.day.zscale + tmean.zscale + (1|YEAR),  zi=~ tmean.zscale, data = hungary_breeding, , family = binomial)
    
    cheers,
    Mollie
    
    
    > On 27Jul 2018, at 11:28, Bansal, Udita <udita.bansal17 at imperial.ac.uk> wrote:
    > 
    > Hi Mollie,
    > 
    > Thanks a lot, I have tried that and it runs the model. My concern is that I cannot include zero inflation of the data in this model. Any ideas for that?
    > 
    > Cheers
    > Udita
    > 
    > On 27/07/18, 9:47 AM, "Mollie Brooks" <mollieebrooks at gmail.com> wrote:
    > 
    >    Hi Udita, 
    > 
    >    It looks like this is binomial data. You probably want logistic regression like this
    > 
    >    library(lme4)
    >    m_glmer <- glmer(cbind(No.of.chicks, Clutch.size-No.of.chicks)~ laying.date.julian.day.zscale + tmean.zscale + (1|YEAR),  data = hungary_breeding, , family = binomial)
    > 
    >    cheers,
    >    Mollie
    > 
    >> On 26Jul 2018, at 22:03, Bansal, Udita <udita.bansal17 at imperial.ac.uk> wrote:
    >> 
    >> I am measuring breeding success as number of chicks produced out of number of eggs laid. So, the values range from 0 to 1 including decimal values. Although, that was just a warning. Should I be too concerned about that?
    >> 
    >> My model statement is as follows: 
    >> m_admb <- glmmadmb( breeding.success ~ laying.date.julian.day.zscale + tmean.zscale + (1|YEAR) , 
    >>                   data = hungary_breeding, zeroInflation = TRUE, family = "nbinom", link = "logit")
    >> 
    >> Summary for relevant columns of my data: 
    >> 
    >> YEAR       No.of.chicks          Clutch.size        laying_date             tmean            prec       
    >> 1988:16   Min.   :0.000   Min.   :2.000   Min.   :1988-04-22   Min.   : 3.45   Min.   : 0.000  
    >> 1989:25   1st Qu.:0.000   1st Qu.:3.000   1st Qu.:1990-05-07   1st Qu.:11.35   1st Qu.: 0.000  
    >> 1990:45   Median :0.000   Median :3.000   Median :1991-05-09   Median :15.12   Median : 0.000  
    >> 1991:65   Mean   :1.021   Mean   :2.946   Mean   :1991-05-24   Mean   :14.62   Mean   : 2.285  
    >> 1992:46   3rd Qu.:3.000   3rd Qu.:3.000   3rd Qu.:1992-05-15   3rd Qu.:17.95   3rd Qu.: 1.050  
    >> 1993:24   Max.   :3.000   Max.   :3.000   Max.   :1994-06-16   Max.   :27.05   Max.   :55.200  
    >> 1994:19                                                                                        
    >> breeding.success clutch.volume   laying.date.julian.day   tmean.zscale.V1      prec.zscale.V1   
    >> Min.   :0.0000   Min.   :15.82   Min.   : 82.0          Min.   :-2.5607265   Min.   :-0.559014  
    >> 1st Qu.:0.0000   1st Qu.:24.60   1st Qu.:115.0          1st Qu.:-0.7638887   1st Qu.:-0.559014  
    >> Median :0.0000   Median :25.89   Median :129.0          Median : 0.0947269   Median :-0.559014  
    >> Mean   :0.3438   Mean   :25.52   Mean   :132.3          Mean   :-0.0190444   Mean   : 0.006583  
    >> 3rd Qu.:1.0000   3rd Qu.:27.06   3rd Qu.:148.2          3rd Qu.: 0.7372670   3rd Qu.: 0.209975  
    >> Max.   :1.0000   Max.   :29.83   Max.   :186.0          Max.   : 2.8070422   Max.   : 3.762186  
    >> 
    >> laying.date.julian.day.zscale.V1
    >> Min.   :-2.2850626              
    >> 1st Qu.:-0.7846733              
    >> Median :-0.1481445              
    >> Mean   : 0.0000000              
    >> 3rd Qu.: 0.7270826              
    >> Max.   : 2.4434370              
    >> 
    >> I will try glmmTMB as well now.
    >> 
    >> Thanks
    >> Udita
    >> 
    >> On 26/07/18, 7:41 PM, "R-sig-mixed-models on behalf of Ben Bolker" <r-sig-mixed-models-bounces at r-project.org on behalf of bbolker at gmail.com> wrote:
    >> 
    >> 
    >>     The first thing that pops  out is the "non-integer response values in
    >>   discrete family" warning.  How are you measuring breeding success?  Can
    >>   you show us your whole glmmadmb() statement, and maybe a summary() of
    >>   the relevant columns of your data set?
    >> 
    >>      I'll also make the now-blanket statement that you may have better
    >>   luck moving forward with glmmTMB.
    >> 
    >>     cheers
    >>       Ben Bolker
    >> 
    >>   On 2018-07-26 12:57 PM, Bansal, Udita wrote:
    >>> Hi all,
    >>> 
    >>> I was trying to use the glmmADMB package but ran into some errors. I?ve
    >>> noticed that other people have run into similar errors but there doesn?t
    >>> seem to be a solution online. It would be great help if anyone could
    >>> provide any insights on it.
    >>> 
    >>> I am using it for running a zero-inflated mixed-effects binomial model.
    >>> The errors are as follows:
    >>> 
    >>> Parameters were estimated, but standard errors were not: the most likely
    >>> problem is that the curvature at MLE was zero or negative
    >>> Error in glmmadmb(breeding.success ~ laying.date.julian.day.zscale +
    >>> tmean.zscale +  :
    >>> The function maximizer failed (couldn't find parameter file)
    >>> Troubleshooting steps include (1) run with 'save.dir' set and inspect
    >>> output files; (2) change run parameters: see '?admbControl';(3) re-run
    >>> with debug=TRUE for more information on failure mode
    >>> In addition: Warning messages:
    >>> 1: In glmmadmb(breeding.success ~ laying.date.julian.day.zscale +
    >>> tmean.zscale +  :
    >>> non-integer response values in discrete family
    >>> 2: running command './glmmadmb -maxfn 500 -maxph 5 -noinit -shess' had
    >>> status 1
    >>> 
    >>> Any kind of help will be greatly appreciated.
    >>> 
    >>> Bests
    >>> Udita Bansal
    >>> 
    >>> 
    >>> 	[[alternative HTML version deleted]]
    >>> 
    >>> _______________________________________________
    >>> R-sig-mixed-models at r-project.org mailing list
    >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
    >>> 
    >> 
    >>   _______________________________________________
    >>   R-sig-mixed-models at r-project.org mailing list
    >>   https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
    >> 
    >> 
    >> _______________________________________________
    >> R-sig-mixed-models at r-project.org mailing list
    >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
    > 
    > 
    > 
    
    


-------------- next part --------------
A non-text attachment was scrubbed...
Name: Screen Shot 2018-07-27 at 11.33.37 AM.png
Type: image/png
Size: 55503 bytes
Desc: Screen Shot 2018-07-27 at 11.33.37 AM.png
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20180727/c4cdeb1c/attachment-0001.png>

From mollieebrook@ @ending from gm@il@com  Fri Jul 27 13:24:25 2018
From: mollieebrook@ @ending from gm@il@com (Mollie Brooks)
Date: Fri, 27 Jul 2018 13:24:25 +0200
Subject: [R-sig-ME] multiple errors when using glmmADMB
In-Reply-To: <8DB3E153-94E0-4423-83F9-BC27561A0F92@ic.ac.uk>
References: <8F918DAA-A9DB-47FD-AC0E-4C090E0B4E43@contoso.com>
 <cfc67200-048e-5485-c6b6-6899f1b56d22@gmail.com>
 <AE9791A8-A8AA-49A9-9164-ECB0C0E6019D@ic.ac.uk>
 <6B8F4A91-F79C-418B-8556-9378D9F00072@gmail.com>
 <3399BDF6-2FCD-454A-90EF-5BD389ECD7C8@ic.ac.uk>
 <EB77BAFB-8CDC-4487-9C66-F0AD6E808465@gmail.com>
 <8DB3E153-94E0-4423-83F9-BC27561A0F92@ic.ac.uk>
Message-ID: <3F06E3F1-B7B4-4C32-9864-0C9FF3BD97DD@gmail.com>

Hi Udita,

breeding.success is between 0 and 1. Therefore it is not Poisson or negative binomial. Even if it could be Poisson or negative binomial, you cannot compare models with and without weights as this is equivalent to the models having different sets of observations. You may need to read background information on GLM(M)s or seek local advice?unless someone else has more time.

The only valid models below are 

> gm1 <- glmer(breeding.success ~ laying.date.julian.day.zscale + tmean.zscale + (1|YEAR) , 
>             data = hungary_breeding, family = binomial, weights = CSIZE)

and 

> m_tmb <- glmmTMB(breeding.success ~ laying.date.julian.day.zscale + tmean.zscale + (1|YEAR) , 
>                 data = hungary_breeding, ziformula = ~1, family = binomial, weights = CSIZE)

The DHARMa graph shows that there?s a problem with your model, but without knowing which model, it?s hard to say. Reading this vignette will be helpful https://cran.r-project.org/web/packages/DHARMa/vignettes/DHARMa.html

cheers,
Mollie

> On 27Jul 2018, at 12:41, Bansal, Udita <udita.bansal17 at imperial.ac.uk> wrote:
> 
> Hi Mollie,
> 
> Thanks again for the ideas and explanation. I am not sure about how to interpret the output from the DHARMa package. I got the graph attached herewith.
> 
> I had run a few models with glmmTMB and a simple one with glmer.
> 
> m_tmb <- glmmTMB(breeding.success ~ laying.date.julian.day.zscale + tmean.zscale + (1|YEAR) , 
>                 data = hungary_breeding, ziformula = ~1, family = binomial, weights = CSIZE)
> 
> tmb_poisson <- glmmTMB(breeding.success ~ laying.date.julian.day.zscale + tmean.zscale + (1|YEAR) , 
>                       data = hungary_breeding, ziformula = ~1, family = poisson)
> 
> tmb_nbinom1 <- glmmTMB(breeding.success ~ laying.date.julian.day.zscale + tmean.zscale + (1|YEAR) , 
>                      data = hungary_breeding, ziformula = ~1, family = nbinom1)
> ## Warning message: In fitTMB(TMBStruc) : Model convergence problem; false convergence (8). See vignette('troubleshooting')
> 
> tmb_nbinom2 <- glmmTMB(breeding.success ~ laying.date.julian.day.zscale + tmean.zscale + (1|YEAR) , 
>                       data = hungary_breeding, ziformula = ~1, family = nbinom2) ## same warning as above
> 
> gm1 <- glmer(breeding.success ~ laying.date.julian.day.zscale + tmean.zscale + (1|YEAR) , 
>             data = hungary_breeding, family = binomial, weights = CSIZE)
> 
> The AIC looks as follows: 
> 
> AIC(m_tmb, tmb_poisson, tmb_nbinom1, tmb_nbinom2, gm1)
>                  df      AIC
> m_tmb            5   489.2653
> tmb_poisson  5   333.4137
> tmb_nbinom1  6 335.3694
> tmb_nbinom2  6 335.4137
> gm1                  4   764.4029
> 
> This makes me think it should one of the models with the lower AIC?
> 
> Thanks
> Udita
> 
> On 27/07/18, 10:52 AM, "Mollie Brooks" <mollieebrooks at gmail.com> wrote:
> 
>    Hi Udita,
> 
>    It?s unlikely (but possible) that you?ll need to handle zero inflation. You could test for it using the DHARMa package. Here?s an example of doing that with binomial data.
> 
>    library(DHARMa)
>    library(lme4)
>    gm1 <- glmer(cbind(incidence, size - incidence) ~ period + (1 | herd),
>                   data = cbpp, family = binomial)
>    simulationOutput <- simulateResiduals(fittedModel = gm1, n=1000)
>    testZeroInflation(simulationOutput)
> 
>    If you do have zero-inflation, then you could use glmmTMB for models like this
> 
>    #nest failure equally possible for all observations
>    m1 <- glmmTMB(cbind(No.of.chicks, Clutch.size-No.of.chicks)~ laying.date.julian.day.zscale + tmean.zscale + (1|YEAR),  zi=~1, data = hungary_breeding, , family = binomial)
> 
>    #nest failure varies randomly by year
>    m2 <- glmmTMB(cbind(No.of.chicks, Clutch.size-No.of.chicks)~ laying.date.julian.day.zscale + tmean.zscale + (1|YEAR),  zi=~(1|YEAR), data = hungary_breeding, , family = binomial)
> 
>    #nest failure varies with tmean.zscale
>    m3 <- glmmTMB(cbind(No.of.chicks, Clutch.size-No.of.chicks)~ laying.date.julian.day.zscale + tmean.zscale + (1|YEAR),  zi=~ tmean.zscale, data = hungary_breeding, , family = binomial)
> 
>    cheers,
>    Mollie
> 
> 
>> On 27Jul 2018, at 11:28, Bansal, Udita <udita.bansal17 at imperial.ac.uk> wrote:
>> 
>> Hi Mollie,
>> 
>> Thanks a lot, I have tried that and it runs the model. My concern is that I cannot include zero inflation of the data in this model. Any ideas for that?
>> 
>> Cheers
>> Udita
>> 
>> On 27/07/18, 9:47 AM, "Mollie Brooks" <mollieebrooks at gmail.com> wrote:
>> 
>>   Hi Udita, 
>> 
>>   It looks like this is binomial data. You probably want logistic regression like this
>> 
>>   library(lme4)
>>   m_glmer <- glmer(cbind(No.of.chicks, Clutch.size-No.of.chicks)~ laying.date.julian.day.zscale + tmean.zscale + (1|YEAR),  data = hungary_breeding, , family = binomial)
>> 
>>   cheers,
>>   Mollie
>> 
>>> On 26Jul 2018, at 22:03, Bansal, Udita <udita.bansal17 at imperial.ac.uk> wrote:
>>> 
>>> I am measuring breeding success as number of chicks produced out of number of eggs laid. So, the values range from 0 to 1 including decimal values. Although, that was just a warning. Should I be too concerned about that?
>>> 
>>> My model statement is as follows: 
>>> m_admb <- glmmadmb( breeding.success ~ laying.date.julian.day.zscale + tmean.zscale + (1|YEAR) , 
>>>                  data = hungary_breeding, zeroInflation = TRUE, family = "nbinom", link = "logit")
>>> 
>>> Summary for relevant columns of my data: 
>>> 
>>> YEAR       No.of.chicks          Clutch.size        laying_date             tmean            prec       
>>> 1988:16   Min.   :0.000   Min.   :2.000   Min.   :1988-04-22   Min.   : 3.45   Min.   : 0.000  
>>> 1989:25   1st Qu.:0.000   1st Qu.:3.000   1st Qu.:1990-05-07   1st Qu.:11.35   1st Qu.: 0.000  
>>> 1990:45   Median :0.000   Median :3.000   Median :1991-05-09   Median :15.12   Median : 0.000  
>>> 1991:65   Mean   :1.021   Mean   :2.946   Mean   :1991-05-24   Mean   :14.62   Mean   : 2.285  
>>> 1992:46   3rd Qu.:3.000   3rd Qu.:3.000   3rd Qu.:1992-05-15   3rd Qu.:17.95   3rd Qu.: 1.050  
>>> 1993:24   Max.   :3.000   Max.   :3.000   Max.   :1994-06-16   Max.   :27.05   Max.   :55.200  
>>> 1994:19                                                                                        
>>> breeding.success clutch.volume   laying.date.julian.day   tmean.zscale.V1      prec.zscale.V1   
>>> Min.   :0.0000   Min.   :15.82   Min.   : 82.0          Min.   :-2.5607265   Min.   :-0.559014  
>>> 1st Qu.:0.0000   1st Qu.:24.60   1st Qu.:115.0          1st Qu.:-0.7638887   1st Qu.:-0.559014  
>>> Median :0.0000   Median :25.89   Median :129.0          Median : 0.0947269   Median :-0.559014  
>>> Mean   :0.3438   Mean   :25.52   Mean   :132.3          Mean   :-0.0190444   Mean   : 0.006583  
>>> 3rd Qu.:1.0000   3rd Qu.:27.06   3rd Qu.:148.2          3rd Qu.: 0.7372670   3rd Qu.: 0.209975  
>>> Max.   :1.0000   Max.   :29.83   Max.   :186.0          Max.   : 2.8070422   Max.   : 3.762186  
>>> 
>>> laying.date.julian.day.zscale.V1
>>> Min.   :-2.2850626              
>>> 1st Qu.:-0.7846733              
>>> Median :-0.1481445              
>>> Mean   : 0.0000000              
>>> 3rd Qu.: 0.7270826              
>>> Max.   : 2.4434370              
>>> 
>>> I will try glmmTMB as well now.
>>> 
>>> Thanks
>>> Udita
>>> 
>>> On 26/07/18, 7:41 PM, "R-sig-mixed-models on behalf of Ben Bolker" <r-sig-mixed-models-bounces at r-project.org on behalf of bbolker at gmail.com> wrote:
>>> 
>>> 
>>>    The first thing that pops  out is the "non-integer response values in
>>>  discrete family" warning.  How are you measuring breeding success?  Can
>>>  you show us your whole glmmadmb() statement, and maybe a summary() of
>>>  the relevant columns of your data set?
>>> 
>>>     I'll also make the now-blanket statement that you may have better
>>>  luck moving forward with glmmTMB.
>>> 
>>>    cheers
>>>      Ben Bolker
>>> 
>>>  On 2018-07-26 12:57 PM, Bansal, Udita wrote:
>>>> Hi all,
>>>> 
>>>> I was trying to use the glmmADMB package but ran into some errors. I?ve
>>>> noticed that other people have run into similar errors but there doesn?t
>>>> seem to be a solution online. It would be great help if anyone could
>>>> provide any insights on it.
>>>> 
>>>> I am using it for running a zero-inflated mixed-effects binomial model.
>>>> The errors are as follows:
>>>> 
>>>> Parameters were estimated, but standard errors were not: the most likely
>>>> problem is that the curvature at MLE was zero or negative
>>>> Error in glmmadmb(breeding.success ~ laying.date.julian.day.zscale +
>>>> tmean.zscale +  :
>>>> The function maximizer failed (couldn't find parameter file)
>>>> Troubleshooting steps include (1) run with 'save.dir' set and inspect
>>>> output files; (2) change run parameters: see '?admbControl';(3) re-run
>>>> with debug=TRUE for more information on failure mode
>>>> In addition: Warning messages:
>>>> 1: In glmmadmb(breeding.success ~ laying.date.julian.day.zscale +
>>>> tmean.zscale +  :
>>>> non-integer response values in discrete family
>>>> 2: running command './glmmadmb -maxfn 500 -maxph 5 -noinit -shess' had
>>>> status 1
>>>> 
>>>> Any kind of help will be greatly appreciated.
>>>> 
>>>> Bests
>>>> Udita Bansal
>>>> 
>>>> 
>>>> 	[[alternative HTML version deleted]]
>>>> 
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>> 
>>> 
>>>  _______________________________________________
>>>  R-sig-mixed-models at r-project.org mailing list
>>>  https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> 
>>> 
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 
>> 
>> 
> 
> 
> 
> <Screen Shot 2018-07-27 at 11.33.37 AM.png>


	[[alternative HTML version deleted]]


From udit@@b@n@@l17 @ending from imperi@l@@c@uk  Fri Jul 27 13:33:22 2018
From: udit@@b@n@@l17 @ending from imperi@l@@c@uk (Bansal, Udita)
Date: Fri, 27 Jul 2018 11:33:22 +0000
Subject: [R-sig-ME] multiple errors when using glmmADMB
In-Reply-To: <3F06E3F1-B7B4-4C32-9864-0C9FF3BD97DD@gmail.com>
References: <8F918DAA-A9DB-47FD-AC0E-4C090E0B4E43@contoso.com>
 <cfc67200-048e-5485-c6b6-6899f1b56d22@gmail.com>
 <AE9791A8-A8AA-49A9-9164-ECB0C0E6019D@ic.ac.uk>
 <6B8F4A91-F79C-418B-8556-9378D9F00072@gmail.com>
 <3399BDF6-2FCD-454A-90EF-5BD389ECD7C8@ic.ac.uk>
 <EB77BAFB-8CDC-4487-9C66-F0AD6E808465@gmail.com>
 <8DB3E153-94E0-4423-83F9-BC27561A0F92@ic.ac.uk>
 <3F06E3F1-B7B4-4C32-9864-0C9FF3BD97DD@gmail.com>
Message-ID: <844A167E-3F02-455A-B256-79029001F08A@ic.ac.uk>

Hi Mollie,

I understand now I think. Thank you so much.

The DHARMa graph was for the gm1 model :
gm1 <- glmer(breeding.success ~ laying.date.julian.day.zscale + tmean.zscale + (1|YEAR) ,
            data = hungary_breeding, family = binomial, weights = CSIZE)

I came across that vignette. Thanks for sharing. I will try the model diagnostics method to be sure as it says.

Thanks
Udita

From: Mollie Brooks <mollieebrooks at gmail.com>
Date: Friday, 27 July 2018 at 12:24 PM
To: "Bansal, Udita" <udita.bansal17 at imperial.ac.uk>
Cc: "r-sig-mixed-models at r-project.org" <r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] multiple errors when using glmmADMB

Hi Udita,

breeding.success is between 0 and 1. Therefore it is not Poisson or negative binomial. Even if it could be Poisson or negative binomial, you cannot compare models with and without weights as this is equivalent to the models having different sets of observations. You may need to read background information on GLM(M)s or seek local advice?unless someone else has more time.

The only valid models below are

gm1 <- glmer(breeding.success ~ laying.date.julian.day.zscale + tmean.zscale + (1|YEAR) ,
            data = hungary_breeding, family = binomial, weights = CSIZE)

and

m_tmb <- glmmTMB(breeding.success ~ laying.date.julian.day.zscale + tmean.zscale + (1|YEAR) ,
                data = hungary_breeding, ziformula = ~1, family = binomial, weights = CSIZE)

The DHARMa graph shows that there?s a problem with your model, but without knowing which model, it?s hard to say. Reading this vignette will be helpful https://cran.r-project.org/web/packages/DHARMa/vignettes/DHARMa.html

cheers,
Mollie


On 27Jul 2018, at 12:41, Bansal, Udita <udita.bansal17 at imperial.ac.uk<mailto:udita.bansal17 at imperial.ac.uk>> wrote:

Hi Mollie,

Thanks again for the ideas and explanation. I am not sure about how to interpret the output from the DHARMa package. I got the graph attached herewith.

I had run a few models with glmmTMB and a simple one with glmer.

m_tmb <- glmmTMB(breeding.success ~ laying.date.julian.day.zscale + tmean.zscale + (1|YEAR) ,
                data = hungary_breeding, ziformula = ~1, family = binomial, weights = CSIZE)

tmb_poisson <- glmmTMB(breeding.success ~ laying.date.julian.day.zscale + tmean.zscale + (1|YEAR) ,
                      data = hungary_breeding, ziformula = ~1, family = poisson)

tmb_nbinom1 <- glmmTMB(breeding.success ~ laying.date.julian.day.zscale + tmean.zscale + (1|YEAR) ,
                     data = hungary_breeding, ziformula = ~1, family = nbinom1)
## Warning message: In fitTMB(TMBStruc) : Model convergence problem; false convergence (8). See vignette('troubleshooting')

tmb_nbinom2 <- glmmTMB(breeding.success ~ laying.date.julian.day.zscale + tmean.zscale + (1|YEAR) ,
                      data = hungary_breeding, ziformula = ~1, family = nbinom2) ## same warning as above

gm1 <- glmer(breeding.success ~ laying.date.julian.day.zscale + tmean.zscale + (1|YEAR) ,
            data = hungary_breeding, family = binomial, weights = CSIZE)

The AIC looks as follows:

AIC(m_tmb, tmb_poisson, tmb_nbinom1, tmb_nbinom2, gm1)
                 df      AIC
m_tmb            5   489.2653
tmb_poisson  5   333.4137
tmb_nbinom1  6 335.3694
tmb_nbinom2  6 335.4137
gm1                  4   764.4029

This makes me think it should one of the models with the lower AIC?

Thanks
Udita

On 27/07/18, 10:52 AM, "Mollie Brooks" <mollieebrooks at gmail.com<mailto:mollieebrooks at gmail.com>> wrote:

   Hi Udita,

   It?s unlikely (but possible) that you?ll need to handle zero inflation. You could test for it using the DHARMa package. Here?s an example of doing that with binomial data.

   library(DHARMa)
   library(lme4)
   gm1 <- glmer(cbind(incidence, size - incidence) ~ period + (1 | herd),
                  data = cbpp, family = binomial)
   simulationOutput <- simulateResiduals(fittedModel = gm1, n=1000)
   testZeroInflation(simulationOutput)

   If you do have zero-inflation, then you could use glmmTMB for models like this

   #nest failure equally possible for all observations
   m1 <- glmmTMB(cbind(No.of.chicks, Clutch.size-No.of.chicks)~ laying.date.julian.day.zscale + tmean.zscale + (1|YEAR),  zi=~1, data = hungary_breeding, , family = binomial)

   #nest failure varies randomly by year
   m2 <- glmmTMB(cbind(No.of.chicks, Clutch.size-No.of.chicks)~ laying.date.julian.day.zscale + tmean.zscale + (1|YEAR),  zi=~(1|YEAR), data = hungary_breeding, , family = binomial)

   #nest failure varies with tmean.zscale
   m3 <- glmmTMB(cbind(No.of.chicks, Clutch.size-No.of.chicks)~ laying.date.julian.day.zscale + tmean.zscale + (1|YEAR),  zi=~ tmean.zscale, data = hungary_breeding, , family = binomial)

   cheers,
   Mollie



On 27Jul 2018, at 11:28, Bansal, Udita <udita.bansal17 at imperial.ac.uk<mailto:udita.bansal17 at imperial.ac.uk>> wrote:

Hi Mollie,

Thanks a lot, I have tried that and it runs the model. My concern is that I cannot include zero inflation of the data in this model. Any ideas for that?

Cheers
Udita

On 27/07/18, 9:47 AM, "Mollie Brooks" <mollieebrooks at gmail.com<mailto:mollieebrooks at gmail.com>> wrote:

  Hi Udita,

  It looks like this is binomial data. You probably want logistic regression like this

  library(lme4)
  m_glmer <- glmer(cbind(No.of.chicks, Clutch.size-No.of.chicks)~ laying.date.julian.day.zscale + tmean.zscale + (1|YEAR),  data = hungary_breeding, , family = binomial)

  cheers,
  Mollie


On 26Jul 2018, at 22:03, Bansal, Udita <udita.bansal17 at imperial.ac.uk<mailto:udita.bansal17 at imperial.ac.uk>> wrote:

I am measuring breeding success as number of chicks produced out of number of eggs laid. So, the values range from 0 to 1 including decimal values. Although, that was just a warning. Should I be too concerned about that?

My model statement is as follows:
m_admb <- glmmadmb( breeding.success ~ laying.date.julian.day.zscale + tmean.zscale + (1|YEAR) ,
                 data = hungary_breeding, zeroInflation = TRUE, family = "nbinom", link = "logit")

Summary for relevant columns of my data:

YEAR       No.of.chicks          Clutch.size        laying_date             tmean            prec
1988:16   Min.   :0.000   Min.   :2.000   Min.   :1988-04-22   Min.   : 3.45   Min.   : 0.000
1989:25   1st Qu.:0.000   1st Qu.:3.000   1st Qu.:1990-05-07   1st Qu.:11.35   1st Qu.: 0.000
1990:45   Median :0.000   Median :3.000   Median :1991-05-09   Median :15.12   Median : 0.000
1991:65   Mean   :1.021   Mean   :2.946   Mean   :1991-05-24   Mean   :14.62   Mean   : 2.285
1992:46   3rd Qu.:3.000   3rd Qu.:3.000   3rd Qu.:1992-05-15   3rd Qu.:17.95   3rd Qu.: 1.050
1993:24   Max.   :3.000   Max.   :3.000   Max.   :1994-06-16   Max.   :27.05   Max.   :55.200
1994:19
breeding.success clutch.volume   laying.date.julian.day   tmean.zscale.V1      prec.zscale.V1
Min.   :0.0000   Min.   :15.82   Min.   : 82.0          Min.   :-2.5607265   Min.   :-0.559014
1st Qu.:0.0000   1st Qu.:24.60   1st Qu.:115.0          1st Qu.:-0.7638887   1st Qu.:-0.559014
Median :0.0000   Median :25.89   Median :129.0          Median : 0.0947269   Median :-0.559014
Mean   :0.3438   Mean   :25.52   Mean   :132.3          Mean   :-0.0190444   Mean   : 0.006583
3rd Qu.:1.0000   3rd Qu.:27.06   3rd Qu.:148.2          3rd Qu.: 0.7372670   3rd Qu.: 0.209975
Max.   :1.0000   Max.   :29.83   Max.   :186.0          Max.   : 2.8070422   Max.   : 3.762186

laying.date.julian.day.zscale.V1
Min.   :-2.2850626
1st Qu.:-0.7846733
Median :-0.1481445
Mean   : 0.0000000
3rd Qu.: 0.7270826
Max.   : 2.4434370

I will try glmmTMB as well now.

Thanks
Udita

On 26/07/18, 7:41 PM, "R-sig-mixed-models on behalf of Ben Bolker" <r-sig-mixed-models-bounces at r-project.org<mailto:r-sig-mixed-models-bounces at r-project.org> on behalf of bbolker at gmail.com<mailto:bbolker at gmail.com>> wrote:


   The first thing that pops  out is the "non-integer response values in
 discrete family" warning.  How are you measuring breeding success?  Can
 you show us your whole glmmadmb() statement, and maybe a summary() of
 the relevant columns of your data set?

    I'll also make the now-blanket statement that you may have better
 luck moving forward with glmmTMB.

   cheers
     Ben Bolker

 On 2018-07-26 12:57 PM, Bansal, Udita wrote:

Hi all,

I was trying to use the glmmADMB package but ran into some errors. I?ve
noticed that other people have run into similar errors but there doesn?t
seem to be a solution online. It would be great help if anyone could
provide any insights on it.

I am using it for running a zero-inflated mixed-effects binomial model.
The errors are as follows:

Parameters were estimated, but standard errors were not: the most likely
problem is that the curvature at MLE was zero or negative
Error in glmmadmb(breeding.success ~ laying.date.julian.day.zscale +
tmean.zscale +  :
The function maximizer failed (couldn't find parameter file)
Troubleshooting steps include (1) run with 'save.dir' set and inspect
output files; (2) change run parameters: see '?admbControl';(3) re-run
with debug=TRUE for more information on failure mode
In addition: Warning messages:
1: In glmmadmb(breeding.success ~ laying.date.julian.day.zscale +
tmean.zscale +  :
non-integer response values in discrete family
2: running command './glmmadmb -maxfn 500 -maxph 5 -noinit -shess' had
status 1

Any kind of help will be greatly appreciated.

Bests
Udita Bansal


[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

 _______________________________________________
 R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
 https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models





<Screen Shot 2018-07-27 at 11.33.37 AM.png>


	[[alternative HTML version deleted]]


From @dl@point @ending from gm@il@com  Fri Jul 27 20:14:09 2018
From: @dl@point @ending from gm@il@com (Scott LaPoint)
Date: Fri, 27 Jul 2018 14:14:09 -0400
Subject: [R-sig-ME] 
 seeking input lme4::glmer with a gamma family: link =
 log or identity?
In-Reply-To: <CAJuCY5yVDyPM+_2VLxkh-Z+O_OezLscsDntco3uRJdca-KY4CA@mail.gmail.com>
References: <CA+SovpNT6Jq03oZJym=KQohFNoMjqW_FKvvTx6AjMzF+UFuQJQ@mail.gmail.com>
 <9D07599F-0EDD-4162-81A3-0C27E8814E3E@glasgow.ac.uk>
 <CA+SovpOZ12ed56-xmSRAo83dnHk=YH+3X-0kK-VJ9BZkVh6BGg@mail.gmail.com>
 <CAJuCY5y2meu9wn9xVtEKhx0iMJ0Ln5u=Zz5HrG9bB4071w2Ckw@mail.gmail.com>
 <CA+SovpP2LSZaS=wvaA6PeLBUkt4sY6SKC-6j=rrUoi+sMoyGUQ@mail.gmail.com>
 <CAJuCY5yVDyPM+_2VLxkh-Z+O_OezLscsDntco3uRJdca-KY4CA@mail.gmail.com>
Message-ID: <CA+SovpMkprAHQhs7eS97toin1w7W9v=ZPv6E5d=hbvMZF=O4PQ@mail.gmail.com>

Thank you again Thierry. I think I had explored different nAGQ values
previously, but not very systematically.

Following Thierry's idea and Professor Bolker's suggestion elsewhere (here:
http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html) under "Trouble
shooting", I compared the LogLikelihood estimates for models run with
different model fitting options:

nAGQ = 0 ("optimizing the random effects and the fixed-effects coefficients
in the penalized iteratively reweighted least squares step")
nAGQ = 1 (Laplace)
nAGQ = 10 (>1 = Gauss-Hermite)

I run this model, with three variants of the nAGQ argument:
mDist <- glmer(distance ~ CSs.lat + CSdirect + CSstart + year + age*sex +
(1|id), data = birds, family = Gamma(link = log), nAGQ = ?, control =
glmerControl(optimizer = "bobyqa"))

I used Bolker's suggestion:
mods <- allFit(mDist)

I provide AIC values as well, just for reference.

With nAGQ = 0:
 AIC = 1887.4
 allFit() = 100% of the optimizers produce models that converge. The LogLik
values all match at -929.6804

With nAGQ = 1:
 AIC = 1843.5
 allFit() = 50% of the optimizers produce models that converge. The LogLik
values for each model are very similar (range = -908.2571 to -907.7478)

With nAGQ = 10:
 AIC = 31.8
 allFit() = 50% of the optimizers produce models that converge. The LogLik
values vary much more substantially (range = -10.481851 to -1.879633)

So, I'm puzzled why despite increasing the nAGQ argument, I seem to be
achieving less certainty...

Thanks to you all.

Scott LaPoint
Postdoctoral Researcher, Lamont-Doherty Earth Observatory, Columbia
University
Associate Scientist, Max-Planck Institute for Ornithology
skype: scott_lapoint
twitter @sdlapoint
scottlapoint.weebly.com

On Fri, Jul 27, 2018 at 4:19 AM, Thierry Onkelinx <thierry.onkelinx at inbo.be>
wrote:

> Dear Scott,
>
> If you run the model with Laplace approximation instead of Adaptive
> Gauss-Hermite Quadrature, then the random effect yields has sensible
> variance estimate. Maybe someone else (Ben Bolker?) can chime in and
> explain why.
>
> Best regards,
>
>
> ir. Thierry Onkelinx
> Statisticus / Statistician
>
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
> FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Havenlaan 88
> <https://maps.google.com/?q=Havenlaan+88&entry=gmail&source=g> bus 73,
> 1000 Brussel
> www.inbo.be
>
> ////////////////////////////////////////////////////////////
> ///////////////////////////////
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
> ////////////////////////////////////////////////////////////
> ///////////////////////////////
>
> <https://www.inbo.be>
>
> 2018-07-26 22:00 GMT+02:00 Scott LaPoint <sdlapoint at gmail.com>:
>
>> Thank you Thierry,
>>
>> The model below does converge and does not produce any warning messages,
>> but the random effect variance and std dev are both = 0:
>>
>> mDist <- glmer(distance ~ CSs.lat + CSdirect + CSstart + year + age*sex +
>> (1|id), data = birds, family = Gamma(link = log), nAGQ = 10, control =
>> glmerControl(optimizer = "bobyqa"))
>>
>> As I understand it, and please correct me if I'm wrong, it is possible
>> (but perhaps unlikely) to have these values = 0. If so, I believe this
>> implies that either the random effect variable is truly not variable or
>> that the variance of the random effect is being captured by the other fixed
>> effects. In my case, that might imply that any variation between birds is
>> captured by year, age, or sex. So, assuming that logic is correct (and it
>> may not be), then the following model would most likely show a variance and
>> std dev > 0:
>>
>> mDist <- glmer(distance ~ CSs.lat + (1|id), data = birds,  family =
>> Gamma(link = log), nAGQ = 10, control = glmerControl(optimizer = "bobyqa"))
>>
>> But, it does not, and still shows a variance and std dev of 0. A quick
>> boxplot of distance grouped by bird id shows both substantial variation
>> across birds and at times within birds.
>>
>> Perhaps I'm still missing something? Is 137 observations really too few
>> for a model with 1 fixed and 1 random effect variable?
>>
>> Apologies for my ignorance. I do appreciate the guidance while I learn to
>> swim in the GLMM sea.
>>
>> scott
>>
>> Scott LaPoint
>> Postdoctoral Researcher, Lamont-Doherty Earth Observatory, Columbia
>> University
>> Associate Scientist, Max-Planck Institute for Ornithology
>> skype: scott_lapoint
>> twitter @sdlapoint
>> scottlapoint.weebly.com
>>
>> On Wed, Jul 25, 2018 at 6:29 PM, Thierry Onkelinx <
>> thierry.onkelinx at inbo.be> wrote:
>>
>>> Dear Scott,
>>>
>>> Random effects model only information which is not captured by the fixed
>>> effects. And the random effects are subject to shrinkage. Combine this with
>>> a large number of fixed effect parameters, a small data set and unbalanced
>>> repeated measurements. Then zero variance random effects and convergence
>>> issues don't come as a surprise.
>>>
>>> ?Bottom line: ?your model is too complex for the data. You'll need to
>>> drop variables or make more observations (often not feasible, I know).
>>> Using a different transformation/link/distribution won't solve any of
>>> these issues.
>>>
>>> Best regards,
>>>
>>>
>>> ir. Thierry Onkelinx
>>> Statisticus / Statistician
>>>
>>> Vlaamse Overheid / Government of Flanders
>>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
>>> AND FOREST
>>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
>>> thierry.onkelinx at inbo.be
>>> Havenlaan 88
>>> <https://maps.google.com/?q=Havenlaan+88&entry=gmail&source=g> bus 73,
>>> 1000 Brussel
>>> www.inbo.be
>>>
>>> ////////////////////////////////////////////////////////////
>>> ///////////////////////////////
>>> To call in the statistician after the experiment is done may be no more
>>> than asking him to perform a post-mortem examination: he may be able to say
>>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>>> The plural of anecdote is not data. ~ Roger Brinner
>>> The combination of some data and an aching desire for an answer does not
>>> ensure that a reasonable answer can be extracted from a given body of data.
>>> ~ John Tukey
>>> ////////////////////////////////////////////////////////////
>>> ///////////////////////////////
>>>
>>> <https://www.inbo.be>
>>>
>>> 2018-07-25 22:05 GMT+02:00 Scott LaPoint <sdlapoint at gmail.com>:
>>>
>>>> Thank you Paul, I appreciate your time. And, apologies if my
>>>> understanding
>>>> is often incomplete.
>>>>
>>>>
>>>> Hi Scott,
>>>> >
>>>> > An incomplete answer?
>>>> >
>>>> > > 1. Is a Gamma distribution best for my distance data? If so, which
>>>> link
>>>> > > function is most appropriate? I explored two link functions:
>>>> identity and
>>>> > > log. I have concerns and see potential issues with both (see my
>>>> > annotations
>>>> > > in the reproducible example below.
>>>> >
>>>> > I don?t know (I haven?t run your code) but I?ve always somehow
>>>> managed to
>>>> > avoid gamma regression for strictly positive data by logging the
>>>> response
>>>> > and fitting a model with normal errors.
>>>> >
>>>>
>>>> If possible, I'd rather not transform the raw data to facilitate
>>>> interpretation of the coefficient estimates. I'm likely naive or
>>>> misunderstanding something though. Log transforming the distance data
>>>> does
>>>> produce a reasonably normal distribution. The following two models have
>>>> very similar AIC, BIC, LogLik, etc. estimates and the p-values of the
>>>> fixed
>>>> effects produce similar interpretations. However, the fixed effects
>>>> estimates are quite different.
>>>>
>>>> gammaDist <- glmer(distance ~ CSs.lat + CSdirect + CSstart + year +
>>>> age*sex
>>>> + (1|id), data = birds, family = Gamma(link = log), nAGQ = 10, control =
>>>> glmerControl(optimizer = "bobyqa"))
>>>> summary(gammaDist)
>>>>
>>>> logGausDist <- glmer(log(distance) ~ CSs.lat + CSdirect + CSstart +
>>>> year +
>>>> age*sex + (1|id), data = birds, family = gaussian(link = log), nAGQ =
>>>> 10,
>>>> control = glmerControl(optimizer = "bobyqa"))
>>>> summary(logGausDist)
>>>>
>>>> The interpretation from these two models are mostly the same: only
>>>> starting
>>>> latitude is a marginally significant predictor of bird migration
>>>> distance.
>>>> Correct?
>>>>
>>>>
>>>> > 2.  If the log link is the best or most appropriate to use, then the
>>>> > > summary(mDist) produces a sd of the random effect = 0 with the
>>>> bobyqa
>>>> > > optimizer. Switching to Nelder_Mead gives a reasonable sd, but
>>>> throws a
>>>> > > convergence warning.
>>>> >
>>>> > (For clarity, I assume that by "sd of the random effect? you mean the
>>>> > square root of the variance parameter that gauges residual inter-bird
>>>> > variation in mean distance and not the SD of the estimate of that
>>>> > parameter, which anyway isn?t output by glmer.)
>>>> >
>>>> > Why is a random effect variance estimate of zero implausible? I would
>>>> > trust a converged estimate over a non-converged estimate, regardless
>>>> of
>>>> > whether the estimate is zero. Also? you could compare the
>>>> log-likelihoods
>>>> > using logLik() ?  you?d expect the converged fit to have a higher LL.
>>>> For
>>>> > more general troubleshooting of convergence warnings:
>>>> > http://rpubs.com/bbolker/lme4trouble1
>>>>
>>>>
>>>> Yes, I believe your assumption is correct. In case I am wrong, I'm
>>>> referring to these estimates from the summary(model) output:
>>>> Random effects:
>>>>  Groups   Name        Variance Std.Dev.
>>>>  id       (Intercept) 0.00000  0.0000
>>>>  Residual             0.02879  0.1697
>>>> Number of obs: 137, groups:  id, 79
>>>>
>>>> The reason I said that a Std.Dev. = 0 is implausible is because the
>>>> ecologist in me says that there is no way that individual birds do not
>>>> vary
>>>> between each other (or even within for birds with multiple migration
>>>> route
>>>> data). Am I misunderstanding the meaning of the Std.Dev here?
>>>>
>>>>
>>>> > Another quick check I often do is to fit the non-converged model with
>>>> > glmmTMB (which appears to be more robust than lme4), and compare
>>>> > likelihoods and estimates with lme4.
>>>> >
>>>> > A quick and dirty model fit assessment is to simulate from the fitted
>>>> > model (which is as easy as simulate(my.fit)), and see if the simulated
>>>> > responses look more or less like the real responses.
>>>> >
>>>> > Good luck,
>>>> > Paul
>>>> >
>>>> >
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>
>>>
>>
>

	[[alternative HTML version deleted]]


From y@@hree19 @ending from gm@il@com  Fri Jul 27 20:22:35 2018
From: y@@hree19 @ending from gm@il@com (Yashree Mehta)
Date: Fri, 27 Jul 2018 20:22:35 +0200
Subject: [R-sig-ME] Correlation between fixed effect and random intercept
Message-ID: <CAOE=hqK1RA+LEqeWB8Y30X9DXsF=87Gd3zcjPpm2N5u1Y+z-wg@mail.gmail.com>

Hi,
I am working with a random intercept model. I have the usual "X" vector of
covariates and one id variable which will make up the random intercept.
For example,
Response variable: Production of maize
Covariate: Size of plot
ID variable: Household_ID

I need to acknowledge that there is correlation between the FIXED EFFECT
coefficient of plot size and the estimated random intercept. It is my model
assumption.

Does lme4 assume this correlation or do I have to make changes in the
formula so that it gets considered?

Thank you!

Regards,
Yashree

	[[alternative HTML version deleted]]


From john@poul@en @ending from duke@edu  Fri Jul 27 20:57:51 2018
From: john@poul@en @ending from duke@edu (John Poulsen, Ph.D.)
Date: Fri, 27 Jul 2018 18:57:51 +0000
Subject: [R-sig-ME] random effects specified in re.form that were not
 present in original model
Message-ID: <CF676168-3D4F-4102-8C4A-71A85D7F8F0D@contoso.com>

Hello --
I am trying to predict from a non-linear mixed model over just part of the range of one of the variables - 'depth', but am having problems with the specification of the random effect term using simulate(). Here is a reproducible dataset, the model, and my attempts at simulating responses.
soildata = data.frame(plot2b = rep(1:10, each=10), depth = rep(seq(1,2,length=10), 10), resp = rnorm(n = 100, 0.86, 0.76))

invpoly.f <- deriv(~depth/(a+b*depth), namevec=c('a', 'b'), function.arg=c('depth', 'a', 'b'))

 fit.invpoly <- nlmer(resp ~ invpoly.f(depth, a, b) ~ depth|plot2b, start=list(nlpars=c(a=1, b=0.5)), data=soildata)
newdat <- data.frame(plot2b = soildata$plot2b, depth = rep(seq(1.5, 2,length=10), 10))

simulate(fit.invpoly, newdata = newdat, re.form=NULL, seed = 1, nsim = 1)

simulate(fit.invpoly, newdata = newdat, re.form=(depth|plot2b), seed = 1, nsim = 1)
simulate(fit.invpoly, newdata = newdat, re.form=(1|plot2b), seed = 1, nsim = 1)

The first attempt at simulating, produces: Error in FUN(X[[i]], ...) : random effects specified in re.form that were not present in original model
The second two attempts produce: Error in mkNewReTrms(object, rfd, re.form, na.action = na.action, allow.new.levels = allow.new.levels) : object 'ReTrms' not found
Any guidance for what I am doing wrong would be appreciated.
Thanks,
John



	[[alternative HTML version deleted]]


From guill@ume@imon@@2 @ending from gm@il@com  Mon Jul 30 10:59:46 2018
From: guill@ume@imon@@2 @ending from gm@il@com (Guillaume Adeux)
Date: Mon, 30 Jul 2018 10:59:46 +0200
Subject: [R-sig-ME] Anova (type III-tests) table based on LRT for glmmTMB
 models
Message-ID: <CAENiVe9u5TktdrwYxrJT3R0KAECRzDB8kahOk2YifwZCX5u5ig@mail.gmail.com>

Hello everyone,

I'm looking for a method/function in order to produce an Anova table based
on Likelihood Ratio Tests (LRT) for a glmmTMB model (R software). In my
case it is with a beta distribution and log link. My response is a ratio
(%) in a repeated measures design.

   -

   the function Anova() from the {car} package doesn't not run on single
   models (i.e. Anova(mod)). It only allows comparison of two models (i.e.
   Anova(mod,mod1)).
   -

   for glmer models, I was used to using the mixed() function from the
   {afex} packages which produced Anova tables (type III tests) based on LRT
   (or parametric bootstrap) for glmms.

Could anyone shed their on light on a function like mixed() which would run
on glmmTMB objects or on a procedure to do this by hand?

I suppose if only one fixed predictor was present in the model, this would
be simple by comparing it to a null model but my model contains an
interaction. Hence, I am incable of comparing a model A+B+B:C with a model
containing A+B:C.

Thanks for your interest.

Guillaume ADEUX

	[[alternative HTML version deleted]]


From mollieebrook@ @ending from gm@il@com  Mon Jul 30 11:04:58 2018
From: mollieebrook@ @ending from gm@il@com (Mollie Brooks)
Date: Mon, 30 Jul 2018 11:04:58 +0200
Subject: [R-sig-ME] 
 Anova (type III-tests) table based on LRT for glmmTMB models
In-Reply-To: <CAENiVe9u5TktdrwYxrJT3R0KAECRzDB8kahOk2YifwZCX5u5ig@mail.gmail.com>
References: <CAENiVe9u5TktdrwYxrJT3R0KAECRzDB8kahOk2YifwZCX5u5ig@mail.gmail.com>
Message-ID: <617858C2-04F9-44BA-8E22-4414F4272338@gmail.com>

Hi Guillaume,

I?m not very experienced with Anova, but I know the development version of glmmTMB supports car::Anova. Ben recently added this functionality.

To install the development version try devtools::install_github("glmmTMB/glmmTMB/glmmTMB")
or see further instructions here https://github.com/glmmTMB/glmmTMB

After installing, check out vignette("model_evaluation")

cheers,
Mollie

> On 30Jul 2018, at 10:59, Guillaume Adeux <guillaumesimon.a2 at gmail.com> wrote:
> 
> Hello everyone,
> 
> I'm looking for a method/function in order to produce an Anova table based
> on Likelihood Ratio Tests (LRT) for a glmmTMB model (R software). In my
> case it is with a beta distribution and log link. My response is a ratio
> (%) in a repeated measures design.
> 
>   -
> 
>   the function Anova() from the {car} package doesn't not run on single
>   models (i.e. Anova(mod)). It only allows comparison of two models (i.e.
>   Anova(mod,mod1)).
>   -
> 
>   for glmer models, I was used to using the mixed() function from the
>   {afex} packages which produced Anova tables (type III tests) based on LRT
>   (or parametric bootstrap) for glmms.
> 
> Could anyone shed their on light on a function like mixed() which would run
> on glmmTMB objects or on a procedure to do this by hand?
> 
> I suppose if only one fixed predictor was present in the model, this would
> be simple by comparing it to a null model but my model contains an
> interaction. Hence, I am incable of comparing a model A+B+B:C with a model
> containing A+B:C.
> 
> Thanks for your interest.
> 
> Guillaume ADEUX
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


	[[alternative HTML version deleted]]


From phillip@@ld@y @ending from mpi@nl  Mon Jul 30 14:38:36 2018
From: phillip@@ld@y @ending from mpi@nl (Phillip Alday)
Date: Mon, 30 Jul 2018 14:38:36 +0200
Subject: [R-sig-ME] Model average error message
In-Reply-To: <VI1PR1001MB1390B65BF59F52547F1F991DAE540@VI1PR1001MB1390.EURPRD10.PROD.OUTLOOK.COM>
References: <DB6PR1001MB138280A451E5B703AB9BCE80AE560@DB6PR1001MB1382.EURPRD10.PROD.OUTLOOK.COM>
 <e5c92d4e-400f-aaf4-01fd-5e41d14ecdaf@mpi.nl>
 <VI1PR1001MB1390F1430CCBE7C331E9E235AE540@VI1PR1001MB1390.EURPRD10.PROD.OUTLOOK.COM>
 <35689173-80dc-0cc6-e647-acd629107a85@mpi.nl>
 <VI1PR1001MB1390468968C6E3AA04E05A4BAE540@VI1PR1001MB1390.EURPRD10.PROD.OUTLOOK.COM>
 <VI1PR1001MB1390B65BF59F52547F1F991DAE540@VI1PR1001MB1390.EURPRD10.PROD.OUTLOOK.COM>
Message-ID: <3c409039-9532-369f-765f-ae37fd9fde06@mpi.nl>

In a previous message, one of the warnings was '2=3=4'. Assuming that
there's nothing weird about any internal sorting, that would mean these
models:

~ d + p + s + t + (1 | random) + d:t + p:s + p:t + s:t
~ d + p + s + t + (1 | random) + d:t + p:s + p:t + s:t + p:s:t
~ d + p + s + t + (1 | random) + d:p + p:s + p:t + s:t + p:s:t

They are similar but not identical in formula form: the first one is
missing the three-way interaction, while the the last two differ in the
two-way interaction involving d (d:t vs d:p). Are the models rank
deficient? i.e. are there combinations of factors that don't exist such
that these model terms get dropped? Try looking at these models and
seeing if there if a term is missing:

summary(get.models(models,subset=delta<5)$`9168`)

Or maybe see if the effective terms in each model are equivalent:

mod3 <- get.models(models,subset=delta<5)$`9168`
mod4 <- get.models(models,subset=delta<5)$`9120`

mean(sort(names(fixef(mod3))) == sort(names(fixef(mod4))))

If that last line return 1, then the models have identical fixed
effects, which combined with their identical random effects, you indeed
make them identical.

And this is a rather weird error -- I'm also grasping at straws here.

Phillip


From j@orkin @ending from @om@um@ryl@nd@edu  Mon Jul 30 17:58:08 2018
From: j@orkin @ending from @om@um@ryl@nd@edu (Sorkin, John)
Date: Mon, 30 Jul 2018 15:58:08 +0000
Subject: [R-sig-ME] 
 Anova (type III-tests) table based on LRT for glmmTMB models
In-Reply-To: <CAENiVe9u5TktdrwYxrJT3R0KAECRzDB8kahOk2YifwZCX5u5ig@mail.gmail.com>
References: <CAENiVe9u5TktdrwYxrJT3R0KAECRzDB8kahOk2YifwZCX5u5ig@mail.gmail.com>
Message-ID: <CO2PR03MB2232BEAC4E1C203593771EB7E22F0@CO2PR03MB2232.namprd03.prod.outlook.com>

Guillaume,

Although not a perfect answer to your question, and I am not certain it will work with glmmTMB, I suggest you look at the drop1 function. It may give you an answer that you can use.

John


John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing)



________________________________
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of Guillaume Adeux <guillaumesimon.a2 at gmail.com>
Sent: Monday, July 30, 2018 4:59 AM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] Anova (type III-tests) table based on LRT for glmmTMB models

CAUTION: This message originated from a non UMB, UMSOM, FPI, or UMMS email system. Whether the sender is known or not known, hover over any links before clicking and use caution opening attachments.



Hello everyone,

I'm looking for a method/function in order to produce an Anova table based
on Likelihood Ratio Tests (LRT) for a glmmTMB model (R software). In my
case it is with a beta distribution and log link. My response is a ratio
(%) in a repeated measures design.

   -

   the function Anova() from the {car} package doesn't not run on single
   models (i.e. Anova(mod)). It only allows comparison of two models (i.e.
   Anova(mod,mod1)).
   -

   for glmer models, I was used to using the mixed() function from the
   {afex} packages which produced Anova tables (type III tests) based on LRT
   (or parametric bootstrap) for glmms.

Could anyone shed their on light on a function like mixed() which would run
on glmmTMB objects or on a procedure to do this by hand?

I suppose if only one fixed predictor was present in the model, this would
be simple by comparing it to a null model but my model contains an
interaction. Hence, I am incable of comparing a model A+B+B:C with a model
containing A+B:C.

Thanks for your interest.

Guillaume ADEUX

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From helenmcc@llin @ending from hotm@il@com  Mon Jul 30 21:56:27 2018
From: helenmcc@llin @ending from hotm@il@com (Helen McCallin)
Date: Mon, 30 Jul 2018 19:56:27 +0000
Subject: [R-sig-ME] Model average error message
In-Reply-To: <3c409039-9532-369f-765f-ae37fd9fde06@mpi.nl>
References: <DB6PR1001MB138280A451E5B703AB9BCE80AE560@DB6PR1001MB1382.EURPRD10.PROD.OUTLOOK.COM>
 <e5c92d4e-400f-aaf4-01fd-5e41d14ecdaf@mpi.nl>
 <VI1PR1001MB1390F1430CCBE7C331E9E235AE540@VI1PR1001MB1390.EURPRD10.PROD.OUTLOOK.COM>
 <35689173-80dc-0cc6-e647-acd629107a85@mpi.nl>
 <VI1PR1001MB1390468968C6E3AA04E05A4BAE540@VI1PR1001MB1390.EURPRD10.PROD.OUTLOOK.COM>
 <VI1PR1001MB1390B65BF59F52547F1F991DAE540@VI1PR1001MB1390.EURPRD10.PROD.OUTLOOK.COM>,
 <3c409039-9532-369f-765f-ae37fd9fde06@mpi.nl>
Message-ID: <DB6PR1001MB13826E04643BCF8B7116B556AE2F0@DB6PR1001MB1382.EURPRD10.PROD.OUTLOOK.COM>

Hi Phillip

Thank you for your reply. 

I got the following output for the mean code  0.5714286. Would I need to try something further with this? 

Many thanks again for your help.

Helen 



> On 30 Jul 2018, at 13:38, Phillip Alday <phillip.alday at mpi.nl> wrote:
> 
> In a previous message, one of the warnings was '2=3=4'. Assuming that
> there's nothing weird about any internal sorting, that would mean these
> models:
> 
> ~ d + p + s + t + (1 | random) + d:t + p:s + p:t + s:t
> ~ d + p + s + t + (1 | random) + d:t + p:s + p:t + s:t + p:s:t
> ~ d + p + s + t + (1 | random) + d:p + p:s + p:t + s:t + p:s:t
> 
> They are similar but not identical in formula form: the first one is
> missing the three-way interaction, while the the last two differ in the
> two-way interaction involving d (d:t vs d:p). Are the models rank
> deficient? i.e. are there combinations of factors that don't exist such
> that these model terms get dropped? Try looking at these models and
> seeing if there if a term is missing:
> 
> summary(get.models(models,subset=delta<5)$`9168`)
> 
> Or maybe see if the effective terms in each model are equivalent:
> 
> mod3 <- get.models(models,subset=delta<5)$`9168`
> mod4 <- get.models(models,subset=delta<5)$`9120`
> 
> mean(sort(names(fixef(mod3))) == sort(names(fixef(mod4))))
> 
> If that last line return 1, then the models have identical fixed
> effects, which combined with their identical random effects, you indeed
> make them identical.
> 
> And this is a rather weird error -- I'm also grasping at straws here.
> 
> Phillip


From bbolker @ending from gm@il@com  Mon Jul 30 23:40:23 2018
From: bbolker @ending from gm@il@com (Ben Bolker)
Date: Mon, 30 Jul 2018 17:40:23 -0400
Subject: [R-sig-ME] 
 Anova (type III-tests) table based on LRT for glmmTMB models
In-Reply-To: <617858C2-04F9-44BA-8E22-4414F4272338@gmail.com>
References: <CAENiVe9u5TktdrwYxrJT3R0KAECRzDB8kahOk2YifwZCX5u5ig@mail.gmail.com>
 <617858C2-04F9-44BA-8E22-4414F4272338@gmail.com>
Message-ID: <CABghstR1XW7ebtqN_6O3a+GxfJYnWF+kmooAeQudD_zcCnXzFQ@mail.gmail.com>

car::Anova only does Wald tests.

I don't know whether drop1() works, although if not it would be worth
seeing what it would take to make it work.

"Type 3" ANOVA is tricky in R, even with drop1() constructs, because
it sometimes requires constructing model matrices that R won't easily
provide.  For example: if A and B are both factors, then ~A:B as
constructed by model.matrix() will still include the main effects.
The only way I know of to do it is to use ~1+A+B+A:B (or equivalently
~A*B) and then drop or zero-out the unwanted columns of the model
matrix.

afex::mixed has some nice type-3 constructs, I don't remember exactly
how they work.

On Mon, Jul 30, 2018 at 5:05 AM Mollie Brooks <mollieebrooks at gmail.com> wrote:
>
> Hi Guillaume,
>
> I?m not very experienced with Anova, but I know the development version of glmmTMB supports car::Anova. Ben recently added this functionality.
>
> To install the development version try devtools::install_github("glmmTMB/glmmTMB/glmmTMB")
> or see further instructions here https://github.com/glmmTMB/glmmTMB
>
> After installing, check out vignette("model_evaluation")
>
> cheers,
> Mollie
>
> > On 30Jul 2018, at 10:59, Guillaume Adeux <guillaumesimon.a2 at gmail.com> wrote:
> >
> > Hello everyone,
> >
> > I'm looking for a method/function in order to produce an Anova table based
> > on Likelihood Ratio Tests (LRT) for a glmmTMB model (R software). In my
> > case it is with a beta distribution and log link. My response is a ratio
> > (%) in a repeated measures design.
> >
> >   -
> >
> >   the function Anova() from the {car} package doesn't not run on single
> >   models (i.e. Anova(mod)). It only allows comparison of two models (i.e.
> >   Anova(mod,mod1)).
> >   -
> >
> >   for glmer models, I was used to using the mixed() function from the
> >   {afex} packages which produced Anova tables (type III tests) based on LRT
> >   (or parametric bootstrap) for glmms.
> >
> > Could anyone shed their on light on a function like mixed() which would run
> > on glmmTMB objects or on a procedure to do this by hand?
> >
> > I suppose if only one fixed predictor was present in the model, this would
> > be simple by comparing it to a null model but my model contains an
> > interaction. Hence, I am incable of comparing a model A+B+B:C with a model
> > containing A+B:C.
> >
> > Thanks for your interest.
> >
> > Guillaume ADEUX
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From john@m@indon@ld @ending from @nu@edu@@u  Tue Jul 31 00:44:36 2018
From: john@m@indon@ld @ending from @nu@edu@@u (John Maindonald)
Date: Mon, 30 Jul 2018 22:44:36 +0000
Subject: [R-sig-ME] 
 Anova (type III-tests) table based on LRT for glmmTMB models
In-Reply-To: <CABghstR1XW7ebtqN_6O3a+GxfJYnWF+kmooAeQudD_zcCnXzFQ@mail.gmail.com>
References: <CAENiVe9u5TktdrwYxrJT3R0KAECRzDB8kahOk2YifwZCX5u5ig@mail.gmail.com>
 <617858C2-04F9-44BA-8E22-4414F4272338@gmail.com>
 <CABghstR1XW7ebtqN_6O3a+GxfJYnWF+kmooAeQudD_zcCnXzFQ@mail.gmail.com>
Message-ID: <13132573-3E12-460D-A16A-885B39BC18D2@anu.edu.au>

On Type III tests, I note that pp.24-26 of the document give a comprehensive
account.
afex::introduction-mixed-models<http://127.0.0.1:11966/help/library/afex/doc/introduction-mixed-models.pdf>
NB that in suitably ?balanced? designs, type III sums of squares are not in
contention.

The complication is that a term A:B, when A and B do not appear in the model
formula, results in general in fitted values and in a contribution to the anova
sum of squares (this gets more complicated in multi-level models) that depend
on how A and B are parameterized (?treatment?, or ?sum?, or ? contrasts).
One needs to think very carefully about the specific meaning that might attach
to any specific type 3 test and/or to the estimates that remain when lower order
terms are left out.  In models with several factors and/or covariates, the
complications of interpretation that result will often be just one more unhelpful
source of confusion.

Any model selection process changes the meaning that should be attached to
the p-values in the model that remains, with the extent of the change cumulating
as more terms are omitted.  The result may readily be that p-values that appear
?highly significant?, in the model that results and with no account taken of
selection effects, should really suggest ?not at all significant?.


John Maindonald             email: john.maindonald at anu.edu.au<mailto:john.maindonald at anu.edu.au>

On 31/07/2018, at 09:40, Ben Bolker <bbolker at gmail.com<mailto:bbolker at gmail.com>> wrote:

car::Anova only does Wald tests.

I don't know whether drop1() works, although if not it would be worth
seeing what it would take to make it work.

"Type 3" ANOVA is tricky in R, even with drop1() constructs, because
it sometimes requires constructing model matrices that R won't easily
provide.  For example: if A and B are both factors, then ~A:B as
constructed by model.matrix() will still include the main effects.
The only way I know of to do it is to use ~1+A+B+A:B (or equivalently
~A*B) and then drop or zero-out the unwanted columns of the model
matrix.

afex::mixed has some nice type-3 constructs, I don't remember exactly
how they work.

On Mon, Jul 30, 2018 at 5:05 AM Mollie Brooks <mollieebrooks at gmail.com<mailto:mollieebrooks at gmail.com>> wrote:

Hi Guillaume,

I?m not very experienced with Anova, but I know the development version of glmmTMB supports car::Anova. Ben recently added this functionality.

To install the development version try devtools::install_github("glmmTMB/glmmTMB/glmmTMB")
or see further instructions here https://github.com/glmmTMB/glmmTMB

After installing, check out vignette("model_evaluation")

cheers,
Mollie

On 30Jul 2018, at 10:59, Guillaume Adeux <guillaumesimon.a2 at gmail.com<mailto:guillaumesimon.a2 at gmail.com>> wrote:

Hello everyone,

I'm looking for a method/function in order to produce an Anova table based
on Likelihood Ratio Tests (LRT) for a glmmTMB model (R software). In my
case it is with a beta distribution and log link. My response is a ratio
(%) in a repeated measures design.

 -

 the function Anova() from the {car} package doesn't not run on single
 models (i.e. Anova(mod)). It only allows comparison of two models (i.e.
 Anova(mod,mod1)).
 -

 for glmer models, I was used to using the mixed() function from the
 {afex} packages which produced Anova tables (type III tests) based on LRT
 (or parametric bootstrap) for glmms.

Could anyone shed their on light on a function like mixed() which would run
on glmmTMB objects or on a procedure to do this by hand?

I suppose if only one fixed predictor was present in the model, this would
be simple by comparing it to a null model but my model contains an
interaction. Hence, I am incable of comparing a model A+B+B:C with a model
containing A+B:C.

Thanks for your interest.

Guillaume ADEUX

     [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


       [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


	[[alternative HTML version deleted]]


From j@orkin @ending from @om@um@ryl@nd@edu  Tue Jul 31 03:46:24 2018
From: j@orkin @ending from @om@um@ryl@nd@edu (Sorkin, John)
Date: Tue, 31 Jul 2018 01:46:24 +0000
Subject: [R-sig-ME] 
 Anova (type III-tests) table based on LRT for glmmTMB models
In-Reply-To: <13132573-3E12-460D-A16A-885B39BC18D2@anu.edu.au>
References: <CAENiVe9u5TktdrwYxrJT3R0KAECRzDB8kahOk2YifwZCX5u5ig@mail.gmail.com>
 <617858C2-04F9-44BA-8E22-4414F4272338@gmail.com>
 <CABghstR1XW7ebtqN_6O3a+GxfJYnWF+kmooAeQudD_zcCnXzFQ@mail.gmail.com>,
 <13132573-3E12-460D-A16A-885B39BC18D2@anu.edu.au>
Message-ID: <CO2PR03MB223269B0DDFE99BDCF45D8F4E22E0@CO2PR03MB2232.namprd03.prod.outlook.com>

A model that contains an interaction without the  main effects that are included in the interaction is unusual. Before I would run, or publish, such a model, I would think long and hard.

John


John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing)



________________________________
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of John Maindonald <john.maindonald at anu.edu.au>
Sent: Monday, July 30, 2018 6:44 PM
To: Ben Bolker
Cc: R SIG Mixed Models
Subject: Re: [R-sig-ME] Anova (type III-tests) table based on LRT for glmmTMB models

CAUTION: This message originated from a non UMB, UMSOM, FPI, or UMMS email system. Whether the sender is known or not known, hover over any links before clicking and use caution opening attachments.



On Type III tests, I note that pp.24-26 of the document give a comprehensive
account.
afex::introduction-mixed-models<http://127.0.0.1:11966/help/library/afex/doc/introduction-mixed-models.pdf>
NB that in suitably ?balanced? designs, type III sums of squares are not in
contention.

The complication is that a term A:B, when A and B do not appear in the model
formula, results in general in fitted values and in a contribution to the anova
sum of squares (this gets more complicated in multi-level models) that depend
on how A and B are parameterized (?treatment?, or ?sum?, or ? contrasts).
One needs to think very carefully about the specific meaning that might attach
to any specific type 3 test and/or to the estimates that remain when lower order
terms are left out.  In models with several factors and/or covariates, the
complications of interpretation that result will often be just one more unhelpful
source of confusion.

Any model selection process changes the meaning that should be attached to
the p-values in the model that remains, with the extent of the change cumulating
as more terms are omitted.  The result may readily be that p-values that appear
?highly significant?, in the model that results and with no account taken of
selection effects, should really suggest ?not at all significant?.


John Maindonald             email: john.maindonald at anu.edu.au<mailto:john.maindonald at anu.edu.au>

On 31/07/2018, at 09:40, Ben Bolker <bbolker at gmail.com<mailto:bbolker at gmail.com>> wrote:

car::Anova only does Wald tests.

I don't know whether drop1() works, although if not it would be worth
seeing what it would take to make it work.

"Type 3" ANOVA is tricky in R, even with drop1() constructs, because
it sometimes requires constructing model matrices that R won't easily
provide.  For example: if A and B are both factors, then ~A:B as
constructed by model.matrix() will still include the main effects.
The only way I know of to do it is to use ~1+A+B+A:B (or equivalently
~A*B) and then drop or zero-out the unwanted columns of the model
matrix.

afex::mixed has some nice type-3 constructs, I don't remember exactly
how they work.

On Mon, Jul 30, 2018 at 5:05 AM Mollie Brooks <mollieebrooks at gmail.com<mailto:mollieebrooks at gmail.com>> wrote:

Hi Guillaume,

I?m not very experienced with Anova, but I know the development version of glmmTMB supports car::Anova. Ben recently added this functionality.

To install the development version try devtools::install_github("glmmTMB/glmmTMB/glmmTMB")
or see further instructions here https://github.com/glmmTMB/glmmTMB

After installing, check out vignette("model_evaluation")

cheers,
Mollie

On 30Jul 2018, at 10:59, Guillaume Adeux <guillaumesimon.a2 at gmail.com<mailto:guillaumesimon.a2 at gmail.com>> wrote:

Hello everyone,

I'm looking for a method/function in order to produce an Anova table based
on Likelihood Ratio Tests (LRT) for a glmmTMB model (R software). In my
case it is with a beta distribution and log link. My response is a ratio
(%) in a repeated measures design.

 -

 the function Anova() from the {car} package doesn't not run on single
 models (i.e. Anova(mod)). It only allows comparison of two models (i.e.
 Anova(mod,mod1)).
 -

 for glmer models, I was used to using the mixed() function from the
 {afex} packages which produced Anova tables (type III tests) based on LRT
 (or parametric bootstrap) for glmms.

Could anyone shed their on light on a function like mixed() which would run
on glmmTMB objects or on a procedure to do this by hand?

I suppose if only one fixed predictor was present in the model, this would
be simple by comparing it to a null model but my model contains an
interaction. Hence, I am incable of comparing a model A+B+B:C with a model
containing A+B:C.

Thanks for your interest.

Guillaume ADEUX

     [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


       [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From drki@mu@@ @ending from gm@il@com  Tue Jul 31 08:24:46 2018
From: drki@mu@@ @ending from gm@il@com (K Imran M)
Date: Tue, 31 Jul 2018 14:24:46 +0800
Subject: [R-sig-ME] Should I include participants with baseline score only
 (missing afterwards) in a longitudinal study?
Message-ID: <CADop7+gHedKbD0Mer22A5q2k2wWNPGXNeew13PKEhgg=fyKnSQ@mail.gmail.com>

Hi everyone,

I did a longitudinal study where I collected functional score at 3
different times (baseline, 1 month after baseline and 3 months after
baseline) from 98 patients. There were 11 patients who died right after
baseline (so they have functional score at baseline only, and they did not
have the scores at 1 month after baseline or 3 months after baseline).

My question is should I remove 11 patients from the dataset (because they
only provide 1 score?)

What I did was, next , I run the nlme::lme function on 2 datasets, the
first dataset that contained 98 participants (11 with only 1 score at
baseline) and the second dataset with participants with at least 2 scores
(baseline + 1 month or baseline + 3 month or baseline + 1 month + 3 month).
I noticed the lme estimates for the two datasets are slightly different.
How can I explain this?

In the analysis above, I used a random intercept model (participants as the
random effect) with time (baseline, 1 month after baseline and 3 months
after baseline) treated as a factor variable. The covariate is age.

The datasets (edited due to privacy) are from this links:
dat.a (https://drive.google.com/open?id=1jAAFnrUfuTsVQST7EE3vjrh0_71ziAut)
dat.b (https://drive.google.com/open?id=1caGTd6SNnzbHSln84jw9b_lVHhnz7Qij)

And the R codes are here:
#######
library(haven)
dat.a <- read_dta("test_complete_data.dta")
dat.b <- read_dta("test_complete_with_at_discharge.dta")

# mixed model
library(nlme)
mod.dta.a <- lme(barthel ~ -1 + age + factor(time), random = ~1| id,
                          data = dat.a, na.action = 'na.omit', method =
'ML')
mod.dta.b <- lme(barthel ~ -1 + age + factor(time), random = ~1| id,
                 data = dat.b, na.action = 'na.omit', method = 'ML')

# res
summary(mod.dta.a)
summary(mod.dta.b)
#####


So let me rephrase the questions (Let us assume we are not interested in
the mechanism of missingness  but purely on the estimation from mixed model)
1) should I include patients that have only 1 measurement in a longitudinal
study in my model?
2) why the estimates are different from the dataset with at least 2 data on
follow-ups) vs the dataset that also contain participants with only 1 data
on follow-up? A simple explanation should be fine for me.

I apologize for my lack of math and stat skill. I really appreciate your
time in responding to this question.

Thank you.

Best wishes

Kamarul Imran
Universiti Sains Malaysia

	[[alternative HTML version deleted]]


From phillip@@ld@y @ending from mpi@nl  Tue Jul 31 15:28:05 2018
From: phillip@@ld@y @ending from mpi@nl (Phillip Alday)
Date: Tue, 31 Jul 2018 15:28:05 +0200
Subject: [R-sig-ME] Model average error message
In-Reply-To: <DB6PR1001MB13826E04643BCF8B7116B556AE2F0@DB6PR1001MB1382.EURPRD10.PROD.OUTLOOK.COM>
References: <DB6PR1001MB138280A451E5B703AB9BCE80AE560@DB6PR1001MB1382.EURPRD10.PROD.OUTLOOK.COM>
 <e5c92d4e-400f-aaf4-01fd-5e41d14ecdaf@mpi.nl>
 <VI1PR1001MB1390F1430CCBE7C331E9E235AE540@VI1PR1001MB1390.EURPRD10.PROD.OUTLOOK.COM>
 <35689173-80dc-0cc6-e647-acd629107a85@mpi.nl>
 <VI1PR1001MB1390468968C6E3AA04E05A4BAE540@VI1PR1001MB1390.EURPRD10.PROD.OUTLOOK.COM>
 <VI1PR1001MB1390B65BF59F52547F1F991DAE540@VI1PR1001MB1390.EURPRD10.PROD.OUTLOOK.COM>
 <3c409039-9532-369f-765f-ae37fd9fde06@mpi.nl>
 <DB6PR1001MB13826E04643BCF8B7116B556AE2F0@DB6PR1001MB1382.EURPRD10.PROD.OUTLOOK.COM>
Message-ID: <06795949-bf96-7d1d-74f8-e40f8520558e@mpi.nl>

That means the model terms aren't identical, which admittedly doesn't
exclude different parameterizations of the same model. I'm at a loss
here, and I don't have time to look at your data even if you were
willing to share, though others on this list may be willing to do so.

Consider filing a bug report with the package maintainer, including
documentation of the extra output you've generated for me.

Good luck.
Phillip

On 07/30/2018 09:56 PM, Helen McCallin wrote:
> Hi Phillip
> 
> Thank you for your reply. 
> 
> I got the following output for the mean code  0.5714286. Would I need to try something further with this? 
> 
> Many thanks again for your help.
> 
> Helen 
> 
> 
> 
>> On 30 Jul 2018, at 13:38, Phillip Alday <phillip.alday at mpi.nl> wrote:
>>
>> In a previous message, one of the warnings was '2=3=4'. Assuming that
>> there's nothing weird about any internal sorting, that would mean these
>> models:
>>
>> ~ d + p + s + t + (1 | random) + d:t + p:s + p:t + s:t
>> ~ d + p + s + t + (1 | random) + d:t + p:s + p:t + s:t + p:s:t
>> ~ d + p + s + t + (1 | random) + d:p + p:s + p:t + s:t + p:s:t
>>
>> They are similar but not identical in formula form: the first one is
>> missing the three-way interaction, while the the last two differ in the
>> two-way interaction involving d (d:t vs d:p). Are the models rank
>> deficient? i.e. are there combinations of factors that don't exist such
>> that these model terms get dropped? Try looking at these models and
>> seeing if there if a term is missing:
>>
>> summary(get.models(models,subset=delta<5)$`9168`)
>>
>> Or maybe see if the effective terms in each model are equivalent:
>>
>> mod3 <- get.models(models,subset=delta<5)$`9168`
>> mod4 <- get.models(models,subset=delta<5)$`9120`
>>
>> mean(sort(names(fixef(mod3))) == sort(names(fixef(mod4))))
>>
>> If that last line return 1, then the models have identical fixed
>> effects, which combined with their identical random effects, you indeed
>> make them identical.
>>
>> And this is a rather weird error -- I'm also grasping at straws here.
>>
>> Phillip


From phillip@@ld@y @ending from mpi@nl  Tue Jul 31 15:34:11 2018
From: phillip@@ld@y @ending from mpi@nl (Phillip Alday)
Date: Tue, 31 Jul 2018 15:34:11 +0200
Subject: [R-sig-ME] 
 Should I include participants with baseline score only
 (missing afterwards) in a longitudinal study?
In-Reply-To: <CADop7+gHedKbD0Mer22A5q2k2wWNPGXNeew13PKEhgg=fyKnSQ@mail.gmail.com>
References: <CADop7+gHedKbD0Mer22A5q2k2wWNPGXNeew13PKEhgg=fyKnSQ@mail.gmail.com>
Message-ID: <e102fbec-13a2-9c66-2656-d711553c0153@mpi.nl>

The model will additional baseline-only participants will have less
uncertainty about the estimates concerning the baseline. This reduced
uncertainty will help "pin" those values, which may also impact other
estimates.

As a simple example, think of a line passing through two points. Your
job is to determine the slope of the line, but this is made more
complicated by you not being totally certain about the position of the
two points. If can reduce the uncertainty in the position of just one
point, then this will still reduce the possible range of slopes and may
event cause your estimate of the slope to tend towards a
particular/different value.

As for your particular inference: I would tend to keep the data in so
that my estimates of function at baseline were as good as possible, even
though this extra data adds no information about function at 1 or 3
months. The loss in uncertainty of the location of the baseline is
potentially useful in its own right and may even help give better
estimates of the slope (=difference between baseline and subsequent
measurement) by creating additional constraints.

Phillip

On 07/31/2018 08:24 AM, K Imran M wrote:
> Hi everyone,
> 
> I did a longitudinal study where I collected functional score at 3
> different times (baseline, 1 month after baseline and 3 months after
> baseline) from 98 patients. There were 11 patients who died right after
> baseline (so they have functional score at baseline only, and they did not
> have the scores at 1 month after baseline or 3 months after baseline).
> 
> My question is should I remove 11 patients from the dataset (because they
> only provide 1 score?)
> 
> What I did was, next , I run the nlme::lme function on 2 datasets, the
> first dataset that contained 98 participants (11 with only 1 score at
> baseline) and the second dataset with participants with at least 2 scores
> (baseline + 1 month or baseline + 3 month or baseline + 1 month + 3 month).
> I noticed the lme estimates for the two datasets are slightly different.
> How can I explain this?
> 
> In the analysis above, I used a random intercept model (participants as the
> random effect) with time (baseline, 1 month after baseline and 3 months
> after baseline) treated as a factor variable. The covariate is age.
> 
> The datasets (edited due to privacy) are from this links:
> dat.a (https://drive.google.com/open?id=1jAAFnrUfuTsVQST7EE3vjrh0_71ziAut)
> dat.b (https://drive.google.com/open?id=1caGTd6SNnzbHSln84jw9b_lVHhnz7Qij)
> 
> And the R codes are here:
> #######
> library(haven)
> dat.a <- read_dta("test_complete_data.dta")
> dat.b <- read_dta("test_complete_with_at_discharge.dta")
> 
> # mixed model
> library(nlme)
> mod.dta.a <- lme(barthel ~ -1 + age + factor(time), random = ~1| id,
>                           data = dat.a, na.action = 'na.omit', method =
> 'ML')
> mod.dta.b <- lme(barthel ~ -1 + age + factor(time), random = ~1| id,
>                  data = dat.b, na.action = 'na.omit', method = 'ML')
> 
> # res
> summary(mod.dta.a)
> summary(mod.dta.b)
> #####
> 
> 
> So let me rephrase the questions (Let us assume we are not interested in
> the mechanism of missingness  but purely on the estimation from mixed model)
> 1) should I include patients that have only 1 measurement in a longitudinal
> study in my model?
> 2) why the estimates are different from the dataset with at least 2 data on
> follow-ups) vs the dataset that also contain participants with only 1 data
> on follow-up? A simple explanation should be fine for me.
> 
> I apologize for my lack of math and stat skill. I really appreciate your
> time in responding to this question.
> 
> Thank you.
> 
> Best wishes
> 
> Kamarul Imran
> Universiti Sains Malaysia
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From helenmcc@llin @ending from hotm@il@com  Tue Jul 31 15:55:57 2018
From: helenmcc@llin @ending from hotm@il@com (Helen McCallin)
Date: Tue, 31 Jul 2018 13:55:57 +0000
Subject: [R-sig-ME] Model average error message
In-Reply-To: <06795949-bf96-7d1d-74f8-e40f8520558e@mpi.nl>
References: <DB6PR1001MB138280A451E5B703AB9BCE80AE560@DB6PR1001MB1382.EURPRD10.PROD.OUTLOOK.COM>
 <e5c92d4e-400f-aaf4-01fd-5e41d14ecdaf@mpi.nl>
 <VI1PR1001MB1390F1430CCBE7C331E9E235AE540@VI1PR1001MB1390.EURPRD10.PROD.OUTLOOK.COM>
 <35689173-80dc-0cc6-e647-acd629107a85@mpi.nl>
 <VI1PR1001MB1390468968C6E3AA04E05A4BAE540@VI1PR1001MB1390.EURPRD10.PROD.OUTLOOK.COM>
 <VI1PR1001MB1390B65BF59F52547F1F991DAE540@VI1PR1001MB1390.EURPRD10.PROD.OUTLOOK.COM>
 <3c409039-9532-369f-765f-ae37fd9fde06@mpi.nl>
 <DB6PR1001MB13826E04643BCF8B7116B556AE2F0@DB6PR1001MB1382.EURPRD10.PROD.OUTLOOK.COM>,
 <06795949-bf96-7d1d-74f8-e40f8520558e@mpi.nl>
Message-ID: <DB6PR1001MB1382A2A23F2854389E4B7740AE2E0@DB6PR1001MB1382.EURPRD10.PROD.OUTLOOK.COM>

Hi Phillip

I understand and am very grateful for all the help you have given. 

Many thanks

Helen 

> On 31 Jul 2018, at 14:28, Phillip Alday <phillip.alday at mpi.nl> wrote:
> 
> That means the model terms aren't identical, which admittedly doesn't
> exclude different parameterizations of the same model. I'm at a loss
> here, and I don't have time to look at your data even if you were
> willing to share, though others on this list may be willing to do so.
> 
> Consider filing a bug report with the package maintainer, including
> documentation of the extra output you've generated for me.
> 
> Good luck.
> Phillip
> 
>> On 07/30/2018 09:56 PM, Helen McCallin wrote:
>> Hi Phillip
>> 
>> Thank you for your reply. 
>> 
>> I got the following output for the mean code  0.5714286. Would I need to try something further with this? 
>> 
>> Many thanks again for your help.
>> 
>> Helen 
>> 
>> 
>> 
>>> On 30 Jul 2018, at 13:38, Phillip Alday <phillip.alday at mpi.nl> wrote:
>>> 
>>> In a previous message, one of the warnings was '2=3=4'. Assuming that
>>> there's nothing weird about any internal sorting, that would mean these
>>> models:
>>> 
>>> ~ d + p + s + t + (1 | random) + d:t + p:s + p:t + s:t
>>> ~ d + p + s + t + (1 | random) + d:t + p:s + p:t + s:t + p:s:t
>>> ~ d + p + s + t + (1 | random) + d:p + p:s + p:t + s:t + p:s:t
>>> 
>>> They are similar but not identical in formula form: the first one is
>>> missing the three-way interaction, while the the last two differ in the
>>> two-way interaction involving d (d:t vs d:p). Are the models rank
>>> deficient? i.e. are there combinations of factors that don't exist such
>>> that these model terms get dropped? Try looking at these models and
>>> seeing if there if a term is missing:
>>> 
>>> summary(get.models(models,subset=delta<5)$`9168`)
>>> 
>>> Or maybe see if the effective terms in each model are equivalent:
>>> 
>>> mod3 <- get.models(models,subset=delta<5)$`9168`
>>> mod4 <- get.models(models,subset=delta<5)$`9120`
>>> 
>>> mean(sort(names(fixef(mod3))) == sort(names(fixef(mod4))))
>>> 
>>> If that last line return 1, then the models have identical fixed
>>> effects, which combined with their identical random effects, you indeed
>>> make them identical.
>>> 
>>> And this is a rather weird error -- I'm also grasping at straws here.
>>> 
>>> Phillip


From b@ron @ending from upenn@edu  Tue Jul 31 16:02:22 2018
From: b@ron @ending from upenn@edu (Jon Baron)
Date: Tue, 31 Jul 2018 10:02:22 -0400
Subject: [R-sig-ME] 
 Should I include participants with baseline score only
 (missing afterwards) in a longitudinal study?
In-Reply-To: <e102fbec-13a2-9c66-2656-d711553c0153@mpi.nl>
References: <CADop7+gHedKbD0Mer22A5q2k2wWNPGXNeew13PKEhgg=fyKnSQ@mail.gmail.com>
 <e102fbec-13a2-9c66-2656-d711553c0153@mpi.nl>
Message-ID: <20180731140222.GA15196@upenn.edu>

On 07/31/18 15:34, Phillip Alday wrote:
>The model will additional baseline-only participants will have less
>uncertainty about the estimates concerning the baseline. This reduced
>uncertainty will help "pin" those values, which may also impact other
>estimates.
>
>As a simple example, think of a line passing through two points. Your
>job is to determine the slope of the line, but this is made more
>complicated by you not being totally certain about the position of the
>two points. If can reduce the uncertainty in the position of just one
>point, then this will still reduce the possible range of slopes and may
>event cause your estimate of the slope to tend towards a
>particular/different value.
>
>As for your particular inference: I would tend to keep the data in so
>that my estimates of function at baseline were as good as possible, even
>though this extra data adds no information about function at 1 or 3
>months. The loss in uncertainty of the location of the baseline is
>potentially useful in its own right and may even help give better
>estimates of the slope (=difference between baseline and subsequent
>measurement) by creating additional constraints.
>
>Phillip

This makes sense if those who died after baseline did not differ
systematically from those who survived. But, if there is any reason for
the baseline measure to correlate with longevity, I think it would be
safer to remove the 11 subjects, even at the expense of some
additional error.

Jon

>On 07/31/2018 08:24 AM, K Imran M wrote:
>> Hi everyone,
>> 
>> I did a longitudinal study where I collected functional score at 3
>> different times (baseline, 1 month after baseline and 3 months after
>> baseline) from 98 patients. There were 11 patients who died right after
>> baseline (so they have functional score at baseline only, and they did not
>> have the scores at 1 month after baseline or 3 months after baseline).
>> 
>> My question is should I remove 11 patients from the dataset (because they
>> only provide 1 score?)
>> 
>> What I did was, next , I run the nlme::lme function on 2 datasets, the
>> first dataset that contained 98 participants (11 with only 1 score at
>> baseline) and the second dataset with participants with at least 2 scores
>> (baseline + 1 month or baseline + 3 month or baseline + 1 month + 3 month).
>> I noticed the lme estimates for the two datasets are slightly different.
>> How can I explain this?
>> 
>> In the analysis above, I used a random intercept model (participants as the
>> random effect) with time (baseline, 1 month after baseline and 3 months
>> after baseline) treated as a factor variable. The covariate is age.
>> 
>> The datasets (edited due to privacy) are from this links:
>> dat.a (https://drive.google.com/open?id=1jAAFnrUfuTsVQST7EE3vjrh0_71ziAut)
>> dat.b (https://drive.google.com/open?id=1caGTd6SNnzbHSln84jw9b_lVHhnz7Qij)
>> 
>> And the R codes are here:
>> #######
>> library(haven)
>> dat.a <- read_dta("test_complete_data.dta")
>> dat.b <- read_dta("test_complete_with_at_discharge.dta")
>> 
>> # mixed model
>> library(nlme)
>> mod.dta.a <- lme(barthel ~ -1 + age + factor(time), random = ~1| id,
>>                           data = dat.a, na.action = 'na.omit', method =
>> 'ML')
>> mod.dta.b <- lme(barthel ~ -1 + age + factor(time), random = ~1| id,
>>                  data = dat.b, na.action = 'na.omit', method = 'ML')
>> 
>> # res
>> summary(mod.dta.a)
>> summary(mod.dta.b)
>> #####
>> 
>> 
>> So let me rephrase the questions (Let us assume we are not interested in
>> the mechanism of missingness  but purely on the estimation from mixed model)
>> 1) should I include patients that have only 1 measurement in a longitudinal
>> study in my model?
>> 2) why the estimates are different from the dataset with at least 2 data on
>> follow-ups) vs the dataset that also contain participants with only 1 data
>> on follow-up? A simple explanation should be fine for me.
>> 
>> I apologize for my lack of math and stat skill. I really appreciate your
>> time in responding to this question.
>> 
>> Thank you.
>> 
>> Best wishes
>> 
>> Kamarul Imran
>> Universiti Sains Malaysia
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>_______________________________________________
>R-sig-mixed-models at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From phillip@@ld@y @ending from mpi@nl  Tue Jul 31 16:08:45 2018
From: phillip@@ld@y @ending from mpi@nl (Phillip Alday)
Date: Tue, 31 Jul 2018 16:08:45 +0200
Subject: [R-sig-ME] 
 Should I include participants with baseline score only
 (missing afterwards) in a longitudinal study?
In-Reply-To: <20180731140222.GA15196@upenn.edu>
References: <CADop7+gHedKbD0Mer22A5q2k2wWNPGXNeew13PKEhgg=fyKnSQ@mail.gmail.com>
 <e102fbec-13a2-9c66-2656-d711553c0153@mpi.nl>
 <20180731140222.GA15196@upenn.edu>
Message-ID: <b9c9d2c7-e497-af73-8ef1-595d55057871@mpi.nl>

Thanks for catching that, Jon,  I wasn't paying attention to the full
details of the study.

My implicit assumption was "missing at random". For missing not at
random, then you should either exclude the missings or model the
missingness explicitly with say a hurdle model.

Phillip

On 07/31/2018 04:02 PM, Jon Baron wrote:
> On 07/31/18 15:34, Phillip Alday wrote:
>> The model will additional baseline-only participants will have less
>> uncertainty about the estimates concerning the baseline. This reduced
>> uncertainty will help "pin" those values, which may also impact other
>> estimates.
>>
>> As a simple example, think of a line passing through two points. Your
>> job is to determine the slope of the line, but this is made more
>> complicated by you not being totally certain about the position of the
>> two points. If can reduce the uncertainty in the position of just one
>> point, then this will still reduce the possible range of slopes and may
>> event cause your estimate of the slope to tend towards a
>> particular/different value.
>>
>> As for your particular inference: I would tend to keep the data in so
>> that my estimates of function at baseline were as good as possible, even
>> though this extra data adds no information about function at 1 or 3
>> months. The loss in uncertainty of the location of the baseline is
>> potentially useful in its own right and may even help give better
>> estimates of the slope (=difference between baseline and subsequent
>> measurement) by creating additional constraints.
>>
>> Phillip
> 
> This makes sense if those who died after baseline did not differ
> systematically from those who survived. But, if there is any reason for
> the baseline measure to correlate with longevity, I think it would be
> safer to remove the 11 subjects, even at the expense of some
> additional error.
> 
> Jon
> 
>> On 07/31/2018 08:24 AM, K Imran M wrote:
>>> Hi everyone,
>>>
>>> I did a longitudinal study where I collected functional score at 3
>>> different times (baseline, 1 month after baseline and 3 months after
>>> baseline) from 98 patients. There were 11 patients who died right after
>>> baseline (so they have functional score at baseline only, and they
>>> did not
>>> have the scores at 1 month after baseline or 3 months after baseline).
>>>
>>> My question is should I remove 11 patients from the dataset (because
>>> they
>>> only provide 1 score?)
>>>
>>> What I did was, next , I run the nlme::lme function on 2 datasets, the
>>> first dataset that contained 98 participants (11 with only 1 score at
>>> baseline) and the second dataset with participants with at least 2
>>> scores
>>> (baseline + 1 month or baseline + 3 month or baseline + 1 month + 3
>>> month).
>>> I noticed the lme estimates for the two datasets are slightly different.
>>> How can I explain this?
>>>
>>> In the analysis above, I used a random intercept model (participants
>>> as the
>>> random effect) with time (baseline, 1 month after baseline and 3 months
>>> after baseline) treated as a factor variable. The covariate is age.
>>>
>>> The datasets (edited due to privacy) are from this links:
>>> dat.a
>>> (https://drive.google.com/open?id=1jAAFnrUfuTsVQST7EE3vjrh0_71ziAut)
>>> dat.b
>>> (https://drive.google.com/open?id=1caGTd6SNnzbHSln84jw9b_lVHhnz7Qij)
>>>
>>> And the R codes are here:
>>> #######
>>> library(haven)
>>> dat.a <- read_dta("test_complete_data.dta")
>>> dat.b <- read_dta("test_complete_with_at_discharge.dta")
>>>
>>> # mixed model
>>> library(nlme)
>>> mod.dta.a <- lme(barthel ~ -1 + age + factor(time), random = ~1| id,
>>>                           data = dat.a, na.action = 'na.omit', method =
>>> 'ML')
>>> mod.dta.b <- lme(barthel ~ -1 + age + factor(time), random = ~1| id,
>>>                  data = dat.b, na.action = 'na.omit', method = 'ML')
>>>
>>> # res
>>> summary(mod.dta.a)
>>> summary(mod.dta.b)
>>> #####
>>>
>>>
>>> So let me rephrase the questions (Let us assume we are not interested in
>>> the mechanism of missingness  but purely on the estimation from mixed
>>> model)
>>> 1) should I include patients that have only 1 measurement in a
>>> longitudinal
>>> study in my model?
>>> 2) why the estimates are different from the dataset with at least 2
>>> data on
>>> follow-ups) vs the dataset that also contain participants with only 1
>>> data
>>> on follow-up? A simple explanation should be fine for me.
>>>
>>> I apologize for my lack of math and stat skill. I really appreciate your
>>> time in responding to this question.
>>>
>>> Thank you.
>>>
>>> Best wishes
>>>
>>> Kamarul Imran
>>> Universiti Sains Malaysia
>>>
>>>     [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From drki@mu@@ @ending from gm@il@com  Tue Jul 31 18:18:15 2018
From: drki@mu@@ @ending from gm@il@com (K Imran M)
Date: Wed, 1 Aug 2018 00:18:15 +0800
Subject: [R-sig-ME] 
 Should I include participants with baseline score only
 (missing afterwards) in a longitudinal study?
In-Reply-To: <b9c9d2c7-e497-af73-8ef1-595d55057871@mpi.nl>
References: <CADop7+gHedKbD0Mer22A5q2k2wWNPGXNeew13PKEhgg=fyKnSQ@mail.gmail.com>
 <e102fbec-13a2-9c66-2656-d711553c0153@mpi.nl>
 <20180731140222.GA15196@upenn.edu>
 <b9c9d2c7-e497-af73-8ef1-595d55057871@mpi.nl>
Message-ID: <CADop7+hdoHWO=PfWMb+dUVKodh-5Q2RpNGRGvT4Sy_otiYo5TQ@mail.gmail.com>

Phillip and Jon,

Very2 helpful explanation and insight. Really appreciate it.

KIM

On Tue, Jul 31, 2018 at 10:08 PM Phillip Alday <phillip.alday at mpi.nl> wrote:

> Thanks for catching that, Jon,  I wasn't paying attention to the full
> details of the study.
>
> My implicit assumption was "missing at random". For missing not at
> random, then you should either exclude the missings or model the
> missingness explicitly with say a hurdle model.
>
> Phillip
>
> On 07/31/2018 04:02 PM, Jon Baron wrote:
> > On 07/31/18 15:34, Phillip Alday wrote:
> >> The model will additional baseline-only participants will have less
> >> uncertainty about the estimates concerning the baseline. This reduced
> >> uncertainty will help "pin" those values, which may also impact other
> >> estimates.
> >>
> >> As a simple example, think of a line passing through two points. Your
> >> job is to determine the slope of the line, but this is made more
> >> complicated by you not being totally certain about the position of the
> >> two points. If can reduce the uncertainty in the position of just one
> >> point, then this will still reduce the possible range of slopes and may
> >> event cause your estimate of the slope to tend towards a
> >> particular/different value.
> >>
> >> As for your particular inference: I would tend to keep the data in so
> >> that my estimates of function at baseline were as good as possible, even
> >> though this extra data adds no information about function at 1 or 3
> >> months. The loss in uncertainty of the location of the baseline is
> >> potentially useful in its own right and may even help give better
> >> estimates of the slope (=difference between baseline and subsequent
> >> measurement) by creating additional constraints.
> >>
> >> Phillip
> >
> > This makes sense if those who died after baseline did not differ
> > systematically from those who survived. But, if there is any reason for
> > the baseline measure to correlate with longevity, I think it would be
> > safer to remove the 11 subjects, even at the expense of some
> > additional error.
> >
> > Jon
> >
> >> On 07/31/2018 08:24 AM, K Imran M wrote:
> >>> Hi everyone,
> >>>
> >>> I did a longitudinal study where I collected functional score at 3
> >>> different times (baseline, 1 month after baseline and 3 months after
> >>> baseline) from 98 patients. There were 11 patients who died right after
> >>> baseline (so they have functional score at baseline only, and they
> >>> did not
> >>> have the scores at 1 month after baseline or 3 months after baseline).
> >>>
> >>> My question is should I remove 11 patients from the dataset (because
> >>> they
> >>> only provide 1 score?)
> >>>
> >>> What I did was, next , I run the nlme::lme function on 2 datasets, the
> >>> first dataset that contained 98 participants (11 with only 1 score at
> >>> baseline) and the second dataset with participants with at least 2
> >>> scores
> >>> (baseline + 1 month or baseline + 3 month or baseline + 1 month + 3
> >>> month).
> >>> I noticed the lme estimates for the two datasets are slightly
> different.
> >>> How can I explain this?
> >>>
> >>> In the analysis above, I used a random intercept model (participants
> >>> as the
> >>> random effect) with time (baseline, 1 month after baseline and 3 months
> >>> after baseline) treated as a factor variable. The covariate is age.
> >>>
> >>> The datasets (edited due to privacy) are from this links:
> >>> dat.a
> >>> (https://drive.google.com/open?id=1jAAFnrUfuTsVQST7EE3vjrh0_71ziAut)
> >>> dat.b
> >>> (https://drive.google.com/open?id=1caGTd6SNnzbHSln84jw9b_lVHhnz7Qij)
> >>>
> >>> And the R codes are here:
> >>> #######
> >>> library(haven)
> >>> dat.a <- read_dta("test_complete_data.dta")
> >>> dat.b <- read_dta("test_complete_with_at_discharge.dta")
> >>>
> >>> # mixed model
> >>> library(nlme)
> >>> mod.dta.a <- lme(barthel ~ -1 + age + factor(time), random = ~1| id,
> >>>                           data = dat.a, na.action = 'na.omit', method =
> >>> 'ML')
> >>> mod.dta.b <- lme(barthel ~ -1 + age + factor(time), random = ~1| id,
> >>>                  data = dat.b, na.action = 'na.omit', method = 'ML')
> >>>
> >>> # res
> >>> summary(mod.dta.a)
> >>> summary(mod.dta.b)
> >>> #####
> >>>
> >>>
> >>> So let me rephrase the questions (Let us assume we are not interested
> in
> >>> the mechanism of missingness  but purely on the estimation from mixed
> >>> model)
> >>> 1) should I include patients that have only 1 measurement in a
> >>> longitudinal
> >>> study in my model?
> >>> 2) why the estimates are different from the dataset with at least 2
> >>> data on
> >>> follow-ups) vs the dataset that also contain participants with only 1
> >>> data
> >>> on follow-up? A simple explanation should be fine for me.
> >>>
> >>> I apologize for my lack of math and stat skill. I really appreciate
> your
> >>> time in responding to this question.
> >>>
> >>> Thank you.
> >>>
> >>> Best wishes
> >>>
> >>> Kamarul Imran
> >>> Universiti Sains Malaysia
> >>>
> >>>     [[alternative HTML version deleted]]
> >>>
> >>> _______________________________________________
> >>> R-sig-mixed-models at r-project.org mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>>
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>

	[[alternative HTML version deleted]]


From peter@p@przycki @ending from gm@il@com  Thu Aug  2 05:30:15 2018
From: peter@p@przycki @ending from gm@il@com (Peter Paprzycki)
Date: Wed, 1 Aug 2018 22:30:15 -0500
Subject: [R-sig-ME] (no subject)
Message-ID: <CAM834X+x+gZr_m75cN5MkM-hjK3MWyJhY9HJBy8VzTydQSusrA@mail.gmail.com>

This is very basic, is there a way to specify in lmer function that I would
like to run my grouping variable as a fixed factor only, without reverting
to lm or plm functions. If one does not specify a random variable, one gets
the error message with lmer function; something that is equivalent to the
statement, "index = "grouping variable", model = "within"" with the plm
function.

<http://www.avg.com/email-signature?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
Virus-free.
www.avg.com
<http://www.avg.com/email-signature?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
<#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>

	[[alternative HTML version deleted]]


From bbolker @ending from gm@il@com  Thu Aug  2 05:57:38 2018
From: bbolker @ending from gm@il@com (Ben Bolker)
Date: Wed, 1 Aug 2018 23:57:38 -0400
Subject: [R-sig-ME] (no subject)
In-Reply-To: <CAM834XKtXfnLF0NVc98-G8Syu6dUZW20m+-34iqW+E2Dz-xWLQ@mail.gmail.com>
References: <CAM834X+x+gZr_m75cN5MkM-hjK3MWyJhY9HJBy8VzTydQSusrA@mail.gmail.com>
 <ec8f5787-693a-18af-516c-7e573786dbfa@gmail.com>
 <CAM834XKtXfnLF0NVc98-G8Syu6dUZW20m+-34iqW+E2Dz-xWLQ@mail.gmail.com>
Message-ID: <32ddc391-c0c2-4c8c-6c3b-b086de963d5c@gmail.com>


  (please keep r-sig-mixed-models in the Cc:)

  I'm pretty sure that lmer and lm models are commensurate, in case that
helps.  Here's an example rigged to make the random-effects variance
equal to zero, so we can check that the log-likelihoods etc. are identical.

set.seed(101)
dd <- data.frame(y=rnorm(20),x=rnorm(20),f=factor(rep(1:2,10)))
library(lme4)
m1 <- lmer(y~x+(1|f),data=dd,REML=FALSE) ## estimated sigma^2_f=0
m2 <- lm(y~x,data=dd)
all.equal(c(logLik(m1)),c(logLik(m2))) ## TRUE
all.equal(fixef(m1),coef(m2))
anova(m1,m2)


On 2018-08-01 11:41 PM, Peter Paprzycki wrote:
> Thank you. Oh, was just trying to compare my random-effects model to the
> one where my grouping variable (schools) is treated as fixed.
> 
> Peter
> 
> <http://www.avg.com/email-signature?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
> 	Virus-free. www.avg.com
> <http://www.avg.com/email-signature?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
> 
> 
> <#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>
> 
> On Wed, Aug 1, 2018 at 10:32 PM, Ben Bolker <bbolker at gmail.com
> <mailto:bbolker at gmail.com>> wrote:
> 
> 
>     ? I'm not 100% sure I understand the question, but I think the answer is
>     "no": lmer cannot fit a model that doesn't contain any random effects.
>     Perhaps you can give more context as to why it won't work for you to
>     revert to lm() or plm() in these cases?
> 
>     On 2018-08-01 11:30 PM, Peter Paprzycki wrote:
>     > This is very basic, is there a way to specify in lmer function
>     that I would
>     > like to run my grouping variable as a fixed factor only, without
>     reverting
>     > to lm or plm functions. If one does not specify a random variable,
>     one gets
>     > the error message with lmer function; something that is equivalent
>     to the
>     > statement, "index = "grouping variable", model = "within"" with
>     the plm
>     > function.
>     >
>     >
>     <http://www.avg.com/email-signature?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail
>     <http://www.avg.com/email-signature?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>>
>     > Virus-free.
>     > www.avg.com <http://www.avg.com>
>     >
>     <http://www.avg.com/email-signature?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail
>     <http://www.avg.com/email-signature?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>>
>     > <#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>
>     >
>     >? ? ? ?[[alternative HTML version deleted]]
>     >
>     > _______________________________________________
>     > R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>     > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>     >
> 
> 
> 
> 
> -- 
> 
> Peter Paprzycki, Ph.D.
> Visiting Assistant Professor
> Research Support Center Manager
> 
> Educational Research and Administration
> College of Education?and Psychology
> The University of Southern Mississippi
> USM Box 5093; 118 College Drive
> Hattiesburg, Mississippi 39406-0001
> tel. (601)-266-4708
> email: Peter.Paprzycki at usm.edu <mailto:Peter.Paprzycki at usm.edu>
> 
> 
> Sidere mens eadum mutato
>


From peter@p@przycki @ending from gm@il@com  Thu Aug  2 06:08:10 2018
From: peter@p@przycki @ending from gm@il@com (Peter Paprzycki)
Date: Wed, 1 Aug 2018 23:08:10 -0500
Subject: [R-sig-ME] (no subject)
In-Reply-To: <32ddc391-c0c2-4c8c-6c3b-b086de963d5c@gmail.com>
References: <CAM834X+x+gZr_m75cN5MkM-hjK3MWyJhY9HJBy8VzTydQSusrA@mail.gmail.com>
 <ec8f5787-693a-18af-516c-7e573786dbfa@gmail.com>
 <CAM834XKtXfnLF0NVc98-G8Syu6dUZW20m+-34iqW+E2Dz-xWLQ@mail.gmail.com>
 <32ddc391-c0c2-4c8c-6c3b-b086de963d5c@gmail.com>
Message-ID: <CAM834X+iZ7YFV5vgJqoVMe6WZmBwJjWY=2jHV7aUS231=tHpKA@mail.gmail.com>

Perfect. Thank you. It is good to know that we can specify the
random-effects variance
equal to zero. Thanks.
Peter

<http://www.avg.com/email-signature?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
Virus-free.
www.avg.com
<http://www.avg.com/email-signature?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
<#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>

On Wed, Aug 1, 2018 at 10:57 PM, Ben Bolker <bbolker at gmail.com> wrote:

>
>   (please keep r-sig-mixed-models in the Cc:)
>
>   I'm pretty sure that lmer and lm models are commensurate, in case that
> helps.  Here's an example rigged to make the random-effects variance
> equal to zero, so we can check that the log-likelihoods etc. are identical.
>
> set.seed(101)
> dd <- data.frame(y=rnorm(20),x=rnorm(20),f=factor(rep(1:2,10)))
> library(lme4)
> m1 <- lmer(y~x+(1|f),data=dd,REML=FALSE) ## estimated sigma^2_f=0
> m2 <- lm(y~x,data=dd)
> all.equal(c(logLik(m1)),c(logLik(m2))) ## TRUE
> all.equal(fixef(m1),coef(m2))
> anova(m1,m2)
>
>
> On 2018-08-01 11:41 PM, Peter Paprzycki wrote:
> > Thank you. Oh, was just trying to compare my random-effects model to the
> > one where my grouping variable (schools) is treated as fixed.
> >
> > Peter
> >
> > <http://www.avg.com/email-signature?utm_medium=email&
> utm_source=link&utm_campaign=sig-email&utm_content=webmail>
> >       Virus-free. www.avg.com
> > <http://www.avg.com/email-signature?utm_medium=email&
> utm_source=link&utm_campaign=sig-email&utm_content=webmail>
> >
> >
> > <#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>
> >
> > On Wed, Aug 1, 2018 at 10:32 PM, Ben Bolker <bbolker at gmail.com
> > <mailto:bbolker at gmail.com>> wrote:
> >
> >
> >       I'm not 100% sure I understand the question, but I think the
> answer is
> >     "no": lmer cannot fit a model that doesn't contain any random
> effects.
> >     Perhaps you can give more context as to why it won't work for you to
> >     revert to lm() or plm() in these cases?
> >
> >     On 2018-08-01 11:30 PM, Peter Paprzycki wrote:
> >     > This is very basic, is there a way to specify in lmer function
> >     that I would
> >     > like to run my grouping variable as a fixed factor only, without
> >     reverting
> >     > to lm or plm functions. If one does not specify a random variable,
> >     one gets
> >     > the error message with lmer function; something that is equivalent
> >     to the
> >     > statement, "index = "grouping variable", model = "within"" with
> >     the plm
> >     > function.
> >     >
> >     >
> >     <http://www.avg.com/email-signature?utm_medium=email&
> utm_source=link&utm_campaign=sig-email&utm_content=webmail
> >     <http://www.avg.com/email-signature?utm_medium=email&
> utm_source=link&utm_campaign=sig-email&utm_content=webmail>>
> >     > Virus-free.
> >     > www.avg.com <http://www.avg.com>
> >     >
> >     <http://www.avg.com/email-signature?utm_medium=email&
> utm_source=link&utm_campaign=sig-email&utm_content=webmail
> >     <http://www.avg.com/email-signature?utm_medium=email&
> utm_source=link&utm_campaign=sig-email&utm_content=webmail>>
> >     > <#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>
> >     >
> >     >       [[alternative HTML version deleted]]
> >     >
> >     > _______________________________________________
> >     > R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org> mailing list
> >     > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >     >
> >
> >
> >
> >
> > --
> >
> > Peter Paprzycki, Ph.D.
> > Visiting Assistant Professor
> > Research Support Center Manager
> >
> > Educational Research and Administration
> > College of Education and Psychology
> > The University of Southern Mississippi
> > USM Box 5093; 118 College Drive
> > Hattiesburg, Mississippi 39406-0001
> > tel. (601)-266-4708
> > email: Peter.Paprzycki at usm.edu <mailto:Peter.Paprzycki at usm.edu>
> >
> >
> > Sidere mens eadum mutato
> >
>



-- 

Peter Paprzycki, Ph.D.
Visiting Assistant Professor
Research Support Center Manager

Educational Research and Administration
College of Education and Psychology
The University of Southern Mississippi
USM Box 5093; 118 College Drive
Hattiesburg, Mississippi 39406-0001
tel. (601)-266-4708
email: Peter.Paprzycki at usm.edu


Sidere mens eadum mutato

	[[alternative HTML version deleted]]


From peter@p@przycki @ending from gm@il@com  Thu Aug  2 06:24:10 2018
From: peter@p@przycki @ending from gm@il@com (Peter Paprzycki)
Date: Wed, 1 Aug 2018 23:24:10 -0500
Subject: [R-sig-ME] (no subject)
In-Reply-To: <CAM834X+iZ7YFV5vgJqoVMe6WZmBwJjWY=2jHV7aUS231=tHpKA@mail.gmail.com>
References: <CAM834X+x+gZr_m75cN5MkM-hjK3MWyJhY9HJBy8VzTydQSusrA@mail.gmail.com>
 <ec8f5787-693a-18af-516c-7e573786dbfa@gmail.com>
 <CAM834XKtXfnLF0NVc98-G8Syu6dUZW20m+-34iqW+E2Dz-xWLQ@mail.gmail.com>
 <32ddc391-c0c2-4c8c-6c3b-b086de963d5c@gmail.com>
 <CAM834X+iZ7YFV5vgJqoVMe6WZmBwJjWY=2jHV7aUS231=tHpKA@mail.gmail.com>
Message-ID: <CAM834X+Kim0OQfGtVm2bgmXbPYS+K13Pju2Rwcj6nQAi9xHffg@mail.gmail.com>

Sorry, you estimated it to be very close to zero, I see.
Peter

On Wed, Aug 1, 2018 at 11:08 PM, Peter Paprzycki <peter.paprzycki at gmail.com>
wrote:

> Perfect. Thank you. It is good to know that we can specify the
> random-effects variance
> equal to zero. Thanks.
> Peter
>
>
> <http://www.avg.com/email-signature?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail> Virus-free.
> www.avg.com
> <http://www.avg.com/email-signature?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
> <#m_981606773260833816_DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>
>
> On Wed, Aug 1, 2018 at 10:57 PM, Ben Bolker <bbolker at gmail.com> wrote:
>
>>
>>   (please keep r-sig-mixed-models in the Cc:)
>>
>>   I'm pretty sure that lmer and lm models are commensurate, in case that
>> helps.  Here's an example rigged to make the random-effects variance
>> equal to zero, so we can check that the log-likelihoods etc. are
>> identical.
>>
>> set.seed(101)
>> dd <- data.frame(y=rnorm(20),x=rnorm(20),f=factor(rep(1:2,10)))
>> library(lme4)
>> m1 <- lmer(y~x+(1|f),data=dd,REML=FALSE) ## estimated sigma^2_f=0
>> m2 <- lm(y~x,data=dd)
>> all.equal(c(logLik(m1)),c(logLik(m2))) ## TRUE
>> all.equal(fixef(m1),coef(m2))
>> anova(m1,m2)
>>
>>
>> On 2018-08-01 11:41 PM, Peter Paprzycki wrote:
>> > Thank you. Oh, was just trying to compare my random-effects model to the
>> > one where my grouping variable (schools) is treated as fixed.
>> >
>> > Peter
>> >
>> > <http://www.avg.com/email-signature?utm_medium=email&utm_
>> source=link&utm_campaign=sig-email&utm_content=webmail>
>> >       Virus-free. www.avg.com
>> > <http://www.avg.com/email-signature?utm_medium=email&utm_
>> source=link&utm_campaign=sig-email&utm_content=webmail>
>> >
>> >
>> > <#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>
>> >
>> > On Wed, Aug 1, 2018 at 10:32 PM, Ben Bolker <bbolker at gmail.com
>> > <mailto:bbolker at gmail.com>> wrote:
>> >
>> >
>> >       I'm not 100% sure I understand the question, but I think the
>> answer is
>> >     "no": lmer cannot fit a model that doesn't contain any random
>> effects.
>> >     Perhaps you can give more context as to why it won't work for you to
>> >     revert to lm() or plm() in these cases?
>> >
>> >     On 2018-08-01 11:30 PM, Peter Paprzycki wrote:
>> >     > This is very basic, is there a way to specify in lmer function
>> >     that I would
>> >     > like to run my grouping variable as a fixed factor only, without
>> >     reverting
>> >     > to lm or plm functions. If one does not specify a random variable,
>> >     one gets
>> >     > the error message with lmer function; something that is equivalent
>> >     to the
>> >     > statement, "index = "grouping variable", model = "within"" with
>> >     the plm
>> >     > function.
>> >     >
>> >     >
>> >     <http://www.avg.com/email-signature?utm_medium=email&utm_
>> source=link&utm_campaign=sig-email&utm_content=webmail
>> >     <http://www.avg.com/email-signature?utm_medium=email&utm_
>> source=link&utm_campaign=sig-email&utm_content=webmail>>
>> >     > Virus-free.
>> >     > www.avg.com <http://www.avg.com>
>> >     >
>> >     <http://www.avg.com/email-signature?utm_medium=email&utm_
>> source=link&utm_campaign=sig-email&utm_content=webmail
>> >     <http://www.avg.com/email-signature?utm_medium=email&utm_
>> source=link&utm_campaign=sig-email&utm_content=webmail>>
>> >     > <#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>
>> >     >
>> >     >       [[alternative HTML version deleted]]
>> >     >
>> >     > _______________________________________________
>> >     > R-sig-mixed-models at r-project.org
>> >     <mailto:R-sig-mixed-models at r-project.org> mailing list
>> >     > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>> >     >
>> >
>> >
>> >
>> >
>> > --
>> >
>> > Peter Paprzycki, Ph.D.
>> > Visiting Assistant Professor
>> > Research Support Center Manager
>> >
>> > Educational Research and Administration
>> > College of Education and Psychology
>> > The University of Southern Mississippi
>> > USM Box 5093; 118 College Drive
>> > Hattiesburg, Mississippi 39406-0001
>> > tel. (601)-266-4708
>> > email: Peter.Paprzycki at usm.edu <mailto:Peter.Paprzycki at usm.edu>
>> >
>> >
>> > Sidere mens eadum mutato
>> >
>>
>
>
>
> --
>
> Peter Paprzycki, Ph.D.
> Visiting Assistant Professor
> Research Support Center Manager
>
> Educational Research and Administration
> College of Education and Psychology
> The University of Southern Mississippi
> USM Box 5093; 118 College Drive
> Hattiesburg, Mississippi 39406-0001
> tel. (601)-266-4708
> email: Peter.Paprzycki at usm.edu
>
>
> Sidere mens eadum mutato
>



-- 

Peter Paprzycki, Ph.D.
Visiting Assistant Professor
Research Support Center Manager

Educational Research and Administration
College of Education and Psychology
The University of Southern Mississippi
USM Box 5093; 118 College Drive
Hattiesburg, Mississippi 39406-0001
tel. (601)-266-4708
email: Peter.Paprzycki at usm.edu


Sidere mens eadum mutato

	[[alternative HTML version deleted]]


From bbolker @ending from gm@il@com  Thu Aug  2 07:26:27 2018
From: bbolker @ending from gm@il@com (Ben Bolker)
Date: Thu, 2 Aug 2018 01:26:27 -0400
Subject: [R-sig-ME] (no subject)
In-Reply-To: <CAM834X+Kim0OQfGtVm2bgmXbPYS+K13Pju2Rwcj6nQAi9xHffg@mail.gmail.com>
References: <CAM834X+x+gZr_m75cN5MkM-hjK3MWyJhY9HJBy8VzTydQSusrA@mail.gmail.com>
 <ec8f5787-693a-18af-516c-7e573786dbfa@gmail.com>
 <CAM834XKtXfnLF0NVc98-G8Syu6dUZW20m+-34iqW+E2Dz-xWLQ@mail.gmail.com>
 <32ddc391-c0c2-4c8c-6c3b-b086de963d5c@gmail.com>
 <CAM834X+iZ7YFV5vgJqoVMe6WZmBwJjWY=2jHV7aUS231=tHpKA@mail.gmail.com>
 <CAM834X+Kim0OQfGtVm2bgmXbPYS+K13Pju2Rwcj6nQAi9xHffg@mail.gmail.com>
Message-ID: <CABghstQvs+jgkutC3PN41Cpfj=QWOqiZOh8ktuSzXGwBV_bNhA@mail.gmail.com>

Yes.  I think you can specify a fixed residual variance in blme::blmer, but
not to exactly zero.

On Thu, Aug 2, 2018 at 12:24 AM Peter Paprzycki <peter.paprzycki at gmail.com>
wrote:

> Sorry, you estimated it to be very close to zero, I see.
> Peter
>
> On Wed, Aug 1, 2018 at 11:08 PM, Peter Paprzycki <
> peter.paprzycki at gmail.com> wrote:
>
>> Perfect. Thank you. It is good to know that we can specify the
>> random-effects variance
>> equal to zero. Thanks.
>> Peter
>>
>>
>> <http://www.avg.com/email-signature?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail> Virus-free.
>> www.avg.com
>> <http://www.avg.com/email-signature?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
>> <#m_3076315220315282584_m_981606773260833816_DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>
>>
>> On Wed, Aug 1, 2018 at 10:57 PM, Ben Bolker <bbolker at gmail.com> wrote:
>>
>>>
>>>   (please keep r-sig-mixed-models in the Cc:)
>>>
>>>   I'm pretty sure that lmer and lm models are commensurate, in case that
>>> helps.  Here's an example rigged to make the random-effects variance
>>> equal to zero, so we can check that the log-likelihoods etc. are
>>> identical.
>>>
>>> set.seed(101)
>>> dd <- data.frame(y=rnorm(20),x=rnorm(20),f=factor(rep(1:2,10)))
>>> library(lme4)
>>> m1 <- lmer(y~x+(1|f),data=dd,REML=FALSE) ## estimated sigma^2_f=0
>>> m2 <- lm(y~x,data=dd)
>>> all.equal(c(logLik(m1)),c(logLik(m2))) ## TRUE
>>> all.equal(fixef(m1),coef(m2))
>>> anova(m1,m2)
>>>
>>>
>>> On 2018-08-01 11:41 PM, Peter Paprzycki wrote:
>>> > Thank you. Oh, was just trying to compare my random-effects model to
>>> the
>>> > one where my grouping variable (schools) is treated as fixed.
>>> >
>>> > Peter
>>> >
>>> > <
>>> http://www.avg.com/email-signature?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail
>>> >
>>> >       Virus-free. www.avg.com
>>> > <
>>> http://www.avg.com/email-signature?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail
>>> >
>>> >
>>> >
>>> > <#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>
>>> >
>>> > On Wed, Aug 1, 2018 at 10:32 PM, Ben Bolker <bbolker at gmail.com
>>> > <mailto:bbolker at gmail.com>> wrote:
>>> >
>>> >
>>> >       I'm not 100% sure I understand the question, but I think the
>>> answer is
>>> >     "no": lmer cannot fit a model that doesn't contain any random
>>> effects.
>>> >     Perhaps you can give more context as to why it won't work for you
>>> to
>>> >     revert to lm() or plm() in these cases?
>>> >
>>> >     On 2018-08-01 11:30 PM, Peter Paprzycki wrote:
>>> >     > This is very basic, is there a way to specify in lmer function
>>> >     that I would
>>> >     > like to run my grouping variable as a fixed factor only, without
>>> >     reverting
>>> >     > to lm or plm functions. If one does not specify a random
>>> variable,
>>> >     one gets
>>> >     > the error message with lmer function; something that is
>>> equivalent
>>> >     to the
>>> >     > statement, "index = "grouping variable", model = "within"" with
>>> >     the plm
>>> >     > function.
>>> >     >
>>> >     >
>>> >     <
>>> http://www.avg.com/email-signature?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail
>>> >     <
>>> http://www.avg.com/email-signature?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail
>>> >>
>>> >     > Virus-free.
>>> >     > www.avg.com <http://www.avg.com>
>>> >     >
>>> >     <
>>> http://www.avg.com/email-signature?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail
>>> >     <
>>> http://www.avg.com/email-signature?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail
>>> >>
>>> >     > <#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>
>>> >     >
>>> >     >       [[alternative HTML version deleted]]
>>> >     >
>>> >     > _______________________________________________
>>> >     > R-sig-mixed-models at r-project.org
>>> >     <mailto:R-sig-mixed-models at r-project.org> mailing list
>>> >     > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>> >     >
>>> >
>>> >
>>> >
>>> >
>>> > --
>>> >
>>> > Peter Paprzycki, Ph.D.
>>> > Visiting Assistant Professor
>>> > Research Support Center Manager
>>> >
>>> > Educational Research and Administration
>>> > College of Education and Psychology
>>> > The University of Southern Mississippi
>>> > USM Box 5093; 118 College Drive
>>> > Hattiesburg, Mississippi 39406-0001
>>> > tel. (601)-266-4708
>>> > email: Peter.Paprzycki at usm.edu <mailto:Peter.Paprzycki at usm.edu>
>>> >
>>> >
>>> > Sidere mens eadum mutato
>>> >
>>>
>>
>>
>>
>> --
>>
>> Peter Paprzycki, Ph.D.
>> Visiting Assistant Professor
>> Research Support Center Manager
>>
>> Educational Research and Administration
>> College of Education and Psychology
>> The University of Southern Mississippi
>> USM Box 5093; 118 College Drive
>> Hattiesburg, Mississippi 39406-0001
>> tel. (601)-266-4708
>> email: Peter.Paprzycki at usm.edu
>>
>>
>> Sidere mens eadum mutato
>>
>
>
>
> --
>
> Peter Paprzycki, Ph.D.
> Visiting Assistant Professor
> Research Support Center Manager
>
> Educational Research and Administration
> College of Education and Psychology
> The University of Southern Mississippi
> USM Box 5093; 118 College Drive
> Hattiesburg, Mississippi 39406-0001
> tel. (601)-266-4708
> email: Peter.Paprzycki at usm.edu
>
>
> Sidere mens eadum mutato
>

	[[alternative HTML version deleted]]


From m@echler @ending from @t@t@m@th@ethz@ch  Thu Aug  2 08:53:59 2018
From: m@echler @ending from @t@t@m@th@ethz@ch (Martin Maechler)
Date: Thu, 2 Aug 2018 08:53:59 +0200
Subject: [R-sig-ME] (no subject)
In-Reply-To: <CABghstQvs+jgkutC3PN41Cpfj=QWOqiZOh8ktuSzXGwBV_bNhA@mail.gmail.com>
References: <CAM834X+x+gZr_m75cN5MkM-hjK3MWyJhY9HJBy8VzTydQSusrA@mail.gmail.com>
 <ec8f5787-693a-18af-516c-7e573786dbfa@gmail.com>
 <CAM834XKtXfnLF0NVc98-G8Syu6dUZW20m+-34iqW+E2Dz-xWLQ@mail.gmail.com>
 <32ddc391-c0c2-4c8c-6c3b-b086de963d5c@gmail.com>
 <CAM834X+iZ7YFV5vgJqoVMe6WZmBwJjWY=2jHV7aUS231=tHpKA@mail.gmail.com>
 <CAM834X+Kim0OQfGtVm2bgmXbPYS+K13Pju2Rwcj6nQAi9xHffg@mail.gmail.com>
 <CABghstQvs+jgkutC3PN41Cpfj=QWOqiZOh8ktuSzXGwBV_bNhA@mail.gmail.com>
Message-ID: <23394.43655.473603.454582@stat.math.ethz.ch>

>>> On Wed, Aug 1, 2018 at 10:57 PM, Ben Bolker <bbolker at gmail.com> wrote:
>>> 

>>>> I'm pretty sure that lmer and lm models are commensurate, in case that
>>>> helps.  Here's an example rigged to make the random-effects variance
>>>> equal to zero, so we can check that the log-likelihoods etc. are
>>>> identical.
>>>> 
>>>> set.seed(101)
>>>> dd <- data.frame(y=rnorm(20),x=rnorm(20),f=factor(rep(1:2,10)))
>>>> library(lme4)
>>>> m1 <- lmer(y~x+(1|f),data=dd,REML=FALSE) ## estimated sigma^2_f=0
>>>> m2 <- lm(y~x,data=dd)
>>>> all.equal(c(logLik(m1)),c(logLik(m2))) ## TRUE
>>>> all.equal(fixef(m1),coef(m2))
>>>> anova(m1,m2)
>>>> 

Then, Peter replied

    >> Sorry, you estimated it to be very close to zero, I see.
    >> Peter

and Ben, again, (Thu, 2 Aug 2018 01:26:27 -0400):

    > Yes.  I think you can specify a fixed residual variance in blme::blmer, but
    >      not to exactly zero. 

Peter: it is estimated to be  *exactly*  zero, not just close to
zero with the lmer example above:

  > VarCorr(m1)$f == 0
	      (Intercept)
  (Intercept)        TRUE
  > 

  (yes, these are always matrices, here of dimension  1x1)

This has been one of the major features of lme4::lmer()  wrt to nlme::lme()
that  \hat{\sigma_j^2} = 0  is naturally possible
because of the parametrization used.

Martin


From guill@ume@imon@@2 @ending from gm@il@com  Thu Aug  2 09:22:52 2018
From: guill@ume@imon@@2 @ending from gm@il@com (Guillaume Adeux)
Date: Thu, 2 Aug 2018 09:22:52 +0200
Subject: [R-sig-ME] feedback: Anova (type III-tests) table based on LRT for
 glmmTMB models (drop1, anova, mixed)
Message-ID: <CAENiVe8eoSb0=bfYp4r7Yn4MHgQw58nVrNtSi34H9AtUfudvBg@mail.gmail.com>

Sorry, my intent was definetely not to shortcut anyone or anything.

I thought I would give you all a little feedback on your propositions.

The problem with drop1 (when an interaction is in the model) is when you
want it to behave like a type III anova. This results in one of the
variables having zero degree of freedom, hence LRT of 0 and no p-value.

Here is the example on an output:



Model: mod=glmmTMB(ratio ~ block + trt * time
+(1|plot)+(1|year)+(1|year:plot),family=list(family="beta",link="logit"),data=biomass)

drop1(mod,.~block+trt*time,test=?Chisq?)

Single term deletions

                               Df                           AIC
LRT                      Pr(>Chi)

<none>                                                -5092.2

block                    1                             -5093.5
0.7345                  0.391415

trt                         4                             -5082.7
17.5018                0.001544

time                      0                             -5092.2
0

trt:time                  4                             -5100.0
0.2169                  0.994527


If I understand correctly, drop1 is incapable of comparing a model A+A:B
with A+B+A:B.

Anova.III.glmmTMB indeed works but only yields Wald tests which I thought
were not ideal for glmms.

I contacted the developper of the {afex} package to see if the mixed
function could be adapted to run on glmmTMB objects but no luck as of now.
Considering the framework of glmmTMB is similar to glmer, maybe this can be
easily adapted.

Thanks for your interest. Don't hesitate if you have any input.

Guillaume ADEUX

	[[alternative HTML version deleted]]


From roeem@or @ending from gm@il@com  Thu Aug  2 15:24:55 2018
From: roeem@or @ending from gm@il@com (roee maor)
Date: Thu, 2 Aug 2018 14:24:55 +0100
Subject: [R-sig-ME] Error in phylogenetic ordinal model with MCMCglmm()
Message-ID: <CACxNx6scRX10fWqXOSAvUn5eT7-g=By8yzV1hAD9Zk2riHVRDQ@mail.gmail.com>

Dear list,

I'm using MCMCglmm to run a phylogenetic model where the response is a
3-level ordinal factor (i.e. level 2 is an intermediate phenotype
between 1 and 3), and the predictors include one factorial (foraging
habitat), one ordinal (trophic level), and several continuous
variables.

As far as I know MCMCglmm is the only package that can handle logistic
models for phylogenetically structured multi-level discrete data, but
please correct me if that's not the case.

My problem right now is that I can't get MCMCglmm() to work with the
'family' argument set to "ordinal", although it does work with
"categorical".
Here's the code I'm using:

> packageVersion("MCMCglmm")
[1] ?2.25?
> R.version.string
[1] "R version 3.4.3 (2017-11-30)"

## model specifications:
> INphylo <- inverseA(mammaltree, nodes="ALL", scale=TRUE)  ## phylogeny with 1399 tips, setting nodes="TIPS" is extremely slow
> k <- length(levels(valid$Response))
> I <- diag(k-1)
> J <- matrix(rep(1, (k-1)^2), c(k-1, k-1))

## categorical model (unordered response) - runs to completion
> m1 <- MCMCglmm(Response ~ -1 + trait + ForagingHab + Troph_Lev + Mass + Mean.Diur.Range + Max.Temp.Warmest.M + Temp.Annual.Range + Precip.Driest.Month + PET,
+                random = ~ us(trait):Binomial,
+                rcov = ~ us(trait):units,
+                prior = list(R = list(fix=1, V=(1/k) * (I + J), n = k-1),
+                             G = list(G1 = list(V = diag(k-1), n = k-1))),
+                ginverse = list(Binomial=INphylo$Ainv),
+                burnin = 300000,
+                nitt = 3000000,
+                thin = 2000,
+                family = "categorical",
+                data = valid,
+                pl = TRUE)

## ordinal model and error message
> m2 <- MCMCglmm(Response ~ -1 + trait + ForagingHab + Troph_Lev + Mass + Mean.Diur.Range + Max.Temp.Warmest.M + Temp.Annual.Range + Precip.Driest.Month + PET,
+                random = ~ us(trait):Binomial,
+                rcov = ~ us(trait):units,
+                prior = list(R = list(fix=1, V=1, n = k-1),
+                             G = list(G1 = list(V = diag(k-1), n = k-1))),
+                ginverse = list(Binomial=INphylo$Ainv),
+                burnin = 300000,
+                nitt = 3000000,
+                thin = 2000,
+                family = "ordinal",
+                data = valid,
+                pl = TRUE)
Error in `contrasts<-`(`*tmp*`, value = contr.funs[1 + isOF[nn]]) :
  contrasts can be applied only to factors with 2 or more levels

## the shape of the data
> str(valid)
'data.frame': 1399 obs. of  16 variables:
 $ Binomial           : chr  "Abrocoma_bennettii" "Abrothrix_andinus"
"Abrothrix_jelskii" "Abrothrix_longipilis" ...
 $ Response           : Factor w/ 3 levels "1","2","3": 1 3 2 2 2 3 2 3 1 3 ...
 $ ForagingHab        : Factor w/ 7 levels "1","3","4","5",..: 2 2 2 2
2 2 2 2 2 2 ...
 $ Troph_Lev          : Factor w/ 3 levels "1","2","3": 1 2 2 2 2 3 2 1 1 1 ...
 $ Mass               : num  250.5 24.9 34.5 38.9 24.5 ...
 $ Annual.Mean.Temp   : num  12.42 7.26 9.18 9.9 8.62 ...
 $ Mean.Diur.Range    : num  10.46 13.82 16.16 9.15 7.78 ...
 $ Max.Temp.Warmest.M : num  22 16.6 19.1 19.8 17.2 ...
 $ Min.Temp.Coldest.M : num  3.77 -3.98 -3.24 2.21 1.46 ...
 $ Temp.Annual.Range  : num  18.3 20.6 22.4 17.6 15.7 ...
 $ Mean.Temp.Warm.Q   : num  16 9.2 11.1 13.8 12.2 ...
 $ Mean.Temp.Cold.Q   : num  8.87 4.49 6.39 5.98 4.87 ...
 $ Annual.Precip      : num  166 645 558 903 1665 ...
 $ Precip.Driest.Month: num  1.74 5.99 6.31 31.31 104.7 ...
 $ AET                : num  213 482 704 455 361 ...
 $ PET                : num  1074 1242 1305 677 638 ...


I don't understand what factors the error refers to, because there
sufficient levels in the response even if one is absorbed in the
intercept.

The R-constraint in the prior is specified as suggested in the
MCMCglmm tutorial (fix=1, V=1), but the error message is the same
whether I use this specification or the categorical model
specification (fix=1, V=(1/k)*(I + J)) .

On a side note - what parameters affect the acceptance rates? The
categorical models maintain a rate of around 0.3 so I think the mixing
could be improved.

Any input would be very much appreciated.

Many thanks,
Roi Maor


From dexter@locke @ending from gm@il@com  Thu Aug  2 15:39:18 2018
From: dexter@locke @ending from gm@il@com (Dexter Locke)
Date: Thu, 2 Aug 2018 09:39:18 -0400
Subject: [R-sig-ME] Error in phylogenetic ordinal model with MCMCglmm()
In-Reply-To: <CACxNx6scRX10fWqXOSAvUn5eT7-g=By8yzV1hAD9Zk2riHVRDQ@mail.gmail.com>
References: <CACxNx6scRX10fWqXOSAvUn5eT7-g=By8yzV1hAD9Zk2riHVRDQ@mail.gmail.com>
Message-ID: <7AD66B65-0524-4F68-B056-EE5D63932249@gmail.com>

Maybe Response needs to be an ordered factor, not a factor with three levels. Try something like

valid$Response <- as.factor(valid$Response, ordered=T)

See also th clmm package. 

HTH, Dexter



> On Aug 2, 2018, at 9:24 AM, roee maor <roeemaor at gmail.com> wrote:
> 
> Dear list,
> 
> I'm using MCMCglmm to run a phylogenetic model where the response is a
> 3-level ordinal factor (i.e. level 2 is an intermediate phenotype
> between 1 and 3), and the predictors include one factorial (foraging
> habitat), one ordinal (trophic level), and several continuous
> variables.
> 
> As far as I know MCMCglmm is the only package that can handle logistic
> models for phylogenetically structured multi-level discrete data, but
> please correct me if that's not the case.
> 
> My problem right now is that I can't get MCMCglmm() to work with the
> 'family' argument set to "ordinal", although it does work with
> "categorical".
> Here's the code I'm using:
> 
>> packageVersion("MCMCglmm")
> [1] ?2.25?
>> R.version.string
> [1] "R version 3.4.3 (2017-11-30)"
> 
> ## model specifications:
>> INphylo <- inverseA(mammaltree, nodes="ALL", scale=TRUE)  ## phylogeny with 1399 tips, setting nodes="TIPS" is extremely slow
>> k <- length(levels(valid$Response))
>> I <- diag(k-1)
>> J <- matrix(rep(1, (k-1)^2), c(k-1, k-1))
> 
> ## categorical model (unordered response) - runs to completion
>> m1 <- MCMCglmm(Response ~ -1 + trait + ForagingHab + Troph_Lev + Mass + Mean.Diur.Range + Max.Temp.Warmest.M + Temp.Annual.Range + Precip.Driest.Month + PET,
> +                random = ~ us(trait):Binomial,
> +                rcov = ~ us(trait):units,
> +                prior = list(R = list(fix=1, V=(1/k) * (I + J), n = k-1),
> +                             G = list(G1 = list(V = diag(k-1), n = k-1))),
> +                ginverse = list(Binomial=INphylo$Ainv),
> +                burnin = 300000,
> +                nitt = 3000000,
> +                thin = 2000,
> +                family = "categorical",
> +                data = valid,
> +                pl = TRUE)
> 
> ## ordinal model and error message
>> m2 <- MCMCglmm(Response ~ -1 + trait + ForagingHab + Troph_Lev + Mass + Mean.Diur.Range + Max.Temp.Warmest.M + Temp.Annual.Range + Precip.Driest.Month + PET,
> +                random = ~ us(trait):Binomial,
> +                rcov = ~ us(trait):units,
> +                prior = list(R = list(fix=1, V=1, n = k-1),
> +                             G = list(G1 = list(V = diag(k-1), n = k-1))),
> +                ginverse = list(Binomial=INphylo$Ainv),
> +                burnin = 300000,
> +                nitt = 3000000,
> +                thin = 2000,
> +                family = "ordinal",
> +                data = valid,
> +                pl = TRUE)
> Error in `contrasts<-`(`*tmp*`, value = contr.funs[1 + isOF[nn]]) :
>  contrasts can be applied only to factors with 2 or more levels
> 
> ## the shape of the data
>> str(valid)
> 'data.frame': 1399 obs. of  16 variables:
> $ Binomial           : chr  "Abrocoma_bennettii" "Abrothrix_andinus"
> "Abrothrix_jelskii" "Abrothrix_longipilis" ...
> $ Response           : Factor w/ 3 levels "1","2","3": 1 3 2 2 2 3 2 3 1 3 ...
> $ ForagingHab        : Factor w/ 7 levels "1","3","4","5",..: 2 2 2 2
> 2 2 2 2 2 2 ...
> $ Troph_Lev          : Factor w/ 3 levels "1","2","3": 1 2 2 2 2 3 2 1 1 1 ...
> $ Mass               : num  250.5 24.9 34.5 38.9 24.5 ...
> $ Annual.Mean.Temp   : num  12.42 7.26 9.18 9.9 8.62 ...
> $ Mean.Diur.Range    : num  10.46 13.82 16.16 9.15 7.78 ...
> $ Max.Temp.Warmest.M : num  22 16.6 19.1 19.8 17.2 ...
> $ Min.Temp.Coldest.M : num  3.77 -3.98 -3.24 2.21 1.46 ...
> $ Temp.Annual.Range  : num  18.3 20.6 22.4 17.6 15.7 ...
> $ Mean.Temp.Warm.Q   : num  16 9.2 11.1 13.8 12.2 ...
> $ Mean.Temp.Cold.Q   : num  8.87 4.49 6.39 5.98 4.87 ...
> $ Annual.Precip      : num  166 645 558 903 1665 ...
> $ Precip.Driest.Month: num  1.74 5.99 6.31 31.31 104.7 ...
> $ AET                : num  213 482 704 455 361 ...
> $ PET                : num  1074 1242 1305 677 638 ...
> 
> 
> I don't understand what factors the error refers to, because there
> sufficient levels in the response even if one is absorbed in the
> intercept.
> 
> The R-constraint in the prior is specified as suggested in the
> MCMCglmm tutorial (fix=1, V=1), but the error message is the same
> whether I use this specification or the categorical model
> specification (fix=1, V=(1/k)*(I + J)) .
> 
> On a side note - what parameters affect the acceptance rates? The
> categorical models maintain a rate of around 0.3 so I think the mixing
> could be improved.
> 
> Any input would be very much appreciated.
> 
> Many thanks,
> Roi Maor
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From pierre@de@villemereuil @ending from m@iloo@org  Thu Aug  2 15:46:10 2018
From: pierre@de@villemereuil @ending from m@iloo@org (Pierre de Villemereuil)
Date: Thu, 02 Aug 2018 15:46:10 +0200
Subject: [R-sig-ME] Error in phylogenetic ordinal model with MCMCglmm()
In-Reply-To: <CACxNx6scRX10fWqXOSAvUn5eT7-g=By8yzV1hAD9Zk2riHVRDQ@mail.gmail.com>
References: <CACxNx6scRX10fWqXOSAvUn5eT7-g=By8yzV1hAD9Zk2riHVRDQ@mail.gmail.com>
Message-ID: <3426219.r1KVDEireR@ev8sa6>

Hi,

Contrary to "categorical", the "ordinal" family is not multivariate on the latent scale, so you need to drop everything related to "trait" in the ordinal model and modify the prior to be univariate as well.

I think MCMCglmm is complaining here because "trait" does not have more than one level due to this.

Hope this helps,
Pierre.

Le jeudi 2 ao?t 2018, 15:24:55 CEST roee maor a ?crit :
> Dear list,
> 
> I'm using MCMCglmm to run a phylogenetic model where the response is a
> 3-level ordinal factor (i.e. level 2 is an intermediate phenotype
> between 1 and 3), and the predictors include one factorial (foraging
> habitat), one ordinal (trophic level), and several continuous
> variables.
> 
> As far as I know MCMCglmm is the only package that can handle logistic
> models for phylogenetically structured multi-level discrete data, but
> please correct me if that's not the case.
> 
> My problem right now is that I can't get MCMCglmm() to work with the
> 'family' argument set to "ordinal", although it does work with
> "categorical".
> Here's the code I'm using:
> 
> > packageVersion("MCMCglmm")
> [1] ?2.25?
> > R.version.string
> [1] "R version 3.4.3 (2017-11-30)"
> 
> ## model specifications:
> > INphylo <- inverseA(mammaltree, nodes="ALL", scale=TRUE)  ## phylogeny with 1399 tips, setting nodes="TIPS" is extremely slow
> > k <- length(levels(valid$Response))
> > I <- diag(k-1)
> > J <- matrix(rep(1, (k-1)^2), c(k-1, k-1))
> 
> ## categorical model (unordered response) - runs to completion
> > m1 <- MCMCglmm(Response ~ -1 + trait + ForagingHab + Troph_Lev + Mass + Mean.Diur.Range + Max.Temp.Warmest.M + Temp.Annual.Range + Precip.Driest.Month + PET,
> +                random = ~ us(trait):Binomial,
> +                rcov = ~ us(trait):units,
> +                prior = list(R = list(fix=1, V=(1/k) * (I + J), n = k-1),
> +                             G = list(G1 = list(V = diag(k-1), n = k-1))),
> +                ginverse = list(Binomial=INphylo$Ainv),
> +                burnin = 300000,
> +                nitt = 3000000,
> +                thin = 2000,
> +                family = "categorical",
> +                data = valid,
> +                pl = TRUE)
> 
> ## ordinal model and error message
> > m2 <- MCMCglmm(Response ~ -1 + trait + ForagingHab + Troph_Lev + Mass + Mean.Diur.Range + Max.Temp.Warmest.M + Temp.Annual.Range + Precip.Driest.Month + PET,
> +                random = ~ us(trait):Binomial,
> +                rcov = ~ us(trait):units,
> +                prior = list(R = list(fix=1, V=1, n = k-1),
> +                             G = list(G1 = list(V = diag(k-1), n = k-1))),
> +                ginverse = list(Binomial=INphylo$Ainv),
> +                burnin = 300000,
> +                nitt = 3000000,
> +                thin = 2000,
> +                family = "ordinal",
> +                data = valid,
> +                pl = TRUE)
> Error in `contrasts<-`(`*tmp*`, value = contr.funs[1 + isOF[nn]]) :
>   contrasts can be applied only to factors with 2 or more levels
> 
> ## the shape of the data
> > str(valid)
> 'data.frame': 1399 obs. of  16 variables:
>  $ Binomial           : chr  "Abrocoma_bennettii" "Abrothrix_andinus"
> "Abrothrix_jelskii" "Abrothrix_longipilis" ...
>  $ Response           : Factor w/ 3 levels "1","2","3": 1 3 2 2 2 3 2 3 1 3 ...
>  $ ForagingHab        : Factor w/ 7 levels "1","3","4","5",..: 2 2 2 2
> 2 2 2 2 2 2 ...
>  $ Troph_Lev          : Factor w/ 3 levels "1","2","3": 1 2 2 2 2 3 2 1 1 1 ...
>  $ Mass               : num  250.5 24.9 34.5 38.9 24.5 ...
>  $ Annual.Mean.Temp   : num  12.42 7.26 9.18 9.9 8.62 ...
>  $ Mean.Diur.Range    : num  10.46 13.82 16.16 9.15 7.78 ...
>  $ Max.Temp.Warmest.M : num  22 16.6 19.1 19.8 17.2 ...
>  $ Min.Temp.Coldest.M : num  3.77 -3.98 -3.24 2.21 1.46 ...
>  $ Temp.Annual.Range  : num  18.3 20.6 22.4 17.6 15.7 ...
>  $ Mean.Temp.Warm.Q   : num  16 9.2 11.1 13.8 12.2 ...
>  $ Mean.Temp.Cold.Q   : num  8.87 4.49 6.39 5.98 4.87 ...
>  $ Annual.Precip      : num  166 645 558 903 1665 ...
>  $ Precip.Driest.Month: num  1.74 5.99 6.31 31.31 104.7 ...
>  $ AET                : num  213 482 704 455 361 ...
>  $ PET                : num  1074 1242 1305 677 638 ...
> 
> 
> I don't understand what factors the error refers to, because there
> sufficient levels in the response even if one is absorbed in the
> intercept.
> 
> The R-constraint in the prior is specified as suggested in the
> MCMCglmm tutorial (fix=1, V=1), but the error message is the same
> whether I use this specification or the categorical model
> specification (fix=1, V=(1/k)*(I + J)) .
> 
> On a side note - what parameters affect the acceptance rates? The
> categorical models maintain a rate of around 0.3 so I think the mixing
> could be improved.
> 
> Any input would be very much appreciated.
> 
> Many thanks,
> Roi Maor
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From p@ul@buerkner @ending from gm@il@com  Thu Aug  2 15:45:24 2018
From: p@ul@buerkner @ending from gm@il@com (Paul Buerkner)
Date: Thu, 2 Aug 2018 15:45:24 +0200
Subject: [R-sig-ME] Error in phylogenetic ordinal model with MCMCglmm()
In-Reply-To: <7AD66B65-0524-4F68-B056-EE5D63932249@gmail.com>
References: <CACxNx6scRX10fWqXOSAvUn5eT7-g=By8yzV1hAD9Zk2riHVRDQ@mail.gmail.com>
 <7AD66B65-0524-4F68-B056-EE5D63932249@gmail.com>
Message-ID: <CAGoSky_d2utNwJtae5rUBn_fwkDPD=ZwPgn-4kqLMx685=SZjQ@mail.gmail.com>

If it doesn't end up working in MCMCglmm, you may also try the brms
package.

See
https://cran.r-project.org/web/packages/brms/vignettes/brms_phylogenetics.html
for an introduction of
phylogenetic models in brms.

2018-08-02 15:39 GMT+02:00 Dexter Locke <dexter.locke at gmail.com>:

> Maybe Response needs to be an ordered factor, not a factor with three
> levels. Try something like
>
> valid$Response <- as.factor(valid$Response, ordered=T)
>
> See also th clmm package.
>
> HTH, Dexter
>
>
>
> > On Aug 2, 2018, at 9:24 AM, roee maor <roeemaor at gmail.com> wrote:
> >
> > Dear list,
> >
> > I'm using MCMCglmm to run a phylogenetic model where the response is a
> > 3-level ordinal factor (i.e. level 2 is an intermediate phenotype
> > between 1 and 3), and the predictors include one factorial (foraging
> > habitat), one ordinal (trophic level), and several continuous
> > variables.
> >
> > As far as I know MCMCglmm is the only package that can handle logistic
> > models for phylogenetically structured multi-level discrete data, but
> > please correct me if that's not the case.
> >
> > My problem right now is that I can't get MCMCglmm() to work with the
> > 'family' argument set to "ordinal", although it does work with
> > "categorical".
> > Here's the code I'm using:
> >
> >> packageVersion("MCMCglmm")
> > [1] ?2.25?
> >> R.version.string
> > [1] "R version 3.4.3 (2017-11-30)"
> >
> > ## model specifications:
> >> INphylo <- inverseA(mammaltree, nodes="ALL", scale=TRUE)  ## phylogeny
> with 1399 tips, setting nodes="TIPS" is extremely slow
> >> k <- length(levels(valid$Response))
> >> I <- diag(k-1)
> >> J <- matrix(rep(1, (k-1)^2), c(k-1, k-1))
> >
> > ## categorical model (unordered response) - runs to completion
> >> m1 <- MCMCglmm(Response ~ -1 + trait + ForagingHab + Troph_Lev + Mass +
> Mean.Diur.Range + Max.Temp.Warmest.M + Temp.Annual.Range +
> Precip.Driest.Month + PET,
> > +                random = ~ us(trait):Binomial,
> > +                rcov = ~ us(trait):units,
> > +                prior = list(R = list(fix=1, V=(1/k) * (I + J), n =
> k-1),
> > +                             G = list(G1 = list(V = diag(k-1), n =
> k-1))),
> > +                ginverse = list(Binomial=INphylo$Ainv),
> > +                burnin = 300000,
> > +                nitt = 3000000,
> > +                thin = 2000,
> > +                family = "categorical",
> > +                data = valid,
> > +                pl = TRUE)
> >
> > ## ordinal model and error message
> >> m2 <- MCMCglmm(Response ~ -1 + trait + ForagingHab + Troph_Lev + Mass +
> Mean.Diur.Range + Max.Temp.Warmest.M + Temp.Annual.Range +
> Precip.Driest.Month + PET,
> > +                random = ~ us(trait):Binomial,
> > +                rcov = ~ us(trait):units,
> > +                prior = list(R = list(fix=1, V=1, n = k-1),
> > +                             G = list(G1 = list(V = diag(k-1), n =
> k-1))),
> > +                ginverse = list(Binomial=INphylo$Ainv),
> > +                burnin = 300000,
> > +                nitt = 3000000,
> > +                thin = 2000,
> > +                family = "ordinal",
> > +                data = valid,
> > +                pl = TRUE)
> > Error in `contrasts<-`(`*tmp*`, value = contr.funs[1 + isOF[nn]]) :
> >  contrasts can be applied only to factors with 2 or more levels
> >
> > ## the shape of the data
> >> str(valid)
> > 'data.frame': 1399 obs. of  16 variables:
> > $ Binomial           : chr  "Abrocoma_bennettii" "Abrothrix_andinus"
> > "Abrothrix_jelskii" "Abrothrix_longipilis" ...
> > $ Response           : Factor w/ 3 levels "1","2","3": 1 3 2 2 2 3 2 3 1
> 3 ...
> > $ ForagingHab        : Factor w/ 7 levels "1","3","4","5",..: 2 2 2 2
> > 2 2 2 2 2 2 ...
> > $ Troph_Lev          : Factor w/ 3 levels "1","2","3": 1 2 2 2 2 3 2 1 1
> 1 ...
> > $ Mass               : num  250.5 24.9 34.5 38.9 24.5 ...
> > $ Annual.Mean.Temp   : num  12.42 7.26 9.18 9.9 8.62 ...
> > $ Mean.Diur.Range    : num  10.46 13.82 16.16 9.15 7.78 ...
> > $ Max.Temp.Warmest.M : num  22 16.6 19.1 19.8 17.2 ...
> > $ Min.Temp.Coldest.M : num  3.77 -3.98 -3.24 2.21 1.46 ...
> > $ Temp.Annual.Range  : num  18.3 20.6 22.4 17.6 15.7 ...
> > $ Mean.Temp.Warm.Q   : num  16 9.2 11.1 13.8 12.2 ...
> > $ Mean.Temp.Cold.Q   : num  8.87 4.49 6.39 5.98 4.87 ...
> > $ Annual.Precip      : num  166 645 558 903 1665 ...
> > $ Precip.Driest.Month: num  1.74 5.99 6.31 31.31 104.7 ...
> > $ AET                : num  213 482 704 455 361 ...
> > $ PET                : num  1074 1242 1305 677 638 ...
> >
> >
> > I don't understand what factors the error refers to, because there
> > sufficient levels in the response even if one is absorbed in the
> > intercept.
> >
> > The R-constraint in the prior is specified as suggested in the
> > MCMCglmm tutorial (fix=1, V=1), but the error message is the same
> > whether I use this specification or the categorical model
> > specification (fix=1, V=(1/k)*(I + J)) .
> >
> > On a side note - what parameters affect the acceptance rates? The
> > categorical models maintain a rate of around 0.3 so I think the mixing
> > could be improved.
> >
> > Any input would be very much appreciated.
> >
> > Many thanks,
> > Roi Maor
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From j@h@dfield @ending from ed@@c@uk  Thu Aug  2 15:44:33 2018
From: j@h@dfield @ending from ed@@c@uk (HADFIELD Jarrod)
Date: Thu, 2 Aug 2018 13:44:33 +0000
Subject: [R-sig-ME] Error in phylogenetic ordinal model with MCMCglmm()
In-Reply-To: <CACxNx6scRX10fWqXOSAvUn5eT7-g=By8yzV1hAD9Zk2riHVRDQ@mail.gmail.com>
References: <CACxNx6scRX10fWqXOSAvUn5eT7-g=By8yzV1hAD9Zk2riHVRDQ@mail.gmail.com>
Message-ID: <2C120162-C8A9-4E37-B721-D08D906C3687@ed.ac.uk>

Hi, 

There is only one ?trait? in an ordinal model, so the terms with trait in are redundant and causing the problem. You should get rid of all trait and us(trait): terms. With family=?categorical? there are two traits with 3 categories, one for each contrast. Note that is  using family=?threshold? will be more efficient than using ?ordinal? although they are almost the same model.

Cheers,

Jarrod

 


> On 2 Aug 2018, at 14:24, roee maor <roeemaor at gmail.com> wrote:
> 
> Dear list,
> 
> I'm using MCMCglmm to run a phylogenetic model where the response is a
> 3-level ordinal factor (i.e. level 2 is an intermediate phenotype
> between 1 and 3), and the predictors include one factorial (foraging
> habitat), one ordinal (trophic level), and several continuous
> variables.
> 
> As far as I know MCMCglmm is the only package that can handle logistic
> models for phylogenetically structured multi-level discrete data, but
> please correct me if that's not the case.
> 
> My problem right now is that I can't get MCMCglmm() to work with the
> 'family' argument set to "ordinal", although it does work with
> "categorical".
> Here's the code I'm using:
> 
>> packageVersion("MCMCglmm")
> [1] ?2.25?
>> R.version.string
> [1] "R version 3.4.3 (2017-11-30)"
> 
> ## model specifications:
>> INphylo <- inverseA(mammaltree, nodes="ALL", scale=TRUE)  ## phylogeny with 1399 tips, setting nodes="TIPS" is extremely slow
>> k <- length(levels(valid$Response))
>> I <- diag(k-1)
>> J <- matrix(rep(1, (k-1)^2), c(k-1, k-1))
> 
> ## categorical model (unordered response) - runs to completion
>> m1 <- MCMCglmm(Response ~ -1 + trait + ForagingHab + Troph_Lev + Mass + Mean.Diur.Range + Max.Temp.Warmest.M + Temp.Annual.Range + Precip.Driest.Month + PET,
> +                random = ~ us(trait):Binomial,
> +                rcov = ~ us(trait):units,
> +                prior = list(R = list(fix=1, V=(1/k) * (I + J), n = k-1),
> +                             G = list(G1 = list(V = diag(k-1), n = k-1))),
> +                ginverse = list(Binomial=INphylo$Ainv),
> +                burnin = 300000,
> +                nitt = 3000000,
> +                thin = 2000,
> +                family = "categorical",
> +                data = valid,
> +                pl = TRUE)
> 
> ## ordinal model and error message
>> m2 <- MCMCglmm(Response ~ -1 + trait + ForagingHab + Troph_Lev + Mass + Mean.Diur.Range + Max.Temp.Warmest.M + Temp.Annual.Range + Precip.Driest.Month + PET,
> +                random = ~ us(trait):Binomial,
> +                rcov = ~ us(trait):units,
> +                prior = list(R = list(fix=1, V=1, n = k-1),
> +                             G = list(G1 = list(V = diag(k-1), n = k-1))),
> +                ginverse = list(Binomial=INphylo$Ainv),
> +                burnin = 300000,
> +                nitt = 3000000,
> +                thin = 2000,
> +                family = "ordinal",
> +                data = valid,
> +                pl = TRUE)
> Error in `contrasts<-`(`*tmp*`, value = contr.funs[1 + isOF[nn]]) :
>  contrasts can be applied only to factors with 2 or more levels
> 
> ## the shape of the data
>> str(valid)
> 'data.frame': 1399 obs. of  16 variables:
> $ Binomial           : chr  "Abrocoma_bennettii" "Abrothrix_andinus"
> "Abrothrix_jelskii" "Abrothrix_longipilis" ...
> $ Response           : Factor w/ 3 levels "1","2","3": 1 3 2 2 2 3 2 3 1 3 ...
> $ ForagingHab        : Factor w/ 7 levels "1","3","4","5",..: 2 2 2 2
> 2 2 2 2 2 2 ...
> $ Troph_Lev          : Factor w/ 3 levels "1","2","3": 1 2 2 2 2 3 2 1 1 1 ...
> $ Mass               : num  250.5 24.9 34.5 38.9 24.5 ...
> $ Annual.Mean.Temp   : num  12.42 7.26 9.18 9.9 8.62 ...
> $ Mean.Diur.Range    : num  10.46 13.82 16.16 9.15 7.78 ...
> $ Max.Temp.Warmest.M : num  22 16.6 19.1 19.8 17.2 ...
> $ Min.Temp.Coldest.M : num  3.77 -3.98 -3.24 2.21 1.46 ...
> $ Temp.Annual.Range  : num  18.3 20.6 22.4 17.6 15.7 ...
> $ Mean.Temp.Warm.Q   : num  16 9.2 11.1 13.8 12.2 ...
> $ Mean.Temp.Cold.Q   : num  8.87 4.49 6.39 5.98 4.87 ...
> $ Annual.Precip      : num  166 645 558 903 1665 ...
> $ Precip.Driest.Month: num  1.74 5.99 6.31 31.31 104.7 ...
> $ AET                : num  213 482 704 455 361 ...
> $ PET                : num  1074 1242 1305 677 638 ...
> 
> 
> I don't understand what factors the error refers to, because there
> sufficient levels in the response even if one is absorbed in the
> intercept.
> 
> The R-constraint in the prior is specified as suggested in the
> MCMCglmm tutorial (fix=1, V=1), but the error message is the same
> whether I use this specification or the categorical model
> specification (fix=1, V=(1/k)*(I + J)) .
> 
> On a side note - what parameters affect the acceptance rates? The
> categorical models maintain a rate of around 0.3 so I think the mixing
> could be improved.
> 
> Any input would be very much appreciated.
> 
> Many thanks,
> Roi Maor
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.


From mnk@tie @ending from gm@il@com  Thu Aug  2 17:25:44 2018
From: mnk@tie @ending from gm@il@com (Katherine Gordon)
Date: Thu, 2 Aug 2018 10:25:44 -0500
Subject: [R-sig-ME] Please remove my email from this listserv, thank you.
Message-ID: <04C4635A-4A25-44DB-B92D-0B970D7B46AF@gmail.com>


From ukoether @ending from uke@de  Thu Aug  2 17:33:21 2018
From: ukoether @ending from uke@de (=?UTF-8?Q?Ulf_K=c3=b6ther?=)
Date: Thu, 2 Aug 2018 17:33:21 +0200
Subject: [R-sig-ME] 
 Please remove my email from this listserv, thank you.
In-Reply-To: <04C4635A-4A25-44DB-B92D-0B970D7B46AF@gmail.com>
References: <04C4635A-4A25-44DB-B92D-0B970D7B46AF@gmail.com>
Message-ID: <d34a3a5e-319f-6eb1-9f8d-b8206d8d6e94@uke.de>

Do it yourself (hint: use the ominous "unsubscribe"-button at the bottom
of the page!):

https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

;-)


Am 02.08.2018 um 17:25 schrieb Katherine Gordon:
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
--

_____________________________________________________________________

Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen Rechts; Gerichtsstand: Hamburg | www.uke.de
Vorstandsmitglieder: Prof. Dr. Burkhard G?ke (Vorsitzender), Prof. Dr. Dr. Uwe Koch-Gromus, Joachim Pr?l?, Martina Saurin (komm.)
_____________________________________________________________________

SAVE PAPER - THINK BEFORE PRINTING

From peter@p@przycki @ending from gm@il@com  Thu Aug  2 23:47:08 2018
From: peter@p@przycki @ending from gm@il@com (Peter Paprzycki)
Date: Thu, 2 Aug 2018 16:47:08 -0500
Subject: [R-sig-ME] (no subject)
In-Reply-To: <23394.43655.473603.454582@stat.math.ethz.ch>
References: <CAM834X+x+gZr_m75cN5MkM-hjK3MWyJhY9HJBy8VzTydQSusrA@mail.gmail.com>
 <ec8f5787-693a-18af-516c-7e573786dbfa@gmail.com>
 <CAM834XKtXfnLF0NVc98-G8Syu6dUZW20m+-34iqW+E2Dz-xWLQ@mail.gmail.com>
 <32ddc391-c0c2-4c8c-6c3b-b086de963d5c@gmail.com>
 <CAM834X+iZ7YFV5vgJqoVMe6WZmBwJjWY=2jHV7aUS231=tHpKA@mail.gmail.com>
 <CAM834X+Kim0OQfGtVm2bgmXbPYS+K13Pju2Rwcj6nQAi9xHffg@mail.gmail.com>
 <CABghstQvs+jgkutC3PN41Cpfj=QWOqiZOh8ktuSzXGwBV_bNhA@mail.gmail.com>
 <23394.43655.473603.454582@stat.math.ethz.ch>
Message-ID: <CAM834XJiciE=EExHoYeoC-KOvgtwqJjKUKqTOoD_BNmL05FG5A@mail.gmail.com>

Thank you, Martin.
Peter

<http://www.avg.com/email-signature?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
Virus-free.
www.avg.com
<http://www.avg.com/email-signature?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
<#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>

On Thu, Aug 2, 2018 at 1:53 AM, Martin Maechler <maechler at stat.math.ethz.ch>
wrote:

> >>> On Wed, Aug 1, 2018 at 10:57 PM, Ben Bolker <bbolker at gmail.com> wrote:
> >>>
>
> >>>> I'm pretty sure that lmer and lm models are commensurate, in case that
> >>>> helps.  Here's an example rigged to make the random-effects variance
> >>>> equal to zero, so we can check that the log-likelihoods etc. are
> >>>> identical.
> >>>>
> >>>> set.seed(101)
> >>>> dd <- data.frame(y=rnorm(20),x=rnorm(20),f=factor(rep(1:2,10)))
> >>>> library(lme4)
> >>>> m1 <- lmer(y~x+(1|f),data=dd,REML=FALSE) ## estimated sigma^2_f=0
> >>>> m2 <- lm(y~x,data=dd)
> >>>> all.equal(c(logLik(m1)),c(logLik(m2))) ## TRUE
> >>>> all.equal(fixef(m1),coef(m2))
> >>>> anova(m1,m2)
> >>>>
>
> Then, Peter replied
>
>     >> Sorry, you estimated it to be very close to zero, I see.
>     >> Peter
>
> and Ben, again, (Thu, 2 Aug 2018 01:26:27 -0400):
>
>     > Yes.  I think you can specify a fixed residual variance in
> blme::blmer, but
>     >      not to exactly zero.
>
> Peter: it is estimated to be  *exactly*  zero, not just close to
> zero with the lmer example above:
>
>   > VarCorr(m1)$f == 0
>               (Intercept)
>   (Intercept)        TRUE
>   >
>
>   (yes, these are always matrices, here of dimension  1x1)
>
> This has been one of the major features of lme4::lmer()  wrt to nlme::lme()
> that  \hat{\sigma_j^2} = 0  is naturally possible
> because of the parametrization used.
>
> Martin
>



-- 

Peter Paprzycki, Ph.D.
Visiting Assistant Professor
Research Support Center Manager

Educational Research and Administration
College of Education and Psychology
The University of Southern Mississippi
USM Box 5093; 118 College Drive
Hattiesburg, Mississippi 39406-0001
tel. (601)-266-4708
email: Peter.Paprzycki at usm.edu


Sidere mens eadum mutato

	[[alternative HTML version deleted]]


From roeem@or @ending from gm@il@com  Fri Aug  3 13:43:28 2018
From: roeem@or @ending from gm@il@com (roee maor)
Date: Fri, 3 Aug 2018 12:43:28 +0100
Subject: [R-sig-ME] Error in phylogenetic ordinal model with MCMCglmm()
In-Reply-To: <CAGoSky_d2utNwJtae5rUBn_fwkDPD=ZwPgn-4kqLMx685=SZjQ@mail.gmail.com>
References: <CACxNx6scRX10fWqXOSAvUn5eT7-g=By8yzV1hAD9Zk2riHVRDQ@mail.gmail.com>
 <7AD66B65-0524-4F68-B056-EE5D63932249@gmail.com>
 <CAGoSky_d2utNwJtae5rUBn_fwkDPD=ZwPgn-4kqLMx685=SZjQ@mail.gmail.com>
Message-ID: <CACxNx6sc2s3BVD1_4F7=vuLNsSFMbONjxELsfSmWZ+XQQ63+CA@mail.gmail.com>

Thanks everyone for your quick and helpful responses.
Removing the 'trait' terms indeed solved this problem and I have taken
Jarrod's advice to use family="threshold" instead of "ordinal".

Would it be possible to get a quick summary of the main differences
between ordinal and threshold models? Both seem to be rarely used and
I can't find much documentation on their inner workings in the
MCMCglmm vignette, tutorial or course notes.

Cheers,
RoiOn Thu, 2 Aug 2018 at 14:45, Paul Buerkner <paul.buerkner at gmail.com> wrote:
>
> If it doesn't end up working in MCMCglmm, you may also try the brms package.
>
> See https://cran.r-project.org/web/packages/brms/vignettes/brms_phylogenetics.html for an introduction of
> phylogenetic models in brms.
>
> 2018-08-02 15:39 GMT+02:00 Dexter Locke <dexter.locke at gmail.com>:
>>
>> Maybe Response needs to be an ordered factor, not a factor with three levels. Try something like
>>
>> valid$Response <- as.factor(valid$Response, ordered=T)
>>
>> See also th clmm package.
>>
>> HTH, Dexter
>>
>>
>>
>> > On Aug 2, 2018, at 9:24 AM, roee maor <roeemaor at gmail.com> wrote:
>> >
>> > Dear list,
>> >
>> > I'm using MCMCglmm to run a phylogenetic model where the response is a
>> > 3-level ordinal factor (i.e. level 2 is an intermediate phenotype
>> > between 1 and 3), and the predictors include one factorial (foraging
>> > habitat), one ordinal (trophic level), and several continuous
>> > variables.
>> >
>> > As far as I know MCMCglmm is the only package that can handle logistic
>> > models for phylogenetically structured multi-level discrete data, but
>> > please correct me if that's not the case.
>> >
>> > My problem right now is that I can't get MCMCglmm() to work with the
>> > 'family' argument set to "ordinal", although it does work with
>> > "categorical".
>> > Here's the code I'm using:
>> >
>> >> packageVersion("MCMCglmm")
>> > [1] ?2.25?
>> >> R.version.string
>> > [1] "R version 3.4.3 (2017-11-30)"
>> >
>> > ## model specifications:
>> >> INphylo <- inverseA(mammaltree, nodes="ALL", scale=TRUE)  ## phylogeny with 1399 tips, setting nodes="TIPS" is extremely slow
>> >> k <- length(levels(valid$Response))
>> >> I <- diag(k-1)
>> >> J <- matrix(rep(1, (k-1)^2), c(k-1, k-1))
>> >
>> > ## categorical model (unordered response) - runs to completion
>> >> m1 <- MCMCglmm(Response ~ -1 + trait + ForagingHab + Troph_Lev + Mass + Mean.Diur.Range + Max.Temp.Warmest.M + Temp.Annual.Range + Precip.Driest.Month + PET,
>> > +                random = ~ us(trait):Binomial,
>> > +                rcov = ~ us(trait):units,
>> > +                prior = list(R = list(fix=1, V=(1/k) * (I + J), n = k-1),
>> > +                             G = list(G1 = list(V = diag(k-1), n = k-1))),
>> > +                ginverse = list(Binomial=INphylo$Ainv),
>> > +                burnin = 300000,
>> > +                nitt = 3000000,
>> > +                thin = 2000,
>> > +                family = "categorical",
>> > +                data = valid,
>> > +                pl = TRUE)
>> >
>> > ## ordinal model and error message
>> >> m2 <- MCMCglmm(Response ~ -1 + trait + ForagingHab + Troph_Lev + Mass + Mean.Diur.Range + Max.Temp.Warmest.M + Temp.Annual.Range + Precip.Driest.Month + PET,
>> > +                random = ~ us(trait):Binomial,
>> > +                rcov = ~ us(trait):units,
>> > +                prior = list(R = list(fix=1, V=1, n = k-1),
>> > +                             G = list(G1 = list(V = diag(k-1), n = k-1))),
>> > +                ginverse = list(Binomial=INphylo$Ainv),
>> > +                burnin = 300000,
>> > +                nitt = 3000000,
>> > +                thin = 2000,
>> > +                family = "ordinal",
>> > +                data = valid,
>> > +                pl = TRUE)
>> > Error in `contrasts<-`(`*tmp*`, value = contr.funs[1 + isOF[nn]]) :
>> >  contrasts can be applied only to factors with 2 or more levels
>> >
>> > ## the shape of the data
>> >> str(valid)
>> > 'data.frame': 1399 obs. of  16 variables:
>> > $ Binomial           : chr  "Abrocoma_bennettii" "Abrothrix_andinus"
>> > "Abrothrix_jelskii" "Abrothrix_longipilis" ...
>> > $ Response           : Factor w/ 3 levels "1","2","3": 1 3 2 2 2 3 2 3 1 3 ...
>> > $ ForagingHab        : Factor w/ 7 levels "1","3","4","5",..: 2 2 2 2
>> > 2 2 2 2 2 2 ...
>> > $ Troph_Lev          : Factor w/ 3 levels "1","2","3": 1 2 2 2 2 3 2 1 1 1 ...
>> > $ Mass               : num  250.5 24.9 34.5 38.9 24.5 ...
>> > $ Annual.Mean.Temp   : num  12.42 7.26 9.18 9.9 8.62 ...
>> > $ Mean.Diur.Range    : num  10.46 13.82 16.16 9.15 7.78 ...
>> > $ Max.Temp.Warmest.M : num  22 16.6 19.1 19.8 17.2 ...
>> > $ Min.Temp.Coldest.M : num  3.77 -3.98 -3.24 2.21 1.46 ...
>> > $ Temp.Annual.Range  : num  18.3 20.6 22.4 17.6 15.7 ...
>> > $ Mean.Temp.Warm.Q   : num  16 9.2 11.1 13.8 12.2 ...
>> > $ Mean.Temp.Cold.Q   : num  8.87 4.49 6.39 5.98 4.87 ...
>> > $ Annual.Precip      : num  166 645 558 903 1665 ...
>> > $ Precip.Driest.Month: num  1.74 5.99 6.31 31.31 104.7 ...
>> > $ AET                : num  213 482 704 455 361 ...
>> > $ PET                : num  1074 1242 1305 677 638 ...
>> >
>> >
>> > I don't understand what factors the error refers to, because there
>> > sufficient levels in the response even if one is absorbed in the
>> > intercept.
>> >
>> > The R-constraint in the prior is specified as suggested in the
>> > MCMCglmm tutorial (fix=1, V=1), but the error message is the same
>> > whether I use this specification or the categorical model
>> > specification (fix=1, V=(1/k)*(I + J)) .
>> >
>> > On a side note - what parameters affect the acceptance rates? The
>> > categorical models maintain a rate of around 0.3 so I think the mixing
>> > could be improved.
>> >
>> > Any input would be very much appreciated.
>> >
>> > Many thanks,
>> > Roi Maor
>> >
>> > _______________________________________________
>> > R-sig-mixed-models at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>


From j@h@dfield @ending from ed@@c@uk  Fri Aug  3 13:58:48 2018
From: j@h@dfield @ending from ed@@c@uk (HADFIELD Jarrod)
Date: Fri, 3 Aug 2018 11:58:48 +0000
Subject: [R-sig-ME] Error in phylogenetic ordinal model with MCMCglmm()
In-Reply-To: <CACxNx6sc2s3BVD1_4F7=vuLNsSFMbONjxELsfSmWZ+XQQ63+CA@mail.gmail.com>
References: <CACxNx6scRX10fWqXOSAvUn5eT7-g=By8yzV1hAD9Zk2riHVRDQ@mail.gmail.com>
 <7AD66B65-0524-4F68-B056-EE5D63932249@gmail.com>
 <CAGoSky_d2utNwJtae5rUBn_fwkDPD=ZwPgn-4kqLMx685=SZjQ@mail.gmail.com>
 <CACxNx6sc2s3BVD1_4F7=vuLNsSFMbONjxELsfSmWZ+XQQ63+CA@mail.gmail.com>
Message-ID: <ED5845D5-8019-4985-B5AD-D245A761F3E2@ed.ac.uk>

Hi,

With three levels you have 4 cut-points, one of which needs estimating (call it cp.est)

cp<-c(-Inf, 0, cp.est, Inf)

If eta is the fixed+random effect linear predictor, Xb+Zu, then the probability of being in category i is

pnorm(cp[i+1], eta , sqrt(Vr)) - pnorm(cp[i], eta, sqrt(Vr))

when family=?threshold?. Vr is the residual (units) variance. When Vr=1 this is standard profit regression. When family=?ordinal? it is:

pnorm(cp[i+1], eta , sqrt(Vr+1)) - pnorm(cp[i], eta, sqrt(Vr+1))

Its not a big deal because the eta cam be rescaled to be equivalent:

eta_ordinal/sqrt(Vr+1) = eta_threshold/sqrt(Vr)

and Vr is fixed.

However, the MCMC algorithm for  family=?threshold? is more efficient.

Cheers,

Jarrod


On 3 Aug 2018, at 12:43, roee maor <roeemaor at gmail.com<mailto:roeemaor at gmail.com>> wrote:

Thanks everyone for your quick and helpful responses.
Removing the 'trait' terms indeed solved this problem and I have taken
Jarrod's advice to use family="threshold" instead of "ordinal".

Would it be possible to get a quick summary of the main differences
between ordinal and threshold models? Both seem to be rarely used and
I can't find much documentation on their inner workings in the
MCMCglmm vignette, tutorial or course notes.

Cheers,
RoiOn Thu, 2 Aug 2018 at 14:45, Paul Buerkner <paul.buerkner at gmail.com<mailto:paul.buerkner at gmail.com>> wrote:

If it doesn't end up working in MCMCglmm, you may also try the brms package.

See https://cran.r-project.org/web/packages/brms/vignettes/brms_phylogenetics.html for an introduction of
phylogenetic models in brms.

2018-08-02 15:39 GMT+02:00 Dexter Locke <dexter.locke at gmail.com<mailto:dexter.locke at gmail.com>>:

Maybe Response needs to be an ordered factor, not a factor with three levels. Try something like

valid$Response <- as.factor(valid$Response, ordered=T)

See also th clmm package.

HTH, Dexter



On Aug 2, 2018, at 9:24 AM, roee maor <roeemaor at gmail.com<mailto:roeemaor at gmail.com>> wrote:

Dear list,

I'm using MCMCglmm to run a phylogenetic model where the response is a
3-level ordinal factor (i.e. level 2 is an intermediate phenotype
between 1 and 3), and the predictors include one factorial (foraging
habitat), one ordinal (trophic level), and several continuous
variables.

As far as I know MCMCglmm is the only package that can handle logistic
models for phylogenetically structured multi-level discrete data, but
please correct me if that's not the case.

My problem right now is that I can't get MCMCglmm() to work with the
'family' argument set to "ordinal", although it does work with
"categorical".
Here's the code I'm using:

packageVersion("MCMCglmm")
[1] ?2.25?
R.version.string
[1] "R version 3.4.3 (2017-11-30)"

## model specifications:
INphylo <- inverseA(mammaltree, nodes="ALL", scale=TRUE)  ## phylogeny with 1399 tips, setting nodes="TIPS" is extremely slow
k <- length(levels(valid$Response))
I <- diag(k-1)
J <- matrix(rep(1, (k-1)^2), c(k-1, k-1))

## categorical model (unordered response) - runs to completion
m1 <- MCMCglmm(Response ~ -1 + trait + ForagingHab + Troph_Lev + Mass + Mean.Diur.Range + Max.Temp.Warmest.M + Temp.Annual.Range + Precip.Driest.Month + PET,
+                random = ~ us(trait):Binomial,
+                rcov = ~ us(trait):units,
+                prior = list(R = list(fix=1, V=(1/k) * (I + J), n = k-1),
+                             G = list(G1 = list(V = diag(k-1), n = k-1))),
+                ginverse = list(Binomial=INphylo$Ainv),
+                burnin = 300000,
+                nitt = 3000000,
+                thin = 2000,
+                family = "categorical",
+                data = valid,
+                pl = TRUE)

## ordinal model and error message
m2 <- MCMCglmm(Response ~ -1 + trait + ForagingHab + Troph_Lev + Mass + Mean.Diur.Range + Max.Temp.Warmest.M + Temp.Annual.Range + Precip.Driest.Month + PET,
+                random = ~ us(trait):Binomial,
+                rcov = ~ us(trait):units,
+                prior = list(R = list(fix=1, V=1, n = k-1),
+                             G = list(G1 = list(V = diag(k-1), n = k-1))),
+                ginverse = list(Binomial=INphylo$Ainv),
+                burnin = 300000,
+                nitt = 3000000,
+                thin = 2000,
+                family = "ordinal",
+                data = valid,
+                pl = TRUE)
Error in `contrasts<-`(`*tmp*`, value = contr.funs[1 + isOF[nn]]) :
contrasts can be applied only to factors with 2 or more levels

## the shape of the data
str(valid)
'data.frame': 1399 obs. of  16 variables:
$ Binomial           : chr  "Abrocoma_bennettii" "Abrothrix_andinus"
"Abrothrix_jelskii" "Abrothrix_longipilis" ...
$ Response           : Factor w/ 3 levels "1","2","3": 1 3 2 2 2 3 2 3 1 3 ...
$ ForagingHab        : Factor w/ 7 levels "1","3","4","5",..: 2 2 2 2
2 2 2 2 2 2 ...
$ Troph_Lev          : Factor w/ 3 levels "1","2","3": 1 2 2 2 2 3 2 1 1 1 ...
$ Mass               : num  250.5 24.9 34.5 38.9 24.5 ...
$ Annual.Mean.Temp   : num  12.42 7.26 9.18 9.9 8.62 ...
$ Mean.Diur.Range    : num  10.46 13.82 16.16 9.15 7.78 ...
$ Max.Temp.Warmest.M : num  22 16.6 19.1 19.8 17.2 ...
$ Min.Temp.Coldest.M : num  3.77 -3.98 -3.24 2.21 1.46 ...
$ Temp.Annual.Range  : num  18.3 20.6 22.4 17.6 15.7 ...
$ Mean.Temp.Warm.Q   : num  16 9.2 11.1 13.8 12.2 ...
$ Mean.Temp.Cold.Q   : num  8.87 4.49 6.39 5.98 4.87 ...
$ Annual.Precip      : num  166 645 558 903 1665 ...
$ Precip.Driest.Month: num  1.74 5.99 6.31 31.31 104.7 ...
$ AET                : num  213 482 704 455 361 ...
$ PET                : num  1074 1242 1305 677 638 ...


I don't understand what factors the error refers to, because there
sufficient levels in the response even if one is absorbed in the
intercept.

The R-constraint in the prior is specified as suggested in the
MCMCglmm tutorial (fix=1, V=1), but the error message is the same
whether I use this specification or the categorical model
specification (fix=1, V=(1/k)*(I + J)) .

On a side note - what parameters affect the acceptance rates? The
categorical models maintain a rate of around 0.3 so I think the mixing
could be improved.

Any input would be very much appreciated.

Many thanks,
Roi Maor

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20180803/3973117b/attachment.ksh>

From roeem@or @ending from gm@il@com  Fri Aug  3 14:08:22 2018
From: roeem@or @ending from gm@il@com (roee maor)
Date: Fri, 3 Aug 2018 13:08:22 +0100
Subject: [R-sig-ME] Error in phylogenetic ordinal model with MCMCglmm()
In-Reply-To: <ED5845D5-8019-4985-B5AD-D245A761F3E2@ed.ac.uk>
References: <CACxNx6scRX10fWqXOSAvUn5eT7-g=By8yzV1hAD9Zk2riHVRDQ@mail.gmail.com>
 <7AD66B65-0524-4F68-B056-EE5D63932249@gmail.com>
 <CAGoSky_d2utNwJtae5rUBn_fwkDPD=ZwPgn-4kqLMx685=SZjQ@mail.gmail.com>
 <CACxNx6sc2s3BVD1_4F7=vuLNsSFMbONjxELsfSmWZ+XQQ63+CA@mail.gmail.com>
 <ED5845D5-8019-4985-B5AD-D245A761F3E2@ed.ac.uk>
Message-ID: <CACxNx6u71ZcwTfAPi9+-6U8_SXSvB3qL7dvn5C6b0hA6vFePtQ@mail.gmail.com>

That's great Jarrod,  thanks very much!
Roi
On Fri, 3 Aug 2018 at 12:58, HADFIELD Jarrod <j.hadfield at ed.ac.uk> wrote:
>
> Hi,
>
> With three levels you have 4 cut-points, one of which needs estimating (call it cp.est)
>
> cp<-c(-Inf, 0, cp.est, Inf)
>
> If eta is the fixed+random effect linear predictor, Xb+Zu, then the probability of being in category i is
>
> pnorm(cp[i+1], eta , sqrt(Vr)) - pnorm(cp[i], eta, sqrt(Vr))
>
> when family=?threshold?. Vr is the residual (units) variance. When Vr=1 this is standard profit regression. When family=?ordinal? it is:
>
> pnorm(cp[i+1], eta , sqrt(Vr+1)) - pnorm(cp[i], eta, sqrt(Vr+1))
>
> Its not a big deal because the eta cam be rescaled to be equivalent:
>
> eta_ordinal/sqrt(Vr+1) = eta_threshold/sqrt(Vr)
>
> and Vr is fixed.
>
> However, the MCMC algorithm for  family=?threshold? is more efficient.
>
> Cheers,
>
> Jarrod
>
>
> On 3 Aug 2018, at 12:43, roee maor <roeemaor at gmail.com> wrote:
>
> Thanks everyone for your quick and helpful responses.
> Removing the 'trait' terms indeed solved this problem and I have taken
> Jarrod's advice to use family="threshold" instead of "ordinal".
>
> Would it be possible to get a quick summary of the main differences
> between ordinal and threshold models? Both seem to be rarely used and
> I can't find much documentation on their inner workings in the
> MCMCglmm vignette, tutorial or course notes.
>
> Cheers,
> RoiOn Thu, 2 Aug 2018 at 14:45, Paul Buerkner <paul.buerkner at gmail.com> wrote:
>
>
> If it doesn't end up working in MCMCglmm, you may also try the brms package.
>
> See https://cran.r-project.org/web/packages/brms/vignettes/brms_phylogenetics.html for an introduction of
> phylogenetic models in brms.
>
> 2018-08-02 15:39 GMT+02:00 Dexter Locke <dexter.locke at gmail.com>:
>
>
> Maybe Response needs to be an ordered factor, not a factor with three levels. Try something like
>
> valid$Response <- as.factor(valid$Response, ordered=T)
>
> See also th clmm package.
>
> HTH, Dexter
>
>
>
> On Aug 2, 2018, at 9:24 AM, roee maor <roeemaor at gmail.com> wrote:
>
> Dear list,
>
> I'm using MCMCglmm to run a phylogenetic model where the response is a
> 3-level ordinal factor (i.e. level 2 is an intermediate phenotype
> between 1 and 3), and the predictors include one factorial (foraging
> habitat), one ordinal (trophic level), and several continuous
> variables.
>
> As far as I know MCMCglmm is the only package that can handle logistic
> models for phylogenetically structured multi-level discrete data, but
> please correct me if that's not the case.
>
> My problem right now is that I can't get MCMCglmm() to work with the
> 'family' argument set to "ordinal", although it does work with
> "categorical".
> Here's the code I'm using:
>
> packageVersion("MCMCglmm")
>
> [1] ?2.25?
>
> R.version.string
>
> [1] "R version 3.4.3 (2017-11-30)"
>
> ## model specifications:
>
> INphylo <- inverseA(mammaltree, nodes="ALL", scale=TRUE)  ## phylogeny with 1399 tips, setting nodes="TIPS" is extremely slow
> k <- length(levels(valid$Response))
> I <- diag(k-1)
> J <- matrix(rep(1, (k-1)^2), c(k-1, k-1))
>
>
> ## categorical model (unordered response) - runs to completion
>
> m1 <- MCMCglmm(Response ~ -1 + trait + ForagingHab + Troph_Lev + Mass + Mean.Diur.Range + Max.Temp.Warmest.M + Temp.Annual.Range + Precip.Driest.Month + PET,
>
> +                random = ~ us(trait):Binomial,
> +                rcov = ~ us(trait):units,
> +                prior = list(R = list(fix=1, V=(1/k) * (I + J), n = k-1),
> +                             G = list(G1 = list(V = diag(k-1), n = k-1))),
> +                ginverse = list(Binomial=INphylo$Ainv),
> +                burnin = 300000,
> +                nitt = 3000000,
> +                thin = 2000,
> +                family = "categorical",
> +                data = valid,
> +                pl = TRUE)
>
> ## ordinal model and error message
>
> m2 <- MCMCglmm(Response ~ -1 + trait + ForagingHab + Troph_Lev + Mass + Mean.Diur.Range + Max.Temp.Warmest.M + Temp.Annual.Range + Precip.Driest.Month + PET,
>
> +                random = ~ us(trait):Binomial,
> +                rcov = ~ us(trait):units,
> +                prior = list(R = list(fix=1, V=1, n = k-1),
> +                             G = list(G1 = list(V = diag(k-1), n = k-1))),
> +                ginverse = list(Binomial=INphylo$Ainv),
> +                burnin = 300000,
> +                nitt = 3000000,
> +                thin = 2000,
> +                family = "ordinal",
> +                data = valid,
> +                pl = TRUE)
> Error in `contrasts<-`(`*tmp*`, value = contr.funs[1 + isOF[nn]]) :
> contrasts can be applied only to factors with 2 or more levels
>
> ## the shape of the data
>
> str(valid)
>
> 'data.frame': 1399 obs. of  16 variables:
> $ Binomial           : chr  "Abrocoma_bennettii" "Abrothrix_andinus"
> "Abrothrix_jelskii" "Abrothrix_longipilis" ...
> $ Response           : Factor w/ 3 levels "1","2","3": 1 3 2 2 2 3 2 3 1 3 ...
> $ ForagingHab        : Factor w/ 7 levels "1","3","4","5",..: 2 2 2 2
> 2 2 2 2 2 2 ...
> $ Troph_Lev          : Factor w/ 3 levels "1","2","3": 1 2 2 2 2 3 2 1 1 1 ...
> $ Mass               : num  250.5 24.9 34.5 38.9 24.5 ...
> $ Annual.Mean.Temp   : num  12.42 7.26 9.18 9.9 8.62 ...
> $ Mean.Diur.Range    : num  10.46 13.82 16.16 9.15 7.78 ...
> $ Max.Temp.Warmest.M : num  22 16.6 19.1 19.8 17.2 ...
> $ Min.Temp.Coldest.M : num  3.77 -3.98 -3.24 2.21 1.46 ...
> $ Temp.Annual.Range  : num  18.3 20.6 22.4 17.6 15.7 ...
> $ Mean.Temp.Warm.Q   : num  16 9.2 11.1 13.8 12.2 ...
> $ Mean.Temp.Cold.Q   : num  8.87 4.49 6.39 5.98 4.87 ...
> $ Annual.Precip      : num  166 645 558 903 1665 ...
> $ Precip.Driest.Month: num  1.74 5.99 6.31 31.31 104.7 ...
> $ AET                : num  213 482 704 455 361 ...
> $ PET                : num  1074 1242 1305 677 638 ...
>
>
> I don't understand what factors the error refers to, because there
> sufficient levels in the response even if one is absorbed in the
> intercept.
>
> The R-constraint in the prior is specified as suggested in the
> MCMCglmm tutorial (fix=1, V=1), but the error message is the same
> whether I use this specification or the categorical model
> specification (fix=1, V=(1/k)*(I + J)) .
>
> On a side note - what parameters affect the acceptance rates? The
> categorical models maintain a rate of around 0.3 so I think the mixing
> could be improved.
>
> Any input would be very much appreciated.
>
> Many thanks,
> Roi Maor
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
> The University of Edinburgh is a charitable body, registered in
> Scotland, with registration number SC005336.


From trichter @ending from uni-bremen@de  Fri Aug  3 14:43:56 2018
From: trichter @ending from uni-bremen@de (Tim Richter-Heitmann)
Date: Fri, 3 Aug 2018 14:43:56 +0200
Subject: [R-sig-ME] group-specific model slopes differ from the global
 slope: random slopes in lme?
Message-ID: <1f62fa31-64b2-23a1-fdfe-9227f8618574@uni-bremen.de>

Dear List,

i am running lme with spatial correlation structures for a dataset of 
~180 observations across six groups:

fit <- lme(outcome~var1+var2+var3, random=1|group, correlation=cor...., 
data, method="ML").

For some models, this works well; plotting the data reveals a nice 
agreement within the six groups in regards of the slope of the model.

However, for other models, plotting the data reveals that the global 
slope is clearly differing from a group-specific slope (interestingly, 
the global model explains the data fairly well, when plotted without 
facetting by group, also the qqplots look nice).

I found some references in the net that lme can incorporate random 
slopes, but i have not found tutorials how to do this. Advice would be 
well appreciated

Also, philosophically, isnt a random slope, random intercept-model 
equivalent to modelling the six groups independently? Also, how to 
report this in a manuscript? Or better not use random intercept models 
at all?

-- 
Dr. Tim Richter-Heitmann

University of Bremen
Microbial Ecophysiology Group (AG Friedrich)
FB02 - Biologie/Chemie
Leobener Stra?e (NW2 A2130)
D-28359 Bremen
Tel.: 0049(0)421 218-63062
Fax: 0049(0)421 218-63069


From bbolker @ending from gm@il@com  Fri Aug  3 16:14:37 2018
From: bbolker @ending from gm@il@com (Ben Bolker)
Date: Fri, 3 Aug 2018 10:14:37 -0400
Subject: [R-sig-ME] group-specific model slopes differ from the global
 slope: random slopes in lme?
In-Reply-To: <1f62fa31-64b2-23a1-fdfe-9227f8618574@uni-bremen.de>
References: <1f62fa31-64b2-23a1-fdfe-9227f8618574@uni-bremen.de>
Message-ID: <CABghstSnTrNX6MTjPEjDhCha2VTwOEn_h8JPLQ=0SQN+pobrfg@mail.gmail.com>

On Fri, Aug 3, 2018 at 8:44 AM Tim Richter-Heitmann
<trichter at uni-bremen.de> wrote:
>
> Dear List,
>
> i am running lme with spatial correlation structures for a dataset of
> ~180 observations across six groups:
>
> fit <- lme(outcome~var1+var2+var3, random=1|group, correlation=cor....,
> data, method="ML").
>
> For some models, this works well; plotting the data reveals a nice
> agreement within the six groups in regards of the slope of the model.
>
> However, for other models, plotting the data reveals that the global
> slope is clearly differing from a group-specific slope (interestingly,
> the global model explains the data fairly well, when plotted without
> facetting by group, also the qqplots look nice).
>
> I found some references in the net that lme can incorporate random
> slopes, but i have not found tutorials how to do this. Advice would be
> well appreciated

  A random-slope model is specified in general by ~1+x|group ; using
the Orthodont
data that comes with nlme, for example,

lme(distance~age*Sex,random=~1+age|Subject,Orthodont)

 Furthermore, the notation for the random-effects formula is shared
across many of the mixed-model
packages in R (with the exception of MCMCglmm: e.g. lme4, glmmTMB,
brms, ...), so that most any tutorial on random-slopes model that
you find will be adaptable to lme. There is a (very brief) section in
the GLMM FAQ, with additional links:
<http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#model-specification>
. Or you could do something drastic :-) and get a copy of Pinheiro and
Bates 2000 (Springer), which is the canonical documentation for lme.



> Also, philosophically, isnt a random slope, random intercept-model
> equivalent to modelling the six groups independently? Also, how to
> report this in a manuscript? Or better not use random intercept models
> at all?

  No; it assumes that (1) the residual variance is the same across all
groups (unless you go out of your way to specify otherwise) and (2)
the group-level intercepts and slopes are drawn from a bivariate
normal distribution.

  Six groups is perhaps too small for fitting a random-slopes model,
but you might succeed.
>
> --
> Dr. Tim Richter-Heitmann
>
> University of Bremen
> Microbial Ecophysiology Group (AG Friedrich)
> FB02 - Biologie/Chemie
> Leobener Stra?e (NW2 A2130)
> D-28359 Bremen
> Tel.: 0049(0)421 218-63062
> Fax: 0049(0)421 218-63069
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From @ingm@nn @ending from p@ychologie@uzh@ch  Tue Aug  7 17:42:05 2018
From: @ingm@nn @ending from p@ychologie@uzh@ch (Henrik Singmann)
Date: Tue, 7 Aug 2018 17:42:05 +0200
Subject: [R-sig-ME] 
 feedback: Anova (type III-tests) table based on LRT for
 glmmTMB models (drop1, anova, mixed)
In-Reply-To: <CAENiVe8eoSb0=bfYp4r7Yn4MHgQw58nVrNtSi34H9AtUfudvBg@mail.gmail.com>
References: <CAENiVe8eoSb0=bfYp4r7Yn4MHgQw58nVrNtSi34H9AtUfudvBg@mail.gmail.com>
Message-ID: <caebfd18-476b-afb3-356c-9977a66bf06d@psychologie.uzh.ch>

Hi all,

It took me some time, but I managed to come up with something that might 
be of help here. Specifically, I have worked on a new package, monet, 
that runs Type III like tests with arbitrary estimation function using 
anova() (i.e., LRT) as default. see: https://github.com/singmann/monet
It basically generalizes what afex::mixed does for arbitrary estimation 
and test functions.

I do not have glmmTMB installed, but as of now it works with lm and 
lme4::lmer. The main function is test_term(). It allows to pass two 
formulas, one for which submodels are created and estimates (i.e., the 
fixed-effects part) and one additional part which can for example hold 
the random-effects part.

devtools::install_github("singmann/monet")
library("monet")
set_sum_contrasts() ## quite important, currently coding is not checked
data("Machines", package = "MEMSS")

# ignoring repeated-measures
m1 <- test_terms(score ~ Machine, data=Machines, est_fun = lm)
m1
# lm Anova Table (Type III tests)
#
# Model: score ~ Machine
# Data: Machines
#    Effect Df 1 Df 0         F Pr(>F)
# 1 Machine   51    2 26.30 *** <.0001
# ---
# Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?+? 0.1 ? ? 1

# simple model with random-slopes for repeated-measures factor
m3 <- test_terms(score ~ Machine, data=Machines,
                  extra_formula = ~ (Machine|Worker),
                  est_fun = lme4::lmer, arg_est = list(REML = FALSE),
                  arg_test = list(model.names=c("f", "r")))
m3
# lme4::lmer Anova Table (Type III tests)
#
# Model: score ~ Machine + (Machine | Worker)
# Data: Machines
#    Effect Df 1 Df 0     Chisq Pr(>Chisq)
# 1 Machine   10    2 17.14 ***      .0002
# ---
# Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?+? 0.1 ? ? 1

It returns an object of class "monet" with print(), nice(), and anova() 
methods. The package is also quite lightweight and has no strong 
dependencies besides to stats.

It it does not work with glmmTMB, a reproducible example would be great. 
And I am of course happy to hear of any other comments.

Cheers,
Henrik


Am 02.08.2018 um 09:22 schrieb Guillaume Adeux:
> Sorry, my intent was definetely not to shortcut anyone or anything.
> 
> I thought I would give you all a little feedback on your propositions.
> 
> The problem with drop1 (when an interaction is in the model) is when you
> want it to behave like a type III anova. This results in one of the
> variables having zero degree of freedom, hence LRT of 0 and no p-value.
> 
> Here is the example on an output:
> 
> 
> 
> Model: mod=glmmTMB(ratio ~ block + trt * time
> +(1|plot)+(1|year)+(1|year:plot),family=list(family="beta",link="logit"),data=biomass)
> 
> drop1(mod,.~block+trt*time,test=?Chisq?)
> 
> Single term deletions
> 
>                                 Df                           AIC
> LRT                      Pr(>Chi)
> 
> <none>                                                -5092.2
> 
> block                    1                             -5093.5
> 0.7345                  0.391415
> 
> trt                         4                             -5082.7
> 17.5018                0.001544
> 
> time                      0                             -5092.2
> 0
> 
> trt:time                  4                             -5100.0
> 0.2169                  0.994527
> 
> 
> If I understand correctly, drop1 is incapable of comparing a model A+A:B
> with A+B+A:B.
> 
> Anova.III.glmmTMB indeed works but only yields Wald tests which I thought
> were not ideal for glmms.
> 
> I contacted the developper of the {afex} package to see if the mixed
> function could be adapted to run on glmmTMB objects but no luck as of now.
> Considering the framework of glmmTMB is similar to glmer, maybe this can be
> easily adapted.
> 
> Thanks for your interest. Don't hesitate if you have any input.
> 
> Guillaume ADEUX
> 
> 	[[alternative HTML version deleted]]
>


From h@nzh @ending from umich@edu  Wed Aug  8 19:22:59 2018
From: h@nzh @ending from umich@edu (Han Zhang)
Date: Wed, 8 Aug 2018 13:22:59 -0400
Subject: [R-sig-ME] Analyzing similarity scores between subjects
Message-ID: <CAH-zeEHdLEkuJXOMDoOhikNBTLtzE3psKMnf0ThaEs60yiWnPw@mail.gmail.com>

Hi all,

I have a modeling problem involving similarity scores between subjects.
During 4 time points in my experiment, I sampled eye movements of my
subjects. At each time point, subjects had either one of two different
states, Y or N. I have no control of the state, it is purely observational.
My data produces 4 similarity matrices - for each sampling, every subject
was compared to every other subject on some similarity measure of eye
movements (self-comparisons excluded). Each matrix contains three types of
comparison: N-N, N-Y, and Y-Y. My hypothesis is that the eye movements of
those in state N were more similar to each other, compared to N-Y, or Y-Y.
So N-N > N-Y or Y-Y.

I came up with a model like this:

lmer(dist ~ type + (1|sub_i) + (1|sub_i:type) + (1|segment) +
(1|segment:type) + (1|sub_i: segment) + (1|sub_i: segment:type), data,
REML=F)

where dist is the similarity score, type is a 3-level factor (n-n, n-y,
y-y), sub_i is subject ID, segment is sample ID. I was
trying to build a model with a "maximal" random structure.

Have I correctly specified my model? I have two concerns:
(1) because any given data point in the matrix belongs to two subjects, i
and j, should I include random effects for both subject i and subject j?

(2) Becuase each matrix is symmetrical, I am duplicating my data in the
above model. Should I use only the unique pairwise comparisons and do
something like this:

lmer(dist ~ type + (1|segment) + (1|segment:type), half_data, REML=F)

Thanks!


-- 
Han Zhang
Graduate Student
Combined Program in Education and Psychology
University of Michigan, Ann Arbor
Email: hanzh at umich.edu
Phone: 1-734-680-6031

	[[alternative HTML version deleted]]


From b@ron @ending from upenn@edu  Wed Aug  8 21:59:00 2018
From: b@ron @ending from upenn@edu (Jon Baron)
Date: Wed, 8 Aug 2018 15:59:00 -0400
Subject: [R-sig-ME] Analyzing similarity scores between subjects
In-Reply-To: <CAH-zeEHdLEkuJXOMDoOhikNBTLtzE3psKMnf0ThaEs60yiWnPw@mail.gmail.com>
References: <CAH-zeEHdLEkuJXOMDoOhikNBTLtzE3psKMnf0ThaEs60yiWnPw@mail.gmail.com>
Message-ID: <20180808195900.GA7286@upenn.edu>

This is a tough problem! And I'm not sure I can solve it without the
data (and I am not willing to go that far), or ever. But here are some
thoughts. If I had these data, I would not automatically think of
using a multi-level model, but, the more I think about it, the more
sense it makes. (And I would first look at something really simple to
see if my hypothesis has a chance of being correct.)

First, 4 time points may not be enough to treat time as a random
effect. It might (or might not) make sense to treat time as a fixed
effect and look at its interaction with type. It may be that time 
segment does not matter at all. But if there is an interaction you
need to worry about coding the variables so that you can still
interpret the main effect of type.

Second, it seems to me that you need random-effect terms for both
subjects in each pair. And you should use only unique pairs, so that
you do not double-count (as you realize).

Thus, the model I would think of would be something like:

lmer(dist_ij ~ type_ij*segment + (1|sub_i) + (1|sub_j))

I'm not sure about which random slopes to include, if any, but with
all of them it would be something like:

lmer(dist_ij ~ type_ij*segment + (1+type*segment|sub_i) + (1+type*segment|sub_j))

Maybe you don't need the 1 in the last grouping term.

I'm just using the "ij" notation to indicate that you have a matrix or
data frame with one row for each unique pair in each segment.

I'm not sure whether "segment" should be a number or a factor.

Jon

On 08/08/18 13:22, Han Zhang wrote:
>Hi all,
>
>I have a modeling problem involving similarity scores between subjects.
>During 4 time points in my experiment, I sampled eye movements of my
>subjects. At each time point, subjects had either one of two different
>states, Y or N. I have no control of the state, it is purely observational.
>My data produces 4 similarity matrices - for each sampling, every subject
>was compared to every other subject on some similarity measure of eye
>movements (self-comparisons excluded). Each matrix contains three types of
>comparison: N-N, N-Y, and Y-Y. My hypothesis is that the eye movements of
>those in state N were more similar to each other, compared to N-Y, or Y-Y.
>So N-N > N-Y or Y-Y.
>
>I came up with a model like this:
>
>lmer(dist ~ type + (1|sub_i) + (1|sub_i:type) + (1|segment) +
>(1|segment:type) + (1|sub_i: segment) + (1|sub_i: segment:type), data,
>REML=F)
>
>where dist is the similarity score, type is a 3-level factor (n-n, n-y,
>y-y), sub_i is subject ID, segment is sample ID. I was
>trying to build a model with a "maximal" random structure.
>
>Have I correctly specified my model? I have two concerns:
>(1) because any given data point in the matrix belongs to two subjects, i
>and j, should I include random effects for both subject i and subject j?
>
>(2) Becuase each matrix is symmetrical, I am duplicating my data in the
>above model. Should I use only the unique pairwise comparisons and do
>something like this:
>
>lmer(dist ~ type + (1|segment) + (1|segment:type), half_data, REML=F)
>
>Thanks!
>
>
>-- 
>Han Zhang
>Graduate Student
>Combined Program in Education and Psychology
>University of Michigan, Ann Arbor
>Email: hanzh at umich.edu
>Phone: 1-734-680-6031
>
>	[[alternative HTML version deleted]]
>
>_______________________________________________
>R-sig-mixed-models at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Jonathan Baron, Professor of Psychology, University of Pennsylvania
Home page: http://www.sas.upenn.edu/~baron
Editor: Judgment and Decision Making (http://journal.sjdm.org)


From tom_philippi @ending from np@@gov  Thu Aug  9 01:57:09 2018
From: tom_philippi @ending from np@@gov (Tom Philippi)
Date: Wed, 8 Aug 2018 16:57:09 -0700
Subject: [R-sig-ME] 
 [EXTERNAL] Analyzing similarity scores between subjects
In-Reply-To: <CAH-zeEHdLEkuJXOMDoOhikNBTLtzE3psKMnf0ThaEs60yiWnPw@mail.gmail.com>
References: <CAH-zeEHdLEkuJXOMDoOhikNBTLtzE3psKMnf0ThaEs60yiWnPw@mail.gmail.com>
Message-ID: <CAM9kYqgxTruBqJgBUhySn_c8FUzGxUjP2cG13_bU_ZLRp0ZRag@mail.gmail.com>

Han--
At the risk of sending you down a completely different rabbit hole:

Each subject contributes to N - 1 similarities at each time.  Depending on
the properties of your similarity score (triangle inequality & such), even
in your half_data example you don't have N * (N - 1) / 2 independent
observations.  One outlier individual will produce N-1 low similarities.
The standard approach to such dependent response variables is to retain the
matrix of similarities with subjects as rows & columns, but permute the
values of the predictor variables across the subjects for ANOSIM or Mantel
tests.

Your hypothesis seems to be a simple pairwise similarity within group N
(N-N) is greater than within group Y (Y-Y) or between groups (N-Y).  If you
had a single time or bout, that would be anosim (analysis of similarity),
where some metric (e.g., mean similarity of N-N) is calculated for the real
data, then the N & Y values are permuted across subjects, and the metric
from the real data is compared to the distribution of the metric across the
permutations (a form of Mantel Test).  One _could_ use a complex mixed
model for the metric, but for your stated hypothesis there is no reason
to.  [Also, since none of the pairwise similarities are changed for that
null distribution, just which ones are considered as N-N, the mean of N-N
similarities is a sufficient statistic.]  Several packages have functions
to perform this test, including ade4, ape, vegan.

Because you have 4 times for the same subjects, things in terms of
hypotheses get much more complicated.  Do individual subjects tend to
persist in the same state Y or N, or is state at time X not predictive of
state at time X + 1?  If subjects tend to persist in N or Y, then you might
set up hypotheses across all 4 time matrices, and permute the observed
sequences of 4 states (N-N-N-Y) across individual subjects. If a subject's
state at time X + 1 is independent of state at time X, for pairs of
subjects with N-N at 1-3 times, you could ask if their similarity at N-N
times is greater than at the other times.  Are these timepoints in a
treatment, where you have hypotheses about the effect getting stronger (or
weaker) over time?  Some such hypotheses are simple to test with functions
in vegan (or ape, etc.), while others may require explicit coding of
restricted permutations.

There are also general approaches to permutation tests for ANOVA (Anderson
2001) and outer partitioning of dissimilarity matrices (McArdle & Anderson
2001, implemented in vegan::adonis)

These approaches do not explicitly use fixed vs random effects.  Rather,
the within-subject correlated measures are accounted for via restrictions
on the permutations.  See, for example, Jari's reply here:
http://r-sig-ecology.471788.n2.nabble.com/Adonis-and-Random-Effects-td7577863.html

This may or may not be useful for your particular question.  I hope it's at
least worth your time to think about.

Tom

Anderson, M.J., 2001. A new method for non?parametric multivariate analysis
of variance. *Austral ecology*, *26*(1), pp.32-46.

Legendre, P. and Anderson, M.J., 1999. Distance?based redundancy analysis:
testing multispecies responses in multifactorial ecological
experiments. *Ecological
monographs*, *69*(1), pp.1-24.

McArdle, B.H. and Anderson, M.J., 2001. Fitting multivariate models to
community data: a comment on distance?based redundancy analysis. *Ecology*,
*82*(1), pp.290-297.



On Wed, Aug 8, 2018 at 10:23 AM Han Zhang <hanzh at umich.edu> wrote:

> Hi all,
>
> I have a modeling problem involving similarity scores between subjects.
> During 4 time points in my experiment, I sampled eye movements of my
> subjects. At each time point, subjects had either one of two different
> states, Y or N. I have no control of the state, it is purely observational.
> My data produces 4 similarity matrices - for each sampling, every subject
> was compared to every other subject on some similarity measure of eye
> movements (self-comparisons excluded). Each matrix contains three types of
> comparison: N-N, N-Y, and Y-Y. My hypothesis is that the eye movements of
> those in state N were more similar to each other, compared to N-Y, or Y-Y.
> So N-N > N-Y or Y-Y.
>
> I came up with a model like this:
>
> lmer(dist ~ type + (1|sub_i) + (1|sub_i:type) + (1|segment) +
> (1|segment:type) + (1|sub_i: segment) + (1|sub_i: segment:type), data,
> REML=F)
>
> where dist is the similarity score, type is a 3-level factor (n-n, n-y,
> y-y), sub_i is subject ID, segment is sample ID. I was
> trying to build a model with a "maximal" random structure.
>
> Have I correctly specified my model? I have two concerns:
> (1) because any given data point in the matrix belongs to two subjects, i
> and j, should I include random effects for both subject i and subject j?
>
> (2) Becuase each matrix is symmetrical, I am duplicating my data in the
> above model. Should I use only the unique pairwise comparisons and do
> something like this:
>
> lmer(dist ~ type + (1|segment) + (1|segment:type), half_data, REML=F)
>
> Thanks!
>
>
> --
> Han Zhang
> Graduate Student
> Combined Program in Education and Psychology
> University of Michigan, Ann Arbor
> Email: hanzh at umich.edu
> Phone: 1-734-680-6031
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From @ri_15_93 @ending from hotm@il@com  Wed Aug  8 19:31:43 2018
From: @ri_15_93 @ending from hotm@il@com (Ariadna Jurado Robles)
Date: Wed, 8 Aug 2018 17:31:43 +0000
Subject: [R-sig-ME] Question about glmmadmb model
Message-ID: <VI1PR0101MB22711DD1D592CF9756A5ABC0BB260@VI1PR0101MB2271.eurprd01.prod.exchangelabs.com>

Dear developers,


I hope this mail finds you well.

I have a glmmadmb model with family=nbinom1 and zeroInflation=TRUE.

I am wondering whether I can get the pseudo R2 under such circunstances.

I have tryed it with the function 'r.squaredGLMM()' but R return me the following error:

r.squaredGLMM cannot (yet) handle 'glmmADMB' object with zero-inflation

How can I get the values for both conditional and marginal R?

Could you please help me?


I wish you all the best,

Ariadna.

	[[alternative HTML version deleted]]


From guill@ume@imon@@2 @ending from gm@il@com  Thu Aug  9 10:20:58 2018
From: guill@ume@imon@@2 @ending from gm@il@com (Guillaume Adeux)
Date: Thu, 9 Aug 2018 10:20:58 +0200
Subject: [R-sig-ME] 
 feedback: Anova (type III-tests) table based on LRT for
 glmmTMB models (drop1, anova, mixed)
In-Reply-To: <caebfd18-476b-afb3-356c-9977a66bf06d@psychologie.uzh.ch>
References: <CAENiVe8eoSb0=bfYp4r7Yn4MHgQw58nVrNtSi34H9AtUfudvBg@mail.gmail.com>
 <caebfd18-476b-afb3-356c-9977a66bf06d@psychologie.uzh.ch>
Message-ID: <CAENiVe_WwoBScw5-7ZCqmOQVC9cnzT4yjdmQXnKWceZJJVzt+A@mail.gmail.com>

Hi Henrik,

Thank you very much for this work. This is highly appreciated. Here is some
feedback...

I did this on my data with the following code:

#set_sum_contrasts()
#test_terms(Ratio~block+year_s+syst+syst:year_s,extra_
formula=~(1|year:plot)+(1|plot)+(1|year),est_fun=glmmTMB::glmmTMB,data=bio)
Here is the output (year_s is scale(year)):

glmmTMB::glmmTMB Anova Table (Type III tests)

Model: Ratio2 ~ block + year_s + syst * year_s + (1 | year:plot) + (1 |
Model:     plot) + (1 | year)
Data: bio
       Effect Df 1 Df 0   Chisq Pr(>Chisq)
1       block   15    1      NA       <NA>
2      year_s   15    1    0.00        .99
3        syst   15    4 10.75 *        .03
4 year_s:syst   15    4    0.01       >.99
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?+? 0.1 ? ? 1


-The function does not seem to recognize scale() when it is directly
applied in the formula (i.e. Ratio2~block+scale(year)+syst+syst:scale(year)).
The variable needs to be scaled outside of the formula. Otherwise, we get
an error message "Error in model.matrix.default(formula,data=new_data):
model frame and formula mismatch in model.matrix()". The same thing happens
if you want to add a small constant to the response (i.e. Ratio + 0.00001).
This needs to be done outside of the function.

-When a submodel has a convergence problem, the function is not capable of
doing the likelihood ratio test (cf. submodel in which "block" was
removed). This is not so surprising but it seems like like afex::mixed was
capable of doing so. I tried bumping up the number of iterations in arg_est
with arg_est=list(control=glmmTMBControl(...)) - which works - but did not
resolve the problem.

I can send you the data if you want to have a look see :) I'm afraid I
can't add much more.

Thanks again! You have a pending citation!

Guillaume ADEUX


2018-08-07 17:42 GMT+02:00 Henrik Singmann <singmann at psychologie.uzh.ch>:

> Hi all,
>
> It took me some time, but I managed to come up with something that might
> be of help here. Specifically, I have worked on a new package, monet, that
> runs Type III like tests with arbitrary estimation function using anova()
> (i.e., LRT) as default. see: https://github.com/singmann/monet
> It basically generalizes what afex::mixed does for arbitrary estimation
> and test functions.
>
> I do not have glmmTMB installed, but as of now it works with lm and
> lme4::lmer. The main function is test_term(). It allows to pass two
> formulas, one for which submodels are created and estimates (i.e., the
> fixed-effects part) and one additional part which can for example hold the
> random-effects part.
>
> devtools::install_github("singmann/monet")
> library("monet")
> set_sum_contrasts() ## quite important, currently coding is not checked
> data("Machines", package = "MEMSS")
>
> # ignoring repeated-measures
> m1 <- test_terms(score ~ Machine, data=Machines, est_fun = lm)
> m1
> # lm Anova Table (Type III tests)
> #
> # Model: score ~ Machine
> # Data: Machines
> #    Effect Df 1 Df 0         F Pr(>F)
> # 1 Machine   51    2 26.30 *** <.0001
> # ---
> # Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?+? 0.1 ? ? 1
>
> # simple model with random-slopes for repeated-measures factor
> m3 <- test_terms(score ~ Machine, data=Machines,
>                  extra_formula = ~ (Machine|Worker),
>                  est_fun = lme4::lmer, arg_est = list(REML = FALSE),
>                  arg_test = list(model.names=c("f", "r")))
> m3
> # lme4::lmer Anova Table (Type III tests)
> #
> # Model: score ~ Machine + (Machine | Worker)
> # Data: Machines
> #    Effect Df 1 Df 0     Chisq Pr(>Chisq)
> # 1 Machine   10    2 17.14 ***      .0002
> # ---
> # Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?+? 0.1 ? ? 1
>
> It returns an object of class "monet" with print(), nice(), and anova()
> methods. The package is also quite lightweight and has no strong
> dependencies besides to stats.
>
> It it does not work with glmmTMB, a reproducible example would be great.
> And I am of course happy to hear of any other comments.
>
> Cheers,
> Henrik
>
>
>
> Am 02.08.2018 um 09:22 schrieb Guillaume Adeux:
>
>> Sorry, my intent was definetely not to shortcut anyone or anything.
>>
>> I thought I would give you all a little feedback on your propositions.
>>
>> The problem with drop1 (when an interaction is in the model) is when you
>> want it to behave like a type III anova. This results in one of the
>> variables having zero degree of freedom, hence LRT of 0 and no p-value.
>>
>> Here is the example on an output:
>>
>>
>>
>> Model: mod=glmmTMB(ratio ~ block + trt * time
>> +(1|plot)+(1|year)+(1|year:plot),family=list(family="beta",
>> link="logit"),data=biomass)
>>
>> drop1(mod,.~block+trt*time,test=?Chisq?)
>>
>> Single term deletions
>>
>>                                 Df                           AIC
>> LRT                      Pr(>Chi)
>>
>> <none>                                                -5092.2
>>
>> block                    1                             -5093.5
>> 0.7345                  0.391415
>>
>> trt                         4                             -5082.7
>> 17.5018                0.001544
>>
>> time                      0                             -5092.2
>> 0
>>
>> trt:time                  4                             -5100.0
>> 0.2169                  0.994527
>>
>>
>> If I understand correctly, drop1 is incapable of comparing a model A+A:B
>> with A+B+A:B.
>>
>> Anova.III.glmmTMB indeed works but only yields Wald tests which I thought
>> were not ideal for glmms.
>>
>> I contacted the developper of the {afex} package to see if the mixed
>> function could be adapted to run on glmmTMB objects but no luck as of now.
>> Considering the framework of glmmTMB is similar to glmer, maybe this can
>> be
>> easily adapted.
>>
>> Thanks for your interest. Don't hesitate if you have any input.
>>
>> Guillaume ADEUX
>>
>>         [[alternative HTML version deleted]]
>>
>>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From @ingm@nn @ending from p@ychologie@uzh@ch  Thu Aug  9 15:00:22 2018
From: @ingm@nn @ending from p@ychologie@uzh@ch (Henrik Singmann)
Date: Thu, 9 Aug 2018 15:00:22 +0200
Subject: [R-sig-ME] 
 feedback: Anova (type III-tests) table based on LRT for
 glmmTMB models (drop1, anova, mixed)
In-Reply-To: <CAENiVe_WwoBScw5-7ZCqmOQVC9cnzT4yjdmQXnKWceZJJVzt+A@mail.gmail.com>
References: <CAENiVe8eoSb0=bfYp4r7Yn4MHgQw58nVrNtSi34H9AtUfudvBg@mail.gmail.com>
 <caebfd18-476b-afb3-356c-9977a66bf06d@psychologie.uzh.ch>
 <CAENiVe_WwoBScw5-7ZCqmOQVC9cnzT4yjdmQXnKWceZJJVzt+A@mail.gmail.com>
Message-ID: <b398a303-f156-e215-84ff-8781832766b4@psychologie.uzh.ch>

Hi Guillaume,

Thanks for your feedback. Indeed, the initial version could not handle 
fancy formulas. I have just updated the package on github to allow this 
and also ensured it works with glmmTMB:

library("monet")
library("glmmTMB")
## adapted from the vignette:
set_sum_contrasts()
Owls <- transform(Owls,
 ????????????????? Nest=reorder(Nest,NegPerChick),
 ????????????????? NCalls=SiblingNegotiation,
 ????????????????? FT=FoodTreatment)
zipp_test <- test_terms(formula = NCalls~(FT+scale(ArrivalTime))*SexParent +
 ????????????????????????? offset(log(BroodSize)),
 ??????????????????????? data = Owls, extra_formula = ~ (1|Nest),
 ??????????????????????? est_fun = glmmTMB,
 ??????????????????????? arg_est = list(ziformula=~1, family=poisson)
)
zipp_test
# glmmTMB Anova Table (Type III tests)
#
# Model: NCalls ~ (FT + scale(ArrivalTime)) * SexParent + 
offset(log(BroodSize)) +
# Model:???? (1 | Nest)
# Data: Owls
#???????????????????????? Effect Df 1 Df 0???? Chisq Pr(>Chisq)
# 1?????????????????????????? FT??? 8??? 1 20.03 ***???? <.0001
# 2?????????? scale(ArrivalTime)??? 8??? 1 58.62 ***???? <.0001
# 3??????????????????? SexParent??? 8??? 1????? 0.00?????? >.99
# 4???????????????? FT:SexParent??? 8??? 1????? 0.00?????? >.99
# 5 scale(ArrivalTime):SexParent??? 8??? 1????? 0.00?????? >.99
# ---
# Signif. codes:? 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?+? 0.1 ? ? 1

If you have some example data, where the LRT fails, I could take a look 
at it as well. Ideally, I would then add this as a test to the package. 
So preferably with some data that is available in some package or so. 
However, if this is not possible, I could also only run the tests only 
locally and keep your data private. In this case, send me the data offlist.

Cheers,
Henrik



Am 09.08.2018 um 10:20 schrieb Guillaume Adeux:
> Hi Henrik,
>
> Thank you very much for this work. This is highly appreciated. Here is 
> some feedback...
>
> I did this on my data with the following code:
>
> #set_sum_contrasts()
> #test_terms(Ratio~block+year_s+syst+syst:year_s,extra_formula=~(1|year:plot)+(1|plot)+(1|year),est_fun=glmmTMB::glmmTMB,data=bio)
> Here is the output (year_s is scale(year)):
> glmmTMB::glmmTMB Anova Table (Type III tests) Model: Ratio2 ~ block + 
> year_s + syst * year_s + (1 | year:plot) + (1 | Model: plot) + (1 | 
> year) Data: bio Effect Df 1 Df 0 Chisq Pr(>Chisq) 1 block 15 1 NA <NA> 
> 2 year_s 15 1 0.00 .99 3 syst 15 4 10.75 * .03 4 year_s:syst 15 4 0.01 
> >.99 --- Signif. codes: 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?+? 0.1 ? ? 1
>
> -The function does not seem to recognize scale() when it is directly 
> applied in the formula (i.e. 
> Ratio2~block+scale(year)+syst+syst:scale(year)). The variable needs to 
> be scaled outside of the formula. Otherwise, we get an error message 
> "Error in model.matrix.default(formula,data=new_data): model frame and 
> formula mismatch in model.matrix()". The same thing happens if you 
> want to add a small constant to the response (i.e. Ratio + 0.00001). 
> This needs to be done outside of the function.
>
> -When a submodel has a convergence problem, the function is not 
> capable of doing the likelihood ratio test (cf. submodel in which 
> "block" was removed). This is not so surprising but it seems like like 
> afex::mixed was capable of doing so. I tried bumping up the number of 
> iterations in arg_est with arg_est=list(control=glmmTMBControl(...)) - 
> which works - but did not resolve the problem.
>
> I can send you the data if you want to have a look see :) I'm afraid I 
> can't add much more.
>
> Thanks again! You have a pending citation!
>
> Guillaume ADEUX
>
>
> 2018-08-07 17:42 GMT+02:00 Henrik Singmann 
> <singmann at psychologie.uzh.ch <mailto:singmann at psychologie.uzh.ch>>:
>
>     Hi all,
>
>     It took me some time, but I managed to come up with something that
>     might be of help here. Specifically, I have worked on a new
>     package, monet, that runs Type III like tests with arbitrary
>     estimation function using anova() (i.e., LRT) as default. see:
>     https://github.com/singmann/monet <https://github.com/singmann/monet>
>     It basically generalizes what afex::mixed does for arbitrary
>     estimation and test functions.
>
>     I do not have glmmTMB installed, but as of now it works with lm
>     and lme4::lmer. The main function is test_term(). It allows to
>     pass two formulas, one for which submodels are created and
>     estimates (i.e., the fixed-effects part) and one additional part
>     which can for example hold the random-effects part.
>
>     devtools::install_github("singmann/monet")
>     library("monet")
>     set_sum_contrasts() ## quite important, currently coding is not
>     checked
>     data("Machines", package = "MEMSS")
>
>     # ignoring repeated-measures
>     m1 <- test_terms(score ~ Machine, data=Machines, est_fun = lm)
>     m1
>     # lm Anova Table (Type III tests)
>     #
>     # Model: score ~ Machine
>     # Data: Machines
>     #? ? Effect Df 1 Df 0? ? ? ? ?F Pr(>F)
>     # 1 Machine? ?51? ? 2 26.30 *** <.0001
>     # ---
>     # Signif. codes:? 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?+? 0.1 ? ? 1
>
>     # simple model with random-slopes for repeated-measures factor
>     m3 <- test_terms(score ~ Machine, data=Machines,
>     ? ? ? ? ? ? ? ? ?extra_formula = ~ (Machine|Worker),
>     ? ? ? ? ? ? ? ? ?est_fun = lme4::lmer, arg_est = list(REML = FALSE),
>     ? ? ? ? ? ? ? ? ?arg_test = list(model.names=c("f", "r")))
>     m3
>     # lme4::lmer Anova Table (Type III tests)
>     #
>     # Model: score ~ Machine + (Machine | Worker)
>     # Data: Machines
>     #? ? Effect Df 1 Df 0? ? ?Chisq Pr(>Chisq)
>     # 1 Machine? ?10? ? 2 17.14 ***? ? ? .0002
>     # ---
>     # Signif. codes:? 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?+? 0.1 ? ? 1
>
>     It returns an object of class "monet" with print(), nice(), and
>     anova() methods. The package is also quite lightweight and has no
>     strong dependencies besides to stats.
>
>     It it does not work with glmmTMB, a reproducible example would be
>     great. And I am of course happy to hear of any other comments.
>
>     Cheers,
>     Henrik
>
>
>
>     Am 02.08.2018 um 09:22 schrieb Guillaume Adeux:
>
>         Sorry, my intent was definetely not to shortcut anyone or
>         anything.
>
>         I thought I would give you all a little feedback on your
>         propositions.
>
>         The problem with drop1 (when an interaction is in the model)
>         is when you
>         want it to behave like a type III anova. This results in one
>         of the
>         variables having zero degree of freedom, hence LRT of 0 and no
>         p-value.
>
>         Here is the example on an output:
>
>
>
>         Model: mod=glmmTMB(ratio ~ block + trt * time
>         +(1|plot)+(1|year)+(1|year:plot),family=list(family="beta",link="logit"),data=biomass)
>
>         drop1(mod,.~block+trt*time,test=?Chisq?)
>
>         Single term deletions
>
>         ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? Df ? ? ? ?AIC
>         LRT? ? ? ? ? ? ? ? ? ? ? Pr(>Chi)
>
>         <none> ? ? ? -5092.2
>
>         block? ? ? ? ? ? ? ? ? ? 1 ?-5093.5
>         0.7345? ? ? ? ? ? ? ? ? 0.391415
>
>         trt? ? ? ? ? ? ? ? ? ? ? ? ?4 ? ?-5082.7
>         17.5018? ? ? ? ? ? ? ? 0.001544
>
>         time? ? ? ? ? ? ? ? ? ? ? 0 ?-5092.2
>         0
>
>         trt:time? ? ? ? ? ? ? ? ? 4 ?-5100.0
>         0.2169? ? ? ? ? ? ? ? ? 0.994527
>
>
>         If I understand correctly, drop1 is incapable of comparing a
>         model A+A:B
>         with A+B+A:B.
>
>         Anova.III.glmmTMB indeed works but only yields Wald tests
>         which I thought
>         were not ideal for glmms.
>
>         I contacted the developper of the {afex} package to see if the
>         mixed
>         function could be adapted to run on glmmTMB objects but no
>         luck as of now.
>         Considering the framework of glmmTMB is similar to glmer,
>         maybe this can be
>         easily adapted.
>
>         Thanks for your interest. Don't hesitate if you have any input.
>
>         Guillaume ADEUX
>
>         ? ? ? ? [[alternative HTML version deleted]]
>
>
>     _______________________________________________
>     R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>
>

-- 
Dr. Henrik Singmann
PostDoc
Universit?t Z?rich, Schweiz
http://singmann.org


From @lte@@ed@c2 @ending from gm@il@com  Fri Aug 10 03:23:53 2018
From: @lte@@ed@c2 @ending from gm@il@com (C. AMAL D. GLELE)
Date: Fri, 10 Aug 2018 03:23:53 +0200
Subject: [R-sig-ME] glmms:Checking out over_under_dispersion
Message-ID: <CANrzCv0nh+D6x5fS7YjrbUtb+QKiiYmC-tb6hckV0=yxPMv+Bg@mail.gmail.com>

If, for a given built glmm "mod", I don't want to use an available tool to
check out (over or under) dispersion, with which variance should I compare
the total variance explained by mod?
In advance, thanks for your replies.
Kind regards,

	[[alternative HTML version deleted]]


From bbolker @ending from gm@il@com  Fri Aug 10 04:10:37 2018
From: bbolker @ending from gm@il@com (Ben Bolker)
Date: Thu, 9 Aug 2018 22:10:37 -0400
Subject: [R-sig-ME] glmms:Checking out over_under_dispersion
In-Reply-To: <CANrzCv0nh+D6x5fS7YjrbUtb+QKiiYmC-tb6hckV0=yxPMv+Bg@mail.gmail.com>
References: <CANrzCv0nh+D6x5fS7YjrbUtb+QKiiYmC-tb6hckV0=yxPMv+Bg@mail.gmail.com>
Message-ID: <CABghstRPuq7=dKR0VMHAHn=_GKHU2=ua7CAvenZXY86L5jhc0Q@mail.gmail.com>

The standard advice is to compare either the residual deviance or the
sum of squares of the Pearson residuals to the residual degrees of
freedom (i.e. (number of observations) - (number of parameters)). This
is essentially taking the advice for GLMs (see e.g. McCullagh and
Nelder, or probably any textbook on GLMs) and applying it to GLMMs.
On Thu, Aug 9, 2018 at 9:24 PM C. AMAL D. GLELE <altessedac2 at gmail.com> wrote:
>
> If, for a given built glmm "mod", I don't want to use an available tool to
> check out (over or under) dispersion, with which variance should I compare
> the total variance explained by mod?
> In advance, thanks for your replies.
> Kind regards,
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From john@m@indon@ld @ending from @nu@edu@@u  Fri Aug 10 05:59:40 2018
From: john@m@indon@ld @ending from @nu@edu@@u (John Maindonald)
Date: Fri, 10 Aug 2018 03:59:40 +0000
Subject: [R-sig-ME] glmms:Checking out over_under_dispersion
In-Reply-To: <CABghstRPuq7=dKR0VMHAHn=_GKHU2=ua7CAvenZXY86L5jhc0Q@mail.gmail.com>
References: <CANrzCv0nh+D6x5fS7YjrbUtb+QKiiYmC-tb6hckV0=yxPMv+Bg@mail.gmail.com>
 <CABghstRPuq7=dKR0VMHAHn=_GKHU2=ua7CAvenZXY86L5jhc0Q@mail.gmail.com>
Message-ID: <663DE863-703A-445E-904A-6F54C2B461C9@anu.edu.au>

Note also the comments of McCullagh and Nelder (2edn, 1999, p.126),
speaking somewhat disparagingly about the use of beta-binomial
models as a way to model dispersion, as defined for glm():
?Though this is an attractive option  from a theoretical standpoint, in
practice it seems unwise to rely on a specific form of over-dispersion,
particularly where the assumed form has been chosen for mathematical
convenience rather than scientific plausibility.?
At least for data with which I have been working, I beg to disagree!

The great virtue of glmmTMB::glmmTMB() is that it allows modeling of
its version of the dispersion parameter (not dispersion as for glm()) as a
function of explanatory variables.  My experience of using glmmTMB()
with a several insect mortality datasets from a much larger collection
was that, consistently, the over-dispersion factor was large at midrange
mortalities, reducing to close to 1 (i.e., binomial-like) at high mortalities.
There are only 2 datasets that I have access to that I am currently free
to make public, unfortunately.

[I suspect that one should somehow be modeling the relevant parameter
as a function of estimated mortality rather than indirectly as a function
of explanatory variables.  I?ve wondered whether there is some different
way to handle the parameterization that would build this in.]

I?ve not tried modeling the GLM style over-dispersion as a function of
explanatory variables ? there may be some of the software that is
about that allows this.  My guess is that, as reported in Morgan and
Ridout (2008) for very different data, the beta-binomial would be
favoured over a quasi-binomial, with a mixture of the two doing better still.
[A new mixture model for capture heterogeneity. Applied Statistics C.
https://doi.org/10.1111/j.1467-9876.2008.00620.x]

See https://maths-people.anu.edu.au/%7Ejohnm/r-book/4edn/ch7-BetaBinomial.pdf<https://maths-people.anu.edu.au/~johnm/r-book/4edn/ch7-BetaBinomial.pdf>
for details of what I have done with a dataset that I have permission to
expose to public view.

The beta-binomial implies that the variance can never be reduced below
a lower bound that depends on the dispersion parameter, which I find
convenient to take for this purpose as the intra-class correlation.  That is
a big difference, if one wants to use results for designing further trials,
from the story that comes from a quasi-binomial model. I think it more
likely that the benefits of increasing sample size attenuate as the sample
size increases, with no variance lower bound.  For the recent data on
which I had been working, the relevant glmmTMB abilities became
available too recently (~Jan, 2018) to be applied across all the datasets
to which I had access.  With what I believe I now know, I?d have had
the confidence to pursue the use of other packages that can be used,
with a bit more effort, to achieve a similar result.  Hindsight is a great
thing.

Were I in mid-career, I?d likely be pursuing these ideas with some vigour.
I?d be happy to co-operate with anyone who wants to take them further,
and might be able to negotiate access to a wider range of datasets than
I can currently expose to public view.  It surprises me that this seems an
area that has been very little explored, certainly as it relates to plant
quarantine research ? what has been done to date, including work that
I did in the 1980s and 1990s, now strikes me as naive.


John Maindonald             email: john.maindonald at anu.edu.au<mailto:john.maindonald at anu.edu.au>

On 10/08/2018, at 14:10, Ben Bolker <bbolker at gmail.com<mailto:bbolker at gmail.com>> wrote:

The standard advice is to compare either the residual deviance or the
sum of squares of the Pearson residuals to the residual degrees of
freedom (i.e. (number of observations) - (number of parameters)). This
is essentially taking the advice for GLMs (see e.g. McCullagh and
Nelder, or probably any textbook on GLMs) and applying it to GLMMs.
On Thu, Aug 9, 2018 at 9:24 PM C. AMAL D. GLELE <altessedac2 at gmail.com<mailto:altessedac2 at gmail.com>> wrote:

If, for a given built glmm "mod", I don't want to use an available tool to
check out (over or under) dispersion, with which variance should I compare
the total variance explained by mod?
In advance, thanks for your replies.
Kind regards,

       [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


	[[alternative HTML version deleted]]


From @lte@@ed@c2 @ending from gm@il@com  Fri Aug 10 15:12:12 2018
From: @lte@@ed@c2 @ending from gm@il@com (C. AMAL D. GLELE)
Date: Fri, 10 Aug 2018 15:12:12 +0200
Subject: [R-sig-ME] glmms:Checking out over_under_dispersion
In-Reply-To: <663DE863-703A-445E-904A-6F54C2B461C9@anu.edu.au>
References: <CANrzCv0nh+D6x5fS7YjrbUtb+QKiiYmC-tb6hckV0=yxPMv+Bg@mail.gmail.com>
 <CABghstRPuq7=dKR0VMHAHn=_GKHU2=ua7CAvenZXY86L5jhc0Q@mail.gmail.com>
 <663DE863-703A-445E-904A-6F54C2B461C9@anu.edu.au>
Message-ID: <CANrzCv28DCm_YSGX5SR--L9G=B6xeuy7Mz1cuXacR1-9RDeESQ@mail.gmail.com>

Dear all,
many thanks for your very useful advices.
Best wishes,
Amal

2018-08-10 5:59 GMT+02:00 John Maindonald <john.maindonald at anu.edu.au>:

> Note also the comments of McCullagh and Nelder (2edn, 1999, p.126),
> speaking somewhat disparagingly about the use of beta-binomial
> models as a way to model dispersion, as defined for glm():
> ?Though this is an attractive option  from a theoretical standpoint, in
> practice it seems unwise to rely on a specific form of over-dispersion,
> particularly where the assumed form has been chosen for mathematical
> convenience rather than scientific plausibility.?
> At least for data with which I have been working, I beg to disagree!
>
> The great virtue of glmmTMB::glmmTMB() is that it allows modeling of
> its version of the dispersion parameter (not dispersion as for glm()) as a
> function of explanatory variables.  My experience of using glmmTMB()
> with a several insect mortality datasets from a much larger collection
> was that, consistently, the over-dispersion factor was large at midrange
> mortalities, reducing to close to 1 (i.e., binomial-like) at high
> mortalities.
> There are only 2 datasets that I have access to that I am currently free
> to make public, unfortunately.
>
> [I suspect that one should somehow be modeling the relevant parameter
> as a function of estimated mortality rather than indirectly as a function
> of explanatory variables.  I?ve wondered whether there is some different
> way to handle the parameterization that would build this in.]
>
> I?ve not tried modeling the GLM style over-dispersion as a function of
> explanatory variables ? there may be some of the software that is
> about that allows this.  My guess is that, as reported in Morgan and
> Ridout (2008) for very different data, the beta-binomial would be
> favoured over a quasi-binomial, with a mixture of the two doing better
> still.
> [A new mixture model for capture heterogeneity. Applied Statistics C.
> https://doi.org/10.1111/j.1467-9876.2008.00620.x]
>
> See https://maths-people.anu.edu.au/%7Ejohnm/r-book/4edn/
> ch7-BetaBinomial.pdf
> <https://maths-people.anu.edu.au/~johnm/r-book/4edn/ch7-BetaBinomial.pdf>
> for details of what I have done with a dataset that I have permission to
> expose to public view.
>
> The beta-binomial implies that the variance can never be reduced below
> a lower bound that depends on the dispersion parameter, which I find
> convenient to take for this purpose as the intra-class correlation.  That
> is
> a big difference, if one wants to use results for designing further trials,
> from the story that comes from a quasi-binomial model. I think it more
> likely that the benefits of increasing sample size attenuate as the sample
> size increases, with no variance lower bound.  For the recent data on
> which I had been working, the relevant glmmTMB abilities became
> available too recently (~Jan, 2018) to be applied across all the datasets
> to which I had access.  With what I believe I now know, I?d have had
> the confidence to pursue the use of other packages that can be used,
> with a bit more effort, to achieve a similar result.  Hindsight is a great
> thing.
>
> Were I in mid-career, I?d likely be pursuing these ideas with some vigour.
> I?d be happy to co-operate with anyone who wants to take them further,
> and might be able to negotiate access to a wider range of datasets than
> I can currently expose to public view.  It surprises me that this seems an
> area that has been very little explored, certainly as it relates to plant
> quarantine research ? what has been done to date, including work that
> I did in the 1980s and 1990s, now strikes me as naive.
>
> John Maindonald             email: john.maindonald at anu.edu.au
> <john.maindonald at anu.edu.au>
>
> On 10/08/2018, at 14:10, Ben Bolker <bbolker at gmail.com> wrote:
>
> The standard advice is to compare either the residual deviance or the
> sum of squares of the Pearson residuals to the residual degrees of
> freedom (i.e. (number of observations) - (number of parameters)). This
> is essentially taking the advice for GLMs (see e.g. McCullagh and
> Nelder, or probably any textbook on GLMs) and applying it to GLMMs.
> On Thu, Aug 9, 2018 at 9:24 PM C. AMAL D. GLELE <altessedac2 at gmail.com>
> wrote:
>
>
> If, for a given built glmm "mod", I don't want to use an available tool to
> check out (over or under) dispersion, with which variance should I compare
> the total variance explained by mod?
> In advance, thanks for your replies.
> Kind regards,
>
>        [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>

	[[alternative HTML version deleted]]


From udit@@b@n@@l17 @ending from imperi@l@@c@uk  Sat Aug 11 23:33:36 2018
From: udit@@b@n@@l17 @ending from imperi@l@@c@uk (Bansal, Udita)
Date: Sat, 11 Aug 2018 21:33:36 +0000
Subject: [R-sig-ME] Interpretation of lme output with correlation structure
 specification
Message-ID: <A38BE93E-B31D-4F09-A4B8-4EA9F5DF8491@ic.ac.uk>

Hi all,

I was modeling the laying date of bird nests against moving averages of weather variables for several years of data. I used Durbin-Watson test and found considerable amount of autocorrelation in the residuals of simple linear and mixed effect models (with month as a random factor). So, I decided to run lme models with correlation structure specified. When I compare the AIC of the models with and without the correlation structure, I find that the models with the correlation structure are better.
Question 1.: How can I interpret the phi (parameter estimate for correlation structure) value in the model output?
Question 2.: Does the interpretation of phi affect the interpretation of the random effect?
Question 3.: How can I interpret the random effect (since this is different from what lmer output shows which I am used to of)?

An example output is as below:

Random effects:
Formula: ~1 | month
        (Intercept) Residual
StdDev:    12.53908 5.009051

Correlation Structure: AR(1)
Formula: ~1 | month
 Parameter estimate(s):
     Phi
0.324984

I could not find much on the interpretation for these online. Any help will be much appreciated.

Thanks
Udita Bansal

	[[alternative HTML version deleted]]


From udit@@b@n@@l17 @ending from imperi@l@@c@uk  Sun Aug 12 11:45:22 2018
From: udit@@b@n@@l17 @ending from imperi@l@@c@uk (Bansal, Udita)
Date: Sun, 12 Aug 2018 09:45:22 +0000
Subject: [R-sig-ME] 
 Interpretation of lme output with correlation structure
 specification
In-Reply-To: <fafd786e-2c37-4aa5-a2b7-a3195c7798b6@Spark>
References: <de970b8c28df4a68bbd917f0c4e8e577@MEXPR01MB0758.ausprd01.prod.outlook.com>
 <fafd786e-2c37-4aa5-a2b7-a3195c7798b6@Spark>
Message-ID: <5886FBA8-1D82-4F00-99E3-E874755EEA9E@ic.ac.uk>

Dear Andrew,

Thank you for suggesting the book. I went through the relevant parts of the book which helped me clarify my third question.

But I still am not clear on phi. What I understood is that it is the within group correlation (which is solved by the model?) whose value ranges from -1 to 1. What I didn?t understand is as follows:
Q1: Is any value of phi acceptable since it is the correlation of the within group observations which is taken into account by the model?
Q2: The AR1 parameter estimate (the ?value?) I provide while specifying the model is calculated based on AR model. How does the phi value relate with that? The book did not say much on it.

Any help will be appreciated!

Thanks
Udita Bansal

From: Andrew Robinson <apro at unimelb.edu.au>
Date: Saturday, 11 August 2018 at 11:16 PM
To: "r-sig-mixed-models at r-project.org" <r-sig-mixed-models at r-project.org>, "Bansal, Udita" <udita.bansal17 at imperial.ac.uk>
Subject: Re: [R-sig-ME] Interpretation of lme output with correlation structure specification

Hi Udita,

You should read the book cited in the package. It?s really worthwhile.

Best wishes,

Andrew

--
Andrew Robinson
Director, CEBRA, School of BioSciences
Reader & Associate Professor in Applied Statistics Tel: (+61) 0403 138 955
School of Mathematics and Statistics Fax: (+61) 03 8344 4599
University of Melbourne, VIC 3010 Australia
Email: apro at unimelb.edu.au
Website: http://cebra.unimelb.edu.au/
On 12 Aug 2018, 7:34 AM +1000, Bansal, Udita <udita.bansal17 at imperial.ac.uk>, wrote:

Hi all,

I was modeling the laying date of bird nests against moving averages of weather variables for several years of data. I used Durbin-Watson test and found considerable amount of autocorrelation in the residuals of simple linear and mixed effect models (with month as a random factor). So, I decided to run lme models with correlation structure specified. When I compare the AIC of the models with and without the correlation structure, I find that the models with the correlation structure are better.
Question 1.: How can I interpret the phi (parameter estimate for correlation structure) value in the model output?
Question 2.: Does the interpretation of phi affect the interpretation of the random effect?
Question 3.: How can I interpret the random effect (since this is different from what lmer output shows which I am used to of)?

An example output is as below:

Random effects:
Formula: ~1 | month
(Intercept) Residual
StdDev: 12.53908 5.009051

Correlation Structure: AR(1)
Formula: ~1 | month
Parameter estimate(s):
Phi
0.324984

I could not find much on the interpretation for these online. Any help will be much appreciated.

Thanks
Udita Bansal

[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From A@Robin@on @ending from m@@unimelb@edu@@u  Mon Aug 13 01:04:09 2018
From: A@Robin@on @ending from m@@unimelb@edu@@u (Andrew Robinson)
Date: Mon, 13 Aug 2018 09:04:09 +1000
Subject: [R-sig-ME] 
 Interpretation of lme output with correlation structure
 specification
In-Reply-To: <b9ef3c1fcd964f15a909b6ec732e63c4@MEXPR01MB0758.ausprd01.prod.outlook.com>
References: <de970b8c28df4a68bbd917f0c4e8e577@MEXPR01MB0758.ausprd01.prod.outlook.com>
 <fafd786e-2c37-4aa5-a2b7-a3195c7798b6@Spark>
 <b9ef3c1fcd964f15a909b6ec732e63c4@MEXPR01MB0758.ausprd01.prod.outlook.com>
Message-ID: <CAHyGmd5maUEB-FArfL-pEPz3D=a7chovL=txoy6+gAej_PQunA@mail.gmail.com>

Hi Udita,

Q1 Yes.  The correlation is taken into account in the model.

Q2 I am not sure that I know what you mean by that.  I tend to leave the
value blank and it then gets estimated in the algorithm.

Cheers,

Andrew


On 12 August 2018 at 19:45, Bansal, Udita <udita.bansal17 at imperial.ac.uk>
wrote:

> Dear Andrew,
>
> Thank you for suggesting the book. I went through the relevant parts of
> the book which helped me clarify my third question.
>
> But I still am not clear on phi. What I understood is that it is the
> within group correlation (which is solved by the model?) whose value ranges
> from -1 to 1. What I didn?t understand is as follows:
> Q1: Is any value of phi acceptable since it is the correlation of the
> within group observations which is taken into account by the model?
> Q2: The AR1 parameter estimate (the ?value?) I provide while specifying
> the model is calculated based on AR model. How does the phi value relate
> with that? The book did not say much on it.
>
> Any help will be appreciated!
>
> Thanks
> Udita Bansal
>
> From: Andrew Robinson <apro at unimelb.edu.au>
> Date: Saturday, 11 August 2018 at 11:16 PM
> To: "r-sig-mixed-models at r-project.org" <r-sig-mixed-models at r-project.org>,
> "Bansal, Udita" <udita.bansal17 at imperial.ac.uk>
> Subject: Re: [R-sig-ME] Interpretation of lme output with correlation
> structure specification
>
>
> Hi Udita,
>
> You should read the book cited in the package. It?s really worthwhile.
>
> Best wishes,
>
> Andrew
>
> --
> Andrew Robinson
> Director, CEBRA, School of BioSciences
> Reader & Associate Professor in Applied Statistics Tel: (+61) 0403 138 955
> School of Mathematics and Statistics Fax: (+61) 03 8344 4599
> University of Melbourne, VIC 3010 Australia
> Email: apro at unimelb.edu.au
> Website: http://cebra.unimelb.edu.au/
> On 12 Aug 2018, 7:34 AM +1000, Bansal, Udita <
> udita.bansal17 at imperial.ac.uk>, wrote:
>
> Hi all,
>
> I was modeling the laying date of bird nests against moving averages of
> weather variables for several years of data. I used Durbin-Watson test and
> found considerable amount of autocorrelation in the residuals of simple
> linear and mixed effect models (with month as a random factor). So, I
> decided to run lme models with correlation structure specified. When I
> compare the AIC of the models with and without the correlation structure, I
> find that the models with the correlation structure are better.
> Question 1.: How can I interpret the phi (parameter estimate for
> correlation structure) value in the model output?
> Question 2.: Does the interpretation of phi affect the interpretation of
> the random effect?
> Question 3.: How can I interpret the random effect (since this is
> different from what lmer output shows which I am used to of)?
>
> An example output is as below:
>
> Random effects:
> Formula: ~1 | month
> (Intercept) Residual
> StdDev: 12.53908 5.009051
>
> Correlation Structure: AR(1)
> Formula: ~1 | month
> Parameter estimate(s):
> Phi
> 0.324984
>
> I could not find much on the interpretation for these online. Any help
> will be much appreciated.
>
> Thanks
> Udita Bansal
>
> [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



-- 
Andrew Robinson
Director, CEBRA, School of BioSciences
Reader & Associate Professor in Applied Statistics  Tel: (+61) 0403 138 955
School of Mathematics and Statistics                        Fax: (+61) 03
8344 4599
University of Melbourne, VIC 3010 Australia
Email: apro at unimelb.edu.au
Website: http://www.ms.unimelb.edu.au/~andrewpr

	[[alternative HTML version deleted]]


From udit@@b@n@@l17 @ending from imperi@l@@c@uk  Mon Aug 13 09:56:52 2018
From: udit@@b@n@@l17 @ending from imperi@l@@c@uk (Bansal, Udita)
Date: Mon, 13 Aug 2018 07:56:52 +0000
Subject: [R-sig-ME] 
 Interpretation of lme output with correlation structure
 specification
In-Reply-To: <CAHyGmd5maUEB-FArfL-pEPz3D=a7chovL=txoy6+gAej_PQunA@mail.gmail.com>
References: <de970b8c28df4a68bbd917f0c4e8e577@MEXPR01MB0758.ausprd01.prod.outlook.com>
 <fafd786e-2c37-4aa5-a2b7-a3195c7798b6@Spark>
 <b9ef3c1fcd964f15a909b6ec732e63c4@MEXPR01MB0758.ausprd01.prod.outlook.com>
 <CAHyGmd5maUEB-FArfL-pEPz3D=a7chovL=txoy6+gAej_PQunA@mail.gmail.com>
Message-ID: <369A4DB3-3D24-4D83-98B7-189C1F476D63@ic.ac.uk>

Hi Andrew,

Thanks for your response.

I had just one more question. I was using a nested random effect and the output looks like follows:

Random effects:
Formula: ~1 | year
        (Intercept)
StdDev: 0.001158148

Formula: ~1 | month %in% year
        (Intercept) Residual
StdDev:    7.551615  3.77298

From an example on non-nested random effect in the book, I understood that (Intercept) is the between group variance explained by the random effect and Residual value gives the within-group variance. And to get the StdDev, I should actually use the intervals command?

So, in the above case the Intercept for ~1|year gives the variance between years, the intercept for ~1|month %in% year gives the variance between months in a given year and the residual is the within month variance in a given year. Am I interpreting it correctly? I would divide each value by all the total sum to get the percentage variance explained? Also, why does the output say StdDev? Do I need to square it to actually get the variance for the groups?

Also, the intervals command doesn?t seem to work with lme models. Anyone has any idea about that?

Thanks
Udita

From: <mensurationist at gmail.com> on behalf of Andrew Robinson <A.Robinson at ms.unimelb.edu.au>
Date: Monday, 13 August 2018 at 12:04 AM
To: "Bansal, Udita" <udita.bansal17 at imperial.ac.uk>
Cc: "r-sig-mixed-models at r-project.org" <r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] Interpretation of lme output with correlation structure specification

Hi Udita,

Q1 Yes.  The correlation is taken into account in the model.

Q2 I am not sure that I know what you mean by that.  I tend to leave the value blank and it then gets estimated in the algorithm.

Cheers,

Andrew


On 12 August 2018 at 19:45, Bansal, Udita <udita.bansal17 at imperial.ac.uk<mailto:udita.bansal17 at imperial.ac.uk>> wrote:
Dear Andrew,

Thank you for suggesting the book. I went through the relevant parts of the book which helped me clarify my third question.

But I still am not clear on phi. What I understood is that it is the within group correlation (which is solved by the model?) whose value ranges from -1 to 1. What I didn?t understand is as follows:
Q1: Is any value of phi acceptable since it is the correlation of the within group observations which is taken into account by the model?
Q2: The AR1 parameter estimate (the ?value?) I provide while specifying the model is calculated based on AR model. How does the phi value relate with that? The book did not say much on it.

Any help will be appreciated!

Thanks
Udita Bansal

From: Andrew Robinson <apro at unimelb.edu.au<mailto:apro at unimelb.edu.au>>
Date: Saturday, 11 August 2018 at 11:16 PM
To: "r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>" <r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>>, "Bansal, Udita" <udita.bansal17 at imperial.ac.uk<mailto:udita.bansal17 at imperial.ac.uk>>
Subject: Re: [R-sig-ME] Interpretation of lme output with correlation structure specification


Hi Udita,

You should read the book cited in the package. It?s really worthwhile.

Best wishes,

Andrew

--
Andrew Robinson
Director, CEBRA, School of BioSciences
Reader & Associate Professor in Applied Statistics Tel: (+61) 0403 138 955
School of Mathematics and Statistics Fax: (+61) 03 8344 4599
University of Melbourne, VIC 3010 Australia
Email: apro at unimelb.edu.au<mailto:apro at unimelb.edu.au>
Website: http://cebra.unimelb.edu.au/
On 12 Aug 2018, 7:34 AM +1000, Bansal, Udita <udita.bansal17 at imperial.ac.uk<mailto:udita.bansal17 at imperial.ac.uk>>, wrote:

Hi all,

I was modeling the laying date of bird nests against moving averages of weather variables for several years of data. I used Durbin-Watson test and found considerable amount of autocorrelation in the residuals of simple linear and mixed effect models (with month as a random factor). So, I decided to run lme models with correlation structure specified. When I compare the AIC of the models with and without the correlation structure, I find that the models with the correlation structure are better.
Question 1.: How can I interpret the phi (parameter estimate for correlation structure) value in the model output?
Question 2.: Does the interpretation of phi affect the interpretation of the random effect?
Question 3.: How can I interpret the random effect (since this is different from what lmer output shows which I am used to of)?

An example output is as below:

Random effects:
Formula: ~1 | month
(Intercept) Residual
StdDev: 12.53908 5.009051

Correlation Structure: AR(1)
Formula: ~1 | month
Parameter estimate(s):
Phi
0.324984

I could not find much on the interpretation for these online. Any help will be much appreciated.

Thanks
Udita Bansal

[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



--
Andrew Robinson
Director, CEBRA, School of BioSciences
Reader & Associate Professor in Applied Statistics  Tel: (+61) 0403 138 955
School of Mathematics and Statistics                        Fax: (+61) 03 8344 4599
University of Melbourne, VIC 3010 Australia
Email: apro at unimelb.edu.au<mailto:apro at unimelb.edu.au>
Website: http://www.ms.unimelb.edu.au/~andrewpr

	[[alternative HTML version deleted]]


From udit@@b@n@@l17 @ending from imperi@l@@c@uk  Mon Aug 13 11:41:10 2018
From: udit@@b@n@@l17 @ending from imperi@l@@c@uk (Bansal, Udita)
Date: Mon, 13 Aug 2018 09:41:10 +0000
Subject: [R-sig-ME] 
 Interpretation of lme output with correlation structure
 specification
In-Reply-To: <CAHyGmd5maUEB-FArfL-pEPz3D=a7chovL=txoy6+gAej_PQunA@mail.gmail.com>
References: <de970b8c28df4a68bbd917f0c4e8e577@MEXPR01MB0758.ausprd01.prod.outlook.com>
 <fafd786e-2c37-4aa5-a2b7-a3195c7798b6@Spark>
 <b9ef3c1fcd964f15a909b6ec732e63c4@MEXPR01MB0758.ausprd01.prod.outlook.com>
 <CAHyGmd5maUEB-FArfL-pEPz3D=a7chovL=txoy6+gAej_PQunA@mail.gmail.com>
Message-ID: <1763090E-91F0-4524-8B5F-BA6344DA9FD6@ic.ac.uk>

Also, in continuation of my previous mail, I found that the error is thrown for intervals() if the model is not correct.

My original model included: ~1|year/month (doesn?t give confidence intervals)
The new model: ~1|month/year (gives me the confidence intervals)

Original model: looks at variation when going from one year to another (~1|year intercept), and whether the effect of going from one month to another changes for different years (~1|month %in% year intercept).

New model: looks at variation when going from one month to another (~1|month), and whether the effect of going from one year to another changes for different months (~1| year %in% month).

To me, the original model makes more sense. Am I not interpreting it correctly? I used the Pinheiro and Bates book for this but maybe I am not getting it right.

Anybody has any understanding on this?

Thanks
Udita

From: <mensurationist at gmail.com> on behalf of Andrew Robinson <A.Robinson at ms.unimelb.edu.au>
Date: Monday, 13 August 2018 at 12:04 AM
To: "Bansal, Udita" <udita.bansal17 at imperial.ac.uk>
Cc: "r-sig-mixed-models at r-project.org" <r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] Interpretation of lme output with correlation structure specification

Hi Udita,

Q1 Yes.  The correlation is taken into account in the model.

Q2 I am not sure that I know what you mean by that.  I tend to leave the value blank and it then gets estimated in the algorithm.

Cheers,

Andrew


On 12 August 2018 at 19:45, Bansal, Udita <udita.bansal17 at imperial.ac.uk<mailto:udita.bansal17 at imperial.ac.uk>> wrote:
Dear Andrew,

Thank you for suggesting the book. I went through the relevant parts of the book which helped me clarify my third question.

But I still am not clear on phi. What I understood is that it is the within group correlation (which is solved by the model?) whose value ranges from -1 to 1. What I didn?t understand is as follows:
Q1: Is any value of phi acceptable since it is the correlation of the within group observations which is taken into account by the model?
Q2: The AR1 parameter estimate (the ?value?) I provide while specifying the model is calculated based on AR model. How does the phi value relate with that? The book did not say much on it.

Any help will be appreciated!

Thanks
Udita Bansal

From: Andrew Robinson <apro at unimelb.edu.au<mailto:apro at unimelb.edu.au>>
Date: Saturday, 11 August 2018 at 11:16 PM
To: "r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>" <r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>>, "Bansal, Udita" <udita.bansal17 at imperial.ac.uk<mailto:udita.bansal17 at imperial.ac.uk>>
Subject: Re: [R-sig-ME] Interpretation of lme output with correlation structure specification


Hi Udita,

You should read the book cited in the package. It?s really worthwhile.

Best wishes,

Andrew

--
Andrew Robinson
Director, CEBRA, School of BioSciences
Reader & Associate Professor in Applied Statistics Tel: (+61) 0403 138 955
School of Mathematics and Statistics Fax: (+61) 03 8344 4599
University of Melbourne, VIC 3010 Australia
Email: apro at unimelb.edu.au<mailto:apro at unimelb.edu.au>
Website: http://cebra.unimelb.edu.au/
On 12 Aug 2018, 7:34 AM +1000, Bansal, Udita <udita.bansal17 at imperial.ac.uk<mailto:udita.bansal17 at imperial.ac.uk>>, wrote:

Hi all,

I was modeling the laying date of bird nests against moving averages of weather variables for several years of data. I used Durbin-Watson test and found considerable amount of autocorrelation in the residuals of simple linear and mixed effect models (with month as a random factor). So, I decided to run lme models with correlation structure specified. When I compare the AIC of the models with and without the correlation structure, I find that the models with the correlation structure are better.
Question 1.: How can I interpret the phi (parameter estimate for correlation structure) value in the model output?
Question 2.: Does the interpretation of phi affect the interpretation of the random effect?
Question 3.: How can I interpret the random effect (since this is different from what lmer output shows which I am used to of)?

An example output is as below:

Random effects:
Formula: ~1 | month
(Intercept) Residual
StdDev: 12.53908 5.009051

Correlation Structure: AR(1)
Formula: ~1 | month
Parameter estimate(s):
Phi
0.324984

I could not find much on the interpretation for these online. Any help will be much appreciated.

Thanks
Udita Bansal

[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



--
Andrew Robinson
Director, CEBRA, School of BioSciences
Reader & Associate Professor in Applied Statistics  Tel: (+61) 0403 138 955
School of Mathematics and Statistics                        Fax: (+61) 03 8344 4599
University of Melbourne, VIC 3010 Australia
Email: apro at unimelb.edu.au<mailto:apro at unimelb.edu.au>
Website: http://www.ms.unimelb.edu.au/~andrewpr

	[[alternative HTML version deleted]]


From A@Robin@on @ending from m@@unimelb@edu@@u  Mon Aug 13 13:45:51 2018
From: A@Robin@on @ending from m@@unimelb@edu@@u (Andrew Robinson)
Date: Mon, 13 Aug 2018 21:45:51 +1000
Subject: [R-sig-ME] 
 Interpretation of lme output with correlation structure
 specification
In-Reply-To: <5ad4df846ffe4a2ea23d9253568337b4@MEXPR01MB0758.ausprd01.prod.outlook.com>
References: <de970b8c28df4a68bbd917f0c4e8e577@MEXPR01MB0758.ausprd01.prod.outlook.com>
 <fafd786e-2c37-4aa5-a2b7-a3195c7798b6@Spark>
 <b9ef3c1fcd964f15a909b6ec732e63c4@MEXPR01MB0758.ausprd01.prod.outlook.com>
 <CAHyGmd5maUEB-FArfL-pEPz3D=a7chovL=txoy6+gAej_PQunA@mail.gmail.com>
 <5ad4df846ffe4a2ea23d9253568337b4@MEXPR01MB0758.ausprd01.prod.outlook.com>
Message-ID: <CAHyGmd6bcvRMEeQncocm-6oC7MgqhrgceQWq+WahGUaOGp1G5A@mail.gmail.com>

What you write seems reasonable.  I can't say more because I don't know how
you fit the model or anything about your data.

Andrew



On 13 August 2018 at 17:56, Bansal, Udita <udita.bansal17 at imperial.ac.uk>
wrote:

> Hi Andrew,
>
>
>
> Thanks for your response.
>
>
>
> I had just one more question. I was using a nested random effect and the
> output looks like follows:
>
>
>
> Random effects:
>
> Formula: ~1 | year
>
>         (Intercept)
>
> StdDev: 0.001158148
>
>
>
> Formula: ~1 | month %in% year
>
>         (Intercept) Residual
>
> StdDev:    7.551615  3.77298
>
>
>
> From an example on non-nested random effect in the book, I understood that
> (Intercept) is the between group variance explained by the random effect
> and Residual value gives the within-group variance. And to get the StdDev,
> I should actually use the intervals command?
>
>
>
> So, in the above case the Intercept for ~1|year gives the variance between
> years, the intercept for ~1|month %in% year gives the variance between
> months in a given year and the residual is the within month variance in a
> given year. Am I interpreting it correctly? I would divide each value by
> all the total sum to get the percentage variance explained? Also, why does
> the output say StdDev? Do I need to square it to actually get the variance
> for the groups?
>
>
>
> Also, the intervals command doesn?t seem to work with lme models. Anyone
> has any idea about that?
>
>
>
> Thanks
> Udita
>
>
>
> *From: *<mensurationist at gmail.com> on behalf of Andrew Robinson <
> A.Robinson at ms.unimelb.edu.au>
> *Date: *Monday, 13 August 2018 at 12:04 AM
> *To: *"Bansal, Udita" <udita.bansal17 at imperial.ac.uk>
> *Cc: *"r-sig-mixed-models at r-project.org" <r-sig-mixed-models at r-project.org
> >
> *Subject: *Re: [R-sig-ME] Interpretation of lme output with correlation
> structure specification
>
>
>
> Hi Udita,
>
>
>
> Q1 Yes.  The correlation is taken into account in the model.
>
>
>
> Q2 I am not sure that I know what you mean by that.  I tend to leave the
> value blank and it then gets estimated in the algorithm.
>
>
>
> Cheers,
>
>
>
> Andrew
>
>
>
>
>
> On 12 August 2018 at 19:45, Bansal, Udita <udita.bansal17 at imperial.ac.uk>
> wrote:
>
> Dear Andrew,
>
> Thank you for suggesting the book. I went through the relevant parts of
> the book which helped me clarify my third question.
>
> But I still am not clear on phi. What I understood is that it is the
> within group correlation (which is solved by the model?) whose value ranges
> from -1 to 1. What I didn?t understand is as follows:
> Q1: Is any value of phi acceptable since it is the correlation of the
> within group observations which is taken into account by the model?
> Q2: The AR1 parameter estimate (the ?value?) I provide while specifying
> the model is calculated based on AR model. How does the phi value relate
> with that? The book did not say much on it.
>
> Any help will be appreciated!
>
> Thanks
> Udita Bansal
>
> From: Andrew Robinson <apro at unimelb.edu.au>
> Date: Saturday, 11 August 2018 at 11:16 PM
> To: "r-sig-mixed-models at r-project.org" <r-sig-mixed-models at r-project.org>,
> "Bansal, Udita" <udita.bansal17 at imperial.ac.uk>
> Subject: Re: [R-sig-ME] Interpretation of lme output with correlation
> structure specification
>
>
>
> Hi Udita,
>
> You should read the book cited in the package. It?s really worthwhile.
>
> Best wishes,
>
> Andrew
>
> --
> Andrew Robinson
> Director, CEBRA, School of BioSciences
> Reader & Associate Professor in Applied Statistics Tel: (+61) 0403 138 955
> School of Mathematics and Statistics Fax: (+61) 03 8344 4599
> University of Melbourne, VIC 3010 Australia
> Email: apro at unimelb.edu.au
> Website: http://cebra.unimelb.edu.au/
> On 12 Aug 2018, 7:34 AM +1000, Bansal, Udita <
> udita.bansal17 at imperial.ac.uk>, wrote:
>
> Hi all,
>
> I was modeling the laying date of bird nests against moving averages of
> weather variables for several years of data. I used Durbin-Watson test and
> found considerable amount of autocorrelation in the residuals of simple
> linear and mixed effect models (with month as a random factor). So, I
> decided to run lme models with correlation structure specified. When I
> compare the AIC of the models with and without the correlation structure, I
> find that the models with the correlation structure are better.
> Question 1.: How can I interpret the phi (parameter estimate for
> correlation structure) value in the model output?
> Question 2.: Does the interpretation of phi affect the interpretation of
> the random effect?
> Question 3.: How can I interpret the random effect (since this is
> different from what lmer output shows which I am used to of)?
>
> An example output is as below:
>
> Random effects:
> Formula: ~1 | month
> (Intercept) Residual
> StdDev: 12.53908 5.009051
>
> Correlation Structure: AR(1)
> Formula: ~1 | month
> Parameter estimate(s):
> Phi
> 0.324984
>
> I could not find much on the interpretation for these online. Any help
> will be much appreciated.
>
> Thanks
> Udita Bansal
>
> [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>
>
>
> --
>
> Andrew Robinson
> Director, CEBRA, School of BioSciences
> Reader & Associate Professor in Applied Statistics  Tel: (+61) 0403 138 955
> School of Mathematics and Statistics                        Fax: (+61) 03
> 8344 4599
> University of Melbourne, VIC 3010 Australia
> Email: apro at unimelb.edu.au
> Website: http://www.ms.unimelb.edu.au/~andrewpr
>



-- 
Andrew Robinson
Director, CEBRA, School of BioSciences
Reader & Associate Professor in Applied Statistics  Tel: (+61) 0403 138 955
School of Mathematics and Statistics                        Fax: (+61) 03
8344 4599
University of Melbourne, VIC 3010 Australia
Email: apro at unimelb.edu.au
Website: http://www.ms.unimelb.edu.au/~andrewpr

	[[alternative HTML version deleted]]


From @lte@@ed@c2 @ending from gm@il@com  Mon Aug 13 15:11:40 2018
From: @lte@@ed@c2 @ending from gm@il@com (C. AMAL D. GLELE)
Date: Mon, 13 Aug 2018 15:11:40 +0200
Subject: [R-sig-ME] Error in reS$ziReStruc[[i]]
Message-ID: <CANrzCv1uuYeVW5NL2nn6S6+7BZDZBxg7=x6JKeSBFpPiVNbb=w@mail.gmail.com>

Hi, dear all.
I've built a glmm (model) with glmmTMB; it had fitted without,  neither
error message, nor warnings;
but, since I've added the following ziformula=~village (village is a 6
levels grouping factor variable), I got the warning message
"Model convergence problem; non-positive-definite Hessian matrix"
Trying to resolve this, I've used ziformula=~(1|village) instead;
 then, the model fits without neither error message, nor warnings; but when
I'd ran "summary(model)", I got the following error message "Error in
reS$ziReStruc[[i]] : subscript out of bounds": it's my first time to get
such an error message and I don't know any idea about its possible cause;
so, any help to solve it will be much appreciated.
In advance, thanks.
Kind regards,

	[[alternative HTML version deleted]]


From @pro @ending from unimelb@edu@@u  Sun Aug 12 00:15:47 2018
From: @pro @ending from unimelb@edu@@u (Andrew Robinson)
Date: Sun, 12 Aug 2018 08:15:47 +1000
Subject: [R-sig-ME] 
 Interpretation of lme output with correlation structure
 specification
In-Reply-To: <de970b8c28df4a68bbd917f0c4e8e577@MEXPR01MB0758.ausprd01.prod.outlook.com>
References: <de970b8c28df4a68bbd917f0c4e8e577@MEXPR01MB0758.ausprd01.prod.outlook.com>
Message-ID: <fafd786e-2c37-4aa5-a2b7-a3195c7798b6@Spark>

Hi Udita,

You should read the book cited in the package. It?s really worthwhile.

Best wishes,

Andrew

--
Andrew Robinson
Director, CEBRA, School of BioSciences
Reader & Associate Professor in Applied Statistics Tel: (+61) 0403 138 955
School of Mathematics and Statistics Fax: (+61) 03 8344 4599
University of Melbourne, VIC 3010 Australia
Email: apro at unimelb.edu.au
Website: http://cebra.unimelb.edu.au/
On 12 Aug 2018, 7:34 AM +1000, Bansal, Udita <udita.bansal17 at imperial.ac.uk>, wrote:
> Hi all,
>
> I was modeling the laying date of bird nests against moving averages of weather variables for several years of data. I used Durbin-Watson test and found considerable amount of autocorrelation in the residuals of simple linear and mixed effect models (with month as a random factor). So, I decided to run lme models with correlation structure specified. When I compare the AIC of the models with and without the correlation structure, I find that the models with the correlation structure are better.
> Question 1.: How can I interpret the phi (parameter estimate for correlation structure) value in the model output?
> Question 2.: Does the interpretation of phi affect the interpretation of the random effect?
> Question 3.: How can I interpret the random effect (since this is different from what lmer output shows which I am used to of)?
>
> An example output is as below:
>
> Random effects:
> Formula: ~1 | month
> (Intercept) Residual
> StdDev: 12.53908 5.009051
>
> Correlation Structure: AR(1)
> Formula: ~1 | month
> Parameter estimate(s):
> Phi
> 0.324984
>
> I could not find much on the interpretation for these online. Any help will be much appreciated.
>
> Thanks
> Udita Bansal
>
> [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From udit@@b@n@@l17 @ending from imperi@l@@c@uk  Mon Aug 13 17:56:46 2018
From: udit@@b@n@@l17 @ending from imperi@l@@c@uk (Bansal, Udita)
Date: Mon, 13 Aug 2018 15:56:46 +0000
Subject: [R-sig-ME] 
 Interpretation of lme output with correlation structure
 specification
In-Reply-To: <CAENiVe9UrM2m3a+Cr9fJrnFRFwDKcrp9NBr3MN+wci9WvoBU7w@mail.gmail.com>
References: <de970b8c28df4a68bbd917f0c4e8e577@MEXPR01MB0758.ausprd01.prod.outlook.com>
 <fafd786e-2c37-4aa5-a2b7-a3195c7798b6@Spark>
 <b9ef3c1fcd964f15a909b6ec732e63c4@MEXPR01MB0758.ausprd01.prod.outlook.com>
 <CAHyGmd5maUEB-FArfL-pEPz3D=a7chovL=txoy6+gAej_PQunA@mail.gmail.com>
 <1763090E-91F0-4524-8B5F-BA6344DA9FD6@ic.ac.uk>
 <CAENiVe9UrM2m3a+Cr9fJrnFRFwDKcrp9NBr3MN+wci9WvoBU7w@mail.gmail.com>
Message-ID: <21324978-CDCD-4CDD-AE86-BBEA1A2CE5BF@ic.ac.uk>

Thank you all for your response. I will try and explain a bit about my study and model and then maybe you can suggest why I get an error when I try to get confidence intervals for the coefficients in my original model.

I am studying the effects of temperature and precipitation across years on the breeding season of a particular bird for which I have data from three different populations. I have the following columns in my dataset:

  1.  Laying date of nest: Date when the clutch was completed for each nest, in Julian days starting from January of each year
  2.  Pre-laying period average temperature: Average temperature for a 30-day period prior to the laying date of each nest
  3.  Pre-laying period average precipitation: Average precipitation for a 30-day period prior to the laying date of each nest
  4.  Population: factor with 3 levels
  5.  Month: month for each laying date (goes from March to July usually)
  6.  Year: 1988-1994, 1994-2017 with a few missing years

My model looks as follows:

lme_m2 <- lme(LD_julian_day ~ prelaying_tmean + prelaying_prec_mean
                 + prelaying_tmean*prelaying_prec_mean + population
                 + prelaying_prec_mean*population + prelaying_tmean*population
                 + prelaying_prec_mean*prelaying_tmean*population,
                 random = ~1|month/year,
                 correlation = corARMA(0.7623, ~1|month/year, 1, 0, fixed = F),
                 data = plovers, method = "ML")

If I use ~1|year/month, it runs the model but throws an error as follows :

Error in intervals.lme(lme_m2) :
  cannot get confidence intervals on var-cov components: Non-positive definite approximate variance-covariance
Consider 'which = "fixed"

Since I want estimates of the random effects as well, I am not putting in which= fixed. If this is just something the package does then I can go ahead without confidence intervals.

Thanks
Udita

From: Guillaume Adeux <guillaumesimon.a2 at gmail.com>
Date: Monday, 13 August 2018 at 2:31 PM
To: "Bansal, Udita" <udita.bansal17 at imperial.ac.uk>
Subject: Re: [R-sig-ME] Interpretation of lme output with correlation structure specification

Indeed your original model makes more sense.
~1|year/month expants to 1|year + 1|year:month (a random intercept for each year plus for each month in each year)
whereas
~1|month/year expands to 1|month +1|month:year (here the random intercept for month will be the same for January 2016 or 2017)
Depending on how a variable is coded, it can be crossed or nested but here "month" has the same levels all the different years, so it has to be nested.
Cheers,
GA2

2018-08-13 11:41 GMT+02:00 Bansal, Udita <udita.bansal17 at imperial.ac.uk<mailto:udita.bansal17 at imperial.ac.uk>>:
Also, in continuation of my previous mail, I found that the error is thrown for intervals() if the model is not correct.

My original model included: ~1|year/month (doesn?t give confidence intervals)
The new model: ~1|month/year (gives me the confidence intervals)

Original model: looks at variation when going from one year to another (~1|year intercept), and whether the effect of going from one month to another changes for different years (~1|month %in% year intercept).

New model: looks at variation when going from one month to another (~1|month), and whether the effect of going from one year to another changes for different months (~1| year %in% month).

To me, the original model makes more sense. Am I not interpreting it correctly? I used the Pinheiro and Bates book for this but maybe I am not getting it right.

Anybody has any understanding on this?

Thanks
Udita

From: <mensurationist at gmail.com<mailto:mensurationist at gmail.com>> on behalf of Andrew Robinson <A.Robinson at ms.unimelb.edu.au<mailto:A.Robinson at ms.unimelb.edu.au>>
Date: Monday, 13 August 2018 at 12:04 AM
To: "Bansal, Udita" <udita.bansal17 at imperial.ac.uk<mailto:udita.bansal17 at imperial.ac.uk>>
Cc: "r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>" <r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>>
Subject: Re: [R-sig-ME] Interpretation of lme output with correlation structure specification

Hi Udita,

Q1 Yes.  The correlation is taken into account in the model.

Q2 I am not sure that I know what you mean by that.  I tend to leave the value blank and it then gets estimated in the algorithm.

Cheers,

Andrew


On 12 August 2018 at 19:45, Bansal, Udita <udita.bansal17 at imperial.ac.uk<mailto:udita.bansal17 at imperial.ac.uk><mailto:udita.bansal17 at imperial.ac.uk<mailto:udita.bansal17 at imperial.ac.uk>>> wrote:
Dear Andrew,

Thank you for suggesting the book. I went through the relevant parts of the book which helped me clarify my third question.

But I still am not clear on phi. What I understood is that it is the within group correlation (which is solved by the model?) whose value ranges from -1 to 1. What I didn?t understand is as follows:
Q1: Is any value of phi acceptable since it is the correlation of the within group observations which is taken into account by the model?
Q2: The AR1 parameter estimate (the ?value?) I provide while specifying the model is calculated based on AR model. How does the phi value relate with that? The book did not say much on it.

Any help will be appreciated!

Thanks
Udita Bansal

From: Andrew Robinson <apro at unimelb.edu.au<mailto:apro at unimelb.edu.au><mailto:apro at unimelb.edu.au<mailto:apro at unimelb.edu.au>>>
Date: Saturday, 11 August 2018 at 11:16 PM
To: "r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org><mailto:r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>>" <r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org><mailto:r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>>>, "Bansal, Udita" <udita.bansal17 at imperial.ac.uk<mailto:udita.bansal17 at imperial.ac.uk><mailto:udita.bansal17 at imperial.ac.uk<mailto:udita.bansal17 at imperial.ac.uk>>>
Subject: Re: [R-sig-ME] Interpretation of lme output with correlation structure specification


Hi Udita,

You should read the book cited in the package. It?s really worthwhile.

Best wishes,

Andrew

--
Andrew Robinson
Director, CEBRA, School of BioSciences
Reader & Associate Professor in Applied Statistics Tel: (+61) 0403 138 955
School of Mathematics and Statistics Fax: (+61) 03 8344 4599
University of Melbourne, VIC 3010 Australia
Email: apro at unimelb.edu.au<mailto:apro at unimelb.edu.au><mailto:apro at unimelb.edu.au<mailto:apro at unimelb.edu.au>>
Website: http://cebra.unimelb.edu.au/
On 12 Aug 2018, 7:34 AM +1000, Bansal, Udita <udita.bansal17 at imperial.ac.uk<mailto:udita.bansal17 at imperial.ac.uk><mailto:udita.bansal17 at imperial.ac.uk<mailto:udita.bansal17 at imperial.ac.uk>>>, wrote:

Hi all,

I was modeling the laying date of bird nests against moving averages of weather variables for several years of data. I used Durbin-Watson test and found considerable amount of autocorrelation in the residuals of simple linear and mixed effect models (with month as a random factor). So, I decided to run lme models with correlation structure specified. When I compare the AIC of the models with and without the correlation structure, I find that the models with the correlation structure are better.
Question 1.: How can I interpret the phi (parameter estimate for correlation structure) value in the model output?
Question 2.: Does the interpretation of phi affect the interpretation of the random effect?
Question 3.: How can I interpret the random effect (since this is different from what lmer output shows which I am used to of)?

An example output is as below:

Random effects:
Formula: ~1 | month
(Intercept) Residual
StdDev: 12.53908 5.009051

Correlation Structure: AR(1)
Formula: ~1 | month
Parameter estimate(s):
Phi
0.324984

I could not find much on the interpretation for these online. Any help will be much appreciated.

Thanks
Udita Bansal

[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org><mailto:R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org>> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org><mailto:R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org>> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



--
Andrew Robinson
Director, CEBRA, School of BioSciences
Reader & Associate Professor in Applied Statistics  Tel: (+61) 0403 138 955
School of Mathematics and Statistics                        Fax: (+61) 03 8344 4599
University of Melbourne, VIC 3010 Australia
Email: apro at unimelb.edu.au<mailto:apro at unimelb.edu.au><mailto:apro at unimelb.edu.au<mailto:apro at unimelb.edu.au>>
Website: http://www.ms.unimelb.edu.au/~andrewpr

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


	[[alternative HTML version deleted]]


From bbolker @ending from gm@il@com  Mon Aug 13 20:28:41 2018
From: bbolker @ending from gm@il@com (Ben Bolker)
Date: Mon, 13 Aug 2018 14:28:41 -0400
Subject: [R-sig-ME] Error in reS$ziReStruc[[i]]
In-Reply-To: <CANrzCv1uuYeVW5NL2nn6S6+7BZDZBxg7=x6JKeSBFpPiVNbb=w@mail.gmail.com>
References: <CANrzCv1uuYeVW5NL2nn6S6+7BZDZBxg7=x6JKeSBFpPiVNbb=w@mail.gmail.com>
Message-ID: <CABghstSzkMU4sbb7AYD8Rnp99Lm16iWOM=CatBz6MwQUhkgv=g@mail.gmail.com>

 ~village would treat village as a fixed effect in the zero-inflation
model; ~1|village would

On Mon, Aug 13, 2018 at 9:11 AM C. AMAL D. GLELE <altessedac2 at gmail.com> wrote:
>
> Hi, dear all.
> I've built a glmm (model) with glmmTMB; it had fitted without,  neither
> error message, nor warnings;
> but, since I've added the following ziformula=~village (village is a 6
> levels grouping factor variable), I got the warning message
> "Model convergence problem; non-positive-definite Hessian matrix"
> Trying to resolve this, I've used ziformula=~(1|village) instead;
>  then, the model fits without neither error message, nor warnings; but when
> I'd ran "summary(model)", I got the following error message "Error in
> reS$ziReStruc[[i]] : subscript out of bounds": it's my first time to get
> such an error message and I don't know any idea about its possible cause;
> so, any help to solve it will be much appreciated.
> In advance, thanks.
> Kind regards,
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbolker @ending from gm@il@com  Mon Aug 13 20:31:15 2018
From: bbolker @ending from gm@il@com (Ben Bolker)
Date: Mon, 13 Aug 2018 14:31:15 -0400
Subject: [R-sig-ME] Error in reS$ziReStruc[[i]]
In-Reply-To: <CABghstSzkMU4sbb7AYD8Rnp99Lm16iWOM=CatBz6MwQUhkgv=g@mail.gmail.com>
References: <CANrzCv1uuYeVW5NL2nn6S6+7BZDZBxg7=x6JKeSBFpPiVNbb=w@mail.gmail.com>
 <CABghstSzkMU4sbb7AYD8Rnp99Lm16iWOM=CatBz6MwQUhkgv=g@mail.gmail.com>
Message-ID: <CABghstSMMWpK_7d5ncUTFvc0ObQ4h-9KawwGO0ZRXdW2cJbb0g@mail.gmail.com>

 Sorry, hit 'send' by accident.

 ~village would treat village as a fixed effect in the zero-inflation
model; ~1|village [or ~(1|village)] would treat it as a random effect.
I can't reproduce a problem with summary(); here's a reproducible
example.  Can you construct a reproducible example that fails ?

dd <- data.frame(village=factor(rep(1:6,50)))
set.seed(101)
zp <- c(0.2,0.8,0.3,0.5,0.6,0.7)
dd$z <- rbinom(300,size=1,prob=zp[dd$village])
dd$z[dd$z==1] <- rpois(sum(dd$z),lambda=3)
library(glmmTMB)
g1 <- glmmTMB(z~1,ziformula=~1|village,data=dd,
        family=poisson)
g2 <- update(g1,ziformula=~village)
summary(g1)
summary(g2)
>
> On Mon, Aug 13, 2018 at 9:11 AM C. AMAL D. GLELE <altessedac2 at gmail.com> wrote:
> >
> > Hi, dear all.
> > I've built a glmm (model) with glmmTMB; it had fitted without,  neither
> > error message, nor warnings;
> > but, since I've added the following ziformula=~village (village is a 6
> > levels grouping factor variable), I got the warning message
> > "Model convergence problem; non-positive-definite Hessian matrix"
> > Trying to resolve this, I've used ziformula=~(1|village) instead;
> >  then, the model fits without neither error message, nor warnings; but when
> > I'd ran "summary(model)", I got the following error message "Error in
> > reS$ziReStruc[[i]] : subscript out of bounds": it's my first time to get
> > such an error message and I don't know any idea about its possible cause;
> > so, any help to solve it will be much appreciated.
> > In advance, thanks.
> > Kind regards,
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From mollieebrook@ @ending from gm@il@com  Mon Aug 13 20:34:54 2018
From: mollieebrook@ @ending from gm@il@com (Mollie Brooks)
Date: Mon, 13 Aug 2018 20:34:54 +0200
Subject: [R-sig-ME] Error in reS$ziReStruc[[i]]
In-Reply-To: <CANrzCv1uuYeVW5NL2nn6S6+7BZDZBxg7=x6JKeSBFpPiVNbb=w@mail.gmail.com>
References: <CANrzCv1uuYeVW5NL2nn6S6+7BZDZBxg7=x6JKeSBFpPiVNbb=w@mail.gmail.com>
Message-ID: <F8311843-E832-4082-B5DB-B9252189A4E5@gmail.com>

I think this bug was fixed in the development version (https://github.com/glmmTMB/glmmTMB/issues/370). It might still be in the CRAN version. 

Install from Github and it should work. https://github.com/glmmTMB/glmmTMB

Cheers,
Mollie

> On 13Aug 2018, at 15:11, C. AMAL D. GLELE <altessedac2 at gmail.com> wrote:
> 
> Hi, dear all.
> I've built a glmm (model) with glmmTMB; it had fitted without,  neither
> error message, nor warnings;
> but, since I've added the following ziformula=~village (village is a 6
> levels grouping factor variable), I got the warning message
> "Model convergence problem; non-positive-definite Hessian matrix"
> Trying to resolve this, I've used ziformula=~(1|village) instead;
> then, the model fits without neither error message, nor warnings; but when
> I'd ran "summary(model)", I got the following error message "Error in
> reS$ziReStruc[[i]] : subscript out of bounds": it's my first time to get
> such an error message and I don't know any idea about its possible cause;
> so, any help to solve it will be much appreciated.
> In advance, thanks.
> Kind regards,
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


	[[alternative HTML version deleted]]


From @lte@@ed@c2 @ending from gm@il@com  Mon Aug 13 23:54:12 2018
From: @lte@@ed@c2 @ending from gm@il@com (C. AMAL D. GLELE)
Date: Mon, 13 Aug 2018 23:54:12 +0200
Subject: [R-sig-ME] Error in reS$ziReStruc[[i]]
In-Reply-To: <F8311843-E832-4082-B5DB-B9252189A4E5@gmail.com>
References: <CANrzCv1uuYeVW5NL2nn6S6+7BZDZBxg7=x6JKeSBFpPiVNbb=w@mail.gmail.com>
 <F8311843-E832-4082-B5DB-B9252189A4E5@gmail.com>
Message-ID: <CANrzCv2HBJ1S-a=qW8nuBWDhZHbybcvDCzwcQXXZmxLgJAinvQ@mail.gmail.com>

Thanks to you all for your replies.
I will first try Mollie's suggestion and keep you informed.
All the best,
Amal


2018-08-13 20:34 GMT+02:00 Mollie Brooks <mollieebrooks at gmail.com>:

> I think this bug was fixed in the development version (
> https://github.com/glmmTMB/glmmTMB/issues/370). It might still be in the
> CRAN version.
>
> Install from Github and it should work. https://github.com/glmmTMB/glmmTMB
>
> Cheers,
> Mollie
>
> On 13Aug 2018, at 15:11, C. AMAL D. GLELE <altessedac2 at gmail.com> wrote:
>
> Hi, dear all.
> I've built a glmm (model) with glmmTMB; it had fitted without,  neither
> error message, nor warnings;
> but, since I've added the following ziformula=~village (village is a 6
> levels grouping factor variable), I got the warning message
> "Model convergence problem; non-positive-definite Hessian matrix"
> Trying to resolve this, I've used ziformula=~(1|village) instead;
> then, the model fits without neither error message, nor warnings; but when
> I'd ran "summary(model)", I got the following error message "Error in
> reS$ziReStruc[[i]] : subscript out of bounds": it's my first time to get
> such an error message and I don't know any idea about its possible cause;
> so, any help to solve it will be much appreciated.
> In advance, thanks.
> Kind regards,
>
> [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>

	[[alternative HTML version deleted]]


From udit@@b@n@@l17 @ending from imperi@l@@c@uk  Tue Aug 14 11:16:33 2018
From: udit@@b@n@@l17 @ending from imperi@l@@c@uk (Bansal, Udita)
Date: Tue, 14 Aug 2018 09:16:33 +0000
Subject: [R-sig-ME] 
 Interpretation of lme output with correlation structure
 specification
In-Reply-To: <CAENiVe9UrM2m3a+Cr9fJrnFRFwDKcrp9NBr3MN+wci9WvoBU7w@mail.gmail.com>
References: <de970b8c28df4a68bbd917f0c4e8e577@MEXPR01MB0758.ausprd01.prod.outlook.com>
 <fafd786e-2c37-4aa5-a2b7-a3195c7798b6@Spark>
 <b9ef3c1fcd964f15a909b6ec732e63c4@MEXPR01MB0758.ausprd01.prod.outlook.com>
 <CAHyGmd5maUEB-FArfL-pEPz3D=a7chovL=txoy6+gAej_PQunA@mail.gmail.com>
 <1763090E-91F0-4524-8B5F-BA6344DA9FD6@ic.ac.uk>
 <CAENiVe9UrM2m3a+Cr9fJrnFRFwDKcrp9NBr3MN+wci9WvoBU7w@mail.gmail.com>
Message-ID: <60260AFA-DC63-4202-A41A-DC8FD260B478@ic.ac.uk>

On second thoughts, won?t it be almost the same? If
~1|year/month expands to 1|year + 1|year:month (a random intercept for each year plus for each month in each year)
~1|month/year expands to 1|month +1|month:year (here the random intercept for month will be the same for January 2016 or 2017)?This would mean that each month has an intercept and each year for each month (like the highlighted part?).

At the end I would have

  1.  An intercept for each OR an intercept for each month
  2.  An intercept for each month in each year

Am I right?

Thanks
Udita

From: Guillaume Adeux <guillaumesimon.a2 at gmail.com>
Date: Monday, 13 August 2018 at 2:31 PM
To: "Bansal, Udita" <udita.bansal17 at imperial.ac.uk>
Subject: Re: [R-sig-ME] Interpretation of lme output with correlation structure specification

Indeed your original model makes more sense.
~1|year/month expants to 1|year + 1|year:month (a random intercept for each year plus for each month in each year)
whereas
~1|month/year expands to 1|month +1|month:year (here the random intercept for month will be the same for January 2016 or 2017)
Depending on how a variable is coded, it can be crossed or nested but here "month" has the same levels all the different years, so it has to be nested.
Cheers,
GA2

2018-08-13 11:41 GMT+02:00 Bansal, Udita <udita.bansal17 at imperial.ac.uk<mailto:udita.bansal17 at imperial.ac.uk>>:
Also, in continuation of my previous mail, I found that the error is thrown for intervals() if the model is not correct.

My original model included: ~1|year/month (doesn?t give confidence intervals)
The new model: ~1|month/year (gives me the confidence intervals)

Original model: looks at variation when going from one year to another (~1|year intercept), and whether the effect of going from one month to another changes for different years (~1|month %in% year intercept).

New model: looks at variation when going from one month to another (~1|month), and whether the effect of going from one year to another changes for different months (~1| year %in% month).

To me, the original model makes more sense. Am I not interpreting it correctly? I used the Pinheiro and Bates book for this but maybe I am not getting it right.

Anybody has any understanding on this?

Thanks
Udita

From: <mensurationist at gmail.com<mailto:mensurationist at gmail.com>> on behalf of Andrew Robinson <A.Robinson at ms.unimelb.edu.au<mailto:A.Robinson at ms.unimelb.edu.au>>
Date: Monday, 13 August 2018 at 12:04 AM
To: "Bansal, Udita" <udita.bansal17 at imperial.ac.uk<mailto:udita.bansal17 at imperial.ac.uk>>
Cc: "r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>" <r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>>
Subject: Re: [R-sig-ME] Interpretation of lme output with correlation structure specification

Hi Udita,

Q1 Yes.  The correlation is taken into account in the model.

Q2 I am not sure that I know what you mean by that.  I tend to leave the value blank and it then gets estimated in the algorithm.

Cheers,

Andrew


On 12 August 2018 at 19:45, Bansal, Udita <udita.bansal17 at imperial.ac.uk<mailto:udita.bansal17 at imperial.ac.uk><mailto:udita.bansal17 at imperial.ac.uk<mailto:udita.bansal17 at imperial.ac.uk>>> wrote:
Dear Andrew,

Thank you for suggesting the book. I went through the relevant parts of the book which helped me clarify my third question.

But I still am not clear on phi. What I understood is that it is the within group correlation (which is solved by the model?) whose value ranges from -1 to 1. What I didn?t understand is as follows:
Q1: Is any value of phi acceptable since it is the correlation of the within group observations which is taken into account by the model?
Q2: The AR1 parameter estimate (the ?value?) I provide while specifying the model is calculated based on AR model. How does the phi value relate with that? The book did not say much on it.

Any help will be appreciated!

Thanks
Udita Bansal

From: Andrew Robinson <apro at unimelb.edu.au<mailto:apro at unimelb.edu.au><mailto:apro at unimelb.edu.au<mailto:apro at unimelb.edu.au>>>
Date: Saturday, 11 August 2018 at 11:16 PM
To: "r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org><mailto:r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>>" <r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org><mailto:r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>>>, "Bansal, Udita" <udita.bansal17 at imperial.ac.uk<mailto:udita.bansal17 at imperial.ac.uk><mailto:udita.bansal17 at imperial.ac.uk<mailto:udita.bansal17 at imperial.ac.uk>>>
Subject: Re: [R-sig-ME] Interpretation of lme output with correlation structure specification


Hi Udita,

You should read the book cited in the package. It?s really worthwhile.

Best wishes,

Andrew

--
Andrew Robinson
Director, CEBRA, School of BioSciences
Reader & Associate Professor in Applied Statistics Tel: (+61) 0403 138 955
School of Mathematics and Statistics Fax: (+61) 03 8344 4599
University of Melbourne, VIC 3010 Australia
Email: apro at unimelb.edu.au<mailto:apro at unimelb.edu.au><mailto:apro at unimelb.edu.au<mailto:apro at unimelb.edu.au>>
Website: http://cebra.unimelb.edu.au/
On 12 Aug 2018, 7:34 AM +1000, Bansal, Udita <udita.bansal17 at imperial.ac.uk<mailto:udita.bansal17 at imperial.ac.uk><mailto:udita.bansal17 at imperial.ac.uk<mailto:udita.bansal17 at imperial.ac.uk>>>, wrote:

Hi all,

I was modeling the laying date of bird nests against moving averages of weather variables for several years of data. I used Durbin-Watson test and found considerable amount of autocorrelation in the residuals of simple linear and mixed effect models (with month as a random factor). So, I decided to run lme models with correlation structure specified. When I compare the AIC of the models with and without the correlation structure, I find that the models with the correlation structure are better.
Question 1.: How can I interpret the phi (parameter estimate for correlation structure) value in the model output?
Question 2.: Does the interpretation of phi affect the interpretation of the random effect?
Question 3.: How can I interpret the random effect (since this is different from what lmer output shows which I am used to of)?

An example output is as below:

Random effects:
Formula: ~1 | month
(Intercept) Residual
StdDev: 12.53908 5.009051

Correlation Structure: AR(1)
Formula: ~1 | month
Parameter estimate(s):
Phi
0.324984

I could not find much on the interpretation for these online. Any help will be much appreciated.

Thanks
Udita Bansal

[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org><mailto:R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org>> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org><mailto:R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org>> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



--
Andrew Robinson
Director, CEBRA, School of BioSciences
Reader & Associate Professor in Applied Statistics  Tel: (+61) 0403 138 955
School of Mathematics and Statistics                        Fax: (+61) 03 8344 4599
University of Melbourne, VIC 3010 Australia
Email: apro at unimelb.edu.au<mailto:apro at unimelb.edu.au><mailto:apro at unimelb.edu.au<mailto:apro at unimelb.edu.au>>
Website: http://www.ms.unimelb.edu.au/~andrewpr

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


	[[alternative HTML version deleted]]


From vicker@@m@thew @ending from gm@il@com  Tue Aug 14 11:40:34 2018
From: vicker@@m@thew @ending from gm@il@com (Mathew Vickers)
Date: Tue, 14 Aug 2018 19:40:34 +1000
Subject: [R-sig-ME] random intercept, random slope plus intercept,
 no random slope alone?
Message-ID: <CAAUAsC8TwtUO0HQEC+Joc-gr_D6viiVz=7RT1wqZBmoPaHQ5Ag@mail.gmail.com>

Dear all,

I measured running speed of 70 individual lizards. The lizards were
siblings born of 7 mothers, 10 offspring each. The Lizards ran at 3
different temperatures, A, B, and C, where A < B < C, and I recorded how
fast they ran.

I want, particularly, to examine whether a given lizard running speed of a
lizard increases, is static, or decreases. I want to know if there is
consistency (or not) in this effect between the 7 maternal lines.

The models I have now are:
m1 <- gls(speed ~ (clim + mum)^2, data=mydf, method="ML")
# fixed effects only

m2 <- lme(speed ~ (temperature + mum)^2, random=~1|LizardID, data=mydf,
control = lmeControl(opt = "optim"), method="ML")
# random intercept model (i.e., one intercept of running speed~temperature
per individual, nested within mother, a common slope per all individuals
within mother  )

m3 <- lme(speed ~ (temperature + mum)^2, random=~1+mum||LizardID,
data=mydf, control = lmeControl(opt = "optim"), method="ML")
# random intercept and slope model (i.e., one slope and one intercept of
running speed~temperature per individual, nested within mother  )


m4 <- lme(speed ~ (temperature + mum)^2, random=~0+mum||LizardID,
data=mydf, control = lmeControl(opt = "optim"), method="ML")
# uncorrelated random slope and intercept - same as last, but slope and
intercept are uncorrelated.


anova(m1, m2, m3, m4)
# this should tell me which model is the best, using AIC or loglik in
combination with the p-value.

Are all of these models and my understanding right?

What I really want to test is random slope among individuals nested within
mother. As I see this set of models, it appears that I can test random
intercept alone, and compare it to the random intercept and slope model,
but I cannot test random slope alone. Is that true, or is there a model
formulation I am missing to test only slope of running speed per individual
nested within mother?

And one other question:
Given that I am particularly interested in the questions: a) is the slope
different among individuals, and b) is the slope more consistent within
mothers than between mothers, do I need this kind of model selection?


Thanks heaps,

Mat.


-- 
Mathew Vickers

	[[alternative HTML version deleted]]


From phillip@@ld@y @ending from mpi@nl  Tue Aug 14 12:50:31 2018
From: phillip@@ld@y @ending from mpi@nl (Phillip Alday)
Date: Tue, 14 Aug 2018 12:50:31 +0200
Subject: [R-sig-ME] random intercept, random slope plus intercept,
 no random slope alone?
In-Reply-To: <CAAUAsC8TwtUO0HQEC+Joc-gr_D6viiVz=7RT1wqZBmoPaHQ5Ag@mail.gmail.com>
References: <CAAUAsC8TwtUO0HQEC+Joc-gr_D6viiVz=7RT1wqZBmoPaHQ5Ag@mail.gmail.com>
Message-ID: <e4894521-9b8d-d36d-7bf3-4e35e6fbc809@mpi.nl>

Not directly answering your question, but I don't think your models m3
and m4 are what you want.

Each LizardID presumably only has one mum, so having a slope for mum
that's allowed to vary by ID doesn't make any sense.

Maybe you want the nested effect

random=~1|mum/LizardID

?

Which will give a by-mum intercept (offset) and a by-lizard intercept.

Best,
Phillip

On 08/14/2018 11:40 AM, Mathew Vickers wrote:
> Dear all,
> 
> I measured running speed of 70 individual lizards. The lizards were
> siblings born of 7 mothers, 10 offspring each. The Lizards ran at 3
> different temperatures, A, B, and C, where A < B < C, and I recorded how
> fast they ran.
> 
> I want, particularly, to examine whether a given lizard running speed of a
> lizard increases, is static, or decreases. I want to know if there is
> consistency (or not) in this effect between the 7 maternal lines.
> 
> The models I have now are:
> m1 <- gls(speed ~ (clim + mum)^2, data=mydf, method="ML")
> # fixed effects only
> 
> m2 <- lme(speed ~ (temperature + mum)^2, random=~1|LizardID, data=mydf,
> control = lmeControl(opt = "optim"), method="ML")
> # random intercept model (i.e., one intercept of running speed~temperature
> per individual, nested within mother, a common slope per all individuals
> within mother  )
> 
> m3 <- lme(speed ~ (temperature + mum)^2, random=~1+mum||LizardID,
> data=mydf, control = lmeControl(opt = "optim"), method="ML")
> # random intercept and slope model (i.e., one slope and one intercept of
> running speed~temperature per individual, nested within mother  )
> 
> 
> m4 <- lme(speed ~ (temperature + mum)^2, random=~0+mum||LizardID,
> data=mydf, control = lmeControl(opt = "optim"), method="ML")
> # uncorrelated random slope and intercept - same as last, but slope and
> intercept are uncorrelated.
> 
> 
> anova(m1, m2, m3, m4)
> # this should tell me which model is the best, using AIC or loglik in
> combination with the p-value.
> 
> Are all of these models and my understanding right?
> 
> What I really want to test is random slope among individuals nested within
> mother. As I see this set of models, it appears that I can test random
> intercept alone, and compare it to the random intercept and slope model,
> but I cannot test random slope alone. Is that true, or is there a model
> formulation I am missing to test only slope of running speed per individual
> nested within mother?
> 
> And one other question:
> Given that I am particularly interested in the questions: a) is the slope
> different among individuals, and b) is the slope more consistent within
> mothers than between mothers, do I need this kind of model selection?
> 
> 
> Thanks heaps,
> 
> Mat.
> 
>


From guill@ume@imon@@2 @ending from gm@il@com  Tue Aug 14 18:57:30 2018
From: guill@ume@imon@@2 @ending from gm@il@com (Guillaume Adeux)
Date: Tue, 14 Aug 2018 18:57:30 +0200
Subject: [R-sig-ME] 
 Interpretation of lme output with correlation structure
 specification
In-Reply-To: <60260AFA-DC63-4202-A41A-DC8FD260B478@ic.ac.uk>
References: <de970b8c28df4a68bbd917f0c4e8e577@MEXPR01MB0758.ausprd01.prod.outlook.com>
 <fafd786e-2c37-4aa5-a2b7-a3195c7798b6@Spark>
 <b9ef3c1fcd964f15a909b6ec732e63c4@MEXPR01MB0758.ausprd01.prod.outlook.com>
 <CAHyGmd5maUEB-FArfL-pEPz3D=a7chovL=txoy6+gAej_PQunA@mail.gmail.com>
 <1763090E-91F0-4524-8B5F-BA6344DA9FD6@ic.ac.uk>
 <CAENiVe9UrM2m3a+Cr9fJrnFRFwDKcrp9NBr3MN+wci9WvoBU7w@mail.gmail.com>
 <60260AFA-DC63-4202-A41A-DC8FD260B478@ic.ac.uk>
Message-ID: <CAENiVe_UgCx75NObotu4YSEoci8+NP-M61Tj0mEsffDrQt5xwg@mail.gmail.com>

"Almost the same" depends on how strong the 1|year or 1|month effect is
because the second part of the random structure is the same(1|month:year =
1|year:month, that is to say a random intercept for each combination of
year:month).

Guillaume ADEUX

2018-08-14 11:16 GMT+02:00 Bansal, Udita <udita.bansal17 at imperial.ac.uk>:

> On second thoughts, won?t it be almost the same? If
>
> ~1|year/month expands to 1|year + 1|year:month (a random intercept for
> each year plus for each month in each year)
>
> ~1|month/year expands to 1|month +1|month:year (here the random intercept
> for month will be the same for January 2016 or 2017)?This would mean that
> each month has an intercept and each year for each month (like the
> highlighted part?).
>
>
>
> At the end I would have
>
>    1. An intercept for each OR an intercept for each month
>    2. An intercept for each month in each year
>
>
>
> Am I right?
>
>
>
> Thanks
>
> Udita
>
>
>
> *From: *Guillaume Adeux <guillaumesimon.a2 at gmail.com>
> *Date: *Monday, 13 August 2018 at 2:31 PM
> *To: *"Bansal, Udita" <udita.bansal17 at imperial.ac.uk>
>
> *Subject: *Re: [R-sig-ME] Interpretation of lme output with correlation
> structure specification
>
>
>
> Indeed your original model makes more sense.
> ~1|year/month expants to 1|year + 1|year:month (a random intercept for
> each year plus for each month in each year)
>
> whereas
> ~1|month/year expands to 1|month +1|month:year (here the random intercept
> for month will be the same for January 2016 or 2017)
>
> Depending on how a variable is coded, it can be crossed or nested but here
> "month" has the same levels all the different years, so it has to be nested.
>
> Cheers,
>
> GA2
>
>
>
> 2018-08-13 11:41 GMT+02:00 Bansal, Udita <udita.bansal17 at imperial.ac.uk>:
>
> Also, in continuation of my previous mail, I found that the error is
> thrown for intervals() if the model is not correct.
>
> My original model included: ~1|year/month (doesn?t give confidence
> intervals)
> The new model: ~1|month/year (gives me the confidence intervals)
>
> Original model: looks at variation when going from one year to another
> (~1|year intercept), and whether the effect of going from one month to
> another changes for different years (~1|month %in% year intercept).
>
> New model: looks at variation when going from one month to another
> (~1|month), and whether the effect of going from one year to another
> changes for different months (~1| year %in% month).
>
> To me, the original model makes more sense. Am I not interpreting it
> correctly? I used the Pinheiro and Bates book for this but maybe I am not
> getting it right.
>
> Anybody has any understanding on this?
>
> Thanks
> Udita
>
> From: <mensurationist at gmail.com> on behalf of Andrew Robinson <
> A.Robinson at ms.unimelb.edu.au>
> Date: Monday, 13 August 2018 at 12:04 AM
> To: "Bansal, Udita" <udita.bansal17 at imperial.ac.uk>
> Cc: "r-sig-mixed-models at r-project.org" <r-sig-mixed-models at r-project.org>
> Subject: Re: [R-sig-ME] Interpretation of lme output with correlation
> structure specification
>
> Hi Udita,
>
> Q1 Yes.  The correlation is taken into account in the model.
>
> Q2 I am not sure that I know what you mean by that.  I tend to leave the
> value blank and it then gets estimated in the algorithm.
>
> Cheers,
>
> Andrew
>
>
> On 12 August 2018 at 19:45, Bansal, Udita <udita.bansal17 at imperial.ac.uk
> <mailto:udita.bansal17 at imperial.ac.uk>> wrote:
> Dear Andrew,
>
> Thank you for suggesting the book. I went through the relevant parts of
> the book which helped me clarify my third question.
>
> But I still am not clear on phi. What I understood is that it is the
> within group correlation (which is solved by the model?) whose value ranges
> from -1 to 1. What I didn?t understand is as follows:
> Q1: Is any value of phi acceptable since it is the correlation of the
> within group observations which is taken into account by the model?
> Q2: The AR1 parameter estimate (the ?value?) I provide while specifying
> the model is calculated based on AR model. How does the phi value relate
> with that? The book did not say much on it.
>
> Any help will be appreciated!
>
> Thanks
> Udita Bansal
>
> From: Andrew Robinson <apro at unimelb.edu.au<mailto:apro at unimelb.edu.au>>
> Date: Saturday, 11 August 2018 at 11:16 PM
> To: "r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models@
> r-project.org>" <r-sig-mixed-models at r-project.org<mailto:
> r-sig-mixed-models at r-project.org>>, "Bansal, Udita" <
> udita.bansal17 at imperial.ac.uk<mailto:udita.bansal17 at imperial.ac.uk>>
> Subject: Re: [R-sig-ME] Interpretation of lme output with correlation
> structure specification
>
>
> Hi Udita,
>
> You should read the book cited in the package. It?s really worthwhile.
>
> Best wishes,
>
> Andrew
>
> --
> Andrew Robinson
> Director, CEBRA, School of BioSciences
> Reader & Associate Professor in Applied Statistics Tel: (+61) 0403 138 955
> School of Mathematics and Statistics Fax: (+61) 03 8344 4599
> University of Melbourne, VIC 3010 Australia
> Email: apro at unimelb.edu.au<mailto:apro at unimelb.edu.au>
> Website: http://cebra.unimelb.edu.au/
> On 12 Aug 2018, 7:34 AM +1000, Bansal, Udita <
> udita.bansal17 at imperial.ac.uk<mailto:udita.bansal17 at imperial.ac.uk>>,
> wrote:
>
> Hi all,
>
> I was modeling the laying date of bird nests against moving averages of
> weather variables for several years of data. I used Durbin-Watson test and
> found considerable amount of autocorrelation in the residuals of simple
> linear and mixed effect models (with month as a random factor). So, I
> decided to run lme models with correlation structure specified. When I
> compare the AIC of the models with and without the correlation structure, I
> find that the models with the correlation structure are better.
> Question 1.: How can I interpret the phi (parameter estimate for
> correlation structure) value in the model output?
> Question 2.: Does the interpretation of phi affect the interpretation of
> the random effect?
> Question 3.: How can I interpret the random effect (since this is
> different from what lmer output shows which I am used to of)?
>
> An example output is as below:
>
> Random effects:
> Formula: ~1 | month
> (Intercept) Residual
> StdDev: 12.53908 5.009051
>
> Correlation Structure: AR(1)
> Formula: ~1 | month
> Parameter estimate(s):
> Phi
> 0.324984
>
> I could not find much on the interpretation for these online. Any help
> will be much appreciated.
>
> Thanks
> Udita Bansal
>
> [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org>
> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org>
> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>
> --
> Andrew Robinson
> Director, CEBRA, School of BioSciences
> Reader & Associate Professor in Applied Statistics  Tel: (+61) 0403 138 955
> School of Mathematics and Statistics                        Fax: (+61) 03
> 8344 4599
> University of Melbourne, VIC 3010 Australia
> Email: apro at unimelb.edu.au<mailto:apro at unimelb.edu.au>
>
> Website: http://www.ms.unimelb.edu.au/~andrewpr
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>

	[[alternative HTML version deleted]]


From udit@@b@n@@l17 @ending from imperi@l@@c@uk  Tue Aug 14 19:51:46 2018
From: udit@@b@n@@l17 @ending from imperi@l@@c@uk (Bansal, Udita)
Date: Tue, 14 Aug 2018 17:51:46 +0000
Subject: [R-sig-ME] 
 Interpretation of lme output with correlation structure
 specification
In-Reply-To: <CAENiVe_UgCx75NObotu4YSEoci8+NP-M61Tj0mEsffDrQt5xwg@mail.gmail.com>
References: <de970b8c28df4a68bbd917f0c4e8e577@MEXPR01MB0758.ausprd01.prod.outlook.com>
 <fafd786e-2c37-4aa5-a2b7-a3195c7798b6@Spark>
 <b9ef3c1fcd964f15a909b6ec732e63c4@MEXPR01MB0758.ausprd01.prod.outlook.com>
 <CAHyGmd5maUEB-FArfL-pEPz3D=a7chovL=txoy6+gAej_PQunA@mail.gmail.com>
 <1763090E-91F0-4524-8B5F-BA6344DA9FD6@ic.ac.uk>
 <CAENiVe9UrM2m3a+Cr9fJrnFRFwDKcrp9NBr3MN+wci9WvoBU7w@mail.gmail.com>
 <60260AFA-DC63-4202-A41A-DC8FD260B478@ic.ac.uk>
 <CAENiVe_UgCx75NObotu4YSEoci8+NP-M61Tj0mEsffDrQt5xwg@mail.gmail.com>
Message-ID: <E4827C8F-84F0-4823-85A0-9D6701D09142@ic.ac.uk>

Yes, that?s what I wanted to confirm. The second part is the same. Thanks a lot!

Udita

From: Guillaume Adeux <guillaumesimon.a2 at gmail.com>
Date: Tuesday, 14 August 2018 at 5:57 PM
To: "Bansal, Udita" <udita.bansal17 at imperial.ac.uk>
Cc: "r-sig-mixed-models at r-project.org" <r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] Interpretation of lme output with correlation structure specification

"Almost the same" depends on how strong the 1|year or 1|month effect is because the second part of the random structure is the same(1|month:year = 1|year:month, that is to say a random intercept for each combination of year:month).

Guillaume ADEUX

2018-08-14 11:16 GMT+02:00 Bansal, Udita <udita.bansal17 at imperial.ac.uk<mailto:udita.bansal17 at imperial.ac.uk>>:
On second thoughts, won?t it be almost the same? If
~1|year/month expands to 1|year + 1|year:month (a random intercept for each year plus for each month in each year)
~1|month/year expands to 1|month +1|month:year (here the random intercept for month will be the same for January 2016 or 2017)?This would mean that each month has an intercept and each year for each month (like the highlighted part?).

At the end I would have

  1.  An intercept for each OR an intercept for each month
  2.  An intercept for each month in each year

Am I right?

Thanks
Udita

From: Guillaume Adeux <guillaumesimon.a2 at gmail.com<mailto:guillaumesimon.a2 at gmail.com>>
Date: Monday, 13 August 2018 at 2:31 PM
To: "Bansal, Udita" <udita.bansal17 at imperial.ac.uk<mailto:udita.bansal17 at imperial.ac.uk>>

Subject: Re: [R-sig-ME] Interpretation of lme output with correlation structure specification

Indeed your original model makes more sense.
~1|year/month expants to 1|year + 1|year:month (a random intercept for each year plus for each month in each year)
whereas
~1|month/year expands to 1|month +1|month:year (here the random intercept for month will be the same for January 2016 or 2017)
Depending on how a variable is coded, it can be crossed or nested but here "month" has the same levels all the different years, so it has to be nested.
Cheers,
GA2

2018-08-13 11:41 GMT+02:00 Bansal, Udita <udita.bansal17 at imperial.ac.uk<mailto:udita.bansal17 at imperial.ac.uk>>:
Also, in continuation of my previous mail, I found that the error is thrown for intervals() if the model is not correct.

My original model included: ~1|year/month (doesn?t give confidence intervals)
The new model: ~1|month/year (gives me the confidence intervals)

Original model: looks at variation when going from one year to another (~1|year intercept), and whether the effect of going from one month to another changes for different years (~1|month %in% year intercept).

New model: looks at variation when going from one month to another (~1|month), and whether the effect of going from one year to another changes for different months (~1| year %in% month).

To me, the original model makes more sense. Am I not interpreting it correctly? I used the Pinheiro and Bates book for this but maybe I am not getting it right.

Anybody has any understanding on this?

Thanks
Udita

From: <mensurationist at gmail.com<mailto:mensurationist at gmail.com>> on behalf of Andrew Robinson <A.Robinson at ms.unimelb.edu.au<mailto:A.Robinson at ms.unimelb.edu.au>>
Date: Monday, 13 August 2018 at 12:04 AM
To: "Bansal, Udita" <udita.bansal17 at imperial.ac.uk<mailto:udita.bansal17 at imperial.ac.uk>>
Cc: "r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>" <r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>>
Subject: Re: [R-sig-ME] Interpretation of lme output with correlation structure specification

Hi Udita,

Q1 Yes.  The correlation is taken into account in the model.

Q2 I am not sure that I know what you mean by that.  I tend to leave the value blank and it then gets estimated in the algorithm.

Cheers,

Andrew


On 12 August 2018 at 19:45, Bansal, Udita <udita.bansal17 at imperial.ac.uk<mailto:udita.bansal17 at imperial.ac.uk><mailto:udita.bansal17 at imperial.ac.uk<mailto:udita.bansal17 at imperial.ac.uk>>> wrote:
Dear Andrew,

Thank you for suggesting the book. I went through the relevant parts of the book which helped me clarify my third question.

But I still am not clear on phi. What I understood is that it is the within group correlation (which is solved by the model?) whose value ranges from -1 to 1. What I didn?t understand is as follows:
Q1: Is any value of phi acceptable since it is the correlation of the within group observations which is taken into account by the model?
Q2: The AR1 parameter estimate (the ?value?) I provide while specifying the model is calculated based on AR model. How does the phi value relate with that? The book did not say much on it.

Any help will be appreciated!

Thanks
Udita Bansal

From: Andrew Robinson <apro at unimelb.edu.au<mailto:apro at unimelb.edu.au><mailto:apro at unimelb.edu.au<mailto:apro at unimelb.edu.au>>>
Date: Saturday, 11 August 2018 at 11:16 PM
To: "r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org><mailto:r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>>" <r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org><mailto:r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>>>, "Bansal, Udita" <udita.bansal17 at imperial.ac.uk<mailto:udita.bansal17 at imperial.ac.uk><mailto:udita.bansal17 at imperial.ac.uk<mailto:udita.bansal17 at imperial.ac.uk>>>
Subject: Re: [R-sig-ME] Interpretation of lme output with correlation structure specification


Hi Udita,

You should read the book cited in the package. It?s really worthwhile.

Best wishes,

Andrew

--
Andrew Robinson
Director, CEBRA, School of BioSciences
Reader & Associate Professor in Applied Statistics Tel: (+61) 0403 138 955
School of Mathematics and Statistics Fax: (+61) 03 8344 4599
University of Melbourne, VIC 3010 Australia
Email: apro at unimelb.edu.au<mailto:apro at unimelb.edu.au><mailto:apro at unimelb.edu.au<mailto:apro at unimelb.edu.au>>
Website: http://cebra.unimelb.edu.au/
On 12 Aug 2018, 7:34 AM +1000, Bansal, Udita <udita.bansal17 at imperial.ac.uk<mailto:udita.bansal17 at imperial.ac.uk><mailto:udita.bansal17 at imperial.ac.uk<mailto:udita.bansal17 at imperial.ac.uk>>>, wrote:

Hi all,

I was modeling the laying date of bird nests against moving averages of weather variables for several years of data. I used Durbin-Watson test and found considerable amount of autocorrelation in the residuals of simple linear and mixed effect models (with month as a random factor). So, I decided to run lme models with correlation structure specified. When I compare the AIC of the models with and without the correlation structure, I find that the models with the correlation structure are better.
Question 1.: How can I interpret the phi (parameter estimate for correlation structure) value in the model output?
Question 2.: Does the interpretation of phi affect the interpretation of the random effect?
Question 3.: How can I interpret the random effect (since this is different from what lmer output shows which I am used to of)?

An example output is as below:

Random effects:
Formula: ~1 | month
(Intercept) Residual
StdDev: 12.53908 5.009051

Correlation Structure: AR(1)
Formula: ~1 | month
Parameter estimate(s):
Phi
0.324984

I could not find much on the interpretation for these online. Any help will be much appreciated.

Thanks
Udita Bansal

[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org><mailto:R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org>> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org><mailto:R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org>> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



--
Andrew Robinson
Director, CEBRA, School of BioSciences
Reader & Associate Professor in Applied Statistics  Tel: (+61) 0403 138 955
School of Mathematics and Statistics                        Fax: (+61) 03 8344 4599
University of Melbourne, VIC 3010 Australia
Email: apro at unimelb.edu.au<mailto:apro at unimelb.edu.au><mailto:apro at unimelb.edu.au<mailto:apro at unimelb.edu.au>>
Website: http://www.ms.unimelb.edu.au/~andrewpr

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



	[[alternative HTML version deleted]]


From oliverhooker @ending from pr@t@ti@tic@@com  Fri Aug 17 19:51:57 2018
From: oliverhooker @ending from pr@t@ti@tic@@com (Oliver Hooker)
Date: Fri, 17 Aug 2018 18:51:57 +0100
Subject: [R-sig-ME] Intro course on Frequentist and Bayesian mixed
 (Hierarchical) models using R (IFBM01)
In-Reply-To: <c85f362bd8d377a81549dec9302ed2e2@prstatistics.com>
References: <c85f362bd8d377a81549dec9302ed2e2@prstatistics.com>
Message-ID: <c25f6a4f4cb947854b24204874d8aa8a@prstatistics.com>

General intro course on Frequentist and Bayesian mixed (Hierarchical) 
models using R (IFBM01)

https://www.prstatistics.com/course/introduction-to-frequentist-and-bayesian-mixed-hierarchical-modelsiifbm01/

Final, few places available.

This course will be delivered by Dr Andrew Parnell from the 8th - 12th 
October 2018 in Glasgow city centre using a varied range of examples 
from life-sciences

Course Overview:
This course will cover introductory mixed or hierarchical modelling 
(fixed and random effects models) for real-world data sets from both a 
Frequentist and Bayesian perspective. These methods lie at the forefront 
of statistics research and are a vital tool in the scientist?s toolbox. 
The course focuses on introducing concepts and demonstrating good 
practice in mixed modelling. All methods are demonstrated with data sets 
which participants can run themselves. Participants will be taught how 
to fit hierarchical models using both the standard lme4 mixed effects 
models library in R, together with the Bayesian modelling framework via 
rstanarm. The course covers the full gamut from simple regression models 
through to full generalised multivariate mixed structures. The relevant 
advantages and disadvantages of both the Frequentist and Bayesian 
approaches will be presented.. Participants are encouraged to bring 
their own data sets for discussion with the course tutors.

Monday 8th ? Classes from 09:30 to 17:30
Basic concepts
Class 1: Introduction; some example datasets; overview of course
Class 2: Revision: probability distributions and likelihood
Class 3: Maximum likelihood and bootstrap uncertainties
Practical: revision on using R to load data, create plots and fit 
statistical models.

Tuesday 9th ? Classes from 09:30 to 17:30
Intro to mixed models
Class 1: Linear and generalised linear models (GLMs)
Class 2: Simple mixed regression models
Class 3: Generalised Linear Mixed Models (GLMMs)
Practical: introduction to lme4

Wednesday 10th ? Classes from 09:00 to 17:00
Bayesian hierarchical models
Class 1: Introduction to Bayesian inference
Class 2: Bayesian computation and Markov chain Monte Carlo
Class 3: Bayesian Hierarchical Models (BHMs)
Practical: Introduction to rstanarm

Thursday 11th ? Classes from 09:00 to 17:00
Extending mixed models
Class 1: Multivariate and multi-layer hierarchical models
Class 2: Shrinkage and variable selection
Class 3: Non-Linear mixed models

Friday 12th ? Classes from 09:30 to 16:00
Advanced topics and bring your own data
Class 1: Extending Bayesian models
Class 2: Using stan (instead of rstanarm) for richer inference
Practical: analyse and get help with your data.

Email oliverhooker at psstatistics.com
Check out our sister sites,
www.PRstatistics.com (Ecology and Life Sciences)
www.PRinformatics.com (Bioinformatics and data science)
www.PSstatsistics.com (Behaviour and cognition)


1.	October 1st ? 5th
TIME SERIES MODELS FOR ECOLOGISTS (TSME02)
Glasgow, Dr Andrew Parnell
https://www.prstatistics.com/course/time-series-models-foe-ecologists-tsme02/

2.	October 1st ? 5th 2018
INTRODUCTION TO LINUX WORKFLOWS FOR BIOLOGISTS (IBUL03)
Glasgow, Scotland, Dr. Martin Jones
https://www.prinformatics.com/course/introduction-to-linux-workflows-for-biologists-ibul03/

3.	October 8th ? 12th 2018
INTRODUCTION TO FREQUENTIST AND BAYESIAN MIXED (HIERARCHICAL) MODELS 
(IFBM01)
Glasgow, Scotland, Dr Andrew Parnell
https://www.psstatistics.com/course/introduction-to-frequentis-and-bayesian-mixed-models-ifbm01/

4.	October 15th ? 19th 2018
APPLIED BAYESIAN MODELLING FOR ECOLOGISTS AND EPIDEMIOLOGISTS (ABME04)
Glasgow, Scotland, Dr. Matt Denwood, Emma Howard
http://www.prstatistics.com/course/applied-bayesian-modelling-ecologists-epidemiologists-abme04/

5.	October 23rd ? 25th 2018
INTRODUCTIUON TO R (This is a private ?in-house? course)
London, England, Dr William Hoppitt

6.	October 29th ? November 2nd 2018
INTRODCUTION TO R AND STATISTICS FOR BIOLOGISTS (IRFB02)
Glasgow, Scotland, Dr. Olivier Gauthier
https://www.prstatistics.com/course/introduction-to-statistics-and-r-for-biologists-irfb02/

7.	October 29th ? November 2nd 2018
INTRODUCTION TO BIOINFORMATICS FOR DNA AND RNA SEQUENCE ANALYSIS 
(IBDR01)
Glasgow, Scotland, Dr Malachi Griffith, Dr. Obi Griffith
www.prinformatics.com/course/precision-medicine-bioinformatics-from-raw-genome-and-transcriptome-data-to-clinical-interpretation-pmbi01/

8.	November 5th ? 8th  2018
PHYLOGENETIC COMPARATIVE METHODS FOR STUDYING DIVERSIFICATION AND 
PHENOTYPIC EVOLUTION (PCME01)
Glasgow, Scotland, Dr. Antigoni Kaliontzopoulou
https://www.prstatistics.com/course/phylogenetic-comparative-methods-for-studying-diversification-and-phenotypic-evolution-pcme01/

9.	November 19th ? 23rd  2018
STRUCTUAL EQUATION MODELLING FOR ECOLOGISTS AND EVOLUTIONARY BIOLOGISTS 
(SEMR02)
Glasgow, Scotland, Dr. Jonathan Lefcheck
https://www.prstatistics.com/course/structural-equation-modelling-for-ecologists-and-evolutionary-biologists-semr02/

10.	November 26th ? 30th 2018
FUNCTIONAL ECOLOGY FROM ORGANISM TO ECOSYSTEM: THEORY AND COMPUTATION 
(FEER01)
Glasgow, Scotland, Dr. Francesco de Bello, Dr. Lars G?tzenberger, Dr. 
Carlos Carmona
http://www.prstatistics.com/course/functional-ecology-from-organism-to-ecosystem-theory-and-computation-feer01/

11.	December 3rd ? 7th 2018
INTRODUCTION TO BAYESIAN DATA ANALYSIS FOR SOCIAL AND BEHAVIOURAL 
SCIENCES USING R AND STAN (BDRS01)
Glasgow, Dr. Mark Andrews
https://www.psstatistics.com/course/introduction-to-bayesian-data-analysis-for-social-and-behavioural-sciences-using-r-and-stan-bdrs01/

12.	January 21st ? 25th 2019
STATISTICAL MODELLING OF TIME-TO-EVENT DATA USING SURVIVAL ANALYSIS: AN 
INTRODUCTION FOR ANIMAL BEHAVIOURISTS, ECOLOGISTS AND EVOLUTIONARY 
BIOLOGISTS (TTED01)
Glasgow, Scotland, Dr. Will Hoppitt
https://www.psstatistics.com/course/statistical-modelling-of-time-to-event-data-using-survival-analysis-tted01/

13.	January 21st ? 25th 2019
ADVANCING IN STATISTICAL MODELLING USING R (ADVR08)
Glasgow, Scotland, Dr. Luc Bussiere, Dr. Tom Houslay
http://www.prstatistics.com/course/advancing-statistical-modelling-using-r-advr08/

14.	January 28th?  February 1st 2019
AQUATIC ACOUSTIC TELEMETRY DATA ANALYSIS AND SURVEY DESIGN
Glasgow, Scotland, VEMCO staff and affiliates
https://www.prstatistics.com/course/aquatic-acoustic-telemetry-data-analysis-atda01/

15.	4th ? 8th February 2019
DESIGNING RELIABLE AND EFFICIENT EXPERIMENTS FOR SOCIAL SCIENCES 
(DRES01)
Glasgow, Scotland, Dr. Daniel Lakens
https://www.psstatistics.com/course/designing-reliable-and-effecient-experiments-for-social-sciences-dres01/

16.	February 11th ? 15th 2019
REPRODUCIBLE DATA SCIEDNCE FOR POPULATION GENETICS
Glasgow, Scotland, Dr. Thibaut Jombart, Dr. Zhain Kamvar
https://www.prstatistics.com/course/reproducible-data-science-for-population-genetics-rdpg02/

17.	25th February ? 1st March 2019
MOVEMENT ECOLOGY (MOVE02)
Margam Discovery Centre, Wales, Dr. Luca Borger, Prof. Ronny Wilson, Dr 
Jonathan Potts
https://www.prstatistics.com/course/movement-ecology-move02/

18.	March 4th ? 8th 2019
BIOACUSTIC DATA ANALYSIS
Glasgow, Scotland, Dr. Paul Howden-Leach
https://www.prstatistics.com/course/bioacoustics-for-ecologists-hardware-survey-design-and-data-analysis-biac01/

19.	March 11th ? 15th  2019
ECOLOGICAL NICHE MODELLING USING R (ENMR03)
Glasgow, Scotland, Dr. Neftali Sillero
http://www.prstatistics.com/course/ecological-niche-modelling-using-r-enmr03/

20.	MARCH 18TH ? 22ND 2019
INRODUCTION TO R FOR BIOMEDICAL SCIENCES (IRBM01)
Crete, Greece, Dr Aristides (Aris) Moustakas
Link to follow soon

21.	March 25th ? 29th 2019
LANDSCAPE GENETIC/GENOMIC DATA ANALYSIS USING R (LNDG03)
Glasgow, Scotland, Prof. Rodney Dyer
http://www.prstatistics.com/course/landscape-genetic-data-analysis-using-r-lndg03/

22.	A pril 1st ? 5th 2019
INTRODUCTION TO STATISTICAL MODELLING FOR PSYCHOLOGISTS USING R (IPSY01)
Glasgow, Scotland, Dr. Dale Barr, Dr Luc Bussierre
http://www.psstatistics.com/course/introduction-to-statistics-using-r-for-psychologists-ipsy02/

23.	April 8th ? 12th
MACHINE LEARNING
Glasgow Scotland, Dr Aristides (Aris) Moustakas
https://www.prstatistics.com/course/machine-learning-using-r-mlur01/


-- 
Oliver Hooker PhD.
PR statistics

2018 publications -

Alternative routes to piscivory: Contrasting growth trajectories in 
brown trout (Salmo trutta) ecotypes exhibiting contrasting life history 
strategies. Ecology of Freshwater Fish. DOI to follow

Phenotypic and resource use partitioning amongst sympatric lacustrine 
brown trout, Salmo trutta. Biological Journal of the Linnean Society. 
DOI 10.1093/biolinnean/bly032

prstatistics.com
facebook.com/prstatistics/
twitter.com/PRstatistics
groups.google.com/d/forum/pr-statistics-post-course-forum
prstatistics.com/organiser/oliver-hooker/

6 Hope Park Crescent
Edinburgh
EH8 9NA

+44 (0) 7966500340


From @lte@@ed@c2 @ending from gm@il@com  Sun Aug 19 16:45:53 2018
From: @lte@@ed@c2 @ending from gm@il@com (C. AMAL D. GLELE)
Date: Sun, 19 Aug 2018 16:45:53 +0200
Subject: [R-sig-ME] Error in reS$ziReStruc[[i]]
In-Reply-To: <F8311843-E832-4082-B5DB-B9252189A4E5@gmail.com>
References: <CANrzCv1uuYeVW5NL2nn6S6+7BZDZBxg7=x6JKeSBFpPiVNbb=w@mail.gmail.com>
 <F8311843-E832-4082-B5DB-B9252189A4E5@gmail.com>
Message-ID: <CANrzCv1XSzjrcRD5tK__zPLVBn=MFZawkCe-45d6dn2RxOqukw@mail.gmail.com>

Hi, dear Mollie.
When installing from Github  "
devtools::install_github("glmmTMB/glmmTMB/glmmTMB")";
I've encountered several errors that I corrected; but I do not have a
solution for the last
one (pasted below) yet:
"Installation failed: Cannot change working directory"
In advance thanks.
All the best.
Amal

2018-08-13 20:34 GMT+02:00 Mollie Brooks <mollieebrooks at gmail.com>:

> I think this bug was fixed in the development version (
> https://github.com/glmmTMB/glmmTMB/issues/370). It might still be in the
> CRAN version.
>
> Install from Github and it should work. https://github.com/glmmTMB/glmmTMB
>
> Cheers,
> Mollie
>
> On 13Aug 2018, at 15:11, C. AMAL D. GLELE <altessedac2 at gmail.com> wrote:
>
> Hi, dear all.
> I've built a glmm (model) with glmmTMB; it had fitted without,  neither
> error message, nor warnings;
> but, since I've added the following ziformula=~village (village is a 6
> levels grouping factor variable), I got the warning message
> "Model convergence problem; non-positive-definite Hessian matrix"
> Trying to resolve this, I've used ziformula=~(1|village) instead;
> then, the model fits without neither error message, nor warnings; but when
> I'd ran "summary(model)", I got the following error message "Error in
> reS$ziReStruc[[i]] : subscript out of bounds": it's my first time to get
> such an error message and I don't know any idea about its possible cause;
> so, any help to solve it will be much appreciated.
> In advance, thanks.
> Kind regards,
>
> [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>

	[[alternative HTML version deleted]]


From bbolker @ending from gm@il@com  Sun Aug 19 17:52:54 2018
From: bbolker @ending from gm@il@com (Ben Bolker)
Date: Sun, 19 Aug 2018 11:52:54 -0400
Subject: [R-sig-ME] Error in reS$ziReStruc[[i]]
In-Reply-To: <CANrzCv1XSzjrcRD5tK__zPLVBn=MFZawkCe-45d6dn2RxOqukw@mail.gmail.com>
References: <CANrzCv1uuYeVW5NL2nn6S6+7BZDZBxg7=x6JKeSBFpPiVNbb=w@mail.gmail.com>
 <F8311843-E832-4082-B5DB-B9252189A4E5@gmail.com>
 <CANrzCv1XSzjrcRD5tK__zPLVBn=MFZawkCe-45d6dn2RxOqukw@mail.gmail.com>
Message-ID: <0f9b3c1c-0fc5-fc2f-b823-7f66948d8046@gmail.com>


  This seems like a permissions problem.  As

 https://github.com/satijalab/seurat/issues/94

says, try running as administrator? (i.e., run R as administrator, then
run install_github(...) within that session

On 2018-08-19 10:45 AM, C. AMAL D. GLELE wrote:
> Hi, dear Mollie.
> When installing from Github  "
> devtools::install_github("glmmTMB/glmmTMB/glmmTMB")";
> I've encountered several errors that I corrected; but I do not have a
> solution for the last
> one (pasted below) yet:
> "Installation failed: Cannot change working directory"
> In advance thanks.
> All the best.
> Amal
> 
> 2018-08-13 20:34 GMT+02:00 Mollie Brooks <mollieebrooks at gmail.com>:
> 
>> I think this bug was fixed in the development version (
>> https://github.com/glmmTMB/glmmTMB/issues/370). It might still be in the
>> CRAN version.
>>
>> Install from Github and it should work. https://github.com/glmmTMB/glmmTMB
>>
>> Cheers,
>> Mollie
>>
>> On 13Aug 2018, at 15:11, C. AMAL D. GLELE <altessedac2 at gmail.com> wrote:
>>
>> Hi, dear all.
>> I've built a glmm (model) with glmmTMB; it had fitted without,  neither
>> error message, nor warnings;
>> but, since I've added the following ziformula=~village (village is a 6
>> levels grouping factor variable), I got the warning message
>> "Model convergence problem; non-positive-definite Hessian matrix"
>> Trying to resolve this, I've used ziformula=~(1|village) instead;
>> then, the model fits without neither error message, nor warnings; but when
>> I'd ran "summary(model)", I got the following error message "Error in
>> reS$ziReStruc[[i]] : subscript out of bounds": it's my first time to get
>> such an error message and I don't know any idea about its possible cause;
>> so, any help to solve it will be much appreciated.
>> In advance, thanks.
>> Kind regards,
>>
>> [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>>
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From d@rizopoulo@ @ending from er@@mu@mc@nl  Sun Aug 19 18:48:05 2018
From: d@rizopoulo@ @ending from er@@mu@mc@nl (D. Rizopoulos)
Date: Sun, 19 Aug 2018 16:48:05 +0000
Subject: [R-sig-ME] Error in reS$ziReStruc[[i]]
In-Reply-To: <CANrzCv1XSzjrcRD5tK__zPLVBn=MFZawkCe-45d6dn2RxOqukw@mail.gmail.com>
References: <CANrzCv1uuYeVW5NL2nn6S6+7BZDZBxg7=x6JKeSBFpPiVNbb=w@mail.gmail.com>
 <F8311843-E832-4082-B5DB-B9252189A4E5@gmail.com>,
 <CANrzCv1XSzjrcRD5tK__zPLVBn=MFZawkCe-45d6dn2RxOqukw@mail.gmail.com>
Message-ID: <7191AFC7255B4F49A30707E39BEAD05FDEB483E9@EXCH-HE03.erasmusmc.nl>

In case you have a single grouping factor for the random effects, you can also try package GLMMadaptive that uses adaptive Gaussian quadrature: https://drizopoulos.github.io/GLMMadaptive/

More info for zero-inflated models at: https://drizopoulos.github.io/GLMMadaptive/articles/ZeroInflated_and_TwoPart_Models.html

Best,
Dimitris

From: C. AMAL D. GLELE <altessedac2 at gmail.com<mailto:altessedac2 at gmail.com>>
Date: Sunday, 19 Aug 2018, 4:46 PM
To: Mollie Brooks <mollieebrooks at gmail.com<mailto:mollieebrooks at gmail.com>>
Cc: R SIG Mixed Models <r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>>
Subject: Re: [R-sig-ME] Error in reS$ziReStruc[[i]]

Hi, dear Mollie.
When installing from Github  "
devtools::install_github("glmmTMB/glmmTMB/glmmTMB")";
I've encountered several errors that I corrected; but I do not have a
solution for the last
one (pasted below) yet:
"Installation failed: Cannot change working directory"
In advance thanks.
All the best.
Amal

2018-08-13 20:34 GMT+02:00 Mollie Brooks <mollieebrooks at gmail.com>:

> I think this bug was fixed in the development version (
> https://github.com/glmmTMB/glmmTMB/issues/370). It might still be in the
> CRAN version.
>
> Install from Github and it should work. https://github.com/glmmTMB/glmmTMB
>
> Cheers,
> Mollie
>
> On 13Aug 2018, at 15:11, C. AMAL D. GLELE <altessedac2 at gmail.com> wrote:
>
> Hi, dear all.
> I've built a glmm (model) with glmmTMB; it had fitted without,  neither
> error message, nor warnings;
> but, since I've added the following ziformula=~village (village is a 6
> levels grouping factor variable), I got the warning message
> "Model convergence problem; non-positive-definite Hessian matrix"
> Trying to resolve this, I've used ziformula=~(1|village) instead;
> then, the model fits without neither error message, nor warnings; but when
> I'd ran "summary(model)", I got the following error message "Error in
> reS$ziReStruc[[i]] : subscript out of bounds": it's my first time to get
> such an error message and I don't know any idea about its possible cause;
> so, any help to solve it will be much appreciated.
> In advance, thanks.
> Kind regards,
>
> [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From high@t@t @ending from high@t@t@com  Tue Aug 21 13:40:44 2018
From: high@t@t @ending from high@t@t@com (Highland Statistics Ltd)
Date: Tue, 21 Aug 2018 09:10:44 -0230
Subject: [R-sig-ME] Mixed modelling courses in Denmark and Holland
Message-ID: <d78a3b16-25f7-bff1-4e70-3432a68566bb@highstat.com>

Apologies for cross-posting

We would like to announce the following two statistics course.


Course: Linear Mixed Effects Models and GLMM with R. Frequentist and 
Bayesian approaches
Where:? NIOZ, Texel, The Netherlands.
When:?? 1-5 October 2018
Course website: http://highstat.com/index.php/courses-upcoming
Course flyer: 
http://highstat.com/Courses/Flyers/2018/Flyer2018_10NIOZ_GLMM.pdf


Course: Linear Mixed Effects Models and GLMM with R. Frequentist and 
Bayesian approaches
Where:? National Institute of Aquatic Resources - DTU Aqua, Lyngby, 
Denmark.
When:?? 22-26 October 2018
Course website: http://highstat.com/index.php/courses-upcoming
Course flyer: 
http://highstat.com/Courses/Flyers/2018/Flyer2018_10DTU_GLMM.pdf




Kind regards, Alain Zuur

-- 

Dr. Alain F. Zuur
Highland Statistics Ltd.
9 St Clair Wynd
AB41 6DZ Newburgh, UK
Email: highstat at highstat.com
URL:   www.highstat.com

And:
NIOZ Royal Netherlands Institute for Sea Research,
Department of Coastal Systems, and Utrecht University,
P.O. Box 59, 1790 AB Den Burg,
Texel, The Netherlands



Author of:
1. Beginner's Guide to Spatial, Temporal and Spatial-Temporal Ecological Data Analysis with R-INLA. (2017).
2. Beginner's Guide to Zero-Inflated Models with R (2016).
3. Beginner's Guide to Data Exploration and Visualisation with R (2015).
4. Beginner's Guide to GAMM with R (2014).
5. Beginner's Guide to GLM and GLMM with R (2013).
6. Beginner's Guide to GAM with R (2012).
7. Zero Inflated Models and GLMM with R (2012).
8. A Beginner's Guide to R (2009).
9. Mixed effects models and extensions in ecology with R (2009).
10. Analysing Ecological Data (2007).


From c@c@voeten @ending from hum@leidenuniv@nl  Tue Aug 21 19:41:04 2018
From: c@c@voeten @ending from hum@leidenuniv@nl (Voeten, C.C.)
Date: Tue, 21 Aug 2018 17:41:04 +0000
Subject: [R-sig-ME] Efficient forward stepwise regression possible for
 mixed-effects models?
Message-ID: <D14049CE02C4F54D95360EEC06CE45C50F9094EC@SPMXM08.VUW.leidenuniv.nl>

When doing forward stepwise regression, a computationally efficient way to choose the next term to add to the model out of a set of candidate predictors, is to calculate the correlation of each of these predictors with the residuals of the current working model. E.g., if my current model is lm(y ~ something,data=data), and I need to choose which of a set of predictors {b1, b2, b3} to add next, the largest result of sapply(data[,c('b1','b2','b3')],cor,resid(current_model)) is the predictor I should pick.

How does this extend to the random effects of mixed-effects models?

I can foresee two issues. The first is that a random effect cannot be represented by a single column vector out of a data set, so we can't use cor(). However, it should be possible to instead regress the residuals on each of the candidate random effects, and select the effect that gives the largest log-likelihood.
A second issue I could think of is that the parameters will be optimized differently. The theta parameters will be optimized sequentially instead of jointly: every future predictor added to the model will be evaluated with the theta parameters from the preceding random effects treated as fixed. I am unsure what impact this will have -- is this known (or perhaps even obvious)?

My use case is that I often find that I have to fit large models with multiple crossed random slopes, and I know that the full model will never converge. I want to be sure that the random effects which I do include are the best possible ones I could have chosen. What I do now is start out with all fixed effects, and try all my random effects one at a time (respecting marginality), and so on, until I have identified the maximal model that will still converge. This works well, but is computationally very, very wasteful. I was wondering if this more efficient approach used in simple linear models (using the correlation of the candidate predictors with the current model's residuals) could in any way be applied to mixed models as well, and at what cost...

Thanks,
Cesko

From bl@zej@mrozin@ki @ending from gm@il@com  Wed Aug 22 13:27:56 2018
From: bl@zej@mrozin@ki @ending from gm@il@com (Blazej Mrozinski)
Date: Wed, 22 Aug 2018 13:27:56 +0200
Subject: [R-sig-ME] Simulatig data for mixed-effects model with predefined
 parameter
Message-ID: <CANAWZx_c=7sA1frSQrMNTJUUfT=crYToyBeYHwdLB-azNhxaFw@mail.gmail.com>

Good morning group,
yesterday I posted a question on simulating mixed-effects data set at
StackOverflow
https://stackoverflow.com/questions/51937986/simulate-data-for-mixed-effects-model-with-predefined-parameter
and Ben Bolker was kind enough to give me a solution, that for some reason
is not working.

If you don't mind I would like to keep this post here as well, as there are
some unsolved issues and questions that are not suitable for SO commenting
system.

To sum up:
I'm trying to simulate data sets following some strict parameters.

For a simple example, for a given nSubjects and nObs I'd like to get a
two-level repeated-measure data, where a continuous level-2 predictor
predicts a continuous level-1 outcome, eg. happiness ~ self-esteem + (1 |
subject), where self-esteem is measured across subjects, and happiness
across occasions (e.g. days) within each subject. The catch here is, I'd
like to define in advance the random variance ratio - for example: given an
unconditional model happiness ~ 1 + (1|subject) the ratio of between
subject variance to within subjcet variance is 50 / 50 (or any other of my
choice).

If the above is possible I would like to know how to extend the simplest
model to one that includes predictors at both levels of measurement (e.g.
self-esteem at subject level, daily stress at observation level) with a
possibility to control variance ratios beforehand.

I would really appreciate some help here.

Ben's solution (https://stackoverflow.com/a/51940024/6925293) looks very
elegant but it doesnt work on my end ( Error in setParams(object,
newparams) : length mismatch in beta (2!=3) ) and I'm not entirely sure how
I can control parameters.

Please note that I'm comfortable with greek equations as long as they don't
go two far (e.g I know whats going on here: https://i.imgur.com/A37oAok.png
)

Best regards,
Blazej Mrozinski
PhD candidate at University of Social Sciences and Humanities in Warsaw,
Poland.

	[[alternative HTML version deleted]]


From mleu@90 @ending from gm@il@com  Wed Aug 22 07:08:07 2018
From: mleu@90 @ending from gm@il@com (Bob H)
Date: Tue, 21 Aug 2018 22:08:07 -0700
Subject: [R-sig-ME] Confidence Intervals for fitted group lines in nlme model
Message-ID: <CAG4XGmE=Lt4VeP9Uqe_xH-H8vFmBoxkVyjX9BowjXLsCemUU0g@mail.gmail.com>

Hi,

I have a npnlinear model y = a*x^b with grouped data (2 groups) and I'd
like to plot the confidence intervals around the fitted lines for each
group. Below you see the fitted lines in the plot.

Can you advise how to do this?

Searching online, there is an answer here:
https://stats.stackexchange.com/questions/231074/confidence-intervals-on-predictions-for-a-non-linear-mixed-model-nlme

that shows how to plot the POPULATION level  (not group-level) confidence
interval in 3 ways (population prediction intervals, bootstrap and delta
method) where there are 14 groups and the overall population fit and
confidence interval is plotted. That is  different than plotting the 14
group confidence intervals around the 14 predicted fits which is what I am
looking to do.

To plot the group-level confidence intervals, for groups A and B in the
example below, how are the random effects, random.effects(m), incorporated
into the confidence interval?

Here is the code:
library(nlme)
library(ggplot2)
set.seed(1)
x = 1:50
y = x^2+rnorm(50,50,50)
x2 = 1:50
y2 = x2^2.2+rnorm(50,50,500)
dat1 = data.frame(x =c(x,x2), y=c(y,y2), group =
c(rep("A",50),rep("B",50))  )

f1<-formula( y ~ a*x^b | group)
#d = groupedData( f1,   data = as.data.frame( dat1 ) )
#### using nlme
m <- nlsList(f1,data=dat1,start=list(a=1,b=1))
m
random.effects(m)
dat1$fitted = predict(m)

#####plot the predicted lines for each group
ggplot(dat1,aes(x= x, y = y,color = group))+geom_point()+
  geom_line(data=dat1, aes(x=x,y=fitted,color=group),inherit.aes=FALSE)

sum(predict(m,level=0)==predict(m,level=1))

Thank you.

library(nlme)

library(brms)

library(ggplot2)

set.seed(1)

x = 1:50

y = x^2+rnorm(50,0,50)

x2 = 1:50

y2 = x2^2.2+rnorm(50,50,500)

dat1 = data.frame(x =c(x,x2), y=c(y,y2), group =
c(rep("A",50),rep("B",50))  )

ggplot(dat1,aes(x= x, y = y,color = group))+geom_point()


f1<-formula( y ~ a*x^b | group)

#d = groupedData( f1,   data = as.data.frame( dat1 ) )


#### using nlme

m <- nlsList(f1,data=d,start=list(a=1,b=1))

m


library(nlme)

library(brms)

library(ggplot2)

set.seed(1)

x = 1:50

y = x^2+rnorm(50,0,50)

x2 = 1:50

y2 = x2^2.2+rnorm(50,50,500)

dat1 = data.frame(x =c(x,x2), y=c(y,y2), group =
c(rep("A",50),rep("B",50))  )

ggplot(dat1,aes(x= x, y = y,color = group))+geom_point()


f1<-formula( y ~ a*x^b | group)

#d = groupedData( f1,   data = as.data.frame( dat1 ) )


#### using nlme

m <- nlsList(f1,data=d,start=list(a=1,b=1))

m

	[[alternative HTML version deleted]]


From y@@hree19 @ending from gm@il@com  Thu Aug 23 17:09:24 2018
From: y@@hree19 @ending from gm@il@com (Yashree Mehta)
Date: Thu, 23 Aug 2018 17:09:24 +0200
Subject: [R-sig-ME] Fixed vs random effects with lme4
Message-ID: <CAOE=hqJBPwPdCm0qJHFRFNum4azi+k5uRKpL2pKUfXmn5CLcCQ@mail.gmail.com>

Hello,

Is there a way to conduct the Hausman test on models which have been
estimated using lme4?

To be more specific,

My model assumption is that the plot size(X covariate) is correlated with
the random intercept ( estimated from Household_ID) which will be
estimated. So I have to find out how to tell lmer to consider this
correlation. I would also, similarly, want to carry random effects where
this correlation assumption is done away with. Finally, I want to conduct
the Hausman test for model choice.

Thank you,

Regards,
Yashree

	[[alternative HTML version deleted]]


From jdpo223 @ending from g@uky@edu  Thu Aug 23 17:43:17 2018
From: jdpo223 @ending from g@uky@edu (John Poe)
Date: Thu, 23 Aug 2018 11:43:17 -0400
Subject: [R-sig-ME] Fixed vs random effects with lme4
In-Reply-To: <CAOE=hqJBPwPdCm0qJHFRFNum4azi+k5uRKpL2pKUfXmn5CLcCQ@mail.gmail.com>
References: <CAOE=hqJBPwPdCm0qJHFRFNum4azi+k5uRKpL2pKUfXmn5CLcCQ@mail.gmail.com>
Message-ID: <CAFW8BypY2SXq=DSekihNrKgXh_g8qRsW4AEMJ2f6h9Of9=WCvQ@mail.gmail.com>

Yep,

Peter Westfall wrote up how to do it in an example script
http://westfall.ba.ttu.edu/ISQS5349/Hausman_test_inR.txt

Please be aware that the test does not imply that you shouldn't use random
effects if there is correlation between a group-varying intercept and a
lower level variable. It just means that you need to do something to
properly model that correlation. That could be a within-group only model
with dummy variables for groups (standard Fixed Effects models) or a
group-mean centered model a la much of multilevel modeling. In econ this is
known as a Hausman Taylor model (yes, the same Hausman as the test) or a
correlated random effects model. You could also use a random slopes model
to allow the variability in Xi across groups but it's less effective at
debiasing than the other choices.

On Thu, Aug 23, 2018 at 11:09 AM Yashree Mehta <yashree19 at gmail.com> wrote:

> Hello,
>
> Is there a way to conduct the Hausman test on models which have been
> estimated using lme4?
>
> To be more specific,
>
> My model assumption is that the plot size(X covariate) is correlated with
> the random intercept ( estimated from Household_ID) which will be
> estimated. So I have to find out how to tell lmer to consider this
> correlation. I would also, similarly, want to carry random effects where
> this correlation assumption is done away with. Finally, I want to conduct
> the Hausman test for model choice.
>
> Thank you,
>
> Regards,
> Yashree
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


-- 




Thanks,
John


John Poe, Ph.D.
Postdoctoral Scholar / Research Methodologist
Center for Public Health Services & Systems Research
University of Kentucky
www.johndavidpoe.com

	[[alternative HTML version deleted]]


From y@@hree19 @ending from gm@il@com  Thu Aug 23 19:05:43 2018
From: y@@hree19 @ending from gm@il@com (Yashree Mehta)
Date: Thu, 23 Aug 2018 19:05:43 +0200
Subject: [R-sig-ME] Fixed vs random effects with lme4
In-Reply-To: <CAFW8BypY2SXq=DSekihNrKgXh_g8qRsW4AEMJ2f6h9Of9=WCvQ@mail.gmail.com>
References: <CAOE=hqJBPwPdCm0qJHFRFNum4azi+k5uRKpL2pKUfXmn5CLcCQ@mail.gmail.com>
 <CAFW8BypY2SXq=DSekihNrKgXh_g8qRsW4AEMJ2f6h9Of9=WCvQ@mail.gmail.com>
Message-ID: <CAOE=hqKtkxyDiDVzFdze8YrUM3RToYqbcJMES2xbsONkmrmJng@mail.gmail.com>

Thank you very much for your reply.

I see that the function "lm" is used for fixed effects and lmer for random
effects. I want to use lmer and specify a random intercept for the fixed
effects model. (In the terminology of efficiency analysis, it can be called
" fixed effects-random intercept" model.
To be more specific,

 A random intercept based on the Household_id is to be included for both
models:
1) Where it is assumed that the random intercept is correlated with
X-covariates (Fixed effects)
2)Where this not assumed. i.e. a correlation of 0. (Random effects)

Having estimated the two models, I want to conduct the Hausman test.

Thanks again,

Regards,
Yashree



On Thu, Aug 23, 2018 at 5:43 PM John Poe <jdpo223 at g.uky.edu> wrote:

> Yep,
>
> Peter Westfall wrote up how to do it in an example script
> http://westfall.ba.ttu.edu/ISQS5349/Hausman_test_inR.txt
>
> Please be aware that the test does not imply that you shouldn't use random
> effects if there is correlation between a group-varying intercept and a
> lower level variable. It just means that you need to do something to
> properly model that correlation. That could be a within-group only model
> with dummy variables for groups (standard Fixed Effects models) or a
> group-mean centered model a la much of multilevel modeling. In econ this is
> known as a Hausman Taylor model (yes, the same Hausman as the test) or a
> correlated random effects model. You could also use a random slopes model
> to allow the variability in Xi across groups but it's less effective at
> debiasing than the other choices.
>
> On Thu, Aug 23, 2018 at 11:09 AM Yashree Mehta <yashree19 at gmail.com>
> wrote:
>
>> Hello,
>>
>> Is there a way to conduct the Hausman test on models which have been
>> estimated using lme4?
>>
>> To be more specific,
>>
>> My model assumption is that the plot size(X covariate) is correlated with
>> the random intercept ( estimated from Household_ID) which will be
>> estimated. So I have to find out how to tell lmer to consider this
>> correlation. I would also, similarly, want to carry random effects where
>> this correlation assumption is done away with. Finally, I want to conduct
>> the Hausman test for model choice.
>>
>> Thank you,
>>
>> Regards,
>> Yashree
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>
> --
>
>
>
>
> Thanks,
> John
>
>
> John Poe, Ph.D.
> Postdoctoral Scholar / Research Methodologist
> Center for Public Health Services & Systems Research
> University of Kentucky
> www.johndavidpoe.com
>

	[[alternative HTML version deleted]]


From jdpo223 @ending from g@uky@edu  Thu Aug 23 19:42:44 2018
From: jdpo223 @ending from g@uky@edu (John Poe)
Date: Thu, 23 Aug 2018 13:42:44 -0400
Subject: [R-sig-ME] Fixed vs random effects with lme4
In-Reply-To: <CAOE=hqKtkxyDiDVzFdze8YrUM3RToYqbcJMES2xbsONkmrmJng@mail.gmail.com>
References: <CAOE=hqJBPwPdCm0qJHFRFNum4azi+k5uRKpL2pKUfXmn5CLcCQ@mail.gmail.com>
 <CAFW8BypY2SXq=DSekihNrKgXh_g8qRsW4AEMJ2f6h9Of9=WCvQ@mail.gmail.com>
 <CAOE=hqKtkxyDiDVzFdze8YrUM3RToYqbcJMES2xbsONkmrmJng@mail.gmail.com>
Message-ID: <CAFW8BypiqCAy9TUiRegD00FeCM=9Y57LqELQ3VPh3mPD3nwL7Q@mail.gmail.com>

I'm getting a bit confused by your language.

A fixed effects model can either refer to a model with one intercept making
no allowance for group variability (so all the effects are assumed fixed
for the population) or a model where all between group variance is removed
from the main variables via dummy variables, the within transform, first
differencing or some other method and thus the betas represent the portion
of the effect common to the population and thus fixed.

If you want to do a hausman test you are comparing beta in a model with a
group varying intercept random effect and beta in a model where between
group effects are segregated via the above techniques. You do not include a
random effect in both models.

The hausman test is completely useless as a model specification tool if
you're going to use both a group mean centered (within transform) to get
the equivalent of a within group effects beta along with a group varying
intercept (random effect).

On Aug 23, 2018 1:05 PM, "Yashree Mehta" <yashree19 at gmail.com> wrote:

Thank you very much for your reply.

I see that the function "lm" is used for fixed effects and lmer for random
effects. I want to use lmer and specify a random intercept for the fixed
effects model. (In the terminology of efficiency analysis, it can be called
" fixed effects-random intercept" model.
To be more specific,

 A random intercept based on the Household_id is to be included for both
models:
1) Where it is assumed that the random intercept is correlated with
X-covariates (Fixed effects)
2)Where this not assumed. i.e. a correlation of 0. (Random effects)

Having estimated the two models, I want to conduct the Hausman test.

Thanks again,

Regards,
Yashree



On Thu, Aug 23, 2018 at 5:43 PM John Poe <jdpo223 at g.uky.edu> wrote:

> Yep,
>
> Peter Westfall wrote up how to do it in an example script
> http://westfall.ba.ttu.edu/ISQS5349/Hausman_test_inR.txt
>
> Please be aware that the test does not imply that you shouldn't use random
> effects if there is correlation between a group-varying intercept and a
> lower level variable. It just means that you need to do something to
> properly model that correlation. That could be a within-group only model
> with dummy variables for groups (standard Fixed Effects models) or a
> group-mean centered model a la much of multilevel modeling. In econ this is
> known as a Hausman Taylor model (yes, the same Hausman as the test) or a
> correlated random effects model. You could also use a random slopes model
> to allow the variability in Xi across groups but it's less effective at
> debiasing than the other choices.
>
> On Thu, Aug 23, 2018 at 11:09 AM Yashree Mehta <yashree19 at gmail.com>
> wrote:
>
>> Hello,
>>
>> Is there a way to conduct the Hausman test on models which have been
>> estimated using lme4?
>>
>> To be more specific,
>>
>> My model assumption is that the plot size(X covariate) is correlated with
>> the random intercept ( estimated from Household_ID) which will be
>> estimated. So I have to find out how to tell lmer to consider this
>> correlation. I would also, similarly, want to carry random effects where
>> this correlation assumption is done away with. Finally, I want to conduct
>> the Hausman test for model choice.
>>
>> Thank you,
>>
>> Regards,
>> Yashree
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>
> --
>
>
>
>
> Thanks,
> John
>
>
> John Poe, Ph.D.
> Postdoctoral Scholar / Research Methodologist
> Center for Public Health Services & Systems Research
> University of Kentucky
> www.johndavidpoe.com
>

	[[alternative HTML version deleted]]


From @d@mmill@c@mpi@i @ending from gm@il@com  Thu Aug 23 21:18:11 2018
From: @d@mmill@c@mpi@i @ending from gm@il@com (Adam Mills-Campisi)
Date: Thu, 23 Aug 2018 15:18:11 -0400
Subject: [R-sig-ME] How to use all the cores while running glmer on a
 piecewise exponential survival with
Message-ID: <CAAoDtR98dC5fXDrYrhMmYwKsXqhT=_7H0NeO=cViQ6S+2nxC4g@mail.gmail.com>

I am estimating a piecewise exponential, mixed-effects, survival model with
recurrent events. Each individual in the dataset gets an individual
interpret (where using a PWP approach). Our full dataset has 10 million
individuals, with 180 million events. I am not sure that there is any
framework which can accommodate data at that size, so we are going to
sample. Our final sample size largely depends on how quickly we can
estimate the model, which brings me to my question: Is there a way to
mutli-thread/core the model? I tried to find some kind of instruction on
the web and the best lead I could find was a reference to this list serve.
Any help would be greatly appreciated.

	[[alternative HTML version deleted]]


From HDor@n @ending from @ir@org  Thu Aug 23 21:21:58 2018
From: HDor@n @ending from @ir@org (Doran, Harold)
Date: Thu, 23 Aug 2018 19:21:58 +0000
Subject: [R-sig-ME] How to use all the cores while running glmer on a
 piecewise exponential survival with
In-Reply-To: <CAAoDtR98dC5fXDrYrhMmYwKsXqhT=_7H0NeO=cViQ6S+2nxC4g@mail.gmail.com>
References: <CAAoDtR98dC5fXDrYrhMmYwKsXqhT=_7H0NeO=cViQ6S+2nxC4g@mail.gmail.com>
Message-ID: <BY2PR0501MB20080539AC4968AFCAA295FACA370@BY2PR0501MB2008.namprd05.prod.outlook.com>

No. You can change to an improved BLAS or I have found the Microsoft R has some built in multithreading that is fast for matrix algebra and it passes that benefit to lmer. From some experience, you can improve computational time of an lmer model with Microsoft R

-----Original Message-----
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> On Behalf Of Adam Mills-Campisi
Sent: Thursday, August 23, 2018 3:18 PM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] How to use all the cores while running glmer on a piecewise exponential survival with

I am estimating a piecewise exponential, mixed-effects, survival model with recurrent events. Each individual in the dataset gets an individual interpret (where using a PWP approach). Our full dataset has 10 million individuals, with 180 million events. I am not sure that there is any framework which can accommodate data at that size, so we are going to sample. Our final sample size largely depends on how quickly we can estimate the model, which brings me to my question: Is there a way to mutli-thread/core the model? I tried to find some kind of instruction on the web and the best lead I could find was a reference to this list serve.
Any help would be greatly appreciated.

	[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From HDor@n @ending from @ir@org  Thu Aug 23 21:23:21 2018
From: HDor@n @ending from @ir@org (Doran, Harold)
Date: Thu, 23 Aug 2018 19:23:21 +0000
Subject: [R-sig-ME] How to use all the cores while running glmer on a
 piecewise exponential survival with
In-Reply-To: <CAAoDtR98dC5fXDrYrhMmYwKsXqhT=_7H0NeO=cViQ6S+2nxC4g@mail.gmail.com>
References: <CAAoDtR98dC5fXDrYrhMmYwKsXqhT=_7H0NeO=cViQ6S+2nxC4g@mail.gmail.com>
Message-ID: <BY2PR0501MB200817E0973BE5476543C372CA370@BY2PR0501MB2008.namprd05.prod.outlook.com>

One idea, though, is you can take samples from your very large data set and estimate models on the samples very quickly. 

-----Original Message-----
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> On Behalf Of Adam Mills-Campisi
Sent: Thursday, August 23, 2018 3:18 PM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] How to use all the cores while running glmer on a piecewise exponential survival with

I am estimating a piecewise exponential, mixed-effects, survival model with recurrent events. Each individual in the dataset gets an individual interpret (where using a PWP approach). Our full dataset has 10 million individuals, with 180 million events. I am not sure that there is any framework which can accommodate data at that size, so we are going to sample. Our final sample size largely depends on how quickly we can estimate the model, which brings me to my question: Is there a way to mutli-thread/core the model? I tried to find some kind of instruction on the web and the best lead I could find was a reference to this list serve.
Any help would be greatly appreciated.

	[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From @d@mmill@c@mpi@i @ending from gm@il@com  Thu Aug 23 21:25:19 2018
From: @d@mmill@c@mpi@i @ending from gm@il@com (Adam Mills-Campisi)
Date: Thu, 23 Aug 2018 15:25:19 -0400
Subject: [R-sig-ME] How to use all the cores while running glmer on a
 piecewise exponential survival with
In-Reply-To: <BY2PR0501MB200817E0973BE5476543C372CA370@BY2PR0501MB2008.namprd05.prod.outlook.com>
References: <CAAoDtR98dC5fXDrYrhMmYwKsXqhT=_7H0NeO=cViQ6S+2nxC4g@mail.gmail.com>
 <BY2PR0501MB200817E0973BE5476543C372CA370@BY2PR0501MB2008.namprd05.prod.outlook.com>
Message-ID: <CAAoDtR_hGCf+_25S9MkWxhfnuFGJiwia7sE8Gt5Go6LWkGZpWw@mail.gmail.com>

That's the plan, the real question is how big should the samples be. The
faster we can estimate the model, the bigger the sample can be. If I can
run the model on multiple cores that would significantly increase the
sample size.

On Thu, Aug 23, 2018 at 12:23 PM Doran, Harold <HDoran at air.org> wrote:

> One idea, though, is you can take samples from your very large data set
> and estimate models on the samples very quickly.
>
> -----Original Message-----
> From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> On
> Behalf Of Adam Mills-Campisi
> Sent: Thursday, August 23, 2018 3:18 PM
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] How to use all the cores while running glmer on a
> piecewise exponential survival with
>
> I am estimating a piecewise exponential, mixed-effects, survival model
> with recurrent events. Each individual in the dataset gets an individual
> interpret (where using a PWP approach). Our full dataset has 10 million
> individuals, with 180 million events. I am not sure that there is any
> framework which can accommodate data at that size, so we are going to
> sample. Our final sample size largely depends on how quickly we can
> estimate the model, which brings me to my question: Is there a way to
> mutli-thread/core the model? I tried to find some kind of instruction on
> the web and the best lead I could find was a reference to this list serve.
> Any help would be greatly appreciated.
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>

	[[alternative HTML version deleted]]


From @d@mmill@c@mpi@i @ending from gm@il@com  Thu Aug 23 21:30:55 2018
From: @d@mmill@c@mpi@i @ending from gm@il@com (Adam Mills-Campisi)
Date: Thu, 23 Aug 2018 15:30:55 -0400
Subject: [R-sig-ME] How to use all the cores while running glmer on a
 piecewise exponential survival with
In-Reply-To: <BY2PR0501MB20080539AC4968AFCAA295FACA370@BY2PR0501MB2008.namprd05.prod.outlook.com>
References: <CAAoDtR98dC5fXDrYrhMmYwKsXqhT=_7H0NeO=cViQ6S+2nxC4g@mail.gmail.com>
 <BY2PR0501MB20080539AC4968AFCAA295FACA370@BY2PR0501MB2008.namprd05.prod.outlook.com>
Message-ID: <CAAoDtR_WYN2cCEPN9xHpBKUT7zhCryUHbDy+povepca8wfV=TQ@mail.gmail.com>

We originally tried to use stan to estimate the model, we were getting
performance issues. I assumed that the frequentist approaches would be
faster.

On Thu, Aug 23, 2018 at 12:28 PM Doran, Harold <HDoran at air.org> wrote:

> No. You can change to an improved BLAS or I have found the Microsoft R has
> some built in multithreading that is fast for matrix algebra and it passes
> that benefit to lmer. From some experience, you can improve computational
> time of an lmer model with Microsoft R
>
> -----Original Message-----
> From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> On
> Behalf Of Adam Mills-Campisi
> Sent: Thursday, August 23, 2018 3:18 PM
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] How to use all the cores while running glmer on a
> piecewise exponential survival with
>
> I am estimating a piecewise exponential, mixed-effects, survival model
> with recurrent events. Each individual in the dataset gets an individual
> interpret (where using a PWP approach). Our full dataset has 10 million
> individuals, with 180 million events. I am not sure that there is any
> framework which can accommodate data at that size, so we are going to
> sample. Our final sample size largely depends on how quickly we can
> estimate the model, which brings me to my question: Is there a way to
> mutli-thread/core the model? I tried to find some kind of instruction on
> the web and the best lead I could find was a reference to this list serve.
> Any help would be greatly appreciated.
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>

	[[alternative HTML version deleted]]


From HDor@n @ending from @ir@org  Thu Aug 23 21:32:10 2018
From: HDor@n @ending from @ir@org (Doran, Harold)
Date: Thu, 23 Aug 2018 19:32:10 +0000
Subject: [R-sig-ME] How to use all the cores while running glmer on a
 piecewise exponential survival with
In-Reply-To: <CAAoDtR_hGCf+_25S9MkWxhfnuFGJiwia7sE8Gt5Go6LWkGZpWw@mail.gmail.com>
References: <CAAoDtR98dC5fXDrYrhMmYwKsXqhT=_7H0NeO=cViQ6S+2nxC4g@mail.gmail.com>
 <BY2PR0501MB200817E0973BE5476543C372CA370@BY2PR0501MB2008.namprd05.prod.outlook.com>
 <CAAoDtR_hGCf+_25S9MkWxhfnuFGJiwia7sE8Gt5Go6LWkGZpWw@mail.gmail.com>
Message-ID: <BY2PR0501MB2008EFE8A6394D50BAC97F6CCA370@BY2PR0501MB2008.namprd05.prod.outlook.com>

Running the model on multiple cores won?t work because lmer isn?t written that way. One idea I?ve toyed with is start with a small-ish sample and get results. Plug those in as starting values to your next run which uses larger sample, but takes fewer steps because you?re closer to the max. Repeat until the difference in the param estimates from prior run is less than some tolerance.


From: Adam Mills-Campisi <adammillscampisi at gmail.com>
Sent: Thursday, August 23, 2018 3:25 PM
To: Doran, Harold <HDoran at air.org>
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] How to use all the cores while running glmer on a piecewise exponential survival with

That's the plan, the real question is how big should the samples be. The faster we can estimate the model, the bigger the sample can be. If I can run the model on multiple cores that would significantly increase the sample size.

On Thu, Aug 23, 2018 at 12:23 PM Doran, Harold <HDoran at air.org<mailto:HDoran at air.org>> wrote:
One idea, though, is you can take samples from your very large data set and estimate models on the samples very quickly.

-----Original Message-----
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org<mailto:r-sig-mixed-models-bounces at r-project.org>> On Behalf Of Adam Mills-Campisi
Sent: Thursday, August 23, 2018 3:18 PM
To: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
Subject: [R-sig-ME] How to use all the cores while running glmer on a piecewise exponential survival with

I am estimating a piecewise exponential, mixed-effects, survival model with recurrent events. Each individual in the dataset gets an individual interpret (where using a PWP approach). Our full dataset has 10 million individuals, with 180 million events. I am not sure that there is any framework which can accommodate data at that size, so we are going to sample. Our final sample size largely depends on how quickly we can estimate the model, which brings me to my question: Is there a way to mutli-thread/core the model? I tried to find some kind of instruction on the web and the best lead I could find was a reference to this list serve.
Any help would be greatly appreciated.

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From bbolker @ending from gm@il@com  Thu Aug 23 21:34:50 2018
From: bbolker @ending from gm@il@com (Ben Bolker)
Date: Thu, 23 Aug 2018 15:34:50 -0400
Subject: [R-sig-ME] How to use all the cores while running glmer on a
 piecewise exponential survival with
In-Reply-To: <CAAoDtR98dC5fXDrYrhMmYwKsXqhT=_7H0NeO=cViQ6S+2nxC4g@mail.gmail.com>
References: <CAAoDtR98dC5fXDrYrhMmYwKsXqhT=_7H0NeO=cViQ6S+2nxC4g@mail.gmail.com>
Message-ID: <CABghstS7HXSNtL9uQ9EdqQnJ7k3Rc5DbdqSzPF7fg12N_4LGzw@mail.gmail.com>

  I'd love to see what anyone else here has to say, but here are some thoughts.

1. There's no easy, pre-packaged way that I know of to scale things in
this way. What you can do will depend enormously on how much hacking
you're willing & able to do.
2. What Harold Doran said: The deepest level at which one *might*
multi-thread/core/parallelize the fitting process would be at the
level of the linear algebra.  lme4 uses some pretty fancy linear
algebra, so I don't know if it will help, but it would definitely be
worth experimenting a little bit with Microsoft "Open R" (or whatever
it's called) and with the various optimized BLAS options (Dirk
Eddelbuettel had an article about this a while back).  Might not help,
but if it does it's low-hanging fruit.
3. Depending on your random-effects structure (i.e. if your problem
decomposes into a moderate number of *conditionally* independent
chunks of data - that is, not a fully or strongly crossed design), it
wouldn't be too hard to write a top-level map-reduce-like operation
that, for a given set of parameters (random-effect var/cov +  called
the separate workers to compute the deviance for each chunk of data,
then summed them to get the total deviance for that set of parameters,
then took another optimization step.  I would love to see someone
implement something like this!
4. It might be worth experimenting with Doug Bates's MixedModels.jl
framework from Julia.
On Thu, Aug 23, 2018 at 3:18 PM Adam Mills-Campisi
<adammillscampisi at gmail.com> wrote:
>
> I am estimating a piecewise exponential, mixed-effects, survival model with
> recurrent events. Each individual in the dataset gets an individual
> interpret (where using a PWP approach). Our full dataset has 10 million
> individuals, with 180 million events. I am not sure that there is any
> framework which can accommodate data at that size, so we are going to
> sample. Our final sample size largely depends on how quickly we can
> estimate the model, which brings me to my question: Is there a way to
> mutli-thread/core the model? I tried to find some kind of instruction on
> the web and the best lead I could find was a reference to this list serve.
> Any help would be greatly appreciated.
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbolker @ending from gm@il@com  Thu Aug 23 22:08:58 2018
From: bbolker @ending from gm@il@com (Ben Bolker)
Date: Thu, 23 Aug 2018 16:08:58 -0400
Subject: [R-sig-ME] How to use all the cores while running glmer on a
 piecewise exponential survival with
In-Reply-To: <BY2PR0501MB2008EFE8A6394D50BAC97F6CCA370@BY2PR0501MB2008.namprd05.prod.outlook.com>
References: <CAAoDtR98dC5fXDrYrhMmYwKsXqhT=_7H0NeO=cViQ6S+2nxC4g@mail.gmail.com>
 <BY2PR0501MB200817E0973BE5476543C372CA370@BY2PR0501MB2008.namprd05.prod.outlook.com>
 <CAAoDtR_hGCf+_25S9MkWxhfnuFGJiwia7sE8Gt5Go6LWkGZpWw@mail.gmail.com>
 <BY2PR0501MB2008EFE8A6394D50BAC97F6CCA370@BY2PR0501MB2008.namprd05.prod.outlook.com>
Message-ID: <e60182d0-d75d-3b3f-610a-62db68c1a8b0@gmail.com>


  Harold, what do you think of my suggestion (partition problem into
multiple conditionally independent subsets, evaluate separate deviances
on workers, run top-level optimization on a central 'master' processor)?
 Am I missing something (except that some problems can't easily be
partitioned that way?)

  FWIW I think Doug Bates has pointed out in the past that for simple
(e.g. nested, not crossed) designs, the whole problem can be
reformulated in a more efficient way (of course I can't dig up that
e-mail ...).  lme4's strength is that it can handle the complex cases,
and so far no-one has had the time/energy/interest/capability of
implementing any of Doug's "special case" strategies, at least in lme4
-- may be done elsewhere in R, or in Doug's MixedModels.jl ...

  cheers
   Ben Bolker


On 2018-08-23 03:32 PM, Doran, Harold wrote:
> Running the model on multiple cores won?t work because lmer isn?t written that way. One idea I?ve toyed with is start with a small-ish sample and get results. Plug those in as starting values to your next run which uses larger sample, but takes fewer steps because you?re closer to the max. Repeat until the difference in the param estimates from prior run is less than some tolerance.
> 
> 
> From: Adam Mills-Campisi <adammillscampisi at gmail.com>
> Sent: Thursday, August 23, 2018 3:25 PM
> To: Doran, Harold <HDoran at air.org>
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] How to use all the cores while running glmer on a piecewise exponential survival with
> 
> That's the plan, the real question is how big should the samples be. The faster we can estimate the model, the bigger the sample can be. If I can run the model on multiple cores that would significantly increase the sample size.
> 
> On Thu, Aug 23, 2018 at 12:23 PM Doran, Harold <HDoran at air.org<mailto:HDoran at air.org>> wrote:
> One idea, though, is you can take samples from your very large data set and estimate models on the samples very quickly.
> 
> -----Original Message-----
> From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org<mailto:r-sig-mixed-models-bounces at r-project.org>> On Behalf Of Adam Mills-Campisi
> Sent: Thursday, August 23, 2018 3:18 PM
> To: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
> Subject: [R-sig-ME] How to use all the cores while running glmer on a piecewise exponential survival with
> 
> I am estimating a piecewise exponential, mixed-effects, survival model with recurrent events. Each individual in the dataset gets an individual interpret (where using a PWP approach). Our full dataset has 10 million individuals, with 180 million events. I am not sure that there is any framework which can accommodate data at that size, so we are going to sample. Our final sample size largely depends on how quickly we can estimate the model, which brings me to my question: Is there a way to mutli-thread/core the model? I tried to find some kind of instruction on the web and the best lead I could find was a reference to this list serve.
> Any help would be greatly appreciated.
> 
>         [[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From bbolker @ending from gm@il@com  Thu Aug 23 22:16:40 2018
From: bbolker @ending from gm@il@com (Ben Bolker)
Date: Thu, 23 Aug 2018 16:16:40 -0400
Subject: [R-sig-ME] How to use all the cores while running glmer on a
 piecewise exponential survival with
In-Reply-To: <CAAoDtR_WYN2cCEPN9xHpBKUT7zhCryUHbDy+povepca8wfV=TQ@mail.gmail.com>
References: <CAAoDtR98dC5fXDrYrhMmYwKsXqhT=_7H0NeO=cViQ6S+2nxC4g@mail.gmail.com>
 <BY2PR0501MB20080539AC4968AFCAA295FACA370@BY2PR0501MB2008.namprd05.prod.outlook.com>
 <CAAoDtR_WYN2cCEPN9xHpBKUT7zhCryUHbDy+povepca8wfV=TQ@mail.gmail.com>
Message-ID: <5bbb351b-409d-0b6d-82ec-dd5ecc50e498@gmail.com>


  Are the frequentist methods *not* faster?  I'd be pretty surprised,
unless some you're hitting some terrible memory bottleneck or something.


On 2018-08-23 03:30 PM, Adam Mills-Campisi wrote:
> We originally tried to use stan to estimate the model, we were getting
> performance issues. I assumed that the frequentist approaches would be
> faster.
> 
> On Thu, Aug 23, 2018 at 12:28 PM Doran, Harold <HDoran at air.org> wrote:
> 
>> No. You can change to an improved BLAS or I have found the Microsoft R has
>> some built in multithreading that is fast for matrix algebra and it passes
>> that benefit to lmer. From some experience, you can improve computational
>> time of an lmer model with Microsoft R
>>
>> -----Original Message-----
>> From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> On
>> Behalf Of Adam Mills-Campisi
>> Sent: Thursday, August 23, 2018 3:18 PM
>> To: r-sig-mixed-models at r-project.org
>> Subject: [R-sig-ME] How to use all the cores while running glmer on a
>> piecewise exponential survival with
>>
>> I am estimating a piecewise exponential, mixed-effects, survival model
>> with recurrent events. Each individual in the dataset gets an individual
>> interpret (where using a PWP approach). Our full dataset has 10 million
>> individuals, with 180 million events. I am not sure that there is any
>> framework which can accommodate data at that size, so we are going to
>> sample. Our final sample size largely depends on how quickly we can
>> estimate the model, which brings me to my question: Is there a way to
>> mutli-thread/core the model? I tried to find some kind of instruction on
>> the web and the best lead I could find was a reference to this list serve.
>> Any help would be greatly appreciated.
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From d@rizopoulo@ @ending from er@@mu@mc@nl  Thu Aug 23 23:27:41 2018
From: d@rizopoulo@ @ending from er@@mu@mc@nl (D. Rizopoulos)
Date: Thu, 23 Aug 2018 21:27:41 +0000
Subject: [R-sig-ME] How to use all the cores while running glmer on a
 piecewise exponential survival with
In-Reply-To: <5bbb351b-409d-0b6d-82ec-dd5ecc50e498@gmail.com>
References: <CAAoDtR98dC5fXDrYrhMmYwKsXqhT=_7H0NeO=cViQ6S+2nxC4g@mail.gmail.com>
 <BY2PR0501MB20080539AC4968AFCAA295FACA370@BY2PR0501MB2008.namprd05.prod.outlook.com>
 <CAAoDtR_WYN2cCEPN9xHpBKUT7zhCryUHbDy+povepca8wfV=TQ@mail.gmail.com>,
 <5bbb351b-409d-0b6d-82ec-dd5ecc50e498@gmail.com>
Message-ID: <7191AFC7255B4F49A30707E39BEAD05FDEB4E025@EXCH-HE03.erasmusmc.nl>

As suggested, an approach could be to split the original big sample in manageable pieces, do the analysis in each, and then combine the results.

Geert Molenberghs, Geert Verbeke and colleagues have worked on this; a relevant recent papers seems to be: https://lirias2repo.kuleuven.be/bitstream/id/470902/

I hope it helps.

Best,
Dimitris


From: Ben Bolker <bbolker at gmail.com<mailto:bbolker at gmail.com>>
Date: Thursday, 23 Aug 2018, 10:29 PM
To: r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>>
Subject: Re: [R-sig-ME] How to use all the cores while running glmer on a piecewise exponential survival with


  Are the frequentist methods *not* faster?  I'd be pretty surprised,
unless some you're hitting some terrible memory bottleneck or something.


On 2018-08-23 03:30 PM, Adam Mills-Campisi wrote:
> We originally tried to use stan to estimate the model, we were getting
> performance issues. I assumed that the frequentist approaches would be
> faster.
>
> On Thu, Aug 23, 2018 at 12:28 PM Doran, Harold <HDoran at air.org> wrote:
>
>> No. You can change to an improved BLAS or I have found the Microsoft R has
>> some built in multithreading that is fast for matrix algebra and it passes
>> that benefit to lmer. From some experience, you can improve computational
>> time of an lmer model with Microsoft R
>>
>> -----Original Message-----
>> From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> On
>> Behalf Of Adam Mills-Campisi
>> Sent: Thursday, August 23, 2018 3:18 PM
>> To: r-sig-mixed-models at r-project.org
>> Subject: [R-sig-ME] How to use all the cores while running glmer on a
>> piecewise exponential survival with
>>
>> I am estimating a piecewise exponential, mixed-effects, survival model
>> with recurrent events. Each individual in the dataset gets an individual
>> interpret (where using a PWP approach). Our full dataset has 10 million
>> individuals, with 180 million events. I am not sure that there is any
>> framework which can accommodate data at that size, so we are going to
>> sample. Our final sample size largely depends on how quickly we can
>> estimate the model, which brings me to my question: Is there a way to
>> mutli-thread/core the model? I tried to find some kind of instruction on
>> the web and the best lead I could find was a reference to this list serve.
>> Any help would be greatly appreciated.
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>
>
>        [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From @d@mmill@c@mpi@i @ending from gm@il@com  Fri Aug 24 00:46:54 2018
From: @d@mmill@c@mpi@i @ending from gm@il@com (Adam Mills-Campisi)
Date: Thu, 23 Aug 2018 18:46:54 -0400
Subject: [R-sig-ME] How to use all the cores while running glmer on a
 piecewise exponential survival with
In-Reply-To: <7191AFC7255B4F49A30707E39BEAD05FDEB4E025@EXCH-HE03.erasmusmc.nl>
References: <CAAoDtR98dC5fXDrYrhMmYwKsXqhT=_7H0NeO=cViQ6S+2nxC4g@mail.gmail.com>
 <BY2PR0501MB20080539AC4968AFCAA295FACA370@BY2PR0501MB2008.namprd05.prod.outlook.com>
 <CAAoDtR_WYN2cCEPN9xHpBKUT7zhCryUHbDy+povepca8wfV=TQ@mail.gmail.com>
 <5bbb351b-409d-0b6d-82ec-dd5ecc50e498@gmail.com>
 <7191AFC7255B4F49A30707E39BEAD05FDEB4E025@EXCH-HE03.erasmusmc.nl>
Message-ID: <CAAoDtR8+_F=8j6Q1PzakgrmyKJ9u8nSyOWVwM2j1PfmhTe+Wng@mail.gmail.com>

Thanks! We are looking into our options. The MixedModels package in Julia
benchmarks at about 2 orders of magnitude faster than R on a small dataset;
however, I would think a lot of that is just overhead from R. On a model of
this size, the computational time should converge because everyone is using
the same BLAS libraries. It might be worth further investigation if timing
remains an issue.

On Thu, Aug 23, 2018 at 2:27 PM D. Rizopoulos <d.rizopoulos at erasmusmc.nl>
wrote:

> As suggested, an approach could be to split the original big sample in
> manageable pieces, do the analysis in each, and then combine the results.
>
> Geert Molenberghs, Geert Verbeke and colleagues have worked on this; a
> relevant recent papers seems to be:
> https://lirias2repo.kuleuven.be/bitstream/id/470902/
>
> I hope it helps.
>
> Best,
> Dimitris
>
>
> From: Ben Bolker <bbolker at gmail.com<mailto:bbolker at gmail.com>>
> Date: Thursday, 23 Aug 2018, 10:29 PM
> To: r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org
> <mailto:r-sig-mixed-models at r-project.org>>
> Subject: Re: [R-sig-ME] How to use all the cores while running glmer on a
> piecewise exponential survival with
>
>
>   Are the frequentist methods *not* faster?  I'd be pretty surprised,
> unless some you're hitting some terrible memory bottleneck or something.
>
>
> On 2018-08-23 03:30 PM, Adam Mills-Campisi wrote:
> > We originally tried to use stan to estimate the model, we were getting
> > performance issues. I assumed that the frequentist approaches would be
> > faster.
> >
> > On Thu, Aug 23, 2018 at 12:28 PM Doran, Harold <HDoran at air.org> wrote:
> >
> >> No. You can change to an improved BLAS or I have found the Microsoft R
> has
> >> some built in multithreading that is fast for matrix algebra and it
> passes
> >> that benefit to lmer. From some experience, you can improve
> computational
> >> time of an lmer model with Microsoft R
> >>
> >> -----Original Message-----
> >> From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> On
> >> Behalf Of Adam Mills-Campisi
> >> Sent: Thursday, August 23, 2018 3:18 PM
> >> To: r-sig-mixed-models at r-project.org
> >> Subject: [R-sig-ME] How to use all the cores while running glmer on a
> >> piecewise exponential survival with
> >>
> >> I am estimating a piecewise exponential, mixed-effects, survival model
> >> with recurrent events. Each individual in the dataset gets an individual
> >> interpret (where using a PWP approach). Our full dataset has 10 million
> >> individuals, with 180 million events. I am not sure that there is any
> >> framework which can accommodate data at that size, so we are going to
> >> sample. Our final sample size largely depends on how quickly we can
> >> estimate the model, which brings me to my question: Is there a way to
> >> mutli-thread/core the model? I tried to find some kind of instruction on
> >> the web and the best lead I could find was a reference to this list
> serve.
> >> Any help would be greatly appreciated.
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>
> >>
> >
> >        [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From m@r@mon@fern@ndez @ending from gm@il@com  Fri Aug 24 08:15:29 2018
From: m@r@mon@fern@ndez @ending from gm@il@com (Manuel Ramon)
Date: Fri, 24 Aug 2018 08:15:29 +0200
Subject: [R-sig-ME] How to use all the cores while running glmer on a
 piecewise exponential survival with
In-Reply-To: <CAAoDtR8+_F=8j6Q1PzakgrmyKJ9u8nSyOWVwM2j1PfmhTe+Wng@mail.gmail.com>
References: <CAAoDtR98dC5fXDrYrhMmYwKsXqhT=_7H0NeO=cViQ6S+2nxC4g@mail.gmail.com>
 <BY2PR0501MB20080539AC4968AFCAA295FACA370@BY2PR0501MB2008.namprd05.prod.outlook.com>
 <CAAoDtR_WYN2cCEPN9xHpBKUT7zhCryUHbDy+povepca8wfV=TQ@mail.gmail.com>
 <5bbb351b-409d-0b6d-82ec-dd5ecc50e498@gmail.com>
 <7191AFC7255B4F49A30707E39BEAD05FDEB4E025@EXCH-HE03.erasmusmc.nl>
 <CAAoDtR8+_F=8j6Q1PzakgrmyKJ9u8nSyOWVwM2j1PfmhTe+Wng@mail.gmail.com>
Message-ID: <CAHB8JpLjbE5R+PP9GwTWewiqtUPJfr_eUpoUyuuVnXRPNb226A@mail.gmail.com>

Not sure if this can be useful:
bigglm: faster-generalised-linear-models-in-largeish-data
<https://notstatschat.rbind.io/2018/03/05/faster-generalised-linear-models-in-largeish-data/>

Manuel


On Fri, Aug 24, 2018 at 12:47 AM Adam Mills-Campisi <
adammillscampisi at gmail.com> wrote:

> Thanks! We are looking into our options. The MixedModels package in Julia
> benchmarks at about 2 orders of magnitude faster than R on a small dataset;
> however, I would think a lot of that is just overhead from R. On a model of
> this size, the computational time should converge because everyone is using
> the same BLAS libraries. It might be worth further investigation if timing
> remains an issue.
>
> On Thu, Aug 23, 2018 at 2:27 PM D. Rizopoulos <d.rizopoulos at erasmusmc.nl>
> wrote:
>
> > As suggested, an approach could be to split the original big sample in
> > manageable pieces, do the analysis in each, and then combine the results.
> >
> > Geert Molenberghs, Geert Verbeke and colleagues have worked on this; a
> > relevant recent papers seems to be:
> > https://lirias2repo.kuleuven.be/bitstream/id/470902/
> >
> > I hope it helps.
> >
> > Best,
> > Dimitris
> >
> >
> > From: Ben Bolker <bbolker at gmail.com<mailto:bbolker at gmail.com>>
> > Date: Thursday, 23 Aug 2018, 10:29 PM
> > To: r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org
> > <mailto:r-sig-mixed-models at r-project.org>>
> > Subject: Re: [R-sig-ME] How to use all the cores while running glmer on a
> > piecewise exponential survival with
> >
> >
> >   Are the frequentist methods *not* faster?  I'd be pretty surprised,
> > unless some you're hitting some terrible memory bottleneck or something.
> >
> >
> > On 2018-08-23 03:30 PM, Adam Mills-Campisi wrote:
> > > We originally tried to use stan to estimate the model, we were getting
> > > performance issues. I assumed that the frequentist approaches would be
> > > faster.
> > >
> > > On Thu, Aug 23, 2018 at 12:28 PM Doran, Harold <HDoran at air.org> wrote:
> > >
> > >> No. You can change to an improved BLAS or I have found the Microsoft R
> > has
> > >> some built in multithreading that is fast for matrix algebra and it
> > passes
> > >> that benefit to lmer. From some experience, you can improve
> > computational
> > >> time of an lmer model with Microsoft R
> > >>
> > >> -----Original Message-----
> > >> From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org>
> On
> > >> Behalf Of Adam Mills-Campisi
> > >> Sent: Thursday, August 23, 2018 3:18 PM
> > >> To: r-sig-mixed-models at r-project.org
> > >> Subject: [R-sig-ME] How to use all the cores while running glmer on a
> > >> piecewise exponential survival with
> > >>
> > >> I am estimating a piecewise exponential, mixed-effects, survival model
> > >> with recurrent events. Each individual in the dataset gets an
> individual
> > >> interpret (where using a PWP approach). Our full dataset has 10
> million
> > >> individuals, with 180 million events. I am not sure that there is any
> > >> framework which can accommodate data at that size, so we are going to
> > >> sample. Our final sample size largely depends on how quickly we can
> > >> estimate the model, which brings me to my question: Is there a way to
> > >> mutli-thread/core the model? I tried to find some kind of instruction
> on
> > >> the web and the best lead I could find was a reference to this list
> > serve.
> > >> Any help would be greatly appreciated.
> > >>
> > >>         [[alternative HTML version deleted]]
> > >>
> > >> _______________________________________________
> > >> R-sig-mixed-models at r-project.org mailing list
> > >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > >>
> > >>
> > >
> > >        [[alternative HTML version deleted]]
> > >
> > > _______________________________________________
> > > R-sig-mixed-models at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > >
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From lize@t@t@ @ending from gm@il@com  Fri Aug 24 09:50:54 2018
From: lize@t@t@ @ending from gm@il@com (Lize van der Merwe)
Date: Fri, 24 Aug 2018 09:50:54 +0200
Subject: [R-sig-ME] how do I describe heteroscedacity
Message-ID: <02b401d43b7f$31abe020$9503a060$@gmail.com>

I  used lme to fit a model which includes different variances for operators.

My question is:


What is the best way to report the operator standard deviations?   

Here are the details.

My data contains an outcome, with predictors load (4 different loads) and
operator (10 different operators).  It is a very large unbalanced data set,
with some operators only working on a single load while others operated on
all 4 loads.  I am interested in the load means, the operator means and the
operator variances.  The latter is my problem.

I used the model  

lme(Outcome~Load,random=~1|Operator,weights = varIdent(form= ~ 1 |
Operator),Data)

I used intervals() to obtain estimates with 95% CIs of the effects of the
loads and the operators.   

Because of identifiability, the model yields delta, the ratio of specific
operator standard deviation to first operator standard deviation with their
95% CIs.  The attached plot shows the deltas, with their confidence
intervals.  

Is it correct to state that, because the some of the CIs do not overlap, the
observer 4 is clearly less precise than some other observers? 

Thankyou in advance for advice.

Regards

Lize van der Merwe 

 

 


-------------- next part --------------
A non-text attachment was scrubbed...
Name: Observers.pdf
Type: application/pdf
Size: 2121 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20180824/b848eb45/attachment.pdf>

From b@chl@w01 @ending from outlook@com  Fri Aug 24 14:51:24 2018
From: b@chl@w01 @ending from outlook@com (Jonathan Judge)
Date: Fri, 24 Aug 2018 12:51:24 +0000
Subject: [R-sig-ME] How to use all the cores while running glmer on a
 piecewise exponential survival with
In-Reply-To: <CAAoDtR8+_F=8j6Q1PzakgrmyKJ9u8nSyOWVwM2j1PfmhTe+Wng@mail.gmail.com>
References: <CAAoDtR98dC5fXDrYrhMmYwKsXqhT=_7H0NeO=cViQ6S+2nxC4g@mail.gmail.com>
 <BY2PR0501MB20080539AC4968AFCAA295FACA370@BY2PR0501MB2008.namprd05.prod.outlook.com>
 <CAAoDtR_WYN2cCEPN9xHpBKUT7zhCryUHbDy+povepca8wfV=TQ@mail.gmail.com>
 <5bbb351b-409d-0b6d-82ec-dd5ecc50e498@gmail.com>
 <7191AFC7255B4F49A30707E39BEAD05FDEB4E025@EXCH-HE03.erasmusmc.nl>,
 <CAAoDtR8+_F=8j6Q1PzakgrmyKJ9u8nSyOWVwM2j1PfmhTe+Wng@mail.gmail.com>
Message-ID: <DM5PR16MB1484E1DE6EC9D6C2C79C1C52AF360@DM5PR16MB1484.namprd16.prod.outlook.com>

Have you given INLA a try? That?s a lot of individuals, but as long as they are members of one ?group? it might only cost you one hyperparameter, which seems to be the primary limitation for that approach. 

Jonathan

Sent from my iPhone

> On Aug 23, 2018, at 5:47 PM, Adam Mills-Campisi <adammillscampisi at gmail.com> wrote:
> 
> Thanks! We are looking into our options. The MixedModels package in Julia
> benchmarks at about 2 orders of magnitude faster than R on a small dataset;
> however, I would think a lot of that is just overhead from R. On a model of
> this size, the computational time should converge because everyone is using
> the same BLAS libraries. It might be worth further investigation if timing
> remains an issue.
> 
> On Thu, Aug 23, 2018 at 2:27 PM D. Rizopoulos <d.rizopoulos at erasmusmc.nl>
> wrote:
> 
>> As suggested, an approach could be to split the original big sample in
>> manageable pieces, do the analysis in each, and then combine the results.
>> 
>> Geert Molenberghs, Geert Verbeke and colleagues have worked on this; a
>> relevant recent papers seems to be:
>> https://lirias2repo.kuleuven.be/bitstream/id/470902/
>> 
>> I hope it helps.
>> 
>> Best,
>> Dimitris
>> 
>> 
>> From: Ben Bolker <bbolker at gmail.com<mailto:bbolker at gmail.com>>
>> Date: Thursday, 23 Aug 2018, 10:29 PM
>> To: r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org
>> <mailto:r-sig-mixed-models at r-project.org>>
>> Subject: Re: [R-sig-ME] How to use all the cores while running glmer on a
>> piecewise exponential survival with
>> 
>> 
>>  Are the frequentist methods *not* faster?  I'd be pretty surprised,
>> unless some you're hitting some terrible memory bottleneck or something.
>> 
>> 
>>> On 2018-08-23 03:30 PM, Adam Mills-Campisi wrote:
>>> We originally tried to use stan to estimate the model, we were getting
>>> performance issues. I assumed that the frequentist approaches would be
>>> faster.
>>> 
>>>> On Thu, Aug 23, 2018 at 12:28 PM Doran, Harold <HDoran at air.org> wrote:
>>>> 
>>>> No. You can change to an improved BLAS or I have found the Microsoft R
>> has
>>>> some built in multithreading that is fast for matrix algebra and it
>> passes
>>>> that benefit to lmer. From some experience, you can improve
>> computational
>>>> time of an lmer model with Microsoft R
>>>> 
>>>> -----Original Message-----
>>>> From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> On
>>>> Behalf Of Adam Mills-Campisi
>>>> Sent: Thursday, August 23, 2018 3:18 PM
>>>> To: r-sig-mixed-models at r-project.org
>>>> Subject: [R-sig-ME] How to use all the cores while running glmer on a
>>>> piecewise exponential survival with
>>>> 
>>>> I am estimating a piecewise exponential, mixed-effects, survival model
>>>> with recurrent events. Each individual in the dataset gets an individual
>>>> interpret (where using a PWP approach). Our full dataset has 10 million
>>>> individuals, with 180 million events. I am not sure that there is any
>>>> framework which can accommodate data at that size, so we are going to
>>>> sample. Our final sample size largely depends on how quickly we can
>>>> estimate the model, which brings me to my question: Is there a way to
>>>> mutli-thread/core the model? I tried to find some kind of instruction on
>>>> the web and the best lead I could find was a reference to this list
>> serve.
>>>> Any help would be greatly appreciated.
>>>> 
>>>>        [[alternative HTML version deleted]]
>>>> 
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>> 
>>>> 
>>> 
>>>       [[alternative HTML version deleted]]
>>> 
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> 
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 
>>        [[alternative HTML version deleted]]
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 
> 
>    [[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

From HDor@n @ending from @ir@org  Fri Aug 24 16:20:59 2018
From: HDor@n @ending from @ir@org (Doran, Harold)
Date: Fri, 24 Aug 2018 14:20:59 +0000
Subject: [R-sig-ME] How to use all the cores while running glmer on a
 piecewise exponential survival with
In-Reply-To: <e60182d0-d75d-3b3f-610a-62db68c1a8b0@gmail.com>
References: <CAAoDtR98dC5fXDrYrhMmYwKsXqhT=_7H0NeO=cViQ6S+2nxC4g@mail.gmail.com>
 <BY2PR0501MB200817E0973BE5476543C372CA370@BY2PR0501MB2008.namprd05.prod.outlook.com>
 <CAAoDtR_hGCf+_25S9MkWxhfnuFGJiwia7sE8Gt5Go6LWkGZpWw@mail.gmail.com>
 <BY2PR0501MB2008EFE8A6394D50BAC97F6CCA370@BY2PR0501MB2008.namprd05.prod.outlook.com>
 <e60182d0-d75d-3b3f-610a-62db68c1a8b0@gmail.com>
Message-ID: <BLUPR0501MB820A939A73FC686EB79D7DDCA360@BLUPR0501MB820.namprd05.prod.outlook.com>

@ben, I like that idea. I've done that with some recent work that reduces some dimensionality in the integration and makes the problem easier to compute. I just don't know the current problem well enough to know if that is feasible here.

But, it's certainly an idea to explore.



-----Original Message-----
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> On Behalf Of Ben Bolker
Sent: Thursday, August 23, 2018 4:09 PM
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] How to use all the cores while running glmer on a piecewise exponential survival with


  Harold, what do you think of my suggestion (partition problem into multiple conditionally independent subsets, evaluate separate deviances on workers, run top-level optimization on a central 'master' processor)?
 Am I missing something (except that some problems can't easily be partitioned that way?)

  FWIW I think Doug Bates has pointed out in the past that for simple (e.g. nested, not crossed) designs, the whole problem can be reformulated in a more efficient way (of course I can't dig up that e-mail ...).  lme4's strength is that it can handle the complex cases, and so far no-one has had the time/energy/interest/capability of implementing any of Doug's "special case" strategies, at least in lme4
-- may be done elsewhere in R, or in Doug's MixedModels.jl ...

  cheers
   Ben Bolker


On 2018-08-23 03:32 PM, Doran, Harold wrote:
> Running the model on multiple cores won?t work because lmer isn?t written that way. One idea I?ve toyed with is start with a small-ish sample and get results. Plug those in as starting values to your next run which uses larger sample, but takes fewer steps because you?re closer to the max. Repeat until the difference in the param estimates from prior run is less than some tolerance.
> 
> 
> From: Adam Mills-Campisi <adammillscampisi at gmail.com>
> Sent: Thursday, August 23, 2018 3:25 PM
> To: Doran, Harold <HDoran at air.org>
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] How to use all the cores while running glmer 
> on a piecewise exponential survival with
> 
> That's the plan, the real question is how big should the samples be. The faster we can estimate the model, the bigger the sample can be. If I can run the model on multiple cores that would significantly increase the sample size.
> 
> On Thu, Aug 23, 2018 at 12:23 PM Doran, Harold <HDoran at air.org<mailto:HDoran at air.org>> wrote:
> One idea, though, is you can take samples from your very large data set and estimate models on the samples very quickly.
> 
> -----Original Message-----
> From: R-sig-mixed-models 
> <r-sig-mixed-models-bounces at r-project.org<mailto:r-sig-mixed-models-bo
> unces at r-project.org>> On Behalf Of Adam Mills-Campisi
> Sent: Thursday, August 23, 2018 3:18 PM
> To: 
> r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.o
> rg>
> Subject: [R-sig-ME] How to use all the cores while running glmer on a 
> piecewise exponential survival with
> 
> I am estimating a piecewise exponential, mixed-effects, survival model with recurrent events. Each individual in the dataset gets an individual interpret (where using a PWP approach). Our full dataset has 10 million individuals, with 180 million events. I am not sure that there is any framework which can accommodate data at that size, so we are going to sample. Our final sample size largely depends on how quickly we can estimate the model, which brings me to my question: Is there a way to mutli-thread/core the model? I tried to find some kind of instruction on the web and the best lead I could find was a reference to this list serve.
> Any help would be greatly appreciated.
> 
>         [[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.o
> rg> mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From d@rizopoulo@ @ending from er@@mu@mc@nl  Fri Aug 24 16:28:18 2018
From: d@rizopoulo@ @ending from er@@mu@mc@nl (D. Rizopoulos)
Date: Fri, 24 Aug 2018 14:28:18 +0000
Subject: [R-sig-ME] How to use all the cores while running glmer on a
 piecewise exponential survival with
In-Reply-To: <BLUPR0501MB820A939A73FC686EB79D7DDCA360@BLUPR0501MB820.namprd05.prod.outlook.com>
References: <CAAoDtR98dC5fXDrYrhMmYwKsXqhT=_7H0NeO=cViQ6S+2nxC4g@mail.gmail.com>
 <BY2PR0501MB200817E0973BE5476543C372CA370@BY2PR0501MB2008.namprd05.prod.outlook.com>
 <CAAoDtR_hGCf+_25S9MkWxhfnuFGJiwia7sE8Gt5Go6LWkGZpWw@mail.gmail.com>
 <BY2PR0501MB2008EFE8A6394D50BAC97F6CCA370@BY2PR0501MB2008.namprd05.prod.outlook.com>
 <e60182d0-d75d-3b3f-610a-62db68c1a8b0@gmail.com>
 <BLUPR0501MB820A939A73FC686EB79D7DDCA360@BLUPR0501MB820.namprd05.prod.outlook.com>
Message-ID: <7191AFC7255B4F49A30707E39BEAD05FDEB4EB5E@EXCH-HE03.erasmusmc.nl>

I think the idea of how to efficiently implement Laplace and adaptive Gauss-Hermite integration in nested random effects designs for GLMMS is described in https://dx.doi.org/10.1198/106186006X96962



-----Original Message-----
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> On Behalf Of Doran, Harold
Sent: Friday, August 24, 2018 4:21 PM
To: Ben Bolker <bbolker at gmail.com>; r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] How to use all the cores while running glmer on a piecewise exponential survival with

@ben, I like that idea. I've done that with some recent work that reduces some dimensionality in the integration and makes the problem easier to compute. I just don't know the current problem well enough to know if that is feasible here.

But, it's certainly an idea to explore.



-----Original Message-----
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> On Behalf Of Ben Bolker
Sent: Thursday, August 23, 2018 4:09 PM
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] How to use all the cores while running glmer on a piecewise exponential survival with


  Harold, what do you think of my suggestion (partition problem into multiple conditionally independent subsets, evaluate separate deviances on workers, run top-level optimization on a central 'master' processor)?
 Am I missing something (except that some problems can't easily be partitioned that way?)

  FWIW I think Doug Bates has pointed out in the past that for simple (e.g. nested, not crossed) designs, the whole problem can be reformulated in a more efficient way (of course I can't dig up that e-mail ...).  lme4's strength is that it can handle the complex cases, and so far no-one has had the time/energy/interest/capability of implementing any of Doug's "special case" strategies, at least in lme4
-- may be done elsewhere in R, or in Doug's MixedModels.jl ...

  cheers
   Ben Bolker


On 2018-08-23 03:32 PM, Doran, Harold wrote:
> Running the model on multiple cores won?t work because lmer isn?t written that way. One idea I?ve toyed with is start with a small-ish sample and get results. Plug those in as starting values to your next run which uses larger sample, but takes fewer steps because you?re closer to the max. Repeat until the difference in the param estimates from prior run is less than some tolerance.
> 
> 
> From: Adam Mills-Campisi <adammillscampisi at gmail.com>
> Sent: Thursday, August 23, 2018 3:25 PM
> To: Doran, Harold <HDoran at air.org>
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] How to use all the cores while running glmer 
> on a piecewise exponential survival with
> 
> That's the plan, the real question is how big should the samples be. The faster we can estimate the model, the bigger the sample can be. If I can run the model on multiple cores that would significantly increase the sample size.
> 
> On Thu, Aug 23, 2018 at 12:23 PM Doran, Harold <HDoran at air.org<mailto:HDoran at air.org>> wrote:
> One idea, though, is you can take samples from your very large data set and estimate models on the samples very quickly.
> 
> -----Original Message-----
> From: R-sig-mixed-models
> <r-sig-mixed-models-bounces at r-project.org<mailto:r-sig-mixed-models-bo
> unces at r-project.org>> On Behalf Of Adam Mills-Campisi
> Sent: Thursday, August 23, 2018 3:18 PM
> To: 
> r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.o
> rg>
> Subject: [R-sig-ME] How to use all the cores while running glmer on a 
> piecewise exponential survival with
> 
> I am estimating a piecewise exponential, mixed-effects, survival model with recurrent events. Each individual in the dataset gets an individual interpret (where using a PWP approach). Our full dataset has 10 million individuals, with 180 million events. I am not sure that there is any framework which can accommodate data at that size, so we are going to sample. Our final sample size largely depends on how quickly we can estimate the model, which brings me to my question: Is there a way to mutli-thread/core the model? I tried to find some kind of instruction on the web and the best lead I could find was a reference to this list serve.
> Any help would be greatly appreciated.
> 
>         [[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.o
> rg> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

From @d@mmill@c@mpi@i @ending from gm@il@com  Fri Aug 24 18:10:49 2018
From: @d@mmill@c@mpi@i @ending from gm@il@com (Adam Mills-Campisi)
Date: Fri, 24 Aug 2018 12:10:49 -0400
Subject: [R-sig-ME] How to use all the cores while running glmer on a
 piecewise exponential survival with
In-Reply-To: <7191AFC7255B4F49A30707E39BEAD05FDEB4EB5E@EXCH-HE03.erasmusmc.nl>
References: <CAAoDtR98dC5fXDrYrhMmYwKsXqhT=_7H0NeO=cViQ6S+2nxC4g@mail.gmail.com>
 <BY2PR0501MB200817E0973BE5476543C372CA370@BY2PR0501MB2008.namprd05.prod.outlook.com>
 <CAAoDtR_hGCf+_25S9MkWxhfnuFGJiwia7sE8Gt5Go6LWkGZpWw@mail.gmail.com>
 <BY2PR0501MB2008EFE8A6394D50BAC97F6CCA370@BY2PR0501MB2008.namprd05.prod.outlook.com>
 <e60182d0-d75d-3b3f-610a-62db68c1a8b0@gmail.com>
 <BLUPR0501MB820A939A73FC686EB79D7DDCA360@BLUPR0501MB820.namprd05.prod.outlook.com>
 <7191AFC7255B4F49A30707E39BEAD05FDEB4EB5E@EXCH-HE03.erasmusmc.nl>
Message-ID: <CAAoDtR9m5JauQu9sSc_7=_B=7rO8b2_q71nwFaW3vc+E0O4CEQ@mail.gmail.com>

We're going to look into INLA and biglm. As long as we are considering
alternatives, does anyone know of a really know of a really fast
implementation of other survival models? If this is off topic, there is no
need to reply. Our only constraint is that we need to control for the
repeated events (we have an uneven number of responses per individual).
We've looked at coxme, but we are getting the same performance bottlenecks
(we can only run single core and there are exponential time costs when we
increase the number of observations).

On Fri, Aug 24, 2018 at 7:36 AM D. Rizopoulos <d.rizopoulos at erasmusmc.nl>
wrote:

> I think the idea of how to efficiently implement Laplace and adaptive
> Gauss-Hermite integration in nested random effects designs for GLMMS is
> described in https://dx.doi.org/10.1198/106186006X96962
>
>
>
> -----Original Message-----
> From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> On
> Behalf Of Doran, Harold
> Sent: Friday, August 24, 2018 4:21 PM
> To: Ben Bolker <bbolker at gmail.com>; r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] How to use all the cores while running glmer on a
> piecewise exponential survival with
>
> @ben, I like that idea. I've done that with some recent work that reduces
> some dimensionality in the integration and makes the problem easier to
> compute. I just don't know the current problem well enough to know if that
> is feasible here.
>
> But, it's certainly an idea to explore.
>
>
>
> -----Original Message-----
> From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> On
> Behalf Of Ben Bolker
> Sent: Thursday, August 23, 2018 4:09 PM
> To: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] How to use all the cores while running glmer on a
> piecewise exponential survival with
>
>
>   Harold, what do you think of my suggestion (partition problem into
> multiple conditionally independent subsets, evaluate separate deviances on
> workers, run top-level optimization on a central 'master' processor)?
>  Am I missing something (except that some problems can't easily be
> partitioned that way?)
>
>   FWIW I think Doug Bates has pointed out in the past that for simple
> (e.g. nested, not crossed) designs, the whole problem can be reformulated
> in a more efficient way (of course I can't dig up that e-mail ...).  lme4's
> strength is that it can handle the complex cases, and so far no-one has had
> the time/energy/interest/capability of implementing any of Doug's "special
> case" strategies, at least in lme4
> -- may be done elsewhere in R, or in Doug's MixedModels.jl ...
>
>   cheers
>    Ben Bolker
>
>
> On 2018-08-23 03:32 PM, Doran, Harold wrote:
> > Running the model on multiple cores won?t work because lmer isn?t
> written that way. One idea I?ve toyed with is start with a small-ish sample
> and get results. Plug those in as starting values to your next run which
> uses larger sample, but takes fewer steps because you?re closer to the max.
> Repeat until the difference in the param estimates from prior run is less
> than some tolerance.
> >
> >
> > From: Adam Mills-Campisi <adammillscampisi at gmail.com>
> > Sent: Thursday, August 23, 2018 3:25 PM
> > To: Doran, Harold <HDoran at air.org>
> > Cc: r-sig-mixed-models at r-project.org
> > Subject: Re: [R-sig-ME] How to use all the cores while running glmer
> > on a piecewise exponential survival with
> >
> > That's the plan, the real question is how big should the samples be. The
> faster we can estimate the model, the bigger the sample can be. If I can
> run the model on multiple cores that would significantly increase the
> sample size.
> >
> > On Thu, Aug 23, 2018 at 12:23 PM Doran, Harold <HDoran at air.org<mailto:
> HDoran at air.org>> wrote:
> > One idea, though, is you can take samples from your very large data set
> and estimate models on the samples very quickly.
> >
> > -----Original Message-----
> > From: R-sig-mixed-models
> > <r-sig-mixed-models-bounces at r-project.org<mailto:r-sig-mixed-models-bo
> > unces at r-project.org>> On Behalf Of Adam Mills-Campisi
> > Sent: Thursday, August 23, 2018 3:18 PM
> > To:
> > r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.o
> > rg>
> > Subject: [R-sig-ME] How to use all the cores while running glmer on a
> > piecewise exponential survival with
> >
> > I am estimating a piecewise exponential, mixed-effects, survival model
> with recurrent events. Each individual in the dataset gets an individual
> interpret (where using a PWP approach). Our full dataset has 10 million
> individuals, with 180 million events. I am not sure that there is any
> framework which can accommodate data at that size, so we are going to
> sample. Our final sample size largely depends on how quickly we can
> estimate the model, which brings me to my question: Is there a way to
> mutli-thread/core the model? I tried to find some kind of instruction on
> the web and the best lead I could find was a reference to this list serve.
> > Any help would be greatly appreciated.
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.o
> > rg> mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From lize@t@t@ @ending from gm@il@com  Sat Aug 25 11:50:24 2018
From: lize@t@t@ @ending from gm@il@com (Lize van der Merwe)
Date: Sat, 25 Aug 2018 11:50:24 +0200
Subject: [R-sig-ME] FW: how do I describe heteroscedacity
In-Reply-To: <02b401d43b7f$31abe020$9503a060$@gmail.com>
References: <02b401d43b7f$31abe020$9503a060$@gmail.com>
Message-ID: <000b01d43c59$0db245d0$2916d170$@gmail.com>

Dear mixed-models list
Please help.
I? used lme to fit a model which includes different variances for operators.
My question is:
?????????????????????????????????????????????????????????????????????? 
What is the best way to report the operator standard deviations?? ?
Here are the details.
My data contains an outcome, with predictors load (4 different loads) and
operator (10 different operators).? It is a very large unbalanced data set,
with some operators only working on a single load while others operated on
all 4 loads.? I am interested in the load means, the operator means and the
operator variances.? The latter is my problem.
I used the model ?
lme(Outcome~Load,random=~1|Operator,weights = varIdent(form= ~ 1 |
Operator),Data)
I used intervals() to obtain estimates with 95% CIs of the effects of the
loads and the operators.? ?
Because of identifiability, the model yields delta, the ratio of specific
operator standard deviation to first operator standard deviation with their
95% CIs.? 
The attached plot shows the deltas, with their confidence intervals.? 
Is it possible to  estimate the standard deviations and their confidence
intervals?
Is it correct to state that, because the some of the CIs do not overlap, the
observer 4 is clearly less precise than some other observers? 
Thankyou in advance for advice.
Regards
Lize van der Merwe 



-------------- next part --------------
A non-text attachment was scrubbed...
Name: Observers.pdf
Type: application/pdf
Size: 2121 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20180825/5f0ed196/attachment.pdf>

From @lte@@ed@c2 @ending from gm@il@com  Sat Aug 25 19:38:14 2018
From: @lte@@ed@c2 @ending from gm@il@com (C. AMAL D. GLELE)
Date: Sat, 25 Aug 2018 19:38:14 +0200
Subject: [R-sig-ME] glmmadmb_problem: "sd.est not defined for this family"
Message-ID: <CANrzCv3d2b39TKt8rKRTyh3Wxwwy8OZetD6_-PoUqUhf3ey0rA@mail.gmail.com>

Hi, dear all.
When fitting models with glmmadmb, I'm encountering the following problems:
Problem1
I've fitted "mymodel" using glmmadmb with family="troncnbinom1";
the model fits, but with the following warning:
"In eval(substitute(expr), data, enclos = parent.frame()) :
  sd.est not defined for this family"
summary() shows correctly the outputs, but residuals(mymodel) gives only
"NA";
the same problem occurs when family="troncnbinom"
Problem2
I've fitted "mymodel2" using glmmadmb, with family"poisson"; it has fitted
well(without neither error, nor warning)
but, plot.glmmadmb() sent  "couldn't see function plot.glmmadmb";
in add, VarCorr(mymodel2) is giving me only intercepts variance, although
I've included random slope in the model.
Taking a look at the "troubleshooting" session of "glmmadmb_manual" did not
help me solving these problems.
In advance, thanks for your helps.
Kind regards,
Amal

	[[alternative HTML version deleted]]


From bbolker @ending from gm@il@com  Sun Aug 26 01:02:03 2018
From: bbolker @ending from gm@il@com (Ben Bolker)
Date: Sat, 25 Aug 2018 19:02:03 -0400
Subject: [R-sig-ME] first release of broom.mixed
Message-ID: <6ee816a5-c940-0b6f-5fa0-752d0558b21b@gmail.com>


  Hi folks,

 I've been working on the 'broom.mixed' package for the last while; this
package provides a unified and (hopefully) clean interface to a variety
of mixed model packages. It's an extension of the 'broom' package, which
is a broader package for "tidying" statistical models ... the intention
is that eventually broom.mixed will take over tidying for mixed model
packages.

  I'm hoping to send it to CRAN in the very near future.  I'm interested
in feedback, **especially those that have implications for the API**
(i.e., changes that would affect backward compatibility if I were to
make them in the future).

  https://github.com/bbolker/broom.mixed/issues

  If you like broom.mixed, you might like the huxtable and dotwhisker
packages too ...

  At present the methods and objects covered are:


          tidy glance augment
brmsfit      1      1       1
gamlss       1      .       .
gamm4        1      1       1
glmmadmb     1      1       1
glmmTMB      1      1       1
gls          1      1       .
lme          1      1       1
mcmc         1      .       .
MCMCglmm     1      .       .
merMod       1      1       1
ranef.mer    .      .       1
rjags        1      .       .
rlmerMod     1      .       .
stanfit      1      .       .
stanreg      1      1       .
TMB          1      .       .

I hope to add INLA tidiers at some point ...


From d@rizopoulo@ @ending from er@@mu@mc@nl  Sun Aug 26 19:01:37 2018
From: d@rizopoulo@ @ending from er@@mu@mc@nl (D. Rizopoulos)
Date: Sun, 26 Aug 2018 17:01:37 +0000
Subject: [R-sig-ME] 
 glmmadmb_problem: "sd.est not defined for this family"
In-Reply-To: <CANrzCv3d2b39TKt8rKRTyh3Wxwwy8OZetD6_-PoUqUhf3ey0rA@mail.gmail.com>
References: <CANrzCv3d2b39TKt8rKRTyh3Wxwwy8OZetD6_-PoUqUhf3ey0rA@mail.gmail.com>
Message-ID: <7191AFC7255B4F49A30707E39BEAD05FDEB50083@EXCH-HE03.erasmusmc.nl>

If you?re interested, you could also give a try in the GLMMadaptive package that can also fit zero-inflated and two-part/hurdle models under maximum likelihood using the adaptive Gaussian quadrature rule.

For more info check: https://drizopoulos.github.io/GLMMadaptive/articles/ZeroInflated_and_TwoPart_Models.html

Best,
Dimitris


- - - - - -
Dimitris Rizopoulos
Professor of Biostatistics
Erasmus University Medical Center
The Netherlands

From: C. AMAL D. GLELE <altessedac2 at gmail.com<mailto:altessedac2 at gmail.com>>
Date: Saturday, 25 Aug 2018, 9:38 PM
To: R SIG Mixed Models <r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>>
Subject: [R-sig-ME] glmmadmb_problem: "sd.est not defined for this family"

Hi, dear all.
When fitting models with glmmadmb, I'm encountering the following problems:
Problem1
I've fitted "mymodel" using glmmadmb with family="troncnbinom1";
the model fits, but with the following warning:
"In eval(substitute(expr), data, enclos = parent.frame()) :
  sd.est not defined for this family"
summary() shows correctly the outputs, but residuals(mymodel) gives only
"NA";
the same problem occurs when family="troncnbinom"
Problem2
I've fitted "mymodel2" using glmmadmb, with family"poisson"; it has fitted
well(without neither error, nor warning)
but, plot.glmmadmb() sent  "couldn't see function plot.glmmadmb";
in add, VarCorr(mymodel2) is giving me only intercepts variance, although
I've included random slope in the model.
Taking a look at the "troubleshooting" session of "glmmadmb_manual" did not
help me solving these problems.
In advance, thanks for your helps.
Kind regards,
Amal

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From @rued@ @ending from ced@u@b@e@  Mon Aug 27 03:19:56 2018
From: @rued@ @ending from ced@u@b@e@ (=?UTF-8?Q?Sarah=C3=AD_Rueda_Salazar?=)
Date: Sun, 26 Aug 2018 22:19:56 -0300
Subject: [R-sig-ME] mixed model in Cox PH with stratified hazard
Message-ID: <CAHRw6-9u-_wU4pnDV2wbKwXiT2xXTD+8sbzKEaN6wNyMKRofqQ@mail.gmail.com>

Hello, dear R users,

I?ve tried to fit a model with random intercept by countries in a cox
proportional hazard model with stratified hazard by different health
transition.

It is a frailty model for a multistate model.

Not sure if I can do it using coxME package,* Has anybody tried before?*

I think that variances for countries should be different by health
transition type but just I got one set of variances.

Any clue is more than welcome!

-- 
*Sarah? *












*Centre d'Estudis Demogr?ficsCarrer de Ca n'Altay?, Edifici E2Universitat
Aut?noma de Barcelona,08193
Bellaterra, Barcelona/SPAINPhone: 34/93.581.30.60
<34%2F93.581.30.60>Fax: 34/93.581.30.61
<34%2F93.581.30.61>e-mail: srueda at ced.uab.es
<ssancho at ced.uab.es>http://www.ced.uab.es
<http://s.bl-1.com/h/cowMjKwY?url=http://www.ced.uab.es/>*

	[[alternative HTML version deleted]]


From D@vid@Duffy @ending from qimrberghofer@edu@@u  Mon Aug 27 04:38:47 2018
From: D@vid@Duffy @ending from qimrberghofer@edu@@u (David Duffy)
Date: Mon, 27 Aug 2018 02:38:47 +0000
Subject: [R-sig-ME] How to use all the cores while running glmer on a
 piecewise exponential survival with
In-Reply-To: <CAAoDtR9m5JauQu9sSc_7=_B=7rO8b2_q71nwFaW3vc+E0O4CEQ@mail.gmail.com>
References: <CAAoDtR98dC5fXDrYrhMmYwKsXqhT=_7H0NeO=cViQ6S+2nxC4g@mail.gmail.com>
 <BY2PR0501MB200817E0973BE5476543C372CA370@BY2PR0501MB2008.namprd05.prod.outlook.com>
 <CAAoDtR_hGCf+_25S9MkWxhfnuFGJiwia7sE8Gt5Go6LWkGZpWw@mail.gmail.com>
 <BY2PR0501MB2008EFE8A6394D50BAC97F6CCA370@BY2PR0501MB2008.namprd05.prod.outlook.com>
 <e60182d0-d75d-3b3f-610a-62db68c1a8b0@gmail.com>
 <BLUPR0501MB820A939A73FC686EB79D7DDCA360@BLUPR0501MB820.namprd05.prod.outlook.com>
 <7191AFC7255B4F49A30707E39BEAD05FDEB4EB5E@EXCH-HE03.erasmusmc.nl>,
 <CAAoDtR9m5JauQu9sSc_7=_B=7rO8b2_q71nwFaW3vc+E0O4CEQ@mail.gmail.com>
Message-ID: <4737E17E7C8C3C4A8B5C1CE5346371D4A84CEC20@EXCH06S.adqimr.ad.lan>

Maybe this is old hat, but folks might have seen 

https://amstat.tandfonline.com/doi/abs/10.1198/jcgs.2009.06127?journalCode=ucgs20

where they fit poisson and binomial GLMMs for 33M records. Just have to develop and code a suitable discrete-time model for your data ;) I did download the code for that paper, but didn't ever follow through.

Cheers, David Duffy.

From @lte@@ed@c2 @ending from gm@il@com  Mon Aug 27 09:58:54 2018
From: @lte@@ed@c2 @ending from gm@il@com (C. AMAL D. GLELE)
Date: Mon, 27 Aug 2018 09:58:54 +0200
Subject: [R-sig-ME] 
 glmmadmb_problem: "sd.est not defined for this family"
In-Reply-To: <7191AFC7255B4F49A30707E39BEAD05FDEB50083@EXCH-HE03.erasmusmc.nl>
References: <CANrzCv3d2b39TKt8rKRTyh3Wxwwy8OZetD6_-PoUqUhf3ey0rA@mail.gmail.com>
 <7191AFC7255B4F49A30707E39BEAD05FDEB50083@EXCH-HE03.erasmusmc.nl>
Message-ID: <CANrzCv21MmhQbZiz9Rtr0MJK_FDuzPidDdqiSBh6qm9HUq3+MA@mail.gmail.com>

Hi, dear Dimitri.
Thanks for your suggestion; I will try it and let you know.
All the Best,
Amal

Le dim. 26 ao?t 2018 ? 19:01, D. Rizopoulos <d.rizopoulos at erasmusmc.nl> a
?crit :

> If you?re interested, you could also give a try in the GLMMadaptive
> package that can also fit zero-inflated and two-part/hurdle models under
> maximum likelihood using the adaptive Gaussian quadrature rule.
>
> For more info check:
> https://drizopoulos.github.io/GLMMadaptive/articles/ZeroInflated_and_TwoPart_Models.html
>
> Best,
> Dimitris
>
>
> - - - - - -
> Dimitris Rizopoulos
> Professor of Biostatistics
> Erasmus University Medical Center
> The Netherlands
>
> *From: *C. AMAL D. GLELE <altessedac2 at gmail.com>
> *Date: *Saturday, 25 Aug 2018, 9:38 PM
> *To: *R SIG Mixed Models <r-sig-mixed-models at r-project.org>
> *Subject: *[R-sig-ME] glmmadmb_problem: "sd.est not defined for this
> family"
>
> Hi, dear all.
> When fitting models with glmmadmb, I'm encountering the following problems:
> Problem1
> I've fitted "mymodel" using glmmadmb with family="troncnbinom1";
> the model fits, but with the following warning:
> "In eval(substitute(expr), data, enclos = parent.frame()) :
>   sd.est not defined for this family"
> summary() shows correctly the outputs, but residuals(mymodel) gives only
> "NA";
> the same problem occurs when family="troncnbinom"
> Problem2
> I've fitted "mymodel2" using glmmadmb, with family"poisson"; it has fitted
> well(without neither error, nor warning)
> but, plot.glmmadmb() sent  "couldn't see function plot.glmmadmb";
> in add, VarCorr(mymodel2) is giving me only intercepts variance, although
> I've included random slope in the model.
> Taking a look at the "troubleshooting" session of "glmmadmb_manual" did not
> help me solving these problems.
> In advance, thanks for your helps.
> Kind regards,
> Amal
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From wj5tu @ending from virgini@@edu  Mon Aug 27 21:28:27 2018
From: wj5tu @ending from virgini@@edu (Wenjian Jia)
Date: Mon, 27 Aug 2018 15:28:27 -0400
Subject: [R-sig-ME] MCMCglmm for unbalanced panel data
Message-ID: <CAHsSxBo8D62geM8771kesi5vC8rP5KX3ROmx4WMZO4tU43tH+g@mail.gmail.com>

Dear list,

I am modeling number of annual registered battery electric vehicle (BEV)
and plug-in hybrid electric vehicle (PHEV) in 133 counties in US. I have
unbalanced panel data that some counties have four years of observations,
while some counties only have one or two years observations. I plan to use
the MCMCglmm package to estimate a bivariate log-normal Poisson mixed model:

   1. County is the random effect
   2. BEV and PHEV are two dependent variables
   3. X1 - X5 are independent variables.

model <- MCMCglmm(cbind(BEV, PHEV) ~ trait-1  + trait:X1 + trait:X2 +
> trait:X3 + trait:X4 + trait:X5,
>              random = ~ us(trait):COUNTY,  rcov = ~ us(trait):units,
>              family = rep("poisson", 2), prior = prior, nitt = 200000,
> thin = 100, burnin = 15000, verbose = FALSE,  pr = TRUE, data = data)
>

My questions is: are the code above also appropriate for my unbalanced
dataset? Thanks in advance!

Best,
-- 
Wenjian Jia, PhD student
Department of Civil and Environmental Engineering
University of Virginia

	[[alternative HTML version deleted]]


From orchidn @ending from live@com  Tue Aug 28 02:58:15 2018
From: orchidn @ending from live@com (dani)
Date: Tue, 28 Aug 2018 00:58:15 +0000
Subject: [R-sig-ME] question about a GAM model
Message-ID: <BYAPR06MB38326EA5F49F8EFB984F1D0FD60A0@BYAPR06MB3832.namprd06.prod.outlook.com>

Hi everyone,


I have a question about a GAM model where I included three non-parametric terms. I obtained the results below. can I conclude that the associations were in fact linear and run a final GLM model without including splines? To me it seems unnecessary to include splines in the final model. How should I report these results?


# Approximate significance of smooth terms:
#                 edf Ref.df Chi.sq p-value
# s(x1)      1.61   2.01   1.17   0.550
# s(x2)      1.00   1.00   0.00   0.955
# s(x3)      1.00   1.00   4.61   0.032 *

Thank you very much,
Dani





	[[alternative HTML version deleted]]


From udit@@b@n@@l17 @ending from imperi@l@@c@uk  Tue Aug 28 11:51:58 2018
From: udit@@b@n@@l17 @ending from imperi@l@@c@uk (Bansal, Udita)
Date: Tue, 28 Aug 2018 09:51:58 +0000
Subject: [R-sig-ME] question about a GAM model
Message-ID: <0193268F-C663-4A3B-B2B3-D2375D5E1207@ic.ac.uk>

Hi Dani,

I don?t know much about GAM but I know you can look at the plots for fitted model results to check if there is any curvature. You can use the following code:

par(mfrow = c(1,3))
plot(GAMmodel)

Bests
Udita

On 28/08/18, 1:58 AM, "R-sig-mixed-models on behalf of dani" <r-sig-mixed-models-bounces at r-project.org on behalf of orchidn at live.com> wrote:

    Hi everyone,
    
    
    I have a question about a GAM model where I included three non-parametric terms. I obtained the results below. can I conclude that the associations were in fact linear and run a final GLM model without including splines? To me it seems unnecessary to include splines in the final model. How should I report these results?
    
    
    # Approximate significance of smooth terms:
    #                 edf Ref.df Chi.sq p-value
    # s(x1)      1.61   2.01   1.17   0.550
    # s(x2)      1.00   1.00   0.00   0.955
    # s(x3)      1.00   1.00   4.61   0.032 *
    
    Thank you very much,
    Dani
    
    
    
    
    
    	[[alternative HTML version deleted]]
    
    _______________________________________________
    R-sig-mixed-models at r-project.org mailing list
    https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
    


From bbolker @ending from gm@il@com  Tue Aug 28 15:19:26 2018
From: bbolker @ending from gm@il@com (Ben Bolker)
Date: Tue, 28 Aug 2018 09:19:26 -0400
Subject: [R-sig-ME] question about a GAM model
In-Reply-To: <0193268F-C663-4A3B-B2B3-D2375D5E1207@ic.ac.uk>
References: <0193268F-C663-4A3B-B2B3-D2375D5E1207@ic.ac.uk>
Message-ID: <7a17f8bd-0576-0e02-c67b-1c71cc7862f1@gmail.com>



   Don't forget to run k.check() on your model to see if you specified a
large enough basis dimension  to start with ...

On 2018-08-28 05:51 AM, Bansal, Udita wrote:
> Hi Dani,
> 
> I don?t know much about GAM but I know you can look at the plots for fitted model results to check if there is any curvature. You can use the following code:
> 
> par(mfrow = c(1,3))
> plot(GAMmodel)
> 
> Bests
> Udita
> 
> On 28/08/18, 1:58 AM, "R-sig-mixed-models on behalf of dani" <r-sig-mixed-models-bounces at r-project.org on behalf of orchidn at live.com> wrote:
> 
>     Hi everyone,
>     
>     
>     I have a question about a GAM model where I included three non-parametric terms. I obtained the results below. can I conclude that the associations were in fact linear and run a final GLM model without including splines? To me it seems unnecessary to include splines in the final model. How should I report these results?
>     
>     
>     # Approximate significance of smooth terms:
>     #                 edf Ref.df Chi.sq p-value
>     # s(x1)      1.61   2.01   1.17   0.550
>     # s(x2)      1.00   1.00   0.00   0.955
>     # s(x3)      1.00   1.00   4.61   0.032 *
>     
>     Thank you very much,
>     Dani
>     
>     
>     
>     
>     
>     	[[alternative HTML version deleted]]
>     
>     _______________________________________________
>     R-sig-mixed-models at r-project.org mailing list
>     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From phillip@@ld@y @ending from mpi@nl  Tue Aug 28 16:08:49 2018
From: phillip@@ld@y @ending from mpi@nl (Phillip Alday)
Date: Tue, 28 Aug 2018 16:08:49 +0200
Subject: [R-sig-ME] How to use all the cores while running glmer on a
 piecewise exponential survival with
In-Reply-To: <e60182d0-d75d-3b3f-610a-62db68c1a8b0@gmail.com>
References: <CAAoDtR98dC5fXDrYrhMmYwKsXqhT=_7H0NeO=cViQ6S+2nxC4g@mail.gmail.com>
 <BY2PR0501MB200817E0973BE5476543C372CA370@BY2PR0501MB2008.namprd05.prod.outlook.com>
 <CAAoDtR_hGCf+_25S9MkWxhfnuFGJiwia7sE8Gt5Go6LWkGZpWw@mail.gmail.com>
 <BY2PR0501MB2008EFE8A6394D50BAC97F6CCA370@BY2PR0501MB2008.namprd05.prod.outlook.com>
 <e60182d0-d75d-3b3f-610a-62db68c1a8b0@gmail.com>
Message-ID: <5570d8ca-4137-1c73-f605-d5b45c975059@mpi.nl>

I'm late to the party on this one, but I've been playing around with
this issue by (ab)using brms::brm_multiple() :

library("tidyverse")
library("brms")

rstan::rstan_options(autowrite=TRUE)
options(mc.cores=2)

dat.split <- dat %>%
    select(A,B,C,G) %>%
    group_by(G) %>%
    mutate(slice=sample.int(100,n(),replace=TRUE)) %>%
    ungroup()

dat.split <- split(dat.split, dat.split$slice)

dat.model.split <- brm_multiple(log10(A) ~ 1 + scale(B) * scale(C) + (1|G),
                               algorithm="sampling",
                               prior=set_prior("normal(0,2)",class="b"),
                               save_all_pars=TRUE,
                               sample_prior = TRUE,
                               family=student(),
                               chains=2,
                               iter=2e3,
                               data=dat.split)


This fits models on different subsets and then combines the posteriors.
Maybe a better Bayesian than me can point out any flaws or potential
pitfalls in this approach.

If you use a slightly less automated approach for the split and combine,
you can run multiple chains for multiple models in parallel. For the
automated split-combine with brm_multiple, each model is run in
sequence, although the chains within a given model are run in parallel
if mc.cores > 1.

Best,
Phillip

On 08/23/2018 10:08 PM, Ben Bolker wrote:
> 
>   Harold, what do you think of my suggestion (partition problem into
> multiple conditionally independent subsets, evaluate separate deviances
> on workers, run top-level optimization on a central 'master' processor)?
>  Am I missing something (except that some problems can't easily be
> partitioned that way?)
> 
>   FWIW I think Doug Bates has pointed out in the past that for simple
> (e.g. nested, not crossed) designs, the whole problem can be
> reformulated in a more efficient way (of course I can't dig up that
> e-mail ...).  lme4's strength is that it can handle the complex cases,
> and so far no-one has had the time/energy/interest/capability of
> implementing any of Doug's "special case" strategies, at least in lme4
> -- may be done elsewhere in R, or in Doug's MixedModels.jl ...
> 
>   cheers
>    Ben Bolker
> 
> 
> On 2018-08-23 03:32 PM, Doran, Harold wrote:
>> Running the model on multiple cores won?t work because lmer isn?t written that way. One idea I?ve toyed with is start with a small-ish sample and get results. Plug those in as starting values to your next run which uses larger sample, but takes fewer steps because you?re closer to the max. Repeat until the difference in the param estimates from prior run is less than some tolerance.
>>
>>
>> From: Adam Mills-Campisi <adammillscampisi at gmail.com>
>> Sent: Thursday, August 23, 2018 3:25 PM
>> To: Doran, Harold <HDoran at air.org>
>> Cc: r-sig-mixed-models at r-project.org
>> Subject: Re: [R-sig-ME] How to use all the cores while running glmer on a piecewise exponential survival with
>>
>> That's the plan, the real question is how big should the samples be. The faster we can estimate the model, the bigger the sample can be. If I can run the model on multiple cores that would significantly increase the sample size.
>>
>> On Thu, Aug 23, 2018 at 12:23 PM Doran, Harold <HDoran at air.org<mailto:HDoran at air.org>> wrote:
>> One idea, though, is you can take samples from your very large data set and estimate models on the samples very quickly.
>>
>> -----Original Message-----
>> From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org<mailto:r-sig-mixed-models-bounces at r-project.org>> On Behalf Of Adam Mills-Campisi
>> Sent: Thursday, August 23, 2018 3:18 PM
>> To: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
>> Subject: [R-sig-ME] How to use all the cores while running glmer on a piecewise exponential survival with
>>
>> I am estimating a piecewise exponential, mixed-effects, survival model with recurrent events. Each individual in the dataset gets an individual interpret (where using a PWP approach). Our full dataset has 10 million individuals, with 180 million events. I am not sure that there is any framework which can accommodate data at that size, so we are going to sample. Our final sample size largely depends on how quickly we can estimate the model, which brings me to my question: Is there a way to mutli-thread/core the model? I tried to find some kind of instruction on the web and the best lead I could find was a reference to this list serve.
>> Any help would be greatly appreciated.
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>> 	[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From M@@rten@Jung @ending from m@ilbox@tu-dre@den@de  Wed Aug 29 11:21:33 2018
From: M@@rten@Jung @ending from m@ilbox@tu-dre@den@de (Maarten Jung)
Date: Wed, 29 Aug 2018 11:21:33 +0200
Subject: [R-sig-ME] Removing random intercepts before random slopes
Message-ID: <CAHr4Dyd=7BEHiwQFGaB_C4MNmCsnOTgdZu7htyrKRPbg1qA=Qw@mail.gmail.com>

Dear list,

Does it make sense to remove random intercepts before one removes
random slopes (regarding the same grouping factor)?

Barr et al. (2013, [1]) suggest that a model "missing within-unit
random intercepts is preferable to one missing the critical random
slopes" (p. 276).
However, I wonder whether this procedure does make sense from a
conceptual perspective and whether it is reconcilable with the
principal of marginality?

And, is there any difference between LMMs with categorical and LMMs
with continuous predictors regarding this?

Best regards,
Maarten

[1] https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3881361/


From phillip@@ld@y @ending from mpi@nl  Wed Aug 29 12:41:10 2018
From: phillip@@ld@y @ending from mpi@nl (Phillip Alday)
Date: Wed, 29 Aug 2018 12:41:10 +0200
Subject: [R-sig-ME] Removing random intercepts before random slopes
In-Reply-To: <CAHr4Dyd=7BEHiwQFGaB_C4MNmCsnOTgdZu7htyrKRPbg1qA=Qw@mail.gmail.com>
References: <CAHr4Dyd=7BEHiwQFGaB_C4MNmCsnOTgdZu7htyrKRPbg1qA=Qw@mail.gmail.com>
Message-ID: <e0e3c61d-43a5-1d28-492c-46b7ba3821ee@mpi.nl>

Focusing on just the last part of your question:

> And, is there any difference between LMMs with categorical and LMMs
> with continuous predictors regarding this?

Absolutely! Consider the trivial case of only one categorical predictor
with dummy coding and no continuous predictors in a fixed-effect model.

Then ~ 0 + cat.pred  and ~ 1 + cat.pred produce identical models in some
sense, but in the former each level of the predictor is estimated as an
"absolute" value, while in the latter, one predictor is coded as the
intercept and estimated as an "absolute" value, while the other levels
are coded as offsets from that value.

For a really interesting example, try this:

data(Oats,package="nlme")
summary(lm(yield ~ 1 + Variety,Oats))
summary(lm(yield ~ 0 + Variety,Oats))

Note that the residual error is identical, but all of the summary
statistics -- R2, F -- are different.

Best,
Phillip

On 08/29/2018 11:21 AM, Maarten Jung wrote:
> Dear list,
> 
> Does it make sense to remove random intercepts before one removes
> random slopes (regarding the same grouping factor)?
> 
> Barr et al. (2013, [1]) suggest that a model "missing within-unit
> random intercepts is preferable to one missing the critical random
> slopes" (p. 276).
> However, I wonder whether this procedure does make sense from a
> conceptual perspective and whether it is reconcilable with the
> principal of marginality?
> 
> And, is there any difference between LMMs with categorical and LMMs
> with continuous predictors regarding this?
> 
> Best regards,
> Maarten
> 
> [1] https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3881361/
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From M@@rten@Jung @ending from m@ilbox@tu-dre@den@de  Wed Aug 29 14:07:47 2018
From: M@@rten@Jung @ending from m@ilbox@tu-dre@den@de (Maarten Jung)
Date: Wed, 29 Aug 2018 14:07:47 +0200
Subject: [R-sig-ME] Removing random intercepts before random slopes
In-Reply-To: <e0e3c61d-43a5-1d28-492c-46b7ba3821ee@mpi.nl>
References: <CAHr4Dyd=7BEHiwQFGaB_C4MNmCsnOTgdZu7htyrKRPbg1qA=Qw@mail.gmail.com>
 <e0e3c61d-43a5-1d28-492c-46b7ba3821ee@mpi.nl>
Message-ID: <CAHr4DydLNEAekQTyuCddp1TEWa3LKsh6Tg64ffmFPkHD4iL1Eg@mail.gmail.com>

On Wed, Aug 29, 2018 at 12:41 PM Phillip Alday <phillip.alday at mpi.nl> wrote:
>
> Focusing on just the last part of your question:
>
> > And, is there any difference between LMMs with categorical and LMMs
> > with continuous predictors regarding this?
>
> Absolutely! Consider the trivial case of only one categorical predictor
> with dummy coding and no continuous predictors in a fixed-effect model.
>
> Then ~ 0 + cat.pred  and ~ 1 + cat.pred produce identical models in some
> sense, but in the former each level of the predictor is estimated as an
> "absolute" value, while in the latter, one predictor is coded as the
> intercept and estimated as an "absolute" value, while the other levels
> are coded as offsets from that value.
>
> For a really interesting example, try this:
>
> data(Oats,package="nlme")
> summary(lm(yield ~ 1 + Variety,Oats))
> summary(lm(yield ~ 0 + Variety,Oats))
>
> Note that the residual error is identical, but all of the summary
> statistics -- R2, F -- are different.

Sorry, I just realized that I didn't make clear what I was talking about.
I know that  ~ 0 + cat.pred and ~ 1 + cat.pred in the fixed effects part
are just reparameterizations of the same model.
As I'm working with afex::lmer_alt() which converts categorical predictors
to numeric covariates (via model.matrix()) per default, I was talking about
removing random intercepts before removing random slopes in such a model,
especially one without correlation parameters [e.g. m1], and whether this
is conceptually different from removing random intercepts before removing
random slopes in a LMM with continuous predictors.
I. e., I would like to know if it makes sense in this case vs. doesn't make
sense in this case but does for continuous predictors vs. does never make
sense.

# here  c1 and c2 represent the two contrasts/numeric covariates defined
for the three levels of a categorical predictor
m1 <- y ~ 1 + c1 + c2 + (1 + c1 + c2 ||  cat.pred)

Best,
Maarten

	[[alternative HTML version deleted]]


From M@@rten@Jung @ending from m@ilbox@tu-dre@den@de  Wed Aug 29 14:13:13 2018
From: M@@rten@Jung @ending from m@ilbox@tu-dre@den@de (Maarten Jung)
Date: Wed, 29 Aug 2018 14:13:13 +0200
Subject: [R-sig-ME] Removing random intercepts before random slopes
In-Reply-To: <CAHr4DydLNEAekQTyuCddp1TEWa3LKsh6Tg64ffmFPkHD4iL1Eg@mail.gmail.com>
References: <CAHr4Dyd=7BEHiwQFGaB_C4MNmCsnOTgdZu7htyrKRPbg1qA=Qw@mail.gmail.com>
 <e0e3c61d-43a5-1d28-492c-46b7ba3821ee@mpi.nl>
 <CAHr4DydLNEAekQTyuCddp1TEWa3LKsh6Tg64ffmFPkHD4iL1Eg@mail.gmail.com>
Message-ID: <CAHr4DyeRZJ5v4WVjJwO8j-F1nNMq8bmstxXwsx2BXr3+-9KMpQ@mail.gmail.com>

Sorry, hit the send button too fast:

# here  c1 and c2 represent the two contrasts/numeric covariates defined
for the three levels of a categorical predictor
m1 <- y ~ 1 + c1 + c2 + (1 + c1 + c2 || group)

On Wed, Aug 29, 2018 at 2:07 PM Maarten Jung <
Maarten.Jung at mailbox.tu-dresden.de> wrote:

>
> On Wed, Aug 29, 2018 at 12:41 PM Phillip Alday <phillip.alday at mpi.nl>
> wrote:
> >
> > Focusing on just the last part of your question:
> >
> > > And, is there any difference between LMMs with categorical and LMMs
> > > with continuous predictors regarding this?
> >
> > Absolutely! Consider the trivial case of only one categorical predictor
> > with dummy coding and no continuous predictors in a fixed-effect model.
> >
> > Then ~ 0 + cat.pred  and ~ 1 + cat.pred produce identical models in some
> > sense, but in the former each level of the predictor is estimated as an
> > "absolute" value, while in the latter, one predictor is coded as the
> > intercept and estimated as an "absolute" value, while the other levels
> > are coded as offsets from that value.
> >
> > For a really interesting example, try this:
> >
> > data(Oats,package="nlme")
> > summary(lm(yield ~ 1 + Variety,Oats))
> > summary(lm(yield ~ 0 + Variety,Oats))
> >
> > Note that the residual error is identical, but all of the summary
> > statistics -- R2, F -- are different.
>
> Sorry, I just realized that I didn't make clear what I was talking about.
> I know that  ~ 0 + cat.pred and ~ 1 + cat.pred in the fixed effects part
> are just reparameterizations of the same model.
> As I'm working with afex::lmer_alt() which converts categorical
> predictors to numeric covariates (via model.matrix()) per default, I was
> talking about removing random intercepts before removing random slopes in
> such a model, especially one without correlation parameters [e.g. m1],
> and whether this is conceptually different from removing random
> intercepts before removing random slopes in a LMM with continuous
> predictors.
> I. e., I would like to know if it makes sense in this case vs. doesn't
> make sense in this case but does for continuous predictors vs. does never
> make sense.
>
> # here  c1 and c2 represent the two contrasts/numeric covariates defined
> for the three levels of a categorical predictor
> m1 <- y ~ 1 + c1 + c2 + (1 + c1 + c2 ||  cat.pred)
>
> Best,
> Maarten
>

	[[alternative HTML version deleted]]


From j@ke@@@we@tf@ll @ending from gm@il@com  Wed Aug 29 15:34:15 2018
From: j@ke@@@we@tf@ll @ending from gm@il@com (Jake Westfall)
Date: Wed, 29 Aug 2018 08:34:15 -0500
Subject: [R-sig-ME] Removing random intercepts before random slopes
In-Reply-To: <CAHr4DyeRZJ5v4WVjJwO8j-F1nNMq8bmstxXwsx2BXr3+-9KMpQ@mail.gmail.com>
References: <CAHr4Dyd=7BEHiwQFGaB_C4MNmCsnOTgdZu7htyrKRPbg1qA=Qw@mail.gmail.com>
 <e0e3c61d-43a5-1d28-492c-46b7ba3821ee@mpi.nl>
 <CAHr4DydLNEAekQTyuCddp1TEWa3LKsh6Tg64ffmFPkHD4iL1Eg@mail.gmail.com>
 <CAHr4DyeRZJ5v4WVjJwO8j-F1nNMq8bmstxXwsx2BXr3+-9KMpQ@mail.gmail.com>
Message-ID: <CAE9_Wg70jEd0cJdp-ebhwTe=qf1LGsBLDtLFz3TyKhRw7axayw@mail.gmail.com>

Maarten,

Regarding whether it makes conceptual sense to have a model with random
slopes but not random intercepts. I believe the context of this
recommendation is an experiment where the goal is to do a confirmatory test
of whether the associated fixed slope = 0. In that case, as long as the
experiment is fairly balanced, the random slope variance appears in (and
expands) the standard error for the fixed effect of interest, while the
random intercept variance has little or no effect on the standard error
(again, assuming the experiment is close to balanced). So we'd like to keep
the random slopes in the model if possible so that the type 1 error rate
won't exceed the nominal alpha level by too much. But keeping the random
intercepts in the model is less important because it should have little or
no impact on the type 1 error rate either way, albeit it would be
conceptually strange to have random slopes but not random intercepts. So,
anyway, that's the line of thinking as I understand it, and I don't think
it's crazy.

Jake

On Wed, Aug 29, 2018 at 7:18 AM Maarten Jung <
Maarten.Jung at mailbox.tu-dresden.de> wrote:

> Sorry, hit the send button too fast:
>
> # here  c1 and c2 represent the two contrasts/numeric covariates defined
> for the three levels of a categorical predictor
> m1 <- y ~ 1 + c1 + c2 + (1 + c1 + c2 || group)
>
> On Wed, Aug 29, 2018 at 2:07 PM Maarten Jung <
> Maarten.Jung at mailbox.tu-dresden.de> wrote:
>
> >
> > On Wed, Aug 29, 2018 at 12:41 PM Phillip Alday <phillip.alday at mpi.nl>
> > wrote:
> > >
> > > Focusing on just the last part of your question:
> > >
> > > > And, is there any difference between LMMs with categorical and LMMs
> > > > with continuous predictors regarding this?
> > >
> > > Absolutely! Consider the trivial case of only one categorical predictor
> > > with dummy coding and no continuous predictors in a fixed-effect model.
> > >
> > > Then ~ 0 + cat.pred  and ~ 1 + cat.pred produce identical models in
> some
> > > sense, but in the former each level of the predictor is estimated as an
> > > "absolute" value, while in the latter, one predictor is coded as the
> > > intercept and estimated as an "absolute" value, while the other levels
> > > are coded as offsets from that value.
> > >
> > > For a really interesting example, try this:
> > >
> > > data(Oats,package="nlme")
> > > summary(lm(yield ~ 1 + Variety,Oats))
> > > summary(lm(yield ~ 0 + Variety,Oats))
> > >
> > > Note that the residual error is identical, but all of the summary
> > > statistics -- R2, F -- are different.
> >
> > Sorry, I just realized that I didn't make clear what I was talking about.
> > I know that  ~ 0 + cat.pred and ~ 1 + cat.pred in the fixed effects part
> > are just reparameterizations of the same model.
> > As I'm working with afex::lmer_alt() which converts categorical
> > predictors to numeric covariates (via model.matrix()) per default, I was
> > talking about removing random intercepts before removing random slopes in
> > such a model, especially one without correlation parameters [e.g. m1],
> > and whether this is conceptually different from removing random
> > intercepts before removing random slopes in a LMM with continuous
> > predictors.
> > I. e., I would like to know if it makes sense in this case vs. doesn't
> > make sense in this case but does for continuous predictors vs. does never
> > make sense.
> >
> > # here  c1 and c2 represent the two contrasts/numeric covariates defined
> > for the three levels of a categorical predictor
> > m1 <- y ~ 1 + c1 + c2 + (1 + c1 + c2 ||  cat.pred)
> >
> > Best,
> > Maarten
> >
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From p@blo@inch@u@ti@f @ending from gm@il@com  Wed Aug 29 15:34:53 2018
From: p@blo@inch@u@ti@f @ending from gm@il@com (Pablo Inchausti)
Date: Wed, 29 Aug 2018 10:34:53 -0300
Subject: [R-sig-ME] parametric bootstrap with glmmTBmodel with Tweedie dist
Message-ID: <CAGdDvs2U89b1_UHs3F8qDu54JWNn19bAPAVas1W81NY+aKgJDQ@mail.gmail.com>

Dear All,
After fitting two models with Tweedie distr with glmmtmb, I need to
compared them using parametric bootstrap because these models differ in
their random effects.
mod1=glmmTMB(actmono~Resin.P.s+Total.P.s+pH.KCl.s+C.s+(1|fieldnumber)+(1|spsab),data=DF,
family=tweedie(link="log"))   has  only random intercepts
mod2=glmmTMB(actmono~Resin.P.s+Total.P.s+pH.KCl.s+C.s+(1|fieldnumber)+(Resin.P.s|spsab),data=DF,
family=tweedie(link="log")) has both random intercepts AND slopes.
As far as I understand, parametric bootstrap is the only acceptable way t
compare these two models. (I need to use Tweedie because the response
variable has many (>30%) zeros and the remaining are positive, real values)

My attempts:
1) pbmodcomp from library pbkrtest does not accept models fitted with
glmmtmb.
2) I tried comparing the logLik ratios of the two models doing:
bmod1=bootMer(mod1, FUN = function(x) as.numeric(logLik(x)), nsim = 500,
type = "parametric", use.u=F)
bmono3=bootMer(mono3, FUN = function(x) as.numeric(logLik(x)), nsim = 500,
type = "parametric", use.u=F)
lrt=as.numeric(-2*(logLik(m3.2) -logLik(m3.1))) # observed LRT
lrt.b=-2*(bm3.2$t-bm3.1$t) # distribution of  simulated LRT
quantile(lrt.b, c(0.025,0.975))
summary(lrt.b)
(if I recall correctly, I had pillaged this idea from some web post by Ben
Bolker, and it had worked well with other GLMM fitted with lme4)

I obtained the following error message:
Error in match.arg(name) :
  'arg' should be one of ?X?, ?Xzi?, ?Z?, ?Zzi?, ?Xd?, ?theta?

I looked into the help of bootMer and it only says that the first argument
should be a fitted merMod object (I believe that models fitted with glmmtmb
are of this type too).

Any help or suggestions would be appreciated.
Regards,
Pablo

	[[alternative HTML version deleted]]


From M@@rten@Jung @ending from m@ilbox@tu-dre@den@de  Wed Aug 29 17:56:28 2018
From: M@@rten@Jung @ending from m@ilbox@tu-dre@den@de (Maarten Jung)
Date: Wed, 29 Aug 2018 17:56:28 +0200
Subject: [R-sig-ME] Removing random intercepts before random slopes
In-Reply-To: <CAE9_Wg70jEd0cJdp-ebhwTe=qf1LGsBLDtLFz3TyKhRw7axayw@mail.gmail.com>
References: <CAHr4Dyd=7BEHiwQFGaB_C4MNmCsnOTgdZu7htyrKRPbg1qA=Qw@mail.gmail.com>
 <e0e3c61d-43a5-1d28-492c-46b7ba3821ee@mpi.nl>
 <CAHr4DydLNEAekQTyuCddp1TEWa3LKsh6Tg64ffmFPkHD4iL1Eg@mail.gmail.com>
 <CAHr4DyeRZJ5v4WVjJwO8j-F1nNMq8bmstxXwsx2BXr3+-9KMpQ@mail.gmail.com>
 <CAE9_Wg70jEd0cJdp-ebhwTe=qf1LGsBLDtLFz3TyKhRw7axayw@mail.gmail.com>
Message-ID: <CAHr4DydEGPB+txgGMpwUP8zD2yiU5TB5kZ_fTAMr2RTTc0pcgA@mail.gmail.com>

Dear Jake,

thanks for your answer, makes sense to me. I think removing the random
intercepts should mostly increase the residual error and thus even
increase the SEs for the fixed effects. Is this correct?

Why exactely would it be conceptually strange to have random slopes but not
random intercepts?
Because intercepts often represent some kind of baseline and, say subjects,
will probably have different baselines (and thus a corresponding variance
component estimated as > 0) if their slopes (i.e. effects) vary, or is
there any other statistical reason why most people remove the random slopes
first?

Best,
Maarten

On Wed, Aug 29, 2018 at 3:34 PM Jake Westfall <jake.a.westfall at gmail.com>
wrote:

> Maarten,
>
> Regarding whether it makes conceptual sense to have a model with random
> slopes but not random intercepts. I believe the context of this
> recommendation is an experiment where the goal is to do a confirmatory test
> of whether the associated fixed slope = 0. In that case, as long as the
> experiment is fairly balanced, the random slope variance appears in (and
> expands) the standard error for the fixed effect of interest, while the
> random intercept variance has little or no effect on the standard error
> (again, assuming the experiment is close to balanced). So we'd like to keep
> the random slopes in the model if possible so that the type 1 error rate
> won't exceed the nominal alpha level by too much. But keeping the random
> intercepts in the model is less important because it should have little or
> no impact on the type 1 error rate either way, albeit it would be
> conceptually strange to have random slopes but not random intercepts. So,
> anyway, that's the line of thinking as I understand it, and I don't think
> it's crazy.
>
> Jake
>
> On Wed, Aug 29, 2018 at 7:18 AM Maarten Jung <
> Maarten.Jung at mailbox.tu-dresden.de> wrote:
>
> > Sorry, hit the send button too fast:
> >
> > # here  c1 and c2 represent the two contrasts/numeric covariates defined
> > for the three levels of a categorical predictor
> > m1 <- y ~ 1 + c1 + c2 + (1 + c1 + c2 || group)
> >
> > On Wed, Aug 29, 2018 at 2:07 PM Maarten Jung <
> > Maarten.Jung at mailbox.tu-dresden.de> wrote:
> >
> > >
> > > On Wed, Aug 29, 2018 at 12:41 PM Phillip Alday <phillip.alday at mpi.nl>
> > > wrote:
> > > >
> > > > Focusing on just the last part of your question:
> > > >
> > > > > And, is there any difference between LMMs with categorical and LMMs
> > > > > with continuous predictors regarding this?
> > > >
> > > > Absolutely! Consider the trivial case of only one categorical
> predictor
> > > > with dummy coding and no continuous predictors in a fixed-effect
> model.
> > > >
> > > > Then ~ 0 + cat.pred  and ~ 1 + cat.pred produce identical models in
> > some
> > > > sense, but in the former each level of the predictor is estimated as
> an
> > > > "absolute" value, while in the latter, one predictor is coded as the
> > > > intercept and estimated as an "absolute" value, while the other
> levels
> > > > are coded as offsets from that value.
> > > >
> > > > For a really interesting example, try this:
> > > >
> > > > data(Oats,package="nlme")
> > > > summary(lm(yield ~ 1 + Variety,Oats))
> > > > summary(lm(yield ~ 0 + Variety,Oats))
> > > >
> > > > Note that the residual error is identical, but all of the summary
> > > > statistics -- R2, F -- are different.
> > >
> > > Sorry, I just realized that I didn't make clear what I was talking
> about.
> > > I know that  ~ 0 + cat.pred and ~ 1 + cat.pred in the fixed effects
> part
> > > are just reparameterizations of the same model.
> > > As I'm working with afex::lmer_alt() which converts categorical
> > > predictors to numeric covariates (via model.matrix()) per default, I
> was
> > > talking about removing random intercepts before removing random slopes
> in
> > > such a model, especially one without correlation parameters [e.g. m1],
> > > and whether this is conceptually different from removing random
> > > intercepts before removing random slopes in a LMM with continuous
> > > predictors.
> > > I. e., I would like to know if it makes sense in this case vs. doesn't
> > > make sense in this case but does for continuous predictors vs. does
> never
> > > make sense.
> > >
> > > # here  c1 and c2 represent the two contrasts/numeric covariates
> defined
> > > for the three levels of a categorical predictor
> > > m1 <- y ~ 1 + c1 + c2 + (1 + c1 + c2 ||  cat.pred)
> > >
> > > Best,
> > > Maarten
> > >
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From @tgrie@ @ending from gm@il@com  Wed Aug 29 18:31:00 2018
From: @tgrie@ @ending from gm@il@com (Stefan Th. Gries)
Date: Wed, 29 Aug 2018 18:31:00 +0200
Subject: [R-sig-ME] Order of terms for random slopes
Message-ID: <CAFrBz2=TzgCaNyxaNeksWP0_15mkie0SnfvjtJr7meV0M6jBkA@mail.gmail.com>

Hi all

I have a question about how the ordering of variable names in the
random effects structure of an lmer model leads to different results.
These are the data:

###############
x <- structure(list(OVERLAParcsine = c(0.232077682862713, 0.656060590924923,
0.546850950695944, 0.668742703202372, 0.631058840778021, 0.433445320069886,
0.315193032440724, 0.656060590924923, 0.389796296474261, 0.455598673395823,
0.500654712404588, 0.477995198518952, 0.304692654015398, 0.631058840778021,
0.489290778014116, 0.694498265626556, 0.656060590924923, 0.466765339047296,
0.411516846067488, 0.582364237868743, 0.33630357515398, 0.36826789343664,
0.489290778014116, 0.582364237868743, 0.283794109208328, 0.631058840778021,
0.33630357515398, 0.606505855213087, 0.512089752934148, 0.150568272776686,
0.273393031467473, 0.466765339047296, 0.160690652951911, 0.120289882394788,
0.558600565342801, 0.400631592701372, 0.273393031467473, 0.72081876087009,
0.444492776935819, 0.681553211563117, 0.546850950695944, 0.523598775598299,
0.273393031467473, 0.694498265626556, 0.294226837748982, 0.500654712404588,
0.411516846067488, 0.618728690672251), NAME = structure(c(1L,
2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 1L, 2L, 3L, 4L,
5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 1L, 2L, 3L, 4L, 5L, 6L, 7L,
8L, 9L, 10L, 11L, 12L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L,
11L, 12L), .Label = c("Anne", "Aran", "Becky", "Carl", "Dominic",
"Gail", "Joel", "John", "Liz", "Nicole", "Ruth", "Warren"), class = "factor"),
    PERSON = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L), .Label = c("caretaker",
    "child"), class = "factor"), PHASE = c(1L, 1L, 1L, 1L, 1L,
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
    2L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
    1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L)), class =
"data.frame", row.names = c(NA, -48L))
###############

With the following order of variables in the random-effects structure,
I get convergence warnings,

###############
summary(m1a <- lme4::lmer(OVERLAParcsine ~ 1+PERSON*PHASE +
(1+PERSON+PHASE|NAME), data=x), correlation=F) # warning
   logLik(m1a) # 31.89056
###############

but not with this order:

###############
summary(m1b <- lme4::lmer(OVERLAParcsine ~ 1+PERSON*PHASE +
(1+PHASE+PERSON|NAME), data=x), correlation=F) # fine
   logLik(m1b) # 31.89128
###############

Why does the order of the random effects matter when PHASE is still
considered numeric? Thanks for any input you may have,
STG


From bbolker @ending from gm@il@com  Wed Aug 29 19:15:57 2018
From: bbolker @ending from gm@il@com (Ben Bolker)
Date: Wed, 29 Aug 2018 13:15:57 -0400
Subject: [R-sig-ME] Order of terms for random slopes
In-Reply-To: <CAFrBz2=TzgCaNyxaNeksWP0_15mkie0SnfvjtJr7meV0M6jBkA@mail.gmail.com>
References: <CAFrBz2=TzgCaNyxaNeksWP0_15mkie0SnfvjtJr7meV0M6jBkA@mail.gmail.com>
Message-ID: <d3f1b48f-76b2-a520-49d7-530bef4df569@gmail.com>


  Thanks. This is a known issue: https://github.com/lme4/lme4/issues/449

  At the risk of sounding like a stuffy old statistical fart:

  - yes, lme4 *should* give an identical fit either way
  - it's not terribly surprising that a model with 11 parameters fitted
to 48 observations is numerically unstable ...
  - there don't seem to be any _substantive_ differences in the estimate ...

  cheers
   Ben Bolker

https://github.com/lme4/lme4/issues/449

On 2018-08-29 12:31 PM, Stefan Th. Gries wrote:
> Hi all
> 
> I have a question about how the ordering of variable names in the
> random effects structure of an lmer model leads to different results.
> These are the data:
> 
> ###############
> x <- structure(list(OVERLAParcsine = c(0.232077682862713, 0.656060590924923,
> 0.546850950695944, 0.668742703202372, 0.631058840778021, 0.433445320069886,
> 0.315193032440724, 0.656060590924923, 0.389796296474261, 0.455598673395823,
> 0.500654712404588, 0.477995198518952, 0.304692654015398, 0.631058840778021,
> 0.489290778014116, 0.694498265626556, 0.656060590924923, 0.466765339047296,
> 0.411516846067488, 0.582364237868743, 0.33630357515398, 0.36826789343664,
> 0.489290778014116, 0.582364237868743, 0.283794109208328, 0.631058840778021,
> 0.33630357515398, 0.606505855213087, 0.512089752934148, 0.150568272776686,
> 0.273393031467473, 0.466765339047296, 0.160690652951911, 0.120289882394788,
> 0.558600565342801, 0.400631592701372, 0.273393031467473, 0.72081876087009,
> 0.444492776935819, 0.681553211563117, 0.546850950695944, 0.523598775598299,
> 0.273393031467473, 0.694498265626556, 0.294226837748982, 0.500654712404588,
> 0.411516846067488, 0.618728690672251), NAME = structure(c(1L,
> 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 1L, 2L, 3L, 4L,
> 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 1L, 2L, 3L, 4L, 5L, 6L, 7L,
> 8L, 9L, 10L, 11L, 12L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L,
> 11L, 12L), .Label = c("Anne", "Aran", "Becky", "Carl", "Dominic",
> "Gail", "Joel", "John", "Liz", "Nicole", "Ruth", "Warren"), class = "factor"),
>     PERSON = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L), .Label = c("caretaker",
>     "child"), class = "factor"), PHASE = c(1L, 1L, 1L, 1L, 1L,
>     1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>     2L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>     1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L)), class =
> "data.frame", row.names = c(NA, -48L))
> ###############
> 
> With the following order of variables in the random-effects structure,
> I get convergence warnings,
> 
> ###############
> summary(m1a <- lme4::lmer(OVERLAParcsine ~ 1+PERSON*PHASE +
> (1+PERSON+PHASE|NAME), data=x), correlation=F) # warning
>    logLik(m1a) # 31.89056
> ###############
> 
> but not with this order:
> 
> ###############
> summary(m1b <- lme4::lmer(OVERLAParcsine ~ 1+PERSON*PHASE +
> (1+PHASE+PERSON|NAME), data=x), correlation=F) # fine
>    logLik(m1b) # 31.89128
> ###############
> 
> Why does the order of the random effects matter when PHASE is still
> considered numeric? Thanks for any input you may have,
> STG
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From orchidn @ending from live@com  Wed Aug 29 19:38:44 2018
From: orchidn @ending from live@com (dani)
Date: Wed, 29 Aug 2018 17:38:44 +0000
Subject: [R-sig-ME] question about a GAM model
In-Reply-To: <7a17f8bd-0576-0e02-c67b-1c71cc7862f1@gmail.com>
References: <0193268F-C663-4A3B-B2B3-D2375D5E1207@ic.ac.uk>,
 <7a17f8bd-0576-0e02-c67b-1c71cc7862f1@gmail.com>
Message-ID: <BYAPR06MB38321CD8470AE34E57716661D6090@BYAPR06MB3832.namprd06.prod.outlook.com>

Thank you very much Udita and Dr. Bolker for your responses.

It is still not clear to me how should I proceed. Would anyone else be able help with this issue,?

Best regards,

Dani


Sent from Outlook<http://aka.ms/weboutlook>


________________________________
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of Ben Bolker <bbolker at gmail.com>
Sent: Tuesday, August 28, 2018 6:19 AM
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] question about a GAM model



   Don't forget to run k.check() on your model to see if you specified a
large enough basis dimension  to start with ...

On 2018-08-28 05:51 AM, Bansal, Udita wrote:
> Hi Dani,
>
> I don?t know much about GAM but I know you can look at the plots for fitted model results to check if there is any curvature. You can use the following code:
>
> par(mfrow = c(1,3))
> plot(GAMmodel)
>
> Bests
> Udita
>
> On 28/08/18, 1:58 AM, "R-sig-mixed-models on behalf of dani" <r-sig-mixed-models-bounces at r-project.org on behalf of orchidn at live.com> wrote:
>
>     Hi everyone,
>
>
>     I have a question about a GAM model where I included three non-parametric terms. I obtained the results below. can I conclude that the associations were in fact linear and run a final GLM model without including splines? To me it seems unnecessary to include splines in the final model. How should I report these results?
>
>
>     # Approximate significance of smooth terms:
>     #                 edf Ref.df Chi.sq p-value
>     # s(x1)      1.61   2.01   1.17   0.550
>     # s(x2)      1.00   1.00   0.00   0.955
>     # s(x3)      1.00   1.00   4.61   0.032 *
>
>     Thank you very much,
>     Dani
>
>
>
>
>
>        [[alternative HTML version deleted]]
>
>     _______________________________________________
>     R-sig-mixed-models at r-project.org mailing list
>     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From orchidn @ending from live@com  Wed Aug 29 19:46:20 2018
From: orchidn @ending from live@com (dani)
Date: Wed, 29 Aug 2018 17:46:20 +0000
Subject: [R-sig-ME] GAM model - standardized regression coefficients
In-Reply-To: <7a17f8bd-0576-0e02-c67b-1c71cc7862f1@gmail.com>
References: <0193268F-C663-4A3B-B2B3-D2375D5E1207@ic.ac.uk>,
 <7a17f8bd-0576-0e02-c67b-1c71cc7862f1@gmail.com>
Message-ID: <BYAPR06MB3832C927FBFE4F1E60463048D6090@BYAPR06MB3832.namprd06.prod.outlook.com>

Hello everyone,


I was wondering if anyone can help me calculate standardized regression coefficients from a GAM model.

I have some dummy and some continuous covariates in my GAM model. I know I could standardize only the continuous covariates and re-run the model to get the standardized coefficients. Can anyone help with some R code to create the standardized coefficients after obtaining a GAM model based on unstandardized coefficients?


Also, on a separate note, what do I do with the dummy covariates - should I just include them as they are in the model with standardized variables? I do not see how I can standardize dummy variables.


Thank you!

Best,

Dani

	[[alternative HTML version deleted]]


From @tgrie@ @ending from gm@il@com  Wed Aug 29 20:51:46 2018
From: @tgrie@ @ending from gm@il@com (Stefan Th. Gries)
Date: Wed, 29 Aug 2018 20:51:46 +0200
Subject: [R-sig-ME] Order of terms for random slopes
In-Reply-To: <CAFrBz2=TzgCaNyxaNeksWP0_15mkie0SnfvjtJr7meV0M6jBkA@mail.gmail.com>
References: <CAFrBz2=TzgCaNyxaNeksWP0_15mkie0SnfvjtJr7meV0M6jBkA@mail.gmail.com>
Message-ID: <CAFrBz2=F=qeP1BYey9A9Ytbmq59LCD3LAK6EO_16nbgDoffOrQ@mail.gmail.com>

> Thanks. This is a known issue: https://github.com/lme4/lme4/issues/449
Ohh, ok, I had googled a bit on 'order of terms', 'random effects'
etc. but hadn't come across this, sorry.

> - it's not terribly surprising that a model with 11 parameters fitted to 48 observations is numerically unstable ...
Absolutely, the example is from a workshop and was used only for
didactic purposes, and ...

> there don't seem to be any _substantive_ differences in the estimate ...
... yes, we only wanted to make sure there wasn't something
superobvious but important we had missed.

Thanks for the quick feedback!


From high@t@t @ending from high@t@t@com  Wed Aug 29 21:30:59 2018
From: high@t@t @ending from high@t@t@com (Highland Statistics Ltd)
Date: Wed, 29 Aug 2018 20:30:59 +0100
Subject: [R-sig-ME] question about a GAM model (dani)
In-Reply-To: <mailman.16859.3748.1535564333.1179.r-sig-mixed-models@r-project.org>
References: <mailman.16859.3748.1535564333.1179.r-sig-mixed-models@r-project.org>
Message-ID: <84716e58-47ad-4097-12bf-56941046caf4@highstat.com>




------------------------------

Message: 4
Date: Wed, 29 Aug 2018 17:38:44 +0000
From: dani <orchidn at live.com>
To: Ben Bolker <bbolker at gmail.com>, "r-sig-mixed-models at r-project.org"
	<r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] question about a GAM model
Message-ID:
	<BYAPR06MB38321CD8470AE34E57716661D6090 at BYAPR06MB3832.namprd06.prod.outlook.com>
	
Content-Type: text/plain; charset="utf-8"

Thank you very much Udita and Dr. Bolker for your responses.

It is still not clear to me how should I proceed. Would anyone else be able help with this issue,?




Dani,

GAMs are useful if you use them with care, but confusing if you just apply them because someone else is doing it as well.
Perhaps you should first ask yourself the question why you are applying a GAM. Then focus on the question
whether the output makes sense.

Based on your output it seems that nothing is important (not even as parametric terms). But I am not familiar with your
data; things like collinearity can mess up the shape of smoothers. And you don't mention the size of your data set neither.

I suggest that you have a go at Wood (2017), or if I may be bold enough to self-cite....try our Beginner's Guide to GAM (2012).



Kind regards,

Alain Zuur

  




 ?Best regards,

Dani


Sent from Outlook<http://aka.ms/weboutlook>


________________________________
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of Ben Bolker <bbolker at gmail.com>
Sent: Tuesday, August 28, 2018 6:19 AM
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] question about a GAM model



    Don't forget to run k.check() on your model to see if you specified a
large enough basis dimension  to start with ...

On 2018-08-28 05:51 AM, Bansal, Udita wrote:
> Hi Dani,
>
> I don?t know much about GAM but I know you can look at the plots for fitted model results to check if there is any curvature. You can use the following code:
>
> par(mfrow = c(1,3))
> plot(GAMmodel)
>
> Bests
> Udita
>
> On 28/08/18, 1:58 AM, "R-sig-mixed-models on behalf of dani" <r-sig-mixed-models-bounces at r-project.org on behalf of orchidn at live.com> wrote:
>
>     Hi everyone,
>
>
>     I have a question about a GAM model where I included three non-parametric terms. I obtained the results below. can I conclude that the associations were in fact linear and run a final GLM model without including splines? To me it seems unnecessary to include splines in the final model. How should I report these results?
>
>
>     # Approximate significance of smooth terms:
>     #                 edf Ref.df Chi.sq p-value
>     # s(x1)      1.61   2.01   1.17   0.550
>     # s(x2)      1.00   1.00   0.00   0.955
>     # s(x3)      1.00   1.00   4.61   0.032 *
>
>     Thank you very much,
>     Dani
>
>
>
>
>
>        [[alternative HTML version deleted]]
>
>     _______________________________________________
>     R-sig-mixed-models at r-project.org mailing list
>     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]




------------------------------

Subject: Digest Footer

_______________________________________________
R-sig-mixed-models mailing list
R-sig-mixed-models at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


------------------------------

End of R-sig-mixed-models Digest, Vol 140, Issue 34
***************************************************

-- 

Dr. Alain F. Zuur
Highland Statistics Ltd.
9 St Clair Wynd
AB41 6DZ Newburgh, UK
Email: highstat at highstat.com
URL:   www.highstat.com

And:
NIOZ Royal Netherlands Institute for Sea Research,
Department of Coastal Systems, and Utrecht University,
P.O. Box 59, 1790 AB Den Burg,
Texel, The Netherlands



Author of:
1. Beginner's Guide to Spatial, Temporal and Spatial-Temporal Ecological Data Analysis with R-INLA. (2017).
2. Beginner's Guide to Zero-Inflated Models with R (2016).
3. Beginner's Guide to Data Exploration and Visualisation with R (2015).
4. Beginner's Guide to GAMM with R (2014).
5. Beginner's Guide to GLM and GLMM with R (2013).
6. Beginner's Guide to GAM with R (2012).
7. Zero Inflated Models and GLMM with R (2012).
8. A Beginner's Guide to R (2009).
9. Mixed effects models and extensions in ecology with R (2009).
10. Analysing Ecological Data (2007).


From orchidn @ending from live@com  Wed Aug 29 21:42:26 2018
From: orchidn @ending from live@com (dani)
Date: Wed, 29 Aug 2018 19:42:26 +0000
Subject: [R-sig-ME] question about a GAM model (dani)
In-Reply-To: <84716e58-47ad-4097-12bf-56941046caf4@highstat.com>
References: <mailman.16859.3748.1535564333.1179.r-sig-mixed-models@r-project.org>,
 <84716e58-47ad-4097-12bf-56941046caf4@highstat.com>
Message-ID: <BYAPR06MB3832704CFFCB5B6CF45F0BC9D6090@BYAPR06MB3832.namprd06.prod.outlook.com>

Hello Dr. Zuur,


Thank you so much for your message!


I am only using this model for educational purposes, I am just playing with a dataset of 500 observations. Variables x1 and x2 are covariates and they are both displaying non-parametric associations with the outcome. The x3 variable is the variable of interest.


I noticed the value of 1 for edfs for the covariate and for the variable of interest so I asked myself if I should not remove the parametric term and re-run the model is situations like these.


If this happens when I conduct an analysis for a study, do I present such results or I re-run the model without smoothers on x2 and x3, even though in bivariate associations with the outcome, x2 and x3 showed non-parametric associations.


Thank you so much for your suggestions, I will definitely look at the two books again, they are always useful!

Best,

Dani

<http://aka.ms/weboutlook>


________________________________
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of Highland Statistics Ltd <highstat at highstat.com>
Sent: Wednesday, August 29, 2018 12:30 PM
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] question about a GAM model (dani)




------------------------------

Message: 4
Date: Wed, 29 Aug 2018 17:38:44 +0000
From: dani <orchidn at live.com>
To: Ben Bolker <bbolker at gmail.com>, "r-sig-mixed-models at r-project.org"
        <r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] question about a GAM model
Message-ID:
        <BYAPR06MB38321CD8470AE34E57716661D6090 at BYAPR06MB3832.namprd06.prod.outlook.com>

Content-Type: text/plain; charset="utf-8"

Thank you very much Udita and Dr. Bolker for your responses.

It is still not clear to me how should I proceed. Would anyone else be able help with this issue,?




Dani,

GAMs are useful if you use them with care, but confusing if you just apply them because someone else is doing it as well.
Perhaps you should first ask yourself the question why you are applying a GAM. Then focus on the question
whether the output makes sense.

Based on your output it seems that nothing is important (not even as parametric terms). But I am not familiar with your
data; things like collinearity can mess up the shape of smoothers. And you don't mention the size of your data set neither.

I suggest that you have a go at Wood (2017), or if I may be bold enough to self-cite....try our Beginner's Guide to GAM (2012).



Kind regards,

Alain Zuur






  Best regards,

Dani


Sent from Outlook<http://aka.ms/weboutlook>


________________________________
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of Ben Bolker <bbolker at gmail.com>
Sent: Tuesday, August 28, 2018 6:19 AM
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] question about a GAM model



    Don't forget to run k.check() on your model to see if you specified a
large enough basis dimension  to start with ...

On 2018-08-28 05:51 AM, Bansal, Udita wrote:
> Hi Dani,
>
> I don?t know much about GAM but I know you can look at the plots for fitted model results to check if there is any curvature. You can use the following code:
>
> par(mfrow = c(1,3))
> plot(GAMmodel)
>
> Bests
> Udita
>
> On 28/08/18, 1:58 AM, "R-sig-mixed-models on behalf of dani" <r-sig-mixed-models-bounces at r-project.org on behalf of orchidn at live.com> wrote:
>
>     Hi everyone,
>
>
>     I have a question about a GAM model where I included three non-parametric terms. I obtained the results below. can I conclude that the associations were in fact linear and run a final GLM model without including splines? To me it seems unnecessary to include splines in the final model. How should I report these results?
>
>
>     # Approximate significance of smooth terms:
>     #                 edf Ref.df Chi.sq p-value
>     # s(x1)      1.61   2.01   1.17   0.550
>     # s(x2)      1.00   1.00   0.00   0.955
>     # s(x3)      1.00   1.00   4.61   0.032 *
>
>     Thank you very much,
>     Dani
>
>
>
>
>
>        [[alternative HTML version deleted]]
>
>     _______________________________________________
>     R-sig-mixed-models at r-project.org mailing list
>     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

        [[alternative HTML version deleted]]




------------------------------

Subject: Digest Footer

_______________________________________________
R-sig-mixed-models mailing list
R-sig-mixed-models at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


------------------------------

End of R-sig-mixed-models Digest, Vol 140, Issue 34
***************************************************

--

Dr. Alain F. Zuur
Highland Statistics Ltd.
9 St Clair Wynd
AB41 6DZ Newburgh, UK
Email: highstat at highstat.com
URL:   www.highstat.com<http://www.highstat.com>

And:
NIOZ Royal Netherlands Institute for Sea Research,
Department of Coastal Systems, and Utrecht University,
P.O. Box 59, 1790 AB Den Burg,
Texel, The Netherlands



Author of:
1. Beginner's Guide to Spatial, Temporal and Spatial-Temporal Ecological Data Analysis with R-INLA. (2017).
2. Beginner's Guide to Zero-Inflated Models with R (2016).
3. Beginner's Guide to Data Exploration and Visualisation with R (2015).
4. Beginner's Guide to GAMM with R (2014).
5. Beginner's Guide to GLM and GLMM with R (2013).
6. Beginner's Guide to GAM with R (2012).
7. Zero Inflated Models and GLMM with R (2012).
8. A Beginner's Guide to R (2009).
9. Mixed effects models and extensions in ecology with R (2009).
10. Analysing Ecological Data (2007).

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From orchidn @ending from live@com  Wed Aug 29 22:08:27 2018
From: orchidn @ending from live@com (dani)
Date: Wed, 29 Aug 2018 20:08:27 +0000
Subject: [R-sig-ME] question about a GAM model (dani)
In-Reply-To: <7a62007d-8f1b-cf57-57e6-ff2345ee5b30@highstat.com>
References: <mailman.16859.3748.1535564333.1179.r-sig-mixed-models@r-project.org>
 <84716e58-47ad-4097-12bf-56941046caf4@highstat.com>
 <BYAPR06MB3832704CFFCB5B6CF45F0BC9D6090@BYAPR06MB3832.namprd06.prod.outlook.com>,
 <7a62007d-8f1b-cf57-57e6-ff2345ee5b30@highstat.com>
Message-ID: <BYAPR06MB3832A48200F7E8FB2655CE40D6090@BYAPR06MB3832.namprd06.prod.outlook.com>

Hello Dr. Zuur,


Thank you so much for your prompt and detailed response. That is very helpful! Thank so much for your advice!


I also have another issue that is not clear to me and I could not find any information about that so far. Assuming that my model includes many parametric covariates, does it make any sense to standardize coefficients in a binomial GAM model and report both unstandardized and standardized coefficients for the parametric coefficients in a manuscript? I have never seen that in the literature, so I really do not know how to approach this issue.


Best regards,

Dani




________________________________
From: Highland Statistics Ltd <highstat at highstat.com>
Sent: Wednesday, August 29, 2018 12:55 PM
To: dani; r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] question about a GAM model (dani)



On 29/08/2018 20:42, dani wrote:

Hello Dr. Zuur,


Thank you so much for your message!


Dani,

I am only using this model for educational purposes, I am just playing with a dataset of 500 observations. Variables x1 and x2 are covariates and they are both displaying non-parametric associations with the outcome. The x3 variable is the variable of interest.


The fact that x1 vs Y and x2 vs Y show non-linear patterns is no 100% guarantee that in a model with Y ~ X1 + X2 each of them also show a non-linear pattern.


I noticed the value of 1 for edfs for the covariate and for the variable of interest so I asked myself if I should not remove the parametric term and re-run the model is situations like these.

That is a sensible line of thinking. The AIC is also your friend here.


If this happens when I conduct an analysis for a study, do I present such results or I re-run the model without smoothers on x2 and x3, even though in bivariate associations with the outcome, x2 and x3 showed non-parametric associations.

My strategy for GAMs is to only use those covariates as smoothers that make (biological) sense. You can then either start with a parametric model (e.g. a GLM) and inspect residuals, or start with a (simple) GAM and see what the edf tells you (or see how the smoothers look like) and potentially move back to a GLM (but note that link functions can also cause non-linear patterns, or remove non-linear patterns). This is the chicken or the egg.

Alain





Thank you so much for your suggestions, I will definitely look at the two books again, they are always useful!

Best,

Dani


________________________________
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org><mailto:r-sig-mixed-models-bounces at r-project.org> on behalf of Highland Statistics Ltd <highstat at highstat.com><mailto:highstat at highstat.com>
Sent: Wednesday, August 29, 2018 12:30 PM
To: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] question about a GAM model (dani)




------------------------------

Message: 4
Date: Wed, 29 Aug 2018 17:38:44 +0000
From: dani <orchidn at live.com><mailto:orchidn at live.com>
To: Ben Bolker <bbolker at gmail.com><mailto:bbolker at gmail.com>, "r-sig-mixed-models at r-project.org"<mailto:r-sig-mixed-models at r-project.org>
        <r-sig-mixed-models at r-project.org><mailto:r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] question about a GAM model
Message-ID:
        <BYAPR06MB38321CD8470AE34E57716661D6090 at BYAPR06MB3832.namprd06.prod.outlook.com><mailto:BYAPR06MB38321CD8470AE34E57716661D6090 at BYAPR06MB3832.namprd06.prod.outlook.com>

Content-Type: text/plain; charset="utf-8"

Thank you very much Udita and Dr. Bolker for your responses.

It is still not clear to me how should I proceed. Would anyone else be able help with this issue,?




Dani,

GAMs are useful if you use them with care, but confusing if you just apply them because someone else is doing it as well.
Perhaps you should first ask yourself the question why you are applying a GAM. Then focus on the question
whether the output makes sense.

Based on your output it seems that nothing is important (not even as parametric terms). But I am not familiar with your
data; things like collinearity can mess up the shape of smoothers. And you don't mention the size of your data set neither.

I suggest that you have a go at Wood (2017), or if I may be bold enough to self-cite....try our Beginner's Guide to GAM (2012).



Kind regards,

Alain Zuur






  Best regards,

Dani


Sent from Outlook<http://aka.ms/weboutlook>


________________________________
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org><mailto:r-sig-mixed-models-bounces at r-project.org> on behalf of Ben Bolker <bbolker at gmail.com><mailto:bbolker at gmail.com>
Sent: Tuesday, August 28, 2018 6:19 AM
To: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] question about a GAM model



    Don't forget to run k.check() on your model to see if you specified a
large enough basis dimension  to start with ...

On 2018-08-28 05:51 AM, Bansal, Udita wrote:
> Hi Dani,
>
> I don?t know much about GAM but I know you can look at the plots for fitted model results to check if there is any curvature. You can use the following code:
>
> par(mfrow = c(1,3))
> plot(GAMmodel)
>
> Bests
> Udita
>
> On 28/08/18, 1:58 AM, "R-sig-mixed-models on behalf of dani" <r-sig-mixed-models-bounces at r-project.org on behalf of orchidn at live.com><mailto:r-sig-mixed-models-bounces at r-project.orgonbehalfoforchidn@live.com> wrote:
>
>     Hi everyone,
>
>
>     I have a question about a GAM model where I included three non-parametric terms. I obtained the results below. can I conclude that the associations were in fact linear and run a final GLM model without including splines? To me it seems unnecessary to include splines in the final model. How should I report these results?
>
>
>     # Approximate significance of smooth terms:
>     #                 edf Ref.df Chi.sq p-value
>     # s(x1)      1.61   2.01   1.17   0.550
>     # s(x2)      1.00   1.00   0.00   0.955
>     # s(x3)      1.00   1.00   4.61   0.032 *
>
>     Thank you very much,
>     Dani
>
>
>
>
>
>        [[alternative HTML version deleted]]
>
>     _______________________________________________
>     R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
>     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

        [[alternative HTML version deleted]]




------------------------------

Subject: Digest Footer

_______________________________________________
R-sig-mixed-models mailing list
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org>
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


------------------------------

End of R-sig-mixed-models Digest, Vol 140, Issue 34
***************************************************

--

Dr. Alain F. Zuur
Highland Statistics Ltd.
9 St Clair Wynd
AB41 6DZ Newburgh, UK
Email: highstat at highstat.com<mailto:highstat at highstat.com>
URL:   www.highstat.com<http://www.highstat.com>

And:
NIOZ Royal Netherlands Institute for Sea Research,
Department of Coastal Systems, and Utrecht University,
P.O. Box 59, 1790 AB Den Burg,
Texel, The Netherlands



Author of:
1. Beginner's Guide to Spatial, Temporal and Spatial-Temporal Ecological Data Analysis with R-INLA. (2017).
2. Beginner's Guide to Zero-Inflated Models with R (2016).
3. Beginner's Guide to Data Exploration and Visualisation with R (2015).
4. Beginner's Guide to GAMM with R (2014).
5. Beginner's Guide to GLM and GLMM with R (2013).
6. Beginner's Guide to GAM with R (2012).
7. Zero Inflated Models and GLMM with R (2012).
8. A Beginner's Guide to R (2009).
9. Mixed effects models and extensions in ecology with R (2009).
10. Analysing Ecological Data (2007).

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


--

Dr. Alain F. Zuur
Highland Statistics Ltd.
9 St Clair Wynd
AB41 6DZ Newburgh, UK
Email: highstat at highstat.com<mailto:highstat at highstat.com>
URL:   www.highstat.com<http://www.highstat.com>

And:
NIOZ Royal Netherlands Institute for Sea Research,
Department of Coastal Systems, and Utrecht University,
P.O. Box 59, 1790 AB Den Burg,
Texel, The Netherlands



Author of:
1. Beginner's Guide to Spatial, Temporal and Spatial-Temporal Ecological Data Analysis with R-INLA. (2017).
2. Beginner's Guide to Zero-Inflated Models with R (2016).
3. Beginner's Guide to Data Exploration and Visualisation with R (2015).
4. Beginner's Guide to GAMM with R (2014).
5. Beginner's Guide to GLM and GLMM with R (2013).
6. Beginner's Guide to GAM with R (2012).
7. Zero Inflated Models and GLMM with R (2012).
8. A Beginner's Guide to R (2009).
9. Mixed effects models and extensions in ecology with R (2009).
10. Analysing Ecological Data (2007).



	[[alternative HTML version deleted]]


From thierry@onkelinx @ending from inbo@be  Thu Aug 30 09:14:36 2018
From: thierry@onkelinx @ending from inbo@be (Thierry Onkelinx)
Date: Thu, 30 Aug 2018 09:14:36 +0200
Subject: [R-sig-ME] Order of terms for random slopes
In-Reply-To: <CAFrBz2=F=qeP1BYey9A9Ytbmq59LCD3LAK6EO_16nbgDoffOrQ@mail.gmail.com>
References: <CAFrBz2=TzgCaNyxaNeksWP0_15mkie0SnfvjtJr7meV0M6jBkA@mail.gmail.com>
 <CAFrBz2=F=qeP1BYey9A9Ytbmq59LCD3LAK6EO_16nbgDoffOrQ@mail.gmail.com>
Message-ID: <CAJuCY5xJ_g31uUtWWSGJh1z7L3abBksuM15UpqL_jHqpOzJwxA@mail.gmail.com>

Dear Stefan,

IMHO you shouldn't use an overfitted model for didatic purposes. Teach
students that you need a sufficiently large data set depending on the
complexity of the model.

Best regards,


ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>

2018-08-29 20:51 GMT+02:00 Stefan Th. Gries <stgries at gmail.com>:

> > Thanks. This is a known issue: https://github.com/lme4/lme4/issues/449
> Ohh, ok, I had googled a bit on 'order of terms', 'random effects'
> etc. but hadn't come across this, sorry.
>
> > - it's not terribly surprising that a model with 11 parameters fitted to
> 48 observations is numerically unstable ...
> Absolutely, the example is from a workshop and was used only for
> didactic purposes, and ...
>
> > there don't seem to be any _substantive_ differences in the estimate ...
> ... yes, we only wanted to make sure there wasn't something
> superobvious but important we had missed.
>
> Thanks for the quick feedback!
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From phillip@@ld@y @ending from mpi@nl  Thu Aug 30 13:58:52 2018
From: phillip@@ld@y @ending from mpi@nl (Phillip Alday)
Date: Thu, 30 Aug 2018 13:58:52 +0200
Subject: [R-sig-ME] Plot a result without a main effect
In-Reply-To: <DB3PR0402MB38513FDC0C54A3031D513915F6770@DB3PR0402MB3851.eurprd04.prod.outlook.com>
References: <DB3PR0402MB38513FDC0C54A3031D513915F6770@DB3PR0402MB3851.eurprd04.prod.outlook.com>
Message-ID: <acfbbe62-3361-09b5-6f25-d379229da911@mpi.nl>

Hi Luca,

I don't think anybody ever answered this question for you, but you
should check out the effects package -- it can do exactly this type of
stuff. But do be careful when interpreting things that violate the
principle of marginality.

Best,
Phillip

On 06/20/2018 10:51 PM, Luca Danieli wrote:
> Hello everybody.
> 
> In an experiment I have 8 tests that are run consecutively. Each of these tests has a different intercept due to the stimulus used, and not related to the object of my study. How can I remove these intercepts? Meaning: in R I am using lmer(), and I provide these intercepts as a fixed effect. Now I would like to plot the scores taking that fixed-effect out of my plot to have a better view of the behaviour of the scores without this effect.
> 
> Is that possible? How can I do that?
> 
> Best
> Luca
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From phillip@@ld@y @ending from mpi@nl  Thu Aug 30 14:06:14 2018
From: phillip@@ld@y @ending from mpi@nl (Phillip Alday)
Date: Thu, 30 Aug 2018 14:06:14 +0200
Subject: [R-sig-ME] Efficient forward stepwise regression possible for
 mixed-effects models?
In-Reply-To: <D14049CE02C4F54D95360EEC06CE45C50F9094EC@SPMXM08.VUW.leidenuniv.nl>
References: <D14049CE02C4F54D95360EEC06CE45C50F9094EC@SPMXM08.VUW.leidenuniv.nl>
Message-ID: <b111d42c-136f-ac94-d26e-8196cee03032@mpi.nl>

There are some interesting suggestions about how to determine the
effective dimensionality of your random effects, so that you actually
know how many terms you need. RePsychLing::rePCA() implements this, see
"Parsimonious Mixed Models" (https://arxiv.org/abs/1506.04967) for more
details.

Beyond that, you could use lmList to get within-groups OLS estimates and
see which model terms show the most variability between groups. This is
very fast, but I'm not sure how "efficient" (and "consistent") it is in
a technical sense.

Best,
Phillip

On 08/21/2018 07:41 PM, Voeten, C.C. wrote:
> When doing forward stepwise regression, a computationally efficient way to choose the next term to add to the model out of a set of candidate predictors, is to calculate the correlation of each of these predictors with the residuals of the current working model. E.g., if my current model is lm(y ~ something,data=data), and I need to choose which of a set of predictors {b1, b2, b3} to add next, the largest result of sapply(data[,c('b1','b2','b3')],cor,resid(current_model)) is the predictor I should pick.
> 
> How does this extend to the random effects of mixed-effects models?
> 
> I can foresee two issues. The first is that a random effect cannot be represented by a single column vector out of a data set, so we can't use cor(). However, it should be possible to instead regress the residuals on each of the candidate random effects, and select the effect that gives the largest log-likelihood.
> A second issue I could think of is that the parameters will be optimized differently. The theta parameters will be optimized sequentially instead of jointly: every future predictor added to the model will be evaluated with the theta parameters from the preceding random effects treated as fixed. I am unsure what impact this will have -- is this known (or perhaps even obvious)?
> 
> My use case is that I often find that I have to fit large models with multiple crossed random slopes, and I know that the full model will never converge. I want to be sure that the random effects which I do include are the best possible ones I could have chosen. What I do now is start out with all fixed effects, and try all my random effects one at a time (respecting marginality), and so on, until I have identified the maximal model that will still converge. This works well, but is computationally very, very wasteful. I was wondering if this more efficient approach used in simple linear models (using the correlation of the candidate predictors with the current model's residuals) could in any way be applied to mixed models as well, and at what cost...
> 
> Thanks,
> Cesko
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From jo@quin@@ld@be @ending from gm@il@com  Thu Aug 30 16:29:19 2018
From: jo@quin@@ld@be @ending from gm@il@com (=?UTF-8?Q?Joaqu=C3=ADn_Aldabe?=)
Date: Thu, 30 Aug 2018 11:29:19 -0300
Subject: [R-sig-ME] mixed effects and occupancy models
Message-ID: <CAMM93=LcO1zyBErhbJUxreQVEs6Aia+qBXzfPHUWOdfhPnHcUA@mail.gmail.com>

Hi all, is it possible to run an occupancy model with random effects? For
example, site as a random intercept.
Thanks in advanced,
Joaqu?n.

-- 
*Joaqu?n Aldabe*

Departamento de Sistemas Agrarios y Paisajes Culturales
Centro Universitario de la Regi?n Este, Universidad de la Rep?blica, Uruguay
Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha

https://sites.google.com/site/joaquin.aldabe
<https://sites.google.com/site/perfilprofesionaljoaquinaldabe>

	[[alternative HTML version deleted]]


From @lte@@ed@c2 @ending from gm@il@com  Fri Aug 31 12:21:39 2018
From: @lte@@ed@c2 @ending from gm@il@com (C. AMAL D. GLELE)
Date: Fri, 31 Aug 2018 12:21:39 +0200
Subject: [R-sig-ME] alternative of_lmeresampler::bootstrap_ for objects of
 class glmmTMB and/or glmmadmb
Message-ID: <CANrzCv1VaQOEeZu5p0kchhgnLHF=E3Fevq9im+K+F68kCfNZxQ@mail.gmail.com>

Hi, dear all.
Is there an alternative of lmeresampler::bootstrap for objects of class
glmmTMB and/or glmmadmb?
In advance, thanks for your help.
Kind regards,

	[[alternative HTML version deleted]]


From bbolker @ending from gm@il@com  Fri Aug 31 20:56:09 2018
From: bbolker @ending from gm@il@com (Ben Bolker)
Date: Fri, 31 Aug 2018 14:56:09 -0400
Subject: [R-sig-ME] 
 alternative of_lmeresampler::bootstrap_ for objects of
 class glmmTMB and/or glmmadmb
In-Reply-To: <CANrzCv1VaQOEeZu5p0kchhgnLHF=E3Fevq9im+K+F68kCfNZxQ@mail.gmail.com>
References: <CANrzCv1VaQOEeZu5p0kchhgnLHF=E3Fevq9im+K+F68kCfNZxQ@mail.gmail.com>
Message-ID: <099de954-558f-db7a-8691-badace747c9c@gmail.com>


  Can you be more specific about what you'd like to do?  It looks like
the lmeresampler::bootstrap functions might be adaptable to glmmTMB
objects (i.e., not in their current form, but since they are mostly
built on accessor methods that work similarly between glmmTMB and lme4,
new generics could be rewritten without huge effort -- probably).
However ... at a quick glance, it looks like only fully parametric
bootstrapping and case-resampling will work for GLMMs rather than LMMs
(and you're probably using glmmTMB/glmmADMB because you need some sort
of exotic GLMM-type thing, not a LMM, anyway ...)


You can also do parametric boostrapping with bootMer in glmmTMB, with
the current CRAN lme4 and the parboot branch of glmmTMB, although there
are still some bugs for binomial-type models:
https://github.com/glmmTMB/glmmTMB/issues/375

On 2018-08-31 06:21 AM, C. AMAL D. GLELE wrote:
> Hi, dear all.
> Is there an alternative of lmeresampler::bootstrap for objects of class
> glmmTMB and/or glmmadmb?
> In advance, thanks for your help.
> Kind regards,
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From M@@rten@Jung @ending from m@ilbox@tu-dre@den@de  Sat Sep  1 15:49:58 2018
From: M@@rten@Jung @ending from m@ilbox@tu-dre@den@de (Maarten Jung)
Date: Sat, 1 Sep 2018 15:49:58 +0200
Subject: [R-sig-ME] Removing random intercepts before random slopes
In-Reply-To: <CAHr4DydEGPB+txgGMpwUP8zD2yiU5TB5kZ_fTAMr2RTTc0pcgA@mail.gmail.com>
References: <CAHr4Dyd=7BEHiwQFGaB_C4MNmCsnOTgdZu7htyrKRPbg1qA=Qw@mail.gmail.com>
 <e0e3c61d-43a5-1d28-492c-46b7ba3821ee@mpi.nl>
 <CAHr4DydLNEAekQTyuCddp1TEWa3LKsh6Tg64ffmFPkHD4iL1Eg@mail.gmail.com>
 <CAHr4DyeRZJ5v4WVjJwO8j-F1nNMq8bmstxXwsx2BXr3+-9KMpQ@mail.gmail.com>
 <CAE9_Wg70jEd0cJdp-ebhwTe=qf1LGsBLDtLFz3TyKhRw7axayw@mail.gmail.com>
 <CAHr4DydEGPB+txgGMpwUP8zD2yiU5TB5kZ_fTAMr2RTTc0pcgA@mail.gmail.com>
Message-ID: <CAHr4DydEiZxo+DfjKrr88L6RKfEkKYaRG7aXroPgdVHAA1AKUA@mail.gmail.com>

> thanks for your answer, makes sense to me. I think removing the random intercepts should mostly increase the residual error and thus even
> increase the SEs for the fixed effects. Is this correct?

Fwiw: this quick test with the Machines data seems to support my speculation:

data("Machines", package = "MEMSS")
d <- Machines
xtabs(~ Worker + Machine, d)  # balanced

mm <- model.matrix(~ 1 + Machine, d)
c1 <- mm[, 2]
c2 <- mm[, 3]

summary(lmerTest::lmer(score ~ 1 + c1 + c2 + (1 + c1 + c2 | Worker), d))
# Fixed effects:
#             Estimate Std. Error     df t value Pr(>|t|)
# (Intercept)   52.356      1.681  5.000  31.151  6.4e-07 ***
# c1             7.967      2.421  5.000   3.291 0.021693 *
# c2            13.917      1.540  5.000   9.036 0.000277 ***

summary(lmerTest::lmer(score ~ 1 + c1 + c2 + (0 + c1 + c2 | Worker), d))
### SEs increased:
# Fixed effects:
#             Estimate Std. Error      df t value Pr(>|t|)
# (Intercept)  52.3556     0.6242 41.0000  83.880  < 2e-16 ***
# c1            7.9667     3.5833  5.3172   2.223 0.073612 .
# c2           13.9167     1.9111  6.2545   7.282 0.000282 ***

summary(lmerTest::lmer(score ~ 1 + c1 + c2 + (1 + c1 + c2 || Worker), d))
# Fixed effects:
#             Estimate Std. Error     df t value Pr(>|t|)
# (Intercept)   52.356      1.679  5.004  31.188 6.31e-07 ***
# c1             7.967      2.426  5.002   3.284 0.021833 *
# c2            13.917      1.523  5.004   9.137 0.000262 ***

summary(lmerTest::lmer(score ~ 1 + c1 + c2 + (0 + c1 + c2 || Worker), d))
### SEs increased:
# Fixed effects:
#             Estimate Std. Error      df t value Pr(>|t|)
# (Intercept)  52.3556     0.6242 41.0000  83.880  < 2e-16 ***
# c1            7.9667     3.5833  5.3172   2.223 0.073612 .
# c2           13.9167     1.9111  6.2545   7.282 0.000282 ***

Still, I would be glad to hear any thoughts on this question:

> Why exactely would it be conceptually strange to have random slopes but not random intercepts?
> Because intercepts often represent some kind of baseline and, say subjects, will probably have different baselines (and thus a corresponding variance component estimated as > 0) if their slopes (i.e. effects) vary, or is there any other statistical reason why most people remove the random slopes first?


From j@ke@@@we@tf@ll @ending from gm@il@com  Sat Sep  1 16:52:10 2018
From: j@ke@@@we@tf@ll @ending from gm@il@com (Jake Westfall)
Date: Sat, 1 Sep 2018 09:52:10 -0500
Subject: [R-sig-ME] Removing random intercepts before random slopes
In-Reply-To: <CAHr4DydEiZxo+DfjKrr88L6RKfEkKYaRG7aXroPgdVHAA1AKUA@mail.gmail.com>
References: <CAHr4Dyd=7BEHiwQFGaB_C4MNmCsnOTgdZu7htyrKRPbg1qA=Qw@mail.gmail.com>
 <e0e3c61d-43a5-1d28-492c-46b7ba3821ee@mpi.nl>
 <CAHr4DydLNEAekQTyuCddp1TEWa3LKsh6Tg64ffmFPkHD4iL1Eg@mail.gmail.com>
 <CAHr4DyeRZJ5v4WVjJwO8j-F1nNMq8bmstxXwsx2BXr3+-9KMpQ@mail.gmail.com>
 <CAE9_Wg70jEd0cJdp-ebhwTe=qf1LGsBLDtLFz3TyKhRw7axayw@mail.gmail.com>
 <CAHr4DydEGPB+txgGMpwUP8zD2yiU5TB5kZ_fTAMr2RTTc0pcgA@mail.gmail.com>
 <CAHr4DydEiZxo+DfjKrr88L6RKfEkKYaRG7aXroPgdVHAA1AKUA@mail.gmail.com>
Message-ID: <CAE9_Wg6b1cGLK_bSOhAQiAfzJeUcb9GeDQK1FrENHSFfXiRkcQ@mail.gmail.com>

Hi Maarten,

I should point out that all of this, both what I said and what the Barr et
al. paper said, is contingent on the fixed predictor being
contrast/deviation coded, NOT treatment/dummy coded. This is sort of
mentioned in the Barr paper in footnote 12 (attached to the paragraph you
cited on p. 276), but it's not 100% clear, and I probably should have
reminded about it too.

If you add `options(contrasts=c("contr.helmert", "contr.poly"))` to the top
of your script you'll see the expected results.

The reason the coding matters in this way is that iff we're using
contrast/deviation codes and the design is approximately balanced, then
removing the random intercepts is the same as constraining all units to
have the same overall mean response -- visually, this just vertically
shifts each of the unit-specific regression lines (actually planes in this
case) so that they all intersect X=0 at the same Y -- but this shift
doesn't have much impact on any of the unit-specific slopes, and thus
doesn't change much the random slope variance. Since the random slope
variance enters the standard errors of the fixed slopes while the random
intercept variance does not (because the fixed slopes are effectively
difference scores that subtract out the unit-specific means), this means
that the standard errors are mostly unchanged by this shift.

As you point you, the residual variance does expand a little bit to soak up
some of the ignored random intercept variance. But this has very little
impact on the standard errors because, in the standard error expression,
the residual variance is divided by the total number of observations, so
its contribution to the entire expression is negligible except for tiny
data sets (which to some extent is true of the Machines dataset).

Now on the other hand, if we use treatment/dummy codes, removing the random
intercepts corresponds to a completely different constraint, specifically
we constrain all units to have the same response *in one of the
experimental conditions*, and the random slopes are left to be whatever
they now need to be to fit the other experimental conditions. This can have
a big impact on the unit-specific regression lines, generally increasing
their variance, possibly by a lot, which has a big impact on the standard
errors of the fixed slopes.

This is a lot easier to understand using pictures (and maybe a few
equations) rather than quickly typed words, but it's Saturday morning and I
want to do fun stuff, so... anyway, I hope this helps a little.

Finally, in answer to your follow-up question of why it might be
conceptually strange to have random slopes but not random intercepts, maybe
this image from the Gelman & Hill textbook of what that implies for the
unit-specific regression lines will make that more clear. I hope you agree
that the middle panel is strange. The image is specifically in a dummy
coding context, but it's not much less strange even if we use
contrast/deviation codes.


Jake



On Sat, Sep 1, 2018 at 8:45 AM Maarten Jung <
Maarten.Jung at mailbox.tu-dresden.de> wrote:

> > thanks for your answer, makes sense to me. I think removing the random
> intercepts should mostly increase the residual error and thus even
> > increase the SEs for the fixed effects. Is this correct?
>
> Fwiw: this quick test with the Machines data seems to support my
> speculation:
>
> data("Machines", package = "MEMSS")
> d <- Machines
> xtabs(~ Worker + Machine, d)  # balanced
>
> mm <- model.matrix(~ 1 + Machine, d)
> c1 <- mm[, 2]
> c2 <- mm[, 3]
>
> summary(lmerTest::lmer(score ~ 1 + c1 + c2 + (1 + c1 + c2 | Worker), d))
> # Fixed effects:
> #             Estimate Std. Error     df t value Pr(>|t|)
> # (Intercept)   52.356      1.681  5.000  31.151  6.4e-07 ***
> # c1             7.967      2.421  5.000   3.291 0.021693 *
> # c2            13.917      1.540  5.000   9.036 0.000277 ***
>
> summary(lmerTest::lmer(score ~ 1 + c1 + c2 + (0 + c1 + c2 | Worker), d))
> ### SEs increased:
> # Fixed effects:
> #             Estimate Std. Error      df t value Pr(>|t|)
> # (Intercept)  52.3556     0.6242 41.0000  83.880  < 2e-16 ***
> # c1            7.9667     3.5833  5.3172   2.223 0.073612 .
> # c2           13.9167     1.9111  6.2545   7.282 0.000282 ***
>
> summary(lmerTest::lmer(score ~ 1 + c1 + c2 + (1 + c1 + c2 || Worker), d))
> # Fixed effects:
> #             Estimate Std. Error     df t value Pr(>|t|)
> # (Intercept)   52.356      1.679  5.004  31.188 6.31e-07 ***
> # c1             7.967      2.426  5.002   3.284 0.021833 *
> # c2            13.917      1.523  5.004   9.137 0.000262 ***
>
> summary(lmerTest::lmer(score ~ 1 + c1 + c2 + (0 + c1 + c2 || Worker), d))
> ### SEs increased:
> # Fixed effects:
> #             Estimate Std. Error      df t value Pr(>|t|)
> # (Intercept)  52.3556     0.6242 41.0000  83.880  < 2e-16 ***
> # c1            7.9667     3.5833  5.3172   2.223 0.073612 .
> # c2           13.9167     1.9111  6.2545   7.282 0.000282 ***
>
> Still, I would be glad to hear any thoughts on this question:
>
> > Why exactely would it be conceptually strange to have random slopes but
> not random intercepts?
> > Because intercepts often represent some kind of baseline and, say
> subjects, will probably have different baselines (and thus a corresponding
> variance component estimated as > 0) if their slopes (i.e. effects) vary,
> or is there any other statistical reason why most people remove the random
> slopes first?
>

	[[alternative HTML version deleted]]


From d@rizopoulo@ @ending from er@@mu@mc@nl  Sat Sep  1 20:45:07 2018
From: d@rizopoulo@ @ending from er@@mu@mc@nl (D. Rizopoulos)
Date: Sat, 1 Sep 2018 18:45:07 +0000
Subject: [R-sig-ME] Removing random intercepts before random slopes
In-Reply-To: <CAE9_Wg6b1cGLK_bSOhAQiAfzJeUcb9GeDQK1FrENHSFfXiRkcQ@mail.gmail.com>
References: <CAHr4Dyd=7BEHiwQFGaB_C4MNmCsnOTgdZu7htyrKRPbg1qA=Qw@mail.gmail.com>
 <e0e3c61d-43a5-1d28-492c-46b7ba3821ee@mpi.nl>
 <CAHr4DydLNEAekQTyuCddp1TEWa3LKsh6Tg64ffmFPkHD4iL1Eg@mail.gmail.com>
 <CAHr4DyeRZJ5v4WVjJwO8j-F1nNMq8bmstxXwsx2BXr3+-9KMpQ@mail.gmail.com>
 <CAE9_Wg70jEd0cJdp-ebhwTe=qf1LGsBLDtLFz3TyKhRw7axayw@mail.gmail.com>
 <CAHr4DydEGPB+txgGMpwUP8zD2yiU5TB5kZ_fTAMr2RTTc0pcgA@mail.gmail.com>
 <CAHr4DydEiZxo+DfjKrr88L6RKfEkKYaRG7aXroPgdVHAA1AKUA@mail.gmail.com>
 <CAE9_Wg6b1cGLK_bSOhAQiAfzJeUcb9GeDQK1FrENHSFfXiRkcQ@mail.gmail.com>
Message-ID: <7191AFC7255B4F49A30707E39BEAD05FDEB631A5@EXCH-RX03.erasmusmc.nl>

When you're using lmer() or lme(), actually you don't fit a mixed model, but the implied marginal model. That is, under maximum likelihood estimation, you integrate out the random effects, and you obtain a marginal model of the form

Y ~ N(Xbeta, ZDZ + sigma^2 I),

where X is the design matrix for the fixed effects beta, Z the design matrix of the random effects, D the covariance matrix of the random effects, and sigma^2 the measurement error variance.

Hence, it all boils down to how this marginal covariance matrix looks like. Typically, a bottom up approach is used. That is, you start with intercepts because it is the simplest structure corresponding to compound symmetry (i.e., constant correlation over time), and you continue with including random slopes that allow correlations to decay with the time lag, and even include higher order terms (e.g., in case of longitudinal data often you can include a spline of your time variable in the random effects). To judge if you need to include an extra random effect a likelihood ratio test is typically used.

Now, if you're only interest in the marginal model, that is in the fixed effects and their standard errors, it is perfectly fine to exclude the random intercepts even if you have slopes in your model, because you just see it as a particular (perhaps more parsimonious) choice for your marginal covariance matrix.

However, if you're also interested in producing subject-specific predictions that will use the empirical Bayes estimates of the random effects that you obtain in a second step, then having slopes without intercepts will look strange in most of the cases (even though I know a couple of example in this makes sense).

I hope it helps.

Best,
Dimitris


-----Original Message-----
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> On Behalf Of Jake Westfall
Sent: Saturday, September 1, 2018 4:52 PM
To: Maarten.Jung at mailbox.tu-dresden.de
Cc: r-sig-mixed-models <r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] Removing random intercepts before random slopes

Hi Maarten,

I should point out that all of this, both what I said and what the Barr et al. paper said, is contingent on the fixed predictor being contrast/deviation coded, NOT treatment/dummy coded. This is sort of mentioned in the Barr paper in footnote 12 (attached to the paragraph you cited on p. 276), but it's not 100% clear, and I probably should have reminded about it too.

If you add `options(contrasts=c("contr.helmert", "contr.poly"))` to the top of your script you'll see the expected results.

The reason the coding matters in this way is that iff we're using contrast/deviation codes and the design is approximately balanced, then removing the random intercepts is the same as constraining all units to have the same overall mean response -- visually, this just vertically shifts each of the unit-specific regression lines (actually planes in this
case) so that they all intersect X=0 at the same Y -- but this shift doesn't have much impact on any of the unit-specific slopes, and thus doesn't change much the random slope variance. Since the random slope variance enters the standard errors of the fixed slopes while the random intercept variance does not (because the fixed slopes are effectively difference scores that subtract out the unit-specific means), this means that the standard errors are mostly unchanged by this shift.

As you point you, the residual variance does expand a little bit to soak up some of the ignored random intercept variance. But this has very little impact on the standard errors because, in the standard error expression, the residual variance is divided by the total number of observations, so its contribution to the entire expression is negligible except for tiny data sets (which to some extent is true of the Machines dataset).

Now on the other hand, if we use treatment/dummy codes, removing the random intercepts corresponds to a completely different constraint, specifically we constrain all units to have the same response *in one of the experimental conditions*, and the random slopes are left to be whatever they now need to be to fit the other experimental conditions. This can have a big impact on the unit-specific regression lines, generally increasing their variance, possibly by a lot, which has a big impact on the standard errors of the fixed slopes.

This is a lot easier to understand using pictures (and maybe a few
equations) rather than quickly typed words, but it's Saturday morning and I want to do fun stuff, so... anyway, I hope this helps a little.

Finally, in answer to your follow-up question of why it might be conceptually strange to have random slopes but not random intercepts, maybe this image from the Gelman & Hill textbook of what that implies for the unit-specific regression lines will make that more clear. I hope you agree that the middle panel is strange. The image is specifically in a dummy coding context, but it's not much less strange even if we use contrast/deviation codes.


Jake



On Sat, Sep 1, 2018 at 8:45 AM Maarten Jung < Maarten.Jung at mailbox.tu-dresden.de> wrote:

> > thanks for your answer, makes sense to me. I think removing the 
> > random
> intercepts should mostly increase the residual error and thus even
> > increase the SEs for the fixed effects. Is this correct?
>
> Fwiw: this quick test with the Machines data seems to support my
> speculation:
>
> data("Machines", package = "MEMSS")
> d <- Machines
> xtabs(~ Worker + Machine, d)  # balanced
>
> mm <- model.matrix(~ 1 + Machine, d)
> c1 <- mm[, 2]
> c2 <- mm[, 3]
>
> summary(lmerTest::lmer(score ~ 1 + c1 + c2 + (1 + c1 + c2 | Worker), 
> d)) # Fixed effects:
> #             Estimate Std. Error     df t value Pr(>|t|)
> # (Intercept)   52.356      1.681  5.000  31.151  6.4e-07 ***
> # c1             7.967      2.421  5.000   3.291 0.021693 *
> # c2            13.917      1.540  5.000   9.036 0.000277 ***
>
> summary(lmerTest::lmer(score ~ 1 + c1 + c2 + (0 + c1 + c2 | Worker), 
> d)) ### SEs increased:
> # Fixed effects:
> #             Estimate Std. Error      df t value Pr(>|t|)
> # (Intercept)  52.3556     0.6242 41.0000  83.880  < 2e-16 ***
> # c1            7.9667     3.5833  5.3172   2.223 0.073612 .
> # c2           13.9167     1.9111  6.2545   7.282 0.000282 ***
>
> summary(lmerTest::lmer(score ~ 1 + c1 + c2 + (1 + c1 + c2 || Worker), 
> d)) # Fixed effects:
> #             Estimate Std. Error     df t value Pr(>|t|)
> # (Intercept)   52.356      1.679  5.004  31.188 6.31e-07 ***
> # c1             7.967      2.426  5.002   3.284 0.021833 *
> # c2            13.917      1.523  5.004   9.137 0.000262 ***
>
> summary(lmerTest::lmer(score ~ 1 + c1 + c2 + (0 + c1 + c2 || Worker), 
> d)) ### SEs increased:
> # Fixed effects:
> #             Estimate Std. Error      df t value Pr(>|t|)
> # (Intercept)  52.3556     0.6242 41.0000  83.880  < 2e-16 ***
> # c1            7.9667     3.5833  5.3172   2.223 0.073612 .
> # c2           13.9167     1.9111  6.2545   7.282 0.000282 ***
>
> Still, I would be glad to hear any thoughts on this question:
>
> > Why exactely would it be conceptually strange to have random slopes 
> > but
> not random intercepts?
> > Because intercepts often represent some kind of baseline and, say
> subjects, will probably have different baselines (and thus a 
> corresponding variance component estimated as > 0) if their slopes 
> (i.e. effects) vary, or is there any other statistical reason why most 
> people remove the random slopes first?
>

	[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From @lte@@ed@c2 @ending from gm@il@com  Sun Sep  2 22:48:18 2018
From: @lte@@ed@c2 @ending from gm@il@com (C. AMAL D. GLELE)
Date: Sun, 2 Sep 2018 22:48:18 +0200
Subject: [R-sig-ME] R-sig-mixed-models Digest, Vol 141, Issue 1
In-Reply-To: <mailman.16871.7.1535796546.1031.r-sig-mixed-models@r-project.org>
References: <mailman.16871.7.1535796546.1031.r-sig-mixed-models@r-project.org>
Message-ID: <CANrzCv04eyLygUE1aHKmZD_CXfVEHhB9rktAouecjPZDR+FRFA@mail.gmail.com>

 Hi, dear Ben.
Many thanks for your suggestion.
Here is my need:
I've fitted a model using glmmadmb; my goal now is to get its estimates's
bootstrapped CI's  and/or p-values.
Best,

Le sam. 1 sept. 2018 ? 12:09, <r-sig-mixed-models-request at r-project.org> a
?crit :

> Send R-sig-mixed-models mailing list submissions to
>         r-sig-mixed-models at r-project.org
>
> To subscribe or unsubscribe via the World Wide Web, visit
>         https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> or, via email, send a message with subject or body 'help' to
>         r-sig-mixed-models-request at r-project.org
>
> You can reach the person managing the list at
>         r-sig-mixed-models-owner at r-project.org
>
> When replying, please edit your Subject line so it is more specific
> than "Re: Contents of R-sig-mixed-models digest..."
>
>
> Today's Topics:
>
>    1. alternative of_lmeresampler::bootstrap_ for objects of class
>       glmmTMB and/or glmmadmb (C. AMAL D. GLELE)
>    2. Re:  alternative of_lmeresampler::bootstrap_ for objects of
>       class glmmTMB and/or glmmadmb (Ben Bolker)
>
> ----------------------------------------------------------------------
>
> Message: 1
> Date: Fri, 31 Aug 2018 12:21:39 +0200
> From: "C. AMAL D. GLELE" <altessedac2 at gmail.com>
> To: R SIG Mixed Models <r-sig-mixed-models at r-project.org>
> Subject: [R-sig-ME] alternative of_lmeresampler::bootstrap_ for
>         objects of class glmmTMB and/or glmmadmb
> Message-ID:
>         <CANrzCv1VaQOEeZu5p0kchhgnLHF=
> E3Fevq9im+K+F68kCfNZxQ at mail.gmail.com>
> Content-Type: text/plain; charset="utf-8"
>
> Hi, dear all.
> Is there an alternative of lmeresampler::bootstrap for objects of class
> glmmTMB and/or glmmadmb?
> In advance, thanks for your help.
> Kind regards,
>
>         [[alternative HTML version deleted]]
>
>
>
>
> ------------------------------
>
> Message: 2
> Date: Fri, 31 Aug 2018 14:56:09 -0400
> From: Ben Bolker <bbolker at gmail.com>
> To: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME]  alternative of_lmeresampler::bootstrap_ for
>         objects of class glmmTMB and/or glmmadmb
> Message-ID: <099de954-558f-db7a-8691-badace747c9c at gmail.com>
> Content-Type: text/plain; charset="utf-8"
>
>
>   Can you be more specific about what you'd like to do?  It looks like
> the lmeresampler::bootstrap functions might be adaptable to glmmTMB
> objects (i.e., not in their current form, but since they are mostly
> built on accessor methods that work similarly between glmmTMB and lme4,
> new generics could be rewritten without huge effort -- probably).
> However ... at a quick glance, it looks like only fully parametric
> bootstrapping and case-resampling will work for GLMMs rather than LMMs
> (and you're probably using glmmTMB/glmmADMB because you need some sort
> of exotic GLMM-type thing, not a LMM, anyway ...)
>
>
> You can also do parametric boostrapping with bootMer in glmmTMB, with
> the current CRAN lme4 and the parboot branch of glmmTMB, although there
> are still some bugs for binomial-type models:
> https://github.com/glmmTMB/glmmTMB/issues/375
>
> On 2018-08-31 06:21 AM, C. AMAL D. GLELE wrote:
> > Hi, dear all.
> > Is there an alternative of lmeresampler::bootstrap for objects of class
> > glmmTMB and/or glmmadmb?
> > In advance, thanks for your help.
> > Kind regards,
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
>
>
>
> ------------------------------
>
> Subject: Digest Footer
>
> _______________________________________________
> R-sig-mixed-models mailing list
> R-sig-mixed-models at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
> ------------------------------
>
> End of R-sig-mixed-models Digest, Vol 141, Issue 1
> **************************************************
>

	[[alternative HTML version deleted]]


From y@@hree19 @ending from gm@il@com  Mon Sep  3 15:32:03 2018
From: y@@hree19 @ending from gm@il@com (Yashree Mehta)
Date: Mon, 3 Sep 2018 15:32:03 +0200
Subject: [R-sig-ME] Fixed vs random effects with lme4
In-Reply-To: <CAFW8BypiqCAy9TUiRegD00FeCM=9Y57LqELQ3VPh3mPD3nwL7Q@mail.gmail.com>
References: <CAOE=hqJBPwPdCm0qJHFRFNum4azi+k5uRKpL2pKUfXmn5CLcCQ@mail.gmail.com>
 <CAFW8BypY2SXq=DSekihNrKgXh_g8qRsW4AEMJ2f6h9Of9=WCvQ@mail.gmail.com>
 <CAOE=hqKtkxyDiDVzFdze8YrUM3RToYqbcJMES2xbsONkmrmJng@mail.gmail.com>
 <CAFW8BypiqCAy9TUiRegD00FeCM=9Y57LqELQ3VPh3mPD3nwL7Q@mail.gmail.com>
Message-ID: <CAOE=hqK_HmZ4q63xbHcRTwRSjzMOOSzh6r9JMGJ3cx0xA6akAw@mail.gmail.com>

Thanks for your explanation.

I now understand the two different references of the fixed effects model. I
want to conduct the Hausman test as described by you , " comparing beta in
a model with a group varying intercept random effect and beta in a model
where between group effects are segregated". The confusion arose because I
was referring to the household-specific within-transformation parameter
(fixed effect) as the random intercept.

The link which you provided is very helpful.

Regards,
Yashree




On Thu, Aug 23, 2018 at 7:42 PM John Poe <jdpo223 at g.uky.edu> wrote:

> I'm getting a bit confused by your language.
>
> A fixed effects model can either refer to a model with one intercept
> making no allowance for group variability (so all the effects are assumed
> fixed for the population) or a model where all between group variance is
> removed from the main variables via dummy variables, the within transform,
> first differencing or some other method and thus the betas represent the
> portion of the effect common to the population and thus fixed.
>
> If you want to do a hausman test you are comparing beta in a model with a
> group varying intercept random effect and beta in a model where between
> group effects are segregated via the above techniques. You do not include a
> random effect in both models.
>
> The hausman test is completely useless as a model specification tool if
> you're going to use both a group mean centered (within transform) to get
> the equivalent of a within group effects beta along with a group varying
> intercept (random effect).
>
> On Aug 23, 2018 1:05 PM, "Yashree Mehta" <yashree19 at gmail.com> wrote:
>
> Thank you very much for your reply.
>
> I see that the function "lm" is used for fixed effects and lmer for random
> effects. I want to use lmer and specify a random intercept for the fixed
> effects model. (In the terminology of efficiency analysis, it can be called
> " fixed effects-random intercept" model.
> To be more specific,
>
>  A random intercept based on the Household_id is to be included for both
> models:
> 1) Where it is assumed that the random intercept is correlated with
> X-covariates (Fixed effects)
> 2)Where this not assumed. i.e. a correlation of 0. (Random effects)
>
> Having estimated the two models, I want to conduct the Hausman test.
>
> Thanks again,
>
> Regards,
> Yashree
>
>
>
> On Thu, Aug 23, 2018 at 5:43 PM John Poe <jdpo223 at g.uky.edu> wrote:
>
>> Yep,
>>
>> Peter Westfall wrote up how to do it in an example script
>> http://westfall.ba.ttu.edu/ISQS5349/Hausman_test_inR.txt
>>
>> Please be aware that the test does not imply that you shouldn't use
>> random effects if there is correlation between a group-varying intercept
>> and a lower level variable. It just means that you need to do something to
>> properly model that correlation. That could be a within-group only model
>> with dummy variables for groups (standard Fixed Effects models) or a
>> group-mean centered model a la much of multilevel modeling. In econ this is
>> known as a Hausman Taylor model (yes, the same Hausman as the test) or a
>> correlated random effects model. You could also use a random slopes model
>> to allow the variability in Xi across groups but it's less effective at
>> debiasing than the other choices.
>>
>> On Thu, Aug 23, 2018 at 11:09 AM Yashree Mehta <yashree19 at gmail.com>
>> wrote:
>>
>>> Hello,
>>>
>>> Is there a way to conduct the Hausman test on models which have been
>>> estimated using lme4?
>>>
>>> To be more specific,
>>>
>>> My model assumption is that the plot size(X covariate) is correlated with
>>> the random intercept ( estimated from Household_ID) which will be
>>> estimated. So I have to find out how to tell lmer to consider this
>>> correlation. I would also, similarly, want to carry random effects where
>>> this correlation assumption is done away with. Finally, I want to conduct
>>> the Hausman test for model choice.
>>>
>>> Thank you,
>>>
>>> Regards,
>>> Yashree
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>>
>> --
>>
>>
>>
>>
>> Thanks,
>> John
>>
>>
>> John Poe, Ph.D.
>> Postdoctoral Scholar / Research Methodologist
>> Center for Public Health Services & Systems Research
>> University of Kentucky
>> www.johndavidpoe.com
>>
>
>

	[[alternative HTML version deleted]]


From M@@rten@Jung @ending from m@ilbox@tu-dre@den@de  Tue Sep  4 01:31:03 2018
From: M@@rten@Jung @ending from m@ilbox@tu-dre@den@de (Maarten Jung)
Date: Tue, 4 Sep 2018 01:31:03 +0200
Subject: [R-sig-ME] Removing random intercepts before random slopes
In-Reply-To: <CAE9_Wg6b1cGLK_bSOhAQiAfzJeUcb9GeDQK1FrENHSFfXiRkcQ@mail.gmail.com>
References: <CAHr4Dyd=7BEHiwQFGaB_C4MNmCsnOTgdZu7htyrKRPbg1qA=Qw@mail.gmail.com>
 <e0e3c61d-43a5-1d28-492c-46b7ba3821ee@mpi.nl>
 <CAHr4DydLNEAekQTyuCddp1TEWa3LKsh6Tg64ffmFPkHD4iL1Eg@mail.gmail.com>
 <CAHr4DyeRZJ5v4WVjJwO8j-F1nNMq8bmstxXwsx2BXr3+-9KMpQ@mail.gmail.com>
 <CAE9_Wg70jEd0cJdp-ebhwTe=qf1LGsBLDtLFz3TyKhRw7axayw@mail.gmail.com>
 <CAHr4DydEGPB+txgGMpwUP8zD2yiU5TB5kZ_fTAMr2RTTc0pcgA@mail.gmail.com>
 <CAHr4DydEiZxo+DfjKrr88L6RKfEkKYaRG7aXroPgdVHAA1AKUA@mail.gmail.com>
 <CAE9_Wg6b1cGLK_bSOhAQiAfzJeUcb9GeDQK1FrENHSFfXiRkcQ@mail.gmail.com>
Message-ID: <CAHr4Dydyw40nEkpi7kc382z85dprGTvVOykKEdbUHSzVr31Bzg@mail.gmail.com>

Thank you, Jake, this makes total sense to me and reminds me to choose
contrasts where the intercept corresponds to the overall mean (which seems
to be handy not only in this case..)

On Sat, Sep 1, 2018 at 4:52 PM Jake Westfall <jake.a.westfall at gmail.com>
wrote:

> Hi Maarten,
>
> I should point out that all of this, both what I said and what the Barr et
> al. paper said, is contingent on the fixed predictor being
> contrast/deviation coded, NOT treatment/dummy coded. This is sort of
> mentioned in the Barr paper in footnote 12 (attached to the paragraph you
> cited on p. 276), but it's not 100% clear, and I probably should have
> reminded about it too.
>
> If you add `options(contrasts=c("contr.helmert", "contr.poly"))` to the
> top of your script you'll see the expected results.
>
> The reason the coding matters in this way is that iff we're using
> contrast/deviation codes and the design is approximately balanced, then
> removing the random intercepts is the same as constraining all units to
> have the same overall mean response -- visually, this just vertically
> shifts each of the unit-specific regression lines (actually planes in this
> case) so that they all intersect X=0 at the same Y -- but this shift
> doesn't have much impact on any of the unit-specific slopes, and thus
> doesn't change much the random slope variance. Since the random slope
> variance enters the standard errors of the fixed slopes while the random
> intercept variance does not (because the fixed slopes are effectively
> difference scores that subtract out the unit-specific means), this means
> that the standard errors are mostly unchanged by this shift.
>
> As you point you, the residual variance does expand a little bit to soak
> up some of the ignored random intercept variance. But this has very little
> impact on the standard errors because, in the standard error expression,
> the residual variance is divided by the total number of observations, so
> its contribution to the entire expression is negligible except for tiny
> data sets (which to some extent is true of the Machines dataset).
>
> Now on the other hand, if we use treatment/dummy codes, removing the
> random intercepts corresponds to a completely different constraint,
> specifically we constrain all units to have the same response *in one of
> the experimental conditions*, and the random slopes are left to be whatever
> they now need to be to fit the other experimental conditions. This can have
> a big impact on the unit-specific regression lines, generally increasing
> their variance, possibly by a lot, which has a big impact on the standard
> errors of the fixed slopes.
>
> This is a lot easier to understand using pictures (and maybe a few
> equations) rather than quickly typed words, but it's Saturday morning and I
> want to do fun stuff, so... anyway, I hope this helps a little.
>
> Finally, in answer to your follow-up question of why it might be
> conceptually strange to have random slopes but not random intercepts, maybe
> this image from the Gelman & Hill textbook of what that implies for the
> unit-specific regression lines will make that more clear. I hope you agree
> that the middle panel is strange. The image is specifically in a dummy
> coding context, but it's not much less strange even if we use
> contrast/deviation codes.
>
>
> Jake
>

	[[alternative HTML version deleted]]


From M@@rten@Jung @ending from m@ilbox@tu-dre@den@de  Tue Sep  4 01:42:37 2018
From: M@@rten@Jung @ending from m@ilbox@tu-dre@den@de (Maarten Jung)
Date: Tue, 4 Sep 2018 01:42:37 +0200
Subject: [R-sig-ME] Removing random intercepts before random slopes
In-Reply-To: <7191AFC7255B4F49A30707E39BEAD05FDEB631A5@EXCH-RX03.erasmusmc.nl>
References: <CAHr4Dyd=7BEHiwQFGaB_C4MNmCsnOTgdZu7htyrKRPbg1qA=Qw@mail.gmail.com>
 <e0e3c61d-43a5-1d28-492c-46b7ba3821ee@mpi.nl>
 <CAHr4DydLNEAekQTyuCddp1TEWa3LKsh6Tg64ffmFPkHD4iL1Eg@mail.gmail.com>
 <CAHr4DyeRZJ5v4WVjJwO8j-F1nNMq8bmstxXwsx2BXr3+-9KMpQ@mail.gmail.com>
 <CAE9_Wg70jEd0cJdp-ebhwTe=qf1LGsBLDtLFz3TyKhRw7axayw@mail.gmail.com>
 <CAHr4DydEGPB+txgGMpwUP8zD2yiU5TB5kZ_fTAMr2RTTc0pcgA@mail.gmail.com>
 <CAHr4DydEiZxo+DfjKrr88L6RKfEkKYaRG7aXroPgdVHAA1AKUA@mail.gmail.com>
 <CAE9_Wg6b1cGLK_bSOhAQiAfzJeUcb9GeDQK1FrENHSFfXiRkcQ@mail.gmail.com>
 <7191AFC7255B4F49A30707E39BEAD05FDEB631A5@EXCH-RX03.erasmusmc.nl>
Message-ID: <CAHr4Dye6-JKm6fFnpD_xsS0ZC+9Ndv2uwKXvKYjrW=k9F2LUPg@mail.gmail.com>

> Now, if you're only interest in the marginal model, that is in the fixed effects and their standard errors, it is perfectly fine to exclude the random intercepts even if you have slopes in your model, because you just see it as a particular (perhaps more parsimonious) choice for your marginal covariance matrix.

This seems to be an interesting point: If one defines the covariance
matrix as in [1], the off-diagonal elements of this matrix should be
zero for a model without correlation parameters (by which I mean the
|| syntax) and without random intercepts, i.e. just (uncorrelated)
random slopes: (0 + c1 + c2 || Worker). This is, of course, a more
parsimonious model compared to
(1 + c1 + c2 || Worker); however, from a conceptual point of view it
does not look like an appropriate model for most situations I can
think of.
On the other hand (as Jake pointed out and I agree with that) this
model should still be OK if one is only interested in the fixed
effects, their SEs and t values.

[1] https://stats.stackexchange.com/a/348572/136579


From z@@v@z @ending from gm@il@com  Tue Sep  4 18:00:42 2018
From: z@@v@z @ending from gm@il@com (Pedro Vaz)
Date: Tue, 4 Sep 2018 17:00:42 +0100
Subject: [R-sig-ME] leave-one-out cross validation in mixed effects logistic
 model (lme4)
Message-ID: <CAKW-RG9Q8KC929quq6=5evqMRN3QAQ_4zxS4yY6U8+CxWpCd9A@mail.gmail.com>

Hello,

So, I have this (simplified for better understanding) binomial mixed
effects model [library (lme4)]

Mymodel <- glmer(cross.01 ~ stream.01 + width.m + grass.per + (1|
structure.id),
  data = Mydata, family = binomial)

stream is a factor with 2 levels; width.m is continuous; grass.per is a
percentage

Now, a reviewer is asking me to apply "a cross-validation procedure (i.e. a
leave-one-out design coupled with predictive metrics as e.g. AUC) on this
model"

Does anyone have R-code to do this cross validation in my logistic mixed
effects model? In the reviewer words: "the model should be evaluated also
as for their predictive performance, not only for assumptions violation and
for goodness-of-fit" (which I presented already in the reviewed paper draft)

Many thanks in advance,
pedro

	[[alternative HTML version deleted]]


From mhorn@eth @ending from gm@il@com  Tue Sep  4 22:18:33 2018
From: mhorn@eth @ending from gm@il@com (Megan Hornseth)
Date: Tue, 4 Sep 2018 16:18:33 -0400
Subject: [R-sig-ME] Zero-inflated beta hurdle model
Message-ID: <CADwMXOuKvxBfv=pQ8s3CRHgyW4M3qSq4hCQ_W_BsF0Gzr4qABA@mail.gmail.com>

I have a dataset that is a proportion of home range overlap (HRO) ranging
from 0-0.9. Depending on the dataset there are only a few zeros (~6) or
many (~50). There are multiple years worth of data for most individuals, so
I've included ID as a random effect. From what I've read, a zero-inflated
beta regression model, fitted using a hurdle model is most appropriate. I
realize I can do this in a two-step modelling process, but it also sounds
like glmmTMB is capable of doing this in a one-step hurdle model.


My current model formula (for HRO>0) is:



 sf.beta<-glmmTMB(HRO ~ Dist+site+(1|ID), data=NI95,
family=list(family="beta",link="logit"))


I haven't specified zi because I don't think it's necessary until I add the
zeros (though I could be wrong about this). Is it possible to use a hurdle
model for this example? What would the formula look like?



Thanks in advance!

	[[alternative HTML version deleted]]


From guill@ume@imon@@2 @ending from gm@il@com  Wed Sep  5 10:43:39 2018
From: guill@ume@imon@@2 @ending from gm@il@com (Guillaume Adeux)
Date: Wed, 5 Sep 2018 10:43:39 +0200
Subject: [R-sig-ME] significance of slope (different than zero) in triple
 interaction
Message-ID: <CAENiVe9Ohsa5B4Mz=Gbuzbm4Dy7BJF62cZP1eEi763qEghtmMw@mail.gmail.com>

Hi mixmoders,

I have the following model:

mod=glmer(Weed_density~block+scale(year)*syst*timing+(1|year)+(1|plot)+(1|plot:year)+(1|ID_quadrat)+(1|OLRE)+offset(log(size_quadrat)),family=poisson(link="log"),dat=WEED)

I have a significant triple interaction between time : treatment : season.

Time is continuous, syst(=treatment) has 5 levels and season(=sampling
session) has two levels.

Here is the model output:

Generalized linear mixed model fit by maximum likelihood (Laplace
Approximation) ['glmerMod']
 Family: poisson  ( log )
Formula: WDall ~ block + scale(year) * syst * timing + (1 | year) + (1
|      plot) + (1 | plot:year) + (1 | ID_quadrat) + (1 | OLRE) +
offset(log(size_quadrat))
   Data: WEED_paired_2
Control: glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 2e+05))

     AIC      BIC   logLik deviance df.resid
 21206.3  21371.9 -10577.2  21154.3     4286

Scaled residuals:
    Min      1Q  Median      3Q     Max
-1.6531 -0.4373 -0.1646  0.1426  2.6313

Random effects:
 Groups     Name        Variance  Std.Dev.
 OLRE       (Intercept) 4.456e-01 6.675e-01
 ID_quadrat (Intercept) 1.011e+00 1.006e+00
 plot:year  (Intercept) 1.429e+00 1.195e+00
 year       (Intercept) 5.635e-15 7.506e-08
 plot       (Intercept) 0.000e+00 0.000e+00
Number of obs: 4312, groups:  OLRE, 4312; ID_quadrat, 2156; plot:year,
86; year, 17; plot, 10

Fixed effects:
                                Estimate Std. Error z value Pr(>|z|)
(Intercept)                     -0.84765    0.33352  -2.542 0.011036 *
blockD                          -0.28663    0.27596  -1.039 0.298971
scale(year)                      0.11385    0.25128   0.453 0.650500
systS2                           2.21797    0.43765   5.068 4.02e-07 ***
systS3                           2.97934    0.42857   6.952 3.61e-12 ***
systS4                           2.64787    0.43488   6.089 1.14e-09 ***
systS5                           0.55059    0.45565   1.208 0.226912
timingavant1                     1.87971    0.10286  18.275  < 2e-16 ***
scale(year):systS2               0.40061    0.38882   1.030 0.302863
scale(year):systS3               0.44798    0.37297   1.201 0.229698
scale(year):systS4              -0.01245    0.36549  -0.034 0.972819
scale(year):systS5               1.06031    0.37957   2.793 0.005215 **
scale(year):timingavant1         0.07949    0.09954   0.799 0.424489
systS2:timingavant1             -0.36039    0.12128  -2.972 0.002963 **
systS3:timingavant1             -0.56704    0.11777  -4.815 1.47e-06 ***
systS4:timingavant1             -0.39785    0.11984  -3.320 0.000901 ***
systS5:timingavant1             -0.06724    0.14990  -0.449 0.653770
scale(year):systS2:timingavant1 -0.15246    0.11992  -1.271 0.203628
scale(year):systS3:timingavant1 -0.04057    0.11556  -0.351 0.725543
scale(year):systS4:timingavant1 -0.49134    0.11614  -4.231 2.33e-05 ***
scale(year):systS5:timingavant1 -0.34391    0.13427  -2.561 0.010429 *
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1


I wish to set up constrats to test if the slopes for scale(year):syst
differ from zero at level 1 of timing.

It seems like we can do this with testInteractions but I'm not sure if my
set up is correct:

testInteractions(mod1,custom=list(syst=c(1,0,0,0,0),timing=c(1,0)),
slope="scale(year)", adjustment="none")

The preceding code yields the following:

Adjusted slope for scale(year)
Chisq Test:
P-value adjustment method: none
                   Value Df  Chisq Pr(>Chisq)
syst1 : timing1 -0.82831  1 0.6464     0.4214

This doesn't seem correct because Value doesn't represent the slope for the
first level of "syst" at the first level of "timing".

Could anyone shed their light?

Thank you very much!

Guillaume ADEUX

	[[alternative HTML version deleted]]


From ru@@ell-lenth @ending from uiow@@edu  Wed Sep  5 16:25:13 2018
From: ru@@ell-lenth @ending from uiow@@edu (Lenth, Russell V)
Date: Wed, 5 Sep 2018 14:25:13 +0000
Subject: [R-sig-ME] 
 significance of slope (different than zero) in triple interaction
Message-ID: <DM6PR04MB4380660646275726318CDBBDF1020@DM6PR04MB4380.namprd04.prod.outlook.com>

I'm a little confused because you refer to predictors by different names in different places, and 'year' seems to be used as both a covariate and a grouping factor. But try something like this:

    library(emmeans)
    emt <- emtrends(mod, ~ syst:timing, var = "year")
    summary(emt, infer = c(TRUE, TRUE))

This will estimate the slope for year at each combination of the two factors syst and timing. (You may need to re-fit the model after creating an additional variable, say WEED$syear <- scale(WEED$year), and with syear in place of scale(year) in the model formula and the emtrends call. You may follow-up with call(s) to emmeans::contrast(emt, ...) to compare or contrast these slopes.

Hope that helps.
-- Russ

Russell V. Lenth? -? Professor Emeritus
Department of Statistics and Actuarial Science?? 
The University of Iowa ?-? Iowa City, IA 52242? USA?? 
Voice (319)335-0712 (Dept. office)? -? FAX (319)335-3017



-----Original Message-----
Date: Wed, 5 Sep 2018 10:43:39 +0200
From: Guillaume Adeux <guillaumesimon.a2 at gmail.com>
To: R-mixed models mailing list <r-sig-mixed-models at r-project.org>
Subject: [R-sig-ME] significance of slope (different than zero) in
	triple interaction


Hi mixmoders,

I have the following model:

mod=glmer(Weed_density~block+scale(year)*syst*timing+(1|year)+(1|plot)+(1|plot:year)+(1|ID_quadrat)+(1|OLRE)+offset(log(size_quadrat)),family=poisson(link="log"),dat=WEED)

I have a significant triple interaction between time : treatment : season.

Time is continuous, syst(=treatment) has 5 levels and season(=sampling
session) has two levels.

Here is the model output:

Generalized linear mixed model fit by maximum likelihood (Laplace
Approximation) ['glmerMod']
 Family: poisson  ( log )
Formula: WDall ~ block + scale(year) * syst * timing + (1 | year) + (1
|      plot) + (1 | plot:year) + (1 | ID_quadrat) + (1 | OLRE) +
offset(log(size_quadrat))
   Data: WEED_paired_2
Control: glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 2e+05))

     AIC      BIC   logLik deviance df.resid
 21206.3  21371.9 -10577.2  21154.3     4286

Scaled residuals:
    Min      1Q  Median      3Q     Max
-1.6531 -0.4373 -0.1646  0.1426  2.6313

Random effects:
 Groups     Name        Variance  Std.Dev.
 OLRE       (Intercept) 4.456e-01 6.675e-01
 ID_quadrat (Intercept) 1.011e+00 1.006e+00  plot:year  (Intercept) 1.429e+00 1.195e+00
 year       (Intercept) 5.635e-15 7.506e-08
 plot       (Intercept) 0.000e+00 0.000e+00
Number of obs: 4312, groups:  OLRE, 4312; ID_quadrat, 2156; plot:year, 86; year, 17; plot, 10

Fixed effects:
                                Estimate Std. Error z value Pr(>|z|)
(Intercept)                     -0.84765    0.33352  -2.542 0.011036 *
blockD                          -0.28663    0.27596  -1.039 0.298971
scale(year)                      0.11385    0.25128   0.453 0.650500
systS2                           2.21797    0.43765   5.068 4.02e-07 ***
systS3                           2.97934    0.42857   6.952 3.61e-12 ***
systS4                           2.64787    0.43488   6.089 1.14e-09 ***
systS5                           0.55059    0.45565   1.208 0.226912
timingavant1                     1.87971    0.10286  18.275  < 2e-16 ***
scale(year):systS2               0.40061    0.38882   1.030 0.302863
scale(year):systS3               0.44798    0.37297   1.201 0.229698
scale(year):systS4              -0.01245    0.36549  -0.034 0.972819
scale(year):systS5               1.06031    0.37957   2.793 0.005215 **
scale(year):timingavant1         0.07949    0.09954   0.799 0.424489
systS2:timingavant1             -0.36039    0.12128  -2.972 0.002963 **
systS3:timingavant1             -0.56704    0.11777  -4.815 1.47e-06 ***
systS4:timingavant1             -0.39785    0.11984  -3.320 0.000901 ***
systS5:timingavant1             -0.06724    0.14990  -0.449 0.653770
scale(year):systS2:timingavant1 -0.15246    0.11992  -1.271 0.203628
scale(year):systS3:timingavant1 -0.04057    0.11556  -0.351 0.725543
scale(year):systS4:timingavant1 -0.49134    0.11614  -4.231 2.33e-05 ***
scale(year):systS5:timingavant1 -0.34391    0.13427  -2.561 0.010429 *
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1


I wish to set up constrats to test if the slopes for scale(year):syst differ from zero at level 1 of timing.

It seems like we can do this with testInteractions but I'm not sure if my set up is correct:

testInteractions(mod1,custom=list(syst=c(1,0,0,0,0),timing=c(1,0)),
slope="scale(year)", adjustment="none")

The preceding code yields the following:

Adjusted slope for scale(year)
Chisq Test:
P-value adjustment method: none
                   Value Df  Chisq Pr(>Chisq)
syst1 : timing1 -0.82831  1 0.6464     0.4214

This doesn't seem correct because Value doesn't represent the slope for the first level of "syst" at the first level of "timing".

Could anyone shed their light?

Thank you very much!

Guillaume ADEUX



From @@brin@g50n @ending from gm@il@com  Wed Sep  5 17:49:57 2018
From: @@brin@g50n @ending from gm@il@com (Sabrina Gavini)
Date: Wed, 5 Sep 2018 12:49:57 -0300
Subject: [R-sig-ME] error when modeling beta-binomial distributed data using
 glmmTBM
Message-ID: <CAHyGrMLjFaXJ0ERFc2bRfYC41kMR4bZNJk6yWAhz9k5BdQbc4Q@mail.gmail.com>

Dear Sir.

I am trying to fit a mixed effect model to asses for effects upon the rate
of germinated polen grains. I started with a binomial distribution with a
model structure like this:

glmer(cbind(NGG,NGNG) ~ RH3*Altitude + AbH + Date3 + (1 |
Receptor/Code/Plant) +
                         (1 | Mountain/Community), data=database,
family="binomial",
                            control = glmerControl(optimizer="bobyqa"))

Where NGG is the number of successes (germinated grains per stigma) can
vary from 0 to e.g. 55.

NGNG is the number of failures (non-germinated grains) 0 to e.g. 80.

Here is the output from summary() and Anova()

Random effects:
 Groups                Name        Variance Std.Dev.
 Plant:(Code:Receptor) (Intercept) 0.4713   0.6865
 Code:Receptor         (Intercept) 0.7417   0.8612
 Receptor              (Intercept) 0.8514   0.9227
 Community:Mountain    (Intercept) 0.0000   0.0000
 Mountain              (Intercept) 0.2003   0.4475
Number of obs: 8082, groups:
Plant:(Code:Receptor), 2184; Code:Receptor, 436; Receptor, 88;
Community:Mountain, 9; Mountain, 3
Fixed effects:
                   Estimate Std. Error z value Pr(>|z|)
(Intercept)       -0.756624   0.408515  -1.852 0.064007 .
RH31               0.128719   0.031442   4.094 4.24e-05 ***
RH32               0.207303   0.059691   3.473 0.000515 ***
RH33              -0.011154   0.122811  -0.091 0.927635
Altitude1800      -0.142022   0.121090  -1.173 0.240851
Altitude2000       0.005628   0.172520   0.033 0.973974
AbH               -0.006041   0.002738  -2.206 0.027363 *
Date3february1    -0.162379   0.301456  -0.539 0.590129
Date3february2    -0.032708   0.320283  -0.102 0.918660
Date3january1     -0.358065   0.301815  -1.186 0.235475
Date3january2     -0.367096   0.296306  -1.239 0.215379
Date3march1        0.938912   0.397963   2.359 0.018310 *
Date3march2       -0.497544   0.561841  -0.886 0.375855
RH31:Altitude1800 -0.092963   0.047143  -1.972 0.048616 *
RH32:Altitude1800 -0.238150   0.084216  -2.828 0.004686 **
RH33:Altitude1800  0.007507   0.184352   0.041 0.967519
RH31:Altitude2000 -0.264065   0.055623  -4.747 2.06e-06 ***
RH32:Altitude2000 -0.335297   0.133998  -2.502 0.012341 *
RH33:Altitude2000  0.173064   0.299377   0.578 0.563209

Analysis of Deviance Table (Type III Wald chisquare tests)
Response: cbind(NGG, NGNG)
               Chisq Df Pr(>Chisq)
(Intercept)   3.4304  1   0.064007 .
RH3          23.0569  3  3.930e-05 ***
Altitude      1.6657  2   0.434800
AbH           4.8678  1   0.027363 *
Date3        23.6524  6   0.000605 ***
RH3:Altitude 30.8681  6  2.686e-05 ***

The issue is data seems to be over-dispersed, as indicated by this
function...

overdisp_fun <- function(model) {
  vpars <- function(m) {
    nrow(m)*(nrow(m)+1)/2
  }
  model.df <- sum(sapply(VarCorr(model), vpars)) + length(fixef(model))
  rdf <- nrow(model.frame(model))-model.df
  rp <- residuals(model, type = "pearson") # computes pearson residuals
  Pearson.chisq <- sum(rp^2)
  prat <- Pearson.chisq/rdf
  pval <- pchisq(Pearson.chisq, df = rdf, lower.tail = FALSE)
  c(chisq = Pearson.chisq, ratio = prat, rdf = rdf, p = pval)}

The output of this function upon my model was:

chisq = 1.334567e+04, ratio = 1.656201e+00, rdf = 8.058000e+03, p =
3.845911e-268

So I decided to try a beta-binomial in glmmTMB as follows (its important to
keep this hierarchical structure):

glmmTMB(cbind(NGG,NGNG) ~ RH3*Altitude + AbH + Date3  +  (1 |
Receptor/Code/Plant) +
                          (1 | Mountain/Community), data=database,
                          family=betabinomial(link = "logit"),
na.action = na.omit)

When I run it this error is displayed:

Error in nlminb(start = par, objective = fn, gradient = gr, control =
control$optCtrl) : (converted from warning) NA/NaN function evaluation

Is there something wrong in the model writing? I already checked for
posible issues in (
http://rstudio-pubs-static.s3.amazonaws.com/263877_d811720e434d47fb8430b8f0bb7f7da4.html)
but did not find any solution yet. I Know that kind of error sometimes came
out as a "warning" but the model still runs... but this was not the case.

The reason why I am scared by the output of my first binomial model, and
for which I try to run a beta-binomial, is that, according to the Anova (),
there is a significant interaction between two factors (richness of
heterospecific pollen (factor of 4 levels) and elevation (three-level
factor)) ... but according to the plots and lsmeans ( ) that interaction
does not seem to be real ... and possibly it is a consequence of an
inappropriate model owed to over-dispersion.

Just a few clarifications of my system so that you understand why I do a
binomial ...
"what I want to evaluate is the proportion of germinated grains; since I
saw many models using the number of polen grains as "succeses" and
non-germinated as "failure" (hence a proportion of succeses from a total
amount of tries (no of grains)). I used a poisson for another model when I
wanted to test for the "total number of polen grains". Here is the "rate of
polen germinated", so poisson is not an option here.  Always the response
variable (germinated grains) is equal or less to the total number of grains
(number of attempts). So a case where the response variable is 55,
denominator is equal (55, succes rate of "1") or exceeds the count (e.g.
55/80, 0.68 of succes rate)".


Thanks
Sabrina

	[[alternative HTML version deleted]]


From ru@@ell-lenth @ending from uiow@@edu  Wed Sep  5 18:38:44 2018
From: ru@@ell-lenth @ending from uiow@@edu (Lenth, Russell V)
Date: Wed, 5 Sep 2018 16:38:44 +0000
Subject: [R-sig-ME] 
 significance of slope (different than zero) in triple interaction
In-Reply-To: <CAENiVe8UhQ-xOucB5QKKsa=gbfgbgyZ0mrX6yo3Qq0FzktPD-g@mail.gmail.com>
References: <DM6PR04MB4380660646275726318CDBBDF1020@DM6PR04MB4380.namprd04.prod.outlook.com>
 <CAENiVe8UhQ-xOucB5QKKsa=gbfgbgyZ0mrX6yo3Qq0FzktPD-g@mail.gmail.com>
Message-ID: <DM6PR04MB438093AFFDFA08B439ADA4BBF1020@DM6PR04MB4380.namprd04.prod.outlook.com>

I?m confused. Do you want to test the slopes against zero, or against 1? I ask because you note that most of the confidence intervals include 1. To test against 1, add `null = 1.0` to the summary() call. To perform an equivalence test that the slopes do not differ from 1 by more than a specified threshold, also add `delta = (desired threshold)` to the call. See help(?summary.emmGrid?) for details.

Russ

From: Guillaume Adeux <guillaumesimon.a2 at gmail.com> 
Sent: Wednesday, September 5, 2018 10:13 AM
To: Lenth, Russell V <russell-lenth at uiowa.edu>
Cc: R-mixed models mailing list <r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] significance of slope (different than zero) in triple interaction

Hi Russell,
Thank you very much for your answer. It's very nice of you.
I ran what you recommended and it produced the following output:

> em=emtrends(mod1,~syst|timing,var="year")
> summary(em,infer=c(TRUE,TRUE))
timing = apr?s2:
 syst year.trend         SE  df  asymp.LCL  asymp.UCL z.ratio p.value
 S1   -0.9946823 0.05952514 Inf -1.1113495 -0.8780152 -16.710  <.0001
 S2   -0.8997828 0.07019881 Inf -1.0373699 -0.7621956 -12.818  <.0001
 S3   -0.8885606 0.06511346 Inf -1.0161806 -0.7609405 -13.646  <.0001
 S4   -0.9976324 0.06288404 Inf -1.1208828 -0.8743819 -15.865  <.0001
 S5   -0.7435081 0.06728649 Inf -0.8753872 -0.6116291 -11.050  <.0001

timing = avant1:
 syst year.trend         SE  df  asymp.LCL  asymp.UCL z.ratio p.value
 S1   -0.9758510 0.05696640 Inf -1.0875031 -0.8641990 -17.130  <.0001
 S2   -0.9170666 0.06973012 Inf -1.0537351 -0.7803980 -13.152  <.0001
 S3   -0.8793391 0.06482135 Inf -1.0063867 -0.7522916 -13.566  <.0001
 S4   -1.0951932 0.06253345 Inf -1.2177565 -0.9726298 -17.514  <.0001
 S5   -0.8061455 0.06589310 Inf -0.9352936 -0.6769974 -12.234  <.0001

However, I find this highly surprising because I know the slopes are not different than 0 for at least 4 of my systems at level "apr?s2" (which means after). We can actually see that the confidence interval for all levels of syst at "timing=apr?s2" embrace 1.
Do you have any explanation to this?
Thanks again for your interest.
Guillaume ADEUX

=========================
Le?mer. 5 sept. 2018 ??16:25, Lenth, Russell V <mailto:russell-lenth at uiowa.edu> a ?crit?:
I'm a little confused because you refer to predictors by different names in different places, and 'year' seems to be used as both a covariate and a grouping factor. But try something like this:

? ? library(emmeans)
? ? emt <- emtrends(mod, ~ syst:timing, var = "year")
? ? summary(emt, infer = c(TRUE, TRUE))

This will estimate the slope for year at each combination of the two factors syst and timing. (You may need to re-fit the model after creating an additional variable, say WEED$syear <- scale(WEED$year), and with syear in place of scale(year) in the model formula and the emtrends call. You may follow-up with call(s) to emmeans::contrast(emt, ...) to compare or contrast these slopes.

Hope that helps.
-- Russ

Russell V. Lenth? -? Professor Emeritus
Department of Statistics and Actuarial Science?? 
The University of Iowa ?-? Iowa City, IA 52242? USA?? 
Voice (319)335-0712 (Dept. office)? -? FAX (319)335-3017



-----Original Message-----
Date: Wed, 5 Sep 2018 10:43:39 +0200
From: Guillaume Adeux <mailto:guillaumesimon.a2 at gmail.com>
To: R-mixed models mailing list <mailto:r-sig-mixed-models at r-project.org>
Subject: [R-sig-ME] significance of slope (different than zero) in
? ? ? ? triple interaction


Hi mixmoders,

I have the following model:

mod=glmer(Weed_density~block+scale(year)*syst*timing+(1|year)+(1|plot)+(1|plot:year)+(1|ID_quadrat)+(1|OLRE)+offset(log(size_quadrat)),family=poisson(link="log"),dat=WEED)

I have a significant triple interaction between time : treatment : season.

Time is continuous, syst(=treatment) has 5 levels and season(=sampling
session) has two levels.

Here is the model output:

Generalized linear mixed model fit by maximum likelihood (Laplace
Approximation) ['glmerMod']
?Family: poisson? ( log )
Formula: WDall ~ block + scale(year) * syst * timing + (1 | year) + (1
|? ? ? plot) + (1 | plot:year) + (1 | ID_quadrat) + (1 | OLRE) +
offset(log(size_quadrat))
? ?Data: WEED_paired_2
Control: glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 2e+05))

? ? ?AIC? ? ? BIC? ?logLik deviance df.resid
?21206.3? 21371.9 -10577.2? 21154.3? ? ?4286

Scaled residuals:
? ? Min? ? ? 1Q? Median? ? ? 3Q? ? ?Max
-1.6531 -0.4373 -0.1646? 0.1426? 2.6313

Random effects:
?Groups? ? ?Name? ? ? ? Variance? Std.Dev.
?OLRE? ? ? ?(Intercept) 4.456e-01 6.675e-01
?ID_quadrat (Intercept) 1.011e+00 1.006e+00? plot:year? (Intercept) 1.429e+00 1.195e+00
?year? ? ? ?(Intercept) 5.635e-15 7.506e-08
?plot? ? ? ?(Intercept) 0.000e+00 0.000e+00
Number of obs: 4312, groups:? OLRE, 4312; ID_quadrat, 2156; plot:year, 86; year, 17; plot, 10

Fixed effects:
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? Estimate Std. Error z value Pr(>|z|)
(Intercept)? ? ? ? ? ? ? ? ? ? ?-0.84765? ? 0.33352? -2.542 0.011036 *
blockD? ? ? ? ? ? ? ? ? ? ? ? ? -0.28663? ? 0.27596? -1.039 0.298971
scale(year)? ? ? ? ? ? ? ? ? ? ? 0.11385? ? 0.25128? ?0.453 0.650500
systS2? ? ? ? ? ? ? ? ? ? ? ? ? ?2.21797? ? 0.43765? ?5.068 4.02e-07 ***
systS3? ? ? ? ? ? ? ? ? ? ? ? ? ?2.97934? ? 0.42857? ?6.952 3.61e-12 ***
systS4? ? ? ? ? ? ? ? ? ? ? ? ? ?2.64787? ? 0.43488? ?6.089 1.14e-09 ***
systS5? ? ? ? ? ? ? ? ? ? ? ? ? ?0.55059? ? 0.45565? ?1.208 0.226912
timingavant1? ? ? ? ? ? ? ? ? ? ?1.87971? ? 0.10286? 18.275? < 2e-16 ***
scale(year):systS2? ? ? ? ? ? ? ?0.40061? ? 0.38882? ?1.030 0.302863
scale(year):systS3? ? ? ? ? ? ? ?0.44798? ? 0.37297? ?1.201 0.229698
scale(year):systS4? ? ? ? ? ? ? -0.01245? ? 0.36549? -0.034 0.972819
scale(year):systS5? ? ? ? ? ? ? ?1.06031? ? 0.37957? ?2.793 0.005215 **
scale(year):timingavant1? ? ? ? ?0.07949? ? 0.09954? ?0.799 0.424489
systS2:timingavant1? ? ? ? ? ? ?-0.36039? ? 0.12128? -2.972 0.002963 **
systS3:timingavant1? ? ? ? ? ? ?-0.56704? ? 0.11777? -4.815 1.47e-06 ***
systS4:timingavant1? ? ? ? ? ? ?-0.39785? ? 0.11984? -3.320 0.000901 ***
systS5:timingavant1? ? ? ? ? ? ?-0.06724? ? 0.14990? -0.449 0.653770
scale(year):systS2:timingavant1 -0.15246? ? 0.11992? -1.271 0.203628
scale(year):systS3:timingavant1 -0.04057? ? 0.11556? -0.351 0.725543
scale(year):systS4:timingavant1 -0.49134? ? 0.11614? -4.231 2.33e-05 ***
scale(year):systS5:timingavant1 -0.34391? ? 0.13427? -2.561 0.010429 *
---
Signif. codes:? 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1


I wish to set up constrats to test if the slopes for scale(year):syst differ from zero at level 1 of timing.

It seems like we can do this with testInteractions but I'm not sure if my set up is correct:

testInteractions(mod1,custom=list(syst=c(1,0,0,0,0),timing=c(1,0)),
slope="scale(year)", adjustment="none")

The preceding code yields the following:

Adjusted slope for scale(year)
Chisq Test:
P-value adjustment method: none
? ? ? ? ? ? ? ? ? ?Value Df? Chisq Pr(>Chisq)
syst1 : timing1 -0.82831? 1 0.6464? ? ?0.4214

This doesn't seem correct because Value doesn't represent the slope for the first level of "syst" at the first level of "timing".

Could anyone shed their light?

Thank you very much!

Guillaume ADEUX


From bbolker @ending from gm@il@com  Wed Sep  5 18:50:58 2018
From: bbolker @ending from gm@il@com (Ben Bolker)
Date: Wed, 5 Sep 2018 12:50:58 -0400
Subject: [R-sig-ME] 
 significance of slope (different than zero) in triple interaction
In-Reply-To: <DM6PR04MB438093AFFDFA08B439ADA4BBF1020@DM6PR04MB4380.namprd04.prod.outlook.com>
References: <DM6PR04MB4380660646275726318CDBBDF1020@DM6PR04MB4380.namprd04.prod.outlook.com>
 <CAENiVe8UhQ-xOucB5QKKsa=gbfgbgyZ0mrX6yo3Qq0FzktPD-g@mail.gmail.com>
 <DM6PR04MB438093AFFDFA08B439ADA4BBF1020@DM6PR04MB4380.namprd04.prod.outlook.com>
Message-ID: <00135387-fda3-5ee3-084d-9a8d1c999f05@gmail.com>


 Even more confusing, your slope CI for apr?s2 seem to (mostly) include
-1, not 1 (except for S5).  Maybe use `null = -1.0` ?

On 2018-09-05 12:38 PM, Lenth, Russell V wrote:
> I?m confused. Do you want to test the slopes against zero, or against 1? I ask because you note that most of the confidence intervals include 1. To test against 1, add `null = 1.0` to the summary() call. To perform an equivalence test that the slopes do not differ from 1 by more than a specified threshold, also add `delta = (desired threshold)` to the call. See help(?summary.emmGrid?) for details.
> 
> Russ
> 
> From: Guillaume Adeux <guillaumesimon.a2 at gmail.com> 
> Sent: Wednesday, September 5, 2018 10:13 AM
> To: Lenth, Russell V <russell-lenth at uiowa.edu>
> Cc: R-mixed models mailing list <r-sig-mixed-models at r-project.org>
> Subject: Re: [R-sig-ME] significance of slope (different than zero) in triple interaction
> 
> Hi Russell,
> Thank you very much for your answer. It's very nice of you.
> I ran what you recommended and it produced the following output:
> 
>> em=emtrends(mod1,~syst|timing,var="year")
>> summary(em,infer=c(TRUE,TRUE))
> timing = apr?s2:
>  syst year.trend         SE  df  asymp.LCL  asymp.UCL z.ratio p.value
>  S1   -0.9946823 0.05952514 Inf -1.1113495 -0.8780152 -16.710  <.0001
>  S2   -0.8997828 0.07019881 Inf -1.0373699 -0.7621956 -12.818  <.0001
>  S3   -0.8885606 0.06511346 Inf -1.0161806 -0.7609405 -13.646  <.0001
>  S4   -0.9976324 0.06288404 Inf -1.1208828 -0.8743819 -15.865  <.0001
>  S5   -0.7435081 0.06728649 Inf -0.8753872 -0.6116291 -11.050  <.0001
> 
> timing = avant1:
>  syst year.trend         SE  df  asymp.LCL  asymp.UCL z.ratio p.value
>  S1   -0.9758510 0.05696640 Inf -1.0875031 -0.8641990 -17.130  <.0001
>  S2   -0.9170666 0.06973012 Inf -1.0537351 -0.7803980 -13.152  <.0001
>  S3   -0.8793391 0.06482135 Inf -1.0063867 -0.7522916 -13.566  <.0001
>  S4   -1.0951932 0.06253345 Inf -1.2177565 -0.9726298 -17.514  <.0001
>  S5   -0.8061455 0.06589310 Inf -0.9352936 -0.6769974 -12.234  <.0001
> 
> However, I find this highly surprising because I know the slopes are not different than 0 for at least 4 of my systems at level "apr?s2" (which means after). We can actually see that the confidence interval for all levels of syst at "timing=apr?s2" embrace 1.
> Do you have any explanation to this?
> Thanks again for your interest.
> Guillaume ADEUX
> 
> =========================
> Le?mer. 5 sept. 2018 ??16:25, Lenth, Russell V <mailto:russell-lenth at uiowa.edu> a ?crit?:
> I'm a little confused because you refer to predictors by different names in different places, and 'year' seems to be used as both a covariate and a grouping factor. But try something like this:
> 
> ? ? library(emmeans)
> ? ? emt <- emtrends(mod, ~ syst:timing, var = "year")
> ? ? summary(emt, infer = c(TRUE, TRUE))
> 
> This will estimate the slope for year at each combination of the two factors syst and timing. (You may need to re-fit the model after creating an additional variable, say WEED$syear <- scale(WEED$year), and with syear in place of scale(year) in the model formula and the emtrends call. You may follow-up with call(s) to emmeans::contrast(emt, ...) to compare or contrast these slopes.
> 
> Hope that helps.
> -- Russ
> 
> Russell V. Lenth? -? Professor Emeritus
> Department of Statistics and Actuarial Science?? 
> The University of Iowa ?-? Iowa City, IA 52242? USA?? 
> Voice (319)335-0712 (Dept. office)? -? FAX (319)335-3017
> 
> 
> 
> -----Original Message-----
> Date: Wed, 5 Sep 2018 10:43:39 +0200
> From: Guillaume Adeux <mailto:guillaumesimon.a2 at gmail.com>
> To: R-mixed models mailing list <mailto:r-sig-mixed-models at r-project.org>
> Subject: [R-sig-ME] significance of slope (different than zero) in
> ? ? ? ? triple interaction
> 
> 
> Hi mixmoders,
> 
> I have the following model:
> 
> mod=glmer(Weed_density~block+scale(year)*syst*timing+(1|year)+(1|plot)+(1|plot:year)+(1|ID_quadrat)+(1|OLRE)+offset(log(size_quadrat)),family=poisson(link="log"),dat=WEED)
> 
> I have a significant triple interaction between time : treatment : season.
> 
> Time is continuous, syst(=treatment) has 5 levels and season(=sampling
> session) has two levels.
> 
> Here is the model output:
> 
> Generalized linear mixed model fit by maximum likelihood (Laplace
> Approximation) ['glmerMod']
> ?Family: poisson? ( log )
> Formula: WDall ~ block + scale(year) * syst * timing + (1 | year) + (1
> |? ? ? plot) + (1 | plot:year) + (1 | ID_quadrat) + (1 | OLRE) +
> offset(log(size_quadrat))
> ? ?Data: WEED_paired_2
> Control: glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 2e+05))
> 
> ? ? ?AIC? ? ? BIC? ?logLik deviance df.resid
> ?21206.3? 21371.9 -10577.2? 21154.3? ? ?4286
> 
> Scaled residuals:
> ? ? Min? ? ? 1Q? Median? ? ? 3Q? ? ?Max
> -1.6531 -0.4373 -0.1646? 0.1426? 2.6313
> 
> Random effects:
> ?Groups? ? ?Name? ? ? ? Variance? Std.Dev.
> ?OLRE? ? ? ?(Intercept) 4.456e-01 6.675e-01
> ?ID_quadrat (Intercept) 1.011e+00 1.006e+00? plot:year? (Intercept) 1.429e+00 1.195e+00
> ?year? ? ? ?(Intercept) 5.635e-15 7.506e-08
> ?plot? ? ? ?(Intercept) 0.000e+00 0.000e+00
> Number of obs: 4312, groups:? OLRE, 4312; ID_quadrat, 2156; plot:year, 86; year, 17; plot, 10
> 
> Fixed effects:
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? Estimate Std. Error z value Pr(>|z|)
> (Intercept)? ? ? ? ? ? ? ? ? ? ?-0.84765? ? 0.33352? -2.542 0.011036 *
> blockD? ? ? ? ? ? ? ? ? ? ? ? ? -0.28663? ? 0.27596? -1.039 0.298971
> scale(year)? ? ? ? ? ? ? ? ? ? ? 0.11385? ? 0.25128? ?0.453 0.650500
> systS2? ? ? ? ? ? ? ? ? ? ? ? ? ?2.21797? ? 0.43765? ?5.068 4.02e-07 ***
> systS3? ? ? ? ? ? ? ? ? ? ? ? ? ?2.97934? ? 0.42857? ?6.952 3.61e-12 ***
> systS4? ? ? ? ? ? ? ? ? ? ? ? ? ?2.64787? ? 0.43488? ?6.089 1.14e-09 ***
> systS5? ? ? ? ? ? ? ? ? ? ? ? ? ?0.55059? ? 0.45565? ?1.208 0.226912
> timingavant1? ? ? ? ? ? ? ? ? ? ?1.87971? ? 0.10286? 18.275? < 2e-16 ***
> scale(year):systS2? ? ? ? ? ? ? ?0.40061? ? 0.38882? ?1.030 0.302863
> scale(year):systS3? ? ? ? ? ? ? ?0.44798? ? 0.37297? ?1.201 0.229698
> scale(year):systS4? ? ? ? ? ? ? -0.01245? ? 0.36549? -0.034 0.972819
> scale(year):systS5? ? ? ? ? ? ? ?1.06031? ? 0.37957? ?2.793 0.005215 **
> scale(year):timingavant1? ? ? ? ?0.07949? ? 0.09954? ?0.799 0.424489
> systS2:timingavant1? ? ? ? ? ? ?-0.36039? ? 0.12128? -2.972 0.002963 **
> systS3:timingavant1? ? ? ? ? ? ?-0.56704? ? 0.11777? -4.815 1.47e-06 ***
> systS4:timingavant1? ? ? ? ? ? ?-0.39785? ? 0.11984? -3.320 0.000901 ***
> systS5:timingavant1? ? ? ? ? ? ?-0.06724? ? 0.14990? -0.449 0.653770
> scale(year):systS2:timingavant1 -0.15246? ? 0.11992? -1.271 0.203628
> scale(year):systS3:timingavant1 -0.04057? ? 0.11556? -0.351 0.725543
> scale(year):systS4:timingavant1 -0.49134? ? 0.11614? -4.231 2.33e-05 ***
> scale(year):systS5:timingavant1 -0.34391? ? 0.13427? -2.561 0.010429 *
> ---
> Signif. codes:? 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> 
> 
> I wish to set up constrats to test if the slopes for scale(year):syst differ from zero at level 1 of timing.
> 
> It seems like we can do this with testInteractions but I'm not sure if my set up is correct:
> 
> testInteractions(mod1,custom=list(syst=c(1,0,0,0,0),timing=c(1,0)),
> slope="scale(year)", adjustment="none")
> 
> The preceding code yields the following:
> 
> Adjusted slope for scale(year)
> Chisq Test:
> P-value adjustment method: none
> ? ? ? ? ? ? ? ? ? ?Value Df? Chisq Pr(>Chisq)
> syst1 : timing1 -0.82831? 1 0.6464? ? ?0.4214
> 
> This doesn't seem correct because Value doesn't represent the slope for the first level of "syst" at the first level of "timing".
> 
> Could anyone shed their light?
> 
> Thank you very much!
> 
> Guillaume ADEUX
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From guill@ume@imon@@2 @ending from gm@il@com  Wed Sep  5 19:08:23 2018
From: guill@ume@imon@@2 @ending from gm@il@com (Guillaume Adeux)
Date: Wed, 5 Sep 2018 19:08:23 +0200
Subject: [R-sig-ME] 
 significance of slope (different than zero) in triple interaction
In-Reply-To: <00135387-fda3-5ee3-084d-9a8d1c999f05@gmail.com>
References: <DM6PR04MB4380660646275726318CDBBDF1020@DM6PR04MB4380.namprd04.prod.outlook.com>
 <CAENiVe8UhQ-xOucB5QKKsa=gbfgbgyZ0mrX6yo3Qq0FzktPD-g@mail.gmail.com>
 <DM6PR04MB438093AFFDFA08B439ADA4BBF1020@DM6PR04MB4380.namprd04.prod.outlook.com>
 <00135387-fda3-5ee3-084d-9a8d1c999f05@gmail.com>
Message-ID: <CAENiVe-9QWJB4aoEVRrpcbvV6vi=0TrhUnaQL+C-JaMNOyJqzg@mail.gmail.com>

Sorry for the trouble.

What I want to test is that the slopes are effectively increasing or
decreasing; that back on the original scale, the regression line is not
parralel to the x-axis. This must be possible but I don't even know if this
is the way to go.

Thank you very much for you interest,

Guillaume ADEUX

Le mer. 5 sept. 2018 ? 18:54, Ben Bolker <bbolker at gmail.com> a ?crit :

>
>  Even more confusing, your slope CI for apr?s2 seem to (mostly) include
> -1, not 1 (except for S5).  Maybe use `null = -1.0` ?
>
> On 2018-09-05 12:38 PM, Lenth, Russell V wrote:
> > I?m confused. Do you want to test the slopes against zero, or against 1?
> I ask because you note that most of the confidence intervals include 1. To
> test against 1, add `null = 1.0` to the summary() call. To perform an
> equivalence test that the slopes do not differ from 1 by more than a
> specified threshold, also add `delta = (desired threshold)` to the call.
> See help(?summary.emmGrid?) for details.
> >
> > Russ
> >
> > From: Guillaume Adeux <guillaumesimon.a2 at gmail.com>
> > Sent: Wednesday, September 5, 2018 10:13 AM
> > To: Lenth, Russell V <russell-lenth at uiowa.edu>
> > Cc: R-mixed models mailing list <r-sig-mixed-models at r-project.org>
> > Subject: Re: [R-sig-ME] significance of slope (different than zero) in
> triple interaction
> >
> > Hi Russell,
> > Thank you very much for your answer. It's very nice of you.
> > I ran what you recommended and it produced the following output:
> >
> >> em=emtrends(mod1,~syst|timing,var="year")
> >> summary(em,infer=c(TRUE,TRUE))
> > timing = apr?s2:
> >  syst year.trend         SE  df  asymp.LCL  asymp.UCL z.ratio p.value
> >  S1   -0.9946823 0.05952514 Inf -1.1113495 -0.8780152 -16.710  <.0001
> >  S2   -0.8997828 0.07019881 Inf -1.0373699 -0.7621956 -12.818  <.0001
> >  S3   -0.8885606 0.06511346 Inf -1.0161806 -0.7609405 -13.646  <.0001
> >  S4   -0.9976324 0.06288404 Inf -1.1208828 -0.8743819 -15.865  <.0001
> >  S5   -0.7435081 0.06728649 Inf -0.8753872 -0.6116291 -11.050  <.0001
> >
> > timing = avant1:
> >  syst year.trend         SE  df  asymp.LCL  asymp.UCL z.ratio p.value
> >  S1   -0.9758510 0.05696640 Inf -1.0875031 -0.8641990 -17.130  <.0001
> >  S2   -0.9170666 0.06973012 Inf -1.0537351 -0.7803980 -13.152  <.0001
> >  S3   -0.8793391 0.06482135 Inf -1.0063867 -0.7522916 -13.566  <.0001
> >  S4   -1.0951932 0.06253345 Inf -1.2177565 -0.9726298 -17.514  <.0001
> >  S5   -0.8061455 0.06589310 Inf -0.9352936 -0.6769974 -12.234  <.0001
> >
> > However, I find this highly surprising because I know the slopes are not
> different than 0 for at least 4 of my systems at level "apr?s2" (which
> means after). We can actually see that the confidence interval for all
> levels of syst at "timing=apr?s2" embrace 1.
> > Do you have any explanation to this?
> > Thanks again for your interest.
> > Guillaume ADEUX
> >
> > =========================
> > Le mer. 5 sept. 2018 ? 16:25, Lenth, Russell V <mailto:
> russell-lenth at uiowa.edu> a ?crit :
> > I'm a little confused because you refer to predictors by different names
> in different places, and 'year' seems to be used as both a covariate and a
> grouping factor. But try something like this:
> >
> >     library(emmeans)
> >     emt <- emtrends(mod, ~ syst:timing, var = "year")
> >     summary(emt, infer = c(TRUE, TRUE))
> >
> > This will estimate the slope for year at each combination of the two
> factors syst and timing. (You may need to re-fit the model after creating
> an additional variable, say WEED$syear <- scale(WEED$year), and with syear
> in place of scale(year) in the model formula and the emtrends call. You may
> follow-up with call(s) to emmeans::contrast(emt, ...) to compare or
> contrast these slopes.
> >
> > Hope that helps.
> > -- Russ
> >
> > Russell V. Lenth  -  Professor Emeritus
> > Department of Statistics and Actuarial Science
> > The University of Iowa  -  Iowa City, IA 52242  USA
> > Voice (319)335-0712 (Dept. office)  -  FAX (319)335-3017
> >
> >
> >
> > -----Original Message-----
> > Date: Wed, 5 Sep 2018 10:43:39 +0200
> > From: Guillaume Adeux <mailto:guillaumesimon.a2 at gmail.com>
> > To: R-mixed models mailing list <mailto:r-sig-mixed-models at r-project.org
> >
> > Subject: [R-sig-ME] significance of slope (different than zero) in
> >         triple interaction
> >
> >
> > Hi mixmoders,
> >
> > I have the following model:
> >
> >
> mod=glmer(Weed_density~block+scale(year)*syst*timing+(1|year)+(1|plot)+(1|plot:year)+(1|ID_quadrat)+(1|OLRE)+offset(log(size_quadrat)),family=poisson(link="log"),dat=WEED)
> >
> > I have a significant triple interaction between time : treatment :
> season.
> >
> > Time is continuous, syst(=treatment) has 5 levels and season(=sampling
> > session) has two levels.
> >
> > Here is the model output:
> >
> > Generalized linear mixed model fit by maximum likelihood (Laplace
> > Approximation) ['glmerMod']
> >  Family: poisson  ( log )
> > Formula: WDall ~ block + scale(year) * syst * timing + (1 | year) + (1
> > |      plot) + (1 | plot:year) + (1 | ID_quadrat) + (1 | OLRE) +
> > offset(log(size_quadrat))
> >    Data: WEED_paired_2
> > Control: glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun =
> 2e+05))
> >
> >      AIC      BIC   logLik deviance df.resid
> >  21206.3  21371.9 -10577.2  21154.3     4286
> >
> > Scaled residuals:
> >     Min      1Q  Median      3Q     Max
> > -1.6531 -0.4373 -0.1646  0.1426  2.6313
> >
> > Random effects:
> >  Groups     Name        Variance  Std.Dev.
> >  OLRE       (Intercept) 4.456e-01 6.675e-01
> >  ID_quadrat (Intercept) 1.011e+00 1.006e+00  plot:year  (Intercept)
> 1.429e+00 1.195e+00
> >  year       (Intercept) 5.635e-15 7.506e-08
> >  plot       (Intercept) 0.000e+00 0.000e+00
> > Number of obs: 4312, groups:  OLRE, 4312; ID_quadrat, 2156; plot:year,
> 86; year, 17; plot, 10
> >
> > Fixed effects:
> >                                 Estimate Std. Error z value Pr(>|z|)
> > (Intercept)                     -0.84765    0.33352  -2.542 0.011036 *
> > blockD                          -0.28663    0.27596  -1.039 0.298971
> > scale(year)                      0.11385    0.25128   0.453 0.650500
> > systS2                           2.21797    0.43765   5.068 4.02e-07 ***
> > systS3                           2.97934    0.42857   6.952 3.61e-12 ***
> > systS4                           2.64787    0.43488   6.089 1.14e-09 ***
> > systS5                           0.55059    0.45565   1.208 0.226912
> > timingavant1                     1.87971    0.10286  18.275  < 2e-16 ***
> > scale(year):systS2               0.40061    0.38882   1.030 0.302863
> > scale(year):systS3               0.44798    0.37297   1.201 0.229698
> > scale(year):systS4              -0.01245    0.36549  -0.034 0.972819
> > scale(year):systS5               1.06031    0.37957   2.793 0.005215 **
> > scale(year):timingavant1         0.07949    0.09954   0.799 0.424489
> > systS2:timingavant1             -0.36039    0.12128  -2.972 0.002963 **
> > systS3:timingavant1             -0.56704    0.11777  -4.815 1.47e-06 ***
> > systS4:timingavant1             -0.39785    0.11984  -3.320 0.000901 ***
> > systS5:timingavant1             -0.06724    0.14990  -0.449 0.653770
> > scale(year):systS2:timingavant1 -0.15246    0.11992  -1.271 0.203628
> > scale(year):systS3:timingavant1 -0.04057    0.11556  -0.351 0.725543
> > scale(year):systS4:timingavant1 -0.49134    0.11614  -4.231 2.33e-05 ***
> > scale(year):systS5:timingavant1 -0.34391    0.13427  -2.561 0.010429 *
> > ---
> > Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> >
> >
> > I wish to set up constrats to test if the slopes for scale(year):syst
> differ from zero at level 1 of timing.
> >
> > It seems like we can do this with testInteractions but I'm not sure if
> my set up is correct:
> >
> > testInteractions(mod1,custom=list(syst=c(1,0,0,0,0),timing=c(1,0)),
> > slope="scale(year)", adjustment="none")
> >
> > The preceding code yields the following:
> >
> > Adjusted slope for scale(year)
> > Chisq Test:
> > P-value adjustment method: none
> >                    Value Df  Chisq Pr(>Chisq)
> > syst1 : timing1 -0.82831  1 0.6464     0.4214
> >
> > This doesn't seem correct because Value doesn't represent the slope for
> the first level of "syst" at the first level of "timing".
> >
> > Could anyone shed their light?
> >
> > Thank you very much!
> >
> > Guillaume ADEUX
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From guill@ume@imon@@2 @ending from gm@il@com  Thu Sep  6 12:03:23 2018
From: guill@ume@imon@@2 @ending from gm@il@com (Guillaume Adeux)
Date: Thu, 6 Sep 2018 12:03:23 +0200
Subject: [R-sig-ME] 
 significance of slope (different than zero) in triple interaction
In-Reply-To: <CAENiVe-9QWJB4aoEVRrpcbvV6vi=0TrhUnaQL+C-JaMNOyJqzg@mail.gmail.com>
References: <DM6PR04MB4380660646275726318CDBBDF1020@DM6PR04MB4380.namprd04.prod.outlook.com>
 <CAENiVe8UhQ-xOucB5QKKsa=gbfgbgyZ0mrX6yo3Qq0FzktPD-g@mail.gmail.com>
 <DM6PR04MB438093AFFDFA08B439ADA4BBF1020@DM6PR04MB4380.namprd04.prod.outlook.com>
 <00135387-fda3-5ee3-084d-9a8d1c999f05@gmail.com>
 <CAENiVe-9QWJB4aoEVRrpcbvV6vi=0TrhUnaQL+C-JaMNOyJqzg@mail.gmail.com>
Message-ID: <CAENiVe-evAKTXxJXrzq2GxjP2ZeH2+XuWoUH3ZNJ46WR9nNOKw@mail.gmail.com>

Ok i found out that was messing up everything.

When an offset is included in the model, the slopes produced by
emtrends(model,~factor1|factor2,"num_var") are very different than the ones
that can be computed with the model output (the coefficients for the slopes
in the output need to be divided by the standard deviation of "num_var" in
case of a scaled(num_var) in order to be directly comparable with emtrends
output). I don't know what emtrends is doing in this case.

However, the slopes produced by emtrends(model,~factor1|factor2,"num_var")
are equivalent to the back transformed scaled coefficients of slopes of the
summary output when the offset is taken out. Is there any way to keep the
offset and have the correct values of slope? I do not know.

To come back to my original questions, I was indeed looking for the "null"
argument which I need to set to 0 because the tests are done on the scale
of the linear predictor and a slope of 0 on the log scale is equivalent to
a multiplicative factor of 1 on the original scale (which means a flat
regression line - no effect).

Don't hesitate to give me your feedback if you believe something I have
said above is incorrect.

Thank you a thousand time for you help.

Guillaume ADEUX


Le mer. 5 sept. 2018 ? 19:08, Guillaume Adeux <guillaumesimon.a2 at gmail.com>
a ?crit :

> Sorry for the trouble.
>
> What I want to test is that the slopes are effectively increasing or
> decreasing; that back on the original scale, the regression line is not
> parralel to the x-axis. This must be possible but I don't even know if this
> is the way to go.
>
> Thank you very much for you interest,
>
> Guillaume ADEUX
>
> Le mer. 5 sept. 2018 ? 18:54, Ben Bolker <bbolker at gmail.com> a ?crit :
>
>>
>>  Even more confusing, your slope CI for apr?s2 seem to (mostly) include
>> -1, not 1 (except for S5).  Maybe use `null = -1.0` ?
>>
>> On 2018-09-05 12:38 PM, Lenth, Russell V wrote:
>> > I?m confused. Do you want to test the slopes against zero, or against
>> 1? I ask because you note that most of the confidence intervals include 1.
>> To test against 1, add `null = 1.0` to the summary() call. To perform an
>> equivalence test that the slopes do not differ from 1 by more than a
>> specified threshold, also add `delta = (desired threshold)` to the call.
>> See help(?summary.emmGrid?) for details.
>> >
>> > Russ
>> >
>> > From: Guillaume Adeux <guillaumesimon.a2 at gmail.com>
>> > Sent: Wednesday, September 5, 2018 10:13 AM
>> > To: Lenth, Russell V <russell-lenth at uiowa.edu>
>> > Cc: R-mixed models mailing list <r-sig-mixed-models at r-project.org>
>> > Subject: Re: [R-sig-ME] significance of slope (different than zero) in
>> triple interaction
>> >
>> > Hi Russell,
>> > Thank you very much for your answer. It's very nice of you.
>> > I ran what you recommended and it produced the following output:
>> >
>> >> em=emtrends(mod1,~syst|timing,var="year")
>> >> summary(em,infer=c(TRUE,TRUE))
>> > timing = apr?s2:
>> >  syst year.trend         SE  df  asymp.LCL  asymp.UCL z.ratio p.value
>> >  S1   -0.9946823 0.05952514 Inf -1.1113495 -0.8780152 -16.710  <.0001
>> >  S2   -0.8997828 0.07019881 Inf -1.0373699 -0.7621956 -12.818  <.0001
>> >  S3   -0.8885606 0.06511346 Inf -1.0161806 -0.7609405 -13.646  <.0001
>> >  S4   -0.9976324 0.06288404 Inf -1.1208828 -0.8743819 -15.865  <.0001
>> >  S5   -0.7435081 0.06728649 Inf -0.8753872 -0.6116291 -11.050  <.0001
>> >
>> > timing = avant1:
>> >  syst year.trend         SE  df  asymp.LCL  asymp.UCL z.ratio p.value
>> >  S1   -0.9758510 0.05696640 Inf -1.0875031 -0.8641990 -17.130  <.0001
>> >  S2   -0.9170666 0.06973012 Inf -1.0537351 -0.7803980 -13.152  <.0001
>> >  S3   -0.8793391 0.06482135 Inf -1.0063867 -0.7522916 -13.566  <.0001
>> >  S4   -1.0951932 0.06253345 Inf -1.2177565 -0.9726298 -17.514  <.0001
>> >  S5   -0.8061455 0.06589310 Inf -0.9352936 -0.6769974 -12.234  <.0001
>> >
>> > However, I find this highly surprising because I know the slopes are
>> not different than 0 for at least 4 of my systems at level "apr?s2" (which
>> means after). We can actually see that the confidence interval for all
>> levels of syst at "timing=apr?s2" embrace 1.
>> > Do you have any explanation to this?
>> > Thanks again for your interest.
>> > Guillaume ADEUX
>> >
>> > =========================
>> > Le mer. 5 sept. 2018 ? 16:25, Lenth, Russell V <mailto:
>> russell-lenth at uiowa.edu> a ?crit :
>> > I'm a little confused because you refer to predictors by different
>> names in different places, and 'year' seems to be used as both a covariate
>> and a grouping factor. But try something like this:
>> >
>> >     library(emmeans)
>> >     emt <- emtrends(mod, ~ syst:timing, var = "year")
>> >     summary(emt, infer = c(TRUE, TRUE))
>> >
>> > This will estimate the slope for year at each combination of the two
>> factors syst and timing. (You may need to re-fit the model after creating
>> an additional variable, say WEED$syear <- scale(WEED$year), and with syear
>> in place of scale(year) in the model formula and the emtrends call. You may
>> follow-up with call(s) to emmeans::contrast(emt, ...) to compare or
>> contrast these slopes.
>> >
>> > Hope that helps.
>> > -- Russ
>> >
>> > Russell V. Lenth  -  Professor Emeritus
>> > Department of Statistics and Actuarial Science
>> > The University of Iowa  -  Iowa City, IA 52242  USA
>> > Voice (319)335-0712 (Dept. office)  -  FAX (319)335-3017
>> >
>> >
>> >
>> > -----Original Message-----
>> > Date: Wed, 5 Sep 2018 10:43:39 +0200
>> > From: Guillaume Adeux <mailto:guillaumesimon.a2 at gmail.com>
>> > To: R-mixed models mailing list <mailto:
>> r-sig-mixed-models at r-project.org>
>> > Subject: [R-sig-ME] significance of slope (different than zero) in
>> >         triple interaction
>> >
>> >
>> > Hi mixmoders,
>> >
>> > I have the following model:
>> >
>> >
>> mod=glmer(Weed_density~block+scale(year)*syst*timing+(1|year)+(1|plot)+(1|plot:year)+(1|ID_quadrat)+(1|OLRE)+offset(log(size_quadrat)),family=poisson(link="log"),dat=WEED)
>> >
>> > I have a significant triple interaction between time : treatment :
>> season.
>> >
>> > Time is continuous, syst(=treatment) has 5 levels and season(=sampling
>> > session) has two levels.
>> >
>> > Here is the model output:
>> >
>> > Generalized linear mixed model fit by maximum likelihood (Laplace
>> > Approximation) ['glmerMod']
>> >  Family: poisson  ( log )
>> > Formula: WDall ~ block + scale(year) * syst * timing + (1 | year) + (1
>> > |      plot) + (1 | plot:year) + (1 | ID_quadrat) + (1 | OLRE) +
>> > offset(log(size_quadrat))
>> >    Data: WEED_paired_2
>> > Control: glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun =
>> 2e+05))
>> >
>> >      AIC      BIC   logLik deviance df.resid
>> >  21206.3  21371.9 -10577.2  21154.3     4286
>> >
>> > Scaled residuals:
>> >     Min      1Q  Median      3Q     Max
>> > -1.6531 -0.4373 -0.1646  0.1426  2.6313
>> >
>> > Random effects:
>> >  Groups     Name        Variance  Std.Dev.
>> >  OLRE       (Intercept) 4.456e-01 6.675e-01
>> >  ID_quadrat (Intercept) 1.011e+00 1.006e+00  plot:year  (Intercept)
>> 1.429e+00 1.195e+00
>> >  year       (Intercept) 5.635e-15 7.506e-08
>> >  plot       (Intercept) 0.000e+00 0.000e+00
>> > Number of obs: 4312, groups:  OLRE, 4312; ID_quadrat, 2156; plot:year,
>> 86; year, 17; plot, 10
>> >
>> > Fixed effects:
>> >                                 Estimate Std. Error z value Pr(>|z|)
>> > (Intercept)                     -0.84765    0.33352  -2.542 0.011036 *
>> > blockD                          -0.28663    0.27596  -1.039 0.298971
>> > scale(year)                      0.11385    0.25128   0.453 0.650500
>> > systS2                           2.21797    0.43765   5.068 4.02e-07 ***
>> > systS3                           2.97934    0.42857   6.952 3.61e-12 ***
>> > systS4                           2.64787    0.43488   6.089 1.14e-09 ***
>> > systS5                           0.55059    0.45565   1.208 0.226912
>> > timingavant1                     1.87971    0.10286  18.275  < 2e-16 ***
>> > scale(year):systS2               0.40061    0.38882   1.030 0.302863
>> > scale(year):systS3               0.44798    0.37297   1.201 0.229698
>> > scale(year):systS4              -0.01245    0.36549  -0.034 0.972819
>> > scale(year):systS5               1.06031    0.37957   2.793 0.005215 **
>> > scale(year):timingavant1         0.07949    0.09954   0.799 0.424489
>> > systS2:timingavant1             -0.36039    0.12128  -2.972 0.002963 **
>> > systS3:timingavant1             -0.56704    0.11777  -4.815 1.47e-06 ***
>> > systS4:timingavant1             -0.39785    0.11984  -3.320 0.000901 ***
>> > systS5:timingavant1             -0.06724    0.14990  -0.449 0.653770
>> > scale(year):systS2:timingavant1 -0.15246    0.11992  -1.271 0.203628
>> > scale(year):systS3:timingavant1 -0.04057    0.11556  -0.351 0.725543
>> > scale(year):systS4:timingavant1 -0.49134    0.11614  -4.231 2.33e-05 ***
>> > scale(year):systS5:timingavant1 -0.34391    0.13427  -2.561 0.010429 *
>> > ---
>> > Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>> >
>> >
>> > I wish to set up constrats to test if the slopes for scale(year):syst
>> differ from zero at level 1 of timing.
>> >
>> > It seems like we can do this with testInteractions but I'm not sure if
>> my set up is correct:
>> >
>> > testInteractions(mod1,custom=list(syst=c(1,0,0,0,0),timing=c(1,0)),
>> > slope="scale(year)", adjustment="none")
>> >
>> > The preceding code yields the following:
>> >
>> > Adjusted slope for scale(year)
>> > Chisq Test:
>> > P-value adjustment method: none
>> >                    Value Df  Chisq Pr(>Chisq)
>> > syst1 : timing1 -0.82831  1 0.6464     0.4214
>> >
>> > This doesn't seem correct because Value doesn't represent the slope for
>> the first level of "syst" at the first level of "timing".
>> >
>> > Could anyone shed their light?
>> >
>> > Thank you very much!
>> >
>> > Guillaume ADEUX
>> >
>> > _______________________________________________
>> > R-sig-mixed-models at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>

	[[alternative HTML version deleted]]


From ru@@ell-lenth @ending from uiow@@edu  Thu Sep  6 17:05:24 2018
From: ru@@ell-lenth @ending from uiow@@edu (Lenth, Russell V)
Date: Thu, 6 Sep 2018 15:05:24 +0000
Subject: [R-sig-ME] 
 significance of slope (different than zero) in triple interaction
In-Reply-To: <CAENiVe-evAKTXxJXrzq2GxjP2ZeH2+XuWoUH3ZNJ46WR9nNOKw@mail.gmail.com>
References: <DM6PR04MB4380660646275726318CDBBDF1020@DM6PR04MB4380.namprd04.prod.outlook.com>
 <CAENiVe8UhQ-xOucB5QKKsa=gbfgbgyZ0mrX6yo3Qq0FzktPD-g@mail.gmail.com>
 <DM6PR04MB438093AFFDFA08B439ADA4BBF1020@DM6PR04MB4380.namprd04.prod.outlook.com>
 <00135387-fda3-5ee3-084d-9a8d1c999f05@gmail.com>
 <CAENiVe-9QWJB4aoEVRrpcbvV6vi=0TrhUnaQL+C-JaMNOyJqzg@mail.gmail.com>
 <CAENiVe-evAKTXxJXrzq2GxjP2ZeH2+XuWoUH3ZNJ46WR9nNOKw@mail.gmail.com>
Message-ID: <DM6PR04MB43804283888136AD4F340182F1010@DM6PR04MB4380.namprd04.prod.outlook.com>

The emtrends function computes difference quotients using the 'var' argument, which is actually processed as an expression. That makes it possible to scale the slopes. For example (with a different model):

require(emmeans)
fiber.lm <- lm(strength ~ diameter*machine, data=fiber)

summary(emtrends(fiber.lm, "machine", var = "diameter"), infer = TRUE)
## machine diameter.trend        SE df  lower.CL upper.CL t.ratio p.value
## A            1.1042781 0.1936634  9 0.6661810 1.542375   5.702  0.0003
## B            0.8571429 0.2238228  9 0.3508205 1.363465   3.830  0.0040
## C            0.8641975 0.2080707  9 0.3935090 1.334886   4.153  0.0025
## Confidence level used: 0.95 

summary(emtrends(fiber.lm, "machine", var = "2*diameter"), infer = TRUE)
## machine 2*diameter.trend        SE df  lower.CL  upper.CL t.ratio p.value
## A              0.5521390 0.0968317  9 0.3330905 0.7711876   5.702  0.0003
## B              0.4285714 0.1119114  9 0.1754102 0.6817326   3.830  0.0040
## C              0.4320988 0.1040353  9 0.1967545 0.6674430   4.153  0.0025
## Confidence level used: 0.95## Confidence level used: 0.95

The second table has estimates and SEs half as large, because we are differentiating with respect to 2*diameter. Note however that scaling the slopes has no effect on the t (or z) ratios or on the P values. The tests given, in both cases, are tests against the slope being zero. In your own results earlier in this discussion, all the slopes are decidedly negative, no matter how you scale them. 

Russ

PS to Ben: Good call -- I should have said -1.

======================
From: Guillaume Adeux <guillaumesimon.a2 at gmail.com> 
Sent: Thursday, September 6, 2018 5:03 AM
To: Ben Bolker <bbolker at gmail.com>; Lenth, Russell V <russell-lenth at uiowa.edu>
Cc: R-mixed models mailing list <r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] significance of slope (different than zero) in triple interaction

Ok i found out that was messing up everything.
When an offset is included in the model, the slopes produced by emtrends(model,~factor1|factor2,"num_var") are very different than the ones that can be computed with the model output (the coefficients for the slopes in the output need to be divided by the standard deviation of "num_var" in case of a scaled(num_var) in order to be directly comparable with emtrends output). I don't know what emtrends is doing in this case.
However, the slopes produced by emtrends(model,~factor1|factor2,"num_var") are equivalent to the back transformed scaled coefficients of slopes of the summary output when the offset is taken out. Is there any way to keep the offset and have the correct values of slope? I do not know.
To come back to my original questions, I was indeed looking for the "null" argument which I need to set to 0 because the tests are done on the scale of the linear predictor and a slope of 0 on the log scale is equivalent to a multiplicative factor of 1 on the original scale (which means a flat regression line - no effect).
Don't hesitate to give me your feedback if you believe something I have said above is incorrect.
Thank you a thousand time for you help.
Guillaume ADEUX


Le?mer. 5 sept. 2018 ??19:08, Guillaume Adeux <mailto:guillaumesimon.a2 at gmail.com> a ?crit?:
Sorry for the trouble.

What I want to test is that the slopes are effectively increasing or decreasing; that back on the original scale, the regression line is not parralel to the x-axis. This must be possible but I don't even know if this is the way to go.

Thank you very much for you interest,

Guillaume ADEUX


From tiff@ny@vid@l @ending from @t@te@m@@u@  Thu Sep  6 19:59:05 2018
From: tiff@ny@vid@l @ending from @t@te@m@@u@ (Vidal, Tiffany (FWE ))
Date: Thu, 6 Sep 2018 17:59:05 +0000
Subject: [R-sig-ME] distribution of random effects glmmTMB - covariance
 structure
Message-ID: <5832d024162546b8adf0183cddae4d26@ES-CHL-EMR-15.es.govt.state.ma.us>

I'm unclear about the distributional assumptions regarding the random effects in glmmTMB, using different covariance structures. It is my understanding that the default is unstructured covariance structure. When estimating a vector of random effects, what is the assumption about the distribution of the factor levels within each grouping? I'm usually assuming normality with a mean of 0 and estimated variance. This doesn't seem to hold looking at the ranef(mod) for the different grouping variables.

For example:
mod <- glmmTMB(Count ~ us(time + 0|Subject))
or
mod <- glmmTMB(Count ~ diag(time + 0|Subject))


Here, I'm modeling (I think) variability among subjects through time (e.g., a different subject variance in each time step), and assuming that the repeated measures within each individual subject at time t, come from some distribution. If the assumed distribution was normal with a mean of 0, I would expect the sum of the Subject BLUPs in each year to approximate 0, but that doesn't appear to be the case. Any clarification on this would be appreciated.

Thank you,
Tiffany


	[[alternative HTML version deleted]]


From oliverhooker @ending from pr@t@ti@tic@@com  Thu Sep  6 20:30:29 2018
From: oliverhooker @ending from pr@t@ti@tic@@com (Oliver Hooker)
Date: Thu, 06 Sep 2018 19:30:29 +0100
Subject: [R-sig-ME] PARTFUNDED SCHOLARHPS - Introduction to Frequentist and
 Bayesian mixed (Hierarchical) models"
Message-ID: <507b0d5cddc564a79e8fc0998393d7f2@prstatistics.com>

PARTFUNDED SCHOLARHPS for the course "Introduction to Frequentist and
Bayesian mixed (Hierarchical) models (IFBM01)"

This course will run from the 8th - 12th October 2018 in Glasgow City
Centre, Scotland, UK

www.psstatistics.com/course/introduction-to-frequentis-and-bayesian-mixed-models-ifbm01/

PS STATISTICS ARE PLEASED TO ANNOUNCE THAT THROUGH THEIR FUNDING SCHEME
THEY ARE ABLE TO OFFER PART-FUNDED SCHOLARSHIPS FOR THREE UP-COMING 
COURSES


1)    Introduction to Frequentist and Bayesian mixed (Hierarchical)
models (IFBM01)

As well as?

2)    Time series models for ecologists (TSME02)
https://www.prstatistics.com/course/time-series-models-for-ecologists-tsme02/

3)    Applied Bayesian modelling for ecologists and epidemiologists
(ABME04)
https://www.prstatistics.com/course/applied-bayesian-modelling-for-ecologists-and-epidemiologists-abme04/


SCHOLARSHIPS FOR IFBM01 CONTRIBUTE TOWARDS COURSE AND ACCOMMODATION FEES
WITH ALL INCLUSIVE PLACES (accommodation and meals included) AVAILABLE 
AT
?475.00 (Fees have been subsidised by 40% from ?775.00).


Applications should be sent to oliverhooker at psstatistics.com and contain

the following.

1.              Full name

2.              Institute name

3.              PhD subject title or Post doc research questions

4.              Do you hold a funded position

5.              150 words why this course would be relevant to your
research or how it would help.

Application deadline is Thursday 13th September and decisions will be 
made
by Friday 14th September 2018.

We still have ?normal? places available for anyone else interested.

Full course details are given below

Introduction to Frequentist and Bayesian mixed (Hierarchical) models
(IFBM01)

https://www.psstatistics.com/course/introduction-to-frequentis-and-bayesian-mixed-models-ifbm01/

Course Overview:
This course will cover introductory mixed or hierarchical modelling 
(fixed
and random effects models) for real-world data sets from both a 
Frequentist
and Bayesian perspective. These methods lie at the forefront of 
statistics
research and are a vital tool in the scientist?s toolbox. The course
focuses on introducing concepts and demonstrating good practice in mixed
modelling. All methods are demonstrated with data sets which 
participants
can run themselves. Participants will be taught how to fit hierarchical
models using both the standard lme4 mixed effects models library in R,
together with the Bayesian modelling framework via rstanarm. The course
covers the full gamut from simple regression models through to full
generalised multivariate mixed structures. The relevant advantages and
disadvantages of both the Frequentist and Bayesian approaches will be
presented.. Participants are encouraged to bring their own data sets for
discussion with the course tutors.

Oliver Hooker PhD.
PS statistics

2018 publications -

Alternative routes to piscivory: Contrasting growth trajectories in 
brown
trout (Salmo trutta) ecotypes exhibiting contrasting life history
strategies. Ecology of Freshwater Fish. DOI to follow

Phenotypic and resource use partitioning amongst sympatric lacustrine 
brown
trout, Salmo trutta. Biological Journal of the Linnean Society. DOI
10.1093/biolinnean/bly032

6 Hope Park Crescent
Edinburgh
EH8 9NA

+44 (0) 7966500340


From d@rizopoulo@ @ending from er@@mu@mc@nl  Thu Sep  6 20:42:50 2018
From: d@rizopoulo@ @ending from er@@mu@mc@nl (D. Rizopoulos)
Date: Thu, 6 Sep 2018 18:42:50 +0000
Subject: [R-sig-ME] distribution of random effects glmmTMB - covariance
 structure
In-Reply-To: <5832d024162546b8adf0183cddae4d26@ES-CHL-EMR-15.es.govt.state.ma.us>
References: <5832d024162546b8adf0183cddae4d26@ES-CHL-EMR-15.es.govt.state.ma.us>
Message-ID: <16c18aa6-4267-101e-1f0a-177c74943050@erasmusmc.nl>

Logically, the ranef() gives you the empirical Bayes estimates of the 
random effects. Note that the distribution (and as a result the variance 
and covariances) of these is not the same as the distribution you 
specified in the formula of the model. Namely, the distribution you 
define is the _prior_ distribution of the random effects, whereas the 
empirical Bayes estimates are coming from the posterior of the random 
effects.

In math terms, the choice of us() of diag() specifies the distribution 
[b] of the random effects, whereas from ranef() you get the modes or 
means of the posterior distribution

[b | y] which is proportional to [y | b] * [b],

where y denotes you Count outcome, and [y | b] denotes the distribution 
of your outcome.

Best,
Dimitris


On 9/6/2018 7:59 PM, Vidal, Tiffany (FWE ) wrote:
> I'm unclear about the distributional assumptions regarding the random effects in glmmTMB, using different covariance structures. It is my understanding that the default is unstructured covariance structure. When estimating a vector of random effects, what is the assumption about the distribution of the factor levels within each grouping? I'm usually assuming normality with a mean of 0 and estimated variance. This doesn't seem to hold looking at the ranef(mod) for the different grouping variables.
> 
> For example:
> mod <- glmmTMB(Count ~ us(time + 0|Subject))
> or
> mod <- glmmTMB(Count ~ diag(time + 0|Subject))
> 
> 
> Here, I'm modeling (I think) variability among subjects through time (e.g., a different subject variance in each time step), and assuming that the repeated measures within each individual subject at time t, come from some distribution. If the assumed distribution was normal with a mean of 0, I would expect the sum of the Subject BLUPs in each year to approximate 0, but that doesn't appear to be the case. Any clarification on this would be appreciated.
> 
> Thank you,
> Tiffany
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

-- 
Dimitris Rizopoulos
Professor of Biostatistics
Department of Biostatistics
Erasmus University Medical Center

Address: PO Box 2040, 3000 CA Rotterdam, the Netherlands
Tel: +31/(0)10/7043478
Fax: +31/(0)10/7043014
Web (personal): http://www.drizopoulos.com/
Web (work): http://www.erasmusmc.nl/biostatistiek/
Blog: http://iprogn.blogspot.nl/

From bbolker @ending from gm@il@com  Thu Sep  6 21:05:23 2018
From: bbolker @ending from gm@il@com (Ben Bolker)
Date: Thu, 6 Sep 2018 15:05:23 -0400
Subject: [R-sig-ME] distribution of random effects glmmTMB - covariance
 structure
In-Reply-To: <16c18aa6-4267-101e-1f0a-177c74943050@erasmusmc.nl>
References: <5832d024162546b8adf0183cddae4d26@ES-CHL-EMR-15.es.govt.state.ma.us>
 <16c18aa6-4267-101e-1f0a-177c74943050@erasmusmc.nl>
Message-ID: <1f0f752d-922b-3367-a248-8f2ab2422cfe@gmail.com>


   Yes.

   While the distribution of conditional modes is certainly not assumed
to be exactly N(0,s^2), informally, if the observed distribution of
conditional modes is far from zero-centered Gaussian, I might worry
about misspecification of the model.  I know of the existence of a
literature on the diagnosis and effects of model misspecification
(especially of the distribution of conditional modes) in (G)LMMs -- e.g.
go to http://bbolker.github.io/mixedmodels-misc/glmmbib.html and search
for "misspec" -- but I don't know its contents well at all.

 (1) adding group-level covariates (to explain some of the non-Normal
among-group variability) can help, if you have any such information
 (2) one more question about your random-effect specification.  Is time
being treated as categorical or continuous?
   If categorical:
     - if there are n time points, us(time+0|Subject) will have
n*(n+1)/2 parameters, which could get out of hand (you'll be trying to
estimate the full variance-covariance matrix among all n observations
for each subject -- you'll need lots of subjects to make this work).
Could be worth trying an ar1() model instead?
     - allowing for a *continuous*, fixed effect of time in addition to
the random effect could help (again, by explaining some of the
systematic variability)
   - if continuous: I'm not sure why you would suppress the intercept
variation?

On 2018-09-06 02:42 PM, D. Rizopoulos wrote:
> Logically, the ranef() gives you the empirical Bayes estimates of the 
> random effects. Note that the distribution (and as a result the variance 
> and covariances) of these is not the same as the distribution you 
> specified in the formula of the model. Namely, the distribution you 
> define is the _prior_ distribution of the random effects, whereas the 
> empirical Bayes estimates are coming from the posterior of the random 
> effects.
> 
> In math terms, the choice of us() of diag() specifies the distribution 
> [b] of the random effects, whereas from ranef() you get the modes or 
> means of the posterior distribution
> 
> [b | y] which is proportional to [y | b] * [b],
> 
> where y denotes you Count outcome, and [y | b] denotes the distribution 
> of your outcome.
> 
> Best,
> Dimitris
> 
> 
> On 9/6/2018 7:59 PM, Vidal, Tiffany (FWE ) wrote:
>> I'm unclear about the distributional assumptions regarding the random effects in glmmTMB, using different covariance structures. It is my understanding that the default is unstructured covariance structure. When estimating a vector of random effects, what is the assumption about the distribution of the factor levels within each grouping? I'm usually assuming normality with a mean of 0 and estimated variance. This doesn't seem to hold looking at the ranef(mod) for the different grouping variables.
>>
>> For example:
>> mod <- glmmTMB(Count ~ us(time + 0|Subject))
>> or
>> mod <- glmmTMB(Count ~ diag(time + 0|Subject))
>>
>>
>> Here, I'm modeling (I think) variability among subjects through time (e.g., a different subject variance in each time step), and assuming that the repeated measures within each individual subject at time t, come from some distribution. If the assumed distribution was normal with a mean of 0, I would expect the sum of the Subject BLUPs in each year to approximate 0, but that doesn't appear to be the case. Any clarification on this would be appreciated.
>>
>> Thank you,
>> Tiffany
>>
>>
>> 	[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>


From tiff@ny@vid@l @ending from @t@te@m@@u@  Thu Sep  6 21:15:33 2018
From: tiff@ny@vid@l @ending from @t@te@m@@u@ (Vidal, Tiffany (FWE ))
Date: Thu, 6 Sep 2018 19:15:33 +0000
Subject: [R-sig-ME] distribution of random effects glmmTMB - covariance
 structure
In-Reply-To: <1f0f752d-922b-3367-a248-8f2ab2422cfe@gmail.com>
References: <5832d024162546b8adf0183cddae4d26@ES-CHL-EMR-15.es.govt.state.ma.us>
 <16c18aa6-4267-101e-1f0a-177c74943050@erasmusmc.nl>
 <1f0f752d-922b-3367-a248-8f2ab2422cfe@gmail.com>
Message-ID: <31ec8a413f2440dabdc85a59cf17a824@ES-CHL-EMR-15.es.govt.state.ma.us>

Thank you. That makes sense regarding the conditional modes. This model is not specified fully yet, but more an example to understand the different covariance structure options in this package. Your replies have been very helpful, and I will consult the materials suggested.

Tiffany

-----Original Message-----
From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of Ben Bolker
Sent: Thursday, September 06, 2018 3:05 PM
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] distribution of random effects glmmTMB - covariance structure


   Yes.

   While the distribution of conditional modes is certainly not assumed to be exactly N(0,s^2), informally, if the observed distribution of conditional modes is far from zero-centered Gaussian, I might worry about misspecification of the model.  I know of the existence of a literature on the diagnosis and effects of model misspecification (especially of the distribution of conditional modes) in (G)LMMs -- e.g.
go to https://urldefense.proofpoint.com/v2/url?u=http-3A__bbolker.github.io_mixedmodels-2Dmisc_glmmbib.html&d=DwICAg&c=lDF7oMaPKXpkYvev9V-fVahWL0QWnGCCAfCDz1Bns_w&r=sqewvGWc5AUwYJSPkw7hFHEzecJLoIBs7pn2DqRZwbw&m=GRAZe7mikKkDmGfVMz0G4FV6LLM-lUlXzdYo2QRJULY&s=R9nkTkXINyOZkqZ3csEKQoPWhmEa8WKDU50YUmGF_9Q&e= and search for "misspec" -- but I don't know its contents well at all.

 (1) adding group-level covariates (to explain some of the non-Normal among-group variability) can help, if you have any such information
 (2) one more question about your random-effect specification.  Is time being treated as categorical or continuous?
   If categorical:
     - if there are n time points, us(time+0|Subject) will have
n*(n+1)/2 parameters, which could get out of hand (you'll be trying to estimate the full variance-covariance matrix among all n observations for each subject -- you'll need lots of subjects to make this work).
Could be worth trying an ar1() model instead?
     - allowing for a *continuous*, fixed effect of time in addition to the random effect could help (again, by explaining some of the systematic variability)
   - if continuous: I'm not sure why you would suppress the intercept variation?

On 2018-09-06 02:42 PM, D. Rizopoulos wrote:
> Logically, the ranef() gives you the empirical Bayes estimates of the 
> random effects. Note that the distribution (and as a result the 
> variance and covariances) of these is not the same as the distribution 
> you specified in the formula of the model. Namely, the distribution 
> you define is the _prior_ distribution of the random effects, whereas 
> the empirical Bayes estimates are coming from the posterior of the 
> random effects.
> 
> In math terms, the choice of us() of diag() specifies the distribution 
> [b] of the random effects, whereas from ranef() you get the modes or 
> means of the posterior distribution
> 
> [b | y] which is proportional to [y | b] * [b],
> 
> where y denotes you Count outcome, and [y | b] denotes the 
> distribution of your outcome.
> 
> Best,
> Dimitris
> 
> 
> On 9/6/2018 7:59 PM, Vidal, Tiffany (FWE ) wrote:
>> I'm unclear about the distributional assumptions regarding the random effects in glmmTMB, using different covariance structures. It is my understanding that the default is unstructured covariance structure. When estimating a vector of random effects, what is the assumption about the distribution of the factor levels within each grouping? I'm usually assuming normality with a mean of 0 and estimated variance. This doesn't seem to hold looking at the ranef(mod) for the different grouping variables.
>>
>> For example:
>> mod <- glmmTMB(Count ~ us(time + 0|Subject)) or mod <- glmmTMB(Count 
>> ~ diag(time + 0|Subject))
>>
>>
>> Here, I'm modeling (I think) variability among subjects through time (e.g., a different subject variance in each time step), and assuming that the repeated measures within each individual subject at time t, come from some distribution. If the assumed distribution was normal with a mean of 0, I would expect the sum of the Subject BLUPs in each year to approximate 0, but that doesn't appear to be the case. Any clarification on this would be appreciated.
>>
>> Thank you,
>> Tiffany
>>
>>
>> 	[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list 
>> https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mai
>> lman_listinfo_r-2Dsig-2Dmixed-2Dmodels&d=DwICAg&c=lDF7oMaPKXpkYvev9V-
>> fVahWL0QWnGCCAfCDz1Bns_w&r=sqewvGWc5AUwYJSPkw7hFHEzecJLoIBs7pn2DqRZwb
>> w&m=GRAZe7mikKkDmGfVMz0G4FV6LLM-lUlXzdYo2QRJULY&s=qblTkKF4oFycWjohI0c
>> 7Fuium-03zG-v81IrPw2vCVM&e=
>>
>

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dsig-2Dmixed-2Dmodels&d=DwICAg&c=lDF7oMaPKXpkYvev9V-fVahWL0QWnGCCAfCDz1Bns_w&r=sqewvGWc5AUwYJSPkw7hFHEzecJLoIBs7pn2DqRZwbw&m=GRAZe7mikKkDmGfVMz0G4FV6LLM-lUlXzdYo2QRJULY&s=qblTkKF4oFycWjohI0c7Fuium-03zG-v81IrPw2vCVM&e=


From d@rizopoulo@ @ending from er@@mu@mc@nl  Thu Sep  6 21:29:30 2018
From: d@rizopoulo@ @ending from er@@mu@mc@nl (D. Rizopoulos)
Date: Thu, 6 Sep 2018 19:29:30 +0000
Subject: [R-sig-ME] distribution of random effects glmmTMB - covariance
 structure
In-Reply-To: <1f0f752d-922b-3367-a248-8f2ab2422cfe@gmail.com>
References: <5832d024162546b8adf0183cddae4d26@ES-CHL-EMR-15.es.govt.state.ma.us>
 <16c18aa6-4267-101e-1f0a-177c74943050@erasmusmc.nl>
 <1f0f752d-922b-3367-a248-8f2ab2422cfe@gmail.com>
Message-ID: <5922ddbb-a075-9842-7158-5efabdedd09e@erasmusmc.nl>

Well, AFAIK checking the normality assumption of the prior distribution 
of the random effects using the EB estimates can be problematic. This is 
because they have different distributions that depend on the design 
matrices of the fixed and random effects of each subject. And, also 
because there is the effect of shrinkage that has an impact on their 
distribution.

For more on these points, a nice overview is given in Section 7.8 of 
book of Verbeke and Molenberghs (2000), "Linear Mixed Models for 
Longitudinal Data", Springer-Verlag.

In any case, if we're talking about linear mixed models, it has be shown 
that misspecifying the prior distribution of the random effects has very 
little impact in parameter estimates and standard errors for the fixed 
effects.

Best,
Dimitris


On 9/6/2018 9:05 PM, Ben Bolker wrote:
> 
>     Yes.
> 
>     While the distribution of conditional modes is certainly not assumed
> to be exactly N(0,s^2), informally, if the observed distribution of
> conditional modes is far from zero-centered Gaussian, I might worry
> about misspecification of the model.  I know of the existence of a
> literature on the diagnosis and effects of model misspecification
> (especially of the distribution of conditional modes) in (G)LMMs -- e.g.
> go to http://bbolker.github.io/mixedmodels-misc/glmmbib.html and search
> for "misspec" -- but I don't know its contents well at all.
> 
>   (1) adding group-level covariates (to explain some of the non-Normal
> among-group variability) can help, if you have any such information
>   (2) one more question about your random-effect specification.  Is time
> being treated as categorical or continuous?
>     If categorical:
>       - if there are n time points, us(time+0|Subject) will have
> n*(n+1)/2 parameters, which could get out of hand (you'll be trying to
> estimate the full variance-covariance matrix among all n observations
> for each subject -- you'll need lots of subjects to make this work).
> Could be worth trying an ar1() model instead?
>       - allowing for a *continuous*, fixed effect of time in addition to
> the random effect could help (again, by explaining some of the
> systematic variability)
>     - if continuous: I'm not sure why you would suppress the intercept
> variation?
> 
> On 2018-09-06 02:42 PM, D. Rizopoulos wrote:
>> Logically, the ranef() gives you the empirical Bayes estimates of the
>> random effects. Note that the distribution (and as a result the variance
>> and covariances) of these is not the same as the distribution you
>> specified in the formula of the model. Namely, the distribution you
>> define is the _prior_ distribution of the random effects, whereas the
>> empirical Bayes estimates are coming from the posterior of the random
>> effects.
>>
>> In math terms, the choice of us() of diag() specifies the distribution
>> [b] of the random effects, whereas from ranef() you get the modes or
>> means of the posterior distribution
>>
>> [b | y] which is proportional to [y | b] * [b],
>>
>> where y denotes you Count outcome, and [y | b] denotes the distribution
>> of your outcome.
>>
>> Best,
>> Dimitris
>>
>>
>> On 9/6/2018 7:59 PM, Vidal, Tiffany (FWE ) wrote:
>>> I'm unclear about the distributional assumptions regarding the random effects in glmmTMB, using different covariance structures. It is my understanding that the default is unstructured covariance structure. When estimating a vector of random effects, what is the assumption about the distribution of the factor levels within each grouping? I'm usually assuming normality with a mean of 0 and estimated variance. This doesn't seem to hold looking at the ranef(mod) for the different grouping variables.
>>>
>>> For example:
>>> mod <- glmmTMB(Count ~ us(time + 0|Subject))
>>> or
>>> mod <- glmmTMB(Count ~ diag(time + 0|Subject))
>>>
>>>
>>> Here, I'm modeling (I think) variability among subjects through time (e.g., a different subject variance in each time step), and assuming that the repeated measures within each individual subject at time t, come from some distribution. If the assumed distribution was normal with a mean of 0, I would expect the sum of the Subject BLUPs in each year to approximate 0, but that doesn't appear to be the case. Any clarification on this would be appreciated.
>>>
>>> Thank you,
>>> Tiffany
>>>
>>>
>>> 	[[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

-- 
Dimitris Rizopoulos
Professor of Biostatistics
Department of Biostatistics
Erasmus University Medical Center

Address: PO Box 2040, 3000 CA Rotterdam, the Netherlands
Tel: +31/(0)10/7043478
Fax: +31/(0)10/7043014
Web (personal): http://www.drizopoulos.com/
Web (work): http://www.erasmusmc.nl/biostatistiek/
Blog: http://iprogn.blogspot.nl/

From tiff@ny@vid@l @ending from @t@te@m@@u@  Thu Sep  6 21:44:45 2018
From: tiff@ny@vid@l @ending from @t@te@m@@u@ (Vidal, Tiffany (FWE ))
Date: Thu, 6 Sep 2018 19:44:45 +0000
Subject: [R-sig-ME] distribution of random effects glmmTMB - covariance
 structure
In-Reply-To: <5922ddbb-a075-9842-7158-5efabdedd09e@erasmusmc.nl>
References: <5832d024162546b8adf0183cddae4d26@ES-CHL-EMR-15.es.govt.state.ma.us>
 <16c18aa6-4267-101e-1f0a-177c74943050@erasmusmc.nl>
 <1f0f752d-922b-3367-a248-8f2ab2422cfe@gmail.com>
 <5922ddbb-a075-9842-7158-5efabdedd09e@erasmusmc.nl>
Message-ID: <8819cbc8f5f643e9a219672a763234bd@ES-CHL-EMR-15.es.govt.state.ma.us>

Thank you for this discussion and suggested materials. This is making much more sense now, and part of the problem could certainly be that the model is not fully specified yet, but was written to try to understand how the different covariance structures were operating. I'll dig into this more - thanks for the guidance!

Tiffany

-----Original Message-----
From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of D. Rizopoulos
Sent: Thursday, September 06, 2018 3:30 PM
To: Ben Bolker; r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] distribution of random effects glmmTMB - covariance structure

Well, AFAIK checking the normality assumption of the prior distribution of the random effects using the EB estimates can be problematic. This is because they have different distributions that depend on the design matrices of the fixed and random effects of each subject. And, also because there is the effect of shrinkage that has an impact on their distribution.

For more on these points, a nice overview is given in Section 7.8 of book of Verbeke and Molenberghs (2000), "Linear Mixed Models for Longitudinal Data", Springer-Verlag.

In any case, if we're talking about linear mixed models, it has be shown that misspecifying the prior distribution of the random effects has very little impact in parameter estimates and standard errors for the fixed effects.

Best,
Dimitris


On 9/6/2018 9:05 PM, Ben Bolker wrote:
> 
>     Yes.
> 
>     While the distribution of conditional modes is certainly not 
> assumed to be exactly N(0,s^2), informally, if the observed 
> distribution of conditional modes is far from zero-centered Gaussian, 
> I might worry about misspecification of the model.  I know of the 
> existence of a literature on the diagnosis and effects of model 
> misspecification (especially of the distribution of conditional modes) in (G)LMMs -- e.g.
> go to 
> https://urldefense.proofpoint.com/v2/url?u=http-3A__bbolker.github.io_mixedmodels-2Dmisc_glmmbib.html&d=DwICAg&c=lDF7oMaPKXpkYvev9V-fVahWL0QWnGCCAfCDz1Bns_w&r=sqewvGWc5AUwYJSPkw7hFHEzecJLoIBs7pn2DqRZwbw&m=1wyRjyOI7n3_7Xn0v20mIyploRKDemTvOsjO0QUR1TM&s=ZPfMOcctjXZQxfX9fEQ8D2iZ5pDIvEopo1I67gQa7Nc&e= and search for "misspec" -- but I don't know its contents well at all.
> 
>   (1) adding group-level covariates (to explain some of the non-Normal 
> among-group variability) can help, if you have any such information
>   (2) one more question about your random-effect specification.  Is 
> time being treated as categorical or continuous?
>     If categorical:
>       - if there are n time points, us(time+0|Subject) will have
> n*(n+1)/2 parameters, which could get out of hand (you'll be trying to 
> estimate the full variance-covariance matrix among all n observations 
> for each subject -- you'll need lots of subjects to make this work).
> Could be worth trying an ar1() model instead?
>       - allowing for a *continuous*, fixed effect of time in addition 
> to the random effect could help (again, by explaining some of the 
> systematic variability)
>     - if continuous: I'm not sure why you would suppress the intercept 
> variation?
> 
> On 2018-09-06 02:42 PM, D. Rizopoulos wrote:
>> Logically, the ranef() gives you the empirical Bayes estimates of the 
>> random effects. Note that the distribution (and as a result the 
>> variance and covariances) of these is not the same as the 
>> distribution you specified in the formula of the model. Namely, the 
>> distribution you define is the _prior_ distribution of the random 
>> effects, whereas the empirical Bayes estimates are coming from the 
>> posterior of the random effects.
>>
>> In math terms, the choice of us() of diag() specifies the 
>> distribution [b] of the random effects, whereas from ranef() you get 
>> the modes or means of the posterior distribution
>>
>> [b | y] which is proportional to [y | b] * [b],
>>
>> where y denotes you Count outcome, and [y | b] denotes the 
>> distribution of your outcome.
>>
>> Best,
>> Dimitris
>>
>>
>> On 9/6/2018 7:59 PM, Vidal, Tiffany (FWE ) wrote:
>>> I'm unclear about the distributional assumptions regarding the random effects in glmmTMB, using different covariance structures. It is my understanding that the default is unstructured covariance structure. When estimating a vector of random effects, what is the assumption about the distribution of the factor levels within each grouping? I'm usually assuming normality with a mean of 0 and estimated variance. This doesn't seem to hold looking at the ranef(mod) for the different grouping variables.
>>>
>>> For example:
>>> mod <- glmmTMB(Count ~ us(time + 0|Subject)) or mod <- glmmTMB(Count 
>>> ~ diag(time + 0|Subject))
>>>
>>>
>>> Here, I'm modeling (I think) variability among subjects through time (e.g., a different subject variance in each time step), and assuming that the repeated measures within each individual subject at time t, come from some distribution. If the assumed distribution was normal with a mean of 0, I would expect the sum of the Subject BLUPs in each year to approximate 0, but that doesn't appear to be the case. Any clarification on this would be appreciated.
>>>
>>> Thank you,
>>> Tiffany
>>>
>>>
>>> 	[[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list 
>>> https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_ma
>>> ilman_listinfo_r-2Dsig-2Dmixed-2Dmodels&d=DwICAg&c=lDF7oMaPKXpkYvev9
>>> V-fVahWL0QWnGCCAfCDz1Bns_w&r=sqewvGWc5AUwYJSPkw7hFHEzecJLoIBs7pn2DqR
>>> Zwbw&m=1wyRjyOI7n3_7Xn0v20mIyploRKDemTvOsjO0QUR1TM&s=nWDwo8-rSy39wCi
>>> vdQsbmA85UQkYviIz1tb-2VIR2cg&e=
>>>
>>
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mail
> man_listinfo_r-2Dsig-2Dmixed-2Dmodels&d=DwICAg&c=lDF7oMaPKXpkYvev9V-fV
> ahWL0QWnGCCAfCDz1Bns_w&r=sqewvGWc5AUwYJSPkw7hFHEzecJLoIBs7pn2DqRZwbw&m
> =1wyRjyOI7n3_7Xn0v20mIyploRKDemTvOsjO0QUR1TM&s=nWDwo8-rSy39wCivdQsbmA8
> 5UQkYviIz1tb-2VIR2cg&e=
> 

--
Dimitris Rizopoulos
Professor of Biostatistics
Department of Biostatistics
Erasmus University Medical Center

Address: PO Box 2040, 3000 CA Rotterdam, the Netherlands
Tel: +31/(0)10/7043478
Fax: +31/(0)10/7043014
Web (personal): https://urldefense.proofpoint.com/v2/url?u=http-3A__www.drizopoulos.com_&d=DwICAg&c=lDF7oMaPKXpkYvev9V-fVahWL0QWnGCCAfCDz1Bns_w&r=sqewvGWc5AUwYJSPkw7hFHEzecJLoIBs7pn2DqRZwbw&m=1wyRjyOI7n3_7Xn0v20mIyploRKDemTvOsjO0QUR1TM&s=G_wJsbEuwqiP3MLBq5ymJYNHv5zjzW_hq9RJeHMh8nY&e=
Web (work): https://urldefense.proofpoint.com/v2/url?u=http-3A__www.erasmusmc.nl_biostatistiek_&d=DwICAg&c=lDF7oMaPKXpkYvev9V-fVahWL0QWnGCCAfCDz1Bns_w&r=sqewvGWc5AUwYJSPkw7hFHEzecJLoIBs7pn2DqRZwbw&m=1wyRjyOI7n3_7Xn0v20mIyploRKDemTvOsjO0QUR1TM&s=elBlIW1rIwFBR6v-ImOrmRW94vUHOTI3YrL-5yjEtzs&e=
Blog: https://urldefense.proofpoint.com/v2/url?u=http-3A__iprogn.blogspot.nl_&d=DwICAg&c=lDF7oMaPKXpkYvev9V-fVahWL0QWnGCCAfCDz1Bns_w&r=sqewvGWc5AUwYJSPkw7hFHEzecJLoIBs7pn2DqRZwbw&m=1wyRjyOI7n3_7Xn0v20mIyploRKDemTvOsjO0QUR1TM&s=ye5iQPWdroI6HXFE_gKH5yOe2xfCrzQFjSVEiKR45Dw&e=
_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dsig-2Dmixed-2Dmodels&d=DwICAg&c=lDF7oMaPKXpkYvev9V-fVahWL0QWnGCCAfCDz1Bns_w&r=sqewvGWc5AUwYJSPkw7hFHEzecJLoIBs7pn2DqRZwbw&m=1wyRjyOI7n3_7Xn0v20mIyploRKDemTvOsjO0QUR1TM&s=nWDwo8-rSy39wCivdQsbmA85UQkYviIz1tb-2VIR2cg&e=


From mr@luced@n @ending from hotm@il@it  Mon Sep 10 15:03:44 2018
From: mr@luced@n @ending from hotm@il@it (Luca Danieli)
Date: Mon, 10 Sep 2018 13:03:44 +0000
Subject: [R-sig-ME] how to group x-axis levels with ggplot()
Message-ID: <DB3PR0402MB38510D27F9863E32440C0995F6050@DB3PR0402MB3851.eurprd04.prod.outlook.com>

Hello everybody,

I have tried to solve this issue by posting a question on StackOverflow, but got no responses:
https://stackoverflow.com/questions/52225595/r-ggplot-how-to-group-levels-in-a-plots-axis-in-order-to-represent-a-cont

Basically, I have a plot (ggplot) of my lmer() model that presents on the x axis 8 levels. As my contrast splits these 8 levels in two groups (1 and 2 together, contrasted to 3,4,5,6,7,8 altogether), I would like to plot the results by grouping the 8 levels of the x axis into the two groups of the contrast hypothesis.

So, instead of:

^
| val  val  val  val  val  val  val  val
|-1----2---3----4---5----6----7---8  ----------> x axis

to have

^
| val                   val
|-front (1+2)---back+sides (3+4+5+6+7+8) -------------> x axis

Is it possible to do such a thing?
In case it was not possible to plot by grouping the x-axis levels through the ggplot() function, would it be the same if I grouped the levels before analyzing the model, in order to plot it as wished?

Best
Luca




	[[alternative HTML version deleted]]


From mbe@le @ending from u@lbert@@c@  Mon Sep 10 22:04:00 2018
From: mbe@le @ending from u@lbert@@c@ (Meghan Beale)
Date: Mon, 10 Sep 2018 14:04:00 -0600
Subject: [R-sig-ME] predict() expected counts for glmmTMB hurdle negative
 binomial model
Message-ID: <CALsK-wO7Qj1QQS-2m7XO=yW=VbYEogNOhpxBp6cbZf3s+-1xGw@mail.gmail.com>

Hi all,

I am modelling bighorn sheep habitat use using the glmmTMB package with a
hurdle negative binomial model. I understand that a hurdle (or
zero-altered, as same call it) negative binomial model exists as two parts
in sequence. First, I modeled whether habitat is used (coded with '1') or
not used (coded with '0') using a binomial distribution. This first piece
is a logistic regression with a logit link. Secondly, I modeled intensity
of habitat use by considering the conditional distribution, which is
truncated to only include positive counts. I modeled the conditional
distribution using a negative binomial distribution with a log link.

I am hoping to calculate predicted probability of habitat use from the
first portion of the model (the logistic regression) and calculate expected
counts from the truncated negative binomial portion of the model. Then, I
will use these 'expected' results in k-fold cross validation to determine
the predictive ability of my top model(s).

Here is an example of the code for my top model using the glmmTMB package:

model17 <- glmmTMB(bighorn.sheep.sum.rounded ~ pedge + rtp + dimroad + (1 |
year),
                         zi = ~ dihwall + pedge + rtp + dingra + dihroad +
dilake + dimroad + (1 | year),
                         family=list(family="truncated_nbinom2",
link="log"),data=bighorn.k)

I have figured out that specifying "zprob" in predict() returns the
probability of a '0', or probability of failure. Thus, (1-p) is the
probability of a '1', or probability of success, and ultimately,
probability of habitat use (what I want!).

bighorn.k$zprob <- predict(model17, newdata = testdata, type="zprob") #
gives p
bighorn.k$probability.habitat.use <- 1 - bighorn.k$zprob # can calculate
1-p in this way

However, I am still stuck trying to calculate expected counts given the
second portion of the zero-altered model, the truncated conditional
distribution. I can specify either "conditional" or "response" to calculate
mu, or (1-p)*mu, respectively. I can also double check the output for
"response".

bighorn.k$conditional <- predict(model17, newdata = testdata,
type="conditional") # mu
bighorn.k$response <- predict(model17, newdata = testdata, type="response")
# (1-p)*mu
# double check below
bighorn.k$probability.habitat.use * bighorn.k$conditional # equals
bighorn.k$response

And, all of this makes sense with this equation for hurdle models:

E[y|x] = [ 1 - f1(0|x) / 1 - f2(0|x) ] * mu(x); where f1(0|x) = p as I have
described above

>From what I understand, the only piece that I am missing is f2(0|x), which
is the probability of a non-zero in the second untruncated process.
Alternatively, if I can calculate the predicted ratio of probabilities for
observing a non-zero count, I can multiply by mu and get my expected
counts. How do I get either f2(0|x) or the entire ratio from predict(),
using glmmTMB models? Am I missing something or not interpreting something
correctly?

Thanks,
Meghan Beale
University of Alberta

	[[alternative HTML version deleted]]


From @rive046 @ending from uott@w@@c@  Fri Sep 14 00:06:30 2018
From: @rive046 @ending from uott@w@@c@ (Stephanie Rivest)
Date: Thu, 13 Sep 2018 18:06:30 -0400
Subject: [R-sig-ME] glmmTMB
Message-ID: <CAAYeMWECOdJ8ajFGgxc7FYsUuibk-hgydNTJ5=Fyu66NjioqPQ@mail.gmail.com>

Hello,

I have 2 questions regarding the use of glmmTMB, hopefully this is the
correct place to ask questions. See below..

1) How can pearson residuals be calculated for a Poisson distributed
zero-inflated glmm using the package glmmTMB? When I attempt to do this, I
get the following error message: pearson residuals are not implemented for
models with zero-inflation or variable dispersion.

2) Is it unusual for the nbinom distributions to fit very poorly compared
to the poisson? What I have done is kept my model identical, expect for
changing the distribution of the conditional model. The poisson fits well,
whereas the nbinom1 has some suspicious parameter estimates and NA values.

Thanks!
Stephanie Rives


Stephanie Rivest
Ph.D. Candidate | Candidate au Doctorat
Dept. of Biology | D?p. de Biologie
University of Ottawa | Universit? d'Ottawa

	[[alternative HTML version deleted]]


From Eric@Michel @ending from @d@t@te@edu  Tue Sep 18 19:15:44 2018
From: Eric@Michel @ending from @d@t@te@edu (Michel, Eric)
Date: Tue, 18 Sep 2018 17:15:44 +0000
Subject: [R-sig-ME] Extracting a p-value for a random effect in glmer
Message-ID: <DM6PR06MB45384214F62084C3C6B5D7D9F51D0@DM6PR06MB4538.namprd06.prod.outlook.com>

Good Afternoon,
I am responding to a reviewers request to provide a p-value for the random effect I used in a glmer model in the lme4 package. I have found plenty of code to produce p-values for lmer models, but not glmer models. Here is my model structure:

Int.litter<-glmer(litter_size~maternal_mass*repro_status + (1|maternal_id), family=binomial, data=litter).

I'd greatly appreciate any help.



	[[alternative HTML version deleted]]


From tom_philippi @ending from np@@gov  Tue Sep 18 20:09:58 2018
From: tom_philippi @ending from np@@gov (Philippi, Tom)
Date: Tue, 18 Sep 2018 11:09:58 -0700
Subject: [R-sig-ME] 
 [EXTERNAL] Extracting a p-value for a random effect in glmer
In-Reply-To: <DM6PR06MB45384214F62084C3C6B5D7D9F51D0@DM6PR06MB4538.namprd06.prod.outlook.com>
References: <DM6PR06MB45384214F62084C3C6B5D7D9F51D0@DM6PR06MB4538.namprd06.prod.outlook.com>
Message-ID: <CAM9kYqgD6tEgetBOfgSnsZWmkgYs057ATiZu8hkGfUrkdr+Ddw@mail.gmail.com>

Eric--
Ben Bolker has kindly covered that in his useful Mixed Models FAQ:
http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#testing-significance-of-random-effects


Tom

"To do science is to search for repeated patterns, not simply to accumulate
facts..."   --Robert MacArthur 1972, Geographical Ecology
"Statistical methods of analysis are intended to aid the interpretation of
data that are subject to appreciable haphazard variability"    --Cox &
Hinkley 1974; Theoretical Statistics

-------------------------------------------
Tom Philippi
Quantitative Ecologist & Data Therapist
Inventory and Monitoring Program
National Park Service


On Tue, Sep 18, 2018 at 11:04 AM Michel, Eric <Eric.Michel at sdstate.edu>
wrote:

> Good Afternoon,
> I am responding to a reviewers request to provide a p-value for the random
> effect I used in a glmer model in the lme4 package. I have found plenty of
> code to produce p-values for lmer models, but not glmer models. Here is my
> model structure:
>
> Int.litter<-glmer(litter_size~maternal_mass*repro_status +
> (1|maternal_id), family=binomial, data=litter).
>
> I'd greatly appreciate any help.
>
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From phillip@@ld@y @ending from mpi@nl  Tue Sep 18 20:14:10 2018
From: phillip@@ld@y @ending from mpi@nl (Phillip Alday)
Date: Tue, 18 Sep 2018 20:14:10 +0200
Subject: [R-sig-ME] Extracting a p-value for a random effect in glmer
In-Reply-To: <DM6PR06MB45384214F62084C3C6B5D7D9F51D0@DM6PR06MB4538.namprd06.prod.outlook.com>
References: <DM6PR06MB45384214F62084C3C6B5D7D9F51D0@DM6PR06MB4538.namprd06.prod.outlook.com>
Message-ID: <e6d29121-ddec-ae6e-da7e-4fbb917db0e9@mpi.nl>

Not answering your question at all, but a binomial model doesn't seem
like the right choice for litter_size, which I assume is a count
variable and not binomially distributed, just on account of biology ....

Related to that: why do you want a p-value for your random effects? In
other words, what's your actual inferential question? Are you interested
in whether mothers differ? Do you have multiple litters from each mother?

Phillip

On 09/18/2018 07:15 PM, Michel, Eric wrote:
> Good Afternoon,
> I am responding to a reviewers request to provide a p-value for the random effect I used in a glmer model in the lme4 package. I have found plenty of code to produce p-values for lmer models, but not glmer models. Here is my model structure:
> 
> Int.litter<-glmer(litter_size~maternal_mass*repro_status + (1|maternal_id), family=binomial, data=litter).
> 
> I'd greatly appreciate any help.
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From @rive046 @ending from uott@w@@c@  Tue Sep 18 20:20:59 2018
From: @rive046 @ending from uott@w@@c@ (Stephanie Rivest)
Date: Tue, 18 Sep 2018 14:20:59 -0400
Subject: [R-sig-ME] glmmTMB pearson residuals
Message-ID: <CAAYeMWGcg14Pug0D5kiz-DauZpM0DCVfOz7oJsLFvtw_0FhgTw@mail.gmail.com>

Hello,

I am working with glmmTMB and have a question about calculating the pearson
residuals. Following the math laid out in Zuur et al. (2012) I can
understand how the following code works for models fit with the family
nbinom2:

v <- family(model)$variance
p <- predict(model,zitype="zprob")  ## z-i probability
mu <- predict(model,zitype="conditional")  ## mean of conditional
distribution
pred <- predict(model,zitype="response") ## (1-p)*mu
k <- sigma(m5) ## dispersion parameter
pvar <- (1-p)*v(mu,k)+mu^2*(p^2+p)
pearson_resid <- (data.frame$Response-pred)/sqrt(pvar)

What I am unsure about is how this changes if the family being used is
nbinom1?

For the poisson family, does the following code make sense for calculating
pearson resids?

p <- predict(model,zitype="zprob")  ## z-i probability
mu <- predict(model,zitype="conditional")  ## mean of conditional
distribution
pred <- predict(model,zitype="response") ## (1-p)*mu
pvar <- (1-p)*(mu + p*mu^2)
pearson_resid <- (data.frame$Response - pred) / sqrt(pvar)

Any help is greatly appreciated!

Stephanie Rivest
Ph.D. Candidate | Candidate au Doctorat
Dept. of Biology | D?p. de Biologie
University of Ottawa | Universit? d'Ottawa

	[[alternative HTML version deleted]]


From emm@nuel@curi@ @ending from p@ri@de@c@rte@@fr  Wed Sep 19 09:30:14 2018
From: emm@nuel@curi@ @ending from p@ri@de@c@rte@@fr (Emmanuel Curis)
Date: Wed, 19 Sep 2018 09:30:14 +0200
Subject: [R-sig-ME] =?iso-8859-1?q?Comparing_Gaussian_and_b=EAta_regressi?=
 =?iso-8859-1?q?on?=
Message-ID: <20180919073014.GA17416@info124.pharmacie.univ-paris5.fr>

Hello,

I'm doing my first try on b?ta regression, with mixed effects model,
and was wondering if my reasonning is correct...

The context is a clinical study where the outcome is a score variable,
with continuous values between 0 and 10 (both included) and, in
practice, values with only one decimal digit (eg. 1.5).  There is
about 400 patients. Random effect is the clinician who does the
examination and afterthat collects the score that evaluates its
intervention.

As a quick-and-dirty analysis, I did a linear mixed effect model on
the raw data, with lmer. Residuals and random effects are not so bad,
and results consistent & easy to interpret, but assuming a Gaussian
distribution is not very satisfactory.

Hence, I tried a b?ta regression on the data after the transformation
(y/10 * (n-1) + 0.5) / n, and used glmmTMB for that. And of course I
wondered if the fit was better.

1) Is it right that ln-likelihood of the model on the raw data
   (Gaussian) and on the transformed data (b?ta) cannot be compared,
   because they involve probability densities and not probabilities,
   hence depend on the data scale ?

2) Is it right that the lmer model done on the raw data and the same
   one done on the transformed data are conceptually the same, since
   the transformation is linear ? so that the ln-likelihood it gives
   is ? the same ? expressed in the two different scales? (of course,
   coefficients and so on will be different because of the scale
   change)

3) And so, is it correct to compare the ln-likelihood (using logLik)
   or the AIC given by glmmTMB with the b?ta model and by lmer on
   transformed data to compare the two models (raw data Gaussian vs
   b?ta)?

   If so, the b?ta model seems better than the Gaussian one. But now
   comes the interpretation problem, other than ? are coefficients
   significantly different from 0? ?.

4) Since the default link is the logit for the mean, interpretation is
   not quite clear for me.  For the Gaussian model on raw data,
   interpretation is clear, for instance ? men score 1 point lower
   than women in average??.  But how can the coefficients of the
   b?ta-model be back-converted in a similar fashion ?

   Would it be easier to use a log link and expression changes in the
   scale as percent changes on the mean?

Thanks in advance,

-- 
                                Emmanuel CURIS
                                emmanuel.curis at parisdescartes.fr

Page WWW: http://emmanuel.curis.online.fr/index.html


From bbolker @ending from gm@il@com  Wed Sep 19 15:49:51 2018
From: bbolker @ending from gm@il@com (Ben Bolker)
Date: Wed, 19 Sep 2018 09:49:51 -0400
Subject: [R-sig-ME] 
 =?utf-8?q?Comparing_Gaussian_and_b=C3=AAta_regression?=
In-Reply-To: <20180919073014.GA17416@info124.pharmacie.univ-paris5.fr>
References: <20180919073014.GA17416@info124.pharmacie.univ-paris5.fr>
Message-ID: <12de47d9-468b-c5e1-c75c-aee8ce59ba86@gmail.com>



On 2018-09-19 03:30 AM, Emmanuel Curis wrote:
> Hello,
> 
> I'm doing my first try on b?ta regression, with mixed effects model,
> and was wondering if my reasonning is correct...
> 
> The context is a clinical study where the outcome is a score variable,
> with continuous values between 0 and 10 (both included) and, in
> practice, values with only one decimal digit (eg. 1.5) There is
> about 400 patients. Random effect is the clinician who does the
> examination and afterthat collects the score that evaluates its
> intervention.
> 
> As a quick-and-dirty analysis, I did a linear mixed effect model on
> the raw data, with lmer. Residuals and random effects are not so bad,
> and results consistent & easy to interpret, but assuming a Gaussian
> distribution is not very satisfactory.

Can you expand on why "not very satisfactory"?  Do you get unrealistic
predictions etc.?

  This sounds like it could also be treated as an ordinal response (with
21 values {0, 0.5, 1, ... 9.5, 10}).
> 
> Hence, I tried a b?ta regression on the data after the transformation
> (y/10 * (n-1) + 0.5) / n, and used glmmTMB for that. And of course I
> wondered if the fit was better.
> 
> 1) Is it right that ln-likelihood of the model on the raw data
>    (Gaussian) and on the transformed data (b?ta) cannot be compared,
>    because they involve probability densities and not probabilities,
>    hence depend on the data scale ?

  You can compare log-likelihoods (actually technically they're
log-likelihood *densities*, which is where the problem comes from) if
you account for the scaling.  In this case since you're doing a linear
transformation the scaling should be pretty easy.
> 
> 2) Is it right that the lmer model done on the raw data and the same
>    one done on the transformed data are conceptually the same, since
>    the transformation is linear ? so that the ln-likelihood it gives
>    is ? the same ? expressed in the two different scales? (of course,
>    coefficients and so on will be different because of the scale
>    change)

   Should be. (You could do a simple test of this ...)
> 
> 3) And so, is it correct to compare the ln-likelihood (using logLik)
>    or the AIC given by glmmTMB with the b?ta model and by lmer on
>    transformed data to compare the two models (raw data Gaussian vs
>    b?ta)?

  I would think so.
> 
>    If so, the b?ta model seems better than the Gaussian one. But now
>    comes the interpretation problem, other than ? are coefficients
>    significantly different from 0? ?.
> 
> 4) Since the default link is the logit for the mean, interpretation is
>    not quite clear for me.  For the Gaussian model on raw data,
>    interpretation is clear, for instance ? men score 1 point lower
>    than women in average??.  But how can the coefficients of the
>    b?ta-model be back-converted in a similar fashion ?

   You probably need to go read stuff about interpretation of
logit/log-odds  parameters: Gelman and Hill's book is good.

Quick rules of thumb:

* for ??x small, as for log (proportional)
* for intermediate values, linear change in probability with
slope ? ?/4
* for large values, as for log ( 1 ? x )
> 
>    Would it be easier to use a log link and expression changes in the
>    scale as percent changes on the mean?

  This will work fine for low score values, but will run into trouble at
the upper end of the score range.

> 
> Thanks in advance,
>


From emm@nuel@curi@ @ending from p@ri@de@c@rte@@fr  Wed Sep 19 17:02:17 2018
From: emm@nuel@curi@ @ending from p@ri@de@c@rte@@fr (Emmanuel Curis)
Date: Wed, 19 Sep 2018 17:02:17 +0200
Subject: [R-sig-ME] 
 =?iso-8859-1?q?Comparing_Gaussian_and_b=EAta_regressi?=
 =?iso-8859-1?q?on?=
In-Reply-To: <12de47d9-468b-c5e1-c75c-aee8ce59ba86@gmail.com>
References: <20180919073014.GA17416@info124.pharmacie.univ-paris5.fr>
 <12de47d9-468b-c5e1-c75c-aee8ce59ba86@gmail.com>
Message-ID: <20180919150217.GD1527@info124.pharmacie.univ-paris5.fr>

Thank you very much for the hints.

The ? not very satisfactory ? is from a "theoretical" point of view:
I'm not very comfortable with modeling with a Gaussian a value
constrained between 0 and 10, with the extremes obtained not so
rarely.  From a practical point of view, it does not seem to produce
unexpected results.  Of course, there are some effects that are
borderline significant, that also makes the question uprise: what is
the part of true signal and basically inadequate model in these
effects? Still finding them with a more sounded model would make them a
little bit more "trustable"...

For the ordinal outcome: I have wrongly selected my example value, it
induced in error, sorry ; the step is 0.1 and not 0.5 ; in practice,
46 different values were observed. Integer values and, to a less
extent, half-integer values are clearly over-represented, I guess
because of inconscient rounding during scoring.  I don't know how to
handle this in a model, however, but that's another problem, and may
be there is no need for that.  But, for the ordinal aspect, I fear
that would make too much parameters in the model... 

Just thinking... Would it be imaginable to make inferences on the
beta-distribution model, since it seems to much better describe the
data, but use the linear model on the raw scale just to have
point-estimates of the changes in an easiest-to-interpret way?
[despite it is problematic close to the boundaries...]

Is the Gelmann & Hill book you're thinking about this one: ?

Data Analysis Using Regression and Multilevel/Hierarchical Models
 Cambridge University Press
ISBN-10: 052168689X

On Wed, Sep 19, 2018 at 09:49:51AM -0400, Ben Bolker wrote:
? 
? 
? On 2018-09-19 03:30 AM, Emmanuel Curis wrote:
? > Hello,
? > 
? > I'm doing my first try on b?ta regression, with mixed effects model,
? > and was wondering if my reasonning is correct...
? > 
? > The context is a clinical study where the outcome is a score variable,
? > with continuous values between 0 and 10 (both included) and, in
? > practice, values with only one decimal digit (eg. 1.5) There is
? > about 400 patients. Random effect is the clinician who does the
? > examination and afterthat collects the score that evaluates its
? > intervention.
? > 
? > As a quick-and-dirty analysis, I did a linear mixed effect model on
? > the raw data, with lmer. Residuals and random effects are not so bad,
? > and results consistent & easy to interpret, but assuming a Gaussian
? > distribution is not very satisfactory.
? 
? Can you expand on why "not very satisfactory"?  Do you get unrealistic
? predictions etc.?
? 
?   This sounds like it could also be treated as an ordinal response (with
? 21 values {0, 0.5, 1, ... 9.5, 10}).
? > 
? > Hence, I tried a b?ta regression on the data after the transformation
? > (y/10 * (n-1) + 0.5) / n, and used glmmTMB for that. And of course I
? > wondered if the fit was better.
? > 
? > 1) Is it right that ln-likelihood of the model on the raw data
? >    (Gaussian) and on the transformed data (b?ta) cannot be compared,
? >    because they involve probability densities and not probabilities,
? >    hence depend on the data scale ?
? 
?   You can compare log-likelihoods (actually technically they're
? log-likelihood *densities*, which is where the problem comes from) if
? you account for the scaling.  In this case since you're doing a linear
? transformation the scaling should be pretty easy.
? > 
? > 2) Is it right that the lmer model done on the raw data and the same
? >    one done on the transformed data are conceptually the same, since
? >    the transformation is linear ? so that the ln-likelihood it gives
? >    is ? the same ? expressed in the two different scales? (of course,
? >    coefficients and so on will be different because of the scale
? >    change)
? 
?    Should be. (You could do a simple test of this ...)
? > 
? > 3) And so, is it correct to compare the ln-likelihood (using logLik)
? >    or the AIC given by glmmTMB with the b?ta model and by lmer on
? >    transformed data to compare the two models (raw data Gaussian vs
? >    b?ta)?
? 
?   I would think so.
? > 
? >    If so, the b?ta model seems better than the Gaussian one. But now
? >    comes the interpretation problem, other than ? are coefficients
? >    significantly different from 0? ?.
? > 
? > 4) Since the default link is the logit for the mean, interpretation is
? >    not quite clear for me.  For the Gaussian model on raw data,
? >    interpretation is clear, for instance ? men score 1 point lower
? >    than women in average??.  But how can the coefficients of the
? >    b?ta-model be back-converted in a similar fashion ?
? 
?    You probably need to go read stuff about interpretation of
? logit/log-odds  parameters: Gelman and Hill's book is good.
? 
? Quick rules of thumb:
? 
? * for ??x small, as for log (proportional)
? * for intermediate values, linear change in probability with
? slope ? ?/4
? * for large values, as for log ( 1 ? x )
? > 
? >    Would it be easier to use a log link and expression changes in the
? >    scale as percent changes on the mean?
? 
?   This will work fine for low score values, but will run into trouble at
? the upper end of the score range.
? 
? > 
? > Thanks in advance,
? >
? 
? _______________________________________________
? R-sig-mixed-models at r-project.org mailing list
? https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
                                Emmanuel CURIS
                                emmanuel.curis at parisdescartes.fr

Page WWW: http://emmanuel.curis.online.fr/index.html


From bbolker @ending from gm@il@com  Wed Sep 19 17:50:47 2018
From: bbolker @ending from gm@il@com (Ben Bolker)
Date: Wed, 19 Sep 2018 11:50:47 -0400
Subject: [R-sig-ME] 
 =?utf-8?q?Comparing_Gaussian_and_b=C3=AAta_regression?=
In-Reply-To: <20180919150217.GD1527@info124.pharmacie.univ-paris5.fr>
References: <20180919073014.GA17416@info124.pharmacie.univ-paris5.fr>
 <12de47d9-468b-c5e1-c75c-aee8ce59ba86@gmail.com>
 <20180919150217.GD1527@info124.pharmacie.univ-paris5.fr>
Message-ID: <435459be-e91b-6ef9-f63b-bbde570a44f0@gmail.com>



On 2018-09-19 11:02 AM, Emmanuel Curis wrote:
> Thank you very much for the hints.
> 
> The ? not very satisfactory ? is from a "theoretical" point of view:
> I'm not very comfortable with modeling with a Gaussian a value
> constrained between 0 and 10, with the extremes obtained not so
> rarely.  From a practical point of view, it does not seem to produce
> unexpected results.  Of course, there are some effects that are
> borderline significant, that also makes the question uprise: what is
> the part of true signal and basically inadequate model in these
> effects? Still finding them with a more sounded model would make them a
> little bit more "trustable"...

  Fair enough.

> For the ordinal outcome: I have wrongly selected my example value, it
> induced in error, sorry ; the step is 0.1 and not 0.5 ; in practice,
> 46 different values were observed. Integer values and, to a less
> extent, half-integer values are clearly over-represented, I guess
> because of inconscient rounding during scoring.  I don't know how to
> handle this in a model, however, but that's another problem, and may
> be there is no need for that.  But, for the ordinal aspect, I fear
> that would make too much parameters in the model... 

    I agree.

> Just thinking... Would it be imaginable to make inferences on the
> beta-distribution model, since it seems to much better describe the
> data, but use the linear model on the raw scale just to have
> point-estimates of the changes in an easiest-to-interpret way?
> [despite it is problematic close to the boundaries...]

   It's certainly "imaginable", but my preference would be for taking
the time to understand logistic-scale parameters -- something like this
will be required any time you're dealing with predictions on a bounded
scale where the data go anywhere close to the boundaries ... if you're
going to go out of your way to use a model that's preferable on
theoretical grounds, why not go all the way?


> Is the Gelmann & Hill book you're thinking about this one: ?
> 
> Data Analysis Using Regression and Multilevel/Hierarchical Models
>  Cambridge University Press
> ISBN-10: 052168689X

 Yes, that's right. It's "Gelman" with one 'n', not to be confused with
the physicist Murray Gell-Mann -- although according to

https://www.edge.org/conversation/murray_gell_mann-the-making-of-a-physicist

> [M. Gell-Mann's brother] reformed the spelling of our surname and made
it just Gelman. He got tired of telling people about the double L, the
double N, the hyphen, and the capital M.

  FWIW there are probably lots and lots of explanations of logit-scale
parameters lying around on the internet, e.g.
https://stats.idre.ucla.edu/other/mult-pkg/faq/general/faq-how-do-i-interpret-odds-ratios-in-logistic-regression/


 Some rules of thumb from my GLM notes (partly taken from G & H):

? logit: log-odds change.

* for ??x small, as for log (proportional)
* for intermediate values, linear change in probability with
slope ? ?/4
* for large values, as for log ( 1 ? x )



  cheers
    Ben Bolker



> 
> On Wed, Sep 19, 2018 at 09:49:51AM -0400, Ben Bolker wrote:
> ? 
> ? 
> ? On 2018-09-19 03:30 AM, Emmanuel Curis wrote:
> ? > Hello,
> ? > 
> ? > I'm doing my first try on b?ta regression, with mixed effects model,
> ? > and was wondering if my reasonning is correct...
> ? > 
> ? > The context is a clinical study where the outcome is a score variable,
> ? > with continuous values between 0 and 10 (both included) and, in
> ? > practice, values with only one decimal digit (eg. 1.5) There is
> ? > about 400 patients. Random effect is the clinician who does the
> ? > examination and afterthat collects the score that evaluates its
> ? > intervention.
> ? > 
> ? > As a quick-and-dirty analysis, I did a linear mixed effect model on
> ? > the raw data, with lmer. Residuals and random effects are not so bad,
> ? > and results consistent & easy to interpret, but assuming a Gaussian
> ? > distribution is not very satisfactory.
> ? 
> ? Can you expand on why "not very satisfactory"?  Do you get unrealistic
> ? predictions etc.?
> ? 
> ?   This sounds like it could also be treated as an ordinal response (with
> ? 21 values {0, 0.5, 1, ... 9.5, 10}).
> ? > 
> ? > Hence, I tried a b?ta regression on the data after the transformation
> ? > (y/10 * (n-1) + 0.5) / n, and used glmmTMB for that. And of course I
> ? > wondered if the fit was better.
> ? > 
> ? > 1) Is it right that ln-likelihood of the model on the raw data
> ? >    (Gaussian) and on the transformed data (b?ta) cannot be compared,
> ? >    because they involve probability densities and not probabilities,
> ? >    hence depend on the data scale ?
> ? 
> ?   You can compare log-likelihoods (actually technically they're
> ? log-likelihood *densities*, which is where the problem comes from) if
> ? you account for the scaling.  In this case since you're doing a linear
> ? transformation the scaling should be pretty easy.
> ? > 
> ? > 2) Is it right that the lmer model done on the raw data and the same
> ? >    one done on the transformed data are conceptually the same, since
> ? >    the transformation is linear ? so that the ln-likelihood it gives
> ? >    is ? the same ? expressed in the two different scales? (of course,
> ? >    coefficients and so on will be different because of the scale
> ? >    change)
> ? 
> ?    Should be. (You could do a simple test of this ...)
> ? > 
> ? > 3) And so, is it correct to compare the ln-likelihood (using logLik)
> ? >    or the AIC given by glmmTMB with the b?ta model and by lmer on
> ? >    transformed data to compare the two models (raw data Gaussian vs
> ? >    b?ta)?
> ? 
> ?   I would think so.
> ? > 
> ? >    If so, the b?ta model seems better than the Gaussian one. But now
> ? >    comes the interpretation problem, other than ? are coefficients
> ? >    significantly different from 0? ?.
> ? > 
> ? > 4) Since the default link is the logit for the mean, interpretation is
> ? >    not quite clear for me.  For the Gaussian model on raw data,
> ? >    interpretation is clear, for instance ? men score 1 point lower
> ? >    than women in average??.  But how can the coefficients of the
> ? >    b?ta-model be back-converted in a similar fashion ?
> ? 
> ?    You probably need to go read stuff about interpretation of
> ? logit/log-odds  parameters: Gelman and Hill's book is good.
> ? 
> ? Quick rules of thumb:
> ? 
> ? * for ??x small, as for log (proportional)
> ? * for intermediate values, linear change in probability with
> ? slope ? ?/4
> ? * for large values, as for log ( 1 ? x )
> ? > 
> ? >    Would it be easier to use a log link and expression changes in the
> ? >    scale as percent changes on the mean?
> ? 
> ?   This will work fine for low score values, but will run into trouble at
> ? the upper end of the score range.
> ? 
> ? > 
> ? > Thanks in advance,
> ? >
> ? 
> ? _______________________________________________
> ? R-sig-mixed-models at r-project.org mailing list
> ? https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From d@rizopoulo@ @ending from er@@mu@mc@nl  Wed Sep 19 18:08:28 2018
From: d@rizopoulo@ @ending from er@@mu@mc@nl (D. Rizopoulos)
Date: Wed, 19 Sep 2018 16:08:28 +0000
Subject: [R-sig-ME] 
 =?utf-8?q?Comparing_Gaussian_and_b=C3=AAta_regression?=
In-Reply-To: <20180919150217.GD1527@info124.pharmacie.univ-paris5.fr>
References: <20180919073014.GA17416@info124.pharmacie.univ-paris5.fr>
 <12de47d9-468b-c5e1-c75c-aee8ce59ba86@gmail.com>
 <20180919150217.GD1527@info124.pharmacie.univ-paris5.fr>
Message-ID: <7191AFC7255B4F49A30707E39BEAD05FDEB7C6BF@EXCH-RX03.erasmusmc.nl>

An additional issue with the interpretation from the Beta mixed model would be that because of the nonlinear link function, the fixed effects coefficients will have an interpretation conditional on the random effects. This same issue you also for example have in the mixed effects logistic and Poisson regression models. Most often this is not the interpretation you want, i.e., a marginal/population interpretation.

Best,
Dimitris


-----Original Message-----
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> On Behalf Of Emmanuel Curis
Sent: Wednesday, September 19, 2018 5:02 PM
To: Ben Bolker <bbolker at gmail.com>
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Comparing Gaussian and b?ta regression

Thank you very much for the hints.

The ? not very satisfactory ? is from a "theoretical" point of view:
I'm not very comfortable with modeling with a Gaussian a value constrained between 0 and 10, with the extremes obtained not so rarely.  From a practical point of view, it does not seem to produce unexpected results.  Of course, there are some effects that are borderline significant, that also makes the question uprise: what is the part of true signal and basically inadequate model in these effects? Still finding them with a more sounded model would make them a little bit more "trustable"...

For the ordinal outcome: I have wrongly selected my example value, it induced in error, sorry ; the step is 0.1 and not 0.5 ; in practice,
46 different values were observed. Integer values and, to a less extent, half-integer values are clearly over-represented, I guess because of inconscient rounding during scoring.  I don't know how to handle this in a model, however, but that's another problem, and may be there is no need for that.  But, for the ordinal aspect, I fear that would make too much parameters in the model... 

Just thinking... Would it be imaginable to make inferences on the beta-distribution model, since it seems to much better describe the data, but use the linear model on the raw scale just to have point-estimates of the changes in an easiest-to-interpret way?
[despite it is problematic close to the boundaries...]

Is the Gelmann & Hill book you're thinking about this one: ?

Data Analysis Using Regression and Multilevel/Hierarchical Models  Cambridge University Press
ISBN-10: 052168689X

On Wed, Sep 19, 2018 at 09:49:51AM -0400, Ben Bolker wrote:
?
?
? On 2018-09-19 03:30 AM, Emmanuel Curis wrote:
? > Hello,
? >
? > I'm doing my first try on b?ta regression, with mixed effects model, ? > and was wondering if my reasonning is correct...
? >
? > The context is a clinical study where the outcome is a score variable, ? > with continuous values between 0 and 10 (both included) and, in ? > practice, values with only one decimal digit (eg. 1.5) There is ? > about 400 patients. Random effect is the clinician who does the ? > examination and afterthat collects the score that evaluates its ? > intervention.
? >
? > As a quick-and-dirty analysis, I did a linear mixed effect model on ? > the raw data, with lmer. Residuals and random effects are not so bad, ? > and results consistent & easy to interpret, but assuming a Gaussian ? > distribution is not very satisfactory.
?
? Can you expand on why "not very satisfactory"?  Do you get unrealistic ? predictions etc.?
? 
?   This sounds like it could also be treated as an ordinal response (with
? 21 values {0, 0.5, 1, ... 9.5, 10}).
? >
? > Hence, I tried a b?ta regression on the data after the transformation ? > (y/10 * (n-1) + 0.5) / n, and used glmmTMB for that. And of course I ? > wondered if the fit was better.
? >
? > 1) Is it right that ln-likelihood of the model on the raw data
? >    (Gaussian) and on the transformed data (b?ta) cannot be compared,
? >    because they involve probability densities and not probabilities,
? >    hence depend on the data scale ?
? 
?   You can compare log-likelihoods (actually technically they're
? log-likelihood *densities*, which is where the problem comes from) if ? you account for the scaling.  In this case since you're doing a linear ? transformation the scaling should be pretty easy.
? >
? > 2) Is it right that the lmer model done on the raw data and the same
? >    one done on the transformed data are conceptually the same, since
? >    the transformation is linear ? so that the ln-likelihood it gives
? >    is ? the same ? expressed in the two different scales? (of course,
? >    coefficients and so on will be different because of the scale
? >    change)
? 
?    Should be. (You could do a simple test of this ...)
? >
? > 3) And so, is it correct to compare the ln-likelihood (using logLik)
? >    or the AIC given by glmmTMB with the b?ta model and by lmer on
? >    transformed data to compare the two models (raw data Gaussian vs
? >    b?ta)?
? 
?   I would think so.
? > 
? >    If so, the b?ta model seems better than the Gaussian one. But now
? >    comes the interpretation problem, other than ? are coefficients
? >    significantly different from 0? ?.
? >
? > 4) Since the default link is the logit for the mean, interpretation is
? >    not quite clear for me.  For the Gaussian model on raw data,
? >    interpretation is clear, for instance ? men score 1 point lower
? >    than women in average??.  But how can the coefficients of the
? >    b?ta-model be back-converted in a similar fashion ?
? 
?    You probably need to go read stuff about interpretation of
? logit/log-odds  parameters: Gelman and Hill's book is good.
?
? Quick rules of thumb:
?
? * for ??x small, as for log (proportional) ? * for intermediate values, linear change in probability with ? slope ? ?/4 ? * for large values, as for log ( 1 ? x ) ? > 
? >    Would it be easier to use a log link and expression changes in the
? >    scale as percent changes on the mean?
? 
?   This will work fine for low score values, but will run into trouble at
? the upper end of the score range.
?
? >
? > Thanks in advance,
? >
?
? _______________________________________________
? R-sig-mixed-models at r-project.org mailing list ? https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
                                Emmanuel CURIS
                                emmanuel.curis at parisdescartes.fr

Page WWW: http://emmanuel.curis.online.fr/index.html

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

From mc@@tillomoine @ending from hotm@il@com  Wed Sep 19 19:33:35 2018
From: mc@@tillomoine @ending from hotm@il@com (=?iso-8859-1?Q?Mat=EDas_Alejandro_Castillo_Moine?=)
Date: Wed, 19 Sep 2018 17:33:35 +0000
Subject: [R-sig-ME] Additive random effects un lme
Message-ID: <RO1P152MB17559C8CA16C6EC3D71E6C3DC11C0@RO1P152MB1755.LAMP152.PROD.OUTLOOK.COM>

Hi everybody!

Additive random effects in lme


I?m working with lme() R function. I want to fit the following model y=u+A+B+e (where y is the response variable, u the general mean, A and B two categorical variables, and e the error term) but using only u as an fixed effect (so A and B must to be random effects but with additive response). How I can specify this model in lme function?

At moment, I was found this manner:


lme(y~1, random= ~1|A/B, data)


But the problem is that, according to the documentation of nlme package, that sintaxis will to fit an nested model of B nested on A.


In my case y are several biometrics variables of a crop, A are environments and B are genotypes. The term e will to include the interaction between A and B. Also, the error term is spatially correlated (I use the correlation argument for clean this effect).


Thanks you for your help!


Best regards,


Mat?as A. Castillo Moine

	[[alternative HTML version deleted]]


From bbolker @ending from gm@il@com  Thu Sep 20 03:46:39 2018
From: bbolker @ending from gm@il@com (Ben Bolker)
Date: Wed, 19 Sep 2018 21:46:39 -0400
Subject: [R-sig-ME] Additive random effects un lme
In-Reply-To: <RO1P152MB17559C8CA16C6EC3D71E6C3DC11C0@RO1P152MB1755.LAMP152.PROD.OUTLOOK.COM>
References: <RO1P152MB17559C8CA16C6EC3D71E6C3DC11C0@RO1P152MB1755.LAMP152.PROD.OUTLOOK.COM>
Message-ID: <387cec48-4efe-9f8b-6c57-0002eaaf9b1d@gmail.com>



  These are also called "crossed" random effects.  lme can do them in a
limited and complex way -- the syntax is given somewhere in one of the
later chapters of the Pinheiro and Bates 2000 book [see
https://stackoverflow.com/questions/36342072/how-to-get-two-random-effects-crossed-with-one-nested-in-the-other-in-nlme
] but it's much easier with lme4::lmer (y ~ 1 + (1|A) + (1|B)). Do you
have a reason you have to stick with lme?



On 2018-09-19 01:33 PM, Mat?as Alejandro Castillo Moine wrote:
> Hi everybody!
> 
> Additive random effects in lme
> 
> 
> I?m working with lme() R function. I want to fit the following model y=u+A+B+e (where y is the response variable, u the general mean, A and B two categorical variables, and e the error term) but using only u as an fixed effect (so A and B must to be random effects but with additive response). How I can specify this model in lme function?
> 
> At moment, I was found this manner:
> 
> 
> lme(y~1, random= ~1|A/B, data)
> 
> 
> But the problem is that, according to the documentation of nlme package, that sintaxis will to fit an nested model of B nested on A.
> 
> 
> In my case y are several biometrics variables of a crop, A are environments and B are genotypes. The term e will to include the interaction between A and B. Also, the error term is spatially correlated (I use the correlation argument for clean this effect).
> 
> 
> Thanks you for your help!
> 
> 
> Best regards,
> 
> 
> Mat?as A. Castillo Moine
> 
> 	[[alternative HTML version deleted]]
> 
> 
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From mengzhu@y@n @ending from vuw@@c@nz  Thu Sep 20 10:32:13 2018
From: mengzhu@y@n @ending from vuw@@c@nz (Mengzhu Yan)
Date: Thu, 20 Sep 2018 08:32:13 +0000
Subject: [R-sig-ME] planned comparisons-lmer
Message-ID: <ME1PR01MB1284D40EC1ECDEFF30EA79DEA6130@ME1PR01MB1284.ausprd01.prod.outlook.com>

Hi everyone,


I am running planned comparisons (using glht function in multcomp package) to test the differences between groups.


What I understand is that we have to apply corrections when we do more than one pairwise comparison, and it is not surprising that p-values will change (normally it becomes larger) when having more pairs.


I am interested in about 20 pairs of comparisons. Two hypotheses are being tested in the planned comparisons. Is it legitimate to have two sets of planned comparisons based on my hypotheses? My thought is no... But does anyone have an opinion on this?


I have tried keeping all comparisons in one set of comparisons using corrections like Tukey, repeated-t and Fisher's LSD Test, and Holm-Bonferroni. The p-values using LSD are the smallest followed by Tukey and Holm-Bonferroni. Reading from posts and discussions online, it seems none of post hoc test is best. But how should we justify ourselves when choosing a correction?


Have a nice day!?


Thanks,

Mengzhu


	[[alternative HTML version deleted]]


From emm@nuel@curi@ @ending from p@ri@de@c@rte@@fr  Fri Sep 21 09:34:12 2018
From: emm@nuel@curi@ @ending from p@ri@de@c@rte@@fr (Emmanuel Curis)
Date: Fri, 21 Sep 2018 09:34:12 +0200
Subject: [R-sig-ME] 
 =?iso-8859-1?q?Comparing_Gaussian_and_b=EAta_regressi?=
 =?iso-8859-1?q?on?=
In-Reply-To: <7191AFC7255B4F49A30707E39BEAD05FDEB7C6BF@EXCH-RX03.erasmusmc.nl>
References: <20180919073014.GA17416@info124.pharmacie.univ-paris5.fr>
 <12de47d9-468b-c5e1-c75c-aee8ce59ba86@gmail.com>
 <20180919150217.GD1527@info124.pharmacie.univ-paris5.fr>
 <7191AFC7255B4F49A30707E39BEAD05FDEB7C6BF@EXCH-RX03.erasmusmc.nl>
Message-ID: <20180921073412.GA2618@info124.pharmacie.univ-paris5.fr>

Hi,

Thanks for the information.  I must say that presently, I do not
understand what this means exactly, so I'm really curious about it.

I was naively thinking that fixed effects coefficients obtained were
estimates of the ? true ? coefficients in the model, and that because
of the maximum likelihood asymptotic properties, were asymptotically
unbiased.  Does this mean it is false? Or that they estimate something
else than these ? true ? coefficients? Or may be that even the notion
of ? true coefficient ? is not so clear?

Would it be possible to have a detailed, simple example, either
directly or through a reference?

Best regards,

On Wed, Sep 19, 2018 at 04:08:28PM +0000, D. Rizopoulos wrote:
? An additional issue with the interpretation from the Beta mixed model would be that because of the nonlinear link function, the fixed effects coefficients will have an interpretation conditional on the random effects. This same issue you also for example have in the mixed effects logistic and Poisson regression models. Most often this is not the interpretation you want, i.e., a marginal/population interpretation.
? 
? Best,
? Dimitris
? 
? 
? -----Original Message-----
? From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> On Behalf Of Emmanuel Curis
? Sent: Wednesday, September 19, 2018 5:02 PM
? To: Ben Bolker <bbolker at gmail.com>
? Cc: r-sig-mixed-models at r-project.org
? Subject: Re: [R-sig-ME] Comparing Gaussian and b?ta regression
? 
? Thank you very much for the hints.
? 
? The ? not very satisfactory ? is from a "theoretical" point of view:
? I'm not very comfortable with modeling with a Gaussian a value constrained between 0 and 10, with the extremes obtained not so rarely.  From a practical point of view, it does not seem to produce unexpected results.  Of course, there are some effects that are borderline significant, that also makes the question uprise: what is the part of true signal and basically inadequate model in these effects? Still finding them with a more sounded model would make them a little bit more "trustable"...
? 
? For the ordinal outcome: I have wrongly selected my example value, it induced in error, sorry ; the step is 0.1 and not 0.5 ; in practice,
? 46 different values were observed. Integer values and, to a less extent, half-integer values are clearly over-represented, I guess because of inconscient rounding during scoring.  I don't know how to handle this in a model, however, but that's another problem, and may be there is no need for that.  But, for the ordinal aspect, I fear that would make too much parameters in the model... 
? 
? Just thinking... Would it be imaginable to make inferences on the beta-distribution model, since it seems to much better describe the data, but use the linear model on the raw scale just to have point-estimates of the changes in an easiest-to-interpret way?
? [despite it is problematic close to the boundaries...]
? 
? Is the Gelmann & Hill book you're thinking about this one: ?
? 
? Data Analysis Using Regression and Multilevel/Hierarchical Models  Cambridge University Press
? ISBN-10: 052168689X
? 
? On Wed, Sep 19, 2018 at 09:49:51AM -0400, Ben Bolker wrote:
? ?
? ?
? ? On 2018-09-19 03:30 AM, Emmanuel Curis wrote:
? ? > Hello,
? ? >
? ? > I'm doing my first try on b?ta regression, with mixed effects model, ? > and was wondering if my reasonning is correct...
? ? >
? ? > The context is a clinical study where the outcome is a score variable, ? > with continuous values between 0 and 10 (both included) and, in ? > practice, values with only one decimal digit (eg. 1.5) There is ? > about 400 patients. Random effect is the clinician who does the ? > examination and afterthat collects the score that evaluates its ? > intervention.
? ? >
? ? > As a quick-and-dirty analysis, I did a linear mixed effect model on ? > the raw data, with lmer. Residuals and random effects are not so bad, ? > and results consistent & easy to interpret, but assuming a Gaussian ? > distribution is not very satisfactory.
? ?
? ? Can you expand on why "not very satisfactory"?  Do you get unrealistic ? predictions etc.?
? ? 
? ?   This sounds like it could also be treated as an ordinal response (with
? ? 21 values {0, 0.5, 1, ... 9.5, 10}).
? ? >
? ? > Hence, I tried a b?ta regression on the data after the transformation ? > (y/10 * (n-1) + 0.5) / n, and used glmmTMB for that. And of course I ? > wondered if the fit was better.
? ? >
? ? > 1) Is it right that ln-likelihood of the model on the raw data
? ? >    (Gaussian) and on the transformed data (b?ta) cannot be compared,
? ? >    because they involve probability densities and not probabilities,
? ? >    hence depend on the data scale ?
? ? 
? ?   You can compare log-likelihoods (actually technically they're
? ? log-likelihood *densities*, which is where the problem comes from) if ? you account for the scaling.  In this case since you're doing a linear ? transformation the scaling should be pretty easy.
? ? >
? ? > 2) Is it right that the lmer model done on the raw data and the same
? ? >    one done on the transformed data are conceptually the same, since
? ? >    the transformation is linear ? so that the ln-likelihood it gives
? ? >    is ? the same ? expressed in the two different scales? (of course,
? ? >    coefficients and so on will be different because of the scale
? ? >    change)
? ? 
? ?    Should be. (You could do a simple test of this ...)
? ? >
? ? > 3) And so, is it correct to compare the ln-likelihood (using logLik)
? ? >    or the AIC given by glmmTMB with the b?ta model and by lmer on
? ? >    transformed data to compare the two models (raw data Gaussian vs
? ? >    b?ta)?
? ? 
? ?   I would think so.
? ? > 
? ? >    If so, the b?ta model seems better than the Gaussian one. But now
? ? >    comes the interpretation problem, other than ? are coefficients
? ? >    significantly different from 0? ?.
? ? >
? ? > 4) Since the default link is the logit for the mean, interpretation is
? ? >    not quite clear for me.  For the Gaussian model on raw data,
? ? >    interpretation is clear, for instance ? men score 1 point lower
? ? >    than women in average??.  But how can the coefficients of the
? ? >    b?ta-model be back-converted in a similar fashion ?
? ? 
? ?    You probably need to go read stuff about interpretation of
? ? logit/log-odds  parameters: Gelman and Hill's book is good.
? ?
? ? Quick rules of thumb:
? ?
? ? * for ??x small, as for log (proportional) ? * for intermediate values, linear change in probability with ? slope ? ?/4 ? * for large values, as for log ( 1 ? x ) ? > 
? ? >    Would it be easier to use a log link and expression changes in the
? ? >    scale as percent changes on the mean?
? ? 
? ?   This will work fine for low score values, but will run into trouble at
? ? the upper end of the score range.
? ?
? ? >
? ? > Thanks in advance,
? ? >
? ?
? ? _______________________________________________
? ? R-sig-mixed-models at r-project.org mailing list ? https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
? 
? -- 
?                                 Emmanuel CURIS
?                                 emmanuel.curis at parisdescartes.fr
? 
? Page WWW: http://emmanuel.curis.online.fr/index.html
? 
? _______________________________________________
? R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
                                Emmanuel CURIS
                                emmanuel.curis at parisdescartes.fr

Page WWW: http://emmanuel.curis.online.fr/index.html


From d@rizopoulo@ @ending from er@@mu@mc@nl  Fri Sep 21 09:54:45 2018
From: d@rizopoulo@ @ending from er@@mu@mc@nl (D. Rizopoulos)
Date: Fri, 21 Sep 2018 07:54:45 +0000
Subject: [R-sig-ME] 
 =?utf-8?q?Comparing_Gaussian_and_b=C3=AAta_regression?=
In-Reply-To: <20180921073412.GA2618@info124.pharmacie.univ-paris5.fr>
References: <20180919073014.GA17416@info124.pharmacie.univ-paris5.fr>
 <12de47d9-468b-c5e1-c75c-aee8ce59ba86@gmail.com>
 <20180919150217.GD1527@info124.pharmacie.univ-paris5.fr>
 <7191AFC7255B4F49A30707E39BEAD05FDEB7C6BF@EXCH-RX03.erasmusmc.nl>
 <20180921073412.GA2618@info124.pharmacie.univ-paris5.fr>
Message-ID: <7191AFC7255B4F49A30707E39BEAD05FDEB7E890@EXCH-RX03.erasmusmc.nl>

The estimates of the coefficients are asymptotically unbiased, and indeed this stems from the properties of maximum likelihood. But what I'm talking about is the *interpretation* of these coefficients. The use of a nonlinear link function complicates things in that regard.

You may check more on this in this discussion on Cross Validated: https://stats.stackexchange.com/questions/365907/interpretation-of-fixed-effects-from-mixed-effect-logistic-regression

Best,
Dimitris

-----Original Message-----
From: Emmanuel Curis <emmanuel.curis at parisdescartes.fr> 
Sent: Friday, September 21, 2018 9:34 AM
To: D. Rizopoulos <d.rizopoulos at erasmusmc.nl>
Cc: Ben Bolker <bbolker at gmail.com>; r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Comparing Gaussian and b?ta regression

Hi,

Thanks for the information.  I must say that presently, I do not understand what this means exactly, so I'm really curious about it.

I was naively thinking that fixed effects coefficients obtained were estimates of the ? true ? coefficients in the model, and that because of the maximum likelihood asymptotic properties, were asymptotically unbiased.  Does this mean it is false? Or that they estimate something else than these ? true ? coefficients? Or may be that even the notion of ? true coefficient ? is not so clear?

Would it be possible to have a detailed, simple example, either directly or through a reference?

Best regards,

On Wed, Sep 19, 2018 at 04:08:28PM +0000, D. Rizopoulos wrote:
? An additional issue with the interpretation from the Beta mixed model would be that because of the nonlinear link function, the fixed effects coefficients will have an interpretation conditional on the random effects. This same issue you also for example have in the mixed effects logistic and Poisson regression models. Most often this is not the interpretation you want, i.e., a marginal/population interpretation.
?
? Best,
? Dimitris
?
?
? -----Original Message-----
? From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> On Behalf Of Emmanuel Curis ? Sent: Wednesday, September 19, 2018 5:02 PM ? To: Ben Bolker <bbolker at gmail.com> ? Cc: r-sig-mixed-models at r-project.org ? Subject: Re: [R-sig-ME] Comparing Gaussian and b?ta regression ? ? Thank you very much for the hints.
?
? The ? not very satisfactory ? is from a "theoretical" point of view:
? I'm not very comfortable with modeling with a Gaussian a value constrained between 0 and 10, with the extremes obtained not so rarely.  From a practical point of view, it does not seem to produce unexpected results.  Of course, there are some effects that are borderline significant, that also makes the question uprise: what is the part of true signal and basically inadequate model in these effects? Still finding them with a more sounded model would make them a little bit more "trustable"...
?
? For the ordinal outcome: I have wrongly selected my example value, it induced in error, sorry ; the step is 0.1 and not 0.5 ; in practice, ? 46 different values were observed. Integer values and, to a less extent, half-integer values are clearly over-represented, I guess because of inconscient rounding during scoring.  I don't know how to handle this in a model, however, but that's another problem, and may be there is no need for that.  But, for the ordinal aspect, I fear that would make too much parameters in the model... 
?
? Just thinking... Would it be imaginable to make inferences on the beta-distribution model, since it seems to much better describe the data, but use the linear model on the raw scale just to have point-estimates of the changes in an easiest-to-interpret way?
? [despite it is problematic close to the boundaries...] ? ? Is the Gelmann & Hill book you're thinking about this one: ?
?
? Data Analysis Using Regression and Multilevel/Hierarchical Models  Cambridge University Press ? ISBN-10: 052168689X ? ? On Wed, Sep 19, 2018 at 09:49:51AM -0400, Ben Bolker wrote:
? ?
? ?
? ? On 2018-09-19 03:30 AM, Emmanuel Curis wrote:
? ? > Hello,
? ? >
? ? > I'm doing my first try on b?ta regression, with mixed effects model, ? > and was wondering if my reasonning is correct...
? ? >
? ? > The context is a clinical study where the outcome is a score variable, ? > with continuous values between 0 and 10 (both included) and, in ? > practice, values with only one decimal digit (eg. 1.5) There is ? > about 400 patients. Random effect is the clinician who does the ? > examination and afterthat collects the score that evaluates its ? > intervention.
? ? >
? ? > As a quick-and-dirty analysis, I did a linear mixed effect model on ? > the raw data, with lmer. Residuals and random effects are not so bad, ? > and results consistent & easy to interpret, but assuming a Gaussian ? > distribution is not very satisfactory.
? ?
? ? Can you expand on why "not very satisfactory"?  Do you get unrealistic ? predictions etc.?
? ? 
? ?   This sounds like it could also be treated as an ordinal response (with
? ? 21 values {0, 0.5, 1, ... 9.5, 10}).
? ? >
? ? > Hence, I tried a b?ta regression on the data after the transformation ? > (y/10 * (n-1) + 0.5) / n, and used glmmTMB for that. And of course I ? > wondered if the fit was better.
? ? >
? ? > 1) Is it right that ln-likelihood of the model on the raw data
? ? >    (Gaussian) and on the transformed data (b?ta) cannot be compared,
? ? >    because they involve probability densities and not probabilities,
? ? >    hence depend on the data scale ?
? ? 
? ?   You can compare log-likelihoods (actually technically they're
? ? log-likelihood *densities*, which is where the problem comes from) if ? you account for the scaling.  In this case since you're doing a linear ? transformation the scaling should be pretty easy.
? ? >
? ? > 2) Is it right that the lmer model done on the raw data and the same
? ? >    one done on the transformed data are conceptually the same, since
? ? >    the transformation is linear ? so that the ln-likelihood it gives
? ? >    is ? the same ? expressed in the two different scales? (of course,
? ? >    coefficients and so on will be different because of the scale
? ? >    change)
? ? 
? ?    Should be. (You could do a simple test of this ...)
? ? >
? ? > 3) And so, is it correct to compare the ln-likelihood (using logLik)
? ? >    or the AIC given by glmmTMB with the b?ta model and by lmer on
? ? >    transformed data to compare the two models (raw data Gaussian vs
? ? >    b?ta)?
? ? 
? ?   I would think so.
? ? > 
? ? >    If so, the b?ta model seems better than the Gaussian one. But now
? ? >    comes the interpretation problem, other than ? are coefficients
? ? >    significantly different from 0? ?.
? ? >
? ? > 4) Since the default link is the logit for the mean, interpretation is
? ? >    not quite clear for me.  For the Gaussian model on raw data,
? ? >    interpretation is clear, for instance ? men score 1 point lower
? ? >    than women in average??.  But how can the coefficients of the
? ? >    b?ta-model be back-converted in a similar fashion ?
? ? 
? ?    You probably need to go read stuff about interpretation of
? ? logit/log-odds  parameters: Gelman and Hill's book is good.
? ?
? ? Quick rules of thumb:
? ?
? ? * for ??x small, as for log (proportional) ? * for intermediate values, linear change in probability with ? slope ? ?/4 ? * for large values, as for log ( 1 ? x ) ? > 
? ? >    Would it be easier to use a log link and expression changes in the
? ? >    scale as percent changes on the mean?
? ? 
? ?   This will work fine for low score values, but will run into trouble at
? ? the upper end of the score range.
? ?
? ? >
? ? > Thanks in advance,
? ? >
? ?
? ? _______________________________________________
? ? R-sig-mixed-models at r-project.org mailing list ? https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
?
? -- 
?                                 Emmanuel CURIS
?                                 emmanuel.curis at parisdescartes.fr
?
? Page WWW: http://emmanuel.curis.online.fr/index.html
?
? _______________________________________________
? R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
                                Emmanuel CURIS
                                emmanuel.curis at parisdescartes.fr

Page WWW: http://emmanuel.curis.online.fr/index.html

From emm@nuel@curi@ @ending from p@ri@de@c@rte@@fr  Fri Sep 21 15:20:01 2018
From: emm@nuel@curi@ @ending from p@ri@de@c@rte@@fr (Emmanuel Curis)
Date: Fri, 21 Sep 2018 15:20:01 +0200
Subject: [R-sig-ME] 
 =?iso-8859-1?q?Comparing_Gaussian_and_b=EAta_regressi?=
 =?iso-8859-1?q?on?=
In-Reply-To: <7191AFC7255B4F49A30707E39BEAD05FDEB7E890@EXCH-RX03.erasmusmc.nl>
References: <20180919073014.GA17416@info124.pharmacie.univ-paris5.fr>
 <12de47d9-468b-c5e1-c75c-aee8ce59ba86@gmail.com>
 <20180919150217.GD1527@info124.pharmacie.univ-paris5.fr>
 <7191AFC7255B4F49A30707E39BEAD05FDEB7C6BF@EXCH-RX03.erasmusmc.nl>
 <20180921073412.GA2618@info124.pharmacie.univ-paris5.fr>
 <7191AFC7255B4F49A30707E39BEAD05FDEB7E890@EXCH-RX03.erasmusmc.nl>
Message-ID: <20180921132001.GB11049@info124.pharmacie.univ-paris5.fr>

Thanks. It's more clear with the example on Cross Validated, but I'll
have to think about it carefully.

As I understand it now, the idea is as follow [I do not try to deal
with the scale-change exactly, it's just to illustrate has I
understand it]:

 - let assume the fixed effect coefficient for sex is one, for
   instance, and is is the only covariate for simplicity, except the
   random effect for clinicians

    => ? score is increased by one in males ?

 - let assume clinician 1 has random effect +0.1 and clinician 2 -0.1

 - interpretation should be done assuming all other variables
   constants, including random effects, here clinicians

    => score is increased by one in males for the same clinician

 - if now I compare between two clinicians, and assuming no
   interaction between sex and clinician, the difference between
   "score male, clinician 1" and "score female, clinician 2" is
     (+1 + 0.1) - (0 - 0.1) = 1.2

 - now the question is what happens when averaging on all clinicians
   (on the random effect)

 - in the ? usual ? linear model, the difference would be
     E( 1 + U1 - (0 + U2) ) = 1 + E(U1 - U2) = 1

   => the ? conditionnal ? effet is the same than when averaging other
   all clinicians
     (but comparing between two specific clinicians still will give a
      coefficient slightly different than +1)

 - in any model with a non-linear link function, in the original
   scale, the difference would be (with f the reciprocal of the link
   function, and assuming ? small ? random effects to use a second
   order Taylor expansion)

    E( f(1 + U1) - f(0 - U2) ) = E( f(1 + U1) ) - E( f(0 - U2) )

      ~ f(1) + E(f'(1) * U1) + E(f"(1) * U1?/2) -
        f(0) - E(f'(0) * U2) - E(f"(0) * U2?/2)
      
      = f(1) - f(0) + f"(1) E(U1?)/2 - f"(0) E(U2?)/2
        -----------
           delta

and delta is the fixed effect interpretation ? conditionnal ? on the
random effect, which is now different than the difference in the
population averaged over all clinicians.

Is this correct? [I guess Taylor expansion is unneeded here, I just
used it to see more clearly the "bias"]

Best regards,

On Fri, Sep 21, 2018 at 07:54:45AM +0000, D. Rizopoulos wrote:
? The estimates of the coefficients are asymptotically unbiased, and indeed this stems from the properties of maximum likelihood. But what I'm talking about is the *interpretation* of these coefficients. The use of a nonlinear link function complicates things in that regard.
? 
? You may check more on this in this discussion on Cross Validated: https://stats.stackexchange.com/questions/365907/interpretation-of-fixed-effects-from-mixed-effect-logistic-regression
? 
? Best,
? Dimitris
? 
? -----Original Message-----
? From: Emmanuel Curis <emmanuel.curis at parisdescartes.fr> 
? Sent: Friday, September 21, 2018 9:34 AM
? To: D. Rizopoulos <d.rizopoulos at erasmusmc.nl>
? Cc: Ben Bolker <bbolker at gmail.com>; r-sig-mixed-models at r-project.org
? Subject: Re: [R-sig-ME] Comparing Gaussian and b?ta regression
? 
? Hi,
? 
? Thanks for the information.  I must say that presently, I do not understand what this means exactly, so I'm really curious about it.
? 
? I was naively thinking that fixed effects coefficients obtained were estimates of the ? true ? coefficients in the model, and that because of the maximum likelihood asymptotic properties, were asymptotically unbiased.  Does this mean it is false? Or that they estimate something else than these ? true ? coefficients? Or may be that even the notion of ? true coefficient ? is not so clear?
? 
? Would it be possible to have a detailed, simple example, either directly or through a reference?
? 
? Best regards,
? 
? On Wed, Sep 19, 2018 at 04:08:28PM +0000, D. Rizopoulos wrote:
? ? An additional issue with the interpretation from the Beta mixed model would be that because of the nonlinear link function, the fixed effects coefficients will have an interpretation conditional on the random effects. This same issue you also for example have in the mixed effects logistic and Poisson regression models. Most often this is not the interpretation you want, i.e., a marginal/population interpretation.
? ?
? ? Best,
? ? Dimitris
? ?
? ?
? ? -----Original Message-----
? ? From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> On Behalf Of Emmanuel Curis ? Sent: Wednesday, September 19, 2018 5:02 PM ? To: Ben Bolker <bbolker at gmail.com> ? Cc: r-sig-mixed-models at r-project.org ? Subject: Re: [R-sig-ME] Comparing Gaussian and b?ta regression ? ? Thank you very much for the hints.
? ?
? ? The ? not very satisfactory ? is from a "theoretical" point of view:
? ? I'm not very comfortable with modeling with a Gaussian a value constrained between 0 and 10, with the extremes obtained not so rarely.  From a practical point of view, it does not seem to produce unexpected results.  Of course, there are some effects that are borderline significant, that also makes the question uprise: what is the part of true signal and basically inadequate model in these effects? Still finding them with a more sounded model would make them a little bit more "trustable"...
? ?
? ? For the ordinal outcome: I have wrongly selected my example value, it induced in error, sorry ; the step is 0.1 and not 0.5 ; in practice, ? 46 different values were observed. Integer values and, to a less extent, half-integer values are clearly over-represented, I guess because of inconscient rounding during scoring.  I don't know how to handle this in a model, however, but that's another problem, and may be there is no need for that.  But, for the ordinal aspect, I fear that would make too much parameters in the model... 
? ?
? ? Just thinking... Would it be imaginable to make inferences on the beta-distribution model, since it seems to much better describe the data, but use the linear model on the raw scale just to have point-estimates of the changes in an easiest-to-interpret way?
? ? [despite it is problematic close to the boundaries...] ? ? Is the Gelmann & Hill book you're thinking about this one: ?
? ?
? ? Data Analysis Using Regression and Multilevel/Hierarchical Models  Cambridge University Press ? ISBN-10: 052168689X ? ? On Wed, Sep 19, 2018 at 09:49:51AM -0400, Ben Bolker wrote:
? ? ?
? ? ?
? ? ? On 2018-09-19 03:30 AM, Emmanuel Curis wrote:
? ? ? > Hello,
? ? ? >
? ? ? > I'm doing my first try on b?ta regression, with mixed effects model, ? > and was wondering if my reasonning is correct...
? ? ? >
? ? ? > The context is a clinical study where the outcome is a score variable, ? > with continuous values between 0 and 10 (both included) and, in ? > practice, values with only one decimal digit (eg. 1.5) There is ? > about 400 patients. Random effect is the clinician who does the ? > examination and afterthat collects the score that evaluates its ? > intervention.
? ? ? >
? ? ? > As a quick-and-dirty analysis, I did a linear mixed effect model on ? > the raw data, with lmer. Residuals and random effects are not so bad, ? > and results consistent & easy to interpret, but assuming a Gaussian ? > distribution is not very satisfactory.
? ? ?
? ? ? Can you expand on why "not very satisfactory"?  Do you get unrealistic ? predictions etc.?
? ? ? 
? ? ?   This sounds like it could also be treated as an ordinal response (with
? ? ? 21 values {0, 0.5, 1, ... 9.5, 10}).
? ? ? >
? ? ? > Hence, I tried a b?ta regression on the data after the transformation ? > (y/10 * (n-1) + 0.5) / n, and used glmmTMB for that. And of course I ? > wondered if the fit was better.
? ? ? >
? ? ? > 1) Is it right that ln-likelihood of the model on the raw data
? ? ? >    (Gaussian) and on the transformed data (b?ta) cannot be compared,
? ? ? >    because they involve probability densities and not probabilities,
? ? ? >    hence depend on the data scale ?
? ? ? 
? ? ?   You can compare log-likelihoods (actually technically they're
? ? ? log-likelihood *densities*, which is where the problem comes from) if ? you account for the scaling.  In this case since you're doing a linear ? transformation the scaling should be pretty easy.
? ? ? >
? ? ? > 2) Is it right that the lmer model done on the raw data and the same
? ? ? >    one done on the transformed data are conceptually the same, since
? ? ? >    the transformation is linear ? so that the ln-likelihood it gives
? ? ? >    is ? the same ? expressed in the two different scales? (of course,
? ? ? >    coefficients and so on will be different because of the scale
? ? ? >    change)
? ? ? 
? ? ?    Should be. (You could do a simple test of this ...)
? ? ? >
? ? ? > 3) And so, is it correct to compare the ln-likelihood (using logLik)
? ? ? >    or the AIC given by glmmTMB with the b?ta model and by lmer on
? ? ? >    transformed data to compare the two models (raw data Gaussian vs
? ? ? >    b?ta)?
? ? ? 
? ? ?   I would think so.
? ? ? > 
? ? ? >    If so, the b?ta model seems better than the Gaussian one. But now
? ? ? >    comes the interpretation problem, other than ? are coefficients
? ? ? >    significantly different from 0? ?.
? ? ? >
? ? ? > 4) Since the default link is the logit for the mean, interpretation is
? ? ? >    not quite clear for me.  For the Gaussian model on raw data,
? ? ? >    interpretation is clear, for instance ? men score 1 point lower
? ? ? >    than women in average??.  But how can the coefficients of the
? ? ? >    b?ta-model be back-converted in a similar fashion ?
? ? ? 
? ? ?    You probably need to go read stuff about interpretation of
? ? ? logit/log-odds  parameters: Gelman and Hill's book is good.
? ? ?
? ? ? Quick rules of thumb:
? ? ?
? ? ? * for ??x small, as for log (proportional) ? * for intermediate values, linear change in probability with ? slope ? ?/4 ? * for large values, as for log ( 1 ? x ) ? > 
? ? ? >    Would it be easier to use a log link and expression changes in the
? ? ? >    scale as percent changes on the mean?
? ? ? 
? ? ?   This will work fine for low score values, but will run into trouble at
? ? ? the upper end of the score range.
? ? ?
? ? ? >
? ? ? > Thanks in advance,
? ? ? >
? ? ?
? ? ? _______________________________________________
? ? ? R-sig-mixed-models at r-project.org mailing list ? https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
? ?
? ? -- 
? ?                                 Emmanuel CURIS
? ?                                 emmanuel.curis at parisdescartes.fr
? ?
? ? Page WWW: http://emmanuel.curis.online.fr/index.html
? ?
? ? _______________________________________________
? ? R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
? 
? -- 
?                                 Emmanuel CURIS
?                                 emmanuel.curis at parisdescartes.fr
? 
? Page WWW: http://emmanuel.curis.online.fr/index.html

-- 
                                Emmanuel CURIS
                                emmanuel.curis at parisdescartes.fr

Page WWW: http://emmanuel.curis.online.fr/index.html


From bbolker @ending from gm@il@com  Fri Sep 21 15:42:35 2018
From: bbolker @ending from gm@il@com (Ben Bolker)
Date: Fri, 21 Sep 2018 09:42:35 -0400
Subject: [R-sig-ME] 
 =?utf-8?q?Comparing_Gaussian_and_b=C3=AAta_regression?=
In-Reply-To: <20180921132001.GB11049@info124.pharmacie.univ-paris5.fr>
References: <20180919073014.GA17416@info124.pharmacie.univ-paris5.fr>
 <12de47d9-468b-c5e1-c75c-aee8ce59ba86@gmail.com>
 <20180919150217.GD1527@info124.pharmacie.univ-paris5.fr>
 <7191AFC7255B4F49A30707E39BEAD05FDEB7C6BF@EXCH-RX03.erasmusmc.nl>
 <20180921073412.GA2618@info124.pharmacie.univ-paris5.fr>
 <7191AFC7255B4F49A30707E39BEAD05FDEB7E890@EXCH-RX03.erasmusmc.nl>
 <20180921132001.GB11049@info124.pharmacie.univ-paris5.fr>
Message-ID: <cd164e9e-559c-711c-a651-e13ac97efd70@gmail.com>


   Does anyone know offhand if there's R code (ideally a package)
floating around that implements these marginalization calculations for
mixed model estimates, by delta method or quadrature or simulation or
... ?  (The mixed-model ecosystem is getting pretty big and messy ...)
Do SAS/Stata/whatever have straightforward ways to do this that we could
copy?

  cheers
    Ben Bolker

On 2018-09-21 09:20 AM, Emmanuel Curis wrote:
> Thanks. It's more clear with the example on Cross Validated, but I'll
> have to think about it carefully.
> 
> As I understand it now, the idea is as follow [I do not try to deal
> with the scale-change exactly, it's just to illustrate has I
> understand it]:
> 
>  - let assume the fixed effect coefficient for sex is one, for
>    instance, and is is the only covariate for simplicity, except the
>    random effect for clinicians
> 
>     => ? score is increased by one in males ?
> 
>  - let assume clinician 1 has random effect +0.1 and clinician 2 -0.1
> 
>  - interpretation should be done assuming all other variables
>    constants, including random effects, here clinicians
> 
>     => score is increased by one in males for the same clinician
> 
>  - if now I compare between two clinicians, and assuming no
>    interaction between sex and clinician, the difference between
>    "score male, clinician 1" and "score female, clinician 2" is
>      (+1 + 0.1) - (0 - 0.1) = 1.2
> 
>  - now the question is what happens when averaging on all clinicians
>    (on the random effect)
> 
>  - in the ? usual ? linear model, the difference would be
>      E( 1 + U1 - (0 + U2) ) = 1 + E(U1 - U2) = 1
> 
>    => the ? conditionnal ? effet is the same than when averaging other
>    all clinicians
>      (but comparing between two specific clinicians still will give a
>       coefficient slightly different than +1)
> 
>  - in any model with a non-linear link function, in the original
>    scale, the difference would be (with f the reciprocal of the link
>    function, and assuming ? small ? random effects to use a second
>    order Taylor expansion)
> 
>     E( f(1 + U1) - f(0 - U2) ) = E( f(1 + U1) ) - E( f(0 - U2) )
> 
>       ~ f(1) + E(f'(1) * U1) + E(f"(1) * U1?/2) -
>         f(0) - E(f'(0) * U2) - E(f"(0) * U2?/2)
>       
>       = f(1) - f(0) + f"(1) E(U1?)/2 - f"(0) E(U2?)/2
>         -----------
>            delta
> 
> and delta is the fixed effect interpretation ? conditionnal ? on the
> random effect, which is now different than the difference in the
> population averaged over all clinicians.
> 
> Is this correct? [I guess Taylor expansion is unneeded here, I just
> used it to see more clearly the "bias"]
> 
> Best regards,
> 
> On Fri, Sep 21, 2018 at 07:54:45AM +0000, D. Rizopoulos wrote:
> ? The estimates of the coefficients are asymptotically unbiased, and indeed this stems from the properties of maximum likelihood. But what I'm talking about is the *interpretation* of these coefficients. The use of a nonlinear link function complicates things in that regard.
> ? 
> ? You may check more on this in this discussion on Cross Validated: https://stats.stackexchange.com/questions/365907/interpretation-of-fixed-effects-from-mixed-effect-logistic-regression
> ? 
> ? Best,
> ? Dimitris
> ? 
> ? -----Original Message-----
> ? From: Emmanuel Curis <emmanuel.curis at parisdescartes.fr> 
> ? Sent: Friday, September 21, 2018 9:34 AM
> ? To: D. Rizopoulos <d.rizopoulos at erasmusmc.nl>
> ? Cc: Ben Bolker <bbolker at gmail.com>; r-sig-mixed-models at r-project.org
> ? Subject: Re: [R-sig-ME] Comparing Gaussian and b?ta regression
> ? 
> ? Hi,
> ? 
> ? Thanks for the information.  I must say that presently, I do not understand what this means exactly, so I'm really curious about it.
> ? 
> ? I was naively thinking that fixed effects coefficients obtained were estimates of the ? true ? coefficients in the model, and that because of the maximum likelihood asymptotic properties, were asymptotically unbiased.  Does this mean it is false? Or that they estimate something else than these ? true ? coefficients? Or may be that even the notion of ? true coefficient ? is not so clear?
> ? 
> ? Would it be possible to have a detailed, simple example, either directly or through a reference?
> ? 
> ? Best regards,
> ? 
> ? On Wed, Sep 19, 2018 at 04:08:28PM +0000, D. Rizopoulos wrote:
> ? ? An additional issue with the interpretation from the Beta mixed model would be that because of the nonlinear link function, the fixed effects coefficients will have an interpretation conditional on the random effects. This same issue you also for example have in the mixed effects logistic and Poisson regression models. Most often this is not the interpretation you want, i.e., a marginal/population interpretation.
> ? ?
> ? ? Best,
> ? ? Dimitris
> ? ?
> ? ?
> ? ? -----Original Message-----
> ? ? From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> On Behalf Of Emmanuel Curis ? Sent: Wednesday, September 19, 2018 5:02 PM ? To: Ben Bolker <bbolker at gmail.com> ? Cc: r-sig-mixed-models at r-project.org ? Subject: Re: [R-sig-ME] Comparing Gaussian and b?ta regression ? ? Thank you very much for the hints.
> ? ?
> ? ? The ? not very satisfactory ? is from a "theoretical" point of view:
> ? ? I'm not very comfortable with modeling with a Gaussian a value constrained between 0 and 10, with the extremes obtained not so rarely.  From a practical point of view, it does not seem to produce unexpected results.  Of course, there are some effects that are borderline significant, that also makes the question uprise: what is the part of true signal and basically inadequate model in these effects? Still finding them with a more sounded model would make them a little bit more "trustable"...
> ? ?
> ? ? For the ordinal outcome: I have wrongly selected my example value, it induced in error, sorry ; the step is 0.1 and not 0.5 ; in practice, ? 46 different values were observed. Integer values and, to a less extent, half-integer values are clearly over-represented, I guess because of inconscient rounding during scoring.  I don't know how to handle this in a model, however, but that's another problem, and may be there is no need for that.  But, for the ordinal aspect, I fear that would make too much parameters in the model... 
> ? ?
> ? ? Just thinking... Would it be imaginable to make inferences on the beta-distribution model, since it seems to much better describe the data, but use the linear model on the raw scale just to have point-estimates of the changes in an easiest-to-interpret way?
> ? ? [despite it is problematic close to the boundaries...] ? ? Is the Gelmann & Hill book you're thinking about this one: ?
> ? ?
> ? ? Data Analysis Using Regression and Multilevel/Hierarchical Models  Cambridge University Press ? ISBN-10: 052168689X ? ? On Wed, Sep 19, 2018 at 09:49:51AM -0400, Ben Bolker wrote:
> ? ? ?
> ? ? ?
> ? ? ? On 2018-09-19 03:30 AM, Emmanuel Curis wrote:
> ? ? ? > Hello,
> ? ? ? >
> ? ? ? > I'm doing my first try on b?ta regression, with mixed effects model, ? > and was wondering if my reasonning is correct...
> ? ? ? >
> ? ? ? > The context is a clinical study where the outcome is a score variable, ? > with continuous values between 0 and 10 (both included) and, in ? > practice, values with only one decimal digit (eg. 1.5) There is ? > about 400 patients. Random effect is the clinician who does the ? > examination and afterthat collects the score that evaluates its ? > intervention.
> ? ? ? >
> ? ? ? > As a quick-and-dirty analysis, I did a linear mixed effect model on ? > the raw data, with lmer. Residuals and random effects are not so bad, ? > and results consistent & easy to interpret, but assuming a Gaussian ? > distribution is not very satisfactory.
> ? ? ?
> ? ? ? Can you expand on why "not very satisfactory"?  Do you get unrealistic ? predictions etc.?
> ? ? ? 
> ? ? ?   This sounds like it could also be treated as an ordinal response (with
> ? ? ? 21 values {0, 0.5, 1, ... 9.5, 10}).
> ? ? ? >
> ? ? ? > Hence, I tried a b?ta regression on the data after the transformation ? > (y/10 * (n-1) + 0.5) / n, and used glmmTMB for that. And of course I ? > wondered if the fit was better.
> ? ? ? >
> ? ? ? > 1) Is it right that ln-likelihood of the model on the raw data
> ? ? ? >    (Gaussian) and on the transformed data (b?ta) cannot be compared,
> ? ? ? >    because they involve probability densities and not probabilities,
> ? ? ? >    hence depend on the data scale ?
> ? ? ? 
> ? ? ?   You can compare log-likelihoods (actually technically they're
> ? ? ? log-likelihood *densities*, which is where the problem comes from) if ? you account for the scaling.  In this case since you're doing a linear ? transformation the scaling should be pretty easy.
> ? ? ? >
> ? ? ? > 2) Is it right that the lmer model done on the raw data and the same
> ? ? ? >    one done on the transformed data are conceptually the same, since
> ? ? ? >    the transformation is linear ? so that the ln-likelihood it gives
> ? ? ? >    is ? the same ? expressed in the two different scales? (of course,
> ? ? ? >    coefficients and so on will be different because of the scale
> ? ? ? >    change)
> ? ? ? 
> ? ? ?    Should be. (You could do a simple test of this ...)
> ? ? ? >
> ? ? ? > 3) And so, is it correct to compare the ln-likelihood (using logLik)
> ? ? ? >    or the AIC given by glmmTMB with the b?ta model and by lmer on
> ? ? ? >    transformed data to compare the two models (raw data Gaussian vs
> ? ? ? >    b?ta)?
> ? ? ? 
> ? ? ?   I would think so.
> ? ? ? > 
> ? ? ? >    If so, the b?ta model seems better than the Gaussian one. But now
> ? ? ? >    comes the interpretation problem, other than ? are coefficients
> ? ? ? >    significantly different from 0? ?.
> ? ? ? >
> ? ? ? > 4) Since the default link is the logit for the mean, interpretation is
> ? ? ? >    not quite clear for me.  For the Gaussian model on raw data,
> ? ? ? >    interpretation is clear, for instance ? men score 1 point lower
> ? ? ? >    than women in average??.  But how can the coefficients of the
> ? ? ? >    b?ta-model be back-converted in a similar fashion ?
> ? ? ? 
> ? ? ?    You probably need to go read stuff about interpretation of
> ? ? ? logit/log-odds  parameters: Gelman and Hill's book is good.
> ? ? ?
> ? ? ? Quick rules of thumb:
> ? ? ?
> ? ? ? * for ??x small, as for log (proportional) ? * for intermediate values, linear change in probability with ? slope ? ?/4 ? * for large values, as for log ( 1 ? x ) ? > 
> ? ? ? >    Would it be easier to use a log link and expression changes in the
> ? ? ? >    scale as percent changes on the mean?
> ? ? ? 
> ? ? ?   This will work fine for low score values, but will run into trouble at
> ? ? ? the upper end of the score range.
> ? ? ?
> ? ? ? >
> ? ? ? > Thanks in advance,
> ? ? ? >
> ? ? ?
> ? ? ? _______________________________________________
> ? ? ? R-sig-mixed-models at r-project.org mailing list ? https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> ? ?
> ? ? -- 
> ? ?                                 Emmanuel CURIS
> ? ?                                 emmanuel.curis at parisdescartes.fr
> ? ?
> ? ? Page WWW: http://emmanuel.curis.online.fr/index.html
> ? ?
> ? ? _______________________________________________
> ? ? R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> ? 
> ? -- 
> ?                                 Emmanuel CURIS
> ?                                 emmanuel.curis at parisdescartes.fr
> ? 
> ? Page WWW: http://emmanuel.curis.online.fr/index.html
>


From bbolker @ending from gm@il@com  Fri Sep 21 15:43:59 2018
From: bbolker @ending from gm@il@com (Ben Bolker)
Date: Fri, 21 Sep 2018 09:43:59 -0400
Subject: [R-sig-ME] 
 =?utf-8?q?Comparing_Gaussian_and_b=C3=AAta_regression?=
In-Reply-To: <20180921132001.GB11049@info124.pharmacie.univ-paris5.fr>
References: <20180919073014.GA17416@info124.pharmacie.univ-paris5.fr>
 <12de47d9-468b-c5e1-c75c-aee8ce59ba86@gmail.com>
 <20180919150217.GD1527@info124.pharmacie.univ-paris5.fr>
 <7191AFC7255B4F49A30707E39BEAD05FDEB7C6BF@EXCH-RX03.erasmusmc.nl>
 <20180921073412.GA2618@info124.pharmacie.univ-paris5.fr>
 <7191AFC7255B4F49A30707E39BEAD05FDEB7E890@EXCH-RX03.erasmusmc.nl>
 <20180921132001.GB11049@info124.pharmacie.univ-paris5.fr>
Message-ID: <52fd755b-12d5-bf8c-4c57-1a567a505c2a@gmail.com>


Also

https://stat.ethz.ch/pipermail/r-sig-mixed-models/2011q1/015736.html

On 2018-09-21 09:20 AM, Emmanuel Curis wrote:
> Thanks. It's more clear with the example on Cross Validated, but I'll
> have to think about it carefully.
> 
> As I understand it now, the idea is as follow [I do not try to deal
> with the scale-change exactly, it's just to illustrate has I
> understand it]:
> 
>  - let assume the fixed effect coefficient for sex is one, for
>    instance, and is is the only covariate for simplicity, except the
>    random effect for clinicians
> 
>     => ? score is increased by one in males ?
> 
>  - let assume clinician 1 has random effect +0.1 and clinician 2 -0.1
> 
>  - interpretation should be done assuming all other variables
>    constants, including random effects, here clinicians
> 
>     => score is increased by one in males for the same clinician
> 
>  - if now I compare between two clinicians, and assuming no
>    interaction between sex and clinician, the difference between
>    "score male, clinician 1" and "score female, clinician 2" is
>      (+1 + 0.1) - (0 - 0.1) = 1.2
> 
>  - now the question is what happens when averaging on all clinicians
>    (on the random effect)
> 
>  - in the ? usual ? linear model, the difference would be
>      E( 1 + U1 - (0 + U2) ) = 1 + E(U1 - U2) = 1
> 
>    => the ? conditionnal ? effet is the same than when averaging other
>    all clinicians
>      (but comparing between two specific clinicians still will give a
>       coefficient slightly different than +1)
> 
>  - in any model with a non-linear link function, in the original
>    scale, the difference would be (with f the reciprocal of the link
>    function, and assuming ? small ? random effects to use a second
>    order Taylor expansion)
> 
>     E( f(1 + U1) - f(0 - U2) ) = E( f(1 + U1) ) - E( f(0 - U2) )
> 
>       ~ f(1) + E(f'(1) * U1) + E(f"(1) * U1?/2) -
>         f(0) - E(f'(0) * U2) - E(f"(0) * U2?/2)
>       
>       = f(1) - f(0) + f"(1) E(U1?)/2 - f"(0) E(U2?)/2
>         -----------
>            delta
> 
> and delta is the fixed effect interpretation ? conditionnal ? on the
> random effect, which is now different than the difference in the
> population averaged over all clinicians.
> 
> Is this correct? [I guess Taylor expansion is unneeded here, I just
> used it to see more clearly the "bias"]
> 
> Best regards,
> 
> On Fri, Sep 21, 2018 at 07:54:45AM +0000, D. Rizopoulos wrote:
> ? The estimates of the coefficients are asymptotically unbiased, and indeed this stems from the properties of maximum likelihood. But what I'm talking about is the *interpretation* of these coefficients. The use of a nonlinear link function complicates things in that regard.
> ? 
> ? You may check more on this in this discussion on Cross Validated: https://stats.stackexchange.com/questions/365907/interpretation-of-fixed-effects-from-mixed-effect-logistic-regression
> ? 
> ? Best,
> ? Dimitris
> ? 
> ? -----Original Message-----
> ? From: Emmanuel Curis <emmanuel.curis at parisdescartes.fr> 
> ? Sent: Friday, September 21, 2018 9:34 AM
> ? To: D. Rizopoulos <d.rizopoulos at erasmusmc.nl>
> ? Cc: Ben Bolker <bbolker at gmail.com>; r-sig-mixed-models at r-project.org
> ? Subject: Re: [R-sig-ME] Comparing Gaussian and b?ta regression
> ? 
> ? Hi,
> ? 
> ? Thanks for the information.  I must say that presently, I do not understand what this means exactly, so I'm really curious about it.
> ? 
> ? I was naively thinking that fixed effects coefficients obtained were estimates of the ? true ? coefficients in the model, and that because of the maximum likelihood asymptotic properties, were asymptotically unbiased.  Does this mean it is false? Or that they estimate something else than these ? true ? coefficients? Or may be that even the notion of ? true coefficient ? is not so clear?
> ? 
> ? Would it be possible to have a detailed, simple example, either directly or through a reference?
> ? 
> ? Best regards,
> ? 
> ? On Wed, Sep 19, 2018 at 04:08:28PM +0000, D. Rizopoulos wrote:
> ? ? An additional issue with the interpretation from the Beta mixed model would be that because of the nonlinear link function, the fixed effects coefficients will have an interpretation conditional on the random effects. This same issue you also for example have in the mixed effects logistic and Poisson regression models. Most often this is not the interpretation you want, i.e., a marginal/population interpretation.
> ? ?
> ? ? Best,
> ? ? Dimitris
> ? ?
> ? ?
> ? ? -----Original Message-----
> ? ? From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> On Behalf Of Emmanuel Curis ? Sent: Wednesday, September 19, 2018 5:02 PM ? To: Ben Bolker <bbolker at gmail.com> ? Cc: r-sig-mixed-models at r-project.org ? Subject: Re: [R-sig-ME] Comparing Gaussian and b?ta regression ? ? Thank you very much for the hints.
> ? ?
> ? ? The ? not very satisfactory ? is from a "theoretical" point of view:
> ? ? I'm not very comfortable with modeling with a Gaussian a value constrained between 0 and 10, with the extremes obtained not so rarely.  From a practical point of view, it does not seem to produce unexpected results.  Of course, there are some effects that are borderline significant, that also makes the question uprise: what is the part of true signal and basically inadequate model in these effects? Still finding them with a more sounded model would make them a little bit more "trustable"...
> ? ?
> ? ? For the ordinal outcome: I have wrongly selected my example value, it induced in error, sorry ; the step is 0.1 and not 0.5 ; in practice, ? 46 different values were observed. Integer values and, to a less extent, half-integer values are clearly over-represented, I guess because of inconscient rounding during scoring.  I don't know how to handle this in a model, however, but that's another problem, and may be there is no need for that.  But, for the ordinal aspect, I fear that would make too much parameters in the model... 
> ? ?
> ? ? Just thinking... Would it be imaginable to make inferences on the beta-distribution model, since it seems to much better describe the data, but use the linear model on the raw scale just to have point-estimates of the changes in an easiest-to-interpret way?
> ? ? [despite it is problematic close to the boundaries...] ? ? Is the Gelmann & Hill book you're thinking about this one: ?
> ? ?
> ? ? Data Analysis Using Regression and Multilevel/Hierarchical Models  Cambridge University Press ? ISBN-10: 052168689X ? ? On Wed, Sep 19, 2018 at 09:49:51AM -0400, Ben Bolker wrote:
> ? ? ?
> ? ? ?
> ? ? ? On 2018-09-19 03:30 AM, Emmanuel Curis wrote:
> ? ? ? > Hello,
> ? ? ? >
> ? ? ? > I'm doing my first try on b?ta regression, with mixed effects model, ? > and was wondering if my reasonning is correct...
> ? ? ? >
> ? ? ? > The context is a clinical study where the outcome is a score variable, ? > with continuous values between 0 and 10 (both included) and, in ? > practice, values with only one decimal digit (eg. 1.5) There is ? > about 400 patients. Random effect is the clinician who does the ? > examination and afterthat collects the score that evaluates its ? > intervention.
> ? ? ? >
> ? ? ? > As a quick-and-dirty analysis, I did a linear mixed effect model on ? > the raw data, with lmer. Residuals and random effects are not so bad, ? > and results consistent & easy to interpret, but assuming a Gaussian ? > distribution is not very satisfactory.
> ? ? ?
> ? ? ? Can you expand on why "not very satisfactory"?  Do you get unrealistic ? predictions etc.?
> ? ? ? 
> ? ? ?   This sounds like it could also be treated as an ordinal response (with
> ? ? ? 21 values {0, 0.5, 1, ... 9.5, 10}).
> ? ? ? >
> ? ? ? > Hence, I tried a b?ta regression on the data after the transformation ? > (y/10 * (n-1) + 0.5) / n, and used glmmTMB for that. And of course I ? > wondered if the fit was better.
> ? ? ? >
> ? ? ? > 1) Is it right that ln-likelihood of the model on the raw data
> ? ? ? >    (Gaussian) and on the transformed data (b?ta) cannot be compared,
> ? ? ? >    because they involve probability densities and not probabilities,
> ? ? ? >    hence depend on the data scale ?
> ? ? ? 
> ? ? ?   You can compare log-likelihoods (actually technically they're
> ? ? ? log-likelihood *densities*, which is where the problem comes from) if ? you account for the scaling.  In this case since you're doing a linear ? transformation the scaling should be pretty easy.
> ? ? ? >
> ? ? ? > 2) Is it right that the lmer model done on the raw data and the same
> ? ? ? >    one done on the transformed data are conceptually the same, since
> ? ? ? >    the transformation is linear ? so that the ln-likelihood it gives
> ? ? ? >    is ? the same ? expressed in the two different scales? (of course,
> ? ? ? >    coefficients and so on will be different because of the scale
> ? ? ? >    change)
> ? ? ? 
> ? ? ?    Should be. (You could do a simple test of this ...)
> ? ? ? >
> ? ? ? > 3) And so, is it correct to compare the ln-likelihood (using logLik)
> ? ? ? >    or the AIC given by glmmTMB with the b?ta model and by lmer on
> ? ? ? >    transformed data to compare the two models (raw data Gaussian vs
> ? ? ? >    b?ta)?
> ? ? ? 
> ? ? ?   I would think so.
> ? ? ? > 
> ? ? ? >    If so, the b?ta model seems better than the Gaussian one. But now
> ? ? ? >    comes the interpretation problem, other than ? are coefficients
> ? ? ? >    significantly different from 0? ?.
> ? ? ? >
> ? ? ? > 4) Since the default link is the logit for the mean, interpretation is
> ? ? ? >    not quite clear for me.  For the Gaussian model on raw data,
> ? ? ? >    interpretation is clear, for instance ? men score 1 point lower
> ? ? ? >    than women in average??.  But how can the coefficients of the
> ? ? ? >    b?ta-model be back-converted in a similar fashion ?
> ? ? ? 
> ? ? ?    You probably need to go read stuff about interpretation of
> ? ? ? logit/log-odds  parameters: Gelman and Hill's book is good.
> ? ? ?
> ? ? ? Quick rules of thumb:
> ? ? ?
> ? ? ? * for ??x small, as for log (proportional) ? * for intermediate values, linear change in probability with ? slope ? ?/4 ? * for large values, as for log ( 1 ? x ) ? > 
> ? ? ? >    Would it be easier to use a log link and expression changes in the
> ? ? ? >    scale as percent changes on the mean?
> ? ? ? 
> ? ? ?   This will work fine for low score values, but will run into trouble at
> ? ? ? the upper end of the score range.
> ? ? ?
> ? ? ? >
> ? ? ? > Thanks in advance,
> ? ? ? >
> ? ? ?
> ? ? ? _______________________________________________
> ? ? ? R-sig-mixed-models at r-project.org mailing list ? https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> ? ?
> ? ? -- 
> ? ?                                 Emmanuel CURIS
> ? ?                                 emmanuel.curis at parisdescartes.fr
> ? ?
> ? ? Page WWW: http://emmanuel.curis.online.fr/index.html
> ? ?
> ? ? _______________________________________________
> ? ? R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> ? 
> ? -- 
> ?                                 Emmanuel CURIS
> ?                                 emmanuel.curis at parisdescartes.fr
> ? 
> ? Page WWW: http://emmanuel.curis.online.fr/index.html
>


From d@rizopoulo@ @ending from er@@mu@mc@nl  Fri Sep 21 16:03:35 2018
From: d@rizopoulo@ @ending from er@@mu@mc@nl (D. Rizopoulos)
Date: Fri, 21 Sep 2018 14:03:35 +0000
Subject: [R-sig-ME] 
 =?utf-8?q?Comparing_Gaussian_and_b=C3=AAta_regression?=
In-Reply-To: <20180921132001.GB11049@info124.pharmacie.univ-paris5.fr>
References: <20180919073014.GA17416@info124.pharmacie.univ-paris5.fr>
 <12de47d9-468b-c5e1-c75c-aee8ce59ba86@gmail.com>
 <20180919150217.GD1527@info124.pharmacie.univ-paris5.fr>
 <7191AFC7255B4F49A30707E39BEAD05FDEB7C6BF@EXCH-RX03.erasmusmc.nl>
 <20180921073412.GA2618@info124.pharmacie.univ-paris5.fr>
 <7191AFC7255B4F49A30707E39BEAD05FDEB7E890@EXCH-RX03.erasmusmc.nl>,
 <20180921132001.GB11049@info124.pharmacie.univ-paris5.fr>
Message-ID: <7191AFC7255B4F49A30707E39BEAD05FDEB7F195@EXCH-RX03.erasmusmc.nl>

Yes, I think this is correct. But I would really call it ?bias?. The issue is that the intepretation is different.

Best,
Dimitris

From: Emmanuel Curis <emmanuel.curis at parisdescartes.fr<mailto:emmanuel.curis at parisdescartes.fr>>
Date: Friday, 21 Sep 2018, 3:20 PM
To: D. Rizopoulos <d.rizopoulos at erasmusmc.nl<mailto:d.rizopoulos at erasmusmc.nl>>
Cc: Ben Bolker <bbolker at gmail.com<mailto:bbolker at gmail.com>>, r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>>
Subject: Re: [R-sig-ME] Comparing Gaussian and b?ta regression

Thanks. It's more clear with the example on Cross Validated, but I'll
have to think about it carefully.

As I understand it now, the idea is as follow [I do not try to deal
with the scale-change exactly, it's just to illustrate has I
understand it]:

 - let assume the fixed effect coefficient for sex is one, for
   instance, and is is the only covariate for simplicity, except the
   random effect for clinicians

    => ? score is increased by one in males ?

 - let assume clinician 1 has random effect +0.1 and clinician 2 -0.1

 - interpretation should be done assuming all other variables
   constants, including random effects, here clinicians

    => score is increased by one in males for the same clinician

 - if now I compare between two clinicians, and assuming no
   interaction between sex and clinician, the difference between
   "score male, clinician 1" and "score female, clinician 2" is
     (+1 + 0.1) - (0 - 0.1) = 1.2

 - now the question is what happens when averaging on all clinicians
   (on the random effect)

 - in the ? usual ? linear model, the difference would be
     E( 1 + U1 - (0 + U2) ) = 1 + E(U1 - U2) = 1

   => the ? conditionnal ? effet is the same than when averaging other
   all clinicians
     (but comparing between two specific clinicians still will give a
      coefficient slightly different than +1)

 - in any model with a non-linear link function, in the original
   scale, the difference would be (with f the reciprocal of the link
   function, and assuming ? small ? random effects to use a second
   order Taylor expansion)

    E( f(1 + U1) - f(0 - U2) ) = E( f(1 + U1) ) - E( f(0 - U2) )

      ~ f(1) + E(f'(1) * U1) + E(f"(1) * U1?/2) -
        f(0) - E(f'(0) * U2) - E(f"(0) * U2?/2)

      = f(1) - f(0) + f"(1) E(U1?)/2 - f"(0) E(U2?)/2
        -----------
           delta

and delta is the fixed effect interpretation ? conditionnal ? on the
random effect, which is now different than the difference in the
population averaged over all clinicians.

Is this correct? [I guess Taylor expansion is unneeded here, I just
used it to see more clearly the "bias"]

Best regards,

On Fri, Sep 21, 2018 at 07:54:45AM +0000, D. Rizopoulos wrote:
? The estimates of the coefficients are asymptotically unbiased, and indeed this stems from the properties of maximum likelihood. But what I'm talking about is the *interpretation* of these coefficients. The use of a nonlinear link function complicates things in that regard.
?
? You may check more on this in this discussion on Cross Validated: https://stats.stackexchange.com/questions/365907/interpretation-of-fixed-effects-from-mixed-effect-logistic-regression
?
? Best,
? Dimitris
?
? -----Original Message-----
? From: Emmanuel Curis <emmanuel.curis at parisdescartes.fr>
? Sent: Friday, September 21, 2018 9:34 AM
? To: D. Rizopoulos <d.rizopoulos at erasmusmc.nl>
? Cc: Ben Bolker <bbolker at gmail.com>; r-sig-mixed-models at r-project.org
? Subject: Re: [R-sig-ME] Comparing Gaussian and b?ta regression
?
? Hi,
?
? Thanks for the information.  I must say that presently, I do not understand what this means exactly, so I'm really curious about it.
?
? I was naively thinking that fixed effects coefficients obtained were estimates of the ? true ? coefficients in the model, and that because of the maximum likelihood asymptotic properties, were asymptotically unbiased.  Does this mean it is false? Or that they estimate something else than these ? true ? coefficients? Or may be that even the notion of ? true coefficient ? is not so clear?
?
? Would it be possible to have a detailed, simple example, either directly or through a reference?
?
? Best regards,
?
? On Wed, Sep 19, 2018 at 04:08:28PM +0000, D. Rizopoulos wrote:
? ? An additional issue with the interpretation from the Beta mixed model would be that because of the nonlinear link function, the fixed effects coefficients will have an interpretation conditional on the random effects. This same issue you also for example have in the mixed effects logistic and Poisson regression models. Most often this is not the interpretation you want, i.e., a marginal/population interpretation.
? ?
? ? Best,
? ? Dimitris
? ?
? ?
? ? -----Original Message-----
? ? From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> On Behalf Of Emmanuel Curis ? Sent: Wednesday, September 19, 2018 5:02 PM ? To: Ben Bolker <bbolker at gmail.com> ? Cc: r-sig-mixed-models at r-project.org ? Subject: Re: [R-sig-ME] Comparing Gaussian and b?ta regression ? ? Thank you very much for the hints.
? ?
? ? The ? not very satisfactory ? is from a "theoretical" point of view:
? ? I'm not very comfortable with modeling with a Gaussian a value constrained between 0 and 10, with the extremes obtained not so rarely.  From a practical point of view, it does not seem to produce unexpected results.  Of course, there are some effects that are borderline significant, that also makes the question uprise: what is the part of true signal and basically inadequate model in these effects? Still finding them with a more sounded model would make them a little bit more "trustable"...
? ?
? ? For the ordinal outcome: I have wrongly selected my example value, it induced in error, sorry ; the step is 0.1 and not 0.5 ; in practice, ? 46 different values were observed. Integer values and, to a less extent, half-integer values are clearly over-represented, I guess because of inconscient rounding during scoring.  I don't know how to handle this in a model, however, but that's another problem, and may be there is no need for that.  But, for the ordinal aspect, I fear that would make too much parameters in the model...
? ?
? ? Just thinking... Would it be imaginable to make inferences on the beta-distribution model, since it seems to much better describe the data, but use the linear model on the raw scale just to have point-estimates of the changes in an easiest-to-interpret way?
? ? [despite it is problematic close to the boundaries...] ? ? Is the Gelmann & Hill book you're thinking about this one: ?
? ?
? ? Data Analysis Using Regression and Multilevel/Hierarchical Models  Cambridge University Press ? ISBN-10: 052168689X ? ? On Wed, Sep 19, 2018 at 09:49:51AM -0400, Ben Bolker wrote:
? ? ?
? ? ?
? ? ? On 2018-09-19 03:30 AM, Emmanuel Curis wrote:
? ? ? > Hello,
? ? ? >
? ? ? > I'm doing my first try on b?ta regression, with mixed effects model, ? > and was wondering if my reasonning is correct...
? ? ? >
? ? ? > The context is a clinical study where the outcome is a score variable, ? > with continuous values between 0 and 10 (both included) and, in ? > practice, values with only one decimal digit (eg. 1.5) There is ? > about 400 patients. Random effect is the clinician who does the ? > examination and afterthat collects the score that evaluates its ? > intervention.
? ? ? >
? ? ? > As a quick-and-dirty analysis, I did a linear mixed effect model on ? > the raw data, with lmer. Residuals and random effects are not so bad, ? > and results consistent & easy to interpret, but assuming a Gaussian ? > distribution is not very satisfactory.
? ? ?
? ? ? Can you expand on why "not very satisfactory"?  Do you get unrealistic ? predictions etc.?
? ? ?
? ? ?   This sounds like it could also be treated as an ordinal response (with
? ? ? 21 values {0, 0.5, 1, ... 9.5, 10}).
? ? ? >
? ? ? > Hence, I tried a b?ta regression on the data after the transformation ? > (y/10 * (n-1) + 0.5) / n, and used glmmTMB for that. And of course I ? > wondered if the fit was better.
? ? ? >
? ? ? > 1) Is it right that ln-likelihood of the model on the raw data
? ? ? >    (Gaussian) and on the transformed data (b?ta) cannot be compared,
? ? ? >    because they involve probability densities and not probabilities,
? ? ? >    hence depend on the data scale ?
? ? ?
? ? ?   You can compare log-likelihoods (actually technically they're
? ? ? log-likelihood *densities*, which is where the problem comes from) if ? you account for the scaling.  In this case since you're doing a linear ? transformation the scaling should be pretty easy.
? ? ? >
? ? ? > 2) Is it right that the lmer model done on the raw data and the same
? ? ? >    one done on the transformed data are conceptually the same, since
? ? ? >    the transformation is linear ? so that the ln-likelihood it gives
? ? ? >    is ? the same ? expressed in the two different scales? (of course,
? ? ? >    coefficients and so on will be different because of the scale
? ? ? >    change)
? ? ?
? ? ?    Should be. (You could do a simple test of this ...)
? ? ? >
? ? ? > 3) And so, is it correct to compare the ln-likelihood (using logLik)
? ? ? >    or the AIC given by glmmTMB with the b?ta model and by lmer on
? ? ? >    transformed data to compare the two models (raw data Gaussian vs
? ? ? >    b?ta)?
? ? ?
? ? ?   I would think so.
? ? ? >
? ? ? >    If so, the b?ta model seems better than the Gaussian one. But now
? ? ? >    comes the interpretation problem, other than ? are coefficients
? ? ? >    significantly different from 0? ?.
? ? ? >
? ? ? > 4) Since the default link is the logit for the mean, interpretation is
? ? ? >    not quite clear for me.  For the Gaussian model on raw data,
? ? ? >    interpretation is clear, for instance ? men score 1 point lower
? ? ? >    than women in average ?.  But how can the coefficients of the
? ? ? >    b?ta-model be back-converted in a similar fashion ?
? ? ?
? ? ?    You probably need to go read stuff about interpretation of
? ? ? logit/log-odds  parameters: Gelman and Hill's book is good.
? ? ?
? ? ? Quick rules of thumb:
? ? ?
? ? ? * for ??x small, as for log (proportional) ? * for intermediate values, linear change in probability with ? slope ? ?/4 ? * for large values, as for log ( 1 ? x ) ? >
? ? ? >    Would it be easier to use a log link and expression changes in the
? ? ? >    scale as percent changes on the mean?
? ? ?
? ? ?   This will work fine for low score values, but will run into trouble at
? ? ? the upper end of the score range.
? ? ?
? ? ? >
? ? ? > Thanks in advance,
? ? ? >
? ? ?
? ? ? _______________________________________________
? ? ? R-sig-mixed-models at r-project.org mailing list ? https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
? ?
? ? --
? ?                                 Emmanuel CURIS
? ?                                 emmanuel.curis at parisdescartes.fr
? ?
? ? Page WWW: http://emmanuel.curis.online.fr/index.html
? ?
? ? _______________________________________________
? ? R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
?
? --
?                                 Emmanuel CURIS
?                                 emmanuel.curis at parisdescartes.fr
?
? Page WWW: http://emmanuel.curis.online.fr/index.html

--
                                Emmanuel CURIS
                                emmanuel.curis at parisdescartes.fr

Page WWW: http://emmanuel.curis.online.fr/index.html

	[[alternative HTML version deleted]]


From d@rizopoulo@ @ending from er@@mu@mc@nl  Fri Sep 21 16:10:46 2018
From: d@rizopoulo@ @ending from er@@mu@mc@nl (D. Rizopoulos)
Date: Fri, 21 Sep 2018 14:10:46 +0000
Subject: [R-sig-ME] 
 =?utf-8?q?Comparing_Gaussian_and_b=C3=AAta_regression?=
In-Reply-To: <cd164e9e-559c-711c-a651-e13ac97efd70@gmail.com>
References: <20180919073014.GA17416@info124.pharmacie.univ-paris5.fr>
 <12de47d9-468b-c5e1-c75c-aee8ce59ba86@gmail.com>
 <20180919150217.GD1527@info124.pharmacie.univ-paris5.fr>
 <7191AFC7255B4F49A30707E39BEAD05FDEB7C6BF@EXCH-RX03.erasmusmc.nl>
 <20180921073412.GA2618@info124.pharmacie.univ-paris5.fr>
 <7191AFC7255B4F49A30707E39BEAD05FDEB7E890@EXCH-RX03.erasmusmc.nl>
 <20180921132001.GB11049@info124.pharmacie.univ-paris5.fr>,
 <cd164e9e-559c-711c-a651-e13ac97efd70@gmail.com>
Message-ID: <7191AFC7255B4F49A30707E39BEAD05FDEB7F223@EXCH-RX03.erasmusmc.nl>

In the case of only random intercepts, there are formulas that you can use to obtain the marginalized coefficients. I.e.,

\beta^M = \beta^SS / sqrt(1 + \kappa * \sigma_b^2),

where \beta^SS are the subject-specific coefficients, \kappa is a constant that depends on the link function, and \sigma_b^2 the variance of the random intercepts.

For the case with more random effects, Heagerty and colleagues have worked on marginalized models, but these are rather complicated.

However, recently Hedeker et al. (2017) came up with a nice a simple idea to obtain the marginalized coefficients. This is implemented in the function marginal_coefs() of my GLMMadaptive package; check https://drizopoulos.github.io/GLMMadaptive/articles/Methods_MixMod.html#marginalized-coefficients

Best,
Dimitris

From: Ben Bolker <bbolker at gmail.com<mailto:bbolker at gmail.com>>
Date: Friday, 21 Sep 2018, 4:02 PM
To: Emmanuel Curis <emmanuel.curis at parisdescartes.fr<mailto:emmanuel.curis at parisdescartes.fr>>, D. Rizopoulos <d.rizopoulos at erasmusmc.nl<mailto:d.rizopoulos at erasmusmc.nl>>
Cc: r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>>
Subject: Re: [R-sig-ME] Comparing Gaussian and b?ta regression


   Does anyone know offhand if there's R code (ideally a package)
floating around that implements these marginalization calculations for
mixed model estimates, by delta method or quadrature or simulation or
... ?  (The mixed-model ecosystem is getting pretty big and messy ...)
Do SAS/Stata/whatever have straightforward ways to do this that we could
copy?

  cheers
    Ben Bolker

On 2018-09-21 09:20 AM, Emmanuel Curis wrote:
> Thanks. It's more clear with the example on Cross Validated, but I'll
> have to think about it carefully.
>
> As I understand it now, the idea is as follow [I do not try to deal
> with the scale-change exactly, it's just to illustrate has I
> understand it]:
>
>  - let assume the fixed effect coefficient for sex is one, for
>    instance, and is is the only covariate for simplicity, except the
>    random effect for clinicians
>
>     => ? score is increased by one in males ?
>
>  - let assume clinician 1 has random effect +0.1 and clinician 2 -0.1
>
>  - interpretation should be done assuming all other variables
>    constants, including random effects, here clinicians
>
>     => score is increased by one in males for the same clinician
>
>  - if now I compare between two clinicians, and assuming no
>    interaction between sex and clinician, the difference between
>    "score male, clinician 1" and "score female, clinician 2" is
>      (+1 + 0.1) - (0 - 0.1) = 1.2
>
>  - now the question is what happens when averaging on all clinicians
>    (on the random effect)
>
>  - in the ? usual ? linear model, the difference would be
>      E( 1 + U1 - (0 + U2) ) = 1 + E(U1 - U2) = 1
>
>    => the ? conditionnal ? effet is the same than when averaging other
>    all clinicians
>      (but comparing between two specific clinicians still will give a
>       coefficient slightly different than +1)
>
>  - in any model with a non-linear link function, in the original
>    scale, the difference would be (with f the reciprocal of the link
>    function, and assuming ? small ? random effects to use a second
>    order Taylor expansion)
>
>     E( f(1 + U1) - f(0 - U2) ) = E( f(1 + U1) ) - E( f(0 - U2) )
>
>       ~ f(1) + E(f'(1) * U1) + E(f"(1) * U1?/2) -
>         f(0) - E(f'(0) * U2) - E(f"(0) * U2?/2)
>
>       = f(1) - f(0) + f"(1) E(U1?)/2 - f"(0) E(U2?)/2
>         -----------
>            delta
>
> and delta is the fixed effect interpretation ? conditionnal ? on the
> random effect, which is now different than the difference in the
> population averaged over all clinicians.
>
> Is this correct? [I guess Taylor expansion is unneeded here, I just
> used it to see more clearly the "bias"]
>
> Best regards,
>
> On Fri, Sep 21, 2018 at 07:54:45AM +0000, D. Rizopoulos wrote:
> ? The estimates of the coefficients are asymptotically unbiased, and indeed this stems from the properties of maximum likelihood. But what I'm talking about is the *interpretation* of these coefficients. The use of a nonlinear link function complicates things in that regard.
> ?
> ? You may check more on this in this discussion on Cross Validated: https://stats.stackexchange.com/questions/365907/interpretation-of-fixed-effects-from-mixed-effect-logistic-regression
> ?
> ? Best,
> ? Dimitris
> ?
> ? -----Original Message-----
> ? From: Emmanuel Curis <emmanuel.curis at parisdescartes.fr>
> ? Sent: Friday, September 21, 2018 9:34 AM
> ? To: D. Rizopoulos <d.rizopoulos at erasmusmc.nl>
> ? Cc: Ben Bolker <bbolker at gmail.com>; r-sig-mixed-models at r-project.org
> ? Subject: Re: [R-sig-ME] Comparing Gaussian and b?ta regression
> ?
> ? Hi,
> ?
> ? Thanks for the information.  I must say that presently, I do not understand what this means exactly, so I'm really curious about it.
> ?
> ? I was naively thinking that fixed effects coefficients obtained were estimates of the ? true ? coefficients in the model, and that because of the maximum likelihood asymptotic properties, were asymptotically unbiased.  Does this mean it is false? Or that they estimate something else than these ? true ? coefficients? Or may be that even the notion of ? true coefficient ? is not so clear?
> ?
> ? Would it be possible to have a detailed, simple example, either directly or through a reference?
> ?
> ? Best regards,
> ?
> ? On Wed, Sep 19, 2018 at 04:08:28PM +0000, D. Rizopoulos wrote:
> ? ? An additional issue with the interpretation from the Beta mixed model would be that because of the nonlinear link function, the fixed effects coefficients will have an interpretation conditional on the random effects. This same issue you also for example have in the mixed effects logistic and Poisson regression models. Most often this is not the interpretation you want, i.e., a marginal/population interpretation.
> ? ?
> ? ? Best,
> ? ? Dimitris
> ? ?
> ? ?
> ? ? -----Original Message-----
> ? ? From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> On Behalf Of Emmanuel Curis ? Sent: Wednesday, September 19, 2018 5:02 PM ? To: Ben Bolker <bbolker at gmail.com> ? Cc: r-sig-mixed-models at r-project.org ? Subject: Re: [R-sig-ME] Comparing Gaussian and b?ta regression ? ? Thank you very much for the hints.
> ? ?
> ? ? The ? not very satisfactory ? is from a "theoretical" point of view:
> ? ? I'm not very comfortable with modeling with a Gaussian a value constrained between 0 and 10, with the extremes obtained not so rarely.  From a practical point of view, it does not seem to produce unexpected results.  Of course, there are some effects that are borderline significant, that also makes the question uprise: what is the part of true signal and basically inadequate model in these effects? Still finding them with a more sounded model would make them a little bit more "trustable"...
> ? ?
> ? ? For the ordinal outcome: I have wrongly selected my example value, it induced in error, sorry ; the step is 0.1 and not 0.5 ; in practice, ? 46 different values were observed. Integer values and, to a less extent, half-integer values are clearly over-represented, I guess because of inconscient rounding during scoring.  I don't know how to handle this in a model, however, but that's another problem, and may be there is no need for that.  But, for the ordinal aspect, I fear that would make too much parameters in the model...
> ? ?
> ? ? Just thinking... Would it be imaginable to make inferences on the beta-distribution model, since it seems to much better describe the data, but use the linear model on the raw scale just to have point-estimates of the changes in an easiest-to-interpret way?
> ? ? [despite it is problematic close to the boundaries...] ? ? Is the Gelmann & Hill book you're thinking about this one: ?
> ? ?
> ? ? Data Analysis Using Regression and Multilevel/Hierarchical Models  Cambridge University Press ? ISBN-10: 052168689X ? ? On Wed, Sep 19, 2018 at 09:49:51AM -0400, Ben Bolker wrote:
> ? ? ?
> ? ? ?
> ? ? ? On 2018-09-19 03:30 AM, Emmanuel Curis wrote:
> ? ? ? > Hello,
> ? ? ? >
> ? ? ? > I'm doing my first try on b?ta regression, with mixed effects model, ? > and was wondering if my reasonning is correct...
> ? ? ? >
> ? ? ? > The context is a clinical study where the outcome is a score variable, ? > with continuous values between 0 and 10 (both included) and, in ? > practice, values with only one decimal digit (eg. 1.5) There is ? > about 400 patients. Random effect is the clinician who does the ? > examination and afterthat collects the score that evaluates its ? > intervention.
> ? ? ? >
> ? ? ? > As a quick-and-dirty analysis, I did a linear mixed effect model on ? > the raw data, with lmer. Residuals and random effects are not so bad, ? > and results consistent & easy to interpret, but assuming a Gaussian ? > distribution is not very satisfactory.
> ? ? ?
> ? ? ? Can you expand on why "not very satisfactory"?  Do you get unrealistic ? predictions etc.?
> ? ? ?
> ? ? ?   This sounds like it could also be treated as an ordinal response (with
> ? ? ? 21 values {0, 0.5, 1, ... 9.5, 10}).
> ? ? ? >
> ? ? ? > Hence, I tried a b?ta regression on the data after the transformation ? > (y/10 * (n-1) + 0.5) / n, and used glmmTMB for that. And of course I ? > wondered if the fit was better.
> ? ? ? >
> ? ? ? > 1) Is it right that ln-likelihood of the model on the raw data
> ? ? ? >    (Gaussian) and on the transformed data (b?ta) cannot be compared,
> ? ? ? >    because they involve probability densities and not probabilities,
> ? ? ? >    hence depend on the data scale ?
> ? ? ?
> ? ? ?   You can compare log-likelihoods (actually technically they're
> ? ? ? log-likelihood *densities*, which is where the problem comes from) if ? you account for the scaling.  In this case since you're doing a linear ? transformation the scaling should be pretty easy.
> ? ? ? >
> ? ? ? > 2) Is it right that the lmer model done on the raw data and the same
> ? ? ? >    one done on the transformed data are conceptually the same, since
> ? ? ? >    the transformation is linear ? so that the ln-likelihood it gives
> ? ? ? >    is ? the same ? expressed in the two different scales? (of course,
> ? ? ? >    coefficients and so on will be different because of the scale
> ? ? ? >    change)
> ? ? ?
> ? ? ?    Should be. (You could do a simple test of this ...)
> ? ? ? >
> ? ? ? > 3) And so, is it correct to compare the ln-likelihood (using logLik)
> ? ? ? >    or the AIC given by glmmTMB with the b?ta model and by lmer on
> ? ? ? >    transformed data to compare the two models (raw data Gaussian vs
> ? ? ? >    b?ta)?
> ? ? ?
> ? ? ?   I would think so.
> ? ? ? >
> ? ? ? >    If so, the b?ta model seems better than the Gaussian one. But now
> ? ? ? >    comes the interpretation problem, other than ? are coefficients
> ? ? ? >    significantly different from 0? ?.
> ? ? ? >
> ? ? ? > 4) Since the default link is the logit for the mean, interpretation is
> ? ? ? >    not quite clear for me.  For the Gaussian model on raw data,
> ? ? ? >    interpretation is clear, for instance ? men score 1 point lower
> ? ? ? >    than women in average ?.  But how can the coefficients of the
> ? ? ? >    b?ta-model be back-converted in a similar fashion ?
> ? ? ?
> ? ? ?    You probably need to go read stuff about interpretation of
> ? ? ? logit/log-odds  parameters: Gelman and Hill's book is good.
> ? ? ?
> ? ? ? Quick rules of thumb:
> ? ? ?
> ? ? ? * for ??x small, as for log (proportional) ? * for intermediate values, linear change in probability with ? slope ? ?/4 ? * for large values, as for log ( 1 ? x ) ? >
> ? ? ? >    Would it be easier to use a log link and expression changes in the
> ? ? ? >    scale as percent changes on the mean?
> ? ? ?
> ? ? ?   This will work fine for low score values, but will run into trouble at
> ? ? ? the upper end of the score range.
> ? ? ?
> ? ? ? >
> ? ? ? > Thanks in advance,
> ? ? ? >
> ? ? ?
> ? ? ? _______________________________________________
> ? ? ? R-sig-mixed-models at r-project.org mailing list ? https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> ? ?
> ? ? --
> ? ?                                 Emmanuel CURIS
> ? ?                                 emmanuel.curis at parisdescartes.fr
> ? ?
> ? ? Page WWW: http://emmanuel.curis.online.fr/index.html
> ? ?
> ? ? _______________________________________________
> ? ? R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> ?
> ? --
> ?                                 Emmanuel CURIS
> ?                                 emmanuel.curis at parisdescartes.fr
> ?
> ? Page WWW: http://emmanuel.curis.online.fr/index.html
>

	[[alternative HTML version deleted]]


From @nne@lerche @ending from uni-leipzig@de  Fri Sep 21 16:54:21 2018
From: @nne@lerche @ending from uni-leipzig@de (Anne Lerche)
Date: Fri, 21 Sep 2018 16:54:21 +0200
Subject: [R-sig-ME] Significance of B-splines components in mixed-effects
 logistic regression (glmer)
Message-ID: <20180921165421.Horde.9QcTOmKm944FrDkhWYTYHoN@mail.uni-leipzig.de>

Good afternoon,
I have a problem with reporting significance of b-splines components  
in a mixed-effects logistic regression fit in lme4 (caused by a  
reviewer's comment on a paper). After several hours of searching the  
literature, forums and the internet more generally, I have not found a  
solution and therefore turn to the recipients of this mailing list for  
help. (My questions are at the very end of the mail)

I am trying to model the change in the use of linguistic variable on  
the basis of corpus data. My dataset contains the binary dependent  
variable (DV, variant "a" or "b" being used), 2 random variables (RV1  
and RV2, both categorical) and three predictors (IV1=time, IV2=another  
numeric variable, IV3=a categorical variable with 7 levels).

I wasn't sure if I should attach my (modified) dataset, so I'm trying  
to produce an example. Unfortunately, it doesn't give the same results  
as my original dataset.

library(lme4)
library(splines)
library(languageR)

df <- dative[dative$Modality == "spoken",]
df <- df[,c("RealizationOfRecipient", "Verb", "Speaker",  
"LengthOfTheme", "SemanticClass")]
colnames(df) <- c("DV", "RV1", "RV2", "IV2", "IV3")
set.seed(130)
df$IV1 <- sample(1:13, 2360, replace = TRUE)

My final regression model looks like this (treatment contrast coding):
fin.mod <- glmer(DV~bs(IV1, knots=c(5,9), degree=1)+IV2+IV3+(1|RV1)+(1|RV2),
                  data=df, family=binomial)
summary(fin.mod, corr=FALSE)

where the effect of IV1 is modelled as a b-spline with 2 knots and a  
degree of 1. Anova comparisons (of the original dataset) show that  
this model performs significantly better than a) a model without IV1  
modelled as a b-spline (bs(IV1, knots=c(5,9), degree=1)), b) a model  
with IV1 as a linear predictor (not using bs), c) a model with the df  
of the spline specified instead of the knots (df=3), so that bs  
chooses knots autonomously, and d) a model with only 2 df (bs(IV1,  
df=2, degree=1)). I also ran comparisons with models with quadratic or  
cubis splines, and still my final model performs significantly better.

The problem is that I am reporting this final model in a paper, and  
one of the reviewers comments that I am reporting a non-significant  
effect of IV1 because according to the coefficients table the variable  
does not seem to have a significant effect (outlier correction does  
not make a big difference):

Fixed effects:
                                       Estimate Std. Error z value Pr(>|z|)
(Intercept)                            0.52473    0.50759   1.034    0.301
bs(IV1, knots = c(5, 9), degree = 1)1 -0.93178    0.59162  -1.575    0.115
bs(IV1, knots = c(5, 9), degree = 1)2  0.69287    0.43018   1.611    0.107
bs(IV1, knots = c(5, 9), degree = 1)3 -0.19389    0.61144  -0.317    0.751
IV2                                    0.47041    0.11615   4.050 5.12e-05 ***
IV3level2                              0.30149    0.53837   0.560    0.575
IV3level3                              0.15682    0.48760   0.322    0.748
IV3level4                             -0.89664    0.18656  -4.806 1.54e-06 ***
IV3level5                             -2.90305    0.68119  -4.262 2.03e-05 ***
IV3level6                             -0.32081    0.29438  -1.090    0.276
IV3level7                             -0.07038    0.87727  -0.080    0.936
(coefficients table of the sample dataset will differ)

I know that the results of anova comparisons and what the coefficients  
table shows are two different things (as in the case of IV3 which also  
significantly improves model quality when added to the regression even  
if only few levels show significant contrasts).

My questions are:
How can I justify reporting my regression model when the regression  
table shows only non-significant components for the b-spline term? (Is  
it enough to point to the anova comparisons?)
Is is possible to keep only some components of the b-spline (as  
suggested here for linear regression:  
https://freakonometrics.hypotheses.org/47681)?
Is there a better way of modeling the data? I am not very familiar  
with gamm4 or nlme, for example.

Any help is very much appreciated!
Thank you,
Anne


-- 
Anne Lerche
Institute of British Studies
Leipzig University


From bbolker @ending from gm@il@com  Fri Sep 21 17:39:15 2018
From: bbolker @ending from gm@il@com (Ben Bolker)
Date: Fri, 21 Sep 2018 11:39:15 -0400
Subject: [R-sig-ME] 
 Significance of B-splines components in mixed-effects
 logistic regression (glmer)
In-Reply-To: <20180921165421.Horde.9QcTOmKm944FrDkhWYTYHoN@mail.uni-leipzig.de>
References: <20180921165421.Horde.9QcTOmKm944FrDkhWYTYHoN@mail.uni-leipzig.de>
Message-ID: <e4b7d98f-c0b1-b0e1-a3b3-69f2aab59b6c@gmail.com>


  fortunes::fortune("should be done")

  The ANOVA comparisons should be all you need.  car::Anova() or drop1()
or afex::mixed() are all convenience functions for that.  Since
parameters for splines are harder to interpret, you could just leave out
that part of the parameter table ...

  The freakonometrics post you cite concludes:

>  So, it looks like having a lot of non significant components in a
spline regression is not a major issue. And reducing the degrees of
freedom is clearly a bad option.

Furthermore, stepwise throwing-away of terms is a recipe for messing up
your inference (snooping/garden of forking paths).

Your modeling approach looks fine; you *could* use gamm4 to get
penalized regression splines, but again, it's better from an
inferential/non-snooping point of view to pick a sensible model and
stick with it unless it's obviously problematic.

  On a technical level, it's not clear whether the "discrepancy" (not
really) between the summary() results and the anova() results is due to
(1) the combined effect of a term with several components being
significant even when the individual components are not; (2) the
difference between Wald tests (used in summary) and likelihood-based
tests (used in anova()).  This could be disentangled, but IMO it's only
worth it from a pedagogical/exploratory perspective.

  Ben Bolker




On 2018-09-21 10:54 AM, Anne Lerche wrote:
> Good afternoon,
> I have a problem with reporting significance of b-splines components in
> a mixed-effects logistic regression fit in lme4 (caused by a reviewer's
> comment on a paper). After several hours of searching the literature,
> forums and the internet more generally, I have not found a solution and
> therefore turn to the recipients of this mailing list for help. (My
> questions are at the very end of the mail)
> 
> I am trying to model the change in the use of linguistic variable on the
> basis of corpus data. My dataset contains the binary dependent variable
> (DV, variant "a" or "b" being used), 2 random variables (RV1 and RV2,
> both categorical) and three predictors (IV1=time, IV2=another numeric
> variable, IV3=a categorical variable with 7 levels).
> 
> I wasn't sure if I should attach my (modified) dataset, so I'm trying to
> produce an example. Unfortunately, it doesn't give the same results as
> my original dataset.
> 
> library(lme4)
> library(splines)
> library(languageR)
> 
> df <- dative[dative$Modality == "spoken",]
> df <- df[,c("RealizationOfRecipient", "Verb", "Speaker",
> "LengthOfTheme", "SemanticClass")]
> colnames(df) <- c("DV", "RV1", "RV2", "IV2", "IV3")
> set.seed(130)
> df$IV1 <- sample(1:13, 2360, replace = TRUE)
> 
> My final regression model looks like this (treatment contrast coding):
> fin.mod <- glmer(DV~bs(IV1, knots=c(5,9),
> degree=1)+IV2+IV3+(1|RV1)+(1|RV2),
> ???????????????? data=df, family=binomial)
> summary(fin.mod, corr=FALSE)
> 
> where the effect of IV1 is modelled as a b-spline with 2 knots and a
> degree of 1. Anova comparisons (of the original dataset) show that this
> model performs significantly better than a) a model without IV1 modelled
> as a b-spline (bs(IV1, knots=c(5,9), degree=1)), b) a model with IV1 as
> a linear predictor (not using bs), c) a model with the df of the spline
> specified instead of the knots (df=3), so that bs chooses knots
> autonomously, and d) a model with only 2 df (bs(IV1, df=2, degree=1)). I
> also ran comparisons with models with quadratic or cubis splines, and
> still my final model performs significantly better.
> 
> The problem is that I am reporting this final model in a paper, and one
> of the reviewers comments that I am reporting a non-significant effect
> of IV1 because according to the coefficients table the variable does not
> seem to have a significant effect (outlier correction does not make a
> big difference):
> 
> Fixed effects:
> ????????????????????????????????????? Estimate Std. Error z value Pr(>|z|)
> (Intercept)??????????????????????????? 0.52473??? 0.50759?? 1.034??? 0.301
> bs(IV1, knots = c(5, 9), degree = 1)1 -0.93178??? 0.59162? -1.575??? 0.115
> bs(IV1, knots = c(5, 9), degree = 1)2? 0.69287??? 0.43018?? 1.611??? 0.107
> bs(IV1, knots = c(5, 9), degree = 1)3 -0.19389??? 0.61144? -0.317??? 0.751
> IV2??????????????????????????????????? 0.47041??? 0.11615?? 4.050
> 5.12e-05 ***
> IV3level2????????????????????????????? 0.30149??? 0.53837?? 0.560??? 0.575
> IV3level3????????????????????????????? 0.15682??? 0.48760?? 0.322??? 0.748
> IV3level4???????????????????????????? -0.89664??? 0.18656? -4.806
> 1.54e-06 ***
> IV3level5???????????????????????????? -2.90305??? 0.68119? -4.262
> 2.03e-05 ***
> IV3level6???????????????????????????? -0.32081??? 0.29438? -1.090??? 0.276
> IV3level7???????????????????????????? -0.07038??? 0.87727? -0.080??? 0.936
> (coefficients table of the sample dataset will differ)
> 
> I know that the results of anova comparisons and what the coefficients
> table shows are two different things (as in the case of IV3 which also
> significantly improves model quality when added to the regression even
> if only few levels show significant contrasts).
> 
> My questions are:
> How can I justify reporting my regression model when the regression
> table shows only non-significant components for the b-spline term? (Is
> it enough to point to the anova comparisons?)
> Is is possible to keep only some components of the b-spline (as
> suggested here for linear regression:
> https://freakonometrics.hypotheses.org/47681)?
> Is there a better way of modeling the data? I am not very familiar with
> gamm4 or nlme, for example.
> 
> Any help is very much appreciated!
> Thank you,
> Anne
> 
>


From emm@nuel@curi@ @ending from p@ri@de@c@rte@@fr  Fri Sep 21 18:48:57 2018
From: emm@nuel@curi@ @ending from p@ri@de@c@rte@@fr (Emmanuel Curis)
Date: Fri, 21 Sep 2018 18:48:57 +0200
Subject: [R-sig-ME] 
 =?iso-8859-1?q?Comparing_Gaussian_and_b=EAta_regressi?=
 =?iso-8859-1?q?on?=
In-Reply-To: <7191AFC7255B4F49A30707E39BEAD05FDEB7F195@EXCH-RX03.erasmusmc.nl>
References: <20180919073014.GA17416@info124.pharmacie.univ-paris5.fr>
 <12de47d9-468b-c5e1-c75c-aee8ce59ba86@gmail.com>
 <20180919150217.GD1527@info124.pharmacie.univ-paris5.fr>
 <7191AFC7255B4F49A30707E39BEAD05FDEB7C6BF@EXCH-RX03.erasmusmc.nl>
 <20180921073412.GA2618@info124.pharmacie.univ-paris5.fr>
 <7191AFC7255B4F49A30707E39BEAD05FDEB7E890@EXCH-RX03.erasmusmc.nl>
 <20180921132001.GB11049@info124.pharmacie.univ-paris5.fr>
 <7191AFC7255B4F49A30707E39BEAD05FDEB7F195@EXCH-RX03.erasmusmc.nl>
Message-ID: <20180921164856.GB24941@info124.pharmacie.univ-paris5.fr>

Thanks!

Best regards,

On Fri, Sep 21, 2018 at 02:03:35PM +0000, D. Rizopoulos wrote:
? Yes, I think this is correct. But I would really call it ?bias?. The issue is that the intepretation is different.
? 
? Best,
? Dimitris

-- 
                                Emmanuel CURIS
                                emmanuel.curis at parisdescartes.fr

Page WWW: http://emmanuel.curis.online.fr/index.html


From @nne@lerche @ending from uni-leipzig@de  Fri Sep 21 19:04:34 2018
From: @nne@lerche @ending from uni-leipzig@de (Anne Lerche)
Date: Fri, 21 Sep 2018 19:04:34 +0200
Subject: [R-sig-ME] 
 Significance of B-splines components in mixed-effects
 logistic regression (glmer)
In-Reply-To: <e4b7d98f-c0b1-b0e1-a3b3-69f2aab59b6c@gmail.com>
References: <20180921165421.Horde.9QcTOmKm944FrDkhWYTYHoN@mail.uni-leipzig.de>
 <e4b7d98f-c0b1-b0e1-a3b3-69f2aab59b6c@gmail.com>
Message-ID: <20180921190434.Horde.HJrQOEMXr5H8IBRslhDr2kK@mail.uni-leipzig.de>

Dear Ben,
thank you very much for your very quick reply. It is reassuring that  
even though this is one of the first times I am using splines, I seem  
to be doing it correctly and I can stick to my lme4 model instead of  
delving into gamm4.
I really liked the fortune you sent along in this connection.

Best, Anne

Zitat von Ben Bolker <bbolker at gmail.com>:

> fortunes::fortune("should be done")
>
>   The ANOVA comparisons should be all you need.  car::Anova() or drop1()
> or afex::mixed() are all convenience functions for that.  Since
> parameters for splines are harder to interpret, you could just leave out
> that part of the parameter table ...
>
>   The freakonometrics post you cite concludes:
>
>>  So, it looks like having a lot of non significant components in a
> spline regression is not a major issue. And reducing the degrees of
> freedom is clearly a bad option.
>
> Furthermore, stepwise throwing-away of terms is a recipe for messing up
> your inference (snooping/garden of forking paths).
>
> Your modeling approach looks fine; you *could* use gamm4 to get
> penalized regression splines, but again, it's better from an
> inferential/non-snooping point of view to pick a sensible model and
> stick with it unless it's obviously problematic.
>
>   On a technical level, it's not clear whether the "discrepancy" (not
> really) between the summary() results and the anova() results is due to
> (1) the combined effect of a term with several components being
> significant even when the individual components are not; (2) the
> difference between Wald tests (used in summary) and likelihood-based
> tests (used in anova()).  This could be disentangled, but IMO it's only
> worth it from a pedagogical/exploratory perspective.
>
>   Ben Bolker
>
>
>
>
> On 2018-09-21 10:54 AM, Anne Lerche wrote:
>> Good afternoon,
>> I have a problem with reporting significance of b-splines components in
>> a mixed-effects logistic regression fit in lme4 (caused by a reviewer's
>> comment on a paper). After several hours of searching the literature,
>> forums and the internet more generally, I have not found a solution and
>> therefore turn to the recipients of this mailing list for help. (My
>> questions are at the very end of the mail)
>>
>> I am trying to model the change in the use of linguistic variable on the
>> basis of corpus data. My dataset contains the binary dependent variable
>> (DV, variant "a" or "b" being used), 2 random variables (RV1 and RV2,
>> both categorical) and three predictors (IV1=time, IV2=another numeric
>> variable, IV3=a categorical variable with 7 levels).
>>
>> I wasn't sure if I should attach my (modified) dataset, so I'm trying to
>> produce an example. Unfortunately, it doesn't give the same results as
>> my original dataset.
>>
>> library(lme4)
>> library(splines)
>> library(languageR)
>>
>> df <- dative[dative$Modality == "spoken",]
>> df <- df[,c("RealizationOfRecipient", "Verb", "Speaker",
>> "LengthOfTheme", "SemanticClass")]
>> colnames(df) <- c("DV", "RV1", "RV2", "IV2", "IV3")
>> set.seed(130)
>> df$IV1 <- sample(1:13, 2360, replace = TRUE)
>>
>> My final regression model looks like this (treatment contrast coding):
>> fin.mod <- glmer(DV~bs(IV1, knots=c(5,9),
>> degree=1)+IV2+IV3+(1|RV1)+(1|RV2),
>> ???????????????? data=df, family=binomial)
>> summary(fin.mod, corr=FALSE)
>>
>> where the effect of IV1 is modelled as a b-spline with 2 knots and a
>> degree of 1. Anova comparisons (of the original dataset) show that this
>> model performs significantly better than a) a model without IV1 modelled
>> as a b-spline (bs(IV1, knots=c(5,9), degree=1)), b) a model with IV1 as
>> a linear predictor (not using bs), c) a model with the df of the spline
>> specified instead of the knots (df=3), so that bs chooses knots
>> autonomously, and d) a model with only 2 df (bs(IV1, df=2, degree=1)). I
>> also ran comparisons with models with quadratic or cubis splines, and
>> still my final model performs significantly better.
>>
>> The problem is that I am reporting this final model in a paper, and one
>> of the reviewers comments that I am reporting a non-significant effect
>> of IV1 because according to the coefficients table the variable does not
>> seem to have a significant effect (outlier correction does not make a
>> big difference):
>>
>> Fixed effects:
>> ????????????????????????????????????? Estimate Std. Error z value Pr(>|z|)
>> (Intercept)??????????????????????????? 0.52473??? 0.50759?? 1.034??? 0.301
>> bs(IV1, knots = c(5, 9), degree = 1)1 -0.93178??? 0.59162? -1.575??? 0.115
>> bs(IV1, knots = c(5, 9), degree = 1)2? 0.69287??? 0.43018?? 1.611??? 0.107
>> bs(IV1, knots = c(5, 9), degree = 1)3 -0.19389??? 0.61144? -0.317??? 0.751
>> IV2??????????????????????????????????? 0.47041??? 0.11615?? 4.050
>> 5.12e-05 ***
>> IV3level2????????????????????????????? 0.30149??? 0.53837?? 0.560??? 0.575
>> IV3level3????????????????????????????? 0.15682??? 0.48760?? 0.322??? 0.748
>> IV3level4???????????????????????????? -0.89664??? 0.18656? -4.806
>> 1.54e-06 ***
>> IV3level5???????????????????????????? -2.90305??? 0.68119? -4.262
>> 2.03e-05 ***
>> IV3level6???????????????????????????? -0.32081??? 0.29438? -1.090??? 0.276
>> IV3level7???????????????????????????? -0.07038??? 0.87727? -0.080??? 0.936
>> (coefficients table of the sample dataset will differ)
>>
>> I know that the results of anova comparisons and what the coefficients
>> table shows are two different things (as in the case of IV3 which also
>> significantly improves model quality when added to the regression even
>> if only few levels show significant contrasts).
>>
>> My questions are:
>> How can I justify reporting my regression model when the regression
>> table shows only non-significant components for the b-spline term? (Is
>> it enough to point to the anova comparisons?)
>> Is is possible to keep only some components of the b-spline (as
>> suggested here for linear regression:
>> https://freakonometrics.hypotheses.org/47681)?
>> Is there a better way of modeling the data? I am not very familiar with
>> gamm4 or nlme, for example.
>>
>> Any help is very much appreciated!
>> Thank you,
>> Anne
>>
>>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



-- 
Anne Lerche
Institute of British Studies
Leipzig University
Beethovenstra?e 15
04107 Leipzig

Phone: +493419737407
http://anglistik.philol.uni-leipzig.de/de/institut/linguistik/mitarbeiter/anne-lerche


From Phillip@Ald@y @ending from mpi@nl  Fri Sep 21 20:24:18 2018
From: Phillip@Ald@y @ending from mpi@nl (Alday, Phillip)
Date: Fri, 21 Sep 2018 18:24:18 +0000
Subject: [R-sig-ME] 
 Significance of B-splines components in mixed-effects
 logistic regression (glmer)
In-Reply-To: <20180921190434.Horde.HJrQOEMXr5H8IBRslhDr2kK@mail.uni-leipzig.de>
References: <20180921165421.Horde.9QcTOmKm944FrDkhWYTYHoN@mail.uni-leipzig.de>
 <e4b7d98f-c0b1-b0e1-a3b3-69f2aab59b6c@gmail.com>
 <20180921190434.Horde.HJrQOEMXr5H8IBRslhDr2kK@mail.uni-leipzig.de>
Message-ID: <336fd594-f21a-02e4-8f68-aabf97e205e4@mpi.nl>

Dear Anne,

For comparison, here's a GAMM for the same example:

# Anne's code first, then

library(gamm4)
gam.mod <- gamm4(DV ~ s(IV1) + IV2 + IV3, random=~(1|RV1) + (1|RV2),
???????????????? data=df, family=binomial)
summary(gam.mod$mer,corr=FALSE)
summary(gam.mod$gam)

With the exception of the intercepts and the smooth/spline parameters
(which are by definition different), the estimates are quite similar.
The smoother is also estimated to be roughly linear (edf=1), so it's not
surprising that it and also your splines aren't significant.

I'm not sure if languageR::dative was just a convenient example, but if
you are working in psycholinguistics or cognitive neuroscience, GA(M)Ms
are starting to gain traction:

Baayen, H., Vasishth, S., Kliegl, R., & Bates, D. (2017). The cave of
shadows: Addressing the human factor with generalized additive mixed
models. Journal of Memory and Language , 94 , 206?234.
doi:10.1016/j.jml.2016.11.006

Tremblay, A., & Newman, A. J. (2015). Modeling nonlinear relationships
in ERP data using mixed-effects regression with R examples.
Psychophysiology , 52 , 124?139. doi:10.1111/psyp.12299

Wieling, M., Nerbonne, J., & Baayen, R. H. (2011). Quantitative social
dialectology: explaining linguistic variation
geographically and socially. PLoS One, 6(9), e23613.
doi:10.1371/journal.pone.0023613

Phillip


On 21/09/18 19:04, Anne Lerche wrote:
> Dear Ben,
> thank you very much for your very quick reply. It is reassuring that
> even though this is one of the first times I am using splines, I seem
> to be doing it correctly and I can stick to my lme4 model instead of
> delving into gamm4.
> I really liked the fortune you sent along in this connection.
>
> Best, Anne
>
> Zitat von Ben Bolker <bbolker at gmail.com>:
>
>> fortunes::fortune("should be done")
>>
>> ? The ANOVA comparisons should be all you need.? car::Anova() or drop1()
>> or afex::mixed() are all convenience functions for that.? Since
>> parameters for splines are harder to interpret, you could just leave out
>> that part of the parameter table ...
>>
>> ? The freakonometrics post you cite concludes:
>>
>>> ?So, it looks like having a lot of non significant components in a
>> spline regression is not a major issue. And reducing the degrees of
>> freedom is clearly a bad option.
>>
>> Furthermore, stepwise throwing-away of terms is a recipe for messing up
>> your inference (snooping/garden of forking paths).
>>
>> Your modeling approach looks fine; you *could* use gamm4 to get
>> penalized regression splines, but again, it's better from an
>> inferential/non-snooping point of view to pick a sensible model and
>> stick with it unless it's obviously problematic.
>>
>> ? On a technical level, it's not clear whether the "discrepancy" (not
>> really) between the summary() results and the anova() results is due to
>> (1) the combined effect of a term with several components being
>> significant even when the individual components are not; (2) the
>> difference between Wald tests (used in summary) and likelihood-based
>> tests (used in anova()).? This could be disentangled, but IMO it's only
>> worth it from a pedagogical/exploratory perspective.
>>
>> ? Ben Bolker
>>
>>
>>
>>
>> On 2018-09-21 10:54 AM, Anne Lerche wrote:
>>> Good afternoon,
>>> I have a problem with reporting significance of b-splines components in
>>> a mixed-effects logistic regression fit in lme4 (caused by a reviewer's
>>> comment on a paper). After several hours of searching the literature,
>>> forums and the internet more generally, I have not found a solution and
>>> therefore turn to the recipients of this mailing list for help. (My
>>> questions are at the very end of the mail)
>>>
>>> I am trying to model the change in the use of linguistic variable on
>>> the
>>> basis of corpus data. My dataset contains the binary dependent variable
>>> (DV, variant "a" or "b" being used), 2 random variables (RV1 and RV2,
>>> both categorical) and three predictors (IV1=time, IV2=another numeric
>>> variable, IV3=a categorical variable with 7 levels).
>>>
>>> I wasn't sure if I should attach my (modified) dataset, so I'm
>>> trying to
>>> produce an example. Unfortunately, it doesn't give the same results as
>>> my original dataset.
>>>
>>> library(lme4)
>>> library(splines)
>>> library(languageR)
>>>
>>> df <- dative[dative$Modality == "spoken",]
>>> df <- df[,c("RealizationOfRecipient", "Verb", "Speaker",
>>> "LengthOfTheme", "SemanticClass")]
>>> colnames(df) <- c("DV", "RV1", "RV2", "IV2", "IV3")
>>> set.seed(130)
>>> df$IV1 <- sample(1:13, 2360, replace = TRUE)
>>>
>>> My final regression model looks like this (treatment contrast coding):
>>> fin.mod <- glmer(DV~bs(IV1, knots=c(5,9),
>>> degree=1)+IV2+IV3+(1|RV1)+(1|RV2),
>>> ???????????????? data=df, family=binomial)
>>> summary(fin.mod, corr=FALSE)
>>>
>>> where the effect of IV1 is modelled as a b-spline with 2 knots and a
>>> degree of 1. Anova comparisons (of the original dataset) show that this
>>> model performs significantly better than a) a model without IV1
>>> modelled
>>> as a b-spline (bs(IV1, knots=c(5,9), degree=1)), b) a model with IV1 as
>>> a linear predictor (not using bs), c) a model with the df of the spline
>>> specified instead of the knots (df=3), so that bs chooses knots
>>> autonomously, and d) a model with only 2 df (bs(IV1, df=2,
>>> degree=1)). I
>>> also ran comparisons with models with quadratic or cubis splines, and
>>> still my final model performs significantly better.
>>>
>>> The problem is that I am reporting this final model in a paper, and one
>>> of the reviewers comments that I am reporting a non-significant effect
>>> of IV1 because according to the coefficients table the variable does
>>> not
>>> seem to have a significant effect (outlier correction does not make a
>>> big difference):
>>>
>>> Fixed effects:
>>> ????????????????????????????????????? Estimate Std. Error z value
>>> Pr(>|z|)
>>> (Intercept)??????????????????????????? 0.52473??? 0.50759?? 1.034???
>>> 0.301
>>> bs(IV1, knots = c(5, 9), degree = 1)1 -0.93178??? 0.59162? -1.575???
>>> 0.115
>>> bs(IV1, knots = c(5, 9), degree = 1)2? 0.69287??? 0.43018?? 1.611???
>>> 0.107
>>> bs(IV1, knots = c(5, 9), degree = 1)3 -0.19389??? 0.61144? -0.317???
>>> 0.751
>>> IV2??????????????????????????????????? 0.47041??? 0.11615?? 4.050
>>> 5.12e-05 ***
>>> IV3level2????????????????????????????? 0.30149??? 0.53837?? 0.560???
>>> 0.575
>>> IV3level3????????????????????????????? 0.15682??? 0.48760?? 0.322???
>>> 0.748
>>> IV3level4???????????????????????????? -0.89664??? 0.18656? -4.806
>>> 1.54e-06 ***
>>> IV3level5???????????????????????????? -2.90305??? 0.68119? -4.262
>>> 2.03e-05 ***
>>> IV3level6???????????????????????????? -0.32081??? 0.29438? -1.090???
>>> 0.276
>>> IV3level7???????????????????????????? -0.07038??? 0.87727? -0.080???
>>> 0.936
>>> (coefficients table of the sample dataset will differ)
>>>
>>> I know that the results of anova comparisons and what the coefficients
>>> table shows are two different things (as in the case of IV3 which also
>>> significantly improves model quality when added to the regression even
>>> if only few levels show significant contrasts).
>>>
>>> My questions are:
>>> How can I justify reporting my regression model when the regression
>>> table shows only non-significant components for the b-spline term? (Is
>>> it enough to point to the anova comparisons?)
>>> Is is possible to keep only some components of the b-spline (as
>>> suggested here for linear regression:
>>> https://freakonometrics.hypotheses.org/47681)?
>>> Is there a better way of modeling the data? I am not very familiar with
>>> gamm4 or nlme, for example.
>>>
>>> Any help is very much appreciated!
>>> Thank you,
>>> Anne
>>>
>>>
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>

From @tevedrd @ending from y@hoo@com  Mon Sep 24 12:52:42 2018
From: @tevedrd @ending from y@hoo@com (Steve Denham)
Date: Mon, 24 Sep 2018 10:52:42 +0000 (UTC)
Subject: [R-sig-ME] 
 =?utf-8?q?Comparing_Gaussian_and_b=C3=AAta_regression?=
In-Reply-To: <cd164e9e-559c-711c-a651-e13ac97efd70@gmail.com>
References: <20180919073014.GA17416@info124.pharmacie.univ-paris5.fr>
 <12de47d9-468b-c5e1-c75c-aee8ce59ba86@gmail.com>
 <20180919150217.GD1527@info124.pharmacie.univ-paris5.fr>
 <7191AFC7255B4F49A30707E39BEAD05FDEB7C6BF@EXCH-RX03.erasmusmc.nl>
 <20180921073412.GA2618@info124.pharmacie.univ-paris5.fr>
 <7191AFC7255B4F49A30707E39BEAD05FDEB7E890@EXCH-RX03.erasmusmc.nl>
 <20180921132001.GB11049@info124.pharmacie.univ-paris5.fr>
 <cd164e9e-559c-711c-a651-e13ac97efd70@gmail.com>
Message-ID: <1605425343.1363873.1537786362806@mail.yahoo.com>

Ben,
Not sure if this is what you are looking for.
In SAS' PROC GLIMMIX, you can get either conditional or marginal estimates.? It comes down to using the keyword RESIDUAL in the RANDOM statement.? If it is not present, then the estimates are conditional on the random effects (what SAS would call G-side).? Quadrature and Laplace methods are available.? If it is present, then the estimates are marginal over the random effects (what SAS would call R-side).? In this case, only residual pseudo-likelihood methods are available if there are correlated errors.? And of course, there is one exception - adding a single overdispersion parameter via the _RESIDUAL_ keyword does NOT trigger what they term as GLMM mode.
Here is a link to the documentation:
http://support.sas.com/documentation/cdl/en/statug/68162/HTML/default/viewer.htm#statug_glimmix_details26.htm

And here is how a GEE type (marginal model) is fit in GLIMMIX
http://support.sas.com/documentation/cdl/en/statug/68162/HTML/default/viewer.htm#statug_glimmix_examples15.htm

Steve Denham Senior Director, Bioinformatics Sciences ?MPI Research, Inc. 

    On Friday, September 21, 2018, 10:02:31 AM EDT, Ben Bolker <bbolker at gmail.com> wrote:  
 
 
? Does anyone know offhand if there's R code (ideally a package)
floating around that implements these marginalization calculations for
mixed model estimates, by delta method or quadrature or simulation or
... ?? (The mixed-model ecosystem is getting pretty big and messy ...)
Do SAS/Stata/whatever have straightforward ways to do this that we could
copy?

? cheers
? ? Ben Bolker

On 2018-09-21 09:20 AM, Emmanuel Curis wrote:
> Thanks. It's more clear with the example on Cross Validated, but I'll
> have to think about it carefully.
> 
> As I understand it now, the idea is as follow [I do not try to deal
> with the scale-change exactly, it's just to illustrate has I
> understand it]:
> 
>? - let assume the fixed effect coefficient for sex is one, for
>? ? instance, and is is the only covariate for simplicity, except the
>? ? random effect for clinicians
> 
>? ? => ? score is increased by one in males ?
> 
>? - let assume clinician 1 has random effect +0.1 and clinician 2 -0.1
> 
>? - interpretation should be done assuming all other variables
>? ? constants, including random effects, here clinicians
> 
>? ? => score is increased by one in males for the same clinician
> 
>? - if now I compare between two clinicians, and assuming no
>? ? interaction between sex and clinician, the difference between
>? ? "score male, clinician 1" and "score female, clinician 2" is
>? ? ? (+1 + 0.1) - (0 - 0.1) = 1.2
> 
>? - now the question is what happens when averaging on all clinicians
>? ? (on the random effect)
> 
>? - in the ? usual ? linear model, the difference would be
>? ? ? E( 1 + U1 - (0 + U2) ) = 1 + E(U1 - U2) = 1
> 
>? ? => the ? conditionnal ? effet is the same than when averaging other
>? ? all clinicians
>? ? ? (but comparing between two specific clinicians still will give a
>? ? ? coefficient slightly different than +1)
> 
>? - in any model with a non-linear link function, in the original
>? ? scale, the difference would be (with f the reciprocal of the link
>? ? function, and assuming ? small ? random effects to use a second
>? ? order Taylor expansion)
> 
>? ? E( f(1 + U1) - f(0 - U2) ) = E( f(1 + U1) ) - E( f(0 - U2) )
> 
>? ? ? ~ f(1) + E(f'(1) * U1) + E(f"(1) * U1?/2) -
>? ? ? ? f(0) - E(f'(0) * U2) - E(f"(0) * U2?/2)
>? ? ? 
>? ? ? = f(1) - f(0) + f"(1) E(U1?)/2 - f"(0) E(U2?)/2
>? ? ? ? -----------
>? ? ? ? ? ? delta
> 
> and delta is the fixed effect interpretation ? conditionnal ? on the
> random effect, which is now different than the difference in the
> population averaged over all clinicians.
> 
> Is this correct? [I guess Taylor expansion is unneeded here, I just
> used it to see more clearly the "bias"]
> 
> Best regards,
> 
> On Fri, Sep 21, 2018 at 07:54:45AM +0000, D. Rizopoulos wrote:
> ? The estimates of the coefficients are asymptotically unbiased, and indeed this stems from the properties of maximum likelihood. But what I'm talking about is the *interpretation* of these coefficients. The use of a nonlinear link function complicates things in that regard.
> ? 
> ? You may check more on this in this discussion on Cross Validated: https://stats.stackexchange.com/questions/365907/interpretation-of-fixed-effects-from-mixed-effect-logistic-regression
> ? 
> ? Best,
> ? Dimitris
> ? 
> ? -----Original Message-----
> ? From: Emmanuel Curis <emmanuel.curis at parisdescartes.fr> 
> ? Sent: Friday, September 21, 2018 9:34 AM
> ? To: D. Rizopoulos <d.rizopoulos at erasmusmc.nl>
> ? Cc: Ben Bolker <bbolker at gmail.com>; r-sig-mixed-models at r-project.org
> ? Subject: Re: [R-sig-ME] Comparing Gaussian and b?ta regression
> ? 
> ? Hi,
> ? 
> ? Thanks for the information.? I must say that presently, I do not understand what this means exactly, so I'm really curious about it.
> ? 
> ? I was naively thinking that fixed effects coefficients obtained were estimates of the ? true ? coefficients in the model, and that because of the maximum likelihood asymptotic properties, were asymptotically unbiased.? Does this mean it is false? Or that they estimate something else than these ? true ? coefficients? Or may be that even the notion of ? true coefficient ? is not so clear?
> ? 
> ? Would it be possible to have a detailed, simple example, either directly or through a reference?
> ? 
> ? Best regards,
> ? 
> ? On Wed, Sep 19, 2018 at 04:08:28PM +0000, D. Rizopoulos wrote:
> ? ? An additional issue with the interpretation from the Beta mixed model would be that because of the nonlinear link function, the fixed effects coefficients will have an interpretation conditional on the random effects. This same issue you also for example have in the mixed effects logistic and Poisson regression models. Most often this is not the interpretation you want, i.e., a marginal/population interpretation.
> ? ?
> ? ? Best,
> ? ? Dimitris
> ? ?
> ? ?
> ? ? -----Original Message-----
> ? ? From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> On Behalf Of Emmanuel Curis ? Sent: Wednesday, September 19, 2018 5:02 PM ? To: Ben Bolker <bbolker at gmail.com> ? Cc: r-sig-mixed-models at r-project.org ? Subject: Re: [R-sig-ME] Comparing Gaussian and b?ta regression ? ? Thank you very much for the hints.
> ? ?
> ? ? The ? not very satisfactory ? is from a "theoretical" point of view:
> ? ? I'm not very comfortable with modeling with a Gaussian a value constrained between 0 and 10, with the extremes obtained not so rarely.? From a practical point of view, it does not seem to produce unexpected results.? Of course, there are some effects that are borderline significant, that also makes the question uprise: what is the part of true signal and basically inadequate model in these effects? Still finding them with a more sounded model would make them a little bit more "trustable"...
> ? ?
> ? ? For the ordinal outcome: I have wrongly selected my example value, it induced in error, sorry ; the step is 0.1 and not 0.5 ; in practice, ? 46 different values were observed. Integer values and, to a less extent, half-integer values are clearly over-represented, I guess because of inconscient rounding during scoring.? I don't know how to handle this in a model, however, but that's another problem, and may be there is no need for that.? But, for the ordinal aspect, I fear that would make too much parameters in the model... 
> ? ?
> ? ? Just thinking... Would it be imaginable to make inferences on the beta-distribution model, since it seems to much better describe the data, but use the linear model on the raw scale just to have point-estimates of the changes in an easiest-to-interpret way?
> ? ? [despite it is problematic close to the boundaries...] ? ? Is the Gelmann & Hill book you're thinking about this one: ?
> ? ?
> ? ? Data Analysis Using Regression and Multilevel/Hierarchical Models? Cambridge University Press ? ISBN-10: 052168689X ? ? On Wed, Sep 19, 2018 at 09:49:51AM -0400, Ben Bolker wrote:
> ? ? ?
> ? ? ?
> ? ? ? On 2018-09-19 03:30 AM, Emmanuel Curis wrote:
> ? ? ? > Hello,
> ? ? ? >
> ? ? ? > I'm doing my first try on b?ta regression, with mixed effects model, ? > and was wondering if my reasonning is correct...
> ? ? ? >
> ? ? ? > The context is a clinical study where the outcome is a score variable, ? > with continuous values between 0 and 10 (both included) and, in ? > practice, values with only one decimal digit (eg. 1.5) There is ? > about 400 patients. Random effect is the clinician who does the ? > examination and afterthat collects the score that evaluates its ? > intervention.
> ? ? ? >
> ? ? ? > As a quick-and-dirty analysis, I did a linear mixed effect model on ? > the raw data, with lmer. Residuals and random effects are not so bad, ? > and results consistent & easy to interpret, but assuming a Gaussian ? > distribution is not very satisfactory.
> ? ? ?
> ? ? ? Can you expand on why "not very satisfactory"?? Do you get unrealistic ? predictions etc.?
> ? ? ? 
> ? ? ?? This sounds like it could also be treated as an ordinal response (with
> ? ? ? 21 values {0, 0.5, 1, ... 9.5, 10}).
> ? ? ? >
> ? ? ? > Hence, I tried a b?ta regression on the data after the transformation ? > (y/10 * (n-1) + 0.5) / n, and used glmmTMB for that. And of course I ? > wondered if the fit was better.
> ? ? ? >
> ? ? ? > 1) Is it right that ln-likelihood of the model on the raw data
> ? ? ? >? ? (Gaussian) and on the transformed data (b?ta) cannot be compared,
> ? ? ? >? ? because they involve probability densities and not probabilities,
> ? ? ? >? ? hence depend on the data scale ?
> ? ? ? 
> ? ? ?? You can compare log-likelihoods (actually technically they're
> ? ? ? log-likelihood *densities*, which is where the problem comes from) if ? you account for the scaling.? In this case since you're doing a linear ? transformation the scaling should be pretty easy.
> ? ? ? >
> ? ? ? > 2) Is it right that the lmer model done on the raw data and the same
> ? ? ? >? ? one done on the transformed data are conceptually the same, since
> ? ? ? >? ? the transformation is linear ? so that the ln-likelihood it gives
> ? ? ? >? ? is ? the same ? expressed in the two different scales? (of course,
> ? ? ? >? ? coefficients and so on will be different because of the scale
> ? ? ? >? ? change)
> ? ? ? 
> ? ? ?? ? Should be. (You could do a simple test of this ...)
> ? ? ? >
> ? ? ? > 3) And so, is it correct to compare the ln-likelihood (using logLik)
> ? ? ? >? ? or the AIC given by glmmTMB with the b?ta model and by lmer on
> ? ? ? >? ? transformed data to compare the two models (raw data Gaussian vs
> ? ? ? >? ? b?ta)?
> ? ? ? 
> ? ? ?? I would think so.
> ? ? ? > 
> ? ? ? >? ? If so, the b?ta model seems better than the Gaussian one. But now
> ? ? ? >? ? comes the interpretation problem, other than ? are coefficients
> ? ? ? >? ? significantly different from 0? ?.
> ? ? ? >
> ? ? ? > 4) Since the default link is the logit for the mean, interpretation is
> ? ? ? >? ? not quite clear for me.? For the Gaussian model on raw data,
> ? ? ? >? ? interpretation is clear, for instance ? men score 1 point lower
> ? ? ? >? ? than women in average??.? But how can the coefficients of the
> ? ? ? >? ? b?ta-model be back-converted in a similar fashion ?
> ? ? ? 
> ? ? ?? ? You probably need to go read stuff about interpretation of
> ? ? ? logit/log-odds? parameters: Gelman and Hill's book is good.
> ? ? ?
> ? ? ? Quick rules of thumb:
> ? ? ?
> ? ? ? * for ??x small, as for log (proportional) ? * for intermediate values, linear change in probability with ? slope ? ?/4 ? * for large values, as for log ( 1 ? x ) ? > 
> ? ? ? >? ? Would it be easier to use a log link and expression changes in the
> ? ? ? >? ? scale as percent changes on the mean?
> ? ? ? 
> ? ? ?? This will work fine for low score values, but will run into trouble at
> ? ? ? the upper end of the score range.
> ? ? ?
> ? ? ? >
> ? ? ? > Thanks in advance,
> ? ? ? >
> ? ? ?
> ? ? ? _______________________________________________
> ? ? ? R-sig-mixed-models at r-project.org mailing list ? https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> ? ?
> ? ? -- 
> ? ?? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? Emmanuel CURIS
> ? ?? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? emmanuel.curis at parisdescartes.fr
> ? ?
> ? ? Page WWW: http://emmanuel.curis.online.fr/index.html
> ? ?
> ? ? _______________________________________________
> ? ? R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> ? 
> ? -- 
> ?? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? Emmanuel CURIS
> ?? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? emmanuel.curis at parisdescartes.fr
> ? 
> ? Page WWW: http://emmanuel.curis.online.fr/index.html
>

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
  
	[[alternative HTML version deleted]]


From bbolker @ending from gm@il@com  Tue Sep 25 22:51:24 2018
From: bbolker @ending from gm@il@com (Ben Bolker)
Date: Tue, 25 Sep 2018 16:51:24 -0400
Subject: [R-sig-ME] R Consortium call for funding
Message-ID: <daeea344-1e24-d314-8583-da0e1e8b6d4d@gmail.com>


https://www.r-consortium.org/announcement/2018/09/25/fall-2018-isc-call-for-proposals

"What can you do to improve the R ecosystem and how can the R Consortium
help you do it?"

 The mixed-model ecosystem is admittedly a small part of the R
ecosystem, but I (biasedly) think it's an important one.

  If people have ideas & opinions about how a chunk of money on the
order of $10,000 could be valuably spent to improve the mixed-model
ecosystem in a way that would be appealing to a very broad audience of
useRs, please discuss.

The deadline for submitting a proposal is midnight PST, Sunday October
31, 2018.


  cheers
   Ben Bolker


From A@Robin@on @ending from m@@unimelb@edu@@u  Tue Sep 25 23:06:15 2018
From: A@Robin@on @ending from m@@unimelb@edu@@u (Andrew Robinson)
Date: Wed, 26 Sep 2018 07:06:15 +1000
Subject: [R-sig-ME] R Consortium call for funding
In-Reply-To: <7d713abea4d44655a4d0d3cbbd581a04@MEXPR01MB0758.ausprd01.prod.outlook.com>
References: <7d713abea4d44655a4d0d3cbbd581a04@MEXPR01MB0758.ausprd01.prod.outlook.com>
Message-ID: <CAHyGmd59eC9ifMkW4x1qujpdVHZaewNVAE=HHEaX5QceMeVUUw@mail.gmail.com>

Hi Ben,

I do really miss the variance functions of nlme, and the temporal and
spatial autocorrelation handling.

Warm wishes,

Andrew



On 26 September 2018 at 06:51, Ben Bolker <bbolker at gmail.com> wrote:

>
> https://www.r-consortium.org/announcement/2018/09/25/fall-
> 2018-isc-call-for-proposals
>
> "What can you do to improve the R ecosystem and how can the R Consortium
> help you do it?"
>
>  The mixed-model ecosystem is admittedly a small part of the R
> ecosystem, but I (biasedly) think it's an important one.
>
>   If people have ideas & opinions about how a chunk of money on the
> order of $10,000 could be valuably spent to improve the mixed-model
> ecosystem in a way that would be appealing to a very broad audience of
> useRs, please discuss.
>
> The deadline for submitting a proposal is midnight PST, Sunday October
> 31, 2018.
>
>
>   cheers
>    Ben Bolker
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>


-- 
Andrew Robinson
Director, CEBRA, School of BioSciences
Reader & Associate Professor in Applied Statistics  Tel: (+61) 0403 138 955
School of Mathematics and Statistics                        Fax: (+61) 03
8344 4599
University of Melbourne, VIC 3010 Australia
Email: apro at unimelb.edu.au
Website: http://www.ms.unimelb.edu.au/~andrewpr

	[[alternative HTML version deleted]]


From d@kot@judo @ending from m@c@com  Tue Sep 25 23:17:42 2018
From: d@kot@judo @ending from m@c@com (Peter Claussen)
Date: Tue, 25 Sep 2018 16:17:42 -0500
Subject: [R-sig-ME] R Consortium call for funding
In-Reply-To: <daeea344-1e24-d314-8583-da0e1e8b6d4d@gmail.com>
References: <daeea344-1e24-d314-8583-da0e1e8b6d4d@gmail.com>
Message-ID: <212A8E59-EEDA-4CC1-BE5F-D769ED5A8F61@mac.com>

Personally, I?m trying to duplicate some standard repeated measures analysis from SAS and am missing Kenward-Roger and Satterthwaite corrections for nlme. I had some concerns about lmeTest, but I haven?t looked at that in a while - I?m a bit more concerned with structure error covariances.

Cheers,

> On Sep 25, 2018, at 3:51 PM, Ben Bolker <bbolker at gmail.com> wrote:
> 
> 
> https://www.r-consortium.org/announcement/2018/09/25/fall-2018-isc-call-for-proposals
> 
> "What can you do to improve the R ecosystem and how can the R Consortium
> help you do it?"
> 
> The mixed-model ecosystem is admittedly a small part of the R
> ecosystem, but I (biasedly) think it's an important one.
> 
>  If people have ideas & opinions about how a chunk of money on the
> order of $10,000 could be valuably spent to improve the mixed-model
> ecosystem in a way that would be appealing to a very broad audience of
> useRs, please discuss.
> 
> The deadline for submitting a proposal is midnight PST, Sunday October
> 31, 2018.
> 
> 
>  cheers
>   Ben Bolker
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From lize@t@t@ @ending from gm@il@com  Wed Sep 26 09:56:06 2018
From: lize@t@t@ @ending from gm@il@com (Lize van der Merwe)
Date: Wed, 26 Sep 2018 09:56:06 +0200
Subject: [R-sig-ME] R Consortium call for funding
In-Reply-To: <daeea344-1e24-d314-8583-da0e1e8b6d4d@gmail.com>
References: <daeea344-1e24-d314-8583-da0e1e8b6d4d@gmail.com>
Message-ID: <001f01d4556e$64f3a680$2edaf380$@gmail.com>


Thankyou.  
I would like to see the functionality of nlme and lmer4 combined, especially
regarding variance-covariance structure. 
Regards
Lize van der Merwe



-----Original Message-----
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> On
Behalf Of Ben Bolker
Sent: Tuesday, 25 September 2018 22:51
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] R Consortium call for funding


https://www.r-consortium.org/announcement/2018/09/25/fall-2018-isc-call-for-
proposals

"What can you do to improve the R ecosystem and how can the R Consortium
help you do it?"

 The mixed-model ecosystem is admittedly a small part of the R ecosystem,
but I (biasedly) think it's an important one.

  If people have ideas & opinions about how a chunk of money on the order of
$10,000 could be valuably spent to improve the mixed-model ecosystem in a
way that would be appealing to a very broad audience of useRs, please
discuss.

The deadline for submitting a proposal is midnight PST, Sunday October 31,
2018.


  cheers
   Ben Bolker

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From m@echler @ending from @t@t@m@th@ethz@ch  Wed Sep 26 10:00:44 2018
From: m@echler @ending from @t@t@m@th@ethz@ch (Martin Maechler)
Date: Wed, 26 Sep 2018 10:00:44 +0200
Subject: [R-sig-ME] R Consortium call for funding
In-Reply-To: <212A8E59-EEDA-4CC1-BE5F-D769ED5A8F61@mac.com>
References: <daeea344-1e24-d314-8583-da0e1e8b6d4d@gmail.com>
 <212A8E59-EEDA-4CC1-BE5F-D769ED5A8F61@mac.com>
Message-ID: <23467.15532.159172.765135@stat.math.ethz.ch>

>>>>> Peter Claussen via R-sig-mixed-models 
>>>>>     on Tue, 25 Sep 2018 16:17:42 -0500 writes:

    > Personally, I?m trying to duplicate some standard repeated measures analysis from SAS and am missing Kenward-Roger and Satterthwaite corrections for nlme. I had some concerns about lmeTest, but I haven?t looked at that in a while - I?m a bit more concerned with structure error covariances.

I assume you mean 'lmerTest' above, the CRAN package originally
mostly by Rune Haubo Christensen
       https://cran.r-project.org/package=lmerTest

I think its Satterthwaite (and Kenward-Roger via CRAN package
'pbkrtest') 'df' approximation computations have become quite
reliable, after Rune's recent refurbishing, see also
	  https://htmlpreview.github.io/?https://github.com/runehaubo/lmerTestR/blob/master/pkg_notes/Satterthwaite_for_LMMs.html

-- as always at least as long as you refrain from fitting much
   overparametrized models -- which you should even though some
   authors tell you to do so.


Martin Maechler
ETH Zurich

    > Cheers,

    >> On Sep 25, 2018, at 3:51 PM, Ben Bolker <bbolker at gmail.com> wrote:
    >> 
    >> 
    >> https://www.r-consortium.org/announcement/2018/09/25/fall-2018-isc-call-for-proposals
    >> 
    >> "What can you do to improve the R ecosystem and how can the R Consortium
    >> help you do it?"
    >> 
    >> The mixed-model ecosystem is admittedly a small part of the R
    >> ecosystem, but I (biasedly) think it's an important one.
    >> 
    >> If people have ideas & opinions about how a chunk of money on the
    >> order of $10,000 could be valuably spent to improve the mixed-model
    >> ecosystem in a way that would be appealing to a very broad audience of
    >> useRs, please discuss.
    >> 
    >> The deadline for submitting a proposal is midnight PST, Sunday October
    >> 31, 2018.
    >> 
    >> 
    >> cheers
    >> Ben Bolker
    >> 
    >> _______________________________________________
    >> R-sig-mixed-models at r-project.org mailing list
    >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

    > _______________________________________________
    > R-sig-mixed-models at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From m@r@mon@fern@ndez @ending from gm@il@com  Wed Sep 26 12:52:46 2018
From: m@r@mon@fern@ndez @ending from gm@il@com (Manuel Ramon)
Date: Wed, 26 Sep 2018 12:52:46 +0200
Subject: [R-sig-ME] R Consortium call for funding
In-Reply-To: <daeea344-1e24-d314-8583-da0e1e8b6d4d@gmail.com>
References: <daeea344-1e24-d314-8583-da0e1e8b6d4d@gmail.com>
Message-ID: <CAHB8JpKDnLWo_R9gf+ep0Gp5N6YPfdig==Bjxr5XHck9O6Fmeg@mail.gmail.com>

I totally agree with you, Ben. I have to admit that all the tidyverse world
has suppose a great improvement in the way I work with data, but in the
end, almost all my analyses conclude with the nlme/lme4 packages. So I
think it is worth investing funds and time on it.

As suggested by others, the inclusion of the variance functions from nlme
would be very useful. Also, some of the capabilities of the mixed.models in
Julia language in terms of computation time and data size would be very
welcome, but this latter it is probably very difficult (almost impossible)
given that they are to different platforms.

In any case, thanks for the initiative and I hope it will go ahead.

Regards,
Manuel


On Tue, Sep 25, 2018 at 11:00 PM Ben Bolker <bbolker at gmail.com> wrote:

>
>
> https://www.r-consortium.org/announcement/2018/09/25/fall-2018-isc-call-for-proposals
>
> "What can you do to improve the R ecosystem and how can the R Consortium
> help you do it?"
>
>  The mixed-model ecosystem is admittedly a small part of the R
> ecosystem, but I (biasedly) think it's an important one.
>
>   If people have ideas & opinions about how a chunk of money on the
> order of $10,000 could be valuably spent to improve the mixed-model
> ecosystem in a way that would be appealing to a very broad audience of
> useRs, please discuss.
>
> The deadline for submitting a proposal is midnight PST, Sunday October
> 31, 2018.
>
>
>   cheers
>    Ben Bolker
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From mollieebrook@ @ending from gm@il@com  Wed Sep 26 13:37:17 2018
From: mollieebrook@ @ending from gm@il@com (Mollie Brooks)
Date: Wed, 26 Sep 2018 13:37:17 +0200
Subject: [R-sig-ME] R Consortium call for funding
In-Reply-To: <CAHB8JpKDnLWo_R9gf+ep0Gp5N6YPfdig==Bjxr5XHck9O6Fmeg@mail.gmail.com>
References: <daeea344-1e24-d314-8583-da0e1e8b6d4d@gmail.com>
 <CAHB8JpKDnLWo_R9gf+ep0Gp5N6YPfdig==Bjxr5XHck9O6Fmeg@mail.gmail.com>
Message-ID: <5861EF0E-B451-4ADF-A237-0C67F6378F16@gmail.com>

Lize and Manuel brought up covariance structures and speed, so I wanted to let you all know that the glmmTMB developers have been working towards these goals (https://cran.r-project.org/web/packages/glmmTMB/vignettes/covstruct.html <https://cran.r-project.org/web/packages/glmmTMB/vignettes/covstruct.html>). It?s also easy to add additional structures to glmmTMB. We could use some help testing the covariance structures (https://github.com/glmmTMB/glmmTMB/issues/344 <https://github.com/glmmTMB/glmmTMB/issues/344>). We recently found a bug that could cause problems in models with multiple types of covariance structures, but it has been fixed if you install the development (i.e. Github) version of lme4 and the fix_covstruct_order2 branch of glmmTMB (https://github.com/glmmTMB/glmmTMB/tree/fix_covstruct_order2 <https://github.com/glmmTMB/glmmTMB/tree/fix_covstruct_order2>). These should both be on CRAN soon. 


In my opinion, the biggest need for improvement is to provide predictions and coefficients with confidence intervals on a meaningful scale when a nonlinear link function is used. This comes up repeatedly on this list (e.g. earlier this month https://stat.ethz.ch/pipermail/r-sig-mixed-models/2018q3/027237.html). The solution will probably involve marginalizing over random effects, but non-parametric bootstrapping while resampling the levels of random effects could also be useful.

cheers,
Mollie

> On 26Sep 2018, at 12:52, Manuel Ramon <m.ramon.fernandez at gmail.com> wrote:
> 
> I totally agree with you, Ben. I have to admit that all the tidyverse world
> has suppose a great improvement in the way I work with data, but in the
> end, almost all my analyses conclude with the nlme/lme4 packages. So I
> think it is worth investing funds and time on it.
> 
> As suggested by others, the inclusion of the variance functions from nlme
> would be very useful. Also, some of the capabilities of the mixed.models in
> Julia language in terms of computation time and data size would be very
> welcome, but this latter it is probably very difficult (almost impossible)
> given that they are to different platforms.
> 
> In any case, thanks for the initiative and I hope it will go ahead.
> 
> Regards,
> Manuel
> 
> 
> On Tue, Sep 25, 2018 at 11:00 PM Ben Bolker <bbolker at gmail.com> wrote:
> 
>> 
>> 
>> https://www.r-consortium.org/announcement/2018/09/25/fall-2018-isc-call-for-proposals
>> 
>> "What can you do to improve the R ecosystem and how can the R Consortium
>> help you do it?"
>> 
>> The mixed-model ecosystem is admittedly a small part of the R
>> ecosystem, but I (biasedly) think it's an important one.
>> 
>>  If people have ideas & opinions about how a chunk of money on the
>> order of $10,000 could be valuably spent to improve the mixed-model
>> ecosystem in a way that would be appealing to a very broad audience of
>> useRs, please discuss.
>> 
>> The deadline for submitting a proposal is midnight PST, Sunday October
>> 31, 2018.
>> 
>> 
>>  cheers
>>   Ben Bolker
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


	[[alternative HTML version deleted]]


From @ingm@nn @ending from p@ychologie@uzh@ch  Wed Sep 26 15:58:39 2018
From: @ingm@nn @ending from p@ychologie@uzh@ch (Henrik Singmann)
Date: Wed, 26 Sep 2018 15:58:39 +0200
Subject: [R-sig-ME] new afex version: plot results from factorial designs
 with afex_plot()
Message-ID: <8bb368fc-e7f7-c263-22d7-c51f356f6581@psychologie.uzh.ch>

Dear list,

A few days ago I have released a new version of afex (0.22-1) to CRAN:
https://cran.r-project.org/package=afex

The main news is a new generic for plotting results from factorial 
designs. afex_plot() combines estimated marginal means and associated 
error bars with a depiction of the raw data in the background. 
Currently, afex_plots() supports ANOVAs and mixed models fitted with 
afex as well as models fitted with lme4 (support for more models will 
come in the next version). It also allows different types of error bars, 
including within-subjects confidence intervals.

afex_plots() is built on ggplot2 and designed in a modular manner, 
making it easy to customize the plot to ones personal preferences. The 
perhaps most important customizations are:
(a) Changing the mapping (in ggplot2 parlance) of the trace/x factor(s). 
That is, they way in which different levels of the factor(s) are 
visually represented. The default is mapping = c("shape", "linetype") 
for the trace factor(s) but, any combination of c("shape", "color", 
"linetype", "fill") can make sense.
(b) Changing the geom for the data plotted in the background. The 
default uses geom_point, but many others such as geom_boxplot or 
geom_violin are possible.

For example:

library("afex")
library("ggplot2")

Oats <- nlme::Oats
## afex_plot does currently not support implicit nesting: (1|Block/Variety)
## Instead, we need to create the factor explicitly
Oats$VarBlock <- Oats$Variety:Oats$Block
Oats.lmer <- lmer(yield ~ Variety * factor(nitro) + (1|VarBlock) + 
(1|Block),
 ??????????????????????? data = Oats)
## basic plots:
afex_plot(Oats.lmer, x = "nitro", trace = "Variety")
afex_plot(Oats.lmer, x = "nitro", panel = "Variety")

# some customization:
afex_plot(Oats.lmer, x = "nitro", trace = "Variety",
 ????????? mapping = c("fill", "shape"), dodge = 0.8,
 ????????? data_geom = geom_violin,
 ????????? data_arg = list(width = 0.7))

An overview of the functionality is provided in the vignette:
https://singmann.github.io/afex_plot_introduction.html

Some more information on the types of error bars can be found at the 
help page:
https://www.rdocumentation.org/packages/afex/versions/0.22-1/topics/afex_plot

The full list of changes is on CRAN:
https://cran.rstudio.com/web/packages/afex/NEWS

I apologize for cross-posting,
Henrik


PS: There is an error in the vignette on CRAN and the help page. The 
correct argument name for new factor levels is "factor_levels" and not 
"new_levels". The vignette linked to above is already corrected.


-- 
Dr. Henrik Singmann
PostDoc
Universit?t Z?rich, Schweiz
http://singmann.org


From trevord@vi@w@lker @ending from gm@il@com  Wed Sep 26 17:42:09 2018
From: trevord@vi@w@lker @ending from gm@il@com (Trevor Walker)
Date: Wed, 26 Sep 2018 11:42:09 -0400
Subject: [R-sig-ME] R Consortium call for funding
Message-ID: <CAMDVrE07aG1u4h9CPVOZ4i=SZBeOCnTL5-o-XyvHq5PuMN0FGw@mail.gmail.com>

It would be nice to have some of the ASReml utilities for flexible
variance-covariance models.  Such as heterogenous residuals for different
levels of fixed effects.  Another is coruh structures for nested random
effects (uniform covariance but heterogenous variances along the diagonal).

 Trevor

	[[alternative HTML version deleted]]


From ddi@@b01 @ending from gm@il@com  Wed Sep 26 22:34:14 2018
From: ddi@@b01 @ending from gm@il@com (David Disabato)
Date: Wed, 26 Sep 2018 16:34:14 -0400
Subject: [R-sig-ME] R-sig-mixed-models Digest, Vol 141, Issue 25
In-Reply-To: <mailman.16927.5632.1537948856.1179.r-sig-mixed-models@r-project.org>
References: <mailman.16927.5632.1537948856.1179.r-sig-mixed-models@r-project.org>
Message-ID: <CACg022-cL=YcHb5uE1ORPiCZLgVD6U6ZbOJggeyxccATT8kazQ@mail.gmail.com>

I would agree with others about the ability for lme4 to more easily and
flexibly specify the random effect variance-covariance matrix, including
autocorrelation for longitudinal models, as is available in nlme, SPSS, and
SAS.

On Wed, Sep 26, 2018 at 4:01 AM <r-sig-mixed-models-request at r-project.org>
wrote:

> Send R-sig-mixed-models mailing list submissions to
>         r-sig-mixed-models at r-project.org
>
> To subscribe or unsubscribe via the World Wide Web, visit
>         https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> or, via email, send a message with subject or body 'help' to
>         r-sig-mixed-models-request at r-project.org
>
> You can reach the person managing the list at
>         r-sig-mixed-models-owner at r-project.org
>
> When replying, please edit your Subject line so it is more specific
> than "Re: Contents of R-sig-mixed-models digest..."
> Today's Topics:
>
>    1. R Consortium call for funding (Ben Bolker)
>    2. Re: R Consortium call for funding (Andrew Robinson)
>    3. Re: R Consortium call for funding (Peter Claussen)
>    4. Re: R Consortium call for funding (Lize van der Merwe)
>    5. Re: R Consortium call for funding (Martin Maechler)
>
>
> ---------- Forwarded message ----------
> From: Ben Bolker <bbolker at gmail.com>
> To: "r-sig-mixed-models at r-project.org" <r-sig-mixed-models at r-project.org>
> Cc:
> Bcc:
> Date: Tue, 25 Sep 2018 16:51:24 -0400
> Subject: [R-sig-ME] R Consortium call for funding
>
>
> https://www.r-consortium.org/announcement/2018/09/25/fall-2018-isc-call-for-proposals
>
> "What can you do to improve the R ecosystem and how can the R Consortium
> help you do it?"
>
>  The mixed-model ecosystem is admittedly a small part of the R
> ecosystem, but I (biasedly) think it's an important one.
>
>   If people have ideas & opinions about how a chunk of money on the
> order of $10,000 could be valuably spent to improve the mixed-model
> ecosystem in a way that would be appealing to a very broad audience of
> useRs, please discuss.
>
> The deadline for submitting a proposal is midnight PST, Sunday October
> 31, 2018.
>
>
>   cheers
>    Ben Bolker
>
>
>
>
>
> ---------- Forwarded message ----------
> From: Andrew Robinson <A.Robinson at ms.unimelb.edu.au>
> To: Ben Bolker <bbolker at gmail.com>
> Cc: "r-sig-mixed-models at r-project.org" <r-sig-mixed-models at r-project.org>
> Bcc:
> Date: Wed, 26 Sep 2018 07:06:15 +1000
> Subject: Re: [R-sig-ME] R Consortium call for funding
> Hi Ben,
>
> I do really miss the variance functions of nlme, and the temporal and
> spatial autocorrelation handling.
>
> Warm wishes,
>
> Andrew
>
>
>
> On 26 September 2018 at 06:51, Ben Bolker <bbolker at gmail.com> wrote:
>
> >
> > https://www.r-consortium.org/announcement/2018/09/25/fall-
> > 2018-isc-call-for-proposals
> >
> > "What can you do to improve the R ecosystem and how can the R Consortium
> > help you do it?"
> >
> >  The mixed-model ecosystem is admittedly a small part of the R
> > ecosystem, but I (biasedly) think it's an important one.
> >
> >   If people have ideas & opinions about how a chunk of money on the
> > order of $10,000 could be valuably spent to improve the mixed-model
> > ecosystem in a way that would be appealing to a very broad audience of
> > useRs, please discuss.
> >
> > The deadline for submitting a proposal is midnight PST, Sunday October
> > 31, 2018.
> >
> >
> >   cheers
> >    Ben Bolker
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> >
>
>
> --
> Andrew Robinson
> Director, CEBRA, School of BioSciences
> Reader & Associate Professor in Applied Statistics  Tel: (+61) 0403 138 955
> School of Mathematics and Statistics                        Fax: (+61) 03
> 8344 4599
> University of Melbourne, VIC 3010 Australia
> Email: apro at unimelb.edu.au
> Website: http://www.ms.unimelb.edu.au/~andrewpr
>
>         [[alternative HTML version deleted]]
>
>
>
>
>
> ---------- Forwarded message ----------
> From: Peter Claussen <dakotajudo at mac.com>
> To: Ben Bolker <bbolker at gmail.com>
> Cc: "r-sig-mixed-models at r-project.org" <r-sig-mixed-models at r-project.org>
> Bcc:
> Date: Tue, 25 Sep 2018 16:17:42 -0500
> Subject: Re: [R-sig-ME] R Consortium call for funding
> Personally, I?m trying to duplicate some standard repeated measures
> analysis from SAS and am missing Kenward-Roger and Satterthwaite
> corrections for nlme. I had some concerns about lmeTest, but I haven?t
> looked at that in a while - I?m a bit more concerned with structure error
> covariances.
>
> Cheers,
>
> > On Sep 25, 2018, at 3:51 PM, Ben Bolker <bbolker at gmail.com> wrote:
> >
> >
> >
> https://www.r-consortium.org/announcement/2018/09/25/fall-2018-isc-call-for-proposals
> >
> > "What can you do to improve the R ecosystem and how can the R Consortium
> > help you do it?"
> >
> > The mixed-model ecosystem is admittedly a small part of the R
> > ecosystem, but I (biasedly) think it's an important one.
> >
> >  If people have ideas & opinions about how a chunk of money on the
> > order of $10,000 could be valuably spent to improve the mixed-model
> > ecosystem in a way that would be appealing to a very broad audience of
> > useRs, please discuss.
> >
> > The deadline for submitting a proposal is midnight PST, Sunday October
> > 31, 2018.
> >
> >
> >  cheers
> >   Ben Bolker
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>
>
>
> ---------- Forwarded message ----------
> From: Lize van der Merwe <lizestats at gmail.com>
> To: "'Ben Bolker'" <bbolker at gmail.com>, <r-sig-mixed-models at r-project.org>
> Cc:
> Bcc:
> Date: Wed, 26 Sep 2018 09:56:06 +0200
> Subject: Re: [R-sig-ME] R Consortium call for funding
>
> Thankyou.
> I would like to see the functionality of nlme and lmer4 combined,
> especially
> regarding variance-covariance structure.
> Regards
> Lize van der Merwe
>
>
>
> -----Original Message-----
> From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> On
> Behalf Of Ben Bolker
> Sent: Tuesday, 25 September 2018 22:51
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] R Consortium call for funding
>
>
>
> https://www.r-consortium.org/announcement/2018/09/25/fall-2018-isc-call-for-
> proposals
>
> "What can you do to improve the R ecosystem and how can the R Consortium
> help you do it?"
>
>  The mixed-model ecosystem is admittedly a small part of the R ecosystem,
> but I (biasedly) think it's an important one.
>
>   If people have ideas & opinions about how a chunk of money on the order
> of
> $10,000 could be valuably spent to improve the mixed-model ecosystem in a
> way that would be appealing to a very broad audience of useRs, please
> discuss.
>
> The deadline for submitting a proposal is midnight PST, Sunday October 31,
> 2018.
>
>
>   cheers
>    Ben Bolker
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>
>
>
> ---------- Forwarded message ----------
> From: Martin Maechler <maechler at stat.math.ethz.ch>
> To: Peter Claussen <dakotajudo at mac.com>
> Cc: Ben Bolker <bbolker at gmail.com>, "r-sig-mixed-models at r-project.org" <
> r-sig-mixed-models at r-project.org>
> Bcc:
> Date: Wed, 26 Sep 2018 10:00:44 +0200
> Subject: Re: [R-sig-ME] R Consortium call for funding
> >>>>> Peter Claussen via R-sig-mixed-models
> >>>>>     on Tue, 25 Sep 2018 16:17:42 -0500 writes:
>
>     > Personally, I?m trying to duplicate some standard repeated measures
> analysis from SAS and am missing Kenward-Roger and Satterthwaite
> corrections for nlme. I had some concerns about lmeTest, but I haven?t
> looked at that in a while - I?m a bit more concerned with structure error
> covariances.
>
> I assume you mean 'lmerTest' above, the CRAN package originally
> mostly by Rune Haubo Christensen
>        https://cran.r-project.org/package=lmerTest
>
> I think its Satterthwaite (and Kenward-Roger via CRAN package
> 'pbkrtest') 'df' approximation computations have become quite
> reliable, after Rune's recent refurbishing, see also
>
> https://htmlpreview.github.io/?https://github.com/runehaubo/lmerTestR/blob/master/pkg_notes/Satterthwaite_for_LMMs.html
>
> -- as always at least as long as you refrain from fitting much
>    overparametrized models -- which you should even though some
>    authors tell you to do so.
>
>
> Martin Maechler
> ETH Zurich
>
>     > Cheers,
>
>     >> On Sep 25, 2018, at 3:51 PM, Ben Bolker <bbolker at gmail.com> wrote:
>     >>
>     >>
>     >>
> https://www.r-consortium.org/announcement/2018/09/25/fall-2018-isc-call-for-proposals
>     >>
>     >> "What can you do to improve the R ecosystem and how can the R
> Consortium
>     >> help you do it?"
>     >>
>     >> The mixed-model ecosystem is admittedly a small part of the R
>     >> ecosystem, but I (biasedly) think it's an important one.
>     >>
>     >> If people have ideas & opinions about how a chunk of money on the
>     >> order of $10,000 could be valuably spent to improve the mixed-model
>     >> ecosystem in a way that would be appealing to a very broad audience
> of
>     >> useRs, please discuss.
>     >>
>     >> The deadline for submitting a proposal is midnight PST, Sunday
> October
>     >> 31, 2018.
>     >>
>     >>
>     >> cheers
>     >> Ben Bolker
>     >>
>     >> _______________________________________________
>     >> R-sig-mixed-models at r-project.org mailing list
>     >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>     > _______________________________________________
>     > R-sig-mixed-models at r-project.org mailing list
>     > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
> _______________________________________________
> R-sig-mixed-models mailing list
> R-sig-mixed-models at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


-- 
David J. Disabato, M.A.
Clinical Psychology Doctoral Student
George Mason University
ddisabat at gmu.edu

Email is not a secure form of communication as information and
confidentiality cannot be guaranteed. Information provided in an email is
not intended to be a professional service. In the case of a crisis or
emergency situation, call 911.

	[[alternative HTML version deleted]]


From orchidn @ending from live@com  Sat Sep 29 02:21:58 2018
From: orchidn @ending from live@com (dani jones)
Date: Sat, 29 Sep 2018 00:21:58 +0000
Subject: [R-sig-ME] spline representation
Message-ID: <BYAPR06MB3832490264935DF50869944BD6ED0@BYAPR06MB3832.namprd06.prod.outlook.com>

Hello everyone,

I am working with a GAM model and I am trying to represent graphically the splines from my model.

I would like to be able to somehow  highlight the portions of the splines in areas in which the confidence bands do not include the value of 0. Any help would be much appreciated.

Thanks! best regards,
Dani

	[[alternative HTML version deleted]]


From jdnewmil @ending from dcn@d@vi@@c@@u@  Sat Sep 29 06:32:46 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Fri, 28 Sep 2018 21:32:46 -0700
Subject: [R-sig-ME] spline representation
In-Reply-To: <BYAPR06MB3832490264935DF50869944BD6ED0@BYAPR06MB3832.namprd06.prod.outlook.com>
References: <BYAPR06MB3832490264935DF50869944BD6ED0@BYAPR06MB3832.namprd06.prod.outlook.com>
Message-ID: <DB819AB0-97BA-4689-821B-E32907C1BE81@dcn.davis.ca.us>

The general method (entirely independent of how you are doing the modeling, as long as you have figured out how to obtain the confidence intervals you wish to test) is to generate  a grid of input points (e.g. expand.grid) and compute your predicted fit and corresponding lwr and upr limits. If you plot your fit points and use a vector of colors created by testing the lwr and upr values then the desired highlighting can be accomplished.

It is not clear how this actually relates to ME... posting your plotting code so far for a toy example in R-help might get you a more thorough response.

One complexity of ME is that it often has more than one dependent variable, so the details of how you are breaking those down into a plot even without the highlighting need to be clarified.

On September 28, 2018 5:21:58 PM PDT, dani jones <orchidn at live.com> wrote:
>Hello everyone,
>
>I am working with a GAM model and I am trying to represent graphically
>the splines from my model.
>
>I would like to be able to somehow  highlight the portions of the
>splines in areas in which the confidence bands do not include the value
>of 0. Any help would be much appreciated.
>
>Thanks! best regards,
>Dani
>
>	[[alternative HTML version deleted]]
>
>_______________________________________________
>R-sig-mixed-models at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Sent from my phone. Please excuse my brevity.


