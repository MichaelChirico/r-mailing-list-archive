From m||||eeng @end|ng |rom gm@||@com  Thu Oct  1 09:30:40 2020
From: m||||eeng @end|ng |rom gm@||@com (Marte Lilleeng)
Date: Thu, 1 Oct 2020 09:30:40 +0200
Subject: [R-sig-ME] (no subject)
Message-ID: <CAM-hW5eqAnSJq-iofF3wXN2zoFSMQRcrXgEpJr-Jg23H2u7S-Q@mail.gmail.com>

I want to unsubscribe from this list.
-- 
Mvh Marte Synn?ve Lilleeng
tlf 97 74 38 12

	[[alternative HTML version deleted]]


From dr@@@tr@nge @end|ng |rom gm@||@com  Fri Oct  2 10:52:43 2020
From: dr@@@tr@nge @end|ng |rom gm@||@com (Michele Scandola)
Date: Fri, 2 Oct 2020 10:52:43 +0200
Subject: [R-sig-ME] Not really interested in correlations or random effects
 variances
Message-ID: <CACCLvzqd3WOk9p-J8xFErP1pMDxHBg8XinJ2u53B7gEA-M7Ebw@mail.gmail.com>

Hi all,

let's hypothesize that I have a full-crossed experiment, that actually it
may be analysed with a standard ANOVA, but because I want to increase the
power of the analyses, and add as random slope the time passed
trail-by-trail since the beginning of the experiment, to take into account
for fatigue effects, I want to analyse these data with a multilevel linear
model.

Let's say that in this experiment I have two within-subjects factors that
are interacting. If I am not really interested neither in the variances
between the random slopes nor in the variances of the random effects, may I
totally avoid random slopes, using in their place random intercepts?

What I mean is, instead of this full slopes model: y~C1*C2+(C2*C2|ID)
can I use this "full intercept model":
y~C1*C2+(1|ID:C1:C2)+(1|ID:C1)+(1|ID:C2)+(1|ID)?

Is there any specific reason why it should not be recommended the second
model?

Thanks a lot for your help, best regards,

Michele Scandola

-- 
Assistant Professor @ NPSY-Lab.VR - University of Verona
Iscrizione all'albo A dell'Ordine degli Psicologi del Veneto n.7733

office tel.

1- 0039 045 802 8407

2- 0039 045 802 8401


https://www.facebook.com/NPSYLab.VR/
http://profs.formazione.univr.it/npsy-labvr/michele-scandola/
http://scholar.google.it/citations?user=mRc0hxsAAAAJ
https://www.researchgate.net/profile/Michele_Scandola
https://orcid.org/0000-0003-0853-8975




*Le informazioni, i dati e le notizie contenute nella presente
comunicazione e i relativi allegati sono di natura privata e come tali
possono essere riservate e sono, comunque, destinate esclusivamente ai
destinatari indicati in epigrafe. La diffusione, distribuzione e/o la
copiatura del documento  trasmesso da parte di qualsiasi soggetto diverso
dal destinatario ? proibita, sia ai sensi dell?art. 616 c.p., sia ai sensi
del D.Lgs. n. 196/2003. Se avete ricevuto questo messaggio per errore, vi
preghiamo di distruggerlo e di darcene immediata comunicazione anche
inviando un messaggio di ritorno all?indirizzo e-mail del mittente.*
*This e-mail (including attachments) is intended only for the recipient(s)
named above. It may contain confidential or privileged information and
should not be read, copied or otherwise used by any other person. If you
are not the named recipient, please contact npsylab.vr at gmail.com
<npsylab.vr at gmail.com> and delete the e-mail from your system. Rif. D.L.
196/2003.*

	[[alternative HTML version deleted]]


From dr@@@tr@nge @end|ng |rom gm@||@com  Fri Oct  2 10:54:17 2020
From: dr@@@tr@nge @end|ng |rom gm@||@com (Michele Scandola)
Date: Fri, 2 Oct 2020 10:54:17 +0200
Subject: [R-sig-ME] Fwd: What "pseudoreplication" or "degrees of freedom
 inflation" is in multilevel models?
In-Reply-To: <CACCLvzrNDDpebZ0zmYErjS3c-JWw9uRD6S_H7odWjem6j_KyiQ@mail.gmail.com>
References: <CACCLvzrNDDpebZ0zmYErjS3c-JWw9uRD6S_H7odWjem6j_KyiQ@mail.gmail.com>
Message-ID: <CACCLvzqyRwMcZr_SM08TRekUn9mPib_6XaFdddwAz2s7_2jYJQ@mail.gmail.com>

Dear all,

probably I am asking something very naive.
In that case, I am sorry, it is not my intention to bother you.
Recently I have found online some references concerning a
"pseudoreplication" or "degrees of freedom inflation" that I understood may
happen when you do not add in the random effects a factor that is a
within-subjects factor.
From the "degrees of freedom inflation" point-of-view, this is more
connected with p-value estimation, leading to an increased first-type
error. From the "pseudoreplication" point-of-view, it is as we are
declaring that data that are dependent, as they were independent.

Is it right? Do you have any specific bibliographic reference about that?

Thanks a lot for your time, best regards,

Michele Scandola

-- 
Assistant Professor @ NPSY-Lab.VR - University of Verona
Iscrizione all'albo A dell'Ordine degli Psicologi del Veneto n.7733

office tel.

1- 0039 045 802 8407

2- 0039 045 802 8401


https://www.facebook.com/NPSYLab.VR/
http://profs.formazione.univr.it/npsy-labvr/michele-scandola/
http://scholar.google.it/citations?user=mRc0hxsAAAAJ
https://www.researchgate.net/profile/Michele_Scandola
https://orcid.org/0000-0003-0853-8975




*Le informazioni, i dati e le notizie contenute nella presente
comunicazione e i relativi allegati sono di natura privata e come tali
possono essere riservate e sono, comunque, destinate esclusivamente ai
destinatari indicati in epigrafe. La diffusione, distribuzione e/o la
copiatura del documento  trasmesso da parte di qualsiasi soggetto diverso
dal destinatario ? proibita, sia ai sensi dell?art. 616 c.p., sia ai sensi
del D.Lgs. n. 196/2003. Se avete ricevuto questo messaggio per errore, vi
preghiamo di distruggerlo e di darcene immediata comunicazione anche
inviando un messaggio di ritorno all?indirizzo e-mail del mittente.*
*This e-mail (including attachments) is intended only for the recipient(s)
named above. It may contain confidential or privileged information and
should not be read, copied or otherwise used by any other person. If you
are not the named recipient, please contact npsylab.vr at gmail.com
<npsylab.vr at gmail.com> and delete the e-mail from your system. Rif. D.L.
196/2003.*

	[[alternative HTML version deleted]]


From ph||||p@@|d@y @end|ng |rom mp|@n|  Fri Oct  2 16:44:57 2020
From: ph||||p@@|d@y @end|ng |rom mp|@n| (Phillip Alday)
Date: Fri, 2 Oct 2020 16:44:57 +0200
Subject: [R-sig-ME] 
 Not really interested in correlations or random effects variances
In-Reply-To: <CACCLvzqd3WOk9p-J8xFErP1pMDxHBg8XinJ2u53B7gEA-M7Ebw@mail.gmail.com>
References: <CACCLvzqd3WOk9p-J8xFErP1pMDxHBg8XinJ2u53B7gEA-M7Ebw@mail.gmail.com>
Message-ID: <ad6c169f-bf19-5ad1-f0ed-a82dc473cd1b@mpi.nl>

You've discovered the compound symmetric model.

I owe this list some comments on this, but if you search the archives
for some discussion between Maarten Jung and me (one thread was titled
"Appropriate model reduction sequence for factorial design in glmmTMB"
from 2020Q2), you'll find some thoughts on this.

Best,
phillip

On 2/10/20 10:52 am, Michele Scandola wrote:
> Hi all,
> 
> let's hypothesize that I have a full-crossed experiment, that actually it
> may be analysed with a standard ANOVA, but because I want to increase the
> power of the analyses, and add as random slope the time passed
> trail-by-trail since the beginning of the experiment, to take into account
> for fatigue effects, I want to analyse these data with a multilevel linear
> model.
> 
> Let's say that in this experiment I have two within-subjects factors that
> are interacting. If I am not really interested neither in the variances
> between the random slopes nor in the variances of the random effects, may I
> totally avoid random slopes, using in their place random intercepts?
> 
> What I mean is, instead of this full slopes model: y~C1*C2+(C2*C2|ID)
> can I use this "full intercept model":
> y~C1*C2+(1|ID:C1:C2)+(1|ID:C1)+(1|ID:C2)+(1|ID)?
> 
> Is there any specific reason why it should not be recommended the second
> model?
> 
> Thanks a lot for your help, best regards,
> 
> Michele Scandola
>


From Tom_Ph|||pp| @end|ng |rom np@@gov  Fri Oct  2 18:48:58 2020
From: Tom_Ph|||pp| @end|ng |rom np@@gov (Philippi, Tom)
Date: Fri, 2 Oct 2020 16:48:58 +0000
Subject: [R-sig-ME] 
 [EXTERNAL] Fwd: What "pseudoreplication" or "degrees of
 freedom inflation" is in multilevel models?
In-Reply-To: <CACCLvzqyRwMcZr_SM08TRekUn9mPib_6XaFdddwAz2s7_2jYJQ@mail.gmail.com>
References: <CACCLvzrNDDpebZ0zmYErjS3c-JWw9uRD6S_H7odWjem6j_KyiQ@mail.gmail.com>
 <CACCLvzqyRwMcZr_SM08TRekUn9mPib_6XaFdddwAz2s7_2jYJQ@mail.gmail.com>
Message-ID: <DM6PR09MB53520CE9A88FEEEB20607B7BF3310@DM6PR09MB5352.namprd09.prod.outlook.com>

Hurlbert 1984 is the core citation for "pseudoreplication":
Hurlbert, S.H., 1984. Pseudoreplication and the design of ecological field experiments. Ecological monographs, 54(2), pp.187-211.

My take is that for split plots, blocked experiments, repeated measures, etc., Hurlbert's pseudoreplication is simply ecologists testing one experimental treatment against the wrong error term: treating subplots as independent for treatments applied to the whole plot, etc.  The same thing in the temporal form would be treatments applied to subjects, but then subjects remeasured repeatedly over time, and testing as if those repeated measures were independent.

1980s-era calculations for split plot or repeated measures designs required tests for sphericity (equal covariance across all and various adjustments to degrees of freedom).  Modern mixed models approaches allow explicitly specifying the statistical model to match the experimental (or sampling) design.  One way of setting up a model testing a treatment applied to whole plots is have whole plots be the "subject", and the subplots be some form of repeated measures within subjects.  It is even possible to fit spatially-structured covariance for subplots in a field, or AR structure for repeated measures over time.

Even though he is more of a SAS guy than R guru, I find Stroup's book with his "What Would Fisher Do?" a good explanation of the issues and approaches of matching the analysis structure to the experimental structure, but that may be because I appreciate his sense of humor:
Stroup, W.W., 2012. Generalized linear mixed models: modern concepts, methods and applications. CRC press.
The StroupGLMM package has datasets and R code for that book.

There are several very good R books on mixed models: Bates, Bolker, Faraway, Woods, Zuur, and others.

Tom
 

-----Original Message-----
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> On Behalf Of Michele Scandola
Sent: Friday, October 2, 2020 1:54 AM
To: r-sig-mixed-models at r-project.org
Subject: [EXTERNAL] [R-sig-ME] Fwd: What "pseudoreplication" or "degrees of freedom inflation" is in multilevel models?



 This email has been received from outside of DOI - Use caution before clicking on links, opening attachments, or responding.



Dear all,

probably I am asking something very naive.
In that case, I am sorry, it is not my intention to bother you.
Recently I have found online some references concerning a "pseudoreplication" or "degrees of freedom inflation" that I understood may happen when you do not add in the random effects a factor that is a within-subjects factor.
From the "degrees of freedom inflation" point-of-view, this is more connected with p-value estimation, leading to an increased first-type error. From the "pseudoreplication" point-of-view, it is as we are declaring that data that are dependent, as they were independent.

Is it right? Do you have any specific bibliographic reference about that?

Thanks a lot for your time, best regards,

Michele Scandola

--
Assistant Professor @ NPSY-Lab.VR - University of Verona Iscrizione all'albo A dell'Ordine degli Psicologi del Veneto n.7733

office tel.

1- 0039 045 802 8407

2- 0039 045 802 8401


https://www.facebook.com/NPSYLab.VR/
http://profs.formazione.univr.it/npsy-labvr/michele-scandola/
http://scholar.google.it/citations?user=mRc0hxsAAAAJ
https://www.researchgate.net/profile/Michele_Scandola
https://orcid.org/0000-0003-0853-8975




*Le informazioni, i dati e le notizie contenute nella presente comunicazione e i relativi allegati sono di natura privata e come tali possono essere riservate e sono, comunque, destinate esclusivamente ai destinatari indicati in epigrafe. La diffusione, distribuzione e/o la copiatura del documento  trasmesso da parte di qualsiasi soggetto diverso dal destinatario ? proibita, sia ai sensi dell?art. 616 c.p., sia ai sensi del D.Lgs. n. 196/2003. Se avete ricevuto questo messaggio per errore, vi preghiamo di distruggerlo e di darcene immediata comunicazione anche inviando un messaggio di ritorno all?indirizzo e-mail del mittente.* *This e-mail (including attachments) is intended only for the recipient(s) named above. It may contain confidential or privileged information and should not be read, copied or otherwise used by any other person. If you are not the named recipient, please contact npsylab.vr at gmail.com <npsylab.vr at gmail.com> and delete the e-mail from your system. Rif. D.L.
196/2003.*

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

From @|m@h@rme| @end|ng |rom gm@||@com  Sat Oct  3 06:35:56 2020
From: @|m@h@rme| @end|ng |rom gm@||@com (Simon Harmel)
Date: Fri, 2 Oct 2020 23:35:56 -0500
Subject: [R-sig-ME] Dropping correlations bet. random-effects in lme4 syntax
Message-ID: <CACgv6yU4o-cJMagugxQVcobeofsnC2wt6VB0Cn0ofVxdj+7CuA@mail.gmail.com>

Hello all,

I know to drop all correlations among all level-1 predictors in the random
part of an lmer() call, I can use `||`. But I was wondering how to drop
correlations (a) "individually" or (b) "in pairs"?

Example of (a) is how to drop the correlation of B with others (A & C)?
Example of (b) is how to drop the correlation between B and C?

lmer(y ~ A * B * C + (A * B * C  || group), data = data)

Thanks,
Simon

	[[alternative HTML version deleted]]


From @|m@h@rme| @end|ng |rom gm@||@com  Sat Oct  3 07:16:43 2020
From: @|m@h@rme| @end|ng |rom gm@||@com (Simon Harmel)
Date: Sat, 3 Oct 2020 00:16:43 -0500
Subject: [R-sig-ME] blmer(),
 minimum amount of prior to get a model to converge
Message-ID: <CACgv6yX980K9BwUQtxg3cdSGuoN2UnZBVi_FFnehQGKwnbF5yA@mail.gmail.com>

Hello all,

This may be a simple/naive question, but I have a non-converging lmer()
model due to singularity.

I was wondering what is the minimum prior specification in `blmer()` to get
this singular model to converge?

library(lme4)
library(blme)
hsb <- read.csv('
https://raw.githubusercontent.com/rnorouzian/e/master/hsb.csv')m4 <- m1 <-
lmer(math ~ ses*sector + (ses | sch.id), data = hsb)

m2 <- blmer(math ~ ses*sector + (ses | sch.id), data = hsb, cov.prior = ???)

	[[alternative HTML version deleted]]


From ph||||p@@|d@y @end|ng |rom mp|@n|  Sat Oct  3 18:33:21 2020
From: ph||||p@@|d@y @end|ng |rom mp|@n| (Phillip Alday)
Date: Sat, 3 Oct 2020 18:33:21 +0200
Subject: [R-sig-ME] 
 Dropping correlations bet. random-effects in lme4 syntax
In-Reply-To: <CACgv6yU4o-cJMagugxQVcobeofsnC2wt6VB0Cn0ofVxdj+7CuA@mail.gmail.com>
References: <CACgv6yU4o-cJMagugxQVcobeofsnC2wt6VB0Cn0ofVxdj+7CuA@mail.gmail.com>
Message-ID: <06a872f4-a00f-ef39-ba88-5c147620039e@mpi.nl>

You can split the specification of your grouping to achieve this, at
least in part:

lmer(y ~ A * B * C + (A * C | group) + (B|group) , data = data)

Note that life gets tricky with the interaction terms.

Phillip

On 03/10/2020 06:35, Simon Harmel wrote:
> Hello all,
>
> I know to drop all correlations among all level-1 predictors in the random
> part of an lmer() call, I can use `||`. But I was wondering how to drop
> correlations (a) "individually" or (b) "in pairs"?
>
> Example of (a) is how to drop the correlation of B with others (A & C)?
> Example of (b) is how to drop the correlation between B and C?
>
> lmer(y ~ A * B * C + (A * B * C  || group), data = data)
>
> Thanks,
> Simon
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From @|m@h@rme| @end|ng |rom gm@||@com  Sat Oct  3 18:44:36 2020
From: @|m@h@rme| @end|ng |rom gm@||@com (Simon Harmel)
Date: Sat, 3 Oct 2020 11:44:36 -0500
Subject: [R-sig-ME] 
 Dropping correlations bet. random-effects in lme4 syntax
In-Reply-To: <06a872f4-a00f-ef39-ba88-5c147620039e@mpi.nl>
References: <CACgv6yU4o-cJMagugxQVcobeofsnC2wt6VB0Cn0ofVxdj+7CuA@mail.gmail.com>
 <06a872f4-a00f-ef39-ba88-5c147620039e@mpi.nl>
Message-ID: <CACgv6yWeKyybJO6vOZM7B+RbxLSr3K75TdTUfoYrsHKXoS=NXQ@mail.gmail.com>

Thanks Phillip. What would be the meaning of placing `0 +` next to any of
the random effects (e.g., B) as shown in m2?

m1 <- lmer(y ~ A * B * C + (A * C | group) + (B|group) , data = data)

m2 <- lmer(y ~ A * B * C + (A * 0+ B * C  | group), data = data)

On Sat, Oct 3, 2020 at 11:33 AM Phillip Alday <phillip.alday at mpi.nl> wrote:

> You can split the specification of your grouping to achieve this, at
> least in part:
>
> lmer(y ~ A * B * C + (A * C | group) + (B|group) , data = data)
>
> Note that life gets tricky with the interaction terms.
>
> Phillip
>
> On 03/10/2020 06:35, Simon Harmel wrote:
> > Hello all,
> >
> > I know to drop all correlations among all level-1 predictors in the
> random
> > part of an lmer() call, I can use `||`. But I was wondering how to drop
> > correlations (a) "individually" or (b) "in pairs"?
> >
> > Example of (a) is how to drop the correlation of B with others (A & C)?
> > Example of (b) is how to drop the correlation between B and C?
> >
> > lmer(y ~ A * B * C + (A * B * C  || group), data = data)
> >
> > Thanks,
> > Simon
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From ph||||p@@|d@y @end|ng |rom mp|@n|  Sat Oct  3 18:52:51 2020
From: ph||||p@@|d@y @end|ng |rom mp|@n| (Phillip Alday)
Date: Sat, 3 Oct 2020 18:52:51 +0200
Subject: [R-sig-ME] 
 Dropping correlations bet. random-effects in lme4 syntax
In-Reply-To: <CACgv6yWeKyybJO6vOZM7B+RbxLSr3K75TdTUfoYrsHKXoS=NXQ@mail.gmail.com>
References: <CACgv6yU4o-cJMagugxQVcobeofsnC2wt6VB0Cn0ofVxdj+7CuA@mail.gmail.com>
 <06a872f4-a00f-ef39-ba88-5c147620039e@mpi.nl>
 <CACgv6yWeKyybJO6vOZM7B+RbxLSr3K75TdTUfoYrsHKXoS=NXQ@mail.gmail.com>
Message-ID: <45f07ac3-22e0-c901-e8b4-e5748843a0b9@mpi.nl>

I have no idea what 0* means, but 0+ means "suppress the intercept"
(which has knock-on effects for categorical variables and whether
they're represented in the model as (nlevels-1) contrasts or nlevels).

For the other things: try it out. The output of summary(m1) will show
you which levels and correlations were kept.

On 03/10/2020 18:44, Simon Harmel wrote:
> Thanks Phillip. What would be the meaning of placing `0 +` next to any
> of the random effects (e.g., B) as shown in m2?
>
> m1 <- lmer(y ~ A * B * C + (A * C | group) + (B|group) , data = data)??
>
> m2 <- lmer(y ~ A * B * C + (A * 0+ B * C ?| group), data = data)??
>
> On Sat, Oct 3, 2020 at 11:33 AM Phillip Alday <phillip.alday at mpi.nl
> <mailto:phillip.alday at mpi.nl>> wrote:
>
>     You can split the specification of your grouping to achieve this, at
>     least in part:
>
>     lmer(y ~ A * B * C + (A * C | group) + (B|group) , data = data)
>
>     Note that life gets tricky with the interaction terms.
>
>     Phillip
>
>     On 03/10/2020 06:35, Simon Harmel wrote:
>     > Hello all,
>     >
>     > I know to drop all correlations among all level-1 predictors in
>     the random
>     > part of an lmer() call, I can use `||`. But I was wondering how
>     to drop
>     > correlations (a) "individually" or (b) "in pairs"?
>     >
>     > Example of (a) is how to drop the correlation of B with others
>     (A & C)?
>     > Example of (b) is how to drop the correlation between B and C?
>     >
>     > lmer(y ~ A * B * C + (A * B * C? || group), data = data)
>     >
>     > Thanks,
>     > Simon
>     >
>     >? ? ? ?[[alternative HTML version deleted]]
>     >
>     > _______________________________________________
>     > R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>     > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From @|m@h@rme| @end|ng |rom gm@||@com  Sat Oct  3 19:24:34 2020
From: @|m@h@rme| @end|ng |rom gm@||@com (Simon Harmel)
Date: Sat, 3 Oct 2020 12:24:34 -0500
Subject: [R-sig-ME] 
 Dropping correlations bet. random-effects in lme4 syntax
In-Reply-To: <45f07ac3-22e0-c901-e8b4-e5748843a0b9@mpi.nl>
References: <CACgv6yU4o-cJMagugxQVcobeofsnC2wt6VB0Cn0ofVxdj+7CuA@mail.gmail.com>
 <06a872f4-a00f-ef39-ba88-5c147620039e@mpi.nl>
 <CACgv6yWeKyybJO6vOZM7B+RbxLSr3K75TdTUfoYrsHKXoS=NXQ@mail.gmail.com>
 <45f07ac3-22e0-c901-e8b4-e5748843a0b9@mpi.nl>
Message-ID: <CACgv6yUajwvMNT08N-0oSXUL+gde1PDDnDCnsU7hiq_rBSKNDw@mail.gmail.com>

Thanks for the additional information about the use of `0+` in the context
of categorical variables:)

So, by splitting the specification of the grouping variable like:

lmer(y ~ A * B * C + (A * C | group) + (B|group) , data = data)

I get the below correlation matrix. So, here we have created 2 different
intercepts, one for each "split" of the same grouping variable, right?

I ask this because B has no correlation with the first split's (intercept)
but it has a singular correlation with the second split's (intercept). The
output looks confusing to a novice like me.


            (Intercept)      A      C    A:C (Intercept)  B
(Intercept)       1.000 -0.794 -0.195  0.953           0  0
A                -0.794  1.000  0.278 -0.854           0  0
C                -0.195  0.278  1.000  0.028           0  0
A:C               0.953 -0.854  0.028  1.000           0  0
(Intercept)       0.000  0.000  0.000  0.000           1 -1
B                 0.000  0.000  0.000  0.000          -1  1

On Sat, Oct 3, 2020 at 11:52 AM Phillip Alday <phillip.alday at mpi.nl> wrote:

> I have no idea what 0* means, but 0+ means "suppress the intercept" (which
> has knock-on effects for categorical variables and whether they're
> represented in the model as (nlevels-1) contrasts or nlevels).
>
> For the other things: try it out. The output of summary(m1) will show you
> which levels and correlations were kept.
> On 03/10/2020 18:44, Simon Harmel wrote:
>
> Thanks Phillip. What would be the meaning of placing `0 +` next to any of
> the random effects (e.g., B) as shown in m2?
>
> m1 <- lmer(y ~ A * B * C + (A * C | group) + (B|group) , data = data)
>
> m2 <- lmer(y ~ A * B * C + (A * 0+ B * C  | group), data = data)
>
> On Sat, Oct 3, 2020 at 11:33 AM Phillip Alday <phillip.alday at mpi.nl>
> wrote:
>
>> You can split the specification of your grouping to achieve this, at
>> least in part:
>>
>> lmer(y ~ A * B * C + (A * C | group) + (B|group) , data = data)
>>
>> Note that life gets tricky with the interaction terms.
>>
>> Phillip
>>
>> On 03/10/2020 06:35, Simon Harmel wrote:
>> > Hello all,
>> >
>> > I know to drop all correlations among all level-1 predictors in the
>> random
>> > part of an lmer() call, I can use `||`. But I was wondering how to drop
>> > correlations (a) "individually" or (b) "in pairs"?
>> >
>> > Example of (a) is how to drop the correlation of B with others (A & C)?
>> > Example of (b) is how to drop the correlation between B and C?
>> >
>> > lmer(y ~ A * B * C + (A * B * C  || group), data = data)
>> >
>> > Thanks,
>> > Simon
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> > _______________________________________________
>> > R-sig-mixed-models at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>

	[[alternative HTML version deleted]]


From ph||||p@@|d@y @end|ng |rom mp|@n|  Sat Oct  3 19:40:12 2020
From: ph||||p@@|d@y @end|ng |rom mp|@n| (Phillip Alday)
Date: Sat, 3 Oct 2020 19:40:12 +0200
Subject: [R-sig-ME] 
 Dropping correlations bet. random-effects in lme4 syntax
In-Reply-To: <CACgv6yUajwvMNT08N-0oSXUL+gde1PDDnDCnsU7hiq_rBSKNDw@mail.gmail.com>
References: <CACgv6yU4o-cJMagugxQVcobeofsnC2wt6VB0Cn0ofVxdj+7CuA@mail.gmail.com>
 <06a872f4-a00f-ef39-ba88-5c147620039e@mpi.nl>
 <CACgv6yWeKyybJO6vOZM7B+RbxLSr3K75TdTUfoYrsHKXoS=NXQ@mail.gmail.com>
 <45f07ac3-22e0-c901-e8b4-e5748843a0b9@mpi.nl>
 <CACgv6yUajwvMNT08N-0oSXUL+gde1PDDnDCnsU7hiq_rBSKNDw@mail.gmail.com>
Message-ID: <53573a57-e3ac-7ca0-3258-6163d78f3910@mpi.nl>

On 03/10/2020 19:24, Simon Harmel wrote:
> Thanks for the additional information about the use of `0+` in the
> context of categorical variables:)
>
> So, by splitting the specification of the grouping variable like:
>
> lmer(y ~ A * B * C + (A * C | group) + (B|group) , data = data)???
>
> I get the below correlation matrix. So, here we have created 2
> different intercepts, one for each "split" of the same grouping
> variable, right?

Yes, by default R adds in an intercept. I recommend always writing 1+ or
0+ to make explicit what you want.

(This was what I meant with "Note that life gets tricky with the
interaction terms." in my first reply.)

>
> I ask this because B has no correlation with the first split's
> (intercept) but it has a singular correlation with the second split's
> (intercept). The output looks confusing to a novice like me.
>
>
> ? ? ? ? ? ? (Intercept) ? ? ?A ? ? ?C ? ?A:C (Intercept) ?B
> (Intercept) ? ? ? 1.000 -0.794 -0.195 ?0.953 ? ? ? ? ? 0 ?0
> A ? ? ? ? ? ? ? ?-0.794 ?1.000 ?0.278 -0.854 ? ? ? ? ? 0 ?0
> C ? ? ? ? ? ? ? ?-0.195 ?0.278 ?1.000 ?0.028 ? ? ? ? ? 0 ?0
> A:C ? ? ? ? ? ? ? 0.953 -0.854 ?0.028 ?1.000 ? ? ? ? ? 0 ?0
> (Intercept) ? ? ? 0.000 ?0.000 ?0.000 ?0.000 ? ? ? ? ? 1 -1
> B ? ? ? ? ? ? ? ? 0.000 ?0.000 ?0.000 ?0.000 ? ? ? ? ?-1 ?1

Singularity isn't a problem per se -- it's mathematically well defined
and being able to fit singular covariance matrices for the random
effects was one of the algorithmic innovations lme4 has compared to its
predecessor nlme.

Singularity can be a problem for inference (because it's often a sign of
overfitting).... but it makes sense here. B has no correlation with the
first intercept because you set it to be zero via your formula
specification, so that term is forced to be zero in the model
computation. The second intercept is perfectly correlated with B because
it (the second intercept) is redundant in the model, but it can't
correlate with the first intercept (because that correlation is forced
to zero by your model specification) and so it collapses into B.

If B is continuous, you can avoid this with 0+B. If B is categorical,
then 0+B will still be overparameterized, but you can try 0+dummy(B) to
set up indicator variable for one of the two levels. (I can tell from
your output that B is continuous or only has two levels because there is
only one slope for it.)

Phillip

>
> On Sat, Oct 3, 2020 at 11:52 AM Phillip Alday <phillip.alday at mpi.nl
> <mailto:phillip.alday at mpi.nl>> wrote:
>
>     I have no idea what 0* means, but 0+ means "suppress the
>     intercept" (which has knock-on effects for categorical variables
>     and whether they're represented in the model as (nlevels-1)
>     contrasts or nlevels).
>
>     For the other things: try it out. The output of summary(m1) will
>     show you which levels and correlations were kept.
>
>     On 03/10/2020 18:44, Simon Harmel wrote:
>>     Thanks Phillip. What would be the meaning of placing `0 +` next
>>     to any of the random effects (e.g., B) as shown in m2?
>>
>>     m1 <- lmer(y ~ A * B * C + (A * C | group) + (B|group) , data =
>>     data)??
>>
>>     m2 <- lmer(y ~ A * B * C + (A * 0+ B * C ?| group), data = data)??
>>
>>     On Sat, Oct 3, 2020 at 11:33 AM Phillip Alday
>>     <phillip.alday at mpi.nl <mailto:phillip.alday at mpi.nl>> wrote:
>>
>>         You can split the specification of your grouping to achieve
>>         this, at
>>         least in part:
>>
>>         lmer(y ~ A * B * C + (A * C | group) + (B|group) , data = data)
>>
>>         Note that life gets tricky with the interaction terms.
>>
>>         Phillip
>>
>>         On 03/10/2020 06:35, Simon Harmel wrote:
>>         > Hello all,
>>         >
>>         > I know to drop all correlations among all level-1
>>         predictors in the random
>>         > part of an lmer() call, I can use `||`. But I was wondering
>>         how to drop
>>         > correlations (a) "individually" or (b) "in pairs"?
>>         >
>>         > Example of (a) is how to drop the correlation of B with
>>         others (A & C)?
>>         > Example of (b) is how to drop the correlation between B and C?
>>         >
>>         > lmer(y ~ A * B * C + (A * B * C? || group), data = data)
>>         >
>>         > Thanks,
>>         > Simon
>>         >
>>         >? ? ? ?[[alternative HTML version deleted]]
>>         >
>>         > _______________________________________________
>>         > R-sig-mixed-models at r-project.org
>>         <mailto:R-sig-mixed-models at r-project.org> mailing list
>>         > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>

	[[alternative HTML version deleted]]


From @|m@h@rme| @end|ng |rom gm@||@com  Sat Oct  3 20:54:13 2020
From: @|m@h@rme| @end|ng |rom gm@||@com (Simon Harmel)
Date: Sat, 3 Oct 2020 13:54:13 -0500
Subject: [R-sig-ME] 
 Dropping correlations bet. random-effects in lme4 syntax
In-Reply-To: <53573a57-e3ac-7ca0-3258-6163d78f3910@mpi.nl>
References: <CACgv6yU4o-cJMagugxQVcobeofsnC2wt6VB0Cn0ofVxdj+7CuA@mail.gmail.com>
 <06a872f4-a00f-ef39-ba88-5c147620039e@mpi.nl>
 <CACgv6yWeKyybJO6vOZM7B+RbxLSr3K75TdTUfoYrsHKXoS=NXQ@mail.gmail.com>
 <45f07ac3-22e0-c901-e8b4-e5748843a0b9@mpi.nl>
 <CACgv6yUajwvMNT08N-0oSXUL+gde1PDDnDCnsU7hiq_rBSKNDw@mail.gmail.com>
 <53573a57-e3ac-7ca0-3258-6163d78f3910@mpi.nl>
Message-ID: <CACgv6yU9khJv6O0cyGtHOtxGftzc+a3M75vjvQ+j+MA4msdw_Q@mail.gmail.com>

Awesome, thanks!

On Sat, Oct 3, 2020 at 12:40 PM Phillip Alday <phillip.alday at mpi.nl> wrote:

> On 03/10/2020 19:24, Simon Harmel wrote:
>
> Thanks for the additional information about the use of `0+` in the context
> of categorical variables:)
>
> So, by splitting the specification of the grouping variable like:
>
> lmer(y ~ A * B * C + (A * C | group) + (B|group) , data = data)
>
> I get the below correlation matrix. So, here we have created 2 different
> intercepts, one for each "split" of the same grouping variable, right?
>
> Yes, by default R adds in an intercept. I recommend always writing 1+ or
> 0+ to make explicit what you want.
>
> (This was what I meant with "Note that life gets tricky with the
> interaction terms." in my first reply.)
>
>
> I ask this because B has no correlation with the first split's (intercept)
> but it has a singular correlation with the second split's (intercept). The
> output looks confusing to a novice like me.
>
>
>             (Intercept)      A      C    A:C (Intercept)  B
> (Intercept)       1.000 -0.794 -0.195  0.953           0  0
> A                -0.794  1.000  0.278 -0.854           0  0
> C                -0.195  0.278  1.000  0.028           0  0
> A:C               0.953 -0.854  0.028  1.000           0  0
> (Intercept)       0.000  0.000  0.000  0.000           1 -1
> B                 0.000  0.000  0.000  0.000          -1  1
>
> Singularity isn't a problem per se -- it's mathematically well defined and
> being able to fit singular covariance matrices for the random effects was
> one of the algorithmic innovations lme4 has compared to its predecessor
> nlme.
>
> Singularity can be a problem for inference (because it's often a sign of
> overfitting).... but it makes sense here. B has no correlation with the
> first intercept because you set it to be zero via your formula
> specification, so that term is forced to be zero in the model computation.
> The second intercept is perfectly correlated with B because it (the second
> intercept) is redundant in the model, but it can't correlate with the first
> intercept (because that correlation is forced to zero by your model
> specification) and so it collapses into B.
>
> If B is continuous, you can avoid this with 0+B. If B is categorical, then
> 0+B will still be overparameterized, but you can try 0+dummy(B) to set up
> indicator variable for one of the two levels. (I can tell from your output
> that B is continuous or only has two levels because there is only one slope
> for it.)
>
> Phillip
>
>
> On Sat, Oct 3, 2020 at 11:52 AM Phillip Alday <phillip.alday at mpi.nl>
> wrote:
>
>> I have no idea what 0* means, but 0+ means "suppress the intercept"
>> (which has knock-on effects for categorical variables and whether they're
>> represented in the model as (nlevels-1) contrasts or nlevels).
>>
>> For the other things: try it out. The output of summary(m1) will show you
>> which levels and correlations were kept.
>> On 03/10/2020 18:44, Simon Harmel wrote:
>>
>> Thanks Phillip. What would be the meaning of placing `0 +` next to any of
>> the random effects (e.g., B) as shown in m2?
>>
>> m1 <- lmer(y ~ A * B * C + (A * C | group) + (B|group) , data = data)
>>
>> m2 <- lmer(y ~ A * B * C + (A * 0+ B * C  | group), data = data)
>>
>> On Sat, Oct 3, 2020 at 11:33 AM Phillip Alday <phillip.alday at mpi.nl>
>> wrote:
>>
>>> You can split the specification of your grouping to achieve this, at
>>> least in part:
>>>
>>> lmer(y ~ A * B * C + (A * C | group) + (B|group) , data = data)
>>>
>>> Note that life gets tricky with the interaction terms.
>>>
>>> Phillip
>>>
>>> On 03/10/2020 06:35, Simon Harmel wrote:
>>> > Hello all,
>>> >
>>> > I know to drop all correlations among all level-1 predictors in the
>>> random
>>> > part of an lmer() call, I can use `||`. But I was wondering how to drop
>>> > correlations (a) "individually" or (b) "in pairs"?
>>> >
>>> > Example of (a) is how to drop the correlation of B with others (A & C)?
>>> > Example of (b) is how to drop the correlation between B and C?
>>> >
>>> > lmer(y ~ A * B * C + (A * B * C  || group), data = data)
>>> >
>>> > Thanks,
>>> > Simon
>>> >
>>> >       [[alternative HTML version deleted]]
>>> >
>>> > _______________________________________________
>>> > R-sig-mixed-models at r-project.org mailing list
>>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>

	[[alternative HTML version deleted]]


From @|m@h@rme| @end|ng |rom gm@||@com  Sun Oct  4 02:43:41 2020
From: @|m@h@rme| @end|ng |rom gm@||@com (Simon Harmel)
Date: Sat, 3 Oct 2020 19:43:41 -0500
Subject: [R-sig-ME] Converting lme4 model syntax into corresponding
 regression equation
Message-ID: <CACgv6yX3J2TjJRCKoNXFkpuBYF-hp-0GRMWsinnvFuXRvFvUoQ@mail.gmail.com>

Hello all,

I was wondering if there is any way (e.g., from an existing R package or
function) to obtain the combined regression equation from an R formula used
to fit an lme4::lmer() model?

For example, if I used `lmer(math ~ ses*sector + (ses | sch.id), data =
data)`, then the expected output in R expression would be:

ex <- expression(math == gamma[00] + gamma[01]*sector + gamma[10]*ses +
gamma[11]*(sector *ses)+U[0]+U1*ses+e)

plot(1, main = ex, cex.main = .7)

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Sun Oct  4 02:47:04 2020
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Sat, 3 Oct 2020 20:47:04 -0400
Subject: [R-sig-ME] Converting lme4 model syntax into corresponding
 regression equation
In-Reply-To: <CACgv6yX3J2TjJRCKoNXFkpuBYF-hp-0GRMWsinnvFuXRvFvUoQ@mail.gmail.com>
References: <CACgv6yX3J2TjJRCKoNXFkpuBYF-hp-0GRMWsinnvFuXRvFvUoQ@mail.gmail.com>
Message-ID: <5b85b343-c3e1-c288-f980-1be00d78c908@gmail.com>

   Assuming this is also you:

https://stackoverflow.com/questions/64189964/converting-a-mixed-model-r-syntax-into-its-corresponding-mathematical-equation

  If you're going to cross-post, **please** indicate that fact by 
providing a link in one or both directions!  (The info page for the 
mailing list does say: "Please refrain from cross-posting to related 
venues (e.g. StackExchange sites and other R mailing lists.)")

   The reason for this request is that cross-posting can lead to a lot 
of confusion and duplicated effort.

   cheers
    Ben Bolker


On 10/3/20 8:43 PM, Simon Harmel wrote:
> Hello all,
> 
> I was wondering if there is any way (e.g., from an existing R package or
> function) to obtain the combined regression equation from an R formula used
> to fit an lme4::lmer() model?
> 
> For example, if I used `lmer(math ~ ses*sector + (ses | sch.id), data =
> data)`, then the expected output in R expression would be:
> 
> ex <- expression(math == gamma[00] + gamma[01]*sector + gamma[10]*ses +
> gamma[11]*(sector *ses)+U[0]+U1*ses+e)
> 
> plot(1, main = ex, cex.main = .7)
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From vdor|e @end|ng |rom gm@||@com  Sun Oct  4 03:22:49 2020
From: vdor|e @end|ng |rom gm@||@com (Vincent Dorie)
Date: Sat, 3 Oct 2020 21:22:49 -0400
Subject: [R-sig-ME] blmer(),
 minimum amount of prior to get a model to converge
In-Reply-To: <CACgv6yX980K9BwUQtxg3cdSGuoN2UnZBVi_FFnehQGKwnbF5yA@mail.gmail.com>
References: <CACgv6yX980K9BwUQtxg3cdSGuoN2UnZBVi_FFnehQGKwnbF5yA@mail.gmail.com>
Message-ID: <CA+++UwQx7TWinkLq9Nh6Sz9qifaa9xCOGoah5ZEiJX7mtu6_UA@mail.gmail.com>

There's no single minimum amount, but you can decrease the relative
impact of the prior by fitting a sequence of models until convergence
becomes a problem again.

# default
m2 <- blmer(math ~ ses*sector + (ses | sch.id), data = hsb, cov.prior
= wishart(df = level.dim + 2.5))
# point at which blme model is same as lme4
m3 <- blmer(math ~ ses*sector + (ses | sch.id), data = hsb, cov.prior
= wishart(df = level.dim + 1))
# fit models in sequence with df from level.dim + 2.5 to level.dim + 1

Technically, any prior which goes to zero when the determinant of the
covariance of the random effects go to zero should have the desired
effect (df > level.dim + 1), but there may be limitations introduced
by the optimizer.

Vince


On Sat, Oct 3, 2020 at 1:17 AM Simon Harmel <sim.harmel at gmail.com> wrote:
>
> Hello all,
>
> This may be a simple/naive question, but I have a non-converging lmer()
> model due to singularity.
>
> I was wondering what is the minimum prior specification in `blmer()` to get
> this singular model to converge?
>
> library(lme4)
> library(blme)
> hsb <- read.csv('
> https://raw.githubusercontent.com/rnorouzian/e/master/hsb.csv')m4 <- m1 <-
> lmer(math ~ ses*sector + (ses | sch.id), data = hsb)
>
> m2 <- blmer(math ~ ses*sector + (ses | sch.id), data = hsb, cov.prior = ???)
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbo|ker @end|ng |rom gm@||@com  Sun Oct  4 03:36:34 2020
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Sat, 3 Oct 2020 21:36:34 -0400
Subject: [R-sig-ME] blmer(),
 minimum amount of prior to get a model to converge
In-Reply-To: <CA+++UwQx7TWinkLq9Nh6Sz9qifaa9xCOGoah5ZEiJX7mtu6_UA@mail.gmail.com>
References: <CACgv6yX980K9BwUQtxg3cdSGuoN2UnZBVi_FFnehQGKwnbF5yA@mail.gmail.com>
 <CA+++UwQx7TWinkLq9Nh6Sz9qifaa9xCOGoah5ZEiJX7mtu6_UA@mail.gmail.com>
Message-ID: <4c916671-5a7c-470b-008e-c087b43c6761@gmail.com>

   Thanks Vincent.

   FWIW it would make me really happy if people distinguished clearly 
between

* "singular/nonsingular" - an issue with the 'true' best estimate, i.e. 
whether the MLE for the variance-covariance matrix of the REs is 
positive definite vs. being only positive *semi*definite

* "converged/nonconverged" - a question of whether we think the 
numerical optimization has worked correctly or not

   cheers
    Ben Bolker


On 10/3/20 9:22 PM, Vincent Dorie wrote:
> There's no single minimum amount, but you can decrease the relative
> impact of the prior by fitting a sequence of models until convergence
> becomes a problem again.
> 
> # default
> m2 <- blmer(math ~ ses*sector + (ses | sch.id), data = hsb, cov.prior
> = wishart(df = level.dim + 2.5))
> # point at which blme model is same as lme4
> m3 <- blmer(math ~ ses*sector + (ses | sch.id), data = hsb, cov.prior
> = wishart(df = level.dim + 1))
> # fit models in sequence with df from level.dim + 2.5 to level.dim + 1
> 
> Technically, any prior which goes to zero when the determinant of the
> covariance of the random effects go to zero should have the desired
> effect (df > level.dim + 1), but there may be limitations introduced
> by the optimizer.
> 
> Vince
> 
> 
> On Sat, Oct 3, 2020 at 1:17 AM Simon Harmel <sim.harmel at gmail.com> wrote:
>>
>> Hello all,
>>
>> This may be a simple/naive question, but I have a non-converging lmer()
>> model due to singularity.
>>
>> I was wondering what is the minimum prior specification in `blmer()` to get
>> this singular model to converge?
>>
>> library(lme4)
>> library(blme)
>> hsb <- read.csv('
>> https://raw.githubusercontent.com/rnorouzian/e/master/hsb.csv')m4 <- m1 <-
>> lmer(math ~ ses*sector + (ses | sch.id), data = hsb)
>>
>> m2 <- blmer(math ~ ses*sector + (ses | sch.id), data = hsb, cov.prior = ???)
>>
>>          [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From p|erre@dev|||emereu|| @end|ng |rom ephe@p@|@eu  Sun Oct  4 09:08:22 2020
From: p|erre@dev|||emereu|| @end|ng |rom ephe@p@|@eu (Pierre de Villemereuil)
Date: Sun, 04 Oct 2020 09:08:22 +0200
Subject: [R-sig-ME] Converting lme4 model syntax into corresponding
 regression equation
In-Reply-To: <CACgv6yX3J2TjJRCKoNXFkpuBYF-hp-0GRMWsinnvFuXRvFvUoQ@mail.gmail.com>
References: <CACgv6yX3J2TjJRCKoNXFkpuBYF-hp-0GRMWsinnvFuXRvFvUoQ@mail.gmail.com>
Message-ID: <4174219.a3eTIyvfnI@flyosfixe>

Hi,

I've recently seen the "equatiomatic" package being advertised for this:
https://github.com/datalorax/equatiomatic/

It doesn't claim to support lmer(), but the author seems to be working toward it:
https://github.com/datalorax/equatiomatic/pull/104

Hope this helps,
Pierre

Le dimanche 4 octobre 2020, 02:43:41 CEST Simon Harmel a ?crit :
> Hello all,
> 
> I was wondering if there is any way (e.g., from an existing R package or
> function) to obtain the combined regression equation from an R formula used
> to fit an lme4::lmer() model?
> 
> For example, if I used `lmer(math ~ ses*sector + (ses | sch.id), data =
> data)`, then the expected output in R expression would be:
> 
> ex <- expression(math == gamma[00] + gamma[01]*sector + gamma[10]*ses +
> gamma[11]*(sector *ses)+U[0]+U1*ses+e)
> 
> plot(1, main = ex, cex.main = .7)
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 


From vdor|e @end|ng |rom gm@||@com  Sun Oct  4 18:10:17 2020
From: vdor|e @end|ng |rom gm@||@com (Vincent Dorie)
Date: Sun, 4 Oct 2020 12:10:17 -0400
Subject: [R-sig-ME] blmer(),
 minimum amount of prior to get a model to converge
In-Reply-To: <4c916671-5a7c-470b-008e-c087b43c6761@gmail.com>
References: <CACgv6yX980K9BwUQtxg3cdSGuoN2UnZBVi_FFnehQGKwnbF5yA@mail.gmail.com>
 <CA+++UwQx7TWinkLq9Nh6Sz9qifaa9xCOGoah5ZEiJX7mtu6_UA@mail.gmail.com>
 <4c916671-5a7c-470b-008e-c087b43c6761@gmail.com>
Message-ID: <CA+++UwSLWJ_LYmanEHr3mvWu=PrcfS+QfPmfy04NsC6oVnzMHA@mail.gmail.com>

I agree, that that is a meaningful distinction. You can use a prior to
nudge the estimate away from the boundary of the space, which
addresses singularity. You can also use a prior to add information to
the likelihood, which addresses convergence. However, in the latter
scenario that information would modify your estimate in a subjective
manner, and it would be impossible to say that it was better than
simply living with an optimizer warning unless you actually had prior
information.

On Sat, Oct 3, 2020 at 9:36 PM Ben Bolker <bbolker at gmail.com> wrote:
>
>    Thanks Vincent.
>
>    FWIW it would make me really happy if people distinguished clearly
> between
>
> * "singular/nonsingular" - an issue with the 'true' best estimate, i.e.
> whether the MLE for the variance-covariance matrix of the REs is
> positive definite vs. being only positive *semi*definite
>
> * "converged/nonconverged" - a question of whether we think the
> numerical optimization has worked correctly or not
>
>    cheers
>     Ben Bolker
>
>
> On 10/3/20 9:22 PM, Vincent Dorie wrote:
> > There's no single minimum amount, but you can decrease the relative
> > impact of the prior by fitting a sequence of models until convergence
> > becomes a problem again.
> >
> > # default
> > m2 <- blmer(math ~ ses*sector + (ses | sch.id), data = hsb, cov.prior
> > = wishart(df = level.dim + 2.5))
> > # point at which blme model is same as lme4
> > m3 <- blmer(math ~ ses*sector + (ses | sch.id), data = hsb, cov.prior
> > = wishart(df = level.dim + 1))
> > # fit models in sequence with df from level.dim + 2.5 to level.dim + 1
> >
> > Technically, any prior which goes to zero when the determinant of the
> > covariance of the random effects go to zero should have the desired
> > effect (df > level.dim + 1), but there may be limitations introduced
> > by the optimizer.
> >
> > Vince
> >
> >
> > On Sat, Oct 3, 2020 at 1:17 AM Simon Harmel <sim.harmel at gmail.com> wrote:
> >>
> >> Hello all,
> >>
> >> This may be a simple/naive question, but I have a non-converging lmer()
> >> model due to singularity.
> >>
> >> I was wondering what is the minimum prior specification in `blmer()` to get
> >> this singular model to converge?
> >>
> >> library(lme4)
> >> library(blme)
> >> hsb <- read.csv('
> >> https://raw.githubusercontent.com/rnorouzian/e/master/hsb.csv')m4 <- m1 <-
> >> lmer(math ~ ses*sector + (ses | sch.id), data = hsb)
> >>
> >> m2 <- blmer(math ~ ses*sector + (ses | sch.id), data = hsb, cov.prior = ???)
> >>
> >>          [[alternative HTML version deleted]]
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From @|m@h@rme| @end|ng |rom gm@||@com  Sun Oct  4 21:34:33 2020
From: @|m@h@rme| @end|ng |rom gm@||@com (Simon Harmel)
Date: Sun, 4 Oct 2020 14:34:33 -0500
Subject: [R-sig-ME] blmer(),
 minimum amount of prior to get a model to converge
In-Reply-To: <CA+++UwSLWJ_LYmanEHr3mvWu=PrcfS+QfPmfy04NsC6oVnzMHA@mail.gmail.com>
References: <CACgv6yX980K9BwUQtxg3cdSGuoN2UnZBVi_FFnehQGKwnbF5yA@mail.gmail.com>
 <CA+++UwQx7TWinkLq9Nh6Sz9qifaa9xCOGoah5ZEiJX7mtu6_UA@mail.gmail.com>
 <4c916671-5a7c-470b-008e-c087b43c6761@gmail.com>
 <CA+++UwSLWJ_LYmanEHr3mvWu=PrcfS+QfPmfy04NsC6oVnzMHA@mail.gmail.com>
Message-ID: <CACgv6yX2GBSzmPTHaYX+6+6Bx3=p_FMMVqHVfvFL4H9YAcE8pw@mail.gmail.com>

Dear Vincent,

Unfortunately, I couldn't improve the singularity problem using the prior
specification solution you suggested (In fact, I played around with
`wishart(df = level.dim + 2.5)` more than your suggested range without
success).

library(lme4)
library(blme)

hsb <- read.csv('
https://raw.githubusercontent.com/rnorouzian/e/master/hsb.csv')
<https://raw.githubusercontent.com/rnorouzian/e/master/hsb.csv')m4>

m1 <- lmer(math ~ ses*sector + (ses | sch.id), data = hsb)

m2 <- blmer(math ~ ses*sector + (ses | sch.id), data = hsb, cov.prior = ???)

On Sun, Oct 4, 2020 at 11:10 AM Vincent Dorie <vdorie at gmail.com> wrote:

> I agree, that that is a meaningful distinction. You can use a prior to
> nudge the estimate away from the boundary of the space, which
> addresses singularity. You can also use a prior to add information to
> the likelihood, which addresses convergence. However, in the latter
> scenario that information would modify your estimate in a subjective
> manner, and it would be impossible to say that it was better than
> simply living with an optimizer warning unless you actually had prior
> information.
>
> On Sat, Oct 3, 2020 at 9:36 PM Ben Bolker <bbolker at gmail.com> wrote:
> >
> >    Thanks Vincent.
> >
> >    FWIW it would make me really happy if people distinguished clearly
> > between
> >
> > * "singular/nonsingular" - an issue with the 'true' best estimate, i.e.
> > whether the MLE for the variance-covariance matrix of the REs is
> > positive definite vs. being only positive *semi*definite
> >
> > * "converged/nonconverged" - a question of whether we think the
> > numerical optimization has worked correctly or not
> >
> >    cheers
> >     Ben Bolker
> >
> >
> > On 10/3/20 9:22 PM, Vincent Dorie wrote:
> > > There's no single minimum amount, but you can decrease the relative
> > > impact of the prior by fitting a sequence of models until convergence
> > > becomes a problem again.
> > >
> > > # default
> > > m2 <- blmer(math ~ ses*sector + (ses | sch.id), data = hsb, cov.prior
> > > = wishart(df = level.dim + 2.5))
> > > # point at which blme model is same as lme4
> > > m3 <- blmer(math ~ ses*sector + (ses | sch.id), data = hsb, cov.prior
> > > = wishart(df = level.dim + 1))
> > > # fit models in sequence with df from level.dim + 2.5 to level.dim + 1
> > >
> > > Technically, any prior which goes to zero when the determinant of the
> > > covariance of the random effects go to zero should have the desired
> > > effect (df > level.dim + 1), but there may be limitations introduced
> > > by the optimizer.
> > >
> > > Vince
> > >
> > >
> > > On Sat, Oct 3, 2020 at 1:17 AM Simon Harmel <sim.harmel at gmail.com>
> wrote:
> > >>
> > >> Hello all,
> > >>
> > >> This may be a simple/naive question, but I have a non-converging
> lmer()
> > >> model due to singularity.
> > >>
> > >> I was wondering what is the minimum prior specification in `blmer()`
> to get
> > >> this singular model to converge?
> > >>
> > >> library(lme4)
> > >> library(blme)
> > >> hsb <- read.csv('
> > >> https://raw.githubusercontent.com/rnorouzian/e/master/hsb.csv')m4 <-
> m1 <-
> > >> lmer(math ~ ses*sector + (ses | sch.id), data = hsb)
> > >>
> > >> m2 <- blmer(math ~ ses*sector + (ses | sch.id), data = hsb,
> cov.prior = ???)
> > >>
> > >>          [[alternative HTML version deleted]]
> > >>
> > >> _______________________________________________
> > >> R-sig-mixed-models at r-project.org mailing list
> > >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > >
> > > _______________________________________________
> > > R-sig-mixed-models at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > >
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Sun Oct  4 22:05:43 2020
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Sun, 4 Oct 2020 16:05:43 -0400
Subject: [R-sig-ME] blmer(),
 minimum amount of prior to get a model to converge
In-Reply-To: <CACgv6yX2GBSzmPTHaYX+6+6Bx3=p_FMMVqHVfvFL4H9YAcE8pw@mail.gmail.com>
References: <CACgv6yX980K9BwUQtxg3cdSGuoN2UnZBVi_FFnehQGKwnbF5yA@mail.gmail.com>
 <CA+++UwQx7TWinkLq9Nh6Sz9qifaa9xCOGoah5ZEiJX7mtu6_UA@mail.gmail.com>
 <4c916671-5a7c-470b-008e-c087b43c6761@gmail.com>
 <CA+++UwSLWJ_LYmanEHr3mvWu=PrcfS+QfPmfy04NsC6oVnzMHA@mail.gmail.com>
 <CACgv6yX2GBSzmPTHaYX+6+6Bx3=p_FMMVqHVfvFL4H9YAcE8pw@mail.gmail.com>
Message-ID: <b45cf24c-3c77-db97-a745-b6e0acdc8d64@gmail.com>

   I got away from singularity for df>=3 (very large values of df, i.e. 
 >20, are giving crazy answers, not sure why -- please disregard ...).
   You could try values between 2 and 3 if you wanted to be very precise 
(in a little bit of playing I got singularity with df=2.9, not with df=3 
...)

   cheers
     Ben Bolker

## fit initial model
m1 <- lmer(math ~ ses*sector + (ses | sch.id), data = hsb)
## explore singularity: not being reported as such on my machine
## because min theta is slightly greater than 1e-4 threshold ...
## but probably singular, in reality
isSingular(m1)
lwr <- getME(m1, "lower")
theta <- getME(m1, "theta")
theta[lwr==0]
## 0.0004824945
dd <- getME(m1,"devfun")
dd(c(theta[1:2],0)) - dd(theta)
## theta=0 is indeed a better fit ...

## fit baseline wishart
m2 <- blmer(math ~ ses*sector + (ses | sch.id), data = hsb,
             cov.prior = wishart(df=2))

## experiment with a variety of df values
wvec <- c(2:20,(3:10)*10)
res <- matrix(NA,nrow=length(wvec),ncol=3)
for (i in seq_along(wvec)) {
     m <- update(m2,cov.prior=wishart(df=wvec[i]))
     res[i,] <- getME(m,"theta")
}
par(las=1,bty="l")
matplot(wvec,res,type="b",pch=1,log="xy",col=c(1,2,4))


On 10/4/20 3:34 PM, Simon Harmel wrote:
> Dear Vincent,
> 
> Unfortunately, I couldn't improve the singularity problem using the prior
> specification solution you suggested (In fact, I played around with
> `wishart(df = level.dim + 2.5)` more than your suggested range without
> success).
> 
> library(lme4)
> library(blme)
> 
> hsb <- read.csv('
> https://raw.githubusercontent.com/rnorouzian/e/master/hsb.csv')
> <https://raw.githubusercontent.com/rnorouzian/e/master/hsb.csv')m4>
> 
> m1 <- lmer(math ~ ses*sector + (ses | sch.id), data = hsb)
> 
> m2 <- blmer(math ~ ses*sector + (ses | sch.id), data = hsb, cov.prior = ???)
> 
> On Sun, Oct 4, 2020 at 11:10 AM Vincent Dorie <vdorie at gmail.com> wrote:
> 
>> I agree, that that is a meaningful distinction. You can use a prior to
>> nudge the estimate away from the boundary of the space, which
>> addresses singularity. You can also use a prior to add information to
>> the likelihood, which addresses convergence. However, in the latter
>> scenario that information would modify your estimate in a subjective
>> manner, and it would be impossible to say that it was better than
>> simply living with an optimizer warning unless you actually had prior
>> information.
>>
>> On Sat, Oct 3, 2020 at 9:36 PM Ben Bolker <bbolker at gmail.com> wrote:
>>>
>>>     Thanks Vincent.
>>>
>>>     FWIW it would make me really happy if people distinguished clearly
>>> between
>>>
>>> * "singular/nonsingular" - an issue with the 'true' best estimate, i.e.
>>> whether the MLE for the variance-covariance matrix of the REs is
>>> positive definite vs. being only positive *semi*definite
>>>
>>> * "converged/nonconverged" - a question of whether we think the
>>> numerical optimization has worked correctly or not
>>>
>>>     cheers
>>>      Ben Bolker
>>>
>>>
>>> On 10/3/20 9:22 PM, Vincent Dorie wrote:
>>>> There's no single minimum amount, but you can decrease the relative
>>>> impact of the prior by fitting a sequence of models until convergence
>>>> becomes a problem again.
>>>>
>>>> # default
>>>> m2 <- blmer(math ~ ses*sector + (ses | sch.id), data = hsb, cov.prior
>>>> = wishart(df = level.dim + 2.5))
>>>> # point at which blme model is same as lme4
>>>> m3 <- blmer(math ~ ses*sector + (ses | sch.id), data = hsb, cov.prior
>>>> = wishart(df = level.dim + 1))
>>>> # fit models in sequence with df from level.dim + 2.5 to level.dim + 1
>>>>
>>>> Technically, any prior which goes to zero when the determinant of the
>>>> covariance of the random effects go to zero should have the desired
>>>> effect (df > level.dim + 1), but there may be limitations introduced
>>>> by the optimizer.
>>>>
>>>> Vince
>>>>
>>>>
>>>> On Sat, Oct 3, 2020 at 1:17 AM Simon Harmel <sim.harmel at gmail.com>
>> wrote:
>>>>>
>>>>> Hello all,
>>>>>
>>>>> This may be a simple/naive question, but I have a non-converging
>> lmer()
>>>>> model due to singularity.
>>>>>
>>>>> I was wondering what is the minimum prior specification in `blmer()`
>> to get
>>>>> this singular model to converge?
>>>>>
>>>>> library(lme4)
>>>>> library(blme)
>>>>> hsb <- read.csv('
>>>>> https://raw.githubusercontent.com/rnorouzian/e/master/hsb.csv')m4 <-
>> m1 <-
>>>>> lmer(math ~ ses*sector + (ses | sch.id), data = hsb)
>>>>>
>>>>> m2 <- blmer(math ~ ses*sector + (ses | sch.id), data = hsb,
>> cov.prior = ???)
>>>>>
>>>>>           [[alternative HTML version deleted]]
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From @|m@h@rme| @end|ng |rom gm@||@com  Wed Oct  7 21:24:58 2020
From: @|m@h@rme| @end|ng |rom gm@||@com (Simon Harmel)
Date: Wed, 7 Oct 2020 14:24:58 -0500
Subject: [R-sig-ME] Why lme4 doesn't throw an error for illegitimate an model
Message-ID: <CACgv6yXTyEk8kp=OvS5WN4zH587VXuGFquBEY4KBi5t02K4vtw@mail.gmail.com>

Dear All,

As far as I understand, in a 2-level model, the use of a level-2 predictor
(here "sector") is illegitimate.

But I wonder why in the following model `lmer` doesn't throw an error to
indicate that?

library(lme4)
hsb <- read.csv('
https://raw.githubusercontent.com/rnorouzian/e/master/hsb.csv')

mn <- lmer(math ~ ses + (sector | sch.id), data = hsb)

	[[alternative HTML version deleted]]


From @|m@h@rme| @end|ng |rom gm@||@com  Wed Oct  7 21:30:58 2020
From: @|m@h@rme| @end|ng |rom gm@||@com (Simon Harmel)
Date: Wed, 7 Oct 2020 14:30:58 -0500
Subject: [R-sig-ME] Why lme4 doesn't throw an error for illegitimate an
 model
In-Reply-To: <CACgv6yXTyEk8kp=OvS5WN4zH587VXuGFquBEY4KBi5t02K4vtw@mail.gmail.com>
References: <CACgv6yXTyEk8kp=OvS5WN4zH587VXuGFquBEY4KBi5t02K4vtw@mail.gmail.com>
Message-ID: <CACgv6yVQkos8ndcffJSea9wkbQd+z6GSC-sp5_Uzgt-3vo=YGA@mail.gmail.com>

correction:

As far as I understand, in a 2-level model, the use of a level-2 predictor
(here "sector") in the ***random part*** is illegitimate.

But I wonder why in the following model `lmer` doesn't throw an error to
indicate that? What does the random part estimates in the output?

library(lme4)
hsb <- read.csv('
https://raw.githubusercontent.com/rnorouzian/e/master/hsb.csv')

mn <- lmer(math ~ ses + (sector | sch.id), data = hsb)



On Wed, Oct 7, 2020 at 2:24 PM Simon Harmel <sim.harmel at gmail.com> wrote:

> Dear All,
>
> As far as I understand, in a 2-level model, the use of a level-2 predictor
> (here "sector") is illegitimate.
>
> But I wonder why in the following model `lmer` doesn't throw an error to
> indicate that?
>
> library(lme4)
> hsb <- read.csv('
> https://raw.githubusercontent.com/rnorouzian/e/master/hsb.csv')
>
> mn <- lmer(math ~ ses + (sector | sch.id), data = hsb)
>

	[[alternative HTML version deleted]]


From ph||||p@@|d@y @end|ng |rom mp|@n|  Wed Oct  7 22:58:10 2020
From: ph||||p@@|d@y @end|ng |rom mp|@n| (Phillip Alday)
Date: Wed, 7 Oct 2020 22:58:10 +0200
Subject: [R-sig-ME] Why lme4 doesn't throw an error for illegitimate an
 model
In-Reply-To: <CACgv6yVQkos8ndcffJSea9wkbQd+z6GSC-sp5_Uzgt-3vo=YGA@mail.gmail.com>
References: <CACgv6yXTyEk8kp=OvS5WN4zH587VXuGFquBEY4KBi5t02K4vtw@mail.gmail.com>
 <CACgv6yVQkos8ndcffJSea9wkbQd+z6GSC-sp5_Uzgt-3vo=YGA@mail.gmail.com>
Message-ID: <9d359e8f-5705-09eb-ea8a-77b0fe8c1218@mpi.nl>

Without knowing the structure of the data, it's hard to answer the
question ... there are ways for me explore and find out what the
nesting/grouping structure is, but that takes time I don't have. So
here's a quick attempt just using general principles.

I think the first trick is to stop thinking of thinking as an ith-level
predictor. For one thing, the levels don't have to be strictly nested.
Personally, I find the i-th level terminology confusing because I can
never remember which direction we're counting from.

Dropping the lm/ler calls for convenience in typing:

math ~ 1 + ses

this estimates a model with a slope for ses and an intercept.

math ~ 1 + ses + (1|sch.id)

this estimates a model with a slope for ses and an intercept and an
offset for each sch.id. (The estimated offsets are technically
"predictions", because the variance of the offsets is what's being
estimated, but we'll leave that be for now.)

An offset to what? Well the population-level/fixed effect corresponding
to the intercept. So you can think of this random effect as providing an
adjustment to the intercept for each sch.id


math ~ 1 + ses + (1+ses|sch.id)

this estimates a model with a slope for ses and an intercept; as well as
per-sch.id adjustments for the intercept and ses.

Note by the way that the model

math ~ 1

is a special case of

math ~ 1 + ses

with the slope of ses set / assumed to be zero.

This will help in the next step.

math ~ 1 + (1+ses|sch.id)

this estimates a model with a slope an intercept; as well as per-sch.id
adjustments for the intercept and ses. But where is ses in the fixed
effects? Well, you can think of it as being zero (see previous point),
so the adjustments will be from the assumed slope of zero, instead of
the estimated slope.

This brings us to

math ~ 1 + ses + (1 + sector | sch.id)

this estimates a model with a slope an intercept; as well as per-sch.id
adjustments for the intercept and sector.

This is mathematically well-defined, even if there is only one value of
sector observed for each sch.id (which is the case when sch.id is nested
within sector), because the shrinkage of the random effects deals with
the rank deficiency. (If you didn't understand that sentence: it's still
possible to estimate these quantities.) In the case that sector doesn't
vary within sch.id, you'll get an estimate that reflects this: either it
will be perfectly correlated with the intercept or shrunk to zero. In
other words, that's one way to get a singular/boundary fit.

Now mathematically well-defined doesn't mean that it makes sense
inferentially. And that's where it's incumbent upon the user to think
about their inferential question, their data, and their phrasing of the
inferential question as a statistical model.

Phillip

On 7/10/20 9:30 pm, Simon Harmel wrote:
> correction:
> 
> As far as I understand, in a 2-level model, the use of a level-2 predictor
> (here "sector") in the ***random part*** is illegitimate.
> 
> But I wonder why in the following model `lmer` doesn't throw an error to
> indicate that? What does the random part estimates in the output?
> 
> library(lme4)
> hsb <- read.csv('
> https://raw.githubusercontent.com/rnorouzian/e/master/hsb.csv')
> 
> mn <- lmer(math ~ ses + (sector | sch.id), data = hsb)
> 
> 
> 
> On Wed, Oct 7, 2020 at 2:24 PM Simon Harmel <sim.harmel at gmail.com> wrote:
> 
>> Dear All,
>>
>> As far as I understand, in a 2-level model, the use of a level-2 predictor
>> (here "sector") is illegitimate.
>>
>> But I wonder why in the following model `lmer` doesn't throw an error to
>> indicate that?
>>
>> library(lme4)
>> hsb <- read.csv('
>> https://raw.githubusercontent.com/rnorouzian/e/master/hsb.csv')
>>
>> mn <- lmer(math ~ ses + (sector | sch.id), data = hsb)
>>
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From @|m@h@rme| @end|ng |rom gm@||@com  Wed Oct  7 23:21:56 2020
From: @|m@h@rme| @end|ng |rom gm@||@com (Simon Harmel)
Date: Wed, 7 Oct 2020 16:21:56 -0500
Subject: [R-sig-ME] Why lme4 doesn't throw an error for illegitimate an
 model
In-Reply-To: <9d359e8f-5705-09eb-ea8a-77b0fe8c1218@mpi.nl>
References: <CACgv6yXTyEk8kp=OvS5WN4zH587VXuGFquBEY4KBi5t02K4vtw@mail.gmail.com>
 <CACgv6yVQkos8ndcffJSea9wkbQd+z6GSC-sp5_Uzgt-3vo=YGA@mail.gmail.com>
 <9d359e8f-5705-09eb-ea8a-77b0fe8c1218@mpi.nl>
Message-ID: <CACgv6yX6sKysA5wTK2Ydeh7TOJmqeH0MpU62hOaowf3T5zvzQw@mail.gmail.com>

Thank you Phillip. The data structure is exactly the way you understood it.
Another nonsensical model without warning would be m2. Where `ses` is a
predictor that varies both within and across `sch.id` (clusters), and
`sector` is a binary variable that only varies across the `sch.id`
(clusters).

The cross-level interaction is set by the software syntax to AGAIN vary
across the levels of a grouping variable. But the model runs without
warning.

hsb <- read.csv('
https://raw.githubusercontent.com/rnorouzian/e/master/hsb.csv')
m2 <- lmer(math ~ ses+sector + (ses:sector | sch.id), data = hsb)

On Wed, Oct 7, 2020 at 3:58 PM Phillip Alday <phillip.alday at mpi.nl> wrote:

> Without knowing the structure of the data, it's hard to answer the
> question ... there are ways for me explore and find out what the
> nesting/grouping structure is, but that takes time I don't have. So
> here's a quick attempt just using general principles.
>
> I think the first trick is to stop thinking of thinking as an ith-level
> predictor. For one thing, the levels don't have to be strictly nested.
> Personally, I find the i-th level terminology confusing because I can
> never remember which direction we're counting from.
>
> Dropping the lm/ler calls for convenience in typing:
>
> math ~ 1 + ses
>
> this estimates a model with a slope for ses and an intercept.
>
> math ~ 1 + ses + (1|sch.id)
>
> this estimates a model with a slope for ses and an intercept and an
> offset for each sch.id. (The estimated offsets are technically
> "predictions", because the variance of the offsets is what's being
> estimated, but we'll leave that be for now.)
>
> An offset to what? Well the population-level/fixed effect corresponding
> to the intercept. So you can think of this random effect as providing an
> adjustment to the intercept for each sch.id
>
>
> math ~ 1 + ses + (1+ses|sch.id)
>
> this estimates a model with a slope for ses and an intercept; as well as
> per-sch.id adjustments for the intercept and ses.
>
> Note by the way that the model
>
> math ~ 1
>
> is a special case of
>
> math ~ 1 + ses
>
> with the slope of ses set / assumed to be zero.
>
> This will help in the next step.
>
> math ~ 1 + (1+ses|sch.id)
>
> this estimates a model with a slope an intercept; as well as per-sch.id
> adjustments for the intercept and ses. But where is ses in the fixed
> effects? Well, you can think of it as being zero (see previous point),
> so the adjustments will be from the assumed slope of zero, instead of
> the estimated slope.
>
> This brings us to
>
> math ~ 1 + ses + (1 + sector | sch.id)
>
> this estimates a model with a slope an intercept; as well as per-sch.id
> adjustments for the intercept and sector.
>
> This is mathematically well-defined, even if there is only one value of
> sector observed for each sch.id (which is the case when sch.id is nested
> within sector), because the shrinkage of the random effects deals with
> the rank deficiency. (If you didn't understand that sentence: it's still
> possible to estimate these quantities.) In the case that sector doesn't
> vary within sch.id, you'll get an estimate that reflects this: either it
> will be perfectly correlated with the intercept or shrunk to zero. In
> other words, that's one way to get a singular/boundary fit.
>
> Now mathematically well-defined doesn't mean that it makes sense
> inferentially. And that's where it's incumbent upon the user to think
> about their inferential question, their data, and their phrasing of the
> inferential question as a statistical model.
>
> Phillip
>
> On 7/10/20 9:30 pm, Simon Harmel wrote:
> > correction:
> >
> > As far as I understand, in a 2-level model, the use of a level-2
> predictor
> > (here "sector") in the ***random part*** is illegitimate.
> >
> > But I wonder why in the following model `lmer` doesn't throw an error to
> > indicate that? What does the random part estimates in the output?
> >
> > library(lme4)
> > hsb <- read.csv('
> > https://raw.githubusercontent.com/rnorouzian/e/master/hsb.csv')
> >
> > mn <- lmer(math ~ ses + (sector | sch.id), data = hsb)
> >
> >
> >
> > On Wed, Oct 7, 2020 at 2:24 PM Simon Harmel <sim.harmel at gmail.com>
> wrote:
> >
> >> Dear All,
> >>
> >> As far as I understand, in a 2-level model, the use of a level-2
> predictor
> >> (here "sector") is illegitimate.
> >>
> >> But I wonder why in the following model `lmer` doesn't throw an error to
> >> indicate that?
> >>
> >> library(lme4)
> >> hsb <- read.csv('
> >> https://raw.githubusercontent.com/rnorouzian/e/master/hsb.csv')
> >>
> >> mn <- lmer(math ~ ses + (sector | sch.id), data = hsb)
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>

	[[alternative HTML version deleted]]


From ph||||p@@|d@y @end|ng |rom mp|@n|  Wed Oct  7 23:39:12 2020
From: ph||||p@@|d@y @end|ng |rom mp|@n| (Phillip Alday)
Date: Wed, 7 Oct 2020 23:39:12 +0200
Subject: [R-sig-ME] 
 Dropping correlations bet. random-effects in lme4 syntax
In-Reply-To: <CACgv6yVu==VJthBenwwffHOHQ+TYmNeEWX84WQJfH2z=dFoGcw@mail.gmail.com>
References: <CACgv6yU4o-cJMagugxQVcobeofsnC2wt6VB0Cn0ofVxdj+7CuA@mail.gmail.com>
 <06a872f4-a00f-ef39-ba88-5c147620039e@mpi.nl>
 <CACgv6yWeKyybJO6vOZM7B+RbxLSr3K75TdTUfoYrsHKXoS=NXQ@mail.gmail.com>
 <45f07ac3-22e0-c901-e8b4-e5748843a0b9@mpi.nl>
 <CACgv6yUajwvMNT08N-0oSXUL+gde1PDDnDCnsU7hiq_rBSKNDw@mail.gmail.com>
 <53573a57-e3ac-7ca0-3258-6163d78f3910@mpi.nl>
 <CACgv6yU9khJv6O0cyGtHOtxGftzc+a3M75vjvQ+j+MA4msdw_Q@mail.gmail.com>
 <CACgv6yVu==VJthBenwwffHOHQ+TYmNeEWX84WQJfH2z=dFoGcw@mail.gmail.com>
Message-ID: <2d38cdae-14cb-9a30-2a0d-87ae9e7cf49c@mpi.nl>

Please keep the list in CC.

I would strongly advise against statistical testing of the correlation
parameters. You can technically do a likelihood ratio test comparing
models fit with | and with ||, because the zero-correlation models are a
special case of the unrestricted-correlation model, but DO NOT DO THIS.
The estimates of the correlation parameters are notoriously unstable: we
typically don't have nearly enough data to estimate them (because you
need both a large number of observations AND a large number of groups).

Moreover, the correlation estimates are intertwined with the estimates
of the variance parameters. The sampling distribution for the variance
parameters often looks a lot like a mixture of a point-mass at zero and
some other, bounded distribution. This results in the sampling
distribution of the correlation parameter also  having a point mass at
?1. We have an example of this in the MixedModels.jl docs
(https://juliastats.org/MixedModels.jl/dev/bootstrap/); there is
probably an lme4 equivalent somewhere on the internet.

For a more practical take on what happens when leave out the correlation
parameters, see e.g. this blog post by John Kruschke

https://doingbayesiandataanalysis.blogspot.com/2019/07/shrinkage-in-hierarchical-models-random.html

or this take on dropping correlations to simplify model structure but
still do good inference by Reinhold Kliegl

https://rpubs.com/Reinhold/22193

Phillip



On 4/10/20 9:33 am, Simon Harmel wrote:
> Hi Phillip,
> 
> I need to ask one follow up question. Suppose I want to test only one
> correlation in `m1`'s random-effects covariance matrix below (pick
> anyone correlation you want) for its statistical significance. I assume
> that I must use?a likelihood ratio test that?compares `m1` with a
> "second model" in which that correlation is absent, right?
> 
> How would you specify that "second model" so you can perform?a
> likelihood ratio test?
> 
> m1 <- lmer(y ~ A * B * C + (A * B * C ?| group), data = data)???
> 
> On Sat, Oct 3, 2020 at 1:54 PM Simon Harmel <sim.harmel at gmail.com
> <mailto:sim.harmel at gmail.com>> wrote:
> 
>     Awesome, thanks!?
> 
>     On Sat, Oct 3, 2020 at 12:40 PM Phillip Alday <phillip.alday at mpi.nl
>     <mailto:phillip.alday at mpi.nl>> wrote:
> 
>         On 03/10/2020 19:24, Simon Harmel wrote:
>>         Thanks for the additional information about the use of `0+` in
>>         the context of categorical variables:)
>>
>>         So, by splitting the specification of the grouping variable like:
>>
>>         lmer(y ~ A * B * C + (A * C | group) + (B|group) , data = data)???
>>
>>         I get the below correlation matrix. So, here we have created 2
>>         different intercepts, one for each "split" of the same
>>         grouping variable, right?
> 
>         Yes, by default R adds in an intercept. I recommend always
>         writing 1+ or 0+ to make explicit what you want.
> 
>         (This was what I meant with "Note that life gets tricky with the
>         interaction terms." in my first reply.)
> 
>>
>>         I ask this because B has no correlation with the first split's
>>         (intercept) but it has a singular correlation with the second
>>         split's (intercept). The output looks confusing to a novice
>>         like me.
>>
>>
>>         ? ? ? ? ? ? (Intercept) ? ? ?A ? ? ?C ? ?A:C (Intercept) ?B
>>         (Intercept) ? ? ? 1.000 -0.794 -0.195 ?0.953 ? ? ? ? ? 0 ?0
>>         A ? ? ? ? ? ? ? ?-0.794 ?1.000 ?0.278 -0.854 ? ? ? ? ? 0 ?0
>>         C ? ? ? ? ? ? ? ?-0.195 ?0.278 ?1.000 ?0.028 ? ? ? ? ? 0 ?0
>>         A:C ? ? ? ? ? ? ? 0.953 -0.854 ?0.028 ?1.000 ? ? ? ? ? 0 ?0
>>         (Intercept) ? ? ? 0.000 ?0.000 ?0.000 ?0.000 ? ? ? ? ? 1 -1
>>         B ? ? ? ? ? ? ? ? 0.000 ?0.000 ?0.000 ?0.000 ? ? ? ? ?-1 ?1
> 
>         Singularity isn't a problem per se -- it's mathematically well
>         defined and being able to fit singular covariance matrices for
>         the random effects was one of the algorithmic innovations lme4
>         has compared to its predecessor nlme.
> 
>         Singularity can be a problem for inference (because it's often a
>         sign of overfitting).... but it makes sense here. B has no
>         correlation with the first intercept because you set it to be
>         zero via your formula specification, so that term is forced to
>         be zero in the model computation. The second intercept is
>         perfectly correlated with B because it (the second intercept) is
>         redundant in the model, but it can't correlate with the first
>         intercept (because that correlation is forced to zero by your
>         model specification) and so it collapses into B.
> 
>         If B is continuous, you can avoid this with 0+B. If B is
>         categorical, then 0+B will still be overparameterized, but you
>         can try 0+dummy(B) to set up indicator variable for one of the
>         two levels. (I can tell from your output that B is continuous or
>         only has two levels because there is only one slope for it.)
> 
>         Phillip
> 
>>
>>         On Sat, Oct 3, 2020 at 11:52 AM Phillip Alday
>>         <phillip.alday at mpi.nl <mailto:phillip.alday at mpi.nl>> wrote:
>>
>>             I have no idea what 0* means, but 0+ means "suppress the
>>             intercept" (which has knock-on effects for categorical
>>             variables and whether they're represented in the model as
>>             (nlevels-1) contrasts or nlevels).
>>
>>             For the other things: try it out. The output of
>>             summary(m1) will show you which levels and correlations
>>             were kept.
>>
>>             On 03/10/2020 18:44, Simon Harmel wrote:
>>>             Thanks Phillip. What would be the meaning of placing `0
>>>             +` next to any of the random effects (e.g., B) as shown
>>>             in m2?
>>>
>>>             m1 <- lmer(y ~ A * B * C + (A * C | group) + (B|group) ,
>>>             data = data)??
>>>
>>>             m2 <- lmer(y ~ A * B * C + (A * 0+ B * C ?| group), data
>>>             = data)??
>>>
>>>             On Sat, Oct 3, 2020 at 11:33 AM Phillip Alday
>>>             <phillip.alday at mpi.nl <mailto:phillip.alday at mpi.nl>> wrote:
>>>
>>>                 You can split the specification of your grouping to
>>>                 achieve this, at
>>>                 least in part:
>>>
>>>                 lmer(y ~ A * B * C + (A * C | group) + (B|group) ,
>>>                 data = data)
>>>
>>>                 Note that life gets tricky with the interaction terms.
>>>
>>>                 Phillip
>>>
>>>                 On 03/10/2020 06:35, Simon Harmel wrote:
>>>                 > Hello all,
>>>                 >
>>>                 > I know to drop all correlations among all level-1
>>>                 predictors in the random
>>>                 > part of an lmer() call, I can use `||`. But I was
>>>                 wondering how to drop
>>>                 > correlations (a) "individually" or (b) "in pairs"?
>>>                 >
>>>                 > Example of (a) is how to drop the correlation of B
>>>                 with others (A & C)?
>>>                 > Example of (b) is how to drop the correlation
>>>                 between B and C?
>>>                 >
>>>                 > lmer(y ~ A * B * C + (A * B * C? || group), data =
>>>                 data)
>>>                 >
>>>                 > Thanks,
>>>                 > Simon
>>>                 >
>>>                 >? ? ? ?[[alternative HTML version deleted]]
>>>                 >
>>>                 > _______________________________________________
>>>                 > R-sig-mixed-models at r-project.org
>>>                 <mailto:R-sig-mixed-models at r-project.org> mailing list
>>>                 >
>>>                 https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>


From ph||||p@@|d@y @end|ng |rom mp|@n|  Wed Oct  7 23:56:56 2020
From: ph||||p@@|d@y @end|ng |rom mp|@n| (Phillip Alday)
Date: Wed, 7 Oct 2020 23:56:56 +0200
Subject: [R-sig-ME] 
 Drop the correlation bet. random effects to find those
 with small variance
In-Reply-To: <CACgv6yV-miMOoDWshwnvJxxY5e-+YXaB5NBRkT43eQzVb0zYXw@mail.gmail.com>
References: <CACgv6yV-miMOoDWshwnvJxxY5e-+YXaB5NBRkT43eQzVb0zYXw@mail.gmail.com>
Message-ID: <781c4d43-7ecb-a701-8de8-84c33b01193d@mpi.nl>

I think this has been answered implicitly in some of the answers to your
other questions, but the bottom line is

The issue is the number of parameters compared to the amount of data /
information in that data. By setting the correlations to zero, you're
greatly reducing the number of parameters you have to estimate, which
leaves more information left over for estimating the other parameters.
This does impact shrinkage, but the resulting model fits are still
typically more stable (less variance across fits) than an
overparameterized model (less bias because you're not forcing any
parameter to a particular value).

In other words, it's an example of the bias-variance tradeoff. In other
words: it's often better to reduce model complexity, even at the cost of
real-world fidelity, in order to avoid overfitting.

Phillip

On 30/9/20 9:57 pm, Simon Harmel wrote:
> Dear All,
> 
> Bates, et al. (2015) <https://arxiv.org/pdf/1506.04967.pdf> mention that to
> identify a mixed-model with a singular variance-covariance matrix we can:
> 
> Fit a zero correlation parameter which will identify random effects with
> zero, or very small, variance
> 
> That is, going from `m0` to `m1` (see below). BUT, how come dropping all
> correlations between slopes and intercepts can lead to identifying random
> effects with zero, or very small, variance?
> 
> library(lme4)
> 
> dat <- read.csv('
> https://raw.githubusercontent.com/WRobertLong/Stackexchange/master/data/singular.csv
> ')
> 
> m0 <- lmer(y ~ A * B * C + (A * B * C  | group), data = dat)
> m1 <- lmer(y ~ A * B * C + (A * B * C || group), data = dat)
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From @|m@h@rme| @end|ng |rom gm@||@com  Wed Oct  7 23:59:27 2020
From: @|m@h@rme| @end|ng |rom gm@||@com (Simon Harmel)
Date: Wed, 7 Oct 2020 16:59:27 -0500
Subject: [R-sig-ME] Why lme4 doesn't throw an error for illegitimate an
 model
In-Reply-To: <CACgv6yX6sKysA5wTK2Ydeh7TOJmqeH0MpU62hOaowf3T5zvzQw@mail.gmail.com>
References: <CACgv6yXTyEk8kp=OvS5WN4zH587VXuGFquBEY4KBi5t02K4vtw@mail.gmail.com>
 <CACgv6yVQkos8ndcffJSea9wkbQd+z6GSC-sp5_Uzgt-3vo=YGA@mail.gmail.com>
 <9d359e8f-5705-09eb-ea8a-77b0fe8c1218@mpi.nl>
 <CACgv6yX6sKysA5wTK2Ydeh7TOJmqeH0MpU62hOaowf3T5zvzQw@mail.gmail.com>
Message-ID: <CACgv6yVUhPy5G85H4omBkoQO-udvN5R7Er+WsHc=K_zg+nAcGA@mail.gmail.com>

Also Phillip, what does `sector` in the output of `VarCorr(mn)` below
denote, now that you say this model is mathematically defined?

mn <- lmer(math ~ ses +  (sector | sch.id), data = hsb)

> VarCorr(mn)
 Groups   Name        Std.Dev. Corr
 sch.id   (Intercept) 2.0256
          sector      1.3717   -0.071
 Residual             6.0858

On Wed, Oct 7, 2020 at 4:21 PM Simon Harmel <sim.harmel at gmail.com> wrote:

> Thank you Phillip. The data structure is exactly the way you understood
> it. Another nonsensical model without warning would be m2. Where `ses` is a
> predictor that varies both within and across `sch.id` (clusters), and
> `sector` is a binary variable that only varies across the `sch.id`
> (clusters).
>
> The cross-level interaction is set by the software syntax to AGAIN vary
> across the levels of a grouping variable. But the model runs without
> warning.
>
> hsb <- read.csv('
> https://raw.githubusercontent.com/rnorouzian/e/master/hsb.csv')
> m2 <- lmer(math ~ ses+sector + (ses:sector | sch.id), data = hsb)
>
> On Wed, Oct 7, 2020 at 3:58 PM Phillip Alday <phillip.alday at mpi.nl> wrote:
>
>> Without knowing the structure of the data, it's hard to answer the
>> question ... there are ways for me explore and find out what the
>> nesting/grouping structure is, but that takes time I don't have. So
>> here's a quick attempt just using general principles.
>>
>> I think the first trick is to stop thinking of thinking as an ith-level
>> predictor. For one thing, the levels don't have to be strictly nested.
>> Personally, I find the i-th level terminology confusing because I can
>> never remember which direction we're counting from.
>>
>> Dropping the lm/ler calls for convenience in typing:
>>
>> math ~ 1 + ses
>>
>> this estimates a model with a slope for ses and an intercept.
>>
>> math ~ 1 + ses + (1|sch.id)
>>
>> this estimates a model with a slope for ses and an intercept and an
>> offset for each sch.id. (The estimated offsets are technically
>> "predictions", because the variance of the offsets is what's being
>> estimated, but we'll leave that be for now.)
>>
>> An offset to what? Well the population-level/fixed effect corresponding
>> to the intercept. So you can think of this random effect as providing an
>> adjustment to the intercept for each sch.id
>>
>>
>> math ~ 1 + ses + (1+ses|sch.id)
>>
>> this estimates a model with a slope for ses and an intercept; as well as
>> per-sch.id adjustments for the intercept and ses.
>>
>> Note by the way that the model
>>
>> math ~ 1
>>
>> is a special case of
>>
>> math ~ 1 + ses
>>
>> with the slope of ses set / assumed to be zero.
>>
>> This will help in the next step.
>>
>> math ~ 1 + (1+ses|sch.id)
>>
>> this estimates a model with a slope an intercept; as well as per-sch.id
>> adjustments for the intercept and ses. But where is ses in the fixed
>> effects? Well, you can think of it as being zero (see previous point),
>> so the adjustments will be from the assumed slope of zero, instead of
>> the estimated slope.
>>
>> This brings us to
>>
>> math ~ 1 + ses + (1 + sector | sch.id)
>>
>> this estimates a model with a slope an intercept; as well as per-sch.id
>> adjustments for the intercept and sector.
>>
>> This is mathematically well-defined, even if there is only one value of
>> sector observed for each sch.id (which is the case when sch.id is nested
>> within sector), because the shrinkage of the random effects deals with
>> the rank deficiency. (If you didn't understand that sentence: it's still
>> possible to estimate these quantities.) In the case that sector doesn't
>> vary within sch.id, you'll get an estimate that reflects this: either it
>> will be perfectly correlated with the intercept or shrunk to zero. In
>> other words, that's one way to get a singular/boundary fit.
>>
>> Now mathematically well-defined doesn't mean that it makes sense
>> inferentially. And that's where it's incumbent upon the user to think
>> about their inferential question, their data, and their phrasing of the
>> inferential question as a statistical model.
>>
>> Phillip
>>
>> On 7/10/20 9:30 pm, Simon Harmel wrote:
>> > correction:
>> >
>> > As far as I understand, in a 2-level model, the use of a level-2
>> predictor
>> > (here "sector") in the ***random part*** is illegitimate.
>> >
>> > But I wonder why in the following model `lmer` doesn't throw an error to
>> > indicate that? What does the random part estimates in the output?
>> >
>> > library(lme4)
>> > hsb <- read.csv('
>> > https://raw.githubusercontent.com/rnorouzian/e/master/hsb.csv')
>> >
>> > mn <- lmer(math ~ ses + (sector | sch.id), data = hsb)
>> >
>> >
>> >
>> > On Wed, Oct 7, 2020 at 2:24 PM Simon Harmel <sim.harmel at gmail.com>
>> wrote:
>> >
>> >> Dear All,
>> >>
>> >> As far as I understand, in a 2-level model, the use of a level-2
>> predictor
>> >> (here "sector") is illegitimate.
>> >>
>> >> But I wonder why in the following model `lmer` doesn't throw an error
>> to
>> >> indicate that?
>> >>
>> >> library(lme4)
>> >> hsb <- read.csv('
>> >> https://raw.githubusercontent.com/rnorouzian/e/master/hsb.csv')
>> >>
>> >> mn <- lmer(math ~ ses + (sector | sch.id), data = hsb)
>> >>
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> > _______________________________________________
>> > R-sig-mixed-models at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >
>>
>

	[[alternative HTML version deleted]]


From ph||||p@@|d@y @end|ng |rom mp|@n|  Thu Oct  8 01:29:30 2020
From: ph||||p@@|d@y @end|ng |rom mp|@n| (Phillip Alday)
Date: Thu, 8 Oct 2020 01:29:30 +0200
Subject: [R-sig-ME] Why lme4 doesn't throw an error for illegitimate an
 model
In-Reply-To: <CACgv6yVUhPy5G85H4omBkoQO-udvN5R7Er+WsHc=K_zg+nAcGA@mail.gmail.com>
References: <CACgv6yXTyEk8kp=OvS5WN4zH587VXuGFquBEY4KBi5t02K4vtw@mail.gmail.com>
 <CACgv6yVQkos8ndcffJSea9wkbQd+z6GSC-sp5_Uzgt-3vo=YGA@mail.gmail.com>
 <9d359e8f-5705-09eb-ea8a-77b0fe8c1218@mpi.nl>
 <CACgv6yX6sKysA5wTK2Ydeh7TOJmqeH0MpU62hOaowf3T5zvzQw@mail.gmail.com>
 <CACgv6yVUhPy5G85H4omBkoQO-udvN5R7Er+WsHc=K_zg+nAcGA@mail.gmail.com>
Message-ID: <b510ed6b-2e9c-86f5-0c23-b9a647b6411c@mpi.nl>

Potentially something that is uninteresting or nonsensical or not
physically real ... the math for a Klein bottle is well defined, but I
doubt you'll find one in the three spatial dimensions we experience. ;)


Here it is actually capturing some aspects of the different sectors:

> summary(coef(lmer(math ~ (sector | sch.id), data =
hsb))$sch.id[,"sector"])
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
-2.0087 -0.1117  0.4981  0.4908  1.0710  2.8777

> summary(lmer(math ~ sector + (1|sch.id), data=hsb))
Linear mixed model fit by REML ['lmerMod']
Formula: math ~ sector + (1 | sch.id)
   Data: hsb

REML criterion at convergence: 47080.1

Scaled residuals:
    Min      1Q  Median      3Q     Max
-3.0130 -0.7523  0.0253  0.7602  2.7472

Random effects:
 Groups   Name        Variance Std.Dev.
 sch.id   (Intercept)  6.677   2.584
 Residual             39.151   6.257
Number of obs: 7185, groups:  sch.id, 160

Fixed effects:
            Estimate Std. Error t value
(Intercept)  11.3930     0.2928  38.907
sector        2.8049     0.4391   6.388


Basically, it's the (shrunken) sector by-school adjustment
from-the-zeroed-out-fixed/population-effect . Since you've omitted
sector from the fixed effects, then the adjustments correspond to
(shrunken) estimates (well, predictions, see previous fine print) of
what the total population + sch.id-level effect would be.  Because the
sch.id-level effect is in reality ideally/approximately(*) zero, these
work out to be approximations to the population level effects.

(*) "ideally/approximately" because the variability between schools may
differ between sectors. In other words, the public schools may have
adjustments distributed as N(public_mean, public_sd) and the private
schools may have adjustments distributed as N(private_mean, private_sd),
where the two SDs aren't equal. The means are handled by the fixed
effects, the SDs by the random effects. This is what you get from this
model:

> summary(lmer(math ~ sector + (1+sector|sch.id), data=hsb))
Linear mixed model fit by REML ['lmerMod']
Formula: math ~ sector + (1 + sector | sch.id)
   Data: hsb

REML criterion at convergence: 47080.1

Scaled residuals:
     Min       1Q   Median       3Q      Max
-3.01392 -0.75219  0.02518  0.76045  2.74806

Random effects:
 Groups   Name        Variance Std.Dev. Corr
 sch.id   (Intercept)  6.7346  2.5951
          sector       0.5322  0.7295   -0.17
 Residual             39.1513  6.2571
Number of obs: 7185, groups:  sch.id, 160

Fixed effects:
            Estimate Std. Error t value
(Intercept)  11.3930     0.2939  38.762
sector        2.8048     0.4387   6.394

> summary(coef(lmer(math ~ sector + (sector | sch.id), data =
hsb))$sch.id[,"sector"])
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
  2.531   2.741   2.806   2.805   2.860   3.104

I'll end with a question which I won't answer but it will help you to
think about why fitting these models might be useful: how is this
related to heteroskedacity?

Phillip

On 7/10/20 11:59 pm, Simon Harmel wrote:
> Also Phillip, what does `sector` in the output of `VarCorr(mn)` below
> denote, now that you say this model is mathematically?defined?
> 
> mn <- lmer(math ~ ses + ?(sector | sch.id), data = hsb)
> 
>> VarCorr(mn)
> ?Groups ? Name ? ? ? ?Std.Dev. Corr ?
> ?sch.id <http://sch.id> ? (Intercept) 2.0256 ? ? ? ?
> ? ? ? ? ? sector ? ? ?1.3717 ? -0.071
> ?Residual ? ? ? ? ? ? 6.0858?
>


From @|m@h@rme| @end|ng |rom gm@||@com  Thu Oct  8 03:21:46 2020
From: @|m@h@rme| @end|ng |rom gm@||@com (Simon Harmel)
Date: Wed, 7 Oct 2020 20:21:46 -0500
Subject: [R-sig-ME] Why lme4 doesn't throw an error for illegitimate an
 model
In-Reply-To: <b510ed6b-2e9c-86f5-0c23-b9a647b6411c@mpi.nl>
References: <CACgv6yXTyEk8kp=OvS5WN4zH587VXuGFquBEY4KBi5t02K4vtw@mail.gmail.com>
 <CACgv6yVQkos8ndcffJSea9wkbQd+z6GSC-sp5_Uzgt-3vo=YGA@mail.gmail.com>
 <9d359e8f-5705-09eb-ea8a-77b0fe8c1218@mpi.nl>
 <CACgv6yX6sKysA5wTK2Ydeh7TOJmqeH0MpU62hOaowf3T5zvzQw@mail.gmail.com>
 <CACgv6yVUhPy5G85H4omBkoQO-udvN5R7Er+WsHc=K_zg+nAcGA@mail.gmail.com>
 <b510ed6b-2e9c-86f5-0c23-b9a647b6411c@mpi.nl>
Message-ID: <CACgv6yWytABfhrYG167awTUGSo45HqAtFJKGmK_=XiZvn0zMhA@mail.gmail.com>

Very interesting Phillip! I'll think about your final question! But, in
your terminology, what is the relationship between "adjustments", "random
effects", and "shrinkage" (of cluster estimates towards the total cluster
mean)?

On the other hand, let's now use an individual-level predictor (i.e.,
"ses": varies within & across clusters) in the random part of the model
WHILE excluding that predictor from the fixed part.

what does `ses` in the output of `VarCorr(m43)` below represent?

hsb <- read.csv('
https://raw.githubusercontent.com/rnorouzian/e/master/hsb.csv')

m43 <- lmer(math ~ female*minority + (ses | sch.id), data = hsb)
> VarCorr(m43)
 Groups   Name        Std.Dev. Corr
 sch.id   (Intercept) 2.1961
          ses         2.0963   -0.285
 Residual             5.9732

On Wed, Oct 7, 2020 at 6:29 PM Phillip Alday <phillip.alday at mpi.nl> wrote:

> Potentially something that is uninteresting or nonsensical or not
> physically real ... the math for a Klein bottle is well defined, but I
> doubt you'll find one in the three spatial dimensions we experience. ;)
>
>
> Here it is actually capturing some aspects of the different sectors:
>
> > summary(coef(lmer(math ~ (sector | sch.id), data =
> hsb))$sch.id[,"sector"])
>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
> -2.0087 -0.1117  0.4981  0.4908  1.0710  2.8777
>
> > summary(lmer(math ~ sector + (1|sch.id), data=hsb))
> Linear mixed model fit by REML ['lmerMod']
> Formula: math ~ sector + (1 | sch.id)
>    Data: hsb
>
> REML criterion at convergence: 47080.1
>
> Scaled residuals:
>     Min      1Q  Median      3Q     Max
> -3.0130 -0.7523  0.0253  0.7602  2.7472
>
> Random effects:
>  Groups   Name        Variance Std.Dev.
>  sch.id   (Intercept)  6.677   2.584
>  Residual             39.151   6.257
> Number of obs: 7185, groups:  sch.id, 160
>
> Fixed effects:
>             Estimate Std. Error t value
> (Intercept)  11.3930     0.2928  38.907
> sector        2.8049     0.4391   6.388
>
>
> Basically, it's the (shrunken) sector by-school adjustment
> from-the-zeroed-out-fixed/population-effect . Since you've omitted
> sector from the fixed effects, then the adjustments correspond to
> (shrunken) estimates (well, predictions, see previous fine print) of
> what the total population + sch.id-level effect would be.  Because the
> sch.id-level effect is in reality ideally/approximately(*) zero, these
> work out to be approximations to the population level effects.
>
> (*) "ideally/approximately" because the variability between schools may
> differ between sectors. In other words, the public schools may have
> adjustments distributed as N(public_mean, public_sd) and the private
> schools may have adjustments distributed as N(private_mean, private_sd),
> where the two SDs aren't equal. The means are handled by the fixed
> effects, the SDs by the random effects. This is what you get from this
> model:
>
> > summary(lmer(math ~ sector + (1+sector|sch.id), data=hsb))
> Linear mixed model fit by REML ['lmerMod']
> Formula: math ~ sector + (1 + sector | sch.id)
>    Data: hsb
>
> REML criterion at convergence: 47080.1
>
> Scaled residuals:
>      Min       1Q   Median       3Q      Max
> -3.01392 -0.75219  0.02518  0.76045  2.74806
>
> Random effects:
>  Groups   Name        Variance Std.Dev. Corr
>  sch.id   (Intercept)  6.7346  2.5951
>           sector       0.5322  0.7295   -0.17
>  Residual             39.1513  6.2571
> Number of obs: 7185, groups:  sch.id, 160
>
> Fixed effects:
>             Estimate Std. Error t value
> (Intercept)  11.3930     0.2939  38.762
> sector        2.8048     0.4387   6.394
>
> > summary(coef(lmer(math ~ sector + (sector | sch.id), data =
> hsb))$sch.id[,"sector"])
>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
>   2.531   2.741   2.806   2.805   2.860   3.104
>
> I'll end with a question which I won't answer but it will help you to
> think about why fitting these models might be useful: how is this
> related to heteroskedacity?
>
> Phillip
>
> On 7/10/20 11:59 pm, Simon Harmel wrote:
> > Also Phillip, what does `sector` in the output of `VarCorr(mn)` below
> > denote, now that you say this model is mathematically defined?
> >
> > mn <- lmer(math ~ ses +  (sector | sch.id), data = hsb)
> >
> >> VarCorr(mn)
> >  Groups   Name        Std.Dev. Corr
> >  sch.id <http://sch.id>   (Intercept) 2.0256
> >           sector      1.3717   -0.071
> >  Residual             6.0858
> >
>

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Thu Oct  8 03:33:25 2020
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Wed, 7 Oct 2020 21:33:25 -0400
Subject: [R-sig-ME] Why lme4 doesn't throw an error for illegitimate an
 model
In-Reply-To: <b510ed6b-2e9c-86f5-0c23-b9a647b6411c@mpi.nl>
References: <CACgv6yXTyEk8kp=OvS5WN4zH587VXuGFquBEY4KBi5t02K4vtw@mail.gmail.com>
 <CACgv6yVQkos8ndcffJSea9wkbQd+z6GSC-sp5_Uzgt-3vo=YGA@mail.gmail.com>
 <9d359e8f-5705-09eb-ea8a-77b0fe8c1218@mpi.nl>
 <CACgv6yX6sKysA5wTK2Ydeh7TOJmqeH0MpU62hOaowf3T5zvzQw@mail.gmail.com>
 <CACgv6yVUhPy5G85H4omBkoQO-udvN5R7Er+WsHc=K_zg+nAcGA@mail.gmail.com>
 <b510ed6b-2e9c-86f5-0c23-b9a647b6411c@mpi.nl>
Message-ID: <09de6798-baf1-5398-979e-f9364de27bc8@gmail.com>

   Some more comments.

* I continue to think that you're mildly abusing the system by 
cross-posting very closely related questions on CrossValidated and here 
(e.g. 
https://stats.stackexchange.com/questions/+/visualizing-the-folly-of-fitting-random-slopes-for-variables-that-dont-vary-wit)

* although the results would be identical if sector were a categorical 
rather than a numeric variable, the fact that it's a 0/1 variable makes 
it clearer what's actually happening (and that the result may not be 
what you want but is not "nonsensical".

   Take the example (sector|sch.id).  The model matrix for the random 
effects (Z) is formed by taking the _Khatri-Rao product_ of the model 
matrix of the terms (~1+sector) with the indicator matrix for the 
grouping variable.  What this means in practice is that if

   b_(0,j(i)) is the random intercept term for the school (j) associated 
with the i^th observation
   b_(1,j(i)) is the random slope term for school j(i)
and
   sector(j(i)) is the sector associated with school j(i)

  this means that the random effect term for the i^th observation will be

   b_(0,j(i)) + b_(1,j(i))*sector(j(i))

which means that for sector==0 this will be

   b_(0,j(i))

and for sector==1 this will be

   b_(0,j(i)) + b_(1,j(i))

this will therefore translate to modeling a higher variance (or at 
least, not lower) among schools with sector==1.

   So in my opinion this does make sense, even if it's not what you had 
in mind.

   * more generally, I _do_ think it would be good to have a system that 
kept track where appropriate of 'levels' (recognizing that they're not 
always appropriate); however, in the absence of that kind of metadata, 
it's very hard to detect simply from the structure of the model whether 
a model is 'misspecified'.

   * this is one reason that Richard McElreath promotes building models 
more 'from scratch' in his _Rethinking Statistics_ book; if you have to 
build the model components more explicitly yourself it's a nuisance, but 
it reduces the chance that you'll get confused by the meaning of a model 
specification.

On 10/7/20 7:29 PM, Phillip Alday wrote:
> Potentially something that is uninteresting or nonsensical or not
> physically real ... the math for a Klein bottle is well defined, but I
> doubt you'll find one in the three spatial dimensions we experience. ;)
> 
> 
> Here it is actually capturing some aspects of the different sectors:
> 
>> summary(coef(lmer(math ~ (sector | sch.id), data =
> hsb))$sch.id[,"sector"])
>     Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
> -2.0087 -0.1117  0.4981  0.4908  1.0710  2.8777
> 
>> summary(lmer(math ~ sector + (1|sch.id), data=hsb))
> Linear mixed model fit by REML ['lmerMod']
> Formula: math ~ sector + (1 | sch.id)
>     Data: hsb
> 
> REML criterion at convergence: 47080.1
> 
> Scaled residuals:
>      Min      1Q  Median      3Q     Max
> -3.0130 -0.7523  0.0253  0.7602  2.7472
> 
> Random effects:
>   Groups   Name        Variance Std.Dev.
>   sch.id   (Intercept)  6.677   2.584
>   Residual             39.151   6.257
> Number of obs: 7185, groups:  sch.id, 160
> 
> Fixed effects:
>              Estimate Std. Error t value
> (Intercept)  11.3930     0.2928  38.907
> sector        2.8049     0.4391   6.388
> 
> 
> Basically, it's the (shrunken) sector by-school adjustment
> from-the-zeroed-out-fixed/population-effect . Since you've omitted
> sector from the fixed effects, then the adjustments correspond to
> (shrunken) estimates (well, predictions, see previous fine print) of
> what the total population + sch.id-level effect would be.  Because the
> sch.id-level effect is in reality ideally/approximately(*) zero, these
> work out to be approximations to the population level effects.
> 
> (*) "ideally/approximately" because the variability between schools may
> differ between sectors. In other words, the public schools may have
> adjustments distributed as N(public_mean, public_sd) and the private
> schools may have adjustments distributed as N(private_mean, private_sd),
> where the two SDs aren't equal. The means are handled by the fixed
> effects, the SDs by the random effects. This is what you get from this
> model:
> 
>> summary(lmer(math ~ sector + (1+sector|sch.id), data=hsb))
> Linear mixed model fit by REML ['lmerMod']
> Formula: math ~ sector + (1 + sector | sch.id)
>     Data: hsb
> 
> REML criterion at convergence: 47080.1
> 
> Scaled residuals:
>       Min       1Q   Median       3Q      Max
> -3.01392 -0.75219  0.02518  0.76045  2.74806
> 
> Random effects:
>   Groups   Name        Variance Std.Dev. Corr
>   sch.id   (Intercept)  6.7346  2.5951
>            sector       0.5322  0.7295   -0.17
>   Residual             39.1513  6.2571
> Number of obs: 7185, groups:  sch.id, 160
> 
> Fixed effects:
>              Estimate Std. Error t value
> (Intercept)  11.3930     0.2939  38.762
> sector        2.8048     0.4387   6.394
> 
>> summary(coef(lmer(math ~ sector + (sector | sch.id), data =
> hsb))$sch.id[,"sector"])
>     Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
>    2.531   2.741   2.806   2.805   2.860   3.104
> 
> I'll end with a question which I won't answer but it will help you to
> think about why fitting these models might be useful: how is this
> related to heteroskedacity?
> 
> Phillip
> 
> On 7/10/20 11:59 pm, Simon Harmel wrote:
>> Also Phillip, what does `sector` in the output of `VarCorr(mn)` below
>> denote, now that you say this model is mathematically?defined?
>>
>> mn <- lmer(math ~ ses + ?(sector | sch.id), data = hsb)
>>
>>> VarCorr(mn)
>>  ?Groups ? Name ? ? ? ?Std.Dev. Corr
>>  ?sch.id <http://sch.id> ? (Intercept) 2.0256
>>  ? ? ? ? ? sector ? ? ?1.3717 ? -0.071
>>  ?Residual ? ? ? ? ? ? 6.0858
>>
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From @uzyr@brun @end|ng |rom gm@||@com  Thu Oct  8 13:22:54 2020
From: @uzyr@brun @end|ng |rom gm@||@com (SuzyR Brun)
Date: Thu, 8 Oct 2020 12:22:54 +0100
Subject: [R-sig-ME] Can DHARMa be used with natural splines in the glmer
 formula?
Message-ID: <CAHZRtqsAMW5Zh2_4yAzCN_NsnJZu4quaLs3XvdpOGhghk4SpQg@mail.gmail.com>

Dear all,

I haven?t found a way to simulate the residuals via
DHARMa::simulateResiduals in a fitted model when applying a natural spline
transformation (library splines) to a fixed term, say:
model <- glmer(alive ~ A + B + log(C) + ns(D,df=4) +... + (1 | id), data =
mydata, family = binomial(link = 'logit')...

All works fine, without warnings and renders quite reasonable coefficients.

Then I apply the DHARMa function to inspect the residuals: simulationOutput
<- simulateResiduals(fittedModel = model, n = 5000, use.u = T), but it
returns the next message:
Error in ns(D, knots = c(`50%` = 80.53), Boundary.knots = c(0, 149 :
 object 'D' not found

For me (inexperienced in GLMMs and R) it is like the function can't
recognize the internal structure of the framemodel at frame[["ns(D, df =
5)"]], and the matrix generated by the knots.

I'm sorry that I can't send a workable example but these are confidential
data and to me it doesn't seem necessary here. It behaves in the same way
whatever the (continuous) factor I introduce as ns.

Interestingly, the "sjPlot" works fine helping to the interpreation of the
ns(D): plot_model(model, type = "eff", terms = c("D[all]")) and also does
the package "performance".

Is there any workaround that I have missed? I have done a quite intensive
search but haven't found anything.

Thanks a lot for your time, and please forgive me if all this is nonsense.

Kind regards

PD: I am using DHARMa version (0.3.3.0), lme4 (1.1 - 23), splines (4.02),
in RStudio (1.3.1093) with R-4.0.2[64-bit]

	[[alternative HTML version deleted]]


From bz117 @end|ng |rom georgetown@edu  Thu Oct  8 18:10:03 2020
From: bz117 @end|ng |rom georgetown@edu (Bingsong Zhang)
Date: Thu, 8 Oct 2020 12:10:03 -0400
Subject: [R-sig-ME] glmmTMB questions
Message-ID: <CAJMQhGs2XVrNSb4RX=pmhzj7O+w94oKEeAUFR7eA3SngGwP8YA@mail.gmail.com>

Hi all,

Did anyone try using glmmTMB to fit the logistic model?

I run the following code as mentioned in the manual page 16, but get error
messages.

> data(cbpp, package="lme4")
> bovine <- glmmTMB(cbind(incidence, size-incidence) ~ period + (1|herd),
family=binomial, data=cbpp)
Error in .Call("FreeADFunObject", ptr, PACKAGE = DLL) :
  "FreeADFunObject" not available for .Call() for package "glmmTMB"
Error in .Call("FreeADFunObject", ptr, PACKAGE = DLL) :
  "FreeADFunObject" not available for .Call() for package "glmmTMB"

Does it mean the package is not ready for binomial data yet?

Best,
Bingsong

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Thu Oct  8 18:18:03 2020
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Thu, 8 Oct 2020 12:18:03 -0400
Subject: [R-sig-ME] glmmTMB questions
In-Reply-To: <CAJMQhGs2XVrNSb4RX=pmhzj7O+w94oKEeAUFR7eA3SngGwP8YA@mail.gmail.com>
References: <CAJMQhGs2XVrNSb4RX=pmhzj7O+w94oKEeAUFR7eA3SngGwP8YA@mail.gmail.com>
Message-ID: <d40b2e33-bc1b-0c30-92f3-1b0d17e1d6dc@gmail.com>

   Please re-install glmmTMB from source after installing TMB, if possible:

https://github.com/glmmTMB/glmmTMB/issues/615

   This problem should go away once a new version of glmmTMB is on CRAN 
(until the next release of TMB after that ...)

On 10/8/20 12:10 PM, Bingsong Zhang wrote:
> Hi all,
> 
> Did anyone try using glmmTMB to fit the logistic model?
> 
> I run the following code as mentioned in the manual page 16, but get error
> messages.
> 
>> data(cbpp, package="lme4")
>> bovine <- glmmTMB(cbind(incidence, size-incidence) ~ period + (1|herd),
> family=binomial, data=cbpp)
> Error in .Call("FreeADFunObject", ptr, PACKAGE = DLL) :
>    "FreeADFunObject" not available for .Call() for package "glmmTMB"
> Error in .Call("FreeADFunObject", ptr, PACKAGE = DLL) :
>    "FreeADFunObject" not available for .Call() for package "glmmTMB"
> 
> Does it mean the package is not ready for binomial data yet?
> 
> Best,
> Bingsong
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From Tom_Ph|||pp| @end|ng |rom np@@gov  Thu Oct  8 18:20:16 2020
From: Tom_Ph|||pp| @end|ng |rom np@@gov (Philippi, Tom)
Date: Thu, 8 Oct 2020 16:20:16 +0000
Subject: [R-sig-ME] [EXTERNAL]  glmmTMB questions
In-Reply-To: <CAJMQhGs2XVrNSb4RX=pmhzj7O+w94oKEeAUFR7eA3SngGwP8YA@mail.gmail.com>
References: <CAJMQhGs2XVrNSb4RX=pmhzj7O+w94oKEeAUFR7eA3SngGwP8YA@mail.gmail.com>
Message-ID: <SA9PR09MB53579FE9F63CF3BC8A07CD68F30B0@SA9PR09MB5357.namprd09.prod.outlook.com>

Bingsong--
I believe that error message means you don't have something installed or configured correctly.  The following runs correctly for me in 3.6.3:
library(glmmTMB)
data(cbpp, package='lme4')
bovine <- glmmTMB(cbind(incidence, size-incidence) ~ period +  (1|herd),
                  family=binomial, data=cbpp)
str(bovine)

> sessionInfo()
R version 3.6.3 (2020-02-29)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 10 x64 (build 18363)

Matrix products: default

locale:
[1] LC_COLLATE=English_United States.1252 
[2] LC_CTYPE=English_United States.1252   
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C                          
[5] LC_TIME=English_United States.1252    

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] glmmTMB_1.0.0

loaded via a namespace (and not attached):
 [1] minqa_1.2.4     MASS_7.3-51.5   compiler_3.6.3  Matrix_1.2-18  
 [5] tools_3.6.3     TMB_1.7.16      Rcpp_1.0.3      splines_3.6.3  
 [9] nlme_3.1-144    grid_3.6.3      nloptr_1.2.2    boot_1.3-24    
[13] lme4_1.1-21     lattice_0.20-38 fortunes_1.5-4


Tom

-----Original Message-----
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> On Behalf Of Bingsong Zhang
Sent: Thursday, October 8, 2020 9:10 AM
To: r-sig-mixed-models at r-project.org
Subject: [EXTERNAL] [R-sig-ME] glmmTMB questions



 This email has been received from outside of DOI - Use caution before clicking on links, opening attachments, or responding.



Hi all,

Did anyone try using glmmTMB to fit the logistic model?

I run the following code as mentioned in the manual page 16, but get error messages.

> data(cbpp, package="lme4")
> bovine <- glmmTMB(cbind(incidence, size-incidence) ~ period + 
> (1|herd),
family=binomial, data=cbpp)
Error in .Call("FreeADFunObject", ptr, PACKAGE = DLL) :
  "FreeADFunObject" not available for .Call() for package "glmmTMB"
Error in .Call("FreeADFunObject", ptr, PACKAGE = DLL) :
  "FreeADFunObject" not available for .Call() for package "glmmTMB"

Does it mean the package is not ready for binomial data yet?

Best,
Bingsong

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bz117 @end|ng |rom georgetown@edu  Thu Oct  8 18:21:44 2020
From: bz117 @end|ng |rom georgetown@edu (Bingsong Zhang)
Date: Thu, 8 Oct 2020 12:21:44 -0400
Subject: [R-sig-ME] [EXTERNAL]  glmmTMB questions
In-Reply-To: <SA9PR09MB53579FE9F63CF3BC8A07CD68F30B0@SA9PR09MB5357.namprd09.prod.outlook.com>
References: <CAJMQhGs2XVrNSb4RX=pmhzj7O+w94oKEeAUFR7eA3SngGwP8YA@mail.gmail.com>
 <SA9PR09MB53579FE9F63CF3BC8A07CD68F30B0@SA9PR09MB5357.namprd09.prod.outlook.com>
Message-ID: <CAJMQhGtpdvzojnkiH_2quQZh6F=5tX+cRFkR+jY7vRkUpDpHQA@mail.gmail.com>

Thanks, I'll check it out.

On Thu, Oct 8, 2020 at 12:20 PM Philippi, Tom <Tom_Philippi at nps.gov> wrote:

> Bingsong--
> I believe that error message means you don't have something installed or
> configured correctly.  The following runs correctly for me in 3.6.3:
> library(glmmTMB)
> data(cbpp, package='lme4')
> bovine <- glmmTMB(cbind(incidence, size-incidence) ~ period +  (1|herd),
>                   family=binomial, data=cbpp)
> str(bovine)
>
> > sessionInfo()
> R version 3.6.3 (2020-02-29)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows 10 x64 (build 18363)
>
> Matrix products: default
>
> locale:
> [1] LC_COLLATE=English_United States.1252
> [2] LC_CTYPE=English_United States.1252
> [3] LC_MONETARY=English_United States.1252
> [4] LC_NUMERIC=C
> [5] LC_TIME=English_United States.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] glmmTMB_1.0.0
>
> loaded via a namespace (and not attached):
>  [1] minqa_1.2.4     MASS_7.3-51.5   compiler_3.6.3  Matrix_1.2-18
>  [5] tools_3.6.3     TMB_1.7.16      Rcpp_1.0.3      splines_3.6.3
>  [9] nlme_3.1-144    grid_3.6.3      nloptr_1.2.2    boot_1.3-24
> [13] lme4_1.1-21     lattice_0.20-38 fortunes_1.5-4
>
>
> Tom
>
> -----Original Message-----
> From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> On
> Behalf Of Bingsong Zhang
> Sent: Thursday, October 8, 2020 9:10 AM
> To: r-sig-mixed-models at r-project.org
> Subject: [EXTERNAL] [R-sig-ME] glmmTMB questions
>
>
>
>  This email has been received from outside of DOI - Use caution before
> clicking on links, opening attachments, or responding.
>
>
>
> Hi all,
>
> Did anyone try using glmmTMB to fit the logistic model?
>
> I run the following code as mentioned in the manual page 16, but get error
> messages.
>
> > data(cbpp, package="lme4")
> > bovine <- glmmTMB(cbind(incidence, size-incidence) ~ period +
> > (1|herd),
> family=binomial, data=cbpp)
> Error in .Call("FreeADFunObject", ptr, PACKAGE = DLL) :
>   "FreeADFunObject" not available for .Call() for package "glmmTMB"
> Error in .Call("FreeADFunObject", ptr, PACKAGE = DLL) :
>   "FreeADFunObject" not available for .Call() for package "glmmTMB"
>
> Does it mean the package is not ready for binomial data yet?
>
> Best,
> Bingsong
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From bz117 @end|ng |rom georgetown@edu  Thu Oct  8 21:41:16 2020
From: bz117 @end|ng |rom georgetown@edu (Bingsong Zhang)
Date: Thu, 8 Oct 2020 15:41:16 -0400
Subject: [R-sig-ME] struc(term|group)
Message-ID: <CAJMQhGuHiVJSYFs7PDZFsfn1Udz8ikTg1hNAJNvVt2Kt4nRh5g@mail.gmail.com>

Hi all,

Did anyone use the struc(term | group) in glmmTMB before? Are there any
materials or examples I can read about it?

Best,
Bill

	[[alternative HTML version deleted]]


From mo|||eebrook@ @end|ng |rom gm@||@com  Thu Oct  8 22:18:21 2020
From: mo|||eebrook@ @end|ng |rom gm@||@com (Mollie Brooks)
Date: Thu, 8 Oct 2020 22:18:21 +0200
Subject: [R-sig-ME] struc(term|group)
In-Reply-To: <CAJMQhGuHiVJSYFs7PDZFsfn1Udz8ikTg1hNAJNvVt2Kt4nRh5g@mail.gmail.com>
References: <CAJMQhGuHiVJSYFs7PDZFsfn1Udz8ikTg1hNAJNvVt2Kt4nRh5g@mail.gmail.com>
Message-ID: <D45AD3FA-8FDC-4EC2-9DA2-577D88B89253@gmail.com>

There?s a vignette on covariance structures
https://cran.r-project.org/web/packages/glmmTMB/vignettes/covstruct.html <https://cran.r-project.org/web/packages/glmmTMB/vignettes/covstruct.html>

In general, you can find a list of available vignettes for any package using commands like
vignette(package="glmmTMB")

cheers,
Mollie


> On 8Oct 2020, at 21:41, Bingsong Zhang <bz117 at georgetown.edu> wrote:
> 
> Hi all,
> 
> Did anyone use the struc(term | group) in glmmTMB before? Are there any
> materials or examples I can read about it?
> 
> Best,
> Bill
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Fri Oct  9 01:38:51 2020
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Thu, 8 Oct 2020 19:38:51 -0400
Subject: [R-sig-ME] struc(term|group)
In-Reply-To: <CAJMQhGuHiVJSYFs7PDZFsfn1Udz8ikTg1hNAJNvVt2Kt4nRh5g@mail.gmail.com>
References: <CAJMQhGuHiVJSYFs7PDZFsfn1Udz8ikTg1hNAJNvVt2Kt4nRh5g@mail.gmail.com>
Message-ID: <147395b3-672d-e8d0-5ee0-82ae7d1c471c@gmail.com>

   Can you please be a little more specific?

   The vignette Mollie referred to is a good start.

   However, there is no literal struc() option for structured covariance 
matrices: the current list of options is  {diag = 0, us, cs, ar1, ou, 
exp, gau, mat, toep}.  Or did you mean struc() as a place-holder for 
structured covariance matrices in general?


On 10/8/20 3:41 PM, Bingsong Zhang wrote:
 > Hi all,
 >
 > Did anyone use the struc(term | group) in glmmTMB before? Are there any
 > materials or examples I can read about it?
 >
 > Best,
 > Bill
 >
 > 	[[alternative HTML version deleted]]
 >
 > _______________________________________________
 > R-sig-mixed-models at r-project.org mailing list
 > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
 >


From bbo|ker @end|ng |rom gm@||@com  Fri Oct  9 21:10:29 2020
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Fri, 9 Oct 2020 15:10:29 -0400
Subject: [R-sig-ME] Predict for glmer
In-Reply-To: <5bef0880-7917-692a-c89e-101df83770f8@yahoo.fr>
References: <5bef0880-7917-692a-c89e-101df83770f8.ref@yahoo.fr>
 <5bef0880-7917-692a-c89e-101df83770f8@yahoo.fr>
Message-ID: <969cc527-a6d8-4580-40e7-8e42f6f65ca8@gmail.com>

   I don't know if anyone ever answered this ...  you need to construct 
the RE model matrix without an intercept, i.e.


   random <- rowSums(model.matrix(~ R1 -1 , data = d) * er$R2[d$R2, ])

  FWIW you can also use getME(.,"X") and getME(.,"Z") to retrieve the 
fixed- and random-effects model matrices (I know that's not the point 
here ...)

   cheers
     Ben Bolker


On 9/27/20 4:52 AM, Marc Girondot via R-sig-mixed-models wrote:
> Hi,
> 
> I try to understand exactly how mixed model is working. Let do this 
> simple model with fake data:
> 
> 
> library(lme4)
> 
> invlogit <- function(n) {1/(1 + exp(-n))}
> 
> d <- data.frame(A=c(10, 20, 10, 20, 30, 15, 17, 19, 20, 30, 20, 30, 21, 
> 23),
>  ??????????????? B=c(2, 3, 7, 9, 10, 8, 5, 7, 9, 10, 2, 3, 7, 8),
>  ??????????????? D=c(10, 11, 12, 13, 14, 10, 11, 12, 13, 14, 13, 12, 12, 
> 13),
>  ??????????????? R1=c("A", "A", "A", "A", "A", "A", "A", "B", "B", "B", 
> "B", "B", "B", "B"),
>  ??????????????? R2=c("C", "C", "C", "D", "D", "D", "D", "E", "E", "E", 
> "F", "F", "F", "F"))
> 
> m <- glmer(formula = cbind(A, B) ~ D + (1 | R1 / R2),
>  ????? data=d,
>  ????? family = binomial(link = "logit"))
> 
> It seems to work well (except the warning for boundary because probably 
> I don't introduce enough data).
> 
> Let do a predict:
> 
> predict(m, type="response")
> 
>  ??????? 1???????? 2???????? 3???????? 4???????? 5 6???????? 7 8         
> 9??????? 10??????? 11
> 0.7706127 0.7665437 0.7624248 0.7502806 0.7459699 0.7629174 0.7587547 
> 0.7572462 0.7530161 0.7487368 0.7696229
>  ?????? 12??????? 13??????? 14
> 0.7736541 0.7736541 0.7696229
> 
> It is ok. Now I try to do the predict by hand to be sure that I 
> understand how it works:
> 
> ef <- fixef(m)
> er <- ranef(m)
> 
> fixed <- model.matrix(~ D, data = d) %*% ef
> random <- rowSums(model.matrix(~ R1, data = d) * er$R2[d$R2, ])
> invlogit(fixed[, 1] + random)
> 
>  ??????? 1???????? 2???????? 3???????? 4???????? 5???????? 6 7 8         
> 9??????? 10??????? 11
> 
> 0.7706127 0.7665437 0.7624248 0.7502806 0.7459699 0.7629174 0.7587547 
> 0.7523144 0.7480270 0.7436906 0.7809063
>  ?????? 12??????? 13??????? 14
> 0.7847953 0.7847953 0.7809063
> 
> The first 7 estimates are ok but not the last 7. So it is related to R1 
> factor... but I don't understand why it is badly estimated.
> 
> 
> If someone can help me...
> 
> Thanks a lot
> 
> Marc
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbo|ker @end|ng |rom gm@||@com  Fri Oct  9 21:13:12 2020
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Fri, 9 Oct 2020 15:13:12 -0400
Subject: [R-sig-ME] (no subject)
In-Reply-To: <CAM-hW5eqAnSJq-iofF3wXN2zoFSMQRcrXgEpJr-Jg23H2u7S-Q@mail.gmail.com>
References: <CAM-hW5eqAnSJq-iofF3wXN2zoFSMQRcrXgEpJr-Jg23H2u7S-Q@mail.gmail.com>
Message-ID: <9f7c7ae2-6694-1828-158d-fe33e7f5f250@gmail.com>



On 10/1/20 3:30 AM, Marte Lilleeng wrote:
> I want to unsubscribe from this list.
> 

   Information on how to unsubscribe is available at the link included 
at the bottom of every mailing-list message, i.e.
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From don-|me4 @end|ng |rom |@|@@c@3-|nc@com  Sat Oct 10 03:34:14 2020
From: don-|me4 @end|ng |rom |@|@@c@3-|nc@com (Don Cohen)
Date: Sat, 10 Oct 2020 01:34:14 +0000
Subject: [R-sig-ME] question on nbinom1
In-Reply-To: <ce732d14-a522-b5e6-8453-ac35bc578e34@gmail.com>
References: <20201008213158.E254940587@chmusic.org>
 <ce732d14-a522-b5e6-8453-ac35bc578e34@gmail.com>
Message-ID: <24449.3990.732499.94723@chmusic.org>


In response to a question about use of nbinom1 in glmTMB, specifically
about this paper by VerHoef J.M. & Boveng:
 https://digitalcommons.unl.edu/cgi/viewcontent.cgi?article=1141&context=usdeptcommercepub
which says that AIC cannot be used to choose between a quasi-Poisson model
and a negative binomial,

Ben Bolker writes:

 >     nbinom1 is *not* quasi-: see Hardin & Hilbe 2007 as suggested in 
 > ?nbinom1.  (It can't be fitted in a standard GLM framework, since this 
 > parameterization of the nbinom doesn't fit into the exponential family, 
 > but glmmTMB is more flexible than that ...)

I've been trying to figure out what Hardin & Hilbe have to say about this,
and so far failing to find the connection.
(BTW, is nbinom1 the same as what they call NB-C ?)

Does "nbinom1 is *not* quasi-" mean that the AIC reported when I use 
nbinom1 really IS comparable to the one reported when I use nbinom2?
And that loglik is actually being computed for a "real" distribution?
Does it matter whether I also use random effects, zero inflation, 
offset, etc. ?

Alternatively, if AIC for nbinom1 is really NOT comparable to AIC for the
other (real?) distributions, how is one supposed to determine which model
better fits the data?  VerHoef suggests trying to determine whether the
variance for different subpopulations with different means more closely
resembles linear or quadratic functions of the mean, but this is not at
all clear in the data I'm trying to analyze.


From bz117 @end|ng |rom georgetown@edu  Sat Oct 10 04:30:01 2020
From: bz117 @end|ng |rom georgetown@edu (Bingsong Zhang)
Date: Fri, 9 Oct 2020 22:30:01 -0400
Subject: [R-sig-ME] struc(term|group)
In-Reply-To: <147395b3-672d-e8d0-5ee0-82ae7d1c471c@gmail.com>
References: <CAJMQhGuHiVJSYFs7PDZFsfn1Udz8ikTg1hNAJNvVt2Kt4nRh5g@mail.gmail.com>
 <147395b3-672d-e8d0-5ee0-82ae7d1c471c@gmail.com>
Message-ID: <CAJMQhGsmu7BquGEZeQqsthX_0Y67bjm1hgLaNk3xETU5Qg90CQ@mail.gmail.com>

In page 15 of glmmTMB manual, I see something about variance-covariance
matrix of random effect, possible options for struc() are diag(), ar1(),
cs() and so on. I just curious how to use this option?



On Thu, Oct 8, 2020 at 7:39 PM Ben Bolker <bbolker at gmail.com> wrote:

>    Can you please be a little more specific?
>
>    The vignette Mollie referred to is a good start.
>
>    However, there is no literal struc() option for structured covariance
> matrices: the current list of options is  {diag = 0, us, cs, ar1, ou,
> exp, gau, mat, toep}.  Or did you mean struc() as a place-holder for
> structured covariance matrices in general?
>
>
> On 10/8/20 3:41 PM, Bingsong Zhang wrote:
>  > Hi all,
>  >
>  > Did anyone use the struc(term | group) in glmmTMB before? Are there any
>  > materials or examples I can read about it?
>  >
>  > Best,
>  > Bill
>  >
>  >      [[alternative HTML version deleted]]
>  >
>  > _______________________________________________
>  > R-sig-mixed-models at r-project.org mailing list
>  > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>  >
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From pr|db @end|ng |rom protonm@||@com  Sat Oct 10 04:52:42 2020
From: pr|db @end|ng |rom protonm@||@com (Peter R Law)
Date: Sat, 10 Oct 2020 02:52:42 +0000
Subject: [R-sig-ME] lme4
Message-ID: <3W5aoG6Fi-5eoL4dmsdML6fnVPmkLbsPVf095uRCewlHw5fV73miR5rMudmydlRtlefRdY8g5NMUf8jrseOtjXpbI_mm4J3nrvmTSB2M1JI=@protonmail.com>

I have a simple question about how lme4 works. If one uses lme4 to model a given data set for several different distributional assumptions (e.g., > gamma distribution, via glmer, and Gaussian via lmer and maximum likelihood rather than REML) are the maximum likelihoods output by lme4 comparable in the sense that one could compute AIC from the MLs and compare these models?

I ran a Gaussian model and a Gamma model on the same set of responses with several predictors and for each distribution checked all predictor combinations. I was struck by the fact that all the Gamma models had lower AICs than all the Gaussian models and wondered if there was some systematic difference between the way the two distributional assumptions were modelled in lme4 that might be responsible for this fat other than the Gamma models just being better.

I would have thought the models with different distributional assumptions do have comparable likelihoods and hence AICs since the likelihood models are formulated in the same manner, Y ~ g^{-1}(Z) + \epsilon, where Y is the response, Z the systematic component and g the link function, so in each case the raw responses are not being transformed, unlike the case when the responses are log-normal, in which case lnY = Z + \epsilon, which does not take the form of a generalized linear model since the residuals are multiplicative on the expectation of Y rather than additive. I take it this is why the log-normal is not included as an option in glmer and one can't compare AIC's of the log-normal model of Y with glmer models of Y. I saw a suggestion on a forum to use

family = gaussian(link =

"log"

)

with lme4 but this model would be Y =Ln^{-1}(Z) + \epsilon = e^Z + \epsilon, i.e., one has linearized the multiplicative error to make it additive, which is not exactly

the same as requiring Y to be log-normally distributed.

Peter R Law
Research Associate
Center for African Conservation Ecology
Nelson Mandela University
South Africa

Sent with [ProtonMail](https://protonmail.com) Secure Email.
	[[alternative HTML version deleted]]


From mo|||eebrook@ @end|ng |rom gm@||@com  Sat Oct 10 11:11:47 2020
From: mo|||eebrook@ @end|ng |rom gm@||@com (Mollie Brooks)
Date: Sat, 10 Oct 2020 11:11:47 +0200
Subject: [R-sig-ME] question on nbinom1
In-Reply-To: <24449.3990.732499.94723@chmusic.org>
References: <20201008213158.E254940587@chmusic.org>
 <ce732d14-a522-b5e6-8453-ac35bc578e34@gmail.com>
 <24449.3990.732499.94723@chmusic.org>
Message-ID: <186726DE-6A2A-4605-9A0B-AA79AA1626C5@gmail.com>

I don?t have a copy of Hardin & Hilbe 2007 on hand, but I answered a few of your questions below.

> On 10Oct 2020, at 3:34, Don Cohen <don-lme4 at isis.cs3-inc.com> wrote:
> 
> 
> In response to a question about use of nbinom1 in glmTMB, specifically
> about this paper by VerHoef J.M. & Boveng:
> https://digitalcommons.unl.edu/cgi/viewcontent.cgi?article=1141&context=usdeptcommercepub
> which says that AIC cannot be used to choose between a quasi-Poisson model
> and a negative binomial,
> 
> Ben Bolker writes:
> 
>>    nbinom1 is *not* quasi-: see Hardin & Hilbe 2007 as suggested in 
>> ?nbinom1.  (It can't be fitted in a standard GLM framework, since this 
>> parameterization of the nbinom doesn't fit into the exponential family, 
>> but glmmTMB is more flexible than that ...)
> 
> I've been trying to figure out what Hardin & Hilbe have to say about this,
> and so far failing to find the connection.
> (BTW, is nbinom1 the same as what they call NB-C ?)
> 
> Does "nbinom1 is *not* quasi-" mean that the AIC reported when I use 
> nbinom1 really IS comparable to the one reported when I use nbinom2?

Yes

> And that loglik is actually being computed for a "real" distribution?

Yes 

> Does it matter whether I also use random effects, zero inflation, 
> offset, etc. ?

No it doesn?t matter; the AIC is comparable when fitting those types of models. 

Some examples are 
https://cran.r-project.org/web/packages/glmmTMB/vignettes/glmmTMB.pdf <https://cran.r-project.org/web/packages/glmmTMB/vignettes/glmmTMB.pdf>
and 
appendix A here https://journal.r-project.org/archive/2017/RJ-2017-066/RJ-2017-066.pdf <https://journal.r-project.org/archive/2017/RJ-2017-066/RJ-2017-066.pdf>

cheers,
Mollie

> 
> Alternatively, if AIC for nbinom1 is really NOT comparable to AIC for the
> other (real?) distributions, how is one supposed to determine which model
> better fits the data?  VerHoef suggests trying to determine whether the
> variance for different subpopulations with different means more closely
> resembles linear or quadratic functions of the mean, but this is not at
> all clear in the data I'm trying to analyze.
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


	[[alternative HTML version deleted]]


From mo|||eebrook@ @end|ng |rom gm@||@com  Sat Oct 10 11:12:41 2020
From: mo|||eebrook@ @end|ng |rom gm@||@com (Mollie Brooks)
Date: Sat, 10 Oct 2020 11:12:41 +0200
Subject: [R-sig-ME] struc(term|group)
In-Reply-To: <CAJMQhGsmu7BquGEZeQqsthX_0Y67bjm1hgLaNk3xETU5Qg90CQ@mail.gmail.com>
References: <CAJMQhGuHiVJSYFs7PDZFsfn1Udz8ikTg1hNAJNvVt2Kt4nRh5g@mail.gmail.com>
 <147395b3-672d-e8d0-5ee0-82ae7d1c471c@gmail.com>
 <CAJMQhGsmu7BquGEZeQqsthX_0Y67bjm1hgLaNk3xETU5Qg90CQ@mail.gmail.com>
Message-ID: <DF778E5F-E896-41EE-82EC-08633B590C7F@gmail.com>

There?s a vignette on covariance structures
https://cran.r-project.org/web/packages/glmmTMB/vignettes/covstruct.html <https://cran.r-project.org/web/packages/glmmTMB/vignettes/covstruct.html>

Did you see that?


> On 10Oct 2020, at 4:30, Bingsong Zhang <bz117 at georgetown.edu> wrote:
> 
> In page 15 of glmmTMB manual, I see something about variance-covariance
> matrix of random effect, possible options for struc() are diag(), ar1(),
> cs() and so on. I just curious how to use this option?
> 
> 
> 
> On Thu, Oct 8, 2020 at 7:39 PM Ben Bolker <bbolker at gmail.com> wrote:
> 
>>   Can you please be a little more specific?
>> 
>>   The vignette Mollie referred to is a good start.
>> 
>>   However, there is no literal struc() option for structured covariance
>> matrices: the current list of options is  {diag = 0, us, cs, ar1, ou,
>> exp, gau, mat, toep}.  Or did you mean struc() as a place-holder for
>> structured covariance matrices in general?
>> 
>> 
>> On 10/8/20 3:41 PM, Bingsong Zhang wrote:
>>> Hi all,
>>> 
>>> Did anyone use the struc(term | group) in glmmTMB before? Are there any
>>> materials or examples I can read about it?
>>> 
>>> Best,
>>> Bill
>>> 
>>>     [[alternative HTML version deleted]]
>>> 
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> 
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


	[[alternative HTML version deleted]]


From b|e|||@@|e@@@ndr@ @end|ng |rom gm@||@com  Sat Oct 10 13:28:30 2020
From: b|e|||@@|e@@@ndr@ @end|ng |rom gm@||@com (Alessandra Bielli)
Date: Sat, 10 Oct 2020 05:28:30 -0600
Subject: [R-sig-ME] confidence intervals with mvrnorm - upper value equal to
 inf
Message-ID: <CA+6N3yX7jOYKLKjB3Hk_q_Ei4H+1bpoHZ9kcontZODPL+XO8xA@mail.gmail.com>

Dear list,

I am trying to predict a value and CI for two different treatments from a
glmmTMB fitted model using posterior predictive simulations (mvrnorm
function in the MASS package) as in the Salamander example, Brooks 2017
appendix B
<https://www.biorxiv.org/content/biorxiv/suppl/2017/05/01/132753.DC1/132753-2.pdf>.
The dependent variable is a count, majority of values are zeros but some
positive values appear.

m1 <- glmmTMB(Dolphins.TOT ~ Used_piNgers + offset(log(Effort)) +
(1|Trip_Code), ziformula =~1,
              data=x, family = "truncated_poisson")

    newdata0 = with(x,
                expand.grid(
                  Used_piNgers = c("Y","N"),
                  Effort=1))

X.cond = model.matrix(lme4::nobars(formula(m1)[-2]), newdata0)

beta.cond = fixef(m1)$cond
pred.cond = X.cond %*% beta.cond
ziformula = m1$modelInfo$allForm$ziformula
X.zi = model.matrix(lme4::nobars(ziformula), newdata0)
beta.zi = fixef(m1)$zi
pred.zi = X.zi %*% beta.zi

pred.ucount = exp(pred.cond)*(1-plogis(pred.zi))


set.seed(101)
pred.condpar.psim = mvrnorm(1000,mu=beta.cond,Sigma=vcov(m1)$cond)
pred.cond.psim = X.cond %*% t(pred.condpar.psim)
pred.zipar.psim = mvrnorm(1000,mu=beta.zi,Sigma=vcov(m1)$zi)
pred.zi.psim = X.zi %*% t(pred.zipar.psim)
pred.ucount.psim = exp(pred.cond.psim)*(1-plogis(pred.zi.psim))
ci.ucount = t(apply(pred.ucount.psim,1,quantile,c(0.025,0.975)))
ci.ucount = data.frame(ci.ucount)
names(ci.ucount) = c("ucount.low","ucount.high")
pred.ucount = data.frame(newdata0, pred.ucount, ci.ucount)

For my upper CI, I get a value equal to Inf:

Used_piNgers Effort  pred.ucount ucount.low ucount.high
1            Y      1 6.758889e-11 0.00000000         Inf
2            N      1 1.575418e-02 0.00223033   0.1096139

Is the Inf caused by the very low variability of values in my dataset? I
tried to lower the upper bound of the CI ci.ucount =
t(apply(pred.ucount.psim,1,quantile,c(0.025,0.975))) and only when reaching
0.475 ci.ucount = t(apply(pred.ucount.psim,1,quantile,c(0.025,0.475))) I
obtained:

Used_piNgers Effort  pred.ucount ucount.low  ucount.high
1            Y      1 6.758889e-11 0.00000000 7.117465e+12
2            N      1 1.575418e-02 0.00223033 1.454579e-02

I found a related post
<https://stackoverflow.com/questions/38272798/bootstrap-confidence-interval-with-inf-in-final-estimates-boot-dplyr-package>
but
the explanation is not clear to me. I would like to publish these results
and I would like to know:

   1. is this a sign that something is wrong? if yes, what is it?
   2. if nothing is wrong, what does the Inf mean and what's the best way
   to report it and plot it in a publication?


I also posted this question on Cross validated
https://stats.stackexchange.com/questions/491196/bootstrap-confidence-interval-with-mvrnorm-upper-value-equal-to-inf

Thanks,
Alessandra

	[[alternative HTML version deleted]]


From don-|me4 @end|ng |rom |@|@@c@3-|nc@com  Sat Oct 10 14:23:35 2020
From: don-|me4 @end|ng |rom |@|@@c@3-|nc@com (Don Cohen)
Date: Sat, 10 Oct 2020 12:23:35 +0000
Subject: [R-sig-ME] question on nbinom1
In-Reply-To: <186726DE-6A2A-4605-9A0B-AA79AA1626C5@gmail.com>
References: <20201008213158.E254940587@chmusic.org>
 <ce732d14-a522-b5e6-8453-ac35bc578e34@gmail.com>
 <24449.3990.732499.94723@chmusic.org>
 <186726DE-6A2A-4605-9A0B-AA79AA1626C5@gmail.com>
Message-ID: <24449.42951.851447.860160@chmusic.org>

Mollie Brooks writes:

 > I don't have a copy of Hardin & Hilbe 2007 on hand, but I answered
 > a few of your questions below.

Thank you.

One more question:

How can I compute the nbinom1 distribution?
Is there a formula for the pdf or cdf ?  An R function ?


From bz117 @end|ng |rom georgetown@edu  Sat Oct 10 22:47:20 2020
From: bz117 @end|ng |rom georgetown@edu (Bingsong Zhang)
Date: Sat, 10 Oct 2020 16:47:20 -0400
Subject: [R-sig-ME] struc(term|group)
In-Reply-To: <DF778E5F-E896-41EE-82EC-08633B590C7F@gmail.com>
References: <CAJMQhGuHiVJSYFs7PDZFsfn1Udz8ikTg1hNAJNvVt2Kt4nRh5g@mail.gmail.com>
 <147395b3-672d-e8d0-5ee0-82ae7d1c471c@gmail.com>
 <CAJMQhGsmu7BquGEZeQqsthX_0Y67bjm1hgLaNk3xETU5Qg90CQ@mail.gmail.com>
 <DF778E5F-E896-41EE-82EC-08633B590C7F@gmail.com>
Message-ID: <CAJMQhGufDkAUMjJPNykxDZnuPygF9KbaNN=Xf5FsGzdDEGw3qw@mail.gmail.com>

Hi Mollie,

Yes I saw it, I think it perfectly fit my case, I will take a careful look
to it, thank you.

On Sat, Oct 10, 2020 at 5:12 AM Mollie Brooks <mollieebrooks at gmail.com>
wrote:

> There?s a vignette on covariance structures
> https://cran.r-project.org/web/packages/glmmTMB/vignettes/covstruct.html
>
> Did you see that?
>
>
> On 10Oct 2020, at 4:30, Bingsong Zhang <bz117 at georgetown.edu> wrote:
>
> In page 15 of glmmTMB manual, I see something about variance-covariance
> matrix of random effect, possible options for struc() are diag(), ar1(),
> cs() and so on. I just curious how to use this option?
>
>
>
> On Thu, Oct 8, 2020 at 7:39 PM Ben Bolker <bbolker at gmail.com> wrote:
>
>   Can you please be a little more specific?
>
>   The vignette Mollie referred to is a good start.
>
>   However, there is no literal struc() option for structured covariance
> matrices: the current list of options is  {diag = 0, us, cs, ar1, ou,
> exp, gau, mat, toep}.  Or did you mean struc() as a place-holder for
> structured covariance matrices in general?
>
>
> On 10/8/20 3:41 PM, Bingsong Zhang wrote:
>
> Hi all,
>
> Did anyone use the struc(term | group) in glmmTMB before? Are there any
> materials or examples I can read about it?
>
> Best,
> Bill
>
>     [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
> [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
>

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Sun Oct 11 23:33:45 2020
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Sun, 11 Oct 2020 17:33:45 -0400
Subject: [R-sig-ME] lme4
In-Reply-To: <3W5aoG6Fi-5eoL4dmsdML6fnVPmkLbsPVf095uRCewlHw5fV73miR5rMudmydlRtlefRdY8g5NMUf8jrseOtjXpbI_mm4J3nrvmTSB2M1JI=@protonmail.com>
References: <3W5aoG6Fi-5eoL4dmsdML6fnVPmkLbsPVf095uRCewlHw5fV73miR5rMudmydlRtlefRdY8g5NMUf8jrseOtjXpbI_mm4J3nrvmTSB2M1JI=@protonmail.com>
Message-ID: <db0e7d20-3b2c-7b59-e126-317847f086e2@gmail.com>




On 10/9/20 10:52 PM, Peter R Law via R-sig-mixed-models wrote:
> I have a simple question about how lme4 works. If one uses lme4 to model a given data set for several different distributional assumptions (e.g., > gamma distribution, via glmer, and Gaussian via lmer and maximum likelihood rather than REML) are the maximum likelihoods output by lme4 comparable in the sense that one could compute AIC from the MLs and compare these models?

   Yes.
> 
> I ran a Gaussian model and a Gamma model on the same set of responses with several predictors and for each distribution checked all predictor combinations. I was struck by the fact that all the Gamma models had lower AICs than all the Gaussian models and wondered if there was some systematic difference between the way the two distributional assumptions were modelled in lme4 that might be responsible for this fat other than the Gamma models just being better.

   No, not that I'm aware of!

If it's useful to you, you can directly compare the implementation of 
AIC for Gamma and Gaussian distributions:

https://github.com/lme4/lme4/blob/master/src/glmFamily.cpp#L239-L247
https://github.com/lme4/lme4/blob/master/src/glmFamily.cpp#L273-L277

   One way to to test your intuition (not *prove*) is to simulate some 
simple data with Gaussian  and Gamma-distributed responses and see that 
the AIC picks the correct model in each case ...

> 
> I would have thought the models with different distributional assumptions do have comparable likelihoods and hence AICs since the likelihood models are formulated in the same manner, Y ~ g^{-1}(Z) + \epsilon, where Y is the response, Z the systematic component and g the link function, so in each case the raw responses are not being transformed, unlike the case when the responses are log-normal, in which case lnY = Z + \epsilon, which does not take the form of a generalized linear model since the residuals are multiplicative on the expectation of Y rather than additive. I take it this is why the log-normal is not included as an option in glmer and one can't compare AIC's of the log-normal model of Y with glmer models of Y. I saw a suggestion on a forum to use
> 
> family = gaussian(link =
> 
> "log"
> 
> )
> 
> with lme4 but this model would be Y =Ln^{-1}(Z) + \epsilon = e^Z + \epsilon, i.e., one has linearized the multiplicative error to make it additive, which is not exactly
> 
> the same as requiring Y to be log-normally distributed.


    Correct.  The correction for the scale transformation is pretty 
simple: see here

https://stats.stackexchange.com/a/100671/2126

> 
> Peter R Law
> Research Associate
> Center for African Conservation Ecology
> Nelson Mandela University
> South Africa
> 
> Sent with [ProtonMail](https://protonmail.com) Secure Email.
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From bbo|ker @end|ng |rom gm@||@com  Sun Oct 11 23:46:28 2020
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Sun, 11 Oct 2020 17:46:28 -0400
Subject: [R-sig-ME] 
 confidence intervals with mvrnorm - upper value equal to inf
In-Reply-To: <CA+6N3yX7jOYKLKjB3Hk_q_Ei4H+1bpoHZ9kcontZODPL+XO8xA@mail.gmail.com>
References: <CA+6N3yX7jOYKLKjB3Hk_q_Ei4H+1bpoHZ9kcontZODPL+XO8xA@mail.gmail.com>
Message-ID: <7c5eea74-0a54-a0b5-acb9-f163ed1bc26b@gmail.com>

   It's hard to troubleshoot this without a reproducible example. Unless 
the answer is obvious -- which it's not, to me -- the easiest way to 
troubleshoot is to work through the steps one at a time and see where 
the infinite values first appear.  Can you create such an example either 
by posting your data or by simulating data that looks like your data?

   The posterior predictive simulation approach assumes that the 
sampling distributions of the parameters are multivariate normal, which 
is likely to be questionable in a low-information setting (which will be 
the case if you don't have very many non-zero values ...)


On 10/10/20 7:28 AM, Alessandra Bielli wrote:
> Dear list,
> 
> I am trying to predict a value and CI for two different treatments from a
> glmmTMB fitted model using posterior predictive simulations (mvrnorm
> function in the MASS package) as in the Salamander example, Brooks 2017
> appendix B
> <https://www.biorxiv.org/content/biorxiv/suppl/2017/05/01/132753.DC1/132753-2.pdf>.
> The dependent variable is a count, majority of values are zeros but some
> positive values appear.
> 
> m1 <- glmmTMB(Dolphins.TOT ~ Used_piNgers + offset(log(Effort)) +
> (1|Trip_Code), ziformula =~1,
>                data=x, family = "truncated_poisson")
> 
>      newdata0 = with(x,
>                  expand.grid(
>                    Used_piNgers = c("Y","N"),
>                    Effort=1))
> 
> X.cond = model.matrix(lme4::nobars(formula(m1)[-2]), newdata0)
> 
> beta.cond = fixef(m1)$cond
> pred.cond = X.cond %*% beta.cond
> ziformula = m1$modelInfo$allForm$ziformula
> X.zi = model.matrix(lme4::nobars(ziformula), newdata0)
> beta.zi = fixef(m1)$zi
> pred.zi = X.zi %*% beta.zi
> 
> pred.ucount = exp(pred.cond)*(1-plogis(pred.zi))
> 
> 
> set.seed(101)
> pred.condpar.psim = mvrnorm(1000,mu=beta.cond,Sigma=vcov(m1)$cond)
> pred.cond.psim = X.cond %*% t(pred.condpar.psim)
> pred.zipar.psim = mvrnorm(1000,mu=beta.zi,Sigma=vcov(m1)$zi)
> pred.zi.psim = X.zi %*% t(pred.zipar.psim)
> pred.ucount.psim = exp(pred.cond.psim)*(1-plogis(pred.zi.psim))
> ci.ucount = t(apply(pred.ucount.psim,1,quantile,c(0.025,0.975)))
> ci.ucount = data.frame(ci.ucount)
> names(ci.ucount) = c("ucount.low","ucount.high")
> pred.ucount = data.frame(newdata0, pred.ucount, ci.ucount)
> 
> For my upper CI, I get a value equal to Inf:
> 
> Used_piNgers Effort  pred.ucount ucount.low ucount.high
> 1            Y      1 6.758889e-11 0.00000000         Inf
> 2            N      1 1.575418e-02 0.00223033   0.1096139
> 
> Is the Inf caused by the very low variability of values in my dataset? I
> tried to lower the upper bound of the CI ci.ucount =
> t(apply(pred.ucount.psim,1,quantile,c(0.025,0.975))) and only when reaching
> 0.475 ci.ucount = t(apply(pred.ucount.psim,1,quantile,c(0.025,0.475))) I
> obtained:
> 
> Used_piNgers Effort  pred.ucount ucount.low  ucount.high
> 1            Y      1 6.758889e-11 0.00000000 7.117465e+12
> 2            N      1 1.575418e-02 0.00223033 1.454579e-02
> 
> I found a related post
> <https://stackoverflow.com/questions/38272798/bootstrap-confidence-interval-with-inf-in-final-estimates-boot-dplyr-package>
> but
> the explanation is not clear to me. I would like to publish these results
> and I would like to know:
> 
>     1. is this a sign that something is wrong? if yes, what is it?
>     2. if nothing is wrong, what does the Inf mean and what's the best way
>     to report it and plot it in a publication?
> 
> 
> I also posted this question on Cross validated
> https://stats.stackexchange.com/questions/491196/bootstrap-confidence-interval-with-mvrnorm-upper-value-equal-to-inf
> 
> Thanks,
> Alessandra
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From @pro @end|ng |rom un|me|b@edu@@u  Sun Oct 11 23:42:05 2020
From: @pro @end|ng |rom un|me|b@edu@@u (Andrew Robinson)
Date: Sun, 11 Oct 2020 21:42:05 +0000
Subject: [R-sig-ME] na.action = na.augment for random effects in lme4?
References: <8526baa0-70c6-45bf-8c34-dd37f42f7345@Spark>
Message-ID: <c3e3eb58-ba9b-440e-b383-d305734eb249@Spark>

Hi all,

I'm interested in fitting and applying models for which the data to which I apply the model will have some observations with random effects levels that are not in the fitting dataset.  I would like to flag these observations in some way.

Naively, I would prefer to have something like the na.action = na.augment argument so that predictions for observations with previously unseen levels of random effects would simply be missing.  Is there such a capability that I've missed?

Warm wishes,

Andrew


--
Andrew Robinson
Director, CEBRA and Professor of Biosecurity,
School/s of BioSciences and Mathematics & Statistics
University of Melbourne, VIC 3010 Australia
Tel: (+61) 0403 138 955
Email: apro at unimelb.edu.au
Website: https://researchers.ms.unimelb.edu.au/~apro at unimelb/

I acknowledge the Traditional Owners of the land I inhabit, and pay my respects to their Elders.

	[[alternative HTML version deleted]]


From ph||||p@@|d@y @end|ng |rom mp|@n|  Mon Oct 12 00:05:34 2020
From: ph||||p@@|d@y @end|ng |rom mp|@n| (Phillip Alday)
Date: Mon, 12 Oct 2020 00:05:34 +0200
Subject: [R-sig-ME] na.action = na.augment for random effects in lme4?
In-Reply-To: <c3e3eb58-ba9b-440e-b383-d305734eb249@Spark>
References: <8526baa0-70c6-45bf-8c34-dd37f42f7345@Spark>
 <c3e3eb58-ba9b-440e-b383-d305734eb249@Spark>
Message-ID: <0887fc99-33a3-046d-3eba-3b65fb7f3797@mpi.nl>

Doesn't look like it, the documentation for predict.merMod has option:


> allow.new.levels: logical if new levels (or NA values) in ?newdata? are
> ????????? allowed. If FALSE (default), such new values in ?newdata?
> ????????? will trigger an error; if TRUE, then the prediction will use
> ????????? the unconditional (population-level) values for data with
> ????????? previously unobserved levels (or NAs).

Maybe packages adding some extra functionality like merTools have some
things for this.


Otherwise, you can just filter your newdata with something like

newdata[newdata$groupingvar %in% levels(olddata$groupingvar), ]

Phillip


On 11/10/2020 23:42, Andrew Robinson wrote:
> Hi all,
>
> I'm interested in fitting and applying models for which the data to which I apply the model will have some observations with random effects levels that are not in the fitting dataset.  I would like to flag these observations in some way.
>
> Naively, I would prefer to have something like the na.action = na.augment argument so that predictions for observations with previously unseen levels of random effects would simply be missing.  Is there such a capability that I've missed?
>
> Warm wishes,
>
> Andrew
>
>
> --
> Andrew Robinson
> Director, CEBRA and Professor of Biosecurity,
> School/s of BioSciences and Mathematics & Statistics
> University of Melbourne, VIC 3010 Australia
> Tel: (+61) 0403 138 955
> Email: apro at unimelb.edu.au
> Website: https://researchers.ms.unimelb.edu.au/~apro at unimelb/
>
> I acknowledge the Traditional Owners of the land I inhabit, and pay my respects to their Elders.
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbo|ker @end|ng |rom gm@||@com  Mon Oct 12 00:22:41 2020
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Sun, 11 Oct 2020 18:22:41 -0400
Subject: [R-sig-ME] na.action = na.augment for random effects in lme4?
In-Reply-To: <0887fc99-33a3-046d-3eba-3b65fb7f3797@mpi.nl>
References: <8526baa0-70c6-45bf-8c34-dd37f42f7345@Spark>
 <c3e3eb58-ba9b-440e-b383-d305734eb249@Spark>
 <0887fc99-33a3-046d-3eba-3b65fb7f3797@mpi.nl>
Message-ID: <5de3331d-547a-1633-056d-1a5e3d9886f3@gmail.com>



On 10/11/20 6:05 PM, Phillip Alday wrote:
> Doesn't look like it, the documentation for predict.merMod has option:
> 
> 
>> allow.new.levels: logical if new levels (or NA values) in ?newdata? are
>>  ????????? allowed. If FALSE (default), such new values in ?newdata?
>>  ????????? will trigger an error; if TRUE, then the prediction will use
>>  ????????? the unconditional (population-level) values for data with
>>  ????????? previously unobserved levels (or NAs).
> 
> Maybe packages adding some extra functionality like merTools have some
> things for this.
> 
> 
> Otherwise, you can just filter your newdata with something like
> 
> newdata[newdata$groupingvar %in% levels(olddata$groupingvar), ]
> 
> Phillip
> 

   Yes. Following up:

* do you mean na.exclude (rather than na.augment)?

* it would certainly make sense that you might want these cases to be NA 
rather than predicted at the population level.  In hindsight it might 
have been a good idea to set this up as new.re.levels allowing the 
options c("population","fail", "exclude", "omit").

   Honestly, sorting out and implementing appropriate behaviours for a 
possible combinations of NAs in covariates or grouping variables of the 
initial data set and in the prediction data set has always given me a 
headache ...

    I would say you should do

  newresp <- predict(fitted_model, newdata, allow.new.levels=TRUE)
  new_levels <- !newdata$groupingvar %in% levels(orig_data$groupingvar)
  newresp[new_levels] <- NA

> 
> On 11/10/2020 23:42, Andrew Robinson wrote:
>> Hi all,
>>
>> I'm interested in fitting and applying models for which the data to which I apply the model will have some observations with random effects levels that are not in the fitting dataset.  I would like to flag these observations in some way.
>>
>> Naively, I would prefer to have something like the na.action = na.augment argument so that predictions for observations with previously unseen levels of random effects would simply be missing.  Is there such a capability that I've missed?
>>
>> Warm wishes,
>>
>> Andrew
>>
>>
>> --
>> Andrew Robinson
>> Director, CEBRA and Professor of Biosecurity,
>> School/s of BioSciences and Mathematics & Statistics
>> University of Melbourne, VIC 3010 Australia
>> Tel: (+61) 0403 138 955
>> Email: apro at unimelb.edu.au
>> Website: https://researchers.ms.unimelb.edu.au/~apro at unimelb/
>>
>> I acknowledge the Traditional Owners of the land I inhabit, and pay my respects to their Elders.
>>
>> 	[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From mo|||eebrook@ @end|ng |rom gm@||@com  Mon Oct 12 12:34:22 2020
From: mo|||eebrook@ @end|ng |rom gm@||@com (Mollie Brooks)
Date: Mon, 12 Oct 2020 12:34:22 +0200
Subject: [R-sig-ME] question on nbinom1
In-Reply-To: <24449.42951.851447.860160@chmusic.org>
References: <20201008213158.E254940587@chmusic.org>
 <ce732d14-a522-b5e6-8453-ac35bc578e34@gmail.com>
 <24449.3990.732499.94723@chmusic.org>
 <186726DE-6A2A-4605-9A0B-AA79AA1626C5@gmail.com>
 <24449.42951.851447.860160@chmusic.org>
Message-ID: <1291ED22-D6E6-4D3A-B4F1-1125F9E8A684@gmail.com>

I think the easiest way to get a numerical representation of the distribution from a fitted model would be using the simulate function.

There?s an example of how to do that on pages 392-393 of this pdf (including Figs 6 and 7)
https://journal.r-project.org/archive/2017/RJ-2017-066/RJ-2017-066.pdf <https://journal.r-project.org/archive/2017/RJ-2017-066/RJ-2017-066.pdf>

cheers,
Mollie

> On 10Oct 2020, at 14:23, Don Cohen <don-lme4 at isis.cs3-inc.com> wrote:
> 
> Mollie Brooks writes:
> 
>> I don't have a copy of Hardin & Hilbe 2007 on hand, but I answered
>> a few of your questions below.
> 
> Thank you.
> 
> One more question:
> 
> How can I compute the nbinom1 distribution?
> Is there a formula for the pdf or cdf ?  An R function ?
> 


	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Tue Oct 13 17:49:45 2020
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Tue, 13 Oct 2020 11:49:45 -0400
Subject: [R-sig-ME] question on nbinom1
In-Reply-To: <1291ED22-D6E6-4D3A-B4F1-1125F9E8A684@gmail.com>
References: <20201008213158.E254940587@chmusic.org>
 <ce732d14-a522-b5e6-8453-ac35bc578e34@gmail.com>
 <24449.3990.732499.94723@chmusic.org>
 <186726DE-6A2A-4605-9A0B-AA79AA1626C5@gmail.com>
 <24449.42951.851447.860160@chmusic.org>
 <1291ED22-D6E6-4D3A-B4F1-1125F9E8A684@gmail.com>
Message-ID: <414c5ac8-574d-99fe-f2c5-2065b0423386@gmail.com>


   I believe the R d/p/q/r functions corresponding to glmmTMB's 
implementation of *nbinom1 would look like this:


rnbinom1 <- function(n, mu, phi) {
     ## var = mu*(1+phi) = mu*(1+mu/k) -> k = mu/phi
     rnbinom(n, mu=mu, size=mu/phi)
}

dnbinom1 <- function(x, mu, phi, ...) {
     dnbinom(n, mu=mu, size=mu/phi, ...)
}

pnbinom1 <- function(q, mu, phi, ...) {
     pnbinom(q, mu=mu, size=mu/phi, ...)
}

qnbinom1 <- function(p, mu, phi, log=FALSE) {
     pnbinom(p, mu=mu, size=mu/phi, ...)
}


   (there would be an even more clever/inscrutable way to do this by 
transforming the body of the code, without repeating oneself so much, 
but it would probably be a bad idea)

On 10/12/20 6:34 AM, Mollie Brooks wrote:
> I think the easiest way to get a numerical representation of the distribution from a fitted model would be using the simulate function.
> 
> There?s an example of how to do that on pages 392-393 of this pdf (including Figs 6 and 7)
> https://journal.r-project.org/archive/2017/RJ-2017-066/RJ-2017-066.pdf <https://journal.r-project.org/archive/2017/RJ-2017-066/RJ-2017-066.pdf>
> 
> cheers,
> Mollie
> 
>> On 10Oct 2020, at 14:23, Don Cohen <don-lme4 at isis.cs3-inc.com> wrote:
>>
>> Mollie Brooks writes:
>>
>>> I don't have a copy of Hardin & Hilbe 2007 on hand, but I answered
>>> a few of your questions below.
>>
>> Thank you.
>>
>> One more question:
>>
>> How can I compute the nbinom1 distribution?
>> Is there a formula for the pdf or cdf ?  An R function ?
>>
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From don-|me4 @end|ng |rom |@|@@c@3-|nc@com  Tue Oct 13 21:01:33 2020
From: don-|me4 @end|ng |rom |@|@@c@3-|nc@com (Don Cohen)
Date: Tue, 13 Oct 2020 19:01:33 +0000
Subject: [R-sig-ME] question on nbinom1
In-Reply-To: <414c5ac8-574d-99fe-f2c5-2065b0423386@gmail.com>
References: <20201008213158.E254940587@chmusic.org>
 <ce732d14-a522-b5e6-8453-ac35bc578e34@gmail.com>
 <24449.3990.732499.94723@chmusic.org>
 <186726DE-6A2A-4605-9A0B-AA79AA1626C5@gmail.com>
 <24449.42951.851447.860160@chmusic.org>
 <1291ED22-D6E6-4D3A-B4F1-1125F9E8A684@gmail.com>
 <414c5ac8-574d-99fe-f2c5-2065b0423386@gmail.com>
Message-ID: <24453.63885.610704.472998@chmusic.org>


Thank you.
This is perfectly clear and enables further analysis.
I hope you can arrange to put it in some (even better, much) documentation.
I wish it were in wikipedia.

Ben Bolker writes:
 > 
 >    I believe the R d/p/q/r functions corresponding to glmmTMB's 
 > implementation of *nbinom1 would look like this:
 > 
 > 
 > rnbinom1 <- function(n, mu, phi) {
 >      ## var = mu*(1+phi) = mu*(1+mu/k) -> k = mu/phi
 >      rnbinom(n, mu=mu, size=mu/phi)
 > }
 > 
 > dnbinom1 <- function(x, mu, phi, ...) {
 >      dnbinom(n, mu=mu, size=mu/phi, ...)
 > }
 > 
 > pnbinom1 <- function(q, mu, phi, ...) {
 >      pnbinom(q, mu=mu, size=mu/phi, ...)
 > }
 > 
 > qnbinom1 <- function(p, mu, phi, log=FALSE) {
 >      pnbinom(p, mu=mu, size=mu/phi, ...)
 > }
 > 
 > 
 >    (there would be an even more clever/inscrutable way to do this by 
 > transforming the body of the code, without repeating oneself so much, 
 > but it would probably be a bad idea)
 > 
 > On 10/12/20 6:34 AM, Mollie Brooks wrote:
 > > I think the easiest way to get a numerical representation of the distribution from a fitted model would be using the simulate function.
 > > 
 > > There's an example of how to do that on pages 392-393 of this pdf (including Figs 6 and 7)
 > > https://journal.r-project.org/archive/2017/RJ-2017-066/RJ-2017-066.pdf <https://journal.r-project.org/archive/2017/RJ-2017-066/RJ-2017-066.pdf>
 > > 
 > > cheers,
 > > Mollie
 > > 
 > >> On 10Oct 2020, at 14:23, Don Cohen <don-lme4 at isis.cs3-inc.com> wrote:
 > >>
 > >> Mollie Brooks writes:
 > >>
 > >>> I don't have a copy of Hardin & Hilbe 2007 on hand, but I answered
 > >>> a few of your questions below.
 > >>
 > >> Thank you.
 > >>
 > >> One more question:
 > >>
 > >> How can I compute the nbinom1 distribution?
 > >> Is there a formula for the pdf or cdf ?  An R function ?
 > >>
 > > 
 > > 
 > > 	[[alternative HTML version deleted]]
 > > 
 > > _______________________________________________
 > > R-sig-mixed-models at r-project.org mailing list
 > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
 > >
 > 
 > _______________________________________________
 > R-sig-mixed-models at r-project.org mailing list
 > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From @h@@k|n @end|ng |rom @tudent@@kenne@@w@edu  Tue Oct 13 22:56:42 2020
From: @h@@k|n @end|ng |rom @tudent@@kenne@@w@edu (Sammie Haskin)
Date: Tue, 13 Oct 2020 20:56:42 +0000
Subject: [R-sig-ME] Assessing whether sigma for a random effects parameter
 is equal to 0
Message-ID: <BN7PR08MB5252B87BC91B76072BB9F040FF040@BN7PR08MB5252.namprd08.prod.outlook.com>

Hello! Given the pistonrings data set from the qcc package in R, I produced the following code to assess whether the standard deviation of random effect of the model was equal to 0. Here is my code:

library(lme4)
library(qcc)
library(RLRsim)
library(nlme)
library(data.table)

fit.pistons <- lmer(formula=diameter ~  sample + (1 | sample), data = pistonrings,REML=T)
fit.pistons0 <- lm(diameter ~ sample, data = pistonrings)
exactLRT(fit.pistons,fit.pistons0)

Here is the output:

LRT = 8.1423, p-value = 0.0014

Is this result implying that the standard deviation for the random effect is significant such that we reject the null hypothesis and that H0: sigma = 0 is false?

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Wed Oct 14 02:08:01 2020
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Tue, 13 Oct 2020 20:08:01 -0400
Subject: [R-sig-ME] 
 Assessing whether sigma for a random effects parameter is equal to 0
In-Reply-To: <BN7PR08MB5252B87BC91B76072BB9F040FF040@BN7PR08MB5252.namprd08.prod.outlook.com>
References: <BN7PR08MB5252B87BC91B76072BB9F040FF040@BN7PR08MB5252.namprd08.prod.outlook.com>
Message-ID: <63726aed-63f8-a5e1-0fbf-3c25e2414d90@gmail.com>



On 10/13/20 4:56 PM, Sammie Haskin wrote:
> Hello! Given the pistonrings data set from the qcc package in R, I produced the following code to assess whether the standard deviation of random effect of the model was equal to 0. Here is my code:
> 
> library(lme4)
> library(qcc)
> library(RLRsim)
> library(nlme)
> library(data.table)
> 
> fit.pistons <- lmer(formula=diameter ~  sample + (1 | sample), data = pistonrings,REML=T)
> fit.pistons0 <- lm(diameter ~ sample, data = pistonrings)
> exactLRT(fit.pistons,fit.pistons0)
> 
> Here is the output:
> 
> LRT = 8.1423, p-value = 0.0014
> 
> Is this result implying that the standard deviation for the random effect is significant such that we reject the null hypothesis 

    Yes, if we're using a standard alpha-level cutoff of 0.05 (or 0.01).

and that H0: sigma = 0 is false?

   For what it's worth I would argue that the null hypothesis is 
(almost??) *always* false, whatever the results of null-hypothesis 
testing are.


> 
> 	[[alternative HTML version deleted]]

   Please avoid sending e-mail to the list in HTML format ...

> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From b|e|||@@|e@@@ndr@ @end|ng |rom gm@||@com  Wed Oct 14 21:11:14 2020
From: b|e|||@@|e@@@ndr@ @end|ng |rom gm@||@com (Alessandra Bielli)
Date: Wed, 14 Oct 2020 13:11:14 -0600
Subject: [R-sig-ME] 
 confidence intervals with mvrnorm - upper value equal to inf
In-Reply-To: <7c5eea74-0a54-a0b5-acb9-f163ed1bc26b@gmail.com>
References: <CA+6N3yX7jOYKLKjB3Hk_q_Ei4H+1bpoHZ9kcontZODPL+XO8xA@mail.gmail.com>
 <7c5eea74-0a54-a0b5-acb9-f163ed1bc26b@gmail.com>
Message-ID: <CA+6N3yXUrH1A_oyJ0pnx9NR1Tq7nasox+zYH3jH9s_cYf+C+zQ@mail.gmail.com>

Hi Ben

That's a good point, my parameters are not multivariate normal.
But then, why was this method used in the Salamander example, where
data are zero inflated and so, I assume, not multivariate normal?

I haven't simulated the data to share yet, but the "Inf" first appears
at the line >pred.ucount.psim =
exp(pred.cond.psim)*(1-plogis(pred.zi.psim))
Only the first row, Used_piNgers=Y, shows "Inf".

Thanks,
Alessandra

On Sun, Oct 11, 2020 at 3:46 PM Ben Bolker <bbolker at gmail.com> wrote:
>
>    It's hard to troubleshoot this without a reproducible example. Unless
> the answer is obvious -- which it's not, to me -- the easiest way to
> troubleshoot is to work through the steps one at a time and see where
> the infinite values first appear.  Can you create such an example either
> by posting your data or by simulating data that looks like your data?
>
>    The posterior predictive simulation approach assumes that the
> sampling distributions of the parameters are multivariate normal, which
> is likely to be questionable in a low-information setting (which will be
> the case if you don't have very many non-zero values ...)
>
>
> On 10/10/20 7:28 AM, Alessandra Bielli wrote:
> > Dear list,
> >
> > I am trying to predict a value and CI for two different treatments from a
> > glmmTMB fitted model using posterior predictive simulations (mvrnorm
> > function in the MASS package) as in the Salamander example, Brooks 2017
> > appendix B
> > <https://www.biorxiv.org/content/biorxiv/suppl/2017/05/01/132753.DC1/132753-2.pdf>.
> > The dependent variable is a count, majority of values are zeros but some
> > positive values appear.
> >
> > m1 <- glmmTMB(Dolphins.TOT ~ Used_piNgers + offset(log(Effort)) +
> > (1|Trip_Code), ziformula =~1,
> >                data=x, family = "truncated_poisson")
> >
> >      newdata0 = with(x,
> >                  expand.grid(
> >                    Used_piNgers = c("Y","N"),
> >                    Effort=1))
> >
> > X.cond = model.matrix(lme4::nobars(formula(m1)[-2]), newdata0)
> >
> > beta.cond = fixef(m1)$cond
> > pred.cond = X.cond %*% beta.cond
> > ziformula = m1$modelInfo$allForm$ziformula
> > X.zi = model.matrix(lme4::nobars(ziformula), newdata0)
> > beta.zi = fixef(m1)$zi
> > pred.zi = X.zi %*% beta.zi
> >
> > pred.ucount = exp(pred.cond)*(1-plogis(pred.zi))
> >
> >
> > set.seed(101)
> > pred.condpar.psim = mvrnorm(1000,mu=beta.cond,Sigma=vcov(m1)$cond)
> > pred.cond.psim = X.cond %*% t(pred.condpar.psim)
> > pred.zipar.psim = mvrnorm(1000,mu=beta.zi,Sigma=vcov(m1)$zi)
> > pred.zi.psim = X.zi %*% t(pred.zipar.psim)
> > pred.ucount.psim = exp(pred.cond.psim)*(1-plogis(pred.zi.psim))
> > ci.ucount = t(apply(pred.ucount.psim,1,quantile,c(0.025,0.975)))
> > ci.ucount = data.frame(ci.ucount)
> > names(ci.ucount) = c("ucount.low","ucount.high")
> > pred.ucount = data.frame(newdata0, pred.ucount, ci.ucount)
> >
> > For my upper CI, I get a value equal to Inf:
> >
> > Used_piNgers Effort  pred.ucount ucount.low ucount.high
> > 1            Y      1 6.758889e-11 0.00000000         Inf
> > 2            N      1 1.575418e-02 0.00223033   0.1096139
> >
> > Is the Inf caused by the very low variability of values in my dataset? I
> > tried to lower the upper bound of the CI ci.ucount =
> > t(apply(pred.ucount.psim,1,quantile,c(0.025,0.975))) and only when reaching
> > 0.475 ci.ucount = t(apply(pred.ucount.psim,1,quantile,c(0.025,0.475))) I
> > obtained:
> >
> > Used_piNgers Effort  pred.ucount ucount.low  ucount.high
> > 1            Y      1 6.758889e-11 0.00000000 7.117465e+12
> > 2            N      1 1.575418e-02 0.00223033 1.454579e-02
> >
> > I found a related post
> > <https://stackoverflow.com/questions/38272798/bootstrap-confidence-interval-with-inf-in-final-estimates-boot-dplyr-package>
> > but
> > the explanation is not clear to me. I would like to publish these results
> > and I would like to know:
> >
> >     1. is this a sign that something is wrong? if yes, what is it?
> >     2. if nothing is wrong, what does the Inf mean and what's the best way
> >     to report it and plot it in a publication?
> >
> >
> > I also posted this question on Cross validated
> > https://stats.stackexchange.com/questions/491196/bootstrap-confidence-interval-with-mvrnorm-upper-value-equal-to-inf
> >
> > Thanks,
> > Alessandra
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From D@v|d@Du||y @end|ng |rom q|mrbergho|er@edu@@u  Wed Oct 14 14:27:50 2020
From: D@v|d@Du||y @end|ng |rom q|mrbergho|er@edu@@u (David Duffy)
Date: Wed, 14 Oct 2020 12:27:50 +0000
Subject: [R-sig-ME] 
 Assessing whether sigma for a random effects parameter is equal to 0
In-Reply-To: <BN7PR08MB5252B87BC91B76072BB9F040FF040@BN7PR08MB5252.namprd08.prod.outlook.com>
References: <BN7PR08MB5252B87BC91B76072BB9F040FF040@BN7PR08MB5252.namprd08.prod.outlook.com>
Message-ID: <ca6fb8d1eda840b9ba50bb734dbd8df4@qimrberghofer.edu.au>

> LRT = 8.1423, p-value = 0.0014
> Is this result implying that the standard deviation for the random effect is significant such that we reject 
> the null hypothesis and that H0: sigma = 0 is false?

Yes. And crosscheck 

 anova(lm(diameter ~ sample + factor(sample), data=pistonrings))
Analysis of Variance Table

Response: diameter
                            Df    Sum Sq    Mean Sq F value    Pr(>F)    
sample                 1 0.0022175 0.00221755 22.2785 5.115e-06 ***
factor(sample)  38 0.0077962 0.00020516  2.0612  0.001039 ** 
Residuals         160 0.0159260 0.00009954                      
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1


From bbo|ker @end|ng |rom gm@||@com  Thu Oct 15 03:24:22 2020
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Wed, 14 Oct 2020 21:24:22 -0400
Subject: [R-sig-ME] 
 confidence intervals with mvrnorm - upper value equal to inf
In-Reply-To: <CA+6N3yXUrH1A_oyJ0pnx9NR1Tq7nasox+zYH3jH9s_cYf+C+zQ@mail.gmail.com>
References: <CA+6N3yX7jOYKLKjB3Hk_q_Ei4H+1bpoHZ9kcontZODPL+XO8xA@mail.gmail.com>
 <7c5eea74-0a54-a0b5-acb9-f163ed1bc26b@gmail.com>
 <CA+6N3yXUrH1A_oyJ0pnx9NR1Tq7nasox+zYH3jH9s_cYf+C+zQ@mail.gmail.com>
Message-ID: <617833be-2f6b-888c-a32c-2538aa1e47f3@gmail.com>

   A few clarifying points below.

On 10/14/20 3:11 PM, Alessandra Bielli wrote:
> Hi Ben
> 
> That's a good point, my parameters are not multivariate normal.
> But then, why was this method used in the Salamander example, where
> data are zero inflated and so, I assume, not multivariate normal?

   The multivariate normality refers to the sampling distribution of the 
*model parameters*, not to the distribution (marginal or conditional of 
the response variable).  In general the sampling distribution of the 
model parameters is multivariate normal if the data are "well enough 
behaved" (i.e., either the responses themselves are normal *or* there is 
enough data, and enough information in the data, for the log-likelihood 
to become quadratic in a sufficiently large neighborhood of the MLE ...)


> 
> I haven't simulated the data to share yet, but the "Inf" first appears
> at the line >pred.ucount.psim =
> exp(pred.cond.psim)*(1-plogis(pred.zi.psim))
> Only the first row, Used_piNgers=Y, shows "Inf".

    Hmm.  That's a little surprising, it implies that pred.cond.psim is 
a large number (>700 or so, which for a log-scale parameter is huge). 
Can you show us X.cond[1,] , beta.cond, vcov(m1)$cond ?
> 
> Thanks,
> Alessandra
> 
> On Sun, Oct 11, 2020 at 3:46 PM Ben Bolker <bbolker at gmail.com> wrote:
>>
>>     It's hard to troubleshoot this without a reproducible example. Unless
>> the answer is obvious -- which it's not, to me -- the easiest way to
>> troubleshoot is to work through the steps one at a time and see where
>> the infinite values first appear.  Can you create such an example either
>> by posting your data or by simulating data that looks like your data?
>>
>>     The posterior predictive simulation approach assumes that the
>> sampling distributions of the parameters are multivariate normal, which
>> is likely to be questionable in a low-information setting (which will be
>> the case if you don't have very many non-zero values ...)
>>
>>
>> On 10/10/20 7:28 AM, Alessandra Bielli wrote:
>>> Dear list,
>>>
>>> I am trying to predict a value and CI for two different treatments from a
>>> glmmTMB fitted model using posterior predictive simulations (mvrnorm
>>> function in the MASS package) as in the Salamander example, Brooks 2017
>>> appendix B
>>> <https://www.biorxiv.org/content/biorxiv/suppl/2017/05/01/132753.DC1/132753-2.pdf>.
>>> The dependent variable is a count, majority of values are zeros but some
>>> positive values appear.
>>>
>>> m1 <- glmmTMB(Dolphins.TOT ~ Used_piNgers + offset(log(Effort)) +
>>> (1|Trip_Code), ziformula =~1,
>>>                 data=x, family = "truncated_poisson")
>>>
>>>       newdata0 = with(x,
>>>                   expand.grid(
>>>                     Used_piNgers = c("Y","N"),
>>>                     Effort=1))
>>>
>>> X.cond = model.matrix(lme4::nobars(formula(m1)[-2]), newdata0)
>>>
>>> beta.cond = fixef(m1)$cond
>>> pred.cond = X.cond %*% beta.cond
>>> ziformula = m1$modelInfo$allForm$ziformula
>>> X.zi = model.matrix(lme4::nobars(ziformula), newdata0)
>>> beta.zi = fixef(m1)$zi
>>> pred.zi = X.zi %*% beta.zi
>>>
>>> pred.ucount = exp(pred.cond)*(1-plogis(pred.zi))
>>>
>>>
>>> set.seed(101)
>>> pred.condpar.psim = mvrnorm(1000,mu=beta.cond,Sigma=vcov(m1)$cond)
>>> pred.cond.psim = X.cond %*% t(pred.condpar.psim)
>>> pred.zipar.psim = mvrnorm(1000,mu=beta.zi,Sigma=vcov(m1)$zi)
>>> pred.zi.psim = X.zi %*% t(pred.zipar.psim)
>>> pred.ucount.psim = exp(pred.cond.psim)*(1-plogis(pred.zi.psim))
>>> ci.ucount = t(apply(pred.ucount.psim,1,quantile,c(0.025,0.975)))
>>> ci.ucount = data.frame(ci.ucount)
>>> names(ci.ucount) = c("ucount.low","ucount.high")
>>> pred.ucount = data.frame(newdata0, pred.ucount, ci.ucount)
>>>
>>> For my upper CI, I get a value equal to Inf:
>>>
>>> Used_piNgers Effort  pred.ucount ucount.low ucount.high
>>> 1            Y      1 6.758889e-11 0.00000000         Inf
>>> 2            N      1 1.575418e-02 0.00223033   0.1096139
>>>
>>> Is the Inf caused by the very low variability of values in my dataset? I
>>> tried to lower the upper bound of the CI ci.ucount =
>>> t(apply(pred.ucount.psim,1,quantile,c(0.025,0.975))) and only when reaching
>>> 0.475 ci.ucount = t(apply(pred.ucount.psim,1,quantile,c(0.025,0.475))) I
>>> obtained:
>>>
>>> Used_piNgers Effort  pred.ucount ucount.low  ucount.high
>>> 1            Y      1 6.758889e-11 0.00000000 7.117465e+12
>>> 2            N      1 1.575418e-02 0.00223033 1.454579e-02
>>>
>>> I found a related post
>>> <https://stackoverflow.com/questions/38272798/bootstrap-confidence-interval-with-inf-in-final-estimates-boot-dplyr-package>
>>> but
>>> the explanation is not clear to me. I would like to publish these results
>>> and I would like to know:
>>>
>>>      1. is this a sign that something is wrong? if yes, what is it?
>>>      2. if nothing is wrong, what does the Inf mean and what's the best way
>>>      to report it and plot it in a publication?
>>>
>>>
>>> I also posted this question on Cross validated
>>> https://stats.stackexchange.com/questions/491196/bootstrap-confidence-interval-with-mvrnorm-upper-value-equal-to-inf
>>>
>>> Thanks,
>>> Alessandra
>>>
>>>        [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bz117 @end|ng |rom georgetown@edu  Thu Oct 15 04:16:24 2020
From: bz117 @end|ng |rom georgetown@edu (Bingsong Zhang)
Date: Wed, 14 Oct 2020 22:16:24 -0400
Subject: [R-sig-ME] glmmTMB installation
Message-ID: <CAJMQhGtgOqKBhJkHtrQjE8k4DRO8F_9JPEqEuCwo085yDoaHtw@mail.gmail.com>

*Hi all,*

*Can anyone help to check what might be the problem of installation? I
tried to install from CRAN and github, but both failed. Below is the
message I got:*

/usr/local/apps/R/4.0/site-library_4.0.0/RcppEigen/include/Eigen/src/Core/Assign.h:66:28:
  required from ?Derived& Eigen::MatrixBase<Derived>::operator=(const
Eigen::DenseBase<OtherDerived>&) [with OtherDerived =
Eigen::Product<Eigen::Map<const Eigen::Matrix<double, -1, -1>, 0,
Eigen::Stride<0, 0> >, Eigen::Map<const Eigen::Matrix<double, -1, -1>, 0,
Eigen::Stride<0, 0> >, 0>; Derived = Eigen::Map<Eigen::Matrix<double, -1,
-1>, 0, Eigen::Stride<0, 0> >]?
/spin1/home/linux/fanr/R/4.0/library/TMB/include/atomic_math.hpp:426:1:
required from ?void atomic::matmul(const CppAD::vector<Type>&,
CppAD::vector<Type>&) [with Double = double]?
/spin1/home/linux/fanr/R/4.0/library/TMB/include/atomic_math.hpp:426:1:
required from ?bool atomic::atomicmatmul<Type>::forward(size_t, size_t,
const CppAD::vector<bool>&, CppAD::vector<bool>&, const
CppAD::vector<Type>&, CppAD::vector<Type>&) [with Type = double; size_t =
long unsigned int]?
/spin1/home/linux/fanr/R/4.0/library/TMB/include/atomic_math.hpp:426:1:
required from here
/usr/local/apps/R/4.0/site-library_4.0.0/RcppEigen/include/Eigen/src/Core/CoreEvaluators.h:960:8:
warning: ignoring attributes on template argument
?Eigen::internal::packet_traits<double>::type? {aka ?__vector(2) double?}
[-Wignored-attributes]
g++: fatal error: Killed signal terminated program cc1plus
compilation terminated.
make: *** [glmmTMB.o] Error 1
ERROR: compilation failed for package ?glmmTMB?
* removing ?/spin1/home/linux/fanr/R/4.0/library/glmmTMB?

The downloaded source packages are in
        ?/tmp/RtmpofDpAq/downloaded_packages?
Warning message:
In install.packages("glmmTMB") :
  installation of package ?glmmTMB? had non-zero exit status

*There are many more actually, but these were the last part of the error
message.*

*Many thanks,*
*Bingsong*

	[[alternative HTML version deleted]]


From b|e|||@@|e@@@ndr@ @end|ng |rom gm@||@com  Thu Oct 15 22:38:01 2020
From: b|e|||@@|e@@@ndr@ @end|ng |rom gm@||@com (Alessandra Bielli)
Date: Thu, 15 Oct 2020 14:38:01 -0600
Subject: [R-sig-ME] 
 confidence intervals with mvrnorm - upper value equal to inf
In-Reply-To: <617833be-2f6b-888c-a32c-2538aa1e47f3@gmail.com>
References: <CA+6N3yX7jOYKLKjB3Hk_q_Ei4H+1bpoHZ9kcontZODPL+XO8xA@mail.gmail.com>
 <7c5eea74-0a54-a0b5-acb9-f163ed1bc26b@gmail.com>
 <CA+6N3yXUrH1A_oyJ0pnx9NR1Tq7nasox+zYH3jH9s_cYf+C+zQ@mail.gmail.com>
 <617833be-2f6b-888c-a32c-2538aa1e47f3@gmail.com>
Message-ID: <CA+6N3yViM1DNTDP4QDjp=+7D7_cYk5fhYrBuGF40Wp=+oKfodg@mail.gmail.com>

Thanks for the clarifications.

So if I understand right, model diagnostics can tell me if my model
parameters are multivariate normal. I think they are, see the dharma
diagnostic plot attached.

The values you requested:
 > X.cond[1,]
  (Intercept) Used_piNgersN
            1             0
>  beta.cond
  (Intercept) Used_piNgersN
    -19.77343      19.26693
> vcov(m1)$cond
              (Intercept) Used_piNgersN
(Intercept)     168344705    -168344704
Used_piNgersN  -168344704     168344705

I noted that STd.Error values in the conditional model are very high
as well (12974.8).
I run the same model but set family as nbinom2

m1 <- glmmTMB(Dolphins.TOT ~ Used_piNgers + offset(log(Effort)) +
(1|tripID), ziformula = ~1,   data=x, family = "nbinom2")

and the Inf value do not appear. Was it an overdispersion problem? Can
I use the negative binomial model instead?

Sorry, I have tried to simulate my data to provide you with more
information but I am not sure I am doing it correctly. The effort
varies in each trial and I believe it can affect the value of
Dolphins.TOT.

On Wed, Oct 14, 2020 at 7:24 PM Ben Bolker <bbolker at gmail.com> wrote:
>
>    A few clarifying points below.
>
> On 10/14/20 3:11 PM, Alessandra Bielli wrote:
> > Hi Ben
> >
> > That's a good point, my parameters are not multivariate normal.
> > But then, why was this method used in the Salamander example, where
> > data are zero inflated and so, I assume, not multivariate normal?
>
>    The multivariate normality refers to the sampling distribution of the
> *model parameters*, not to the distribution (marginal or conditional of
> the response variable).  In general the sampling distribution of the
> model parameters is multivariate normal if the data are "well enough
> behaved" (i.e., either the responses themselves are normal *or* there is
> enough data, and enough information in the data, for the log-likelihood
> to become quadratic in a sufficiently large neighborhood of the MLE ...)
>
>
> >
> > I haven't simulated the data to share yet, but the "Inf" first appears
> > at the line >pred.ucount.psim =
> > exp(pred.cond.psim)*(1-plogis(pred.zi.psim))
> > Only the first row, Used_piNgers=Y, shows "Inf".
>
>     Hmm.  That's a little surprising, it implies that pred.cond.psim is
> a large number (>700 or so, which for a log-scale parameter is huge).
> Can you show us X.cond[1,] , beta.cond, vcov(m1)$cond ?
> >
> > Thanks,
> > Alessandra
> >
> > On Sun, Oct 11, 2020 at 3:46 PM Ben Bolker <bbolker at gmail.com> wrote:
> >>
> >>     It's hard to troubleshoot this without a reproducible example. Unless
> >> the answer is obvious -- which it's not, to me -- the easiest way to
> >> troubleshoot is to work through the steps one at a time and see where
> >> the infinite values first appear.  Can you create such an example either
> >> by posting your data or by simulating data that looks like your data?
> >>
> >>     The posterior predictive simulation approach assumes that the
> >> sampling distributions of the parameters are multivariate normal, which
> >> is likely to be questionable in a low-information setting (which will be
> >> the case if you don't have very many non-zero values ...)
> >>
> >>
> >> On 10/10/20 7:28 AM, Alessandra Bielli wrote:
> >>> Dear list,
> >>>
> >>> I am trying to predict a value and CI for two different treatments from a
> >>> glmmTMB fitted model using posterior predictive simulations (mvrnorm
> >>> function in the MASS package) as in the Salamander example, Brooks 2017
> >>> appendix B
> >>> <https://www.biorxiv.org/content/biorxiv/suppl/2017/05/01/132753.DC1/132753-2.pdf>.
> >>> The dependent variable is a count, majority of values are zeros but some
> >>> positive values appear.
> >>>
> >>> m1 <- glmmTMB(Dolphins.TOT ~ Used_piNgers + offset(log(Effort)) +
> >>> (1|Trip_Code), ziformula =~1,
> >>>                 data=x, family = "truncated_poisson")
> >>>
> >>>       newdata0 = with(x,
> >>>                   expand.grid(
> >>>                     Used_piNgers = c("Y","N"),
> >>>                     Effort=1))
> >>>
> >>> X.cond = model.matrix(lme4::nobars(formula(m1)[-2]), newdata0)
> >>>
> >>> beta.cond = fixef(m1)$cond
> >>> pred.cond = X.cond %*% beta.cond
> >>> ziformula = m1$modelInfo$allForm$ziformula
> >>> X.zi = model.matrix(lme4::nobars(ziformula), newdata0)
> >>> beta.zi = fixef(m1)$zi
> >>> pred.zi = X.zi %*% beta.zi
> >>>
> >>> pred.ucount = exp(pred.cond)*(1-plogis(pred.zi))
> >>>
> >>>
> >>> set.seed(101)
> >>> pred.condpar.psim = mvrnorm(1000,mu=beta.cond,Sigma=vcov(m1)$cond)
> >>> pred.cond.psim = X.cond %*% t(pred.condpar.psim)
> >>> pred.zipar.psim = mvrnorm(1000,mu=beta.zi,Sigma=vcov(m1)$zi)
> >>> pred.zi.psim = X.zi %*% t(pred.zipar.psim)
> >>> pred.ucount.psim = exp(pred.cond.psim)*(1-plogis(pred.zi.psim))
> >>> ci.ucount = t(apply(pred.ucount.psim,1,quantile,c(0.025,0.975)))
> >>> ci.ucount = data.frame(ci.ucount)
> >>> names(ci.ucount) = c("ucount.low","ucount.high")
> >>> pred.ucount = data.frame(newdata0, pred.ucount, ci.ucount)
> >>>
> >>> For my upper CI, I get a value equal to Inf:
> >>>
> >>> Used_piNgers Effort  pred.ucount ucount.low ucount.high
> >>> 1            Y      1 6.758889e-11 0.00000000         Inf
> >>> 2            N      1 1.575418e-02 0.00223033   0.1096139
> >>>
> >>> Is the Inf caused by the very low variability of values in my dataset? I
> >>> tried to lower the upper bound of the CI ci.ucount =
> >>> t(apply(pred.ucount.psim,1,quantile,c(0.025,0.975))) and only when reaching
> >>> 0.475 ci.ucount = t(apply(pred.ucount.psim,1,quantile,c(0.025,0.475))) I
> >>> obtained:
> >>>
> >>> Used_piNgers Effort  pred.ucount ucount.low  ucount.high
> >>> 1            Y      1 6.758889e-11 0.00000000 7.117465e+12
> >>> 2            N      1 1.575418e-02 0.00223033 1.454579e-02
> >>>
> >>> I found a related post
> >>> <https://stackoverflow.com/questions/38272798/bootstrap-confidence-interval-with-inf-in-final-estimates-boot-dplyr-package>
> >>> but
> >>> the explanation is not clear to me. I would like to publish these results
> >>> and I would like to know:
> >>>
> >>>      1. is this a sign that something is wrong? if yes, what is it?
> >>>      2. if nothing is wrong, what does the Inf mean and what's the best way
> >>>      to report it and plot it in a publication?
> >>>
> >>>
> >>> I also posted this question on Cross validated
> >>> https://stats.stackexchange.com/questions/491196/bootstrap-confidence-interval-with-mvrnorm-upper-value-equal-to-inf
> >>>
> >>> Thanks,
> >>> Alessandra
> >>>
> >>>        [[alternative HTML version deleted]]
> >>>
> >>> _______________________________________________
> >>> R-sig-mixed-models at r-project.org mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>>
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbo|ker @end|ng |rom gm@||@com  Thu Oct 15 21:18:05 2020
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Thu, 15 Oct 2020 15:18:05 -0400
Subject: [R-sig-ME] 
 confidence intervals with mvrnorm - upper value equal to inf
In-Reply-To: <CA+6N3yViM1DNTDP4QDjp=+7D7_cYk5fhYrBuGF40Wp=+oKfodg@mail.gmail.com>
References: <CA+6N3yX7jOYKLKjB3Hk_q_Ei4H+1bpoHZ9kcontZODPL+XO8xA@mail.gmail.com>
 <7c5eea74-0a54-a0b5-acb9-f163ed1bc26b@gmail.com>
 <CA+6N3yXUrH1A_oyJ0pnx9NR1Tq7nasox+zYH3jH9s_cYf+C+zQ@mail.gmail.com>
 <617833be-2f6b-888c-a32c-2538aa1e47f3@gmail.com>
 <CA+6N3yViM1DNTDP4QDjp=+7D7_cYk5fhYrBuGF40Wp=+oKfodg@mail.gmail.com>
Message-ID: <17bdc53d-5ba7-872e-2aad-23053aed70e2@gmail.com>



On 10/15/20 4:38 PM, Alessandra Bielli wrote:
> Thanks for the clarifications.
> 
> So if I understand right, model diagnostics can tell me if my model
> parameters are multivariate normal. I think they are, see the dharma
> diagnostic plot attached.

    No, that's still not evaluating the multivariate normality of the 
sampling distribution of the model parameters.  Computing the likelihood 
profile is the main way to do that.
> 
> The values you requested:
>   > X.cond[1,]
>    (Intercept) Used_piNgersN
>              1             0
>>   beta.cond
>    (Intercept) Used_piNgersN
>      -19.77343      19.26693
>> vcov(m1)$cond
>                (Intercept) Used_piNgersN
> (Intercept)     168344705    -168344704
> Used_piNgersN  -168344704     168344705
> 
> I noted that STd.Error values in the conditional model are very high
> as well (12974.8).
> I run the same model but set family as nbinom2
> 
> m1 <- glmmTMB(Dolphins.TOT ~ Used_piNgers + offset(log(Effort)) +
> (1|tripID), ziformula = ~1,   data=x, family = "nbinom2")
> 
> and the Inf value do not appear. Was it an overdispersion problem? Can
> I use the negative binomial model instead?


   I would normally say this is an example of (quasi)complete separation 
<http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#penalizationhandling-complete-separation> 
(large beta values, ridiculous Wald standard errors)

    But it may be overdispersion as well (since it disappears with nbinom2).

    Why are you using a hurdle model in one case (truncated Poisson) and 
a zero-inflation model (*non*-truncated nbinom2) in the other?




> 
> Sorry, I have tried to simulate my data to provide you with more
> information but I am not sure I am doing it correctly. The effort
> varies in each trial and I believe it can affect the value of
> Dolphins.TOT.
> 
> On Wed, Oct 14, 2020 at 7:24 PM Ben Bolker <bbolker at gmail.com> wrote:
>>
>>     A few clarifying points below.
>>
>> On 10/14/20 3:11 PM, Alessandra Bielli wrote:
>>> Hi Ben
>>>
>>> That's a good point, my parameters are not multivariate normal.
>>> But then, why was this method used in the Salamander example, where
>>> data are zero inflated and so, I assume, not multivariate normal?
>>
>>     The multivariate normality refers to the sampling distribution of the
>> *model parameters*, not to the distribution (marginal or conditional of
>> the response variable).  In general the sampling distribution of the
>> model parameters is multivariate normal if the data are "well enough
>> behaved" (i.e., either the responses themselves are normal *or* there is
>> enough data, and enough information in the data, for the log-likelihood
>> to become quadratic in a sufficiently large neighborhood of the MLE ...)
>>
>>
>>>
>>> I haven't simulated the data to share yet, but the "Inf" first appears
>>> at the line >pred.ucount.psim =
>>> exp(pred.cond.psim)*(1-plogis(pred.zi.psim))
>>> Only the first row, Used_piNgers=Y, shows "Inf".
>>
>>      Hmm.  That's a little surprising, it implies that pred.cond.psim is
>> a large number (>700 or so, which for a log-scale parameter is huge).
>> Can you show us X.cond[1,] , beta.cond, vcov(m1)$cond ?
>>>
>>> Thanks,
>>> Alessandra
>>>
>>> On Sun, Oct 11, 2020 at 3:46 PM Ben Bolker <bbolker at gmail.com> wrote:
>>>>
>>>>      It's hard to troubleshoot this without a reproducible example. Unless
>>>> the answer is obvious -- which it's not, to me -- the easiest way to
>>>> troubleshoot is to work through the steps one at a time and see where
>>>> the infinite values first appear.  Can you create such an example either
>>>> by posting your data or by simulating data that looks like your data?
>>>>
>>>>      The posterior predictive simulation approach assumes that the
>>>> sampling distributions of the parameters are multivariate normal, which
>>>> is likely to be questionable in a low-information setting (which will be
>>>> the case if you don't have very many non-zero values ...)
>>>>
>>>>
>>>> On 10/10/20 7:28 AM, Alessandra Bielli wrote:
>>>>> Dear list,
>>>>>
>>>>> I am trying to predict a value and CI for two different treatments from a
>>>>> glmmTMB fitted model using posterior predictive simulations (mvrnorm
>>>>> function in the MASS package) as in the Salamander example, Brooks 2017
>>>>> appendix B
>>>>> <https://www.biorxiv.org/content/biorxiv/suppl/2017/05/01/132753.DC1/132753-2.pdf>.
>>>>> The dependent variable is a count, majority of values are zeros but some
>>>>> positive values appear.
>>>>>
>>>>> m1 <- glmmTMB(Dolphins.TOT ~ Used_piNgers + offset(log(Effort)) +
>>>>> (1|Trip_Code), ziformula =~1,
>>>>>                  data=x, family = "truncated_poisson")
>>>>>
>>>>>        newdata0 = with(x,
>>>>>                    expand.grid(
>>>>>                      Used_piNgers = c("Y","N"),
>>>>>                      Effort=1))
>>>>>
>>>>> X.cond = model.matrix(lme4::nobars(formula(m1)[-2]), newdata0)
>>>>>
>>>>> beta.cond = fixef(m1)$cond
>>>>> pred.cond = X.cond %*% beta.cond
>>>>> ziformula = m1$modelInfo$allForm$ziformula
>>>>> X.zi = model.matrix(lme4::nobars(ziformula), newdata0)
>>>>> beta.zi = fixef(m1)$zi
>>>>> pred.zi = X.zi %*% beta.zi
>>>>>
>>>>> pred.ucount = exp(pred.cond)*(1-plogis(pred.zi))
>>>>>
>>>>>
>>>>> set.seed(101)
>>>>> pred.condpar.psim = mvrnorm(1000,mu=beta.cond,Sigma=vcov(m1)$cond)
>>>>> pred.cond.psim = X.cond %*% t(pred.condpar.psim)
>>>>> pred.zipar.psim = mvrnorm(1000,mu=beta.zi,Sigma=vcov(m1)$zi)
>>>>> pred.zi.psim = X.zi %*% t(pred.zipar.psim)
>>>>> pred.ucount.psim = exp(pred.cond.psim)*(1-plogis(pred.zi.psim))
>>>>> ci.ucount = t(apply(pred.ucount.psim,1,quantile,c(0.025,0.975)))
>>>>> ci.ucount = data.frame(ci.ucount)
>>>>> names(ci.ucount) = c("ucount.low","ucount.high")
>>>>> pred.ucount = data.frame(newdata0, pred.ucount, ci.ucount)
>>>>>
>>>>> For my upper CI, I get a value equal to Inf:
>>>>>
>>>>> Used_piNgers Effort  pred.ucount ucount.low ucount.high
>>>>> 1            Y      1 6.758889e-11 0.00000000         Inf
>>>>> 2            N      1 1.575418e-02 0.00223033   0.1096139
>>>>>
>>>>> Is the Inf caused by the very low variability of values in my dataset? I
>>>>> tried to lower the upper bound of the CI ci.ucount =
>>>>> t(apply(pred.ucount.psim,1,quantile,c(0.025,0.975))) and only when reaching
>>>>> 0.475 ci.ucount = t(apply(pred.ucount.psim,1,quantile,c(0.025,0.475))) I
>>>>> obtained:
>>>>>
>>>>> Used_piNgers Effort  pred.ucount ucount.low  ucount.high
>>>>> 1            Y      1 6.758889e-11 0.00000000 7.117465e+12
>>>>> 2            N      1 1.575418e-02 0.00223033 1.454579e-02
>>>>>
>>>>> I found a related post
>>>>> <https://stackoverflow.com/questions/38272798/bootstrap-confidence-interval-with-inf-in-final-estimates-boot-dplyr-package>
>>>>> but
>>>>> the explanation is not clear to me. I would like to publish these results
>>>>> and I would like to know:
>>>>>
>>>>>       1. is this a sign that something is wrong? if yes, what is it?
>>>>>       2. if nothing is wrong, what does the Inf mean and what's the best way
>>>>>       to report it and plot it in a publication?
>>>>>
>>>>>
>>>>> I also posted this question on Cross validated
>>>>> https://stats.stackexchange.com/questions/491196/bootstrap-confidence-interval-with-mvrnorm-upper-value-equal-to-inf
>>>>>
>>>>> Thanks,
>>>>> Alessandra
>>>>>
>>>>>         [[alternative HTML version deleted]]
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bz117 @end|ng |rom georgetown@edu  Fri Oct 16 03:08:27 2020
From: bz117 @end|ng |rom georgetown@edu (Bingsong Zhang)
Date: Thu, 15 Oct 2020 21:08:27 -0400
Subject: [R-sig-ME] glmmTMB installation
In-Reply-To: <CAJMQhGtgOqKBhJkHtrQjE8k4DRO8F_9JPEqEuCwo085yDoaHtw@mail.gmail.com>
References: <CAJMQhGtgOqKBhJkHtrQjE8k4DRO8F_9JPEqEuCwo085yDoaHtw@mail.gmail.com>
Message-ID: <CAJMQhGuK8Q03aB8n+qvti5sQnMQZ4nfnX1aP40zcJ8YW-4JB-w@mail.gmail.com>

*Hi all,*

*Can anyone help to check what might be the problem of installation? I
tried to install from CRAN and github, but both failed. Below is the
message I got:*

/usr/local/apps/R/4.0/site-library_4.0.0/RcppEigen/include/Eigen/src/Core/Assign.h:66:28:
  required from ?Derived& Eigen::MatrixBase<Derived>::operator=(const
Eigen::DenseBase<OtherDerived>&) [with OtherDerived =
Eigen::Product<Eigen::Map<const Eigen::Matrix<double, -1, -1>, 0,
Eigen::Stride<0, 0> >, Eigen::Map<const Eigen::Matrix<double, -1, -1>, 0,
Eigen::Stride<0, 0> >, 0>; Derived = Eigen::Map<Eigen::Matrix<double, -1,
-1>, 0, Eigen::Stride<0, 0> >]?
/spin1/home/linux/fanr/R/4.0/library/TMB/include/atomic_math.hpp:426:1:
required from ?void atomic::matmul(const CppAD::vector<Type>&,
CppAD::vector<Type>&) [with Double = double]?
/spin1/home/linux/fanr/R/4.0/library/TMB/include/atomic_math.hpp:426:1:
required from ?bool atomic::atomicmatmul<Type>::forward(size_t, size_t,
const CppAD::vector<bool>&, CppAD::vector<bool>&, const
CppAD::vector<Type>&, CppAD::vector<Type>&) [with Type = double; size_t =
long unsigned int]?
/spin1/home/linux/fanr/R/4.0/library/TMB/include/atomic_math.hpp:426:1:
required from here
/usr/local/apps/R/4.0/site-library_4.0.0/RcppEigen/include/Eigen/src/Core/CoreEvaluators.h:960:8:
warning: ignoring attributes on template argument
?Eigen::internal::packet_traits<double>::type? {aka ?__vector(2) double?}
[-Wignored-attributes]
g++: fatal error: Killed signal terminated program cc1plus
compilation terminated.
make: *** [glmmTMB.o] Error 1
ERROR: compilation failed for package ?glmmTMB?
* removing ?/spin1/home/linux/fanr/R/4.0/library/glmmTMB?

The downloaded source packages are in
        ?/tmp/RtmpofDpAq/downloaded_packages?
Warning message:
In install.packages("glmmTMB") :
  installation of package ?glmmTMB? had non-zero exit status

*There are many more actually, but these were the last part of the error
message.*

*Many thanks,*
*Bingsong*

On Wed, Oct 14, 2020 at 10:16 PM Bingsong Zhang <bz117 at georgetown.edu>
wrote:

> *Hi all,*
>
> *Can anyone help to check what might be the problem of installation? I
> tried to install from CRAN and github, but both failed. Below is the
> message I got:*
>
> /usr/local/apps/R/4.0/site-library_4.0.0/RcppEigen/include/Eigen/src/Core/Assign.h:66:28:
>   required from ?Derived& Eigen::MatrixBase<Derived>::operator=(const
> Eigen::DenseBase<OtherDerived>&) [with OtherDerived =
> Eigen::Product<Eigen::Map<const Eigen::Matrix<double, -1, -1>, 0,
> Eigen::Stride<0, 0> >, Eigen::Map<const Eigen::Matrix<double, -1, -1>, 0,
> Eigen::Stride<0, 0> >, 0>; Derived = Eigen::Map<Eigen::Matrix<double, -1,
> -1>, 0, Eigen::Stride<0, 0> >]?
> /spin1/home/linux/fanr/R/4.0/library/TMB/include/atomic_math.hpp:426:1:
> required from ?void atomic::matmul(const CppAD::vector<Type>&,
> CppAD::vector<Type>&) [with Double = double]?
> /spin1/home/linux/fanr/R/4.0/library/TMB/include/atomic_math.hpp:426:1:
> required from ?bool atomic::atomicmatmul<Type>::forward(size_t, size_t,
> const CppAD::vector<bool>&, CppAD::vector<bool>&, const
> CppAD::vector<Type>&, CppAD::vector<Type>&) [with Type = double; size_t =
> long unsigned int]?
> /spin1/home/linux/fanr/R/4.0/library/TMB/include/atomic_math.hpp:426:1:
> required from here
> /usr/local/apps/R/4.0/site-library_4.0.0/RcppEigen/include/Eigen/src/Core/CoreEvaluators.h:960:8:
> warning: ignoring attributes on template argument
> ?Eigen::internal::packet_traits<double>::type? {aka ?__vector(2) double?}
> [-Wignored-attributes]
> g++: fatal error: Killed signal terminated program cc1plus
> compilation terminated.
> make: *** [glmmTMB.o] Error 1
> ERROR: compilation failed for package ?glmmTMB?
> * removing ?/spin1/home/linux/fanr/R/4.0/library/glmmTMB?
>
> The downloaded source packages are in
>         ?/tmp/RtmpofDpAq/downloaded_packages?
> Warning message:
> In install.packages("glmmTMB") :
>   installation of package ?glmmTMB? had non-zero exit status
>
> *There are many more actually, but these were the last part of the error
> message.*
>
> *Many thanks,*
> *Bingsong*
>

	[[alternative HTML version deleted]]


From @ndrew@r@john@on @end|ng |rom po@tgr@d@curt|n@edu@@u  Fri Oct 16 04:10:44 2020
From: @ndrew@r@john@on @end|ng |rom po@tgr@d@curt|n@edu@@u (Andrew Johnson)
Date: Fri, 16 Oct 2020 02:10:44 +0000
Subject: [R-sig-ME] glmmTMB installation
In-Reply-To: <CAJMQhGuK8Q03aB8n+qvti5sQnMQZ4nfnX1aP40zcJ8YW-4JB-w@mail.gmail.com>
References: <CAJMQhGtgOqKBhJkHtrQjE8k4DRO8F_9JPEqEuCwo085yDoaHtw@mail.gmail.com>
 <CAJMQhGuK8Q03aB8n+qvti5sQnMQZ4nfnX1aP40zcJ8YW-4JB-w@mail.gmail.com>
Message-ID: <PSBPR01MB3703E26EFBC11F46F236E547A3030@PSBPR01MB3703.apcprd01.prod.exchangelabs.com>

Hi Bingsong,

Can you open an issue over on the glmmTMB github: https://github.com/glmmTMB/glmmTMB/issues? It's a bit easier than troubleshooting over the list, and it's helpful to have the resolution available for others to find if they have a similar issue.

Cheers,
Andrew

Dr Andrew Johnson
BPsych(Hons), MBiostat, PhD, GStat.
Research Associate | School of Psychology

Curtin University 
Email | andrew.johnson at curtin.edu.au 
Web | www.curtin.edu.au 



CRICOS Provider Code 00301J 


-----Original Message-----
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> On Behalf Of Bingsong Zhang
Sent: Friday, 16 October 2020 9:08 AM
To: R-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] glmmTMB installation

*Hi all,*

*Can anyone help to check what might be the problem of installation? I tried to install from CRAN and github, but both failed. Below is the message I got:*

/usr/local/apps/R/4.0/site-library_4.0.0/RcppEigen/include/Eigen/src/Core/Assign.h:66:28:
  required from ?Derived& Eigen::MatrixBase<Derived>::operator=(const
Eigen::DenseBase<OtherDerived>&) [with OtherDerived = Eigen::Product<Eigen::Map<const Eigen::Matrix<double, -1, -1>, 0, Eigen::Stride<0, 0> >, Eigen::Map<const Eigen::Matrix<double, -1, -1>, 0, Eigen::Stride<0, 0> >, 0>; Derived = Eigen::Map<Eigen::Matrix<double, -1,
-1>, 0, Eigen::Stride<0, 0> >]?
/spin1/home/linux/fanr/R/4.0/library/TMB/include/atomic_math.hpp:426:1:
required from ?void atomic::matmul(const CppAD::vector<Type>&,
CppAD::vector<Type>&) [with Double = double]?
/spin1/home/linux/fanr/R/4.0/library/TMB/include/atomic_math.hpp:426:1:
required from ?bool atomic::atomicmatmul<Type>::forward(size_t, size_t, const CppAD::vector<bool>&, CppAD::vector<bool>&, const CppAD::vector<Type>&, CppAD::vector<Type>&) [with Type = double; size_t = long unsigned int]?
/spin1/home/linux/fanr/R/4.0/library/TMB/include/atomic_math.hpp:426:1:
required from here
/usr/local/apps/R/4.0/site-library_4.0.0/RcppEigen/include/Eigen/src/Core/CoreEvaluators.h:960:8:
warning: ignoring attributes on template argument ?Eigen::internal::packet_traits<double>::type? {aka ?__vector(2) double?} [-Wignored-attributes]
g++: fatal error: Killed signal terminated program cc1plus
compilation terminated.
make: *** [glmmTMB.o] Error 1
ERROR: compilation failed for package ?glmmTMB?
* removing ?/spin1/home/linux/fanr/R/4.0/library/glmmTMB?

The downloaded source packages are in
        ?/tmp/RtmpofDpAq/downloaded_packages?
Warning message:
In install.packages("glmmTMB") :
  installation of package ?glmmTMB? had non-zero exit status

*There are many more actually, but these were the last part of the error
message.*

*Many thanks,*
*Bingsong*

On Wed, Oct 14, 2020 at 10:16 PM Bingsong Zhang <bz117 at georgetown.edu>
wrote:

> *Hi all,*
>
> *Can anyone help to check what might be the problem of installation? I 
> tried to install from CRAN and github, but both failed. Below is the 
> message I got:*
>
> /usr/local/apps/R/4.0/site-library_4.0.0/RcppEigen/include/Eigen/src/Core/Assign.h:66:28:
>   required from ?Derived& Eigen::MatrixBase<Derived>::operator=(const
> Eigen::DenseBase<OtherDerived>&) [with OtherDerived = 
> Eigen::Product<Eigen::Map<const Eigen::Matrix<double, -1, -1>, 0, 
> Eigen::Stride<0, 0> >, Eigen::Map<const Eigen::Matrix<double, -1, -1>, 
> 0, Eigen::Stride<0, 0> >, 0>; Derived = 
> Eigen::Map<Eigen::Matrix<double, -1,
> -1>, 0, Eigen::Stride<0, 0> >]?
> /spin1/home/linux/fanr/R/4.0/library/TMB/include/atomic_math.hpp:426:1:
> required from ?void atomic::matmul(const CppAD::vector<Type>&,
> CppAD::vector<Type>&) [with Double = double]?
> /spin1/home/linux/fanr/R/4.0/library/TMB/include/atomic_math.hpp:426:1:
> required from ?bool atomic::atomicmatmul<Type>::forward(size_t, 
> size_t, const CppAD::vector<bool>&, CppAD::vector<bool>&, const 
> CppAD::vector<Type>&, CppAD::vector<Type>&) [with Type = double; 
> size_t = long unsigned int]?
> /spin1/home/linux/fanr/R/4.0/library/TMB/include/atomic_math.hpp:426:1:
> required from here
> /usr/local/apps/R/4.0/site-library_4.0.0/RcppEigen/include/Eigen/src/Core/CoreEvaluators.h:960:8:
> warning: ignoring attributes on template argument 
> ?Eigen::internal::packet_traits<double>::type? {aka ?__vector(2) 
> double?} [-Wignored-attributes]
> g++: fatal error: Killed signal terminated program cc1plus
> compilation terminated.
> make: *** [glmmTMB.o] Error 1
> ERROR: compilation failed for package ?glmmTMB?
> * removing ?/spin1/home/linux/fanr/R/4.0/library/glmmTMB?
>
> The downloaded source packages are in
>         ?/tmp/RtmpofDpAq/downloaded_packages?
> Warning message:
> In install.packages("glmmTMB") :
>   installation of package ?glmmTMB? had non-zero exit status
>
> *There are many more actually, but these were the last part of the 
> error
> message.*
>
> *Many thanks,*
> *Bingsong*
>

	[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

From bbo|ker @end|ng |rom gm@||@com  Fri Oct 16 04:13:39 2020
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Thu, 15 Oct 2020 22:13:39 -0400
Subject: [R-sig-ME] glmmTMB installation
In-Reply-To: <PSBPR01MB3703E26EFBC11F46F236E547A3030@PSBPR01MB3703.apcprd01.prod.exchangelabs.com>
References: <CAJMQhGtgOqKBhJkHtrQjE8k4DRO8F_9JPEqEuCwo085yDoaHtw@mail.gmail.com>
 <CAJMQhGuK8Q03aB8n+qvti5sQnMQZ4nfnX1aP40zcJ8YW-4JB-w@mail.gmail.com>
 <PSBPR01MB3703E26EFBC11F46F236E547A3030@PSBPR01MB3703.apcprd01.prod.exchangelabs.com>
Message-ID: <5f296bad-37af-3ab1-4565-bef3813160aa@gmail.com>

   I agree with Andrew.

   My best guess based on what I can see is that

* most of the warnings are irrelevant chaff (using 
CXXFLAGS+=-Wno-ignored-attributes in a .R/Makevars file helps enormously 
with this)
* the actual problem is running out of memory during compilation (in my 
experience this is the most common cause of out-of-the-blue 'killed' errors)

On 10/15/20 10:10 PM, Andrew Johnson wrote:
> Hi Bingsong,
> 
> Can you open an issue over on the glmmTMB github: https://github.com/glmmTMB/glmmTMB/issues? It's a bit easier than troubleshooting over the list, and it's helpful to have the resolution available for others to find if they have a similar issue.
> 
> Cheers,
> Andrew
> 
> Dr Andrew Johnson
> BPsych(Hons), MBiostat, PhD, GStat.
> Research Associate | School of Psychology
> 
> Curtin University
> Email | andrew.johnson at curtin.edu.au
> Web | www.curtin.edu.au
> 
> 
> 
> CRICOS Provider Code 00301J
> 
> 
> -----Original Message-----
> From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> On Behalf Of Bingsong Zhang
> Sent: Friday, 16 October 2020 9:08 AM
> To: R-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] glmmTMB installation
> 
> *Hi all,*
> 
> *Can anyone help to check what might be the problem of installation? I tried to install from CRAN and github, but both failed. Below is the message I got:*
> 
> /usr/local/apps/R/4.0/site-library_4.0.0/RcppEigen/include/Eigen/src/Core/Assign.h:66:28:
>    required from ?Derived& Eigen::MatrixBase<Derived>::operator=(const
> Eigen::DenseBase<OtherDerived>&) [with OtherDerived = Eigen::Product<Eigen::Map<const Eigen::Matrix<double, -1, -1>, 0, Eigen::Stride<0, 0> >, Eigen::Map<const Eigen::Matrix<double, -1, -1>, 0, Eigen::Stride<0, 0> >, 0>; Derived = Eigen::Map<Eigen::Matrix<double, -1,
> -1>, 0, Eigen::Stride<0, 0> >]?
> /spin1/home/linux/fanr/R/4.0/library/TMB/include/atomic_math.hpp:426:1:
> required from ?void atomic::matmul(const CppAD::vector<Type>&,
> CppAD::vector<Type>&) [with Double = double]?
> /spin1/home/linux/fanr/R/4.0/library/TMB/include/atomic_math.hpp:426:1:
> required from ?bool atomic::atomicmatmul<Type>::forward(size_t, size_t, const CppAD::vector<bool>&, CppAD::vector<bool>&, const CppAD::vector<Type>&, CppAD::vector<Type>&) [with Type = double; size_t = long unsigned int]?
> /spin1/home/linux/fanr/R/4.0/library/TMB/include/atomic_math.hpp:426:1:
> required from here
> /usr/local/apps/R/4.0/site-library_4.0.0/RcppEigen/include/Eigen/src/Core/CoreEvaluators.h:960:8:
> warning: ignoring attributes on template argument ?Eigen::internal::packet_traits<double>::type? {aka ?__vector(2) double?} [-Wignored-attributes]
> g++: fatal error: Killed signal terminated program cc1plus
> compilation terminated.
> make: *** [glmmTMB.o] Error 1
> ERROR: compilation failed for package ?glmmTMB?
> * removing ?/spin1/home/linux/fanr/R/4.0/library/glmmTMB?
> 
> The downloaded source packages are in
>          ?/tmp/RtmpofDpAq/downloaded_packages?
> Warning message:
> In install.packages("glmmTMB") :
>    installation of package ?glmmTMB? had non-zero exit status
> 
> *There are many more actually, but these were the last part of the error
> message.*
> 
> *Many thanks,*
> *Bingsong*
> 
> On Wed, Oct 14, 2020 at 10:16 PM Bingsong Zhang <bz117 at georgetown.edu>
> wrote:
> 
>> *Hi all,*
>>
>> *Can anyone help to check what might be the problem of installation? I
>> tried to install from CRAN and github, but both failed. Below is the
>> message I got:*
>>
>> /usr/local/apps/R/4.0/site-library_4.0.0/RcppEigen/include/Eigen/src/Core/Assign.h:66:28:
>>    required from ?Derived& Eigen::MatrixBase<Derived>::operator=(const
>> Eigen::DenseBase<OtherDerived>&) [with OtherDerived =
>> Eigen::Product<Eigen::Map<const Eigen::Matrix<double, -1, -1>, 0,
>> Eigen::Stride<0, 0> >, Eigen::Map<const Eigen::Matrix<double, -1, -1>,
>> 0, Eigen::Stride<0, 0> >, 0>; Derived =
>> Eigen::Map<Eigen::Matrix<double, -1,
>> -1>, 0, Eigen::Stride<0, 0> >]?
>> /spin1/home/linux/fanr/R/4.0/library/TMB/include/atomic_math.hpp:426:1:
>> required from ?void atomic::matmul(const CppAD::vector<Type>&,
>> CppAD::vector<Type>&) [with Double = double]?
>> /spin1/home/linux/fanr/R/4.0/library/TMB/include/atomic_math.hpp:426:1:
>> required from ?bool atomic::atomicmatmul<Type>::forward(size_t,
>> size_t, const CppAD::vector<bool>&, CppAD::vector<bool>&, const
>> CppAD::vector<Type>&, CppAD::vector<Type>&) [with Type = double;
>> size_t = long unsigned int]?
>> /spin1/home/linux/fanr/R/4.0/library/TMB/include/atomic_math.hpp:426:1:
>> required from here
>> /usr/local/apps/R/4.0/site-library_4.0.0/RcppEigen/include/Eigen/src/Core/CoreEvaluators.h:960:8:
>> warning: ignoring attributes on template argument
>> ?Eigen::internal::packet_traits<double>::type? {aka ?__vector(2)
>> double?} [-Wignored-attributes]
>> g++: fatal error: Killed signal terminated program cc1plus
>> compilation terminated.
>> make: *** [glmmTMB.o] Error 1
>> ERROR: compilation failed for package ?glmmTMB?
>> * removing ?/spin1/home/linux/fanr/R/4.0/library/glmmTMB?
>>
>> The downloaded source packages are in
>>          ?/tmp/RtmpofDpAq/downloaded_packages?
>> Warning message:
>> In install.packages("glmmTMB") :
>>    installation of package ?glmmTMB? had non-zero exit status
>>
>> *There are many more actually, but these were the last part of the
>> error
>> message.*
>>
>> *Many thanks,*
>> *Bingsong*
>>
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From don-|me4 @end|ng |rom |@|@@c@3-|nc@com  Fri Oct 16 18:32:11 2020
From: don-|me4 @end|ng |rom |@|@@c@3-|nc@com (Don Cohen)
Date: Fri, 16 Oct 2020 16:32:11 +0000
Subject: [R-sig-ME] aggregation of count data
Message-ID: <24457.51979.179554.866870@chmusic.org>


Let me know if there's a better place to post this question.
I don't think it really has anything to do with random effects,
though I am using random effects.

I'm using models that look like this:
count ~ covariate + offset(log(exposure)) + (1 | group)

The question is about how much to aggregate the data,
i.e., two data rows with the same group and covariates, like this
group A  covariate 0  exposure 4  count 3
      A            0           5        2
could be combined into one row:
group A  covariate 0  exposure 9  count 5

I'm convinced that if I use family=poisson then it doesn't matter
whether rows are aggregated, but if I use family nbinom2 (or probably
any other than poisson) it does.  That is, the model for the aggregated
data differs from the model for the unaggregated data.

What I'm looking for is some way to decide how much aggregation to do,
i.e., which model is "best" in terms of telling me something useful
about the data, or perhaps even the world from which it was collected.
Note that "best" here does not mean anything like AIC - that will
always be lower for more aggregated data.

Here's my guess about why the results are different and which results
are likely to be "better".  I'll be interested in any insight that can
be offered by experts who read this.  Also I'd like to know if there
are any references with discussion of this problem.

First, I think the reason the results do NOT differ for poisson is
that there's only one parameter to be estimated (average
count/exposure), and that parameter is the same regardless of how the
rows are aggregated.  Whereas other distributions are also estimating
some other parameter (overdispersion) and that's different for the
aggregated data and the unaggregated data.

I suspect that there might be many different aggregation choices that
tell you different things about the data, i.e., there's no one best
answer, and you should try different choices to find different patterns
in the data.  Here's my argument.

Consider an extreme case where there are many samples for only one
group and covariate, and we combine them all into one row.  This
provides no information on the overdispersion parameter.  It might as
well be poisson.

In the case where there are many different groups or perhaps if the
covariates have enough different values, even if most of the
aggregated data points have high count and exposure, this might allow
a good estimate of the overdispersion parameter, but I'm not convinced
of that.  (Any ideas on this?)

There is an opposite extreme that seems to have the same problem.  In
the data I started with, an individual (the grouping turns out to be
by individual) was observed for some amount of time, and whenever an
event of interest was observed that was noted.  For instance the data
could have been

 started observing at 10:01:00, event at 10:03:14, event at 10:03:29,
 stopped observing 10:11:15

Let's assume that all events are recorded with timestamps at one
second granularity and that it's impossible to have two events at the
same timestamp (for the same individual).  Then the opposite extreme
would be to model every second as a data point for that individual
during which the exposure was 1 second and the count was either zero
or one.

Two lines like those aggregated above are understood by the model to
be independent observations.  Well, not quite, since they have the
same group and covariate.  But within that group and covariate, and
then accounting for exposure, they are supposed to be independent
samples drawn from whatever distribution is specified, e.g., nbinom2.

That assumption with extreme disaggregation leads again to a poisson
distribution.  So if the events are NOT independent (i.e., the
distribution is NOT poisson) then it's important to not disaggregate
too far.

In all cases the information in danger of being lost is the fact that
at SOME time scales the events are not poisson.  And you have to
sample at those time scales to realize that.  So watching an
individual for 10 minutes at a time and reporting separate data points
for each 10 minute sample will tell you something about overdispersion
at the 10 minute time scale but might not tell much about
overdispersion at the time scale of days or seconds.

The data I have is mostly collected in 10 minute chunks, which would
be good for finding differences from poisson at the 10 minute scale
(or lower by disaggregating).  The 10 minute samples can be combined
to get data for days or months, but the sampling rate is irregular,
i.e., there might be only one 10 minute sample for one month and 20
for another month.  I suspect that by doing maximum aggregation I'm
actually getting an average signal for many different time scales,
since there's a wide range of exposures.


From j@de@ @end|ng |rom he@|th@uc@d@edu  Sun Oct 18 02:00:34 2020
From: j@de@ @end|ng |rom he@|th@uc@d@edu (Ades, James)
Date: Sun, 18 Oct 2020 00:00:34 +0000
Subject: [R-sig-ME] Pulling specific parameters from models to prevent
 exhausting memory.
Message-ID: <BY5PR19MB3859498E5E7D1EE81DFE7B38EA000@BY5PR19MB3859.namprd19.prod.outlook.com>

Hi all,

I'm modeling fMRI imaging data using lme4. There are 4 time points and roughly 550 subjects with 27,730 regions of interest (these are the variables). Since I have access to a super computer, my thought was to create a long dataset with a repeated measures of regions of interest per time point and then subjects over the 4 time points. I'm using the model below. I gather the regions of interest using the super computer because it ends up being roughly 70 million something observations. Timepoint is discrete and timepoint.nu is just numerical time point.

lmer(connectivity ~ roi * timepoint + (timepoint.nu|subjectID) + (timepoint.nu|subjectID:roi), na.action = 'na.exclude', control = lmerControl(optimizer = "nloptwrap", calc.derivs = FALSE), REML = FALSE, data)

I received back the following error: "cannot allocate vector of size 30206.2 GbExecution halted"

So I'm wondering how I can only pull the essential parameters I need (group means vs individual fixed effects) while modeling, such that the super computer can finish the job without exhausting the memory. I say group means because I will eventually be adding in covariates.

Also, the super computer rules are that the job must finish within two days. I'm not sure that this would, so I'm wondering whether there is any way to parallel code in lme4 such that I could make access of multiple cores and nodes.

I've included a slice of data here: https://drive.google.com/file/d/1mhTj6qZZ2nT35fXUuYG_ThQ-QtWbb-8L/view?usp=sharing

Thanks much,

James



	[[alternative HTML version deleted]]


From c@c@voeten @end|ng |rom hum@|e|denun|v@n|  Sun Oct 18 10:16:49 2020
From: c@c@voeten @end|ng |rom hum@|e|denun|v@n| (Voeten, C.C.)
Date: Sun, 18 Oct 2020 08:16:49 +0000
Subject: [R-sig-ME] Pulling specific parameters from models to prevent
 exhausting memory.
In-Reply-To: <BY5PR19MB3859498E5E7D1EE81DFE7B38EA000@BY5PR19MB3859.namprd19.prod.outlook.com>
References: <BY5PR19MB3859498E5E7D1EE81DFE7B38EA000@BY5PR19MB3859.namprd19.prod.outlook.com>
Message-ID: <118c97447f5a49b1b17d0604434944bf@hum.leidenuniv.nl>

Hi James,

You may have luck using mgcv::bam instead of lme4. It can also fit random-slopes models and is optimized for "big data", in terms of memory usage and computational efficiency. The modeling syntax is slightly different, though; the correct translation of lme4 random effects into mgcv's s(...,bs='re') terms depends on whether timepoint.nu is a covariate or a factor.

HTH,
Cesko

> -----Original Message-----
> From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> On
> Behalf Of Ades, James
> Sent: Sunday, October 18, 2020 2:01 AM
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] Pulling specific parameters from models to prevent
> exhausting memory.
> 
> Hi all,
> 
> I'm modeling fMRI imaging data using lme4. There are 4 time points and
> roughly 550 subjects with 27,730 regions of interest (these are the variables).
> Since I have access to a super computer, my thought was to create a long
> dataset with a repeated measures of regions of interest per time point and
> then subjects over the 4 time points. I'm using the model below. I gather the
> regions of interest using the super computer because it ends up being
> roughly 70 million something observations. Timepoint is discrete and
> timepoint.nu is just numerical time point.
> 
> lmer(connectivity ~ roi * timepoint + (timepoint.nu|subjectID) +
> (timepoint.nu|subjectID:roi), na.action = 'na.exclude', control =
> lmerControl(optimizer = "nloptwrap", calc.derivs = FALSE), REML = FALSE,
> data)
> 
> I received back the following error: "cannot allocate vector of size 30206.2
> GbExecution halted"
> 
> So I'm wondering how I can only pull the essential parameters I need (group
> means vs individual fixed effects) while modeling, such that the super
> computer can finish the job without exhausting the memory. I say group
> means because I will eventually be adding in covariates.
> 
> Also, the super computer rules are that the job must finish within two days.
> I'm not sure that this would, so I'm wondering whether there is any way to
> parallel code in lme4 such that I could make access of multiple cores and
> nodes.
> 
> I've included a slice of data here:
> https://drive.google.com/file/d/1mhTj6qZZ2nT35fXUuYG_ThQ-QtWbb-
> 8L/view?usp=sharing
> 
> Thanks much,
> 
> James
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

From j@de@ @end|ng |rom he@|th@uc@d@edu  Mon Oct 19 06:50:57 2020
From: j@de@ @end|ng |rom he@|th@uc@d@edu (Ades, James)
Date: Mon, 19 Oct 2020 04:50:57 +0000
Subject: [R-sig-ME] Pulling specific parameters from models to prevent
 exhausting memory.
In-Reply-To: <118c97447f5a49b1b17d0604434944bf@hum.leidenuniv.nl>
References: <BY5PR19MB3859498E5E7D1EE81DFE7B38EA000@BY5PR19MB3859.namprd19.prod.outlook.com>,
 <118c97447f5a49b1b17d0604434944bf@hum.leidenuniv.nl>
Message-ID: <BY5PR19MB3859AA476C4696AF0490A5ECEA1E0@BY5PR19MB3859.namprd19.prod.outlook.com>

Thanks, Cesko. I'll look into BAM.

James
________________________________
From: Voeten, C.C. <c.c.voeten at hum.leidenuniv.nl>
Sent: Sunday, October 18, 2020 1:16 AM
To: Ades, James <jades at health.ucsd.edu>; r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>
Subject: RE: Pulling specific parameters from models to prevent exhausting memory.

Hi James,

You may have luck using mgcv::bam instead of lme4. It can also fit random-slopes models and is optimized for "big data", in terms of memory usage and computational efficiency. The modeling syntax is slightly different, though; the correct translation of lme4 random effects into mgcv's s(...,bs='re') terms depends on whether timepoint.nu is a covariate or a factor.

HTH,
Cesko

> -----Original Message-----
> From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> On
> Behalf Of Ades, James
> Sent: Sunday, October 18, 2020 2:01 AM
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] Pulling specific parameters from models to prevent
> exhausting memory.
>
> Hi all,
>
> I'm modeling fMRI imaging data using lme4. There are 4 time points and
> roughly 550 subjects with 27,730 regions of interest (these are the variables).
> Since I have access to a super computer, my thought was to create a long
> dataset with a repeated measures of regions of interest per time point and
> then subjects over the 4 time points. I'm using the model below. I gather the
> regions of interest using the super computer because it ends up being
> roughly 70 million something observations. Timepoint is discrete and
> timepoint.nu is just numerical time point.
>
> lmer(connectivity ~ roi * timepoint + (timepoint.nu|subjectID) +
> (timepoint.nu|subjectID:roi), na.action = 'na.exclude', control =
> lmerControl(optimizer = "nloptwrap", calc.derivs = FALSE), REML = FALSE,
> data)
>
> I received back the following error: "cannot allocate vector of size 30206.2
> GbExecution halted"
>
> So I'm wondering how I can only pull the essential parameters I need (group
> means vs individual fixed effects) while modeling, such that the super
> computer can finish the job without exhausting the memory. I say group
> means because I will eventually be adding in covariates.
>
> Also, the super computer rules are that the job must finish within two days.
> I'm not sure that this would, so I'm wondering whether there is any way to
> parallel code in lme4 such that I could make access of multiple cores and
> nodes.
>
> I've included a slice of data here:
> https://drive.google.com/file/d/1mhTj6qZZ2nT35fXUuYG_ThQ-QtWbb-
> 8L/view?usp=sharing
>
> Thanks much,
>
> James
>
>
>
>        [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From @@|@h@d|n@|ot|| @end|ng |rom gm@||@com  Mon Oct 19 07:00:08 2020
From: @@|@h@d|n@|ot|| @end|ng |rom gm@||@com (Salahadin Lotfi)
Date: Mon, 19 Oct 2020 00:00:08 -0500
Subject: [R-sig-ME] Reporting den of df for f like AOV table using
 Sattertwaite's method
Message-ID: <CAJTPX_WPjYQibFU+mwi+Y5msUpM6Xvf8Vhq74Mi93+UQBfRMyw@mail.gmail.com>

Hi everyone,
I have run several MLM models with over 200,000 observations. I intend to
report f values calculated using lmerTest package for each model
(Sattertwaite's method). I am trying to learn best practices to report
denominators of df estimated by Sattertwaite's method as I am reporting
usual f(NumDF, DenDF)=xxx. The obtained den of df is pretty large and I am
not sure it does make sense to report 6 digits values. I have run several
of these models and it takes a big chunk of the result section if I keep
reporting 6 digits.
I am also aware that many researchers report beta/ES/t/z estimates,
however, it makes sense to report f values in the context of my study,
hence I am here with my question. :-)

What is the best practice when it comes to report pretty large DenDF of f
models?

Any input will be greatly appreciated.

Thanks,
Sala

	[[alternative HTML version deleted]]


From b|e|||@@|e@@@ndr@ @end|ng |rom gm@||@com  Tue Oct 20 00:39:02 2020
From: b|e|||@@|e@@@ndr@ @end|ng |rom gm@||@com (Alessandra Bielli)
Date: Mon, 19 Oct 2020 16:39:02 -0600
Subject: [R-sig-ME] 
 confidence intervals with mvrnorm - upper value equal to inf
In-Reply-To: <17bdc53d-5ba7-872e-2aad-23053aed70e2@gmail.com>
References: <CA+6N3yX7jOYKLKjB3Hk_q_Ei4H+1bpoHZ9kcontZODPL+XO8xA@mail.gmail.com>
 <7c5eea74-0a54-a0b5-acb9-f163ed1bc26b@gmail.com>
 <CA+6N3yXUrH1A_oyJ0pnx9NR1Tq7nasox+zYH3jH9s_cYf+C+zQ@mail.gmail.com>
 <617833be-2f6b-888c-a32c-2538aa1e47f3@gmail.com>
 <CA+6N3yViM1DNTDP4QDjp=+7D7_cYk5fhYrBuGF40Wp=+oKfodg@mail.gmail.com>
 <17bdc53d-5ba7-872e-2aad-23053aed70e2@gmail.com>
Message-ID: <CA+6N3yWKjoBV9jxSEQ-WvKgzN1p-L9NEj+tMMxCc_c=diMxARw@mail.gmail.com>

You are right, I missed the *truncated* in the nbinom2 model.
In principle, I wanted to use a hurdle model because we are talking
about how many individuals are entangled in a net, and some zeros are
caused by the present of a treatment (reducing entanglement) while
other zeros are caused by the absence of individuals in the water. I
thought a hurdle model would be appropriate.

I now tested both truncated and non truncated nbinom and poisson
models, and the non truncated poisson is the top model in terms of AIC
and its diagnostics plots are good.
            dAIC df
m1.zip   0.0  4
m1.nb   16.7 5
m1.zitp 17.7 4
m1.tnb  20.8 5

I get sensible CI values this time (pred_plot attached).
It seems to me that this model fits the data well, does it make sense
to use this instead of the hurdle model?
I have researched online about ways to compute the likelihood profile
for a zero inflated model, but I haven't found any help. Is there any
resource you'd recommend?

Going back to the Inf values, would (quasi) complete separation be
possible for models other than binomial, though? My response is not
binary, it is a count and I have some positive values different from
1.
I used the same code for the 4 model tested, and only the truncated
models (poisson and nbinom2) predict Inf CI values.

Have a nice start of the week!

Alessandra


On Thu, Oct 15, 2020 at 1:18 PM Ben Bolker <bbolker at gmail.com> wrote:
>
>
>
> On 10/15/20 4:38 PM, Alessandra Bielli wrote:
> > Thanks for the clarifications.
> >
> > So if I understand right, model diagnostics can tell me if my model
> > parameters are multivariate normal. I think they are, see the dharma
> > diagnostic plot attached.
>
>     No, that's still not evaluating the multivariate normality of the
> sampling distribution of the model parameters.  Computing the likelihood
> profile is the main way to do that.
> >
> > The values you requested:
> >   > X.cond[1,]
> >    (Intercept) Used_piNgersN
> >              1             0
> >>   beta.cond
> >    (Intercept) Used_piNgersN
> >      -19.77343      19.26693
> >> vcov(m1)$cond
> >                (Intercept) Used_piNgersN
> > (Intercept)     168344705    -168344704
> > Used_piNgersN  -168344704     168344705
> >
> > I noted that STd.Error values in the conditional model are very high
> > as well (12974.8).
> > I run the same model but set family as nbinom2
> >
> > m1 <- glmmTMB(Dolphins.TOT ~ Used_piNgers + offset(log(Effort)) +
> > (1|tripID), ziformula = ~1,   data=x, family = "nbinom2")
> >
> > and the Inf value do not appear. Was it an overdispersion problem? Can
> > I use the negative binomial model instead?
>
>
>    I would normally say this is an example of (quasi)complete separation
> <http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#penalizationhandling-complete-separation>
> (large beta values, ridiculous Wald standard errors)
>
>     But it may be overdispersion as well (since it disappears with nbinom2).
>
>     Why are you using a hurdle model in one case (truncated Poisson) and
> a zero-inflation model (*non*-truncated nbinom2) in the other?
>
>
>
>
> >
> > Sorry, I have tried to simulate my data to provide you with more
> > information but I am not sure I am doing it correctly. The effort
> > varies in each trial and I believe it can affect the value of
> > Dolphins.TOT.
> >
> > On Wed, Oct 14, 2020 at 7:24 PM Ben Bolker <bbolker at gmail.com> wrote:
> >>
> >>     A few clarifying points below.
> >>
> >> On 10/14/20 3:11 PM, Alessandra Bielli wrote:
> >>> Hi Ben
> >>>
> >>> That's a good point, my parameters are not multivariate normal.
> >>> But then, why was this method used in the Salamander example, where
> >>> data are zero inflated and so, I assume, not multivariate normal?
> >>
> >>     The multivariate normality refers to the sampling distribution of the
> >> *model parameters*, not to the distribution (marginal or conditional of
> >> the response variable).  In general the sampling distribution of the
> >> model parameters is multivariate normal if the data are "well enough
> >> behaved" (i.e., either the responses themselves are normal *or* there is
> >> enough data, and enough information in the data, for the log-likelihood
> >> to become quadratic in a sufficiently large neighborhood of the MLE ...)
> >>
> >>
> >>>
> >>> I haven't simulated the data to share yet, but the "Inf" first appears
> >>> at the line >pred.ucount.psim =
> >>> exp(pred.cond.psim)*(1-plogis(pred.zi.psim))
> >>> Only the first row, Used_piNgers=Y, shows "Inf".
> >>
> >>      Hmm.  That's a little surprising, it implies that pred.cond.psim is
> >> a large number (>700 or so, which for a log-scale parameter is huge).
> >> Can you show us X.cond[1,] , beta.cond, vcov(m1)$cond ?
> >>>
> >>> Thanks,
> >>> Alessandra
> >>>
> >>> On Sun, Oct 11, 2020 at 3:46 PM Ben Bolker <bbolker at gmail.com> wrote:
> >>>>
> >>>>      It's hard to troubleshoot this without a reproducible example. Unless
> >>>> the answer is obvious -- which it's not, to me -- the easiest way to
> >>>> troubleshoot is to work through the steps one at a time and see where
> >>>> the infinite values first appear.  Can you create such an example either
> >>>> by posting your data or by simulating data that looks like your data?
> >>>>
> >>>>      The posterior predictive simulation approach assumes that the
> >>>> sampling distributions of the parameters are multivariate normal, which
> >>>> is likely to be questionable in a low-information setting (which will be
> >>>> the case if you don't have very many non-zero values ...)
> >>>>
> >>>>
> >>>> On 10/10/20 7:28 AM, Alessandra Bielli wrote:
> >>>>> Dear list,
> >>>>>
> >>>>> I am trying to predict a value and CI for two different treatments from a
> >>>>> glmmTMB fitted model using posterior predictive simulations (mvrnorm
> >>>>> function in the MASS package) as in the Salamander example, Brooks 2017
> >>>>> appendix B
> >>>>> <https://www.biorxiv.org/content/biorxiv/suppl/2017/05/01/132753.DC1/132753-2.pdf>.
> >>>>> The dependent variable is a count, majority of values are zeros but some
> >>>>> positive values appear.
> >>>>>
> >>>>> m1 <- glmmTMB(Dolphins.TOT ~ Used_piNgers + offset(log(Effort)) +
> >>>>> (1|Trip_Code), ziformula =~1,
> >>>>>                  data=x, family = "truncated_poisson")
> >>>>>
> >>>>>        newdata0 = with(x,
> >>>>>                    expand.grid(
> >>>>>                      Used_piNgers = c("Y","N"),
> >>>>>                      Effort=1))
> >>>>>
> >>>>> X.cond = model.matrix(lme4::nobars(formula(m1)[-2]), newdata0)
> >>>>>
> >>>>> beta.cond = fixef(m1)$cond
> >>>>> pred.cond = X.cond %*% beta.cond
> >>>>> ziformula = m1$modelInfo$allForm$ziformula
> >>>>> X.zi = model.matrix(lme4::nobars(ziformula), newdata0)
> >>>>> beta.zi = fixef(m1)$zi
> >>>>> pred.zi = X.zi %*% beta.zi
> >>>>>
> >>>>> pred.ucount = exp(pred.cond)*(1-plogis(pred.zi))
> >>>>>
> >>>>>
> >>>>> set.seed(101)
> >>>>> pred.condpar.psim = mvrnorm(1000,mu=beta.cond,Sigma=vcov(m1)$cond)
> >>>>> pred.cond.psim = X.cond %*% t(pred.condpar.psim)
> >>>>> pred.zipar.psim = mvrnorm(1000,mu=beta.zi,Sigma=vcov(m1)$zi)
> >>>>> pred.zi.psim = X.zi %*% t(pred.zipar.psim)
> >>>>> pred.ucount.psim = exp(pred.cond.psim)*(1-plogis(pred.zi.psim))
> >>>>> ci.ucount = t(apply(pred.ucount.psim,1,quantile,c(0.025,0.975)))
> >>>>> ci.ucount = data.frame(ci.ucount)
> >>>>> names(ci.ucount) = c("ucount.low","ucount.high")
> >>>>> pred.ucount = data.frame(newdata0, pred.ucount, ci.ucount)
> >>>>>
> >>>>> For my upper CI, I get a value equal to Inf:
> >>>>>
> >>>>> Used_piNgers Effort  pred.ucount ucount.low ucount.high
> >>>>> 1            Y      1 6.758889e-11 0.00000000         Inf
> >>>>> 2            N      1 1.575418e-02 0.00223033   0.1096139
> >>>>>
> >>>>> Is the Inf caused by the very low variability of values in my dataset? I
> >>>>> tried to lower the upper bound of the CI ci.ucount =
> >>>>> t(apply(pred.ucount.psim,1,quantile,c(0.025,0.975))) and only when reaching
> >>>>> 0.475 ci.ucount = t(apply(pred.ucount.psim,1,quantile,c(0.025,0.475))) I
> >>>>> obtained:
> >>>>>
> >>>>> Used_piNgers Effort  pred.ucount ucount.low  ucount.high
> >>>>> 1            Y      1 6.758889e-11 0.00000000 7.117465e+12
> >>>>> 2            N      1 1.575418e-02 0.00223033 1.454579e-02
> >>>>>
> >>>>> I found a related post
> >>>>> <https://stackoverflow.com/questions/38272798/bootstrap-confidence-interval-with-inf-in-final-estimates-boot-dplyr-package>
> >>>>> but
> >>>>> the explanation is not clear to me. I would like to publish these results
> >>>>> and I would like to know:
> >>>>>
> >>>>>       1. is this a sign that something is wrong? if yes, what is it?
> >>>>>       2. if nothing is wrong, what does the Inf mean and what's the best way
> >>>>>       to report it and plot it in a publication?
> >>>>>
> >>>>>
> >>>>> I also posted this question on Cross validated
> >>>>> https://stats.stackexchange.com/questions/491196/bootstrap-confidence-interval-with-mvrnorm-upper-value-equal-to-inf
> >>>>>
> >>>>> Thanks,
> >>>>> Alessandra
> >>>>>
> >>>>>         [[alternative HTML version deleted]]
> >>>>>
> >>>>> _______________________________________________
> >>>>> R-sig-mixed-models at r-project.org mailing list
> >>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>>>>
> >>>>
> >>>> _______________________________________________
> >>>> R-sig-mixed-models at r-project.org mailing list
> >>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-------------- next part --------------
A non-text attachment was scrubbed...
Name: pred_plot.png
Type: image/png
Size: 5053 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20201019/ab1edfbf/attachment.png>

From bbo|ker @end|ng |rom gm@||@com  Mon Oct 19 17:26:47 2020
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Mon, 19 Oct 2020 11:26:47 -0400
Subject: [R-sig-ME] 
 confidence intervals with mvrnorm - upper value equal to inf
In-Reply-To: <CA+6N3yWKjoBV9jxSEQ-WvKgzN1p-L9NEj+tMMxCc_c=diMxARw@mail.gmail.com>
References: <CA+6N3yX7jOYKLKjB3Hk_q_Ei4H+1bpoHZ9kcontZODPL+XO8xA@mail.gmail.com>
 <7c5eea74-0a54-a0b5-acb9-f163ed1bc26b@gmail.com>
 <CA+6N3yXUrH1A_oyJ0pnx9NR1Tq7nasox+zYH3jH9s_cYf+C+zQ@mail.gmail.com>
 <617833be-2f6b-888c-a32c-2538aa1e47f3@gmail.com>
 <CA+6N3yViM1DNTDP4QDjp=+7D7_cYk5fhYrBuGF40Wp=+oKfodg@mail.gmail.com>
 <17bdc53d-5ba7-872e-2aad-23053aed70e2@gmail.com>
 <CA+6N3yWKjoBV9jxSEQ-WvKgzN1p-L9NEj+tMMxCc_c=diMxARw@mail.gmail.com>
Message-ID: <1829dc4e-0958-d59a-d661-3c4bc99cccfb@gmail.com>



On 10/19/20 6:39 PM, Alessandra Bielli wrote:
> You are right, I missed the *truncated* in the nbinom2 model.
> In principle, I wanted to use a hurdle model because we are talking
> about how many individuals are entangled in a net, and some zeros are
> caused by the present of a treatment (reducing entanglement) while
> other zeros are caused by the absence of individuals in the water. I
> thought a hurdle model would be appropriate.

    Honestly, this sounds to me more like a zero-inflated model than a 
hurdle model to me (ZI is appropriate when the zero observations are a 
*mixture* of different sources, 'structural' (absence of individuals, 
obs will always be zero) and 'sampling' (individuals are there but 
sometimes none are caught; zeros from this source are more frequent when 
the conditional catch rate is low due to the treatment).


> 
> I now tested both truncated and non truncated nbinom and poisson
> models, and the non truncated poisson is the top model in terms of AIC
> and its diagnostics plots are good.
>              dAIC df
> m1.zip   0.0  4
> m1.nb   16.7 5
> m1.zitp 17.7 4
> m1.tnb  20.8 5

    It's a little weird that the AIC differences are so big; if you were 
comparing e.g. ZIP to ZINB, the ZINB should be at worst 2 AIC units 
higher (since it uses one additional parameter [unless dispformula is 
being used] and the log-likelihood can't be lower)

> 
> I get sensible CI values this time (pred_plot attached).
> It seems to me that this model fits the data well, does it make sense
> to use this instead of the hurdle model?

  Sure (to me)

> I have researched online about ways to compute the likelihood profile
> for a zero inflated model, but I haven't found any help. Is there any
> resource you'd recommend?
> 
> Going back to the Inf values, would (quasi) complete separation be
> possible for models other than binomial, though? My response is not
> binary, it is a count and I have some positive values different from
> 1.
> I used the same code for the 4 model tested, and only the truncated
> models (poisson and nbinom2) predict Inf CI values.

   Something like complete separation could be possible, (1) because the 
zero-inflation gives a binary component; (2) if one treatment 
combination has all zeros in the Poisson component, then the log-mean is 
-Inf.

> 
> Have a nice start of the week!
> 
> Alessandra
> 
> 
> On Thu, Oct 15, 2020 at 1:18 PM Ben Bolker <bbolker at gmail.com> wrote:
>>
>>
>>
>> On 10/15/20 4:38 PM, Alessandra Bielli wrote:
>>> Thanks for the clarifications.
>>>
>>> So if I understand right, model diagnostics can tell me if my model
>>> parameters are multivariate normal. I think they are, see the dharma
>>> diagnostic plot attached.
>>
>>      No, that's still not evaluating the multivariate normality of the
>> sampling distribution of the model parameters.  Computing the likelihood
>> profile is the main way to do that.
>>>
>>> The values you requested:
>>>    > X.cond[1,]
>>>     (Intercept) Used_piNgersN
>>>               1             0
>>>>    beta.cond
>>>     (Intercept) Used_piNgersN
>>>       -19.77343      19.26693
>>>> vcov(m1)$cond
>>>                 (Intercept) Used_piNgersN
>>> (Intercept)     168344705    -168344704
>>> Used_piNgersN  -168344704     168344705
>>>
>>> I noted that STd.Error values in the conditional model are very high
>>> as well (12974.8).
>>> I run the same model but set family as nbinom2
>>>
>>> m1 <- glmmTMB(Dolphins.TOT ~ Used_piNgers + offset(log(Effort)) +
>>> (1|tripID), ziformula = ~1,   data=x, family = "nbinom2")
>>>
>>> and the Inf value do not appear. Was it an overdispersion problem? Can
>>> I use the negative binomial model instead?
>>
>>
>>     I would normally say this is an example of (quasi)complete separation
>> <http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#penalizationhandling-complete-separation>
>> (large beta values, ridiculous Wald standard errors)
>>
>>      But it may be overdispersion as well (since it disappears with nbinom2).
>>
>>      Why are you using a hurdle model in one case (truncated Poisson) and
>> a zero-inflation model (*non*-truncated nbinom2) in the other?
>>
>>
>>
>>
>>>
>>> Sorry, I have tried to simulate my data to provide you with more
>>> information but I am not sure I am doing it correctly. The effort
>>> varies in each trial and I believe it can affect the value of
>>> Dolphins.TOT.
>>>
>>> On Wed, Oct 14, 2020 at 7:24 PM Ben Bolker <bbolker at gmail.com> wrote:
>>>>
>>>>      A few clarifying points below.
>>>>
>>>> On 10/14/20 3:11 PM, Alessandra Bielli wrote:
>>>>> Hi Ben
>>>>>
>>>>> That's a good point, my parameters are not multivariate normal.
>>>>> But then, why was this method used in the Salamander example, where
>>>>> data are zero inflated and so, I assume, not multivariate normal?
>>>>
>>>>      The multivariate normality refers to the sampling distribution of the
>>>> *model parameters*, not to the distribution (marginal or conditional of
>>>> the response variable).  In general the sampling distribution of the
>>>> model parameters is multivariate normal if the data are "well enough
>>>> behaved" (i.e., either the responses themselves are normal *or* there is
>>>> enough data, and enough information in the data, for the log-likelihood
>>>> to become quadratic in a sufficiently large neighborhood of the MLE ...)
>>>>
>>>>
>>>>>
>>>>> I haven't simulated the data to share yet, but the "Inf" first appears
>>>>> at the line >pred.ucount.psim =
>>>>> exp(pred.cond.psim)*(1-plogis(pred.zi.psim))
>>>>> Only the first row, Used_piNgers=Y, shows "Inf".
>>>>
>>>>       Hmm.  That's a little surprising, it implies that pred.cond.psim is
>>>> a large number (>700 or so, which for a log-scale parameter is huge).
>>>> Can you show us X.cond[1,] , beta.cond, vcov(m1)$cond ?
>>>>>
>>>>> Thanks,
>>>>> Alessandra
>>>>>
>>>>> On Sun, Oct 11, 2020 at 3:46 PM Ben Bolker <bbolker at gmail.com> wrote:
>>>>>>
>>>>>>       It's hard to troubleshoot this without a reproducible example. Unless
>>>>>> the answer is obvious -- which it's not, to me -- the easiest way to
>>>>>> troubleshoot is to work through the steps one at a time and see where
>>>>>> the infinite values first appear.  Can you create such an example either
>>>>>> by posting your data or by simulating data that looks like your data?
>>>>>>
>>>>>>       The posterior predictive simulation approach assumes that the
>>>>>> sampling distributions of the parameters are multivariate normal, which
>>>>>> is likely to be questionable in a low-information setting (which will be
>>>>>> the case if you don't have very many non-zero values ...)
>>>>>>
>>>>>>
>>>>>> On 10/10/20 7:28 AM, Alessandra Bielli wrote:
>>>>>>> Dear list,
>>>>>>>
>>>>>>> I am trying to predict a value and CI for two different treatments from a
>>>>>>> glmmTMB fitted model using posterior predictive simulations (mvrnorm
>>>>>>> function in the MASS package) as in the Salamander example, Brooks 2017
>>>>>>> appendix B
>>>>>>> <https://www.biorxiv.org/content/biorxiv/suppl/2017/05/01/132753.DC1/132753-2.pdf>.
>>>>>>> The dependent variable is a count, majority of values are zeros but some
>>>>>>> positive values appear.
>>>>>>>
>>>>>>> m1 <- glmmTMB(Dolphins.TOT ~ Used_piNgers + offset(log(Effort)) +
>>>>>>> (1|Trip_Code), ziformula =~1,
>>>>>>>                   data=x, family = "truncated_poisson")
>>>>>>>
>>>>>>>         newdata0 = with(x,
>>>>>>>                     expand.grid(
>>>>>>>                       Used_piNgers = c("Y","N"),
>>>>>>>                       Effort=1))
>>>>>>>
>>>>>>> X.cond = model.matrix(lme4::nobars(formula(m1)[-2]), newdata0)
>>>>>>>
>>>>>>> beta.cond = fixef(m1)$cond
>>>>>>> pred.cond = X.cond %*% beta.cond
>>>>>>> ziformula = m1$modelInfo$allForm$ziformula
>>>>>>> X.zi = model.matrix(lme4::nobars(ziformula), newdata0)
>>>>>>> beta.zi = fixef(m1)$zi
>>>>>>> pred.zi = X.zi %*% beta.zi
>>>>>>>
>>>>>>> pred.ucount = exp(pred.cond)*(1-plogis(pred.zi))
>>>>>>>
>>>>>>>
>>>>>>> set.seed(101)
>>>>>>> pred.condpar.psim = mvrnorm(1000,mu=beta.cond,Sigma=vcov(m1)$cond)
>>>>>>> pred.cond.psim = X.cond %*% t(pred.condpar.psim)
>>>>>>> pred.zipar.psim = mvrnorm(1000,mu=beta.zi,Sigma=vcov(m1)$zi)
>>>>>>> pred.zi.psim = X.zi %*% t(pred.zipar.psim)
>>>>>>> pred.ucount.psim = exp(pred.cond.psim)*(1-plogis(pred.zi.psim))
>>>>>>> ci.ucount = t(apply(pred.ucount.psim,1,quantile,c(0.025,0.975)))
>>>>>>> ci.ucount = data.frame(ci.ucount)
>>>>>>> names(ci.ucount) = c("ucount.low","ucount.high")
>>>>>>> pred.ucount = data.frame(newdata0, pred.ucount, ci.ucount)
>>>>>>>
>>>>>>> For my upper CI, I get a value equal to Inf:
>>>>>>>
>>>>>>> Used_piNgers Effort  pred.ucount ucount.low ucount.high
>>>>>>> 1            Y      1 6.758889e-11 0.00000000         Inf
>>>>>>> 2            N      1 1.575418e-02 0.00223033   0.1096139
>>>>>>>
>>>>>>> Is the Inf caused by the very low variability of values in my dataset? I
>>>>>>> tried to lower the upper bound of the CI ci.ucount =
>>>>>>> t(apply(pred.ucount.psim,1,quantile,c(0.025,0.975))) and only when reaching
>>>>>>> 0.475 ci.ucount = t(apply(pred.ucount.psim,1,quantile,c(0.025,0.475))) I
>>>>>>> obtained:
>>>>>>>
>>>>>>> Used_piNgers Effort  pred.ucount ucount.low  ucount.high
>>>>>>> 1            Y      1 6.758889e-11 0.00000000 7.117465e+12
>>>>>>> 2            N      1 1.575418e-02 0.00223033 1.454579e-02
>>>>>>>
>>>>>>> I found a related post
>>>>>>> <https://stackoverflow.com/questions/38272798/bootstrap-confidence-interval-with-inf-in-final-estimates-boot-dplyr-package>
>>>>>>> but
>>>>>>> the explanation is not clear to me. I would like to publish these results
>>>>>>> and I would like to know:
>>>>>>>
>>>>>>>        1. is this a sign that something is wrong? if yes, what is it?
>>>>>>>        2. if nothing is wrong, what does the Inf mean and what's the best way
>>>>>>>        to report it and plot it in a publication?
>>>>>>>
>>>>>>>
>>>>>>> I also posted this question on Cross validated
>>>>>>> https://stats.stackexchange.com/questions/491196/bootstrap-confidence-interval-with-mvrnorm-upper-value-equal-to-inf
>>>>>>>
>>>>>>> Thanks,
>>>>>>> Alessandra
>>>>>>>
>>>>>>>          [[alternative HTML version deleted]]
>>>>>>>
>>>>>>> _______________________________________________
>>>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>>>
>>>>>>
>>>>>> _______________________________________________
>>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From jrhode@ @end|ng |rom ||||no|@@edu  Mon Oct 19 19:41:38 2020
From: jrhode@ @end|ng |rom ||||no|@@edu (Rhodes, Justin S)
Date: Mon, 19 Oct 2020 17:41:38 +0000
Subject: [R-sig-ME] problem with lme4 glmer
Message-ID: <CH2PR11MB42802A05A7675FE54B1A3248D61E0@CH2PR11MB4280.namprd11.prod.outlook.com>

Dear R project mixed models users:

We used "lmer4", "glmer" function see below.  I attached the data set.  The programs and results for SAS and R are shown below.  Results are incredibly different, and seem impossible to explain by differences in computational algorithms.  The estimates from SAS are reasonable, but the estimates from R are clearly wrong, based on looking at the simple data.  We realize that we are underpowered to estimate the random effect here, but it still should give reasonable estimates if it converges, right?  Can someone please help us figure this out?  Thanks very much for any information

R code:

#import data
Pole<-read.table("Pole.txt",header = TRUE)

#define factors
Pole$Color<-as.factor(Pole$Color)
Pole$Treatment<-as.factor(Pole$Treatment)
Pole$ID<-as.factor(Pole$ID)

#model statement
fm1<-glmer(Outcome ~ Eggs + Color + Treatment + (1|ID), family=binomial, data=Pole)

#results
summary(fm1)

                                               Estimate            Std. Error            z value                 Pr(>|z|)
(Intercept)                         -23.4673             12.4832                -1.880                                0.06012 .
Eggs                                    -0.0496                3.4036                 -0.015                  0.98837
Colorspotted                     36.0295               8.4055                  4.286                   1.82e-05 ***
Treatmentsharp                12.4964              4.1453                 3.015                    0.00257 **
---


SAS code:

proc genmod data=temp.Pole;
class ID Treatment Color;
model Outcome= Eggs Color Treatment/d=bin link=logit;
repeated subject=ID/type=cs;
run;

Analysis Of GEE Parameter Estimates
Empirical Standard Error Estimates
Parameter

Estimate
Standard
Error
95% Confidence Limits
Z
Pr > |Z|
Intercept

-1.0491
1.3990
-3.7911
1.6928
-0.75
0.4533
Eggs

-0.1071
0.4632
-1.0151
0.8008
-0.23
0.8171
Color
blue
1.5046
0.8476
-0.1567
3.1660
1.78
0.0759
Color
spot
0.0000
0.0000
0.0000
0.0000
.
.
Treatment
blunt
0.3908
0.2841
-0.1660
0.9476
1.38
0.1690
Treatment
sharp
0.0000
0.0000
0.0000
0.0000
.
.




Thanks very much for your help!!

Justin Rhodes
Professor
Department of Psychology
Beckman Institute

405 N Mathews Ave
Urbana, IL 61801

Affiliations:  Neuroscience Program, Program for Ecology, Evolution and Conservation Biology, Institute for Genomic Biology, Division of Nutritional Sciences

Email: jrhodes at illinois.edu<mailto:jrhodes at illinois.edu>
Phone: 217-265-0021

Website: http://rhodeslab.beckman.illinois.edu/


-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: Pole2.txt
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20201019/95448317/attachment.txt>

From th|erry@onke||nx @end|ng |rom |nbo@be  Mon Oct 19 19:58:29 2020
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Mon, 19 Oct 2020 19:58:29 +0200
Subject: [R-sig-ME] problem with lme4 glmer
In-Reply-To: <CH2PR11MB42802A05A7675FE54B1A3248D61E0@CH2PR11MB4280.namprd11.prod.outlook.com>
References: <CH2PR11MB42802A05A7675FE54B1A3248D61E0@CH2PR11MB4280.namprd11.prod.outlook.com>
Message-ID: <CAJuCY5zqrmP0d27LP7HJfUaL1NJNymSr6Ay4A9LEH6Rf3z+Etw@mail.gmail.com>

Dear Justin,

First of all you are comparing two different algorithms: GEE vs mixed
models. GEE estimates 'population average' estimates for the fixed effect.
The mixed models fixed effect refers to an average individual. Those will
be by definition different.

Very large estimates and standard errors indicate (quasi) complete
separation, leading to numerical instability. Rather a problem with the
data / model formulation than with the algorithm.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op ma 19 okt. 2020 om 19:46 schreef Rhodes, Justin S <jrhodes at illinois.edu>:

> Dear R project mixed models users:
>
> We used "lmer4", "glmer" function see below.  I attached the data set.
> The programs and results for SAS and R are shown below.  Results are
> incredibly different, and seem impossible to explain by differences in
> computational algorithms.  The estimates from SAS are reasonable, but the
> estimates from R are clearly wrong, based on looking at the simple data.
> We realize that we are underpowered to estimate the random effect here, but
> it still should give reasonable estimates if it converges, right?  Can
> someone please help us figure this out?  Thanks very much for any
> information
>
> R code:
>
> #import data
> Pole<-read.table("Pole.txt",header = TRUE)
>
> #define factors
> Pole$Color<-as.factor(Pole$Color)
> Pole$Treatment<-as.factor(Pole$Treatment)
> Pole$ID<-as.factor(Pole$ID)
>
> #model statement
> fm1<-glmer(Outcome ~ Eggs + Color + Treatment + (1|ID), family=binomial,
> data=Pole)
>
> #results
> summary(fm1)
>
>                                                Estimate            Std.
> Error            z value                 Pr(>|z|)
> (Intercept)                         -23.4673             12.4832
>       -1.880                                0.06012 .
> Eggs                                    -0.0496                3.4036
>            -0.015                  0.98837
> Colorspotted                     36.0295               8.4055
>     4.286                   1.82e-05 ***
> Treatmentsharp                12.4964              4.1453
>  3.015                    0.00257 **
> ---
>
>
> SAS code:
>
> proc genmod data=temp.Pole;
> class ID Treatment Color;
> model Outcome= Eggs Color Treatment/d=bin link=logit;
> repeated subject=ID/type=cs;
> run;
>
> Analysis Of GEE Parameter Estimates
> Empirical Standard Error Estimates
> Parameter
>
> Estimate
> Standard
> Error
> 95% Confidence Limits
> Z
> Pr > |Z|
> Intercept
>
> -1.0491
> 1.3990
> -3.7911
> 1.6928
> -0.75
> 0.4533
> Eggs
>
> -0.1071
> 0.4632
> -1.0151
> 0.8008
> -0.23
> 0.8171
> Color
> blue
> 1.5046
> 0.8476
> -0.1567
> 3.1660
> 1.78
> 0.0759
> Color
> spot
> 0.0000
> 0.0000
> 0.0000
> 0.0000
> .
> .
> Treatment
> blunt
> 0.3908
> 0.2841
> -0.1660
> 0.9476
> 1.38
> 0.1690
> Treatment
> sharp
> 0.0000
> 0.0000
> 0.0000
> 0.0000
> .
> .
>
>
>
>
> Thanks very much for your help!!
>
> Justin Rhodes
> Professor
> Department of Psychology
> Beckman Institute
>
> 405 N Mathews Ave
> Urbana, IL 61801
>
> Affiliations:  Neuroscience Program, Program for Ecology, Evolution and
> Conservation Biology, Institute for Genomic Biology, Division of
> Nutritional Sciences
>
> Email: jrhodes at illinois.edu<mailto:jrhodes at illinois.edu>
> Phone: 217-265-0021
>
> Website: http://rhodeslab.beckman.illinois.edu/
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From j@n@ve||m@ky @end|ng |rom y@hoo@de  Mon Oct 19 22:21:28 2020
From: j@n@ve||m@ky @end|ng |rom y@hoo@de (Jan anye Velimsky)
Date: Mon, 19 Oct 2020 20:21:28 +0000 (UTC)
Subject: [R-sig-ME] Marginal effect plot for an interaction effect from GLMM
 following a beta-distribution (glmmTMB)
References: <812925434.1862165.1603138888973.ref@mail.yahoo.com>
Message-ID: <812925434.1862165.1603138888973@mail.yahoo.com>


Dear R project mixedmodels users,

I am struggling to estimateand visualize the marginal effects (interaction effect) from a GLMM Model. 

We have been estimatinga GLMM model following a beta-distribution with the glmmTMB-package. The model consistsof factors influencing referendum turnout (range between 0-1) in german municipalities.The primary units of investigation are city districts nested in referendumsnested in cities.

Here an example model: 

model1 <-?glmmTMB (ref_turnout ~ unemployment + contestation+ experience_with_ref + (experience_with_ref *unemployment)+ (1| town/ referendum), family=list(family="beta", link ='logit'), data = ml)

?

Results example model: 

??????????????????????????????????????????????????????????????????????????????????????????????????Estimate ?????Std. Error ???zvalue ????Pr(>|z|)??? 

(Intercept)???????????????????????????????????????? ???????????????????????????????????????-0.583?????????????0.131??????-4.455? ???8.4e-06***

unemployment? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? -0.067 ?????????????0.002 ?????-30.397 ???< 2e-16 ***

contestation??????????????????????? ?????????????????????????????????????????????????????0.008 ?????????????0.003?? ?????2.398?????0.0165 *? 

experience_with_ref???????????????????????????????????????????????????????????????0.012 ?????????????0.052? ?????0.228? ????0.8200???

unemployment: experience_with_ref? ?? ? ? ? ? ? ? ? ? ? ? ? ? ? ? -0.001?????????????0.001 ?????-1.725? ????0.0845 .

?

The model contains an interaction effect with unemploymentper district and experience with referendums in the respective city. 

The aim is to visualize the interaction effects plotting the marginal effects.

With the "marginal_effects" command from the (margins-package) it was possible to estimate marginal effects,but no further summaries which are needed for plotting the model. ?The "margins" command does not work for the glmmTMBmodel. ?The idea is to have a simplemarginal effects plot for the interaction effect like this: ?


Thanks a lot for your help!
Jan Velimsky?

--?Jan Velimsky, MAResearch associate
Ludwig-Maximilians-Universit?t Munich
Geschwister-Scholl-Institut of Political Science (GSI)
Oettingenstrasse 67
D-80538 Munich?






-------------- next part --------------
A non-text attachment was scrubbed...
Name: 1603138302457blob.jpg
Type: image/png
Size: 3705 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20201019/abc6ace5/attachment-0001.png>

From bbo|ker @end|ng |rom gm@||@com  Mon Oct 19 22:54:05 2020
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Mon, 19 Oct 2020 16:54:05 -0400
Subject: [R-sig-ME] 
 Marginal effect plot for an interaction effect from GLMM
 following a beta-distribution (glmmTMB)
In-Reply-To: <812925434.1862165.1603138888973@mail.yahoo.com>
References: <812925434.1862165.1603138888973.ref@mail.yahoo.com>
 <812925434.1862165.1603138888973@mail.yahoo.com>
Message-ID: <b34e284c-22dc-81d3-e822-92a2d4ba3032@gmail.com>

   I always get confused about the different meanings of the term 
'marginal', but it's possible that the emmeans package will do what you 
want ...

On 10/19/20 4:21 PM, Jan anye Velimsky via R-sig-mixed-models wrote:
> 
> Dear R project mixedmodels users,
> 
> I am struggling to estimateand visualize the marginal effects (interaction effect) from a GLMM Model.
> 
> We have been estimatinga GLMM model following a beta-distribution with the glmmTMB-package. The model consistsof factors influencing referendum turnout (range between 0-1) in german municipalities.The primary units of investigation are city districts nested in referendumsnested in cities.
> 
> Here an example model:
> 
> model1 <-?glmmTMB (ref_turnout ~ unemployment + contestation+ experience_with_ref + (experience_with_ref *unemployment)+ (1| town/ referendum), family=list(family="beta", link ='logit'), data = ml)
> 
>   
> 
> Results example model:
> 
>  ??????????????????????????????????????????????????????????????????????????????????????????????????Estimate ?????Std. Error ???zvalue ????Pr(>|z|)
> 
> (Intercept)???????????????????????????????????????? ???????????????????????????????????????-0.583?????????????0.131??????-4.455? ???8.4e-06***
> 
> unemployment? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? -0.067 ?????????????0.002 ?????-30.397 ???< 2e-16 ***
> 
> contestation??????????????????????? ?????????????????????????????????????????????????????0.008 ?????????????0.003?? ?????2.398?????0.0165 *
> 
> experience_with_ref???????????????????????????????????????????????????????????????0.012 ?????????????0.052? ?????0.228? ????0.8200
> 
> unemployment: experience_with_ref? ?? ? ? ? ? ? ? ? ? ? ? ? ? ? ? -0.001?????????????0.001 ?????-1.725? ????0.0845 .
> 
>   
> 
> The model contains an interaction effect with unemploymentper district and experience with referendums in the respective city.
> 
> The aim is to visualize the interaction effects plotting the marginal effects.
> 
> With the "marginal_effects" command from the (margins-package) it was possible to estimate marginal effects,but no further summaries which are needed for plotting the model. ?The "margins" command does not work for the glmmTMBmodel. ?The idea is to have a simplemarginal effects plot for the interaction effect like this:
> 
> 
> Thanks a lot for your help!
> Jan Velimsky
> 
> --?Jan Velimsky, MAResearch associate
> Ludwig-Maximilians-Universit?t Munich
> Geschwister-Scholl-Institut of Political Science (GSI)
> Oettingenstrasse 67
> D-80538 Munich
> 
> 
> 
> 
> 
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From j|ox @end|ng |rom mcm@@ter@c@  Tue Oct 20 00:30:04 2020
From: j|ox @end|ng |rom mcm@@ter@c@ (John Fox)
Date: Mon, 19 Oct 2020 18:30:04 -0400
Subject: [R-sig-ME] 
 Marginal effect plot for an interaction effect from GLMM
 following a beta-distribution (glmmTMB)
In-Reply-To: <3321_1603138905_09JKLf9P024289_812925434.1862165.1603138888973@mail.yahoo.com>
References: <812925434.1862165.1603138888973.ref@mail.yahoo.com>
 <3321_1603138905_09JKLf9P024289_812925434.1862165.1603138888973@mail.yahoo.com>
Message-ID: <b3472308-636c-0fdf-1d4a-631988bc7376@mcmaster.ca>

Dear Jan,

Though I haven't tried it, I believe that the functions in the effects 
package should work with a glmmTMB model of this structure.

Note that you're using the * operator in the model formula incorrectly 
(i.e, redundantly) -- your fixed-effects specification is equivalent to 
ref_turnout ~ contestation + experience_with_ref * unemployment .

I hope this helps,
  John

John Fox, Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
web: https://socialsciences.mcmaster.ca/jfox/

On 2020-10-19 4:21 p.m., Jan anye Velimsky via R-sig-mixed-models wrote:
> 
> Dear R project mixedmodels users,
> 
> I am struggling to estimateand visualize the marginal effects 
> (interaction effect) from a GLMM Model.
> 
> We have been estimatinga GLMM model following a beta-distribution with 
> the glmmTMB-package. The model consistsof factors influencing referendum 
> turnout (range between 0-1) in german municipalities.The primary units 
> of investigation are city districts nested in referendumsnested in cities.
> 
> Here an example model:
> 
> model1 <-?glmmTMB (ref_turnout ~ unemployment + contestation+ 
> experience_with_ref + (experience_with_ref *unemployment)+ (1| town/ 
> referendum), family=list(family="beta", link ='logit'), data = ml)
> 
> 
> 
> Results example model:
> 
>  ??????????????????????????????????????????????????????????????????????????????????????????????????Estimate ?????Std. Error ???zvalue ????Pr(>|z|)
> 
> (Intercept)                                         
>  ???????????????????????????????????????-0.583?????????????0.131??????-4.455? ???8.4e-06***
> 
> unemployment                                                            
>  ? ? ? ? ? ? -0.067 ?????????????0.002 ?????-30.397 ???< 2e-16 ***
> 
> contestation                        
>  ?????????????????????????????????????????????????????0.008 
>  ?????????????0.003?? ?????2.398?????0.0165 *
> 
> experience_with_ref???????????????????????????????????????????????????????????????0.012 
>  ?????????????0.052? ?????0.228? ????0.8200
> 
> unemployment: experience_with_ref                                 
> -0.001?????????????0.001 ?????-1.725? ????0.0845 .
> 
> 
> 
> The model contains an interaction effect with unemploymentper district 
> and experience with referendums in the respective city.
> 
> The aim is to visualize the interaction effects plotting the marginal 
> effects.
> 
> With the "marginal_effects" command from the (margins-package) it was 
> possible to estimate marginal effects,but no further summaries which are 
> needed for plotting the model. ?The "margins" command does not work for 
> the glmmTMBmodel. ?The idea is to have a simplemarginal effects plot for 
> the interaction effect like this:
> 
> 
> Thanks a lot for your help!
> Jan Velimsky
> 
> --?Jan Velimsky, MAResearch associate
> Ludwig-Maximilians-Universit?t Munich
> Geschwister-Scholl-Institut of Political Science (GSI)
> Oettingenstrasse 67
> D-80538 Munich
> 
> 
> 
> 
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models 
> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>


From d@|uedecke @end|ng |rom uke@de  Tue Oct 20 08:54:21 2020
From: d@|uedecke @end|ng |rom uke@de (=?utf-8?Q?Daniel_L=C3=BCdecke?=)
Date: Tue, 20 Oct 2020 08:54:21 +0200
Subject: [R-sig-ME] 
 Marginal effect plot for an interaction effect from GLMM
 following a beta-distribution (glmmTMB)
In-Reply-To: <b34e284c-22dc-81d3-e822-92a2d4ba3032@gmail.com>
References: <812925434.1862165.1603138888973.ref@mail.yahoo.com>
 <812925434.1862165.1603138888973@mail.yahoo.com>
 <b34e284c-22dc-81d3-e822-92a2d4ba3032@gmail.com>
Message-ID: <000001d6a6ad$d6d821d0$84886570$@uke.de>

I share this confusion. I believe, the "margins" package computes *average* marginal effects, and the "emmeans" and "effects" packages average over factor levels for non-focal terms, so some people call this "marginal" effects / means.

You could also try the ggeffects package, which actually is a convenient wrapper for stats::predict() (via ggpredict()), effects::effect() (via ggeffect()) and emmeans::emmeans() (via ggemmeans()). ggeffects provides a consistent API / function design, so you can switch between the three underlying packages (predict, effects and emmeans) as needed, without changing the code.

There is a comprehensive online documentation: http://strengejacke.github.io/ggeffects

In your case, the simplest function call would be:

ggeffect(model1, c("unemployment", "experience_with_ref")) # uses effects package
ggemmeans(model1, c("unemployment", "experience_with_ref")) # uses emmeans package
ggpredict(model1, c("unemployment", "experience_with_ref")) # uses stats::predict

or:

plot(ggeffect(model1, c("unemployment", "experience_with_ref")))
plot(ggemmeans(model1, c("unemployment", "experience_with_ref")))
plot(ggpredict(model1, c("unemployment", "experience_with_ref")))

I think the function calls in "effects" and "emmeans" are quite similar, however, plotting capabilities may differ between packages.

Best
Daniel

-----Urspr?ngliche Nachricht-----
Von: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> Im Auftrag von Ben Bolker
Gesendet: Montag, 19. Oktober 2020 22:54
An: r-sig-mixed-models at r-project.org
Betreff: Re: [R-sig-ME] Marginal effect plot for an interaction effect from GLMM following a beta-distribution (glmmTMB)

   I always get confused about the different meanings of the term 
'marginal', but it's possible that the emmeans package will do what you 
want ...

On 10/19/20 4:21 PM, Jan anye Velimsky via R-sig-mixed-models wrote:
> 
> Dear R project mixedmodels users,
> 
> I am struggling to estimateand visualize the marginal effects (interaction effect) from a GLMM Model.
> 
> We have been estimatinga GLMM model following a beta-distribution with the glmmTMB-package. The model consistsof factors influencing referendum turnout (range between 0-1) in german municipalities.The primary units of investigation are city districts nested in referendumsnested in cities.
> 
> Here an example model:
> 
> model1 <- glmmTMB (ref_turnout ~ unemployment + contestation+ experience_with_ref + (experience_with_ref *unemployment)+ (1| town/ referendum), family=list(family="beta", link ='logit'), data = ml)
> 
>   
> 
> Results example model:
> 
>                                                                                                    Estimate      Std. Error    zvalue     Pr(>|z|)
> 
> (Intercept)                                                                                -0.583             0.131      -4.455     8.4e-06***
> 
> unemployment                                                                        -0.067              0.002      -30.397    < 2e-16 ***
> 
> contestation                                                                             0.008              0.003        2.398     0.0165 *
> 
> experience_with_ref                                                               0.012              0.052       0.228      0.8200
> 
> unemployment: experience_with_ref                                 -0.001             0.001      -1.725      0.0845 .
> 
>   
> 
> The model contains an interaction effect with unemploymentper district and experience with referendums in the respective city.
> 
> The aim is to visualize the interaction effects plotting the marginal effects.
> 
> With the "marginal_effects" command from the (margins-package) it was possible to estimate marginal effects,but no further summaries which are needed for plotting the model.  The "margins" command does not work for the glmmTMBmodel.  The idea is to have a simplemarginal effects plot for the interaction effect like this:
> 
> 
> Thanks a lot for your help!
> Jan Velimsky
> 
> -- Jan Velimsky, MAResearch associate
> Ludwig-Maximilians-Universit?t Munich
> Geschwister-Scholl-Institut of Political Science (GSI)
> Oettingenstrasse 67
> D-80538 Munich
> 
> 
> 
> 
> 
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

--

_____________________________________________________________________

Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen Rechts; Gerichtsstand: Hamburg | www.uke.de
Vorstandsmitglieder: Prof. Dr. Burkhard G?ke (Vorsitzender), Joachim Pr?l?, Prof. Dr. Blanche Schwappach-Pignataro, Marya Verdel
_____________________________________________________________________

SAVE PAPER - THINK BEFORE PRINTING

From th|erry@onke||nx @end|ng |rom |nbo@be  Tue Oct 20 10:29:29 2020
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Tue, 20 Oct 2020 10:29:29 +0200
Subject: [R-sig-ME] problem with lme4 glmer
In-Reply-To: <DM6PR11MB41224A09DB55E188F7B9B8D2DF1E0@DM6PR11MB4122.namprd11.prod.outlook.com>
References: <CH2PR11MB42802A05A7675FE54B1A3248D61E0@CH2PR11MB4280.namprd11.prod.outlook.com>
 <CAJuCY5zqrmP0d27LP7HJfUaL1NJNymSr6Ay4A9LEH6Rf3z+Etw@mail.gmail.com>
 <DM6PR11MB41224A09DB55E188F7B9B8D2DF1E0@DM6PR11MB4122.namprd11.prod.outlook.com>
Message-ID: <CAJuCY5w_0NetRnFD0TcrO3x+bbNV149rhRrtzce39=Zy-JFJUA@mail.gmail.com>

Dear Mark,

Please keep the mailing list in cc. There are a dozen R packages that fit
GEE models. Have a look at
https://cran.r-project.org/web/packages/available_packages_by_name.html and
search for GEE. I've used geepack in the past. Other packages might be more
suitable for your needs.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op ma 19 okt. 2020 om 20:04 schreef Hauber, Mark Erno <mhauber at illinois.edu
>:

> Thanks Thierry, for the quick respond.
>
> Is there a GEE equivalent in R, please? I work with Justin and I keep
> finding glmer as the solution which is not what we are after.
>
> Thanks,
>
> Best, Mark
> _______________________________
> Mark E. Hauber, Ph.D., D.Sc. (he/him)
> Harley Jones Van Cleave Professor of Host-Parasite Interactions
>
> Department of Evolution, Ecology, and Behavior;
> School of Integrative Biology;
> University of Illinois at Urbana-Champaign,
> 469 Morrill Hall, 505 S. Goodwin Avenue, Urbana, IL 61801, USA
> www.cowbirdlab.org @cowbirdlab
>
>
> ________________________________________
> From: Thierry Onkelinx <thierry.onkelinx at inbo.be>
> Sent: Monday, October 19, 2020 12:58 PM
> To: Rhodes, Justin S
> Cc: r-sig-mixed-models at r-project.org; Hauber, Mark Erno
> Subject: Re: [R-sig-ME] problem with lme4 glmer
>
> Dear Justin,
>
> First of all you are comparing two different algorithms: GEE vs mixed
> models. GEE estimates 'population average' estimates for the fixed effect.
> The mixed models fixed effect refers to an average individual. Those will
> be by definition different.
>
> Very large estimates and standard errors indicate (quasi) complete
> separation, leading to numerical instability. Rather a problem with the
> data / model formulation than with the algorithm.
>
> Best regards,
>
> ir. Thierry Onkelinx
> Statisticus / Statistician
>
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
> FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be<mailto:thierry.onkelinx at inbo.be>
> Havenlaan 88 bus 73, 1000 Brussel
> www.inbo.be<http://www.inbo.be>
>
>
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> ///////////////////////////////////////////////////////////////////////////////////////////
>
> [
> https://inbo-website-prd-532750756126.s3-eu-west-1.amazonaws.com/inbologoleeuw_nl.png
> ]<https://www.inbo.be>
>
>
> Op ma 19 okt. 2020 om 19:46 schreef Rhodes, Justin S <jrhodes at illinois.edu
> <mailto:jrhodes at illinois.edu>>:
> Dear R project mixed models users:
>
> We used "lmer4", "glmer" function see below.  I attached the data set.
> The programs and results for SAS and R are shown below.  Results are
> incredibly different, and seem impossible to explain by differences in
> computational algorithms.  The estimates from SAS are reasonable, but the
> estimates from R are clearly wrong, based on looking at the simple data.
> We realize that we are underpowered to estimate the random effect here, but
> it still should give reasonable estimates if it converges, right?  Can
> someone please help us figure this out?  Thanks very much for any
> information
>
> R code:
>
> #import data
> Pole<-read.table("Pole.txt",header = TRUE)
>
> #define factors
> Pole$Color<-as.factor(Pole$Color)
> Pole$Treatment<-as.factor(Pole$Treatment)
> Pole$ID<-as.factor(Pole$ID)
>
> #model statement
> fm1<-glmer(Outcome ~ Eggs + Color + Treatment + (1|ID), family=binomial,
> data=Pole)
>
> #results
> summary(fm1)
>
>                                                Estimate            Std.
> Error            z value                 Pr(>|z|)
> (Intercept)                         -23.4673             12.4832
>       -1.880                                0.06012 .
> Eggs                                    -0.0496                3.4036
>            -0.015                  0.98837
> Colorspotted                     36.0295               8.4055
>     4.286                   1.82e-05 ***
> Treatmentsharp                12.4964              4.1453
>  3.015                    0.00257 **
> ---
>
>
> SAS code:
>
> proc genmod data=temp.Pole;
> class ID Treatment Color;
> model Outcome= Eggs Color Treatment/d=bin link=logit;
> repeated subject=ID/type=cs;
> run;
>
> Analysis Of GEE Parameter Estimates
> Empirical Standard Error Estimates
> Parameter
>
> Estimate
> Standard
> Error
> 95% Confidence Limits
> Z
> Pr > |Z|
> Intercept
>
> -1.0491
> 1.3990
> -3.7911
> 1.6928
> -0.75
> 0.4533
> Eggs
>
> -0.1071
> 0.4632
> -1.0151
> 0.8008
> -0.23
> 0.8171
> Color
> blue
> 1.5046
> 0.8476
> -0.1567
> 3.1660
> 1.78
> 0.0759
> Color
> spot
> 0.0000
> 0.0000
> 0.0000
> 0.0000
> .
> .
> Treatment
> blunt
> 0.3908
> 0.2841
> -0.1660
> 0.9476
> 1.38
> 0.1690
> Treatment
> sharp
> 0.0000
> 0.0000
> 0.0000
> 0.0000
> .
> .
>
>
>
>
> Thanks very much for your help!!
>
> Justin Rhodes
> Professor
> Department of Psychology
> Beckman Institute
>
> 405 N Mathews Ave
> Urbana, IL 61801
>
> Affiliations:  Neuroscience Program, Program for Ecology, Evolution and
> Conservation Biology, Institute for Genomic Biology, Division of
> Nutritional Sciences
>
> Email: jrhodes at illinois.edu<mailto:jrhodes at illinois.edu><mailto:
> jrhodes at illinois.edu<mailto:jrhodes at illinois.edu>>
> Phone: 217-265-0021
>
> Website: http://rhodeslab.beckman.illinois.edu/
>
> _______________________________________________
> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org>
> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From bz117 @end|ng |rom georgetown@edu  Tue Oct 20 18:07:56 2020
From: bz117 @end|ng |rom georgetown@edu (Bingsong Zhang)
Date: Tue, 20 Oct 2020 12:07:56 -0400
Subject: [R-sig-ME] Installation of glmmTMB
Message-ID: <CAJMQhGu8p5oFVmgKv3ZYuLEpjEqcbswT6FbVU0HGFR5CVZ=0sA@mail.gmail.com>

Dear all,

Did anyone encounter installation problems in R? I can successfully install
glmmTMB in Rstudio, no matter from CRAN or github, but failed to do so in
R. Does anyone have idea what the problem is?

Best,
Bingsong

	[[alternative HTML version deleted]]


From ph||||p@@|d@y @end|ng |rom mp|@n|  Tue Oct 20 18:17:30 2020
From: ph||||p@@|d@y @end|ng |rom mp|@n| (Phillip Alday)
Date: Tue, 20 Oct 2020 18:17:30 +0200
Subject: [R-sig-ME] Installation of glmmTMB
In-Reply-To: <CAJMQhGu8p5oFVmgKv3ZYuLEpjEqcbswT6FbVU0HGFR5CVZ=0sA@mail.gmail.com>
References: <CAJMQhGu8p5oFVmgKv3ZYuLEpjEqcbswT6FbVU0HGFR5CVZ=0sA@mail.gmail.com>
Message-ID: <1da459e2-25e4-8959-d95b-d1a9377488c8@mpi.nl>

Can you show the output of sessionInfo() when run in vanilla R and RStudio?

Phillip

On 20/10/20 6:07 pm, Bingsong Zhang wrote:
> Dear all,
> 
> Did anyone encounter installation problems in R? I can successfully install
> glmmTMB in Rstudio, no matter from CRAN or github, but failed to do so in
> R. Does anyone have idea what the problem is?
> 
> Best,
> Bingsong
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From bz117 @end|ng |rom georgetown@edu  Tue Oct 20 18:18:03 2020
From: bz117 @end|ng |rom georgetown@edu (Bingsong Zhang)
Date: Tue, 20 Oct 2020 12:18:03 -0400
Subject: [R-sig-ME] Installation of glmmTMB
In-Reply-To: <CAJMQhGu8p5oFVmgKv3ZYuLEpjEqcbswT6FbVU0HGFR5CVZ=0sA@mail.gmail.com>
References: <CAJMQhGu8p5oFVmgKv3ZYuLEpjEqcbswT6FbVU0HGFR5CVZ=0sA@mail.gmail.com>
Message-ID: <CAJMQhGs22rHUMbWRz8-PD_JzHG4AD+ZV=C_YsxfVUtxb=6M7kA@mail.gmail.com>

Attached is the error message I got during installation. Just in case you
cannot see it, it said:

Rterm.exe - Entry Point Not Found
The procedure entry point EXTPTR_PTR could not be located in the dynamic
link library
C:\Users\fanr\Documents\R\R-4.0.0\library\Rcpp\libs\x64\Rcpp.dll.

On Tue, Oct 20, 2020 at 12:07 PM Bingsong Zhang <bz117 at georgetown.edu>
wrote:

> Dear all,
>
> Did anyone encounter installation problems in R? I can successfully
> install glmmTMB in Rstudio, no matter from CRAN or github, but failed to do
> so in R. Does anyone have idea what the problem is?
>
> Best,
> Bingsong
>

-------------- next part --------------
A non-text attachment was scrubbed...
Name: Error message.PNG
Type: image/png
Size: 10841 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20201020/e5eeac05/attachment-0001.png>

From d@n|e|@wr|ght @end|ng |rom uconn@edu  Tue Oct 20 18:56:37 2020
From: d@n|e|@wr|ght @end|ng |rom uconn@edu (Daniel Wright)
Date: Tue, 20 Oct 2020 12:56:37 -0400
Subject: [R-sig-ME] Convergence in glmmTMB but not glmer
Message-ID: <CA+9RvJChD=xiUFLs6SvgF6SHBVbOMfDfSGwD_U=CsxfLO6Litg@mail.gmail.com>

Hello,

I'm having convergence issues when using glmer in lme4, but not glmmTMB.
I'm running a series of generalized linear mixed effect models with poisson
distribution for ecological count data. I've included a random effect of
site (n = 26) in each model. All non-factor covariates are standardized.

The coefficient estimates of models run in glmer and glmmTMB are very
similar, but models run in glmer are having convergence issues. Any advice
would be appreciated, as I'm not sure if I can rely on my results from
glmmTMB.

Attached are example of outputs from glmmTMB vs glmer:

-- 
----------------------------------------------------------------
Daniel Wright, Graduate Research Assistant
Wildlife and Fisheries Conservation Center
Depart. Natural Resources and the Environment
<https://na01.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.nre.uconn.edu%2F&data=02%7C01%7C%7Cba31f0d133a24848eb3208d614ebb2f0%7C17f1a87e2a254eaab9df9d439034b080%7C0%7C0%7C636719399881397445&sdata=l3Lhp0QtBoRy5xpfyem%2FzYHmGZU0%2FHfPkq4mELHdRqE%3D&reserved=0>
University of Connecticut
Phone: 413-348-7388
Email: daniel.wright at uconn.edu

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: glmmTMBSummary.txt
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20201020/13d3c7d7/attachment.txt>

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: glmerSummary.txt
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20201020/13d3c7d7/attachment-0001.txt>

From th|erry@onke||nx @end|ng |rom |nbo@be  Tue Oct 20 19:16:06 2020
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Tue, 20 Oct 2020 19:16:06 +0200
Subject: [R-sig-ME] Convergence in glmmTMB but not glmer
In-Reply-To: <CA+9RvJChD=xiUFLs6SvgF6SHBVbOMfDfSGwD_U=CsxfLO6Litg@mail.gmail.com>
References: <CA+9RvJChD=xiUFLs6SvgF6SHBVbOMfDfSGwD_U=CsxfLO6Litg@mail.gmail.com>
Message-ID: <CAJuCY5wFX_cWr2AoenTUaYEaOyVDh2m4XfsMRFK-TUVqXacnHA@mail.gmail.com>

Dear Daniel,

Can you share the data? That would make it easier for us to inspect the
issue.

Best regards,

Thierry

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op di 20 okt. 2020 om 18:57 schreef Daniel Wright <daniel.wright at uconn.edu>:

> Hello,
>
> I'm having convergence issues when using glmer in lme4, but not glmmTMB.
> I'm running a series of generalized linear mixed effect models with poisson
> distribution for ecological count data. I've included a random effect of
> site (n = 26) in each model. All non-factor covariates are standardized.
>
> The coefficient estimates of models run in glmer and glmmTMB are very
> similar, but models run in glmer are having convergence issues. Any advice
> would be appreciated, as I'm not sure if I can rely on my results from
> glmmTMB.
>
> Attached are example of outputs from glmmTMB vs glmer:
>
> --
> ----------------------------------------------------------------
> Daniel Wright, Graduate Research Assistant
> Wildlife and Fisheries Conservation Center
> Depart. Natural Resources and the Environment
> <
> https://na01.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.nre.uconn.edu%2F&data=02%7C01%7C%7Cba31f0d133a24848eb3208d614ebb2f0%7C17f1a87e2a254eaab9df9d439034b080%7C0%7C0%7C636719399881397445&sdata=l3Lhp0QtBoRy5xpfyem%2FzYHmGZU0%2FHfPkq4mELHdRqE%3D&reserved=0
> >
> University of Connecticut
> Phone: 413-348-7388
> Email: daniel.wright at uconn.edu
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Tue Oct 20 19:32:50 2020
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Tue, 20 Oct 2020 13:32:50 -0400
Subject: [R-sig-ME] Convergence in glmmTMB but not glmer
In-Reply-To: <CA+9RvJChD=xiUFLs6SvgF6SHBVbOMfDfSGwD_U=CsxfLO6Litg@mail.gmail.com>
References: <CA+9RvJChD=xiUFLs6SvgF6SHBVbOMfDfSGwD_U=CsxfLO6Litg@mail.gmail.com>
Message-ID: <8621c16f-b58b-56a3-56b5-f9c2df4893f7@gmail.com>

   As Thierry says, the data would allow us to give a more detailed 
answer.  However:

   * the overall goodness-of-fit is very similar (differences of ~0.001 
or less on the deviance scale)

   * the random-effects std deve estimate is similar (2% difference)
   * the parameter estimates are quite similar
   * the standard errors of the coefficients look reasonable for glmmTMB 
and bogus for lme4 (in any case, if there's a disagreement I would be 
more suspicious of the platform that gave convergence warnings)

   There's also strong evidence of dispersion (deviance/resid df > 6); 
you should definitely do something to account for that (check for 
nonlinearity in residuals, switch to negative binomial, add an 
observation-level random effect ...)

    You might try the usual set of remedies for convergence problems 
(see ?troubleshooting, ?convergence in lme4), e.g. ?allFit.  Or try 
re-running the lme4 model with starting values set to the glmmTMB 
estimates.

   Overall, though, I would trust the glmmTMB results.

On 10/20/20 12:56 PM, Daniel Wright wrote:
> Hello,
> 
> I'm having convergence issues when using glmer in lme4, but not glmmTMB.
> I'm running a series of generalized linear mixed effect models with poisson
> distribution for ecological count data. I've included a random effect of
> site (n = 26) in each model. All non-factor covariates are standardized.
> 
> The coefficient estimates of models run in glmer and glmmTMB are very
> similar, but models run in glmer are having convergence issues. Any advice
> would be appreciated, as I'm not sure if I can rely on my results from
> glmmTMB.
> 
> Attached are example of outputs from glmmTMB vs glmer:
> 
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From bbo|ker @end|ng |rom gm@||@com  Tue Oct 20 19:35:59 2020
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Tue, 20 Oct 2020 13:35:59 -0400
Subject: [R-sig-ME] Installation of glmmTMB
In-Reply-To: <CAJMQhGs22rHUMbWRz8-PD_JzHG4AD+ZV=C_YsxfVUtxb=6M7kA@mail.gmail.com>
References: <CAJMQhGu8p5oFVmgKv3ZYuLEpjEqcbswT6FbVU0HGFR5CVZ=0sA@mail.gmail.com>
 <CAJMQhGs22rHUMbWRz8-PD_JzHG4AD+ZV=C_YsxfVUtxb=6M7kA@mail.gmail.com>
Message-ID: <68629dc3-986c-90d4-8677-dec998a5cb14@gmail.com>

   Do any other packages depending on Rcpp (e.g. lme4) install successfully?

    Googling the error finds this .. . 
https://rickpackblog.wordpress.com/2020/08/06/updating-rcpp-extprt_ptr-error/


On 10/20/20 12:18 PM, Bingsong Zhang wrote:
> Attached is the error message I got during installation. Just in case you
> cannot see it, it said:
> 
> Rterm.exe - Entry Point Not Found
> The procedure entry point EXTPTR_PTR could not be located in the dynamic
> link library
> C:\Users\fanr\Documents\R\R-4.0.0\library\Rcpp\libs\x64\Rcpp.dll.
> 
> On Tue, Oct 20, 2020 at 12:07 PM Bingsong Zhang <bz117 at georgetown.edu>
> wrote:
> 
>> Dear all,
>>
>> Did anyone encounter installation problems in R? I can successfully
>> install glmmTMB in Rstudio, no matter from CRAN or github, but failed to do
>> so in R. Does anyone have idea what the problem is?
>>
>> Best,
>> Bingsong
>>
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From th|erry@onke||nx @end|ng |rom |nbo@be  Tue Oct 20 20:02:09 2020
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Tue, 20 Oct 2020 20:02:09 +0200
Subject: [R-sig-ME] Convergence in glmmTMB but not glmer
In-Reply-To: <8621c16f-b58b-56a3-56b5-f9c2df4893f7@gmail.com>
References: <CA+9RvJChD=xiUFLs6SvgF6SHBVbOMfDfSGwD_U=CsxfLO6Litg@mail.gmail.com>
 <8621c16f-b58b-56a3-56b5-f9c2df4893f7@gmail.com>
Message-ID: <CAJuCY5yamk=qW=5UHDYMgDF=WfWP1AJhUxAhVuSd9wMptNKCjw@mail.gmail.com>

Daniel sent me the data in private.

A couple of remarks on the dataset.
- the response is non-integer. You'll need to convert it to integer (total
number) and use an appropriate offset term (log(nights)).
- make sure the factor covariate is a factor and not an integer.

Please see if that solves the problem. What happens if you use a nbinom
distribution as Ben suggested?

Personally, I don't like to "standardise" covariates. It makes them much
harder to interpret. I prefer to center to a more meaningful value than the
mean. And rescale it by changing the unit. E.g. Age ranges from 1 to 15
with mean 6.76. I'd use something like AgeC = (Age - 5) / 10. This gives a
similar range as the standardisation of Age. But one unit of AgeC
represents 10 year. And the intercept refers to Age = 5. Making the
parameters estimates easier to interpret IMHO.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op di 20 okt. 2020 om 19:40 schreef Ben Bolker <bbolker at gmail.com>:

>    As Thierry says, the data would allow us to give a more detailed
> answer.  However:
>
>    * the overall goodness-of-fit is very similar (differences of ~0.001
> or less on the deviance scale)
>
>    * the random-effects std deve estimate is similar (2% difference)
>    * the parameter estimates are quite similar
>    * the standard errors of the coefficients look reasonable for glmmTMB
> and bogus for lme4 (in any case, if there's a disagreement I would be
> more suspicious of the platform that gave convergence warnings)
>
>    There's also strong evidence of dispersion (deviance/resid df > 6);
> you should definitely do something to account for that (check for
> nonlinearity in residuals, switch to negative binomial, add an
> observation-level random effect ...)
>
>     You might try the usual set of remedies for convergence problems
> (see ?troubleshooting, ?convergence in lme4), e.g. ?allFit.  Or try
> re-running the lme4 model with starting values set to the glmmTMB
> estimates.
>
>    Overall, though, I would trust the glmmTMB results.
>
> On 10/20/20 12:56 PM, Daniel Wright wrote:
> > Hello,
> >
> > I'm having convergence issues when using glmer in lme4, but not glmmTMB.
> > I'm running a series of generalized linear mixed effect models with
> poisson
> > distribution for ecological count data. I've included a random effect of
> > site (n = 26) in each model. All non-factor covariates are standardized.
> >
> > The coefficient estimates of models run in glmer and glmmTMB are very
> > similar, but models run in glmer are having convergence issues. Any
> advice
> > would be appreciated, as I'm not sure if I can rely on my results from
> > glmmTMB.
> >
> > Attached are example of outputs from glmmTMB vs glmer:
> >
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Tue Oct 20 20:14:49 2020
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Tue, 20 Oct 2020 14:14:49 -0400
Subject: [R-sig-ME] Convergence in glmmTMB but not glmer
In-Reply-To: <CAJuCY5yamk=qW=5UHDYMgDF=WfWP1AJhUxAhVuSd9wMptNKCjw@mail.gmail.com>
References: <CA+9RvJChD=xiUFLs6SvgF6SHBVbOMfDfSGwD_U=CsxfLO6Litg@mail.gmail.com>
 <8621c16f-b58b-56a3-56b5-f9c2df4893f7@gmail.com>
 <CAJuCY5yamk=qW=5UHDYMgDF=WfWP1AJhUxAhVuSd9wMptNKCjw@mail.gmail.com>
Message-ID: <225ff648-a066-55d2-d665-a9c458a10b17@gmail.com>



On 10/20/20 2:02 PM, Thierry Onkelinx wrote:
> Daniel sent me the data in private.
> 
> A couple?of?remarks on the dataset.
> - the response is non-integer. You'll need to convert it to integer 
> (total number) and use an appropriate offset term (log(nights)).
> - make sure the factor covariate is a factor and not an integer.

   If the response is non-integer, that makes my comment about 
overdispersion not necessarily relevant (check again after re-fitting).

   It's often a good idea when using an offset such as log(nights) to 
*also* (alternatively) try using log(nights) as a predictor: using 
log(nights) assumes that the number of counts is strictly proportional 
to the number of nights measured (log(counts) ~ log(nights) + <stuff> -> 
counts ~ nights*exp(stuff) , whereas using log(counts) allows for some 
saturation effects (log(counts) ~ alpha*log(nights) + <stuff> -> counts 
~ nights^alpha*exp(stuff))


> 
> Please see if that solves the problem. What happens if you use a nbinom 
> distribution as Ben suggested?
> 
> Personally, I don't like to "standardise" covariates. It makes them much 
> harder to interpret. I prefer to center to a?more meaningful?value than 
> the mean. And rescale it by changing the unit. E.g. Age ranges from 1 to 
> 15 with mean 6.76. I'd use something like AgeC = (Age - 5) / 10. This 
> gives a similar range as the standardisation of Age. But one unit of 
> AgeC represents 10 year. And the intercept refers to Age = 5. Making the 
> parameters estimates easier to interpret IMHO.

   Yes, although 'strict' standardization (scaling by predictor SD or 
2*predictor SD) allows direct interpretation of the parameters as a kind 
of effect size (Schielzeth 2010), whereas 'human-friendly' 
standardization trades interpretability for the comparison of magnitudes 
being only an approximation.


> 
> Best regards,
> 
> ir. Thierry Onkelinx
> Statisticus / Statistician
> 
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE 
> AND FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be <mailto:thierry.onkelinx at inbo.be>
> Havenlaan 88 bus 73, 1000 Brussel
> www.inbo.be <http://www.inbo.be>
> 
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no more 
> than asking him to perform a post-mortem examination: he may be able to 
> say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not 
> ensure that a reasonable answer can be extracted from a given body of 
> data. ~ John Tukey
> ///////////////////////////////////////////////////////////////////////////////////////////
> 
> <https://www.inbo.be>
> 
> 
> Op di 20 okt. 2020 om 19:40 schreef Ben Bolker <bbolker at gmail.com 
> <mailto:bbolker at gmail.com>>:
> 
>      ? ?As Thierry says, the data would allow us to give a more detailed
>     answer.? However:
> 
>      ? ?* the overall goodness-of-fit is very similar (differences of
>     ~0.001
>     or less on the deviance scale)
> 
>      ? ?* the random-effects std deve estimate is similar (2% difference)
>      ? ?* the parameter estimates are quite similar
>      ? ?* the standard errors of the coefficients look reasonable for
>     glmmTMB
>     and bogus for lme4 (in any case, if there's a disagreement I would be
>     more suspicious of the platform that gave convergence warnings)
> 
>      ? ?There's also strong evidence of dispersion (deviance/resid df > 6);
>     you should definitely do something to account for that (check for
>     nonlinearity in residuals, switch to negative binomial, add an
>     observation-level random effect ...)
> 
>      ? ? You might try the usual set of remedies for convergence problems
>     (see ?troubleshooting, ?convergence in lme4), e.g. ?allFit.? Or try
>     re-running the lme4 model with starting values set to the glmmTMB
>     estimates.
> 
>      ? ?Overall, though, I would trust the glmmTMB results.
> 
>     On 10/20/20 12:56 PM, Daniel Wright wrote:
>      > Hello,
>      >
>      > I'm having convergence issues when using glmer in lme4, but not
>     glmmTMB.
>      > I'm running a series of generalized linear mixed effect models
>     with poisson
>      > distribution for ecological count data. I've included a random
>     effect of
>      > site (n = 26) in each model. All non-factor covariates are
>     standardized.
>      >
>      > The coefficient estimates of models run in glmer and glmmTMB are very
>      > similar, but models run in glmer are having convergence issues.
>     Any advice
>      > would be appreciated, as I'm not sure if I can rely on my results
>     from
>      > glmmTMB.
>      >
>      > Attached are example of outputs from glmmTMB vs glmer:
>      >
>      >
>      > _______________________________________________
>      > R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>      > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>      >
> 
>     _______________________________________________
>     R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From d@n|e|@wr|ght @end|ng |rom uconn@edu  Tue Oct 20 20:17:46 2020
From: d@n|e|@wr|ght @end|ng |rom uconn@edu (Daniel Wright)
Date: Tue, 20 Oct 2020 14:17:46 -0400
Subject: [R-sig-ME] Convergence in glmmTMB but not glmer
In-Reply-To: <CAJuCY5yamk=qW=5UHDYMgDF=WfWP1AJhUxAhVuSd9wMptNKCjw@mail.gmail.com>
References: <CA+9RvJChD=xiUFLs6SvgF6SHBVbOMfDfSGwD_U=CsxfLO6Litg@mail.gmail.com>
 <8621c16f-b58b-56a3-56b5-f9c2df4893f7@gmail.com>
 <CAJuCY5yamk=qW=5UHDYMgDF=WfWP1AJhUxAhVuSd9wMptNKCjw@mail.gmail.com>
Message-ID: <CA+9RvJDci-7aoQ=7d7mKRauMXGrwWpUNWF1KoxVtuN123O6=9Q@mail.gmail.com>

My mistake with sending the data privately. I've re-attached my dataset in
this email.

In my analysis, I included activity as an integer using the as.interger()
function in R.

I'll give nbinom a shot and see if that fixes the problem. Thanks for the
suggestions!

Dan

On Tue, Oct 20, 2020 at 2:10 PM Thierry Onkelinx via R-sig-mixed-models <
r-sig-mixed-models at r-project.org> wrote:

> *Message sent from a system outside of UConn.*
>
>
> Daniel sent me the data in private.
>
> A couple of remarks on the dataset.
> - the response is non-integer. You'll need to convert it to integer (total
> number) and use an appropriate offset term (log(nights)).
> - make sure the factor covariate is a factor and not an integer.
>
> Please see if that solves the problem. What happens if you use a nbinom
> distribution as Ben suggested?
>
> Personally, I don't like to "standardise" covariates. It makes them much
> harder to interpret. I prefer to center to a more meaningful value than the
> mean. And rescale it by changing the unit. E.g. Age ranges from 1 to 15
> with mean 6.76. I'd use something like AgeC = (Age - 5) / 10. This gives a
> similar range as the standardisation of Age. But one unit of AgeC
> represents 10 year. And the intercept refers to Age = 5. Making the
> parameters estimates easier to interpret IMHO.
>
> Best regards,
>
> ir. Thierry Onkelinx
> Statisticus / Statistician
>
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
> FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Havenlaan 88 bus 73, 1000 Brussel
> www.inbo.be
>
>
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> ///////////////////////////////////////////////////////////////////////////////////////////
>
> <https://www.inbo.be>
>
>
> Op di 20 okt. 2020 om 19:40 schreef Ben Bolker <bbolker at gmail.com>:
>
> >    As Thierry says, the data would allow us to give a more detailed
> > answer.  However:
> >
> >    * the overall goodness-of-fit is very similar (differences of ~0.001
> > or less on the deviance scale)
> >
> >    * the random-effects std deve estimate is similar (2% difference)
> >    * the parameter estimates are quite similar
> >    * the standard errors of the coefficients look reasonable for glmmTMB
> > and bogus for lme4 (in any case, if there's a disagreement I would be
> > more suspicious of the platform that gave convergence warnings)
> >
> >    There's also strong evidence of dispersion (deviance/resid df > 6);
> > you should definitely do something to account for that (check for
> > nonlinearity in residuals, switch to negative binomial, add an
> > observation-level random effect ...)
> >
> >     You might try the usual set of remedies for convergence problems
> > (see ?troubleshooting, ?convergence in lme4), e.g. ?allFit.  Or try
> > re-running the lme4 model with starting values set to the glmmTMB
> > estimates.
> >
> >    Overall, though, I would trust the glmmTMB results.
> >
> > On 10/20/20 12:56 PM, Daniel Wright wrote:
> > > Hello,
> > >
> > > I'm having convergence issues when using glmer in lme4, but not
> glmmTMB.
> > > I'm running a series of generalized linear mixed effect models with
> > poisson
> > > distribution for ecological count data. I've included a random effect
> of
> > > site (n = 26) in each model. All non-factor covariates are
> standardized.
> > >
> > > The coefficient estimates of models run in glmer and glmmTMB are very
> > > similar, but models run in glmer are having convergence issues. Any
> > advice
> > > would be appreciated, as I'm not sure if I can rely on my results from
> > > glmmTMB.
> > >
> > > Attached are example of outputs from glmmTMB vs glmer:
> > >
> > >
> > > _______________________________________________
> > > R-sig-mixed-models at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > >
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


-- 
----------------------------------------------------------------
Daniel Wright, Graduate Research Assistant
Wildlife and Fisheries Conservation Center
Depart. Natural Resources and the Environment
<https://na01.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.nre.uconn.edu%2F&data=02%7C01%7C%7Cba31f0d133a24848eb3208d614ebb2f0%7C17f1a87e2a254eaab9df9d439034b080%7C0%7C0%7C636719399881397445&sdata=l3Lhp0QtBoRy5xpfyem%2FzYHmGZU0%2FHfPkq4mELHdRqE%3D&reserved=0>
University of Connecticut
Phone: 413-348-7388
Email: daniel.wright at uconn.edu

From d@n|e|@wr|ght @end|ng |rom uconn@edu  Tue Oct 20 20:48:17 2020
From: d@n|e|@wr|ght @end|ng |rom uconn@edu (Daniel Wright)
Date: Tue, 20 Oct 2020 14:48:17 -0400
Subject: [R-sig-ME] Convergence in glmmTMB but not glmer
In-Reply-To: <225ff648-a066-55d2-d665-a9c458a10b17@gmail.com>
References: <CA+9RvJChD=xiUFLs6SvgF6SHBVbOMfDfSGwD_U=CsxfLO6Litg@mail.gmail.com>
 <8621c16f-b58b-56a3-56b5-f9c2df4893f7@gmail.com>
 <CAJuCY5yamk=qW=5UHDYMgDF=WfWP1AJhUxAhVuSd9wMptNKCjw@mail.gmail.com>
 <225ff648-a066-55d2-d665-a9c458a10b17@gmail.com>
Message-ID: <CA+9RvJCurJ+_-WREFrBodUyPztbzkZMFPkQo9gPchBoKiEth+Q@mail.gmail.com>

" It's often a good idea when using an offset such as log(nights) to
*also* (alternatively) try using log(nights) as a predictor: using
log(nights) assumes that the number of counts is strictly proportional
to the number of nights measured (log(counts) ~ log(nights) + <stuff> ->
counts ~ nights*exp(stuff) , whereas using log(counts) allows for some
saturation effects (log(counts) ~ alpha*log(nights) + <stuff> -> counts
~ nights^alpha*exp(stuff)) "

Hi Ben, to respond to your comments I think it's necessary to explain a bit
about my dataset if you don't mind.

For my research, I've collected bat acoustic data and invertebrate samples
at 26 regenerating forest stands. Each site was monitored for
a minimum of two consecutive nights, three when weather permitted. On the
last night of each monitoring effort, nocturnal flying insects
were collected to observe the influence of prey biomass on activity in
selected sites. In order to include invertebrate biomass as a variable
in model selection, I've averaged passes per night as a general measure of
activity and used the single night of invertebrate sampling
as representative of available prey biomass. Bat activity in a single
location is notoriously variable from night to night, and
activity is typically average across sampling nights.

I will try log(counts) as per your suggestion. I appreciate the help.

I apologize if my response was too lengthy for this platform. This will be
my first contribution to the e-sig-mixed-models mailing list.



On Tue, Oct 20, 2020 at 2:21 PM Ben Bolker <bbolker at gmail.com> wrote:

> *Message sent from a system outside of UConn.*
>
>
> On 10/20/20 2:02 PM, Thierry Onkelinx wrote:
> > Daniel sent me the data in private.
> >
> > A couple of remarks on the dataset.
> > - the response is non-integer. You'll need to convert it to integer
> > (total number) and use an appropriate offset term (log(nights)).
> > - make sure the factor covariate is a factor and not an integer.
>
>    If the response is non-integer, that makes my comment about
> overdispersion not necessarily relevant (check again after re-fitting).
>
>    It's often a good idea when using an offset such as log(nights) to
> *also* (alternatively) try using log(nights) as a predictor: using
> log(nights) assumes that the number of counts is strictly proportional
> to the number of nights measured (log(counts) ~ log(nights) + <stuff> ->
> counts ~ nights*exp(stuff) , whereas using log(counts) allows for some
> saturation effects (log(counts) ~ alpha*log(nights) + <stuff> -> counts
> ~ nights^alpha*exp(stuff))
>
>
> >
> > Please see if that solves the problem. What happens if you use a nbinom
> > distribution as Ben suggested?
> >
> > Personally, I don't like to "standardise" covariates. It makes them much
> > harder to interpret. I prefer to center to a more meaningful value than
> > the mean. And rescale it by changing the unit. E.g. Age ranges from 1 to
> > 15 with mean 6.76. I'd use something like AgeC = (Age - 5) / 10. This
> > gives a similar range as the standardisation of Age. But one unit of
> > AgeC represents 10 year. And the intercept refers to Age = 5. Making the
> > parameters estimates easier to interpret IMHO.
>
>    Yes, although 'strict' standardization (scaling by predictor SD or
> 2*predictor SD) allows direct interpretation of the parameters as a kind
> of effect size (Schielzeth 2010), whereas 'human-friendly'
> standardization trades interpretability for the comparison of magnitudes
> being only an approximation.
>
>
> >
> > Best regards,
> >
> > ir. Thierry Onkelinx
> > Statisticus / Statistician
> >
> > Vlaamse Overheid / Government of Flanders
> > INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
> > AND FOREST
> > Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> > thierry.onkelinx at inbo.be <mailto:thierry.onkelinx at inbo.be>
> > Havenlaan 88 bus 73, 1000 Brussel
> > www.inbo.be <http://www.inbo.be>
> >
> >
> ///////////////////////////////////////////////////////////////////////////////////////////
> > To call in the statistician after the experiment is done may be no more
> > than asking him to perform a post-mortem examination: he may be able to
> > say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> > The plural of anecdote is not data. ~ Roger Brinner
> > The combination of some data and an aching desire for an answer does not
> > ensure that a reasonable answer can be extracted from a given body of
> > data. ~ John Tukey
> >
> ///////////////////////////////////////////////////////////////////////////////////////////
> >
> > <https://www.inbo.be>
> >
> >
> > Op di 20 okt. 2020 om 19:40 schreef Ben Bolker <bbolker at gmail.com
> > <mailto:bbolker at gmail.com>>:
> >
> >         As Thierry says, the data would allow us to give a more detailed
> >     answer.  However:
> >
> >         * the overall goodness-of-fit is very similar (differences of
> >     ~0.001
> >     or less on the deviance scale)
> >
> >         * the random-effects std deve estimate is similar (2% difference)
> >         * the parameter estimates are quite similar
> >         * the standard errors of the coefficients look reasonable for
> >     glmmTMB
> >     and bogus for lme4 (in any case, if there's a disagreement I would be
> >     more suspicious of the platform that gave convergence warnings)
> >
> >         There's also strong evidence of dispersion (deviance/resid df >
> 6);
> >     you should definitely do something to account for that (check for
> >     nonlinearity in residuals, switch to negative binomial, add an
> >     observation-level random effect ...)
> >
> >          You might try the usual set of remedies for convergence problems
> >     (see ?troubleshooting, ?convergence in lme4), e.g. ?allFit.  Or try
> >     re-running the lme4 model with starting values set to the glmmTMB
> >     estimates.
> >
> >         Overall, though, I would trust the glmmTMB results.
> >
> >     On 10/20/20 12:56 PM, Daniel Wright wrote:
> >      > Hello,
> >      >
> >      > I'm having convergence issues when using glmer in lme4, but not
> >     glmmTMB.
> >      > I'm running a series of generalized linear mixed effect models
> >     with poisson
> >      > distribution for ecological count data. I've included a random
> >     effect of
> >      > site (n = 26) in each model. All non-factor covariates are
> >     standardized.
> >      >
> >      > The coefficient estimates of models run in glmer and glmmTMB are
> very
> >      > similar, but models run in glmer are having convergence issues.
> >     Any advice
> >      > would be appreciated, as I'm not sure if I can rely on my results
> >     from
> >      > glmmTMB.
> >      >
> >      > Attached are example of outputs from glmmTMB vs glmer:
> >      >
> >      >
> >      > _______________________________________________
> >      > R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org> mailing list
> >      > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >      >
> >
> >     _______________________________________________
> >     R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org> mailing list
> >     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


-- 
----------------------------------------------------------------
Daniel Wright, Graduate Research Assistant
Wildlife and Fisheries Conservation Center
Depart. Natural Resources and the Environment
<https://na01.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.nre.uconn.edu%2F&data=02%7C01%7C%7Cba31f0d133a24848eb3208d614ebb2f0%7C17f1a87e2a254eaab9df9d439034b080%7C0%7C0%7C636719399881397445&sdata=l3Lhp0QtBoRy5xpfyem%2FzYHmGZU0%2FHfPkq4mELHdRqE%3D&reserved=0>
University of Connecticut
Phone: 413-348-7388
Email: daniel.wright at uconn.edu

	[[alternative HTML version deleted]]


From bz117 @end|ng |rom georgetown@edu  Tue Oct 20 22:42:53 2020
From: bz117 @end|ng |rom georgetown@edu (Bingsong Zhang)
Date: Tue, 20 Oct 2020 16:42:53 -0400
Subject: [R-sig-ME] Installation of glmmTMB
In-Reply-To: <68629dc3-986c-90d4-8677-dec998a5cb14@gmail.com>
References: <CAJMQhGu8p5oFVmgKv3ZYuLEpjEqcbswT6FbVU0HGFR5CVZ=0sA@mail.gmail.com>
 <CAJMQhGs22rHUMbWRz8-PD_JzHG4AD+ZV=C_YsxfVUtxb=6M7kA@mail.gmail.com>
 <68629dc3-986c-90d4-8677-dec998a5cb14@gmail.com>
Message-ID: <CAJMQhGu13v3dLxa+0EHxMa-t5JoA=noyRjs2uTeiyHjDXqkZ7Q@mail.gmail.com>

Yes, lme4 is OK.

On Tue, Oct 20, 2020 at 1:40 PM Ben Bolker <bbolker at gmail.com> wrote:

>    Do any other packages depending on Rcpp (e.g. lme4) install
> successfully?
>
>     Googling the error finds this .. .
>
> https://rickpackblog.wordpress.com/2020/08/06/updating-rcpp-extprt_ptr-error/
>
>
> On 10/20/20 12:18 PM, Bingsong Zhang wrote:
> > Attached is the error message I got during installation. Just in case you
> > cannot see it, it said:
> >
> > Rterm.exe - Entry Point Not Found
> > The procedure entry point EXTPTR_PTR could not be located in the dynamic
> > link library
> > C:\Users\fanr\Documents\R\R-4.0.0\library\Rcpp\libs\x64\Rcpp.dll.
> >
> > On Tue, Oct 20, 2020 at 12:07 PM Bingsong Zhang <bz117 at georgetown.edu>
> > wrote:
> >
> >> Dear all,
> >>
> >> Did anyone encounter installation problems in R? I can successfully
> >> install glmmTMB in Rstudio, no matter from CRAN or github, but failed
> to do
> >> so in R. Does anyone have idea what the problem is?
> >>
> >> Best,
> >> Bingsong
> >>
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From mo|||eebrook@ @end|ng |rom gm@||@com  Wed Oct 21 15:48:12 2020
From: mo|||eebrook@ @end|ng |rom gm@||@com (Mollie Brooks)
Date: Wed, 21 Oct 2020 15:48:12 +0200
Subject: [R-sig-ME] Convergence in glmmTMB but not glmer
In-Reply-To: <CA+9RvJCurJ+_-WREFrBodUyPztbzkZMFPkQo9gPchBoKiEth+Q@mail.gmail.com>
References: <CA+9RvJChD=xiUFLs6SvgF6SHBVbOMfDfSGwD_U=CsxfLO6Litg@mail.gmail.com>
 <8621c16f-b58b-56a3-56b5-f9c2df4893f7@gmail.com>
 <CAJuCY5yamk=qW=5UHDYMgDF=WfWP1AJhUxAhVuSd9wMptNKCjw@mail.gmail.com>
 <225ff648-a066-55d2-d665-a9c458a10b17@gmail.com>
 <CA+9RvJCurJ+_-WREFrBodUyPztbzkZMFPkQo9gPchBoKiEth+Q@mail.gmail.com>
Message-ID: <C298D487-FED5-465C-94AB-783899E02041@gmail.com>



> On 20Oct 2020, at 20:48, Daniel Wright <daniel.wright at uconn.edu> wrote:
> 
> " It's often a good idea when using an offset such as log(nights) to
> *also* (alternatively) try using log(nights) as a predictor: using
> log(nights) assumes that the number of counts is strictly proportional
> to the number of nights measured (log(counts) ~ log(nights) + <stuff> ->
> counts ~ nights*exp(stuff) , whereas using log(counts) allows for some
> saturation effects (log(counts) ~ alpha*log(nights) + <stuff> -> counts
> ~ nights^alpha*exp(stuff)) "
> 
> Hi Ben, to respond to your comments I think it's necessary to explain a bit
> about my dataset if you don't mind.
> 
> For my research, I've collected bat acoustic data and invertebrate samples
> at 26 regenerating forest stands. Each site was monitored for
> a minimum of two consecutive nights, three when weather permitted. On the
> last night of each monitoring effort, nocturnal flying insects
> were collected to observe the influence of prey biomass on activity in
> selected sites. In order to include invertebrate biomass as a variable
> in model selection, I've averaged passes per night as a general measure of
> activity and used the single night of invertebrate sampling
> as representative of available prey biomass. Bat activity in a single
> location is notoriously variable from night to night, and
> activity is typically average across sampling nights.
> 
> I will try log(counts) as per your suggestion. I appreciate the help.

Was there possibly a miscommunication here? I think Ben was just using log(counts) in reference to math, not the formula. 
Continue to use counts as the response, but try log(nights) as a predictor rather than offset.

cheers,
Mollie

> 
> I apologize if my response was too lengthy for this platform. This will be
> my first contribution to the e-sig-mixed-models mailing list.
> 
> 
> 
> On Tue, Oct 20, 2020 at 2:21 PM Ben Bolker <bbolker at gmail.com> wrote:
> 
>> *Message sent from a system outside of UConn.*
>> 
>> 
>> On 10/20/20 2:02 PM, Thierry Onkelinx wrote:
>>> Daniel sent me the data in private.
>>> 
>>> A couple of remarks on the dataset.
>>> - the response is non-integer. You'll need to convert it to integer
>>> (total number) and use an appropriate offset term (log(nights)).
>>> - make sure the factor covariate is a factor and not an integer.
>> 
>>   If the response is non-integer, that makes my comment about
>> overdispersion not necessarily relevant (check again after re-fitting).
>> 
>>   It's often a good idea when using an offset such as log(nights) to
>> *also* (alternatively) try using log(nights) as a predictor: using
>> log(nights) assumes that the number of counts is strictly proportional
>> to the number of nights measured (log(counts) ~ log(nights) + <stuff> ->
>> counts ~ nights*exp(stuff) , whereas using log(counts) allows for some
>> saturation effects (log(counts) ~ alpha*log(nights) + <stuff> -> counts
>> ~ nights^alpha*exp(stuff))
>> 
>> 
>>> 
>>> Please see if that solves the problem. What happens if you use a nbinom
>>> distribution as Ben suggested?
>>> 
>>> Personally, I don't like to "standardise" covariates. It makes them much
>>> harder to interpret. I prefer to center to a more meaningful value than
>>> the mean. And rescale it by changing the unit. E.g. Age ranges from 1 to
>>> 15 with mean 6.76. I'd use something like AgeC = (Age - 5) / 10. This
>>> gives a similar range as the standardisation of Age. But one unit of
>>> AgeC represents 10 year. And the intercept refers to Age = 5. Making the
>>> parameters estimates easier to interpret IMHO.
>> 
>>   Yes, although 'strict' standardization (scaling by predictor SD or
>> 2*predictor SD) allows direct interpretation of the parameters as a kind
>> of effect size (Schielzeth 2010), whereas 'human-friendly'
>> standardization trades interpretability for the comparison of magnitudes
>> being only an approximation.
>> 
>> 
>>> 
>>> Best regards,
>>> 
>>> ir. Thierry Onkelinx
>>> Statisticus / Statistician
>>> 
>>> Vlaamse Overheid / Government of Flanders
>>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
>>> AND FOREST
>>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
>>> thierry.onkelinx at inbo.be <mailto:thierry.onkelinx at inbo.be>
>>> Havenlaan 88 bus 73, 1000 Brussel
>>> www.inbo.be <http://www.inbo.be>
>>> 
>>> 
>> ///////////////////////////////////////////////////////////////////////////////////////////
>>> To call in the statistician after the experiment is done may be no more
>>> than asking him to perform a post-mortem examination: he may be able to
>>> say what the experiment died of. ~ Sir Ronald Aylmer Fisher
>>> The plural of anecdote is not data. ~ Roger Brinner
>>> The combination of some data and an aching desire for an answer does not
>>> ensure that a reasonable answer can be extracted from a given body of
>>> data. ~ John Tukey
>>> 
>> ///////////////////////////////////////////////////////////////////////////////////////////
>>> 
>>> <https://www.inbo.be>
>>> 
>>> 
>>> Op di 20 okt. 2020 om 19:40 schreef Ben Bolker <bbolker at gmail.com
>>> <mailto:bbolker at gmail.com>>:
>>> 
>>>        As Thierry says, the data would allow us to give a more detailed
>>>    answer.  However:
>>> 
>>>        * the overall goodness-of-fit is very similar (differences of
>>>    ~0.001
>>>    or less on the deviance scale)
>>> 
>>>        * the random-effects std deve estimate is similar (2% difference)
>>>        * the parameter estimates are quite similar
>>>        * the standard errors of the coefficients look reasonable for
>>>    glmmTMB
>>>    and bogus for lme4 (in any case, if there's a disagreement I would be
>>>    more suspicious of the platform that gave convergence warnings)
>>> 
>>>        There's also strong evidence of dispersion (deviance/resid df >
>> 6);
>>>    you should definitely do something to account for that (check for
>>>    nonlinearity in residuals, switch to negative binomial, add an
>>>    observation-level random effect ...)
>>> 
>>>         You might try the usual set of remedies for convergence problems
>>>    (see ?troubleshooting, ?convergence in lme4), e.g. ?allFit.  Or try
>>>    re-running the lme4 model with starting values set to the glmmTMB
>>>    estimates.
>>> 
>>>        Overall, though, I would trust the glmmTMB results.
>>> 
>>>    On 10/20/20 12:56 PM, Daniel Wright wrote:
>>>> Hello,
>>>> 
>>>> I'm having convergence issues when using glmer in lme4, but not
>>>    glmmTMB.
>>>> I'm running a series of generalized linear mixed effect models
>>>    with poisson
>>>> distribution for ecological count data. I've included a random
>>>    effect of
>>>> site (n = 26) in each model. All non-factor covariates are
>>>    standardized.
>>>> 
>>>> The coefficient estimates of models run in glmer and glmmTMB are
>> very
>>>> similar, but models run in glmer are having convergence issues.
>>>    Any advice
>>>> would be appreciated, as I'm not sure if I can rely on my results
>>>    from
>>>> glmmTMB.
>>>> 
>>>> Attached are example of outputs from glmmTMB vs glmer:
>>>> 
>>>> 
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org
>>>    <mailto:R-sig-mixed-models at r-project.org> mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>> 
>>> 
>>>    _______________________________________________
>>>    R-sig-mixed-models at r-project.org
>>>    <mailto:R-sig-mixed-models at r-project.org> mailing list
>>>    https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> 
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 
> 
> 
> -- 
> ----------------------------------------------------------------
> Daniel Wright, Graduate Research Assistant
> Wildlife and Fisheries Conservation Center
> Depart. Natural Resources and the Environment
> <https://na01.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.nre.uconn.edu%2F&data=02%7C01%7C%7Cba31f0d133a24848eb3208d614ebb2f0%7C17f1a87e2a254eaab9df9d439034b080%7C0%7C0%7C636719399881397445&sdata=l3Lhp0QtBoRy5xpfyem%2FzYHmGZU0%2FHfPkq4mELHdRqE%3D&reserved=0>
> University of Connecticut
> Phone: 413-348-7388
> Email: daniel.wright at uconn.edu
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From d@n|e|@wr|ght @end|ng |rom uconn@edu  Wed Oct 21 16:20:16 2020
From: d@n|e|@wr|ght @end|ng |rom uconn@edu (Daniel Wright)
Date: Wed, 21 Oct 2020 10:20:16 -0400
Subject: [R-sig-ME] Convergence in glmmTMB but not glmer
In-Reply-To: <C298D487-FED5-465C-94AB-783899E02041@gmail.com>
References: <CA+9RvJChD=xiUFLs6SvgF6SHBVbOMfDfSGwD_U=CsxfLO6Litg@mail.gmail.com>
 <8621c16f-b58b-56a3-56b5-f9c2df4893f7@gmail.com>
 <CAJuCY5yamk=qW=5UHDYMgDF=WfWP1AJhUxAhVuSd9wMptNKCjw@mail.gmail.com>
 <225ff648-a066-55d2-d665-a9c458a10b17@gmail.com>
 <CA+9RvJCurJ+_-WREFrBodUyPztbzkZMFPkQo9gPchBoKiEth+Q@mail.gmail.com>
 <C298D487-FED5-465C-94AB-783899E02041@gmail.com>
Message-ID: <CA+9RvJBvpiE+PBfRFXQfTfpNMOUTYJL46QkNP9cBHXway=iNVA@mail.gmail.com>

Switching to negative binomial and selecting an optimizer via allFit did
the trick.
Thanks for the help!

Dan

On Wed, Oct 21, 2020 at 9:48 AM Mollie Brooks <mollieebrooks at gmail.com>
wrote:

> *Message sent from a system outside of UConn.*
>
>
> > On 20Oct 2020, at 20:48, Daniel Wright <daniel.wright at uconn.edu> wrote:
> >
> > " It's often a good idea when using an offset such as log(nights) to
> > *also* (alternatively) try using log(nights) as a predictor: using
> > log(nights) assumes that the number of counts is strictly proportional
> > to the number of nights measured (log(counts) ~ log(nights) + <stuff> ->
> > counts ~ nights*exp(stuff) , whereas using log(counts) allows for some
> > saturation effects (log(counts) ~ alpha*log(nights) + <stuff> -> counts
> > ~ nights^alpha*exp(stuff)) "
> >
> > Hi Ben, to respond to your comments I think it's necessary to explain a
> bit
> > about my dataset if you don't mind.
> >
> > For my research, I've collected bat acoustic data and invertebrate
> samples
> > at 26 regenerating forest stands. Each site was monitored for
> > a minimum of two consecutive nights, three when weather permitted. On the
> > last night of each monitoring effort, nocturnal flying insects
> > were collected to observe the influence of prey biomass on activity in
> > selected sites. In order to include invertebrate biomass as a variable
> > in model selection, I've averaged passes per night as a general measure
> of
> > activity and used the single night of invertebrate sampling
> > as representative of available prey biomass. Bat activity in a single
> > location is notoriously variable from night to night, and
> > activity is typically average across sampling nights.
> >
> > I will try log(counts) as per your suggestion. I appreciate the help.
>
> Was there possibly a miscommunication here? I think Ben was just using
> log(counts) in reference to math, not the formula.
> Continue to use counts as the response, but try log(nights) as a predictor
> rather than offset.
>
> cheers,
> Mollie
>
> >
> > I apologize if my response was too lengthy for this platform. This will
> be
> > my first contribution to the e-sig-mixed-models mailing list.
> >
> >
> >
> > On Tue, Oct 20, 2020 at 2:21 PM Ben Bolker <bbolker at gmail.com> wrote:
> >
> >> *Message sent from a system outside of UConn.*
> >>
> >>
> >> On 10/20/20 2:02 PM, Thierry Onkelinx wrote:
> >>> Daniel sent me the data in private.
> >>>
> >>> A couple of remarks on the dataset.
> >>> - the response is non-integer. You'll need to convert it to integer
> >>> (total number) and use an appropriate offset term (log(nights)).
> >>> - make sure the factor covariate is a factor and not an integer.
> >>
> >>   If the response is non-integer, that makes my comment about
> >> overdispersion not necessarily relevant (check again after re-fitting).
> >>
> >>   It's often a good idea when using an offset such as log(nights) to
> >> *also* (alternatively) try using log(nights) as a predictor: using
> >> log(nights) assumes that the number of counts is strictly proportional
> >> to the number of nights measured (log(counts) ~ log(nights) + <stuff> ->
> >> counts ~ nights*exp(stuff) , whereas using log(counts) allows for some
> >> saturation effects (log(counts) ~ alpha*log(nights) + <stuff> -> counts
> >> ~ nights^alpha*exp(stuff))
> >>
> >>
> >>>
> >>> Please see if that solves the problem. What happens if you use a nbinom
> >>> distribution as Ben suggested?
> >>>
> >>> Personally, I don't like to "standardise" covariates. It makes them
> much
> >>> harder to interpret. I prefer to center to a more meaningful value than
> >>> the mean. And rescale it by changing the unit. E.g. Age ranges from 1
> to
> >>> 15 with mean 6.76. I'd use something like AgeC = (Age - 5) / 10. This
> >>> gives a similar range as the standardisation of Age. But one unit of
> >>> AgeC represents 10 year. And the intercept refers to Age = 5. Making
> the
> >>> parameters estimates easier to interpret IMHO.
> >>
> >>   Yes, although 'strict' standardization (scaling by predictor SD or
> >> 2*predictor SD) allows direct interpretation of the parameters as a kind
> >> of effect size (Schielzeth 2010), whereas 'human-friendly'
> >> standardization trades interpretability for the comparison of magnitudes
> >> being only an approximation.
> >>
> >>
> >>>
> >>> Best regards,
> >>>
> >>> ir. Thierry Onkelinx
> >>> Statisticus / Statistician
> >>>
> >>> Vlaamse Overheid / Government of Flanders
> >>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
> >>> AND FOREST
> >>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> >>> thierry.onkelinx at inbo.be <mailto:thierry.onkelinx at inbo.be>
> >>> Havenlaan 88 bus 73, 1000 Brussel
> >>> www.inbo.be <http://www.inbo.be>
> >>>
> >>>
> >>
> ///////////////////////////////////////////////////////////////////////////////////////////
> >>> To call in the statistician after the experiment is done may be no more
> >>> than asking him to perform a post-mortem examination: he may be able to
> >>> say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> >>> The plural of anecdote is not data. ~ Roger Brinner
> >>> The combination of some data and an aching desire for an answer does
> not
> >>> ensure that a reasonable answer can be extracted from a given body of
> >>> data. ~ John Tukey
> >>>
> >>
> ///////////////////////////////////////////////////////////////////////////////////////////
> >>>
> >>> <https://www.inbo.be>
> >>>
> >>>
> >>> Op di 20 okt. 2020 om 19:40 schreef Ben Bolker <bbolker at gmail.com
> >>> <mailto:bbolker at gmail.com>>:
> >>>
> >>>        As Thierry says, the data would allow us to give a more detailed
> >>>    answer.  However:
> >>>
> >>>        * the overall goodness-of-fit is very similar (differences of
> >>>    ~0.001
> >>>    or less on the deviance scale)
> >>>
> >>>        * the random-effects std deve estimate is similar (2%
> difference)
> >>>        * the parameter estimates are quite similar
> >>>        * the standard errors of the coefficients look reasonable for
> >>>    glmmTMB
> >>>    and bogus for lme4 (in any case, if there's a disagreement I would
> be
> >>>    more suspicious of the platform that gave convergence warnings)
> >>>
> >>>        There's also strong evidence of dispersion (deviance/resid df >
> >> 6);
> >>>    you should definitely do something to account for that (check for
> >>>    nonlinearity in residuals, switch to negative binomial, add an
> >>>    observation-level random effect ...)
> >>>
> >>>         You might try the usual set of remedies for convergence
> problems
> >>>    (see ?troubleshooting, ?convergence in lme4), e.g. ?allFit.  Or try
> >>>    re-running the lme4 model with starting values set to the glmmTMB
> >>>    estimates.
> >>>
> >>>        Overall, though, I would trust the glmmTMB results.
> >>>
> >>>    On 10/20/20 12:56 PM, Daniel Wright wrote:
> >>>> Hello,
> >>>>
> >>>> I'm having convergence issues when using glmer in lme4, but not
> >>>    glmmTMB.
> >>>> I'm running a series of generalized linear mixed effect models
> >>>    with poisson
> >>>> distribution for ecological count data. I've included a random
> >>>    effect of
> >>>> site (n = 26) in each model. All non-factor covariates are
> >>>    standardized.
> >>>>
> >>>> The coefficient estimates of models run in glmer and glmmTMB are
> >> very
> >>>> similar, but models run in glmer are having convergence issues.
> >>>    Any advice
> >>>> would be appreciated, as I'm not sure if I can rely on my results
> >>>    from
> >>>> glmmTMB.
> >>>>
> >>>> Attached are example of outputs from glmmTMB vs glmer:
> >>>>
> >>>>
> >>>> _______________________________________________
> >>>> R-sig-mixed-models at r-project.org
> >>>    <mailto:R-sig-mixed-models at r-project.org> mailing list
> >>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>>>
> >>>
> >>>    _______________________________________________
> >>>    R-sig-mixed-models at r-project.org
> >>>    <mailto:R-sig-mixed-models at r-project.org> mailing list
> >>>    https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>>
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>
> >
> >
> > --
> > ----------------------------------------------------------------
> > Daniel Wright, Graduate Research Assistant
> > Wildlife and Fisheries Conservation Center
> > Depart. Natural Resources and the Environment
> > <
> https://na01.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.nre.uconn.edu%2F&data=02%7C01%7C%7Cba31f0d133a24848eb3208d614ebb2f0%7C17f1a87e2a254eaab9df9d439034b080%7C0%7C0%7C636719399881397445&sdata=l3Lhp0QtBoRy5xpfyem%2FzYHmGZU0%2FHfPkq4mELHdRqE%3D&reserved=0
> >
> > University of Connecticut
> > Phone: 413-348-7388
> > Email: daniel.wright at uconn.edu
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>

-- 
----------------------------------------------------------------
Daniel Wright, Graduate Research Assistant
Wildlife and Fisheries Conservation Center
Depart. Natural Resources and the Environment
<https://na01.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.nre.uconn.edu%2F&data=02%7C01%7C%7Cba31f0d133a24848eb3208d614ebb2f0%7C17f1a87e2a254eaab9df9d439034b080%7C0%7C0%7C636719399881397445&sdata=l3Lhp0QtBoRy5xpfyem%2FzYHmGZU0%2FHfPkq4mELHdRqE%3D&reserved=0>
University of Connecticut
Phone: 413-348-7388
Email: daniel.wright at uconn.edu

	[[alternative HTML version deleted]]


From don-|me4 @end|ng |rom |@|@@c@3-|nc@com  Fri Oct 23 03:40:39 2020
From: don-|me4 @end|ng |rom |@|@@c@3-|nc@com (Don Cohen)
Date: Fri, 23 Oct 2020 01:40:39 +0000 (UTC)
Subject: [R-sig-ME] more on nbinom1 vs 2
Message-ID: <20201023014039.2BC5F40486@chmusic.org>


I'm still hoping to see some reaction to my message of 10-16
on aggregation of count data.

In the mean while, here's an attempt to explain something related.  
I'm again hoping for feedback - is this all correct, am I missing 
something important?

I now think I (finally) understand that nbinom1 is really the SAME 
distribution as nbinom2.  How well a set of values fits a single NB
distribution has nothing to do with whether the distribution is
described by the parameters of nbinom1 or those of nbinom2.
It is a set of different NB distributions that can fit one better
than the other, and most models actually do predict a set of 
distributions rather than just one.  In particular, if there
are covariates, then a different distribution is predicted for
each value of the covariates.

If there are no covariates, then there should be no difference 
between nbinom1 and nbinom2, except for different overdispersion
parameters predicting the same variance.  (This variance is 
presumably observed in the different result values.)

Getting rid of covariates, 
if glmmTMB(result~1,family=nbinom1,data=D) says

 Overdispersion parameter for nbinom1 family (): x
 with (Intercept) y

while glmmTMB(result~1,family=nbinom2,data=D) says

 Overdispersion parameter for nbinom2 family (): z
 with (Intercept) w

then y better be the same as w, since the mean would be 
exp(y) in the first case and exp(w) in the second.
Similarly the variance would be
 mean * (1 + param) = exp(y) * (1+x) in the first case and
 mean * (1 + (mean/param)) = exp(w) * (1+ (exp(w)/z)) in the second.
which again should be the same value.

This was indeed what I found when I tried it.
This remained true when I added an offset: result~offset(log(exposure))

However, when I added a random effect: result ~ (1|group)
I was surprised to get different results for nbinom1 and nbinom2, i.e.,
different AIC and different intercept.  
I also noticed a difference in the variance of the random effect.

I now think I understand why.  The random effect allows different
means and variances for different groups, and this (unlike any 
previous examples) can agree with nbinom1 better or worse than 
nbinom2, depending on whether the relation between the means and 
variances of the groups is closer to linear or quadratic.

Perhaps I should stop here and wait for replies before moving
on to how this is related to the aggregation issue in the
earlier message.


From bbo|ker @end|ng |rom gm@||@com  Fri Oct 23 03:49:37 2020
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Thu, 22 Oct 2020 21:49:37 -0400
Subject: [R-sig-ME] more on nbinom1 vs 2
In-Reply-To: <20201023014039.2BC5F40486@chmusic.org>
References: <20201023014039.2BC5F40486@chmusic.org>
Message-ID: <ccaee4aa-ef25-de9b-e997-40792c920942@gmail.com>

   Very short answer: all your insights here look correct, and well 
expressed.

   I think the problem with your earlier aggregation question (I vaguely 
remember it ) is a fairly common one with well-posed but moderately 
interesting/difficult questions: questions that take more than a few 
minutes to come up with an adequate answer/understanding, and that don't 
happen to be in someone's wheelhouse -- so that they've either thought 
about it before and have an answer ready, *or* it's worth it to them to 
take some time to work on it -- often get neglected and gradually sink 
into the pile.

  This is one of the advantages of forums like StackOverflow or 
CrossValidated that (1) are much easier to search for old questions; (2) 
allow people to offer 'brownie points' for solutions to interesting 
questions.  (I think a sufficient interval has gone by that it would be 
reasonable to cross-post it to CrossValidated ...)

On 10/22/20 9:40 PM, Don Cohen wrote:
> 
> I'm still hoping to see some reaction to my message of 10-16
> on aggregation of count data.
> 
> In the mean while, here's an attempt to explain something related.
> I'm again hoping for feedback - is this all correct, am I missing
> something important?
> 
> I now think I (finally) understand that nbinom1 is really the SAME
> distribution as nbinom2.  How well a set of values fits a single NB
> distribution has nothing to do with whether the distribution is
> described by the parameters of nbinom1 or those of nbinom2.
> It is a set of different NB distributions that can fit one better
> than the other, and most models actually do predict a set of
> distributions rather than just one.  In particular, if there
> are covariates, then a different distribution is predicted for
> each value of the covariates.
> 
> If there are no covariates, then there should be no difference
> between nbinom1 and nbinom2, except for different overdispersion
> parameters predicting the same variance.  (This variance is
> presumably observed in the different result values.)
> 
> Getting rid of covariates,
> if glmmTMB(result~1,family=nbinom1,data=D) says
> 
>   Overdispersion parameter for nbinom1 family (): x
>   with (Intercept) y
> 
> while glmmTMB(result~1,family=nbinom2,data=D) says
> 
>   Overdispersion parameter for nbinom2 family (): z
>   with (Intercept) w
> 
> then y better be the same as w, since the mean would be
> exp(y) in the first case and exp(w) in the second.
> Similarly the variance would be
>   mean * (1 + param) = exp(y) * (1+x) in the first case and
>   mean * (1 + (mean/param)) = exp(w) * (1+ (exp(w)/z)) in the second.
> which again should be the same value.
> 
> This was indeed what I found when I tried it.
> This remained true when I added an offset: result~offset(log(exposure))
> 
> However, when I added a random effect: result ~ (1|group)
> I was surprised to get different results for nbinom1 and nbinom2, i.e.,
> different AIC and different intercept.
> I also noticed a difference in the variance of the random effect.
> 
> I now think I understand why.  The random effect allows different
> means and variances for different groups, and this (unlike any
> previous examples) can agree with nbinom1 better or worse than
> nbinom2, depending on whether the relation between the means and
> variances of the groups is closer to linear or quadratic.
> 
> Perhaps I should stop here and wait for replies before moving
> on to how this is related to the aggregation issue in the
> earlier message.
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From don-|me4 @end|ng |rom |@|@@c@3-|nc@com  Sun Oct 25 02:04:26 2020
From: don-|me4 @end|ng |rom |@|@@c@3-|nc@com (Don Cohen)
Date: Sun, 25 Oct 2020 01:04:26 +0000 (UTC)
Subject: [R-sig-ME] next on aggregation, nbinom1, nbinom2
Message-ID: <20201025010426.719FA406B9@chmusic.org>


Again, I'll be happy to hear if there's a better place to post this, but
since it includes some R code and calls to glmmTMB, this mailing list 
does seem reasonably appropriate.

There are several things I find surprising about the results below.  
I'd be interested in any ideas of what could cause these things or 
reasons why I should be less surprised.

The table below shows output of four different calls of form
 glmmTMB(count~offset(log(exposure))+(1|groupid), data= ...,family= ...)
where family is either nbinom1 or nbinom2 and data is aggregated or
unaggregated.  The aggregated data was derived from the unaggregated by:

 unagg.group = group_by(unaggregated,groupid)
 aggregated = summarise(unagg.group,count=sum(count),exposure=sum(exposure))

(Note the aggregated data have exactly one observation per group.
But that's a topic that I think I at least partly understand.)

There are 5474 unaggregated observations and 78 groups.
The unaggregated observations all have close to the same exposure
(9 - 11 minutes, but exposure is measured in hours), so it does make
sense to look at the distribution of counts in that data.  
The mean of the counts is 0.0524, or .3144/hr, 
the variance is 0.315, or 1.89/hr, and the distribution matches NB
with that mean and variance surprisingly (at least to me) well.

The groups have widely varying exposures: 22 have less than 1 hr
(all of those have zero counts), 9 have 1-2 hrs, 15 have 2-5 hrs,
15 have 5-15 hrs, 15 have 15-50 hrs and 3 have over 50 hrs.
The count/exposure of the groups has mean 0.437 and variance 1.59, 
so I expected the models to predict means somewhere near the 
range .31 - .43 and variances around the range 1.59 - 1.89 
The three groups with exposure>50 hr have count/exposure .26,.30,.38

The aggregated data clearly contain much less information than the
unaggregated, so it would not be surprising if the models using the
unaggregated data were "better" in some undefined sense at describing
the world from which the data were drawn.  Whereas it WOULD be 
surprising if those models were actually worse.

The particular data that are missing from the aggregated data have to
do with the distribution of the counts and exposures (and perhaps the
count/exposure's) from which the aggregated data were derived.
I imagine this to be useful in estimating the non-mean NB parameters.
And yet there do seem to be other data from which to estimate them,
such as the relation between variance and exposure.  Possibly this is
not enough data for that purpose.  The variation among groups is used 
for the random effect size, which I expect makes it less useful for
estimating other parameters.

#    unaggregated          aggregated 
#  NB1         NB2        NB1      NB2       
#  1370.0 ~=  1372.4      257.4 << 275.9       AIC
#  0.2635     0.4604      7e-9 !   1.315       group variance
#  5.07       0.0116      8.58     0.661       overdispersion parameter
#  -1.2600    -1.3104     -1.1567  -1.3887     intercept
#  0.28        0.27       0.315    0.25        exp(intercept) => mean
#  1.7         6.5 ??     3         .35 ??     mean,overdisp => variance

1. The computed means are at least in the right ball park, but the
computed variances seem wildly off, esp. for NB2.
Am I computing the variance correctly for NB2?
mean * (1 + mean/param) ?
Why is the NB2 overdispersion parameter so different for aggregated data?
This is not supposed to depend on scale is it?
(I'm even surprised that the NB1 parameter is so different, but that's
a factor of less than 2 while NB2 is a factor of 60.)

2. Why is AIC for NB1 so much better than for NB2 in aggregated data 
when the two are so close for unaggregated data?  This seems to be 
telling us something about the aggregated data which is not evident in 
the unaggregated data.  (What could that be?)  And this contradicts my 
expectation above.

3. Is the near zero variance in NB1 aggregated data a coincidence or
does it mean something?  Surely it's not the case that all of the 
groups have the same mean.  I did check to see that, as expected,
the AIC was 2 less without the random effect.


From @|m@h@rme| @end|ng |rom gm@||@com  Mon Oct 26 01:54:58 2020
From: @|m@h@rme| @end|ng |rom gm@||@com (Simon Harmel)
Date: Sun, 25 Oct 2020 19:54:58 -0500
Subject: [R-sig-ME] lme4: plotting profile density (not Zeta) manually not
 by lattice
Message-ID: <CACgv6yU6+t69mOzN-ZwUCoR9oWk4mpNSsDnKxqTksK3nEvX_ag@mail.gmail.com>

Dear All,

I'm trying to plot the sampling distributions of my model parameters using `
densityplot()` from the `lattice` package but lattice often throws an error
even if one of the estimate's density distribution is highly skewed or
funny-looking.

Is there a better package or a better way (even manually) to plot the
densities (not Zeta) from a `profile()` call?

library(lattice)
library(lme4)

hsb <- read.csv('
https://raw.githubusercontent.com/rnorouzian/e/master/hsb.csv')
m31 <- lmer(math ~ ses*meanses + (ses | sch.id), data = hsb)

p <-  profile(m31)
densityplot(p)
Error in UseMethod("predict") :
  no applicable method for 'predict' applied to an object of class "NULL"

	[[alternative HTML version deleted]]


From d@|uedecke @end|ng |rom uke@de  Mon Oct 26 08:16:36 2020
From: d@|uedecke @end|ng |rom uke@de (=?iso-8859-1?Q?Daniel_L=FCdecke?=)
Date: Mon, 26 Oct 2020 08:16:36 +0100
Subject: [R-sig-ME] 
 lme4: plotting profile density (not Zeta) manually not by lattice
In-Reply-To: <CACgv6yU6+t69mOzN-ZwUCoR9oWk4mpNSsDnKxqTksK3nEvX_ag@mail.gmail.com>
References: <CACgv6yU6+t69mOzN-ZwUCoR9oWk4mpNSsDnKxqTksK3nEvX_ag@mail.gmail.com>
Message-ID: <000001d6ab67$f1657e30$d4307a90$@uke.de>

Dear Simon,
you could use the "estimate_density()" function from the bayestestR package
(see examples here:
https://easystats.github.io/see/articles/bayestestR.html), which works on
data frames (like the object returned by "profile()") and has an own
plot()-method. Another approach that *might* come close to what you would
like to achieve is simulating parameters from a multivariate normal
distribution, based on MASS:: mvrnorm(). This can be done with the
"simulate_parameters()" function from the parameters package, which also has
a print()-method (see visual examples here:
https://easystats.github.io/see/articles/parameters.html#simulated-model-par
ameters-1).

Here is some working code, I hope I got your point and provided a useful
answer...

library(lme4)
library(bayestestR)
library(parameters)
library(ggplot2)

theme_set(theme_classic())
hsb <-
read.csv('https://raw.githubusercontent.com/rnorouzian/e/master/hsb.csv')
m31 <- lmer(math ~ ses*meanses + (ses | sch.id), data = hsb)
mp <- profile(m31)

# some profiled densities have very high spikes, so plot is probably less
useful...
d1 <- estimate_density(mp[c("ses", "meanses", "ses:meanses")])
d2 <- estimate_density(mp$ses)
d3 <- estimate_density(mp[c("ses", "ses:meanses")])

plot(d1) + ggplot2::xlim(c(0, 4))
plot(d2) + ggplot2::xlim(c(2.15, 2.25))
plot(d3) + ggplot2::xlim(c(0, 3))

sp <- simulate_parameters(m31)
plot(sp)
plot(sp, stack = FALSE)

Best
Daniel


-----Urspr?ngliche Nachricht-----
Von: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> Im
Auftrag von Simon Harmel
Gesendet: Montag, 26. Oktober 2020 01:55
An: r-sig-mixed-models <r-sig-mixed-models at r-project.org>
Betreff: [R-sig-ME] lme4: plotting profile density (not Zeta) manually not
by lattice

Dear All,

I'm trying to plot the sampling distributions of my model parameters using `
densityplot()` from the `lattice` package but lattice often throws an error
even if one of the estimate's density distribution is highly skewed or
funny-looking.

Is there a better package or a better way (even manually) to plot the
densities (not Zeta) from a `profile()` call?

library(lattice)
library(lme4)

hsb <- read.csv('
https://raw.githubusercontent.com/rnorouzian/e/master/hsb.csv')
m31 <- lmer(math ~ ses*meanses + (ses | sch.id), data = hsb)

p <-  profile(m31)
densityplot(p)
Error in UseMethod("predict") :
  no applicable method for 'predict' applied to an object of class "NULL"

	[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

--

_____________________________________________________________________

Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen Rechts; Gerichtsstand: Hamburg | www.uke.de
Vorstandsmitglieder: Prof. Dr. Burkhard G?ke (Vorsitzender), Joachim Pr?l?, Prof. Dr. Blanche Schwappach-Pignataro, Marya Verdel
_____________________________________________________________________

SAVE PAPER - THINK BEFORE PRINTING


From @|m@h@rme| @end|ng |rom gm@||@com  Mon Oct 26 08:42:21 2020
From: @|m@h@rme| @end|ng |rom gm@||@com (Simon Harmel)
Date: Mon, 26 Oct 2020 02:42:21 -0500
Subject: [R-sig-ME] Variance of the fixed effects lme4
Message-ID: <CACgv6yUkovnb64oZKRM319EK2BsXVncYTJS7JUHGWSp9Tgaz8Q@mail.gmail.com>

Hello All,

The below website talks about the use of "the variance of the fixed
effects" in the computation of R-squared from a mixed model.

But what is "the variance of the fixed effects"? Is it the sum of
the diagonal elements obtained from:   vcov(fitted_model)?

The website:
https://www.theanalysisfactor.com/r-squared-for-mixed-effects-models/

	[[alternative HTML version deleted]]


From ph||||p@@|d@y @end|ng |rom mp|@n|  Mon Oct 26 10:55:56 2020
From: ph||||p@@|d@y @end|ng |rom mp|@n| (Phillip Alday)
Date: Mon, 26 Oct 2020 10:55:56 +0100
Subject: [R-sig-ME] Variance of the fixed effects lme4
In-Reply-To: <CACgv6yUkovnb64oZKRM319EK2BsXVncYTJS7JUHGWSp9Tgaz8Q@mail.gmail.com>
References: <CACgv6yUkovnb64oZKRM319EK2BsXVncYTJS7JUHGWSp9Tgaz8Q@mail.gmail.com>
Message-ID: <c482d0a4-dcb9-bd99-51d5-edf899fb93e4@mpi.nl>

(once again without PGP signing)

I would strongly advise against depending on any R2 version for
mixed-models. Despite that blog posts claim about their preferred
definition, there isn't really any consensus on what R2 would look like.
Moreover, for fundamental reasons, there isn't any measure that will
have the properties of R2 from classical OLS/fixed-effecs regression.
See e.g.

https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#how-do-i-compute-a-coefficient-of-determination-r2-or-an-analogue-for-glmms
(including linked threads  and the section "Variable importance")

Various R2 measures -- including  Nakagawa and Shielzeth -- are
implemented in that discussion and linked packages.

For a perhaps more intuitive example of why R2 is not clearly defined
for mixed models, note that many definitions of R2 are something like

1 - var(null_model) / var(model)

where the null_model is the intercepts-only model. But is the intercepts
only model? Is it just the fixed-effects intercept? Is it just the
random-effects intercept? (And if you have more than one grouping
variable, which of these make the cut?) Is it both the fixed- and
random-effects intercepts? Do we care more about the variance explained
by the fixed effects, the random effects or by both? (Note that the
"marginal" and "conditional" R2 discussed in that blog post only cover 2
out of 3 of those possibilities.)

And this is before getting into all the problems with R2 as a measure in
general -- there are lots of discussions of the problems of R2, even
when applied to classical OLS regression. For example, aggregating or
binning data can increase R2, even though the model may now explain less
of the variance in the original data.


Phillip


On 26/10/20 8:42 am, Simon Harmel wrote:
> Hello All,
> 
> The below website talks about the use of "the variance of the fixed
> effects" in the computation of R-squared from a mixed model.
> 
> But what is "the variance of the fixed effects"? Is it the sum of
> the diagonal elements obtained from:   vcov(fitted_model)?
> 
> The website:
> https://www.theanalysisfactor.com/r-squared-for-mixed-effects-models/
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From p@u|@john@on @end|ng |rom g|@@gow@@c@uk  Mon Oct 26 11:11:10 2020
From: p@u|@john@on @end|ng |rom g|@@gow@@c@uk (Paul Johnson)
Date: Mon, 26 Oct 2020 10:11:10 +0000
Subject: [R-sig-ME] Variance of the fixed effects lme4
In-Reply-To: <CACgv6yUkovnb64oZKRM319EK2BsXVncYTJS7JUHGWSp9Tgaz8Q@mail.gmail.com>
References: <CACgv6yUkovnb64oZKRM319EK2BsXVncYTJS7JUHGWSp9Tgaz8Q@mail.gmail.com>
Message-ID: <0997001E-E284-4746-85E2-731935E3F8E4@glasgow.ac.uk>

Hi Simon,

The usual way is to calculate the variance of the fitted values on the link scale, using only the fixed effects. 
E.g. for lme4 fits, appendix S6 of https://doi.org/10.1098/rsif.2017.0213 gives:

# Calculation of the variance in fitted values
VarF <-var(as.vector(model.matrix(parmodGLMERf) %*% fixef(parmodGLMERf)))

Which is essentially the same as the method used in the code for the original Nakagawa & Schielzeth R2_GLMM paper cited in the website you mentioned: https://doi.org/10.1111/j.2041-210x.2012.00261.x

I think this will be the same as:
VarF <-var(fitted(parmodGLMERf))

But as a general method this might be less safe because I can never remember if all the fitted() methods give the link scale fitted values by default, and whether they ever include random effects.

Best wishes,
Paul


> On 26 Oct 2020, at 07:42, Simon Harmel <sim.harmel at gmail.com> wrote:
> 
> Hello All,
> 
> The below website talks about the use of "the variance of the fixed
> effects" in the computation of R-squared from a mixed model.
> 
> But what is "the variance of the fixed effects"? Is it the sum of
> the diagonal elements obtained from:   vcov(fitted_model)?
> 
> The website:
> https://www.theanalysisfactor.com/r-squared-for-mixed-effects-models/
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbo|ker @end|ng |rom gm@||@com  Mon Oct 26 14:19:01 2020
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Mon, 26 Oct 2020 09:19:01 -0400
Subject: [R-sig-ME] 
 lme4: plotting profile density (not Zeta) manually not by lattice
In-Reply-To: <CACgv6yU6+t69mOzN-ZwUCoR9oWk4mpNSsDnKxqTksK3nEvX_ag@mail.gmail.com>
References: <CACgv6yU6+t69mOzN-ZwUCoR9oWk4mpNSsDnKxqTksK3nEvX_ag@mail.gmail.com>
Message-ID: <6e76e2e4-e974-60b0-33c4-c0c8074ad185@gmail.com>

    Can you clarify a bit what you want to plot?
   as.data.frame(p) is a good way to retrieve a simple data frame from 
profile objects that you can then transform/use to plot as you see fit.

   Ben Bolker

On 10/25/20 8:54 PM, Simon Harmel wrote:
> Dear All,
> 
> I'm trying to plot the sampling distributions of my model parameters using `
> densityplot()` from the `lattice` package but lattice often throws an error
> even if one of the estimate's density distribution is highly skewed or
> funny-looking.
> 
> Is there a better package or a better way (even manually) to plot the
> densities (not Zeta) from a `profile()` call?
> 
> library(lattice)
> library(lme4)
> 
> hsb <- read.csv('
> https://raw.githubusercontent.com/rnorouzian/e/master/hsb.csv')
> m31 <- lmer(math ~ ses*meanses + (ses | sch.id), data = hsb)
> 
> p <-  profile(m31)
> densityplot(p)
> Error in UseMethod("predict") :
>    no applicable method for 'predict' applied to an object of class "NULL"
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From @|m@h@rme| @end|ng |rom gm@||@com  Mon Oct 26 15:51:26 2020
From: @|m@h@rme| @end|ng |rom gm@||@com (Simon Harmel)
Date: Mon, 26 Oct 2020 09:51:26 -0500
Subject: [R-sig-ME] 
 lme4: plotting profile density (not Zeta) manually not by lattice
In-Reply-To: <6e76e2e4-e974-60b0-33c4-c0c8074ad185@gmail.com>
References: <CACgv6yU6+t69mOzN-ZwUCoR9oWk4mpNSsDnKxqTksK3nEvX_ag@mail.gmail.com>
 <6e76e2e4-e974-60b0-33c4-c0c8074ad185@gmail.com>
Message-ID: <CACgv6yX4ouiySba7s_NbmOnm4FVPXXdJQ2A49L6Ou_GNTOOqFA@mail.gmail.com>

Ben,
I expect the exact same plots that densityplot(profile(fitted_model)) from
lattice produces?

again, densityplot(profile(fitted_model)) throws an error for the model in
my original question (and generally when any parameter's likelihood
distribution is highly spiked or funny-looking)

On Mon, Oct 26, 2020, 8:19 AM Ben Bolker <bbolker at gmail.com> wrote:

>     Can you clarify a bit what you want to plot?
>    as.data.frame(p) is a good way to retrieve a simple data frame from
> profile objects that you can then transform/use to plot as you see fit.
>
>    Ben Bolker
>
> On 10/25/20 8:54 PM, Simon Harmel wrote:
> > Dear All,
> >
> > I'm trying to plot the sampling distributions of my model parameters
> using `
> > densityplot()` from the `lattice` package but lattice often throws an
> error
> > even if one of the estimate's density distribution is highly skewed or
> > funny-looking.
> >
> > Is there a better package or a better way (even manually) to plot the
> > densities (not Zeta) from a `profile()` call?
> >
> > library(lattice)
> > library(lme4)
> >
> > hsb <- read.csv('
> > https://raw.githubusercontent.com/rnorouzian/e/master/hsb.csv')
> > m31 <- lmer(math ~ ses*meanses + (ses | sch.id), data = hsb)
> >
> > p <-  profile(m31)
> > densityplot(p)
> > Error in UseMethod("predict") :
> >    no applicable method for 'predict' applied to an object of class
> "NULL"
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Mon Oct 26 17:03:14 2020
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Mon, 26 Oct 2020 17:03:14 +0100
Subject: [R-sig-ME] 
 lme4: plotting profile density (not Zeta) manually not by lattice
In-Reply-To: <CACgv6yX4ouiySba7s_NbmOnm4FVPXXdJQ2A49L6Ou_GNTOOqFA@mail.gmail.com>
References: <CACgv6yU6+t69mOzN-ZwUCoR9oWk4mpNSsDnKxqTksK3nEvX_ag@mail.gmail.com>
 <6e76e2e4-e974-60b0-33c4-c0c8074ad185@gmail.com>
 <CACgv6yX4ouiySba7s_NbmOnm4FVPXXdJQ2A49L6Ou_GNTOOqFA@mail.gmail.com>
Message-ID: <24470.62274.33849.795053@stat.math.ethz.ch>

>>>>> Simon Harmel 
>>>>>     on Mon, 26 Oct 2020 09:51:26 -0500 writes:

    > Ben,
    > I expect the exact same plots that densityplot(profile(fitted_model)) from
    > lattice produces?

    > again, densityplot(profile(fitted_model)) throws an error for the model in
    > my original question (and generally when any parameter's likelihood
    > distribution is highly spiked or funny-looking)

Hmm.. interesting.
As I'm coauthor of lme4  and have been doing nonparametric curve
estimation during my ph.d. years ("yesterday, .."),
I'm interested to rather fix the problem than try other
packages.

>From your error message, there must be a buglet in either lattice
or lme4 ...

*BUT* (see below)

    > On Mon, Oct 26, 2020, 8:19 AM Ben Bolker <bbolker at gmail.com> wrote:

    >> Can you clarify a bit what you want to plot?
    >> as.data.frame(p) is a good way to retrieve a simple data frame from
    >> profile objects that you can then transform/use to plot as you see fit.
    >> 
    >> Ben Bolker
    >> 
    >> On 10/25/20 8:54 PM, Simon Harmel wrote:
    >> > Dear All,
    >> >
    >> > I'm trying to plot the sampling distributions of my model parameters
    >> using `
    >> > densityplot()` from the `lattice` package but lattice often throws an
    >> error
    >> > even if one of the estimate's density distribution is highly skewed or
    >> > funny-looking.
    >> >
    >> > Is there a better package or a better way (even manually) to plot the
    >> > densities (not Zeta) from a `profile()` call?

   hsb <- read.csv('https://raw.githubusercontent.com/rnorouzian/e/master/hsb.csv')

   library(lme4) # gets 'lattice' 
   m31 <- lmer(math ~ ses*meanses + (ses | sch.id), data = hsb)

   p <-  profile(m31)

## the profiling above gives *TONS and TONS* of warnings !

## so I guess now wonder you cannot easily plot it ..
## still you should at least get a better  error message

> 
densityplot(p)
> Error in UseMethod("predict") :
>  no applicable method for 'predict' applied to an object of class
>   NULL



Here's what I do to "summarize" ... and show "the solution" (?)

options(nwarnings=2^12) # so we store all the warnings !
system.time( p <- profile(m31) )
##   user  system elapsed 
## 19.007   0.002  19.111 
## There were 92 warnings (use warnings() to see them)

## MM: the cool thing is I wrote a summary() method for warnings in R 
##     a while ago, so use it:
summary( warnings() )
## Summary of (a total of 92) warning messages:
##  3x : In nextpar(mat, cc, i, delta, lowcut, upcut) :
##   unexpected decrease in profile: using minstep
## 88x : In nextpar(mat, cc, i, delta, lowcut, upcut) :
##   Last two rows have identical or NA .zeta values: using minstep
##  1x : In FUN(X[[i]], ...) : non-monotonic profile for .sig02

confint(p)
>                  2.5 %     97.5 %
> .sig01       1.4034755  1.8925324
> .sig02      -0.9025412  0.2035804
> .sig03       0.1824510  0.9800896
> .sigma       5.9659398  6.1688744
> (Intercept) 12.3231883 12.9337235
> ses          1.9545565  2.4326048
> meanses      3.0178000  4.5260869
> ses:meanses -0.4044241  0.7279685
> Warning messages:
> 1: In confint.thpr(p) :
>   bad spline fit for .sig02: falling back to linear interpolation
> 2: In regularize.values(x, y, ties, missing(ties), na.rm = na.rm) :
>   collapsing to unique 'x' values

so you see indeed, that  sig02 should probably be omitted from
the model

which I can "easily" confirm :

m30 <- lmer(math ~ ses * meanses + (1|sch.id) + (0+ ses | sch.id), data= hsb)
m20 <- lmer(math ~ ses * meanses + (1|sch.id), data= hsb)

anova(m31,m30,m20)
> refitting model(s) with ML (instead of REML)
> Data: hsb
> Models:
> m20: math ~ ses * meanses + (1 | sch.id)
> m30: math ~ ses * meanses + (1 | sch.id) + (0 + ses | sch.id)
> m31: math ~ ses * meanses + (ses | sch.id)
>     npar   AIC   BIC logLik deviance  Chisq Df Pr(>Chisq)  
> m20    6 46575 46616 -23282    46563                       
> m30    7 46572 46620 -23279    46558 5.5415  1    0.01857 *
> m31    8 46573 46628 -23278    46557 0.9669  1    0.32546  
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

So it seems m30, the model with no correlation between intercept
and slope fits well enough

and indeed,

system.time( p30 <- profile(m30 )
## ends in 5 sec, without any warnings,

and then

xyplot(p30)  # <-- more useful I think than
densityplot(p30) # both work fine

-- still I agree there's something we should do to fix the
   buglet !!

Martin Maechler
ETH Zurich


From bbo|ker @end|ng |rom gm@||@com  Tue Oct 27 03:38:10 2020
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Mon, 26 Oct 2020 22:38:10 -0400
Subject: [R-sig-ME] 
 lme4: plotting profile density (not Zeta) manually not by lattice
In-Reply-To: <24470.62274.33849.795053@stat.math.ethz.ch>
References: <CACgv6yU6+t69mOzN-ZwUCoR9oWk4mpNSsDnKxqTksK3nEvX_ag@mail.gmail.com>
 <6e76e2e4-e974-60b0-33c4-c0c8074ad185@gmail.com>
 <CACgv6yX4ouiySba7s_NbmOnm4FVPXXdJQ2A49L6Ou_GNTOOqFA@mail.gmail.com>
 <24470.62274.33849.795053@stat.math.ethz.ch>
Message-ID: <9e8f40b2-5d4e-d0c2-085b-e9204aee1b64@gmail.com>

    I've pushed an improved version of densityplot to github.  It 
creates density plots for all but .sig02 (the correlation parameter, I 
think), leaving that panel blank, and warns about skipped parameters. 
Give it a try ...

On 10/26/20 12:03 PM, Martin Maechler wrote:
>>>>>> Simon Harmel
>>>>>>      on Mon, 26 Oct 2020 09:51:26 -0500 writes:
> 
>      > Ben,
>      > I expect the exact same plots that densityplot(profile(fitted_model)) from
>      > lattice produces?
> 
>      > again, densityplot(profile(fitted_model)) throws an error for the model in
>      > my original question (and generally when any parameter's likelihood
>      > distribution is highly spiked or funny-looking)
> 
> Hmm.. interesting.
> As I'm coauthor of lme4  and have been doing nonparametric curve
> estimation during my ph.d. years ("yesterday, .."),
> I'm interested to rather fix the problem than try other
> packages.
> 
>  From your error message, there must be a buglet in either lattice
> or lme4 ...
> 
> *BUT* (see below)
> 
>      > On Mon, Oct 26, 2020, 8:19 AM Ben Bolker <bbolker at gmail.com> wrote:
> 
>      >> Can you clarify a bit what you want to plot?
>      >> as.data.frame(p) is a good way to retrieve a simple data frame from
>      >> profile objects that you can then transform/use to plot as you see fit.
>      >>
>      >> Ben Bolker
>      >>
>      >> On 10/25/20 8:54 PM, Simon Harmel wrote:
>      >> > Dear All,
>      >> >
>      >> > I'm trying to plot the sampling distributions of my model parameters
>      >> using `
>      >> > densityplot()` from the `lattice` package but lattice often throws an
>      >> error
>      >> > even if one of the estimate's density distribution is highly skewed or
>      >> > funny-looking.
>      >> >
>      >> > Is there a better package or a better way (even manually) to plot the
>      >> > densities (not Zeta) from a `profile()` call?
> 
>     hsb <- read.csv('https://raw.githubusercontent.com/rnorouzian/e/master/hsb.csv')
> 
>     library(lme4) # gets 'lattice'
>     m31 <- lmer(math ~ ses*meanses + (ses | sch.id), data = hsb)
> 
>     p <-  profile(m31)
> 
> ## the profiling above gives *TONS and TONS* of warnings !
> 
> ## so I guess now wonder you cannot easily plot it ..
> ## still you should at least get a better  error message
> 
>>
> densityplot(p)
>> Error in UseMethod("predict") :
>>   no applicable method for 'predict' applied to an object of class
>>    NULL
> 
> 
> 
> Here's what I do to "summarize" ... and show "the solution" (?)
> 
> options(nwarnings=2^12) # so we store all the warnings !
> system.time( p <- profile(m31) )
> ##   user  system elapsed
> ## 19.007   0.002  19.111
> ## There were 92 warnings (use warnings() to see them)
> 
> ## MM: the cool thing is I wrote a summary() method for warnings in R
> ##     a while ago, so use it:
> summary( warnings() )
> ## Summary of (a total of 92) warning messages:
> ##  3x : In nextpar(mat, cc, i, delta, lowcut, upcut) :
> ##   unexpected decrease in profile: using minstep
> ## 88x : In nextpar(mat, cc, i, delta, lowcut, upcut) :
> ##   Last two rows have identical or NA .zeta values: using minstep
> ##  1x : In FUN(X[[i]], ...) : non-monotonic profile for .sig02
> 
> confint(p)
>>                   2.5 %     97.5 %
>> .sig01       1.4034755  1.8925324
>> .sig02      -0.9025412  0.2035804
>> .sig03       0.1824510  0.9800896
>> .sigma       5.9659398  6.1688744
>> (Intercept) 12.3231883 12.9337235
>> ses          1.9545565  2.4326048
>> meanses      3.0178000  4.5260869
>> ses:meanses -0.4044241  0.7279685
>> Warning messages:
>> 1: In confint.thpr(p) :
>>    bad spline fit for .sig02: falling back to linear interpolation
>> 2: In regularize.values(x, y, ties, missing(ties), na.rm = na.rm) :
>>    collapsing to unique 'x' values
> 
> so you see indeed, that  sig02 should probably be omitted from
> the model
> 
> which I can "easily" confirm :
> 
> m30 <- lmer(math ~ ses * meanses + (1|sch.id) + (0+ ses | sch.id), data= hsb)
> m20 <- lmer(math ~ ses * meanses + (1|sch.id), data= hsb)
> 
> anova(m31,m30,m20)
>> refitting model(s) with ML (instead of REML)
>> Data: hsb
>> Models:
>> m20: math ~ ses * meanses + (1 | sch.id)
>> m30: math ~ ses * meanses + (1 | sch.id) + (0 + ses | sch.id)
>> m31: math ~ ses * meanses + (ses | sch.id)
>>      npar   AIC   BIC logLik deviance  Chisq Df Pr(>Chisq)
>> m20    6 46575 46616 -23282    46563
>> m30    7 46572 46620 -23279    46558 5.5415  1    0.01857 *
>> m31    8 46573 46628 -23278    46557 0.9669  1    0.32546
>> ---
>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> 
> So it seems m30, the model with no correlation between intercept
> and slope fits well enough
> 
> and indeed,
> 
> system.time( p30 <- profile(m30 )
> ## ends in 5 sec, without any warnings,
> 
> and then
> 
> xyplot(p30)  # <-- more useful I think than
> densityplot(p30) # both work fine
> 
> -- still I agree there's something we should do to fix the
>     buglet !!
> 
> Martin Maechler
> ETH Zurich
>


From @|m@h@rme| @end|ng |rom gm@||@com  Tue Oct 27 05:52:06 2020
From: @|m@h@rme| @end|ng |rom gm@||@com (Simon Harmel)
Date: Mon, 26 Oct 2020 23:52:06 -0500
Subject: [R-sig-ME] 
 lme4: plotting profile density (not Zeta) manually not by lattice
In-Reply-To: <9e8f40b2-5d4e-d0c2-085b-e9204aee1b64@gmail.com>
References: <CACgv6yU6+t69mOzN-ZwUCoR9oWk4mpNSsDnKxqTksK3nEvX_ag@mail.gmail.com>
 <6e76e2e4-e974-60b0-33c4-c0c8074ad185@gmail.com>
 <CACgv6yX4ouiySba7s_NbmOnm4FVPXXdJQ2A49L6Ou_GNTOOqFA@mail.gmail.com>
 <24470.62274.33849.795053@stat.math.ethz.ch>
 <9e8f40b2-5d4e-d0c2-085b-e9204aee1b64@gmail.com>
Message-ID: <CACgv6yVgrYBow448oyJyOiNANABAgP1HQKYatUO9TpBmnx2+Qw@mail.gmail.com>

Awesome, thanks! That was what I was looking for.

On Mon, Oct 26, 2020 at 9:38 PM Ben Bolker <bbolker at gmail.com> wrote:

>     I've pushed an improved version of densityplot to github.  It
> creates density plots for all but .sig02 (the correlation parameter, I
> think), leaving that panel blank, and warns about skipped parameters.
> Give it a try ...
>
> On 10/26/20 12:03 PM, Martin Maechler wrote:
> >>>>>> Simon Harmel
> >>>>>>      on Mon, 26 Oct 2020 09:51:26 -0500 writes:
> >
> >      > Ben,
> >      > I expect the exact same plots that
> densityplot(profile(fitted_model)) from
> >      > lattice produces?
> >
> >      > again, densityplot(profile(fitted_model)) throws an error for the
> model in
> >      > my original question (and generally when any parameter's
> likelihood
> >      > distribution is highly spiked or funny-looking)
> >
> > Hmm.. interesting.
> > As I'm coauthor of lme4  and have been doing nonparametric curve
> > estimation during my ph.d. years ("yesterday, .."),
> > I'm interested to rather fix the problem than try other
> > packages.
> >
> >  From your error message, there must be a buglet in either lattice
> > or lme4 ...
> >
> > *BUT* (see below)
> >
> >      > On Mon, Oct 26, 2020, 8:19 AM Ben Bolker <bbolker at gmail.com>
> wrote:
> >
> >      >> Can you clarify a bit what you want to plot?
> >      >> as.data.frame(p) is a good way to retrieve a simple data frame
> from
> >      >> profile objects that you can then transform/use to plot as you
> see fit.
> >      >>
> >      >> Ben Bolker
> >      >>
> >      >> On 10/25/20 8:54 PM, Simon Harmel wrote:
> >      >> > Dear All,
> >      >> >
> >      >> > I'm trying to plot the sampling distributions of my model
> parameters
> >      >> using `
> >      >> > densityplot()` from the `lattice` package but lattice often
> throws an
> >      >> error
> >      >> > even if one of the estimate's density distribution is highly
> skewed or
> >      >> > funny-looking.
> >      >> >
> >      >> > Is there a better package or a better way (even manually) to
> plot the
> >      >> > densities (not Zeta) from a `profile()` call?
> >
> >     hsb <- read.csv('
> https://raw.githubusercontent.com/rnorouzian/e/master/hsb.csv')
> >
> >     library(lme4) # gets 'lattice'
> >     m31 <- lmer(math ~ ses*meanses + (ses | sch.id), data = hsb)
> >
> >     p <-  profile(m31)
> >
> > ## the profiling above gives *TONS and TONS* of warnings !
> >
> > ## so I guess now wonder you cannot easily plot it ..
> > ## still you should at least get a better  error message
> >
> >>
> > densityplot(p)
> >> Error in UseMethod("predict") :
> >>   no applicable method for 'predict' applied to an object of class
> >>    NULL
> >
> >
> >
> > Here's what I do to "summarize" ... and show "the solution" (?)
> >
> > options(nwarnings=2^12) # so we store all the warnings !
> > system.time( p <- profile(m31) )
> > ##   user  system elapsed
> > ## 19.007   0.002  19.111
> > ## There were 92 warnings (use warnings() to see them)
> >
> > ## MM: the cool thing is I wrote a summary() method for warnings in R
> > ##     a while ago, so use it:
> > summary( warnings() )
> > ## Summary of (a total of 92) warning messages:
> > ##  3x : In nextpar(mat, cc, i, delta, lowcut, upcut) :
> > ##   unexpected decrease in profile: using minstep
> > ## 88x : In nextpar(mat, cc, i, delta, lowcut, upcut) :
> > ##   Last two rows have identical or NA .zeta values: using minstep
> > ##  1x : In FUN(X[[i]], ...) : non-monotonic profile for .sig02
> >
> > confint(p)
> >>                   2.5 %     97.5 %
> >> .sig01       1.4034755  1.8925324
> >> .sig02      -0.9025412  0.2035804
> >> .sig03       0.1824510  0.9800896
> >> .sigma       5.9659398  6.1688744
> >> (Intercept) 12.3231883 12.9337235
> >> ses          1.9545565  2.4326048
> >> meanses      3.0178000  4.5260869
> >> ses:meanses -0.4044241  0.7279685
> >> Warning messages:
> >> 1: In confint.thpr(p) :
> >>    bad spline fit for .sig02: falling back to linear interpolation
> >> 2: In regularize.values(x, y, ties, missing(ties), na.rm = na.rm) :
> >>    collapsing to unique 'x' values
> >
> > so you see indeed, that  sig02 should probably be omitted from
> > the model
> >
> > which I can "easily" confirm :
> >
> > m30 <- lmer(math ~ ses * meanses + (1|sch.id) + (0+ ses | sch.id),
> data= hsb)
> > m20 <- lmer(math ~ ses * meanses + (1|sch.id), data= hsb)
> >
> > anova(m31,m30,m20)
> >> refitting model(s) with ML (instead of REML)
> >> Data: hsb
> >> Models:
> >> m20: math ~ ses * meanses + (1 | sch.id)
> >> m30: math ~ ses * meanses + (1 | sch.id) + (0 + ses | sch.id)
> >> m31: math ~ ses * meanses + (ses | sch.id)
> >>      npar   AIC   BIC logLik deviance  Chisq Df Pr(>Chisq)
> >> m20    6 46575 46616 -23282    46563
> >> m30    7 46572 46620 -23279    46558 5.5415  1    0.01857 *
> >> m31    8 46573 46628 -23278    46557 0.9669  1    0.32546
> >> ---
> >> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> >
> > So it seems m30, the model with no correlation between intercept
> > and slope fits well enough
> >
> > and indeed,
> >
> > system.time( p30 <- profile(m30 )
> > ## ends in 5 sec, without any warnings,
> >
> > and then
> >
> > xyplot(p30)  # <-- more useful I think than
> > densityplot(p30) # both work fine
> >
> > -- still I agree there's something we should do to fix the
> >     buglet !!
> >
> > Martin Maechler
> > ETH Zurich
> >
>

	[[alternative HTML version deleted]]


From @|m@h@rme| @end|ng |rom gm@||@com  Tue Oct 27 08:37:13 2020
From: @|m@h@rme| @end|ng |rom gm@||@com (Simon Harmel)
Date: Tue, 27 Oct 2020 02:37:13 -0500
Subject: [R-sig-ME] pooled within-cluster regression line
Message-ID: <CACgv6yWU1+VJDuze81jz7SCZkoWNKGhG3SqGypgc-mE5-H0f3A@mail.gmail.com>

Dear All,

Top panel of Figure 3 of this open access paper (see **link below**) shows
3 clusters of datapoints, each with five datapoints.

The authors note:

> "The dotted line represents the regression of well-being (y) on workload
(x) within each cluster (i.e., the pooled within-cluster regression,
Beta_w)".

Say I have the hypothetical data blow with 3 clusters (`group`). How can I
find and draw the **the pooled within-cluster, $\beta_w$** regression line?

THE LINK: (
https://www.researchgate.net/publication/6274186_Centering_Predictor_Variables_in_Cross-Sectional_Multilevel_Models_A_New_Look_at_An_Old_Issue
)

## R code: ---------------------------------------------------
  set.seed(2)
  pop_mean <- 80
  n_groups <- 3
  groups <- gl(n_groups, 5)
  x <-rnorm(length(groups), 55, 15)
  Z <-model.matrix(~groups-1)
  group_means <-rnorm(n_groups, 0, 2.5)
  y <- pop_mean + -.3*x + Z%*%group_means + rnorm(length(groups), 0, 2)
  data <- data.frame(y, groups, x)

	[[alternative HTML version deleted]]


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Tue Oct 27 10:06:41 2020
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Tue, 27 Oct 2020 10:06:41 +0100
Subject: [R-sig-ME] 
 lme4: plotting profile density (not Zeta) manually not by lattice
In-Reply-To: <9e8f40b2-5d4e-d0c2-085b-e9204aee1b64@gmail.com>
References: <CACgv6yU6+t69mOzN-ZwUCoR9oWk4mpNSsDnKxqTksK3nEvX_ag@mail.gmail.com>
 <6e76e2e4-e974-60b0-33c4-c0c8074ad185@gmail.com>
 <CACgv6yX4ouiySba7s_NbmOnm4FVPXXdJQ2A49L6Ou_GNTOOqFA@mail.gmail.com>
 <24470.62274.33849.795053@stat.math.ethz.ch>
 <9e8f40b2-5d4e-d0c2-085b-e9204aee1b64@gmail.com>
Message-ID: <24471.58145.891011.93342@stat.math.ethz.ch>

>>>>> Ben Bolker 
>>>>>     on Mon, 26 Oct 2020 22:38:10 -0400 writes:

    > I've pushed an improved version of densityplot to github.  It 
    > creates density plots for all but .sig02 (the correlation parameter, I 
    > think), leaving that panel blank, and warns about skipped parameters. 
    > Give it a try ...

That may be the best solution.

Note that xyplot()  which I'd prefer over densityplot() almost
always *does* deal with the situation,
using linear interpolation instead of the splines (which failed
here for .sig02).

We may also think of an alternative for parameters where the
splines had failed.  Simply skipping it for the plot seems "too
dangerous".

In your case the good model is really the m30 I used in my
previous e-mail, which indeed is the one where you set
the ".sig02"  \sigma_2 = 0

Martin


    > On 10/26/20 12:03 PM, Martin Maechler wrote:
    >>>>>>> Simon Harmel
    >>>>>>> on Mon, 26 Oct 2020 09:51:26 -0500 writes:
    >> 
    >> > Ben,
    >> > I expect the exact same plots that densityplot(profile(fitted_model)) from
    >> > lattice produces?
    >> 
    >> > again, densityplot(profile(fitted_model)) throws an error for the model in
    >> > my original question (and generally when any parameter's likelihood
    >> > distribution is highly spiked or funny-looking)
    >> 
    >> Hmm.. interesting.
    >> As I'm coauthor of lme4  and have been doing nonparametric curve
    >> estimation during my ph.d. years ("yesterday, .."),
    >> I'm interested to rather fix the problem than try other
    >> packages.
    >> 
    >> From your error message, there must be a buglet in either lattice
    >> or lme4 ...
    >> 
    >> *BUT* (see below)
    >> 
    >> > On Mon, Oct 26, 2020, 8:19 AM Ben Bolker <bbolker at gmail.com> wrote:
    >> 
    >> >> Can you clarify a bit what you want to plot?
    >> >> as.data.frame(p) is a good way to retrieve a simple data frame from
    >> >> profile objects that you can then transform/use to plot as you see fit.
    >> >>
    >> >> Ben Bolker
    >> >>
    >> >> On 10/25/20 8:54 PM, Simon Harmel wrote:
    >> >> > Dear All,
    >> >> >
    >> >> > I'm trying to plot the sampling distributions of my model parameters
    >> >> using `
    >> >> > densityplot()` from the `lattice` package but lattice often throws an
    >> >> error
    >> >> > even if one of the estimate's density distribution is highly skewed or
    >> >> > funny-looking.
    >> >> >
    >> >> > Is there a better package or a better way (even manually) to plot the
    >> >> > densities (not Zeta) from a `profile()` call?
    >> 
    >> hsb <- read.csv('https://raw.githubusercontent.com/rnorouzian/e/master/hsb.csv')
    >> 
    >> library(lme4) # gets 'lattice'
    >> m31 <- lmer(math ~ ses*meanses + (ses | sch.id), data = hsb)
    >> 
    >> p <-  profile(m31)
    >> 
    >> ## the profiling above gives *TONS and TONS* of warnings !
    >> 
    >> ## so I guess now wonder you cannot easily plot it ..
    >> ## still you should at least get a better  error message
    >> 
    >>> 
    >> densityplot(p)
    >>> Error in UseMethod("predict") :
    >>> no applicable method for 'predict' applied to an object of class
    >>> NULL
    >> 
    >> 
    >> 
    >> Here's what I do to "summarize" ... and show "the solution" (?)
    >> 
    >> options(nwarnings=2^12) # so we store all the warnings !
    >> system.time( p <- profile(m31) )
    >> ##   user  system elapsed
    >> ## 19.007   0.002  19.111
    >> ## There were 92 warnings (use warnings() to see them)
    >> 
    >> ## MM: the cool thing is I wrote a summary() method for warnings in R
    >> ##     a while ago, so use it:
    >> summary( warnings() )
    >> ## Summary of (a total of 92) warning messages:
    >> ##  3x : In nextpar(mat, cc, i, delta, lowcut, upcut) :
    >> ##   unexpected decrease in profile: using minstep
    >> ## 88x : In nextpar(mat, cc, i, delta, lowcut, upcut) :
    >> ##   Last two rows have identical or NA .zeta values: using minstep
    >> ##  1x : In FUN(X[[i]], ...) : non-monotonic profile for .sig02
    >> 
    >> confint(p)
    >>> 2.5 %     97.5 %
    >>> .sig01       1.4034755  1.8925324
    >>> .sig02      -0.9025412  0.2035804
    >>> .sig03       0.1824510  0.9800896
    >>> .sigma       5.9659398  6.1688744
    >>> (Intercept) 12.3231883 12.9337235
    >>> ses          1.9545565  2.4326048
    >>> meanses      3.0178000  4.5260869
    >>> ses:meanses -0.4044241  0.7279685
    >>> Warning messages:
    >>> 1: In confint.thpr(p) :
    >>> bad spline fit for .sig02: falling back to linear interpolation
    >>> 2: In regularize.values(x, y, ties, missing(ties), na.rm = na.rm) :
    >>> collapsing to unique 'x' values
    >> 
    >> so you see indeed, that  sig02 should probably be omitted from
    >> the model
    >> 
    >> which I can "easily" confirm :
    >> 
    >> m30 <- lmer(math ~ ses * meanses + (1|sch.id) + (0+ ses | sch.id), data= hsb)
    >> m20 <- lmer(math ~ ses * meanses + (1|sch.id), data= hsb)
    >> 
    >> anova(m31,m30,m20)
    >>> refitting model(s) with ML (instead of REML)
    >>> Data: hsb
    >>> Models:
    >>> m20: math ~ ses * meanses + (1 | sch.id)
    >>> m30: math ~ ses * meanses + (1 | sch.id) + (0 + ses | sch.id)
    >>> m31: math ~ ses * meanses + (ses | sch.id)
    >>> npar   AIC   BIC logLik deviance  Chisq Df Pr(>Chisq)
    >>> m20    6 46575 46616 -23282    46563
    >>> m30    7 46572 46620 -23279    46558 5.5415  1    0.01857 *
    >>> m31    8 46573 46628 -23278    46557 0.9669  1    0.32546
    >>> ---
    >>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
    >> 
    >> So it seems m30, the model with no correlation between intercept
    >> and slope fits well enough
    >> 
    >> and indeed,
    >> 
    >> system.time( p30 <- profile(m30 )
    >> ## ends in 5 sec, without any warnings,
    >> 
    >> and then
    >> 
    >> xyplot(p30)  # <-- more useful I think than
    >> densityplot(p30) # both work fine
    >> 
    >> -- still I agree there's something we should do to fix the
    >> buglet !!
    >> 
    >> Martin Maechler
    >> ETH Zurich
    >>


From o||v|er@ren@ud @end|ng |rom un|ge@ch  Wed Oct 28 11:51:34 2020
From: o||v|er@ren@ud @end|ng |rom un|ge@ch (Olivier Renaud)
Date: Wed, 28 Oct 2020 11:51:34 +0100
Subject: [R-sig-ME] Open PhD position on mixed effect models at University
 of Geneva
In-Reply-To: <948d5428-00bc-7383-ae0a-f6aa37c523cf@unige.ch>
References: <948d5428-00bc-7383-ae0a-f6aa37c523cf@unige.ch>
Message-ID: <b0179d57-dfde-87c8-a069-ffd8998b1ef4@unige.ch>


I would appreciate it if you can forward this email to anyone who might 
be interested.

The Methodology and Data Analysis group ( https://www.unige.ch/fapse/mad 
) at the University of Geneva (Switzerland) is considering applications 
for a 4-year PhD position funded by the Swiss National Science Foundation.

The PhD student will be enrolled in the statistics PhD program and will 
be under the supervision of Prof. Olivier Renaud. The topic of the 
thesis focusses on the development of new methods in mixed effect models 
to be applied in psychology and in neurosciences. Broadly speaking, it 
will consist in both statistical and computational extensions of 
Frossard J, Renaud O (2019) Choosing the correlation structure of mixed 
effect models for experiments with stimuli. 
http://arxiv.org/abs/1903.10766 .

Ideal candidates would hold a Master in statistics, or a related field, 
have excellent skills in mathematical statistics, have excellent 
programming skills, be interested in interdisciplinary research, and be 
proficient in English.

Geneva is a great place to work and is noted for its international 
character and its high quality of life. The research environment is very 
interdisciplinary, with great conditions, the possibility to interact 
and to improve general and technical skills e.g. through programs for 
doctoral students.

For more information and to apply send an e-mail to 
mailto:Olivier.Renaud at unige.ch . Applications should include a short 
statement of research interests, CV, copies of Bachelor and Master 
degrees, including the grades obtained, and contact details of potential 
references, who can be contacted for more information.

Review of applications will begin immediately and will continue until 
the position has been filled.

Olivier Renaud https://www.unige.ch/fapse/mad/renaud/

full text: https://www.unige.ch/fapse/mad/openposition/


	[[alternative HTML version deleted]]


From don-|me4 @end|ng |rom |@|@@c@3-|nc@com  Thu Oct 29 02:20:29 2020
From: don-|me4 @end|ng |rom |@|@@c@3-|nc@com (Don Cohen)
Date: Thu, 29 Oct 2020 01:20:29 +0000
Subject: [R-sig-ME] next question about random effects (and where to post)
In-Reply-To: <ccaee4aa-ef25-de9b-e997-40792c920942@gmail.com>
References: <20201023014039.2BC5F40486@chmusic.org>
 <ccaee4aa-ef25-de9b-e997-40792c920942@gmail.com>
Message-ID: <24474.6365.372649.909800@chmusic.org>


Ben Bolker writes:

 >   This is one of the advantages of forums like StackOverflow or 
 > CrossValidated that (1) are much easier to search for old questions; (2) 
 > allow people to offer 'brownie points' for solutions to interesting 
 > questions.  (I think a sufficient interval has gone by that it would be 
 > reasonable to cross-post it to CrossValidated ...)

I've now posted a few things to CrossValidated and seen no responses:

https://stats.stackexchange.com/questions/242821/how-will-random-effects-with-only-1-observation-affect-a-generalized-linear-mixe/493597

https://stats.stackexchange.com/questions/493601/random-effect-with-one-observation-per-group-improves-aic-drastically-explain

So that's one reason to send the next one back here.
This is related to the first link above, but it may actually
be specific to glmmTMB.  In fact it didn't work in lmer, I 
gather precisely because it has as many groups as obervations.

Here I have a random effect with one group per observation,
which I claimed made sense in cases like the second link above,
but not in THIS case.  And yet I get no complaints, and a 
separate variance for the residual and the group.
I don't understand how these can be separated.  
Wouldn't any combination of the two with the same sum of 
variances give the same loglik ?  Or perhaps this solution
is being returned since it's as good as any other, even though
others are equally good?  (But without warning?)


> md2 <- glmmTMB( Y ~ (1|Id), data = d2 )
> summary(md2)
 Family: gaussian  ( identity )
Formula:          Y ~ (1 | Id)
Data: d2

     AIC      BIC   logLik deviance df.resid 
    18.4     16.5     -6.2     12.4        1 

Random effects:

Conditional model:
 Groups   Name        Variance Std.Dev.
 Id       (Intercept) 0.4248   0.6518  
 Residual             0.8606   0.9277  
Number of obs: 4, groups:  Id, 4

Dispersion estimate for gaussian family (sigma^2): 0.861 

Conditional model:
            Estimate Std. Error z value Pr(>|z|)    
(Intercept)  10.0478     0.5669   17.73   <2e-16 ***


From @|m@h@rme| @end|ng |rom gm@||@com  Thu Oct 29 03:29:53 2020
From: @|m@h@rme| @end|ng |rom gm@||@com (Simon Harmel)
Date: Wed, 28 Oct 2020 21:29:53 -0500
Subject: [R-sig-ME] lme4: Obtaining the SE of difference in two
 fixed-effects slope
Message-ID: <CACgv6yVbsBJanYRLo4af7P=wUCLQn7RiyhPmE06sSVxNxbdF3Q@mail.gmail.com>

Dear All,

I'm interested in obtaining standard error (SE) of [*meanses - ses]* estimate
in my model below which serves as the contextual effect coefficient.

Is there a way to obtain this SE in R?

hsb <- read.csv('
https://raw.githubusercontent.com/rnorouzian/e/master/hsb.csv')

fit <- lmer(math ~ ses + meanses + (1|sch.id), data = hsb)

coef(summary(fit))

             Estimate Std. Error   t value
(Intercept) 12.661262  0.1493726 84.762956
ses          2.191165  0.1086673 20.163983
meanses      3.675037  0.3776607  9.731055

	[[alternative HTML version deleted]]


From ru@@e||-|enth @end|ng |rom u|ow@@edu  Thu Oct 29 14:42:35 2020
From: ru@@e||-|enth @end|ng |rom u|ow@@edu (Lenth, Russell V)
Date: Thu, 29 Oct 2020 13:42:35 +0000
Subject: [R-sig-ME] lme4: Obtaining the SE of difference in two
 fixed-effects
Message-ID: <CH2PR04MB6855CBF23FA4AC298D9CDE9EF1140@CH2PR04MB6855.namprd04.prod.outlook.com>

Do this:

    a <- c(0, 1, -1)
    V <- vcov(fit)
    sqrt(t(a) %*% V %*% a)

Russ


-----Original Message-----

Message: 2
Date: Wed, 28 Oct 2020 21:29:53 -0500
From: Simon Harmel <sim.harmel at gmail.com>
To: r-sig-mixed-models <r-sig-mixed-models at r-project.org>
Subject: [R-sig-ME] lme4: Obtaining the SE of difference in two
	fixed-effects slope
Message-ID:
	<CACgv6yVbsBJanYRLo4af7P=wUCLQn7RiyhPmE06sSVxNxbdF3Q at mail.gmail.com>
Content-Type: text/plain; charset="utf-8"

Dear All,

I'm interested in obtaining standard error (SE) of [*meanses - ses]* estimate
in my model below which serves as the contextual effect coefficient.

Is there a way to obtain this SE in R?

hsb <- read.csv('
https://raw.githubusercontent.com/rnorouzian/e/master/hsb.csv')

fit <- lmer(math ~ ses + meanses + (1|sch.id), data = hsb)

coef(summary(fit))

             Estimate Std. Error   t value
(Intercept) 12.661262  0.1493726 84.762956
ses          2.191165  0.1086673 20.163983
meanses      3.675037  0.3776607  9.731055


From bbo|ker @end|ng |rom gm@||@com  Thu Oct 29 15:29:36 2020
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Thu, 29 Oct 2020 10:29:36 -0400
Subject: [R-sig-ME] lme4: Obtaining the SE of difference in two
 fixed-effects
In-Reply-To: <CH2PR04MB6855CBF23FA4AC298D9CDE9EF1140@CH2PR04MB6855.namprd04.prod.outlook.com>
References: <CH2PR04MB6855CBF23FA4AC298D9CDE9EF1140@CH2PR04MB6855.namprd04.prod.outlook.com>
Message-ID: <5fb4d80f-f31f-2559-363a-d65ee35403f5@gmail.com>

   Another slightly more automated way to do this is with the 'glht' 
function from multcomp

library(multcomp)
g1 <- glht(fit,linfct=matrix(c(0,1,-1),nrow=1))
(ss <- summary(g1))

	 Simultaneous Tests for General Linear Hypotheses

Fit: lmer(formula = math ~ ses + meanses + (1 | sch.id), data = hsb)

Linear Hypotheses:
        Estimate Std. Error z value Pr(>|z|)
1 == 0   -1.484      0.422  -3.517 0.000437 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
(Adjusted p values reported -- single-step method)

   The 'linfct' argument here is the same as Russ's 'a' vector: it's the 
multiplier for each coefficient in the contrast you want to test.

   ss$sigma will extract the SD from the summary object.


On 10/29/20 9:42 AM, Lenth, Russell V wrote:
> Do this:
> 
>      a <- c(0, 1, -1)
>      V <- vcov(fit)
>      sqrt(t(a) %*% V %*% a)
> 
> Russ
> 
> 
> -----Original Message-----
> 
> Message: 2
> Date: Wed, 28 Oct 2020 21:29:53 -0500
> From: Simon Harmel <sim.harmel at gmail.com>
> To: r-sig-mixed-models <r-sig-mixed-models at r-project.org>
> Subject: [R-sig-ME] lme4: Obtaining the SE of difference in two
> 	fixed-effects slope
> Message-ID:
> 	<CACgv6yVbsBJanYRLo4af7P=wUCLQn7RiyhPmE06sSVxNxbdF3Q at mail.gmail.com>
> Content-Type: text/plain; charset="utf-8"
> 
> Dear All,
> 
> I'm interested in obtaining standard error (SE) of [*meanses - ses]* estimate
> in my model below which serves as the contextual effect coefficient.
> 
> Is there a way to obtain this SE in R?
> 
> hsb <- read.csv('
> https://raw.githubusercontent.com/rnorouzian/e/master/hsb.csv')
> 
> fit <- lmer(math ~ ses + meanses + (1|sch.id), data = hsb)
> 
> coef(summary(fit))
> 
>               Estimate Std. Error   t value
> (Intercept) 12.661262  0.1493726 84.762956
> ses          2.191165  0.1086673 20.163983
> meanses      3.675037  0.3776607  9.731055
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From th|erry@onke||nx @end|ng |rom |nbo@be  Thu Oct 29 18:09:25 2020
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Thu, 29 Oct 2020 18:09:25 +0100
Subject: [R-sig-ME] lme4: Obtaining the SE of difference in two
 fixed-effects slope
In-Reply-To: <CACgv6yVbsBJanYRLo4af7P=wUCLQn7RiyhPmE06sSVxNxbdF3Q@mail.gmail.com>
References: <CACgv6yVbsBJanYRLo4af7P=wUCLQn7RiyhPmE06sSVxNxbdF3Q@mail.gmail.com>
Message-ID: <CAJuCY5ysmAZeXzO74nOb8GKruBbACCX_H045tqtUnw2twLGfHA@mail.gmail.com>

Dear Simon,

You want to compute a contrast. You can do this with the glht() function
from the multcomp package.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op do 29 okt. 2020 om 03:30 schreef Simon Harmel <sim.harmel at gmail.com>:

> Dear All,
>
> I'm interested in obtaining standard error (SE) of [*meanses - ses]*
> estimate
> in my model below which serves as the contextual effect coefficient.
>
> Is there a way to obtain this SE in R?
>
> hsb <- read.csv('
> https://raw.githubusercontent.com/rnorouzian/e/master/hsb.csv')
>
> fit <- lmer(math ~ ses + meanses + (1|sch.id), data = hsb)
>
> coef(summary(fit))
>
>              Estimate Std. Error   t value
> (Intercept) 12.661262  0.1493726 84.762956
> ses          2.191165  0.1086673 20.163983
> meanses      3.675037  0.3776607  9.731055
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From |@b|en@|eboeu| @end|ng |rom gm@||@com  Fri Oct 30 11:08:30 2020
From: |@b|en@|eboeu| @end|ng |rom gm@||@com (fabien leboeuf)
Date: Fri, 30 Oct 2020 11:08:30 +0100
Subject: [R-sig-ME] ICC from lmer with back transform
Message-ID: <CAGYcRVFz4iH3GCuupbJW7NQLMKJAo=iQF-Z8qTs8i=j7R3qm1Q@mail.gmail.com>

Hello
what a nice idea to have a forum dedidated to lmer question :-). i came
acros it from cross-validated.

Here is my question:

I want to calculate the ICC from a mixed model coded with lmer as follow.

model <- lmer(formula = log(VARIABLE) ~ 1
+(1|Side)+(1|Asessor)+(1|ID), data = data,REML=FALSE)

am i wrong if i compute the iCC from back transform , like that

vc <- as.data.frame((VarCorr(model)))
ICC_log = sum(exp(vc$vcov[1]),exp(vc$vcov[3]))/(sum(exp(vc$vcov)))

I appreciate any replies.

Fabien

-- 
Fabien

----------------------------------------------------------------------------------------------
Fabien Leboeuf
-------------------------------------------------------
Ing?nieur "analyste du mouvement" du Pole 10, CHU Nantes, France
Chercheur associ? de l'Universit? de Salford, Manchester, Royaume uni
-------------------------------------------------------
Laboratoire d'analyse du mouvement
85 rue saint Jacques
44093 Nantes, FRANCE
------------------------------------------------------------------------------------------------

	[[alternative HTML version deleted]]


From p|erre@dev|||emereu|| @end|ng |rom ephe@p@|@eu  Fri Oct 30 11:35:57 2020
From: p|erre@dev|||emereu|| @end|ng |rom ephe@p@|@eu (Pierre de Villemereuil)
Date: Fri, 30 Oct 2020 11:35:57 +0100
Subject: [R-sig-ME] ICC from lmer with back transform
In-Reply-To: <CAGYcRVFz4iH3GCuupbJW7NQLMKJAo=iQF-Z8qTs8i=j7R3qm1Q@mail.gmail.com>
References: <CAGYcRVFz4iH3GCuupbJW7NQLMKJAo=iQF-Z8qTs8i=j7R3qm1Q@mail.gmail.com>
Message-ID: <1961458.u106kpX54X@flyosfixe>

Hi,

I am not sure I understand your calculation proposal, but if you want to compute the ICC from the original scale before a log-transformation, you will need to also account for the intercept and the formula is a bit more complex. You can see equations 35 and 36 of:
Nakagawa, S. & Schielzeth, H. Repeatability for Gaussian and non Gaussian data: a practical guide for biologists. Biological Reviews 85, 935?956 (2010).

Note that, due to Jensen's inequality, I believe that, to use these equations, you'd need your to use a log-link rather than a log-transform in the formula (although in practice, the difference might be subtle). Something like:

model <- lmer(VARIABLE ~ 1 +(1|Side)+(1|Asessor)+(1|ID), data = data, family = gaussian(link = "log"), REML=FALSE)

Hope this helps,
Pierre

Le vendredi 30 octobre 2020, 11:08:30 CET fabien leboeuf a ?crit :
> Hello
> what a nice idea to have a forum dedidated to lmer question :-). i came
> acros it from cross-validated.
> 
> Here is my question:
> 
> I want to calculate the ICC from a mixed model coded with lmer as follow.
> 
> model <- lmer(formula = log(VARIABLE) ~ 1
> +(1|Side)+(1|Asessor)+(1|ID), data = data,REML=FALSE)
> 
> am i wrong if i compute the iCC from back transform , like that
> 
> vc <- as.data.frame((VarCorr(model)))
> ICC_log = sum(exp(vc$vcov[1]),exp(vc$vcov[3]))/(sum(exp(vc$vcov)))
> 
> I appreciate any replies.
> 
> Fabien
> 
> 


From p|erre@dev|||emereu|| @end|ng |rom ephe@p@|@eu  Fri Oct 30 12:14:06 2020
From: p|erre@dev|||emereu|| @end|ng |rom ephe@p@|@eu (Pierre de Villemereuil)
Date: Fri, 30 Oct 2020 12:14:06 +0100
Subject: [R-sig-ME] ICC from lmer with back transform
In-Reply-To: <1961458.u106kpX54X@flyosfixe>
References: <CAGYcRVFz4iH3GCuupbJW7NQLMKJAo=iQF-Z8qTs8i=j7R3qm1Q@mail.gmail.com>
 <1961458.u106kpX54X@flyosfixe>
Message-ID: <2007976.hZtzzLRu93@flyosfixe>

Sorry, I was a bit confused during my previous response. Thinking now more clearly about this.

- If you are using a log-transform in the formula as per your first email, then Eq. 35 is actually much simpler and does not depend on Eq. 36, it becomes:
ICC = (exp(var_effect) - 1) / (exp(var_tot) -1)
where var_effect is the variance of the effect you want to measure the ICC of and var_tot is the sum of the random variance components. Note that this ICC will measure how much of the variance you can predict knowing the effect, but it does not work as a "variance decomposition" framework, because the ICCs from all variance components (including "residual") will not sum up to 1 as they do for a classical LMM.

- Using a log-link as I suggested actually makes everything more complicated and I am still unsure what would the impact of Jensen's equality be. I'll need to think more about this in terms of the impact on these back-transformations... unless someone already has a clue on this mailing list?

Cheers,
Pierre.

Le vendredi 30 octobre 2020, 11:35:57 CET Pierre de Villemereuil a ?crit :
> Hi,
> 
> I am not sure I understand your calculation proposal, but if you want to compute the ICC from the original scale before a log-transformation, you will need to also account for the intercept and the formula is a bit more complex. You can see equations 35 and 36 of:
> Nakagawa, S. & Schielzeth, H. Repeatability for Gaussian and non Gaussian data: a practical guide for biologists. Biological Reviews 85, 935?956 (2010).
> 
> Note that, due to Jensen's inequality, I believe that, to use these equations, you'd need your to use a log-link rather than a log-transform in the formula (although in practice, the difference might be subtle). Something like:
> 
> model <- lmer(VARIABLE ~ 1 +(1|Side)+(1|Asessor)+(1|ID), data = data, family = gaussian(link = "log"), REML=FALSE)
> 
> Hope this helps,
> Pierre
> 
> Le vendredi 30 octobre 2020, 11:08:30 CET fabien leboeuf a ?crit :
> > Hello
> > what a nice idea to have a forum dedidated to lmer question :-). i came
> > acros it from cross-validated.
> > 
> > Here is my question:
> > 
> > I want to calculate the ICC from a mixed model coded with lmer as follow.
> > 
> > model <- lmer(formula = log(VARIABLE) ~ 1
> > +(1|Side)+(1|Asessor)+(1|ID), data = data,REML=FALSE)
> > 
> > am i wrong if i compute the iCC from back transform , like that
> > 
> > vc <- as.data.frame((VarCorr(model)))
> > ICC_log = sum(exp(vc$vcov[1]),exp(vc$vcov[3]))/(sum(exp(vc$vcov)))
> > 
> > I appreciate any replies.
> > 
> > Fabien
> > 
> > 
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 


From @|m@h@rme| @end|ng |rom gm@||@com  Sun Nov  1 10:02:15 2020
From: @|m@h@rme| @end|ng |rom gm@||@com (Simon Harmel)
Date: Sun, 1 Nov 2020 03:02:15 -0600
Subject: [R-sig-ME] lme: count the number extra parameters estimated for
 variance or covariances
Message-ID: <CACgv6yU6+nOyqH=KO1Cq78h=tALFz_FA4ewh7_5__ixVap+_yw@mail.gmail.com>

Hello All,

In addition to fixed and random effects, is there a way to extract how many
other parameters (for modeling residual variances or covariances) an
"lme()" object has estimated?

Here is a reproducible example:

library(nlme)

hsb <- read.csv('
https://raw.githubusercontent.com/rnorouzian/e/master/hsb.csv')
hsb$female <- as.factor(hsb$female)

fit <- lme(math ~ female, random = ~ 1|sch.id, data = hsb, weights =
varIdent(form = ~1 |female))

	[[alternative HTML version deleted]]


From h@ro|d@dor@n @end|ng |rom c@mb|um@@@e@@ment@com  Sun Nov  1 11:43:37 2020
From: h@ro|d@dor@n @end|ng |rom c@mb|um@@@e@@ment@com (Harold Doran)
Date: Sun, 1 Nov 2020 10:43:37 +0000
Subject: [R-sig-ME] lme: count the number extra parameters estimated for
 variance or covariances
In-Reply-To: <CACgv6yU6+nOyqH=KO1Cq78h=tALFz_FA4ewh7_5__ixVap+_yw@mail.gmail.com>
References: <CACgv6yU6+nOyqH=KO1Cq78h=tALFz_FA4ewh7_5__ixVap+_yw@mail.gmail.com>
Message-ID: <fd1c7706d48046e5b5ad65652176b22b@cambiumassessment.com>

In order to answer that you need to specify what "thing" you want. The object itself has many things and there are extractor functions to grab many of them. I say "thing" because the *parameters* of a mixed model are the fixed effects and the variance components. Random effects etc are not parameters of a mixed model.

You can always look at the structure of a fitted model object in R to see what things are generally in it.

-----Original Message-----
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> On Behalf Of Simon Harmel
Sent: Sunday, November 1, 2020 4:02 AM
To: r-sig-mixed-models <r-sig-mixed-models at r-project.org>
Subject: [R-sig-ME] lme: count the number extra parameters estimated for variance or covariances

External email alert: Be wary of links & attachments.


Hello All,

In addition to fixed and random effects, is there a way to extract how many other parameters (for modeling residual variances or covariances) an "lme()" object has estimated?

Here is a reproducible example:

library(nlme)

hsb <- read.csv('
https://raw.githubusercontent.com/rnorouzian/e/master/hsb.csv')
hsb$female <- as.factor(hsb$female)

fit <- lme(math ~ female, random = ~ 1|sch.id, data = hsb, weights = varIdent(form = ~1 |female))

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From @|m@h@rme| @end|ng |rom gm@||@com  Sun Nov  1 15:57:32 2020
From: @|m@h@rme| @end|ng |rom gm@||@com (Simon Harmel)
Date: Sun, 1 Nov 2020 08:57:32 -0600
Subject: [R-sig-ME] lme: count the number extra parameters estimated for
 variance or covariances
In-Reply-To: <fd1c7706d48046e5b5ad65652176b22b@cambiumassessment.com>
References: <CACgv6yU6+nOyqH=KO1Cq78h=tALFz_FA4ewh7_5__ixVap+_yw@mail.gmail.com>
 <fd1c7706d48046e5b5ad65652176b22b@cambiumassessment.com>
Message-ID: <CACgv6yV32U=w+PaP-nat1igtYMuXUh_LvFRB1h16GiYy6-s=uQ@mail.gmail.com>

Dear Harold,

My question "specifically" is:  is there a way (e.g., via an extractor
function) to obtain parameters estimated for modeling residual variances or
covariances from an "lme" model?

For concreteness, please consider the reproducible model I provided in my
original post in which a variance function has been used.

Thanks,


On Sun, Nov 1, 2020, 4:43 AM Harold Doran <
harold.doran at cambiumassessment.com> wrote:

> In order to answer that you need to specify what "thing" you want. The
> object itself has many things and there are extractor functions to grab
> many of them. I say "thing" because the *parameters* of a mixed model are
> the fixed effects and the variance components. Random effects etc are not
> parameters of a mixed model.
>
> You can always look at the structure of a fitted model object in R to see
> what things are generally in it.
>
> -----Original Message-----
> From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> On
> Behalf Of Simon Harmel
> Sent: Sunday, November 1, 2020 4:02 AM
> To: r-sig-mixed-models <r-sig-mixed-models at r-project.org>
> Subject: [R-sig-ME] lme: count the number extra parameters estimated for
> variance or covariances
>
> External email alert: Be wary of links & attachments.
>
>
> Hello All,
>
> In addition to fixed and random effects, is there a way to extract how
> many other parameters (for modeling residual variances or covariances) an
> "lme()" object has estimated?
>
> Here is a reproducible example:
>
> library(nlme)
>
> hsb <- read.csv('
> https://raw.githubusercontent.com/rnorouzian/e/master/hsb.csv')
> hsb$female <- as.factor(hsb$female)
>
> fit <- lme(math ~ female, random = ~ 1|sch.id, data = hsb, weights =
> varIdent(form = ~1 |female))
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>

	[[alternative HTML version deleted]]


From h@ro|d@dor@n @end|ng |rom c@mb|um@@@e@@ment@com  Sun Nov  1 16:25:32 2020
From: h@ro|d@dor@n @end|ng |rom c@mb|um@@@e@@ment@com (Harold Doran)
Date: Sun, 1 Nov 2020 15:25:32 +0000
Subject: [R-sig-ME] lme: count the number extra parameters estimated for
 variance or covariances
In-Reply-To: <CACgv6yV32U=w+PaP-nat1igtYMuXUh_LvFRB1h16GiYy6-s=uQ@mail.gmail.com>
References: <CACgv6yU6+nOyqH=KO1Cq78h=tALFz_FA4ewh7_5__ixVap+_yw@mail.gmail.com>
 <fd1c7706d48046e5b5ad65652176b22b@cambiumassessment.com>
 <CACgv6yV32U=w+PaP-nat1igtYMuXUh_LvFRB1h16GiYy6-s=uQ@mail.gmail.com>
Message-ID: <9db3914e693b4630a8c6f3324b2838af@cambiumassessment.com>

I think you need to understand what a reproducible example is intended to do. Your data estimates a model and yields a fiitted model object. What parameter from that object using an extractor are you intending to find?

For example, a well posed question would be something like. I want to extract the fixed effects from a fitted model object. How do I get them?

To say I want the ?parameters estimated for modeling residual variances? etc makes no sense. The parameters of a mixed model are the fixed effects and the marginal variances (and covariances) of the random effects.

So, specifically what parameters do you think exist in a model that you want?

From: Simon Harmel <sim.harmel at gmail.com>
Sent: Sunday, November 1, 2020 9:58 AM
To: Harold Doran <harold.doran at cambiumassessment.com>
Cc: r-sig-mixed-models <r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] lme: count the number extra parameters estimated for variance or covariances

Dear Harold,

My question "specifically" is:  is there a way (e.g., via an extractor function) to obtain parameters estimated for modeling residual variances or covariances from an "lme" model?

For concreteness, please consider the reproducible model I provided in my original post in which a variance function has been used.

Thanks,


On Sun, Nov 1, 2020, 4:43 AM Harold Doran <harold.doran at cambiumassessment.com<mailto:harold.doran at cambiumassessment.com>> wrote:
In order to answer that you need to specify what "thing" you want. The object itself has many things and there are extractor functions to grab many of them. I say "thing" because the *parameters* of a mixed model are the fixed effects and the variance components. Random effects etc are not parameters of a mixed model.

You can always look at the structure of a fitted model object in R to see what things are generally in it.

-----Original Message-----
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org<mailto:r-sig-mixed-models-bounces at r-project.org>> On Behalf Of Simon Harmel
Sent: Sunday, November 1, 2020 4:02 AM
To: r-sig-mixed-models <r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>>
Subject: [R-sig-ME] lme: count the number extra parameters estimated for variance or covariances

External email alert: Be wary of links & attachments.


Hello All,

In addition to fixed and random effects, is there a way to extract how many other parameters (for modeling residual variances or covariances) an "lme()" object has estimated?

Here is a reproducible example:

library(nlme)

hsb <- read.csv('
https://raw.githubusercontent.com/rnorouzian/e/master/hsb.csv')
hsb$female <- as.factor(hsb$female)

fit <- lme(math ~ female, random = ~ 1|sch.id<http://sch.id>, data = hsb, weights = varIdent(form = ~1 |female))

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From wo||g@ng@v|echtb@uer @end|ng |rom m@@@tr|chtun|ver@|ty@n|  Sun Nov  1 16:44:40 2020
From: wo||g@ng@v|echtb@uer @end|ng |rom m@@@tr|chtun|ver@|ty@n| (Viechtbauer, Wolfgang (SP))
Date: Sun, 1 Nov 2020 15:44:40 +0000
Subject: [R-sig-ME] lme: count the number extra parameters estimated for
 variance or covariances
In-Reply-To: <9db3914e693b4630a8c6f3324b2838af@cambiumassessment.com>
References: <CACgv6yU6+nOyqH=KO1Cq78h=tALFz_FA4ewh7_5__ixVap+_yw@mail.gmail.com>
 <fd1c7706d48046e5b5ad65652176b22b@cambiumassessment.com>
 <CACgv6yV32U=w+PaP-nat1igtYMuXUh_LvFRB1h16GiYy6-s=uQ@mail.gmail.com>
 <9db3914e693b4630a8c6f3324b2838af@cambiumassessment.com>
Message-ID: <14b45e454e9246f7acddc6ccda5688b7@UM-MAIL3213.unimaas.nl>

Dear Simon,

For variance structures, you can use:

coef(fit$modelStruct$varStruct)

That will give you the parameter estimates involved in the variance structure (in their constrained form as used during the optimization). With:

coef(fit$modelStruct$varStruct, unconstrained=FALSE)

you can get the unconstrained estimates. Only coefficients that are actually estimated are returned by default. With:

coef(fit$modelStruct$varStruct, unconstrained=FALSE, allCoef=TRUE)

you will also get the coefficient (= 1) for the males. But that is not actually an estimated parameter. For more details, see:

help(coef.varFunc)

And these *are* parameters (besides the fixed effects and the vars/covs of the random effects).

Best,
Wolfgang

>-----Original Message-----
>From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org]
>On Behalf Of Harold Doran
>Sent: Sunday, 01 November, 2020 16:26
>To: Simon Harmel
>Cc: r-sig-mixed-models
>Subject: Re: [R-sig-ME] lme: count the number extra parameters estimated for
>variance or covariances
>
>I think you need to understand what a reproducible example is intended to
>do. Your data estimates a model and yields a fiitted model object. What
>parameter from that object using an extractor are you intending to find?
>
>For example, a well posed question would be something like. I want to
>extract the fixed effects from a fitted model object. How do I get them?
>
>To say I want the ?parameters estimated for modeling residual variances? etc
>makes no sense. The parameters of a mixed model are the fixed effects and
>the marginal variances (and covariances) of the random effects.
>
>So, specifically what parameters do you think exist in a model that you
>want?
>
>From: Simon Harmel <sim.harmel at gmail.com>
>Sent: Sunday, November 1, 2020 9:58 AM
>To: Harold Doran <harold.doran at cambiumassessment.com>
>Cc: r-sig-mixed-models <r-sig-mixed-models at r-project.org>
>Subject: Re: [R-sig-ME] lme: count the number extra parameters estimated for
>variance or covariances
>
>Dear Harold,
>
>My question "specifically" is:  is there a way (e.g., via an extractor
>function) to obtain parameters estimated for modeling residual variances or
>covariances from an "lme" model?
>
>For concreteness, please consider the reproducible model I provided in my
>original post in which a variance function has been used.
>
>Thanks,
>
>On Sun, Nov 1, 2020, 4:43 AM Harold Doran
><harold.doran at cambiumassessment.com<mailto:harold.doran at cambiumassessment.co
>m>> wrote:
>In order to answer that you need to specify what "thing" you want. The
>object itself has many things and there are extractor functions to grab many
>of them. I say "thing" because the *parameters* of a mixed model are the
>fixed effects and the variance components. Random effects etc are not
>parameters of a mixed model.
>
>You can always look at the structure of a fitted model object in R to see
>what things are generally in it.
>
>-----Original Message-----
>From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org<mailto:r-
>sig-mixed-models-bounces at r-project.org>> On Behalf Of Simon Harmel
>Sent: Sunday, November 1, 2020 4:02 AM
>To: r-sig-mixed-models <r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-
>models at r-project.org>>
>Subject: [R-sig-ME] lme: count the number extra parameters estimated for
>variance or covariances
>
>External email alert: Be wary of links & attachments.
>
>Hello All,
>
>In addition to fixed and random effects, is there a way to extract how many
>other parameters (for modeling residual variances or covariances) an "lme()"
>object has estimated?
>
>Here is a reproducible example:
>
>library(nlme)
>
>hsb <- read.csv('
>https://raw.githubusercontent.com/rnorouzian/e/master/hsb.csv')
>hsb$female <- as.factor(hsb$female)
>
>fit <- lme(math ~ female, random = ~ 1|sch.id<http://sch.id>, data = hsb,
>weights = varIdent(form = ~1 |female))

From @|m@h@rme| @end|ng |rom gm@||@com  Sun Nov  1 17:14:34 2020
From: @|m@h@rme| @end|ng |rom gm@||@com (Simon Harmel)
Date: Sun, 1 Nov 2020 10:14:34 -0600
Subject: [R-sig-ME] lme: count the number extra parameters estimated for
 variance or covariances
In-Reply-To: <14b45e454e9246f7acddc6ccda5688b7@UM-MAIL3213.unimaas.nl>
References: <CACgv6yU6+nOyqH=KO1Cq78h=tALFz_FA4ewh7_5__ixVap+_yw@mail.gmail.com>
 <fd1c7706d48046e5b5ad65652176b22b@cambiumassessment.com>
 <CACgv6yV32U=w+PaP-nat1igtYMuXUh_LvFRB1h16GiYy6-s=uQ@mail.gmail.com>
 <9db3914e693b4630a8c6f3324b2838af@cambiumassessment.com>
 <14b45e454e9246f7acddc6ccda5688b7@UM-MAIL3213.unimaas.nl>
Message-ID: <CACgv6yUvGQP6PHyV2FppJpi3N68EjcBCyJ9sCzdZJ4vQZgXGwg@mail.gmail.com>

Thank you Wolfang. That was exactly what I was looking for. If an lme()
model uses  `correlation = corAR1()`, then I'm assuming something new
will appear for the question mark in the following: `m2$modelStruct$???`,
right?

Wolfang, on the one the hand you mentioned: "you will also get the
coefficient (= 1) for the males. But that is not actually an estimated
parameter",

On the other hand you mentioned: "And these *are* parameters (besides the
fixed effects and the vars/covs of the random effects)."

Multiple software I used show that my model with `varIdent(form = ~1
|female)` estimates one additional parameter compared to a corresponding
model without `varIdent(form = ~1 |female)`.

Books (e.g., Mixed Effects Models and Extensions in Ecology with R by Zuur
et al, 2009; Pinheiro & Bates, 2000, p. 209) also clearly mention
`varIdent(form
= ~1 |female)` estimates one more parameter.

Would you please clarify?





On Sun, Nov 1, 2020 at 9:44 AM Viechtbauer, Wolfgang (SP) <
wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:

> Dear Simon,
>
> For variance structures, you can use:
>
> coef(fit$modelStruct$varStruct)
>
> That will give you the parameter estimates involved in the variance
> structure (in their constrained form as used during the optimization). With:
>
> coef(fit$modelStruct$varStruct, unconstrained=FALSE)
>
> you can get the unconstrained estimates. Only coefficients that are
> actually estimated are returned by default. With:
>
> coef(fit$modelStruct$varStruct, unconstrained=FALSE, allCoef=TRUE)
>
> you will also get the coefficient (= 1) for the males. But that is not
> actually an estimated parameter. For more details, see:
>
> help(coef.varFunc)
>
> And these *are* parameters (besides the fixed effects and the vars/covs of
> the random effects).
>
> Best,
> Wolfgang
>
> >-----Original Message-----
> >From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org
> ]
> >On Behalf Of Harold Doran
> >Sent: Sunday, 01 November, 2020 16:26
> >To: Simon Harmel
> >Cc: r-sig-mixed-models
> >Subject: Re: [R-sig-ME] lme: count the number extra parameters estimated
> for
> >variance or covariances
> >
> >I think you need to understand what a reproducible example is intended to
> >do. Your data estimates a model and yields a fiitted model object. What
> >parameter from that object using an extractor are you intending to find?
> >
> >For example, a well posed question would be something like. I want to
> >extract the fixed effects from a fitted model object. How do I get them?
> >
> >To say I want the ?parameters estimated for modeling residual variances?
> etc
> >makes no sense. The parameters of a mixed model are the fixed effects and
> >the marginal variances (and covariances) of the random effects.
> >
> >So, specifically what parameters do you think exist in a model that you
> >want?
> >
> >From: Simon Harmel <sim.harmel at gmail.com>
> >Sent: Sunday, November 1, 2020 9:58 AM
> >To: Harold Doran <harold.doran at cambiumassessment.com>
> >Cc: r-sig-mixed-models <r-sig-mixed-models at r-project.org>
> >Subject: Re: [R-sig-ME] lme: count the number extra parameters estimated
> for
> >variance or covariances
> >
> >Dear Harold,
> >
> >My question "specifically" is:  is there a way (e.g., via an extractor
> >function) to obtain parameters estimated for modeling residual variances
> or
> >covariances from an "lme" model?
> >
> >For concreteness, please consider the reproducible model I provided in my
> >original post in which a variance function has been used.
> >
> >Thanks,
> >
> >On Sun, Nov 1, 2020, 4:43 AM Harold Doran
> ><harold.doran at cambiumassessment.com<mailto:
> harold.doran at cambiumassessment.co
> >m>> wrote:
> >In order to answer that you need to specify what "thing" you want. The
> >object itself has many things and there are extractor functions to grab
> many
> >of them. I say "thing" because the *parameters* of a mixed model are the
> >fixed effects and the variance components. Random effects etc are not
> >parameters of a mixed model.
> >
> >You can always look at the structure of a fitted model object in R to see
> >what things are generally in it.
> >
> >-----Original Message-----
> >From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org
> <mailto:r-
> >sig-mixed-models-bounces at r-project.org>> On Behalf Of Simon Harmel
> >Sent: Sunday, November 1, 2020 4:02 AM
> >To: r-sig-mixed-models <r-sig-mixed-models at r-project.org<mailto:
> r-sig-mixed-
> >models at r-project.org>>
> >Subject: [R-sig-ME] lme: count the number extra parameters estimated for
> >variance or covariances
> >
> >External email alert: Be wary of links & attachments.
> >
> >Hello All,
> >
> >In addition to fixed and random effects, is there a way to extract how
> many
> >other parameters (for modeling residual variances or covariances) an
> "lme()"
> >object has estimated?
> >
> >Here is a reproducible example:
> >
> >library(nlme)
> >
> >hsb <- read.csv('
> >https://raw.githubusercontent.com/rnorouzian/e/master/hsb.csv')
> >hsb$female <- as.factor(hsb$female)
> >
> >fit <- lme(math ~ female, random = ~ 1|sch.id<http://sch.id>, data = hsb,
> >weights = varIdent(form = ~1 |female))
>

	[[alternative HTML version deleted]]


From wo||g@ng@v|echtb@uer @end|ng |rom m@@@tr|chtun|ver@|ty@n|  Sun Nov  1 17:30:42 2020
From: wo||g@ng@v|echtb@uer @end|ng |rom m@@@tr|chtun|ver@|ty@n| (Viechtbauer, Wolfgang (SP))
Date: Sun, 1 Nov 2020 16:30:42 +0000
Subject: [R-sig-ME] lme: count the number extra parameters estimated for
 variance or covariances
In-Reply-To: <CACgv6yUvGQP6PHyV2FppJpi3N68EjcBCyJ9sCzdZJ4vQZgXGwg@mail.gmail.com>
References: <CACgv6yU6+nOyqH=KO1Cq78h=tALFz_FA4ewh7_5__ixVap+_yw@mail.gmail.com>
 <fd1c7706d48046e5b5ad65652176b22b@cambiumassessment.com>
 <CACgv6yV32U=w+PaP-nat1igtYMuXUh_LvFRB1h16GiYy6-s=uQ@mail.gmail.com>
 <9db3914e693b4630a8c6f3324b2838af@cambiumassessment.com>
 <14b45e454e9246f7acddc6ccda5688b7@UM-MAIL3213.unimaas.nl>
 <CACgv6yUvGQP6PHyV2FppJpi3N68EjcBCyJ9sCzdZJ4vQZgXGwg@mail.gmail.com>
Message-ID: <cbbe359b4c0f4ef694de8fc5d7aba31e@UM-MAIL3213.unimaas.nl>

I meant that the 1 for males is not an estimated parameter. The coefficient for the females is of course (and hence one additional parameter). Apologies for the confusion.

For correlation structures, there will indeed be a 'corStruct' element under 'modelStruct'.

Best,
Wolfgang

>-----Original Message-----
>From: Simon Harmel [mailto:sim.harmel at gmail.com]
>Sent: Sunday, 01 November, 2020 17:15
>To: Viechtbauer, Wolfgang (SP)
>Cc: Harold Doran; r-sig-mixed-models
>Subject: Re: [R-sig-ME] lme: count the number extra parameters estimated for
>variance or covariances
>
>Thank you Wolfang. That was exactly?what I was looking for. If an lme()
>model uses? `correlation = corAR1()`, then I'm assuming something new
>will?appear for the question mark in the following: `m2$modelStruct$???`,
>right?
>
>Wolfang, on the one the hand you mentioned: "you will also get the
>coefficient (= 1) for the males. But that is not actually an estimated
>parameter",
>
>On the other hand you mentioned: "And these *are* parameters (besides the
>fixed effects and the vars/covs of the random effects)."
>
>Multiple software I used show that my model with `varIdent(form = ~1
>|female)`?estimates one additional parameter compared to a corresponding
>model without `varIdent(form = ~1 |female)`.
>
>Books (e.g., Mixed Effects Models and Extensions in Ecology with R by Zuur
>et al, 2009; Pinheiro & Bates, 2000, p. 209) also clearly mention
>`varIdent(form = ~1 |female)`?estimates one more parameter.
>
>Would you please clarify?
>
>On Sun, Nov 1, 2020 at 9:44 AM Viechtbauer, Wolfgang (SP)
><wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:
>Dear Simon,
>
>For variance structures, you can use:
>
>coef(fit$modelStruct$varStruct)
>
>That will give you the parameter estimates involved in the variance
>structure (in their constrained form as used during the optimization). With:
>
>coef(fit$modelStruct$varStruct, unconstrained=FALSE)
>
>you can get the unconstrained estimates. Only coefficients that are actually
>estimated are returned by default. With:
>
>coef(fit$modelStruct$varStruct, unconstrained=FALSE, allCoef=TRUE)
>
>you will also get the coefficient (= 1) for the males. But that is not
>actually an estimated parameter. For more details, see:
>
>help(coef.varFunc)
>
>And these *are* parameters (besides the fixed effects and the vars/covs of
>the random effects).
>
>Best,
>Wolfgang
>
>>-----Original Message-----
>>From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org]
>>On Behalf Of Harold Doran
>>Sent: Sunday, 01 November, 2020 16:26
>>To: Simon Harmel
>>Cc: r-sig-mixed-models
>>Subject: Re: [R-sig-ME] lme: count the number extra parameters estimated
>for
>>variance or covariances
>>
>>I think you need to understand what a reproducible example is intended to
>>do. Your data estimates a model and yields a fiitted model object. What
>>parameter from that object using an extractor are you intending to find?
>>
>>For example, a well posed question would be something like. I want to
>>extract the fixed effects from a fitted model object. How do I get them?
>>
>>To say I want the ?parameters estimated for modeling residual variances?
>etc
>>makes no sense. The parameters of a mixed model are the fixed effects and
>>the marginal variances (and covariances) of the random effects.
>>
>>So, specifically what parameters do you think exist in a model that you
>>want?
>>
>>From: Simon Harmel <sim.harmel at gmail.com>
>>Sent: Sunday, November 1, 2020 9:58 AM
>>To: Harold Doran <harold.doran at cambiumassessment.com>
>>Cc: r-sig-mixed-models <r-sig-mixed-models at r-project.org>
>>Subject: Re: [R-sig-ME] lme: count the number extra parameters estimated
>for
>>variance or covariances
>>
>>Dear Harold,
>>
>>My question "specifically" is:? is there a way (e.g., via an extractor
>>function) to obtain parameters estimated for modeling residual variances or
>>covariances from an "lme" model?
>>
>>For concreteness, please consider the reproducible model I provided in my
>>original post in which a variance function has been used.
>>
>>Thanks,
>>
>>On Sun, Nov 1, 2020, 4:43 AM Harold Doran
>><harold.doran at cambiumassessment.com<mailto:harold.doran at cambiumassessment.c
>o
>>m>> wrote:
>>In order to answer that you need to specify what "thing" you want. The
>>object itself has many things and there are extractor functions to grab
>many
>>of them. I say "thing" because the *parameters* of a mixed model are the
>>fixed effects and the variance components. Random effects etc are not
>>parameters of a mixed model.
>>
>>You can always look at the structure of a fitted model object in R to see
>>what things are generally in it.
>>
>>-----Original Message-----
>>From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-
>project.org<mailto:r-
>>sig-mixed-models-bounces at r-project.org>> On Behalf Of Simon Harmel
>>Sent: Sunday, November 1, 2020 4:02 AM
>>To: r-sig-mixed-models <r-sig-mixed-models at r-project.org<mailto:r-sig-
>mixed-
>>models at r-project.org>>
>>Subject: [R-sig-ME] lme: count the number extra parameters estimated for
>>variance or covariances
>>
>>External email alert: Be wary of links & attachments.
>>
>>Hello All,
>>
>>In addition to fixed and random effects, is there a way to extract how many
>>other parameters (for modeling residual variances or covariances) an
>"lme()"
>>object has estimated?
>>
>>Here is a reproducible example:
>>
>>library(nlme)
>>
>>hsb <- read.csv('
>>https://raw.githubusercontent.com/rnorouzian/e/master/hsb.csv')
>>hsb$female <- as.factor(hsb$female)
>>
>>fit <- lme(math ~ female, random = ~ 1|sch.id<http://sch.id>, data = hsb,
>>weights = varIdent(form = ~1 |female))

From @|m@h@rme| @end|ng |rom gm@||@com  Sun Nov  1 17:37:03 2020
From: @|m@h@rme| @end|ng |rom gm@||@com (Simon Harmel)
Date: Sun, 1 Nov 2020 10:37:03 -0600
Subject: [R-sig-ME] lme: count the number extra parameters estimated for
 variance or covariances
In-Reply-To: <cbbe359b4c0f4ef694de8fc5d7aba31e@UM-MAIL3213.unimaas.nl>
References: <CACgv6yU6+nOyqH=KO1Cq78h=tALFz_FA4ewh7_5__ixVap+_yw@mail.gmail.com>
 <fd1c7706d48046e5b5ad65652176b22b@cambiumassessment.com>
 <CACgv6yV32U=w+PaP-nat1igtYMuXUh_LvFRB1h16GiYy6-s=uQ@mail.gmail.com>
 <9db3914e693b4630a8c6f3324b2838af@cambiumassessment.com>
 <14b45e454e9246f7acddc6ccda5688b7@UM-MAIL3213.unimaas.nl>
 <CACgv6yUvGQP6PHyV2FppJpi3N68EjcBCyJ9sCzdZJ4vQZgXGwg@mail.gmail.com>
 <cbbe359b4c0f4ef694de8fc5d7aba31e@UM-MAIL3213.unimaas.nl>
Message-ID: <CACgv6yUbrQ0ywgFv8u9eY476hWKK-Punv7vK--RY+fg-QGYViw@mail.gmail.com>

Thank you, Wolfgang (sorry for misspelling). So, by: " The coefficient for
the females is of course [one additional parameter]" you mean for the
variance coefficient of `female == 1` as a binary predictor, right?

On Sun, Nov 1, 2020 at 10:31 AM Viechtbauer, Wolfgang (SP) <
wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:

> I meant that the 1 for males is not an estimated parameter. The
> coefficient for the females is of course (and hence one additional
> parameter). Apologies for the confusion.
>
> For correlation structures, there will indeed be a 'corStruct' element
> under 'modelStruct'.
>
> Best,
> Wolfgang
>
> >-----Original Message-----
> >From: Simon Harmel [mailto:sim.harmel at gmail.com]
> >Sent: Sunday, 01 November, 2020 17:15
> >To: Viechtbauer, Wolfgang (SP)
> >Cc: Harold Doran; r-sig-mixed-models
> >Subject: Re: [R-sig-ME] lme: count the number extra parameters estimated
> for
> >variance or covariances
> >
> >Thank you Wolfang. That was exactly what I was looking for. If an lme()
> >model uses  `correlation = corAR1()`, then I'm assuming something new
> >will appear for the question mark in the following: `m2$modelStruct$???`,
> >right?
> >
> >Wolfang, on the one the hand you mentioned: "you will also get the
> >coefficient (= 1) for the males. But that is not actually an estimated
> >parameter",
> >
> >On the other hand you mentioned: "And these *are* parameters (besides the
> >fixed effects and the vars/covs of the random effects)."
> >
> >Multiple software I used show that my model with `varIdent(form = ~1
> >|female)` estimates one additional parameter compared to a corresponding
> >model without `varIdent(form = ~1 |female)`.
> >
> >Books (e.g., Mixed Effects Models and Extensions in Ecology with R by Zuur
> >et al, 2009; Pinheiro & Bates, 2000, p. 209) also clearly mention
> >`varIdent(form = ~1 |female)` estimates one more parameter.
> >
> >Would you please clarify?
> >
> >On Sun, Nov 1, 2020 at 9:44 AM Viechtbauer, Wolfgang (SP)
> ><wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:
> >Dear Simon,
> >
> >For variance structures, you can use:
> >
> >coef(fit$modelStruct$varStruct)
> >
> >That will give you the parameter estimates involved in the variance
> >structure (in their constrained form as used during the optimization).
> With:
> >
> >coef(fit$modelStruct$varStruct, unconstrained=FALSE)
> >
> >you can get the unconstrained estimates. Only coefficients that are
> actually
> >estimated are returned by default. With:
> >
> >coef(fit$modelStruct$varStruct, unconstrained=FALSE, allCoef=TRUE)
> >
> >you will also get the coefficient (= 1) for the males. But that is not
> >actually an estimated parameter. For more details, see:
> >
> >help(coef.varFunc)
> >
> >And these *are* parameters (besides the fixed effects and the vars/covs of
> >the random effects).
> >
> >Best,
> >Wolfgang
> >
> >>-----Original Message-----
> >>From: R-sig-mixed-models [mailto:
> r-sig-mixed-models-bounces at r-project.org]
> >>On Behalf Of Harold Doran
> >>Sent: Sunday, 01 November, 2020 16:26
> >>To: Simon Harmel
> >>Cc: r-sig-mixed-models
> >>Subject: Re: [R-sig-ME] lme: count the number extra parameters estimated
> >for
> >>variance or covariances
> >>
> >>I think you need to understand what a reproducible example is intended to
> >>do. Your data estimates a model and yields a fiitted model object. What
> >>parameter from that object using an extractor are you intending to find?
> >>
> >>For example, a well posed question would be something like. I want to
> >>extract the fixed effects from a fitted model object. How do I get them?
> >>
> >>To say I want the ?parameters estimated for modeling residual variances?
> >etc
> >>makes no sense. The parameters of a mixed model are the fixed effects and
> >>the marginal variances (and covariances) of the random effects.
> >>
> >>So, specifically what parameters do you think exist in a model that you
> >>want?
> >>
> >>From: Simon Harmel <sim.harmel at gmail.com>
> >>Sent: Sunday, November 1, 2020 9:58 AM
> >>To: Harold Doran <harold.doran at cambiumassessment.com>
> >>Cc: r-sig-mixed-models <r-sig-mixed-models at r-project.org>
> >>Subject: Re: [R-sig-ME] lme: count the number extra parameters estimated
> >for
> >>variance or covariances
> >>
> >>Dear Harold,
> >>
> >>My question "specifically" is:  is there a way (e.g., via an extractor
> >>function) to obtain parameters estimated for modeling residual variances
> or
> >>covariances from an "lme" model?
> >>
> >>For concreteness, please consider the reproducible model I provided in my
> >>original post in which a variance function has been used.
> >>
> >>Thanks,
> >>
> >>On Sun, Nov 1, 2020, 4:43 AM Harold Doran
> >><harold.doran at cambiumassessment.com<mailto:
> harold.doran at cambiumassessment.c
> >o
> >>m>> wrote:
> >>In order to answer that you need to specify what "thing" you want. The
> >>object itself has many things and there are extractor functions to grab
> >many
> >>of them. I say "thing" because the *parameters* of a mixed model are the
> >>fixed effects and the variance components. Random effects etc are not
> >>parameters of a mixed model.
> >>
> >>You can always look at the structure of a fitted model object in R to see
> >>what things are generally in it.
> >>
> >>-----Original Message-----
> >>From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-
> >project.org<mailto:r-
> >>sig-mixed-models-bounces at r-project.org>> On Behalf Of Simon Harmel
> >>Sent: Sunday, November 1, 2020 4:02 AM
> >>To: r-sig-mixed-models <r-sig-mixed-models at r-project.org<mailto:r-sig-
> >mixed-
> >>models at r-project.org>>
> >>Subject: [R-sig-ME] lme: count the number extra parameters estimated for
> >>variance or covariances
> >>
> >>External email alert: Be wary of links & attachments.
> >>
> >>Hello All,
> >>
> >>In addition to fixed and random effects, is there a way to extract how
> many
> >>other parameters (for modeling residual variances or covariances) an
> >"lme()"
> >>object has estimated?
> >>
> >>Here is a reproducible example:
> >>
> >>library(nlme)
> >>
> >>hsb <- read.csv('
> >>https://raw.githubusercontent.com/rnorouzian/e/master/hsb.csv')
> >>hsb$female <- as.factor(hsb$female)
> >>
> >>fit <- lme(math ~ female, random = ~ 1|sch.id<http://sch.id>, data =
> hsb,
> >>weights = varIdent(form = ~1 |female))
>

	[[alternative HTML version deleted]]


From jepu@to @end|ng |rom gm@||@com  Sun Nov  1 18:02:56 2020
From: jepu@to @end|ng |rom gm@||@com (James Pustejovsky)
Date: Sun, 1 Nov 2020 11:02:56 -0600
Subject: [R-sig-ME] lme: count the number extra parameters estimated for
 variance or covariances
In-Reply-To: <CACgv6yUbrQ0ywgFv8u9eY476hWKK-Punv7vK--RY+fg-QGYViw@mail.gmail.com>
References: <CACgv6yU6+nOyqH=KO1Cq78h=tALFz_FA4ewh7_5__ixVap+_yw@mail.gmail.com>
 <fd1c7706d48046e5b5ad65652176b22b@cambiumassessment.com>
 <CACgv6yV32U=w+PaP-nat1igtYMuXUh_LvFRB1h16GiYy6-s=uQ@mail.gmail.com>
 <9db3914e693b4630a8c6f3324b2838af@cambiumassessment.com>
 <14b45e454e9246f7acddc6ccda5688b7@UM-MAIL3213.unimaas.nl>
 <CACgv6yUvGQP6PHyV2FppJpi3N68EjcBCyJ9sCzdZJ4vQZgXGwg@mail.gmail.com>
 <cbbe359b4c0f4ef694de8fc5d7aba31e@UM-MAIL3213.unimaas.nl>
 <CACgv6yUbrQ0ywgFv8u9eY476hWKK-Punv7vK--RY+fg-QGYViw@mail.gmail.com>
Message-ID: <CAFUVuJzZ3wBcCr8QTj3-yUOC7QhymBVgZgmabtqZYOjk8NN1-w@mail.gmail.com>

Simon,

Here is a quick way to accomplish the same thing that Wolfgang
demonstrated, using the lmeInfo package:
VC <- lmeInfo::extract_varcomp(fit)   # get all the variance components
lengths(VC)                                        # count the number of
estimated parameters in each component
sum(lengths(VC))                               # total number of variance
component parameters

Kind Regards,
James


On Sun, Nov 1, 2020 at 10:45 AM Simon Harmel <sim.harmel at gmail.com> wrote:

> Thank you, Wolfgang (sorry for misspelling). So, by: " The coefficient for
> the females is of course [one additional parameter]" you mean for the
> variance coefficient of `female == 1` as a binary predictor, right?
>
> On Sun, Nov 1, 2020 at 10:31 AM Viechtbauer, Wolfgang (SP) <
> wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:
>
> > I meant that the 1 for males is not an estimated parameter. The
> > coefficient for the females is of course (and hence one additional
> > parameter). Apologies for the confusion.
> >
> > For correlation structures, there will indeed be a 'corStruct' element
> > under 'modelStruct'.
> >
> > Best,
> > Wolfgang
> >
> > >-----Original Message-----
> > >From: Simon Harmel [mailto:sim.harmel at gmail.com]
> > >Sent: Sunday, 01 November, 2020 17:15
> > >To: Viechtbauer, Wolfgang (SP)
> > >Cc: Harold Doran; r-sig-mixed-models
> > >Subject: Re: [R-sig-ME] lme: count the number extra parameters estimated
> > for
> > >variance or covariances
> > >
> > >Thank you Wolfang. That was exactly what I was looking for. If an lme()
> > >model uses  `correlation = corAR1()`, then I'm assuming something new
> > >will appear for the question mark in the following:
> `m2$modelStruct$???`,
> > >right?
> > >
> > >Wolfang, on the one the hand you mentioned: "you will also get the
> > >coefficient (= 1) for the males. But that is not actually an estimated
> > >parameter",
> > >
> > >On the other hand you mentioned: "And these *are* parameters (besides
> the
> > >fixed effects and the vars/covs of the random effects)."
> > >
> > >Multiple software I used show that my model with `varIdent(form = ~1
> > >|female)` estimates one additional parameter compared to a corresponding
> > >model without `varIdent(form = ~1 |female)`.
> > >
> > >Books (e.g., Mixed Effects Models and Extensions in Ecology with R by
> Zuur
> > >et al, 2009; Pinheiro & Bates, 2000, p. 209) also clearly mention
> > >`varIdent(form = ~1 |female)` estimates one more parameter.
> > >
> > >Would you please clarify?
> > >
> > >On Sun, Nov 1, 2020 at 9:44 AM Viechtbauer, Wolfgang (SP)
> > ><wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:
> > >Dear Simon,
> > >
> > >For variance structures, you can use:
> > >
> > >coef(fit$modelStruct$varStruct)
> > >
> > >That will give you the parameter estimates involved in the variance
> > >structure (in their constrained form as used during the optimization).
> > With:
> > >
> > >coef(fit$modelStruct$varStruct, unconstrained=FALSE)
> > >
> > >you can get the unconstrained estimates. Only coefficients that are
> > actually
> > >estimated are returned by default. With:
> > >
> > >coef(fit$modelStruct$varStruct, unconstrained=FALSE, allCoef=TRUE)
> > >
> > >you will also get the coefficient (= 1) for the males. But that is not
> > >actually an estimated parameter. For more details, see:
> > >
> > >help(coef.varFunc)
> > >
> > >And these *are* parameters (besides the fixed effects and the vars/covs
> of
> > >the random effects).
> > >
> > >Best,
> > >Wolfgang
> > >
> > >>-----Original Message-----
> > >>From: R-sig-mixed-models [mailto:
> > r-sig-mixed-models-bounces at r-project.org]
> > >>On Behalf Of Harold Doran
> > >>Sent: Sunday, 01 November, 2020 16:26
> > >>To: Simon Harmel
> > >>Cc: r-sig-mixed-models
> > >>Subject: Re: [R-sig-ME] lme: count the number extra parameters
> estimated
> > >for
> > >>variance or covariances
> > >>
> > >>I think you need to understand what a reproducible example is intended
> to
> > >>do. Your data estimates a model and yields a fiitted model object. What
> > >>parameter from that object using an extractor are you intending to
> find?
> > >>
> > >>For example, a well posed question would be something like. I want to
> > >>extract the fixed effects from a fitted model object. How do I get
> them?
> > >>
> > >>To say I want the ?parameters estimated for modeling residual
> variances?
> > >etc
> > >>makes no sense. The parameters of a mixed model are the fixed effects
> and
> > >>the marginal variances (and covariances) of the random effects.
> > >>
> > >>So, specifically what parameters do you think exist in a model that you
> > >>want?
> > >>
> > >>From: Simon Harmel <sim.harmel at gmail.com>
> > >>Sent: Sunday, November 1, 2020 9:58 AM
> > >>To: Harold Doran <harold.doran at cambiumassessment.com>
> > >>Cc: r-sig-mixed-models <r-sig-mixed-models at r-project.org>
> > >>Subject: Re: [R-sig-ME] lme: count the number extra parameters
> estimated
> > >for
> > >>variance or covariances
> > >>
> > >>Dear Harold,
> > >>
> > >>My question "specifically" is:  is there a way (e.g., via an extractor
> > >>function) to obtain parameters estimated for modeling residual
> variances
> > or
> > >>covariances from an "lme" model?
> > >>
> > >>For concreteness, please consider the reproducible model I provided in
> my
> > >>original post in which a variance function has been used.
> > >>
> > >>Thanks,
> > >>
> > >>On Sun, Nov 1, 2020, 4:43 AM Harold Doran
> > >><harold.doran at cambiumassessment.com<mailto:
> > harold.doran at cambiumassessment.c
> > >o
> > >>m>> wrote:
> > >>In order to answer that you need to specify what "thing" you want. The
> > >>object itself has many things and there are extractor functions to grab
> > >many
> > >>of them. I say "thing" because the *parameters* of a mixed model are
> the
> > >>fixed effects and the variance components. Random effects etc are not
> > >>parameters of a mixed model.
> > >>
> > >>You can always look at the structure of a fitted model object in R to
> see
> > >>what things are generally in it.
> > >>
> > >>-----Original Message-----
> > >>From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-
> > >project.org<mailto:r-
> > >>sig-mixed-models-bounces at r-project.org>> On Behalf Of Simon Harmel
> > >>Sent: Sunday, November 1, 2020 4:02 AM
> > >>To: r-sig-mixed-models <r-sig-mixed-models at r-project.org<mailto:r-sig-
> > >mixed-
> > >>models at r-project.org>>
> > >>Subject: [R-sig-ME] lme: count the number extra parameters estimated
> for
> > >>variance or covariances
> > >>
> > >>External email alert: Be wary of links & attachments.
> > >>
> > >>Hello All,
> > >>
> > >>In addition to fixed and random effects, is there a way to extract how
> > many
> > >>other parameters (for modeling residual variances or covariances) an
> > >"lme()"
> > >>object has estimated?
> > >>
> > >>Here is a reproducible example:
> > >>
> > >>library(nlme)
> > >>
> > >>hsb <- read.csv('
> > >>https://raw.githubusercontent.com/rnorouzian/e/master/hsb.csv')
> > >>hsb$female <- as.factor(hsb$female)
> > >>
> > >>fit <- lme(math ~ female, random = ~ 1|sch.id<http://sch.id>, data =
> > hsb,
> > >>weights = varIdent(form = ~1 |female))
> >
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From @|m@h@rme| @end|ng |rom gm@||@com  Sun Nov  1 18:05:43 2020
From: @|m@h@rme| @end|ng |rom gm@||@com (Simon Harmel)
Date: Sun, 1 Nov 2020 11:05:43 -0600
Subject: [R-sig-ME] lme: count the number extra parameters estimated for
 variance or covariances
In-Reply-To: <CAFUVuJzZ3wBcCr8QTj3-yUOC7QhymBVgZgmabtqZYOjk8NN1-w@mail.gmail.com>
References: <CACgv6yU6+nOyqH=KO1Cq78h=tALFz_FA4ewh7_5__ixVap+_yw@mail.gmail.com>
 <fd1c7706d48046e5b5ad65652176b22b@cambiumassessment.com>
 <CACgv6yV32U=w+PaP-nat1igtYMuXUh_LvFRB1h16GiYy6-s=uQ@mail.gmail.com>
 <9db3914e693b4630a8c6f3324b2838af@cambiumassessment.com>
 <14b45e454e9246f7acddc6ccda5688b7@UM-MAIL3213.unimaas.nl>
 <CACgv6yUvGQP6PHyV2FppJpi3N68EjcBCyJ9sCzdZJ4vQZgXGwg@mail.gmail.com>
 <cbbe359b4c0f4ef694de8fc5d7aba31e@UM-MAIL3213.unimaas.nl>
 <CACgv6yUbrQ0ywgFv8u9eY476hWKK-Punv7vK--RY+fg-QGYViw@mail.gmail.com>
 <CAFUVuJzZ3wBcCr8QTj3-yUOC7QhymBVgZgmabtqZYOjk8NN1-w@mail.gmail.com>
Message-ID: <CACgv6yU4hLXcY=4a+0Ne5Hx_69fS_SjxMgsa-a-9iMnzVjYpeg@mail.gmail.com>

Thanks, James!

On Sun, Nov 1, 2020 at 11:03 AM James Pustejovsky <jepusto at gmail.com> wrote:

> Simon,
>
> Here is a quick way to accomplish the same thing that Wolfgang
> demonstrated, using the lmeInfo package:
> VC <- lmeInfo::extract_varcomp(fit)   # get all the variance components
> lengths(VC)                                        # count the number of
> estimated parameters in each component
> sum(lengths(VC))                               # total number of variance
> component parameters
>
> Kind Regards,
> James
>
>
> On Sun, Nov 1, 2020 at 10:45 AM Simon Harmel <sim.harmel at gmail.com> wrote:
>
>> Thank you, Wolfgang (sorry for misspelling). So, by: " The coefficient for
>> the females is of course [one additional parameter]" you mean for the
>> variance coefficient of `female == 1` as a binary predictor, right?
>>
>> On Sun, Nov 1, 2020 at 10:31 AM Viechtbauer, Wolfgang (SP) <
>> wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:
>>
>> > I meant that the 1 for males is not an estimated parameter. The
>> > coefficient for the females is of course (and hence one additional
>> > parameter). Apologies for the confusion.
>> >
>> > For correlation structures, there will indeed be a 'corStruct' element
>> > under 'modelStruct'.
>> >
>> > Best,
>> > Wolfgang
>> >
>> > >-----Original Message-----
>> > >From: Simon Harmel [mailto:sim.harmel at gmail.com]
>> > >Sent: Sunday, 01 November, 2020 17:15
>> > >To: Viechtbauer, Wolfgang (SP)
>> > >Cc: Harold Doran; r-sig-mixed-models
>> > >Subject: Re: [R-sig-ME] lme: count the number extra parameters
>> estimated
>> > for
>> > >variance or covariances
>> > >
>> > >Thank you Wolfang. That was exactly what I was looking for. If an lme()
>> > >model uses  `correlation = corAR1()`, then I'm assuming something new
>> > >will appear for the question mark in the following:
>> `m2$modelStruct$???`,
>> > >right?
>> > >
>> > >Wolfang, on the one the hand you mentioned: "you will also get the
>> > >coefficient (= 1) for the males. But that is not actually an estimated
>> > >parameter",
>> > >
>> > >On the other hand you mentioned: "And these *are* parameters (besides
>> the
>> > >fixed effects and the vars/covs of the random effects)."
>> > >
>> > >Multiple software I used show that my model with `varIdent(form = ~1
>> > >|female)` estimates one additional parameter compared to a
>> corresponding
>> > >model without `varIdent(form = ~1 |female)`.
>> > >
>> > >Books (e.g., Mixed Effects Models and Extensions in Ecology with R by
>> Zuur
>> > >et al, 2009; Pinheiro & Bates, 2000, p. 209) also clearly mention
>> > >`varIdent(form = ~1 |female)` estimates one more parameter.
>> > >
>> > >Would you please clarify?
>> > >
>> > >On Sun, Nov 1, 2020 at 9:44 AM Viechtbauer, Wolfgang (SP)
>> > ><wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:
>> > >Dear Simon,
>> > >
>> > >For variance structures, you can use:
>> > >
>> > >coef(fit$modelStruct$varStruct)
>> > >
>> > >That will give you the parameter estimates involved in the variance
>> > >structure (in their constrained form as used during the optimization).
>> > With:
>> > >
>> > >coef(fit$modelStruct$varStruct, unconstrained=FALSE)
>> > >
>> > >you can get the unconstrained estimates. Only coefficients that are
>> > actually
>> > >estimated are returned by default. With:
>> > >
>> > >coef(fit$modelStruct$varStruct, unconstrained=FALSE, allCoef=TRUE)
>> > >
>> > >you will also get the coefficient (= 1) for the males. But that is not
>> > >actually an estimated parameter. For more details, see:
>> > >
>> > >help(coef.varFunc)
>> > >
>> > >And these *are* parameters (besides the fixed effects and the
>> vars/covs of
>> > >the random effects).
>> > >
>> > >Best,
>> > >Wolfgang
>> > >
>> > >>-----Original Message-----
>> > >>From: R-sig-mixed-models [mailto:
>> > r-sig-mixed-models-bounces at r-project.org]
>> > >>On Behalf Of Harold Doran
>> > >>Sent: Sunday, 01 November, 2020 16:26
>> > >>To: Simon Harmel
>> > >>Cc: r-sig-mixed-models
>> > >>Subject: Re: [R-sig-ME] lme: count the number extra parameters
>> estimated
>> > >for
>> > >>variance or covariances
>> > >>
>> > >>I think you need to understand what a reproducible example is
>> intended to
>> > >>do. Your data estimates a model and yields a fiitted model object.
>> What
>> > >>parameter from that object using an extractor are you intending to
>> find?
>> > >>
>> > >>For example, a well posed question would be something like. I want to
>> > >>extract the fixed effects from a fitted model object. How do I get
>> them?
>> > >>
>> > >>To say I want the ?parameters estimated for modeling residual
>> variances?
>> > >etc
>> > >>makes no sense. The parameters of a mixed model are the fixed effects
>> and
>> > >>the marginal variances (and covariances) of the random effects.
>> > >>
>> > >>So, specifically what parameters do you think exist in a model that
>> you
>> > >>want?
>> > >>
>> > >>From: Simon Harmel <sim.harmel at gmail.com>
>> > >>Sent: Sunday, November 1, 2020 9:58 AM
>> > >>To: Harold Doran <harold.doran at cambiumassessment.com>
>> > >>Cc: r-sig-mixed-models <r-sig-mixed-models at r-project.org>
>> > >>Subject: Re: [R-sig-ME] lme: count the number extra parameters
>> estimated
>> > >for
>> > >>variance or covariances
>> > >>
>> > >>Dear Harold,
>> > >>
>> > >>My question "specifically" is:  is there a way (e.g., via an extractor
>> > >>function) to obtain parameters estimated for modeling residual
>> variances
>> > or
>> > >>covariances from an "lme" model?
>> > >>
>> > >>For concreteness, please consider the reproducible model I provided
>> in my
>> > >>original post in which a variance function has been used.
>> > >>
>> > >>Thanks,
>> > >>
>> > >>On Sun, Nov 1, 2020, 4:43 AM Harold Doran
>> > >><harold.doran at cambiumassessment.com<mailto:
>> > harold.doran at cambiumassessment.c
>> > >o
>> > >>m>> wrote:
>> > >>In order to answer that you need to specify what "thing" you want. The
>> > >>object itself has many things and there are extractor functions to
>> grab
>> > >many
>> > >>of them. I say "thing" because the *parameters* of a mixed model are
>> the
>> > >>fixed effects and the variance components. Random effects etc are not
>> > >>parameters of a mixed model.
>> > >>
>> > >>You can always look at the structure of a fitted model object in R to
>> see
>> > >>what things are generally in it.
>> > >>
>> > >>-----Original Message-----
>> > >>From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-
>> > >project.org<mailto:r-
>> > >>sig-mixed-models-bounces at r-project.org>> On Behalf Of Simon Harmel
>> > >>Sent: Sunday, November 1, 2020 4:02 AM
>> > >>To: r-sig-mixed-models <r-sig-mixed-models at r-project.org<mailto:
>> r-sig-
>> > >mixed-
>> > >>models at r-project.org>>
>> > >>Subject: [R-sig-ME] lme: count the number extra parameters estimated
>> for
>> > >>variance or covariances
>> > >>
>> > >>External email alert: Be wary of links & attachments.
>> > >>
>> > >>Hello All,
>> > >>
>> > >>In addition to fixed and random effects, is there a way to extract how
>> > many
>> > >>other parameters (for modeling residual variances or covariances) an
>> > >"lme()"
>> > >>object has estimated?
>> > >>
>> > >>Here is a reproducible example:
>> > >>
>> > >>library(nlme)
>> > >>
>> > >>hsb <- read.csv('
>> > >>https://raw.githubusercontent.com/rnorouzian/e/master/hsb.csv')
>> > >>hsb$female <- as.factor(hsb$female)
>> > >>
>> > >>fit <- lme(math ~ female, random = ~ 1|sch.id<http://sch.id>, data =
>> > hsb,
>> > >>weights = varIdent(form = ~1 |female))
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>

	[[alternative HTML version deleted]]


From wo||g@ng@v|echtb@uer @end|ng |rom m@@@tr|chtun|ver@|ty@n|  Sun Nov  1 18:13:34 2020
From: wo||g@ng@v|echtb@uer @end|ng |rom m@@@tr|chtun|ver@|ty@n| (Viechtbauer, Wolfgang (SP))
Date: Sun, 1 Nov 2020 17:13:34 +0000
Subject: [R-sig-ME] lme: count the number extra parameters estimated for
 variance or covariances
In-Reply-To: <CACgv6yU4hLXcY=4a+0Ne5Hx_69fS_SjxMgsa-a-9iMnzVjYpeg@mail.gmail.com>
References: <CACgv6yU6+nOyqH=KO1Cq78h=tALFz_FA4ewh7_5__ixVap+_yw@mail.gmail.com>
 <fd1c7706d48046e5b5ad65652176b22b@cambiumassessment.com>
 <CACgv6yV32U=w+PaP-nat1igtYMuXUh_LvFRB1h16GiYy6-s=uQ@mail.gmail.com>
 <9db3914e693b4630a8c6f3324b2838af@cambiumassessment.com>
 <14b45e454e9246f7acddc6ccda5688b7@UM-MAIL3213.unimaas.nl>
 <CACgv6yUvGQP6PHyV2FppJpi3N68EjcBCyJ9sCzdZJ4vQZgXGwg@mail.gmail.com>
 <cbbe359b4c0f4ef694de8fc5d7aba31e@UM-MAIL3213.unimaas.nl>
 <CACgv6yUbrQ0ywgFv8u9eY476hWKK-Punv7vK--RY+fg-QGYViw@mail.gmail.com>
 <CAFUVuJzZ3wBcCr8QTj3-yUOC7QhymBVgZgmabtqZYOjk8NN1-w@mail.gmail.com>
 <CACgv6yU4hLXcY=4a+0Ne5Hx_69fS_SjxMgsa-a-9iMnzVjYpeg@mail.gmail.com>
Message-ID: <fa17a7d01ffa4bd28e50b44f7ef32f63@UM-MAIL3213.unimaas.nl>

Ah, very cool. Did not know about the lmeInfo package.

And yes, one can think of the parameter/coefficient for females as a binary predictor that allows the error variance to differ for females from that of the males.

Best,
Wolfgang

>-----Original Message-----
>From: Simon Harmel [mailto:sim.harmel at gmail.com]
>Sent: Sunday, 01 November, 2020 18:06
>To: James Pustejovsky
>Cc: Viechtbauer, Wolfgang (SP); Harold Doran; r-sig-mixed-models
>Subject: Re: [R-sig-ME] lme: count the number extra parameters estimated for
>variance or covariances
>
>Thanks, James!
>
>On Sun, Nov 1, 2020 at 11:03 AM James Pustejovsky <jepusto at gmail.com> wrote:
>Simon,
>
>Here is a quick way to accomplish the same thing that Wolfgang demonstrated,
>using the lmeInfo?package:
>VC <- lmeInfo::extract_varcomp(fit)? ?# get all the variance components
>lengths(VC)? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? # count the number of
>estimated parameters in each component
>sum(lengths(VC))? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?# total number of variance
>component parameters
>
>Kind Regards,
>James
>
>On Sun, Nov 1, 2020 at 10:45 AM Simon Harmel <sim.harmel at gmail.com> wrote:
>Thank you, Wolfgang (sorry for misspelling). So, by: " The coefficient for
>the females is of course [one additional parameter]" you mean for the
>variance coefficient of `female == 1` as a binary predictor, right?
>
>On Sun, Nov 1, 2020 at 10:31 AM Viechtbauer, Wolfgang (SP) <
>wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:
>
>> I meant that the 1 for males is not an estimated parameter. The
>> coefficient for the females is of course (and hence one additional
>> parameter). Apologies for the confusion.
>>
>> For correlation structures, there will indeed be a 'corStruct' element
>> under 'modelStruct'.
>>
>> Best,
>> Wolfgang
>>
>> >-----Original Message-----
>> >From: Simon Harmel [mailto:sim.harmel at gmail.com]
>> >Sent: Sunday, 01 November, 2020 17:15
>> >To: Viechtbauer, Wolfgang (SP)
>> >Cc: Harold Doran; r-sig-mixed-models
>> >Subject: Re: [R-sig-ME] lme: count the number extra parameters estimated
>> for
>> >variance or covariances
>> >
>> >Thank you Wolfang. That was exactly what I was looking for. If an lme()
>> >model uses? `correlation = corAR1()`, then I'm assuming something new
>> >will appear for the question mark in the following: `m2$modelStruct$???`,
>> >right?
>> >
>> >Wolfang, on the one the hand you mentioned: "you will also get the
>> >coefficient (= 1) for the males. But that is not actually an estimated
>> >parameter",
>> >
>> >On the other hand you mentioned: "And these *are* parameters (besides the
>> >fixed effects and the vars/covs of the random effects)."
>> >
>> >Multiple software I used show that my model with `varIdent(form = ~1
>> >|female)` estimates one additional parameter compared to a corresponding
>> >model without `varIdent(form = ~1 |female)`.
>> >
>> >Books (e.g., Mixed Effects Models and Extensions in Ecology with R by
>Zuur
>> >et al, 2009; Pinheiro & Bates, 2000, p. 209) also clearly mention
>> >`varIdent(form = ~1 |female)` estimates one more parameter.
>> >
>> >Would you please clarify?
>> >
>> >On Sun, Nov 1, 2020 at 9:44 AM Viechtbauer, Wolfgang (SP)
>> ><wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:
>> >Dear Simon,
>> >
>> >For variance structures, you can use:
>> >
>> >coef(fit$modelStruct$varStruct)
>> >
>> >That will give you the parameter estimates involved in the variance
>> >structure (in their constrained form as used during the optimization).
>> With:
>> >
>> >coef(fit$modelStruct$varStruct, unconstrained=FALSE)
>> >
>> >you can get the unconstrained estimates. Only coefficients that are
>> actually
>> >estimated are returned by default. With:
>> >
>> >coef(fit$modelStruct$varStruct, unconstrained=FALSE, allCoef=TRUE)
>> >
>> >you will also get the coefficient (= 1) for the males. But that is not
>> >actually an estimated parameter. For more details, see:
>> >
>> >help(coef.varFunc)
>> >
>> >And these *are* parameters (besides the fixed effects and the vars/covs
>of
>> >the random effects).
>> >
>> >Best,
>> >Wolfgang
>> >
>> >>-----Original Message-----
>> >>From: R-sig-mixed-models [mailto:
>> r-sig-mixed-models-bounces at r-project.org]
>> >>On Behalf Of Harold Doran
>> >>Sent: Sunday, 01 November, 2020 16:26
>> >>To: Simon Harmel
>> >>Cc: r-sig-mixed-models
>> >>Subject: Re: [R-sig-ME] lme: count the number extra parameters estimated
>> >for
>> >>variance or covariances
>> >>
>> >>I think you need to understand what a reproducible example is intended
>to
>> >>do. Your data estimates a model and yields a fiitted model object. What
>> >>parameter from that object using an extractor are you intending to find?
>> >>
>> >>For example, a well posed question would be something like. I want to
>> >>extract the fixed effects from a fitted model object. How do I get them?
>> >>
>> >>To say I want the ?parameters estimated for modeling residual variances?
>> >etc
>> >>makes no sense. The parameters of a mixed model are the fixed effects
>and
>> >>the marginal variances (and covariances) of the random effects.
>> >>
>> >>So, specifically what parameters do you think exist in a model that you
>> >>want?
>> >>
>> >>From: Simon Harmel <sim.harmel at gmail.com>
>> >>Sent: Sunday, November 1, 2020 9:58 AM
>> >>To: Harold Doran <harold.doran at cambiumassessment.com>
>> >>Cc: r-sig-mixed-models <r-sig-mixed-models at r-project.org>
>> >>Subject: Re: [R-sig-ME] lme: count the number extra parameters estimated
>> >for
>> >>variance or covariances
>> >>
>> >>Dear Harold,
>> >>
>> >>My question "specifically" is:? is there a way (e.g., via an extractor
>> >>function) to obtain parameters estimated for modeling residual variances
>> or
>> >>covariances from an "lme" model?
>> >>
>> >>For concreteness, please consider the reproducible model I provided in
>my
>> >>original post in which a variance function has been used.
>> >>
>> >>Thanks,
>> >>
>> >>On Sun, Nov 1, 2020, 4:43 AM Harold Doran
>> >><harold.doran at cambiumassessment.com<mailto:
>> harold.doran at cambiumassessment.c
>> >o
>> >>m>> wrote:
>> >>In order to answer that you need to specify what "thing" you want. The
>> >>object itself has many things and there are extractor functions to grab
>> >many
>> >>of them. I say "thing" because the *parameters* of a mixed model are the
>> >>fixed effects and the variance components. Random effects etc are not
>> >>parameters of a mixed model.
>> >>
>> >>You can always look at the structure of a fitted model object in R to
>see
>> >>what things are generally in it.
>> >>
>> >>-----Original Message-----
>> >>From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-
>> >project.org<mailto:r-
>> >>sig-mixed-models-bounces at r-project.org>> On Behalf Of Simon Harmel
>> >>Sent: Sunday, November 1, 2020 4:02 AM
>> >>To: r-sig-mixed-models <r-sig-mixed-models at r-project.org<mailto:r-sig-
>> >mixed-
>> >>models at r-project.org>>
>> >>Subject: [R-sig-ME] lme: count the number extra parameters estimated for
>> >>variance or covariances
>> >>
>> >>External email alert: Be wary of links & attachments.
>> >>
>> >>Hello All,
>> >>
>> >>In addition to fixed and random effects, is there a way to extract how
>> many
>> >>other parameters (for modeling residual variances or covariances) an
>> >"lme()"
>> >>object has estimated?
>> >>
>> >>Here is a reproducible example:
>> >>
>> >>library(nlme)
>> >>
>> >>hsb <- read.csv('
>> >>https://raw.githubusercontent.com/rnorouzian/e/master/hsb.csv')
>> >>hsb$female <- as.factor(hsb$female)
>> >>
>> >>fit <- lme(math ~ female, random = ~ 1|sch.id<http://sch.id>, data =
>> hsb,
>> >>weights = varIdent(form = ~1 |female))

From @|m@h@rme| @end|ng |rom gm@||@com  Sun Nov  1 18:15:30 2020
From: @|m@h@rme| @end|ng |rom gm@||@com (Simon Harmel)
Date: Sun, 1 Nov 2020 11:15:30 -0600
Subject: [R-sig-ME] lme: count the number extra parameters estimated for
 variance or covariances
In-Reply-To: <fa17a7d01ffa4bd28e50b44f7ef32f63@UM-MAIL3213.unimaas.nl>
References: <CACgv6yU6+nOyqH=KO1Cq78h=tALFz_FA4ewh7_5__ixVap+_yw@mail.gmail.com>
 <fd1c7706d48046e5b5ad65652176b22b@cambiumassessment.com>
 <CACgv6yV32U=w+PaP-nat1igtYMuXUh_LvFRB1h16GiYy6-s=uQ@mail.gmail.com>
 <9db3914e693b4630a8c6f3324b2838af@cambiumassessment.com>
 <14b45e454e9246f7acddc6ccda5688b7@UM-MAIL3213.unimaas.nl>
 <CACgv6yUvGQP6PHyV2FppJpi3N68EjcBCyJ9sCzdZJ4vQZgXGwg@mail.gmail.com>
 <cbbe359b4c0f4ef694de8fc5d7aba31e@UM-MAIL3213.unimaas.nl>
 <CACgv6yUbrQ0ywgFv8u9eY476hWKK-Punv7vK--RY+fg-QGYViw@mail.gmail.com>
 <CAFUVuJzZ3wBcCr8QTj3-yUOC7QhymBVgZgmabtqZYOjk8NN1-w@mail.gmail.com>
 <CACgv6yU4hLXcY=4a+0Ne5Hx_69fS_SjxMgsa-a-9iMnzVjYpeg@mail.gmail.com>
 <fa17a7d01ffa4bd28e50b44f7ef32f63@UM-MAIL3213.unimaas.nl>
Message-ID: <CACgv6yUiAbbp6ZP0giL49SPm4xsLLvcuxj5dtR9rr37H5v+qyQ@mail.gmail.com>

Great, many thanks to all!

On Sun, Nov 1, 2020 at 11:14 AM Viechtbauer, Wolfgang (SP) <
wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:

> Ah, very cool. Did not know about the lmeInfo package.
>
> And yes, one can think of the parameter/coefficient for females as a
> binary predictor that allows the error variance to differ for females from
> that of the males.
>
> Best,
> Wolfgang
>
> >-----Original Message-----
> >From: Simon Harmel [mailto:sim.harmel at gmail.com]
> >Sent: Sunday, 01 November, 2020 18:06
> >To: James Pustejovsky
> >Cc: Viechtbauer, Wolfgang (SP); Harold Doran; r-sig-mixed-models
> >Subject: Re: [R-sig-ME] lme: count the number extra parameters estimated
> for
> >variance or covariances
> >
> >Thanks, James!
> >
> >On Sun, Nov 1, 2020 at 11:03 AM James Pustejovsky <jepusto at gmail.com>
> wrote:
> >Simon,
> >
> >Here is a quick way to accomplish the same thing that Wolfgang
> demonstrated,
> >using the lmeInfo package:
> >VC <- lmeInfo::extract_varcomp(fit)   # get all the variance components
> >lengths(VC)                                        # count the number of
> >estimated parameters in each component
> >sum(lengths(VC))                               # total number of variance
> >component parameters
> >
> >Kind Regards,
> >James
> >
> >On Sun, Nov 1, 2020 at 10:45 AM Simon Harmel <sim.harmel at gmail.com>
> wrote:
> >Thank you, Wolfgang (sorry for misspelling). So, by: " The coefficient for
> >the females is of course [one additional parameter]" you mean for the
> >variance coefficient of `female == 1` as a binary predictor, right?
> >
> >On Sun, Nov 1, 2020 at 10:31 AM Viechtbauer, Wolfgang (SP) <
> >wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:
> >
> >> I meant that the 1 for males is not an estimated parameter. The
> >> coefficient for the females is of course (and hence one additional
> >> parameter). Apologies for the confusion.
> >>
> >> For correlation structures, there will indeed be a 'corStruct' element
> >> under 'modelStruct'.
> >>
> >> Best,
> >> Wolfgang
> >>
> >> >-----Original Message-----
> >> >From: Simon Harmel [mailto:sim.harmel at gmail.com]
> >> >Sent: Sunday, 01 November, 2020 17:15
> >> >To: Viechtbauer, Wolfgang (SP)
> >> >Cc: Harold Doran; r-sig-mixed-models
> >> >Subject: Re: [R-sig-ME] lme: count the number extra parameters
> estimated
> >> for
> >> >variance or covariances
> >> >
> >> >Thank you Wolfang. That was exactly what I was looking for. If an lme()
> >> >model uses  `correlation = corAR1()`, then I'm assuming something new
> >> >will appear for the question mark in the following:
> `m2$modelStruct$???`,
> >> >right?
> >> >
> >> >Wolfang, on the one the hand you mentioned: "you will also get the
> >> >coefficient (= 1) for the males. But that is not actually an estimated
> >> >parameter",
> >> >
> >> >On the other hand you mentioned: "And these *are* parameters (besides
> the
> >> >fixed effects and the vars/covs of the random effects)."
> >> >
> >> >Multiple software I used show that my model with `varIdent(form = ~1
> >> >|female)` estimates one additional parameter compared to a
> corresponding
> >> >model without `varIdent(form = ~1 |female)`.
> >> >
> >> >Books (e.g., Mixed Effects Models and Extensions in Ecology with R by
> >Zuur
> >> >et al, 2009; Pinheiro & Bates, 2000, p. 209) also clearly mention
> >> >`varIdent(form = ~1 |female)` estimates one more parameter.
> >> >
> >> >Would you please clarify?
> >> >
> >> >On Sun, Nov 1, 2020 at 9:44 AM Viechtbauer, Wolfgang (SP)
> >> ><wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:
> >> >Dear Simon,
> >> >
> >> >For variance structures, you can use:
> >> >
> >> >coef(fit$modelStruct$varStruct)
> >> >
> >> >That will give you the parameter estimates involved in the variance
> >> >structure (in their constrained form as used during the optimization).
> >> With:
> >> >
> >> >coef(fit$modelStruct$varStruct, unconstrained=FALSE)
> >> >
> >> >you can get the unconstrained estimates. Only coefficients that are
> >> actually
> >> >estimated are returned by default. With:
> >> >
> >> >coef(fit$modelStruct$varStruct, unconstrained=FALSE, allCoef=TRUE)
> >> >
> >> >you will also get the coefficient (= 1) for the males. But that is not
> >> >actually an estimated parameter. For more details, see:
> >> >
> >> >help(coef.varFunc)
> >> >
> >> >And these *are* parameters (besides the fixed effects and the vars/covs
> >of
> >> >the random effects).
> >> >
> >> >Best,
> >> >Wolfgang
> >> >
> >> >>-----Original Message-----
> >> >>From: R-sig-mixed-models [mailto:
> >> r-sig-mixed-models-bounces at r-project.org]
> >> >>On Behalf Of Harold Doran
> >> >>Sent: Sunday, 01 November, 2020 16:26
> >> >>To: Simon Harmel
> >> >>Cc: r-sig-mixed-models
> >> >>Subject: Re: [R-sig-ME] lme: count the number extra parameters
> estimated
> >> >for
> >> >>variance or covariances
> >> >>
> >> >>I think you need to understand what a reproducible example is intended
> >to
> >> >>do. Your data estimates a model and yields a fiitted model object.
> What
> >> >>parameter from that object using an extractor are you intending to
> find?
> >> >>
> >> >>For example, a well posed question would be something like. I want to
> >> >>extract the fixed effects from a fitted model object. How do I get
> them?
> >> >>
> >> >>To say I want the ?parameters estimated for modeling residual
> variances?
> >> >etc
> >> >>makes no sense. The parameters of a mixed model are the fixed effects
> >and
> >> >>the marginal variances (and covariances) of the random effects.
> >> >>
> >> >>So, specifically what parameters do you think exist in a model that
> you
> >> >>want?
> >> >>
> >> >>From: Simon Harmel <sim.harmel at gmail.com>
> >> >>Sent: Sunday, November 1, 2020 9:58 AM
> >> >>To: Harold Doran <harold.doran at cambiumassessment.com>
> >> >>Cc: r-sig-mixed-models <r-sig-mixed-models at r-project.org>
> >> >>Subject: Re: [R-sig-ME] lme: count the number extra parameters
> estimated
> >> >for
> >> >>variance or covariances
> >> >>
> >> >>Dear Harold,
> >> >>
> >> >>My question "specifically" is:  is there a way (e.g., via an extractor
> >> >>function) to obtain parameters estimated for modeling residual
> variances
> >> or
> >> >>covariances from an "lme" model?
> >> >>
> >> >>For concreteness, please consider the reproducible model I provided in
> >my
> >> >>original post in which a variance function has been used.
> >> >>
> >> >>Thanks,
> >> >>
> >> >>On Sun, Nov 1, 2020, 4:43 AM Harold Doran
> >> >><harold.doran at cambiumassessment.com<mailto:
> >> harold.doran at cambiumassessment.c
> >> >o
> >> >>m>> wrote:
> >> >>In order to answer that you need to specify what "thing" you want. The
> >> >>object itself has many things and there are extractor functions to
> grab
> >> >many
> >> >>of them. I say "thing" because the *parameters* of a mixed model are
> the
> >> >>fixed effects and the variance components. Random effects etc are not
> >> >>parameters of a mixed model.
> >> >>
> >> >>You can always look at the structure of a fitted model object in R to
> >see
> >> >>what things are generally in it.
> >> >>
> >> >>-----Original Message-----
> >> >>From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-
> >> >project.org<mailto:r-
> >> >>sig-mixed-models-bounces at r-project.org>> On Behalf Of Simon Harmel
> >> >>Sent: Sunday, November 1, 2020 4:02 AM
> >> >>To: r-sig-mixed-models <r-sig-mixed-models at r-project.org<mailto:
> r-sig-
> >> >mixed-
> >> >>models at r-project.org>>
> >> >>Subject: [R-sig-ME] lme: count the number extra parameters estimated
> for
> >> >>variance or covariances
> >> >>
> >> >>External email alert: Be wary of links & attachments.
> >> >>
> >> >>Hello All,
> >> >>
> >> >>In addition to fixed and random effects, is there a way to extract how
> >> many
> >> >>other parameters (for modeling residual variances or covariances) an
> >> >"lme()"
> >> >>object has estimated?
> >> >>
> >> >>Here is a reproducible example:
> >> >>
> >> >>library(nlme)
> >> >>
> >> >>hsb <- read.csv('
> >> >>https://raw.githubusercontent.com/rnorouzian/e/master/hsb.csv')
> >> >>hsb$female <- as.factor(hsb$female)
> >> >>
> >> >>fit <- lme(math ~ female, random = ~ 1|sch.id<http://sch.id>, data =
> >> hsb,
> >> >>weights = varIdent(form = ~1 |female))
>

	[[alternative HTML version deleted]]


From @|m@h@rme| @end|ng |rom gm@||@com  Sun Nov  1 19:19:23 2020
From: @|m@h@rme| @end|ng |rom gm@||@com (Simon Harmel)
Date: Sun, 1 Nov 2020 12:19:23 -0600
Subject: [R-sig-ME] lme: count the number extra parameters estimated for
 variance or covariances
In-Reply-To: <CACgv6yUiAbbp6ZP0giL49SPm4xsLLvcuxj5dtR9rr37H5v+qyQ@mail.gmail.com>
References: <CACgv6yU6+nOyqH=KO1Cq78h=tALFz_FA4ewh7_5__ixVap+_yw@mail.gmail.com>
 <fd1c7706d48046e5b5ad65652176b22b@cambiumassessment.com>
 <CACgv6yV32U=w+PaP-nat1igtYMuXUh_LvFRB1h16GiYy6-s=uQ@mail.gmail.com>
 <9db3914e693b4630a8c6f3324b2838af@cambiumassessment.com>
 <14b45e454e9246f7acddc6ccda5688b7@UM-MAIL3213.unimaas.nl>
 <CACgv6yUvGQP6PHyV2FppJpi3N68EjcBCyJ9sCzdZJ4vQZgXGwg@mail.gmail.com>
 <cbbe359b4c0f4ef694de8fc5d7aba31e@UM-MAIL3213.unimaas.nl>
 <CACgv6yUbrQ0ywgFv8u9eY476hWKK-Punv7vK--RY+fg-QGYViw@mail.gmail.com>
 <CAFUVuJzZ3wBcCr8QTj3-yUOC7QhymBVgZgmabtqZYOjk8NN1-w@mail.gmail.com>
 <CACgv6yU4hLXcY=4a+0Ne5Hx_69fS_SjxMgsa-a-9iMnzVjYpeg@mail.gmail.com>
 <fa17a7d01ffa4bd28e50b44f7ef32f63@UM-MAIL3213.unimaas.nl>
 <CACgv6yUiAbbp6ZP0giL49SPm4xsLLvcuxj5dtR9rr37H5v+qyQ@mail.gmail.com>
Message-ID: <CACgv6yUGWt4jNwwMvmmTcwwfN3wCCsMz_04f1-TWBt05SjH5oQ@mail.gmail.com>

By the way, Wolfgang, for my model above the variance function returns
1.047655 for males. I know this is a multiplicative constant, but should
I multiply this constant by the estimated residual variance for the entire
model to obtain the estimated residual variance for males? That is:

sigma(fit)^2 * 1.047655 ## > [1] 38.91265 ## what would be the residual
variance for females?

===============
library(nlme)

hsb <- read.csv('
https://raw.githubusercontent.com/rnorouzian/e/master/hsb.csv')
hsb$female <- as.factor(hsb$female)

fit <- lme(math ~ female, random = ~ 1|sch.id, data = hsb, weights =
varIdent(form = ~1 |female))

Variance function:
Formula: ~1 | female
 Parameter estimates:
       1         0
1.000000 1.047655



On Sun, Nov 1, 2020 at 11:15 AM Simon Harmel <sim.harmel at gmail.com> wrote:

> Great, many thanks to all!
>
> On Sun, Nov 1, 2020 at 11:14 AM Viechtbauer, Wolfgang (SP) <
> wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:
>
>> Ah, very cool. Did not know about the lmeInfo package.
>>
>> And yes, one can think of the parameter/coefficient for females as a
>> binary predictor that allows the error variance to differ for females from
>> that of the males.
>>
>> Best,
>> Wolfgang
>>
>> >-----Original Message-----
>> >From: Simon Harmel [mailto:sim.harmel at gmail.com]
>> >Sent: Sunday, 01 November, 2020 18:06
>> >To: James Pustejovsky
>> >Cc: Viechtbauer, Wolfgang (SP); Harold Doran; r-sig-mixed-models
>> >Subject: Re: [R-sig-ME] lme: count the number extra parameters estimated
>> for
>> >variance or covariances
>> >
>> >Thanks, James!
>> >
>> >On Sun, Nov 1, 2020 at 11:03 AM James Pustejovsky <jepusto at gmail.com>
>> wrote:
>> >Simon,
>> >
>> >Here is a quick way to accomplish the same thing that Wolfgang
>> demonstrated,
>> >using the lmeInfo package:
>> >VC <- lmeInfo::extract_varcomp(fit)   # get all the variance components
>> >lengths(VC)                                        # count the number of
>> >estimated parameters in each component
>> >sum(lengths(VC))                               # total number of variance
>> >component parameters
>> >
>> >Kind Regards,
>> >James
>> >
>> >On Sun, Nov 1, 2020 at 10:45 AM Simon Harmel <sim.harmel at gmail.com>
>> wrote:
>> >Thank you, Wolfgang (sorry for misspelling). So, by: " The coefficient
>> for
>> >the females is of course [one additional parameter]" you mean for the
>> >variance coefficient of `female == 1` as a binary predictor, right?
>> >
>> >On Sun, Nov 1, 2020 at 10:31 AM Viechtbauer, Wolfgang (SP) <
>> >wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:
>> >
>> >> I meant that the 1 for males is not an estimated parameter. The
>> >> coefficient for the females is of course (and hence one additional
>> >> parameter). Apologies for the confusion.
>> >>
>> >> For correlation structures, there will indeed be a 'corStruct' element
>> >> under 'modelStruct'.
>> >>
>> >> Best,
>> >> Wolfgang
>> >>
>> >> >-----Original Message-----
>> >> >From: Simon Harmel [mailto:sim.harmel at gmail.com]
>> >> >Sent: Sunday, 01 November, 2020 17:15
>> >> >To: Viechtbauer, Wolfgang (SP)
>> >> >Cc: Harold Doran; r-sig-mixed-models
>> >> >Subject: Re: [R-sig-ME] lme: count the number extra parameters
>> estimated
>> >> for
>> >> >variance or covariances
>> >> >
>> >> >Thank you Wolfang. That was exactly what I was looking for. If an
>> lme()
>> >> >model uses  `correlation = corAR1()`, then I'm assuming something new
>> >> >will appear for the question mark in the following:
>> `m2$modelStruct$???`,
>> >> >right?
>> >> >
>> >> >Wolfang, on the one the hand you mentioned: "you will also get the
>> >> >coefficient (= 1) for the males. But that is not actually an estimated
>> >> >parameter",
>> >> >
>> >> >On the other hand you mentioned: "And these *are* parameters (besides
>> the
>> >> >fixed effects and the vars/covs of the random effects)."
>> >> >
>> >> >Multiple software I used show that my model with `varIdent(form = ~1
>> >> >|female)` estimates one additional parameter compared to a
>> corresponding
>> >> >model without `varIdent(form = ~1 |female)`.
>> >> >
>> >> >Books (e.g., Mixed Effects Models and Extensions in Ecology with R by
>> >Zuur
>> >> >et al, 2009; Pinheiro & Bates, 2000, p. 209) also clearly mention
>> >> >`varIdent(form = ~1 |female)` estimates one more parameter.
>> >> >
>> >> >Would you please clarify?
>> >> >
>> >> >On Sun, Nov 1, 2020 at 9:44 AM Viechtbauer, Wolfgang (SP)
>> >> ><wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:
>> >> >Dear Simon,
>> >> >
>> >> >For variance structures, you can use:
>> >> >
>> >> >coef(fit$modelStruct$varStruct)
>> >> >
>> >> >That will give you the parameter estimates involved in the variance
>> >> >structure (in their constrained form as used during the optimization).
>> >> With:
>> >> >
>> >> >coef(fit$modelStruct$varStruct, unconstrained=FALSE)
>> >> >
>> >> >you can get the unconstrained estimates. Only coefficients that are
>> >> actually
>> >> >estimated are returned by default. With:
>> >> >
>> >> >coef(fit$modelStruct$varStruct, unconstrained=FALSE, allCoef=TRUE)
>> >> >
>> >> >you will also get the coefficient (= 1) for the males. But that is not
>> >> >actually an estimated parameter. For more details, see:
>> >> >
>> >> >help(coef.varFunc)
>> >> >
>> >> >And these *are* parameters (besides the fixed effects and the
>> vars/covs
>> >of
>> >> >the random effects).
>> >> >
>> >> >Best,
>> >> >Wolfgang
>> >> >
>> >> >>-----Original Message-----
>> >> >>From: R-sig-mixed-models [mailto:
>> >> r-sig-mixed-models-bounces at r-project.org]
>> >> >>On Behalf Of Harold Doran
>> >> >>Sent: Sunday, 01 November, 2020 16:26
>> >> >>To: Simon Harmel
>> >> >>Cc: r-sig-mixed-models
>> >> >>Subject: Re: [R-sig-ME] lme: count the number extra parameters
>> estimated
>> >> >for
>> >> >>variance or covariances
>> >> >>
>> >> >>I think you need to understand what a reproducible example is
>> intended
>> >to
>> >> >>do. Your data estimates a model and yields a fiitted model object.
>> What
>> >> >>parameter from that object using an extractor are you intending to
>> find?
>> >> >>
>> >> >>For example, a well posed question would be something like. I want to
>> >> >>extract the fixed effects from a fitted model object. How do I get
>> them?
>> >> >>
>> >> >>To say I want the ?parameters estimated for modeling residual
>> variances?
>> >> >etc
>> >> >>makes no sense. The parameters of a mixed model are the fixed effects
>> >and
>> >> >>the marginal variances (and covariances) of the random effects.
>> >> >>
>> >> >>So, specifically what parameters do you think exist in a model that
>> you
>> >> >>want?
>> >> >>
>> >> >>From: Simon Harmel <sim.harmel at gmail.com>
>> >> >>Sent: Sunday, November 1, 2020 9:58 AM
>> >> >>To: Harold Doran <harold.doran at cambiumassessment.com>
>> >> >>Cc: r-sig-mixed-models <r-sig-mixed-models at r-project.org>
>> >> >>Subject: Re: [R-sig-ME] lme: count the number extra parameters
>> estimated
>> >> >for
>> >> >>variance or covariances
>> >> >>
>> >> >>Dear Harold,
>> >> >>
>> >> >>My question "specifically" is:  is there a way (e.g., via an
>> extractor
>> >> >>function) to obtain parameters estimated for modeling residual
>> variances
>> >> or
>> >> >>covariances from an "lme" model?
>> >> >>
>> >> >>For concreteness, please consider the reproducible model I provided
>> in
>> >my
>> >> >>original post in which a variance function has been used.
>> >> >>
>> >> >>Thanks,
>> >> >>
>> >> >>On Sun, Nov 1, 2020, 4:43 AM Harold Doran
>> >> >><harold.doran at cambiumassessment.com<mailto:
>> >> harold.doran at cambiumassessment.c
>> >> >o
>> >> >>m>> wrote:
>> >> >>In order to answer that you need to specify what "thing" you want.
>> The
>> >> >>object itself has many things and there are extractor functions to
>> grab
>> >> >many
>> >> >>of them. I say "thing" because the *parameters* of a mixed model are
>> the
>> >> >>fixed effects and the variance components. Random effects etc are not
>> >> >>parameters of a mixed model.
>> >> >>
>> >> >>You can always look at the structure of a fitted model object in R to
>> >see
>> >> >>what things are generally in it.
>> >> >>
>> >> >>-----Original Message-----
>> >> >>From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-
>> >> >project.org<mailto:r-
>> >> >>sig-mixed-models-bounces at r-project.org>> On Behalf Of Simon Harmel
>> >> >>Sent: Sunday, November 1, 2020 4:02 AM
>> >> >>To: r-sig-mixed-models <r-sig-mixed-models at r-project.org<mailto:
>> r-sig-
>> >> >mixed-
>> >> >>models at r-project.org>>
>> >> >>Subject: [R-sig-ME] lme: count the number extra parameters estimated
>> for
>> >> >>variance or covariances
>> >> >>
>> >> >>External email alert: Be wary of links & attachments.
>> >> >>
>> >> >>Hello All,
>> >> >>
>> >> >>In addition to fixed and random effects, is there a way to extract
>> how
>> >> many
>> >> >>other parameters (for modeling residual variances or covariances) an
>> >> >"lme()"
>> >> >>object has estimated?
>> >> >>
>> >> >>Here is a reproducible example:
>> >> >>
>> >> >>library(nlme)
>> >> >>
>> >> >>hsb <- read.csv('
>> >> >>https://raw.githubusercontent.com/rnorouzian/e/master/hsb.csv')
>> >> >>hsb$female <- as.factor(hsb$female)
>> >> >>
>> >> >>fit <- lme(math ~ female, random = ~ 1|sch.id<http://sch.id>, data =
>> >> hsb,
>> >> >>weights = varIdent(form = ~1 |female))
>>
>

	[[alternative HTML version deleted]]


From jepu@to @end|ng |rom gm@||@com  Sun Nov  1 22:41:18 2020
From: jepu@to @end|ng |rom gm@||@com (James Pustejovsky)
Date: Sun, 1 Nov 2020 15:41:18 -0600
Subject: [R-sig-ME] lme: count the number extra parameters estimated for
 variance or covariances
In-Reply-To: <CACgv6yUGWt4jNwwMvmmTcwwfN3wCCsMz_04f1-TWBt05SjH5oQ@mail.gmail.com>
References: <CACgv6yU6+nOyqH=KO1Cq78h=tALFz_FA4ewh7_5__ixVap+_yw@mail.gmail.com>
 <fd1c7706d48046e5b5ad65652176b22b@cambiumassessment.com>
 <CACgv6yV32U=w+PaP-nat1igtYMuXUh_LvFRB1h16GiYy6-s=uQ@mail.gmail.com>
 <9db3914e693b4630a8c6f3324b2838af@cambiumassessment.com>
 <14b45e454e9246f7acddc6ccda5688b7@UM-MAIL3213.unimaas.nl>
 <CACgv6yUvGQP6PHyV2FppJpi3N68EjcBCyJ9sCzdZJ4vQZgXGwg@mail.gmail.com>
 <cbbe359b4c0f4ef694de8fc5d7aba31e@UM-MAIL3213.unimaas.nl>
 <CACgv6yUbrQ0ywgFv8u9eY476hWKK-Punv7vK--RY+fg-QGYViw@mail.gmail.com>
 <CAFUVuJzZ3wBcCr8QTj3-yUOC7QhymBVgZgmabtqZYOjk8NN1-w@mail.gmail.com>
 <CACgv6yU4hLXcY=4a+0Ne5Hx_69fS_SjxMgsa-a-9iMnzVjYpeg@mail.gmail.com>
 <fa17a7d01ffa4bd28e50b44f7ef32f63@UM-MAIL3213.unimaas.nl>
 <CACgv6yUiAbbp6ZP0giL49SPm4xsLLvcuxj5dtR9rr37H5v+qyQ@mail.gmail.com>
 <CACgv6yUGWt4jNwwMvmmTcwwfN3wCCsMz_04f1-TWBt05SjH5oQ@mail.gmail.com>
Message-ID: <CAFUVuJx=-4WEX25masxOHfjLza_brgdk61kdZRdSwbVcO+tpnA@mail.gmail.com>

Hi Simon,

Yes, the estimated residual variance among males is as you've calculated.
Using lmeInfo again:

VC <- extract_varcomp(fit)
with(VC, var_params * sigma_sq)

Female is the reference level here, so the residual variance there is
simply VC$sigma_sq.

James

On Sun, Nov 1, 2020 at 12:19 PM Simon Harmel <sim.harmel at gmail.com> wrote:

> By the way, Wolfgang, for my model above the variance function returns
> 1.047655 for males. I know this is a multiplicative constant, but should
> I multiply this constant by the estimated residual variance for the entire
> model to obtain the estimated residual variance for males? That is:
>
> sigma(fit)^2 * 1.047655 ## > [1] 38.91265 ## what would be the residual
> variance for females?
>
> ===============
> library(nlme)
>
> hsb <- read.csv('
> https://raw.githubusercontent.com/rnorouzian/e/master/hsb.csv')
> hsb$female <- as.factor(hsb$female)
>
> fit <- lme(math ~ female, random = ~ 1|sch.id, data = hsb, weights =
> varIdent(form = ~1 |female))
>
> Variance function:
> Formula: ~1 | female
>  Parameter estimates:
>        1         0
> 1.000000 1.047655
>
>
>
> On Sun, Nov 1, 2020 at 11:15 AM Simon Harmel <sim.harmel at gmail.com> wrote:
>
>> Great, many thanks to all!
>>
>> On Sun, Nov 1, 2020 at 11:14 AM Viechtbauer, Wolfgang (SP) <
>> wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:
>>
>>> Ah, very cool. Did not know about the lmeInfo package.
>>>
>>> And yes, one can think of the parameter/coefficient for females as a
>>> binary predictor that allows the error variance to differ for females from
>>> that of the males.
>>>
>>> Best,
>>> Wolfgang
>>>
>>> >-----Original Message-----
>>> >From: Simon Harmel [mailto:sim.harmel at gmail.com]
>>> >Sent: Sunday, 01 November, 2020 18:06
>>> >To: James Pustejovsky
>>> >Cc: Viechtbauer, Wolfgang (SP); Harold Doran; r-sig-mixed-models
>>> >Subject: Re: [R-sig-ME] lme: count the number extra parameters
>>> estimated for
>>> >variance or covariances
>>> >
>>> >Thanks, James!
>>> >
>>> >On Sun, Nov 1, 2020 at 11:03 AM James Pustejovsky <jepusto at gmail.com>
>>> wrote:
>>> >Simon,
>>> >
>>> >Here is a quick way to accomplish the same thing that Wolfgang
>>> demonstrated,
>>> >using the lmeInfo package:
>>> >VC <- lmeInfo::extract_varcomp(fit)   # get all the variance components
>>> >lengths(VC)                                        # count the number of
>>> >estimated parameters in each component
>>> >sum(lengths(VC))                               # total number of
>>> variance
>>> >component parameters
>>> >
>>> >Kind Regards,
>>> >James
>>> >
>>> >On Sun, Nov 1, 2020 at 10:45 AM Simon Harmel <sim.harmel at gmail.com>
>>> wrote:
>>> >Thank you, Wolfgang (sorry for misspelling). So, by: " The coefficient
>>> for
>>> >the females is of course [one additional parameter]" you mean for the
>>> >variance coefficient of `female == 1` as a binary predictor, right?
>>> >
>>> >On Sun, Nov 1, 2020 at 10:31 AM Viechtbauer, Wolfgang (SP) <
>>> >wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:
>>> >
>>> >> I meant that the 1 for males is not an estimated parameter. The
>>> >> coefficient for the females is of course (and hence one additional
>>> >> parameter). Apologies for the confusion.
>>> >>
>>> >> For correlation structures, there will indeed be a 'corStruct' element
>>> >> under 'modelStruct'.
>>> >>
>>> >> Best,
>>> >> Wolfgang
>>> >>
>>> >> >-----Original Message-----
>>> >> >From: Simon Harmel [mailto:sim.harmel at gmail.com]
>>> >> >Sent: Sunday, 01 November, 2020 17:15
>>> >> >To: Viechtbauer, Wolfgang (SP)
>>> >> >Cc: Harold Doran; r-sig-mixed-models
>>> >> >Subject: Re: [R-sig-ME] lme: count the number extra parameters
>>> estimated
>>> >> for
>>> >> >variance or covariances
>>> >> >
>>> >> >Thank you Wolfang. That was exactly what I was looking for. If an
>>> lme()
>>> >> >model uses  `correlation = corAR1()`, then I'm assuming something new
>>> >> >will appear for the question mark in the following:
>>> `m2$modelStruct$???`,
>>> >> >right?
>>> >> >
>>> >> >Wolfang, on the one the hand you mentioned: "you will also get the
>>> >> >coefficient (= 1) for the males. But that is not actually an
>>> estimated
>>> >> >parameter",
>>> >> >
>>> >> >On the other hand you mentioned: "And these *are* parameters
>>> (besides the
>>> >> >fixed effects and the vars/covs of the random effects)."
>>> >> >
>>> >> >Multiple software I used show that my model with `varIdent(form = ~1
>>> >> >|female)` estimates one additional parameter compared to a
>>> corresponding
>>> >> >model without `varIdent(form = ~1 |female)`.
>>> >> >
>>> >> >Books (e.g., Mixed Effects Models and Extensions in Ecology with R by
>>> >Zuur
>>> >> >et al, 2009; Pinheiro & Bates, 2000, p. 209) also clearly mention
>>> >> >`varIdent(form = ~1 |female)` estimates one more parameter.
>>> >> >
>>> >> >Would you please clarify?
>>> >> >
>>> >> >On Sun, Nov 1, 2020 at 9:44 AM Viechtbauer, Wolfgang (SP)
>>> >> ><wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:
>>> >> >Dear Simon,
>>> >> >
>>> >> >For variance structures, you can use:
>>> >> >
>>> >> >coef(fit$modelStruct$varStruct)
>>> >> >
>>> >> >That will give you the parameter estimates involved in the variance
>>> >> >structure (in their constrained form as used during the
>>> optimization).
>>> >> With:
>>> >> >
>>> >> >coef(fit$modelStruct$varStruct, unconstrained=FALSE)
>>> >> >
>>> >> >you can get the unconstrained estimates. Only coefficients that are
>>> >> actually
>>> >> >estimated are returned by default. With:
>>> >> >
>>> >> >coef(fit$modelStruct$varStruct, unconstrained=FALSE, allCoef=TRUE)
>>> >> >
>>> >> >you will also get the coefficient (= 1) for the males. But that is
>>> not
>>> >> >actually an estimated parameter. For more details, see:
>>> >> >
>>> >> >help(coef.varFunc)
>>> >> >
>>> >> >And these *are* parameters (besides the fixed effects and the
>>> vars/covs
>>> >of
>>> >> >the random effects).
>>> >> >
>>> >> >Best,
>>> >> >Wolfgang
>>> >> >
>>> >> >>-----Original Message-----
>>> >> >>From: R-sig-mixed-models [mailto:
>>> >> r-sig-mixed-models-bounces at r-project.org]
>>> >> >>On Behalf Of Harold Doran
>>> >> >>Sent: Sunday, 01 November, 2020 16:26
>>> >> >>To: Simon Harmel
>>> >> >>Cc: r-sig-mixed-models
>>> >> >>Subject: Re: [R-sig-ME] lme: count the number extra parameters
>>> estimated
>>> >> >for
>>> >> >>variance or covariances
>>> >> >>
>>> >> >>I think you need to understand what a reproducible example is
>>> intended
>>> >to
>>> >> >>do. Your data estimates a model and yields a fiitted model object.
>>> What
>>> >> >>parameter from that object using an extractor are you intending to
>>> find?
>>> >> >>
>>> >> >>For example, a well posed question would be something like. I want
>>> to
>>> >> >>extract the fixed effects from a fitted model object. How do I get
>>> them?
>>> >> >>
>>> >> >>To say I want the ?parameters estimated for modeling residual
>>> variances?
>>> >> >etc
>>> >> >>makes no sense. The parameters of a mixed model are the fixed
>>> effects
>>> >and
>>> >> >>the marginal variances (and covariances) of the random effects.
>>> >> >>
>>> >> >>So, specifically what parameters do you think exist in a model that
>>> you
>>> >> >>want?
>>> >> >>
>>> >> >>From: Simon Harmel <sim.harmel at gmail.com>
>>> >> >>Sent: Sunday, November 1, 2020 9:58 AM
>>> >> >>To: Harold Doran <harold.doran at cambiumassessment.com>
>>> >> >>Cc: r-sig-mixed-models <r-sig-mixed-models at r-project.org>
>>> >> >>Subject: Re: [R-sig-ME] lme: count the number extra parameters
>>> estimated
>>> >> >for
>>> >> >>variance or covariances
>>> >> >>
>>> >> >>Dear Harold,
>>> >> >>
>>> >> >>My question "specifically" is:  is there a way (e.g., via an
>>> extractor
>>> >> >>function) to obtain parameters estimated for modeling residual
>>> variances
>>> >> or
>>> >> >>covariances from an "lme" model?
>>> >> >>
>>> >> >>For concreteness, please consider the reproducible model I provided
>>> in
>>> >my
>>> >> >>original post in which a variance function has been used.
>>> >> >>
>>> >> >>Thanks,
>>> >> >>
>>> >> >>On Sun, Nov 1, 2020, 4:43 AM Harold Doran
>>> >> >><harold.doran at cambiumassessment.com<mailto:
>>> >> harold.doran at cambiumassessment.c
>>> >> >o
>>> >> >>m>> wrote:
>>> >> >>In order to answer that you need to specify what "thing" you want.
>>> The
>>> >> >>object itself has many things and there are extractor functions to
>>> grab
>>> >> >many
>>> >> >>of them. I say "thing" because the *parameters* of a mixed model
>>> are the
>>> >> >>fixed effects and the variance components. Random effects etc are
>>> not
>>> >> >>parameters of a mixed model.
>>> >> >>
>>> >> >>You can always look at the structure of a fitted model object in R
>>> to
>>> >see
>>> >> >>what things are generally in it.
>>> >> >>
>>> >> >>-----Original Message-----
>>> >> >>From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-
>>> >> >project.org<mailto:r-
>>> >> >>sig-mixed-models-bounces at r-project.org>> On Behalf Of Simon Harmel
>>> >> >>Sent: Sunday, November 1, 2020 4:02 AM
>>> >> >>To: r-sig-mixed-models <r-sig-mixed-models at r-project.org<mailto:
>>> r-sig-
>>> >> >mixed-
>>> >> >>models at r-project.org>>
>>> >> >>Subject: [R-sig-ME] lme: count the number extra parameters
>>> estimated for
>>> >> >>variance or covariances
>>> >> >>
>>> >> >>External email alert: Be wary of links & attachments.
>>> >> >>
>>> >> >>Hello All,
>>> >> >>
>>> >> >>In addition to fixed and random effects, is there a way to extract
>>> how
>>> >> many
>>> >> >>other parameters (for modeling residual variances or covariances) an
>>> >> >"lme()"
>>> >> >>object has estimated?
>>> >> >>
>>> >> >>Here is a reproducible example:
>>> >> >>
>>> >> >>library(nlme)
>>> >> >>
>>> >> >>hsb <- read.csv('
>>> >> >>https://raw.githubusercontent.com/rnorouzian/e/master/hsb.csv')
>>> >> >>hsb$female <- as.factor(hsb$female)
>>> >> >>
>>> >> >>fit <- lme(math ~ female, random = ~ 1|sch.id<http://sch.id>, data
>>> =
>>> >> hsb,
>>> >> >>weights = varIdent(form = ~1 |female))
>>>
>>

	[[alternative HTML version deleted]]


From @|m@h@rme| @end|ng |rom gm@||@com  Mon Nov  2 01:23:39 2020
From: @|m@h@rme| @end|ng |rom gm@||@com (Simon Harmel)
Date: Sun, 1 Nov 2020 18:23:39 -0600
Subject: [R-sig-ME] lme: count the number extra parameters estimated for
 variance or covariances
In-Reply-To: <CAFUVuJx=-4WEX25masxOHfjLza_brgdk61kdZRdSwbVcO+tpnA@mail.gmail.com>
References: <CACgv6yU6+nOyqH=KO1Cq78h=tALFz_FA4ewh7_5__ixVap+_yw@mail.gmail.com>
 <fd1c7706d48046e5b5ad65652176b22b@cambiumassessment.com>
 <CACgv6yV32U=w+PaP-nat1igtYMuXUh_LvFRB1h16GiYy6-s=uQ@mail.gmail.com>
 <9db3914e693b4630a8c6f3324b2838af@cambiumassessment.com>
 <14b45e454e9246f7acddc6ccda5688b7@UM-MAIL3213.unimaas.nl>
 <CACgv6yUvGQP6PHyV2FppJpi3N68EjcBCyJ9sCzdZJ4vQZgXGwg@mail.gmail.com>
 <cbbe359b4c0f4ef694de8fc5d7aba31e@UM-MAIL3213.unimaas.nl>
 <CACgv6yUbrQ0ywgFv8u9eY476hWKK-Punv7vK--RY+fg-QGYViw@mail.gmail.com>
 <CAFUVuJzZ3wBcCr8QTj3-yUOC7QhymBVgZgmabtqZYOjk8NN1-w@mail.gmail.com>
 <CACgv6yU4hLXcY=4a+0Ne5Hx_69fS_SjxMgsa-a-9iMnzVjYpeg@mail.gmail.com>
 <fa17a7d01ffa4bd28e50b44f7ef32f63@UM-MAIL3213.unimaas.nl>
 <CACgv6yUiAbbp6ZP0giL49SPm4xsLLvcuxj5dtR9rr37H5v+qyQ@mail.gmail.com>
 <CACgv6yUGWt4jNwwMvmmTcwwfN3wCCsMz_04f1-TWBt05SjH5oQ@mail.gmail.com>
 <CAFUVuJx=-4WEX25masxOHfjLza_brgdk61kdZRdSwbVcO+tpnA@mail.gmail.com>
Message-ID: <CACgv6yU2+phH9_cZmTfxsRGsPZeAqDF+UBFfTPVswp9GMB=QeA@mail.gmail.com>

Thank you James. Both SPSS and the HLM software estimate the variance for
males to be ~40.

But that aside, given the larger estimated variance for males (coded 0), I
thought I should see a "wider" distribution for males compared to females.
I don't see that to be the case, though (see ggplot below)?

hsb <- read.csv('
https://raw.githubusercontent.com/rnorouzian/e/master/hsb.csv')
hsb$female <- as.factor(hsb$female)

ggplot(hsb) + aes(x = math, color = female) + facet_wrap(~female, scales =
"free")+
  geom_histogram()

Of course, when I plot the "female" variable (a factor of 1s & 0s) against
the residuals of the model I see that the model has correctly worked
showing males are more scattered than females in their residual.

hsb <- within(hsb, resid <- resid(fit))
ggplot(hsb) + aes(x = female, y = resid) + facet_wrap(~female)+geom_point()

On Sun, Nov 1, 2020 at 3:41 PM James Pustejovsky <jepusto at gmail.com> wrote:

> Hi Simon,
>
> Yes, the estimated residual variance among males is as you've calculated.
> Using lmeInfo again:
>
> VC <- extract_varcomp(fit)
> with(VC, var_params * sigma_sq)
>
> Female is the reference level here, so the residual variance there is
> simply VC$sigma_sq.
>
> James
>
> On Sun, Nov 1, 2020 at 12:19 PM Simon Harmel <sim.harmel at gmail.com> wrote:
>
>> By the way, Wolfgang, for my model above the variance function returns
>> 1.047655 for males. I know this is a multiplicative constant, but should
>> I multiply this constant by the estimated residual variance for the entire
>> model to obtain the estimated residual variance for males? That is:
>>
>> sigma(fit)^2 * 1.047655 ## > [1] 38.91265 ## what would be the residual
>> variance for females?
>>
>> ===============
>> library(nlme)
>>
>> hsb <- read.csv('
>> https://raw.githubusercontent.com/rnorouzian/e/master/hsb.csv')
>> hsb$female <- as.factor(hsb$female)
>>
>> fit <- lme(math ~ female, random = ~ 1|sch.id, data = hsb, weights =
>> varIdent(form = ~1 |female))
>>
>> Variance function:
>> Formula: ~1 | female
>>  Parameter estimates:
>>        1         0
>> 1.000000 1.047655
>>
>>
>>
>> On Sun, Nov 1, 2020 at 11:15 AM Simon Harmel <sim.harmel at gmail.com>
>> wrote:
>>
>>> Great, many thanks to all!
>>>
>>> On Sun, Nov 1, 2020 at 11:14 AM Viechtbauer, Wolfgang (SP) <
>>> wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:
>>>
>>>> Ah, very cool. Did not know about the lmeInfo package.
>>>>
>>>> And yes, one can think of the parameter/coefficient for females as a
>>>> binary predictor that allows the error variance to differ for females from
>>>> that of the males.
>>>>
>>>> Best,
>>>> Wolfgang
>>>>
>>>> >-----Original Message-----
>>>> >From: Simon Harmel [mailto:sim.harmel at gmail.com]
>>>> >Sent: Sunday, 01 November, 2020 18:06
>>>> >To: James Pustejovsky
>>>> >Cc: Viechtbauer, Wolfgang (SP); Harold Doran; r-sig-mixed-models
>>>> >Subject: Re: [R-sig-ME] lme: count the number extra parameters
>>>> estimated for
>>>> >variance or covariances
>>>> >
>>>> >Thanks, James!
>>>> >
>>>> >On Sun, Nov 1, 2020 at 11:03 AM James Pustejovsky <jepusto at gmail.com>
>>>> wrote:
>>>> >Simon,
>>>> >
>>>> >Here is a quick way to accomplish the same thing that Wolfgang
>>>> demonstrated,
>>>> >using the lmeInfo package:
>>>> >VC <- lmeInfo::extract_varcomp(fit)   # get all the variance components
>>>> >lengths(VC)                                        # count the number
>>>> of
>>>> >estimated parameters in each component
>>>> >sum(lengths(VC))                               # total number of
>>>> variance
>>>> >component parameters
>>>> >
>>>> >Kind Regards,
>>>> >James
>>>> >
>>>> >On Sun, Nov 1, 2020 at 10:45 AM Simon Harmel <sim.harmel at gmail.com>
>>>> wrote:
>>>> >Thank you, Wolfgang (sorry for misspelling). So, by: " The coefficient
>>>> for
>>>> >the females is of course [one additional parameter]" you mean for the
>>>> >variance coefficient of `female == 1` as a binary predictor, right?
>>>> >
>>>> >On Sun, Nov 1, 2020 at 10:31 AM Viechtbauer, Wolfgang (SP) <
>>>> >wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:
>>>> >
>>>> >> I meant that the 1 for males is not an estimated parameter. The
>>>> >> coefficient for the females is of course (and hence one additional
>>>> >> parameter). Apologies for the confusion.
>>>> >>
>>>> >> For correlation structures, there will indeed be a 'corStruct'
>>>> element
>>>> >> under 'modelStruct'.
>>>> >>
>>>> >> Best,
>>>> >> Wolfgang
>>>> >>
>>>> >> >-----Original Message-----
>>>> >> >From: Simon Harmel [mailto:sim.harmel at gmail.com]
>>>> >> >Sent: Sunday, 01 November, 2020 17:15
>>>> >> >To: Viechtbauer, Wolfgang (SP)
>>>> >> >Cc: Harold Doran; r-sig-mixed-models
>>>> >> >Subject: Re: [R-sig-ME] lme: count the number extra parameters
>>>> estimated
>>>> >> for
>>>> >> >variance or covariances
>>>> >> >
>>>> >> >Thank you Wolfang. That was exactly what I was looking for. If an
>>>> lme()
>>>> >> >model uses  `correlation = corAR1()`, then I'm assuming something
>>>> new
>>>> >> >will appear for the question mark in the following:
>>>> `m2$modelStruct$???`,
>>>> >> >right?
>>>> >> >
>>>> >> >Wolfang, on the one the hand you mentioned: "you will also get the
>>>> >> >coefficient (= 1) for the males. But that is not actually an
>>>> estimated
>>>> >> >parameter",
>>>> >> >
>>>> >> >On the other hand you mentioned: "And these *are* parameters
>>>> (besides the
>>>> >> >fixed effects and the vars/covs of the random effects)."
>>>> >> >
>>>> >> >Multiple software I used show that my model with `varIdent(form = ~1
>>>> >> >|female)` estimates one additional parameter compared to a
>>>> corresponding
>>>> >> >model without `varIdent(form = ~1 |female)`.
>>>> >> >
>>>> >> >Books (e.g., Mixed Effects Models and Extensions in Ecology with R
>>>> by
>>>> >Zuur
>>>> >> >et al, 2009; Pinheiro & Bates, 2000, p. 209) also clearly mention
>>>> >> >`varIdent(form = ~1 |female)` estimates one more parameter.
>>>> >> >
>>>> >> >Would you please clarify?
>>>> >> >
>>>> >> >On Sun, Nov 1, 2020 at 9:44 AM Viechtbauer, Wolfgang (SP)
>>>> >> ><wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:
>>>> >> >Dear Simon,
>>>> >> >
>>>> >> >For variance structures, you can use:
>>>> >> >
>>>> >> >coef(fit$modelStruct$varStruct)
>>>> >> >
>>>> >> >That will give you the parameter estimates involved in the variance
>>>> >> >structure (in their constrained form as used during the
>>>> optimization).
>>>> >> With:
>>>> >> >
>>>> >> >coef(fit$modelStruct$varStruct, unconstrained=FALSE)
>>>> >> >
>>>> >> >you can get the unconstrained estimates. Only coefficients that are
>>>> >> actually
>>>> >> >estimated are returned by default. With:
>>>> >> >
>>>> >> >coef(fit$modelStruct$varStruct, unconstrained=FALSE, allCoef=TRUE)
>>>> >> >
>>>> >> >you will also get the coefficient (= 1) for the males. But that is
>>>> not
>>>> >> >actually an estimated parameter. For more details, see:
>>>> >> >
>>>> >> >help(coef.varFunc)
>>>> >> >
>>>> >> >And these *are* parameters (besides the fixed effects and the
>>>> vars/covs
>>>> >of
>>>> >> >the random effects).
>>>> >> >
>>>> >> >Best,
>>>> >> >Wolfgang
>>>> >> >
>>>> >> >>-----Original Message-----
>>>> >> >>From: R-sig-mixed-models [mailto:
>>>> >> r-sig-mixed-models-bounces at r-project.org]
>>>> >> >>On Behalf Of Harold Doran
>>>> >> >>Sent: Sunday, 01 November, 2020 16:26
>>>> >> >>To: Simon Harmel
>>>> >> >>Cc: r-sig-mixed-models
>>>> >> >>Subject: Re: [R-sig-ME] lme: count the number extra parameters
>>>> estimated
>>>> >> >for
>>>> >> >>variance or covariances
>>>> >> >>
>>>> >> >>I think you need to understand what a reproducible example is
>>>> intended
>>>> >to
>>>> >> >>do. Your data estimates a model and yields a fiitted model object.
>>>> What
>>>> >> >>parameter from that object using an extractor are you intending to
>>>> find?
>>>> >> >>
>>>> >> >>For example, a well posed question would be something like. I want
>>>> to
>>>> >> >>extract the fixed effects from a fitted model object. How do I get
>>>> them?
>>>> >> >>
>>>> >> >>To say I want the ?parameters estimated for modeling residual
>>>> variances?
>>>> >> >etc
>>>> >> >>makes no sense. The parameters of a mixed model are the fixed
>>>> effects
>>>> >and
>>>> >> >>the marginal variances (and covariances) of the random effects.
>>>> >> >>
>>>> >> >>So, specifically what parameters do you think exist in a model
>>>> that you
>>>> >> >>want?
>>>> >> >>
>>>> >> >>From: Simon Harmel <sim.harmel at gmail.com>
>>>> >> >>Sent: Sunday, November 1, 2020 9:58 AM
>>>> >> >>To: Harold Doran <harold.doran at cambiumassessment.com>
>>>> >> >>Cc: r-sig-mixed-models <r-sig-mixed-models at r-project.org>
>>>> >> >>Subject: Re: [R-sig-ME] lme: count the number extra parameters
>>>> estimated
>>>> >> >for
>>>> >> >>variance or covariances
>>>> >> >>
>>>> >> >>Dear Harold,
>>>> >> >>
>>>> >> >>My question "specifically" is:  is there a way (e.g., via an
>>>> extractor
>>>> >> >>function) to obtain parameters estimated for modeling residual
>>>> variances
>>>> >> or
>>>> >> >>covariances from an "lme" model?
>>>> >> >>
>>>> >> >>For concreteness, please consider the reproducible model I
>>>> provided in
>>>> >my
>>>> >> >>original post in which a variance function has been used.
>>>> >> >>
>>>> >> >>Thanks,
>>>> >> >>
>>>> >> >>On Sun, Nov 1, 2020, 4:43 AM Harold Doran
>>>> >> >><harold.doran at cambiumassessment.com<mailto:
>>>> >> harold.doran at cambiumassessment.c
>>>> >> >o
>>>> >> >>m>> wrote:
>>>> >> >>In order to answer that you need to specify what "thing" you want.
>>>> The
>>>> >> >>object itself has many things and there are extractor functions to
>>>> grab
>>>> >> >many
>>>> >> >>of them. I say "thing" because the *parameters* of a mixed model
>>>> are the
>>>> >> >>fixed effects and the variance components. Random effects etc are
>>>> not
>>>> >> >>parameters of a mixed model.
>>>> >> >>
>>>> >> >>You can always look at the structure of a fitted model object in R
>>>> to
>>>> >see
>>>> >> >>what things are generally in it.
>>>> >> >>
>>>> >> >>-----Original Message-----
>>>> >> >>From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-
>>>> >> >project.org<mailto:r-
>>>> >> >>sig-mixed-models-bounces at r-project.org>> On Behalf Of Simon Harmel
>>>> >> >>Sent: Sunday, November 1, 2020 4:02 AM
>>>> >> >>To: r-sig-mixed-models <r-sig-mixed-models at r-project.org<mailto:
>>>> r-sig-
>>>> >> >mixed-
>>>> >> >>models at r-project.org>>
>>>> >> >>Subject: [R-sig-ME] lme: count the number extra parameters
>>>> estimated for
>>>> >> >>variance or covariances
>>>> >> >>
>>>> >> >>External email alert: Be wary of links & attachments.
>>>> >> >>
>>>> >> >>Hello All,
>>>> >> >>
>>>> >> >>In addition to fixed and random effects, is there a way to extract
>>>> how
>>>> >> many
>>>> >> >>other parameters (for modeling residual variances or covariances)
>>>> an
>>>> >> >"lme()"
>>>> >> >>object has estimated?
>>>> >> >>
>>>> >> >>Here is a reproducible example:
>>>> >> >>
>>>> >> >>library(nlme)
>>>> >> >>
>>>> >> >>hsb <- read.csv('
>>>> >> >>https://raw.githubusercontent.com/rnorouzian/e/master/hsb.csv')
>>>> >> >>hsb$female <- as.factor(hsb$female)
>>>> >> >>
>>>> >> >>fit <- lme(math ~ female, random = ~ 1|sch.id<http://sch.id>,
>>>> data =
>>>> >> hsb,
>>>> >> >>weights = varIdent(form = ~1 |female))
>>>>
>>>

	[[alternative HTML version deleted]]


From j@de@ @end|ng |rom he@|th@uc@d@edu  Wed Nov  4 21:46:47 2020
From: j@de@ @end|ng |rom he@|th@uc@d@edu (Ades, James)
Date: Wed, 4 Nov 2020 20:46:47 +0000
Subject: [R-sig-ME] Pulling specific parameters from models to prevent
 exhausting memory.
In-Reply-To: <118c97447f5a49b1b17d0604434944bf@hum.leidenuniv.nl>
References: <BY5PR19MB3859498E5E7D1EE81DFE7B38EA000@BY5PR19MB3859.namprd19.prod.outlook.com>,
 <118c97447f5a49b1b17d0604434944bf@hum.leidenuniv.nl>
Message-ID: <BY5PR19MB3859B050F1B4A4E6839431D2EAEF0@BY5PR19MB3859.namprd19.prod.outlook.com>

Hi all,

Just following up on this. I've been reading up on GAMs and the bam function, and I think I have the model correctly specified except for one random effect interaction component, for which I am not certain how to specify within the "mgcv" context.

This is the model I am trying to specify for mgcv in an lme4 framework:

lmer(connectivity ~ roi * timepoint + (timepoint.nu|subjectID) + (timepoint.nu|subjectID:roi), na.action = 'na.exclude', control = lmerControl(optimizer = "nloptwrap", calc.derivs = FALSE), REML = FALSE, data)

This is what I have, however the "subjectID: roi" interaction does not seem to be correctly specified because in the results, the first random effect is the same as the second. The first two terms are parametric (but perhaps will need to receive some kind of spline depending), then the latter two are random effects.

bam(connectivity ~ roi * timepoint + s(timepoint.nu, subjectID, bs = "re") + s(timepoint.nu, subjectID:roi), bs = "re"), data = tot.add.1, method = "fREML")

Thanks much!

James
________________________________
From: Voeten, C.C. <c.c.voeten at hum.leidenuniv.nl>
Sent: Sunday, October 18, 2020 1:16 AM
To: Ades, James <jades at health.ucsd.edu>; r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>
Subject: RE: Pulling specific parameters from models to prevent exhausting memory.

Hi James,

You may have luck using mgcv::bam instead of lme4. It can also fit random-slopes models and is optimized for "big data", in terms of memory usage and computational efficiency. The modeling syntax is slightly different, though; the correct translation of lme4 random effects into mgcv's s(...,bs='re') terms depends on whether timepoint.nu is a covariate or a factor.

HTH,
Cesko

> -----Original Message-----
> From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> On
> Behalf Of Ades, James
> Sent: Sunday, October 18, 2020 2:01 AM
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] Pulling specific parameters from models to prevent
> exhausting memory.
>
> Hi all,
>
> I'm modeling fMRI imaging data using lme4. There are 4 time points and
> roughly 550 subjects with 27,730 regions of interest (these are the variables).
> Since I have access to a super computer, my thought was to create a long
> dataset with a repeated measures of regions of interest per time point and
> then subjects over the 4 time points. I'm using the model below. I gather the
> regions of interest using the super computer because it ends up being
> roughly 70 million something observations. Timepoint is discrete and
> timepoint.nu is just numerical time point.
>
> lmer(connectivity ~ roi * timepoint + (timepoint.nu|subjectID) +
> (timepoint.nu|subjectID:roi), na.action = 'na.exclude', control =
> lmerControl(optimizer = "nloptwrap", calc.derivs = FALSE), REML = FALSE,
> data)
>
> I received back the following error: "cannot allocate vector of size 30206.2
> GbExecution halted"
>
> So I'm wondering how I can only pull the essential parameters I need (group
> means vs individual fixed effects) while modeling, such that the super
> computer can finish the job without exhausting the memory. I say group
> means because I will eventually be adding in covariates.
>
> Also, the super computer rules are that the job must finish within two days.
> I'm not sure that this would, so I'm wondering whether there is any way to
> parallel code in lme4 such that I could make access of multiple cores and
> nodes.
>
> I've included a slice of data here:
> https://drive.google.com/file/d/1mhTj6qZZ2nT35fXUuYG_ThQ-QtWbb-
> 8L/view?usp=sharing
>
> Thanks much,
>
> James
>
>
>
>        [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From c@c@voeten @end|ng |rom hum@|e|denun|v@n|  Thu Nov  5 18:06:57 2020
From: c@c@voeten @end|ng |rom hum@|e|denun|v@n| (Cesko Voeten)
Date: Thu, 5 Nov 2020 18:06:57 +0100
Subject: [R-sig-ME] Pulling specific parameters from models to prevent
 exhausting memory.
In-Reply-To: <BY5PR19MB3859B050F1B4A4E6839431D2EAEF0@BY5PR19MB3859.namprd19.prod.outlook.com>
References: <BY5PR19MB3859498E5E7D1EE81DFE7B38EA000@BY5PR19MB3859.namprd19.prod.outlook.com>
 <118c97447f5a49b1b17d0604434944bf@hum.leidenuniv.nl>
 <BY5PR19MB3859B050F1B4A4E6839431D2EAEF0@BY5PR19MB3859.namprd19.prod.outlook.com>
Message-ID: <a0c49fba-3bc5-eaba-1b59-4c30f9388a10@hum.leidenuniv.nl>

Hi James,

You indeed need to specify the interaction a bit differently: just change the colon to a comma, so that you are describing a random intercept over multiple arguments simultaneously.
If you're uncertain, you can try using buildmer::re2mgcv to automatically convert your lmer formula to an mgcv formula. (But not sure if it is capable of handling interactions between grouping terms -- it's been a while since I've delved into its code.)

One more thing: with your current code, bam will fit the model using REML, while your lmer model uses ML. If you want your bam model to use ML as well, you should pass method='ML'. However, if you don't care, method='fREML' is preferred as it is faster, and only with method='fREML' you can also pass discrete=TRUE, which will result in a significant speedup and much lower memory usage with very large datasets like yours.

Hope this helps,

Cesko

Op 4-11-2020 om 21:46 schreef Ades, James:
> Hi all,
> 
> Just following up on this. I've been reading up on GAMs and the bam function, and I think I have the model correctly specified except for one random effect interaction component, for which I am not certain how to specify within the "mgcv" context.
> 
> This is the model I am trying to specify for mgcv in an lme4 framework:
> 
> lmer(connectivity ~ roi * timepoint + (timepoint.nu|subjectID) + (timepoint.nu|subjectID:roi), na.action = 'na.exclude', control = lmerControl(optimizer = "nloptwrap", calc.derivs = FALSE), REML = FALSE, data)
> 
> This is what I have, however the "subjectID: roi" interaction does not seem to be correctly specified because in the results, the first random effect is the same as the second. The first two terms are parametric (but perhaps will need to receive some kind of spline depending), then the latter two are random effects.
> bam(connectivity ~ roi * timepoint + s(timepoint.nu, subjectID, bs = "re") + s(timepoint.nu, subjectID:roi), bs = "re"), data = tot.add.1, method = "fREML")
> 
> Thanks much!
> 
> James
> ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
> *From:* Voeten, C.C. <c.c.voeten at hum.leidenuniv.nl>
> *Sent:* Sunday, October 18, 2020 1:16 AM
> *To:* Ades, James <jades at health.ucsd.edu>; r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>
> *Subject:* RE: Pulling specific parameters from models to prevent exhausting memory.
> Hi James,
> 
> You may have luck using mgcv::bam instead of lme4. It can also fit random-slopes models and is optimized for "big data", in terms of memory usage and computational efficiency. The modeling syntax is slightly different, though; the correct translation of lme4 random effects into mgcv's s(...,bs='re') terms depends on whether timepoint.nu is a covariate or a factor.
> 
> HTH,
> Cesko
> 
>> -----Original Message-----
>> From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> On
>> Behalf Of Ades, James
>> Sent: Sunday, October 18, 2020 2:01 AM
>> To: r-sig-mixed-models at r-project.org
>> Subject: [R-sig-ME] Pulling specific parameters from models to prevent
>> exhausting memory.
>> 
>> Hi all,
>> 
>> I'm modeling fMRI imaging data using lme4. There are 4 time points and
>> roughly 550 subjects with 27,730 regions of interest (these are the variables).
>> Since I have access to a super computer, my thought was to create a long
>> dataset with a repeated measures of regions of interest per time point and
>> then subjects over the 4 time points. I'm using the model below. I gather the
>> regions of interest using the super computer because it ends up being
>> roughly 70 million something observations. Timepoint is discrete and
>> timepoint.nu is just numerical time point.
>> 
>> lmer(connectivity ~ roi * timepoint + (timepoint.nu|subjectID) +
>> (timepoint.nu|subjectID:roi), na.action = 'na.exclude', control =
>> lmerControl(optimizer = "nloptwrap", calc.derivs = FALSE), REML = FALSE,
>> data)
>> 
>> I received back the following error: "cannot allocate vector of size 30206.2
>> GbExecution halted"
>> 
>> So I'm wondering how I can only pull the essential parameters I need (group
>> means vs individual fixed effects) while modeling, such that the super
>> computer can finish the job without exhausting the memory. I say group
>> means because I will eventually be adding in covariates.
>> 
>> Also, the super computer rules are that the job must finish within two days.
>> I'm not sure that this would, so I'm wondering whether there is any way to
>> parallel code in lme4 such that I could make access of multiple cores and
>> nodes.
>> 
>> I've included a slice of data here:
>> https://drive.google.com/file/d/1mhTj6qZZ2nT35fXUuYG_ThQ-QtWbb- <https://drive.google.com/file/d/1mhTj6qZZ2nT35fXUuYG_ThQ-QtWbb->
>> 8L/view?usp=sharing
>> 
>> Thanks much,
>> 
>> James
>> 
>> 
>> 
>>??????? [[alternative HTML version deleted]]
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>

From c@c@voeten @end|ng |rom hum@|e|denun|v@n|  Thu Nov  5 19:48:19 2020
From: c@c@voeten @end|ng |rom hum@|e|denun|v@n| (Voeten, C.C.)
Date: Thu, 5 Nov 2020 18:48:19 +0000
Subject: [R-sig-ME] Pulling specific parameters from models to prevent
 exhausting memory.
In-Reply-To: <a0c49fba-3bc5-eaba-1b59-4c30f9388a10@hum.leidenuniv.nl>
References: <BY5PR19MB3859498E5E7D1EE81DFE7B38EA000@BY5PR19MB3859.namprd19.prod.outlook.com>
 <118c97447f5a49b1b17d0604434944bf@hum.leidenuniv.nl>
 <BY5PR19MB3859B050F1B4A4E6839431D2EAEF0@BY5PR19MB3859.namprd19.prod.outlook.com>
 <a0c49fba-3bc5-eaba-1b59-4c30f9388a10@hum.leidenuniv.nl>
Message-ID: <a1c1caaf3c204f9db194810e8f60a4ad@hum.leidenuniv.nl>

By the way: it occurs to me that it may be statistically preferable if you use s(subject,bs='re',by=timepoint) and s(subject,roi,bs='re',by=timepoint). You say that timepoint is discrete, I'm presuming that it therefore is a non-ordered factor variable. The by=... formulation with a factor variable produces four separate random intercepts for your four timepoints; this is probably more appropriate than drawing a straight line through the four of them, which is what you are doing now (also in your lmer model).

> -----Original Message-----
> From: Cesko Voeten <c.c.voeten at hum.leidenuniv.nl>
> Sent: Thursday, November 5, 2020 6:07 PM
> To: Ades, James <jades at health.ucsd.edu>; r-sig-mixed-models at r-
> project.org
> Subject: Re: Pulling specific parameters from models to prevent exhausting
> memory.
> 
> Hi James,
> 
> You indeed need to specify the interaction a bit differently: just change the
> colon to a comma, so that you are describing a random intercept over
> multiple arguments simultaneously.
> If you're uncertain, you can try using buildmer::re2mgcv to automatically
> convert your lmer formula to an mgcv formula. (But not sure if it is capable of
> handling interactions between grouping terms -- it's been a while since I've
> delved into its code.)
> 
> One more thing: with your current code, bam will fit the model using REML,
> while your lmer model uses ML. If you want your bam model to use ML as
> well, you should pass method='ML'. However, if you don't care,
> method='fREML' is preferred as it is faster, and only with method='fREML'
> you can also pass discrete=TRUE, which will result in a significant speedup
> and much lower memory usage with very large datasets like yours.
> 
> Hope this helps,
> 
> Cesko
> 
> Op 4-11-2020 om 21:46 schreef Ades, James:
> > Hi all,
> >
> > Just following up on this. I've been reading up on GAMs and the bam
> function, and I think I have the model correctly specified except for one
> random effect interaction component, for which I am not certain how to
> specify within the "mgcv" context.
> >
> > This is the model I am trying to specify for mgcv in an lme4 framework:
> >
> > lmer(connectivity ~ roi * timepoint + (timepoint.nu|subjectID) +
> (timepoint.nu|subjectID:roi), na.action = 'na.exclude', control =
> lmerControl(optimizer = "nloptwrap", calc.derivs = FALSE), REML = FALSE,
> data)
> >
> > This is what I have, however the "subjectID: roi" interaction does not seem
> to be correctly specified because in the results, the first random effect is the
> same as the second. The first two terms are parametric (but perhaps will
> need to receive some kind of spline depending), then the latter two are
> random effects.
> > bam(connectivity ~ roi * timepoint + s(timepoint.nu, subjectID, bs = "re") +
> s(timepoint.nu, subjectID:roi), bs = "re"), data = tot.add.1, method =
> "fREML")
> >
> > Thanks much!
> >
> > James
> > -------------------------------------------------------------------------------------------
> ----------------------------------------------------------------------------------------------
> ----------------------------------------------------------------------------------------------
> ----------------------------------------------------------------------------------------------
> ----------------------------------------------------------------------------------------------
> ----------------------------------------------------------------------------------------------
> ----------------------------------------------------------------------------------------------
> ----------------------------------------------------------------------------------------------
> ----------------------------------------------------------------------------------------------
> ----------------------------------------------------------------------------------------------
> -----------------------------------------------------
> > *From:* Voeten, C.C. <c.c.voeten at hum.leidenuniv.nl>
> > *Sent:* Sunday, October 18, 2020 1:16 AM
> > *To:* Ades, James <jades at health.ucsd.edu>; r-sig-mixed-models at r-
> project.org <r-sig-mixed-models at r-project.org>
> > *Subject:* RE: Pulling specific parameters from models to prevent
> exhausting memory.
> > Hi James,
> >
> > You may have luck using mgcv::bam instead of lme4. It can also fit random-
> slopes models and is optimized for "big data", in terms of memory usage and
> computational efficiency. The modeling syntax is slightly different, though;
> the correct translation of lme4 random effects into mgcv's s(...,bs='re') terms
> depends on whether timepoint.nu is a covariate or a factor.
> >
> > HTH,
> > Cesko
> >
> >> -----Original Message-----
> >> From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org>
> On
> >> Behalf Of Ades, James
> >> Sent: Sunday, October 18, 2020 2:01 AM
> >> To: r-sig-mixed-models at r-project.org
> >> Subject: [R-sig-ME] Pulling specific parameters from models to prevent
> >> exhausting memory.
> >>
> >> Hi all,
> >>
> >> I'm modeling fMRI imaging data using lme4. There are 4 time points and
> >> roughly 550 subjects with 27,730 regions of interest (these are the
> variables).
> >> Since I have access to a super computer, my thought was to create a long
> >> dataset with a repeated measures of regions of interest per time point
> and
> >> then subjects over the 4 time points. I'm using the model below. I gather
> the
> >> regions of interest using the super computer because it ends up being
> >> roughly 70 million something observations. Timepoint is discrete and
> >> timepoint.nu is just numerical time point.
> >>
> >> lmer(connectivity ~ roi * timepoint + (timepoint.nu|subjectID) +
> >> (timepoint.nu|subjectID:roi), na.action = 'na.exclude', control =
> >> lmerControl(optimizer = "nloptwrap", calc.derivs = FALSE), REML = FALSE,
> >> data)
> >>
> >> I received back the following error: "cannot allocate vector of size 30206.2
> >> GbExecution halted"
> >>
> >> So I'm wondering how I can only pull the essential parameters I need
> (group
> >> means vs individual fixed effects) while modeling, such that the super
> >> computer can finish the job without exhausting the memory. I say group
> >> means because I will eventually be adding in covariates.
> >>
> >> Also, the super computer rules are that the job must finish within two
> days.
> >> I'm not sure that this would, so I'm wondering whether there is any way
> to
> >> parallel code in lme4 such that I could make access of multiple cores and
> >> nodes.
> >>
> >> I've included a slice of data here:
> >> https://drive.google.com/file/d/1mhTj6qZZ2nT35fXUuYG_ThQ-QtWbb-
> <https://drive.google.com/file/d/1mhTj6qZZ2nT35fXUuYG_ThQ-QtWbb->
> >> 8L/view?usp=sharing
> >>
> >> Thanks much,
> >>
> >> James
> >>
> >>
> >>
> >>??????? [[alternative HTML version deleted]]
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>

From @|m@h@rme| @end|ng |rom gm@||@com  Fri Nov  6 03:44:52 2020
From: @|m@h@rme| @end|ng |rom gm@||@com (Simon Harmel)
Date: Thu, 5 Nov 2020 20:44:52 -0600
Subject: [R-sig-ME] nlme: The meaning of residual variance when using a
 variance structure
Message-ID: <CACgv6yWMFsnPGKbX+uCBmOG_12chXMasu2zpMfaVCtj-BRgJRg@mail.gmail.com>

Hello All,

My understanding is that a varFixed() variance structure in lme() call,
models the residual variance proportional to a numeric variance covariate
(e.g., `x`) such that there would be a linear relation between the two.

But what is the exact meaning of sigma(fitted_model)^2 alone in a fitted
model that has used  varFixed(~x)  in it?

Below is a fully reproducible example.

library(nlme)

dat <- read.csv('
https://raw.githubusercontent.com/rnorouzian/e/master/var.csv')
dat$month <- factor(dat$month)

m2 <- lme(y ~ x * month, random = ~1|id, weights = varFixed(~x), data = dat)

varFix <- function(x) sigma(m2)^2*x  ## What is the meaning of  "sigma(m2)^2"
here?

with(dat, curve(varFix(x), min(x), max(x), lwd = 2))

	[[alternative HTML version deleted]]


From ph||||p@@|d@y @end|ng |rom mp|@n|  Fri Nov  6 13:24:22 2020
From: ph||||p@@|d@y @end|ng |rom mp|@n| (Phillip Alday)
Date: Fri, 6 Nov 2020 13:24:22 +0100
Subject: [R-sig-ME] nlme: The meaning of residual variance when using a
 variance structure
In-Reply-To: <CACgv6yWMFsnPGKbX+uCBmOG_12chXMasu2zpMfaVCtj-BRgJRg@mail.gmail.com>
References: <CACgv6yWMFsnPGKbX+uCBmOG_12chXMasu2zpMfaVCtj-BRgJRg@mail.gmail.com>
Message-ID: <3f909169-2648-b4f4-9fe6-93516eecbbaf@mpi.nl>

Looking at varFix alone, it looks like the variance is proportional to
the mean.

Looking at the documentation for varFixed (e.g.
https://www.rdocumentation.org/packages/nlme/versions/3.1-150/topics/varFixed),
varFixed sets the variance as being the mean. Looking at the
documentation for lme
(https://www.rdocumentation.org/packages/nlme/versions/3.1-150/topics/lme),
the weights describe the "within-group heteroskedacity structure", which
here basically means the observation-level variation after the grouping
has been taken into account.

So then sigma(model)^2 is the constant of proportionality for going from
a particular observation to the (residual) variance at that observation.
Note that only 'part' of an observation is relevant in this example: x
matters but not month.

Also, I'm guessing that you got this example from somewhere (because it
uses things beyond your own understanding), so it would be usual
practice to give credit to the individual(s) who came up with it.

Phillip

On 6/11/20 3:44 am, Simon Harmel wrote:
> Hello All,
> 
> My understanding is that a varFixed() variance structure in lme() call,
> models the residual variance proportional to a numeric variance covariate
> (e.g., `x`) such that there would be a linear relation between the two.
> 
> But what is the exact meaning of sigma(fitted_model)^2 alone in a fitted
> model that has used  varFixed(~x)  in it?
> 
> Below is a fully reproducible example.
> 
> library(nlme)
> 
> dat <- read.csv('
> https://raw.githubusercontent.com/rnorouzian/e/master/var.csv')
> dat$month <- factor(dat$month)
> 
> m2 <- lme(y ~ x * month, random = ~1|id, weights = varFixed(~x), data = dat)
> 
> varFix <- function(x) sigma(m2)^2*x  ## What is the meaning of  "sigma(m2)^2"
> here?
> 
> with(dat, curve(varFix(x), min(x), max(x), lwd = 2))
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From @|m@h@rme| @end|ng |rom gm@||@com  Fri Nov  6 18:31:50 2020
From: @|m@h@rme| @end|ng |rom gm@||@com (Simon Harmel)
Date: Fri, 6 Nov 2020 11:31:50 -0600
Subject: [R-sig-ME] nlme: The meaning of residual variance when using a
 variance structure
In-Reply-To: <3f909169-2648-b4f4-9fe6-93516eecbbaf@mpi.nl>
References: <CACgv6yWMFsnPGKbX+uCBmOG_12chXMasu2zpMfaVCtj-BRgJRg@mail.gmail.com>
 <3f909169-2648-b4f4-9fe6-93516eecbbaf@mpi.nl>
Message-ID: <CACgv6yVzWL2G6V8s5_srjkTAf2jrxQAnjeianhSr_vRJT_2yUg@mail.gmail.com>

Thanks. You mentioned "varFixed() sets the variance as being the mean",
mean of what?

On the other hand, you mentioned "sigma(model)^2 [residual variance] is the
constant of proportionality for going from a particular observation to the
(residual) variance at that observation".

How does your definition for  "sigma(model)^2"  change for the following
variance structures?

(1) varPower(form= ~x)   ;   (2) varExp(form= ~x)   ;   (3) varConstPower(form=
~x)

Thank you very much,
Simon



On Fri, Nov 6, 2020 at 6:24 AM Phillip Alday <phillip.alday at mpi.nl> wrote:

> Looking at varFix alone, it looks like the variance is proportional to
> the mean.
>
> Looking at the documentation for varFixed (e.g.
>
> https://www.rdocumentation.org/packages/nlme/versions/3.1-150/topics/varFixed
> ),
> varFixed sets the variance as being the mean. Looking at the
> documentation for lme
> (https://www.rdocumentation.org/packages/nlme/versions/3.1-150/topics/lme
> ),
> the weights describe the "within-group heteroskedacity structure", which
> here basically means the observation-level variation after the grouping
> has been taken into account.
>
> So then sigma(model)^2 is the constant of proportionality for going from
> a particular observation to the (residual) variance at that observation.
> Note that only 'part' of an observation is relevant in this example: x
> matters but not month.
>
> Also, I'm guessing that you got this example from somewhere (because it
> uses things beyond your own understanding), so it would be usual
> practice to give credit to the individual(s) who came up with it.
>
> Phillip
>
> On 6/11/20 3:44 am, Simon Harmel wrote:
> > Hello All,
> >
> > My understanding is that a varFixed() variance structure in lme() call,
> > models the residual variance proportional to a numeric variance covariate
> > (e.g., `x`) such that there would be a linear relation between the two.
> >
> > But what is the exact meaning of sigma(fitted_model)^2 alone in a fitted
> > model that has used  varFixed(~x)  in it?
> >
> > Below is a fully reproducible example.
> >
> > library(nlme)
> >
> > dat <- read.csv('
> > https://raw.githubusercontent.com/rnorouzian/e/master/var.csv')
> > dat$month <- factor(dat$month)
> >
> > m2 <- lme(y ~ x * month, random = ~1|id, weights = varFixed(~x), data =
> dat)
> >
> > varFix <- function(x) sigma(m2)^2*x  ## What is the meaning of
> "sigma(m2)^2"
> > here?
> >
> > with(dat, curve(varFix(x), min(x), max(x), lwd = 2))
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>

	[[alternative HTML version deleted]]


From ph||||p@@|d@y @end|ng |rom mp|@n|  Fri Nov  6 19:37:24 2020
From: ph||||p@@|d@y @end|ng |rom mp|@n| (Phillip Alday)
Date: Fri, 6 Nov 2020 19:37:24 +0100
Subject: [R-sig-ME] nlme: The meaning of residual variance when using a
 variance structure
In-Reply-To: <CACgv6yVzWL2G6V8s5_srjkTAf2jrxQAnjeianhSr_vRJT_2yUg@mail.gmail.com>
References: <CACgv6yWMFsnPGKbX+uCBmOG_12chXMasu2zpMfaVCtj-BRgJRg@mail.gmail.com>
 <3f909169-2648-b4f4-9fe6-93516eecbbaf@mpi.nl>
 <CACgv6yVzWL2G6V8s5_srjkTAf2jrxQAnjeianhSr_vRJT_2yUg@mail.gmail.com>
Message-ID: <8e820988-2494-7590-a32b-220ae1b47c40@mpi.nl>



On 6/11/20 6:31 pm, Simon Harmel wrote:
> Thanks. You mentioned "varFixed() sets the variance as being the mean",
> mean of what??
> 

It's proportional to x, as it says the documentation I linked to.

Recall that for linear regression, we're solving for the conditional
mean. For example, we can write a simple model in terms of the
distribution of the error

y_i = beta_0 + beta_1 * x_i + error_i

error_i ~ N(0, sigma)

or we can write in terms of the conditional distribution of the observed
values (note that the linear predictor mu gives the mean of the observed
values conditional on the predictors)

mu_i = beta_0  beta_0 + beta_1 * x_i

y_i ~ N(mu_i, sigma)

(see e.g.
http://sumsar.net/blog/2013/10/how-do-you-write-your-model-definitions/)

For those other variance structures: consult the documentation. What do
you think they mean? If you have questions about what particular
statements in the documentation mean, you can ask those, but I'm
hesitant to go look up the documentation for you.

Phillip

> On the other hand, you mentioned "sigma(model)^2 [residual variance] is
> the constant of proportionality for going from a particular observation
> to the (residual) variance at that observation".?
> 
> How does your definition?for? "sigma(model)^2"? change for the following
> variance structures?
> 
> (1)?varPower(form= ~x)? ?;???(2)?varExp(form= ~x)?
> ?;???(3)?varConstPower(form= ~x)?
> 
> Thank you very?much,
> Simon
> 
> 
> 
> On Fri, Nov 6, 2020 at 6:24 AM Phillip Alday <phillip.alday at mpi.nl
> <mailto:phillip.alday at mpi.nl>> wrote:
> 
>     Looking at varFix alone, it looks like the variance is proportional to
>     the mean.
> 
>     Looking at the documentation for varFixed (e.g.
>     https://www.rdocumentation.org/packages/nlme/versions/3.1-150/topics/varFixed),
>     varFixed sets the variance as being the mean. Looking at the
>     documentation for lme
>     (https://www.rdocumentation.org/packages/nlme/versions/3.1-150/topics/lme),
>     the weights describe the "within-group heteroskedacity structure", which
>     here basically means the observation-level variation after the grouping
>     has been taken into account.
> 
>     So then sigma(model)^2 is the constant of proportionality for going from
>     a particular observation to the (residual) variance at that observation.
>     Note that only 'part' of an observation is relevant in this example: x
>     matters but not month.
> 
>     Also, I'm guessing that you got this example from somewhere (because it
>     uses things beyond your own understanding), so it would be usual
>     practice to give credit to the individual(s) who came up with it.
> 
>     Phillip
> 
>     On 6/11/20 3:44 am, Simon Harmel wrote:
>     > Hello All,
>     >
>     > My understanding is that a varFixed() variance structure in lme()
>     call,
>     > models the residual variance proportional to a numeric variance
>     covariate
>     > (e.g., `x`) such that there would be a linear relation between the
>     two.
>     >
>     > But what is the exact meaning of sigma(fitted_model)^2 alone in a
>     fitted
>     > model that has used? varFixed(~x)? in it?
>     >
>     > Below is a fully reproducible example.
>     >
>     > library(nlme)
>     >
>     > dat <- read.csv('
>     > https://raw.githubusercontent.com/rnorouzian/e/master/var.csv')
>     > dat$month <- factor(dat$month)
>     >
>     > m2 <- lme(y ~ x * month, random = ~1|id, weights = varFixed(~x),
>     data = dat)
>     >
>     > varFix <- function(x) sigma(m2)^2*x? ## What is the meaning of?
>     "sigma(m2)^2"
>     > here?
>     >
>     > with(dat, curve(varFix(x), min(x), max(x), lwd = 2))
>     >
>     >? ? ? ?[[alternative HTML version deleted]]
>     >
>     > _______________________________________________
>     > R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>     > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     >
>


From r_1470 @end|ng |rom y@hoo@co@uk  Mon Nov  9 14:30:54 2020
From: r_1470 @end|ng |rom y@hoo@co@uk (r_1470)
Date: Mon, 9 Nov 2020 13:30:54 +0000 (UTC)
Subject: [R-sig-ME] Using a custom random effects design matrix in MCMCglmm
References: <541305795.6389505.1604928654527.ref@mail.yahoo.com>
Message-ID: <541305795.6389505.1604928654527@mail.yahoo.com>

Hi,
 Does anyone know if it's possible to use a custom random effects design matrix with MCMCglmm, e.g. by replacing the model$Z object with a custom object in the same format before passing it to the MCMC??
To give more background, I have a multi-membership model with an interaction for each element, but the 'mm' argument in MCMCglmm doesn't allow interactions. There's a partial solution using the 'mult.memb' function, but I also need to associate the multi-membership model with the inverse relationship matrix using 'ginverse', and I haven't found a solution with mult.memb that allows this.
I've worked out what the correct design matrix should be, but just can't figure out how to use it. Making a custom 'MCMCglmm2' function with a new argument for using a custom Z object didn't work, presumably because it failed to connect to the C code for the MCMC. If that part worked, I think it would run.

Best wishes,
Richard.
	[[alternative HTML version deleted]]


From @r|v@t@ch@r| @end|ng |rom gm@||@com  Mon Nov  9 16:44:03 2020
From: @r|v@t@ch@r| @end|ng |rom gm@||@com (Srivats Chari)
Date: Mon, 9 Nov 2020 15:44:03 +0000
Subject: [R-sig-ME] Covariance values for Random Effects in MCMCGlmm?
Message-ID: <CAFnkSc=7wVQxHB1TWTw-TCVhaT9QOdXxNcKt7X_6ptmneKJQPg@mail.gmail.com>

Greetings,

I have my MCMCglmm output and I was successful in extracting the random
effect using the broom.mixed package.

```
library(broom.mixed)
sample1<- tidy(mcmc_6h_v1_1run[[1]], effects = "ran_vals",conf.int = TRUE)
> head(sample1)
# A tibble: 6 x 8
  effect   group level term       estimate std.error conf.low conf.high
  <chr>    <chr> <chr> <chr>         <dbl>     <dbl>    <dbl>     <dbl>
1 ran_vals ID    10    traitspeed  -0.283      0.235   -1.09      0.570
2 ran_vals ID    1005  traitspeed  -0.0876     0.217   -0.742     0.565
3 ran_vals ID    13    traitspeed  -0.231      0.246   -1.10      0.553
4 ran_vals ID    132   traitspeed  -0.418      0.274   -1.36      0.361
5 ran_vals ID    142   traitspeed  -0.221      0.226   -0.977     0.560
6 ran_vals ID    144   traitspeed  -0.250      0.218   -0.964     0.678

```

Further I was also able to extract the covariance of the traits
```
sample2<- tidy(mcmc_6h_v1_1run[[1]], effects = "ran_pars", conf.int = T,
conf.method = "HPDinterval")

> head(sample2)
# A tibble: 6 x 8
  effect   group level term                                  estimate
std.error conf.low conf.high
  <chr>    <chr> <chr> <chr>                                    <dbl>
 <dbl>    <dbl>     <dbl>
1 ran_pars ID    NA    var__traitspeed                         0.110
 0.0256   0.0629    0.160
2 ran_pars ID    NA    cov__traitmean_act.traitspeed           0.0385
0.0326  -0.0219    0.104
3 ran_pars ID    NA    cov__traithr50.traitspeed               0.0359
0.0235  -0.0131    0.0793
4 ran_pars ID    NA    cov__traitani_excursion.traitspeed      0.0125
0.0255  -0.0378    0.0627
5 ran_pars ID    NA    cov__traithr_ratio.traitspeed          -0.0161
0.0181  -0.0488    0.0200
6 ran_pars ID    NA    cov__traitpopen_diurnality.traitspeed  -0.0769
0.0241  -0.125    -0.0331

```

Now what I am trying is to get is the covariance of traits for the random
effect. What I mean is I have 196 individuals and I am trying to get 1
value with 95% credible interval for each individual for a trait covariance
like - cov__traithr_ratio.traitspeed

Is it possible to do this with ```broom.mixed``` ? Or is there any other
way of doing this?

Any help is much appreciated. :)

Thank you in advance.!

Regards,
Srivats.

	[[alternative HTML version deleted]]


From @bdu||@h|cen @end|ng |rom gm@||@com  Mon Nov  9 18:40:13 2020
From: @bdu||@h|cen @end|ng |rom gm@||@com (=?UTF-8?Q?Abdullah_i=C3=A7en?=)
Date: Mon, 9 Nov 2020 20:40:13 +0300
Subject: [R-sig-ME] nlmer function Error in devfun(rho$pp$theta) error
Message-ID: <CABXDCj9MEzX6UVCYKtEJvU-f_NZw9JmftEOpsD6ugrWr3UxHWQ@mail.gmail.com>

Hi all,

Hope you are well and healthy, everything is fine on these bad days.

I want to model my data using nlmer function in lme4 package but i got the
following error.



*Error in devfun(rho$pp$theta) :   step factor reduced below 0.001 without
reducing pwrss*

This is my nonlinear function:













































*NLSite <- function(PSAr, Vs30, h800, f5, b1, b2, b3, c){    #Linear term
.exprN1 <- ifelse(Vs30>1000, 1000/760, Vs30/760)  .exprN2 <- log(.exprN1)
.valueN <- b1*.exprN2  # Depth-to-rock term (in log)     # in SD18 they are
estimated from CY08 equation for Z1  h800[h800<1]<-1  .exprZ1 <-
ifelse(Vs30>=760, 1, h800)  .exprZ2 <- log(.exprZ1)  .valueZ <- b2*.exprZ2
  #Nonlinear term  .f5 <- f5  .exprNL1 <- ifelse(Vs30>760, 760-360,
Vs30-360)  .exprNL2 <- .f5*.exprNL1  .exprNL3 <- exp(.exprNL2)  .exprNL4 <-
.f5*400  .exprNL5 <- exp(.exprNL4)  .exprNL6 <- .exprNL3 - .exprNL5
.exprNL7 <- PSAr/c   .exprNL8 <- 1+.exprNL7 #log(1+PSAr/c)  .exprNL9 <-
log(.exprNL8)  .valueNL <- b3*.exprNL9*.exprNL6    .value <- .valueN +
.valueZ + .valueNL    .grad <- array(0, c(length(.value), 4L), list(NULL,
c("b1", "b2", "b3","c")))      ## e1 ##  ## b1, b2 ,b3 ##  .grad[, "b1"] <-
.exprN2  .grad[, "b2"] <- .exprZ2  .grad[, "b3"] <- .exprNL9*.exprNL6
.grad[, "c"] <- .exprNL6*((1/(.exprNL8))*(-.exprNL7/c))      attr(.value,
"gradient") <- .grad  .value}*

And i use the following code for running the nlmer function (by the way i
don't use intercept in my model and just writing 0|EQID is not accepted so
i wrote random effects  (b1 + b2 + b3 + c + 0|EQID) hope that is true)


* nlmer_site <- nlmer( log(PSAm) ~ NLSite(PSAr, Vs30, h800, f5, b1, b2, b3,
c)  ~ 0+ b1 + b2 + b3 + c + (b1 + b2 + b3 + c + 0|EQID) + (b1 + b2 + b3 + c
+ 0|STID),                       data = data.frame(data),
 nlmerControl(optimizer = "Nelder_Mead"), start =  c( b1 = 0.2, b2 = 0.5,
b3 =-1,  c = 0.1),  nAGQ = 1L)*

when i change my nonlinear term c with constant value and run it (
NLSite(PSAr, Vs30, h800, f5, b1, b2, b3) like this) works without error. I
also compared it with lmer (without nonlinear parameter, taking c as
constant) both gave almost (correct till 10^-6) the same result.

To explain my data. PSAr, Vs30, h800, f5 are my input values. PSAr is
acceleration values, Vs is velocity, h800 is depth and f5 is a parameter i
used. Using these inputs i want to predict nonlinear site amplification b1
b2 and b3 are linear parameters c is nonlinear which is log((PSAr+c)/c)
taking c as constant doesn't give any error so there is no problem with my
data. I used starting values from the previous studies which i expected to
be close to my values but i also didn't work.  In the previous studies for
deriving the f5 and b1 b2 b3 parameters it's assumed to be constant and
taken as 0.1 but also there are c values derived using this nonlinear
function.

Also i want to say that the following code below works well with my data
without any error. so problem is about my nonlinear function.
























































*GMPE <- function(M,R,Mref,Mh,Rref,e1,b1,b2,b3,c1,c2,c3,h) {    ## FM ##
.Mh <- Mh   .exprM1 <- M - .Mh  .exprM2 <- .exprM1 ^ 2  .exprM3 <- b1 *
.exprM1 + b2 * .exprM2  .exprM4 <- b3 * .exprM1  .valueFM <- ifelse(M<=.Mh,
.exprM3, .exprM4)    ##FD ##  .Mref <- Mref  .Rref <- Rref  .exprD1 <- M -
.Mref   .exprD2 <- c1 + c2 * .exprD1  # [c1 + c2(M-Mref)]  .exprD3 <- R^2 +
h^2  # [Rjb^2 + h^2]  .exprD4 <- sqrt(.exprD3)  # [sqrt[Rjb^2 + h^2]]
.exprD5 <- .exprD4/.Rref      # [sqrt[Rjb^2 + h^2]/Rref]  .exprD6 <-
log(.exprD5)   # LN[sqrt[Rjb^2 + h^2]/Rref]  .exprD7 <- .exprD4 - .Rref  #
[sqrt[Rjb^2 + h^2] - Rref]  .valueFD <- .exprD2 * .exprD6 + c3 * .exprD7
## Value ##  .value <- e1 + .valueFD + .valueFM   ## Gradient ##  .grad <-
array(0, c(length(.value), 8L), list(NULL, c("e1","b1", "b2", "b3","c1",
"c2", "c3", "h")))      ## e1 ##  .grad[, "e1"] <- 1.0      ## b1, b2 ,b3
##  .grad[, "b1"] <- ifelse(M<=.Mh,.exprM1,0)  .grad[, "b2"] <-
ifelse(M<=.Mh,.exprM2,0)  .grad[, "b3"] <- ifelse(M<=.Mh,0,.exprM1)    ##
c1, c2 ,c3, h ##  .grad[, "c1"] <- .exprD6  .grad[, "c2"] <- .exprD1 *
.exprD6  .grad[, "c3"] <- .exprD7  .grad[, "h"] <- .exprD2 * (h/.exprD3) +
c3 * (h /.exprD4)    attr(.value, "gradient") <- .grad  .value  }data$Mref
<- 4data$Mh <- 5data$Rref <- 100nlmer_gmpe <- nlmer( log(PSA) ~ GMPE(Mw,
RJB, Mref,Mh,Rref,e1,b1,b2,b3,c1,c2,c3,h)  ~ e1 + b1 + b2 + b3 + c1 + c2 +
c3 + h + (e1 + 0|EQID) + (e1+0|STID),                     data =
data.frame(data), start =   c(e1 = 3, b1 = 1, b2 = 1, b3 =1,  c1 = 1, c2 =
1, c3 = 1, h = 5),  nAGQ = 1L)fixef(nlmer_gmpe)Have nice days,*
Abdullah

	[[alternative HTML version deleted]]


From j@n@ve||m@ky @end|ng |rom y@hoo@de  Mon Nov  9 19:11:40 2020
From: j@n@ve||m@ky @end|ng |rom y@hoo@de (Jan Velimsky)
Date: Mon, 9 Nov 2020 19:11:40 +0100
Subject: [R-sig-ME] Interpreting Estimates from GLMM following a
 beta-distribution (glmmTMB)
References: <3094cd29-bfb3-b3da-6faa-68cc2cad210a.ref@yahoo.de>
Message-ID: <3094cd29-bfb3-b3da-6faa-68cc2cad210a@yahoo.de>

Dear R project mixed models users,

I am struggling to interpret the estimates from a GLMM following a 
beta-distribution with a logit link. There is not much literature 
regarding the interpretation of this special case.

We have been estimating a GLMM model following a beta-distribution (with 
a logit link) with the glmmTMB-package. The model consists of factors 
influencing referendum turnout in German municipalities. The primary 
units of investigation are city districts nested in referendums nested 
in cities. The dependent variable (0-100) has been transformed to the 
unit interval 0-1.

Here an example model:

 ?glmmTMB (ref_turnout ~ unemployment + contestation+ (1| 
city/referendum), family=list(family="beta", link ='logit'), data = ml)


Results example model:

Estimate????? Std. Error??? zvalue???? Pr(>|z|)

(Intercept) -0.583???????????? 0.131????? -4.455???? 8.4e-06***

unemployment rate (in%) -0.067????????????? 0.002????? -30.397??? < 
2e-16 ***

contestation 0.008????????????? 0.003??????? 2.398???? 0.0165 *

All explanatory variables are grand mean centered.

Taking into account the link function and the parameterization of beta 
regression, my interpretation for the effect of unemployment would be:? 
One percent increase from the average unemployment-rate in districts of 
German municipalities (grand-mean) is associated with a? 0.067 unit 
decrease from the overall mean of the participation rate in referendums 
(log odds)

1) Is this interpretation correct?

2) Are there more intuitive options for interpretation (e.g. with odd 
ratios or marginal effects )

Thanks a lot for your help!

Jan

-- 
Jan Velimsky, M.A.
Wissenschaftlicher Mitarbeiter
Lehrstuhl f?r Politische Systeme und Europ?ische Integration
Geschwister-Scholl-Institut f?r Politikwissenschaft
Ludwig-Maximilians-Universit?t M?nchen

D-80538 M?nchen
Oettingenstrasse 67
Tel. 0176 73292389


From bbo|ker @end|ng |rom gm@||@com  Mon Nov  9 19:25:42 2020
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Mon, 9 Nov 2020 13:25:42 -0500
Subject: [R-sig-ME] Interpreting Estimates from GLMM following a
 beta-distribution (glmmTMB)
In-Reply-To: <3094cd29-bfb3-b3da-6faa-68cc2cad210a@yahoo.de>
References: <3094cd29-bfb3-b3da-6faa-68cc2cad210a.ref@yahoo.de>
 <3094cd29-bfb3-b3da-6faa-68cc2cad210a@yahoo.de>
Message-ID: <CABghstSNmrAbenUkXbC2Y6mYS-QOhKG6L1qrD4TAPigoMX1vtg@mail.gmail.com>

On Mon, Nov 9, 2020 at 1:12 PM Jan Velimsky via R-sig-mixed-models
<r-sig-mixed-models at r-project.org> wrote:
>
> Dear R project mixed models users,
>
> I am struggling to interpret the estimates from a GLMM following a
> beta-distribution with a logit link. There is not much literature
> regarding the interpretation of this special case.
>
> We have been estimating a GLMM model following a beta-distribution (with
> a logit link) with the glmmTMB-package. The model consists of factors
> influencing referendum turnout in German municipalities. The primary
> units of investigation are city districts nested in referendums nested
> in cities. The dependent variable (0-100) has been transformed to the
> unit interval 0-1.

  Is there a reason you can't get information on the voter base for
each municipality? That would make the model into a more standard
binomial model, which would have two advantages: (1) municipalities of
different sizes would be appropriately weighted; (2) it would be a
more familiar model type (less convincing of reviewers, wider range of
available software, etc.)

>
> Here an example model:
>
>   glmmTMB (ref_turnout ~ unemployment + contestation+ (1|
> city/referendum), family=list(family="beta", link ='logit'), data = ml)
>
>
> Results example model:
>
> Estimate      Std. Error    zvalue     Pr(>|z|)
>
> (Intercept) -0.583             0.131      -4.455     8.4e-06***
>
> unemployment rate (in%) -0.067              0.002      -30.397    <
> 2e-16 ***
>
> contestation 0.008              0.003        2.398     0.0165 *
>
> All explanatory variables are grand mean centered.
>
> Taking into account the link function and the parameterization of beta
> regression, my interpretation for the effect of unemployment would be:
> One percent increase from the average unemployment-rate in districts of
> German municipalities (grand-mean) is associated with a  0.067 unit
> decrease from the overall mean of the participation rate in referendums
> (log odds)
>
> 1) Is this interpretation correct?

  Yes

> 2) Are there more intuitive options for interpretation (e.g. with odd
> ratios or marginal effects )

  You could exponentiate the coefficient and conclude that there was a
proportional change of 0.064 (1-exp(-0.067)), or 6.4%, in the *odds*
of turnout per 1% increase in the unemployment rate (the numbers
(0.067, 0.064) are similar because the coefficient is <<1).

  Because your baseline rate is intermediate (exp(-0.583) is 0.56, in
the range 0.3-0.7 where the following rule of thumb applies) you could
say there is *approximately* a decrease of beta/4 = 1.7 percentage
points, in turnout per percent increase in unemployment (this is an
*absolute*, linear change rather than a proportional change). (See
e.g. Gelman and Hill's book.)

   You should be a little careful about the effect of transformation
and variation: see the last ("Bias adjustment") section of the
"transformations" vignette from the emmeans package.



> Thanks a lot for your help!
>
> Jan
>
> --
> Jan Velimsky, M.A.
> Wissenschaftlicher Mitarbeiter
> Lehrstuhl f?r Politische Systeme und Europ?ische Integration
> Geschwister-Scholl-Institut f?r Politikwissenschaft
> Ludwig-Maximilians-Universit?t M?nchen
>
> D-80538 M?nchen
> Oettingenstrasse 67
> Tel. 0176 73292389
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From @chr@@uge @end|ng |rom gm@||@com  Mon Nov  9 23:54:52 2020
From: @chr@@uge @end|ng |rom gm@||@com (Anne-Christine Auge)
Date: Mon, 9 Nov 2020 17:54:52 -0500
Subject: [R-sig-ME] nlme issue with multiple random effects and
 autoregression
Message-ID: <CANb_3M_7bXgp5Ate2KzT2xSP68O9BL4G98wi7j0RCaTmmeC17A@mail.gmail.com>

I am trying to analyse the effect of temperature range (T.range) on turtle
animal activity (odba_mean).
I have multiple daily measurements for multiple individuals (name_ID) from
two species. I have data for 3 years (no turtle repeats over the years). A
datafile is attached.
Activity (mean_ODBA) measures appear to be temporally autocorrelated, so
this needs to be accounted for).

I am fairly new to mixed models, so I am very unsure about my code. I am
using the nlme package because this seems to one that can more easily
account for autoregression.
This is the code I have so far:

Mlme <- lme(odba_mean ~ T.range + species + T.range*species,
             random = ~ T.range|species/name_ID,
             data = df3,
             correlation = corAR1(form = ~date|species/name_ID))


I have a couple issues that I cannot seem to solve:
1. I get the warning: "Warning message: In pt(-abs(tVal), fDF) : NaNs
produced" which appears to be due to the nesting structure, but I just do
not know how to fix it.
2. I cannot figure out how to include year as another random effect. I read
that it is very difficult in nlme to include multiple random effects that
are not nested. I suppose technically name_ID is nested in years, but it is
already nested in species, and species is not nested in years (but
crossed). How do I incorporate this?

Thank you.
Regards,
Anni

-- 
*_________________________________________*


*Anne-Christine Auge*

From @reedt@8 @end|ng |rom gm@||@com  Tue Nov 10 04:45:30 2020
From: @reedt@8 @end|ng |rom gm@||@com (sree datta)
Date: Mon, 9 Nov 2020 22:45:30 -0500
Subject: [R-sig-ME] nlme issue with multiple random effects and
 autoregression
In-Reply-To: <CANb_3M_7bXgp5Ate2KzT2xSP68O9BL4G98wi7j0RCaTmmeC17A@mail.gmail.com>
References: <CANb_3M_7bXgp5Ate2KzT2xSP68O9BL4G98wi7j0RCaTmmeC17A@mail.gmail.com>
Message-ID: <CAHftDbgTMjZaDZdfA6ccb2SzjFcwGZMsb7ydsZjtx5LVsnqdVQ@mail.gmail.com>

I do not see the data file. Please attach it if possible. In addition, how
is the "species" variable set-up? Is it coded as a numeric variable or as a
factor? Since you only have two species, if species is not set up as a
factor variable and data within species is in a string/character format,
that can generate NaNs.
What version of R are you using? Starting with R V4.0,
StringsAsFactors=FALSE is the default setting.

Please send the results of the following commands:

str(data) (where data is the name of your data-frame)

head(data, n = 10)

class(data$species)

Sree

On Mon, Nov 9, 2020 at 5:55 PM Anne-Christine Auge <achr.auge at gmail.com>
wrote:

> I am trying to analyse the effect of temperature range (T.range) on turtle
> animal activity (odba_mean).
> I have multiple daily measurements for multiple individuals (name_ID) from
> two species. I have data for 3 years (no turtle repeats over the years). A
> datafile is attached.
> Activity (mean_ODBA) measures appear to be temporally autocorrelated, so
> this needs to be accounted for).
>
> I am fairly new to mixed models, so I am very unsure about my code. I am
> using the nlme package because this seems to one that can more easily
> account for autoregression.
> This is the code I have so far:
>
> Mlme <- lme(odba_mean ~ T.range + species + T.range*species,
>              random = ~ T.range|species/name_ID,
>              data = df3,
>              correlation = corAR1(form = ~date|species/name_ID))
>
>
> I have a couple issues that I cannot seem to solve:
> 1. I get the warning: "Warning message: In pt(-abs(tVal), fDF) : NaNs
> produced" which appears to be due to the nesting structure, but I just do
> not know how to fix it.
> 2. I cannot figure out how to include year as another random effect. I read
> that it is very difficult in nlme to include multiple random effects that
> are not nested. I suppose technically name_ID is nested in years, but it is
> already nested in species, and species is not nested in years (but
> crossed). How do I incorporate this?
>
> Thank you.
> Regards,
> Anni
>
> --
> *_________________________________________*
>
>
> *Anne-Christine Auge*
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From @|m@h@rme| @end|ng |rom gm@||@com  Tue Nov 10 07:17:29 2020
From: @|m@h@rme| @end|ng |rom gm@||@com (Simon Harmel)
Date: Tue, 10 Nov 2020 00:17:29 -0600
Subject: [R-sig-ME] Using broom.mixed library with lme4
Message-ID: <CACgv6yW=uvWH5rP+SwsfD45cwTY3WEy5+6132EZPWy0vX5N8QQ@mail.gmail.com>

Dear All,

Belwo, I've used library `broom.mixed` and imputed some data with library
`mice` to then fit a "random-intercept" `lmer()` model.

BUT I wonder why after I `pool()` my analyses, there is an extra "ubar"
(random-effect) for slope (`sex`) which is not even in the model?!

library(mice)
library(lme4)
library(broom.mixed)

imp <- mice(popmis, m = 5) # `popmis` is a dataset from `mice`

fit <- with(data = imp, exp = lme4::lmer(popular ~ sex + (1|school)))

pool(fit)

### `ubar` is the random effect for intercept (0.007524509) BUT WHY we see
a ubar ALSO for `sex` (0.001177781)?

Class: mipo    m = 5
         term m  estimate        ubar            b           t dfcom
 df
1 (Intercept) 5 4.9007789 0.007524509 0.0004845564 0.008105977  1996
547.44383
2         sex 5 0.8617941 0.001177781 0.0015867795 0.003081916  1996
 10.33653
        riv     lambda       fmi
1 0.0772765 0.07173321 0.0751060
2 1.6167147 0.61784141 0.6751515

	[[alternative HTML version deleted]]


From th|erry@onke||nx @end|ng |rom |nbo@be  Tue Nov 10 08:28:13 2020
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Tue, 10 Nov 2020 08:28:13 +0100
Subject: [R-sig-ME] nlme issue with multiple random effects and
 autoregression
In-Reply-To: <CAHftDbgTMjZaDZdfA6ccb2SzjFcwGZMsb7ydsZjtx5LVsnqdVQ@mail.gmail.com>
References: <CANb_3M_7bXgp5Ate2KzT2xSP68O9BL4G98wi7j0RCaTmmeC17A@mail.gmail.com>
 <CAHftDbgTMjZaDZdfA6ccb2SzjFcwGZMsb7ydsZjtx5LVsnqdVQ@mail.gmail.com>
Message-ID: <CAJuCY5yxBaqvm=tTpRPckgFxJuS2j4i87oBR2FxvEumqzni75w@mail.gmail.com>

Dear Anne-Christine,

You have too few levels for species and years to handle them as random
effects. You'll need to handle them as fixed effects. Leaving only name_id
as random effect.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op di 10 nov. 2020 om 04:46 schreef sree datta <sreedta8 at gmail.com>:

> I do not see the data file. Please attach it if possible. In addition, how
> is the "species" variable set-up? Is it coded as a numeric variable or as a
> factor? Since you only have two species, if species is not set up as a
> factor variable and data within species is in a string/character format,
> that can generate NaNs.
> What version of R are you using? Starting with R V4.0,
> StringsAsFactors=FALSE is the default setting.
>
> Please send the results of the following commands:
>
> str(data) (where data is the name of your data-frame)
>
> head(data, n = 10)
>
> class(data$species)
>
> Sree
>
> On Mon, Nov 9, 2020 at 5:55 PM Anne-Christine Auge <achr.auge at gmail.com>
> wrote:
>
> > I am trying to analyse the effect of temperature range (T.range) on
> turtle
> > animal activity (odba_mean).
> > I have multiple daily measurements for multiple individuals (name_ID)
> from
> > two species. I have data for 3 years (no turtle repeats over the years).
> A
> > datafile is attached.
> > Activity (mean_ODBA) measures appear to be temporally autocorrelated, so
> > this needs to be accounted for).
> >
> > I am fairly new to mixed models, so I am very unsure about my code. I am
> > using the nlme package because this seems to one that can more easily
> > account for autoregression.
> > This is the code I have so far:
> >
> > Mlme <- lme(odba_mean ~ T.range + species + T.range*species,
> >              random = ~ T.range|species/name_ID,
> >              data = df3,
> >              correlation = corAR1(form = ~date|species/name_ID))
> >
> >
> > I have a couple issues that I cannot seem to solve:
> > 1. I get the warning: "Warning message: In pt(-abs(tVal), fDF) : NaNs
> > produced" which appears to be due to the nesting structure, but I just do
> > not know how to fix it.
> > 2. I cannot figure out how to include year as another random effect. I
> read
> > that it is very difficult in nlme to include multiple random effects that
> > are not nested. I suppose technically name_ID is nested in years, but it
> is
> > already nested in species, and species is not nested in years (but
> > crossed). How do I incorporate this?
> >
> > Thank you.
> > Regards,
> > Anni
> >
> > --
> > *_________________________________________*
> >
> >
> > *Anne-Christine Auge*
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From D@v|d@Du||y @end|ng |rom q|mrbergho|er@edu@@u  Tue Nov 10 08:55:22 2020
From: D@v|d@Du||y @end|ng |rom q|mrbergho|er@edu@@u (David Duffy)
Date: Tue, 10 Nov 2020 07:55:22 +0000
Subject: [R-sig-ME] Interpreting Estimates from GLMM following a
 beta-distribution (glmmTMB)
In-Reply-To: <CABghstSNmrAbenUkXbC2Y6mYS-QOhKG6L1qrD4TAPigoMX1vtg@mail.gmail.com>
References: <3094cd29-bfb3-b3da-6faa-68cc2cad210a.ref@yahoo.de>
 <3094cd29-bfb3-b3da-6faa-68cc2cad210a@yahoo.de>,
 <CABghstSNmrAbenUkXbC2Y6mYS-QOhKG6L1qrD4TAPigoMX1vtg@mail.gmail.com>
Message-ID: <ad8d77066a494dea9749cb591a726794@qimrberghofer.edu.au>

I would cheat, by using predict.glmmTMB(..., type="response") on grids of the predictors, from which you
can look for "nice" summaries.
________________________________________
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of Ben Bolker <bbolker at gmail.com>
Sent: Tuesday, 10 November 2020 4:25:42 AM
To: Jan Velimsky
Cc: R SIG Mixed Models
Subject: Re: [R-sig-ME] Interpreting Estimates from GLMM following a beta-distribution (glmmTMB)

On Mon, Nov 9, 2020 at 1:12 PM Jan Velimsky via R-sig-mixed-models
<r-sig-mixed-models at r-project.org> wrote:
>
> Dear R project mixed models users,
>
> I am struggling to interpret the estimates from a GLMM following a
> beta-distribution with a logit link. There is not much literature
> regarding the interpretation of this special case.
>
> We have been estimating a GLMM model following a beta-distribution (with
> a logit link) with the glmmTMB-package. The model consists of factors
> influencing referendum turnout in German municipalities. The primary
> units of investigation are city districts nested in referendums nested
> in cities. The dependent variable (0-100) has been transformed to the
> unit interval 0-1.

  Is there a reason you can't get information on the voter base for
each municipality? That would make the model into a more standard
binomial model, which would have two advantages: (1) municipalities of
different sizes would be appropriately weighted; (2) it would be a
more familiar model type (less convincing of reviewers, wider range of
available software, etc.)

>
> Here an example model:
>
>   glmmTMB (ref_turnout ~ unemployment + contestation+ (1|
> city/referendum), family=list(family="beta", link ='logit'), data = ml)
>
>
> Results example model:
>
> Estimate      Std. Error    zvalue     Pr(>|z|)
>
> (Intercept) -0.583             0.131      -4.455     8.4e-06***
>
> unemployment rate (in%) -0.067              0.002      -30.397    <
> 2e-16 ***
>
> contestation 0.008              0.003        2.398     0.0165 *
>
> All explanatory variables are grand mean centered.
>
> Taking into account the link function and the parameterization of beta
> regression, my interpretation for the effect of unemployment would be:
> One percent increase from the average unemployment-rate in districts of
> German municipalities (grand-mean) is associated with a  0.067 unit
> decrease from the overall mean of the participation rate in referendums
> (log odds)
>
> 1) Is this interpretation correct?

  Yes

> 2) Are there more intuitive options for interpretation (e.g. with odd
> ratios or marginal effects )

  You could exponentiate the coefficient and conclude that there was a
proportional change of 0.064 (1-exp(-0.067)), or 6.4%, in the *odds*
of turnout per 1% increase in the unemployment rate (the numbers
(0.067, 0.064) are similar because the coefficient is <<1).

  Because your baseline rate is intermediate (exp(-0.583) is 0.56, in
the range 0.3-0.7 where the following rule of thumb applies) you could
say there is *approximately* a decrease of beta/4 = 1.7 percentage
points, in turnout per percent increase in unemployment (this is an
*absolute*, linear change rather than a proportional change). (See
e.g. Gelman and Hill's book.)

   You should be a little careful about the effect of transformation
and variation: see the last ("Bias adjustment") section of the
"transformations" vignette from the emmeans package.



> Thanks a lot for your help!
>
> Jan
>
> --
> Jan Velimsky, M.A.
> Wissenschaftlicher Mitarbeiter
> Lehrstuhl f?r Politische Systeme und Europ?ische Integration
> Geschwister-Scholl-Institut f?r Politikwissenschaft
> Ludwig-Maximilians-Universit?t M?nchen
>
> D-80538 M?nchen
> Oettingenstrasse 67
> Tel. 0176 73292389
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
[EXTERNAL EMAIL] This message originates from an external email address, please exercise caution when clicking any links or opening attachments. If you believe the sender is impersonating someone at QIMR Berghofer, please forward this message to phishing at qimrberghofer.edu.au.


From ph||||p@@|d@y @end|ng |rom mp|@n|  Tue Nov 10 12:30:30 2020
From: ph||||p@@|d@y @end|ng |rom mp|@n| (Phillip Alday)
Date: Tue, 10 Nov 2020 12:30:30 +0100
Subject: [R-sig-ME] Using broom.mixed library with lme4
In-Reply-To: <CACgv6yW=uvWH5rP+SwsfD45cwTY3WEy5+6132EZPWy0vX5N8QQ@mail.gmail.com>
References: <CACgv6yW=uvWH5rP+SwsfD45cwTY3WEy5+6132EZPWy0vX5N8QQ@mail.gmail.com>
Message-ID: <35d40579-e361-ba1f-19e4-0cfba9c91d83@mpi.nl>

Why do you think ubar is for the random effects? In my very quick skim
of the documentation, I didn't see anything indicating that. Looking at
the structures in `fit`, I see:

> tidy(fit$analyses[[5]])
# A tibble: 4 x 6
  effect   group    term            estimate std.error statistic
  <chr>    <chr>    <chr>              <dbl>     <dbl>     <dbl>
1 fixed    NA       (Intercept)        4.91     0.0855      57.4
2 fixed    NA       sex                0.853    0.0350      24.4
3 ran_pars school   sd__(Intercept)    0.820   NA           NA
4 ran_pars Residual sd__Observation    0.767   NA           NA

None of the random effects line up with the output of pool(). Moreover,
the pool() documentation notes that it needs the standard error of each
estimate, but lme4 doesn't produce those (for good reason) for random
effects, so pool() won't produce pooled estimates for the random effects.

The pool() documentation mentions the mipo class, so I looked at ?mipo
and found this:


       ?estimate?  Pooled complete data estimate
       ?ubar?      Within-imputation variance of ?estimate?
       ?b?         Between-imputation variance of ?estimate?
       ?t?         Total variance, of ?estimate?
       ?dfcom?     Degrees of freedom in complete data
       ?df?        Degrees of freedom of $t$-statistic
       ?riv?       Relative increase in variance
       ?lambda?    Proportion attributable to the missingness
       ?fmi?       Fraction of missing information


So `ubar` and `b` are perhaps random effects, but not in the sense
you're thinking of, but rather the random effects that go into
imputation procedures (this is a guess on my part). I don't know much
about imputation, but I suspect this is analogous to the parallels
between mixed models and meta-analysis
(http://www.metafor-project.org/doku.php/tips:rma_vs_lm_lme_lmer). But
again, this is rapidly getting out of my area of expertise and into the
expertise of other members of this list (e.g. Wolfgang Viechtbauer for
meta analysis).

Phillip

On 10/11/20 7:17 am, Simon Harmel wrote:
> Dear All,
> 
> Belwo, I've used library `broom.mixed` and imputed some data with library
> `mice` to then fit a "random-intercept" `lmer()` model.
> 
> BUT I wonder why after I `pool()` my analyses, there is an extra "ubar"
> (random-effect) for slope (`sex`) which is not even in the model?!
> 
> library(mice)
> library(lme4)
> library(broom.mixed)
> 
> imp <- mice(popmis, m = 5) # `popmis` is a dataset from `mice`
> 
> fit <- with(data = imp, exp = lme4::lmer(popular ~ sex + (1|school)))
> 
> pool(fit)
> 
> ### `ubar` is the random effect for intercept (0.007524509) BUT WHY we see
> a ubar ALSO for `sex` (0.001177781)?
> 
> Class: mipo    m = 5
>          term m  estimate        ubar            b           t dfcom
>  df
> 1 (Intercept) 5 4.9007789 0.007524509 0.0004845564 0.008105977  1996
> 547.44383
> 2         sex 5 0.8617941 0.001177781 0.0015867795 0.003081916  1996
>  10.33653
>         riv     lambda       fmi
> 1 0.0772765 0.07173321 0.0751060
> 2 1.6167147 0.61784141 0.6751515
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From Benj@m|n@C|nget @end|ng |rom |@@@@u|@v@|@c@  Tue Nov 10 19:37:54 2020
From: Benj@m|n@C|nget @end|ng |rom |@@@@u|@v@|@c@ (Benjamin Cinget)
Date: Tue, 10 Nov 2020 18:37:54 +0000
Subject: [R-sig-ME] GLM in an observatory study.
Message-ID: <QB1PR01MB3345CC4314F102E156DD08FDDAE90@QB1PR01MB3345.CANPRD01.PROD.OUTLOOK.COM>

Good Morning everyone,

I am interested in whether plant pathogens species show any distribution across various agricultural factors and, in particular, whether there are any interactions among these factors impacting the pathogen abundances. I am working with different farmers, and consequently I did not choose the experimental design. Consequently, I have a very unbalanced structure in my data because the farms have different number of fields and, of course, different agricultural practices (Survey study).

I considered that the response variable is the species abundances (?Abun?) and three explanatory variables, all categorical: ?Fun? is a three-level factor for fungicide treatments of the farm (one treatment by farm), ?Cult? is a nine-level factor for cultivar (only one planted in one field), ?Stime? is a three-level factor for three sampling times for a same field,  and there are twelve pathogen species observed.

Basically, because I learned like that:

First - I built the following full model with a Poisson correction error (because I am working with abundances):

model. -> glmer(Abun ~ Fun * Cult * Stime * Spe + (Stime|Farm/Field), family = Poisson)

where ?(Stime|Farm/Field)? term is to consider the repeated measurements of nested fields in farms as random effects.

Second -  I performed by deviance analysis, step by step, by suppressing the interactions involving the ?Spe? variable to test their significant, and by beginning by the highest interaction (Fun:Cult:Stime:Spe, three-way interaction).

My questions are :

  1.  Because my glm classes are far away (2005), is that still a good approach? I do not want to build a perfect model,  but just to estimate if my three parameters (and interactions) are involved in the species distributions. If not have you some up to date suggestions, please ?



  1.  I am not sure for the ?(Stime|Farm/Field)? because ?Stime? is categorical, do I have to dissociate the two random effects ?

Thank you very much for your help,

Benjamin Cinget


	[[alternative HTML version deleted]]


From @reedt@8 @end|ng |rom gm@||@com  Tue Nov 10 21:19:19 2020
From: @reedt@8 @end|ng |rom gm@||@com (sree datta)
Date: Tue, 10 Nov 2020 15:19:19 -0500
Subject: [R-sig-ME] nlme issue with multiple random effects and
 autoregression
In-Reply-To: <CAHftDbgi3KA4+H06gOkK70XjnCVzB13+UQWrfpvquMHcJMTt=Q@mail.gmail.com>
References: <CANb_3M_7bXgp5Ate2KzT2xSP68O9BL4G98wi7j0RCaTmmeC17A@mail.gmail.com>
 <CAHftDbgTMjZaDZdfA6ccb2SzjFcwGZMsb7ydsZjtx5LVsnqdVQ@mail.gmail.com>
 <CANb_3M-VAfJ5cDuz==TsPg-PtbEOtYps1RtTAZJtLRDuahpTrw@mail.gmail.com>
 <CAHftDbgi3KA4+H06gOkK70XjnCVzB13+UQWrfpvquMHcJMTt=Q@mail.gmail.com>
Message-ID: <CAHftDbhV2w=4xKvHfHunEDd_BPSRixGA9D0Qk6hjP+Xy7pf=hA@mail.gmail.com>

Hi Anne

I was able to fix your error. The error you are getting is due to how *date* is
being currently categorised as - *factor*. That is incorrect and the reason
why you are seeing NaNs. Instead if you convert it into a proper *date* using
the command below

*turtles$date <- as.Date(turtles$date) *   # I read in your csv file as a
dataframe called *turtles*

then I successfully execute the model command:

*library(nlme)*




*Mlme <- lme(odba_mean ~ T.range + species + T.range*species,
 random = ~ T.range|species/name_ID,             data = turtles,   # change
the name of data to your dataframe             correlation = corAR1(form =
~date|species/name_ID))*

Here is the output:

> *summary(Mlme)*
Linear mixed-effects model fit by REML
 Data: turtles
        AIC       BIC   logLik
  -8556.186 -8488.761 4290.093

Random effects:
 Formula: ~T.range | species
 Structure: General positive-definite, Log-Cholesky parametrization
            StdDev       Corr
(Intercept) 0.0023228641 (Intr)
T.range     0.0005050215 0

 Formula: ~T.range | name_ID %in% species
 Structure: General positive-definite, Log-Cholesky parametrization
            StdDev      Corr
(Intercept) 0.022010442 (Intr)
T.range     0.004108761 -0.484
Residual    0.027819874

Correlation Structure: ARMA(1,0)
 Formula: ~date | species/name_ID
 Parameter estimate(s):
Phi1
   0
Fixed effects: odba_mean ~ T.range + species + T.range * species
                                              Value           Std.Error
       DF           t-value      p-value
(Intercept)                            0.05806883 0.006167821     1986
 9.414805    0.0000
T.range                                0.00277333 0.001315326      1986
   2.108475    0.0351
species[T.Painted]               0.01371710 0.008022122      0
 1.709909     NaN
T.range:species[T.Painted] -0.00214764 0.001669308      1986
-1.286544    0.1984
 Correlation:
                           (Intr) T.rang s[T.P]
T.range                    -0.510
species[T.Painted]         -0.769  0.392
T.range:species[T.Painted]  0.402 -0.788 -0.493

Standardized Within-Group Residuals:
        Min          Q1                    Med              Q3
  Max
-3.20979441 -0.64327078 -0.06066791  0.57720480  5.88216284

Number of Observations: 2040
Number of Groups:
             species name_ID %in% species
                   2                   52




On Tue, Nov 10, 2020 at 2:56 PM sree datta <sreedta8 at gmail.com> wrote:

> Thanks Anne. Let me set up the models into a working condition and see if
> I can find a solution for you.
>
> Sree
>
> On Tue, Nov 10, 2020 at 8:58 AM Anne-Christine Auge <achr.auge at gmail.com>
> wrote:
>
>> Hello Sree,
>> thank you for your reply. I am attaching the datafile again here. Hope it
>> works this time.
>>
>> Species is set up as a factor. I am using R version 4.0.2.
>>
>> Here are is the output:
>>
>> > str(df3)
>> 'data.frame': 2040 obs. of  8 variables:
>>  $ name_ID  : Factor w/ 52 levels "Alison_2020",..: 1 1 1 1 1 1 1 1 1 1
>> ...
>>  $ name     : chr  "Alison" "Alison" "Alison" "Alison" ...
>>  $ year     : int  2020 2020 2020 2020 2020 2020 2020 2020 2020 2020 ...
>>  $ species  : Factor w/ 2 levels "Blandings","Painted": 2 2 2 2 2 2 2 2 2
>> 2 ...
>>  $ date     : Date, format: "2020-05-11" "2020-05-12" "2020-05-13"
>> "2020-05-14" ...
>>  $ Jday     : int  132 133 134 135 137 138 139 140 141 142 ...
>>  $ T.range  : num  3.63 4.51 3.39 4.95 5.36 ...
>>  $ odba_mean: num  0.0613 0.0169 0.0306 0.0225 0.0254 ...
>>
>> > head(df3, n=10)
>>        name_ID   name year species       date Jday  T.range  odba_mean
>> 1  Alison_2020 Alison 2020 Painted 2020-05-11  132 3.630952 0.06125982
>> 2  Alison_2020 Alison 2020 Painted 2020-05-12  133 4.507440 0.01687152
>> 3  Alison_2020 Alison 2020 Painted 2020-05-13  134 3.392361 0.03059397
>> 4  Alison_2020 Alison 2020 Painted 2020-05-14  135 4.951389 0.02250526
>> 5  Alison_2020 Alison 2020 Painted 2020-05-16  137 5.362847 0.02542538
>> 6  Alison_2020 Alison 2020 Painted 2020-05-17  138 6.307292 0.04627075
>> 7  Alison_2020 Alison 2020 Painted 2020-05-18  139 6.208333 0.03905372
>> 8  Alison_2020 Alison 2020 Painted 2020-05-19  140 4.828125 0.04999669
>> 9  Alison_2020 Alison 2020 Painted 2020-05-20  141 7.390625 0.04744481
>> 10 Alison_2020 Alison 2020 Painted 2020-05-21  142 6.901042 0.05230780
>>
>> > class(df3$species)
>> [1] "factor"
>>
>>
>> On Mon, 9 Nov 2020 at 22:45, sree datta <sreedta8 at gmail.com> wrote:
>>
>>> I do not see the data file. Please attach it if possible. In addition,
>>> how is the "species" variable set-up? Is it coded as a numeric variable or
>>> as a factor? Since you only have two species, if species is not set up as a
>>> factor variable and data within species is in a string/character format,
>>> that can generate NaNs.
>>> What version of R are you using? Starting with R V4.0,
>>> StringsAsFactors=FALSE is the default setting.
>>>
>>> Please send the results of the following commands:
>>>
>>> str(data) (where data is the name of your data-frame)
>>>
>>> head(data, n = 10)
>>>
>>> class(data$species)
>>>
>>> Sree
>>>
>>> On Mon, Nov 9, 2020 at 5:55 PM Anne-Christine Auge <achr.auge at gmail.com>
>>> wrote:
>>>
>>>> I am trying to analyse the effect of temperature range (T.range) on
>>>> turtle
>>>> animal activity (odba_mean).
>>>> I have multiple daily measurements for multiple individuals (name_ID)
>>>> from
>>>> two species. I have data for 3 years (no turtle repeats over the
>>>> years). A
>>>> datafile is attached.
>>>> Activity (mean_ODBA) measures appear to be temporally autocorrelated, so
>>>> this needs to be accounted for).
>>>>
>>>> I am fairly new to mixed models, so I am very unsure about my code. I am
>>>> using the nlme package because this seems to one that can more easily
>>>> account for autoregression.
>>>> This is the code I have so far:
>>>>
>>>> Mlme <- lme(odba_mean ~ T.range + species + T.range*species,
>>>>              random = ~ T.range|species/name_ID,
>>>>              data = df3,
>>>>              correlation = corAR1(form = ~date|species/name_ID))
>>>>
>>>>
>>>> I have a couple issues that I cannot seem to solve:
>>>> 1. I get the warning: "Warning message: In pt(-abs(tVal), fDF) : NaNs
>>>> produced" which appears to be due to the nesting structure, but I just
>>>> do
>>>> not know how to fix it.
>>>> 2. I cannot figure out how to include year as another random effect. I
>>>> read
>>>> that it is very difficult in nlme to include multiple random effects
>>>> that
>>>> are not nested. I suppose technically name_ID is nested in years, but
>>>> it is
>>>> already nested in species, and species is not nested in years (but
>>>> crossed). How do I incorporate this?
>>>>
>>>> Thank you.
>>>> Regards,
>>>> Anni
>>>>
>>>> --
>>>> *_________________________________________*
>>>>
>>>>
>>>> *Anne-Christine Auge*
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>
>>
>> --
>> *_________________________________________*
>>
>>
>> *Anne-Christine Auge*
>>
>

	[[alternative HTML version deleted]]


From zp@|mp@o @end|ng |rom gm@||@com  Tue Nov 10 22:27:48 2020
From: zp@|mp@o @end|ng |rom gm@||@com (Zach Simpson)
Date: Wed, 11 Nov 2020 10:27:48 +1300
Subject: [R-sig-ME] Using broom.mixed library with lme4
Message-ID: <CAJByKzoJT3ZQHC4nQ4vK6J4ztfwftQh=P_kxiwPxkP=bzeMifA@mail.gmail.com>

Just to add to Phillip's answer, the ubar has to do with the multiple
imputation procedure: ubar is the within-imputation variance of the
sex term. You fitted 5 lmer models on 5 'completed' datasets whose
NA's were filled using default imputation procedures from mice.
mice::pool() combines these m=5 fits using Rubin's rules. There's
uncertainty in model estimates due to the data itself as well as the
imputation uncertainty.

Stef van Buuren has put online an enormous amount of documentation,
which would pay dividends to read:

https://amices.org/mice/

HTH
Zach

> Why do you think ubar is for the random effects? In my very quick skim
> of the documentation, I didn't see anything indicating that. Looking at
> the structures in `fit`, I see:
>
> > tidy(fit$analyses[[5]])
> # A tibble: 4 x 6
>   effect   group    term            estimate std.error statistic
>   <chr>    <chr>    <chr>              <dbl>     <dbl>     <dbl>
> 1 fixed    NA       (Intercept)        4.91     0.0855      57.4
> 2 fixed    NA       sex                0.853    0.0350      24.4
> 3 ran_pars school   sd__(Intercept)    0.820   NA           NA
> 4 ran_pars Residual sd__Observation    0.767   NA           NA
>
> None of the random effects line up with the output of pool(). Moreover,
> the pool() documentation notes that it needs the standard error of each
> estimate, but lme4 doesn't produce those (for good reason) for random
> effects, so pool() won't produce pooled estimates for the random effects.
>
> The pool() documentation mentions the mipo class, so I looked at ?mipo
> and found this:
>
>
>        ?estimate?  Pooled complete data estimate
>        ?ubar?      Within-imputation variance of ?estimate?
>        ?b?         Between-imputation variance of ?estimate?
>        ?t?         Total variance, of ?estimate?
>        ?dfcom?     Degrees of freedom in complete data
>        ?df?        Degrees of freedom of $t$-statistic
>        ?riv?       Relative increase in variance
>        ?lambda?    Proportion attributable to the missingness
>        ?fmi?       Fraction of missing information
>
>
> So `ubar` and `b` are perhaps random effects, but not in the sense
> you're thinking of, but rather the random effects that go into
> imputation procedures (this is a guess on my part). I don't know much
> about imputation, but I suspect this is analogous to the parallels
> between mixed models and meta-analysis
> (http://www.metafor-project.org/doku.php/tips:rma_vs_lm_lme_lmer). But
> again, this is rapidly getting out of my area of expertise and into the
> expertise of other members of this list (e.g. Wolfgang Viechtbauer for
> meta analysis).
>
> Phillip
>
> On 10/11/20 7:17 am, Simon Harmel wrote:
> > Dear All,
> >
> > Belwo, I've used library `broom.mixed` and imputed some data with library
> > `mice` to then fit a "random-intercept" `lmer()` model.
> >
> > BUT I wonder why after I `pool()` my analyses, there is an extra "ubar"
> > (random-effect) for slope (`sex`) which is not even in the model?!
> >
> > library(mice)
> > library(lme4)
> > library(broom.mixed)
> >
> > imp <- mice(popmis, m = 5) # `popmis` is a dataset from `mice`
> >
> > fit <- with(data = imp, exp = lme4::lmer(popular ~ sex + (1|school)))
> >
> > pool(fit)
> >
> > ### `ubar` is the random effect for intercept (0.007524509) BUT WHY we see
> > a ubar ALSO for `sex` (0.001177781)?
> >
> > Class: mipo    m = 5
> >          term m  estimate        ubar            b           t dfcom
> >  df
> > 1 (Intercept) 5 4.9007789 0.007524509 0.0004845564 0.008105977  1996
> > 547.44383
> > 2         sex 5 0.8617941 0.001177781 0.0015867795 0.003081916  1996
> >  10.33653
> >         riv     lambda       fmi
> > 1 0.0772765 0.07173321 0.0751060
> > 2 1.6167147 0.61784141 0.6751515
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >


From @|m@h@rme| @end|ng |rom gm@||@com  Tue Nov 10 23:26:23 2020
From: @|m@h@rme| @end|ng |rom gm@||@com (Simon Harmel)
Date: Tue, 10 Nov 2020 16:26:23 -0600
Subject: [R-sig-ME] Using broom.mixed library with lme4
In-Reply-To: <CAJByKzoJT3ZQHC4nQ4vK6J4ztfwftQh=P_kxiwPxkP=bzeMifA@mail.gmail.com>
References: <CAJByKzoJT3ZQHC4nQ4vK6J4ztfwftQh=P_kxiwPxkP=bzeMifA@mail.gmail.com>
Message-ID: <CACgv6yUBoikSPog1Bc3MQopVwHNSe28EG9yoxLQwJ3OOkiy_Og@mail.gmail.com>

Thanks.  I think a point is being missed. I did have carefully read the
documentation.  And pool() is in fact supposed to apply the RUBIN RULE and
pool across the estimates from 5 imputed datasets.

For lm() objects, pool() does what I describe above. But it seems, it
doesn't do the same for the lmer() objects.

That was really the core of my question and l was wondering if a solution
to it might be available?


There is no documentation on that.

On Tue, Nov 10, 2020, 3:28 PM Zach Simpson <zpsimpso at gmail.com> wrote:

> Just to add to Phillip's answer, the ubar has to do with the multiple
> imputation procedure: ubar is the within-imputation variance of the
> sex term. You fitted 5 lmer models on 5 'completed' datasets whose
> NA's were filled using default imputation procedures from mice.
> mice::pool() combines these m=5 fits using Rubin's rules. There's
> uncertainty in model estimates due to the data itself as well as the
> imputation uncertainty.
>
> Stef van Buuren has put online an enormous amount of documentation,
> which would pay dividends to read:
>
> https://amices.org/mice/
>
> HTH
> Zach
>
> > Why do you think ubar is for the random effects? In my very quick skim
> > of the documentation, I didn't see anything indicating that. Looking at
> > the structures in `fit`, I see:
> >
> > > tidy(fit$analyses[[5]])
> > # A tibble: 4 x 6
> >   effect   group    term            estimate std.error statistic
> >   <chr>    <chr>    <chr>              <dbl>     <dbl>     <dbl>
> > 1 fixed    NA       (Intercept)        4.91     0.0855      57.4
> > 2 fixed    NA       sex                0.853    0.0350      24.4
> > 3 ran_pars school   sd__(Intercept)    0.820   NA           NA
> > 4 ran_pars Residual sd__Observation    0.767   NA           NA
> >
> > None of the random effects line up with the output of pool(). Moreover,
> > the pool() documentation notes that it needs the standard error of each
> > estimate, but lme4 doesn't produce those (for good reason) for random
> > effects, so pool() won't produce pooled estimates for the random effects.
> >
> > The pool() documentation mentions the mipo class, so I looked at ?mipo
> > and found this:
> >
> >
> >        ?estimate?  Pooled complete data estimate
> >        ?ubar?      Within-imputation variance of ?estimate?
> >        ?b?         Between-imputation variance of ?estimate?
> >        ?t?         Total variance, of ?estimate?
> >        ?dfcom?     Degrees of freedom in complete data
> >        ?df?        Degrees of freedom of $t$-statistic
> >        ?riv?       Relative increase in variance
> >        ?lambda?    Proportion attributable to the missingness
> >        ?fmi?       Fraction of missing information
> >
> >
> > So `ubar` and `b` are perhaps random effects, but not in the sense
> > you're thinking of, but rather the random effects that go into
> > imputation procedures (this is a guess on my part). I don't know much
> > about imputation, but I suspect this is analogous to the parallels
> > between mixed models and meta-analysis
> > (http://www.metafor-project.org/doku.php/tips:rma_vs_lm_lme_lmer). But
> > again, this is rapidly getting out of my area of expertise and into the
> > expertise of other members of this list (e.g. Wolfgang Viechtbauer for
> > meta analysis).
> >
> > Phillip
> >
> > On 10/11/20 7:17 am, Simon Harmel wrote:
> > > Dear All,
> > >
> > > Belwo, I've used library `broom.mixed` and imputed some data with
> library
> > > `mice` to then fit a "random-intercept" `lmer()` model.
> > >
> > > BUT I wonder why after I `pool()` my analyses, there is an extra "ubar"
> > > (random-effect) for slope (`sex`) which is not even in the model?!
> > >
> > > library(mice)
> > > library(lme4)
> > > library(broom.mixed)
> > >
> > > imp <- mice(popmis, m = 5) # `popmis` is a dataset from `mice`
> > >
> > > fit <- with(data = imp, exp = lme4::lmer(popular ~ sex + (1|school)))
> > >
> > > pool(fit)
> > >
> > > ### `ubar` is the random effect for intercept (0.007524509) BUT WHY we
> see
> > > a ubar ALSO for `sex` (0.001177781)?
> > >
> > > Class: mipo    m = 5
> > >          term m  estimate        ubar            b           t dfcom
> > >  df
> > > 1 (Intercept) 5 4.9007789 0.007524509 0.0004845564 0.008105977  1996
> > > 547.44383
> > > 2         sex 5 0.8617941 0.001177781 0.0015867795 0.003081916  1996
> > >  10.33653
> > >         riv     lambda       fmi
> > > 1 0.0772765 0.07173321 0.0751060
> > > 2 1.6167147 0.61784141 0.6751515
> > >
> > >       [[alternative HTML version deleted]]
> > >
> > > _______________________________________________
> > > R-sig-mixed-models at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > >
>

	[[alternative HTML version deleted]]


From ph||||p@@|d@y @end|ng |rom mp|@n|  Tue Nov 10 23:50:51 2020
From: ph||||p@@|d@y @end|ng |rom mp|@n| (Phillip Alday)
Date: Tue, 10 Nov 2020 23:50:51 +0100
Subject: [R-sig-ME] Using broom.mixed library with lme4
In-Reply-To: <CACgv6yUBoikSPog1Bc3MQopVwHNSe28EG9yoxLQwJ3OOkiy_Og@mail.gmail.com>
References: <CAJByKzoJT3ZQHC4nQ4vK6J4ztfwftQh=P_kxiwPxkP=bzeMifA@mail.gmail.com>
 <CACgv6yUBoikSPog1Bc3MQopVwHNSe28EG9yoxLQwJ3OOkiy_Og@mail.gmail.com>
Message-ID: <d427f35e-8b3b-bc45-b9e0-cc21f06d4f10@mpi.nl>

I'm a bit confused now and think a point is being missed, although I'm
not sure where.

Zach pointed out that the Rubin Rule is being applied. Both Zach and I
pointed out that you still get the pooled estimate and that the ubar and
b columns are uncertainty on the pooled estimate. In some quick tries
with example datasets, it seems that you don't get the ubar and b
columns for lm() fits, but I'm guessing that this means that it's not
possible to break down the variance of t (total variance of estimate)
into between and within estimates for non mixed models.

In other words, it seems that pool does more for lmer() than it does for
lm(), not less.

Your original question asked about the random effects, and we pointed
out that the the pool() table doesn't have the random effects from the
lmer() fit.

This becomes even clearer if you call summary() on the value of pool():

> summary(pool(fit))
         term  estimate  std.error statistic        df      p.value
1 (Intercept) 4.8932366 0.08966606  54.57178 521.81717 0.000000e+00
2         sex 0.8772664 0.05428838  16.15938  11.17712 4.226618e-09

(and that use of summary() is from the documentation Zach linked).

Can you try to pose your question a different way if we're
misunderstanding?

Best,
Phillip

On 10/11/20 11:26 pm, Simon Harmel wrote:
> Thanks.? I think a point is being missed. I did have carefully read the
> documentation.? And pool() is in fact supposed to apply the RUBIN RULE
> and pool across the estimates from 5 imputed datasets.
> 
> For lm() objects, pool() does what I describe above. But it seems, it
> doesn't do the same for the lmer() objects.?
> 
> That was really the core of my question and l was wondering if a
> solution to it might be available?
> 
> 
> There is no documentation on that.
> 
> On Tue, Nov 10, 2020, 3:28 PM Zach Simpson <zpsimpso at gmail.com
> <mailto:zpsimpso at gmail.com>> wrote:
> 
>     Just to add to Phillip's answer, the ubar has to do with the multiple
>     imputation procedure: ubar is the within-imputation variance of the
>     sex term. You fitted 5 lmer models on 5 'completed' datasets whose
>     NA's were filled using default imputation procedures from mice.
>     mice::pool() combines these m=5 fits using Rubin's rules. There's
>     uncertainty in model estimates due to the data itself as well as the
>     imputation uncertainty.
> 
>     Stef van Buuren has put online an enormous amount of documentation,
>     which would pay dividends to read:
> 
>     https://amices.org/mice/
> 
>     HTH
>     Zach
> 
>     > Why do you think ubar is for the random effects? In my very quick skim
>     > of the documentation, I didn't see anything indicating that.
>     Looking at
>     > the structures in `fit`, I see:
>     >
>     > > tidy(fit$analyses[[5]])
>     > # A tibble: 4 x 6
>     >? ?effect? ?group? ? term? ? ? ? ? ? estimate std.error statistic
>     >? ?<chr>? ? <chr>? ? <chr>? ? ? ? ? ? ? <dbl>? ? ?<dbl>? ? ?<dbl>
>     > 1 fixed? ? NA? ? ? ?(Intercept)? ? ? ? 4.91? ? ?0.0855? ? ? 57.4
>     > 2 fixed? ? NA? ? ? ?sex? ? ? ? ? ? ? ? 0.853? ? 0.0350? ? ? 24.4
>     > 3 ran_pars school? ?sd__(Intercept)? ? 0.820? ?NA? ? ? ? ? ?NA
>     > 4 ran_pars Residual sd__Observation? ? 0.767? ?NA? ? ? ? ? ?NA
>     >
>     > None of the random effects line up with the output of pool().
>     Moreover,
>     > the pool() documentation notes that it needs the standard error of
>     each
>     > estimate, but lme4 doesn't produce those (for good reason) for random
>     > effects, so pool() won't produce pooled estimates for the random
>     effects.
>     >
>     > The pool() documentation mentions the mipo class, so I looked at ?mipo
>     > and found this:
>     >
>     >
>     >? ? ? ? ?estimate?? Pooled complete data estimate
>     >? ? ? ? ?ubar?? ? ? Within-imputation variance of ?estimate?
>     >? ? ? ? ?b?? ? ? ? ?Between-imputation variance of ?estimate?
>     >? ? ? ? ?t?? ? ? ? ?Total variance, of ?estimate?
>     >? ? ? ? ?dfcom?? ? ?Degrees of freedom in complete data
>     >? ? ? ? ?df?? ? ? ? Degrees of freedom of $t$-statistic
>     >? ? ? ? ?riv?? ? ? ?Relative increase in variance
>     >? ? ? ? ?lambda?? ? Proportion attributable to the missingness
>     >? ? ? ? ?fmi?? ? ? ?Fraction of missing information
>     >
>     >
>     > So `ubar` and `b` are perhaps random effects, but not in the sense
>     > you're thinking of, but rather the random effects that go into
>     > imputation procedures (this is a guess on my part). I don't know much
>     > about imputation, but I suspect this is analogous to the parallels
>     > between mixed models and meta-analysis
>     > (http://www.metafor-project.org/doku.php/tips:rma_vs_lm_lme_lmer). But
>     > again, this is rapidly getting out of my area of expertise and
>     into the
>     > expertise of other members of this list (e.g. Wolfgang Viechtbauer for
>     > meta analysis).
>     >
>     > Phillip
>     >
>     > On 10/11/20 7:17 am, Simon Harmel wrote:
>     > > Dear All,
>     > >
>     > > Belwo, I've used library `broom.mixed` and imputed some data
>     with library
>     > > `mice` to then fit a "random-intercept" `lmer()` model.
>     > >
>     > > BUT I wonder why after I `pool()` my analyses, there is an extra
>     "ubar"
>     > > (random-effect) for slope (`sex`) which is not even in the model?!
>     > >
>     > > library(mice)
>     > > library(lme4)
>     > > library(broom.mixed)
>     > >
>     > > imp <- mice(popmis, m = 5) # `popmis` is a dataset from `mice`
>     > >
>     > > fit <- with(data = imp, exp = lme4::lmer(popular ~ sex +
>     (1|school)))
>     > >
>     > > pool(fit)
>     > >
>     > > ### `ubar` is the random effect for intercept (0.007524509) BUT
>     WHY we see
>     > > a ubar ALSO for `sex` (0.001177781)?
>     > >
>     > > Class: mipo? ? m = 5
>     > >? ? ? ? ? term m? estimate? ? ? ? ubar? ? ? ? ? ? b? ? ? ? ? ?t dfcom
>     > >? df
>     > > 1 (Intercept) 5 4.9007789 0.007524509 0.0004845564 0.008105977? 1996
>     > > 547.44383
>     > > 2? ? ? ? ?sex 5 0.8617941 0.001177781 0.0015867795 0.003081916? 1996
>     > >? 10.33653
>     > >? ? ? ? ?riv? ? ?lambda? ? ? ?fmi
>     > > 1 0.0772765 0.07173321 0.0751060
>     > > 2 1.6167147 0.61784141 0.6751515
>     > >
>     > >? ? ? ?[[alternative HTML version deleted]]
>     > >
>     > > _______________________________________________
>     > > R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>     > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     > >
>


From @|m@h@rme| @end|ng |rom gm@||@com  Wed Nov 11 00:16:13 2020
From: @|m@h@rme| @end|ng |rom gm@||@com (Simon Harmel)
Date: Tue, 10 Nov 2020 17:16:13 -0600
Subject: [R-sig-ME] Using broom.mixed library with lme4
In-Reply-To: <d427f35e-8b3b-bc45-b9e0-cc21f06d4f10@mpi.nl>
References: <CAJByKzoJT3ZQHC4nQ4vK6J4ztfwftQh=P_kxiwPxkP=bzeMifA@mail.gmail.com>
 <CACgv6yUBoikSPog1Bc3MQopVwHNSe28EG9yoxLQwJ3OOkiy_Og@mail.gmail.com>
 <d427f35e-8b3b-bc45-b9e0-cc21f06d4f10@mpi.nl>
Message-ID: <CACgv6yUUZcDH7kXoRjpxHMyv7P0OQdStnunB2DhVX8oJ+pTbUQ@mail.gmail.com>

Sorry guys, I found what the problem was! I didn't use `summary()` after
the pool() call! However, it there a way to find out how the estimates of
random-effects can be pooled across the imputations?

On Tue, Nov 10, 2020 at 5:01 PM Phillip Alday <phillip.alday at mpi.nl> wrote:

> I'm a bit confused now and think a point is being missed, although I'm
> not sure where.
>
> Zach pointed out that the Rubin Rule is being applied. Both Zach and I
> pointed out that you still get the pooled estimate and that the ubar and
> b columns are uncertainty on the pooled estimate. In some quick tries
> with example datasets, it seems that you don't get the ubar and b
> columns for lm() fits, but I'm guessing that this means that it's not
> possible to break down the variance of t (total variance of estimate)
> into between and within estimates for non mixed models.
>
> In other words, it seems that pool does more for lmer() than it does for
> lm(), not less.
>
> Your original question asked about the random effects, and we pointed
> out that the the pool() table doesn't have the random effects from the
> lmer() fit.
>
> This becomes even clearer if you call summary() on the value of pool():
>
> > summary(pool(fit))
>          term  estimate  std.error statistic        df      p.value
> 1 (Intercept) 4.8932366 0.08966606  54.57178 521.81717 0.000000e+00
> 2         sex 0.8772664 0.05428838  16.15938  11.17712 4.226618e-09
>
> (and that use of summary() is from the documentation Zach linked).
>
> Can you try to pose your question a different way if we're
> misunderstanding?
>
> Best,
> Phillip
>
> On 10/11/20 11:26 pm, Simon Harmel wrote:
> > Thanks.  I think a point is being missed. I did have carefully read the
> > documentation.  And pool() is in fact supposed to apply the RUBIN RULE
> > and pool across the estimates from 5 imputed datasets.
> >
> > For lm() objects, pool() does what I describe above. But it seems, it
> > doesn't do the same for the lmer() objects.
> >
> > That was really the core of my question and l was wondering if a
> > solution to it might be available?
> >
> >
> > There is no documentation on that.
> >
> > On Tue, Nov 10, 2020, 3:28 PM Zach Simpson <zpsimpso at gmail.com
> > <mailto:zpsimpso at gmail.com>> wrote:
> >
> >     Just to add to Phillip's answer, the ubar has to do with the multiple
> >     imputation procedure: ubar is the within-imputation variance of the
> >     sex term. You fitted 5 lmer models on 5 'completed' datasets whose
> >     NA's were filled using default imputation procedures from mice.
> >     mice::pool() combines these m=5 fits using Rubin's rules. There's
> >     uncertainty in model estimates due to the data itself as well as the
> >     imputation uncertainty.
> >
> >     Stef van Buuren has put online an enormous amount of documentation,
> >     which would pay dividends to read:
> >
> >     https://amices.org/mice/
> >
> >     HTH
> >     Zach
> >
> >     > Why do you think ubar is for the random effects? In my very quick
> skim
> >     > of the documentation, I didn't see anything indicating that.
> >     Looking at
> >     > the structures in `fit`, I see:
> >     >
> >     > > tidy(fit$analyses[[5]])
> >     > # A tibble: 4 x 6
> >     >   effect   group    term            estimate std.error statistic
> >     >   <chr>    <chr>    <chr>              <dbl>     <dbl>     <dbl>
> >     > 1 fixed    NA       (Intercept)        4.91     0.0855      57.4
> >     > 2 fixed    NA       sex                0.853    0.0350      24.4
> >     > 3 ran_pars school   sd__(Intercept)    0.820   NA           NA
> >     > 4 ran_pars Residual sd__Observation    0.767   NA           NA
> >     >
> >     > None of the random effects line up with the output of pool().
> >     Moreover,
> >     > the pool() documentation notes that it needs the standard error of
> >     each
> >     > estimate, but lme4 doesn't produce those (for good reason) for
> random
> >     > effects, so pool() won't produce pooled estimates for the random
> >     effects.
> >     >
> >     > The pool() documentation mentions the mipo class, so I looked at
> ?mipo
> >     > and found this:
> >     >
> >     >
> >     >        ?estimate?  Pooled complete data estimate
> >     >        ?ubar?      Within-imputation variance of ?estimate?
> >     >        ?b?         Between-imputation variance of ?estimate?
> >     >        ?t?         Total variance, of ?estimate?
> >     >        ?dfcom?     Degrees of freedom in complete data
> >     >        ?df?        Degrees of freedom of $t$-statistic
> >     >        ?riv?       Relative increase in variance
> >     >        ?lambda?    Proportion attributable to the missingness
> >     >        ?fmi?       Fraction of missing information
> >     >
> >     >
> >     > So `ubar` and `b` are perhaps random effects, but not in the sense
> >     > you're thinking of, but rather the random effects that go into
> >     > imputation procedures (this is a guess on my part). I don't know
> much
> >     > about imputation, but I suspect this is analogous to the parallels
> >     > between mixed models and meta-analysis
> >     > (http://www.metafor-project.org/doku.php/tips:rma_vs_lm_lme_lmer).
> But
> >     > again, this is rapidly getting out of my area of expertise and
> >     into the
> >     > expertise of other members of this list (e.g. Wolfgang Viechtbauer
> for
> >     > meta analysis).
> >     >
> >     > Phillip
> >     >
> >     > On 10/11/20 7:17 am, Simon Harmel wrote:
> >     > > Dear All,
> >     > >
> >     > > Belwo, I've used library `broom.mixed` and imputed some data
> >     with library
> >     > > `mice` to then fit a "random-intercept" `lmer()` model.
> >     > >
> >     > > BUT I wonder why after I `pool()` my analyses, there is an extra
> >     "ubar"
> >     > > (random-effect) for slope (`sex`) which is not even in the
> model?!
> >     > >
> >     > > library(mice)
> >     > > library(lme4)
> >     > > library(broom.mixed)
> >     > >
> >     > > imp <- mice(popmis, m = 5) # `popmis` is a dataset from `mice`
> >     > >
> >     > > fit <- with(data = imp, exp = lme4::lmer(popular ~ sex +
> >     (1|school)))
> >     > >
> >     > > pool(fit)
> >     > >
> >     > > ### `ubar` is the random effect for intercept (0.007524509) BUT
> >     WHY we see
> >     > > a ubar ALSO for `sex` (0.001177781)?
> >     > >
> >     > > Class: mipo    m = 5
> >     > >          term m  estimate        ubar            b           t
> dfcom
> >     > >  df
> >     > > 1 (Intercept) 5 4.9007789 0.007524509 0.0004845564 0.008105977
> 1996
> >     > > 547.44383
> >     > > 2         sex 5 0.8617941 0.001177781 0.0015867795 0.003081916
> 1996
> >     > >  10.33653
> >     > >         riv     lambda       fmi
> >     > > 1 0.0772765 0.07173321 0.0751060
> >     > > 2 1.6167147 0.61784141 0.6751515
> >     > >
> >     > >       [[alternative HTML version deleted]]
> >     > >
> >     > > _______________________________________________
> >     > > R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org> mailing list
> >     > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     > >
> >
>

	[[alternative HTML version deleted]]


From ph||||p@@|d@y @end|ng |rom mp|@n|  Wed Nov 11 00:44:24 2020
From: ph||||p@@|d@y @end|ng |rom mp|@n| (Phillip Alday)
Date: Wed, 11 Nov 2020 00:44:24 +0100
Subject: [R-sig-ME] Using broom.mixed library with lme4
In-Reply-To: <CACgv6yUUZcDH7kXoRjpxHMyv7P0OQdStnunB2DhVX8oJ+pTbUQ@mail.gmail.com>
References: <CAJByKzoJT3ZQHC4nQ4vK6J4ztfwftQh=P_kxiwPxkP=bzeMifA@mail.gmail.com>
 <CACgv6yUBoikSPog1Bc3MQopVwHNSe28EG9yoxLQwJ3OOkiy_Og@mail.gmail.com>
 <d427f35e-8b3b-bc45-b9e0-cc21f06d4f10@mpi.nl>
 <CACgv6yUUZcDH7kXoRjpxHMyv7P0OQdStnunB2DhVX8oJ+pTbUQ@mail.gmail.com>
Message-ID: <4914f62e-1bd6-4795-cb1d-927b0c2d2fd4@mpi.nl>

As I indicated in my initial response, I'm guessing no because mice
depends on the model fitting function returning standard errors for
imputed estimates and lme4 does not do that for random effects. (The
sampling distribution of the random effects is very skewed, so standard
errors really don't make much sense as a summary.)

Although I really, really don't recommend it, there are R packages
implementing standard errors for variance components in lme4. (To show
my lack of recommendation, I'm not providing links.) With those, you
could then compute the pooled estimates / implement the necessary
functions to have mice do it for you.

Phillip

On 11/11/20 12:16 am, Simon Harmel wrote:
> Sorry guys, I found what the problem was! I didn't use `summary()` after
> the pool() call! However, it there a way to find out how the estimates
> of random-effects can be pooled across the imputations?
> 
> On Tue, Nov 10, 2020 at 5:01 PM Phillip Alday <phillip.alday at mpi.nl
> <mailto:phillip.alday at mpi.nl>> wrote:
> 
>     I'm a bit confused now and think a point is being missed, although I'm
>     not sure where.
> 
>     Zach pointed out that the Rubin Rule is being applied. Both Zach and I
>     pointed out that you still get the pooled estimate and that the ubar and
>     b columns are uncertainty on the pooled estimate. In some quick tries
>     with example datasets, it seems that you don't get the ubar and b
>     columns for lm() fits, but I'm guessing that this means that it's not
>     possible to break down the variance of t (total variance of estimate)
>     into between and within estimates for non mixed models.
> 
>     In other words, it seems that pool does more for lmer() than it does for
>     lm(), not less.
> 
>     Your original question asked about the random effects, and we pointed
>     out that the the pool() table doesn't have the random effects from the
>     lmer() fit.
> 
>     This becomes even clearer if you call summary() on the value of pool():
> 
>     > summary(pool(fit))
>     ? ? ? ? ?term? estimate? std.error statistic? ? ? ? df? ? ? p.value
>     1 (Intercept) 4.8932366 0.08966606? 54.57178 521.81717 0.000000e+00
>     2? ? ? ? ?sex 0.8772664 0.05428838? 16.15938? 11.17712 4.226618e-09
> 
>     (and that use of summary() is from the documentation Zach linked).
> 
>     Can you try to pose your question a different way if we're
>     misunderstanding?
> 
>     Best,
>     Phillip
> 
>     On 10/11/20 11:26 pm, Simon Harmel wrote:
>     > Thanks.? I think a point is being missed. I did have carefully
>     read the
>     > documentation.? And pool() is in fact supposed to apply the RUBIN RULE
>     > and pool across the estimates from 5 imputed datasets.
>     >
>     > For lm() objects, pool() does what I describe above. But it seems, it
>     > doesn't do the same for the lmer() objects.?
>     >
>     > That was really the core of my question and l was wondering if a
>     > solution to it might be available?
>     >
>     >
>     > There is no documentation on that.
>     >
>     > On Tue, Nov 10, 2020, 3:28 PM Zach Simpson <zpsimpso at gmail.com
>     <mailto:zpsimpso at gmail.com>
>     > <mailto:zpsimpso at gmail.com <mailto:zpsimpso at gmail.com>>> wrote:
>     >
>     >? ? ?Just to add to Phillip's answer, the ubar has to do with the
>     multiple
>     >? ? ?imputation procedure: ubar is the within-imputation variance
>     of the
>     >? ? ?sex term. You fitted 5 lmer models on 5 'completed' datasets whose
>     >? ? ?NA's were filled using default imputation procedures from mice.
>     >? ? ?mice::pool() combines these m=5 fits using Rubin's rules. There's
>     >? ? ?uncertainty in model estimates due to the data itself as well
>     as the
>     >? ? ?imputation uncertainty.
>     >
>     >? ? ?Stef van Buuren has put online an enormous amount of
>     documentation,
>     >? ? ?which would pay dividends to read:
>     >
>     >? ? ?https://amices.org/mice/
>     >
>     >? ? ?HTH
>     >? ? ?Zach
>     >
>     >? ? ?> Why do you think ubar is for the random effects? In my very
>     quick skim
>     >? ? ?> of the documentation, I didn't see anything indicating that.
>     >? ? ?Looking at
>     >? ? ?> the structures in `fit`, I see:
>     >? ? ?>
>     >? ? ?> > tidy(fit$analyses[[5]])
>     >? ? ?> # A tibble: 4 x 6
>     >? ? ?>? ?effect? ?group? ? term? ? ? ? ? ? estimate std.error statistic
>     >? ? ?>? ?<chr>? ? <chr>? ? <chr>? ? ? ? ? ? ? <dbl>? ? ?<dbl>? ? ?<dbl>
>     >? ? ?> 1 fixed? ? NA? ? ? ?(Intercept)? ? ? ? 4.91? ? ?0.0855? ? ? 57.4
>     >? ? ?> 2 fixed? ? NA? ? ? ?sex? ? ? ? ? ? ? ? 0.853? ? 0.0350? ? ? 24.4
>     >? ? ?> 3 ran_pars school? ?sd__(Intercept)? ? 0.820? ?NA? ? ? ? ? ?NA
>     >? ? ?> 4 ran_pars Residual sd__Observation? ? 0.767? ?NA? ? ? ? ? ?NA
>     >? ? ?>
>     >? ? ?> None of the random effects line up with the output of pool().
>     >? ? ?Moreover,
>     >? ? ?> the pool() documentation notes that it needs the standard
>     error of
>     >? ? ?each
>     >? ? ?> estimate, but lme4 doesn't produce those (for good reason)
>     for random
>     >? ? ?> effects, so pool() won't produce pooled estimates for the random
>     >? ? ?effects.
>     >? ? ?>
>     >? ? ?> The pool() documentation mentions the mipo class, so I
>     looked at ?mipo
>     >? ? ?> and found this:
>     >? ? ?>
>     >? ? ?>
>     >? ? ?>? ? ? ? ?estimate?? Pooled complete data estimate
>     >? ? ?>? ? ? ? ?ubar?? ? ? Within-imputation variance of ?estimate?
>     >? ? ?>? ? ? ? ?b?? ? ? ? ?Between-imputation variance of ?estimate?
>     >? ? ?>? ? ? ? ?t?? ? ? ? ?Total variance, of ?estimate?
>     >? ? ?>? ? ? ? ?dfcom?? ? ?Degrees of freedom in complete data
>     >? ? ?>? ? ? ? ?df?? ? ? ? Degrees of freedom of $t$-statistic
>     >? ? ?>? ? ? ? ?riv?? ? ? ?Relative increase in variance
>     >? ? ?>? ? ? ? ?lambda?? ? Proportion attributable to the missingness
>     >? ? ?>? ? ? ? ?fmi?? ? ? ?Fraction of missing information
>     >? ? ?>
>     >? ? ?>
>     >? ? ?> So `ubar` and `b` are perhaps random effects, but not in the
>     sense
>     >? ? ?> you're thinking of, but rather the random effects that go into
>     >? ? ?> imputation procedures (this is a guess on my part). I don't
>     know much
>     >? ? ?> about imputation, but I suspect this is analogous to the
>     parallels
>     >? ? ?> between mixed models and meta-analysis
>     >? ? ?>
>     (http://www.metafor-project.org/doku.php/tips:rma_vs_lm_lme_lmer). But
>     >? ? ?> again, this is rapidly getting out of my area of expertise and
>     >? ? ?into the
>     >? ? ?> expertise of other members of this list (e.g. Wolfgang
>     Viechtbauer for
>     >? ? ?> meta analysis).
>     >? ? ?>
>     >? ? ?> Phillip
>     >? ? ?>
>     >? ? ?> On 10/11/20 7:17 am, Simon Harmel wrote:
>     >? ? ?> > Dear All,
>     >? ? ?> >
>     >? ? ?> > Belwo, I've used library `broom.mixed` and imputed some data
>     >? ? ?with library
>     >? ? ?> > `mice` to then fit a "random-intercept" `lmer()` model.
>     >? ? ?> >
>     >? ? ?> > BUT I wonder why after I `pool()` my analyses, there is an
>     extra
>     >? ? ?"ubar"
>     >? ? ?> > (random-effect) for slope (`sex`) which is not even in the
>     model?!
>     >? ? ?> >
>     >? ? ?> > library(mice)
>     >? ? ?> > library(lme4)
>     >? ? ?> > library(broom.mixed)
>     >? ? ?> >
>     >? ? ?> > imp <- mice(popmis, m = 5) # `popmis` is a dataset from `mice`
>     >? ? ?> >
>     >? ? ?> > fit <- with(data = imp, exp = lme4::lmer(popular ~ sex +
>     >? ? ?(1|school)))
>     >? ? ?> >
>     >? ? ?> > pool(fit)
>     >? ? ?> >
>     >? ? ?> > ### `ubar` is the random effect for intercept
>     (0.007524509) BUT
>     >? ? ?WHY we see
>     >? ? ?> > a ubar ALSO for `sex` (0.001177781)?
>     >? ? ?> >
>     >? ? ?> > Class: mipo? ? m = 5
>     >? ? ?> >? ? ? ? ? term m? estimate? ? ? ? ubar? ? ? ? ? ? b? ? ? ?
>     ? ?t dfcom
>     >? ? ?> >? df
>     >? ? ?> > 1 (Intercept) 5 4.9007789 0.007524509 0.0004845564
>     0.008105977? 1996
>     >? ? ?> > 547.44383
>     >? ? ?> > 2? ? ? ? ?sex 5 0.8617941 0.001177781 0.0015867795
>     0.003081916? 1996
>     >? ? ?> >? 10.33653
>     >? ? ?> >? ? ? ? ?riv? ? ?lambda? ? ? ?fmi
>     >? ? ?> > 1 0.0772765 0.07173321 0.0751060
>     >? ? ?> > 2 1.6167147 0.61784141 0.6751515
>     >? ? ?> >
>     >? ? ?> >? ? ? ?[[alternative HTML version deleted]]
>     >? ? ?> >
>     >? ? ?> > _______________________________________________
>     >? ? ?> > R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>     >? ? ?<mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>> mailing list
>     >? ? ?> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     >? ? ?> >
>     >
>


From @|m@h@rme| @end|ng |rom gm@||@com  Wed Nov 11 01:42:14 2020
From: @|m@h@rme| @end|ng |rom gm@||@com (Simon Harmel)
Date: Tue, 10 Nov 2020 18:42:14 -0600
Subject: [R-sig-ME] Using broom.mixed library with lme4
In-Reply-To: <4914f62e-1bd6-4795-cb1d-927b0c2d2fd4@mpi.nl>
References: <CAJByKzoJT3ZQHC4nQ4vK6J4ztfwftQh=P_kxiwPxkP=bzeMifA@mail.gmail.com>
 <CACgv6yUBoikSPog1Bc3MQopVwHNSe28EG9yoxLQwJ3OOkiy_Og@mail.gmail.com>
 <d427f35e-8b3b-bc45-b9e0-cc21f06d4f10@mpi.nl>
 <CACgv6yUUZcDH7kXoRjpxHMyv7P0OQdStnunB2DhVX8oJ+pTbUQ@mail.gmail.com>
 <4914f62e-1bd6-4795-cb1d-927b0c2d2fd4@mpi.nl>
Message-ID: <CACgv6yV=kdRRYZrxOMnOD2KMGLoAeGWs-vJti_yPaHRYMJEJLA@mail.gmail.com>

Much appreciated Phillip!

On Tue, Nov 10, 2020 at 6:23 PM Phillip Alday <phillip.alday at mpi.nl> wrote:

> As I indicated in my initial response, I'm guessing no because mice
> depends on the model fitting function returning standard errors for
> imputed estimates and lme4 does not do that for random effects. (The
> sampling distribution of the random effects is very skewed, so standard
> errors really don't make much sense as a summary.)
>
> Although I really, really don't recommend it, there are R packages
> implementing standard errors for variance components in lme4. (To show
> my lack of recommendation, I'm not providing links.) With those, you
> could then compute the pooled estimates / implement the necessary
> functions to have mice do it for you.
>
> Phillip
>
> On 11/11/20 12:16 am, Simon Harmel wrote:
> > Sorry guys, I found what the problem was! I didn't use `summary()` after
> > the pool() call! However, it there a way to find out how the estimates
> > of random-effects can be pooled across the imputations?
> >
> > On Tue, Nov 10, 2020 at 5:01 PM Phillip Alday <phillip.alday at mpi.nl
> > <mailto:phillip.alday at mpi.nl>> wrote:
> >
> >     I'm a bit confused now and think a point is being missed, although
> I'm
> >     not sure where.
> >
> >     Zach pointed out that the Rubin Rule is being applied. Both Zach and
> I
> >     pointed out that you still get the pooled estimate and that the ubar
> and
> >     b columns are uncertainty on the pooled estimate. In some quick tries
> >     with example datasets, it seems that you don't get the ubar and b
> >     columns for lm() fits, but I'm guessing that this means that it's not
> >     possible to break down the variance of t (total variance of estimate)
> >     into between and within estimates for non mixed models.
> >
> >     In other words, it seems that pool does more for lmer() than it does
> for
> >     lm(), not less.
> >
> >     Your original question asked about the random effects, and we pointed
> >     out that the the pool() table doesn't have the random effects from
> the
> >     lmer() fit.
> >
> >     This becomes even clearer if you call summary() on the value of
> pool():
> >
> >     > summary(pool(fit))
> >              term  estimate  std.error statistic        df      p.value
> >     1 (Intercept) 4.8932366 0.08966606  54.57178 521.81717 0.000000e+00
> >     2         sex 0.8772664 0.05428838  16.15938  11.17712 4.226618e-09
> >
> >     (and that use of summary() is from the documentation Zach linked).
> >
> >     Can you try to pose your question a different way if we're
> >     misunderstanding?
> >
> >     Best,
> >     Phillip
> >
> >     On 10/11/20 11:26 pm, Simon Harmel wrote:
> >     > Thanks.  I think a point is being missed. I did have carefully
> >     read the
> >     > documentation.  And pool() is in fact supposed to apply the RUBIN
> RULE
> >     > and pool across the estimates from 5 imputed datasets.
> >     >
> >     > For lm() objects, pool() does what I describe above. But it seems,
> it
> >     > doesn't do the same for the lmer() objects.
> >     >
> >     > That was really the core of my question and l was wondering if a
> >     > solution to it might be available?
> >     >
> >     >
> >     > There is no documentation on that.
> >     >
> >     > On Tue, Nov 10, 2020, 3:28 PM Zach Simpson <zpsimpso at gmail.com
> >     <mailto:zpsimpso at gmail.com>
> >     > <mailto:zpsimpso at gmail.com <mailto:zpsimpso at gmail.com>>> wrote:
> >     >
> >     >     Just to add to Phillip's answer, the ubar has to do with the
> >     multiple
> >     >     imputation procedure: ubar is the within-imputation variance
> >     of the
> >     >     sex term. You fitted 5 lmer models on 5 'completed' datasets
> whose
> >     >     NA's were filled using default imputation procedures from mice.
> >     >     mice::pool() combines these m=5 fits using Rubin's rules.
> There's
> >     >     uncertainty in model estimates due to the data itself as well
> >     as the
> >     >     imputation uncertainty.
> >     >
> >     >     Stef van Buuren has put online an enormous amount of
> >     documentation,
> >     >     which would pay dividends to read:
> >     >
> >     >     https://amices.org/mice/
> >     >
> >     >     HTH
> >     >     Zach
> >     >
> >     >     > Why do you think ubar is for the random effects? In my very
> >     quick skim
> >     >     > of the documentation, I didn't see anything indicating that.
> >     >     Looking at
> >     >     > the structures in `fit`, I see:
> >     >     >
> >     >     > > tidy(fit$analyses[[5]])
> >     >     > # A tibble: 4 x 6
> >     >     >   effect   group    term            estimate std.error
> statistic
> >     >     >   <chr>    <chr>    <chr>              <dbl>     <dbl>
>  <dbl>
> >     >     > 1 fixed    NA       (Intercept)        4.91     0.0855
> 57.4
> >     >     > 2 fixed    NA       sex                0.853    0.0350
> 24.4
> >     >     > 3 ran_pars school   sd__(Intercept)    0.820   NA
>  NA
> >     >     > 4 ran_pars Residual sd__Observation    0.767   NA
>  NA
> >     >     >
> >     >     > None of the random effects line up with the output of pool().
> >     >     Moreover,
> >     >     > the pool() documentation notes that it needs the standard
> >     error of
> >     >     each
> >     >     > estimate, but lme4 doesn't produce those (for good reason)
> >     for random
> >     >     > effects, so pool() won't produce pooled estimates for the
> random
> >     >     effects.
> >     >     >
> >     >     > The pool() documentation mentions the mipo class, so I
> >     looked at ?mipo
> >     >     > and found this:
> >     >     >
> >     >     >
> >     >     >        ?estimate?  Pooled complete data estimate
> >     >     >        ?ubar?      Within-imputation variance of ?estimate?
> >     >     >        ?b?         Between-imputation variance of ?estimate?
> >     >     >        ?t?         Total variance, of ?estimate?
> >     >     >        ?dfcom?     Degrees of freedom in complete data
> >     >     >        ?df?        Degrees of freedom of $t$-statistic
> >     >     >        ?riv?       Relative increase in variance
> >     >     >        ?lambda?    Proportion attributable to the missingness
> >     >     >        ?fmi?       Fraction of missing information
> >     >     >
> >     >     >
> >     >     > So `ubar` and `b` are perhaps random effects, but not in the
> >     sense
> >     >     > you're thinking of, but rather the random effects that go
> into
> >     >     > imputation procedures (this is a guess on my part). I don't
> >     know much
> >     >     > about imputation, but I suspect this is analogous to the
> >     parallels
> >     >     > between mixed models and meta-analysis
> >     >     >
> >     (http://www.metafor-project.org/doku.php/tips:rma_vs_lm_lme_lmer).
> But
> >     >     > again, this is rapidly getting out of my area of expertise
> and
> >     >     into the
> >     >     > expertise of other members of this list (e.g. Wolfgang
> >     Viechtbauer for
> >     >     > meta analysis).
> >     >     >
> >     >     > Phillip
> >     >     >
> >     >     > On 10/11/20 7:17 am, Simon Harmel wrote:
> >     >     > > Dear All,
> >     >     > >
> >     >     > > Belwo, I've used library `broom.mixed` and imputed some
> data
> >     >     with library
> >     >     > > `mice` to then fit a "random-intercept" `lmer()` model.
> >     >     > >
> >     >     > > BUT I wonder why after I `pool()` my analyses, there is an
> >     extra
> >     >     "ubar"
> >     >     > > (random-effect) for slope (`sex`) which is not even in the
> >     model?!
> >     >     > >
> >     >     > > library(mice)
> >     >     > > library(lme4)
> >     >     > > library(broom.mixed)
> >     >     > >
> >     >     > > imp <- mice(popmis, m = 5) # `popmis` is a dataset from
> `mice`
> >     >     > >
> >     >     > > fit <- with(data = imp, exp = lme4::lmer(popular ~ sex +
> >     >     (1|school)))
> >     >     > >
> >     >     > > pool(fit)
> >     >     > >
> >     >     > > ### `ubar` is the random effect for intercept
> >     (0.007524509) BUT
> >     >     WHY we see
> >     >     > > a ubar ALSO for `sex` (0.001177781)?
> >     >     > >
> >     >     > > Class: mipo    m = 5
> >     >     > >          term m  estimate        ubar            b
> >        t dfcom
> >     >     > >  df
> >     >     > > 1 (Intercept) 5 4.9007789 0.007524509 0.0004845564
> >     0.008105977  1996
> >     >     > > 547.44383
> >     >     > > 2         sex 5 0.8617941 0.001177781 0.0015867795
> >     0.003081916  1996
> >     >     > >  10.33653
> >     >     > >         riv     lambda       fmi
> >     >     > > 1 0.0772765 0.07173321 0.0751060
> >     >     > > 2 1.6167147 0.61784141 0.6751515
> >     >     > >
> >     >     > >       [[alternative HTML version deleted]]
> >     >     > >
> >     >     > > _______________________________________________
> >     >     > > R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >     >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>> mailing list
> >     >     > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     >     > >
> >     >
> >
>

	[[alternative HTML version deleted]]


From @ndrew@r@john@on @end|ng |rom po@tgr@d@curt|n@edu@@u  Wed Nov 11 07:52:19 2020
From: @ndrew@r@john@on @end|ng |rom po@tgr@d@curt|n@edu@@u (Andrew Johnson)
Date: Wed, 11 Nov 2020 06:52:19 +0000
Subject: [R-sig-ME] Using broom.mixed library with lme4
In-Reply-To: <CACgv6yV=kdRRYZrxOMnOD2KMGLoAeGWs-vJti_yPaHRYMJEJLA@mail.gmail.com>
References: <CAJByKzoJT3ZQHC4nQ4vK6J4ztfwftQh=P_kxiwPxkP=bzeMifA@mail.gmail.com>
 <CACgv6yUBoikSPog1Bc3MQopVwHNSe28EG9yoxLQwJ3OOkiy_Og@mail.gmail.com>
 <d427f35e-8b3b-bc45-b9e0-cc21f06d4f10@mpi.nl>
 <CACgv6yUUZcDH7kXoRjpxHMyv7P0OQdStnunB2DhVX8oJ+pTbUQ@mail.gmail.com>
 <4914f62e-1bd6-4795-cb1d-927b0c2d2fd4@mpi.nl>
 <CACgv6yV=kdRRYZrxOMnOD2KMGLoAeGWs-vJti_yPaHRYMJEJLA@mail.gmail.com>
Message-ID: <PSBPR01MB37035ABB88E07E0324E71F15A3E80@PSBPR01MB3703.apcprd01.prod.exchangelabs.com>

If you're only interested in the pooled estimate of the random effect, not its standard error (or within-imputation variance) then you can just take its mean across the imputations.

Additionally, the miceadds package has a functionality for pooling both fixed and random effects from lme4. The summary gives standard errors for the random effects, but I don't know how they've been derived and (as Phillip said) I wouldn't recommend using or relying on them for inference.

A quick example is:

library(lme4)
library(miceadds)

data("sleepstudy")
sleepstudy$Reaction[sample(1:180,30)] = NA

imp <- mice(sleepstudy, m = 5, print=F)
fit <- with(imp, lmer(Reaction ~ Days + (Days | Subject)))

summary(lmer_pool(fit$analyses))



Dr Andrew Johnson
BPsych(Hons), MBiostat, PhD, GStat.
Research Associate | School of Psychology

Curtin University 
Email | andrew.johnson at curtin.edu.au 
Web | www.curtin.edu.au 



CRICOS Provider Code 00301J 


-----Original Message-----
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> On Behalf Of Simon Harmel
Sent: Wednesday, 11 November 2020 8:42 AM
To: Phillip Alday <phillip.alday at mpi.nl>
Cc: r-sig-mixed-models <r-sig-mixed-models at r-project.org>; Zach Simpson <zpsimpso at gmail.com>
Subject: Re: [R-sig-ME] Using broom.mixed library with lme4

Much appreciated Phillip!

On Tue, Nov 10, 2020 at 6:23 PM Phillip Alday <phillip.alday at mpi.nl> wrote:

> As I indicated in my initial response, I'm guessing no because mice 
> depends on the model fitting function returning standard errors for 
> imputed estimates and lme4 does not do that for random effects. (The 
> sampling distribution of the random effects is very skewed, so 
> standard errors really don't make much sense as a summary.)
>
> Although I really, really don't recommend it, there are R packages 
> implementing standard errors for variance components in lme4. (To show 
> my lack of recommendation, I'm not providing links.) With those, you 
> could then compute the pooled estimates / implement the necessary 
> functions to have mice do it for you.
>
> Phillip
>
> On 11/11/20 12:16 am, Simon Harmel wrote:
> > Sorry guys, I found what the problem was! I didn't use `summary()` 
> > after the pool() call! However, it there a way to find out how the 
> > estimates of random-effects can be pooled across the imputations?
> >
> > On Tue, Nov 10, 2020 at 5:01 PM Phillip Alday <phillip.alday at mpi.nl 
> > <mailto:phillip.alday at mpi.nl>> wrote:
> >
> >     I'm a bit confused now and think a point is being missed, 
> > although
> I'm
> >     not sure where.
> >
> >     Zach pointed out that the Rubin Rule is being applied. Both Zach 
> > and
> I
> >     pointed out that you still get the pooled estimate and that the 
> > ubar
> and
> >     b columns are uncertainty on the pooled estimate. In some quick tries
> >     with example datasets, it seems that you don't get the ubar and b
> >     columns for lm() fits, but I'm guessing that this means that it's not
> >     possible to break down the variance of t (total variance of estimate)
> >     into between and within estimates for non mixed models.
> >
> >     In other words, it seems that pool does more for lmer() than it 
> > does
> for
> >     lm(), not less.
> >
> >     Your original question asked about the random effects, and we pointed
> >     out that the the pool() table doesn't have the random effects 
> > from
> the
> >     lmer() fit.
> >
> >     This becomes even clearer if you call summary() on the value of
> pool():
> >
> >     > summary(pool(fit))
> >              term  estimate  std.error statistic        df      p.value
> >     1 (Intercept) 4.8932366 0.08966606  54.57178 521.81717 0.000000e+00
> >     2         sex 0.8772664 0.05428838  16.15938  11.17712 4.226618e-09
> >
> >     (and that use of summary() is from the documentation Zach linked).
> >
> >     Can you try to pose your question a different way if we're
> >     misunderstanding?
> >
> >     Best,
> >     Phillip
> >
> >     On 10/11/20 11:26 pm, Simon Harmel wrote:
> >     > Thanks.  I think a point is being missed. I did have carefully
> >     read the
> >     > documentation.  And pool() is in fact supposed to apply the 
> > RUBIN
> RULE
> >     > and pool across the estimates from 5 imputed datasets.
> >     >
> >     > For lm() objects, pool() does what I describe above. But it 
> > seems,
> it
> >     > doesn't do the same for the lmer() objects.
> >     >
> >     > That was really the core of my question and l was wondering if a
> >     > solution to it might be available?
> >     >
> >     >
> >     > There is no documentation on that.
> >     >
> >     > On Tue, Nov 10, 2020, 3:28 PM Zach Simpson <zpsimpso at gmail.com
> >     <mailto:zpsimpso at gmail.com>
> >     > <mailto:zpsimpso at gmail.com <mailto:zpsimpso at gmail.com>>> wrote:
> >     >
> >     >     Just to add to Phillip's answer, the ubar has to do with the
> >     multiple
> >     >     imputation procedure: ubar is the within-imputation variance
> >     of the
> >     >     sex term. You fitted 5 lmer models on 5 'completed' datasets
> whose
> >     >     NA's were filled using default imputation procedures from mice.
> >     >     mice::pool() combines these m=5 fits using Rubin's rules.
> There's
> >     >     uncertainty in model estimates due to the data itself as well
> >     as the
> >     >     imputation uncertainty.
> >     >
> >     >     Stef van Buuren has put online an enormous amount of
> >     documentation,
> >     >     which would pay dividends to read:
> >     >
> >     >     https://amices.org/mice/
> >     >
> >     >     HTH
> >     >     Zach
> >     >
> >     >     > Why do you think ubar is for the random effects? In my very
> >     quick skim
> >     >     > of the documentation, I didn't see anything indicating that.
> >     >     Looking at
> >     >     > the structures in `fit`, I see:
> >     >     >
> >     >     > > tidy(fit$analyses[[5]])
> >     >     > # A tibble: 4 x 6
> >     >     >   effect   group    term            estimate std.error
> statistic
> >     >     >   <chr>    <chr>    <chr>              <dbl>     <dbl>
>  <dbl>
> >     >     > 1 fixed    NA       (Intercept)        4.91     0.0855
> 57.4
> >     >     > 2 fixed    NA       sex                0.853    0.0350
> 24.4
> >     >     > 3 ran_pars school   sd__(Intercept)    0.820   NA
>  NA
> >     >     > 4 ran_pars Residual sd__Observation    0.767   NA
>  NA
> >     >     >
> >     >     > None of the random effects line up with the output of pool().
> >     >     Moreover,
> >     >     > the pool() documentation notes that it needs the standard
> >     error of
> >     >     each
> >     >     > estimate, but lme4 doesn't produce those (for good reason)
> >     for random
> >     >     > effects, so pool() won't produce pooled estimates for the
> random
> >     >     effects.
> >     >     >
> >     >     > The pool() documentation mentions the mipo class, so I
> >     looked at ?mipo
> >     >     > and found this:
> >     >     >
> >     >     >
> >     >     >        ?estimate?  Pooled complete data estimate
> >     >     >        ?ubar?      Within-imputation variance of ?estimate?
> >     >     >        ?b?         Between-imputation variance of ?estimate?
> >     >     >        ?t?         Total variance, of ?estimate?
> >     >     >        ?dfcom?     Degrees of freedom in complete data
> >     >     >        ?df?        Degrees of freedom of $t$-statistic
> >     >     >        ?riv?       Relative increase in variance
> >     >     >        ?lambda?    Proportion attributable to the missingness
> >     >     >        ?fmi?       Fraction of missing information
> >     >     >
> >     >     >
> >     >     > So `ubar` and `b` are perhaps random effects, but not in the
> >     sense
> >     >     > you're thinking of, but rather the random effects that go
> into
> >     >     > imputation procedures (this is a guess on my part). I don't
> >     know much
> >     >     > about imputation, but I suspect this is analogous to the
> >     parallels
> >     >     > between mixed models and meta-analysis
> >     >     >
> >     (http://www.metafor-project.org/doku.php/tips:rma_vs_lm_lme_lmer).
> But
> >     >     > again, this is rapidly getting out of my area of expertise
> and
> >     >     into the
> >     >     > expertise of other members of this list (e.g. Wolfgang
> >     Viechtbauer for
> >     >     > meta analysis).
> >     >     >
> >     >     > Phillip
> >     >     >
> >     >     > On 10/11/20 7:17 am, Simon Harmel wrote:
> >     >     > > Dear All,
> >     >     > >
> >     >     > > Belwo, I've used library `broom.mixed` and imputed some
> data
> >     >     with library
> >     >     > > `mice` to then fit a "random-intercept" `lmer()` model.
> >     >     > >
> >     >     > > BUT I wonder why after I `pool()` my analyses, there is an
> >     extra
> >     >     "ubar"
> >     >     > > (random-effect) for slope (`sex`) which is not even in the
> >     model?!
> >     >     > >
> >     >     > > library(mice)
> >     >     > > library(lme4)
> >     >     > > library(broom.mixed)
> >     >     > >
> >     >     > > imp <- mice(popmis, m = 5) # `popmis` is a dataset from
> `mice`
> >     >     > >
> >     >     > > fit <- with(data = imp, exp = lme4::lmer(popular ~ sex +
> >     >     (1|school)))
> >     >     > >
> >     >     > > pool(fit)
> >     >     > >
> >     >     > > ### `ubar` is the random effect for intercept
> >     (0.007524509) BUT
> >     >     WHY we see
> >     >     > > a ubar ALSO for `sex` (0.001177781)?
> >     >     > >
> >     >     > > Class: mipo    m = 5
> >     >     > >          term m  estimate        ubar            b
> >        t dfcom
> >     >     > >  df
> >     >     > > 1 (Intercept) 5 4.9007789 0.007524509 0.0004845564
> >     0.008105977  1996
> >     >     > > 547.44383
> >     >     > > 2         sex 5 0.8617941 0.001177781 0.0015867795
> >     0.003081916  1996
> >     >     > >  10.33653
> >     >     > >         riv     lambda       fmi
> >     >     > > 1 0.0772765 0.07173321 0.0751060
> >     >     > > 2 1.6167147 0.61784141 0.6751515
> >     >     > >
> >     >     > >       [[alternative HTML version deleted]]
> >     >     > >
> >     >     > > _______________________________________________
> >     >     > > R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >     >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>> mailing list
> >     >     > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     >     > >
> >     >
> >
>

	[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

From @bdu||@h|cen @end|ng |rom gm@||@com  Wed Nov 11 15:35:29 2020
From: @bdu||@h|cen @end|ng |rom gm@||@com (=?UTF-8?Q?Abdullah_i=C3=A7en?=)
Date: Wed, 11 Nov 2020 17:35:29 +0300
Subject: [R-sig-ME] Input function when using nlme() in nlme package
Message-ID: <CABXDCj-=Bqx9O-K0zsSRi_EVRe-B3oJZt0nGCcqsvs5bmaWL4Q@mail.gmail.com>

Hi all,

I've tried nlmer() function but it couldn't converge for some reason. Now
i'm trying to use nlme() function in nlme package my function is below

Sandikkaya_NLSite <- function(PSAr, Vs30, h800, b1, b2, b3, c){

  #Linear term
  .exprN1 <- ifelse(Vs30>1000, 1000/760, Vs30/760)
  .exprN2 <- log(.exprN1)
  .valueN <- b1*.exprN2

  # Depth-to-rock term (in log)   #!!!!!!!!!!!!!!!!!! z<1 = 1 i deleted it
dont forget to change!!!!!!!!!!!!!!
  # in SD18 they are estimated from CY08 equation for Z1
  h800[h800<1]<-1
  .exprZ1 <- ifelse(Vs30>=760, 1, h800)
  .exprZ2 <- log(.exprZ1)
  .valueZ <- b2*.exprZ2

  #Nonlinear term
  .exprNL1 <- ifelse(Vs30>760, 760-360, Vs30-360)
  .exprNL2 <- -0.00701*.exprNL1
  .exprNL3 <- exp(.exprNL2)
  .exprNL4 <- -0.00701*400
  .exprNL5 <- exp(.exprNL4)
  .exprNL6 <- .exprNL3 - .exprNL5
  .exprNL7 <- PSAr/c
  .exprNL8 <- 1+.exprNL7 #log(1+PSAr/c)
  .exprNL9 <- log(.exprNL8)
  .valueNL <- b3*.exprNL9*.exprNL6


  .value <- 0 + .valueN + .valueZ + .valueNL

  .grad <- array(0, c(length(.value), 4L), list(NULL, c("b1", "b2",
"b3","c")))

  ## e1 ##

  ## b1, b2 ,b3 ##
  .grad[, "b1"] <- .exprN2
  .grad[, "b2"] <- .exprZ2
  .grad[, "b3"] <- .exprNL9*.exprNL6
  .grad[, "c"] <- b3*.exprNL6*((1/(.exprNL8))*(-.exprNL7/c))


  attr(.value, "gradient") <- .grad
  .value
}



and i tried to run nlme() like

fm1 <- nlme(log(PSAm) ~ Sandikkaya_NLSite(PSAr, Vs30, h800, b1, b2, b3, c),
 data = data,
                       fixed = b1+ b2+ b3~1 ,
                       random = EQID~1 ,
                       start = c(b1 = 1, b2 = 1, b3 = 1, c=0.1))



b1,b2,b3 and c are my fixed effects and my random effects in lmer is
(1|EQID), EQID is earthquake ids in my data frame (data) my structure in
lmer is below


fm <-lmer(log(data$PSAm)~ 0  + data$VN + data$Z1 + data$VN03 + data$VN19 +
data$VN21 + data$VN28 + (1|data$EQID)  , data, REML=FALSE)


thank you for your attention.

	[[alternative HTML version deleted]]


From @|m@h@rme| @end|ng |rom gm@||@com  Sat Nov 14 22:02:09 2020
From: @|m@h@rme| @end|ng |rom gm@||@com (Simon Harmel)
Date: Sat, 14 Nov 2020 15:02:09 -0600
Subject: [R-sig-ME] Convergence in lme4: Something in the documentation
Message-ID: <CACgv6yXxqRkoB_cXucc6Lag9JwwZW5OV14ZwVXX5Ofho6_QwVw@mail.gmail.com>

Dear All,

This page (http://search.r-project.org/R/library/lme4/html/convergence.html)
does a fantastic job of explaining how to possibly overcome/explore the
lack of convergence in lme4 models.

However, I have a question about item "#4 restart the fit from the original
value".

For my `lmer()` model, the `getME(fiitted_model,"theta")` returns:

pars = c(0.55714322,  0.04364260, -0.00577823,  0.35910270, -0.03138007,
 0.02750460)

Following the documentation, when I then do:

(pars_x <- runif(length(pars), pars/1.01, pars*1.01)), I get:

[1] 0.55558159 0.04369471        NaN 0.36202453        NaN 0.02732069
Warning message:
In runif(length(pars), pars/1.01, pars * 1.01) : NAs produced

These NaN will mess up the next steps. Is there a solution to this?

Simon

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Sat Nov 14 22:11:38 2020
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Sat, 14 Nov 2020 16:11:38 -0500
Subject: [R-sig-ME] Convergence in lme4: Something in the documentation
In-Reply-To: <CACgv6yXxqRkoB_cXucc6Lag9JwwZW5OV14ZwVXX5Ofho6_QwVw@mail.gmail.com>
References: <CACgv6yXxqRkoB_cXucc6Lag9JwwZW5OV14ZwVXX5Ofho6_QwVw@mail.gmail.com>
Message-ID: <CABghstRY5X5Tb6+DVmYg+XPKOQfMhg3cSvO0Hk-t5j23oLODMg@mail.gmail.com>

  The problem here is that some of your pars values are negative, so
you're giving runif() a {min,max} pair that are in the wrong order.
Maybe:

   mins <- pmin(pars/1.01, pars*1.01)
   maxs <- pmax(pars/1.01, pars*1.01)
  runif(length(pars),mins, maxs)

  will do what you want.

On Sat, Nov 14, 2020 at 4:02 PM Simon Harmel <sim.harmel at gmail.com> wrote:
>
> Dear All,
>
> This page (http://search.r-project.org/R/library/lme4/html/convergence.html)
> does a fantastic job of explaining how to possibly overcome/explore the
> lack of convergence in lme4 models.
>
> However, I have a question about item "#4 restart the fit from the original
> value".
>
> For my `lmer()` model, the `getME(fiitted_model,"theta")` returns:
>
> pars = c(0.55714322,  0.04364260, -0.00577823,  0.35910270, -0.03138007,
>  0.02750460)
>
> Following the documentation, when I then do:
>
> (pars_x <- runif(length(pars), pars/1.01, pars*1.01)), I get:
>
> [1] 0.55558159 0.04369471        NaN 0.36202453        NaN 0.02732069
> Warning message:
> In runif(length(pars), pars/1.01, pars * 1.01) : NAs produced
>
> These NaN will mess up the next steps. Is there a solution to this?
>
> Simon
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From @|m@h@rme| @end|ng |rom gm@||@com  Sat Nov 14 22:16:09 2020
From: @|m@h@rme| @end|ng |rom gm@||@com (Simon Harmel)
Date: Sat, 14 Nov 2020 15:16:09 -0600
Subject: [R-sig-ME] Convergence in lme4: Something in the documentation
In-Reply-To: <CABghstRY5X5Tb6+DVmYg+XPKOQfMhg3cSvO0Hk-t5j23oLODMg@mail.gmail.com>
References: <CACgv6yXxqRkoB_cXucc6Lag9JwwZW5OV14ZwVXX5Ofho6_QwVw@mail.gmail.com>
 <CABghstRY5X5Tb6+DVmYg+XPKOQfMhg3cSvO0Hk-t5j23oLODMg@mail.gmail.com>
Message-ID: <CACgv6yUAVX-c+hkN9o+nKdonPhCQhW_=PztbT6=jY3gvtGAVdQ@mail.gmail.com>

Thank you, Ben!

On Sat, Nov 14, 2020 at 3:11 PM Ben Bolker <bbolker at gmail.com> wrote:

>   The problem here is that some of your pars values are negative, so
> you're giving runif() a {min,max} pair that are in the wrong order.
> Maybe:
>
>    mins <- pmin(pars/1.01, pars*1.01)
>    maxs <- pmax(pars/1.01, pars*1.01)
>   runif(length(pars),mins, maxs)
>
>   will do what you want.
>
> On Sat, Nov 14, 2020 at 4:02 PM Simon Harmel <sim.harmel at gmail.com> wrote:
> >
> > Dear All,
> >
> > This page (
> http://search.r-project.org/R/library/lme4/html/convergence.html)
> > does a fantastic job of explaining how to possibly overcome/explore the
> > lack of convergence in lme4 models.
> >
> > However, I have a question about item "#4 restart the fit from the
> original
> > value".
> >
> > For my `lmer()` model, the `getME(fiitted_model,"theta")` returns:
> >
> > pars = c(0.55714322,  0.04364260, -0.00577823,  0.35910270, -0.03138007,
> >  0.02750460)
> >
> > Following the documentation, when I then do:
> >
> > (pars_x <- runif(length(pars), pars/1.01, pars*1.01)), I get:
> >
> > [1] 0.55558159 0.04369471        NaN 0.36202453        NaN 0.02732069
> > Warning message:
> > In runif(length(pars), pars/1.01, pars * 1.01) : NAs produced
> >
> > These NaN will mess up the next steps. Is there a solution to this?
> >
> > Simon
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From @|e@@@ndro@noc| @end|ng |rom roche@com  Mon Nov 16 17:26:20 2020
From: @|e@@@ndro@noc| @end|ng |rom roche@com (Noci, Alessandro)
Date: Mon, 16 Nov 2020 17:26:20 +0100
Subject: [R-sig-ME] glmmTMB: fit mixed model with different covariance
 between two groups
Message-ID: <CAFGJF4oVBU6ESMDwJtU=1DS9QV_EWoUStXVZbGT=qZTCp7byDA@mail.gmail.com>

Hi all,

I am interested in fitting a linear mixed model with different unstructured
covariance between the two arms.

To give you an idea, suppose that I have longitudinal data related to
patients belonging to two different arms in a clinical trial. The dataset
has the following variables:

   1. *id*: the id of the patients.
   2. *group*: 2 levels factor indicating which arm each patient belongs to.
   3. *time: *time-variable.
   4. *var1:* baseline covariate.
   5. *y: *outcome variable.

# simulate data (toy example)

set.seed(123)
data = data.frame("id" = rep(1:40, each = 4), "group" = factor(rep(c(0,1),
each = 20*4)), "time" = factor(rep(1:4, 40)), "var1" = rnorm(40*4), "y" =
rnorm(40*4))

I can fit a linear mixed model with unstructured covariance calling:

# fit model

fit = glmmTMB(y ~ time*group + us(0 + time | id), data = data, dispformula
= ~0, REML = TRUE, control=
glmmTMBControl(optimizer=optim,optArgs=list(method="L-BFGS-B")))

However this is assuming that the covariance matrices of the two groups are
identical. I would like to fit the model assuming a
different (unstructured) covariance matrix for each arm and extract the two
estimated covariance matrices. Is it possible to do this?

Best,
Alessandro

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Tue Nov 17 00:12:00 2020
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Mon, 16 Nov 2020 18:12:00 -0500
Subject: [R-sig-ME] glmmTMB: fit mixed model with different covariance
 between two groups
In-Reply-To: <CAFGJF4oVBU6ESMDwJtU=1DS9QV_EWoUStXVZbGT=qZTCp7byDA@mail.gmail.com>
References: <CAFGJF4oVBU6ESMDwJtU=1DS9QV_EWoUStXVZbGT=qZTCp7byDA@mail.gmail.com>
Message-ID: <971d84a4-f128-62dd-465e-0f83a3328504@gmail.com>

 ? The standard way to do this would be to set up a 0/1 dummy variable 
that indicated the arm of the treatment and allow it to interact with 
the random effects, e.g. something like this:

data$g1 <- lme4::dummy(data$group,"0")

data$g2 <- lme4::dummy(data$group,"1")

y ~ time*group + us(0 + g1:time | id) + us(0 + g2:time | id)

The two RE terms appear to be redundant, but each one applies only to individuals in one group (because the effect of constructing an interaction with a numerical (0/1) covariate is essentially to multiply the effects by either 0 or 1).

   I haven't tested this, of course :-)


On 11/16/20 11:26 AM, Noci, Alessandro via R-sig-mixed-models wrote:
> Hi all,
>
> I am interested in fitting a linear mixed model with different unstructured
> covariance between the two arms.
>
> To give you an idea, suppose that I have longitudinal data related to
> patients belonging to two different arms in a clinical trial. The dataset
> has the following variables:
>
>     1. *id*: the id of the patients.
>     2. *group*: 2 levels factor indicating which arm each patient belongs to.
>     3. *time: *time-variable.
>     4. *var1:* baseline covariate.
>     5. *y: *outcome variable.
>
> # simulate data (toy example)
>
> set.seed(123)
> data = data.frame("id" = rep(1:40, each = 4), "group" = factor(rep(c(0,1),
> each = 20*4)), "time" = factor(rep(1:4, 40)), "var1" = rnorm(40*4), "y" =
> rnorm(40*4))
>
> I can fit a linear mixed model with unstructured covariance calling:
>
> # fit model
>
> fit = glmmTMB(y ~ time*group + us(0 + time | id), data = data, dispformula
> = ~0, REML = TRUE, control=
> glmmTMBControl(optimizer=optim,optArgs=list(method="L-BFGS-B")))
>
> However this is assuming that the covariance matrices of the two groups are
> identical. I would like to fit the model assuming a
> different (unstructured) covariance matrix for each arm and extract the two
> estimated covariance matrices. Is it possible to do this?
>
> Best,
> Alessandro
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From m@r|n@p@@tor @end|ng |rom |cm@c@|c@e@  Tue Nov 17 11:19:42 2020
From: m@r|n@p@@tor @end|ng |rom |cm@c@|c@e@ (Marina Pastor)
Date: Tue, 17 Nov 2020 11:19:42 +0100
Subject: [R-sig-ME] Trying to modify variance structure
Message-ID: <20201117111942.Horde.cmPZT0VHhQiyY9e-MvOOVtw@webmail.csic.es>


Hello,
We are studying the jellyfish distribution and we would like to know  
if it depends of temperature and salinity. As our database are counts  
and we have a high amount of 0, but also other high numbers around  
400, we used a Negative Binomial Generalised Lineal Model. As the  
filtered volume was not the same for all the counts, we incorporated  
this through an offset.
Checking the residual distribution we realised we were violating the  
homogeneity assumption since the larger the temperature, the larger  
the variation.
We first tried to apply different variance structures through  
varFixed, varPower and varExp functions (nlme package) depending on  
the temperature, but we did not manage.
The reproducible example is below.
- For varFixed(~Temp) we followed the R help example. Why we obtained  
this error?: Error in `$<-.data.frame`(`*tmp*`, VarFixedT, value =  
numeric(0)) :   replacement has 0 rows, data has 10
- For varPower(1, form =~Temp) and varExp(1, form =~ Temp), how to  
choose the best ?value? before ?form? in the formula (?1? in the  
example)?
We would be very grateful if you could help us, we don?t know how to  
improve our model and is one of the requirements to publish our  
article. Many thanks for your time in advance.
Best wishes,
Marina Pastor


Reproducible example:
library("nlme")
library("MASS")

my.df <- data.frame (Jelly = c(1.13, 10.98, 0.00, 0.97, 0.62, 1.04,  
0.00, 77.83, 4.12, 0.18), Temp = c(24.63, 24.61, 24.63, 25.64, 25.63,  
26.22, 26.17, 25.34, 25.44, 25.09), Sal = c(37.16, 36.79, 38.06,  
38.20, 38.15, 38.26, 38.25, 38.10, 38.07, 37.96), Vol = c(971.0,  
965.5, 835.0, 823.0, 640.0, 1147.0, 1322.0, 912.0, 1018.0, 1095.0))


my.df$VarFixedT <- varFixed(~Temp)
GLMNB_W <- glm.nb(Jelly ~ Temp + Sal +
                     offset(log(Vol)),
                   data= my.df,
                   weights = VarFixedT)

my.df$VarPowerT <- varPower(1, form =~Temp)
GLMNB_W <- glm.nb(Jelly ~ Temp + Sal +
                     offset(log(Vol)),
                   data= my.df,
                   weights = VarPowerT)
summary(GLMNB_W)

my.df$VarExpT <- varExp(1, form =~ Temp)
GLMNB_W <- glm.nb(Jelly ~ Temp + Sal +
                     offset(log(Vol)),
                   data= my.df,
                   weights = VarExpT)
summary(GLMNB_W)

-- 
Marina Pastor
PhD Student
Marine biology and oceanography department
Institut de Ci?ncies del Mar (ICM-CSIC)
Spanish National Research Council
Passeig Mar?tim de la Barceloneta 37-49, E-08003 Barcelona, Catalonia, Spain
Phone: +34 932309500 (ext. 1113)
E-mail: marinapastor at icm.csic.es


From th|erry@onke||nx @end|ng |rom |nbo@be  Tue Nov 17 11:33:27 2020
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Tue, 17 Nov 2020 11:33:27 +0100
Subject: [R-sig-ME] Trying to modify variance structure
In-Reply-To: <20201117111942.Horde.cmPZT0VHhQiyY9e-MvOOVtw@webmail.csic.es>
References: <20201117111942.Horde.cmPZT0VHhQiyY9e-MvOOVtw@webmail.csic.es>
Message-ID: <CAJuCY5y7PKwsdJgaJ7LWYtdZY_KPNXOFVYQjH5HjEX+=kW_JKA@mail.gmail.com>

Dear Marina,

The Poisson and negative binomial distributions assume counts =
non-negative integers. Your response variable is not integer. You'll need
the actual counts instead.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op di 17 nov. 2020 om 11:20 schreef Marina Pastor <marinapastor at icm.csic.es
>:

>
> Hello,
> We are studying the jellyfish distribution and we would like to know
> if it depends of temperature and salinity. As our database are counts
> and we have a high amount of 0, but also other high numbers around
> 400, we used a Negative Binomial Generalised Lineal Model. As the
> filtered volume was not the same for all the counts, we incorporated
> this through an offset.
> Checking the residual distribution we realised we were violating the
> homogeneity assumption since the larger the temperature, the larger
> the variation.
> We first tried to apply different variance structures through
> varFixed, varPower and varExp functions (nlme package) depending on
> the temperature, but we did not manage.
> The reproducible example is below.
> - For varFixed(~Temp) we followed the R help example. Why we obtained
> this error?: Error in `$<-.data.frame`(`*tmp*`, VarFixedT, value =
> numeric(0)) :   replacement has 0 rows, data has 10
> - For varPower(1, form =~Temp) and varExp(1, form =~ Temp), how to
> choose the best ?value? before ?form? in the formula (?1? in the
> example)?
> We would be very grateful if you could help us, we don?t know how to
> improve our model and is one of the requirements to publish our
> article. Many thanks for your time in advance.
> Best wishes,
> Marina Pastor
>
>
> Reproducible example:
> library("nlme")
> library("MASS")
>
> my.df <- data.frame (Jelly = c(1.13, 10.98, 0.00, 0.97, 0.62, 1.04,
> 0.00, 77.83, 4.12, 0.18), Temp = c(24.63, 24.61, 24.63, 25.64, 25.63,
> 26.22, 26.17, 25.34, 25.44, 25.09), Sal = c(37.16, 36.79, 38.06,
> 38.20, 38.15, 38.26, 38.25, 38.10, 38.07, 37.96), Vol = c(971.0,
> 965.5, 835.0, 823.0, 640.0, 1147.0, 1322.0, 912.0, 1018.0, 1095.0))
>
>
> my.df$VarFixedT <- varFixed(~Temp)
> GLMNB_W <- glm.nb(Jelly ~ Temp + Sal +
>                      offset(log(Vol)),
>                    data= my.df,
>                    weights = VarFixedT)
>
> my.df$VarPowerT <- varPower(1, form =~Temp)
> GLMNB_W <- glm.nb(Jelly ~ Temp + Sal +
>                      offset(log(Vol)),
>                    data= my.df,
>                    weights = VarPowerT)
> summary(GLMNB_W)
>
> my.df$VarExpT <- varExp(1, form =~ Temp)
> GLMNB_W <- glm.nb(Jelly ~ Temp + Sal +
>                      offset(log(Vol)),
>                    data= my.df,
>                    weights = VarExpT)
> summary(GLMNB_W)
>
> --
> Marina Pastor
> PhD Student
> Marine biology and oceanography department
> Institut de Ci?ncies del Mar (ICM-CSIC)
> Spanish National Research Council
> Passeig Mar?tim de la Barceloneta 37-49, E-08003 Barcelona, Catalonia,
> Spain
> Phone: +34 932309500 (ext. 1113)
> E-mail: marinapastor at icm.csic.es
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From m@r|n@p@@tor @end|ng |rom |cm@c@|c@e@  Tue Nov 17 12:42:41 2020
From: m@r|n@p@@tor @end|ng |rom |cm@c@|c@e@ (Marina Pastor)
Date: Tue, 17 Nov 2020 12:42:41 +0100
Subject: [R-sig-ME] Trying to modify variance structure
In-Reply-To: <CAJuCY5y7PKwsdJgaJ7LWYtdZY_KPNXOFVYQjH5HjEX+=kW_JKA@mail.gmail.com>
References: <20201117111942.Horde.cmPZT0VHhQiyY9e-MvOOVtw@webmail.csic.es>
 <CAJuCY5y7PKwsdJgaJ7LWYtdZY_KPNXOFVYQjH5HjEX+=kW_JKA@mail.gmail.com>
Message-ID: <20201117124241.Horde.JgrHJcXK-Y88_EG7PGL_xSl@webmail.csic.es>

Thank you Thierry,
Here is the reproducible example (I copied the wrong jelly column),  
but we obtained the same error:
- For varFixed(~Temp) we followed the R help example. Why we obtained  
this error?: Error in `$<-.data.frame`(`*tmp*`, VarFixedT, value =  
numeric(0)) :   replacement has 0 rows, data has 10
- For varPower(1, form =~Temp) and varExp(1, form =~ Temp), how to  
choose the best ?value? before ?form? in the formula (?1? in the  
example)?
Best wishes,
Marina Pastor

library("nlme")
library("MASS")
my.df <- data.frame (Jelly = c(11, 106, 0, 8, 4, 12, 0, 699, 42, 2),  
Temp = c(24.63, 24.61, 24.63, 25.64, 25.63, 26.22, 26.17, 25.34,  
25.44, 25.09), Sal = c(37.16, 36.79, 38.06, 38.20, 38.15, 38.26,  
38.25, 38.10, 38.07, 37.96), Vol = c(971.0, 965.5, 835.0, 823.0,  
640.0, 1147.0, 1322.0, 912.0, 1018.0, 1095.0))

my.df$VarFixedT <- varFixed(~Temp)
GLMNB_W <- glm.nb(Jelly ~ Temp + Sal +
                     offset(log(Vol)),
                   data= my.df,
                   weights = VarFixedT)

my.df$VarPowerT <- varPower(1, form =~Temp)
GLMNB_W <- glm.nb(Jelly ~ Temp + Sal +
                     offset(log(Vol)),
                   data= my.df,
                   weights = VarPowerT)
summary(GLMNB_W)

my.df$VarExpT <- varExp(1, form =~ Temp)
GLMNB_W <- glm.nb(Jelly ~ Temp + Sal +
                     offset(log(Vol)),
                   data= my.df,
                   weights = VarExpT)
summary(GLMNB_W)


Thierry Onkelinx <thierry.onkelinx at inbo.be> escribi?:

> Dear Marina,
>
> The Poisson and negative binomial distributions assume counts =
> non-negative integers. Your response variable is not integer. You'll need
> the actual counts instead.
>
> Best regards,
>
> ir. Thierry Onkelinx
> Statisticus / Statistician
>
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
> FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Havenlaan 88 bus 73, 1000 Brussel
> www.inbo.be
>
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
> ///////////////////////////////////////////////////////////////////////////////////////////
>
> <https://www.inbo.be>
>
>
> Op di 17 nov. 2020 om 11:20 schreef Marina Pastor <marinapastor at icm.csic.es
>> :
>
>>
>> Hello,
>> We are studying the jellyfish distribution and we would like to know
>> if it depends of temperature and salinity. As our database are counts
>> and we have a high amount of 0, but also other high numbers around
>> 400, we used a Negative Binomial Generalised Lineal Model. As the
>> filtered volume was not the same for all the counts, we incorporated
>> this through an offset.
>> Checking the residual distribution we realised we were violating the
>> homogeneity assumption since the larger the temperature, the larger
>> the variation.
>> We first tried to apply different variance structures through
>> varFixed, varPower and varExp functions (nlme package) depending on
>> the temperature, but we did not manage.
>> The reproducible example is below.
>> - For varFixed(~Temp) we followed the R help example. Why we obtained
>> this error?: Error in `$<-.data.frame`(`*tmp*`, VarFixedT, value =
>> numeric(0)) :   replacement has 0 rows, data has 10
>> - For varPower(1, form =~Temp) and varExp(1, form =~ Temp), how to
>> choose the best ?value? before ?form? in the formula (?1? in the
>> example)?
>> We would be very grateful if you could help us, we don?t know how to
>> improve our model and is one of the requirements to publish our
>> article. Many thanks for your time in advance.
>> Best wishes,
>> Marina Pastor
>>
>>
>> Reproducible example:
>> library("nlme")
>> library("MASS")
>>
>> my.df <- data.frame (Jelly = c(1.13, 10.98, 0.00, 0.97, 0.62, 1.04,
>> 0.00, 77.83, 4.12, 0.18), Temp = c(24.63, 24.61, 24.63, 25.64, 25.63,
>> 26.22, 26.17, 25.34, 25.44, 25.09), Sal = c(37.16, 36.79, 38.06,
>> 38.20, 38.15, 38.26, 38.25, 38.10, 38.07, 37.96), Vol = c(971.0,
>> 965.5, 835.0, 823.0, 640.0, 1147.0, 1322.0, 912.0, 1018.0, 1095.0))
>>
>>
>> my.df$VarFixedT <- varFixed(~Temp)
>> GLMNB_W <- glm.nb(Jelly ~ Temp + Sal +
>>                      offset(log(Vol)),
>>                    data= my.df,
>>                    weights = VarFixedT)
>>
>> my.df$VarPowerT <- varPower(1, form =~Temp)
>> GLMNB_W <- glm.nb(Jelly ~ Temp + Sal +
>>                      offset(log(Vol)),
>>                    data= my.df,
>>                    weights = VarPowerT)
>> summary(GLMNB_W)
>>
>> my.df$VarExpT <- varExp(1, form =~ Temp)
>> GLMNB_W <- glm.nb(Jelly ~ Temp + Sal +
>>                      offset(log(Vol)),
>>                    data= my.df,
>>                    weights = VarExpT)
>> summary(GLMNB_W)
>>
>> --
>> Marina Pastor
>> PhD Student
>> Marine biology and oceanography department
>> Institut de Ci?ncies del Mar (ICM-CSIC)
>> Spanish National Research Council
>> Passeig Mar?tim de la Barceloneta 37-49, E-08003 Barcelona, Catalonia,
>> Spain
>> Phone: +34 932309500 (ext. 1113)
>> E-mail: marinapastor at icm.csic.es
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>


-- 
Marina Pastor
PhD Student
Marine biology and oceanography department
Institut de Ci?ncies del Mar (ICM-CSIC)
Spanish National Research Council
Passeig Mar?tim de la Barceloneta 37-49, E-08003 Barcelona, Catalonia, Spain
Phone: +34 932309500 (ext. 1113)
E-mail: marinapastor at icm.csic.es


From hedyeh@h @end|ng |rom u@c@edu  Wed Nov 25 04:28:27 2020
From: hedyeh@h @end|ng |rom u@c@edu (Hedyeh Ahmadi)
Date: Wed, 25 Nov 2020 03:28:27 +0000
Subject: [R-sig-ME] A GLMM Question
Message-ID: <BYAPR07MB509418C293339B05BC45C3A4D1FA0@BYAPR07MB5094.namprd07.prod.outlook.com>

Hi All,
I'm looking for a resource and/or advice for GLMM with logit link assumption checking.

I understand that Normality assumption of random effects, over-dispersion, and checking the appropriateness of the chosen link need to be checked but is there anything else that needs to be checked in terms of model assumptions for GLMM with logit link?

I am planning to use glmer() in the lme4 package. Any help and/or resources would be greatly appreciated and thank you in advance for your time and help.

Best,

Hedyeh Ahmadi, Ph.D.
Statistician
Keck School of Medicine
Department of Preventive Medicine
University of Southern California

Postdoctoral Scholar
Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
University of California, Irvine

LinkedIn
www.linkedin.com/in/hedyeh-ahmadi<http://www.linkedin.com/in/hedyeh-ahmadi>


	[[alternative HTML version deleted]]


From c@r|o@@mb@rboz@ @end|ng |rom gm@||@com  Tue Nov 24 09:38:38 2020
From: c@r|o@@mb@rboz@ @end|ng |rom gm@||@com (Carlos Barboza)
Date: Tue, 24 Nov 2020 05:38:38 -0300
Subject: [R-sig-ME] Levels in random effect
Message-ID: <CAGAvxRmCJzQoEC=Xfc52JzZvKhbOcKrGDx_L8MZY=hnDUW190w@mail.gmail.com>

Dear Dr. Bolker,
I'm running a mixed model with 193 records including three continuous
variables and an interaction. My random intercept has 75 levels.
However, many of them with 2-3 replicates. Using lme and lmer
everything runs ok with no problems of convergence, warnings etc. As I
suspected I have a big contribution of random effects to the total
variance. My doubt is if can I trust in model having levels of random
effects with reduced number of replicates?
thank you very much in advance
Carlos


-- 
Universidade Federal do Rio de Janeiro (UFRJ)
Instituto de Biodiversidade e Sustentabilidade - NUPEM
Caixa Postal 119331, CEP 27910-970
Maca?, RJ, Brazil
https://www.macae.ufrj.br/nupem/
http://lattes.cnpq.br/3629226944950076
https://scholar.google.com.br/citations?user=p-PRvd4AAAAJ&hl=pt-BR
https://www.researchgate.net/profile/Carlos_Barboza3


From o||verhooker @end|ng |rom pr@t@t|@t|c@@com  Wed Nov 25 18:04:52 2020
From: o||verhooker @end|ng |rom pr@t@t|@t|c@@com (Oliver Hooker)
Date: Wed, 25 Nov 2020 17:04:52 +0000
Subject: [R-sig-ME] Bayesian hierarchical modelling using R (IBHM05)
Message-ID: <CAEsSYzyAW7RFFy+sL6K7_4ZyrpWF9BBkgFViC_vJnznAEr7F_g@mail.gmail.com>

Apologies for cross posting and the flurry of posts.

Bayesian hierarchical modelling using R (IBHM05)

https://www.prstatistics.com/course/bayesian-hierarchical-modelling-using-r-ibhm05/

We still have places available

This is a ?LIVE COURSE? ? the instructor will be delivering lectures
and coaching attendees through the accompanying computer practical?s
via video link, a good internet connection is essential.

TIME ZONE ? GMT ? however all sessions will be recorded and made
available allowing attendees from different time zones to follow a day
behind with an additional 1/2 days support after the official course
finish date (please email oliverhooker at prstatistics.com for full
details or to discuss how we can accommodate you).

Course Overview:
This course will cover introductory hierarchical modelling for
real-world data sets from a Bayesian perspective. These methods lie at
the forefront of statistics research and are a vital tool in the
scientist?s toolbox. The course focuses on introducing concepts and
demonstrating good practice in hierarchical models. All methods are
demonstrated with data sets which participants can run themselves.
Participants will be taught how to fit hierarchical models using the
Bayesian modelling software Jags and Stan through the R software
interface. The course covers the full gamut from simple regression
models through to full generalised multivariate hierarchical
structures. A Bayesian approach is taken throughout, meaning that
participants can include all available information in their models and
estimates all unknown quantities with uncertainty. Participants are
encouraged to bring their own data sets for discussion with the course
tutors.

Friday 27th November ? Classes from 09:30 to 17:30

Module 3: Simple hierarchical regression models
Module 4: Hierarchical models for non-Gaussian data
Practical: Fitting hierarchical models

Friday 4th December ? Classes from 09:30 to 17:30

Module 5: Hierarchical models vs mixed effects models
Module 6: Multivariate and multi-layer hierarchical models
Practical: Advanced examples of hierarchical models

Friday 11th December ? Classes from 09:30 to 17:30

Module 7: Shrinkage and variable selection
Module 8: Hierarchical models and partial pooling
Practical: Shrinkage modelling

-- 
Oliver Hooker PhD.
PR statistics

2020 publications;
Parallelism in eco-morphology and gene expression despite variable
evolutionary and genomic backgrounds in a Holarctic fish. PLOS
GENETICS (2020). IN PRESS

www.PRstatistics.com
facebook.com/PRstatistics/
twitter.com/PRstatistics

53 Morrison Street
Glasgow
G5 8LB
+44 (0) 7966500340
+44 (0) 7966500340


From th|erry@onke||nx @end|ng |rom |nbo@be  Wed Nov 25 19:19:18 2020
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Wed, 25 Nov 2020 19:19:18 +0100
Subject: [R-sig-ME] Levels in random effect
In-Reply-To: <CAGAvxRmCJzQoEC=Xfc52JzZvKhbOcKrGDx_L8MZY=hnDUW190w@mail.gmail.com>
References: <CAGAvxRmCJzQoEC=Xfc52JzZvKhbOcKrGDx_L8MZY=hnDUW190w@mail.gmail.com>
Message-ID: <CAJuCY5znOLoNAU3iCKaeCBkBR4+CC7MBTD7BQP6bo+YUe4EmQQ@mail.gmail.com>

Dear Carlos,

In theory, you should be fine. The example below compares a paired t-test
and its mixed model equivalent. It has less levels and less replicates than
your example. Note that the estimates and t-values are identical.
In practice, you should carefully check your model. As you always should.

library(lme4)

set.seed(20201125)
n <- 50
sd_rf <- 2
sd_error <- 0.1
delta <- 0.2
rf <- rnorm(n, sd = sd_rf)
error <- rnorm(2 * n, sd = sd_error)
ds <- expand.grid(
  id = seq_len(n),
  type = 0:1
)
ds$y <- delta * ds$type + rf[ds$id] + error

t.test(ds$y[ds$type == 1], ds$y[ds$type == 0], paired = TRUE)
summary(lmer(y ~ type + (1|id), data = ds))

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op wo 25 nov. 2020 om 18:07 schreef Carlos Barboza <
carlosambarboza at gmail.com>:

> Dear Dr. Bolker,
> I'm running a mixed model with 193 records including three continuous
> variables and an interaction. My random intercept has 75 levels.
> However, many of them with 2-3 replicates. Using lme and lmer
> everything runs ok with no problems of convergence, warnings etc. As I
> suspected I have a big contribution of random effects to the total
> variance. My doubt is if can I trust in model having levels of random
> effects with reduced number of replicates?
> thank you very much in advance
> Carlos
>
>
> --
> Universidade Federal do Rio de Janeiro (UFRJ)
> Instituto de Biodiversidade e Sustentabilidade - NUPEM
> Caixa Postal 119331, CEP 27910-970
> Maca?, RJ, Brazil
> https://www.macae.ufrj.br/nupem/
> http://lattes.cnpq.br/3629226944950076
> https://scholar.google.com.br/citations?user=p-PRvd4AAAAJ&hl=pt-BR
> https://www.researchgate.net/profile/Carlos_Barboza3
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From @|m@h@rme| @end|ng |rom gm@||@com  Sat Nov 28 02:30:09 2020
From: @|m@h@rme| @end|ng |rom gm@||@com (Simon Harmel)
Date: Fri, 27 Nov 2020 19:30:09 -0600
Subject: [R-sig-ME] What it means for rho to be 0 in lme() when using
 compound symmetry
Message-ID: <CACgv6yX97JD_tsuAb6AVrd4-ErpUYQagmyXpmupgjDoU92KY7Q@mail.gmail.com>

Hello All,

Below, I'm using corCompSymm() (compound symmetry) for my simple model.

The rho is estimated to be 0. I was wondering what it means for rho in the
var-covariance matrix to be "0"? Is my var-covariance matrix below valid?
-- Thank you all, Simon
#----------------------------------------------------------------
library(nlme)
data <- read.csv('https://raw.githubusercontent.com/hkil/m/master/R.csv')

m <- lme(Achieve ~ time, random = ~1|subid, data = data, correlation =
corCompSymm())

  aa <- corMatrix(m$modelStruct$corStruct)[[1]]
  aa * sigma(m)^2

         [,1]     [,2]     [,3]     [,4]
[1,] 112.5003   0.0000   0.0000   0.0000
[2,]   0.0000 112.5003   0.0000   0.0000
[3,]   0.0000   0.0000 112.5003   0.0000
[4,]   0.0000   0.0000   0.0000 112.5003

	[[alternative HTML version deleted]]


From g@br|e||@@kountour|de@ @end|ng |rom @jc@ox@@c@uk  Mon Nov 30 01:23:48 2020
From: g@br|e||@@kountour|de@ @end|ng |rom @jc@ox@@c@uk (Gabriella Kountourides)
Date: Mon, 30 Nov 2020 00:23:48 +0000
Subject: [R-sig-ME] What to do with zero inflated, negative skewed,
 negative data: a question about GLMMs
Message-ID: <LNXP265MB053880E8735CF63A25DBCF43E8F50@LNXP265MB0538.GBRP265.PROD.OUTLOOK.COM>

Hello everyone,

This is my first question to this list :) I  hope this email finds you all well.


  I have been struggling for the past few weeks to set an appropriate model for my data. I have read Prof Bolker's practical guide for ecology and evolution paper, as well as the GLMM FAQs which have been immensely helpful. I am only just beginning my stats journey (and R!) and although I am really enjoying it, I have found myself completely stumped with my dataset. I will describe the data set below, and below that the various attempts I have made to analyse it. I would be incredibly grateful to hear your thoughts.

All the very best

Data:


I want to look whether there is a relationship between the phrasing used when a question is asked (positive, negative, neutral wording) and the polarity of the response from the individual.


2638 people were asked a question about medical symptoms.

1/3 of the people were asked it with a negative wording, 1/3 with a neutral one, 1/3 with a positive one.

The big question is: does the way the question is asked  affect the polarity of the response


>From this, I did sentiment analysis (using trincker's<https://github.com/trinker/sentimentr> package), which provides a polarity score (this can be negative, neutral or positive) to see whether their responses were more positive or negative, depending on the wording of the question.


Sentiment analysis breaks down responses into sentences, so I have 2638 people, but 7924 sentences, so I would assume to fit ID as a random effect.


Range: -4.0376 to + 0.7915.
Median :-0.1830
Mean   :-0.2149

Mode: 0
skew: -1.7

There are many 0s in my model, these are true 0s, they represent a 'neutral' response, which is important. My data is negatively skewed, so more people answer in a negative way. But I still want to know, whether the phrasings affect the skew/is one phrasing leading to 'less negative' responses?

What I've tried:
Initially, I tried to do a glm with the raw data, but I can't use poisson as it is negative, it is skewed so its not gaussian, and its not binomial.

So next I made 3 new variables, which were counts. For example 'PosCount' scored 1 for each row with a +polarity score, and a 0 if not.  Idem for neutral (sentiment=0) and positive (sentiment>0). Decided to run Zero Inflated Poisson

I ran a glmm for each count variable-example for the positive one:
pos <-glmmTMB(PosCount~ wordingQ + (1|id) + age, data=allprimesent, ziformula=~1, family=poisson)

and then the 'overdisp_fun' function which gave
> overdisp_fun(posmodel)
 chisq                  ratio                          rdf            p
6268.8427185    0.8295412.   7557.0000000    1.0000000

So I suppose my questions are: do you think this is the best thing to do with my data? Do you know of any better thing I can do with the raw data, I'd rather not lose the information about the strength of the sentiment, but if I keep it, I need a model that can deal with 0 inflation, negative skew, and negative numbers.

Many thanks if you've read this! I look forward to hearing from you!
All the best

p.s. I am relatively new to stats and R, please bare that in mind with your terminology if you are kind enough to answer


Gabriella Kountourides

DPhil Student | Department of Anthropology

Evolutionary Medicine and Public Health Group

St. John?s College, University of Oxford

gabriella.kountourides at sjc.ox.ac.uk

Tweet me: https://twitter.com/GKountourides

________________________________



	[[alternative HTML version deleted]]


From chr|@ @end|ng |rom tr|cky@o|ut|on@@com@@u  Mon Nov 30 03:16:29 2020
From: chr|@ @end|ng |rom tr|cky@o|ut|on@@com@@u (Chris Howden)
Date: Mon, 30 Nov 2020 02:16:29 +0000
Subject: [R-sig-ME] What to do with zero inflated, negative skewed,
 negative data: a question about GLMMs
In-Reply-To: <LNXP265MB053880E8735CF63A25DBCF43E8F50@LNXP265MB0538.GBRP265.PROD.OUTLOOK.COM>
References: <LNXP265MB053880E8735CF63A25DBCF43E8F50@LNXP265MB0538.GBRP265.PROD.OUTLOOK.COM>
Message-ID: <SYBPR01MB4988DEE74DA2FD005CA6B7E298F50@SYBPR01MB4988.ausprd01.prod.outlook.com>

Hi Gabriella,

I'm not sure you really have zero inflation here. 0 inflation usually occurs when you have counts or a yes/no response. The 0 means a 'lack of a response'. One way to think of this is that the 0's represent when the 'thing' you are measuring didn?t occur, and the count is when it did. For example if you had random samples from all over the planet, you wouldn?t find fish in the desert, but you do find them in water. And when you do find them there are lots of different variables that might affect how many you see. So you would fit 2 models:
1) model 1: are fish present i.e. is the sample a water or land sample?
2) model 2: how many fish did you find, assuming they were there.  

So in yr example your 0's don?t really mean an absence of data, they mean a neutral score. 

1 way to analyse this is to use at least 2 logistic regressions. 1 that explains the difference between negative vs neutral, and then another neutral vs positive. You might also want to have a 3rd model that shows negative vs positive. 


Chris Howden B.Sc. (Hons)
Founding Partner
Data Analysis, Modelling and Training
Evidence Based Strategy/Policy Development, IP Commercialisation and Innovation
(mobile) +61 (0) 410 689 945 | (skype) chris at trickysolutions.com.au

-----Original Message-----
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> On Behalf Of Gabriella Kountourides
Sent: Monday, 30 November 2020 11:24 AM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] What to do with zero inflated, negative skewed, negative data: a question about GLMMs

Hello everyone,

This is my first question to this list :) I  hope this email finds you all well.


  I have been struggling for the past few weeks to set an appropriate model for my data. I have read Prof Bolker's practical guide for ecology and evolution paper, as well as the GLMM FAQs which have been immensely helpful. I am only just beginning my stats journey (and R!) and although I am really enjoying it, I have found myself completely stumped with my dataset. I will describe the data set below, and below that the various attempts I have made to analyse it. I would be incredibly grateful to hear your thoughts.

All the very best

Data:


I want to look whether there is a relationship between the phrasing used when a question is asked (positive, negative, neutral wording) and the polarity of the response from the individual.


2638 people were asked a question about medical symptoms.

1/3 of the people were asked it with a negative wording, 1/3 with a neutral one, 1/3 with a positive one.

The big question is: does the way the question is asked  affect the polarity of the response


From this, I did sentiment analysis (using trincker's<https://github.com/trinker/sentimentr> package), which provides a polarity score (this can be negative, neutral or positive) to see whether their responses were more positive or negative, depending on the wording of the question.


Sentiment analysis breaks down responses into sentences, so I have 2638 people, but 7924 sentences, so I would assume to fit ID as a random effect.


Range: -4.0376 to + 0.7915.
Median :-0.1830
Mean   :-0.2149

Mode: 0
skew: -1.7

There are many 0s in my model, these are true 0s, they represent a 'neutral' response, which is important. My data is negatively skewed, so more people answer in a negative way. But I still want to know, whether the phrasings affect the skew/is one phrasing leading to 'less negative' responses?

What I've tried:
Initially, I tried to do a glm with the raw data, but I can't use poisson as it is negative, it is skewed so its not gaussian, and its not binomial.

So next I made 3 new variables, which were counts. For example 'PosCount' scored 1 for each row with a +polarity score, and a 0 if not.  Idem for neutral (sentiment=0) and positive (sentiment>0). Decided to run Zero Inflated Poisson

I ran a glmm for each count variable-example for the positive one:
pos <-glmmTMB(PosCount~ wordingQ + (1|id) + age, data=allprimesent, ziformula=~1, family=poisson)

and then the 'overdisp_fun' function which gave
> overdisp_fun(posmodel)
 chisq                  ratio                          rdf            p
6268.8427185    0.8295412.   7557.0000000    1.0000000

So I suppose my questions are: do you think this is the best thing to do with my data? Do you know of any better thing I can do with the raw data, I'd rather not lose the information about the strength of the sentiment, but if I keep it, I need a model that can deal with 0 inflation, negative skew, and negative numbers.

Many thanks if you've read this! I look forward to hearing from you!
All the best

p.s. I am relatively new to stats and R, please bare that in mind with your terminology if you are kind enough to answer


Gabriella Kountourides

DPhil Student | Department of Anthropology

Evolutionary Medicine and Public Health Group

St. John?s College, University of Oxford

gabriella.kountourides at sjc.ox.ac.uk

Tweet me: https://twitter.com/GKountourides

________________________________



	[[alternative HTML version deleted]]


From th|erry@onke||nx @end|ng |rom |nbo@be  Mon Nov 30 08:50:49 2020
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Mon, 30 Nov 2020 08:50:49 +0100
Subject: [R-sig-ME] What to do with zero inflated, negative skewed,
 negative data: a question about GLMMs
In-Reply-To: <LNXP265MB053880E8735CF63A25DBCF43E8F50@LNXP265MB0538.GBRP265.PROD.OUTLOOK.COM>
References: <LNXP265MB053880E8735CF63A25DBCF43E8F50@LNXP265MB0538.GBRP265.PROD.OUTLOOK.COM>
Message-ID: <CAJuCY5yMdjP5FnmVBmZMPLTt5Q3v2tv76VokjivX4=cSFcZtpw@mail.gmail.com>

Dear Gabriella,

I'd try to fit a single model to the data.The response seems continuous to
me. So I'd try a Gaussian distribution. You might need to fit a different
variance for each of the questions.

library(nlme)
lme(sentiment ~ question + age + (1|patient))
lme(sentiment ~ question + age + (1|patient), weight = VarIdent(form = ~
1|question))

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op ma 30 nov. 2020 om 01:24 schreef Gabriella Kountourides <
gabriella.kountourides at sjc.ox.ac.uk>:

> Hello everyone,
>
> This is my first question to this list :) I  hope this email finds you all
> well.
>
>
>   I have been struggling for the past few weeks to set an appropriate
> model for my data. I have read Prof Bolker's practical guide for ecology
> and evolution paper, as well as the GLMM FAQs which have been immensely
> helpful. I am only just beginning my stats journey (and R!) and although I
> am really enjoying it, I have found myself completely stumped with my
> dataset. I will describe the data set below, and below that the various
> attempts I have made to analyse it. I would be incredibly grateful to hear
> your thoughts.
>
> All the very best
>
> Data:
>
>
> I want to look whether there is a relationship between the phrasing used
> when a question is asked (positive, negative, neutral wording) and the
> polarity of the response from the individual.
>
>
> 2638 people were asked a question about medical symptoms.
>
> 1/3 of the people were asked it with a negative wording, 1/3 with a
> neutral one, 1/3 with a positive one.
>
> The big question is: does the way the question is asked  affect the
> polarity of the response
>
>
> From this, I did sentiment analysis (using trincker's<
> https://github.com/trinker/sentimentr> package), which provides a
> polarity score (this can be negative, neutral or positive) to see whether
> their responses were more positive or negative, depending on the wording of
> the question.
>
>
> Sentiment analysis breaks down responses into sentences, so I have 2638
> people, but 7924 sentences, so I would assume to fit ID as a random effect.
>
>
> Range: -4.0376 to + 0.7915.
> Median :-0.1830
> Mean   :-0.2149
>
> Mode: 0
> skew: -1.7
>
> There are many 0s in my model, these are true 0s, they represent a
> 'neutral' response, which is important. My data is negatively skewed, so
> more people answer in a negative way. But I still want to know, whether the
> phrasings affect the skew/is one phrasing leading to 'less negative'
> responses?
>
> What I've tried:
> Initially, I tried to do a glm with the raw data, but I can't use poisson
> as it is negative, it is skewed so its not gaussian, and its not binomial.
>
> So next I made 3 new variables, which were counts. For example 'PosCount'
> scored 1 for each row with a +polarity score, and a 0 if not.  Idem for
> neutral (sentiment=0) and positive (sentiment>0). Decided to run Zero
> Inflated Poisson
>
> I ran a glmm for each count variable-example for the positive one:
> pos <-glmmTMB(PosCount~ wordingQ + (1|id) + age, data=allprimesent,
> ziformula=~1, family=poisson)
>
> and then the 'overdisp_fun' function which gave
> > overdisp_fun(posmodel)
>  chisq                  ratio                          rdf            p
> 6268.8427185    0.8295412.   7557.0000000    1.0000000
>
> So I suppose my questions are: do you think this is the best thing to do
> with my data? Do you know of any better thing I can do with the raw data,
> I'd rather not lose the information about the strength of the sentiment,
> but if I keep it, I need a model that can deal with 0 inflation, negative
> skew, and negative numbers.
>
> Many thanks if you've read this! I look forward to hearing from you!
> All the best
>
> p.s. I am relatively new to stats and R, please bare that in mind with
> your terminology if you are kind enough to answer
>
>
> Gabriella Kountourides
>
> DPhil Student | Department of Anthropology
>
> Evolutionary Medicine and Public Health Group
>
> St. John?s College, University of Oxford
>
> gabriella.kountourides at sjc.ox.ac.uk
>
> Tweet me: https://twitter.com/GKountourides
>
> ________________________________
>
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Mon Nov 30 18:09:29 2020
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Mon, 30 Nov 2020 12:09:29 -0500
Subject: [R-sig-ME] What to do with zero inflated, negative skewed,
 negative data: a question about GLMMs
In-Reply-To: <CAJuCY5yMdjP5FnmVBmZMPLTt5Q3v2tv76VokjivX4=cSFcZtpw@mail.gmail.com>
References: <LNXP265MB053880E8735CF63A25DBCF43E8F50@LNXP265MB0538.GBRP265.PROD.OUTLOOK.COM>
 <CAJuCY5yMdjP5FnmVBmZMPLTt5Q3v2tv76VokjivX4=cSFcZtpw@mail.gmail.com>
Message-ID: <74f50cd0-6842-162b-58e9-055c41f2a5c4@gmail.com>

 ? I think Gabriella may have abandoned the linear mixed model (i.e. 
Gaussian distribution) because of a skewed distribution of responses.? A 
couple of things to keep in mind about this:

 ??? - you don't need to worry about the *marginal* distribution of the 
data (i.e., what you get if you plot the histogram or density of your 
response variable). The assumptions in LMMs (like most models) are about 
the *conditional* distribution, i.e. the distribution of the residuals 
(e.g., fit your model first, then examine lattice::qqmath(fitted_model) 
or hist(residuals(fitted_model))

 ??? - non-normality (including skewness) even in the conditional model 
is much less important to the validity (accuracy of the parameter 
estimates, confidence intervals, etc.) than many people think

 ?? - in principle you could transform the response variable to deal 
with this, although admittedly the choice of transformations is much 
more limited for non-positive data (e.g. Yeo-Johnson transformations, 
see `?car::yjPower`, although there are some issues here about whether 
you're transforming the marginal or the conditional distribution ...


 ? cheers

 ??? Ben Bolker


On 11/30/20 2:50 AM, Thierry Onkelinx via R-sig-mixed-models wrote:
> Dear Gabriella,
>
> I'd try to fit a single model to the data.The response seems continuous to
> me. So I'd try a Gaussian distribution. You might need to fit a different
> variance for each of the questions.
>
> library(nlme)
> lme(sentiment ~ question + age + (1|patient))
> lme(sentiment ~ question + age + (1|patient), weight = VarIdent(form = ~
> 1|question))
>
> Best regards,
>
> ir. Thierry Onkelinx
> Statisticus / Statistician
>
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
> FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Havenlaan 88 bus 73, 1000 Brussel
> www.inbo.be
>
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
> ///////////////////////////////////////////////////////////////////////////////////////////
>
> <https://www.inbo.be>
>
>
> Op ma 30 nov. 2020 om 01:24 schreef Gabriella Kountourides <
> gabriella.kountourides at sjc.ox.ac.uk>:
>
>> Hello everyone,
>>
>> This is my first question to this list :) I  hope this email finds you all
>> well.
>>
>>
>>    I have been struggling for the past few weeks to set an appropriate
>> model for my data. I have read Prof Bolker's practical guide for ecology
>> and evolution paper, as well as the GLMM FAQs which have been immensely
>> helpful. I am only just beginning my stats journey (and R!) and although I
>> am really enjoying it, I have found myself completely stumped with my
>> dataset. I will describe the data set below, and below that the various
>> attempts I have made to analyse it. I would be incredibly grateful to hear
>> your thoughts.
>>
>> All the very best
>>
>> Data:
>>
>>
>> I want to look whether there is a relationship between the phrasing used
>> when a question is asked (positive, negative, neutral wording) and the
>> polarity of the response from the individual.
>>
>>
>> 2638 people were asked a question about medical symptoms.
>>
>> 1/3 of the people were asked it with a negative wording, 1/3 with a
>> neutral one, 1/3 with a positive one.
>>
>> The big question is: does the way the question is asked  affect the
>> polarity of the response
>>
>>
>>  From this, I did sentiment analysis (using trincker's<
>> https://github.com/trinker/sentimentr> package), which provides a
>> polarity score (this can be negative, neutral or positive) to see whether
>> their responses were more positive or negative, depending on the wording of
>> the question.
>>
>>
>> Sentiment analysis breaks down responses into sentences, so I have 2638
>> people, but 7924 sentences, so I would assume to fit ID as a random effect.
>>
>>
>> Range: -4.0376 to + 0.7915.
>> Median :-0.1830
>> Mean   :-0.2149
>>
>> Mode: 0
>> skew: -1.7
>>
>> There are many 0s in my model, these are true 0s, they represent a
>> 'neutral' response, which is important. My data is negatively skewed, so
>> more people answer in a negative way. But I still want to know, whether the
>> phrasings affect the skew/is one phrasing leading to 'less negative'
>> responses?
>>
>> What I've tried:
>> Initially, I tried to do a glm with the raw data, but I can't use poisson
>> as it is negative, it is skewed so its not gaussian, and its not binomial.
>>
>> So next I made 3 new variables, which were counts. For example 'PosCount'
>> scored 1 for each row with a +polarity score, and a 0 if not.  Idem for
>> neutral (sentiment=0) and positive (sentiment>0). Decided to run Zero
>> Inflated Poisson
>>
>> I ran a glmm for each count variable-example for the positive one:
>> pos <-glmmTMB(PosCount~ wordingQ + (1|id) + age, data=allprimesent,
>> ziformula=~1, family=poisson)
>>
>> and then the 'overdisp_fun' function which gave
>>> overdisp_fun(posmodel)
>>   chisq                  ratio                          rdf            p
>> 6268.8427185    0.8295412.   7557.0000000    1.0000000
>>
>> So I suppose my questions are: do you think this is the best thing to do
>> with my data? Do you know of any better thing I can do with the raw data,
>> I'd rather not lose the information about the strength of the sentiment,
>> but if I keep it, I need a model that can deal with 0 inflation, negative
>> skew, and negative numbers.
>>
>> Many thanks if you've read this! I look forward to hearing from you!
>> All the best
>>
>> p.s. I am relatively new to stats and R, please bare that in mind with
>> your terminology if you are kind enough to answer
>>
>>
>> Gabriella Kountourides
>>
>> DPhil Student | Department of Anthropology
>>
>> Evolutionary Medicine and Public Health Group
>>
>> St. John?s College, University of Oxford
>>
>> gabriella.kountourides at sjc.ox.ac.uk
>>
>> Tweet me: https://twitter.com/GKountourides
>>
>> ________________________________
>>
>>
>>
>>          [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From @r|v@t@ch@r| @end|ng |rom gm@||@com  Wed Dec  2 16:56:52 2020
From: @r|v@t@ch@r| @end|ng |rom gm@||@com (Srivats Chari)
Date: Wed, 2 Dec 2020 15:56:52 +0000
Subject: [R-sig-ME] MCMCglmm covariance matrix question
Message-ID: <CAFnkSckmh1Z1sNDsCrnHgww7xYwGNZ3-AxFbCDZ-sGEzwCFdCQ@mail.gmail.com>

Greetings,

I'm trying to run a multivariate MCMCglmm with 9 traits. My traits are
measured mostly at the same time except for 1 trait which is measured only
once or twice per individual. After reading a some literature on this I
have a basic idea on how to structure my dataset. But the problem I am
facing is that I need my covariance matrix to be different. I want my
covariance matrix to exclude the 1 trait so that all trait can COvary
together except for a particular one! So there won't be any
within-individual COvariation between the particular trait and others.

creating a sample dataset-

df<- data.frame(ani_id = as.factor(1:10),
sex=c("male","female","male","female","male","female","male","female","male","female"),age=c("young","adult","young","adult","adult","young","young",
"adult","adult","adult"),value=runif(200,min=1,
max=5),year=ceiling(runif(200,min=2010, max=2019)), PC1=runif(200, min=0.1,
max=0.9))
df$value[5:9]<- NA
df$trait_id<- as.factor(paste("T",rep(1:10, each=20), sep="_"))

## My Prior
prior1 <- list(R = list(V =diag(10), nu = 0.002),
                      G = list(G1 = list(V = diag(10), nu = 0.002,
                                         alpha.mu = rep(0, 10),
                                         alpha.V  = diag(10)*25^2)))
## MCMC model
mcmc_trial1<-MCMCglmm(scale(value) ~ factor(sex)+
             scale(year) + scale(year^2)+
             scale(PC1)+ scale(PC1^2)+
             factor(age),
           random =~ us(trait_id):ani_id,
           rcov =~ idh(trait_id):units,
           family = c("gaussian"),
           prior = prior1,
           nitt=10000,
           burnin=1000,
           thin=10,
           verbose = TRUE,
           pr=TRUE,
           data = df)

So when I see a covariance matrix I want the trait T1 to not covary with
any other trait.

T1 T2 T3 T4 T5 T6 T7 T8 T9 T10
T1 0,1 0 0 0 0 0 0 0 0 0
T2 0 0,1 0,1 0,1 0,1 0,1 0,1 0,1 0,1 0,1
T3 0 0,1 0,1 0,1 0,1 0,1 0,1 0,1 0,1 0,1
T4 0 0,1 0,1 0,1 0,1 0,1 0,1 0,1 0,1 0,1
T5 0 0,1 0,1 0,1 0,1 0,1 0,1 0,1 0,1 0,1
T6 0 0,1 0,1 0,1 0,1 0,1 0,1 0,1 0,1 0,1
T7 0 0,1 0,1 0,1 0,1 0,1 0,1 0,1 0,1 0,1
T8 0 0,1 0,1 0,1 0,1 0,1 0,1 0,1 0,1 0,1
T9 0 0,1 0,1 0,1 0,1 0,1 0,1 0,1 0,1 0,1
T10 0 0,1 0,1 0,1 0,1 0,1 0,1 0,1 0,1 0,1

Where I am stuck is I do not know how to structure the covariance matrix to
exclude T1.

Any suggestions or help is much appreciated. :)

Regards,
Srivats.

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Wed Dec  2 16:59:45 2020
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Wed, 2 Dec 2020 10:59:45 -0500
Subject: [R-sig-ME] MCMCglmm covariance matrix question
In-Reply-To: <CAFnkSckmh1Z1sNDsCrnHgww7xYwGNZ3-AxFbCDZ-sGEzwCFdCQ@mail.gmail.com>
References: <CAFnkSckmh1Z1sNDsCrnHgww7xYwGNZ3-AxFbCDZ-sGEzwCFdCQ@mail.gmail.com>
Message-ID: <8807c877-518f-7735-0257-518f9814e747@gmail.com>

   That seems quite difficult to set up in a single analysis.
   Would it work to analyze 8 of the traits with one model, and then 
analyze the other trait (which you want to treat independently) with a 
separate, univariate model?

On 12/2/20 10:56 AM, Srivats Chari wrote:
> Greetings,
> 
> I'm trying to run a multivariate MCMCglmm with 9 traits. My traits are
> measured mostly at the same time except for 1 trait which is measured only
> once or twice per individual. After reading a some literature on this I
> have a basic idea on how to structure my dataset. But the problem I am
> facing is that I need my covariance matrix to be different. I want my
> covariance matrix to exclude the 1 trait so that all trait can COvary
> together except for a particular one! So there won't be any
> within-individual COvariation between the particular trait and others.
> 
> creating a sample dataset-
> 
> df<- data.frame(ani_id = as.factor(1:10),
> sex=c("male","female","male","female","male","female","male","female","male","female"),age=c("young","adult","young","adult","adult","young","young",
> "adult","adult","adult"),value=runif(200,min=1,
> max=5),year=ceiling(runif(200,min=2010, max=2019)), PC1=runif(200, min=0.1,
> max=0.9))
> df$value[5:9]<- NA
> df$trait_id<- as.factor(paste("T",rep(1:10, each=20), sep="_"))
> 
> ## My Prior
> prior1 <- list(R = list(V =diag(10), nu = 0.002),
>                        G = list(G1 = list(V = diag(10), nu = 0.002,
>                                           alpha.mu = rep(0, 10),
>                                           alpha.V  = diag(10)*25^2)))
> ## MCMC model
> mcmc_trial1<-MCMCglmm(scale(value) ~ factor(sex)+
>               scale(year) + scale(year^2)+
>               scale(PC1)+ scale(PC1^2)+
>               factor(age),
>             random =~ us(trait_id):ani_id,
>             rcov =~ idh(trait_id):units,
>             family = c("gaussian"),
>             prior = prior1,
>             nitt=10000,
>             burnin=1000,
>             thin=10,
>             verbose = TRUE,
>             pr=TRUE,
>             data = df)
> 
> So when I see a covariance matrix I want the trait T1 to not covary with
> any other trait.
> 
> T1 T2 T3 T4 T5 T6 T7 T8 T9 T10
> T1 0,1 0 0 0 0 0 0 0 0 0
> T2 0 0,1 0,1 0,1 0,1 0,1 0,1 0,1 0,1 0,1
> T3 0 0,1 0,1 0,1 0,1 0,1 0,1 0,1 0,1 0,1
> T4 0 0,1 0,1 0,1 0,1 0,1 0,1 0,1 0,1 0,1
> T5 0 0,1 0,1 0,1 0,1 0,1 0,1 0,1 0,1 0,1
> T6 0 0,1 0,1 0,1 0,1 0,1 0,1 0,1 0,1 0,1
> T7 0 0,1 0,1 0,1 0,1 0,1 0,1 0,1 0,1 0,1
> T8 0 0,1 0,1 0,1 0,1 0,1 0,1 0,1 0,1 0,1
> T9 0 0,1 0,1 0,1 0,1 0,1 0,1 0,1 0,1 0,1
> T10 0 0,1 0,1 0,1 0,1 0,1 0,1 0,1 0,1 0,1
> 
> Where I am stuck is I do not know how to structure the covariance matrix to
> exclude T1.
> 
> Any suggestions or help is much appreciated. :)
> 
> Regards,
> Srivats.
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From ju@np|de @end|ng |rom gm@||@com  Wed Dec  2 20:01:53 2020
From: ju@np|de @end|ng |rom gm@||@com (Pi)
Date: Wed, 2 Dec 2020 20:01:53 +0100
Subject: [R-sig-ME] How to report and quantify the random effect in a
 logistic model?
Message-ID: <CAEQWovSyCXO+SmQEgsdKTieFXFs0CWMAOtHphSjJy5Li14txJw@mail.gmail.com>

Hello.

I'm fitting a logistic regression model with mixed effects using the
package glmmTMB. (Because the dataset is quite large and lme4 produces out
of memory errors, even increasing memory.limit).

I need help to interpret and report the output.

    Family: binomial  ( logit )
    Formula:      OUTPUT ~ SEX + YEAR + OTHER +  (1|CITY/ID)
    Data: mydata

          AIC       BIC    logLik  deviance  df.resid
     890000  891000 -450000  889000    1000000

    Random effects:

    Conditional model:
     Groups Name        Variance Std.Dev.
     ID:CITY (Intercept) 10.0    3.1
     CITY    (Intercept) 1.5    1.2
    Number of obs: 1000009, groups:  ID:CITY, 200000; CITY, 20

    Conditional model:
                 Estimate Std.Error z value Pr(>|z|)
    (Intercept)  0.79   0.28    2.9   0.005
    SEX1       -0.21   0.017 -12   <2e-16
    YEAR        0.48   0.0048 100   <2e-16
    OTHER       -0.70   0.005 -130   <2e-16

Output from sjPlot:

    Random Effects
    ?2 3.29
    ?00 ID:CITY 10.0
    ?00 CITY 1.5
    ICC 0.78


How can I report the effect of CITY and its confidence interval?
I think most people would report the CI of the odds of the Intercept using
the variance to calculate

     { exp(Intercept-1.96*1.2) , exp(Intercept+1.96*1.2) }

but this doesn't take into account the standard error of the Intercept from
the conditional model, 0.28. How should I combine them?
(I think this is the estimated deviation for the Intercept excluding the
random effects).

Is it acceptable to ignore the Intercept value and just say...?
"The 95% CI for the odds ratio for the CITY is
{exp(-1.96\*1.2),exp(+1.96\*1.2)}"

or

"The odds of OUTPUT is multiplied by a number between exp(-1.96\*1.2) and
exp(+1.96\*1.2) due to the variability of CITY". I don't know how to
include here the 95%IC argument.

I have also tried to calculate the residuals with residuals(model) but it
produces an out of memory error.
Is there any way to do it approximately? or is there already some useful
information in the output?

I just need to say what proportion of the total variance (or of the
residuals) is explained by the variable CITY.

The ?2 value reported by sjPlot is the variance of the residuals.

What about the variance of ID:CITY (Intercept) 10.0? How should I report
it? How can I split it into variance due to ID and variance due to the
interaction of ID and CITY?

	[[alternative HTML version deleted]]


From g@br|e||@@kountour|de@ @end|ng |rom @jc@ox@@c@uk  Wed Dec  2 20:25:27 2020
From: g@br|e||@@kountour|de@ @end|ng |rom @jc@ox@@c@uk (Gabriella Kountourides)
Date: Wed, 2 Dec 2020 19:25:27 +0000
Subject: [R-sig-ME] What to do with zero inflated, negative skewed,
 negative data: a question about GLMMs
In-Reply-To: <LNXP265MB053880E8735CF63A25DBCF43E8F50@LNXP265MB0538.GBRP265.PROD.OUTLOOK.COM>
References: <LNXP265MB053880E8735CF63A25DBCF43E8F50@LNXP265MB0538.GBRP265.PROD.OUTLOOK.COM>
Message-ID: <LNXP265MB0538F2C520AF1662C35751E3E8F30@LNXP265MB0538.GBRP265.PROD.OUTLOOK.COM>

Dear all,

Thank you for your valuable insight. Sorry, it has taken a few days to respond, I've had some trouble with glmmTMB on mac, I think it's sorted now...though I am still getting an error message, so I'm not certain whether or not my model is ok for my data.

I can't seem to fit the variance differently in glmmTMB (Thierry kindly suggested setting this, but the example was in lme, do you think I should do it here?
I'd love some insight into my model, can I do anything to make it better? Is it OK as is? I'm new to this so I'm not too sure what I'm checking for.

 See below:

> model1 <- glmmTMB(sentiment ~ question  + age + (1|patientID), data=dataset1)

Error in .Call("FreeADFunObject", ptr, PACKAGE = DLL) : "FreeADFunObject" not available for .Call() for package "glmmTMB"

model 1 gives me:

Family: gaussian  ( identity )
Formula:          sentiment ~ question + age + (1 | patientID)
Data: dataset1
AIC              BIC               logLik                 deviance              df.resid
7254.9      7296.5              -3621.4                 7242.9                7556

Random effects:
Conditional model:
     Groups          Name             Variance             Std.Dev.
      patientID     (Intercept).        8.732e-11        9.344e-06
     Residual                                 1.526e-01         3.906e-01
Number of obs: 7562, groups:  id, 2520

Dispersion estimate for gaussian family (sigma^2): 0.153

Conditional model:
                         Estimate         Std. Error        z value                    Pr(>|z|)
(Intercept)     -0.1655972       0.0204310       -8.105                    5.27e-16 ***
question2      0.0907564        0.0114045        7.958                    1.75e-15 ***
question3      0.0977533        0.0115802        8.441                     < 2e-16 ***
age               -0.0020644        0.0006483        -3.184                     0.00145 **

Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Once again, a huge thank you to all who have taken the time to read this!

Gabriella


Get Outlook for iOS<https://aka.ms/o0ukef>
________________________________
From: Gabriella Kountourides
Sent: Monday, November 30, 2020 12:23:48 AM
To: r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>
Subject: What to do with zero inflated, negative skewed, negative data: a question about GLMMs

Hello everyone,

This is my first question to this list :) I  hope this email finds you all well.


  I have been struggling for the past few weeks to set an appropriate model for my data. I have read Prof Bolker's practical guide for ecology and evolution paper, as well as the GLMM FAQs which have been immensely helpful. I am only just beginning my stats journey (and R!) and although I am really enjoying it, I have found myself completely stumped with my dataset. I will describe the data set below, and below that the various attempts I have made to analyse it. I would be incredibly grateful to hear your thoughts.

All the very best

Data:


I want to look whether there is a relationship between the phrasing used when a question is asked (positive, negative, neutral wording) and the polarity of the response from the individual.


2638 people were asked a question about medical symptoms.

1/3 of the people were asked it with a negative wording, 1/3 with a neutral one, 1/3 with a positive one.

The big question is: does the way the question is asked  affect the polarity of the response


>From this, I did sentiment analysis (using trincker's<https://github.com/trinker/sentimentr> package), which provides a polarity score (this can be negative, neutral or positive) to see whether their responses were more positive or negative, depending on the wording of the question.


Sentiment analysis breaks down responses into sentences, so I have 2638 people, but 7924 sentences, so I would assume to fit ID as a random effect.


Range: -4.0376 to + 0.7915.
Median :-0.1830
Mean   :-0.2149

Mode: 0
skew: -1.7

There are many 0s in my model, these are true 0s, they represent a 'neutral' response, which is important. My data is negatively skewed, so more people answer in a negative way. But I still want to know, whether the phrasings affect the skew/is one phrasing leading to 'less negative' responses?

What I've tried:
Initially, I tried to do a glm with the raw data, but I can't use poisson as it is negative, it is skewed so its not gaussian, and its not binomial.

So next I made 3 new variables, which were counts. For example 'PosCount' scored 1 for each row with a +polarity score, and a 0 if not.  Idem for neutral (sentiment=0) and positive (sentiment>0). Decided to run Zero Inflated Poisson

I ran a glmm for each count variable-example for the positive one:
pos <-glmmTMB(PosCount~ wordingQ + (1|id) + age, data=allprimesent, ziformula=~1, family=poisson)

and then the 'overdisp_fun' function which gave
> overdisp_fun(posmodel)
 chisq                  ratio                          rdf            p
6268.8427185    0.8295412.   7557.0000000    1.0000000

So I suppose my questions are: do you think this is the best thing to do with my data? Do you know of any better thing I can do with the raw data, I'd rather not lose the information about the strength of the sentiment, but if I keep it, I need a model that can deal with 0 inflation, negative skew, and negative numbers.

Many thanks if you've read this! I look forward to hearing from you!
All the best

p.s. I am relatively new to stats and R, please bare that in mind with your terminology if you are kind enough to answer


Gabriella Kountourides

DPhil Student | Department of Anthropology

Evolutionary Medicine and Public Health Group

St. John?s College, University of Oxford

gabriella.kountourides at sjc.ox.ac.uk

Tweet me: https://twitter.com/GKountourides

________________________________



	[[alternative HTML version deleted]]


From ebhod@ghe|@|th @end|ng |rom gm@||@com  Thu Dec  3 11:24:21 2020
From: ebhod@ghe|@|th @end|ng |rom gm@||@com (Ebhodaghe Faith)
Date: Thu, 3 Dec 2020 13:24:21 +0300
Subject: [R-sig-ME] Quasi Poisson for glmm
Message-ID: <CAEatWUraCCPskjfHcV-X=gWkEEaK0tPrMmdCCJKXqEtu=ts_TA@mail.gmail.com>

Hi All.

I have a dataset for wish I intend to model an over-dispersed proportion
response variable with hierarchical structure. I tried using the Quasi
Poisson family, but available packages including glmmTMB do not allow this.
What do you advice?

Thanks in advance for your kind response.

Faith Ebhodaghe
Nairobi, Kenya

	[[alternative HTML version deleted]]


From th|erry@onke||nx @end|ng |rom |nbo@be  Thu Dec  3 11:32:36 2020
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Thu, 3 Dec 2020 11:32:36 +0100
Subject: [R-sig-ME] Quasi Poisson for glmm
In-Reply-To: <CAEatWUraCCPskjfHcV-X=gWkEEaK0tPrMmdCCJKXqEtu=ts_TA@mail.gmail.com>
References: <CAEatWUraCCPskjfHcV-X=gWkEEaK0tPrMmdCCJKXqEtu=ts_TA@mail.gmail.com>
Message-ID: <CAJuCY5yrmU197WAb6OM7CpmDLSRg1SGZi9ZvZCampkGmqqiXEQ@mail.gmail.com>

Dear Faith,

You can use a negative binomial distribution.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op do 3 dec. 2020 om 11:24 schreef Ebhodaghe Faith <ebhodaghefaith at gmail.com
>:

> Hi All.
>
> I have a dataset for wish I intend to model an over-dispersed proportion
> response variable with hierarchical structure. I tried using the Quasi
> Poisson family, but available packages including glmmTMB do not allow this.
> What do you advice?
>
> Thanks in advance for your kind response.
>
> Faith Ebhodaghe
> Nairobi, Kenya
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From ebhod@ghe|@|th @end|ng |rom gm@||@com  Thu Dec  3 13:14:28 2020
From: ebhod@ghe|@|th @end|ng |rom gm@||@com (Ebhodaghe Faith)
Date: Thu, 3 Dec 2020 15:14:28 +0300
Subject: [R-sig-ME] Quasi Poisson for glmm
In-Reply-To: <CAJuCY5yrmU197WAb6OM7CpmDLSRg1SGZi9ZvZCampkGmqqiXEQ@mail.gmail.com>
References: <CAEatWUraCCPskjfHcV-X=gWkEEaK0tPrMmdCCJKXqEtu=ts_TA@mail.gmail.com>
 <CAJuCY5yrmU197WAb6OM7CpmDLSRg1SGZi9ZvZCampkGmqqiXEQ@mail.gmail.com>
Message-ID: <CAEatWUquTUXjiOypezTXZUYgbw4S5UZ+L2gajnkhVF+ixi41rw@mail.gmail.com>

Thanks, Thierry.

But could you please refer me to an article preferably in the biological
sciences where a negative binomial distribution was used to model an
over-dispersed multilevel proportion response variable?

Thanks for your kind assistance.

Regards
Faith

On Thu, 3 Dec 2020, 1:32 p.m. Thierry Onkelinx, <thierry.onkelinx at inbo.be>
wrote:

> Dear Faith,
>
> You can use a negative binomial distribution.
>
> Best regards,
>
> ir. Thierry Onkelinx
> Statisticus / Statistician
>
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
> FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Havenlaan 88 bus 73, 1000 Brussel
> www.inbo.be
>
>
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> ///////////////////////////////////////////////////////////////////////////////////////////
>
> <https://www.inbo.be>
>
>
> Op do 3 dec. 2020 om 11:24 schreef Ebhodaghe Faith <
> ebhodaghefaith at gmail.com>:
>
>> Hi All.
>>
>> I have a dataset for wish I intend to model an over-dispersed proportion
>> response variable with hierarchical structure. I tried using the Quasi
>> Poisson family, but available packages including glmmTMB do not allow
>> this.
>> What do you advice?
>>
>> Thanks in advance for your kind response.
>>
>> Faith Ebhodaghe
>> Nairobi, Kenya
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>

	[[alternative HTML version deleted]]


From th|erry@onke||nx @end|ng |rom |nbo@be  Thu Dec  3 14:48:17 2020
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Thu, 3 Dec 2020 14:48:17 +0100
Subject: [R-sig-ME] Quasi Poisson for glmm
In-Reply-To: <CAEatWUquTUXjiOypezTXZUYgbw4S5UZ+L2gajnkhVF+ixi41rw@mail.gmail.com>
References: <CAEatWUraCCPskjfHcV-X=gWkEEaK0tPrMmdCCJKXqEtu=ts_TA@mail.gmail.com>
 <CAJuCY5yrmU197WAb6OM7CpmDLSRg1SGZi9ZvZCampkGmqqiXEQ@mail.gmail.com>
 <CAEatWUquTUXjiOypezTXZUYgbw4S5UZ+L2gajnkhVF+ixi41rw@mail.gmail.com>
Message-ID: <CAJuCY5wY=8zh8OrT8q1+8dGRzJCWEyLJiZuwDPwgOqe2K0N4aA@mail.gmail.com>

Dear Faith,

I missed to see you have a proportion response. The negative binomial is a
(better) alternative for the quasi Poisson. But they assume count data.
What kind of proportions do you have? Is it based on a number of successes
for a number of trials (binomial, beta binomial)? Or a continuous value
between 0 and 1 (beta)?

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op do 3 dec. 2020 om 13:14 schreef Ebhodaghe Faith <ebhodaghefaith at gmail.com
>:

> Thanks, Thierry.
>
> But could you please refer me to an article preferably in the biological
> sciences where a negative binomial distribution was used to model an
> over-dispersed multilevel proportion response variable?
>
> Thanks for your kind assistance.
>
> Regards
> Faith
>
> On Thu, 3 Dec 2020, 1:32 p.m. Thierry Onkelinx, <thierry.onkelinx at inbo.be>
> wrote:
>
>> Dear Faith,
>>
>> You can use a negative binomial distribution.
>>
>> Best regards,
>>
>> ir. Thierry Onkelinx
>> Statisticus / Statistician
>>
>> Vlaamse Overheid / Government of Flanders
>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
>> AND FOREST
>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
>> thierry.onkelinx at inbo.be
>> Havenlaan 88 bus 73, 1000 Brussel
>> www.inbo.be
>>
>>
>> ///////////////////////////////////////////////////////////////////////////////////////////
>> To call in the statistician after the experiment is done may be no more
>> than asking him to perform a post-mortem examination: he may be able to say
>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does not
>> ensure that a reasonable answer can be extracted from a given body of data.
>> ~ John Tukey
>>
>> ///////////////////////////////////////////////////////////////////////////////////////////
>>
>> <https://www.inbo.be>
>>
>>
>> Op do 3 dec. 2020 om 11:24 schreef Ebhodaghe Faith <
>> ebhodaghefaith at gmail.com>:
>>
>>> Hi All.
>>>
>>> I have a dataset for wish I intend to model an over-dispersed proportion
>>> response variable with hierarchical structure. I tried using the Quasi
>>> Poisson family, but available packages including glmmTMB do not allow
>>> this.
>>> What do you advice?
>>>
>>> Thanks in advance for your kind response.
>>>
>>> Faith Ebhodaghe
>>> Nairobi, Kenya
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>

	[[alternative HTML version deleted]]


From ebhod@ghe|@|th @end|ng |rom gm@||@com  Thu Dec  3 16:16:51 2020
From: ebhod@ghe|@|th @end|ng |rom gm@||@com (Ebhodaghe Faith)
Date: Thu, 3 Dec 2020 18:16:51 +0300
Subject: [R-sig-ME] Quasi Poisson for glmm
In-Reply-To: <CAJuCY5wY=8zh8OrT8q1+8dGRzJCWEyLJiZuwDPwgOqe2K0N4aA@mail.gmail.com>
References: <CAEatWUraCCPskjfHcV-X=gWkEEaK0tPrMmdCCJKXqEtu=ts_TA@mail.gmail.com>
 <CAJuCY5yrmU197WAb6OM7CpmDLSRg1SGZi9ZvZCampkGmqqiXEQ@mail.gmail.com>
 <CAEatWUquTUXjiOypezTXZUYgbw4S5UZ+L2gajnkhVF+ixi41rw@mail.gmail.com>
 <CAJuCY5wY=8zh8OrT8q1+8dGRzJCWEyLJiZuwDPwgOqe2K0N4aA@mail.gmail.com>
Message-ID: <CAEatWUrAjvR8YvP5d06MPM0CpUeHxz_bjDmVBTTGyfDegCQFeg@mail.gmail.com>

Dear Thierry,
The proportions are on number of individuals infected by a parasite divided
by total number of individuals examined.

Thanks
Faith

On Thu, 3 Dec 2020, 4:48 p.m. Thierry Onkelinx, <thierry.onkelinx at inbo.be>
wrote:

> Dear Faith,
>
> I missed to see you have a proportion response. The negative binomial is a
> (better) alternative for the quasi Poisson. But they assume count data.
> What kind of proportions do you have? Is it based on a number of successes
> for a number of trials (binomial, beta binomial)? Or a continuous value
> between 0 and 1 (beta)?
>
> Best regards,
>
> ir. Thierry Onkelinx
> Statisticus / Statistician
>
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
> FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Havenlaan 88 bus 73, 1000 Brussel
> www.inbo.be
>
>
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> ///////////////////////////////////////////////////////////////////////////////////////////
>
> <https://www.inbo.be>
>
>
> Op do 3 dec. 2020 om 13:14 schreef Ebhodaghe Faith <
> ebhodaghefaith at gmail.com>:
>
>> Thanks, Thierry.
>>
>> But could you please refer me to an article preferably in the biological
>> sciences where a negative binomial distribution was used to model an
>> over-dispersed multilevel proportion response variable?
>>
>> Thanks for your kind assistance.
>>
>> Regards
>> Faith
>>
>> On Thu, 3 Dec 2020, 1:32 p.m. Thierry Onkelinx, <thierry.onkelinx at inbo.be>
>> wrote:
>>
>>> Dear Faith,
>>>
>>> You can use a negative binomial distribution.
>>>
>>> Best regards,
>>>
>>> ir. Thierry Onkelinx
>>> Statisticus / Statistician
>>>
>>> Vlaamse Overheid / Government of Flanders
>>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
>>> AND FOREST
>>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
>>> thierry.onkelinx at inbo.be
>>> Havenlaan 88 bus 73, 1000 Brussel
>>> www.inbo.be
>>>
>>>
>>> ///////////////////////////////////////////////////////////////////////////////////////////
>>> To call in the statistician after the experiment is done may be no more
>>> than asking him to perform a post-mortem examination: he may be able to say
>>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>>> The plural of anecdote is not data. ~ Roger Brinner
>>> The combination of some data and an aching desire for an answer does not
>>> ensure that a reasonable answer can be extracted from a given body of data.
>>> ~ John Tukey
>>>
>>> ///////////////////////////////////////////////////////////////////////////////////////////
>>>
>>> <https://www.inbo.be>
>>>
>>>
>>> Op do 3 dec. 2020 om 11:24 schreef Ebhodaghe Faith <
>>> ebhodaghefaith at gmail.com>:
>>>
>>>> Hi All.
>>>>
>>>> I have a dataset for wish I intend to model an over-dispersed proportion
>>>> response variable with hierarchical structure. I tried using the Quasi
>>>> Poisson family, but available packages including glmmTMB do not allow
>>>> this.
>>>> What do you advice?
>>>>
>>>> Thanks in advance for your kind response.
>>>>
>>>> Faith Ebhodaghe
>>>> Nairobi, Kenya
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>

	[[alternative HTML version deleted]]


From th|erry@onke||nx @end|ng |rom |nbo@be  Thu Dec  3 16:55:43 2020
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Thu, 3 Dec 2020 16:55:43 +0100
Subject: [R-sig-ME] Quasi Poisson for glmm
In-Reply-To: <CAEatWUrAjvR8YvP5d06MPM0CpUeHxz_bjDmVBTTGyfDegCQFeg@mail.gmail.com>
References: <CAEatWUraCCPskjfHcV-X=gWkEEaK0tPrMmdCCJKXqEtu=ts_TA@mail.gmail.com>
 <CAJuCY5yrmU197WAb6OM7CpmDLSRg1SGZi9ZvZCampkGmqqiXEQ@mail.gmail.com>
 <CAEatWUquTUXjiOypezTXZUYgbw4S5UZ+L2gajnkhVF+ixi41rw@mail.gmail.com>
 <CAJuCY5wY=8zh8OrT8q1+8dGRzJCWEyLJiZuwDPwgOqe2K0N4aA@mail.gmail.com>
 <CAEatWUrAjvR8YvP5d06MPM0CpUeHxz_bjDmVBTTGyfDegCQFeg@mail.gmail.com>
Message-ID: <CAJuCY5wGsDqK_G3rcW+ubhxmvQr_sadtq4jQd_O4rWYv+ZqGOg@mail.gmail.com>

Dear Faith,

I'd recommend starting with a full model with binomial distribution. What
you perceive as overdispersion in the response is often modelled by the
covariates.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op do 3 dec. 2020 om 16:17 schreef Ebhodaghe Faith <ebhodaghefaith at gmail.com
>:

> Dear Thierry,
> The proportions are on number of individuals infected by a parasite
> divided by total number of individuals examined.
>
> Thanks
> Faith
>
> On Thu, 3 Dec 2020, 4:48 p.m. Thierry Onkelinx, <thierry.onkelinx at inbo.be>
> wrote:
>
>> Dear Faith,
>>
>> I missed to see you have a proportion response. The negative binomial is
>> a (better) alternative for the quasi Poisson. But they assume count data.
>> What kind of proportions do you have? Is it based on a number of
>> successes for a number of trials (binomial, beta binomial)? Or a continuous
>> value between 0 and 1 (beta)?
>>
>> Best regards,
>>
>> ir. Thierry Onkelinx
>> Statisticus / Statistician
>>
>> Vlaamse Overheid / Government of Flanders
>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
>> AND FOREST
>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
>> thierry.onkelinx at inbo.be
>> Havenlaan 88 bus 73, 1000 Brussel
>> www.inbo.be
>>
>>
>> ///////////////////////////////////////////////////////////////////////////////////////////
>> To call in the statistician after the experiment is done may be no more
>> than asking him to perform a post-mortem examination: he may be able to say
>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does not
>> ensure that a reasonable answer can be extracted from a given body of data.
>> ~ John Tukey
>>
>> ///////////////////////////////////////////////////////////////////////////////////////////
>>
>> <https://www.inbo.be>
>>
>>
>> Op do 3 dec. 2020 om 13:14 schreef Ebhodaghe Faith <
>> ebhodaghefaith at gmail.com>:
>>
>>> Thanks, Thierry.
>>>
>>> But could you please refer me to an article preferably in the biological
>>> sciences where a negative binomial distribution was used to model an
>>> over-dispersed multilevel proportion response variable?
>>>
>>> Thanks for your kind assistance.
>>>
>>> Regards
>>> Faith
>>>
>>> On Thu, 3 Dec 2020, 1:32 p.m. Thierry Onkelinx, <
>>> thierry.onkelinx at inbo.be> wrote:
>>>
>>>> Dear Faith,
>>>>
>>>> You can use a negative binomial distribution.
>>>>
>>>> Best regards,
>>>>
>>>> ir. Thierry Onkelinx
>>>> Statisticus / Statistician
>>>>
>>>> Vlaamse Overheid / Government of Flanders
>>>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
>>>> AND FOREST
>>>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
>>>> thierry.onkelinx at inbo.be
>>>> Havenlaan 88 bus 73, 1000 Brussel
>>>> www.inbo.be
>>>>
>>>>
>>>> ///////////////////////////////////////////////////////////////////////////////////////////
>>>> To call in the statistician after the experiment is done may be no more
>>>> than asking him to perform a post-mortem examination: he may be able to say
>>>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>>>> The plural of anecdote is not data. ~ Roger Brinner
>>>> The combination of some data and an aching desire for an answer does
>>>> not ensure that a reasonable answer can be extracted from a given body of
>>>> data. ~ John Tukey
>>>>
>>>> ///////////////////////////////////////////////////////////////////////////////////////////
>>>>
>>>> <https://www.inbo.be>
>>>>
>>>>
>>>> Op do 3 dec. 2020 om 11:24 schreef Ebhodaghe Faith <
>>>> ebhodaghefaith at gmail.com>:
>>>>
>>>>> Hi All.
>>>>>
>>>>> I have a dataset for wish I intend to model an over-dispersed
>>>>> proportion
>>>>> response variable with hierarchical structure. I tried using the Quasi
>>>>> Poisson family, but available packages including glmmTMB do not allow
>>>>> this.
>>>>> What do you advice?
>>>>>
>>>>> Thanks in advance for your kind response.
>>>>>
>>>>> Faith Ebhodaghe
>>>>> Nairobi, Kenya
>>>>>
>>>>>         [[alternative HTML version deleted]]
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>
>>>>

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Thu Dec  3 18:30:40 2020
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Thu, 3 Dec 2020 12:30:40 -0500
Subject: [R-sig-ME] Quasi Poisson for glmm
In-Reply-To: <CAJuCY5wGsDqK_G3rcW+ubhxmvQr_sadtq4jQd_O4rWYv+ZqGOg@mail.gmail.com>
References: <CAEatWUraCCPskjfHcV-X=gWkEEaK0tPrMmdCCJKXqEtu=ts_TA@mail.gmail.com>
 <CAJuCY5yrmU197WAb6OM7CpmDLSRg1SGZi9ZvZCampkGmqqiXEQ@mail.gmail.com>
 <CAEatWUquTUXjiOypezTXZUYgbw4S5UZ+L2gajnkhVF+ixi41rw@mail.gmail.com>
 <CAJuCY5wY=8zh8OrT8q1+8dGRzJCWEyLJiZuwDPwgOqe2K0N4aA@mail.gmail.com>
 <CAEatWUrAjvR8YvP5d06MPM0CpUeHxz_bjDmVBTTGyfDegCQFeg@mail.gmail.com>
 <CAJuCY5wGsDqK_G3rcW+ubhxmvQr_sadtq4jQd_O4rWYv+ZqGOg@mail.gmail.com>
Message-ID: <b66055d6-e162-c86e-e72d-f44f68b17cd7@gmail.com>

    I agree with Thierry that the binomial is a good start.

    If you do find that there is overdispersion in your binomial model, 
there are (at least) three possible approaches (see 
http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#overdispersion ):

   * beta-binomial model
   * observation-level random effects in a binomial model
   * quasi-binomial

   The last one is not available in glmmTMB, but the GLMM FAQ 
http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html shows you how to 
get quasi-likelihood results if you want.

   cheers
     Ben Bolker


On 12/3/20 10:55 AM, Thierry Onkelinx via R-sig-mixed-models wrote:
> Dear Faith,
> 
> I'd recommend starting with a full model with binomial distribution. What
> you perceive as overdispersion in the response is often modelled by the
> covariates.
> 
> Best regards,
> 
> ir. Thierry Onkelinx
> Statisticus / Statistician
> 
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
> FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Havenlaan 88 bus 73, 1000 Brussel
> www.inbo.be
> 
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
> ///////////////////////////////////////////////////////////////////////////////////////////
> 
> <https://www.inbo.be>
> 
> 
> Op do 3 dec. 2020 om 16:17 schreef Ebhodaghe Faith <ebhodaghefaith at gmail.com
>> :
> 
>> Dear Thierry,
>> The proportions are on number of individuals infected by a parasite
>> divided by total number of individuals examined.
>>
>> Thanks
>> Faith
>>
>> On Thu, 3 Dec 2020, 4:48 p.m. Thierry Onkelinx, <thierry.onkelinx at inbo.be>
>> wrote:
>>
>>> Dear Faith,
>>>
>>> I missed to see you have a proportion response. The negative binomial is
>>> a (better) alternative for the quasi Poisson. But they assume count data.
>>> What kind of proportions do you have? Is it based on a number of
>>> successes for a number of trials (binomial, beta binomial)? Or a continuous
>>> value between 0 and 1 (beta)?
>>>
>>> Best regards,
>>>
>>> ir. Thierry Onkelinx
>>> Statisticus / Statistician
>>>
>>> Vlaamse Overheid / Government of Flanders
>>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
>>> AND FOREST
>>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
>>> thierry.onkelinx at inbo.be
>>> Havenlaan 88 bus 73, 1000 Brussel
>>> www.inbo.be
>>>
>>>
>>> ///////////////////////////////////////////////////////////////////////////////////////////
>>> To call in the statistician after the experiment is done may be no more
>>> than asking him to perform a post-mortem examination: he may be able to say
>>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>>> The plural of anecdote is not data. ~ Roger Brinner
>>> The combination of some data and an aching desire for an answer does not
>>> ensure that a reasonable answer can be extracted from a given body of data.
>>> ~ John Tukey
>>>
>>> ///////////////////////////////////////////////////////////////////////////////////////////
>>>
>>> <https://www.inbo.be>
>>>
>>>
>>> Op do 3 dec. 2020 om 13:14 schreef Ebhodaghe Faith <
>>> ebhodaghefaith at gmail.com>:
>>>
>>>> Thanks, Thierry.
>>>>
>>>> But could you please refer me to an article preferably in the biological
>>>> sciences where a negative binomial distribution was used to model an
>>>> over-dispersed multilevel proportion response variable?
>>>>
>>>> Thanks for your kind assistance.
>>>>
>>>> Regards
>>>> Faith
>>>>
>>>> On Thu, 3 Dec 2020, 1:32 p.m. Thierry Onkelinx, <
>>>> thierry.onkelinx at inbo.be> wrote:
>>>>
>>>>> Dear Faith,
>>>>>
>>>>> You can use a negative binomial distribution.
>>>>>
>>>>> Best regards,
>>>>>
>>>>> ir. Thierry Onkelinx
>>>>> Statisticus / Statistician
>>>>>
>>>>> Vlaamse Overheid / Government of Flanders
>>>>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
>>>>> AND FOREST
>>>>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
>>>>> thierry.onkelinx at inbo.be
>>>>> Havenlaan 88 bus 73, 1000 Brussel
>>>>> www.inbo.be
>>>>>
>>>>>
>>>>> ///////////////////////////////////////////////////////////////////////////////////////////
>>>>> To call in the statistician after the experiment is done may be no more
>>>>> than asking him to perform a post-mortem examination: he may be able to say
>>>>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>>>>> The plural of anecdote is not data. ~ Roger Brinner
>>>>> The combination of some data and an aching desire for an answer does
>>>>> not ensure that a reasonable answer can be extracted from a given body of
>>>>> data. ~ John Tukey
>>>>>
>>>>> ///////////////////////////////////////////////////////////////////////////////////////////
>>>>>
>>>>> <https://www.inbo.be>
>>>>>
>>>>>
>>>>> Op do 3 dec. 2020 om 11:24 schreef Ebhodaghe Faith <
>>>>> ebhodaghefaith at gmail.com>:
>>>>>
>>>>>> Hi All.
>>>>>>
>>>>>> I have a dataset for wish I intend to model an over-dispersed
>>>>>> proportion
>>>>>> response variable with hierarchical structure. I tried using the Quasi
>>>>>> Poisson family, but available packages including glmmTMB do not allow
>>>>>> this.
>>>>>> What do you advice?
>>>>>>
>>>>>> Thanks in advance for your kind response.
>>>>>>
>>>>>> Faith Ebhodaghe
>>>>>> Nairobi, Kenya
>>>>>>
>>>>>>          [[alternative HTML version deleted]]
>>>>>>
>>>>>> _______________________________________________
>>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>>
>>>>>
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From ebhod@ghe|@|th @end|ng |rom gm@||@com  Thu Dec  3 19:26:03 2020
From: ebhod@ghe|@|th @end|ng |rom gm@||@com (Ebhodaghe Faith)
Date: Thu, 3 Dec 2020 21:26:03 +0300
Subject: [R-sig-ME] Quasi Poisson for glmm
In-Reply-To: <b66055d6-e162-c86e-e72d-f44f68b17cd7@gmail.com>
References: <CAEatWUraCCPskjfHcV-X=gWkEEaK0tPrMmdCCJKXqEtu=ts_TA@mail.gmail.com>
 <CAJuCY5yrmU197WAb6OM7CpmDLSRg1SGZi9ZvZCampkGmqqiXEQ@mail.gmail.com>
 <CAEatWUquTUXjiOypezTXZUYgbw4S5UZ+L2gajnkhVF+ixi41rw@mail.gmail.com>
 <CAJuCY5wY=8zh8OrT8q1+8dGRzJCWEyLJiZuwDPwgOqe2K0N4aA@mail.gmail.com>
 <CAEatWUrAjvR8YvP5d06MPM0CpUeHxz_bjDmVBTTGyfDegCQFeg@mail.gmail.com>
 <CAJuCY5wGsDqK_G3rcW+ubhxmvQr_sadtq4jQd_O4rWYv+ZqGOg@mail.gmail.com>
 <b66055d6-e162-c86e-e72d-f44f68b17cd7@gmail.com>
Message-ID: <CAEatWUqtvO-+2kz+wLrA0NPq6qBsvXfn_nxjbzGsAfxuYiRP+w@mail.gmail.com>

Many thanks to you both, Thierry and Ben for your kind responses, which I
find really helpful.

Regards
Faith

On Thu, 3 Dec 2020 8:31 pm Ben Bolker, <bbolker at gmail.com> wrote:

>     I agree with Thierry that the binomial is a good start.
>
>     If you do find that there is overdispersion in your binomial model,
> there are (at least) three possible approaches (see
> http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#overdispersion ):
>
>    * beta-binomial model
>    * observation-level random effects in a binomial model
>    * quasi-binomial
>
>    The last one is not available in glmmTMB, but the GLMM FAQ
> http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html shows you how to
> get quasi-likelihood results if you want.
>
>    cheers
>      Ben Bolker
>
>
> On 12/3/20 10:55 AM, Thierry Onkelinx via R-sig-mixed-models wrote:
> > Dear Faith,
> >
> > I'd recommend starting with a full model with binomial distribution. What
> > you perceive as overdispersion in the response is often modelled by the
> > covariates.
> >
> > Best regards,
> >
> > ir. Thierry Onkelinx
> > Statisticus / Statistician
> >
> > Vlaamse Overheid / Government of Flanders
> > INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
> AND
> > FOREST
> > Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> > thierry.onkelinx at inbo.be
> > Havenlaan 88 bus 73, 1000 Brussel
> > www.inbo.be
> >
> >
> ///////////////////////////////////////////////////////////////////////////////////////////
> > To call in the statistician after the experiment is done may be no more
> > than asking him to perform a post-mortem examination: he may be able to
> say
> > what the experiment died of. ~ Sir Ronald Aylmer Fisher
> > The plural of anecdote is not data. ~ Roger Brinner
> > The combination of some data and an aching desire for an answer does not
> > ensure that a reasonable answer can be extracted from a given body of
> data.
> > ~ John Tukey
> >
> ///////////////////////////////////////////////////////////////////////////////////////////
> >
> > <https://www.inbo.be>
> >
> >
> > Op do 3 dec. 2020 om 16:17 schreef Ebhodaghe Faith <
> ebhodaghefaith at gmail.com
> >> :
> >
> >> Dear Thierry,
> >> The proportions are on number of individuals infected by a parasite
> >> divided by total number of individuals examined.
> >>
> >> Thanks
> >> Faith
> >>
> >> On Thu, 3 Dec 2020, 4:48 p.m. Thierry Onkelinx, <
> thierry.onkelinx at inbo.be>
> >> wrote:
> >>
> >>> Dear Faith,
> >>>
> >>> I missed to see you have a proportion response. The negative binomial
> is
> >>> a (better) alternative for the quasi Poisson. But they assume count
> data.
> >>> What kind of proportions do you have? Is it based on a number of
> >>> successes for a number of trials (binomial, beta binomial)? Or a
> continuous
> >>> value between 0 and 1 (beta)?
> >>>
> >>> Best regards,
> >>>
> >>> ir. Thierry Onkelinx
> >>> Statisticus / Statistician
> >>>
> >>> Vlaamse Overheid / Government of Flanders
> >>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
> >>> AND FOREST
> >>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> >>> thierry.onkelinx at inbo.be
> >>> Havenlaan 88 bus 73, 1000 Brussel
> >>> www.inbo.be
> >>>
> >>>
> >>>
> ///////////////////////////////////////////////////////////////////////////////////////////
> >>> To call in the statistician after the experiment is done may be no more
> >>> than asking him to perform a post-mortem examination: he may be able
> to say
> >>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> >>> The plural of anecdote is not data. ~ Roger Brinner
> >>> The combination of some data and an aching desire for an answer does
> not
> >>> ensure that a reasonable answer can be extracted from a given body of
> data.
> >>> ~ John Tukey
> >>>
> >>>
> ///////////////////////////////////////////////////////////////////////////////////////////
> >>>
> >>> <https://www.inbo.be>
> >>>
> >>>
> >>> Op do 3 dec. 2020 om 13:14 schreef Ebhodaghe Faith <
> >>> ebhodaghefaith at gmail.com>:
> >>>
> >>>> Thanks, Thierry.
> >>>>
> >>>> But could you please refer me to an article preferably in the
> biological
> >>>> sciences where a negative binomial distribution was used to model an
> >>>> over-dispersed multilevel proportion response variable?
> >>>>
> >>>> Thanks for your kind assistance.
> >>>>
> >>>> Regards
> >>>> Faith
> >>>>
> >>>> On Thu, 3 Dec 2020, 1:32 p.m. Thierry Onkelinx, <
> >>>> thierry.onkelinx at inbo.be> wrote:
> >>>>
> >>>>> Dear Faith,
> >>>>>
> >>>>> You can use a negative binomial distribution.
> >>>>>
> >>>>> Best regards,
> >>>>>
> >>>>> ir. Thierry Onkelinx
> >>>>> Statisticus / Statistician
> >>>>>
> >>>>> Vlaamse Overheid / Government of Flanders
> >>>>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR
> NATURE
> >>>>> AND FOREST
> >>>>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> >>>>> thierry.onkelinx at inbo.be
> >>>>> Havenlaan 88 bus 73, 1000 Brussel
> >>>>> www.inbo.be
> >>>>>
> >>>>>
> >>>>>
> ///////////////////////////////////////////////////////////////////////////////////////////
> >>>>> To call in the statistician after the experiment is done may be no
> more
> >>>>> than asking him to perform a post-mortem examination: he may be able
> to say
> >>>>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> >>>>> The plural of anecdote is not data. ~ Roger Brinner
> >>>>> The combination of some data and an aching desire for an answer does
> >>>>> not ensure that a reasonable answer can be extracted from a given
> body of
> >>>>> data. ~ John Tukey
> >>>>>
> >>>>>
> ///////////////////////////////////////////////////////////////////////////////////////////
> >>>>>
> >>>>> <https://www.inbo.be>
> >>>>>
> >>>>>
> >>>>> Op do 3 dec. 2020 om 11:24 schreef Ebhodaghe Faith <
> >>>>> ebhodaghefaith at gmail.com>:
> >>>>>
> >>>>>> Hi All.
> >>>>>>
> >>>>>> I have a dataset for wish I intend to model an over-dispersed
> >>>>>> proportion
> >>>>>> response variable with hierarchical structure. I tried using the
> Quasi
> >>>>>> Poisson family, but available packages including glmmTMB do not
> allow
> >>>>>> this.
> >>>>>> What do you advice?
> >>>>>>
> >>>>>> Thanks in advance for your kind response.
> >>>>>>
> >>>>>> Faith Ebhodaghe
> >>>>>> Nairobi, Kenya
> >>>>>>
> >>>>>>          [[alternative HTML version deleted]]
> >>>>>>
> >>>>>> _______________________________________________
> >>>>>> R-sig-mixed-models at r-project.org mailing list
> >>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>>>>>
> >>>>>
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From m@|one @end|ng |rom m@|onequ@nt|t@t|ve@com  Thu Dec  3 22:50:53 2020
From: m@|one @end|ng |rom m@|onequ@nt|t@t|ve@com (Patrick (Malone Quantitative))
Date: Thu, 3 Dec 2020 16:50:53 -0500
Subject: [R-sig-ME] Multiple random slopes in coxme
Message-ID: <CAJc=yOEDfLeci-gLw_TXGoKUsApMSN4HbV_AjzzCJMEv0neWKA@mail.gmail.com>

Greetings. I was referred here from Cross-Validated and would
appreciate any help.

I'm using coxme v.2.2-16 in R v.4.0.3. The goal is a multilevel Cox
survival model with random slopes associated with level-1 predictors
"x1" and "x2," nested in level-2 units "cluster." I'm getting an error
I'm stuck on.

I found a related question on Stack Exchange at
https://stackoverflow.com/questions/51246155/random-slopes-cox-proportional-hazards
, in which a respondent quoted Terry Thernau saying multiple random
slopes (Terry's example fit4) should be possible, though estimation is
challenging--my error is different, I'm just citing Terry's "should."

The data look like:

  FailTime Event x1 x2 cluster
1     1778     1  1  1     516
2     2192     0  1  1     618
3     1108     1  0  1     516
4      903     1  1  1     516
5     2031     1  1  0     558
6      836     1  1  1     619

A minimal reprex is:

library(coxme)
library(readr)
testdata <- read.csv(file="coxme_test.csv",row.names=1)
resultx1 <- coxme(Surv(FailTime,Event) ~ x1 + x2 + (1 + x1 | cluster),
data=testdata)
resultx1x2 <- coxme(Surv(FailTime,Event) ~ x1 + x2 + (1 + x1 + x2 |
cluster), data=testdata)

resultx1 runs fine (as does the same model with a single random slope
for x2 instead of x1).

resultx1x2 returns

Error in `[<-`(`*tmp*`, 1:n1 + irow, 1:n1 + icol, value =
as.matrix(addup(zcov))) :
  subscript out of bounds
In addition: Warning message:
In sqrt(xvar * zvar) : NaNs produced

For now, I'm not worried about the warning--I can improve my starting
values. But I've had no luck tracking down any information about the
error. I'd appreciate any help.

I have placed a masked sample of my data as a .csv at
https://github.com/psmalone/reprex/blob/main/coxme_test.csv .

Thanks,
Pat

-- 
Patrick S. Malone, Ph.D., Malone Quantitative
NEW Service Models: http://malonequantitative.com

He/Him/His


From t|@nt|y @end|ng |rom g@c|em@on@edu  Fri Dec  4 03:37:00 2020
From: t|@nt|y @end|ng |rom g@c|em@on@edu (Tiantian Yang)
Date: Thu, 3 Dec 2020 21:37:00 -0500
Subject: [R-sig-ME] Different estimates for mixed effects Logistic
 regression and pwrssUpdate Error message with binomial glmer
Message-ID: <CA+kyBsVrnwiRFjHCg=pRwQoO-yzXfHfV=b5qrvgvXKQRVaOqdg@mail.gmail.com>

Hi All,

I am new to this list. I hope this email finds you all well.

I have several questions and it is not convenient to post here via email. I
just posted my questions on Cross-Validated with details. The link is as
below.
https://stats.stackexchange.com/questions/499269/different-estimates-for-mixed-effects-logistic-regression-and-pwrssupdate-error

The data and sample code are shared below.
https://drive.google.com/file/d/1ZTiDUhTcoyOWUCa2vjXR95VlcpyzxGiU/view?usp=sharing
https://drive.google.com/file/d/1Fe3RMMh-tkgFg5gCbrsSgD0uyklKJejl/view?usp=sharing

I will deeply appreciate any comments on one or all of the issues.

Best,
Tiantian

	[[alternative HTML version deleted]]


From D@v|d@Du||y @end|ng |rom q|mrbergho|er@edu@@u  Fri Dec  4 05:03:49 2020
From: D@v|d@Du||y @end|ng |rom q|mrbergho|er@edu@@u (David Duffy)
Date: Fri, 4 Dec 2020 04:03:49 +0000
Subject: [R-sig-ME] Different estimates for mixed effects Logistic
 regression and pwrssUpdate Error message with binomial glmer
In-Reply-To: <CA+kyBsVrnwiRFjHCg=pRwQoO-yzXfHfV=b5qrvgvXKQRVaOqdg@mail.gmail.com>
References: <CA+kyBsVrnwiRFjHCg=pRwQoO-yzXfHfV=b5qrvgvXKQRVaOqdg@mail.gmail.com>
Message-ID: <3df461edb5da4af091e50a82e291410f@qimrberghofer.edu.au>

Hi.

> https://stats.stackexchange.com/questions/499269/different-estimates-for-mixed-effects-logistic-regression-and-pwrssupdate-error

> The data are shared below.
> https://drive.google.com/file/d/1ZTiDUhTcoyOWUCa2vjXR95VlcpyzxGiU/view?usp=sharing

I'm having a little trouble understanding exactly what you want. Are these the actual data you want to analyse? Since you have such a simple random effects art of the model, there are many alternatives, including nonparametric models where you don't have to specify a distribution for the random effects (the default you are using here is Gaussian).  These programs will *all* give slightly different answers. Check out the different published results different programs give for the dataset from Crowder, "Beta-binomial ANOVA for proportions." Applied statistics 1978: 34-37. 

I tried out the glmmML package on your data, as I find it well behaved - see its documentation. One advantage (for me) is that it gives significance tests for the random effects.

glmmML(formula = y ~ x1 + x2, data = x, cluster = group, control = list(maxit = 1000),  method = "ghq") 

                          coef se(coef)      z Pr(>|z|)
(Intercept) -1.1521   0.8386 -1.374    0.169
x1                 0.6044   0.4626  1.306    0.191
x2                1.1099   0.8141  1.363    0.173
Scale parameter in mixing distribution:  2.12 gaussian 
Std. Error:                              2.599 
        LR p-value for H_0: sigma = 0:  0.2082 

Call:  glmmML(formula = y ~ x1 + x2, data = x[-55, ], cluster = group,  control = list(maxit = 1000), method = "ghq") 
               coef se(coef)      z Pr(>|z|)
(Intercept) -1.1491   0.8369 -1.373    0.170
x1                 0.5981   0.4630  1.292    0.196
x2                1.0992   0.8145  1.350    0.177
Scale parameter in mixing distribution:  2.101 gaussian 
Std. Error:                              2.615 
        LR p-value for H_0: sigma = 0:  0.2116 

Call:  glmmML(formula = y ~ x1 + x2, data = x, cluster = group, prior = "logistic",  control = list(maxit = 1000), method = "ghq") 
               coef se(coef)      z Pr(>|z|)
(Intercept) -1.4260   1.1504 -1.240    0.215
x1           0.8034   0.5658  1.420    0.156
x2           1.4835   1.0384  1.429    0.153
Scale parameter in mixing distribution:  1.76 logistic 
Std. Error:                              1.548 
        LR p-value for H_0: sigma = 0:  0.1227 

Call:  glmmML(formula = y ~ x1 + x2, data = x, cluster = group, prior = "cauchy",  control = list(maxit = 1000), method = "ghq") 

               coef se(coef)      z Pr(>|z|)
(Intercept) -1.5690   1.0233 -1.533  0.12500
x1           0.9551   0.3442  2.775  0.00553
x2           1.7864   0.6710  2.662  0.00776
Scale parameter in mixing distribution:  1.44 cauchy 
Std. Error:                              0.4347 
        LR p-value for H_0: sigma = 0:  0.5 
Residual deviance: 60.08 on 71 degrees of freedom 	AIC: 68.08

These look comparable to results from non-R programs.

From me @end|ng |rom ph||||p@|d@y@com  Fri Dec  4 16:11:21 2020
From: me @end|ng |rom ph||||p@|d@y@com (Phillip Alday)
Date: Fri, 4 Dec 2020 16:11:21 +0100
Subject: [R-sig-ME] What it means for rho to be 0 in lme() when using
 compound symmetry
In-Reply-To: <CACgv6yX97JD_tsuAb6AVrd4-ErpUYQagmyXpmupgjDoU92KY7Q@mail.gmail.com>
References: <CACgv6yX97JD_tsuAb6AVrd4-ErpUYQagmyXpmupgjDoU92KY7Q@mail.gmail.com>
Message-ID: <0d4833ff-b3d9-92ed-07f3-3fe70ddc7335@phillipalday.com>

From
https://stat.ethz.ch/R-manual/R-devel/library/nlme/html/pdCompSymm.html :

"This function is a constructor for the pdCompSymm class, representing a
positive-definite matrix with compound symmetry structure (constant
diagonal and constant off-diagonal elements)."

Any multiple of the identity matrix is technically compound symmetric,
because all the off-diagonal elements are the same (0).

Phillip

On 28/11/20 2:30 am, Simon Harmel wrote:
> Hello All,
> 
> Below, I'm using corCompSymm() (compound symmetry) for my simple model.
> 
> The rho is estimated to be 0. I was wondering what it means for rho in the
> var-covariance matrix to be "0"? Is my var-covariance matrix below valid?
> -- Thank you all, Simon
> #----------------------------------------------------------------
> library(nlme)
> data <- read.csv('https://raw.githubusercontent.com/hkil/m/master/R.csv')
> 
> m <- lme(Achieve ~ time, random = ~1|subid, data = data, correlation =
> corCompSymm())
> 
>   aa <- corMatrix(m$modelStruct$corStruct)[[1]]
>   aa * sigma(m)^2
> 
>          [,1]     [,2]     [,3]     [,4]
> [1,] 112.5003   0.0000   0.0000   0.0000
> [2,]   0.0000 112.5003   0.0000   0.0000
> [3,]   0.0000   0.0000 112.5003   0.0000
> [4,]   0.0000   0.0000   0.0000 112.5003
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From @|m@h@rme| @end|ng |rom gm@||@com  Fri Dec  4 16:23:25 2020
From: @|m@h@rme| @end|ng |rom gm@||@com (Simon Harmel)
Date: Fri, 4 Dec 2020 09:23:25 -0600
Subject: [R-sig-ME] What it means for rho to be 0 in lme() when using
 compound symmetry
In-Reply-To: <0d4833ff-b3d9-92ed-07f3-3fe70ddc7335@phillipalday.com>
References: <CACgv6yX97JD_tsuAb6AVrd4-ErpUYQagmyXpmupgjDoU92KY7Q@mail.gmail.com>
 <0d4833ff-b3d9-92ed-07f3-3fe70ddc7335@phillipalday.com>
Message-ID: <CACgv6yXxMHcBP9EJDiHNKR0CBWv_3xLoup68D0LKvZbZaPa9JA@mail.gmail.com>

Thanks, Phillip. Given the estimated rho of 0 obtained from the default
correlation structure in lme(), can we say that for this dataset there is
no dependence left after fitting the 2-level model shown in my original
post?

In other words, once getting a rho of 0 from the default correlation
structure for this model, then one doesn't need to think of alternative
correlation structures, because even the default correlation structure has
shown that there is no dependence to model.

Is this a reasonable conclusion?

On Fri, Dec 4, 2020, 9:11 AM Phillip Alday <me at phillipalday.com> wrote:

> From
> https://stat.ethz.ch/R-manual/R-devel/library/nlme/html/pdCompSymm.html :
>
> "This function is a constructor for the pdCompSymm class, representing a
> positive-definite matrix with compound symmetry structure (constant
> diagonal and constant off-diagonal elements)."
>
> Any multiple of the identity matrix is technically compound symmetric,
> because all the off-diagonal elements are the same (0).
>
> Phillip
>
> On 28/11/20 2:30 am, Simon Harmel wrote:
> > Hello All,
> >
> > Below, I'm using corCompSymm() (compound symmetry) for my simple model.
> >
> > The rho is estimated to be 0. I was wondering what it means for rho in
> the
> > var-covariance matrix to be "0"? Is my var-covariance matrix below valid?
> > -- Thank you all, Simon
> > #----------------------------------------------------------------
> > library(nlme)
> > data <- read.csv('https://raw.githubusercontent.com/hkil/m/master/R.csv
> ')
> >
> > m <- lme(Achieve ~ time, random = ~1|subid, data = data, correlation =
> > corCompSymm())
> >
> >   aa <- corMatrix(m$modelStruct$corStruct)[[1]]
> >   aa * sigma(m)^2
> >
> >          [,1]     [,2]     [,3]     [,4]
> > [1,] 112.5003   0.0000   0.0000   0.0000
> > [2,]   0.0000 112.5003   0.0000   0.0000
> > [3,]   0.0000   0.0000 112.5003   0.0000
> > [4,]   0.0000   0.0000   0.0000 112.5003
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>

	[[alternative HTML version deleted]]


From me @end|ng |rom ph||||p@|d@y@com  Fri Dec  4 16:32:41 2020
From: me @end|ng |rom ph||||p@|d@y@com (Phillip Alday)
Date: Fri, 4 Dec 2020 16:32:41 +0100
Subject: [R-sig-ME] What it means for rho to be 0 in lme() when using
 compound symmetry
In-Reply-To: <CACgv6yXxMHcBP9EJDiHNKR0CBWv_3xLoup68D0LKvZbZaPa9JA@mail.gmail.com>
References: <CACgv6yX97JD_tsuAb6AVrd4-ErpUYQagmyXpmupgjDoU92KY7Q@mail.gmail.com>
 <0d4833ff-b3d9-92ed-07f3-3fe70ddc7335@phillipalday.com>
 <CACgv6yXxMHcBP9EJDiHNKR0CBWv_3xLoup68D0LKvZbZaPa9JA@mail.gmail.com>
Message-ID: <3d374dd1-3f9c-d411-b7c8-ddf8562de1c1@phillipalday.com>

The 'default' structure is generally the unstructured positive definite
matrix. (In lme4, this constraint is loosened to positive
semi-definite). Starting from compound symmetric is already placing a
constraint and so forcing all off-diagonal elements to zero may be the
best solution *under that constraint*. (And a multiple of the identity
matrix is a stricter constraint than a diagonal matrix, even though both
have all off diagonal elements set to zero.)

A more modern take would be using something like rePCA on the full
unstructured matrix (https://arxiv.org/abs/1506.04967 or
https://doi.org/10.33016/nextjournal.100002) to see what the effective
dimensionality is. Of course, you can fit a model with a diagonal RE
covariance matrix even if the data have some correlation, at the cost of
changing how shrinkage works
(https://doingbayesiandataanalysis.blogspot.com/2019/07/shrinkage-in-hierarchical-models-random.html).
That may be an acceptable (variance-bias) tradeoff -- less efficient
shrinkage but also less overparameterization.

All of these comments without looking at your data.

On 4/12/20 4:23 pm, Simon Harmel wrote:
> Thanks, Phillip. Given the estimated rho of 0 obtained from the default
> correlation structure in lme(), can we say that for this dataset there
> is no dependence left after fitting the 2-level model shown in my
> original post?
> 
> In other words, once getting a rho of 0 from the default correlation
> structure for this model, then one doesn't need to think of alternative
> correlation structures, because even the default correlation structure
> has shown that there is no dependence to model.
> 
> Is this a reasonable conclusion?
> 
> On Fri, Dec 4, 2020, 9:11 AM Phillip Alday <me at phillipalday.com
> <mailto:me at phillipalday.com>> wrote:
> 
>     From
>     https://stat.ethz.ch/R-manual/R-devel/library/nlme/html/pdCompSymm.html
>     :
> 
>     "This function is a constructor for the pdCompSymm class, representing a
>     positive-definite matrix with compound symmetry structure (constant
>     diagonal and constant off-diagonal elements)."
> 
>     Any multiple of the identity matrix is technically compound symmetric,
>     because all the off-diagonal elements are the same (0).
> 
>     Phillip
> 
>     On 28/11/20 2:30 am, Simon Harmel wrote:
>     > Hello All,
>     >
>     > Below, I'm using corCompSymm() (compound symmetry) for my simple
>     model.
>     >
>     > The rho is estimated to be 0. I was wondering what it means for
>     rho in the
>     > var-covariance matrix to be "0"? Is my var-covariance matrix below
>     valid?
>     > -- Thank you all, Simon
>     > #----------------------------------------------------------------
>     > library(nlme)
>     > data <-
>     read.csv('https://raw.githubusercontent.com/hkil/m/master/R.csv')
>     >
>     > m <- lme(Achieve ~ time, random = ~1|subid, data = data, correlation =
>     > corCompSymm())
>     >
>     >? ?aa <- corMatrix(m$modelStruct$corStruct)[[1]]
>     >? ?aa * sigma(m)^2
>     >
>     >? ? ? ? ? [,1]? ? ?[,2]? ? ?[,3]? ? ?[,4]
>     > [1,] 112.5003? ?0.0000? ?0.0000? ?0.0000
>     > [2,]? ?0.0000 112.5003? ?0.0000? ?0.0000
>     > [3,]? ?0.0000? ?0.0000 112.5003? ?0.0000
>     > [4,]? ?0.0000? ?0.0000? ?0.0000 112.5003
>     >
>     >? ? ? ?[[alternative HTML version deleted]]
>     >
>     > _______________________________________________
>     > R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>     > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     >
>


From |uc@c1980 @end|ng |rom y@hoo@|t  Fri Dec  4 23:33:03 2020
From: |uc@c1980 @end|ng |rom y@hoo@|t (luca corlatti)
Date: Fri, 4 Dec 2020 22:33:03 +0000 (UTC)
Subject: [R-sig-ME] Quasi-GAMM AIC?
References: <892791016.8917662.1607121183468.ref@mail.yahoo.com>
Message-ID: <892791016.8917662.1607121183468@mail.yahoo.com>

Dear all,?a quick question regarding AIC & quasi-GAMM.
I'm investigating age-dependent variation in body mass in 2 different populations, and decided to go for a GAM approach. As my data are grouped within years & areas, these have been fitted as random intercepts. In the attempt to fix heterogeneity issues in residual variance, I fitted the model with a "quasi" family, so that it looks like:
mod1 <- gamm(mass ~ s(age, by= population) + population,? ? ? ? ? ? ? ? ? ? ? ? ? data = my.data,? ? ? ? ? ? ? ? ? ? ? ? ? random = list(year = ~ 1, area = ~ 1),?? ? ? ? ? ? ? ? ? ? ? ? ? family = quasi(link = "identity", variance = "mu"))
Now, if I try to extract the AIC from this model, I actually get a value (16620.34), and a seemingly reasonable one (if compared to a corresponding full-likelihood Tweedie GAMM, which returns the same AIC).
My question is, how is it possible that I get an AIC from a quasi-family?
Re-fitting the same model without random terms:?
mod2 <- gam(mass ~ s(age, by= population) + population,? ? ? ? ? ? ? ? ? ? ? ?data = my.data,? ? ? ? ? ? ? ? ? ? ? ?family=quasi(link="identity", variance = "mu"))
AIC(mod2) gives, as expected, a "NA".
What allows GAMM to return an AIC value even when using a quasi-family?
Thanks in advance for your help!Luca

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Sat Dec  5 01:12:57 2020
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Fri, 4 Dec 2020 19:12:57 -0500
Subject: [R-sig-ME] Quasi-GAMM AIC?
In-Reply-To: <892791016.8917662.1607121183468@mail.yahoo.com>
References: <892791016.8917662.1607121183468.ref@mail.yahoo.com>
 <892791016.8917662.1607121183468@mail.yahoo.com>
Message-ID: <b162b833-8cee-934b-db82-0ef19763d9ef@gmail.com>



On 12/4/20 5:33 PM, luca corlatti via R-sig-mixed-models wrote:
> Dear all,?a quick question regarding AIC & quasi-GAMM.
> I'm investigating age-dependent variation in body mass in 2 different populations, and decided to go for a GAM approach. As my data are grouped within years & areas, these have been fitted as random intercepts. In the attempt to fix heterogeneity issues in residual variance, I fitted the model with a "quasi" family, so that it looks like:


> mod1 <- gamm(mass ~ s(age, by= population) + population,? ? ? ? ? ? ? ? ? ? ? ? ? data = my.data,? ? ? ? ? ? ? ? ? ? ? ? ? random = list(year = ~ 1, area = ~ 1),?? ? ? ? ? ? ? ? ? ? ? ? ? family = quasi(link = "identity", variance = "mu"))
> Now, if I try to extract the AIC from this model, I actually get a value (16620.34), and a seemingly reasonable one (if compared to a corresponding full-likelihood Tweedie GAMM, which returns the same AIC).
> My question is, how is it possible that I get an AIC from a quasi-family?
> Re-fitting the same model without random terms:
> mod2 <- gam(mass ~ s(age, by= population) + population,? ? ? ? ? ? ? ? ? ? ? ?data = my.data,? ? ? ? ? ? ? ? ? ? ? ?family=quasi(link="identity", variance = "mu"))
> AIC(mod2) gives, as expected, a "NA".
> What allows GAMM to return an AIC value even when using a quasi-family?
> Thanks in advance for your help!

Luca

tl;dr I wouldn't trust it !

   It took me a while, but I think I found the answer.

   Your AIC calculation only 'works' (for some value of 'works') because 
you have the MuMIn package loaded.
	

library(mgcv)
library(MuMIn)
data(sleepstudy,package="lme4")
mod1 <- gamm(Reaction ~s(Days), random=list(Subject = ~1),
              data=sleepstudy,
              family=quasi(link="identity", variance="mu"))


The mystery of why MuMIn provides a logLik method for gamm objects is 
explained in a document called "Model selection with MuMIn and GAMM" 
which can be found here ...

https://r-forge.r-project.org/scm/viewvc.php/*checkout*/pkg/inst/doc/gamm.pdf?revision=91&root=mumin&pathrev=92

"In the case of gamm and gamm4, the returned object has no special 
class, it is a list with two items: lme or mer, and gam (with some 
information stripped from it). Therefore no specific methods can be 
applied.The solution is to provide a wrapper function for gamm that 
evaluates the model and adds a class attribute onto it ...

<technical details>

It should be noted here that the issue of what the log-likelihood for 
GAMM should be is not entirely clear. The documentation for gamm states 
that the log-likelihood of lme is not the one of the fitted GAMM. 
However, comparing alternative models shows some evidence that it may be 
still appropriate for gamm. Namely the log-likelihood of fitted lme, and 
one of the lme part of gamm (including only linear terms to make the 
comparison adequate), have identical value ..."

?mgcv::gamm says:

?gamm? assumes that you know what you are doing! For example, unlike 
?glmmPQL? from ?MASS? it will return the complete ?lme? object from the 
working model at convergence of the PQL iteration, including the `log 
likelihood', even though this is not the likelihood of the fitted GAMM.

   THere's an argument for using "quasi-AIC" in model selection problems 
<https://cran.r-project.org/web/packages/bbmle/vignettes/quasi.pdf> , 
but it seems mostly confined to wildlife ecologists ... 
https://stat.ethz.ch/pipermail/r-help/2003-July/035898.html


From @|m@h@rme| @end|ng |rom gm@||@com  Sat Dec  5 01:57:06 2020
From: @|m@h@rme| @end|ng |rom gm@||@com (Simon Harmel)
Date: Fri, 4 Dec 2020 18:57:06 -0600
Subject: [R-sig-ME] What it means for rho to be 0 in lme() when using
 compound symmetry
In-Reply-To: <3d374dd1-3f9c-d411-b7c8-ddf8562de1c1@phillipalday.com>
References: <CACgv6yX97JD_tsuAb6AVrd4-ErpUYQagmyXpmupgjDoU92KY7Q@mail.gmail.com>
 <0d4833ff-b3d9-92ed-07f3-3fe70ddc7335@phillipalday.com>
 <CACgv6yXxMHcBP9EJDiHNKR0CBWv_3xLoup68D0LKvZbZaPa9JA@mail.gmail.com>
 <3d374dd1-3f9c-d411-b7c8-ddf8562de1c1@phillipalday.com>
Message-ID: <CACgv6yV22v9TBi4JgyNkenZFJXae-C=V652tt+eVeo7k0=rVEw@mail.gmail.com>

Phillip, I think I called corCompSymm() default in my specific case because
the rho was estimated to be "0" and of course the same variances are taken
to be on the diagonal. In other words, I thought such a result from
corCompSymm() acts as an equivalent to the default covariance structure of
random-effects (see AIC() comparison below).

The above reasoning also made me think that perhaps there is no correlation
left after fitting a default model and thus no need to think about what
correlation structure may best fit this particular dataset.

I also read Bates et al (2015). My takeaway was that we should use
lme4::rePCA to detect possible overfit in the random structure of the model
(often fitting random slopes when no/little such variation among the
individual slopes really exists in the data).

So, would you mind elaborating on the connection between using lme4::rePCA
and specifying the correlation structure in the model (e.g., using lme())?

For concreteness, here is the simple model I have in mind:

library(nlme)
data <- read.csv('https://raw.githubusercontent.com/hkil/m/master/R.csv')

m1 <- lme(Achieve ~ time, random = ~1|subid, data = data, correlation =
corCompSymm())
m2 <- lme(Achieve ~ time, random = ~1|subid, data = data, correlation = NULL
)

AIC(m1, m2)

   df      AIC
m1  5 2534.387  # Yes, rho is estimated But it is 0!
m2  4 2532.387

On Fri, Dec 4, 2020 at 9:32 AM Phillip Alday <me at phillipalday.com> wrote:

> The 'default' structure is generally the unstructured positive definite
> matrix. (In lme4, this constraint is loosened to positive
> semi-definite). Starting from compound symmetric is already placing a
> constraint and so forcing all off-diagonal elements to zero may be the
> best solution *under that constraint*. (And a multiple of the identity
> matrix is a stricter constraint than a diagonal matrix, even though both
> have all off diagonal elements set to zero.)
>
> A more modern take would be using something like rePCA on the full
> unstructured matrix (https://arxiv.org/abs/1506.04967 or
> https://doi.org/10.33016/nextjournal.100002) to see what the effective
> dimensionality is. Of course, you can fit a model with a diagonal RE
> covariance matrix even if the data have some correlation, at the cost of
> changing how shrinkage works
> (
> https://doingbayesiandataanalysis.blogspot.com/2019/07/shrinkage-in-hierarchical-models-random.html
> ).
> That may be an acceptable (variance-bias) tradeoff -- less efficient
> shrinkage but also less overparameterization.
>
> All of these comments without looking at your data.
>
> On 4/12/20 4:23 pm, Simon Harmel wrote:
> > Thanks, Phillip. Given the estimated rho of 0 obtained from the default
> > correlation structure in lme(), can we say that for this dataset there
> > is no dependence left after fitting the 2-level model shown in my
> > original post?
> >
> > In other words, once getting a rho of 0 from the default correlation
> > structure for this model, then one doesn't need to think of alternative
> > correlation structures, because even the default correlation structure
> > has shown that there is no dependence to model.
> >
> > Is this a reasonable conclusion?
> >
> > On Fri, Dec 4, 2020, 9:11 AM Phillip Alday <me at phillipalday.com
> > <mailto:me at phillipalday.com>> wrote:
> >
> >     From
> >
> https://stat.ethz.ch/R-manual/R-devel/library/nlme/html/pdCompSymm.html
> >     :
> >
> >     "This function is a constructor for the pdCompSymm class,
> representing a
> >     positive-definite matrix with compound symmetry structure (constant
> >     diagonal and constant off-diagonal elements)."
> >
> >     Any multiple of the identity matrix is technically compound
> symmetric,
> >     because all the off-diagonal elements are the same (0).
> >
> >     Phillip
> >
> >     On 28/11/20 2:30 am, Simon Harmel wrote:
> >     > Hello All,
> >     >
> >     > Below, I'm using corCompSymm() (compound symmetry) for my simple
> >     model.
> >     >
> >     > The rho is estimated to be 0. I was wondering what it means for
> >     rho in the
> >     > var-covariance matrix to be "0"? Is my var-covariance matrix below
> >     valid?
> >     > -- Thank you all, Simon
> >     > #----------------------------------------------------------------
> >     > library(nlme)
> >     > data <-
> >     read.csv('https://raw.githubusercontent.com/hkil/m/master/R.csv')
> >     >
> >     > m <- lme(Achieve ~ time, random = ~1|subid, data = data,
> correlation =
> >     > corCompSymm())
> >     >
> >     >   aa <- corMatrix(m$modelStruct$corStruct)[[1]]
> >     >   aa * sigma(m)^2
> >     >
> >     >          [,1]     [,2]     [,3]     [,4]
> >     > [1,] 112.5003   0.0000   0.0000   0.0000
> >     > [2,]   0.0000 112.5003   0.0000   0.0000
> >     > [3,]   0.0000   0.0000 112.5003   0.0000
> >     > [4,]   0.0000   0.0000   0.0000 112.5003
> >     >
> >     >       [[alternative HTML version deleted]]
> >     >
> >     > _______________________________________________
> >     > R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org> mailing list
> >     > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     >
> >
>

	[[alternative HTML version deleted]]


From |uc@@cor|@tt| @end|ng |rom boku@@c@@t  Sat Dec  5 09:10:02 2020
From: |uc@@cor|@tt| @end|ng |rom boku@@c@@t (Boku mail)
Date: Sat, 5 Dec 2020 09:10:02 +0100
Subject: [R-sig-ME] Quasi-GAMM AIC?
In-Reply-To: <892791016.8917662.1607121183468.ref@mail.yahoo.com>
 <892791016.8917662.1607121183468@mail.yahoo.com>
 <b162b833-8cee-934b-db82-0ef19763d9ef@gmail.com>
References: <892791016.8917662.1607121183468.ref@mail.yahoo.com>
 <892791016.8917662.1607121183468@mail.yahoo.com>
 <b162b833-8cee-934b-db82-0ef19763d9ef@gmail.com>
Message-ID: <2f38bcda-cff2-4dd8-ad98-83918167c03c@Spark>

Thank you Ben, that explains a lot!

Just to add up to the discussion, interestingly, when comparing:

library(mgcv)
library(MuMIn)
data(sleepstudy,package="lme4")

mod1 <- gamm(Reaction ~s(Days), random=list(Subject = ~1),
?				data=sleepstudy,
				 family=quasi(link="identity", variance="mu"))

to:

mod2 <- gamm(Reaction ~s(Days), random=list(Subject = ~1),
?				data=sleepstudy,
?				family=Tweedie(p=1.0001, link=power(1)))

AIC(mod1, mod2)

mod1 1797.943
mod2 1797.943

the AIC values are indeed identical.

I suppose it would be interesting to know under which circumstances Barton?s heuristic works or not.
(qAIC is a minor pain, but from a practitioner?s perspective, AIC is handier!)

Luca

Il 5 dic 2020, 01:13 +0100, Ben Bolker <bbolker at gmail.com>, ha scritto:
>
>
> On 12/4/20 5:33 PM, luca corlatti via R-sig-mixed-models wrote:
> > Dear all,?a quick question regarding AIC & quasi-GAMM.
> > I'm investigating age-dependent variation in body mass in 2 different populations, and decided to go for a GAM approach. As my data are grouped within years & areas, these have been fitted as random intercepts. In the attempt to fix heterogeneity issues in residual variance, I fitted the model with a "quasi" family, so that it looks like:
>
>
> > mod1 <- gamm(mass ~ s(age, by= population) + population,? ? ? ? ? ? ? ? ? ? ? ? ? data = my.data,? ? ? ? ? ? ? ? ? ? ? ? ? random = list(year = ~ 1, area = ~ 1),?? ? ? ? ? ? ? ? ? ? ? ? ? family = quasi(link = "identity", variance = "mu"))
> > Now, if I try to extract the AIC from this model, I actually get a value (16620.34), and a seemingly reasonable one (if compared to a corresponding full-likelihood Tweedie GAMM, which returns the same AIC).
> > My question is, how is it possible that I get an AIC from a quasi-family?
> > Re-fitting the same model without random terms:
> > mod2 <- gam(mass ~ s(age, by= population) + population,? ? ? ? ? ? ? ? ? ? ? ?data = my.data,? ? ? ? ? ? ? ? ? ? ? ?family=quasi(link="identity", variance = "mu"))
> > AIC(mod2) gives, as expected, a "NA".
> > What allows GAMM to return an AIC value even when using a quasi-family?
> > Thanks in advance for your help!
>
> Luca
>
> tl;dr I wouldn't trust it !
>
> It took me a while, but I think I found the answer.
>
> Your AIC calculation only 'works' (for some value of 'works') because
> you have the MuMIn package loaded.
>
>
> library(mgcv)
> library(MuMIn)
> data(sleepstudy,package="lme4")
> mod1 <- gamm(Reaction ~s(Days), random=list(Subject = ~1),
> data=sleepstudy,
> family=quasi(link="identity", variance="mu"))
>
>
> The mystery of why MuMIn provides a logLik method for gamm objects is
> explained in a document called "Model selection with MuMIn and GAMM"
> which can be found here ...
>
> https://r-forge.r-project.org/scm/viewvc.php/*checkout*/pkg/inst/doc/gamm.pdf?revision=91&root=mumin&pathrev=92
>
> "In the case of gamm and gamm4, the returned object has no special
> class, it is a list with two items: lme or mer, and gam (with some
> information stripped from it). Therefore no specific methods can be
> applied.The solution is to provide a wrapper function for gamm that
> evaluates the model and adds a class attribute onto it ...
>
> <technical details>
>
> It should be noted here that the issue of what the log-likelihood for
> GAMM should be is not entirely clear. The documentation for gamm states
> that the log-likelihood of lme is not the one of the fitted GAMM.
> However, comparing alternative models shows some evidence that it may be
> still appropriate for gamm. Namely the log-likelihood of fitted lme, and
> one of the lme part of gamm (including only linear terms to make the
> comparison adequate), have identical value ..."
>
> ?mgcv::gamm says:
>
> ?gamm? assumes that you know what you are doing! For example, unlike
> ?glmmPQL? from ?MASS? it will return the complete ?lme? object from the
> working model at convergence of the PQL iteration, including the `log
> likelihood', even though this is not the likelihood of the fitted GAMM.
>
> THere's an argument for using "quasi-AIC" in model selection problems
> <https://cran.r-project.org/web/packages/bbmle/vignettes/quasi.pdf> ,
> but it seems mostly confined to wildlife ecologists ...
> https://stat.ethz.ch/pipermail/r-help/2003-July/035898.html
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From D@v|d@Du||y @end|ng |rom q|mrbergho|er@edu@@u  Mon Dec  7 00:50:35 2020
From: D@v|d@Du||y @end|ng |rom q|mrbergho|er@edu@@u (David Duffy)
Date: Sun, 6 Dec 2020 23:50:35 +0000
Subject: [R-sig-ME] Multiple random slopes in coxme
In-Reply-To: <CAJc=yOEDfLeci-gLw_TXGoKUsApMSN4HbV_AjzzCJMEv0neWKA@mail.gmail.com>
References: <CAJc=yOEDfLeci-gLw_TXGoKUsApMSN4HbV_AjzzCJMEv0neWKA@mail.gmail.com>
Message-ID: <ae350192014641429d37e43492e0297b@qimrberghofer.edu.au>

> I have placed a masked sample of my data as a .csv at
> https://github.com/psmalone/reprex/blob/main/coxme_test.csv .

I don't know how much it helps, but I think parametric survival models are more robust if you want slopes
eg for your data above, a Weibull model:

survreg(formula = Surv(FailTime, Event) ~ x1 + x2 + (x1 + x2) *  frailty(cluster), data = x)

                    coef     se(coef) se2      Chisq    DF   p      
(Intercept)          7.47245 0.038162 0.030435 38340.62  1.0 0.0e+00
x1                  -0.04780 0.047612 0.044369     1.01  1.0 3.2e-01
x2                   0.06143 0.038344 0.038165     2.57  1.0 1.1e-01
frailty(cluster)                                 157.43 71.1 1.8e-08
x1:frailty(cluster)  0.00104 0.000746 0.000659     1.95  1.0 1.6e-01
x2:frailty(cluster) -0.00171 0.000642 0.000638     7.08  1.0 7.8e-03

Scale= 0.552 

Iterations: 10 outer, 30 Newton-Raphson
     Variance of random effect= 0.0522   I-likelihood = -5351.6 
Degrees of freedom for terms=  0.6  0.9  1.0 71.1  0.8  1.0  1.0 
Likelihood ratio test=224  on 74.3 df, p=<2e-16  n= 5000 


From m@|one @end|ng |rom m@|onequ@nt|t@t|ve@com  Mon Dec  7 01:38:37 2020
From: m@|one @end|ng |rom m@|onequ@nt|t@t|ve@com (Patrick (Malone Quantitative))
Date: Sun, 6 Dec 2020 19:38:37 -0500
Subject: [R-sig-ME] Multiple random slopes in coxme
In-Reply-To: <ae350192014641429d37e43492e0297b@qimrberghofer.edu.au>
References: <CAJc=yOEDfLeci-gLw_TXGoKUsApMSN4HbV_AjzzCJMEv0neWKA@mail.gmail.com>
 <ae350192014641429d37e43492e0297b@qimrberghofer.edu.au>
Message-ID: <CAJc=yOFb0_82fb2FeE3iUOBvw1PYOvRp8E_2pr_ZDtw4RETB1w@mail.gmail.com>

Huh. I'll think about how that generalizes to the bigger use case. Thanks!

On Sun, Dec 6, 2020 at 6:50 PM David Duffy <David.Duffy at qimrberghofer.edu.au>
wrote:

> > I have placed a masked sample of my data as a .csv at
> > https://github.com/psmalone/reprex/blob/main/coxme_test.csv .
>
> I don't know how much it helps, but I think parametric survival models are
> more robust if you want slopes
> eg for your data above, a Weibull model:
>
> survreg(formula = Surv(FailTime, Event) ~ x1 + x2 + (x1 + x2) *
> frailty(cluster), data = x)
>
>                     coef     se(coef) se2      Chisq    DF   p
> (Intercept)          7.47245 0.038162 0.030435 38340.62  1.0 0.0e+00
> x1                  -0.04780 0.047612 0.044369     1.01  1.0 3.2e-01
> x2                   0.06143 0.038344 0.038165     2.57  1.0 1.1e-01
> frailty(cluster)                                 157.43 71.1 1.8e-08
> x1:frailty(cluster)  0.00104 0.000746 0.000659     1.95  1.0 1.6e-01
> x2:frailty(cluster) -0.00171 0.000642 0.000638     7.08  1.0 7.8e-03
>
> Scale= 0.552
>
> Iterations: 10 outer, 30 Newton-Raphson
>      Variance of random effect= 0.0522   I-likelihood = -5351.6
> Degrees of freedom for terms=  0.6  0.9  1.0 71.1  0.8  1.0  1.0
> Likelihood ratio test=224  on 74.3 df, p=<2e-16  n= 5000
>
>
>

-- 
Patrick S. Malone, Ph.D., Malone Quantitative
NEW Service Models: http://malonequantitative.com

He/Him/His

	[[alternative HTML version deleted]]


From g@br|e||@@kountour|de@ @end|ng |rom @jc@ox@@c@uk  Mon Dec  7 18:09:35 2020
From: g@br|e||@@kountour|de@ @end|ng |rom @jc@ox@@c@uk (Gabriella Kountourides)
Date: Mon, 7 Dec 2020 17:09:35 +0000
Subject: [R-sig-ME] Interpreting GLMM output and is this the right model?
Message-ID: <LNXP265MB05387D448BFA6431EAC91F7AE8CE0@LNXP265MB0538.GBRP265.PROD.OUTLOOK.COM>

Hi everyone,

I emailed a few weeks ago, but am still struggling with this data.
The description of the question below, and model/code/output at the bottom. Many thanks for reading.


I want to look at whether there is a relationship between the way a question is asked (positive, negative, neutral wording) and the sentiment of the response. I have 2638 people asked a question about symptoms. 1/3 of the people were asked it with a negative wording, 1/3 with a neutral one, 1/3 with a positive one. From this, I did sentiment analysis (using Trincker's package) to see whether their responses were more positive or negative, depending on the wording of the question.
Sentiment analysis breaks down responses into sentences, so I have 2638 people, but 7924 sentences, so I would assume to fit ID as a random effect.

The big question is: does the way the question is asked (primetype) affect the polarity/sentiment of the response?
My data is negatively skewed, and has a lot of 0s (this is because some people felt 'neutral'  and so they scored '0'.

Model using the dataframe DF, to see how primetype (this is the way the question is asked) predicts sentiment (the polarity score, which is negatively skewed with lots of 0s), fixed effect is age, and random effect is ID

```
glmmTMB(sentiment ~ primetype + age + (1|id), data=DF)
```


Output:

```
Family: gaussian  ( identity )
Formula:          sentiment ~ primetype + age + (1 | id)
Data: DF

     AIC      BIC                 logLik        deviance       df.resid
  7254.9   7296.5          -3621.4        7242.9         7556

Random effects:

Conditional model:
 Groups          Name                Variance           Std.Dev.
 id                   (Intercept)            8.732e-11     9.344e-06
 Residual                                   1.526e-01         3.906e-01
Number of obs: 7562, groups:  id, 2520

Dispersion estimate for gaussian family (sigma^2): 0.153

Conditional model:
                         Estimate           Std. Error            z value           Pr(>|z|)
(Intercept).   -0.1655972         0.0204310         -8.105           5.27e-16 ***
primetype2   0.0907564         0.0114045          7.958           1.75e-15 ***
primetype3   0.0977533         0.0115802         8.441           < 2e-16 ***
age                -0.0020644          0.0006483       -3.184           0.00145 **
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
```
How can I interpret whether the model is a good one for my data, is there something else I should be doing? I'm not sure how to interpret the output at all. Would be immensely grateful for any insight


Thanks all


Gabriella Kountourides

DPhil Student | Department of Anthropology

Evolutionary Medicine and Public Health Group

St. John?s College, University of Oxford

gabriella.kountourides at sjc.ox.ac.uk

Tweet me: https://twitter.com/GKountourides

________________________________



	[[alternative HTML version deleted]]


From |uc@@cor|@tt| @end|ng |rom boku@@c@@t  Mon Dec  7 19:07:55 2020
From: |uc@@cor|@tt| @end|ng |rom boku@@c@@t (Boku mail)
Date: Mon, 7 Dec 2020 19:07:55 +0100
Subject: [R-sig-ME] 
 Interpreting GLMM output and is this the right model?
In-Reply-To: <LNXP265MB05387D448BFA6431EAC91F7AE8CE0@LNXP265MB0538.GBRP265.PROD.OUTLOOK.COM>
References: <LNXP265MB05387D448BFA6431EAC91F7AE8CE0@LNXP265MB0538.GBRP265.PROD.OUTLOOK.COM>
Message-ID: <a984b669-0758-4a39-9d45-5600c9bb6e15@Spark>

Dear Gabriella,
A few thoughts:

1) generally speaking, it doesn?t make much sense to look at the distribution of the raw response. The choice of the ?family? argument is rather??based on the conditional distribution, i.e., the distribution of the response across the fitted line (or, in other words, the distribution of the response after accounting for the linear predictor). In this respect, I guess it?s hard to say whether the skewness you mention may be a problem or not (same for the zeros).

2) you fitted a mixed model with Gaussian conditional distribution. Whether this is a ?good model? or not, is hard to say (e.g., does your linear predictor include the *supposedly* important explanatory variables, in the correct form? etc.), but at least I would inspect the residuals? behavior. This would allow you at least to check if the model is not grossly wrong. Suppose your model name is ?mod.1?, then you could do:

library(DHARMa)
sim.mod.1 <- simulateResiduals(mod.1)
plot(sim.mod.1)

Or, alternatively:
library(performance)
check_model(mod.1) # but DHARMa would be handier if you decided to change conditional distribution, and fit a GLMM

If the model is not grossly wrong, residuals should be distributed in an unsystematic way. If you have weird patterns, then you?re probably off-track. If that happens, you should inspect what?s wrong in your model (conditional distribution? Missing variables? etc.)

3) once you?re confident your model is ?well behaved?, then you can inspect the results. What your current summary says, basically, is that after accounting for primetype, if you increase age by 1 unit, you?ll have a decrease??of -0.0020644 in sentiment, and this decrease is statistically significant (basically, Estimate/ Std. Error??= z value; the z-score measures how far [in standard errors] your estimate is from zero; z-score follows a standard normal distribution, hence a value of z < -1.96 or z > 1.96 will be statistically significant at an alpha = 0.5). Whether this is also biologically significant, up to you to say!
The same reasoning applies to the primetype levels, except that this is a categorical variable, so primetype2 will be 0.0907564 ?sentiment scores? higher than the baseline primetype1 (the intercept).
Should you be interested in comparing different primetype levels in a pairwise manner:

library(emmeans)
emmeans(mod.1, ~primetype) # haven?t used this in a while, so cross-check in the package :-)

Result interpretation is straightforward in the case of a LMM, which uses an identity link function; should you use a different link, then things would be tricker to interpret, and plotting the marginal effects would be wise:

library(visreg)
visreg(mod.1, ?primetype", scale=?response")

However, I guess the crucial step for you will be to inspect the behavior of the model in the first place.

Hope this helps!
Luca




Il 7 dic 2020, 18:10 +0100, Gabriella Kountourides <gabriella.kountourides at sjc.ox.ac.uk>, ha scritto:
> Hi everyone,
>
> I emailed a few weeks ago, but am still struggling with this data.
> The description of the question below, and model/code/output at the bottom. Many thanks for reading.
>
>
> I want to look at whether there is a relationship between the way a question is asked (positive, negative, neutral wording) and the sentiment of the response. I have 2638 people asked a question about symptoms. 1/3 of the people were asked it with a negative wording, 1/3 with a neutral one, 1/3 with a positive one. From this, I did sentiment analysis (using Trincker's package) to see whether their responses were more positive or negative, depending on the wording of the question.
> Sentiment analysis breaks down responses into sentences, so I have 2638 people, but 7924 sentences, so I would assume to fit ID as a random effect.
>
> The big question is: does the way the question is asked (primetype) affect the polarity/sentiment of the response?
> My data is negatively skewed, and has a lot of 0s (this is because some people felt 'neutral' and so they scored '0'.
>
> Model using the dataframe DF, to see how primetype (this is the way the question is asked) predicts sentiment (the polarity score, which is negatively skewed with lots of 0s), fixed effect is age, and random effect is ID
>
> ```
> glmmTMB(sentiment ~ primetype + age + (1|id), data=DF)
> ```
>
>
> Output:
>
> ```
> Family: gaussian ( identity )
> Formula: sentiment ~ primetype + age + (1 | id)
> Data: DF
>
> AIC BIC logLik deviance df.resid
> 7254.9 7296.5 -3621.4 7242.9 7556
>
> Random effects:
>
> Conditional model:
> Groups Name Variance Std.Dev.
> id (Intercept) 8.732e-11 9.344e-06
> Residual 1.526e-01 3.906e-01
> Number of obs: 7562, groups: id, 2520
>
> Dispersion estimate for gaussian family (sigma^2): 0.153
>
> Conditional model:
> Estimate Std. Error z value Pr(>|z|)
> (Intercept). -0.1655972 0.0204310 -8.105 5.27e-16 ***
> primetype2 0.0907564 0.0114045 7.958 1.75e-15 ***
> primetype3 0.0977533 0.0115802 8.441 < 2e-16 ***
> age -0.0020644 0.0006483 -3.184 0.00145 **
> ---
> Signif. codes: 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> >
> ```
> How can I interpret whether the model is a good one for my data, is there something else I should be doing? I'm not sure how to interpret the output at all. Would be immensely grateful for any insight
>
>
> Thanks all
>
>
> Gabriella Kountourides
>
> DPhil Student | Department of Anthropology
>
> Evolutionary Medicine and Public Health Group
>
> St. John?s College, University of Oxford
>
> gabriella.kountourides at sjc.ox.ac.uk
>
> Tweet me: https://twitter.com/GKountourides
>
> ________________________________
>
>
>
> [[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From roh|t@ror@yyc @end|ng |rom gm@||@com  Mon Dec  7 21:08:29 2020
From: roh|t@ror@yyc @end|ng |rom gm@||@com (Rohit Arora)
Date: Mon, 7 Dec 2020 13:08:29 -0700
Subject: [R-sig-ME] Generalized Linear Mixed-Effects Model for single RNA
 sequencing data
Message-ID: <CAJipRKqRiTw3kEY5echbsBoG6zmcySv9cab7Bvi+s4k0+v09xA@mail.gmail.com>

I am currently working on a single cell RNA sequencing project with some
time pressure that requires the use of multiple generalized linear effects
models.

My experiment consists of unique patients receiving or not receiving a drug
(let's call it drug B) and has all patients' blood sequenced at 3 days and
some patients' blood sequenced at 7 days.

I am hoping to compare the cell composition of these patients (%neutrophil,
TCell, BCell, Monocyte, Platelet, etc.) between treatment with drug B and
no treatment with drug B at 3 days and 7 days.

I am doing each of the day 3 and 7 comparisons separately (with more than 5
patients in the patient column).

Thus, my data frame looks similar to the one below for day 3 (specifically
Tcells):


freqs:
drug_status proportion_Tcells
patient ncells
Received 0.5 A10 2765
no 0.3 A2 1456
Received 0.6 A11 3102
no 0.4 A3 2013
Received 0.3 A13 4105
Where ncells was the total number of cells recovered from that patient.

The first glm that I wrote was:

glmer(proportion_Tcells ~ drug_status + (1 | patient),
                   weights = ncells,
                   family = binomial,
                   data = freqs)

Although this model seems to work very well for comparing cell proportions
at day 3 and day 7 across treatment groups, I was wondering if I required
another level of nesting like (1 |drug_status:patient).

The main issue I'm running into however is when I try to longitudinally
compare cell proportions in paired samples when nearly all of my cell type
proportions come out as significant.

I am doing the day3 to day 7 comparisons separately for treatment with drug
B and no treatment with drug B(but now with only 3 or 4 patients in the
patient column as not all patients had longitudinal comparators).


Thus, my data frame looks like the one below for treatment with drug B
(specifically Tcells):

freqs:
time proportion_Tcells
patient ncells
day3 0.3 patient1 1456
day7 0.4 patient1 1644
day3 0.4 patient2 2341
day7 0.3 patient2 4312
day3 0.5 patient3 3012
day7 0.7 patient3
1829
I think that this would be a fully crossed design.

I was wondering if there was an issue with running my model like this
again? I am not sure if my sample size is large enough and that is what is
driving my very low p values, or if my model is not appropriately designed.

glmer(proportion_Tcells ~ time + (1 | patient),
                   weights = ncells,
                   family = binomial,
                   data = freqs)

Best,

Rohit

	[[alternative HTML version deleted]]


From @r|v@t@ch@r| @end|ng |rom gm@||@com  Tue Dec  8 13:32:34 2020
From: @r|v@t@ch@r| @end|ng |rom gm@||@com (Srivats Chari)
Date: Tue, 8 Dec 2020 12:32:34 +0000
Subject: [R-sig-ME] MCMCglmm covariance matrix question
In-Reply-To: <8807c877-518f-7735-0257-518f9814e747@gmail.com>
References: <CAFnkSckmh1Z1sNDsCrnHgww7xYwGNZ3-AxFbCDZ-sGEzwCFdCQ@mail.gmail.com>
 <8807c877-518f-7735-0257-518f9814e747@gmail.com>
Message-ID: <CAFnkSc=+4BrOGLNBuTnkzJUyh-XwW3DOsHh3E-Gh6y7yVH89tg@mail.gmail.com>

Greetings Dr. Bolker,

I apologize for the delayed response.

Your idea would work ideally.

Would you know if it was possible to set the value as 0? For example-
https://stat.ethz.ch/pipermail/r-sig-mixed-models/2015q4/024036.html

Here they use antedependance model and fix the value as 0.

Let me know what you think.

Regards,
Sri.



On Wed, Dec 2, 2020 at 4:07 PM Ben Bolker <bbolker at gmail.com> wrote:

>    That seems quite difficult to set up in a single analysis.
>    Would it work to analyze 8 of the traits with one model, and then
> analyze the other trait (which you want to treat independently) with a
> separate, univariate model?
>
> On 12/2/20 10:56 AM, Srivats Chari wrote:
> > Greetings,
> >
> > I'm trying to run a multivariate MCMCglmm with 9 traits. My traits are
> > measured mostly at the same time except for 1 trait which is measured
> only
> > once or twice per individual. After reading a some literature on this I
> > have a basic idea on how to structure my dataset. But the problem I am
> > facing is that I need my covariance matrix to be different. I want my
> > covariance matrix to exclude the 1 trait so that all trait can COvary
> > together except for a particular one! So there won't be any
> > within-individual COvariation between the particular trait and others.
> >
> > creating a sample dataset-
> >
> > df<- data.frame(ani_id = as.factor(1:10),
> >
> sex=c("male","female","male","female","male","female","male","female","male","female"),age=c("young","adult","young","adult","adult","young","young",
> > "adult","adult","adult"),value=runif(200,min=1,
> > max=5),year=ceiling(runif(200,min=2010, max=2019)), PC1=runif(200,
> min=0.1,
> > max=0.9))
> > df$value[5:9]<- NA
> > df$trait_id<- as.factor(paste("T",rep(1:10, each=20), sep="_"))
> >
> > ## My Prior
> > prior1 <- list(R = list(V =diag(10), nu = 0.002),
> >                        G = list(G1 = list(V = diag(10), nu = 0.002,
> >                                           alpha.mu = rep(0, 10),
> >                                           alpha.V  = diag(10)*25^2)))
> > ## MCMC model
> > mcmc_trial1<-MCMCglmm(scale(value) ~ factor(sex)+
> >               scale(year) + scale(year^2)+
> >               scale(PC1)+ scale(PC1^2)+
> >               factor(age),
> >             random =~ us(trait_id):ani_id,
> >             rcov =~ idh(trait_id):units,
> >             family = c("gaussian"),
> >             prior = prior1,
> >             nitt=10000,
> >             burnin=1000,
> >             thin=10,
> >             verbose = TRUE,
> >             pr=TRUE,
> >             data = df)
> >
> > So when I see a covariance matrix I want the trait T1 to not covary with
> > any other trait.
> >
> > T1 T2 T3 T4 T5 T6 T7 T8 T9 T10
> > T1 0,1 0 0 0 0 0 0 0 0 0
> > T2 0 0,1 0,1 0,1 0,1 0,1 0,1 0,1 0,1 0,1
> > T3 0 0,1 0,1 0,1 0,1 0,1 0,1 0,1 0,1 0,1
> > T4 0 0,1 0,1 0,1 0,1 0,1 0,1 0,1 0,1 0,1
> > T5 0 0,1 0,1 0,1 0,1 0,1 0,1 0,1 0,1 0,1
> > T6 0 0,1 0,1 0,1 0,1 0,1 0,1 0,1 0,1 0,1
> > T7 0 0,1 0,1 0,1 0,1 0,1 0,1 0,1 0,1 0,1
> > T8 0 0,1 0,1 0,1 0,1 0,1 0,1 0,1 0,1 0,1
> > T9 0 0,1 0,1 0,1 0,1 0,1 0,1 0,1 0,1 0,1
> > T10 0 0,1 0,1 0,1 0,1 0,1 0,1 0,1 0,1 0,1
> >
> > Where I am stuck is I do not know how to structure the covariance matrix
> to
> > exclude T1.
> >
> > Any suggestions or help is much appreciated. :)
> >
> > Regards,
> > Srivats.
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From |uc@@cor|@tt| @end|ng |rom boku@@c@@t  Tue Dec  8 14:31:21 2020
From: |uc@@cor|@tt| @end|ng |rom boku@@c@@t (Boku mail)
Date: Tue, 8 Dec 2020 14:31:21 +0100
Subject: [R-sig-ME] 
 Interpreting GLMM output and is this the right model?
In-Reply-To: <LNXP265MB05387D448BFA6431EAC91F7AE8CE0@LNXP265MB0538.GBRP265.PROD.OUTLOOK.COM>
 <a984b669-0758-4a39-9d45-5600c9bb6e15@Spark>
 <LNXP265MB0538027D8410E196605A4F83E8CD0@LNXP265MB0538.GBRP265.PROD.OUTLOOK.COM>
References: <LNXP265MB05387D448BFA6431EAC91F7AE8CE0@LNXP265MB0538.GBRP265.PROD.OUTLOOK.COM>
 <a984b669-0758-4a39-9d45-5600c9bb6e15@Spark>
 <LNXP265MB0538027D8410E196605A4F83E8CD0@LNXP265MB0538.GBRP265.PROD.OUTLOOK.COM>
Message-ID: <48b7837b-c4e5-4c98-a71d-1e26aa19afdf@Spark>

Hi Gabriella,
looks like your residuals are not behaving well, so I would not trust your model output.
I have no idea about your data, and there are many people more competent than me in this list, who can give you useful advice. At least you know that your starting point needs to be redefined =) It might be that you actually need to change conditional distribution and pick one that can handle skewed responses in linear mixed models(?).

Try have look here:?https://cran.r-project.org/web/packages/skewlmm/skewlmm.pdf
(You can fit the same model and look again at the residuals)

Alternatively, a similar model could be fitted with the package ?brms?, in a Bayesian framework:

library(brms)
mod.1.brm <- brm(sentiment ~ primetype + age + (1|id), data=DF, family=skew_normal()) # get a coffee, it might take a while...
predict.mod.1.brm <- t(posterior_predict(mod.1.brm)) # extract posterior predictions to feed to DHARMa
library(DHARMa)
sim.resid.mod.1.brm <- createDHARMa(simulatedResponse = predict.mod.1.brm, observedResponse = DF$sentiment)
plot(sim.resid.mod.1.brm) # other stuff should be inspected, but this should allow you to preliminary check if the distributional assumption is ok
library(parameters)
parameters(mod.1.brm, ci=0.95, digits=3, ci_digits=3)

L.
Il 8 dic 2020, 13:47 +0100, Gabriella Kountourides <gabriella.kountourides at sjc.ox.ac.uk>, ha scritto:
> Dear Luca,
>
> Many thanks!
>
> That code worked well, output is attached, I'm not sure how to interpret it, but the KS test p=0 (devation is sig),?the dispersion test p=0.992(devation is not sig) and?but the outlier test p=0 (devation is sig)
>
> Thank you for your well explained answer, it is all much clearer to me, I really appreciate it!
> From: Boku mail <luca.corlatti at boku.ac.at>
> Sent: 07 December 2020 18:07
> To: r-sig-mixed-models <r-sig-mixed-models at r-project.org>; Gabriella Kountourides <gabriella.kountourides at sjc.ox.ac.uk>
> Subject: Re: [R-sig-ME] Interpreting GLMM output and is this the right model?
>
> Dear Gabriella,
> A few thoughts:
>
> 1) generally speaking, it doesn?t make much sense to look at the distribution of the raw response. The choice of the ?family? argument is rather??based on the conditional distribution, i.e., the distribution of the response across the fitted line (or, in other words, the distribution of the response after accounting for the linear predictor). In this respect, I guess it?s hard to say whether the skewness you mention may be a problem or not (same for the zeros).
>
> 2) you fitted a mixed model with Gaussian conditional distribution. Whether this is a ?good model? or not, is hard to say (e.g., does your linear predictor include the *supposedly* important explanatory variables, in the correct form? etc.), but at least I would inspect the residuals? behavior. This would allow you at least to check if the model is not grossly wrong. Suppose your model name is ?mod.1?, then you could do:
>
> library(DHARMa)
> sim.mod.1 <- simulateResiduals(mod.1)
> plot(sim.mod.1)
>
> Or, alternatively:
> library(performance)
> check_model(mod.1) # but DHARMa would be handier if you decided to change conditional distribution, and fit a GLMM
>
> If the model is not grossly wrong, residuals should be distributed in an unsystematic way. If you have weird patterns, then you?re probably off-track. If that happens, you should inspect what?s wrong in your model (conditional distribution? Missing variables? etc.)
>
> 3) once you?re confident your model is ?well behaved?, then you can inspect the results. What your current summary says, basically, is that after accounting for primetype, if you increase age by 1 unit, you?ll have a decrease??of -0.0020644 in sentiment, and this decrease is statistically significant (basically, Estimate/ Std. Error??= z value; the z-score measures how far [in standard errors] your estimate is from zero; z-score follows a standard normal distribution, hence a value of z < -1.96 or z > 1.96 will be statistically significant at an alpha = 0.5). Whether this is also biologically significant, up to you to say!
> The same reasoning applies to the primetype levels, except that this is a categorical variable, so primetype2 will be 0.0907564 ?sentiment scores? higher than the baseline primetype1 (the intercept).
> Should you be interested in comparing different primetype levels in a pairwise manner:
>
> library(emmeans)
> emmeans(mod.1, ~primetype) # haven?t used this in a while, so cross-check in the package :-)
>
> Result interpretation is straightforward in the case of a LMM, which uses an identity link function; should you use a different link, then things would be tricker to interpret, and plotting the marginal effects would be wise:
>
> library(visreg)
> visreg(mod.1, ?primetype", scale=?response")
>
> However, I guess the crucial step for you will be to inspect the behavior of the model in the first place.
>
> Hope this helps!
> Luca
>
>
>
>
> Il 7 dic 2020, 18:10 +0100, Gabriella Kountourides <gabriella.kountourides at sjc.ox.ac.uk>, ha scritto:
> > Hi everyone,
> >
> > I emailed a few weeks ago, but am still struggling with this data.
> > The description of the question below, and model/code/output at the bottom. Many thanks for reading.
> >
> >
> > I want to look at whether there is a relationship between the way a question is asked (positive, negative, neutral wording) and the sentiment of the response. I have 2638 people asked a question about symptoms. 1/3 of the people were asked it with a negative wording, 1/3 with a neutral one, 1/3 with a positive one. From this, I did sentiment analysis (using Trincker's package) to see whether their responses were more positive or negative, depending on the wording of the question.
> > Sentiment analysis breaks down responses into sentences, so I have 2638 people, but 7924 sentences, so I would assume to fit ID as a random effect.
> >
> > The big question is: does the way the question is asked (primetype) affect the polarity/sentiment of the response?
> > My data is negatively skewed, and has a lot of 0s (this is because some people felt 'neutral' and so they scored '0'.
> >
> > Model using the dataframe DF, to see how primetype (this is the way the question is asked) predicts sentiment (the polarity score, which is negatively skewed with lots of 0s), fixed effect is age, and random effect is ID
> >
> > ```
> > glmmTMB(sentiment ~ primetype + age + (1|id), data=DF)
> > ```
> >
> >
> > Output:
> >
> > ```
> > Family: gaussian ( identity )
> > Formula: sentiment ~ primetype + age + (1 | id)
> > Data: DF
> >
> > AIC BIC logLik deviance df.resid
> > 7254.9 7296.5 -3621.4 7242.9 7556
> >
> > Random effects:
> >
> > Conditional model:
> > Groups Name Variance Std.Dev.
> > id (Intercept) 8.732e-11 9.344e-06
> > Residual 1.526e-01 3.906e-01
> > Number of obs: 7562, groups: id, 2520
> >
> > Dispersion estimate for gaussian family (sigma^2): 0.153
> >
> > Conditional model:
> > Estimate Std. Error z value Pr(>|z|)
> > (Intercept). -0.1655972 0.0204310 -8.105 5.27e-16 ***
> > primetype2 0.0907564 0.0114045 7.958 1.75e-15 ***
> > primetype3 0.0977533 0.0115802 8.441 < 2e-16 ***
> > age -0.0020644 0.0006483 -3.184 0.00145 **
> > ---
> > Signif. codes: 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> > >
> > ```
> > How can I interpret whether the model is a good one for my data, is there something else I should be doing? I'm not sure how to interpret the output at all. Would be immensely grateful for any insight
> >
> >
> > Thanks all
> >
> >
> > Gabriella Kountourides
> >
> > DPhil Student | Department of Anthropology
> >
> > Evolutionary Medicine and Public Health Group
> >
> > St. John?s College, University of Oxford
> >
> > gabriella.kountourides at sjc.ox.ac.uk
> >
> > Tweet me: https://twitter.com/GKountourides
> >
> > ________________________________
> >
> >
> >
> > [[alternative HTML version deleted]]
> >
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From g@br|e||@@kountour|de@ @end|ng |rom @jc@ox@@c@uk  Tue Dec  8 13:46:32 2020
From: g@br|e||@@kountour|de@ @end|ng |rom @jc@ox@@c@uk (Gabriella Kountourides)
Date: Tue, 8 Dec 2020 12:46:32 +0000
Subject: [R-sig-ME] 
 Interpreting GLMM output and is this the right model?
In-Reply-To: <a984b669-0758-4a39-9d45-5600c9bb6e15@Spark>
References: <LNXP265MB05387D448BFA6431EAC91F7AE8CE0@LNXP265MB0538.GBRP265.PROD.OUTLOOK.COM>,
 <a984b669-0758-4a39-9d45-5600c9bb6e15@Spark>
Message-ID: <LNXP265MB0538027D8410E196605A4F83E8CD0@LNXP265MB0538.GBRP265.PROD.OUTLOOK.COM>

Dear Luca,

Many thanks!

That code worked well, output is attached, I'm not sure how to interpret it, but the KS test p=0 (devation is sig), the dispersion test p=0.992(devation is not sig) and but the outlier test p=0 (devation is sig)

Thank you for your well explained answer, it is all much clearer to me, I really appreciate it!
________________________________
From: Boku mail <luca.corlatti at boku.ac.at>
Sent: 07 December 2020 18:07
To: r-sig-mixed-models <r-sig-mixed-models at r-project.org>; Gabriella Kountourides <gabriella.kountourides at sjc.ox.ac.uk>
Subject: Re: [R-sig-ME] Interpreting GLMM output and is this the right model?

Dear Gabriella,
A few thoughts:

1) generally speaking, it doesn?t make much sense to look at the distribution of the raw response. The choice of the ?family? argument is rather  based on the conditional distribution, i.e., the distribution of the response across the fitted line (or, in other words, the distribution of the response after accounting for the linear predictor). In this respect, I guess it?s hard to say whether the skewness you mention may be a problem or not (same for the zeros).

2) you fitted a mixed model with Gaussian conditional distribution. Whether this is a ?good model? or not, is hard to say (e.g., does your linear predictor include the *supposedly* important explanatory variables, in the correct form? etc.), but at least I would inspect the residuals? behavior. This would allow you at least to check if the model is not grossly wrong. Suppose your model name is ?mod.1?, then you could do:

library(DHARMa)
sim.mod.1 <- simulateResiduals(mod.1)
plot(sim.mod.1)

Or, alternatively:
library(performance)
check_model(mod.1) # but DHARMa would be handier if you decided to change conditional distribution, and fit a GLMM

If the model is not grossly wrong, residuals should be distributed in an unsystematic way. If you have weird patterns, then you?re probably off-track. If that happens, you should inspect what?s wrong in your model (conditional distribution? Missing variables? etc.)

3) once you?re confident your model is ?well behaved?, then you can inspect the results. What your current summary says, basically, is that after accounting for primetype, if you increase age by 1 unit, you?ll have a decrease  of -0.0020644 in sentiment, and this decrease is statistically significant (basically, Estimate/ Std. Error  = z value; the z-score measures how far [in standard errors] your estimate is from zero; z-score follows a standard normal distribution, hence a value of z < -1.96 or z > 1.96 will be statistically significant at an alpha = 0.5). Whether this is also biologically significant, up to you to say!
The same reasoning applies to the primetype levels, except that this is a categorical variable, so primetype2 will be 0.0907564 ?sentiment scores? higher than the baseline primetype1 (the intercept).
Should you be interested in comparing different primetype levels in a pairwise manner:

library(emmeans)
emmeans(mod.1, ~primetype) # haven?t used this in a while, so cross-check in the package :-)

Result interpretation is straightforward in the case of a LMM, which uses an identity link function; should you use a different link, then things would be tricker to interpret, and plotting the marginal effects would be wise:

library(visreg)
visreg(mod.1, ?primetype", scale=?response")

However, I guess the crucial step for you will be to inspect the behavior of the model in the first place.

Hope this helps!
Luca




Il 7 dic 2020, 18:10 +0100, Gabriella Kountourides <gabriella.kountourides at sjc.ox.ac.uk>, ha scritto:
Hi everyone,

I emailed a few weeks ago, but am still struggling with this data.
The description of the question below, and model/code/output at the bottom. Many thanks for reading.


I want to look at whether there is a relationship between the way a question is asked (positive, negative, neutral wording) and the sentiment of the response. I have 2638 people asked a question about symptoms. 1/3 of the people were asked it with a negative wording, 1/3 with a neutral one, 1/3 with a positive one. From this, I did sentiment analysis (using Trincker's package) to see whether their responses were more positive or negative, depending on the wording of the question.
Sentiment analysis breaks down responses into sentences, so I have 2638 people, but 7924 sentences, so I would assume to fit ID as a random effect.

The big question is: does the way the question is asked (primetype) affect the polarity/sentiment of the response?
My data is negatively skewed, and has a lot of 0s (this is because some people felt 'neutral' and so they scored '0'.

Model using the dataframe DF, to see how primetype (this is the way the question is asked) predicts sentiment (the polarity score, which is negatively skewed with lots of 0s), fixed effect is age, and random effect is ID

```
glmmTMB(sentiment ~ primetype + age + (1|id), data=DF)
```


Output:

```
Family: gaussian ( identity )
Formula: sentiment ~ primetype + age + (1 | id)
Data: DF

AIC BIC logLik deviance df.resid
7254.9 7296.5 -3621.4 7242.9 7556

Random effects:

Conditional model:
Groups Name Variance Std.Dev.
id (Intercept) 8.732e-11 9.344e-06
Residual 1.526e-01 3.906e-01
Number of obs: 7562, groups: id, 2520

Dispersion estimate for gaussian family (sigma^2): 0.153

Conditional model:
Estimate Std. Error z value Pr(>|z|)
(Intercept). -0.1655972 0.0204310 -8.105 5.27e-16 ***
primetype2 0.0907564 0.0114045 7.958 1.75e-15 ***
primetype3 0.0977533 0.0115802 8.441 < 2e-16 ***
age -0.0020644 0.0006483 -3.184 0.00145 **
---
Signif. codes: 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

```
How can I interpret whether the model is a good one for my data, is there something else I should be doing? I'm not sure how to interpret the output at all. Would be immensely grateful for any insight


Thanks all


Gabriella Kountourides

DPhil Student | Department of Anthropology

Evolutionary Medicine and Public Health Group

St. John?s College, University of Oxford

gabriella.kountourides at sjc.ox.ac.uk

Tweet me: https://twitter.com/GKountourides

________________________________



[[alternative HTML version deleted]]


_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-------------- next part --------------
A non-text attachment was scrubbed...
Name: Screenshot 2020-12-08 at 12.38.17.png
Type: image/png
Size: 324167 bytes
Desc: Screenshot 2020-12-08 at 12.38.17.png
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20201208/8240d02c/attachment-0001.png>

From m@r|n@p@@tor @end|ng |rom |cm@c@|c@e@  Tue Dec  8 15:43:34 2020
From: m@r|n@p@@tor @end|ng |rom |cm@c@|c@e@ (Marina Pastor)
Date: Tue, 08 Dec 2020 15:43:34 +0100
Subject: [R-sig-ME] How to generate the equation of a GLMM?
Message-ID: <20201208154334.Horde.GJ9_30shpQ28oa9Fhb4pzJ8@webmail.csic.es>

Dear all,
I have to obtain the equation of a GLMM. I hoped to do it using the  
equatiomatic package, but it does not generate the equations for GLMM.  
Any other package to generate it?
I have two different GLMMs:
- For the first one (glmer.nb(Zooplankton ~ offset(filtered volume) +  
Temp + Sal + (1|stationNumber), data)) I think I managed to generate  
the equation manually (the coefficients are below), but what I should  
add as offset?
The equation: Y = 20.57 + 1.17 Temp -2.12 Sal +ai
ai ~ N(0, 1.32^2)
The coefficients:
Random effects:
  Groups        Name        Variance Std.Dev.
  stationNumber (Intercept) 1.702    1.324
Number of obs: 72, groups:  stationNumber, 72

Fixed effects:
             Estimate Std. Error z value Pr(>|z|)
(Intercept)  20.5694    12.6924   2.182  0.00146 **
Temp          1.1716     0.2222   3.823 2.41e-05 ***
Sal          -2.1222     0.3710  -6.450 4.04e-05 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1


- For the other GLMM (glmer.nb(Zooplankton ~ offset(filtered volume) +  
Light * Depth + (1|stationNumber), data)), how can I generate the  
equation? What to put as offset?
The coefficients are:
Random effects:
  Groups  Name        Variance Std.Dev.
  Station (Intercept) 1.865    1.365
Number of obs: 102, groups:  Station, 51

Fixed effects:
                             Estimate Std. Error  z value Pr(>|z|)
(Intercept)                 -2.31986    0.53036 -32.290  < 2e-7 ***
Light_2N                    -0.24249    0.03018   -2.852 0.000117 ***
FIni_Depth_Net_m25           1.46617    0.35821    0.301 0.193128
Light_2N:FIni_Depth_Net_m25  1.07005    0.66873    1.095 0.001965 **
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1


Many thanks in advance for your time and help,
All the best!
Marina Pastor

-- 
Marina Pastor
PhD Student
Marine biology and oceanography department
Institut de Ci?ncies del Mar (ICM-CSIC)
Spanish National Research Council
Passeig Mar?tim de la Barceloneta 37-49, E-08003 Barcelona, Catalonia, Spain
Phone: +34 932309500 (ext. 1113)
E-mail: marinapastor at icm.csic.es


From bbo|ker @end|ng |rom gm@||@com  Tue Dec  8 23:36:57 2020
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Tue, 8 Dec 2020 17:36:57 -0500
Subject: [R-sig-ME] How to generate the equation of a GLMM?
In-Reply-To: <20201208154334.Horde.GJ9_30shpQ28oa9Fhb4pzJ8@webmail.csic.es>
References: <20201208154334.Horde.GJ9_30shpQ28oa9Fhb4pzJ8@webmail.csic.es>
Message-ID: <d8de173d-85cf-2ec8-f868-c567c92f818c@gmail.com>



On 12/8/20 9:43 AM, Marina Pastor wrote:
> Dear all,
> I have to obtain the equation of a GLMM. I hoped to do it using the 
> equatiomatic package, but it does not generate the equations for GLMM. 
> Any other package to generate it?
> I have two different GLMMs:
> - For the first one (glmer.nb(Zooplankton ~ offset(filtered volume) + 
> Temp + Sal + (1|stationNumber), data)) I think I managed to generate the 
> equation manually (the coefficients are below), but what I should add as 
> offset?
> The equation: Y = 20.57 + 1.17 Temp -2.12 Sal +ai
> ai ~ N(0, 1.32^2)
> The coefficients:
> Random effects:
>  ?Groups??????? Name??????? Variance Std.Dev.
>  ?stationNumber (Intercept) 1.702??? 1.324
> Number of obs: 72, groups:? stationNumber, 72
> 
> Fixed effects:
>  ??????????? Estimate Std. Error z value Pr(>|z|)
> (Intercept)? 20.5694??? 12.6924?? 2.182? 0.00146 **
> Temp????????? 1.1716???? 0.2222?? 3.823 2.41e-05 ***
> Sal????????? -2.1222???? 0.3710? -6.450 4.04e-05 ***
> ---
> Signif. codes:? 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

   (1) You could always run the same model with lmer() and run the 
results through equatiomatic: that would tell you the equation of the 
*linear predictor*. You could combine that with the results of running 
equatiomatic on the model _without_ the random effect in MASS::glm.nb 
and running that through equatiomatic as well.

   (2) the offset is simply added to the RHS of the equation
   (3) You almost certainly want to be using log(filtered volume) rather 
than filtered volume itself as your offset.

   Suggestion 1 should work for your other equation as well ...
> 
> 
> - For the other GLMM (glmer.nb(Zooplankton ~ offset(filtered volume) + 
> Light * Depth + (1|stationNumber), data)), how can I generate the 
> equation? What to put as offset?
> The coefficients are:
> Random effects:
>  ?Groups? Name??????? Variance Std.Dev.
>  ?Station (Intercept) 1.865??? 1.365
> Number of obs: 102, groups:? Station, 51
> 
> Fixed effects:
>  ??????????????????????????? Estimate Std. Error? z value Pr(>|z|)
> (Intercept)???????????????? -2.31986??? 0.53036 -32.290? < 2e-7 ***
> Light_2N??????????????????? -0.24249??? 0.03018?? -2.852 0.000117 ***
> FIni_Depth_Net_m25?????????? 1.46617??? 0.35821??? 0.301 0.193128
> Light_2N:FIni_Depth_Net_m25? 1.07005??? 0.66873??? 1.095 0.001965 **
> ---
> Signif. codes:? 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> 
> 
> Many thanks in advance for your time and help,
> All the best!
> Marina Pastor
>


From ebhod@ghe|@|th @end|ng |rom gm@||@com  Wed Dec  9 07:06:54 2020
From: ebhod@ghe|@|th @end|ng |rom gm@||@com (Ebhodaghe Faith)
Date: Wed, 9 Dec 2020 09:06:54 +0300
Subject: [R-sig-ME] Choice of fixed effects and random effects in glmm
Message-ID: <CAEatWUrF_j8FOwxK33QY4SeZQG8_aha3RP35tfyE7qO7a_9RQg@mail.gmail.com>

Hi All.

I'm running a Generalised Linear Mixed Model for a study in which I
repeatedly collected data within each of 14 different locations. My
predictor variable is 'location' and at same time wish to account for
repeated measures within locations. Is it okay in this case to select
'location' as both fixed effects and random effects?

Thanks in advance for kind response.

Cheers
Faith

	[[alternative HTML version deleted]]


From me @end|ng |rom ph||||p@|d@y@com  Wed Dec  9 11:24:18 2020
From: me @end|ng |rom ph||||p@|d@y@com (Phillip Alday)
Date: Wed, 9 Dec 2020 11:24:18 +0100
Subject: [R-sig-ME] Choice of fixed effects and random effects in glmm
In-Reply-To: <CAEatWUrF_j8FOwxK33QY4SeZQG8_aha3RP35tfyE7qO7a_9RQg@mail.gmail.com>
References: <CAEatWUrF_j8FOwxK33QY4SeZQG8_aha3RP35tfyE7qO7a_9RQg@mail.gmail.com>
Message-ID: <7927033b-23c4-493b-d82f-755688103798@phillipalday.com>

Hi? Faith,

if you have a model like

y ~ 1 + x * location

(i.e. fixed-effects only), then this still accounts for
repeated-measurements within the location. The motivation for doing a
mixed model like

y ~ 1 + x + (1+x|location)

is that this reduces the complexity of the fixed effects, especially
when you don't want to interpret the effects of the individual levels of
location. This reduction in complexity means that you have fewer things
in your fixed-effects table, which is nice, but it also means that there
are fewer parameters in the model (because you model the variance across
locations instead of the mean at each location) and so it becomes easier
to fit such models when you have lots of locations. (There are also some
other more subtle differences in terms of partial pooling, but we can
leave those aside for now).

But if you want to interpret the effect of location or particular
locations, e.g. "the effect of x at location A", then that extra
complexity in the fixed-effects table isn't really a problem. In that
case, I would recommend just treating location as? a fixed effect.

My commentary thus far is simplifying a lot of detail -- there are
exceptions to almost all of the rules I'm stating. I don't know enough
about your data, research question and inference goals to be able to
tell if you are one of the exceptions.

Thierry Onkelinx has a nice blog post on when it's okay to have
something as both a fixed and a random effect:

https://www.muscardinus.be/2017/08/fixed-and-random/

The short answer is "only when you have discrete data, not for
categorical nor continuous data", where discrete data are things like
"time samples" which have a numerical structure but are not truly
continuous. Distinct locations are usually simply categorical because
they don't have a numerical structure (though I guess locations
expressed as e.g. latitude or longitude might).

Best,

Phillip

On 09/12/2020 07:06, Ebhodaghe Faith wrote:
> Hi All.
>
> I'm running a Generalised Linear Mixed Model for a study in which I
> repeatedly collected data within each of 14 different locations. My
> predictor variable is 'location' and at same time wish to account for
> repeated measures within locations. Is it okay in this case to select
> 'location' as both fixed effects and random effects?
>
> Thanks in advance for kind response.
>
> Cheers
> Faith
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From ho|tm@nn @end|ng |rom b|o|og|e@un|-muenchen@de  Wed Dec  9 09:28:24 2020
From: ho|tm@nn @end|ng |rom b|o|og|e@un|-muenchen@de (Benedikt Holtmann)
Date: Wed, 9 Dec 2020 09:28:24 +0100
Subject: [R-sig-ME] Trait specific random effects and covariance between
 them in MCMCglmm
Message-ID: <CAMbz680Lw0fE2zxkKY_E3rL_-MUnVFXR+rdTHd46UECsMj2=7A@mail.gmail.com>

Dear list members,

I'm trying to estimate the covariance and correlation of observer-effects
between male and female exploration scores in a bivariate model.
My problem is that observers can differ between males and females (not
always measured together). I use str() to allow covariances to exist
between ObserverFemale and ObserverMale.

My model looks as follows:
prior_multi_2 <- list(R = list(V = diag(2), nu = 0.002), G = list(
  G1 = list(V = diag(2), nu = 2, alpha.mu = rep(0, 2), alpha.V = diag(2) *
1000),
  G2 = list(V = diag(2), nu = 2, alpha.mu = rep(0, 2), alpha.V = diag(2) *
1000),
  G3 = list(V = diag(2), nu = 2, alpha.mu = rep(0, 2), alpha.V = diag(2) *
1000),
  G4 = list(V = diag(2), nu = 2, alpha.mu = rep(0, 2), alpha.V = diag(2) *
1000),
  G5 = list(V = diag(4), nu = 4, alpha.mu = rep(0, 4), alpha.V = diag(4) *
1000)
))

Biv_MCMC <- MCMCglmm(cbind(scale(ExpScoreFemale), scale(ExpScoreMale)) ~
(trait - 1) +
  at.level(trait, 1):scale(AgeFemale) +
  at.level(trait, 2):scale(AgeMale) +
random = ~ us(trait):PairID + us(trait):Plot + us(trait):Year +
us(trait):NestBox + us(trait):str(ObserverFemale + ObserverMale),
rcov = ~ us(trait):units,
prior = prior_multi_2, data = exploration_data, nitt = 13000 * 10, burnin =
3000 * 10, thin = 10 * 10,
pr = TRUE, saveX = TRUE, saveZ = TRUE,
family = c("gaussian", "gaussian")
)

However, since ObserverFemale and ObserverMale are trait-specific, I was
wondering whether there is a way to model trait-specific observer random
effects such as: us(trait):str(at.level(trait,1):ObserverFemale +
at.level(trait,2):ObserverMale)?

I saw that this is possible in ASReml. For example, Class& Brommer 2018,
BiologyLetters 14:20180106 used:
random = ~ str(~at(trait,1):ObserverFemale + at(trait,2):ObserverMale~
us(2):id(12))

Is it possible to fit something similar in MCMCglmm?

Best regards,
Benedikt

-------------------------------------------------------
*Dr Benedikt Holtmann*
DFG Research Fellow
Behavioural Ecology, Department of Biology II
Ludwig-Maximilians-University of Munich
Gro?haderner Stra?e 2
82152 Planegg-Martinsried
Germany

	[[alternative HTML version deleted]]


From D@v|d@Du||y @end|ng |rom q|mrbergho|er@edu@@u  Wed Dec  9 23:17:20 2020
From: D@v|d@Du||y @end|ng |rom q|mrbergho|er@edu@@u (David Duffy)
Date: Wed, 9 Dec 2020 22:17:20 +0000
Subject: [R-sig-ME] Trait specific random effects and covariance between
 them in MCMCglmm
In-Reply-To: <CAMbz680Lw0fE2zxkKY_E3rL_-MUnVFXR+rdTHd46UECsMj2=7A@mail.gmail.com>
References: <CAMbz680Lw0fE2zxkKY_E3rL_-MUnVFXR+rdTHd46UECsMj2=7A@mail.gmail.com>
Message-ID: <7081f38fd8bd4e8ebaf75d6eda640431@qimrberghofer.edu.au>


________________________________________
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of Benedikt Holtmann <holtmann at biologie.uni-muenchen.de>
Sent: Wednesday, 9 December 2020 6:28:24 PM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] Trait specific random effects and covariance between them in MCMCglmm

Dear list members,

I'm trying to estimate the covariance and correlation of observer-effects
between male and female exploration scores in a bivariate model.
My problem is that observers can differ between males and females (not
always measured together). I use str() to allow covariances to exist
between ObserverFemale and ObserverMale.

My model looks as follows:
prior_multi_2 <- list(R = list(V = diag(2), nu = 0.002), G = list(
  G1 = list(V = diag(2), nu = 2, alpha.mu = rep(0, 2), alpha.V = diag(2) *
1000),
  G2 = list(V = diag(2), nu = 2, alpha.mu = rep(0, 2), alpha.V = diag(2) *
1000),
  G3 = list(V = diag(2), nu = 2, alpha.mu = rep(0, 2), alpha.V = diag(2) *
1000),
  G4 = list(V = diag(2), nu = 2, alpha.mu = rep(0, 2), alpha.V = diag(2) *
1000),
  G5 = list(V = diag(4), nu = 4, alpha.mu = rep(0, 4), alpha.V = diag(4) *
1000)
))

Biv_MCMC <- MCMCglmm(cbind(scale(ExpScoreFemale), scale(ExpScoreMale)) ~
(trait - 1) +
  at.level(trait, 1):scale(AgeFemale) +
  at.level(trait, 2):scale(AgeMale) +
random = ~ us(trait):PairID + us(trait):Plot + us(trait):Year +
us(trait):NestBox + us(trait):str(ObserverFemale + ObserverMale),
rcov = ~ us(trait):units,
prior = prior_multi_2, data = exploration_data, nitt = 13000 * 10, burnin =
3000 * 10, thin = 10 * 10,
pr = TRUE, saveX = TRUE, saveZ = TRUE,
family = c("gaussian", "gaussian")
)

However, since ObserverFemale and ObserverMale are trait-specific, I was
wondering whether there is a way to model trait-specific observer random
effects such as: us(trait):str(at.level(trait,1):ObserverFemale +
at.level(trait,2):ObserverMale)?

I saw that this is possible in ASReml. For example, Class& Brommer 2018,
BiologyLetters 14:20180106 used:
random = ~ str(~at(trait,1):ObserverFemale + at(trait,2):ObserverMale~
us(2):id(12))

Is it possible to fit something similar in MCMCglmm?

Best regards,
Benedikt

-------------------------------------------------------
*Dr Benedikt Holtmann*
DFG Research Fellow
Behavioural Ecology, Department of Biology II
Ludwig-Maximilians-University of Munich
Gro?haderner Stra?e 2
82152 Planegg-Martinsried
Germany

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
[EXTERNAL EMAIL] This message originates from an external email address, please exercise caution when clicking any links or opening attachments. If you believe the sender is impersonating someone at QIMR Berghofer, please forward this message to phishing at qimrberghofer.edu.au.


From m@r|n@p@@tor @end|ng |rom |cm@c@|c@e@  Thu Dec 10 13:13:53 2020
From: m@r|n@p@@tor @end|ng |rom |cm@c@|c@e@ (Marina Pastor)
Date: Thu, 10 Dec 2020 13:13:53 +0100
Subject: [R-sig-ME] How to generate the equation of a GLMM?
In-Reply-To: <d8de173d-85cf-2ec8-f868-c567c92f818c@gmail.com>
References: <20201208154334.Horde.GJ9_30shpQ28oa9Fhb4pzJ8@webmail.csic.es>
 <d8de173d-85cf-2ec8-f868-c567c92f818c@gmail.com>
Message-ID: <20201210131353.Horde.UBksWkSoqcQAk9MATH4K73Y@webmail.csic.es>

Thank you for the answer!
Apparently, the package ?equatiomatic? does not accept mixed models. I  
did it with a glm, and applied the same structure for the glmer.bn  
with the coefficients of glmer.nb.
Then the result of the second example is:
Ephyra = -2.32 - 0.24(LightNight) + 1.47(Depth25m) + 1.07(LightNight x  
Depth25m) + offset(LogFilteredVolume) + ai
ai  ~ N(0, 1.372)
Could you tell me if is any information lacking to write the equation?
Yes, I am using the Log of the filtered volume as offset, thank you  
for your suggestion.
Cheers and thanks again,
Marina

Ben Bolker <bbolker at gmail.com> escribi?:

> On 12/8/20 9:43 AM, Marina Pastor wrote:
>> Dear all,
>> I have to obtain the equation of a GLMM. I hoped to do it using the  
>> equatiomatic package, but it does not generate the equations for  
>> GLMM. Any other package to generate it?
>> I have two different GLMMs:
>> - For the first one (glmer.nb(Zooplankton ~ offset(filtered volume)  
>> + Temp + Sal + (1|stationNumber), data)) I think I managed to  
>> generate the equation manually (the coefficients are below), but  
>> what I should add as offset?
>> The equation: Y = 20.57 + 1.17 Temp -2.12 Sal +ai
>> ai ~ N(0, 1.32^2)
>> The coefficients:
>> Random effects:
>> ?Groups??????? Name??????? Variance Std.Dev.
>> ?stationNumber (Intercept) 1.702??? 1.324
>> Number of obs: 72, groups:? stationNumber, 72
>>
>> Fixed effects:
>> ??????????? Estimate Std. Error z value Pr(>|z|)
>> (Intercept)? 20.5694??? 12.6924?? 2.182? 0.00146 **
>> Temp????????? 1.1716???? 0.2222?? 3.823 2.41e-05 ***
>> Sal????????? -2.1222???? 0.3710? -6.450 4.04e-05 ***
>> ---
>> Signif. codes:? 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
>   (1) You could always run the same model with lmer() and run the  
> results through equatiomatic: that would tell you the equation of  
> the *linear predictor*. You could combine that with the results of  
> running equatiomatic on the model _without_ the random effect in  
> MASS::glm.nb and running that through equatiomatic as well.
>
>   (2) the offset is simply added to the RHS of the equation
>   (3) You almost certainly want to be using log(filtered volume)  
> rather than filtered volume itself as your offset.
>
>   Suggestion 1 should work for your other equation as well ...
>>
>>
>> - For the other GLMM (glmer.nb(Zooplankton ~ offset(filtered  
>> volume) + Light * Depth + (1|stationNumber), data)), how can I  
>> generate the equation? What to put as offset?
>> The coefficients are:
>> Random effects:
>> ?Groups? Name??????? Variance Std.Dev.
>> ?Station (Intercept) 1.865??? 1.365
>> Number of obs: 102, groups:? Station, 51
>>
>> Fixed effects:
>> ??????????????????????????? Estimate Std. Error? z value Pr(>|z|)
>> (Intercept)???????????????? -2.31986??? 0.53036 -32.290? < 2e-7 ***
>> Light_2N??????????????????? -0.24249??? 0.03018?? -2.852 0.000117 ***
>> FIni_Depth_Net_m25?????????? 1.46617??? 0.35821??? 0.301 0.193128
>> Light_2N:FIni_Depth_Net_m25? 1.07005??? 0.66873??? 1.095 0.001965 **
>> ---
>> Signif. codes:? 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>
>>
>> Many thanks in advance for your time and help,
>> All the best!
>> Marina Pastor
>>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
Marina Pastor
PhD Student
Marine biology and oceanography department
Institut de Ci?ncies del Mar (ICM-CSIC)
Spanish National Research Council
Passeig Mar?tim de la Barceloneta 37-49, E-08003 Barcelona, Catalonia, Spain
Phone: +34 932309500 (ext. 1113)
E-mail: marinapastor at icm.csic.es


From j@d@mo@w@d @end|ng |rom un||@ch  Thu Dec 10 13:11:52 2020
From: j@d@mo@w@d @end|ng |rom un||@ch (Jad Moawad)
Date: Thu, 10 Dec 2020 12:11:52 +0000
Subject: [R-sig-ME] Question regarding large data.frame in LMER?
Message-ID: <bbb6420ece704ba795b95f7a446c5b53@unil.ch>

I am working with a large data.frame that contains around 1.4 million observations. Initially when i was running my models, i was working on a sub-sample (10% of my full-sample). This is because running one model can take a lot of time using the original data. Once i was sure that all variables are well harmonized and all regressions were running fine, i ran my models using the full sample. However, the regression did not converge and i received the following two errors from two different models:

Error in fun(xaa, ...) : Downdated VtV is not positive definite

Error in fun(xss, ...) : Downdated VtV is not positive definite

I use the lmer function to fit my model and i include a random slopes at the country and country_year level. Below you find the code that i use.

Model1 <- lmer(health~ class + age + I(age^2)  + class*macro_unemployment +
               (class + age + I(age^2)|country) +
               (class+ age + I(age^2) |country_year) +
               (1|id), data=df)

Model2 <- lmer(health~ education + age + I(age^2)  + education*macro_unemployment+
               (education + age + I(age^2)|country) +
               (education + age + I(age^2) |country_year) +
               (1|id), data=df)


Could someone help me please with solving this issue?

Below you find a glimpse (str) of my data and my sessionInfo():

tibble [1,370,264 ? 8] (S3: grouped_df/tbl_df/tbl/data.frame)
 $ health            : num [1:1370264] 100 100 50 100 0 75 75 100 100 50 ...
 $ class             : Factor w/ 3 levels "Upper-middle class",..: 3 3 NA 3 3 3 3 1 1 3 ...
 $ education         : Factor w/ 3 levels "low","mid","high": 1 1 1 1 1 1 2 3 3 1 ...
 $ age               : num [1:1370264] 24 25 24 25 42 43 34 34 35 58 ...
 $ macro_unemployment: num [1:1370264] 5.24 4.86 5.24 4.86 5.24 ...
 $ id                : int [1:1370264] 2 2 3 3 4 4 6 7 7 8 ...
 $ country_year      : int [1:1370264] 1 2 1 2 1 2 1 1 2 1 ...
 $ country           : Factor w/ 30 levels "Austria","Belgium",..: 1 1 1 1 1 1 1 1 1 1 ...
 - attr(*, "groups")= tibble [27 ? 2] (S3: tbl_df/tbl/data.frame)
  ..$ country: Factor w/ 30 levels "Austria","Belgium",..: 1 2 3 6 7 8 9 10 11 12 ...
  ..$ .rows  : list<int> [1:27]
  .. ..$ : int [1:47204] 1 2 3 4 5 6 7 8 9 10 ...
  .. ..$ : int [1:41361] 47205 47206 47207 47208 47209 47210 47211 47212 47213 47214 ...
  .. ..$ : int [1:42407] 88566 88567 88568 88569 88570 88571 88572 88573 88574 88575 ...
  .. ..$ : int [1:48253] 130973 130974 130975 130976 130977 130978 130979 130980 130981 130982 ...
  .. ..$ : int [1:31917] 179226 179227 179228 179229 179230 179231 179232 179233 179234 179235 ...
  .. ..$ : int [1:44047] 211143 211144 211145 211146 211147 211148 211149 211150 211151 211152 ...
  .. ..$ : int [1:62087] 255190 255191 255192 255193 255194 255195 255196 255197 255198 255199 ...
  .. ..$ : int [1:94309] 317277 317278 317279 317280 317281 317282 317283 317284 317285 317286 ...
  .. ..$ : int [1:37246] 411586 411587 411588 411589 411590 411591 411592 411593 411594 411595 ...
  .. ..$ : int [1:77253] 448832 448833 448834 448835 448836 448837 448838 448839 448840 448841 ...
  .. ..$ : int [1:16823] 526085 526086 526087 526088 526089 526090 526091 526092 526093 526094 ...
  .. ..$ : int [1:24687] 542908 542909 542910 542911 542912 542913 542914 542915 542916 542917 ...
  .. ..$ : int [1:116263] 567595 567596 567597 567598 567599 567600 567601 567602 567603 567604 ...
  .. ..$ : int [1:43218] 683858 683859 683860 683861 683862 683863 683864 683865 683866 683867 ...
  .. ..$ : int [1:28709] 727076 727077 727078 727079 727080 727081 727082 727083 727084 727085 ...
  .. ..$ : int [1:27583] 755785 755786 755787 755788 755789 755790 755791 755792 755793 755794 ...
  .. ..$ : int [1:77960] 783368 783369 783370 783371 783372 783373 783374 783375 783376 783377 ...
  .. ..$ : int [1:36922] 861328 861329 861330 861331 861332 861333 861334 861335 861336 861337 ...
  .. ..$ : int [1:93194] 898250 898251 898252 898253 898254 898255 898256 898257 898258 898259 ...
  .. ..$ : int [1:9004] 991444 991445 991446 991447 991448 991449 991450 991451 991452 991453 ...
  .. ..$ : int [1:40074] 1000448 1000449 1000450 1000451 1000452 1000453 1000454 1000455 1000456 1000457 ...
  .. ..$ : int [1:29342] 1040522 1040523 1040524 1040525 1040526 1040527 1040528 1040529 1040530 1040531 ...
  .. ..$ : int [1:85124] 1069864 1069865 1069866 1069867 1069868 1069869 1069870 1069871 1069872 1069873 ...
  .. ..$ : int [1:92350] 1154988 1154989 1154990 1154991 1154992 1154993 1154994 1154995 1154996 1154997 ...
  .. ..$ : int [1:50188] 1247338 1247339 1247340 1247341 1247342 1247343 1247344 1247345 1247346 1247347 ...
  .. ..$ : int [1:7598] 1297526 1297527 1297528 1297529 1297530 1297531 1297532 1297533 1297534 1297535 ...
  .. ..$ : int [1:65141] 1305124 1305125 1305126 1305127 1305128 1305129 1305130 1305131 1305132 1305133 ...
  .. ..@ ptype: int(0)
  ..- attr(*, ".drop")= logi TRUE
>


Session Info:

R version 4.0.2 (2020-06-22)
Platform: x86_64-apple-darwin17.0 (64-bit)
Running under: macOS Catalina 10.15.6

Matrix products: default
BLAS:   /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libBLAS.dylib
LAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices
[4] utils     datasets  methods
[7] base

other attached packages:
 [1] sessioninfo_1.1.1
 [2] sjlabelled_1.1.5
 [3] varhandle_2.0.5
 [4] labelled_2.7.0
 [5] dplyr_1.0.0
 [6] ggplot2_3.3.2
 [7] forcats_0.5.0
 [8] reprex_0.3.0
 [9] lmerTest_3.1-3
[10] lme4_1.1-25
[11] Matrix_1.2-18

loaded via a namespace (and not attached):
 [1] Rcpp_1.0.4.6
 [2] compiler_4.0.2
 [3] pillar_1.4.4
 [4] nloptr_1.2.2.1
 [5] tools_4.0.2
 [6] digest_0.6.25
 [7] boot_1.3-25
 [8] statmod_1.4.34
 [9] lifecycle_0.2.0
[10] tibble_3.0.1
[11] nlme_3.1-148
[12] gtable_0.3.0
[13] lattice_0.20-41
[14] pkgconfig_2.0.3
[15] rlang_0.4.7
[16] cli_2.0.2
[17] rstudioapi_0.11
[18] haven_2.3.1
[19] withr_2.2.0
[20] hms_0.5.3
[21] generics_0.0.2
[22] vctrs_0.3.1
[23] fs_1.4.1
[24] grid_4.0.2
[25] tidyselect_1.1.0
[26] glue_1.4.1
[27] R6_2.4.1
[28] fansi_0.4.1
[29] minqa_1.2.4
[30] farver_2.0.3
[31] purrr_0.3.4
[32] magrittr_1.5
[33] scales_1.1.1
[34] ellipsis_0.3.1
[35] MASS_7.3-51.6
[36] splines_4.0.2
[37] insight_0.11.0
[38] assertthat_0.2.1
[39] colorspace_1.4-1
[40] numDeriv_2016.8-1.1
[41] labeling_0.3
[42] utf8_1.1.4
[43] munsell_0.5.0
[44] crayon_1.3.4




Sincerely,



Jad Moawad


PhD candidate and teaching assistant
University of Lausanne  - NCCR Lives
Institut des Sciences Sociales
B?timent Geopolis - 5621
1015 Lausanne
Switzerland


	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Thu Dec 10 17:11:09 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Thu, 10 Dec 2020 08:11:09 -0800
Subject: [R-sig-ME] Question regarding large data.frame in LMER?
In-Reply-To: <bbb6420ece704ba795b95f7a446c5b53@unil.ch>
References: <bbb6420ece704ba795b95f7a446c5b53@unil.ch>
Message-ID: <4E860600-7F5B-47DB-9B8F-6CC9B3E6C0FA@dcn.davis.ca.us>

I may be completely off base, but two things that could affect this:

1) You have a lot of integers in your data. With a lot of "rounded" data you could start to see duplicate data records as you increase the size. This could particularly be associated with specific countries that were not in your test sample.

2) You might consider using as.data.frame on your data because tibbles don't respond to column slicing quite the same as data.frame (specifically around the drop parameter). I don't know if lmer is compatible with tibbles.

On December 10, 2020 4:11:52 AM PST, Jad Moawad <jad.moawad at unil.ch> wrote:
>I am working with a large data.frame that contains around 1.4 million
>observations. Initially when i was running my models, i was working on
>a sub-sample (10% of my full-sample). This is because running one model
>can take a lot of time using the original data. Once i was sure that
>all variables are well harmonized and all regressions were running
>fine, i ran my models using the full sample. However, the regression
>did not converge and i received the following two errors from two
>different models:
>
>Error in fun(xaa, ...) : Downdated VtV is not positive definite
>
>Error in fun(xss, ...) : Downdated VtV is not positive definite
>
>I use the lmer function to fit my model and i include a random slopes
>at the country and country_year level. Below you find the code that i
>use.
>
>Model1 <- lmer(health~ class + age + I(age^2)  +
>class*macro_unemployment +
>               (class + age + I(age^2)|country) +
>               (class+ age + I(age^2) |country_year) +
>               (1|id), data=df)
>
>Model2 <- lmer(health~ education + age + I(age^2)  +
>education*macro_unemployment+
>               (education + age + I(age^2)|country) +
>               (education + age + I(age^2) |country_year) +
>               (1|id), data=df)
>
>
>Could someone help me please with solving this issue?
>
>Below you find a glimpse (str) of my data and my sessionInfo():
>
>tibble [1,370,264 ? 8] (S3: grouped_df/tbl_df/tbl/data.frame)
>$ health            : num [1:1370264] 100 100 50 100 0 75 75 100 100 50
>...
>$ class             : Factor w/ 3 levels "Upper-middle class",..: 3 3
>NA 3 3 3 3 1 1 3 ...
>$ education         : Factor w/ 3 levels "low","mid","high": 1 1 1 1 1
>1 2 3 3 1 ...
>$ age               : num [1:1370264] 24 25 24 25 42 43 34 34 35 58 ...
> $ macro_unemployment: num [1:1370264] 5.24 4.86 5.24 4.86 5.24 ...
> $ id                : int [1:1370264] 2 2 3 3 4 4 6 7 7 8 ...
> $ country_year      : int [1:1370264] 1 2 1 2 1 2 1 1 2 1 ...
>$ country           : Factor w/ 30 levels "Austria","Belgium",..: 1 1 1
>1 1 1 1 1 1 1 ...
> - attr(*, "groups")= tibble [27 ? 2] (S3: tbl_df/tbl/data.frame)
>..$ country: Factor w/ 30 levels "Austria","Belgium",..: 1 2 3 6 7 8 9
>10 11 12 ...
>  ..$ .rows  : list<int> [1:27]
>  .. ..$ : int [1:47204] 1 2 3 4 5 6 7 8 9 10 ...
>.. ..$ : int [1:41361] 47205 47206 47207 47208 47209 47210 47211 47212
>47213 47214 ...
>.. ..$ : int [1:42407] 88566 88567 88568 88569 88570 88571 88572 88573
>88574 88575 ...
>.. ..$ : int [1:48253] 130973 130974 130975 130976 130977 130978 130979
>130980 130981 130982 ...
>.. ..$ : int [1:31917] 179226 179227 179228 179229 179230 179231 179232
>179233 179234 179235 ...
>.. ..$ : int [1:44047] 211143 211144 211145 211146 211147 211148 211149
>211150 211151 211152 ...
>.. ..$ : int [1:62087] 255190 255191 255192 255193 255194 255195 255196
>255197 255198 255199 ...
>.. ..$ : int [1:94309] 317277 317278 317279 317280 317281 317282 317283
>317284 317285 317286 ...
>.. ..$ : int [1:37246] 411586 411587 411588 411589 411590 411591 411592
>411593 411594 411595 ...
>.. ..$ : int [1:77253] 448832 448833 448834 448835 448836 448837 448838
>448839 448840 448841 ...
>.. ..$ : int [1:16823] 526085 526086 526087 526088 526089 526090 526091
>526092 526093 526094 ...
>.. ..$ : int [1:24687] 542908 542909 542910 542911 542912 542913 542914
>542915 542916 542917 ...
>.. ..$ : int [1:116263] 567595 567596 567597 567598 567599 567600
>567601 567602 567603 567604 ...
>.. ..$ : int [1:43218] 683858 683859 683860 683861 683862 683863 683864
>683865 683866 683867 ...
>.. ..$ : int [1:28709] 727076 727077 727078 727079 727080 727081 727082
>727083 727084 727085 ...
>.. ..$ : int [1:27583] 755785 755786 755787 755788 755789 755790 755791
>755792 755793 755794 ...
>.. ..$ : int [1:77960] 783368 783369 783370 783371 783372 783373 783374
>783375 783376 783377 ...
>.. ..$ : int [1:36922] 861328 861329 861330 861331 861332 861333 861334
>861335 861336 861337 ...
>.. ..$ : int [1:93194] 898250 898251 898252 898253 898254 898255 898256
>898257 898258 898259 ...
>.. ..$ : int [1:9004] 991444 991445 991446 991447 991448 991449 991450
>991451 991452 991453 ...
>.. ..$ : int [1:40074] 1000448 1000449 1000450 1000451 1000452 1000453
>1000454 1000455 1000456 1000457 ...
>.. ..$ : int [1:29342] 1040522 1040523 1040524 1040525 1040526 1040527
>1040528 1040529 1040530 1040531 ...
>.. ..$ : int [1:85124] 1069864 1069865 1069866 1069867 1069868 1069869
>1069870 1069871 1069872 1069873 ...
>.. ..$ : int [1:92350] 1154988 1154989 1154990 1154991 1154992 1154993
>1154994 1154995 1154996 1154997 ...
>.. ..$ : int [1:50188] 1247338 1247339 1247340 1247341 1247342 1247343
>1247344 1247345 1247346 1247347 ...
>.. ..$ : int [1:7598] 1297526 1297527 1297528 1297529 1297530 1297531
>1297532 1297533 1297534 1297535 ...
>.. ..$ : int [1:65141] 1305124 1305125 1305126 1305127 1305128 1305129
>1305130 1305131 1305132 1305133 ...
>  .. ..@ ptype: int(0)
>  ..- attr(*, ".drop")= logi TRUE
>>
>
>
>Session Info:
>
>R version 4.0.2 (2020-06-22)
>Platform: x86_64-apple-darwin17.0 (64-bit)
>Running under: macOS Catalina 10.15.6
>
>Matrix products: default
>BLAS:  
>/System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libBLAS.dylib
>LAPACK:
>/Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib
>
>locale:
>[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>
>attached base packages:
>[1] stats     graphics  grDevices
>[4] utils     datasets  methods
>[7] base
>
>other attached packages:
> [1] sessioninfo_1.1.1
> [2] sjlabelled_1.1.5
> [3] varhandle_2.0.5
> [4] labelled_2.7.0
> [5] dplyr_1.0.0
> [6] ggplot2_3.3.2
> [7] forcats_0.5.0
> [8] reprex_0.3.0
> [9] lmerTest_3.1-3
>[10] lme4_1.1-25
>[11] Matrix_1.2-18
>
>loaded via a namespace (and not attached):
> [1] Rcpp_1.0.4.6
> [2] compiler_4.0.2
> [3] pillar_1.4.4
> [4] nloptr_1.2.2.1
> [5] tools_4.0.2
> [6] digest_0.6.25
> [7] boot_1.3-25
> [8] statmod_1.4.34
> [9] lifecycle_0.2.0
>[10] tibble_3.0.1
>[11] nlme_3.1-148
>[12] gtable_0.3.0
>[13] lattice_0.20-41
>[14] pkgconfig_2.0.3
>[15] rlang_0.4.7
>[16] cli_2.0.2
>[17] rstudioapi_0.11
>[18] haven_2.3.1
>[19] withr_2.2.0
>[20] hms_0.5.3
>[21] generics_0.0.2
>[22] vctrs_0.3.1
>[23] fs_1.4.1
>[24] grid_4.0.2
>[25] tidyselect_1.1.0
>[26] glue_1.4.1
>[27] R6_2.4.1
>[28] fansi_0.4.1
>[29] minqa_1.2.4
>[30] farver_2.0.3
>[31] purrr_0.3.4
>[32] magrittr_1.5
>[33] scales_1.1.1
>[34] ellipsis_0.3.1
>[35] MASS_7.3-51.6
>[36] splines_4.0.2
>[37] insight_0.11.0
>[38] assertthat_0.2.1
>[39] colorspace_1.4-1
>[40] numDeriv_2016.8-1.1
>[41] labeling_0.3
>[42] utf8_1.1.4
>[43] munsell_0.5.0
>[44] crayon_1.3.4
>
>
>
>
>Sincerely,
>
>
>
>Jad Moawad
>
>
>PhD candidate and teaching assistant
>University of Lausanne  - NCCR Lives
>Institut des Sciences Sociales
>B?timent Geopolis - 5621
>1015 Lausanne
>Switzerland
>
>
>	[[alternative HTML version deleted]]

-- 
Sent from my phone. Please excuse my brevity.


From ebhod@ghe|@|th @end|ng |rom gm@||@com  Thu Dec 10 19:47:12 2020
From: ebhod@ghe|@|th @end|ng |rom gm@||@com (Ebhodaghe Faith)
Date: Thu, 10 Dec 2020 21:47:12 +0300
Subject: [R-sig-ME] Choice of fixed effects and random effects in glmm
In-Reply-To: <7927033b-23c4-493b-d82f-755688103798@phillipalday.com>
References: <CAEatWUrF_j8FOwxK33QY4SeZQG8_aha3RP35tfyE7qO7a_9RQg@mail.gmail.com>
 <7927033b-23c4-493b-d82f-755688103798@phillipalday.com>
Message-ID: <CAEatWUqi0u9+PWE=iLUQEqd=i_WizOAbndGJSO-yfzv05Ry3Tg@mail.gmail.com>

Many thanks, Philip and apologies for delayed response. Your text gives
some really great insights but I'm still studying it and trying to clearly
grasp some aspects of the message.

Cheers
Faith

On Wed, 9 Dec 2020, 1:24 p.m. Phillip Alday, <me at phillipalday.com> wrote:

> Hi  Faith,
>
> if you have a model like
>
> y ~ 1 + x * location
>
> (i.e. fixed-effects only), then this still accounts for
> repeated-measurements within the location. The motivation for doing a
> mixed model like
>
> y ~ 1 + x + (1+x|location)
>
> is that this reduces the complexity of the fixed effects, especially
> when you don't want to interpret the effects of the individual levels of
> location. This reduction in complexity means that you have fewer things
> in your fixed-effects table, which is nice, but it also means that there
> are fewer parameters in the model (because you model the variance across
> locations instead of the mean at each location) and so it becomes easier
> to fit such models when you have lots of locations. (There are also some
> other more subtle differences in terms of partial pooling, but we can
> leave those aside for now).
>
> But if you want to interpret the effect of location or particular
> locations, e.g. "the effect of x at location A", then that extra
> complexity in the fixed-effects table isn't really a problem. In that
> case, I would recommend just treating location as  a fixed effect.
>
> My commentary thus far is simplifying a lot of detail -- there are
> exceptions to almost all of the rules I'm stating. I don't know enough
> about your data, research question and inference goals to be able to
> tell if you are one of the exceptions.
>
> Thierry Onkelinx has a nice blog post on when it's okay to have
> something as both a fixed and a random effect:
>
> https://www.muscardinus.be/2017/08/fixed-and-random/
>
> The short answer is "only when you have discrete data, not for
> categorical nor continuous data", where discrete data are things like
> "time samples" which have a numerical structure but are not truly
> continuous. Distinct locations are usually simply categorical because
> they don't have a numerical structure (though I guess locations
> expressed as e.g. latitude or longitude might).
>
> Best,
>
> Phillip
>
> On 09/12/2020 07:06, Ebhodaghe Faith wrote:
> > Hi All.
> >
> > I'm running a Generalised Linear Mixed Model for a study in which I
> > repeatedly collected data within each of 14 different locations. My
> > predictor variable is 'location' and at same time wish to account for
> > repeated measures within locations. Is it okay in this case to select
> > 'location' as both fixed effects and random effects?
> >
> > Thanks in advance for kind response.
> >
> > Cheers
> > Faith
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From j|@ver|@@|mo @end|ng |rom gm@||@com  Thu Dec 10 23:13:29 2020
From: j|@ver|@@|mo @end|ng |rom gm@||@com (=?ISO-8859-1?Q?Jo=E3o_Ver=EDssimo?=)
Date: Thu, 10 Dec 2020 22:13:29 +0000
Subject: [R-sig-ME] Question regarding large data.frame in LMER?
In-Reply-To: <bbb6420ece704ba795b95f7a446c5b53@unil.ch>
References: <bbb6420ece704ba795b95f7a446c5b53@unil.ch>
Message-ID: <49d648ea0a406cbc24c82b15080703706f6dcde0.camel@gmail.com>

Not sure if these are solutions, but I'd try:

a) centering/scaling Age

and/or

b) using poly(Age, 2), rather than I(age^2)
(i.e., an orthogonal polynomial)

Maybe related to "badly scaled parameters"?
https://github.com/lme4/lme4/issues/173

Jo?o

On Thu, 2020-12-10 at 12:11 +0000, Jad Moawad wrote:
> I am working with a large data.frame that contains around 1.4 million
> observations. Initially when i was running my models, i was working
> on a sub-sample (10% of my full-sample). This is because running one
> model can take a lot of time using the original data. Once i was sure
> that all variables are well harmonized and all regressions were
> running fine, i ran my models using the full sample. However, the
> regression did not converge and i received the following two errors
> from two different models:
> 
> Error in fun(xaa, ...) : Downdated VtV is not positive definite
> 
> Error in fun(xss, ...) : Downdated VtV is not positive definite
> 
> I use the lmer function to fit my model and i include a random slopes
> at the country and country_year level. Below you find the code that i
> use.
> 
> Model1 <- lmer(health~ class + age + I(age^2)  +
> class*macro_unemployment +
>                (class + age + I(age^2)|country) +
>                (class+ age + I(age^2) |country_year) +
>                (1|id), data=df)
> 
> Model2 <- lmer(health~ education + age + I(age^2)  +
> education*macro_unemployment+
>                (education + age + I(age^2)|country) +
>                (education + age + I(age^2) |country_year) +
>                (1|id), data=df)
> 
> 
> Could someone help me please with solving this issue?
> 
> Below you find a glimpse (str) of my data and my sessionInfo():
> 
> tibble [1,370,264  8] (S3: grouped_df/tbl_df/tbl/data.frame)
>  $ health            : num [1:1370264] 100 100 50 100 0 75 75 100 100
> 50 ...
>  $ class             : Factor w/ 3 levels "Upper-middle class",..: 3
> 3 NA 3 3 3 3 1 1 3 ...
>  $ education         : Factor w/ 3 levels "low","mid","high": 1 1 1 1
> 1 1 2 3 3 1 ...
>  $ age               : num [1:1370264] 24 25 24 25 42 43 34 34 35 58
> ...
>  $ macro_unemployment: num [1:1370264] 5.24 4.86 5.24 4.86 5.24 ...
>  $ id                : int [1:1370264] 2 2 3 3 4 4 6 7 7 8 ...
>  $ country_year      : int [1:1370264] 1 2 1 2 1 2 1 1 2 1 ...
>  $ country           : Factor w/ 30 levels "Austria","Belgium",..: 1
> 1 1 1 1 1 1 1 1 1 ...
>  - attr(*, "groups")= tibble [27  2] (S3: tbl_df/tbl/data.frame)
>   ..$ country: Factor w/ 30 levels "Austria","Belgium",..: 1 2 3 6 7
> 8 9 10 11 12 ...
>   ..$ .rows  : list<int> [1:27]
>   .. ..$ : int [1:47204] 1 2 3 4 5 6 7 8 9 10 ...
>   .. ..$ : int [1:41361] 47205 47206 47207 47208 47209 47210 47211
> 47212 47213 47214 ...
>   .. ..$ : int [1:42407] 88566 88567 88568 88569 88570 88571 88572
> 88573 88574 88575 ...
>   .. ..$ : int [1:48253] 130973 130974 130975 130976 130977 130978
> 130979 130980 130981 130982 ...
>   .. ..$ : int [1:31917] 179226 179227 179228 179229 179230 179231
> 179232 179233 179234 179235 ...
>   .. ..$ : int [1:44047] 211143 211144 211145 211146 211147 211148
> 211149 211150 211151 211152 ...
>   .. ..$ : int [1:62087] 255190 255191 255192 255193 255194 255195
> 255196 255197 255198 255199 ...
>   .. ..$ : int [1:94309] 317277 317278 317279 317280 317281 317282
> 317283 317284 317285 317286 ...
>   .. ..$ : int [1:37246] 411586 411587 411588 411589 411590 411591
> 411592 411593 411594 411595 ...
>   .. ..$ : int [1:77253] 448832 448833 448834 448835 448836 448837
> 448838 448839 448840 448841 ...
>   .. ..$ : int [1:16823] 526085 526086 526087 526088 526089 526090
> 526091 526092 526093 526094 ...
>   .. ..$ : int [1:24687] 542908 542909 542910 542911 542912 542913
> 542914 542915 542916 542917 ...
>   .. ..$ : int [1:116263] 567595 567596 567597 567598 567599 567600
> 567601 567602 567603 567604 ...
>   .. ..$ : int [1:43218] 683858 683859 683860 683861 683862 683863
> 683864 683865 683866 683867 ...
>   .. ..$ : int [1:28709] 727076 727077 727078 727079 727080 727081
> 727082 727083 727084 727085 ...
>   .. ..$ : int [1:27583] 755785 755786 755787 755788 755789 755790
> 755791 755792 755793 755794 ...
>   .. ..$ : int [1:77960] 783368 783369 783370 783371 783372 783373
> 783374 783375 783376 783377 ...
>   .. ..$ : int [1:36922] 861328 861329 861330 861331 861332 861333
> 861334 861335 861336 861337 ...
>   .. ..$ : int [1:93194] 898250 898251 898252 898253 898254 898255
> 898256 898257 898258 898259 ...
>   .. ..$ : int [1:9004] 991444 991445 991446 991447 991448 991449
> 991450 991451 991452 991453 ...
>   .. ..$ : int [1:40074] 1000448 1000449 1000450 1000451 1000452
> 1000453 1000454 1000455 1000456 1000457 ...
>   .. ..$ : int [1:29342] 1040522 1040523 1040524 1040525 1040526
> 1040527 1040528 1040529 1040530 1040531 ...
>   .. ..$ : int [1:85124] 1069864 1069865 1069866 1069867 1069868
> 1069869 1069870 1069871 1069872 1069873 ...
>   .. ..$ : int [1:92350] 1154988 1154989 1154990 1154991 1154992
> 1154993 1154994 1154995 1154996 1154997 ...
>   .. ..$ : int [1:50188] 1247338 1247339 1247340 1247341 1247342
> 1247343 1247344 1247345 1247346 1247347 ...
>   .. ..$ : int [1:7598] 1297526 1297527 1297528 1297529 1297530
> 1297531 1297532 1297533 1297534 1297535 ...
>   .. ..$ : int [1:65141] 1305124 1305125 1305126 1305127 1305128
> 1305129 1305130 1305131 1305132 1305133 ...
>   .. ..@ ptype: int(0)
>   ..- attr(*, ".drop")= logi TRUE
> > 
> 
> 
> Session Info:
> 
> R version 4.0.2 (2020-06-22)
> Platform: x86_64-apple-darwin17.0 (64-bit)
> Running under: macOS Catalina 10.15.6
> 
> Matrix products: default
> BLAS:   /System/Library/Frameworks/Accelerate.framework/Versions/A/Fr
> ameworks/vecLib.framework/Versions/A/libBLAS.dylib
> LAPACK:
> /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack
> .dylib
> 
> locale:
> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
> 
> attached base packages:
> [1] stats     graphics  grDevices
> [4] utils     datasets  methods
> [7] base
> 
> other attached packages:
>  [1] sessioninfo_1.1.1
>  [2] sjlabelled_1.1.5
>  [3] varhandle_2.0.5
>  [4] labelled_2.7.0
>  [5] dplyr_1.0.0
>  [6] ggplot2_3.3.2
>  [7] forcats_0.5.0
>  [8] reprex_0.3.0
>  [9] lmerTest_3.1-3
> [10] lme4_1.1-25
> [11] Matrix_1.2-18
> 
> loaded via a namespace (and not attached):
>  [1] Rcpp_1.0.4.6
>  [2] compiler_4.0.2
>  [3] pillar_1.4.4
>  [4] nloptr_1.2.2.1
>  [5] tools_4.0.2
>  [6] digest_0.6.25
>  [7] boot_1.3-25
>  [8] statmod_1.4.34
>  [9] lifecycle_0.2.0
> [10] tibble_3.0.1
> [11] nlme_3.1-148
> [12] gtable_0.3.0
> [13] lattice_0.20-41
> [14] pkgconfig_2.0.3
> [15] rlang_0.4.7
> [16] cli_2.0.2
> [17] rstudioapi_0.11
> [18] haven_2.3.1
> [19] withr_2.2.0
> [20] hms_0.5.3
> [21] generics_0.0.2
> [22] vctrs_0.3.1
> [23] fs_1.4.1
> [24] grid_4.0.2
> [25] tidyselect_1.1.0
> [26] glue_1.4.1
> [27] R6_2.4.1
> [28] fansi_0.4.1
> [29] minqa_1.2.4
> [30] farver_2.0.3
> [31] purrr_0.3.4
> [32] magrittr_1.5
> [33] scales_1.1.1
> [34] ellipsis_0.3.1
> [35] MASS_7.3-51.6
> [36] splines_4.0.2
> [37] insight_0.11.0
> [38] assertthat_0.2.1
> [39] colorspace_1.4-1
> [40] numDeriv_2016.8-1.1
> [41] labeling_0.3
> [42] utf8_1.1.4
> [43] munsell_0.5.0
> [44] crayon_1.3.4
> 
> 
> 
> 
> Sincerely,
> 
> 
> 
> Jad Moawad
> 
> 
> PhD candidate and teaching assistant
> University of Lausanne  - NCCR Lives
> Institut des Sciences Sociales
> Btiment Geopolis - 5621
> 1015 Lausanne
> Switzerland
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From v|n|c|u@@@@m@|@77 @end|ng |rom gm@||@com  Fri Dec 11 03:33:20 2020
From: v|n|c|u@@@@m@|@77 @end|ng |rom gm@||@com (Vinicius Maia)
Date: Thu, 10 Dec 2020 23:33:20 -0300
Subject: [R-sig-ME] Question regarding large data.frame in LMER?
In-Reply-To: <49d648ea0a406cbc24c82b15080703706f6dcde0.camel@gmail.com>
References: <bbb6420ece704ba795b95f7a446c5b53@unil.ch>
 <49d648ea0a406cbc24c82b15080703706f6dcde0.camel@gmail.com>
Message-ID: <CAMXcYmapD+PpJ8mfbwKAeJuJ+keJWnNe19qxDixWObWBoaRY1Q@mail.gmail.com>

I agree with the comments above about scale and centering the continuous
predictors and use poly instead of ^2.

How many levels do you have in country_year? It seems you have only two
levels (1 and 2) in this variable.
If you have only two levels in country_year it is not a good idea to treat
this variable as random, you need more levels to estimate random slopes and
intercepts.
If it is your case, treating country_year as fixed may solve your problem.

Best,

Vin?cius

<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
Livre
de v?rus. www.avast.com
<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>.
<#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>

Em qui., 10 de dez. de 2020 ?s 19:13, Jo?o Ver?ssimo <jl.verissimo at gmail.com>
escreveu:

> Not sure if these are solutions, but I'd try:
>
> a) centering/scaling Age
>
> and/or
>
> b) using poly(Age, 2), rather than I(age^2)
> (i.e., an orthogonal polynomial)
>
> Maybe related to "badly scaled parameters"?
> https://github.com/lme4/lme4/issues/173
>
> Jo?o
>
> On Thu, 2020-12-10 at 12:11 +0000, Jad Moawad wrote:
> > I am working with a large data.frame that contains around 1.4 million
> > observations. Initially when i was running my models, i was working
> > on a sub-sample (10% of my full-sample). This is because running one
> > model can take a lot of time using the original data. Once i was sure
> > that all variables are well harmonized and all regressions were
> > running fine, i ran my models using the full sample. However, the
> > regression did not converge and i received the following two errors
> > from two different models:
> >
> > Error in fun(xaa, ...) : Downdated VtV is not positive definite
> >
> > Error in fun(xss, ...) : Downdated VtV is not positive definite
> >
> > I use the lmer function to fit my model and i include a random slopes
> > at the country and country_year level. Below you find the code that i
> > use.
> >
> > Model1 <- lmer(health~ class + age + I(age^2)  +
> > class*macro_unemployment +
> >                (class + age + I(age^2)|country) +
> >                (class+ age + I(age^2) |country_year) +
> >                (1|id), data=df)
> >
> > Model2 <- lmer(health~ education + age + I(age^2)  +
> > education*macro_unemployment+
> >                (education + age + I(age^2)|country) +
> >                (education + age + I(age^2) |country_year) +
> >                (1|id), data=df)
> >
> >
> > Could someone help me please with solving this issue?
> >
> > Below you find a glimpse (str) of my data and my sessionInfo():
> >
> > tibble [1,370,264  8] (S3: grouped_df/tbl_df/tbl/data.frame)
> >  $ health            : num [1:1370264] 100 100 50 100 0 75 75 100 100
> > 50 ...
> >  $ class             : Factor w/ 3 levels "Upper-middle class",..: 3
> > 3 NA 3 3 3 3 1 1 3 ...
> >  $ education         : Factor w/ 3 levels "low","mid","high": 1 1 1 1
> > 1 1 2 3 3 1 ...
> >  $ age               : num [1:1370264] 24 25 24 25 42 43 34 34 35 58
> > ...
> >  $ macro_unemployment: num [1:1370264] 5.24 4.86 5.24 4.86 5.24 ...
> >  $ id                : int [1:1370264] 2 2 3 3 4 4 6 7 7 8 ...
> >  $ country_year      : int [1:1370264] 1 2 1 2 1 2 1 1 2 1 ...
> >  $ country           : Factor w/ 30 levels "Austria","Belgium",..: 1
> > 1 1 1 1 1 1 1 1 1 ...
> >  - attr(*, "groups")= tibble [27  2] (S3: tbl_df/tbl/data.frame)
> >   ..$ country: Factor w/ 30 levels "Austria","Belgium",..: 1 2 3 6 7
> > 8 9 10 11 12 ...
> >   ..$ .rows  : list<int> [1:27]
> >   .. ..$ : int [1:47204] 1 2 3 4 5 6 7 8 9 10 ...
> >   .. ..$ : int [1:41361] 47205 47206 47207 47208 47209 47210 47211
> > 47212 47213 47214 ...
> >   .. ..$ : int [1:42407] 88566 88567 88568 88569 88570 88571 88572
> > 88573 88574 88575 ...
> >   .. ..$ : int [1:48253] 130973 130974 130975 130976 130977 130978
> > 130979 130980 130981 130982 ...
> >   .. ..$ : int [1:31917] 179226 179227 179228 179229 179230 179231
> > 179232 179233 179234 179235 ...
> >   .. ..$ : int [1:44047] 211143 211144 211145 211146 211147 211148
> > 211149 211150 211151 211152 ...
> >   .. ..$ : int [1:62087] 255190 255191 255192 255193 255194 255195
> > 255196 255197 255198 255199 ...
> >   .. ..$ : int [1:94309] 317277 317278 317279 317280 317281 317282
> > 317283 317284 317285 317286 ...
> >   .. ..$ : int [1:37246] 411586 411587 411588 411589 411590 411591
> > 411592 411593 411594 411595 ...
> >   .. ..$ : int [1:77253] 448832 448833 448834 448835 448836 448837
> > 448838 448839 448840 448841 ...
> >   .. ..$ : int [1:16823] 526085 526086 526087 526088 526089 526090
> > 526091 526092 526093 526094 ...
> >   .. ..$ : int [1:24687] 542908 542909 542910 542911 542912 542913
> > 542914 542915 542916 542917 ...
> >   .. ..$ : int [1:116263] 567595 567596 567597 567598 567599 567600
> > 567601 567602 567603 567604 ...
> >   .. ..$ : int [1:43218] 683858 683859 683860 683861 683862 683863
> > 683864 683865 683866 683867 ...
> >   .. ..$ : int [1:28709] 727076 727077 727078 727079 727080 727081
> > 727082 727083 727084 727085 ...
> >   .. ..$ : int [1:27583] 755785 755786 755787 755788 755789 755790
> > 755791 755792 755793 755794 ...
> >   .. ..$ : int [1:77960] 783368 783369 783370 783371 783372 783373
> > 783374 783375 783376 783377 ...
> >   .. ..$ : int [1:36922] 861328 861329 861330 861331 861332 861333
> > 861334 861335 861336 861337 ...
> >   .. ..$ : int [1:93194] 898250 898251 898252 898253 898254 898255
> > 898256 898257 898258 898259 ...
> >   .. ..$ : int [1:9004] 991444 991445 991446 991447 991448 991449
> > 991450 991451 991452 991453 ...
> >   .. ..$ : int [1:40074] 1000448 1000449 1000450 1000451 1000452
> > 1000453 1000454 1000455 1000456 1000457 ...
> >   .. ..$ : int [1:29342] 1040522 1040523 1040524 1040525 1040526
> > 1040527 1040528 1040529 1040530 1040531 ...
> >   .. ..$ : int [1:85124] 1069864 1069865 1069866 1069867 1069868
> > 1069869 1069870 1069871 1069872 1069873 ...
> >   .. ..$ : int [1:92350] 1154988 1154989 1154990 1154991 1154992
> > 1154993 1154994 1154995 1154996 1154997 ...
> >   .. ..$ : int [1:50188] 1247338 1247339 1247340 1247341 1247342
> > 1247343 1247344 1247345 1247346 1247347 ...
> >   .. ..$ : int [1:7598] 1297526 1297527 1297528 1297529 1297530
> > 1297531 1297532 1297533 1297534 1297535 ...
> >   .. ..$ : int [1:65141] 1305124 1305125 1305126 1305127 1305128
> > 1305129 1305130 1305131 1305132 1305133 ...
> >   .. ..@ ptype: int(0)
> >   ..- attr(*, ".drop")= logi TRUE
> > >
> >
> >
> > Session Info:
> >
> > R version 4.0.2 (2020-06-22)
> > Platform: x86_64-apple-darwin17.0 (64-bit)
> > Running under: macOS Catalina 10.15.6
> >
> > Matrix products: default
> > BLAS:   /System/Library/Frameworks/Accelerate.framework/Versions/A/Fr
> > ameworks/vecLib.framework/Versions/A/libBLAS.dylib
> > LAPACK:
> > /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack
> > .dylib
> >
> > locale:
> > [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
> >
> > attached base packages:
> > [1] stats     graphics  grDevices
> > [4] utils     datasets  methods
> > [7] base
> >
> > other attached packages:
> >  [1] sessioninfo_1.1.1
> >  [2] sjlabelled_1.1.5
> >  [3] varhandle_2.0.5
> >  [4] labelled_2.7.0
> >  [5] dplyr_1.0.0
> >  [6] ggplot2_3.3.2
> >  [7] forcats_0.5.0
> >  [8] reprex_0.3.0
> >  [9] lmerTest_3.1-3
> > [10] lme4_1.1-25
> > [11] Matrix_1.2-18
> >
> > loaded via a namespace (and not attached):
> >  [1] Rcpp_1.0.4.6
> >  [2] compiler_4.0.2
> >  [3] pillar_1.4.4
> >  [4] nloptr_1.2.2.1
> >  [5] tools_4.0.2
> >  [6] digest_0.6.25
> >  [7] boot_1.3-25
> >  [8] statmod_1.4.34
> >  [9] lifecycle_0.2.0
> > [10] tibble_3.0.1
> > [11] nlme_3.1-148
> > [12] gtable_0.3.0
> > [13] lattice_0.20-41
> > [14] pkgconfig_2.0.3
> > [15] rlang_0.4.7
> > [16] cli_2.0.2
> > [17] rstudioapi_0.11
> > [18] haven_2.3.1
> > [19] withr_2.2.0
> > [20] hms_0.5.3
> > [21] generics_0.0.2
> > [22] vctrs_0.3.1
> > [23] fs_1.4.1
> > [24] grid_4.0.2
> > [25] tidyselect_1.1.0
> > [26] glue_1.4.1
> > [27] R6_2.4.1
> > [28] fansi_0.4.1
> > [29] minqa_1.2.4
> > [30] farver_2.0.3
> > [31] purrr_0.3.4
> > [32] magrittr_1.5
> > [33] scales_1.1.1
> > [34] ellipsis_0.3.1
> > [35] MASS_7.3-51.6
> > [36] splines_4.0.2
> > [37] insight_0.11.0
> > [38] assertthat_0.2.1
> > [39] colorspace_1.4-1
> > [40] numDeriv_2016.8-1.1
> > [41] labeling_0.3
> > [42] utf8_1.1.4
> > [43] munsell_0.5.0
> > [44] crayon_1.3.4
> >
> >
> >
> >
> > Sincerely,
> >
> >
> >
> > Jad Moawad
> >
> >
> > PhD candidate and teaching assistant
> > University of Lausanne  - NCCR Lives
> > Institut des Sciences Sociales
> > Btiment Geopolis - 5621
> > 1015 Lausanne
> > Switzerland
> >
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From p@u|@john@on @end|ng |rom g|@@gow@@c@uk  Fri Dec 11 10:54:04 2020
From: p@u|@john@on @end|ng |rom g|@@gow@@c@uk (Paul Johnson)
Date: Fri, 11 Dec 2020 09:54:04 +0000
Subject: [R-sig-ME] Question regarding large data.frame in LMER?
In-Reply-To: <CAMXcYmapD+PpJ8mfbwKAeJuJ+keJWnNe19qxDixWObWBoaRY1Q@mail.gmail.com>
References: <bbb6420ece704ba795b95f7a446c5b53@unil.ch>
 <49d648ea0a406cbc24c82b15080703706f6dcde0.camel@gmail.com>
 <CAMXcYmapD+PpJ8mfbwKAeJuJ+keJWnNe19qxDixWObWBoaRY1Q@mail.gmail.com>
Message-ID: <79E79858-5593-4ADF-A52F-97673BE754D2@glasgow.ac.uk>

Hi Jad,

I've found that for some models on a data set of similar size to yours, glmmTMB was much faster than lme4. In my case the model was binomial, but it might be worth a try. It?s very easy to use ? basically the same syntax as lme4.

Best wishes,
Paul



> On 11 Dec 2020, at 02:33, Vinicius Maia <vinicius.a.maia77 at gmail.com> wrote:
> 
> I agree with the comments above about scale and centering the continuous
> predictors and use poly instead of ^2.
> 
> How many levels do you have in country_year? It seems you have only two
> levels (1 and 2) in this variable.
> If you have only two levels in country_year it is not a good idea to treat
> this variable as random, you need more levels to estimate random slopes and
> intercepts.
> If it is your case, treating country_year as fixed may solve your problem.
> 
> Best,
> 
> Vin?cius
> 
> <https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
> Livre
> de v?rus. www.avast.com
> <https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>.
> <#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>
> 
> Em qui., 10 de dez. de 2020 ?s 19:13, Jo?o Ver?ssimo <jl.verissimo at gmail.com>
> escreveu:
> 
>> Not sure if these are solutions, but I'd try:
>> 
>> a) centering/scaling Age
>> 
>> and/or
>> 
>> b) using poly(Age, 2), rather than I(age^2)
>> (i.e., an orthogonal polynomial)
>> 
>> Maybe related to "badly scaled parameters"?
>> https://github.com/lme4/lme4/issues/173
>> 
>> Jo?o
>> 
>> On Thu, 2020-12-10 at 12:11 +0000, Jad Moawad wrote:
>>> I am working with a large data.frame that contains around 1.4 million
>>> observations. Initially when i was running my models, i was working
>>> on a sub-sample (10% of my full-sample). This is because running one
>>> model can take a lot of time using the original data. Once i was sure
>>> that all variables are well harmonized and all regressions were
>>> running fine, i ran my models using the full sample. However, the
>>> regression did not converge and i received the following two errors
>>> from two different models:
>>> 
>>> Error in fun(xaa, ...) : Downdated VtV is not positive definite
>>> 
>>> Error in fun(xss, ...) : Downdated VtV is not positive definite
>>> 
>>> I use the lmer function to fit my model and i include a random slopes
>>> at the country and country_year level. Below you find the code that i
>>> use.
>>> 
>>> Model1 <- lmer(health~ class + age + I(age^2)  +
>>> class*macro_unemployment +
>>>               (class + age + I(age^2)|country) +
>>>               (class+ age + I(age^2) |country_year) +
>>>               (1|id), data=df)
>>> 
>>> Model2 <- lmer(health~ education + age + I(age^2)  +
>>> education*macro_unemployment+
>>>               (education + age + I(age^2)|country) +
>>>               (education + age + I(age^2) |country_year) +
>>>               (1|id), data=df)
>>> 
>>> 
>>> Could someone help me please with solving this issue?
>>> 
>>> Below you find a glimpse (str) of my data and my sessionInfo():
>>> 
>>> tibble [1,370,264  8] (S3: grouped_df/tbl_df/tbl/data.frame)
>>> $ health            : num [1:1370264] 100 100 50 100 0 75 75 100 100
>>> 50 ...
>>> $ class             : Factor w/ 3 levels "Upper-middle class",..: 3
>>> 3 NA 3 3 3 3 1 1 3 ...
>>> $ education         : Factor w/ 3 levels "low","mid","high": 1 1 1 1
>>> 1 1 2 3 3 1 ...
>>> $ age               : num [1:1370264] 24 25 24 25 42 43 34 34 35 58
>>> ...
>>> $ macro_unemployment: num [1:1370264] 5.24 4.86 5.24 4.86 5.24 ...
>>> $ id                : int [1:1370264] 2 2 3 3 4 4 6 7 7 8 ...
>>> $ country_year      : int [1:1370264] 1 2 1 2 1 2 1 1 2 1 ...
>>> $ country           : Factor w/ 30 levels "Austria","Belgium",..: 1
>>> 1 1 1 1 1 1 1 1 1 ...
>>> - attr(*, "groups")= tibble [27  2] (S3: tbl_df/tbl/data.frame)
>>>  ..$ country: Factor w/ 30 levels "Austria","Belgium",..: 1 2 3 6 7
>>> 8 9 10 11 12 ...
>>>  ..$ .rows  : list<int> [1:27]
>>>  .. ..$ : int [1:47204] 1 2 3 4 5 6 7 8 9 10 ...
>>>  .. ..$ : int [1:41361] 47205 47206 47207 47208 47209 47210 47211
>>> 47212 47213 47214 ...
>>>  .. ..$ : int [1:42407] 88566 88567 88568 88569 88570 88571 88572
>>> 88573 88574 88575 ...
>>>  .. ..$ : int [1:48253] 130973 130974 130975 130976 130977 130978
>>> 130979 130980 130981 130982 ...
>>>  .. ..$ : int [1:31917] 179226 179227 179228 179229 179230 179231
>>> 179232 179233 179234 179235 ...
>>>  .. ..$ : int [1:44047] 211143 211144 211145 211146 211147 211148
>>> 211149 211150 211151 211152 ...
>>>  .. ..$ : int [1:62087] 255190 255191 255192 255193 255194 255195
>>> 255196 255197 255198 255199 ...
>>>  .. ..$ : int [1:94309] 317277 317278 317279 317280 317281 317282
>>> 317283 317284 317285 317286 ...
>>>  .. ..$ : int [1:37246] 411586 411587 411588 411589 411590 411591
>>> 411592 411593 411594 411595 ...
>>>  .. ..$ : int [1:77253] 448832 448833 448834 448835 448836 448837
>>> 448838 448839 448840 448841 ...
>>>  .. ..$ : int [1:16823] 526085 526086 526087 526088 526089 526090
>>> 526091 526092 526093 526094 ...
>>>  .. ..$ : int [1:24687] 542908 542909 542910 542911 542912 542913
>>> 542914 542915 542916 542917 ...
>>>  .. ..$ : int [1:116263] 567595 567596 567597 567598 567599 567600
>>> 567601 567602 567603 567604 ...
>>>  .. ..$ : int [1:43218] 683858 683859 683860 683861 683862 683863
>>> 683864 683865 683866 683867 ...
>>>  .. ..$ : int [1:28709] 727076 727077 727078 727079 727080 727081
>>> 727082 727083 727084 727085 ...
>>>  .. ..$ : int [1:27583] 755785 755786 755787 755788 755789 755790
>>> 755791 755792 755793 755794 ...
>>>  .. ..$ : int [1:77960] 783368 783369 783370 783371 783372 783373
>>> 783374 783375 783376 783377 ...
>>>  .. ..$ : int [1:36922] 861328 861329 861330 861331 861332 861333
>>> 861334 861335 861336 861337 ...
>>>  .. ..$ : int [1:93194] 898250 898251 898252 898253 898254 898255
>>> 898256 898257 898258 898259 ...
>>>  .. ..$ : int [1:9004] 991444 991445 991446 991447 991448 991449
>>> 991450 991451 991452 991453 ...
>>>  .. ..$ : int [1:40074] 1000448 1000449 1000450 1000451 1000452
>>> 1000453 1000454 1000455 1000456 1000457 ...
>>>  .. ..$ : int [1:29342] 1040522 1040523 1040524 1040525 1040526
>>> 1040527 1040528 1040529 1040530 1040531 ...
>>>  .. ..$ : int [1:85124] 1069864 1069865 1069866 1069867 1069868
>>> 1069869 1069870 1069871 1069872 1069873 ...
>>>  .. ..$ : int [1:92350] 1154988 1154989 1154990 1154991 1154992
>>> 1154993 1154994 1154995 1154996 1154997 ...
>>>  .. ..$ : int [1:50188] 1247338 1247339 1247340 1247341 1247342
>>> 1247343 1247344 1247345 1247346 1247347 ...
>>>  .. ..$ : int [1:7598] 1297526 1297527 1297528 1297529 1297530
>>> 1297531 1297532 1297533 1297534 1297535 ...
>>>  .. ..$ : int [1:65141] 1305124 1305125 1305126 1305127 1305128
>>> 1305129 1305130 1305131 1305132 1305133 ...
>>>  .. ..@ ptype: int(0)
>>>  ..- attr(*, ".drop")= logi TRUE
>>>> 
>>> 
>>> 
>>> Session Info:
>>> 
>>> R version 4.0.2 (2020-06-22)
>>> Platform: x86_64-apple-darwin17.0 (64-bit)
>>> Running under: macOS Catalina 10.15.6
>>> 
>>> Matrix products: default
>>> BLAS:   /System/Library/Frameworks/Accelerate.framework/Versions/A/Fr
>>> ameworks/vecLib.framework/Versions/A/libBLAS.dylib
>>> LAPACK:
>>> /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack
>>> .dylib
>>> 
>>> locale:
>>> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>>> 
>>> attached base packages:
>>> [1] stats     graphics  grDevices
>>> [4] utils     datasets  methods
>>> [7] base
>>> 
>>> other attached packages:
>>> [1] sessioninfo_1.1.1
>>> [2] sjlabelled_1.1.5
>>> [3] varhandle_2.0.5
>>> [4] labelled_2.7.0
>>> [5] dplyr_1.0.0
>>> [6] ggplot2_3.3.2
>>> [7] forcats_0.5.0
>>> [8] reprex_0.3.0
>>> [9] lmerTest_3.1-3
>>> [10] lme4_1.1-25
>>> [11] Matrix_1.2-18
>>> 
>>> loaded via a namespace (and not attached):
>>> [1] Rcpp_1.0.4.6
>>> [2] compiler_4.0.2
>>> [3] pillar_1.4.4
>>> [4] nloptr_1.2.2.1
>>> [5] tools_4.0.2
>>> [6] digest_0.6.25
>>> [7] boot_1.3-25
>>> [8] statmod_1.4.34
>>> [9] lifecycle_0.2.0
>>> [10] tibble_3.0.1
>>> [11] nlme_3.1-148
>>> [12] gtable_0.3.0
>>> [13] lattice_0.20-41
>>> [14] pkgconfig_2.0.3
>>> [15] rlang_0.4.7
>>> [16] cli_2.0.2
>>> [17] rstudioapi_0.11
>>> [18] haven_2.3.1
>>> [19] withr_2.2.0
>>> [20] hms_0.5.3
>>> [21] generics_0.0.2
>>> [22] vctrs_0.3.1
>>> [23] fs_1.4.1
>>> [24] grid_4.0.2
>>> [25] tidyselect_1.1.0
>>> [26] glue_1.4.1
>>> [27] R6_2.4.1
>>> [28] fansi_0.4.1
>>> [29] minqa_1.2.4
>>> [30] farver_2.0.3
>>> [31] purrr_0.3.4
>>> [32] magrittr_1.5
>>> [33] scales_1.1.1
>>> [34] ellipsis_0.3.1
>>> [35] MASS_7.3-51.6
>>> [36] splines_4.0.2
>>> [37] insight_0.11.0
>>> [38] assertthat_0.2.1
>>> [39] colorspace_1.4-1
>>> [40] numDeriv_2016.8-1.1
>>> [41] labeling_0.3
>>> [42] utf8_1.1.4
>>> [43] munsell_0.5.0
>>> [44] crayon_1.3.4
>>> 
>>> 
>>> 
>>> 
>>> Sincerely,
>>> 
>>> 
>>> 
>>> Jad Moawad
>>> 
>>> 
>>> PhD candidate and teaching assistant
>>> University of Lausanne  - NCCR Lives
>>> Institut des Sciences Sociales
>>> Btiment Geopolis - 5621
>>> 1015 Lausanne
>>> Switzerland
>>> 
>>> 
>>>      [[alternative HTML version deleted]]
>>> 
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From h@ro|d@dor@n @end|ng |rom c@mb|um@@@e@@ment@com  Fri Dec 11 11:37:55 2020
From: h@ro|d@dor@n @end|ng |rom c@mb|um@@@e@@ment@com (Harold Doran)
Date: Fri, 11 Dec 2020 10:37:55 +0000
Subject: [R-sig-ME] Question regarding large data.frame in LMER?
In-Reply-To: <bbb6420ece704ba795b95f7a446c5b53@unil.ch>
References: <bbb6420ece704ba795b95f7a446c5b53@unil.ch>
Message-ID: <76a26ccefdb54623a345e5a48c01c482@cambiumassessment.com>

Assuming that you're sampling from your complete data set in a way that represents the complete data, one strategy might also be to use starting values from prior converged models and incrementally increase the size of the data.

For example, 

1) run model with 10% of data and get parameter estimates
2) use the param estimates from (1) as starting values and now increase size of data to 40%
3) repeat 

The strategy doesn't help/solve with the p.d. issue, but it does improve the potential for reaching the top of the hill with a big data file faster.

It's an incremental EM idea that reduces the amount of work lmer() (or any iterative maximization procedure) would need to do with a very large file. In other words, why start all over again with a very big file when we can start somewhere better and let the algorithm start closer to the top of the hill, so to speak.

Hope it helps.
Harold
  
 

-----Original Message-----
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> On Behalf Of Jad Moawad
Sent: Thursday, December 10, 2020 7:12 AM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] Question regarding large data.frame in LMER?

External email alert: Be wary of links & attachments.


I am working with a large data.frame that contains around 1.4 million observations. Initially when i was running my models, i was working on a sub-sample (10% of my full-sample). This is because running one model can take a lot of time using the original data. Once i was sure that all variables are well harmonized and all regressions were running fine, i ran my models using the full sample. However, the regression did not converge and i received the following two errors from two different models:

Error in fun(xaa, ...) : Downdated VtV is not positive definite

Error in fun(xss, ...) : Downdated VtV is not positive definite

I use the lmer function to fit my model and i include a random slopes at the country and country_year level. Below you find the code that i use.

Model1 <- lmer(health~ class + age + I(age^2)  + class*macro_unemployment +
               (class + age + I(age^2)|country) +
               (class+ age + I(age^2) |country_year) +
               (1|id), data=df)

Model2 <- lmer(health~ education + age + I(age^2)  + education*macro_unemployment+
               (education + age + I(age^2)|country) +
               (education + age + I(age^2) |country_year) +
               (1|id), data=df)


Could someone help me please with solving this issue?

Below you find a glimpse (str) of my data and my sessionInfo():

tibble [1,370,264   8] (S3: grouped_df/tbl_df/tbl/data.frame)
 $ health            : num [1:1370264] 100 100 50 100 0 75 75 100 100 50 ...
 $ class             : Factor w/ 3 levels "Upper-middle class",..: 3 3 NA 3 3 3 3 1 1 3 ...
 $ education         : Factor w/ 3 levels "low","mid","high": 1 1 1 1 1 1 2 3 3 1 ...
 $ age               : num [1:1370264] 24 25 24 25 42 43 34 34 35 58 ...
 $ macro_unemployment: num [1:1370264] 5.24 4.86 5.24 4.86 5.24 ...
 $ id                : int [1:1370264] 2 2 3 3 4 4 6 7 7 8 ...
 $ country_year      : int [1:1370264] 1 2 1 2 1 2 1 1 2 1 ...
 $ country           : Factor w/ 30 levels "Austria","Belgium",..: 1 1 1 1 1 1 1 1 1 1 ...
 - attr(*, "groups")= tibble [27   2] (S3: tbl_df/tbl/data.frame)
  ..$ country: Factor w/ 30 levels "Austria","Belgium",..: 1 2 3 6 7 8 9 10 11 12 ...
  ..$ .rows  : list<int> [1:27]
  .. ..$ : int [1:47204] 1 2 3 4 5 6 7 8 9 10 ...
  .. ..$ : int [1:41361] 47205 47206 47207 47208 47209 47210 47211 47212 47213 47214 ...
  .. ..$ : int [1:42407] 88566 88567 88568 88569 88570 88571 88572 88573 88574 88575 ...
  .. ..$ : int [1:48253] 130973 130974 130975 130976 130977 130978 130979 130980 130981 130982 ...
  .. ..$ : int [1:31917] 179226 179227 179228 179229 179230 179231 179232 179233 179234 179235 ...
  .. ..$ : int [1:44047] 211143 211144 211145 211146 211147 211148 211149 211150 211151 211152 ...
  .. ..$ : int [1:62087] 255190 255191 255192 255193 255194 255195 255196 255197 255198 255199 ...
  .. ..$ : int [1:94309] 317277 317278 317279 317280 317281 317282 317283 317284 317285 317286 ...
  .. ..$ : int [1:37246] 411586 411587 411588 411589 411590 411591 411592 411593 411594 411595 ...
  .. ..$ : int [1:77253] 448832 448833 448834 448835 448836 448837 448838 448839 448840 448841 ...
  .. ..$ : int [1:16823] 526085 526086 526087 526088 526089 526090 526091 526092 526093 526094 ...
  .. ..$ : int [1:24687] 542908 542909 542910 542911 542912 542913 542914 542915 542916 542917 ...
  .. ..$ : int [1:116263] 567595 567596 567597 567598 567599 567600 567601 567602 567603 567604 ...
  .. ..$ : int [1:43218] 683858 683859 683860 683861 683862 683863 683864 683865 683866 683867 ...
  .. ..$ : int [1:28709] 727076 727077 727078 727079 727080 727081 727082 727083 727084 727085 ...
  .. ..$ : int [1:27583] 755785 755786 755787 755788 755789 755790 755791 755792 755793 755794 ...
  .. ..$ : int [1:77960] 783368 783369 783370 783371 783372 783373 783374 783375 783376 783377 ...
  .. ..$ : int [1:36922] 861328 861329 861330 861331 861332 861333 861334 861335 861336 861337 ...
  .. ..$ : int [1:93194] 898250 898251 898252 898253 898254 898255 898256 898257 898258 898259 ...
  .. ..$ : int [1:9004] 991444 991445 991446 991447 991448 991449 991450 991451 991452 991453 ...
  .. ..$ : int [1:40074] 1000448 1000449 1000450 1000451 1000452 1000453 1000454 1000455 1000456 1000457 ...
  .. ..$ : int [1:29342] 1040522 1040523 1040524 1040525 1040526 1040527 1040528 1040529 1040530 1040531 ...
  .. ..$ : int [1:85124] 1069864 1069865 1069866 1069867 1069868 1069869 1069870 1069871 1069872 1069873 ...
  .. ..$ : int [1:92350] 1154988 1154989 1154990 1154991 1154992 1154993 1154994 1154995 1154996 1154997 ...
  .. ..$ : int [1:50188] 1247338 1247339 1247340 1247341 1247342 1247343 1247344 1247345 1247346 1247347 ...
  .. ..$ : int [1:7598] 1297526 1297527 1297528 1297529 1297530 1297531 1297532 1297533 1297534 1297535 ...
  .. ..$ : int [1:65141] 1305124 1305125 1305126 1305127 1305128 1305129 1305130 1305131 1305132 1305133 ...
  .. ..@ ptype: int(0)
  ..- attr(*, ".drop")= logi TRUE
>


Session Info:

R version 4.0.2 (2020-06-22)
Platform: x86_64-apple-darwin17.0 (64-bit) Running under: macOS Catalina 10.15.6

Matrix products: default
BLAS:   /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libBLAS.dylib
LAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices
[4] utils     datasets  methods
[7] base

other attached packages:
 [1] sessioninfo_1.1.1
 [2] sjlabelled_1.1.5
 [3] varhandle_2.0.5
 [4] labelled_2.7.0
 [5] dplyr_1.0.0
 [6] ggplot2_3.3.2
 [7] forcats_0.5.0
 [8] reprex_0.3.0
 [9] lmerTest_3.1-3
[10] lme4_1.1-25
[11] Matrix_1.2-18

loaded via a namespace (and not attached):
 [1] Rcpp_1.0.4.6
 [2] compiler_4.0.2
 [3] pillar_1.4.4
 [4] nloptr_1.2.2.1
 [5] tools_4.0.2
 [6] digest_0.6.25
 [7] boot_1.3-25
 [8] statmod_1.4.34
 [9] lifecycle_0.2.0
[10] tibble_3.0.1
[11] nlme_3.1-148
[12] gtable_0.3.0
[13] lattice_0.20-41
[14] pkgconfig_2.0.3
[15] rlang_0.4.7
[16] cli_2.0.2
[17] rstudioapi_0.11
[18] haven_2.3.1
[19] withr_2.2.0
[20] hms_0.5.3
[21] generics_0.0.2
[22] vctrs_0.3.1
[23] fs_1.4.1
[24] grid_4.0.2
[25] tidyselect_1.1.0
[26] glue_1.4.1
[27] R6_2.4.1
[28] fansi_0.4.1
[29] minqa_1.2.4
[30] farver_2.0.3
[31] purrr_0.3.4
[32] magrittr_1.5
[33] scales_1.1.1
[34] ellipsis_0.3.1
[35] MASS_7.3-51.6
[36] splines_4.0.2
[37] insight_0.11.0
[38] assertthat_0.2.1
[39] colorspace_1.4-1
[40] numDeriv_2016.8-1.1
[41] labeling_0.3
[42] utf8_1.1.4
[43] munsell_0.5.0
[44] crayon_1.3.4




Sincerely,



Jad Moawad


PhD candidate and teaching assistant
University of Lausanne  - NCCR Lives
Institut des Sciences Sociales
B timent Geopolis - 5621
1015 Lausanne
Switzerland


        [[alternative HTML version deleted]]


From c@c@voeten @end|ng |rom hum@|e|denun|v@n|  Fri Dec 11 11:46:17 2020
From: c@c@voeten @end|ng |rom hum@|e|denun|v@n| (Voeten, C.C.)
Date: Fri, 11 Dec 2020 10:46:17 +0000
Subject: [R-sig-ME] Question regarding large data.frame in LMER?
In-Reply-To: <76a26ccefdb54623a345e5a48c01c482@cambiumassessment.com>
References: <bbb6420ece704ba795b95f7a446c5b53@unil.ch>
 <76a26ccefdb54623a345e5a48c01c482@cambiumassessment.com>
Message-ID: <4b20de81a4324407b523c38f5ce68fb2@hum.leidenuniv.nl>

Another option could be to try fitting your model using mgcv::bam, which is optimized for 'big' datasets. The function is primarily intended for GAMMs, but an LMM is just a specific type of GAMM, so this is no problem. You could use buildmer::re2mgcv to convert your lme4 random-effects specification (i.e. your formula using | terms) to the equivalent mgcv specification (using s() terms).

However, note that the bam model will not be completely equivalent to the lme4 model, in that the bam model will not model the correlations between the random effects. If those are important to you, then please disregard my suggestion!

Cesko

-----Original Message-----
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> On Behalf Of Harold Doran
Sent: Friday, December 11, 2020 11:38 AM
To: Jad Moawad <jad.moawad at unil.ch>; r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Question regarding large data.frame in LMER?

Assuming that you're sampling from your complete data set in a way that represents the complete data, one strategy might also be to use starting values from prior converged models and incrementally increase the size of the data.

For example, 

1) run model with 10% of data and get parameter estimates
2) use the param estimates from (1) as starting values and now increase size of data to 40%
3) repeat 

The strategy doesn't help/solve with the p.d. issue, but it does improve the potential for reaching the top of the hill with a big data file faster.

It's an incremental EM idea that reduces the amount of work lmer() (or any iterative maximization procedure) would need to do with a very large file. In other words, why start all over again with a very big file when we can start somewhere better and let the algorithm start closer to the top of the hill, so to speak.

Hope it helps.
Harold
  
 

-----Original Message-----
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> On Behalf Of Jad Moawad
Sent: Thursday, December 10, 2020 7:12 AM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] Question regarding large data.frame in LMER?

External email alert: Be wary of links & attachments.


I am working with a large data.frame that contains around 1.4 million observations. Initially when i was running my models, i was working on a sub-sample (10% of my full-sample). This is because running one model can take a lot of time using the original data. Once i was sure that all variables are well harmonized and all regressions were running fine, i ran my models using the full sample. However, the regression did not converge and i received the following two errors from two different models:

Error in fun(xaa, ...) : Downdated VtV is not positive definite

Error in fun(xss, ...) : Downdated VtV is not positive definite

I use the lmer function to fit my model and i include a random slopes at the country and country_year level. Below you find the code that i use.

Model1 <- lmer(health~ class + age + I(age^2)  + class*macro_unemployment +
               (class + age + I(age^2)|country) +
               (class+ age + I(age^2) |country_year) +
               (1|id), data=df)

Model2 <- lmer(health~ education + age + I(age^2)  + education*macro_unemployment+
               (education + age + I(age^2)|country) +
               (education + age + I(age^2) |country_year) +
               (1|id), data=df)


Could someone help me please with solving this issue?

Below you find a glimpse (str) of my data and my sessionInfo():

tibble [1,370,264   8] (S3: grouped_df/tbl_df/tbl/data.frame)
 $ health            : num [1:1370264] 100 100 50 100 0 75 75 100 100 50 ...
 $ class             : Factor w/ 3 levels "Upper-middle class",..: 3 3 NA 3 3 3 3 1 1 3 ...
 $ education         : Factor w/ 3 levels "low","mid","high": 1 1 1 1 1 1 2 3 3 1 ...
 $ age               : num [1:1370264] 24 25 24 25 42 43 34 34 35 58 ...
 $ macro_unemployment: num [1:1370264] 5.24 4.86 5.24 4.86 5.24 ...
 $ id                : int [1:1370264] 2 2 3 3 4 4 6 7 7 8 ...
 $ country_year      : int [1:1370264] 1 2 1 2 1 2 1 1 2 1 ...
 $ country           : Factor w/ 30 levels "Austria","Belgium",..: 1 1 1 1 1 1 1 1 1 1 ...
 - attr(*, "groups")= tibble [27   2] (S3: tbl_df/tbl/data.frame)
  ..$ country: Factor w/ 30 levels "Austria","Belgium",..: 1 2 3 6 7 8 9 10 11 12 ...
  ..$ .rows  : list<int> [1:27]
  .. ..$ : int [1:47204] 1 2 3 4 5 6 7 8 9 10 ...
  .. ..$ : int [1:41361] 47205 47206 47207 47208 47209 47210 47211 47212 47213 47214 ...
  .. ..$ : int [1:42407] 88566 88567 88568 88569 88570 88571 88572 88573 88574 88575 ...
  .. ..$ : int [1:48253] 130973 130974 130975 130976 130977 130978 130979 130980 130981 130982 ...
  .. ..$ : int [1:31917] 179226 179227 179228 179229 179230 179231 179232 179233 179234 179235 ...
  .. ..$ : int [1:44047] 211143 211144 211145 211146 211147 211148 211149 211150 211151 211152 ...
  .. ..$ : int [1:62087] 255190 255191 255192 255193 255194 255195 255196 255197 255198 255199 ...
  .. ..$ : int [1:94309] 317277 317278 317279 317280 317281 317282 317283 317284 317285 317286 ...
  .. ..$ : int [1:37246] 411586 411587 411588 411589 411590 411591 411592 411593 411594 411595 ...
  .. ..$ : int [1:77253] 448832 448833 448834 448835 448836 448837 448838 448839 448840 448841 ...
  .. ..$ : int [1:16823] 526085 526086 526087 526088 526089 526090 526091 526092 526093 526094 ...
  .. ..$ : int [1:24687] 542908 542909 542910 542911 542912 542913 542914 542915 542916 542917 ...
  .. ..$ : int [1:116263] 567595 567596 567597 567598 567599 567600 567601 567602 567603 567604 ...
  .. ..$ : int [1:43218] 683858 683859 683860 683861 683862 683863 683864 683865 683866 683867 ...
  .. ..$ : int [1:28709] 727076 727077 727078 727079 727080 727081 727082 727083 727084 727085 ...
  .. ..$ : int [1:27583] 755785 755786 755787 755788 755789 755790 755791 755792 755793 755794 ...
  .. ..$ : int [1:77960] 783368 783369 783370 783371 783372 783373 783374 783375 783376 783377 ...
  .. ..$ : int [1:36922] 861328 861329 861330 861331 861332 861333 861334 861335 861336 861337 ...
  .. ..$ : int [1:93194] 898250 898251 898252 898253 898254 898255 898256 898257 898258 898259 ...
  .. ..$ : int [1:9004] 991444 991445 991446 991447 991448 991449 991450 991451 991452 991453 ...
  .. ..$ : int [1:40074] 1000448 1000449 1000450 1000451 1000452 1000453 1000454 1000455 1000456 1000457 ...
  .. ..$ : int [1:29342] 1040522 1040523 1040524 1040525 1040526 1040527 1040528 1040529 1040530 1040531 ...
  .. ..$ : int [1:85124] 1069864 1069865 1069866 1069867 1069868 1069869 1069870 1069871 1069872 1069873 ...
  .. ..$ : int [1:92350] 1154988 1154989 1154990 1154991 1154992 1154993 1154994 1154995 1154996 1154997 ...
  .. ..$ : int [1:50188] 1247338 1247339 1247340 1247341 1247342 1247343 1247344 1247345 1247346 1247347 ...
  .. ..$ : int [1:7598] 1297526 1297527 1297528 1297529 1297530 1297531 1297532 1297533 1297534 1297535 ...
  .. ..$ : int [1:65141] 1305124 1305125 1305126 1305127 1305128 1305129 1305130 1305131 1305132 1305133 ...
  .. ..@ ptype: int(0)
  ..- attr(*, ".drop")= logi TRUE
>


Session Info:

R version 4.0.2 (2020-06-22)
Platform: x86_64-apple-darwin17.0 (64-bit) Running under: macOS Catalina 10.15.6

Matrix products: default
BLAS:   /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libBLAS.dylib
LAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices
[4] utils     datasets  methods
[7] base

other attached packages:
 [1] sessioninfo_1.1.1
 [2] sjlabelled_1.1.5
 [3] varhandle_2.0.5
 [4] labelled_2.7.0
 [5] dplyr_1.0.0
 [6] ggplot2_3.3.2
 [7] forcats_0.5.0
 [8] reprex_0.3.0
 [9] lmerTest_3.1-3
[10] lme4_1.1-25
[11] Matrix_1.2-18

loaded via a namespace (and not attached):
 [1] Rcpp_1.0.4.6
 [2] compiler_4.0.2
 [3] pillar_1.4.4
 [4] nloptr_1.2.2.1
 [5] tools_4.0.2
 [6] digest_0.6.25
 [7] boot_1.3-25
 [8] statmod_1.4.34
 [9] lifecycle_0.2.0
[10] tibble_3.0.1
[11] nlme_3.1-148
[12] gtable_0.3.0
[13] lattice_0.20-41
[14] pkgconfig_2.0.3
[15] rlang_0.4.7
[16] cli_2.0.2
[17] rstudioapi_0.11
[18] haven_2.3.1
[19] withr_2.2.0
[20] hms_0.5.3
[21] generics_0.0.2
[22] vctrs_0.3.1
[23] fs_1.4.1
[24] grid_4.0.2
[25] tidyselect_1.1.0
[26] glue_1.4.1
[27] R6_2.4.1
[28] fansi_0.4.1
[29] minqa_1.2.4
[30] farver_2.0.3
[31] purrr_0.3.4
[32] magrittr_1.5
[33] scales_1.1.1
[34] ellipsis_0.3.1
[35] MASS_7.3-51.6
[36] splines_4.0.2
[37] insight_0.11.0
[38] assertthat_0.2.1
[39] colorspace_1.4-1
[40] numDeriv_2016.8-1.1
[41] labeling_0.3
[42] utf8_1.1.4
[43] munsell_0.5.0
[44] crayon_1.3.4




Sincerely,



Jad Moawad


PhD candidate and teaching assistant
University of Lausanne  - NCCR Lives
Institut des Sciences Sociales
B timent Geopolis - 5621
1015 Lausanne
Switzerland


        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From ch|r|eu @end|ng |rom gm@||@com  Mon Dec 14 09:13:42 2020
From: ch|r|eu @end|ng |rom gm@||@com (=?UTF-8?Q?David_Villegas_R=C3=ADos?=)
Date: Mon, 14 Dec 2020 09:13:42 +0100
Subject: [R-sig-ME] simulating gam/bam model
Message-ID: <CALC46t-M2UpTr5A_WkXkesUySbYXte8FaxBz7XMWJamFvOQGtQ@mail.gmail.com>

Hi,
I have been using the *sim *function in the arm package to simulate glm
models in R and then extract random effects.

mymodel =lmer(y~x1+x2+x3+(1|ID),data=mydataset)
mysim=sim(mymodel,n.sims=1000)
simulated_raneffs=as.data.frame(mysim at ranef)

However, it seems that the *sim *function doesn?t work with additive
(gam/bam) models. Is there any alternative for simulating gam/bam models to
later extract random effects?

Thanks,
David

	[[alternative HTML version deleted]]


From h@ro|d@dor@n @end|ng |rom c@mb|um@@@e@@ment@com  Mon Dec 14 12:45:01 2020
From: h@ro|d@dor@n @end|ng |rom c@mb|um@@@e@@ment@com (Harold Doran)
Date: Mon, 14 Dec 2020 11:45:01 +0000
Subject: [R-sig-ME] Follow up question
In-Reply-To: <c3ec1ac55a99412b9247b29aa56c1627@cambiumassessment.com>
References: <26348ea8de234a2b9bcd1e12ca9ef7d9@unil.ch>
 <c3ec1ac55a99412b9247b29aa56c1627@cambiumassessment.com>
Message-ID: <83a04b1fa0bf40378b855798579cadf1@cambiumassessment.com>

(adding the list back to this thread).

No web page. It's an idea I've worked with for many years but haven't published. In the world of psychometrics (specifically what are called "value-added models") we deal with hundreds of thousands of students where each student has multiple test scores and students are linked to multiple teachers and schools.

Estimating the parameters for these models is a huge challenge and Doug Bates and I discussed sparse matrix many years ago as one way to implement a faster approach. That helps a lot, but going even faster is sometimes needed.

So, in psychometrics, we use what is sometimes referred to as an "early return sample" and that's the idea I'm basing this concept on.

In k-12 testing, we need to obtain parameter estimates for test items very quickly so we can use them in other activities (like generate test scores). So, in order to be fast, we define a priori a scientific sample and those students provide data by which we estimate the statistical parameters we need and those parameters from the sample are projected onto the population.

We can conceptually apply this concept to mixed model estimation or even more broadly to iterative statistical procedures. I have written software that implements estimation for error-in-variables linear mixed effects that uses Henderson's method, so I'll illustrate speaking that "language", although Ben Bolker and others might use a different approach for LME (I'm not sure anymore).

Let Ax = y be the linear system where A is the leftmost part of the Henderson equation, x is the vector of parameters we wish to solve for and y is the vector of outcomes. The issue that is "hard" is that the dimension of A are n x m (where m is a concatenation of columns over the fixed and random effects matrices). The typical challenge as in your case is that n is huge-it's the number of observations in the data and that can be millions.

Solving mixed models is an iterative process and so we have to find decompositions on the matrix A at each iteration. But, if A is big, that's a lot of work. So, we can make a big problem small and sample such that there are n_1 rows in the matrix A such that n_1 < n.

It's much easier to work with a smaller A than it is a bigger A.  Use this smaller A to run the model and get some parameters estimates. If you sample properly, those parameter estimates will reflect the population within sampling error, right?

Now, plug those in as starting values to lmer and increase the number of observations you use by some amount. Since lmer is starting from a better place, it will do fewer iterations and "converge" more quickly. Repeat until you have your full data

This is a bit "art" and it's more of a concept that can be applied to a big data problem with no real hard rules. But, I deal with large state wide data files with millions of observations like you and often use this method.

While I don't have exact timing data, I'll share with you that this approach has saved about 50% run time on some large data sets I've used. When those models take many hours, 50% is huge.




From: Jad Moawad <jad.moawad at unil.ch<mailto:jad.moawad at unil.ch>>
Sent: Monday, December 14, 2020 5:37 AM
To: Harold Doran <harold.doran at cambiumassessment.com<mailto:harold.doran at cambiumassessment.com>>
Subject: Follow up question


Dear Harold,



Thanks a lot for your response on my LME4 question. I am currently working on the comments that i have received. So far, unfortunately, the issue is still there. I was wondering whether you know a good webpage that has a good example on how to execute the gradual regression approach that you have mentioned in your comment.


I'm sure you're busy, so even a short line or reference would be greatly appreciated.


All the best,



Jad Moawad



Assuming that you're sampling from your complete data set in a way that represents the complete data, one strategy might also be to use starting values from prior converged models and incrementally increase the size of the data.

For example,

1) run model with 10% of data and get parameter estimates
2) use the param estimates from (1) as starting values and now increase size of data to 40%
3) repeat

The strategy doesn't help/solve with the p.d. issue, but it does improve the potential for reaching the top of the hill with a big data file faster.

It's an incremental EM idea that reduces the amount of work lmer() (or any iterative maximization procedure) would need to do with a very large file. In other words, why start all over again with a very big file when we can start somewhere better and let the algorithm start closer to the top of the hill, so to speak.

Hope it helps.
Harold



	[[alternative HTML version deleted]]


From jungm@@rten @end|ng |rom gm@||@com  Mon Dec 14 16:51:23 2020
From: jungm@@rten @end|ng |rom gm@||@com (Maarten Jung)
Date: Mon, 14 Dec 2020 16:51:23 +0100
Subject: [R-sig-ME] Finding interval with negligible linear trend
Message-ID: <fe613a97-d963-8b94-8121-e26d55e48103@gmail.com>

Dear list,

I have time course data with many data points per subject over time and 
want to dertermine the interval in which my dependent variable lies 
within given equivalence bounds around a zero (linear) trend.
I thought about using lme4::lmer() (or the like) for fitting a linear 
mixed model with (possibly orthogonal) polynomials in time as fixed 
effects and the corresponding by-subject random intercept and slopes to 
(i) get a (simultaneous) 90% confidence band for the regression function 
and (ii) then determine the interval in which this confindence band lies 
within the equivalence bounds.
But I'm not exactely sure whether this is a reasonable approach and if 
so how I could do this in R.

Any help is highly appreciated.

Best regards,
Maarten


From j@d@mo@w@d @end|ng |rom un||@ch  Mon Dec 14 17:00:41 2020
From: j@d@mo@w@d @end|ng |rom un||@ch (Jad Moawad)
Date: Mon, 14 Dec 2020 16:00:41 +0000
Subject: [R-sig-ME] Question regarding large data.frame in LMER?
In-Reply-To: <4b20de81a4324407b523c38f5ce68fb2@hum.leidenuniv.nl>
References: <bbb6420ece704ba795b95f7a446c5b53@unil.ch>
 <76a26ccefdb54623a345e5a48c01c482@cambiumassessment.com>,
 <4b20de81a4324407b523c38f5ce68fb2@hum.leidenuniv.nl>
Message-ID: <1ed013a1ff97498fbc24e73d27ec4ba0@unil.ch>

Thanks a lot everyone for all the suggestions you have provided, I really appreciate it. I have some replies over some comments and will write what have worked so far.



1)    If understood well the comment regarding the duplicates, there was already no id that has the same number twice across different countries and years.

2)    I switched the data.frame from tibble to as.dataframe.

3)    I use now: poly(agecent, degree=2, raw=T) instead of I(age^2).

4)    I tried centering, scaling and/or standardizing my variables but this have not solved the issue.

5)    Regarding the question about how many country_years level I have. I have observations (1,150,110)  that are nested in *both* individuals (472,604) and country-years (180). In other words, they are cross-classified. In turn, individuals and country-years are *both* nested in countries (30). So the data structure is like a diamond, with a point (observations) at the bottom, another point (countries) at the top, and the other two levels in between.

6)    I tried to use glmTMB on a binary outcome, however, I received an error that it directed me to this page: https://cran.r-project.org/web/packages/glmmTMB/vignettes/troubleshooting.html



In the meantime, i received a comment from a statistics professor to change the design of my model. He suggested to do observation_years (level 1) nested within individuals (level 2) nested within countries (level 3). This model seemed to work fine.



In short, I am still not sure what is the main issue. I still have to try the methods suggested by Harold and Cesko. However, I am still not sure how to use buildmer::re2mgcv. If I don?t succeed with these methods, I will stick to the new design.



All the best,



Jad




________________________________
De : Voeten, C.C. <c.c.voeten at hum.leidenuniv.nl>
Envoy? : vendredi 11 d?cembre 2020 11:46:17
? : Harold Doran; Jad Moawad; r-sig-mixed-models at r-project.org
Objet : RE: Question regarding large data.frame in LMER?

Another option could be to try fitting your model using mgcv::bam, which is optimized for 'big' datasets. The function is primarily intended for GAMMs, but an LMM is just a specific type of GAMM, so this is no problem. You could use buildmer::re2mgcv to convert your lme4 random-effects specification (i.e. your formula using | terms) to the equivalent mgcv specification (using s() terms).

However, note that the bam model will not be completely equivalent to the lme4 model, in that the bam model will not model the correlations between the random effects. If those are important to you, then please disregard my suggestion!

Cesko

-----Original Message-----
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> On Behalf Of Harold Doran
Sent: Friday, December 11, 2020 11:38 AM
To: Jad Moawad <jad.moawad at unil.ch>; r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Question regarding large data.frame in LMER?

Assuming that you're sampling from your complete data set in a way that represents the complete data, one strategy might also be to use starting values from prior converged models and incrementally increase the size of the data.

For example,

1) run model with 10% of data and get parameter estimates
2) use the param estimates from (1) as starting values and now increase size of data to 40%
3) repeat

The strategy doesn't help/solve with the p.d. issue, but it does improve the potential for reaching the top of the hill with a big data file faster.

It's an incremental EM idea that reduces the amount of work lmer() (or any iterative maximization procedure) would need to do with a very large file. In other words, why start all over again with a very big file when we can start somewhere better and let the algorithm start closer to the top of the hill, so to speak.

Hope it helps.
Harold



-----Original Message-----
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> On Behalf Of Jad Moawad
Sent: Thursday, December 10, 2020 7:12 AM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] Question regarding large data.frame in LMER?

External email alert: Be wary of links & attachments.


I am working with a large data.frame that contains around 1.4 million observations. Initially when i was running my models, i was working on a sub-sample (10% of my full-sample). This is because running one model can take a lot of time using the original data. Once i was sure that all variables are well harmonized and all regressions were running fine, i ran my models using the full sample. However, the regression did not converge and i received the following two errors from two different models:

Error in fun(xaa, ...) : Downdated VtV is not positive definite

Error in fun(xss, ...) : Downdated VtV is not positive definite

I use the lmer function to fit my model and i include a random slopes at the country and country_year level. Below you find the code that i use.

Model1 <- lmer(health~ class + age + I(age^2)  + class*macro_unemployment +
               (class + age + I(age^2)|country) +
               (class+ age + I(age^2) |country_year) +
               (1|id), data=df)

Model2 <- lmer(health~ education + age + I(age^2)  + education*macro_unemployment+
               (education + age + I(age^2)|country) +
               (education + age + I(age^2) |country_year) +
               (1|id), data=df)


Could someone help me please with solving this issue?

Below you find a glimpse (str) of my data and my sessionInfo():

tibble [1,370,264   8] (S3: grouped_df/tbl_df/tbl/data.frame)
 $ health            : num [1:1370264] 100 100 50 100 0 75 75 100 100 50 ...
 $ class             : Factor w/ 3 levels "Upper-middle class",..: 3 3 NA 3 3 3 3 1 1 3 ...
 $ education         : Factor w/ 3 levels "low","mid","high": 1 1 1 1 1 1 2 3 3 1 ...
 $ age               : num [1:1370264] 24 25 24 25 42 43 34 34 35 58 ...
 $ macro_unemployment: num [1:1370264] 5.24 4.86 5.24 4.86 5.24 ...
 $ id                : int [1:1370264] 2 2 3 3 4 4 6 7 7 8 ...
 $ country_year      : int [1:1370264] 1 2 1 2 1 2 1 1 2 1 ...
 $ country           : Factor w/ 30 levels "Austria","Belgium",..: 1 1 1 1 1 1 1 1 1 1 ...
 - attr(*, "groups")= tibble [27   2] (S3: tbl_df/tbl/data.frame)
  ..$ country: Factor w/ 30 levels "Austria","Belgium",..: 1 2 3 6 7 8 9 10 11 12 ...
  ..$ .rows  : list<int> [1:27]
  .. ..$ : int [1:47204] 1 2 3 4 5 6 7 8 9 10 ...
  .. ..$ : int [1:41361] 47205 47206 47207 47208 47209 47210 47211 47212 47213 47214 ...
  .. ..$ : int [1:42407] 88566 88567 88568 88569 88570 88571 88572 88573 88574 88575 ...
  .. ..$ : int [1:48253] 130973 130974 130975 130976 130977 130978 130979 130980 130981 130982 ...
  .. ..$ : int [1:31917] 179226 179227 179228 179229 179230 179231 179232 179233 179234 179235 ...
  .. ..$ : int [1:44047] 211143 211144 211145 211146 211147 211148 211149 211150 211151 211152 ...
  .. ..$ : int [1:62087] 255190 255191 255192 255193 255194 255195 255196 255197 255198 255199 ...
  .. ..$ : int [1:94309] 317277 317278 317279 317280 317281 317282 317283 317284 317285 317286 ...
  .. ..$ : int [1:37246] 411586 411587 411588 411589 411590 411591 411592 411593 411594 411595 ...
  .. ..$ : int [1:77253] 448832 448833 448834 448835 448836 448837 448838 448839 448840 448841 ...
  .. ..$ : int [1:16823] 526085 526086 526087 526088 526089 526090 526091 526092 526093 526094 ...
  .. ..$ : int [1:24687] 542908 542909 542910 542911 542912 542913 542914 542915 542916 542917 ...
  .. ..$ : int [1:116263] 567595 567596 567597 567598 567599 567600 567601 567602 567603 567604 ...
  .. ..$ : int [1:43218] 683858 683859 683860 683861 683862 683863 683864 683865 683866 683867 ...
  .. ..$ : int [1:28709] 727076 727077 727078 727079 727080 727081 727082 727083 727084 727085 ...
  .. ..$ : int [1:27583] 755785 755786 755787 755788 755789 755790 755791 755792 755793 755794 ...
  .. ..$ : int [1:77960] 783368 783369 783370 783371 783372 783373 783374 783375 783376 783377 ...
  .. ..$ : int [1:36922] 861328 861329 861330 861331 861332 861333 861334 861335 861336 861337 ...
  .. ..$ : int [1:93194] 898250 898251 898252 898253 898254 898255 898256 898257 898258 898259 ...
  .. ..$ : int [1:9004] 991444 991445 991446 991447 991448 991449 991450 991451 991452 991453 ...
  .. ..$ : int [1:40074] 1000448 1000449 1000450 1000451 1000452 1000453 1000454 1000455 1000456 1000457 ...
  .. ..$ : int [1:29342] 1040522 1040523 1040524 1040525 1040526 1040527 1040528 1040529 1040530 1040531 ...
  .. ..$ : int [1:85124] 1069864 1069865 1069866 1069867 1069868 1069869 1069870 1069871 1069872 1069873 ...
  .. ..$ : int [1:92350] 1154988 1154989 1154990 1154991 1154992 1154993 1154994 1154995 1154996 1154997 ...
  .. ..$ : int [1:50188] 1247338 1247339 1247340 1247341 1247342 1247343 1247344 1247345 1247346 1247347 ...
  .. ..$ : int [1:7598] 1297526 1297527 1297528 1297529 1297530 1297531 1297532 1297533 1297534 1297535 ...
  .. ..$ : int [1:65141] 1305124 1305125 1305126 1305127 1305128 1305129 1305130 1305131 1305132 1305133 ...
  .. ..@ ptype: int(0)
  ..- attr(*, ".drop")= logi TRUE
>


Session Info:

R version 4.0.2 (2020-06-22)
Platform: x86_64-apple-darwin17.0 (64-bit) Running under: macOS Catalina 10.15.6

Matrix products: default
BLAS:   /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libBLAS.dylib
LAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices
[4] utils     datasets  methods
[7] base

other attached packages:
 [1] sessioninfo_1.1.1
 [2] sjlabelled_1.1.5
 [3] varhandle_2.0.5
 [4] labelled_2.7.0
 [5] dplyr_1.0.0
 [6] ggplot2_3.3.2
 [7] forcats_0.5.0
 [8] reprex_0.3.0
 [9] lmerTest_3.1-3
[10] lme4_1.1-25
[11] Matrix_1.2-18

loaded via a namespace (and not attached):
 [1] Rcpp_1.0.4.6
 [2] compiler_4.0.2
 [3] pillar_1.4.4
 [4] nloptr_1.2.2.1
 [5] tools_4.0.2
 [6] digest_0.6.25
 [7] boot_1.3-25
 [8] statmod_1.4.34
 [9] lifecycle_0.2.0
[10] tibble_3.0.1
[11] nlme_3.1-148
[12] gtable_0.3.0
[13] lattice_0.20-41
[14] pkgconfig_2.0.3
[15] rlang_0.4.7
[16] cli_2.0.2
[17] rstudioapi_0.11
[18] haven_2.3.1
[19] withr_2.2.0
[20] hms_0.5.3
[21] generics_0.0.2
[22] vctrs_0.3.1
[23] fs_1.4.1
[24] grid_4.0.2
[25] tidyselect_1.1.0
[26] glue_1.4.1
[27] R6_2.4.1
[28] fansi_0.4.1
[29] minqa_1.2.4
[30] farver_2.0.3
[31] purrr_0.3.4
[32] magrittr_1.5
[33] scales_1.1.1
[34] ellipsis_0.3.1
[35] MASS_7.3-51.6
[36] splines_4.0.2
[37] insight_0.11.0
[38] assertthat_0.2.1
[39] colorspace_1.4-1
[40] numDeriv_2016.8-1.1
[41] labeling_0.3
[42] utf8_1.1.4
[43] munsell_0.5.0
[44] crayon_1.3.4




Sincerely,



Jad Moawad


PhD candidate and teaching assistant
University of Lausanne  - NCCR Lives
Institut des Sciences Sociales
B timent Geopolis - 5621
1015 Lausanne
Switzerland


        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From b@te@ @end|ng |rom @t@t@w|@c@edu  Mon Dec 14 17:09:15 2020
From: b@te@ @end|ng |rom @t@t@w|@c@edu (Douglas Bates)
Date: Mon, 14 Dec 2020 10:09:15 -0600
Subject: [R-sig-ME] Question regarding large data.frame in LMER?
In-Reply-To: <9688_1607683706_0QL600JKI8OPJL00_4b20de81a4324407b523c38f5ce68fb2@hum.leidenuniv.nl>
References: <bbb6420ece704ba795b95f7a446c5b53@unil.ch>
 <76a26ccefdb54623a345e5a48c01c482@cambiumassessment.com>
 <9688_1607683706_0QL600JKI8OPJL00_4b20de81a4324407b523c38f5ce68fb2@hum.leidenuniv.nl>
Message-ID: <CAO7JsnQzCYt11tZsTyV=w6E=6nUCrYi_qh-N6kvofESSGQAoAg@mail.gmail.com>

Sorry for coming to this discussion late.  I notice that in the glimpse of
the data set the first few values of id occur in pairs.  If you convert id
to a factor how many levels does it have?

The implementation of mixed-effects models in the MixedModels (
https://github.com/JuliaStats/MixedModels.jl) package for Julia is better
suited to dealing with large numbers of observations than is the one in
lme4.  It uses a more compact numerical representation of the model during
the iterations to optimize the profiled log-likelihood.  Some of this is
described in
https://nextjournal.com/dmbates/complexity-in-fitting-linear-mixed-models
The important point is that evaluation of the profiled log-likelihood for
new parameter values does not require working with matrices whose size
depends on n, the number of observations.  All matrices are of sizes
determined by the number of random effects and the number of fixed-effects
parameters.  Of course, if each id only occurs twice then the number of
random effects is already on the order of the number of observations so
this will not be an advantage.

If you are interested in trying the Julia package we can help with that.

If anyone wants to try to implement the MixedModels approach in R I can
advise you how to do it but I really don't have the energy to do the R/C++
two-language dance any more.

On Fri, Dec 11, 2020 at 4:48 AM Voeten, C.C. <c.c.voeten at hum.leidenuniv.nl>
wrote:

> Another option could be to try fitting your model using mgcv::bam, which
> is optimized for 'big' datasets. The function is primarily intended for
> GAMMs, but an LMM is just a specific type of GAMM, so this is no problem.
> You could use buildmer::re2mgcv to convert your lme4 random-effects
> specification (i.e. your formula using | terms) to the equivalent mgcv
> specification (using s() terms).
>
> However, note that the bam model will not be completely equivalent to the
> lme4 model, in that the bam model will not model the correlations between
> the random effects. If those are important to you, then please disregard my
> suggestion!
>
> Cesko
>
> -----Original Message-----
> From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> On
> Behalf Of Harold Doran
> Sent: Friday, December 11, 2020 11:38 AM
> To: Jad Moawad <jad.moawad at unil.ch>; r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Question regarding large data.frame in LMER?
>
> Assuming that you're sampling from your complete data set in a way that
> represents the complete data, one strategy might also be to use starting
> values from prior converged models and incrementally increase the size of
> the data.
>
> For example,
>
> 1) run model with 10% of data and get parameter estimates
> 2) use the param estimates from (1) as starting values and now increase
> size of data to 40%
> 3) repeat
>
> The strategy doesn't help/solve with the p.d. issue, but it does improve
> the potential for reaching the top of the hill with a big data file faster.
>
> It's an incremental EM idea that reduces the amount of work lmer() (or any
> iterative maximization procedure) would need to do with a very large file.
> In other words, why start all over again with a very big file when we can
> start somewhere better and let the algorithm start closer to the top of the
> hill, so to speak.
>
> Hope it helps.
> Harold
>
>
>
> -----Original Message-----
> From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> On
> Behalf Of Jad Moawad
> Sent: Thursday, December 10, 2020 7:12 AM
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] Question regarding large data.frame in LMER?
>
> External email alert: Be wary of links & attachments.
>
>
> I am working with a large data.frame that contains around 1.4 million
> observations. Initially when i was running my models, i was working on a
> sub-sample (10% of my full-sample). This is because running one model can
> take a lot of time using the original data. Once i was sure that all
> variables are well harmonized and all regressions were running fine, i ran
> my models using the full sample. However, the regression did not converge
> and i received the following two errors from two different models:
>
> Error in fun(xaa, ...) : Downdated VtV is not positive definite
>
> Error in fun(xss, ...) : Downdated VtV is not positive definite
>
> I use the lmer function to fit my model and i include a random slopes at
> the country and country_year level. Below you find the code that i use.
>
> Model1 <- lmer(health~ class + age + I(age^2)  + class*macro_unemployment +
>                (class + age + I(age^2)|country) +
>                (class+ age + I(age^2) |country_year) +
>                (1|id), data=df)
>
> Model2 <- lmer(health~ education + age + I(age^2)  +
> education*macro_unemployment+
>                (education + age + I(age^2)|country) +
>                (education + age + I(age^2) |country_year) +
>                (1|id), data=df)
>
>
> Could someone help me please with solving this issue?
>
> Below you find a glimpse (str) of my data and my sessionInfo():
>
> tibble [1,370,264   8] (S3: grouped_df/tbl_df/tbl/data.frame)
>  $ health            : num [1:1370264] 100 100 50 100 0 75 75 100 100 50
> ...
>  $ class             : Factor w/ 3 levels "Upper-middle class",..: 3 3 NA
> 3 3 3 3 1 1 3 ...
>  $ education         : Factor w/ 3 levels "low","mid","high": 1 1 1 1 1 1
> 2 3 3 1 ...
>  $ age               : num [1:1370264] 24 25 24 25 42 43 34 34 35 58 ...
>  $ macro_unemployment: num [1:1370264] 5.24 4.86 5.24 4.86 5.24 ...
>  $ id                : int [1:1370264] 2 2 3 3 4 4 6 7 7 8 ...
>  $ country_year      : int [1:1370264] 1 2 1 2 1 2 1 1 2 1 ...
>  $ country           : Factor w/ 30 levels "Austria","Belgium",..: 1 1 1 1
> 1 1 1 1 1 1 ...
>  - attr(*, "groups")= tibble [27   2] (S3: tbl_df/tbl/data.frame)
>   ..$ country: Factor w/ 30 levels "Austria","Belgium",..: 1 2 3 6 7 8 9
> 10 11 12 ...
>   ..$ .rows  : list<int> [1:27]
>   .. ..$ : int [1:47204] 1 2 3 4 5 6 7 8 9 10 ...
>   .. ..$ : int [1:41361] 47205 47206 47207 47208 47209 47210 47211 47212
> 47213 47214 ...
>   .. ..$ : int [1:42407] 88566 88567 88568 88569 88570 88571 88572 88573
> 88574 88575 ...
>   .. ..$ : int [1:48253] 130973 130974 130975 130976 130977 130978 130979
> 130980 130981 130982 ...
>   .. ..$ : int [1:31917] 179226 179227 179228 179229 179230 179231 179232
> 179233 179234 179235 ...
>   .. ..$ : int [1:44047] 211143 211144 211145 211146 211147 211148 211149
> 211150 211151 211152 ...
>   .. ..$ : int [1:62087] 255190 255191 255192 255193 255194 255195 255196
> 255197 255198 255199 ...
>   .. ..$ : int [1:94309] 317277 317278 317279 317280 317281 317282 317283
> 317284 317285 317286 ...
>   .. ..$ : int [1:37246] 411586 411587 411588 411589 411590 411591 411592
> 411593 411594 411595 ...
>   .. ..$ : int [1:77253] 448832 448833 448834 448835 448836 448837 448838
> 448839 448840 448841 ...
>   .. ..$ : int [1:16823] 526085 526086 526087 526088 526089 526090 526091
> 526092 526093 526094 ...
>   .. ..$ : int [1:24687] 542908 542909 542910 542911 542912 542913 542914
> 542915 542916 542917 ...
>   .. ..$ : int [1:116263] 567595 567596 567597 567598 567599 567600 567601
> 567602 567603 567604 ...
>   .. ..$ : int [1:43218] 683858 683859 683860 683861 683862 683863 683864
> 683865 683866 683867 ...
>   .. ..$ : int [1:28709] 727076 727077 727078 727079 727080 727081 727082
> 727083 727084 727085 ...
>   .. ..$ : int [1:27583] 755785 755786 755787 755788 755789 755790 755791
> 755792 755793 755794 ...
>   .. ..$ : int [1:77960] 783368 783369 783370 783371 783372 783373 783374
> 783375 783376 783377 ...
>   .. ..$ : int [1:36922] 861328 861329 861330 861331 861332 861333 861334
> 861335 861336 861337 ...
>   .. ..$ : int [1:93194] 898250 898251 898252 898253 898254 898255 898256
> 898257 898258 898259 ...
>   .. ..$ : int [1:9004] 991444 991445 991446 991447 991448 991449 991450
> 991451 991452 991453 ...
>   .. ..$ : int [1:40074] 1000448 1000449 1000450 1000451 1000452 1000453
> 1000454 1000455 1000456 1000457 ...
>   .. ..$ : int [1:29342] 1040522 1040523 1040524 1040525 1040526 1040527
> 1040528 1040529 1040530 1040531 ...
>   .. ..$ : int [1:85124] 1069864 1069865 1069866 1069867 1069868 1069869
> 1069870 1069871 1069872 1069873 ...
>   .. ..$ : int [1:92350] 1154988 1154989 1154990 1154991 1154992 1154993
> 1154994 1154995 1154996 1154997 ...
>   .. ..$ : int [1:50188] 1247338 1247339 1247340 1247341 1247342 1247343
> 1247344 1247345 1247346 1247347 ...
>   .. ..$ : int [1:7598] 1297526 1297527 1297528 1297529 1297530 1297531
> 1297532 1297533 1297534 1297535 ...
>   .. ..$ : int [1:65141] 1305124 1305125 1305126 1305127 1305128 1305129
> 1305130 1305131 1305132 1305133 ...
>   .. ..@ ptype: int(0)
>   ..- attr(*, ".drop")= logi TRUE
> >
>
>
> Session Info:
>
> R version 4.0.2 (2020-06-22)
> Platform: x86_64-apple-darwin17.0 (64-bit) Running under: macOS Catalina
> 10.15.6
>
> Matrix products: default
> BLAS:
>  /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libBLAS.dylib
> LAPACK:
> /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib
>
> locale:
> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>
> attached base packages:
> [1] stats     graphics  grDevices
> [4] utils     datasets  methods
> [7] base
>
> other attached packages:
>  [1] sessioninfo_1.1.1
>  [2] sjlabelled_1.1.5
>  [3] varhandle_2.0.5
>  [4] labelled_2.7.0
>  [5] dplyr_1.0.0
>  [6] ggplot2_3.3.2
>  [7] forcats_0.5.0
>  [8] reprex_0.3.0
>  [9] lmerTest_3.1-3
> [10] lme4_1.1-25
> [11] Matrix_1.2-18
>
> loaded via a namespace (and not attached):
>  [1] Rcpp_1.0.4.6
>  [2] compiler_4.0.2
>  [3] pillar_1.4.4
>  [4] nloptr_1.2.2.1
>  [5] tools_4.0.2
>  [6] digest_0.6.25
>  [7] boot_1.3-25
>  [8] statmod_1.4.34
>  [9] lifecycle_0.2.0
> [10] tibble_3.0.1
> [11] nlme_3.1-148
> [12] gtable_0.3.0
> [13] lattice_0.20-41
> [14] pkgconfig_2.0.3
> [15] rlang_0.4.7
> [16] cli_2.0.2
> [17] rstudioapi_0.11
> [18] haven_2.3.1
> [19] withr_2.2.0
> [20] hms_0.5.3
> [21] generics_0.0.2
> [22] vctrs_0.3.1
> [23] fs_1.4.1
> [24] grid_4.0.2
> [25] tidyselect_1.1.0
> [26] glue_1.4.1
> [27] R6_2.4.1
> [28] fansi_0.4.1
> [29] minqa_1.2.4
> [30] farver_2.0.3
> [31] purrr_0.3.4
> [32] magrittr_1.5
> [33] scales_1.1.1
> [34] ellipsis_0.3.1
> [35] MASS_7.3-51.6
> [36] splines_4.0.2
> [37] insight_0.11.0
> [38] assertthat_0.2.1
> [39] colorspace_1.4-1
> [40] numDeriv_2016.8-1.1
> [41] labeling_0.3
> [42] utf8_1.1.4
> [43] munsell_0.5.0
> [44] crayon_1.3.4
>
>
>
>
> Sincerely,
>
>
>
> Jad Moawad
>
>
> PhD candidate and teaching assistant
> University of Lausanne  - NCCR Lives
> Institut des Sciences Sociales
> B timent Geopolis - 5621
> 1015 Lausanne
> Switzerland
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From j|@ver|@@|mo @end|ng |rom gm@||@com  Mon Dec 14 17:22:09 2020
From: j|@ver|@@|mo @end|ng |rom gm@||@com (=?ISO-8859-1?Q?Jo=E3o_Ver=EDssimo?=)
Date: Mon, 14 Dec 2020 16:22:09 +0000
Subject: [R-sig-ME] Question regarding large data.frame in LMER?
In-Reply-To: <1ed013a1ff97498fbc24e73d27ec4ba0@unil.ch>
References: <bbb6420ece704ba795b95f7a446c5b53@unil.ch>
 <76a26ccefdb54623a345e5a48c01c482@cambiumassessment.com>
 , <4b20de81a4324407b523c38f5ce68fb2@hum.leidenuniv.nl>
 <1ed013a1ff97498fbc24e73d27ec4ba0@unil.ch>
Message-ID: <9933c11d8ac39740252039c7cdbfb31adcf613c2.camel@gmail.com>

My comment about using poly(Age, 2) instead of I(Age^2) was a
suggestion for trying orthogonal polynomials specifically (i.e., not
raw=T but the default which is raw=F).

The reason is that Age and Age^2 will be very highly correlated,
whereas the linear and non-linear part of poly(Age, 2) are not
correlated.

Can't say if it'll help with your issue, though.

On Mon, 2020-12-14 at 16:00 +0000, Jad Moawad wrote:
> Thanks a lot everyone for all the suggestions you have provided, I
> really appreciate it. I have some replies over some comments and will
> write what have worked so far.
> 
> 
> 
> 1)    If understood well the comment regarding the duplicates, there
> was already no id that has the same number twice across different
> countries and years.
> 
> 2)    I switched the data.frame from tibble to as.dataframe.
> 
> 3)    I use now: poly(agecent, degree=2, raw=T) instead of I(age^2).
> 
> 4)    I tried centering, scaling and/or standardizing my variables
> but this have not solved the issue.
> 
> 5)    Regarding the question about how many country_years level I
> have. I have observations (1,150,110)  that are nested in *both*
> individuals (472,604) and country-years (180). In other words, they
> are cross-classified. In turn, individuals and country-years are
> *both* nested in countries (30). So the data structure is like a
> diamond, with a point (observatio


From j@d@mo@w@d @end|ng |rom un||@ch  Mon Dec 14 17:38:29 2020
From: j@d@mo@w@d @end|ng |rom un||@ch (Jad Moawad)
Date: Mon, 14 Dec 2020 16:38:29 +0000
Subject: [R-sig-ME] Question regarding large data.frame in LMER?
In-Reply-To: <CAO7JsnQzCYt11tZsTyV=w6E=6nUCrYi_qh-N6kvofESSGQAoAg@mail.gmail.com>
References: <bbb6420ece704ba795b95f7a446c5b53@unil.ch>
 <76a26ccefdb54623a345e5a48c01c482@cambiumassessment.com>
 <9688_1607683706_0QL600JKI8OPJL00_4b20de81a4324407b523c38f5ce68fb2@hum.leidenuniv.nl>,
 <CAO7JsnQzCYt11tZsTyV=w6E=6nUCrYi_qh-N6kvofESSGQAoAg@mail.gmail.com>
Message-ID: <433e49985c684454827f0ac493198d75@unil.ch>

Sorry, I did not know that i had to keep poly(Age, 2) as default. Thank you for clarifying, I will try it again.


The number of levels in the id variable is 567058. People are supposedly followed for 4 years, but of course there is some attrition along the way.


Yes please, i would like to try with the package of Julia. After all, i am using now the second-best option in terms of design. However, if i can go back to the original, it would be better to answer my research question.

________________________________
De : Douglas Bates <bates at stat.wisc.edu>
Envoy? : lundi 14 d?cembre 2020 17:09:15
? : Voeten, C.C.
Cc : Harold Doran; Jad Moawad; r-sig-mixed-models at r-project.org
Objet : Re: [R-sig-ME] Question regarding large data.frame in LMER?

Sorry for coming to this discussion late.  I notice that in the glimpse of the data set the first few values of id occur in pairs.  If you convert id to a factor how many levels does it have?

The implementation of mixed-effects models in the MixedModels (https://github.com/JuliaStats/MixedModels.jl) package for Julia is better suited to dealing with large numbers of observations than is the one in lme4.  It uses a more compact numerical representation of the model during the iterations to optimize the profiled log-likelihood.  Some of this is described in https://nextjournal.com/dmbates/complexity-in-fitting-linear-mixed-models  The important point is that evaluation of the profiled log-likelihood for new parameter values does not require working with matrices whose size depends on n, the number of observations.  All matrices are of sizes determined by the number of random effects and the number of fixed-effects parameters.  Of course, if each id only occurs twice then the number of random effects is already on the order of the number of observations so this will not be an advantage.

If you are interested in trying the Julia package we can help with that.

If anyone wants to try to implement the MixedModels approach in R I can advise you how to do it but I really don't have the energy to do the R/C++ two-language dance any more.

On Fri, Dec 11, 2020 at 4:48 AM Voeten, C.C. <c.c.voeten at hum.leidenuniv.nl<mailto:c.c.voeten at hum.leidenuniv.nl>> wrote:
Another option could be to try fitting your model using mgcv::bam, which is optimized for 'big' datasets. The function is primarily intended for GAMMs, but an LMM is just a specific type of GAMM, so this is no problem. You could use buildmer::re2mgcv to convert your lme4 random-effects specification (i.e. your formula using | terms) to the equivalent mgcv specification (using s() terms).

However, note that the bam model will not be completely equivalent to the lme4 model, in that the bam model will not model the correlations between the random effects. If those are important to you, then please disregard my suggestion!

Cesko

-----Original Message-----
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org<mailto:r-sig-mixed-models-bounces at r-project.org>> On Behalf Of Harold Doran
Sent: Friday, December 11, 2020 11:38 AM
To: Jad Moawad <jad.moawad at unil.ch<mailto:jad.moawad at unil.ch>>; r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] Question regarding large data.frame in LMER?

Assuming that you're sampling from your complete data set in a way that represents the complete data, one strategy might also be to use starting values from prior converged models and incrementally increase the size of the data.

For example,

1) run model with 10% of data and get parameter estimates
2) use the param estimates from (1) as starting values and now increase size of data to 40%
3) repeat

The strategy doesn't help/solve with the p.d. issue, but it does improve the potential for reaching the top of the hill with a big data file faster.

It's an incremental EM idea that reduces the amount of work lmer() (or any iterative maximization procedure) would need to do with a very large file. In other words, why start all over again with a very big file when we can start somewhere better and let the algorithm start closer to the top of the hill, so to speak.

Hope it helps.
Harold



-----Original Message-----
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org<mailto:r-sig-mixed-models-bounces at r-project.org>> On Behalf Of Jad Moawad
Sent: Thursday, December 10, 2020 7:12 AM
To: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
Subject: [R-sig-ME] Question regarding large data.frame in LMER?

External email alert: Be wary of links & attachments.


I am working with a large data.frame that contains around 1.4 million observations. Initially when i was running my models, i was working on a sub-sample (10% of my full-sample). This is because running one model can take a lot of time using the original data. Once i was sure that all variables are well harmonized and all regressions were running fine, i ran my models using the full sample. However, the regression did not converge and i received the following two errors from two different models:

Error in fun(xaa, ...) : Downdated VtV is not positive definite

Error in fun(xss, ...) : Downdated VtV is not positive definite

I use the lmer function to fit my model and i include a random slopes at the country and country_year level. Below you find the code that i use.

Model1 <- lmer(health~ class + age + I(age^2)  + class*macro_unemployment +
               (class + age + I(age^2)|country) +
               (class+ age + I(age^2) |country_year) +
               (1|id), data=df)

Model2 <- lmer(health~ education + age + I(age^2)  + education*macro_unemployment+
               (education + age + I(age^2)|country) +
               (education + age + I(age^2) |country_year) +
               (1|id), data=df)


Could someone help me please with solving this issue?

Below you find a glimpse (str) of my data and my sessionInfo():

tibble [1,370,264   8] (S3: grouped_df/tbl_df/tbl/data.frame)
 $ health            : num [1:1370264] 100 100 50 100 0 75 75 100 100 50 ...
 $ class             : Factor w/ 3 levels "Upper-middle class",..: 3 3 NA 3 3 3 3 1 1 3 ...
 $ education         : Factor w/ 3 levels "low","mid","high": 1 1 1 1 1 1 2 3 3 1 ...
 $ age               : num [1:1370264] 24 25 24 25 42 43 34 34 35 58 ...
 $ macro_unemployment: num [1:1370264] 5.24 4.86 5.24 4.86 5.24 ...
 $ id                : int [1:1370264] 2 2 3 3 4 4 6 7 7 8 ...
 $ country_year      : int [1:1370264] 1 2 1 2 1 2 1 1 2 1 ...
 $ country           : Factor w/ 30 levels "Austria","Belgium",..: 1 1 1 1 1 1 1 1 1 1 ...
 - attr(*, "groups")= tibble [27   2] (S3: tbl_df/tbl/data.frame)
  ..$ country: Factor w/ 30 levels "Austria","Belgium",..: 1 2 3 6 7 8 9 10 11 12 ...
  ..$ .rows  : list<int> [1:27]
  .. ..$ : int [1:47204] 1 2 3 4 5 6 7 8 9 10 ...
  .. ..$ : int [1:41361] 47205 47206 47207 47208 47209 47210 47211 47212 47213 47214 ...
  .. ..$ : int [1:42407] 88566 88567 88568 88569 88570 88571 88572 88573 88574 88575 ...
  .. ..$ : int [1:48253] 130973 130974 130975 130976 130977 130978 130979 130980 130981 130982 ...
  .. ..$ : int [1:31917] 179226 179227 179228 179229 179230 179231 179232 179233 179234 179235 ...
  .. ..$ : int [1:44047] 211143 211144 211145 211146 211147 211148 211149 211150 211151 211152 ...
  .. ..$ : int [1:62087] 255190 255191 255192 255193 255194 255195 255196 255197 255198 255199 ...
  .. ..$ : int [1:94309] 317277 317278 317279 317280 317281 317282 317283 317284 317285 317286 ...
  .. ..$ : int [1:37246] 411586 411587 411588 411589 411590 411591 411592 411593 411594 411595 ...
  .. ..$ : int [1:77253] 448832 448833 448834 448835 448836 448837 448838 448839 448840 448841 ...
  .. ..$ : int [1:16823] 526085 526086 526087 526088 526089 526090 526091 526092 526093 526094 ...
  .. ..$ : int [1:24687] 542908 542909 542910 542911 542912 542913 542914 542915 542916 542917 ...
  .. ..$ : int [1:116263] 567595 567596 567597 567598 567599 567600 567601 567602 567603 567604 ...
  .. ..$ : int [1:43218] 683858 683859 683860 683861 683862 683863 683864 683865 683866 683867 ...
  .. ..$ : int [1:28709] 727076 727077 727078 727079 727080 727081 727082 727083 727084 727085 ...
  .. ..$ : int [1:27583] 755785 755786 755787 755788 755789 755790 755791 755792 755793 755794 ...
  .. ..$ : int [1:77960] 783368 783369 783370 783371 783372 783373 783374 783375 783376 783377 ...
  .. ..$ : int [1:36922] 861328 861329 861330 861331 861332 861333 861334 861335 861336 861337 ...
  .. ..$ : int [1:93194] 898250 898251 898252 898253 898254 898255 898256 898257 898258 898259 ...
  .. ..$ : int [1:9004] 991444 991445 991446 991447 991448 991449 991450 991451 991452 991453 ...
  .. ..$ : int [1:40074] 1000448 1000449 1000450 1000451 1000452 1000453 1000454 1000455 1000456 1000457 ...
  .. ..$ : int [1:29342] 1040522 1040523 1040524 1040525 1040526 1040527 1040528 1040529 1040530 1040531 ...
  .. ..$ : int [1:85124] 1069864 1069865 1069866 1069867 1069868 1069869 1069870 1069871 1069872 1069873 ...
  .. ..$ : int [1:92350] 1154988 1154989 1154990 1154991 1154992 1154993 1154994 1154995 1154996 1154997 ...
  .. ..$ : int [1:50188] 1247338 1247339 1247340 1247341 1247342 1247343 1247344 1247345 1247346 1247347 ...
  .. ..$ : int [1:7598] 1297526 1297527 1297528 1297529 1297530 1297531 1297532 1297533 1297534 1297535 ...
  .. ..$ : int [1:65141] 1305124 1305125 1305126 1305127 1305128 1305129 1305130 1305131 1305132 1305133 ...
  .. ..@ ptype: int(0)
  ..- attr(*, ".drop")= logi TRUE
>


Session Info:

R version 4.0.2 (2020-06-22)
Platform: x86_64-apple-darwin17.0 (64-bit) Running under: macOS Catalina 10.15.6

Matrix products: default
BLAS:   /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libBLAS.dylib
LAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices
[4] utils     datasets  methods
[7] base

other attached packages:
 [1] sessioninfo_1.1.1
 [2] sjlabelled_1.1.5
 [3] varhandle_2.0.5
 [4] labelled_2.7.0
 [5] dplyr_1.0.0
 [6] ggplot2_3.3.2
 [7] forcats_0.5.0
 [8] reprex_0.3.0
 [9] lmerTest_3.1-3
[10] lme4_1.1-25
[11] Matrix_1.2-18

loaded via a namespace (and not attached):
 [1] Rcpp_1.0.4.6
 [2] compiler_4.0.2
 [3] pillar_1.4.4
 [4] nloptr_1.2.2.1
 [5] tools_4.0.2
 [6] digest_0.6.25
 [7] boot_1.3-25
 [8] statmod_1.4.34
 [9] lifecycle_0.2.0
[10] tibble_3.0.1
[11] nlme_3.1-148
[12] gtable_0.3.0
[13] lattice_0.20-41
[14] pkgconfig_2.0.3
[15] rlang_0.4.7
[16] cli_2.0.2
[17] rstudioapi_0.11
[18] haven_2.3.1
[19] withr_2.2.0
[20] hms_0.5.3
[21] generics_0.0.2
[22] vctrs_0.3.1
[23] fs_1.4.1
[24] grid_4.0.2
[25] tidyselect_1.1.0
[26] glue_1.4.1
[27] R6_2.4.1
[28] fansi_0.4.1
[29] minqa_1.2.4
[30] farver_2.0.3
[31] purrr_0.3.4
[32] magrittr_1.5
[33] scales_1.1.1
[34] ellipsis_0.3.1
[35] MASS_7.3-51.6
[36] splines_4.0.2
[37] insight_0.11.0
[38] assertthat_0.2.1
[39] colorspace_1.4-1
[40] numDeriv_2016.8-1.1
[41] labeling_0.3
[42] utf8_1.1.4
[43] munsell_0.5.0
[44] crayon_1.3.4




Sincerely,



Jad Moawad


PhD candidate and teaching assistant
University of Lausanne  - NCCR Lives
Institut des Sciences Sociales
B timent Geopolis - 5621
1015 Lausanne
Switzerland


        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From h@ro|d@dor@n @end|ng |rom c@mb|um@@@e@@ment@com  Tue Dec 15 16:14:44 2020
From: h@ro|d@dor@n @end|ng |rom c@mb|um@@@e@@ment@com (Harold Doran)
Date: Tue, 15 Dec 2020 15:14:44 +0000
Subject: [R-sig-ME] Question regarding large data.frame in LMER?
In-Reply-To: <433e49985c684454827f0ac493198d75@unil.ch>
References: <bbb6420ece704ba795b95f7a446c5b53@unil.ch>
 <76a26ccefdb54623a345e5a48c01c482@cambiumassessment.com>
 <9688_1607683706_0QL600JKI8OPJL00_4b20de81a4324407b523c38f5ce68fb2@hum.leidenuniv.nl>,
 <CAO7JsnQzCYt11tZsTyV=w6E=6nUCrYi_qh-N6kvofESSGQAoAg@mail.gmail.com>
 <433e49985c684454827f0ac493198d75@unil.ch>
Message-ID: <d9545047222c44bf86bc6509856d934d@cambiumassessment.com>

@doug, it seems like the "speed" conversation for mixed models have two considerations: 1) how can we rewrite the log-likelihood to improve optimization and 2) what computational things can be done to improve the speed.

As an example, your note below is more along the lines of (1) whereas sparse matrices are more along the lines of (2).

One computational topic that I know is harder with LMMs is parallel processing. Almost all software I have written in the past 5 years uses parallel processing-but my tasks are based on the concept of being "embarrassingly parallel", which makes the split, apply, combine problem quite easy.

Parallel processing with larger matrix operations is more complex. However, I have implemented lmer models using Microsoft's R implementation and timed it against R and found it was quite a bit faster. Same data, same computer, same model, same output (and same results). I *think* it's more than just a different BLAS being used by MS, but perhaps something fundamentally different in its workhorse for some matrix ops. Others correct me if I'm wrong, but I'm curious on your thoughts Doug as whether this is an avenue mixed model thinkers/developers should consider (being agnostic for a moment about which software is used).



From: Jad Moawad <jad.moawad at unil.ch>
Sent: Monday, December 14, 2020 11:38 AM
To: Douglas Bates <bates at stat.wisc.edu>; Voeten, C.C. <c.c.voeten at hum.leidenuniv.nl>
Cc: Harold Doran <harold.doran at cambiumassessment.com>; r-sig-mixed-models at r-project.org
Subject: RE: [R-sig-ME] Question regarding large data.frame in LMER?


Sorry, I did not know that i had to keep poly(Age, 2) as default. Thank you for clarifying, I will try it again.



The number of levels in the id variable is 567058. People are supposedly followed for 4 years, but of course there is some attrition along the way.



Yes please, i would like to try with the package of Julia. After all, i am using now the second-best option in terms of design. However, if i can go back to the original, it would be better to answer my research question.

________________________________
De : Douglas Bates <bates at stat.wisc.edu<mailto:bates at stat.wisc.edu>>
Envoy? : lundi 14 d?cembre 2020 17:09:15
? : Voeten, C.C.
Cc : Harold Doran; Jad Moawad; r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
Objet : Re: [R-sig-ME] Question regarding large data.frame in LMER?

Sorry for coming to this discussion late.  I notice that in the glimpse of the data set the first few values of id occur in pairs.  If you convert id to a factor how many levels does it have?

The implementation of mixed-effects models in the MixedModels (https://github.com/JuliaStats/MixedModels.jl) package for Julia is better suited to dealing with large numbers of observations than is the one in lme4.  It uses a more compact numerical representation of the model during the iterations to optimize the profiled log-likelihood.  Some of this is described in https://nextjournal.com/dmbates/complexity-in-fitting-linear-mixed-models  The important point is that evaluation of the profiled log-likelihood for new parameter values does not require working with matrices whose size depends on n, the number of observations.  All matrices are of sizes determined by the number of random effects and the number of fixed-effects parameters.  Of course, if each id only occurs twice then the number of random effects is already on the order of the number of observations so this will not be an advantage.

If you are interested in trying the Julia package we can help with that.

If anyone wants to try to implement the MixedModels approach in R I can advise you how to do it but I really don't have the energy to do the R/C++ two-language dance any more.

On Fri, Dec 11, 2020 at 4:48 AM Voeten, C.C. <c.c.voeten at hum.leidenuniv.nl<mailto:c.c.voeten at hum.leidenuniv.nl>> wrote:
Another option could be to try fitting your model using mgcv::bam, which is optimized for 'big' datasets. The function is primarily intended for GAMMs, but an LMM is just a specific type of GAMM, so this is no problem. You could use buildmer::re2mgcv to convert your lme4 random-effects specification (i.e. your formula using | terms) to the equivalent mgcv specification (using s() terms).

However, note that the bam model will not be completely equivalent to the lme4 model, in that the bam model will not model the correlations between the random effects. If those are important to you, then please disregard my suggestion!

Cesko

-----Original Message-----
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org<mailto:r-sig-mixed-models-bounces at r-project.org>> On Behalf Of Harold Doran
Sent: Friday, December 11, 2020 11:38 AM
To: Jad Moawad <jad.moawad at unil.ch<mailto:jad.moawad at unil.ch>>; r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] Question regarding large data.frame in LMER?

Assuming that you're sampling from your complete data set in a way that represents the complete data, one strategy might also be to use starting values from prior converged models and incrementally increase the size of the data.

For example,

1) run model with 10% of data and get parameter estimates
2) use the param estimates from (1) as starting values and now increase size of data to 40%
3) repeat

The strategy doesn't help/solve with the p.d. issue, but it does improve the potential for reaching the top of the hill with a big data file faster.

It's an incremental EM idea that reduces the amount of work lmer() (or any iterative maximization procedure) would need to do with a very large file. In other words, why start all over again with a very big file when we can start somewhere better and let the algorithm start closer to the top of the hill, so to speak.

Hope it helps.
Harold



-----Original Message-----
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org<mailto:r-sig-mixed-models-bounces at r-project.org>> On Behalf Of Jad Moawad
Sent: Thursday, December 10, 2020 7:12 AM
To: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
Subject: [R-sig-ME] Question regarding large data.frame in LMER?

External email alert: Be wary of links & attachments.


I am working with a large data.frame that contains around 1.4 million observations. Initially when i was running my models, i was working on a sub-sample (10% of my full-sample). This is because running one model can take a lot of time using the original data. Once i was sure that all variables are well harmonized and all regressions were running fine, i ran my models using the full sample. However, the regression did not converge and i received the following two errors from two different models:

Error in fun(xaa, ...) : Downdated VtV is not positive definite

Error in fun(xss, ...) : Downdated VtV is not positive definite

I use the lmer function to fit my model and i include a random slopes at the country and country_year level. Below you find the code that i use.

Model1 <- lmer(health~ class + age + I(age^2)  + class*macro_unemployment +
               (class + age + I(age^2)|country) +
               (class+ age + I(age^2) |country_year) +
               (1|id), data=df)

Model2 <- lmer(health~ education + age + I(age^2)  + education*macro_unemployment+
               (education + age + I(age^2)|country) +
               (education + age + I(age^2) |country_year) +
               (1|id), data=df)


Could someone help me please with solving this issue?

Below you find a glimpse (str) of my data and my sessionInfo():

tibble [1,370,264   8] (S3: grouped_df/tbl_df/tbl/data.frame)
 $ health            : num [1:1370264] 100 100 50 100 0 75 75 100 100 50 ...
 $ class             : Factor w/ 3 levels "Upper-middle class",..: 3 3 NA 3 3 3 3 1 1 3 ...
 $ education         : Factor w/ 3 levels "low","mid","high": 1 1 1 1 1 1 2 3 3 1 ...
 $ age               : num [1:1370264] 24 25 24 25 42 43 34 34 35 58 ...
 $ macro_unemployment: num [1:1370264] 5.24 4.86 5.24 4.86 5.24 ...
 $ id                : int [1:1370264] 2 2 3 3 4 4 6 7 7 8 ...
 $ country_year      : int [1:1370264] 1 2 1 2 1 2 1 1 2 1 ...
 $ country           : Factor w/ 30 levels "Austria","Belgium",..: 1 1 1 1 1 1 1 1 1 1 ...
 - attr(*, "groups")= tibble [27   2] (S3: tbl_df/tbl/data.frame)
  ..$ country: Factor w/ 30 levels "Austria","Belgium",..: 1 2 3 6 7 8 9 10 11 12 ...
  ..$ .rows  : list<int> [1:27]
  .. ..$ : int [1:47204] 1 2 3 4 5 6 7 8 9 10 ...
  .. ..$ : int [1:41361] 47205 47206 47207 47208 47209 47210 47211 47212 47213 47214 ...
  .. ..$ : int [1:42407] 88566 88567 88568 88569 88570 88571 88572 88573 88574 88575 ...
  .. ..$ : int [1:48253] 130973 130974 130975 130976 130977 130978 130979 130980 130981 130982 ...
  .. ..$ : int [1:31917] 179226 179227 179228 179229 179230 179231 179232 179233 179234 179235 ...
  .. ..$ : int [1:44047] 211143 211144 211145 211146 211147 211148 211149 211150 211151 211152 ...
  .. ..$ : int [1:62087] 255190 255191 255192 255193 255194 255195 255196 255197 255198 255199 ...
  .. ..$ : int [1:94309] 317277 317278 317279 317280 317281 317282 317283 317284 317285 317286 ...
  .. ..$ : int [1:37246] 411586 411587 411588 411589 411590 411591 411592 411593 411594 411595 ...
  .. ..$ : int [1:77253] 448832 448833 448834 448835 448836 448837 448838 448839 448840 448841 ...
  .. ..$ : int [1:16823] 526085 526086 526087 526088 526089 526090 526091 526092 526093 526094 ...
  .. ..$ : int [1:24687] 542908 542909 542910 542911 542912 542913 542914 542915 542916 542917 ...
  .. ..$ : int [1:116263] 567595 567596 567597 567598 567599 567600 567601 567602 567603 567604 ...
  .. ..$ : int [1:43218] 683858 683859 683860 683861 683862 683863 683864 683865 683866 683867 ...
  .. ..$ : int [1:28709] 727076 727077 727078 727079 727080 727081 727082 727083 727084 727085 ...
  .. ..$ : int [1:27583] 755785 755786 755787 755788 755789 755790 755791 755792 755793 755794 ...
  .. ..$ : int [1:77960] 783368 783369 783370 783371 783372 783373 783374 783375 783376 783377 ...
  .. ..$ : int [1:36922] 861328 861329 861330 861331 861332 861333 861334 861335 861336 861337 ...
  .. ..$ : int [1:93194] 898250 898251 898252 898253 898254 898255 898256 898257 898258 898259 ...
  .. ..$ : int [1:9004] 991444 991445 991446 991447 991448 991449 991450 991451 991452 991453 ...
  .. ..$ : int [1:40074] 1000448 1000449 1000450 1000451 1000452 1000453 1000454 1000455 1000456 1000457 ...
  .. ..$ : int [1:29342] 1040522 1040523 1040524 1040525 1040526 1040527 1040528 1040529 1040530 1040531 ...
  .. ..$ : int [1:85124] 1069864 1069865 1069866 1069867 1069868 1069869 1069870 1069871 1069872 1069873 ...
  .. ..$ : int [1:92350] 1154988 1154989 1154990 1154991 1154992 1154993 1154994 1154995 1154996 1154997 ...
  .. ..$ : int [1:50188] 1247338 1247339 1247340 1247341 1247342 1247343 1247344 1247345 1247346 1247347 ...
  .. ..$ : int [1:7598] 1297526 1297527 1297528 1297529 1297530 1297531 1297532 1297533 1297534 1297535 ...
  .. ..$ : int [1:65141] 1305124 1305125 1305126 1305127 1305128 1305129 1305130 1305131 1305132 1305133 ...
  .. ..@ ptype: int(0)
  ..- attr(*, ".drop")= logi TRUE
>


Session Info:

R version 4.0.2 (2020-06-22)
Platform: x86_64-apple-darwin17.0 (64-bit) Running under: macOS Catalina 10.15.6

Matrix products: default
BLAS:   /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libBLAS.dylib
LAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices
[4] utils     datasets  methods
[7] base

other attached packages:
 [1] sessioninfo_1.1.1
 [2] sjlabelled_1.1.5
 [3] varhandle_2.0.5
 [4] labelled_2.7.0
 [5] dplyr_1.0.0
 [6] ggplot2_3.3.2
 [7] forcats_0.5.0
 [8] reprex_0.3.0
 [9] lmerTest_3.1-3
[10] lme4_1.1-25
[11] Matrix_1.2-18

loaded via a namespace (and not attached):
 [1] Rcpp_1.0.4.6
 [2] compiler_4.0.2
 [3] pillar_1.4.4
 [4] nloptr_1.2.2.1
 [5] tools_4.0.2
 [6] digest_0.6.25
 [7] boot_1.3-25
 [8] statmod_1.4.34
 [9] lifecycle_0.2.0
[10] tibble_3.0.1
[11] nlme_3.1-148
[12] gtable_0.3.0
[13] lattice_0.20-41
[14] pkgconfig_2.0.3
[15] rlang_0.4.7
[16] cli_2.0.2
[17] rstudioapi_0.11
[18] haven_2.3.1
[19] withr_2.2.0
[20] hms_0.5.3
[21] generics_0.0.2
[22] vctrs_0.3.1
[23] fs_1.4.1
[24] grid_4.0.2
[25] tidyselect_1.1.0
[26] glue_1.4.1
[27] R6_2.4.1
[28] fansi_0.4.1
[29] minqa_1.2.4
[30] farver_2.0.3
[31] purrr_0.3.4
[32] magrittr_1.5
[33] scales_1.1.1
[34] ellipsis_0.3.1
[35] MASS_7.3-51.6
[36] splines_4.0.2
[37] insight_0.11.0
[38] assertthat_0.2.1
[39] colorspace_1.4-1
[40] numDeriv_2016.8-1.1
[41] labeling_0.3
[42] utf8_1.1.4
[43] munsell_0.5.0
[44] crayon_1.3.4




Sincerely,



Jad Moawad


PhD candidate and teaching assistant
University of Lausanne  - NCCR Lives
Institut des Sciences Sociales
B timent Geopolis - 5621
1015 Lausanne
Switzerland


        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From me @end|ng |rom ph||||p@|d@y@com  Tue Dec 15 17:12:04 2020
From: me @end|ng |rom ph||||p@|d@y@com (Phillip Alday)
Date: Tue, 15 Dec 2020 17:12:04 +0100
Subject: [R-sig-ME] Question regarding large data.frame in LMER?
In-Reply-To: <d9545047222c44bf86bc6509856d934d@cambiumassessment.com>
References: <bbb6420ece704ba795b95f7a446c5b53@unil.ch>
 <76a26ccefdb54623a345e5a48c01c482@cambiumassessment.com>
 <9688_1607683706_0QL600JKI8OPJL00_4b20de81a4324407b523c38f5ce68fb2@hum.leidenuniv.nl>
 <CAO7JsnQzCYt11tZsTyV=w6E=6nUCrYi_qh-N6kvofESSGQAoAg@mail.gmail.com>
 <433e49985c684454827f0ac493198d75@unil.ch>
 <d9545047222c44bf86bc6509856d934d@cambiumassessment.com>
Message-ID: <54f42719-99e8-bc6f-24aa-abd8316d2989@phillipalday.com>

Hi everybody,

since I'm the one who wrote the limited parallelized code in
MixedModels.jl, I'll comment a little bit on that as well as a few
general points.

1. An efficient profiled loglikelihood is important to both lme4 and
MixedModels.jl. Critically, both manage to rewrite the problem as a
penalized least squares problem instead of the more typical generalized
least squares formulation used by e.g. nlme.  This has advantages both
in computation and representation (next point). For that, see the lme4
paper or the NextJournal article Doug linked or .... when I actually can
block out some time from the day job and finish my small part of it, the
forthcoming MixedModels.jl paper. (Sorry, Doug! I haven't forgotten
about it...)

2. Sparse matrices are important to both lme4 and MixedModels.jl not
just because of the direct issues with a reduced memory footprint. It
turns out that memory allocation itself is really slow, even when you
have enough memory, so if you can do sparse operations in place (rather
than allocating and copying), then you can make things really fast. Joel
on Software discusses this issue in one his posts
(https://www.joelonsoftware.com/2001/12/11/back-to-basics/). lme4 does
this to some extent, but requires bouncing back and forth between R and
C++ to really it do it well, but that introduces its own complexities.

So that brings us to where Julia shines compared to R: you do everything
in Julia and Julia's memory model is such that it's easier to do things
in place. So in Julia we can write prototype very specialized methods
for particular types of sparsity and do all of those sparse operations
in place, without bringing in another language. In other words, it's
easier to try new stuff out, which is how some of the innovations in
MixedModels.jl arose compared to lme4 -- Doug tried prototyped a
particular specialized quickly because it was easy to do so and it
proved worthwhile. (There were also a few happy accidents in deriving a
somewhat more efficient profiled log-likelihood, both in computation and
in storage, but back porting those changes to lme4 is somewhat more
difficult due to the two-language problem.)

@Doug: feel free to correct any infelicities or oversimplifications that
I probably introduced.

On the parallelism front: there are may different levels to be parallel
at. The easiest and most obvious one is at the level of the basic matrix
operations, i.e. those provided by the BLAS (basic linear algebra
subroutines). Microsoft/Revolution's R release actually packages the
Intel MKL, a very specialized and fast BLAS, instead of the default
system BLAS that R uses on most platforms. (On MacOS, the system BLAS is
actually very good, at least on Intel chips). There are decades of
research into making BLAS work fast, including its parallelization. I
frequently see all cores being saturated when doing BLAS calls from
Julia because the OpenBLAS variant Julia links to is multi-threaded by
default.  On Linux, you change the BLAS that R uses to be something more
tuned to your system, if you want; here's my somewhat outdated blogpost
on it: https://phillipalday.com/blog/2013/05/31/Speed-up-R-(on-Linux)/

In Julia, I've tried to parallelize some loops in the evaluation of the
log likelihood but ... it generally didn't actually help much. This
suggests that those weren't the bottleneck and/or parallelization
introduces a different bottleneck (more on that in a minute). lme4
currently has an open issue on using an optimizer that can itself be
parallelized (i.e the thing that takes the log likelihood function and
uses that to find out the parameters values corresponding to the maximum
likelihood): https://github.com/lme4/lme4/issues/508 but progress on
that has kinda stalled. It doesn't seem to offer a huge boost; parallel
programming is hard; etc. Both lme4 and MixedModels.jl are written in
such a way that it is theoretically possible to use a parallelized
optimizer, but it just doesn't seem to be worth it.

One thing that should be worth parallelizing though is the parametric
bootstrap because each bootstrap replication is, per definition,
independent of the others (it's an "embarrassingly parallel" problem). I
wrote this for MixedModels.jl -- if you want this to be really nice,
then there is some subtlety in dealing with the random number generator
and not making superfluous memory allocations (see above), but it's
relatively straightforward as far as parallel programming goes. When I
first implemented it, we noticed a huge speed boost. Then Doug made some
algorithmic improvements for the single-threaded case and a new Julia
version came out that was linked to a new BLAS version and the boost
went away, sometimes running even slower. The problem? The new BLAS
version was very multithreaded and so it was already taking full
advantage of all the cores on my system for a single model fit, so when
I added another layer of parallelism on top of that, I suddenly had more
parallel operations than cores and swapping between operations (context
switching) is not free. So even then it didn't help. I tried increasing
the granularity of the parallelism ... and that helped a bit, but added
a huge amount of code complexity, so I ultimately discarded that
attempt. (I think lme4 can still take better advantage of this in its
bootstrap because the default R BLAS isn't quite as good as the current
Julia BLAS for multithreading.) If you're curious and bored, I talked
about this as part of JuliaCon this year:
https://www.youtube.com/watch?v=qhfQKIDR7Ms

Of course, this is all parallelism at the level of multiple local
CPUs/cores -- with things like clusters with multiple nodes (which
require some coordination overhead) or  GPUs (which don't always place
nice with sparse matrices and introduce their own coordination
overhead), you can introduce some more parallelism, so there may still
be some gains to be made in this area. Also, if you have a system with
just an insane number of cores (> 64), then you probably have more cores
than your BLAS can take advantage of and then layering local threaded
bootstrapping on top of that may still help. (Anybody with a
Threadripper CPU want to run some benchmarks for me?)

There's also Amdah's Law (https://en.wikipedia.org/wiki/Amdahl's_law),
which puts a hard limit to how much of a boost parallelism can give you.
(Though for things like bootstrapping, if you had zero coordination
cost, then you do get linear scaling until the number of cluster nodes
matches the number of bootstrap replicates...)

In other words, parallelism is hard and not quite as helpful as you'd
hope. (And I haven't even talked about SIMD-type of parallelism, which
is a bit closer to GPU-style parallelism but on a smaller scale and part
of the floating-point unit of most modern CPUs.)

This doesn't mean there are no more performance enhancements to be made.
Quite the contrary -- if we can continue improving and specializing our
storage and computation methods, then we can often reduce the total
number of (multithreaded) BLAS operations necessary, which is far more
effective than just making those operations each individually faster.
And these advancements are exactly (1) and (2) above and in Harold's
message.

As a contrast, Stan has seen some recent improvements in speed by using
more types of parallelism within chains, but these are related to (A)
the types of BLAS-level parallelism I mentioned above and (B) taking
advantage of some nice associativity tricks in summing up the individual
terms of log-likelihoods. These types of algorithm advances are largely
already present in MixedModels.jl, just in very specialized form. (I
think the Stan team is doing some really cool work, but the pro  and con
of Stan or general frameworks like TMB is that they are general, so they
can't take advantage of some specializations very particular to a given
model class, like mixed models.)

Best,
Phillip

PS: I liked the question! This is not meant to be dismissive, but
instead to highlight how hard it all is. :)

On 15/12/20 4:14 pm, Harold Doran wrote:
> @doug, it seems like the "speed" conversation for mixed models have two considerations: 1) how can we rewrite the log-likelihood to improve optimization and 2) what computational things can be done to improve the speed.
> 
> As an example, your note below is more along the lines of (1) whereas sparse matrices are more along the lines of (2).
> 
> One computational topic that I know is harder with LMMs is parallel processing. Almost all software I have written in the past 5 years uses parallel processing-but my tasks are based on the concept of being "embarrassingly parallel", which makes the split, apply, combine problem quite easy.
> 
> Parallel processing with larger matrix operations is more complex. However, I have implemented lmer models using Microsoft's R implementation and timed it against R and found it was quite a bit faster. Same data, same computer, same model, same output (and same results). I *think* it's more than just a different BLAS being used by MS, but perhaps something fundamentally different in its workhorse for some matrix ops. Others correct me if I'm wrong, but I'm curious on your thoughts Doug as whether this is an avenue mixed model thinkers/developers should consider (being agnostic for a moment about which software is used).
> 
> 
> 
> From: Jad Moawad <jad.moawad at unil.ch>
> Sent: Monday, December 14, 2020 11:38 AM
> To: Douglas Bates <bates at stat.wisc.edu>; Voeten, C.C. <c.c.voeten at hum.leidenuniv.nl>
> Cc: Harold Doran <harold.doran at cambiumassessment.com>; r-sig-mixed-models at r-project.org
> Subject: RE: [R-sig-ME] Question regarding large data.frame in LMER?
> 
> 
> Sorry, I did not know that i had to keep poly(Age, 2) as default. Thank you for clarifying, I will try it again.
> 
> 
> 
> The number of levels in the id variable is 567058. People are supposedly followed for 4 years, but of course there is some attrition along the way.
> 
> 
> 
> Yes please, i would like to try with the package of Julia. After all, i am using now the second-best option in terms of design. However, if i can go back to the original, it would be better to answer my research question.
> 
> ________________________________
> De : Douglas Bates <bates at stat.wisc.edu<mailto:bates at stat.wisc.edu>>
> Envoy? : lundi 14 d?cembre 2020 17:09:15
> ? : Voeten, C.C.
> Cc : Harold Doran; Jad Moawad; r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
> Objet : Re: [R-sig-ME] Question regarding large data.frame in LMER?
> 
> Sorry for coming to this discussion late.  I notice that in the glimpse of the data set the first few values of id occur in pairs.  If you convert id to a factor how many levels does it have?
> 
> The implementation of mixed-effects models in the MixedModels (https://github.com/JuliaStats/MixedModels.jl) package for Julia is better suited to dealing with large numbers of observations than is the one in lme4.  It uses a more compact numerical representation of the model during the iterations to optimize the profiled log-likelihood.  Some of this is described in https://nextjournal.com/dmbates/complexity-in-fitting-linear-mixed-models  The important point is that evaluation of the profiled log-likelihood for new parameter values does not require working with matrices whose size depends on n, the number of observations.  All matrices are of sizes determined by the number of random effects and the number of fixed-effects parameters.  Of course, if each id only occurs twice then the number of random effects is already on the order of the number of observations so this will not be an advantage.
> 
> If you are interested in trying the Julia package we can help with that.
> 
> If anyone wants to try to implement the MixedModels approach in R I can advise you how to do it but I really don't have the energy to do the R/C++ two-language dance any more.
> 
> On Fri, Dec 11, 2020 at 4:48 AM Voeten, C.C. <c.c.voeten at hum.leidenuniv.nl<mailto:c.c.voeten at hum.leidenuniv.nl>> wrote:
> Another option could be to try fitting your model using mgcv::bam, which is optimized for 'big' datasets. The function is primarily intended for GAMMs, but an LMM is just a specific type of GAMM, so this is no problem. You could use buildmer::re2mgcv to convert your lme4 random-effects specification (i.e. your formula using | terms) to the equivalent mgcv specification (using s() terms).
> 
> However, note that the bam model will not be completely equivalent to the lme4 model, in that the bam model will not model the correlations between the random effects. If those are important to you, then please disregard my suggestion!
> 
> Cesko
> 
> -----Original Message-----
> From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org<mailto:r-sig-mixed-models-bounces at r-project.org>> On Behalf Of Harold Doran
> Sent: Friday, December 11, 2020 11:38 AM
> To: Jad Moawad <jad.moawad at unil.ch<mailto:jad.moawad at unil.ch>>; r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
> Subject: Re: [R-sig-ME] Question regarding large data.frame in LMER?
> 
> Assuming that you're sampling from your complete data set in a way that represents the complete data, one strategy might also be to use starting values from prior converged models and incrementally increase the size of the data.
> 
> For example,
> 
> 1) run model with 10% of data and get parameter estimates
> 2) use the param estimates from (1) as starting values and now increase size of data to 40%
> 3) repeat
> 
> The strategy doesn't help/solve with the p.d. issue, but it does improve the potential for reaching the top of the hill with a big data file faster.
> 
> It's an incremental EM idea that reduces the amount of work lmer() (or any iterative maximization procedure) would need to do with a very large file. In other words, why start all over again with a very big file when we can start somewhere better and let the algorithm start closer to the top of the hill, so to speak.
> 
> Hope it helps.
> Harold
> 
> 
> 
> -----Original Message-----
> From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org<mailto:r-sig-mixed-models-bounces at r-project.org>> On Behalf Of Jad Moawad
> Sent: Thursday, December 10, 2020 7:12 AM
> To: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
> Subject: [R-sig-ME] Question regarding large data.frame in LMER?
> 
> External email alert: Be wary of links & attachments.
> 
> 
> I am working with a large data.frame that contains around 1.4 million observations. Initially when i was running my models, i was working on a sub-sample (10% of my full-sample). This is because running one model can take a lot of time using the original data. Once i was sure that all variables are well harmonized and all regressions were running fine, i ran my models using the full sample. However, the regression did not converge and i received the following two errors from two different models:
> 
> Error in fun(xaa, ...) : Downdated VtV is not positive definite
> 
> Error in fun(xss, ...) : Downdated VtV is not positive definite
> 
> I use the lmer function to fit my model and i include a random slopes at the country and country_year level. Below you find the code that i use.
> 
> Model1 <- lmer(health~ class + age + I(age^2)  + class*macro_unemployment +
>                (class + age + I(age^2)|country) +
>                (class+ age + I(age^2) |country_year) +
>                (1|id), data=df)
> 
> Model2 <- lmer(health~ education + age + I(age^2)  + education*macro_unemployment+
>                (education + age + I(age^2)|country) +
>                (education + age + I(age^2) |country_year) +
>                (1|id), data=df)
> 
> 
> Could someone help me please with solving this issue?
> 
> Below you find a glimpse (str) of my data and my sessionInfo():
> 
> tibble [1,370,264   8] (S3: grouped_df/tbl_df/tbl/data.frame)
>  $ health            : num [1:1370264] 100 100 50 100 0 75 75 100 100 50 ...
>  $ class             : Factor w/ 3 levels "Upper-middle class",..: 3 3 NA 3 3 3 3 1 1 3 ...
>  $ education         : Factor w/ 3 levels "low","mid","high": 1 1 1 1 1 1 2 3 3 1 ...
>  $ age               : num [1:1370264] 24 25 24 25 42 43 34 34 35 58 ...
>  $ macro_unemployment: num [1:1370264] 5.24 4.86 5.24 4.86 5.24 ...
>  $ id                : int [1:1370264] 2 2 3 3 4 4 6 7 7 8 ...
>  $ country_year      : int [1:1370264] 1 2 1 2 1 2 1 1 2 1 ...
>  $ country           : Factor w/ 30 levels "Austria","Belgium",..: 1 1 1 1 1 1 1 1 1 1 ...
>  - attr(*, "groups")= tibble [27   2] (S3: tbl_df/tbl/data.frame)
>   ..$ country: Factor w/ 30 levels "Austria","Belgium",..: 1 2 3 6 7 8 9 10 11 12 ...
>   ..$ .rows  : list<int> [1:27]
>   .. ..$ : int [1:47204] 1 2 3 4 5 6 7 8 9 10 ...
>   .. ..$ : int [1:41361] 47205 47206 47207 47208 47209 47210 47211 47212 47213 47214 ...
>   .. ..$ : int [1:42407] 88566 88567 88568 88569 88570 88571 88572 88573 88574 88575 ...
>   .. ..$ : int [1:48253] 130973 130974 130975 130976 130977 130978 130979 130980 130981 130982 ...
>   .. ..$ : int [1:31917] 179226 179227 179228 179229 179230 179231 179232 179233 179234 179235 ...
>   .. ..$ : int [1:44047] 211143 211144 211145 211146 211147 211148 211149 211150 211151 211152 ...
>   .. ..$ : int [1:62087] 255190 255191 255192 255193 255194 255195 255196 255197 255198 255199 ...
>   .. ..$ : int [1:94309] 317277 317278 317279 317280 317281 317282 317283 317284 317285 317286 ...
>   .. ..$ : int [1:37246] 411586 411587 411588 411589 411590 411591 411592 411593 411594 411595 ...
>   .. ..$ : int [1:77253] 448832 448833 448834 448835 448836 448837 448838 448839 448840 448841 ...
>   .. ..$ : int [1:16823] 526085 526086 526087 526088 526089 526090 526091 526092 526093 526094 ...
>   .. ..$ : int [1:24687] 542908 542909 542910 542911 542912 542913 542914 542915 542916 542917 ...
>   .. ..$ : int [1:116263] 567595 567596 567597 567598 567599 567600 567601 567602 567603 567604 ...
>   .. ..$ : int [1:43218] 683858 683859 683860 683861 683862 683863 683864 683865 683866 683867 ...
>   .. ..$ : int [1:28709] 727076 727077 727078 727079 727080 727081 727082 727083 727084 727085 ...
>   .. ..$ : int [1:27583] 755785 755786 755787 755788 755789 755790 755791 755792 755793 755794 ...
>   .. ..$ : int [1:77960] 783368 783369 783370 783371 783372 783373 783374 783375 783376 783377 ...
>   .. ..$ : int [1:36922] 861328 861329 861330 861331 861332 861333 861334 861335 861336 861337 ...
>   .. ..$ : int [1:93194] 898250 898251 898252 898253 898254 898255 898256 898257 898258 898259 ...
>   .. ..$ : int [1:9004] 991444 991445 991446 991447 991448 991449 991450 991451 991452 991453 ...
>   .. ..$ : int [1:40074] 1000448 1000449 1000450 1000451 1000452 1000453 1000454 1000455 1000456 1000457 ...
>   .. ..$ : int [1:29342] 1040522 1040523 1040524 1040525 1040526 1040527 1040528 1040529 1040530 1040531 ...
>   .. ..$ : int [1:85124] 1069864 1069865 1069866 1069867 1069868 1069869 1069870 1069871 1069872 1069873 ...
>   .. ..$ : int [1:92350] 1154988 1154989 1154990 1154991 1154992 1154993 1154994 1154995 1154996 1154997 ...
>   .. ..$ : int [1:50188] 1247338 1247339 1247340 1247341 1247342 1247343 1247344 1247345 1247346 1247347 ...
>   .. ..$ : int [1:7598] 1297526 1297527 1297528 1297529 1297530 1297531 1297532 1297533 1297534 1297535 ...
>   .. ..$ : int [1:65141] 1305124 1305125 1305126 1305127 1305128 1305129 1305130 1305131 1305132 1305133 ...
>   .. ..@ ptype: int(0)
>   ..- attr(*, ".drop")= logi TRUE
>>
> 
> 
> Session Info:
> 
> R version 4.0.2 (2020-06-22)
> Platform: x86_64-apple-darwin17.0 (64-bit) Running under: macOS Catalina 10.15.6
> 
> Matrix products: default
> BLAS:   /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libBLAS.dylib
> LAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib
> 
> locale:
> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
> 
> attached base packages:
> [1] stats     graphics  grDevices
> [4] utils     datasets  methods
> [7] base
> 
> other attached packages:
>  [1] sessioninfo_1.1.1
>  [2] sjlabelled_1.1.5
>  [3] varhandle_2.0.5
>  [4] labelled_2.7.0
>  [5] dplyr_1.0.0
>  [6] ggplot2_3.3.2
>  [7] forcats_0.5.0
>  [8] reprex_0.3.0
>  [9] lmerTest_3.1-3
> [10] lme4_1.1-25
> [11] Matrix_1.2-18
> 
> loaded via a namespace (and not attached):
>  [1] Rcpp_1.0.4.6
>  [2] compiler_4.0.2
>  [3] pillar_1.4.4
>  [4] nloptr_1.2.2.1
>  [5] tools_4.0.2
>  [6] digest_0.6.25
>  [7] boot_1.3-25
>  [8] statmod_1.4.34
>  [9] lifecycle_0.2.0
> [10] tibble_3.0.1
> [11] nlme_3.1-148
> [12] gtable_0.3.0
> [13] lattice_0.20-41
> [14] pkgconfig_2.0.3
> [15] rlang_0.4.7
> [16] cli_2.0.2
> [17] rstudioapi_0.11
> [18] haven_2.3.1
> [19] withr_2.2.0
> [20] hms_0.5.3
> [21] generics_0.0.2
> [22] vctrs_0.3.1
> [23] fs_1.4.1
> [24] grid_4.0.2
> [25] tidyselect_1.1.0
> [26] glue_1.4.1
> [27] R6_2.4.1
> [28] fansi_0.4.1
> [29] minqa_1.2.4
> [30] farver_2.0.3
> [31] purrr_0.3.4
> [32] magrittr_1.5
> [33] scales_1.1.1
> [34] ellipsis_0.3.1
> [35] MASS_7.3-51.6
> [36] splines_4.0.2
> [37] insight_0.11.0
> [38] assertthat_0.2.1
> [39] colorspace_1.4-1
> [40] numDeriv_2016.8-1.1
> [41] labeling_0.3
> [42] utf8_1.1.4
> [43] munsell_0.5.0
> [44] crayon_1.3.4
> 
> 
> 
> 
> Sincerely,
> 
> 
> 
> Jad Moawad
> 
> 
> PhD candidate and teaching assistant
> University of Lausanne  - NCCR Lives
> Institut des Sciences Sociales
> B timent Geopolis - 5621
> 1015 Lausanne
> Switzerland
> 
> 
>         [[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 	[[alternative HTML version deleted]]
> 
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From bbo|ker @end|ng |rom gm@||@com  Tue Dec 15 17:22:51 2020
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Tue, 15 Dec 2020 11:22:51 -0500
Subject: [R-sig-ME] Question regarding large data.frame in LMER?
In-Reply-To: <54f42719-99e8-bc6f-24aa-abd8316d2989@phillipalday.com>
References: <bbb6420ece704ba795b95f7a446c5b53@unil.ch>
 <76a26ccefdb54623a345e5a48c01c482@cambiumassessment.com>
 <9688_1607683706_0QL600JKI8OPJL00_4b20de81a4324407b523c38f5ce68fb2@hum.leidenuniv.nl>
 <CAO7JsnQzCYt11tZsTyV=w6E=6nUCrYi_qh-N6kvofESSGQAoAg@mail.gmail.com>
 <433e49985c684454827f0ac493198d75@unil.ch>
 <d9545047222c44bf86bc6509856d934d@cambiumassessment.com>
 <54f42719-99e8-bc6f-24aa-abd8316d2989@phillipalday.com>
Message-ID: <f2433ffb-0188-a990-1280-fd4b62f86cff@gmail.com>

   This is great stuff.
   I don't have much to add to this very clear description of 
performance issues in lme4 and MixedModels.jl; I'll just point out two 
other promising (but very different!) avenues for fitting mixed models 
to very large data sets, one by Gao (and Owen) and one by folks at 
StitchFix:

   Gao, K., and A. B. Owen. ?Estimation and Inference for Very Large 
Linear Mixed Effects Models.? ArXiv:1610.08088 [Stat], May 26, 2017. 
http://arxiv.org/abs/1610.08088.

Gao, Katelyn. ?Scalable Estimation and Inference for Massive Linear 
Mixed Models with Crossed Random Effects.? PhD Thesis, Stanford 
University, 2017. 
https://statweb.stanford.edu/~owen/students/KatelynGaoThesis.pdf.

Gao, Katelyn, and Art Owen. ?Efficient Moment Calculations for Variance 
Components in Large Unbalanced Crossed Random Effects Models.? 
Electronic Journal of Statistics 11, no. 1 (2017): 1235?96. 
https://doi.org/10.1214/17-EJS1236.

Diamond: Python Solver for Mixed-Effects Models. Python. 2017. Reprint, 
Stitch Fix Technology, 2017. https://github.com/stitchfix/diamond.
Sweetser, Tim, and Aaron Bradley. ?Diamond Part I.? Stitch Fix 
Technology: Multithreaded. Accessed October 22, 2020.

https://multithreaded.stitchfix.com/blog/2017/08/07/diamond1/.
???. ?Diamond Part II: Stitch Fix Technology.? Stitch Fix Technology: 
Multithreaded, August 7, 2017. 
https://multithreaded.stitchfix.com/blog/2017/08/07/diamond2/.


On 12/15/20 11:12 AM, Phillip Alday wrote:
> Hi everybody,
> 
> since I'm the one who wrote the limited parallelized code in
> MixedModels.jl, I'll comment a little bit on that as well as a few
> general points.
> 
> 1. An efficient profiled loglikelihood is important to both lme4 and
> MixedModels.jl. Critically, both manage to rewrite the problem as a
> penalized least squares problem instead of the more typical generalized
> least squares formulation used by e.g. nlme.  This has advantages both
> in computation and representation (next point). For that, see the lme4
> paper or the NextJournal article Doug linked or .... when I actually can
> block out some time from the day job and finish my small part of it, the
> forthcoming MixedModels.jl paper. (Sorry, Doug! I haven't forgotten
> about it...)
> 
> 2. Sparse matrices are important to both lme4 and MixedModels.jl not
> just because of the direct issues with a reduced memory footprint. It
> turns out that memory allocation itself is really slow, even when you
> have enough memory, so if you can do sparse operations in place (rather
> than allocating and copying), then you can make things really fast. Joel
> on Software discusses this issue in one his posts
> (https://www.joelonsoftware.com/2001/12/11/back-to-basics/). lme4 does
> this to some extent, but requires bouncing back and forth between R and
> C++ to really it do it well, but that introduces its own complexities.
> 
> So that brings us to where Julia shines compared to R: you do everything
> in Julia and Julia's memory model is such that it's easier to do things
> in place. So in Julia we can write prototype very specialized methods
> for particular types of sparsity and do all of those sparse operations
> in place, without bringing in another language. In other words, it's
> easier to try new stuff out, which is how some of the innovations in
> MixedModels.jl arose compared to lme4 -- Doug tried prototyped a
> particular specialized quickly because it was easy to do so and it
> proved worthwhile. (There were also a few happy accidents in deriving a
> somewhat more efficient profiled log-likelihood, both in computation and
> in storage, but back porting those changes to lme4 is somewhat more
> difficult due to the two-language problem.)
> 
> @Doug: feel free to correct any infelicities or oversimplifications that
> I probably introduced.
> 
> On the parallelism front: there are may different levels to be parallel
> at. The easiest and most obvious one is at the level of the basic matrix
> operations, i.e. those provided by the BLAS (basic linear algebra
> subroutines). Microsoft/Revolution's R release actually packages the
> Intel MKL, a very specialized and fast BLAS, instead of the default
> system BLAS that R uses on most platforms. (On MacOS, the system BLAS is
> actually very good, at least on Intel chips). There are decades of
> research into making BLAS work fast, including its parallelization. I
> frequently see all cores being saturated when doing BLAS calls from
> Julia because the OpenBLAS variant Julia links to is multi-threaded by
> default.  On Linux, you change the BLAS that R uses to be something more
> tuned to your system, if you want; here's my somewhat outdated blogpost
> on it: https://phillipalday.com/blog/2013/05/31/Speed-up-R-(on-Linux)/
> 
> In Julia, I've tried to parallelize some loops in the evaluation of the
> log likelihood but ... it generally didn't actually help much. This
> suggests that those weren't the bottleneck and/or parallelization
> introduces a different bottleneck (more on that in a minute). lme4
> currently has an open issue on using an optimizer that can itself be
> parallelized (i.e the thing that takes the log likelihood function and
> uses that to find out the parameters values corresponding to the maximum
> likelihood): https://github.com/lme4/lme4/issues/508 but progress on
> that has kinda stalled. It doesn't seem to offer a huge boost; parallel
> programming is hard; etc. Both lme4 and MixedModels.jl are written in
> such a way that it is theoretically possible to use a parallelized
> optimizer, but it just doesn't seem to be worth it.
> 
> One thing that should be worth parallelizing though is the parametric
> bootstrap because each bootstrap replication is, per definition,
> independent of the others (it's an "embarrassingly parallel" problem). I
> wrote this for MixedModels.jl -- if you want this to be really nice,
> then there is some subtlety in dealing with the random number generator
> and not making superfluous memory allocations (see above), but it's
> relatively straightforward as far as parallel programming goes. When I
> first implemented it, we noticed a huge speed boost. Then Doug made some
> algorithmic improvements for the single-threaded case and a new Julia
> version came out that was linked to a new BLAS version and the boost
> went away, sometimes running even slower. The problem? The new BLAS
> version was very multithreaded and so it was already taking full
> advantage of all the cores on my system for a single model fit, so when
> I added another layer of parallelism on top of that, I suddenly had more
> parallel operations than cores and swapping between operations (context
> switching) is not free. So even then it didn't help. I tried increasing
> the granularity of the parallelism ... and that helped a bit, but added
> a huge amount of code complexity, so I ultimately discarded that
> attempt. (I think lme4 can still take better advantage of this in its
> bootstrap because the default R BLAS isn't quite as good as the current
> Julia BLAS for multithreading.) If you're curious and bored, I talked
> about this as part of JuliaCon this year:
> https://www.youtube.com/watch?v=qhfQKIDR7Ms
> 
> Of course, this is all parallelism at the level of multiple local
> CPUs/cores -- with things like clusters with multiple nodes (which
> require some coordination overhead) or  GPUs (which don't always place
> nice with sparse matrices and introduce their own coordination
> overhead), you can introduce some more parallelism, so there may still
> be some gains to be made in this area. Also, if you have a system with
> just an insane number of cores (> 64), then you probably have more cores
> than your BLAS can take advantage of and then layering local threaded
> bootstrapping on top of that may still help. (Anybody with a
> Threadripper CPU want to run some benchmarks for me?)
> 
> There's also Amdah's Law (https://en.wikipedia.org/wiki/Amdahl's_law),
> which puts a hard limit to how much of a boost parallelism can give you.
> (Though for things like bootstrapping, if you had zero coordination
> cost, then you do get linear scaling until the number of cluster nodes
> matches the number of bootstrap replicates...)
> 
> In other words, parallelism is hard and not quite as helpful as you'd
> hope. (And I haven't even talked about SIMD-type of parallelism, which
> is a bit closer to GPU-style parallelism but on a smaller scale and part
> of the floating-point unit of most modern CPUs.)
> 
> This doesn't mean there are no more performance enhancements to be made.
> Quite the contrary -- if we can continue improving and specializing our
> storage and computation methods, then we can often reduce the total
> number of (multithreaded) BLAS operations necessary, which is far more
> effective than just making those operations each individually faster.
> And these advancements are exactly (1) and (2) above and in Harold's
> message.
> 
> As a contrast, Stan has seen some recent improvements in speed by using
> more types of parallelism within chains, but these are related to (A)
> the types of BLAS-level parallelism I mentioned above and (B) taking
> advantage of some nice associativity tricks in summing up the individual
> terms of log-likelihoods. These types of algorithm advances are largely
> already present in MixedModels.jl, just in very specialized form. (I
> think the Stan team is doing some really cool work, but the pro  and con
> of Stan or general frameworks like TMB is that they are general, so they
> can't take advantage of some specializations very particular to a given
> model class, like mixed models.)
> 
> Best,
> Phillip
> 
> PS: I liked the question! This is not meant to be dismissive, but
> instead to highlight how hard it all is. :)
> 
> On 15/12/20 4:14 pm, Harold Doran wrote:
>> @doug, it seems like the "speed" conversation for mixed models have two considerations: 1) how can we rewrite the log-likelihood to improve optimization and 2) what computational things can be done to improve the speed.
>>
>> As an example, your note below is more along the lines of (1) whereas sparse matrices are more along the lines of (2).
>>
>> One computational topic that I know is harder with LMMs is parallel processing. Almost all software I have written in the past 5 years uses parallel processing-but my tasks are based on the concept of being "embarrassingly parallel", which makes the split, apply, combine problem quite easy.
>>
>> Parallel processing with larger matrix operations is more complex. However, I have implemented lmer models using Microsoft's R implementation and timed it against R and found it was quite a bit faster. Same data, same computer, same model, same output (and same results). I *think* it's more than just a different BLAS being used by MS, but perhaps something fundamentally different in its workhorse for some matrix ops. Others correct me if I'm wrong, but I'm curious on your thoughts Doug as whether this is an avenue mixed model thinkers/developers should consider (being agnostic for a moment about which software is used).
>>
>>
>>
>> From: Jad Moawad <jad.moawad at unil.ch>
>> Sent: Monday, December 14, 2020 11:38 AM
>> To: Douglas Bates <bates at stat.wisc.edu>; Voeten, C.C. <c.c.voeten at hum.leidenuniv.nl>
>> Cc: Harold Doran <harold.doran at cambiumassessment.com>; r-sig-mixed-models at r-project.org
>> Subject: RE: [R-sig-ME] Question regarding large data.frame in LMER?
>>
>>
>> Sorry, I did not know that i had to keep poly(Age, 2) as default. Thank you for clarifying, I will try it again.
>>
>>
>>
>> The number of levels in the id variable is 567058. People are supposedly followed for 4 years, but of course there is some attrition along the way.
>>
>>
>>
>> Yes please, i would like to try with the package of Julia. After all, i am using now the second-best option in terms of design. However, if i can go back to the original, it would be better to answer my research question.
>>
>> ________________________________
>> De : Douglas Bates <bates at stat.wisc.edu<mailto:bates at stat.wisc.edu>>
>> Envoy? : lundi 14 d?cembre 2020 17:09:15
>> ? : Voeten, C.C.
>> Cc : Harold Doran; Jad Moawad; r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
>> Objet : Re: [R-sig-ME] Question regarding large data.frame in LMER?
>>
>> Sorry for coming to this discussion late.  I notice that in the glimpse of the data set the first few values of id occur in pairs.  If you convert id to a factor how many levels does it have?
>>
>> The implementation of mixed-effects models in the MixedModels (https://github.com/JuliaStats/MixedModels.jl) package for Julia is better suited to dealing with large numbers of observations than is the one in lme4.  It uses a more compact numerical representation of the model during the iterations to optimize the profiled log-likelihood.  Some of this is described in https://nextjournal.com/dmbates/complexity-in-fitting-linear-mixed-models  The important point is that evaluation of the profiled log-likelihood for new parameter values does not require working with matrices whose size depends on n, the number of observations.  All matrices are of sizes determined by the number of random effects and the number of fixed-effects parameters.  Of course, if each id only occurs twice then the number of random effects is already on the order of the number of observations so this will not be an advantage.
>>
>> If you are interested in trying the Julia package we can help with that.
>>
>> If anyone wants to try to implement the MixedModels approach in R I can advise you how to do it but I really don't have the energy to do the R/C++ two-language dance any more.
>>
>> On Fri, Dec 11, 2020 at 4:48 AM Voeten, C.C. <c.c.voeten at hum.leidenuniv.nl<mailto:c.c.voeten at hum.leidenuniv.nl>> wrote:
>> Another option could be to try fitting your model using mgcv::bam, which is optimized for 'big' datasets. The function is primarily intended for GAMMs, but an LMM is just a specific type of GAMM, so this is no problem. You could use buildmer::re2mgcv to convert your lme4 random-effects specification (i.e. your formula using | terms) to the equivalent mgcv specification (using s() terms).
>>
>> However, note that the bam model will not be completely equivalent to the lme4 model, in that the bam model will not model the correlations between the random effects. If those are important to you, then please disregard my suggestion!
>>
>> Cesko
>>
>> -----Original Message-----
>> From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org<mailto:r-sig-mixed-models-bounces at r-project.org>> On Behalf Of Harold Doran
>> Sent: Friday, December 11, 2020 11:38 AM
>> To: Jad Moawad <jad.moawad at unil.ch<mailto:jad.moawad at unil.ch>>; r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
>> Subject: Re: [R-sig-ME] Question regarding large data.frame in LMER?
>>
>> Assuming that you're sampling from your complete data set in a way that represents the complete data, one strategy might also be to use starting values from prior converged models and incrementally increase the size of the data.
>>
>> For example,
>>
>> 1) run model with 10% of data and get parameter estimates
>> 2) use the param estimates from (1) as starting values and now increase size of data to 40%
>> 3) repeat
>>
>> The strategy doesn't help/solve with the p.d. issue, but it does improve the potential for reaching the top of the hill with a big data file faster.
>>
>> It's an incremental EM idea that reduces the amount of work lmer() (or any iterative maximization procedure) would need to do with a very large file. In other words, why start all over again with a very big file when we can start somewhere better and let the algorithm start closer to the top of the hill, so to speak.
>>
>> Hope it helps.
>> Harold
>>
>>
>>
>> -----Original Message-----
>> From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org<mailto:r-sig-mixed-models-bounces at r-project.org>> On Behalf Of Jad Moawad
>> Sent: Thursday, December 10, 2020 7:12 AM
>> To: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
>> Subject: [R-sig-ME] Question regarding large data.frame in LMER?
>>
>> External email alert: Be wary of links & attachments.
>>
>>
>> I am working with a large data.frame that contains around 1.4 million observations. Initially when i was running my models, i was working on a sub-sample (10% of my full-sample). This is because running one model can take a lot of time using the original data. Once i was sure that all variables are well harmonized and all regressions were running fine, i ran my models using the full sample. However, the regression did not converge and i received the following two errors from two different models:
>>
>> Error in fun(xaa, ...) : Downdated VtV is not positive definite
>>
>> Error in fun(xss, ...) : Downdated VtV is not positive definite
>>
>> I use the lmer function to fit my model and i include a random slopes at the country and country_year level. Below you find the code that i use.
>>
>> Model1 <- lmer(health~ class + age + I(age^2)  + class*macro_unemployment +
>>                 (class + age + I(age^2)|country) +
>>                 (class+ age + I(age^2) |country_year) +
>>                 (1|id), data=df)
>>
>> Model2 <- lmer(health~ education + age + I(age^2)  + education*macro_unemployment+
>>                 (education + age + I(age^2)|country) +
>>                 (education + age + I(age^2) |country_year) +
>>                 (1|id), data=df)
>>
>>
>> Could someone help me please with solving this issue?
>>
>> Below you find a glimpse (str) of my data and my sessionInfo():
>>
>> tibble [1,370,264   8] (S3: grouped_df/tbl_df/tbl/data.frame)
>>   $ health            : num [1:1370264] 100 100 50 100 0 75 75 100 100 50 ...
>>   $ class             : Factor w/ 3 levels "Upper-middle class",..: 3 3 NA 3 3 3 3 1 1 3 ...
>>   $ education         : Factor w/ 3 levels "low","mid","high": 1 1 1 1 1 1 2 3 3 1 ...
>>   $ age               : num [1:1370264] 24 25 24 25 42 43 34 34 35 58 ...
>>   $ macro_unemployment: num [1:1370264] 5.24 4.86 5.24 4.86 5.24 ...
>>   $ id                : int [1:1370264] 2 2 3 3 4 4 6 7 7 8 ...
>>   $ country_year      : int [1:1370264] 1 2 1 2 1 2 1 1 2 1 ...
>>   $ country           : Factor w/ 30 levels "Austria","Belgium",..: 1 1 1 1 1 1 1 1 1 1 ...
>>   - attr(*, "groups")= tibble [27   2] (S3: tbl_df/tbl/data.frame)
>>    ..$ country: Factor w/ 30 levels "Austria","Belgium",..: 1 2 3 6 7 8 9 10 11 12 ...
>>    ..$ .rows  : list<int> [1:27]
>>    .. ..$ : int [1:47204] 1 2 3 4 5 6 7 8 9 10 ...
>>    .. ..$ : int [1:41361] 47205 47206 47207 47208 47209 47210 47211 47212 47213 47214 ...
>>    .. ..$ : int [1:42407] 88566 88567 88568 88569 88570 88571 88572 88573 88574 88575 ...
>>    .. ..$ : int [1:48253] 130973 130974 130975 130976 130977 130978 130979 130980 130981 130982 ...
>>    .. ..$ : int [1:31917] 179226 179227 179228 179229 179230 179231 179232 179233 179234 179235 ...
>>    .. ..$ : int [1:44047] 211143 211144 211145 211146 211147 211148 211149 211150 211151 211152 ...
>>    .. ..$ : int [1:62087] 255190 255191 255192 255193 255194 255195 255196 255197 255198 255199 ...
>>    .. ..$ : int [1:94309] 317277 317278 317279 317280 317281 317282 317283 317284 317285 317286 ...
>>    .. ..$ : int [1:37246] 411586 411587 411588 411589 411590 411591 411592 411593 411594 411595 ...
>>    .. ..$ : int [1:77253] 448832 448833 448834 448835 448836 448837 448838 448839 448840 448841 ...
>>    .. ..$ : int [1:16823] 526085 526086 526087 526088 526089 526090 526091 526092 526093 526094 ...
>>    .. ..$ : int [1:24687] 542908 542909 542910 542911 542912 542913 542914 542915 542916 542917 ...
>>    .. ..$ : int [1:116263] 567595 567596 567597 567598 567599 567600 567601 567602 567603 567604 ...
>>    .. ..$ : int [1:43218] 683858 683859 683860 683861 683862 683863 683864 683865 683866 683867 ...
>>    .. ..$ : int [1:28709] 727076 727077 727078 727079 727080 727081 727082 727083 727084 727085 ...
>>    .. ..$ : int [1:27583] 755785 755786 755787 755788 755789 755790 755791 755792 755793 755794 ...
>>    .. ..$ : int [1:77960] 783368 783369 783370 783371 783372 783373 783374 783375 783376 783377 ...
>>    .. ..$ : int [1:36922] 861328 861329 861330 861331 861332 861333 861334 861335 861336 861337 ...
>>    .. ..$ : int [1:93194] 898250 898251 898252 898253 898254 898255 898256 898257 898258 898259 ...
>>    .. ..$ : int [1:9004] 991444 991445 991446 991447 991448 991449 991450 991451 991452 991453 ...
>>    .. ..$ : int [1:40074] 1000448 1000449 1000450 1000451 1000452 1000453 1000454 1000455 1000456 1000457 ...
>>    .. ..$ : int [1:29342] 1040522 1040523 1040524 1040525 1040526 1040527 1040528 1040529 1040530 1040531 ...
>>    .. ..$ : int [1:85124] 1069864 1069865 1069866 1069867 1069868 1069869 1069870 1069871 1069872 1069873 ...
>>    .. ..$ : int [1:92350] 1154988 1154989 1154990 1154991 1154992 1154993 1154994 1154995 1154996 1154997 ...
>>    .. ..$ : int [1:50188] 1247338 1247339 1247340 1247341 1247342 1247343 1247344 1247345 1247346 1247347 ...
>>    .. ..$ : int [1:7598] 1297526 1297527 1297528 1297529 1297530 1297531 1297532 1297533 1297534 1297535 ...
>>    .. ..$ : int [1:65141] 1305124 1305125 1305126 1305127 1305128 1305129 1305130 1305131 1305132 1305133 ...
>>    .. ..@ ptype: int(0)
>>    ..- attr(*, ".drop")= logi TRUE
>>>
>>
>>
>> Session Info:
>>
>> R version 4.0.2 (2020-06-22)
>> Platform: x86_64-apple-darwin17.0 (64-bit) Running under: macOS Catalina 10.15.6
>>
>> Matrix products: default
>> BLAS:   /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libBLAS.dylib
>> LAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib
>>
>> locale:
>> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>>
>> attached base packages:
>> [1] stats     graphics  grDevices
>> [4] utils     datasets  methods
>> [7] base
>>
>> other attached packages:
>>   [1] sessioninfo_1.1.1
>>   [2] sjlabelled_1.1.5
>>   [3] varhandle_2.0.5
>>   [4] labelled_2.7.0
>>   [5] dplyr_1.0.0
>>   [6] ggplot2_3.3.2
>>   [7] forcats_0.5.0
>>   [8] reprex_0.3.0
>>   [9] lmerTest_3.1-3
>> [10] lme4_1.1-25
>> [11] Matrix_1.2-18
>>
>> loaded via a namespace (and not attached):
>>   [1] Rcpp_1.0.4.6
>>   [2] compiler_4.0.2
>>   [3] pillar_1.4.4
>>   [4] nloptr_1.2.2.1
>>   [5] tools_4.0.2
>>   [6] digest_0.6.25
>>   [7] boot_1.3-25
>>   [8] statmod_1.4.34
>>   [9] lifecycle_0.2.0
>> [10] tibble_3.0.1
>> [11] nlme_3.1-148
>> [12] gtable_0.3.0
>> [13] lattice_0.20-41
>> [14] pkgconfig_2.0.3
>> [15] rlang_0.4.7
>> [16] cli_2.0.2
>> [17] rstudioapi_0.11
>> [18] haven_2.3.1
>> [19] withr_2.2.0
>> [20] hms_0.5.3
>> [21] generics_0.0.2
>> [22] vctrs_0.3.1
>> [23] fs_1.4.1
>> [24] grid_4.0.2
>> [25] tidyselect_1.1.0
>> [26] glue_1.4.1
>> [27] R6_2.4.1
>> [28] fansi_0.4.1
>> [29] minqa_1.2.4
>> [30] farver_2.0.3
>> [31] purrr_0.3.4
>> [32] magrittr_1.5
>> [33] scales_1.1.1
>> [34] ellipsis_0.3.1
>> [35] MASS_7.3-51.6
>> [36] splines_4.0.2
>> [37] insight_0.11.0
>> [38] assertthat_0.2.1
>> [39] colorspace_1.4-1
>> [40] numDeriv_2016.8-1.1
>> [41] labeling_0.3
>> [42] utf8_1.1.4
>> [43] munsell_0.5.0
>> [44] crayon_1.3.4
>>
>>
>>
>>
>> Sincerely,
>>
>>
>>
>> Jad Moawad
>>
>>
>> PhD candidate and teaching assistant
>> University of Lausanne  - NCCR Lives
>> Institut des Sciences Sociales
>> B timent Geopolis - 5621
>> 1015 Lausanne
>> Switzerland
>>
>>
>>          [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>> 	[[alternative HTML version deleted]]
>>
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From h@ro|d@dor@n @end|ng |rom c@mb|um@@@e@@ment@com  Tue Dec 15 18:07:12 2020
From: h@ro|d@dor@n @end|ng |rom c@mb|um@@@e@@ment@com (Harold Doran)
Date: Tue, 15 Dec 2020 17:07:12 +0000
Subject: [R-sig-ME] Question regarding large data.frame in LMER?
In-Reply-To: <54f42719-99e8-bc6f-24aa-abd8316d2989@phillipalday.com>
References: <bbb6420ece704ba795b95f7a446c5b53@unil.ch>
 <76a26ccefdb54623a345e5a48c01c482@cambiumassessment.com>
 <9688_1607683706_0QL600JKI8OPJL00_4b20de81a4324407b523c38f5ce68fb2@hum.leidenuniv.nl>
 <CAO7JsnQzCYt11tZsTyV=w6E=6nUCrYi_qh-N6kvofESSGQAoAg@mail.gmail.com>
 <433e49985c684454827f0ac493198d75@unil.ch>
 <d9545047222c44bf86bc6509856d934d@cambiumassessment.com>
 <54f42719-99e8-bc6f-24aa-abd8316d2989@phillipalday.com>
Message-ID: <46192629068c4cdaa08e5bcbd856e69c@cambiumassessment.com>

This is an outstanding, reply and hugely helpful post. Phillip, you have done good work. It will take me a bit of time to absorb all of this and may have some future thoughts/questions. 

My software for mixed models dances between R and C++ as Doug notes is a bit of work. I fear my representation of the Henderson mixed model solution differs drastically from how lmer (or Julia variants not sure what to refer to those as), but it stands on the shoulders of Davis' work and Bates/Maechler implementations in Matrix package. In profiling my applications, the simple symbolic/numeric Cholesky decompositions (for me) were huge improvements.

I have two "tricks" I use in my solution that have improved speed. One is using the woodbury identity lemma. There is one place where I found I *had* to take an inverse and I was able to reduce the size of that matrix using that lemma.

I also found some smaller places where I could parallelize some data management tasks within the code, but not inside the real workhorse--I found that a harder problem and gave up on that front. 

These are hard problems.


-----Original Message-----
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> On Behalf Of Phillip Alday
Sent: Tuesday, December 15, 2020 11:12 AM
To: Harold Doran <harold.doran at cambiumassessment.com>; Jad Moawad <jad.moawad at unil.ch>; Douglas Bates <bates at stat.wisc.edu>; Voeten, C.C. <c.c.voeten at hum.leidenuniv.nl>
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Question regarding large data.frame in LMER?

External email alert: Be wary of links & attachments.


Hi everybody,

since I'm the one who wrote the limited parallelized code in MixedModels.jl, I'll comment a little bit on that as well as a few general points.

1. An efficient profiled loglikelihood is important to both lme4 and MixedModels.jl. Critically, both manage to rewrite the problem as a penalized least squares problem instead of the more typical generalized least squares formulation used by e.g. nlme.  This has advantages both in computation and representation (next point). For that, see the lme4 paper or the NextJournal article Doug linked or .... when I actually can block out some time from the day job and finish my small part of it, the forthcoming MixedModels.jl paper. (Sorry, Doug! I haven't forgotten about it...)

2. Sparse matrices are important to both lme4 and MixedModels.jl not just because of the direct issues with a reduced memory footprint. It turns out that memory allocation itself is really slow, even when you have enough memory, so if you can do sparse operations in place (rather than allocating and copying), then you can make things really fast. Joel on Software discusses this issue in one his posts (https://www.joelonsoftware.com/2001/12/11/back-to-basics/). lme4 does this to some extent, but requires bouncing back and forth between R and
C++ to really it do it well, but that introduces its own complexities.

So that brings us to where Julia shines compared to R: you do everything in Julia and Julia's memory model is such that it's easier to do things in place. So in Julia we can write prototype very specialized methods for particular types of sparsity and do all of those sparse operations in place, without bringing in another language. In other words, it's easier to try new stuff out, which is how some of the innovations in MixedModels.jl arose compared to lme4 -- Doug tried prototyped a particular specialized quickly because it was easy to do so and it proved worthwhile. (There were also a few happy accidents in deriving a somewhat more efficient profiled log-likelihood, both in computation and in storage, but back porting those changes to lme4 is somewhat more difficult due to the two-language problem.)

@Doug: feel free to correct any infelicities or oversimplifications that I probably introduced.

On the parallelism front: there are may different levels to be parallel at. The easiest and most obvious one is at the level of the basic matrix operations, i.e. those provided by the BLAS (basic linear algebra subroutines). Microsoft/Revolution's R release actually packages the Intel MKL, a very specialized and fast BLAS, instead of the default system BLAS that R uses on most platforms. (On MacOS, the system BLAS is actually very good, at least on Intel chips). There are decades of research into making BLAS work fast, including its parallelization. I frequently see all cores being saturated when doing BLAS calls from Julia because the OpenBLAS variant Julia links to is multi-threaded by default.  On Linux, you change the BLAS that R uses to be something more tuned to your system, if you want; here's my somewhat outdated blogpost on it: https://phillipalday.com/blog/2013/05/31/Speed-up-R-(on-Linux)/

In Julia, I've tried to parallelize some loops in the evaluation of the log likelihood but ... it generally didn't actually help much. This suggests that those weren't the bottleneck and/or parallelization introduces a different bottleneck (more on that in a minute). lme4 currently has an open issue on using an optimizer that can itself be parallelized (i.e the thing that takes the log likelihood function and uses that to find out the parameters values corresponding to the maximum
likelihood): https://github.com/lme4/lme4/issues/508 but progress on that has kinda stalled. It doesn't seem to offer a huge boost; parallel programming is hard; etc. Both lme4 and MixedModels.jl are written in such a way that it is theoretically possible to use a parallelized optimizer, but it just doesn't seem to be worth it.

One thing that should be worth parallelizing though is the parametric bootstrap because each bootstrap replication is, per definition, independent of the others (it's an "embarrassingly parallel" problem). I wrote this for MixedModels.jl -- if you want this to be really nice, then there is some subtlety in dealing with the random number generator and not making superfluous memory allocations (see above), but it's relatively straightforward as far as parallel programming goes. When I first implemented it, we noticed a huge speed boost. Then Doug made some algorithmic improvements for the single-threaded case and a new Julia version came out that was linked to a new BLAS version and the boost went away, sometimes running even slower. The problem? The new BLAS version was very multithreaded and so it was already taking full advantage of all the cores on my system for a single model fit, so when I added another layer of parallelism on top of that, I suddenly had more parallel operations than cores and swapping between operations (context
switching) is not free. So even then it didn't help. I tried increasing the granularity of the parallelism ... and that helped a bit, but added a huge amount of code complexity, so I ultimately discarded that attempt. (I think lme4 can still take better advantage of this in its bootstrap because the default R BLAS isn't quite as good as the current Julia BLAS for multithreading.) If you're curious and bored, I talked about this as part of JuliaCon this year:
https://www.youtube.com/watch?v=qhfQKIDR7Ms

Of course, this is all parallelism at the level of multiple local CPUs/cores -- with things like clusters with multiple nodes (which require some coordination overhead) or  GPUs (which don't always place nice with sparse matrices and introduce their own coordination overhead), you can introduce some more parallelism, so there may still be some gains to be made in this area. Also, if you have a system with just an insane number of cores (> 64), then you probably have more cores than your BLAS can take advantage of and then layering local threaded bootstrapping on top of that may still help. (Anybody with a Threadripper CPU want to run some benchmarks for me?)

There's also Amdah's Law (https://en.wikipedia.org/wiki/Amdahl's_law),
which puts a hard limit to how much of a boost parallelism can give you.
(Though for things like bootstrapping, if you had zero coordination cost, then you do get linear scaling until the number of cluster nodes matches the number of bootstrap replicates...)

In other words, parallelism is hard and not quite as helpful as you'd hope. (And I haven't even talked about SIMD-type of parallelism, which is a bit closer to GPU-style parallelism but on a smaller scale and part of the floating-point unit of most modern CPUs.)

This doesn't mean there are no more performance enhancements to be made.
Quite the contrary -- if we can continue improving and specializing our storage and computation methods, then we can often reduce the total number of (multithreaded) BLAS operations necessary, which is far more effective than just making those operations each individually faster.
And these advancements are exactly (1) and (2) above and in Harold's message.

As a contrast, Stan has seen some recent improvements in speed by using more types of parallelism within chains, but these are related to (A) the types of BLAS-level parallelism I mentioned above and (B) taking advantage of some nice associativity tricks in summing up the individual terms of log-likelihoods. These types of algorithm advances are largely already present in MixedModels.jl, just in very specialized form. (I think the Stan team is doing some really cool work, but the pro  and con of Stan or general frameworks like TMB is that they are general, so they can't take advantage of some specializations very particular to a given model class, like mixed models.)

Best,
Phillip

PS: I liked the question! This is not meant to be dismissive, but instead to highlight how hard it all is. :)

On 15/12/20 4:14 pm, Harold Doran wrote:
> @doug, it seems like the "speed" conversation for mixed models have two considerations: 1) how can we rewrite the log-likelihood to improve optimization and 2) what computational things can be done to improve the speed.
>
> As an example, your note below is more along the lines of (1) whereas sparse matrices are more along the lines of (2).
>
> One computational topic that I know is harder with LMMs is parallel processing. Almost all software I have written in the past 5 years uses parallel processing-but my tasks are based on the concept of being "embarrassingly parallel", which makes the split, apply, combine problem quite easy.
>
> Parallel processing with larger matrix operations is more complex. However, I have implemented lmer models using Microsoft's R implementation and timed it against R and found it was quite a bit faster. Same data, same computer, same model, same output (and same results). I *think* it's more than just a different BLAS being used by MS, but perhaps something fundamentally different in its workhorse for some matrix ops. Others correct me if I'm wrong, but I'm curious on your thoughts Doug as whether this is an avenue mixed model thinkers/developers should consider (being agnostic for a moment about which software is used).
>
>
>
> From: Jad Moawad <jad.moawad at unil.ch>
> Sent: Monday, December 14, 2020 11:38 AM
> To: Douglas Bates <bates at stat.wisc.edu>; Voeten, C.C. 
> <c.c.voeten at hum.leidenuniv.nl>
> Cc: Harold Doran <harold.doran at cambiumassessment.com>; 
> r-sig-mixed-models at r-project.org
> Subject: RE: [R-sig-ME] Question regarding large data.frame in LMER?
>
>
> Sorry, I did not know that i had to keep poly(Age, 2) as default. Thank you for clarifying, I will try it again.
>
>
>
> The number of levels in the id variable is 567058. People are supposedly followed for 4 years, but of course there is some attrition along the way.
>
>
>
> Yes please, i would like to try with the package of Julia. After all, i am using now the second-best option in terms of design. However, if i can go back to the original, it would be better to answer my research question.
>
> ________________________________
> De : Douglas Bates <bates at stat.wisc.edu<mailto:bates at stat.wisc.edu>>
> Envoy  : lundi 14 d cembre 2020 17:09:15   : Voeten, C.C.
> Cc : Harold Doran; Jad Moawad; 
> r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.o
> rg> Objet : Re: [R-sig-ME] Question regarding large data.frame in 
> LMER?
>
> Sorry for coming to this discussion late.  I notice that in the glimpse of the data set the first few values of id occur in pairs.  If you convert id to a factor how many levels does it have?
>
> The implementation of mixed-effects models in the MixedModels (https://github.com/JuliaStats/MixedModels.jl) package for Julia is better suited to dealing with large numbers of observations than is the one in lme4.  It uses a more compact numerical representation of the model during the iterations to optimize the profiled log-likelihood.  Some of this is described in https://nextjournal.com/dmbates/complexity-in-fitting-linear-mixed-models  The important point is that evaluation of the profiled log-likelihood for new parameter values does not require working with matrices whose size depends on n, the number of observations.  All matrices are of sizes determined by the number of random effects and the number of fixed-effects parameters.  Of course, if each id only occurs twice then the number of random effects is already on the order of the number of observations so this will not be an advantage.
>
> If you are interested in trying the Julia package we can help with that.
>
> If anyone wants to try to implement the MixedModels approach in R I can advise you how to do it but I really don't have the energy to do the R/C++ two-language dance any more.
>
> On Fri, Dec 11, 2020 at 4:48 AM Voeten, C.C. <c.c.voeten at hum.leidenuniv.nl<mailto:c.c.voeten at hum.leidenuniv.nl>> wrote:
> Another option could be to try fitting your model using mgcv::bam, which is optimized for 'big' datasets. The function is primarily intended for GAMMs, but an LMM is just a specific type of GAMM, so this is no problem. You could use buildmer::re2mgcv to convert your lme4 random-effects specification (i.e. your formula using | terms) to the equivalent mgcv specification (using s() terms).
>
> However, note that the bam model will not be completely equivalent to the lme4 model, in that the bam model will not model the correlations between the random effects. If those are important to you, then please disregard my suggestion!
>
> Cesko
>
> -----Original Message-----
> From: R-sig-mixed-models 
> <r-sig-mixed-models-bounces at r-project.org<mailto:r-sig-mixed-models-bo
> unces at r-project.org>> On Behalf Of Harold Doran
> Sent: Friday, December 11, 2020 11:38 AM
> To: Jad Moawad <jad.moawad at unil.ch<mailto:jad.moawad at unil.ch>>; 
> r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.o
> rg>
> Subject: Re: [R-sig-ME] Question regarding large data.frame in LMER?
>
> Assuming that you're sampling from your complete data set in a way that represents the complete data, one strategy might also be to use starting values from prior converged models and incrementally increase the size of the data.
>
> For example,
>
> 1) run model with 10% of data and get parameter estimates
> 2) use the param estimates from (1) as starting values and now 
> increase size of data to 40%
> 3) repeat
>
> The strategy doesn't help/solve with the p.d. issue, but it does improve the potential for reaching the top of the hill with a big data file faster.
>
> It's an incremental EM idea that reduces the amount of work lmer() (or any iterative maximization procedure) would need to do with a very large file. In other words, why start all over again with a very big file when we can start somewhere better and let the algorithm start closer to the top of the hill, so to speak.
>
> Hope it helps.
> Harold
>
>
>
> -----Original Message-----
> From: R-sig-mixed-models 
> <r-sig-mixed-models-bounces at r-project.org<mailto:r-sig-mixed-models-bo
> unces at r-project.org>> On Behalf Of Jad Moawad
> Sent: Thursday, December 10, 2020 7:12 AM
> To: 
> r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.o
> rg>
> Subject: [R-sig-ME] Question regarding large data.frame in LMER?
>
> External email alert: Be wary of links & attachments.
>
>
> I am working with a large data.frame that contains around 1.4 million observations. Initially when i was running my models, i was working on a sub-sample (10% of my full-sample). This is because running one model can take a lot of time using the original data. Once i was sure that all variables are well harmonized and all regressions were running fine, i ran my models using the full sample. However, the regression did not converge and i received the following two errors from two different models:
>
> Error in fun(xaa, ...) : Downdated VtV is not positive definite
>
> Error in fun(xss, ...) : Downdated VtV is not positive definite
>
> I use the lmer function to fit my model and i include a random slopes at the country and country_year level. Below you find the code that i use.
>
> Model1 <- lmer(health~ class + age + I(age^2)  + class*macro_unemployment +
>                (class + age + I(age^2)|country) +
>                (class+ age + I(age^2) |country_year) +
>                (1|id), data=df)
>
> Model2 <- lmer(health~ education + age + I(age^2)  + education*macro_unemployment+
>                (education + age + I(age^2)|country) +
>                (education + age + I(age^2) |country_year) +
>                (1|id), data=df)
>
>
> Could someone help me please with solving this issue?
>
> Below you find a glimpse (str) of my data and my sessionInfo():
>
> tibble [1,370,264   8] (S3: grouped_df/tbl_df/tbl/data.frame)
>  $ health            : num [1:1370264] 100 100 50 100 0 75 75 100 100 50 ...
>  $ class             : Factor w/ 3 levels "Upper-middle class",..: 3 3 NA 3 3 3 3 1 1 3 ...
>  $ education         : Factor w/ 3 levels "low","mid","high": 1 1 1 1 1 1 2 3 3 1 ...
>  $ age               : num [1:1370264] 24 25 24 25 42 43 34 34 35 58 ...
>  $ macro_unemployment: num [1:1370264] 5.24 4.86 5.24 4.86 5.24 ...
>  $ id                : int [1:1370264] 2 2 3 3 4 4 6 7 7 8 ...
>  $ country_year      : int [1:1370264] 1 2 1 2 1 2 1 1 2 1 ...
>  $ country           : Factor w/ 30 levels "Austria","Belgium",..: 1 1 1 1 1 1 1 1 1 1 ...
>  - attr(*, "groups")= tibble [27   2] (S3: tbl_df/tbl/data.frame)
>   ..$ country: Factor w/ 30 levels "Austria","Belgium",..: 1 2 3 6 7 8 9 10 11 12 ...
>   ..$ .rows  : list<int> [1:27]
>   .. ..$ : int [1:47204] 1 2 3 4 5 6 7 8 9 10 ...
>   .. ..$ : int [1:41361] 47205 47206 47207 47208 47209 47210 47211 47212 47213 47214 ...
>   .. ..$ : int [1:42407] 88566 88567 88568 88569 88570 88571 88572 88573 88574 88575 ...
>   .. ..$ : int [1:48253] 130973 130974 130975 130976 130977 130978 130979 130980 130981 130982 ...
>   .. ..$ : int [1:31917] 179226 179227 179228 179229 179230 179231 179232 179233 179234 179235 ...
>   .. ..$ : int [1:44047] 211143 211144 211145 211146 211147 211148 211149 211150 211151 211152 ...
>   .. ..$ : int [1:62087] 255190 255191 255192 255193 255194 255195 255196 255197 255198 255199 ...
>   .. ..$ : int [1:94309] 317277 317278 317279 317280 317281 317282 317283 317284 317285 317286 ...
>   .. ..$ : int [1:37246] 411586 411587 411588 411589 411590 411591 411592 411593 411594 411595 ...
>   .. ..$ : int [1:77253] 448832 448833 448834 448835 448836 448837 448838 448839 448840 448841 ...
>   .. ..$ : int [1:16823] 526085 526086 526087 526088 526089 526090 526091 526092 526093 526094 ...
>   .. ..$ : int [1:24687] 542908 542909 542910 542911 542912 542913 542914 542915 542916 542917 ...
>   .. ..$ : int [1:116263] 567595 567596 567597 567598 567599 567600 567601 567602 567603 567604 ...
>   .. ..$ : int [1:43218] 683858 683859 683860 683861 683862 683863 683864 683865 683866 683867 ...
>   .. ..$ : int [1:28709] 727076 727077 727078 727079 727080 727081 727082 727083 727084 727085 ...
>   .. ..$ : int [1:27583] 755785 755786 755787 755788 755789 755790 755791 755792 755793 755794 ...
>   .. ..$ : int [1:77960] 783368 783369 783370 783371 783372 783373 783374 783375 783376 783377 ...
>   .. ..$ : int [1:36922] 861328 861329 861330 861331 861332 861333 861334 861335 861336 861337 ...
>   .. ..$ : int [1:93194] 898250 898251 898252 898253 898254 898255 898256 898257 898258 898259 ...
>   .. ..$ : int [1:9004] 991444 991445 991446 991447 991448 991449 991450 991451 991452 991453 ...
>   .. ..$ : int [1:40074] 1000448 1000449 1000450 1000451 1000452 1000453 1000454 1000455 1000456 1000457 ...
>   .. ..$ : int [1:29342] 1040522 1040523 1040524 1040525 1040526 1040527 1040528 1040529 1040530 1040531 ...
>   .. ..$ : int [1:85124] 1069864 1069865 1069866 1069867 1069868 1069869 1069870 1069871 1069872 1069873 ...
>   .. ..$ : int [1:92350] 1154988 1154989 1154990 1154991 1154992 1154993 1154994 1154995 1154996 1154997 ...
>   .. ..$ : int [1:50188] 1247338 1247339 1247340 1247341 1247342 1247343 1247344 1247345 1247346 1247347 ...
>   .. ..$ : int [1:7598] 1297526 1297527 1297528 1297529 1297530 1297531 1297532 1297533 1297534 1297535 ...
>   .. ..$ : int [1:65141] 1305124 1305125 1305126 1305127 1305128 1305129 1305130 1305131 1305132 1305133 ...
>   .. ..@ ptype: int(0)
>   ..- attr(*, ".drop")= logi TRUE
>>
>
>
> Session Info:
>
> R version 4.0.2 (2020-06-22)
> Platform: x86_64-apple-darwin17.0 (64-bit) Running under: macOS 
> Catalina 10.15.6
>
> Matrix products: default
> BLAS:   /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libBLAS.dylib
> LAPACK: 
> /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.
> dylib
>
> locale:
> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>
> attached base packages:
> [1] stats     graphics  grDevices
> [4] utils     datasets  methods
> [7] base
>
> other attached packages:
>  [1] sessioninfo_1.1.1
>  [2] sjlabelled_1.1.5
>  [3] varhandle_2.0.5
>  [4] labelled_2.7.0
>  [5] dplyr_1.0.0
>  [6] ggplot2_3.3.2
>  [7] forcats_0.5.0
>  [8] reprex_0.3.0
>  [9] lmerTest_3.1-3
> [10] lme4_1.1-25
> [11] Matrix_1.2-18
>
> loaded via a namespace (and not attached):
>  [1] Rcpp_1.0.4.6
>  [2] compiler_4.0.2
>  [3] pillar_1.4.4
>  [4] nloptr_1.2.2.1
>  [5] tools_4.0.2
>  [6] digest_0.6.25
>  [7] boot_1.3-25
>  [8] statmod_1.4.34
>  [9] lifecycle_0.2.0
> [10] tibble_3.0.1
> [11] nlme_3.1-148
> [12] gtable_0.3.0
> [13] lattice_0.20-41
> [14] pkgconfig_2.0.3
> [15] rlang_0.4.7
> [16] cli_2.0.2
> [17] rstudioapi_0.11
> [18] haven_2.3.1
> [19] withr_2.2.0
> [20] hms_0.5.3
> [21] generics_0.0.2
> [22] vctrs_0.3.1
> [23] fs_1.4.1
> [24] grid_4.0.2
> [25] tidyselect_1.1.0
> [26] glue_1.4.1
> [27] R6_2.4.1
> [28] fansi_0.4.1
> [29] minqa_1.2.4
> [30] farver_2.0.3
> [31] purrr_0.3.4
> [32] magrittr_1.5
> [33] scales_1.1.1
> [34] ellipsis_0.3.1
> [35] MASS_7.3-51.6
> [36] splines_4.0.2
> [37] insight_0.11.0
> [38] assertthat_0.2.1
> [39] colorspace_1.4-1
> [40] numDeriv_2016.8-1.1
> [41] labeling_0.3
> [42] utf8_1.1.4
> [43] munsell_0.5.0
> [44] crayon_1.3.4
>
>
>
>
> Sincerely,
>
>
>
> Jad Moawad
>
>
> PhD candidate and teaching assistant
> University of Lausanne  - NCCR Lives
> Institut des Sciences Sociales
> B timent Geopolis - 5621
> 1015 Lausanne
> Switzerland
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.o
> rg> mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.o
> rg> mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>       [[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From me @end|ng |rom ph||||p@|d@y@com  Tue Dec 15 23:40:20 2020
From: me @end|ng |rom ph||||p@|d@y@com (Phillip Alday)
Date: Tue, 15 Dec 2020 23:40:20 +0100
Subject: [R-sig-ME] Pulling specific parameters from models to prevent
 exhausting memory.
In-Reply-To: <BY5PR19MB3859498E5E7D1EE81DFE7B38EA000@BY5PR19MB3859.namprd19.prod.outlook.com>
References: <BY5PR19MB3859498E5E7D1EE81DFE7B38EA000@BY5PR19MB3859.namprd19.prod.outlook.com>
Message-ID: <59467869-1c81-b37d-ab3c-706e525f5025@phillipalday.com>

Hi James,

I missed this discussion early on, but Cesko's suggestion is pretty
good. Your problem is also the type of thing that Benedikt Ehinger, Dave
Kleinschmidt and I have been tinkering around with in Julia using
Benedikt's unfold.jl toolbox, which in turn uses MixedModels.jl for
fitting the models. As discussed in other threads on this list recently,
we have a few tricks up our sleeves on the Julia side that allows us to
be a bit more efficient in memory than lme4 when fitting the model.
Using my JellyMe4 package, it's also possible to convert the Julia fit
back to an lme4 fit, if you want to do that to take advantage of all the
excellent tooling around lme4 in R.

I decided to take a quick stab at your model and found a few things:

1. Your data were still in wide format; maybe mention that next time ;)
2. The data only had one timepoint, so I couldn't test them at scale
3. ROI should realistically be a grouping variable and not a categorical
fixed effect for these data -- it seems that you have tens of thousands
of levels (which isn't surprising for fMRI).
4. If you have some sparsity in the fixed effects, that may be something
we can take advantage of, but that wasn't completely clear to me in the
5 minutes I spent on this.

My quick Julia attempt can be found here:

https://github.com/palday/ades-fmri-lmm

Best,
Phillip


On 18/10/20 2:00 am, Ades, James wrote:
> Hi all,
> 
> I'm modeling fMRI imaging data using lme4. There are 4 time points and roughly 550 subjects with 27,730 regions of interest (these are the variables). Since I have access to a super computer, my thought was to create a long dataset with a repeated measures of regions of interest per time point and then subjects over the 4 time points. I'm using the model below. I gather the regions of interest using the super computer because it ends up being roughly 70 million something observations. Timepoint is discrete and timepoint.nu is just numerical time point.
> 
> lmer(connectivity ~ roi * timepoint + (timepoint.nu|subjectID) + (timepoint.nu|subjectID:roi), na.action = 'na.exclude', control = lmerControl(optimizer = "nloptwrap", calc.derivs = FALSE), REML = FALSE, data)
> 
> I received back the following error: "cannot allocate vector of size 30206.2 GbExecution halted"
> 
> So I'm wondering how I can only pull the essential parameters I need (group means vs individual fixed effects) while modeling, such that the super computer can finish the job without exhausting the memory. I say group means because I will eventually be adding in covariates.
> 
> Also, the super computer rules are that the job must finish within two days. I'm not sure that this would, so I'm wondering whether there is any way to parallel code in lme4 such that I could make access of multiple cores and nodes.
> 
> I've included a slice of data here: https://drive.google.com/file/d/1mhTj6qZZ2nT35fXUuYG_ThQ-QtWbb-8L/view?usp=sharing
> 
> Thanks much,
> 
> James
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From me @end|ng |rom ph||||p@|d@y@com  Tue Dec 15 23:47:50 2020
From: me @end|ng |rom ph||||p@|d@y@com (Phillip Alday)
Date: Tue, 15 Dec 2020 23:47:50 +0100
Subject: [R-sig-ME] Reporting den of df for f like AOV table using
 Sattertwaite's method
In-Reply-To: <CAJTPX_WPjYQibFU+mwi+Y5msUpM6Xvf8Vhq74Mi93+UQBfRMyw@mail.gmail.com>
References: <CAJTPX_WPjYQibFU+mwi+Y5msUpM6Xvf8Vhq74Mi93+UQBfRMyw@mail.gmail.com>
Message-ID: <87903af9-64ce-2afc-e9eb-ff6217607eb7@phillipalday.com>

I didn't see an answer go past for this question yet so let me make a
few comments:


- If your ddf are that large, then the F distribution is very close to a
chi-squared distribution and the approximation used by e.g.
car::Anova(model, KR=FALSE) will be faster and nearly as accurate.

- (This is why one of the suggested ways for dealing with the missing
p-values in lme4 is to simply treat the t values as z values -- at some
point with a few tens of groups and a few hundreds of observations, the
effective degrees of freedom are so large that you can treat them as
infinite and thus t -> z and F -> chi-square)

- If you decide to stick with the F distribution, then you need to
report all digits of your ddf before the decimal point and maybe 1 or 2
after the decimal point (if they aren't integers).

Best,
Phillip


On 19/10/20 7:00 am, Salahadin Lotfi wrote:
> Hi everyone,
> I have run several MLM models with over 200,000 observations. I intend to
> report f values calculated using lmerTest package for each model
> (Sattertwaite's method). I am trying to learn best practices to report
> denominators of df estimated by Sattertwaite's method as I am reporting
> usual f(NumDF, DenDF)=xxx. The obtained den of df is pretty large and I am
> not sure it does make sense to report 6 digits values. I have run several
> of these models and it takes a big chunk of the result section if I keep
> reporting 6 digits.
> I am also aware that many researchers report beta/ES/t/z estimates,
> however, it makes sense to report f values in the context of my study,
> hence I am here with my question. :-)
> 
> What is the best practice when it comes to report pretty large DenDF of f
> models?
> 
> Any input will be greatly appreciated.
> 
> Thanks,
> Sala
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From me @end|ng |rom ph||||p@|d@y@com  Wed Dec 16 00:17:23 2020
From: me @end|ng |rom ph||||p@|d@y@com (Phillip Alday)
Date: Wed, 16 Dec 2020 00:17:23 +0100
Subject: [R-sig-ME] How to report and quantify the random effect in a
 logistic model?
In-Reply-To: <CAEQWovSyCXO+SmQEgsdKTieFXFs0CWMAOtHphSjJy5Li14txJw@mail.gmail.com>
References: <CAEQWovSyCXO+SmQEgsdKTieFXFs0CWMAOtHphSjJy5Li14txJw@mail.gmail.com>
Message-ID: <29e6bfd3-8c82-c977-8d64-62fcbe11fee4@phillipalday.com>

To get the confidence intervals from the random effects, you need to
either use profiling or bootstrapping. Variances -- like the random
effects -- tend to have very skewed sampling distributions, so symmetric
(Wald) confidence intervals based on standard errors don't make sense.

I wouldn't back transform the RE estimates. They are meaningful in their
own right as the variance between groups. For example, in your model,
the random effect for CITY is just the variance of (1.5) between the
intercepts for cities. I would just report the model summary as a table,
but I guess you could also write something like "The standard deviation
of distribution of the intercept between cities was 3.1" but that seems
very awkward to me.

For something like "proportion of variance explained", you're looking
for something like a standardized effect size, but that is *very*
difficult to define in a meaningful way for GLMs and LMMs and thus
doubly so for GLMMs. Henrik Singmann has a nice way to explain the issue
briefly to reviewers
(https://afex.singmann.science/forums/topic/compute-effect-sizes-for-mixed-objects#post-295)
and links to the larger GLMM FAQ question on that section.

Best,
Phillip



On 2/12/20 8:01 pm, Pi wrote:
> Hello.
> 
> I'm fitting a logistic regression model with mixed effects using the
> package glmmTMB. (Because the dataset is quite large and lme4 produces out
> of memory errors, even increasing memory.limit).
> 
> I need help to interpret and report the output.
> 
>     Family: binomial  ( logit )
>     Formula:      OUTPUT ~ SEX + YEAR + OTHER +  (1|CITY/ID)
>     Data: mydata
> 
>           AIC       BIC    logLik  deviance  df.resid
>      890000  891000 -450000  889000    1000000
> 
>     Random effects:
> 
>     Conditional model:
>      Groups Name        Variance Std.Dev.
>      ID:CITY (Intercept) 10.0    3.1
>      CITY    (Intercept) 1.5    1.2
>     Number of obs: 1000009, groups:  ID:CITY, 200000; CITY, 20
> 
>     Conditional model:
>                  Estimate Std.Error z value Pr(>|z|)
>     (Intercept)  0.79   0.28    2.9   0.005
>     SEX1       -0.21   0.017 -12   <2e-16
>     YEAR        0.48   0.0048 100   <2e-16
>     OTHER       -0.70   0.005 -130   <2e-16
> 
> Output from sjPlot:
> 
>     Random Effects
>     ?2 3.29
>     ?00 ID:CITY 10.0
>     ?00 CITY 1.5
>     ICC 0.78
> 
> 
> How can I report the effect of CITY and its confidence interval?
> I think most people would report the CI of the odds of the Intercept using
> the variance to calculate
> 
>      { exp(Intercept-1.96*1.2) , exp(Intercept+1.96*1.2) }
> 
> but this doesn't take into account the standard error of the Intercept from
> the conditional model, 0.28. How should I combine them?
> (I think this is the estimated deviation for the Intercept excluding the
> random effects).
> 
> Is it acceptable to ignore the Intercept value and just say...?
> "The 95% CI for the odds ratio for the CITY is
> {exp(-1.96\*1.2),exp(+1.96\*1.2)}"
> 
> or
> 
> "The odds of OUTPUT is multiplied by a number between exp(-1.96\*1.2) and
> exp(+1.96\*1.2) due to the variability of CITY". I don't know how to
> include here the 95%IC argument.
> 
> I have also tried to calculate the residuals with residuals(model) but it
> produces an out of memory error.
> Is there any way to do it approximately? or is there already some useful
> information in the output?
> 
> I just need to say what proportion of the total variance (or of the
> residuals) is explained by the variable CITY.
> 
> The ?2 value reported by sjPlot is the variance of the residuals.
> 
> What about the variance of ID:CITY (Intercept) 10.0? How should I report
> it? How can I split it into variance due to ID and variance due to the
> interaction of ID and CITY?
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From D@v|d@Du||y @end|ng |rom q|mrbergho|er@edu@@u  Wed Dec 16 00:42:49 2020
From: D@v|d@Du||y @end|ng |rom q|mrbergho|er@edu@@u (David Duffy)
Date: Tue, 15 Dec 2020 23:42:49 +0000
Subject: [R-sig-ME] Question regarding large data.frame in LMER?
In-Reply-To: <46192629068c4cdaa08e5bcbd856e69c@cambiumassessment.com>
References: <bbb6420ece704ba795b95f7a446c5b53@unil.ch>
 <76a26ccefdb54623a345e5a48c01c482@cambiumassessment.com>
 <9688_1607683706_0QL600JKI8OPJL00_4b20de81a4324407b523c38f5ce68fb2@hum.leidenuniv.nl>
 <CAO7JsnQzCYt11tZsTyV=w6E=6nUCrYi_qh-N6kvofESSGQAoAg@mail.gmail.com>
 <433e49985c684454827f0ac493198d75@unil.ch>
 <d9545047222c44bf86bc6509856d934d@cambiumassessment.com>
 <54f42719-99e8-bc6f-24aa-abd8316d2989@phillipalday.com>,
 <46192629068c4cdaa08e5bcbd856e69c@cambiumassessment.com>
Message-ID: <f43db351581b40f0a30b7c1d6cf642d6@qimrberghofer.edu.au>

I have not done any comparisons versus other programs, but:

https://mran.microsoft.com/package/HMMEsolver

where the algorithm is described in
Kim (2017) A Fast Algorithm for Solving Henderson's Mixed Model Equation
https://arxiv.org/pdf/1710.09663

From b@te@ @end|ng |rom @t@t@w|@c@edu  Wed Dec 16 17:16:24 2020
From: b@te@ @end|ng |rom @t@t@w|@c@edu (Douglas Bates)
Date: Wed, 16 Dec 2020 10:16:24 -0600
Subject: [R-sig-ME] Question regarding large data.frame in LMER?
In-Reply-To: <3998_1608076089_0QLE005HUNG80Z40_f43db351581b40f0a30b7c1d6cf642d6@qimrberghofer.edu.au>
References: <bbb6420ece704ba795b95f7a446c5b53@unil.ch>
 <76a26ccefdb54623a345e5a48c01c482@cambiumassessment.com>
 <9688_1607683706_0QL600JKI8OPJL00_4b20de81a4324407b523c38f5ce68fb2@hum.leidenuniv.nl>
 <CAO7JsnQzCYt11tZsTyV=w6E=6nUCrYi_qh-N6kvofESSGQAoAg@mail.gmail.com>
 <433e49985c684454827f0ac493198d75@unil.ch>
 <d9545047222c44bf86bc6509856d934d@cambiumassessment.com>
 <54f42719-99e8-bc6f-24aa-abd8316d2989@phillipalday.com>
 <46192629068c4cdaa08e5bcbd856e69c@cambiumassessment.com>
 <3998_1608076089_0QLE005HUNG80Z40_f43db351581b40f0a30b7c1d6cf642d6@qimrberghofer.edu.au>
Message-ID: <CAO7JsnQvuc2MRmGEET5QU9021-HLAG9sxC2DdbAwy7s_JpQ8bQ@mail.gmail.com>

A point that gets lost in these discussions is that there is more to the
calculation than solving, e.g., Henderson's mixed-model equations.  The
method that is used in lme4 evaluates a profiled log-likelihood from the
solution to a sparse penalized least squares problem.  This is described in
our 2015 J. Stat. Soft. paper.

One innovation in the MixedModels.jl is to extend this penalized least
squares problem to a blocked system that incorporates the fixed-effects
model matrix and the response in addition to the random-effects model
matrix.  Again sparsity in the random-effects model matrix is exploited but
using sparse patterns (diagonal or block diagonal) rather than general
sparse matrix techniques.  It turns out that it is not necessary to "solve"
any equations when evaluating the profiled log-likelihood.  It is only
necessary to update the blocked Cholesky factor.  (This isn't as big a win
as it may seem because most of the work in solving for the conditional
estimates of the fixed-effects and the conditional modes of the random
effects is in updating the Cholesky factor).  If you look at the code in
the MixedModels.jl package it is literally a matter of installing a new
value of the covariance parameter (written ? in both lme4 and
MixedModels.jl), updating the Cholesky factor L and adding up logarithms of
elements on the diagonal.

With regard to Harold's point of using Microsoft R, in my experience there
is a big gain in using MKL BLAS on Intel processors relative to using
OpenBLAS which is the default for Julia.  One benchmark I keep running for
myself takes a little over 7 ms. per evaluation on my computer with
OpenBLAS and a little over 4 ms. per evaluation using MKL.  One thing to
note is that the optimum is different when using MKL, in this case.  When
you rearrange the order of operations in the numerical linear algebra in
these multi-threaded BLAS you can get slightly different answers which, in
this case, leads to a different optimum.

I believe that R still ships with the reference, single-threaded BLAS so
the difference in switching to MKL could be even more dramatic on modern
multi-core processors.

The point that I am trying to make here is that the numerical methods
should be judged first on accuracy and reliability of the method and then
on speed to obtain the estimate not just on solving one system of
equations.  One difference between generalized least squares (Henderson's
mixed-model equations) and the penalized least squares approach in
lme4/MixedModels is that GLS is usually written in terms of the precision
matrix (inverse of the covariance matrix) of the random effects whereas we
formulate the PLS approach in terms of the Cholesky factor of the
covariance matrix.  The covariance matrix of the random effects can be and
often is singular at the estimates in over-parameterized models.  In those
cases you can't use the precision matrix because it doesn't exist.


On Tue, Dec 15, 2020 at 5:48 PM David Duffy <
David.Duffy at qimrberghofer.edu.au> wrote:

> I have not done any comparisons versus other programs, but:
>
> https://mran.microsoft.com/package/HMMEsolver
>
> where the algorithm is described in
> Kim (2017) A Fast Algorithm for Solving Henderson's Mixed Model Equation
> https://arxiv.org/pdf/1710.09663
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From @ch|@023 @end|ng |rom uott@w@@c@  Thu Dec 17 17:19:27 2020
From: @ch|@023 @end|ng |rom uott@w@@c@ (Sarah Patricia Chisholm)
Date: Thu, 17 Dec 2020 16:19:27 +0000
Subject: [R-sig-ME] Interpret the output of a Tweedie GLMM
Message-ID: <QB1PR01MB38127F7A9FED5159BE89AA34E8C40@QB1PR01MB3812.CANPRD01.PROD.OUTLOOK.COM>

Hello,

I recently posted a question on Cross Validated<https://stats.stackexchange.com/questions/500855/interpret-the-output-of-a-tweedie-glmm> but haven't had any responses yet and figured I would try here. I've copied and pasted my CV question below.

I've fit the following glmm using the glmmTMB package with the tweedie(link = "log") distribution, where y is a positive, continuous DV with a large number of zeros, x is a continuous IV and z is a categorical IV with two levels (A & B). Random factor a and a spatial correlation term are also included:


library(glmmTMB)
df$pos <- numFactor(df$LONG,df$LAT)
df$group <- factor(1)

m <- glmmTMB(y ~ x*z + (1|a) + exp(0 + pos|group),
                 family = tweedie(),
                 data = df,
                 REML = TRUE)

Here's some simplified output:

               Estimate Std. Error z value Pr(>|z|)
(Intercept)   3.669e+01  1.007e+01   3.644 0.000269 ***
x            -1.838e-02  5.007e-03  -3.672 0.000241 ***
zB           -3.149e+00  1.695e+01  -0.186 0.852592
x:zB          1.574e-03  8.435e-03   0.187 0.851962


My question is how do I interpret these parameter estimates? For example, if IV x represents time in years, is there simply a -0.01838 response in y each year (when z = A)? Or, because of the log link, do I need to apply a transformation to these parameter estimates for interpretation?


Thanks everyone,


Sarah

Sarah Chisholm
MSc Biology Candidate
Department of Biology
University of Ottawa
Linkedin<https://www.linkedin.com/in/sarah-chisholm-422a5785/>

	[[alternative HTML version deleted]]


From @||@ogh@b|@n @end|ng |rom he|@|nk|@||  Fri Dec 18 11:59:56 2020
From: @||@ogh@b|@n @end|ng |rom he|@|nk|@|| (Oghabian, Ali)
Date: Fri, 18 Dec 2020 10:59:56 +0000
Subject: [R-sig-ME] lmer analysis of identical twins data
Message-ID: <HE1PR0701MB2714A217C9213852444F18E683C30@HE1PR0701MB2714.eurprd07.prod.outlook.com>

Hi all!

I have a question related to using lmer() function of lme4 package in identical twins' studies which I would appreciate if you could answer.

We have PFAS measured pollution dataset constructed of ~50 (n=100) monozygotic (identical) twins. The goal is to detect the significantly differential PFAS pollutants between the leaner individuals (L) and those individuals with obesity (F):

1. As a solution, I was planning to run lmer() to run differential PFAS levels while adjusting for the sex, age (young/old) and the sample extraction year. As a random effect I was thinking to use the family IDs (i.e. extreme similarities between the individuals that is caused by 'twinship'). Therefore, I am using the design model as 'pfasLogStandardized ~  LF + sex + youngOrOld + yearClass +  (1 | familyID)'. However, I am wondering whether this is the best approach since considering the 'twinship' as a random effect means that the sample size within each of the random effects will be 2 (since it is family IDs of the 'twins') ! It seems like due to small sample size the fitted regressions will feature high variances. I was wondering if this the best approach in your opinion. Note that twinship or family ID is not completely independent from sex and age since identical twins have also the same sex and age.

2. The alternative approach that comes to my mind is to not adjust for familyID (or twinship) but to run ANOVA or student-t test and adjust for 'pfasLogStandardized ~  LF + sex + youngOrOld + yearClass'. Here the problem is that the analysis will not be adjusting for the extreme similarities between the twins.

3. Another approach is to swap the formula in lmer and to adjust for familyID as covariate and to consider a factor with combined info of age-sex-year as random effect, e.g. s.th. like 'pfasLogStandardized ~  LF + familyID + (1 | RandFact)' , while RandFact = as.factor(paste(sex , youngOrOld , yearClass)) .

I would really appreciate your opinion on this issue and on, overall, what is the best way to run these kinds of analyses on identical twins' data while adjusting for the extreme similarities of the twins.

Cheers,

	[[alternative HTML version deleted]]


From D@v|d@Du||y @end|ng |rom q|mrbergho|er@edu@@u  Mon Dec 21 02:22:47 2020
From: D@v|d@Du||y @end|ng |rom q|mrbergho|er@edu@@u (David Duffy)
Date: Mon, 21 Dec 2020 01:22:47 +0000
Subject: [R-sig-ME] lmer analysis of identical twins data
In-Reply-To: <HE1PR0701MB2714A217C9213852444F18E683C30@HE1PR0701MB2714.eurprd07.prod.outlook.com>
References: <HE1PR0701MB2714A217C9213852444F18E683C30@HE1PR0701MB2714.eurprd07.prod.outlook.com>
Message-ID: <93f023deae5347cdb6855c835c9bc1dc@qimrberghofer.edu.au>


________________________________________
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of Oghabian, Ali <ali.oghabian at helsinki.fi>
Sent: Friday, 18 December 2020 8:59:56 PM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] lmer analysis of identical twins data

Hi all!

I have a question related to using lmer() function of lme4 package in identical twins' studies which I would appreciate if you could answer.

We have PFAS measured pollution dataset constructed of ~50 (n=100) monozygotic (identical) twins. The goal is to detect the significantly differential PFAS pollutants between the leaner individuals (L) and those individuals with obesity (F):

1. As a solution, I was planning to run lmer() to run differential PFAS levels while adjusting for the sex, age (young/old) and the sample extraction year. As a random effect I was thinking to use the family IDs (i.e. extreme similarities between the individuals that is caused by 'twinship'). Therefore, I am using the design model as 'pfasLogStandardized ~  LF + sex + youngOrOld + yearClass +  (1 | familyID)'. However, I am wondering whether this is the best approach since considering the 'twinship' as a random effect means that the sample size within each of the random effects will be 2 (since it is family IDs of the 'twins') ! It seems like due to small sample size the fitted regressions will feature high variances. I was wondering if this the best approach in your opinion. Note that twinship or family ID is not completely independent from sex and age since identical twins have also the same sex and age.

2. The alternative approach that comes to my mind is to not adjust for familyID (or twinship) but to run ANOVA or student-t test and adjust for 'pfasLogStandardized ~  LF + sex + youngOrOld + yearClass'. Here the problem is that the analysis will not be adjusting for the extreme similarities between the twins.

3. Another approach is to swap the formula in lmer and to adjust for familyID as covariate and to consider a factor with combined info of age-sex-year as random effect, e.g. s.th. like 'pfasLogStandardized ~  LF + familyID + (1 | RandFact)' , while RandFact = as.factor(paste(sex , youngOrOld , yearClass)) .

I would really appreciate your opinion on this issue and on, overall, what is the best way to run these kinds of analyses on identical twins' data while adjusting for the extreme similarities of the twins.

Cheers,

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
[EXTERNAL EMAIL] This message originates from an external email address, please exercise caution when clicking any links or opening attachments. If you believe the sender is impersonating someone at QIMR Berghofer, please forward this message to phishing at qimrberghofer.edu.au.


From D@v|d@Du||y @end|ng |rom q|mrbergho|er@edu@@u  Mon Dec 21 02:33:11 2020
From: D@v|d@Du||y @end|ng |rom q|mrbergho|er@edu@@u (David Duffy)
Date: Mon, 21 Dec 2020 01:33:11 +0000
Subject: [R-sig-ME] lmer analysis of identical twins data
In-Reply-To: <HE1PR0701MB2714A217C9213852444F18E683C30@HE1PR0701MB2714.eurprd07.prod.outlook.com>
References: <HE1PR0701MB2714A217C9213852444F18E683C30@HE1PR0701MB2714.eurprd07.prod.outlook.com>
Message-ID: <6d30a267d2ac47ec9d5accbeb7e5bcd8@qimrberghofer.edu.au>

> We have PFAS measured pollution dataset constructed of ~50 (n=100) monozygotic (identical) twins. 
> The goal is to detect the significantly differential PFAS pollutants between the leaner individuals (L) and 
> those individuals with obesity (F):

>  'pfasLogStandardized ~  LF + sex + youngOrOld + yearClass +  (1 | familyID)'.

This is the correct approach, given this is a cotwin-control design. You might first check the magnitude of the twin intraclass correlation, but I think it very unlikely that you can ignore genetics and shared environment. How has zygosity been diagnosed? The model can be extended if you have dizygotic twins present as well.

Cheers, David Duffy.

From mm@|ten @end|ng |rom gm@||@com  Thu Dec 24 02:19:59 2020
From: mm@|ten @end|ng |rom gm@||@com (Mitchell Maltenfort)
Date: Wed, 23 Dec 2020 20:19:59 -0500
Subject: [R-sig-ME] Efficient mixed logistic reg w 500k individuals
Message-ID: <CANOgrHaBAk8LCie-wMWQcZqV86GRCjQF+5UQyAgfhYjOdu5Jhw@mail.gmail.com>

Here?s a fun one for you (I hope)

I?m mucking about with a logistic regression that may have about 30 million
records for half a million individuals.

Yes, I have a large RAM machine - 64 Gig.  And I?ve used nAGQ 0 and other
recommendations from
http://angrystatistician.blogspot.com/2015/10/mixed-models-in-r-bigger-faster-stronger.html?m=1
 which should be reasonable for the large data.

It works but I?d still be interested in tweaks to improve speed or
accuracy.  Any ideas?
-- 
Sent from Gmail Mobile

	[[alternative HTML version deleted]]


From d|@n@m|ch| @end|ng |rom @|kq@de  Thu Dec 24 12:21:11 2020
From: d|@n@m|ch| @end|ng |rom @|kq@de (Diana Michl)
Date: Thu, 24 Dec 2020 12:21:11 +0100
Subject: [R-sig-ME] Regression analysis with small but complete dataset
 (fully representing reality)?
Message-ID: <8fe547b7-8cac-e473-6030-ba30553809e6@aikq.de>

I have a repeated measures design with about 16 cases and 5-6 points of 
measuring. Sometimes, 1-4 full cases or some points of measure are 
missing. (The measures are 20 numerical and categorical data taken from 
questionnaires.)

The clue is: It's a small dataset with holes in it, but the 16 cases are 
all that even exist. So they fully represent reality wherever they're 
complete.

I wanted to run logistic regressions with up to 6 predictors. But can I 
do that? I know about the many problems such small datasets have for 
regression analysis - but do they matter as much if there aren't any 
more cases in reality?
Are descriptive analyses the only ones I can use?

Many thanks

-- 
Dr. Diana Michl
#www.diana-michl.de

#Film: Der unber?hrte Garten - eine ungew?hnliche Geschichte ?bers 
Erwachsenwerden (www.vimeo.com/148014360)

#Musik: Singer-Songwriter (www.youtube.com/user/ghiaghiafy)


	[[alternative HTML version deleted]]


From m@|one @end|ng |rom m@|onequ@nt|t@t|ve@com  Thu Dec 24 17:22:42 2020
From: m@|one @end|ng |rom m@|onequ@nt|t@t|ve@com (Patrick (Malone Quantitative))
Date: Thu, 24 Dec 2020 11:22:42 -0500
Subject: [R-sig-ME] Regression analysis with small but complete dataset
 (fully representing reality)?
In-Reply-To: <8fe547b7-8cac-e473-6030-ba30553809e6@aikq.de>
References: <8fe547b7-8cac-e473-6030-ba30553809e6@aikq.de>
Message-ID: <CAJc=yOFBCg6DAv=zu6UX0CcnyMYyWDFDxna=7sUago-HER9R6g@mail.gmail.com>

Diana,

It depends on the nature of the missing. Are the present values the only
ones that could exist? If so, you have the entire population's data, and
descriptive statistics are in fact preferable to inferential ones. There's
no need to run inferential statistics if you have the population--they are
by definition for inferring population values from a sample.

Pat

On Thu, Dec 24, 2020 at 6:21 AM Diana Michl <dianamichl at aikq.de> wrote:

> I have a repeated measures design with about 16 cases and 5-6 points of
> measuring. Sometimes, 1-4 full cases or some points of measure are
> missing. (The measures are 20 numerical and categorical data taken from
> questionnaires.)
>
> The clue is: It's a small dataset with holes in it, but the 16 cases are
> all that even exist. So they fully represent reality wherever they're
> complete.
>
> I wanted to run logistic regressions with up to 6 predictors. But can I
> do that? I know about the many problems such small datasets have for
> regression analysis - but do they matter as much if there aren't any
> more cases in reality?
> Are descriptive analyses the only ones I can use?
>
> Many thanks
>
> --
> Dr. Diana Michl
> #www.diana-michl.de
>
> #Film: Der unber?hrte Garten - eine ungew?hnliche Geschichte ?bers
> Erwachsenwerden (www.vimeo.com/148014360)
>
> #Musik: Singer-Songwriter (www.youtube.com/user/ghiaghiafy)
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


-- 
Patrick S. Malone, Ph.D., Malone Quantitative
NEW Service Models: http://malonequantitative.com

He/Him/His

	[[alternative HTML version deleted]]


From m@|one @end|ng |rom m@|onequ@nt|t@t|ve@com  Fri Dec 25 18:07:17 2020
From: m@|one @end|ng |rom m@|onequ@nt|t@t|ve@com (Patrick (Malone Quantitative))
Date: Fri, 25 Dec 2020 12:07:17 -0500
Subject: [R-sig-ME] Regression analysis with small but complete dataset
 (fully representing reality)?
In-Reply-To: <25316b9a-977f-8ef6-93fd-f1426fbe1ba7@aikq.de>
References: <8fe547b7-8cac-e473-6030-ba30553809e6@aikq.de>
 <CAJc=yOFBCg6DAv=zu6UX0CcnyMYyWDFDxna=7sUago-HER9R6g@mail.gmail.com>
 <25316b9a-977f-8ef6-93fd-f1426fbe1ba7@aikq.de>
Message-ID: <CAJc=yOHpb7FXj7qf4AnHu_yzjq36irsCnkCCGz_QOBjz=cFsZQ@mail.gmail.com>

Diana,

cc'ing the list again in case anyone else has input

I was asking if the missing was structural--for example, hours per shift if
someone is unemployed at the time of measurement. In that scenario, you
could have missing "values" but still completely observed *data*.

Normally, I would assume that questions about missing data refer to
incomplete observation, but you clearly have a special situation, which is
why I asked.

If your population data is completely observed, again, you don't need
inferential statistics.

If not, you do indeed have a sample of the data, not the population, even
though you have most of it. I believe there are corrections that need to be
made to inferential statistics for small populations. I don't have
experience with that, but that might get you started.

Pat

On Fri, Dec 25, 2020 at 9:55 AM Diana Michl <dianamichl at aikq.de> wrote:

> Hi Pat,
>
> thanks very much for your help! Helps me see things a bit more clearly.
> Well, the present values aren't the only ones that could exist. There are
> questions like "How long is your shift", which could be 3, 4, or 5 hours;
> "How many shifts per week do you have", which could be between 1 and 7, or
> "how many callers do you have per semester" which could be - in theory -
> between 0 and thousands. Of course, there's only one response to every
> question that's actually true.
> (Maybe I'm misunderstanding your question, though, cause you probably
> didn't mean whether there could be only one possible response to every
> question, right?)
>
> Diana
>
>
> Am 24.12.2020 um 17:22 schrieb Patrick (Malone Quantitative):
>
> Diana,
>
> It depends on the nature of the missing. Are the present values the only
> ones that could exist? If so, you have the entire population's data, and
> descriptive statistics are in fact preferable to inferential ones. There's
> no need to run inferential statistics if you have the population--they are
> by definition for inferring population values from a sample.
>
> Pat
>
> On Thu, Dec 24, 2020 at 6:21 AM Diana Michl <dianamichl at aikq.de> wrote:
>
>> I have a repeated measures design with about 16 cases and 5-6 points of
>> measuring. Sometimes, 1-4 full cases or some points of measure are
>> missing. (The measures are 20 numerical and categorical data taken from
>> questionnaires.)
>>
>> The clue is: It's a small dataset with holes in it, but the 16 cases are
>> all that even exist. So they fully represent reality wherever they're
>> complete.
>>
>> I wanted to run logistic regressions with up to 6 predictors. But can I
>> do that? I know about the many problems such small datasets have for
>> regression analysis - but do they matter as much if there aren't any
>> more cases in reality?
>> Are descriptive analyses the only ones I can use?
>>
>> Many thanks
>>
>> --
>> Dr. Diana Michl
>> #www.diana-michl.de
>>
>> #Film: Der unber?hrte Garten - eine ungew?hnliche Geschichte ?bers
>> Erwachsenwerden (www.vimeo.com/148014360)
>>
>> #Musik: Singer-Songwriter (www.youtube.com/user/ghiaghiafy)
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
>
> --
> Patrick S. Malone, Ph.D., Malone Quantitative
> NEW Service Models: http://malonequantitative.com
>
> He/Him/His
>
> --
> Dr. Diana Michl
> Kastanienallee 4
> 14471 Potsdam
> Tel: 0331 ? 27 34 15 10
> 01577 ? 3065650
> dianamichl at aikq.de
>
> #www.diana-michl.de
>
> #Film: Der unber?hrte Garten - eine ungew?hnliche Geschichte ?bers
> Erwachsenwerden (www.vimeo.com/148014360)
>
> #Musik: Singer-Songwriter (www.youtube.com/user/ghiaghiafy)
>


-- 
Patrick S. Malone, Ph.D., Malone Quantitative
NEW Service Models: http://malonequantitative.com

He/Him/His

	[[alternative HTML version deleted]]


From @reedt@8 @end|ng |rom gm@||@com  Sat Dec 26 07:14:42 2020
From: @reedt@8 @end|ng |rom gm@||@com (sree datta)
Date: Sat, 26 Dec 2020 01:14:42 -0500
Subject: [R-sig-ME] Efficient mixed logistic reg w 500k individuals
In-Reply-To: <CANOgrHaBAk8LCie-wMWQcZqV86GRCjQF+5UQyAgfhYjOdu5Jhw@mail.gmail.com>
References: <CANOgrHaBAk8LCie-wMWQcZqV86GRCjQF+5UQyAgfhYjOdu5Jhw@mail.gmail.com>
Message-ID: <CAHftDbgpuBjJbKftHj-v5SamUr5RuvUXJsvN3j7P1iJx7XRGCA@mail.gmail.com>

With such a large dataset, I would recommend exploring interactions among
variables using ensemble methods such as Random Forests and Extreme
Gradient Boosting (since you have a binary dependent variable).
These models also correct against bias since with such a large dataset, you
may end up finding a lot of spurious and unstable relationships (both in
main effects and interaction effects) with such large N.
In terms of processing efficiency, have you tried using the *parallel* package
in R (in addition, I would also suggest *foreach* and *doParallel* package
to improve processing speed). For a more detailed description of
parallelism implemented in R see this article:
https://www.jigsawacademy.com/handling-big-data-using-r/ (a good summary of
packages).


<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail&utm_term=icon>
Virus-free.
www.avast.com
<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail&utm_term=link>
<#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>

On Wed, Dec 23, 2020 at 8:20 PM Mitchell Maltenfort <mmalten at gmail.com>
wrote:

> Here?s a fun one for you (I hope)
>
> I?m mucking about with a logistic regression that may have about 30 million
> records for half a million individuals.
>
> Yes, I have a large RAM machine - 64 Gig.  And I?ve used nAGQ 0 and other
> recommendations from
>
> http://angrystatistician.blogspot.com/2015/10/mixed-models-in-r-bigger-faster-stronger.html?m=1
>  which should be reasonable for the large data.
>
> It works but I?d still be interested in tweaks to improve speed or
> accuracy.  Any ideas?
> --
> Sent from Gmail Mobile
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From @reedt@8 @end|ng |rom gm@||@com  Sat Dec 26 07:27:05 2020
From: @reedt@8 @end|ng |rom gm@||@com (sree datta)
Date: Sat, 26 Dec 2020 01:27:05 -0500
Subject: [R-sig-ME] Regression analysis with small but complete dataset
 (fully representing reality)?
In-Reply-To: <CAJc=yOHpb7FXj7qf4AnHu_yzjq36irsCnkCCGz_QOBjz=cFsZQ@mail.gmail.com>
References: <8fe547b7-8cac-e473-6030-ba30553809e6@aikq.de>
 <CAJc=yOFBCg6DAv=zu6UX0CcnyMYyWDFDxna=7sUago-HER9R6g@mail.gmail.com>
 <25316b9a-977f-8ef6-93fd-f1426fbe1ba7@aikq.de>
 <CAJc=yOHpb7FXj7qf4AnHu_yzjq36irsCnkCCGz_QOBjz=cFsZQ@mail.gmail.com>
Message-ID: <CAHftDbhpb0fh65i0SHA4DvnoHcbT7eCzVG9JQU5=Yv5+GpQKSA@mail.gmail.com>

Hi Diana

In addition to using descriptive statistics, I would also recommend using
Partial Least Squares regression that was specifically designed for the
problem of small sample size and having many variables. (your dependent can
be continuous, binary or multinomial in PLS). I have successfully used PLS
regression in medical / healthcare arena for rare and orphan disease
analyses where the affected population is very small and getting data from
30 patients represents any where from 25% to 60% of the overall population.

I strongly recommend this excellent resource (a detailed PDF document - 235
pages)  by Gaston Sanchez on his website:
https://www.gastonsanchez.com/PLS_Path_Modeling_with_R.pdf

Hope this helps. If you have any questions or need additional information
please get back to me and I can help you in identifying whether PLS
regression would be relevant and helpful for you.

Sree



<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail&utm_term=icon>
Virus-free.
www.avast.com
<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail&utm_term=link>
<#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>

On Fri, Dec 25, 2020 at 12:08 PM Patrick (Malone Quantitative) <
malone at malonequantitative.com> wrote:

> Diana,
>
> cc'ing the list again in case anyone else has input
>
> I was asking if the missing was structural--for example, hours per shift if
> someone is unemployed at the time of measurement. In that scenario, you
> could have missing "values" but still completely observed *data*.
>
> Normally, I would assume that questions about missing data refer to
> incomplete observation, but you clearly have a special situation, which is
> why I asked.
>
> If your population data is completely observed, again, you don't need
> inferential statistics.
>
> If not, you do indeed have a sample of the data, not the population, even
> though you have most of it. I believe there are corrections that need to be
> made to inferential statistics for small populations. I don't have
> experience with that, but that might get you started.
>
> Pat
>
> On Fri, Dec 25, 2020 at 9:55 AM Diana Michl <dianamichl at aikq.de> wrote:
>
> > Hi Pat,
> >
> > thanks very much for your help! Helps me see things a bit more clearly.
> > Well, the present values aren't the only ones that could exist. There are
> > questions like "How long is your shift", which could be 3, 4, or 5 hours;
> > "How many shifts per week do you have", which could be between 1 and 7,
> or
> > "how many callers do you have per semester" which could be - in theory -
> > between 0 and thousands. Of course, there's only one response to every
> > question that's actually true.
> > (Maybe I'm misunderstanding your question, though, cause you probably
> > didn't mean whether there could be only one possible response to every
> > question, right?)
> >
> > Diana
> >
> >
> > Am 24.12.2020 um 17:22 schrieb Patrick (Malone Quantitative):
> >
> > Diana,
> >
> > It depends on the nature of the missing. Are the present values the only
> > ones that could exist? If so, you have the entire population's data, and
> > descriptive statistics are in fact preferable to inferential ones.
> There's
> > no need to run inferential statistics if you have the population--they
> are
> > by definition for inferring population values from a sample.
> >
> > Pat
> >
> > On Thu, Dec 24, 2020 at 6:21 AM Diana Michl <dianamichl at aikq.de> wrote:
> >
> >> I have a repeated measures design with about 16 cases and 5-6 points of
> >> measuring. Sometimes, 1-4 full cases or some points of measure are
> >> missing. (The measures are 20 numerical and categorical data taken from
> >> questionnaires.)
> >>
> >> The clue is: It's a small dataset with holes in it, but the 16 cases are
> >> all that even exist. So they fully represent reality wherever they're
> >> complete.
> >>
> >> I wanted to run logistic regressions with up to 6 predictors. But can I
> >> do that? I know about the many problems such small datasets have for
> >> regression analysis - but do they matter as much if there aren't any
> >> more cases in reality?
> >> Are descriptive analyses the only ones I can use?
> >>
> >> Many thanks
> >>
> >> --
> >> Dr. Diana Michl
> >> #www.diana-michl.de
> >>
> >> #Film: Der unber?hrte Garten - eine ungew?hnliche Geschichte ?bers
> >> Erwachsenwerden (www.vimeo.com/148014360)
> >>
> >> #Musik: Singer-Songwriter (www.youtube.com/user/ghiaghiafy)
> >>
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>
> >
> >
> > --
> > Patrick S. Malone, Ph.D., Malone Quantitative
> > NEW Service Models: http://malonequantitative.com
> >
> > He/Him/His
> >
> > --
> > Dr. Diana Michl
> > Kastanienallee 4
> > 14471 Potsdam
> > Tel: 0331 ? 27 34 15 10
> > 01577 ? 3065650
> > dianamichl at aikq.de
> >
> > #www.diana-michl.de
> >
> > #Film: Der unber?hrte Garten - eine ungew?hnliche Geschichte ?bers
> > Erwachsenwerden (www.vimeo.com/148014360)
> >
> > #Musik: Singer-Songwriter (www.youtube.com/user/ghiaghiafy)
> >
>
>
> --
> Patrick S. Malone, Ph.D., Malone Quantitative
> NEW Service Models: http://malonequantitative.com
>
> He/Him/His
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From me @end|ng |rom ph||||p@|d@y@com  Sat Dec 26 21:04:53 2020
From: me @end|ng |rom ph||||p@|d@y@com (Phillip Alday)
Date: Sat, 26 Dec 2020 21:04:53 +0100
Subject: [R-sig-ME] Efficient mixed logistic reg w 500k individuals
In-Reply-To: <CAHftDbgpuBjJbKftHj-v5SamUr5RuvUXJsvN3j7P1iJx7XRGCA@mail.gmail.com>
References: <CANOgrHaBAk8LCie-wMWQcZqV86GRCjQF+5UQyAgfhYjOdu5Jhw@mail.gmail.com>
 <CAHftDbgpuBjJbKftHj-v5SamUr5RuvUXJsvN3j7P1iJx7XRGCA@mail.gmail.com>
Message-ID: <258dece2-1807-7a6a-476b-ae18afd03f67@phillipalday.com>

The problem with random forests is that they don't respect the
hierarchical nature of the data, which depending on the OP's goals may
or may not be a problem. That's in addition to the differences between
random forests vs logistic regression even in a non
hierarchical/multilevel context.

Also, I think the spurious/unstable relationships bit requires some
qualification. Yes, if you're looking at p-values, then with that much
data, you'll typically be able to estimate trivial effects. But the
solution is then not to focus on p-values.

(Not saying random forests and the like aren't useful -- quite the
contrary. But the motivations here are a bit of a red herring.)

Phillip

On 26/12/20 7:14 am, sree datta wrote:
> With such a large dataset, I would recommend exploring interactions among
> variables using ensemble methods such as Random Forests and Extreme
> Gradient Boosting (since you have a binary dependent variable).
> These models also correct against bias since with such a large dataset, you
> may end up finding a lot of spurious and unstable relationships (both in
> main effects and interaction effects) with such large N.
> In terms of processing efficiency, have you tried using the *parallel* package
> in R (in addition, I would also suggest *foreach* and *doParallel* package
> to improve processing speed). For a more detailed description of
> parallelism implemented in R see this article:
> https://www.jigsawacademy.com/handling-big-data-using-r/ (a good summary of
> packages).
> 
> 
> <https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail&utm_term=icon>
> Virus-free.
> www.avast.com
> <https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail&utm_term=link>
> <#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>
> 
> On Wed, Dec 23, 2020 at 8:20 PM Mitchell Maltenfort <mmalten at gmail.com>
> wrote:
> 
>> Here?s a fun one for you (I hope)
>>
>> I?m mucking about with a logistic regression that may have about 30 million
>> records for half a million individuals.
>>
>> Yes, I have a large RAM machine - 64 Gig.  And I?ve used nAGQ 0 and other
>> recommendations from
>>
>> http://angrystatistician.blogspot.com/2015/10/mixed-models-in-r-bigger-faster-stronger.html?m=1
>>  which should be reasonable for the large data.
>>
>> It works but I?d still be interested in tweaks to improve speed or
>> accuracy.  Any ideas?
>> --
>> Sent from Gmail Mobile
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From me @end|ng |rom ph||||p@|d@y@com  Sat Dec 26 21:07:50 2020
From: me @end|ng |rom ph||||p@|d@y@com (Phillip Alday)
Date: Sat, 26 Dec 2020 21:07:50 +0100
Subject: [R-sig-ME] Efficient mixed logistic reg w 500k individuals
In-Reply-To: <CANOgrHaBAk8LCie-wMWQcZqV86GRCjQF+5UQyAgfhYjOdu5Jhw@mail.gmail.com>
References: <CANOgrHaBAk8LCie-wMWQcZqV86GRCjQF+5UQyAgfhYjOdu5Jhw@mail.gmail.com>
Message-ID: <a0b3d063-b461-275c-07c7-9d8287f5ea04@phillipalday.com>

If you're up for branching out from R a little, then MixedModels.jl in
Julia should be able to handle this. And if it can't, then I would very
interested in fixing that shortcoming. :)  I'm also willing to help you
get the Julia code running.

The previous paragraph was a bit of self advertising, but I can add even
more in. :D With my JellyMe4 package, you can fit a model in Julia, then
move it back to lme4/R to take advantage of the wonderful ecosystem for
plotting, post-hoc comparisons, etc. that's grown up in R general and
around lme4 in particular.


Best,
Phillip

On 24/12/20 2:19 am, Mitchell Maltenfort wrote:
> Here?s a fun one for you (I hope)
> 
> I?m mucking about with a logistic regression that may have about 30 million
> records for half a million individuals.
> 
> Yes, I have a large RAM machine - 64 Gig.  And I?ve used nAGQ 0 and other
> recommendations from
> http://angrystatistician.blogspot.com/2015/10/mixed-models-in-r-bigger-faster-stronger.html?m=1
>  which should be reasonable for the large data.
> 
> It works but I?d still be interested in tweaks to improve speed or
> accuracy.  Any ideas?
>


From me @end|ng |rom ph||||p@|d@y@com  Sat Dec 26 21:36:39 2020
From: me @end|ng |rom ph||||p@|d@y@com (Phillip Alday)
Date: Sat, 26 Dec 2020 21:36:39 +0100
Subject: [R-sig-ME] Regression analysis with small but complete dataset
 (fully representing reality)?
In-Reply-To: <CAJc=yOHpb7FXj7qf4AnHu_yzjq36irsCnkCCGz_QOBjz=cFsZQ@mail.gmail.com>
References: <8fe547b7-8cac-e473-6030-ba30553809e6@aikq.de>
 <CAJc=yOFBCg6DAv=zu6UX0CcnyMYyWDFDxna=7sUago-HER9R6g@mail.gmail.com>
 <25316b9a-977f-8ef6-93fd-f1426fbe1ba7@aikq.de>
 <CAJc=yOHpb7FXj7qf4AnHu_yzjq36irsCnkCCGz_QOBjz=cFsZQ@mail.gmail.com>
Message-ID: <cf2bf228-bb5a-a7fc-8683-1df2173fadba@phillipalday.com>

I think there is some confusion about what's meant with "complete" --do
you mean that

- all possible combinations of predictors occur?
- you observed all possible individuals in a population?
- you observed all possible individuals in a 'cohort' but there might be
future cohorts (e.g. all students in a given degree program in a given
year, but there will be more students in other years)?
- something else entirely?

The first three possibilities can obviously overlap and which aspect you
focus on depends on your exact inferential question. For example, if you
observed all students in a given degree program in a given year, then
you might want to make statements about those students (which would be a
descriptive task, as Pat mentioned) or you might want to make statements
about the entire abstract population of students who may in the future
be in that degree program (in which case you would have an inferential
task). That distinction may not be obvious in the original research
question, but one of the hardest things in statistics is figuring out
what the actual statistical problem is, which may or may not be obvious
from the research question. :)

If you're doing descriptive stats, then you don't need any special
methods. The usual summary statistics -- mean, median, mode for central
tendency; range, standard deviation, median absolute deviation,
histogram for variability -- will do the trick.

If you're doing inferential stats with small data, then there a few
intertwined issues:

- the amount of inference you can perform is inherently limited because
the amount of information present is inherently limited. (this is of
course always true, regardless of how much data you have!)

- regularization of various forms is your friend and can even help you
fit otherwise 'impossible' models. Ridge regression, LASSO, elastic net
are all examples of regularized methods; mixed models also perform
regularization in the random effects, but it's a bit different.

- if you have prior knowledge from other means (strong theory, other
data, etc.), then Bayesian methods can help you integrate that into the
statistical procedure.

Note that you can also use priors as a form of regularization, see e.g.
https://jakevdp.github.io/blog/2015/07/06/model-complexity-myth/ for a
good overview of lots of relevant details for the tips above.

Elsewhere in the thread, PLS was suggested. PLS is an interesting
technique, but it doesn't solve the small data problem. In some sense,
you can think of PLS as a generalization of PCA, where the components
are determined not the basis of shared variation within the predictors,
but rather shared variation between the predictors and response
variable. The PLS package
(https://cran.r-project.org/web/packages/pls/index.html) has decent
documentation. PLS is really useful if you want to identify specific
combinations of predictors that can be combined into a single predictive
factor.  Both PLS and PCA are often used for 'dimensionality reduction'
where you transform your original variables into a new set of variables,
ordered by something like explanatory power. (That is a massive
oversimplification.) Then you can drop the low-ranked variables and thus
reduce the number of variables you're dealing with. In other words, PLS
and PCA can be useful for reducing the number of variables you're
dealing with, which can sidestep the small data problem. This is great
for prediction, but if you want to do inference on model parameters,
then it makes things a bit more complicated. It really depends on what
you want to do.

All that said, I'm not seeing anything here that's particular to mixed
models (nor actually anything involving mixed models at all...), so you
might have better luck finding information in you look beyond the mixed
models mailing list. :)

Best,
Phillip

On 25/12/20 6:07 pm, Patrick (Malone Quantitative) wrote:
> Diana,
> 
> cc'ing the list again in case anyone else has input
> 
> I was asking if the missing was structural--for example, hours per shift if
> someone is unemployed at the time of measurement. In that scenario, you
> could have missing "values" but still completely observed *data*.
> 
> Normally, I would assume that questions about missing data refer to
> incomplete observation, but you clearly have a special situation, which is
> why I asked.
> 
> If your population data is completely observed, again, you don't need
> inferential statistics.
> 
> If not, you do indeed have a sample of the data, not the population, even
> though you have most of it. I believe there are corrections that need to be
> made to inferential statistics for small populations. I don't have
> experience with that, but that might get you started.
> 
> Pat
> 
> On Fri, Dec 25, 2020 at 9:55 AM Diana Michl <dianamichl at aikq.de> wrote:
> 
>> Hi Pat,
>>
>> thanks very much for your help! Helps me see things a bit more clearly.
>> Well, the present values aren't the only ones that could exist. There are
>> questions like "How long is your shift", which could be 3, 4, or 5 hours;
>> "How many shifts per week do you have", which could be between 1 and 7, or
>> "how many callers do you have per semester" which could be - in theory -
>> between 0 and thousands. Of course, there's only one response to every
>> question that's actually true.
>> (Maybe I'm misunderstanding your question, though, cause you probably
>> didn't mean whether there could be only one possible response to every
>> question, right?)
>>
>> Diana
>>
>>
>> Am 24.12.2020 um 17:22 schrieb Patrick (Malone Quantitative):
>>
>> Diana,
>>
>> It depends on the nature of the missing. Are the present values the only
>> ones that could exist? If so, you have the entire population's data, and
>> descriptive statistics are in fact preferable to inferential ones. There's
>> no need to run inferential statistics if you have the population--they are
>> by definition for inferring population values from a sample.
>>
>> Pat
>>
>> On Thu, Dec 24, 2020 at 6:21 AM Diana Michl <dianamichl at aikq.de> wrote:
>>
>>> I have a repeated measures design with about 16 cases and 5-6 points of
>>> measuring. Sometimes, 1-4 full cases or some points of measure are
>>> missing. (The measures are 20 numerical and categorical data taken from
>>> questionnaires.)
>>>
>>> The clue is: It's a small dataset with holes in it, but the 16 cases are
>>> all that even exist. So they fully represent reality wherever they're
>>> complete.
>>>
>>> I wanted to run logistic regressions with up to 6 predictors. But can I
>>> do that? I know about the many problems such small datasets have for
>>> regression analysis - but do they matter as much if there aren't any
>>> more cases in reality?
>>> Are descriptive analyses the only ones I can use?
>>>
>>> Many thanks
>>>
>>> --
>>> Dr. Diana Michl
>>> #www.diana-michl.de
>>>
>>> #Film: Der unber?hrte Garten - eine ungew?hnliche Geschichte ?bers
>>> Erwachsenwerden (www.vimeo.com/148014360)
>>>
>>> #Musik: Singer-Songwriter (www.youtube.com/user/ghiaghiafy)
>>>
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>>
>> --
>> Patrick S. Malone, Ph.D., Malone Quantitative
>> NEW Service Models: http://malonequantitative.com
>>
>> He/Him/His
>>
>> --
>> Dr. Diana Michl
>> Kastanienallee 4
>> 14471 Potsdam
>> Tel: 0331 ? 27 34 15 10
>> 01577 ? 3065650
>> dianamichl at aikq.de
>>
>> #www.diana-michl.de
>>
>> #Film: Der unber?hrte Garten - eine ungew?hnliche Geschichte ?bers
>> Erwachsenwerden (www.vimeo.com/148014360)
>>
>> #Musik: Singer-Songwriter (www.youtube.com/user/ghiaghiafy)
>>
> 
>


From mm@|ten @end|ng |rom gm@||@com  Sat Dec 26 21:56:06 2020
From: mm@|ten @end|ng |rom gm@||@com (Mitchell Maltenfort)
Date: Sat, 26 Dec 2020 15:56:06 -0500
Subject: [R-sig-ME] Efficient mixed logistic reg w 500k individuals
In-Reply-To: <258dece2-1807-7a6a-476b-ae18afd03f67@phillipalday.com>
References: <CANOgrHaBAk8LCie-wMWQcZqV86GRCjQF+5UQyAgfhYjOdu5Jhw@mail.gmail.com>
 <CAHftDbgpuBjJbKftHj-v5SamUr5RuvUXJsvN3j7P1iJx7XRGCA@mail.gmail.com>
 <258dece2-1807-7a6a-476b-ae18afd03f67@phillipalday.com>
Message-ID: <CANOgrHaf7TTUX7ant8pkOaObEetxUDhZCxxAyhBysE5545137Q@mail.gmail.com>

As the OP, the hierarchical structure is only part of the problem.  The
other part is that RF?s are opaque. I need an interpretable model.  But
p-values aren?t an issue.  I?d try Bayesian except I think that?s even more
computationally demanding.

On Sat, Dec 26, 2020 at 3:05 PM Phillip Alday <me at phillipalday.com> wrote:

> The problem with random forests is that they don't respect the
> hierarchical nature of the data, which depending on the OP's goals may
> or may not be a problem. That's in addition to the differences between
> random forests vs logistic regression even in a non
> hierarchical/multilevel context.
>
> Also, I think the spurious/unstable relationships bit requires some
> qualification. Yes, if you're looking at p-values, then with that much
> data, you'll typically be able to estimate trivial effects. But the
> solution is then not to focus on p-values.
>
> (Not saying random forests and the like aren't useful -- quite the
> contrary. But the motivations here are a bit of a red herring.)
>
> Phillip
>
> On 26/12/20 7:14 am, sree datta wrote:
> > With such a large dataset, I would recommend exploring interactions among
> > variables using ensemble methods such as Random Forests and Extreme
> > Gradient Boosting (since you have a binary dependent variable).
> > These models also correct against bias since with such a large dataset,
> you
> > may end up finding a lot of spurious and unstable relationships (both in
> > main effects and interaction effects) with such large N.
> > In terms of processing efficiency, have you tried using the *parallel*
> package
> > in R (in addition, I would also suggest *foreach* and *doParallel*
> package
> > to improve processing speed). For a more detailed description of
> > parallelism implemented in R see this article:
> > https://www.jigsawacademy.com/handling-big-data-using-r/ (a good
> summary of
> > packages).
> >
> >
> > <
> https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail&utm_term=icon
> >
> > Virus-free.
> > www.avast.com
> > <
> https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail&utm_term=link
> >
> > <#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>
> >
> > On Wed, Dec 23, 2020 at 8:20 PM Mitchell Maltenfort <mmalten at gmail.com>
> > wrote:
> >
> >> Here?s a fun one for you (I hope)
> >>
> >> I?m mucking about with a logistic regression that may have about 30
> million
> >> records for half a million individuals.
> >>
> >> Yes, I have a large RAM machine - 64 Gig.  And I?ve used nAGQ 0 and
> other
> >> recommendations from
> >>
> >>
> http://angrystatistician.blogspot.com/2015/10/mixed-models-in-r-bigger-faster-stronger.html?m=1
> >>  which should be reasonable for the large data.
> >>
> >> It works but I?d still be interested in tweaks to improve speed or
> >> accuracy.  Any ideas?
> >> --
> >> Sent from Gmail Mobile
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
-- 
Sent from Gmail Mobile

	[[alternative HTML version deleted]]


From mm@|ten @end|ng |rom gm@||@com  Sat Dec 26 21:58:01 2020
From: mm@|ten @end|ng |rom gm@||@com (Mitchell Maltenfort)
Date: Sat, 26 Dec 2020 15:58:01 -0500
Subject: [R-sig-ME] Efficient mixed logistic reg w 500k individuals
In-Reply-To: <a0b3d063-b461-275c-07c7-9d8287f5ea04@phillipalday.com>
References: <CANOgrHaBAk8LCie-wMWQcZqV86GRCjQF+5UQyAgfhYjOdu5Jhw@mail.gmail.com>
 <a0b3d063-b461-275c-07c7-9d8287f5ea04@phillipalday.com>
Message-ID: <CANOgrHa=XR7W8MCBzuJMTsCPVzOXCh2p14UUbS9BpyoYanbSRg@mail.gmail.com>

I?ll keep that in mind if lme4 chokes.  Thanks!

On Sat, Dec 26, 2020 at 3:07 PM Phillip Alday <me at phillipalday.com> wrote:

> If you're up for branching out from R a little, then MixedModels.jl in
> Julia should be able to handle this. And if it can't, then I would very
> interested in fixing that shortcoming. :)  I'm also willing to help you
> get the Julia code running.
>
> The previous paragraph was a bit of self advertising, but I can add even
> more in. :D With my JellyMe4 package, you can fit a model in Julia, then
> move it back to lme4/R to take advantage of the wonderful ecosystem for
> plotting, post-hoc comparisons, etc. that's grown up in R general and
> around lme4 in particular.
>
>
> Best,
> Phillip
>
> On 24/12/20 2:19 am, Mitchell Maltenfort wrote:
> > Here?s a fun one for you (I hope)
> >
> > I?m mucking about with a logistic regression that may have about 30
> million
> > records for half a million individuals.
> >
> > Yes, I have a large RAM machine - 64 Gig.  And I?ve used nAGQ 0 and other
> > recommendations from
> >
> http://angrystatistician.blogspot.com/2015/10/mixed-models-in-r-bigger-faster-stronger.html?m=1
> >  which should be reasonable for the large data.
> >
> > It works but I?d still be interested in tweaks to improve speed or
> > accuracy.  Any ideas?
> >
>
-- 
Sent from Gmail Mobile

	[[alternative HTML version deleted]]


From d|@n@m|ch| @end|ng |rom @|kq@de  Mon Dec 28 13:17:42 2020
From: d|@n@m|ch| @end|ng |rom @|kq@de (Diana Michl)
Date: Mon, 28 Dec 2020 13:17:42 +0100
Subject: [R-sig-ME] Regression analysis with small but complete dataset
 (fully representing reality)?
In-Reply-To: <CAHftDbhpb0fh65i0SHA4DvnoHcbT7eCzVG9JQU5=Yv5+GpQKSA@mail.gmail.com>
References: <8fe547b7-8cac-e473-6030-ba30553809e6@aikq.de>
 <CAJc=yOFBCg6DAv=zu6UX0CcnyMYyWDFDxna=7sUago-HER9R6g@mail.gmail.com>
 <25316b9a-977f-8ef6-93fd-f1426fbe1ba7@aikq.de>
 <CAJc=yOHpb7FXj7qf4AnHu_yzjq36irsCnkCCGz_QOBjz=cFsZQ@mail.gmail.com>
 <CAHftDbhpb0fh65i0SHA4DvnoHcbT7eCzVG9JQU5=Yv5+GpQKSA@mail.gmail.com>
Message-ID: <1810b2bb-ad4e-70e0-ca8e-40b72aa3925a@aikq.de>

Hi all,

sorry it took me a while to respond, the holidays... Thanks very much 
for your help and suggestions!

@Pat: Right, I get it. The data is completely observed and the missing 
data not structural. I mostly get what you're saying about not needing 
inferential statistics. I thought, though, that they give information 
about relationships between variables which descriptive statistics just 
can't. Like, descriptive stats can tell me means, iqrs, maybe frequency 
distributions - but regressions can show how some variables /predict/ 
others. Or correlations show how (strongly) variables relate to one 
another and whether that's likely significant or random. I could really 
use methods that can do that. But if it's not possible with a dataset 
such as mine, then that's the way it is.

@Sree: Maybe partial least squares is what I'm looking for! I've never 
done this or heard of it. Is it much like ordinary least squares?
Thanks very much for the link, I'll look into it. I'll see how far I get 
and will gladly get back to you once I'm there. It will take a few days. 
My data sounds similar to yours indeed, except the set never represents 
less than about 70% of all existing cases.

Best

Diana


Am 26.12.2020 um 07:27 schrieb sree datta:
> Hi Diana
>
> In addition to using descriptive statistics, I?would also recommend 
> using Partial Least Squares regression that was specifically designed 
> for the problem of small sample size and having many variables. (your 
> dependent?can be continuous, binary or multinomial in PLS). I have 
> successfully used PLS regression in medical / healthcare arena for 
> rare and orphan disease analyses where the affected population is very 
> small and getting data from 30 patients represents any where from 25% 
> to 60% of the overall?population.
>
> I strongly recommend this?excellent resource (a detailed PDF document 
> - 235 pages)? by Gaston Sanchez on his website: 
> https://www.gastonsanchez.com/PLS_Path_Modeling_with_R.pdf 
> <https://www.gastonsanchez.com/PLS_Path_Modeling_with_R.pdf>
>
> Hope this?helps. If you?have any questions or need additional 
> information please get?back to me and I can help you in identifying 
> whether PLS regression would be relevant and helpful for you.
>
> Sree
>
>
>
> <https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail&utm_term=icon> 
> 	Virus-free. www.avast.com 
> <https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail&utm_term=link> 
>
>
>
> On Fri, Dec 25, 2020 at 12:08 PM Patrick (Malone Quantitative) 
> <malone at malonequantitative.com <mailto:malone at malonequantitative.com>> 
> wrote:
>
>     Diana,
>
>     cc'ing the list again in case anyone else has input
>
>     I was asking if the missing was structural--for example, hours per
>     shift if
>     someone is unemployed at the time of measurement. In that
>     scenario, you
>     could have missing "values" but still completely observed *data*.
>
>     Normally, I would assume that questions about missing data refer to
>     incomplete observation, but you clearly have a special situation,
>     which is
>     why I asked.
>
>     If your population data is completely observed, again, you don't need
>     inferential statistics.
>
>     If not, you do indeed have a sample of the data, not the
>     population, even
>     though you have most of it. I believe there are corrections that
>     need to be
>     made to inferential statistics for small populations. I don't have
>     experience with that, but that might get you started.
>
>     Pat
>
>     On Fri, Dec 25, 2020 at 9:55 AM Diana Michl <dianamichl at aikq.de
>     <mailto:dianamichl at aikq.de>> wrote:
>
>     > Hi Pat,
>     >
>     > thanks very much for your help! Helps me see things a bit more
>     clearly.
>     > Well, the present values aren't the only ones that could exist.
>     There are
>     > questions like "How long is your shift", which could be 3, 4, or
>     5 hours;
>     > "How many shifts per week do you have", which could be between 1
>     and 7, or
>     > "how many callers do you have per semester" which could be - in
>     theory -
>     > between 0 and thousands. Of course, there's only one response to
>     every
>     > question that's actually true.
>     > (Maybe I'm misunderstanding your question, though, cause you
>     probably
>     > didn't mean whether there could be only one possible response to
>     every
>     > question, right?)
>     >
>     > Diana
>     >
>     >
>     > Am 24.12.2020 um 17:22 schrieb Patrick (Malone Quantitative):
>     >
>     > Diana,
>     >
>     > It depends on the nature of the missing. Are the present values
>     the only
>     > ones that could exist? If so, you have the entire population's
>     data, and
>     > descriptive statistics are in fact preferable to inferential
>     ones. There's
>     > no need to run inferential statistics if you have the
>     population--they are
>     > by definition for inferring population values from a sample.
>     >
>     > Pat
>     >
>     > On Thu, Dec 24, 2020 at 6:21 AM Diana Michl <dianamichl at aikq.de
>     <mailto:dianamichl at aikq.de>> wrote:
>     >
>     >> I have a repeated measures design with about 16 cases and 5-6
>     points of
>     >> measuring. Sometimes, 1-4 full cases or some points of measure are
>     >> missing. (The measures are 20 numerical and categorical data
>     taken from
>     >> questionnaires.)
>     >>
>     >> The clue is: It's a small dataset with holes in it, but the 16
>     cases are
>     >> all that even exist. So they fully represent reality wherever
>     they're
>     >> complete.
>     >>
>     >> I wanted to run logistic regressions with up to 6 predictors.
>     But can I
>     >> do that? I know about the many problems such small datasets
>     have for
>     >> regression analysis - but do they matter as much if there
>     aren't any
>     >> more cases in reality?
>     >> Are descriptive analyses the only ones I can use?
>     >>
>     >> Many thanks
>     >>
>     >> --
>     >> Dr. Diana Michl
>     >> #www.diana-michl.de <http://www.diana-michl.de>
>     >>
>     >> #Film: Der unber?hrte Garten - eine ungew?hnliche Geschichte ?bers
>     >> Erwachsenwerden (www.vimeo.com/148014360
>     <http://www.vimeo.com/148014360>)
>     >>
>     >> #Musik: Singer-Songwriter (www.youtube.com/user/ghiaghiafy
>     <http://www.youtube.com/user/ghiaghiafy>)
>     >>
>     >>
>     >>? ? ? ? ?[[alternative HTML version deleted]]
>     >>
>     >> _______________________________________________
>     >> R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>     >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>     >>
>     >
>     >
>     > --
>     > Patrick S. Malone, Ph.D., Malone Quantitative
>     > NEW Service Models: http://malonequantitative.com
>     <http://malonequantitative.com>
>     >
>     > He/Him/His
>     >
>     > --
>     > Dr. Diana Michl
>     > Kastanienallee 4
>     > 14471 Potsdam
>     > Tel: 0331 ? 27 34 15 10
>     > 01577 ? 3065650
>     > dianamichl at aikq.de <mailto:dianamichl at aikq.de>
>     >
>     > #www.diana-michl.de <http://www.diana-michl.de>
>     >
>     > #Film: Der unber?hrte Garten - eine ungew?hnliche Geschichte ?bers
>     > Erwachsenwerden (www.vimeo.com/148014360
>     <http://www.vimeo.com/148014360>)
>     >
>     > #Musik: Singer-Songwriter (www.youtube.com/user/ghiaghiafy
>     <http://www.youtube.com/user/ghiaghiafy>)
>     >
>
>
>     -- 
>     Patrick S. Malone, Ph.D., Malone Quantitative
>     NEW Service Models: http://malonequantitative.com
>     <http://malonequantitative.com>
>
>     He/Him/His
>
>     ? ? ? ? [[alternative HTML version deleted]]
>
>     _______________________________________________
>     R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>
-- 
Dr. Diana Michl
Kastanienallee 4
14471 Potsdam
Tel: 0331 ? 27 34 15 10
01577 ? 3065650
dianamichl at aikq.de

#www.diana-michl.de

#Film: Der unber?hrte Garten - eine ungew?hnliche Geschichte ?bers 
Erwachsenwerden (www.vimeo.com/148014360)

#Musik: Singer-Songwriter (www.youtube.com/user/ghiaghiafy)


	[[alternative HTML version deleted]]


