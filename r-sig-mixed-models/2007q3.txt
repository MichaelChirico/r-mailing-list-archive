From bates at stat.wisc.edu  Wed Jul  4 15:04:46 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 4 Jul 2007 08:04:46 -0500
Subject: [R-sig-ME] lme4_0.99875-3.tar.gz uploaded to CRAN
Message-ID: <40e66e0b0707040604j432e4cf9pbf500d8a72f44845@mail.gmail.com>

This will be the last release of lme4 compatible with the current API
from the Matrix package.

A version of lme4 compatible with the new API from the Matrix package
will be made available for confirmation of results.  However it will
not be uploaded to CRAN until all the methods currently available in
lme4 have been defined under the new formulation.

It would be a good idea for those who depend on the lme4 package to
preserve a copy of the 0.99875-3 release in case I botch this process
and you find yourself needing to back out changes.



From kyler at mail.smu.edu  Mon Jul  9 22:13:56 2007
From: kyler at mail.smu.edu (Roberts, Kyle)
Date: Mon, 9 Jul 2007 15:13:56 -0500
Subject: [R-sig-ME] Growth Curve Modeling in NY Times
Message-ID: <F8AF6BF6CD1CC040AF35B0C2D1680BBB03184C2C@s31xe7.systems.smu.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20070709/4b4c8fd3/attachment.pl>

From bates at stat.wisc.edu  Mon Jul  9 22:36:07 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 9 Jul 2007 15:36:07 -0500
Subject: [R-sig-ME] Growth Curve Modeling in NY Times
In-Reply-To: <F8AF6BF6CD1CC040AF35B0C2D1680BBB03184C2C@s31xe7.systems.smu.edu>
References: <F8AF6BF6CD1CC040AF35B0C2D1680BBB03184C2C@s31xe7.systems.smu.edu>
Message-ID: <40e66e0b0707091336p5b92a0abwf5e80dac7b6925d2@mail.gmail.com>

On 7/9/07, Roberts, Kyle <kyler at mail.smu.edu> wrote:
> Not sure if you saw this on the 6th in the NY Times, but I thought that
> it might be of interest to this group. Please forgive it not being
> "lmer" related.

> http://www.nytimes.com/2007/07/06/education/06test.html?_r=1&oref=slogin

I would say that it is definitely lmer-related.  It is for exactly
this type of model that I worked hard to ensure that lmer could handle
large data sets and models with crossed or partially crossed random
effects.



From afshart at exchange.sba.miami.edu  Tue Jul 10 16:23:21 2007
From: afshart at exchange.sba.miami.edu (Afshartous, David)
Date: Tue, 10 Jul 2007 10:23:21 -0400
Subject: [R-sig-ME] random effect variance per treatment group in lmer
In-Reply-To: <F8AF6BF6CD1CC040AF35B0C2D1680BBB03184C2C@s31xe7.systems.smu.edu>
Message-ID: <6BCB4D493A447546A8126F24332056E8063E8F8E@school1.business.edu>


All,
I didn't receive a response to the query below sent to the general
R-help mailing list so figured I'd try this mailing list.  Apologies
in advance if this is an overly simplistic question for this list; I
just started 
w/ lmer after not using lme for awhile.
Cheers,
Dave 




___________________________________________________________

All,
 
How does one specify a model in lmer such that say the random effect for

the intercept has a different variance per treatment group?  
Thus, in the model equation, we'd have say b_ij represent the random
effect
for patient j in treatment group i, with variance depending on i, i.e,
var(b_ij) = tau_i.
 
Didn't see this in the docs or Pinherio & Bates (section 5.2 is specific
for 
modelling within group errors).  Sample repeated measures code below is
for 
a single random effect variance, where the random effect corresponds to
patient.
cheers,
dave
 
 
z <- rnorm(24, mean=0, sd=1)
time <- factor(paste("Time-", rep(1:6, 4), sep="")) 
Patient <- rep(1:4, each = 6) 
drug <- factor(rep(c("D", "P"), each = 6, times = 2)) ## P = placebo, D
= Drug
dat.new <- data.frame(time, drug, z, Patient) 
fm =  lmer(z ~ drug + time + (1 | Patient), data = dat.new )



From A.Robinson at ms.unimelb.edu.au  Wed Jul 11 07:04:48 2007
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Wed, 11 Jul 2007 15:04:48 +1000
Subject: [R-sig-ME] random effect variance per treatment group in lmer
In-Reply-To: <6BCB4D493A447546A8126F24332056E8063E8F8E@school1.business.edu>
References: <F8AF6BF6CD1CC040AF35B0C2D1680BBB03184C2C@s31xe7.systems.smu.edu>
	<6BCB4D493A447546A8126F24332056E8063E8F8E@school1.business.edu>
Message-ID: <20070711050448.GZ5296@ms.unimelb.edu.au>

Hi David,

as far as I am aware, there is no option for stratifying the variance
of random effects in either lme or lmer.  One can stratify the
variance of the innermost residuals in lme, but that is different than
what you are asking for. 

Cheers,

Andrew


On Tue, Jul 10, 2007 at 10:23:21AM -0400, Afshartous, David wrote:
> 
> All,
> I didn't receive a response to the query below sent to the general
> R-help mailing list so figured I'd try this mailing list.  Apologies
> in advance if this is an overly simplistic question for this list; I
> just started 
> w/ lmer after not using lme for awhile.
> Cheers,
> Dave 
> 
> 
> 
> 
> ___________________________________________________________
> 
> All,
>  
> How does one specify a model in lmer such that say the random effect for
> 
> the intercept has a different variance per treatment group?  
> Thus, in the model equation, we'd have say b_ij represent the random
> effect
> for patient j in treatment group i, with variance depending on i, i.e,
> var(b_ij) = tau_i.
>  
> Didn't see this in the docs or Pinherio & Bates (section 5.2 is specific
> for 
> modelling within group errors).  Sample repeated measures code below is
> for 
> a single random effect variance, where the random effect corresponds to
> patient.
> cheers,
> dave
>  
>  
> z <- rnorm(24, mean=0, sd=1)
> time <- factor(paste("Time-", rep(1:6, 4), sep="")) 
> Patient <- rep(1:4, each = 6) 
> drug <- factor(rep(c("D", "P"), each = 6, times = 2)) ## P = placebo, D
> = Drug
> dat.new <- data.frame(time, drug, z, Patient) 
> fm =  lmer(z ~ drug + time + (1 | Patient), data = dat.new )
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Andrew Robinson  
Department of Mathematics and Statistics            Tel: +61-3-8344-9763
University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
http://www.ms.unimelb.edu.au/~andrewpr
http://blogs.mbs.edu/fishing-in-the-bay/



From s.blomberg1 at uq.edu.au  Wed Jul 11 07:58:03 2007
From: s.blomberg1 at uq.edu.au (Simon Blomberg)
Date: Wed, 11 Jul 2007 15:58:03 +1000
Subject: [R-sig-ME] random effect variance per treatment group in lmer
In-Reply-To: <20070711050448.GZ5296@ms.unimelb.edu.au>
References: <F8AF6BF6CD1CC040AF35B0C2D1680BBB03184C2C@s31xe7.systems.smu.edu>
	<6BCB4D493A447546A8126F24332056E8063E8F8E@school1.business.edu>
	<20070711050448.GZ5296@ms.unimelb.edu.au>
Message-ID: <1184133483.4812.95.camel@sib-sblomber01d.sib.uq.edu.au>

I think he is asking to stratify the variance of the innermost
residuals, or at least it's not clear. In lme that can be accomplished
with weights=varFixed(~1|Patient).

To stratify at different levels of nesting, say the data is this:
 dat <- data.frame(inner=rep(1:10, each=5), outer=rep(1:2, each=25),
x=rnorm(50))

Then this call to lme does the job:

 fit <- lme(x ~ 1, random=list(outer=~1, inner=~1), data=dat,
weights=varComb(varIdent(form=~1|outer), varIdent(form=~1|inner)))

edited output:

Combination of variance functions: 
 Structure: Different standard deviations per stratum
 Formula: ~1 | outer 
 Parameter estimates:
        1         2 
1.0000000 0.5170794 
 Structure: Different standard deviations per stratum
 Formula: ~1 | inner 
 Parameter estimates:
        1         2         3         4         5         6         7
8 
1.0000000 0.3127693 0.4475444 0.7323698 0.3647991 0.5962917 1.4127508
1.7664527 
        9        10 
0.9475334 0.3666155 

Cheers,

Simon.

weights=varOn Wed, 2007-07-11 at 15:04 +1000, Andrew Robinson wrote:
> Hi David,
> 
> as far as I am aware, there is no option for stratifying the variance
> of random effects in either lme or lmer.  One can stratify the
> variance of the innermost residuals in lme, but that is different than
> what you are asking for. 
> 
> Cheers,
> 
> Andrew
> 
> 
> On Tue, Jul 10, 2007 at 10:23:21AM -0400, Afshartous, David wrote:
> > 
> > All,
> > I didn't receive a response to the query below sent to the general
> > R-help mailing list so figured I'd try this mailing list.  Apologies
> > in advance if this is an overly simplistic question for this list; I
> > just started 
> > w/ lmer after not using lme for awhile.
> > Cheers,
> > Dave 
> > 
> > 
> > 
> > 
> > ___________________________________________________________
> > 
> > All,
> >  
> > How does one specify a model in lmer such that say the random effect for
> > 
> > the intercept has a different variance per treatment group?  
> > Thus, in the model equation, we'd have say b_ij represent the random
> > effect
> > for patient j in treatment group i, with variance depending on i, i.e,
> > var(b_ij) = tau_i.
> >  
> > Didn't see this in the docs or Pinherio & Bates (section 5.2 is specific
> > for 
> > modelling within group errors).  Sample repeated measures code below is
> > for 
> > a single random effect variance, where the random effect corresponds to
> > patient.
> > cheers,
> > dave
> >  
> >  
> > z <- rnorm(24, mean=0, sd=1)
> > time <- factor(paste("Time-", rep(1:6, 4), sep="")) 
> > Patient <- rep(1:4, each = 6) 
> > drug <- factor(rep(c("D", "P"), each = 6, times = 2)) ## P = placebo, D
> > = Drug
> > dat.new <- data.frame(time, drug, z, Patient) 
> > fm =  lmer(z ~ drug + time + (1 | Patient), data = dat.new )
> > 
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
-- 
Simon Blomberg, BSc (Hons), PhD, MAppStat. 
Lecturer and Consultant Statistician 
Faculty of Biological and Chemical Sciences 
The University of Queensland 
St. Lucia Queensland 4072 
Australia
Room 320 Goddard Building (8)
T: +61 7 3365 2506 
email: S.Blomberg1_at_uq.edu.au

Policies:
1.  I will NOT analyse your data for you.
2.  Your deadline is your problem.

The combination of some data and an aching desire for 
an answer does not ensure that a reasonable answer can 
be extracted from a given body of data. - John Tukey.



From Fredrik.X.Nilsson at skane.se  Wed Jul 11 14:37:43 2007
From: Fredrik.X.Nilsson at skane.se (Nilsson Fredrik X)
Date: Wed, 11 Jul 2007 14:37:43 +0200
Subject: [R-sig-ME] inference in a mixed poisson models
Message-ID: <87A0C64299B27148B40BE0DB83EDE2DBD4B6C5@RSMAIL002.REG.SKANE.SE>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20070711/833c5fee/attachment.pl>

From Fredrik.X.Nilsson at skane.se  Wed Jul 11 14:48:15 2007
From: Fredrik.X.Nilsson at skane.se (Nilsson Fredrik X)
Date: Wed, 11 Jul 2007 14:48:15 +0200
Subject: [R-sig-ME] Inference in a mixed poisson models (resent,
	since I mailed in html format).
Message-ID: <87A0C64299B27148B40BE0DB83EDE2DBD4B6C7@RSMAIL002.REG.SKANE.SE>

Dear All,

I have a data set where 22 laboratory rats have been treated with two
treatments (A and/or B). Then their brains have been cut into sections
and some cells (of a certain type) have been counted within a section
and every 6th section has been counted within each animal.

This has been done in two different regions in the brain (which gives
rise to msmtA resp. msmtB).

Now I have the following questions:
1. Would you analyze the cell types in the two different regions
separately? 
   If not, what model should one use?
2. How do one test for overdispersion in the model M2.lmer<-
   lmer(msmtB~tmtA*tmtB + (1|Animal), data=snitt2u, family=poisson)? (Or
for 
   that matter in M1.lmer<- lmer(msmtA~...) which seems to be more 
   overdispersed, but not so important for me).
3. What's the difference with a model M2.gee<-gee(msmtB~tmtA*tmtB, 
   id=Animal, data=snitt2u, family=poisson, corstr="AR-M")? And 
  a. which corstr to choose ("fixed" causes my computer to hang it
self)?   
     What correlation structure to use (if one could) is also relevant
for 
     the lmer.
  b. Is it correct in MASS (p.300) that the inference in a GLMM for the 
     beta's is on the individual level and for a GEE on the population 
     level? Seems strange to me... (but that's me).
  c. The gee gives much more significant "robust" z-values, how come?
  d. Do you trust gees anymore?
4. The structures that were measured on are somewhat ellipsoidal (resp.
the 
  shell of this structure), this could influence the number of
potentially 
  measured cells, what to do with that error?

I hope this is not too many, nor too silly questions!

Best regards,
Fredrik Nilsson

Data with rownumbers (collected in dataframe snitt2u above).
"Animal","msmtA","msmtB","Section","tmtA","tmtB"
"1","ind1",139,2,1,1,1
"2","ind1",123,0,7,1,1
"4","ind1",90,3,19,1,1
"5","ind1",118,2,25,1,1
"6","ind1",95,2,31,1,1
"7","ind1",118,2,37,1,1
"8","ind1",118,4,43,1,1
"9","ind1",107,4,49,1,1
"10","ind2",166,5,1,1,1
"11","ind2",150,0,7,1,1
"12","ind2",146,5,13,1,1
"13","ind2",109,3,19,1,1
"14","ind2",95,1,25,1,1
"15","ind2",98,1,31,1,1
"16","ind2",131,5,37,1,1
"17","ind2",112,1,43,1,1
"18","ind2",95,2,49,1,1
"19","ind2",117,0,55,1,1
"21","ind2",148,3,67,1,1
"22","ind2",108,2,73,1,1
"23","ind2",114,4,79,1,1
"24","ind2",67,0,85,1,1
"25","ind3",111,2,1,1,1
"26","ind3",95,6,7,1,1
"27","ind3",72,1,13,1,1
"28","ind3",93,5,19,1,1
"30","ind3",137,2,31,1,1
"31","ind3",109,3,37,1,1
"32","ind3",109,3,43,1,1
"33","ind3",84,4,49,1,1
"34","ind3",96,3,55,1,1
"35","ind3",105,2,61,1,1
"36","ind3",145,4,67,1,1
"37","ind3",120,1,73,1,1
"38","ind3",115,5,79,1,1
"39","ind3",82,4,85,1,1
"40","ind4",119,0,1,1,1
"41","ind4",70,0,7,1,1
"42","ind4",116,0,13,1,1
"43","ind4",197,1,19,1,1
"45","ind4",135,1,31,1,1
"46","ind4",149,1,37,1,1
"47","ind4",142,0,43,1,1
"48","ind4",90,1,49,1,1
"49","ind4",98,0,55,1,1
"50","ind4",102,0,61,1,1
"51","ind5",86,5,1,1,1
"52","ind5",117,6,7,1,1
"53","ind5",117,6,13,1,1
"55","ind5",126,5,25,1,1
"56","ind5",92,7,31,1,1
"57","ind5",113,2,37,1,1
"58","ind5",111,5,43,1,1
"59","ind5",131,11,49,1,1
"60","ind5",74,14,55,1,1
"61","ind5",111,2,61,1,1
"62","ind5",99,4,67,1,1
"63","ind6",166,2,1,1,1
"64","ind6",176,3,7,1,1
"65","ind6",177,0,13,1,1
"66","ind6",156,0,19,1,1
"67","ind6",128,1,25,1,1
"68","ind6",142,0,31,1,1
"69","ind6",78,0,37,1,1
"70","ind6",90,0,43,1,1
"72","ind6",187,1,55,1,1
"73","ind6",153,2,61,1,1
"74","ind6",119,1,67,1,1
"75","ind6",114,2,73,1,1
"76","ind6",93,1,79,1,1
"77","ind6",133,2,85,1,1
"78","ind6",93,2,91,1,1
"79","ind6",111,0,97,1,1
"80","ind7",24,0,1,0,1
"81","ind7",32,0,7,0,1
"82","ind7",21,0,13,0,1
"83","ind7",29,0,19,0,1
"84","ind7",33,0,25,0,1
"85","ind7",19,0,31,0,1
"86","ind7",25,0,37,0,1
"87","ind7",26,0,43,0,1
"88","ind7",28,0,49,0,1
"89","ind7",23,0,55,0,1
"90","ind7",33,0,61,0,1
"91","ind7",55,0,67,0,1
"93","ind7",41,0,79,0,1
"94","ind7",39,0,85,0,1
"95","ind9",33,0,1,0,1
"96","ind9",44,0,7,0,1
"97","ind9",25,0,13,0,1
"98","ind9",44,0,19,0,1
"99","ind9",26,0,25,0,1
"100","ind9",42,0,31,0,1
"102","ind9",27,0,43,0,1
"103","ind9",42,0,49,0,1
"104","ind9",12,0,55,0,1
"105","ind9",25,1,61,0,1
"106","ind9",23,0,67,0,1
"107","ind9",32,0,73,0,1
"108","ind10",19,0,1,0,1
"109","ind10",11,0,7,0,1
"110","ind10",16,0,13,0,1
"111","ind10",32,0,19,0,1
"112","ind10",10,0,25,0,1
"113","ind10",9,0,31,0,1
"114","ind10",13,0,37,0,1
"115","ind10",21,0,43,0,1
"116","ind11",15,0,1,0,1
"117","ind11",11,0,7,0,1
"118","ind11",19,0,13,0,1
"119","ind11",20,0,19,0,1
"120","ind11",16,1,25,0,1
"121","ind11",10,0,31,0,1
"122","ind11",7,0,37,0,1
"123","ind11",13,0,43,0,1
"124","ind12",17,0,1,0,1
"125","ind12",15,0,7,0,1
"126","ind12",15,0,13,0,1
"127","ind12",3,0,19,0,1
"129","ind12",12,0,31,0,1
"130","ind12",17,0,37,0,1
"131","ind12",10,0,43,0,1
"132","ind12",21,0,49,0,1
"133","ind12",13,0,55,0,1
"134","ind12",15,0,61,0,1
"135","ind12",30,0,67,0,1
"136","ind12",23,0,73,0,1
"137","ind12",14,0,79,0,1
"138","ind12",19,0,85,0,1
"139","ind13",137,47,1,1,0
"140","ind13",102,37,7,1,0
"141","ind13",126,41,13,1,0
"142","ind13",146,52,19,1,0
"143","ind13",102,35,25,1,0
"144","ind13",90,31,31,1,0
"145","ind13",90,40,37,1,0
"146","ind13",105,36,43,1,0
"148","ind13",93,59,55,1,0
"149","ind13",106,54,61,1,0
"150","ind13",101,62,67,1,0
"151","ind13",110,65,73,1,0
"152","ind14",157,79,1,1,0
"153","ind14",195,59,7,1,0
"154","ind14",209,54,13,1,0
"155","ind14",143,70,19,1,0
"156","ind14",142,41,25,1,0
"157","ind14",129,48,31,1,0
"158","ind14",124,74,37,1,0
"159","ind14",162,77,43,1,0
"160","ind14",114,70,49,1,0
"161","ind14",127,63,55,1,0
"162","ind14",101,65,61,1,0
"163","ind14",129,54,67,1,0
"164","ind15",131,54,1,1,0
"165","ind15",123,29,7,1,0
"166","ind15",93,26,13,1,0
"167","ind15",127,25,19,1,0
"168","ind15",187,28,25,1,0
"169","ind15",126,30,31,1,0
"170","ind15",116,29,37,1,0
"171","ind15",113,30,43,1,0
"173","ind15",128,55,55,1,0
"174","ind15",125,40,61,1,0
"175","ind15",97,19,67,1,0
"176","ind15",108,26,73,1,0
"177","ind15",240,52,79,1,0
"178","ind15",119,42,85,1,0
"179","ind15",120,53,91,1,0
"180","ind15",108,44,97,1,0
"181","ind16",172,119,1,1,0
"182","ind16",119,84,7,1,0
"183","ind16",118,79,13,1,0
"184","ind16",145,81,19,1,0
"186","ind16",143,74,31,1,0
"187","ind16",169,69,37,1,0
"188","ind16",131,57,43,1,0
"189","ind16",115,52,49,1,0
"190","ind16",136,53,55,1,0
"191","ind16",127,70,61,1,0
"192","ind16",151,56,67,1,0
"193","ind16",127,57,73,1,0
"194","ind16",94,54,79,1,0
"195","ind17",158,44,1,1,0
"196","ind17",173,48,7,1,0
"197","ind17",137,36,13,1,0
"198","ind17",157,61,19,1,0
"199","ind17",95,41,25,1,0
"200","ind17",133,47,31,1,0
"201","ind17",135,48,37,1,0
"202","ind17",125,41,43,1,0
"204","ind17",94,47,55,1,0
"205","ind17",106,45,61,1,0
"206","ind17",87,24,67,1,0
"207","ind17",95,37,73,1,0
"208","ind19",23,3,1,0,0
"209","ind19",35,0,7,0,0
"210","ind19",25,2,13,0,0
"211","ind19",25,1,19,0,0
"212","ind19",20,2,25,0,0
"213","ind19",26,4,31,0,0
"214","ind19",15,2,37,0,0
"215","ind19",14,1,43,0,0
"216","ind19",20,0,49,0,0
"217","ind19",10,0,55,0,0
"218","ind20",48,4,1,0,0
"219","ind20",34,2,7,0,0
"220","ind20",46,2,13,0,0
"221","ind20",43,5,19,0,0
"222","ind20",18,2,25,0,0
"223","ind20",41,3,31,0,0
"224","ind20",57,2,37,0,0
"225","ind20",43,2,43,0,0
"226","ind21",35,1,1,0,0
"227","ind21",35,2,7,0,0
"228","ind21",41,2,13,0,0
"229","ind21",30,2,19,0,0
"230","ind21",33,4,25,0,0
"231","ind21",41,3,31,0,0
"232","ind21",35,6,37,0,0
"233","ind21",38,2,43,0,0
"234","ind21",38,3,49,0,0
"235","ind21",56,1,55,0,0
"237","ind21",47,2,67,0,0
"238","ind21",50,3,73,0,0
"239","ind21",33,4,79,0,0
"240","ind21",32,2,85,0,0
"241","ind22",39,13,1,0,0
"242","ind22",47,9,7,0,0
"243","ind22",43,4,13,0,0
"245","ind22",46,9,25,0,0
"246","ind22",44,12,31,0,0
"247","ind22",43,5,37,0,0
"248","ind22",41,12,43,0,0
"249","ind23",40,3,1,0,0
"250","ind23",30,6,7,0,0
"252","ind23",45,4,19,0,0
"253","ind23",33,0,25,0,0
"254","ind23",31,0,31,0,0
"255","ind23",35,2,37,0,0
"256","ind23",24,3,43,0,0
"257","ind23",31,4,49,0,0
"258","ind23",30,1,55,0,0
"259","ind23",34,3,61,0,0
"260","ind23",50,0,67,0,0
"261","ind23",39,4,73,0,0
"262","ind23",57,0,79,0,0
"263","ind24",36,3,1,0,0
"264","ind24",48,8,7,0,0
"265","ind24",33,4,13,0,0
"266","ind24",51,1,19,0,0



From afshart at exchange.sba.miami.edu  Wed Jul 11 17:23:39 2007
From: afshart at exchange.sba.miami.edu (Afshartous, David)
Date: Wed, 11 Jul 2007 11:23:39 -0400
Subject: [R-sig-ME] random effect variance per treatment group in lmer
In-Reply-To: <1184133483.4812.95.camel@sib-sblomber01d.sib.uq.edu.au>
Message-ID: <6BCB4D493A447546A8126F24332056E8063E92B9@school1.business.edu>

 
Simon, Andrew:

Thanks for the replies.
I am not interested in stratifying the variance of the innermost
residuals,
but rather the variance of the random effects, viz., b_ij (drug i,
patient j) 
is a random variable w/ variance depending on i.  

Possible solution suggested offline for previously supplied pseudo data:

fm.cov =  lmer(z ~ drug + time + (drug|Patient), data = dat.new ) 
OR,
fm.no.cov  =  lmer(z ~ drug + time + (0 + drug|Patient), data = dat.new
) 

Formally, consider:

Case 1:
Y_ijk = mu + alpha_i + b_ij + theta_k + espilon_ijk 
alpha = fixed effect for group, theta = fixed effect for time, 
b = random effect per patient; b_ij ~ N(0, tau_i)  ## variance of random
effect depends on treatment

Case 2: 
Y_ijk = mu + alpha_i + Indicator_treat_i * b_treatment_ij + 
		Indicator_placebo_i * b_placebo_ij + theta_k +
espilon_ijk

Indicator_treat_i = 1 if i is in treatment group, 0 otherwise 
Indicator_placebo_i = 1 if i is in placebo group, 0 otherwise

where b_treatment_ij and b_placebo_ij are different random effects
terms, with
different variances; only one will apply per patient equation as per the
indicator 
variables.  The cumbersome notation allows for a covariance since we now
have "two" random effects. (although it seem nonsensical to want such a 
covariance)

Does fm.no.cov estimates Case 1 model and fm.cov estimates Case 2 model?

Cheers,
Dave








-----Original Message-----
From: Simon Blomberg [mailto:s.blomberg1 at uq.edu.au] 
Sent: Wednesday, July 11, 2007 1:58 AM
To: Andrew Robinson
Cc: Afshartous, David; r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] random effect variance per treatment group in
lmer

I think he is asking to stratify the variance of the innermost
residuals, or at least it's not clear. In lme that can be accomplished
with weights=varFixed(~1|Patient).

To stratify at different levels of nesting, say the data is this:
 dat <- data.frame(inner=rep(1:10, each=5), outer=rep(1:2, each=25),
x=rnorm(50))

Then this call to lme does the job:

 fit <- lme(x ~ 1, random=list(outer=~1, inner=~1), data=dat,
weights=varComb(varIdent(form=~1|outer), varIdent(form=~1|inner)))

edited output:

Combination of variance functions: 
 Structure: Different standard deviations per stratum
 Formula: ~1 | outer
 Parameter estimates:
        1         2 
1.0000000 0.5170794
 Structure: Different standard deviations per stratum
 Formula: ~1 | inner
 Parameter estimates:
        1         2         3         4         5         6         7
8
1.0000000 0.3127693 0.4475444 0.7323698 0.3647991 0.5962917 1.4127508
1.7664527 
        9        10 
0.9475334 0.3666155 

Cheers,

Simon.

weights=varOn Wed, 2007-07-11 at 15:04 +1000, Andrew Robinson wrote:
> Hi David,
> 
> as far as I am aware, there is no option for stratifying the variance 
> of random effects in either lme or lmer.  One can stratify the 
> variance of the innermost residuals in lme, but that is different than

> what you are asking for.
> 
> Cheers,
> 
> Andrew
> 
> 
> On Tue, Jul 10, 2007 at 10:23:21AM -0400, Afshartous, David wrote:
> > 
> > All,
> > I didn't receive a response to the query below sent to the general 
> > R-help mailing list so figured I'd try this mailing list.  Apologies

> > in advance if this is an overly simplistic question for this list; I

> > just started w/ lmer after not using lme for awhile.
> > Cheers,
> > Dave
> > 
> > 
> > 
> > 
> > ___________________________________________________________
> > 
> > All,
> >  
> > How does one specify a model in lmer such that say the random effect

> > for
> > 
> > the intercept has a different variance per treatment group?  
> > Thus, in the model equation, we'd have say b_ij represent the random

> > effect for patient j in treatment group i, with variance depending 
> > on i, i.e,
> > var(b_ij) = tau_i.
> >  
> > Didn't see this in the docs or Pinherio & Bates (section 5.2 is 
> > specific for modelling within group errors).  Sample repeated 
> > measures code below is for a single random effect variance, where 
> > the random effect corresponds to patient.
> > cheers,
> > dave
> >  
> >  
> > z <- rnorm(24, mean=0, sd=1)
> > time <- factor(paste("Time-", rep(1:6, 4), sep="")) Patient <- 
> > rep(1:4, each = 6) drug <- factor(rep(c("D", "P"), each = 6, times =

> > 2)) ## P = placebo, D = Drug dat.new <- data.frame(time, drug, z, 
> > Patient) fm =  lmer(z ~ drug + time + (1 | Patient), data = dat.new 
> > )
> > 
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list 
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
--
Simon Blomberg, BSc (Hons), PhD, MAppStat. 
Lecturer and Consultant Statistician
Faculty of Biological and Chemical Sciences The University of Queensland
St. Lucia Queensland 4072 Australia Room 320 Goddard Building (8)
T: +61 7 3365 2506
email: S.Blomberg1_at_uq.edu.au

Policies:
1.  I will NOT analyse your data for you.
2.  Your deadline is your problem.

The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of
data. - John Tukey.



From A.Robinson at ms.unimelb.edu.au  Wed Jul 11 22:57:44 2007
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Thu, 12 Jul 2007 06:57:44 +1000
Subject: [R-sig-ME] random effect variance per treatment group in lmer
In-Reply-To: <6BCB4D493A447546A8126F24332056E8063E92B9@school1.business.edu>
References: <1184133483.4812.95.camel@sib-sblomber01d.sib.uq.edu.au>
	<6BCB4D493A447546A8126F24332056E8063E92B9@school1.business.edu>
Message-ID: <20070711205744.GK5296@ms.unimelb.edu.au>

Dave,

I don't feel that I am sufficiently well informed about the
conventions in lmer to comment.  It could work that way.  I suggest
that you try some simulations, if you are not convinced by the
solution suggested offline.  

Cheers,

Andrew

On Wed, Jul 11, 2007 at 11:23:39AM -0400, Afshartous, David wrote:
>  
> Simon, Andrew:
> 
> Thanks for the replies.
> I am not interested in stratifying the variance of the innermost
> residuals,
> but rather the variance of the random effects, viz., b_ij (drug i,
> patient j) 
> is a random variable w/ variance depending on i.  
> 
> Possible solution suggested offline for previously supplied pseudo data:
> 
> fm.cov =  lmer(z ~ drug + time + (drug|Patient), data = dat.new ) 
> OR,
> fm.no.cov  =  lmer(z ~ drug + time + (0 + drug|Patient), data = dat.new
> ) 
> 
> Formally, consider:
> 
> Case 1:
> Y_ijk = mu + alpha_i + b_ij + theta_k + espilon_ijk 
> alpha = fixed effect for group, theta = fixed effect for time, 
> b = random effect per patient; b_ij ~ N(0, tau_i)  ## variance of random
> effect depends on treatment
> 
> Case 2: 
> Y_ijk = mu + alpha_i + Indicator_treat_i * b_treatment_ij + 
> 		Indicator_placebo_i * b_placebo_ij + theta_k +
> espilon_ijk
> 
> Indicator_treat_i = 1 if i is in treatment group, 0 otherwise 
> Indicator_placebo_i = 1 if i is in placebo group, 0 otherwise
> 
> where b_treatment_ij and b_placebo_ij are different random effects
> terms, with
> different variances; only one will apply per patient equation as per the
> indicator 
> variables.  The cumbersome notation allows for a covariance since we now
> have "two" random effects. (although it seem nonsensical to want such a 
> covariance)
> 
> Does fm.no.cov estimates Case 1 model and fm.cov estimates Case 2 model?
> 
> Cheers,
> Dave
> 
> 
> 
> 
> 
> 
> 
> 
> -----Original Message-----
> From: Simon Blomberg [mailto:s.blomberg1 at uq.edu.au] 
> Sent: Wednesday, July 11, 2007 1:58 AM
> To: Andrew Robinson
> Cc: Afshartous, David; r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] random effect variance per treatment group in
> lmer
> 
> I think he is asking to stratify the variance of the innermost
> residuals, or at least it's not clear. In lme that can be accomplished
> with weights=varFixed(~1|Patient).
> 
> To stratify at different levels of nesting, say the data is this:
>  dat <- data.frame(inner=rep(1:10, each=5), outer=rep(1:2, each=25),
> x=rnorm(50))
> 
> Then this call to lme does the job:
> 
>  fit <- lme(x ~ 1, random=list(outer=~1, inner=~1), data=dat,
> weights=varComb(varIdent(form=~1|outer), varIdent(form=~1|inner)))
> 
> edited output:
> 
> Combination of variance functions: 
>  Structure: Different standard deviations per stratum
>  Formula: ~1 | outer
>  Parameter estimates:
>         1         2 
> 1.0000000 0.5170794
>  Structure: Different standard deviations per stratum
>  Formula: ~1 | inner
>  Parameter estimates:
>         1         2         3         4         5         6         7
> 8
> 1.0000000 0.3127693 0.4475444 0.7323698 0.3647991 0.5962917 1.4127508
> 1.7664527 
>         9        10 
> 0.9475334 0.3666155 
> 
> Cheers,
> 
> Simon.
> 
> weights=varOn Wed, 2007-07-11 at 15:04 +1000, Andrew Robinson wrote:
> > Hi David,
> > 
> > as far as I am aware, there is no option for stratifying the variance 
> > of random effects in either lme or lmer.  One can stratify the 
> > variance of the innermost residuals in lme, but that is different than
> 
> > what you are asking for.
> > 
> > Cheers,
> > 
> > Andrew
> > 
> > 
> > On Tue, Jul 10, 2007 at 10:23:21AM -0400, Afshartous, David wrote:
> > > 
> > > All,
> > > I didn't receive a response to the query below sent to the general 
> > > R-help mailing list so figured I'd try this mailing list.  Apologies
> 
> > > in advance if this is an overly simplistic question for this list; I
> 
> > > just started w/ lmer after not using lme for awhile.
> > > Cheers,
> > > Dave
> > > 
> > > 
> > > 
> > > 
> > > ___________________________________________________________
> > > 
> > > All,
> > >  
> > > How does one specify a model in lmer such that say the random effect
> 
> > > for
> > > 
> > > the intercept has a different variance per treatment group?  
> > > Thus, in the model equation, we'd have say b_ij represent the random
> 
> > > effect for patient j in treatment group i, with variance depending 
> > > on i, i.e,
> > > var(b_ij) = tau_i.
> > >  
> > > Didn't see this in the docs or Pinherio & Bates (section 5.2 is 
> > > specific for modelling within group errors).  Sample repeated 
> > > measures code below is for a single random effect variance, where 
> > > the random effect corresponds to patient.
> > > cheers,
> > > dave
> > >  
> > >  
> > > z <- rnorm(24, mean=0, sd=1)
> > > time <- factor(paste("Time-", rep(1:6, 4), sep="")) Patient <- 
> > > rep(1:4, each = 6) drug <- factor(rep(c("D", "P"), each = 6, times =
> 
> > > 2)) ## P = placebo, D = Drug dat.new <- data.frame(time, drug, z, 
> > > Patient) fm =  lmer(z ~ drug + time + (1 | Patient), data = dat.new 
> > > )
> > > 
> > > _______________________________________________
> > > R-sig-mixed-models at r-project.org mailing list 
> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > 
> --
> Simon Blomberg, BSc (Hons), PhD, MAppStat. 
> Lecturer and Consultant Statistician
> Faculty of Biological and Chemical Sciences The University of Queensland
> St. Lucia Queensland 4072 Australia Room 320 Goddard Building (8)
> T: +61 7 3365 2506
> email: S.Blomberg1_at_uq.edu.au
> 
> Policies:
> 1.  I will NOT analyse your data for you.
> 2.  Your deadline is your problem.
> 
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of
> data. - John Tukey.

-- 
Andrew Robinson  
Department of Mathematics and Statistics            Tel: +61-3-8344-9763
University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
http://www.ms.unimelb.edu.au/~andrewpr
http://blogs.mbs.edu/fishing-in-the-bay/



From alanc at umit.maine.edu  Thu Jul 12 00:39:44 2007
From: alanc at umit.maine.edu (Alan Cobo-Lewis)
Date: Wed, 11 Jul 2007 18:39:44 -0400
Subject: [R-sig-ME] random effect variance per treatment group in lmer
In-Reply-To: <mailman.23.1184148017.29558.r-sig-mixed-models@r-project.org>
References: <mailman.23.1184148017.29558.r-sig-mixed-models@r-project.org>
Message-ID: <fc.004c4d19316fbce23b9aca007ddaf390.3172e8d6@umit.maine.edu>


Dave,

How about using stratifying variance on level of drug using
( 0 + as.numeric(drug=="D") | Patient ) + ( 0 + as.numeric(drug=="P") | Patient )
Here's some code (whose sim also builds in a fixed effect of time that applies only to the Drug condition).

set.seed(500)
n.timepoints <- 8
n.subj.per.tx <- 20
sd.d <- 5; sd.p <- 2; sd.res <- 1.3
drug <- factor(rep(c("D", "P"), each = n.timepoints, times = n.subj.per.tx))
drug.baseline <- rep( c(0,5), each=n.timepoints, times=n.subj.per.tx )
Patient <- rep(1:(n.subj.per.tx*2), each = n.timepoints)
Patient.baseline <- rep( rnorm( n.subj.per.tx*2, sd=c(sd.d, sd.p) ), each=n.timepoints )
time <- factor(paste("Time-", rep(1:n.timepoints, n.subj.per.tx*2), sep="")) 
time.baseline <- rep(1:n.timepoints,n.subj.per.tx*2)*as.numeric(drug=="D")
dv <- rnorm( n.subj.per.tx*n.timepoints*2, mean=time.baseline+Patient.baseline+drug.baseline, sd=sd.res )
dat.new <- data.frame(time, drug, dv, Patient) 
xyplot( dv~time|drug, group=Patient, type="l", data=dat.new )
# fit model treats time as a quantitative predictor
( fm.het <- lmer( dv ~ rep(1:n.timepoints, n.subj.per.tx*2)*drug + ( 0 + as.numeric(drug=="D") | Patient ) + ( 0 + as.numeric(drug=="P") | Patient ), data=dat.new ) )


HTH,
alan


>From: "Afshartous, David" <afshart at exchange.sba.miami.edu>
 asked:

>
>All,
>I didn't receive a response to the query below sent to the general
>R-help mailing list so figured I'd try this mailing list.  Apologies
>in advance if this is an overly simplistic question for this list; I
>just started 
>w/ lmer after not using lme for awhile.
>Cheers,
>Dave 
>
>
>__________________________________________________________
>
>All,
> 
>How does one specify a model in lmer such that say the random effect for
>
>the intercept has a different variance per treatment group?  
>Thus, in the model equation, we'd have say b_ij represent the random
>effect
>for patient j in treatment group i, with variance depending on i, i.e,
>var(b_ij) = tau_i.
> 
>Didn't see this in the docs or Pinherio & Bates (section 5.2 is specific
>for 
>modelling within group errors).  Sample repeated measures code below is
>for 
>a single random effect variance, where the random effect corresponds to
>patient.
>cheers,
>dave
> 
> 
>z <- rnorm(24, mean=0, sd=1)
>time <- factor(paste("Time-", rep(1:6, 4), sep="")) 
>Patient <- rep(1:4, each = 6) 
>drug <- factor(rep(c("D", "P"), each = 6, times = 2)) ## P = placebo, D
>= Drug
>dat.new <- data.frame(time, drug, z, Patient) 
>fm =  lmer(z ~ drug + time + (1 | Patient), data = dat.new )



--
Alan B. Cobo-Lewis, Ph.D.		(207) 581-3840 tel
Department of Psychology		(207) 581-6128 fax
University of Maine
Orono, ME 04469-5742     		alanc at maine.edu

http://www.umaine.edu/visualperception



From alanc at umit.maine.edu  Thu Jul 12 00:47:40 2007
From: alanc at umit.maine.edu (Alan Cobo-Lewis)
Date: Wed, 11 Jul 2007 18:47:40 -0400
Subject: [R-sig-ME] random effect variance per treatment group in lmer
In-Reply-To: <mailman.199.1184187515.2070.r-sig-mixed-models@r-project.org>
References: <mailman.199.1184187515.2070.r-sig-mixed-models@r-project.org>
Message-ID: <fc.004c4d193172ebbb3b9aca00d002bdd4.3172eee8@umit.maine.edu>


From: "Afshartous, David" <afshart at exchange.sba.miami.edu>
Subject: Re: [R-sig-ME]

"Afshartous, David" <afshart at exchange.sba.miami.edu> wrote:
>(although it seem nonsensical to want such a covariance)

Dave,

Doug Bates' lmer formulas offer an elegant notation for constraining covariances to zero.

You won't have a covariance parameter if you use
( 0 + as.numeric(drug=="D") | Patient ) + ( 0 + as.numeric(drug=="P") | Patient )

which is why you'd want to use two terms instead of combining them as
( 0 + as.numeric(drug=="D") + as.numeric(drug=="P") | Patient )
because this second version would give you the silly covariace parameter (which unsurprisingly would always have the value 0, even though it would burn a degree of freedom)

alan

--
Alan B. Cobo-Lewis, Ph.D.		(207) 581-3840 tel
Department of Psychology		(207) 581-6128 fax
University of Maine
Orono, ME 04469-5742     		alanc at maine.edu

http://www.umaine.edu/visualperception



From s.blomberg1 at uq.edu.au  Thu Jul 12 02:09:59 2007
From: s.blomberg1 at uq.edu.au (Simon Blomberg)
Date: Thu, 12 Jul 2007 10:09:59 +1000
Subject: [R-sig-ME] random effect variance per treatment group in lmer
In-Reply-To: <20070711205744.GK5296@ms.unimelb.edu.au>
References: <1184133483.4812.95.camel@sib-sblomber01d.sib.uq.edu.au>
	<6BCB4D493A447546A8126F24332056E8063E92B9@school1.business.edu>
	<20070711205744.GK5296@ms.unimelb.edu.au>
Message-ID: <1184198999.4902.51.camel@sib-sblomber01d.sib.uq.edu.au>

On Thu, 2007-07-12 at 06:57 +1000, Andrew Robinson wrote:
> Dave,
> 
> I don't feel that I am sufficiently well informed about the
> conventions in lmer to comment.  It could work that way.  I suggest
> that you try some simulations, if you are not convinced by the
> solution suggested offline.  
> 
> Cheers,
> 
> Andrew
> 
> On Wed, Jul 11, 2007 at 11:23:39AM -0400, Afshartous, David wrote:
> >  
> > Simon, Andrew:
> > 
> > Thanks for the replies.
> > I am not interested in stratifying the variance of the innermost
> > residuals,
> > but rather the variance of the random effects, viz., b_ij (drug i,
> > patient j) 
> > is a random variable w/ variance depending on i.  
> > 
> > Possible solution suggested offline for previously supplied pseudo data:
> > 
> > fm.cov =  lmer(z ~ drug + time + (drug|Patient), data = dat.new ) 

The above model specifies a random intercept with one random effect per
Patient, and a random slope term for drug, with 1 random effect per
patient. Covariances of the random effects for intercept and drug are
estimated.

This is the model with zero covariances for the random effects, with
Patient as the single level of grouping:

fm.cov <- lmer(z ~ drug + time + (1|Patient) + (0 + drug|Patient),
data=dat.new)


> > OR,
> > fm.no.cov  =  lmer(z ~ drug + time + (0 + drug|Patient), data = dat.new
> > ) 
> > 
> > Formally, consider:
> > 
> > Case 1:
> > Y_ijk = mu + alpha_i + b_ij + theta_k + espilon_ijk 
> > alpha = fixed effect for group, theta = fixed effect for time, 
> > b = random effect per patient; b_ij ~ N(0, tau_i)  ## variance of random
> > effect depends on treatment

If your notation is correct, then this is the lmer call:

fm <- lmer(z ~ drug + time + (1|drug:Patient), data=dat.new)

So you get different random effects on the intercept for each drug *
Patient combination. you can estimate one variance of these random
effects.

> > 
> > Case 2: 
> > Y_ijk = mu + alpha_i + Indicator_treat_i * b_treatment_ij + 
> > 		Indicator_placebo_i * b_placebo_ij + theta_k +
> > espilon_ijk

Hold on, I think the above model can be rewritten as:

Y_ijk = mu + alpha_i + Indicator_i * b1_i + Indicator_ij * b2_ij +
theta_k + epsilon_ijk


fm <- lmer(z ~ drug + time + (1|drug) + (1|drug:Patient), data=dat.new)

Here we have 2 levels of grouping of random effects on the intercept: at
the drug level (b1), and at the drug*patient level (or equivalently,
Patient within drug level (b2)). So two variances are estimated: for b1
and b2. So to get the total random effect for each patient, just sum the
appropriate random effects across the grouping levels.

The only trick with lmer (compared to lme) is that the Patient j's
should have unique identifiers. Don't have Patients  1,2,3 for within
treatment 1 and 1,2,3 for patients within treatment 2. Use 1,2,3 for
treatment 1 and 4,5,6 for treatment 2 etc.

I hope I have now understood your problem correctly!

Simon.

> > 
> > Indicator_treat_i = 1 if i is in treatment group, 0 otherwise 
> > Indicator_placebo_i = 1 if i is in placebo group, 0 otherwise
> > 
> > where b_treatment_ij and b_placebo_ij are different random effects
> > terms, with
> > different variances; only one will apply per patient equation as per the
> > indicator 
> > variables.  The cumbersome notation allows for a covariance since we now
> > have "two" random effects. (although it seem nonsensical to want such a 
> > covariance)
> > 
> > Does fm.no.cov estimates Case 1 model and fm.cov estimates Case 2 model?
> > 
> > Cheers,
> > Dave
> > 
> > 
> > 
> > 
> > 
> > 
> > 
> > 
> > -----Original Message-----
> > From: Simon Blomberg [mailto:s.blomberg1 at uq.edu.au] 
> > Sent: Wednesday, July 11, 2007 1:58 AM
> > To: Andrew Robinson
> > Cc: Afshartous, David; r-sig-mixed-models at r-project.org
> > Subject: Re: [R-sig-ME] random effect variance per treatment group in
> > lmer
> > 
> > I think he is asking to stratify the variance of the innermost
> > residuals, or at least it's not clear. In lme that can be accomplished
> > with weights=varFixed(~1|Patient).
> > 
> > To stratify at different levels of nesting, say the data is this:
> >  dat <- data.frame(inner=rep(1:10, each=5), outer=rep(1:2, each=25),
> > x=rnorm(50))
> > 
> > Then this call to lme does the job:
> > 
> >  fit <- lme(x ~ 1, random=list(outer=~1, inner=~1), data=dat,
> > weights=varComb(varIdent(form=~1|outer), varIdent(form=~1|inner)))
> > 
> > edited output:
> > 
> > Combination of variance functions: 
> >  Structure: Different standard deviations per stratum
> >  Formula: ~1 | outer
> >  Parameter estimates:
> >         1         2 
> > 1.0000000 0.5170794
> >  Structure: Different standard deviations per stratum
> >  Formula: ~1 | inner
> >  Parameter estimates:
> >         1         2         3         4         5         6         7
> > 8
> > 1.0000000 0.3127693 0.4475444 0.7323698 0.3647991 0.5962917 1.4127508
> > 1.7664527 
> >         9        10 
> > 0.9475334 0.3666155 
> > 
> > Cheers,
> > 
> > Simon.
> > 
> > weights=varOn Wed, 2007-07-11 at 15:04 +1000, Andrew Robinson wrote:
> > > Hi David,
> > > 
> > > as far as I am aware, there is no option for stratifying the variance 
> > > of random effects in either lme or lmer.  One can stratify the 
> > > variance of the innermost residuals in lme, but that is different than
> > 
> > > what you are asking for.
> > > 
> > > Cheers,
> > > 
> > > Andrew
> > > 
> > > 
> > > On Tue, Jul 10, 2007 at 10:23:21AM -0400, Afshartous, David wrote:
> > > > 
> > > > All,
> > > > I didn't receive a response to the query below sent to the general 
> > > > R-help mailing list so figured I'd try this mailing list.  Apologies
> > 
> > > > in advance if this is an overly simplistic question for this list; I
> > 
> > > > just started w/ lmer after not using lme for awhile.
> > > > Cheers,
> > > > Dave
> > > > 
> > > > 
> > > > 
> > > > 
> > > > ___________________________________________________________
> > > > 
> > > > All,
> > > >  
> > > > How does one specify a model in lmer such that say the random effect
> > 
> > > > for
> > > > 
> > > > the intercept has a different variance per treatment group?  
> > > > Thus, in the model equation, we'd have say b_ij represent the random
> > 
> > > > effect for patient j in treatment group i, with variance depending 
> > > > on i, i.e,
> > > > var(b_ij) = tau_i.
> > > >  
> > > > Didn't see this in the docs or Pinherio & Bates (section 5.2 is 
> > > > specific for modelling within group errors).  Sample repeated 
> > > > measures code below is for a single random effect variance, where 
> > > > the random effect corresponds to patient.
> > > > cheers,
> > > > dave
> > > >  
> > > >  
> > > > z <- rnorm(24, mean=0, sd=1)
> > > > time <- factor(paste("Time-", rep(1:6, 4), sep="")) Patient <- 
> > > > rep(1:4, each = 6) drug <- factor(rep(c("D", "P"), each = 6, times =
> > 
> > > > 2)) ## P = placebo, D = Drug dat.new <- data.frame(time, drug, z, 
> > > > Patient) fm =  lmer(z ~ drug + time + (1 | Patient), data = dat.new 
> > > > )
> > > > 
> > > > _______________________________________________
> > > > R-sig-mixed-models at r-project.org mailing list 
> > > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > > 
> > --
> > Simon Blomberg, BSc (Hons), PhD, MAppStat. 
> > Lecturer and Consultant Statistician
> > Faculty of Biological and Chemical Sciences The University of Queensland
> > St. Lucia Queensland 4072 Australia Room 320 Goddard Building (8)
> > T: +61 7 3365 2506
> > email: S.Blomberg1_at_uq.edu.au
> > 
> > Policies:
> > 1.  I will NOT analyse your data for you.
> > 2.  Your deadline is your problem.
> > 
> > The combination of some data and an aching desire for an answer does not
> > ensure that a reasonable answer can be extracted from a given body of
> > data. - John Tukey.
> 
-- 
Simon Blomberg, BSc (Hons), PhD, MAppStat. 
Lecturer and Consultant Statistician 
Faculty of Biological and Chemical Sciences 
The University of Queensland 
St. Lucia Queensland 4072 
Australia
Room 320 Goddard Building (8)
T: +61 7 3365 2506 
email: S.Blomberg1_at_uq.edu.au

Policies:
1.  I will NOT analyse your data for you.
2.  Your deadline is your problem.

The combination of some data and an aching desire for 
an answer does not ensure that a reasonable answer can 
be extracted from a given body of data. - John Tukey.



From afshart at exchange.sba.miami.edu  Thu Jul 12 23:30:25 2007
From: afshart at exchange.sba.miami.edu (Afshartous, David)
Date: Thu, 12 Jul 2007 17:30:25 -0400
Subject: [R-sig-ME] random effect variance per treatment group in lmer
In-Reply-To: <1184198999.4902.51.camel@sib-sblomber01d.sib.uq.edu.au>
Message-ID: <6BCB4D493A447546A8126F24332056E8064AA2CA@school1.business.edu>

 
Simon,
Thanks for your extensive comments. Please see my replies below.
I checked out all lmer calls and so far it seems that none
achieve the desired variance stratification in the desired manner.
Part of the issure may rest in not wanting to have a random 
effect for the drug term (see below). If I'm missing something
incredibly simple I apologize in advance to the list.
Dave

> -----Original Message-----
> From: Simon Blomberg [mailto:s.blomberg1 at uq.edu.au] 
> Sent: Wednesday, July 11, 2007 8:10 PM
> To: Afshartous, David; r-sig-mixed-models at r-project.org; 
> r-sig-mixed-models at r-project.org
> Cc: Andrew Robinson
> Subject: Re: [R-sig-ME] random effect variance per treatment 
> group in lmer
> 
> On Thu, 2007-07-12 at 06:57 +1000, Andrew Robinson wrote:
> > Dave,
> > 
> > I don't feel that I am sufficiently well informed about the 
> > conventions in lmer to comment.  It could work that way.  I suggest 
> > that you try some simulations, if you are not convinced by the 
> > solution suggested offline.
> > 
> > Cheers,
> > 
> > Andrew
> > 
> > On Wed, Jul 11, 2007 at 11:23:39AM -0400, Afshartous, David wrote:
> > >  
> > > Simon, Andrew:
> > > 
> > > Thanks for the replies.
> > > I am not interested in stratifying the variance of the innermost 
> > > residuals, but rather the variance of the random effects, 
> viz., b_ij 
> > > (drug i, patient j) is a random variable w/ variance 
> depending on i.
> > > 
> > > Possible solution suggested offline for previously 
> supplied pseudo data:
> > > 
> > > fm.cov =  lmer(z ~ drug + time + (drug|Patient), data = dat.new )
> 
> The above model specifies a random intercept with one random 
> effect per Patient, and a random slope term for drug, with 1 
> random effect per patient. Covariances of the random effects 
> for intercept and drug are estimated.
> 

upon further thought, this is not precisely the model I want since this 
model treats the drug shift from the intercept as random per patient, 
and I want this to be a fixed effect only.  
However, as the random effect on this shift its own variance, this model

seems to implicitly stratify the random effect variance on the intercept

per drug. I.e., there is patient level variability around an intercept
term (representing the reference level of drug), and there is a separate

patient level variability around the drug slope, representing the shift
to the 
next level of drug.  but once again, I'd rather not have a random 
effect for the drug term. 

> This is the model with zero covariances for the random 
> effects, with Patient as the single level of grouping:
> 
> fm.cov <- lmer(z ~ drug + time + (1|Patient) + (0 + drug|Patient),
> data=dat.new)
> 

BTW, this model estimates okay but has the following problem w/ invoking
coef():
Error in coef(fm.no.cov.2) : unable to align random and fixed effects

> 
> > > OR,
> > > fm.no.cov  =  lmer(z ~ drug + time + (0 + drug|Patient), data = 
> > > dat.new
> > > )
> > > 
> > > Formally, consider:
> > > 
> > > Case 1:
> > > Y_ijk = mu + alpha_i + b_ij + theta_k + espilon_ijk alpha = fixed 
> > > effect for group, theta = fixed effect for time, b = 
> random effect 
> > > per patient; b_ij ~ N(0, tau_i)  ## variance of random effect 
> > > depends on treatment
> 
> If your notation is correct, then this is the lmer call:
> 
> fm <- lmer(z ~ drug + time + (1|drug:Patient), data=dat.new)
> 
> So you get different random effects on the intercept for each 
> drug * Patient combination. you can estimate one variance of 
> these random effects.
> 

This lmer call still doesn't model b_ij ~ N(0, tau_i), i.e., more than 
one variance.  (BTW, I assume that the "drug:Patient" can be replaced 
by "Patient" when patients only receive 1 drug, as both versions
produced
identical results for the pseudo data below where that is the case).

> > > 
> > > Case 2: 
> > > Y_ijk = mu + alpha_i + Indicator_treat_i * b_treatment_ij + 
> > > 		Indicator_placebo_i * b_placebo_ij + theta_k + 
> espilon_ijk
> 
> Hold on, I think the above model can be rewritten as:
> 
> Y_ijk = mu + alpha_i + Indicator_i * b1_i + Indicator_ij * 
> b2_ij + theta_k + epsilon_ijk
> 
> 
> fm <- lmer(z ~ drug + time + (1|drug) + (1|drug:Patient), 
> data=dat.new)
> 
> Here we have 2 levels of grouping of random effects on the 
> intercept: at the drug level (b1), and at the drug*patient 
> level (or equivalently, Patient within drug level (b2)). So 
> two variances are estimated: for b1 and b2. So to get the 
> total random effect for each patient, just sum the 
> appropriate random effects across the grouping levels.
> 

Although I'm still not quite sure this model can be 
re-written as such, this model doesn't seem to stratify the
random effect variance as desired.  There is a random effect on 
the intercept for every patient (once again, "drug:Patient" can be 
replaced by "Patient" for pseudo data below), and there is a random
effect 
on the intercept for every drug, but the latter's probability 
distribution does not have its variance depend on drug level.


> The only trick with lmer (compared to lme) is that the 
> Patient j's should have unique identifiers. Don't have 
> Patients  1,2,3 for within treatment 1 and 1,2,3 for patients 
> within treatment 2. Use 1,2,3 for treatment 1 and 4,5,6 for 
> treatment 2 etc.
> 

What does one do if the data is from a crossover study and 
indeed patients 1,2,3 exist in both treatment 1 and treatment 2?


> I hope I have now understood your problem correctly!
> 
> Simon.
> 
> > > 
> > > Indicator_treat_i = 1 if i is in treatment group, 0 otherwise 
> > > Indicator_placebo_i = 1 if i is in placebo group, 0 otherwise
> > > 
> > > where b_treatment_ij and b_placebo_ij are different 
> random effects 
> > > terms, with different variances; only one will apply per patient 
> > > equation as per the indicator variables.  The cumbersome notation 
> > > allows for a covariance since we now have "two" random effects. 
> > > (although it seem nonsensical to want such a
> > > covariance)
> > > 
> > > Does fm.no.cov estimates Case 1 model and fm.cov 
> estimates Case 2 model?
> > > 
> > > Cheers,
> > > Dave
> > > 
> > > 
> > > 
> > > 
> > > 
> > > 
> > > 
> > > 
> > > -----Original Message-----
> > > From: Simon Blomberg [mailto:s.blomberg1 at uq.edu.au]
> > > Sent: Wednesday, July 11, 2007 1:58 AM
> > > To: Andrew Robinson
> > > Cc: Afshartous, David; r-sig-mixed-models at r-project.org
> > > Subject: Re: [R-sig-ME] random effect variance per 
> treatment group 
> > > in lmer
> > > 
> > > I think he is asking to stratify the variance of the innermost 
> > > residuals, or at least it's not clear. In lme that can be 
> > > accomplished with weights=varFixed(~1|Patient).
> > > 
> > > To stratify at different levels of nesting, say the data is this:
> > >  dat <- data.frame(inner=rep(1:10, each=5), 
> outer=rep(1:2, each=25),
> > > x=rnorm(50))
> > > 
> > > Then this call to lme does the job:
> > > 
> > >  fit <- lme(x ~ 1, random=list(outer=~1, inner=~1), data=dat, 
> > > weights=varComb(varIdent(form=~1|outer), varIdent(form=~1|inner)))
> > > 
> > > edited output:
> > > 
> > > Combination of variance functions: 
> > >  Structure: Different standard deviations per stratum
> > >  Formula: ~1 | outer
> > >  Parameter estimates:
> > >         1         2 
> > > 1.0000000 0.5170794
> > >  Structure: Different standard deviations per stratum
> > >  Formula: ~1 | inner
> > >  Parameter estimates:
> > >         1         2         3         4         5         
> 6         7
> > > 8
> > > 1.0000000 0.3127693 0.4475444 0.7323698 0.3647991 0.5962917 
> > > 1.4127508
> > > 1.7664527 
> > >         9        10 
> > > 0.9475334 0.3666155
> > > 
> > > Cheers,
> > > 
> > > Simon.
> > > 
> > > weights=varOn Wed, 2007-07-11 at 15:04 +1000, Andrew 
> Robinson wrote:
> > > > Hi David,
> > > > 
> > > > as far as I am aware, there is no option for stratifying the 
> > > > variance of random effects in either lme or lmer.  One can 
> > > > stratify the variance of the innermost residuals in 
> lme, but that 
> > > > is different than
> > > 
> > > > what you are asking for.
> > > > 
> > > > Cheers,
> > > > 
> > > > Andrew
> > > > 
> > > > 
> > > > On Tue, Jul 10, 2007 at 10:23:21AM -0400, Afshartous, 
> David wrote:
> > > > > 
> > > > > All,
> > > > > I didn't receive a response to the query below sent to the 
> > > > > general R-help mailing list so figured I'd try this mailing 
> > > > > list.  Apologies
> > > 
> > > > > in advance if this is an overly simplistic question for this 
> > > > > list; I
> > > 
> > > > > just started w/ lmer after not using lme for awhile.
> > > > > Cheers,
> > > > > Dave
> > > > > 
> > > > > 
> > > > > 
> > > > > 
> > > > > ___________________________________________________________
> > > > > 
> > > > > All,
> > > > >  
> > > > > How does one specify a model in lmer such that say the random 
> > > > > effect
> > > 
> > > > > for
> > > > > 
> > > > > the intercept has a different variance per treatment group?  
> > > > > Thus, in the model equation, we'd have say b_ij represent the 
> > > > > random
> > > 
> > > > > effect for patient j in treatment group i, with variance 
> > > > > depending on i, i.e,
> > > > > var(b_ij) = tau_i.
> > > > >  
> > > > > Didn't see this in the docs or Pinherio & Bates 
> (section 5.2 is 
> > > > > specific for modelling within group errors).  Sample repeated 
> > > > > measures code below is for a single random effect variance, 
> > > > > where the random effect corresponds to patient.
> > > > > cheers,
> > > > > dave
> > > > >  
> > > > >  
> > > > > z <- rnorm(24, mean=0, sd=1)
> > > > > time <- factor(paste("Time-", rep(1:6, 4), sep="")) 
> Patient <- 
> > > > > rep(1:4, each = 6) drug <- factor(rep(c("D", "P"), each = 6, 
> > > > > times =
> > > 
> > > > > 2)) ## P = placebo, D = Drug dat.new <- 
> data.frame(time, drug, 
> > > > > z,
> > > > > Patient) fm =  lmer(z ~ drug + time + (1 | Patient), data = 
> > > > > dat.new
> > > > > )
> > > > > 
> > > > > _______________________________________________
> > > > > R-sig-mixed-models at r-project.org mailing list 
> > > > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > > > 
> > > --
> > > Simon Blomberg, BSc (Hons), PhD, MAppStat. 
> > > Lecturer and Consultant Statistician Faculty of Biological and 
> > > Chemical Sciences The University of Queensland St. Lucia 
> Queensland 
> > > 4072 Australia Room 320 Goddard Building (8)
> > > T: +61 7 3365 2506
> > > email: S.Blomberg1_at_uq.edu.au
> > > 
> > > Policies:
> > > 1.  I will NOT analyse your data for you.
> > > 2.  Your deadline is your problem.
> > > 
> > > The combination of some data and an aching desire for an 
> answer does 
> > > not ensure that a reasonable answer can be extracted from a given 
> > > body of data. - John Tukey.
> > 
> --
> Simon Blomberg, BSc (Hons), PhD, MAppStat. 
> Lecturer and Consultant Statistician
> Faculty of Biological and Chemical Sciences The University of 
> Queensland St. Lucia Queensland 4072 Australia Room 320 
> Goddard Building (8)
> T: +61 7 3365 2506
> email: S.Blomberg1_at_uq.edu.au
> 
> Policies:
> 1.  I will NOT analyse your data for you.
> 2.  Your deadline is your problem.
> 
> The combination of some data and an aching desire for an 
> answer does not ensure that a reasonable answer can be 
> extracted from a given body of data. - John Tukey.
> 
>



From afshart at exchange.sba.miami.edu  Fri Jul 13 16:44:04 2007
From: afshart at exchange.sba.miami.edu (Afshartous, David)
Date: Fri, 13 Jul 2007 10:44:04 -0400
Subject: [R-sig-ME] random effect variance per treatment group in lmer
In-Reply-To: <fc.004c4d19316fbce23b9aca007ddaf390.3172e8d6@umit.maine.edu>
Message-ID: <6BCB4D493A447546A8126F24332056E8064AA386@school1.business.edu>

 
Alan,

Thanks for the suggestion.  I noticed the following error msg
for that lmer call:

> ( fm.het <- lmer( dv ~ rep(1:n.timepoints, n.subj.per.tx*2)*drug + ( 0
+ as.numeric(drug=="D") | Patient ) + ( 0 + as.numeric(drug=="P") |
Patient ), data=dat.new ) )
Error: length(term) == 3 is not TRUE

I tried a few changes to the model but the error still exists; I'll 
keep checking.  I assume the rationale for the structure of your lmer
call, where you use as.numeric as opposed to just drug above, is to
insure that
you do not introduce a random effect for drug into the model?

Regards,
Dave



> -----Original Message-----
> From: Alan Cobo-Lewis [mailto:alanc at umit.maine.edu] 
> Sent: Wednesday, July 11, 2007 6:40 PM
> To: r-sig-mixed-models at r-project.org
> Cc: " "Afshartous at basalt.its.maine.edu; Afshartous, David; 
> Andrew Robinson
> Subject: Re: random effect variance per treatment group in lmer
> 
> 
> Dave,
> 
> How about using stratifying variance on level of drug using ( 
> 0 + as.numeric(drug=="D") | Patient ) + ( 0 + 
> as.numeric(drug=="P") | Patient ) Here's some code (whose sim 
> also builds in a fixed effect of time that applies only to 
> the Drug condition).
> 
> set.seed(500)
> n.timepoints <- 8
> n.subj.per.tx <- 20
> sd.d <- 5; sd.p <- 2; sd.res <- 1.3
> drug <- factor(rep(c("D", "P"), each = n.timepoints, times = 
> n.subj.per.tx)) drug.baseline <- rep( c(0,5), 
> each=n.timepoints, times=n.subj.per.tx ) Patient <- 
> rep(1:(n.subj.per.tx*2), each = n.timepoints) 
> Patient.baseline <- rep( rnorm( n.subj.per.tx*2, sd=c(sd.d, 
> sd.p) ), each=n.timepoints ) time <- factor(paste("Time-", 
> rep(1:n.timepoints, n.subj.per.tx*2), sep="")) time.baseline 
> <- rep(1:n.timepoints,n.subj.per.tx*2)*as.numeric(drug=="D")
> dv <- rnorm( n.subj.per.tx*n.timepoints*2, 
> mean=time.baseline+Patient.baseline+drug.baseline, sd=sd.res 
> ) dat.new <- data.frame(time, drug, dv, Patient) xyplot( 
> dv~time|drug, group=Patient, type="l", data=dat.new ) # fit 
> model treats time as a quantitative predictor ( fm.het <- 
> lmer( dv ~ rep(1:n.timepoints, n.subj.per.tx*2)*drug + ( 0 + 
> as.numeric(drug=="D") | Patient ) + ( 0 + 
> as.numeric(drug=="P") | Patient ), data=dat.new ) )
> 
> 
> HTH,
> alan
> 
> 
> >From: "Afshartous, David" <afshart at exchange.sba.miami.edu>
>  asked:
> 
> >
> >All,
> >I didn't receive a response to the query below sent to the general 
> >R-help mailing list so figured I'd try this mailing list.  
> Apologies in 
> >advance if this is an overly simplistic question for this 
> list; I just 
> >started w/ lmer after not using lme for awhile.
> >Cheers,
> >Dave
> >
> >
> >__________________________________________________________
> >
> >All,
> > 
> >How does one specify a model in lmer such that say the random effect 
> >for
> >
> >the intercept has a different variance per treatment group?  
> >Thus, in the model equation, we'd have say b_ij represent the random 
> >effect for patient j in treatment group i, with variance 
> depending on 
> >i, i.e,
> >var(b_ij) = tau_i.
> > 
> >Didn't see this in the docs or Pinherio & Bates (section 5.2 is 
> >specific for modelling within group errors).  Sample 
> repeated measures 
> >code below is for a single random effect variance, where the random 
> >effect corresponds to patient.
> >cheers,
> >dave
> > 
> > 
> >z <- rnorm(24, mean=0, sd=1)
> >time <- factor(paste("Time-", rep(1:6, 4), sep="")) Patient 
> <- rep(1:4, 
> >each = 6) drug <- factor(rep(c("D", "P"), each = 6, times = 
> 2)) ## P = 
> >placebo, D = Drug dat.new <- data.frame(time, drug, z, 
> Patient) fm =  
> >lmer(z ~ drug + time + (1 | Patient), data = dat.new )
> 
> 
> 
> --
> Alan B. Cobo-Lewis, Ph.D.		(207) 581-3840 tel
> Department of Psychology		(207) 581-6128 fax
> University of Maine
> Orono, ME 04469-5742     		alanc at maine.edu
> 
> http://www.umaine.edu/visualperception
> 
> 
>



From bates at stat.wisc.edu  Fri Jul 13 18:16:07 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 13 Jul 2007 11:16:07 -0500
Subject: [R-sig-ME] random effect variance per treatment group in lmer
In-Reply-To: <6BCB4D493A447546A8126F24332056E8064AA386@school1.business.edu>
References: <fc.004c4d19316fbce23b9aca007ddaf390.3172e8d6@umit.maine.edu>
	<6BCB4D493A447546A8126F24332056E8064AA386@school1.business.edu>
Message-ID: <40e66e0b0707130916n1210bc6bs1eb6e51dbac1e4aa@mail.gmail.com>

On 7/13/07, Afshartous, David <afshart at exchange.sba.miami.edu> wrote:

> Alan,

> Thanks for the suggestion.  I noticed the following error msg
> for that lmer call:

> > ( fm.het <- lmer( dv ~ rep(1:n.timepoints, n.subj.per.tx*2)*drug + ( 0
> + as.numeric(drug=="D") | Patient ) + ( 0 + as.numeric(drug=="P") |
> Patient ), data=dat.new ) )
> Error: length(term) == 3 is not TRUE

I expect that the problem is due to "AsIs" terms in the model frame
not being identified correctly in later function calls that build
model matrices.  Parsing model formulas and building the model frame
and model matrices in general settings is a bit of a black art.

The easiest way out is to add variables to the dat.new data frame. Say

dat.new$Dind <- as.numeric(dat.new$drug == "D")
dat.new$Pind <- as.numeric(dat.new$drug == "P")

(fm.het <- lmer(dv ~ ... + (0+Dind|Patient)+(0+Pind|Patient))

I'm afraid I don't understand what the expression

rep(1:n.timepoints, n.subj.per.tx*2)*drug

would mean.  It seems that the variable drug is a factor and it
doesn't make sense to multiply a factor by an integer variable.

I hope this helps,
Doug Bates

> I tried a few changes to the model but the error still exists; I'll
> keep checking.  I assume the rationale for the structure of your lmer
> call, where you use as.numeric as opposed to just drug above, is to
> insure that
> you do not introduce a random effect for drug into the model?
>
> Regards,
> Dave
>
>
>
> > -----Original Message-----
> > From: Alan Cobo-Lewis [mailto:alanc at umit.maine.edu]
> > Sent: Wednesday, July 11, 2007 6:40 PM
> > To: r-sig-mixed-models at r-project.org
> > Cc: " "Afshartous at basalt.its.maine.edu; Afshartous, David;
> > Andrew Robinson
> > Subject: Re: random effect variance per treatment group in lmer
> >
> >
> > Dave,
> >
> > How about using stratifying variance on level of drug using (
> > 0 + as.numeric(drug=="D") | Patient ) + ( 0 +
> > as.numeric(drug=="P") | Patient ) Here's some code (whose sim
> > also builds in a fixed effect of time that applies only to
> > the Drug condition).
> >
> > set.seed(500)
> > n.timepoints <- 8
> > n.subj.per.tx <- 20
> > sd.d <- 5; sd.p <- 2; sd.res <- 1.3
> > drug <- factor(rep(c("D", "P"), each = n.timepoints, times =
> > n.subj.per.tx)) drug.baseline <- rep( c(0,5),
> > each=n.timepoints, times=n.subj.per.tx ) Patient <-
> > rep(1:(n.subj.per.tx*2), each = n.timepoints)
> > Patient.baseline <- rep( rnorm( n.subj.per.tx*2, sd=c(sd.d,
> > sd.p) ), each=n.timepoints ) time <- factor(paste("Time-",
> > rep(1:n.timepoints, n.subj.per.tx*2), sep="")) time.baseline
> > <- rep(1:n.timepoints,n.subj.per.tx*2)*as.numeric(drug=="D")
> > dv <- rnorm( n.subj.per.tx*n.timepoints*2,
> > mean=time.baseline+Patient.baseline+drug.baseline, sd=sd.res
> > ) dat.new <- data.frame(time, drug, dv, Patient) xyplot(
> > dv~time|drug, group=Patient, type="l", data=dat.new ) # fit
> > model treats time as a quantitative predictor ( fm.het <-
> > lmer( dv ~ rep(1:n.timepoints, n.subj.per.tx*2)*drug + ( 0 +
> > as.numeric(drug=="D") | Patient ) + ( 0 +
> > as.numeric(drug=="P") | Patient ), data=dat.new ) )
> >
> >
> > HTH,
> > alan
> >
> >
> > >From: "Afshartous, David" <afshart at exchange.sba.miami.edu>
> >  asked:
> >
> > >
> > >All,
> > >I didn't receive a response to the query below sent to the general
> > >R-help mailing list so figured I'd try this mailing list.
> > Apologies in
> > >advance if this is an overly simplistic question for this
> > list; I just
> > >started w/ lmer after not using lme for awhile.
> > >Cheers,
> > >Dave
> > >
> > >
> > >__________________________________________________________
> > >
> > >All,
> > >
> > >How does one specify a model in lmer such that say the random effect
> > >for
> > >
> > >the intercept has a different variance per treatment group?
> > >Thus, in the model equation, we'd have say b_ij represent the random
> > >effect for patient j in treatment group i, with variance
> > depending on
> > >i, i.e,
> > >var(b_ij) = tau_i.
> > >
> > >Didn't see this in the docs or Pinherio & Bates (section 5.2 is
> > >specific for modelling within group errors).  Sample
> > repeated measures
> > >code below is for a single random effect variance, where the random
> > >effect corresponds to patient.
> > >cheers,
> > >dave
> > >
> > >
> > >z <- rnorm(24, mean=0, sd=1)
> > >time <- factor(paste("Time-", rep(1:6, 4), sep="")) Patient
> > <- rep(1:4,
> > >each = 6) drug <- factor(rep(c("D", "P"), each = 6, times =
> > 2)) ## P =
> > >placebo, D = Drug dat.new <- data.frame(time, drug, z,
> > Patient) fm =
> > >lmer(z ~ drug + time + (1 | Patient), data = dat.new )
> >
> >
> >
> > --
> > Alan B. Cobo-Lewis, Ph.D.             (207) 581-3840 tel
> > Department of Psychology              (207) 581-6128 fax
> > University of Maine
> > Orono, ME 04469-5742                  alanc at maine.edu
> >
> > http://www.umaine.edu/visualperception
> >
> >
> >
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From alanc at umit.maine.edu  Fri Jul 13 18:27:24 2007
From: alanc at umit.maine.edu (Alan Cobo-Lewis)
Date: Fri, 13 Jul 2007 12:27:24 -0400
Subject: [R-sig-ME] random effect variance per treatment group in lmer
In-Reply-To: <6BCB4D493A447546A8126F24332056E8064AA386@school1.business.edu>
References: <6BCB4D493A447546A8126F24332056E8064AA386@school1.business.edu>
Message-ID: <fc.004c4d19317a031e3b9aca007ddaf390.317a5579@umit.maine.edu>


Hmm, could it be a word-wrap issue? I just verified that the code works on R 2.5 with lme4 and lattice packages installed. See http://www.umaine.edu/visualperception/lme4het

The model I posted assumes that the subj-to-subj variability in baseline score has higher variability in the "D" condition than in the "P" condition. You are correct that there's no random effect for drug. I don't think you *want* there to be a
random effect for drug, since drug doesn't have levels sampled from some population (it's properly a fixed effect). Instead, the code I posted has the random effect of Patient with a higher variability in one level of drug than in the other level of
drug.

If you're looking some the drug to have a different time course for some patients than for other patients I think that'd be a random effect of Time. (To avoid overparameterization I think you'd almost surely want to treat time as a quantitative
predictor if you're going to model it as having a random effect.)

One of the reasons that I constructed a full example with a new sim was to get a big-enough data set together so that the lmer fit fairly obviously matched the parameters of the sim (to verify the correctness of the sim and the suggested model
formula). Another reason is that the code of your sim didn't actually have different subj-to-subj variability in the "D" condition than it did in the "P" condition, so a model with such an effect was overparameterized for your original simulated
data. Could this be why the lmer call I suggested failed for you?

BTW, nice to see someone from the UM School of Business (I didn't notice until just now what your email address said). I worked there about 20 years ago on the Applied AI Reporter when I was an undergraduate psychology major. But, looking at the SBA
web site, I recognize barely anyone, and those I do recognize probably wouldn't recognize me.

alan

"Afshartous, David" <afshart at exchange.sba.miami.edu> on Friday, July 13, 2007 at 10:44 AM -0500 wrote:
> 
>Alan,
>
>Thanks for the suggestion.  I noticed the following error msg
>for that lmer call:
>
>> ( fm.het <- lmer( dv ~ rep(1:n.timepoints, n.subj.per.tx*2)*drug + ( 0
>+ as.numeric(drug=="D") | Patient ) + ( 0 + as.numeric(drug=="P") |
>Patient ), data=dat.new ) )
>Error: length(term) == 3 is not TRUE
>
>I tried a few changes to the model but the error still exists; I'll 
>keep checking.  I assume the rationale for the structure of your lmer
>call, where you use as.numeric as opposed to just drug above, is to
>insure that
>you do not introduce a random effect for drug into the model?
>
>Regards,
>Dave
>
>
>
>> -----Original Message-----
>> From: Alan Cobo-Lewis [mailto:alanc at umit.maine.edu] 
>> Sent: Wednesday, July 11, 2007 6:40 PM
>> To: r-sig-mixed-models at r-project.org
>> Cc: " "Afshartous at basalt.its.maine.edu; Afshartous, David; 
>> Andrew Robinson
>> Subject: Re: random effect variance per treatment group in lmer
>> 
>> 
>> Dave,
>> 
>> How about using stratifying variance on level of drug using ( 
>> 0 + as.numeric(drug=="D") | Patient ) + ( 0 + 
>> as.numeric(drug=="P") | Patient ) Here's some code (whose sim 
>> also builds in a fixed effect of time that applies only to 
>> the Drug condition).
>> 
>> set.seed(500)
>> n.timepoints <- 8
>> n.subj.per.tx <- 20
>> sd.d <- 5; sd.p <- 2; sd.res <- 1.3
>> drug <- factor(rep(c("D", "P"), each = n.timepoints, times = 
>> n.subj.per.tx)) drug.baseline <- rep( c(0,5), 
>> each=n.timepoints, times=n.subj.per.tx ) Patient <- 
>> rep(1:(n.subj.per.tx*2), each = n.timepoints) 
>> Patient.baseline <- rep( rnorm( n.subj.per.tx*2, sd=c(sd.d, 
>> sd.p) ), each=n.timepoints ) time <- factor(paste("Time-", 
>> rep(1:n.timepoints, n.subj.per.tx*2), sep="")) time.baseline 
>> <- rep(1:n.timepoints,n.subj.per.tx*2)*as.numeric(drug=="D")
>> dv <- rnorm( n.subj.per.tx*n.timepoints*2, 
>> mean=time.baseline+Patient.baseline+drug.baseline, sd=sd.res 
>> ) dat.new <- data.frame(time, drug, dv, Patient) xyplot( 
>> dv~time|drug, group=Patient, type="l", data=dat.new ) # fit 
>> model treats time as a quantitative predictor ( fm.het <- 
>> lmer( dv ~ rep(1:n.timepoints, n.subj.per.tx*2)*drug + ( 0 + 
>> as.numeric(drug=="D") | Patient ) + ( 0 + 
>> as.numeric(drug=="P") | Patient ), data=dat.new ) )
>> 
>> 
>> HTH,
>> alan
>> 
>> 
>> >From: "Afshartous, David" <afshart at exchange.sba.miami.edu>
>>  asked:
>> 
>> >
>> >All,
>> >I didn't receive a response to the query below sent to the general 
>> >R-help mailing list so figured I'd try this mailing list.  
>> Apologies in 
>> >advance if this is an overly simplistic question for this 
>> list; I just 
>> >started w/ lmer after not using lme for awhile.
>> >Cheers,
>> >Dave
>> >
>> >
>> >__________________________________________________________
>> >
>> >All,
>> > 
>> >How does one specify a model in lmer such that say the random effect 
>> >for
>> >
>> >the intercept has a different variance per treatment group?  
>> >Thus, in the model equation, we'd have say b_ij represent the random 
>> >effect for patient j in treatment group i, with variance 
>> depending on 
>> >i, i.e,
>> >var(b_ij) = tau_i.
>> > 
>> >Didn't see this in the docs or Pinherio & Bates (section 5.2 is 
>> >specific for modelling within group errors).  Sample 
>> repeated measures 
>> >code below is for a single random effect variance, where the random 
>> >effect corresponds to patient.
>> >cheers,
>> >dave
>> > 
>> > 
>> >z <- rnorm(24, mean=0, sd=1)
>> >time <- factor(paste("Time-", rep(1:6, 4), sep="")) Patient 
>> <- rep(1:4, 
>> >each = 6) drug <- factor(rep(c("D", "P"), each = 6, times = 
>> 2)) ## P = 
>> >placebo, D = Drug dat.new <- data.frame(time, drug, z, 
>> Patient) fm =  
>> >lmer(z ~ drug + time + (1 | Patient), data = dat.new )
>> 
>> 
>> 
>> --
>> Alan B. Cobo-Lewis, Ph.D.		(207) 581-3840 tel
>> Department of Psychology		(207) 581-6128 fax
>> University of Maine
>> Orono, ME 04469-5742     		alanc at maine.edu
>> 
>> http://www.umaine.edu/visualperception
>> 
>> 
>> 
>



--
Alan B. Cobo-Lewis, Ph.D.		(207) 581-3840 tel
Department of Psychology		(207) 581-6128 fax
University of Maine
Orono, ME 04469-5742     		alanc at maine.edu

http://www.umaine.edu/visualperception



From alanc at umit.maine.edu  Fri Jul 13 18:36:11 2007
From: alanc at umit.maine.edu (Alan Cobo-Lewis)
Date: Fri, 13 Jul 2007 12:36:11 -0400
Subject: [R-sig-ME] random effect variance per treatment group in lmer
In-Reply-To: <40e66e0b0707130916n1210bc6bs1eb6e51dbac1e4aa@mail.gmail.com>
References: <fc.004c4d19316fbce23b9aca007ddaf390.3172e8d6@umit.maine.edu> <	>
	<6BCB4D493A447546A8126F24332056E8064AA386@school1.business.edu>
	<40e66e0b0707130916n1210bc6bs1eb6e51dbac1e4aa@mail.gmail.com>
Message-ID: <fc.004c4d19317a56603b9aca007ddaf390.317a605f@umit.maine.edu>


"Douglas Bates" <bates at stat.wisc.edu> on Friday, July 13, 2007 at 12:16 PM -0500 wrote:

>I'm afraid I don't understand what the expression
>
>rep(1:n.timepoints, n.subj.per.tx*2)*drug
>
>would mean.  It seems that the variable drug is a factor and it
>doesn't make sense to multiply a factor by an integer variable.

rep(1:n.timepoints, n.subj.per.tx*2) was a cheesy way of turning time back into a quantitative predictor.

Since rep(1:n.timepoints, n.subj.per.tx*2)*drug wasn't wrapped in I(), this expression in the context of a model formula indicates that there's a fixed linear effect of time, a main effect of drug, and an interaction term (in other words letting the
fixed effect of time be different for the "D" condition than it is for the "P" condition).

"Douglas Bates" <bates at stat.wisc.edu> on Friday, July 13, 2007 at 12:16 PM -0500 wrote:

>The easiest way out is to add variables to the dat.new data frame. Say
>
>dat.new$Dind <- as.numeric(dat.new$drug == "D")
>dat.new$Pind <- as.numeric(dat.new$drug == "P")
>
>(fm.het <- lmer(dv ~ ... + (0+Dind|Patient)+(0+Pind|Patient))

Yes, that would be clearer! As would adding a variable to the data frame for quantitative time! This would allow a fairly simple lmer call like

fm.het <- lmer( dv ~ time.num*drug + (0+Dind|Patient) + (0+Pind|Patient), ... )
for a parameterization in terms of an interaction
or
fm.het <- lmer( dv ~ drug/time.num + (0+Dind|Patient) + (0+Pind|Patient), ... )
for a parameterization in terms of the time course being nested within level of drug

>On 7/13/07, Afshartous, David <afshart at exchange.sba.miami.edu> wrote:
>
>> Alan,
>
>> Thanks for the suggestion.  I noticed the following error msg
>> for that lmer call:
>
>> > ( fm.het <- lmer( dv ~ rep(1:n.timepoints, n.subj.per.tx*2)*drug + ( 0
>> + as.numeric(drug=="D") | Patient ) + ( 0 + as.numeric(drug=="P") |
>> Patient ), data=dat.new ) )
>> Error: length(term) == 3 is not TRUE
>
>I expect that the problem is due to "AsIs" terms in the model frame
>not being identified correctly in later function calls that build
>model matrices.  Parsing model formulas and building the model frame
>and model matrices in general settings is a bit of a black art.
>
>The easiest way out is to add variables to the dat.new data frame. Say
>
>dat.new$Dind <- as.numeric(dat.new$drug == "D")
>dat.new$Pind <- as.numeric(dat.new$drug == "P")
>
>(fm.het <- lmer(dv ~ ... + (0+Dind|Patient)+(0+Pind|Patient))
>
>I'm afraid I don't understand what the expression
>
>rep(1:n.timepoints, n.subj.per.tx*2)*drug
>
>would mean.  It seems that the variable drug is a factor and it
>doesn't make sense to multiply a factor by an integer variable.
>
>I hope this helps,
>Doug Bates
>
>> I tried a few changes to the model but the error still exists; I'll
>> keep checking.  I assume the rationale for the structure of your lmer
>> call, where you use as.numeric as opposed to just drug above, is to
>> insure that
>> you do not introduce a random effect for drug into the model?
>>
>> Regards,
>> Dave
>>
>>
>>
>> > -----Original Message-----
>> > From: Alan Cobo-Lewis [mailto:alanc at umit.maine.edu]
>> > Sent: Wednesday, July 11, 2007 6:40 PM
>> > To: r-sig-mixed-models at r-project.org
>> > Cc: " "Afshartous at basalt.its.maine.edu; Afshartous, David;
>> > Andrew Robinson
>> > Subject: Re: random effect variance per treatment group in lmer
>> >
>> >
>> > Dave,
>> >
>> > How about using stratifying variance on level of drug using (
>> > 0 + as.numeric(drug=="D") | Patient ) + ( 0 +
>> > as.numeric(drug=="P") | Patient ) Here's some code (whose sim
>> > also builds in a fixed effect of time that applies only to
>> > the Drug condition).
>> >
>> > set.seed(500)
>> > n.timepoints <- 8
>> > n.subj.per.tx <- 20
>> > sd.d <- 5; sd.p <- 2; sd.res <- 1.3
>> > drug <- factor(rep(c("D", "P"), each = n.timepoints, times =
>> > n.subj.per.tx)) drug.baseline <- rep( c(0,5),
>> > each=n.timepoints, times=n.subj.per.tx ) Patient <-
>> > rep(1:(n.subj.per.tx*2), each = n.timepoints)
>> > Patient.baseline <- rep( rnorm( n.subj.per.tx*2, sd=c(sd.d,
>> > sd.p) ), each=n.timepoints ) time <- factor(paste("Time-",
>> > rep(1:n.timepoints, n.subj.per.tx*2), sep="")) time.baseline
>> > <- rep(1:n.timepoints,n.subj.per.tx*2)*as.numeric(drug=="D")
>> > dv <- rnorm( n.subj.per.tx*n.timepoints*2,
>> > mean=time.baseline+Patient.baseline+drug.baseline, sd=sd.res
>> > ) dat.new <- data.frame(time, drug, dv, Patient) xyplot(
>> > dv~time|drug, group=Patient, type="l", data=dat.new ) # fit
>> > model treats time as a quantitative predictor ( fm.het <-
>> > lmer( dv ~ rep(1:n.timepoints, n.subj.per.tx*2)*drug + ( 0 +
>> > as.numeric(drug=="D") | Patient ) + ( 0 +
>> > as.numeric(drug=="P") | Patient ), data=dat.new ) )
>> >
>> >
>> > HTH,
>> > alan
>> >
>> >
>> > >From: "Afshartous, David" <afshart at exchange.sba.miami.edu>
>> >  asked:
>> >
>> > >
>> > >All,
>> > >I didn't receive a response to the query below sent to the general
>> > >R-help mailing list so figured I'd try this mailing list.
>> > Apologies in
>> > >advance if this is an overly simplistic question for this
>> > list; I just
>> > >started w/ lmer after not using lme for awhile.
>> > >Cheers,
>> > >Dave
>> > >
>> > >
>> > >__________________________________________________________
>> > >
>> > >All,
>> > >
>> > >How does one specify a model in lmer such that say the random effect
>> > >for
>> > >
>> > >the intercept has a different variance per treatment group?
>> > >Thus, in the model equation, we'd have say b_ij represent the random
>> > >effect for patient j in treatment group i, with variance
>> > depending on
>> > >i, i.e,
>> > >var(b_ij) = tau_i.
>> > >
>> > >Didn't see this in the docs or Pinherio & Bates (section 5.2 is
>> > >specific for modelling within group errors).  Sample
>> > repeated measures
>> > >code below is for a single random effect variance, where the random
>> > >effect corresponds to patient.
>> > >cheers,
>> > >dave
>> > >
>> > >
>> > >z <- rnorm(24, mean=0, sd=1)
>> > >time <- factor(paste("Time-", rep(1:6, 4), sep="")) Patient
>> > <- rep(1:4,
>> > >each = 6) drug <- factor(rep(c("D", "P"), each = 6, times =
>> > 2)) ## P =
>> > >placebo, D = Drug dat.new <- data.frame(time, drug, z,
>> > Patient) fm =
>> > >lmer(z ~ drug + time + (1 | Patient), data = dat.new )
>> >
>> >
>> >
>> > --
>> > Alan B. Cobo-Lewis, Ph.D.             (207) 581-3840 tel
>> > Department of Psychology              (207) 581-6128 fax
>> > University of Maine
>> > Orono, ME 04469-5742                  alanc at maine.edu
>> >
>> > http://www.umaine.edu/visualperception
>> >
>> >
>> >
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>



--
Alan B. Cobo-Lewis, Ph.D.		(207) 581-3840 tel
Department of Psychology		(207) 581-6128 fax
University of Maine
Orono, ME 04469-5742     		alanc at maine.edu

http://www.umaine.edu/visualperception



From agalecki at umich.edu  Fri Jul 13 21:12:33 2007
From: agalecki at umich.edu (Andrzej Galecki)
Date: Fri, 13 Jul 2007 15:12:33 -0400
Subject: [R-sig-ME] [Fwd: Re: gls/lme/lmer Likelihood]
Message-ID: <4697CEA1.70600@umich.edu>

Hello,

logLik function appears to return gls/lme/lmer log-likelihood evaluated for a
model at:

1. the set of  estimated coefficients
  and
2. for the data set, to which the model was fitted.

I am wondering whether there is a simple/elegant way to return the
log-likelihood for the same model evaluated at:

1. a given set of parameter values _other_ than the estimated coefficients
 and
2. for a different data set ?

Respectfully,

Andrzej



From bates at stat.wisc.edu  Fri Jul 13 21:56:20 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 13 Jul 2007 14:56:20 -0500
Subject: [R-sig-ME] gls/lme/lmer Likelihood
In-Reply-To: <4697CEA1.70600@umich.edu>
References: <4697CEA1.70600@umich.edu>
Message-ID: <40e66e0b0707131256j24a2a473q394a078d729e6822@mail.gmail.com>

On 7/13/07, Andrzej Galecki <agalecki at umich.edu> wrote:
> Hello,

> logLik function appears to return gls/lme/lmer log-likelihood evaluated for a
> model at:

> 1. the set of  estimated coefficients
>   and
> 2. for the data set, to which the model was fitted.

> I am wondering whether there is a simple/elegant way to return the
> log-likelihood for the same model evaluated at:

> 1. a given set of parameter values _other_ than the estimated coefficients
>  and

I can answer regarding lmer.  I have forgotten the details of exactly
how the log-likelihood evaluation is done in lme and gls.  All I
remember is that it is complicated.

The lmer function does not incorporate all the parameters from the
model in the evaluation of the log-likelihood when optimizing the
parameter estimates.  It minimizes a profiled deviance with respect to
a reduced set of parameters, which I call $\theta$, that determine the
relative variance-covariance matrix of the random effects.  The model
itself depends on $\beta$, the fixed-effects parameters, $\theta$ and
$\sigma^2$, the scalar variance of the conditional distribution of Y
given B.

If it happens that you want to evaluate the profiled log-likelihood
for different values of $\theta$ then the task is easy.  Look at the R
code in the Sweave file Implementation.Rnw that generates the
Implementation.pdf vignette.  However, if you want to choose arbitrary
values of $\beta$, $\theta$ and $\sigma^2$ then evaluate the
log-likelihood for them, you are better off going back to the formula
for the log-likelihood in the "Computational methods for mixed models"
vignette.  If you are doing that I would recommend getting the
development version of the code from the SVN site
https://svn.r-project.org/R-packages/branches/gappy-lmer/ because that
is the version of the code described in the vignette.  (It is a
development version and there are lots of things broken in it but the
likelihood evaluation does work.)

To evaluate the log-likelihood for different data you need to replace
the slots XytXy and ZtXy then force a likelihood evaluation.  Look at
the code in the lmer function (gappy version) to see how those
matrices are defined.

Once I get this version running and validated I will be open to the
idea of defining functions for evaluation at arbitrary values of the
parameters and for, say, entire matrices of responses.  Designing such
functions is more difficult that it seems and I would prefer to devote
my efforts to getting the other parts working right now.

The details of exactly how the evaluation takes place are described in
the vignette "Computational methods for mixed models" that is part of
recent versions of the lme4 package.  (That vignette is not yet
finished.  Once I have a completed version I will release it as a
technical report.)It uses a reduced set of parameters that I write as
$\bm\theta$
> 2. for a different data set ?
>
> Respectfully,
>
> Andrzej
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From afshart at exchange.sba.miami.edu  Fri Jul 13 22:31:40 2007
From: afshart at exchange.sba.miami.edu (Afshartous, David)
Date: Fri, 13 Jul 2007 16:31:40 -0400
Subject: [R-sig-ME] random effect variance per treatment group in lmer
In-Reply-To: <fc.004c4d19317a031e3b9aca007ddaf390.317a5579@umit.maine.edu>
Message-ID: <6BCB4D493A447546A8126F24332056E8064AA4E6@school1.business.edu>


Alan,

Thanks again for the help.  I defined time.num, Dind, and Pind outside
the lmer call as per Doug Bates' suggestion and now it works and I get 
the same results as your output w/ the suggested lmer call:

( fm.het <- lmer( dv ~ time.num*drug + ( 0 + Dind | Patient ) + ( 0 +
Pind | Patient ), data=dat.new ) )

More importantly, this achieves the goal I was seeking originally.
Looks 
like the key to the issue is not defining a random effect via "(1 |
Patient)" 
as once this is done it doesn't seem possible to stratify; but rather
splitting 
the "1" into the two pieces as per the drug dichotomy, and getting
separate random 
effects variances for each while mainting drug as a fixed effect.

Thanks again to you and everyone else for the help!

Cheers,
Dave






 

> -----Original Message-----
> From: Alan Cobo-Lewis [mailto:alanc at umit.maine.edu] 
> Sent: Friday, July 13, 2007 12:27 PM
> To: Afshartous, David
> Cc: r-sig-mixed-models at r-project.org; " 
> "Afshartous at basalt.its.maine.edu; Andrew Robinson
> Subject: Re: random effect variance per treatment group in lmer
> 
> 
> Hmm, could it be a word-wrap issue? I just verified that the 
> code works on R 2.5 with lme4 and lattice packages installed. 
> See http://www.umaine.edu/visualperception/lme4het
> 
> The model I posted assumes that the subj-to-subj variability 
> in baseline score has higher variability in the "D" condition 
> than in the "P" condition. You are correct that there's no 
> random effect for drug. I don't think you *want* there to be 
> a random effect for drug, since drug doesn't have levels 
> sampled from some population (it's properly a fixed effect). 
> Instead, the code I posted has the random effect of Patient 
> with a higher variability in one level of drug than in the 
> other level of drug.
> 
> If you're looking some the drug to have a different time 
> course for some patients than for other patients I think 
> that'd be a random effect of Time. (To avoid 
> overparameterization I think you'd almost surely want to 
> treat time as a quantitative predictor if you're going to 
> model it as having a random effect.)
> 
> One of the reasons that I constructed a full example with a 
> new sim was to get a big-enough data set together so that the 
> lmer fit fairly obviously matched the parameters of the sim 
> (to verify the correctness of the sim and the suggested model 
> formula). Another reason is that the code of your sim didn't 
> actually have different subj-to-subj variability in the "D" 
> condition than it did in the "P" condition, so a model with 
> such an effect was overparameterized for your original 
> simulated data. Could this be why the lmer call I suggested 
> failed for you?
> 
> BTW, nice to see someone from the UM School of Business (I 
> didn't notice until just now what your email address said). I 
> worked there about 20 years ago on the Applied AI Reporter 
> when I was an undergraduate psychology major. But, looking at 
> the SBA web site, I recognize barely anyone, and those I do 
> recognize probably wouldn't recognize me.
> 
> alan
> 
> "Afshartous, David" <afshart at exchange.sba.miami.edu> on 
> Friday, July 13, 2007 at 10:44 AM -0500 wrote:
> > 
> >Alan,
> >
> >Thanks for the suggestion.  I noticed the following error 
> msg for that 
> >lmer call:
> >
> >> ( fm.het <- lmer( dv ~ rep(1:n.timepoints, 
> n.subj.per.tx*2)*drug + ( 
> >> 0
> >+ as.numeric(drug=="D") | Patient ) + ( 0 + as.numeric(drug=="P") |
> >Patient ), data=dat.new ) )
> >Error: length(term) == 3 is not TRUE
> >
> >I tried a few changes to the model but the error still exists; I'll 
> >keep checking.  I assume the rationale for the structure of 
> your lmer 
> >call, where you use as.numeric as opposed to just drug above, is to 
> >insure that you do not introduce a random effect for drug into the 
> >model?
> >
> >Regards,
> >Dave
> >
> >
> >
> >> -----Original Message-----
> >> From: Alan Cobo-Lewis [mailto:alanc at umit.maine.edu]
> >> Sent: Wednesday, July 11, 2007 6:40 PM
> >> To: r-sig-mixed-models at r-project.org
> >> Cc: " "Afshartous at basalt.its.maine.edu; Afshartous, David; Andrew 
> >> Robinson
> >> Subject: Re: random effect variance per treatment group in lmer
> >> 
> >> 
> >> Dave,
> >> 
> >> How about using stratifying variance on level of drug using ( 0 + 
> >> as.numeric(drug=="D") | Patient ) + ( 0 +
> >> as.numeric(drug=="P") | Patient ) Here's some code (whose sim also 
> >> builds in a fixed effect of time that applies only to the Drug 
> >> condition).
> >> 
> >> set.seed(500)
> >> n.timepoints <- 8
> >> n.subj.per.tx <- 20
> >> sd.d <- 5; sd.p <- 2; sd.res <- 1.3
> >> drug <- factor(rep(c("D", "P"), each = n.timepoints, times =
> >> n.subj.per.tx)) drug.baseline <- rep( c(0,5), each=n.timepoints, 
> >> times=n.subj.per.tx ) Patient <- rep(1:(n.subj.per.tx*2), each = 
> >> n.timepoints) Patient.baseline <- rep( rnorm( n.subj.per.tx*2, 
> >> sd=c(sd.d,
> >> sd.p) ), each=n.timepoints ) time <- factor(paste("Time-", 
> >> rep(1:n.timepoints, n.subj.per.tx*2), sep="")) time.baseline
> >> <- rep(1:n.timepoints,n.subj.per.tx*2)*as.numeric(drug=="D")
> >> dv <- rnorm( n.subj.per.tx*n.timepoints*2, 
> >> mean=time.baseline+Patient.baseline+drug.baseline, sd=sd.res
> >> ) dat.new <- data.frame(time, drug, dv, Patient) xyplot( 
> >> dv~time|drug, group=Patient, type="l", data=dat.new ) # fit model 
> >> treats time as a quantitative predictor ( fm.het <- lmer( dv ~ 
> >> rep(1:n.timepoints, n.subj.per.tx*2)*drug + ( 0 +
> >> as.numeric(drug=="D") | Patient ) + ( 0 +
> >> as.numeric(drug=="P") | Patient ), data=dat.new ) )
> >> 
> >> 
> >> HTH,
> >> alan
> >> 
> >> 
> >> >From: "Afshartous, David" <afshart at exchange.sba.miami.edu>
> >>  asked:
> >> 
> >> >
> >> >All,
> >> >I didn't receive a response to the query below sent to 
> the general 
> >> >R-help mailing list so figured I'd try this mailing list.
> >> Apologies in
> >> >advance if this is an overly simplistic question for this
> >> list; I just
> >> >started w/ lmer after not using lme for awhile.
> >> >Cheers,
> >> >Dave
> >> >
> >> >
> >> >__________________________________________________________
> >> >
> >> >All,
> >> > 
> >> >How does one specify a model in lmer such that say the 
> random effect 
> >> >for
> >> >
> >> >the intercept has a different variance per treatment group?  
> >> >Thus, in the model equation, we'd have say b_ij represent 
> the random 
> >> >effect for patient j in treatment group i, with variance
> >> depending on
> >> >i, i.e,
> >> >var(b_ij) = tau_i.
> >> > 
> >> >Didn't see this in the docs or Pinherio & Bates (section 5.2 is 
> >> >specific for modelling within group errors).  Sample
> >> repeated measures
> >> >code below is for a single random effect variance, where 
> the random 
> >> >effect corresponds to patient.
> >> >cheers,
> >> >dave
> >> > 
> >> > 
> >> >z <- rnorm(24, mean=0, sd=1)
> >> >time <- factor(paste("Time-", rep(1:6, 4), sep="")) Patient
> >> <- rep(1:4,
> >> >each = 6) drug <- factor(rep(c("D", "P"), each = 6, times =
> >> 2)) ## P =
> >> >placebo, D = Drug dat.new <- data.frame(time, drug, z,
> >> Patient) fm =
> >> >lmer(z ~ drug + time + (1 | Patient), data = dat.new )
> >> 
> >> 
> >> 
> >> --
> >> Alan B. Cobo-Lewis, Ph.D.		(207) 581-3840 tel
> >> Department of Psychology		(207) 581-6128 fax
> >> University of Maine
> >> Orono, ME 04469-5742     		alanc at maine.edu
> >> 
> >> http://www.umaine.edu/visualperception
> >> 
> >> 
> >> 
> >
> 
> 
> 
> --
> Alan B. Cobo-Lewis, Ph.D.		(207) 581-3840 tel
> Department of Psychology		(207) 581-6128 fax
> University of Maine
> Orono, ME 04469-5742     		alanc at maine.edu
> 
> http://www.umaine.edu/visualperception
> 
> 
>



From afshart at exchange.sba.miami.edu  Sat Jul 14 01:18:31 2007
From: afshart at exchange.sba.miami.edu (Afshartous, David)
Date: Fri, 13 Jul 2007 19:18:31 -0400
Subject: [R-sig-ME] random effect variance per treatment group in lmer
In-Reply-To: <6BCB4D493A447546A8126F24332056E8064AA4E6@school1.business.edu>
Message-ID: <6BCB4D493A447546A8126F24332056E8064AA525@school1.business.edu>

All,

Here is a brief summary of the problem, model, and solution 
as the multiple e-mails have probably made it difficult to read.

Problem: 
In the context of growth curve data with drug/placebo
conditions, the subject to subject variability is greater in 
the drug group than the placebo group.  It is desired to model
this differential variability by having a random effect on the
intercept, where the variance of this random effect depends on drug.
(Time may either be treated as discrete or continuous.)

Model:

fm.het <- lmer( dv ~ time.num*drug + ( 0 + Dind | Patient )  + ( 0 +
Pind | Patient ), data=dat.new ) )

For a data set w/ the aforementioned variability (generated via code
below), this lmer call fits a model where time is continuous and there 
is an interaction between time and drug, i.e., a slope shift.  Thus,
there 
are fixed effects for intercept, time trend, drug (representing a shift
from drug reference level when using treatment contrasts), and slope
shift.
Dind and Pind are indicator variables for drug and placebo.  Note that
one does not define a random effect via "(1 | Patient)" as once this is
done 
it doesn't seem possible to stratify; but rather one splits the "1" into

the two pieces as per the drug dichotomy, and getting separate random 
effects variances for each while mainting drug as a fixed effect.
Examining
ranef(fm.het) shows that this is accomplished.

Solution:
The estimated model from the simulated data clearly accomplished 
the desired stratification:
Random effects:
 Groups   Name Variance Std.Dev.
 Patient  Dind 29.0183  5.3869  
 Patient  Pind  3.9571  1.9893  
 Residual       1.7108  1.3080 


Note that the second term (3.957) does not represent variability around
the fixed effect for the shift from drug to placebo, but rather
variability 
around the fixed effect for the placebo intercept itself (obtained by 
summing the appropriate fixed effects in the output; one can always
remove
the intercept from the lmer call to inrease the correspondence between
the
fixed effect and random effect ouput).

Thanks again to all for the extensive help,

David

code below for the simulated data:
## from Alan Cobo-Lewis e-mail:
set.seed(500)
n.timepoints <- 8
n.subj.per.tx <- 20
sd.d <- 5; 
sd.p <- 2; 
sd.res <- 1.3
drug <- factor(rep(c("D", "P"), each = n.timepoints, times =
n.subj.per.tx)) 
drug.baseline <- rep( c(0,5), each=n.timepoints, times=n.subj.per.tx ) 
Patient <- rep(1:(n.subj.per.tx*2), each = n.timepoints) 
Patient.baseline <- rep( rnorm( n.subj.per.tx*2, sd=c(sd.d, sd.p) ),
each=n.timepoints ) 
time <- factor(paste("Time-", rep(1:n.timepoints, n.subj.per.tx*2),
sep="")) 
time.baseline <-
rep(1:n.timepoints,n.subj.per.tx*2)*as.numeric(drug=="D")
dv <- rnorm( n.subj.per.tx*n.timepoints*2,
mean=time.baseline+Patient.baseline+drug.baseline, sd=sd.res ) 
dat.new <- data.frame(time, drug, dv, Patient) 
xyplot( dv~time|drug, group=Patient, type="l", data=dat.new) # fit model
treats time as a quantitative predictor 
dat.new$Dind <- as.numeric(dat.new$drug == "D") 
dat.new$Pind <- as.numeric(dat.new$drug == "P")
dat.new$time.num = rep(1:n.timepoints, n.subj.per.tx*2)
( fm.het <- lmer( dv ~ time.num*drug + ( 0 + Dind | Patient ) + ( 0 +
Pind | Patient ), data=dat.new ) )








 

> -----Original Message-----
> From: Afshartous, David 
> Sent: Friday, July 13, 2007 4:32 PM
> To: Alan Cobo-Lewis
> Cc: r-sig-mixed-models at r-project.org; Afshartous, David; 
> Andrew Robinson
> Subject: RE: random effect variance per treatment group in lmer
> 
> 
> Alan,
> 
> Thanks again for the help.  I defined time.num, Dind, and 
> Pind outside the lmer call as per Doug Bates' suggestion and 
> now it works and I get the same results as your output w/ the 
> suggested lmer call:
> 
> ( fm.het <- lmer( dv ~ time.num*drug + ( 0 + Dind | Patient ) 
> + ( 0 + Pind | Patient ), data=dat.new ) )
> 
> More importantly, this achieves the goal I was seeking 
> originally.  Looks like the key to the issue is not defining 
> a random effect via "(1 | Patient)" 
> as once this is done it doesn't seem possible to stratify; 
> but rather splitting the "1" into the two pieces as per the 
> drug dichotomy, and getting separate random effects variances 
> for each while mainting drug as a fixed effect.
> 
> Thanks again to you and everyone else for the help!
> 
> Cheers,
> Dave
> 
> 
> 
> 
> 
> 
>  
> 
> > -----Original Message-----
> > From: Alan Cobo-Lewis [mailto:alanc at umit.maine.edu]
> > Sent: Friday, July 13, 2007 12:27 PM
> > To: Afshartous, David
> > Cc: r-sig-mixed-models at r-project.org; " 
> > "Afshartous at basalt.its.maine.edu; Andrew Robinson
> > Subject: Re: random effect variance per treatment group in lmer
> > 
> > 
> > Hmm, could it be a word-wrap issue? I just verified that the code 
> > works on R 2.5 with lme4 and lattice packages installed.
> > See http://www.umaine.edu/visualperception/lme4het
> > 
> > The model I posted assumes that the subj-to-subj variability in 
> > baseline score has higher variability in the "D" condition 
> than in the 
> > "P" condition. You are correct that there's no random 
> effect for drug. 
> > I don't think you *want* there to be a random effect for 
> drug, since 
> > drug doesn't have levels sampled from some population (it's 
> properly a 
> > fixed effect).
> > Instead, the code I posted has the random effect of Patient with a 
> > higher variability in one level of drug than in the other level of 
> > drug.
> > 
> > If you're looking some the drug to have a different time course for 
> > some patients than for other patients I think that'd be a random 
> > effect of Time. (To avoid overparameterization I think you'd almost 
> > surely want to treat time as a quantitative predictor if 
> you're going 
> > to model it as having a random effect.)
> > 
> > One of the reasons that I constructed a full example with a new sim 
> > was to get a big-enough data set together so that the lmer 
> fit fairly 
> > obviously matched the parameters of the sim (to verify the 
> correctness 
> > of the sim and the suggested model formula). Another reason is that 
> > the code of your sim didn't actually have different subj-to-subj 
> > variability in the "D"
> > condition than it did in the "P" condition, so a model with such an 
> > effect was overparameterized for your original simulated 
> data. Could 
> > this be why the lmer call I suggested failed for you?
> > 
> > BTW, nice to see someone from the UM School of Business (I didn't 
> > notice until just now what your email address said). I worked there 
> > about 20 years ago on the Applied AI Reporter when I was an 
> > undergraduate psychology major. But, looking at the SBA web site, I 
> > recognize barely anyone, and those I do recognize probably wouldn't 
> > recognize me.
> > 
> > alan
> > 
> > "Afshartous, David" <afshart at exchange.sba.miami.edu> on 
> Friday, July 
> > 13, 2007 at 10:44 AM -0500 wrote:
> > > 
> > >Alan,
> > >
> > >Thanks for the suggestion.  I noticed the following error
> > msg for that
> > >lmer call:
> > >
> > >> ( fm.het <- lmer( dv ~ rep(1:n.timepoints,
> > n.subj.per.tx*2)*drug + (
> > >> 0
> > >+ as.numeric(drug=="D") | Patient ) + ( 0 + as.numeric(drug=="P") |
> > >Patient ), data=dat.new ) )
> > >Error: length(term) == 3 is not TRUE
> > >
> > >I tried a few changes to the model but the error still 
> exists; I'll 
> > >keep checking.  I assume the rationale for the structure of
> > your lmer
> > >call, where you use as.numeric as opposed to just drug 
> above, is to 
> > >insure that you do not introduce a random effect for drug into the 
> > >model?
> > >
> > >Regards,
> > >Dave
> > >
> > >
> > >
> > >> -----Original Message-----
> > >> From: Alan Cobo-Lewis [mailto:alanc at umit.maine.edu]
> > >> Sent: Wednesday, July 11, 2007 6:40 PM
> > >> To: r-sig-mixed-models at r-project.org
> > >> Cc: " "Afshartous at basalt.its.maine.edu; Afshartous, 
> David; Andrew 
> > >> Robinson
> > >> Subject: Re: random effect variance per treatment group in lmer
> > >> 
> > >> 
> > >> Dave,
> > >> 
> > >> How about using stratifying variance on level of drug using ( 0 +
> > >> as.numeric(drug=="D") | Patient ) + ( 0 +
> > >> as.numeric(drug=="P") | Patient ) Here's some code 
> (whose sim also 
> > >> builds in a fixed effect of time that applies only to the Drug 
> > >> condition).
> > >> 
> > >> set.seed(500)
> > >> n.timepoints <- 8
> > >> n.subj.per.tx <- 20
> > >> sd.d <- 5; sd.p <- 2; sd.res <- 1.3 drug <- 
> factor(rep(c("D", "P"), 
> > >> each = n.timepoints, times =
> > >> n.subj.per.tx)) drug.baseline <- rep( c(0,5), each=n.timepoints, 
> > >> times=n.subj.per.tx ) Patient <- rep(1:(n.subj.per.tx*2), each =
> > >> n.timepoints) Patient.baseline <- rep( rnorm( n.subj.per.tx*2, 
> > >> sd=c(sd.d,
> > >> sd.p) ), each=n.timepoints ) time <- factor(paste("Time-", 
> > >> rep(1:n.timepoints, n.subj.per.tx*2), sep="")) time.baseline
> > >> <- rep(1:n.timepoints,n.subj.per.tx*2)*as.numeric(drug=="D")
> > >> dv <- rnorm( n.subj.per.tx*n.timepoints*2, 
> > >> mean=time.baseline+Patient.baseline+drug.baseline, sd=sd.res
> > >> ) dat.new <- data.frame(time, drug, dv, Patient) xyplot( 
> > >> dv~time|drug, group=Patient, type="l", data=dat.new ) # 
> fit model 
> > >> treats time as a quantitative predictor ( fm.het <- lmer( dv ~ 
> > >> rep(1:n.timepoints, n.subj.per.tx*2)*drug + ( 0 +
> > >> as.numeric(drug=="D") | Patient ) + ( 0 +
> > >> as.numeric(drug=="P") | Patient ), data=dat.new ) )
> > >> 
> > >> 
> > >> HTH,
> > >> alan
> > >> 
> > >> 
> > >> >From: "Afshartous, David" <afshart at exchange.sba.miami.edu>
> > >>  asked:
> > >> 
> > >> >
> > >> >All,
> > >> >I didn't receive a response to the query below sent to
> > the general
> > >> >R-help mailing list so figured I'd try this mailing list.
> > >> Apologies in
> > >> >advance if this is an overly simplistic question for this
> > >> list; I just
> > >> >started w/ lmer after not using lme for awhile.
> > >> >Cheers,
> > >> >Dave
> > >> >
> > >> >
> > >> >__________________________________________________________
> > >> >
> > >> >All,
> > >> > 
> > >> >How does one specify a model in lmer such that say the
> > random effect
> > >> >for
> > >> >
> > >> >the intercept has a different variance per treatment group?  
> > >> >Thus, in the model equation, we'd have say b_ij represent
> > the random
> > >> >effect for patient j in treatment group i, with variance
> > >> depending on
> > >> >i, i.e,
> > >> >var(b_ij) = tau_i.
> > >> > 
> > >> >Didn't see this in the docs or Pinherio & Bates (section 5.2 is 
> > >> >specific for modelling within group errors).  Sample
> > >> repeated measures
> > >> >code below is for a single random effect variance, where
> > the random
> > >> >effect corresponds to patient.
> > >> >cheers,
> > >> >dave
> > >> > 
> > >> > 
> > >> >z <- rnorm(24, mean=0, sd=1)
> > >> >time <- factor(paste("Time-", rep(1:6, 4), sep="")) Patient
> > >> <- rep(1:4,
> > >> >each = 6) drug <- factor(rep(c("D", "P"), each = 6, times =
> > >> 2)) ## P =
> > >> >placebo, D = Drug dat.new <- data.frame(time, drug, z,
> > >> Patient) fm =
> > >> >lmer(z ~ drug + time + (1 | Patient), data = dat.new )
> > >> 
> > >> 
> > >> 
> > >> --
> > >> Alan B. Cobo-Lewis, Ph.D.		(207) 581-3840 tel
> > >> Department of Psychology		(207) 581-6128 fax
> > >> University of Maine
> > >> Orono, ME 04469-5742     		alanc at maine.edu
> > >> 
> > >> http://www.umaine.edu/visualperception
> > >> 
> > >> 
> > >> 
> > >
> > 
> > 
> > 
> > --
> > Alan B. Cobo-Lewis, Ph.D.		(207) 581-3840 tel
> > Department of Psychology		(207) 581-6128 fax
> > University of Maine
> > Orono, ME 04469-5742     		alanc at maine.edu
> > 
> > http://www.umaine.edu/visualperception
> > 
> > 
> >



From afshart at exchange.sba.miami.edu  Sun Jul 15 00:10:32 2007
From: afshart at exchange.sba.miami.edu (Afshartous, David)
Date: Sat, 14 Jul 2007 18:10:32 -0400
Subject: [R-sig-ME] estimated growth curves from lme4
Message-ID: <6BCB4D493A447546A8126F24332056E8064AA549@school1.business.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20070714/b37d93b7/attachment.pl>

From bates at stat.wisc.edu  Sun Jul 15 13:54:22 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Sun, 15 Jul 2007 06:54:22 -0500
Subject: [R-sig-ME] estimated growth curves from lme4
In-Reply-To: <6BCB4D493A447546A8126F24332056E8064AA549@school1.business.edu>
References: <6BCB4D493A447546A8126F24332056E8064AA549@school1.business.edu>
Message-ID: <40e66e0b0707150454y3efc4ae9l2e1375dc82e01e96@mail.gmail.com>

On 7/14/07, Afshartous, David <afshart at exchange.sba.miami.edu> wrote:
> All,
>
> The archive email below mentions the lack of general predict methods in
> lme4.  I would like to plot the estimated growth curves for
> treatment/placebo
> groups (or the estimated patient growth curves that augment the former
> w/ the patient estimated
> random effects).
>
> I obtained the plot manually by constructing the appropriate functions
> from the fixed effects output and plotting using curve() (sample code
> below).
>
> For those that have transitioned from lme, do you suggest sticking w/
> such an approach
> (and possibly automating it w/ additional code, but this would be
> dependent on the type
> of model that is estimated each time), or going back to lme where I
> recall that this was relatively
> simple given the nesting mentioned by Douglas Bates below.
>
> Thanks,
> David
>
> sample code:
> ## assume growth curve is quadratic, and coefficeints for placego group
> are 10, 50, -20:
> quad.fun.Placebo <- function(t) {
> y = 100 + 50*t - 20*t^2
> y}
> ## plot from t=0 to t=5
> curve(quad.fun.Placebo, 0,5, xlab="Time", ylab="Dependent Variable",
> col="red")
>
> ps - why don't the methods show up below?
> > library(lme4)
> Loading required package: Matrix
> Loading required package: lattice
> > methods(class="lme4")
> no methods were found

I think you meant class = "lmer" (there is no class called "lme4").
Even that won't show any methods, however, because the lme4 package
uses S4 classes and methods, which is the reason for the "4" in the
name of the package.  The methods function only shows S3 methods.  To
see the listing of methods defined in the lme4 package use

library(lme4)
showMethods(where = "package:lme4")


> From: Douglas Bates <bates_at_stat.wisc.edu
> <mailto:bates_at_stat.wisc.edu?Subject=Re:%20%5BR%5D%20Predicted%20value
> s%20in%20lmer%20modeling> >
> Date: Tue 28 Nov 2006 - 13:53:23 GMT
>
>
> On 11/28/06, Fucikova, Eva <E.Fucikova at nioo.knaw.nl> wrote:
> > Dear All,
>
>
> > I am working with linear mixed-effects models using the lme4 package
> in
> <http://tolstoy.newcastle.edu.au/R/e2/help/06/11/6158.html#6180qlink1>
> > R. I created a model with the lmer function including some main
> effects,
> > a two-way interaction and a random effect. Now I am searching for a
> way
> > to save the predicted values for this model.
>
>
> > As far as I can see, there is no command in lme4 to save the predicted
> <http://tolstoy.newcastle.edu.au/R/e2/help/06/11/6158.html#6180qlink2>
> > values (like the predict(model) function in e.g. glm).
>
>
> If you want the predictions at the observed values of the covariates you
> can use
>
>  fitted(model)
>
> > This gives the following R output: Error in predict(lmer(model)) no
> <http://tolstoy.newcastle.edu.au/R/e2/help/06/11/6158.html#6180qlink3>
> > applicable method for "predict"
>
>
> > I found the same question in the R forum archives, but no answer.
> <http://tolstoy.newcastle.edu.au/R/e2/help/06/11/6158.html#6180qlink4>
>
>
> > Could anybody please give me an advice how to solve this problem?
> <http://tolstoy.newcastle.edu.au/R/e2/help/06/11/6158.html#6180qlink5>
>
>
> I haven't written a general method for predict applied to an lmer object
> because it is difficult to define what it should do. It is clear what
> the predictions based on the fixed effects only should be and perhaps it
> is clear what the standard errors of those predictions are (although
> that would be a case where my favorite topic of the degrees of freedom
> associated with a standard error would rear its ugly head again).
>
> It is trickier to define the predictions should be when you want to
> incorporate the random effects. If you incorporate all the "levels" of
> the random effects I think it is clear what the prediction should be.
> Defining a standard error for that prediction could be difficult - I'm
> not sure. However, I don't know what the answer should be if you only
> incorporate some of the random effects. We could define that
> unambiguously for lme models because the grouping factors were required
> to be nested. Because lmer allows for fully crossed or partially crossed
> grouping factors the concept of levels is lost. That is, there is no
> strict hierarchy in the grouping factors and we can't levels to define
> predictions.
>
> The bottom line is that I won't be able to write a predict method for
> lmer objects until I can decide what it should do, what options should
> be allowed and what the calling sequence should be.
>
> ________________________________
>
>
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do read the posting
> guide http://www.R-project.org/posting-guide.html and provide commented,
> minimal, self-contained, reproducible code. Received on Wed Nov 29
> 18:44:37 2006
>
> *       This message: [ Message body
> <http://tolstoy.newcastle.edu.au/R/e2/help/06/11/6180.html#start>  ]
> *       Next message: Guenther, Cameron: "[R] Counting zeros in a
> matrix" <http://tolstoy.newcastle.edu.au/R/e2/help/06/11/6181.html>
> *       Previous message: Liaw, Andy: "Re: [R] automatic cleaning of
> workspace" <http://tolstoy.newcastle.edu.au/R/e2/help/06/11/6179.html>
> *       In reply to Fucikova, Eva: "[R] Predicted values in lmer
> modeling" <http://tolstoy.newcastle.edu.au/R/e2/help/06/11/6158.html>
> *       Next in thread: Benilton Carvalho: "[R] predict on biglm class"
> <http://tolstoy.newcastle.edu.au/R/e2/help/07/02/10349.html>
> *       Reply: Benilton Carvalho: "[R] predict on biglm class"
> <http://tolstoy.newcastle.edu.au/R/e2/help/07/02/10349.html>
>
> *       Contemporary messages sorted: [ By Date
> <http://tolstoy.newcastle.edu.au/R/e2/help/06/11/date.html#6180>  ] [ By
> Thread <http://tolstoy.newcastle.edu.au/R/e2/help/06/11/index.html#6180>
> ] [ By Subject
> <http://tolstoy.newcastle.edu.au/R/e2/help/06/11/subject.html#6180>  ] [
> By Author
> <http://tolstoy.newcastle.edu.au/R/e2/help/06/11/author.html#6180>  ] [
> By messages with attachments
> <http://tolstoy.newcastle.edu.au/R/e2/help/06/11/attachment.html>  ]
>
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From alanc at umit.maine.edu  Mon Jul 16 16:05:39 2007
From: alanc at umit.maine.edu (Alan Cobo-Lewis)
Date: Mon, 16 Jul 2007 10:05:39 -0400
Subject: [R-sig-ME] estimated growth curves from lme4
In-Reply-To: <mailman.19.1184580009.27115.r-sig-mixed-models@r-project.org>
References: <mailman.19.1184580009.27115.r-sig-mixed-models@r-project.org>
Message-ID: <fc.004c4d1931837e563b9aca00adcd95d6.3183d248@umit.maine.edu>


Setting aside the knotty question of standard errors, is it really unclear what predict() should do in this case?
fixef(), resid(), and ranef() all work, and the help entry for ranef() says that it returns an object that is "A list of data frames, one for each grouping factor for the random effects." So where predict.lme() has a level argument, couldn't
predict() for mer objects have a grouping.factor argument that was a vector of which grouping factors should be considered in generating the predictions? Alternatively, grouping.factor could be a list of numeric vectors.

In cases where predict.lme() has scalar level= , predict() for mer objects would have vector or scalar grouping.factor=
In cases where predict.lme() has vector level=, predict() for mer objects would have grouping.factor=list()

Something like this:

fm1.lme <- lme(pixel ~ day + I(day^2), data = Pixel, random = list(Dog = ~ day, Side = ~ 1))
fm1.lmer <- lmer(pixel ~ day + I(day^2) + (day|Dog)+ (1|Side:Dog), data = Pixel )

# To generate vector of fixed-effect predictions based on ~day+I(day^2):
predict( fm1.lme, level=0 )
predict( fm1.lmer, grouping.factor=0 )

# To generate vector of predictions based on ~day+I(day^2)+(day|Dog):
predict( fm1.lme, level=1 )
predict( fm1.lmer, grouping.factor=1 )

# To generate vector of predictions based on ~day+I(day^2)+(day|Dog)+(1|Side:Dog):
predict( fm1.lme, level=2 )
predict( fm1.lmer, grouping.factor=1:2 )

# To generate vector of predictions based on ~day+I(day^2)+(1|Side:Dog)
# can't do it in lme
predict( fm1.lmer, grouping.factor=2 )

# To generate data.frame of fixed-effect preds, Dog-specific preds, and Side-specific preds:
predict( fm1.lme, level=0:2 )
predict( fm1.lmer, grouping.factor=list(0, 1, 1:2) ) # inclusion of fixed effect in prediction equation is implicit in 2nd and 3rd elements of grouping.factor
predict( fm1.lmer, grouping.factor=list(0, 0:1, 0:2) ) # equivalent to line above. Inclusion of fixed effect in all three prediction equations is now explicit

Obviously easier to describe than to implement! But is there anything obviously wrong with the description?

alan


Date: Sun, 15 Jul 2007 06:54:22 -0500
From: "Douglas Bates" <bates at stat.wisc.edu>
Subject: Re: [R-sig-ME] estimated growth curves from lme4
To: "Afshartous, David" <afshart at exchange.sba.miami.edu>
Cc: r-sig-mixed-models at r-project.org
Message-ID:
	<40e66e0b0707150454y3efc4ae9l2e1375dc82e01e96 at mail.gmail.com>
Content-Type: text/plain; charset=ISO-8859-1; format=flowed

>> It is trickier to define the predictions should be when you want to
>> incorporate the random effects. If you incorporate all the "levels" of
>> the random effects I think it is clear what the prediction should be.
>> Defining a standard error for that prediction could be difficult - I'm
>> not sure. However, I don't know what the answer should be if you only
>> incorporate some of the random effects. We could define that
>> unambiguously for lme models because the grouping factors were required
>> to be nested. Because lmer allows for fully crossed or partially crossed
>> grouping factors the concept of levels is lost. That is, there is no
>> strict hierarchy in the grouping factors and we can't levels to define
>> predictions.



From bates at stat.wisc.edu  Mon Jul 16 20:48:55 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 16 Jul 2007 13:48:55 -0500
Subject: [R-sig-ME] Alpha test version of the latest (and last - trust me on
	this) reformulation of lmer and friends
Message-ID: <40e66e0b0707161148g21852ee3k7909a104126da358@mail.gmail.com>

At one point in the movie "The Big Chill" Nick (William Hurt) is
talking with Chloe (Meg Tilly) and says, "Well, yes, I do have a small
but deeply disturbed following."

So I would like to announce to the small but deeply disturbed
following of the lme4 package that the version of the package based on
the most recent redesign of the computational methods (and this is the
last time I'm going to tear it apart and rebuild it - I promise -
really) is ready for a few brave testers.  Currently lmer works but
glmer and nlmer need a bit more tuning up.  Also mcmcsamp doesn't work
at present in this version.

I would very much appreciate those who have written papers or books
that quote results from earlier versions of lmer checking those
results in the new lmer.  The answers from the new lmer should be at
least as good (in the sense of returning parameter estimates with a
log-likelihood or log-restricted-likelihood at least as large) as
those from earlier versions.  If the results are not as good as the
previous results, please let me know so we can work out what the
problem is.

If you can install source packages, the best way to get alpha test
releases of lme4 is from the SVN repository

 https://svn.r-project.org/R-packages/branches/gappy-lmer

using whatever svn client is handy for you.

A source tarball and a Windows binary package are also available as

 http://www.stat.wisc.edu/~bates/lme4_0.999375-0.tar.gz

and

 http://www.stat.wisc.edu/~bates/lme4_0.999375-0.zip

respectively.  The Windows binary package is prepared on Uwe Ligges'
wonderful win-builder facility at win-builder.R-project.org

I have again observed peculiar timing results when using accelerated
BLAS with lmer.  I haven't done intensive profiling of the C code to
determine exactly what is happening but the bottom line is that on my
machine (Athlon-64 dual-core, Ubuntu 7.10 "gutsy" devel) using the
reference BLAS compiled with gfortran is faster than using the AMD
Core Mathematics Library (ACML) "accelerated" BLAS, even the single
threaded version.  My typical test is shown in the enclosed
transcript.  The timing results there, about 55 - 60 seconds user
time, are with R's reference BLAS.  If I switch to single-threaded
ACML the time jumps to about 2 minutes.  With multithreaded BLAS it
takes about 4 minutes.

The computational methods are derived and described in the vignette
"Computational methods for mixed models" included with the package.
The "Implementation" vignette is in transition between a description
of earlier and current versions so don't believe everything in there.

I am also quite interested in timings.  Although I consider
robustness, reliability and accuracy to be more important than speed,
I would like to know how the speed of this version compares to earlier
versions on models fit to large data sets.

From austin.frank at gmail.com  Tue Jul 17 00:21:27 2007
From: austin.frank at gmail.com (Austin Frank)
Date: Mon, 16 Jul 2007 15:21:27 -0700
Subject: [R-sig-ME] multinomial mixed effects models
Message-ID: <m0r6n80z2w.fsf@dnab422077.stanford.edu>

Hello!

I and several of my colleagues are wondering whether it is possible to
use any of the methods of lme4 as it exists now to fit a mixed effects
model with a response variable drawn from a multinomial distribution.
glm does not include a multinomial family, so if it is possible to
accomplish this I'm not sure how to do so.  Packages that do allow
multinomial response variables (like multinomRob) don't seem to allow
for the inclusion of random effects.

If it is not currently possible to fit a data set with a categorical
dependent variable with more than two levels, might this be possible in
the forthcoming update to lme4?

Finally, if it isn't possible now and won't be in the next version of
the package either, would someone be willing to explain the conceptual
or technical difficulties associated with including a response variable
from a multinomial distribution in a mixed effects model?

Thanks for any help,
/au

-- 
Austin Frank
http://aufrank.net
GPG Public Key (D7398C2F): http://aufrank.net/personal.asc



From bates at stat.wisc.edu  Tue Jul 17 00:34:34 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 16 Jul 2007 17:34:34 -0500
Subject: [R-sig-ME] multinomial mixed effects models
In-Reply-To: <m0r6n80z2w.fsf@dnab422077.stanford.edu>
References: <m0r6n80z2w.fsf@dnab422077.stanford.edu>
Message-ID: <40e66e0b0707161534y1e87a11cj1a758ab16b0222ca@mail.gmail.com>

On 7/16/07, Austin Frank <austin.frank at gmail.com> wrote:
> Hello!

> I and several of my colleagues are wondering whether it is possible to
> use any of the methods of lme4 as it exists now to fit a mixed effects
> model with a response variable drawn from a multinomial distribution.
> glm does not include a multinomial family, so if it is possible to
> accomplish this I'm not sure how to do so.  Packages that do allow
> multinomial response variables (like multinomRob) don't seem to allow
> for the inclusion of random effects.

> If it is not currently possible to fit a data set with a categorical
> dependent variable with more than two levels, might this be possible in
> the forthcoming update to lme4?

> Finally, if it isn't possible now and won't be in the next version of
> the package either, would someone be willing to explain the conceptual
> or technical difficulties associated with including a response variable
> from a multinomial distribution in a mixed effects model?

The big problem is defining the model for a multinomial response.  I
haven't looked at the multinomRob package so perhaps it is just my
lack of understanding but I think it is difficult to formulate a
general model using a linear predictor for a multinomial response.

There is a special case of an ordered categorical response, such as
one gets from questions of the form "on a scale of 1 to 5 ...".  The
polr function from the MASS package fits a proportional odds logistic
regression model for which I think it should be straightforward to
define a version with random effects.



From afshart at exchange.sba.miami.edu  Tue Jul 17 18:35:10 2007
From: afshart at exchange.sba.miami.edu (Afshartous, David)
Date: Tue, 17 Jul 2007 12:35:10 -0400
Subject: [R-sig-ME] stratifying autocorrelation parameter in corAR1() in lme
In-Reply-To: <40e66e0b0707161534y1e87a11cj1a758ab16b0222ca@mail.gmail.com>
Message-ID: <6BCB4D493A447546A8126F24332056E8064AAA6E@school1.business.edu>

All,

In repeated measures over time it is possible that the witin patient 
autocorrelation model differs between treatment and placebo; thus one 
might want to stratify the AR1 parameter (phi) accordingly.  I attempted

to model this with corAR1() within the lme call, but the output still
produces only
one phi estimate.  Didn't see this in P&B, the archives, or docs.  
Is there a simple way to do this w/ lme?  (The simulated data below has 
repeated measures for each patient on both drug and placebo (not a
crossover).)

Thanks,
David

ps - the lme call below also stratifies the variance of the random
effect on the
intercept; for details, search archives for "random effect variance per
treatment group in lmer".


##################################################
## simulated data 
set.seed(500)
n.timepoints <- 8
n.subj.per.tx <- 20
sd.d <- 5; 
sd.p <- 2; 
sd.res <- 1.3
drug <- factor(rep(c("D", "P"), each = n.timepoints, times =
n.subj.per.tx)) 
drug.baseline <- rep( c(0,5), each=n.timepoints, times=n.subj.per.tx ) 
## Patient <- rep(1:(n.subj.per.tx*2), each = n.timepoints) 
dat.new$Patient.new = rep(1:20, each=16)    
## add new patient numer ID to emulate design where drug various within
patient
Patient.baseline <- rep( rnorm( n.subj.per.tx*2, sd=c(sd.d, sd.p) ),
each=n.timepoints ) 
time <- factor(paste("Time-", rep(1:n.timepoints, n.subj.per.tx*2),
sep="")) 
time.baseline <-
rep(1:n.timepoints,n.subj.per.tx*2)*as.numeric(drug=="D")
dv <- rnorm( n.subj.per.tx*n.timepoints*2,
mean=time.baseline+Patient.baseline+drug.baseline, sd=sd.res ) 
dat.new <- data.frame(time, drug, dv, Patient) 
xyplot( dv~time|drug, group=Patient, type="l", data=dat.new)
# fit model treats time as a quantitative predictor 
dat.new$Dind <- as.numeric(dat.new$drug == "D") 
dat.new$Pind <- as.numeric(dat.new$drug == "P")
dat.new$time.num = rep(1:n.timepoints, n.subj.per.tx*2)
########################################################################
## lme calls:
fm1 <- lme( dv ~ time.num*drug,  random = ~ 0 + Pind + Dind |
Patient.new,  data=dat.new)
## no autocorrelation 
fm1.AR1 <- lme( dv ~ time.num*drug,  random = ~ 0 + Pind + Dind |
Patient.new,  data=dat.new, correlation = corAR1(0, ~ 1 | Patient.new) )

## AR1 w/o stratification
fm1.AR1.strat <- lme( dv ~ time.num*drug,  random = ~ 0 + Pind + Dind |
Patient.new,  data=dat.new, correlation = corAR1(0, ~ time.num|
Patient.new/drug ) ) 
## attempted call, but doesn't stratify, i.e., only one phi in output


David Afshartous, PhD
University of Miami
School of Business
Rm KE-408
Coral Gables, FL 33124



From hskaug at gmail.com  Thu Jul 19 10:21:50 2007
From: hskaug at gmail.com (H. Skaug)
Date: Thu, 19 Jul 2007 10:21:50 +0200
Subject: [R-sig-ME] multinomial mixed effects models
Message-ID: <ed96c8240707190121u5a4f2a92h6354e01dcca4b952@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20070719/328e53de/attachment.pl>

From lamprianou at yahoo.com  Tue Jul 24 16:19:04 2007
From: lamprianou at yahoo.com (Iasonas Lamprianou)
Date: Tue, 24 Jul 2007 07:19:04 -0700 (PDT)
Subject: [R-sig-ME] lmer problem
Message-ID: <437290.49956.qm@web54107.mail.re2.yahoo.com>

<No dataset - too big>
Hi all,
I have a dataset (attached) which shows the score of pupils on different subjects. For example, pupil 13 may have been tested on subjects 1 (Greek), subject 4 (History) and 5 (Latin) whereas pupil 124 may have been tested on subjects 1 (Greek), 38 (Physics) and 19 (Chemistry). All pupils took Greek (subject with code 1). I attach the file with some data. Below, I show some of the R commands that I used. My intention is to estimate which of the subjects was more difficlut, and to estimate the % of variance because of pupils and because of subjects. Please give me some help, also send me any commands you may want to suggest and some explanations. I realized that SPSS 15 has included a new mixed models component, is it much better than R?


library(RODBC)
channel <- odbcConnectExcel("C:/JASON/PROJECTS/vathmoi2007/alldata.xls")
channel <- odbcConnectExcel("C:\smalldata.xls")
sqlTables(channel)
sqlTables(channel, errors = FALSE, as.is = TRUE)
Dataset = sqlQuery(channel, paste("select * from [data$]"))
Dataset$mathima <- factor(Dataset$mathima)
Dataset$app_aa <- factor(Dataset$app_aa)

note: app_aa is the code of the pupil

this is the model for the analysis I used, but how do I show that the pupils take more than one test?
mod2 <- lmer(arxiki ~ mathima + (1|app_aa), Dataset)

how about mod3 <- lmer(arxiki ~ 1 + (1|mathima) + (1|mathima:app_aa), Dataset)


Thanks

Jason
 
Dr. Iasonas Lamprianou
Department of Education
The University of Manchester
Oxford Road, Manchester M13 9PL, UK
Tel. 0044 161 275 3485
iasonas.lamprianou at manchester.ac.uk


----- Original Message ----
From: "r-sig-mixed-models-request at r-project.org" <r-sig-mixed-models-request at r-project.org>
To: r-sig-mixed-models at r-project.org
Sent: Friday, 20 July, 2007 1:00:13 PM
Subject: R-sig-mixed-models Digest, Vol 7, Issue 13


Send R-sig-mixed-models mailing list submissions to
    r-sig-mixed-models at r-project.org

To subscribe or unsubscribe via the World Wide Web, visit
    https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
or, via email, send a message with subject or body 'help' to
    r-sig-mixed-models-request at r-project.org

You can reach the person managing the list at
    r-sig-mixed-models-owner at r-project.org

When replying, please edit your Subject line so it is more specific
than "Re: Contents of R-sig-mixed-models digest..."


Today's Topics:

   1. multinomial mixed effects models (H. Skaug)


----------------------------------------------------------------------

Message: 1
Date: Thu, 19 Jul 2007 10:21:50 +0200
From: "H. Skaug" <hskaug at gmail.com>
Subject: [R-sig-ME] multinomial mixed effects models
To: r-sig-mixed-models at r-project.org
Message-ID:
    <ed96c8240707190121u5a4f2a92h6354e01dcca4b952 at mail.gmail.com>
Content-Type: text/plain

Hi,

If you are willing to move outside R,
mixed effects multinomial models can be fit with the
commercial software AD Model Builder:

http://otter-rsch.com/admbre/admbre.html

Ordered and unordered categorical responses can
be handled, and there is no limit on the number
of nesting levels (in principle). For an example see:

http://otter-rsch.com/admbre/examples/socatt/socatt.html

It is easy to call an AD Model Builder program from R:

http://otter-rsch.com/admbre/examples/glmmadmb/glmmADMB.html

There obviously are limitations on the size of the model,
and I will be happy to clarify if your problem at hand is within reach.

hans


>Hello!
>
>I and several of my colleagues are wondering whether it is possible to
>use any of the methods of lme4 as it exists now to fit a mixed effects
>model with a response variable drawn from a multinomial distribution.
>glm does not include a multinomial family, so if it is possible to
>accomplish this I'm not sure how to do so.  Packages that do allow
>multinomial response variables (like multinomRob) don't seem to allow
>for the inclusion of random effects.
>
>If it is not currently possible to fit a data set with a categorical
>dependent variable with more than two levels, might this be possible in
>the forthcoming update to lme4?
>
>Finally, if it isn't possible now and won't be in the next version of
>the package either, would someone be willing to explain the conceptual
>or technical difficulties associated with including a response variable
>from a multinomial distribution in a mixed effects model?
>
>Thanks for any help,
>/au

    [[alternative HTML version deleted]]



------------------------------

_______________________________________________
R-sig-mixed-models mailing list
R-sig-mixed-models at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


End of R-sig-mixed-models Digest, Vol 7, Issue 13
*************************************************


      ___________________________________________________________



From bates at stat.wisc.edu  Tue Jul 24 16:38:21 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 24 Jul 2007 09:38:21 -0500
Subject: [R-sig-ME] partly crossed design
Message-ID: <40e66e0b0707240738j5e60725er77ffb89311d14729@mail.gmail.com>

Iasonas Lamprianou sent the enclosed message to the R-SIG-Mixed-Models
mailing list.  It was deferred because the enclosed data in the form
of a zip file containing a .xls spreadsheet exceeded the limit on size
of messages.  I have made the data available as a .rda file (which is
less than 1/10 the size of the .xls file and about 1/3 the size of the
.zip file containing the .xls file) as

 http://www.stat.wisc.edu/~bates/sdata.rda

I enclose a transcript of a model fit to these data.  I will respond
to this posting with some comments.  That way the conversation becomes
properly threaded.

---------- Forwarded message ----------
From: Iasonas Lamprianou <lamprianou at yahoo.com>
To: r-sig-mixed-models at r-project.org
Date: Tue, 24 Jul 2007 06:38:28 -0700 (PDT)
Subject: partly crossed design
Hi all,
I have a dataset (attached) which shows the score of pupils on
different subjects. For example, pupil 13 may have been tested on
subjects 1 (Greek), subject 4 (History) and 5 (Latin) whereas pupil
124 may have been tested on subjects 1 (Greek), 38 (Physics) and 19
(Chemistry). All pupils took Greek (subject with code 1). I attach the
file with some data. Below, I show some of the R commands that I used.
My intention is to estimate which of the subjects was more difficlut,
and to estimate the % of variance because of pupils and because of
subjects. Please give me some help, also send me any commands you may
want to suggest and some explanations. I realized that SPSS 15 has
included a new mixed models component, is it much better than R?


library(RODBC)
channel <- odbcConnectExcel("C:/JASON/PROJECTS/vathmoi2007/alldata.xls")
channel <- odbcConnectExcel("C:\smalldata.xls")
sqlTables(channel)
sqlTables(channel, errors = FALSE, as.is = TRUE)
Dataset = sqlQuery(channel, paste("select * from [data$]"))
Dataset$mathima <- factor(Dataset$mathima)
Dataset$app_aa <- factor(Dataset$app_aa)

note: app_aa is the code of the pupil

this is the model for the analysis I used, but how do I show that the
pupils take more than one test?
mod2 <- lmer(arxiki ~ mathima + (1|app_aa), Dataset)

how about mod3 <- lmer(arxiki ~ 1 + (1|mathima) + (1|mathima:app_aa), Dataset)


Thanks

Jason



Dr. Iasonas Lamprianou
Department of Education
The University of Manchester
Oxford Road, Manchester M13 9PL, UK
Tel. 0044 161 275 3485
iasonas.lamprianou at manchester.ac.uk
----------

From bates at stat.wisc.edu  Tue Jul 24 17:16:44 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 24 Jul 2007 10:16:44 -0500
Subject: [R-sig-ME] partly crossed design
In-Reply-To: <40e66e0b0707240738j5e60725er77ffb89311d14729@mail.gmail.com>
References: <40e66e0b0707240738j5e60725er77ffb89311d14729@mail.gmail.com>
Message-ID: <40e66e0b0707240816k5909aee0v78823307c228e3af@mail.gmail.com>

> ---------- Forwarded message ----------
> From: Iasonas Lamprianou <lamprianou at yahoo.com>
> To: r-sig-mixed-models at r-project.org
> Date: Tue, 24 Jul 2007 06:38:28 -0700 (PDT)
> Subject: partly crossed design

> Hi all,

> I have a dataset (attached) which shows the score of pupils on
> different subjects. For example, pupil 13 may have been tested on
> subjects 1 (Greek), subject 4 (History) and 5 (Latin) whereas pupil
> 124 may have been tested on subjects 1 (Greek), 38 (Physics) and 19
> (Chemistry). All pupils took Greek (subject with code 1).

Apparently not.  There are 9409 student id's and only 9403 scores for Greek.

It would help if you could give us the complete set of codes so the
labels could be changed to Greek, History, Latin, etc. instead of 9
arbitrary numbers.

> I attach the
> file with some data. Below, I show some of the R commands that I used.

> My intention is to estimate which of the subjects was more difficult,
> and to estimate the % of variance because of pupils and because of
> subjects.

The coefficients in the model that I fit to these data are typical
scores on the subjects, adjusted for student abilities, as measured by
the random effects.

> Please give me some help, also send me any commands you may
> want to suggest and some explanations. I realized that SPSS 15 has
> included a new mixed models component, is it much better than R?

I'll let others handle that question. :-)

With this message I enclose another transcript that contains a model
fit with random effects for subject and for student.   This would be
another way of assessing difficulty of subject adjusted for student.
In this case there are partially crossed random effects.  (BTW, I
would be interested in the results from SPSS v15 on such a model and
in how long it takes to fit such a model. I should say that I am using
the development version of the lme4 package in fitting these models.
If I were to use the released version of the package I would replace
lmer by lmer2.)

...

> this is the model for the analysis I used, but how do I show that the
> pupils take more than one test?

I'm not sure what you mean by that.  You could tabulate the table of
the number of observations per student as shown in this transcript or
you can show the results from a selection of students as was done
here.

> mod2 <- lmer(arxiki ~ mathima + (1|app_aa), Dataset)

> how about mod3 <- lmer(arxiki ~ 1 + (1|mathima) + (1|mathima:app_aa), Dataset)

That won't work because the number of levels of the mathima:app_aa
interaction is the same as the number of observations so the
per-observation noise term is completely confounded with the random
effect you are trying to specify.
-------------- next part --------------
A non-text attachment was scrubbed...
Name: sdata.pdf
Type: application/pdf
Size: 25938 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20070724/c727dac5/attachment.pdf>
-------------- next part --------------

R version 2.6.0 Under development (unstable) (2007-07-24 r42297)
Copyright (C) 2007 The R Foundation for Statistical Computing
ISBN 3-900051-07-0

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> library(lme4)
Loading required package: Matrix
Loading required package: lattice
> load(url("http://www.stat.wisc.edu/~bates/sdata.rda"))
> pdf(file = "sdata.pdf")
> str(sdata)
'data.frame':	25120 obs. of  3 variables:
 $ app_aa : Factor w/ 9409 levels "1","10","1,000",..: 1 1093 2178 4362 5448 6536 7628 8721 2 109 ...
 $ mathima: Factor w/ 9 levels "1","19","21",..: 1 1 1 1 1 1 1 1 1 1 ...
 $ score  : int  107 43 47 26 37 112 51 72 88 83 ...
Warning message:
closing unused connection 3 (gzcon(http://www.stat.wisc.edu/~bates/sdata.rda)) 
> xtabs(~ mathima, sdata)
mathima
   1   19   21   37   38    4   43    5    6 
9403  448 1659 3204 1834 1736 5019  177 1640 
> with(sdata, table(table(app_aa)))

   1    2    3    4    5 
1104 2860 3542 1845   58 
> set.seed(123454321)
> subs <- subset(sdata, app_aa %in% sample(levels(app_aa), 20))
> subs[order(subs$app_aa),]
      app_aa mathima score
1151   1,173       1    14
1200   1,223       1    84
13616  1,223      21    10
15454  1,223      37    41
18486  1,223      38    23
1998   2,036       1   110
9766   2,036       4    74
21207  2,036      43   130
2082   2,124       1    77
11683  2,124       6   129
21250  2,124      43   130
2526   2,580       1    69
15912  2,580      37    24
2929   2,990       1    97
21706  2,990      43   128
3202   3,267       1    82
21844  3,267      43   110
3296   3,363       1    44
21894  3,363      43    87
3657   3,731       1    94
16297  3,731      37   104
18985  3,731      38   104
3764   3,841       1     8
22138  3,841      43    21
3845   3,923       1    75
16373  3,923      37   106
19028  3,923      38   108
5982   6,108       1     5
7061   7,209       1    71
12567  7,209       6    97
23881  7,209      43    23
8182   8,346       1   141
10906  8,346       4   147
24477  8,346      43   191
8320   8,486       1    12
8401   8,567       1    35
24591  8,567      43    31
850      867       1    19
20580    867      43    40
8790   8,965       1   146
11024  8,965       4   170
24794  8,965      43   197
9086   9,261       1    98
18153  9,261      37    77
20042  9,261      38   106
9107   9,282       1    43
11084  9,282       4    27
12914  9,282       6   124
24966  9,282      43    14
> densityplot(~ score, sdata, plot.points = FALSE)
> densityplot(~ score|mathima, sdata, plot.points = FALSE)
> system.time(m1 <- lmer(score ~ 0 + mathima + (1|app_aa),
+                        sdata, control = list(msV = 1)))
  0:     258960.61: 0.999416
  1:     258081.58:  1.99942
  2:     257669.40:  1.73209
  3:     257601.36:  1.48965
  4:     257583.86:  1.57219
  5:     257583.55:  1.56285
  6:     257583.54:  1.56229
  7:     257583.54:  1.56230
   user  system elapsed 
  2.220   0.036   2.255 
> system.time(m1 <- lmer(score ~ 0 + mathima + (1|app_aa), sdata))
   user  system elapsed 
  0.904   0.036   0.942 
> m1
Linear mixed-effects model fit by REML 
Formula: score ~ 0 + mathima + (1 | app_aa) 
   Data: sdata 
    AIC    BIC  logLik MLdeviance REMLdeviance
 257604 257685 -128792     257597       257584
Random effects:
 Groups   Name Variance Std.Dev.
 app_aa        1947.05  44.125  
 Residual       797.84  28.246  
Number of obs: 25120, groups: app_aa, 9409

Fixed effects:
          Estimate Std. Error t value
mathima1   81.0323     0.5402  150.01
mathima19  75.0738     1.5907   47.20
mathima21  86.2260     0.9119   94.55
mathima37  86.0341     0.7428  115.82
mathima38  91.0371     0.8998  101.18
mathima4   80.6845     0.9060   89.05
mathima43 109.5310     0.6398  171.21
mathima5  118.4503     2.4699   47.96
mathima6  126.3008     0.9205  137.20

Correlation of Fixed Effects:
          mathm1 mthm19 mthm21 mthm37 mthm38 mathm4 mthm43 mathm5
mathima19 0.241                                                  
mathima21 0.420  0.206                                           
mathima37 0.516  0.243  0.341                                    
mathima38 0.426  0.198  0.291  0.455                             
mathima4  0.423  0.113  0.230  0.242  0.194                      
mathima43 0.599  0.167  0.351  0.338  0.276  0.423               
mathima5  0.155  0.040  0.078  0.085  0.069  0.165  0.157        
mathima6  0.416  0.118  0.229  0.274  0.206  0.308  0.391  0.094 
> system.time(m2 <- lmer(score ~ 1 + (1|mathima) + (1|app_aa),
+                        sdata, control = list(msV = 1)))
  0:     260067.68: 0.0309098 0.999416
  1:     258490.09:  1.02452  1.11227
  2:     257665.35:  1.02320  1.61227
  3:     257658.21:  1.02195  1.57729
  4:     257657.49:  1.02005  1.56186
  5:     257657.48:  1.01875  1.56236
  6:     257657.32: 0.996976  1.56620
  7:     257657.03: 0.948383  1.57035
  8:     257656.33: 0.801040  1.57692
  9:     257655.81: 0.645518  1.57769
 10:     257655.25: 0.660122  1.57025
 11:     257655.04: 0.636126  1.56172
 12:     257655.04: 0.654799  1.56199
 13:     257655.03: 0.649502  1.56216
 14:     257655.03: 0.649233  1.56214
   user  system elapsed 
  1.261   0.008   1.266 
> system.time(m2 <- lmer(score ~ 1 + (1|mathima) + (1|app_aa), sdata))
   user  system elapsed 
  1.236   0.020   1.258 
> m2
Linear mixed-effects model fit by REML 
Formula: score ~ 1 + (1 | mathima) + (1 | app_aa) 
   Data: sdata 
    AIC    BIC  logLik MLdeviance REMLdeviance
 257661 257685 -128828     257661       257655
Random effects:
 Groups   Name Variance Std.Dev.
 mathima        336.32  18.339  
 app_aa        1946.80  44.123  
 Residual       797.89  28.247  
Number of obs: 25120, groups: mathima, 9; app_aa, 9409

Fixed effects:
            Estimate Std. Error t value
(Intercept)   94.902      6.141   15.45
> ranef(m2)$mathima
   (Intercept)
1   -13.865747
19  -19.678775
21   -8.649562
37   -8.845464
38   -3.841410
4   -14.212544
43   14.613201
5    23.142992
6    31.337310
> 
> 
> 
> 
> proc.time()
   user  system elapsed 
 19.637   0.320  19.987 

From lamprianou at yahoo.com  Wed Jul 25 00:42:12 2007
From: lamprianou at yahoo.com (Iasonas Lamprianou)
Date: Tue, 24 Jul 2007 15:42:12 -0700 (PDT)
Subject: [R-sig-ME] R-sig-mixed-models Digest, Vol 7, Issue 14
Message-ID: <409369.43334.qm@web54110.mail.re2.yahoo.com>

thanks for the models, but what is the conceptual difference between m1 and m2? how is the interpretation different? would the subject with the smallest estimate be the most difficult?

jason


      ___________________________________________________________



From rlevy at ucsd.edu  Wed Jul 25 07:16:56 2007
From: rlevy at ucsd.edu (Roger Levy)
Date: Tue, 24 Jul 2007 22:16:56 -0700
Subject: [R-sig-ME] multinomial mixed effects models
In-Reply-To: <40e66e0b0707161534y1e87a11cj1a758ab16b0222ca@mail.gmail.com>
References: <m0r6n80z2w.fsf@dnab422077.stanford.edu>
	<40e66e0b0707161534y1e87a11cj1a758ab16b0222ca@mail.gmail.com>
Message-ID: <46A6DCC8.5080809@ucsd.edu>

Douglas Bates wrote:
> On 7/16/07, Austin Frank <austin.frank at gmail.com> wrote:
>> Hello!
> 
>> I and several of my colleagues are wondering whether it is possible to
>> use any of the methods of lme4 as it exists now to fit a mixed effects
>> model with a response variable drawn from a multinomial distribution.
>> glm does not include a multinomial family, so if it is possible to
>> accomplish this I'm not sure how to do so.  Packages that do allow
>> multinomial response variables (like multinomRob) don't seem to allow
>> for the inclusion of random effects.
> 
>> If it is not currently possible to fit a data set with a categorical
>> dependent variable with more than two levels, might this be possible in
>> the forthcoming update to lme4?
> 
>> Finally, if it isn't possible now and won't be in the next version of
>> the package either, would someone be willing to explain the conceptual
>> or technical difficulties associated with including a response variable
>> from a multinomial distribution in a mixed effects model?
> 
> The big problem is defining the model for a multinomial response.  I
> haven't looked at the multinomRob package so perhaps it is just my
> lack of understanding but I think it is difficult to formulate a
> general model using a linear predictor for a multinomial response.

May I follow up on this question?  Ordinary multinomial regression for K 
categorical outcome responses is generalized from binary logistic 
regression by choosing one outcome as the reference category, and using 
K-1 for the remaining K-1 outcomes.  So what would be the problem with 
just adding random effects to each of the K-1 linear predictors?  Is the 
trouble perhaps that the random effect introduces an asymmetry such that 
the inferred model could depend on the choice of the reference outcome 
category?

Many thanks,

Roger



From sundar.dorai-raj at pdf.com  Wed Jul 25 18:50:46 2007
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Wed, 25 Jul 2007 09:50:46 -0700
Subject: [R-sig-ME] weights in lmer
Message-ID: <46A77F66.3020402@pdf.com>

Hi, Prof. Bates,

It appears the weights argument is ignored in lmer but not in lmer2. 
See, for example:

library(lme4)
set.seed(1)
w <- abs(rnorm(nrow(sleepstudy)))
fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy)
fm2 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy, weights = w)
fm3 <- lmer2(Reaction ~ Days + (Days|Subject), sleepstudy, weights = w)
VarCorr(fm1) # no weights
VarCorr(fm2) # same as fm1, incorrect
VarCorr(fm3) # `w' applied correctly

sessionInfo()
R version 2.5.1 (2007-06-27)
i386-pc-mingw32

locale:
LC_COLLATE=English_United States.1252;LC_CTYPE=English_United 
States.1252;LC_MONETARY=English_United 
States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252

attached base packages:
[1] "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods"
[7] "base"

other attached packages:
         lme4       Matrix      lattice
  "0.99875-6" "0.999375-0"     "0.16-2"



From n.l.pace at utah.edu  Thu Jul 26 19:39:16 2007
From: n.l.pace at utah.edu (Nathan Leon Pace, MD, MStat)
Date: Thu, 26 Jul 2007 11:39:16 -0600
Subject: [R-sig-ME] syntax lmer random effects
Message-ID: <C2CE3864.6758%n.l.pace@utah.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20070726/f133fc2d/attachment.pl>

From n.l.pace at utah.edu  Thu Jul 26 19:43:29 2007
From: n.l.pace at utah.edu (Nathan Leon Pace, MD, MStat)
Date: Thu, 26 Jul 2007 11:43:29 -0600
Subject: [R-sig-ME] FW:  syntax lmer random effects
In-Reply-To: <C2CE3864.6758%n.l.pace@utah.edu>
Message-ID: <C2CE3961.675E%n.l.pace@utah.edu>

Forgot to add that the family = binomial.

Nathan

> Hi,
> 
> Even after reading the various help files, I don?t really understand the
> formatting of the grouping factor.
> 
> My model is z ~ x*y with 1 grouping factor. I wish to compare models with
> only an intercept random effect, random effects for intercept and x, random
> effects for intercept and y, random effects for intercept plus x and y
> (independent and not independent), and random effects for all fixed effects
> (independent and not independent).
> 
> My data frame has 360 rows with 24 levels of the grouping factor
> 
>> sessionInfo()
> R version 2.5.1 (2007-06-27)
> i386-apple-darwin8.9.1
> 
> locale:
> en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
> 
> attached base packages:
> [1] "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods"
> "base"     
> 
> other attached packages:
>         lme4       Matrix      lattice
>  "0.99875-4" "0.999375-0"     "0.16-2"
> 
> Insights will be appreciated.
> 
> Nathan
> -- 
> Nathan Leon Pace, MD, MStat
> University of Utah
> n.l.pace at utah.edu
> W: 801.581.6393
> F: 801.581.4367
> M: 801.205.1019
> 
> 
> 
> 
> [[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

------ End of Forwarded Message



From bates at stat.wisc.edu  Thu Jul 26 19:45:45 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 26 Jul 2007 12:45:45 -0500
Subject: [R-sig-ME] R-sig-mixed-models Digest, Vol 7, Issue 14
In-Reply-To: <409369.43334.qm@web54110.mail.re2.yahoo.com>
References: <409369.43334.qm@web54110.mail.re2.yahoo.com>
Message-ID: <40e66e0b0707261045w585afe11r1d30c933fff06619@mail.gmail.com>

On 7/24/07, Iasonas Lamprianou <lamprianou at yahoo.com> wrote:

> thanks for the models,

My message was intended to show how you could fit the models.  I have
no plans to offer a service to fit models for others.

> but what is the conceptual difference between m1 and m2? how is the interpretation different?

Do you mean in addition to the fact that the effects for the subject
of study are fixed effects in model m1 and random effects in model m2?

If you are not familiar with the distinction between fixed effects and
random effects I suggest doing some background reading.

> would the subject with the smallest estimate be the most difficult?

Presumably.  It is your data so you would be the one to know whether a
larger score is good or bad.  The parameter estimates for the fixed
effects in model 1 represent a typical score for the subject taking
into account each student's overall ability.  In model m2 the
estimates for the random effects are relative to a "typical" or
average subject.



From HDoran at air.org  Thu Jul 26 19:52:24 2007
From: HDoran at air.org (Doran, Harold)
Date: Thu, 26 Jul 2007 13:52:24 -0400
Subject: [R-sig-ME] syntax lmer random effects
In-Reply-To: <C2CE3864.6758%n.l.pace@utah.edu>
Message-ID: <2323A6D37908A847A7C32F1E3662C80EE58049@dc1ex01.air.org>

Nathan:

Here are a few small examples given what you have provided below. To use lmer with an intercept only and random intercepts:

fit1 <-  lmer(z ~ 1 + (1|ID), data, method='ML')

Now, to fit a model with a fixed effect, 'x', and to allow for the intercept and for the variable x to vary randomly, use the following:

fit2 <-  lmer(z ~ x + (x|ID), data, method='ML')

Notice that the random terms are always (x|ID), where x is the variable you want to have as the random effect, followed by a "pipe" (|) and then the grouping variable. In this example the grouping variable is ID. So, you have a random variable x, "given", or "conditional on" ID.

Also notice I use method='ML'. You said you wanted to compare models and these models differ in their fixed effects. REML is the default estimation procedure, and so you need this portion of code. 

> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org 
> [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf 
> Of Nathan Leon Pace, MD, MStat
> Sent: Thursday, July 26, 2007 1:39 PM
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] syntax lmer random effects
> 
> Hi,
> 
> Even after reading the various help files, I don?t really 
> understand the formatting of the grouping factor.
> 
> My model is z ~ x*y with 1 grouping factor. I wish to compare 
> models with only an intercept random effect, random effects 
> for intercept and x, random effects for intercept and y, 
> random effects for intercept plus x and y (independent and 
> not independent), and random effects for all fixed effects 
> (independent and not independent).
> 
> My data frame has 360 rows with 24 levels of the grouping factor
> 
> > sessionInfo()
> R version 2.5.1 (2007-06-27)
> i386-apple-darwin8.9.1
> 
> locale:
> en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
> 
> attached base packages:
> [1] "stats"     "graphics"  "grDevices" "utils"     
> "datasets"  "methods"
> "base"     
> 
> other attached packages:
>         lme4       Matrix      lattice
>  "0.99875-4" "0.999375-0"     "0.16-2"
> 
> Insights will be appreciated.
> 
> Nathan
> --
> Nathan Leon Pace, MD, MStat
> University of Utah
> n.l.pace at utah.edu
> W: 801.581.6393
> F: 801.581.4367
> M: 801.205.1019
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
>



From valdar at well.ox.ac.uk  Wed Aug  1 19:49:58 2007
From: valdar at well.ox.ac.uk (William Valdar)
Date: Wed, 1 Aug 2007 18:49:58 +0100 (BST)
Subject: [R-sig-ME] simulate() fails for poisson lmer fits
Message-ID: <Pine.LNX.4.64.0708011822100.8824@zeon.well.ox.ac.uk>

Hello,

I wish to simulate() from a fitted Poisson GLMM. Both lmer() and lmer2() 
from lme4 (version info at the bottom) fail, apparently due to bugs. 
Here's a test case:

counts <- data.frame(
         count  = c(8, 3, 0, 3, 0, 9, 0, 11, 4, 7, 0, 0, 0, 4, 3, 6, 3,
                 15, 11, 9),
         batch = c(3.1, 3.1, 3.1, 3.3, 3.3, 3.3, 3.2, 3.12, 3.8, 3.11,
                 3.4, 3.4, 3.4, 3.4, 3.5, 3.5, 3.5, 3.5, 3.6, 3.6),
         weight = c(324.4, 372.5, 352.7, 379.6, 388.1, 431, 448.4, 377.3,
                 376.5, 358.4, 356, 351.4, 350.8, 332.1, 334.5, 392, 370.5,
                 409.7, 375, 318.5))

fit <- lmer(count ~ weight + (1|batch),  family=poisson, data=counts)
# Error: inherits(object, "lmer") is not TRUE

fit <- lmer2(count ~ weight + (1|batch),  family=poisson, data=counts)
simulate(fit)
# CHOLMOD error: X and/or Y have wrong dimensions
# Error in crossprod(object at ZXyt, c(unlist(lapply(seq_along(re), 
# function(k) (t(cholL[[k]]) %*%  :
#        Cholmod error 'X and/or Y have wrong dimensions' at 
# file:../MatrixOps/cholmod_sdmult.c, line 90

Is there a quick fix for either of these two? Otherwise, is there an 
alternative (I've checked objects produced by nlme, glmmPQL, GLMMGibbs 
with no luck)? I am using lme4 0.99875-6 version R 2.5.1 on Windows XP.

Many thanks,

Will

=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=
Dr William Valdar               ++44 (0)1865 287 589
Wellcome Trust Centre           valdar at well.ox.ac.uk
for Human Genetics, Oxford      www.well.ox.ac.uk/~valdar



From valdar at well.ox.ac.uk  Thu Aug  2 01:23:07 2007
From: valdar at well.ox.ac.uk (William Valdar)
Date: Thu, 2 Aug 2007 00:23:07 +0100 (BST)
Subject: [R-sig-ME] simulate() fails for poisson lmer fits
In-Reply-To: <Pine.LNX.4.64.0708011822100.8824@zeon.well.ox.ac.uk>
References: <Pine.LNX.4.64.0708011822100.8824@zeon.well.ox.ac.uk>
Message-ID: <Pine.LNX.4.64.0708020021210.7087@zeon.well.ox.ac.uk>


I missed out a line in the code below. The line that throws the error is 
not the fitting but the subsequent simulation, ie:

fit <- lmer(count ~ weight + (1|batch),  family=poisson, data=counts)
simulate(fit)
# Error: inherits(object, "lmer") is not TRUE


On Wed, 1 Aug 2007, William Valdar wrote:
> Hello,
>
> I wish to simulate() from a fitted Poisson GLMM. Both lmer() and lmer2() from 
> lme4 (version info at the bottom) fail, apparently due to bugs. Here's a test 
> case:
>
> counts <- data.frame(
>        count  = c(8, 3, 0, 3, 0, 9, 0, 11, 4, 7, 0, 0, 0, 4, 3, 6, 3,
>                15, 11, 9),
>        batch = c(3.1, 3.1, 3.1, 3.3, 3.3, 3.3, 3.2, 3.12, 3.8, 3.11,
>                3.4, 3.4, 3.4, 3.4, 3.5, 3.5, 3.5, 3.5, 3.6, 3.6),
>        weight = c(324.4, 372.5, 352.7, 379.6, 388.1, 431, 448.4, 377.3,
>                376.5, 358.4, 356, 351.4, 350.8, 332.1, 334.5, 392, 370.5,
>                409.7, 375, 318.5))
>
> fit <- lmer(count ~ weight + (1|batch),  family=poisson, data=counts)
> # Error: inherits(object, "lmer") is not TRUE
>
> fit <- lmer2(count ~ weight + (1|batch),  family=poisson, data=counts)
> simulate(fit)
> # CHOLMOD error: X and/or Y have wrong dimensions
> # Error in crossprod(object at ZXyt, c(unlist(lapply(seq_along(re), # 
> function(k) (t(cholL[[k]]) %*%  :
> #        Cholmod error 'X and/or Y have wrong dimensions' at # 
> file:../MatrixOps/cholmod_sdmult.c, line 90
>
> Is there a quick fix for either of these two? Otherwise, is there an 
> alternative (I've checked objects produced by nlme, glmmPQL, GLMMGibbs with 
> no luck)? I am using lme4 0.99875-6 version R 2.5.1 on Windows XP.
>
> Many thanks,
>
> Will
>
> =-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=
> Dr William Valdar               ++44 (0)1865 287 589
> Wellcome Trust Centre           valdar at well.ox.ac.uk
> for Human Genetics, Oxford      www.well.ox.ac.uk/~valdar
>
>

=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=
Dr William Valdar               ++44 (0)1865 287 589
Wellcome Trust Centre           valdar at well.ox.ac.uk
for Human Genetics, Oxford      www.well.ox.ac.uk/~valdar



From maechler at stat.math.ethz.ch  Thu Aug  2 13:09:51 2007
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 2 Aug 2007 13:09:51 +0200
Subject: [R-sig-ME] simulate() fails for poisson lmer fits
In-Reply-To: <Pine.LNX.4.64.0708011822100.8824@zeon.well.ox.ac.uk>
References: <Pine.LNX.4.64.0708011822100.8824@zeon.well.ox.ac.uk>
Message-ID: <18097.47999.782177.945026@stat.math.ethz.ch>

Hi,
>>>>> "WV" == William Valdar <valdar at well.ox.ac.uk>
>>>>>     on Wed, 1 Aug 2007 18:49:58 +0100 (BST) writes:

    WV> Hello, I wish to simulate() from a fitted Poisson
    WV> GLMM. Both lmer() and lmer2() from lme4 (version info at
    WV> the bottom) fail, apparently due to bugs.  Here's a test
    WV> case:

    counts <- data.frame(
	     count  = c(8, 3, 0, 3, 0, 9, 0, 11, 4, 7, 0, 0, 0, 4, 3, 6, 3,
		     15, 11, 9),
	     batch = c(3.1, 3.1, 3.1, 3.3, 3.3, 3.3, 3.2, 3.12, 3.8, 3.11,
		     3.4, 3.4, 3.4, 3.4, 3.5, 3.5, 3.5, 3.5, 3.6, 3.6),
	     weight = c(324.4, 372.5, 352.7, 379.6, 388.1, 431, 448.4, 377.3,
		     376.5, 358.4, 356, 351.4, 350.8, 332.1, 334.5, 392, 370.5,
		     409.7, 375, 318.5))

    fit <- lmer(count ~ weight + (1|batch),  family=poisson, data=counts)

MM, that works fine, but

    simulate(fit)

gives what you say:

  WV>    # Error: inherits(object, "lmer") is not TRUE

and that's indeed a bug in the simulate method:

Using  inherits(object, "lmer")  is wrong and should be
replaced by  is(object, "lmer") .

Instead of waiting for the next version of lme4, 
I think the following should work for you:


setMethod("simulate", signature(object = "mer"),
	  function(object, nsim = 1, seed = NULL, ...)
      {
	  if(!exists(".Random.seed", envir = .GlobalEnv))
	      runif(1)		     # initialize the RNG if necessary
	  if(is.null(seed))
	      RNGstate <- .Random.seed
	  else {
	      R.seed <- .Random.seed
	      set.seed(seed)
	      RNGstate <- structure(seed, kind = as.list(RNGkind()))
	      on.exit(assign(".Random.seed", R.seed, envir = .GlobalEnv))
	  }

	  stopifnot((nsim <- as.integer(nsim[1])) > 0, is(object, "lmer"))
	  ## similate the linear predictors
	  lpred <- .Call(lme4:::mer_simulate, object, nsim)
	  sc <- abs(object at devComp[8])

	  ## add fixed-effects contribution and per-observation noise term
	  lpred <- as.data.frame(lpred + drop(object at X %*% fixef(object)) +
				 rnorm(prod(dim(lpred)), sd = sc))
	  ## save the seed
	  attr(lpred, "seed") <- RNGstate
	  lpred
      })


at least it fixes the problem for me.


    WV> fit <- lmer2(count ~ weight + (1|batch),  family=poisson, data=counts)
    WV> simulate(fit)
    WV> # CHOLMOD error: X and/or Y have wrong dimensions
    WV> # Error in crossprod(object at ZXyt, c(unlist(lapply(seq_along(re), 
    WV> # function(k) (t(cholL[[k]]) %*%  :
    WV> #        Cholmod error 'X and/or Y have wrong dimensions' at 
    WV> # file:../MatrixOps/cholmod_sdmult.c, line 90

I can confirm that error and I agree that it is a bug,
well at least in the error message :-)

BTW, also     summary(fit)   gives an error.
{which is caused by  vcov(fit)  getting 0 x 0 matrix }

But then,  lmer2() is in beta testing,
so thanks a lot for your nicely reproducible example.


Note that your data set has only one observation for some batch
levels which may be deemed to give problems,
but in fact that's not the problem here at all.

Regards,
Martin Maechler, ETH Zurich


    WV> Is there a quick fix for either of these two? Otherwise, is there an 
    WV> alternative (I've checked objects produced by nlme, glmmPQL, GLMMGibbs 
    WV> with no luck)? I am using lme4 0.99875-6 version R 2.5.1 on Windows XP.

    WV> Many thanks,

    WV> Will

    WV> =-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=
    WV> Dr William Valdar               ++44 (0)1865 287 589
    WV> Wellcome Trust Centre           valdar at well.ox.ac.uk
    WV> for Human Genetics, Oxford      www.well.ox.ac.uk/~valdar



From valdar at well.ox.ac.uk  Thu Aug  2 14:11:32 2007
From: valdar at well.ox.ac.uk (William Valdar)
Date: Thu, 2 Aug 2007 13:11:32 +0100 (BST)
Subject: [R-sig-ME] simulate() fails for poisson lmer fits
In-Reply-To: <18097.47999.782177.945026@stat.math.ethz.ch>
References: <Pine.LNX.4.64.0708011822100.8824@zeon.well.ox.ac.uk>
	<18097.47999.782177.945026@stat.math.ethz.ch>
Message-ID: <Pine.LNX.4.64.0708021303280.12021@zeon.well.ox.ac.uk>


That works perfectly, thanks very much!

It's also considerably faster than the hack fix I wrote in the early hours 
of this morning (included below only for interest and as a warning to 
others).

Will

---hack---

rnorm.factor <- function(g, sd=1, mean=0)
# generate rnorm for a simple "batch" effect
{
     g   <- as.factor(g)[drop=TRUE]
     x.g <- rnorm( nlevels(g), sd=sd, mean=mean )
     return (x.g[g])
}

simulate.lmer.hack <- function(fit, nsim=1, seed=NULL, ...)
# simulate from fitted lmer obj with simple random intercepts
{
     if (!is.null(seed)) set.seed(seed)

     n <- length(fitted(fit))
     fixed.linpreds <- model.matrix(attr(fit, "terms"),
             data=attr(fit, "frame")) %*% fixef(fit)

     ymat <- matrix(NA, nrow=n, ncol=nsim)
     for (s in 1:nsim)
     {
         random.linpreds <- rep(0, length(n))
         vc <- VarCorr(fit)
         for (i in 1:length(vc))
         {
             random.sd   <- sqrt(vc[[i]][1])
             random.data <- attr(fit, "flist")[[i]]
             random.linpreds <- random.linpreds +
                     rnorm.factor(random.data, sd=random.sd, mean=0)
         }
         # make canonical param
         theta <- fixed.linpreds + random.linpreds
         if (is.null(attr(fit, "family")))
         {
             scale <- attr(vc, "sc")
             ymat[,s] <- rnorm(n, theta, scale)
         }
         else if ("poisson" == attr(fit, "family")$family)
         {
             ymat[,s] <- rpois(n, attr(fit, "family")$linkinv(theta))
         }
     }
     as.data.frame(ymat)
}

counts <- data.frame(
         count  = c(8, 3, 0, 3, 0, 9, 0, 11, 4, 7, 0, 0, 0, 4, 3, 6, 3,
                 15, 11, 9),
         batch = c(3.1, 3.1, 3.1, 3.3, 3.3, 3.3, 3.2, 3.12, 3.8, 3.11,
                 3.4, 3.4, 3.4, 3.4, 3.5, 3.5, 3.5, 3.5, 3.6, 3.6),
         weight = c(324.4, 372.5, 352.7, 379.6, 388.1, 431, 448.4, 377.3,
                 376.5, 358.4, 356, 351.4, 350.8, 332.1, 334.5, 392, 370.5,
                 409.7, 375, 318.5))

fit.poisson <- lmer(count ~ weight + (1|batch),  family=poisson, 
data=counts)
simulate.lmer.hack(fit.poisson)


On Thu, 2 Aug 2007, Martin Maechler wrote:
> Hi,
>>>>>> "WV" == William Valdar <valdar at well.ox.ac.uk>
>>>>>>     on Wed, 1 Aug 2007 18:49:58 +0100 (BST) writes:
>
>    WV> Hello, I wish to simulate() from a fitted Poisson
>    WV> GLMM. Both lmer() and lmer2() from lme4 (version info at
>    WV> the bottom) fail, apparently due to bugs.  Here's a test
>    WV> case:
>
>    counts <- data.frame(
> 	     count  = c(8, 3, 0, 3, 0, 9, 0, 11, 4, 7, 0, 0, 0, 4, 3, 6, 3,
> 		     15, 11, 9),
> 	     batch = c(3.1, 3.1, 3.1, 3.3, 3.3, 3.3, 3.2, 3.12, 3.8, 3.11,
> 		     3.4, 3.4, 3.4, 3.4, 3.5, 3.5, 3.5, 3.5, 3.6, 3.6),
> 	     weight = c(324.4, 372.5, 352.7, 379.6, 388.1, 431, 448.4, 377.3,
> 		     376.5, 358.4, 356, 351.4, 350.8, 332.1, 334.5, 392, 370.5,
> 		     409.7, 375, 318.5))
>
>    fit <- lmer(count ~ weight + (1|batch),  family=poisson, data=counts)
>
> MM, that works fine, but
>
>    simulate(fit)
>
> gives what you say:
>
>  WV>    # Error: inherits(object, "lmer") is not TRUE
>
> and that's indeed a bug in the simulate method:
>
> Using  inherits(object, "lmer")  is wrong and should be
> replaced by  is(object, "lmer") .
>
> Instead of waiting for the next version of lme4,
> I think the following should work for you:
>
>
> setMethod("simulate", signature(object = "mer"),
> 	  function(object, nsim = 1, seed = NULL, ...)
>      {
> 	  if(!exists(".Random.seed", envir = .GlobalEnv))
> 	      runif(1)		     # initialize the RNG if necessary
> 	  if(is.null(seed))
> 	      RNGstate <- .Random.seed
> 	  else {
> 	      R.seed <- .Random.seed
> 	      set.seed(seed)
> 	      RNGstate <- structure(seed, kind = as.list(RNGkind()))
> 	      on.exit(assign(".Random.seed", R.seed, envir = .GlobalEnv))
> 	  }
>
> 	  stopifnot((nsim <- as.integer(nsim[1])) > 0, is(object, "lmer"))
> 	  ## similate the linear predictors
> 	  lpred <- .Call(lme4:::mer_simulate, object, nsim)
> 	  sc <- abs(object at devComp[8])
>
> 	  ## add fixed-effects contribution and per-observation noise term
> 	  lpred <- as.data.frame(lpred + drop(object at X %*% fixef(object)) +
> 				 rnorm(prod(dim(lpred)), sd = sc))
> 	  ## save the seed
> 	  attr(lpred, "seed") <- RNGstate
> 	  lpred
>      })
>
>
> at least it fixes the problem for me.
>
>
>    WV> fit <- lmer2(count ~ weight + (1|batch),  family=poisson, data=counts)
>    WV> simulate(fit)
>    WV> # CHOLMOD error: X and/or Y have wrong dimensions
>    WV> # Error in crossprod(object at ZXyt, c(unlist(lapply(seq_along(re),
>    WV> # function(k) (t(cholL[[k]]) %*%  :
>    WV> #        Cholmod error 'X and/or Y have wrong dimensions' at
>    WV> # file:../MatrixOps/cholmod_sdmult.c, line 90
>
> I can confirm that error and I agree that it is a bug,
> well at least in the error message :-)
>
> BTW, also     summary(fit)   gives an error.
> {which is caused by  vcov(fit)  getting 0 x 0 matrix }
>
> But then,  lmer2() is in beta testing,
> so thanks a lot for your nicely reproducible example.
>
>
> Note that your data set has only one observation for some batch
> levels which may be deemed to give problems,
> but in fact that's not the problem here at all.
>
> Regards,
> Martin Maechler, ETH Zurich
>
>
>    WV> Is there a quick fix for either of these two? Otherwise, is there an
>    WV> alternative (I've checked objects produced by nlme, glmmPQL, GLMMGibbs
>    WV> with no luck)? I am using lme4 0.99875-6 version R 2.5.1 on Windows XP.
>
>    WV> Many thanks,
>
>    WV> Will
>
>    WV> =-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=
>    WV> Dr William Valdar               ++44 (0)1865 287 589
>    WV> Wellcome Trust Centre           valdar at well.ox.ac.uk
>    WV> for Human Genetics, Oxford      www.well.ox.ac.uk/~valdar
>
>

=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=
Dr William Valdar               ++44 (0)1865 287 589
Wellcome Trust Centre           valdar at well.ox.ac.uk
for Human Genetics, Oxford      www.well.ox.ac.uk/~valdar



From valdar at well.ox.ac.uk  Thu Aug  2 18:50:53 2007
From: valdar at well.ox.ac.uk (William Valdar)
Date: Thu, 2 Aug 2007 17:50:53 +0100 (BST)
Subject: [R-sig-ME] simulate() fails for poisson lmer fits
In-Reply-To: <Pine.LNX.4.64.0708021303280.12021@zeon.well.ox.ac.uk>
References: <Pine.LNX.4.64.0708011822100.8824@zeon.well.ox.ac.uk>
	<18097.47999.782177.945026@stat.math.ethz.ch>
	<Pine.LNX.4.64.0708021303280.12021@zeon.well.ox.ac.uk>
Message-ID: <Pine.LNX.4.64.0708021710330.12021@zeon.well.ox.ac.uk>


I spoke too soon. The simulate() runs but produces a real-valued response 
rather than an integral response. Here's a modification of the code you 
sent for gaussian and poisson responses:

setMethod("simulate", signature(object = "mer"),
     function(object, nsim = 1, seed = NULL, ...)
        {
     if(!exists(".Random.seed", envir = .GlobalEnv))
         runif(1)		     # initialize the RNG if necessary
     if(is.null(seed))
         RNGstate <- .Random.seed
     else {
         R.seed <- .Random.seed
         set.seed(seed)
         RNGstate <- structure(seed, kind = as.list(RNGkind()))
         on.exit(assign(".Random.seed", R.seed, envir = .GlobalEnv))
     }

     stopifnot((nsim <- as.integer(nsim[1])) > 0, is(object, "lmer"))
     ## similate the linear predictors
     lpred <- .Call(lme4:::mer_simulate, object, nsim)
     sc <- abs(object at devComp[8])

     ## add fixed-effects contribution
     lpred <- lpred + drop(object at X %*% fixef(object))
     n <- prod(dim(lpred))

     response <- NULL
     if (is.null(attr(object, "family")))
     {
          ## and per-observation noise term
          response <- as.data.frame(lpred + rnorm(n, sd = sc))
     }
     else
     {
          fam <- attr(object, "family")
          if ("poisson"==fam$family)
          {
              response <- as.data.frame(matrix(byrow = FALSE, ncol=nsim,
                      rpois(n, fam$linkinv(lpred))))
          }
          else
          {
              stop("simulate() not yet implemented for", fam$family,
                      "glmms\n")
          }
     }

     ## save the seed
     attr(response, "seed") <- RNGstate
     response
     })



On Thu, 2 Aug 2007, William Valdar wrote:
>
> That works perfectly, thanks very much!
>
> It's also considerably faster than the hack fix I wrote in the early hours of 
> this morning (included below only for interest and as a warning to others).
>
> Will
>
> ---hack---
>
> rnorm.factor <- function(g, sd=1, mean=0)
> # generate rnorm for a simple "batch" effect
> {
>    g   <- as.factor(g)[drop=TRUE]
>    x.g <- rnorm( nlevels(g), sd=sd, mean=mean )
>    return (x.g[g])
> }
>
> simulate.lmer.hack <- function(fit, nsim=1, seed=NULL, ...)
> # simulate from fitted lmer obj with simple random intercepts
> {
>    if (!is.null(seed)) set.seed(seed)
>
>    n <- length(fitted(fit))
>    fixed.linpreds <- model.matrix(attr(fit, "terms"),
>            data=attr(fit, "frame")) %*% fixef(fit)
>
>    ymat <- matrix(NA, nrow=n, ncol=nsim)
>    for (s in 1:nsim)
>    {
>        random.linpreds <- rep(0, length(n))
>        vc <- VarCorr(fit)
>        for (i in 1:length(vc))
>        {
>            random.sd   <- sqrt(vc[[i]][1])
>            random.data <- attr(fit, "flist")[[i]]
>            random.linpreds <- random.linpreds +
>                    rnorm.factor(random.data, sd=random.sd, mean=0)
>        }
>        # make canonical param
>        theta <- fixed.linpreds + random.linpreds
>        if (is.null(attr(fit, "family")))
>        {
>            scale <- attr(vc, "sc")
>            ymat[,s] <- rnorm(n, theta, scale)
>        }
>        else if ("poisson" == attr(fit, "family")$family)
>        {
>            ymat[,s] <- rpois(n, attr(fit, "family")$linkinv(theta))
>        }
>    }
>    as.data.frame(ymat)
> }
>
> counts <- data.frame(
>        count  = c(8, 3, 0, 3, 0, 9, 0, 11, 4, 7, 0, 0, 0, 4, 3, 6, 3,
>                15, 11, 9),
>        batch = c(3.1, 3.1, 3.1, 3.3, 3.3, 3.3, 3.2, 3.12, 3.8, 3.11,
>                3.4, 3.4, 3.4, 3.4, 3.5, 3.5, 3.5, 3.5, 3.6, 3.6),
>        weight = c(324.4, 372.5, 352.7, 379.6, 388.1, 431, 448.4, 377.3,
>                376.5, 358.4, 356, 351.4, 350.8, 332.1, 334.5, 392, 370.5,
>                409.7, 375, 318.5))
>
> fit.poisson <- lmer(count ~ weight + (1|batch),  family=poisson, data=counts)
> simulate.lmer.hack(fit.poisson)
>
>
> On Thu, 2 Aug 2007, Martin Maechler wrote:
>> Hi,
>>>>>>> "WV" == William Valdar <valdar at well.ox.ac.uk>
>>>>>>>     on Wed, 1 Aug 2007 18:49:58 +0100 (BST) writes:
>>
>>    WV> Hello, I wish to simulate() from a fitted Poisson
>>    WV> GLMM. Both lmer() and lmer2() from lme4 (version info at
>>    WV> the bottom) fail, apparently due to bugs.  Here's a test
>>    WV> case:
>>
>>    counts <- data.frame(
>> 	     count  = c(8, 3, 0, 3, 0, 9, 0, 11, 4, 7, 0, 0, 0, 4, 3, 6, 3,
>> 		     15, 11, 9),
>> 	     batch = c(3.1, 3.1, 3.1, 3.3, 3.3, 3.3, 3.2, 3.12, 3.8, 3.11,
>> 		     3.4, 3.4, 3.4, 3.4, 3.5, 3.5, 3.5, 3.5, 3.6, 3.6),
>> 	     weight = c(324.4, 372.5, 352.7, 379.6, 388.1, 431, 448.4, 377.3,
>> 		     376.5, 358.4, 356, 351.4, 350.8, 332.1, 334.5, 392, 
>> 370.5,
>> 		     409.7, 375, 318.5))
>>
>>    fit <- lmer(count ~ weight + (1|batch),  family=poisson, data=counts)
>> 
>> MM, that works fine, but
>>
>>    simulate(fit)
>> 
>> gives what you say:
>>
>>  WV>    # Error: inherits(object, "lmer") is not TRUE
>> 
>> and that's indeed a bug in the simulate method:
>> 
>> Using  inherits(object, "lmer")  is wrong and should be
>> replaced by  is(object, "lmer") .
>> 
>> Instead of waiting for the next version of lme4,
>> I think the following should work for you:
>> 
>> 
>> setMethod("simulate", signature(object = "mer"),
>> 	  function(object, nsim = 1, seed = NULL, ...)
>>      {
>> 	  if(!exists(".Random.seed", envir = .GlobalEnv))
>> 	      runif(1)		     # initialize the RNG if necessary
>> 	  if(is.null(seed))
>> 	      RNGstate <- .Random.seed
>> 	  else {
>> 	      R.seed <- .Random.seed
>> 	      set.seed(seed)
>> 	      RNGstate <- structure(seed, kind = as.list(RNGkind()))
>> 	      on.exit(assign(".Random.seed", R.seed, envir = .GlobalEnv))
>> 	  }
>>
>> 	  stopifnot((nsim <- as.integer(nsim[1])) > 0, is(object, "lmer"))
>> 	  ## similate the linear predictors
>> 	  lpred <- .Call(lme4:::mer_simulate, object, nsim)
>> 	  sc <- abs(object at devComp[8])
>>
>> 	  ## add fixed-effects contribution and per-observation noise term
>> 	  lpred <- as.data.frame(lpred + drop(object at X %*% fixef(object)) +
>> 				 rnorm(prod(dim(lpred)), sd = sc))
>> 	  ## save the seed
>> 	  attr(lpred, "seed") <- RNGstate
>> 	  lpred
>>      })
>> 
>> 
>> at least it fixes the problem for me.
>> 
>>
>>    WV> fit <- lmer2(count ~ weight + (1|batch),  family=poisson, 
>> data=counts)
>>    WV> simulate(fit)
>>    WV> # CHOLMOD error: X and/or Y have wrong dimensions
>>    WV> # Error in crossprod(object at ZXyt, c(unlist(lapply(seq_along(re),
>>    WV> # function(k) (t(cholL[[k]]) %*%  :
>>    WV> #        Cholmod error 'X and/or Y have wrong dimensions' at
>>    WV> # file:../MatrixOps/cholmod_sdmult.c, line 90
>> 
>> I can confirm that error and I agree that it is a bug,
>> well at least in the error message :-)
>> 
>> BTW, also     summary(fit)   gives an error.
>> {which is caused by  vcov(fit)  getting 0 x 0 matrix }
>> 
>> But then,  lmer2() is in beta testing,
>> so thanks a lot for your nicely reproducible example.
>> 
>> 
>> Note that your data set has only one observation for some batch
>> levels which may be deemed to give problems,
>> but in fact that's not the problem here at all.
>> 
>> Regards,
>> Martin Maechler, ETH Zurich
>> 
>>
>>    WV> Is there a quick fix for either of these two? Otherwise, is there an
>>    WV> alternative (I've checked objects produced by nlme, glmmPQL, 
>> GLMMGibbs
>>    WV> with no luck)? I am using lme4 0.99875-6 version R 2.5.1 on Windows 
>> XP.
>>
>>    WV> Many thanks,
>>
>>    WV> Will
>>
>>    WV> =-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=
>>    WV> Dr William Valdar               ++44 (0)1865 287 589
>>    WV> Wellcome Trust Centre           valdar at well.ox.ac.uk
>>    WV> for Human Genetics, Oxford      www.well.ox.ac.uk/~valdar
>> 
>> 
>
> =-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=
> Dr William Valdar               ++44 (0)1865 287 589
> Wellcome Trust Centre           valdar at well.ox.ac.uk
> for Human Genetics, Oxford      www.well.ox.ac.uk/~valdar
>
>

=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=
Dr William Valdar               ++44 (0)1865 287 589
Wellcome Trust Centre           valdar at well.ox.ac.uk
for Human Genetics, Oxford      www.well.ox.ac.uk/~valdar



From lamprianou at yahoo.com  Fri Aug  3 09:46:23 2007
From: lamprianou at yahoo.com (Iasonas Lamprianou)
Date: Fri, 3 Aug 2007 00:46:23 -0700 (PDT)
Subject: [R-sig-ME] R questions
Message-ID: <562209.79789.qm@web54102.mail.re2.yahoo.com>

Dear friends, 

in this web page http://cran.r-project.org/src/contrib/Views/Psychometrics.html, I read: A multilevel Rasch model can be estimated using the package lme4 with functions for mixed-effects models with crossed or partially crossed random effects. How can this be done? Is there an example to read?

Also, why are the random effects (BLUPS  usinf the ranef fucnction) and the fixed effects estimates the same most pf the time?

Thanks

jason
 
Dr. Iasonas Lamprianou
Department of Education
The University of Manchester
Oxford Road, Manchester M13 9PL, UK
Tel. 0044 161 275 3485
iasonas.lamprianou at manchester.ac.uk


----- Original Message ----
From: "r-sig-mixed-models-request at r-project.org" <r-sig-mixed-models-request at r-project.org>
To: r-sig-mixed-models at r-project.org
Sent: Thursday, 2 August, 2007 1:00:22 PM
Subject: R-sig-mixed-models Digest, Vol 8, Issue 1


Send R-sig-mixed-models mailing list submissions to
    r-sig-mixed-models at r-project.org

To subscribe or unsubscribe via the World Wide Web, visit
    https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
or, via email, send a message with subject or body 'help' to
    r-sig-mixed-models-request at r-project.org

You can reach the person managing the list at
    r-sig-mixed-models-owner at r-project.org

When replying, please edit your Subject line so it is more specific
than "Re: Contents of R-sig-mixed-models digest..."


Today's Topics:

   1. simulate() fails for poisson lmer fits (William Valdar)
   2. Re: simulate() fails for poisson lmer fits (William Valdar)


----------------------------------------------------------------------

Message: 1
Date: Wed, 1 Aug 2007 18:49:58 +0100 (BST)
From: William Valdar <valdar at well.ox.ac.uk>
Subject: [R-sig-ME] simulate() fails for poisson lmer fits
To: R-SIG-Mixed-Models <r-sig-mixed-models at r-project.org>
Message-ID: <Pine.LNX.4.64.0708011822100.8824 at zeon.well.ox.ac.uk>
Content-Type: TEXT/PLAIN; charset=US-ASCII; format=flowed

Hello,

I wish to simulate() from a fitted Poisson GLMM. Both lmer() and lmer2() 
from lme4 (version info at the bottom) fail, apparently due to bugs. 
Here's a test case:

counts <- data.frame(
         count  = c(8, 3, 0, 3, 0, 9, 0, 11, 4, 7, 0, 0, 0, 4, 3, 6, 3,
                 15, 11, 9),
         batch = c(3.1, 3.1, 3.1, 3.3, 3.3, 3.3, 3.2, 3.12, 3.8, 3.11,
                 3.4, 3.4, 3.4, 3.4, 3.5, 3.5, 3.5, 3.5, 3.6, 3.6),
         weight = c(324.4, 372.5, 352.7, 379.6, 388.1, 431, 448.4, 377.3,
                 376.5, 358.4, 356, 351.4, 350.8, 332.1, 334.5, 392, 370.5,
                 409.7, 375, 318.5))

fit <- lmer(count ~ weight + (1|batch),  family=poisson, data=counts)
# Error: inherits(object, "lmer") is not TRUE

fit <- lmer2(count ~ weight + (1|batch),  family=poisson, data=counts)
simulate(fit)
# CHOLMOD error: X and/or Y have wrong dimensions
# Error in crossprod(object at ZXyt, c(unlist(lapply(seq_along(re), 
# function(k) (t(cholL[[k]]) %*%  :
#        Cholmod error 'X and/or Y have wrong dimensions' at 
# file:../MatrixOps/cholmod_sdmult.c, line 90

Is there a quick fix for either of these two? Otherwise, is there an 
alternative (I've checked objects produced by nlme, glmmPQL, GLMMGibbs 
with no luck)? I am using lme4 0.99875-6 version R 2.5.1 on Windows XP.

Many thanks,

Will

=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=
Dr William Valdar               ++44 (0)1865 287 589
Wellcome Trust Centre           valdar at well.ox.ac.uk
for Human Genetics, Oxford      www.well.ox.ac.uk/~valdar



------------------------------

Message: 2
Date: Thu, 2 Aug 2007 00:23:07 +0100 (BST)
From: William Valdar <valdar at well.ox.ac.uk>
Subject: Re: [R-sig-ME] simulate() fails for poisson lmer fits
To: R-SIG-Mixed-Models <r-sig-mixed-models at r-project.org>
Message-ID: <Pine.LNX.4.64.0708020021210.7087 at zeon.well.ox.ac.uk>
Content-Type: TEXT/PLAIN; charset=US-ASCII; format=flowed


I missed out a line in the code below. The line that throws the error is 
not the fitting but the subsequent simulation, ie:

fit <- lmer(count ~ weight + (1|batch),  family=poisson, data=counts)
simulate(fit)
# Error: inherits(object, "lmer") is not TRUE


On Wed, 1 Aug 2007, William Valdar wrote:
> Hello,
>
> I wish to simulate() from a fitted Poisson GLMM. Both lmer() and lmer2() from 
> lme4 (version info at the bottom) fail, apparently due to bugs. Here's a test 
> case:
>
> counts <- data.frame(
>        count  = c(8, 3, 0, 3, 0, 9, 0, 11, 4, 7, 0, 0, 0, 4, 3, 6, 3,
>                15, 11, 9),
>        batch = c(3.1, 3.1, 3.1, 3.3, 3.3, 3.3, 3.2, 3.12, 3.8, 3.11,
>                3.4, 3.4, 3.4, 3.4, 3.5, 3.5, 3.5, 3.5, 3.6, 3.6),
>        weight = c(324.4, 372.5, 352.7, 379.6, 388.1, 431, 448.4, 377.3,
>                376.5, 358.4, 356, 351.4, 350.8, 332.1, 334.5, 392, 370.5,
>                409.7, 375, 318.5))
>
> fit <- lmer(count ~ weight + (1|batch),  family=poisson, data=counts)
> # Error: inherits(object, "lmer") is not TRUE
>
> fit <- lmer2(count ~ weight + (1|batch),  family=poisson, data=counts)
> simulate(fit)
> # CHOLMOD error: X and/or Y have wrong dimensions
> # Error in crossprod(object at ZXyt, c(unlist(lapply(seq_along(re), # 
> function(k) (t(cholL[[k]]) %*%  :
> #        Cholmod error 'X and/or Y have wrong dimensions' at # 
> file:../MatrixOps/cholmod_sdmult.c, line 90
>
> Is there a quick fix for either of these two? Otherwise, is there an 
> alternative (I've checked objects produced by nlme, glmmPQL, GLMMGibbs with 
> no luck)? I am using lme4 0.99875-6 version R 2.5.1 on Windows XP.
>
> Many thanks,
>
> Will
>
> =-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=
> Dr William Valdar               ++44 (0)1865 287 589
> Wellcome Trust Centre           valdar at well.ox.ac.uk
> for Human Genetics, Oxford      www.well.ox.ac.uk/~valdar
>
>

=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=
Dr William Valdar               ++44 (0)1865 287 589
Wellcome Trust Centre           valdar at well.ox.ac.uk
for Human Genetics, Oxford      www.well.ox.ac.uk/~valdar



------------------------------

_______________________________________________
R-sig-mixed-models mailing list
R-sig-mixed-models at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


End of R-sig-mixed-models Digest, Vol 8, Issue 1
************************************************


      ___________________________________________________________



From gavin.simpson at ucl.ac.uk  Fri Aug  3 11:27:29 2007
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Fri, 03 Aug 2007 10:27:29 +0100
Subject: [R-sig-ME] R questions
In-Reply-To: <562209.79789.qm@web54102.mail.re2.yahoo.com>
References: <562209.79789.qm@web54102.mail.re2.yahoo.com>
Message-ID: <1186133249.30885.6.camel@gsimpson.geog.ucl.ac.uk>

On Fri, 2007-08-03 at 00:46 -0700, Iasonas Lamprianou wrote:
> Dear friends, 
> 
> in this web page
> http://cran.r-project.org/src/contrib/Views/Psychometrics.html, I
> read: A multilevel Rasch model can be estimated using the package lme4
> with functions for mixed-effects models with crossed or partially
> crossed random effects. How can this be done? Is there an example to
> read?

You might take a look at Doran et al (2006; Vol 20 issue 2 of the
Journal Of Statistical Software - link below), which discusses Rasch
models with lme4.

http://www.jstatsoft.org/index.php?vol=20

HTH

G

> 
> Also, why are the random effects (BLUPS  usinf the ranef fucnction)
> and the fixed effects estimates the same most pf the time?
> 
> Thanks
> 
> jason
>  
> Dr. Iasonas Lamprianou
> Department of Education
> The University of Manchester
> Oxford Road, Manchester M13 9PL, UK
> Tel. 0044 161 275 3485
> iasonas.lamprianou at manchester.ac.uk

<snip />
-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
 Gavin Simpson                 [t] +44 (0)20 7679 0522
 ECRC, UCL Geography,          [f] +44 (0)20 7679 0565
 Pearson Building,             [e] gavin.simpsonATNOSPAMucl.ac.uk
 Gower Street, London          [w] http://www.ucl.ac.uk/~ucfagls/
 UK. WC1E 6BT.                 [w] http://www.freshwaters.org.uk
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%



From john.maindonald at anu.edu.au  Fri Aug  3 14:11:45 2007
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Fri, 3 Aug 2007 22:11:45 +1000
Subject: [R-sig-ME] R questions
In-Reply-To: <562209.79789.qm@web54102.mail.re2.yahoo.com>
References: <562209.79789.qm@web54102.mail.re2.yahoo.com>
Message-ID: <A13FFF83-963F-425E-B004-771E0715F16F@anu.edu.au>

Whether or not the BLUPs are very similar to the means depends
on the relative magnitudes of the relevant components of variance.
Try the following code (from p.309 of the 2nd edn of my book with
John Braun):

ant111b.lmer <- lmer(harvwt ~ 1 + (1 | site), data=ant111b)
options(digits=4)

ant111b.lmer

##           Fitted values and residuals in \texttt{lmer()}
s2W <- 0.578; s2L <- 2.37; n <- 4
sitemeans <- with(ant111b, sapply(split(harvwt, site), mean))
grandmean <- mean(sitemeans)
shrinkage <- (n*s2L)/(n*s2L+s2W)
grandmean + shrinkage*(sitemeans - grandmean)
##
## More directly, use fitted() with the lmer object
unique(fitted(ant111b.lmer))
##
## Compare with site means
sitemeans


John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.


On 3 Aug 2007, at 5:46 PM, Iasonas Lamprianou wrote:

> Dear friends,
>
> in this web page http://cran.r-project.org/src/contrib/Views/ 
> Psychometrics.html, I read: A multilevel Rasch model can be  
> estimated using the package lme4 with functions for mixed-effects  
> models with crossed or partially crossed random effects. How can  
> this be done? Is there an example to read?
>
> Also, why are the random effects (BLUPS  usinf the ranef fucnction)  
> and the fixed effects estimates the same most pf the time?
>
> Thanks
>
> jason
>
> Dr. Iasonas Lamprianou
> Department of Education
> The University of Manchester
> Oxford Road, Manchester M13 9PL, UK
> Tel. 0044 161 275 3485
> iasonas.lamprianou at manchester.ac.uk
>
>
> ----- Original Message ----
> From: "r-sig-mixed-models-request at r-project.org" <r-sig-mixed- 
> models-request at r-project.org>
> To: r-sig-mixed-models at r-project.org
> Sent: Thursday, 2 August, 2007 1:00:22 PM
> Subject: R-sig-mixed-models Digest, Vol 8, Issue 1
>
>
> Send R-sig-mixed-models mailing list submissions to
>     r-sig-mixed-models at r-project.org
>
> To subscribe or unsubscribe via the World Wide Web, visit
>     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> or, via email, send a message with subject or body 'help' to
>     r-sig-mixed-models-request at r-project.org
>
> You can reach the person managing the list at
>     r-sig-mixed-models-owner at r-project.org
>
> When replying, please edit your Subject line so it is more specific
> than "Re: Contents of R-sig-mixed-models digest..."
>
>
> Today's Topics:
>
>    1. simulate() fails for poisson lmer fits (William Valdar)
>    2. Re: simulate() fails for poisson lmer fits (William Valdar)
>
>
> ----------------------------------------------------------------------
>
> Message: 1
> Date: Wed, 1 Aug 2007 18:49:58 +0100 (BST)
> From: William Valdar <valdar at well.ox.ac.uk>
> Subject: [R-sig-ME] simulate() fails for poisson lmer fits
> To: R-SIG-Mixed-Models <r-sig-mixed-models at r-project.org>
> Message-ID: <Pine.LNX.4.64.0708011822100.8824 at zeon.well.ox.ac.uk>
> Content-Type: TEXT/PLAIN; charset=US-ASCII; format=flowed
>
> Hello,
>
> I wish to simulate() from a fitted Poisson GLMM. Both lmer() and  
> lmer2()
> from lme4 (version info at the bottom) fail, apparently due to bugs.
> Here's a test case:
>
> counts <- data.frame(
>          count  = c(8, 3, 0, 3, 0, 9, 0, 11, 4, 7, 0, 0, 0, 4, 3,  
> 6, 3,
>                  15, 11, 9),
>          batch = c(3.1, 3.1, 3.1, 3.3, 3.3, 3.3, 3.2, 3.12, 3.8, 3.11,
>                  3.4, 3.4, 3.4, 3.4, 3.5, 3.5, 3.5, 3.5, 3.6, 3.6),
>          weight = c(324.4, 372.5, 352.7, 379.6, 388.1, 431, 448.4,  
> 377.3,
>                  376.5, 358.4, 356, 351.4, 350.8, 332.1, 334.5,  
> 392, 370.5,
>                  409.7, 375, 318.5))
>
> fit <- lmer(count ~ weight + (1|batch),  family=poisson, data=counts)
> # Error: inherits(object, "lmer") is not TRUE
>
> fit <- lmer2(count ~ weight + (1|batch),  family=poisson, data=counts)
> simulate(fit)
> # CHOLMOD error: X and/or Y have wrong dimensions
> # Error in crossprod(object at ZXyt, c(unlist(lapply(seq_along(re),
> # function(k) (t(cholL[[k]]) %*%  :
> #        Cholmod error 'X and/or Y have wrong dimensions' at
> # file:../MatrixOps/cholmod_sdmult.c, line 90
>
> Is there a quick fix for either of these two? Otherwise, is there an
> alternative (I've checked objects produced by nlme, glmmPQL, GLMMGibbs
> with no luck)? I am using lme4 0.99875-6 version R 2.5.1 on Windows  
> XP.
>
> Many thanks,
>
> Will
>
> =-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=
> Dr William Valdar               ++44 (0)1865 287 589
> Wellcome Trust Centre           valdar at well.ox.ac.uk
> for Human Genetics, Oxford      www.well.ox.ac.uk/~valdar
>
>
>
> ------------------------------
>
> Message: 2
> Date: Thu, 2 Aug 2007 00:23:07 +0100 (BST)
> From: William Valdar <valdar at well.ox.ac.uk>
> Subject: Re: [R-sig-ME] simulate() fails for poisson lmer fits
> To: R-SIG-Mixed-Models <r-sig-mixed-models at r-project.org>
> Message-ID: <Pine.LNX.4.64.0708020021210.7087 at zeon.well.ox.ac.uk>
> Content-Type: TEXT/PLAIN; charset=US-ASCII; format=flowed
>
>
> I missed out a line in the code below. The line that throws the  
> error is
> not the fitting but the subsequent simulation, ie:
>
> fit <- lmer(count ~ weight + (1|batch),  family=poisson, data=counts)
> simulate(fit)
> # Error: inherits(object, "lmer") is not TRUE
>
>
> On Wed, 1 Aug 2007, William Valdar wrote:
>> Hello,
>>
>> I wish to simulate() from a fitted Poisson GLMM. Both lmer() and  
>> lmer2() from
>> lme4 (version info at the bottom) fail, apparently due to bugs.  
>> Here's a test
>> case:
>>
>> counts <- data.frame(
>>        count  = c(8, 3, 0, 3, 0, 9, 0, 11, 4, 7, 0, 0, 0, 4, 3, 6, 3,
>>                15, 11, 9),
>>        batch = c(3.1, 3.1, 3.1, 3.3, 3.3, 3.3, 3.2, 3.12, 3.8, 3.11,
>>                3.4, 3.4, 3.4, 3.4, 3.5, 3.5, 3.5, 3.5, 3.6, 3.6),
>>        weight = c(324.4, 372.5, 352.7, 379.6, 388.1, 431, 448.4,  
>> 377.3,
>>                376.5, 358.4, 356, 351.4, 350.8, 332.1, 334.5, 392,  
>> 370.5,
>>                409.7, 375, 318.5))
>>
>> fit <- lmer(count ~ weight + (1|batch),  family=poisson, data=counts)
>> # Error: inherits(object, "lmer") is not TRUE
>>
>> fit <- lmer2(count ~ weight + (1|batch),  family=poisson,  
>> data=counts)
>> simulate(fit)
>> # CHOLMOD error: X and/or Y have wrong dimensions
>> # Error in crossprod(object at ZXyt, c(unlist(lapply(seq_along(re), #
>> function(k) (t(cholL[[k]]) %*%  :
>> #        Cholmod error 'X and/or Y have wrong dimensions' at #
>> file:../MatrixOps/cholmod_sdmult.c, line 90
>>
>> Is there a quick fix for either of these two? Otherwise, is there an
>> alternative (I've checked objects produced by nlme, glmmPQL,  
>> GLMMGibbs with
>> no luck)? I am using lme4 0.99875-6 version R 2.5.1 on Windows XP.
>>
>> Many thanks,
>>
>> Will
>>
>> =-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=
>> Dr William Valdar               ++44 (0)1865 287 589
>> Wellcome Trust Centre           valdar at well.ox.ac.uk
>> for Human Genetics, Oxford      www.well.ox.ac.uk/~valdar
>>
>>
>
> =-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=
> Dr William Valdar               ++44 (0)1865 287 589
> Wellcome Trust Centre           valdar at well.ox.ac.uk
> for Human Genetics, Oxford      www.well.ox.ac.uk/~valdar
>
>
>
> ------------------------------
>
> _______________________________________________
> R-sig-mixed-models mailing list
> R-sig-mixed-models at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
> End of R-sig-mixed-models Digest, Vol 8, Issue 1
> ************************************************
>
>
>       ___________________________________________________________
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From m.gardiner-garden at garvan.org.au  Thu Aug  9 05:32:57 2007
From: m.gardiner-garden at garvan.org.au (Margaret Gardiner-Garden)
Date: Thu, 9 Aug 2007 13:32:57 +1000
Subject: [R-sig-ME] residual plots for lmer
Message-ID: <000b01c7da35$faddcbf0$0ce15e81@dg3qn71s>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20070809/52002de2/attachment.pl>

From nikko at hailmail.net  Fri Aug 10 20:10:17 2007
From: nikko at hailmail.net (Nicholas Lewin-Koh)
Date: Fri, 10 Aug 2007 14:10:17 -0400
Subject: [R-sig-ME] Independent curves with common variance parameter
Message-ID: <1186769417.16010.1204779289@webmail.messagingengine.com>

Hi,
There is hopefully a simple answer to this that I am not seeing. I would
like to fit the models:
y_ij = f(x_ij,B_i) + g{f(x_ij,B_i), v_i}e_ij       (1)
and
y_ij = f(x_ij,B_i) + g{f(x_ij,B_i), v_pooled}e_ij  (2)

where v=(sigma,d), and I would like to test for a common variance
parameter. 
If I am understanding correctly
than the following code will get me model (2) with a pooled variance
parameter?

tt<-groupedData(response~conc|curve,assay.data)
bb<-nlsList(response~SSllogis(conc,A,B,xmid,scal),tt,start=start[[1]])
bb2<-nlme(bb,weights=varPower(), random=list(A~1,B~1,xmid~1,scal~1))

And then to get model (1) I would have to define a gnlsList structure
and fit each curve. How would I go about fitting a model with
v={sigma_pooled, dij} ? is this possible in the nlme framework?
Any suggestions appreciated, and I can provide the data I am
using if requested, it is published.

Nicholas



From j.hadfield at ed.ac.uk  Sun Aug 12 14:03:08 2007
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Sun, 12 Aug 2007 13:03:08 +0100
Subject: [R-sig-ME] Bug in mcmcsamp
Message-ID: <1D4C0CEE-43B7-481C-9C64-D86292706BE3@ed.ac.uk>

Hi,

I'm using lme4 0.99875-6 and I think there may be a bug in mcmcsamp.   
When I fit 2 random effects, the posterior variances always seem to  
be approximately the same irrespective of the true variances (or the  
REML estimates of the true variances).  For example:

    A<-gl(100,10)
    B<-gl(100,1,1000)
    y<-rnorm(100,0,sqrt(1))[A]+rnorm(100,0,sqrt(3))[B]+rnorm 
(1000,0,sqrt(3))
    model1<-lmer(y~(1|A)+(1|B))
    model1MCMC<-mcmcsamp(model1,n=5000,trans=FALSE)
    plot(model1MCMC)

Sorry, if its my mistake.

Jarrod



From bates at stat.wisc.edu  Sun Aug 12 16:06:31 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Sun, 12 Aug 2007 09:06:31 -0500
Subject: [R-sig-ME] Bug in mcmcsamp
In-Reply-To: <1D4C0CEE-43B7-481C-9C64-D86292706BE3@ed.ac.uk>
References: <1D4C0CEE-43B7-481C-9C64-D86292706BE3@ed.ac.uk>
Message-ID: <40e66e0b0708120706j5b83742dlbd7ee5b1a8eaa9a0@mail.gmail.com>

On 8/12/07, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:
> Hi,

> I'm using lme4 0.99875-6 and I think there may be a bug in mcmcsamp.
> When I fit 2 random effects, the posterior variances always seem to
> be approximately the same irrespective of the true variances (or the
> REML estimates of the true variances).  For example:

>     A<-gl(100,10)
>     B<-gl(100,1,1000)
>     y<-rnorm(100,0,sqrt(1))[A]+rnorm(100,0,sqrt(3))[B]+rnorm
> (1000,0,sqrt(3))
>     model1<-lmer(y~(1|A)+(1|B))
>     model1MCMC<-mcmcsamp(model1,n=5000,trans=FALSE)
>     plot(model1MCMC)

Thanks for reporting the problem, Jarrod.  I tried your script with
the development version of lme4 and got the expected results, which I
enclose Could you try the mcmcsamp.R script in lme4 0.99875-6 and tell
me if the results are similar?
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Hadfield.pdf
Type: application/pdf
Size: 338640 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20070812/dd518120/attachment.pdf>
-------------- next part --------------
## bug report by Jarrod Hadfield (2007-08-12)
library(lme4)
library(coda)
set.seed(1)
A<-gl(100,10)
B<-gl(100,1,1000)
y<-rnorm(100,0,sqrt(1))[A]+rnorm(100,0,sqrt(3))[B]+rnorm(1000,0,sqrt(3))
model1<-lmer(y~(1|A)+(1|B))
model1MCMC<-mcmcsamp(model1,n=5000,trans=FALSE)
head(as.data.frame(model1MCMC), n = 20)
HPDinterval(model1MCMC)
pdf(file = "Hadfield.pdf", height = 8, width = 6)
xyplot(model1MCMC, strip = FALSE, strip.left = TRUE,
       scales = list(x=list(axs='i')), type = c("g", "l"))
densityplot(model1MCMC, plot.points = FALSE)
dev.off()

From j.hadfield at ed.ac.uk  Sun Aug 12 16:31:12 2007
From: j.hadfield at ed.ac.uk (Jarrod Hadfield)
Date: Sun, 12 Aug 2007 15:31:12 +0100
Subject: [R-sig-ME] Bug in mcmcsamp
In-Reply-To: <40e66e0b0708120706j5b83742dlbd7ee5b1a8eaa9a0@mail.gmail.com>
References: <1D4C0CEE-43B7-481C-9C64-D86292706BE3@ed.ac.uk>
	<40e66e0b0708120706j5b83742dlbd7ee5b1a8eaa9a0@mail.gmail.com>
Message-ID: <9DD78394-C91C-451A-9681-A582B9E67D70@ed.ac.uk>

Hi,

With version 0.99875-6 I get the posterior variances for A and B both  
coming out with a mode around 1.5 (See Hadfield2.pdf)

Cheers,

Jarrod

-------------- next part --------------
A non-text attachment was scrubbed...
Name: Hadfield2.pdf
Type: application/pdf
Size: 337185 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20070812/c24ca3f5/attachment.pdf>
-------------- next part --------------


On 12 Aug 2007, at 15:06, Douglas Bates wrote:

> On 8/12/07, Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:
>> Hi,
>
>> I'm using lme4 0.99875-6 and I think there may be a bug in mcmcsamp.
>> When I fit 2 random effects, the posterior variances always seem to
>> be approximately the same irrespective of the true variances (or the
>> REML estimates of the true variances).  For example:
>
>>     A<-gl(100,10)
>>     B<-gl(100,1,1000)
>>     y<-rnorm(100,0,sqrt(1))[A]+rnorm(100,0,sqrt(3))[B]+rnorm
>> (1000,0,sqrt(3))
>>     model1<-lmer(y~(1|A)+(1|B))
>>     model1MCMC<-mcmcsamp(model1,n=5000,trans=FALSE)
>>     plot(model1MCMC)
>
> Thanks for reporting the problem, Jarrod.  I tried your script with
> the development version of lme4 and got the expected results, which I
> enclose Could you try the mcmcsamp.R script in lme4 0.99875-6 and tell
> me if the results are similar?
> <Hadfield.pdf>
> <mcmcsamp.R>
> <mcmcsamp.Rout>


From shravan.vasishth at gmail.com  Mon Aug 13 14:17:44 2007
From: shravan.vasishth at gmail.com (Shravan Vasishth)
Date: Mon, 13 Aug 2007 14:17:44 +0200
Subject: [R-sig-ME] showCorrelation does not work in lmer
Message-ID: <8b1813aa0708130517k3126794dt6982ca66021ecb30@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20070813/a39496f4/attachment.pl>

From bates at stat.wisc.edu  Mon Aug 13 16:20:15 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 13 Aug 2007 09:20:15 -0500
Subject: [R-sig-ME] showCorrelation does not work in lmer
In-Reply-To: <8b1813aa0708130517k3126794dt6982ca66021ecb30@mail.gmail.com>
References: <8b1813aa0708130517k3126794dt6982ca66021ecb30@mail.gmail.com>
Message-ID: <40e66e0b0708130720u450a06bva7ad9921b826d060@mail.gmail.com>

You should be able to suppress the correlations by explicitly calling
print with the argument corr = FALSE

On 8/13/07, Shravan Vasishth <shravan.vasishth at gmail.com> wrote:
> Hi all,
>
> as far as I understand it,
>
> summary(lmer.fit,showCorrelation=FALSE)
>
> should not show the correlations of the fixed effects, but at least in my
> setup it does not; correlations are displayed even with the above setting.
> I'm using R 2.4.1 and an older version of lme4 (0.9975-11, dated
> 2007-1-25)), running on a Mac OS X machine (intel).
>
> Thanks,
>
> --
> Shravan Vasishth,    Empirical Methods in Syntax
> Juniorprofessor, Institute for Linguistics, Potsdam
> Tel: +49-(0)331-977-2016, -2457  Fax: -2087
> http://www.ling.uni-potsdam.de/~vasishth
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From sarah at stats.gla.ac.uk  Tue Aug 14 11:40:26 2007
From: sarah at stats.gla.ac.uk (Sarah Barry)
Date: Tue, 14 Aug 2007 10:40:26 +0100
Subject: [R-sig-ME] Zero estimated random effects
Message-ID: <46C1788A.7000405@stats.gla.ac.uk>

Hi,

I have longitudinal facial shape data on two treatment groups, which I 
break down into individual coordinates and fit linear mixed effects 
models to each of the pairwise combinations of these coordinates (and 
subsequently aggregate the results).  I would like to fit a random 
intercept with a different variance for each of the two coordinates 
within any model, along with various fixed effects (for coordinate r=1,2 
measured on individual i at time t):

y_{ir}(t) = \beta_{0r} + b_{ir} + \beta_{1r} group_i + \beta_{2r} t + 
\beta_{3r} group_i : t + \epsilon_{ir}(t), 

where \epsilon_{ir}(t) ~ N(0, \sigma^2) and the random effect b_{ir} ~ 
N(0, \sigma_r^2).

The problem is that for a small selection of coordinate pairs, the 
responses for one coordinate are much more variable for the other and 
when I try to fit the model using lmer2, it estimates all the random 
effects for the coordinate with less variation as zero.  This results in 
the variance of that random effect also being estimated as zero.  This 
doesn't seem to happen with lme, even though the variance is still 
estimated as very small.  Using lmer, a warning is given and the 
variance is estimated as very small, although still not exactly zero. 

I don't think it's unreasonable to estimate a different random effects 
variance for each coordinate, especially since the variation is clearly 
so different.  But am I overparameterising, is my syntax wrong or is 
there a problem with lmer2?  I enclose a reproducible example below, 
including code for a plot of the responses.

set.seed(100)
n.subj <- 200
n.times <- 3
n.coords <- 2
simdata <- data.frame(coord1=c(rep(1,n.subj*n.times), 
rep(0,n.subj*n.times)))
simdata$coord2 <- c(rep(0,n.subj*n.times), rep(1,n.subj*n.times))
simdata$coord <- ifelse(simdata$coord1==1, 1, 2)
simdata$ID <- rep(1:n.subj, each=n.times*n.coords)
simdata$time <- rep(1:n.times, n.subj*n.coords)
simdata$group <- rep(c(1,0,1,0), each=n.subj*n.times/2)
simdata$y <- rep(NA, dim(simdata)[1])
for (i in 1:dim(simdata)[1]) simdata$y[i] <- rnorm(1, 
simdata$group[i]*(simdata$coord[i]-1)*40+simdata$time[i], 
1+simdata$coord[i]*10)
plot(simdata$y[simdata$coord==1 & simdata$group==0], 
simdata$y[simdata$coord==2 & simdata$group==0], xlim=range(simdata$y), 
ylim=range(simdata$y), pch=20, xlab="Coordinate 1", ylab="Coordinate 2")
points(simdata$y[simdata$coord==1 & simdata$group==1], 
simdata$y[simdata$coord==2 & simdata$group==1], pch=20, col="red")

require(lme4)
lmer2(y~-1+coord1+coord2+coord1:(time+group+time:group)+coord2:(time+group+time:group) 
+ (0+coord1|ID)+(0+coord2|ID), data=simdata)
lmer(y~-1+coord1+coord2+coord1:(time+group+time:group)+coord2:(time+group+time:group) 
+ (0+coord1|ID)+(0+coord2|ID), data=simdata)
require(nlme)
summary(lme(y~-1+coord1+coord2+coord1:(time+group+time:group)+coord2:(time+group+time:group), 
random=list(ID=pdDiag(~-1+coord1+coord2)), data=simdata))

Thanks in advance for any help.

Regards,
Sarah

-- 
Sarah Barry, MSc
PhD student
Department of Statistics
University of Glasgow
Tel: +44 (0)141 330 2474
Fax: +44 (0)141 330 4814
www.stats.gla.ac.uk/~sarah



From farewelld at cf.ac.uk  Tue Aug 14 18:39:02 2007
From: farewelld at cf.ac.uk (Daniel Farewell)
Date: Tue, 14 Aug 2007 16:39:02 +0000 (GMT)
Subject: [R-sig-ME] lmer, intercepts and offsets
Message-ID: <523651.84987.qm@web27101.mail.ukl.yahoo.com>

This is a follow-up to a thread from back in March ("lmer, intercepts and offsets"). I'm hoping (at least) to better understand how lmer works.

I'd like to "trick" lmer into thinking it has converged to certain parameter estimates. This is straightforward for variance components, making use of the 'start' parameter and using 'control' to set the number of the various kinds of iteration to zero.

My ultimate goal is to extract posterior second moments from a model "fit" where I have specified both the variance components and the fixed effects.

Obviously it is possible to dig inside the fitted model and manually alter the fixed effects, but this has no impact on the result of a call to ranef, presumably because the posterior means (and variances?) have already been calculated, and are sitting in the ranef slot of the fitted model.

My question is this: at what stage do the random effects get calculated? Simplifying greatly, at some stage lmer must calculate betahat(Omega) (the fixed effects) and ranef(Omega) (the estimated random effects) for the converged value of Omega. Does ranef(Omega) depend on the result of betahat(Omega)? If so, then presumably tinkering with the betahat(Omega) results at the appropriate point inside lmer would result in what I want. If not (that is, if the dependence on the fixed effects is indirect) what needs tinkering with?

Is there a good reason why lmer does not allow models with no fixed effects at all? With the right offset, this would be another way to achieve the same result.

I hope the above makes sense. Thanks in advance for any advice you can offer!

Daniel Farewell



From lunina at access.unizh.ch  Thu Aug 16 16:36:46 2007
From: lunina at access.unizh.ch (lunina at access.unizh.ch)
Date: Thu, 16 Aug 2007 16:36:46 +0200
Subject: [R-sig-ME] Boxplot for lmer
Message-ID: <web-9540342@idmailbe1b.unizh.ch>


Dear Members

I'm computing a lmer-model.I wanted to check if a heteroscedastic model 
would fit better, but had to find out, that the "weights"-argument in lmer 
don't work yet. In the archiv I found that lmer2 doesn't have this problem 
and therefore I computed my heteroscedastic model with lmer2. But now I want 
to draw a boxplot, to check how mutch better the heteroscedastic model is. 
Somehow, no one of the functions/slots "residuals()" or "fitted" works. How 
could I get them out of my lmer2- model?

Thanks a lot



From kalle.eerikainen at metla.fi  Fri Aug 17 10:52:23 2007
From: kalle.eerikainen at metla.fi (=?ISO-8859-1?Q?Kalle_Eerik=E4inen?=)
Date: Fri, 17 Aug 2007 11:52:23 +0300
Subject: [R-sig-ME] lme4/nlmer problem
Message-ID: <46C561C7.3010008@metla.fi>

Hello,

I have done some test estimations using the lme4 package of R. The 
estimation of the parameters of linear mixed-effect models using the 
'lmer' goes well. For instance, a very simple single-level mixed model 
"Naslund_lmer1  <- lmer(y ~ d13 + (1 |stand), data = height1)" for the 
relationship between the tree height (or its transformation) and 
diameter comes out perfectly.

However, if I attempt to estimate nonlinear mixed-effect models, I 
always receive an error message that tells me: "Error: 
length(start$fixed) is not TRUE". This is also the case with the 
following model:

Schumacher_nlmer1 <- lme4:::nlmer(ht   ~ exp(p0 + p1*1/d13)+u0 ~ 
(u0|stand) , fixed=p0+p1~1, data = height1, start = c(p0 = 0.1, p1 = 
-9.0), verb = 1)

It is obvious that there exists a trivial bug/mistake in my code, but I 
cannot see what is wrong with it. Could someone give me a helping hand 
with my 'nlmer problem'?

Regards,

Kalle Eerik?inen

From markus.jantti at iki.fi  Fri Aug 17 11:37:31 2007
From: markus.jantti at iki.fi (=?ISO-8859-1?Q?Markus_J=E4ntti?=)
Date: Fri, 17 Aug 2007 12:37:31 +0300
Subject: [R-sig-ME] lme4/nlmer problem
In-Reply-To: <46C561C7.3010008@metla.fi>
References: <46C561C7.3010008@metla.fi>
Message-ID: <46C56C5B.7090305@iki.fi>

Kalle Eerik?inen wrote:
> Hello,
> 
> I have done some test estimations using the lme4 package of R. The 
> estimation of the parameters of linear mixed-effect models using the 
> 'lmer' goes well. For instance, a very simple single-level mixed model 
> "Naslund_lmer1  <- lmer(y ~ d13 + (1 |stand), data = height1)" for the 
> relationship between the tree height (or its transformation) and 
> diameter comes out perfectly.
> 
> However, if I attempt to estimate nonlinear mixed-effect models, I 
> always receive an error message that tells me: "Error: 
> length(start$fixed) is not TRUE". This is also the case with the 
> following model:
> 
> Schumacher_nlmer1 <- lme4:::nlmer(ht   ~ exp(p0 + p1*1/d13)+u0 ~ 
> (u0|stand) , fixed=p0+p1~1, data = height1, start = c(p0 = 0.1, p1 = 
> -9.0), verb = 1)

What is the purpose of the argument "fixed=p0+p1~1"? The help page makes no 
mention of it. Maybe this is what is generating the error message.

markus
> 


> It is obvious that there exists a trivial bug/mistake in my code, but I 
> cannot see what is wrong with it. Could someone give me a helping hand 
> with my 'nlmer problem'?
> 
> Regards,
> 
> Kalle Eerik?inen
> 
> 
> ------------------------------------------------------------------------
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
Markus Jantti
Abo Akademi University
markus.jantti at iki.fi
http://www.iki.fi/~mjantti



From kalle.eerikainen at metla.fi  Fri Aug 17 12:50:49 2007
From: kalle.eerikainen at metla.fi (=?ISO-8859-1?Q?Kalle_Eerik=E4inen?=)
Date: Fri, 17 Aug 2007 13:50:49 +0300
Subject: [R-sig-ME] lme4/nlmer problem
In-Reply-To: <46C56C5B.7090305@iki.fi>
References: <46C561C7.3010008@metla.fi> <46C56C5B.7090305@iki.fi>
Message-ID: <46C57D89.9010802@metla.fi>

Hi Markus,

Many thanks for your message. Unfortunately, it makes no change whether 
or not the argument "fixed=p0+p1~1" is included into the model formula.

Kalle

Markus J?ntti wrote:
> Kalle Eerik?inen wrote:
>> Hello,
>>
>> I have done some test estimations using the lme4 package of R. The 
>> estimation of the parameters of linear mixed-effect models using the 
>> 'lmer' goes well. For instance, a very simple single-level mixed model 
>> "Naslund_lmer1  <- lmer(y ~ d13 + (1 |stand), data = height1)" for the 
>> relationship between the tree height (or its transformation) and 
>> diameter comes out perfectly.
>>
>> However, if I attempt to estimate nonlinear mixed-effect models, I 
>> always receive an error message that tells me: "Error: 
>> length(start$fixed) is not TRUE". This is also the case with the 
>> following model:
>>
>> Schumacher_nlmer1 <- lme4:::nlmer(ht   ~ exp(p0 + p1*1/d13)+u0 ~ 
>> (u0|stand) , fixed=p0+p1~1, data = height1, start = c(p0 = 0.1, p1 = 
>> -9.0), verb = 1)
> 
> What is the purpose of the argument "fixed=p0+p1~1"? The help page makes 
> no mention of it. Maybe this is what is generating the error message.
> 
> markus
>>
> 
> 
>> It is obvious that there exists a trivial bug/mistake in my code, but 
>> I cannot see what is wrong with it. Could someone give me a helping 
>> hand with my 'nlmer problem'?
>>
>> Regards,
>>
>> Kalle Eerik?inen
>>
>>
>> ------------------------------------------------------------------------
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 

From bates at stat.wisc.edu  Fri Aug 17 14:40:02 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 17 Aug 2007 07:40:02 -0500
Subject: [R-sig-ME] lme4/nlmer problem
In-Reply-To: <46C57D89.9010802@metla.fi>
References: <46C561C7.3010008@metla.fi> <46C56C5B.7090305@iki.fi>
	<46C57D89.9010802@metla.fi>
Message-ID: <40e66e0b0708170540r529026acsfd47fac5235eb795@mail.gmail.com>

A call to nlmer looks different from a call to nlme.  The formula
argument should be a three-part formula of the form

response ~ nonlinear_model ~ mixed-model_formula

Some examples are shown below.  I am "near" release of the development
version of the lme4 package that includes nlmer.  I still need to
debug the version of glmer in this release.  We will need to arrange
for a transition period so users can take previously fit lmer objects
and convert them to the new form.  The source package for the
development version can be created from the sources in the SVN archive

https://svn.r-project.org/R-packages/branches/gappy-lmer/

I don't use Windows and do not have a Windows package for
installation.  i can create one using Uwe's win-builder.R-project.org
if it is urgent.  Otherwise I would suggest waiting until we transfer
the project to R-forge.R-project.org where the development version
will be build and tested every night.


On 8/17/07, Kalle Eerik?inen <kalle.eerikainen at metla.fi> wrote:
> Hi Markus,
>
> Many thanks for your message. Unfortunately, it makes no change whether
> or not the argument "fixed=p0+p1~1" is included into the model formula.
>
> Kalle
>
> Markus J?ntti wrote:
> > Kalle Eerik?inen wrote:
> >> Hello,
> >>
> >> I have done some test estimations using the lme4 package of R. The
> >> estimation of the parameters of linear mixed-effect models using the
> >> 'lmer' goes well. For instance, a very simple single-level mixed model
> >> "Naslund_lmer1  <- lmer(y ~ d13 + (1 |stand), data = height1)" for the
> >> relationship between the tree height (or its transformation) and
> >> diameter comes out perfectly.
> >>
> >> However, if I attempt to estimate nonlinear mixed-effect models, I
> >> always receive an error message that tells me: "Error:
> >> length(start$fixed) is not TRUE". This is also the case with the
> >> following model:
> >>
> >> Schumacher_nlmer1 <- lme4:::nlmer(ht   ~ exp(p0 + p1*1/d13)+u0 ~
> >> (u0|stand) , fixed=p0+p1~1, data = height1, start = c(p0 = 0.1, p1 =
> >> -9.0), verb = 1)
> >
> > What is the purpose of the argument "fixed=p0+p1~1"? The help page makes
> > no mention of it. Maybe this is what is generating the error message.
> >
> > markus
> >>
> >
> >
> >> It is obvious that there exists a trivial bug/mistake in my code, but
> >> I cannot see what is wrong with it. Could someone give me a helping
> >> hand with my 'nlmer problem'?
> >>
> >> Regards,
> >>
> >> Kalle Eerik?inen

> example(lmer)

lmer> (fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy))
Linear mixed-effects model fit by REML
Formula: Reaction ~ Days + (Days | Subject)
   Data: sleepstudy
  AIC  BIC logLik MLdeviance REMLdeviance
 1754 1770 -871.8       1752         1744
Random effects:
 Groups   Name Variance Std.Dev. Corr
 Subject       612.095  24.7405
                35.071   5.9221  0.065
 Residual      654.944  25.5919
Number of obs: 180, groups: Subject, 18

Fixed effects:
            Estimate Std. Error t value
(Intercept)  251.405      6.825   36.84
Days          10.467      1.546    6.77

Correlation of Fixed Effects:
     (Intr)
Days -0.138

lmer> (fm2 <- lmer(Reaction ~ Days + (1|Subject) + (0+Days|Subject),
sleepstudy))
Linear mixed-effects model fit by REML
Formula: Reaction ~ Days + (1 | Subject) + (0 + Days | Subject)
   Data: sleepstudy
  AIC  BIC logLik MLdeviance REMLdeviance
 1752 1764 -871.8       1752         1744
Random effects:
 Groups   Name Variance Std.Dev.
 Subject       627.577  25.0515
 Subject        35.852   5.9876
 Residual      653.594  25.5655
Number of obs: 180, groups: Subject, 18; Subject, 18

Fixed effects:
            Estimate Std. Error t value
(Intercept)  251.405      6.885   36.51
Days          10.467      1.559    6.71

Correlation of Fixed Effects:
     (Intr)
Days -0.184

lmer> anova(fm1, fm2)
Data: sleepstudy
Models:
fm2: Reaction ~ Days + (1 | Subject) + (0 + Days | Subject)
fm1: Reaction ~ Days + (Days | Subject)
      Df     AIC     BIC  logLik  Chisq Chi Df Pr(>Chisq)
fm2.p  4 1760.05 1772.82 -876.02
fm1.p  5 1761.99 1777.95 -875.99 0.0609      1      0.805

lmer> (nm1 <- nlmer(circumference ~ SSlogis(age, Asym, xmid, scal) ~ Asym|Tree,
lmer+               Orange, verb = 1, start = c(Asym = 200, xmid =
725, scal = 350)))
  0:     299.40520: 0.617213  200.000  725.000  350.000
  1:     273.38196:  1.61716  199.990  725.001  350.001
  2:     268.17768:  2.12832  199.806  725.025  349.991
  3:     265.29713:  2.68723  199.487  725.077  349.967
  4:     264.04456:  3.19444  199.108  725.150  349.930
  5:     263.54365:  3.63803  198.706  725.240  349.882
  6:     263.39702:  3.95389  198.355  725.330  349.831
  7:     263.36716:  4.12286  198.105  725.403  349.787
  8:     263.35927:  4.19219  197.935  725.460  349.750
  9:     263.34864:  4.25604  197.657  725.563  349.684
 10:     263.32421:  4.34084  196.975  725.830  349.511
 11:     263.27812:  4.41246  195.592  726.386  349.148
 12:     263.21385:  4.39497  193.467  727.261  348.574
 13:     263.16418:  4.24055  191.721  728.004  348.085
 14:     263.14648:  4.07901  191.496  728.122  348.004
 15:     263.14386:  4.03244  191.929  727.953  348.114
 16:     263.14379:  4.03495  192.037  727.908  348.143
 17:     263.14379:  4.03500  192.037  727.909  348.142
 18:     263.14378:  4.03507  192.039  727.912  348.137
 19:     263.14377:  4.03516  192.058  727.934  348.092
 20:     263.14377:  4.03509  192.059  727.934  348.092
Nonlinear mixed model fit by Laplace
Formula: circumference ~ SSlogis(age, Asym, xmid, scal) ~ Asym | Tree
   Data: Orange
Random effects:
 Groups   Name Variance Std.Dev.
 Tree          1095.44  33.0975
 Residual        67.28   8.2024
Number of obs: 35, groups: Tree, 5

Fixed effects:
    Asym     xmid     scal
192.0589 727.9341 348.0919

lmer> (nm2 <- nlmer(conc ~ SSfol(Dose, Time,lKe, lKa, lCl) ~
(lKe+lKa+lCl|Subject),
lmer+               Theoph, start = c(lKe = -2.5, lKa = 0.5, lCl =
-3), verbose = 1))
  0:     386.09968: 0.492366 0.492366 0.492366  0.00000  0.00000
0.00000 -2.50000 0.500000 -3.00000
  1:     384.88844: 0.492038 0.492958 0.492286 -0.00561125 -0.00334076
-0.00230366 -2.49991 0.499929 -3.00040
  2:     381.72748: 0.491706 0.493621 0.492187 -0.0103177 0.00147481
-0.00387406 -2.49971 0.499862 -3.00083
  3:     378.94261: 0.491251 0.494615 0.492040 -0.0166021 -0.00115673
-0.00448798 -2.49934 0.499774 -3.00149
  4:     377.39285: 0.490840 0.495891 0.491841 -0.0230831 0.000679450
-0.00400797 -2.49870 0.499687 -3.00236
  5:     375.74378: 0.490427 0.498498 0.491398 -0.0284192 -0.000543731
-0.00618135 -2.49679 0.499589 -3.00411
  6:     375.28979: 0.490375 0.499569 0.491218 -0.0301946 -0.000209774
-0.00465660 -2.49587 0.499576 -3.00483
  7:     374.93047: 0.490232 0.500576 0.491053 -0.0318322 -0.000446596
-0.00650892 -2.49521 0.499528 -3.00552
  8:     374.87512: 0.490216 0.500699 0.491032 -0.0320955 -3.46514e-05
-0.00643436 -2.49512 0.499524 -3.00561
  9:     374.80736: 0.490203 0.500903 0.490997 -0.0323720 -0.000371694
-0.00640277 -2.49497 0.499519 -3.00575
 10:     374.68230: 0.490180 0.501525 0.490889 -0.0327856 -5.04549e-05
-0.00657813 -2.49451 0.499506 -3.00618
 11:     373.33408: 0.489949 0.513472 0.488761 -0.0368005 -0.000495062
-0.0110244 -2.48566 0.499303 -3.01444
 12:     371.55810: 0.489649 0.526067 0.486246 -0.0398701 0.000796899
-0.00972192 -2.47684 0.499174 -3.02308
 13:     370.08650: 0.489135 0.538835 0.483436 -0.0416520 -0.000892153
-0.00945036 -2.46818 0.499034 -3.03190
 14:     368.56980: 0.488093 0.551720 0.479905 -0.0412694 0.000129599
-0.00929399 -2.46002 0.498898 -3.04099
 15:     361.51477: 0.475950 0.684052 0.429743 -0.0257205 -0.00194058
-0.00365960 -2.39601 0.496206 -3.13671
 16:     361.16262: 0.461171 0.807883 0.337864 -0.0637066 0.00266451
-0.00944405 -2.39669 0.488808 -3.22711
 17:     354.97662: 0.430456 0.861847 0.284795 -0.0586136 -0.000373538
-0.0251852 -2.43362 0.492158 -3.23712
 18:     352.94931: 0.391715 0.930566 0.270056 -0.0586716 0.00268354
-0.0188094 -2.47603 0.488436 -3.22586
 19:     352.50958: 0.391680 0.930588 0.270078 -0.0590697 -0.00104861
-0.0177875 -2.47592 0.488454 -3.22589
 20:     351.81346: 0.389032 0.929977 0.270567 -0.0593194 0.000716624
-0.0177630 -2.47413 0.489169 -3.22510
 21:     351.77196: 0.386876 0.929332 0.270890 -0.0599408 0.000422051
-0.0172655 -2.47144 0.490263 -3.22421
 22:     351.70183: 0.384614 0.928486 0.271183 -0.0602270 0.000947320
-0.0176223 -2.46906 0.491483 -3.22294
 23:     351.64354: 0.381907 0.927674 0.271615 -0.0605585 0.000612578
-0.0177979 -2.46695 0.492636 -3.22198
 24:     351.45295: 0.361792 0.920922 0.274368 -0.0626416 0.000948215
-0.0184277 -2.45587 0.500714 -3.22173
 25:     351.41920: 0.340043 0.925736 0.263511 -0.0627954 0.000382087
-0.0181634 -2.45748 0.499773 -3.22745
 26:     351.36176: 0.319527 0.936642 0.272866 -0.0634084 0.000640883
-0.0181702 -2.45989 0.496879 -3.22451
 27:     351.35763: 0.319522 0.936663 0.272862 -0.0633127 0.000811601
-0.0181654 -2.45982 0.496886 -3.22453
 28:     351.35398: 0.319514 0.936695 0.272856 -0.0631903 0.000687667
-0.0181293 -2.45972 0.496897 -3.22457
 29:     351.34976: 0.319278 0.936827 0.272741 -0.0630328 0.000846531
-0.0181026 -2.45954 0.496867 -3.22447
 30:     351.34465: 0.318678 0.937095 0.272459 -0.0629431 0.000681116
-0.0180636 -2.45934 0.496770 -3.22413
 31:     351.33832: 0.317346 0.937578 0.271910 -0.0627742 0.000842182
-0.0180250 -2.45900 0.496565 -3.22354
 32:     351.32914: 0.314176 0.938064 0.271044 -0.0625923 0.000668059
-0.0179401 -2.45882 0.496133 -3.22318
 33:     351.29439: 0.285503 0.934514 0.269028 -0.0604029 0.000717185
-0.0171005 -2.46262 0.493595 -3.23365
 34:     351.22704: 0.255183 0.937197 0.263394 -0.0572005 9.67627e-05
-0.0158327 -2.46159 0.491972 -3.23286
 35:     351.17757: 0.224719 0.940024 0.257824 -0.0554810 0.000966560
-0.0153756 -2.46183 0.490199 -3.23206
 36:     351.15197: 0.194079 0.944209 0.255029 -0.0535618 0.000374553
-0.0146192 -2.46285 0.492320 -3.23134
 37:     351.11990: 0.220162 0.951637 0.269429 -0.0533941 0.000422727
-0.0150733 -2.46169 0.497667 -3.22999
 38:     351.07908: 0.237936 0.970464 0.270589 -0.0549069 0.000977890
-0.0156717 -2.45577 0.481794 -3.22638
 39:     351.04280: 0.252398 0.986541 0.268059 -0.0566637 0.000413897
-0.0162241 -2.45778 0.503965 -3.22759
 40:     351.03651: 0.250609 0.985292 0.268665 -0.0555838 0.000793777
-0.0154951 -2.45641 0.509033 -3.22700
 41:     351.02001: 0.249118 0.983275 0.269207 -0.0547708 0.000399987
-0.0155318 -2.45505 0.504024 -3.22628
 42:     351.01884: 0.246330 0.987848 0.268166 -0.0540239 0.000759755
-0.0159234 -2.45462 0.502039 -3.22590
 43:     351.00355: 0.245350 0.987979 0.268552 -0.0539114 0.000430733
-0.0155863 -2.45398 0.499423 -3.22558
 44:     351.00194: 0.243729 0.989303 0.269419 -0.0536648 0.000630739
-0.0151864 -2.45254 0.494226 -3.22494
 45:     350.99261: 0.243157 0.994940 0.269152 -0.0540473 0.000474664
-0.0153853 -2.45275 0.495783 -3.22509
 46:     350.97638: 0.251550  1.01754 0.268227 -0.0538946 0.000480603
-0.0154727 -2.45108 0.504181 -3.22516
 47:     350.97018: 0.248046  1.02234 0.269093 -0.0529578 0.000372733
-0.0154663 -2.44907 0.496315 -3.22439
 48:     350.96949: 0.244190  1.02531 0.269006 -0.0531794 0.000428105
-0.0154698 -2.44957 0.496147 -3.22475
 49:     350.96929: 0.248611  1.02686 0.270018 -0.0535457 0.000415639
-0.0155669 -2.44946 0.495945 -3.22572
 50:     350.96917: 0.246859  1.02631 0.269920 -0.0532843 0.000400073
-0.0154960 -2.44968 0.496594 -3.22596
 51:     350.96912: 0.245792  1.02604 0.269656 -0.0532195 0.000403823
-0.0154806 -2.44961 0.496563 -3.22551
 52:     350.96912: 0.245999  1.02613 0.269687 -0.0532265 0.000403255
-0.0154822 -2.44965 0.496527 -3.22560
 53:     350.96912: 0.246003  1.02610 0.269697 -0.0532315 0.000403090
-0.0154834 -2.44963 0.496558 -3.22560
 54:     350.96912: 0.245997  1.02611 0.269692 -0.0532292 0.000403164
-0.0154828 -2.44964 0.496546 -3.22560
 55:     350.96912: 0.245997  1.02611 0.269692 -0.0532292 0.000403165
-0.0154828 -2.44964 0.496546 -3.22560
Nonlinear mixed model fit by Laplace
Formula: conc ~ SSfol(Dose, Time, lKe, lKa, lCl) ~ (lKe + lKa + lCl |
    Subject)
   Data: Theoph
Random effects:
 Groups   Name Variance Std.Dev. Corr
 Subject       0.029956 0.17308
               0.521301 0.72201  -0.013
               0.036130 0.19008   0.000 -0.059
 Residual      0.495029 0.70358
Number of obs: 132, groups: Subject, 12

Fixed effects:
       lKe        lKa        lCl
-2.4496370  0.4965462 -3.2256163

lmer> (nm3 <- nlmer(conc ~ SSfol(Dose, Time,lKe, lKa, lCl) ~
lmer+               (lKe|Subject) + (lKa|Subject) + (lCl|Subject), Theoph,
lmer+               start = c(lKe = -2.5, lKa = 0.5, lCl = -3), verbose = 1))
  0:     386.09968: 0.492366 0.492366 0.492366 -2.50000 0.500000 -3.00000
  1:     377.43545: 0.0825471  1.23161 0.393063 -2.38231 0.411355 -3.50398
  2:     366.00277: 0.112039  1.21790 0.461466 -2.57362 0.412740 -3.33669
  3:     360.02522: 0.162062  1.15605 0.375272 -2.39847 0.435753 -3.17745
  4:     357.53543: 0.133920  1.14625 0.328917 -2.46420 0.437507 -3.19196
  5:     355.97764: 0.0867116  1.13276 0.279073 -2.43653 0.442893 -3.23534
  6:     355.27369: 0.0718404  1.12642 0.264747 -2.46936 0.444271 -3.21897
  7:     354.97499: 0.0464245  1.11570 0.247811 -2.44891 0.448129 -3.23724
  8:     354.69747: 0.0300521  1.10541 0.245427 -2.47167 0.450630 -3.22029
  9:     354.44380: 0.0113476  1.08241 0.247659 -2.45877 0.456802 -3.23041
 10:     354.30407: 0.0106401  1.05289 0.234811 -2.46665 0.463454 -3.22351
 11:     354.17495: 0.0111025  1.02220 0.243825 -2.46532 0.469804 -3.23472
 12:     354.07980: 0.00619672 0.990430 0.238104 -2.46637 0.474160 -3.22448
 13:     354.06447: 0.00476224 0.987768 0.238322 -2.46122 0.474818 -3.23062
 14:     354.04416: 0.00549549 0.981257 0.239218 -2.46669 0.475108 -3.23036
 15:     354.03247: 0.00462216 0.974265 0.236284 -2.46289 0.476168 -3.23060
 16:     354.00978: 0.00332796 0.958014 0.239023 -2.46434 0.476629 -3.22613
 17:     354.00268: 0.00263076 0.953403 0.238980 -2.46373 0.477606 -3.23179
 18:     353.99869: 0.00561923 0.948876 0.236087 -2.46739 0.479069 -3.23041
 19:     353.99299:  0.00000 0.947792 0.238852 -2.46573 0.480566 -3.23083
 20:     353.99084:  0.00000 0.946198 0.236413 -2.46555 0.480836 -3.23022
 21:     353.98958: 2.84393e-11 0.943787 0.237974 -2.46491 0.481186 -3.23065
 22:     353.98840: 0.000535840 0.941514 0.237039 -2.46633 0.481093 -3.22986
 23:     353.98700: 0.00173219 0.939219 0.236789 -2.46529 0.480775 -3.23087
 24:     353.98595: 0.00110715 0.936591 0.237723 -2.46594 0.480285 -3.23052
 25:     353.98506: 0.00112750 0.935243 0.236653 -2.46543 0.482676 -3.23039
 26:     353.98465:  0.00000 0.933278 0.237169 -2.46590 0.481052 -3.23009
 27:     353.98452:  0.00000 0.931806 0.236825 -2.46509 0.479685 -3.23084
 28:     353.98407: 0.000981068 0.930591 0.236833 -2.46573 0.481267 -3.23069
 29:     353.98390: 0.000380416 0.930199 0.236642 -2.46544 0.481447 -3.23018
 30:     353.98386: 0.000194769 0.929921 0.236808 -2.46537 0.481545 -3.23043
 31:     353.98381: 8.11621e-05 0.929672 0.236742 -2.46558 0.481823 -3.23030
 32:     353.98378: 0.000138324 0.929240 0.236665 -2.46546 0.481748 -3.23036
 33:     353.98375: 0.000130336 0.928850 0.236742 -2.46551 0.481972 -3.23027
 34:     353.98373:  0.00000 0.928494 0.236666 -2.46553 0.481790 -3.23040
 35:     353.98372: 1.53639e-05 0.928261 0.236665 -2.46551 0.482194 -3.23037
 36:     353.98372: 1.18744e-05 0.928223 0.236687 -2.46554 0.482191 -3.23034
 37:     353.98372: 8.34650e-06 0.928177 0.236693 -2.46551 0.482190 -3.23036
 38:     353.98371: 2.79048e-05 0.928069 0.236682 -2.46553 0.482143 -3.23033
 39:     353.98371: 6.40584e-05 0.927846 0.236665 -2.46549 0.482045 -3.23034
 40:     353.98371:  0.00000 0.927624 0.236703 -2.46553 0.482091 -3.23035
 41:     353.98371:  0.00000 0.927553 0.236661 -2.46554 0.482132 -3.23036
 42:     353.98371: 5.96124e-06 0.927462 0.236670 -2.46552 0.482124 -3.23035
 43:     353.98371: 5.96124e-06 0.927462 0.236670 -2.46552 0.482124 -3.23035
Nonlinear mixed model fit by Laplace
Formula: conc ~ SSfol(Dose, Time, lKe, lKa, lCl) ~ (lKe | Subject) +
(lKa |      Subject) + (lCl | Subject)
   Data: Theoph
Random effects:
 Groups   Name Variance Std.Dev.
 Subject       0.000000 0.00000
 Subject       0.440903 0.66401
 Subject       0.028714 0.16945
 Residual      0.512588 0.71595
Number of obs: 132, groups: Subject, 12; Subject, 12; Subject, 12

Fixed effects:
       lKe        lKa        lCl
-2.4655320  0.4821415 -3.2303559

lmer> (nm4 <- nlmer(conc ~ SSfol(Dose, Time,lKe, lKa, lCl) ~ (lKa+lCl|Subject),
lmer+               Theoph, start = c(lKe = -2.5, lKa = 0.5, lCl =
-3), verbose = 1))
  0:     377.00821: 0.492366 0.492366  0.00000 -2.50000 0.500000 -3.00000
  1:     375.06636: 0.496628 0.491116 0.115284 -2.49669 0.499833 -3.00310
  2:     368.73772: 0.418871 0.467676 0.109343 -2.35636 0.496774 -3.12849
  3:     360.04981: 0.402170 0.453340 0.0643095 -2.39295 0.495044 -3.13138
  4:     358.31247: 0.398371 0.448441 0.0509030 -2.40073 0.494430 -3.13321
  5:     357.53116: 0.391620 0.435052 0.0276480 -2.41896 0.492729 -3.13855
  6:     355.71678: 0.387375 0.415764 0.0480068 -2.42360 0.490169 -3.15578
  7:     351.92166: 0.324845 0.256277 0.0457815 -2.43077 0.474642 -3.28062
  8:     350.29390: 0.325207 0.256363 0.0582163 -2.45170 0.473363 -3.26257
  9:     349.96730: 0.317341 0.252784 0.0418845 -2.46832 0.472434 -3.24521
 10:     349.38606: 0.308708 0.235571 0.0592500 -2.46265 0.472845 -3.23054
 11:     349.18344: 0.278968 0.238355 0.0619188 -2.46058 0.473807 -3.22663
 12:     349.13588: 0.256679 0.253837 0.0727460 -2.46387 0.474327 -3.23405
 13:     348.96171: 0.233013 0.237400 0.0771499 -2.46412 0.474256 -3.22567
 14:     348.75767: 0.185282 0.237304 0.112341 -2.45487 0.480483 -3.21946
 15:     348.75117: 0.175838 0.237215 0.108856 -2.45946 0.477093 -3.22310
 16:     348.69939: 0.176307 0.237053 0.116914 -2.45842 0.468137 -3.22395
 17:     348.67673: 0.167417 0.237420 0.120847 -2.45913 0.475105 -3.22583
 18:     348.66522: 0.151724 0.238434 0.137320 -2.45369 0.474436 -3.21949
 19:     348.64376: 0.153956 0.236286 0.141555 -2.45956 0.473758 -3.22274
 20:     348.62932: 0.148758 0.236232 0.140890 -2.45963 0.467458 -3.22516
 21:     348.62094: 0.149100 0.236064 0.142779 -2.45980 0.475667 -3.22653
 22:     348.61541: 0.145964 0.235440 0.148000 -2.46327 0.470978 -3.22776
 23:     348.61273: 0.139750 0.235058 0.150849 -2.46421 0.475931 -3.22862
 24:     348.60077: 0.136844 0.235397 0.157547 -2.46107 0.473210 -3.23013
 25:     348.59434: 0.133357 0.233908 0.164716 -2.46229 0.474504 -3.22811
 26:     348.58838: 0.128060 0.234947 0.171218 -2.46270 0.473326 -3.22830
 27:     348.58516: 0.123314 0.235122 0.178312 -2.46234 0.473393 -3.22836
 28:     348.58388: 0.119894 0.237515 0.185676 -2.46285 0.472785 -3.22922
 29:     348.58175: 0.115664 0.235953 0.192852 -2.46184 0.472936 -3.22882
 30:     348.58112: 0.116375 0.235245 0.192781 -2.46174 0.473003 -3.22860
 31:     348.58089: 0.114832 0.235288 0.195777 -2.46201 0.472733 -3.22865
 32:     348.58084: 0.113840 0.235423 0.197880 -2.46202 0.472782 -3.22866
 33:     348.58084: 0.113738 0.235410 0.198166 -2.46201 0.472733 -3.22867
 34:     348.58084: 0.113718 0.235407 0.198209 -2.46200 0.472738 -3.22867
Nonlinear mixed model fit by Laplace
Formula: conc ~ SSfol(Dose, Time, lKe, lKa, lCl) ~ (lKa + lCl | Subject)
   Data: Theoph
Random effects:
 Groups   Name Variance Std.Dev. Corr
 Subject       0.006640 0.081486
               0.028715 0.169455 0.095
 Residual      0.513461 0.716562
Number of obs: 132, groups: Subject, 12

Fixed effects:
       lKe        lKa        lCl
-2.4620040  0.4727376 -3.2286810

lmer> (nm5 <- nlmer(conc ~ SSfol(Dose, Time,lKe, lKa, lCl) ~
(lKa|Subject) + (lCl|Subject),
lmer+               Theoph, start = c(lKe = -2.5, lKa = 0.5, lCl =
-3), verbose = 1))
  0:     377.00821: 0.492366 0.492366 -2.50000 0.500000 -3.00000
  1:     366.76107: 0.651153 0.445802 -2.37680 0.493764 -3.11563
  2:     365.36949: 0.727845 0.339343 -2.56858 0.470938 -3.15375
  3:     357.95634: 0.800556 0.235553 -2.43727 0.469676 -3.30431
  4:     354.99052: 0.832260 0.259765 -2.48344 0.471084 -3.20395
  5:     354.24411: 0.870423 0.236936 -2.44799 0.476074 -3.20614
  6:     354.17301: 0.882142 0.234273 -2.47983 0.474481 -3.25200
  7:     354.01600: 0.931094 0.245475 -2.46839 0.482925 -3.22876
  8:     353.98864: 0.931074 0.239664 -2.46436 0.483016 -3.23136
  9:     353.98458: 0.930993 0.237968 -2.46595 0.482944 -3.23014
 10:     353.98400: 0.930867 0.237118 -2.46538 0.482925 -3.23051
 11:     353.98394: 0.930160 0.236646 -2.46583 0.482637 -3.23007
 12:     353.98374: 0.929216 0.236720 -2.46550 0.482309 -3.23037
 13:     353.98370: 0.928140 0.236724 -2.46568 0.482320 -3.23030
 14:     353.98368: 0.927745 0.236701 -2.46539 0.482224 -3.23029
 15:     353.98368: 0.927700 0.236705 -2.46552 0.481755 -3.23040
 16:     353.98368: 0.927689 0.236686 -2.46554 0.481775 -3.23036
 17:     353.98368: 0.927672 0.236679 -2.46551 0.481820 -3.23037
 18:     353.98367: 0.927645 0.236677 -2.46555 0.481928 -3.23037
 19:     353.98367: 0.927612 0.236678 -2.46553 0.482015 -3.23039
 20:     353.98367: 0.927527 0.236683 -2.46551 0.482012 -3.23035
 21:     353.98367: 0.927478 0.236679 -2.46554 0.482090 -3.23035
 22:     353.98367: 0.927453 0.236672 -2.46553 0.482134 -3.23035
 23:     353.98367: 0.927456 0.236674 -2.46553 0.482133 -3.23035
Nonlinear mixed model fit by Laplace
Formula: conc ~ SSfol(Dose, Time, lKe, lKa, lCl) ~ (lKa | Subject) +
(lCl |      Subject)
   Data: Theoph
Random effects:
 Groups   Name Variance Std.Dev.
 Subject       0.440915 0.66401
 Subject       0.028712 0.16945
 Residual      0.512588 0.71595
Number of obs: 132, groups: Subject, 12; Subject, 12

Fixed effects:
       lKe        lKa        lCl
-2.4655280  0.4821327 -3.2303658



From austin.frank at gmail.com  Fri Aug 17 23:26:06 2007
From: austin.frank at gmail.com (Austin Frank)
Date: Fri, 17 Aug 2007 17:26:06 -0400
Subject: [R-sig-ME] perturb with lme4
Message-ID: <m0k5rt97kh.fsf@gmail.com>

Hello!

I'd like to evaluate the degree of colinearity introduced into my model
by two categorical independent variables.  I'd like to use a
perturbation analysis, and so reached for the 'perturb' package.
Unfortunately, the perturb function as written doesn't work with lmer
models.

The funtion directly accesses the "call" slot of its model argument (frm
<- mod$call$formula, for example).  I attempted the obvious fix of
either using an accessor function (frm <- formula(mod)) or using the
right slotting operator (frm <- mod at call$frm).  This naive replacement
attempt didn't get me very far.

Can anyone suggest a way to modify the perturb function as written, some
work-alike code for an lmer model, or an alternative way for assessing
colinearity introduced by categorical variables in an lmer model?

My (half-hearted) attempt at a modified perturb function is below.

Thanks,
/au


## should be called with
# ptb <- my.perturb(mod.lmer,
#     pfac=list(
#         list("fac1",pcnt=95),
#         list("fac2",pcnt=95)))

my.perturb <- function
( mod, pvars = NULL,
 prange = NULL,
 ptrans = NULL,
 pfac = NULL, 
 uniform = FALSE,
 niter = 100) 
{
    cutsp <- function(indx, tbl) {
        findInterval(runif(1), tbl[indx, ], rightmost.closed = TRUE)
    }
    if (is.null(formula(mod))) 
        stop("First argument does not contain a formula")
    stopifnot(is.list(pfac) || is.null(pfac))
    nms <- all.vars(terms(mod))
    stopifnot(all(pvars %in% nms))
    result <- NULL
    ncases <- length(get(nms[1]))
    frm <- deparse(formula(mod), width.cutoff = 500)
    result$formula <- frm
    allb <- coefficients(mod)
    if (length(pvars) > 0) {
        stopifnot(is.vector(get(pvars)))
        stopifnot(length(pvars) == length(prange))
        result$pvars <- pvars
        result$prange <- prange
        if (length(ptrans) > 0) 
            result$ptrans <- ptrans
        b <- make.names(c(nms, pvars), unique = TRUE)
        pvars.1 <- b[(length(nms) + 1):length(b)]
        for (i in 1:length(pvars)) {
            inp <- paste("\\<", pvars[i], "(\\>[^.]|$)", sep = "")
            outp <- paste(pvars.1[i], "\\1", sep = "")
            frm <- gsub(inp, outp, frm)
            ptrans <- gsub(inp, outp, ptrans)
        }
        result$ptrans2 <- ptrans
    }
    if (length(pfac[[1]]) > 0) {
        rcls.tbl <- NULL
        pfac.1 <- NULL
        if (is.list(pfac[[1]])) 
            n <- length(pfac)
        else n <- 1
        for (i in 1:n) {
            if (n == 1) 
                lstnm <- pfac
            else lstnm <- pfac[[i]]
            stopifnot(all(lstnm[[1]] %in% nms))
            b <- make.names(c(nms, lstnm[[1]]), unique = TRUE)
            pfc <- b[(length(nms) + 1):length(b)]
            inp <- paste("\\<", lstnm[[1]], "(\\>[^.]|$)", sep = "")
            outp <- paste(pfc, "\\1", sep = "")
            frm <- gsub(inp, outp, frm)
            rcls <- do.call("reclassify", lstnm)
            rcls.tbl <- c(rcls.tbl, list(rcls))
            pfac.1 <- c(pfac.1, pfc)
        }
        result$reclassify.tables <- rcls.tbl
    }
    result$formula2 <- frm
    mod at call$formula <- as.formula(frm)
    if (uniform) {
        ranexp <- "runif(ncases,-prange[i],prange[i])"
        result$distribution <- "uniform"
    }
    else {
        ranexp <- "rnorm(ncases,0,prange[i])"
        result$distribution <- "normal"
    }
    for (k in 1:niter) {
        if (length(prange) > 0) {
            for (i in 1:length(prange)) {
                assign(pvars.1[i], get(pvars[i]) + eval(parse(text = ranexp))
             }
        }
        for (trans in ptrans) eval(trans)
        if (length(pfac[[1]]) > 0) {
            for (i in 1:length(rcls.tbl)) {
                tbl <- rcls.tbl[[i]]$cum.reclass.prob
                tbl <- cbind(0, tbl)
                assign("tmpvar", as.numeric(get(rcls.tbl[[i]]$variable)))
                assign(pfac.1[i], sapply(tmpvar, cutsp, tbl))
                assign(pfac.1[i], as.factor(get(pfac.1[i])))
            }
        }
        mod2 <- eval(mod at call)
        allb <- rbind(allb, coefficients(mod2))
    }
    rownames(allb) <- NULL
    result$coeff.table <- allb
    class(result) <- "perturb"
    result
}

-- 
Austin Frank
http://aufrank.net
GPG Public Key (D7398C2F): http://aufrank.net/personal.asc



From lamprianou at yahoo.com  Tue Aug 21 12:35:05 2007
From: lamprianou at yahoo.com (Iasonas Lamprianou)
Date: Tue, 21 Aug 2007 03:35:05 -0700 (PDT)
Subject: [R-sig-ME] R-sig-mixed-models Digest, Vol 8, Issue 10
Message-ID: <607384.7411.qm@web54103.mail.re2.yahoo.com>

Hi all, I have a question regarding the paper
Estimating the Multilevel Rasch Model: With the
lme4 Package
by Doran, Bates etc al.
I would be greateful if someone could answer these questions, I am still a beginner.

In page 10, they fitted a model with no intercept. (1) What might be the motivation for this?  (1) How would the interpretation be different if they had included am intercept? (3) How may I derive the table of residuals (observed-predicted)? (4) How can I estimate/evaluate the fit of individual items, subjects or companies?
 
I know that I have many questions, but I really love lme4 and I would like to routinely use it in my research. I have a great education dataset which I would love to analyse. Any experts wishing a joint publication? My motivation is to learn as much as possible during the collaboration for this paper.

Dr. Iasonas Lamprianou
Department of Education
The University of Manchester
Oxford Road, Manchester M13 9PL, UK
Tel. 0044 161 275 3485
iasonas.lamprianou at manchester.ac.uk


----- Original Message ----
From: "r-sig-mixed-models-request at r-project.org" <r-sig-mixed-models-request at r-project.org>
To: r-sig-mixed-models at r-project.org
Sent: Wednesday, 15 August, 2007 1:00:14 PM
Subject: R-sig-mixed-models Digest, Vol 8, Issue 10


Send R-sig-mixed-models mailing list submissions to
    r-sig-mixed-models at r-project.org

To subscribe or unsubscribe via the World Wide Web, visit
    https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
or, via email, send a message with subject or body 'help' to
    r-sig-mixed-models-request at r-project.org

You can reach the person managing the list at
    r-sig-mixed-models-owner at r-project.org

When replying, please edit your Subject line so it is more specific
than "Re: Contents of R-sig-mixed-models digest..."


Today's Topics:

   1. Re: lmer, intercepts and offsets (Daniel Farewell)


----------------------------------------------------------------------

Message: 1
Date: Tue, 14 Aug 2007 16:39:02 +0000 (GMT)
From: Daniel Farewell <farewelld at cf.ac.uk>
Subject: Re: [R-sig-ME] lmer, intercepts and offsets
To: r-sig-mixed-models at r-project.org
Message-ID: <523651.84987.qm at web27101.mail.ukl.yahoo.com>
Content-Type: text/plain; charset=iso-8859-1

This is a follow-up to a thread from back in March ("lmer, intercepts and offsets"). I'm hoping (at least) to better understand how lmer works.

I'd like to "trick" lmer into thinking it has converged to certain parameter estimates. This is straightforward for variance components, making use of the 'start' parameter and using 'control' to set the number of the various kinds of iteration to zero.

My ultimate goal is to extract posterior second moments from a model "fit" where I have specified both the variance components and the fixed effects.

Obviously it is possible to dig inside the fitted model and manually alter the fixed effects, but this has no impact on the result of a call to ranef, presumably because the posterior means (and variances?) have already been calculated, and are sitting in the ranef slot of the fitted model.

My question is this: at what stage do the random effects get calculated? Simplifying greatly, at some stage lmer must calculate betahat(Omega) (the fixed effects) and ranef(Omega) (the estimated random effects) for the converged value of Omega. Does ranef(Omega) depend on the result of betahat(Omega)? If so, then presumably tinkering with the betahat(Omega) results at the appropriate point inside lmer would result in what I want. If not (that is, if the dependence on the fixed effects is indirect) what needs tinkering with?

Is there a good reason why lmer does not allow models with no fixed effects at all? With the right offset, this would be another way to achieve the same result.

[[replacing trailing spam]]

Daniel Farewell



------------------------------

_______________________________________________
R-sig-mixed-models mailing list
R-sig-mixed-models at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


End of R-sig-mixed-models Digest, Vol 8, Issue 10



From lamprianou at yahoo.com  Fri Aug 24 11:55:10 2007
From: lamprianou at yahoo.com (Iasonas Lamprianou)
Date: Fri, 24 Aug 2007 02:55:10 -0700 (PDT)
Subject: [R-sig-ME] R-sig-mixed-models Digest, Vol 8, Issue 13
Message-ID: <172313.56035.qm@web54103.mail.re2.yahoo.com>

Dear friends, in the following example, I am testing teacher effect. So, the teacher is affecting the score of the pupils, and the items are also random effects. The ID is the id of the pupils. Year (pupils are either year6 ot year7) and age and gender may play some role on the test score. 


Question 1: In the following example, I am not sure what the Correlation of Fixed Effects is. Could someone please explain it to me? How do I use these numbers? 

Question 2: Also, what is the meaning of this statment? Estimated scale (compare to  1 )  0.865952 . How do I interpet this?

Thanks



Generalized linear mixed model fit using Laplace 
Formula: SCORE ~ YEAR + AGE + GENDER + (1 | ITEM) + (1 | ID) + (1 | TEACHER) 
   Data: data2 
 Family: binomial(logit link)
  AIC  BIC logLik deviance
 4979 5027  -2482     4965
Random effects:
 Groups  Name Variance Std.Dev.
 ID           0.508153 0.71285 
 TEACHER      0.039018 0.19753 
 ITEM         3.874608 1.96840 
number of obs: 7043, groups: ID, 754; TEACHER, 29; ITEM, 10
Estimated scale (compare to  1 )  0.865952 
Fixed effects:
                 Estimate Std. Error z value Pr(>|z|)  
(Intercept)    -1.6334597  0.6457887 -2.5294   0.0114 *
YEAR[T.Year 7]  0.0495903  0.1262880  0.3927   0.6946  
AGE             0.0004811  0.0009579  0.5023   0.6155  
GENDER[T.girl] -0.0546018  0.0924347 -0.5907   0.5547  
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
Correlation of Fixed Effects:
            (Intr) YEAR[7 AGE   
YEAR[T.Yr7] -0.101              
AGE         -0.203 -0.095       
GENDER[T.g] -0.063 -0.067 -0.008


 
Dr. Iasonas Lamprianou
Department of Education
The University of Manchester
Oxford Road, Manchester M13 9PL, UK
Tel. 0044 161 275 3485
iasonas.lamprianou at manchester.ac.uk


----- Original Message ----
From: "r-sig-mixed-models-request at r-project.org" <r-sig-mixed-models-request at r-project.org>
To: r-sig-mixed-models at r-project.org
Sent: Wednesday, 22 August, 2007 1:00:17 PM
Subject: R-sig-mixed-models Digest, Vol 8, Issue 13


Send R-sig-mixed-models mailing list submissions to
    r-sig-mixed-models at r-project.org

To subscribe or unsubscribe via the World Wide Web, visit
    https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
or, via email, send a message with subject or body 'help' to
    r-sig-mixed-models-request at r-project.org

You can reach the person managing the list at
    r-sig-mixed-models-owner at r-project.org

When replying, please edit your Subject line so it is more specific
than "Re: Contents of R-sig-mixed-models digest..."


Today's Topics:

   1. Re: R-sig-mixed-models Digest, Vol 8, Issue 10
      (Iasonas Lamprianou)


----------------------------------------------------------------------

Message: 1
Date: Tue, 21 Aug 2007 03:35:05 -0700 (PDT)

Subject: Re: [R-sig-ME] R-sig-mixed-models Digest, Vol 8, Issue 10
To: r-sig-mixed-models at r-project.org
Message-ID: <607384.7411.qm at web54103.mail.re2.yahoo.com>
Content-Type: text/plain; charset=iso-8859-1

Hi all, I have a question regarding the paper
Estimating the Multilevel Rasch Model: With the
lme4 Package
by Doran, Bates etc al.
I would be greateful if someone could answer these questions, I am still a beginner.

In page 10, they fitted a model with no intercept. (1) What might be the motivation for this?  (1) How would the interpretation be different if they had included am intercept? (3) How may I derive the table of residuals (observed-predicted)? (4) How can I estimate/evaluate the fit of individual items, subjects or companies?

I know that I have many questions, but I really love lme4 and I would like to routinely use it in my research. I have a great education dataset which I would love to analyse. Any experts wishing a joint publication? My motivation is to learn as much as possible during the collaboration for this paper.

Dr. Iasonas Lamprianou
Department of Education
The University of Manchester
Oxford Road, Manchester M13 9PL, UK
Tel. 0044 161 275 3485
iasonas.lamprianou at manchester.ac.uk


----- Original Message ----
From: "r-sig-mixed-models-request at r-project.org" <r-sig-mixed-models-request at r-project.org>
To: r-sig-mixed-models at r-project.org
Sent: Wednesday, 15 August, 2007 1:00:14 PM
Subject: R-sig-mixed-models Digest, Vol 8, Issue 10


Send R-sig-mixed-models mailing list submissions to
    r-sig-mixed-models at r-project.org

To subscribe or unsubscribe via the World Wide Web, visit
    https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
or, via email, send a message with subject or body 'help' to
    r-sig-mixed-models-request at r-project.org

You can reach the person managing the list at
    r-sig-mixed-models-owner at r-project.org

When replying, please edit your Subject line so it is more specific
than "Re: Contents of R-sig-mixed-models digest..."


Today's Topics:

   1. Re: lmer, intercepts and offsets (Daniel Farewell)


----------------------------------------------------------------------

Message: 1
Date: Tue, 14 Aug 2007 16:39:02 +0000 (GMT)
From: Daniel Farewell <farewelld at cf.ac.uk>
Subject: Re: [R-sig-ME] lmer, intercepts and offsets
To: r-sig-mixed-models at r-project.org
Message-ID: <523651.84987.qm at web27101.mail.ukl.yahoo.com>
Content-Type: text/plain; charset=iso-8859-1

This is a follow-up to a thread from back in March ("lmer, intercepts and offsets"). I'm hoping (at least) to better understand how lmer works.

I'd like to "trick" lmer into thinking it has converged to certain parameter estimates. This is straightforward for variance components, making use of the 'start' parameter and using 'control' to set the number of the various kinds of iteration to zero.

My ultimate goal is to extract posterior second moments from a model "fit" where I have specified both the variance components and the fixed effects.

Obviously it is possible to dig inside the fitted model and manually alter the fixed effects, but this has no impact on the result of a call to ranef, presumably because the posterior means (and variances?) have already been calculated, and are sitting in the ranef slot of the fitted model.

My question is this: at what stage do the random effects get calculated? Simplifying greatly, at some stage lmer must calculate betahat(Omega) (the fixed effects) and ranef(Omega) (the estimated random effects) for the converged value of Omega. Does ranef(Omega) depend on the result of betahat(Omega)? If so, then presumably tinkering with the betahat(Omega) results at the appropriate point inside lmer would result in what I want. If not (that is, if the dependence on the fixed effects is indirect) what needs tinkering with?

Is there a good reason why lmer does not allow models with no fixed effects at all? With the right offset, this would be another way to achieve the same result.

[[replacing trailing spam]]

Daniel Farewell



------------------------------

_______________________________________________
R-sig-mixed-models mailing list
R-sig-mixed-models at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


End of R-sig-mixed-models Digest, Vol 8, Issue 10



------------------------------

_______________________________________________
R-sig-mixed-models mailing list
R-sig-mixed-models at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


End of R-sig-mixed-models Digest, Vol 8, Issue 13



From ccleland at optonline.net  Fri Aug 24 14:42:24 2007
From: ccleland at optonline.net (Chuck Cleland)
Date: Fri, 24 Aug 2007 08:42:24 -0400
Subject: [R-sig-ME] Simulating Data from a Generalized Linear Mixed Model
Message-ID: <46CED230.3080506@optonline.net>

Hello:
  Does anyone have suggestions for how one can simulate data for a
generalized linear mixed model?  For example, below are summaries of two
models fit by lmer() for which I would like to simulate new data.  If
the summaries do not provide sufficient information to generate new
observations, what other information is needed?

thanks for any help,

Chuck

> summary(fm1)
Linear mixed-effects model fit by REML
Formula: Y ~ V7 * TIME + (TIME | id)
   Data: df.uni
  AIC  BIC logLik MLdeviance REMLdeviance
 8795 8836  -4390       8763         8781
Random effects:
 Groups   Name Variance Std.Dev. Corr
 id            0.23671  0.48653
               0.52332  0.72341  -0.079
 Residual      0.51130  0.71506
number of obs: 2611, groups: id, 480

Fixed effects:
            Estimate Std. Error t value
(Intercept)  0.02499    0.04311   0.580
V7          -0.08775    0.06027  -1.456
TIME         0.15238    0.04826   3.158
V7:TIME      0.29308    0.06717   4.364

Correlation of Fixed Effects:
        (Intr) V7     TIME
V7      -0.715
TIME    -0.106  0.076
V7:TIME  0.076 -0.107 -0.718

> summary(fm2)
Generalized linear mixed model fit using Laplace
Formula: Y ~ V7 * TIME + (TIME | id)
   Data: df.uni
 Family: binomial(logit link)
  AIC  BIC logLik deviance
 2278 2319  -1132     2264
Random effects:
 Groups Name Variance Std.Dev. Corr
 id          0.63468  0.79667
             2.96036  1.72057  0.125
number of obs: 2601, groups: id, 480

Estimated scale (compare to  1 )  0.6274443

Fixed effects:
            Estimate Std. Error z value Pr(>|z|)
(Intercept)  0.29549    0.12484   2.367   0.0179 *
V7           0.08769    0.17198   0.510   0.6101
TIME        -0.67834    0.14820  -4.577 4.71e-06 ***
V7:TIME      0.45752    0.20165   2.269   0.0233 *
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Correlation of Fixed Effects:
        (Intr) V7     TIME
V7      -0.726
TIME    -0.260  0.189
V7:TIME  0.191 -0.253 -0.735

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 512-0171 (M, W, F)
fax: (917) 438-0894



From dimitris.rizopoulos at med.kuleuven.be  Fri Aug 24 16:42:01 2007
From: dimitris.rizopoulos at med.kuleuven.be (Dimitris Rizopoulos)
Date: Fri, 24 Aug 2007 16:42:01 +0200
Subject: [R-sig-ME] Simulating Data from a Generalized Linear Mixed Model
References: <46CED230.3080506@optonline.net>
Message-ID: <007a01c7e65c$ee444620$0540210a@www.domain>

for simple models you can use something like the following:

sleepstudy$Reaction2 <- sleepstudy$Reaction > 
median(sleepstudy$Reaction)
(fm1 <- lmer(Reaction2 ~ Days + (Days | Subject), family = "binomial", 
sleepstudy))
############
n <- length(unique(sleepstudy$Subject))
ni <- as.vector(tapply(sleepstudy$Subject, sleepstudy$Subject, 
length))
p <- fm1 at nc
X <- fm1 at X
Z <- X[, 1:2] # keep the relevant columns of X
V <- matrix(VarCorr(fm1)[[1]]@x, p)
b <- mvrnorm(n, rep(0, p), V)
mu <- X %*% fixef(fm1) + rowSums(Z * b[rep(1:n, ni), ])
y <- rbinom(sum(ni), 1, plogis(mu))
# y <- rnorm(sum(ni), mu, attr(VarCorr(fm1), "sc")) for linear mixed 
model


I hope it helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/(0)16/336899
Fax: +32/(0)16/337015
Web: http://med.kuleuven.be/biostat/
     http://www.student.kuleuven.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: "Chuck Cleland" <ccleland at optonline.net>
To: <r-sig-mixed-models at r-project.org>
Sent: Friday, August 24, 2007 2:42 PM
Subject: [R-sig-ME] Simulating Data from a Generalized Linear Mixed 
Model


> Hello:
>  Does anyone have suggestions for how one can simulate data for a
> generalized linear mixed model?  For example, below are summaries of 
> two
> models fit by lmer() for which I would like to simulate new data. 
> If
> the summaries do not provide sufficient information to generate new
> observations, what other information is needed?
>
> thanks for any help,
>
> Chuck
>
>> summary(fm1)
> Linear mixed-effects model fit by REML
> Formula: Y ~ V7 * TIME + (TIME | id)
>   Data: df.uni
>  AIC  BIC logLik MLdeviance REMLdeviance
> 8795 8836  -4390       8763         8781
> Random effects:
> Groups   Name Variance Std.Dev. Corr
> id            0.23671  0.48653
>               0.52332  0.72341  -0.079
> Residual      0.51130  0.71506
> number of obs: 2611, groups: id, 480
>
> Fixed effects:
>            Estimate Std. Error t value
> (Intercept)  0.02499    0.04311   0.580
> V7          -0.08775    0.06027  -1.456
> TIME         0.15238    0.04826   3.158
> V7:TIME      0.29308    0.06717   4.364
>
> Correlation of Fixed Effects:
>        (Intr) V7     TIME
> V7      -0.715
> TIME    -0.106  0.076
> V7:TIME  0.076 -0.107 -0.718
>
>> summary(fm2)
> Generalized linear mixed model fit using Laplace
> Formula: Y ~ V7 * TIME + (TIME | id)
>   Data: df.uni
> Family: binomial(logit link)
>  AIC  BIC logLik deviance
> 2278 2319  -1132     2264
> Random effects:
> Groups Name Variance Std.Dev. Corr
> id          0.63468  0.79667
>             2.96036  1.72057  0.125
> number of obs: 2601, groups: id, 480
>
> Estimated scale (compare to  1 )  0.6274443
>
> Fixed effects:
>            Estimate Std. Error z value Pr(>|z|)
> (Intercept)  0.29549    0.12484   2.367   0.0179 *
> V7           0.08769    0.17198   0.510   0.6101
> TIME        -0.67834    0.14820  -4.577 4.71e-06 ***
> V7:TIME      0.45752    0.20165   2.269   0.0233 *
> ---
> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>
> Correlation of Fixed Effects:
>        (Intr) V7     TIME
> V7      -0.726
> TIME    -0.260  0.189
> V7:TIME  0.191 -0.253 -0.735
>
> -- 
> Chuck Cleland, Ph.D.
> NDRI, Inc.
> 71 West 23rd Street, 8th floor
> New York, NY 10010
> tel: (212) 845-4495 (Tu, Th)
> tel: (732) 512-0171 (M, W, F)
> fax: (917) 438-0894
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 


Disclaimer: http://www.kuleuven.be/cwis/email_disclaimer.htm



From afshart at exchange.sba.miami.edu  Fri Aug 24 16:06:54 2007
From: afshart at exchange.sba.miami.edu (Afshartous, David)
Date: Fri, 24 Aug 2007 10:06:54 -0400
Subject: [R-sig-ME] Simulating Data from a Generalized Linear Mixed Model
In-Reply-To: <46CED230.3080506@optonline.net>
Message-ID: <6BCB4D493A447546A8126F24332056E806961C28@school1.business.edu>

Chuck,
Gelman's book Data Analysis Using Regression and Multilevel/Hierarchical
Model has
good examples in both R and Bugs; see p.363 and also look in the index
under "fake data simulation" for other examples.
Cheers,
David
 

> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org 
> [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf 
> Of Chuck Cleland
> Sent: Friday, August 24, 2007 8:42 AM
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] Simulating Data from a Generalized Linear 
> Mixed Model
> 
> Hello:
>   Does anyone have suggestions for how one can simulate data 
> for a generalized linear mixed model?  For example, below are 
> summaries of two models fit by lmer() for which I would like 
> to simulate new data.  If the summaries do not provide 
> sufficient information to generate new observations, what 
> other information is needed?
> 
> thanks for any help,
> 
> Chuck
> 
> > summary(fm1)
> Linear mixed-effects model fit by REML
> Formula: Y ~ V7 * TIME + (TIME | id)
>    Data: df.uni
>   AIC  BIC logLik MLdeviance REMLdeviance
>  8795 8836  -4390       8763         8781
> Random effects:
>  Groups   Name Variance Std.Dev. Corr
>  id            0.23671  0.48653
>                0.52332  0.72341  -0.079
>  Residual      0.51130  0.71506
> number of obs: 2611, groups: id, 480
> 
> Fixed effects:
>             Estimate Std. Error t value
> (Intercept)  0.02499    0.04311   0.580
> V7          -0.08775    0.06027  -1.456
> TIME         0.15238    0.04826   3.158
> V7:TIME      0.29308    0.06717   4.364
> 
> Correlation of Fixed Effects:
>         (Intr) V7     TIME
> V7      -0.715
> TIME    -0.106  0.076
> V7:TIME  0.076 -0.107 -0.718
> 
> > summary(fm2)
> Generalized linear mixed model fit using Laplace
> Formula: Y ~ V7 * TIME + (TIME | id)
>    Data: df.uni
>  Family: binomial(logit link)
>   AIC  BIC logLik deviance
>  2278 2319  -1132     2264
> Random effects:
>  Groups Name Variance Std.Dev. Corr
>  id          0.63468  0.79667
>              2.96036  1.72057  0.125
> number of obs: 2601, groups: id, 480
> 
> Estimated scale (compare to  1 )  0.6274443
> 
> Fixed effects:
>             Estimate Std. Error z value Pr(>|z|)
> (Intercept)  0.29549    0.12484   2.367   0.0179 *
> V7           0.08769    0.17198   0.510   0.6101
> TIME        -0.67834    0.14820  -4.577 4.71e-06 ***
> V7:TIME      0.45752    0.20165   2.269   0.0233 *
> ---
> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
> 
> Correlation of Fixed Effects:
>         (Intr) V7     TIME
> V7      -0.726
> TIME    -0.260  0.189
> V7:TIME  0.191 -0.253 -0.735
> 
> --
> Chuck Cleland, Ph.D.
> NDRI, Inc.
> 71 West 23rd Street, 8th floor
> New York, NY 10010
> tel: (212) 845-4495 (Tu, Th)
> tel: (732) 512-0171 (M, W, F)
> fax: (917) 438-0894
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From lamprianou at yahoo.com  Sun Aug 26 11:58:04 2007
From: lamprianou at yahoo.com (Iasonas Lamprianou)
Date: Sun, 26 Aug 2007 02:58:04 -0700 (PDT)
Subject: [R-sig-ME] R mixed effects problem
Message-ID: <854873.59759.qm@web54102.mail.re2.yahoo.com>

Deat friends, I still need some answers on the following questions. I posted this email but I got no response, it would be great if any one of you could give me some hints. Also, I noticed that the resid function "is not yet implemented" in lmer for the bionomial model. Has this been solved in lme2?

jason
 
Dr. Iasonas Lamprianou
Department of Education
The University of Manchester
Oxford Road, Manchester M13 9PL, UK
Tel. 0044 161 275 3485
iasonas.lamprianou at manchester.ac.uk


----- Forwarded Message ----
From: Iasonas Lamprianou <lamprianou at yahoo.com>
To: r-sig-mixed-models at r-project.org
Sent: Friday, 24 August, 2007 12:55:10 PM
Subject: Re: R-sig-mixed-models Digest, Vol 8, Issue 13


Dear friends, in the following example, I am testing teacher effect. So, the teacher is affecting the score of the pupils, and the items are also random effects. The ID is the id of the pupils. Year (pupils are either year6 ot year7) and age and gender may play some role on the test score. 


Question 1: In the following example, I am not sure what the Correlation of Fixed Effects is. Could someone please explain it to me? How do I use these numbers? 

Question 2: Also, what is the meaning of this statment? Estimated scale (compare to  1 )  0.865952 . How do I interpet this?

Thanks



Generalized linear mixed model fit using Laplace 
Formula: SCORE ~ YEAR + AGE + GENDER + (1 | ITEM) + (1 | ID) + (1 | TEACHER) 
   Data: data2 
Family: binomial(logit link)
  AIC  BIC logLik deviance
4979 5027  -2482     4965
Random effects:
Groups  Name Variance Std.Dev.
ID           0.508153 0.71285 
TEACHER      0.039018 0.19753 
ITEM         3.874608 1.96840 
number of obs: 7043, groups: ID, 754; TEACHER, 29; ITEM, 10
Estimated scale (compare to  1 )  0.865952 
Fixed effects:
                 Estimate Std. Error z value Pr(>|z|)  
(Intercept)    -1.6334597  0.6457887 -2.5294   0.0114 *
YEAR[T.Year 7]  0.0495903  0.1262880  0.3927   0.6946  
AGE             0.0004811  0.0009579  0.5023   0.6155  
GENDER[T.girl] -0.0546018  0.0924347 -0.5907   0.5547  
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
Correlation of Fixed Effects:
            (Intr) YEAR[7 AGE   
YEAR[T.Yr7] -0.101              
AGE         -0.203 -0.095       
GENDER[T.g] -0.063 -0.067 -0.008



Dr. Iasonas Lamprianou
Department of Education
The University of Manchester
Oxford Road, Manchester M13 9PL, UK
Tel. 0044 161 275 3485
iasonas.lamprianou at manchester.ac.uk


----- Original Message ----
From: "r-sig-mixed-models-request at r-project.org" <r-sig-mixed-models-request at r-project.org>
To: r-sig-mixed-models at r-project.org
Sent: Wednesday, 22 August, 2007 1:00:17 PM
Subject: R-sig-mixed-models Digest, Vol 8, Issue 13


Send R-sig-mixed-models mailing list submissions to
    r-sig-mixed-models at r-project.org

To subscribe or unsubscribe via the World Wide Web, visit
    https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
or, via email, send a message with subject or body 'help' to
    r-sig-mixed-models-request at r-project.org

You can reach the person managing the list at
    r-sig-mixed-models-owner at r-project.org

When replying, please edit your Subject line so it is more specific
than "Re: Contents of R-sig-mixed-models digest..."


Today's Topics:

   1. Re: R-sig-mixed-models Digest, Vol 8, Issue 10
      (Iasonas Lamprianou)


----------------------------------------------------------------------

Message: 1
Date: Tue, 21 Aug 2007 03:35:05 -0700 (PDT)

Subject: Re: [R-sig-ME] R-sig-mixed-models Digest, Vol 8, Issue 10
To: r-sig-mixed-models at r-project.org
Message-ID: <607384.7411.qm at web54103.mail.re2.yahoo.com>
Content-Type: text/plain; charset=iso-8859-1

Hi all, I have a question regarding the paper
Estimating the Multilevel Rasch Model: With the
lme4 Package
by Doran, Bates etc al.
I would be greateful if someone could answer these questions, I am still a beginner.

In page 10, they fitted a model with no intercept. (1) What might be the motivation for this?  (1) How would the interpretation be different if they had included am intercept? (3) How may I derive the table of residuals (observed-predicted)? (4) How can I estimate/evaluate the fit of individual items, subjects or companies?

I know that I have many questions, but I really love lme4 and I would like to routinely use it in my research. I have a great education dataset which I would love to analyse. Any experts wishing a joint publication? My motivation is to learn as much as possible during the collaboration for this paper.

Dr. Iasonas Lamprianou
Department of Education
The University of Manchester
Oxford Road, Manchester M13 9PL, UK
Tel. 0044 161 275 3485
iasonas.lamprianou at manchester.ac.uk


----- Original Message ----
From: "r-sig-mixed-models-request at r-project.org" <r-sig-mixed-models-request at r-project.org>
To: r-sig-mixed-models at r-project.org
Sent: Wednesday, 15 August, 2007 1:00:14 PM
Subject: R-sig-mixed-models Digest, Vol 8, Issue 10


Send R-sig-mixed-models mailing list submissions to
    r-sig-mixed-models at r-project.org

To subscribe or unsubscribe via the World Wide Web, visit
    https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
or, via email, send a message with subject or body 'help' to
    r-sig-mixed-models-request at r-project.org

You can reach the person managing the list at
    r-sig-mixed-models-owner at r-project.org

When replying, please edit your Subject line so it is more specific
than "Re: Contents of R-sig-mixed-models digest..."


Today's Topics:

   1. Re: lmer, intercepts and offsets (Daniel Farewell)


----------------------------------------------------------------------

Message: 1
Date: Tue, 14 Aug 2007 16:39:02 +0000 (GMT)
From: Daniel Farewell <farewelld at cf.ac.uk>
Subject: Re: [R-sig-ME] lmer, intercepts and offsets
To: r-sig-mixed-models at r-project.org
Message-ID: <523651.84987.qm at web27101.mail.ukl.yahoo.com>
Content-Type: text/plain; charset=iso-8859-1

This is a follow-up to a thread from back in March ("lmer, intercepts and offsets"). I'm hoping (at least) to better understand how lmer works.

I'd like to "trick" lmer into thinking it has converged to certain parameter estimates. This is straightforward for variance components, making use of the 'start' parameter and using 'control' to set the number of the various kinds of iteration to zero.

My ultimate goal is to extract posterior second moments from a model "fit" where I have specified both the variance components and the fixed effects.

Obviously it is possible to dig inside the fitted model and manually alter the fixed effects, but this has no impact on the result of a call to ranef, presumably because the posterior means (and variances?) have already been calculated, and are sitting in the ranef slot of the fitted model.

My question is this: at what stage do the random effects get calculated? Simplifying greatly, at some stage lmer must calculate betahat(Omega) (the fixed effects) and ranef(Omega) (the estimated random effects) for the converged value of Omega. Does ranef(Omega) depend on the result of betahat(Omega)? If so, then presumably tinkering with the betahat(Omega) results at the appropriate point inside lmer would result in what I want. If not (that is, if the dependence on the fixed effects is indirect) what needs tinkering with?

Is there a good reason why lmer does not allow models with no fixed effects at all? With the right offset, this would be another way to achieve the same result.

[[replacing trailing spam]]

Daniel Farewell



------------------------------

_______________________________________________
R-sig-mixed-models mailing list
R-sig-mixed-models at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


End of R-sig-mixed-models Digest, Vol 8, Issue 10



------------------------------

_______________________________________________
R-sig-mixed-models mailing list
R-sig-mixed-models at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


End of R-sig-mixed-models Digest, Vol 8, Issue 13



From lunina at access.unizh.ch  Sun Aug 26 12:04:22 2007
From: lunina at access.unizh.ch (lunina at access.unizh.ch)
Date: Sun, 26 Aug 2007 12:04:22 +0200
Subject: [R-sig-ME] residuals in lme4
Message-ID: <web-9990359@idmailbe2b.unizh.ch>


Hello

I want to get the residuals of a heteroscedastic linear mixed-effects-model. 
How can I fit such one ond how is it possible to extract the residuals?

I saw that the the usual function "resid(.)" works for lmer, but not for 
lmer2. But no one of these two shows any change in the model values if I 
define some "weights". Is "weights" not yet implementet? And is there 
another possibility to calculate a weighted linear mixed-effects-model?

I already tried it with "lme(.)" of the package "nlme", but the models with 
"lme" fit much worse than those with "lmer", also if I compare the 
unweighted ones...

Thanks a lot

Monika



From bates at stat.wisc.edu  Mon Aug 27 15:29:34 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 27 Aug 2007 08:29:34 -0500
Subject: [R-sig-ME] residuals in lme4
In-Reply-To: <web-9990359@idmailbe2b.unizh.ch>
References: <web-9990359@idmailbe2b.unizh.ch>
Message-ID: <40e66e0b0708270629t335f473fm7712a7f3b4e9716d@mail.gmail.com>

On 8/26/07, lunina at access.unizh.ch <lunina at access.unizh.ch> wrote:

> Hello

> I want to get the residuals of a heteroscedastic linear mixed-effects-model.
> How can I fit such one ond how is it possible to extract the residuals?

> I saw that the the usual function "resid(.)" works for lmer, but not for
> lmer2. But no one of these two shows any change in the model values if I
> define some "weights". Is "weights" not yet implementet? And is there
> another possibility to calculate a weighted linear mixed-effects-model?

The weights argument to lmer() is for fixed weights, as in the lm()
function, not for variable weights, as in lme().  So the answer is
that if you want weights that, for example, depend on the fitted
values, then that is not implemented in lmer().

> I already tried it with "lme(.)" of the package "nlme", but the models with
> "lme" fit much worse than those with "lmer", also if I compare the
> unweighted ones...
>
> Thanks a lot
>
> Monika
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From bates at stat.wisc.edu  Mon Aug 27 15:45:22 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 27 Aug 2007 08:45:22 -0500
Subject: [R-sig-ME] R mixed effects problem
In-Reply-To: <854873.59759.qm@web54102.mail.re2.yahoo.com>
References: <854873.59759.qm@web54102.mail.re2.yahoo.com>
Message-ID: <40e66e0b0708270645s4c9de84dl29b337abf529f6f0@mail.gmail.com>

On 8/26/07, Iasonas Lamprianou <lamprianou at yahoo.com> wrote:
> Deat friends, I still need some answers on the following questions. I posted this email but I got no response, it would be great if any one of you could give me some hints. Also, I noticed that the resid function "is not yet implemented" in lmer for the bionomial model. Has this been solved in lme2?

> jason

> ----- Forwarded Message ----
> From: Iasonas Lamprianou <lamprianou at yahoo.com>
> To: r-sig-mixed-models at r-project.org
> Sent: Friday, 24 August, 2007 12:55:10 PM
> Subject: Re: R-sig-mixed-models Digest, Vol 8, Issue 13

> Dear friends, in the following example, I am testing teacher effect. So, the teacher is affecting the score of the pupils, and the items are also random effects. The ID is the id of the pupils. Year (pupils are either year6 ot year7) and age and gender may play some role on the test score.

> Question 1: In the following example, I am not sure what the Correlation of Fixed Effects is. Could someone please explain it to me? How do I use these numbers?

The estimators of the fixed-effects parameters are random variables
and can be correlated.  This table shows the correlation of the
estimators, evaluated at the estimates.

It would be hard to go into more detail without explaining some
elementary statistics, which would raise the question of why you are
trying to fit very sophisticated statistical models if you are unaware
of basic properties of statistical models.  We can answer questions
about the software but it is not realistic to expect that we will
provide a tutorial on statistics via an email list.

> Question 2: Also, what is the meaning of this statment? Estimated scale (compare to  1 )  0.865952 . How do I interpet this?

The log-likelihood for a generalized linear mixed model cannot be
evaluated explicitly - it must be approximated.  One of the
approximations, called penalized quasi-likelihood (PQL), provides an
estimate of a scale parameter that should be fixed at 1 for a GLMM
model with binomial or Poisson responses.  The apparent value of this
parameter is returned.  Values much larger than 1 indicate
over-dispersion relative to the assumed conditional distribution of
the responses.  Values less than 1 indicate under-dispersion.

It is not uncommon to have moderate under-dispersion in GLMMs because
the variability in the data can be modeled by random effects or by the
per-observation noise.

> Thanks
>
>
>
> Generalized linear mixed model fit using Laplace
> Formula: SCORE ~ YEAR + AGE + GENDER + (1 | ITEM) + (1 | ID) + (1 | TEACHER)
>    Data: data2
> Family: binomial(logit link)
>   AIC  BIC logLik deviance
> 4979 5027  -2482     4965
> Random effects:
> Groups  Name Variance Std.Dev.
> ID           0.508153 0.71285
> TEACHER      0.039018 0.19753
> ITEM         3.874608 1.96840
> number of obs: 7043, groups: ID, 754; TEACHER, 29; ITEM, 10
> Estimated scale (compare to  1 )  0.865952
> Fixed effects:
>                  Estimate Std. Error z value Pr(>|z|)
> (Intercept)    -1.6334597  0.6457887 -2.5294   0.0114 *
> YEAR[T.Year 7]  0.0495903  0.1262880  0.3927   0.6946
> AGE             0.0004811  0.0009579  0.5023   0.6155
> GENDER[T.girl] -0.0546018  0.0924347 -0.5907   0.5547
> ---
> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
> Correlation of Fixed Effects:
>             (Intr) YEAR[7 AGE
> YEAR[T.Yr7] -0.101
> AGE         -0.203 -0.095
> GENDER[T.g] -0.063 -0.067 -0.008
>
>
>
> Dr. Iasonas Lamprianou
> Department of Education
> The University of Manchester
> Oxford Road, Manchester M13 9PL, UK
> Tel. 0044 161 275 3485
> iasonas.lamprianou at manchester.ac.uk
>
>
> ----- Original Message ----
> From: "r-sig-mixed-models-request at r-project.org" <r-sig-mixed-models-request at r-project.org>
> To: r-sig-mixed-models at r-project.org
> Sent: Wednesday, 22 August, 2007 1:00:17 PM
> Subject: R-sig-mixed-models Digest, Vol 8, Issue 13
>
>
> Send R-sig-mixed-models mailing list submissions to
>     r-sig-mixed-models at r-project.org
>
> To subscribe or unsubscribe via the World Wide Web, visit
>     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> or, via email, send a message with subject or body 'help' to
>     r-sig-mixed-models-request at r-project.org
>
> You can reach the person managing the list at
>     r-sig-mixed-models-owner at r-project.org
>
> When replying, please edit your Subject line so it is more specific
> than "Re: Contents of R-sig-mixed-models digest..."
>
>
> Today's Topics:
>
>    1. Re: R-sig-mixed-models Digest, Vol 8, Issue 10
>       (Iasonas Lamprianou)
>
>
> ----------------------------------------------------------------------
>
> Message: 1
> Date: Tue, 21 Aug 2007 03:35:05 -0700 (PDT)
>
> Subject: Re: [R-sig-ME] R-sig-mixed-models Digest, Vol 8, Issue 10
> To: r-sig-mixed-models at r-project.org
> Message-ID: <607384.7411.qm at web54103.mail.re2.yahoo.com>
> Content-Type: text/plain; charset=iso-8859-1
>
> Hi all, I have a question regarding the paper
> Estimating the Multilevel Rasch Model: With the
> lme4 Package
> by Doran, Bates etc al.
> I would be greateful if someone could answer these questions, I am still a beginner.
>
> In page 10, they fitted a model with no intercept. (1) What might be the motivation for this?  (1) How would the interpretation be different if they had included am intercept? (3) How may I derive the table of residuals (observed-predicted)? (4) How can I estimate/evaluate the fit of individual items, subjects or companies?
>
> I know that I have many questions, but I really love lme4 and I would like to routinely use it in my research. I have a great education dataset which I would love to analyse. Any experts wishing a joint publication? My motivation is to learn as much as possible during the collaboration for this paper.
>
> Dr. Iasonas Lamprianou
> Department of Education
> The University of Manchester
> Oxford Road, Manchester M13 9PL, UK
> Tel. 0044 161 275 3485
> iasonas.lamprianou at manchester.ac.uk
>
>
> ----- Original Message ----
> From: "r-sig-mixed-models-request at r-project.org" <r-sig-mixed-models-request at r-project.org>
> To: r-sig-mixed-models at r-project.org
> Sent: Wednesday, 15 August, 2007 1:00:14 PM
> Subject: R-sig-mixed-models Digest, Vol 8, Issue 10
>
>
> Send R-sig-mixed-models mailing list submissions to
>     r-sig-mixed-models at r-project.org
>
> To subscribe or unsubscribe via the World Wide Web, visit
>     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> or, via email, send a message with subject or body 'help' to
>     r-sig-mixed-models-request at r-project.org
>
> You can reach the person managing the list at
>     r-sig-mixed-models-owner at r-project.org
>
> When replying, please edit your Subject line so it is more specific
> than "Re: Contents of R-sig-mixed-models digest..."
>
>
> Today's Topics:
>
>    1. Re: lmer, intercepts and offsets (Daniel Farewell)
>
>
> ----------------------------------------------------------------------
>
> Message: 1
> Date: Tue, 14 Aug 2007 16:39:02 +0000 (GMT)
> From: Daniel Farewell <farewelld at cf.ac.uk>
> Subject: Re: [R-sig-ME] lmer, intercepts and offsets
> To: r-sig-mixed-models at r-project.org
> Message-ID: <523651.84987.qm at web27101.mail.ukl.yahoo.com>
> Content-Type: text/plain; charset=iso-8859-1
>
> This is a follow-up to a thread from back in March ("lmer, intercepts and offsets"). I'm hoping (at least) to better understand how lmer works.
>
> I'd like to "trick" lmer into thinking it has converged to certain parameter estimates. This is straightforward for variance components, making use of the 'start' parameter and using 'control' to set the number of the various kinds of iteration to zero.
>
> My ultimate goal is to extract posterior second moments from a model "fit" where I have specified both the variance components and the fixed effects.
>
> Obviously it is possible to dig inside the fitted model and manually alter the fixed effects, but this has no impact on the result of a call to ranef, presumably because the posterior means (and variances?) have already been calculated, and are sitting in the ranef slot of the fitted model.
>
> My question is this: at what stage do the random effects get calculated? Simplifying greatly, at some stage lmer must calculate betahat(Omega) (the fixed effects) and ranef(Omega) (the estimated random effects) for the converged value of Omega. Does ranef(Omega) depend on the result of betahat(Omega)? If so, then presumably tinkering with the betahat(Omega) results at the appropriate point inside lmer would result in what I want. If not (that is, if the dependence on the fixed effects is indirect) what needs tinkering with?
>
> Is there a good reason why lmer does not allow models with no fixed effects at all? With the right offset, this would be another way to achieve the same result.
>
> [[replacing trailing spam]]
>
> Daniel Farewell
>
>
>
> ------------------------------
>
> _______________________________________________
> R-sig-mixed-models mailing list
> R-sig-mixed-models at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
> End of R-sig-mixed-models Digest, Vol 8, Issue 10
>
>
>
> ------------------------------
>
> _______________________________________________
> R-sig-mixed-models mailing list
> R-sig-mixed-models at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
> End of R-sig-mixed-models Digest, Vol 8, Issue 13
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From bolker at zoo.ufl.edu  Tue Aug 28 03:49:07 2007
From: bolker at zoo.ufl.edu (Ben Bolker)
Date: Mon, 27 Aug 2007 21:49:07 -0400
Subject: [R-sig-ME] boneheaded (?) question about SS in anova (lmer vs lme)
Message-ID: <46D37F13.9070109@zoo.ufl.edu>


  I've been working through some basic nested analyses of variance
just to try to understand the details, and where lme(r)-style analyses
depart from classical F-ratio tests.

  I'm having trouble understanding the results of anova(lmer(...)) ,
which don't match up in any way I can figure out with direct
calculations or with the results of lme().

Andrew and Underwood did a simple nested experiment on urchins
and algal cover -- 4 treatments, 4 patches per treatment, 5 samples
per patch.

## get data
datafile <- "http://www.zoology.unimelb.edu.au/qkstats/chpt9/andrew.csv"
urchins <- read.csv(file=datafile,
                    colClasses=c(rep("factor",3),"numeric"))

## calculate SS/F statistic by hand
attach(urchins)
tmeans <- tapply(ALGAE,TREAT,mean)[c(1,4,3,2)]
pmeans <- tapply(ALGAE,PATCH,mean)[c(1,9:16,2:8)]
ss.treat <- 20*sum((tmeans-mean(ALGAE))^2)
ss.patch <- 5*sum((rep(tmeans,each=4)-pmeans)^2)
fratio = (ss.treat/3)/(ss.patch/12)
c(ss.treat,ss.patch,fratio)
## results, rounded: 14429.14 21241.95     2.72
detach(urchins)

## same model with lme
library(nlme)
lme1 = lme(ALGAE~TREAT,random=~1|PATCH,data=urchins,method="REML")
anova(lme1)
detach("package:nlme")

##             numDF denDF   F-value p-value
## (Intercept)     1    64 18.555081  0.0001
## TREAT           3    12  2.717102  0.0913

F value agrees with hand calculation above
(for what it's worth, line 2 of ?anova.lme
states that result of applying anova.lme to
a single lme object will include the sums of squares,
which seems to be false)


## 3. lmer: all parameter estimates agree with
##    lme fit, but ANOVA table is very odd --
##    don't know where these SS numbers come from??

library(lme4)
anova(lmer(ALGAE~TREAT+(1|PATCH),data=urchins,method="REML"))
detach("package:lme4")

## Analysis of Variance Table
##       Df  Sum Sq Mean Sq
## TREAT  3 2434.27  811.42

why is treatment SS not the same as ss.treat?
(ss.treat also matches the results of aov())

  Hope I haven't done something boneheaded, nor included too much
nor too little information.

  thanks
    Ben Bolker



From bates at stat.wisc.edu  Fri Aug 31 23:10:11 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Fri, 31 Aug 2007 16:10:11 -0500
Subject: [R-sig-ME] boneheaded (?) question about SS in anova (lmer vs
	lme)
In-Reply-To: <46D37F13.9070109@zoo.ufl.edu>
References: <46D37F13.9070109@zoo.ufl.edu>
Message-ID: <40e66e0b0708311410m34ba427fm2121821df02d8227@mail.gmail.com>

On 8/27/07, Ben Bolker <bolker at zoo.ufl.edu> wrote:

>   I've been working through some basic nested analyses of variance
> just to try to understand the details, and where lme(r)-style analyses
> depart from classical F-ratio tests.

Thanks for the questions, Ben, and for the well-constructed example.

Before going into detail about how the analysis of variance table is
constructed for an lmer model, I thought that I would do a bit of
plotting of the data.  Some of the plots indicate that a linear mixed
model is probably not appropriate.  Consider

library(lattice)
print(dotplot(reorder(PATCH, ALGAE) ~ ALGAE,  urchins, ylab = "Patch"))

and the same plot for the TREAT variable (PDF files attached).

I would be much more inclined to use a generalized linear mixed model
with a Poisson conditional distribution than a normal conditional
distribution for these data.

>   I'm having trouble understanding the results of anova(lmer(...)) ,
> which don't match up in any way I can figure out with direct
> calculations or with the results of lme().
>
> Andrew and Underwood did a simple nested experiment on urchins
> and algal cover -- 4 treatments, 4 patches per treatment, 5 samples
> per patch.
>
> ## get data
> datafile <- "http://www.zoology.unimelb.edu.au/qkstats/chpt9/andrew.csv"
> urchins <- read.csv(file=datafile,
>                     colClasses=c(rep("factor",3),"numeric"))
>
> ## calculate SS/F statistic by hand
> attach(urchins)
> tmeans <- tapply(ALGAE,TREAT,mean)[c(1,4,3,2)]
> pmeans <- tapply(ALGAE,PATCH,mean)[c(1,9:16,2:8)]
> ss.treat <- 20*sum((tmeans-mean(ALGAE))^2)
> ss.patch <- 5*sum((rep(tmeans,each=4)-pmeans)^2)
> fratio = (ss.treat/3)/(ss.patch/12)
> c(ss.treat,ss.patch,fratio)
> ## results, rounded: 14429.14 21241.95     2.72
> detach(urchins)
>
> ## same model with lme
> library(nlme)
> lme1 = lme(ALGAE~TREAT,random=~1|PATCH,data=urchins,method="REML")
> anova(lme1)
> detach("package:nlme")
>
> ##             numDF denDF   F-value p-value
> ## (Intercept)     1    64 18.555081  0.0001
> ## TREAT           3    12  2.717102  0.0913
>
> F value agrees with hand calculation above
> (for what it's worth, line 2 of ?anova.lme
> states that result of applying anova.lme to
> a single lme object will include the sums of squares,
> which seems to be false)
>
>
> ## 3. lmer: all parameter estimates agree with
> ##    lme fit, but ANOVA table is very odd --
> ##    don't know where these SS numbers come from??
>
> library(lme4)
> anova(lmer(ALGAE~TREAT+(1|PATCH),data=urchins,method="REML"))
> detach("package:lme4")
>
> ## Analysis of Variance Table
> ##       Df  Sum Sq Mean Sq
> ## TREAT  3 2434.27  811.42
>
> why is treatment SS not the same as ss.treat?
> (ss.treat also matches the results of aov())
>
>   Hope I haven't done something boneheaded, nor included too much
> nor too little information.
>
>   thanks
>     Ben Bolker
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Urchins1.pdf
Type: application/pdf
Size: 8948 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20070831/aef3e375/attachment.pdf>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Urchins2.pdf
Type: application/pdf
Size: 7926 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20070831/aef3e375/attachment-0001.pdf>

From mdu at ceh.ac.uk  Mon Sep  3 14:45:54 2007
From: mdu at ceh.ac.uk (Mike Dunbar)
Date: Mon, 03 Sep 2007 13:45:54 +0100
Subject: [R-sig-ME] explaining lme variance component results
Message-ID: <s6dc101d.036@wpo.nerc.ac.uk>

Dear All

Ben's recent question "boneheaded (?) question about SS in anova (lmer vs lme)", prompted me to post this very marginally related question. Time and time again I come across problems presenting results of multilevel models fitted with lme to either scientists not familiar with random effects, or only familiar with random effects in the traditional balanced, linear anova context. It's the latter I'm having particular troubles with at the moment. 

Recently I've had a manuscript come back from review from an ecology journal where the reviewers and also some of my co-workers fall into the latter category. The analysis in brief is a variance components analysis, with 4 nested random effects, hence no fixed effects. I illustrated the results showing the variance component at each level, including the residual. I then undertook likelihood ratio tests for each random effect by deletion. The results are a little strange in that in one instance a higher level component (MONTH: 25% of the total variance) is significant, but a lower level component (POLE: 29% of the total variance) is not. The results are also a little strange as for the highest level factor, MONTH, there are only 4 levels, hence I'd have thought that its variance component would be fairly imprecise and hence less likely to be significant. I'm prepared to believe these results as I think the deletion tests are entirely sound, but I'm not sure if I understand the reasons. I think its inherent in the nested design and the degrees of freedom, but I'm having a hell of a job explaining it without alot of arm waving. One way of course would be to provide an explanation using F-tests and expected mean squares, but I don't know how to do that for such a complex design.

Data and analysis below. If the data get mangled somehow then I'm happy to email as an attachment.

I posted a similar question on the multilevel list a few weeks ago, but had no replies, hence this is another try to a different audience with a slightly different question. I'm aware this isn't a comparison of lmer and lme (hope that doesn't matter), and I'm also aware that a GLMM analysis may be more appropriate, but I want to understand fully this more basic analysis first!

regards, and thanks in advance for any replies

Mike Dunbar


# analysis (run data below first)
varcor.insects <- lme(log(insectdens+1) ~ 1, random=~1|MONTH/TIME/TRANSECT/POLE, data=temp)
VarCorr(varcor.insects)
# variance components: MONTH: 0.757, TIME: 1.074, TRANSECT: 0.000, POLE: 0.898, resid: 0.307 

varcor.insects.nopole <- lme(log(insectdens+1) ~ 1, random=~1|MONTH/TIME/TRANSECT, data=temp)
varcor.insects.nomonth <- lme(log(insectdens+1) ~ 1, random=~1|TIME/TRANSECT/POLE, data=temp)
varcor.insects.notime <- lme(log(insectdens+1) ~ 1, random=~1|MONTH/TRANSECT/POLE, data=temp)

anova(varcor.insects.nomonth, varcor.insects)
anova(varcor.insects.notime, varcor.insects)
anova(varcor.insects.nopole,varcor.insects)
# variance component for pole is greater than that for month, yet month is significant, pole is not



# data: run this first
temp <-
structure(list(MONTH = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
4L, 4L, 4L, 4L, 4L, 4L, 4L), .Label = c("4", "5", "6", "7"), class = "factor"), 
    TRANSECT = structure(c(1L, 1L, 1L, 1L, 2L, 2L, 3L, 3L, 3L, 
    3L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L, 1L, 1L, 1L, 2L, 2L, 3L, 
    3L, 3L, 3L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L, 1L, 1L, 1L, 1L, 
    2L, 2L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L, 1L, 
    1L, 1L, 1L, 2L, 2L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 5L, 5L, 
    5L, 5L, 1L, 1L, 1L, 1L, 2L, 2L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 
    4L, 5L, 5L, 5L, 5L, 1L, 1L, 1L, 1L, 2L, 2L, 3L, 3L, 3L, 3L, 
    4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L, 1L, 1L, 1L, 1L, 2L, 2L, 3L, 
    3L, 3L, 3L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L, 1L, 1L, 1L, 1L, 
    2L, 2L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 5L, 5L, 5L, 5L, 1L, 1L, 
    1L, 1L, 2L, 2L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 
    5L, 1L, 1L, 1L, 1L, 2L, 2L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 
    5L, 5L, 5L, 5L, 1L, 1L, 1L, 1L, 2L, 2L, 3L, 3L, 3L, 3L, 4L, 
    4L, 4L, 4L, 5L, 5L, 5L, 5L, 1L, 1L, 1L, 1L, 2L, 2L, 3L, 3L, 
    3L, 3L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L, 1L, 1L, 1L, 1L, 2L, 
    2L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L, 1L, 1L, 
    1L, 1L, 2L, 2L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 
    5L, 1L, 1L, 1L, 1L, 2L, 2L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 
    5L, 5L, 5L, 5L, 1L, 1L, 1L, 1L, 2L, 2L, 3L, 3L, 3L, 3L, 4L, 
    4L, 4L, 4L, 5L, 5L, 5L, 5L), .Label = c("1", "2", "3", "4", 
    "5"), class = "factor"), POLE = structure(c(1L, 2L, 3L, 4L, 
    5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 
    18L, 2L, 3L, 4L, 5L, 5L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 
    14L, 15L, 16L, 17L, 18L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 
    9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 1L, 2L, 
    3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 
    16L, 17L, 18L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 
    12L, 13L, 14L, 15L, 16L, 17L, 18L, 1L, 2L, 3L, 4L, 5L, 6L, 
    7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 
    1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 
    15L, 16L, 17L, 18L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 
    11L, 13L, 14L, 15L, 16L, 17L, 18L, 1L, 2L, 3L, 4L, 5L, 6L, 
    7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 
    1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 
    15L, 16L, 17L, 18L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 
    11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 1L, 2L, 3L, 4L, 5L, 
    6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 
    1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 
    15L, 16L, 17L, 18L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 
    11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 1L, 2L, 3L, 4L, 5L, 
    6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 
    1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 
    15L, 16L, 17L, 18L), .Label = c("11", "12", "13", "14", "23", 
    "24", "31", "32", "33", "34", "41", "42", "43", "44", "51", 
    "52", "53", "54"), class = "factor"), TIME = structure(c(1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
    4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
    4L, 4L, 4L, 4L, 4L, 4L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
    4L, 4L, 4L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 
    4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L
    ), .Label = c("1", "2", "3", "4"), class = "factor"), insectdens = c(0, 
    63.64, 14.57, 22.5, 0, 107.6, 87.16, 22.24, 51.92, 42.1, 
    0, 15.78, 43.02, 9.98, 7.47, 38.92, 11.78, 0, 44.61, 45.9, 
    26.78, 80.2, 37.4, 17.58, 8.94, 54.7, 141.89, 10.39, 14.6, 
    158.34, 9.52, 14.36, 47.94, 12.26, 31.44, 104.37, 74.4, 73.38, 
    94.36, 120.26, 48.12, 264.87, 129.36, 107.03, 145.53, 95.2, 
    116.55, 492, 140.4, 111.28, 104.8, 59.76, 91.92, 12.92, 22.6, 
    53.6, 102.6, 151.92, 0, 0, 34.96, 21.38, 60.4, 16.9, 24.96, 
    263.76, 37.12, 30.76, 26.24, 25.88, 7.2, 48.87, 28.1, 44.28, 
    67.26, 0, 50.49, 0, 0, 10.82, 27.06, 9.09, 13.56, 13.25, 
    31.74, 11.98, 12.08, 30.55, 31.16, 16.35, 78.15, 13.54, 80.44, 
    104.55, 37.32, 107.7, 21.52, 22.28, 55.6, 40.72, 15.12, 25.44, 
    87.36, 19.94, 78.32, 13.04, 40.55, 14.37, 34.68, 69.4, 62.28, 
    117.96, 18.27, 34.74, 69.86, 100.89, 95.7, 0, 129.6, 147.4, 
    92.16, 76.1, 52.78, 52.32, 46.7, 49.41, 54.8, 59.2, 0, 0, 
    15.89, 35.42, 8.54, 52.98, 48.81, 49.85, 64.6, 20.2, 80.29, 
    38.52, 17.28, 41.55, 237.25, 38.88, 25.69, 0, 0, 0, 467.64, 
    36, 112.05, 42.08, 26.86, 0, 17.48, 34.95, 43.88, 33.76, 
    23.24, 16.29, 189.99, 365.6, 329.29, 228, 140.91, 433.84, 
    228.9, 130.3, 609.9, 371.88, 360.36, 338.91, 139.15, 285.9, 
    253.68, 353.35, 839.16, 717.42, 2081.2, 1052.03, 1276.65, 
    512.25, 614.46, 479.52, 3020.4, 885.96, 932.49, 1476.09, 
    576.46, 568.8, 712.53, 1864.56, 792.05, 1807.52, 899.25, 
    1487.7, 166.5, 78.7, 169.2, 99.35, 176.85, 104.6, 0, 193.05, 
    204.49, 201.9, 49.71, 93.06, 75.72, 207.79, 73.26, 96.4, 
    227.63, 141.7, 98.25, 58.4, 30.84, 141.72, 277.16, 534.19, 
    508.04, 68.44, 215.37, 0, 48.68, 81.36, 65.07, 133.5, 70.28, 
    79.62, 107.73, 30.14, 407.76, 422.24, 317.7, 241.5, 644.49, 
    1104.24, 268.24, 449.25, 475.57, 311.63, 461.3, 247.69, 395.25, 
    399.84, 529.48, 440.82, 394.56, 322, 353.5, 452.4, 699.72, 
    89.04, 347.6, 563.67, 456.88, 513, 440.37, 398.86, 428, 398.06, 
    438.75, 367.9, 501.48, 522.6, 616.11, 309.96, 232.08, 198.06, 
    109.59, 49.59, 152.08, 617.83, 372.75, 66.81, 68.28, 157.48, 
    46.24, 99.18, 158.05, 91.68, 112.62, 98.21, 117.54, 77.3)), .Names = c("MONTH", 
"TRANSECT", "POLE", "TIME", "insectdens"), class = "data.frame", row.names = c(1L, 
4L, 7L, 9L, 13L, 16L, 19L, 22L, 25L, 28L, 31L, 34L, 37L, 40L, 
43L, 44L, 46L, 49L, 55L, 58L, 60L, 64L, 67L, 70L, 73L, 76L, 79L, 
82L, 85L, 88L, 91L, 94L, 95L, 97L, 100L, 103L, 106L, 109L, 111L, 
115L, 118L, 121L, 124L, 127L, 130L, 133L, 136L, 139L, 142L, 145L, 
146L, 148L, 151L, 154L, 157L, 160L, 162L, 166L, 169L, 172L, 175L, 
178L, 181L, 184L, 187L, 190L, 193L, 196L, 197L, 199L, 202L, 205L, 
208L, 211L, 213L, 217L, 220L, 223L, 226L, 229L, 232L, 235L, 238L, 
241L, 244L, 247L, 248L, 250L, 253L, 256L, 259L, 262L, 264L, 268L, 
271L, 274L, 277L, 280L, 283L, 286L, 289L, 292L, 295L, 298L, 299L, 
301L, 304L, 307L, 310L, 313L, 315L, 319L, 322L, 325L, 328L, 331L, 
334L, 337L, 340L, 343L, 346L, 349L, 350L, 352L, 355L, 358L, 361L, 
364L, 366L, 370L, 373L, 376L, 379L, 382L, 385L, 388L, 394L, 397L, 
400L, 401L, 403L, 406L, 409L, 412L, 415L, 417L, 421L, 424L, 427L, 
430L, 433L, 436L, 439L, 442L, 445L, 448L, 451L, 452L, 454L, 457L, 
460L, 463L, 466L, 468L, 472L, 475L, 478L, 481L, 484L, 487L, 490L, 
493L, 496L, 499L, 502L, 503L, 505L, 508L, 511L, 514L, 517L, 519L, 
523L, 526L, 529L, 532L, 535L, 538L, 541L, 544L, 547L, 550L, 553L, 
554L, 556L, 559L, 562L, 565L, 568L, 570L, 574L, 577L, 580L, 583L, 
586L, 589L, 592L, 595L, 598L, 601L, 604L, 605L, 607L, 610L, 613L, 
616L, 619L, 621L, 625L, 628L, 631L, 634L, 637L, 640L, 643L, 646L, 
649L, 652L, 655L, 656L, 658L, 661L, 664L, 667L, 670L, 672L, 676L, 
679L, 682L, 685L, 688L, 691L, 694L, 697L, 700L, 703L, 706L, 707L, 
709L, 712L, 715L, 718L, 721L, 723L, 727L, 730L, 733L, 736L, 739L, 
742L, 745L, 748L, 751L, 754L, 757L, 758L, 760L, 763L, 766L, 769L, 
772L, 774L, 778L, 781L, 784L, 787L, 790L, 793L, 796L, 799L, 802L, 
805L, 808L, 809L, 811L, 814L))




-- 
This message (and any attachments) is for the recipient only...{{dropped}}



From kw.statr at gmail.com  Tue Sep  4 18:38:17 2007
From: kw.statr at gmail.com (Kevin Wright)
Date: Tue, 4 Sep 2007 11:38:17 -0500
Subject: [R-sig-ME] explaining lme variance component results
In-Reply-To: <s6dc101d.036@wpo.nerc.ac.uk>
References: <s6dc101d.036@wpo.nerc.ac.uk>
Message-ID: <c968588d0709040938h6edbbda9y7782675ffd3236f6@mail.gmail.com>

Mike,

I find asinh(x/2) to be an interesting (more palatable?) alternative
to log(x+1).

A couple of other comments inserted below:

Kevin Wright


On 9/3/07, Mike Dunbar <mdu at ceh.ac.uk> wrote:
> Dear All
>
> Ben's recent question "boneheaded (?) question about SS in anova (lmer vs lme)", prompted me to post this very marginally related question. Time and time again I come across problems presenting results of multilevel models fitted with lme to either scientists not familiar with random effects, or only familiar with random effects in the traditional balanced, linear anova context. It's the latter I'm having particular troubles with at the moment.
>
> Recently I've had a manuscript come back from review from an ecology journal where the reviewers and also some of my co-workers fall into the latter category. The analysis in brief is a variance components analysis, with 4 nested random effects, hence no fixed effects. I illustrated the results showing the variance component at each level, including the residual. I then undertook likelihood ratio tests for each random effect by deletion. The results are a little strange in that in one instance a higher level component (MONTH: 25% of the total variance) is significant, but a lower level component (POLE: 29% of the total variance) is not. The results are also a little strange as for the highest level factor, MONTH, there are only 4 levels, hence I'd have thought that its variance component would be fairly imprecise and hence less likely to be significant. I'm prepared to believe these results as I think the deletion tests are entirely sound, but I'm not sure if I understand th!
>  e reasons. I think its inherent in the nested design and the degrees of freedom, but I'm having a hell of a job explaining it without alot of arm waving. One way of course would be to provide an explanation using F-tests and expected mean squares, but I don't know how to do that for such a complex design.

In my experience with biological data, factors that have levels that
are widely (temporal/spatial) separated are often more variable than
factors with levels that are closer together.  In your data, I would
(a priori) expect MONTH is more likely to be significant than POLE.

Have you plotted this data?  I often find dotplots very useful for
exploring/understanding data that have a few factors.  For example:

levels(temp$MONTH) <- paste("Mo",levels(temp$MONTH),sep="")
levels(temp$POLE) <- paste("Po",levels(temp$POLE),sep="")
levels(temp$TRANSECT) <- paste("Tr",levels(temp$TRANSECT),sep="")
levels(temp$TIME) <- paste("Ti",levels(temp$TIME),sep="")

# Time2 and Time3 have big differences between months
dotplot(TRANSECT~y|TIME*MONTH, data=temp)
# Pole-to-pole variation is often small
dotplot(POLE~y|MONTH*TIME*TRANSECT, data=temp,
        scales=list(y=list(cex=.5,relation="free")))

I often try many different arrangements of the panels/lines to find
the most informative view.

The zero values of insectdens look odd, given the
not-so-unlike-Gaussian distribution of the other values.

>
> Data and analysis below. If the data get mangled somehow then I'm happy to email as an attachment.
>
> I posted a similar question on the multilevel list a few weeks ago, but had no replies, hence this is another try to a different audience with a slightly different question. I'm aware this isn't a comparison of lmer and lme (hope that doesn't matter), and I'm also aware that a GLMM analysis may be more appropriate, but I want to understand fully this more basic analysis first!
>
> regards, and thanks in advance for any replies
>
> Mike Dunbar
>
>
> # analysis (run data below first)
> varcor.insects <- lme(log(insectdens+1) ~ 1, random=~1|MONTH/TIME/TRANSECT/POLE, data=temp)
> VarCorr(varcor.insects)
> # variance components: MONTH: 0.757, TIME: 1.074, TRANSECT: 0.000, POLE: 0.898, resid: 0.307
>
> varcor.insects.nopole <- lme(log(insectdens+1) ~ 1, random=~1|MONTH/TIME/TRANSECT, data=temp)
> varcor.insects.nomonth <- lme(log(insectdens+1) ~ 1, random=~1|TIME/TRANSECT/POLE, data=temp)
> varcor.insects.notime <- lme(log(insectdens+1) ~ 1, random=~1|MONTH/TRANSECT/POLE, data=temp)
>
> anova(varcor.insects.nomonth, varcor.insects)
> anova(varcor.insects.notime, varcor.insects)
> anova(varcor.insects.nopole,varcor.insects)
> # variance component for pole is greater than that for month, yet month is significant, pole is not
>
>
>
> # data: run this first
> temp <-
> structure(list(MONTH = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L,
> 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
> 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
> 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
> 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
> 4L, 4L, 4L, 4L, 4L, 4L, 4L), .Label = c("4", "5", "6", "7"), class = "factor"),
>     TRANSECT = structure(c(1L, 1L, 1L, 1L, 2L, 2L, 3L, 3L, 3L,
>     3L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L, 1L, 1L, 1L, 2L, 2L, 3L,
>     3L, 3L, 3L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L, 1L, 1L, 1L, 1L,
>     2L, 2L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L, 1L,
>     1L, 1L, 1L, 2L, 2L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 5L, 5L,
>     5L, 5L, 1L, 1L, 1L, 1L, 2L, 2L, 3L, 3L, 3L, 3L, 4L, 4L, 4L,
>     4L, 5L, 5L, 5L, 5L, 1L, 1L, 1L, 1L, 2L, 2L, 3L, 3L, 3L, 3L,
>     4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L, 1L, 1L, 1L, 1L, 2L, 2L, 3L,
>     3L, 3L, 3L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L, 1L, 1L, 1L, 1L,
>     2L, 2L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 5L, 5L, 5L, 5L, 1L, 1L,
>     1L, 1L, 2L, 2L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 5L, 5L, 5L,
>     5L, 1L, 1L, 1L, 1L, 2L, 2L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L,
>     5L, 5L, 5L, 5L, 1L, 1L, 1L, 1L, 2L, 2L, 3L, 3L, 3L, 3L, 4L,
>     4L, 4L, 4L, 5L, 5L, 5L, 5L, 1L, 1L, 1L, 1L, 2L, 2L, 3L, 3L,
>     3L, 3L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L, 1L, 1L, 1L, 1L, 2L,
>     2L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L, 1L, 1L,
>     1L, 1L, 2L, 2L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 5L, 5L, 5L,
>     5L, 1L, 1L, 1L, 1L, 2L, 2L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L,
>     5L, 5L, 5L, 5L, 1L, 1L, 1L, 1L, 2L, 2L, 3L, 3L, 3L, 3L, 4L,
>     4L, 4L, 4L, 5L, 5L, 5L, 5L), .Label = c("1", "2", "3", "4",
>     "5"), class = "factor"), POLE = structure(c(1L, 2L, 3L, 4L,
>     5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L,
>     18L, 2L, 3L, 4L, 5L, 5L, 7L, 8L, 9L, 10L, 11L, 12L, 13L,
>     14L, 15L, 16L, 17L, 18L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L,
>     9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 1L, 2L,
>     3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L,
>     16L, 17L, 18L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L,
>     12L, 13L, 14L, 15L, 16L, 17L, 18L, 1L, 2L, 3L, 4L, 5L, 6L,
>     7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L,
>     1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L,
>     15L, 16L, 17L, 18L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L,
>     11L, 13L, 14L, 15L, 16L, 17L, 18L, 1L, 2L, 3L, 4L, 5L, 6L,
>     7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L,
>     1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L,
>     15L, 16L, 17L, 18L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L,
>     11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 1L, 2L, 3L, 4L, 5L,
>     6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L,
>     1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L,
>     15L, 16L, 17L, 18L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L,
>     11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 1L, 2L, 3L, 4L, 5L,
>     6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L,
>     1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L,
>     15L, 16L, 17L, 18L), .Label = c("11", "12", "13", "14", "23",
>     "24", "31", "32", "33", "34", "41", "42", "43", "44", "51",
>     "52", "53", "54"), class = "factor"), TIME = structure(c(1L,
>     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>     1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>     2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
>     3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
>     4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 1L, 1L, 1L, 1L, 1L,
>     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L,
>     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>     2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
>     3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
>     4L, 4L, 4L, 4L, 4L, 4L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L,
>     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L,
>     3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
>     4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
>     4L, 4L, 4L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>     1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L,
>     3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L,
>     4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L
>     ), .Label = c("1", "2", "3", "4"), class = "factor"), insectdens = c(0,
>     63.64, 14.57, 22.5, 0, 107.6, 87.16, 22.24, 51.92, 42.1,
>     0, 15.78, 43.02, 9.98, 7.47, 38.92, 11.78, 0, 44.61, 45.9,
>     26.78, 80.2, 37.4, 17.58, 8.94, 54.7, 141.89, 10.39, 14.6,
>     158.34, 9.52, 14.36, 47.94, 12.26, 31.44, 104.37, 74.4, 73.38,
>     94.36, 120.26, 48.12, 264.87, 129.36, 107.03, 145.53, 95.2,
>     116.55, 492, 140.4, 111.28, 104.8, 59.76, 91.92, 12.92, 22.6,
>     53.6, 102.6, 151.92, 0, 0, 34.96, 21.38, 60.4, 16.9, 24.96,
>     263.76, 37.12, 30.76, 26.24, 25.88, 7.2, 48.87, 28.1, 44.28,
>     67.26, 0, 50.49, 0, 0, 10.82, 27.06, 9.09, 13.56, 13.25,
>     31.74, 11.98, 12.08, 30.55, 31.16, 16.35, 78.15, 13.54, 80.44,
>     104.55, 37.32, 107.7, 21.52, 22.28, 55.6, 40.72, 15.12, 25.44,
>     87.36, 19.94, 78.32, 13.04, 40.55, 14.37, 34.68, 69.4, 62.28,
>     117.96, 18.27, 34.74, 69.86, 100.89, 95.7, 0, 129.6, 147.4,
>     92.16, 76.1, 52.78, 52.32, 46.7, 49.41, 54.8, 59.2, 0, 0,
>     15.89, 35.42, 8.54, 52.98, 48.81, 49.85, 64.6, 20.2, 80.29,
>     38.52, 17.28, 41.55, 237.25, 38.88, 25.69, 0, 0, 0, 467.64,
>     36, 112.05, 42.08, 26.86, 0, 17.48, 34.95, 43.88, 33.76,
>     23.24, 16.29, 189.99, 365.6, 329.29, 228, 140.91, 433.84,
>     228.9, 130.3, 609.9, 371.88, 360.36, 338.91, 139.15, 285.9,
>     253.68, 353.35, 839.16, 717.42, 2081.2, 1052.03, 1276.65,
>     512.25, 614.46, 479.52, 3020.4, 885.96, 932.49, 1476.09,
>     576.46, 568.8, 712.53, 1864.56, 792.05, 1807.52, 899.25,
>     1487.7, 166.5, 78.7, 169.2, 99.35, 176.85, 104.6, 0, 193.05,
>     204.49, 201.9, 49.71, 93.06, 75.72, 207.79, 73.26, 96.4,
>     227.63, 141.7, 98.25, 58.4, 30.84, 141.72, 277.16, 534.19,
>     508.04, 68.44, 215.37, 0, 48.68, 81.36, 65.07, 133.5, 70.28,
>     79.62, 107.73, 30.14, 407.76, 422.24, 317.7, 241.5, 644.49,
>     1104.24, 268.24, 449.25, 475.57, 311.63, 461.3, 247.69, 395.25,
>     399.84, 529.48, 440.82, 394.56, 322, 353.5, 452.4, 699.72,
>     89.04, 347.6, 563.67, 456.88, 513, 440.37, 398.86, 428, 398.06,
>     438.75, 367.9, 501.48, 522.6, 616.11, 309.96, 232.08, 198.06,
>     109.59, 49.59, 152.08, 617.83, 372.75, 66.81, 68.28, 157.48,
>     46.24, 99.18, 158.05, 91.68, 112.62, 98.21, 117.54, 77.3)), .Names = c("MONTH",
> "TRANSECT", "POLE", "TIME", "insectdens"), class = "data.frame", row.names = c(1L,
> 4L, 7L, 9L, 13L, 16L, 19L, 22L, 25L, 28L, 31L, 34L, 37L, 40L,
> 43L, 44L, 46L, 49L, 55L, 58L, 60L, 64L, 67L, 70L, 73L, 76L, 79L,
> 82L, 85L, 88L, 91L, 94L, 95L, 97L, 100L, 103L, 106L, 109L, 111L,
> 115L, 118L, 121L, 124L, 127L, 130L, 133L, 136L, 139L, 142L, 145L,
> 146L, 148L, 151L, 154L, 157L, 160L, 162L, 166L, 169L, 172L, 175L,
> 178L, 181L, 184L, 187L, 190L, 193L, 196L, 197L, 199L, 202L, 205L,
> 208L, 211L, 213L, 217L, 220L, 223L, 226L, 229L, 232L, 235L, 238L,
> 241L, 244L, 247L, 248L, 250L, 253L, 256L, 259L, 262L, 264L, 268L,
> 271L, 274L, 277L, 280L, 283L, 286L, 289L, 292L, 295L, 298L, 299L,
> 301L, 304L, 307L, 310L, 313L, 315L, 319L, 322L, 325L, 328L, 331L,
> 334L, 337L, 340L, 343L, 346L, 349L, 350L, 352L, 355L, 358L, 361L,
> 364L, 366L, 370L, 373L, 376L, 379L, 382L, 385L, 388L, 394L, 397L,
> 400L, 401L, 403L, 406L, 409L, 412L, 415L, 417L, 421L, 424L, 427L,
> 430L, 433L, 436L, 439L, 442L, 445L, 448L, 451L, 452L, 454L, 457L,
> 460L, 463L, 466L, 468L, 472L, 475L, 478L, 481L, 484L, 487L, 490L,
> 493L, 496L, 499L, 502L, 503L, 505L, 508L, 511L, 514L, 517L, 519L,
> 523L, 526L, 529L, 532L, 535L, 538L, 541L, 544L, 547L, 550L, 553L,
> 554L, 556L, 559L, 562L, 565L, 568L, 570L, 574L, 577L, 580L, 583L,
> 586L, 589L, 592L, 595L, 598L, 601L, 604L, 605L, 607L, 610L, 613L,
> 616L, 619L, 621L, 625L, 628L, 631L, 634L, 637L, 640L, 643L, 646L,
> 649L, 652L, 655L, 656L, 658L, 661L, 664L, 667L, 670L, 672L, 676L,
> 679L, 682L, 685L, 688L, 691L, 694L, 697L, 700L, 703L, 706L, 707L,
> 709L, 712L, 715L, 718L, 721L, 723L, 727L, 730L, 733L, 736L, 739L,
> 742L, 745L, 748L, 751L, 754L, 757L, 758L, 760L, 763L, 766L, 769L,
> 772L, 774L, 778L, 781L, 784L, 787L, 790L, 793L, 796L, 799L, 802L,
> 805L, 808L, 809L, 811L, 814L))
>
>
>
>
> --
> This message (and any attachments) is for the recipient only...{{dropped}}
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From mdu at ceh.ac.uk  Tue Sep  4 20:54:38 2007
From: mdu at ceh.ac.uk (Mike Dunbar)
Date: Tue, 04 Sep 2007 19:54:38 +0100
Subject: [R-sig-ME] explaining lme variance component results
Message-ID: <s6ddb823.054@wpo.nerc.ac.uk>

Thanks to all, a couple more comments following up on Kevin's comments below, and also ones sent to me directly.

I have plotted the data in many different ways, having spent several years (yes!) trying to work out a suitable analysis for these data. The aim of this particular analysis is to try to keep things as simple as possible, I'm aware in particular that there are differences between the behaviour of the factors across the months (so one option is a month by month analysis - which I have done but it was vetoed by co-workers for this paper so long as there's a simple interpretation as well), and also that time is generally the most important factor overall (this is already documented by others - the data are of drifting macroinvertebrates in rivers in case anyones interested).

The structure of the nesting is designed to mirror our expected view of the correlations in the data based on spatial/temporal proximity, a bit as Kevin describes below: so four times were measured across a day and the experiment repeated across four months, and for each of the 16 occasions, we have five transects, within those four poles each, and not described previously, 1-3 measures at different heights on the poles. 

Regarding the zero values: yes the normality is an assumption, I hope to do better once this initial analysis is over. What I hoped to show is despite this, and despite the assumptions of the variance components analysis, there is evidence of an effect of TRANSECT and / or POLE, once MONTH and TIME are accounted for. 

What is very pertinent (thanks John) is the fact that in the data as described, there is no replication within the lowest stratum, POLE. There was one seeming replicate, but that must be an error. This may well be the source of the problem that the POLE variance component was large but not significant.

I had thought that despite the lack of replication within POLE that it would still be possible to estimate a variance component for POLE separately from the residual. The very wooly reasoning being that the POLE component represents consistency in drift density between POLEs across TRANSECT, TIME and MONTH, and residual represents lack of consistency. 

If my reasoning above is flawed, I really don't want to ditch the POLE component, as its fairly central to the analysis, and I could bring in HEIGHT to give replication within POLE (previous data is for one height only). I'd prefer to do this as a fixed effect and I've posted below some example data/code: can anyone comment if this is valid?

Regarding the issue of magnitude of variance component/random effect vs significance, I wonder if there is more too it than that, certainly in this case we know that TIME is more important than MONTH, despite being nested, but more critically, I can show some data where the magnitude of the component doesn't seem to relate to its significance. I'll post this in a separate mail to avoid confusion, once again any comments are welcome. This gives me a real headache explaining my results to my co-workers, let alone reviewers. I ought to add that there could easily still be mistakes where, as one regarding a non-replicate 
has already been identified.

All the best again - hope this is interesting to others struggling with similar issues??

Mike




varcor.2h.insects.hf <- lme(log(insectdens+1) ~ HEIGHT, random=~1|MONTH/TIME/TRANSECT/POLE, data=temp2)
# introduce HEIGHT as a fixed effect, there are two heights per pole for some poles: hence unbalanced
VarCorr(varcor.2h.insects.hf)
# variances: MONTH - 0.639, TIME: 1.248, TRANSECT: 0.013, POLE: 0.160, Residual: 1.016

varcor.2h.insects.nospat.hf <- lme(log(insectdens+1) ~ HEIGHT, random=~1|MONTH/TIME, data=temp2)

anova(varcor.2h.insects.hf,varcor.2h.insects.nospat.hf)
# two spatial factors together marginally signficant: p=0.06, but test likely conservative 
# simulation approach for null distribution (Faraway) probably too difficult at this depth of nesting
intervals(varcor.2h.insects.hf)
# again some evidence for significance of TRANSECT, but POLE lower bound close to 0.

# delete transect term and just compare models with and without pole term
varcor.2h.insects.pole.hf <- lme(log(insectdens+1) ~ HEIGHT, random=~1|MONTH/TIME/POLE, data=temp2)
# test pole factor on its own. This is possible as pole is coded as a combination of transect and pole within transect
anova(varcor.2h.insects.pole.hf,varcor.2h.insects.nospat.hf)
# p=0.019. This would be great if analysis is valid



# read in data: this time with one or two heights per pole

temp2 <-
structure(list(MONTH = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L
), .Label = c("4", "5", "6", "7"), class = "factor"), TRANSECT = structure(c(1L, 
1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L, 5L, 5L, 
1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L, 5L, 5L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L, 5L, 
5L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L, 
5L, 5L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 
5L, 5L, 5L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 
5L, 5L, 5L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 
5L, 5L, 5L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L, 
5L, 5L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 
5L, 5L, 5L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 5L, 5L, 
5L, 5L, 5L, 5L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 5L, 
5L, 5L, 5L, 5L, 5L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
5L, 5L, 5L, 5L, 5L, 5L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
5L, 5L, 5L, 5L, 5L, 5L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
5L, 5L, 5L, 5L, 5L, 5L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
5L, 5L, 5L, 5L, 5L, 5L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
5L, 5L, 5L, 5L, 5L, 5L), .Label = c("1", "2", "3", "4", "5"), class = "factor"), 
    POLE = structure(c(1L, 1L, 2L, 2L, 3L, 4L, 4L, 5L, 5L, 6L, 
    6L, 7L, 7L, 8L, 8L, 9L, 9L, 10L, 10L, 11L, 11L, 12L, 12L, 
    13L, 13L, 14L, 14L, 15L, 16L, 17L, 17L, 18L, 18L, 1L, 2L, 
    2L, 3L, 4L, 4L, 5L, 5L, 5L, 6L, 7L, 7L, 8L, 8L, 9L, 9L, 10L, 
    10L, 11L, 11L, 12L, 12L, 13L, 13L, 14L, 14L, 15L, 16L, 17L, 
    17L, 18L, 18L, 1L, 1L, 2L, 2L, 3L, 4L, 4L, 5L, 5L, 6L, 6L, 
    7L, 7L, 8L, 8L, 9L, 9L, 10L, 10L, 11L, 11L, 12L, 12L, 13L, 
    13L, 14L, 14L, 15L, 16L, 17L, 17L, 18L, 18L, 1L, 1L, 2L, 
    2L, 3L, 4L, 4L, 5L, 5L, 6L, 6L, 7L, 7L, 8L, 8L, 9L, 9L, 10L, 
    10L, 11L, 11L, 12L, 12L, 13L, 13L, 14L, 14L, 15L, 16L, 17L, 
    17L, 18L, 18L, 1L, 1L, 2L, 2L, 3L, 4L, 4L, 5L, 5L, 6L, 6L, 
    7L, 7L, 8L, 8L, 9L, 9L, 10L, 10L, 11L, 11L, 12L, 12L, 13L, 
    13L, 14L, 14L, 15L, 16L, 17L, 17L, 18L, 18L, 1L, 2L, 2L, 
    3L, 4L, 4L, 5L, 5L, 6L, 6L, 7L, 7L, 8L, 8L, 9L, 9L, 10L, 
    10L, 11L, 11L, 12L, 12L, 13L, 13L, 14L, 14L, 15L, 16L, 17L, 
    17L, 18L, 18L, 1L, 2L, 2L, 3L, 4L, 4L, 5L, 5L, 6L, 6L, 7L, 
    7L, 8L, 8L, 9L, 9L, 10L, 10L, 11L, 11L, 12L, 12L, 13L, 13L, 
    14L, 14L, 15L, 16L, 17L, 17L, 18L, 18L, 1L, 1L, 2L, 2L, 3L, 
    4L, 4L, 5L, 5L, 6L, 6L, 7L, 7L, 8L, 8L, 9L, 9L, 10L, 10L, 
    11L, 11L, 13L, 13L, 14L, 14L, 15L, 16L, 17L, 17L, 18L, 18L, 
    1L, 1L, 2L, 2L, 3L, 4L, 4L, 5L, 5L, 6L, 6L, 7L, 7L, 8L, 8L, 
    9L, 9L, 10L, 10L, 11L, 11L, 12L, 12L, 13L, 13L, 14L, 14L, 
    15L, 16L, 17L, 17L, 18L, 18L, 1L, 1L, 2L, 2L, 3L, 4L, 4L, 
    5L, 5L, 6L, 6L, 7L, 7L, 8L, 8L, 9L, 9L, 10L, 10L, 11L, 11L, 
    12L, 12L, 13L, 13L, 14L, 14L, 15L, 16L, 17L, 17L, 18L, 18L, 
    1L, 1L, 2L, 2L, 3L, 4L, 4L, 5L, 5L, 6L, 6L, 7L, 7L, 8L, 8L, 
    9L, 9L, 10L, 10L, 11L, 11L, 12L, 12L, 13L, 13L, 14L, 14L, 
    15L, 16L, 17L, 17L, 18L, 18L, 1L, 1L, 2L, 2L, 3L, 4L, 4L, 
    5L, 5L, 6L, 6L, 7L, 7L, 8L, 8L, 9L, 9L, 10L, 10L, 11L, 11L, 
    12L, 12L, 13L, 13L, 14L, 14L, 15L, 16L, 17L, 17L, 18L, 18L, 
    1L, 2L, 2L, 3L, 4L, 4L, 5L, 5L, 6L, 6L, 7L, 7L, 8L, 8L, 9L, 
    9L, 10L, 10L, 11L, 11L, 12L, 12L, 13L, 13L, 14L, 14L, 15L, 
    16L, 17L, 17L, 18L, 18L, 1L, 2L, 2L, 3L, 4L, 4L, 5L, 5L, 
    6L, 6L, 7L, 7L, 8L, 8L, 9L, 9L, 10L, 10L, 11L, 11L, 12L, 
    12L, 13L, 13L, 14L, 14L, 15L, 16L, 17L, 17L, 18L, 18L, 1L, 
    2L, 2L, 3L, 4L, 4L, 5L, 5L, 6L, 6L, 7L, 7L, 8L, 8L, 9L, 9L, 
    10L, 10L, 11L, 11L, 12L, 12L, 13L, 13L, 14L, 14L, 15L, 16L, 
    17L, 17L, 18L, 18L, 1L, 2L, 2L, 3L, 4L, 4L, 5L, 5L, 6L, 6L, 
    7L, 7L, 8L, 8L, 9L, 9L, 10L, 10L, 11L, 11L, 12L, 12L, 13L, 
    13L, 14L, 14L, 15L, 16L, 17L, 17L, 18L, 18L), .Label = c("11", 
    "12", "13", "14", "23", "24", "31", "32", "33", "34", "41", 
    "42", "43", "44", "51", "52", "53", "54"), class = "factor"), 
    TIME = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 
    4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
    4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
    4L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
    4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
    4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
    4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
    4L, 4L, 4L, 4L, 4L, 4L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 
    4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
    4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L), .Label = c("1", 
    "2", "3", "4"), class = "factor"), HEIGHT = structure(c(1L, 
    2L, 1L, 2L, 1L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 
    2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, 2L, 
    1L, 2L, 2L, 1L, 2L, 1L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 
    2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 1L, 
    1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 1L, 2L, 1L, 2L, 1L, 2L, 
    1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 
    2L, 1L, 1L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 1L, 2L, 1L, 
    2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 
    1L, 2L, 1L, 2L, 1L, 1L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 
    1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 
    2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, 2L, 1L, 2L, 1L, 1L, 
    2L, 1L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 
    2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, 2L, 1L, 2L, 
    1L, 1L, 2L, 1L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 
    2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, 2L, 
    1L, 2L, 1L, 2L, 1L, 2L, 1L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 
    1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, 
    2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 
    2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 
    1L, 1L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 1L, 2L, 1L, 2L, 
    1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 
    2L, 1L, 2L, 1L, 1L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 1L, 
    2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 
    1L, 2L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 
    2L, 1L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 
    2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, 2L, 1L, 2L, 
    1L, 1L, 2L, 1L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 
    2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, 2L, 
    1L, 2L, 1L, 1L, 2L, 1L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 
    2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 1L, 
    1L, 2L, 1L, 2L, 1L, 1L, 2L, 1L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 
    2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 
    1L, 1L, 1L, 2L, 1L, 2L, 1L, 1L, 2L, 1L, 1L, 2L, 1L, 2L, 1L, 
    2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 
    1L, 2L, 1L, 1L, 1L, 2L, 1L, 2L), .Label = c("1", "2", "3"
    ), class = "factor"), insectdens = c(0, 0, 63.64, 11.99, 
    14.57, 22.5, 15.53, 0, 20.49, 107.6, 0, 87.16, 19.82, 22.24, 
    18.28, 51.92, 33.87, 42.1, 59.01, 0, 47.32, 15.78, 12.46, 
    43.02, 12.23, 9.98, 27.75, 7.47, 38.92, 11.78, 11.18, 0, 
    0, 120.6, 44.61, 24.02, 45.9, 26.78, 14.56, 80.2, 62.34, 
    37.4, 32.44, 17.58, 47.52, 8.94, 26.01, 54.7, 9.19, 141.89, 
    29.36, 10.39, 48.88, 14.6, 20.46, 158.34, 20.5, 9.52, 18.82, 
    14.36, 47.94, 12.26, 45.76, 31.44, 53.82, 104.37, 112, 74.4, 
    59.88, 73.38, 94.36, 73.78, 120.26, 305, 48.12, 129.45, 264.87, 
    53.88, 129.36, 87.9, 107.03, 57.33, 145.53, 90.48, 95.2, 
    110, 116.55, 110.44, 492, 50.7, 140.4, 68.16, 111.28, 104.8, 
    59.76, 75, 91.92, 68.4, 12.92, 19.94, 22.6, 17.38, 53.6, 
    102.6, 10.45, 151.92, 30.3, 0, 0, 0, 39.18, 34.96, 16.38, 
    21.38, 18.32, 60.4, 35.48, 16.9, 0, 24.96, 56.28, 263.76, 
    38.24, 37.12, 9.26, 30.76, 26.24, 25.88, 46.48, 7.2, 21.09, 
    48.87, 0, 28.1, 10.09, 44.28, 67.26, 0, 0, 29.72, 50.49, 
    63.92, 0, 0, 0, 18.28, 10.82, 7.5, 27.06, 21.48, 9.09, 21.94, 
    13.56, 10.4, 13.25, 46.6, 31.74, 8.57, 11.98, 12.08, 30.55, 
    12.46, 31.16, 27.27, 16.35, 78.15, 100.8, 13.54, 80.44, 69.35, 
    104.55, 83.6, 37.32, 0, 107.7, 91.55, 21.52, 50.76, 22.28, 
    17, 55.6, 52.85, 40.72, 15.76, 15.12, 41.08, 25.44, 10.79, 
    87.36, 19.58, 19.94, 78.32, 13.04, 39.54, 40.55, 74.08, 14.37, 
    34.68, 31.68, 69.4, 62.28, 13.13, 117.96, 41.02, 18.27, 72.66, 
    34.74, 30.2, 69.86, 17.4, 100.89, 16.72, 95.7, 43.92, 0, 
    27.6, 129.6, 73.64, 147.4, 107.82, 92.16, 46.9, 76.1, 52.78, 
    52.32, 60.57, 46.7, 48.65, 49.41, 0, 54.8, 30.18, 59.2, 0, 
    12.52, 0, 0, 15.89, 90.39, 35.42, 26.64, 8.54, 17.46, 52.98, 
    7.88, 48.81, 12.68, 49.85, 32.67, 64.6, 41.2, 20.2, 8.47, 
    80.29, 38.52, 17.28, 35.94, 41.55, 9.4, 237.25, 0, 38.88, 
    24.56, 25.69, 0, 15.42, 0, 0, 0, 0, 467.64, 25.82, 36, 11.64, 
    112.05, 31.54, 42.08, 0, 26.86, 79.74, 0, 27.18, 17.48, 0, 
    34.95, 14.45, 43.88, 33.76, 23.24, 32.2, 16.29, 72.84, 189.99, 
    436.05, 365.6, 259.98, 329.29, 228, 158.4, 140.91, 448.95, 
    433.84, 47.11, 228.9, 193.13, 130.3, 335.73, 609.9, 202.54, 
    371.88, 332, 360.36, 219.56, 338.91, 329.94, 139.15, 262.34, 
    285.9, 357.76, 253.68, 353.35, 839.16, 368, 717.42, 840.18, 
    2081.2, 900.15, 1052.03, 705.12, 1276.65, 512.25, 838.88, 
    614.46, 734.58, 479.52, 286.38, 3020.4, 750.6, 885.96, 796.8, 
    932.49, 824.67, 1476.09, 716.76, 576.46, 528.58, 568.8, 568.8, 
    712.53, 1168.86, 1864.56, 997.26, 792.05, 1807.52, 899.25, 
    939.03, 1487.7, 1121.12, 166.5, 84.96, 78.7, 31.98, 169.2, 
    99.35, 124.2, 176.85, 116.88, 104.6, 45.43, 0, 82.44, 193.05, 
    53.5, 204.49, 135.72, 201.9, 129.76, 49.71, 50.5, 93.06, 
    239.98, 75.72, 221.54, 207.79, 218.24, 73.26, 96.4, 227.63, 
    155.4, 141.7, 280.63, 98.25, 58.4, 16.6, 30.84, 141.72, 0, 
    277.16, 313.82, 534.19, 104.74, 508.04, 67.62, 68.44, 119.7, 
    215.37, 26.92, 0, 63.24, 48.68, 11.62, 81.36, 142.5, 65.07, 
    28.06, 133.5, 126.54, 70.28, 79.62, 107.73, 36.16, 30.14, 
    31.76, 407.76, 422.24, 274.24, 317.7, 241.5, 190.3, 644.49, 
    162.17, 1104.24, 324.78, 268.24, 214.2, 449.25, 363.22, 475.57, 
    197.12, 311.63, 154.28, 461.3, 352.52, 247.69, 382.65, 395.25, 
    270.63, 399.84, 338.4, 529.48, 440.82, 394.56, 270.48, 322, 
    441.22, 353.5, 452.4, 414.96, 699.72, 89.04, 173.7, 347.6, 
    10150.24, 563.67, 353.94, 456.88, 117.92, 513, 245.48, 440.37, 
    372.36, 398.86, 334.35, 428, 410.13, 398.06, 674.87, 438.75, 
    226.16, 367.9, 416.8, 501.48, 522.6, 616.11, 421.2, 309.96, 
    423.09, 232.08, 198.06, 48.66, 109.59, 49.59, 58.05, 152.08, 
    0, 617.83, 64.66, 372.75, 32.07, 66.81, 112.24, 68.28, 83.64, 
    157.48, 145.2, 46.24, 143, 99.18, 117.5, 158.05, 61.1, 91.68, 
    67.5, 112.62, 98.21, 117.54, 58.92, 77.3, 0)), .Names = c("MONTH", 
"TRANSECT", "POLE", "TIME", "HEIGHT", "insectdens"), class = "data.frame", row.names = c(1L, 
2L, 4L, 5L, 7L, 9L, 10L, 13L, 14L, 16L, 17L, 19L, 20L, 22L, 23L, 
25L, 26L, 28L, 29L, 31L, 32L, 34L, 35L, 37L, 38L, 40L, 41L, 43L, 
44L, 46L, 47L, 49L, 50L, 53L, 55L, 56L, 58L, 60L, 61L, 64L, 65L, 
67L, 68L, 70L, 71L, 73L, 74L, 76L, 77L, 79L, 80L, 82L, 83L, 85L, 
86L, 88L, 89L, 91L, 92L, 94L, 95L, 97L, 98L, 100L, 101L, 103L, 
104L, 106L, 107L, 109L, 111L, 112L, 115L, 116L, 118L, 119L, 121L, 
122L, 124L, 125L, 127L, 128L, 130L, 131L, 133L, 134L, 136L, 137L, 
139L, 140L, 142L, 143L, 145L, 146L, 148L, 149L, 151L, 152L, 154L, 
155L, 157L, 158L, 160L, 162L, 163L, 166L, 167L, 169L, 170L, 172L, 
173L, 175L, 176L, 178L, 179L, 181L, 182L, 184L, 185L, 187L, 188L, 
190L, 191L, 193L, 194L, 196L, 197L, 199L, 200L, 202L, 203L, 205L, 
206L, 208L, 209L, 211L, 213L, 214L, 217L, 218L, 220L, 221L, 223L, 
224L, 226L, 227L, 229L, 230L, 232L, 233L, 235L, 236L, 238L, 239L, 
241L, 242L, 244L, 245L, 247L, 248L, 250L, 251L, 253L, 254L, 256L, 
259L, 260L, 262L, 264L, 265L, 268L, 269L, 271L, 272L, 274L, 275L, 
277L, 278L, 280L, 281L, 283L, 284L, 286L, 287L, 289L, 290L, 292L, 
293L, 295L, 296L, 298L, 299L, 301L, 302L, 304L, 305L, 307L, 310L, 
311L, 313L, 315L, 316L, 319L, 320L, 322L, 323L, 325L, 326L, 328L, 
329L, 331L, 332L, 334L, 335L, 337L, 338L, 340L, 341L, 343L, 344L, 
346L, 347L, 349L, 350L, 352L, 353L, 355L, 356L, 358L, 359L, 361L, 
362L, 364L, 366L, 367L, 370L, 371L, 373L, 374L, 376L, 377L, 379L, 
380L, 382L, 383L, 385L, 386L, 388L, 389L, 394L, 395L, 397L, 398L, 
400L, 401L, 403L, 404L, 406L, 407L, 409L, 410L, 412L, 413L, 415L, 
417L, 418L, 421L, 422L, 424L, 425L, 427L, 428L, 430L, 431L, 433L, 
434L, 436L, 437L, 439L, 440L, 442L, 443L, 445L, 446L, 448L, 449L, 
451L, 452L, 454L, 455L, 457L, 458L, 460L, 461L, 463L, 464L, 466L, 
468L, 469L, 472L, 473L, 475L, 476L, 478L, 479L, 481L, 482L, 484L, 
485L, 487L, 488L, 490L, 491L, 493L, 494L, 496L, 497L, 499L, 500L, 
502L, 503L, 505L, 506L, 508L, 509L, 511L, 512L, 514L, 515L, 517L, 
519L, 520L, 523L, 524L, 526L, 527L, 529L, 530L, 532L, 533L, 535L, 
536L, 538L, 539L, 541L, 542L, 544L, 545L, 547L, 548L, 550L, 551L, 
553L, 554L, 556L, 557L, 559L, 560L, 562L, 563L, 565L, 566L, 568L, 
570L, 571L, 574L, 575L, 577L, 578L, 580L, 581L, 583L, 584L, 586L, 
587L, 589L, 590L, 592L, 593L, 595L, 596L, 598L, 599L, 601L, 602L, 
604L, 605L, 607L, 608L, 610L, 611L, 613L, 616L, 617L, 619L, 621L, 
622L, 625L, 626L, 628L, 629L, 631L, 632L, 634L, 635L, 637L, 638L, 
640L, 641L, 643L, 644L, 646L, 647L, 649L, 650L, 652L, 653L, 655L, 
656L, 658L, 659L, 661L, 662L, 664L, 667L, 668L, 670L, 672L, 673L, 
676L, 677L, 679L, 680L, 682L, 683L, 685L, 686L, 688L, 689L, 691L, 
692L, 694L, 695L, 697L, 698L, 700L, 701L, 703L, 704L, 706L, 707L, 
709L, 710L, 712L, 713L, 715L, 718L, 719L, 721L, 723L, 724L, 727L, 
728L, 730L, 731L, 733L, 734L, 736L, 737L, 739L, 740L, 742L, 743L, 
745L, 746L, 748L, 749L, 751L, 752L, 754L, 755L, 757L, 758L, 760L, 
761L, 763L, 764L, 766L, 769L, 770L, 772L, 774L, 775L, 778L, 779L, 
781L, 782L, 784L, 785L, 787L, 788L, 790L, 791L, 793L, 794L, 796L, 
797L, 799L, 800L, 802L, 803L, 805L, 806L, 808L, 809L, 811L, 812L, 
814L, 815L))


-- 
This message (and any attachments) is for the recipient only...{{dropped}}



From mdu at ceh.ac.uk  Tue Sep  4 21:04:16 2007
From: mdu at ceh.ac.uk (Mike Dunbar)
Date: Tue, 04 Sep 2007 20:04:16 +0100
Subject: [R-sig-ME] magnitude of random effect vs significance
Message-ID: <s6ddba6c.060@wpo.nerc.ac.uk>


Following on from previous recent post, here is an example of a random effect which is tiny but highly significant. I've got no problem explaining a fixed effect which is tiny but significant (ie precisely estimated), but I'm struggling here!

regards

Mike



# read in temp3 first below
varcor.2h.crustacea.hf <- lme(log(crustdens+1) ~ HEIGHT, random=~1|MONTH/TIME/TRANSECT/POLE, data=temp3)
VarCorr(varcor.2h.crustacea.hf)

varcor.2h.crustacea.nomonth.hf <- lme(log(crustdens+1) ~ HEIGHT, random=~1|TIME/TRANSECT/POLE, data=invdens.bottommiddle)

anova(varcor.2h.crustacea.hf,varcor.2h.crustacea.nomonth.hf)
# month random effect of very low magnitude, yet it it highly significant: how can I explain this, or have I made a mistake!


temp3 <-
structure(list(MONTH = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L
), .Label = c("4", "5", "6", "7"), class = "factor"), TRANSECT = structure(c(1L, 
1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L, 5L, 5L, 
1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L, 5L, 5L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L, 5L, 
5L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L, 
5L, 5L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 
5L, 5L, 5L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 
5L, 5L, 5L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 
5L, 5L, 5L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L, 
5L, 5L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 
5L, 5L, 5L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 5L, 5L, 
5L, 5L, 5L, 5L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 5L, 
5L, 5L, 5L, 5L, 5L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
5L, 5L, 5L, 5L, 5L, 5L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
5L, 5L, 5L, 5L, 5L, 5L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
5L, 5L, 5L, 5L, 5L, 5L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
5L, 5L, 5L, 5L, 5L, 5L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
5L, 5L, 5L, 5L, 5L, 5L), .Label = c("1", "2", "3", "4", "5"), class = "factor"), 
    POLE = structure(c(1L, 1L, 2L, 2L, 3L, 4L, 4L, 5L, 5L, 6L, 
    6L, 7L, 7L, 8L, 8L, 9L, 9L, 10L, 10L, 11L, 11L, 12L, 12L, 
    13L, 13L, 14L, 14L, 15L, 16L, 17L, 17L, 18L, 18L, 1L, 2L, 
    2L, 3L, 4L, 4L, 5L, 5L, 5L, 6L, 7L, 7L, 8L, 8L, 9L, 9L, 10L, 
    10L, 11L, 11L, 12L, 12L, 13L, 13L, 14L, 14L, 15L, 16L, 17L, 
    17L, 18L, 18L, 1L, 1L, 2L, 2L, 3L, 4L, 4L, 5L, 5L, 6L, 6L, 
    7L, 7L, 8L, 8L, 9L, 9L, 10L, 10L, 11L, 11L, 12L, 12L, 13L, 
    13L, 14L, 14L, 15L, 16L, 17L, 17L, 18L, 18L, 1L, 1L, 2L, 
    2L, 3L, 4L, 4L, 5L, 5L, 6L, 6L, 7L, 7L, 8L, 8L, 9L, 9L, 10L, 
    10L, 11L, 11L, 12L, 12L, 13L, 13L, 14L, 14L, 15L, 16L, 17L, 
    17L, 18L, 18L, 1L, 1L, 2L, 2L, 3L, 4L, 4L, 5L, 5L, 6L, 6L, 
    7L, 7L, 8L, 8L, 9L, 9L, 10L, 10L, 11L, 11L, 12L, 12L, 13L, 
    13L, 14L, 14L, 15L, 16L, 17L, 17L, 18L, 18L, 1L, 2L, 2L, 
    3L, 4L, 4L, 5L, 5L, 6L, 6L, 7L, 7L, 8L, 8L, 9L, 9L, 10L, 
    10L, 11L, 11L, 12L, 12L, 13L, 13L, 14L, 14L, 15L, 16L, 17L, 
    17L, 18L, 18L, 1L, 2L, 2L, 3L, 4L, 4L, 5L, 5L, 6L, 6L, 7L, 
    7L, 8L, 8L, 9L, 9L, 10L, 10L, 11L, 11L, 12L, 12L, 13L, 13L, 
    14L, 14L, 15L, 16L, 17L, 17L, 18L, 18L, 1L, 1L, 2L, 2L, 3L, 
    4L, 4L, 5L, 5L, 6L, 6L, 7L, 7L, 8L, 8L, 9L, 9L, 10L, 10L, 
    11L, 11L, 13L, 13L, 14L, 14L, 15L, 16L, 17L, 17L, 18L, 18L, 
    1L, 1L, 2L, 2L, 3L, 4L, 4L, 5L, 5L, 6L, 6L, 7L, 7L, 8L, 8L, 
    9L, 9L, 10L, 10L, 11L, 11L, 12L, 12L, 13L, 13L, 14L, 14L, 
    15L, 16L, 17L, 17L, 18L, 18L, 1L, 1L, 2L, 2L, 3L, 4L, 4L, 
    5L, 5L, 6L, 6L, 7L, 7L, 8L, 8L, 9L, 9L, 10L, 10L, 11L, 11L, 
    12L, 12L, 13L, 13L, 14L, 14L, 15L, 16L, 17L, 17L, 18L, 18L, 
    1L, 1L, 2L, 2L, 3L, 4L, 4L, 5L, 5L, 6L, 6L, 7L, 7L, 8L, 8L, 
    9L, 9L, 10L, 10L, 11L, 11L, 12L, 12L, 13L, 13L, 14L, 14L, 
    15L, 16L, 17L, 17L, 18L, 18L, 1L, 1L, 2L, 2L, 3L, 4L, 4L, 
    5L, 5L, 6L, 6L, 7L, 7L, 8L, 8L, 9L, 9L, 10L, 10L, 11L, 11L, 
    12L, 12L, 13L, 13L, 14L, 14L, 15L, 16L, 17L, 17L, 18L, 18L, 
    1L, 2L, 2L, 3L, 4L, 4L, 5L, 5L, 6L, 6L, 7L, 7L, 8L, 8L, 9L, 
    9L, 10L, 10L, 11L, 11L, 12L, 12L, 13L, 13L, 14L, 14L, 15L, 
    16L, 17L, 17L, 18L, 18L, 1L, 2L, 2L, 3L, 4L, 4L, 5L, 5L, 
    6L, 6L, 7L, 7L, 8L, 8L, 9L, 9L, 10L, 10L, 11L, 11L, 12L, 
    12L, 13L, 13L, 14L, 14L, 15L, 16L, 17L, 17L, 18L, 18L, 1L, 
    2L, 2L, 3L, 4L, 4L, 5L, 5L, 6L, 6L, 7L, 7L, 8L, 8L, 9L, 9L, 
    10L, 10L, 11L, 11L, 12L, 12L, 13L, 13L, 14L, 14L, 15L, 16L, 
    17L, 17L, 18L, 18L, 1L, 2L, 2L, 3L, 4L, 4L, 5L, 5L, 6L, 6L, 
    7L, 7L, 8L, 8L, 9L, 9L, 10L, 10L, 11L, 11L, 12L, 12L, 13L, 
    13L, 14L, 14L, 15L, 16L, 17L, 17L, 18L, 18L), .Label = c("11", 
    "12", "13", "14", "23", "24", "31", "32", "33", "34", "41", 
    "42", "43", "44", "51", "52", "53", "54"), class = "factor"), 
    TIME = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 
    4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
    4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
    4L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
    4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
    4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
    4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
    4L, 4L, 4L, 4L, 4L, 4L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 
    4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
    4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L), .Label = c("1", 
    "2", "3", "4"), class = "factor"), HEIGHT = structure(c(1L, 
    2L, 1L, 2L, 1L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 
    2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, 2L, 
    1L, 2L, 2L, 1L, 2L, 1L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 
    2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 1L, 
    1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 1L, 2L, 1L, 2L, 1L, 2L, 
    1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 
    2L, 1L, 1L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 1L, 2L, 1L, 
    2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 
    1L, 2L, 1L, 2L, 1L, 1L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 
    1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 
    2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, 2L, 1L, 2L, 1L, 1L, 
    2L, 1L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 
    2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, 2L, 1L, 2L, 
    1L, 1L, 2L, 1L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 
    2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, 2L, 
    1L, 2L, 1L, 2L, 1L, 2L, 1L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 
    1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, 
    2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 
    2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 
    1L, 1L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 1L, 2L, 1L, 2L, 
    1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 
    2L, 1L, 2L, 1L, 1L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 1L, 
    2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 
    1L, 2L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 
    2L, 1L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 
    2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, 2L, 1L, 2L, 
    1L, 1L, 2L, 1L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 
    2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, 2L, 
    1L, 2L, 1L, 1L, 2L, 1L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 
    2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 1L, 
    1L, 2L, 1L, 2L, 1L, 1L, 2L, 1L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 
    2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 
    1L, 1L, 1L, 2L, 1L, 2L, 1L, 1L, 2L, 1L, 1L, 2L, 1L, 2L, 1L, 
    2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 
    1L, 2L, 1L, 1L, 1L, 2L, 1L, 2L), .Label = c("1", "2", "3"
    ), class = "factor"), crustdens = c(0, 0, 0, 11.99, 14.57, 
    45, 0, 0, 0, 26.9, 0, 21.79, 19.82, 22.24, 9.14, 51.92, 22.58, 
    105.25, 78.68, 26.07, 11.83, 15.78, 112.14, 14.34, 36.69, 
    19.96, 37, 37.35, 48.65, 11.78, 0, 7.48, 7.44, 13.4, 0, 0, 
    15.3, 0, 29.12, 60.15, 31.17, 56.1, 0, 0, 0, 0, 0, 21.88, 
    101.09, 101.35, 176.16, 51.95, 36.66, 21.9, 61.38, 219.24, 
    61.5, 19.04, 47.05, 50.26, 175.78, 12.26, 22.88, 31.44, 8.97, 
    29.82, 56, 136.4, 169.66, 134.53, 161.76, 42.16, 171.8, 183, 
    96.24, 43.15, 147.15, 143.68, 157.08, 61.53, 272.44, 163.8, 
    498.96, 407.16, 76.16, 22, 178.71, 190.76, 393.6, 324.48, 
    318.24, 161.88, 222.56, 320.95, 73.04, 106.25, 206.82, 106.4, 
    12.92, 0, 45.2, 0, 42.88, 0, 10.45, 67.52, 0, 0, 0, 18.81, 
    13.06, 17.48, 8.19, 0, 100.76, 135.9, 53.22, 8.45, 11.58, 
    24.96, 75.04, 87.92, 248.56, 55.68, 46.3, 30.76, 137.76, 
    51.76, 23.24, 14.4, 70.3, 114.03, 0, 28.1, 0, 14.76, 0, 0, 
    16.39, 0, 16.83, 0, 0, 13.82, 16.64, 9.14, 0, 0, 40.59, 0, 
    72.72, 0, 0, 10.4, 79.5, 0, 105.8, 0, 0, 12.08, 0, 0, 38.95, 
    0, 294.3, 156.3, 78.4, 243.72, 201.1, 55.48, 104.55, 33.44, 
    111.96, 0, 215.4, 18.31, 86.08, 67.68, 77.98, 68, 180.7, 
    63.42, 223.96, 78.8, 37.8, 51.35, 496.08, 107.9, 152.88, 
    78.32, 239.28, 78.32, 84.76, 39.54, 48.66, 46.3, 28.74, 23.12, 
    10.56, 27.76, 83.04, 65.65, 334.22, 143.57, 200.97, 24.22, 
    34.74, 30.2, 109.78, 34.8, 89.68, 58.52, 207.35, 54.9, 148.58, 
    46, 116.64, 84.16, 536, 131.78, 149.76, 103.18, 91.32, 82.94, 
    137.34, 26.92, 56.04, 29.19, 16.47, 11.12, 0, 0, 0, 39.38, 
    0, 0, 0, 0, 0, 0, 0, 0, 8.73, 17.66, 0, 48.81, 50.72, 59.82, 
    32.67, 232.56, 0, 40.4, 0, 22.94, 6.42, 17.28, 5.99, 24.93, 
    18.8, 47.45, 0, 0, 0, 25.69, 30.76, 0, 0, 0, 0, 0, 0, 0, 
    0, 0, 22.41, 0, 0, 0, 0, 13.29, 0, 0, 17.48, 0, 0, 0, 0, 
    0, 0, 8.05, 16.29, 0, 84.44, 129.2, 237.64, 148.56, 484.25, 
    45.6, 15.84, 80.52, 29.93, 216.92, 0, 274.68, 82.77, 117.27, 
    32.49, 112.35, 74.62, 289.24, 132.8, 262.08, 69.86, 41.08, 
    54.99, 63.25, 100.9, 247.78, 123.84, 120.8, 95.5, 119.88, 
    95.68, 65.22, 103.18, 884.51, 441.25, 407.93, 325.44, 539.03, 
    307.35, 85.6, 452.76, 285.67, 839.16, 0, 5537.4, 111.2, 205.44, 
    149.4, 645.57, 252.45, 849.87, 477.84, 492.1, 250.38, 265.44, 
    142.2, 164.43, 723.58, 438.72, 181.32, 407.34, 295.46, 371.69, 
    132.96, 297.54, 295.68, 0, 42.48, 47.22, 0, 50.76, 19.87, 
    27.6, 58.95, 0, 0, 0, 0, 54.96, 25.74, 0, 15.73, 0, 40.38, 
    48.66, 149.13, 30.3, 41.36, 18.46, 12.62, 0, 37.78, 27.28, 
    73.26, 38.56, 40.17, 7.4, 0, 29.54, 0, 0, 16.6, 61.68, 47.24, 
    0, 0, 0, 0, 0, 381.03, 0, 68.44, 0, 47.86, 0, 0, 21.08, 12.17, 
    0, 0, 23.75, 0, 0, 26.7, 0, 0, 0, 0, 0, 0, 15.88, 407.76, 
    482.56, 205.68, 254.16, 96.6, 86.5, 644.49, 162.17, 0, 0, 
    536.48, 178.5, 197.67, 181.61, 275.33, 140.8, 311.63, 286.52, 
    158.16, 12.59, 131.13, 178.57, 139.5, 30.07, 142.8, 225.6, 
    226.92, 170.64, 131.52, 125.58, 257.6, 254.55, 282.8, 301.6, 
    44.46, 266.56, 222.6, 17.37, 834.24, 2537.56, 2818.35, 235.96, 
    456.88, 176.88, 205.2, 116.28, 440.37, 166.92, 253.82, 200.61, 
    224.7, 119.07, 91.86, 108.85, 321.75, 113.08, 113.2, 62.52, 
    214.92, 80.4, 354.73, 93.6, 162.36, 203.71, 0, 66.02, 0, 
    36.53, 49.59, 0, 76.04, 0, 0, 0, 0, 32.07, 0, 0, 0, 13.94, 
    118.11, 0, 46.24, 42.9, 0, 0, 0, 30.55, 0, 0, 18.77, 14.03, 
    0, 0, 0, 16.41)), .Names = c("MONTH", "TRANSECT", "POLE", 
"TIME", "HEIGHT", "crustdens"), class = "data.frame", row.names = c(1L, 
2L, 4L, 5L, 7L, 9L, 10L, 13L, 14L, 16L, 17L, 19L, 20L, 22L, 23L, 
25L, 26L, 28L, 29L, 31L, 32L, 34L, 35L, 37L, 38L, 40L, 41L, 43L, 
44L, 46L, 47L, 49L, 50L, 53L, 55L, 56L, 58L, 60L, 61L, 64L, 65L, 
67L, 68L, 70L, 71L, 73L, 74L, 76L, 77L, 79L, 80L, 82L, 83L, 85L, 
86L, 88L, 89L, 91L, 92L, 94L, 95L, 97L, 98L, 100L, 101L, 103L, 
104L, 106L, 107L, 109L, 111L, 112L, 115L, 116L, 118L, 119L, 121L, 
122L, 124L, 125L, 127L, 128L, 130L, 131L, 133L, 134L, 136L, 137L, 
139L, 140L, 142L, 143L, 145L, 146L, 148L, 149L, 151L, 152L, 154L, 
155L, 157L, 158L, 160L, 162L, 163L, 166L, 167L, 169L, 170L, 172L, 
173L, 175L, 176L, 178L, 179L, 181L, 182L, 184L, 185L, 187L, 188L, 
190L, 191L, 193L, 194L, 196L, 197L, 199L, 200L, 202L, 203L, 205L, 
206L, 208L, 209L, 211L, 213L, 214L, 217L, 218L, 220L, 221L, 223L, 
224L, 226L, 227L, 229L, 230L, 232L, 233L, 235L, 236L, 238L, 239L, 
241L, 242L, 244L, 245L, 247L, 248L, 250L, 251L, 253L, 254L, 256L, 
259L, 260L, 262L, 264L, 265L, 268L, 269L, 271L, 272L, 274L, 275L, 
277L, 278L, 280L, 281L, 283L, 284L, 286L, 287L, 289L, 290L, 292L, 
293L, 295L, 296L, 298L, 299L, 301L, 302L, 304L, 305L, 307L, 310L, 
311L, 313L, 315L, 316L, 319L, 320L, 322L, 323L, 325L, 326L, 328L, 
329L, 331L, 332L, 334L, 335L, 337L, 338L, 340L, 341L, 343L, 344L, 
346L, 347L, 349L, 350L, 352L, 353L, 355L, 356L, 358L, 359L, 361L, 
362L, 364L, 366L, 367L, 370L, 371L, 373L, 374L, 376L, 377L, 379L, 
380L, 382L, 383L, 385L, 386L, 388L, 389L, 394L, 395L, 397L, 398L, 
400L, 401L, 403L, 404L, 406L, 407L, 409L, 410L, 412L, 413L, 415L, 
417L, 418L, 421L, 422L, 424L, 425L, 427L, 428L, 430L, 431L, 433L, 
434L, 436L, 437L, 439L, 440L, 442L, 443L, 445L, 446L, 448L, 449L, 
451L, 452L, 454L, 455L, 457L, 458L, 460L, 461L, 463L, 464L, 466L, 
468L, 469L, 472L, 473L, 475L, 476L, 478L, 479L, 481L, 482L, 484L, 
485L, 487L, 488L, 490L, 491L, 493L, 494L, 496L, 497L, 499L, 500L, 
502L, 503L, 505L, 506L, 508L, 509L, 511L, 512L, 514L, 515L, 517L, 
519L, 520L, 523L, 524L, 526L, 527L, 529L, 530L, 532L, 533L, 535L, 
536L, 538L, 539L, 541L, 542L, 544L, 545L, 547L, 548L, 550L, 551L, 
553L, 554L, 556L, 557L, 559L, 560L, 562L, 563L, 565L, 566L, 568L, 
570L, 571L, 574L, 575L, 577L, 578L, 580L, 581L, 583L, 584L, 586L, 
587L, 589L, 590L, 592L, 593L, 595L, 596L, 598L, 599L, 601L, 602L, 
604L, 605L, 607L, 608L, 610L, 611L, 613L, 616L, 617L, 619L, 621L, 
622L, 625L, 626L, 628L, 629L, 631L, 632L, 634L, 635L, 637L, 638L, 
640L, 641L, 643L, 644L, 646L, 647L, 649L, 650L, 652L, 653L, 655L, 
656L, 658L, 659L, 661L, 662L, 664L, 667L, 668L, 670L, 672L, 673L, 
676L, 677L, 679L, 680L, 682L, 683L, 685L, 686L, 688L, 689L, 691L, 
692L, 694L, 695L, 697L, 698L, 700L, 701L, 703L, 704L, 706L, 707L, 
709L, 710L, 712L, 713L, 715L, 718L, 719L, 721L, 723L, 724L, 727L, 
728L, 730L, 731L, 733L, 734L, 736L, 737L, 739L, 740L, 742L, 743L, 
745L, 746L, 748L, 749L, 751L, 752L, 754L, 755L, 757L, 758L, 760L, 
761L, 763L, 764L, 766L, 769L, 770L, 772L, 774L, 775L, 778L, 779L, 
781L, 782L, 784L, 785L, 787L, 788L, 790L, 791L, 793L, 794L, 796L, 
797L, 799L, 800L, 802L, 803L, 805L, 806L, 808L, 809L, 811L, 812L, 
814L, 815L))


-- 
This message (and any attachments) is for the recipient only...{{dropped}}



From p.dalgaard at biostat.ku.dk  Tue Sep  4 21:53:07 2007
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Tue, 04 Sep 2007 21:53:07 +0200
Subject: [R-sig-ME] magnitude of random effect vs significance
In-Reply-To: <s6ddba6c.060@wpo.nerc.ac.uk>
References: <s6ddba6c.060@wpo.nerc.ac.uk>
Message-ID: <46DDB7A3.9020803@biostat.ku.dk>

Mike Dunbar wrote:
> Following on from previous recent post, here is an example of a random effect which is tiny but highly significant. I've got no problem explaining a fixed effect which is tiny but significant (ie precisely estimated), but I'm struggling here!
>
> regards
>
> Mike
>
>
>
> # read in temp3 first below
> varcor.2h.crustacea.hf <- lme(log(crustdens+1) ~ HEIGHT, random=~1|MONTH/TIME/TRANSECT/POLE, data=temp3)
> VarCorr(varcor.2h.crustacea.hf)
>
> varcor.2h.crustacea.nomonth.hf <- lme(log(crustdens+1) ~ HEIGHT, random=~1|TIME/TRANSECT/POLE, data=invdens.bottommiddle)
>
> anova(varcor.2h.crustacea.hf,varcor.2h.crustacea.nomonth.hf)
> # month random effect of very low magnitude, yet it it highly significant: how can I explain this, or have I made a mistake!
>
>   
I don't think those models are comparable. Let's ignore TRANSECT and 
POLE for now. In one model you have MONTH with 4 groups and TIME %in% 
MONTH with 16 groups,  and in the other you have TIME with 4 groups. Put 
differently the variance for that term in one case means main effect of 
TIME and in the other case ditto plus the interaction. If TIME really 
only makes sense as nested in MONTH, the former can give a substantially 
worse fit to data whether or not there is a MONTH term.  For 
comparability, try this:

 > temp3$MTIME <- interaction(temp3$MONTH,temp3$TIME)> 
varcor.2h.crustacea.nomonth2.hf <- lme(log(crustdens+1) ~ HEIGHT, 
random=~1|MTIME/TRANSECT/POLE, data=temp3)

> anova(varcor.2h.crustacea.hf,varcor.2h.crustacea.nomonth2.hf)                             
                             Model df      AIC      BIC    logLik   Test
varcor.2h.crustacea.hf              1  7 1900.187 1929.923 -943.0935       

varcor.2h.crustacea.nomonth2.hf     2  6 1898.187 1923.675 -943.0935 1 vs 2
                                     L.Ratio p-value
varcor.2h.crustacea.hf                             
varcor.2h.crustacea.nomonth2.hf 3.202003e-07  0.9995

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From mdu at ceh.ac.uk  Tue Sep  4 22:09:23 2007
From: mdu at ceh.ac.uk (Mike Dunbar)
Date: Tue, 04 Sep 2007 21:09:23 +0100
Subject: [R-sig-ME] magnitude of random effect vs significance
Message-ID: <s6ddc999.085@wpo.nerc.ac.uk>

Hi Peter

Just to check I'm understanding you: So in the generic case where you have a nesting say A/B/C/D, if you want to test by removal of any factor that isn't the lowest in the hierarchy then you have to re-label that factor as including the levels of the next lowest factor. So for example testing by removing A, you must recode B as interaction(A,B) and test that against the full model. If so then I already understood this in the case of POLE and TRANSECT, I'd just forgotten it for the higher level factors.

regards

Mike


>>> Peter Dalgaard <p.dalgaard at biostat.ku.dk> 04/09/2007 20:53 >>>
Mike Dunbar wrote:
> Following on from previous recent post, here is an example of a random effect which is tiny but highly significant. I've got no problem explaining a fixed effect which is tiny but significant (ie precisely estimated), but I'm struggling here!
>
> regards
>
> Mike
>
>
>
> # read in temp3 first below
> varcor.2h.crustacea.hf <- lme(log(crustdens+1) ~ HEIGHT, random=~1|MONTH/TIME/TRANSECT/POLE, data=temp3)
> VarCorr(varcor.2h.crustacea.hf)
>
> varcor.2h.crustacea.nomonth.hf <- lme(log(crustdens+1) ~ HEIGHT, random=~1|TIME/TRANSECT/POLE, data=invdens.bottommiddle)
>
> anova(varcor.2h.crustacea.hf,varcor.2h.crustacea.nomonth.hf)
> # month random effect of very low magnitude, yet it it highly significant: how can I explain this, or have I made a mistake!
>
>   
I don't think those models are comparable. Let's ignore TRANSECT and 
POLE for now. In one model you have MONTH with 4 groups and TIME %in% 
MONTH with 16 groups,  and in the other you have TIME with 4 groups. Put 
differently the variance for that term in one case means main effect of 
TIME and in the other case ditto plus the interaction. If TIME really 
only makes sense as nested in MONTH, the former can give a substantially 
worse fit to data whether or not there is a MONTH term.  For 
comparability, try this:

 > temp3$MTIME <- interaction(temp3$MONTH,temp3$TIME)> 
varcor.2h.crustacea.nomonth2.hf <- lme(log(crustdens+1) ~ HEIGHT, 
random=~1|MTIME/TRANSECT/POLE, data=temp3)

> anova(varcor.2h.crustacea.hf,varcor.2h.crustacea.nomonth2.hf)                             
                             Model df      AIC      BIC    logLik   Test
varcor.2h.crustacea.hf              1  7 1900.187 1929.923 -943.0935       

varcor.2h.crustacea.nomonth2.hf     2  6 1898.187 1923.675 -943.0935 1 vs 2
                                     L.Ratio p-value
varcor.2h.crustacea.hf                             
varcor.2h.crustacea.nomonth2.hf 3.202003e-07  0.9995

-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907




-- 
This message (and any attachments) is for the recipient only...{{dropped}}



From gangchen at mail.nih.gov  Wed Sep  5 00:22:48 2007
From: gangchen at mail.nih.gov (Gang Chen)
Date: Tue, 4 Sep 2007 18:22:48 -0400
Subject: [R-sig-ME] Dealing with large datasets in lme/lmer
Message-ID: <3002B649-86D2-42DA-981E-9639CAAF8E37@mail.nih.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20070904/bd9f3012/attachment.pl>

From bxc at steno.dk  Wed Sep  5 14:12:22 2007
From: bxc at steno.dk (BXC (Bendix Carstensen))
Date: Wed, 5 Sep 2007 14:12:22 +0200
Subject: [R-sig-ME] Extract variance components from lme object
Message-ID: <40D3930AC1C8EA469E39536E5BC8083504A6F68F@EXDKBA021.corp.novocorp.net>

I have fitted the following model to a three-way layout of meth, item,
repl:

lme( y ~ meth + item,
         random=list( item = pdIdent( ~ meth-1 ),
                      repl = ~1 ),
         weights = varIdent( form = ~1 | meth ),
         data=ox
         )

So I have a model with random meth-by-item and item-by-repl effects and
seprate 
residual variances for each of the two levels of meth.

How do I extract these 4 variance components to an R-structure that I
can use for 
further calculations?

The output is below.

Best
Bendix
______________________________________________

Bendix Carstensen
Senior Statistician

Steno Diabetes Center
Niels Steensens Vej 2-4
DK-2820 Gentofte
Denmark
+45 44 43 87 38 (direct)
+45 30 75 87 38 (mobile)
+45 44 43 73 13 (fax)
bxc at steno.dk   http://www.biostat.ku.dk/~bxc


Linear mixed-effects model fit by REML
  Data: ox 
  Log-restricted-likelihood: -911.7401
  Fixed: y ~ meth + item 
(Intercept)   methpulse       item2       item3       item4       item5
item6       item7       item8 
 76.0428384  -2.4704462  -7.0216227   5.1497034 -10.7281860  -1.1137199
3.1649924   9.7065633   3.5568599 
      item9      item10      item11      item12      item13      item14
item15      item16      item17 
 -4.1821374 -14.4222445  12.7503731 -47.3135668   3.3219575  -1.1293724
6.2565251  -0.5367298  13.9153464 
     item18      item19      item20      item21      item22      item23
item24      item25      item26 
  1.5322522  -2.0861271  -1.0351969   6.4653272  -0.4416475   4.5820322
8.2772197   2.1049894   2.7779659 
     item27      item28      item29      item30      item31      item32
item33      item34      item35 
-10.3186089 -10.8197187   0.7833716   2.6444795 -29.2466418   5.6528703
6.8769614   8.7365767   0.9285974 
     item36      item37      item38      item39      item40      item41
item42      item43      item44 
  3.0492155   3.6735649   7.5298316   2.7392939  -8.6159587  -0.1044011
-4.3450727 -20.7468236 -16.2943647 
     item45      item46      item47      item48      item49      item50
item51      item52      item53 
  2.0329985   4.5130501   3.4254305  -3.0309414  10.4662553 -24.8350417
-20.8508611  -0.3525354  -3.6222924 
     item54      item55      item56      item57      item58      item59
item60      item61 
  1.4299082  12.8385572   9.7971680  13.3501148  13.4953406  15.6657386
7.3963452  -1.7503731 

Random effects:
 Formula: ~meth - 1 | item
 Structure: Multiple of an Identity
          methCO methpulse
StdDev: 2.928042  2.928042

 Formula: ~1 | repl %in% item
        (Intercept) Residual
StdDev:    3.415692 2.224868

Variance function:
 Structure: Different standard deviations per stratum
 Formula: ~1 | meth 
 Parameter estimates:
      CO    pulse 
1.000000 1.795365 
Number of Observations: 354
Number of Groups: 
          item repl %in% item 
            61            177 
>



From bates at stat.wisc.edu  Wed Sep  5 21:11:28 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 5 Sep 2007 14:11:28 -0500
Subject: [R-sig-ME] Dealing with large datasets in lme/lmer
In-Reply-To: <3002B649-86D2-42DA-981E-9639CAAF8E37@mail.nih.gov>
References: <3002B649-86D2-42DA-981E-9639CAAF8E37@mail.nih.gov>
Message-ID: <40e66e0b0709051211y22c7e896g94ef1c38200a50cb@mail.gmail.com>

On 9/4/07, Gang Chen <gangchen at mail.nih.gov> wrote:
> Dear all,

> I'm running mixed-effects analysis with large datasets in a loop like
> this:

> for (i in 1:60) {
> for (j in 1:60) {
> for (k in 1:60) {
>     [...update y here in Model here...]
>     fit.lme <- lme(y ~ FA*FB*FC+weight, random = pdBlocked(list
> (pdCompSymm(~FB-1), pdCompSymm(~FC-1), pdIdent(~1))), weights=varIdent
> (form=~1|FA), Model);
>     Stat[i, j, k,] <- anova(fit.lme)$F[-1];
> }
> }
> }

Did you create the array Stat outside the loop?  If not you will be
doing a lot of copying of elements of that array.

> This takes a little over 100 hours to finish on a Mac G5 with duo
> 2.7GHz processors and 4GB memory.

> In the mixed-effects model

> y = X*beta + Z*b + e

> the fixed-effects nxp matrix X and random-effects matrix nxq Z are
> always the same for all the iterations in my case, and the only thing
> that differs is y (and the estimates of beta, b and e also differ of
> course). In my case n = 504 (large), p and q are moderate.  I just
> read Dr. Douglas Bates's presentation during uerR! 2007 (very
> informative by the way):

Thank you.

> http://user2007.org/program/presentations/bates.pdf

> It seems many components in the extended system matrix (equation (2)
> on page 22) for the Cholesky decomposition remain the same during the
> iterations. So there are a lot of repetitive computations on those
> same matrix operations in the above loop. How can I achieve a better
> efficiency? Someone suggested to me running lme/lmer with a two-
> dimensional response Y instead of one-dimensional y. My questions are:

> (1) So far I have only seen people running lme/lmer with y in a
> format of one-dimensional array from a table. If I combine all those
> y's (indices i, j, k) into an two-dimensional array Y, is there a way
> I can run lme/lmer on Y instead of y? In other words, does lme/lmer
> take a two-dimensional array Y?

Not at present.

> If so, do I have to save the huge
> array in a table in text file and then read in R before I run lme/
> lmer?

No.  There are many ways of getting data into R other than creating a
text file and reading it.  See the manual "R Data Import/Export" and
also Martin Maechler's presentation at useR!2007.
http://user2007.org/program/presentations/maechler.pdf

> Also if that is the case, how can I label those many columns
> somehow associated with Y?

> (2) A more serious concern is about memory. With the current looping
> approach it uses about 1GB. If I could possibly go with the matrix
> method described in (1), I'm worried that it might not be practically
> feasible with the current computers. Any thoughts?

Well first you are discussing the computational methods used in lmer
but you want to fit a model with different residual variances for
different groups.  At present you can't do that in lmer.

If you look at the lmer function in the development version of the
lme4 package (currently at
https://svn.r-project.org/R-packages/branches/gappy-lmer, soon to be
at http://r-forge.r-project.org/projects/lme4 for some value of
"soon") you will see that it follows the equations in my useR
presentation fairly closely.  The Xy array is n by (p + 1) with X in
the first p columns and y in the p + 1st column.  The object of class
"lmer" has slots named y, Zt (Z-transpose), ZtXy (Zt %*% Xy), and
XytXy (crossprod(Xy)). After fitting the model to the first simulated
response, producing the object 'fm',  the only operations needed to
update the model are

 fm at y <- newy
 Xy <- cbind(fm at X, fm at y)
 fm at ZtXy <- fm at Zt %*% Xy
 fm at XytXy <- crossprod(Xy)
 lme4:::mer_finalize(fm, verbose)

where 'verbose' is a logical scalar indicating if you want verbose
output during the optimization phase.  Once you get things working on
a small example you would probably want to turn that off.

Please note that this code applies to the development version of the
lme4 package.



From ajbush at bellsouth.net  Thu Sep  6 00:53:25 2007
From: ajbush at bellsouth.net (Andy Bush)
Date: Wed, 5 Sep 2007 17:53:25 -0500
Subject: [R-sig-ME] Specifying random effects for multiple covariates via
	lmer
Message-ID: <000f01c7f00f$91f5f6e0$0301a8c0@AndyXPS>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20070905/9b63aeb4/attachment.pl>

From bates at stat.wisc.edu  Thu Sep  6 04:22:00 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 5 Sep 2007 21:22:00 -0500
Subject: [R-sig-ME] Specifying random effects for multiple covariates
	via lmer
In-Reply-To: <000f01c7f00f$91f5f6e0$0301a8c0@AndyXPS>
References: <000f01c7f00f$91f5f6e0$0301a8c0@AndyXPS>
Message-ID: <40e66e0b0709051922jda8f867i490b304c14e6a8df@mail.gmail.com>

On 9/5/07, Andy Bush <ajbush at bellsouth.net> wrote:
> While working through the text "Applied Longitudinal Analysis" by
> Fitzmaurice, Laird and Ware, I encountered a fairly simple case study (pp
> 210-7) in which a longitudinal model specifies three random effects: (1)
> random intercepts for id, (2) random slopes for covariate1 (Age | id), and
> (3) random slopes for covariate2 (log(ht) | id).  I've had no difficulty
> formulating lmer models with correlated random intercepts and slopes for
> either of the covariates individually but have not succeeded when I try to
> compose a model with correlated random intercepts and slopes for two
> covariates.

> Following is code that works well with the individual covariates separately:

> m1=lmer(LFEV1~Age + loght + InitAge + logbht + (1 + Age | id),data=fev,
>        na.action=na.omit, method="REML")

> m2=lmer(LFEV1~Age + loght + InitAge + logbht+(1 + loght | id),data=fev,
>        na.action=na.omit, method="REML")

Maybe I am missing the point but wouldn't the model you are
considering be written as

lmer(LFEV1 ~ Age + loght + InitAge + logbht + (loght + Age|id), data =
fev, na.action = na.omit, method = "REML")

That provides correlated random effects for the intercept, the
coefficient for loght and the coefficient for Age at each level of the
id factor.



From john.maindonald at anu.edu.au  Thu Sep  6 11:07:52 2007
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Thu, 6 Sep 2007 19:07:52 +1000
Subject: [R-sig-ME] explaining lme variance component results
In-Reply-To: <s6ddb823.054@wpo.nerc.ac.uk>
References: <s6ddb823.054@wpo.nerc.ac.uk>
Message-ID: <A54F1284-C02D-4AD4-BCB8-CEA941FCC791@anu.edu.au>

While I was out of contact with the list for a couple of days, I put the
following together.  It is for the data that Mike gave initially, so  
that
it assumes no replicates within POLE. The mean square for
MONTH:TIME:TRANSECT:POLE is the Residual.

The variance component for TRANSECT is effectively zero.  For
purposes of exposition, it can be set to zero.

The terms formula MONTH/TIME then suffices. lme() gives the numbers of
groups as:

Number of Observations: 286
Number of Groups:
           MONTH TIME %in% MONTH
               4              16

Observe that the design is then very nearly a complete balanced design:

 > with(temp, table(MONTH,TIME))
      TIME
MONTH  1  2  3  4
     4 18 17 18 18
     5 18 18 18 17
     6 18 18 18 18
     7 18 18 18 18

Observe that
   286/16=17.875
less than 18 because two of the TIME:MONTH combinations have
only 17 values.  The harmonic mean, which is 17.87, seems however
preferable.

If the design were balanced, with replicates at
MONTH/TIME/POLE level equal to n1=4/n2=4/n3=17.87
then the mean squares would estimate, respectively

4 x 17.87 s1^2 +  17.87 s2^2 + s3^2  = 4 x 17.87 (s1^2 +  s2^2 /4 +  
s3^2 / (4*17.87)
17.87 s2^2 + s3^2  = 17.87 ( s2^2 + s3^2 / 17.87)
s3^2

In the first two cases, a second version of the formula is given
that makes (to me, at least) better intuitive sense.

We have
          Variance     Anova        DF     No. of repeats
          Component    mean square         per 'parent'
MONTH    0.75287      74.10751      3     4
TIME     1.07395      20.52433     12     4
Residual 1.20354      1.20356     270     17.87 (harmonic mean)

Observe that the residual mean square estimates the residual variance.
The TIME variance component is calculated pretty much as
(20.52433 - 1.20356)/17.87 = 1.0813, which does not quite agree
with the ML estimate (nor should it; equating mean squares to expected
mean squares is not the same as REML!)).

The statistical error is affected both by the statistical error in  
the TIME
anova mean square, and by the statistical error in the Residual mean
square.  The variance formula that is given below for MONTH can be
readily adapted for this case also.

The MONTH variance component is calculated pretty much as: (74.10751 -
20.52433)/(4*17.87) = 0.7497 Again the agreement with the REML
estimate is, quite properly, not perfect.

The estimate for s1^2 (MONTH} has a statistical error that is a
compound of the errors in the ANOVA mean squares for both TIME and
MONTH.  The variances of the two anova mean squares (both sample
values of chi-squared statistics, under the usual assumptions) add,
while the quantities themselves are subtracted.  The SE (sqrt of
variance), for the estimate s1^2 of sig1^2, is

sqrt( (n2 * n3 * sig1^2 + n3 * sig2^2 + sig3^2)^2 / nu1
      + (n3 * sig2^2 + sig3^2)^2 / nu2 ) / (n2*n3)

[The n's are the numbers of repeats.  The nu's are degrees of freedom.]

Variances are not, for quantities that are differences multiples of
chi-squared statistics, a good basis for inference. (Here I am tempted
to make rude comments about over-reliance on variances in much
sample  survey work!). The variance calculations may however be useful
in giving an idea of the relative contributions of the different  
sources of
statistical noise.

I'd expect, though I have not gone through the arithmetic in detail,
that the estimate for SE[s1^2] will increase, if we allow for the
possibility that the TRANSECT component of variance, even though
estimated as zero, may actually be greater than zero.

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.


On 5 Sep 2007, at 4:54 AM, Mike Dunbar wrote:

> Thanks to all, a couple more comments following up on Kevin's  
> comments below, and also ones sent to me directly.
>
> I have plotted the data in many different ways, having spent  
> several years (yes!) trying to work out a suitable analysis for  
> these data. The aim of this particular analysis is to try to keep  
> things as simple as possible, I'm aware in particular that there  
> are differences between the behaviour of the factors across the  
> months (so one option is a month by month analysis - which I have  
> done but it was vetoed by co-workers for this paper so long as  
> there's a simple interpretation as well), and also that time is  
> generally the most important factor overall (this is already  
> documented by others - the data are of drifting macroinvertebrates  
> in rivers in case anyones interested).
>
> The structure of the nesting is designed to mirror our expected  
> view of the correlations in the data based on spatial/temporal  
> proximity, a bit as Kevin describes below: so four times were  
> measured across a day and the experiment repeated across four  
> months, and for each of the 16 occasions, we have five transects,  
> within those four poles each, and not described previously, 1-3  
> measures at different heights on the poles.
>
> Regarding the zero values: yes the normality is an assumption, I  
> hope to do better once this initial analysis is over. What I hoped  
> to show is despite this, and despite the assumptions of the  
> variance components analysis, there is evidence of an effect of  
> TRANSECT and / or POLE, once MONTH and TIME are accounted for.
>
> What is very pertinent (thanks John) is the fact that in the data  
> as described, there is no replication within the lowest stratum,  
> POLE. There was one seeming replicate, but that must be an error.  
> This may well be the source of the problem that the POLE variance  
> component was large but not significant.
>
> I had thought that despite the lack of replication within POLE that  
> it would still be possible to estimate a variance component for  
> POLE separately from the residual. The very wooly reasoning being  
> that the POLE component represents consistency in drift density  
> between POLEs across TRANSECT, TIME and MONTH, and residual  
> represents lack of consistency.
>
> If my reasoning above is flawed, I really don't want to ditch the  
> POLE component, as its fairly central to the analysis, and I could  
> bring in HEIGHT to give replication within POLE (previous data is  
> for one height only). I'd prefer to do this as a fixed effect and  
> I've posted below some example data/code: can anyone comment if  
> this is valid?
>
> Regarding the issue of magnitude of variance component/random  
> effect vs significance, I wonder if there is more too it than that,  
> certainly in this case we know that TIME is more important than  
> MONTH, despite being nested, but more critically, I can show some  
> data where the magnitude of the component doesn't seem to relate to  
> its significance. I'll post this in a separate mail to avoid  
> confusion, once again any comments are welcome. This gives me a  
> real headache explaining my results to my co-workers, let alone  
> reviewers. I ought to add that there could easily still be mistakes  
> where, as one regarding a non-replicate
> has already been identified.
>
> All the best again - hope this is interesting to others struggling  
> with similar issues??
>
> Mike
>
>
>
>
> varcor.2h.insects.hf <- lme(log(insectdens+1) ~ HEIGHT, random=~1| 
> MONTH/TIME/TRANSECT/POLE, data=temp2)
> # introduce HEIGHT as a fixed effect, there are two heights per  
> pole for some poles: hence unbalanced
> VarCorr(varcor.2h.insects.hf)
> # variances: MONTH - 0.639, TIME: 1.248, TRANSECT: 0.013, POLE:  
> 0.160, Residual: 1.016
>
> varcor.2h.insects.nospat.hf <- lme(log(insectdens+1) ~ HEIGHT,  
> random=~1|MONTH/TIME, data=temp2)
>
> anova(varcor.2h.insects.hf,varcor.2h.insects.nospat.hf)
> # two spatial factors together marginally signficant: p=0.06, but  
> test likely conservative
> # simulation approach for null distribution (Faraway) probably too  
> difficult at this depth of nesting
> intervals(varcor.2h.insects.hf)
> # again some evidence for significance of TRANSECT, but POLE lower  
> bound close to 0.
>
> # delete transect term and just compare models with and without  
> pole term
> varcor.2h.insects.pole.hf <- lme(log(insectdens+1) ~ HEIGHT,  
> random=~1|MONTH/TIME/POLE, data=temp2)
> # test pole factor on its own. This is possible as pole is coded as  
> a combination of transect and pole within transect
> anova(varcor.2h.insects.pole.hf,varcor.2h.insects.nospat.hf)
> # p=0.019. This would be great if analysis is valid
>
>
>
> # read in data: this time with one or two heights per pole
>
> temp2 <-
> structure(list(MONTH = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L,
> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
> 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
> 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
> 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
> 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
> 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
> 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
> 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L
> ), .Label = c("4", "5", "6", "7"), class = "factor"), TRANSECT =  
> structure(c(1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L,
> 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L, 5L, 5L,
> 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L,
> 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L, 5L, 5L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L,
> 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L, 5L,
> 5L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L,
> 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L,
> 5L, 5L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 3L, 3L, 3L,
> 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 5L, 5L, 5L,
> 5L, 5L, 5L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 3L, 3L, 3L,
> 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 5L, 5L, 5L,
> 5L, 5L, 5L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 3L, 3L, 3L,
> 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 5L, 5L, 5L,
> 5L, 5L, 5L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 3L, 3L,
> 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L,
> 5L, 5L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 3L, 3L, 3L,
> 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 5L, 5L, 5L,
> 5L, 5L, 5L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 3L, 3L,
> 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 5L, 5L,
> 5L, 5L, 5L, 5L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 3L,
> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 5L,
> 5L, 5L, 5L, 5L, 5L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L,
> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
> 5L, 5L, 5L, 5L, 5L, 5L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L,
> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
> 5L, 5L, 5L, 5L, 5L, 5L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L,
> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
> 5L, 5L, 5L, 5L, 5L, 5L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L,
> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
> 5L, 5L, 5L, 5L, 5L, 5L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L,
> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
> 5L, 5L, 5L, 5L, 5L, 5L), .Label = c("1", "2", "3", "4", "5"), class  
> = "factor"),
>     POLE = structure(c(1L, 1L, 2L, 2L, 3L, 4L, 4L, 5L, 5L, 6L,
>     6L, 7L, 7L, 8L, 8L, 9L, 9L, 10L, 10L, 11L, 11L, 12L, 12L,
>     13L, 13L, 14L, 14L, 15L, 16L, 17L, 17L, 18L, 18L, 1L, 2L,
>     2L, 3L, 4L, 4L, 5L, 5L, 5L, 6L, 7L, 7L, 8L, 8L, 9L, 9L, 10L,
>     10L, 11L, 11L, 12L, 12L, 13L, 13L, 14L, 14L, 15L, 16L, 17L,
>     17L, 18L, 18L, 1L, 1L, 2L, 2L, 3L, 4L, 4L, 5L, 5L, 6L, 6L,
>     7L, 7L, 8L, 8L, 9L, 9L, 10L, 10L, 11L, 11L, 12L, 12L, 13L,
>     13L, 14L, 14L, 15L, 16L, 17L, 17L, 18L, 18L, 1L, 1L, 2L,
>     2L, 3L, 4L, 4L, 5L, 5L, 6L, 6L, 7L, 7L, 8L, 8L, 9L, 9L, 10L,
>     10L, 11L, 11L, 12L, 12L, 13L, 13L, 14L, 14L, 15L, 16L, 17L,
>     17L, 18L, 18L, 1L, 1L, 2L, 2L, 3L, 4L, 4L, 5L, 5L, 6L, 6L,
>     7L, 7L, 8L, 8L, 9L, 9L, 10L, 10L, 11L, 11L, 12L, 12L, 13L,
>     13L, 14L, 14L, 15L, 16L, 17L, 17L, 18L, 18L, 1L, 2L, 2L,
>     3L, 4L, 4L, 5L, 5L, 6L, 6L, 7L, 7L, 8L, 8L, 9L, 9L, 10L,
>     10L, 11L, 11L, 12L, 12L, 13L, 13L, 14L, 14L, 15L, 16L, 17L,
>     17L, 18L, 18L, 1L, 2L, 2L, 3L, 4L, 4L, 5L, 5L, 6L, 6L, 7L,
>     7L, 8L, 8L, 9L, 9L, 10L, 10L, 11L, 11L, 12L, 12L, 13L, 13L,
>     14L, 14L, 15L, 16L, 17L, 17L, 18L, 18L, 1L, 1L, 2L, 2L, 3L,
>     4L, 4L, 5L, 5L, 6L, 6L, 7L, 7L, 8L, 8L, 9L, 9L, 10L, 10L,
>     11L, 11L, 13L, 13L, 14L, 14L, 15L, 16L, 17L, 17L, 18L, 18L,
>     1L, 1L, 2L, 2L, 3L, 4L, 4L, 5L, 5L, 6L, 6L, 7L, 7L, 8L, 8L,
>     9L, 9L, 10L, 10L, 11L, 11L, 12L, 12L, 13L, 13L, 14L, 14L,
>     15L, 16L, 17L, 17L, 18L, 18L, 1L, 1L, 2L, 2L, 3L, 4L, 4L,
>     5L, 5L, 6L, 6L, 7L, 7L, 8L, 8L, 9L, 9L, 10L, 10L, 11L, 11L,
>     12L, 12L, 13L, 13L, 14L, 14L, 15L, 16L, 17L, 17L, 18L, 18L,
>     1L, 1L, 2L, 2L, 3L, 4L, 4L, 5L, 5L, 6L, 6L, 7L, 7L, 8L, 8L,
>     9L, 9L, 10L, 10L, 11L, 11L, 12L, 12L, 13L, 13L, 14L, 14L,
>     15L, 16L, 17L, 17L, 18L, 18L, 1L, 1L, 2L, 2L, 3L, 4L, 4L,
>     5L, 5L, 6L, 6L, 7L, 7L, 8L, 8L, 9L, 9L, 10L, 10L, 11L, 11L,
>     12L, 12L, 13L, 13L, 14L, 14L, 15L, 16L, 17L, 17L, 18L, 18L,
>     1L, 2L, 2L, 3L, 4L, 4L, 5L, 5L, 6L, 6L, 7L, 7L, 8L, 8L, 9L,
>     9L, 10L, 10L, 11L, 11L, 12L, 12L, 13L, 13L, 14L, 14L, 15L,
>     16L, 17L, 17L, 18L, 18L, 1L, 2L, 2L, 3L, 4L, 4L, 5L, 5L,
>     6L, 6L, 7L, 7L, 8L, 8L, 9L, 9L, 10L, 10L, 11L, 11L, 12L,
>     12L, 13L, 13L, 14L, 14L, 15L, 16L, 17L, 17L, 18L, 18L, 1L,
>     2L, 2L, 3L, 4L, 4L, 5L, 5L, 6L, 6L, 7L, 7L, 8L, 8L, 9L, 9L,
>     10L, 10L, 11L, 11L, 12L, 12L, 13L, 13L, 14L, 14L, 15L, 16L,
>     17L, 17L, 18L, 18L, 1L, 2L, 2L, 3L, 4L, 4L, 5L, 5L, 6L, 6L,
>     7L, 7L, 8L, 8L, 9L, 9L, 10L, 10L, 11L, 11L, 12L, 12L, 13L,
>     13L, 14L, 14L, 15L, 16L, 17L, 17L, 18L, 18L), .Label = c("11",
>     "12", "13", "14", "23", "24", "31", "32", "33", "34", "41",
>     "42", "43", "44", "51", "52", "53", "54"), class = "factor"),
>     TIME = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L,
>     3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
>     3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L,
>     4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
>     4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
>     4L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>     1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>     2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
>     3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
>     3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
>     4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
>     4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 1L, 1L, 1L, 1L, 1L, 1L,
>     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L,
>     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>     3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
>     3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
>     3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
>     4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
>     4L, 4L, 4L, 4L, 4L, 4L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L,
>     3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
>     3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L,
>     4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
>     4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L), .Label  
> = c("1",
>     "2", "3", "4"), class = "factor"), HEIGHT = structure(c(1L,
>     2L, 1L, 2L, 1L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L,
>     2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, 2L,
>     1L, 2L, 2L, 1L, 2L, 1L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L,
>     2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 1L,
>     1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 1L, 2L, 1L, 2L, 1L, 2L,
>     1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L,
>     2L, 1L, 1L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 1L, 2L, 1L,
>     2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L,
>     1L, 2L, 1L, 2L, 1L, 1L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L,
>     1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L,
>     2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, 2L, 1L, 2L, 1L, 1L,
>     2L, 1L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L,
>     2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, 2L, 1L, 2L,
>     1L, 1L, 2L, 1L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L,
>     2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, 2L,
>     1L, 2L, 1L, 2L, 1L, 2L, 1L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L,
>     1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 1L, 1L,
>     2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 1L, 2L, 1L, 2L, 1L, 2L, 1L,
>     2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L,
>     1L, 1L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 1L, 2L, 1L, 2L,
>     1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L,
>     2L, 1L, 2L, 1L, 1L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 1L,
>     2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L,
>     1L, 2L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, 2L, 1L, 2L, 1L, 2L, 1L,
>     2L, 1L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L,
>     2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, 2L, 1L, 2L,
>     1L, 1L, 2L, 1L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L,
>     2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, 2L,
>     1L, 2L, 1L, 1L, 2L, 1L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L,
>     2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 1L,
>     1L, 2L, 1L, 2L, 1L, 1L, 2L, 1L, 1L, 2L, 1L, 2L, 1L, 2L, 1L,
>     2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L,
>     1L, 1L, 1L, 2L, 1L, 2L, 1L, 1L, 2L, 1L, 1L, 2L, 1L, 2L, 1L,
>     2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L,
>     1L, 2L, 1L, 1L, 1L, 2L, 1L, 2L), .Label = c("1", "2", "3"
>     ), class = "factor"), insectdens = c(0, 0, 63.64, 11.99,
>     14.57, 22.5, 15.53, 0, 20.49, 107.6, 0, 87.16, 19.82, 22.24,
>     18.28, 51.92, 33.87, 42.1, 59.01, 0, 47.32, 15.78, 12.46,
>     43.02, 12.23, 9.98, 27.75, 7.47, 38.92, 11.78, 11.18, 0,
>     0, 120.6, 44.61, 24.02, 45.9, 26.78, 14.56, 80.2, 62.34,
>     37.4, 32.44, 17.58, 47.52, 8.94, 26.01, 54.7, 9.19, 141.89,
>     29.36, 10.39, 48.88, 14.6, 20.46, 158.34, 20.5, 9.52, 18.82,
>     14.36, 47.94, 12.26, 45.76, 31.44, 53.82, 104.37, 112, 74.4,
>     59.88, 73.38, 94.36, 73.78, 120.26, 305, 48.12, 129.45, 264.87,
>     53.88, 129.36, 87.9, 107.03, 57.33, 145.53, 90.48, 95.2,
>     110, 116.55, 110.44, 492, 50.7, 140.4, 68.16, 111.28, 104.8,
>     59.76, 75, 91.92, 68.4, 12.92, 19.94, 22.6, 17.38, 53.6,
>     102.6, 10.45, 151.92, 30.3, 0, 0, 0, 39.18, 34.96, 16.38,
>     21.38, 18.32, 60.4, 35.48, 16.9, 0, 24.96, 56.28, 263.76,
>     38.24, 37.12, 9.26, 30.76, 26.24, 25.88, 46.48, 7.2, 21.09,
>     48.87, 0, 28.1, 10.09, 44.28, 67.26, 0, 0, 29.72, 50.49,
>     63.92, 0, 0, 0, 18.28, 10.82, 7.5, 27.06, 21.48, 9.09, 21.94,
>     13.56, 10.4, 13.25, 46.6, 31.74, 8.57, 11.98, 12.08, 30.55,
>     12.46, 31.16, 27.27, 16.35, 78.15, 100.8, 13.54, 80.44, 69.35,
>     104.55, 83.6, 37.32, 0, 107.7, 91.55, 21.52, 50.76, 22.28,
>     17, 55.6, 52.85, 40.72, 15.76, 15.12, 41.08, 25.44, 10.79,
>     87.36, 19.58, 19.94, 78.32, 13.04, 39.54, 40.55, 74.08, 14.37,
>     34.68, 31.68, 69.4, 62.28, 13.13, 117.96, 41.02, 18.27, 72.66,
>     34.74, 30.2, 69.86, 17.4, 100.89, 16.72, 95.7, 43.92, 0,
>     27.6, 129.6, 73.64, 147.4, 107.82, 92.16, 46.9, 76.1, 52.78,
>     52.32, 60.57, 46.7, 48.65, 49.41, 0, 54.8, 30.18, 59.2, 0,
>     12.52, 0, 0, 15.89, 90.39, 35.42, 26.64, 8.54, 17.46, 52.98,
>     7.88, 48.81, 12.68, 49.85, 32.67, 64.6, 41.2, 20.2, 8.47,
>     80.29, 38.52, 17.28, 35.94, 41.55, 9.4, 237.25, 0, 38.88,
>     24.56, 25.69, 0, 15.42, 0, 0, 0, 0, 467.64, 25.82, 36, 11.64,
>     112.05, 31.54, 42.08, 0, 26.86, 79.74, 0, 27.18, 17.48, 0,
>     34.95, 14.45, 43.88, 33.76, 23.24, 32.2, 16.29, 72.84, 189.99,
>     436.05, 365.6, 259.98, 329.29, 228, 158.4, 140.91, 448.95,
>     433.84, 47.11, 228.9, 193.13, 130.3, 335.73, 609.9, 202.54,
>     371.88, 332, 360.36, 219.56, 338.91, 329.94, 139.15, 262.34,
>     285.9, 357.76, 253.68, 353.35, 839.16, 368, 717.42, 840.18,
>     2081.2, 900.15, 1052.03, 705.12, 1276.65, 512.25, 838.88,
>     614.46, 734.58, 479.52, 286.38, 3020.4, 750.6, 885.96, 796.8,
>     932.49, 824.67, 1476.09, 716.76, 576.46, 528.58, 568.8, 568.8,
>     712.53, 1168.86, 1864.56, 997.26, 792.05, 1807.52, 899.25,
>     939.03, 1487.7, 1121.12, 166.5, 84.96, 78.7, 31.98, 169.2,
>     99.35, 124.2, 176.85, 116.88, 104.6, 45.43, 0, 82.44, 193.05,
>     53.5, 204.49, 135.72, 201.9, 129.76, 49.71, 50.5, 93.06,
>     239.98, 75.72, 221.54, 207.79, 218.24, 73.26, 96.4, 227.63,
>     155.4, 141.7, 280.63, 98.25, 58.4, 16.6, 30.84, 141.72, 0,
>     277.16, 313.82, 534.19, 104.74, 508.04, 67.62, 68.44, 119.7,
>     215.37, 26.92, 0, 63.24, 48.68, 11.62, 81.36, 142.5, 65.07,
>     28.06, 133.5, 126.54, 70.28, 79.62, 107.73, 36.16, 30.14,
>     31.76, 407.76, 422.24, 274.24, 317.7, 241.5, 190.3, 644.49,
>     162.17, 1104.24, 324.78, 268.24, 214.2, 449.25, 363.22, 475.57,
>     197.12, 311.63, 154.28, 461.3, 352.52, 247.69, 382.65, 395.25,
>     270.63, 399.84, 338.4, 529.48, 440.82, 394.56, 270.48, 322,
>     441.22, 353.5, 452.4, 414.96, 699.72, 89.04, 173.7, 347.6,
>     10150.24, 563.67, 353.94, 456.88, 117.92, 513, 245.48, 440.37,
>     372.36, 398.86, 334.35, 428, 410.13, 398.06, 674.87, 438.75,
>     226.16, 367.9, 416.8, 501.48, 522.6, 616.11, 421.2, 309.96,
>     423.09, 232.08, 198.06, 48.66, 109.59, 49.59, 58.05, 152.08,
>     0, 617.83, 64.66, 372.75, 32.07, 66.81, 112.24, 68.28, 83.64,
>     157.48, 145.2, 46.24, 143, 99.18, 117.5, 158.05, 61.1, 91.68,
>     67.5, 112.62, 98.21, 117.54, 58.92, 77.3, 0)), .Names = c("MONTH",
> "TRANSECT", "POLE", "TIME", "HEIGHT", "insectdens"), class =  
> "data.frame", row.names = c(1L,
> 2L, 4L, 5L, 7L, 9L, 10L, 13L, 14L, 16L, 17L, 19L, 20L, 22L, 23L,
> 25L, 26L, 28L, 29L, 31L, 32L, 34L, 35L, 37L, 38L, 40L, 41L, 43L,
> 44L, 46L, 47L, 49L, 50L, 53L, 55L, 56L, 58L, 60L, 61L, 64L, 65L,
> 67L, 68L, 70L, 71L, 73L, 74L, 76L, 77L, 79L, 80L, 82L, 83L, 85L,
> 86L, 88L, 89L, 91L, 92L, 94L, 95L, 97L, 98L, 100L, 101L, 103L,
> 104L, 106L, 107L, 109L, 111L, 112L, 115L, 116L, 118L, 119L, 121L,
> 122L, 124L, 125L, 127L, 128L, 130L, 131L, 133L, 134L, 136L, 137L,
> 139L, 140L, 142L, 143L, 145L, 146L, 148L, 149L, 151L, 152L, 154L,
> 155L, 157L, 158L, 160L, 162L, 163L, 166L, 167L, 169L, 170L, 172L,
> 173L, 175L, 176L, 178L, 179L, 181L, 182L, 184L, 185L, 187L, 188L,
> 190L, 191L, 193L, 194L, 196L, 197L, 199L, 200L, 202L, 203L, 205L,
> 206L, 208L, 209L, 211L, 213L, 214L, 217L, 218L, 220L, 221L, 223L,
> 224L, 226L, 227L, 229L, 230L, 232L, 233L, 235L, 236L, 238L, 239L,
> 241L, 242L, 244L, 245L, 247L, 248L, 250L, 251L, 253L, 254L, 256L,
> 259L, 260L, 262L, 264L, 265L, 268L, 269L, 271L, 272L, 274L, 275L,
> 277L, 278L, 280L, 281L, 283L, 284L, 286L, 287L, 289L, 290L, 292L,
> 293L, 295L, 296L, 298L, 299L, 301L, 302L, 304L, 305L, 307L, 310L,
> 311L, 313L, 315L, 316L, 319L, 320L, 322L, 323L, 325L, 326L, 328L,
> 329L, 331L, 332L, 334L, 335L, 337L, 338L, 340L, 341L, 343L, 344L,
> 346L, 347L, 349L, 350L, 352L, 353L, 355L, 356L, 358L, 359L, 361L,
> 362L, 364L, 366L, 367L, 370L, 371L, 373L, 374L, 376L, 377L, 379L,
> 380L, 382L, 383L, 385L, 386L, 388L, 389L, 394L, 395L, 397L, 398L,
> 400L, 401L, 403L, 404L, 406L, 407L, 409L, 410L, 412L, 413L, 415L,
> 417L, 418L, 421L, 422L, 424L, 425L, 427L, 428L, 430L, 431L, 433L,
> 434L, 436L, 437L, 439L, 440L, 442L, 443L, 445L, 446L, 448L, 449L,
> 451L, 452L, 454L, 455L, 457L, 458L, 460L, 461L, 463L, 464L, 466L,
> 468L, 469L, 472L, 473L, 475L, 476L, 478L, 479L, 481L, 482L, 484L,
> 485L, 487L, 488L, 490L, 491L, 493L, 494L, 496L, 497L, 499L, 500L,
> 502L, 503L, 505L, 506L, 508L, 509L, 511L, 512L, 514L, 515L, 517L,
> 519L, 520L, 523L, 524L, 526L, 527L, 529L, 530L, 532L, 533L, 535L,
> 536L, 538L, 539L, 541L, 542L, 544L, 545L, 547L, 548L, 550L, 551L,
> 553L, 554L, 556L, 557L, 559L, 560L, 562L, 563L, 565L, 566L, 568L,
> 570L, 571L, 574L, 575L, 577L, 578L, 580L, 581L, 583L, 584L, 586L,
> 587L, 589L, 590L, 592L, 593L, 595L, 596L, 598L, 599L, 601L, 602L,
> 604L, 605L, 607L, 608L, 610L, 611L, 613L, 616L, 617L, 619L, 621L,
> 622L, 625L, 626L, 628L, 629L, 631L, 632L, 634L, 635L, 637L, 638L,
> 640L, 641L, 643L, 644L, 646L, 647L, 649L, 650L, 652L, 653L, 655L,
> 656L, 658L, 659L, 661L, 662L, 664L, 667L, 668L, 670L, 672L, 673L,
> 676L, 677L, 679L, 680L, 682L, 683L, 685L, 686L, 688L, 689L, 691L,
> 692L, 694L, 695L, 697L, 698L, 700L, 701L, 703L, 704L, 706L, 707L,
> 709L, 710L, 712L, 713L, 715L, 718L, 719L, 721L, 723L, 724L, 727L,
> 728L, 730L, 731L, 733L, 734L, 736L, 737L, 739L, 740L, 742L, 743L,
> 745L, 746L, 748L, 749L, 751L, 752L, 754L, 755L, 757L, 758L, 760L,
> 761L, 763L, 764L, 766L, 769L, 770L, 772L, 774L, 775L, 778L, 779L,
> 781L, 782L, 784L, 785L, 787L, 788L, 790L, 791L, 793L, 794L, 796L,
> 797L, 799L, 800L, 802L, 803L, 805L, 806L, 808L, 809L, 811L, 812L,
> 814L, 815L))
>
>
> -- 
> This message (and any attachments) is for the recipient on...{{dropped}}



From P.Dalgaard at biostat.ku.dk  Thu Sep  6 11:51:56 2007
From: P.Dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: Thu, 06 Sep 2007 11:51:56 +0200
Subject: [R-sig-ME] magnitude of random effect vs significance
In-Reply-To: <s6ddc999.084@wpo.nerc.ac.uk>
References: <s6ddc999.084@wpo.nerc.ac.uk>
Message-ID: <46DFCDBC.3020305@biostat.ku.dk>

Mike Dunbar wrote:
> Hi Peter
>
> Just to check I'm understanding you: So in the generic case where you have a nesting say A/B/C/D, if you want to test by removal of any factor that isn't the lowest in the hierarchy then you have to re-label that factor as including the levels of the next lowest factor. So for example testing by removing A, you must recode B as interaction(A,B) and test that against the full model. If so then I already understood this in the case of POLE and TRANSECT, I'd just forgotten it for the higher level factors.
>
>   
Yes. Or put differently, using aov-like terms: If you remove A from A/B
you don't get B but A:B, because A/B==A+A:B by definition.

    -p

(BTW. "Higher" and "lower" for model terms is a bit ambiguous. With your
convention, higher-order interactions describe lower-level terms. I
prefer "coarser" and "finer" as I was taught by Tue Tjur many years ago. )

> regards
>
> Mike
>
>
>   
>>>> Peter Dalgaard <p.dalgaard at biostat.ku.dk> 04/09/2007 20:53 >>>
>>>>         
> Mike Dunbar wrote:
>   
>> Following on from previous recent post, here is an example of a random effect which is tiny but highly significant. I've got no problem explaining a fixed effect which is tiny but significant (ie precisely estimated), but I'm struggling here!
>>
>> regards
>>
>> Mike
>>
>>
>>
>> # read in temp3 first below
>> varcor.2h.crustacea.hf <- lme(log(crustdens+1) ~ HEIGHT, random=~1|MONTH/TIME/TRANSECT/POLE, data=temp3)
>> VarCorr(varcor.2h.crustacea.hf)
>>
>> varcor.2h.crustacea.nomonth.hf <- lme(log(crustdens+1) ~ HEIGHT, random=~1|TIME/TRANSECT/POLE, data=invdens.bottommiddle)
>>
>> anova(varcor.2h.crustacea.hf,varcor.2h.crustacea.nomonth.hf)
>> # month random effect of very low magnitude, yet it it highly significant: how can I explain this, or have I made a mistake!
>>
>>   
>>     
> I don't think those models are comparable. Let's ignore TRANSECT and 
> POLE for now. In one model you have MONTH with 4 groups and TIME %in% 
> MONTH with 16 groups,  and in the other you have TIME with 4 groups. Put 
> differently the variance for that term in one case means main effect of 
> TIME and in the other case ditto plus the interaction. If TIME really 
> only makes sense as nested in MONTH, the former can give a substantially 
> worse fit to data whether or not there is a MONTH term.  For 
> comparability, try this:
>
>  > temp3$MTIME <- interaction(temp3$MONTH,temp3$TIME)> 
> varcor.2h.crustacea.nomonth2.hf <- lme(log(crustdens+1) ~ HEIGHT, 
> random=~1|MTIME/TRANSECT/POLE, data=temp3)
>
>   
>> anova(varcor.2h.crustacea.hf,varcor.2h.crustacea.nomonth2.hf)                             
>>     
>                              Model df      AIC      BIC    logLik   Test
> varcor.2h.crustacea.hf              1  7 1900.187 1929.923 -943.0935       
>
> varcor.2h.crustacea.nomonth2.hf     2  6 1898.187 1923.675 -943.0935 1 vs 2
>                                      L.Ratio p-value
> varcor.2h.crustacea.hf                             
> varcor.2h.crustacea.nomonth2.hf 3.202003e-07  0.9995
>
>   


-- 
   O__  ---- Peter Dalgaard             ?ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From ajbush at bellsouth.net  Thu Sep  6 13:36:26 2007
From: ajbush at bellsouth.net (Andy Bush)
Date: Thu, 6 Sep 2007 06:36:26 -0500
Subject: [R-sig-ME] Specifying random effects for multiple covariates
	via lmer
In-Reply-To: <40e66e0b0709051922jda8f867i490b304c14e6a8df@mail.gmail.com>
Message-ID: <001101c7f07a$2a515c80$0301a8c0@AndyXPS>

Thank you for taking the time to try to help me, Douglas. I had already
formulated the suggested model as model m3 shown below.  Please note that id
is defined as "ordered" and all other variables are defined as "numeric".
Here are the models I've tried:

m1=lmer(LFEV1~Age+loght+InitAge+logbht+(1+Age|id),data=fev,
       na.action=na.omit,
       method="REML")
m2=lmer(LFEV1~Age+loght+InitAge+logbht+
       (1+loght|id),data=fev,
       na.action=na.omit,
       method="REML")
m3=lmer(LFEV1~Age+loght+InitAge+logbht+
       (Age+loght|id),
       data=fev,
       na.action=na.omit,
       method="REML")

lmer handles models m1 and m2 with no difficulty (and the results agree
quite closely with SAS Proc Mixed returns). However, lmer generates the
following warning messages for m3 and lead me to wonder if I'd mispecified
the model:

1: Estimated variance-covariance for factor 'id' is singular
 in: `LMEoptimize<-`(`*tmp*`, value = list(maxIter = 200L, tolerance =
1.49011611938477e-08,  
2: nlminb returned message false convergence (8)
 in: `LMEoptimize<-`(`*tmp*`, value = list(maxIter = 200L, tolerance =
1.49011611938477e-08,  

Please note that when I run this model through SAS Proc Mixed, I get quite
different results for the random effects without apparent convergence
problems.

Following is the lmer summary of random effects for m3:

Linear mixed-effects model fit by REML 
Formula: LFEV1 ~ Age + loght + InitAge + logbht + (Age + loght | id) 
   Data: fev 
   AIC   BIC logLik MLdeviance REMLdeviance
 -4511 -4449   2266      -4570        -4533
Random effects:
 Groups   Name Variance   Std.Dev.  Corr        
 id            3.1748e-03 0.0563455             
               7.4210e-06 0.0027241 0.064       
               9.4341e-03 0.0971292 0.064 1.000 
 Residual      3.9789e-03 0.0630788             
number of obs: 1993, groups: id, 299

In retrospect, I wonder if I should attempt to add an override for default
convergence control values in lmer for m3. 

I'll be glad to email you the dataset and programs directly if you'd like.

Respectfully,
Andy

-----Original Message-----
From: dmbates at gmail.com [mailto:dmbates at gmail.com] On Behalf Of Douglas
Bates
Sent: Wednesday, September 05, 2007 9:22 PM
To: ajbush at bellsouth.net
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Specifying random effects for multiple covariates
via lmer

On 9/5/07, Andy Bush <ajbush at bellsouth.net> wrote:
> While working through the text "Applied Longitudinal Analysis" by
> Fitzmaurice, Laird and Ware, I encountered a fairly simple case study (pp
> 210-7) in which a longitudinal model specifies three random effects: (1)
> random intercepts for id, (2) random slopes for covariate1 (Age | id), and
> (3) random slopes for covariate2 (log(ht) | id).  I've had no difficulty
> formulating lmer models with correlated random intercepts and slopes for
> either of the covariates individually but have not succeeded when I try to
> compose a model with correlated random intercepts and slopes for two
> covariates.

> Following is code that works well with the individual covariates
separately:

> m1=lmer(LFEV1~Age + loght + InitAge + logbht + (1 + Age | id),data=fev,
>        na.action=na.omit, method="REML")

> m2=lmer(LFEV1~Age + loght + InitAge + logbht+(1 + loght | id),data=fev,
>        na.action=na.omit, method="REML")

Maybe I am missing the point but wouldn't the model you are
considering be written as

lmer(LFEV1 ~ Age + loght + InitAge + logbht + (loght + Age|id), data =
fev, na.action = na.omit, method = "REML")

That provides correlated random effects for the intercept, the
coefficient for loght and the coefficient for Age at each level of the
id factor.



From bates at stat.wisc.edu  Thu Sep  6 14:31:01 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 6 Sep 2007 07:31:01 -0500
Subject: [R-sig-ME] Specifying random effects for multiple covariates
	via lmer
In-Reply-To: <001101c7f07a$2a515c80$0301a8c0@AndyXPS>
References: <40e66e0b0709051922jda8f867i490b304c14e6a8df@mail.gmail.com>
	<001101c7f07a$2a515c80$0301a8c0@AndyXPS>
Message-ID: <40e66e0b0709060531w2482d0e3hb296fdbd569a3fdb@mail.gmail.com>

On 9/6/07, Andy Bush <ajbush at bellsouth.net> wrote:
> Thank you for taking the time to try to help me, Douglas. I had already
> formulated the suggested model as model m3 shown below.  Please note that id
> is defined as "ordered" and all other variables are defined as "numeric".
> Here are the models I've tried:
>
> m1=lmer(LFEV1~Age+loght+InitAge+logbht+(1+Age|id),data=fev,
>        na.action=na.omit,
>        method="REML")
> m2=lmer(LFEV1~Age+loght+InitAge+logbht+
>        (1+loght|id),data=fev,
>        na.action=na.omit,
>        method="REML")
> m3=lmer(LFEV1~Age+loght+InitAge+logbht+
>        (Age+loght|id),
>        data=fev,
>        na.action=na.omit,
>        method="REML")
>
> lmer handles models m1 and m2 with no difficulty (and the results agree
> quite closely with SAS Proc Mixed returns). However, lmer generates the
> following warning messages for m3 and lead me to wonder if I'd mispecified
> the model:
>
> 1: Estimated variance-covariance for factor 'id' is singular
>  in: `LMEoptimize<-`(`*tmp*`, value = list(maxIter = 200L, tolerance =
> 1.49011611938477e-08,
> 2: nlminb returned message false convergence (8)
>  in: `LMEoptimize<-`(`*tmp*`, value = list(maxIter = 200L, tolerance =
> 1.49011611938477e-08,
>
> Please note that when I run this model through SAS Proc Mixed, I get quite
> different results for the random effects without apparent convergence
> problems.

Thanks for checking further on this.  I would appreciate it if you
could email the data.  One  way to do this so that it retains all the
attributes is to create an R Data save file

save(fev, file = "fev.rda")

and email that file.  The representation in such a file is independent
of the hardware and operating system.

By the way, when you get such results it is a good idea to rerun the
model fitting process with the "verbose" option set.  In the currently
released version of the lme4 package this is done with the rather
wordy argument specification

control = list(msVerbose = 1)

In the development version of the lme4 package this specification
still works or it can be shortened to

verbose = 1

> Following is the lmer summary of random effects for m3:
>
> Linear mixed-effects model fit by REML
> Formula: LFEV1 ~ Age + loght + InitAge + logbht + (Age + loght | id)
>    Data: fev
>    AIC   BIC logLik MLdeviance REMLdeviance
>  -4511 -4449   2266      -4570        -4533
> Random effects:
>  Groups   Name Variance   Std.Dev.  Corr
>  id            3.1748e-03 0.0563455
>                7.4210e-06 0.0027241 0.064
>                9.4341e-03 0.0971292 0.064 1.000
>  Residual      3.9789e-03 0.0630788
> number of obs: 1993, groups: id, 299

Notice that one of the correlations is effectively 1.00.  This
indicates a singular variance-covariance matrix for the random
effects.  The maximum likelihood estimates or the REML estimates can
correspond to a singular matrix.  In this case none of the variances
are zero, it is a variance of a linear combination of the random
effects that has been driven to zero.   SAS PROC MIXED doesn't handle
this situation well.

> In retrospect, I wonder if I should attempt to add an override for default
> convergence control values in lmer for m3.

Typically that doesn't improve the situation.  If the REML estimates
are singular no amount of tweaking of the optimization procedure will
improve the situation.

> I'll be glad to email you the dataset and programs directly if you'd like.

I appreciate the offer and look forward to examining the data and models.

> -----Original Message-----
> From: dmbates at gmail.com [mailto:dmbates at gmail.com] On Behalf Of Douglas
> Bates
> Sent: Wednesday, September 05, 2007 9:22 PM
> To: ajbush at bellsouth.net
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Specifying random effects for multiple covariates
> via lmer
>
> On 9/5/07, Andy Bush <ajbush at bellsouth.net> wrote:
> > While working through the text "Applied Longitudinal Analysis" by
> > Fitzmaurice, Laird and Ware, I encountered a fairly simple case study (pp
> > 210-7) in which a longitudinal model specifies three random effects: (1)
> > random intercepts for id, (2) random slopes for covariate1 (Age | id), and
> > (3) random slopes for covariate2 (log(ht) | id).  I've had no difficulty
> > formulating lmer models with correlated random intercepts and slopes for
> > either of the covariates individually but have not succeeded when I try to
> > compose a model with correlated random intercepts and slopes for two
> > covariates.
>
> > Following is code that works well with the individual covariates
> separately:
>
> > m1=lmer(LFEV1~Age + loght + InitAge + logbht + (1 + Age | id),data=fev,
> >        na.action=na.omit, method="REML")
>
> > m2=lmer(LFEV1~Age + loght + InitAge + logbht+(1 + loght | id),data=fev,
> >        na.action=na.omit, method="REML")
>
> Maybe I am missing the point but wouldn't the model you are
> considering be written as
>
> lmer(LFEV1 ~ Age + loght + InitAge + logbht + (loght + Age|id), data =
> fev, na.action = na.omit, method = "REML")
>
> That provides correlated random effects for the intercept, the
> coefficient for loght and the coefficient for Age at each level of the
> id factor.
>
>



From abush at utmem.edu  Thu Sep  6 17:58:02 2007
From: abush at utmem.edu (Bush, Andrew J)
Date: Thu, 6 Sep 2007 10:58:02 -0500
Subject: [R-sig-ME] lmer vs lmer2
In-Reply-To: <40e66e0b0709051922jda8f867i490b304c14e6a8df@mail.gmail.com>
References: <000f01c7f00f$91f5f6e0$0301a8c0@AndyXPS>
	<40e66e0b0709051922jda8f867i490b304c14e6a8df@mail.gmail.com>
Message-ID: <351D3C0A50D2FF47B31C2ADBD015A50D01BA1440@EXCHANGEVS1.uthsc.tennessee.edu>

Dear Douglas,

In frustration, I invoked lmer2 this morning and I'm pleased to be able
to tell you that lmer2 copes well and quickly with the model having a
random intercept and two random covariate slopes.  I have not been able
to get lmer to converge for the model on the same data.

Andy

-----Original Message-----
From: dmbates at gmail.com [mailto:dmbates at gmail.com] On Behalf Of Douglas
Bates
Sent: Wednesday, September 05, 2007 9:22 PM
To: ajbush at bellsouth.net
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Specifying random effects for multiple
covariates via lmer

On 9/5/07, Andy Bush <ajbush at bellsouth.net> wrote:
> While working through the text "Applied Longitudinal Analysis" by
> Fitzmaurice, Laird and Ware, I encountered a fairly simple case study
(pp
> 210-7) in which a longitudinal model specifies three random effects:
(1)
> random intercepts for id, (2) random slopes for covariate1 (Age | id),
and
> (3) random slopes for covariate2 (log(ht) | id).  I've had no
difficulty
> formulating lmer models with correlated random intercepts and slopes
for
> either of the covariates individually but have not succeeded when I
try to
> compose a model with correlated random intercepts and slopes for two
> covariates.

> Following is code that works well with the individual covariates
separately:

> m1=lmer(LFEV1~Age + loght + InitAge + logbht + (1 + Age |
id),data=fev,
>        na.action=na.omit, method="REML")

> m2=lmer(LFEV1~Age + loght + InitAge + logbht+(1 + loght |
id),data=fev,
>        na.action=na.omit, method="REML")

Maybe I am missing the point but wouldn't the model you are
considering be written as

lmer(LFEV1 ~ Age + loght + InitAge + logbht + (loght + Age|id), data =
fev, na.action = na.omit, method = "REML")

That provides correlated random effects for the intercept, the
coefficient for loght and the coefficient for Age at each level of the
id factor.



From bates at stat.wisc.edu  Thu Sep  6 18:17:17 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 6 Sep 2007 11:17:17 -0500
Subject: [R-sig-ME] lmer vs lmer2
In-Reply-To: <351D3C0A50D2FF47B31C2ADBD015A50D01BA1440@EXCHANGEVS1.uthsc.tennessee.edu>
References: <000f01c7f00f$91f5f6e0$0301a8c0@AndyXPS>
	<40e66e0b0709051922jda8f867i490b304c14e6a8df@mail.gmail.com>
	<351D3C0A50D2FF47B31C2ADBD015A50D01BA1440@EXCHANGEVS1.uthsc.tennessee.edu>
Message-ID: <40e66e0b0709060917y1b3c5395n24045fc1a5f1d172@mail.gmail.com>

On 9/6/07, Bush, Andrew J <abush at utmem.edu> wrote:
> Dear Douglas,

> In frustration, I invoked lmer2 this morning and I'm pleased to be able
> to tell you that lmer2 copes well and quickly with the model having a
> random intercept and two random covariate slopes.  I have not been able
> to get lmer to converge for the model on the same data.

Thanks for the information.

I expect to remove the confusion between lmer and lmer2 in the near
future.  The development version of the lme4 package has an lmer
function that is close to the current lmer2 in design.  It should
exhibit the same convergence behavior and be slightly faster on models
fit to large data sets than is the current lmer2.

This version has been in development for longer than I had expected.
I still have a few "infelicities" to resolve in the Laplace method for
generalized linear mixed models before I make test versions available.

I would be interested in the data set if you would be willing to
provide it.  I could perhaps incorporate it in the lme4 package so
others would have access to it.

> -----Original Message-----
> From: dmbates at gmail.com [mailto:dmbates at gmail.com] On Behalf Of Douglas
> Bates
> Sent: Wednesday, September 05, 2007 9:22 PM
> To: ajbush at bellsouth.net
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] Specifying random effects for multiple
> covariates via lmer
>
> On 9/5/07, Andy Bush <ajbush at bellsouth.net> wrote:
> > While working through the text "Applied Longitudinal Analysis" by
> > Fitzmaurice, Laird and Ware, I encountered a fairly simple case study
> (pp
> > 210-7) in which a longitudinal model specifies three random effects:
> (1)
> > random intercepts for id, (2) random slopes for covariate1 (Age | id),
> and
> > (3) random slopes for covariate2 (log(ht) | id).  I've had no
> difficulty
> > formulating lmer models with correlated random intercepts and slopes
> for
> > either of the covariates individually but have not succeeded when I
> try to
> > compose a model with correlated random intercepts and slopes for two
> > covariates.
>
> > Following is code that works well with the individual covariates
> separately:
>
> > m1=lmer(LFEV1~Age + loght + InitAge + logbht + (1 + Age |
> id),data=fev,
> >        na.action=na.omit, method="REML")
>
> > m2=lmer(LFEV1~Age + loght + InitAge + logbht+(1 + loght |
> id),data=fev,
> >        na.action=na.omit, method="REML")
>
> Maybe I am missing the point but wouldn't the model you are
> considering be written as
>
> lmer(LFEV1 ~ Age + loght + InitAge + logbht + (loght + Age|id), data =
> fev, na.action = na.omit, method = "REML")
>
> That provides correlated random effects for the intercept, the
> coefficient for loght and the coefficient for Age at each level of the
> id factor.
>



From obrienc at email.arizona.edu  Fri Sep  7 01:40:44 2007
From: obrienc at email.arizona.edu (Chris O'Brien)
Date: Thu, 06 Sep 2007 16:40:44 -0700
Subject: [R-sig-ME] lmer and autocorrelation structures
Message-ID: <6.2.1.2.2.20070906163033.03900eb0@inbox.email.arizona.edu>

Dear mixed-modelers,

I'm interested in modelling a dataset using generalized linear mixed models 
(specifying "family=binomial" with random effects) in which there is 
temporal autocorrelation in the response. Is there a way to do this in the 
new lme4 package?  I've used the "correlation" argument in the nlme library 
to specify a correlation structure for least-square means regression, but 
this option appears not to be implemented in the new lmer call in the lme4 
package.   Is such a thing possible (and appropriate) at this time?
thanks,

chris o'brien



From bates at stat.wisc.edu  Fri Sep  7 02:30:43 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 6 Sep 2007 19:30:43 -0500
Subject: [R-sig-ME] lmer and autocorrelation structures
In-Reply-To: <6.2.1.2.2.20070906163033.03900eb0@inbox.email.arizona.edu>
References: <6.2.1.2.2.20070906163033.03900eb0@inbox.email.arizona.edu>
Message-ID: <40e66e0b0709061730l1b8e8293j37f0c39553ee6e46@mail.gmail.com>

On 9/6/07, Chris O'Brien <obrienc at email.arizona.edu> wrote:
> Dear mixed-modelers,

> I'm interested in modelling a dataset using generalized linear mixed models
> (specifying "family=binomial" with random effects) in which there is
> temporal autocorrelation in the response. Is there a way to do this in the
> new lme4 package?  I've used the "correlation" argument in the nlme library
> to specify a correlation structure for least-square means regression, but
> this option appears not to be implemented in the new lmer call in the lme4
> package.   Is such a thing possible (and appropriate) at this time?
> thanks,

Possible, but only in the fortune("Yoda") sense.  In other words that
capability is not built into the lme4 package.

I don't think we can comment on the appropriateness of the model
without more information and perhaps a look at the data.  However,
until someone writes the code to incorporate an autoregressive
structure into lmer, the question is moot.



From bates at stat.wisc.edu  Fri Sep  7 02:32:33 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 6 Sep 2007 19:32:33 -0500
Subject: [R-sig-ME] lmer and autocorrelation structures
In-Reply-To: <40e66e0b0709061730l1b8e8293j37f0c39553ee6e46@mail.gmail.com>
References: <6.2.1.2.2.20070906163033.03900eb0@inbox.email.arizona.edu>
	<40e66e0b0709061730l1b8e8293j37f0c39553ee6e46@mail.gmail.com>
Message-ID: <40e66e0b0709061732t2ab4fd75j39130443cc7ff93e@mail.gmail.com>

On 9/6/07, Douglas Bates <bates at stat.wisc.edu> wrote:
> On 9/6/07, Chris O'Brien <obrienc at email.arizona.edu> wrote:
> > Dear mixed-modelers,
>
> > I'm interested in modelling a dataset using generalized linear mixed models
> > (specifying "family=binomial" with random effects) in which there is
> > temporal autocorrelation in the response. Is there a way to do this in the
> > new lme4 package?  I've used the "correlation" argument in the nlme library
> > to specify a correlation structure for least-square means regression, but
> > this option appears not to be implemented in the new lmer call in the lme4
> > package.   Is such a thing possible (and appropriate) at this time?
> > thanks,
>
> Possible, but only in the fortune("Yoda") sense.  In other words that
> capability is not built into the lme4 package.
>
> I don't think we can comment on the appropriateness of the model
> without more information and perhaps a look at the data.  However,
> until someone writes the code to incorporate an autoregressive
> structure into lmer, the question is moot.

P.S. If the reference to fortune("Yoda") is too obscure, try

install.packages("fortunes"); library(fortunes); fortune("Yoda")



From bates at stat.wisc.edu  Fri Sep  7 02:35:34 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 6 Sep 2007 19:35:34 -0500
Subject: [R-sig-ME] lmer and autocorrelation structures
In-Reply-To: <40e66e0b0709061732t2ab4fd75j39130443cc7ff93e@mail.gmail.com>
References: <6.2.1.2.2.20070906163033.03900eb0@inbox.email.arizona.edu>
	<40e66e0b0709061730l1b8e8293j37f0c39553ee6e46@mail.gmail.com>
	<40e66e0b0709061732t2ab4fd75j39130443cc7ff93e@mail.gmail.com>
Message-ID: <40e66e0b0709061735m73a8a30cu6be832f30ef630b2@mail.gmail.com>

On 9/6/07, Douglas Bates <bates at stat.wisc.edu> wrote:
> On 9/6/07, Douglas Bates <bates at stat.wisc.edu> wrote:
> > On 9/6/07, Chris O'Brien <obrienc at email.arizona.edu> wrote:
> > > Dear mixed-modelers,
> >
> > > I'm interested in modelling a dataset using generalized linear mixed models
> > > (specifying "family=binomial" with random effects) in which there is
> > > temporal autocorrelation in the response. Is there a way to do this in the
> > > new lme4 package?  I've used the "correlation" argument in the nlme library
> > > to specify a correlation structure for least-square means regression, but
> > > this option appears not to be implemented in the new lmer call in the lme4
> > > package.   Is such a thing possible (and appropriate) at this time?
> > > thanks,
> >
> > Possible, but only in the fortune("Yoda") sense.  In other words that
> > capability is not built into the lme4 package.
> >
> > I don't think we can comment on the appropriateness of the model
> > without more information and perhaps a look at the data.  However,
> > until someone writes the code to incorporate an autoregressive
> > structure into lmer, the question is moot.
>
> P.S. If the reference to fortune("Yoda") is too obscure, try
>
> install.packages("fortunes"); library(fortunes); fortune("Yoda")

P.P.S.  I have always felt that to qualify as a Yodaism, Simon's first
sentence should have been "R this is.", not "This is R."



From obrienc at email.arizona.edu  Fri Sep  7 19:08:29 2007
From: obrienc at email.arizona.edu (Chris O'Brien)
Date: Fri, 07 Sep 2007 10:08:29 -0700
Subject: [R-sig-ME] lmer and autocorrelation structures
Message-ID: <6.2.1.2.2.20070907100733.04cb6990@inbox.email.arizona.edu>

Dr. Bates,
Thanks for your response.  Yes, the first "Yoda" reference was too obscure, 
but the post script made
it clear, and the point is well taken.  I'll burden the list with my 
question of what is appropriate at
a later date.

cheers,
chris


Chris O'Brien
Sonoran Desert Research Station and
School of Natural Resources
Biological Sciences, room 125
University of Arizona
Tucson, AZ 85721
work (520) 623-3720
FAX (520) 671-5001
http://www.u.arizona.edu/~obrienc/



From lamprianou at yahoo.com  Sun Sep  9 08:16:28 2007
From: lamprianou at yahoo.com (Iasonas Lamprianou)
Date: Sat, 8 Sep 2007 23:16:28 -0700 (PDT)
Subject: [R-sig-ME] R-sig-mixed-models Digest, Vol 9, Issue 9
Message-ID: <929820.93969.qm@web54110.mail.re2.yahoo.com>

Dear friends,
first of all I would like to thank everybody, and especially Dr Bates, for all the support on using lmer. I now have another question. When using lmer on binary responses using family=binomial, we do not get the residual variance. In the default option (normal model) we do get the variance for every rndom effect, as well as the residual variance, so that we can compute the % of variance accounted by each effect. How can we find the residual variance in the binomial case, so that we compute the% of variance explained by each random effect? Thank you for your help once again
jason
 
Dr. Iasonas Lamprianou
Department of Education
The University of Manchester
Oxford Road, Manchester M13 9PL, UK
Tel. 0044 161 275 3485
iasonas.lamprianou at manchester.ac.uk


----- Original Message ----
From: "r-sig-mixed-models-request at r-project.org" <r-sig-mixed-models-request at r-project.org>
To: r-sig-mixed-models at r-project.org
Sent: Friday, 7 September, 2007 1:00:09 PM
Subject: R-sig-mixed-models Digest, Vol 9, Issue 9


Send R-sig-mixed-models mailing list submissions to
    r-sig-mixed-models at r-project.org

To subscribe or unsubscribe via the World Wide Web, visit
    https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
or, via email, send a message with subject or body 'help' to
    r-sig-mixed-models-request at r-project.org

You can reach the person managing the list at
    r-sig-mixed-models-owner at r-project.org

When replying, please edit your Subject line so it is more specific
than "Re: Contents of R-sig-mixed-models digest..."


Today's Topics:

   1. Re: lmer and autocorrelation structures (Douglas Bates)


----------------------------------------------------------------------

Message: 1
Date: Thu, 6 Sep 2007 19:35:34 -0500
From: "Douglas Bates" <bates at stat.wisc.edu>
Subject: Re: [R-sig-ME] lmer and autocorrelation structures
To: "Chris O'Brien" <obrienc at email.arizona.edu>
Cc: r-sig-mixed-models at r-project.org
Message-ID:
    <40e66e0b0709061735m73a8a30cu6be832f30ef630b2 at mail.gmail.com>
Content-Type: text/plain; charset=ISO-8859-1

On 9/6/07, Douglas Bates <bates at stat.wisc.edu> wrote:
> On 9/6/07, Douglas Bates <bates at stat.wisc.edu> wrote:
> > On 9/6/07, Chris O'Brien <obrienc at email.arizona.edu> wrote:
> > > Dear mixed-modelers,
> >
> > > I'm interested in modelling a dataset using generalized linear mixed models
> > > (specifying "family=binomial" with random effects) in which there is
> > > temporal autocorrelation in the response. Is there a way to do this in the
> > > new lme4 package?  I've used the "correlation" argument in the nlme library
> > > to specify a correlation structure for least-square means regression, but
> > > this option appears not to be implemented in the new lmer call in the lme4
> > > package.   Is such a thing possible (and appropriate) at this time?
> > > thanks,
> >
> > Possible, but only in the fortune("Yoda") sense.  In other words that
> > capability is not built into the lme4 package.
> >
> > I don't think we can comment on the appropriateness of the model
> > without more information and perhaps a look at the data.  However,
> > until someone writes the code to incorporate an autoregressive
> > structure into lmer, the question is moot.
>
> P.S. If the reference to fortune("Yoda") is too obscure, try
>
> install.packages("fortunes"); library(fortunes); fortune("Yoda")

P.P.S.  I have always felt that to qualify as a Yodaism, Simon's first
sentence should have been "R this is.", not "This is R."



------------------------------

_______________________________________________
R-sig-mixed-models mailing list
R-sig-mixed-models at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


End of R-sig-mixed-models Digest, Vol 9, Issue 9
************************************************


      ___________________________________________________________

now.



From pts007 at hotmail.com  Sun Sep  9 16:57:39 2007
From: pts007 at hotmail.com (ts p)
Date: Sun, 09 Sep 2007 14:57:39 +0000
Subject: [R-sig-ME] How to estimate the scale parameter in R
Message-ID: <BAY138-F391C9600234E98CBC178A08FC70@phx.gbl>

I use SAS PROC GLIMMIX to estimate generalized linear mixed model. The 
procedure can estimate the scale parameter and R-side random effects of 
GLMM. I wonder if I want to estimate the scale parameter and R-side random 
effects in R. I wonder which function in R I should use to do that.

Thanks!



From pierces1 at msu.edu  Mon Sep 10 05:35:42 2007
From: pierces1 at msu.edu (Steven J. Pierce)
Date: Sun, 9 Sep 2007 23:35:42 -0400
Subject: [R-sig-ME] Underdispersion in multilevel logistic regression
In-Reply-To: <929820.93969.qm@web54110.mail.re2.yahoo.com>
References: <929820.93969.qm@web54110.mail.re2.yahoo.com>
Message-ID: <001501c7f35b$aa814300$0a00a8c0@TheVoid>

Hi folks,

I'm doing some multilevel logistic models with lmer() and I noticed that the
estimated scale in my model (see code & results below) suggests the presence
of under-dispersion. Are there any guidelines on when the scale is
sufficiently far from 1 that one should conclude that underdispersion (or
overdispersion) is serious enough to warrant switching from family =
binomial(logit) to family = quasibinomial(logit)?

> model.17f <- lmer(formula = EventTV ~ Period + OR1pc + OR1flyer + OR2pctv
+ 
+                             OR2flyertv + Spanish_Version + MUDwell + 0 +
+                             (1 | ClusterID) + (1 | SurveyID), 
+                 data=RS05.Round1A, family = binomial(logit),
method="Laplace")   
> summary(model.17f)
Generalized linear mixed model fit using Laplace 
Formula: EventTV ~ Period + OR1pc + OR1flyer + OR2pctv + OR2flyertv +
Spanish_Version + MUDwell + 0 + (1 | ClusterID) + (1 | SurveyID) 
   Data: RS05.Round1A 
 Family: binomial(logit link)
  AIC  BIC logLik deviance
 5324 5578  -2631     5262
Random effects:
 Groups    Name Variance   Std.Dev.  
 SurveyID       1.4455e+00 1.2023e+00
 ClusterID      5.0000e-10 2.2361e-05
number of obs: 27460, groups: SurveyID, 1787; ClusterID, 52

Estimated scale (compare to  1 )  0.6785013 
 


Steven J. Pierce, M.S.
Doctoral Student in Ecological/Community Psychology
Department of Psychology
Michigan State University
240B Psychology Building
East Lansing, MI 48824-1116

E-mail: pierces1 at msu.edu
Web: http://www.psychology.msu.edu/eco/



From smitaj at ukzn.ac.za  Mon Sep 10 06:39:06 2007
From: smitaj at ukzn.ac.za (AJ Smit)
Date: Mon, 10 Sep 2007 06:39:06 +0200
Subject: [R-sig-ME] lmer and lme: using apply etc.
Message-ID: <8220E91F-E37C-418E-9734-D930886439FD@ukzn.ac.za>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20070910/afca491e/attachment.pl>

From bxc at steno.dk  Mon Sep 10 12:40:51 2007
From: bxc at steno.dk (BXC (Bendix Carstensen))
Date: Mon, 10 Sep 2007 12:40:51 +0200
Subject: [R-sig-ME] lmer and lme: using apply etc.
In-Reply-To: <8220E91F-E37C-418E-9734-D930886439FD@ukzn.ac.za>
Message-ID: <40D3930AC1C8EA469E39536E5BC8083504AAEE14@EXDKBA021.corp.novocorp.net>

Isn't it because you use

data2[2]/ data2[25]

instead of

data2[,2]/ data2[,25] 

Best 
Bendix
______________________________________________

Bendix Carstensen
Senior Statistician
Steno Diabetes Center
Niels Steensens Vej 2-4
DK-2820 Gentofte
Denmark
+45 44 43 87 38 (direct)
+45 30 75 87 38 (mobile)
+45 44 43 73 13 (fax)
bxc at steno.dk   http://www.biostat.ku.dk/~bxc 

> -----Original Message-----
> From: r-sig-mixed-models-bounces at r-project.org 
> [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of AJ Smit
> Sent: Monday, September 10, 2007 6:39 AM
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] lmer and lme: using apply etc.
> 
> Dear Mixed Model users,
> 
> I want to fit the same mixed model to each of 21 variables 
> (columns) in my dataset. If coded individually for each 
> variable it would look like this:
> 
> lmer(colour ~ feed + (-1 + feed | taster), data = data2)
> 
> Then I just change 'colour' and run through the variables on 
> at a time. Or I can use apply or for statements like this to 
> cycle through each variable like this:
> 
> auto <- function(x) lmer(x ~ data2$feed + (-1 + data2$feed | data2
> $taster))
> apply(data2[3:22], 2, auto)
> 
> or
> 
> for(i in 3:22) print(c(names(data2[i]), 
> summary(lmer(data2[,i] ~ 1 + data2$feed + (-1 + data2$feed | 
> data2$taster)))))
> 
> Either works fine. However, when I try the same with lme it does not
> work:
> 
>  > for(i in 3:22) lme(data2[,i] ~ data2[25], random = ~1 | 
> data2[2]/ data2[25], method = "ML")
> 
> Error in model.frame(formula, rownames, variables, varnames, 
> extras, extranames,  :
> 	invalid type (list) for variable 'data2'
> 
> (column 25 is has the name taster, and 2 feed)
> 
> Any ideas why it works for one but not the other? I suppose I 
> could stack the 21 response variable and then use dummy 
> variables to code the multivariate response, but that would 
> be a bit cumbersome.
> 
> Thanks,
> AJ
> 
> ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
> Dr Albertus J Smit
> (Marine Biologist)
> School of Biological & Conservation Sciences G. Campbell 
> Building University of KwaZulu-Natal Howard College Campus 
> Durban 4041, South Africa
> 
> E-mail: smitaj at ukzn.ac.za
> Tel. +27 031 260 7410;
> Fax +27 031 260 2029
> 
> Marine Biology web page: http://marinesci.ukzn.ac.za/biology
> ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
> 
> "The ocean weeds out, from all the races of mankind that come 
> upon it to make a living, a certain type of person. This type 
> of person stays with the ocean, and the rest are cast back 
> ashore to deal with the land people." ~~ Wilbert Chapman
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From maechler at stat.math.ethz.ch  Mon Sep 10 12:39:20 2007
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 10 Sep 2007 12:39:20 +0200
Subject: [R-sig-ME] How to estimate the scale parameter in R
In-Reply-To: <BAY138-F391C9600234E98CBC178A08FC70@phx.gbl>
References: <BAY138-F391C9600234E98CBC178A08FC70@phx.gbl>
Message-ID: <18149.7896.584447.840678@stat.math.ethz.ch>

>>>>> "tp" == ts p <pts007 at hotmail.com>
>>>>>     on Sun, 09 Sep 2007 14:57:39 +0000 writes:

    tp> I use SAS PROC GLIMMIX to estimate generalized linear mixed model. The 
    tp> procedure can estimate the scale parameter and R-side random effects of 
    tp> GLMM. I wonder if I want to estimate the scale parameter and R-side random 
    tp> effects in R. I wonder which function in R I should use to do that.

Please consider reading and obeying the posting guide
==> http://www.r-project.org/posting-guide.html 
and then probably repost your question: 
--> more details; your identity?

Martin



From pierces1 at msu.edu  Mon Sep 10 17:47:35 2007
From: pierces1 at msu.edu (Steven J. Pierce)
Date: Mon, 10 Sep 2007 11:47:35 -0400
Subject: [R-sig-ME] How to estimate the scale parameter in R
In-Reply-To: <BAY138-F391C9600234E98CBC178A08FC70@phx.gbl>
References: <BAY138-F391C9600234E98CBC178A08FC70@phx.gbl>
Message-ID: <001301c7f3c1$e85ec0b0$8d300d23@TheVoid>

Take a look at the lme4 package, particularly the lmer() and glmer()
functions provided in that package. 


Steven J. Pierce
E-mail: pierces1 at msu.edu

-----Original Message-----
From: ts p [mailto:pts007 at hotmail.com] 
Sent: Sunday, September 09, 2007 10:58 AM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] How to estimate the scale parameter in R

I use SAS PROC GLIMMIX to estimate generalized linear mixed model. The
procedure can estimate the scale parameter and R-side random effects of
GLMM. I wonder if I want to estimate the scale parameter and R-side random
effects in R. I wonder which function in R I should use to do that.

Thanks!



From bates at stat.wisc.edu  Mon Sep 10 21:17:27 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 10 Sep 2007 14:17:27 -0500
Subject: [R-sig-ME] R-sig-mixed-models Digest, Vol 9, Issue 9
In-Reply-To: <929820.93969.qm@web54110.mail.re2.yahoo.com>
References: <929820.93969.qm@web54110.mail.re2.yahoo.com>
Message-ID: <40e66e0b0709101217s7d177625g4a7919daed3a5212@mail.gmail.com>

On 9/9/07, Iasonas Lamprianou <lamprianou at yahoo.com> wrote:
> Dear friends,
> first of all I would like to thank everybody, and especially Dr Bates, for all the support on using lmer. I now have another question. When using lmer on binary responses using family=binomial, we do not get the residual variance. In the default option (normal model) we do get the variance for every rndom effect, as well as the residual variance, so that we can compute the % of variance accounted by each effect. How can we find the residual variance in the binomial case, so that we compute the% of variance explained by each random effect? Thank you for your help once again

The binomial distribution is determined by the mean (i.e. the
probability of success on each trial) and the number of trials.
Unlike the normal distribution there is no scale parameter in addition
to the parameters determining the mean.  If the distribution of the
response in a mixed model, conditional on the value of the linear
predictor, is binomial then there is no separate calculation of the
residual variance and you cannot meaningfully talk about % of variance
accounted for by each effect.



From bates at stat.wisc.edu  Mon Sep 10 21:23:06 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 10 Sep 2007 14:23:06 -0500
Subject: [R-sig-ME] Underdispersion in multilevel logistic regression
In-Reply-To: <001501c7f35b$aa814300$0a00a8c0@TheVoid>
References: <929820.93969.qm@web54110.mail.re2.yahoo.com>
	<001501c7f35b$aa814300$0a00a8c0@TheVoid>
Message-ID: <40e66e0b0709101223x1927ce71g79c3de90e79bd60e@mail.gmail.com>

You have a variance component for ClusterID that is being estimated as
"effectively zero".  You should refit the model with that random
effects term removed and check the estimated scale for the modified
model.

I don't have good guidelines for under- or over-dispersion.  When the
estimated scale is < 0.75 I get concerned and when it is < 0.5 I get
very concerned but I don't know if those are reasonable comparison
values or not.

On 9/9/07, Steven J. Pierce <pierces1 at msu.edu> wrote:
> Hi folks,
>
> I'm doing some multilevel logistic models with lmer() and I noticed that the
> estimated scale in my model (see code & results below) suggests the presence
> of under-dispersion. Are there any guidelines on when the scale is
> sufficiently far from 1 that one should conclude that underdispersion (or
> overdispersion) is serious enough to warrant switching from family =
> binomial(logit) to family = quasibinomial(logit)?
>
> > model.17f <- lmer(formula = EventTV ~ Period + OR1pc + OR1flyer + OR2pctv
> +
> +                             OR2flyertv + Spanish_Version + MUDwell + 0 +
> +                             (1 | ClusterID) + (1 | SurveyID),
> +                 data=RS05.Round1A, family = binomial(logit),
> method="Laplace")
> > summary(model.17f)
> Generalized linear mixed model fit using Laplace
> Formula: EventTV ~ Period + OR1pc + OR1flyer + OR2pctv + OR2flyertv +
> Spanish_Version + MUDwell + 0 + (1 | ClusterID) + (1 | SurveyID)
>    Data: RS05.Round1A
>  Family: binomial(logit link)
>   AIC  BIC logLik deviance
>  5324 5578  -2631     5262
> Random effects:
>  Groups    Name Variance   Std.Dev.
>  SurveyID       1.4455e+00 1.2023e+00
>  ClusterID      5.0000e-10 2.2361e-05
> number of obs: 27460, groups: SurveyID, 1787; ClusterID, 52
>
> Estimated scale (compare to  1 )  0.6785013
>
>
>
> Steven J. Pierce, M.S.
> Doctoral Student in Ecological/Community Psychology
> Department of Psychology
> Michigan State University
> 240B Psychology Building
> East Lansing, MI 48824-1116
>
> E-mail: pierces1 at msu.edu
> Web: http://www.psychology.msu.edu/eco/
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From gangchen at mail.nih.gov  Mon Sep 10 21:59:38 2007
From: gangchen at mail.nih.gov (Gang Chen)
Date: Mon, 10 Sep 2007 15:59:38 -0400
Subject: [R-sig-ME] Dealing with large datasets in lme/lmer
In-Reply-To: <40e66e0b0709051211y22c7e896g94ef1c38200a50cb@mail.gmail.com>
References: <3002B649-86D2-42DA-981E-9639CAAF8E37@mail.nih.gov>
	<40e66e0b0709051211y22c7e896g94ef1c38200a50cb@mail.gmail.com>
Message-ID: <823D13BA-AED5-4FCD-BA2A-B3A090D02DCF@mail.nih.gov>

Dr. Bates,

Thank you very much for the quick response and suggestions.

I really want to try out the lmer development package, but could not  
figure out how to download it. I tried to run

wget https://svn.r-project.org/R-packages/branches/gappy-lmer/
(Or wget --no-check-certificate -r -nv -m -np -nH https://svn.r- 
project.org/R-packages/branches/gappy-lmer/ )

but it didn't work. So how can I obtain the package? Do I only need  
the files under

https://svn.r-project.org/R-packages/branches/gappy-lmer/R/

or do I need to compile/build the package with the source code somehow?

Thanks,
Gang

=========
Gang Chen, Ph. D.
National Institutes of Health, HHS


On Sep 5, 2007, at 3:11 PM, Douglas Bates wrote:

> On 9/4/07, Gang Chen <gangchen at mail.nih.gov> wrote:
>> Dear all,
>
>> I'm running mixed-effects analysis with large datasets in a loop like
>> this:
>
>> for (i in 1:60) {
>> for (j in 1:60) {
>> for (k in 1:60) {
>>     [...update y here in Model here...]
>>     fit.lme <- lme(y ~ FA*FB*FC+weight, random = pdBlocked(list
>> (pdCompSymm(~FB-1), pdCompSymm(~FC-1), pdIdent(~1))),  
>> weights=varIdent
>> (form=~1|FA), Model);
>>     Stat[i, j, k,] <- anova(fit.lme)$F[-1];
>> }
>> }
>> }
>
> Did you create the array Stat outside the loop?  If not you will be
> doing a lot of copying of elements of that array.
>
>> This takes a little over 100 hours to finish on a Mac G5 with duo
>> 2.7GHz processors and 4GB memory.
>
>> In the mixed-effects model
>
>> y = X*beta + Z*b + e
>
>> the fixed-effects nxp matrix X and random-effects matrix nxq Z are
>> always the same for all the iterations in my case, and the only thing
>> that differs is y (and the estimates of beta, b and e also differ of
>> course). In my case n = 504 (large), p and q are moderate.  I just
>> read Dr. Douglas Bates's presentation during uerR! 2007 (very
>> informative by the way):
>
> Thank you.
>
>> http://user2007.org/program/presentations/bates.pdf
>
>> It seems many components in the extended system matrix (equation (2)
>> on page 22) for the Cholesky decomposition remain the same during the
>> iterations. So there are a lot of repetitive computations on those
>> same matrix operations in the above loop. How can I achieve a better
>> efficiency? Someone suggested to me running lme/lmer with a two-
>> dimensional response Y instead of one-dimensional y. My questions  
>> are:
>
>> (1) So far I have only seen people running lme/lmer with y in a
>> format of one-dimensional array from a table. If I combine all those
>> y's (indices i, j, k) into an two-dimensional array Y, is there a way
>> I can run lme/lmer on Y instead of y? In other words, does lme/lmer
>> take a two-dimensional array Y?
>
> Not at present.
>
>> If so, do I have to save the huge
>> array in a table in text file and then read in R before I run lme/
>> lmer?
>
> No.  There are many ways of getting data into R other than creating a
> text file and reading it.  See the manual "R Data Import/Export" and
> also Martin Maechler's presentation at useR!2007.
> http://user2007.org/program/presentations/maechler.pdf
>
>> Also if that is the case, how can I label those many columns
>> somehow associated with Y?
>
>> (2) A more serious concern is about memory. With the current looping
>> approach it uses about 1GB. If I could possibly go with the matrix
>> method described in (1), I'm worried that it might not be practically
>> feasible with the current computers. Any thoughts?
>
> Well first you are discussing the computational methods used in lmer
> but you want to fit a model with different residual variances for
> different groups.  At present you can't do that in lmer.
>
> If you look at the lmer function in the development version of the
> lme4 package (currently at
> https://svn.r-project.org/R-packages/branches/gappy-lmer, soon to be
> at http://r-forge.r-project.org/projects/lme4 for some value of
> "soon") you will see that it follows the equations in my useR
> presentation fairly closely.  The Xy array is n by (p + 1) with X in
> the first p columns and y in the p + 1st column.  The object of class
> "lmer" has slots named y, Zt (Z-transpose), ZtXy (Zt %*% Xy), and
> XytXy (crossprod(Xy)). After fitting the model to the first simulated
> response, producing the object 'fm',  the only operations needed to
> update the model are
>
>  fm at y <- newy
>  Xy <- cbind(fm at X, fm at y)
>  fm at ZtXy <- fm at Zt %*% Xy
>  fm at XytXy <- crossprod(Xy)
>  lme4:::mer_finalize(fm, verbose)
>
> where 'verbose' is a logical scalar indicating if you want verbose
> output during the optimization phase.  Once you get things working on
> a small example you would probably want to turn that off.
>
> Please note that this code applies to the development version of the
> lme4 package.



From bates at stat.wisc.edu  Mon Sep 10 22:26:56 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 10 Sep 2007 15:26:56 -0500
Subject: [R-sig-ME] Dealing with large datasets in lme/lmer
In-Reply-To: <823D13BA-AED5-4FCD-BA2A-B3A090D02DCF@mail.nih.gov>
References: <3002B649-86D2-42DA-981E-9639CAAF8E37@mail.nih.gov>
	<40e66e0b0709051211y22c7e896g94ef1c38200a50cb@mail.gmail.com>
	<823D13BA-AED5-4FCD-BA2A-B3A090D02DCF@mail.nih.gov>
Message-ID: <40e66e0b0709101326i7c0984eaqaed39da1a95a091d@mail.gmail.com>

The best way to obtain the package sources is with a subversion
client.  On Linux it is called svn.  The call to check out a copy of
the package sources is

svn co https://svn.r-project.org/R-packages/branches/gappy-lmer ./lme4

You need the whole directory to build the package.  Under Linux or Mac
OS X I use

R CMD INSTALL ./lme4

For Windows I use Uwe's win-builder at win-builder.R-project.org

On 9/10/07, Gang Chen <gangchen at mail.nih.gov> wrote:
> Dr. Bates,
>
> Thank you very much for the quick response and suggestions.
>
> I really want to try out the lmer development package, but could not
> figure out how to download it. I tried to run
>
> wget https://svn.r-project.org/R-packages/branches/gappy-lmer/
> (Or wget --no-check-certificate -r -nv -m -np -nH https://svn.r-
> project.org/R-packages/branches/gappy-lmer/ )
>
> but it didn't work. So how can I obtain the package? Do I only need
> the files under
>
> https://svn.r-project.org/R-packages/branches/gappy-lmer/R/
>
> or do I need to compile/build the package with the source code somehow?
>
> Thanks,
> Gang
>
> =========
> Gang Chen, Ph. D.
> National Institutes of Health, HHS
>
>
> On Sep 5, 2007, at 3:11 PM, Douglas Bates wrote:
>
> > On 9/4/07, Gang Chen <gangchen at mail.nih.gov> wrote:
> >> Dear all,
> >
> >> I'm running mixed-effects analysis with large datasets in a loop like
> >> this:
> >
> >> for (i in 1:60) {
> >> for (j in 1:60) {
> >> for (k in 1:60) {
> >>     [...update y here in Model here...]
> >>     fit.lme <- lme(y ~ FA*FB*FC+weight, random = pdBlocked(list
> >> (pdCompSymm(~FB-1), pdCompSymm(~FC-1), pdIdent(~1))),
> >> weights=varIdent
> >> (form=~1|FA), Model);
> >>     Stat[i, j, k,] <- anova(fit.lme)$F[-1];
> >> }
> >> }
> >> }
> >
> > Did you create the array Stat outside the loop?  If not you will be
> > doing a lot of copying of elements of that array.
> >
> >> This takes a little over 100 hours to finish on a Mac G5 with duo
> >> 2.7GHz processors and 4GB memory.
> >
> >> In the mixed-effects model
> >
> >> y = X*beta + Z*b + e
> >
> >> the fixed-effects nxp matrix X and random-effects matrix nxq Z are
> >> always the same for all the iterations in my case, and the only thing
> >> that differs is y (and the estimates of beta, b and e also differ of
> >> course). In my case n = 504 (large), p and q are moderate.  I just
> >> read Dr. Douglas Bates's presentation during uerR! 2007 (very
> >> informative by the way):
> >
> > Thank you.
> >
> >> http://user2007.org/program/presentations/bates.pdf
> >
> >> It seems many components in the extended system matrix (equation (2)
> >> on page 22) for the Cholesky decomposition remain the same during the
> >> iterations. So there are a lot of repetitive computations on those
> >> same matrix operations in the above loop. How can I achieve a better
> >> efficiency? Someone suggested to me running lme/lmer with a two-
> >> dimensional response Y instead of one-dimensional y. My questions
> >> are:
> >
> >> (1) So far I have only seen people running lme/lmer with y in a
> >> format of one-dimensional array from a table. If I combine all those
> >> y's (indices i, j, k) into an two-dimensional array Y, is there a way
> >> I can run lme/lmer on Y instead of y? In other words, does lme/lmer
> >> take a two-dimensional array Y?
> >
> > Not at present.
> >
> >> If so, do I have to save the huge
> >> array in a table in text file and then read in R before I run lme/
> >> lmer?
> >
> > No.  There are many ways of getting data into R other than creating a
> > text file and reading it.  See the manual "R Data Import/Export" and
> > also Martin Maechler's presentation at useR!2007.
> > http://user2007.org/program/presentations/maechler.pdf
> >
> >> Also if that is the case, how can I label those many columns
> >> somehow associated with Y?
> >
> >> (2) A more serious concern is about memory. With the current looping
> >> approach it uses about 1GB. If I could possibly go with the matrix
> >> method described in (1), I'm worried that it might not be practically
> >> feasible with the current computers. Any thoughts?
> >
> > Well first you are discussing the computational methods used in lmer
> > but you want to fit a model with different residual variances for
> > different groups.  At present you can't do that in lmer.
> >
> > If you look at the lmer function in the development version of the
> > lme4 package (currently at
> > https://svn.r-project.org/R-packages/branches/gappy-lmer, soon to be
> > at http://r-forge.r-project.org/projects/lme4 for some value of
> > "soon") you will see that it follows the equations in my useR
> > presentation fairly closely.  The Xy array is n by (p + 1) with X in
> > the first p columns and y in the p + 1st column.  The object of class
> > "lmer" has slots named y, Zt (Z-transpose), ZtXy (Zt %*% Xy), and
> > XytXy (crossprod(Xy)). After fitting the model to the first simulated
> > response, producing the object 'fm',  the only operations needed to
> > update the model are
> >
> >  fm at y <- newy
> >  Xy <- cbind(fm at X, fm at y)
> >  fm at ZtXy <- fm at Zt %*% Xy
> >  fm at XytXy <- crossprod(Xy)
> >  lme4:::mer_finalize(fm, verbose)
> >
> > where 'verbose' is a logical scalar indicating if you want verbose
> > output during the optimization phase.  Once you get things working on
> > a small example you would probably want to turn that off.
> >
> > Please note that this code applies to the development version of the
> > lme4 package.
>



From mdu at ceh.ac.uk  Tue Sep 11 13:48:59 2007
From: mdu at ceh.ac.uk (Mike Dunbar)
Date: Tue, 11 Sep 2007 12:48:59 +0100
Subject: [R-sig-ME] magnitude of random effect vs significance: try 2
Message-ID: <s6e68eda.056@wpo.nerc.ac.uk>


I'm hoping I am getting close to the end of posting on this topic and associated topic "explaining lme variance component results". 

Firstly many thanks again to John, Peter and Kevin for comments so far. I have discovered an error in the coding in one row, now corrected (thanks John) and am also much more informed as to how to ensure correct coding for nested model comparison (thanks Peter). 

I'm also better informed as to the links between anova-based analyses and REML-based (thanks John), but still struggle with these anovas.

Two points I'd like to follow up on.

1.
Firstly Kevin's point that 
"In my experience with biological data, factors that have levels that are widely (temporal/spatial) separated are often more variable than factors with levels that are closer together"
and linked to John's points
"Variances are not, for quantities that are differences multiples of chi-squared statistics, a good basis for inference."
and
"The estimate for s1^2 (MONTH} has a statistical error that is a compound of the errors in the ANOVA mean squares for both TIME and MONTH."

Generalising from anova mean squares principles, it makes sense that the variation for coarser-grain factors (i.e. less well replicated, more widely varying in time and or space) is likely to be higher by chance because confounded within it is some of the variation that ought to be in the finer level factors (whether the factors are specifed or unknown). In addition, the inevitable poorer replication at the coarse level reduces power. Now I can see how this follows analytically in the case of anova mean squares derived analysis, however I'd just like some advice that the same principles apply in REML-derived analyses. 

If this reasoning is correct, then I have no trouble explaining the results from the attached analysis. In this case, to abbreviate the full table, we have.
	Variance	p-value (from LR test, removing single factor)
MONTH	0.639	0.1889
..
POLE	0.160	0.0496
...
Note that month is the coarser grain factor, and pole the finer. If there are any references as to why its the p-values from LR tests that matter and not the magnitude of the components (other than John Maindonald, pers. comm. which is OK of course) that would do me a massive favour. In my manuscript, I could of course illustrate with anova-derived workings now John has explained this, but I would prefer to just present the REML-based analyses. 

2.
I'm still slightly muddled about the implications of including a random effect at the finest unreplicated level. Again I can understand that since there is no replication, the random effect at that level should be confounded with the residual. However, in practice, lme(r) still gives separate variances for the two components. How can this be? Is REML extracting some information that is not available in an anova-based analysis. In the analysis below, replication is obtained at the finest level by there being 2 levels of the height factor in many cases (but not all, its unbalanced), but since I know there is a consistent height effect, I add a fixed effect for this, are we back to square one and no fine-level replication. Again I would appreciate any advice and will try to bring this to a close now (honest!)

regards

Mike



# analysis: data are below
varcor.2h.insects.hf <- lme(log(insectdens+1) ~ HEIGHT, random=~1|MONTH/TIME/TRANSECT/POLE, data=temp4)
VarCorr(varcor.2h.insects.hf)
# variance for month: 0.639, time: 1.24, transect: 0.013, pole: 0.160, resid: 1.02

varcor.2h.insects.nomonth.hf <- lme(log(insectdens+1) ~ HEIGHT, random=~1|MONTHTIME/TRANSECT/POLE, data=invdens.bottommiddle) # P Dalgaard email
varcor.2h.insects.nopole.hf <- lme(log(insectdens+1) ~ HEIGHT, random=~1|MONTH/TIME/TRANSECT, data=invdens.bottommiddle)

anova(varcor.2h.insects.hf,varcor.2h.insects.nomonth.hf) # p=0.1889
anova(varcor.2h.insects.hf,varcor.2h.insects.nopole.hf) # p= 0.0496 (p is lower if ns month and transect terms removed)



# read in data first
temp4 <-
structure(list(MONTH = structure(as.integer(c(1, 1, 1, 1, 1, 
1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 
1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 
1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 
1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 
1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 
1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 
2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 
2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 
2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 
2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 
2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 
2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 
2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 
3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 
3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 
3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 
3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 
3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 
3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 
4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 
4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 
4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 
4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 
4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 
4, 4, 4, 4, 4, 4, 4, 4, 4, 4)), .Label = c("4", "5", "6", "7"
), class = "factor"), TRANSECT = structure(as.integer(c(1, 1, 
1, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 
4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 3, 
3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 
1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 
4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 1, 1, 1, 1, 1, 1, 1, 2, 2, 
2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 
5, 5, 5, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 
3, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 1, 1, 1, 1, 1, 1, 
2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 5, 
5, 5, 5, 5, 5, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 
3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 1, 1, 1, 1, 1, 
1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 5, 
5, 5, 5, 5, 5, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 3, 
3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 1, 1, 1, 1, 
1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 
4, 4, 5, 5, 5, 5, 5, 5, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 
3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 1, 
1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 
4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 
3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 
5, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 
4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 1, 1, 1, 1, 1, 1, 2, 2, 2, 
2, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 
5, 5, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 4, 
4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5)), .Label = c("1", "2", 
"3", "4", "5"), class = "factor"), POLE = structure(as.integer(c(1, 
1, 2, 2, 3, 4, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9, 10, 10, 11, 11, 
12, 12, 13, 13, 14, 14, 15, 16, 17, 17, 18, 18, 1, 2, 2, 3, 4, 
4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9, 10, 10, 11, 11, 12, 12, 13, 
13, 14, 14, 15, 16, 17, 17, 18, 18, 1, 1, 2, 2, 3, 4, 4, 5, 5, 
6, 6, 7, 7, 8, 8, 9, 9, 10, 10, 11, 11, 12, 12, 13, 13, 14, 14, 
15, 16, 17, 17, 18, 18, 1, 1, 2, 2, 3, 4, 4, 5, 5, 6, 6, 7, 7, 
8, 8, 9, 9, 10, 10, 11, 11, 12, 12, 13, 13, 14, 14, 15, 16, 17, 
17, 18, 18, 1, 1, 2, 2, 3, 4, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9, 
10, 10, 11, 11, 12, 12, 13, 13, 14, 14, 15, 16, 17, 17, 18, 18, 
1, 2, 2, 3, 4, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9, 10, 10, 11, 11, 
12, 12, 13, 13, 14, 14, 15, 16, 17, 17, 18, 18, 1, 2, 2, 3, 4, 
4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9, 10, 10, 11, 11, 12, 12, 13, 
13, 14, 14, 15, 16, 17, 17, 18, 18, 1, 1, 2, 2, 3, 4, 4, 5, 5, 
6, 6, 7, 7, 8, 8, 9, 9, 10, 10, 11, 11, 13, 13, 14, 14, 15, 16, 
17, 17, 18, 18, 1, 1, 2, 2, 3, 4, 4, 5, 5, 6, 6, 7, 7, 8, 8, 
9, 9, 10, 10, 11, 11, 12, 12, 13, 13, 14, 14, 15, 16, 17, 17, 
18, 18, 1, 1, 2, 2, 3, 4, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9, 10, 
10, 11, 11, 12, 12, 13, 13, 14, 14, 15, 16, 17, 17, 18, 18, 1, 
1, 2, 2, 3, 4, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9, 10, 10, 11, 11, 
12, 12, 13, 13, 14, 14, 15, 16, 17, 17, 18, 18, 1, 1, 2, 2, 3, 
4, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9, 10, 10, 11, 11, 12, 12, 13, 
13, 14, 14, 15, 16, 17, 17, 18, 18, 1, 2, 2, 3, 4, 4, 5, 5, 6, 
6, 7, 7, 8, 8, 9, 9, 10, 10, 11, 11, 12, 12, 13, 13, 14, 14, 
15, 16, 17, 17, 18, 18, 1, 2, 2, 3, 4, 4, 5, 5, 6, 6, 7, 7, 8, 
8, 9, 9, 10, 10, 11, 11, 12, 12, 13, 13, 14, 14, 15, 16, 17, 
17, 18, 18, 1, 2, 2, 3, 4, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9, 10, 
10, 11, 11, 12, 12, 13, 13, 14, 14, 15, 16, 17, 17, 18, 18, 1, 
2, 2, 3, 4, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9, 10, 10, 11, 11, 
12, 12, 13, 13, 14, 14, 15, 16, 17, 17, 18, 18)), .Label = c("11", 
"12", "13", "14", "23", "24", "31", "32", "33", "34", "41", "42", 
"43", "44", "51", "52", "53", "54"), class = "factor"), TIME = structure(as.integer(c(1, 
1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 
1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 
2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 
2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 
3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 
4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 
4, 4, 4, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 
1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 
2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 
2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 
3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 
4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 
4, 4, 4, 4, 4, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 
1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 
2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 
2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 
3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 
4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 
4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 
1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 
1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 
2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 
3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 
3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 
4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)), .Label = c("1", "2", 
"3", "4"), class = "factor"), HEIGHT = structure(as.integer(c(1, 
2, 1, 2, 1, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 
2, 1, 2, 1, 2, 1, 1, 1, 2, 1, 2, 2, 1, 2, 1, 1, 2, 1, 2, 1, 2, 
1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 1, 1, 2, 1, 
2, 1, 2, 1, 2, 1, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 
2, 1, 2, 1, 2, 1, 2, 1, 1, 1, 2, 1, 2, 1, 2, 1, 2, 1, 1, 2, 1, 
2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 1, 
1, 2, 1, 2, 1, 2, 1, 2, 1, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 
1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 1, 1, 2, 1, 2, 1, 1, 2, 1, 1, 
2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 
1, 1, 1, 2, 1, 2, 1, 1, 2, 1, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 
2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 1, 1, 2, 1, 2, 1, 2, 1, 2, 
1, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 
1, 1, 1, 2, 1, 2, 1, 2, 1, 2, 1, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 
1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 1, 1, 2, 1, 2, 1, 2, 1, 
2, 1, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 
2, 1, 2, 1, 1, 1, 2, 1, 2, 1, 2, 1, 2, 1, 1, 2, 1, 2, 1, 2, 1, 
2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 1, 1, 2, 1, 2, 
1, 2, 1, 2, 1, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 
1, 2, 1, 2, 1, 2, 1, 1, 1, 2, 1, 2, 1, 1, 2, 1, 1, 2, 1, 2, 1, 
2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 1, 1, 2, 
1, 2, 1, 1, 2, 1, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 
2, 1, 2, 1, 2, 1, 2, 1, 1, 1, 2, 1, 2, 1, 1, 2, 1, 1, 2, 1, 2, 
1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 1, 1, 
2, 1, 2, 1, 1, 2, 1, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 
1, 2, 1, 2, 1, 2, 1, 2, 1, 1, 1, 2, 1, 2)), .Label = c("1", "2", 
"3"), class = "factor"), insectdens = c(0, 0, 63.64, 11.99, 14.57, 
22.5, 15.53, 0, 20.49, 107.6, 0, 87.16, 19.82, 22.24, 18.28, 
51.92, 33.87, 42.1, 59.01, 0, 47.32, 15.78, 12.46, 43.02, 12.23, 
9.98, 27.75, 7.47, 38.92, 11.78, 11.18, 0, 0, 120.6, 44.61, 24.02, 
45.9, 26.78, 14.56, 80.2, 62.34, 37.4, 32.44, 17.58, 47.52, 8.94, 
26.01, 54.7, 9.19, 141.89, 29.36, 10.39, 48.88, 14.6, 20.46, 
158.34, 20.5, 9.52, 18.82, 14.36, 47.94, 12.26, 45.76, 31.44, 
53.82, 104.37, 112, 74.4, 59.88, 73.38, 94.36, 73.78, 120.26, 
305, 48.12, 129.45, 264.87, 53.88, 129.36, 87.9, 107.03, 57.33, 
145.53, 90.48, 95.2, 110, 116.55, 110.44, 492, 50.7, 140.4, 68.16, 
111.28, 104.8, 59.76, 75, 91.92, 68.4, 12.92, 19.94, 22.6, 17.38, 
53.6, 102.6, 10.45, 151.92, 30.3, 0, 0, 0, 39.18, 34.96, 16.38, 
21.38, 18.32, 60.4, 35.48, 16.9, 0, 24.96, 56.28, 263.76, 38.24, 
37.12, 9.26, 30.76, 26.24, 25.88, 46.48, 7.2, 21.09, 48.87, 0, 
28.1, 10.09, 44.28, 67.26, 0, 0, 29.72, 50.49, 63.92, 0, 0, 0, 
18.28, 10.82, 7.5, 27.06, 21.48, 9.09, 21.94, 13.56, 10.4, 13.25, 
46.6, 31.74, 8.57, 11.98, 12.08, 30.55, 12.46, 31.16, 27.27, 
16.35, 78.15, 100.8, 13.54, 80.44, 69.35, 104.55, 83.6, 37.32, 
0, 107.7, 91.55, 21.52, 50.76, 22.28, 17, 55.6, 52.85, 40.72, 
15.76, 15.12, 41.08, 25.44, 10.79, 87.36, 19.58, 19.94, 78.32, 
13.04, 39.54, 40.55, 74.08, 14.37, 34.68, 31.68, 69.4, 62.28, 
13.13, 117.96, 41.02, 18.27, 72.66, 34.74, 30.2, 69.86, 17.4, 
100.89, 16.72, 95.7, 43.92, 0, 27.6, 129.6, 73.64, 147.4, 107.82, 
92.16, 46.9, 76.1, 52.78, 52.32, 60.57, 46.7, 48.65, 49.41, 0, 
54.8, 30.18, 59.2, 0, 12.52, 0, 0, 15.89, 90.39, 35.42, 26.64, 
8.54, 17.46, 52.98, 7.88, 48.81, 12.68, 49.85, 32.67, 64.6, 41.2, 
20.2, 8.47, 80.29, 38.52, 17.28, 35.94, 41.55, 9.4, 237.25, 0, 
38.88, 24.56, 25.69, 0, 15.42, 0, 0, 0, 0, 467.64, 25.82, 36, 
11.64, 112.05, 31.54, 42.08, 0, 26.86, 79.74, 0, 27.18, 17.48, 
0, 34.95, 14.45, 43.88, 33.76, 23.24, 32.2, 16.29, 72.84, 189.99, 
436.05, 365.6, 259.98, 329.29, 228, 158.4, 140.91, 448.95, 433.84, 
47.11, 228.9, 193.13, 130.3, 335.73, 609.9, 202.54, 371.88, 332, 
360.36, 219.56, 338.91, 329.94, 139.15, 262.34, 285.9, 357.76, 
253.68, 353.35, 839.16, 368, 717.42, 840.18, 2081.2, 900.15, 
1052.03, 705.12, 1276.65, 512.25, 838.88, 614.46, 734.58, 479.52, 
286.38, 3020.4, 750.6, 885.96, 796.8, 932.49, 824.67, 1476.09, 
716.76, 576.46, 528.58, 568.8, 568.8, 712.53, 1168.86, 1864.56, 
997.26, 792.05, 1807.52, 899.25, 939.03, 1487.7, 1121.12, 166.5, 
84.96, 78.7, 31.98, 169.2, 99.35, 124.2, 176.85, 116.88, 104.6, 
45.43, 0, 82.44, 193.05, 53.5, 204.49, 135.72, 201.9, 129.76, 
49.71, 50.5, 93.06, 239.98, 75.72, 221.54, 207.79, 218.24, 73.26, 
96.4, 227.63, 155.4, 141.7, 280.63, 98.25, 58.4, 16.6, 30.84, 
141.72, 0, 277.16, 313.82, 534.19, 104.74, 508.04, 67.62, 68.44, 
119.7, 215.37, 26.92, 0, 63.24, 48.68, 11.62, 81.36, 142.5, 65.07, 
28.06, 133.5, 126.54, 70.28, 79.62, 107.73, 36.16, 30.14, 31.76, 
407.76, 422.24, 274.24, 317.7, 241.5, 190.3, 644.49, 162.17, 
1104.24, 324.78, 268.24, 214.2, 449.25, 363.22, 475.57, 197.12, 
311.63, 154.28, 461.3, 352.52, 247.69, 382.65, 395.25, 270.63, 
399.84, 338.4, 529.48, 440.82, 394.56, 270.48, 322, 441.22, 353.5, 
452.4, 414.96, 699.72, 89.04, 173.7, 347.6, 10150.24, 563.67, 
353.94, 456.88, 117.92, 513, 245.48, 440.37, 372.36, 398.86, 
334.35, 428, 410.13, 398.06, 674.87, 438.75, 226.16, 367.9, 416.8, 
501.48, 522.6, 616.11, 421.2, 309.96, 423.09, 232.08, 198.06, 
48.66, 109.59, 49.59, 58.05, 152.08, 0, 617.83, 64.66, 372.75, 
32.07, 66.81, 112.24, 68.28, 83.64, 157.48, 145.2, 46.24, 143, 
99.18, 117.5, 158.05, 61.1, 91.68, 67.5, 112.62, 98.21, 117.54, 
58.92, 77.3, 0), MONTHTIME = structure(as.integer(c(1, 1, 1, 
1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 
1, 1, 1, 1, 1, 1, 1, 1, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 
5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 9, 
9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 
9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 13, 13, 13, 13, 13, 13, 13, 
13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 
13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 2, 2, 2, 2, 2, 2, 2, 
2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 
2, 2, 2, 2, 2, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 
6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 10, 10, 10, 10, 
10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 
10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 14, 14, 14, 14, 
14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 
14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 3, 3, 3, 3, 3, 3, 
3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 
3, 3, 3, 3, 3, 3, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 
7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 11, 11, 
11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 
11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 15, 
15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 
15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 
4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 
4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 
8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 
8, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 
12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 
12, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 
16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 
16)), .Label = c("4.1", "5.1", "6.1", "7.1", "4.2", "5.2", "6.2", 
"7.2", "4.3", "5.3", "6.3", "7.3", "4.4", "5.4", "6.4", "7.4"
), class = "factor")), .Names = c("MONTH", "TRANSECT", "POLE", 
"TIME", "HEIGHT", "insectdens", "MONTHTIME"), row.names = c("1", 
"2", "4", "5", "7", "9", "10", "13", "14", "16", "17", "19", 
"20", "22", "23", "25", "26", "28", "29", "31", "32", "34", "35", 
"37", "38", "40", "41", "43", "44", "46", "47", "49", "50", "53", 
"55", "56", "58", "60", "61", "64", "65", "67", "68", "70", "71", 
"73", "74", "76", "77", "79", "80", "82", "83", "85", "86", "88", 
"89", "91", "92", "94", "95", "97", "98", "100", "101", "103", 
"104", "106", "107", "109", "111", "112", "115", "116", "118", 
"119", "121", "122", "124", "125", "127", "128", "130", "131", 
"133", "134", "136", "137", "139", "140", "142", "143", "145", 
"146", "148", "149", "151", "152", "154", "155", "157", "158", 
"160", "162", "163", "166", "167", "169", "170", "172", "173", 
"175", "176", "178", "179", "181", "182", "184", "185", "187", 
"188", "190", "191", "193", "194", "196", "197", "199", "200", 
"202", "203", "205", "206", "208", "209", "211", "213", "214", 
"217", "218", "220", "221", "223", "224", "226", "227", "229", 
"230", "232", "233", "235", "236", "238", "239", "241", "242", 
"244", "245", "247", "248", "250", "251", "253", "254", "256", 
"259", "260", "262", "264", "265", "268", "269", "271", "272", 
"274", "275", "277", "278", "280", "281", "283", "284", "286", 
"287", "289", "290", "292", "293", "295", "296", "298", "299", 
"301", "302", "304", "305", "307", "310", "311", "313", "315", 
"316", "319", "320", "322", "323", "325", "326", "328", "329", 
"331", "332", "334", "335", "337", "338", "340", "341", "343", 
"344", "346", "347", "349", "350", "352", "353", "355", "356", 
"358", "359", "361", "362", "364", "366", "367", "370", "371", 
"373", "374", "376", "377", "379", "380", "382", "383", "385", 
"386", "388", "389", "394", "395", "397", "398", "400", "401", 
"403", "404", "406", "407", "409", "410", "412", "413", "415", 
"417", "418", "421", "422", "424", "425", "427", "428", "430", 
"431", "433", "434", "436", "437", "439", "440", "442", "443", 
"445", "446", "448", "449", "451", "452", "454", "455", "457", 
"458", "460", "461", "463", "464", "466", "468", "469", "472", 
"473", "475", "476", "478", "479", "481", "482", "484", "485", 
"487", "488", "490", "491", "493", "494", "496", "497", "499", 
"500", "502", "503", "505", "506", "508", "509", "511", "512", 
"514", "515", "517", "519", "520", "523", "524", "526", "527", 
"529", "530", "532", "533", "535", "536", "538", "539", "541", 
"542", "544", "545", "547", "548", "550", "551", "553", "554", 
"556", "557", "559", "560", "562", "563", "565", "566", "568", 
"570", "571", "574", "575", "577", "578", "580", "581", "583", 
"584", "586", "587", "589", "590", "592", "593", "595", "596", 
"598", "599", "601", "602", "604", "605", "607", "608", "610", 
"611", "613", "616", "617", "619", "621", "622", "625", "626", 
"628", "629", "631", "632", "634", "635", "637", "638", "640", 
"641", "643", "644", "646", "647", "649", "650", "652", "653", 
"655", "656", "658", "659", "661", "662", "664", "667", "668", 
"670", "672", "673", "676", "677", "679", "680", "682", "683", 
"685", "686", "688", "689", "691", "692", "694", "695", "697", 
"698", "700", "701", "703", "704", "706", "707", "709", "710", 
"712", "713", "715", "718", "719", "721", "723", "724", "727", 
"728", "730", "731", "733", "734", "736", "737", "739", "740", 
"742", "743", "745", "746", "748", "749", "751", "752", "754", 
"755", "757", "758", "760", "761", "763", "764", "766", "769", 
"770", "772", "774", "775", "778", "779", "781", "782", "784", 
"785", "787", "788", "790", "791", "793", "794", "796", "797", 
"799", "800", "802", "803", "805", "806", "808", "809", "811", 
"812", "814", "815"), class = "data.frame")



-- 
This message (and any attachments) is for the recipient only...{{dropped}}



From gangchen at mail.nih.gov  Tue Sep 11 17:30:43 2007
From: gangchen at mail.nih.gov (Gang Chen)
Date: Tue, 11 Sep 2007 11:30:43 -0400
Subject: [R-sig-ME] Dealing with large datasets in lme/lmer
In-Reply-To: <40e66e0b0709101326i7c0984eaqaed39da1a95a091d@mail.gmail.com>
References: <3002B649-86D2-42DA-981E-9639CAAF8E37@mail.nih.gov>
	<40e66e0b0709051211y22c7e896g94ef1c38200a50cb@mail.gmail.com>
	<823D13BA-AED5-4FCD-BA2A-B3A090D02DCF@mail.nih.gov>
	<40e66e0b0709101326i7c0984eaqaed39da1a95a091d@mail.gmail.com>
Message-ID: <ABD5D493-AB4C-4DB1-8916-5463331B038E@mail.nih.gov>

Again thanks a lot for the help, Dr. Bates!

Now with the development version of lmer I got an error for the  
following model which works fine with the old lmer:

 >fit.lmer <- lmer(y ~ FA*FB*FC+weight+(1|Subj), Model);
Error in validObject(.Object) : invalid class "lmer" object: dims  
slot not named or incorrect length

What went wrong?

Regarding compiling, it works fine on a Mac OS X 10.4 with with duo  
2.7GHz processors, but failed on a Mac OS X 10.4.10 with a 2 GHz  
Intel Core Duo processor with the following error (does it have  
something to do with the Intel processor?):

 >  R CMD INSTALL ./lme4
* Installing to library '/Library/Frameworks/R.framework/Resources/ 
library'
* Installing *source* package 'lme4' ...
** libs
** arch - i386
gcc-4.0 -arch i386 -isysroot /Developer/SDKs/MacOSX10.4u.sdk -no-cpp- 
precomp -I/Library/Frameworks/R.framework/Resources/include -I/ 
Library/Frameworks/R.framework/Resources/include/i386  -msse3 -I"/ 
Library/Frameworks/R.framework/Resources/library/Matrix/include" - 
D__NO_MATH_INLINES  -fPIC  -g -O2 -std=gnu99 -march=nocona -c init.c - 
o init.o
gcc-4.0 -arch i386 -isysroot /Developer/SDKs/MacOSX10.4u.sdk -no-cpp- 
precomp -I/Library/Frameworks/R.framework/Resources/include -I/ 
Library/Frameworks/R.framework/Resources/include/i386  -msse3 -I"/ 
Library/Frameworks/R.framework/Resources/library/Matrix/include" - 
D__NO_MATH_INLINES  -fPIC  -g -O2 -std=gnu99 -march=nocona -c lmer.c - 
o lmer.o
lmer.c:356:48: error: macro "N_AS_CHM_DN" passed 3 arguments, but  
takes just 2
lmer.c: In function 'Mer_eta':
lmer.c:356: error: 'N_AS_CHM_DN' undeclared (first use in this function)
lmer.c:356: error: (Each undeclared identifier is reported only once
lmer.c:356: error: for each function it appears in.)
lmer.c:1448:40: error: macro "N_AS_CHM_DN" passed 3 arguments, but  
takes just 2
lmer.c: In function 'nglmer_condMode':
lmer.c:1448: error: 'N_AS_CHM_DN' undeclared (first use in this  
function)
lmer.c:1449:30: error: macro "N_AS_CHM_DN" passed 3 arguments, but  
takes just 2
lmer.c:1718:45: error: macro "N_AS_CHM_DN" passed 3 arguments, but  
takes just 2
lmer.c: In function 'lmer_MCMC_betab':
lmer.c:1718: error: 'N_AS_CHM_DN' undeclared (first use in this  
function)
make: *** [lmer.o] Error 1
chmod: /Library/Frameworks/R.framework/Versions/2.5/Resources/library/ 
lme4/libs/i386/*: No such file or directory
** arch - ppc
gcc-4.0 -arch ppc -isysroot /Developer/SDKs/MacOSX10.4u.sdk - 
std=gnu99 -no-cpp-precomp -I/Library/Frameworks/R.framework/Resources/ 
include -I/Library/Frameworks/R.framework/Resources/include/ppc  -I/ 
usr/local/include -I"/Library/Frameworks/R.framework/Resources/ 
library/Matrix/include"   -fPIC  -g -O2 -c init.c -o init.o
gcc-4.0 -arch ppc -isysroot /Developer/SDKs/MacOSX10.4u.sdk - 
std=gnu99 -no-cpp-precomp -I/Library/Frameworks/R.framework/Resources/ 
include -I/Library/Frameworks/R.framework/Resources/include/ppc  -I/ 
usr/local/include -I"/Library/Frameworks/R.framework/Resources/ 
library/Matrix/include"   -fPIC  -g -O2 -c lmer.c -o lmer.o
lmer.c:356:48: error: macro "N_AS_CHM_DN" passed 3 arguments, but  
takes just 2
lmer.c: In function 'Mer_eta':
lmer.c:356: error: 'N_AS_CHM_DN' undeclared (first use in this function)
lmer.c:356: error: (Each undeclared identifier is reported only once
lmer.c:356: error: for each function it appears in.)
lmer.c:1448:40: error: macro "N_AS_CHM_DN" passed 3 arguments, but  
takes just 2
lmer.c: In function 'nglmer_condMode':
lmer.c:1448: error: 'N_AS_CHM_DN' undeclared (first use in this  
function)
lmer.c:1449:30: error: macro "N_AS_CHM_DN" passed 3 arguments, but  
takes just 2
lmer.c:1718:45: error: macro "N_AS_CHM_DN" passed 3 arguments, but  
takes just 2
lmer.c: In function 'lmer_MCMC_betab':
lmer.c:1718: error: 'N_AS_CHM_DN' undeclared (first use in this  
function)
make: *** [lmer.o] Error 1
chmod: /Library/Frameworks/R.framework/Versions/2.5/Resources/library/ 
lme4/libs/ppc/*: No such file or directory
ERROR: compilation failed for package 'lme4'
** Removing '/Library/Frameworks/R.framework/Versions/2.5/Resources/ 
library/lme4'
** Restoring previous '/Library/Frameworks/R.framework/Versions/2.5/ 
Resources/library/lme4'


Thanks,
Gang

=========
Gang Chen, Ph. D.
National Institutes of Health, DHHS

On Sep 10, 2007, at 4:26 PM, Douglas Bates wrote:

> The best way to obtain the package sources is with a subversion
> client.  On Linux it is called svn.  The call to check out a copy of
> the package sources is
>
> svn co https://svn.r-project.org/R-packages/branches/gappy-lmer ./lme4
>
> You need the whole directory to build the package.  Under Linux or Mac
> OS X I use
>
> R CMD INSTALL ./lme4
>
> For Windows I use Uwe's win-builder at win-builder.R-project.org
>
> On 9/10/07, Gang Chen <gangchen at mail.nih.gov> wrote:
>> Dr. Bates,
>>
>> Thank you very much for the quick response and suggestions.
>>
>> I really want to try out the lmer development package, but could not
>> figure out how to download it. I tried to run
>>
>> wget https://svn.r-project.org/R-packages/branches/gappy-lmer/
>> (Or wget --no-check-certificate -r -nv -m -np -nH https://svn.r-
>> project.org/R-packages/branches/gappy-lmer/ )
>>
>> but it didn't work. So how can I obtain the package? Do I only need
>> the files under
>>
>> https://svn.r-project.org/R-packages/branches/gappy-lmer/R/
>>
>> or do I need to compile/build the package with the source code  
>> somehow?
>>
>> Thanks,
>> Gang
>>
>> =========
>> Gang Chen, Ph. D.
>> National Institutes of Health, HHS
>>
>>
>> On Sep 5, 2007, at 3:11 PM, Douglas Bates wrote:
>>
>>> On 9/4/07, Gang Chen <gangchen at mail.nih.gov> wrote:
>>>> Dear all,
>>>
>>>> I'm running mixed-effects analysis with large datasets in a loop  
>>>> like
>>>> this:
>>>
>>>> for (i in 1:60) {
>>>> for (j in 1:60) {
>>>> for (k in 1:60) {
>>>>     [...update y here in Model here...]
>>>>     fit.lme <- lme(y ~ FA*FB*FC+weight, random = pdBlocked(list
>>>> (pdCompSymm(~FB-1), pdCompSymm(~FC-1), pdIdent(~1))),
>>>> weights=varIdent
>>>> (form=~1|FA), Model);
>>>>     Stat[i, j, k,] <- anova(fit.lme)$F[-1];
>>>> }
>>>> }
>>>> }
>>>
>>> Did you create the array Stat outside the loop?  If not you will be
>>> doing a lot of copying of elements of that array.
>>>
>>>> This takes a little over 100 hours to finish on a Mac G5 with duo
>>>> 2.7GHz processors and 4GB memory.
>>>
>>>> In the mixed-effects model
>>>
>>>> y = X*beta + Z*b + e
>>>
>>>> the fixed-effects nxp matrix X and random-effects matrix nxq Z are
>>>> always the same for all the iterations in my case, and the only  
>>>> thing
>>>> that differs is y (and the estimates of beta, b and e also  
>>>> differ of
>>>> course). In my case n = 504 (large), p and q are moderate.  I just
>>>> read Dr. Douglas Bates's presentation during uerR! 2007 (very
>>>> informative by the way):
>>>
>>> Thank you.
>>>
>>>> http://user2007.org/program/presentations/bates.pdf
>>>
>>>> It seems many components in the extended system matrix (equation  
>>>> (2)
>>>> on page 22) for the Cholesky decomposition remain the same  
>>>> during the
>>>> iterations. So there are a lot of repetitive computations on those
>>>> same matrix operations in the above loop. How can I achieve a  
>>>> better
>>>> efficiency? Someone suggested to me running lme/lmer with a two-
>>>> dimensional response Y instead of one-dimensional y. My questions
>>>> are:
>>>
>>>> (1) So far I have only seen people running lme/lmer with y in a
>>>> format of one-dimensional array from a table. If I combine all  
>>>> those
>>>> y's (indices i, j, k) into an two-dimensional array Y, is there  
>>>> a way
>>>> I can run lme/lmer on Y instead of y? In other words, does lme/lmer
>>>> take a two-dimensional array Y?
>>>
>>> Not at present.
>>>
>>>> If so, do I have to save the huge
>>>> array in a table in text file and then read in R before I run lme/
>>>> lmer?
>>>
>>> No.  There are many ways of getting data into R other than  
>>> creating a
>>> text file and reading it.  See the manual "R Data Import/Export" and
>>> also Martin Maechler's presentation at useR!2007.
>>> http://user2007.org/program/presentations/maechler.pdf
>>>
>>>> Also if that is the case, how can I label those many columns
>>>> somehow associated with Y?
>>>
>>>> (2) A more serious concern is about memory. With the current  
>>>> looping
>>>> approach it uses about 1GB. If I could possibly go with the matrix
>>>> method described in (1), I'm worried that it might not be  
>>>> practically
>>>> feasible with the current computers. Any thoughts?
>>>
>>> Well first you are discussing the computational methods used in lmer
>>> but you want to fit a model with different residual variances for
>>> different groups.  At present you can't do that in lmer.
>>>
>>> If you look at the lmer function in the development version of the
>>> lme4 package (currently at
>>> https://svn.r-project.org/R-packages/branches/gappy-lmer, soon to be
>>> at http://r-forge.r-project.org/projects/lme4 for some value of
>>> "soon") you will see that it follows the equations in my useR
>>> presentation fairly closely.  The Xy array is n by (p + 1) with X in
>>> the first p columns and y in the p + 1st column.  The object of  
>>> class
>>> "lmer" has slots named y, Zt (Z-transpose), ZtXy (Zt %*% Xy), and
>>> XytXy (crossprod(Xy)). After fitting the model to the first  
>>> simulated
>>> response, producing the object 'fm',  the only operations needed to
>>> update the model are
>>>
>>>  fm at y <- newy
>>>  Xy <- cbind(fm at X, fm at y)
>>>  fm at ZtXy <- fm at Zt %*% Xy
>>>  fm at XytXy <- crossprod(Xy)
>>>  lme4:::mer_finalize(fm, verbose)
>>>
>>> where 'verbose' is a logical scalar indicating if you want verbose
>>> output during the optimization phase.  Once you get things  
>>> working on
>>> a small example you would probably want to turn that off.
>>>
>>> Please note that this code applies to the development version of the
>>> lme4 package.
>>



From bates at stat.wisc.edu  Tue Sep 11 18:08:24 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 11 Sep 2007 11:08:24 -0500
Subject: [R-sig-ME] Dealing with large datasets in lme/lmer
In-Reply-To: <ABD5D493-AB4C-4DB1-8916-5463331B038E@mail.nih.gov>
References: <3002B649-86D2-42DA-981E-9639CAAF8E37@mail.nih.gov>
	<40e66e0b0709051211y22c7e896g94ef1c38200a50cb@mail.gmail.com>
	<823D13BA-AED5-4FCD-BA2A-B3A090D02DCF@mail.nih.gov>
	<40e66e0b0709101326i7c0984eaqaed39da1a95a091d@mail.gmail.com>
	<ABD5D493-AB4C-4DB1-8916-5463331B038E@mail.nih.gov>
Message-ID: <40e66e0b0709110908q6346a7f7oe5c8fb93afc3e62a@mail.gmail.com>

On 9/11/07, Gang Chen <gangchen at mail.nih.gov> wrote:
> Again thanks a lot for the help, Dr. Bates!

> Now with the development version of lmer I got an error for the
> following model which works fine with the old lmer:

>  >fit.lmer <- lmer(y ~ FA*FB*FC+weight+(1|Subj), Model);
> Error in validObject(.Object) : invalid class "lmer" object: dims
> slot not named or incorrect length

> What went wrong?

I don't know.  I'd need the output from

sessionInfo()

to be able to even start to guess.

> Regarding compiling, it works fine on a Mac OS X 10.4 with with duo
> 2.7GHz processors, but failed on a Mac OS X 10.4.10 with a 2 GHz
> Intel Core Duo processor with the following error (does it have
> something to do with the Intel processor?):

You need the most recent version of the Matrix package installed
before you can compile the development lme4

>  >  R CMD INSTALL ./lme4
> * Installing to library '/Library/Frameworks/R.framework/Resources/
> library'
> * Installing *source* package 'lme4' ...
> ** libs
> ** arch - i386
> gcc-4.0 -arch i386 -isysroot /Developer/SDKs/MacOSX10.4u.sdk -no-cpp-
> precomp -I/Library/Frameworks/R.framework/Resources/include -I/
> Library/Frameworks/R.framework/Resources/include/i386  -msse3 -I"/
> Library/Frameworks/R.framework/Resources/library/Matrix/include" -
> D__NO_MATH_INLINES  -fPIC  -g -O2 -std=gnu99 -march=nocona -c init.c -
> o init.o
> gcc-4.0 -arch i386 -isysroot /Developer/SDKs/MacOSX10.4u.sdk -no-cpp-
> precomp -I/Library/Frameworks/R.framework/Resources/include -I/
> Library/Frameworks/R.framework/Resources/include/i386  -msse3 -I"/
> Library/Frameworks/R.framework/Resources/library/Matrix/include" -
> D__NO_MATH_INLINES  -fPIC  -g -O2 -std=gnu99 -march=nocona -c lmer.c -
> o lmer.o
> lmer.c:356:48: error: macro "N_AS_CHM_DN" passed 3 arguments, but
> takes just 2
> lmer.c: In function 'Mer_eta':
> lmer.c:356: error: 'N_AS_CHM_DN' undeclared (first use in this function)
> lmer.c:356: error: (Each undeclared identifier is reported only once
> lmer.c:356: error: for each function it appears in.)
> lmer.c:1448:40: error: macro "N_AS_CHM_DN" passed 3 arguments, but
> takes just 2
> lmer.c: In function 'nglmer_condMode':
> lmer.c:1448: error: 'N_AS_CHM_DN' undeclared (first use in this
> function)
> lmer.c:1449:30: error: macro "N_AS_CHM_DN" passed 3 arguments, but
> takes just 2
> lmer.c:1718:45: error: macro "N_AS_CHM_DN" passed 3 arguments, but
> takes just 2
> lmer.c: In function 'lmer_MCMC_betab':
> lmer.c:1718: error: 'N_AS_CHM_DN' undeclared (first use in this
> function)
> make: *** [lmer.o] Error 1
> chmod: /Library/Frameworks/R.framework/Versions/2.5/Resources/library/
> lme4/libs/i386/*: No such file or directory
> ** arch - ppc
> gcc-4.0 -arch ppc -isysroot /Developer/SDKs/MacOSX10.4u.sdk -
> std=gnu99 -no-cpp-precomp -I/Library/Frameworks/R.framework/Resources/
> include -I/Library/Frameworks/R.framework/Resources/include/ppc  -I/
> usr/local/include -I"/Library/Frameworks/R.framework/Resources/
> library/Matrix/include"   -fPIC  -g -O2 -c init.c -o init.o
> gcc-4.0 -arch ppc -isysroot /Developer/SDKs/MacOSX10.4u.sdk -
> std=gnu99 -no-cpp-precomp -I/Library/Frameworks/R.framework/Resources/
> include -I/Library/Frameworks/R.framework/Resources/include/ppc  -I/
> usr/local/include -I"/Library/Frameworks/R.framework/Resources/
> library/Matrix/include"   -fPIC  -g -O2 -c lmer.c -o lmer.o
> lmer.c:356:48: error: macro "N_AS_CHM_DN" passed 3 arguments, but
> takes just 2
> lmer.c: In function 'Mer_eta':
> lmer.c:356: error: 'N_AS_CHM_DN' undeclared (first use in this function)
> lmer.c:356: error: (Each undeclared identifier is reported only once
> lmer.c:356: error: for each function it appears in.)
> lmer.c:1448:40: error: macro "N_AS_CHM_DN" passed 3 arguments, but
> takes just 2
> lmer.c: In function 'nglmer_condMode':
> lmer.c:1448: error: 'N_AS_CHM_DN' undeclared (first use in this
> function)
> lmer.c:1449:30: error: macro "N_AS_CHM_DN" passed 3 arguments, but
> takes just 2
> lmer.c:1718:45: error: macro "N_AS_CHM_DN" passed 3 arguments, but
> takes just 2
> lmer.c: In function 'lmer_MCMC_betab':
> lmer.c:1718: error: 'N_AS_CHM_DN' undeclared (first use in this
> function)
> make: *** [lmer.o] Error 1
> chmod: /Library/Frameworks/R.framework/Versions/2.5/Resources/library/
> lme4/libs/ppc/*: No such file or directory
> ERROR: compilation failed for package 'lme4'
> ** Removing '/Library/Frameworks/R.framework/Versions/2.5/Resources/
> library/lme4'
> ** Restoring previous '/Library/Frameworks/R.framework/Versions/2.5/
> Resources/library/lme4'
>
>
> Thanks,
> Gang
>
> =========
> Gang Chen, Ph. D.
> National Institutes of Health, DHHS
>
> On Sep 10, 2007, at 4:26 PM, Douglas Bates wrote:
>
> > The best way to obtain the package sources is with a subversion
> > client.  On Linux it is called svn.  The call to check out a copy of
> > the package sources is
> >
> > svn co https://svn.r-project.org/R-packages/branches/gappy-lmer ./lme4
> >
> > You need the whole directory to build the package.  Under Linux or Mac
> > OS X I use
> >
> > R CMD INSTALL ./lme4
> >
> > For Windows I use Uwe's win-builder at win-builder.R-project.org
> >
> > On 9/10/07, Gang Chen <gangchen at mail.nih.gov> wrote:
> >> Dr. Bates,
> >>
> >> Thank you very much for the quick response and suggestions.
> >>
> >> I really want to try out the lmer development package, but could not
> >> figure out how to download it. I tried to run
> >>
> >> wget https://svn.r-project.org/R-packages/branches/gappy-lmer/
> >> (Or wget --no-check-certificate -r -nv -m -np -nH https://svn.r-
> >> project.org/R-packages/branches/gappy-lmer/ )
> >>
> >> but it didn't work. So how can I obtain the package? Do I only need
> >> the files under
> >>
> >> https://svn.r-project.org/R-packages/branches/gappy-lmer/R/
> >>
> >> or do I need to compile/build the package with the source code
> >> somehow?
> >>
> >> Thanks,
> >> Gang
> >>
> >> =========
> >> Gang Chen, Ph. D.
> >> National Institutes of Health, HHS
> >>
> >>
> >> On Sep 5, 2007, at 3:11 PM, Douglas Bates wrote:
> >>
> >>> On 9/4/07, Gang Chen <gangchen at mail.nih.gov> wrote:
> >>>> Dear all,
> >>>
> >>>> I'm running mixed-effects analysis with large datasets in a loop
> >>>> like
> >>>> this:
> >>>
> >>>> for (i in 1:60) {
> >>>> for (j in 1:60) {
> >>>> for (k in 1:60) {
> >>>>     [...update y here in Model here...]
> >>>>     fit.lme <- lme(y ~ FA*FB*FC+weight, random = pdBlocked(list
> >>>> (pdCompSymm(~FB-1), pdCompSymm(~FC-1), pdIdent(~1))),
> >>>> weights=varIdent
> >>>> (form=~1|FA), Model);
> >>>>     Stat[i, j, k,] <- anova(fit.lme)$F[-1];
> >>>> }
> >>>> }
> >>>> }
> >>>
> >>> Did you create the array Stat outside the loop?  If not you will be
> >>> doing a lot of copying of elements of that array.
> >>>
> >>>> This takes a little over 100 hours to finish on a Mac G5 with duo
> >>>> 2.7GHz processors and 4GB memory.
> >>>
> >>>> In the mixed-effects model
> >>>
> >>>> y = X*beta + Z*b + e
> >>>
> >>>> the fixed-effects nxp matrix X and random-effects matrix nxq Z are
> >>>> always the same for all the iterations in my case, and the only
> >>>> thing
> >>>> that differs is y (and the estimates of beta, b and e also
> >>>> differ of
> >>>> course). In my case n = 504 (large), p and q are moderate.  I just
> >>>> read Dr. Douglas Bates's presentation during uerR! 2007 (very
> >>>> informative by the way):
> >>>
> >>> Thank you.
> >>>
> >>>> http://user2007.org/program/presentations/bates.pdf
> >>>
> >>>> It seems many components in the extended system matrix (equation
> >>>> (2)
> >>>> on page 22) for the Cholesky decomposition remain the same
> >>>> during the
> >>>> iterations. So there are a lot of repetitive computations on those
> >>>> same matrix operations in the above loop. How can I achieve a
> >>>> better
> >>>> efficiency? Someone suggested to me running lme/lmer with a two-
> >>>> dimensional response Y instead of one-dimensional y. My questions
> >>>> are:
> >>>
> >>>> (1) So far I have only seen people running lme/lmer with y in a
> >>>> format of one-dimensional array from a table. If I combine all
> >>>> those
> >>>> y's (indices i, j, k) into an two-dimensional array Y, is there
> >>>> a way
> >>>> I can run lme/lmer on Y instead of y? In other words, does lme/lmer
> >>>> take a two-dimensional array Y?
> >>>
> >>> Not at present.
> >>>
> >>>> If so, do I have to save the huge
> >>>> array in a table in text file and then read in R before I run lme/
> >>>> lmer?
> >>>
> >>> No.  There are many ways of getting data into R other than
> >>> creating a
> >>> text file and reading it.  See the manual "R Data Import/Export" and
> >>> also Martin Maechler's presentation at useR!2007.
> >>> http://user2007.org/program/presentations/maechler.pdf
> >>>
> >>>> Also if that is the case, how can I label those many columns
> >>>> somehow associated with Y?
> >>>
> >>>> (2) A more serious concern is about memory. With the current
> >>>> looping
> >>>> approach it uses about 1GB. If I could possibly go with the matrix
> >>>> method described in (1), I'm worried that it might not be
> >>>> practically
> >>>> feasible with the current computers. Any thoughts?
> >>>
> >>> Well first you are discussing the computational methods used in lmer
> >>> but you want to fit a model with different residual variances for
> >>> different groups.  At present you can't do that in lmer.
> >>>
> >>> If you look at the lmer function in the development version of the
> >>> lme4 package (currently at
> >>> https://svn.r-project.org/R-packages/branches/gappy-lmer, soon to be
> >>> at http://r-forge.r-project.org/projects/lme4 for some value of
> >>> "soon") you will see that it follows the equations in my useR
> >>> presentation fairly closely.  The Xy array is n by (p + 1) with X in
> >>> the first p columns and y in the p + 1st column.  The object of
> >>> class
> >>> "lmer" has slots named y, Zt (Z-transpose), ZtXy (Zt %*% Xy), and
> >>> XytXy (crossprod(Xy)). After fitting the model to the first
> >>> simulated
> >>> response, producing the object 'fm',  the only operations needed to
> >>> update the model are
> >>>
> >>>  fm at y <- newy
> >>>  Xy <- cbind(fm at X, fm at y)
> >>>  fm at ZtXy <- fm at Zt %*% Xy
> >>>  fm at XytXy <- crossprod(Xy)
> >>>  lme4:::mer_finalize(fm, verbose)
> >>>
> >>> where 'verbose' is a logical scalar indicating if you want verbose
> >>> output during the optimization phase.  Once you get things
> >>> working on
> >>> a small example you would probably want to turn that off.
> >>>
> >>> Please note that this code applies to the development version of the
> >>> lme4 package.
> >>
>



From gangchen at mail.nih.gov  Tue Sep 11 18:12:09 2007
From: gangchen at mail.nih.gov (Gang Chen)
Date: Tue, 11 Sep 2007 12:12:09 -0400
Subject: [R-sig-ME] Dealing with large datasets in lme/lmer
In-Reply-To: <40e66e0b0709110908q6346a7f7oe5c8fb93afc3e62a@mail.gmail.com>
References: <3002B649-86D2-42DA-981E-9639CAAF8E37@mail.nih.gov>
	<40e66e0b0709051211y22c7e896g94ef1c38200a50cb@mail.gmail.com>
	<823D13BA-AED5-4FCD-BA2A-B3A090D02DCF@mail.nih.gov>
	<40e66e0b0709101326i7c0984eaqaed39da1a95a091d@mail.gmail.com>
	<ABD5D493-AB4C-4DB1-8916-5463331B038E@mail.nih.gov>
	<40e66e0b0709110908q6346a7f7oe5c8fb93afc3e62a@mail.gmail.com>
Message-ID: <13BFC64F-0464-4539-820E-1AB2E9F54FB7@mail.nih.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20070911/81f5b06b/attachment.pl>

From john.maindonald at anu.edu.au  Wed Sep 12 01:08:51 2007
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Wed, 12 Sep 2007 09:08:51 +1000
Subject: [R-sig-ME] magnitude of random effect vs significance: try 2
In-Reply-To: <s6e68eda.056@wpo.nerc.ac.uk>
References: <s6e68eda.056@wpo.nerc.ac.uk>
Message-ID: <C4B06E79-16B7-473E-B56D-379F96A37BF4@anu.edu.au>

I'll take your points in reverse order

1. You might like to compare the following, using the kiwishade data  
frame from the DAAG package

VarCorr(lme(yield ~ shade, random=~1|block/shade/plot,  
data=kiwishade))  ## The units are plots

VarCorr(lme(yield ~ shade, random=~1|block/shade, data=kiwishade))

The first one splits the block:shade component of variance between  
block:shade and block:shade:plot  This is just wrong. The alleged  
block:shade:plot component has nothing to do with plots.  It is some  
deep mystery in the internal workings of lme() that it splits the  
block:shade component of variance in this strange way rather than  
throwing an error or recognizing that block:shade:plot is just  
another name for the residual, and that it should act accordingly.   
Doug may be able to throw light on this.

2.  "Variances are not a good basis for inference".  Variances are  
readily interpretable when the distributions are normal. In other  
circumstances, they are more problematic, and care is necessary.   
That is all I was saying.

John.

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.


On 11 Sep 2007, at 9:48 PM, Mike Dunbar wrote:

>
> I'm hoping I am getting close to the end of posting on this topic  
> and associated topic "explaining lme variance component results".
>
> Firstly many thanks again to John, Peter and Kevin for comments so  
> far. I have discovered an error in the coding in one row, now  
> corrected (thanks John) and am also much more informed as to how to  
> ensure correct coding for nested model comparison (thanks Peter).
>
> I'm also better informed as to the links between anova-based  
> analyses and REML-based (thanks John), but still struggle with  
> these anovas.
>
> Two points I'd like to follow up on.
>
> 1.
> Firstly Kevin's point that
> "In my experience with biological data, factors that have levels  
> that are widely (temporal/spatial) separated are often more  
> variable than factors with levels that are closer together"
> and linked to John's points
> "Variances are not, for quantities that are differences multiples  
> of chi-squared statistics, a good basis for inference."
> and
> "The estimate for s1^2 (MONTH} has a statistical error that is a  
> compound of the errors in the ANOVA mean squares for both TIME and  
> MONTH."
>
> Generalising from anova mean squares principles, it makes sense  
> that the variation for coarser-grain factors (i.e. less well  
> replicated, more widely varying in time and or space) is likely to  
> be higher by chance because confounded within it is some of the  
> variation that ought to be in the finer level factors (whether the  
> factors are specifed or unknown). In addition, the inevitable  
> poorer replication at the coarse level reduces power. Now I can see  
> how this follows analytically in the case of anova mean squares  
> derived analysis, however I'd just like some advice that the same  
> principles apply in REML-derived analyses.
>
> If this reasoning is correct, then I have no trouble explaining the  
> results from the attached analysis. In this case, to abbreviate the  
> full table, we have.
> 	Variance	p-value (from LR test, removing single factor)
> MONTH	0.639	0.1889
> ..
> POLE	0.160	0.0496
> ...
> Note that month is the coarser grain factor, and pole the finer. If  
> there are any references as to why its the p-values from LR tests  
> that matter and not the magnitude of the components (other than  
> John Maindonald, pers. comm. which is OK of course) that would do  
> me a massive favour. In my manuscript, I could of course illustrate  
> with anova-derived workings now John has explained this, but I  
> would prefer to just present the REML-based analyses.
>
> 2.
> I'm still slightly muddled about the implications of including a  
> random effect at the finest unreplicated level. Again I can  
> understand that since there is no replication, the random effect at  
> that level should be confounded with the residual. However, in  
> practice, lme(r) still gives separate variances for the two  
> components. How can this be? Is REML extracting some information  
> that is not available in an anova-based analysis. In the analysis  
> below, replication is obtained at the finest level by there being 2  
> levels of the height factor in many cases (but not all, its  
> unbalanced), but since I know there is a consistent height effect,  
> I add a fixed effect for this, are we back to square one and no  
> fine-level replication. Again I would appreciate any advice and  
> will try to bring this to a close now (honest!)
>
> regards
>
> Mike
>
>
>
> # analysis: data are below
> varcor.2h.insects.hf <- lme(log(insectdens+1) ~ HEIGHT, random=~1| 
> MONTH/TIME/TRANSECT/POLE, data=temp4)
> VarCorr(varcor.2h.insects.hf)
> # variance for month: 0.639, time: 1.24, transect: 0.013, pole:  
> 0.160, resid: 1.02
>
> varcor.2h.insects.nomonth.hf <- lme(log(insectdens+1) ~ HEIGHT,  
> random=~1|MONTHTIME/TRANSECT/POLE, data=invdens.bottommiddle) # P  
> Dalgaard email
> varcor.2h.insects.nopole.hf <- lme(log(insectdens+1) ~ HEIGHT,  
> random=~1|MONTH/TIME/TRANSECT, data=invdens.bottommiddle)
>
> anova(varcor.2h.insects.hf,varcor.2h.insects.nomonth.hf) # p=0.1889
> anova(varcor.2h.insects.hf,varcor.2h.insects.nopole.hf) # p= 0.0496  
> (p is lower if ns month and transect terms removed)
>
>
>
> # read in data first
> temp4 <-
> structure(list(MONTH = structure(as.integer(c(1, 1, 1, 1, 1,
> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
> 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,
> 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,
> 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,
> 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,
> 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,
> 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,
> 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,
> 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,
> 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,
> 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,
> 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,
> 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,
> 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)), .Label = c("4", "5", "6", "7"
> ), class = "factor"), TRANSECT = structure(as.integer(c(1, 1,
> 1, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4,
> 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 3,
> 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5,
> 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4,
> 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 1, 1, 1, 1, 1, 1, 1, 2, 2,
> 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5,
> 5, 5, 5, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3,
> 3, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 1, 1, 1, 1, 1, 1,
> 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 5,
> 5, 5, 5, 5, 5, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3,
> 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 1, 1, 1, 1, 1,
> 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 5,
> 5, 5, 5, 5, 5, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 3,
> 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 1, 1, 1, 1,
> 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4,
> 4, 4, 5, 5, 5, 5, 5, 5, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3,
> 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 1,
> 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4,
> 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2,
> 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5,
> 5, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4,
> 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 1, 1, 1, 1, 1, 1, 2, 2, 2,
> 2, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5,
> 5, 5, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 4,
> 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5)), .Label = c("1", "2",
> "3", "4", "5"), class = "factor"), POLE = structure(as.integer(c(1,
> 1, 2, 2, 3, 4, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9, 10, 10, 11, 11,
> 12, 12, 13, 13, 14, 14, 15, 16, 17, 17, 18, 18, 1, 2, 2, 3, 4,
> 4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9, 10, 10, 11, 11, 12, 12, 13,
> 13, 14, 14, 15, 16, 17, 17, 18, 18, 1, 1, 2, 2, 3, 4, 4, 5, 5,
> 6, 6, 7, 7, 8, 8, 9, 9, 10, 10, 11, 11, 12, 12, 13, 13, 14, 14,
> 15, 16, 17, 17, 18, 18, 1, 1, 2, 2, 3, 4, 4, 5, 5, 6, 6, 7, 7,
> 8, 8, 9, 9, 10, 10, 11, 11, 12, 12, 13, 13, 14, 14, 15, 16, 17,
> 17, 18, 18, 1, 1, 2, 2, 3, 4, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9,
> 10, 10, 11, 11, 12, 12, 13, 13, 14, 14, 15, 16, 17, 17, 18, 18,
> 1, 2, 2, 3, 4, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9, 10, 10, 11, 11,
> 12, 12, 13, 13, 14, 14, 15, 16, 17, 17, 18, 18, 1, 2, 2, 3, 4,
> 4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9, 10, 10, 11, 11, 12, 12, 13,
> 13, 14, 14, 15, 16, 17, 17, 18, 18, 1, 1, 2, 2, 3, 4, 4, 5, 5,
> 6, 6, 7, 7, 8, 8, 9, 9, 10, 10, 11, 11, 13, 13, 14, 14, 15, 16,
> 17, 17, 18, 18, 1, 1, 2, 2, 3, 4, 4, 5, 5, 6, 6, 7, 7, 8, 8,
> 9, 9, 10, 10, 11, 11, 12, 12, 13, 13, 14, 14, 15, 16, 17, 17,
> 18, 18, 1, 1, 2, 2, 3, 4, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9, 10,
> 10, 11, 11, 12, 12, 13, 13, 14, 14, 15, 16, 17, 17, 18, 18, 1,
> 1, 2, 2, 3, 4, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9, 10, 10, 11, 11,
> 12, 12, 13, 13, 14, 14, 15, 16, 17, 17, 18, 18, 1, 1, 2, 2, 3,
> 4, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9, 10, 10, 11, 11, 12, 12, 13,
> 13, 14, 14, 15, 16, 17, 17, 18, 18, 1, 2, 2, 3, 4, 4, 5, 5, 6,
> 6, 7, 7, 8, 8, 9, 9, 10, 10, 11, 11, 12, 12, 13, 13, 14, 14,
> 15, 16, 17, 17, 18, 18, 1, 2, 2, 3, 4, 4, 5, 5, 6, 6, 7, 7, 8,
> 8, 9, 9, 10, 10, 11, 11, 12, 12, 13, 13, 14, 14, 15, 16, 17,
> 17, 18, 18, 1, 2, 2, 3, 4, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9, 10,
> 10, 11, 11, 12, 12, 13, 13, 14, 14, 15, 16, 17, 17, 18, 18, 1,
> 2, 2, 3, 4, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9, 10, 10, 11, 11,
> 12, 12, 13, 13, 14, 14, 15, 16, 17, 17, 18, 18)), .Label = c("11",
> "12", "13", "14", "23", "24", "31", "32", "33", "34", "41", "42",
> "43", "44", "51", "52", "53", "54"), class = "factor"), TIME =  
> structure(as.integer(c(1,
> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
> 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,
> 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,
> 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,
> 4, 4, 4, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2,
> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
> 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,
> 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4,
> 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,
> 4, 4, 4, 4, 4, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2,
> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
> 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,
> 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,
> 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,
> 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3,
> 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,
> 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,
> 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)), .Label = c("1", "2",
> "3", "4"), class = "factor"), HEIGHT = structure(as.integer(c(1,
> 2, 1, 2, 1, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1,
> 2, 1, 2, 1, 2, 1, 1, 1, 2, 1, 2, 2, 1, 2, 1, 1, 2, 1, 2, 1, 2,
> 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 1, 1, 2, 1,
> 2, 1, 2, 1, 2, 1, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1,
> 2, 1, 2, 1, 2, 1, 2, 1, 1, 1, 2, 1, 2, 1, 2, 1, 2, 1, 1, 2, 1,
> 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 1,
> 1, 2, 1, 2, 1, 2, 1, 2, 1, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2,
> 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 1, 1, 2, 1, 2, 1, 1, 2, 1, 1,
> 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2,
> 1, 1, 1, 2, 1, 2, 1, 1, 2, 1, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1,
> 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 1, 1, 2, 1, 2, 1, 2, 1, 2,
> 1, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2,
> 1, 1, 1, 2, 1, 2, 1, 2, 1, 2, 1, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2,
> 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 1, 1, 2, 1, 2, 1, 2, 1,
> 2, 1, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1,
> 2, 1, 2, 1, 1, 1, 2, 1, 2, 1, 2, 1, 2, 1, 1, 2, 1, 2, 1, 2, 1,
> 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 1, 1, 2, 1, 2,
> 1, 2, 1, 2, 1, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2,
> 1, 2, 1, 2, 1, 2, 1, 1, 1, 2, 1, 2, 1, 1, 2, 1, 1, 2, 1, 2, 1,
> 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 1, 1, 2,
> 1, 2, 1, 1, 2, 1, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1,
> 2, 1, 2, 1, 2, 1, 2, 1, 1, 1, 2, 1, 2, 1, 1, 2, 1, 1, 2, 1, 2,
> 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 1, 1,
> 2, 1, 2, 1, 1, 2, 1, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2,
> 1, 2, 1, 2, 1, 2, 1, 2, 1, 1, 1, 2, 1, 2)), .Label = c("1", "2",
> "3"), class = "factor"), insectdens = c(0, 0, 63.64, 11.99, 14.57,
> 22.5, 15.53, 0, 20.49, 107.6, 0, 87.16, 19.82, 22.24, 18.28,
> 51.92, 33.87, 42.1, 59.01, 0, 47.32, 15.78, 12.46, 43.02, 12.23,
> 9.98, 27.75, 7.47, 38.92, 11.78, 11.18, 0, 0, 120.6, 44.61, 24.02,
> 45.9, 26.78, 14.56, 80.2, 62.34, 37.4, 32.44, 17.58, 47.52, 8.94,
> 26.01, 54.7, 9.19, 141.89, 29.36, 10.39, 48.88, 14.6, 20.46,
> 158.34, 20.5, 9.52, 18.82, 14.36, 47.94, 12.26, 45.76, 31.44,
> 53.82, 104.37, 112, 74.4, 59.88, 73.38, 94.36, 73.78, 120.26,
> 305, 48.12, 129.45, 264.87, 53.88, 129.36, 87.9, 107.03, 57.33,
> 145.53, 90.48, 95.2, 110, 116.55, 110.44, 492, 50.7, 140.4, 68.16,
> 111.28, 104.8, 59.76, 75, 91.92, 68.4, 12.92, 19.94, 22.6, 17.38,
> 53.6, 102.6, 10.45, 151.92, 30.3, 0, 0, 0, 39.18, 34.96, 16.38,
> 21.38, 18.32, 60.4, 35.48, 16.9, 0, 24.96, 56.28, 263.76, 38.24,
> 37.12, 9.26, 30.76, 26.24, 25.88, 46.48, 7.2, 21.09, 48.87, 0,
> 28.1, 10.09, 44.28, 67.26, 0, 0, 29.72, 50.49, 63.92, 0, 0, 0,
> 18.28, 10.82, 7.5, 27.06, 21.48, 9.09, 21.94, 13.56, 10.4, 13.25,
> 46.6, 31.74, 8.57, 11.98, 12.08, 30.55, 12.46, 31.16, 27.27,
> 16.35, 78.15, 100.8, 13.54, 80.44, 69.35, 104.55, 83.6, 37.32,
> 0, 107.7, 91.55, 21.52, 50.76, 22.28, 17, 55.6, 52.85, 40.72,
> 15.76, 15.12, 41.08, 25.44, 10.79, 87.36, 19.58, 19.94, 78.32,
> 13.04, 39.54, 40.55, 74.08, 14.37, 34.68, 31.68, 69.4, 62.28,
> 13.13, 117.96, 41.02, 18.27, 72.66, 34.74, 30.2, 69.86, 17.4,
> 100.89, 16.72, 95.7, 43.92, 0, 27.6, 129.6, 73.64, 147.4, 107.82,
> 92.16, 46.9, 76.1, 52.78, 52.32, 60.57, 46.7, 48.65, 49.41, 0,
> 54.8, 30.18, 59.2, 0, 12.52, 0, 0, 15.89, 90.39, 35.42, 26.64,
> 8.54, 17.46, 52.98, 7.88, 48.81, 12.68, 49.85, 32.67, 64.6, 41.2,
> 20.2, 8.47, 80.29, 38.52, 17.28, 35.94, 41.55, 9.4, 237.25, 0,
> 38.88, 24.56, 25.69, 0, 15.42, 0, 0, 0, 0, 467.64, 25.82, 36,
> 11.64, 112.05, 31.54, 42.08, 0, 26.86, 79.74, 0, 27.18, 17.48,
> 0, 34.95, 14.45, 43.88, 33.76, 23.24, 32.2, 16.29, 72.84, 189.99,
> 436.05, 365.6, 259.98, 329.29, 228, 158.4, 140.91, 448.95, 433.84,
> 47.11, 228.9, 193.13, 130.3, 335.73, 609.9, 202.54, 371.88, 332,
> 360.36, 219.56, 338.91, 329.94, 139.15, 262.34, 285.9, 357.76,
> 253.68, 353.35, 839.16, 368, 717.42, 840.18, 2081.2, 900.15,
> 1052.03, 705.12, 1276.65, 512.25, 838.88, 614.46, 734.58, 479.52,
> 286.38, 3020.4, 750.6, 885.96, 796.8, 932.49, 824.67, 1476.09,
> 716.76, 576.46, 528.58, 568.8, 568.8, 712.53, 1168.86, 1864.56,
> 997.26, 792.05, 1807.52, 899.25, 939.03, 1487.7, 1121.12, 166.5,
> 84.96, 78.7, 31.98, 169.2, 99.35, 124.2, 176.85, 116.88, 104.6,
> 45.43, 0, 82.44, 193.05, 53.5, 204.49, 135.72, 201.9, 129.76,
> 49.71, 50.5, 93.06, 239.98, 75.72, 221.54, 207.79, 218.24, 73.26,
> 96.4, 227.63, 155.4, 141.7, 280.63, 98.25, 58.4, 16.6, 30.84,
> 141.72, 0, 277.16, 313.82, 534.19, 104.74, 508.04, 67.62, 68.44,
> 119.7, 215.37, 26.92, 0, 63.24, 48.68, 11.62, 81.36, 142.5, 65.07,
> 28.06, 133.5, 126.54, 70.28, 79.62, 107.73, 36.16, 30.14, 31.76,
> 407.76, 422.24, 274.24, 317.7, 241.5, 190.3, 644.49, 162.17,
> 1104.24, 324.78, 268.24, 214.2, 449.25, 363.22, 475.57, 197.12,
> 311.63, 154.28, 461.3, 352.52, 247.69, 382.65, 395.25, 270.63,
> 399.84, 338.4, 529.48, 440.82, 394.56, 270.48, 322, 441.22, 353.5,
> 452.4, 414.96, 699.72, 89.04, 173.7, 347.6, 10150.24, 563.67,
> 353.94, 456.88, 117.92, 513, 245.48, 440.37, 372.36, 398.86,
> 334.35, 428, 410.13, 398.06, 674.87, 438.75, 226.16, 367.9, 416.8,
> 501.48, 522.6, 616.11, 421.2, 309.96, 423.09, 232.08, 198.06,
> 48.66, 109.59, 49.59, 58.05, 152.08, 0, 617.83, 64.66, 372.75,
> 32.07, 66.81, 112.24, 68.28, 83.64, 157.48, 145.2, 46.24, 143,
> 99.18, 117.5, 158.05, 61.1, 91.68, 67.5, 112.62, 98.21, 117.54,
> 58.92, 77.3, 0), MONTHTIME = structure(as.integer(c(1, 1, 1,
> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> 1, 1, 1, 1, 1, 1, 1, 1, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,
> 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 9,
> 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,
> 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 13, 13, 13, 13, 13, 13, 13,
> 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,
> 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 2, 2, 2, 2, 2, 2, 2,
> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
> 2, 2, 2, 2, 2, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,
> 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 10, 10, 10, 10,
> 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,
> 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 14, 14, 14, 14,
> 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,
> 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 3, 3, 3, 3, 3, 3,
> 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,
> 3, 3, 3, 3, 3, 3, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,
> 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 11, 11,
> 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,
> 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 15,
> 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,
> 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,
> 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,
> 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
> 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,
> 8, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,
> 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,
> 12, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,
> 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,
> 16)), .Label = c("4.1", "5.1", "6.1", "7.1", "4.2", "5.2", "6.2",
> "7.2", "4.3", "5.3", "6.3", "7.3", "4.4", "5.4", "6.4", "7.4"
> ), class = "factor")), .Names = c("MONTH", "TRANSECT", "POLE",
> "TIME", "HEIGHT", "insectdens", "MONTHTIME"), row.names = c("1",
> "2", "4", "5", "7", "9", "10", "13", "14", "16", "17", "19",
> "20", "22", "23", "25", "26", "28", "29", "31", "32", "34", "35",
> "37", "38", "40", "41", "43", "44", "46", "47", "49", "50", "53",
> "55", "56", "58", "60", "61", "64", "65", "67", "68", "70", "71",
> "73", "74", "76", "77", "79", "80", "82", "83", "85", "86", "88",
> "89", "91", "92", "94", "95", "97", "98", "100", "101", "103",
> "104", "106", "107", "109", "111", "112", "115", "116", "118",
> "119", "121", "122", "124", "125", "127", "128", "130", "131",
> "133", "134", "136", "137", "139", "140", "142", "143", "145",
> "146", "148", "149", "151", "152", "154", "155", "157", "158",
> "160", "162", "163", "166", "167", "169", "170", "172", "173",
> "175", "176", "178", "179", "181", "182", "184", "185", "187",
> "188", "190", "191", "193", "194", "196", "197", "199", "200",
> "202", "203", "205", "206", "208", "209", "211", "213", "214",
> "217", "218", "220", "221", "223", "224", "226", "227", "229",
> "230", "232", "233", "235", "236", "238", "239", "241", "242",
> "244", "245", "247", "248", "250", "251", "253", "254", "256",
> "259", "260", "262", "264", "265", "268", "269", "271", "272",
> "274", "275", "277", "278", "280", "281", "283", "284", "286",
> "287", "289", "290", "292", "293", "295", "296", "298", "299",
> "301", "302", "304", "305", "307", "310", "311", "313", "315",
> "316", "319", "320", "322", "323", "325", "326", "328", "329",
> "331", "332", "334", "335", "337", "338", "340", "341", "343",
> "344", "346", "347", "349", "350", "352", "353", "355", "356",
> "358", "359", "361", "362", "364", "366", "367", "370", "371",
> "373", "374", "376", "377", "379", "380", "382", "383", "385",
> "386", "388", "389", "394", "395", "397", "398", "400", "401",
> "403", "404", "406", "407", "409", "410", "412", "413", "415",
> "417", "418", "421", "422", "424", "425", "427", "428", "430",
> "431", "433", "434", "436", "437", "439", "440", "442", "443",
> "445", "446", "448", "449", "451", "452", "454", "455", "457",
> "458", "460", "461", "463", "464", "466", "468", "469", "472",
> "473", "475", "476", "478", "479", "481", "482", "484", "485",
> "487", "488", "490", "491", "493", "494", "496", "497", "499",
> "500", "502", "503", "505", "506", "508", "509", "511", "512",
> "514", "515", "517", "519", "520", "523", "524", "526", "527",
> "529", "530", "532", "533", "535", "536", "538", "539", "541",
> "542", "544", "545", "547", "548", "550", "551", "553", "554",
> "556", "557", "559", "560", "562", "563", "565", "566", "568",
> "570", "571", "574", "575", "577", "578", "580", "581", "583",
> "584", "586", "587", "589", "590", "592", "593", "595", "596",
> "598", "599", "601", "602", "604", "605", "607", "608", "610",
> "611", "613", "616", "617", "619", "621", "622", "625", "626",
> "628", "629", "631", "632", "634", "635", "637", "638", "640",
> "641", "643", "644", "646", "647", "649", "650", "652", "653",
> "655", "656", "658", "659", "661", "662", "664", "667", "668",
> "670", "672", "673", "676", "677", "679", "680", "682", "683",
> "685", "686", "688", "689", "691", "692", "694", "695", "697",
> "698", "700", "701", "703", "704", "706", "707", "709", "710",
> "712", "713", "715", "718", "719", "721", "723", "724", "727",
> "728", "730", "731", "733", "734", "736", "737", "739", "740",
> "742", "743", "745", "746", "748", "749", "751", "752", "754",
> "755", "757", "758", "760", "761", "763", "764", "766", "769",
> "770", "772", "774", "775", "778", "779", "781", "782", "784",
> "785", "787", "788", "790", "791", "793", "794", "796", "797",
> "799", "800", "802", "803", "805", "806", "808", "809", "811",
> "812", "814", "815"), class = "data.frame")
>
>
>
> -- 
> This message (and any attachments) is for the recipient on...{{dropped}}



From john.maindonald at anu.edu.au  Wed Sep 12 04:02:47 2007
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Wed, 12 Sep 2007 12:02:47 +1000
Subject: [R-sig-ME] A spurious splitting of a variance component
In-Reply-To: <s6e68eda.056@wpo.nerc.ac.uk>
References: <s6e68eda.056@wpo.nerc.ac.uk>
Message-ID: <CC8E8086-C4E8-4D7D-96EA-01CB17B74F0E@anu.edu.au>

I have changed the subject line because the subject has changed.

Mea culpa, here is the example that I intended.
 > kiwishade$vine <- factor(rep(1:4,12))
 > ## The following offers, at least in simpler cases, a check.
 > unique(with(kiwishade, xtabs(~block+shade+vine)))
[1] 1
 > library(nlme)
 > VarCorr(lme(yield ~ shade, random=~1|block/shade/vine,  
data=kiwishade))
             Variance     StdDev
block =     pdLogChol(1)
(Intercept)  4.077830    2.019364
shade =     pdLogChol(1)
(Intercept)  2.186341    1.478628
vine =      pdLogChol(1)
(Intercept) 10.617337    3.258426
Residual     1.565418    1.251167
 > VarCorr(lme(yield ~ shade, random=~1|block/shade, data=kiwishade))
             Variance     StdDev
block =     pdLogChol(1)
(Intercept)  4.077868    2.019373
shade =     pdLogChol(1)
(Intercept)  2.186325    1.478623
Residual    12.182756    3.490381

Notice that, with 'random=~1|block/shade/vine', the Residual  
component of variances gets split in two parts.  I have no idea why  
this happens.  I notice that lmer() throws an error if given the  
formula ' ~ shade + (1|block/shade/vine)'

My earlier example doubled up on the random term for the block:shade  
level.  The lme() code, obviously wanting to please, obligingly split  
the component of variance into two more or less equal parts.  In this  
instance, lmer() gives very nearly the same result.

          lme4       Matrix
"0.999375-0" "0.999375-0"

 > library(lme4)
Loading required package: Matrix
 > lmer(yield ~ shade + (1|block/shade/plot), data=kiwishade)
. . . .

Random effects:
Groups             Name        Variance Std.Dev.
shade:block        (Intercept)  1.0965  1.0471
plot:(shade:block) (Intercept)  1.0899  1.0440
block              (Intercept)  4.0769  2.0191
Residual                       12.1829  3.4904
Number of obs: 48, groups: shade:block, 12; plot:(shade:block), 12;  
block, 3

> You might like to compare the following, using the kiwishade data  
> frame from the DAAG package
>
> VarCorr(lme(yield ~ shade, random=~1|block/shade/plot,  
> data=kiwishade))  ## The units are plots
>
> VarCorr(lme(yield ~ shade, random=~1|block/shade, data=kiwishade))
>
> The first one splits the block:shade component of variance between  
> block:shade and block:shade:plot  This is just wrong. The alleged  
> block:shade:plot component has nothing to do with plots.  It is  
> some deep mystery in the internal workings of lme() that it splits  
> the block:shade component of variance in this strange way rather  
> than throwing an error

The following is incorrect

> or recognizing that block:shade:plot is just another name for the  
> residual, and that it should act accordingly.

The following is correct.

> Doug may be able to throw light on this.


John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.



From dimitris.rizopoulos at med.kuleuven.be  Wed Sep 12 13:50:16 2007
From: dimitris.rizopoulos at med.kuleuven.be (Dimitris Rizopoulos)
Date: Wed, 12 Sep 2007 13:50:16 +0200
Subject: [R-sig-ME] lmer2() syntax with natural cubic splines
Message-ID: <001f01c7f533$15f58e60$0540210a@www.domain>

Dear lmer2() users,

I was wondering which is the appropriate `formula' syntax in the case 
I'd like to include a nonlinear time effect using natural cubic 
splines, with a diagonal covariance matrix for the random effects. In 
particular, in the following example

library(lme4)
library(splines)

fit1 <- lmer2(y ~ treat * ns(time, df = 7) + (ns(time, df = 7) | id), 
data = test.data)

`fit1' assumes an unspecified (8 by 8) covariance matrix for the 
random effects. How should I specify the formula argument such that 
the model assumes a diagonal 8 by 8 covariance matrix.

A solution I thought of is to include the output of `ns(time, df = 7)' 
as extra columns in `test.data' and use something like,

fit2 <- lmer2(y ~ treat * ns(time, df = 7) + (1 | id ) + (0 + time1 | 
id) +
    (0 + time2 | id) + (0 + time3 | id) + (0 + time4 | id) + (0 + 
time5 | id) +
    (0 + time6 | id) + (0 + time7|id), data = test.data)

where `time1, ..., time7' denote the output columns of `ns(time, df = 
7)'.

Is there a more efficient specification of `formula' in order to 
achieve the above.


Thans in advance for any hints.

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/(0)16/336899
Fax: +32/(0)16/337015
Web: http://med.kuleuven.be/biostat/
     http://www.student.kuleuven.be/~m0390867/dimitris.htm


Disclaimer: http://www.kuleuven.be/cwis/email_disclaimer.htm



From maechler at stat.math.ethz.ch  Wed Sep 12 15:46:46 2007
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 12 Sep 2007 15:46:46 +0200
Subject: [R-sig-ME] lmer vs lmer2
In-Reply-To: <40e66e0b0709060917y1b3c5395n24045fc1a5f1d172@mail.gmail.com>
References: <000f01c7f00f$91f5f6e0$0301a8c0@AndyXPS>
	<40e66e0b0709051922jda8f867i490b304c14e6a8df@mail.gmail.com>
	<351D3C0A50D2FF47B31C2ADBD015A50D01BA1440@EXCHANGEVS1.uthsc.tennessee.edu>
	<40e66e0b0709060917y1b3c5395n24045fc1a5f1d172@mail.gmail.com>
Message-ID: <18151.60870.787123.962355@stat.math.ethz.ch>

>>>>> "DB" == Douglas Bates <bates at stat.wisc.edu>
>>>>>     on Thu, 6 Sep 2007 11:17:17 -0500 writes:

    DB> On 9/6/07, Bush, Andrew J <abush at utmem.edu> wrote:
    >> Dear Douglas,

    >> In frustration, I invoked lmer2 this morning and I'm pleased to be able
    >> to tell you that lmer2 copes well and quickly with the model having a
    >> random intercept and two random covariate slopes.  I have not been able
    >> to get lmer to converge for the model on the same data.

    DB> Thanks for the information.

    DB> I expect to remove the confusion between lmer and lmer2 in the near
    DB> future.  The development version of the lme4 package has an lmer
    DB> function that is close to the current lmer2 in design.  It should
    DB> exhibit the same convergence behavior and be slightly faster on models
    DB> fit to large data sets than is the current lmer2.

    DB> This version has been in development for longer than I had expected.
    DB> I still have a few "infelicities" to resolve in the Laplace method for
    DB> generalized linear mixed models before I make test versions available.

    DB> I would be interested in the data set if you would be willing to
    DB> provide it.  I could perhaps incorporate it in the lme4 package so
    DB> others would have access to it.

Yes, indeed.  
The example might be particularly interesting as test case, not
only because some software implementations "converge" with
singular covariance matrix, but also because it
differs from other examples in having "many" fixed effects and
just one level random effects.

Martin

    >> -----Original Message-----
    >> From: dmbates at gmail.com [mailto:dmbates at gmail.com] On Behalf Of Douglas
    >> Bates
    >> Sent: Wednesday, September 05, 2007 9:22 PM
    >> To: ajbush at bellsouth.net
    >> Cc: r-sig-mixed-models at r-project.org
    >> Subject: Re: [R-sig-ME] Specifying random effects for multiple
    >> covariates via lmer
    >> 
    >> On 9/5/07, Andy Bush <ajbush at bellsouth.net> wrote:
    >> > While working through the text "Applied Longitudinal Analysis" by
    >> > Fitzmaurice, Laird and Ware, I encountered a fairly simple case study
    >> (pp
    >> > 210-7) in which a longitudinal model specifies three random effects:
    >> (1)
    >> > random intercepts for id, (2) random slopes for covariate1 (Age | id),
    >> and
    >> > (3) random slopes for covariate2 (log(ht) | id).  I've had no
    >> difficulty
    >> > formulating lmer models with correlated random intercepts and slopes
    >> for
    >> > either of the covariates individually but have not succeeded when I
    >> try to
    >> > compose a model with correlated random intercepts and slopes for two
    >> > covariates.
    >> 
    >> > Following is code that works well with the individual covariates
    >> separately:
    >> 
    >> > m1=lmer(LFEV1~Age + loght + InitAge + logbht + (1 + Age |
    >> id),data=fev,
    >> >        na.action=na.omit, method="REML")
    >> 
    >> > m2=lmer(LFEV1~Age + loght + InitAge + logbht+(1 + loght |
    >> id),data=fev,
    >> >        na.action=na.omit, method="REML")
    >> 
    >> Maybe I am missing the point but wouldn't the model you are
    >> considering be written as
    >> 
    >> lmer(LFEV1 ~ Age + loght + InitAge + logbht + (loght + Age|id), data =
    >> fev, na.action = na.omit, method = "REML")
    >> 
    >> That provides correlated random effects for the intercept, the
    >> coefficient for loght and the coefficient for Age at each level of the
    >> id factor.
    >> 

    DB> _______________________________________________
    DB> R-sig-mixed-models at r-project.org mailing list
    DB> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From nilsson.henric at gmail.com  Thu Sep 13 09:51:17 2007
From: nilsson.henric at gmail.com (Henric Nilsson (Private))
Date: Thu, 13 Sep 2007 09:51:17 +0200
Subject: [R-sig-ME] lmer vs lmer2
In-Reply-To: <18151.60870.787123.962355@stat.math.ethz.ch>
References: <000f01c7f00f$91f5f6e0$0301a8c0@AndyXPS>
	<40e66e0b0709051922jda8f867i490b304c14e6a8df@mail.gmail.com>
	<351D3C0A50D2FF47B31C2ADBD015A50D01BA1440@EXCHANGEVS1.uthsc.tennessee.edu>
	<40e66e0b0709060917y1b3c5395n24045fc1a5f1d172@mail.gmail.com>
	<18151.60870.787123.962355@stat.math.ethz.ch>
Message-ID: <20070913095117.3u6uhm22ckwwwc8k@www.sorch.se>

Quoting Martin Maechler <maechler at stat.math.ethz.ch>:

>>>>>> "DB" == Douglas Bates <bates at stat.wisc.edu>
>>>>>>     on Thu, 6 Sep 2007 11:17:17 -0500 writes:
>
>     DB> On 9/6/07, Bush, Andrew J <abush at utmem.edu> wrote:
>     >> Dear Douglas,
>
>     >> In frustration, I invoked lmer2 this morning and I'm pleased   
> to be able
>     >> to tell you that lmer2 copes well and quickly with the model having a
>     >> random intercept and two random covariate slopes.  I have not  
>  been able
>     >> to get lmer to converge for the model on the same data.
>
>     DB> Thanks for the information.
>
>     DB> I expect to remove the confusion between lmer and lmer2 in the near
>     DB> future.  The development version of the lme4 package has an lmer
>     DB> function that is close to the current lmer2 in design.  It should
>     DB> exhibit the same convergence behavior and be slightly faster  
>  on models
>     DB> fit to large data sets than is the current lmer2.
>
>     DB> This version has been in development for longer than I had expected.
>     DB> I still have a few "infelicities" to resolve in the Laplace   
> method for
>     DB> generalized linear mixed models before I make test versions   
> available.
>
>     DB> I would be interested in the data set if you would be willing to
>     DB> provide it.  I could perhaps incorporate it in the lme4 package so
>     DB> others would have access to it.
>
> Yes, indeed.
> The example might be particularly interesting as test case, not
> only because some software implementations "converge" with
> singular covariance matrix, but also because it
> differs from other examples in having "many" fixed effects and
> just one level random effects.

The data set in question, and, I belive, most others from Fitzmaurice,  
Laird and Ware's (2004) book on longitudinal data analysis, is  
available along with accompanying SAS programs at

http://biosun1.harvard.edu/~fitzmaur/ala/

In particular, the data used above is here

http://biosun1.harvard.edu/~fitzmaur/ala/fev1.txt

and the SAS code is here

http://biosun1.harvard.edu/~fitzmaur/ala/prog8_8.html


HTH,
Henric



>
> Martin
>
>     >> -----Original Message-----
>     >> From: dmbates at gmail.com [mailto:dmbates at gmail.com] On Behalf   
> Of Douglas
>     >> Bates
>     >> Sent: Wednesday, September 05, 2007 9:22 PM
>     >> To: ajbush at bellsouth.net
>     >> Cc: r-sig-mixed-models at r-project.org
>     >> Subject: Re: [R-sig-ME] Specifying random effects for multiple
>     >> covariates via lmer
>     >>
>     >> On 9/5/07, Andy Bush <ajbush at bellsouth.net> wrote:
>     >> > While working through the text "Applied Longitudinal Analysis" by
>     >> > Fitzmaurice, Laird and Ware, I encountered a fairly simple   
> case study
>     >> (pp
>     >> > 210-7) in which a longitudinal model specifies three random effects:
>     >> (1)
>     >> > random intercepts for id, (2) random slopes for covariate1   
> (Age | id),
>     >> and
>     >> > (3) random slopes for covariate2 (log(ht) | id).  I've had no
>     >> difficulty
>     >> > formulating lmer models with correlated random intercepts and slopes
>     >> for
>     >> > either of the covariates individually but have not succeeded when I
>     >> try to
>     >> > compose a model with correlated random intercepts and slopes for two
>     >> > covariates.
>     >>
>     >> > Following is code that works well with the individual covariates
>     >> separately:
>     >>
>     >> > m1=lmer(LFEV1~Age + loght + InitAge + logbht + (1 + Age |
>     >> id),data=fev,
>     >> >        na.action=na.omit, method="REML")
>     >>
>     >> > m2=lmer(LFEV1~Age + loght + InitAge + logbht+(1 + loght |
>     >> id),data=fev,
>     >> >        na.action=na.omit, method="REML")
>     >>
>     >> Maybe I am missing the point but wouldn't the model you are
>     >> considering be written as
>     >>
>     >> lmer(LFEV1 ~ Age + loght + InitAge + logbht + (loght + Age|id), data =
>     >> fev, na.action = na.omit, method = "REML")
>     >>
>     >> That provides correlated random effects for the intercept, the
>     >> coefficient for loght and the coefficient for Age at each level of the
>     >> id factor.
>     >>
>
>     DB> _______________________________________________
>     DB> R-sig-mixed-models at r-project.org mailing list
>     DB> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>



From reinhold.kliegl at gmail.com  Thu Sep 13 11:13:54 2007
From: reinhold.kliegl at gmail.com (Reinhold Kliegl)
Date: Thu, 13 Sep 2007 11:13:54 +0200
Subject: [R-sig-ME] lmer vs lmer2
In-Reply-To: <20070913095117.3u6uhm22ckwwwc8k@www.sorch.se>
References: <000f01c7f00f$91f5f6e0$0301a8c0@AndyXPS>
	<40e66e0b0709051922jda8f867i490b304c14e6a8df@mail.gmail.com>
	<351D3C0A50D2FF47B31C2ADBD015A50D01BA1440@EXCHANGEVS1.uthsc.tennessee.edu>
	<40e66e0b0709060917y1b3c5395n24045fc1a5f1d172@mail.gmail.com>
	<18151.60870.787123.962355@stat.math.ethz.ch>
	<20070913095117.3u6uhm22ckwwwc8k@www.sorch.se>
Message-ID: <F7CB4FF9-4E35-4F26-A719-25405F45F3AB@uni-potsdam.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20070913/8c9fab35/attachment.pl>

From reinhold.kliegl at gmail.com  Thu Sep 13 12:32:03 2007
From: reinhold.kliegl at gmail.com (Reinhold Kliegl)
Date: Thu, 13 Sep 2007 12:32:03 +0200
Subject: [R-sig-ME] lmer vs lmer2
In-Reply-To: <20070913095117.3u6uhm22ckwwwc8k@www.sorch.se>
References: <000f01c7f00f$91f5f6e0$0301a8c0@AndyXPS>
	<40e66e0b0709051922jda8f867i490b304c14e6a8df@mail.gmail.com>
	<351D3C0A50D2FF47B31C2ADBD015A50D01BA1440@EXCHANGEVS1.uthsc.tennessee.edu>
	<40e66e0b0709060917y1b3c5395n24045fc1a5f1d172@mail.gmail.com>
	<18151.60870.787123.962355@stat.math.ethz.ch>
	<20070913095117.3u6uhm22ckwwwc8k@www.sorch.se>
Message-ID: <4ACA1A0E-ABD9-43BD-A265-BB5F86314B83@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20070913/1f22de28/attachment.pl>

From A.Robinson at ms.unimelb.edu.au  Thu Sep 13 12:53:51 2007
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Thu, 13 Sep 2007 20:53:51 +1000
Subject: [R-sig-ME] [OT] was: lmer vs lmer2 is: great book!
In-Reply-To: <20070913095117.3u6uhm22ckwwwc8k@www.sorch.se>
References: <000f01c7f00f$91f5f6e0$0301a8c0@AndyXPS>
	<40e66e0b0709051922jda8f867i490b304c14e6a8df@mail.gmail.com>
	<351D3C0A50D2FF47B31C2ADBD015A50D01BA1440@EXCHANGEVS1.uthsc.tennessee.edu>
	<40e66e0b0709060917y1b3c5395n24045fc1a5f1d172@mail.gmail.com>
	<18151.60870.787123.962355@stat.math.ethz.ch>
	<20070913095117.3u6uhm22ckwwwc8k@www.sorch.se>
Message-ID: <20070913105351.GS17360@ms.unimelb.edu.au>

On Thu, Sep 13, 2007 at 09:51:17AM +0200, Henric Nilsson (Private) wrote:
> The data set in question, and, I belive, most others from Fitzmaurice,  
> Laird and Ware's (2004) book on longitudinal data analysis, is  

Which, I would like to add is a great book.  As part of a review for
Statistics in Medicine I asked Fitzmaurice to count the occurrences of
"For example," and "In other words," ... it was 300 and 400 times,
respectively.

I heartily recommend it as an introductory text to the area.

Andrew

> available along with accompanying SAS programs at
> 
> http://biosun1.harvard.edu/~fitzmaur/ala/
> 
> In particular, the data used above is here
> 
> http://biosun1.harvard.edu/~fitzmaur/ala/fev1.txt
> 
> and the SAS code is here
> 
> http://biosun1.harvard.edu/~fitzmaur/ala/prog8_8.html
> 
> 
> HTH,
> Henric
> 
-- 
Andrew Robinson  
Department of Mathematics and Statistics            Tel: +61-3-8344-9763
University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
http://www.ms.unimelb.edu.au/~andrewpr
http://blogs.mbs.edu/fishing-in-the-bay/



From abush at utmem.edu  Thu Sep 13 14:37:21 2007
From: abush at utmem.edu (Bush, Andrew J)
Date: Thu, 13 Sep 2007 07:37:21 -0500
Subject: [R-sig-ME] lmer vs lmer2
In-Reply-To: <AA6A8EB1-F5DF-432C-9005-37E4E86042B4@gmail.com>
Message-ID: <351D3C0A50D2FF47B31C2ADBD015A50D01C96EE2@EXCHANGEVS1.uthsc.tennessee.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20070913/97097572/attachment.pl>

From reinhold.kliegl at gmail.com  Thu Sep 13 16:10:50 2007
From: reinhold.kliegl at gmail.com (Reinhold Kliegl)
Date: Thu, 13 Sep 2007 16:10:50 +0200
Subject: [R-sig-ME] lmer vs lmer2
In-Reply-To: <351D3C0A50D2FF47B31C2ADBD015A50D01C96EE2@EXCHANGEVS1.uthsc.tennessee.edu>
References: <AA6A8EB1-F5DF-432C-9005-37E4E86042B4@gmail.com>
	<351D3C0A50D2FF47B31C2ADBD015A50D01C96EE2@EXCHANGEVS1.uthsc.tennessee.edu>
Message-ID: <aefe4d0a0709130710v11d9f5bbyae3aa542464f0212@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20070913/6061f559/attachment.pl>

From dafshartous at med.miami.edu  Thu Sep 13 18:05:56 2007
From: dafshartous at med.miami.edu (David Afshartous)
Date: Thu, 13 Sep 2007 12:05:56 -0400
Subject: [R-sig-ME] explaining lme variance component results
In-Reply-To: <A54F1284-C02D-4AD4-BCB8-CEA941FCC791@anu.edu.au>
Message-ID: <C30ED824.11B6%dafshartous@med.miami.edu>


All,
I don't have the initial e-mails from this thread and when I searched the
mail archives for "explaining lme variance component results" it doesn't
come up.  Do the SIGs need to be searched differently  then r-help?
Thanks,
David



On 9/6/07 5:07 AM, "John Maindonald" <john.maindonald at anu.edu.au> wrote:

> While I was out of contact with the list for a couple of days, I put the
> following together.  It is for the data that Mike gave initially, so
> that
> it assumes no replicates within POLE. The mean square for
> MONTH:TIME:TRANSECT:POLE is the Residual.
> 
> The variance component for TRANSECT is effectively zero.  For
> purposes of exposition, it can be set to zero.
> 
> The terms formula MONTH/TIME then suffices. lme() gives the numbers of
> groups as:
> 
> Number of Observations: 286
> Number of Groups:
>            MONTH TIME %in% MONTH
>                4              16
> 
> Observe that the design is then very nearly a complete balanced design:
> 
>> with(temp, table(MONTH,TIME))
>       TIME
> MONTH  1  2  3  4
>      4 18 17 18 18
>      5 18 18 18 17
>      6 18 18 18 18
>      7 18 18 18 18
> 
> Observe that
>    286/16=17.875
> less than 18 because two of the TIME:MONTH combinations have
> only 17 values.  The harmonic mean, which is 17.87, seems however
> preferable.
> 
> If the design were balanced, with replicates at
> MONTH/TIME/POLE level equal to n1=4/n2=4/n3=17.87
> then the mean squares would estimate, respectively
> 
> 4 x 17.87 s1^2 +  17.87 s2^2 + s3^2  = 4 x 17.87 (s1^2 +  s2^2 /4 +
> s3^2 / (4*17.87)
> 17.87 s2^2 + s3^2  = 17.87 ( s2^2 + s3^2 / 17.87)
> s3^2
> 
> In the first two cases, a second version of the formula is given
> that makes (to me, at least) better intuitive sense.
> 
> We have
>           Variance     Anova        DF     No. of repeats
>           Component    mean square         per 'parent'
> MONTH    0.75287      74.10751      3     4
> TIME     1.07395      20.52433     12     4
> Residual 1.20354      1.20356     270     17.87 (harmonic mean)
> 
> Observe that the residual mean square estimates the residual variance.
> The TIME variance component is calculated pretty much as
> (20.52433 - 1.20356)/17.87 = 1.0813, which does not quite agree
> with the ML estimate (nor should it; equating mean squares to expected
> mean squares is not the same as REML!)).
> 
> The statistical error is affected both by the statistical error in
> the TIME
> anova mean square, and by the statistical error in the Residual mean
> square.  The variance formula that is given below for MONTH can be
> readily adapted for this case also.
> 
> The MONTH variance component is calculated pretty much as: (74.10751 -
> 20.52433)/(4*17.87) = 0.7497 Again the agreement with the REML
> estimate is, quite properly, not perfect.
> 
> The estimate for s1^2 (MONTH} has a statistical error that is a
> compound of the errors in the ANOVA mean squares for both TIME and
> MONTH.  The variances of the two anova mean squares (both sample
> values of chi-squared statistics, under the usual assumptions) add,
> while the quantities themselves are subtracted.  The SE (sqrt of
> variance), for the estimate s1^2 of sig1^2, is
> 
> sqrt( (n2 * n3 * sig1^2 + n3 * sig2^2 + sig3^2)^2 / nu1
>       + (n3 * sig2^2 + sig3^2)^2 / nu2 ) / (n2*n3)
> 
> [The n's are the numbers of repeats.  The nu's are degrees of freedom.]
> 
> Variances are not, for quantities that are differences multiples of
> chi-squared statistics, a good basis for inference. (Here I am tempted
> to make rude comments about over-reliance on variances in much
> sample  survey work!). The variance calculations may however be useful
> in giving an idea of the relative contributions of the different
> sources of
> statistical noise.
> 
> I'd expect, though I have not gone through the arithmetic in detail,
> that the estimate for SE[s1^2] will increase, if we allow for the
> possibility that the TRANSECT component of variance, even though
> estimated as zero, may actually be greater than zero.
> 
> John Maindonald             email: john.maindonald at anu.edu.au
> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
> Centre for Mathematics & Its Applications, Room 1194,
> John Dedman Mathematical Sciences Building (Building 27)
> Australian National University, Canberra ACT 0200.
> 
> 
> On 5 Sep 2007, at 4:54 AM, Mike Dunbar wrote:
> 
>> Thanks to all, a couple more comments following up on Kevin's
>> comments below, and also ones sent to me directly.
>> 
>> I have plotted the data in many different ways, having spent
>> several years (yes!) trying to work out a suitable analysis for
>> these data. The aim of this particular analysis is to try to keep
>> things as simple as possible, I'm aware in particular that there
>> are differences between the behaviour of the factors across the
>> months (so one option is a month by month analysis - which I have
>> done but it was vetoed by co-workers for this paper so long as
>> there's a simple interpretation as well), and also that time is
>> generally the most important factor overall (this is already
>> documented by others - the data are of drifting macroinvertebrates
>> in rivers in case anyones interested).
>> 
>> The structure of the nesting is designed to mirror our expected
>> view of the correlations in the data based on spatial/temporal
>> proximity, a bit as Kevin describes below: so four times were
>> measured across a day and the experiment repeated across four
>> months, and for each of the 16 occasions, we have five transects,
>> within those four poles each, and not described previously, 1-3
>> measures at different heights on the poles.
>> 
>> Regarding the zero values: yes the normality is an assumption, I
>> hope to do better once this initial analysis is over. What I hoped
>> to show is despite this, and despite the assumptions of the
>> variance components analysis, there is evidence of an effect of
>> TRANSECT and / or POLE, once MONTH and TIME are accounted for.
>> 
>> What is very pertinent (thanks John) is the fact that in the data
>> as described, there is no replication within the lowest stratum,
>> POLE. There was one seeming replicate, but that must be an error.
>> This may well be the source of the problem that the POLE variance
>> component was large but not significant.
>> 
>> I had thought that despite the lack of replication within POLE that
>> it would still be possible to estimate a variance component for
>> POLE separately from the residual. The very wooly reasoning being
>> that the POLE component represents consistency in drift density
>> between POLEs across TRANSECT, TIME and MONTH, and residual
>> represents lack of consistency.
>> 
>> If my reasoning above is flawed, I really don't want to ditch the
>> POLE component, as its fairly central to the analysis, and I could
>> bring in HEIGHT to give replication within POLE (previous data is
>> for one height only). I'd prefer to do this as a fixed effect and
>> I've posted below some example data/code: can anyone comment if
>> this is valid?
>> 
>> Regarding the issue of magnitude of variance component/random
>> effect vs significance, I wonder if there is more too it than that,
>> certainly in this case we know that TIME is more important than
>> MONTH, despite being nested, but more critically, I can show some
>> data where the magnitude of the component doesn't seem to relate to
>> its significance. I'll post this in a separate mail to avoid
>> confusion, once again any comments are welcome. This gives me a
>> real headache explaining my results to my co-workers, let alone
>> reviewers. I ought to add that there could easily still be mistakes
>> where, as one regarding a non-replicate
>> has already been identified.
>> 
>> All the best again - hope this is interesting to others struggling
>> with similar issues??
>> 
>> Mike
>> 
>> 
>> 
>> 
>> varcor.2h.insects.hf <- lme(log(insectdens+1) ~ HEIGHT, random=~1|
>> MONTH/TIME/TRANSECT/POLE, data=temp2)
>> # introduce HEIGHT as a fixed effect, there are two heights per
>> pole for some poles: hence unbalanced
>> VarCorr(varcor.2h.insects.hf)
>> # variances: MONTH - 0.639, TIME: 1.248, TRANSECT: 0.013, POLE:
>> 0.160, Residual: 1.016
>> 
>> varcor.2h.insects.nospat.hf <- lme(log(insectdens+1) ~ HEIGHT,
>> random=~1|MONTH/TIME, data=temp2)
>> 
>> anova(varcor.2h.insects.hf,varcor.2h.insects.nospat.hf)
>> # two spatial factors together marginally signficant: p=0.06, but
>> test likely conservative
>> # simulation approach for null distribution (Faraway) probably too
>> difficult at this depth of nesting
>> intervals(varcor.2h.insects.hf)
>> # again some evidence for significance of TRANSECT, but POLE lower
>> bound close to 0.
>> 
>> # delete transect term and just compare models with and without
>> pole term
>> varcor.2h.insects.pole.hf <- lme(log(insectdens+1) ~ HEIGHT,
>> random=~1|MONTH/TIME/POLE, data=temp2)
>> # test pole factor on its own. This is possible as pole is coded as
>> a combination of transect and pole within transect
>> anova(varcor.2h.insects.pole.hf,varcor.2h.insects.nospat.hf)
>> # p=0.019. This would be great if analysis is valid
>> 
>> 
>> 
>> # read in data: this time with one or two heights per pole
>> 
>> temp2 <-
>> structure(list(MONTH = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L,
>> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L,
>> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
>> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
>> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
>> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
>> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
>> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
>> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
>> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
>> 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
>> 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
>> 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
>> 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
>> 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
>> 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
>> 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
>> 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L
>> ), .Label = c("4", "5", "6", "7"), class = "factor"), TRANSECT =
>> structure(c(1L,
>> 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L,
>> 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L, 5L, 5L,
>> 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L,
>> 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L, 5L, 5L,
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L,
>> 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L, 5L,
>> 5L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L,
>> 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L,
>> 5L, 5L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 3L, 3L, 3L,
>> 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 5L, 5L, 5L,
>> 5L, 5L, 5L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 3L, 3L, 3L,
>> 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 5L, 5L, 5L,
>> 5L, 5L, 5L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 3L, 3L, 3L,
>> 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 5L, 5L, 5L,
>> 5L, 5L, 5L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 3L, 3L,
>> 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L,
>> 5L, 5L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 3L, 3L, 3L,
>> 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 5L, 5L, 5L,
>> 5L, 5L, 5L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 3L, 3L,
>> 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 5L, 5L,
>> 5L, 5L, 5L, 5L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 3L,
>> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 5L,
>> 5L, 5L, 5L, 5L, 5L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L,
>> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
>> 5L, 5L, 5L, 5L, 5L, 5L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L,
>> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
>> 5L, 5L, 5L, 5L, 5L, 5L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L,
>> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
>> 5L, 5L, 5L, 5L, 5L, 5L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L,
>> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
>> 5L, 5L, 5L, 5L, 5L, 5L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L,
>> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
>> 5L, 5L, 5L, 5L, 5L, 5L), .Label = c("1", "2", "3", "4", "5"), class
>> = "factor"),
>>     POLE = structure(c(1L, 1L, 2L, 2L, 3L, 4L, 4L, 5L, 5L, 6L,
>>     6L, 7L, 7L, 8L, 8L, 9L, 9L, 10L, 10L, 11L, 11L, 12L, 12L,
>>     13L, 13L, 14L, 14L, 15L, 16L, 17L, 17L, 18L, 18L, 1L, 2L,
>>     2L, 3L, 4L, 4L, 5L, 5L, 5L, 6L, 7L, 7L, 8L, 8L, 9L, 9L, 10L,
>>     10L, 11L, 11L, 12L, 12L, 13L, 13L, 14L, 14L, 15L, 16L, 17L,
>>     17L, 18L, 18L, 1L, 1L, 2L, 2L, 3L, 4L, 4L, 5L, 5L, 6L, 6L,
>>     7L, 7L, 8L, 8L, 9L, 9L, 10L, 10L, 11L, 11L, 12L, 12L, 13L,
>>     13L, 14L, 14L, 15L, 16L, 17L, 17L, 18L, 18L, 1L, 1L, 2L,
>>     2L, 3L, 4L, 4L, 5L, 5L, 6L, 6L, 7L, 7L, 8L, 8L, 9L, 9L, 10L,
>>     10L, 11L, 11L, 12L, 12L, 13L, 13L, 14L, 14L, 15L, 16L, 17L,
>>     17L, 18L, 18L, 1L, 1L, 2L, 2L, 3L, 4L, 4L, 5L, 5L, 6L, 6L,
>>     7L, 7L, 8L, 8L, 9L, 9L, 10L, 10L, 11L, 11L, 12L, 12L, 13L,
>>     13L, 14L, 14L, 15L, 16L, 17L, 17L, 18L, 18L, 1L, 2L, 2L,
>>     3L, 4L, 4L, 5L, 5L, 6L, 6L, 7L, 7L, 8L, 8L, 9L, 9L, 10L,
>>     10L, 11L, 11L, 12L, 12L, 13L, 13L, 14L, 14L, 15L, 16L, 17L,
>>     17L, 18L, 18L, 1L, 2L, 2L, 3L, 4L, 4L, 5L, 5L, 6L, 6L, 7L,
>>     7L, 8L, 8L, 9L, 9L, 10L, 10L, 11L, 11L, 12L, 12L, 13L, 13L,
>>     14L, 14L, 15L, 16L, 17L, 17L, 18L, 18L, 1L, 1L, 2L, 2L, 3L,
>>     4L, 4L, 5L, 5L, 6L, 6L, 7L, 7L, 8L, 8L, 9L, 9L, 10L, 10L,
>>     11L, 11L, 13L, 13L, 14L, 14L, 15L, 16L, 17L, 17L, 18L, 18L,
>>     1L, 1L, 2L, 2L, 3L, 4L, 4L, 5L, 5L, 6L, 6L, 7L, 7L, 8L, 8L,
>>     9L, 9L, 10L, 10L, 11L, 11L, 12L, 12L, 13L, 13L, 14L, 14L,
>>     15L, 16L, 17L, 17L, 18L, 18L, 1L, 1L, 2L, 2L, 3L, 4L, 4L,
>>     5L, 5L, 6L, 6L, 7L, 7L, 8L, 8L, 9L, 9L, 10L, 10L, 11L, 11L,
>>     12L, 12L, 13L, 13L, 14L, 14L, 15L, 16L, 17L, 17L, 18L, 18L,
>>     1L, 1L, 2L, 2L, 3L, 4L, 4L, 5L, 5L, 6L, 6L, 7L, 7L, 8L, 8L,
>>     9L, 9L, 10L, 10L, 11L, 11L, 12L, 12L, 13L, 13L, 14L, 14L,
>>     15L, 16L, 17L, 17L, 18L, 18L, 1L, 1L, 2L, 2L, 3L, 4L, 4L,
>>     5L, 5L, 6L, 6L, 7L, 7L, 8L, 8L, 9L, 9L, 10L, 10L, 11L, 11L,
>>     12L, 12L, 13L, 13L, 14L, 14L, 15L, 16L, 17L, 17L, 18L, 18L,
>>     1L, 2L, 2L, 3L, 4L, 4L, 5L, 5L, 6L, 6L, 7L, 7L, 8L, 8L, 9L,
>>     9L, 10L, 10L, 11L, 11L, 12L, 12L, 13L, 13L, 14L, 14L, 15L,
>>     16L, 17L, 17L, 18L, 18L, 1L, 2L, 2L, 3L, 4L, 4L, 5L, 5L,
>>     6L, 6L, 7L, 7L, 8L, 8L, 9L, 9L, 10L, 10L, 11L, 11L, 12L,
>>     12L, 13L, 13L, 14L, 14L, 15L, 16L, 17L, 17L, 18L, 18L, 1L,
>>     2L, 2L, 3L, 4L, 4L, 5L, 5L, 6L, 6L, 7L, 7L, 8L, 8L, 9L, 9L,
>>     10L, 10L, 11L, 11L, 12L, 12L, 13L, 13L, 14L, 14L, 15L, 16L,
>>     17L, 17L, 18L, 18L, 1L, 2L, 2L, 3L, 4L, 4L, 5L, 5L, 6L, 6L,
>>     7L, 7L, 8L, 8L, 9L, 9L, 10L, 10L, 11L, 11L, 12L, 12L, 13L,
>>     13L, 14L, 14L, 15L, 16L, 17L, 17L, 18L, 18L), .Label = c("11",
>>     "12", "13", "14", "23", "24", "31", "32", "33", "34", "41",
>>     "42", "43", "44", "51", "52", "53", "54"), class = "factor"),
>>     TIME = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>>     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>>     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>>     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>>     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L,
>>     3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
>>     3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L,
>>     4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
>>     4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
>>     4L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>>     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>>     1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>>     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>>     2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
>>     3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
>>     3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
>>     4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
>>     4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 1L, 1L, 1L, 1L, 1L, 1L,
>>     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>>     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L,
>>     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>>     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>>     3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
>>     3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
>>     3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
>>     4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
>>     4L, 4L, 4L, 4L, 4L, 4L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>>     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>>     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>>     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>>     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L,
>>     3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
>>     3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L,
>>     4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
>>     4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L), .Label
>> = c("1",
>>     "2", "3", "4"), class = "factor"), HEIGHT = structure(c(1L,
>>     2L, 1L, 2L, 1L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L,
>>     2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, 2L,
>>     1L, 2L, 2L, 1L, 2L, 1L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L,
>>     2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 1L,
>>     1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 1L, 2L, 1L, 2L, 1L, 2L,
>>     1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L,
>>     2L, 1L, 1L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 1L, 2L, 1L,
>>     2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L,
>>     1L, 2L, 1L, 2L, 1L, 1L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L,
>>     1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L,
>>     2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, 2L, 1L, 2L, 1L, 1L,
>>     2L, 1L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L,
>>     2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, 2L, 1L, 2L,
>>     1L, 1L, 2L, 1L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L,
>>     2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, 2L,
>>     1L, 2L, 1L, 2L, 1L, 2L, 1L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L,
>>     1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 1L, 1L,
>>     2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 1L, 2L, 1L, 2L, 1L, 2L, 1L,
>>     2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L,
>>     1L, 1L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 1L, 2L, 1L, 2L,
>>     1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L,
>>     2L, 1L, 2L, 1L, 1L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 1L,
>>     2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L,
>>     1L, 2L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, 2L, 1L, 2L, 1L, 2L, 1L,
>>     2L, 1L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L,
>>     2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, 2L, 1L, 2L,
>>     1L, 1L, 2L, 1L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L,
>>     2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, 2L,
>>     1L, 2L, 1L, 1L, 2L, 1L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L,
>>     2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 1L,
>>     1L, 2L, 1L, 2L, 1L, 1L, 2L, 1L, 1L, 2L, 1L, 2L, 1L, 2L, 1L,
>>     2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L,
>>     1L, 1L, 1L, 2L, 1L, 2L, 1L, 1L, 2L, 1L, 1L, 2L, 1L, 2L, 1L,
>>     2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L,
>>     1L, 2L, 1L, 1L, 1L, 2L, 1L, 2L), .Label = c("1", "2", "3"
>>     ), class = "factor"), insectdens = c(0, 0, 63.64, 11.99,
>>     14.57, 22.5, 15.53, 0, 20.49, 107.6, 0, 87.16, 19.82, 22.24,
>>     18.28, 51.92, 33.87, 42.1, 59.01, 0, 47.32, 15.78, 12.46,
>>     43.02, 12.23, 9.98, 27.75, 7.47, 38.92, 11.78, 11.18, 0,
>>     0, 120.6, 44.61, 24.02, 45.9, 26.78, 14.56, 80.2, 62.34,
>>     37.4, 32.44, 17.58, 47.52, 8.94, 26.01, 54.7, 9.19, 141.89,
>>     29.36, 10.39, 48.88, 14.6, 20.46, 158.34, 20.5, 9.52, 18.82,
>>     14.36, 47.94, 12.26, 45.76, 31.44, 53.82, 104.37, 112, 74.4,
>>     59.88, 73.38, 94.36, 73.78, 120.26, 305, 48.12, 129.45, 264.87,
>>     53.88, 129.36, 87.9, 107.03, 57.33, 145.53, 90.48, 95.2,
>>     110, 116.55, 110.44, 492, 50.7, 140.4, 68.16, 111.28, 104.8,
>>     59.76, 75, 91.92, 68.4, 12.92, 19.94, 22.6, 17.38, 53.6,
>>     102.6, 10.45, 151.92, 30.3, 0, 0, 0, 39.18, 34.96, 16.38,
>>     21.38, 18.32, 60.4, 35.48, 16.9, 0, 24.96, 56.28, 263.76,
>>     38.24, 37.12, 9.26, 30.76, 26.24, 25.88, 46.48, 7.2, 21.09,
>>     48.87, 0, 28.1, 10.09, 44.28, 67.26, 0, 0, 29.72, 50.49,
>>     63.92, 0, 0, 0, 18.28, 10.82, 7.5, 27.06, 21.48, 9.09, 21.94,
>>     13.56, 10.4, 13.25, 46.6, 31.74, 8.57, 11.98, 12.08, 30.55,
>>     12.46, 31.16, 27.27, 16.35, 78.15, 100.8, 13.54, 80.44, 69.35,
>>     104.55, 83.6, 37.32, 0, 107.7, 91.55, 21.52, 50.76, 22.28,
>>     17, 55.6, 52.85, 40.72, 15.76, 15.12, 41.08, 25.44, 10.79,
>>     87.36, 19.58, 19.94, 78.32, 13.04, 39.54, 40.55, 74.08, 14.37,
>>     34.68, 31.68, 69.4, 62.28, 13.13, 117.96, 41.02, 18.27, 72.66,
>>     34.74, 30.2, 69.86, 17.4, 100.89, 16.72, 95.7, 43.92, 0,
>>     27.6, 129.6, 73.64, 147.4, 107.82, 92.16, 46.9, 76.1, 52.78,
>>     52.32, 60.57, 46.7, 48.65, 49.41, 0, 54.8, 30.18, 59.2, 0,
>>     12.52, 0, 0, 15.89, 90.39, 35.42, 26.64, 8.54, 17.46, 52.98,
>>     7.88, 48.81, 12.68, 49.85, 32.67, 64.6, 41.2, 20.2, 8.47,
>>     80.29, 38.52, 17.28, 35.94, 41.55, 9.4, 237.25, 0, 38.88,
>>     24.56, 25.69, 0, 15.42, 0, 0, 0, 0, 467.64, 25.82, 36, 11.64,
>>     112.05, 31.54, 42.08, 0, 26.86, 79.74, 0, 27.18, 17.48, 0,
>>     34.95, 14.45, 43.88, 33.76, 23.24, 32.2, 16.29, 72.84, 189.99,
>>     436.05, 365.6, 259.98, 329.29, 228, 158.4, 140.91, 448.95,
>>     433.84, 47.11, 228.9, 193.13, 130.3, 335.73, 609.9, 202.54,
>>     371.88, 332, 360.36, 219.56, 338.91, 329.94, 139.15, 262.34,
>>     285.9, 357.76, 253.68, 353.35, 839.16, 368, 717.42, 840.18,
>>     2081.2, 900.15, 1052.03, 705.12, 1276.65, 512.25, 838.88,
>>     614.46, 734.58, 479.52, 286.38, 3020.4, 750.6, 885.96, 796.8,
>>     932.49, 824.67, 1476.09, 716.76, 576.46, 528.58, 568.8, 568.8,
>>     712.53, 1168.86, 1864.56, 997.26, 792.05, 1807.52, 899.25,
>>     939.03, 1487.7, 1121.12, 166.5, 84.96, 78.7, 31.98, 169.2,
>>     99.35, 124.2, 176.85, 116.88, 104.6, 45.43, 0, 82.44, 193.05,
>>     53.5, 204.49, 135.72, 201.9, 129.76, 49.71, 50.5, 93.06,
>>     239.98, 75.72, 221.54, 207.79, 218.24, 73.26, 96.4, 227.63,
>>     155.4, 141.7, 280.63, 98.25, 58.4, 16.6, 30.84, 141.72, 0,
>>     277.16, 313.82, 534.19, 104.74, 508.04, 67.62, 68.44, 119.7,
>>     215.37, 26.92, 0, 63.24, 48.68, 11.62, 81.36, 142.5, 65.07,
>>     28.06, 133.5, 126.54, 70.28, 79.62, 107.73, 36.16, 30.14,
>>     31.76, 407.76, 422.24, 274.24, 317.7, 241.5, 190.3, 644.49,
>>     162.17, 1104.24, 324.78, 268.24, 214.2, 449.25, 363.22, 475.57,
>>     197.12, 311.63, 154.28, 461.3, 352.52, 247.69, 382.65, 395.25,
>>     270.63, 399.84, 338.4, 529.48, 440.82, 394.56, 270.48, 322,
>>     441.22, 353.5, 452.4, 414.96, 699.72, 89.04, 173.7, 347.6,
>>     10150.24, 563.67, 353.94, 456.88, 117.92, 513, 245.48, 440.37,
>>     372.36, 398.86, 334.35, 428, 410.13, 398.06, 674.87, 438.75,
>>     226.16, 367.9, 416.8, 501.48, 522.6, 616.11, 421.2, 309.96,
>>     423.09, 232.08, 198.06, 48.66, 109.59, 49.59, 58.05, 152.08,
>>     0, 617.83, 64.66, 372.75, 32.07, 66.81, 112.24, 68.28, 83.64,
>>     157.48, 145.2, 46.24, 143, 99.18, 117.5, 158.05, 61.1, 91.68,
>>     67.5, 112.62, 98.21, 117.54, 58.92, 77.3, 0)), .Names = c("MONTH",
>> "TRANSECT", "POLE", "TIME", "HEIGHT", "insectdens"), class =
>> "data.frame", row.names = c(1L,
>> 2L, 4L, 5L, 7L, 9L, 10L, 13L, 14L, 16L, 17L, 19L, 20L, 22L, 23L,
>> 25L, 26L, 28L, 29L, 31L, 32L, 34L, 35L, 37L, 38L, 40L, 41L, 43L,
>> 44L, 46L, 47L, 49L, 50L, 53L, 55L, 56L, 58L, 60L, 61L, 64L, 65L,
>> 67L, 68L, 70L, 71L, 73L, 74L, 76L, 77L, 79L, 80L, 82L, 83L, 85L,
>> 86L, 88L, 89L, 91L, 92L, 94L, 95L, 97L, 98L, 100L, 101L, 103L,
>> 104L, 106L, 107L, 109L, 111L, 112L, 115L, 116L, 118L, 119L, 121L,
>> 122L, 124L, 125L, 127L, 128L, 130L, 131L, 133L, 134L, 136L, 137L,
>> 139L, 140L, 142L, 143L, 145L, 146L, 148L, 149L, 151L, 152L, 154L,
>> 155L, 157L, 158L, 160L, 162L, 163L, 166L, 167L, 169L, 170L, 172L,
>> 173L, 175L, 176L, 178L, 179L, 181L, 182L, 184L, 185L, 187L, 188L,
>> 190L, 191L, 193L, 194L, 196L, 197L, 199L, 200L, 202L, 203L, 205L,
>> 206L, 208L, 209L, 211L, 213L, 214L, 217L, 218L, 220L, 221L, 223L,
>> 224L, 226L, 227L, 229L, 230L, 232L, 233L, 235L, 236L, 238L, 239L,
>> 241L, 242L, 244L, 245L, 247L, 248L, 250L, 251L, 253L, 254L, 256L,
>> 259L, 260L, 262L, 264L, 265L, 268L, 269L, 271L, 272L, 274L, 275L,
>> 277L, 278L, 280L, 281L, 283L, 284L, 286L, 287L, 289L, 290L, 292L,
>> 293L, 295L, 296L, 298L, 299L, 301L, 302L, 304L, 305L, 307L, 310L,
>> 311L, 313L, 315L, 316L, 319L, 320L, 322L, 323L, 325L, 326L, 328L,
>> 329L, 331L, 332L, 334L, 335L, 337L, 338L, 340L, 341L, 343L, 344L,
>> 346L, 347L, 349L, 350L, 352L, 353L, 355L, 356L, 358L, 359L, 361L,
>> 362L, 364L, 366L, 367L, 370L, 371L, 373L, 374L, 376L, 377L, 379L,
>> 380L, 382L, 383L, 385L, 386L, 388L, 389L, 394L, 395L, 397L, 398L,
>> 400L, 401L, 403L, 404L, 406L, 407L, 409L, 410L, 412L, 413L, 415L,
>> 417L, 418L, 421L, 422L, 424L, 425L, 427L, 428L, 430L, 431L, 433L,
>> 434L, 436L, 437L, 439L, 440L, 442L, 443L, 445L, 446L, 448L, 449L,
>> 451L, 452L, 454L, 455L, 457L, 458L, 460L, 461L, 463L, 464L, 466L,
>> 468L, 469L, 472L, 473L, 475L, 476L, 478L, 479L, 481L, 482L, 484L,
>> 485L, 487L, 488L, 490L, 491L, 493L, 494L, 496L, 497L, 499L, 500L,
>> 502L, 503L, 505L, 506L, 508L, 509L, 511L, 512L, 514L, 515L, 517L,
>> 519L, 520L, 523L, 524L, 526L, 527L, 529L, 530L, 532L, 533L, 535L,
>> 536L, 538L, 539L, 541L, 542L, 544L, 545L, 547L, 548L, 550L, 551L,
>> 553L, 554L, 556L, 557L, 559L, 560L, 562L, 563L, 565L, 566L, 568L,
>> 570L, 571L, 574L, 575L, 577L, 578L, 580L, 581L, 583L, 584L, 586L,
>> 587L, 589L, 590L, 592L, 593L, 595L, 596L, 598L, 599L, 601L, 602L,
>> 604L, 605L, 607L, 608L, 610L, 611L, 613L, 616L, 617L, 619L, 621L,
>> 622L, 625L, 626L, 628L, 629L, 631L, 632L, 634L, 635L, 637L, 638L,
>> 640L, 641L, 643L, 644L, 646L, 647L, 649L, 650L, 652L, 653L, 655L,
>> 656L, 658L, 659L, 661L, 662L, 664L, 667L, 668L, 670L, 672L, 673L,
>> 676L, 677L, 679L, 680L, 682L, 683L, 685L, 686L, 688L, 689L, 691L,
>> 692L, 694L, 695L, 697L, 698L, 700L, 701L, 703L, 704L, 706L, 707L,
>> 709L, 710L, 712L, 713L, 715L, 718L, 719L, 721L, 723L, 724L, 727L,
>> 728L, 730L, 731L, 733L, 734L, 736L, 737L, 739L, 740L, 742L, 743L,
>> 745L, 746L, 748L, 749L, 751L, 752L, 754L, 755L, 757L, 758L, 760L,
>> 761L, 763L, 764L, 766L, 769L, 770L, 772L, 774L, 775L, 778L, 779L,
>> 781L, 782L, 784L, 785L, 787L, 788L, 790L, 791L, 793L, 794L, 796L,
>> 797L, 799L, 800L, 802L, 803L, 805L, 806L, 808L, 809L, 811L, 812L,
>> 814L, 815L))
>> 
>> 
>> -- 
>> This message (and any attachments) is for the recipient on...{{dropped}}
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From lamprianou at yahoo.com  Fri Sep 14 11:50:34 2007
From: lamprianou at yahoo.com (Iasonas Lamprianou)
Date: Fri, 14 Sep 2007 02:50:34 -0700 (PDT)
Subject: [R-sig-ME] R-sig-mixed-models Digest, Vol 9, Issue 19
Message-ID: <449770.67174.qm@web54102.mail.re2.yahoo.com>

Dear friends, this is a question that has to do with both stats and lmer. I hope somebody could respond.
I gave a probabilities test to around 300 Year 6 and Year 7 pupils in England. I also gave the same test to their teachers (14 teachers). The test for the teachers consists of  two parts, only 8 of the teachers completed the second part, so only 8 teachedrs and 230 pupils are in the analysis. I also gave the test to other 100 (approximately teachers), so I know where those 14 teachers stand compared to the other 100 teachers that completed the test.  I am using the ability of the teachers on the two parts of the test as predictors of the ability of the pupils. This is the model:

ab2 <- lmer(PupilAbility ~ 1+TeacherAbilityPart_A * TeacherAbilityPArt_B +(1|TEACHER),mix,method="ML")

So, I have teachers as second level (random) and the performance of each teacher on each part of the test as predictor. Can lmer fit this model reliably in the sense that there are only eight teachers on the second level? Is it right to use second level variables (teacher's variables) as fixed effetcts where there are 230 rows/pupils and 8 teahcers (around 25 pupils per teacher - is there enough variance)?
Thanks for the response
P.S.These are the results

Linear mixed-effects model fit by maximum likelihood 
Formula: ZPROBABI ~ 1 + ZPCABT * ZABILC + (1 | TEACHER) 
   Data: mix 
 AIC   BIC logLik MLdeviance REMLdeviance
 701 718.4 -345.5        691        695.5
Random effects:
 Groups   Name Variance Std.Dev.
 TEACHER       0.28153  0.53059 
 Residual      0.98756  0.99376 
number of obs: 238, groups: TEACHER, 9
 
Fixed effects:
              Estimate Std. Error t value
(Intercept)   -0.05188    0.29532 -0.1757
ZPCABT         0.41414    0.24732  1.6745
ZABILC         0.08206    0.24415  0.3361
ZPCABT:ZABILC -0.23751    0.34840 -0.6817
 
Correlation of Fixed Effects:
            (Intr) ZPCABT ZABILC
ZPCABT       0.472              
ZABILC      -0.635 -0.520       
ZPCABT:ZABI -0.675 -0.227  0.593


 By the way, is anyone out there coming from Greece or Cyprus?
 

Dr. Iasonas Lamprianou
Department of Education
The University of Manchester
Oxford Road, Manchester M13 9PL, UK
Tel. 0044 161 275 3485
iasonas.lamprianou at manchester.ac.uk



----- Original Message ----
From: "r-sig-mixed-models-request at r-project.org" <r-sig-mixed-models-request at r-project.org>
To: r-sig-mixed-models at r-project.org
Sent: Thursday, 13 September, 2007 7:00:05 PM
Subject: R-sig-mixed-models Digest, Vol 9, Issue 19


Send R-sig-mixed-models mailing list submissions to
    r-sig-mixed-models at r-project.org

To subscribe or unsubscribe via the World Wide Web, visit
    https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
or, via email, send a message with subject or body 'help' to
    r-sig-mixed-models-request at r-project.org

You can reach the person managing the list at
    r-sig-mixed-models-owner at r-project.org

When replying, please edit your Subject line so it is more specific
than "Re: Contents of R-sig-mixed-models digest..."


Today's Topics:

   1. Re: explaining lme variance component results (David Afshartous)


----------------------------------------------------------------------

Message: 1
Date: Thu, 13 Sep 2007 12:05:56 -0400
From: David Afshartous <dafshartous at med.miami.edu>
Subject: Re: [R-sig-ME] explaining lme variance component results
To: John Maindonald <john.maindonald at anu.edu.au>, Mike Dunbar
    <mdu at ceh.ac.uk>
Cc: r-sig-mixed-models at r-project.org
Message-ID: <C30ED824.11B6%dafshartous at med.miami.edu>
Content-Type: text/plain;    charset="US-ASCII"


All,
I don't have the initial e-mails from this thread and when I searched the
mail archives for "explaining lme variance component results" it doesn't
come up.  Do the SIGs need to be searched differently  then r-help?
Thanks,
David



On 9/6/07 5:07 AM, "John Maindonald" <john.maindonald at anu.edu.au> wrote:

> While I was out of contact with the list for a couple of days, I put the
> following together.  It is for the data that Mike gave initially, so
> that
> it assumes no replicates within POLE. The mean square for
> MONTH:TIME:TRANSECT:POLE is the Residual.
> 
> The variance component for TRANSECT is effectively zero.  For
> purposes of exposition, it can be set to zero.
> 
> The terms formula MONTH/TIME then suffices. lme() gives the numbers of
> groups as:
> 
> Number of Observations: 286
> Number of Groups:
>            MONTH TIME %in% MONTH
>                4              16
> 
> Observe that the design is then very nearly a complete balanced design:
> 
>> with(temp, table(MONTH,TIME))
>       TIME
> MONTH  1  2  3  4
>      4 18 17 18 18
>      5 18 18 18 17
>      6 18 18 18 18
>      7 18 18 18 18
> 
> Observe that
>    286/16=17.875
> less than 18 because two of the TIME:MONTH combinations have
> only 17 values.  The harmonic mean, which is 17.87, seems however
> preferable.
> 
> If the design were balanced, with replicates at
> MONTH/TIME/POLE level equal to n1=4/n2=4/n3=17.87
> then the mean squares would estimate, respectively
> 
> 4 x 17.87 s1^2 +  17.87 s2^2 + s3^2  = 4 x 17.87 (s1^2 +  s2^2 /4 +
> s3^2 / (4*17.87)
> 17.87 s2^2 + s3^2  = 17.87 ( s2^2 + s3^2 / 17.87)
> s3^2
> 
> In the first two cases, a second version of the formula is given
> that makes (to me, at least) better intuitive sense.
> 
> We have
>           Variance     Anova        DF     No. of repeats
>           Component    mean square         per 'parent'
> MONTH    0.75287      74.10751      3     4
> TIME     1.07395      20.52433     12     4
> Residual 1.20354      1.20356     270     17.87 (harmonic mean)
> 
> Observe that the residual mean square estimates the residual variance.
> The TIME variance component is calculated pretty much as
> (20.52433 - 1.20356)/17.87 = 1.0813, which does not quite agree
> with the ML estimate (nor should it; equating mean squares to expected
> mean squares is not the same as REML!)).
> 
> The statistical error is affected both by the statistical error in
> the TIME
> anova mean square, and by the statistical error in the Residual mean
> square.  The variance formula that is given below for MONTH can be
> readily adapted for this case also.
> 
> The MONTH variance component is calculated pretty much as: (74.10751 -
> 20.52433)/(4*17.87) = 0.7497 Again the agreement with the REML
> estimate is, quite properly, not perfect.
> 
> The estimate for s1^2 (MONTH} has a statistical error that is a
> compound of the errors in the ANOVA mean squares for both TIME and
> MONTH.  The variances of the two anova mean squares (both sample
> values of chi-squared statistics, under the usual assumptions) add,
> while the quantities themselves are subtracted.  The SE (sqrt of
> variance), for the estimate s1^2 of sig1^2, is
> 
> sqrt( (n2 * n3 * sig1^2 + n3 * sig2^2 + sig3^2)^2 / nu1
>       + (n3 * sig2^2 + sig3^2)^2 / nu2 ) / (n2*n3)
> 
> [The n's are the numbers of repeats.  The nu's are degrees of freedom.]
> 
> Variances are not, for quantities that are differences multiples of
> chi-squared statistics, a good basis for inference. (Here I am tempted
> to make rude comments about over-reliance on variances in much
> sample  survey work!). The variance calculations may however be useful
> in giving an idea of the relative contributions of the different
> sources of
> statistical noise.
> 
> I'd expect, though I have not gone through the arithmetic in detail,
> that the estimate for SE[s1^2] will increase, if we allow for the
> possibility that the TRANSECT component of variance, even though
> estimated as zero, may actually be greater than zero.
> 
> John Maindonald             email: john.maindonald at anu.edu.au
> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
> Centre for Mathematics & Its Applications, Room 1194,
> John Dedman Mathematical Sciences Building (Building 27)
> Australian National University, Canberra ACT 0200.
> 
> 
> On 5 Sep 2007, at 4:54 AM, Mike Dunbar wrote:
> 
>> Thanks to all, a couple more comments following up on Kevin's
>> comments below, and also ones sent to me directly.
>> 
>> I have plotted the data in many different ways, having spent
>> several years (yes!) trying to work out a suitable analysis for
>> these data. The aim of this particular analysis is to try to keep
>> things as simple as possible, I'm aware in particular that there
>> are differences between the behaviour of the factors across the
>> months (so one option is a month by month analysis - which I have
>> done but it was vetoed by co-workers for this paper so long as
>> there's a simple interpretation as well), and also that time is
>> generally the most important factor overall (this is already
>> documented by others - the data are of drifting macroinvertebrates
>> in rivers in case anyones interested).
>> 
>> The structure of the nesting is designed to mirror our expected
>> view of the correlations in the data based on spatial/temporal
>> proximity, a bit as Kevin describes below: so four times were
>> measured across a day and the experiment repeated across four
>> months, and for each of the 16 occasions, we have five transects,
>> within those four poles each, and not described previously, 1-3
>> measures at different heights on the poles.
>> 
>> Regarding the zero values: yes the normality is an assumption, I
>> hope to do better once this initial analysis is over. What I hoped
>> to show is despite this, and despite the assumptions of the
>> variance components analysis, there is evidence of an effect of
>> TRANSECT and / or POLE, once MONTH and TIME are accounted for.
>> 
>> What is very pertinent (thanks John) is the fact that in the data
>> as described, there is no replication within the lowest stratum,
>> POLE. There was one seeming replicate, but that must be an error.
>> This may well be the source of the problem that the POLE variance
>> component was large but not significant.
>> 
>> I had thought that despite the lack of replication within POLE that
>> it would still be possible to estimate a variance component for
>> POLE separately from the residual. The very wooly reasoning being
>> that the POLE component represents consistency in drift density
>> between POLEs across TRANSECT, TIME and MONTH, and residual
>> represents lack of consistency.
>> 
>> If my reasoning above is flawed, I really don't want to ditch the
>> POLE component, as its fairly central to the analysis, and I could
>> bring in HEIGHT to give replication within POLE (previous data is
>> for one height only). I'd prefer to do this as a fixed effect and
>> I've posted below some example data/code: can anyone comment if
>> this is valid?
>> 
>> Regarding the issue of magnitude of variance component/random
>> effect vs significance, I wonder if there is more too it than that,
>> certainly in this case we know that TIME is more important than
>> MONTH, despite being nested, but more critically, I can show some
>> data where the magnitude of the component doesn't seem to relate to
>> its significance. I'll post this in a separate mail to avoid
>> confusion, once again any comments are welcome. This gives me a
>> real headache explaining my results to my co-workers, let alone
>> reviewers. I ought to add that there could easily still be mistakes
>> where, as one regarding a non-replicate
>> has already been identified.
>> 
>> All the best again - hope this is interesting to others struggling
>> with similar issues??
>> 
>> Mike
>> 
>> 
>> 
>> 
>> varcor.2h.insects.hf <- lme(log(insectdens+1) ~ HEIGHT, random=~1|
>> MONTH/TIME/TRANSECT/POLE, data=temp2)
>> # introduce HEIGHT as a fixed effect, there are two heights per
>> pole for some poles: hence unbalanced
>> VarCorr(varcor.2h.insects.hf)
>> # variances: MONTH - 0.639, TIME: 1.248, TRANSECT: 0.013, POLE:
>> 0.160, Residual: 1.016
>> 
>> varcor.2h.insects.nospat.hf <- lme(log(insectdens+1) ~ HEIGHT,
>> random=~1|MONTH/TIME, data=temp2)
>> 
>> anova(varcor.2h.insects.hf,varcor.2h.insects.nospat.hf)
>> # two spatial factors together marginally signficant: p=0.06, but
>> test likely conservative
>> # simulation approach for null distribution (Faraway) probably too
>> difficult at this depth of nesting
>> intervals(varcor.2h.insects.hf)
>> # again some evidence for significance of TRANSECT, but POLE lower
>> bound close to 0.
>> 
>> # delete transect term and just compare models with and without
>> pole term
>> varcor.2h.insects.pole.hf <- lme(log(insectdens+1) ~ HEIGHT,
>> random=~1|MONTH/TIME/POLE, data=temp2)
>> # test pole factor on its own. This is possible as pole is coded as
>> a combination of transect and pole within transect
>> anova(varcor.2h.insects.pole.hf,varcor.2h.insects.nospat.hf)
>> # p=0.019. This would be great if analysis is valid
>> 
>> 
>> 
>> # read in data: this time with one or two heights per pole
>> 
>> temp2 <-
>> structure(list(MONTH = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L,
>> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L,
>> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
>> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
>> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
>> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
>> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
>> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
>> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
>> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
>> 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
>> 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
>> 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
>> 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
>> 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
>> 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
>> 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
>> 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L
>> ), .Label = c("4", "5", "6", "7"), class = "factor"), TRANSECT =
>> structure(c(1L,
>> 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L,
>> 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L, 5L, 5L,
>> 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L,
>> 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L, 5L, 5L,
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L,
>> 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L, 5L,
>> 5L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L,
>> 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L,
>> 5L, 5L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 3L, 3L, 3L,
>> 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 5L, 5L, 5L,
>> 5L, 5L, 5L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 3L, 3L, 3L,
>> 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 5L, 5L, 5L,
>> 5L, 5L, 5L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 3L, 3L, 3L,
>> 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 5L, 5L, 5L,
>> 5L, 5L, 5L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 3L, 3L,
>> 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L,
>> 5L, 5L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 3L, 3L, 3L,
>> 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 5L, 5L, 5L,
>> 5L, 5L, 5L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 3L, 3L,
>> 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 5L, 5L,
>> 5L, 5L, 5L, 5L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 3L,
>> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 5L,
>> 5L, 5L, 5L, 5L, 5L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L,
>> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
>> 5L, 5L, 5L, 5L, 5L, 5L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L,
>> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
>> 5L, 5L, 5L, 5L, 5L, 5L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L,
>> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
>> 5L, 5L, 5L, 5L, 5L, 5L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L,
>> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
>> 5L, 5L, 5L, 5L, 5L, 5L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L,
>> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
>> 5L, 5L, 5L, 5L, 5L, 5L), .Label = c("1", "2", "3", "4", "5"), class
>> = "factor"),
>>     POLE = structure(c(1L, 1L, 2L, 2L, 3L, 4L, 4L, 5L, 5L, 6L,
>>     6L, 7L, 7L, 8L, 8L, 9L, 9L, 10L, 10L, 11L, 11L, 12L, 12L,
>>     13L, 13L, 14L, 14L, 15L, 16L, 17L, 17L, 18L, 18L, 1L, 2L,
>>     2L, 3L, 4L, 4L, 5L, 5L, 5L, 6L, 7L, 7L, 8L, 8L, 9L, 9L, 10L,
>>     10L, 11L, 11L, 12L, 12L, 13L, 13L, 14L, 14L, 15L, 16L, 17L,
>>     17L, 18L, 18L, 1L, 1L, 2L, 2L, 3L, 4L, 4L, 5L, 5L, 6L, 6L,
>>     7L, 7L, 8L, 8L, 9L, 9L, 10L, 10L, 11L, 11L, 12L, 12L, 13L,
>>     13L, 14L, 14L, 15L, 16L, 17L, 17L, 18L, 18L, 1L, 1L, 2L,
>>     2L, 3L, 4L, 4L, 5L, 5L, 6L, 6L, 7L, 7L, 8L, 8L, 9L, 9L, 10L,
>>     10L, 11L, 11L, 12L, 12L, 13L, 13L, 14L, 14L, 15L, 16L, 17L,
>>     17L, 18L, 18L, 1L, 1L, 2L, 2L, 3L, 4L, 4L, 5L, 5L, 6L, 6L,
>>     7L, 7L, 8L, 8L, 9L, 9L, 10L, 10L, 11L, 11L, 12L, 12L, 13L,
>>     13L, 14L, 14L, 15L, 16L, 17L, 17L, 18L, 18L, 1L, 2L, 2L,
>>     3L, 4L, 4L, 5L, 5L, 6L, 6L, 7L, 7L, 8L, 8L, 9L, 9L, 10L,
>>     10L, 11L, 11L, 12L, 12L, 13L, 13L, 14L, 14L, 15L, 16L, 17L,
>>     17L, 18L, 18L, 1L, 2L, 2L, 3L, 4L, 4L, 5L, 5L, 6L, 6L, 7L,
>>     7L, 8L, 8L, 9L, 9L, 10L, 10L, 11L, 11L, 12L, 12L, 13L, 13L,
>>     14L, 14L, 15L, 16L, 17L, 17L, 18L, 18L, 1L, 1L, 2L, 2L, 3L,
>>     4L, 4L, 5L, 5L, 6L, 6L, 7L, 7L, 8L, 8L, 9L, 9L, 10L, 10L,
>>     11L, 11L, 13L, 13L, 14L, 14L, 15L, 16L, 17L, 17L, 18L, 18L,
>>     1L, 1L, 2L, 2L, 3L, 4L, 4L, 5L, 5L, 6L, 6L, 7L, 7L, 8L, 8L,
>>     9L, 9L, 10L, 10L, 11L, 11L, 12L, 12L, 13L, 13L, 14L, 14L,
>>     15L, 16L, 17L, 17L, 18L, 18L, 1L, 1L, 2L, 2L, 3L, 4L, 4L,
>>     5L, 5L, 6L, 6L, 7L, 7L, 8L, 8L, 9L, 9L, 10L, 10L, 11L, 11L,
>>     12L, 12L, 13L, 13L, 14L, 14L, 15L, 16L, 17L, 17L, 18L, 18L,
>>     1L, 1L, 2L, 2L, 3L, 4L, 4L, 5L, 5L, 6L, 6L, 7L, 7L, 8L, 8L,
>>     9L, 9L, 10L, 10L, 11L, 11L, 12L, 12L, 13L, 13L, 14L, 14L,
>>     15L, 16L, 17L, 17L, 18L, 18L, 1L, 1L, 2L, 2L, 3L, 4L, 4L,
>>     5L, 5L, 6L, 6L, 7L, 7L, 8L, 8L, 9L, 9L, 10L, 10L, 11L, 11L,
>>     12L, 12L, 13L, 13L, 14L, 14L, 15L, 16L, 17L, 17L, 18L, 18L,
>>     1L, 2L, 2L, 3L, 4L, 4L, 5L, 5L, 6L, 6L, 7L, 7L, 8L, 8L, 9L,
>>     9L, 10L, 10L, 11L, 11L, 12L, 12L, 13L, 13L, 14L, 14L, 15L,
>>     16L, 17L, 17L, 18L, 18L, 1L, 2L, 2L, 3L, 4L, 4L, 5L, 5L,
>>     6L, 6L, 7L, 7L, 8L, 8L, 9L, 9L, 10L, 10L, 11L, 11L, 12L,
>>     12L, 13L, 13L, 14L, 14L, 15L, 16L, 17L, 17L, 18L, 18L, 1L,
>>     2L, 2L, 3L, 4L, 4L, 5L, 5L, 6L, 6L, 7L, 7L, 8L, 8L, 9L, 9L,
>>     10L, 10L, 11L, 11L, 12L, 12L, 13L, 13L, 14L, 14L, 15L, 16L,
>>     17L, 17L, 18L, 18L, 1L, 2L, 2L, 3L, 4L, 4L, 5L, 5L, 6L, 6L,
>>     7L, 7L, 8L, 8L, 9L, 9L, 10L, 10L, 11L, 11L, 12L, 12L, 13L,
>>     13L, 14L, 14L, 15L, 16L, 17L, 17L, 18L, 18L), .Label = c("11",
>>     "12", "13", "14", "23", "24", "31", "32", "33", "34", "41",
>>     "42", "43", "44", "51", "52", "53", "54"), class = "factor"),
>>     TIME = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>>     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>>     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>>     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>>     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L,
>>     3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
>>     3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L,
>>     4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
>>     4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
>>     4L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>>     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>>     1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>>     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>>     2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
>>     3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
>>     3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
>>     4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
>>     4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 1L, 1L, 1L, 1L, 1L, 1L,
>>     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>>     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L,
>>     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>>     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>>     3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
>>     3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
>>     3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
>>     4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
>>     4L, 4L, 4L, 4L, 4L, 4L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>>     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>>     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>>     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>>     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L,
>>     3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
>>     3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L,
>>     4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
>>     4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L), .Label
>> = c("1",
>>     "2", "3", "4"), class = "factor"), HEIGHT = structure(c(1L,
>>     2L, 1L, 2L, 1L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L,
>>     2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, 2L,
>>     1L, 2L, 2L, 1L, 2L, 1L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L,
>>     2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 1L,
>>     1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 1L, 2L, 1L, 2L, 1L, 2L,
>>     1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L,
>>     2L, 1L, 1L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 1L, 2L, 1L,
>>     2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L,
>>     1L, 2L, 1L, 2L, 1L, 1L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L,
>>     1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L,
>>     2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, 2L, 1L, 2L, 1L, 1L,
>>     2L, 1L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L,
>>     2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, 2L, 1L, 2L,
>>     1L, 1L, 2L, 1L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L,
>>     2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, 2L,
>>     1L, 2L, 1L, 2L, 1L, 2L, 1L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L,
>>     1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 1L, 1L,
>>     2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 1L, 2L, 1L, 2L, 1L, 2L, 1L,
>>     2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L,
>>     1L, 1L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 1L, 2L, 1L, 2L,
>>     1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L,
>>     2L, 1L, 2L, 1L, 1L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 1L,
>>     2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L,
>>     1L, 2L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, 2L, 1L, 2L, 1L, 2L, 1L,
>>     2L, 1L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L,
>>     2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, 2L, 1L, 2L,
>>     1L, 1L, 2L, 1L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L,
>>     2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, 2L,
>>     1L, 2L, 1L, 1L, 2L, 1L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L,
>>     2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 1L,
>>     1L, 2L, 1L, 2L, 1L, 1L, 2L, 1L, 1L, 2L, 1L, 2L, 1L, 2L, 1L,
>>     2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L,
>>     1L, 1L, 1L, 2L, 1L, 2L, 1L, 1L, 2L, 1L, 1L, 2L, 1L, 2L, 1L,
>>     2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L,
>>     1L, 2L, 1L, 1L, 1L, 2L, 1L, 2L), .Label = c("1", "2", "3"
>>     ), class = "factor"), insectdens = c(0, 0, 63.64, 11.99,
>>     14.57, 22.5, 15.53, 0, 20.49, 107.6, 0, 87.16, 19.82, 22.24,
>>     18.28, 51.92, 33.87, 42.1, 59.01, 0, 47.32, 15.78, 12.46,
>>     43.02, 12.23, 9.98, 27.75, 7.47, 38.92, 11.78, 11.18, 0,
>>     0, 120.6, 44.61, 24.02, 45.9, 26.78, 14.56, 80.2, 62.34,
>>     37.4, 32.44, 17.58, 47.52, 8.94, 26.01, 54.7, 9.19, 141.89,
>>     29.36, 10.39, 48.88, 14.6, 20.46, 158.34, 20.5, 9.52, 18.82,
>>     14.36, 47.94, 12.26, 45.76, 31.44, 53.82, 104.37, 112, 74.4,
>>     59.88, 73.38, 94.36, 73.78, 120.26, 305, 48.12, 129.45, 264.87,
>>     53.88, 129.36, 87.9, 107.03, 57.33, 145.53, 90.48, 95.2,
>>     110, 116.55, 110.44, 492, 50.7, 140.4, 68.16, 111.28, 104.8,
>>     59.76, 75, 91.92, 68.4, 12.92, 19.94, 22.6, 17.38, 53.6,
>>     102.6, 10.45, 151.92, 30.3, 0, 0, 0, 39.18, 34.96, 16.38,
>>     21.38, 18.32, 60.4, 35.48, 16.9, 0, 24.96, 56.28, 263.76,
>>     38.24, 37.12, 9.26, 30.76, 26.24, 25.88, 46.48, 7.2, 21.09,
>>     48.87, 0, 28.1, 10.09, 44.28, 67.26, 0, 0, 29.72, 50.49,
>>     63.92, 0, 0, 0, 18.28, 10.82, 7.5, 27.06, 21.48, 9.09, 21.94,
>>     13.56, 10.4, 13.25, 46.6, 31.74, 8.57, 11.98, 12.08, 30.55,
>>     12.46, 31.16, 27.27, 16.35, 78.15, 100.8, 13.54, 80.44, 69.35,
>>     104.55, 83.6, 37.32, 0, 107.7, 91.55, 21.52, 50.76, 22.28,
>>     17, 55.6, 52.85, 40.72, 15.76, 15.12, 41.08, 25.44, 10.79,
>>     87.36, 19.58, 19.94, 78.32, 13.04, 39.54, 40.55, 74.08, 14.37,
>>     34.68, 31.68, 69.4, 62.28, 13.13, 117.96, 41.02, 18.27, 72.66,
>>     34.74, 30.2, 69.86, 17.4, 100.89, 16.72, 95.7, 43.92, 0,
>>     27.6, 129.6, 73.64, 147.4, 107.82, 92.16, 46.9, 76.1, 52.78,
>>     52.32, 60.57, 46.7, 48.65, 49.41, 0, 54.8, 30.18, 59.2, 0,
>>     12.52, 0, 0, 15.89, 90.39, 35.42, 26.64, 8.54, 17.46, 52.98,
>>     7.88, 48.81, 12.68, 49.85, 32.67, 64.6, 41.2, 20.2, 8.47,
>>     80.29, 38.52, 17.28, 35.94, 41.55, 9.4, 237.25, 0, 38.88,
>>     24.56, 25.69, 0, 15.42, 0, 0, 0, 0, 467.64, 25.82, 36, 11.64,
>>     112.05, 31.54, 42.08, 0, 26.86, 79.74, 0, 27.18, 17.48, 0,
>>     34.95, 14.45, 43.88, 33.76, 23.24, 32.2, 16.29, 72.84, 189.99,
>>     436.05, 365.6, 259.98, 329.29, 228, 158.4, 140.91, 448.95,
>>     433.84, 47.11, 228.9, 193.13, 130.3, 335.73, 609.9, 202.54,
>>     371.88, 332, 360.36, 219.56, 338.91, 329.94, 139.15, 262.34,
>>     285.9, 357.76, 253.68, 353.35, 839.16, 368, 717.42, 840.18,
>>     2081.2, 900.15, 1052.03, 705.12, 1276.65, 512.25, 838.88,
>>     614.46, 734.58, 479.52, 286.38, 3020.4, 750.6, 885.96, 796.8,
>>     932.49, 824.67, 1476.09, 716.76, 576.46, 528.58, 568.8, 568.8,
>>     712.53, 1168.86, 1864.56, 997.26, 792.05, 1807.52, 899.25,
>>     939.03, 1487.7, 1121.12, 166.5, 84.96, 78.7, 31.98, 169.2,
>>     99.35, 124.2, 176.85, 116.88, 104.6, 45.43, 0, 82.44, 193.05,
>>     53.5, 204.49, 135.72, 201.9, 129.76, 49.71, 50.5, 93.06,
>>     239.98, 75.72, 221.54, 207.79, 218.24, 73.26, 96.4, 227.63,
>>     155.4, 141.7, 280.63, 98.25, 58.4, 16.6, 30.84, 141.72, 0,
>>     277.16, 313.82, 534.19, 104.74, 508.04, 67.62, 68.44, 119.7,
>>     215.37, 26.92, 0, 63.24, 48.68, 11.62, 81.36, 142.5, 65.07,
>>     28.06, 133.5, 126.54, 70.28, 79.62, 107.73, 36.16, 30.14,
>>     31.76, 407.76, 422.24, 274.24, 317.7, 241.5, 190.3, 644.49,
>>     162.17, 1104.24, 324.78, 268.24, 214.2, 449.25, 363.22, 475.57,
>>     197.12, 311.63, 154.28, 461.3, 352.52, 247.69, 382.65, 395.25,
>>     270.63, 399.84, 338.4, 529.48, 440.82, 394.56, 270.48, 322,
>>     441.22, 353.5, 452.4, 414.96, 699.72, 89.04, 173.7, 347.6,
>>     10150.24, 563.67, 353.94, 456.88, 117.92, 513, 245.48, 440.37,
>>     372.36, 398.86, 334.35, 428, 410.13, 398.06, 674.87, 438.75,
>>     226.16, 367.9, 416.8, 501.48, 522.6, 616.11, 421.2, 309.96,
>>     423.09, 232.08, 198.06, 48.66, 109.59, 49.59, 58.05, 152.08,
>>     0, 617.83, 64.66, 372.75, 32.07, 66.81, 112.24, 68.28, 83.64,
>>     157.48, 145.2, 46.24, 143, 99.18, 117.5, 158.05, 61.1, 91.68,
>>     67.5, 112.62, 98.21, 117.54, 58.92, 77.3, 0)), .Names = c("MONTH",
>> "TRANSECT", "POLE", "TIME", "HEIGHT", "insectdens"), class =
>> "data.frame", row.names = c(1L,
>> 2L, 4L, 5L, 7L, 9L, 10L, 13L, 14L, 16L, 17L, 19L, 20L, 22L, 23L,
>> 25L, 26L, 28L, 29L, 31L, 32L, 34L, 35L, 37L, 38L, 40L, 41L, 43L,
>> 44L, 46L, 47L, 49L, 50L, 53L, 55L, 56L, 58L, 60L, 61L, 64L, 65L,
>> 67L, 68L, 70L, 71L, 73L, 74L, 76L, 77L, 79L, 80L, 82L, 83L, 85L,
>> 86L, 88L, 89L, 91L, 92L, 94L, 95L, 97L, 98L, 100L, 101L, 103L,
>> 104L, 106L, 107L, 109L, 111L, 112L, 115L, 116L, 118L, 119L, 121L,
>> 122L, 124L, 125L, 127L, 128L, 130L, 131L, 133L, 134L, 136L, 137L,
>> 139L, 140L, 142L, 143L, 145L, 146L, 148L, 149L, 151L, 152L, 154L,
>> 155L, 157L, 158L, 160L, 162L, 163L, 166L, 167L, 169L, 170L, 172L,
>> 173L, 175L, 176L, 178L, 179L, 181L, 182L, 184L, 185L, 187L, 188L,
>> 190L, 191L, 193L, 194L, 196L, 197L, 199L, 200L, 202L, 203L, 205L,
>> 206L, 208L, 209L, 211L, 213L, 214L, 217L, 218L, 220L, 221L, 223L,
>> 224L, 226L, 227L, 229L, 230L, 232L, 233L, 235L, 236L, 238L, 239L,
>> 241L, 242L, 244L, 245L, 247L, 248L, 250L, 251L, 253L, 254L, 256L,
>> 259L, 260L, 262L, 264L, 265L, 268L, 269L, 271L, 272L, 274L, 275L,
>> 277L, 278L, 280L, 281L, 283L, 284L, 286L, 287L, 289L, 290L, 292L,
>> 293L, 295L, 296L, 298L, 299L, 301L, 302L, 304L, 305L, 307L, 310L,
>> 311L, 313L, 315L, 316L, 319L, 320L, 322L, 323L, 325L, 326L, 328L,
>> 329L, 331L, 332L, 334L, 335L, 337L, 338L, 340L, 341L, 343L, 344L,
>> 346L, 347L, 349L, 350L, 352L, 353L, 355L, 356L, 358L, 359L, 361L,
>> 362L, 364L, 366L, 367L, 370L, 371L, 373L, 374L, 376L, 377L, 379L,
>> 380L, 382L, 383L, 385L, 386L, 388L, 389L, 394L, 395L, 397L, 398L,
>> 400L, 401L, 403L, 404L, 406L, 407L, 409L, 410L, 412L, 413L, 415L,
>> 417L, 418L, 421L, 422L, 424L, 425L, 427L, 428L, 430L, 431L, 433L,
>> 434L, 436L, 437L, 439L, 440L, 442L, 443L, 445L, 446L, 448L, 449L,
>> 451L, 452L, 454L, 455L, 457L, 458L, 460L, 461L, 463L, 464L, 466L,
>> 468L, 469L, 472L, 473L, 475L, 476L, 478L, 479L, 481L, 482L, 484L,
>> 485L, 487L, 488L, 490L, 491L, 493L, 494L, 496L, 497L, 499L, 500L,
>> 502L, 503L, 505L, 506L, 508L, 509L, 511L, 512L, 514L, 515L, 517L,
>> 519L, 520L, 523L, 524L, 526L, 527L, 529L, 530L, 532L, 533L, 535L,
>> 536L, 538L, 539L, 541L, 542L, 544L, 545L, 547L, 548L, 550L, 551L,
>> 553L, 554L, 556L, 557L, 559L, 560L, 562L, 563L, 565L, 566L, 568L,
>> 570L, 571L, 574L, 575L, 577L, 578L, 580L, 581L, 583L, 584L, 586L,
>> 587L, 589L, 590L, 592L, 593L, 595L, 596L, 598L, 599L, 601L, 602L,
>> 604L, 605L, 607L, 608L, 610L, 611L, 613L, 616L, 617L, 619L, 621L,
>> 622L, 625L, 626L, 628L, 629L, 631L, 632L, 634L, 635L, 637L, 638L,
>> 640L, 641L, 643L, 644L, 646L, 647L, 649L, 650L, 652L, 653L, 655L,
>> 656L, 658L, 659L, 661L, 662L, 664L, 667L, 668L, 670L, 672L, 673L,
>> 676L, 677L, 679L, 680L, 682L, 683L, 685L, 686L, 688L, 689L, 691L,
>> 692L, 694L, 695L, 697L, 698L, 700L, 701L, 703L, 704L, 706L, 707L,
>> 709L, 710L, 712L, 713L, 715L, 718L, 719L, 721L, 723L, 724L, 727L,
>> 728L, 730L, 731L, 733L, 734L, 736L, 737L, 739L, 740L, 742L, 743L,
>> 745L, 746L, 748L, 749L, 751L, 752L, 754L, 755L, 757L, 758L, 760L,
>> 761L, 763L, 764L, 766L, 769L, 770L, 772L, 774L, 775L, 778L, 779L,
>> 781L, 782L, 784L, 785L, 787L, 788L, 790L, 791L, 793L, 794L, 796L,
>> 797L, 799L, 800L, 802L, 803L, 805L, 806L, 808L, 809L, 811L, 812L,
>> 814L, 815L))
>> 
>> 
>> -- 
>> This message (and any attachments) is for the recipient on...{{dropped}}
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



------------------------------

_______________________________________________
R-sig-mixed-models mailing list
R-sig-mixed-models at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


End of R-sig-mixed-models Digest, Vol 9, Issue 19
*************************************************


      ___________________________________________________________
Yahoo! Answers - Got a question? Someone out there knows the answer. Try it
now.
http://uk.answers.yahoo.com/



From David.Duffy at qimr.edu.au  Sun Sep 16 23:46:13 2007
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Mon, 17 Sep 2007 07:46:13 +1000 (EST)
Subject: [R-sig-ME] PupilAbility
In-Reply-To: <449770.67174.qm@web54102.mail.re2.yahoo.com>
References: <449770.67174.qm@web54102.mail.re2.yahoo.com>
Message-ID: <Pine.LNX.4.64.0709170734210.22992@orpheus.qimr.edu.au>

On Fri, 14 Sep 2007, Iasonas Lamprianou wrote:

> Dear friends, this is a question that has to do with both stats and 
> lmer. I hope somebody could respond. I gave a probabilities test to 
> around 300 Year 6 and Year 7 pupils in England. I also gave the same 
> test to their teachers (14 teachers). The test for the teachers consists 
> of two parts, only 8 of the teachers completed the second part, so only 
> 8 teachedrs and 230 pupils are in the analysis. I also gave the test to 
> other 100 (approximately teachers), so I know where those 14 teachers 
> stand compared to the other 100 teachers that completed the test.  I am 
> using the ability of the teachers on the two parts of the test as 
> predictors of the ability of the pupils. This is the model:
>
> ab2 <- lmer(PupilAbility ~ 1+TeacherAbilityPart_A * TeacherAbilityPArt_B +(1|TEACHER),mix,method="ML")
>

I would think you need to fit a structural equation model that includes a
measurement model for TeacherAbility.  Then you can also use the teachers who
only completed part A but not part B.  Unfortunately, the R sem package
doesn't handle multigroup or missing data type problems, as far as I know.


    TeacherAbility ------> PupilAbility
         /  \
        /    \
       V      V
      A        B

>
>  Is it right to use second level variables (teacher's variables) 
> as fixed effects where there are 230 rows/pupils and 8 teachers (around 
> 25 pupils per teacher - is there enough variance)?
>

I would think so.

David Duffy.
-- 
| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From pts007 at hotmail.com  Mon Sep 17 02:54:01 2007
From: pts007 at hotmail.com (ts p)
Date: Mon, 17 Sep 2007 00:54:01 +0000
Subject: [R-sig-ME] how to estimate R- and G-side random effects of GLMM in R
Message-ID: <BAY138-F32A64D6B09EAA12856501B8FBF0@phx.gbl>

Hello, everyone,

I am not very familiar to use R.
I used SAS Proc GLIMMIX to estimate R- and G-side random effects of 
generalized linear mixed models. But the procedure can just use PQL or MQL. 
Now I want to lmer function in R to estimate GLMM because it can use Laplace 
approximation. It is more precise than PQL or MQL. But I read the manual of 
lmer. I did not find the information how to write a covariance structure in 
the function and how the function can know the struction is for R- or G-side 
random effects.

For example, if I use the following SAS proc GLIMMIX code to estimate a 
model, I wonder who can tell me how to use lmer to write R code to estimate 
the same model.

proc glimmix ;
    class person group item;
    model score(event='1')=item group /noint dist=binary link=logit s;
    random _residual_ / sub=person type=cs ;
run;

Thanks a lot!

P. T. Shu



From bates at stat.wisc.edu  Mon Sep 17 14:57:05 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Mon, 17 Sep 2007 07:57:05 -0500
Subject: [R-sig-ME] how to estimate R- and G-side random effects of GLMM
	in R
In-Reply-To: <BAY138-F32A64D6B09EAA12856501B8FBF0@phx.gbl>
References: <BAY138-F32A64D6B09EAA12856501B8FBF0@phx.gbl>
Message-ID: <40e66e0b0709170557r6fe1e023x9a822ec7b2220783@mail.gmail.com>

On 9/16/07, ts p <pts007 at hotmail.com> wrote:
> Hello, everyone,
>
> I am not very familiar to use R.
> I used SAS Proc GLIMMIX to estimate R- and G-side random effects of
> generalized linear mixed models. But the procedure can just use PQL or MQL.
> Now I want to lmer function in R to estimate GLMM because it can use Laplace
> approximation. It is more precise than PQL or MQL. But I read the manual of
> lmer. I did not find the information how to write a covariance structure in
> the function and how the function can know the struction is for R- or G-side
> random effects.
>
> For example, if I use the following SAS proc GLIMMIX code to estimate a
> model, I wonder who can tell me how to use lmer to write R code to estimate
> the same model.
>
> proc glimmix ;
>     class person group item;
>     model score(event='1')=item group /noint dist=binary link=logit s;
>     random _residual_ / sub=person type=cs ;
> run;

I am not fluent in SAS but I believe the model that you want to fit would be

lmer(score ~ item + group + (1|person), <dataSetName>, family = binomial)

assuming that score, item, person and group are stored as factors and
that score has only two levels.  If not you should dichotomize score
before fitting the model.

Others may be better able to decide what model the SAS code would fit.
 I have difficulty with this because, for example, I can't see what
the compound symmetry structure is supposed to mean.  There certainly
isn't a compound symmetry structure on either the marginal or the
conditional distribution of the response given the random effects,
because the variance of a binomial depends on the mean.  Specifying an
R matrix independently of the linear predictor doesn't make sense to
me.



From lamprianou at yahoo.com  Wed Sep 19 08:41:45 2007
From: lamprianou at yahoo.com (Iasonas Lamprianou)
Date: Tue, 18 Sep 2007 23:41:45 -0700 (PDT)
Subject: [R-sig-ME] lmer residuals
Message-ID: <499776.37067.qm@web54102.mail.re2.yahoo.com>

Dear friends, 
I know (already discussed this with Prof Bates) that  lmer and lmer2 cannot estimate residuals or predicted values when family=binomial. Can anyone give me an idea of how to estimate predicted values, and then compute the residuals in another way? Can anyone give me some code (even if it needs some modifications) in order to generate predicted values, and then compute the residuals? 

jason

 
Dr. Iasonas Lamprianou
Department of Education
The University of Manchester
Oxford Road, Manchester M13 9PL, UK
Tel. 0044 161 275 3485
iasonas.lamprianou at manchester.ac.uk


----- Original Message ----
From: "r-sig-mixed-models-request at r-project.org" <r-sig-mixed-models-request at r-project.org>
To: r-sig-mixed-models at r-project.org
Sent: Tuesday, 18 September, 2007 1:00:01 PM
Subject: R-sig-mixed-models Digest, Vol 9, Issue 22


Send R-sig-mixed-models mailing list submissions to
    r-sig-mixed-models at r-project.org

To subscribe or unsubscribe via the World Wide Web, visit
    https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
or, via email, send a message with subject or body 'help' to
    r-sig-mixed-models-request at r-project.org

You can reach the person managing the list at
    r-sig-mixed-models-owner at r-project.org

When replying, please edit your Subject line so it is more specific
than "Re: Contents of R-sig-mixed-models digest..."


Today's Topics:

   1. Re: how to estimate R- and G-side random effects of GLMM    in R
      (Douglas Bates)


----------------------------------------------------------------------

Message: 1
Date: Mon, 17 Sep 2007 07:57:05 -0500
From: "Douglas Bates" <bates at stat.wisc.edu>
Subject: Re: [R-sig-ME] how to estimate R- and G-side random effects
    of GLMM    in R
To: "ts p" <pts007 at hotmail.com>
Cc: r-sig-mixed-models at r-project.org
Message-ID:
    <40e66e0b0709170557r6fe1e023x9a822ec7b2220783 at mail.gmail.com>
Content-Type: text/plain; charset=ISO-8859-1

On 9/16/07, ts p <pts007 at hotmail.com> wrote:
> Hello, everyone,
>
> I am not very familiar to use R.
> I used SAS Proc GLIMMIX to estimate R- and G-side random effects of
> generalized linear mixed models. But the procedure can just use PQL or MQL.
> Now I want to lmer function in R to estimate GLMM because it can use Laplace
> approximation. It is more precise than PQL or MQL. But I read the manual of
> lmer. I did not find the information how to write a covariance structure in
> the function and how the function can know the struction is for R- or G-side
> random effects.
>
> For example, if I use the following SAS proc GLIMMIX code to estimate a
> model, I wonder who can tell me how to use lmer to write R code to estimate
> the same model.
>
> proc glimmix ;
>     class person group item;
>     model score(event='1')=item group /noint dist=binary link=logit s;
>     random _residual_ / sub=person type=cs ;
> run;

I am not fluent in SAS but I believe the model that you want to fit would be

lmer(score ~ item + group + (1|person), <dataSetName>, family = binomial)

assuming that score, item, person and group are stored as factors and
that score has only two levels.  If not you should dichotomize score
before fitting the model.

Others may be better able to decide what model the SAS code would fit.
I have difficulty with this because, for example, I can't see what
the compound symmetry structure is supposed to mean.  There certainly
isn't a compound symmetry structure on either the marginal or the
conditional distribution of the response given the random effects,
because the variance of a binomial depends on the mean.  Specifying an
R matrix independently of the linear predictor doesn't make sense to
me.



------------------------------

_______________________________________________
R-sig-mixed-models mailing list
R-sig-mixed-models at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


End of R-sig-mixed-models Digest, Vol 9, Issue 22
*************************************************


      ___________________________________________________________
Yahoo! Answers - Got a question? Someone out there knows the answer. Try it
now.
http://uk.answers.yahoo.com/



From sarah at stats.gla.ac.uk  Wed Sep 19 14:28:03 2007
From: sarah at stats.gla.ac.uk (Sarah Barry)
Date: Wed, 19 Sep 2007 13:28:03 +0100
Subject: [R-sig-ME] Different random effects variances for outcomes and
	groups
Message-ID: <46F115D3.1090002@stats.gla.ac.uk>

Dear all,

I wonder if someone could give me some insight on coding lmer.  I have 
facial shape data on children in two groups at four time points (3,6,12 
and 24 months).  Each child has a set of coordinate positions measured 
on their face at each time point (the set of coordinates is the same 
across individuals and times).  Take coordinates 1 and 2 only for now 
(reproducible code at the bottom of this email for simulated data).

If I plot the trends for coordinates 1 and 2 for each individual over 
time, there is a different amount of variance amongst the individuals 
(at least in the intercept, and maybe in the slope) for the two 
coordinates and also within the two groups, with group 1 (cleft) having 
higher variation than group 0 (control).  I want to allow for these 
sources of variation in the model.  The other thing is that I would 
expect coordinate positions within an individual to be correlated so I 
also want to allow for this.  The model, therefore, would be (for 
coordinate r=1,2 measured on individual i at time t, group_i an 
indicator variable taking value one for group 1 and zero otherwise):

y_{ir}(t) = \beta_{0r} + \beta_{1r} group_i + \beta_{2r} t + \beta_{3r} 
group_i : t  + b_{ir0} + group_i * b_{ir1} + \epsilon_{ir}(t),

where \epsilon_{ir}(t) ~ N(0, \sigma2) and the random effect b_{irp} ~ 
N(0, \sigma_{rp}2), for p=0,1.   I think the following code is 
appropriate (model 1):

lmer2(y~-1+coord1+coord2+coord1:(time+group+time:group)+coord2:(time+group+time:group) 
+ (0+coord1+coord2+coord1:group+coord2:group|ID), data=simdata)

where coord1 and coord2 are indicator variables for coordinates 1 and 2, 
respectively, time is continuous and group is an indicator variable 
taking value one for the cleft group and zero for the controls.  Does 
the random effects part make sense?  I'm especially unsure about 
allowing correlations between all of the random effects terms, although 
I think that's it's appropriate under this parameterisation because each 
person has a value for both coordinates 1 and 2, and the group effect is 
additional. 


An alternative parameterisation is (model 2):

lmer2(y~-1+coord1+coord2+coord1:(time+group+time:group)+coord2:(time+group+time:group) 
+ (0+gp0:coord1+gp0:coord2|ID)+(0+coord1:group+coord2:group|ID), 
data=simdata),

where gp0 is an indicator variable taking value one if the individual is 
in group 0 and zero otherwise.  It seems to me that this should be 
equivalent to model 1, but it doesn't appear to be (perhaps this just 
comes down to fewer correlations estimated in model 2).

If a correlation between random effects is estimated to be 1 or -1, is 
this generally because the model is over-parameterised?

Reproducible code is below.

set.seed(100)
n.subj <- 200
n.times <- 3
n.coords <- 2
simdata <- data.frame(coord1=c(rep(1,n.subj*n.times), 
rep(0,n.subj*n.times)))
simdata$coord2 <- c(rep(0,n.subj*n.times), rep(1,n.subj*n.times))
simdata$coord <- ifelse(simdata$coord1==1, 1, 2)
simdata$ID <- rep(rep(1:n.subj, each=n.times),2)
simdata$time <- rep(1:n.times, n.subj*n.coords)
simdata$group <- rep(c(1,0,1,0), each=n.subj*n.times/2)
simdata$gp0 <- 1-simdata$group
simdata$y <- rep(NA, dim(simdata)[1])
randeff <- c(rep(rnorm(n.subj/2, 0, 15),each=n.times), 
rep(rnorm(n.subj/2, 0, 10), each=n.times), rep(rnorm(n.subj/2, 0, 25), 
each=n.times), rep(rnorm(n.subj/2, 0, 20), each=3))
for (i in 1:dim(simdata)[1]) simdata$y[i] <- rnorm(1, 
randeff[i]+simdata$time[i]+simdata$coord[i]+10*simdata$group[i], 16)

lmer2(y~-1+coord1+coord2+coord1:(time+group+time:group)+coord2:(time+group+time:group) 
+ (0+coord1+coord2+coord1:group+coord2:group|ID), data=simdata)
lmer2(y~-1+coord1+coord2+coord1:(time+group+time:group)+coord2:(time+group+time:group) 
+ (0+gp0:coord1+gp0:coord2|ID)+(0+coord1:group+coord2:group|ID), 
data=simdata),

Many thanks for any help.

Best regards,
Sarah

-- 
Sarah Barry, MSc
Department of Statistics
University of Glasgow
Tel: +44 (0)141 330 2474
Fax: +44 (0)141 330 4814
www.stats.gla.ac.uk/~sarah



From dafshartous at med.miami.edu  Mon Sep 24 22:32:32 2007
From: dafshartous at med.miami.edu (David Afshartous)
Date: Mon, 24 Sep 2007 16:32:32 -0400
Subject: [R-sig-ME] Different random effects variances for outcomes and
 groups
In-Reply-To: <46F115D3.1090002@stats.gla.ac.uk>
Message-ID: <C31D9720.130A%dafshartous@med.miami.edu>


Hi Sarah,

Did you receive any replies to your post?  Some comments below, perhaps
tangential to you main question but possibly of interest.

First let me make sure I understand you data structure.  You have 100
children in each of 2 groups, and for each child you take 3 measurements at
coordinate 1 and coordinate 2.
Hence there are 100 x 2 x 3 x 3 = 1200 observations.  Moreover, the children
in the two groups are different children, hence the different IDs in the
data (as opposed to the same children being in both groups e.g. when each
child receives both treatment and placebo; this affects the number of random
effects).

In your model equation:
> y_{ir}(t) = \beta_{0r} + \beta_{1r} group_i + \beta_{2r} t + \beta_{3r}
> group_i : t  + b_{ir0} + group_i * b_{ir1} + \epsilon_{ir}(t),
> 

You have a random intercept model, where the intercept is broken down
according to fixed effects for coordinate and group, and similarly for the
slope.  I assume you want the random effect for the intercept stratified
according to both group and coordinate.  I'm not sure how the terms above
reflect this; perhaps all you need is the term b_{irp} ~ > N(0,
\sigma_{rp}2), for p=0,1; r = 1,2.

RE your simulation code to generate the random effects, I assume you have
broken "randeff" into blocks of 300 ( = 1200/4) because the group x
coordinate stratification yields 4 distinct combinations.
However, I have a question RE the way in which these random effects are
simulated.  For instance, consider patient 1 in group 1.  According to your
simulation code, two separate random normals will be generated to reflect
the random effect of this patient at coordinate 1 and coordinate 2, with
random normal variance equal to the sum of the group random effect variance
and the coordinate random effect variance.  However, I don't think this
reflects the nesting appropriately.  Perhaps the group component should only
be generated once as it is the same child in the same group; and the
coordinate component is the part that needs to be generated twice. This of
course will increase the correlation between the two realized values.
(BTW, did you chose the standard deviations values of 15, 10, 25, and 20 to
reflect the aforementioned sub-component structure, and if so what were the
standard deviations of the sub-components?).

With respect to random effects, I assume your model will generate 400 unique
random effects estimates, i.e., two (for each coordinate) for each of the
200 children.  And each of these may be viewed as the sum of the
sub-components of coordinate and group.  Running your first lmer2 model
statement yields a 200 x 4 matrix for the estimated random effects, w/ each
row being a patient and the columns corresponding apparently to the
aforementioned subcomponents:

An object of class ?ranef.lmer?
[[1]]
           coord1       coord2  coord1:group coord2:group
1    -0.502182860   7.98888012  -4.590717867    5.6973871
2    -0.190673717   3.38674017  -1.849503513    2.4098210
3    -0.981561080  12.80952815  -8.127985669    9.1788197
Etc

However, I would think some of these cells need to be 0, e.g., each patient
is only in 1 group and thus shouldn't have a random effect estimate from
both groups?  Or am I reading the table completely wrong?

Now, when I ran your second lmer2 model statement and checked the estimated
random effects (too messy to copy here), I got two lists of 2 random effects
per child (1 for each coordinate), where it appears that the two lists
correspond to the two groups, and apparently there are 0's for children that
were not in the respective group. Based on the estimated random effects
produced by the two model statements, I think that the second more
representative of what you're trying to do.  Have a look at the random
effects for the second model statement and let me know if you agree.

Cheers,
David






On 9/19/07 8:28 AM, "Sarah Barry" <sarah at stats.gla.ac.uk> wrote:

> Dear all,
> 
> I wonder if someone could give me some insight on coding lmer.  I have
> facial shape data on children in two groups at four time points (3,6,12
> and 24 months).  Each child has a set of coordinate positions measured
> on their face at each time point (the set of coordinates is the same
> across individuals and times).  Take coordinates 1 and 2 only for now
> (reproducible code at the bottom of this email for simulated data).
> 
> If I plot the trends for coordinates 1 and 2 for each individual over
> time, there is a different amount of variance amongst the individuals
> (at least in the intercept, and maybe in the slope) for the two
> coordinates and also within the two groups, with group 1 (cleft) having
> higher variation than group 0 (control).  I want to allow for these
> sources of variation in the model.  The other thing is that I would
> expect coordinate positions within an individual to be correlated so I
> also want to allow for this.  The model, therefore, would be (for
> coordinate r=1,2 measured on individual i at time t, group_i an
> indicator variable taking value one for group 1 and zero otherwise):
> 
> y_{ir}(t) = \beta_{0r} + \beta_{1r} group_i + \beta_{2r} t + \beta_{3r}
> group_i : t  + b_{ir0} + group_i * b_{ir1} + \epsilon_{ir}(t),
> 
> where \epsilon_{ir}(t) ~ N(0, \sigma2) and the random effect b_{irp} ~
> N(0, \sigma_{rp}2), for p=0,1.   I think the following code is
> appropriate (model 1):
> 
> lmer2(y~-1+coord1+coord2+coord1:(time+group+time:group)+coord2:(time+group+tim
> e:group) 
> + (0+coord1+coord2+coord1:group+coord2:group|ID), data=simdata)
> 
> where coord1 and coord2 are indicator variables for coordinates 1 and 2,
> respectively, time is continuous and group is an indicator variable
> taking value one for the cleft group and zero for the controls.  Does
> the random effects part make sense?  I'm especially unsure about
> allowing correlations between all of the random effects terms, although
> I think that's it's appropriate under this parameterisation because each
> person has a value for both coordinates 1 and 2, and the group effect is
> additional. 
> 
> 
> An alternative parameterisation is (model 2):
> 
> lmer2(y~-1+coord1+coord2+coord1:(time+group+time:group)+coord2:(time+group+tim
> e:group) 
> + (0+gp0:coord1+gp0:coord2|ID)+(0+coord1:group+coord2:group|ID),
> data=simdata),
> 
> where gp0 is an indicator variable taking value one if the individual is
> in group 0 and zero otherwise.  It seems to me that this should be
> equivalent to model 1, but it doesn't appear to be (perhaps this just
> comes down to fewer correlations estimated in model 2).
> 
> If a correlation between random effects is estimated to be 1 or -1, is
> this generally because the model is over-parameterised?
> 
> Reproducible code is below.
> 
> set.seed(100)
> n.subj <- 200
> n.times <- 3
> n.coords <- 2
> simdata <- data.frame(coord1=c(rep(1,n.subj*n.times),
> rep(0,n.subj*n.times)))
> simdata$coord2 <- c(rep(0,n.subj*n.times), rep(1,n.subj*n.times))
> simdata$coord <- ifelse(simdata$coord1==1, 1, 2)
> simdata$ID <- rep(rep(1:n.subj, each=n.times),2)
> simdata$time <- rep(1:n.times, n.subj*n.coords)
> simdata$group <- rep(c(1,0,1,0), each=n.subj*n.times/2)
> simdata$gp0 <- 1-simdata$group
> simdata$y <- rep(NA, dim(simdata)[1])
> randeff <- c(rep(rnorm(n.subj/2, 0, 15),each=n.times),
> rep(rnorm(n.subj/2, 0, 10), each=n.times), rep(rnorm(n.subj/2, 0, 25),
> each=n.times), rep(rnorm(n.subj/2, 0, 20), each=3))
> for (i in 1:dim(simdata)[1]) simdata$y[i] <- rnorm(1,
> randeff[i]+simdata$time[i]+simdata$coord[i]+10*simdata$group[i], 16)
> 
> lmer2(y~-1+coord1+coord2+coord1:(time+group+time:group)+coord2:(time+group+tim
> e:group) 
> + (0+coord1+coord2+coord1:group+coord2:group|ID), data=simdata)
> lmer2(y~-1+coord1+coord2+coord1:(time+group+time:group)+coord2:(time+group+tim
> e:group) 
> + (0+gp0:coord1+gp0:coord2|ID)+(0+coord1:group+coord2:group|ID),
> data=simdata),
> 
> Many thanks for any help.
> 
> Best regards,
> Sarah



From sarah at stats.gla.ac.uk  Tue Sep 25 15:05:15 2007
From: sarah at stats.gla.ac.uk (Sarah Barry)
Date: Tue, 25 Sep 2007 14:05:15 +0100
Subject: [R-sig-ME] Different random effects variances for outcomes and
 groups
In-Reply-To: <C31D9720.130A%dafshartous@med.miami.edu>
References: <C31D9720.130A%dafshartous@med.miami.edu>
Message-ID: <46F9078B.2000802@stats.gla.ac.uk>

Hi David,

Thanks for your reply.  I comment on your various questions below.

David Afshartous wrote:

>Hi Sarah,
>
>Did you receive any replies to your post?  Some comments below, perhaps
>tangential to you main question but possibly of interest.
>
>First let me make sure I understand you data structure.  You have 100
>children in each of 2 groups, and for each child you take 3 measurements at
>coordinate 1 and coordinate 2.
>Hence there are 100 x 2 x 3 x 3 = 1200 observations.  Moreover, the children
>in the two groups are different children, hence the different IDs in the
>data (as opposed to the same children being in both groups e.g. when each
>child receives both treatment and placebo; this affects the number of random
>effects).
>
>  
>
Yes, you are right here (apart from a typo - there are 100 x 2 x 3 x 2 = 
1200 observations).  The groups do contain different children.

>In your model equation:
>  
>
>>y_{ir}(t) = \beta_{0r} + \beta_{1r} group_i + \beta_{2r} t + \beta_{3r}
>>group_i : t  + b_{ir0} + group_i * b_{ir1} + \epsilon_{ir}(t),
>>
>>    
>>
>
>You have a random intercept model, where the intercept is broken down
>according to fixed effects for coordinate and group, and similarly for the
>slope.  I assume you want the random effect for the intercept stratified
>according to both group and coordinate.  I'm not sure how the terms above
>reflect this; perhaps all you need is the term b_{irp} ~ > N(0,
>\sigma_{rp}2), for p=0,1; r = 1,2.
>
>  
>
I think you're right here and this corresponds with what you say below.  
I think my model should be instead written as

y_{ir}(t) = \beta_{0r} + \beta_{1r} group_i + \beta_{2r} t + \beta_{3r}
group_i : t  + group_i * b_{irp} + \epsilon_{ir}(t),

where p=0,1 represents the value of 'group_i' and is distributed as you 
suggest.  This seems to make more sense than everyone having a random 
intercept from one distribution and group 1 having an additional one.  
This way they are completely separate.

>RE your simulation code to generate the random effects, I assume you have
>broken "randeff" into blocks of 300 ( = 1200/4) because the group x
>coordinate stratification yields 4 distinct combinations.
>However, I have a question RE the way in which these random effects are
>simulated.  For instance, consider patient 1 in group 1.  According to your
>simulation code, two separate random normals will be generated to reflect
>the random effect of this patient at coordinate 1 and coordinate 2, with
>random normal variance equal to the sum of the group random effect variance
>and the coordinate random effect variance.  However, I don't think this
>reflects the nesting appropriately.  Perhaps the group component should only
>be generated once as it is the same child in the same group; and the
>coordinate component is the part that needs to be generated twice. This of
>course will increase the correlation between the two realized values.
>(BTW, did you chose the standard deviations values of 15, 10, 25, and 20 to
>reflect the aforementioned sub-component structure, and if so what were the
>standard deviations of the sub-components?).
>
>  
>
Yes, I should have considered this more carefully.  Certainly the random 
effects for coordinates 1 and 2 for a particular individual should have 
been simulated from a multivariate normal distribution rather than from 
two separate normals.  I don't think that there is so much a group 
component and a coordinate component, as a coordinate component that 
differs depending on which group the individual comes from.  So, for 
example, instead of the randeff statement below we could have (repeated 
across times and inserted in the correct positions for each group):

randeff.gp0 <- mvrnorm(n.subj/2, c(0,0), matrix(c(100,50,50,400), 
nc=2))  # coordinates 1 and 2 (respectively) for individuals in group 0 #
randeff.gp1 <- mvrnorm(n.subj/2, c(0,0), matrix(c(225,70,70,625), 
nc=2))  # coordinates 1 and 2 (respectively) for individuals in group 1 #

I think the group itself should only be a fixed effect because, while 
individuals are randomly sampled from two populations of cleft-lip 
patients and healthy controls, the groups are fixed (not sampled from a 
population of groups).  What do you think?  This has been one point that 
I have wondered long and hard about.

>With respect to random effects, I assume your model will generate 400 unique
>random effects estimates, i.e., two (for each coordinate) for each of the
>200 children.  And each of these may be viewed as the sum of the
>sub-components of coordinate and group.  Running your first lmer2 model
>statement yields a 200 x 4 matrix for the estimated random effects, w/ each
>row being a patient and the columns corresponding apparently to the
>aforementioned subcomponents:
>
>An object of class ?ranef.lmer?
>[[1]]
>           coord1       coord2  coord1:group coord2:group
>1    -0.502182860   7.98888012  -4.590717867    5.6973871
>2    -0.190673717   3.38674017  -1.849503513    2.4098210
>3    -0.981561080  12.80952815  -8.127985669    9.1788197
>Etc
>
>However, I would think some of these cells need to be 0, e.g., each patient
>is only in 1 group and thus shouldn't have a random effect estimate from
>both groups?  Or am I reading the table completely wrong?
>
>Now, when I ran your second lmer2 model statement and checked the estimated
>random effects (too messy to copy here), I got two lists of 2 random effects
>per child (1 for each coordinate), where it appears that the two lists
>correspond to the two groups, and apparently there are 0's for children that
>were not in the respective group. Based on the estimated random effects
>produced by the two model statements, I think that the second more
>representative of what you're trying to do.  Have a look at the random
>effects for the second model statement and let me know if you agree.
>
>Cheers,
>David
>  
>
I do agree and I'm not sure now what model the first lmer2 model 
statement is actually fitting, because I would have expected at least 
some of the coord1:group and coord2:group random effects to be zero.  
The second lmer2 statement gives more sensible answers and corresponds 
with the rewritten model above.  Also when I check the estimated random 
effects variances and covariances against the actual values, there is 
good correspondence so I think I will proceed with this parameterisation.

Many thanks for your help,
Sarah

>
>
>
>
>On 9/19/07 8:28 AM, "Sarah Barry" <sarah at stats.gla.ac.uk> wrote:
>
>  
>
>>Dear all,
>>
>>I wonder if someone could give me some insight on coding lmer.  I have
>>facial shape data on children in two groups at four time points (3,6,12
>>and 24 months).  Each child has a set of coordinate positions measured
>>on their face at each time point (the set of coordinates is the same
>>across individuals and times).  Take coordinates 1 and 2 only for now
>>(reproducible code at the bottom of this email for simulated data).
>>
>>If I plot the trends for coordinates 1 and 2 for each individual over
>>time, there is a different amount of variance amongst the individuals
>>(at least in the intercept, and maybe in the slope) for the two
>>coordinates and also within the two groups, with group 1 (cleft) having
>>higher variation than group 0 (control).  I want to allow for these
>>sources of variation in the model.  The other thing is that I would
>>expect coordinate positions within an individual to be correlated so I
>>also want to allow for this.  The model, therefore, would be (for
>>coordinate r=1,2 measured on individual i at time t, group_i an
>>indicator variable taking value one for group 1 and zero otherwise):
>>
>>y_{ir}(t) = \beta_{0r} + \beta_{1r} group_i + \beta_{2r} t + \beta_{3r}
>>group_i : t  + b_{ir0} + group_i * b_{ir1} + \epsilon_{ir}(t),
>>
>>where \epsilon_{ir}(t) ~ N(0, \sigma2) and the random effect b_{irp} ~
>>N(0, \sigma_{rp}2), for p=0,1.   I think the following code is
>>appropriate (model 1):
>>
>>lmer2(y~-1+coord1+coord2+coord1:(time+group+time:group)+coord2:(time+group+tim
>>e:group) 
>>+ (0+coord1+coord2+coord1:group+coord2:group|ID), data=simdata)
>>
>>where coord1 and coord2 are indicator variables for coordinates 1 and 2,
>>respectively, time is continuous and group is an indicator variable
>>taking value one for the cleft group and zero for the controls.  Does
>>the random effects part make sense?  I'm especially unsure about
>>allowing correlations between all of the random effects terms, although
>>I think that's it's appropriate under this parameterisation because each
>>person has a value for both coordinates 1 and 2, and the group effect is
>>additional. 
>>
>>
>>An alternative parameterisation is (model 2):
>>
>>lmer2(y~-1+coord1+coord2+coord1:(time+group+time:group)+coord2:(time+group+tim
>>e:group) 
>>+ (0+gp0:coord1+gp0:coord2|ID)+(0+coord1:group+coord2:group|ID),
>>data=simdata),
>>
>>where gp0 is an indicator variable taking value one if the individual is
>>in group 0 and zero otherwise.  It seems to me that this should be
>>equivalent to model 1, but it doesn't appear to be (perhaps this just
>>comes down to fewer correlations estimated in model 2).
>>
>>If a correlation between random effects is estimated to be 1 or -1, is
>>this generally because the model is over-parameterised?
>>
>>Reproducible code is below.
>>
>>set.seed(100)
>>n.subj <- 200
>>n.times <- 3
>>n.coords <- 2
>>simdata <- data.frame(coord1=c(rep(1,n.subj*n.times),
>>rep(0,n.subj*n.times)))
>>simdata$coord2 <- c(rep(0,n.subj*n.times), rep(1,n.subj*n.times))
>>simdata$coord <- ifelse(simdata$coord1==1, 1, 2)
>>simdata$ID <- rep(rep(1:n.subj, each=n.times),2)
>>simdata$time <- rep(1:n.times, n.subj*n.coords)
>>simdata$group <- rep(c(1,0,1,0), each=n.subj*n.times/2)
>>simdata$gp0 <- 1-simdata$group
>>simdata$y <- rep(NA, dim(simdata)[1])
>>randeff <- c(rep(rnorm(n.subj/2, 0, 15),each=n.times),
>>rep(rnorm(n.subj/2, 0, 10), each=n.times), rep(rnorm(n.subj/2, 0, 25),
>>each=n.times), rep(rnorm(n.subj/2, 0, 20), each=3))
>>for (i in 1:dim(simdata)[1]) simdata$y[i] <- rnorm(1,
>>randeff[i]+simdata$time[i]+simdata$coord[i]+10*simdata$group[i], 16)
>>
>>lmer2(y~-1+coord1+coord2+coord1:(time+group+time:group)+coord2:(time+group+tim
>>e:group) 
>>+ (0+coord1+coord2+coord1:group+coord2:group|ID), data=simdata)
>>lmer2(y~-1+coord1+coord2+coord1:(time+group+time:group)+coord2:(time+group+tim
>>e:group) 
>>+ (0+gp0:coord1+gp0:coord2|ID)+(0+coord1:group+coord2:group|ID),
>>data=simdata),
>>
>>Many thanks for any help.
>>
>>Best regards,
>>Sarah
>>    
>>
>
>  
>

-- 
Sarah Barry, MSc
Department of Statistics
University of Glasgow
Tel: +44 (0)141 330 2474
Fax: +44 (0)141 330 4814
www.stats.gla.ac.uk/~sarah



From dafshartous at med.miami.edu  Tue Sep 25 16:03:44 2007
From: dafshartous at med.miami.edu (David Afshartous)
Date: Tue, 25 Sep 2007 10:03:44 -0400
Subject: [R-sig-ME] Different random effects variances for outcomes and
 groups
In-Reply-To: <46F9078B.2000802@stats.gla.ac.uk>
Message-ID: <C31E8D80.1324%dafshartous@med.miami.edu>

Hi Sarah,
A few comments below.
David


On 9/25/07 9:05 AM, "Sarah Barry" <sarah at stats.gla.ac.uk> wrote:

> Hi David,
> 
> Thanks for your reply.  I comment on your various questions below.
> 
> David Afshartous wrote:
> 
>> Hi Sarah,
>> 
>> Did you receive any replies to your post?  Some comments below, perhaps
>> tangential to you main question but possibly of interest.
>> 
>> First let me make sure I understand you data structure.  You have 100
>> children in each of 2 groups, and for each child you take 3 measurements at
>> coordinate 1 and coordinate 2.
>> Hence there are 100 x 2 x 3 x 3 = 1200 observations.  Moreover, the children
>> in the two groups are different children, hence the different IDs in the
>> data (as opposed to the same children being in both groups e.g. when each
>> child receives both treatment and placebo; this affects the number of random
>> effects).
>> 
>>  
>> 
> Yes, you are right here (apart from a typo - there are 100 x 2 x 3 x 2 =
> 1200 observations).  The groups do contain different children.
> 
>> In your model equation:
>>  
>> 
>>> y_{ir}(t) = \beta_{0r} + \beta_{1r} group_i + \beta_{2r} t + \beta_{3r}
>>> group_i : t  + b_{ir0} + group_i * b_{ir1} + \epsilon_{ir}(t),
>>> 
>>>    
>>> 
>> 
>> You have a random intercept model, where the intercept is broken down
>> according to fixed effects for coordinate and group, and similarly for the
>> slope.  I assume you want the random effect for the intercept stratified
>> according to both group and coordinate.  I'm not sure how the terms above
>> reflect this; perhaps all you need is the term b_{irp} ~ > N(0,
>> \sigma_{rp}2), for p=0,1; r = 1,2.
>> 
>>  
>> 
> I think you're right here and this corresponds with what you say below.
> I think my model should be instead written as
> 
> y_{ir}(t) = \beta_{0r} + \beta_{1r} group_i + \beta_{2r} t + \beta_{3r}
> group_i : t  + group_i * b_{irp} + \epsilon_{ir}(t),
> 
> where p=0,1 represents the value of 'group_i' and is distributed as you
> suggest.  This seems to make more sense than everyone having a random
> intercept from one distribution and group 1 having an additional one.
> This way they are completely separate.
> 
>> RE your simulation code to generate the random effects, I assume you have
>> broken "randeff" into blocks of 300 ( = 1200/4) because the group x
>> coordinate stratification yields 4 distinct combinations.
>> However, I have a question RE the way in which these random effects are
>> simulated.  For instance, consider patient 1 in group 1.  According to your
>> simulation code, two separate random normals will be generated to reflect
>> the random effect of this patient at coordinate 1 and coordinate 2, with
>> random normal variance equal to the sum of the group random effect variance
>> and the coordinate random effect variance.  However, I don't think this
>> reflects the nesting appropriately.  Perhaps the group component should only
>> be generated once as it is the same child in the same group; and the
>> coordinate component is the part that needs to be generated twice. This of
>> course will increase the correlation between the two realized values.
>> (BTW, did you chose the standard deviations values of 15, 10, 25, and 20 to
>> reflect the aforementioned sub-component structure, and if so what were the
>> standard deviations of the sub-components?).
>> 
>>  
>> 
> Yes, I should have considered this more carefully.  Certainly the random
> effects for coordinates 1 and 2 for a particular individual should have
> been simulated from a multivariate normal distribution rather than from
> two separate normals.  I don't think that there is so much a group
> component and a coordinate component, as a coordinate component that
> differs depending on which group the individual comes from.  So, for
> example, instead of the randeff statement below we could have (repeated
> across times and inserted in the correct positions for each group):
> 
> randeff.gp0 <- mvrnorm(n.subj/2, c(0,0), matrix(c(100,50,50,400),
> nc=2))  # coordinates 1 and 2 (respectively) for individuals in group 0 #
> randeff.gp1 <- mvrnorm(n.subj/2, c(0,0), matrix(c(225,70,70,625),
> nc=2))  # coordinates 1 and 2 (respectively) for individuals in group 1 #
> 
> I think the group itself should only be a fixed effect because, while
> individuals are randomly sampled from two populations of cleft-lip
> patients and healthy controls, the groups are fixed (not sampled from a
> population of groups).  What do you think?  This has been one point that
> I have wondered long and hard about.
> 

I agree that group should be a fixed effect based on your description. In
your current model, group is a fixed effect, and the random effect on the
intercept is for child ID, although this depends on both the group and
coordinate for the child.  You do not have a random effect for group per se.
This can be contrasted w/ instead employing separate random effects for the
nesting levels (Pinheiro & Bates p.40 is a good example of a nesting
structure where random effects are used for each level of the nesting.)  It
would be interesting to observe the difference in the results.


>> With respect to random effects, I assume your model will generate 400 unique
>> random effects estimates, i.e., two (for each coordinate) for each of the
>> 200 children.  And each of these may be viewed as the sum of the
>> sub-components of coordinate and group.  Running your first lmer2 model
>> statement yields a 200 x 4 matrix for the estimated random effects, w/ each
>> row being a patient and the columns corresponding apparently to the
>> aforementioned subcomponents:
>> 
>> An object of class ?ranef.lmer?
>> [[1]]
>>           coord1       coord2  coord1:group coord2:group
>> 1    -0.502182860   7.98888012  -4.590717867    5.6973871
>> 2    -0.190673717   3.38674017  -1.849503513    2.4098210
>> 3    -0.981561080  12.80952815  -8.127985669    9.1788197
>> Etc
>> 
>> However, I would think some of these cells need to be 0, e.g., each patient
>> is only in 1 group and thus shouldn't have a random effect estimate from
>> both groups?  Or am I reading the table completely wrong?
>> 
>> Now, when I ran your second lmer2 model statement and checked the estimated
>> random effects (too messy to copy here), I got two lists of 2 random effects
>> per child (1 for each coordinate), where it appears that the two lists
>> correspond to the two groups, and apparently there are 0's for children that
>> were not in the respective group. Based on the estimated random effects
>> produced by the two model statements, I think that the second more
>> representative of what you're trying to do.  Have a look at the random
>> effects for the second model statement and let me know if you agree.
>> 
>> Cheers,
>> David
>>  
>> 
> I do agree and I'm not sure now what model the first lmer2 model
> statement is actually fitting, because I would have expected at least
> some of the coord1:group and coord2:group random effects to be zero.
> The second lmer2 statement gives more sensible answers and corresponds
> with the rewritten model above.  Also when I check the estimated random
> effects variances and covariances against the actual values, there is
> good correspondence so I think I will proceed with this parameterisation.
> 
> Many thanks for your help,
> Sarah
> 
>> 
>> 
>> 
>> 
>> On 9/19/07 8:28 AM, "Sarah Barry" <sarah at stats.gla.ac.uk> wrote:
>> 
>>  
>> 
>>> Dear all,
>>> 
>>> I wonder if someone could give me some insight on coding lmer.  I have
>>> facial shape data on children in two groups at four time points (3,6,12
>>> and 24 months).  Each child has a set of coordinate positions measured
>>> on their face at each time point (the set of coordinates is the same
>>> across individuals and times).  Take coordinates 1 and 2 only for now
>>> (reproducible code at the bottom of this email for simulated data).
>>> 
>>> If I plot the trends for coordinates 1 and 2 for each individual over
>>> time, there is a different amount of variance amongst the individuals
>>> (at least in the intercept, and maybe in the slope) for the two
>>> coordinates and also within the two groups, with group 1 (cleft) having
>>> higher variation than group 0 (control).  I want to allow for these
>>> sources of variation in the model.  The other thing is that I would
>>> expect coordinate positions within an individual to be correlated so I
>>> also want to allow for this.  The model, therefore, would be (for
>>> coordinate r=1,2 measured on individual i at time t, group_i an
>>> indicator variable taking value one for group 1 and zero otherwise):
>>> 
>>> y_{ir}(t) = \beta_{0r} + \beta_{1r} group_i + \beta_{2r} t + \beta_{3r}
>>> group_i : t  + b_{ir0} + group_i * b_{ir1} + \epsilon_{ir}(t),
>>> 
>>> where \epsilon_{ir}(t) ~ N(0, \sigma2) and the random effect b_{irp} ~
>>> N(0, \sigma_{rp}2), for p=0,1.   I think the following code is
>>> appropriate (model 1):
>>> 
>>> lmer2(y~-1+coord1+coord2+coord1:(time+group+time:group)+coord2:(time+group+t
>>> im
>>> e:group) 
>>> + (0+coord1+coord2+coord1:group+coord2:group|ID), data=simdata)
>>> 
>>> where coord1 and coord2 are indicator variables for coordinates 1 and 2,
>>> respectively, time is continuous and group is an indicator variable
>>> taking value one for the cleft group and zero for the controls.  Does
>>> the random effects part make sense?  I'm especially unsure about
>>> allowing correlations between all of the random effects terms, although
>>> I think that's it's appropriate under this parameterisation because each
>>> person has a value for both coordinates 1 and 2, and the group effect is
>>> additional. 
>>> 
>>> 
>>> An alternative parameterisation is (model 2):
>>> 
>>> lmer2(y~-1+coord1+coord2+coord1:(time+group+time:group)+coord2:(time+group+t
>>> im
>>> e:group) 
>>> + (0+gp0:coord1+gp0:coord2|ID)+(0+coord1:group+coord2:group|ID),
>>> data=simdata),
>>> 
>>> where gp0 is an indicator variable taking value one if the individual is
>>> in group 0 and zero otherwise.  It seems to me that this should be
>>> equivalent to model 1, but it doesn't appear to be (perhaps this just
>>> comes down to fewer correlations estimated in model 2).
>>> 
>>> If a correlation between random effects is estimated to be 1 or -1, is
>>> this generally because the model is over-parameterised?
>>> 
>>> Reproducible code is below.
>>> 
>>> set.seed(100)
>>> n.subj <- 200
>>> n.times <- 3
>>> n.coords <- 2
>>> simdata <- data.frame(coord1=c(rep(1,n.subj*n.times),
>>> rep(0,n.subj*n.times)))
>>> simdata$coord2 <- c(rep(0,n.subj*n.times), rep(1,n.subj*n.times))
>>> simdata$coord <- ifelse(simdata$coord1==1, 1, 2)
>>> simdata$ID <- rep(rep(1:n.subj, each=n.times),2)
>>> simdata$time <- rep(1:n.times, n.subj*n.coords)
>>> simdata$group <- rep(c(1,0,1,0), each=n.subj*n.times/2)
>>> simdata$gp0 <- 1-simdata$group
>>> simdata$y <- rep(NA, dim(simdata)[1])
>>> randeff <- c(rep(rnorm(n.subj/2, 0, 15),each=n.times),
>>> rep(rnorm(n.subj/2, 0, 10), each=n.times), rep(rnorm(n.subj/2, 0, 25),
>>> each=n.times), rep(rnorm(n.subj/2, 0, 20), each=3))
>>> for (i in 1:dim(simdata)[1]) simdata$y[i] <- rnorm(1,
>>> randeff[i]+simdata$time[i]+simdata$coord[i]+10*simdata$group[i], 16)
>>> 
>>> lmer2(y~-1+coord1+coord2+coord1:(time+group+time:group)+coord2:(time+group+t
>>> im
>>> e:group) 
>>> + (0+coord1+coord2+coord1:group+coord2:group|ID), data=simdata)
>>> lmer2(y~-1+coord1+coord2+coord1:(time+group+time:group)+coord2:(time+group+t
>>> im
>>> e:group) 
>>> + (0+gp0:coord1+gp0:coord2|ID)+(0+coord1:group+coord2:group|ID),
>>> data=simdata),
>>> 
>>> Many thanks for any help.
>>> 
>>> Best regards,
>>> Sarah
>>>    
>>> 
>> 
>>  
>> 



From dafshartous at med.miami.edu  Tue Sep 25 18:17:57 2007
From: dafshartous at med.miami.edu (David Afshartous)
Date: Tue, 25 Sep 2007 12:17:57 -0400
Subject: [R-sig-ME] Different random effects variances for outcomes and
 groups
In-Reply-To: <C31E8D80.1324%dafshartous@med.miami.edu>
Message-ID: <C31EACF5.132F%dafshartous@med.miami.edu>


One additional comment below ...


On 9/25/07 10:03 AM, "David Afshartous" <dafshartous at med.miami.edu> wrote:

> Hi Sarah,
> A few comments below.
> David
> 
> 
> On 9/25/07 9:05 AM, "Sarah Barry" <sarah at stats.gla.ac.uk> wrote:
> 
>> Hi David,
>> 
>> Thanks for your reply.  I comment on your various questions below.
>> 
>> David Afshartous wrote:
>> 
>>> Hi Sarah,
>>> 
>>> Did you receive any replies to your post?  Some comments below, perhaps
>>> tangential to you main question but possibly of interest.
>>> 
>>> First let me make sure I understand you data structure.  You have 100
>>> children in each of 2 groups, and for each child you take 3 measurements at
>>> coordinate 1 and coordinate 2.
>>> Hence there are 100 x 2 x 3 x 3 = 1200 observations.  Moreover, the children
>>> in the two groups are different children, hence the different IDs in the
>>> data (as opposed to the same children being in both groups e.g. when each
>>> child receives both treatment and placebo; this affects the number of random
>>> effects).
>>> 
>>>  
>>> 
>> Yes, you are right here (apart from a typo - there are 100 x 2 x 3 x 2 =
>> 1200 observations).  The groups do contain different children.
>> 
>>> In your model equation:
>>>  
>>> 
>>>> y_{ir}(t) = \beta_{0r} + \beta_{1r} group_i + \beta_{2r} t + \beta_{3r}
>>>> group_i : t  + b_{ir0} + group_i * b_{ir1} + \epsilon_{ir}(t),
>>>> 
>>>>    
>>>> 
>>> 
>>> You have a random intercept model, where the intercept is broken down
>>> according to fixed effects for coordinate and group, and similarly for the
>>> slope.  I assume you want the random effect for the intercept stratified
>>> according to both group and coordinate.  I'm not sure how the terms above
>>> reflect this; perhaps all you need is the term b_{irp} ~ > N(0,
>>> \sigma_{rp}2), for p=0,1; r = 1,2.
>>> 
>>>  
>>> 
>> I think you're right here and this corresponds with what you say below.
>> I think my model should be instead written as
>> 
>> y_{ir}(t) = \beta_{0r} + \beta_{1r} group_i + \beta_{2r} t + \beta_{3r}
>> group_i : t  + group_i * b_{irp} + \epsilon_{ir}(t),
>> 
>> where p=0,1 represents the value of 'group_i' and is distributed as you
>> suggest.  This seems to make more sense than everyone having a random
>> intercept from one distribution and group 1 having an additional one.
>> This way they are completely separate.
>> 
>>> RE your simulation code to generate the random effects, I assume you have
>>> broken "randeff" into blocks of 300 ( = 1200/4) because the group x
>>> coordinate stratification yields 4 distinct combinations.
>>> However, I have a question RE the way in which these random effects are
>>> simulated.  For instance, consider patient 1 in group 1.  According to your
>>> simulation code, two separate random normals will be generated to reflect
>>> the random effect of this patient at coordinate 1 and coordinate 2, with
>>> random normal variance equal to the sum of the group random effect variance
>>> and the coordinate random effect variance.  However, I don't think this
>>> reflects the nesting appropriately.  Perhaps the group component should only
>>> be generated once as it is the same child in the same group; and the
>>> coordinate component is the part that needs to be generated twice. This of
>>> course will increase the correlation between the two realized values.
>>> (BTW, did you chose the standard deviations values of 15, 10, 25, and 20 to
>>> reflect the aforementioned sub-component structure, and if so what were the
>>> standard deviations of the sub-components?).
>>> 
>>>  
>>> 
>> Yes, I should have considered this more carefully.  Certainly the random
>> effects for coordinates 1 and 2 for a particular individual should have
>> been simulated from a multivariate normal distribution rather than from
>> two separate normals.  I don't think that there is so much a group
>> component and a coordinate component, as a coordinate component that
>> differs depending on which group the individual comes from.  So, for
>> example, instead of the randeff statement below we could have (repeated
>> across times and inserted in the correct positions for each group):
>> 
>> randeff.gp0 <- mvrnorm(n.subj/2, c(0,0), matrix(c(100,50,50,400),
>> nc=2))  # coordinates 1 and 2 (respectively) for individuals in group 0 #
>> randeff.gp1 <- mvrnorm(n.subj/2, c(0,0), matrix(c(225,70,70,625),
>> nc=2))  # coordinates 1 and 2 (respectively) for individuals in group 1 #
>> 
>> I think the group itself should only be a fixed effect because, while
>> individuals are randomly sampled from two populations of cleft-lip
>> patients and healthy controls, the groups are fixed (not sampled from a
>> population of groups).  What do you think?  This has been one point that
>> I have wondered long and hard about.
>> 
> 
> I agree that group should be a fixed effect based on your description. In
> your current model, group is a fixed effect, and the random effect on the
> intercept is for child ID, although this depends on both the group and
> coordinate for the child.  You do not have a random effect for group per se.
> This can be contrasted w/ instead employing separate random effects for the
> nesting levels (Pinheiro & Bates p.40 is a good example of a nesting
> structure where random effects are used for each level of the nesting.)  It
> would be interesting to observe the difference in the results.
> 

Moreover, allowing a random effect for group is definitely not what you want
as this would not model the differential variability in your data.  Each
child would have a single group random effect (distributed the same for each
group), and there would be a child random effect that depends on the
coordinate, but they would not be distributed differently across the groups
(you would get 1 list instead of two lists for the random effects in your
second model statement).  Having said that, I estimated both cases for some
simple repeated measures data that has a treatment factor.  Specifically:
1) Stratified RE variance: fixed effects for treatment, RE for each subject,
stratified per treatment group.
2) RE for treatment group: fixed effects for treatment, RE for each subject
(not stratified per treatment), plus RE for treatment group.
Although I really don't want option 2), I was curious about the differences
in model fit.  Both models were extremely similar for AIC/BIC/LogLik, which
is surprising since 2) doesn't model at all the differential growth curve
variability per treatment in my data. I didn't try this comparison for your
data as I was unsure of how to modify your lmer2 statement (perhaps mine was
much simpler due to the single factor of treatment). If you are able to do
the appropriate modification I'd be interested in the results.

> 
>>> With respect to random effects, I assume your model will generate 400 unique
>>> random effects estimates, i.e., two (for each coordinate) for each of the
>>> 200 children.  And each of these may be viewed as the sum of the
>>> sub-components of coordinate and group.  Running your first lmer2 model
>>> statement yields a 200 x 4 matrix for the estimated random effects, w/ each
>>> row being a patient and the columns corresponding apparently to the
>>> aforementioned subcomponents:
>>> 
>>> An object of class ?ranef.lmer?
>>> [[1]]
>>>           coord1       coord2  coord1:group coord2:group
>>> 1    -0.502182860   7.98888012  -4.590717867    5.6973871
>>> 2    -0.190673717   3.38674017  -1.849503513    2.4098210
>>> 3    -0.981561080  12.80952815  -8.127985669    9.1788197
>>> Etc
>>> 
>>> However, I would think some of these cells need to be 0, e.g., each patient
>>> is only in 1 group and thus shouldn't have a random effect estimate from
>>> both groups?  Or am I reading the table completely wrong?
>>> 
>>> Now, when I ran your second lmer2 model statement and checked the estimated
>>> random effects (too messy to copy here), I got two lists of 2 random effects
>>> per child (1 for each coordinate), where it appears that the two lists
>>> correspond to the two groups, and apparently there are 0's for children that
>>> were not in the respective group. Based on the estimated random effects
>>> produced by the two model statements, I think that the second more
>>> representative of what you're trying to do.  Have a look at the random
>>> effects for the second model statement and let me know if you agree.
>>> 
>>> Cheers,
>>> David
>>>  
>>> 
>> I do agree and I'm not sure now what model the first lmer2 model
>> statement is actually fitting, because I would have expected at least
>> some of the coord1:group and coord2:group random effects to be zero.
>> The second lmer2 statement gives more sensible answers and corresponds
>> with the rewritten model above.  Also when I check the estimated random
>> effects variances and covariances against the actual values, there is
>> good correspondence so I think I will proceed with this parameterisation.
>> 
>> Many thanks for your help,
>> Sarah
>> 
>>> 
>>> 
>>> 
>>> 
>>> On 9/19/07 8:28 AM, "Sarah Barry" <sarah at stats.gla.ac.uk> wrote:
>>> 
>>>  
>>> 
>>>> Dear all,
>>>> 
>>>> I wonder if someone could give me some insight on coding lmer.  I have
>>>> facial shape data on children in two groups at four time points (3,6,12
>>>> and 24 months).  Each child has a set of coordinate positions measured
>>>> on their face at each time point (the set of coordinates is the same
>>>> across individuals and times).  Take coordinates 1 and 2 only for now
>>>> (reproducible code at the bottom of this email for simulated data).
>>>> 
>>>> If I plot the trends for coordinates 1 and 2 for each individual over
>>>> time, there is a different amount of variance amongst the individuals
>>>> (at least in the intercept, and maybe in the slope) for the two
>>>> coordinates and also within the two groups, with group 1 (cleft) having
>>>> higher variation than group 0 (control).  I want to allow for these
>>>> sources of variation in the model.  The other thing is that I would
>>>> expect coordinate positions within an individual to be correlated so I
>>>> also want to allow for this.  The model, therefore, would be (for
>>>> coordinate r=1,2 measured on individual i at time t, group_i an
>>>> indicator variable taking value one for group 1 and zero otherwise):
>>>> 
>>>> y_{ir}(t) = \beta_{0r} + \beta_{1r} group_i + \beta_{2r} t + \beta_{3r}
>>>> group_i : t  + b_{ir0} + group_i * b_{ir1} + \epsilon_{ir}(t),
>>>> 
>>>> where \epsilon_{ir}(t) ~ N(0, \sigma2) and the random effect b_{irp} ~
>>>> N(0, \sigma_{rp}2), for p=0,1.   I think the following code is
>>>> appropriate (model 1):
>>>> 
>>>> 
lmer2(y~-1+coord1+coord2+coord1:(time+group+time:group)+coord2:(time+group+>>>>
t
>>>> im
>>>> e:group) 
>>>> + (0+coord1+coord2+coord1:group+coord2:group|ID), data=simdata)
>>>> 
>>>> where coord1 and coord2 are indicator variables for coordinates 1 and 2,
>>>> respectively, time is continuous and group is an indicator variable
>>>> taking value one for the cleft group and zero for the controls.  Does
>>>> the random effects part make sense?  I'm especially unsure about
>>>> allowing correlations between all of the random effects terms, although
>>>> I think that's it's appropriate under this parameterisation because each
>>>> person has a value for both coordinates 1 and 2, and the group effect is
>>>> additional. 
>>>> 
>>>> 
>>>> An alternative parameterisation is (model 2):
>>>> 
>>>> 
lmer2(y~-1+coord1+coord2+coord1:(time+group+time:group)+coord2:(time+group+>>>>
t
>>>> im
>>>> e:group) 
>>>> + (0+gp0:coord1+gp0:coord2|ID)+(0+coord1:group+coord2:group|ID),
>>>> data=simdata),
>>>> 
>>>> where gp0 is an indicator variable taking value one if the individual is
>>>> in group 0 and zero otherwise.  It seems to me that this should be
>>>> equivalent to model 1, but it doesn't appear to be (perhaps this just
>>>> comes down to fewer correlations estimated in model 2).
>>>> 
>>>> If a correlation between random effects is estimated to be 1 or -1, is
>>>> this generally because the model is over-parameterised?
>>>> 
>>>> Reproducible code is below.
>>>> 
>>>> set.seed(100)
>>>> n.subj <- 200
>>>> n.times <- 3
>>>> n.coords <- 2
>>>> simdata <- data.frame(coord1=c(rep(1,n.subj*n.times),
>>>> rep(0,n.subj*n.times)))
>>>> simdata$coord2 <- c(rep(0,n.subj*n.times), rep(1,n.subj*n.times))
>>>> simdata$coord <- ifelse(simdata$coord1==1, 1, 2)
>>>> simdata$ID <- rep(rep(1:n.subj, each=n.times),2)
>>>> simdata$time <- rep(1:n.times, n.subj*n.coords)
>>>> simdata$group <- rep(c(1,0,1,0), each=n.subj*n.times/2)
>>>> simdata$gp0 <- 1-simdata$group
>>>> simdata$y <- rep(NA, dim(simdata)[1])
>>>> randeff <- c(rep(rnorm(n.subj/2, 0, 15),each=n.times),
>>>> rep(rnorm(n.subj/2, 0, 10), each=n.times), rep(rnorm(n.subj/2, 0, 25),
>>>> each=n.times), rep(rnorm(n.subj/2, 0, 20), each=3))
>>>> for (i in 1:dim(simdata)[1]) simdata$y[i] <- rnorm(1,
>>>> randeff[i]+simdata$time[i]+simdata$coord[i]+10*simdata$group[i], 16)
>>>> 
>>>> 
lmer2(y~-1+coord1+coord2+coord1:(time+group+time:group)+coord2:(time+group+>>>>
t
>>>> im
>>>> e:group) 
>>>> + (0+coord1+coord2+coord1:group+coord2:group|ID), data=simdata)
>>>> 
lmer2(y~-1+coord1+coord2+coord1:(time+group+time:group)+coord2:(time+group+>>>>
t
>>>> im
>>>> e:group) 
>>>> + (0+gp0:coord1+gp0:coord2|ID)+(0+coord1:group+coord2:group|ID),
>>>> data=simdata),
>>>> 
>>>> Many thanks for any help.
>>>> 
>>>> Best regards,
>>>> Sarah
>>>>    
>>>> 
>>> 
>>>  
>>> 
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



From jorge.gonzalez at psy.kuleuven.be  Tue Sep 25 20:42:40 2007
From: jorge.gonzalez at psy.kuleuven.be (=?ISO-8859-1?Q?Jorge_Gonz=E1lez?=)
Date: Tue, 25 Sep 2007 20:42:40 +0200
Subject: [R-sig-ME] Missing information in "name" column of Random effects
	output
Message-ID: <46F956A0.60602@psy.kuleuven.be>

Dear all,

My apologies if this has been discussed before. When estimating a model 
with lmer, I can't see anymore the contents of the "name" column in the 
Random effects part of the output. See the example below

###### begin example ###################
 > sessionInfo()
R version 2.5.1 (2007-06-27)
i386-pc-mingw32

locale:
LC_COLLATE=Dutch_Belgium.1252;LC_CTYPE=Dutch_Belgium.1252;LC_MONETARY=Dutch_Belgium.1252;LC_NUMERIC=C;LC_TIME=Dutch_Belgium.1252

attached base packages:
[1] "stats"     "graphics"  "grDevices" "utils"     "datasets"  
"methods"   "base"    

other attached packages:
        lme4       Matrix      lattice
 "0.99875-7" "0.999375-2"     "0.16-5"
 > fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy)
 > fm1
Linear mixed-effects model fit by REML
Formula: Reaction ~ Days + (Days | Subject)
   Data: sleepstudy
  AIC  BIC logLik MLdeviance REMLdeviance
 1754 1770 -871.8       1752         1744
Random effects:
 Groups   Name Variance  Std.Dev. Corr 
 Subject             610.835  24.7151       
                            35.056   5.9208  0.067
 Residual            655.066  25.5943       
number of obs: 180, groups: Subject, 18

Fixed effects:
                 Estimate   Std. Error t value
(Intercept)  251.405      6.820   36.86
Days            10.467      1.546    6.77

Correlation of Fixed Effects:
     (Intr)
Days -0.137
 >
#################### end example ##################
How can I know which variance correspond to the subject  random 
intercept and which one to the subject slope Days? As far as I remember 
this information was available in previous versions. Is this a bug?

Thank you very much in advance

Jorge

-- 

 _-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_
|Jorge Gonz?lez                                                       |
|Faculty of Psychology                                                |
|Research Group of Quantitative Psychology and Individual Differences |
|jorge.gonzalez at psy.kuleuven.be                                       |
|http://perswww.kuleuven.be/jorge_gonzalez                            |
|http://www.kuleuven.be/cv/u0045204e.htm                              |
|_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_|




Disclaimer: http://www.kuleuven.be/cwis/email_disclaimer.htm



From dafshartous at med.miami.edu  Tue Sep 25 21:43:15 2007
From: dafshartous at med.miami.edu (David Afshartous)
Date: Tue, 25 Sep 2007 15:43:15 -0400
Subject: [R-sig-ME] Missing information in "name" column of Random
 effects output
In-Reply-To: <46F956A0.60602@psy.kuleuven.be>
Message-ID: <C31EDD13.133A%dafshartous@med.miami.edu>



Jorge,

Awhile back I think I noticed a similar issue. I don't recall if I was able
to do anything different w/ the lmer statement to fix it. In any event, my
guess is that the first term corresponds to the intercept RE and the second
to the slope RE.  Looking at the estimated RE's themselves supports this:

> ranef(fm1)
An object of class ?ranef.lmer?
[[1]]
    (Intercept)        Days
308   2.2713451   9.1966961
309 -40.3825921  -8.6223099
310 -38.9403378  -5.4521894
330  23.6656443  -4.8100611
331  22.2391295  -3.0662861
332   9.0324969  -0.2709760
333  16.8277808  -0.2214775
334  -7.2256113   1.0733822
335  -0.3503176 -10.7492136
337  34.8784025   8.6302064
349 -25.1898574   1.1699674
350 -13.0500361   6.6107496
351   4.5697621  -3.0138529
352  20.8539011   3.5376139
369   3.2744289   0.8723798
370 -25.5865985   4.8179542
371   0.8049003  -0.9877807
372  12.3075594   1.2851975

> fm1.junk = ranef(fm1)[[1]]
> int.ranef  = fm1.junk[,1]
> slope.ranef  = fm1.junk[,2]
> var(int.ranef)
[1] 465.8012
> var(slope.ranef)
[1] 29.75055




On 9/25/07 2:42 PM, "Jorge Gonz?lez" <jorge.gonzalez at psy.kuleuven.be> wrote:

> Dear all,
> 
> My apologies if this has been discussed before. When estimating a model
> with lmer, I can't see anymore the contents of the "name" column in the
> Random effects part of the output. See the example below
> 
> ###### begin example ###################
>> sessionInfo()
> R version 2.5.1 (2007-06-27)
> i386-pc-mingw32
> 
> locale:
> LC_COLLATE=Dutch_Belgium.1252;LC_CTYPE=Dutch_Belgium.1252;LC_MONETARY=Dutch_Be
> lgium.1252;LC_NUMERIC=C;LC_TIME=Dutch_Belgium.1252
> 
> attached base packages:
> [1] "stats"     "graphics"  "grDevices" "utils"     "datasets"
> "methods"   "base"
> 
> other attached packages:
>         lme4       Matrix      lattice
>  "0.99875-7" "0.999375-2"     "0.16-5"
>> fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy)
>> fm1
> Linear mixed-effects model fit by REML
> Formula: Reaction ~ Days + (Days | Subject)
>    Data: sleepstudy
>   AIC  BIC logLik MLdeviance REMLdeviance
>  1754 1770 -871.8       1752         1744
> Random effects:
>  Groups   Name Variance  Std.Dev. Corr
>  Subject             610.835  24.7151
>                             35.056   5.9208  0.067
>  Residual            655.066  25.5943
> number of obs: 180, groups: Subject, 18
> 
> Fixed effects:
>                  Estimate   Std. Error t value
> (Intercept)  251.405      6.820   36.86
> Days            10.467      1.546    6.77
> 
> Correlation of Fixed Effects:
>      (Intr)
> Days -0.137
>> 
> #################### end example ##################
> How can I know which variance correspond to the subject  random
> intercept and which one to the subject slope Days? As far as I remember
> this information was available in previous versions. Is this a bug?
> 
> Thank you very much in advance
> 
> Jorge



From sarah at stats.gla.ac.uk  Wed Sep 26 11:57:44 2007
From: sarah at stats.gla.ac.uk (Sarah Barry)
Date: Wed, 26 Sep 2007 10:57:44 +0100
Subject: [R-sig-ME] Different random effects variances for outcomes and
 groups
In-Reply-To: <C31EACF5.132F%dafshartous@med.miami.edu>
References: <C31EACF5.132F%dafshartous@med.miami.edu>
Message-ID: <46FA2D18.4060301@stats.gla.ac.uk>

David,

Perhaps that's actually what I was fitting before:

(2) 
lmer2(y~-1+coord1+coord2+coord1:(time+group+time:group)+coord2:(time+group+time:group) 
+ (0+coord1+coord2+coord1:group+coord2:group|ID), data=simdata)

with a separate group effect for each coordinate.  An alternative with 
the same group effect across coordinates would be:

(3) 
lmer2(y~-1+coord1+coord2+coord1:(time+group+time:group)+coord2:(time+group+time:group) 
+ (0+coord1+coord2+group|ID), data=simdata)

Model (2) gives the same loglik as model (1) (the desired model with 
stratified variances), but a higher AIC.  Model (3) gives a slightly 
lower loglik, with the same AIC as model (2).  BIC is a bit more 
varying, being lowest for model (1) and highest for model (2).

Sarah

David Afshartous wrote:

>One additional comment below ...
>
>
>On 9/25/07 10:03 AM, "David Afshartous" <dafshartous at med.miami.edu> wrote:
>
>  
>
>>Hi Sarah,
>>A few comments below.
>>David
>>
>>
>>On 9/25/07 9:05 AM, "Sarah Barry" <sarah at stats.gla.ac.uk> wrote:
>>
>>    
>>
>>>Hi David,
>>>
>>>Thanks for your reply.  I comment on your various questions below.
>>>
>>>David Afshartous wrote:
>>>
>>>      
>>>
>>>>Hi Sarah,
>>>>
>>>>Did you receive any replies to your post?  Some comments below, perhaps
>>>>tangential to you main question but possibly of interest.
>>>>
>>>>First let me make sure I understand you data structure.  You have 100
>>>>children in each of 2 groups, and for each child you take 3 measurements at
>>>>coordinate 1 and coordinate 2.
>>>>Hence there are 100 x 2 x 3 x 3 = 1200 observations.  Moreover, the children
>>>>in the two groups are different children, hence the different IDs in the
>>>>data (as opposed to the same children being in both groups e.g. when each
>>>>child receives both treatment and placebo; this affects the number of random
>>>>effects).
>>>>
>>>> 
>>>>
>>>>        
>>>>
>>>Yes, you are right here (apart from a typo - there are 100 x 2 x 3 x 2 =
>>>1200 observations).  The groups do contain different children.
>>>
>>>      
>>>
>>>>In your model equation:
>>>> 
>>>>
>>>>        
>>>>
>>>>>y_{ir}(t) = \beta_{0r} + \beta_{1r} group_i + \beta_{2r} t + \beta_{3r}
>>>>>group_i : t  + b_{ir0} + group_i * b_{ir1} + \epsilon_{ir}(t),
>>>>>
>>>>>   
>>>>>
>>>>>          
>>>>>
>>>>You have a random intercept model, where the intercept is broken down
>>>>according to fixed effects for coordinate and group, and similarly for the
>>>>slope.  I assume you want the random effect for the intercept stratified
>>>>according to both group and coordinate.  I'm not sure how the terms above
>>>>reflect this; perhaps all you need is the term b_{irp} ~ > N(0,
>>>>\sigma_{rp}2), for p=0,1; r = 1,2.
>>>>
>>>> 
>>>>
>>>>        
>>>>
>>>I think you're right here and this corresponds with what you say below.
>>>I think my model should be instead written as
>>>
>>>y_{ir}(t) = \beta_{0r} + \beta_{1r} group_i + \beta_{2r} t + \beta_{3r}
>>>group_i : t  + group_i * b_{irp} + \epsilon_{ir}(t),
>>>
>>>where p=0,1 represents the value of 'group_i' and is distributed as you
>>>suggest.  This seems to make more sense than everyone having a random
>>>intercept from one distribution and group 1 having an additional one.
>>>This way they are completely separate.
>>>
>>>      
>>>
>>>>RE your simulation code to generate the random effects, I assume you have
>>>>broken "randeff" into blocks of 300 ( = 1200/4) because the group x
>>>>coordinate stratification yields 4 distinct combinations.
>>>>However, I have a question RE the way in which these random effects are
>>>>simulated.  For instance, consider patient 1 in group 1.  According to your
>>>>simulation code, two separate random normals will be generated to reflect
>>>>the random effect of this patient at coordinate 1 and coordinate 2, with
>>>>random normal variance equal to the sum of the group random effect variance
>>>>and the coordinate random effect variance.  However, I don't think this
>>>>reflects the nesting appropriately.  Perhaps the group component should only
>>>>be generated once as it is the same child in the same group; and the
>>>>coordinate component is the part that needs to be generated twice. This of
>>>>course will increase the correlation between the two realized values.
>>>>(BTW, did you chose the standard deviations values of 15, 10, 25, and 20 to
>>>>reflect the aforementioned sub-component structure, and if so what were the
>>>>standard deviations of the sub-components?).
>>>>
>>>> 
>>>>
>>>>        
>>>>
>>>Yes, I should have considered this more carefully.  Certainly the random
>>>effects for coordinates 1 and 2 for a particular individual should have
>>>been simulated from a multivariate normal distribution rather than from
>>>two separate normals.  I don't think that there is so much a group
>>>component and a coordinate component, as a coordinate component that
>>>differs depending on which group the individual comes from.  So, for
>>>example, instead of the randeff statement below we could have (repeated
>>>across times and inserted in the correct positions for each group):
>>>
>>>randeff.gp0 <- mvrnorm(n.subj/2, c(0,0), matrix(c(100,50,50,400),
>>>nc=2))  # coordinates 1 and 2 (respectively) for individuals in group 0 #
>>>randeff.gp1 <- mvrnorm(n.subj/2, c(0,0), matrix(c(225,70,70,625),
>>>nc=2))  # coordinates 1 and 2 (respectively) for individuals in group 1 #
>>>
>>>I think the group itself should only be a fixed effect because, while
>>>individuals are randomly sampled from two populations of cleft-lip
>>>patients and healthy controls, the groups are fixed (not sampled from a
>>>population of groups).  What do you think?  This has been one point that
>>>I have wondered long and hard about.
>>>
>>>      
>>>
>>I agree that group should be a fixed effect based on your description. In
>>your current model, group is a fixed effect, and the random effect on the
>>intercept is for child ID, although this depends on both the group and
>>coordinate for the child.  You do not have a random effect for group per se.
>>This can be contrasted w/ instead employing separate random effects for the
>>nesting levels (Pinheiro & Bates p.40 is a good example of a nesting
>>structure where random effects are used for each level of the nesting.)  It
>>would be interesting to observe the difference in the results.
>>
>>    
>>
>
>Moreover, allowing a random effect for group is definitely not what you want
>as this would not model the differential variability in your data.  Each
>child would have a single group random effect (distributed the same for each
>group), and there would be a child random effect that depends on the
>coordinate, but they would not be distributed differently across the groups
>(you would get 1 list instead of two lists for the random effects in your
>second model statement).  Having said that, I estimated both cases for some
>simple repeated measures data that has a treatment factor.  Specifically:
>1) Stratified RE variance: fixed effects for treatment, RE for each subject,
>stratified per treatment group.
>2) RE for treatment group: fixed effects for treatment, RE for each subject
>(not stratified per treatment), plus RE for treatment group.
>Although I really don't want option 2), I was curious about the differences
>in model fit.  Both models were extremely similar for AIC/BIC/LogLik, which
>is surprising since 2) doesn't model at all the differential growth curve
>variability per treatment in my data. I didn't try this comparison for your
>data as I was unsure of how to modify your lmer2 statement (perhaps mine was
>much simpler due to the single factor of treatment). If you are able to do
>the appropriate modification I'd be interested in the results.
>
>  
>
>>>>With respect to random effects, I assume your model will generate 400 unique
>>>>random effects estimates, i.e., two (for each coordinate) for each of the
>>>>200 children.  And each of these may be viewed as the sum of the
>>>>sub-components of coordinate and group.  Running your first lmer2 model
>>>>statement yields a 200 x 4 matrix for the estimated random effects, w/ each
>>>>row being a patient and the columns corresponding apparently to the
>>>>aforementioned subcomponents:
>>>>
>>>>An object of class ?ranef.lmer?
>>>>[[1]]
>>>>          coord1       coord2  coord1:group coord2:group
>>>>1    -0.502182860   7.98888012  -4.590717867    5.6973871
>>>>2    -0.190673717   3.38674017  -1.849503513    2.4098210
>>>>3    -0.981561080  12.80952815  -8.127985669    9.1788197
>>>>Etc
>>>>
>>>>However, I would think some of these cells need to be 0, e.g., each patient
>>>>is only in 1 group and thus shouldn't have a random effect estimate from
>>>>both groups?  Or am I reading the table completely wrong?
>>>>
>>>>Now, when I ran your second lmer2 model statement and checked the estimated
>>>>random effects (too messy to copy here), I got two lists of 2 random effects
>>>>per child (1 for each coordinate), where it appears that the two lists
>>>>correspond to the two groups, and apparently there are 0's for children that
>>>>were not in the respective group. Based on the estimated random effects
>>>>produced by the two model statements, I think that the second more
>>>>representative of what you're trying to do.  Have a look at the random
>>>>effects for the second model statement and let me know if you agree.
>>>>
>>>>Cheers,
>>>>David
>>>> 
>>>>
>>>>        
>>>>
>>>I do agree and I'm not sure now what model the first lmer2 model
>>>statement is actually fitting, because I would have expected at least
>>>some of the coord1:group and coord2:group random effects to be zero.
>>>The second lmer2 statement gives more sensible answers and corresponds
>>>with the rewritten model above.  Also when I check the estimated random
>>>effects variances and covariances against the actual values, there is
>>>good correspondence so I think I will proceed with this parameterisation.
>>>
>>>Many thanks for your help,
>>>Sarah
>>>
>>>      
>>>
>>>>
>>>>
>>>>On 9/19/07 8:28 AM, "Sarah Barry" <sarah at stats.gla.ac.uk> wrote:
>>>>
>>>> 
>>>>
>>>>        
>>>>
>>>>>Dear all,
>>>>>
>>>>>I wonder if someone could give me some insight on coding lmer.  I have
>>>>>facial shape data on children in two groups at four time points (3,6,12
>>>>>and 24 months).  Each child has a set of coordinate positions measured
>>>>>on their face at each time point (the set of coordinates is the same
>>>>>across individuals and times).  Take coordinates 1 and 2 only for now
>>>>>(reproducible code at the bottom of this email for simulated data).
>>>>>
>>>>>If I plot the trends for coordinates 1 and 2 for each individual over
>>>>>time, there is a different amount of variance amongst the individuals
>>>>>(at least in the intercept, and maybe in the slope) for the two
>>>>>coordinates and also within the two groups, with group 1 (cleft) having
>>>>>higher variation than group 0 (control).  I want to allow for these
>>>>>sources of variation in the model.  The other thing is that I would
>>>>>expect coordinate positions within an individual to be correlated so I
>>>>>also want to allow for this.  The model, therefore, would be (for
>>>>>coordinate r=1,2 measured on individual i at time t, group_i an
>>>>>indicator variable taking value one for group 1 and zero otherwise):
>>>>>
>>>>>y_{ir}(t) = \beta_{0r} + \beta_{1r} group_i + \beta_{2r} t + \beta_{3r}
>>>>>group_i : t  + b_{ir0} + group_i * b_{ir1} + \epsilon_{ir}(t),
>>>>>
>>>>>where \epsilon_{ir}(t) ~ N(0, \sigma2) and the random effect b_{irp} ~
>>>>>N(0, \sigma_{rp}2), for p=0,1.   I think the following code is
>>>>>appropriate (model 1):
>>>>>
>>>>>
>>>>>          
>>>>>
>lmer2(y~-1+coord1+coord2+coord1:(time+group+time:group)+coord2:(time+group+>>>>
>t
>  
>
>>>>>im
>>>>>e:group) 
>>>>>+ (0+coord1+coord2+coord1:group+coord2:group|ID), data=simdata)
>>>>>
>>>>>where coord1 and coord2 are indicator variables for coordinates 1 and 2,
>>>>>respectively, time is continuous and group is an indicator variable
>>>>>taking value one for the cleft group and zero for the controls.  Does
>>>>>the random effects part make sense?  I'm especially unsure about
>>>>>allowing correlations between all of the random effects terms, although
>>>>>I think that's it's appropriate under this parameterisation because each
>>>>>person has a value for both coordinates 1 and 2, and the group effect is
>>>>>additional. 
>>>>>
>>>>>
>>>>>An alternative parameterisation is (model 2):
>>>>>
>>>>>
>>>>>          
>>>>>
>lmer2(y~-1+coord1+coord2+coord1:(time+group+time:group)+coord2:(time+group+>>>>
>t
>  
>
>>>>>im
>>>>>e:group) 
>>>>>+ (0+gp0:coord1+gp0:coord2|ID)+(0+coord1:group+coord2:group|ID),
>>>>>data=simdata),
>>>>>
>>>>>where gp0 is an indicator variable taking value one if the individual is
>>>>>in group 0 and zero otherwise.  It seems to me that this should be
>>>>>equivalent to model 1, but it doesn't appear to be (perhaps this just
>>>>>comes down to fewer correlations estimated in model 2).
>>>>>
>>>>>If a correlation between random effects is estimated to be 1 or -1, is
>>>>>this generally because the model is over-parameterised?
>>>>>
>>>>>Reproducible code is below.
>>>>>
>>>>>set.seed(100)
>>>>>n.subj <- 200
>>>>>n.times <- 3
>>>>>n.coords <- 2
>>>>>simdata <- data.frame(coord1=c(rep(1,n.subj*n.times),
>>>>>rep(0,n.subj*n.times)))
>>>>>simdata$coord2 <- c(rep(0,n.subj*n.times), rep(1,n.subj*n.times))
>>>>>simdata$coord <- ifelse(simdata$coord1==1, 1, 2)
>>>>>simdata$ID <- rep(rep(1:n.subj, each=n.times),2)
>>>>>simdata$time <- rep(1:n.times, n.subj*n.coords)
>>>>>simdata$group <- rep(c(1,0,1,0), each=n.subj*n.times/2)
>>>>>simdata$gp0 <- 1-simdata$group
>>>>>simdata$y <- rep(NA, dim(simdata)[1])
>>>>>randeff <- c(rep(rnorm(n.subj/2, 0, 15),each=n.times),
>>>>>rep(rnorm(n.subj/2, 0, 10), each=n.times), rep(rnorm(n.subj/2, 0, 25),
>>>>>each=n.times), rep(rnorm(n.subj/2, 0, 20), each=3))
>>>>>for (i in 1:dim(simdata)[1]) simdata$y[i] <- rnorm(1,
>>>>>randeff[i]+simdata$time[i]+simdata$coord[i]+10*simdata$group[i], 16)
>>>>>
>>>>>
>>>>>          
>>>>>
>lmer2(y~-1+coord1+coord2+coord1:(time+group+time:group)+coord2:(time+group+>>>>
>t
>  
>
>>>>>im
>>>>>e:group) 
>>>>>+ (0+coord1+coord2+coord1:group+coord2:group|ID), data=simdata)
>>>>>
>>>>>          
>>>>>
>lmer2(y~-1+coord1+coord2+coord1:(time+group+time:group)+coord2:(time+group+>>>>
>t
>  
>
>>>>>im
>>>>>e:group) 
>>>>>+ (0+gp0:coord1+gp0:coord2|ID)+(0+coord1:group+coord2:group|ID),
>>>>>data=simdata),
>>>>>
>>>>>Many thanks for any help.
>>>>>
>>>>>Best regards,
>>>>>Sarah
>>>>>   
>>>>>
>>>>>          
>>>>>
>>>> 
>>>>
>>>>        
>>>>
>>_______________________________________________
>>R-sig-mixed-models at r-project.org mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>    
>>
>
>  
>

-- 
Sarah Barry, MSc
Department of Statistics
University of Glasgow
Tel: +44 (0)141 330 2474
Fax: +44 (0)141 330 4814
www.stats.gla.ac.uk/~sarah



From jdeke73 at gmail.com  Wed Sep 26 13:49:27 2007
From: jdeke73 at gmail.com (John Deke)
Date: Wed, 26 Sep 2007 07:49:27 -0400
Subject: [R-sig-ME] survey weights in lmer?
Message-ID: <82372b520709260449x1fe8412amb87ddaf2147ec1b4@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20070926/c325f4bb/attachment.pl>

From bates at stat.wisc.edu  Wed Sep 26 15:10:16 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 26 Sep 2007 08:10:16 -0500
Subject: [R-sig-ME] Missing information in "name" column of Random
	effects output
In-Reply-To: <C31EDD13.133A%dafshartous@med.miami.edu>
References: <46F956A0.60602@psy.kuleuven.be>
	<C31EDD13.133A%dafshartous@med.miami.edu>
Message-ID: <40e66e0b0709260610i224bf71cv13b65f2e886fcb0b@mail.gmail.com>

On 9/25/07, David Afshartous <dafshartous at med.miami.edu> wrote:

> Jorge,

> Awhile back I think I noticed a similar issue. I don't recall if I was able
> to do anything different w/ the lmer statement to fix it. In any event, my
> guess is that the first term corresponds to the intercept RE and the second
> to the slope RE.  Looking at the estimated RE's themselves supports this:

Jorge is correct that the name column is no longer being filled out
and David is correct that the order of variance components corresponds
to the order of the terms in the model matrix for the random effects
term.  Thanks to both of you for the report.

At some point I changed where the names are stored and I forgot to
update the VarCorr method accordingly.  I will release a new version
with this fixed.

> > ranef(fm1)
> An object of class ?ranef.lmer?
> [[1]]
>     (Intercept)        Days
> 308   2.2713451   9.1966961
> 309 -40.3825921  -8.6223099
> 310 -38.9403378  -5.4521894
> 330  23.6656443  -4.8100611
> 331  22.2391295  -3.0662861
> 332   9.0324969  -0.2709760
> 333  16.8277808  -0.2214775
> 334  -7.2256113   1.0733822
> 335  -0.3503176 -10.7492136
> 337  34.8784025   8.6302064
> 349 -25.1898574   1.1699674
> 350 -13.0500361   6.6107496
> 351   4.5697621  -3.0138529
> 352  20.8539011   3.5376139
> 369   3.2744289   0.8723798
> 370 -25.5865985   4.8179542
> 371   0.8049003  -0.9877807
> 372  12.3075594   1.2851975

> > fm1.junk = ranef(fm1)[[1]]
> > int.ranef  = fm1.junk[,1]
> > slope.ranef  = fm1.junk[,2]
> > var(int.ranef)
> [1] 465.8012
> > var(slope.ranef)
> [1] 29.75055

> On 9/25/07 2:42 PM, "Jorge Gonz?lez" <jorge.gonzalez at psy.kuleuven.be> wrote:
>
> > Dear all,
> >
> > My apologies if this has been discussed before. When estimating a model
> > with lmer, I can't see anymore the contents of the "name" column in the
> > Random effects part of the output. See the example below
> >
> > ###### begin example ###################
> >> sessionInfo()
> > R version 2.5.1 (2007-06-27)
> > i386-pc-mingw32
> >
> > locale:
> > LC_COLLATE=Dutch_Belgium.1252;LC_CTYPE=Dutch_Belgium.1252;LC_MONETARY=Dutch_Be
> > lgium.1252;LC_NUMERIC=C;LC_TIME=Dutch_Belgium.1252
> >
> > attached base packages:
> > [1] "stats"     "graphics"  "grDevices" "utils"     "datasets"
> > "methods"   "base"
> >
> > other attached packages:
> >         lme4       Matrix      lattice
> >  "0.99875-7" "0.999375-2"     "0.16-5"
> >> fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy)
> >> fm1
> > Linear mixed-effects model fit by REML
> > Formula: Reaction ~ Days + (Days | Subject)
> >    Data: sleepstudy
> >   AIC  BIC logLik MLdeviance REMLdeviance
> >  1754 1770 -871.8       1752         1744
> > Random effects:
> >  Groups   Name Variance  Std.Dev. Corr
> >  Subject             610.835  24.7151
> >                             35.056   5.9208  0.067
> >  Residual            655.066  25.5943
> > number of obs: 180, groups: Subject, 18
> >
> > Fixed effects:
> >                  Estimate   Std. Error t value
> > (Intercept)  251.405      6.820   36.86
> > Days            10.467      1.546    6.77
> >
> > Correlation of Fixed Effects:
> >      (Intr)
> > Days -0.137
> >>
> > #################### end example ##################
> > How can I know which variance correspond to the subject  random
> > intercept and which one to the subject slope Days? As far as I remember
> > this information was available in previous versions. Is this a bug?
> >
> > Thank you very much in advance
> >
> > Jorge
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From dafshartous at med.miami.edu  Wed Sep 26 20:43:11 2007
From: dafshartous at med.miami.edu (David Afshartous)
Date: Wed, 26 Sep 2007 14:43:11 -0400
Subject: [R-sig-ME] Different random effects variances for outcomes and
 groups
In-Reply-To: <46FA2D18.4060301@stats.gla.ac.uk>
Message-ID: <C320207F.136D%dafshartous@med.miami.edu>


Hi Sarah,

comments below; please excuse the e-mail length, I'm trying to tie up a
previously related thread.

Consider:  1) random term for each child, stratified for some partitioning.
2) random term for each child, PLUS random terms for other grouping factors,
e.g., group and/or coordinate (whether this is a good ideas is a separate
issue).  In terms of the mathematical equation, 1) involves only 1 random
term (aside from the lowest level residual error term), whose variance needs
subscripts for the desired stratification. On the other hand, 2) will
involve multiple random terms (w/o subscripts for their variance; one could
attempt this, but let's assume not for now).   Moreover, 2) does not
accomplish stratification, i.e., differential variability for some defined
partition.  

Now, with respect to your three models (below I'll number them from the
beginning to avoid e-mail thread confusion), I don't think any of them has a
random effect for group. This would require a "(... | group)" term. All of
the models have the random effect defined by "(...| ID)"; thus the random
term is defined per child (ID), and the "(...|" part defines a variance
stratification of this random term. However, for this to make sense, I think
that the stratification must uniquely partition the data (comments below for
each model on what I mean by this):

Model 1: 
Barryfm1 
=lmer2(y~-1+coord1+coord2+coord1:(time+group+time:group)+coord2:(time+group+
time:group) 
+ (0+coord1+coord2+coord1:group+coord2:group|ID), data=simdata)
 Data: simdata 
   AIC   BIC logLik MLdeviance REMLdeviance
 10702 10794  -5333      10687        10666

For this model the random statement is:
(0+coord1+coord2+coord1:group+coord2:group|ID)

One way to assess what this does is to sum the left hand side of "(...| ID)"
for a particular observation. For the partition and hence variance
stratification to work, I think that this sum should always be equal to 1.
Otherwise, I think the stratification will be redundant. Here, the sum will
equal 1 or 2, e.g., all observations in the second group will have sum equal
to 2.  Now, regarding the random effects,

> ranef(Barryfm1)
An object of class ?ranef.lmer?
[[1]]
           coord1       coord2  coord1:group coord2:group
1    -0.502182860   7.98888012  -4.590717867    5.6973871
2    -0.190673717   3.38674017  -1.849503513    2.4098210
...

there are 4 components for each child.  Recall that there is really only 1
random intercept term and this is being stratified for a partition, and it
looks like this partition is redundant.  For instance, one might be tempted
to say that the 4 components above correspond to the 4=2x2 cells defined by
coord and group, and that for child1 we have an estimated intercept random
effect of -0.502182860 under coord1 and group 0, and 7.98888012 + 5.6973871
when under coord2 and group 1; however, it doesn't seem that the indicator
variables are defined that way, since coord1 is not defined as specific or
"baseline" to group 0.  Or is perhaps lmer imposing this? (I calculated the
variance of these estimated random effects and compared them w/ the
estimated model random effect variances and they didn't seem to "match" ...
To be sure, they shouldn't be the same, but one would except some type of
correspondence.)


Model 2:
Barryfm2 = 
lmer2(y~-1+coord1+coord2+coord1:(time+group+time:group)+coord2:(time+group+t
ime:group) 
+ (0+gp0:coord1+gp0:coord2|ID)+(0+coord1:group+coord2:group|ID),
data=simdata)
Data: simdata 
   AIC   BIC logLik MLdeviance REMLdeviance
 10694 10765  -5333      10687        10666

This model statement seems to accomplish the desired partitioning, viz., the
two "(...| ID)" components will have the left hand side sum to 1 for all
observations and partition the observations to your desired stratification.
Moreover, the way you have it gives you the covariance for the coordinates
within the same group that you wanted.  Finally, as mentioned before, the
estimated random effects exhibit variability that seems to correspond to the
estimated model random effects variances.

Model 3: 
Barryfm3= 
lmer2(y~-1+coord1+coord2+coord1:(time+group+time:group)+coord2:(time+group+t
ime:group) 
+ (0+coord1+coord2+group|ID), data=simdata)
 Data: simdata 
   AIC   BIC logLik MLdeviance REMLdeviance
 10697 10768  -5335      10690        10669

For this model the random statement is "(0+coord1+coord2+group|ID)".
Similar to comments for model 1, this doesn't provide a clean partitioning
to yield a variance stratification, nor does it have a random effect for
group.  Random effects are:

> ranef(Barryfm3)
An object of class ?ranef.lmer?
[[1]]
           coord1       coord2         group
1   -1.596120e+00  16.48042299  -3.145684833
2   -6.500204e-01   6.89408428  -1.243928305
...

As with 1), I'm not sure how to interpret this stratification. Once again,
there a random intercept defined by the "(...| ID)" or child grouping, but
this is stratified by "...|" in a way that doesn't seem to make sense, yet
we have estimates of random effects.  As w/ 1), based on the way the
indicators are defined, I don't think we can say that the estimated random
effect for child 1 in coord1 and group 0 is -1.596120e+00, and 16.48042299
-3.145684833 for coord2 and group 1.

In summary, it would be interesting to get closure on what is going on in 1)
and 3), and why the logLik is so similar to 2), and whether lmer should be
producing any estimates at all if the random intercept variance
stratification is really redundant as I suggest. Perhaps Prof. Bates could
shed light on the latter issue.

Cheers,
David



On 9/26/07 5:57 AM, "Sarah Barry" <sarah at stats.gla.ac.uk> wrote:

> David,
> 
> Perhaps that's actually what I was fitting before:
> 
> (2) 
> lmer2(y~-1+coord1+coord2+coord1:(time+group+time:group)+coord2:(time+group+tim
> e:group) 
> + (0+coord1+coord2+coord1:group+coord2:group|ID), data=simdata)
> 
> with a separate group effect for each coordinate.  An alternative with
> the same group effect across coordinates would be:
> 
> (3) 
> lmer2(y~-1+coord1+coord2+coord1:(time+group+time:group)+coord2:(time+group+tim
> e:group) 
> + (0+coord1+coord2+group|ID), data=simdata)
> 
> Model (2) gives the same loglik as model (1) (the desired model with
> stratified variances), but a higher AIC.  Model (3) gives a slightly
> lower loglik, with the same AIC as model (2).  BIC is a bit more
> varying, being lowest for model (1) and highest for model (2).
> 
> Sarah
> 
> David Afshartous wrote:
> 
>> One additional comment below ...
>> 
>> 
>> On 9/25/07 10:03 AM, "David Afshartous" <dafshartous at med.miami.edu> wrote:
>> 
>>  
>> 
>>> Hi Sarah,
>>> A few comments below.
>>> David
>>> 
>>> 
>>> On 9/25/07 9:05 AM, "Sarah Barry" <sarah at stats.gla.ac.uk> wrote:
>>> 
>>>    
>>> 
>>>> Hi David,
>>>> 
>>>> Thanks for your reply.  I comment on your various questions below.
>>>> 
>>>> David Afshartous wrote:
>>>> 
>>>>      
>>>> 
>>>>> Hi Sarah,
>>>>> 
>>>>> Did you receive any replies to your post?  Some comments below, perhaps
>>>>> tangential to you main question but possibly of interest.
>>>>> 
>>>>> First let me make sure I understand you data structure.  You have 100
>>>>> children in each of 2 groups, and for each child you take 3 measurements
>>>>> at
>>>>> coordinate 1 and coordinate 2.
>>>>> Hence there are 100 x 2 x 3 x 3 = 1200 observations.  Moreover, the
>>>>> children
>>>>> in the two groups are different children, hence the different IDs in the
>>>>> data (as opposed to the same children being in both groups e.g. when each
>>>>> child receives both treatment and placebo; this affects the number of
>>>>> random
>>>>> effects).
>>>>> 
>>>>> 
>>>>> 
>>>>>        
>>>>> 
>>>> Yes, you are right here (apart from a typo - there are 100 x 2 x 3 x 2 =
>>>> 1200 observations).  The groups do contain different children.
>>>> 
>>>>      
>>>> 
>>>>> In your model equation:
>>>>> 
>>>>> 
>>>>>        
>>>>> 
>>>>>> y_{ir}(t) = \beta_{0r} + \beta_{1r} group_i + \beta_{2r} t + \beta_{3r}
>>>>>> group_i : t  + b_{ir0} + group_i * b_{ir1} + \epsilon_{ir}(t),
>>>>>> 
>>>>>>   
>>>>>> 
>>>>>>          
>>>>>> 
>>>>> You have a random intercept model, where the intercept is broken down
>>>>> according to fixed effects for coordinate and group, and similarly for the
>>>>> slope.  I assume you want the random effect for the intercept stratified
>>>>> according to both group and coordinate.  I'm not sure how the terms above
>>>>> reflect this; perhaps all you need is the term b_{irp} ~ > N(0,
>>>>> \sigma_{rp}2), for p=0,1; r = 1,2.
>>>>> 
>>>>> 
>>>>> 
>>>>>        
>>>>> 
>>>> I think you're right here and this corresponds with what you say below.
>>>> I think my model should be instead written as
>>>> 
>>>> y_{ir}(t) = \beta_{0r} + \beta_{1r} group_i + \beta_{2r} t + \beta_{3r}
>>>> group_i : t  + group_i * b_{irp} + \epsilon_{ir}(t),
>>>> 
>>>> where p=0,1 represents the value of 'group_i' and is distributed as you
>>>> suggest.  This seems to make more sense than everyone having a random
>>>> intercept from one distribution and group 1 having an additional one.
>>>> This way they are completely separate.
>>>> 
>>>>      
>>>> 
>>>>> RE your simulation code to generate the random effects, I assume you have
>>>>> broken "randeff" into blocks of 300 ( = 1200/4) because the group x
>>>>> coordinate stratification yields 4 distinct combinations.
>>>>> However, I have a question RE the way in which these random effects are
>>>>> simulated.  For instance, consider patient 1 in group 1.  According to
>>>>> your
>>>>> simulation code, two separate random normals will be generated to reflect
>>>>> the random effect of this patient at coordinate 1 and coordinate 2, with
>>>>> random normal variance equal to the sum of the group random effect
>>>>> variance
>>>>> and the coordinate random effect variance.  However, I don't think this
>>>>> reflects the nesting appropriately.  Perhaps the group component should
>>>>> only
>>>>> be generated once as it is the same child in the same group; and the
>>>>> coordinate component is the part that needs to be generated twice. This of
>>>>> course will increase the correlation between the two realized values.
>>>>> (BTW, did you chose the standard deviations values of 15, 10, 25, and 20
>>>>> to
>>>>> reflect the aforementioned sub-component structure, and if so what were
>>>>> the
>>>>> standard deviations of the sub-components?).
>>>>> 
>>>>> 
>>>>> 
>>>>>        
>>>>> 
>>>> Yes, I should have considered this more carefully.  Certainly the random
>>>> effects for coordinates 1 and 2 for a particular individual should have
>>>> been simulated from a multivariate normal distribution rather than from
>>>> two separate normals.  I don't think that there is so much a group
>>>> component and a coordinate component, as a coordinate component that
>>>> differs depending on which group the individual comes from.  So, for
>>>> example, instead of the randeff statement below we could have (repeated
>>>> across times and inserted in the correct positions for each group):
>>>> 
>>>> randeff.gp0 <- mvrnorm(n.subj/2, c(0,0), matrix(c(100,50,50,400),
>>>> nc=2))  # coordinates 1 and 2 (respectively) for individuals in group 0 #
>>>> randeff.gp1 <- mvrnorm(n.subj/2, c(0,0), matrix(c(225,70,70,625),
>>>> nc=2))  # coordinates 1 and 2 (respectively) for individuals in group 1 #
>>>> 
>>>> I think the group itself should only be a fixed effect because, while
>>>> individuals are randomly sampled from two populations of cleft-lip
>>>> patients and healthy controls, the groups are fixed (not sampled from a
>>>> population of groups).  What do you think?  This has been one point that
>>>> I have wondered long and hard about.
>>>> 
>>>>      
>>>> 
>>> I agree that group should be a fixed effect based on your description. In
>>> your current model, group is a fixed effect, and the random effect on the
>>> intercept is for child ID, although this depends on both the group and
>>> coordinate for the child.  You do not have a random effect for group per se.
>>> This can be contrasted w/ instead employing separate random effects for the
>>> nesting levels (Pinheiro & Bates p.40 is a good example of a nesting
>>> structure where random effects are used for each level of the nesting.)  It
>>> would be interesting to observe the difference in the results.
>>> 
>>>    
>>> 
>> 
>> Moreover, allowing a random effect for group is definitely not what you want
>> as this would not model the differential variability in your data.  Each
>> child would have a single group random effect (distributed the same for each
>> group), and there would be a child random effect that depends on the
>> coordinate, but they would not be distributed differently across the groups
>> (you would get 1 list instead of two lists for the random effects in your
>> second model statement).  Having said that, I estimated both cases for some
>> simple repeated measures data that has a treatment factor.  Specifically:
>> 1) Stratified RE variance: fixed effects for treatment, RE for each subject,
>> stratified per treatment group.
>> 2) RE for treatment group: fixed effects for treatment, RE for each subject
>> (not stratified per treatment), plus RE for treatment group.
>> Although I really don't want option 2), I was curious about the differences
>> in model fit.  Both models were extremely similar for AIC/BIC/LogLik, which
>> is surprising since 2) doesn't model at all the differential growth curve
>> variability per treatment in my data. I didn't try this comparison for your
>> data as I was unsure of how to modify your lmer2 statement (perhaps mine was
>> much simpler due to the single factor of treatment). If you are able to do
>> the appropriate modification I'd be interested in the results.
>> 
>>  
>> 
>>>>> With respect to random effects, I assume your model will generate 400
>>>>> unique
>>>>> random effects estimates, i.e., two (for each coordinate) for each of the
>>>>> 200 children.  And each of these may be viewed as the sum of the
>>>>> sub-components of coordinate and group.  Running your first lmer2 model
>>>>> statement yields a 200 x 4 matrix for the estimated random effects, w/
>>>>> each
>>>>> row being a patient and the columns corresponding apparently to the
>>>>> aforementioned subcomponents:
>>>>> 
>>>>> An object of class ?ranef.lmer?
>>>>> [[1]]
>>>>>          coord1       coord2  coord1:group coord2:group
>>>>> 1    -0.502182860   7.98888012  -4.590717867    5.6973871
>>>>> 2    -0.190673717   3.38674017  -1.849503513    2.4098210
>>>>> 3    -0.981561080  12.80952815  -8.127985669    9.1788197
>>>>> Etc
>>>>> 
>>>>> However, I would think some of these cells need to be 0, e.g., each
>>>>> patient
>>>>> is only in 1 group and thus shouldn't have a random effect estimate from
>>>>> both groups?  Or am I reading the table completely wrong?
>>>>> 
>>>>> Now, when I ran your second lmer2 model statement and checked the
>>>>> estimated
>>>>> random effects (too messy to copy here), I got two lists of 2 random
>>>>> effects
>>>>> per child (1 for each coordinate), where it appears that the two lists
>>>>> correspond to the two groups, and apparently there are 0's for children
>>>>> that
>>>>> were not in the respective group. Based on the estimated random effects
>>>>> produced by the two model statements, I think that the second more
>>>>> representative of what you're trying to do.  Have a look at the random
>>>>> effects for the second model statement and let me know if you agree.
>>>>> 
>>>>> Cheers,
>>>>> David
>>>>> 
>>>>> 
>>>>>        
>>>>> 
>>>> I do agree and I'm not sure now what model the first lmer2 model
>>>> statement is actually fitting, because I would have expected at least
>>>> some of the coord1:group and coord2:group random effects to be zero.
>>>> The second lmer2 statement gives more sensible answers and corresponds
>>>> with the rewritten model above.  Also when I check the estimated random
>>>> effects variances and covariances against the actual values, there is
>>>> good correspondence so I think I will proceed with this parameterisation.
>>>> 
>>>> Many thanks for your help,
>>>> Sarah
>>>> 
>>>>      
>>>> 
>>>>> 
>>>>> 
>>>>> On 9/19/07 8:28 AM, "Sarah Barry" <sarah at stats.gla.ac.uk> wrote:
>>>>> 
>>>>> 
>>>>> 
>>>>>        
>>>>> 
>>>>>> Dear all,
>>>>>> 
>>>>>> I wonder if someone could give me some insight on coding lmer.  I have
>>>>>> facial shape data on children in two groups at four time points (3,6,12
>>>>>> and 24 months).  Each child has a set of coordinate positions measured
>>>>>> on their face at each time point (the set of coordinates is the same
>>>>>> across individuals and times).  Take coordinates 1 and 2 only for now
>>>>>> (reproducible code at the bottom of this email for simulated data).
>>>>>> 
>>>>>> If I plot the trends for coordinates 1 and 2 for each individual over
>>>>>> time, there is a different amount of variance amongst the individuals
>>>>>> (at least in the intercept, and maybe in the slope) for the two
>>>>>> coordinates and also within the two groups, with group 1 (cleft) having
>>>>>> higher variation than group 0 (control).  I want to allow for these
>>>>>> sources of variation in the model.  The other thing is that I would
>>>>>> expect coordinate positions within an individual to be correlated so I
>>>>>> also want to allow for this.  The model, therefore, would be (for
>>>>>> coordinate r=1,2 measured on individual i at time t, group_i an
>>>>>> indicator variable taking value one for group 1 and zero otherwise):
>>>>>> 
>>>>>> y_{ir}(t) = \beta_{0r} + \beta_{1r} group_i + \beta_{2r} t + \beta_{3r}
>>>>>> group_i : t  + b_{ir0} + group_i * b_{ir1} + \epsilon_{ir}(t),
>>>>>> 
>>>>>> where \epsilon_{ir}(t) ~ N(0, \sigma2) and the random effect b_{irp} ~
>>>>>> N(0, \sigma_{rp}2), for p=0,1.   I think the following code is
>>>>>> appropriate (model 1):
>>>>>> 
>>>>>> 
>>>>>>          
>>>>>> 
>> lmer2(y~-1+coord1+coord2+coord1:(time+group+time:group)+coord2:(time+group+>>
>> >>
>> t
>>  
>> 
>>>>>> im
>>>>>> e:group) 
>>>>>> + (0+coord1+coord2+coord1:group+coord2:group|ID), data=simdata)
>>>>>> 
>>>>>> where coord1 and coord2 are indicator variables for coordinates 1 and 2,
>>>>>> respectively, time is continuous and group is an indicator variable
>>>>>> taking value one for the cleft group and zero for the controls.  Does
>>>>>> the random effects part make sense?  I'm especially unsure about
>>>>>> allowing correlations between all of the random effects terms, although
>>>>>> I think that's it's appropriate under this parameterisation because each
>>>>>> person has a value for both coordinates 1 and 2, and the group effect is
>>>>>> additional. 
>>>>>> 
>>>>>> 
>>>>>> An alternative parameterisation is (model 2):
>>>>>> 
>>>>>> 
>>>>>>          
>>>>>> 
>> lmer2(y~-1+coord1+coord2+coord1:(time+group+time:group)+coord2:(time+group+>>
>> >>
>> t
>>  
>> 
>>>>>> im
>>>>>> e:group) 
>>>>>> + (0+gp0:coord1+gp0:coord2|ID)+(0+coord1:group+coord2:group|ID),
>>>>>> data=simdata),
>>>>>> 
>>>>>> where gp0 is an indicator variable taking value one if the individual is
>>>>>> in group 0 and zero otherwise.  It seems to me that this should be
>>>>>> equivalent to model 1, but it doesn't appear to be (perhaps this just
>>>>>> comes down to fewer correlations estimated in model 2).
>>>>>> 
>>>>>> If a correlation between random effects is estimated to be 1 or -1, is
>>>>>> this generally because the model is over-parameterised?
>>>>>> 
>>>>>> Reproducible code is below.
>>>>>> 
>>>>>> set.seed(100)
>>>>>> n.subj <- 200
>>>>>> n.times <- 3
>>>>>> n.coords <- 2
>>>>>> simdata <- data.frame(coord1=c(rep(1,n.subj*n.times),
>>>>>> rep(0,n.subj*n.times)))
>>>>>> simdata$coord2 <- c(rep(0,n.subj*n.times), rep(1,n.subj*n.times))
>>>>>> simdata$coord <- ifelse(simdata$coord1==1, 1, 2)
>>>>>> simdata$ID <- rep(rep(1:n.subj, each=n.times),2)
>>>>>> simdata$time <- rep(1:n.times, n.subj*n.coords)
>>>>>> simdata$group <- rep(c(1,0,1,0), each=n.subj*n.times/2)
>>>>>> simdata$gp0 <- 1-simdata$group
>>>>>> simdata$y <- rep(NA, dim(simdata)[1])
>>>>>> randeff <- c(rep(rnorm(n.subj/2, 0, 15),each=n.times),
>>>>>> rep(rnorm(n.subj/2, 0, 10), each=n.times), rep(rnorm(n.subj/2, 0, 25),
>>>>>> each=n.times), rep(rnorm(n.subj/2, 0, 20), each=3))
>>>>>> for (i in 1:dim(simdata)[1]) simdata$y[i] <- rnorm(1,
>>>>>> randeff[i]+simdata$time[i]+simdata$coord[i]+10*simdata$group[i], 16)
>>>>>> 
>>>>>> 
>>>>>>          
>>>>>> 
>> lmer2(y~-1+coord1+coord2+coord1:(time+group+time:group)+coord2:(time+group+>>
>> >>
>> t
>>  
>> 
>>>>>> im
>>>>>> e:group) 
>>>>>> + (0+coord1+coord2+coord1:group+coord2:group|ID), data=simdata)
>>>>>> 
>>>>>>          
>>>>>> 
>> lmer2(y~-1+coord1+coord2+coord1:(time+group+time:group)+coord2:(time+group+>>
>> >>
>> t
>>  
>> 
>>>>>> im
>>>>>> e:group) 
>>>>>> + (0+gp0:coord1+gp0:coord2|ID)+(0+coord1:group+coord2:group|ID),
>>>>>> data=simdata),
>>>>>> 
>>>>>> Many thanks for any help.
>>>>>> 
>>>>>> Best regards,
>>>>>> Sarah
>>>>>>   
>>>>>> 
>>>>>>          
>>>>>> 
>>>>> 
>>>>> 
>>>>>        
>>>>> 
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>    
>>> 
>> 
>>  
>> 



From dafshartous at med.miami.edu  Wed Sep 26 21:27:58 2007
From: dafshartous at med.miami.edu (David Afshartous)
Date: Wed, 26 Sep 2007 15:27:58 -0400
Subject: [R-sig-ME] Interdependence of lme and lmer methods?
In-Reply-To: <C320207F.136D%dafshartous@med.miami.edu>
Message-ID: <C3202AFE.1373%dafshartous@med.miami.edu>


All,

Has anyone noticed interdependence of lmer and lmer methods, i.e., problems
w/ methods when one is estimating models via both lme and lmer in the same
session?  Example below. I searched the archives and didn't see anything.


> sessionInfo()
R version 2.5.1 (2007-06-27)
i386-apple-darwin8.9.1

locale:
en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods"
"base"     

other attached packages:
    nlme 
"3.1-84" 
> fm1 = lme(Thickness ~ 1, random = ~ 1 | Lot, Oxide)
> ranef(fm1)
  (Intercept)
1   -3.702524
2  -11.996179
3    0.928997
4   -4.779622
5   14.392722
6   20.747600
7   -8.764885
8   -6.826109
## ranef methol works fine.
## now load lme4 via menu far:
Loading required package: Matrix
Loading required package: lattice
> ranef(fm1)
Error in function (classes, fdef, mtable)  :
    unable to find an inherited method for function "ranef", for signature
"lme"

## ranef no longer works
## load nlme again via menu bar

Attaching package: 'nlme'


    The following object(s) are masked from package:lme4 :

     BIC,
     VarCorr,
     fixef,
     gsummary,
     lmList,
     pooledSD,
     ranef 

> ranef(fm1)
  (Intercept)
1   -3.702524
2  -11.996179
3    0.928997
4   -4.779622
5   14.392722
6   20.747600
7   -8.764885
8   -6.826109

## now it works fine

In the other direction, similar problems for ranef on lmer models.
for both directions, quick fix solution is to re-load the package for
which the ranef statement applies


Cheers,
David



From agalecki at umich.edu  Wed Sep 26 21:36:16 2007
From: agalecki at umich.edu (Andrzej Galecki)
Date: Wed, 26 Sep 2007 15:36:16 -0400
Subject: [R-sig-ME] simulate.lme (nlme)
Message-ID: <46FAB4B0.9020207@umich.edu>

Dear All,

simulate.lme generates an object (list) containing the MLs (and REMLs) 
for null and alternative models,  fitted to simulated data. Since models 
are nested and are fitted to the same data we anticipate that elements 
of the vector difx containing ML differences , i.e. object$alt$ML - 
objectnull$ML, are positive.

In the example below this difference is calculated for  30 simulations.
I am wondering why some of the elements in difx vector are less than zero.

Thank you

Andrzej Galecki
University of Michigan

PS. Thank you Professor Bates for your response to my previous question.




 > require(lme)
 > sessionInfo()
R version 2.5.0 (2007-04-23)
i386-pc-mingw32

locale:
LC_COLLATE=English_United States.1252;LC_CTYPE=English_United 
States.1252;LC_MONETARY=English_United 
States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252

attached base packages:
[1] "stats"     "graphics"  "grDevices" "utils"     "datasets"  
"methods"   "base"    

other attached packages:
 lattice     nlme
"0.15-4" "3.1-80"

 > orthSim <-simulate.lme(list(fixed = distance ~ age, data = Orthodont,
+ random = ~ 1 | Subject), nsim=30, seed=12345, m2 = list(random = ~ age 
| Subject))
 > difx <- orthSim$alt$ML - orthSim$null$ML
 > range(difx)
[1] -0.006097405  5.222863611



From bates at stat.wisc.edu  Thu Sep 27 16:13:29 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 27 Sep 2007 09:13:29 -0500
Subject: [R-sig-ME] Interdependence of lme and lmer methods?
In-Reply-To: <C3202AFE.1373%dafshartous@med.miami.edu>
References: <C320207F.136D%dafshartous@med.miami.edu>
	<C3202AFE.1373%dafshartous@med.miami.edu>
Message-ID: <40e66e0b0709270713r49df948eyd07136da1f159746@mail.gmail.com>

You are correct, the lme4 and nlme package mask methods from each
other.  It is not recommended that you have both of them attached in
the same session.

On 9/26/07, David Afshartous <dafshartous at med.miami.edu> wrote:
>
> All,
>
> Has anyone noticed interdependence of lmer and lmer methods, i.e., problems
> w/ methods when one is estimating models via both lme and lmer in the same
> session?  Example below. I searched the archives and didn't see anything.
>
>
> > sessionInfo()
> R version 2.5.1 (2007-06-27)
> i386-apple-darwin8.9.1
>
> locale:
> en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>
> attached base packages:
> [1] "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods"
> "base"
>
> other attached packages:
>     nlme
> "3.1-84"
> > fm1 = lme(Thickness ~ 1, random = ~ 1 | Lot, Oxide)
> > ranef(fm1)
>   (Intercept)
> 1   -3.702524
> 2  -11.996179
> 3    0.928997
> 4   -4.779622
> 5   14.392722
> 6   20.747600
> 7   -8.764885
> 8   -6.826109
> ## ranef methol works fine.
> ## now load lme4 via menu far:
> Loading required package: Matrix
> Loading required package: lattice
> > ranef(fm1)
> Error in function (classes, fdef, mtable)  :
>     unable to find an inherited method for function "ranef", for signature
> "lme"
>
> ## ranef no longer works
> ## load nlme again via menu bar
>
> Attaching package: 'nlme'
>
>
>     The following object(s) are masked from package:lme4 :
>
>      BIC,
>      VarCorr,
>      fixef,
>      gsummary,
>      lmList,
>      pooledSD,
>      ranef
>
> > ranef(fm1)
>   (Intercept)
> 1   -3.702524
> 2  -11.996179
> 3    0.928997
> 4   -4.779622
> 5   14.392722
> 6   20.747600
> 7   -8.764885
> 8   -6.826109
>
> ## now it works fine
>
> In the other direction, similar problems for ranef on lmer models.
> for both directions, quick fix solution is to re-load the package for
> which the ranef statement applies
>
>
> Cheers,
> David
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From bates at stat.wisc.edu  Thu Sep 27 16:21:25 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 27 Sep 2007 09:21:25 -0500
Subject: [R-sig-ME] simulate.lme (nlme)
In-Reply-To: <46FAB4B0.9020207@umich.edu>
References: <46FAB4B0.9020207@umich.edu>
Message-ID: <40e66e0b0709270721n68bda576i278c0e1f2e4242c0@mail.gmail.com>

Your transcript looks peculiar.  It shows require(lme) and you end up
with the nlme package attached.  Does that really work or is it a
misprint?

The reason for the small negative difference in the likelihood values
is because of convergence on the boundary.  It is possible for the
difference in the negative log-likelihoods of the alternative and null
models fit to the same data to be zero.  This corresponds to the
situation where the MLE or REML estimate of one of the variance
components in the alternative model is zero.  When using a numerical
optimization technique that difference will not come out to be exactly
zero, especially given the way that the optimization is done in nlme
package, so you end up with a very small difference that can be
negative or positive.

On 9/26/07, Andrzej Galecki <agalecki at umich.edu> wrote:
> Dear All,
>
> simulate.lme generates an object (list) containing the MLs (and REMLs)
> for null and alternative models,  fitted to simulated data. Since models
> are nested and are fitted to the same data we anticipate that elements
> of the vector difx containing ML differences , i.e. object$alt$ML -
> objectnull$ML, are positive.
>
> In the example below this difference is calculated for  30 simulations.
> I am wondering why some of the elements in difx vector are less than zero.
>
> Thank you
>
> Andrzej Galecki
> University of Michigan
>
> PS. Thank you Professor Bates for your response to my previous question.
>
>
>
>
>  > require(lme)
>  > sessionInfo()
> R version 2.5.0 (2007-04-23)
> i386-pc-mingw32
>
> locale:
> LC_COLLATE=English_United States.1252;LC_CTYPE=English_United
> States.1252;LC_MONETARY=English_United
> States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252
>
> attached base packages:
> [1] "stats"     "graphics"  "grDevices" "utils"     "datasets"
> "methods"   "base"
>
> other attached packages:
>  lattice     nlme
> "0.15-4" "3.1-80"
>
>  > orthSim <-simulate.lme(list(fixed = distance ~ age, data = Orthodont,
> + random = ~ 1 | Subject), nsim=30, seed=12345, m2 = list(random = ~ age
> | Subject))
>  > difx <- orthSim$alt$ML - orthSim$null$ML
>  > range(difx)
> [1] -0.006097405  5.222863611
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>



From bates at stat.wisc.edu  Thu Sep 27 19:53:16 2007
From: bates at stat.wisc.edu (Douglas Bates)
Date: Thu, 27 Sep 2007 12:53:16 -0500
Subject: [R-sig-ME] Missing information in "name" column of Random
	effects output
In-Reply-To: <40e66e0b0709260610i224bf71cv13b65f2e886fcb0b@mail.gmail.com>
References: <46F956A0.60602@psy.kuleuven.be>
	<C31EDD13.133A%dafshartous@med.miami.edu>
	<40e66e0b0709260610i224bf71cv13b65f2e886fcb0b@mail.gmail.com>
Message-ID: <40e66e0b0709271053n4f09281bk76338560210c7c45@mail.gmail.com>

Version 0.99875-8 of the lme4 package, with this glich fixed, is now on CRAN.

On 9/26/07, Douglas Bates <bates at stat.wisc.edu> wrote:
> On 9/25/07, David Afshartous <dafshartous at med.miami.edu> wrote:
>
> > Jorge,
>
> > Awhile back I think I noticed a similar issue. I don't recall if I was able
> > to do anything different w/ the lmer statement to fix it. In any event, my
> > guess is that the first term corresponds to the intercept RE and the second
> > to the slope RE.  Looking at the estimated RE's themselves supports this:
>
> Jorge is correct that the name column is no longer being filled out
> and David is correct that the order of variance components corresponds
> to the order of the terms in the model matrix for the random effects
> term.  Thanks to both of you for the report.
>
> At some point I changed where the names are stored and I forgot to
> update the VarCorr method accordingly.  I will release a new version
> with this fixed.
>
> > > ranef(fm1)
> > An object of class ?ranef.lmer?
> > [[1]]
> >     (Intercept)        Days
> > 308   2.2713451   9.1966961
> > 309 -40.3825921  -8.6223099
> > 310 -38.9403378  -5.4521894
> > 330  23.6656443  -4.8100611
> > 331  22.2391295  -3.0662861
> > 332   9.0324969  -0.2709760
> > 333  16.8277808  -0.2214775
> > 334  -7.2256113   1.0733822
> > 335  -0.3503176 -10.7492136
> > 337  34.8784025   8.6302064
> > 349 -25.1898574   1.1699674
> > 350 -13.0500361   6.6107496
> > 351   4.5697621  -3.0138529
> > 352  20.8539011   3.5376139
> > 369   3.2744289   0.8723798
> > 370 -25.5865985   4.8179542
> > 371   0.8049003  -0.9877807
> > 372  12.3075594   1.2851975
>
> > > fm1.junk = ranef(fm1)[[1]]
> > > int.ranef  = fm1.junk[,1]
> > > slope.ranef  = fm1.junk[,2]
> > > var(int.ranef)
> > [1] 465.8012
> > > var(slope.ranef)
> > [1] 29.75055
>
> > On 9/25/07 2:42 PM, "Jorge Gonz?lez" <jorge.gonzalez at psy.kuleuven.be> wrote:
> >
> > > Dear all,
> > >
> > > My apologies if this has been discussed before. When estimating a model
> > > with lmer, I can't see anymore the contents of the "name" column in the
> > > Random effects part of the output. See the example below
> > >
> > > ###### begin example ###################
> > >> sessionInfo()
> > > R version 2.5.1 (2007-06-27)
> > > i386-pc-mingw32
> > >
> > > locale:
> > > LC_COLLATE=Dutch_Belgium.1252;LC_CTYPE=Dutch_Belgium.1252;LC_MONETARY=Dutch_Be
> > > lgium.1252;LC_NUMERIC=C;LC_TIME=Dutch_Belgium.1252
> > >
> > > attached base packages:
> > > [1] "stats"     "graphics"  "grDevices" "utils"     "datasets"
> > > "methods"   "base"
> > >
> > > other attached packages:
> > >         lme4       Matrix      lattice
> > >  "0.99875-7" "0.999375-2"     "0.16-5"
> > >> fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy)
> > >> fm1
> > > Linear mixed-effects model fit by REML
> > > Formula: Reaction ~ Days + (Days | Subject)
> > >    Data: sleepstudy
> > >   AIC  BIC logLik MLdeviance REMLdeviance
> > >  1754 1770 -871.8       1752         1744
> > > Random effects:
> > >  Groups   Name Variance  Std.Dev. Corr
> > >  Subject             610.835  24.7151
> > >                             35.056   5.9208  0.067
> > >  Residual            655.066  25.5943
> > > number of obs: 180, groups: Subject, 18
> > >
> > > Fixed effects:
> > >                  Estimate   Std. Error t value
> > > (Intercept)  251.405      6.820   36.86
> > > Days            10.467      1.546    6.77
> > >
> > > Correlation of Fixed Effects:
> > >      (Intr)
> > > Days -0.137
> > >>
> > > #################### end example ##################
> > > How can I know which variance correspond to the subject  random
> > > intercept and which one to the subject slope Days? As far as I remember
> > > this information was available in previous versions. Is this a bug?
> > >
> > > Thank you very much in advance
> > >
> > > Jorge
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>



