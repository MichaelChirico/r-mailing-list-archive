From d@r|zopou|o@ @end|ng |rom er@@mu@mc@n|  Mon Apr  1 13:09:24 2019
From: d@r|zopou|o@ @end|ng |rom er@@mu@mc@n| (D. Rizopoulos)
Date: Mon, 1 Apr 2019 11:09:24 +0000
Subject: [R-sig-ME] choice of prediction error calculations for zero
 inflated model
In-Reply-To: <652135489.13963702.1554042005410@mail.yahoo.com>
References: <1734950256.13655666.1553950166796.ref@mail.yahoo.com>
 <1734950256.13655666.1553950166796@mail.yahoo.com>
 <7191AFC7255B4F49A30707E39BEAD05FDECF858C@EXCH-RX03.erasmusmc.nl>
 <652135489.13963702.1554042005410@mail.yahoo.com>
Message-ID: <8d349228-3e18-d849-3f7e-7703b5a8e4cc@erasmusmc.nl>

Andras,

Thanks for sharing the code.

I actually realized that there is a mistake in my implementation for 
zero-inflated model. Namely, the call to the predict() method in 
scoring_rules() provides the mean response, which in the case of 
zero-inflated models is

(1 - pi) * mean_response_non-zero_part,

where pi is the probability of being in the zero-part. But in the 
specification of prob_fun(), 'mean' should be the 
"mean_response_non-zero_part" not multiplied by (1 - pi).

You could also check that in the version with pscl.

Best,
Dimitris



On 3/31/2019 4:20 PM, Andras Farkas wrote:
> Dimitris,
> 
> thank you, very helpful.... I took a look at your scoring_rules function and attempted to "re-write" it for zero inflated poisson based on output of pscl predict models, would you mind taking a quick look, maybe it will become useful for someone else eventually:
> 
> library(caret)
> library(pscl)
> data("bioChemists", package = "pscl")
> split=0.7
> inTrain <- createDataPartition(bioChemists[,1], p=split, list=FALSE)
> training <- bioChemists[ inTrain,]
> test <- bioChemists[-inTrain,]
> fm_zip2 <- zeroinfl(art ~ . | ., data = training)
> 
> y <-test$art
> n <- length(y)
> max_count<-5000
> 
> max_count <- rep(max_count, length.out = n)
> prob_fun <- function (x, mean, pis) {
>  ? ? ind0 <- x == 0
>  ? ? out <- (1 - pis) * dpois(x, lambda = mean)
>  ? ? out[ind0] <- pis + out[ind0]
>  ? ? out
>  ? }
> 
> max_count_seq <- lapply(max_count, seq, from = 0)
> pred <- predict(fm_zip2, newdata = test, type = "response")
> pred_zi <- predict(fm_zip2, newdata = test, type="zero")? #zero probs equal to your zi_probs? attribute generated by predict.MixMod?.
> 
> logarithmic <- quadratic <- spherical <- numeric(n)
> for (i in seq_len(n)) {
>  ? p_y <- prob_fun(y[i], mean = pred[i], pis = pred_zi[i])
>  ? quadrat_p <- sum(prob_fun(max_count_seq[[i]], mean = pred[i],
>  ? ? ? ? ? ? ? ? ? ? ? ? ? ? pis = pred_zi[i])^2)
>  ? logarithmic[i] <- log(p_y)
>  ? quadratic[i] <- 2 * p_y + quadrat_p
>  ? spherical[i] <- p_y / sqrt(quadrat_p)
> }
> result <- data.frame(logarithmic = logarithmic, quadratic = quadratic,
>  ? ? ? ? ? ? ? ? ? ? ?spherical = spherical)
> 
> thanks
> 
> Andras
> 
> 
> 
> 
> On Saturday, March 30, 2019, 9:25:25 AM EDT, D. Rizopoulos <d.rizopoulos at erasmusmc.nl> wrote:
> 
> 
> 
> 
> 
> 
> You could have a look at proper scoring rules:?https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fen.m.wikipedia.org%2Fwiki%2FScoring_rule&amp;data=02%7C01%7Cd.rizopoulos%40erasmusmc.nl%7Cfedc913de8ea400e48d808d6b5e3fae5%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C0%7C636896388107783285&amp;sdata=kPRwQj5q68TWZTZFIEWw6FJHY%2FlM3XaCu3W91otbwZQ%3D&amp;reserved=0
> 
> 
> 
> For an example in mixed models check this example in the GLMMadaptive package:?https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fdrizopoulos.github.io%2FGLMMadaptive%2Farticles%2FDynamic_Predictions.html&amp;data=02%7C01%7Cd.rizopoulos%40erasmusmc.nl%7Cfedc913de8ea400e48d808d6b5e3fae5%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C0%7C636896388107793294&amp;sdata=XCW3fbJk6sBLMiFOt1ccrgB93waO07iRcn9%2BK6wTcj4%3D&amp;reserved=0
> 
> 
> 
> 
> Best,
> 
> Dimitris
> 
> 
> Sent with my iPhone - apologies for typos
> 
> 
> 
> 
> 
> From: Andras Farkas via R-sig-mixed-models <r-sig-mixed-models at r-project.org>
> 
> Date: Saturday, 30 Mar 2019, 13:49
> 
> To: R-sig-mixed-models <r-sig-mixed-models at r-project.org>
> 
> Subject: [R-sig-ME] choice of prediction error calculations for zero inflated model
> 
> 
> 
>    
> Hello All,
> 
> thought I would reach out to see if you have some guidance on the following: I am working with a zero inflated data set and fitting models that should be reasonable to model such data (zeroinfl() and hurdle() from pscl, mixtures from flexmix, glm.nb, etc) and trying to compare model predictive performance based on a validation data set (70% of all data was used to train and the renaming 30% for validation)... This is not necessarily a coding question but rather a stat oriented perhaps although a working example would be helpful, if there is one: I have looked extensively to see what is in the literature for measures of predictive performance of zero inflated models based on a validation data set to compare observed vs predicted responses for count data, but could not come up with much. I am familiar with general measures of performance, like RMSE, MAE, etc but finding not much on it's appropriateness for use in my setting. Some references point towards adjusted/pseudo r squared approaches but most references are to evaluate model fit during model development vs predictive performance using a validation set... Any thoughts, directions you may be able to help me with?
> 
> much appreciate your input...
> 
> thanks,
> 
> Andras
> 
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=02%7C01%7Cd.rizopoulos%40erasmusmc.nl%7Cfedc913de8ea400e48d808d6b5e3fae5%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C0%7C636896388107793294&amp;sdata=yScrIOYFZ1QYNKF7Jsv3Mkq%2BiQK75xs%2BYi7sZAnsElU%3D&amp;reserved=0
> 
> 
> 
> 

-- 
Dimitris Rizopoulos
Professor of Biostatistics
Department of Biostatistics
Erasmus University Medical Center

Address: PO Box 2040, 3000 CA Rotterdam, the Netherlands
Tel: +31/(0)10/7043478
Fax: +31/(0)10/7043014
Web (personal): http://www.drizopoulos.com/
Web (work): http://www.erasmusmc.nl/biostatistiek/
Blog: http://iprogn.blogspot.nl/

From 113499328 @end|ng |rom um@||@ucc@|e  Mon Apr  1 13:56:39 2019
From: 113499328 @end|ng |rom um@||@ucc@|e (Ronan James Osullivan)
Date: Mon, 1 Apr 2019 12:56:39 +0100
Subject: [R-sig-ME] 
 Unrealistic coefficient values from an MCMCglmm mixed model
Message-ID: <CAO1C-jOUncho1Qm81rUX2e4sMc8b0K-YOE1-LDHxY2mCZFyHcQ@mail.gmail.com>

Dear forum,

I am struggling with the interpretation of the coefficients from a glmm
implemented using MCMCglmm. My data set has lifetime reproductive success
(LRS) for individual fish and associated climatic variables (NAO and
Temperature) are indexed to each fish. I also know the genetic type of each
fish (A or B). In total, I have 2938 observations with 1321 A fish and 1671
B fish.

I ran the following model:

model<- MCMCglmm(LRS~GeneticType*NAO+
                             GeneticType *Temp,
                          random = ~Year_of_Spawning,
                          family = "poisson",
                          data = data,
                          verbose = TRUE,
                          nitt = 1010000, burnin = 1000, thin = 1000)

Which gave the following summary:

 G-structure:  ~Year_of_Spawning

                                 post.mean     l-95% CI        u-95% CI
  eff.samp
Year_of_Spawning       0.792            0.1521            1.934
1111

 R-structure:  ~units

                              post.mean         l-95% CI        u-95% CI
 eff.samp
       units                  1.257                 1.029
1.488         1447

 Location effects: LRS ~  GeneticType *NAO + GeneticType * Temp-1

                                     post.mean      l-95% CI      u-95% CI
   eff.samp    pMCMC
GeneticTypeA                 5.5510        -4.5345        15.9627
 1009.0      0.2577
GeneticTypeB                -2.8334      -10.6020         8.0720
1009.0     0.4916
NAO                                0.6995        -0.6520         1.9512
        918.3     0.2220
Temp                              -8.2807      -18.7522         1.8865
    1009.0     0.0991 .
GeneticTypeB:NAO       -0.7729         -1.2302       -0.3119
 1009.0   <0.001 ***
GeneticTypeB:Temp       9.8697          4.7849        15.4317
 1009.0   <0.001 ***

My issue is that the predicted LRS values for Genetic Type A are far too
high. The intercept for A fish is 5.551, and exp(5.551) = expected mean for
H fish when Temp=0 and NAO = 0 is 244.7. When I solve for LRS for Type A
fish at a given NAO or temperature (holding the other one constant), I get
incredibly high values.

The predicted LRS for Genetic Type B is exp(-2.8334)=0.05881255 which is
far more realistic for my study system

Am I somehow mis-specifying the model or mis-calculating LRS with respect
to each genetic type?

Cheers,
Ronan



-- 
Ronan O'Sullivan | Ph.D student | School of Biological, Earth and
Environmental Sciences, University College Cork, Ireland |
http://fisheye.ucc.ie/toms-team/  <http://fisheye.ucc.ie/toms-team/>

Irish Ecological Association - Ordinary Committee Member

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Mon Apr  1 18:17:23 2019
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Mon, 1 Apr 2019 12:17:23 -0400
Subject: [R-sig-ME] 
 Unrealistic coefficient values from an MCMCglmm mixed model
In-Reply-To: <CAO1C-jOUncho1Qm81rUX2e4sMc8b0K-YOE1-LDHxY2mCZFyHcQ@mail.gmail.com>
References: <CAO1C-jOUncho1Qm81rUX2e4sMc8b0K-YOE1-LDHxY2mCZFyHcQ@mail.gmail.com>
Message-ID: <ddc3b14f-b652-68d2-8c2d-77c1effb551d@gmail.com>

  Hard to say without more information, but it also looks like you have
extremely wide confidence  on your GeneticTypeA estimate (-4.5345,
15.9627).  A few questions/things that look fishy:

* MCMCglmm is reporting results for both "GeneticTypeA" and
"GeneticTypeB", which suggests that it is using a *third* level (maybe
some sort of blank level/typo?) as the baseline.  What is
levels(data$GeneticType) (or table(data$GeneticType) ?)

* is one of your variables (e.g. Temp) a continuous predictor whose mean
is far from zero, in which case the main effects will be reported at an
unrealistic level?


On 2019-04-01 7:56 a.m., Ronan James Osullivan wrote:
> Dear forum,
> 
> I am struggling with the interpretation of the coefficients from a glmm
> implemented using MCMCglmm. My data set has lifetime reproductive success
> (LRS) for individual fish and associated climatic variables (NAO and
> Temperature) are indexed to each fish. I also know the genetic type of each
> fish (A or B). In total, I have 2938 observations with 1321 A fish and 1671
> B fish.
> 
> I ran the following model:
> 
> model<- MCMCglmm(LRS~GeneticType*NAO+
>                              GeneticType *Temp,
>                           random = ~Year_of_Spawning,
>                           family = "poisson",
>                           data = data,
>                           verbose = TRUE,
>                           nitt = 1010000, burnin = 1000, thin = 1000)
> 
> Which gave the following summary:
> 
>  G-structure:  ~Year_of_Spawning
> 
>                                  post.mean     l-95% CI        u-95% CI
>   eff.samp
> Year_of_Spawning       0.792            0.1521            1.934
> 1111
> 
>  R-structure:  ~units
> 
>                               post.mean         l-95% CI        u-95% CI
>  eff.samp
>        units                  1.257                 1.029
> 1.488         1447
> 
>  Location effects: LRS ~  GeneticType *NAO + GeneticType * Temp-1
> 
>                                      post.mean      l-95% CI      u-95% CI
>    eff.samp    pMCMC
> GeneticTypeA                 5.5510        -4.5345        15.9627
>  1009.0      0.2577
> GeneticTypeB                -2.8334      -10.6020         8.0720
> 1009.0     0.4916
> NAO                                0.6995        -0.6520         1.9512
>         918.3     0.2220
> Temp                              -8.2807      -18.7522         1.8865
>     1009.0     0.0991 .
> GeneticTypeB:NAO       -0.7729         -1.2302       -0.3119
>  1009.0   <0.001 ***
> GeneticTypeB:Temp       9.8697          4.7849        15.4317
>  1009.0   <0.001 ***
> 
> My issue is that the predicted LRS values for Genetic Type A are far too
> high. The intercept for A fish is 5.551, and exp(5.551) = expected mean for
> H fish when Temp=0 and NAO = 0 is 244.7. When I solve for LRS for Type A
> fish at a given NAO or temperature (holding the other one constant), I get
> incredibly high values.
> 
> The predicted LRS for Genetic Type B is exp(-2.8334)=0.05881255 which is
> far more realistic for my study system
> 
> Am I somehow mis-specifying the model or mis-calculating LRS with respect
> to each genetic type?
> 
> Cheers,
> Ronan
> 
> 
>


From 113499328 @end|ng |rom um@||@ucc@|e  Mon Apr  1 18:45:43 2019
From: 113499328 @end|ng |rom um@||@ucc@|e (Ronan James Osullivan)
Date: Mon, 1 Apr 2019 17:45:43 +0100
Subject: [R-sig-ME] 
 Unrealistic coefficient values from an MCMCglmm mixed model
Message-ID: <CAO1C-jM_kRzAM0s_LxYKNuW07pzGcZSO6JYTCzb1KLW7F7EWjw@mail.gmail.com>

Hi Ben,

In my model, I have set the intercepts for GeneticType so that B isn't
relative to A (using "-1"). There are only 2 levels to GeneticType.
Apologies for the confusion.

The correct model should read:
model<- MCMCglmm(LRS~GeneticType*NAO+
                             GeneticType *Temp-1,
                          random = ~Year_of_Spawning,
                          family = "poisson",
                          data = data,
                          verbose = TRUE,
                          nitt = 1010000, burnin = 1000, thin = 1000)

Regards Temp, it is mean-centred whereas NAO wasn't. I re-ran the model
with a mean-centred NAO variable and it made no difference.

Cheers,
Ronan


-- 
Ronan O'Sullivan | Ph.D student | School of Biological, Earth and
Environmental Sciences, University College Cork, Ireland |
http://fisheye.ucc.ie/toms-team/  <http://fisheye.ucc.ie/toms-team/>

Irish Ecological Association - Ordinary Committee Member

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Mon Apr  1 19:36:39 2019
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Mon, 1 Apr 2019 13:36:39 -0400
Subject: [R-sig-ME] 
 Unrealistic coefficient values from an MCMCglmm mixed model
In-Reply-To: <CAO1C-jM_kRzAM0s_LxYKNuW07pzGcZSO6JYTCzb1KLW7F7EWjw@mail.gmail.com>
References: <CAO1C-jM_kRzAM0s_LxYKNuW07pzGcZSO6JYTCzb1KLW7F7EWjw@mail.gmail.com>
Message-ID: <3358fec5-7124-9646-ee2a-096549d6eeb3@gmail.com>


  OK.  In that case: did you check the MCMC diagnostics (effective
sample size, trace plots, autocorrelation, R-hat/Gelman-Rubin
statistics)?  Is your burn-in long enough?  What results do you get if
you fit a comparable model in a frequentist framework (lme4::glmer,
glmmTMB, GLMMadaptive, etc.)?  What about HMC/Stan engines (brms, rstanarm)?



On 2019-04-01 12:45 p.m., Ronan James Osullivan wrote:
> Hi Ben,
> 
> In my model, I have set the intercepts for GeneticType so that B isn't
> relative to A (using "-1"). There are only 2 levels to GeneticType.
> Apologies for the confusion.
> 
> The correct model should read:
> model<- MCMCglmm(LRS~GeneticType*NAO+
>                              GeneticType *Temp-1,
>                           random = ~Year_of_Spawning,
>                           family = "poisson",
>                           data = data,
>                           verbose = TRUE,
>                           nitt = 1010000, burnin = 1000, thin = 1000)
> 
> Regards Temp, it is mean-centred whereas NAO wasn't. I re-ran the model
> with a mean-centred NAO variable and it made no difference.
> 
> Cheers,
> Ronan
> 
>


From @e@n_m@ce@ch @end|ng |rom hotm@||@com  Mon Apr  1 20:40:56 2019
From: @e@n_m@ce@ch @end|ng |rom hotm@||@com (Sean MacEachern)
Date: Mon, 1 Apr 2019 18:40:56 +0000
Subject: [R-sig-ME] Blue model timing out.
Message-ID: <PSXP216MB0440523D5F49ACCE61FBDA38E9550@PSXP216MB0440.KORP216.PROD.OUTLOOK.COM>

Hi,

I?m having troubles with memory allocation when running a BLUE with approximately 9000 genotypes using LMER or ASREML. I?ve looked at increasing the workspace in ASREML to over 12 gb, and from what I can see I?m only using ~6gb. However, I constantly get errors about insufficient workspace. Conversely, if I fit an animal model with the 9000 genotypes plus 3000 additional parents I can obtain BLUPs without too much trouble. Has anyone experienced any problems fitting BLUE models with reasonably large numbers of genotypes?



One thought I have would be to use tryCatch, and withTimeout to cancel the BLUE model if it didn?t run within a certain time frame, but this doesn?t work with ASREML or LMER.

As an example:



system.time(tryCatch({ asr_blu <- withTimeout( {areml(data=bdat, fixed = Trait~Genotype, random= ~Field+Rep)}, timeout=5,elapsed = 5)}, TimeoutException = function(ex) cat("BLUE Timed out\n")))



BLUE Timed out

user system elapsed

1462.257 10.843 1484.458





The timing shows that CPU and elapsed time is going way longer than the 5 seconds I?ve specified in the withTimeout call. Does the native code in asreml-r not check for user interrupts, which I believe is needed to interrupt the function? Is there another way to kill a function if it goes into a zombie state?



Regards,



Sean MacEachern


	[[alternative HTML version deleted]]


From c@r|@@|re|t@@@br@ndt @end|ng |rom h|@no  Wed Apr  3 07:36:33 2019
From: c@r|@@|re|t@@@br@ndt @end|ng |rom h|@no (Brandt, Carla Freitas)
Date: Wed, 3 Apr 2019 05:36:33 +0000
Subject: [R-sig-ME] Random effects with data collected at different scales
Message-ID: <700474895f4a4c3b91fbddf977a199a0@hi.no>

Dear all,
I'm reviewing a scientific article and have a doubt about an important part of the article. I wonder if any of you could help...
For confidentiality issues, I will illustrate the question with an example.

The authors tracked marine animals and measured residence time (RT) inside imaginary circles along the track (at regular 10 km along the track). The problem is that the size of the circles was different for each animal (meaning that RT for some animals is the time spent in 10 km radius areas for example, while for other animals RT is the time spent in 60 km radius areas).
The authors then fitted a GAM with individual ID as random effect (using s(ID, bs="re") and argue that this will account for the fact that RT was measured at different scales for different individuals. Is this valid? The authors provide this reference:
https://stat.ethz.ch/R-manual/R-devel/library/mgcv/html/random.effects.html

Random effects are often used in telemetry studies to take into account repeated measurements from the same individual and to take into account random intrinsic variability between individuals. Is it valid to use random effects to take into account that data from different individuals were collected at different scales?

Thank you in advance for any help about this.
Best regards,

Carla


	[[alternative HTML version deleted]]


From v|n|c|u@@@@m@|@ @end|ng |rom hotm@||@com  Thu Apr  4 12:36:53 2019
From: v|n|c|u@@@@m@|@ @end|ng |rom hotm@||@com (Vinicius Maia)
Date: Thu, 4 Apr 2019 10:36:53 +0000
Subject: [R-sig-ME] 
 Random effects with data collected at different scales
In-Reply-To: <700474895f4a4c3b91fbddf977a199a0@hi.no>
References: <700474895f4a4c3b91fbddf977a199a0@hi.no>
Message-ID: <MN2PR14MB25419F16A5E406A066164CBEBE500@MN2PR14MB2541.namprd14.prod.outlook.com>

Hi Carla,

It is a little bit odd, I would suggest to use the circle size as a control variable to deal with the circle size effect on the response (if there is).

Best

Obter o Outlook para Android<https://aka.ms/ghei36>

________________________________
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of Brandt, Carla Freitas via R-sig-mixed-models <r-sig-mixed-models at r-project.org>
Sent: Wednesday, April 3, 2019 2:36:33 AM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] Random effects with data collected at different scales

Dear all,
I'm reviewing a scientific article and have a doubt about an important part of the article. I wonder if any of you could help...
For confidentiality issues, I will illustrate the question with an example.

The authors tracked marine animals and measured residence time (RT) inside imaginary circles along the track (at regular 10 km along the track). The problem is that the size of the circles was different for each animal (meaning that RT for some animals is the time spent in 10 km radius areas for example, while for other animals RT is the time spent in 60 km radius areas).
The authors then fitted a GAM with individual ID as random effect (using s(ID, bs="re") and argue that this will account for the fact that RT was measured at different scales for different individuals. Is this valid? The authors provide this reference:
https://stat.ethz.ch/R-manual/R-devel/library/mgcv/html/random.effects.html

Random effects are often used in telemetry studies to take into account repeated measurements from the same individual and to take into account random intrinsic variability between individuals. Is it valid to use random effects to take into account that data from different individuals were collected at different scales?

Thank you in advance for any help about this.
Best regards,

Carla


        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Thu Apr  4 18:32:16 2019
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Thu, 4 Apr 2019 12:32:16 -0400
Subject: [R-sig-ME] 
 Random effects with data collected at different scales
In-Reply-To: <MN2PR14MB25419F16A5E406A066164CBEBE500@MN2PR14MB2541.namprd14.prod.outlook.com>
References: <700474895f4a4c3b91fbddf977a199a0@hi.no>
 <MN2PR14MB25419F16A5E406A066164CBEBE500@MN2PR14MB2541.namprd14.prod.outlook.com>
Message-ID: <4d600220-accd-baf8-5528-fad698c5a805@gmail.com>


  I agree.  Fitting a random effect would presumably help a bit to take
care of the variation in circle radii, but it seems like an odd way to
do it.  If the authors are doing a log-link model or a log-transformed
model, then adding log(radius) as a predictor variable will translate to
fitting a dependence of the form RT ~ radius^b, which also has the nice
property that it can interpolate between b=1 (animals are moving
linearly, so expected time to leave the circle will scale proportionally
to the distance to the edge) and b=2 (animals are random-walking,
expected time scales as the square of the distance).  (If there are
multiple observations per individual, the random effect is needed *in
addition* to a fixed effect of log(r).)

  If the authors are using advanced statistical methods and you're
feeling uncertain of your ability to evaluate them, sometimes editors
will be responsive to a suggestion that the paper should be seen be a
statistical expert in addition to the regular scientific reviewers.

  cheers
    Ben Bolker


On 2019-04-04 6:36 a.m., Vinicius Maia wrote:
> Hi Carla,
> 
> It is a little bit odd, I would suggest to use the circle size as a control variable to deal with the circle size effect on the response (if there is).
> 
> Best
> 
> Obter o Outlook para Android<https://aka.ms/ghei36>
> 
> ________________________________
> From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of Brandt, Carla Freitas via R-sig-mixed-models <r-sig-mixed-models at r-project.org>
> Sent: Wednesday, April 3, 2019 2:36:33 AM
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] Random effects with data collected at different scales
> 
> Dear all,
> I'm reviewing a scientific article and have a doubt about an important part of the article. I wonder if any of you could help...
> For confidentiality issues, I will illustrate the question with an example.
> 
> The authors tracked marine animals and measured residence time (RT) inside imaginary circles along the track (at regular 10 km along the track). The problem is that the size of the circles was different for each animal (meaning that RT for some animals is the time spent in 10 km radius areas for example, while for other animals RT is the time spent in 60 km radius areas).
> The authors then fitted a GAM with individual ID as random effect (using s(ID, bs="re") and argue that this will account for the fact that RT was measured at different scales for different individuals. Is this valid? The authors provide this reference:
> https://stat.ethz.ch/R-manual/R-devel/library/mgcv/html/random.effects.html
> 
> Random effects are often used in telemetry studies to take into account repeated measurements from the same individual and to take into account random intrinsic variability between individuals. Is it valid to use random effects to take into account that data from different individuals were collected at different scales?
> 
> Thank you in advance for any help about this.
> Best regards,
> 
> Carla
> 
> 
>         [[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From john@morrong|e||o @end|ng |rom un|me|b@edu@@u  Fri Apr  5 14:47:40 2019
From: john@morrong|e||o @end|ng |rom un|me|b@edu@@u (John Morrongiello)
Date: Fri, 5 Apr 2019 12:47:40 +0000
Subject: [R-sig-ME] random slopes in gamm4
Message-ID: <MEAPR01MB27600DBF16BFFD037C48FD02C4510@MEAPR01MB2760.ausprd01.prod.outlook.com>

Hi all



I posted this question back in 2015 but unfortunately didn't get a reply. I'd like to use these models again so thought it worth another ask.



Most GAMM examples involve the fitting of a model with just a random intercept (e.g. M1 below). However, I'd like to explore the possibility of each individual (ID) having a different X1 smoother 'slope', or even just linear slope, akin to a random slope in lmer (M2).



M1<-gamm4(response ~ s(X1,k=4), random =~(1|ID),data)

M2<-gamm4(response ~ s(X1,k=4), random =~(X1|ID),data)



However, I'm unsure how to interpret the random slope X1 in M2. If positive, is it an overall increase in smoother 'wriggliness' i.e. increase in edf (opposite for negative)? Or is it something else? Would someone know how to visualise these 'random slopes' so I can get a feel for what is going on?



A manuscript by Pedersen and colleagues has recently been posted on PeeJ that explores related models within the gam function https://peerj.com/preprints/27320/. I'm happy to use these, but still would like to understand the random slope in a gamm4 context.



Cheers



John

	[[alternative HTML version deleted]]


From b|mono@om @end|ng |rom gm@||@com  Fri Apr  5 21:44:26 2019
From: b|mono@om @end|ng |rom gm@||@com (=?UTF-8?B?UmVuw6k=?=)
Date: Fri, 5 Apr 2019 21:44:26 +0200
Subject: [R-sig-ME] random slopes in gamm4
In-Reply-To: <MEAPR01MB27600DBF16BFFD037C48FD02C4510@MEAPR01MB2760.ausprd01.prod.outlook.com>
References: <MEAPR01MB27600DBF16BFFD037C48FD02C4510@MEAPR01MB2760.ausprd01.prod.outlook.com>
Message-ID: <CADcpBHPa-z0+4C4Cq8p_LidgJg=wPYC01oz3nCbqiwozH4uuDw@mail.gmail.com>

Dear John,

I almost tend to say, you should ask Simon Wood, Fabian Scheipl directly :))
but, you know, in the gamm4 manual for formula they say: 'Note that ids for
smooths and fixed smoothing parameters are not supported.'
(Which I do not understand) But later it says:

gamm4 allows the random effects specifiable with lmer to be combined with
any number of any of the (single penalty) smooth terms available in gam from
package mgcv as well as t2 tensor product smooths. Note that the model
comparison on the basis of the (Laplace approximate) log likelihood is
possible with GAMMs fitted by gamm4.

Which I, honestly, again, absolutely do not understand. But it seems that
random slopes are about penalty smooth terms (how much you like them
to...). Interestingly, when clicking on 'gam' (to learn more), it redirects
me to the same page... which almost feels like magic (or buddhist).

And the second part of your question alarms me...  it seems that you want
to analyze residual terms (i.e. random errors, which by frequentist
definition are random), is this the case? Otherwise, whether positive or
negative, the mean of any random effect should be zero, and the residuals
should be normally (or appropriately) distributed. I would argue (as others
do), that any directed hypothesis should be part of the fixed effects. And
maybe the question is, whether there are better packages to do this, and
allow to predict the function parameters you are interested in (In case of
interest, check 'brms' and its non-linear function applications. You might
become happier with this, as it would be on you to define 'positive or
negative', and also with respect to the support.)

:)


Best wishes, Ren?



Am Fr., 5. Apr. 2019 um 14:48 Uhr schrieb John Morrongiello <
john.morrongiello at unimelb.edu.au>:

> Hi all
>
>
>
> I posted this question back in 2015 but unfortunately didn't get a reply.
> I'd like to use these models again so thought it worth another ask.
>
>
>
> Most GAMM examples involve the fitting of a model with just a random
> intercept (e.g. M1 below). However, I'd like to explore the possibility of
> each individual (ID) having a different X1 smoother 'slope', or even just
> linear slope, akin to a random slope in lmer (M2).
>
>
>
> M1<-gamm4(response ~ s(X1,k=4), random =~(1|ID),data)
>
> M2<-gamm4(response ~ s(X1,k=4), random =~(X1|ID),data)
>
>
>
> However, I'm unsure how to interpret the random slope X1 in M2. If
> positive, is it an overall increase in smoother 'wriggliness' i.e. increase
> in edf (opposite for negative)? Or is it something else? Would someone know
> how to visualise these 'random slopes' so I can get a feel for what is
> going on?
>
>
>
> A manuscript by Pedersen and colleagues has recently been posted on PeeJ
> that explores related models within the gam function
> https://peerj.com/preprints/27320/. I'm happy to use these, but still
> would like to understand the random slope in a gamm4 context.
>
>
>
> Cheers
>
>
>
> John
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From c@c@voeten @end|ng |rom hum@|e|denun|v@n|  Sat Apr  6 10:37:59 2019
From: c@c@voeten @end|ng |rom hum@|e|denun|v@n| (Cesko Voeten)
Date: Sat, 6 Apr 2019 10:37:59 +0200
Subject: [R-sig-ME] random slopes in gamm4
In-Reply-To: <CADcpBHPa-z0+4C4Cq8p_LidgJg=wPYC01oz3nCbqiwozH4uuDw@mail.gmail.com>
References: <MEAPR01MB27600DBF16BFFD037C48FD02C4510@MEAPR01MB2760.ausprd01.prod.outlook.com>
 <CADcpBHPa-z0+4C4Cq8p_LidgJg=wPYC01oz3nCbqiwozH4uuDw@mail.gmail.com>
Message-ID: <2c75c9df-c291-dfdc-548b-8c80addaa21b@hum.leidenuniv.nl>

Dear John,

A random slope in gamm4 is the same as a random slope in lme4, i.e. 
(X1|ID) gives you separate linear slopes for X1 by IDs. If X1 is 
numeric, this should be exactly identical to mgcv's s(ID,X1,bs='re').

It sounds like what you really want is a random smooth, which in mgcv is 
called a factor smooth: s(ID,X1,bs='fs',xt=list(k=4),m=1). If you want 
the *smooth* to vary across IDs, this is appropriate. Pass 'm=1' to 
penalize the smooth a little bit more -- this is common for random smooths.

You can read more about this on 
http://www.sfs.uni-tuebingen.de/~jvanrij/Tutorial/GAMM.html. If you use 
a factor smooth, you do not need to add a separate random slope, btw.

Best,
Cesko

Op 05-04-2019 om 21:44 schreef Ren?:
> Dear John,
> 
> I almost tend to say, you should ask Simon Wood, Fabian Scheipl directly :))
> but, you know, in the gamm4 manual for formula they say: 'Note that ids for
> smooths and fixed smoothing parameters are not supported.'
> (Which I do not understand) But later it says:
> 
> gamm4 allows the random effects specifiable with lmer to be combined with
> any number of any of the (single penalty) smooth terms available in gam from
> package mgcv as well as t2 tensor product smooths. Note that the model
> comparison on the basis of the (Laplace approximate) log likelihood is
> possible with GAMMs fitted by gamm4.
> 
> Which I, honestly, again, absolutely do not understand. But it seems that
> random slopes are about penalty smooth terms (how much you like them
> to...). Interestingly, when clicking on 'gam' (to learn more), it redirects
> me to the same page... which almost feels like magic (or buddhist).
> 
> And the second part of your question alarms me...  it seems that you want
> to analyze residual terms (i.e. random errors, which by frequentist
> definition are random), is this the case? Otherwise, whether positive or
> negative, the mean of any random effect should be zero, and the residuals
> should be normally (or appropriately) distributed. I would argue (as others
> do), that any directed hypothesis should be part of the fixed effects. And
> maybe the question is, whether there are better packages to do this, and
> allow to predict the function parameters you are interested in (In case of
> interest, check 'brms' and its non-linear function applications. You might
> become happier with this, as it would be on you to define 'positive or
> negative', and also with respect to the support.)
> 
> :)
> 
> 
> Best wishes, Ren?
> 
> 
> 
> Am Fr., 5. Apr. 2019 um 14:48 Uhr schrieb John Morrongiello <
> john.morrongiello at unimelb.edu.au>:
> 
>> Hi all
>>
>>
>>
>> I posted this question back in 2015 but unfortunately didn't get a reply.
>> I'd like to use these models again so thought it worth another ask.
>>
>>
>>
>> Most GAMM examples involve the fitting of a model with just a random
>> intercept (e.g. M1 below). However, I'd like to explore the possibility of
>> each individual (ID) having a different X1 smoother 'slope', or even just
>> linear slope, akin to a random slope in lmer (M2).
>>
>>
>>
>> M1<-gamm4(response ~ s(X1,k=4), random =~(1|ID),data)
>>
>> M2<-gamm4(response ~ s(X1,k=4), random =~(X1|ID),data)
>>
>>
>>
>> However, I'm unsure how to interpret the random slope X1 in M2. If
>> positive, is it an overall increase in smoother 'wriggliness' i.e. increase
>> in edf (opposite for negative)? Or is it something else? Would someone know
>> how to visualise these 'random slopes' so I can get a feel for what is
>> going on?
>>
>>
>>
>> A manuscript by Pedersen and colleagues has recently been posted on PeeJ
>> that explores related models within the gam function
>> https://peerj.com/preprints/27320/. I'm happy to use these, but still
>> would like to understand the random slope in a gamm4 context.
>>
>>
>>
>> Cheers
>>
>>
>>
>> John
>>
>>          [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From bbo|ker @end|ng |rom gm@||@com  Sat Apr  6 21:52:49 2019
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Sat, 6 Apr 2019 15:52:49 -0400
Subject: [R-sig-ME] random slopes in gamm4
In-Reply-To: <2c75c9df-c291-dfdc-548b-8c80addaa21b@hum.leidenuniv.nl>
References: <MEAPR01MB27600DBF16BFFD037C48FD02C4510@MEAPR01MB2760.ausprd01.prod.outlook.com>
 <CADcpBHPa-z0+4C4Cq8p_LidgJg=wPYC01oz3nCbqiwozH4uuDw@mail.gmail.com>
 <2c75c9df-c291-dfdc-548b-8c80addaa21b@hum.leidenuniv.nl>
Message-ID: <dd232010-d09f-b253-e6de-46b8a8359be1@gmail.com>


 See also:

Pedersen, Eric J., David L. Miller, Gavin L. Simpson, and Noam Ross.
?Hierarchical Generalized Additive Models: An Introduction with Mgcv.?
PeerJ Inc., November 5, 2018.
https://doi.org/10.7287/peerj.preprints.27320v1.


On 2019-04-06 4:37 a.m., Cesko Voeten wrote:
> Dear John,
> 
> A random slope in gamm4 is the same as a random slope in lme4, i.e.
> (X1|ID) gives you separate linear slopes for X1 by IDs. If X1 is
> numeric, this should be exactly identical to mgcv's s(ID,X1,bs='re').
> 
> It sounds like what you really want is a random smooth, which in mgcv is
> called a factor smooth: s(ID,X1,bs='fs',xt=list(k=4),m=1). If you want
> the *smooth* to vary across IDs, this is appropriate. Pass 'm=1' to
> penalize the smooth a little bit more -- this is common for random smooths.
> 
> You can read more about this on
> http://www.sfs.uni-tuebingen.de/~jvanrij/Tutorial/GAMM.html. If you use
> a factor smooth, you do not need to add a separate random slope, btw.
> 
> Best,
> Cesko
> 
> Op 05-04-2019 om 21:44 schreef Ren?:
>> Dear John,
>>
>> I almost tend to say, you should ask Simon Wood, Fabian Scheipl
>> directly :))
>> but, you know, in the gamm4 manual for formula they say: 'Note that
>> ids for
>> smooths and fixed smoothing parameters are not supported.'
>> (Which I do not understand) But later it says:
>>
>> gamm4 allows the random effects specifiable with lmer to be combined with
>> any number of any of the (single penalty) smooth terms available in
>> gam from
>> package mgcv as well as t2 tensor product smooths. Note that the model
>> comparison on the basis of the (Laplace approximate) log likelihood is
>> possible with GAMMs fitted by gamm4.
>>
>> Which I, honestly, again, absolutely do not understand. But it seems that
>> random slopes are about penalty smooth terms (how much you like them
>> to...). Interestingly, when clicking on 'gam' (to learn more), it
>> redirects
>> me to the same page... which almost feels like magic (or buddhist).
>>
>> And the second part of your question alarms me...? it seems that you want
>> to analyze residual terms (i.e. random errors, which by frequentist
>> definition are random), is this the case? Otherwise, whether positive or
>> negative, the mean of any random effect should be zero, and the residuals
>> should be normally (or appropriately) distributed. I would argue (as
>> others
>> do), that any directed hypothesis should be part of the fixed effects.
>> And
>> maybe the question is, whether there are better packages to do this, and
>> allow to predict the function parameters you are interested in (In
>> case of
>> interest, check 'brms' and its non-linear function applications. You
>> might
>> become happier with this, as it would be on you to define 'positive or
>> negative', and also with respect to the support.)
>>
>> :)
>>
>>
>> Best wishes, Ren?
>>
>>
>>
>> Am Fr., 5. Apr. 2019 um 14:48 Uhr schrieb John Morrongiello <
>> john.morrongiello at unimelb.edu.au>:
>>
>>> Hi all
>>>
>>>
>>>
>>> I posted this question back in 2015 but unfortunately didn't get a
>>> reply.
>>> I'd like to use these models again so thought it worth another ask.
>>>
>>>
>>>
>>> Most GAMM examples involve the fitting of a model with just a random
>>> intercept (e.g. M1 below). However, I'd like to explore the
>>> possibility of
>>> each individual (ID) having a different X1 smoother 'slope', or even
>>> just
>>> linear slope, akin to a random slope in lmer (M2).
>>>
>>>
>>>
>>> M1<-gamm4(response ~ s(X1,k=4), random =~(1|ID),data)
>>>
>>> M2<-gamm4(response ~ s(X1,k=4), random =~(X1|ID),data)
>>>
>>>
>>>
>>> However, I'm unsure how to interpret the random slope X1 in M2. If
>>> positive, is it an overall increase in smoother 'wriggliness' i.e.
>>> increase
>>> in edf (opposite for negative)? Or is it something else? Would
>>> someone know
>>> how to visualise these 'random slopes' so I can get a feel for what is
>>> going on?
>>>
>>>
>>>
>>> A manuscript by Pedersen and colleagues has recently been posted on PeeJ
>>> that explores related models within the gam function
>>> https://peerj.com/preprints/27320/. I'm happy to use these, but still
>>> would like to understand the random slope in a gamm4 context.
>>>
>>>
>>>
>>> Cheers
>>>
>>>
>>>
>>> John
>>>
>>> ???????? [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
>> ????[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From @oreg @end|ng |rom y@hoo@com  Sun Apr  7 07:43:15 2019
From: @oreg @end|ng |rom y@hoo@com (Shaul Oreg)
Date: Sun, 7 Apr 2019 05:43:15 +0000 (UTC)
Subject: [R-sig-ME] Multilevel moderated mediation
References: <432391487.774762.1554615795567.ref@mail.yahoo.com>
Message-ID: <432391487.774762.1554615795567@mail.yahoo.com>


Hello,

I am trying to run a multilevel moderated mediation model in R, with datanested in three levels (children, within classes, within schools). All of myvariables are at the individual level, but I still need to account for thenested nature of the data.

In separate analyses of mediation and of moderation I find evidence forindirect effects of the predictor on the outcome, and evidence that mymoderator moderates the effects of the predictor on the mediator. But I?d alsolike to test if the moderator moderates the indirect effect of the predictoron the outcome. Any suggestions as to how I should go about doing this?


Thanks,
Shaul

	[[alternative HTML version deleted]]


From |oke@h@ry@@@ry@99 @end|ng |rom gm@||@com  Thu Apr 11 13:09:36 2019
From: |oke@h@ry@@@ry@99 @end|ng |rom gm@||@com (Lokesh Arya)
Date: Thu, 11 Apr 2019 16:39:36 +0530
Subject: [R-sig-ME] Why is glmmTMP is estimating approx half value for Zero
 inflated Conway maxwell poisson mixed model only for the non Zero part?
Message-ID: <CAJhvOVO1+U2RLxYgs_WxeiqbEC66grFrcvLLMncOJA-cyXsnqQ@mail.gmail.com>

Hi All,

I'm trying to estimate parameter for Zero-inflated Conway Maxwell Poisson
Mixed Model. I'm not getting why GlmmTMP function is giving approx half
value for the non zero effect part and giving nice estimates for the Zero
part and dispersion part?
E.g:- Actual value for intercept is 2.5 and I'm getting 1.21
         for "sexfemale" actual value is 1.2 and I'm getting 0.548342.
somebody, please help me out in this situation?

Thank you

#--------Simulation from ZICOMP mix lambda---------
library(COMPoissonReg)
library(glmmTMB)
set.seed(123)
n <- 100 # number of subjects
K <- 8 # number of measurements per subject
t_max <- 5 # maximum follow-up time
# we constuct a data frame with the design: # everyone has a baseline
measurment, and then measurements at random follow-up times
DF_CMP <- data.frame(id = rep(seq_len(n), each = K),
                     time = c(replicate(n, c(0, sort(runif(K - 1, 0, t_max))))),
                     sex = rep(gl(2, n/2, labels = c("male",
"female")), each = K))
# design matrices for the fixed and random effects non-zero part
X <- model.matrix(~ sex * time, data = DF_CMP)
Z <- model.matrix(~ 1, data = DF_CMP)# design matrices for the fixed
and random effects zero part
X_zi <- model.matrix(~ sex, data = DF_CMP)

betas <- c(2.5 , 1.2 , 2.3, -1.5) # fixed effects coefficients non-zero part
shape <- 2
gammas <- c(-1.5, 0.9) # fixed effects coefficients zero part
D11 <- 0.5 # variance of random intercepts non-zero part
# we simulate random effects
b <- rnorm(n, sd = sqrt(D11))# linear predictor non-zero part
eta_y <- as.vector(X %*% betas + rowSums(Z * b[DF_CMP$id,drop =
FALSE]))# linear predictor zero part
eta_zi <- as.vector(X_zi %*% gammas)
DF_CMP$CMP_y <- rzicmp(n * K, lambda = exp(eta_y), nu = shape, p =
plogis(eta_zi))
hist(DF_CMP$CMP_y)#------ estimation -------------
CMPzicmpm0 = glmmTMB(CMP_y~ sex*time + (1|id) , zi= ~ sex, data =
DF_CMP, family=compois)

summary(CMPzicmpm0)

 Family: compois  ( log )
Formula:          CMP_y ~ sex * time + (1 | id)
Zero inflation:         ~sex
Data: DF_CMP

     AIC      BIC   logLik deviance df.resid
  4586.2   4623.7  -2285.1   4570.2      792

Random effects:

Conditional model:
 Groups Name        Variance Std.Dev.
 id     (Intercept) 0.1328   0.3644
Number of obs: 800, groups:  id, 100

Overdispersion parameter for compois family (): 0.557

Conditional model:
                Estimate Std. Error z value Pr(>|z|)    (Intercept)
 1.217269   0.054297   22.42  < 2e-16 ***
sexfemale       0.548342   0.079830    6.87 6.47e-12 ***
time            1.151549   0.004384  262.70  < 2e-16 ***
sexfemale:time -0.735348   0.009247  -79.52  < 2e-16 ***---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Zero-inflation model:
            Estimate Std. Error z value Pr(>|z|)    (Intercept)
-1.6291     0.1373 -11.866  < 2e-16 ***
sexfemale     0.9977     0.1729   5.771 7.89e-09 ***---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

	[[alternative HTML version deleted]]


From gu|||@ume@|mon@@2 @end|ng |rom gm@||@com  Mon Apr 15 15:35:30 2019
From: gu|||@ume@|mon@@2 @end|ng |rom gm@||@com (Guillaume Adeux)
Date: Mon, 15 Apr 2019 15:35:30 +0200
Subject: [R-sig-ME] Fwd: car::Anova type III for glmer: are very high chi
 square values a sign of overfitting?
In-Reply-To: <CAENiVe-5K1XPupDqK+4s4z1dtSso=qn5Ds=O_gFbUT74Yy2UwA@mail.gmail.com>
References: <CAENiVe-5K1XPupDqK+4s4z1dtSso=qn5Ds=O_gFbUT74Yy2UwA@mail.gmail.com>
Message-ID: <CAENiVe94j49K=ezD8GtjXHGZfBtuUEKzzcWhY65omAH6T=+izQ@mail.gmail.com>

Hello everyone,

My experimental lay out is a split split plot experiment
(block/tillage/nitrogen/cover crop type) replicated on 4 blocks. 2
pseudoreplications were carried out within the experimental units (hence
the last level of nesting) each of the two years.

I am analyzing the effect of these factors (tillage*nitrogen*cover crop
type) on weed biomass.

Up until now, the following model was working just fine:
mod=glmer(dry_bio_weeds_m2+0.001~*block+year+tillage*nitrogen*cover crop*
+(1|block:tillage)+(1|block:tillage:N)+(1|block:tillage:N:CC)+(1|block:year)+(1|block:year:tillage)+(1|block:year:tillage:N)+(1|block:year:tillage:N:CC),family=gaussian(link="sqrt"),control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e5)),data=biomassCC)

However, I also wanted to take into account the variability of cover crop
biomass production because I expect that the relationship between weed and
cover crop biomass is not the same depending on cover crop type (Brassica
vs. Legume) :
mod1=glmer(dry_bio_weeds_m2+0.001~*block+year+dry_bio_cover_m2*tillage*nitrogen*cover
crop*+(1|block:tillage)+(1|block:tillage:N)+(1|block:tillage:N:CC)+(1|block:year)+(1|block:year:tillage)+(1|block:year:tillage:N)+(1|block:year:tillage:N:CC),family=gaussian(link="sqrt"),control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e5)),data=biomassCC_wo_C)
# the control = baresoil was taken out

For each combination of cover crop type, nitrogen level and tillage, 16
observations of cover crop biomass (i.e. dry_bio_cover_m2) are available (4
blocks x 2 points per experimental unit x 2 years). It seems reasonable (at
least to me) to test these slopes. I usually obtain p. values with
monet::test_terms or afex::mixed() but it produces non sensical denominator
d.f. with this model (first sign of overfitting?). However, mod1 shows a 10
point AIC drop compared to a model that would not include
"dry_bio_cover_m2".

To investigate further, I headed toward car::Anova(model, type="III") and
obtained the following table:

Analysis of Deviance Table (Type III Wald chisquare tests)

Response: dry_bio_weeds_m2 + 0.001
                                                              Chisq Df
Pr(>Chisq)
(Intercept)                                   5.3317e+02  1  < 2.2e-16 ***
block                                           8.0032e+00  3  0.0459463 *
year                                             2.7720e-01  1  0.5985096

dry_bio_cover_m2                      *7.8745e+04*  1  < 2.2e-16 ***
tillage                                          1.3815e+01  1  0.0002017
***
N                                                 8.4024e+01  3  < 2.2e-16
***
CC                                              2.7821e+01  2  9.095e-07 ***
dry_bio_cover_m2:tillage           2.6228e+01  1  3.034e-07 ***
dry_bio_cover_m2:N                  *1.3953e+05*  3  < 2.2e-16 ***
tillage:N                                      1.3281e+01  3  0.0040657 **
dry_bio_cover_m2:CC               4.2261e+01  2  6.654e-10 ***
tillage:CC                                   1.3697e+01  2  0.0010613 **
N:CC                                          4.1353e+01  6  2.467e-07 ***
dry_bio_cover_m2:tillage:N       1.7634e+01  3  0.0005234 ***
dry_bio_cover_m2:tillage:CC    7.5090e-01  2  0.6869748
dry_bio_cover_m2:N:CC           4.7310e+01  6  1.623e-08 ***
tillage:N:CC                               1.7857e+01  6  0.0065986 **
dry_bio_cover_m2:tillage:N:CC 3.7262e+01  6  1.565e-06 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

I am no statistician but some of the Chi square values seem particularly
huge (*7.8745e+04 and **1.3953e+05)*. The output plots however seem to back
this up....

Could anyone give me their feedback?

Thank you very much.

Guillaume ADEUX

PS: don't hesitate to ask for complementary information

<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
Virus-free.
www.avast.com
<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
<#m_8799212940511435848_DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>

	[[alternative HTML version deleted]]


From j|ox @end|ng |rom mcm@@ter@c@  Mon Apr 15 16:14:47 2019
From: j|ox @end|ng |rom mcm@@ter@c@ (Fox, John)
Date: Mon, 15 Apr 2019 14:14:47 +0000
Subject: [R-sig-ME] 
 Fwd: car::Anova type III for glmer: are very high chi
 square values a sign of overfitting?
In-Reply-To: <315_1555335354_x3FDZsUY014789_CAENiVe94j49K=ezD8GtjXHGZfBtuUEKzzcWhY65omAH6T=+izQ@mail.gmail.com>
References: <CAENiVe-5K1XPupDqK+4s4z1dtSso=qn5Ds=O_gFbUT74Yy2UwA@mail.gmail.com>
 <315_1555335354_x3FDZsUY014789_CAENiVe94j49K=ezD8GtjXHGZfBtuUEKzzcWhY65omAH6T=+izQ@mail.gmail.com>
Message-ID: <B231E7FF-FE32-44A7-8821-C67FFA2629F0@mcmaster.ca>

Dear Guillaume,

I don't have anything to say about the magnitude of the Wald statistics, which are calculated reasonably straightforwardly from the covariance matrix of the fixed effects, but, AFAICS, you're using the default contr.treatment to generate contrasts for the factors. With that choice, Anova() produces tests for lower-order terms (such as main effects marginal to an interaction) that are essentially nonsense.

So, if for some reason, you really want type-III tests, and if you really did use the default contrasts, then instead use contrasts that are orthogonal in the row-basis of the model matrix, such as contr.sum, contr.helmert, or contr.poly. OTOH, why not use type-II tests, which are the default in Anova()?

I hope that this helps,
 John

  -------------------------------------------------
  John Fox, Professor Emeritus
  McMaster University
  Hamilton, Ontario, Canada
  Web: http::/socserv.mcmaster.ca/jfox

> On Apr 15, 2019, at 9:35 AM, Guillaume Adeux <guillaumesimon.a2 at gmail.com> wrote:
> 
> Hello everyone,
> 
> My experimental lay out is a split split plot experiment
> (block/tillage/nitrogen/cover crop type) replicated on 4 blocks. 2
> pseudoreplications were carried out within the experimental units (hence
> the last level of nesting) each of the two years.
> 
> I am analyzing the effect of these factors (tillage*nitrogen*cover crop
> type) on weed biomass.
> 
> Up until now, the following model was working just fine:
> mod=glmer(dry_bio_weeds_m2+0.001~*block+year+tillage*nitrogen*cover crop*
> +(1|block:tillage)+(1|block:tillage:N)+(1|block:tillage:N:CC)+(1|block:year)+(1|block:year:tillage)+(1|block:year:tillage:N)+(1|block:year:tillage:N:CC),family=gaussian(link="sqrt"),control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e5)),data=biomassCC)
> 
> However, I also wanted to take into account the variability of cover crop
> biomass production because I expect that the relationship between weed and
> cover crop biomass is not the same depending on cover crop type (Brassica
> vs. Legume) :
> mod1=glmer(dry_bio_weeds_m2+0.001~*block+year+dry_bio_cover_m2*tillage*nitrogen*cover
> crop*+(1|block:tillage)+(1|block:tillage:N)+(1|block:tillage:N:CC)+(1|block:year)+(1|block:year:tillage)+(1|block:year:tillage:N)+(1|block:year:tillage:N:CC),family=gaussian(link="sqrt"),control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e5)),data=biomassCC_wo_C)
> # the control = baresoil was taken out
> 
> For each combination of cover crop type, nitrogen level and tillage, 16
> observations of cover crop biomass (i.e. dry_bio_cover_m2) are available (4
> blocks x 2 points per experimental unit x 2 years). It seems reasonable (at
> least to me) to test these slopes. I usually obtain p. values with
> monet::test_terms or afex::mixed() but it produces non sensical denominator
> d.f. with this model (first sign of overfitting?). However, mod1 shows a 10
> point AIC drop compared to a model that would not include
> "dry_bio_cover_m2".
> 
> To investigate further, I headed toward car::Anova(model, type="III") and
> obtained the following table:
> 
> Analysis of Deviance Table (Type III Wald chisquare tests)
> 
> Response: dry_bio_weeds_m2 + 0.001
>                                                              Chisq Df
> Pr(>Chisq)
> (Intercept)                                   5.3317e+02  1  < 2.2e-16 ***
> block                                           8.0032e+00  3  0.0459463 *
> year                                             2.7720e-01  1  0.5985096
> 
> dry_bio_cover_m2                      *7.8745e+04*  1  < 2.2e-16 ***
> tillage                                          1.3815e+01  1  0.0002017
> ***
> N                                                 8.4024e+01  3  < 2.2e-16
> ***
> CC                                              2.7821e+01  2  9.095e-07 ***
> dry_bio_cover_m2:tillage           2.6228e+01  1  3.034e-07 ***
> dry_bio_cover_m2:N                  *1.3953e+05*  3  < 2.2e-16 ***
> tillage:N                                      1.3281e+01  3  0.0040657 **
> dry_bio_cover_m2:CC               4.2261e+01  2  6.654e-10 ***
> tillage:CC                                   1.3697e+01  2  0.0010613 **
> N:CC                                          4.1353e+01  6  2.467e-07 ***
> dry_bio_cover_m2:tillage:N       1.7634e+01  3  0.0005234 ***
> dry_bio_cover_m2:tillage:CC    7.5090e-01  2  0.6869748
> dry_bio_cover_m2:N:CC           4.7310e+01  6  1.623e-08 ***
> tillage:N:CC                               1.7857e+01  6  0.0065986 **
> dry_bio_cover_m2:tillage:N:CC 3.7262e+01  6  1.565e-06 ***
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> 
> I am no statistician but some of the Chi square values seem particularly
> huge (*7.8745e+04 and **1.3953e+05)*. The output plots however seem to back
> this up....
> 
> Could anyone give me their feedback?
> 
> Thank you very much.
> 
> Guillaume ADEUX
> 
> PS: don't hesitate to ask for complementary information
> 
> <https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
> Virus-free.
> www.avast.com
> <https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
> <#m_8799212940511435848_DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From ben@@@c@r|@on @end|ng |rom gm@||@com  Tue Apr 16 03:13:57 2019
From: ben@@@c@r|@on @end|ng |rom gm@||@com (Ben Carlson)
Date: Mon, 15 Apr 2019 21:13:57 -0400
Subject: [R-sig-ME] glmmTMB false convergence
Message-ID: <CAEEm8-NEEZXQf=9SMWGm5WUwAnFtK99nTMhu8uUnBKmJjB77Kg@mail.gmail.com>

Hello,

I'm experiencing an issue with glmmTMB and I can't figure out how to
troubleshoot it. I'm running a model according to Muff et al. 2018:
https://www.biorxiv.org/content/10.1101/411801v2

I have movement observations of multiple animals for multiple breeding
seasons (several thousand observations per animal per year, over 3 years),
and I would like to allow each animal to have a different slope for each
breeding season. This is so that I can test hypotheses regarding responses
to habitat variables among individuals and stability within individuals
across years. "pct_tree" is the habitat variable, representing the
percentage of tree cover.

I'm sorry I can't create a reproducible example, but I don't think I should
post my data to a public forum. Any pointers to how I might troubleshoot
this issue would be very helpful!

I'm running the following model:

TMBStruc <- glmmTMB(y ~ pct_tree + (1|stratum) + (0 + pct_tree |
individual_id:year),family=poisson,data=ssf,doFit=FALSE)
TMBStruc$parameters$theta[1] = log(1e3)
TMBStruc$mapArg = list(theta=factor(c(NA,1)))

The model runs, but I receive the following warning message. Based on the
message, I'm not sure if I should trust my results:

Warning message:
In glmmTMB:::fitTMB(TMBStruc) :
  Model convergence problem; false convergence (8). See
vignette('troubleshooting')

I have searched around but I can't find any information regarding "false
convergence" (including the troubleshooting vignette!).

Please let me know if I can provide any additional information. Thank you
for your help!

Ben

	[[alternative HTML version deleted]]


From mo|||eebrook@ @end|ng |rom gm@||@com  Tue Apr 16 09:00:08 2019
From: mo|||eebrook@ @end|ng |rom gm@||@com (Mollie Brooks)
Date: Tue, 16 Apr 2019 09:00:08 +0200
Subject: [R-sig-ME] 
 Why is glmmTMP is estimating approx half value for Zero
 inflated Conway maxwell poisson mixed model only for the non Zero part?
In-Reply-To: <CAJhvOVO1+U2RLxYgs_WxeiqbEC66grFrcvLLMncOJA-cyXsnqQ@mail.gmail.com>
References: <CAJhvOVO1+U2RLxYgs_WxeiqbEC66grFrcvLLMncOJA-cyXsnqQ@mail.gmail.com>
Message-ID: <CAMu=eMDdKM3v=PFmCB40=gs+N5pHOZnQMGWFpDMHmuBsaZQJ0w@mail.gmail.com>

Families are documented in the helpfile ?family_glmmTMBcompois is the
Conway-Maxwell Poisson parameterized with the exact mean which differs from
the COMPoissonReg package (Sellers & Lotze 2015)
cheers,Mollie

On Thu, Apr 11, 2019 at 7:01 PM Lokesh Arya <lokesharya.arya99 at gmail.com>
wrote:

> Hi All,
>
> I'm trying to estimate parameter for Zero-inflated Conway Maxwell Poisson
> Mixed Model. I'm not getting why GlmmTMP function is giving approx half
> value for the non zero effect part and giving nice estimates for the Zero
> part and dispersion part?
> E.g:- Actual value for intercept is 2.5 and I'm getting 1.21
>          for "sexfemale" actual value is 1.2 and I'm getting 0.548342.
> somebody, please help me out in this situation?
>
> Thank you
>
> #--------Simulation from ZICOMP mix lambda---------
> library(COMPoissonReg)
> library(glmmTMB)
> set.seed(123)
> n <- 100 # number of subjects
> K <- 8 # number of measurements per subject
> t_max <- 5 # maximum follow-up time
> # we constuct a data frame with the design: # everyone has a baseline
> measurment, and then measurements at random follow-up times
> DF_CMP <- data.frame(id = rep(seq_len(n), each = K),
>                      time = c(replicate(n, c(0, sort(runif(K - 1, 0,
> t_max))))),
>                      sex = rep(gl(2, n/2, labels = c("male",
> "female")), each = K))
> # design matrices for the fixed and random effects non-zero part
> X <- model.matrix(~ sex * time, data = DF_CMP)
> Z <- model.matrix(~ 1, data = DF_CMP)# design matrices for the fixed
> and random effects zero part
> X_zi <- model.matrix(~ sex, data = DF_CMP)
>
> betas <- c(2.5 , 1.2 , 2.3, -1.5) # fixed effects coefficients non-zero
> part
> shape <- 2
> gammas <- c(-1.5, 0.9) # fixed effects coefficients zero part
> D11 <- 0.5 # variance of random intercepts non-zero part
> # we simulate random effects
> b <- rnorm(n, sd = sqrt(D11))# linear predictor non-zero part
> eta_y <- as.vector(X %*% betas + rowSums(Z * b[DF_CMP$id,drop =
> FALSE]))# linear predictor zero part
> eta_zi <- as.vector(X_zi %*% gammas)
> DF_CMP$CMP_y <- rzicmp(n * K, lambda = exp(eta_y), nu = shape, p =
> plogis(eta_zi))
> hist(DF_CMP$CMP_y)#------ estimation -------------
> CMPzicmpm0 = glmmTMB(CMP_y~ sex*time + (1|id) , zi= ~ sex, data =
> DF_CMP, family=compois)
>
> summary(CMPzicmpm0)
>
>  Family: compois  ( log )
> Formula:          CMP_y ~ sex * time + (1 | id)
> Zero inflation:         ~sex
> Data: DF_CMP
>
>      AIC      BIC   logLik deviance df.resid
>   4586.2   4623.7  -2285.1   4570.2      792
>
> Random effects:
>
> Conditional model:
>  Groups Name        Variance Std.Dev.
>  id     (Intercept) 0.1328   0.3644
> Number of obs: 800, groups:  id, 100
>
> Overdispersion parameter for compois family (): 0.557
>
> Conditional model:
>                 Estimate Std. Error z value Pr(>|z|)    (Intercept)
>  1.217269   0.054297   22.42  < 2e-16 ***
> sexfemale       0.548342   0.079830    6.87 6.47e-12 ***
> time            1.151549   0.004384  262.70  < 2e-16 ***
> sexfemale:time -0.735348   0.009247  -79.52  < 2e-16 ***---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Zero-inflation model:
>             Estimate Std. Error z value Pr(>|z|)    (Intercept)
> -1.6291     0.1373 -11.866  < 2e-16 ***
> sexfemale     0.9977     0.1729   5.771 7.89e-09 ***---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From gu|||@ume@|mon@@2 @end|ng |rom gm@||@com  Tue Apr 16 10:03:02 2019
From: gu|||@ume@|mon@@2 @end|ng |rom gm@||@com (Guillaume Adeux)
Date: Tue, 16 Apr 2019 10:03:02 +0200
Subject: [R-sig-ME] 
 Fwd: car::Anova type III for glmer: are very high chi
 square values a sign of overfitting?
In-Reply-To: <B231E7FF-FE32-44A7-8821-C67FFA2629F0@mcmaster.ca>
References: <CAENiVe-5K1XPupDqK+4s4z1dtSso=qn5Ds=O_gFbUT74Yy2UwA@mail.gmail.com>
 <315_1555335354_x3FDZsUY014789_CAENiVe94j49K=ezD8GtjXHGZfBtuUEKzzcWhY65omAH6T=+izQ@mail.gmail.com>
 <B231E7FF-FE32-44A7-8821-C67FFA2629F0@mcmaster.ca>
Message-ID: <CAENiVe_5yt4ZkSD44pzMXAA8MjkNzpKSaaRcunWzeB2b3_1WyQ@mail.gmail.com>

Hi John,

Thank you very much for your answer. I am very grateful.

I had indeed set sum contrasts before running car::Anova(mod,type="III")
(i.e. *options(contrasts = c("contr.sum", "contr.poly"))* ).

However, I think the high X? values were due to the unscaled variable
(dry_bio_cover_m2)
which has a very important effect. After centering and scaling this
variable, the output seemed much more reasonable:

Analysis of Deviance Table (Type III Wald chisquare tests)

Response: dry_bio_weeds_m2 + 0.001
                                                                   Chisq Df
Pr(>Chisq)
(Intercept)                                             426.0559  1  <
2.2e-16 ***
block                                                     13.4253  3
0.0038016 **
year                                                       0.5495  1
0.4585110
scale(dry_bio_cover_m2)                  *    82.2881  1  < 2.2e-16 ****
tillage                                                     0.0068  1
0.9343231
N                                                            38.9274  3
1.798e-08 ***
CC                                                         0.6841  2
0.7103247
scale(dry_bio_cover_m2):tillage            7.2857  1  0.0069507 **
scale(dry_bio_cover_m2):N                 * 47.9310  3  2.203e-10 ****
tillage:N                                                 1.5697  3
0.6662878
scale(dry_bio_cover_m2):CC               34.2547  2  3.645e-08 ***
tillage:CC                                              20.2074  2
4.093e-05 ***
N:CC                                                     17.4129  6
0.0078797 **
scale(dry_bio_cover_m2):tillage:N        5.1705  3  0.1597323
scale(dry_bio_cover_m2):tillage:CC     4.3092  2  0.1159493
scale(dry_bio_cover_m2):N:CC            31.7859  6  1.793e-05 ***
tillage:N:CC                                           13.3195  6
0.0382343 *
scale(dry_bio_cover_m2):tillage:N:CC  23.3366  6  0.0006912 ***

Thank you again.

Sincerely,

Guillaume ADEUX


<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
Virus-free.
www.avast.com
<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
<#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>

Le lun. 15 avr. 2019 ? 16:14, Fox, John <jfox at mcmaster.ca> a ?crit :

> Dear Guillaume,
>
> I don't have anything to say about the magnitude of the Wald statistics,
> which are calculated reasonably straightforwardly from the covariance
> matrix of the fixed effects, but, AFAICS, you're using the default
> contr.treatment to generate contrasts for the factors. With that choice,
> Anova() produces tests for lower-order terms (such as main effects marginal
> to an interaction) that are essentially nonsense.
>
> So, if for some reason, you really want type-III tests, and if you really
> did use the default contrasts, then instead use contrasts that are
> orthogonal in the row-basis of the model matrix, such as contr.sum,
> contr.helmert, or contr.poly. OTOH, why not use type-II tests, which are
> the default in Anova()?
>
> I hope that this helps,
>  John
>
>   -------------------------------------------------
>   John Fox, Professor Emeritus
>   McMaster University
>   Hamilton, Ontario, Canada
>   Web: http::/socserv.mcmaster.ca/jfox
>
> > On Apr 15, 2019, at 9:35 AM, Guillaume Adeux <
> guillaumesimon.a2 at gmail.com> wrote:
> >
> > Hello everyone,
> >
> > My experimental lay out is a split split plot experiment
> > (block/tillage/nitrogen/cover crop type) replicated on 4 blocks. 2
> > pseudoreplications were carried out within the experimental units (hence
> > the last level of nesting) each of the two years.
> >
> > I am analyzing the effect of these factors (tillage*nitrogen*cover crop
> > type) on weed biomass.
> >
> > Up until now, the following model was working just fine:
> > mod=glmer(dry_bio_weeds_m2+0.001~*block+year+tillage*nitrogen*cover crop*
> >
> +(1|block:tillage)+(1|block:tillage:N)+(1|block:tillage:N:CC)+(1|block:year)+(1|block:year:tillage)+(1|block:year:tillage:N)+(1|block:year:tillage:N:CC),family=gaussian(link="sqrt"),control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e5)),data=biomassCC)
> >
> > However, I also wanted to take into account the variability of cover crop
> > biomass production because I expect that the relationship between weed
> and
> > cover crop biomass is not the same depending on cover crop type (Brassica
> > vs. Legume) :
> >
> mod1=glmer(dry_bio_weeds_m2+0.001~*block+year+dry_bio_cover_m2*tillage*nitrogen*cover
> >
> crop*+(1|block:tillage)+(1|block:tillage:N)+(1|block:tillage:N:CC)+(1|block:year)+(1|block:year:tillage)+(1|block:year:tillage:N)+(1|block:year:tillage:N:CC),family=gaussian(link="sqrt"),control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e5)),data=biomassCC_wo_C)
> > # the control = baresoil was taken out
> >
> > For each combination of cover crop type, nitrogen level and tillage, 16
> > observations of cover crop biomass (i.e. dry_bio_cover_m2) are available
> (4
> > blocks x 2 points per experimental unit x 2 years). It seems reasonable
> (at
> > least to me) to test these slopes. I usually obtain p. values with
> > monet::test_terms or afex::mixed() but it produces non sensical
> denominator
> > d.f. with this model (first sign of overfitting?). However, mod1 shows a
> 10
> > point AIC drop compared to a model that would not include
> > "dry_bio_cover_m2".
> >
> > To investigate further, I headed toward car::Anova(model, type="III") and
> > obtained the following table:
> >
> > Analysis of Deviance Table (Type III Wald chisquare tests)
> >
> > Response: dry_bio_weeds_m2 + 0.001
> >                                                              Chisq Df
> > Pr(>Chisq)
> > (Intercept)                                   5.3317e+02  1  < 2.2e-16
> ***
> > block                                           8.0032e+00  3  0.0459463
> *
> > year                                             2.7720e-01  1  0.5985096
> >
> > dry_bio_cover_m2                      *7.8745e+04*  1  < 2.2e-16 ***
> > tillage                                          1.3815e+01  1  0.0002017
> > ***
> > N                                                 8.4024e+01  3  <
> 2.2e-16
> > ***
> > CC                                              2.7821e+01  2  9.095e-07
> ***
> > dry_bio_cover_m2:tillage           2.6228e+01  1  3.034e-07 ***
> > dry_bio_cover_m2:N                  *1.3953e+05*  3  < 2.2e-16 ***
> > tillage:N                                      1.3281e+01  3  0.0040657
> **
> > dry_bio_cover_m2:CC               4.2261e+01  2  6.654e-10 ***
> > tillage:CC                                   1.3697e+01  2  0.0010613 **
> > N:CC                                          4.1353e+01  6  2.467e-07
> ***
> > dry_bio_cover_m2:tillage:N       1.7634e+01  3  0.0005234 ***
> > dry_bio_cover_m2:tillage:CC    7.5090e-01  2  0.6869748
> > dry_bio_cover_m2:N:CC           4.7310e+01  6  1.623e-08 ***
> > tillage:N:CC                               1.7857e+01  6  0.0065986 **
> > dry_bio_cover_m2:tillage:N:CC 3.7262e+01  6  1.565e-06 ***
> > ---
> > Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> >
> > I am no statistician but some of the Chi square values seem particularly
> > huge (*7.8745e+04 and **1.3953e+05)*. The output plots however seem to
> back
> > this up....
> >
> > Could anyone give me their feedback?
> >
> > Thank you very much.
> >
> > Guillaume ADEUX
> >
> > PS: don't hesitate to ask for complementary information
> >
> > <
> https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail
> >
> > Virus-free.
> > www.avast.com
> > <
> https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail
> >
> > <#m_8799212940511435848_DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
Virus-free.
www.avast.com
<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
<#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>

	[[alternative HTML version deleted]]


From j|ox @end|ng |rom mcm@@ter@c@  Tue Apr 16 14:52:39 2019
From: j|ox @end|ng |rom mcm@@ter@c@ (Fox, John)
Date: Tue, 16 Apr 2019 12:52:39 +0000
Subject: [R-sig-ME] 
 car::Anova type III for glmer: are very high chi square
 values a sign of overfitting?
In-Reply-To: <CAENiVe_5yt4ZkSD44pzMXAA8MjkNzpKSaaRcunWzeB2b3_1WyQ@mail.gmail.com>
References: <CAENiVe-5K1XPupDqK+4s4z1dtSso=qn5Ds=O_gFbUT74Yy2UwA@mail.gmail.com>
 <315_1555335354_x3FDZsUY014789_CAENiVe94j49K=ezD8GtjXHGZfBtuUEKzzcWhY65omAH6T=+izQ@mail.gmail.com>
 <B231E7FF-FE32-44A7-8821-C67FFA2629F0@mcmaster.ca>
 <CAENiVe_5yt4ZkSD44pzMXAA8MjkNzpKSaaRcunWzeB2b3_1WyQ@mail.gmail.com>
Message-ID: <ADA5CBFE-24AA-4CA3-9778-B5D3E9753811@mcmaster.ca>

Dear Guillaume,

I wasn't aware that the model included a covariate involved in interactions. Centering a covariate in this context is analogous to using contrasts for factors that are orthogonal in the row basis of the model matrix. Otherwise, you're in effect testing differences where the covariate is 0, which may extrapolate far beyond the range of the data. 

The general point is that you should pay attention to the hypotheses that are tested -- or just use type-II tests, which test generally sensible hypotheses.

Best,
 John

  -------------------------------------------------
  John Fox, Professor Emeritus
  McMaster University
  Hamilton, Ontario, Canada
  Web: http::/socserv.mcmaster.ca/jfox

> On Apr 16, 2019, at 4:03 AM, Guillaume Adeux <guillaumesimon.a2 at gmail.com> wrote:
> 
> Hi John,
> 
> Thank you very much for your answer. I am very grateful.
> 
> I had indeed set sum contrasts before running car::Anova(mod,type="III") (i.e. options(contrasts = c("contr.sum", "contr.poly")) ).
> 
> However, I think the high X? values were due to the unscaled variable (dry_bio_cover_m2) which has a very important effect. After centering and scaling this variable, the output seemed much more reasonable:
> 
> Analysis of Deviance Table (Type III Wald chisquare tests)
> 
> Response: dry_bio_weeds_m2 + 0.001
>                                                                    Chisq Df Pr(>Chisq)    
> (Intercept)                                             426.0559  1  < 2.2e-16 ***
> block                                                     13.4253  3  0.0038016 ** 
> year                                                       0.5495  1  0.4585110    
> scale(dry_bio_cover_m2)                      82.2881  1  < 2.2e-16 ***
> tillage                                                     0.0068  1  0.9343231    
> N                                                            38.9274  3  1.798e-08 ***
> CC                                                         0.6841  2  0.7103247    
> scale(dry_bio_cover_m2):tillage            7.2857  1  0.0069507 ** 
> scale(dry_bio_cover_m2):N                  47.9310  3  2.203e-10 ***
> tillage:N                                                 1.5697  3  0.6662878    
> scale(dry_bio_cover_m2):CC               34.2547  2  3.645e-08 ***
> tillage:CC                                              20.2074  2  4.093e-05 ***
> N:CC                                                     17.4129  6  0.0078797 ** 
> scale(dry_bio_cover_m2):tillage:N        5.1705  3  0.1597323    
> scale(dry_bio_cover_m2):tillage:CC     4.3092  2  0.1159493    
> scale(dry_bio_cover_m2):N:CC            31.7859  6  1.793e-05 ***
> tillage:N:CC                                           13.3195  6  0.0382343 *  
> scale(dry_bio_cover_m2):tillage:N:CC  23.3366  6  0.0006912 ***
> 
> Thank you again.
> 
> Sincerely,
> 
> Guillaume ADEUX
> 
> 
> 	Virus-free. www.avast.com
> 
> Le lun. 15 avr. 2019 ? 16:14, Fox, John <jfox at mcmaster.ca> a ?crit :
> Dear Guillaume,
> 
> I don't have anything to say about the magnitude of the Wald statistics, which are calculated reasonably straightforwardly from the covariance matrix of the fixed effects, but, AFAICS, you're using the default contr.treatment to generate contrasts for the factors. With that choice, Anova() produces tests for lower-order terms (such as main effects marginal to an interaction) that are essentially nonsense.
> 
> So, if for some reason, you really want type-III tests, and if you really did use the default contrasts, then instead use contrasts that are orthogonal in the row-basis of the model matrix, such as contr.sum, contr.helmert, or contr.poly. OTOH, why not use type-II tests, which are the default in Anova()?
> 
> I hope that this helps,
>  John
> 
>   -------------------------------------------------
>   John Fox, Professor Emeritus
>   McMaster University
>   Hamilton, Ontario, Canada
>   Web: http::/socserv.mcmaster.ca/jfox
> 
> > On Apr 15, 2019, at 9:35 AM, Guillaume Adeux <guillaumesimon.a2 at gmail.com> wrote:
> > 
> > Hello everyone,
> > 
> > My experimental lay out is a split split plot experiment
> > (block/tillage/nitrogen/cover crop type) replicated on 4 blocks. 2
> > pseudoreplications were carried out within the experimental units (hence
> > the last level of nesting) each of the two years.
> > 
> > I am analyzing the effect of these factors (tillage*nitrogen*cover crop
> > type) on weed biomass.
> > 
> > Up until now, the following model was working just fine:
> > mod=glmer(dry_bio_weeds_m2+0.001~*block+year+tillage*nitrogen*cover crop*
> > +(1|block:tillage)+(1|block:tillage:N)+(1|block:tillage:N:CC)+(1|block:year)+(1|block:year:tillage)+(1|block:year:tillage:N)+(1|block:year:tillage:N:CC),family=gaussian(link="sqrt"),control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e5)),data=biomassCC)
> > 
> > However, I also wanted to take into account the variability of cover crop
> > biomass production because I expect that the relationship between weed and
> > cover crop biomass is not the same depending on cover crop type (Brassica
> > vs. Legume) :
> > mod1=glmer(dry_bio_weeds_m2+0.001~*block+year+dry_bio_cover_m2*tillage*nitrogen*cover
> > crop*+(1|block:tillage)+(1|block:tillage:N)+(1|block:tillage:N:CC)+(1|block:year)+(1|block:year:tillage)+(1|block:year:tillage:N)+(1|block:year:tillage:N:CC),family=gaussian(link="sqrt"),control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e5)),data=biomassCC_wo_C)
> > # the control = baresoil was taken out
> > 
> > For each combination of cover crop type, nitrogen level and tillage, 16
> > observations of cover crop biomass (i.e. dry_bio_cover_m2) are available (4
> > blocks x 2 points per experimental unit x 2 years). It seems reasonable (at
> > least to me) to test these slopes. I usually obtain p. values with
> > monet::test_terms or afex::mixed() but it produces non sensical denominator
> > d.f. with this model (first sign of overfitting?). However, mod1 shows a 10
> > point AIC drop compared to a model that would not include
> > "dry_bio_cover_m2".
> > 
> > To investigate further, I headed toward car::Anova(model, type="III") and
> > obtained the following table:
> > 
> > Analysis of Deviance Table (Type III Wald chisquare tests)
> > 
> > Response: dry_bio_weeds_m2 + 0.001
> >                                                              Chisq Df
> > Pr(>Chisq)
> > (Intercept)                                   5.3317e+02  1  < 2.2e-16 ***
> > block                                           8.0032e+00  3  0.0459463 *
> > year                                             2.7720e-01  1  0.5985096
> > 
> > dry_bio_cover_m2                      *7.8745e+04*  1  < 2.2e-16 ***
> > tillage                                          1.3815e+01  1  0.0002017
> > ***
> > N                                                 8.4024e+01  3  < 2.2e-16
> > ***
> > CC                                              2.7821e+01  2  9.095e-07 ***
> > dry_bio_cover_m2:tillage           2.6228e+01  1  3.034e-07 ***
> > dry_bio_cover_m2:N                  *1.3953e+05*  3  < 2.2e-16 ***
> > tillage:N                                      1.3281e+01  3  0.0040657 **
> > dry_bio_cover_m2:CC               4.2261e+01  2  6.654e-10 ***
> > tillage:CC                                   1.3697e+01  2  0.0010613 **
> > N:CC                                          4.1353e+01  6  2.467e-07 ***
> > dry_bio_cover_m2:tillage:N       1.7634e+01  3  0.0005234 ***
> > dry_bio_cover_m2:tillage:CC    7.5090e-01  2  0.6869748
> > dry_bio_cover_m2:N:CC           4.7310e+01  6  1.623e-08 ***
> > tillage:N:CC                               1.7857e+01  6  0.0065986 **
> > dry_bio_cover_m2:tillage:N:CC 3.7262e+01  6  1.565e-06 ***
> > ---
> > Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> > 
> > I am no statistician but some of the Chi square values seem particularly
> > huge (*7.8745e+04 and **1.3953e+05)*. The output plots however seem to back
> > this up....
> > 
> > Could anyone give me their feedback?
> > 
> > Thank you very much.
> > 
> > Guillaume ADEUX
> > 
> > PS: don't hesitate to ask for complementary information
> > 
> > <https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
> > Virus-free.
> > www.avast.com
> > <https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
> > <#m_8799212940511435848_DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>
> > 
> >       [[alternative HTML version deleted]]
> > 
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
> 	Virus-free. www.avast.com


From c@r@t@|@ @end|ng |rom donder@@ru@n|  Wed Apr 17 18:12:46 2019
From: c@r@t@|@ @end|ng |rom donder@@ru@n| (Catalina Ratala)
Date: Wed, 17 Apr 2019 19:12:46 +0300
Subject: [R-sig-ME] singularity issue in lmer
Message-ID: <E93B3350-1BD7-4B1C-B592-52C8221CFA3F@donders.ru.nl>

Dear List,

I?m trying to make the following model converge without warnings, using the lme4 package:

Variables: Order (3 levels), Valence (2 levels), and Attribute (2 levels) are all factors, Rate is the DV, continuous, 1-10 range.

model_lme4 <- lmer(Rate ~ f_Order*f_Valence + f_Attribute +  (1 + f_Order*f_Valence | Subject), data = data)

summary(model_lme4)

Linear mixed model fit by REML ['lmerMod']
Formula: Rate ~ f_Order * f_Valence + f_Attribute + (1 + f_Order * f_Valence | 
    Subject)
   Data: data
 
REML criterion at convergence: 12167.1
 
Scaled residuals:
    Min      1Q  Median      3Q     Max
-5.0966 -0.5745 -0.0331  0.5851  5.1733
 
Random effects:
 Groups   Name                Variance Std.Dev. Corr                        
 Subject  (Intercept)         0.135654 0.36831                              
          f_Order1            0.002681 0.05178  -0.66                       
          f_Order2            0.003578 0.05982   0.31 -0.92                 
          f_Valence1          0.343519 0.58611   0.35 -0.01 -0.17           
          f_Order1:f_Valence1 0.009916 0.09958  -0.09 -0.49  0.66  0.36     
          f_Order2:f_Valence1 0.001073 0.03276   0.01  0.02 -0.02 -0.88 -0.70
 Residual                     0.974439 0.98714                              
Number of obs: 4237, groups:  Subject, 29
 
Fixed effects:
                      Estimate Std. Error t value
(Intercept)          4.8820728  0.0700895  69.655
f_Order1            -0.0005486  0.0235150  -0.023
f_Order2             0.0220543  0.0241765   0.912
f_Valence1          -1.3284410  0.1099083 -12.087
f_Attribute1         0.0401858  0.0221600   1.813
f_Attribute2        -0.1078952  0.0217247  -4.966
f_Order1:f_Valence1 -0.0157678  0.0283515  -0.556
f_Order2:f_Valence1  0.0552990  0.0223037   2.479
 
Correlation of Fixed Effects:
            (Intr) f_Ord1 f_Ord2 f_Vln1 f_Att1 f_Att2 f_O1:_
f_Order1    -0.263                                         
f_Order2     0.138 -0.578                                   
f_Valence1   0.340 -0.005 -0.077                           
f_Attribut1  0.014 -0.014 -0.024 -0.001                    
f_Attribut2  0.000 -0.007  0.023  0.007 -0.531             
f_Ordr1:_V1 -0.057 -0.131  0.200  0.234  0.016 -0.008      
f_Ordr2:_V1  0.001  0.001 -0.002 -0.237 -0.019  0.027 -0.488
convergence code: 0
boundary (singular) fit: see ?isSingular



My problem is that I get this warning message saying that the model is singular:

boundary (singular) fit: see ?isSingular

 

I used the function isSingular() (package lme4) to test whether actually the warning is valid. It returned TRUE as an outcome, meaning the parameters are on the boundary of the feasible parameter space, and variances of one or more linear combinations of effects are (close to) zero.

I also used allfits() function (afex package) to check whether different optimizers give the same error, which was the case for all the optimizers with which the model converged.

Following different guidelines presented in the literature I tried:

a)     to remove the covariance between random effects, by running the following model:

model_nocov <- lmer(Rate ~ f_Order*f_Valence +  f_Attribute + (0 + f_Order*f_Valence | Subject) + (1 | Subject), data = data);

Linear mixed model fit by REML ['lmerMod']
Formula: Rate ~ f_Order * f_Valence + f_Attribute + (0 + f_Order * f_Valence | 
    Subject) + (1 | Subject)
   Data: data
 
REML criterion at convergence: 11707
 
Scaled residuals:
    Min      1Q  Median      3Q     Max
-5.1014 -0.5736 -0.0361  0.5815  5.1984
 
Random effects:
 Groups    Name                Variance Std.Dev. Corr                        
 Subject   f_Orderfirst        0.000000 0.00000                              
           f_Ordersecond       0.009510 0.09752    NaN                       
           f_Orderthird        0.004304 0.06561    NaN  0.66                 
           f_Valence1          0.105713 0.32514    NaN  0.74  0.68           
           f_Order1:f_Valence1 0.009706 0.09852    NaN  0.83  0.13  0.49     
           f_Order2:f_Valence1 0.001249 0.03534    NaN -0.52 -0.14 -0.82 -0.60
 Subject.1 (Intercept)         0.127141 0.35657                              
 Residual                      0.973996 0.98691                              
Number of obs: 4087, groups:  Subject, 28
 
Fixed effects:
                     Estimate Std. Error t value
(Intercept)          4.873808   0.069807  69.818
f_Order1            -0.005478   0.023784  -0.230
f_Order2             0.028555   0.024044   1.188
f_Valence1          -1.420611   0.063388 -22.411
f_Attribute1         0.048127   0.022588   2.131
f_Attribute2        -0.120467   0.022118  -5.447
f_Order1:f_Valence1 -0.016950   0.028729  -0.590
f_Order2:f_Valence1  0.057331   0.022845   2.510
 
Correlation of Fixed Effects:
            (Intr) f_Ord1 f_Ord2 f_Vln1 f_Att1 f_Att2 f_O1:_
f_Order1    -0.054                                         
f_Order2     0.045 -0.548                                  
f_Valence1   0.103 -0.301  0.255                           
f_Attribut1  0.015 -0.015 -0.025 -0.001                    
f_Attribut2  0.000 -0.004  0.019  0.010 -0.533             
f_Ordr1:_V1  0.053 -0.154  0.260  0.306  0.018 -0.009      
f_Ordr2:_V1 -0.016  0.046 -0.070 -0.233 -0.018  0.028 -0.477
convergence code: 0
boundary (singular) fit: see ?isSingular
 

 

b)     to remove outlier cases;

However, I still got the same warning and the is.singular() indicated that the warnings were to be considered (TRUE).

Moreover, I realized that in this case, what causes the problem are the correlations between the levels of the factor ORDER, which is the one related to my main hypothesis and therefore, I cannot exclude its random slope from the model, as I am interested in its statistical significance and, thus, getting a p-value for it. 

I would like to ask for advice on what I can do to make the model converge without warnings. Is there anything that could be done with the levels of the factor (Order), that seem to be causing the problem? Any other suggestion is, of course, welcomed.



Thank you in advance for your time and help!

 

Best,

Catalina






	[[alternative HTML version deleted]]


From th|erry@onke||nx @end|ng |rom |nbo@be  Wed Apr 17 20:04:13 2019
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Wed, 17 Apr 2019 20:04:13 +0200
Subject: [R-sig-ME] singularity issue in lmer
In-Reply-To: <E93B3350-1BD7-4B1C-B592-52C8221CFA3F@donders.ru.nl>
References: <E93B3350-1BD7-4B1C-B592-52C8221CFA3F@donders.ru.nl>
Message-ID: <CAJuCY5wvOACHmNx8ezDP3nj=dteA1+B1wCee5T90mdHh1g0nAQ@mail.gmail.com>

Dear Catalina,

Your model is too complex for the data. The NaN values in the output are a
hint. I see two solutions. 1) collect more data. 2) simplify your model.

Ttest if  lmer(Rate ~ f_Order*f_Valence +  f_Attribute + (1 | Subject),
data = data) works.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op wo 17 apr. 2019 om 18:13 schreef Catalina Ratala <c.ratala at donders.ru.nl
>:

> Dear List,
>
> I?m trying to make the following model converge without warnings, using
> the lme4 package:
>
> Variables: Order (3 levels), Valence (2 levels), and Attribute (2 levels)
> are all factors, Rate is the DV, continuous, 1-10 range.
>
> model_lme4 <- lmer(Rate ~ f_Order*f_Valence + f_Attribute +  (1 +
> f_Order*f_Valence | Subject), data = data)
>
> summary(model_lme4)
>
> Linear mixed model fit by REML ['lmerMod']
> Formula: Rate ~ f_Order * f_Valence + f_Attribute + (1 + f_Order *
> f_Valence |
>     Subject)
>    Data: data
>
> REML criterion at convergence: 12167.1
>
> Scaled residuals:
>     Min      1Q  Median      3Q     Max
> -5.0966 -0.5745 -0.0331  0.5851  5.1733
>
> Random effects:
>  Groups   Name                Variance Std.Dev. Corr
>
>  Subject  (Intercept)         0.135654 0.36831
>
>           f_Order1            0.002681 0.05178  -0.66
>
>           f_Order2            0.003578 0.05982   0.31 -0.92
>
>           f_Valence1          0.343519 0.58611   0.35 -0.01 -0.17
>
>           f_Order1:f_Valence1 0.009916 0.09958  -0.09 -0.49  0.66  0.36
>
>           f_Order2:f_Valence1 0.001073 0.03276   0.01  0.02 -0.02 -0.88
> -0.70
>  Residual                     0.974439 0.98714
>
> Number of obs: 4237, groups:  Subject, 29
>
> Fixed effects:
>                       Estimate Std. Error t value
> (Intercept)          4.8820728  0.0700895  69.655
> f_Order1            -0.0005486  0.0235150  -0.023
> f_Order2             0.0220543  0.0241765   0.912
> f_Valence1          -1.3284410  0.1099083 -12.087
> f_Attribute1         0.0401858  0.0221600   1.813
> f_Attribute2        -0.1078952  0.0217247  -4.966
> f_Order1:f_Valence1 -0.0157678  0.0283515  -0.556
> f_Order2:f_Valence1  0.0552990  0.0223037   2.479
>
> Correlation of Fixed Effects:
>             (Intr) f_Ord1 f_Ord2 f_Vln1 f_Att1 f_Att2 f_O1:_
> f_Order1    -0.263
> f_Order2     0.138 -0.578
> f_Valence1   0.340 -0.005 -0.077
> f_Attribut1  0.014 -0.014 -0.024 -0.001
> f_Attribut2  0.000 -0.007  0.023  0.007 -0.531
> f_Ordr1:_V1 -0.057 -0.131  0.200  0.234  0.016 -0.008
> f_Ordr2:_V1  0.001  0.001 -0.002 -0.237 -0.019  0.027 -0.488
> convergence code: 0
> boundary (singular) fit: see ?isSingular
>
>
>
> My problem is that I get this warning message saying that the model is
> singular:
>
> boundary (singular) fit: see ?isSingular
>
>
>
> I used the function isSingular() (package lme4) to test whether actually
> the warning is valid. It returned TRUE as an outcome, meaning the
> parameters are on the boundary of the feasible parameter space, and
> variances of one or more linear combinations of effects are (close to) zero.
>
> I also used allfits() function (afex package) to check whether different
> optimizers give the same error, which was the case for all the optimizers
> with which the model converged.
>
> Following different guidelines presented in the literature I tried:
>
> a)     to remove the covariance between random effects, by running the
> following model:
>
> model_nocov <- lmer(Rate ~ f_Order*f_Valence +  f_Attribute + (0 +
> f_Order*f_Valence | Subject) + (1 | Subject), data = data);
>
> Linear mixed model fit by REML ['lmerMod']
> Formula: Rate ~ f_Order * f_Valence + f_Attribute + (0 + f_Order *
> f_Valence |
>     Subject) + (1 | Subject)
>    Data: data
>
> REML criterion at convergence: 11707
>
> Scaled residuals:
>     Min      1Q  Median      3Q     Max
> -5.1014 -0.5736 -0.0361  0.5815  5.1984
>
> Random effects:
>  Groups    Name                Variance Std.Dev. Corr
>
>  Subject   f_Orderfirst        0.000000 0.00000
>
>            f_Ordersecond       0.009510 0.09752    NaN
>
>            f_Orderthird        0.004304 0.06561    NaN  0.66
>
>            f_Valence1          0.105713 0.32514    NaN  0.74  0.68
>
>            f_Order1:f_Valence1 0.009706 0.09852    NaN  0.83  0.13  0.49
>
>            f_Order2:f_Valence1 0.001249 0.03534    NaN -0.52 -0.14 -0.82
> -0.60
>  Subject.1 (Intercept)         0.127141 0.35657
>
>  Residual                      0.973996 0.98691
>
> Number of obs: 4087, groups:  Subject, 28
>
> Fixed effects:
>                      Estimate Std. Error t value
> (Intercept)          4.873808   0.069807  69.818
> f_Order1            -0.005478   0.023784  -0.230
> f_Order2             0.028555   0.024044   1.188
> f_Valence1          -1.420611   0.063388 -22.411
> f_Attribute1         0.048127   0.022588   2.131
> f_Attribute2        -0.120467   0.022118  -5.447
> f_Order1:f_Valence1 -0.016950   0.028729  -0.590
> f_Order2:f_Valence1  0.057331   0.022845   2.510
>
> Correlation of Fixed Effects:
>             (Intr) f_Ord1 f_Ord2 f_Vln1 f_Att1 f_Att2 f_O1:_
> f_Order1    -0.054
> f_Order2     0.045 -0.548
> f_Valence1   0.103 -0.301  0.255
> f_Attribut1  0.015 -0.015 -0.025 -0.001
> f_Attribut2  0.000 -0.004  0.019  0.010 -0.533
> f_Ordr1:_V1  0.053 -0.154  0.260  0.306  0.018 -0.009
> f_Ordr2:_V1 -0.016  0.046 -0.070 -0.233 -0.018  0.028 -0.477
> convergence code: 0
> boundary (singular) fit: see ?isSingular
>
>
>
>
> b)     to remove outlier cases;
>
> However, I still got the same warning and the is.singular() indicated that
> the warnings were to be considered (TRUE).
>
> Moreover, I realized that in this case, what causes the problem are the
> correlations between the levels of the factor ORDER, which is the one
> related to my main hypothesis and therefore, I cannot exclude its random
> slope from the model, as I am interested in its statistical significance
> and, thus, getting a p-value for it.
>
> I would like to ask for advice on what I can do to make the model converge
> without warnings. Is there anything that could be done with the levels of
> the factor (Order), that seem to be causing the problem? Any other
> suggestion is, of course, welcomed.
>
>
>
> Thank you in advance for your time and help!
>
>
>
> Best,
>
> Catalina
>
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From ben@@@c@r|@on @end|ng |rom gm@||@com  Wed Apr 17 20:36:18 2019
From: ben@@@c@r|@on @end|ng |rom gm@||@com (Ben Carlson)
Date: Wed, 17 Apr 2019 14:36:18 -0400
Subject: [R-sig-ME] R-sig-mixed-models Digest, Vol 148, Issue 9
In-Reply-To: <mailman.17444.770.1555398074.8580.r-sig-mixed-models@r-project.org>
References: <mailman.17444.770.1555398074.8580.r-sig-mixed-models@r-project.org>
Message-ID: <CAEEm8-PjqFJo6veOcDWGqJXyHuGXOp4TrqJSXfch6KXB3y7L9w@mail.gmail.com>

Hello,

Regarding my earlier post, I've fixed an issue with the data (so that
stratum id is unique across the dataset) and I'm now getting two warning
errors. I've tried out various troubleshooting tactics based on the
troubleshooting vignette and google searches, but I still can't figure out
why I'm getting these warnings. I've created a reproducible example below,
and have include the output from the model summary.

If anybody has any suggestions about how I might figure out the problem I
would be most grateful!

#Reproducible example

library(glmmTMB)

download.file('https://www.dropbox.com/s/kdh30gfkwro8ba7/modeldata.rds?dl=1',
'modeldata.rds')
ssf <- readRDS('modeldata.rds')

#Fit model according to Muff et al. 2018:
https://www.biorxiv.org/content/10.1101/411801v2
TMBStruc <- glmmTMB(y ~ pct_tree + (1|stratum) + (0 + pct_tree |
individual_id:year),
                    family=poisson,data=ssf,doFit=FALSE)
TMBStruc$parameters$theta[1] = log(1e3)
TMBStruc$mapArg = list(theta=factor(c(NA,1)))

m <- glmmTMB:::fitTMB(TMBStruc); summary(m)

This is the results of summary:

Warning messages:
1: In glmmTMB:::fitTMB(TMBStruc) :
  Model convergence problem; non-positive-definite Hessian matrix. See
vignette('troubleshooting')
2: In glmmTMB:::fitTMB(TMBStruc) :
  Model convergence problem; false convergence (8). See
vignette('troubleshooting')
 Family: poisson  ( log )
Formula:          y ~ pct_tree + (1 | stratum) + (0 + pct_tree |
individual_id:year)
Data: ssf

     AIC      BIC   logLik deviance df.resid
      NA       NA       NA       NA  2541723

Random effects:

Conditional model:
 Groups             Name        Variance  Std.Dev.
 stratum            (Intercept) 1.000e+06 1000.0000
 individual_id:year pct_tree    4.218e-02    0.2054
Number of obs: 2541726, groups:  stratum, 231204; individual_id:year, 31

Conditional model:
            Estimate Std. Error z value Pr(>|z|)
(Intercept) -3.89638         NA      NA       NA
pct_tree    -0.28095    0.03716   -7.56 4.02e-14 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
Warning message:
In sqrt(diag(vcov)) : NaNs produced



> Message: 3
> Date: Mon, 15 Apr 2019 21:13:57 -0400
> From: Ben Carlson <ben.s.carlson at gmail.com>
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] glmmTMB false convergence
> Message-ID:
>         <CAEEm8-NEEZXQf=
> 9SMWGm5WUwAnFtK99nTMhu8uUnBKmJjB77Kg at mail.gmail.com>
> Content-Type: text/plain; charset="utf-8"
>
> Hello,
>
> I'm experiencing an issue with glmmTMB and I can't figure out how to
> troubleshoot it. I'm running a model according to Muff et al. 2018:
> https://www.biorxiv.org/content/10.1101/411801v2
>
> I have movement observations of multiple animals for multiple breeding
> seasons (several thousand observations per animal per year, over 3 years),
> and I would like to allow each animal to have a different slope for each
> breeding season. This is so that I can test hypotheses regarding responses
> to habitat variables among individuals and stability within individuals
> across years. "pct_tree" is the habitat variable, representing the
> percentage of tree cover.
>
> I'm sorry I can't create a reproducible example, but I don't think I should
> post my data to a public forum. Any pointers to how I might troubleshoot
> this issue would be very helpful!
>
> I'm running the following model:
>
> TMBStruc <- glmmTMB(y ~ pct_tree + (1|stratum) + (0 + pct_tree |
> individual_id:year),family=poisson,data=ssf,doFit=FALSE)
> TMBStruc$parameters$theta[1] = log(1e3)
> TMBStruc$mapArg = list(theta=factor(c(NA,1)))
>
> The model runs, but I receive the following warning message. Based on the
> message, I'm not sure if I should trust my results:
>
> Warning message:
> In glmmTMB:::fitTMB(TMBStruc) :
>   Model convergence problem; false convergence (8). See
> vignette('troubleshooting')
>
> I have searched around but I can't find any information regarding "false
> convergence" (including the troubleshooting vignette!).
>
> Please let me know if I can provide any additional information. Thank you
> for your help!
>
> Ben

	[[alternative HTML version deleted]]


From mo|||eebrook@ @end|ng |rom gm@||@com  Wed Apr 17 20:40:26 2019
From: mo|||eebrook@ @end|ng |rom gm@||@com (Mollie Brooks)
Date: Wed, 17 Apr 2019 20:40:26 +0200
Subject: [R-sig-ME] 
 Why is glmmTMP is estimating approx half value for Zero
 inflated Conway maxwell poisson mixed model only for the non Zero part?
In-Reply-To: <CAMu=eMDdKM3v=PFmCB40=gs+N5pHOZnQMGWFpDMHmuBsaZQJ0w@mail.gmail.com>
References: <CAJhvOVO1+U2RLxYgs_WxeiqbEC66grFrcvLLMncOJA-cyXsnqQ@mail.gmail.com>
 <CAMu=eMDdKM3v=PFmCB40=gs+N5pHOZnQMGWFpDMHmuBsaZQJ0w@mail.gmail.com>
Message-ID: <CAMu=eMBL+OXzRDReK-91mpmzNzH4zZ_VBxTOiinm9OrX+fRV=g@mail.gmail.com>

I forgot to mention, the more recent documentation also includes the
following reference

Huang A (2017). "Mean-parametrized Conway?Maxwell?Poisson regression models
for dispersed counts. " Statistical Modelling 17(6), 1-22.

This paper has a thorough explanation of the parameterization. We chose the
mean parameterization so that the coefficients are comparable to other
distributions such as the Poisson.

cheers,
Mollie

On Tue, Apr 16, 2019 at 9:00 AM Mollie Brooks <mollieebrooks at gmail.com>
wrote:

> Families are documented in the helpfile ?family_glmmTMBcompois is the
> Conway-Maxwell Poisson parameterized with the exact mean which differs from
> the COMPoissonReg package (Sellers & Lotze 2015)
> cheers,Mollie
>
> On Thu, Apr 11, 2019 at 7:01 PM Lokesh Arya <lokesharya.arya99 at gmail.com>
> wrote:
>
>> Hi All,
>>
>> I'm trying to estimate parameter for Zero-inflated Conway Maxwell Poisson
>> Mixed Model. I'm not getting why GlmmTMP function is giving approx half
>> value for the non zero effect part and giving nice estimates for the Zero
>> part and dispersion part?
>> E.g:- Actual value for intercept is 2.5 and I'm getting 1.21
>>          for "sexfemale" actual value is 1.2 and I'm getting 0.548342.
>> somebody, please help me out in this situation?
>>
>> Thank you
>>
>> #--------Simulation from ZICOMP mix lambda---------
>> library(COMPoissonReg)
>> library(glmmTMB)
>> set.seed(123)
>> n <- 100 # number of subjects
>> K <- 8 # number of measurements per subject
>> t_max <- 5 # maximum follow-up time
>> # we constuct a data frame with the design: # everyone has a baseline
>> measurment, and then measurements at random follow-up times
>> DF_CMP <- data.frame(id = rep(seq_len(n), each = K),
>>                      time = c(replicate(n, c(0, sort(runif(K - 1, 0,
>> t_max))))),
>>                      sex = rep(gl(2, n/2, labels = c("male",
>> "female")), each = K))
>> # design matrices for the fixed and random effects non-zero part
>> X <- model.matrix(~ sex * time, data = DF_CMP)
>> Z <- model.matrix(~ 1, data = DF_CMP)# design matrices for the fixed
>> and random effects zero part
>> X_zi <- model.matrix(~ sex, data = DF_CMP)
>>
>> betas <- c(2.5 , 1.2 , 2.3, -1.5) # fixed effects coefficients non-zero
>> part
>> shape <- 2
>> gammas <- c(-1.5, 0.9) # fixed effects coefficients zero part
>> D11 <- 0.5 # variance of random intercepts non-zero part
>> # we simulate random effects
>> b <- rnorm(n, sd = sqrt(D11))# linear predictor non-zero part
>> eta_y <- as.vector(X %*% betas + rowSums(Z * b[DF_CMP$id,drop =
>> FALSE]))# linear predictor zero part
>> eta_zi <- as.vector(X_zi %*% gammas)
>> DF_CMP$CMP_y <- rzicmp(n * K, lambda = exp(eta_y), nu = shape, p =
>> plogis(eta_zi))
>> hist(DF_CMP$CMP_y)#------ estimation -------------
>> CMPzicmpm0 = glmmTMB(CMP_y~ sex*time + (1|id) , zi= ~ sex, data =
>> DF_CMP, family=compois)
>>
>> summary(CMPzicmpm0)
>>
>>  Family: compois  ( log )
>> Formula:          CMP_y ~ sex * time + (1 | id)
>> Zero inflation:         ~sex
>> Data: DF_CMP
>>
>>      AIC      BIC   logLik deviance df.resid
>>   4586.2   4623.7  -2285.1   4570.2      792
>>
>> Random effects:
>>
>> Conditional model:
>>  Groups Name        Variance Std.Dev.
>>  id     (Intercept) 0.1328   0.3644
>> Number of obs: 800, groups:  id, 100
>>
>> Overdispersion parameter for compois family (): 0.557
>>
>> Conditional model:
>>                 Estimate Std. Error z value Pr(>|z|)    (Intercept)
>>  1.217269   0.054297   22.42  < 2e-16 ***
>> sexfemale       0.548342   0.079830    6.87 6.47e-12 ***
>> time            1.151549   0.004384  262.70  < 2e-16 ***
>> sexfemale:time -0.735348   0.009247  -79.52  < 2e-16 ***---
>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>
>> Zero-inflation model:
>>             Estimate Std. Error z value Pr(>|z|)    (Intercept)
>> -1.6291     0.1373 -11.866  < 2e-16 ***
>> sexfemale     0.9977     0.1729   5.771 7.89e-09 ***---
>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>

	[[alternative HTML version deleted]]


From c@c@voeten @end|ng |rom hum@|e|denun|v@n|  Thu Apr 18 09:37:14 2019
From: c@c@voeten @end|ng |rom hum@|e|denun|v@n| (Voeten, C.C.)
Date: Thu, 18 Apr 2019 07:37:14 +0000
Subject: [R-sig-ME] R:  singularity issue in lmer
In-Reply-To: <CAJuCY5wvOACHmNx8ezDP3nj=dteA1+B1wCee5T90mdHh1g0nAQ@mail.gmail.com>
References: <E93B3350-1BD7-4B1C-B592-52C8221CFA3F@donders.ru.nl>
 <CAJuCY5wvOACHmNx8ezDP3nj=dteA1+B1wCee5T90mdHh1g0nAQ@mail.gmail.com>
Message-ID: <D14049CE02C4F54D95360EEC06CE45C50FA349EC@SPMXM08.VUW.leidenuniv.nl>

Hi Catalina,

Another point to note is that the double-bar syntax does not correctly remove correlations between different levels of the same factor, so you did not actually remove *all* correlations. The workaround is easy: use afex::lmer_alt instead of lmer and use the double-bar syntax -- lmer_alt contains a workaround for this issue. Or try using glmmTMB::glmmTMB with the diag() operator.

Good luck,
Cesko

-----Messaggio originale-----
Da: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> Per conto di Thierry Onkelinx via R-sig-mixed-models
Inviato: mercoled? 17 aprile 2019 20:04
A: Catalina Ratala <c.ratala at donders.ru.nl>
Cc: r-sig-mixed-models <r-sig-mixed-models at r-project.org>
Oggetto: Re: [R-sig-ME] singularity issue in lmer

Dear Catalina,

Your model is too complex for the data. The NaN values in the output are a hint. I see two solutions. 1) collect more data. 2) simplify your model.

Ttest if  lmer(Rate ~ f_Order*f_Valence +  f_Attribute + (1 | Subject), data = data) works.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND FOREST Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance thierry.onkelinx at inbo.be Havenlaan 88 bus 73, 1000 Brussel www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher The plural of anecdote is not data. ~ Roger Brinner The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op wo 17 apr. 2019 om 18:13 schreef Catalina Ratala <c.ratala at donders.ru.nl
>:

> Dear List,
>
> I?m trying to make the following model converge without warnings, 
> using the lme4 package:
>
> Variables: Order (3 levels), Valence (2 levels), and Attribute (2 
> levels) are all factors, Rate is the DV, continuous, 1-10 range.
>
> model_lme4 <- lmer(Rate ~ f_Order*f_Valence + f_Attribute +  (1 + 
> f_Order*f_Valence | Subject), data = data)
>
> summary(model_lme4)
>
> Linear mixed model fit by REML ['lmerMod']
> Formula: Rate ~ f_Order * f_Valence + f_Attribute + (1 + f_Order * 
> f_Valence |
>     Subject)
>    Data: data
>
> REML criterion at convergence: 12167.1
>
> Scaled residuals:
>     Min      1Q  Median      3Q     Max
> -5.0966 -0.5745 -0.0331  0.5851  5.1733
>
> Random effects:
>  Groups   Name                Variance Std.Dev. Corr
>
>  Subject  (Intercept)         0.135654 0.36831
>
>           f_Order1            0.002681 0.05178  -0.66
>
>           f_Order2            0.003578 0.05982   0.31 -0.92
>
>           f_Valence1          0.343519 0.58611   0.35 -0.01 -0.17
>
>           f_Order1:f_Valence1 0.009916 0.09958  -0.09 -0.49  0.66  
> 0.36
>
>           f_Order2:f_Valence1 0.001073 0.03276   0.01  0.02 -0.02 -0.88
> -0.70
>  Residual                     0.974439 0.98714
>
> Number of obs: 4237, groups:  Subject, 29
>
> Fixed effects:
>                       Estimate Std. Error t value
> (Intercept)          4.8820728  0.0700895  69.655
> f_Order1            -0.0005486  0.0235150  -0.023
> f_Order2             0.0220543  0.0241765   0.912
> f_Valence1          -1.3284410  0.1099083 -12.087
> f_Attribute1         0.0401858  0.0221600   1.813
> f_Attribute2        -0.1078952  0.0217247  -4.966
> f_Order1:f_Valence1 -0.0157678  0.0283515  -0.556
> f_Order2:f_Valence1  0.0552990  0.0223037   2.479
>
> Correlation of Fixed Effects:
>             (Intr) f_Ord1 f_Ord2 f_Vln1 f_Att1 f_Att2 f_O1:_
> f_Order1    -0.263
> f_Order2     0.138 -0.578
> f_Valence1   0.340 -0.005 -0.077
> f_Attribut1  0.014 -0.014 -0.024 -0.001
> f_Attribut2  0.000 -0.007  0.023  0.007 -0.531
> f_Ordr1:_V1 -0.057 -0.131  0.200  0.234  0.016 -0.008
> f_Ordr2:_V1  0.001  0.001 -0.002 -0.237 -0.019  0.027 -0.488 
> convergence code: 0 boundary (singular) fit: see ?isSingular
>
>
>
> My problem is that I get this warning message saying that the model is
> singular:
>
> boundary (singular) fit: see ?isSingular
>
>
>
> I used the function isSingular() (package lme4) to test whether 
> actually the warning is valid. It returned TRUE as an outcome, meaning 
> the parameters are on the boundary of the feasible parameter space, 
> and variances of one or more linear combinations of effects are (close to) zero.
>
> I also used allfits() function (afex package) to check whether 
> different optimizers give the same error, which was the case for all 
> the optimizers with which the model converged.
>
> Following different guidelines presented in the literature I tried:
>
> a)     to remove the covariance between random effects, by running the
> following model:
>
> model_nocov <- lmer(Rate ~ f_Order*f_Valence +  f_Attribute + (0 + 
> f_Order*f_Valence | Subject) + (1 | Subject), data = data);
>
> Linear mixed model fit by REML ['lmerMod']
> Formula: Rate ~ f_Order * f_Valence + f_Attribute + (0 + f_Order * 
> f_Valence |
>     Subject) + (1 | Subject)
>    Data: data
>
> REML criterion at convergence: 11707
>
> Scaled residuals:
>     Min      1Q  Median      3Q     Max
> -5.1014 -0.5736 -0.0361  0.5815  5.1984
>
> Random effects:
>  Groups    Name                Variance Std.Dev. Corr
>
>  Subject   f_Orderfirst        0.000000 0.00000
>
>            f_Ordersecond       0.009510 0.09752    NaN
>
>            f_Orderthird        0.004304 0.06561    NaN  0.66
>
>            f_Valence1          0.105713 0.32514    NaN  0.74  0.68
>
>            f_Order1:f_Valence1 0.009706 0.09852    NaN  0.83  0.13  0.49
>
>            f_Order2:f_Valence1 0.001249 0.03534    NaN -0.52 -0.14 -0.82
> -0.60
>  Subject.1 (Intercept)         0.127141 0.35657
>
>  Residual                      0.973996 0.98691
>
> Number of obs: 4087, groups:  Subject, 28
>
> Fixed effects:
>                      Estimate Std. Error t value
> (Intercept)          4.873808   0.069807  69.818
> f_Order1            -0.005478   0.023784  -0.230
> f_Order2             0.028555   0.024044   1.188
> f_Valence1          -1.420611   0.063388 -22.411
> f_Attribute1         0.048127   0.022588   2.131
> f_Attribute2        -0.120467   0.022118  -5.447
> f_Order1:f_Valence1 -0.016950   0.028729  -0.590
> f_Order2:f_Valence1  0.057331   0.022845   2.510
>
> Correlation of Fixed Effects:
>             (Intr) f_Ord1 f_Ord2 f_Vln1 f_Att1 f_Att2 f_O1:_
> f_Order1    -0.054
> f_Order2     0.045 -0.548
> f_Valence1   0.103 -0.301  0.255
> f_Attribut1  0.015 -0.015 -0.025 -0.001
> f_Attribut2  0.000 -0.004  0.019  0.010 -0.533
> f_Ordr1:_V1  0.053 -0.154  0.260  0.306  0.018 -0.009
> f_Ordr2:_V1 -0.016  0.046 -0.070 -0.233 -0.018  0.028 -0.477 
> convergence code: 0 boundary (singular) fit: see ?isSingular
>
>
>
>
> b)     to remove outlier cases;
>
> However, I still got the same warning and the is.singular() indicated 
> that the warnings were to be considered (TRUE).
>
> Moreover, I realized that in this case, what causes the problem are 
> the correlations between the levels of the factor ORDER, which is the 
> one related to my main hypothesis and therefore, I cannot exclude its 
> random slope from the model, as I am interested in its statistical 
> significance and, thus, getting a p-value for it.
>
> I would like to ask for advice on what I can do to make the model 
> converge without warnings. Is there anything that could be done with 
> the levels of the factor (Order), that seem to be causing the problem? 
> Any other suggestion is, of course, welcomed.
>
>
>
> Thank you in advance for your time and help!
>
>
>
> Best,
>
> Catalina
>
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

From @ouhey|@@ghebghoub @end|ng |rom gm@||@com  Thu Apr 18 13:14:10 2019
From: @ouhey|@@ghebghoub @end|ng |rom gm@||@com (Souheyla GHEBGHOUB)
Date: Thu, 18 Apr 2019 12:14:10 +0100
Subject: [R-sig-ME] convergence: nearly unidentifiable: very large
 eigenvalue-Rescale variables?
Message-ID: <CAEA998gRS3uC=DStvxqt_XPXD7peV9Yy+n0YVFoBWrhyL3NzPw@mail.gmail.com>

Hi everyone,

I have a continuous predictor, duration, of 28 levels but with a large
variance (from 0 to 400). This inhibits convergence. I used all techniques
mentioned in this link lme4 convergence warnings: troubleshooting
<https://rstudio-pubs-static.s3.amazonaws.com/33653_57fc7b8e5d484c909b615d8633c01d51.html>
but
nothing worked : ( ?
Here is my model:

*mod <- glmer(response~duration + wfpre + sequence + verbalfreq + PoS +
Characters + (1|Subject) + (1|Word), glmerControl(optimizer="bobyqa",
optCtrl = list(maxfun = 2e5)), **data = df, family = 'binomial')*

Could you please assist me with this?
Thank you
Souheyla

	[[alternative HTML version deleted]]


From ph||||p@@|d@y @end|ng |rom mp|@n|  Thu Apr 18 13:41:47 2019
From: ph||||p@@|d@y @end|ng |rom mp|@n| (Phillip Alday)
Date: Thu, 18 Apr 2019 13:41:47 +0200
Subject: [R-sig-ME] convergence: nearly unidentifiable: very large
 eigenvalue-Rescale variables?
In-Reply-To: <CAEA998gRS3uC=DStvxqt_XPXD7peV9Yy+n0YVFoBWrhyL3NzPw@mail.gmail.com>
References: <CAEA998gRS3uC=DStvxqt_XPXD7peV9Yy+n0YVFoBWrhyL3NzPw@mail.gmail.com>
Message-ID: <1c5acb1f-330f-0fba-59d9-19d1abb1e7c0@mpi.nl>

Um, how do you have a continuous predictor with levels? Do you mean that
there are only 28 different/unique observed values within that
continuous predictor?

Did you try applying scale() to duration? Or if duration is a response
time, maybe log()?

How many subjects do you have? How many words? Are they fully crossed?

Best,
Phillip


On 18/4/19 1:14 pm, Souheyla GHEBGHOUB wrote:
> Hi everyone,
> 
> I have a continuous predictor, duration, of 28 levels but with a large
> variance (from 0 to 400). This inhibits convergence. I used all techniques
> mentioned in this link lme4 convergence warnings: troubleshooting
> <https://rstudio-pubs-static.s3.amazonaws.com/33653_57fc7b8e5d484c909b615d8633c01d51.html>
> but
> nothing worked : ( ?
> Here is my model:
> 
> *mod <- glmer(response~duration + wfpre + sequence + verbalfreq + PoS +
> Characters + (1|Subject) + (1|Word), glmerControl(optimizer="bobyqa",
> optCtrl = list(maxfun = 2e5)), **data = df, family = 'binomial')*
> 
> Could you please assist me with this?
> Thank you
> Souheyla
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From ph||||p@@|d@y @end|ng |rom mp|@n|  Thu Apr 18 13:41:47 2019
From: ph||||p@@|d@y @end|ng |rom mp|@n| (Phillip Alday)
Date: Thu, 18 Apr 2019 13:41:47 +0200
Subject: [R-sig-ME] convergence: nearly unidentifiable: very large
 eigenvalue-Rescale variables?
In-Reply-To: <CAEA998gRS3uC=DStvxqt_XPXD7peV9Yy+n0YVFoBWrhyL3NzPw@mail.gmail.com>
References: <CAEA998gRS3uC=DStvxqt_XPXD7peV9Yy+n0YVFoBWrhyL3NzPw@mail.gmail.com>
Message-ID: <c4771632-f128-20ab-051b-55a466b34eb8@mpi.nl>

Um, how do you have a continuous predictor with levels? Do you mean that
there are only 28 different/unique observed values within that
continuous predictor?

Did you try applying scale() to duration? Or if duration is a response
time, maybe log()?

How many subjects do you have? How many words? Are they fully crossed?

Best,
Phillip


On 18/4/19 1:14 pm, Souheyla GHEBGHOUB wrote:
> Hi everyone,
> 
> I have a continuous predictor, duration, of 28 levels but with a large
> variance (from 0 to 400). This inhibits convergence. I used all techniques
> mentioned in this link lme4 convergence warnings: troubleshooting
> <https://rstudio-pubs-static.s3.amazonaws.com/33653_57fc7b8e5d484c909b615d8633c01d51.html>
> but
> nothing worked : ( ?
> Here is my model:
> 
> *mod <- glmer(response~duration + wfpre + sequence + verbalfreq + PoS +
> Characters + (1|Subject) + (1|Word), glmerControl(optimizer="bobyqa",
> optCtrl = list(maxfun = 2e5)), **data = df, family = 'binomial')*
> 
> Could you please assist me with this?
> Thank you
> Souheyla
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From @ouhey|@@ghebghoub @end|ng |rom gm@||@com  Thu Apr 18 15:22:55 2019
From: @ouhey|@@ghebghoub @end|ng |rom gm@||@com (Souheyla GHEBGHOUB)
Date: Thu, 18 Apr 2019 14:22:55 +0100
Subject: [R-sig-ME] convergence: nearly unidentifiable: very large
 eigenvalue-Rescale variables?
In-Reply-To: <ff376d01-e98b-59eb-dd00-7313b6b7a130@mpi.nl>
References: <CAEA998gRS3uC=DStvxqt_XPXD7peV9Yy+n0YVFoBWrhyL3NzPw@mail.gmail.com>
 <ff376d01-e98b-59eb-dd00-7313b6b7a130@mpi.nl>
Message-ID: <CAEA998htbx5j==fKPSJjT6ORWcnttRV47TKWiKq6Ht=WyHgB+Q@mail.gmail.com>

Hi Phillip,

Yes. Duration is a predictor for 28 words. So there are 28 values for
duration, in a range of 0 to 400, e.g. c(0, 10, 0, 320, 8, 35, 2, 400, 10,
2, 0..).
Yes, I applied log() since its a duration in seconds, but values of 0
turned to infin values does the model did not recognise.
I used scale() , though the model converged but it resulted in certain
negative values for duration, I found that the scaling made the values
quite close, no much difference between them and I am worried to what
extent this affects my hypothesis testing that the duration should have an
effect on DV ? I found no significant effect could this be due to scale()
function?

Thank you very much,
Souheyla



On Thu, 18 Apr 2019 at 12:40, Phillip Alday <phillip.alday at mpi.nl> wrote:

>
>
> On 18/4/19 1:14 pm, Souheyla GHEBGHOUB wrote:
> > Hi everyone,
> >
> > I have a continuous predictor, duration, of 28 levels but with a large
> > variance (from 0 to 400).
>
> Um, how do you have a continuous predictor with levels? Do you mean that
> there are only 28 different/unique observed values within that
> continuous predictor?
>
> Did you try applying scale() to duration? Or if duration is a response
> time, maybe log()?
>
> How many subjects do you have? How many words? Are they fully crossed?
>
> Best,
> Phillip
>
>
>
>
>
> This inhibits convergence. I used all techniques
> > mentioned in this link lme4 convergence warnings: troubleshooting
> > <
> https://rstudio-pubs-static.s3.amazonaws.com/33653_57fc7b8e5d484c909b615d8633c01d51.html
> >
> > but
> > nothing worked : ( ?
> > Here is my model:
> >
> > *mod <- glmer(response~duration + wfpre + sequence + verbalfreq + PoS +
> > Characters + (1|Subject) + (1|Word), glmerControl(optimizer="bobyqa",
> > optCtrl = list(maxfun = 2e5)), **data = df, family = 'binomial')*
> >
> > Could you please assist me with this?
> > Thank you
> > Souheyla
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
>

	[[alternative HTML version deleted]]


From @oreg @end|ng |rom y@hoo@com  Thu Apr 18 15:33:06 2019
From: @oreg @end|ng |rom y@hoo@com (Shaul Oreg)
Date: Thu, 18 Apr 2019 13:33:06 +0000 (UTC)
Subject: [R-sig-ME] Multilevel moderated mediation - Take 2
In-Reply-To: <1464111961.1300743.1555401241719@mail.yahoo.com>
References: <CAJhvOVO1+U2RLxYgs_WxeiqbEC66grFrcvLLMncOJA-cyXsnqQ@mail.gmail.com>
 <CAMu=eMDdKM3v=PFmCB40=gs+N5pHOZnQMGWFpDMHmuBsaZQJ0w@mail.gmail.com>
 <1464111961.1300743.1555401241719@mail.yahoo.com>
Message-ID: <136941247.2499058.1555594386045@mail.yahoo.com>

 Hello, I sent the message below a short while ago, and given no response, thought of trying again. Does anyone have an idea how one can test moderation of an indirect effect within a multilevel (nested) data set? (more details below).
Thanks!

    On Tuesday, April 16, 2019, 10:54:01 AM GMT+3, Shaul Oreg <soreg at yahoo.com> wrote:  
 
 Hello,
I am trying to run a multilevel moderated mediation model in R, with data nested in three levels (children, within classes, within schools). All of my variables are at the individual level, but I still need to account for the nested nature of the data.
In separate analyses of mediation and of moderation I find evidence for indirect effects of the predictor on the outcome, and evidence that my moderator moderates the effects of the predictor on the mediator. But I?d also like to test if the moderator moderates the indirect effect of the predictor on the outcome.
Does anyone know if there's a way to do this?

Thanks,
Shaul

  
	[[alternative HTML version deleted]]


From juho@kr|@t|@n@ruohonen @end|ng |rom gm@||@com  Thu Apr 18 16:35:49 2019
From: juho@kr|@t|@n@ruohonen @end|ng |rom gm@||@com (Juho Kristian Ruohonen)
Date: Thu, 18 Apr 2019 17:35:49 +0300
Subject: [R-sig-ME] Anova()'s Wald chisquare test for predictors with df > 1
 in a logistic GLMM
Message-ID: <CAG_dBVeQ7jf3NcojTXish6BOCovAUCE75eW0RUZJCYtnd4H72g@mail.gmail.com>

Hi,

I'm trying to figure out how the Wald chi-square test is performed for a
nominal predictor with more than two levels in the context of a logistic
GLMM. With fixed-effects logistic models, Anova() defaults to a
likelihood-ratio test, but since this requires refitting the model, it
would be too slow for a GLMM, thus Anova() performs Wald chi-square tests
instead. But how are they calculated for a multi-level nominal predictor?

My (un)educated guess is that for each level of the nominal variable, the
z-score is squared and the sum of these squares compared to the right-tail
probability of the chi-squared distribution with DF equal to the number of
levels of the predictor minus one. And indeed this square-the-z approach
seems to correctly reproduce the results of Anova() for predictors with a
single degree of freedom. But I can't make it reproduce the results of
Anova() for predictors with more than one level. Hence my question: how is
the test statistic calculated?

(My logistic GLMM was fit using glmer())

Best,

J

	[[alternative HTML version deleted]]


From thor@ten@@|che|e @end|ng |rom un|-wuerzburg@de  Thu Apr 18 16:59:17 2019
From: thor@ten@@|che|e @end|ng |rom un|-wuerzburg@de (Thorsten Aichele)
Date: Thu, 18 Apr 2019 16:59:17 +0200
Subject: [R-sig-ME] Specification of random effects structure
Message-ID: <02f401d4f5f7$4bd2a410$e377ec30$@uni-wuerzburg.de>

Dear List,

 

I am trying to specify the optimal random effect structure and I am not
sure, if there's a problem with my understanding of the random effects
structure, or with my data, or with none of these two.

 

Design: 

-          Two Levels, Repeated measures (L2 = 140 Participants)

-          Measure of Personality trait 'N' on L2

-          One experimental factor 'Condition' (on L1)

-          The control condition contained 12 Items. The experimental
condition contained another 12 items (Item 1-12 = control group, item 13-24=
experimental group)

-          Each participant answered all the items and all conditions. (Each
item was only answered once)

-          The experimental comparison was:  funny (experimental condition)
vs. not funny (control condition)

-          I have two random factors (participants on Level 2 and items on
level 1)

-          Items are nested under condition (as the items in both conditions
were not the same)

 

Now I want to look for a Cross-Level Interaction of the L2 variable
(personality trait 'N') with the L1 variable 'Condition' (my main
hypothesis)

 

I made the following Random effect structure under the assumption "include
every possible random slope"

                               lme(DV ~ 1 + (1 + Condition|participants) +
(1|Item)  

[I excluded random slope for N on item, as the model did not converge]

 

                               Now I tried to compare this model with a
model with fixed effects + interaction for 'condition' and 'N'

                               lme(DV ~ 1 + Condition*N + (1 +
Condition|participants) + (1|Item)  

                                               -Fixed effects part showed
nonsignificant effect for 'condition' and 'N' 

-Fixed effects part showed a significant interaction effect  Condition:N

-Fixed effect for intercept was also significant

 

Both Models share identical residual variance (1.7450). I have no idea how
this could be possible. The interaction effect is rather small (-.0247), but
I doubt, that an interaction effect could become significant without
explaining any variance.

 

I would be thankful if anyone could help me with this problem

 

Best,

Thorsten Aichele

 

 

 

 

 


	[[alternative HTML version deleted]]


From j|ox @end|ng |rom mcm@@ter@c@  Thu Apr 18 17:26:57 2019
From: j|ox @end|ng |rom mcm@@ter@c@ (Fox, John)
Date: Thu, 18 Apr 2019 15:26:57 +0000
Subject: [R-sig-ME] 
 Anova()'s Wald chisquare test for predictors with df > 1
 in a logistic GLMM
In-Reply-To: <15785_1555598177_x3IEaHPI022364_CAG_dBVeQ7jf3NcojTXish6BOCovAUCE75eW0RUZJCYtnd4H72g@mail.gmail.com>
References: <15785_1555598177_x3IEaHPI022364_CAG_dBVeQ7jf3NcojTXish6BOCovAUCE75eW0RUZJCYtnd4H72g@mail.gmail.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC836B81D7C@FHSDB2D11-2.csu.mcmaster.ca>

Dear Juho,

> -----Original Message-----
> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-
> project.org] On Behalf Of Juho Kristian Ruohonen
> Sent: Thursday, April 18, 2019 10:36 AM
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] Anova()'s Wald chisquare test for predictors with df > 1 in
> a logistic GLMM
> 
> Hi,
> 
> I'm trying to figure out how the Wald chi-square test is performed for a
> nominal predictor with more than two levels in the context of a logistic
> GLMM. With fixed-effects logistic models, Anova() defaults to a likelihood-
> ratio test, but since this requires refitting the model, it would be too slow for a
> GLMM, thus Anova() performs Wald chi-square tests instead. But how are
> they calculated for a multi-level nominal predictor?

For a "type-III" test, Anova() simply calculates the Wald statistic for the hypothesis that all population coefficients in a term, such as the coefficients of contrasts for a factor, are simultaneously 0, not individually 0 as you suggest below, which wouldn't account for the correlation of the coefficients. This test requires just the coefficient estimates and their covariance matrix but, unless you're careful, will test strange hypotheses.

"Type-II" Wald tests are more complicated (though they too are based only on the estimated coefficients and their covariance matrix), but a simple way to describe them is that they are computed to be maximally powerful while obeying the principle of marginality, so that, e.g., a test of a main effect marginal to an interaction ignores that interaction (i.e., assumes that it is 0). This is accomplished by a projection involving nested hypothesis matrices, and to see how it works, you can look at the code for the Anova() function in the sources of the car package.

Best,
 John

-----------------------------------------------------------------
John Fox
Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
Web: https://socialsciences.mcmaster.ca/jfox/



> 
> My (un)educated guess is that for each level of the nominal variable, the z-
> score is squared and the sum of these squares compared to the right-tail
> probability of the chi-squared distribution with DF equal to the number of
> levels of the predictor minus one. And indeed this square-the-z approach
> seems to correctly reproduce the results of Anova() for predictors with a
> single degree of freedom. But I can't make it reproduce the results of
> Anova() for predictors with more than one level. Hence my question: how is
> the test statistic calculated?
> 
> (My logistic GLMM was fit using glmer())
> 
> Best,
> 
> J
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From p@u|@john@on @end|ng |rom g|@@gow@@c@uk  Thu Apr 18 18:18:45 2019
From: p@u|@john@on @end|ng |rom g|@@gow@@c@uk (Paul Johnson)
Date: Thu, 18 Apr 2019 16:18:45 +0000
Subject: [R-sig-ME] 
 Anova()'s Wald chisquare test for predictors with df > 1
 in a logistic GLMM
In-Reply-To: <CAG_dBVeQ7jf3NcojTXish6BOCovAUCE75eW0RUZJCYtnd4H72g@mail.gmail.com>
References: <CAG_dBVeQ7jf3NcojTXish6BOCovAUCE75eW0RUZJCYtnd4H72g@mail.gmail.com>
Message-ID: <8ADA0DBD-9E7F-4EFD-9A35-D41608E14B94@glasgow.ac.uk>

> I'm trying to figure out how the Wald chi-square test is performed for a
> nominal predictor with more than two levels in the context of a logistic
> GLMM.

Keep in mind that Wald tests and LRTs for GLMMs come with health warnings, e.g. 
https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#tests-of-effects-i.e.testing-that-several-parameters-are-simultaneously-zero

> But how are they calculated for a multi-level nominal predictor?
> 
> My (un)educated guess is that for each level of the nominal variable, the
> z-score is squared and the sum of these squares compared to the right-tail
> probability of the chi-squared distribution with DF equal to the number of
> levels of the predictor minus one. And indeed this square-the-z approach
> seems to correctly reproduce the results of Anova() for predictors with a
> single degree of freedom. But I can't make it reproduce the results of
> Anova() for predictors with more than one level. Hence my question: how is
> the test statistic calculated?

When the null hypothesis is that more than one fixed effect is zero (as with a factor with >2 levels), the covariances of the fixed effects have to be be taken into account. The Wald statistic is

    t(R %*% b) %*% solve(R %*% vc %*% t(R)) %*% (R %*% b)

where R is a restriction matrix that picks out the contrasts you're interested in, b is the fixed effect estimates vector, and vc is the estimated covariance matrix of the fixed effects (and we?re assuming that as is usual the null hypothesis values of b are all zero). In the case where you?re testing a multilevel categorical variable, R %*% b is simply the vector of estimates for the k-1 non-reference levels and R %*% vc %*% t(R) is the k-1 X k-1 block of the covariance matrix for those k-1 fixed effects. If the covariances were all zero (e.g. by design ? but I don?t think they can be for multilevel factors), the Wald statistic formula above would reduce to your sum of squares of z method.

Below is an binomial glmer example with a Wald test function I found on the web years ago. It gives the same result as car::Anova but it?s easier to see the inner workings.

Best wishes,
Paul


# wald z-test function 
# (adapted from Stijn Ruiter's function http://stijnruiter.nl/blog/?p=309 - broken link)

Wald<-
  function(object, # lme4 or glmmTMB fit
           R, # restrictions matrix. null hypothesis: R %*% fixef(object) = q
           q = NULL, # null values. by default q is a vector of zeroes
           gmmTMB.model = "cond")
  {
    require(lme4)
    if (!is.matrix(R)) stop("Restrictions must be a matrix")
    if(is.null(q)) q <- rep(0, nrow(R))
    b <- fixef(object)
    if(class(b) == "fixef.glmmTMB") b <- b[[gmmTMB.model]]
    vc <- vcov(object)
    if("vcov.glmmTMB" %in% class(vc)) vc <- vc[[gmmTMB.model]]
    w <- t(R %*% b - q) %*% solve(R %*% vc %*% t(R)) %*% (R %*% b - q)
    pw <- pchisq(w[1], length(q), lower.tail = FALSE)
    cat("*************\n* Wald Test *\n*************\n")
    cat("lme4 fixed effects:\n")
    print(fixef(object))
    cat("\nRestrictions:\n")
    print(R)
    cat("\nq = ",q)
    cat("\nChi-square:", round(w[1],3), " df = ", length(q))
    cat("\nProb x>chisq:", round(pw, 5), "\n")
    return(pw)
  }


# first example from ?glmer
library(lme4)
library(car)
(gm1 <- glmer(cbind(incidence, size - incidence) ~ period + (1 | herd),
              data = cbpp, family = binomial))


R <- cbind(0, diag(3))
# ...but ideally you want to generate the restriction matrix automatically

Wald(gm1, R = R)
anova(gm1, update(gm1, ~ . - period))
Anova(gm1)



From j|ox @end|ng |rom mcm@@ter@c@  Thu Apr 18 18:58:52 2019
From: j|ox @end|ng |rom mcm@@ter@c@ (Fox, John)
Date: Thu, 18 Apr 2019 16:58:52 +0000
Subject: [R-sig-ME] 
 Anova()'s Wald chisquare test for predictors with df > 1
 in a logistic GLMM
In-Reply-To: <22786_1555604346_x3IGJ5dE009292_8ADA0DBD-9E7F-4EFD-9A35-D41608E14B94@glasgow.ac.uk>
References: <CAG_dBVeQ7jf3NcojTXish6BOCovAUCE75eW0RUZJCYtnd4H72g@mail.gmail.com>
 <22786_1555604346_x3IGJ5dE009292_8ADA0DBD-9E7F-4EFD-9A35-D41608E14B94@glasgow.ac.uk>
Message-ID: <8B5BED48-515B-4161-AC7C-18A0D581B4BA@mcmaster.ca>

Dear Paul,

The Wald() function suffices for the simple case you use, where there are no interactions. The trick in the more complex case of "type-II" tests for models with terms related by marginality is to generate the correct restriction matrix, which doesn't simply pick out certain coefficients.

Best,
 John

  -------------------------------------------------
  John Fox, Professor Emeritus
  McMaster University
  Hamilton, Ontario, Canada
  Web: http::/socserv.mcmaster.ca/jfox

> On Apr 18, 2019, at 12:18 PM, Paul Johnson <paul.johnson at glasgow.ac.uk> wrote:
> 
>> I'm trying to figure out how the Wald chi-square test is performed for a
>> nominal predictor with more than two levels in the context of a logistic
>> GLMM.
> 
> Keep in mind that Wald tests and LRTs for GLMMs come with health warnings, e.g. 
> https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#tests-of-effects-i.e.testing-that-several-parameters-are-simultaneously-zero
> 
>> But how are they calculated for a multi-level nominal predictor?
>> 
>> My (un)educated guess is that for each level of the nominal variable, the
>> z-score is squared and the sum of these squares compared to the right-tail
>> probability of the chi-squared distribution with DF equal to the number of
>> levels of the predictor minus one. And indeed this square-the-z approach
>> seems to correctly reproduce the results of Anova() for predictors with a
>> single degree of freedom. But I can't make it reproduce the results of
>> Anova() for predictors with more than one level. Hence my question: how is
>> the test statistic calculated?
> 
> When the null hypothesis is that more than one fixed effect is zero (as with a factor with >2 levels), the covariances of the fixed effects have to be be taken into account. The Wald statistic is
> 
>    t(R %*% b) %*% solve(R %*% vc %*% t(R)) %*% (R %*% b)
> 
> where R is a restriction matrix that picks out the contrasts you're interested in, b is the fixed effect estimates vector, and vc is the estimated covariance matrix of the fixed effects (and we?re assuming that as is usual the null hypothesis values of b are all zero). In the case where you?re testing a multilevel categorical variable, R %*% b is simply the vector of estimates for the k-1 non-reference levels and R %*% vc %*% t(R) is the k-1 X k-1 block of the covariance matrix for those k-1 fixed effects. If the covariances were all zero (e.g. by design ? but I don?t think they can be for multilevel factors), the Wald statistic formula above would reduce to your sum of squares of z method.
> 
> Below is an binomial glmer example with a Wald test function I found on the web years ago. It gives the same result as car::Anova but it?s easier to see the inner workings.
> 
> Best wishes,
> Paul
> 
> 
> # wald z-test function 
> # (adapted from Stijn Ruiter's function http://stijnruiter.nl/blog/?p=309 - broken link)
> 
> Wald<-
>  function(object, # lme4 or glmmTMB fit
>           R, # restrictions matrix. null hypothesis: R %*% fixef(object) = q
>           q = NULL, # null values. by default q is a vector of zeroes
>           gmmTMB.model = "cond")
>  {
>    require(lme4)
>    if (!is.matrix(R)) stop("Restrictions must be a matrix")
>    if(is.null(q)) q <- rep(0, nrow(R))
>    b <- fixef(object)
>    if(class(b) == "fixef.glmmTMB") b <- b[[gmmTMB.model]]
>    vc <- vcov(object)
>    if("vcov.glmmTMB" %in% class(vc)) vc <- vc[[gmmTMB.model]]
>    w <- t(R %*% b - q) %*% solve(R %*% vc %*% t(R)) %*% (R %*% b - q)
>    pw <- pchisq(w[1], length(q), lower.tail = FALSE)
>    cat("*************\n* Wald Test *\n*************\n")
>    cat("lme4 fixed effects:\n")
>    print(fixef(object))
>    cat("\nRestrictions:\n")
>    print(R)
>    cat("\nq = ",q)
>    cat("\nChi-square:", round(w[1],3), " df = ", length(q))
>    cat("\nProb x>chisq:", round(pw, 5), "\n")
>    return(pw)
>  }
> 
> 
> # first example from ?glmer
> library(lme4)
> library(car)
> (gm1 <- glmer(cbind(incidence, size - incidence) ~ period + (1 | herd),
>              data = cbpp, family = binomial))
> 
> 
> R <- cbind(0, diag(3))
> # ...but ideally you want to generate the restriction matrix automatically
> 
> Wald(gm1, R = R)
> anova(gm1, update(gm1, ~ . - period))
> Anova(gm1)
> 
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From juho@kr|@t|@n@ruohonen @end|ng |rom gm@||@com  Thu Apr 18 21:30:45 2019
From: juho@kr|@t|@n@ruohonen @end|ng |rom gm@||@com (Juho Kristian Ruohonen)
Date: Thu, 18 Apr 2019 22:30:45 +0300
Subject: [R-sig-ME] 
 Anova()'s Wald chisquare test for predictors with df > 1
 in a logistic GLMM
In-Reply-To: <8B5BED48-515B-4161-AC7C-18A0D581B4BA@mcmaster.ca>
References: <CAG_dBVeQ7jf3NcojTXish6BOCovAUCE75eW0RUZJCYtnd4H72g@mail.gmail.com>
 <22786_1555604346_x3IGJ5dE009292_8ADA0DBD-9E7F-4EFD-9A35-D41608E14B94@glasgow.ac.uk>
 <8B5BED48-515B-4161-AC7C-18A0D581B4BA@mcmaster.ca>
Message-ID: <CAG_dBVf5pMWUC07diCgabCs2zouQEFn=ZWSw-6mw-fNEMZim-g@mail.gmail.com>

I was talking type-II tests of a main-effects model all along, which I
apologize for not specifying at the outset. Anyway, this is now resolved.
Many thanks to John for weighing in and to Paul for the pedagogical code
snippets! (And here I I was assuming that the multi-df Wald test would be
as simple as the single-parameter one. Joke's on me.)

Best,

J

to 18. huhtik. 2019 klo 19.58 Fox, John (jfox at mcmaster.ca) kirjoitti:

> Dear Paul,
>
> The Wald() function suffices for the simple case you use, where there are
> no interactions. The trick in the more complex case of "type-II" tests for
> models with terms related by marginality is to generate the correct
> restriction matrix, which doesn't simply pick out certain coefficients.
>
> Best,
>  John
>
>   -------------------------------------------------
>   John Fox, Professor Emeritus
>   McMaster University
>   Hamilton, Ontario, Canada
>   Web: http::/socserv.mcmaster.ca/jfox
>
> > On Apr 18, 2019, at 12:18 PM, Paul Johnson <paul.johnson at glasgow.ac.uk>
> wrote:
> >
> >> I'm trying to figure out how the Wald chi-square test is performed for a
> >> nominal predictor with more than two levels in the context of a logistic
> >> GLMM.
> >
> > Keep in mind that Wald tests and LRTs for GLMMs come with health
> warnings, e.g.
> >
> https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#tests-of-effects-i.e.testing-that-several-parameters-are-simultaneously-zero
> >
> >> But how are they calculated for a multi-level nominal predictor?
> >>
> >> My (un)educated guess is that for each level of the nominal variable,
> the
> >> z-score is squared and the sum of these squares compared to the
> right-tail
> >> probability of the chi-squared distribution with DF equal to the number
> of
> >> levels of the predictor minus one. And indeed this square-the-z approach
> >> seems to correctly reproduce the results of Anova() for predictors with
> a
> >> single degree of freedom. But I can't make it reproduce the results of
> >> Anova() for predictors with more than one level. Hence my question: how
> is
> >> the test statistic calculated?
> >
> > When the null hypothesis is that more than one fixed effect is zero (as
> with a factor with >2 levels), the covariances of the fixed effects have to
> be be taken into account. The Wald statistic is
> >
> >    t(R %*% b) %*% solve(R %*% vc %*% t(R)) %*% (R %*% b)
> >
> > where R is a restriction matrix that picks out the contrasts you're
> interested in, b is the fixed effect estimates vector, and vc is the
> estimated covariance matrix of the fixed effects (and we?re assuming that
> as is usual the null hypothesis values of b are all zero). In the case
> where you?re testing a multilevel categorical variable, R %*% b is simply
> the vector of estimates for the k-1 non-reference levels and R %*% vc %*%
> t(R) is the k-1 X k-1 block of the covariance matrix for those k-1 fixed
> effects. If the covariances were all zero (e.g. by design ? but I don?t
> think they can be for multilevel factors), the Wald statistic formula above
> would reduce to your sum of squares of z method.
> >
> > Below is an binomial glmer example with a Wald test function I found on
> the web years ago. It gives the same result as car::Anova but it?s easier
> to see the inner workings.
> >
> > Best wishes,
> > Paul
> >
> >
> > # wald z-test function
> > # (adapted from Stijn Ruiter's function
> http://stijnruiter.nl/blog/?p=309 - broken link)
> >
> > Wald<-
> >  function(object, # lme4 or glmmTMB fit
> >           R, # restrictions matrix. null hypothesis: R %*% fixef(object)
> = q
> >           q = NULL, # null values. by default q is a vector of zeroes
> >           gmmTMB.model = "cond")
> >  {
> >    require(lme4)
> >    if (!is.matrix(R)) stop("Restrictions must be a matrix")
> >    if(is.null(q)) q <- rep(0, nrow(R))
> >    b <- fixef(object)
> >    if(class(b) == "fixef.glmmTMB") b <- b[[gmmTMB.model]]
> >    vc <- vcov(object)
> >    if("vcov.glmmTMB" %in% class(vc)) vc <- vc[[gmmTMB.model]]
> >    w <- t(R %*% b - q) %*% solve(R %*% vc %*% t(R)) %*% (R %*% b - q)
> >    pw <- pchisq(w[1], length(q), lower.tail = FALSE)
> >    cat("*************\n* Wald Test *\n*************\n")
> >    cat("lme4 fixed effects:\n")
> >    print(fixef(object))
> >    cat("\nRestrictions:\n")
> >    print(R)
> >    cat("\nq = ",q)
> >    cat("\nChi-square:", round(w[1],3), " df = ", length(q))
> >    cat("\nProb x>chisq:", round(pw, 5), "\n")
> >    return(pw)
> >  }
> >
> >
> > # first example from ?glmer
> > library(lme4)
> > library(car)
> > (gm1 <- glmer(cbind(incidence, size - incidence) ~ period + (1 | herd),
> >              data = cbpp, family = binomial))
> >
> >
> > R <- cbind(0, diag(3))
> > # ...but ideally you want to generate the restriction matrix
> automatically
> >
> > Wald(gm1, R = R)
> > anova(gm1, update(gm1, ~ . - period))
> > Anova(gm1)
> >
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>

	[[alternative HTML version deleted]]


From j|ox @end|ng |rom mcm@@ter@c@  Thu Apr 18 23:04:51 2019
From: j|ox @end|ng |rom mcm@@ter@c@ (Fox, John)
Date: Thu, 18 Apr 2019 21:04:51 +0000
Subject: [R-sig-ME] 
 Anova()'s Wald chisquare test for predictors with df > 1
 in a logistic GLMM
In-Reply-To: <CAG_dBVf5pMWUC07diCgabCs2zouQEFn=ZWSw-6mw-fNEMZim-g@mail.gmail.com>
References: <CAG_dBVeQ7jf3NcojTXish6BOCovAUCE75eW0RUZJCYtnd4H72g@mail.gmail.com>
 <22786_1555604346_x3IGJ5dE009292_8ADA0DBD-9E7F-4EFD-9A35-D41608E14B94@glasgow.ac.uk>
 <8B5BED48-515B-4161-AC7C-18A0D581B4BA@mcmaster.ca>
 <CAG_dBVf5pMWUC07diCgabCs2zouQEFn=ZWSw-6mw-fNEMZim-g@mail.gmail.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC836B83688@FHSDB2D11-2.csu.mcmaster.ca>

Dear Juho,

Actually, for a main-effect-only model, there is no distinction between the "type-II" and "type-III" Wald tests computed by Anova(). It's only when there are terms (beyond the constant) related by marginality that the distinction arises.

Best,
 John 

> -----Original Message-----
> From: Juho Kristian Ruohonen [mailto:juho.kristian.ruohonen at gmail.com]
> Sent: Thursday, April 18, 2019 3:31 PM
> To: Fox, John <jfox at mcmaster.ca>
> Cc: Paul Johnson <paul.johnson at glasgow.ac.uk>; Shaul Oreg via R-sig-mixed-
> models <r-sig-mixed-models at r-project.org>
> Subject: Re: [R-sig-ME] Anova()'s Wald chisquare test for predictors with df > 1
> in a logistic GLMM
> 
> I was talking type-II tests of a main-effects model all along, which I apologize
> for not specifying at the outset. Anyway, this is now resolved. Many thanks to
> John for weighing in and to Paul for the pedagogical code snippets! (And here I
> I was assuming that the multi-df Wald test would be as simple as the single-
> parameter one. Joke's on me.)
> 
> Best,
> 
> J
> 
> 
> to 18. huhtik. 2019 klo 19.58 Fox, John (jfox at mcmaster.ca
> <mailto:jfox at mcmaster.ca> ) kirjoitti:
> 
> 
> 	Dear Paul,
> 
> 	The Wald() function suffices for the simple case you use, where there
> are no interactions. The trick in the more complex case of "type-II" tests for
> models with terms related by marginality is to generate the correct restriction
> matrix, which doesn't simply pick out certain coefficients.
> 
> 	Best,
> 	 John
> 
> 	  -------------------------------------------------
> 	  John Fox, Professor Emeritus
> 	  McMaster University
> 	  Hamilton, Ontario, Canada
> 	  Web: http::/socserv.mcmaster.ca/jfox
> <http://socserv.mcmaster.ca/jfox>
> 
> 	> On Apr 18, 2019, at 12:18 PM, Paul Johnson
> <paul.johnson at glasgow.ac.uk <mailto:paul.johnson at glasgow.ac.uk> >
> wrote:
> 	>
> 	>> I'm trying to figure out how the Wald chi-square test is performed
> for a
> 	>> nominal predictor with more than two levels in the context of a
> logistic
> 	>> GLMM.
> 	>
> 	> Keep in mind that Wald tests and LRTs for GLMMs come with health
> warnings, e.g.
> 	> https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#tests-
> of-effects-i.e.testing-that-several-parameters-are-simultaneously-zero
> 	>
> 	>> But how are they calculated for a multi-level nominal predictor?
> 	>>
> 	>> My (un)educated guess is that for each level of the nominal
> variable, the
> 	>> z-score is squared and the sum of these squares compared to the
> right-tail
> 	>> probability of the chi-squared distribution with DF equal to the
> number of
> 	>> levels of the predictor minus one. And indeed this square-the-z
> approach
> 	>> seems to correctly reproduce the results of Anova() for predictors
> with a
> 	>> single degree of freedom. But I can't make it reproduce the results
> of
> 	>> Anova() for predictors with more than one level. Hence my
> question: how is
> 	>> the test statistic calculated?
> 	>
> 	> When the null hypothesis is that more than one fixed effect is zero
> (as with a factor with >2 levels), the covariances of the fixed effects have to be
> be taken into account. The Wald statistic is
> 	>
> 	>    t(R %*% b) %*% solve(R %*% vc %*% t(R)) %*% (R %*% b)
> 	>
> 	> where R is a restriction matrix that picks out the contrasts you're
> interested in, b is the fixed effect estimates vector, and vc is the estimated
> covariance matrix of the fixed effects (and we?re assuming that as is usual the
> null hypothesis values of b are all zero). In the case where you?re testing a
> multilevel categorical variable, R %*% b is simply the vector of estimates for
> the k-1 non-reference levels and R %*% vc %*% t(R) is the k-1 X k-1 block of
> the covariance matrix for those k-1 fixed effects. If the covariances were all
> zero (e.g. by design ? but I don?t think they can be for multilevel factors), the
> Wald statistic formula above would reduce to your sum of squares of z
> method.
> 	>
> 	> Below is an binomial glmer example with a Wald test function I
> found on the web years ago. It gives the same result as car::Anova but it?s
> easier to see the inner workings.
> 	>
> 	> Best wishes,
> 	> Paul
> 	>
> 	>
> 	> # wald z-test function
> 	> # (adapted from Stijn Ruiter's function
> http://stijnruiter.nl/blog/?p=309 - broken link)
> 	>
> 	> Wald<-
> 	>  function(object, # lme4 or glmmTMB fit
> 	>           R, # restrictions matrix. null hypothesis: R %*% fixef(object) = q
> 	>           q = NULL, # null values. by default q is a vector of zeroes
> 	>           gmmTMB.model = "cond")
> 	>  {
> 	>    require(lme4)
> 	>    if (!is.matrix(R)) stop("Restrictions must be a matrix")
> 	>    if(is.null(q)) q <- rep(0, nrow(R))
> 	>    b <- fixef(object)
> 	>    if(class(b) == "fixef.glmmTMB") b <- b[[gmmTMB.model]]
> 	>    vc <- vcov(object)
> 	>    if("vcov.glmmTMB" %in% class(vc)) vc <- vc[[gmmTMB.model]]
> 	>    w <- t(R %*% b - q) %*% solve(R %*% vc %*% t(R)) %*% (R %*% b -
> q)
> 	>    pw <- pchisq(w[1], length(q), lower.tail = FALSE)
> 	>    cat("*************\n* Wald Test *\n*************\n")
> 	>    cat("lme4 fixed effects:\n")
> 	>    print(fixef(object))
> 	>    cat("\nRestrictions:\n")
> 	>    print(R)
> 	>    cat("\nq = ",q)
> 	>    cat("\nChi-square:", round(w[1],3), " df = ", length(q))
> 	>    cat("\nProb x>chisq:", round(pw, 5), "\n")
> 	>    return(pw)
> 	>  }
> 	>
> 	>
> 	> # first example from ?glmer
> 	> library(lme4)
> 	> library(car)
> 	> (gm1 <- glmer(cbind(incidence, size - incidence) ~ period + (1 | herd),
> 	>              data = cbpp, family = binomial))
> 	>
> 	>
> 	> R <- cbind(0, diag(3))
> 	> # ...but ideally you want to generate the restriction matrix
> automatically
> 	>
> 	> Wald(gm1, R = R)
> 	> anova(gm1, update(gm1, ~ . - period))
> 	> Anova(gm1)
> 	>
> 	>
> 	> _______________________________________________
> 	> R-sig-mixed-models at r-project.org <mailto:R-sig-mixed-models at r-
> project.org>  mailing list
> 	> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 


From db@r@cort|n@ @end|ng |rom gm@||@com  Fri Apr 19 17:36:44 2019
From: db@r@cort|n@ @end|ng |rom gm@||@com (David Bars)
Date: Fri, 19 Apr 2019 17:36:44 +0200
Subject: [R-sig-ME] Specific doubts about glmer() function
Message-ID: <CAD-H4Cgw9RzoO9-gTcj3tud=4j2+VjtbdnCTMBpec+SqzGX2Xw@mail.gmail.com>

Hi everybody,

My name's David Bars, PhD student at the University of Lleida (Spain)
that currently I'm performing a PhD stage at one INRA research centre of
France.

I have three particular problems/doubts in order to try to implement  a
glmer model and understand it better, because I'm uncapable to solve by
myself.

I attach my microbiota raw data and R script in the next link:
https://ln.sync.com/dl/4df498890/5vf6ws7z-4f8i8t7p-mkawd5vk-mt3gfkm6

Briefly, I have the count of the total number of molecules of DNA by two
times (time 1 and time 2). My response variable (DNA_pr_copies_number) is
not normal-distributed (by Shapiro - Wilk Test). Therefore I go ahead
through glmer() instead of lmer() function. HorseID is the horse studied,
so my random effect in the model.


As pointed out me Dr. Ben Bolker I had a huge change in variance from time 1
to time 2:

library(ggplot2); theme_set(theme_bw())
ggplot(m16, aes(Time,DNApr_copies_number))+
    scale_y_log10()+geom_point()+
    geom_line(aes(group=Horse),alpha=0.2)

3 concrete doubts about my data:

1- Due to my response variable is a count, I considered as a discrete
variable. As you can see in the R script attached I used the fitdist()
function from fitdistrplus package and a negative binomial is suggested. I
performed glmer.nb() but I obtained the following error (as you can also
see in the R script). What may can cause this error???

# Error in (function (fr, X, reTrms, family, nAGQ = 1L, verbose = 0L, maxit
= 100L,  :
#                       (maxstephalfit) PIRLS step-halvings failed to
reduce deviance in pwrssUpdate
#                     In addition: Warning messages:
#                       1: In checkConv(attr(opt, "derivs"), opt$par, ctrl
= control$checkConv,  :
#                                         Model failed to converge with
max|grad| = 0.204772 (tol = 0.001, component 1)
#                                       2: In checkConv(attr(opt,
"derivs"), opt$par, ctrl = control$checkConv,  :
#                                                         Model is nearly
unidentifiable: very large eigenvalue
#                                                       - Rescale
variables?;Model is nearly unidentifiable: large eigenvalue ratio
#                                                       - Rescale variables?


2- As general rule, in glmer models and due to in my model we have only one
random effect, maybe it's more recommended always to perform a
Gauss-Hermite Quadrature approximation instead of Laplace approximation
because we can perform more than one iteration?

3 - (other general doubt from other microbiote data not attached in the
link above)
I've read some posts addressing why the variance of Random effect differs
between lmer and
glmer... (
https://stats.stackexchange.com/questions/115090/why-do-i-get-zero-variance-of-a-random-effect-in-my-mixed-model-despite-some-va
but
I'm uncapable yet to understand it.

Due to non-normality of my data, I need to use glmer, but how can I explain
that the variance of my random variable (Horse) is practically 0???
Performing an analogous analysis by lmer (assuming badly "normality")
the variance of my random variable (HorseID) increased up to 33%!!!  I
think that horse, must be an important value of explaining the variance of
my model (as states lmer model).

Therefore, I perform glmer and I obtained a variance for HorseID as random
effect of 0, meanwhile performing a lmer()  I obtained a variance for
HorseID as random effect of 33%. How can I assess the importance of the
random effect on my model? How can I interpret well the model?

Thanks on advance for your help/comments,


David Bars
PhD Student
University of Lleida (Spain)
ES-15198
Avenue Rovira Roure, 80.
 Building HUAV.

	[[alternative HTML version deleted]]


From r@turner @end|ng |rom @uck|@nd@@c@nz  Sat Apr 20 01:22:28 2019
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Sat, 20 Apr 2019 11:22:28 +1200
Subject: [R-sig-ME] Log likelihood of a glmer() binomial model .
Message-ID: <306f44cf-a1f9-25d4-4f9f-3dd581698d23@auckland.ac.nz>


I am trying to implement cross-validated likelihood (see e.g. "Model 
selection for probabilistic clustering using cross-validated 
likelihood", P. Smyth, 2000, Statistics and Computing vol. 10, pp. 
63--72) for model selection in the glmer() binomial family context.

Briefly what I do is:

    * divide the data into a "training set" and a "validation set"
      (e.g. 80% and 20%)
    * fit the model of interest to the training set *only*
    * calculate the log-likelihood of the validation set on the
      basis of the model fitted to the training set

It is the last step about which I have some concern.  I calculate
this log likelihood as

     sum(log(predict(fit,newdata=VS,type="response")))

where "fit" is the model fitted to the training set and "VS" is the 
validation set.

I have the uneasy feeling that I may well be doing something stupidly 
na?ve here, but I can't see anything obviously wrong with what I am doing.

I have observed that, if I execute

     sum(log(predict(fit,type="response")))

ostensibly calculating the log likelihood of "fit" for the data set from 
which "fit" was obtained, I get a very different value from that which 
is obtained from executing logLik(fit).   This does not *necessarily* 
imply, however, that my method is wrong, since the log likelihood is 
"unique only up to an additive constant".  I cannot however see how to 
work out what this additive constant might be equal to, so that I can check.

Can anyone enlighten me as to whether my log likelihood is "correct"?

And if not, could someone suggest a *correct* means of calculating a 
"cross-validated" log likelihood?

Thanks.

cheers,

Rolf Turner

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From bbo|ker @end|ng |rom gm@||@com  Sat Apr 20 02:44:06 2019
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Fri, 19 Apr 2019 20:44:06 -0400
Subject: [R-sig-ME] Log likelihood of a glmer() binomial model .
In-Reply-To: <306f44cf-a1f9-25d4-4f9f-3dd581698d23@auckland.ac.nz>
References: <306f44cf-a1f9-25d4-4f9f-3dd581698d23@auckland.ac.nz>
Message-ID: <CABghstTKrwA9x5Xmk=ECwVzHawBp6OnRQCsymKA9DSpZPuATeg@mail.gmail.com>

  This seems wrong.  The GLMM log-likelihood includes an integral over
the distribution of the random effects.  If you use `nAGQ=0` (which
skips the integral) you *might* get the same answer (I think there's
no additional additive constant to be included for a Bernoulli
response?  The likelihood of a bernoulli is p or 1-p, no normalizing
constants needed ...)  Otherwise I think you might have to hack
around.

 Here is an **inefficient** method for computing the likelihood

   coefs <- unlist(getME(fit,c("theta","beta"))
   newdev <- update(fit, data=VS, devFunOnly=TRUE)
   newdev(coefs)

This is slow because it has to reconstruct all of the random-effects
matrices, do permutations to reorder the relevant matrices to be as
sparse as possible, etc. etc.

  It would be nice if we had a more efficient form of update(), but in
this case I'm not even sure it's easy/ possible (since the structure
of the Z matrices could change a lot when we go from the training to
the test data).

refit() efficiently rebuilds a new deviance function that uses a new
response variable, but it relies on everything else in the model
staying the same (especially, structure of the  matrices).
Before I realized it wouldn't help, I made a quick lme4 branch that
adds a "devFunOnly" argument to the refit.merMod method:
https://github.com/lme4/lme4/tree/refit_dfonly

  If I get feedback that this would be useful for someone I may merge
it back to the master branch ...


On Fri, Apr 19, 2019 at 7:22 PM Rolf Turner <r.turner at auckland.ac.nz> wrote:
>
>
> I am trying to implement cross-validated likelihood (see e.g. "Model
> selection for probabilistic clustering using cross-validated
> likelihood", P. Smyth, 2000, Statistics and Computing vol. 10, pp.
> 63--72) for model selection in the glmer() binomial family context.
>
> Briefly what I do is:
>
>     * divide the data into a "training set" and a "validation set"
>       (e.g. 80% and 20%)
>     * fit the model of interest to the training set *only*
>     * calculate the log-likelihood of the validation set on the
>       basis of the model fitted to the training set
>
> It is the last step about which I have some concern.  I calculate
> this log likelihood as
>
>      sum(log(predict(fit,newdata=VS,type="response")))
>
> where "fit" is the model fitted to the training set and "VS" is the
> validation set.
>
> I have the uneasy feeling that I may well be doing something stupidly
> na?ve here, but I can't see anything obviously wrong with what I am doing.
>
> I have observed that, if I execute
>
>      sum(log(predict(fit,type="response")))
>
> ostensibly calculating the log likelihood of "fit" for the data set from
> which "fit" was obtained, I get a very different value from that which
> is obtained from executing logLik(fit).   This does not *necessarily*
> imply, however, that my method is wrong, since the log likelihood is
> "unique only up to an additive constant".  I cannot however see how to
> work out what this additive constant might be equal to, so that I can check.
>
> Can anyone enlighten me as to whether my log likelihood is "correct"?
>
> And if not, could someone suggest a *correct* means of calculating a
> "cross-validated" log likelihood?
>
> Thanks.
>
> cheers,
>
> Rolf Turner
>
> --
> Honorary Research Fellow
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From r@turner @end|ng |rom @uck|@nd@@c@nz  Sat Apr 20 07:51:05 2019
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Sat, 20 Apr 2019 17:51:05 +1200
Subject: [R-sig-ME] Log likelihood of a glmer() binomial model .
In-Reply-To: <CABghstTKrwA9x5Xmk=ECwVzHawBp6OnRQCsymKA9DSpZPuATeg@mail.gmail.com>
References: <306f44cf-a1f9-25d4-4f9f-3dd581698d23@auckland.ac.nz>
 <CABghstTKrwA9x5Xmk=ECwVzHawBp6OnRQCsymKA9DSpZPuATeg@mail.gmail.com>
Message-ID: <33fd981f-d9db-b824-1c2b-40050b72993e@auckland.ac.nz>


On 20/04/19 12:44 PM, Ben Bolker wrote:

>    This seems wrong.

Yeah, that figures.

> The GLMM log-likelihood includes an integral over
> the distribution of the random effects.

I was aware of this.  I guess what I was na?vely expecting was that 
predict.merMod() would handle this.  I.e. that this predict method
(with type = "response") would return, for each observed y_i in the 
(new) data set

   Pr(Y = y_i) = \int_0 Pr(Y = y_i | R = r) f(r) dr

where R is the vector of random effects and f(r) is its probability 
density function (multivariate normal, with mean 0 and some covariance 
matrix, which has been estimated in the fitting process.

I guess that this is *not* what predict.merMod() returns --- but I don't 
understand why not.  It seems to me that this is what it "should" return.

I'm probably misunderstanding something, possibly simple, possibly subtle.

Apropos of nothing much, what *does* predict.merMod() return?
Maybe Pr(Y = y_i | R = 0) ???

<SNIP>
>   Here is an **inefficient** method for computing the likelihood
> 
>     coefs <- unlist(getME(fit,c("theta","beta"))
>     newdev <- update(fit, data=VS, devFunOnly=TRUE)
>     newdev(coefs)
> 
> This is slow because it has to reconstruct all of the random-effects
> matrices, do permutations to reorder the relevant matrices to be as
> sparse as possible, etc. etc.

Thanks for this.  I'll give it a go.  I think that the slowness may not 
be an overwhelming drawback.  Anyhow I shall try to test it out.

Thanks again.

cheers,

Rolf

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From juho@kr|@t|@n@ruohonen @end|ng |rom gm@||@com  Sat Apr 20 09:42:16 2019
From: juho@kr|@t|@n@ruohonen @end|ng |rom gm@||@com (Juho Kristian Ruohonen)
Date: Sat, 20 Apr 2019 10:42:16 +0300
Subject: [R-sig-ME] Log likelihood of a glmer() binomial model .
In-Reply-To: <33fd981f-d9db-b824-1c2b-40050b72993e@auckland.ac.nz>
References: <306f44cf-a1f9-25d4-4f9f-3dd581698d23@auckland.ac.nz>
 <CABghstTKrwA9x5Xmk=ECwVzHawBp6OnRQCsymKA9DSpZPuATeg@mail.gmail.com>
 <33fd981f-d9db-b824-1c2b-40050b72993e@auckland.ac.nz>
Message-ID: <CAG_dBVdTdwiSn=9SzR7ewWAqXdgy8sobxRYKE8xd4fJNeuCRJQ@mail.gmail.com>

Rolf: Forgive my ignorance, but isn't the relevant log-likelihood here the
log-likelihood of the observed responses in the validation set given the
model-predicted probabilities? I.e. sum(dbinom(VS$y, size = VS$n, prob =
predict(fit, newdata = VS, type = "response"), log = TRUE))? Even this
would be somewhat off because dbinom() isn't aware of the random-effects
integral business. But it looks to me like your current call is calculating
the log-sum of the predicted probabilities of y = 1 in the validation set,
not the loglikelihood of the observed responses in the validation set.

la 20. huhtik. 2019 klo 8.51 Rolf Turner (r.turner at auckland.ac.nz)
kirjoitti:

>
> On 20/04/19 12:44 PM, Ben Bolker wrote:
>
> >    This seems wrong.
>
> Yeah, that figures.
>
> > The GLMM log-likelihood includes an integral over
> > the distribution of the random effects.
>
> I was aware of this.  I guess what I was na?vely expecting was that
> predict.merMod() would handle this.  I.e. that this predict method
> (with type = "response") would return, for each observed y_i in the
> (new) data set
>
>    Pr(Y = y_i) = \int_0 Pr(Y = y_i | R = r) f(r) dr
>
> where R is the vector of random effects and f(r) is its probability
> density function (multivariate normal, with mean 0 and some covariance
> matrix, which has been estimated in the fitting process.
>
> I guess that this is *not* what predict.merMod() returns --- but I don't
> understand why not.  It seems to me that this is what it "should" return.
>
> I'm probably misunderstanding something, possibly simple, possibly subtle.
>
> Apropos of nothing much, what *does* predict.merMod() return?
> Maybe Pr(Y = y_i | R = 0) ???
>
> <SNIP>
> >   Here is an **inefficient** method for computing the likelihood
> >
> >     coefs <- unlist(getME(fit,c("theta","beta"))
> >     newdev <- update(fit, data=VS, devFunOnly=TRUE)
> >     newdev(coefs)
> >
> > This is slow because it has to reconstruct all of the random-effects
> > matrices, do permutations to reorder the relevant matrices to be as
> > sparse as possible, etc. etc.
>
> Thanks for this.  I'll give it a go.  I think that the slowness may not
> be an overwhelming drawback.  Anyhow I shall try to test it out.
>
> Thanks again.
>
> cheers,
>
> Rolf
>
> --
> Honorary Research Fellow
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Sat Apr 20 16:51:05 2019
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Sat, 20 Apr 2019 10:51:05 -0400
Subject: [R-sig-ME] Log likelihood of a glmer() binomial model .
In-Reply-To: <CAG_dBVdTdwiSn=9SzR7ewWAqXdgy8sobxRYKE8xd4fJNeuCRJQ@mail.gmail.com>
References: <306f44cf-a1f9-25d4-4f9f-3dd581698d23@auckland.ac.nz>
 <CABghstTKrwA9x5Xmk=ECwVzHawBp6OnRQCsymKA9DSpZPuATeg@mail.gmail.com>
 <33fd981f-d9db-b824-1c2b-40050b72993e@auckland.ac.nz>
 <CAG_dBVdTdwiSn=9SzR7ewWAqXdgy8sobxRYKE8xd4fJNeuCRJQ@mail.gmail.com>
Message-ID: <b41fc0d8-a841-fc55-985d-3457b703e8ce@gmail.com>


  I agree with Juho that there's a typo -- would be something like.

 sum((y==1)*log(pred_prob) + (y==0)*log(1-pred_prob))

  As far as what predict() does: depending on the value of re.form, it
either gives a population-level prediction (R=0) or a conditional
prediction (R set to its conditional mode).  You might be looking for
*marginal* predictions (which Rizopoulous's GLMMadaptive package can do ...)


On 2019-04-20 3:42 a.m., Juho Kristian Ruohonen wrote:
> Rolf: Forgive my ignorance, but isn't the relevant log-likelihood here
> the log-likelihood of the observed responses in the validation set given
> the model-predicted probabilities? I.e. sum(dbinom(VS$y, size = VS$n,
> prob = predict(fit, newdata = VS, type = "response"), log = TRUE))? Even
> this would be somewhat off because dbinom() isn't aware of the
> random-effects integral business. But it looks to me like your current
> call is calculating the log-sum of the predicted probabilities of y = 1
> in the validation set, not the loglikelihood of the observed responses
> in the validation set.
> 
> la 20. huhtik. 2019 klo 8.51 Rolf Turner (r.turner at auckland.ac.nz
> <mailto:r.turner at auckland.ac.nz>) kirjoitti:
> 
> 
>     On 20/04/19 12:44 PM, Ben Bolker wrote:
> 
>     >? ? This seems wrong.
> 
>     Yeah, that figures.
> 
>     > The GLMM log-likelihood includes an integral over
>     > the distribution of the random effects.
> 
>     I was aware of this.? I guess what I was na?vely expecting was that
>     predict.merMod() would handle this.? I.e. that this predict method
>     (with type = "response") would return, for each observed y_i in the
>     (new) data set
> 
>     ? ?Pr(Y = y_i) = \int_0 Pr(Y = y_i | R = r) f(r) dr
> 
>     where R is the vector of random effects and f(r) is its probability
>     density function (multivariate normal, with mean 0 and some covariance
>     matrix, which has been estimated in the fitting process.
> 
>     I guess that this is *not* what predict.merMod() returns --- but I
>     don't
>     understand why not.? It seems to me that this is what it "should"
>     return.
> 
>     I'm probably misunderstanding something, possibly simple, possibly
>     subtle.
> 
>     Apropos of nothing much, what *does* predict.merMod() return?
>     Maybe Pr(Y = y_i | R = 0) ???
> 
>     <SNIP>
>     >? ?Here is an **inefficient** method for computing the likelihood
>     >
>     >? ? ?coefs <- unlist(getME(fit,c("theta","beta"))
>     >? ? ?newdev <- update(fit, data=VS, devFunOnly=TRUE)
>     >? ? ?newdev(coefs)
>     >
>     > This is slow because it has to reconstruct all of the random-effects
>     > matrices, do permutations to reorder the relevant matrices to be as
>     > sparse as possible, etc. etc.
> 
>     Thanks for this.? I'll give it a go.? I think that the slowness may not
>     be an overwhelming drawback.? Anyhow I shall try to test it out.
> 
>     Thanks again.
> 
>     cheers,
> 
>     Rolf
> 
>     -- 
>     Honorary Research Fellow
>     Department of Statistics
>     University of Auckland
>     Phone: +64-9-373-7599 ext. 88276
> 
>     _______________________________________________
>     R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From bbo|ker @end|ng |rom gm@||@com  Sat Apr 20 20:43:57 2019
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Sat, 20 Apr 2019 14:43:57 -0400
Subject: [R-sig-ME] Log likelihood of a glmer() binomial model .
In-Reply-To: <CAO7JsnRCE6nd0bjDSGC_hLmPWBx3e5fnRa5sijWC+zgCzp1oOw@mail.gmail.com>
References: <306f44cf-a1f9-25d4-4f9f-3dd581698d23@auckland.ac.nz>
 <48897_1555721325_0PQ800YD4I97QR00_CABghstTKrwA9x5Xmk=ECwVzHawBp6OnRQCsymKA9DSpZPuATeg@mail.gmail.com>
 <CAO7JsnRCE6nd0bjDSGC_hLmPWBx3e5fnRa5sijWC+zgCzp1oOw@mail.gmail.com>
Message-ID: <CABghstS4Ji28GU8AQGF0qvnO4GXNV8c2OY1K8GQ_QuK5NcuuDQ@mail.gmail.com>

  Oops. thanks.

On Sat, Apr 20, 2019 at 1:09 PM Douglas Bates <bates at stat.wisc.edu> wrote:
>
> nAGQ=0 doesn't skip the integral, it just includes the fixed effects in the PIRLS optimization process. Both that and nAGQ=1 use the Laplace approximation to the integral.
>
> Admittedly, using nAGQ=0 to signal something unrelated to the integral was probably not the best choice. I tried to economize on the number of optional argument names at the cost of transparency.
>
> On Fri, Apr 19, 2019, 19:48 Ben Bolker <bbolker at gmail.com> wrote:
>>
>>   This seems wrong.  The GLMM log-likelihood includes an integral over
>> the distribution of the random effects.  If you use `nAGQ=0` (which
>> skips the integral) you *might* get the same answer (I think there's
>> no additional additive constant to be included for a Bernoulli
>> response?  The likelihood of a bernoulli is p or 1-p, no normalizing
>> constants needed ...)  Otherwise I think you might have to hack
>> around.
>>
>>  Here is an **inefficient** method for computing the likelihood
>>
>>    coefs <- unlist(getME(fit,c("theta","beta"))
>>    newdev <- update(fit, data=VS, devFunOnly=TRUE)
>>    newdev(coefs)
>>
>> This is slow because it has to reconstruct all of the random-effects
>> matrices, do permutations to reorder the relevant matrices to be as
>> sparse as possible, etc. etc.
>>
>>   It would be nice if we had a more efficient form of update(), but in
>> this case I'm not even sure it's easy/ possible (since the structure
>> of the Z matrices could change a lot when we go from the training to
>> the test data).
>>
>> refit() efficiently rebuilds a new deviance function that uses a new
>> response variable, but it relies on everything else in the model
>> staying the same (especially, structure of the  matrices).
>> Before I realized it wouldn't help, I made a quick lme4 branch that
>> adds a "devFunOnly" argument to the refit.merMod method:
>> https://github.com/lme4/lme4/tree/refit_dfonly
>>
>>   If I get feedback that this would be useful for someone I may merge
>> it back to the master branch ...
>>
>>
>> On Fri, Apr 19, 2019 at 7:22 PM Rolf Turner <r.turner at auckland.ac.nz> wrote:
>> >
>> >
>> > I am trying to implement cross-validated likelihood (see e.g. "Model
>> > selection for probabilistic clustering using cross-validated
>> > likelihood", P. Smyth, 2000, Statistics and Computing vol. 10, pp.
>> > 63--72) for model selection in the glmer() binomial family context.
>> >
>> > Briefly what I do is:
>> >
>> >     * divide the data into a "training set" and a "validation set"
>> >       (e.g. 80% and 20%)
>> >     * fit the model of interest to the training set *only*
>> >     * calculate the log-likelihood of the validation set on the
>> >       basis of the model fitted to the training set
>> >
>> > It is the last step about which I have some concern.  I calculate
>> > this log likelihood as
>> >
>> >      sum(log(predict(fit,newdata=VS,type="response")))
>> >
>> > where "fit" is the model fitted to the training set and "VS" is the
>> > validation set.
>> >
>> > I have the uneasy feeling that I may well be doing something stupidly
>> > na?ve here, but I can't see anything obviously wrong with what I am doing.
>> >
>> > I have observed that, if I execute
>> >
>> >      sum(log(predict(fit,type="response")))
>> >
>> > ostensibly calculating the log likelihood of "fit" for the data set from
>> > which "fit" was obtained, I get a very different value from that which
>> > is obtained from executing logLik(fit).   This does not *necessarily*
>> > imply, however, that my method is wrong, since the log likelihood is
>> > "unique only up to an additive constant".  I cannot however see how to
>> > work out what this additive constant might be equal to, so that I can check.
>> >
>> > Can anyone enlighten me as to whether my log likelihood is "correct"?
>> >
>> > And if not, could someone suggest a *correct* means of calculating a
>> > "cross-validated" log likelihood?
>> >
>> > Thanks.
>> >
>> > cheers,
>> >
>> > Rolf Turner
>> >
>> > --
>> > Honorary Research Fellow
>> > Department of Statistics
>> > University of Auckland
>> > Phone: +64-9-373-7599 ext. 88276
>> >
>> > _______________________________________________
>> > R-sig-mixed-models at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From r@turner @end|ng |rom @uck|@nd@@c@nz  Sun Apr 21 01:03:17 2019
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Sun, 21 Apr 2019 11:03:17 +1200
Subject: [R-sig-ME] Log likelihood of a glmer() binomial model .
In-Reply-To: <b41fc0d8-a841-fc55-985d-3457b703e8ce@gmail.com>
References: <306f44cf-a1f9-25d4-4f9f-3dd581698d23@auckland.ac.nz>
 <CABghstTKrwA9x5Xmk=ECwVzHawBp6OnRQCsymKA9DSpZPuATeg@mail.gmail.com>
 <33fd981f-d9db-b824-1c2b-40050b72993e@auckland.ac.nz>
 <CAG_dBVdTdwiSn=9SzR7ewWAqXdgy8sobxRYKE8xd4fJNeuCRJQ@mail.gmail.com>
 <b41fc0d8-a841-fc55-985d-3457b703e8ce@gmail.com>
Message-ID: <f6dd510e-eb80-ce0a-f9ba-eb4d53fa7625@auckland.ac.nz>


On 21/04/19 2:51 AM, Ben Bolker wrote:

>    I agree with Juho that there's a typo -- would be something like.
> 
>   sum((y==1)*log(pred_prob) + (y==0)*log(1-pred_prob))

Whoops.  Not a typo as such but a failure (lapse) in my understanding. 
I was (stupidly) thinking that predict(...,type="response") would 
produce Pr(Y = y_i | predictors_i) but *of course* (!!!) it doesn't --- 
it produces Pr(success | predictors-i).  So I need to invoke dbinom(), 
as Prof. Ruohonen has pointed out.  I think I "really" knew that, but 
somehow my brain slipped a cog.

Sorry for the confusion.

That notwithstanding, (again as Prof. Ruohonen pointed out) this is 
still not right since predict() produces Pr(success | predictors_i, R = 
0) whereas I need Pr(success | predictors_i) with the random effect R 
"integrated out".

>    As far as what predict() does: depending on the value of re.form, it
> either gives a population-level prediction (R=0) or a conditional
> prediction (R set to its conditional mode).  You might be looking for
> *marginal* predictions (which Rizopoulous's GLMMadaptive package can do ...)

Oh dear.  I would then have to switch over from using lme4 to using 
GLMMadaptive ....  Maybe I'll have to climb that mountain.  Or maybe 
I'll go with the "slow" method of calculating cross-validated likelihood 
that Ben Bolker outlined in a previous email.

cheers,

Rolf

> On 2019-04-20 3:42 a.m., Juho Kristian Ruohonen wrote:
>> Rolf: Forgive my ignorance, but isn't the relevant log-likelihood here
>> the log-likelihood of the observed responses in the validation set given
>> the model-predicted probabilities? I.e. sum(dbinom(VS$y, size = VS$n,
>> prob = predict(fit, newdata = VS, type = "response"), log = TRUE))? Even
>> this would be somewhat off because dbinom() isn't aware of the
>> random-effects integral business. But it looks to me like your current
>> call is calculating the log-sum of the predicted probabilities of y = 1
>> in the validation set, not the loglikelihood of the observed responses
>> in the validation set.
>>
>> la 20. huhtik. 2019 klo 8.51 Rolf Turner (r.turner at auckland.ac.nz
>> <mailto:r.turner at auckland.ac.nz>) kirjoitti:
>>
>>
>>      On 20/04/19 12:44 PM, Ben Bolker wrote:
>>
>>      >? ? This seems wrong.
>>
>>      Yeah, that figures.
>>
>>      > The GLMM log-likelihood includes an integral over
>>      > the distribution of the random effects.
>>
>>      I was aware of this.? I guess what I was na?vely expecting was that
>>      predict.merMod() would handle this.? I.e. that this predict method
>>      (with type = "response") would return, for each observed y_i in the
>>      (new) data set
>>
>>      ? ?Pr(Y = y_i) = \int_0 Pr(Y = y_i | R = r) f(r) dr
>>
>>      where R is the vector of random effects and f(r) is its probability
>>      density function (multivariate normal, with mean 0 and some covariance
>>      matrix, which has been estimated in the fitting process.
>>
>>      I guess that this is *not* what predict.merMod() returns --- but I
>>      don't
>>      understand why not.? It seems to me that this is what it "should"
>>      return.
>>
>>      I'm probably misunderstanding something, possibly simple, possibly
>>      subtle.
>>
>>      Apropos of nothing much, what *does* predict.merMod() return?
>>      Maybe Pr(Y = y_i | R = 0) ???
>>
>>      <SNIP>
>>      >? ?Here is an **inefficient** method for computing the likelihood
>>      >
>>      >? ? ?coefs <- unlist(getME(fit,c("theta","beta"))
>>      >? ? ?newdev <- update(fit, data=VS, devFunOnly=TRUE)
>>      >? ? ?newdev(coefs)
>>      >
>>      > This is slow because it has to reconstruct all of the random-effects
>>      > matrices, do permutations to reorder the relevant matrices to be as
>>      > sparse as possible, etc. etc.
>>
>>      Thanks for this.? I'll give it a go.? I think that the slowness may not
>>      be an overwhelming drawback.? Anyhow I shall try to test it out.
>>
>>      Thanks again.
>>
>>      cheers,
>>
>>      Rolf
>>
>>      --
>>      Honorary Research Fellow
>>      Department of Statistics
>>      University of Auckland
>>      Phone: +64-9-373-7599 ext. 88276
>>
>>      _______________________________________________
>>      R-sig-mixed-models at r-project.org
>>      <mailto:R-sig-mixed-models at r-project.org> mailing list
>>      https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>


-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From @ouhey|@@ghebghoub @end|ng |rom gm@||@com  Sun Apr 21 10:57:56 2019
From: @ouhey|@@ghebghoub @end|ng |rom gm@||@com (Souheyla GHEBGHOUB)
Date: Sun, 21 Apr 2019 09:57:56 +0100
Subject: [R-sig-ME] logistic regression on posttest (0, 1) with pretest(0,
 1)*Group(Treatment, Ctrl) interaction
Message-ID: <CAEA998gw2dBJa15idOanou56y-fqCdEv2wFgEsJny-r3TV3Nwg@mail.gmail.com>

Dear Rene, and any member of the list who is willing to read this : )

I have decided to use the interesting model that you have structured for me,
To refresh your memory here is what you said :

*Anyway, there is a second possibility to define your model, depending on
> how you want to interpret it. In the previous model you can say something
> about the type-of-change likelihoods depending on the treatment group.
> But you could implement the model as binomial as well (i.e. logistic
> regression) mod2 <- brm(posttest ~ pretest*Group + (1|Subject) +
> (1+Group|Word),...)  And what you would expect here would be an interaction
> between pre-test and Group. For instance; if pretest=0 & treatment 1 then
> posttest larger than with pretest=0 & treatment 2; but not when pretest=1
> (because this is a plausible no gain situation). And so on...*


But I found the interpretation of the Pretest*Group interaction results to
be tough. I still can't grasp how to claim there is an effect of Group on
posttest outcome when considering pretest. The pretest slope does not come
with 0 or 1 in the output, the Group does come with one category, but its
confusing what the intercept and slope estimates refer to in this case?

Thank you very much,
Souheyla

	[[alternative HTML version deleted]]


From juho@kr|@t|@n@ruohonen @end|ng |rom gm@||@com  Sun Apr 21 18:27:29 2019
From: juho@kr|@t|@n@ruohonen @end|ng |rom gm@||@com (Juho Kristian Ruohonen)
Date: Sun, 21 Apr 2019 19:27:29 +0300
Subject: [R-sig-ME] Log likelihood of a glmer() binomial model .
In-Reply-To: <f6dd510e-eb80-ce0a-f9ba-eb4d53fa7625@auckland.ac.nz>
References: <306f44cf-a1f9-25d4-4f9f-3dd581698d23@auckland.ac.nz>
 <CABghstTKrwA9x5Xmk=ECwVzHawBp6OnRQCsymKA9DSpZPuATeg@mail.gmail.com>
 <33fd981f-d9db-b824-1c2b-40050b72993e@auckland.ac.nz>
 <CAG_dBVdTdwiSn=9SzR7ewWAqXdgy8sobxRYKE8xd4fJNeuCRJQ@mail.gmail.com>
 <b41fc0d8-a841-fc55-985d-3457b703e8ce@gmail.com>
 <f6dd510e-eb80-ce0a-f9ba-eb4d53fa7625@auckland.ac.nz>
Message-ID: <CAG_dBVf6Jj=-=jY+4shU0N_YSbm2-+wjBs4b1LuurPrM6OQnHA@mail.gmail.com>

Rolf: I'm no Prof but a lowly grad student of an unrelated field, so take
all my input with a grain of salt.

As alluded to by Ben, predict() can certainly provide fitted probabilities
for the validation set with the random effects taken into account. This is
achieved by the re.form = NULL argument. However -- and I'll be happy to be
corrected on this -- the problem is that dbinom() will calculate a
(log)likelihood of the observed responses assuming a regular binomial PMF,
which does not apply in the case of a mixed-effects model. Thus the result
will not equal the loglikelihood that is maximized in the fitting process,
i.e. will not equal logLik(validationFit) unless it's a standard logistic
GLM.

Best,

J



su 21. huhtik. 2019 klo 2.03 Rolf Turner (r.turner at auckland.ac.nz)
kirjoitti:

>
> On 21/04/19 2:51 AM, Ben Bolker wrote:
>
> >    I agree with Juho that there's a typo -- would be something like.
> >
> >   sum((y==1)*log(pred_prob) + (y==0)*log(1-pred_prob))
>
> Whoops.  Not a typo as such but a failure (lapse) in my understanding.
> I was (stupidly) thinking that predict(...,type="response") would
> produce Pr(Y = y_i | predictors_i) but *of course* (!!!) it doesn't ---
> it produces Pr(success | predictors-i).  So I need to invoke dbinom(),
> as Prof. Ruohonen has pointed out.  I think I "really" knew that, but
> somehow my brain slipped a cog.
>
> Sorry for the confusion.
>
> That notwithstanding, (again as Prof. Ruohonen pointed out) this is
> still not right since predict() produces Pr(success | predictors_i, R =
> 0) whereas I need Pr(success | predictors_i) with the random effect R
> "integrated out".
>
> >    As far as what predict() does: depending on the value of re.form, it
> > either gives a population-level prediction (R=0) or a conditional
> > prediction (R set to its conditional mode).  You might be looking for
> > *marginal* predictions (which Rizopoulous's GLMMadaptive package can do
> ...)
>
> Oh dear.  I would then have to switch over from using lme4 to using
> GLMMadaptive ....  Maybe I'll have to climb that mountain.  Or maybe
> I'll go with the "slow" method of calculating cross-validated likelihood
> that Ben Bolker outlined in a previous email.
>
> cheers,
>
> Rolf
>
> > On 2019-04-20 3:42 a.m., Juho Kristian Ruohonen wrote:
> >> Rolf: Forgive my ignorance, but isn't the relevant log-likelihood here
> >> the log-likelihood of the observed responses in the validation set given
> >> the model-predicted probabilities? I.e. sum(dbinom(VS$y, size = VS$n,
> >> prob = predict(fit, newdata = VS, type = "response"), log = TRUE))? Even
> >> this would be somewhat off because dbinom() isn't aware of the
> >> random-effects integral business. But it looks to me like your current
> >> call is calculating the log-sum of the predicted probabilities of y = 1
> >> in the validation set, not the loglikelihood of the observed responses
> >> in the validation set.
> >>
> >> la 20. huhtik. 2019 klo 8.51 Rolf Turner (r.turner at auckland.ac.nz
> >> <mailto:r.turner at auckland.ac.nz>) kirjoitti:
> >>
> >>
> >>      On 20/04/19 12:44 PM, Ben Bolker wrote:
> >>
> >>      >    This seems wrong.
> >>
> >>      Yeah, that figures.
> >>
> >>      > The GLMM log-likelihood includes an integral over
> >>      > the distribution of the random effects.
> >>
> >>      I was aware of this.  I guess what I was na?vely expecting was that
> >>      predict.merMod() would handle this.  I.e. that this predict method
> >>      (with type = "response") would return, for each observed y_i in the
> >>      (new) data set
> >>
> >>         Pr(Y = y_i) = \int_0 Pr(Y = y_i | R = r) f(r) dr
> >>
> >>      where R is the vector of random effects and f(r) is its probability
> >>      density function (multivariate normal, with mean 0 and some
> covariance
> >>      matrix, which has been estimated in the fitting process.
> >>
> >>      I guess that this is *not* what predict.merMod() returns --- but I
> >>      don't
> >>      understand why not.  It seems to me that this is what it "should"
> >>      return.
> >>
> >>      I'm probably misunderstanding something, possibly simple, possibly
> >>      subtle.
> >>
> >>      Apropos of nothing much, what *does* predict.merMod() return?
> >>      Maybe Pr(Y = y_i | R = 0) ???
> >>
> >>      <SNIP>
> >>      >   Here is an **inefficient** method for computing the likelihood
> >>      >
> >>      >     coefs <- unlist(getME(fit,c("theta","beta"))
> >>      >     newdev <- update(fit, data=VS, devFunOnly=TRUE)
> >>      >     newdev(coefs)
> >>      >
> >>      > This is slow because it has to reconstruct all of the
> random-effects
> >>      > matrices, do permutations to reorder the relevant matrices to be
> as
> >>      > sparse as possible, etc. etc.
> >>
> >>      Thanks for this.  I'll give it a go.  I think that the slowness
> may not
> >>      be an overwhelming drawback.  Anyhow I shall try to test it out.
> >>
> >>      Thanks again.
> >>
> >>      cheers,
> >>
> >>      Rolf
> >>
> >>      --
> >>      Honorary Research Fellow
> >>      Department of Statistics
> >>      University of Auckland
> >>      Phone: +64-9-373-7599 ext. 88276
> >>
> >>      _______________________________________________
> >>      R-sig-mixed-models at r-project.org
> >>      <mailto:R-sig-mixed-models at r-project.org> mailing list
> >>      https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>
>
>
> --
> Honorary Research Fellow
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>

	[[alternative HTML version deleted]]


From j@ork|n @end|ng |rom @om@um@ry|@nd@edu  Sun Apr 21 20:01:59 2019
From: j@ork|n @end|ng |rom @om@um@ry|@nd@edu (Sorkin, John)
Date: Sun, 21 Apr 2019 18:01:59 +0000
Subject: [R-sig-ME] 
 logistic regression on posttest (0, 1) with pretest(0,
 1)*Group(Treatment, Ctrl) interaction
In-Reply-To: <CAEA998gw2dBJa15idOanou56y-fqCdEv2wFgEsJny-r3TV3Nwg@mail.gmail.com>
References: <CAEA998gw2dBJa15idOanou56y-fqCdEv2wFgEsJny-r3TV3Nwg@mail.gmail.com>
Message-ID: <BN7PR03MB3730B3739E6AC1A906671022E2210@BN7PR03MB3730.namprd03.prod.outlook.com>

Souheyla,

It is both difficult and dangerous to add a comment to a thread that one has not followed, and in doing so possibly making an inappropriate suggestion. Please forgive what may be an not fully informed thought.

The model you suggest, posttest ~ pretest*Group  (ignoring random effects) is unusual. In a model that contains an interaction,  I would expect to see, in addition to the interaction, all main effects included in the interaction, i.e.
posttest ~ group+pretest+pretest*Group

John


John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing)


________________________________
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of Souheyla GHEBGHOUB <souheyla.ghebghoub at gmail.com>
Sent: Sunday, April 21, 2019 4:57 AM
To: Ren?; r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] logistic regression on posttest (0, 1) with pretest(0, 1)*Group(Treatment, Ctrl) interaction

Dear Rene, and any member of the list who is willing to read this : )

I have decided to use the interesting model that you have structured for me,
To refresh your memory here is what you said :

*Anyway, there is a second possibility to define your model, depending on
> how you want to interpret it. In the previous model you can say something
> about the type-of-change likelihoods depending on the treatment group.
> But you could implement the model as binomial as well (i.e. logistic
> regression) mod2 <- brm(posttest ~ pretest*Group + (1|Subject) +
> (1+Group|Word),...)  And what you would expect here would be an interaction
> between pre-test and Group. For instance; if pretest=0 & treatment 1 then
> posttest larger than with pretest=0 & treatment 2; but not when pretest=1
> (because this is a plausible no gain situation). And so on...*


But I found the interpretation of the Pretest*Group interaction results to
be tough. I still can't grasp how to claim there is an effect of Group on
posttest outcome when considering pretest. The pretest slope does not come
with 0 or 1 in the output, the Group does come with one category, but its
confusing what the intercept and slope estimates refer to in this case?

Thank you very much,
Souheyla

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From @ouhey|@@ghebghoub @end|ng |rom gm@||@com  Sun Apr 21 20:07:32 2019
From: @ouhey|@@ghebghoub @end|ng |rom gm@||@com (Souheyla GHEBGHOUB)
Date: Sun, 21 Apr 2019 19:07:32 +0100
Subject: [R-sig-ME] 
 logistic regression on posttest (0, 1) with pretest(0,
 1)*Group(Treatment, Ctrl) interaction
In-Reply-To: <BN7PR03MB3730B3739E6AC1A906671022E2210@BN7PR03MB3730.namprd03.prod.outlook.com>
References: <CAEA998gw2dBJa15idOanou56y-fqCdEv2wFgEsJny-r3TV3Nwg@mail.gmail.com>
 <BN7PR03MB3730B3739E6AC1A906671022E2210@BN7PR03MB3730.namprd03.prod.outlook.com>
Message-ID: <CAEA998i_MzN7vN_mPptTaRRj7sYj4unPrrvRRY1YoSEXGioUBQ@mail.gmail.com>

Dear John,

Thank you for your email.
I used to think that  *posttest ~ pretest*Group* will automatically give
you the main effects of group and pretest without having to set them again
separately in the syntax? Please correct me if I am wrong.

Thank you again,
Souheyla


On Sun, 21 Apr 2019 at 19:02, Sorkin, John <jsorkin at som.umaryland.edu>
wrote:

> Souheyla,
>
> It is both difficult and dangerous to add a comment to a thread that one
> has not followed, and in doing so possibly making an inappropriate
> suggestion. Please forgive what may be an not fully informed thought.
>
> The model you suggest, posttest ~ pretest*Group  (ignoring random
> effects) is unusual. In a model that contains an interaction,  I would
> expect to see, in addition to the interaction, all main effects included in
> the interaction, i.e.
> posttest ~ group+pretest+pretest*Group
>
> John
>
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and
> Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>
>
>
> ------------------------------
> *From:* R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on
> behalf of Souheyla GHEBGHOUB <souheyla.ghebghoub at gmail.com>
> *Sent:* Sunday, April 21, 2019 4:57 AM
> *To:* Ren?; r-sig-mixed-models at r-project.org
> *Subject:* [R-sig-ME] logistic regression on posttest (0, 1) with
> pretest(0, 1)*Group(Treatment, Ctrl) interaction
>
> Dear Rene, and any member of the list who is willing to read this : )
>
> I have decided to use the interesting model that you have structured for
> me,
> To refresh your memory here is what you said :
>
> *Anyway, there is a second possibility to define your model, depending on
> > how you want to interpret it. In the previous model you can say something
> > about the type-of-change likelihoods depending on the treatment group.
> > But you could implement the model as binomial as well (i.e. logistic
> > regression) mod2 <- brm(posttest ~ pretest*Group + (1|Subject) +
> > (1+Group|Word),...)  And what you would expect here would be an
> interaction
> > between pre-test and Group. For instance; if pretest=0 & treatment 1 then
> > posttest larger than with pretest=0 & treatment 2; but not when pretest=1
> > (because this is a plausible no gain situation). And so on...*
>
>
> But I found the interpretation of the Pretest*Group interaction results to
> be tough. I still can't grasp how to claim there is an effect of Group on
> posttest outcome when considering pretest. The pretest slope does not come
> with 0 or 1 in the output, the Group does come with one category, but its
> confusing what the intercept and slope estimates refer to in this case?
>
> Thank you very much,
> Souheyla
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From j@ork|n @end|ng |rom @om@um@ry|@nd@edu  Sun Apr 21 20:55:55 2019
From: j@ork|n @end|ng |rom @om@um@ry|@nd@edu (Sorkin, John)
Date: Sun, 21 Apr 2019 18:55:55 +0000
Subject: [R-sig-ME] 
 logistic regression on posttest (0, 1) with pretest(0,
 1)*Group(Treatment, Ctrl) interaction
In-Reply-To: <CAEA998i_MzN7vN_mPptTaRRj7sYj4unPrrvRRY1YoSEXGioUBQ@mail.gmail.com>
References: <CAEA998gw2dBJa15idOanou56y-fqCdEv2wFgEsJny-r3TV3Nwg@mail.gmail.com>
 <BN7PR03MB3730B3739E6AC1A906671022E2210@BN7PR03MB3730.namprd03.prod.outlook.com>,
 <CAEA998i_MzN7vN_mPptTaRRj7sYj4unPrrvRRY1YoSEXGioUBQ@mail.gmail.com>
Message-ID: <BN7PR03MB37300E47039A0DB642EE1DA7E2210@BN7PR03MB3730.namprd03.prod.outlook.com>

Souheyla,

Souheyla,

I don't know every R package so I can't make a blanket statement. Searching the internet makes it appear that  using lm(y~x*z) will produce a model with the main effects and the interaction, i.e. y=f(x,z,x*z). Nevertheless, I believe it to be best coding practices (especially when sending your code to a third part) to always expressly give all terms in a model and never leave the main effects out of a model with an interaction. I am sorry I can't be of any additional help with the more fundamental aspects of your original posting.

John


John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing)


________________________________
From: Souheyla GHEBGHOUB <souheyla.ghebghoub at gmail.com>
Sent: Sunday, April 21, 2019 2:07 PM
To: Sorkin, John
Cc: Ren?; r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] logistic regression on posttest (0, 1) with pretest(0, 1)*Group(Treatment, Ctrl) interaction

Dear John,

Thank you for your email.
I used to think that  posttest ~ pretest*Group will automatically give you the main effects of group and pretest without having to set them again separately in the syntax? Please correct me if I am wrong.

Thank you again,
Souheyla


On Sun, 21 Apr 2019 at 19:02, Sorkin, John <jsorkin at som.umaryland.edu<mailto:jsorkin at som.umaryland.edu>> wrote:
Souheyla,

It is both difficult and dangerous to add a comment to a thread that one has not followed, and in doing so possibly making an inappropriate suggestion. Please forgive what may be an not fully informed thought.

The model you suggest, posttest ~ pretest*Group  (ignoring random effects) is unusual. In a model that contains an interaction,  I would expect to see, in addition to the interaction, all main effects included in the interaction, i.e.
posttest ~ group+pretest+pretest*Group

John


John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing)


________________________________
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org<mailto:r-sig-mixed-models-bounces at r-project.org>> on behalf of Souheyla GHEBGHOUB <souheyla.ghebghoub at gmail.com<mailto:souheyla.ghebghoub at gmail.com>>
Sent: Sunday, April 21, 2019 4:57 AM
To: Ren?; r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>
Subject: [R-sig-ME] logistic regression on posttest (0, 1) with pretest(0, 1)*Group(Treatment, Ctrl) interaction

Dear Rene, and any member of the list who is willing to read this : )

I have decided to use the interesting model that you have structured for me,
To refresh your memory here is what you said :

*Anyway, there is a second possibility to define your model, depending on
> how you want to interpret it. In the previous model you can say something
> about the type-of-change likelihoods depending on the treatment group.
> But you could implement the model as binomial as well (i.e. logistic
> regression) mod2 <- brm(posttest ~ pretest*Group + (1|Subject) +
> (1+Group|Word),...)  And what you would expect here would be an interaction
> between pre-test and Group. For instance; if pretest=0 & treatment 1 then
> posttest larger than with pretest=0 & treatment 2; but not when pretest=1
> (because this is a plausible no gain situation). And so on...*


But I found the interpretation of the Pretest*Group interaction results to
be tough. I still can't grasp how to claim there is an effect of Group on
posttest outcome when considering pretest. The pretest slope does not come
with 0 or 1 in the output, the Group does come with one category, but its
confusing what the intercept and slope estimates refer to in this case?

Thank you very much,
Souheyla

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From @ouhey|@@ghebghoub @end|ng |rom gm@||@com  Sun Apr 21 21:01:16 2019
From: @ouhey|@@ghebghoub @end|ng |rom gm@||@com (Souheyla GHEBGHOUB)
Date: Sun, 21 Apr 2019 20:01:16 +0100
Subject: [R-sig-ME] 
 logistic regression on posttest (0, 1) with pretest(0,
 1)*Group(Treatment, Ctrl) interaction
In-Reply-To: <BN7PR03MB37300E47039A0DB642EE1DA7E2210@BN7PR03MB3730.namprd03.prod.outlook.com>
References: <CAEA998gw2dBJa15idOanou56y-fqCdEv2wFgEsJny-r3TV3Nwg@mail.gmail.com>
 <BN7PR03MB3730B3739E6AC1A906671022E2210@BN7PR03MB3730.namprd03.prod.outlook.com>
 <CAEA998i_MzN7vN_mPptTaRRj7sYj4unPrrvRRY1YoSEXGioUBQ@mail.gmail.com>
 <BN7PR03MB37300E47039A0DB642EE1DA7E2210@BN7PR03MB3730.namprd03.prod.outlook.com>
Message-ID: <CAEA998io9w3GKdMKLzvP-+ukcQwXckVFnG=88q7CXveNmZ+3Ag@mail.gmail.com>

Dear John,

Thank you for the sound advice I will make sure to always be explicit when
writing  models.
Thank you and I totally understand you cannot be of help in this specific
post.

Kind regards,
Souheyla

On Sun, 21 Apr 2019 at 19:55, Sorkin, John <jsorkin at som.umaryland.edu>
wrote:

> Souheyla,
>
> Souheyla,
>
> I don't know every R package so I can't make a blanket statement.
> Searching the internet makes it appear that  using lm(y~x*z) will produce
> a model with the main effects and the interaction, i.e. y=f(x,z,x*z).
> Nevertheless, I believe it to be best coding practices (especially when
> sending your code to a third part) to always expressly give all terms in a
> model and never leave the main effects out of a model with an interaction.
> I am sorry I can't be of any additional help with the more fundamental
> aspects of your original posting.
>
> John
>
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and
> Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>
>
>
> ------------------------------
> *From:* Souheyla GHEBGHOUB <souheyla.ghebghoub at gmail.com>
> *Sent:* Sunday, April 21, 2019 2:07 PM
> *To:* Sorkin, John
> *Cc:* Ren?; r-sig-mixed-models at r-project.org
> *Subject:* Re: [R-sig-ME] logistic regression on posttest (0, 1) with
> pretest(0, 1)*Group(Treatment, Ctrl) interaction
>
> Dear John,
>
> Thank you for your email.
> I used to think that  *posttest ~ pretest*Group* will automatically give
> you the main effects of group and pretest without having to set them again
> separately in the syntax? Please correct me if I am wrong.
>
> Thank you again,
> Souheyla
>
>
> On Sun, 21 Apr 2019 at 19:02, Sorkin, John <jsorkin at som.umaryland.edu>
> wrote:
>
> Souheyla,
>
> It is both difficult and dangerous to add a comment to a thread that one
> has not followed, and in doing so possibly making an inappropriate
> suggestion. Please forgive what may be an not fully informed thought.
>
> The model you suggest, posttest ~ pretest*Group  (ignoring random
> effects) is unusual. In a model that contains an interaction,  I would
> expect to see, in addition to the interaction, all main effects included in
> the interaction, i.e.
> posttest ~ group+pretest+pretest*Group
>
> John
>
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and
> Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>
>
>
> ------------------------------
> *From:* R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on
> behalf of Souheyla GHEBGHOUB <souheyla.ghebghoub at gmail.com>
> *Sent:* Sunday, April 21, 2019 4:57 AM
> *To:* Ren?; r-sig-mixed-models at r-project.org
> *Subject:* [R-sig-ME] logistic regression on posttest (0, 1) with
> pretest(0, 1)*Group(Treatment, Ctrl) interaction
>
> Dear Rene, and any member of the list who is willing to read this : )
>
> I have decided to use the interesting model that you have structured for
> me,
> To refresh your memory here is what you said :
>
> *Anyway, there is a second possibility to define your model, depending on
> > how you want to interpret it. In the previous model you can say something
> > about the type-of-change likelihoods depending on the treatment group.
> > But you could implement the model as binomial as well (i.e. logistic
> > regression) mod2 <- brm(posttest ~ pretest*Group + (1|Subject) +
> > (1+Group|Word),...)  And what you would expect here would be an
> interaction
> > between pre-test and Group. For instance; if pretest=0 & treatment 1 then
> > posttest larger than with pretest=0 & treatment 2; but not when pretest=1
> > (because this is a plausible no gain situation). And so on...*
>
>
> But I found the interpretation of the Pretest*Group interaction results to
> be tough. I still can't grasp how to claim there is an effect of Group on
> posttest outcome when considering pretest. The pretest slope does not come
> with 0 or 1 in the output, the Group does come with one category, but its
> confusing what the intercept and slope estimates refer to in this case?
>
> Thank you very much,
> Souheyla
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>

	[[alternative HTML version deleted]]


From r@turner @end|ng |rom @uck|@nd@@c@nz  Mon Apr 22 01:48:54 2019
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Mon, 22 Apr 2019 11:48:54 +1200
Subject: [R-sig-ME] Log likelihood of a glmer() binomial model .
In-Reply-To: <CAG_dBVf6Jj=-=jY+4shU0N_YSbm2-+wjBs4b1LuurPrM6OQnHA@mail.gmail.com>
References: <306f44cf-a1f9-25d4-4f9f-3dd581698d23@auckland.ac.nz>
 <CABghstTKrwA9x5Xmk=ECwVzHawBp6OnRQCsymKA9DSpZPuATeg@mail.gmail.com>
 <33fd981f-d9db-b824-1c2b-40050b72993e@auckland.ac.nz>
 <CAG_dBVdTdwiSn=9SzR7ewWAqXdgy8sobxRYKE8xd4fJNeuCRJQ@mail.gmail.com>
 <b41fc0d8-a841-fc55-985d-3457b703e8ce@gmail.com>
 <f6dd510e-eb80-ce0a-f9ba-eb4d53fa7625@auckland.ac.nz>
 <CAG_dBVf6Jj=-=jY+4shU0N_YSbm2-+wjBs4b1LuurPrM6OQnHA@mail.gmail.com>
Message-ID: <ca44075b-78c7-590c-1a25-2ff36ba7a97f@auckland.ac.nz>


On 22/04/19 4:27 AM, Juho Kristian Ruohonen wrote:

> Rolf: I'm no Prof but a lowly grad student of an unrelated field, so 
> take all my input with a grain of salt.

Well, you will very likely *be* a Prof. someday.  And your input seems 
very sound to me.  (I am a retired "Honorary" Research Fellow, which 
seems to me to be even lowlier than a grad student; grad students 
generally get at least a *bit* of monetary compensation, in the form of 
scholarships or other stipends. :-) )

> As alluded to by Ben, predict() can certainly provide fitted 
> probabilities for the validation set with the random effects taken into 
> account. This is achieved by the re.form = NULL argument. However -- and 
> I'll be happy to be corrected on this -- the problem is that dbinom() 
> will calculate a (log)likelihood of the observed responses assuming a 
> regular binomial PMF, which does not apply in the case of a 
> mixed-effects model. Thus the result will not equal the loglikelihood 
> that is maximized in the fitting process, i.e. will not equal 
> logLik(validationFit) unless it's a standard logistic GLM.

Thanks.  I'm going to have to chew this over a bit more .... Takes me a 
while to get my head around these issues.

cheers,

Rolf

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From r@turner @end|ng |rom @uck|@nd@@c@nz  Mon Apr 22 01:58:44 2019
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Mon, 22 Apr 2019 11:58:44 +1200
Subject: [R-sig-ME] [FORGED] Re:  logistic regression on posttest (0,
 1) with pretest(0, 1)*Group(Treatment, Ctrl) interaction
In-Reply-To: <BN7PR03MB3730B3739E6AC1A906671022E2210@BN7PR03MB3730.namprd03.prod.outlook.com>
References: <CAEA998gw2dBJa15idOanou56y-fqCdEv2wFgEsJny-r3TV3Nwg@mail.gmail.com>
 <BN7PR03MB3730B3739E6AC1A906671022E2210@BN7PR03MB3730.namprd03.prod.outlook.com>
Message-ID: <8b76dea0-0d9a-5b61-0c15-465c3705b988@auckland.ac.nz>


On 22/04/19 6:01 AM, Sorkin, John wrote:

> Souheyla,
> 
> It is both difficult and dangerous to add a comment to a thread that
> one has not followed, and in doing so possibly making an
> inappropriate suggestion. Please forgive what may be an not fully
> informed thought.
> 
> The model you suggest, posttest ~ pretest*Group  (ignoring random
> effects) is unusual. In a model that contains an interaction,  I
> would expect to see, in addition to the interaction, all main effects
> included in the interaction, i.e. posttest ~
> group+pretest+pretest*Group.

As Souheyla has already indicated, in the R (and previously S/Splus) 
formula syntax, interactions are indicated by a *colon* --- a:b.  The 
notation "a*b" is a shorthand for
a + b + a:b.

So pretest*Group is the same as pretest + Group + pretest:Group, whence 
it contains the main effects.

I disagree with the advice that you gave Souheyla in a follow-up email.
The construction pretest*Group is preferable, being compact and tidy. 
Brevity is a virtue.

cheers,

Rolf

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Mon Apr 22 04:02:41 2019
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sun, 21 Apr 2019 19:02:41 -0700 (PDT)
Subject: [R-sig-ME] [FORGED] Re: logistic regression on posttest (0,
 1) with pretest(0, 1)*Group(Treatment, Ctrl) interaction
In-Reply-To: <8b76dea0-0d9a-5b61-0c15-465c3705b988@auckland.ac.nz>
References: <CAEA998gw2dBJa15idOanou56y-fqCdEv2wFgEsJny-r3TV3Nwg@mail.gmail.com>
 <BN7PR03MB3730B3739E6AC1A906671022E2210@BN7PR03MB3730.namprd03.prod.outlook.com>
 <8b76dea0-0d9a-5b61-0c15-465c3705b988@auckland.ac.nz>
Message-ID: <alpine.BSF.2.00.1904211856000.82745@pedal.dcn.davis.ca.us>

There is no "formula" syntax other than it has to have at least one 
tilde... there is "lm" formula syntax, and "lme" formula syntax, and "nls" 
formula syntax, etc... and other model builders are not obligated to 
adhere to the "lm" interpretation of formulas.

I don't see why using * alone in an lm formula should be avoided, but 
perhaps John's advice could be reframed as "watch out for the specific 
syntax used by your model building function... it may not be the same as 
that used by lm".

On Mon, 22 Apr 2019, Rolf Turner wrote:

>
> On 22/04/19 6:01 AM, Sorkin, John wrote:
>
>> Souheyla,
>> 
>> It is both difficult and dangerous to add a comment to a thread that
>> one has not followed, and in doing so possibly making an
>> inappropriate suggestion. Please forgive what may be an not fully
>> informed thought.
>> 
>> The model you suggest, posttest ~ pretest*Group  (ignoring random
>> effects) is unusual. In a model that contains an interaction,  I
>> would expect to see, in addition to the interaction, all main effects
>> included in the interaction, i.e. posttest ~
>> group+pretest+pretest*Group.
>
> As Souheyla has already indicated, in the R (and previously S/Splus) formula 
> syntax, interactions are indicated by a *colon* --- a:b.  The notation "a*b" 
> is a shorthand for
> a + b + a:b.
>
> So pretest*Group is the same as pretest + Group + pretest:Group, whence it 
> contains the main effects.
>
> I disagree with the advice that you gave Souheyla in a follow-up email.
> The construction pretest*Group is preferable, being compact and tidy. Brevity 
> is a virtue.
>
> cheers,
>
> Rolf
>
> -- 
> Honorary Research Fellow
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From r@turner @end|ng |rom @uck|@nd@@c@nz  Mon Apr 22 09:49:09 2019
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Mon, 22 Apr 2019 19:49:09 +1200
Subject: [R-sig-ME] Log likelihood of a glmer() binomial model .
In-Reply-To: <CAG_dBVf6Jj=-=jY+4shU0N_YSbm2-+wjBs4b1LuurPrM6OQnHA@mail.gmail.com>
References: <306f44cf-a1f9-25d4-4f9f-3dd581698d23@auckland.ac.nz>
 <CABghstTKrwA9x5Xmk=ECwVzHawBp6OnRQCsymKA9DSpZPuATeg@mail.gmail.com>
 <33fd981f-d9db-b824-1c2b-40050b72993e@auckland.ac.nz>
 <CAG_dBVdTdwiSn=9SzR7ewWAqXdgy8sobxRYKE8xd4fJNeuCRJQ@mail.gmail.com>
 <b41fc0d8-a841-fc55-985d-3457b703e8ce@gmail.com>
 <f6dd510e-eb80-ce0a-f9ba-eb4d53fa7625@auckland.ac.nz>
 <CAG_dBVf6Jj=-=jY+4shU0N_YSbm2-+wjBs4b1LuurPrM6OQnHA@mail.gmail.com>
Message-ID: <e5a38615-6798-6107-0e21-ab394df09e72@auckland.ac.nz>


On 22/04/19 4:27 AM, Juho Kristian Ruohonen wrote:

<SNIP>

> As alluded to by Ben, predict() can certainly provide fitted 
> probabilities for the validation set with the random effects taken into 
> account. This is achieved by the re.form = NULL argument. However -- and 
> I'll be happy to be corrected on this -- the problem is that dbinom() 
> will calculate a (log)likelihood of the observed responses assuming a 
> regular binomial PMF, which does not apply in the case of a 
> mixed-effects model. Thus the result will not equal the loglikelihood 
> that is maximized in the fitting process, i.e. will not equal 
> logLik(validationFit) unless it's a standard logistic GLM.

OK.  I have finally understood the stupidity that I was perpetrating. 
It can expressed succinctly as thinking that E(f(P)) = f(E(P)).  Which 
is true only if f() is an affine function.  I used to go off my trolley 
complaining when undergraduate students committed such atrocities. :-(

(In the foregoing f() may be taken to be the binomial probability 
function with some fixed "x" value, and P to be the success probability.
So even if predict.merMod() delivered E(P) as I previously thought it 
did, my so called cross-validated log likelihood would still be incorrect.)

Sorry for all the noise.

cheers,

Rolf

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From c@r@t@|@ @end|ng |rom donder@@ru@n|  Mon Apr 22 12:29:14 2019
From: c@r@t@|@ @end|ng |rom donder@@ru@n| (Catalina Ratala)
Date: Mon, 22 Apr 2019 13:29:14 +0300
Subject: [R-sig-ME] singularity issue in lmer
In-Reply-To: <CAJuCY5wvOACHmNx8ezDP3nj=dteA1+B1wCee5T90mdHh1g0nAQ@mail.gmail.com>
References: <E93B3350-1BD7-4B1C-B592-52C8221CFA3F@donders.ru.nl>
 <CAJuCY5wvOACHmNx8ezDP3nj=dteA1+B1wCee5T90mdHh1g0nAQ@mail.gmail.com>
Message-ID: <C2161D46-9E12-4B65-A8EF-CDC260C54C03@donders.ru.nl>

Dear Thierry,

Thank you very much for your reply! 
Indeed, i tried to simplify the model in different ways - the ones that run without errors are the ones where f_Order is not modelled as a random slope. So, the one you suggested:
> lmer(Rate ~ f_Order*f_Valence +  f_Attribute + (1 | Subject), data = data) 
works, without any errors. 
However, won?t the p-values I get for this model be inflated, since I don?t have random effects for any of the fixed factors in which I am interested in (f_Order and f_Valence)? 
Are these p-values reliable?

best,
Catalina


> On 17 Apr 2019, at 21:04, Thierry Onkelinx <thierry.onkelinx at inbo.be> wrote:
> 
> Dear Catalina,
> 
> Your model is too complex for the data. The NaN values in the output are a hint. I see two solutions. 1) collect more data. 2) simplify your model.
> 
> Ttest if  lmer(Rate ~ f_Order*f_Valence +  f_Attribute + (1 | Subject), data = data) works.
> 
> Best regards,
> 
> ir. Thierry Onkelinx
> Statisticus / Statistician
> 
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance 
> thierry.onkelinx at inbo.be <mailto:thierry.onkelinx at inbo.be>
> Havenlaan 88 bus 73, 1000 Brussel
> www.inbo.be <http://www.inbo.be/>
> 
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey
> ///////////////////////////////////////////////////////////////////////////////////////////
> 
>  <https://www.inbo.be/>
> 
> 
> Op wo 17 apr. 2019 om 18:13 schreef Catalina Ratala <c.ratala at donders.ru.nl <mailto:c.ratala at donders.ru.nl>>:
> Dear List,
> 
> I?m trying to make the following model converge without warnings, using the lme4 package:
> 
> Variables: Order (3 levels), Valence (2 levels), and Attribute (2 levels) are all factors, Rate is the DV, continuous, 1-10 range.
> 
> model_lme4 <- lmer(Rate ~ f_Order*f_Valence + f_Attribute +  (1 + f_Order*f_Valence | Subject), data = data)
> 
> summary(model_lme4)
> 
> Linear mixed model fit by REML ['lmerMod']
> Formula: Rate ~ f_Order * f_Valence + f_Attribute + (1 + f_Order * f_Valence | 
>     Subject)
>    Data: data
> 
> REML criterion at convergence: 12167.1
> 
> Scaled residuals:
>     Min      1Q  Median      3Q     Max
> -5.0966 -0.5745 -0.0331  0.5851  5.1733
> 
> Random effects:
>  Groups   Name                Variance Std.Dev. Corr                        
>  Subject  (Intercept)         0.135654 0.36831                              
>           f_Order1            0.002681 0.05178  -0.66                       
>           f_Order2            0.003578 0.05982   0.31 -0.92                 
>           f_Valence1          0.343519 0.58611   0.35 -0.01 -0.17           
>           f_Order1:f_Valence1 0.009916 0.09958  -0.09 -0.49  0.66  0.36     
>           f_Order2:f_Valence1 0.001073 0.03276   0.01  0.02 -0.02 -0.88 -0.70
>  Residual                     0.974439 0.98714                              
> Number of obs: 4237, groups:  Subject, 29
> 
> Fixed effects:
>                       Estimate Std. Error t value
> (Intercept)          4.8820728  0.0700895  69.655
> f_Order1            -0.0005486  0.0235150  -0.023
> f_Order2             0.0220543  0.0241765   0.912
> f_Valence1          -1.3284410  0.1099083 -12.087
> f_Attribute1         0.0401858  0.0221600   1.813
> f_Attribute2        -0.1078952  0.0217247  -4.966
> f_Order1:f_Valence1 -0.0157678  0.0283515  -0.556
> f_Order2:f_Valence1  0.0552990  0.0223037   2.479
> 
> Correlation of Fixed Effects:
>             (Intr) f_Ord1 f_Ord2 f_Vln1 f_Att1 f_Att2 f_O1:_
> f_Order1    -0.263                                         
> f_Order2     0.138 -0.578                                   
> f_Valence1   0.340 -0.005 -0.077                           
> f_Attribut1  0.014 -0.014 -0.024 -0.001                    
> f_Attribut2  0.000 -0.007  0.023  0.007 -0.531             
> f_Ordr1:_V1 -0.057 -0.131  0.200  0.234  0.016 -0.008      
> f_Ordr2:_V1  0.001  0.001 -0.002 -0.237 -0.019  0.027 -0.488
> convergence code: 0
> boundary (singular) fit: see ?isSingular
> 
> 
> 
> My problem is that I get this warning message saying that the model is singular:
> 
> boundary (singular) fit: see ?isSingular
> 
> 
> 
> I used the function isSingular() (package lme4) to test whether actually the warning is valid. It returned TRUE as an outcome, meaning the parameters are on the boundary of the feasible parameter space, and variances of one or more linear combinations of effects are (close to) zero.
> 
> I also used allfits() function (afex package) to check whether different optimizers give the same error, which was the case for all the optimizers with which the model converged.
> 
> Following different guidelines presented in the literature I tried:
> 
> a)     to remove the covariance between random effects, by running the following model:
> 
> model_nocov <- lmer(Rate ~ f_Order*f_Valence +  f_Attribute + (0 + f_Order*f_Valence | Subject) + (1 | Subject), data = data);
> 
> Linear mixed model fit by REML ['lmerMod']
> Formula: Rate ~ f_Order * f_Valence + f_Attribute + (0 + f_Order * f_Valence | 
>     Subject) + (1 | Subject)
>    Data: data
> 
> REML criterion at convergence: 11707
> 
> Scaled residuals:
>     Min      1Q  Median      3Q     Max
> -5.1014 -0.5736 -0.0361  0.5815  5.1984
> 
> Random effects:
>  Groups    Name                Variance Std.Dev. Corr                        
>  Subject   f_Orderfirst        0.000000 0.00000                              
>            f_Ordersecond       0.009510 0.09752    NaN                       
>            f_Orderthird        0.004304 0.06561    NaN  0.66                 
>            f_Valence1          0.105713 0.32514    NaN  0.74  0.68           
>            f_Order1:f_Valence1 0.009706 0.09852    NaN  0.83  0.13  0.49     
>            f_Order2:f_Valence1 0.001249 0.03534    NaN -0.52 -0.14 -0.82 -0.60
>  Subject.1 (Intercept)         0.127141 0.35657                              
>  Residual                      0.973996 0.98691                              
> Number of obs: 4087, groups:  Subject, 28
> 
> Fixed effects:
>                      Estimate Std. Error t value
> (Intercept)          4.873808   0.069807  69.818
> f_Order1            -0.005478   0.023784  -0.230
> f_Order2             0.028555   0.024044   1.188
> f_Valence1          -1.420611   0.063388 -22.411
> f_Attribute1         0.048127   0.022588   2.131
> f_Attribute2        -0.120467   0.022118  -5.447
> f_Order1:f_Valence1 -0.016950   0.028729  -0.590
> f_Order2:f_Valence1  0.057331   0.022845   2.510
> 
> Correlation of Fixed Effects:
>             (Intr) f_Ord1 f_Ord2 f_Vln1 f_Att1 f_Att2 f_O1:_
> f_Order1    -0.054                                         
> f_Order2     0.045 -0.548                                  
> f_Valence1   0.103 -0.301  0.255                           
> f_Attribut1  0.015 -0.015 -0.025 -0.001                    
> f_Attribut2  0.000 -0.004  0.019  0.010 -0.533             
> f_Ordr1:_V1  0.053 -0.154  0.260  0.306  0.018 -0.009      
> f_Ordr2:_V1 -0.016  0.046 -0.070 -0.233 -0.018  0.028 -0.477
> convergence code: 0
> boundary (singular) fit: see ?isSingular
> 
> 
> 
> 
> b)     to remove outlier cases;
> 
> However, I still got the same warning and the is.singular() indicated that the warnings were to be considered (TRUE).
> 
> Moreover, I realized that in this case, what causes the problem are the correlations between the levels of the factor ORDER, which is the one related to my main hypothesis and therefore, I cannot exclude its random slope from the model, as I am interested in its statistical significance and, thus, getting a p-value for it. 
> 
> I would like to ask for advice on what I can do to make the model converge without warnings. Is there anything that could be done with the levels of the factor (Order), that seem to be causing the problem? Any other suggestion is, of course, welcomed.
> 
> 
> 
> Thank you in advance for your time and help!
> 
> 
> 
> Best,
> 
> Catalina
> 
> 
> 
> 
> 
> 
>         [[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org <mailto:R-sig-mixed-models at r-project.org> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>

C?t?lina E R??al? MSc
PhD candidate
 	 

ROTTERDAM SCHOOL OF MANAGEMENT
ERASMUS UNIVERSITY
DEPARTMENT OF MARKETING MANAGEMENT
 
postal address: P.O. Box 1738; 3000 DR Rotterdam
email: cratala at rsm.nl <mailto:touburg at rsm.nl>
http://www.rsm.nl/people/catalina-ratala/

DONDERS INSTITUTE FOR BRAIN, COGNITION & BEHAVIOUR
DONDERS CENTRE FOR COGNITIVE NEUROIMAGING
 
visiting address: Kapittelweg 29, Room 2.262n, 6525 EN, Nijmegen
postal address: P.O. box 9101, 6500 HB Nijmegen
tel: +31 - (0)24-3668388
email: c.ratala at donders.ru.nl
http://www.ru.nl/people/donders/ratala-c/
http://www.decisionneurosciencelab.com/people/





	[[alternative HTML version deleted]]


From m@tr@cc|@ @end|ng |rom hotm@||@com  Mon Apr 22 22:29:24 2019
From: m@tr@cc|@ @end|ng |rom hotm@||@com (Mark Straccia)
Date: Mon, 22 Apr 2019 20:29:24 +0000
Subject: [R-sig-ME] MCMCglmm bivariate logistic and poisson regression
Message-ID: <BYAPR01MB53842D0E4CA846C4FB357840BE220@BYAPR01MB5384.prod.exchangelabs.com>

Hi all,

I am trying to run a bivariate cross-classified logistic and poisson regression with MCMCglmm. First I have to say MCMCglmm is great because it is so flexible! The part I am having trouble with is that logistic regression has no error terms so running bivariate (two outputs) regression seems pointless because I can't capture the correlation between two outputs. In MCMCglmm, the error variance has to be set to a number in order for the program to run. Whatever it is set to, the beta values must then be correct by k <- sqrt(1 + (((16 * sqrt(3))/(15 * pi))^2) * sigma (where sigma is the set variance). If I am running bivariate logistic regression the covariance between the errors also has to be set. It is recommended to be set at 0.5 and variances as 1.

1) Since the covariance is 0.5 in addition to variance being 1, do the betas need to be corrected by anything other than the standard k <- sqrt(1 + (((16 * sqrt(3))/(15 * pi))^2) * sigma (where sigma=1)?

2) 0.5 value seems arbitrary and I should instead let the data determine what the covariance is between the outputs. I tried rcov = ~corg(trait):units and when I run it, the covariance becomes 1 which I do not understand why this is happening. For output1 and output2 are 14% ones. If there is a one for output1, there is a 61% of the time there is a one for output2 and if there is a zero for output1, there is a 93.7% of the time there is a zero for output2. The correlation between output1 and output2 is 0.55 and the hamming distance is 264 out of 2450 data points (0.108). Why does the covariance become 1 rather than a lower number? (I should note that the data is doubled so outcome A in output1 and outcome B in output2 will later become outcome B for output1 and outcome A for output2, however, as noted earlier output1 is not perfectly predictive of output2)

3) Since logistic regression has no error terms, it is not clear what the program is doing when I run rcov = ~corg(trait):units with bivariate logistic regression. Does anyone have any insights?

4) With Gaussian bivariate regression, the error terms are allow to correlate to account for the dependencies between the two outputs. With poisson regression in MCMCglmm, my understanding is the error terms become the overdispersion in the model. With bivariate poisson regression, does the covariance between the errors for two output variables do the same thing as allowing the error terms to correlate in Gaussian bivariate regression or is it doing something else?

5) I also have count data that I want to run bivariate hurdle poisson regression with overdispersion. In MCMCglmm it will run both logisitic regression for the zeros and poisson regression with overdispersion for the counts. To problem comes that the error variance should be fixed for the two logistic regression parts while the error variance for the poisson part should be allowed to vary to account for the overdispersion. There seems to be no way in MCMCglmm to allow this. You can fix the R matrix (using fix = #) which will fix sections of the R matrix but you can't fix certain columns and rows. So you can't specify to fix the logistic regression parts and allow the poisson part to vary. Is that correct?

6) If #5 is true, are there any plans in the future to allow the column/rows to be fixed in the error R matrix so that multivariate hurdle poisson regression can be run with overdispresion?

7) Are there any plans in the future to add hurdle negative binomial (rather than just poisson) to MCMCglmm? Would that be difficult to implement?


Thanks for your help!
-Mark

	[[alternative HTML version deleted]]


From th|erry@onke||nx @end|ng |rom |nbo@be  Tue Apr 23 11:33:07 2019
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Tue, 23 Apr 2019 11:33:07 +0200
Subject: [R-sig-ME] singularity issue in lmer
In-Reply-To: <C2161D46-9E12-4B65-A8EF-CDC260C54C03@donders.ru.nl>
References: <E93B3350-1BD7-4B1C-B592-52C8221CFA3F@donders.ru.nl>
 <CAJuCY5wvOACHmNx8ezDP3nj=dteA1+B1wCee5T90mdHh1g0nAQ@mail.gmail.com>
 <C2161D46-9E12-4B65-A8EF-CDC260C54C03@donders.ru.nl>
Message-ID: <CAJuCY5yQsJBX5w=-o3yae=i9A4eTMWsLk0QsBv2ZNUUdiCd17A@mail.gmail.com>

Dear Catalina,

This will depend on your assumptions. f_Order + (1|Subject) assumes an
overall effect of f_Order (constant over all subjects) and an overall
effect of subject (constant over all f_Order). f_Order + (f_Order|Subject)
allows for both an overall effect of f_Order and a different effect for
each subject. Another options is f_Order + (1|Subject)  +
(1|Subject:f_Order). The difference between the last to is the correlation
structure among the random effects.

Whether f_Order + (1|Subject) is conceptually too simple, depends on domain
knowledge. If domain knowledge dictate at least f_Order +
(f_Order|Subject), then you should collect enough data to support a model
with such complexity.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op ma 22 apr. 2019 om 12:29 schreef Catalina Ratala <c.ratala at donders.ru.nl
>:

> Dear Thierry,
>
> Thank you very much for your reply!
> Indeed, i tried to simplify the model in different ways - the ones that
> run without errors are the ones where f_Order is not modelled as a random
> slope. So, the one you suggested:
>
> lmer(Rate ~ f_Order*f_Valence +  f_Attribute + (1 | Subject), data = data)
>
> works, without any errors.
> However, won?t the p-values I get for this model be inflated, since I
> don?t have random effects for any of the fixed factors in which I am
> interested in (f_Order and f_Valence)?
> Are these p-values reliable?
>
> best,
> Catalina
>
>
> On 17 Apr 2019, at 21:04, Thierry Onkelinx <thierry.onkelinx at inbo.be>
> wrote:
>
> Dear Catalina,
>
> Your model is too complex for the data. The NaN values in the output are a
> hint. I see two solutions. 1) collect more data. 2) simplify your model.
>
> Ttest if  lmer(Rate ~ f_Order*f_Valence +  f_Attribute + (1 | Subject),
> data = data) works.
>
> Best regards,
>
> ir. Thierry Onkelinx
> Statisticus / Statistician
>
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
> FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Havenlaan 88 bus 73, 1000 Brussel
> www.inbo.be
>
>
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> ///////////////////////////////////////////////////////////////////////////////////////////
>
> <https://www.inbo.be/>
>
>
> Op wo 17 apr. 2019 om 18:13 schreef Catalina Ratala <
> c.ratala at donders.ru.nl>:
>
>> Dear List,
>>
>> I?m trying to make the following model converge without warnings, using
>> the lme4 package:
>>
>> Variables: Order (3 levels), Valence (2 levels), and Attribute (2 levels)
>> are all factors, Rate is the DV, continuous, 1-10 range.
>>
>> model_lme4 <- lmer(Rate ~ f_Order*f_Valence + f_Attribute +  (1 +
>> f_Order*f_Valence | Subject), data = data)
>>
>> summary(model_lme4)
>>
>> Linear mixed model fit by REML ['lmerMod']
>> Formula: Rate ~ f_Order * f_Valence + f_Attribute + (1 + f_Order *
>> f_Valence |
>>     Subject)
>>    Data: data
>>
>> REML criterion at convergence: 12167.1
>>
>> Scaled residuals:
>>     Min      1Q  Median      3Q     Max
>> -5.0966 -0.5745 -0.0331  0.5851  5.1733
>>
>> Random effects:
>>  Groups   Name                Variance Std.Dev. Corr
>>
>>  Subject  (Intercept)         0.135654 0.36831
>>
>>           f_Order1            0.002681 0.05178  -0.66
>>
>>           f_Order2            0.003578 0.05982   0.31 -0.92
>>
>>           f_Valence1          0.343519 0.58611   0.35 -0.01 -0.17
>>
>>           f_Order1:f_Valence1 0.009916 0.09958  -0.09 -0.49  0.66  0.36
>>
>>           f_Order2:f_Valence1 0.001073 0.03276   0.01  0.02 -0.02 -0.88
>> -0.70
>>  Residual                     0.974439 0.98714
>>
>> Number of obs: 4237, groups:  Subject, 29
>>
>> Fixed effects:
>>                       Estimate Std. Error t value
>> (Intercept)          4.8820728  0.0700895  69.655
>> f_Order1            -0.0005486  0.0235150  -0.023
>> f_Order2             0.0220543  0.0241765   0.912
>> f_Valence1          -1.3284410  0.1099083 -12.087
>> f_Attribute1         0.0401858  0.0221600   1.813
>> f_Attribute2        -0.1078952  0.0217247  -4.966
>> f_Order1:f_Valence1 -0.0157678  0.0283515  -0.556
>> f_Order2:f_Valence1  0.0552990  0.0223037   2.479
>>
>> Correlation of Fixed Effects:
>>             (Intr) f_Ord1 f_Ord2 f_Vln1 f_Att1 f_Att2 f_O1:_
>> f_Order1    -0.263
>> f_Order2     0.138 -0.578
>> f_Valence1   0.340 -0.005 -0.077
>> f_Attribut1  0.014 -0.014 -0.024 -0.001
>> f_Attribut2  0.000 -0.007  0.023  0.007 -0.531
>> f_Ordr1:_V1 -0.057 -0.131  0.200  0.234  0.016 -0.008
>> f_Ordr2:_V1  0.001  0.001 -0.002 -0.237 -0.019  0.027 -0.488
>> convergence code: 0
>> boundary (singular) fit: see ?isSingular
>>
>>
>>
>> My problem is that I get this warning message saying that the model is
>> singular:
>>
>> boundary (singular) fit: see ?isSingular
>>
>>
>>
>> I used the function isSingular() (package lme4) to test whether actually
>> the warning is valid. It returned TRUE as an outcome, meaning the
>> parameters are on the boundary of the feasible parameter space, and
>> variances of one or more linear combinations of effects are (close to) zero.
>>
>> I also used allfits() function (afex package) to check whether different
>> optimizers give the same error, which was the case for all the optimizers
>> with which the model converged.
>>
>> Following different guidelines presented in the literature I tried:
>>
>> a)     to remove the covariance between random effects, by running the
>> following model:
>>
>> model_nocov <- lmer(Rate ~ f_Order*f_Valence +  f_Attribute + (0 +
>> f_Order*f_Valence | Subject) + (1 | Subject), data = data);
>>
>> Linear mixed model fit by REML ['lmerMod']
>> Formula: Rate ~ f_Order * f_Valence + f_Attribute + (0 + f_Order *
>> f_Valence |
>>     Subject) + (1 | Subject)
>>    Data: data
>>
>> REML criterion at convergence: 11707
>>
>> Scaled residuals:
>>     Min      1Q  Median      3Q     Max
>> -5.1014 -0.5736 -0.0361  0.5815  5.1984
>>
>> Random effects:
>>  Groups    Name                Variance Std.Dev. Corr
>>
>>  Subject   f_Orderfirst        0.000000 0.00000
>>
>>            f_Ordersecond       0.009510 0.09752    NaN
>>
>>            f_Orderthird        0.004304 0.06561    NaN  0.66
>>
>>            f_Valence1          0.105713 0.32514    NaN  0.74  0.68
>>
>>            f_Order1:f_Valence1 0.009706 0.09852    NaN  0.83  0.13  0.49
>>
>>            f_Order2:f_Valence1 0.001249 0.03534    NaN -0.52 -0.14 -0.82
>> -0.60
>>  Subject.1 (Intercept)         0.127141 0.35657
>>
>>  Residual                      0.973996 0.98691
>>
>> Number of obs: 4087, groups:  Subject, 28
>>
>> Fixed effects:
>>                      Estimate Std. Error t value
>> (Intercept)          4.873808   0.069807  69.818
>> f_Order1            -0.005478   0.023784  -0.230
>> f_Order2             0.028555   0.024044   1.188
>> f_Valence1          -1.420611   0.063388 -22.411
>> f_Attribute1         0.048127   0.022588   2.131
>> f_Attribute2        -0.120467   0.022118  -5.447
>> f_Order1:f_Valence1 -0.016950   0.028729  -0.590
>> f_Order2:f_Valence1  0.057331   0.022845   2.510
>>
>> Correlation of Fixed Effects:
>>             (Intr) f_Ord1 f_Ord2 f_Vln1 f_Att1 f_Att2 f_O1:_
>> f_Order1    -0.054
>> f_Order2     0.045 -0.548
>> f_Valence1   0.103 -0.301  0.255
>> f_Attribut1  0.015 -0.015 -0.025 -0.001
>> f_Attribut2  0.000 -0.004  0.019  0.010 -0.533
>> f_Ordr1:_V1  0.053 -0.154  0.260  0.306  0.018 -0.009
>> f_Ordr2:_V1 -0.016  0.046 -0.070 -0.233 -0.018  0.028 -0.477
>> convergence code: 0
>> boundary (singular) fit: see ?isSingular
>>
>>
>>
>>
>> b)     to remove outlier cases;
>>
>> However, I still got the same warning and the is.singular() indicated
>> that the warnings were to be considered (TRUE).
>>
>> Moreover, I realized that in this case, what causes the problem are the
>> correlations between the levels of the factor ORDER, which is the one
>> related to my main hypothesis and therefore, I cannot exclude its random
>> slope from the model, as I am interested in its statistical significance
>> and, thus, getting a p-value for it.
>>
>> I would like to ask for advice on what I can do to make the model
>> converge without warnings. Is there anything that could be done with the
>> levels of the factor (Order), that seem to be causing the problem? Any
>> other suggestion is, of course, welcomed.
>>
>>
>>
>> Thank you in advance for your time and help!
>>
>>
>>
>> Best,
>>
>> Catalina
>>
>>
>>
>>
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>
> C?t?lina E R??al? MSc
> PhD candidate
>
>
>
> ROTTERDAM SCHOOL OF MANAGEMENT
> ERASMUS UNIVERSITY
> DEPARTMENT OF MARKETING MANAGEMENT
>
> postal address: P.O. Box 1738; 3000 DR Rotterdam
> email: cratala at rsm.nl <touburg at rsm.nl>
> http://www.rsm.nl/people/catalina-ratala/
>
> DONDERS INSTITUTE FOR BRAIN, COGNITION & BEHAVIOUR
> DONDERS CENTRE FOR COGNITIVE NEUROIMAGING
>
> visiting address: Kapittelweg 29, Room 2.262n, 6525 EN, Nijmegen
> postal address: P.O. box 9101, 6500 HB Nijmegen
> tel: +31 - (0)24-3668388
> email: c.ratala at donders.ru.nl <c.ratala at donders.ru.nl>
> http://www.ru.nl/people/donders/ratala-c/
> http://www.decisionneurosciencelab.com/people/
>
>
>
>
>

	[[alternative HTML version deleted]]


From db@r@cort|n@ @end|ng |rom gm@||@com  Wed Apr 24 16:45:30 2019
From: db@r@cort|n@ @end|ng |rom gm@||@com (David Bars)
Date: Wed, 24 Apr 2019 16:45:30 +0200
Subject: [R-sig-ME] Theoric rapid doubts about glmer()
Message-ID: <CAD-H4CizVTw+D5Sd0T+=P+aDtcoSQvfkH_GQwHuaMpiqHgMuQw@mail.gmail.com>

Dear community,

My previous e-mail with links has not been slipped through the cracks. For
this reason, this second time, only I send two teoric doubts if someone
could help me to understand two simple doubts but for me (as PhD student
with a curiosity in statistics) I've not capable to solve by myself yet.

1- As general rule, in glmer models if we have only one random effect,
maybe it's more recommended always to perform a Gauss-Hermite Quadrature
approximation instead of Laplace approximation because we can perform more
than one iteration?

2 - I've read some posts addressing why the variance of Random effect
differs between lmer and glmer... ([(
https://stats.stackexchange.com/questions/115090/why-do-i-get-zero-variance-of-a-random-effect-in-my-mixed-model-despite-some-va)]).
..

Due to non-normality of my data (not attached), I need to use glmer, but
how can I explain that the variance of my random variable (Horse) is
practically 0???
Performing an analogous analysis by lmer (assuming badly "normality") the
variance of my random variable (Horse) increased up to 33%!!! I think that
horse, must be an important value of explaining the variance of my model
(as states lmer model).

Therefore, I perform glmer and I obtained a variance for Horse as random
effect of 0, meanwhile performing a lmer() I obtained a variance for Horse
as random effect of 33%. How can I assess the importance of the random
effect on my model? How can I interpret well the model?

Thanks on advance for your help,

David Bars
PhD Student
University of Lleida // INRA Jouy-en-Josas

	[[alternative HTML version deleted]]


From d@r|zopou|o@ @end|ng |rom er@@mu@mc@n|  Wed Apr 24 17:51:24 2019
From: d@r|zopou|o@ @end|ng |rom er@@mu@mc@n| (D. Rizopoulos)
Date: Wed, 24 Apr 2019 15:51:24 +0000
Subject: [R-sig-ME] Theoric rapid doubts about glmer()
In-Reply-To: <CAD-H4CizVTw+D5Sd0T+=P+aDtcoSQvfkH_GQwHuaMpiqHgMuQw@mail.gmail.com>
References: <CAD-H4CizVTw+D5Sd0T+=P+aDtcoSQvfkH_GQwHuaMpiqHgMuQw@mail.gmail.com>
Message-ID: <7191AFC7255B4F49A30707E39BEAD05FDED0FEA9@EXCH-RX03.erasmusmc.nl>


From: David Bars <dbarscortina at gmail.com<mailto:dbarscortina at gmail.com>>
Date: Wednesday, 24 Apr 2019, 17:46
To: r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>>
Subject: [R-sig-ME] Theoric rapid doubts about glmer()

Dear community,

My previous e-mail with links has not been slipped through the cracks. For
this reason, this second time, only I send two teoric doubts if someone
could help me to understand two simple doubts but for me (as PhD student
with a curiosity in statistics) I've not capable to solve by myself yet.

1- As general rule, in glmer models if we have only one random effect,
maybe it's more recommended always to perform a Gauss-Hermite Quadrature
approximation instead of Laplace approximation because we can perform more
than one iteration?

In generalized linear mixed models, fitted by glmer(), the likelihood function involves an integral over the random effects that cannot be solved analyticaly. Hence, it is required to numerically approximate it. A standard method to do this is the adaptive Gaussian quadrature. The more points you use the better the more accurate the approximation. The Laplace approximation is equivalent to adaptive Gaussian quadrature with one point, and it often does not work that optimally especially for binary data.

 Currently glmer() allows for adaptive Gaussian quadrature for scalar random effects. If you want to include something more than random intercepts and use the adaptive Gaussian quadrature you can do it with the GLMMadaptive package
https://drizopoulos.github.io/GLMMadaptive/



2 - I've read some posts addressing why the variance of Random effect
differs between lmer and glmer... ([(
https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstats.stackexchange.com%2Fquestions%2F115090%2Fwhy-do-i-get-zero-variance-of-a-random-effect-in-my-mixed-model-despite-some-va&data=02%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C1a89a3d603e34e816eb908d6c8c3936a%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C0%7C636917139659987189&sdata=A1uq0pbAvXc2VJ514VSyxW0V0A%2FkU5R0aqoKR08yr3Q%3D&reserved=0)]).
..

Due to non-normality of my data (not attached), I need to use glmer, but
how can I explain that the variance of my random variable (Horse) is
practically 0???
Performing an analogous analysis by lmer (assuming badly "normality") the
variance of my random variable (Horse) increased up to 33%!!! I think that
horse, must be an important value of explaining the variance of my model
(as states lmer model).

Therefore, I perform glmer and I obtained a variance for Horse as random
effect of 0, meanwhile performing a lmer() I obtained a variance for Horse
as random effect of 33%. How can I assess the importance of the random
effect on my model? How can I interpret well the model?

Thanks on advance for your help,

David Bars
PhD Student
University of Lleida // INRA Jouy-en-Josas

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&data=02%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C1a89a3d603e34e816eb908d6c8c3936a%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C0%7C636917139659987189&sdata=%2B9kQX7M6GTJZpz53om9dEL%2Bnhv4BpYpt43TL%2FPoFidg%3D&reserved=0

	[[alternative HTML version deleted]]


From r@turner @end|ng |rom @uck|@nd@@c@nz  Thu Apr 25 11:23:01 2019
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Thu, 25 Apr 2019 21:23:01 +1200
Subject: [R-sig-ME] Log likelihood of a glmer() binomial model .
In-Reply-To: <CABghstTKrwA9x5Xmk=ECwVzHawBp6OnRQCsymKA9DSpZPuATeg@mail.gmail.com>
References: <306f44cf-a1f9-25d4-4f9f-3dd581698d23@auckland.ac.nz>
 <CABghstTKrwA9x5Xmk=ECwVzHawBp6OnRQCsymKA9DSpZPuATeg@mail.gmail.com>
Message-ID: <48be3a45-eb18-fd36-6a12-25c7c5f9e386@auckland.ac.nz>


On 20/04/19 12:44 PM, Ben Bolker wrote:

<SNIP>

>   Here is an **inefficient** method for computing the likelihood
> 
>     coefs <- unlist(getME(fit,c("theta","beta"))
>     newdev <- update(fit, data=VS, devFunOnly=TRUE)
>     newdev(coefs)

<SNIP>

Well I (finally) tried that, and got an error.  Since I haven't a clue 
as to what is going on, there is no way that I can do any debugging.

I'm hoping that Ben, or someone, can tell me what I doing rong ( :-) ).

I have attached a sample data set (simulated; in the file X.txt) and the
code that I used in the file demo.R.  I *think* that *.txt and *.R files 
pass through the list server OK.  This should demonstrate the error that 
arises.

If you source demo.R (having made sure that X.txt is in the working 
directory) you will the error message:

> Error in pp$setTheta(theta) : theta size mismatch

The crucial code is essentially copy-and-pasted from Ben's email 
(referred to above) so I have no idea where I'm messing up.

Can anyone enlighten me?  Thanks.

cheers,

Rolf

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: X.txt
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20190425/b957ab4f/attachment-0001.txt>

From ph||||p@@|d@y @end|ng |rom mp|@n|  Thu Apr 25 11:27:29 2019
From: ph||||p@@|d@y @end|ng |rom mp|@n| (Phillip Alday)
Date: Thu, 25 Apr 2019 11:27:29 +0200
Subject: [R-sig-ME] Log likelihood of a glmer() binomial model .
In-Reply-To: <c42d6787-c011-736c-cbf5-cd1fc502414f@mpi.nl>
References: <306f44cf-a1f9-25d4-4f9f-3dd581698d23@auckland.ac.nz>
 <CABghstTKrwA9x5Xmk=ECwVzHawBp6OnRQCsymKA9DSpZPuATeg@mail.gmail.com>
 <48be3a45-eb18-fd36-6a12-25c7c5f9e386@auckland.ac.nz>
 <c42d6787-c011-736c-cbf5-cd1fc502414f@mpi.nl>
Message-ID: <8fcffcda-9561-c521-8f90-be042c71de85@mpi.nl>

And speaking of things not getting through, here's the my message again
without digital signing.

Phillip

On 25/4/19 11:26 am, Phillip Alday wrote:
The X.txt got through, but not the demo.R. Care to resend the demo.R as
demo.X and/or put it up as a gist/code snippet on GitHub/GitLab/etc.?

Best,
Phillip

> 
> On 25/4/19 11:23 am, Rolf Turner wrote:
>>
>> On 20/04/19 12:44 PM, Ben Bolker wrote:
>>
>> <SNIP>
>>
>>> ? Here is an **inefficient** method for computing the likelihood
>>>
>>> ??? coefs <- unlist(getME(fit,c("theta","beta"))
>>> ??? newdev <- update(fit, data=VS, devFunOnly=TRUE)
>>> ??? newdev(coefs)
>>
>> <SNIP>
>>
>> Well I (finally) tried that, and got an error.? Since I haven't a clue
>> as to what is going on, there is no way that I can do any debugging.
>>
>> I'm hoping that Ben, or someone, can tell me what I doing rong ( :-) ).
>>
>> I have attached a sample data set (simulated; in the file X.txt) and the
>> code that I used in the file demo.R.? I *think* that *.txt and *.R files
>> pass through the list server OK.? This should demonstrate the error that
>> arises.
>>
>> If you source demo.R (having made sure that X.txt is in the working
>> directory) you will the error message:
>>
>>> Error in pp$setTheta(theta) : theta size mismatch
>>
>> The crucial code is essentially copy-and-pasted from Ben's email
>> (referred to above) so I have no idea where I'm messing up.
>>
>> Can anyone enlighten me?? Thanks.
>>
>> cheers,
>>
>> Rolf
>>
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>


From r@turner @end|ng |rom @uck|@nd@@c@nz  Thu Apr 25 11:51:58 2019
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Thu, 25 Apr 2019 21:51:58 +1200
Subject: [R-sig-ME] Log likelihood of a glmer() binomial model .
In-Reply-To: <c42d6787-c011-736c-cbf5-cd1fc502414f@mpi.nl>
References: <306f44cf-a1f9-25d4-4f9f-3dd581698d23@auckland.ac.nz>
 <CABghstTKrwA9x5Xmk=ECwVzHawBp6OnRQCsymKA9DSpZPuATeg@mail.gmail.com>
 <48be3a45-eb18-fd36-6a12-25c7c5f9e386@auckland.ac.nz>
 <c42d6787-c011-736c-cbf5-cd1fc502414f@mpi.nl>
Message-ID: <16bd5a07-648f-94cd-7fab-53351e5b8f9d@auckland.ac.nz>


On 25/04/19 9:26 PM, Phillip Alday wrote:

> The X.txt got through, but not the demo.R. Care to resend the demo.R as
> demo.X and/or put it up as a gist/code snippet on GitHub/GitLab/etc.?

My problematic code is attached as demo.txt.

cheers,

Rolf

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: demo.txt
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20190425/1f148c2c/attachment.txt>

From db@r@cort|n@ @end|ng |rom gm@||@com  Thu Apr 25 15:31:22 2019
From: db@r@cort|n@ @end|ng |rom gm@||@com (David Bars)
Date: Thu, 25 Apr 2019 15:31:22 +0200
Subject: [R-sig-ME] Theoric rapid doubts about glmer()
In-Reply-To: <7191AFC7255B4F49A30707E39BEAD05FDED0FEA9@EXCH-RX03.erasmusmc.nl>
References: <CAD-H4CizVTw+D5Sd0T+=P+aDtcoSQvfkH_GQwHuaMpiqHgMuQw@mail.gmail.com>
 <7191AFC7255B4F49A30707E39BEAD05FDED0FEA9@EXCH-RX03.erasmusmc.nl>
Message-ID: <CAD-H4ChcHNOYCrVS48tVjLwhjVEig9sanc9DYmKctyEK2VXQ6Q@mail.gmail.com>

Many thanks Dr. Rizopoulos for your comments and the recommendation
about GLMMadaptive
package.

One of two of my doubts solved.!!! Many thanks.

David Bars.




On Wed, 24 Apr 2019 at 17:51, D. Rizopoulos <d.rizopoulos at erasmusmc.nl>
wrote:

>
> *From: *David Bars <dbarscortina at gmail.com>
> *Date: *Wednesday, 24 Apr 2019, 17:46
> *To: *r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>
> *Subject: *[R-sig-ME] Theoric rapid doubts about glmer()
>
> Dear community,
>
> My previous e-mail with links has not been slipped through the cracks. For
> this reason, this second time, only I send two teoric doubts if someone
> could help me to understand two simple doubts but for me (as PhD student
> with a curiosity in statistics) I've not capable to solve by myself yet.
>
> 1- As general rule, in glmer models if we have only one random effect,
> maybe it's more recommended always to perform a Gauss-Hermite Quadrature
> approximation instead of Laplace approximation because we can perform more
> than one iteration?
>
> In generalized linear mixed models, fitted by glmer(), the likelihood
> function involves an integral over the random effects that cannot be solved
> analyticaly. Hence, it is required to numerically approximate it. A
> standard method to do this is the adaptive Gaussian quadrature. The more
> points you use the better the more accurate the approximation. The Laplace
> approximation is equivalent to adaptive Gaussian quadrature with one point,
> and it often does not work that optimally especially for binary data.
>
>  Currently glmer() allows for adaptive Gaussian quadrature for scalar
> random effects. If you want to include something more than random
> intercepts and use the adaptive Gaussian quadrature you can do it with the
> GLMMadaptive package
> https://drizopoulos.github.io/GLMMadaptive/
>
>
>
> 2 - I've read some posts addressing why the variance of Random effect
> differs between lmer and glmer... ([(
>
> https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstats.stackexchange.com%2Fquestions%2F115090%2Fwhy-do-i-get-zero-variance-of-a-random-effect-in-my-mixed-model-despite-some-va&data=02%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C1a89a3d603e34e816eb908d6c8c3936a%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C0%7C636917139659987189&sdata=A1uq0pbAvXc2VJ514VSyxW0V0A%2FkU5R0aqoKR08yr3Q%3D&reserved=0
> )]).
> ..
>
> Due to non-normality of my data (not attached), I need to use glmer, but
> how can I explain that the variance of my random variable (Horse) is
> practically 0???
> Performing an analogous analysis by lmer (assuming badly "normality") the
> variance of my random variable (Horse) increased up to 33%!!! I think that
> horse, must be an important value of explaining the variance of my model
> (as states lmer model).
>
> Therefore, I perform glmer and I obtained a variance for Horse as random
> effect of 0, meanwhile performing a lmer() I obtained a variance for Horse
> as random effect of 33%. How can I assess the importance of the random
> effect on my model? How can I interpret well the model?
>
> Thanks on advance for your help,
>
> David Bars
> PhD Student
> University of Lleida // INRA Jouy-en-Josas
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
>
> https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&data=02%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C1a89a3d603e34e816eb908d6c8c3936a%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C0%7C636917139659987189&sdata=%2B9kQX7M6GTJZpz53om9dEL%2Bnhv4BpYpt43TL%2FPoFidg%3D&reserved=0
>
>

	[[alternative HTML version deleted]]


From jov23 @end|ng |rom b@th@@c@uk  Sat Apr 20 14:53:21 2019
From: jov23 @end|ng |rom b@th@@c@uk (Jose Valdebenito Chavez)
Date: Sat, 20 Apr 2019 12:53:21 +0000
Subject: [R-sig-ME] MCMCglmm parameter expansion prior for binary model?
Message-ID: <LO2P265MB0592A059C134080BEDCF04808B200@LO2P265MB0592.GBRP265.PROD.OUTLOOK.COM>

Hello all,



I am having troubles with the convergence of a binary model using MCMCglmm.



It?s a relatively simple model but it only has binary variables (0,1):



The response variable "camply_1" represents presence or absence of bacteria in several individuals.

?wmi_campy_1? is whether the couple of this individual was infected or not.

?quality?  is either the individual was came from place A or B, and ?sex? is the sex of the individual.



mc1 <- MCMCglmm(campy_1 ~ wmi_campy_1 + quality + sex,

                random = ~id + population,

                prior=prior.ex,

                family = "categorical",

                data = mated,

                nitt=1000000,burnin=1000,thin=500)



I struggled a bit to set the priors for the model, actually I tried several online but they did not work for me. However after fiddling with other examples (like this one: https://stat.ethz.ch/pipermail/r-sig-mixed-models/2017q4/026115.html) and reading Hadfield Course notes I ended up with this:



prior.ex<- list(G = list(

  G1 = list(V = 1, nu = 1000, alpha.mu = 0, alpha.V = 1),

  G2 = list(V = 1, nu = 1000, alpha.mu = 0, alpha.V = 1)),

                R = list(V=1, fix = TRUE))



When I run my previous models with this prior it gave me very good results. But then when I run this model (?mc1?), which was basically very similar, the diagnostic plots showed that the variable ?wmi_campy_1? was not converging properly. Also in the outcome I could see the posterior going wrong.



                          post.mean  l-95% CI  u-95% CI eff.samp pMCMC

(Intercept)              -2.5012   -4.7919   -0.2275 1502.426    0.028 *

wmi_campy_1   -200.9957 -410.5838   -1.0065    3.155    0.001 **

qualityisland         -3.9733   -8.2205   -0.4725 1770.965    0.024 *

sexM                       0.4699   -1.4708    2.2580 1830.226    0.604



I think this can be solved modifying the parameter expansion (alpha.mu, alpha.V) of the prior but I am out of ideas at this point. Any recommendations?



Many thanks.

Jose


	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Fri Apr 26 03:32:22 2019
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Thu, 25 Apr 2019 21:32:22 -0400
Subject: [R-sig-ME] Cross-validated likelihood, cont.
In-Reply-To: <de2c02d1-b889-059f-4e1d-775960222bb3@auckland.ac.nz>
References: <de2c02d1-b889-059f-4e1d-775960222bb3@auckland.ac.nz>
Message-ID: <3423aca1-2482-31e7-742d-4835e47aa04c@gmail.com>

Rolf,

 [cc'ing r-sig-mixed-models; apologies for breaking the thread]

Two issues:

 - I had to override some checking that glmer does (here I think the
problem is that the sample was sufficiently unbalanced that glmer
figured the random effects would be unidentifiable)
 - there's some trickiness about whether the deviance function is
stage-1/nAGQ=0 -- in which case, as Doug pointed out, the fixed-effect
[beta] parameters are profiled out, and the parameter vector should only
include theta (var-cov/Cholesky params), not theta+beta -- or if it's
stage-2/nAGQ>0 -- in which case the parameter vector should combine
theta and beta.

  What's below seems to work (at least, it returns a number).

  If this seems mysterious, the second example in ?lme4::modular *might*
help ...


====
#
# Script demo.txt
#

library(lme4)
set.seed(42)
X       <- dget("X.txt")
ind.trn <- sample(1:124,100)
ind.val <- setdiff(1:124,ind.trn)
TS      <- X[ind.trn,]
VS      <- X[ind.val,]
f.trn   <- glmer(cbind(Dead,Alive) ~ (Trt+0)/Dose + (Dose | Rep),
                 data=TS,family=binomial(link="cloglog"),nAGQ=0)
## coefs   <- unlist(getME(f.trn,c("theta","beta")))
##
coefs   <- unlist(getME(f.trn,"theta"))
## Error: number of observations (=24) < number of random effects (=30)
for term (Dose | Rep); the random-effects parameters are probably
unidentifiable
newdev  <- update(f.trn, data=VS, devFunOnly=TRUE,
                  control=glmerControl(check.nobs.vs.nRE="ignore"))
newdev(coefs)


From r@turner @end|ng |rom @uck|@nd@@c@nz  Fri Apr 26 06:41:00 2019
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Fri, 26 Apr 2019 16:41:00 +1200
Subject: [R-sig-ME] Cross-validated likelihood, cont.
In-Reply-To: <3423aca1-2482-31e7-742d-4835e47aa04c@gmail.com>
References: <de2c02d1-b889-059f-4e1d-775960222bb3@auckland.ac.nz>
 <3423aca1-2482-31e7-742d-4835e47aa04c@gmail.com>
Message-ID: <fda8011f-98fa-3d5f-f44f-b2d539d0ebc4@auckland.ac.nz>


Got it.  Thanks very much.  A bit messier than I'd hoped, but I guess 
that's life ....

I shall look at the lme4::modular example that you pointed to, and see 
if it enlightens me at all.

Would things have less of a tendency to go to custard if I set nAGQ=1?
I've been using nAGQ=0 since it's faster and less likely to throw 
errors, and appears to give essentially the same results in the 
applications in which I am interested.

cheers,

Rolf

On 26/04/19 1:32 PM, Ben Bolker wrote:
> Rolf,
> 
>   [cc'ing r-sig-mixed-models; apologies for breaking the thread]
> 
> Two issues:
> 
>   - I had to override some checking that glmer does (here I think the
> problem is that the sample was sufficiently unbalanced that glmer
> figured the random effects would be unidentifiable)
>   - there's some trickiness about whether the deviance function is
> stage-1/nAGQ=0 -- in which case, as Doug pointed out, the fixed-effect
> [beta] parameters are profiled out, and the parameter vector should only
> include theta (var-cov/Cholesky params), not theta+beta -- or if it's
> stage-2/nAGQ>0 -- in which case the parameter vector should combine
> theta and beta.
> 
>    What's below seems to work (at least, it returns a number).
> 
>    If this seems mysterious, the second example in ?lme4::modular *might*
> help ...
> 
> 
> ====
> #
> # Script demo.txt
> #
> 
> library(lme4)
> set.seed(42)
> X       <- dget("X.txt")
> ind.trn <- sample(1:124,100)
> ind.val <- setdiff(1:124,ind.trn)
> TS      <- X[ind.trn,]
> VS      <- X[ind.val,]
> f.trn   <- glmer(cbind(Dead,Alive) ~ (Trt+0)/Dose + (Dose | Rep),
>                   data=TS,family=binomial(link="cloglog"),nAGQ=0)
> ## coefs   <- unlist(getME(f.trn,c("theta","beta")))
> ##
> coefs   <- unlist(getME(f.trn,"theta"))
> ## Error: number of observations (=24) < number of random effects (=30)
> for term (Dose | Rep); the random-effects parameters are probably
> unidentifiable
> newdev  <- update(f.trn, data=VS, devFunOnly=TRUE,
>                    control=glmerControl(check.nobs.vs.nRE="ignore"))
> newdev(coefs)


From bbo|ker @end|ng |rom gm@||@com  Fri Apr 26 13:01:04 2019
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Fri, 26 Apr 2019 07:01:04 -0400
Subject: [R-sig-ME] Cross-validated likelihood, cont.
In-Reply-To: <fda8011f-98fa-3d5f-f44f-b2d539d0ebc4@auckland.ac.nz>
References: <de2c02d1-b889-059f-4e1d-775960222bb3@auckland.ac.nz>
 <3423aca1-2482-31e7-742d-4835e47aa04c@gmail.com>
 <fda8011f-98fa-3d5f-f44f-b2d539d0ebc4@auckland.ac.nz>
Message-ID: <CABghstSGtqamBRvDJTveueHi80S1ptzW1O6q3V_xw=chPxSXDQ@mail.gmail.com>

No, nAGQ=0 is probably as simple as you can get.

On Fri, Apr 26, 2019 at 12:41 AM Rolf Turner <r.turner at auckland.ac.nz> wrote:
>
>
> Got it.  Thanks very much.  A bit messier than I'd hoped, but I guess
> that's life ....
>
> I shall look at the lme4::modular example that you pointed to, and see
> if it enlightens me at all.
>
> Would things have less of a tendency to go to custard if I set nAGQ=1?
> I've been using nAGQ=0 since it's faster and less likely to throw
> errors, and appears to give essentially the same results in the
> applications in which I am interested.
>
> cheers,
>
> Rolf
>
> On 26/04/19 1:32 PM, Ben Bolker wrote:
> > Rolf,
> >
> >   [cc'ing r-sig-mixed-models; apologies for breaking the thread]
> >
> > Two issues:
> >
> >   - I had to override some checking that glmer does (here I think the
> > problem is that the sample was sufficiently unbalanced that glmer
> > figured the random effects would be unidentifiable)
> >   - there's some trickiness about whether the deviance function is
> > stage-1/nAGQ=0 -- in which case, as Doug pointed out, the fixed-effect
> > [beta] parameters are profiled out, and the parameter vector should only
> > include theta (var-cov/Cholesky params), not theta+beta -- or if it's
> > stage-2/nAGQ>0 -- in which case the parameter vector should combine
> > theta and beta.
> >
> >    What's below seems to work (at least, it returns a number).
> >
> >    If this seems mysterious, the second example in ?lme4::modular *might*
> > help ...
> >
> >
> > ====
> > #
> > # Script demo.txt
> > #
> >
> > library(lme4)
> > set.seed(42)
> > X       <- dget("X.txt")
> > ind.trn <- sample(1:124,100)
> > ind.val <- setdiff(1:124,ind.trn)
> > TS      <- X[ind.trn,]
> > VS      <- X[ind.val,]
> > f.trn   <- glmer(cbind(Dead,Alive) ~ (Trt+0)/Dose + (Dose | Rep),
> >                   data=TS,family=binomial(link="cloglog"),nAGQ=0)
> > ## coefs   <- unlist(getME(f.trn,c("theta","beta")))
> > ##
> > coefs   <- unlist(getME(f.trn,"theta"))
> > ## Error: number of observations (=24) < number of random effects (=30)
> > for term (Dose | Rep); the random-effects parameters are probably
> > unidentifiable
> > newdev  <- update(f.trn, data=VS, devFunOnly=TRUE,
> >                    control=glmerControl(check.nobs.vs.nRE="ignore"))
> > newdev(coefs)
>


From r@turner @end|ng |rom @uck|@nd@@c@nz  Mon Apr 29 01:03:18 2019
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Mon, 29 Apr 2019 11:03:18 +1200
Subject: [R-sig-ME] Cross-validated likelihood, cont.
In-Reply-To: <3423aca1-2482-31e7-742d-4835e47aa04c@gmail.com>
References: <de2c02d1-b889-059f-4e1d-775960222bb3@auckland.ac.nz>
 <3423aca1-2482-31e7-742d-4835e47aa04c@gmail.com>
Message-ID: <e6aa6183-5917-0de5-47ac-c06274db4cfe@auckland.ac.nz>


Please see in-line below.

On 26/04/19 1:32 PM, Ben Bolker wrote:
> Rolf,
> 
>   [cc'ing r-sig-mixed-models; apologies for breaking the thread]
> 
> Two issues:
> 
>   - I had to override some checking that glmer does (here I think the
> problem is that the sample was sufficiently unbalanced that glmer
> figured the random effects would be unidentifiable)
>   - there's some trickiness about whether the deviance function is
> stage-1/nAGQ=0 -- in which case, as Doug pointed out, the fixed-effect
> [beta] parameters are profiled out, and the parameter vector should only
> include theta (var-cov/Cholesky params), not theta+beta -- or if it's
> stage-2/nAGQ>0 -- in which case the parameter vector should combine
> theta and beta.
> 
>    What's below seems to work (at least, it returns a number).

Some rudimentary experimentation that I've done appears to indicate that 
the *number* returned is equal to -2*(the log likelihood) --- presumably 
the deviance.  Is this correct?

If I want to get the log likelihood (e.g. for comparison with other 
procedures) is it "safe" to assume that the log likelihood is equal to
-0.5*(the number returned)?

Thanks.

cheers,

Rolf

> 
>    If this seems mysterious, the second example in ?lme4::modular *might*
> help ...
> 
> 
> ====
> #
> # Script demo.txt
> #
> 
> library(lme4)
> set.seed(42)
> X       <- dget("X.txt")
> ind.trn <- sample(1:124,100)
> ind.val <- setdiff(1:124,ind.trn)
> TS      <- X[ind.trn,]
> VS      <- X[ind.val,]
> f.trn   <- glmer(cbind(Dead,Alive) ~ (Trt+0)/Dose + (Dose | Rep),
>                   data=TS,family=binomial(link="cloglog"),nAGQ=0)
> ## coefs   <- unlist(getME(f.trn,c("theta","beta")))
> ##
> coefs   <- unlist(getME(f.trn,"theta"))
> ## Error: number of observations (=24) < number of random effects (=30)
> for term (Dose | Rep); the random-effects parameters are probably
> unidentifiable
> newdev  <- update(f.trn, data=VS, devFunOnly=TRUE,
>                    control=glmerControl(check.nobs.vs.nRE="ignore"))
> newdev(coefs)
>


From r@turner @end|ng |rom @uck|@nd@@c@nz  Mon Apr 29 01:41:01 2019
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Mon, 29 Apr 2019 11:41:01 +1200
Subject: [R-sig-ME] Cross-validated likelihood, cont.
In-Reply-To: <CABghstSGtqamBRvDJTveueHi80S1ptzW1O6q3V_xw=chPxSXDQ@mail.gmail.com>
References: <de2c02d1-b889-059f-4e1d-775960222bb3@auckland.ac.nz>
 <3423aca1-2482-31e7-742d-4835e47aa04c@gmail.com>
 <fda8011f-98fa-3d5f-f44f-b2d539d0ebc4@auckland.ac.nz>
 <CABghstSGtqamBRvDJTveueHi80S1ptzW1O6q3V_xw=chPxSXDQ@mail.gmail.com>
Message-ID: <548d0055-520f-3a66-b6a7-e0a80f39394b@auckland.ac.nz>

On 26/04/19 11:01 PM, Ben Bolker wrote:

> No, nAGQ=0 is probably as simple as you can get.

Hmm.  Indeed.  I tried things just now with nAGQ=1, and everything seems 
to go to custard.  If I do:

f.trn   <- glmer(cbind(Dead,Alive) ~ (Trt+0)/Dose + (Dose | Rep),
                  data=TS,family=binomial(link="cloglog"),nAGQ=1)
coefs   <- unlist(getME(f.trn,"theta"))
newdev  <- update(f.trn, data=VS, devFunOnly=TRUE,
                   control=glmerControl(check.nobs.vs.nRE="ignore"))
print(newdev(coefs))
check  <- update(f.trn, data=TS, devFunOnly=TRUE,
                   control=glmerControl(check.nobs.vs.nRE="ignore"))
print(check(coefs))

I get:

[1] 390.7528

and

[1] 2194.427

which are way out of line with the nAGQ=0 results:

[1] 42.75071

and

[1] 245.8587

Note that when nAGQ is set equal to 0, logLik(f.trn) gives -122.9294 
which is, at least approximately equal to -0.5*245.8587.

Note also that when nAGQ is set equal to 1, logLik(f.trn) gives
-122.8933 which is "reasonably" close to the nAGQ=0 result.   Whereas 
2194.427 is *not* by any stretch close to 245.8587.

Is there anything that can be done to make nAGQ=1 "behave"?  Ideally I 
would like to be able to apply "cross-validated" log likelihood to 
models that are fitted any which-way.  (And *not* have to restrict to 
nAGQ=0 fits.)

Or am I, as is so often the case ( :-) ) out of luck?

cheers,

Rolf

> 
> On Fri, Apr 26, 2019 at 12:41 AM Rolf Turner <r.turner at auckland.ac.nz> wrote:
>>
>>
>> Got it.  Thanks very much.  A bit messier than I'd hoped, but I guess
>> that's life ....
>>
>> I shall look at the lme4::modular example that you pointed to, and see
>> if it enlightens me at all.
>>
>> Would things have less of a tendency to go to custard if I set nAGQ=1?
>> I've been using nAGQ=0 since it's faster and less likely to throw
>> errors, and appears to give essentially the same results in the
>> applications in which I am interested.
>>
>> cheers,
>>
>> Rolf
>>
>> On 26/04/19 1:32 PM, Ben Bolker wrote:
>>> Rolf,
>>>
>>>    [cc'ing r-sig-mixed-models; apologies for breaking the thread]
>>>
>>> Two issues:
>>>
>>>    - I had to override some checking that glmer does (here I think the
>>> problem is that the sample was sufficiently unbalanced that glmer
>>> figured the random effects would be unidentifiable)
>>>    - there's some trickiness about whether the deviance function is
>>> stage-1/nAGQ=0 -- in which case, as Doug pointed out, the fixed-effect
>>> [beta] parameters are profiled out, and the parameter vector should only
>>> include theta (var-cov/Cholesky params), not theta+beta -- or if it's
>>> stage-2/nAGQ>0 -- in which case the parameter vector should combine
>>> theta and beta.
>>>
>>>     What's below seems to work (at least, it returns a number).
>>>
>>>     If this seems mysterious, the second example in ?lme4::modular *might*
>>> help ...
>>>
>>>
>>> ====
>>> #
>>> # Script demo.txt
>>> #
>>>
>>> library(lme4)
>>> set.seed(42)
>>> X       <- dget("X.txt")
>>> ind.trn <- sample(1:124,100)
>>> ind.val <- setdiff(1:124,ind.trn)
>>> TS      <- X[ind.trn,]
>>> VS      <- X[ind.val,]
>>> f.trn   <- glmer(cbind(Dead,Alive) ~ (Trt+0)/Dose + (Dose | Rep),
>>>                    data=TS,family=binomial(link="cloglog"),nAGQ=0)
>>> ## coefs   <- unlist(getME(f.trn,c("theta","beta")))
>>> ##
>>> coefs   <- unlist(getME(f.trn,"theta"))
>>> ## Error: number of observations (=24) < number of random effects (=30)
>>> for term (Dose | Rep); the random-effects parameters are probably
>>> unidentifiable
>>> newdev  <- update(f.trn, data=VS, devFunOnly=TRUE,
>>>                     control=glmerControl(check.nobs.vs.nRE="ignore"))
>>> newdev(coefs)


From d@r|zopou|o@ @end|ng |rom er@@mu@mc@n|  Mon Apr 29 06:25:01 2019
From: d@r|zopou|o@ @end|ng |rom er@@mu@mc@n| (D. Rizopoulos)
Date: Mon, 29 Apr 2019 04:25:01 +0000
Subject: [R-sig-ME] Cross-validated likelihood, cont.
In-Reply-To: <548d0055-520f-3a66-b6a7-e0a80f39394b@auckland.ac.nz>
References: <de2c02d1-b889-059f-4e1d-775960222bb3@auckland.ac.nz>
 <3423aca1-2482-31e7-742d-4835e47aa04c@gmail.com>
 <fda8011f-98fa-3d5f-f44f-b2d539d0ebc4@auckland.ac.nz>
 <CABghstSGtqamBRvDJTveueHi80S1ptzW1O6q3V_xw=chPxSXDQ@mail.gmail.com>,
 <548d0055-520f-3a66-b6a7-e0a80f39394b@auckland.ac.nz>
Message-ID: <7191AFC7255B4F49A30707E39BEAD05FDED16140@EXCH-HE03.erasmusmc.nl>

If you want you could give a try to the GLMMadaptive package that implements the adaptive Gaussian quadrature for a vector of random effects (e.g., intercepts and slopes as in your case), and from which you get the log-likelihood in two steps, e.g.,

library(GLMMadaptive)
# the log-likelihood at the initial values
fm <- mixed_model(cbind(Dead, Alive) ~ (Trt + 0) / Dose, random = ~ Dose | Rep,
  data = Ts, family = binomial(link = ?cloglog?), iter_EM = 0, iter_qN_outer = 0)
logLik(fm)

# the log-likelihood at user-specified values
gm <-  mixed_model(cbind(Dead, Alive) ~ (Trt + 0) / Dose, random = ~ Dose | Rep,
  data = Ts, family = binomial(link = ?cloglog?), iter_EM = 0, iter_qN_outer = 0,
  initial_values = list(beta = <put_your_fixed_effects_here>, D = <put_the_RE_cov_matrix_here>))
logLik(gm)

Best,
Dimitris

- - - - - -
Dimitris Rizopoulos
Professor of Biostatistics
Erasmus University Medical Center
The Netherlands

From: Rolf Turner <r.turner at auckland.ac.nz<mailto:r.turner at auckland.ac.nz>>
Date: Monday, 29 Apr 2019, 2:41 AM
To: Ben Bolker <bbolker at gmail.com<mailto:bbolker at gmail.com>>
Cc: r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>>
Subject: Re: [R-sig-ME] Cross-validated likelihood, cont.

On 26/04/19 11:01 PM, Ben Bolker wrote:

> No, nAGQ=0 is probably as simple as you can get.

Hmm.  Indeed.  I tried things just now with nAGQ=1, and everything seems
to go to custard.  If I do:

f.trn   <- glmer(cbind(Dead,Alive) ~ (Trt+0)/Dose + (Dose | Rep),
                  data=TS,family=binomial(link="cloglog"),nAGQ=1)
coefs   <- unlist(getME(f.trn,"theta"))
newdev  <- update(f.trn, data=VS, devFunOnly=TRUE,
                   control=glmerControl(check.nobs.vs.nRE="ignore"))
print(newdev(coefs))
check  <- update(f.trn, data=TS, devFunOnly=TRUE,
                   control=glmerControl(check.nobs.vs.nRE="ignore"))
print(check(coefs))

I get:

[1] 390.7528

and

[1] 2194.427

which are way out of line with the nAGQ=0 results:

[1] 42.75071

and

[1] 245.8587

Note that when nAGQ is set equal to 0, logLik(f.trn) gives -122.9294
which is, at least approximately equal to -0.5*245.8587.

Note also that when nAGQ is set equal to 1, logLik(f.trn) gives
-122.8933 which is "reasonably" close to the nAGQ=0 result.   Whereas
2194.427 is *not* by any stretch close to 245.8587.

Is there anything that can be done to make nAGQ=1 "behave"?  Ideally I
would like to be able to apply "cross-validated" log likelihood to
models that are fitted any which-way.  (And *not* have to restrict to
nAGQ=0 fits.)

Or am I, as is so often the case ( :-) ) out of luck?

cheers,

Rolf

>
> On Fri, Apr 26, 2019 at 12:41 AM Rolf Turner <r.turner at auckland.ac.nz> wrote:
>>
>>
>> Got it.  Thanks very much.  A bit messier than I'd hoped, but I guess
>> that's life ....
>>
>> I shall look at the lme4::modular example that you pointed to, and see
>> if it enlightens me at all.
>>
>> Would things have less of a tendency to go to custard if I set nAGQ=1?
>> I've been using nAGQ=0 since it's faster and less likely to throw
>> errors, and appears to give essentially the same results in the
>> applications in which I am interested.
>>
>> cheers,
>>
>> Rolf
>>
>> On 26/04/19 1:32 PM, Ben Bolker wrote:
>>> Rolf,
>>>
>>>    [cc'ing r-sig-mixed-models; apologies for breaking the thread]
>>>
>>> Two issues:
>>>
>>>    - I had to override some checking that glmer does (here I think the
>>> problem is that the sample was sufficiently unbalanced that glmer
>>> figured the random effects would be unidentifiable)
>>>    - there's some trickiness about whether the deviance function is
>>> stage-1/nAGQ=0 -- in which case, as Doug pointed out, the fixed-effect
>>> [beta] parameters are profiled out, and the parameter vector should only
>>> include theta (var-cov/Cholesky params), not theta+beta -- or if it's
>>> stage-2/nAGQ>0 -- in which case the parameter vector should combine
>>> theta and beta.
>>>
>>>     What's below seems to work (at least, it returns a number).
>>>
>>>     If this seems mysterious, the second example in ?lme4::modular *might*
>>> help ...
>>>
>>>
>>> ====
>>> #
>>> # Script demo.txt
>>> #
>>>
>>> library(lme4)
>>> set.seed(42)
>>> X       <- dget("X.txt")
>>> ind.trn <- sample(1:124,100)
>>> ind.val <- setdiff(1:124,ind.trn)
>>> TS      <- X[ind.trn,]
>>> VS      <- X[ind.val,]
>>> f.trn   <- glmer(cbind(Dead,Alive) ~ (Trt+0)/Dose + (Dose | Rep),
>>>                    data=TS,family=binomial(link="cloglog"),nAGQ=0)
>>> ## coefs   <- unlist(getME(f.trn,c("theta","beta")))
>>> ##
>>> coefs   <- unlist(getME(f.trn,"theta"))
>>> ## Error: number of observations (=24) < number of random effects (=30)
>>> for term (Dose | Rep); the random-effects parameters are probably
>>> unidentifiable
>>> newdev  <- update(f.trn, data=VS, devFunOnly=TRUE,
>>>                     control=glmerControl(check.nobs.vs.nRE="ignore"))
>>> newdev(coefs)

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=02%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C2809ad114d6c4906bfec08d6cc330a1e%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C0%7C636920916920782143&amp;sdata=nds0cDpFmm2PAcrP1g4NlhabC9u85taAdUe2u213UGo%3D&amp;reserved=0

	[[alternative HTML version deleted]]


From r@turner @end|ng |rom @uck|@nd@@c@nz  Mon Apr 29 07:10:23 2019
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Mon, 29 Apr 2019 17:10:23 +1200
Subject: [R-sig-ME] Cross-validated likelihood, cont.
In-Reply-To: <7191AFC7255B4F49A30707E39BEAD05FDED16140@EXCH-HE03.erasmusmc.nl>
References: <de2c02d1-b889-059f-4e1d-775960222bb3@auckland.ac.nz>
 <3423aca1-2482-31e7-742d-4835e47aa04c@gmail.com>
 <fda8011f-98fa-3d5f-f44f-b2d539d0ebc4@auckland.ac.nz>
 <CABghstSGtqamBRvDJTveueHi80S1ptzW1O6q3V_xw=chPxSXDQ@mail.gmail.com>
 <548d0055-520f-3a66-b6a7-e0a80f39394b@auckland.ac.nz>
 <7191AFC7255B4F49A30707E39BEAD05FDED16140@EXCH-HE03.erasmusmc.nl>
Message-ID: <9f5354aa-a874-db83-b88f-05a1eed9d99e@auckland.ac.nz>


On 29/04/19 4:25 PM, D. Rizopoulos wrote:

> If you want you could give a try to the GLMMadaptive package that 
> implements the adaptive Gaussian quadrature for a vector of random 
> effects (e.g., intercepts and slopes as in your case), and from which 
> you get the log-likelihood in two steps, e.g.,
> 
> library(GLMMadaptive)
> # the log-likelihood at the initial values
> fm <- mixed_model(cbind(Dead, Alive) ~ (Trt + 0) / Dose, random = ~ Dose 
> | Rep,
>  ? data = Ts, family = binomial(link = ?cloglog?), iter_EM = 0, 
> iter_qN_outer = 0)
> logLik(fm)
> 
> # the log-likelihood at user-specified values
> gm <- ?mixed_model(cbind(Dead, Alive) ~ (Trt + 0) / Dose, random = ~ 
> Dose | Rep,
>  ? data = Ts, family = binomial(link = ?cloglog?), iter_EM = 0, 
> iter_qN_outer = 0,
>  ? initial_values = list(beta = <put_your_fixed_effects_here>, D = 
> <put_the_RE_cov_matrix_here>))
> logLik(gm)

This looks promising; I'll give it a go.  I will probably have to come 
back and pester you with questions once I get started.  Hope you don't mind.

cheers,

Rolf

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From b|mono@om @end|ng |rom gm@||@com  Mon Apr 29 12:19:50 2019
From: b|mono@om @end|ng |rom gm@||@com (=?UTF-8?B?UmVuw6k=?=)
Date: Mon, 29 Apr 2019 12:19:50 +0200
Subject: [R-sig-ME] [FORGED] Re: logistic regression on posttest (0,
 1) with pretest(0, 1)*Group(Treatment, Ctrl) interaction
In-Reply-To: <alpine.BSF.2.00.1904211856000.82745@pedal.dcn.davis.ca.us>
References: <CAEA998gw2dBJa15idOanou56y-fqCdEv2wFgEsJny-r3TV3Nwg@mail.gmail.com>
 <BN7PR03MB3730B3739E6AC1A906671022E2210@BN7PR03MB3730.namprd03.prod.outlook.com>
 <8b76dea0-0d9a-5b61-0c15-465c3705b988@auckland.ac.nz>
 <alpine.BSF.2.00.1904211856000.82745@pedal.dcn.davis.ca.us>
Message-ID: <CADcpBHO4quyXCmN0dD+7gdyVO+msQzbhoeL=ROWivt6TpYRBGA@mail.gmail.com>

Hi Souheyla,

coming back to the topic (I was busy lately).

The interpretation is always a bit of a problem in regressions with
categorical interactions. There are two ways to deal with this, one would
be to prefer effect coding (search for contrast sum coding online) over
dummy coding. In short, with effect coding, you model the deviation of each
group from a grand mean. With dummy coding, you start with the intercept
parameter and then add up the design cells to have the actual mean estimate
of it... I actually do not like both, because first I have no idea how to
ideally tell this bro, and also... there is a second and much much easier
way:

Try this:
## if this is your model: mod2 <- brm(posttest ~ pretest*Group +...)
library(emmeans)
emmip(mod2,~pretest|Group,type="response",CIs=TRUE)
Et voila :)
This gives you the posterior marginal estimates from the model for your
interaction, predicting the cell specific response probability, including
highest density intervals (or Bayesian credible intervals). The option
type="response" gives you the predicted probability of post =1; if you
delete this option, the marginal estimates will be given on the log scale.
In short, this tells you whether something is better remembered post, if it
was already known pre (or not), depending on the group.

You can get also the marginal main effects like this, using:
emmip(mod2,~pretest,type="response",CIs=TRUE)
Which would tell you whether something is better remembered post, if it was
already known pre. Likewise for group.

And if you want to simply get the summary statistics instead of the plot,
use this:
summod2<-emmip(mod2,~pretest|Group,type="response",CIs=TRUE)
summod2$data

Best, Ren?



Am Mo., 22. Apr. 2019 um 03:59 Uhr schrieb Jeff Newmiller <
jdnewmil at dcn.davis.ca.us>:

> There is no "formula" syntax other than it has to have at least one
> tilde... there is "lm" formula syntax, and "lme" formula syntax, and "nls"
> formula syntax, etc... and other model builders are not obligated to
> adhere to the "lm" interpretation of formulas.
>
> I don't see why using * alone in an lm formula should be avoided, but
> perhaps John's advice could be reframed as "watch out for the specific
> syntax used by your model building function... it may not be the same as
> that used by lm".
>
> On Mon, 22 Apr 2019, Rolf Turner wrote:
>
> >
> > On 22/04/19 6:01 AM, Sorkin, John wrote:
> >
> >> Souheyla,
> >>
> >> It is both difficult and dangerous to add a comment to a thread that
> >> one has not followed, and in doing so possibly making an
> >> inappropriate suggestion. Please forgive what may be an not fully
> >> informed thought.
> >>
> >> The model you suggest, posttest ~ pretest*Group  (ignoring random
> >> effects) is unusual. In a model that contains an interaction,  I
> >> would expect to see, in addition to the interaction, all main effects
> >> included in the interaction, i.e. posttest ~
> >> group+pretest+pretest*Group.
> >
> > As Souheyla has already indicated, in the R (and previously S/Splus)
> formula
> > syntax, interactions are indicated by a *colon* --- a:b.  The notation
> "a*b"
> > is a shorthand for
> > a + b + a:b.
> >
> > So pretest*Group is the same as pretest + Group + pretest:Group, whence
> it
> > contains the main effects.
> >
> > I disagree with the advice that you gave Souheyla in a follow-up email.
> > The construction pretest*Group is preferable, being compact and tidy.
> Brevity
> > is a virtue.
> >
> > cheers,
> >
> > Rolf
> >
> > --
> > Honorary Research Fellow
> > Department of Statistics
> > University of Auckland
> > Phone: +64-9-373-7599 ext. 88276
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> Go...
>                                        Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From @ouhey|@@ghebghoub @end|ng |rom gm@||@com  Mon Apr 29 12:25:32 2019
From: @ouhey|@@ghebghoub @end|ng |rom gm@||@com (Souheyla GHEBGHOUB)
Date: Mon, 29 Apr 2019 11:25:32 +0100
Subject: [R-sig-ME] [FORGED] Re: logistic regression on posttest (0,
 1) with pretest(0, 1)*Group(Treatment, Ctrl) interaction
In-Reply-To: <CADcpBHO4quyXCmN0dD+7gdyVO+msQzbhoeL=ROWivt6TpYRBGA@mail.gmail.com>
References: <CAEA998gw2dBJa15idOanou56y-fqCdEv2wFgEsJny-r3TV3Nwg@mail.gmail.com>
 <BN7PR03MB3730B3739E6AC1A906671022E2210@BN7PR03MB3730.namprd03.prod.outlook.com>
 <8b76dea0-0d9a-5b61-0c15-465c3705b988@auckland.ac.nz>
 <alpine.BSF.2.00.1904211856000.82745@pedal.dcn.davis.ca.us>
 <CADcpBHO4quyXCmN0dD+7gdyVO+msQzbhoeL=ROWivt6TpYRBGA@mail.gmail.com>
Message-ID: <CAEA998jn7Xkrq-gMf6QfTSiMCm=xv0oLa5AJ71XAk4c+1ntEQA@mail.gmail.com>

Dear Rene,

Thank youbforbyour feedback.
I will look into this. But before I do, I would like to ask how much
difference would it make if I am using lme4 package (glmer).

I keep switching between both and havent decided yet. But is it easy to
implement the aforesaid if its glmer and not brms?

Thank you
Souheyla


On Mon, 29 Apr 2019, 11:20 Ren?, <bimonosom at gmail.com> wrote:

> Hi Souheyla,
>
> coming back to the topic (I was busy lately).
>
> The interpretation is always a bit of a problem in regressions with
> categorical interactions. There are two ways to deal with this, one would
> be to prefer effect coding (search for contrast sum coding online) over
> dummy coding. In short, with effect coding, you model the deviation of each
> group from a grand mean. With dummy coding, you start with the intercept
> parameter and then add up the design cells to have the actual mean estimate
> of it... I actually do not like both, because first I have no idea how to
> ideally tell this bro, and also... there is a second and much much easier
> way:
>
> Try this:
> ## if this is your model: mod2 <- brm(posttest ~ pretest*Group +...)
> library(emmeans)
> emmip(mod2,~pretest|Group,type="response",CIs=TRUE)
> Et voila :)
> This gives you the posterior marginal estimates from the model for your
> interaction, predicting the cell specific response probability, including
> highest density intervals (or Bayesian credible intervals). The option
> type="response" gives you the predicted probability of post =1; if you
> delete this option, the marginal estimates will be given on the log scale.
> In short, this tells you whether something is better remembered post, if it
> was already known pre (or not), depending on the group.
>
> You can get also the marginal main effects like this, using:
> emmip(mod2,~pretest,type="response",CIs=TRUE)
> Which would tell you whether something is better remembered post, if it was
> already known pre. Likewise for group.
>
> And if you want to simply get the summary statistics instead of the plot,
> use this:
> summod2<-emmip(mod2,~pretest|Group,type="response",CIs=TRUE)
> summod2$data
>
> Best, Ren?
>
>
>
> Am Mo., 22. Apr. 2019 um 03:59 Uhr schrieb Jeff Newmiller <
> jdnewmil at dcn.davis.ca.us>:
>
> > There is no "formula" syntax other than it has to have at least one
> > tilde... there is "lm" formula syntax, and "lme" formula syntax, and
> "nls"
> > formula syntax, etc... and other model builders are not obligated to
> > adhere to the "lm" interpretation of formulas.
> >
> > I don't see why using * alone in an lm formula should be avoided, but
> > perhaps John's advice could be reframed as "watch out for the specific
> > syntax used by your model building function... it may not be the same as
> > that used by lm".
> >
> > On Mon, 22 Apr 2019, Rolf Turner wrote:
> >
> > >
> > > On 22/04/19 6:01 AM, Sorkin, John wrote:
> > >
> > >> Souheyla,
> > >>
> > >> It is both difficult and dangerous to add a comment to a thread that
> > >> one has not followed, and in doing so possibly making an
> > >> inappropriate suggestion. Please forgive what may be an not fully
> > >> informed thought.
> > >>
> > >> The model you suggest, posttest ~ pretest*Group  (ignoring random
> > >> effects) is unusual. In a model that contains an interaction,  I
> > >> would expect to see, in addition to the interaction, all main effects
> > >> included in the interaction, i.e. posttest ~
> > >> group+pretest+pretest*Group.
> > >
> > > As Souheyla has already indicated, in the R (and previously S/Splus)
> > formula
> > > syntax, interactions are indicated by a *colon* --- a:b.  The notation
> > "a*b"
> > > is a shorthand for
> > > a + b + a:b.
> > >
> > > So pretest*Group is the same as pretest + Group + pretest:Group, whence
> > it
> > > contains the main effects.
> > >
> > > I disagree with the advice that you gave Souheyla in a follow-up email.
> > > The construction pretest*Group is preferable, being compact and tidy.
> > Brevity
> > > is a virtue.
> > >
> > > cheers,
> > >
> > > Rolf
> > >
> > > --
> > > Honorary Research Fellow
> > > Department of Statistics
> > > University of Auckland
> > > Phone: +64-9-373-7599 ext. 88276
> > >
> > > _______________________________________________
> > > R-sig-mixed-models at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > >
> >
> >
> ---------------------------------------------------------------------------
> > Jeff Newmiller                        The     .....       .....  Go
> Live...
> > DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> > Go...
> >                                        Live:   OO#.. Dead: OO#..  Playing
> > Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> > /Software/Embedded Controllers)               .OO#.       .OO#.
> rocks...1k
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From b|mono@om @end|ng |rom gm@||@com  Mon Apr 29 13:20:33 2019
From: b|mono@om @end|ng |rom gm@||@com (=?UTF-8?B?UmVuw6k=?=)
Date: Mon, 29 Apr 2019 13:20:33 +0200
Subject: [R-sig-ME] [FORGED] Re: logistic regression on posttest (0,
 1) with pretest(0, 1)*Group(Treatment, Ctrl) interaction
In-Reply-To: <CAEA998jn7Xkrq-gMf6QfTSiMCm=xv0oLa5AJ71XAk4c+1ntEQA@mail.gmail.com>
References: <CAEA998gw2dBJa15idOanou56y-fqCdEv2wFgEsJny-r3TV3Nwg@mail.gmail.com>
 <BN7PR03MB3730B3739E6AC1A906671022E2210@BN7PR03MB3730.namprd03.prod.outlook.com>
 <8b76dea0-0d9a-5b61-0c15-465c3705b988@auckland.ac.nz>
 <alpine.BSF.2.00.1904211856000.82745@pedal.dcn.davis.ca.us>
 <CADcpBHO4quyXCmN0dD+7gdyVO+msQzbhoeL=ROWivt6TpYRBGA@mail.gmail.com>
 <CAEA998jn7Xkrq-gMf6QfTSiMCm=xv0oLa5AJ71XAk4c+1ntEQA@mail.gmail.com>
Message-ID: <CADcpBHOfeLALWPX09cjFtFCd3tJMnMDPLrRy5KYeXS7bR+ha3Q@mail.gmail.com>

Both packages work the same way with respect to the coding/scripting (which
was intended), even for emmeans both give the same. However, I would also
suggest considering afex::mixed (in case you stay with the frequentist
approach), because it enhances the way of testing your models towards
hierarchical likelihood ratio tests (which is not the same as an anova
output from a single glm fit).

Thus, the way the effects and design differences are 'constructed' is the
same, but in lme4 you obtain p-values (i.e. how likely are the data given
you assume a null-effect), and in brm you obtain posterior parameter
estimates (i.e. what is the range of parameters that are considered to be
likely). A lot of people find the latter much more informative in terms of
statistical decision making, which is layed out in basically every
introductory paper on Bayes Factors etc (see work by Wagenmakers, Kruschke,
or Michael Lee and colleagues). But there is a debate, of course, of what
should be preferred, which I am not able to sum up in a few sentences. Just
to name a few arguments... 1) people are used to p-values, and like the
idea of having a 'decisive' criterion. 2) but p-values are not reliable
(strong argument actually) 3) signigifance testing relies on the quality of
the research methods (including replications, like Fisher said); 4) What
the researcher wants to say is something about the likelihood of a theory,
which is achieved by Bayesian statistics, but not by frequentist statistics
(e.g. with p-values, you "decide" to reject a null-hypothesis, which does
not tell you anything about whether or something is true or not; but in
Bayesian statistics, you tell the model what you intially believe - i.e.
parameter priors - and then you get results (evidence) which tells you to
which degree you should change your beliefs.)


Best, Ren?

Am Mo., 29. Apr. 2019 um 12:25 Uhr schrieb Souheyla GHEBGHOUB <
souheyla.ghebghoub at gmail.com>:

> Dear Rene,
>
> Thank youbforbyour feedback.
> I will look into this. But before I do, I would like to ask how much
> difference would it make if I am using lme4 package (glmer).
>
> I keep switching between both and havent decided yet. But is it easy to
> implement the aforesaid if its glmer and not brms?
>
> Thank you
> Souheyla
>
>
> On Mon, 29 Apr 2019, 11:20 Ren?, <bimonosom at gmail.com> wrote:
>
>> Hi Souheyla,
>>
>> coming back to the topic (I was busy lately).
>>
>> The interpretation is always a bit of a problem in regressions with
>> categorical interactions. There are two ways to deal with this, one would
>> be to prefer effect coding (search for contrast sum coding online) over
>> dummy coding. In short, with effect coding, you model the deviation of
>> each
>> group from a grand mean. With dummy coding, you start with the intercept
>> parameter and then add up the design cells to have the actual mean
>> estimate
>> of it... I actually do not like both, because first I have no idea how to
>> ideally tell this bro, and also... there is a second and much much easier
>> way:
>>
>> Try this:
>> ## if this is your model: mod2 <- brm(posttest ~ pretest*Group +...)
>> library(emmeans)
>> emmip(mod2,~pretest|Group,type="response",CIs=TRUE)
>> Et voila :)
>> This gives you the posterior marginal estimates from the model for your
>> interaction, predicting the cell specific response probability, including
>> highest density intervals (or Bayesian credible intervals). The option
>> type="response" gives you the predicted probability of post =1; if you
>> delete this option, the marginal estimates will be given on the log scale.
>> In short, this tells you whether something is better remembered post, if
>> it
>> was already known pre (or not), depending on the group.
>>
>> You can get also the marginal main effects like this, using:
>> emmip(mod2,~pretest,type="response",CIs=TRUE)
>> Which would tell you whether something is better remembered post, if it
>> was
>> already known pre. Likewise for group.
>>
>> And if you want to simply get the summary statistics instead of the plot,
>> use this:
>> summod2<-emmip(mod2,~pretest|Group,type="response",CIs=TRUE)
>> summod2$data
>>
>> Best, Ren?
>>
>>
>>
>> Am Mo., 22. Apr. 2019 um 03:59 Uhr schrieb Jeff Newmiller <
>> jdnewmil at dcn.davis.ca.us>:
>>
>> > There is no "formula" syntax other than it has to have at least one
>> > tilde... there is "lm" formula syntax, and "lme" formula syntax, and
>> "nls"
>> > formula syntax, etc... and other model builders are not obligated to
>> > adhere to the "lm" interpretation of formulas.
>> >
>> > I don't see why using * alone in an lm formula should be avoided, but
>> > perhaps John's advice could be reframed as "watch out for the specific
>> > syntax used by your model building function... it may not be the same as
>> > that used by lm".
>> >
>> > On Mon, 22 Apr 2019, Rolf Turner wrote:
>> >
>> > >
>> > > On 22/04/19 6:01 AM, Sorkin, John wrote:
>> > >
>> > >> Souheyla,
>> > >>
>> > >> It is both difficult and dangerous to add a comment to a thread that
>> > >> one has not followed, and in doing so possibly making an
>> > >> inappropriate suggestion. Please forgive what may be an not fully
>> > >> informed thought.
>> > >>
>> > >> The model you suggest, posttest ~ pretest*Group  (ignoring random
>> > >> effects) is unusual. In a model that contains an interaction,  I
>> > >> would expect to see, in addition to the interaction, all main effects
>> > >> included in the interaction, i.e. posttest ~
>> > >> group+pretest+pretest*Group.
>> > >
>> > > As Souheyla has already indicated, in the R (and previously S/Splus)
>> > formula
>> > > syntax, interactions are indicated by a *colon* --- a:b.  The notation
>> > "a*b"
>> > > is a shorthand for
>> > > a + b + a:b.
>> > >
>> > > So pretest*Group is the same as pretest + Group + pretest:Group,
>> whence
>> > it
>> > > contains the main effects.
>> > >
>> > > I disagree with the advice that you gave Souheyla in a follow-up
>> email.
>> > > The construction pretest*Group is preferable, being compact and tidy.
>> > Brevity
>> > > is a virtue.
>> > >
>> > > cheers,
>> > >
>> > > Rolf
>> > >
>> > > --
>> > > Honorary Research Fellow
>> > > Department of Statistics
>> > > University of Auckland
>> > > Phone: +64-9-373-7599 ext. 88276
>> > >
>> > > _______________________________________________
>> > > R-sig-mixed-models at r-project.org mailing list
>> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> > >
>> >
>> >
>> ---------------------------------------------------------------------------
>> > Jeff Newmiller                        The     .....       .....  Go
>> Live...
>> > DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>> > Go...
>> >                                        Live:   OO#.. Dead: OO#..
>> Playing
>> > Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> > /Software/Embedded Controllers)               .OO#.       .OO#.
>> rocks...1k
>> >
>> > _______________________________________________
>> > R-sig-mixed-models at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>

	[[alternative HTML version deleted]]


From @ouhey|@@ghebghoub @end|ng |rom gm@||@com  Mon Apr 29 13:25:48 2019
From: @ouhey|@@ghebghoub @end|ng |rom gm@||@com (Souheyla GHEBGHOUB)
Date: Mon, 29 Apr 2019 12:25:48 +0100
Subject: [R-sig-ME] [FORGED] Re: logistic regression on posttest (0,
 1) with pretest(0, 1)*Group(Treatment, Ctrl) interaction
In-Reply-To: <CADcpBHOfeLALWPX09cjFtFCd3tJMnMDPLrRy5KYeXS7bR+ha3Q@mail.gmail.com>
References: <CAEA998gw2dBJa15idOanou56y-fqCdEv2wFgEsJny-r3TV3Nwg@mail.gmail.com>
 <BN7PR03MB3730B3739E6AC1A906671022E2210@BN7PR03MB3730.namprd03.prod.outlook.com>
 <8b76dea0-0d9a-5b61-0c15-465c3705b988@auckland.ac.nz>
 <alpine.BSF.2.00.1904211856000.82745@pedal.dcn.davis.ca.us>
 <CADcpBHO4quyXCmN0dD+7gdyVO+msQzbhoeL=ROWivt6TpYRBGA@mail.gmail.com>
 <CAEA998jn7Xkrq-gMf6QfTSiMCm=xv0oLa5AJ71XAk4c+1ntEQA@mail.gmail.com>
 <CADcpBHOfeLALWPX09cjFtFCd3tJMnMDPLrRy5KYeXS7bR+ha3Q@mail.gmail.com>
Message-ID: <CAEA998jgp+5=ZcVSCRCkPdozSP0t9XEgUp_Q_7rNWrHDO--nRw@mail.gmail.com>

Ouh Rene, thank you so much.

This is very helpful. I did not know all of this before. Thank you again.

Best regards,
Souheyla

On Mon, 29 Apr 2019, 12:20 Ren?, <bimonosom at gmail.com> wrote:

> Both packages work the same way with respect to the coding/scripting
> (which was intended), even for emmeans both give the same. However, I would
> also suggest considering afex::mixed (in case you stay with the frequentist
> approach), because it enhances the way of testing your models towards
> hierarchical likelihood ratio tests (which is not the same as an anova
> output from a single glm fit).
>
> Thus, the way the effects and design differences are 'constructed' is the
> same, but in lme4 you obtain p-values (i.e. how likely are the data given
> you assume a null-effect), and in brm you obtain posterior parameter
> estimates (i.e. what is the range of parameters that are considered to be
> likely). A lot of people find the latter much more informative in terms of
> statistical decision making, which is layed out in basically every
> introductory paper on Bayes Factors etc (see work by Wagenmakers, Kruschke,
> or Michael Lee and colleagues). But there is a debate, of course, of what
> should be preferred, which I am not able to sum up in a few sentences. Just
> to name a few arguments... 1) people are used to p-values, and like the
> idea of having a 'decisive' criterion. 2) but p-values are not reliable
> (strong argument actually) 3) signigifance testing relies on the quality of
> the research methods (including replications, like Fisher said); 4) What
> the researcher wants to say is something about the likelihood of a theory,
> which is achieved by Bayesian statistics, but not by frequentist statistics
> (e.g. with p-values, you "decide" to reject a null-hypothesis, which does
> not tell you anything about whether or something is true or not; but in
> Bayesian statistics, you tell the model what you intially believe - i.e.
> parameter priors - and then you get results (evidence) which tells you to
> which degree you should change your beliefs.)
>
>
> Best, Ren?
>
> Am Mo., 29. Apr. 2019 um 12:25 Uhr schrieb Souheyla GHEBGHOUB <
> souheyla.ghebghoub at gmail.com>:
>
>> Dear Rene,
>>
>> Thank youbforbyour feedback.
>> I will look into this. But before I do, I would like to ask how much
>> difference would it make if I am using lme4 package (glmer).
>>
>> I keep switching between both and havent decided yet. But is it easy to
>> implement the aforesaid if its glmer and not brms?
>>
>> Thank you
>> Souheyla
>>
>>
>> On Mon, 29 Apr 2019, 11:20 Ren?, <bimonosom at gmail.com> wrote:
>>
>>> Hi Souheyla,
>>>
>>> coming back to the topic (I was busy lately).
>>>
>>> The interpretation is always a bit of a problem in regressions with
>>> categorical interactions. There are two ways to deal with this, one would
>>> be to prefer effect coding (search for contrast sum coding online) over
>>> dummy coding. In short, with effect coding, you model the deviation of
>>> each
>>> group from a grand mean. With dummy coding, you start with the intercept
>>> parameter and then add up the design cells to have the actual mean
>>> estimate
>>> of it... I actually do not like both, because first I have no idea how to
>>> ideally tell this bro, and also... there is a second and much much easier
>>> way:
>>>
>>> Try this:
>>> ## if this is your model: mod2 <- brm(posttest ~ pretest*Group +...)
>>> library(emmeans)
>>> emmip(mod2,~pretest|Group,type="response",CIs=TRUE)
>>> Et voila :)
>>> This gives you the posterior marginal estimates from the model for your
>>> interaction, predicting the cell specific response probability, including
>>> highest density intervals (or Bayesian credible intervals). The option
>>> type="response" gives you the predicted probability of post =1; if you
>>> delete this option, the marginal estimates will be given on the log
>>> scale.
>>> In short, this tells you whether something is better remembered post, if
>>> it
>>> was already known pre (or not), depending on the group.
>>>
>>> You can get also the marginal main effects like this, using:
>>> emmip(mod2,~pretest,type="response",CIs=TRUE)
>>> Which would tell you whether something is better remembered post, if it
>>> was
>>> already known pre. Likewise for group.
>>>
>>> And if you want to simply get the summary statistics instead of the plot,
>>> use this:
>>> summod2<-emmip(mod2,~pretest|Group,type="response",CIs=TRUE)
>>> summod2$data
>>>
>>> Best, Ren?
>>>
>>>
>>>
>>> Am Mo., 22. Apr. 2019 um 03:59 Uhr schrieb Jeff Newmiller <
>>> jdnewmil at dcn.davis.ca.us>:
>>>
>>> > There is no "formula" syntax other than it has to have at least one
>>> > tilde... there is "lm" formula syntax, and "lme" formula syntax, and
>>> "nls"
>>> > formula syntax, etc... and other model builders are not obligated to
>>> > adhere to the "lm" interpretation of formulas.
>>> >
>>> > I don't see why using * alone in an lm formula should be avoided, but
>>> > perhaps John's advice could be reframed as "watch out for the specific
>>> > syntax used by your model building function... it may not be the same
>>> as
>>> > that used by lm".
>>> >
>>> > On Mon, 22 Apr 2019, Rolf Turner wrote:
>>> >
>>> > >
>>> > > On 22/04/19 6:01 AM, Sorkin, John wrote:
>>> > >
>>> > >> Souheyla,
>>> > >>
>>> > >> It is both difficult and dangerous to add a comment to a thread that
>>> > >> one has not followed, and in doing so possibly making an
>>> > >> inappropriate suggestion. Please forgive what may be an not fully
>>> > >> informed thought.
>>> > >>
>>> > >> The model you suggest, posttest ~ pretest*Group  (ignoring random
>>> > >> effects) is unusual. In a model that contains an interaction,  I
>>> > >> would expect to see, in addition to the interaction, all main
>>> effects
>>> > >> included in the interaction, i.e. posttest ~
>>> > >> group+pretest+pretest*Group.
>>> > >
>>> > > As Souheyla has already indicated, in the R (and previously S/Splus)
>>> > formula
>>> > > syntax, interactions are indicated by a *colon* --- a:b.  The
>>> notation
>>> > "a*b"
>>> > > is a shorthand for
>>> > > a + b + a:b.
>>> > >
>>> > > So pretest*Group is the same as pretest + Group + pretest:Group,
>>> whence
>>> > it
>>> > > contains the main effects.
>>> > >
>>> > > I disagree with the advice that you gave Souheyla in a follow-up
>>> email.
>>> > > The construction pretest*Group is preferable, being compact and tidy.
>>> > Brevity
>>> > > is a virtue.
>>> > >
>>> > > cheers,
>>> > >
>>> > > Rolf
>>> > >
>>> > > --
>>> > > Honorary Research Fellow
>>> > > Department of Statistics
>>> > > University of Auckland
>>> > > Phone: +64-9-373-7599 ext. 88276
>>> > >
>>> > > _______________________________________________
>>> > > R-sig-mixed-models at r-project.org mailing list
>>> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> > >
>>> >
>>> >
>>> ---------------------------------------------------------------------------
>>> > Jeff Newmiller                        The     .....       .....  Go
>>> Live...
>>> > DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>>> > Go...
>>> >                                        Live:   OO#.. Dead: OO#..
>>> Playing
>>> > Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>>> > /Software/Embedded Controllers)               .OO#.       .OO#.
>>> rocks...1k
>>> >
>>> > _______________________________________________
>>> > R-sig-mixed-models at r-project.org mailing list
>>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> >
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>

	[[alternative HTML version deleted]]


From m@tr@cc|@ @end|ng |rom g@uc|@@edu  Thu Apr 18 03:06:46 2019
From: m@tr@cc|@ @end|ng |rom g@uc|@@edu (Mark Straccia)
Date: Wed, 17 Apr 2019 18:06:46 -0700
Subject: [R-sig-ME] MCMCglmm biivariate logistic and poisson regression
Message-ID: <CAAanNQ9GiJbwW-9kjaKCG+tvxeJ3UzLEwsMMzTTGa88pwY0AAw@mail.gmail.com>

Hi all,

I am trying to run a bivariate cross-classified logistic and poisson
regression with MCMCglmm. First I have to say MCMCglmm is great because it
is so flexible! The part I am having trouble with is that logistic
regression has no error terms so running bivariate (two outputs) regression
seems pointless because I can't capture the correlation between two
outputs. In MCMCglmm, the error variance has to be set to a number in order
for the program to run. Whatever it is set to, the beta values must then be
correct by k <- sqrt(1 + (((16 * sqrt(3))/(15 * pi))^2) * sigma (where
sigma is the set variance). If I am running bivariate logistic regression
the covariance between the errors also has to be set. It is recommended to
be set at 0.5 and variances as 1.

1) Since the covariance is 0.5 in addition to variance being 1, do the
betas need to be corrected by anything other than the standard k <- sqrt(1
+ (((16 * sqrt(3))/(15 * pi))^2) * sigma (where sigma=1)?

2) 0.5 value seems arbitrary and I should instead let the data determine
what the covariance is between the outputs. I tried rcov =
~corg(trait):units and when I run it, the covariance becomes 1 which I do
not understand why this is happening. For output1 and output2 are 14% ones.
If there is a one for output1, there is a 61% of the time there is a one
for output2 and if there is a zero for output1, there is a 93.7% of the
time there is a zero for output2. The correlation between output1 and
output2 is 0.55 and the hamming distance is 264 out of 2450 data points
(0.108). Why does the covariance become 1 rather than a lower number? (I
should note that the data is doubled so outcome A in output1 and outcome B
in output2 will later become outcome B for output1 and outcome A for
output2, however, as noted earlier output1 is not perfectly predictive of
output2)

3) Since logistic regression has no error terms, it is not clear what the
program is doing when I run rcov = ~corg(trait):units with bivariate
logistic regression. Does anyone have any insights?

4) With Gaussian bivariate regression, the error terms are allow to
correlate to account for the dependencies between the two outputs. With
poisson regression in MCMCglmm, my understanding is the error terms become
the overdispersion in the model. With bivariate poisson regression, does
the covariance between the errors for two output variables do the same
thing as allowing the error terms to correlate in Gaussian bivariate
regression or is it doing something else?

5) I also have count data that I want to run bivariate hurdle poisson
regression with overdispersion. In MCMCglmm it will run both logisitic
regression for the zeros and poisson regression with overdispersion for the
counts. To problem comes that the error variance should be fixed for the
two logistic regression parts while the error variance for the poisson part
should be allowed to vary to account for the overdispersion. There seems to
be no way in MCMCglmm to allow this. You can fix the R matrix (using fix =
#) which will fix sections of the R matrix but you can't fix certain
columns and rows. So you can't specify to fix the logistic regression parts
and allow the poisson part to vary. Is that correct?

6) If #5 is true, are there any plans in the future to allow the
column/rows to be fixed in the error R matrix so that multivariate hurdle
poisson regression can be run with overdispresion?

7) Are there any plans in the future to add hurdle negative binomial
(rather than just poisson) to MCMCglmm? Would that be difficult to
implement?


Thanks for your help!
-Mark

	[[alternative HTML version deleted]]


From ru@@e||-|enth @end|ng |rom u|ow@@edu  Mon Apr 29 18:11:41 2019
From: ru@@e||-|enth @end|ng |rom u|ow@@edu (Lenth, Russell V)
Date: Mon, 29 Apr 2019 16:11:41 +0000
Subject: [R-sig-ME] [FORGED] Re: logistic regression on posttest (0,
 1) with pretest(0, 1)*Group(Treatment, Ctrl) interaction
Message-ID: <DM6PR04MB4380A258B3E8B155E0A5FBCEF1390@DM6PR04MB4380.namprd04.prod.outlook.com>

With regards to obtaining summary statistics, one should use the 'emmeans()' function itself, not 'emmip()'.

For example:

    emmeans(mod2, ~ pretest | Group, type="response")
    pairs(.Last.value)       # to see pairwise comparisons


Russell V. Lenth  -  Professor Emeritus
Department of Statistics and Actuarial Science
The University of Iowa  -  Iowa City, IA 52242  USA
Voice (319)335-0712 (Dept. office)  -  FAX (319)335-3017




> Date: Mon, 29 Apr 2019 12:19:50 +0200
> From: =?UTF-8?B?UmVuw6k=?= <bimonosom at gmail.com>
> To: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> Cc: Rolf Turner <r.turner at auckland.ac.nz>,
>             "r-sig-mixed-models at r-project.org" <r-sig-mixed-models at r-project.org>
> Subject: Re: [R-sig-ME] [FORGED] Re: logistic regression on posttest
>             (0, 1) with pretest(0, 1)*Group(Treatment, Ctrl) interaction
> Message-ID:
>             <CADcpBHO4quyXCmN0dD+7gdyVO+msQzbhoeL=ROWivt6TpYRBGA at mail.gmail.com>
> Content-Type: text/plain; charset="utf-8"
>
> Hi Souheyla,
>
> coming back to the topic (I was busy lately).
>
> The interpretation is always a bit of a problem in regressions with categorical interactions. There are two ways to deal with this, one would be to prefer effect coding (search for contrast sum coding online) over dummy coding. In short, with effect coding, you model the deviation of each group from a grand mean. With dummy coding, you start with the intercept parameter and then add up the design cells to have the actual mean estimate of it... I actually do not like both, because first I have no idea how to ideally tell this bro, and also... there is a second and much much easier
> way:
>
> Try this:
> ## if this is your model: mod2 <- brm(posttest ~ pretest*Group +...)
> library(emmeans)
> emmip(mod2,~pretest|Group,type="response",CIs=TRUE)
> Et voila :)
> This gives you the posterior marginal estimates from the model for your interaction, predicting the cell specific response probability, including highest density intervals (or Bayesian credible intervals). The option type="response" gives you the predicted probability of post =1; if you delete this option, the marginal estimates will be given on the log scale.
> In short, this tells you whether something is better remembered post, if it was already known pre (or not), depending on the group.
>
> You can get also the marginal main effects like this, using:
> emmip(mod2,~pretest,type="response",CIs=TRUE)
> Which would tell you whether something is better remembered post, if it was already known pre. Likewise for group.
>
> And if you want to simply get the summary statistics instead of the plot, use this:
> summod2<-emmip(mod2,~pretest|Group,type="response",CIs=TRUE)
> summod2$data
>
> Best, Ren?
>

	[[alternative HTML version deleted]]


From gu|||@ume@|mon@@2 @end|ng |rom gm@||@com  Mon Apr 29 18:18:09 2019
From: gu|||@ume@|mon@@2 @end|ng |rom gm@||@com (Guillaume Adeux)
Date: Mon, 29 Apr 2019 18:18:09 +0200
Subject: [R-sig-ME] multivariate mixed model for composition data : RRPP,
 mvabund as alternatives to permanova?
Message-ID: <CAENiVe_5cH+XBiz3XxHkr8H061UXLhxec43ED8X57sB0GCHFrw@mail.gmail.com>

Hi everyone,

Does anybody have any experience with multivariate "mixed" models? And more
specifically with the RRPP package or other alternatives to vegan::adonis
for complex hierarchical designs?

I took knowledge of the RRPP package (associated publication:
https://besjournals.onlinelibrary.wiley.com/doi/10.1111/2041-210X.13029 )
but I am having a real hard time transcribing my design into actual code
and defining against what Mean Square the different effects (including
random) should be tested.

The design is the following (split split split plot, very similar to oats
dataset):
    - 4 blocks  -> "block"
    - each block is split into two tillage types (conventional vs.reduced)
-> "tillage"
    - each tillage type is split into 4 nitrogen levels   -> "N"
    - each nitrogen level is split into 4 cover crop types  -> "CC"

To complicate things further, 2 pseudo-replicates were carried out in the
plots at the lowest hierarchical level (cover crops). This results in 32
combinations of tillage, nitrogen and cover crops (128 plots total, x2 =
256 observations). My response is the cover per species of segetal plants.

My objective would be to test all simple effects, first order interactions
and the second order interaction in order to investigate things further.
I'm really looking for something similar to vegan::adonis that takes into
account more than one level of nesting (BiodiversityR::nested.permanova
also only takes into account one level of nesting and does not test the
interaction).

Moreover, reading the Supp. Mat. of the article cited above, it is written
that "mixed model ANOVA is possible via multimodel comparison" with
{mvabund}. Could anyone give me more insight?

Thank you once again for your very appreciated help,

Guillaume ADEUX

	[[alternative HTML version deleted]]


From tor@ten@h@u||e @end|ng |rom gm@||@com  Mon Apr 29 19:05:52 2019
From: tor@ten@h@u||e @end|ng |rom gm@||@com (Torsten Hauffe)
Date: Mon, 29 Apr 2019 19:05:52 +0200
Subject: [R-sig-ME] 
 multivariate mixed model for composition data : RRPP,
 mvabund as alternatives to permanova?
In-Reply-To: <CAENiVe_5cH+XBiz3XxHkr8H061UXLhxec43ED8X57sB0GCHFrw@mail.gmail.com>
References: <CAENiVe_5cH+XBiz3XxHkr8H061UXLhxec43ED8X57sB0GCHFrw@mail.gmail.com>
Message-ID: <CAGCrCxYgQ=PRnAJuwL_b5udXGOpPRb_kVMzgDECtM8HjrNRctA@mail.gmail.com>

The boral package features a straight-forward coding of nested 'random' row
effects. If I remember right, the help package includes an 2-level nested
example.
boral uses Bayesian inferrence and not permutations and is therefore closer
to mvabund than to permanovas. Therefore, and for being not into
experimental design, I don't know whether you need a a more complicated
high-level random structure than just the 'block' and the rest go as
'fixed' effects. In that sense, boral is maybe more similar to lme4,
MCMCglmm etc than community packages like vegan.

However, the boral predictor syntax is different to the regular R formula
and does not include interactions. With model.matrix() first and then
removing the intercept, you can nevertheless specify interactions.

HTH,
Torsten





On Mon, 29 Apr 2019 at 18:22, Guillaume Adeux <guillaumesimon.a2 at gmail.com>
wrote:

> Hi everyone,
>
> Does anybody have any experience with multivariate "mixed" models? And more
> specifically with the RRPP package or other alternatives to vegan::adonis
> for complex hierarchical designs?
>
> I took knowledge of the RRPP package (associated publication:
> https://besjournals.onlinelibrary.wiley.com/doi/10.1111/2041-210X.13029 )
> but I am having a real hard time transcribing my design into actual code
> and defining against what Mean Square the different effects (including
> random) should be tested.
>
> The design is the following (split split split plot, very similar to oats
> dataset):
>     - 4 blocks  -> "block"
>     - each block is split into two tillage types (conventional vs.reduced)
> -> "tillage"
>     - each tillage type is split into 4 nitrogen levels   -> "N"
>     - each nitrogen level is split into 4 cover crop types  -> "CC"
>
> To complicate things further, 2 pseudo-replicates were carried out in the
> plots at the lowest hierarchical level (cover crops). This results in 32
> combinations of tillage, nitrogen and cover crops (128 plots total, x2 =
> 256 observations). My response is the cover per species of segetal plants.
>
> My objective would be to test all simple effects, first order interactions
> and the second order interaction in order to investigate things further.
> I'm really looking for something similar to vegan::adonis that takes into
> account more than one level of nesting (BiodiversityR::nested.permanova
> also only takes into account one level of nesting and does not test the
> interaction).
>
> Moreover, reading the Supp. Mat. of the article cited above, it is written
> that "mixed model ANOVA is possible via multimodel comparison" with
> {mvabund}. Could anyone give me more insight?
>
> Thank you once again for your very appreciated help,
>
> Guillaume ADEUX
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From de@m|ch@|||dou @end|ng |rom gm@||@com  Tue Apr 30 02:09:32 2019
From: de@m|ch@|||dou @end|ng |rom gm@||@com (DESPINA MICHAILIDOU)
Date: Mon, 29 Apr 2019 20:09:32 -0400
Subject: [R-sig-ME] What does that mean?
Message-ID: <CAGP99JEACH7QXjgntD1A1KaOhJ651kU4VjuizQJkp6ydztGFGQ@mail.gmail.com>

I am trying to run the following analysis and receive the following output

glmm_Comb_PH_tod <- glmer(Comb_PH_tod~ CA_effect + (1 | ID/SCAN_DATE/Side),
data=TAK_data, family=binomial(link = "logit"))
summary(glmm_Comb_PH_tod)

Output
Error in length(value <- as.numeric(value)) == 1L :
  (maxstephalfit) PIRLS step-halvings failed to reduce deviance in
pwrssUpdate
> summary(glmm_Comb_PH_tod)
Error in summary(glmm_Comb_PH_tod) : object 'glmm_Comb_PH_tod' not found

How can I fix that? Any suggestions? I am very new to R.

Thank you in advance.
Despina

	[[alternative HTML version deleted]]


From th|erry@onke||nx @end|ng |rom |nbo@be  Tue Apr 30 09:42:45 2019
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Tue, 30 Apr 2019 09:42:45 +0200
Subject: [R-sig-ME] What does that mean?
In-Reply-To: <CAGP99JEACH7QXjgntD1A1KaOhJ651kU4VjuizQJkp6ydztGFGQ@mail.gmail.com>
References: <CAGP99JEACH7QXjgntD1A1KaOhJ651kU4VjuizQJkp6ydztGFGQ@mail.gmail.com>
Message-ID: <CAJuCY5wieQjOkGdcytOe6PFQvJLmzeV1+WayXzwwN-Eo4Dy5dA@mail.gmail.com>

Dear Despina,

I'm guessing that something might be wrong with the coding of the nested
random effect. Note that (1|A/B/C) is equivalent to (1|A) + (1|A:B) +
(1|A:B:C) You'll need to tell us more on your design if you need help on
that. If possible, send a reproducible example including some data.

Another thing you'll need to worry about is (quasi) complete separation.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op di 30 apr. 2019 om 02:09 schreef DESPINA MICHAILIDOU <
de.michailidou at gmail.com>:

> I am trying to run the following analysis and receive the following output
>
> glmm_Comb_PH_tod <- glmer(Comb_PH_tod~ CA_effect + (1 | ID/SCAN_DATE/Side),
> data=TAK_data, family=binomial(link = "logit"))
> summary(glmm_Comb_PH_tod)
>
> Output
> Error in length(value <- as.numeric(value)) == 1L :
>   (maxstephalfit) PIRLS step-halvings failed to reduce deviance in
> pwrssUpdate
> > summary(glmm_Comb_PH_tod)
> Error in summary(glmm_Comb_PH_tod) : object 'glmm_Comb_PH_tod' not found
>
> How can I fix that? Any suggestions? I am very new to R.
>
> Thank you in advance.
> Despina
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From de@m|ch@|||dou @end|ng |rom gm@||@com  Wed May  1 19:24:10 2019
From: de@m|ch@|||dou @end|ng |rom gm@||@com (DESPINA MICHAILIDOU)
Date: Wed, 1 May 2019 13:24:10 -0400
Subject: [R-sig-ME] (no subject)
Message-ID: <CAGP99JEbZ5=BPr6AGriWAMcqjdgw2L6mJt=2AO0d9_nKvjOUDw@mail.gmail.com>

Hi,

I run the following regression analysis with lme4 package and I get the
following message.

glmm_CA_intens<- glmer(Dizz_today ~ CA_intens  + (1 | ID/SCAN_DATE/Side),
data=TAK_data, family=binomial(link = "logit"))
summary(glmm_CA_intens)

Generalized linear mixed model fit by maximum likelihood (Laplace
Approximation) ['glmerMod']
 Family: binomial  ( logit )
Formula: Dizz_today ~ CA_intens + (1 | ID/SCAN_DATE/Side)
   Data: TAK_data

     AIC      BIC   logLik deviance df.resid
    41.7     58.4    -15.8     31.7      205

Scaled residuals:
      Min        1Q    Median        3Q       Max
-0.003892 -0.000827 -0.000826  0.000000  0.054166

Random effects:
 Groups              Name        Variance Std.Dev.
 Side:(SCAN_DATE:ID) (Intercept)    0.0    0.00
 SCAN_DATE:ID        (Intercept) 3223.4   56.78
 ID                  (Intercept)  199.4   14.12
Number of obs: 210, groups:  Side:(SCAN_DATE:ID), 210; SCAN_DATE:ID, 105;
ID, 55

Fixed effects:
              Estimate Std. Error z value Pr(>|z|)
(Intercept) -1.419e+01  1.901e+01  -0.747    0.455
CA_intens   -2.892e+03  1.103e+07   0.000    1.000

Correlation of Fixed Effects:
          (Intr)
CA_intens 0.000
convergence code: 0
boundary (singular) fit: see ?isSingular

Warning messages:
1: In vcov.merMod(object, use.hessian = use.hessian) :
  variance-covariance matrix computed from finite-difference Hessian is
not positive definite or contains NA values: falling back to var-cov
estimated from RX
2: In vcov.merMod(object, correlation = correlation, sigm = sig) :
  variance-covariance matrix computed from finite-difference Hessian is
not positive definite or contains NA values: falling back to var-cov
estimated from RX
>
What is wrong?

Thank you in advance for your help.

Sincerely,
Despina

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Wed May  1 21:40:44 2019
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Wed, 1 May 2019 15:40:44 -0400
Subject: [R-sig-ME] What does that mean?
In-Reply-To: <CAGP99JEACH7QXjgntD1A1KaOhJ651kU4VjuizQJkp6ydztGFGQ@mail.gmail.com>
References: <CAGP99JEACH7QXjgntD1A1KaOhJ651kU4VjuizQJkp6ydztGFGQ@mail.gmail.com>
Message-ID: <34083d93-1e46-6262-4aa4-d1d21712bd8d@gmail.com>



On 2019-04-29 8:09 p.m., DESPINA MICHAILIDOU wrote:
> I am trying to run the following analysis and receive the following output
> 
> glmm_Comb_PH_tod <- glmer(Comb_PH_tod~ CA_effect + (1 | ID/SCAN_DATE/Side),
> data=TAK_data, family=binomial(link = "logit"))
> summary(glmm_Comb_PH_tod)
> 
> Output
> Error in length(value <- as.numeric(value)) == 1L :
>   (maxstephalfit) PIRLS step-halvings failed to reduce deviance in
> pwrssUpdate
>> summary(glmm_Comb_PH_tod)
> Error in summary(glmm_Comb_PH_tod) : object 'glmm_Comb_PH_tod' not found
> 
> How can I fix that? Any suggestions? I am very new to R.
> 
> Thank you in advance.
> Despina

  The second error is relatively easy to understand; since your first
command (using glmer(...)) didn't work, no object "glmm_Comb_PH_tod" has
been created for you to summarize.

  The first part is harder.  My guess would be that there's complete
separation ; I've added a few more notes about the "PIRLS step-halving"
error to the GLMM FAQ
<http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html>.  But it's hard
to know without seeing the actual data.


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Thu May  2 16:20:13 2019
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Thu, 2 May 2019 16:20:13 +0200
Subject: [R-sig-ME] What does that mean?
In-Reply-To: <34083d93-1e46-6262-4aa4-d1d21712bd8d@gmail.com>
References: <CAGP99JEACH7QXjgntD1A1KaOhJ651kU4VjuizQJkp6ydztGFGQ@mail.gmail.com>
 <34083d93-1e46-6262-4aa4-d1d21712bd8d@gmail.com>
Message-ID: <23754.64669.576167.757100@stat.math.ethz.ch>

>>>>> Ben Bolker 
>>>>>     on Wed, 1 May 2019 15:40:44 -0400 writes:

    > On 2019-04-29 8:09 p.m., DESPINA MICHAILIDOU wrote:
    >> I am trying to run the following analysis and receive the following output
    >> 
    >> glmm_Comb_PH_tod <- glmer(Comb_PH_tod~ CA_effect + (1 | ID/SCAN_DATE/Side),
    >> 			      data=TAK_data, family=binomial(link = "logit"))

what happens if you (Despina Michailidou) add  'verbose = 2,'
in the above call to glmer() ?

You should get output which may help us to help you ..

(Note to lme4 maintainers: I'm working at improving our help
 pages so people are less likely to *not* notice the 'verbose' argument.)

Best,
Martin Maechler
ETH Zurich

    >> summary(glmm_Comb_PH_tod)
    >> 
    >> Output
    >> Error in length(value <- as.numeric(value)) == 1L :
    >> (maxstephalfit) PIRLS step-halvings failed to reduce deviance in
    >> pwrssUpdate
    >>> summary(glmm_Comb_PH_tod)
    >> Error in summary(glmm_Comb_PH_tod) : object 'glmm_Comb_PH_tod' not found
    >> 
    >> How can I fix that? Any suggestions? I am very new to R.
    >> 
    >> Thank you in advance.
    >> Despina

    > The second error is relatively easy to understand; since your first
    > command (using glmer(...)) didn't work, no object "glmm_Comb_PH_tod" has
    > been created for you to summarize.

    > The first part is harder.  My guess would be that there's complete
    > separation ; I've added a few more notes about the "PIRLS step-halving"
    > error to the GLMM FAQ
    > <http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html>.  But it's hard
    > to know without seeing the actual data.

    > _______________________________________________
    > R-sig-mixed-models at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbo|ker @end|ng |rom gm@||@com  Thu May  2 16:21:25 2019
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Thu, 2 May 2019 10:21:25 -0400
Subject: [R-sig-ME] What does that mean?
In-Reply-To: <23754.64669.576167.757100@stat.math.ethz.ch>
References: <CAGP99JEACH7QXjgntD1A1KaOhJ651kU4VjuizQJkp6ydztGFGQ@mail.gmail.com>
 <34083d93-1e46-6262-4aa4-d1d21712bd8d@gmail.com>
 <23754.64669.576167.757100@stat.math.ethz.ch>
Message-ID: <09d5b8ed-b4ed-536a-1361-41cdc57fb699@gmail.com>


  More generally (mostly lme4 maintainers will care about this): I
suspect that the PIRLS warning is most often thrown when an NaN occurs
within the computations done in C++ code for *any* reason (predictions
outside of the domain of the link function, complete separation, weirdly
misspecified models, etc.). Figuring out how to better flag these at the
point(s) of origin might help a lot with reporting useful errors.

On 2019-05-02 10:20 a.m., Martin Maechler wrote:
>>>>>> Ben Bolker 
>>>>>>     on Wed, 1 May 2019 15:40:44 -0400 writes:
> 
>     > On 2019-04-29 8:09 p.m., DESPINA MICHAILIDOU wrote:
>     >> I am trying to run the following analysis and receive the following output
>     >> 
>     >> glmm_Comb_PH_tod <- glmer(Comb_PH_tod~ CA_effect + (1 | ID/SCAN_DATE/Side),
>     >> 			      data=TAK_data, family=binomial(link = "logit"))
> 
> what happens if you (Despina Michailidou) add  'verbose = 2,'
> in the above call to glmer() ?
> 
> You should get output which may help us to help you ..
> 
> (Note to lme4 maintainers: I'm working at improving our help
>  pages so people are less likely to *not* notice the 'verbose' argument.)
> 
> Best,
> Martin Maechler
> ETH Zurich
> 
>     >> summary(glmm_Comb_PH_tod)
>     >> 
>     >> Output
>     >> Error in length(value <- as.numeric(value)) == 1L :
>     >> (maxstephalfit) PIRLS step-halvings failed to reduce deviance in
>     >> pwrssUpdate
>     >>> summary(glmm_Comb_PH_tod)
>     >> Error in summary(glmm_Comb_PH_tod) : object 'glmm_Comb_PH_tod' not found
>     >> 
>     >> How can I fix that? Any suggestions? I am very new to R.
>     >> 
>     >> Thank you in advance.
>     >> Despina
> 
>     > The second error is relatively easy to understand; since your first
>     > command (using glmer(...)) didn't work, no object "glmm_Comb_PH_tod" has
>     > been created for you to summarize.
> 
>     > The first part is harder.  My guess would be that there's complete
>     > separation ; I've added a few more notes about the "PIRLS step-halving"
>     > error to the GLMM FAQ
>     > <http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html>.  But it's hard
>     > to know without seeing the actual data.
> 
>     > _______________________________________________
>     > R-sig-mixed-models at r-project.org mailing list
>     > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From de@m|ch@|||dou @end|ng |rom gm@||@com  Thu May  2 21:30:12 2019
From: de@m|ch@|||dou @end|ng |rom gm@||@com (DESPINA MICHAILIDOU)
Date: Thu, 2 May 2019 15:30:12 -0400
Subject: [R-sig-ME] What p value should I report here?
Message-ID: <CAGP99JEWYAGXpeosORPWRdtCwXqv7jCvboigtvLmHL6oeYJK0Q@mail.gmail.com>

Hi everyone,


I am running this regression analysis model and I get the following output.
What P value should I report for my variable P-Dizz today?What does it mean
that fixed-effect model matrix is rank deficient so dropping 1 column /
coefficient? Can anyone help me with the interpretation of those data?


Thank you in advance.


Despina


Generalized linear mixed model fit by maximum likelihood (Laplace
Approximation) ['glmerMod']

 Family: binomial  ( logit )

Formula: Vert_effect ~ P_Diz_today + (1 | ID/SCAN_DATE/Side)

   Data: GCA_data



     AIC      BIC   logLik deviance df.resid

    80.3     94.5    -36.1     72.3      254



Scaled residuals:

      Min        1Q    Median        3Q       Max

-0.012501 -0.000639 -0.000639 -0.000639  0.105723



Random effects:

 Groups              Name        Variance Std.Dev.

 Side:(SCAN_DATE:ID) (Intercept) 1502.7   38.76

 SCAN_DATE:ID        (Intercept)    0.0    0.00

 ID                  (Intercept)  235.1   15.33

Number of obs: 258, groups:  Side:(SCAN_DATE:ID), 258; SCAN_DATE:ID, 130;
ID, 52



Fixed effects:

            Estimate Std. Error z value Pr(>|z|)

(Intercept)  -14.711      3.646  -4.035 5.47e-05 ***

---

Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

fit warnings:

fixed-effect model matrix is rank deficient so dropping 1 column /
coefficient

convergence code: 0

boundary (singular) fit: see ?isSingular

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Fri May  3 04:17:17 2019
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Thu, 2 May 2019 22:17:17 -0400
Subject: [R-sig-ME] What p value should I report here?
In-Reply-To: <CAGP99JEWYAGXpeosORPWRdtCwXqv7jCvboigtvLmHL6oeYJK0Q@mail.gmail.com>
References: <CAGP99JEWYAGXpeosORPWRdtCwXqv7jCvboigtvLmHL6oeYJK0Q@mail.gmail.com>
Message-ID: <0982360f-ae2a-f7d2-2d8c-0f861cebed53@gmail.com>


  Can you show us summary(GCA_data) and
summary(model.frame(fitted_model)) please? It looks like for some reason
(maybe because of observations dropped due to NA values?) you have no
variation in your predictor variable (P_Diz_today).

  It's also potentially problematic that you have an observation-level
random effect for a Bernoulli outcome (i.e., you're fitting a binomial
model with a single-column value as the response and no weights=
argument, which implies you have a 0/1 outcome; you have the same number
of groups in your fully nested [ID:Scan:Side] random effect as
observations), but I don't think this would lead to the dropping of the
P_Diz_today predictor ...

  cheers
    Ben Bolker

On 2019-05-02 3:30 p.m., DESPINA MICHAILIDOU wrote:
> Hi everyone,
> 
> 
> I am running this regression analysis model and I get the following output.
> What P value should I report for my variable P-Dizz today?What does it mean
> that fixed-effect model matrix is rank deficient so dropping 1 column /
> coefficient? Can anyone help me with the interpretation of those data?
> 
> 
> Thank you in advance.
> 
> 
> Despina
> 
> 
> Generalized linear mixed model fit by maximum likelihood (Laplace
> Approximation) ['glmerMod']
> 
>  Family: binomial  ( logit )
> 
> Formula: Vert_effect ~ P_Diz_today + (1 | ID/SCAN_DATE/Side)
> 
>    Data: GCA_data
> 
> 
> 
>      AIC      BIC   logLik deviance df.resid
> 
>     80.3     94.5    -36.1     72.3      254
> 
> 
> 
> Scaled residuals:
> 
>       Min        1Q    Median        3Q       Max
> 
> -0.012501 -0.000639 -0.000639 -0.000639  0.105723
> 
> 
> 
> Random effects:
> 
>  Groups              Name        Variance Std.Dev.
> 
>  Side:(SCAN_DATE:ID) (Intercept) 1502.7   38.76
> 
>  SCAN_DATE:ID        (Intercept)    0.0    0.00
> 
>  ID                  (Intercept)  235.1   15.33
> 
> Number of obs: 258, groups:  Side:(SCAN_DATE:ID), 258; SCAN_DATE:ID, 130;
> ID, 52
> 
> 
> 
> Fixed effects:
> 
>             Estimate Std. Error z value Pr(>|z|)
> 
> (Intercept)  -14.711      3.646  -4.035 5.47e-05 ***
> 
> ---
> 
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> 
> fit warnings:
> 
> fixed-effect model matrix is rank deficient so dropping 1 column /
> coefficient
> 
> convergence code: 0
> 
> boundary (singular) fit: see ?isSingular
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From bbo|ker @end|ng |rom gm@||@com  Fri May  3 04:53:24 2019
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Thu, 2 May 2019 22:53:24 -0400
Subject: [R-sig-ME] What p value should I report here?
In-Reply-To: <CAGP99JHO51FpxRDDbH+d1tpg65YBdzPZtXc8eH7NuzM40spE8w@mail.gmail.com>
References: <CAGP99JEWYAGXpeosORPWRdtCwXqv7jCvboigtvLmHL6oeYJK0Q@mail.gmail.com>
 <0982360f-ae2a-f7d2-2d8c-0f861cebed53@gmail.com>
 <CAGP99JG8vNnRK56oF28zJpdn_FpyGjojtr=+Yog7X-QOndE5QA@mail.gmail.com>
 <1341f37e-18ff-7715-7e90-6e57489a0fa7@gmail.com>
 <CAGP99JHO51FpxRDDbH+d1tpg65YBdzPZtXc8eH7NuzM40spE8w@mail.gmail.com>
Message-ID: <dd92a18a-92d0-49c4-f37c-c185b97af299@gmail.com>


  What we'd like to see is the *results* of summary(Vert_effect) and
summary(model.frame(glmm_Vert_effect)) ... for example, if I was running
the first example in ?lmer, the desired output would look something like
this (here, the two outputs are identical because there are no NA values
in the input).


> library(lme4)
Loading required package: Matrix
> fm1 <- lmer(Reaction~Days+(1|Subject), sleepstudy)
> summary(sleepstudy)
    Reaction          Days        Subject
 Min.   :194.3   Min.   :0.0   308    : 10
 1st Qu.:255.4   1st Qu.:2.0   309    : 10
 Median :288.7   Median :4.5   310    : 10
 Mean   :298.5   Mean   :4.5   330    : 10
 3rd Qu.:336.8   3rd Qu.:7.0   331    : 10
 Max.   :466.4   Max.   :9.0   332    : 10
                               (Other):120
> summary(model.frame(fm1))
    Reaction          Days        Subject
 Min.   :194.3   Min.   :0.0   308    : 10
 1st Qu.:255.4   1st Qu.:2.0   309    : 10
 Median :288.7   Median :4.5   310    : 10
 Mean   :298.5   Mean   :4.5   330    : 10
 3rd Qu.:336.8   3rd Qu.:7.0   331    : 10
 Max.   :466.4   Max.   :9.0   332    : 10
                               (Other):120


On 2019-05-02 10:51 p.m., DESPINA MICHAILIDOU wrote:
> The code is
> 
> glmm_Vert_effect?<- glmer(Vert_effect?~ P-Diz-today?+ (1|
> ID/SCAN_DATE/Side), data=GCA_data, family=binomial(link= "logit"))
> 
> summary(Vert_effect).
> 
> 
> That is your question?
> 
> 
> I am sorry i am very new to R.
> 
> 
> Thank you for your interest and help. Really appreciate it.
> 
> 
> Despina
> 
> 
> ???? ???, 2 ??? 2019 ???? 10:40 ?.?., ?/? Ben Bolker <bbolker at gmail.com
> <mailto:bbolker at gmail.com>> ??????:
> 
> 
>     ? We will be able to help much better if you can provide a reproducible
>     example, or at least the results of the summary() commands requested
>     below ...
> 
>     On 2019-05-02 10:29 p.m., DESPINA MICHAILIDOU wrote:
>     > Yes you are correct. I have a 0 or 1 scoring outcome. I do have some
>     > blanks in my observations.? Thank you for your response.
>     >
>     > Despina
>     >
>     > ???? ???, 2 ??? 2019 ???? 10:19 ?.?., ?/? Ben Bolker
>     <bbolker at gmail.com <mailto:bbolker at gmail.com>
>     > <mailto:bbolker at gmail.com <mailto:bbolker at gmail.com>>> ??????:
>     >
>     >
>     >? ? ?? Can you show us summary(GCA_data) and
>     >? ? ?summary(model.frame(fitted_model)) please? It looks like for
>     some reason
>     >? ? ?(maybe because of observations dropped due to NA values?) you
>     have no
>     >? ? ?variation in your predictor variable (P_Diz_today).
>     >
>     >? ? ?? It's also potentially problematic that you have an
>     observation-level
>     >? ? ?random effect for a Bernoulli outcome (i.e., you're fitting a
>     binomial
>     >? ? ?model with a single-column value as the response and no weights=
>     >? ? ?argument, which implies you have a 0/1 outcome; you have the
>     same number
>     >? ? ?of groups in your fully nested [ID:Scan:Side] random effect as
>     >? ? ?observations), but I don't think this would lead to the
>     dropping of the
>     >? ? ?P_Diz_today predictor ...
>     >
>     >? ? ?? cheers
>     >? ? ?? ? Ben Bolker
>     >
>     >? ? ?On 2019-05-02 3:30 p.m., DESPINA MICHAILIDOU wrote:
>     >? ? ?> Hi everyone,
>     >? ? ?>
>     >? ? ?>
>     >? ? ?> I am running this regression analysis model and I get the
>     >? ? ?following output.
>     >? ? ?> What P value should I report for my variable P-Dizz today?What
>     >? ? ?does it mean
>     >? ? ?> that fixed-effect model matrix is rank deficient so dropping 1
>     >? ? ?column /
>     >? ? ?> coefficient? Can anyone help me with the interpretation of
>     those data?
>     >? ? ?>
>     >? ? ?>
>     >? ? ?> Thank you in advance.
>     >? ? ?>
>     >? ? ?>
>     >? ? ?> Despina
>     >? ? ?>
>     >? ? ?>
>     >? ? ?> Generalized linear mixed model fit by maximum likelihood
>     (Laplace
>     >? ? ?> Approximation) ['glmerMod']
>     >? ? ?>
>     >? ? ?>? Family: binomial? ( logit )
>     >? ? ?>
>     >? ? ?> Formula: Vert_effect ~ P_Diz_today + (1 | ID/SCAN_DATE/Side)
>     >? ? ?>
>     >? ? ?>? ? Data: GCA_data
>     >? ? ?>
>     >? ? ?>
>     >? ? ?>
>     >? ? ?>? ? ? AIC? ? ? BIC? ?logLik deviance df.resid
>     >? ? ?>
>     >? ? ?>? ? ?80.3? ? ?94.5? ? -36.1? ? ?72.3? ? ? 254
>     >? ? ?>
>     >? ? ?>
>     >? ? ?>
>     >? ? ?> Scaled residuals:
>     >? ? ?>
>     >? ? ?>? ? ? ?Min? ? ? ? 1Q? ? Median? ? ? ? 3Q? ? ? ?Max
>     >? ? ?>
>     >? ? ?> -0.012501 -0.000639 -0.000639 -0.000639? 0.105723
>     >? ? ?>
>     >? ? ?>
>     >? ? ?>
>     >? ? ?> Random effects:
>     >? ? ?>
>     >? ? ?>? Groups? ? ? ? ? ? ? Name? ? ? ? Variance Std.Dev.
>     >? ? ?>
>     >? ? ?>? Side:(SCAN_DATE:ID) (Intercept) 1502.7? ?38.76
>     >? ? ?>
>     >? ? ?>? SCAN_DATE:ID? ? ? ? (Intercept)? ? 0.0? ? 0.00
>     >? ? ?>
>     >? ? ?>? ID? ? ? ? ? ? ? ? ? (Intercept)? 235.1? ?15.33
>     >? ? ?>
>     >? ? ?> Number of obs: 258, groups:? Side:(SCAN_DATE:ID), 258;
>     >? ? ?SCAN_DATE:ID, 130;
>     >? ? ?> ID, 52
>     >? ? ?>
>     >? ? ?>
>     >? ? ?>
>     >? ? ?> Fixed effects:
>     >? ? ?>
>     >? ? ?>? ? ? ? ? ? ?Estimate Std. Error z value Pr(>|z|)
>     >? ? ?>
>     >? ? ?> (Intercept)? -14.711? ? ? 3.646? -4.035 5.47e-05 ***
>     >? ? ?>
>     >? ? ?> ---
>     >? ? ?>
>     >? ? ?> Signif. codes:? 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>     >? ? ?>
>     >? ? ?> fit warnings:
>     >? ? ?>
>     >? ? ?> fixed-effect model matrix is rank deficient so dropping 1
>     column /
>     >? ? ?> coefficient
>     >? ? ?>
>     >? ? ?> convergence code: 0
>     >? ? ?>
>     >? ? ?> boundary (singular) fit: see ?isSingular
>     >? ? ?>
>     >? ? ?>? ? ? ?[[alternative HTML version deleted]]
>     >? ? ?>
>     >? ? ?> _______________________________________________
>     >? ? ?> R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>     >? ? ?<mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>> mailing list
>     >? ? ?> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     >? ? ?>
>     >
>     >? ? ?_______________________________________________
>     >? ? ?R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>     >? ? ?<mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>> mailing list
>     >? ? ?https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     >
>


From p@r|@m @end|ng |rom @t@n|ord@edu  Fri May  3 08:59:12 2019
From: p@r|@m @end|ng |rom @t@n|ord@edu (Pardis Miri)
Date: Fri, 3 May 2019 06:59:12 +0000
Subject: [R-sig-ME] Dealing with zero inflated models: How to visualize and
 bootstrap to calculate the CIs?
Message-ID: <CA+WU=HC7sVNmg5A+mhQZhQdmC_QuEVQugm4=hd933_eO9ERY7Q@mail.gmail.com>

Hi everyone,

I have five DVs (Attend, Differentiate, Synchronize, Negative Affect (NA), and Positive Affect (PA)) collected from slider bars. Zero value means that haptic pattern that a participant experienced was  easy to attend, easy to differentiate, and easy to synchronize breathing with.
Zero value also means that the participant didn't feel negative at all.

As you can see in link<https://wehab.stanford.edu/wp-content/uploads/2019/05/zero_inflated_2.png> 1 and link 2<https://wehab.stanford.edu/wp-content/uploads/2019/05/zero_inflated_1.png> , the data for Attend, Differentiate, Synchronize, and NA are all zero inflated. We expected to see this: this is an indication that our intervention worked well. But, I am struggling with the following three problems.

IVs:
      Bodysite: Abdomen, Lowerback, and Chest
      Pattern:  Vertical, Horizontal, and Diagonal
      Shape:   Strong Inhale, and Strong Exhale.



1. I am not sure which one of these formulas I should be using to model my data and why one should be better than the other.

### Differentiate (zero inflation) --> Boot strapping doesn't work.
```{r  Differentiate}
# >> won't work with boothstrapping
# bootstrap parameter estimates -->  error bootstrapping doesn't accept the glmmTBM. instead you should be using the lmer or glmer.... . n = 36  (number of participants).


# first way

fit.differentiate = glmmTMB((Differentiate/100* 35 + .5) /36 ~ Bodysite + Pattern * Strength + (1 |id), data=df.cleaned,  ziformula=~1, family=beta_family(link = "logit"))
fit.attend %>%
  summary()

# Alternative way

library("GLMMadaptive")
fit.differentiate = mixed_model(Differentiate ~ Bodysite + Pattern * Strength, random = ~ 1 | id, data=df.cleaned, family=zi.poisson(), zi_fixed = ~ Bodysite + Pattern * Strength, zi_random = ~ 1 | id)
fit.attend %>%
  summary()


#still won't work with bootstrapping
boot.lmer = bootMer(fit.differentiate,
FUN = fixef,
nsim = 1000)

n = 1  # one hypothesis testing for now. Have to change it later.

# compute confidence intervals for all the estimates in one go.
tidy(boot.lmer,conf.int<http://conf.int>=TRUE,conf.method="perc", conf.level = 1 - (.05/n))
```

2. I don't know how to use bootstrapping to calculate the CI for inflated with zero models.

3. I don't know how to visualize the data like how I did for another DV that is not inflated with zero (see example<https://wehab.stanford.edu/wp-content/uploads/2019/05/mixed_model_vis1.png>).
```{r slop_visualization}
p = fit.lmer %>%
augment() %>%
clean_names() %>%
ggplot(data = .,
mapping = aes(x = bodysite,
y = sc_slope,
col = id,
shape = strength,
group = interaction(strength,id))) +
facet_wrap(~pattern, ncol = 5) +
geom_point(alpha = 0.2) +
geom_line(alpha = 0.5) +
geom_point(aes(y = fitted),
color = "red") +
geom_line(aes(y = fitted),
          color = "red") +
xlab("") +
ylab("SC_slope")

p

ggsave("SC_slope_model.png", plot = p, width = 8, height = 6, units = "in")

```

Thank you in advance!
P





	[[alternative HTML version deleted]]


From @on|@@bej@r@no @end|ng |rom |e|bn|z-zmt@de  Fri May  3 17:13:46 2019
From: @on|@@bej@r@no @end|ng |rom |e|bn|z-zmt@de (Sonia Bejarano)
Date: Fri, 3 May 2019 17:13:46 +0200
Subject: [R-sig-ME] Fitting a zero inflated mixed-effects mode to proportion
 data using glmmTMB
Message-ID: <15a5b2b5-ce2e-98ea-239a-3bd2fa56877b@leibniz-zmt.de>

Dear R-sig-mixed-models Listers

I am trying to fit a zero inflated mixed-effects model to determine 
whether my response variable (i.e. proportion of organisms with 
parasite) differs between 2 conditions (protected zones vs. open zones), 
and between 2 zones (inner, outer). Aside from these two fixed factors, 
I have 2 random factors (i.e. transect and site). As my response 
variable is zero-inflated (i.e. I have 41% observations are 0)? I tried 
fitting:

MZINF<- glmmTMB(organisms.with.parasites/total.num.organisms.checked ~ 
condition + zone + +(1 | site)+ (1 | transect), + zi=~., + disp=~zone, + 
family = binomial, + weights=total.num.organisms.checked, + data=zanvic)


Here my questions:

1) if I fitzi = ~.  or evenzi = ~ condition + zone  I get convergence problems and NAs
but I get no NAs or convergence problems when I fitzi = ~ 1, zi = ~ condition, orzi = ~ zone
does this mean that due to insufficient observations per condition or per zone, I cannot test
simultaneously whether the probability of observing a structural 0 is influenced by zone and by condition?

2) If when I fitzi = ~ 1
Zero-inflation model:
             Estimate Std. Error z value Pr(>|z|)
(Intercept)   -21.37   12320.75  -0.002    0.999

Does the p value > 0.05 values in here mean that the probability of observing structural zeroes
is independent of by zone or condition? or is*not *independent of zone or condition?

2) Different from the outputs explained in Brooks et al 2019 (The R 
Journal Vol. 9/2, December 2017) when fitting the above I do not get a 
Dispersion model section in my output, why is this? have I coded 
something wrong in my model?

Many thanks,

Sonia


	[[alternative HTML version deleted]]


From r@ckerm@n27 @end|ng |rom gm@||@com  Sat May  4 21:38:12 2019
From: r@ckerm@n27 @end|ng |rom gm@||@com (Robert Ackerman)
Date: Sat, 4 May 2019 14:38:12 -0500
Subject: [R-sig-ME] False Convergence warning
Message-ID: <CADwBd8Ve4ROYb+-MoajGDJ=_TxOgSrWgvJyAqEmmhrAQyDJkUg@mail.gmail.com>

Hi everyone,

I have data from a speed-dating study, where groups of men and women
interacted with each other for five minutes and subsequently provided
ratings of the interaction and their partner.

These are the first lines of my data set:

   GROUPID MaleID FemaleID MF FM Agender AATTRACT

1        1      1        2  1  0       1     3.00

2        1      1        4  1  0       1     3.25

3        1      1        6  1  0       1     6.00

4        1      1        8  1  0       1     3.50

5        1      1       10  1  0       1     3.50

6        1      1        2  0  1      -1     5.00

7        1      3        2  0  1      -1     3.50

8        1      5        2  0  1      -1     5.00

9        1      7        2  0  1      -1     4.75

10       1      9        2  0  1      -1     2.25

11       1      3        2  1  0       1     1.25

12       1      3        4  1  0       1     3.25



Altogether, I have 904 observations (33 speed-dating groups comprised of
3-5 men and women each).

I?m trying to use glmmTMB to get a model with crossed random effects and an
unstructured covariance matrix for the residuals to run. Please note that I
was able to get this model to run in SPSS without problems (estimates of
fixed effects and random effects are also virtually identical). However, I
wanted to use R for its ease of checking multilevel modeling assumptions.

Here is the syntax for the model I tried to run in glmmTMB:

glmmTMB(AATTRACT ~ 1 + Agender+ (0 + MF + FM|GROUPID:MaleID) +

                   (0 + FM + MF|GROUPID:FemaleID)  + us(MF + FM + 0|
GROUPID:MaleID:FemaleID),

                    data = SD_data,  family = gaussian(link = "identity"),
dispformula=~0, REML = FALSE,

                   verbose = TRUE)

I received the following output and error message after running this model:

Formula: AATTRACT ~ 1 + Agender + (0 + MF + FM | GROUPID:MaleID) + (0 +

  FM + MF | GROUPID:FemaleID) + us(0 + MF + FM + 0 | GROUPID:MaleID:FemaleID)

Dispersion:                ~0

Data: SD_data

      AIC       BIC    logLik  df.resid

 2891.436  2944.311 -1434.718       893

Random-effects (co)variances:



Conditional model:

 Groups                  Name Std.Dev.  Corr

 GROUPID:MaleID          MF   0.5572656

                         FM   0.7916470 -0.02

 GROUPID:FemaleID        FM   0.6732786

                         MF   0.7529185 -0.16

 GROUPID:MaleID:FemaleID MF   0.8523621

                         FM   0.9419247 0.26

 Residual                     0.0001221



Number of obs: 904 / Conditional model: GROUPID:MaleID, 120;
GROUPID:FemaleID, 120; GROUPID:MaleID:FemaleID, 452



Fixed Effects:



Conditional model:

(Intercept)      Agender

     3.9048       0.1112

Warning message:

In fitTMB(TMBStruc) :

  Model convergence problem; false convergence (8). See
vignette('troubleshooting')



Because I used verbose = TRUE, I also received the following mgc values
(I?m only including the last few lines here).

mgc: 5.077952e-08

outer mgc:  0.544794

iter: 1  value: -5887.447 mgc: 0.003153025 ustep: 1

iter: 2  value: -5887.447 mgc: 6.546202e-08 ustep: 1

mgc: 9.447453e-08

outer mgc:  0.2579731

iter: 1  value: -5887.346 mgc: 0.003152465 ustep: 1

iter: 2  value: -5887.346 mgc: 5.733777e-08 ustep: 1

mgc: 7.849359e-08

outer mgc:  0.2594169



Does anyone have any insights into what might be going wrong?

Thanks!

Rob

	[[alternative HTML version deleted]]


From 18754808835 @end|ng |rom 163@com  Mon May  6 03:11:47 2019
From: 18754808835 @end|ng |rom 163@com (=?GBK?B?us7I58PO?=)
Date: Mon, 6 May 2019 09:11:47 +0800 (CST)
Subject: [R-sig-ME] A consultation about DF of the result of lmer
Message-ID: <70f1b859.675a.16a8ab261f0.Coremail.18754808835@163.com>

Dear, 
I am a graduated student who's topic is  ecology. Recently, I am studying how to establish a liner mixed model to exclude the error caused by the difference of site by using lme4 in R. I found  when I calculated p value by using the function of "Anova" of car package the Df is 1. But in fact the data set has 6 levels. Then I also operate according to the code of reference PDF of lme4 in P52(lmer) without any change. When run "anova(fm1, fm2)" I found the Df of fm1 also is 1. As I see if the Df is wrong the p value would be wrong either. I want to know how to correct my wrong. I will very appreciate your reply.


Best regards,
Rumeng He
	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Tue May  7 18:31:14 2019
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Tue, 7 May 2019 12:31:14 -0400
Subject: [R-sig-ME] A consultation about DF of the result of lmer
In-Reply-To: <70f1b859.675a.16a8ab261f0.Coremail.18754808835@163.com>
References: <70f1b859.675a.16a8ab261f0.Coremail.18754808835@163.com>
Message-ID: <8b3d3fe4-ab47-ea83-e2c2-ffc1d77f0488@gmail.com>

   It's very hard to say without more information (try e.g. here
<https://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example>
or look at other posts in the list archive
<https://stat.ethz.ch/pipermail/r-sig-mixed-models/>

  A first guess is that you have a fixed-effect predictor that's
supposed to be a factor with 6 levels, but is actually being interpreted
as a numeric variable.  If that's the case, then either changing it
within the data set

  mydata$pred1 <- factor(mydata$pred1)

or doing it on the fly in your  model

  lmer(response ~ factor(pred1) + ...)

should fix the problem.


On 2019-05-05 9:11 p.m., ??? wrote:
> Dear, 
> I am a graduated student who's topic is  ecology. Recently, I am studying how to establish a liner mixed model to exclude the error caused by the difference of site by using lme4 in R. I found  when I calculated p value by using the function of "Anova" of car package the Df is 1. But in fact the data set has 6 levels. Then I also operate according to the code of reference PDF of lme4 in P52(lmer) without any change. When run "anova(fm1, fm2)" I found the Df of fm1 also is 1. As I see if the Df is wrong the p value would be wrong either. I want to know how to correct my wrong. I will very appreciate your reply.
> 
> 
> Best regards,
> Rumeng He
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From de@m|ch@|||dou @end|ng |rom gm@||@com  Tue May  7 19:15:13 2019
From: de@m|ch@|||dou @end|ng |rom gm@||@com (DESPINA MICHAILIDOU)
Date: Tue, 7 May 2019 13:15:13 -0400
Subject: [R-sig-ME] How do I run ordinal regression analysis
Message-ID: <CAGP99JETG9hCRv-W5vGBgA4pxaEzqsXqpktPJaL9L_eBPVxKBQ@mail.gmail.com>

Hi Everyone,

I would like to run a regression analysis and look at the association
between dizziness and 0 vs 1 neck vessels vs 2 neck vessels vs 3 neck
vessels vs 4 neck vessels individually. Which package should i use? What
would the code in R would look like?

Thank you All.

Sincerely,
Despina

	[[alternative HTML version deleted]]


From j|ox @end|ng |rom mcm@@ter@c@  Tue May  7 19:49:39 2019
From: j|ox @end|ng |rom mcm@@ter@c@ (Fox, John)
Date: Tue, 7 May 2019 17:49:39 +0000
Subject: [R-sig-ME] A consultation about DF of the result of lmer
In-Reply-To: <15858_1557246694_x47GVXNA004405_8b3d3fe4-ab47-ea83-e2c2-ffc1d77f0488@gmail.com>
References: <70f1b859.675a.16a8ab261f0.Coremail.18754808835@163.com>
 <15858_1557246694_x47GVXNA004405_8b3d3fe4-ab47-ea83-e2c2-ffc1d77f0488@gmail.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC836BA4B38@FHSDB2D11-2.csu.mcmaster.ca>

Dear Rumeng He,

For what it's worth, my guess is the same as Ben's. If we're wrong, then you'll have to send more information about what you did, ideally including a reproducible example of the problem.

Best,
 John

--------------------------------------
John Fox, Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
Web: socialsciences.mcmaster.ca/jfox/



> -----Original Message-----
> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-
> project.org] On Behalf Of Ben Bolker
> Sent: Tuesday, May 7, 2019 12:31 PM
> To: r-sig-mixed-models at r-project.org
> Subject: Re: [R-sig-ME] A consultation about DF of the result of lmer
> 
>    It's very hard to say without more information (try e.g. here
> <https://stackoverflow.com/questions/5963269/how-to-make-a-great-r-
> reproducible-example>
> or look at other posts in the list archive
> <https://stat.ethz.ch/pipermail/r-sig-mixed-models/>
> 
>   A first guess is that you have a fixed-effect predictor that's
> supposed to be a factor with 6 levels, but is actually being interpreted
> as a numeric variable.  If that's the case, then either changing it
> within the data set
> 
>   mydata$pred1 <- factor(mydata$pred1)
> 
> or doing it on the fly in your  model
> 
>   lmer(response ~ factor(pred1) + ...)
> 
> should fix the problem.
> 
> 
> On 2019-05-05 9:11 p.m., ??? wrote:
> > Dear,
> > I am a graduated student who's topic is  ecology. Recently, I am
> studying how to establish a liner mixed model to exclude the error
> caused by the difference of site by using lme4 in R. I found  when I
> calculated p value by using the function of "Anova" of car package the
> Df is 1. But in fact the data set has 6 levels. Then I also operate
> according to the code of reference PDF of lme4 in P52(lmer) without any
> change. When run "anova(fm1, fm2)" I found the Df of fm1 also is 1. As I
> see if the Df is wrong the p value would be wrong either. I want to know
> how to correct my wrong. I will very appreciate your reply.
> >
> >
> > Best regards,
> > Rumeng He
> > 	[[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

From p@u|@buerkner @end|ng |rom gm@||@com  Tue May  7 20:10:25 2019
From: p@u|@buerkner @end|ng |rom gm@||@com (Paul Buerkner)
Date: Tue, 7 May 2019 21:10:25 +0300
Subject: [R-sig-ME] How do I run ordinal regression analysis
In-Reply-To: <CAGP99JETG9hCRv-W5vGBgA4pxaEzqsXqpktPJaL9L_eBPVxKBQ@mail.gmail.com>
References: <CAGP99JETG9hCRv-W5vGBgA4pxaEzqsXqpktPJaL9L_eBPVxKBQ@mail.gmail.com>
Message-ID: <CAGoSky-CaER9aptjg4L1AJPzk1mie6woTStKi3W3bKMZhn-itw@mail.gmail.com>

You may want to take a look at the brms R package. An introduction to
ordinal models with brms can be found at
https://psyarxiv.com/x8swp/

Paul

Am Di., 7. Mai 2019 um 20:15 Uhr schrieb DESPINA MICHAILIDOU <
de.michailidou at gmail.com>:

> Hi Everyone,
>
> I would like to run a regression analysis and look at the association
> between dizziness and 0 vs 1 neck vessels vs 2 neck vessels vs 3 neck
> vessels vs 4 neck vessels individually. Which package should i use? What
> would the code in R would look like?
>
> Thank you All.
>
> Sincerely,
> Despina
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From r@ch@e|@m@dy @end|ng |rom gm@||@com  Tue May  7 23:17:00 2019
From: r@ch@e|@m@dy @end|ng |rom gm@||@com (Rachael Mady)
Date: Tue, 7 May 2019 17:17:00 -0400
Subject: [R-sig-ME] Warning message after "unscaling" predictor variable
Message-ID: <CAC8Jvgw3hDpMef3vOORnadQRHW2cVQdZ8EpEmF8yf8okySm_kQ@mail.gmail.com>

Hello,

I have been successfully using the glmmTMB package, but have come across a
Warning today that I cannot solve. The data and the code are provided below
this posting.

I have been running mixed models with julian date scaled and centered (such
that it is a z-score; julian2 in the data). Today, I tried to run the same
models without julian date scaled and centered and received this warning:

*Warning message:*
*In nlminb(start = par, objective = fn, gradient = gr, control =
control$optCtrl) :*
*  NA/NaN function evaluation*

To recreate, see the code below. Mod1 is with julian not scaled/centered
and mod2 is with julian scaled.

*The data and code to reproduce situation: *

data <-
structure(list(sum.50 = c(2L, 1L, 2L, 0L, 0L, 7L, 0L, 6L, 1L,
0L, 3L, 8L, 1L, 0L, 2L, 7L, 0L, 0L, 1L, 3L, 2L, 0L, 8L, 9L, 6L,
1L, 8L, 8L, 0L, 5L, 0L, 0L, 5L, 3L, 1L, 5L, 2L, 0L, 0L, 2L, 7L,
0L, 0L, 7L, 1L, 0L, 5L, 8L, 5L, 3L, 0L, 4L, 8L, 2L, 7L, 0L, 2L,
7L, 0L, 1L, 12L, 5L, 0L, 14L, 0L, 5L, 5L, 2L, 6L, 0L, 3L, 1L,
0L, 4L, 5L, 1L, 0L, 3L, 9L, 1L, 13L, 0L, 5L, 7L, 8L, 5L, 0L,
9L, 11L, 0L, 0L, 4L, 3L, 0L, 4L, 7L, 7L, 7L, 0L, 1L, 5L, 1L),
    trtmt_simple = structure(c(3L, 1L, 2L, 3L, 1L, 2L, 1L, 2L,
    3L, 1L, 2L, 3L, 2L, 3L, 1L, 2L, 3L, 1L, 1L, 2L, 3L, 1L, 2L,
    3L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 2L, 3L,
    1L, 2L, 3L, 1L, 1L, 2L, 3L, 1L, 2L, 3L, 2L, 3L, 1L, 2L, 3L,
    1L, 3L, 1L, 2L, 2L, 3L, 1L, 2L, 3L, 1L, 3L, 1L, 2L, 3L, 1L,
    2L, 1L, 2L, 3L, 1L, 2L, 3L, 3L, 1L, 2L, 3L, 1L, 2L, 1L, 2L,
    3L, 2L, 3L, 1L, 2L, 3L, 1L, 1L, 2L, 3L, 1L, 2L, 3L, 2L, 3L,
    1L, 2L, 3L, 1L), .Label = c("control", "constant", "pulsed"
    ), class = "factor"), site = structure(c(3L, 4L, 5L, 3L,
    4L, 5L, 8L, 9L, 6L, 8L, 9L, 6L, 1L, 2L, 7L, 1L, 2L, 7L, 4L,
    5L, 3L, 4L, 5L, 3L, 6L, 8L, 9L, 6L, 8L, 9L, 2L, 7L, 1L, 2L,
    7L, 1L, 9L, 6L, 8L, 9L, 6L, 8L, 7L, 1L, 2L, 7L, 1L, 2L, 5L,
    3L, 4L, 5L, 3L, 4L, 6L, 8L, 9L, 1L, 2L, 7L, 1L, 2L, 7L, 3L,
    4L, 5L, 3L, 4L, 5L, 8L, 9L, 6L, 8L, 9L, 6L, 2L, 7L, 1L, 2L,
    7L, 1L, 4L, 5L, 3L, 9L, 6L, 8L, 9L, 6L, 8L, 7L, 1L, 2L, 7L,
    1L, 2L, 5L, 3L, 4L, 5L, 3L, 4L), .Label = c("bakh", "icel",
    "lid1", "lid2", "lid3", "mtpl", "nemi", "yb01", "yb02"), class =
"factor"),
    julian = c(12L, 12L, 12L, 14L, 14L, 14L, 19L, 19L, 19L, 21L,
    21L, 21L, 26L, 26L, 26L, 28L, 28L, 28L, 33L, 33L, 33L, 35L,
    35L, 35L, 40L, 40L, 40L, 42L, 42L, 42L, 47L, 47L, 47L, 49L,
    49L, 49L, 61L, 61L, 61L, 63L, 63L, 63L, 68L, 68L, 68L, 70L,
    70L, 70L, 75L, 75L, 75L, 77L, 77L, 77L, 84L, 84L, 84L, 89L,
    89L, 89L, 91L, 91L, 91L, 96L, 96L, 96L, 98L, 98L, 98L, 103L,
    103L, 103L, 105L, 105L, 105L, 110L, 110L, 110L, 112L, 112L,
    112L, 119L, 119L, 119L, 124L, 124L, 124L, 126L, 126L, 126L,
    131L, 131L, 131L, 133L, 133L, 133L, 138L, 138L, 138L, 140L,
    140L, 140L), julian2 = structure(c(-1.60484310158565,
-1.60484310158565,
    -1.60484310158565, -1.55457625178932, -1.55457625178932,
    -1.55457625178932, -1.42890912729851, -1.42890912729851,
    -1.42890912729851, -1.37864227750218, -1.37864227750218,
    -1.37864227750218, -1.25297515301137, -1.25297515301137,
    -1.25297515301137, -1.20270830321504, -1.20270830321504,
    -1.20270830321504, -1.07704117872422, -1.07704117872422,
    -1.07704117872422, -1.0267743289279, -1.0267743289279,
-1.0267743289279,
    -0.901107204437083, -0.901107204437083, -0.901107204437083,
    -0.850840354640757, -0.850840354640757, -0.850840354640757,
    -0.725173230149941, -0.725173230149941, -0.725173230149941,
    -0.674906380353615, -0.674906380353615, -0.674906380353615,
    -0.373305281575658, -0.373305281575658, -0.373305281575658,
    -0.323038431779332, -0.323038431779332, -0.323038431779332,
    -0.197371307288516, -0.197371307288516, -0.197371307288516,
    -0.14710445749219, -0.14710445749219, -0.14710445749219,
    -0.0214373330013746, -0.0214373330013746, -0.0214373330013746,
    0.0288295167949516, 0.0288295167949516, 0.0288295167949516,
    0.204763491082093, 0.204763491082093, 0.204763491082093,
    0.330430615572909, 0.330430615572909, 0.330430615572909,
    0.380697465369235, 0.380697465369235, 0.380697465369235,
    0.506364589860051, 0.506364589860051, 0.506364589860051,
    0.556631439656377, 0.556631439656377, 0.556631439656377,
    0.682298564147192, 0.682298564147192, 0.682298564147192,
    0.732565413943518, 0.732565413943518, 0.732565413943518,
    0.858232538434334, 0.858232538434334, 0.858232538434334,
    0.90849938823066, 0.90849938823066, 0.90849938823066, 1.0844333625178,
    1.0844333625178, 1.0844333625178, 1.21010048700862, 1.21010048700862,
    1.21010048700862, 1.26036733680494, 1.26036733680494, 1.26036733680494,
    1.38603446129576, 1.38603446129576, 1.38603446129576, 1.43630131109209,
    1.43630131109209, 1.43630131109209, 1.5619684355829, 1.5619684355829,
    1.5619684355829, 1.61223528537923, 1.61223528537923, 1.61223528537923
    ), .Dim = c(102L, 1L), "`\`scaled:center\``" = 75.8529411764706,
"`\`scaled:scale\``" = 39.7876534555816)), row.names = c(NA,
-102L), class = "data.frame")

# library
library(glmmTMB)

# model
mod1 <- glmmTMB(sum.50 ~ trtmt_simple + julian + (1|site), data = data,
ziformula=~1, family=nbinom1)
summary(mod1)

mod2 <- glmmTMB(sum.50 ~ trtmt_simple + julian2 + (1|site), data = data,
ziformula=~1, family=nbinom1)
summary(mod2)

Thank you very much in advance for your help!

Cheers,
Rachael

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Tue May  7 23:39:27 2019
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Tue, 7 May 2019 17:39:27 -0400
Subject: [R-sig-ME] Warning message after "unscaling" predictor variable
In-Reply-To: <CAC8Jvgw3hDpMef3vOORnadQRHW2cVQdZ8EpEmF8yf8okySm_kQ@mail.gmail.com>
References: <CAC8Jvgw3hDpMef3vOORnadQRHW2cVQdZ8EpEmF8yf8okySm_kQ@mail.gmail.com>
Message-ID: <4a54c466-eb83-6cae-944b-d4d79b6a6cab@gmail.com>


  Quick answer (1): if you get the same likelihood (or very similar,
e.g. difference < 1e-3) for both models, then it should be safe to
disregard the warning.

  (2) If you want to double-check that you're really getting equivalent
results, you can try unscaling the parameters "by hand": this is covered
in the following StackOverflow questions:

https://stackoverflow.com/questions/23642111/how-to-unscale-the-coefficients-from-an-lmer-model-fitted-with-a-scaled-respon/23643740#23643740

https://stackoverflow.com/questions/24268031/unscale-and-uncenter-glmer-parameters

  It would take a few minutes longer than I have right now to dig in and
see what causes the warning (i.e., what combination of
correlation/difference in parameter scales is actually causing the
problem).  My offhand guess would be that it's the centering, not the
scaling, that's important here, but I could be wrong.


On 2019-05-07 5:17 p.m., Rachael Mady wrote:
> Hello,
> 
> I have been successfully using the glmmTMB package, but have come across a
> Warning today that I cannot solve. The data and the code are provided below
> this posting.
> 
> I have been running mixed models with julian date scaled and centered (such
> that it is a z-score; julian2 in the data). Today, I tried to run the same
> models without julian date scaled and centered and received this warning:
> 
> *Warning message:*
> *In nlminb(start = par, objective = fn, gradient = gr, control =
> control$optCtrl) :*
> *  NA/NaN function evaluation*
> 
> To recreate, see the code below. Mod1 is with julian not scaled/centered
> and mod2 is with julian scaled.
> 
> *The data and code to reproduce situation: *
> 
> data <-
> structure(list(sum.50 = c(2L, 1L, 2L, 0L, 0L, 7L, 0L, 6L, 1L,
> 0L, 3L, 8L, 1L, 0L, 2L, 7L, 0L, 0L, 1L, 3L, 2L, 0L, 8L, 9L, 6L,
> 1L, 8L, 8L, 0L, 5L, 0L, 0L, 5L, 3L, 1L, 5L, 2L, 0L, 0L, 2L, 7L,
> 0L, 0L, 7L, 1L, 0L, 5L, 8L, 5L, 3L, 0L, 4L, 8L, 2L, 7L, 0L, 2L,
> 7L, 0L, 1L, 12L, 5L, 0L, 14L, 0L, 5L, 5L, 2L, 6L, 0L, 3L, 1L,
> 0L, 4L, 5L, 1L, 0L, 3L, 9L, 1L, 13L, 0L, 5L, 7L, 8L, 5L, 0L,
> 9L, 11L, 0L, 0L, 4L, 3L, 0L, 4L, 7L, 7L, 7L, 0L, 1L, 5L, 1L),
>     trtmt_simple = structure(c(3L, 1L, 2L, 3L, 1L, 2L, 1L, 2L,
>     3L, 1L, 2L, 3L, 2L, 3L, 1L, 2L, 3L, 1L, 1L, 2L, 3L, 1L, 2L,
>     3L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 2L, 3L,
>     1L, 2L, 3L, 1L, 1L, 2L, 3L, 1L, 2L, 3L, 2L, 3L, 1L, 2L, 3L,
>     1L, 3L, 1L, 2L, 2L, 3L, 1L, 2L, 3L, 1L, 3L, 1L, 2L, 3L, 1L,
>     2L, 1L, 2L, 3L, 1L, 2L, 3L, 3L, 1L, 2L, 3L, 1L, 2L, 1L, 2L,
>     3L, 2L, 3L, 1L, 2L, 3L, 1L, 1L, 2L, 3L, 1L, 2L, 3L, 2L, 3L,
>     1L, 2L, 3L, 1L), .Label = c("control", "constant", "pulsed"
>     ), class = "factor"), site = structure(c(3L, 4L, 5L, 3L,
>     4L, 5L, 8L, 9L, 6L, 8L, 9L, 6L, 1L, 2L, 7L, 1L, 2L, 7L, 4L,
>     5L, 3L, 4L, 5L, 3L, 6L, 8L, 9L, 6L, 8L, 9L, 2L, 7L, 1L, 2L,
>     7L, 1L, 9L, 6L, 8L, 9L, 6L, 8L, 7L, 1L, 2L, 7L, 1L, 2L, 5L,
>     3L, 4L, 5L, 3L, 4L, 6L, 8L, 9L, 1L, 2L, 7L, 1L, 2L, 7L, 3L,
>     4L, 5L, 3L, 4L, 5L, 8L, 9L, 6L, 8L, 9L, 6L, 2L, 7L, 1L, 2L,
>     7L, 1L, 4L, 5L, 3L, 9L, 6L, 8L, 9L, 6L, 8L, 7L, 1L, 2L, 7L,
>     1L, 2L, 5L, 3L, 4L, 5L, 3L, 4L), .Label = c("bakh", "icel",
>     "lid1", "lid2", "lid3", "mtpl", "nemi", "yb01", "yb02"), class =
> "factor"),
>     julian = c(12L, 12L, 12L, 14L, 14L, 14L, 19L, 19L, 19L, 21L,
>     21L, 21L, 26L, 26L, 26L, 28L, 28L, 28L, 33L, 33L, 33L, 35L,
>     35L, 35L, 40L, 40L, 40L, 42L, 42L, 42L, 47L, 47L, 47L, 49L,
>     49L, 49L, 61L, 61L, 61L, 63L, 63L, 63L, 68L, 68L, 68L, 70L,
>     70L, 70L, 75L, 75L, 75L, 77L, 77L, 77L, 84L, 84L, 84L, 89L,
>     89L, 89L, 91L, 91L, 91L, 96L, 96L, 96L, 98L, 98L, 98L, 103L,
>     103L, 103L, 105L, 105L, 105L, 110L, 110L, 110L, 112L, 112L,
>     112L, 119L, 119L, 119L, 124L, 124L, 124L, 126L, 126L, 126L,
>     131L, 131L, 131L, 133L, 133L, 133L, 138L, 138L, 138L, 140L,
>     140L, 140L), julian2 = structure(c(-1.60484310158565,
> -1.60484310158565,
>     -1.60484310158565, -1.55457625178932, -1.55457625178932,
>     -1.55457625178932, -1.42890912729851, -1.42890912729851,
>     -1.42890912729851, -1.37864227750218, -1.37864227750218,
>     -1.37864227750218, -1.25297515301137, -1.25297515301137,
>     -1.25297515301137, -1.20270830321504, -1.20270830321504,
>     -1.20270830321504, -1.07704117872422, -1.07704117872422,
>     -1.07704117872422, -1.0267743289279, -1.0267743289279,
> -1.0267743289279,
>     -0.901107204437083, -0.901107204437083, -0.901107204437083,
>     -0.850840354640757, -0.850840354640757, -0.850840354640757,
>     -0.725173230149941, -0.725173230149941, -0.725173230149941,
>     -0.674906380353615, -0.674906380353615, -0.674906380353615,
>     -0.373305281575658, -0.373305281575658, -0.373305281575658,
>     -0.323038431779332, -0.323038431779332, -0.323038431779332,
>     -0.197371307288516, -0.197371307288516, -0.197371307288516,
>     -0.14710445749219, -0.14710445749219, -0.14710445749219,
>     -0.0214373330013746, -0.0214373330013746, -0.0214373330013746,
>     0.0288295167949516, 0.0288295167949516, 0.0288295167949516,
>     0.204763491082093, 0.204763491082093, 0.204763491082093,
>     0.330430615572909, 0.330430615572909, 0.330430615572909,
>     0.380697465369235, 0.380697465369235, 0.380697465369235,
>     0.506364589860051, 0.506364589860051, 0.506364589860051,
>     0.556631439656377, 0.556631439656377, 0.556631439656377,
>     0.682298564147192, 0.682298564147192, 0.682298564147192,
>     0.732565413943518, 0.732565413943518, 0.732565413943518,
>     0.858232538434334, 0.858232538434334, 0.858232538434334,
>     0.90849938823066, 0.90849938823066, 0.90849938823066, 1.0844333625178,
>     1.0844333625178, 1.0844333625178, 1.21010048700862, 1.21010048700862,
>     1.21010048700862, 1.26036733680494, 1.26036733680494, 1.26036733680494,
>     1.38603446129576, 1.38603446129576, 1.38603446129576, 1.43630131109209,
>     1.43630131109209, 1.43630131109209, 1.5619684355829, 1.5619684355829,
>     1.5619684355829, 1.61223528537923, 1.61223528537923, 1.61223528537923
>     ), .Dim = c(102L, 1L), "`\`scaled:center\``" = 75.8529411764706,
> "`\`scaled:scale\``" = 39.7876534555816)), row.names = c(NA,
> -102L), class = "data.frame")
> 
> # library
> library(glmmTMB)
> 
> # model
> mod1 <- glmmTMB(sum.50 ~ trtmt_simple + julian + (1|site), data = data,
> ziformula=~1, family=nbinom1)
> summary(mod1)
> 
> mod2 <- glmmTMB(sum.50 ~ trtmt_simple + julian2 + (1|site), data = data,
> ziformula=~1, family=nbinom1)
> summary(mod2)
> 
> Thank you very much in advance for your help!
> 
> Cheers,
> Rachael
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From d@r|zopou|o@ @end|ng |rom er@@mu@mc@n|  Wed May  8 09:35:24 2019
From: d@r|zopou|o@ @end|ng |rom er@@mu@mc@n| (D. Rizopoulos)
Date: Wed, 8 May 2019 07:35:24 +0000
Subject: [R-sig-ME] Warning message after "unscaling" predictor variable
In-Reply-To: <CAC8Jvgw3hDpMef3vOORnadQRHW2cVQdZ8EpEmF8yf8okySm_kQ@mail.gmail.com>
References: <CAC8Jvgw3hDpMef3vOORnadQRHW2cVQdZ8EpEmF8yf8okySm_kQ@mail.gmail.com>
Message-ID: <840afd72-e115-4fc4-7eb1-25179f842058@erasmusmc.nl>

You could also give a try in GLMMadaptive 
(https://drizopoulos.github.io/GLMMadaptive/) that fits the same model 
using the adaptive Gaussian quadrature instead on the Laplace 
approximation. The equivalent code is:

fm <- mixed_model(sum.50 ~ trtmt_simple + julian, random = ~ 1 | site,
                   data = data, family = zi.negative.binomial(),
                   zi_fixed = ~ 1)
summary(fm)

For more examples check here:

https://drizopoulos.github.io/GLMMadaptive/articles/ZeroInflated_and_TwoPart_Models.html

https://drizopoulos.github.io/GLMMadaptive/articles/Goodness_of_Fit.html

Best,
Dimitris



On 5/7/2019 11:17 PM, Rachael Mady wrote:
> Hello,
> 
> I have been successfully using the glmmTMB package, but have come across a
> Warning today that I cannot solve. The data and the code are provided below
> this posting.
> 
> I have been running mixed models with julian date scaled and centered (such
> that it is a z-score; julian2 in the data). Today, I tried to run the same
> models without julian date scaled and centered and received this warning:
> 
> *Warning message:*
> *In nlminb(start = par, objective = fn, gradient = gr, control =
> control$optCtrl) :*
> *  NA/NaN function evaluation*
> 
> To recreate, see the code below. Mod1 is with julian not scaled/centered
> and mod2 is with julian scaled.
> 
> *The data and code to reproduce situation: *
> 
> data <-
> structure(list(sum.50 = c(2L, 1L, 2L, 0L, 0L, 7L, 0L, 6L, 1L,
> 0L, 3L, 8L, 1L, 0L, 2L, 7L, 0L, 0L, 1L, 3L, 2L, 0L, 8L, 9L, 6L,
> 1L, 8L, 8L, 0L, 5L, 0L, 0L, 5L, 3L, 1L, 5L, 2L, 0L, 0L, 2L, 7L,
> 0L, 0L, 7L, 1L, 0L, 5L, 8L, 5L, 3L, 0L, 4L, 8L, 2L, 7L, 0L, 2L,
> 7L, 0L, 1L, 12L, 5L, 0L, 14L, 0L, 5L, 5L, 2L, 6L, 0L, 3L, 1L,
> 0L, 4L, 5L, 1L, 0L, 3L, 9L, 1L, 13L, 0L, 5L, 7L, 8L, 5L, 0L,
> 9L, 11L, 0L, 0L, 4L, 3L, 0L, 4L, 7L, 7L, 7L, 0L, 1L, 5L, 1L),
>      trtmt_simple = structure(c(3L, 1L, 2L, 3L, 1L, 2L, 1L, 2L,
>      3L, 1L, 2L, 3L, 2L, 3L, 1L, 2L, 3L, 1L, 1L, 2L, 3L, 1L, 2L,
>      3L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 2L, 3L,
>      1L, 2L, 3L, 1L, 1L, 2L, 3L, 1L, 2L, 3L, 2L, 3L, 1L, 2L, 3L,
>      1L, 3L, 1L, 2L, 2L, 3L, 1L, 2L, 3L, 1L, 3L, 1L, 2L, 3L, 1L,
>      2L, 1L, 2L, 3L, 1L, 2L, 3L, 3L, 1L, 2L, 3L, 1L, 2L, 1L, 2L,
>      3L, 2L, 3L, 1L, 2L, 3L, 1L, 1L, 2L, 3L, 1L, 2L, 3L, 2L, 3L,
>      1L, 2L, 3L, 1L), .Label = c("control", "constant", "pulsed"
>      ), class = "factor"), site = structure(c(3L, 4L, 5L, 3L,
>      4L, 5L, 8L, 9L, 6L, 8L, 9L, 6L, 1L, 2L, 7L, 1L, 2L, 7L, 4L,
>      5L, 3L, 4L, 5L, 3L, 6L, 8L, 9L, 6L, 8L, 9L, 2L, 7L, 1L, 2L,
>      7L, 1L, 9L, 6L, 8L, 9L, 6L, 8L, 7L, 1L, 2L, 7L, 1L, 2L, 5L,
>      3L, 4L, 5L, 3L, 4L, 6L, 8L, 9L, 1L, 2L, 7L, 1L, 2L, 7L, 3L,
>      4L, 5L, 3L, 4L, 5L, 8L, 9L, 6L, 8L, 9L, 6L, 2L, 7L, 1L, 2L,
>      7L, 1L, 4L, 5L, 3L, 9L, 6L, 8L, 9L, 6L, 8L, 7L, 1L, 2L, 7L,
>      1L, 2L, 5L, 3L, 4L, 5L, 3L, 4L), .Label = c("bakh", "icel",
>      "lid1", "lid2", "lid3", "mtpl", "nemi", "yb01", "yb02"), class =
> "factor"),
>      julian = c(12L, 12L, 12L, 14L, 14L, 14L, 19L, 19L, 19L, 21L,
>      21L, 21L, 26L, 26L, 26L, 28L, 28L, 28L, 33L, 33L, 33L, 35L,
>      35L, 35L, 40L, 40L, 40L, 42L, 42L, 42L, 47L, 47L, 47L, 49L,
>      49L, 49L, 61L, 61L, 61L, 63L, 63L, 63L, 68L, 68L, 68L, 70L,
>      70L, 70L, 75L, 75L, 75L, 77L, 77L, 77L, 84L, 84L, 84L, 89L,
>      89L, 89L, 91L, 91L, 91L, 96L, 96L, 96L, 98L, 98L, 98L, 103L,
>      103L, 103L, 105L, 105L, 105L, 110L, 110L, 110L, 112L, 112L,
>      112L, 119L, 119L, 119L, 124L, 124L, 124L, 126L, 126L, 126L,
>      131L, 131L, 131L, 133L, 133L, 133L, 138L, 138L, 138L, 140L,
>      140L, 140L), julian2 = structure(c(-1.60484310158565,
> -1.60484310158565,
>      -1.60484310158565, -1.55457625178932, -1.55457625178932,
>      -1.55457625178932, -1.42890912729851, -1.42890912729851,
>      -1.42890912729851, -1.37864227750218, -1.37864227750218,
>      -1.37864227750218, -1.25297515301137, -1.25297515301137,
>      -1.25297515301137, -1.20270830321504, -1.20270830321504,
>      -1.20270830321504, -1.07704117872422, -1.07704117872422,
>      -1.07704117872422, -1.0267743289279, -1.0267743289279,
> -1.0267743289279,
>      -0.901107204437083, -0.901107204437083, -0.901107204437083,
>      -0.850840354640757, -0.850840354640757, -0.850840354640757,
>      -0.725173230149941, -0.725173230149941, -0.725173230149941,
>      -0.674906380353615, -0.674906380353615, -0.674906380353615,
>      -0.373305281575658, -0.373305281575658, -0.373305281575658,
>      -0.323038431779332, -0.323038431779332, -0.323038431779332,
>      -0.197371307288516, -0.197371307288516, -0.197371307288516,
>      -0.14710445749219, -0.14710445749219, -0.14710445749219,
>      -0.0214373330013746, -0.0214373330013746, -0.0214373330013746,
>      0.0288295167949516, 0.0288295167949516, 0.0288295167949516,
>      0.204763491082093, 0.204763491082093, 0.204763491082093,
>      0.330430615572909, 0.330430615572909, 0.330430615572909,
>      0.380697465369235, 0.380697465369235, 0.380697465369235,
>      0.506364589860051, 0.506364589860051, 0.506364589860051,
>      0.556631439656377, 0.556631439656377, 0.556631439656377,
>      0.682298564147192, 0.682298564147192, 0.682298564147192,
>      0.732565413943518, 0.732565413943518, 0.732565413943518,
>      0.858232538434334, 0.858232538434334, 0.858232538434334,
>      0.90849938823066, 0.90849938823066, 0.90849938823066, 1.0844333625178,
>      1.0844333625178, 1.0844333625178, 1.21010048700862, 1.21010048700862,
>      1.21010048700862, 1.26036733680494, 1.26036733680494, 1.26036733680494,
>      1.38603446129576, 1.38603446129576, 1.38603446129576, 1.43630131109209,
>      1.43630131109209, 1.43630131109209, 1.5619684355829, 1.5619684355829,
>      1.5619684355829, 1.61223528537923, 1.61223528537923, 1.61223528537923
>      ), .Dim = c(102L, 1L), "`\`scaled:center\``" = 75.8529411764706,
> "`\`scaled:scale\``" = 39.7876534555816)), row.names = c(NA,
> -102L), class = "data.frame")
> 
> # library
> library(glmmTMB)
> 
> # model
> mod1 <- glmmTMB(sum.50 ~ trtmt_simple + julian + (1|site), data = data,
> ziformula=~1, family=nbinom1)
> summary(mod1)
> 
> mod2 <- glmmTMB(sum.50 ~ trtmt_simple + julian2 + (1|site), data = data,
> ziformula=~1, family=nbinom1)
> summary(mod2)
> 
> Thank you very much in advance for your help!
> 
> Cheers,
> Rachael
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=02%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C91bb409ad91f4855ce9708d6d33177d3%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C0%7C636928606752416375&amp;sdata=VsIzaPmGoNpEOQ23%2FYVhrVyMDL8SV3oJZYdwvT%2BB%2Faw%3D&amp;reserved=0
> 

-- 
Dimitris Rizopoulos
Professor of Biostatistics
Department of Biostatistics
Erasmus University Medical Center

Address: PO Box 2040, 3000 CA Rotterdam, the Netherlands
Tel: +31/(0)10/7043478
Fax: +31/(0)10/7043014
Web (personal): http://www.drizopoulos.com/
Web (work): http://www.erasmusmc.nl/biostatistiek/
Blog: http://iprogn.blogspot.nl/

From @ndre@p@rd@|@@ouz@ @end|ng |rom gm@||@com  Wed May  8 10:53:30 2019
From: @ndre@p@rd@|@@ouz@ @end|ng |rom gm@||@com (=?UTF-8?Q?Andr=C3=A9_Pardal?=)
Date: Wed, 8 May 2019 09:53:30 +0100
Subject: [R-sig-ME] Doubts on zero-inflated model (glmmTMB)
Message-ID: <CAFxBq7yX1_O-7E38dqdM+hMat=tebV6eXBwfnnYGjuCwgMdBcA@mail.gmail.com>

Hello,

I am trying to run mixed effect zero-inflated models in order to
investigate spatial variability in density of a intertidal barnacle and
effect of environmental variables.

First, I am trying to determinate the best random model. I have 3 scales of
variability: *region* (2 levels), *sub-regions* (3 levels nested in each
region = 6) and *locations* (number of levels *unbalanced* nested in each
sub-region and region, total = 62). I am using negative binomial family
(nbinom1: best fit than other possibilities).

After selecting such model, I intend to compare it with most parsimonious
mixed model considering random effects plus the effect of a specific
predictor.

For example:
Best random model: density ~ subregion + location
Best mixed model:   density ~ temperature + subregion + location

My doubts are:

1) Following recommended approaches for regular GLMM's, should I use REML
instead of ML for estimation of parameters?

2) For making models comparable, how should I set zero-inflation component?
I am using ziformula = 1. Is that the best approach? When I try to consider
all terms in zero-inflation component (ziformula = ~.) it usually leads to
errors. Overparameterisation I guess.

3) Once I have my best random and mixed models, should I refit them using
ML method and then compare them (as recommended for regular GLMM's)?

4) (Finally) How to validate model? I am trying to use DHARMa package for
checking simulated residuals vs fitted values, but it doesn't work well for
models with strong random effects (my case).

Thank you so very much.

My best,

Andre.

-- 
Visiting PhD student
School of Ocean Sciences
Bangor University
Menai Bridge, Anglesey, UK

	[[alternative HTML version deleted]]


From j|ox @end|ng |rom mcm@@ter@c@  Wed May  8 18:04:31 2019
From: j|ox @end|ng |rom mcm@@ter@c@ (Fox, John)
Date: Wed, 8 May 2019 16:04:31 +0000
Subject: [R-sig-ME] A consultation about DF of the result of lmer
In-Reply-To: <31054bb8.11301.16a961405ba.Coremail.18754808835@163.com>
References: <70f1b859.675a.16a8ab261f0.Coremail.18754808835@163.com>
 <15858_1557246694_x47GVXNA004405_8b3d3fe4-ab47-ea83-e2c2-ffc1d77f0488@gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC836BA4B38@FHSDB2D11-2.csu.mcmaster.ca>
 <31054bb8.11301.16a961405ba.Coremail.18754808835@163.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC836BA6596@FHSDB2D11-2.csu.mcmaster.ca>

Dear Rumeng He,

First, when you ask a question on the R-sig-ME list, it's polite to copy further messages to the list, as I've done with this response to your latest message.

Second, you don't say what model you fit to the sleepstudy data, so I'll answer by ESP:

Here I fit two models with lmer() to the sleepstudy data, one treating Days as a numeric predictor and one as a factor. You'll see that I get 1 df for the term in the first case and 9 in the second, as one would expect, which is what Ben Bolker and I both suggested:

--------------- snip ------------------

> library(car)
Loading required package: carData
> library(lme4)
Loading required package: Matrix
Registered S3 methods overwritten by 'lme4':
  method                          from
  cooks.distance.influence.merMod car 
  influence.merMod                car 
  dfbeta.influence.merMod         car 
  dfbetas.influence.merMod        car 

> # example from ?lmer
> (fm1 <- lmer(Reaction ~ Days + (Days | Subject), sleepstudy))
Linear mixed model fit by REML ['lmerMod']
Formula: Reaction ~ Days + (Days | Subject)
   Data: sleepstudy
REML criterion at convergence: 1743.628
Random effects:
 Groups   Name        Std.Dev. Corr
 Subject  (Intercept) 24.737       
          Days         5.923   0.07
 Residual             25.592       
Number of obs: 180, groups:  Subject, 18
Fixed Effects:
(Intercept)         Days  
     251.41        10.47  

> Anova(fm1)
Analysis of Deviance Table (Type II Wald chisquare tests)

Response: Reaction
      Chisq Df Pr(>Chisq)    
Days 45.843  1  1.281e-11 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

> # making Days a factor
> sleepstudy$DaysF <- as.factor(sleepstudy$Days)
> levels(sleepstudy$DaysF)
 [1] "0" "1" "2" "3" "4" "5" "6" "7" "8" "9"

> # can only fit random-intercept model
> (fm1F <- lmer(Reaction ~ DaysF + (1 | Subject), sleepstudy))
Linear mixed model fit by REML ['lmerMod']
Formula: Reaction ~ DaysF + (1 | Subject)
   Data: sleepstudy
REML criterion at convergence: 1729.493
Random effects:
 Groups   Name        Std.Dev.
 Subject  (Intercept) 37.09   
 Residual             31.43   
Number of obs: 180, groups:  Subject, 18
Fixed Effects:
(Intercept)       DaysF1       DaysF2       DaysF3       DaysF4       DaysF5       DaysF6       DaysF7       DaysF8       DaysF9  
    256.652        7.844        8.710       26.340       31.998       51.867       55.526       62.099       79.978       94.199  

> Anova(fm1F)
Analysis of Deviance Table (Type II Wald chisquare tests)

Response: Reaction
       Chisq Df Pr(>Chisq)    
DaysF 168.32  9  < 2.2e-16 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

> Anova(fm1F, test.statistic="F")
Analysis of Deviance Table (Type II Wald F tests with Kenward-Roger df)

Response: Reaction
           F Df Df.res    Pr(>F)    
DaysF 18.703  9    153 < 2.2e-16 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

--------------------- snip ---------------

So what's the problem?

John

> -----Original Message-----
> From: ??? [mailto:18754808835 at 163.com]
> Sent: Wednesday, May 8, 2019 2:14 AM
> To: Fox, John <jfox at mcmaster.ca>
> Subject: Re:RE: [R-sig-ME] A consultation about DF of the result of lmer
> 
> Dear John,
> Thanks for your reply. I  tried to translate random effect as factors
> but it didn't work. (The dataset of sleepstudy is in R)
> 
> 
> Then I also made analyse of "aov". The Df is right. So I think there
> would be other reasons for this wrong.
> 
> I also found other pepole met the same question (as the follow website)
> but for too many years ago.  I want to know whethere I can correct
> https://stat.ethz.ch/pipermail/r-help/2008-October/176084.html
> 
> 
> At 2019-05-08 01:49:39, "Fox, John" <jfox at mcmaster.ca> wrote:
> >Dear Rumeng He,
> >
> >For what it's worth, my guess is the same as Ben's. If we're wrong,
> then you'll have to send more information about what you did, ideally
> including a reproducible example of the problem.
> >
> >Best,
> > John
> >
> >--------------------------------------
> >John Fox, Professor Emeritus
> >McMaster University
> >Hamilton, Ontario, Canada
> >Web: socialsciences.mcmaster.ca/jfox/
> >
> >
> >
> >> -----Original Message-----
> >> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-
> >> project.org] On Behalf Of Ben Bolker
> >> Sent: Tuesday, May 7, 2019 12:31 PM
> >> To: r-sig-mixed-models at r-project.org
> >> Subject: Re: [R-sig-ME] A consultation about DF of the result of lmer
> >>
> >>    It's very hard to say without more information (try e.g. here
> >> <https://stackoverflow.com/questions/5963269/how-to-make-a-great-r-
> >> reproducible-example>
> >> or look at other posts in the list archive
> >> <https://stat.ethz.ch/pipermail/r-sig-mixed-models/>
> >>
> >>   A first guess is that you have a fixed-effect predictor that's
> >> supposed to be a factor with 6 levels, but is actually being
> >> interpreted as a numeric variable.  If that's the case, then either
> >> changing it within the data set
> >>
> >>   mydata$pred1 <- factor(mydata$pred1)
> >>
> >> or doing it on the fly in your  model
> >>
> >>   lmer(response ~ factor(pred1) + ...)
> >>
> >> should fix the problem.
> >>
> >>
> >> On 2019-05-05 9:11 p.m., ??? wrote:
> >> > Dear,
> >> > I am a graduated student who's topic is  ecology. Recently, I am
> >> studying how to establish a liner mixed model to exclude the error
> >> caused by the difference of site by using lme4 in R. I found  when I
> >> calculated p value by using the function of "Anova" of car package
> >> the Df is 1. But in fact the data set has 6 levels. Then I also
> >> operate according to the code of reference PDF of lme4 in P52(lmer)
> >> without any change. When run "anova(fm1, fm2)" I found the Df of fm1
> >> also is 1. As I see if the Df is wrong the p value would be wrong
> >> either. I want to know how to correct my wrong. I will very
> appreciate your reply.
> >> >
> >> >
> >> > Best regards,
> >> > Rumeng He
> >> > 	[[alternative HTML version deleted]]
> >> >
> >> > _______________________________________________
> >> > R-sig-mixed-models at r-project.org mailing list
> >> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >> >
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
> 
> 


From j|ox @end|ng |rom mcm@@ter@c@  Thu May  9 14:46:27 2019
From: j|ox @end|ng |rom mcm@@ter@c@ (Fox, John)
Date: Thu, 9 May 2019 12:46:27 +0000
Subject: [R-sig-ME] A consultation about DF of the result of lmer
In-Reply-To: <cc4417b.14aa6.16a9b8d8f17.Coremail.18754808835@163.com>
References: <70f1b859.675a.16a8ab261f0.Coremail.18754808835@163.com>
 <15858_1557246694_x47GVXNA004405_8b3d3fe4-ab47-ea83-e2c2-ffc1d77f0488@gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC836BA4B38@FHSDB2D11-2.csu.mcmaster.ca>
 <31054bb8.11301.16a961405ba.Coremail.18754808835@163.com>
 <ACD1644AA6C67E4FBD0C350625508EC836BA6596@FHSDB2D11-2.csu.mcmaster.ca>
 <cc4417b.14aa6.16a9b8d8f17.Coremail.18754808835@163.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC836BA7E38@FHSDB2D11-2.csu.mcmaster.ca>

Dear Rumeng He,

I'm glad that you were able to solve your problem. 

In future, please always copy your responses to the list, as I've done with this response, rather than sending a personal email to someone like me. Otherwise, people following the email thread won't know what the resolution was, and might think, in this case, than Anova() and anova() calculate df incorrectly.

Best,
 John

> -----Original Message-----
> From: ??? [mailto:18754808835 at 163.com]
> Sent: Thursday, May 9, 2019 3:45 AM
> To: Fox, John <jfox at mcmaster.ca>
> Subject: Re:RE: Re:RE: [R-sig-ME] A consultation about DF of the result of lmer
> 
> Dear John,
>     Thanks for your reply. when I saw your example, I learned why I did wrong
> (In my experiment the individuals in different plots (in different stand density)
> suffer from different competition intensity. I hope to analyse the relationship
> between competition index and trees response to drought while exclude the
> impact of difference among plots characteristic. So I set the ID of plot as
> random effect and translate it to factors not competition index. Thus I did
> wrong. And when I used the dataset of sleepstudy making an example, I also
> did the same error.). Thank you very much.
> 
> Best regards,
> Rumeng He
> 
> 
> 
> 
> 


From doongc|e23 @end|ng |rom gm@||@com  Thu May  9 10:14:04 2019
From: doongc|e23 @end|ng |rom gm@||@com (Suna Park)
Date: Thu, 9 May 2019 17:14:04 +0900
Subject: [R-sig-ME] Extract individual likelihood from glmmTMB
Message-ID: <CANZfssyPua39rU7QuXe-a5rVtp76GgrqrtbryOiJQ9wg0DLRKQ@mail.gmail.com>

Dear R-sig-mixed-models members,

Hello, this is Suna.

I'm studying the use of medical care for the elderly using zero-inflated
Poisson and negative binomial mixed model with random intercept.

And I'm considering how to extract the individual likelihood from the
glmmTMB for Vuong(1989)'s test.

Looking at the source code of the glmmTMB, it seems that the likelihood
function is in the 'glmmTMB.dll'.

But I can't open and see the function in the 'glmmTMB.dll'.

Could you let me know about how to modify the likelihood function or
extract individual likelihood?

Thank you,

Suna Park


*Suna Park*
College of Economics & Finance, Hanyang University,

	[[alternative HTML version deleted]]


From m|ch@e|@w||||@m@on @end|ng |rom kc|@@c@uk  Thu May  9 17:13:28 2019
From: m|ch@e|@w||||@m@on @end|ng |rom kc|@@c@uk (Williamson, Michael)
Date: Thu, 9 May 2019 15:13:28 +0000
Subject: [R-sig-ME] Collinearity tests (e.g. VIF) for glmmTMB package
Message-ID: <DB7PR03MB4555314A110F206CE6E18603C2330@DB7PR03MB4555.eurprd03.prod.outlook.com>

Good Afternoon,

I've been running a few generalised linear mixed models on my data. Due to convergence issues, down to the size of the data set, I was recommended to switch to the glmmTMB package from the glmer function in lme4.. The models are running much better now with no more convergence issues.

I'm looking to test the collinearity of my models, but the VIF function in the car package does not work with the glmmTMB package. Does anyone know of any packages or functions that can be used to calculate collinearity from model outputs generated by glmmTMB?

Many thanks,

Mike Williamson

Email: michael.williamson at kcl.ac.uk<mailto:michael.williamson at kcl.ac.uk>




	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Thu May  9 19:33:17 2019
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Thu, 9 May 2019 13:33:17 -0400
Subject: [R-sig-ME] Extract individual likelihood from glmmTMB
In-Reply-To: <CANZfssyPua39rU7QuXe-a5rVtp76GgrqrtbryOiJQ9wg0DLRKQ@mail.gmail.com>
References: <CANZfssyPua39rU7QuXe-a5rVtp76GgrqrtbryOiJQ9wg0DLRKQ@mail.gmail.com>
Message-ID: <de1857f2-8a31-5923-0818-9174e58b2cd0@gmail.com>


  By "individual likelihood" do you mean you want the log-likelihood of
a particular model?  logLik(fitted_model) should do it. (This is  a
generic method that should work for most model types in R, although you
do have to be a bit careful in comparing log-likelihood values across
models from different packages as they may make different choices about
which constant terms to include/exclude.)

  If you want something else, please clarify ...

  cheers
    Ben Bolker

On 2019-05-09 4:14 a.m., Suna Park wrote:
> Dear R-sig-mixed-models members,
> 
> Hello, this is Suna.
> 
> I'm studying the use of medical care for the elderly using zero-inflated
> Poisson and negative binomial mixed model with random intercept.
> 
> And I'm considering how to extract the individual likelihood from the
> glmmTMB for Vuong(1989)'s test.
> 
> Looking at the source code of the glmmTMB, it seems that the likelihood
> function is in the 'glmmTMB.dll'.
> 
> But I can't open and see the function in the 'glmmTMB.dll'.
> 
> Could you let me know about how to modify the likelihood function or
> extract individual likelihood?
> 
> Thank you,
> 
> Suna Park
> 
> 
> *Suna Park*
> College of Economics & Finance, Hanyang University,
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From chr|@ho|d @end|ng |rom p@yctc@org  Thu May  9 20:25:45 2019
From: chr|@ho|d @end|ng |rom p@yctc@org (Chris Evans)
Date: Thu, 9 May 2019 19:25:45 +0100 (BST)
Subject: [R-sig-ME] First post: binomial model for omission of items of
 questionnaire, and advice on reading
Message-ID: <428321569.33058.1557426345212.JavaMail.zimbra@psyctc.org>

I've followed this list for some years now and learned much about analyses of mixed models from it but I'm pretty sure this is my first post and I suspect it's embarrassingly obvious and that leads to its second part: advice on reading. 

The immediate question is about testing whether participants omitting an item of a questionnaire relates to the cueing, negative or positive of the item. The data look like this: 

> head(longDat[,c(7,3,4,6)]) 
ID itemN positive missed 
1 1 1 FALSE 1 
2 2 1 FALSE 0 
3 3 1 FALSE 0 
4 4 1 FALSE 0 
5 5 1 FALSE 1 
6 6 1 FALSE 0 

"itemN" is a factor as at the moment I'm not testing any order effect through completion of the questionnaire. The variable "positive" is the cueing and "missed" is whether the item was omitted by the participant or not. 

I think a reasonable model is that people vary in a general willingness to omit items and that there might in addition to that random variance, be an effect of cueing, probably that negatively cued items are less likely to be omitted but I wouldn't want a directional test. As it happens in this questionnaire there are 10 items, three positively cued and seven negatively cued. I've simulated data so the ten items have rather different omission rates and the cueing has an effect on top of those. 

I analysed my data with: 

> res3 <- glmer(missed ~ positive + (1 | ID), family = binomial, data = longDat) 
> res3 
Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) ['glmerMod'] 
Family: binomial ( logit ) 
Formula: missed ~ positive + (1 | ID) 
Data: longDat 
AIC BIC logLik deviance df.resid 
12597.534 12619.165 -6295.767 12591.534 9997 
Random effects: 
Groups Name Std.Dev. 
ID (Intercept) 1.056 
Number of obs: 10000, groups: ID, 1000 
Fixed Effects: 
(Intercept) positiveTRUE 
0.6102 -0.7833 
> se <- sqrt(diag(vcov(res1))) 
> (tab <- cbind(Est = fixef(res3), LL = fixef(res3) - 1.96 * se, UL = fixef(res3) + 1.96 * se)) 
Est LL UL 
(Intercept) 0.6101525 0.5330314 0.6872737 
positiveTRUE -0.7832788 -0.8603999 -0.7061576 
> 

That all seems fine and to fit with the parameters that I'd put into simulating the data but I'm sufficiently new to this to want to check with people more experienced than I am if that does seem the right approach. I may have some follow up work where there are more ways to classify the ten items (including order). 

My tangential question is about recommended reading for someone who comes out of medicine through psychotherapy so doesn't really have algebra, let alone matrix algebra and Bayesian theory say, running in my veins. I have many peer-reviewed, empirical, quantitative papers from the last three decades, almost all based on my having to do my own statistical analyses as I've rarely worked anywhere where I've had either money to pay for statistical help or a resident statistician. However, I'm fairly new to multilevel models (as you can see!) but I'm increasingly seeing them as vital to the sorts of data I analyse. Where should I start?! 

TIA, 

Chris 


-- 
Chris Evans <chris at psyctc.org> Skype: chris-psyctc 
Visiting Professor, University of Sheffield <chris.evans at sheffield.ac.uk> 
I do some consultation work for the University of Roehampton <chris.evans at roehampton.ac.uk> and other places but this <chris at psyctc.org> remains my main Email address. 
I have "semigrated" to France, see: https://www.psyctc.org/pelerinage2016/semigrating-to-france/ if you want to book to talk, I am trying to keep that to Thursdays and my diary is now available at: https://www.psyctc.org/pelerinage2016/ecwd_calendar/calendar/ 
Beware: French time, generally an hour ahead of UK. That page will also take you to my blog which started with earlier joys in France and Spain! 

	[[alternative HTML version deleted]]


From j|ox @end|ng |rom mcm@@ter@c@  Thu May  9 21:28:43 2019
From: j|ox @end|ng |rom mcm@@ter@c@ (Fox, John)
Date: Thu, 9 May 2019 19:28:43 +0000
Subject: [R-sig-ME] Collinearity tests (e.g. VIF) for glmmTMB package
In-Reply-To: <9080_1557416206_x49Fajqo025294_DB7PR03MB4555314A110F206CE6E18603C2330@DB7PR03MB4555.eurprd03.prod.outlook.com>
References: <9080_1557416206_x49Fajqo025294_DB7PR03MB4555314A110F206CE6E18603C2330@DB7PR03MB4555.eurprd03.prod.outlook.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC836BA9E2C@FHSDB2D11-2.csu.mcmaster.ca>

Dear Mike,

I'm not sufficiently familiar with the objects produced by glmmTMB() to answer definitively, and I'm also not entirely sure why you want to check for collinearity, but maybe the following would help:

You can used vcov() to return the variances and covariances of coefficients in the various parts of the "glmmTMB" model. For example:

---------------- snip ------------

> library(glmmTMB)
> example("glmmTMB")
> v <- vcov(m3)
> v
Conditional model:
            (Intercept)        sppPR        sppDM       sppEC-A      sppEC-L     sppDES-L       sppDF       minedno
(Intercept)  0.04245503 -0.012754751 -0.013349646 -0.0125136751 -0.013436038 -0.013225977 -0.01391389 -0.0305911919
sppPR       -0.01275475  0.077687602  0.011642383  0.0119168647  0.011903658  0.011843477  0.01185466  0.0013084323
sppDM       -0.01334965  0.011642383  0.020980164  0.0117137251  0.011868129  0.011728938  0.01171587  0.0015986374
sppEC-A     -0.01251368  0.011916865  0.011713725  0.0404883426  0.011904829  0.011680709  0.01185958  0.0009042868
sppEC-L     -0.01343604  0.011903658  0.011868129  0.0119048294  0.017500122  0.011744878  0.01192195  0.0016761527
sppDES-L    -0.01322598  0.011843477  0.011728938  0.0116807092  0.011744878  0.016968986  0.01186668  0.0015556516
sppDF       -0.01391389  0.011854661  0.011715873  0.0118595830  0.011921947  0.011866683  0.02370581  0.0021442905
minedno     -0.03059119  0.001308432  0.001598637  0.0009042868  0.001676153  0.001555652  0.00214429  0.0350573728

Zero-inflation model:
               zi~(Intercept)     zi~sppPR     zi~sppDM   zi~sppEC-A   zi~sppEC-L  zi~sppDES-L     zi~sppDF   zi~minedno
zi~(Intercept)     0.08027669 -0.055011989 -0.064230942 -0.056164325 -0.064230942 -0.066122481 -0.064230942 -0.028881293
zi~sppPR          -0.05501199  0.157151941  0.060172003  0.062766076  0.060172003  0.059563719  0.060172003 -0.009287683
zi~sppDM          -0.06423094  0.060172003  0.122669211  0.060357133  0.061653087  0.061956976  0.061653087  0.004639967
zi~sppEC-A        -0.05616432  0.062766076  0.060357133  0.135723657  0.060357133  0.059862868  0.060357133 -0.007546778
zi~sppEC-L        -0.06423094  0.060172003  0.061653087  0.060357133  0.122669211  0.061956976  0.061653087  0.004639967
zi~sppDES-L       -0.06612248  0.059563719  0.061956976  0.059862868  0.061956976  0.123808814  0.061956976  0.007497634
zi~sppDF          -0.06423094  0.060172003  0.061653087  0.060357133  0.061653087  0.061956976  0.122669211  0.004639967
zi~minedno        -0.02888129 -0.009287683  0.004639967 -0.007546778  0.004639967  0.007497634  0.004639967  0.043632782

---------------- snip ------------

In this case, there are two components to the model -- the conditional model and the zero-inflation model -- and I believe that they are independent, so you should be able to eliminate the intercept from each and compute VIFs for the other coefficients:

---------------- snip ------------

> diag(solve(cov2cor(v[[1]][-1, -1])))
   sppPR    sppDM  sppEC-A  sppEC-L sppDES-L    sppDF  minedno 
1.154418 1.918674 1.340247 2.317812 2.344363 1.767413 1.006961 

> diag(solve(cov2cor(v[[2]][-1, -1])))
   zi~sppPR    zi~sppDM  zi~sppEC-A  zi~sppEC-L zi~sppDES-L    zi~sppDF  zi~minedno 
   1.503986    1.699895    1.614313    1.699895    1.707801    1.699895    1.079338

---------------- snip ------------

Of course, it would be nice to automate this and to compute generalized VIFs for terms with more than one coefficient, but I don't see where to recover the necessary information about the structures of the component models from the "glmmTMB" object.

I'm cc'ing Ben Bolker in case he has something to add (or correct).

I hope this helps,
 John

--------------------------------------
John Fox, Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
Web: socialsciences.mcmaster.ca/jfox/



> -----Original Message-----
> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-
> project.org] On Behalf Of Williamson, Michael via R-sig-mixed-models
> Sent: Thursday, May 9, 2019 11:13 AM
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] Collinearity tests (e.g. VIF) for glmmTMB package
> 
> Good Afternoon,
> 
> I've been running a few generalised linear mixed models on my data. Due
> to convergence issues, down to the size of the data set, I was
> recommended to switch to the glmmTMB package from the glmer function in
> lme4.. The models are running much better now with no more convergence
> issues.
> 
> I'm looking to test the collinearity of my models, but the VIF function
> in the car package does not work with the glmmTMB package. Does anyone
> know of any packages or functions that can be used to calculate
> collinearity from model outputs generated by glmmTMB?
> 
> Many thanks,
> 
> Mike Williamson
> 
> Email: michael.williamson at kcl.ac.uk<mailto:michael.williamson at kcl.ac.uk>
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbo|ker @end|ng |rom gm@||@com  Thu May  9 21:31:21 2019
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Thu, 9 May 2019 15:31:21 -0400
Subject: [R-sig-ME] Collinearity tests (e.g. VIF) for glmmTMB package
In-Reply-To: <ACD1644AA6C67E4FBD0C350625508EC836BA9E2C@FHSDB2D11-2.csu.mcmaster.ca>
References: <9080_1557416206_x49Fajqo025294_DB7PR03MB4555314A110F206CE6E18603C2330@DB7PR03MB4555.eurprd03.prod.outlook.com>
 <ACD1644AA6C67E4FBD0C350625508EC836BA9E2C@FHSDB2D11-2.csu.mcmaster.ca>
Message-ID: <cbe0dbea-871b-fa7d-2596-728bb3e1b079@gmail.com>



  I'm not sure what you else need to know about the component structures?

>  but I don't see where to recover the necessary information about the
structures of the component models from the "glmmTMB" object.

   I've been meaning to write a vif.glmmTMB method, but I was planning
to just add a "component" argument to make the user choose: the names of
the vcov() components are "cond" and "zi" (and there could be a "disp"
component if there's a non-trivial dispersion model ...)




On 2019-05-09 3:28 p.m., Fox, John wrote:
> Dear Mike,
> 
> I'm not sufficiently familiar with the objects produced by glmmTMB() to answer definitively, and I'm also not entirely sure why you want to check for collinearity, but maybe the following would help:
> 
> You can used vcov() to return the variances and covariances of coefficients in the various parts of the "glmmTMB" model. For example:
> 
> ---------------- snip ------------
> 
>> library(glmmTMB)
>> example("glmmTMB")
>> v <- vcov(m3)
>> v
> Conditional model:
>             (Intercept)        sppPR        sppDM       sppEC-A      sppEC-L     sppDES-L       sppDF       minedno
> (Intercept)  0.04245503 -0.012754751 -0.013349646 -0.0125136751 -0.013436038 -0.013225977 -0.01391389 -0.0305911919
> sppPR       -0.01275475  0.077687602  0.011642383  0.0119168647  0.011903658  0.011843477  0.01185466  0.0013084323
> sppDM       -0.01334965  0.011642383  0.020980164  0.0117137251  0.011868129  0.011728938  0.01171587  0.0015986374
> sppEC-A     -0.01251368  0.011916865  0.011713725  0.0404883426  0.011904829  0.011680709  0.01185958  0.0009042868
> sppEC-L     -0.01343604  0.011903658  0.011868129  0.0119048294  0.017500122  0.011744878  0.01192195  0.0016761527
> sppDES-L    -0.01322598  0.011843477  0.011728938  0.0116807092  0.011744878  0.016968986  0.01186668  0.0015556516
> sppDF       -0.01391389  0.011854661  0.011715873  0.0118595830  0.011921947  0.011866683  0.02370581  0.0021442905
> minedno     -0.03059119  0.001308432  0.001598637  0.0009042868  0.001676153  0.001555652  0.00214429  0.0350573728
> 
> Zero-inflation model:
>                zi~(Intercept)     zi~sppPR     zi~sppDM   zi~sppEC-A   zi~sppEC-L  zi~sppDES-L     zi~sppDF   zi~minedno
> zi~(Intercept)     0.08027669 -0.055011989 -0.064230942 -0.056164325 -0.064230942 -0.066122481 -0.064230942 -0.028881293
> zi~sppPR          -0.05501199  0.157151941  0.060172003  0.062766076  0.060172003  0.059563719  0.060172003 -0.009287683
> zi~sppDM          -0.06423094  0.060172003  0.122669211  0.060357133  0.061653087  0.061956976  0.061653087  0.004639967
> zi~sppEC-A        -0.05616432  0.062766076  0.060357133  0.135723657  0.060357133  0.059862868  0.060357133 -0.007546778
> zi~sppEC-L        -0.06423094  0.060172003  0.061653087  0.060357133  0.122669211  0.061956976  0.061653087  0.004639967
> zi~sppDES-L       -0.06612248  0.059563719  0.061956976  0.059862868  0.061956976  0.123808814  0.061956976  0.007497634
> zi~sppDF          -0.06423094  0.060172003  0.061653087  0.060357133  0.061653087  0.061956976  0.122669211  0.004639967
> zi~minedno        -0.02888129 -0.009287683  0.004639967 -0.007546778  0.004639967  0.007497634  0.004639967  0.043632782
> 
> ---------------- snip ------------
> 
> In this case, there are two components to the model -- the conditional model and the zero-inflation model -- and I believe that they are independent, so you should be able to eliminate the intercept from each and compute VIFs for the other coefficients:
> 
> ---------------- snip ------------
> 
>> diag(solve(cov2cor(v[[1]][-1, -1])))
>    sppPR    sppDM  sppEC-A  sppEC-L sppDES-L    sppDF  minedno 
> 1.154418 1.918674 1.340247 2.317812 2.344363 1.767413 1.006961 
> 
>> diag(solve(cov2cor(v[[2]][-1, -1])))
>    zi~sppPR    zi~sppDM  zi~sppEC-A  zi~sppEC-L zi~sppDES-L    zi~sppDF  zi~minedno 
>    1.503986    1.699895    1.614313    1.699895    1.707801    1.699895    1.079338
> 
> ---------------- snip ------------
> 
> Of course, it would be nice to automate this and to compute generalized VIFs for terms with more than one coefficient, but I don't see where to recover the necessary information about the structures of the component models from the "glmmTMB" object.
> 
> I'm cc'ing Ben Bolker in case he has something to add (or correct).
> 
> I hope this helps,
>  John
> 
> --------------------------------------
> John Fox, Professor Emeritus
> McMaster University
> Hamilton, Ontario, Canada
> Web: socialsciences.mcmaster.ca/jfox/
> 
> 
> 
>> -----Original Message-----
>> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-
>> project.org] On Behalf Of Williamson, Michael via R-sig-mixed-models
>> Sent: Thursday, May 9, 2019 11:13 AM
>> To: r-sig-mixed-models at r-project.org
>> Subject: [R-sig-ME] Collinearity tests (e.g. VIF) for glmmTMB package
>>
>> Good Afternoon,
>>
>> I've been running a few generalised linear mixed models on my data. Due
>> to convergence issues, down to the size of the data set, I was
>> recommended to switch to the glmmTMB package from the glmer function in
>> lme4.. The models are running much better now with no more convergence
>> issues.
>>
>> I'm looking to test the collinearity of my models, but the VIF function
>> in the car package does not work with the glmmTMB package. Does anyone
>> know of any packages or functions that can be used to calculate
>> collinearity from model outputs generated by glmmTMB?
>>
>> Many thanks,
>>
>> Mike Williamson
>>
>> Email: michael.williamson at kcl.ac.uk<mailto:michael.williamson at kcl.ac.uk>
>>
>>
>>
>>
>> 	[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From j|ox @end|ng |rom mcm@@ter@c@  Fri May 10 00:30:37 2019
From: j|ox @end|ng |rom mcm@@ter@c@ (Fox, John)
Date: Thu, 9 May 2019 22:30:37 +0000
Subject: [R-sig-ME] Collinearity tests (e.g. VIF) for glmmTMB package
In-Reply-To: <cbe0dbea-871b-fa7d-2596-728bb3e1b079@gmail.com>
References: <9080_1557416206_x49Fajqo025294_DB7PR03MB4555314A110F206CE6E18603C2330@DB7PR03MB4555.eurprd03.prod.outlook.com>
 <ACD1644AA6C67E4FBD0C350625508EC836BA9E2C@FHSDB2D11-2.csu.mcmaster.ca>
 <cbe0dbea-871b-fa7d-2596-728bb3e1b079@gmail.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC836BAA115@FHSDB2D11-2.csu.mcmaster.ca>

Hi Ben,

Take a look at the vif.merMod() method from the car package:

> car:::vif.merMod
function(mod, ...) {
  if (any(is.na(fixef(mod)))) 
    stop ("there are aliased coefficients in the model")
  v <- as.matrix(vcov(mod))
  assign <- attr(model.matrix(mod), "assign")
  if (names(fixef(mod)[1]) == "(Intercept)") {
    v <- v[-1, -1]
    assign <- assign[-1]
  }
  else warning("No intercept: vifs may not be sensible.")
  terms <- labels(terms(mod))
  n.terms <- length(terms)
  if (n.terms < 2) stop("model contains fewer than 2 terms")
  R <- cov2cor(v)
  detR <- det(R)
  result <- matrix(0, n.terms, 3)
  rownames(result) <- terms
  colnames(result) <- c("GVIF", "Df", "GVIF^(1/(2*Df))")
  for (term in 1:n.terms) {
    subs <- which(assign == term)
    result[term, 1] <- det(as.matrix(R[subs, subs])) *
      det(as.matrix(R[-subs, -subs])) / detR
    result[term, 2] <- length(subs)
  }
  if (all(result[, 2] == 1)) result <- result[, 1]
  else result[, 3] <- result[, 1]^(1/(2 * result[, 2]))
  result
}

So for each model component, I'd need the "assign" attribute from the model matrix. My relatively cursory examination of objects produced by glmmTMB() didn't turn up whether (or where) this information is stored.

I agree that for glmmTMB() VIFs could be computed componentwise, with the user specifying which component(s) and perhaps a default of "all". 

Best,
 John

> -----Original Message-----
> From: Ben Bolker [mailto:bbolker at gmail.com]
> Sent: Thursday, May 9, 2019 3:31 PM
> To: Fox, John <jfox at mcmaster.ca>; Williamson, Michael
> <michael.williamson at kcl.ac.uk>
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: Collinearity tests (e.g. VIF) for glmmTMB package
> 
> 
> 
>   I'm not sure what you else need to know about the component
> structures?
> 
> >  but I don't see where to recover the necessary information about the
> structures of the component models from the "glmmTMB" object.
> 
>    I've been meaning to write a vif.glmmTMB method, but I was planning
> to just add a "component" argument to make the user choose: the names of
> the vcov() components are "cond" and "zi" (and there could be a "disp"
> component if there's a non-trivial dispersion model ...)
> 
> 
> 
> 
> On 2019-05-09 3:28 p.m., Fox, John wrote:
> > Dear Mike,
> >
> > I'm not sufficiently familiar with the objects produced by glmmTMB()
> to answer definitively, and I'm also not entirely sure why you want to
> check for collinearity, but maybe the following would help:
> >
> > You can used vcov() to return the variances and covariances of
> coefficients in the various parts of the "glmmTMB" model. For example:
> >
> > ---------------- snip ------------
> >
> >> library(glmmTMB)
> >> example("glmmTMB")
> >> v <- vcov(m3)
> >> v
> > Conditional model:
> >             (Intercept)        sppPR        sppDM       sppEC-A
> sppEC-L     sppDES-L       sppDF       minedno
> > (Intercept)  0.04245503 -0.012754751 -0.013349646 -0.0125136751 -
> 0.013436038 -0.013225977 -0.01391389 -0.0305911919
> > sppPR       -0.01275475  0.077687602  0.011642383  0.0119168647
> 0.011903658  0.011843477  0.01185466  0.0013084323
> > sppDM       -0.01334965  0.011642383  0.020980164  0.0117137251
> 0.011868129  0.011728938  0.01171587  0.0015986374
> > sppEC-A     -0.01251368  0.011916865  0.011713725  0.0404883426
> 0.011904829  0.011680709  0.01185958  0.0009042868
> > sppEC-L     -0.01343604  0.011903658  0.011868129  0.0119048294
> 0.017500122  0.011744878  0.01192195  0.0016761527
> > sppDES-L    -0.01322598  0.011843477  0.011728938  0.0116807092
> 0.011744878  0.016968986  0.01186668  0.0015556516
> > sppDF       -0.01391389  0.011854661  0.011715873  0.0118595830
> 0.011921947  0.011866683  0.02370581  0.0021442905
> > minedno     -0.03059119  0.001308432  0.001598637  0.0009042868
> 0.001676153  0.001555652  0.00214429  0.0350573728
> >
> > Zero-inflation model:
> >                zi~(Intercept)     zi~sppPR     zi~sppDM   zi~sppEC-A
> zi~sppEC-L  zi~sppDES-L     zi~sppDF   zi~minedno
> > zi~(Intercept)     0.08027669 -0.055011989 -0.064230942 -0.056164325 -
> 0.064230942 -0.066122481 -0.064230942 -0.028881293
> > zi~sppPR          -0.05501199  0.157151941  0.060172003  0.062766076
> 0.060172003  0.059563719  0.060172003 -0.009287683
> > zi~sppDM          -0.06423094  0.060172003  0.122669211  0.060357133
> 0.061653087  0.061956976  0.061653087  0.004639967
> > zi~sppEC-A        -0.05616432  0.062766076  0.060357133  0.135723657
> 0.060357133  0.059862868  0.060357133 -0.007546778
> > zi~sppEC-L        -0.06423094  0.060172003  0.061653087  0.060357133
> 0.122669211  0.061956976  0.061653087  0.004639967
> > zi~sppDES-L       -0.06612248  0.059563719  0.061956976  0.059862868
> 0.061956976  0.123808814  0.061956976  0.007497634
> > zi~sppDF          -0.06423094  0.060172003  0.061653087  0.060357133
> 0.061653087  0.061956976  0.122669211  0.004639967
> > zi~minedno        -0.02888129 -0.009287683  0.004639967 -0.007546778
> 0.004639967  0.007497634  0.004639967  0.043632782
> >
> > ---------------- snip ------------
> >
> > In this case, there are two components to the model -- the conditional
> model and the zero-inflation model -- and I believe that they are
> independent, so you should be able to eliminate the intercept from each
> and compute VIFs for the other coefficients:
> >
> > ---------------- snip ------------
> >
> >> diag(solve(cov2cor(v[[1]][-1, -1])))
> >    sppPR    sppDM  sppEC-A  sppEC-L sppDES-L    sppDF  minedno
> > 1.154418 1.918674 1.340247 2.317812 2.344363 1.767413 1.006961
> >
> >> diag(solve(cov2cor(v[[2]][-1, -1])))
> >    zi~sppPR    zi~sppDM  zi~sppEC-A  zi~sppEC-L zi~sppDES-L
> zi~sppDF  zi~minedno
> >    1.503986    1.699895    1.614313    1.699895    1.707801
> 1.699895    1.079338
> >
> > ---------------- snip ------------
> >
> > Of course, it would be nice to automate this and to compute
> generalized VIFs for terms with more than one coefficient, but I don't
> see where to recover the necessary information about the structures of
> the component models from the "glmmTMB" object.
> >
> > I'm cc'ing Ben Bolker in case he has something to add (or correct).
> >
> > I hope this helps,
> >  John
> >
> > --------------------------------------
> > John Fox, Professor Emeritus
> > McMaster University
> > Hamilton, Ontario, Canada
> > Web: socialsciences.mcmaster.ca/jfox/
> >
> >
> >
> >> -----Original Message-----
> >> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-
> >> project.org] On Behalf Of Williamson, Michael via R-sig-mixed-models
> >> Sent: Thursday, May 9, 2019 11:13 AM
> >> To: r-sig-mixed-models at r-project.org
> >> Subject: [R-sig-ME] Collinearity tests (e.g. VIF) for glmmTMB package
> >>
> >> Good Afternoon,
> >>
> >> I've been running a few generalised linear mixed models on my data.
> >> Due to convergence issues, down to the size of the data set, I was
> >> recommended to switch to the glmmTMB package from the glmer function
> >> in lme4.. The models are running much better now with no more
> >> convergence issues.
> >>
> >> I'm looking to test the collinearity of my models, but the VIF
> >> function in the car package does not work with the glmmTMB package.
> >> Does anyone know of any packages or functions that can be used to
> >> calculate collinearity from model outputs generated by glmmTMB?
> >>
> >> Many thanks,
> >>
> >> Mike Williamson
> >>
> >> Email:
> >> michael.williamson at kcl.ac.uk<mailto:michael.williamson at kcl.ac.uk>
> >>
> >>
> >>
> >>
> >> 	[[alternative HTML version deleted]]
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

From d@r|zopou|o@ @end|ng |rom er@@mu@mc@n|  Fri May 10 07:14:15 2019
From: d@r|zopou|o@ @end|ng |rom er@@mu@mc@n| (D. Rizopoulos)
Date: Fri, 10 May 2019 05:14:15 +0000
Subject: [R-sig-ME] First post: binomial model for omission of items of
 questionnaire, and advice on reading
In-Reply-To: <428321569.33058.1557426345212.JavaMail.zimbra@psyctc.org>
References: <428321569.33058.1557426345212.JavaMail.zimbra@psyctc.org>
Message-ID: <7191AFC7255B4F49A30707E39BEAD05FDED28C83@EXCH-HE03.erasmusmc.nl>

Hi Chris,

You can have a look at my course notes for Repeated Measurements data; participants of my course have mainly a epidemiological, public health or medical background: http://www.drizopoulos.com/courses/EMC/CE08.pdf

I have also created a shiny app that replicates all analysis in the course: https://github.com/drizopoulos/Repeated_Measurements

In the near future the course will also be available online, using a blended-learning format.

Best,
Dimitris

- - - - - -
Dimitris Rizopoulos
Professor of Biostatistics
Erasmus University Medical Center
The Netherlands

From: Chris Evans <chrishold at psyctc.org<mailto:chrishold at psyctc.org>>
Date: Thursday, 09 May 2019, 8:26 PM
To: r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>>
Subject: [R-sig-ME] First post: binomial model for omission of items of questionnaire, and advice on reading

I've followed this list for some years now and learned much about analyses of mixed models from it but I'm pretty sure this is my first post and I suspect it's embarrassingly obvious and that leads to its second part: advice on reading.

The immediate question is about testing whether participants omitting an item of a questionnaire relates to the cueing, negative or positive of the item. The data look like this:

> head(longDat[,c(7,3,4,6)])
ID itemN positive missed
1 1 1 FALSE 1
2 2 1 FALSE 0
3 3 1 FALSE 0
4 4 1 FALSE 0
5 5 1 FALSE 1
6 6 1 FALSE 0

"itemN" is a factor as at the moment I'm not testing any order effect through completion of the questionnaire. The variable "positive" is the cueing and "missed" is whether the item was omitted by the participant or not.

I think a reasonable model is that people vary in a general willingness to omit items and that there might in addition to that random variance, be an effect of cueing, probably that negatively cued items are less likely to be omitted but I wouldn't want a directional test. As it happens in this questionnaire there are 10 items, three positively cued and seven negatively cued. I've simulated data so the ten items have rather different omission rates and the cueing has an effect on top of those.

I analysed my data with:

> res3 <- glmer(missed ~ positive + (1 | ID), family = binomial, data = longDat)
> res3
Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) ['glmerMod']
Family: binomial ( logit )
Formula: missed ~ positive + (1 | ID)
Data: longDat
AIC BIC logLik deviance df.resid
12597.534 12619.165 -6295.767 12591.534 9997
Random effects:
Groups Name Std.Dev.
ID (Intercept) 1.056
Number of obs: 10000, groups: ID, 1000
Fixed Effects:
(Intercept) positiveTRUE
0.6102 -0.7833
> se <- sqrt(diag(vcov(res1)))
> (tab <- cbind(Est = fixef(res3), LL = fixef(res3) - 1.96 * se, UL = fixef(res3) + 1.96 * se))
Est LL UL
(Intercept) 0.6101525 0.5330314 0.6872737
positiveTRUE -0.7832788 -0.8603999 -0.7061576
>

That all seems fine and to fit with the parameters that I'd put into simulating the data but I'm sufficiently new to this to want to check with people more experienced than I am if that does seem the right approach. I may have some follow up work where there are more ways to classify the ten items (including order).

My tangential question is about recommended reading for someone who comes out of medicine through psychotherapy so doesn't really have algebra, let alone matrix algebra and Bayesian theory say, running in my veins. I have many peer-reviewed, empirical, quantitative papers from the last three decades, almost all based on my having to do my own statistical analyses as I've rarely worked anywhere where I've had either money to pay for statistical help or a resident statistician. However, I'm fairly new to multilevel models (as you can see!) but I'm increasingly seeing them as vital to the sorts of data I analyse. Where should I start?!

TIA,

Chris


--
Chris Evans <chris at psyctc.org> Skype: chris-psyctc
Visiting Professor, University of Sheffield <chris.evans at sheffield.ac.uk>
I do some consultation work for the University of Roehampton <chris.evans at roehampton.ac.uk> and other places but this <chris at psyctc.org> remains my main Email address.
I have "semigrated" to France, see: https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fwww.psyctc.org%2Fpelerinage2016%2Fsemigrating-to-france%2F&amp;data=02%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C5b955bbee7254e48256d08d6d4abcdfd%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C0%7C636930231694193093&amp;sdata=luUc6XwSc6go4c45clYHcawAkXyUpsQwWT3p4QX51yU%3D&amp;reserved=0 if you want to book to talk, I am trying to keep that to Thursdays and my diary is now available at: https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fwww.psyctc.org%2Fpelerinage2016%2Fecwd_calendar%2Fcalendar%2F&amp;data=02%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C5b955bbee7254e48256d08d6d4abcdfd%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C0%7C636930231694193093&amp;sdata=gVRBIgRL2WJo1MZzrxbDXO11ksKccQiWTsWWoAERYZU%3D&amp;reserved=0
Beware: French time, generally an hour ahead of UK. That page will also take you to my blog which started with earlier joys in France and Spain!

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=02%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C5b955bbee7254e48256d08d6d4abcdfd%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C0%7C636930231694193093&amp;sdata=yr8dBnouiCsOS8sjxb78qXq%2Fc8yivKwTZM9wR42Xry0%3D&amp;reserved=0

	[[alternative HTML version deleted]]


From gerr|t@e|chner @end|ng |rom m@th@un|-g|e@@en@de  Fri May 10 13:07:48 2019
From: gerr|t@e|chner @end|ng |rom m@th@un|-g|e@@en@de (Gerrit Eichner)
Date: Fri, 10 May 2019 13:07:48 +0200
Subject: [R-sig-ME] lme4: Error from allFit when applied to lmer model
 fitted with changed control parameters
Message-ID: <6e76be6a-744e-ae97-3dd1-8167d46c2fd3@math.uni-giessen.de>

Dear lme4-experts,

when fitting an lmer model with changed control parameters as in the
following toy example

fm <- lmer(Reaction ~ Days + (Days | Subject), sleepstudy,
            control = lmerControl(optCtrl = list(xtol_abs = 1e-8,
                                                 ftol_abs = 1e-8)))

and then trying to refit the fitted model with all available optimizers
using allFit an error is thrown:

allFit(fm)

bobyqa : Error in do.call(if (isGLMM(m)) glmerControl else lmerControl,
ctrl) : second argument must be a list


The problem originates apparently from the function ffun within allFit
which doesn't seem to properly pass on the already provided control
list.

Does anyone have a work-around for this? I would like to compare all
optimizers with the changed optCtrl setting.

Thanks for any hints.

  Best regards  --  Gerrit

 > sessionInfo()
R version 3.5.3 (2019-03-11)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 10 x64 (build 17763)

Matrix products: default

locale:
[1] LC_COLLATE=German_Germany.1252  LC_CTYPE=German_Germany.1252
[3] LC_MONETARY=German_Germany.1252 LC_NUMERIC=C
[5] LC_TIME=German_Germany.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] dfoptim_2018.2-1 lme4_1.1-21      Matrix_1.2-17

loaded via a namespace (and not attached):
  [1] minqa_1.2.4     MASS_7.3-51.3   compiler_3.5.3  Rcpp_1.0.1
  [5] splines_3.5.3   nlme_3.1-137    grid_3.5.3      nloptr_1.2.1
  [9] boot_1.3-20     lattice_0.20-38


---------------------------------------------------------------------
Dr. Gerrit Eichner                   Mathematical Institute, Room 212
gerrit.eichner at math.uni-giessen.de   Justus-Liebig-University Giessen
Tel: +49-(0)641-99-32104          Arndtstr. 2, 35392 Giessen, Germany
http://www.uni-giessen.de/eichner


From bbo|ker @end|ng |rom gm@||@com  Fri May 10 15:16:55 2019
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Fri, 10 May 2019 09:16:55 -0400
Subject: [R-sig-ME] lme4: Error from allFit when applied to lmer model
 fitted with changed control parameters
In-Reply-To: <6e76be6a-744e-ae97-3dd1-8167d46c2fd3@math.uni-giessen.de>
References: <6e76be6a-744e-ae97-3dd1-8167d46c2fd3@math.uni-giessen.de>
Message-ID: <2d0ae901-2c3d-12f9-8e90-d3d93b7d01af@gmail.com>


  I've posted this as an issue: https://github.com/lme4/lme4/issues/520

  There probably ought to be an `optCtrl` option to `allFit` that would
all optimizer-specific controls ...

On 2019-05-10 7:07 a.m., Gerrit Eichner wrote:
> Dear lme4-experts,
> 
> when fitting an lmer model with changed control parameters as in the
> following toy example
> 
> fm <- lmer(Reaction ~ Days + (Days | Subject), sleepstudy,
> ?????????? control = lmerControl(optCtrl = list(xtol_abs = 1e-8,
> ??????????????????????????????????????????????? ftol_abs = 1e-8)))
> 
> and then trying to refit the fitted model with all available optimizers
> using allFit an error is thrown:
> 
> allFit(fm)
> 
> bobyqa : Error in do.call(if (isGLMM(m)) glmerControl else lmerControl,
> ctrl) : second argument must be a list
> 
> 
> The problem originates apparently from the function ffun within allFit
> which doesn't seem to properly pass on the already provided control
> list.
> 
> Does anyone have a work-around for this? I would like to compare all
> optimizers with the changed optCtrl setting.
> 
> Thanks for any hints.
> 
> ?Best regards? --? Gerrit
> 
>> sessionInfo()
> R version 3.5.3 (2019-03-11)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows 10 x64 (build 17763)
> 
> Matrix products: default
> 
> locale:
> [1] LC_COLLATE=German_Germany.1252? LC_CTYPE=German_Germany.1252
> [3] LC_MONETARY=German_Germany.1252 LC_NUMERIC=C
> [5] LC_TIME=German_Germany.1252
> 
> attached base packages:
> [1] stats???? graphics? grDevices utils???? datasets? methods?? base
> 
> other attached packages:
> [1] dfoptim_2018.2-1 lme4_1.1-21????? Matrix_1.2-17
> 
> loaded via a namespace (and not attached):
> ?[1] minqa_1.2.4???? MASS_7.3-51.3?? compiler_3.5.3? Rcpp_1.0.1
> ?[5] splines_3.5.3?? nlme_3.1-137??? grid_3.5.3????? nloptr_1.2.1
> ?[9] boot_1.3-20???? lattice_0.20-38
> 
> 
> ---------------------------------------------------------------------
> Dr. Gerrit Eichner?????????????????? Mathematical Institute, Room 212
> gerrit.eichner at math.uni-giessen.de?? Justus-Liebig-University Giessen
> Tel: +49-(0)641-99-32104????????? Arndtstr. 2, 35392 Giessen, Germany
> http://www.uni-giessen.de/eichner
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From chr|@ho|d @end|ng |rom p@yctc@org  Fri May 10 18:37:11 2019
From: chr|@ho|d @end|ng |rom p@yctc@org (Chris Evans)
Date: Fri, 10 May 2019 17:37:11 +0100 (BST)
Subject: [R-sig-ME] First post: binomial model for omission of items of
 questionnaire, and advice on reading
In-Reply-To: <DM6PR12MB27323134FA34960ECF576897810C0@DM6PR12MB2732.namprd12.prod.outlook.com>
References: <428321569.33058.1557426345212.JavaMail.zimbra@psyctc.org>
 <DM6PR12MB27323134FA34960ECF576897810C0@DM6PR12MB2732.namprd12.prod.outlook.com>
Message-ID: <198843979.1075539.1557506231884.JavaMail.zimbra@psyctc.org>

Huge thanks to both Steven and Dimitris for these inputs. I managed to scan read pertinent parts of Dimitris's lecture notes this morning and that was already hugely helpful (and your shiny app looked great Dimitris), these too look great pointers. 

Can I be cheeky as I realise a committed a fundamental error in my post by asking two rather different questions. Would any comment on the first part of the question about whether what I was doing looked right, Dimitris's lecture notes suggested to me that it wasn't necessarily wrong and helped me understand that the question could also be tackled using a GEE approach which is really new to me but I got the impression that my glmer was on the right lines but I'm still keen to have reassurance or corrections/improvements or just any comments. 

TIA, 

Chris 

> From: "Pierce, Steven" <pierces1 at msu.edu>
> To: "Chris Evans" <chrishold at psyctc.org>
> Sent: Friday, 10 May, 2019 14:22:52
> Subject: RE: [R-sig-ME] First post: binomial model for omission of items of
> questionnaire, and advice on reading

> Chris,

> Here are some reading suggestions that may help you learn more about using mixed
> effects models. I could provide more (mixed models is a huge topic area), but
> these are a good start. Best of luck in your continuing journey to learn how to
> use mixed models.

> Singer, J. D., & Willett, J. B. (2003). Applied longitudinal data analysis:
> Modeling change and event occurrence . New York, NY: Oxford University Press.

> ? First half of the book is a very reader-friendly intro to mixed effect models,
> second half focuses on discrete-time survival analysis.

> Gelman, A., & Hill, J. (2007). Data analysis using regression and
> multilevel/hierarchical models . New York, NY: Cambridge University Press.

> ? Shows the connection between basic regression and mixed effects models. Good
> foundational resource.

> Snijders, T. A. B., & Bosker, R. J. (2012). Multilevel analysis: An introduction
> to basic and advanced multilevel modeling (2nd ed.). London, UK: Sage.

> ? Good foundational resource.

> West, B. T., Welch, K. B., Ga?ecki, A. T., & Gillespie, B. W. (2015). Linear
> mixed models: A practical guide using statistical software. Retrieved from [
> http://www.crcnetbase.com/isbn/978-1-4665-6102-1 |
> http://www.crcnetbase.com/isbn/978-1-4665-6102-1 ]

> Enders, C. K., & Tofighi, D. (2007). Centering predictor variables in
> cross-sectional multilevel models: A new look at an old issue. Psychological
> Methods, 12(2), 121-138. doi:10.1037/1082-989X.12.2.121

> ? Centering affects how one interprets the coefficients in models. This is an
> excellent paper for getting a handle on that issue.

> Steven J. Pierce, Ph.D.

> Acting Director; Associate Director

> Center for Statistical Training & Consulting (CSTAT)

> Michigan State University

> Giltner Hall

> 293 Farm Lane, Room 100A

> East Lansing, MI 48824

> Office Phone & Fax: (517) 353-1051

> E-mail: pierces1 at msu or Steve.Pierce at cstat.msu.edu

> Web: https://cstat.msu.edu

> -----Original Message-----
> From: Chris Evans <chrishold at psyctc.org>
> Sent: Thursday, May 9, 2019 2:26 PM
> To: r-sig-mixed-models at r-project.org
> Subject: [R-sig-ME] First post: binomial model for omission of items of
> questionnaire, and advice on reading

> I've followed this list for some years now and learned much about analyses of
> mixed models from it but I'm pretty sure this is my first post and I suspect
> it's embarrassingly obvious and that leads to its second part: advice on
> reading.

> The immediate question is about testing whether participants omitting an item of
> a questionnaire relates to the cueing, negative or positive of the item. The
> data look like this:

> > head(longDat[,c(7,3,4,6)])

> ID itemN positive missed

> 1 1 1 FALSE 1

> 2 2 1 FALSE 0

> 3 3 1 FALSE 0

> 4 4 1 FALSE 0

> 5 5 1 FALSE 1

> 6 6 1 FALSE 0

> "itemN" is a factor as at the moment I'm not testing any order effect through
> completion of the questionnaire. The variable "positive" is the cueing and
> "missed" is whether the item was omitted by the participant or not.

> I think a reasonable model is that people vary in a general willingness to omit
> items and that there might in addition to that random variance, be an effect of
> cueing, probably that negatively cued items are less likely to be omitted but I
> wouldn't want a directional test. As it happens in this questionnaire there are
> 10 items, three positively cued and seven negatively cued. I've simulated data
> so the ten items have rather different omission rates and the cueing has an
> effect on top of those.

> I analysed my data with:

> > res3 <- glmer(missed ~ positive + (1 | ID), family = binomial, data = longDat)

> > res3

> Generalized linear mixed model fit by maximum likelihood (Laplace Approximation)
> ['glmerMod']

> Family: binomial ( logit )

> Formula: missed ~ positive + (1 | ID)

> Data: longDat

> AIC BIC logLik deviance df.resid

> 12597.534 12619.165 -6295.767 12591.534 9997

> Random effects:

> Groups Name Std.Dev.

> ID (Intercept) 1.056

> Number of obs: 10000, groups: ID, 1000

> Fixed Effects:

> (Intercept) positiveTRUE

> 0.6102 -0.7833

> > se <- sqrt(diag(vcov(res1)))

>> (tab <- cbind(Est = fixef(res3), LL = fixef(res3) - 1.96 * se, UL = fixef(res3)
> > + 1.96 * se))

> Est LL UL

> (Intercept) 0.6101525 0.5330314 0.6872737

> positiveTRUE -0.7832788 -0.8603999 -0.7061576



> That all seems fine and to fit with the parameters that I'd put into simulating
> the data but I'm sufficiently new to this to want to check with people more
> experienced than I am if that does seem the right approach. I may have some
> follow up work where there are more ways to classify the ten items (including
> order).

> My tangential question is about recommended reading for someone who comes out of
> medicine through psychotherapy so doesn't really have algebra, let alone matrix
> algebra and Bayesian theory say, running in my veins. I have many
> peer-reviewed, empirical, quantitative papers from the last three decades,
> almost all based on my having to do my own statistical analyses as I've rarely
> worked anywhere where I've had either money to pay for statistical help or a
> resident statistician. However, I'm fairly new to multilevel models (as you can
> see!) but I'm increasingly seeing them as vital to the sorts of data I analyse.
> Where should I start?!

> TIA,

> Chris

> --

> Chris Evans < [ mailto:chris at psyctc.org | chris at psyctc.org ] > Skype:
> chris-psyctc

> Visiting Professor, University of Sheffield < [
> mailto:chris.evans at sheffield.ac.uk | chris.evans at sheffield.ac.uk ] >

> I do some consultation work for the University of Roehampton < [
> mailto:chris.evans at roehampton.ac.uk | chris.evans at roehampton.ac.uk ] > and
> other places but this < [ mailto:chris at psyctc.org | chris at psyctc.org ] >
> remains my main Email address.

> I have "semigrated" to France, see: [
> https://urldefense.proofpoint.com/v2/url?u=https-3A__www.psyctc.org_pelerinage2016_semigrating-2Dto-2Dfrance_&d=DwICaQ&c=nE__W8dFE-shTxStwXtp0A&r=91SB6keVyEb7FtX7ZipxyQ&m=V4A7m7gcB5GqNrJG_2Hddj8JBPLv03RM_9xv-xeKcY4&s=88bPf9SGHq8AqqUF_ULhy9NgZEcVjOR5BnHHUsHcg4M&e
> |
> https://urldefense.proofpoint.com/v2/url?u=https-3A__www.psyctc.org_pelerinage2016_semigrating-2Dto-2Dfrance_&d=DwICaQ&c=nE__W8dFE-shTxStwXtp0A&r=91SB6keVyEb7FtX7ZipxyQ&m=V4A7m7gcB5GqNrJG_2Hddj8JBPLv03RM_9xv-xeKcY4&s=88bPf9SGHq8AqqUF_ULhy9NgZEcVjOR5BnHHUsHcg4M&e
> ] = if you want to book to talk, I am trying to keep that to Thursdays and my
> diary is now available at: [
> https://urldefense.proofpoint.com/v2/url?u=https-3A__www.psyctc.org_pelerinage2016_ecwd-5Fcalendar_calendar_&d=DwICaQ&c=nE__W8dFE-shTxStwXtp0A&r=91SB6keVyEb7FtX7ZipxyQ&m=V4A7m7gcB5GqNrJG_2Hddj8JBPLv03RM_9xv-xeKcY4&s=EzLP6hulVhzP7gynubmwovaDJ8WgJU49RLRz-lxD03Q&e
> |
> https://urldefense.proofpoint.com/v2/url?u=https-3A__www.psyctc.org_pelerinage2016_ecwd-5Fcalendar_calendar_&d=DwICaQ&c=nE__W8dFE-shTxStwXtp0A&r=91SB6keVyEb7FtX7ZipxyQ&m=V4A7m7gcB5GqNrJG_2Hddj8JBPLv03RM_9xv-xeKcY4&s=EzLP6hulVhzP7gynubmwovaDJ8WgJU49RLRz-lxD03Q&e
> ] =

> Beware: French time, generally an hour ahead of UK. That page will also take you
> to my blog which started with earlier joys in France and Spain!

> [[alternative HTML version deleted]]

-- 
Chris Evans <chris at psyctc.org> Skype: chris-psyctc 
Visiting Professor, University of Sheffield <chris.evans at sheffield.ac.uk> 
I do some consultation work for the University of Roehampton <chris.evans at roehampton.ac.uk> and other places but this <chris at psyctc.org> remains my main Email address. 
I have "semigrated" to France, see: https://www.psyctc.org/pelerinage2016/semigrating-to-france/ if you want to book to talk, I am trying to keep that to Thursdays and my diary is now available at: https://www.psyctc.org/pelerinage2016/ecwd_calendar/calendar/ 
Beware: French time, generally an hour ahead of UK. That page will also take you to my blog which started with earlier joys in France and Spain! 

	[[alternative HTML version deleted]]


From ju@npe @end|ng |rom un|ov|@e@  Sat May 11 09:27:02 2019
From: ju@npe @end|ng |rom un|ov|@e@ (JUAN PEDRO GONZALEZ VARO)
Date: Sat, 11 May 2019 07:27:02 +0000
Subject: [R-sig-ME] factor importance in glmm with a two-way ANOVA structure
In-Reply-To: <a703d3b7-33d1-4259-d57a-0743249a0de3@mcmaster.ca>
References: <a703d3b7-33d1-4259-d57a-0743249a0de3@mcmaster.ca>
Message-ID: <b6b3acdc-6226-3173-f66b-cc4c93a18a3c@uniovi.es>

Hi

I'm running a glmm with negative binomial family, because my dataset
has many zeros, yet, they are not structural zeros.

The model design is a 2-way ANOVA: habitat_type * season

In a glm, I can assess the relative importance of each factor
through the deviances (null and residual deviances of the model, and
partial deviances accounted by each factor).

The analogous way in a LMM would be the Sum of Squares.

But, how can I assess the performance (or variance accounted) by
different factors in a glmm?

I've been searching a lot in internet but I haven't found anything
clear about it.

I hope you can provide some advice on it.

Thanks!

Jp


From juho@kr|@t|@n@ruohonen @end|ng |rom gm@||@com  Sun May 12 19:26:29 2019
From: juho@kr|@t|@n@ruohonen @end|ng |rom gm@||@com (Juho Kristian Ruohonen)
Date: Sun, 12 May 2019 20:26:29 +0300
Subject: [R-sig-ME] Optimism introduced by non-converging models in
 bootstrap validation of GLMM (lme4)
Message-ID: <CAG_dBVczX26aX+67CTYkSbMkJqeanmeNq-Z_s3xdJD46jBW5Gg@mail.gmail.com>

Hi,

I have a random-intercept logistic GLMM fit to a dataset of 650
observations. The model discriminates the binary outcomes of the dataset
very nicely (C-index aka ROC AUC equals .85). But a reviewer suggested that
in a dataset this small, the model's discrimination performance should be
tested through a bootstrap procedure.

My script draws a bootstrap sample from the dataset, fits the model to it,
then uses the somers2() function from the Hmisc library to calculate the
C-index of the boostrap-fit model when used to discriminate the original
data. This is repeated 1000 times:

# The original dataset is called d
require(lme4)
require(Hmisc)
n <- 1000
c.index <- numeric(length = n)
set.seed(2019)
for(i in 1:n){
  bootsample <- d[sample(nrow(d), replace = T),]
  tmpmod <- update(MyModel, ~., data = bootsample)
  c.index[i] <- somers2(predict(tmpmod, newdata = d, re.form = NULL,
allow.new.levels =  TRUE), d$dep.var)["C"]
}

It turns out that at .854, average discrimination in 1000 bootstrap
iterations is slightly Higher than the original model's in-sample
discrimination (.85). There must be an error, no? Surely the out-of-sample
performance of any model should be worse, on average, than its in-sample
performance?

My actual code includes additional, fairly messy bits which attempt to
refit non-converging models using alternative optimizers (from the optimx
package) and, failing that, draws a new bootstrap sample if the model
cannot be fit to the first bootstrap sample for that iteration. In total,
there were 128 bootstrap samples for which the model failed to converge,
necessitating an alternative bootstrap sample. My suspicion is that this is
the reason behind the too-good-to-be-true results -- the exclusion of those
bootstrap 128 samples for which the model failed to converge has introduced
an optimistic bias into the bootstrap sampling, such that favorable
bootstrap samples are overrepresented and unfavorable ones
underrepresented. The question is: since it is impossible to achieve
convergence in every bootstrap sample, is there some heuristic for
estimating the degree of optimism introduced by bootstrap samples that had
to be discarded due to non-convergence?

Best,

J

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Sun May 12 19:59:30 2019
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Sun, 12 May 2019 13:59:30 -0400
Subject: [R-sig-ME] Optimism introduced by non-converging models in
 bootstrap validation of GLMM (lme4)
In-Reply-To: <CAG_dBVczX26aX+67CTYkSbMkJqeanmeNq-Z_s3xdJD46jBW5Gg@mail.gmail.com>
References: <CAG_dBVczX26aX+67CTYkSbMkJqeanmeNq-Z_s3xdJD46jBW5Gg@mail.gmail.com>
Message-ID: <f6fdc343-19df-2e98-6c08-554a5d256ed9@gmail.com>


  Quick thought: "non-convergence" doesn't necessarily mean the fit is
actually bad (false positives blah blah blah), and in most (all?) cases
you actually get a working fitted model (i.e., you could get the
C-index).  If you compare the distribution of C-indices from converging
and non-converging models, what do you see?

  Also: is bootstrapping at the level of observations OK, or should you
be bootstrapping at the level of groups (or hierarchically, i.e. both
among and within groups)?

  I'm also not 100% sure that the discrimination must be lower in the
bootstrap samples -- among other things, the model is *not* maximizing
discrimination, it's maximizing likelihood (which are presumably
asymptotically equivalent but needn't be identical ... ?)

On 2019-05-12 1:26 p.m., Juho Kristian Ruohonen wrote:
> Hi,
> 
> I have a random-intercept logistic GLMM fit to a dataset of 650
> observations. The model discriminates the binary outcomes of the dataset
> very nicely (C-index aka ROC AUC equals .85). But a reviewer suggested that
> in a dataset this small, the model's discrimination performance should be
> tested through a bootstrap procedure.
> 
> My script draws a bootstrap sample from the dataset, fits the model to it,
> then uses the somers2() function from the Hmisc library to calculate the
> C-index of the boostrap-fit model when used to discriminate the original
> data. This is repeated 1000 times:
> 
> # The original dataset is called d
> require(lme4)
> require(Hmisc)
> n <- 1000
> c.index <- numeric(length = n)
> set.seed(2019)
> for(i in 1:n){
>   bootsample <- d[sample(nrow(d), replace = T),]
>   tmpmod <- update(MyModel, ~., data = bootsample)
>   c.index[i] <- somers2(predict(tmpmod, newdata = d, re.form = NULL,
> allow.new.levels =  TRUE), d$dep.var)["C"]
> }
> 
> It turns out that at .854, average discrimination in 1000 bootstrap
> iterations is slightly Higher than the original model's in-sample
> discrimination (.85). There must be an error, no? Surely the out-of-sample
> performance of any model should be worse, on average, than its in-sample
> performance?
> 
> My actual code includes additional, fairly messy bits which attempt to
> refit non-converging models using alternative optimizers (from the optimx
> package) and, failing that, draws a new bootstrap sample if the model
> cannot be fit to the first bootstrap sample for that iteration. In total,
> there were 128 bootstrap samples for which the model failed to converge,
> necessitating an alternative bootstrap sample. My suspicion is that this is
> the reason behind the too-good-to-be-true results -- the exclusion of those
> bootstrap 128 samples for which the model failed to converge has introduced
> an optimistic bias into the bootstrap sampling, such that favorable
> bootstrap samples are overrepresented and unfavorable ones
> underrepresented. The question is: since it is impossible to achieve
> convergence in every bootstrap sample, is there some heuristic for
> estimating the degree of optimism introduced by bootstrap samples that had
> to be discarded due to non-convergence?
> 
> Best,
> 
> J
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From @h@ecr@|n @end|ng |rom gm@||@com  Mon May 13 18:43:43 2019
From: @h@ecr@|n @end|ng |rom gm@||@com (Shae Crain)
Date: Mon, 13 May 2019 12:43:43 -0400
Subject: [R-sig-ME] MCMCglmm random slope model
Message-ID: <CA+KNi5ZjVWy-KWUDSU0GrzUZd-Vz9M2tgMujxC3REqdy=H8=Jw@mail.gmail.com>

Dear List,

Hi, I'm Shae and I'm a grad student working on the chronobiology and
behavioral profile of a spider (Frontinella communis). I'm looking into
whether there's a possible correlation between antipredator behavior and
time of day. My data is quite zero-inflated and overdispersed...therefore
I'm using MCMCglmm.

Quick synopsis of my project so I'm not just throwing a model at yall:

I assayed wariness levels in indivs over a 24hr period (all at the same
time points), twice. Responses are however long they pause (seconds) and
whether they exhibited huddling behavior. I pooled the measurements into
whether the time point was in light and or dark conditions.

I've been using Dingemanse and Dochtermann (2013) instructional paper,
worked through their random intercept examples and now I'm trying to fit
univariate random slope models to answer my further questions regarding the
plasticity of Frontinella's antipredator strategies.(I wish to do bivariate
RR as well but one step at a time).

There are no Bayesians in my department so I'm sending out a lifeline to be
sure that I am doing this correctly (I'm going against my advisor's wishes
to run a binomial logistic regression). I am very new to R and have spent
the last few weeks teaching myself (so thank you for all of your very
helpful papers!)

xdevh is my centered covariate
xjh are individual level averages

I'm using the prior from Bolker et al (2012)'s owl example

>prior_overdisp  <- list(R=list(V=diag(c(1,1)),nu=0.002,fix=2),
G=list(list(V=diag(c(1,1e-6)),nu=0.002,fix=2)))

pmc.rs<-MCMCglmm(p~trait-1+at.level(trait,1):xjh+at.level(trait,1):xdevh,
random = ~idh(trait):id, family="zipoisson",rcov=~idh(trait):units,pr=TRUE,
prior = prior_overdisp,,nitt=1300000,thin=1000,burnin=300000,
data=fullpuff ,verbose=FALSE,start=list(QUASI=FALSE))

# I increased the nitt to avoid autocorrelation of the zi variables...I'm
still at a loss on how to interpret them. The zeros in my responses are
there for a reason; if indivs were very bold and refused to huddle/pause at
all.

My model summary:

 Iterations = 300001:1299001
 Thinning interval  = 1000
 Sample size  = 1000

 DIC: 1555.507

 G-structure:  ~idh(trait):id

             post.mean l-95% CI u-95% CI eff.samp
traitp.id     0.701283 0.361328 1.117891     1000
traitzi_p.id  0.000001 0.000001 0.000001        0

 R-structure:  ~idh(trait):units

                post.mean l-95% CI u-95% CI eff.samp
traitp.units       0.6587   0.4952    0.818     1000
traitzi_p.units    1.0000   1.0000    1.000        0

 Location effects: p ~ trait - 1 + at.level(trait, 1):xjh + at.level(trait,
1):xdevh

                         post.mean l-95% CI u-95% CI eff.samp  pMCMC
traitp                      3.7466   3.2505   4.2624  1000.00 <0.001 ***
traitzi_p                 -30.6866 -48.3946 -11.6482     2.15 <0.001 ***
at.level(trait, 1):xjh      0.4811   0.3001   0.6716  1000.00 <0.001 ***
at.level(trait, 1):xdevh    0.2335   0.1286   0.3399   942.41 <0.001 ***
---

I do not feel secure in whether the model fit...and I do not know how to
approach the effect sizes of my zi variables. I have a nagging feeling that
I did the model incorrectly and the traceplots for the zi variables are far
from ideal.

In conclusion, my most pressing questions are:
1. Does my model appear to make sense? Would random=~us(trait):id be more
appropriate? Could it be the prior?

2. Could the effect sizes of my zi variables be a product of the model
fitting poorly? Or are they okay? Should I just run the model longer?

3. Whenever I plot my observed responses over my model, some indivs will
have estimates far larger than should be reasonable (like 7500). Could that
be just an artifact and can it be controlled for? Or is it a diagnostic of
a poor fit?

Thank you all so very much in advance for reading this and I'll appreciate
any feedback at all.

-Respectfully,

Shae

	[[alternative HTML version deleted]]


From d@|uedecke @end|ng |rom uke@de  Tue May 14 12:25:58 2019
From: d@|uedecke @end|ng |rom uke@de (=?iso-8859-1?Q?Daniel_L=FCdecke?=)
Date: Tue, 14 May 2019 12:25:58 +0200
Subject: [R-sig-ME] Collinearity tests (e.g. VIF) for glmmTMB package
In-Reply-To: <ACD1644AA6C67E4FBD0C350625508EC836BAA115@FHSDB2D11-2.csu.mcmaster.ca>
References: <9080_1557416206_x49Fajqo025294_DB7PR03MB4555314A110F206CE6E18603C2330@DB7PR03MB4555.eurprd03.prod.outlook.com>
 <ACD1644AA6C67E4FBD0C350625508EC836BA9E2C@FHSDB2D11-2.csu.mcmaster.ca>
 <cbe0dbea-871b-fa7d-2596-728bb3e1b079@gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC836BAA115@FHSDB2D11-2.csu.mcmaster.ca>
Message-ID: <000001d50a3f$6befe940$43cfbbc0$@uke.de>

Hi John and Ben,

iirc, model.matrix() for glmmTMB objects returns an assign-attribute,
however, I think you can only return the model matrix for the
count-component, not for the zero-inflated component. I don't know if there
might be situations where you have models that have different variables in
the ZI-formula as compared to the count-formula, but in such cases, VIF
can't be calculated.

Best
Daniel

-----Urspr?ngliche Nachricht-----
Von: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] Im
Auftrag von Fox, John
Gesendet: Freitag, 10. Mai 2019 00:31
An: Ben Bolker <bbolker at gmail.com>; Williamson, Michael
<michael.williamson at kcl.ac.uk>
Cc: r-sig-mixed-models at r-project.org
Betreff: Re: [R-sig-ME] Collinearity tests (e.g. VIF) for glmmTMB package

Hi Ben,

Take a look at the vif.merMod() method from the car package:

> car:::vif.merMod
function(mod, ...) {
  if (any(is.na(fixef(mod)))) 
    stop ("there are aliased coefficients in the model")
  v <- as.matrix(vcov(mod))
  assign <- attr(model.matrix(mod), "assign")
  if (names(fixef(mod)[1]) == "(Intercept)") {
    v <- v[-1, -1]
    assign <- assign[-1]
  }
  else warning("No intercept: vifs may not be sensible.")
  terms <- labels(terms(mod))
  n.terms <- length(terms)
  if (n.terms < 2) stop("model contains fewer than 2 terms")
  R <- cov2cor(v)
  detR <- det(R)
  result <- matrix(0, n.terms, 3)
  rownames(result) <- terms
  colnames(result) <- c("GVIF", "Df", "GVIF^(1/(2*Df))")
  for (term in 1:n.terms) {
    subs <- which(assign == term)
    result[term, 1] <- det(as.matrix(R[subs, subs])) *
      det(as.matrix(R[-subs, -subs])) / detR
    result[term, 2] <- length(subs)
  }
  if (all(result[, 2] == 1)) result <- result[, 1]
  else result[, 3] <- result[, 1]^(1/(2 * result[, 2]))
  result
}

So for each model component, I'd need the "assign" attribute from the model
matrix. My relatively cursory examination of objects produced by glmmTMB()
didn't turn up whether (or where) this information is stored.

I agree that for glmmTMB() VIFs could be computed componentwise, with the
user specifying which component(s) and perhaps a default of "all". 

Best,
 John

> -----Original Message-----
> From: Ben Bolker [mailto:bbolker at gmail.com]
> Sent: Thursday, May 9, 2019 3:31 PM
> To: Fox, John <jfox at mcmaster.ca>; Williamson, Michael 
> <michael.williamson at kcl.ac.uk>
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: Collinearity tests (e.g. VIF) for glmmTMB package
> 
> 
> 
>   I'm not sure what you else need to know about the component 
> structures?
> 
> >  but I don't see where to recover the necessary information about 
> > the
> structures of the component models from the "glmmTMB" object.
> 
>    I've been meaning to write a vif.glmmTMB method, but I was planning 
> to just add a "component" argument to make the user choose: the names 
> of the vcov() components are "cond" and "zi" (and there could be a "disp"
> component if there's a non-trivial dispersion model ...)
> 
> 
> 
> 
> On 2019-05-09 3:28 p.m., Fox, John wrote:
> > Dear Mike,
> >
> > I'm not sufficiently familiar with the objects produced by glmmTMB()
> to answer definitively, and I'm also not entirely sure why you want to 
> check for collinearity, but maybe the following would help:
> >
> > You can used vcov() to return the variances and covariances of
> coefficients in the various parts of the "glmmTMB" model. For example:
> >
> > ---------------- snip ------------
> >
> >> library(glmmTMB)
> >> example("glmmTMB")
> >> v <- vcov(m3)
> >> v
> > Conditional model:
> >             (Intercept)        sppPR        sppDM       sppEC-A
> sppEC-L     sppDES-L       sppDF       minedno
> > (Intercept)  0.04245503 -0.012754751 -0.013349646 -0.0125136751 -
> 0.013436038 -0.013225977 -0.01391389 -0.0305911919
> > sppPR       -0.01275475  0.077687602  0.011642383  0.0119168647
> 0.011903658  0.011843477  0.01185466  0.0013084323
> > sppDM       -0.01334965  0.011642383  0.020980164  0.0117137251
> 0.011868129  0.011728938  0.01171587  0.0015986374
> > sppEC-A     -0.01251368  0.011916865  0.011713725  0.0404883426
> 0.011904829  0.011680709  0.01185958  0.0009042868
> > sppEC-L     -0.01343604  0.011903658  0.011868129  0.0119048294
> 0.017500122  0.011744878  0.01192195  0.0016761527
> > sppDES-L    -0.01322598  0.011843477  0.011728938  0.0116807092
> 0.011744878  0.016968986  0.01186668  0.0015556516
> > sppDF       -0.01391389  0.011854661  0.011715873  0.0118595830
> 0.011921947  0.011866683  0.02370581  0.0021442905
> > minedno     -0.03059119  0.001308432  0.001598637  0.0009042868
> 0.001676153  0.001555652  0.00214429  0.0350573728
> >
> > Zero-inflation model:
> >                zi~(Intercept)     zi~sppPR     zi~sppDM   zi~sppEC-A
> zi~sppEC-L  zi~sppDES-L     zi~sppDF   zi~minedno
> > zi~(Intercept)     0.08027669 -0.055011989 -0.064230942 -0.056164325 -
> 0.064230942 -0.066122481 -0.064230942 -0.028881293
> > zi~sppPR          -0.05501199  0.157151941  0.060172003  0.062766076
> 0.060172003  0.059563719  0.060172003 -0.009287683
> > zi~sppDM          -0.06423094  0.060172003  0.122669211  0.060357133
> 0.061653087  0.061956976  0.061653087  0.004639967
> > zi~sppEC-A        -0.05616432  0.062766076  0.060357133  0.135723657
> 0.060357133  0.059862868  0.060357133 -0.007546778
> > zi~sppEC-L        -0.06423094  0.060172003  0.061653087  0.060357133
> 0.122669211  0.061956976  0.061653087  0.004639967
> > zi~sppDES-L       -0.06612248  0.059563719  0.061956976  0.059862868
> 0.061956976  0.123808814  0.061956976  0.007497634
> > zi~sppDF          -0.06423094  0.060172003  0.061653087  0.060357133
> 0.061653087  0.061956976  0.122669211  0.004639967
> > zi~minedno        -0.02888129 -0.009287683  0.004639967 -0.007546778
> 0.004639967  0.007497634  0.004639967  0.043632782
> >
> > ---------------- snip ------------
> >
> > In this case, there are two components to the model -- the 
> > conditional
> model and the zero-inflation model -- and I believe that they are 
> independent, so you should be able to eliminate the intercept from 
> each and compute VIFs for the other coefficients:
> >
> > ---------------- snip ------------
> >
> >> diag(solve(cov2cor(v[[1]][-1, -1])))
> >    sppPR    sppDM  sppEC-A  sppEC-L sppDES-L    sppDF  minedno
> > 1.154418 1.918674 1.340247 2.317812 2.344363 1.767413 1.006961
> >
> >> diag(solve(cov2cor(v[[2]][-1, -1])))
> >    zi~sppPR    zi~sppDM  zi~sppEC-A  zi~sppEC-L zi~sppDES-L
> zi~sppDF  zi~minedno
> >    1.503986    1.699895    1.614313    1.699895    1.707801
> 1.699895    1.079338
> >
> > ---------------- snip ------------
> >
> > Of course, it would be nice to automate this and to compute
> generalized VIFs for terms with more than one coefficient, but I don't 
> see where to recover the necessary information about the structures of 
> the component models from the "glmmTMB" object.
> >
> > I'm cc'ing Ben Bolker in case he has something to add (or correct).
> >
> > I hope this helps,
> >  John
> >
> > --------------------------------------
> > John Fox, Professor Emeritus
> > McMaster University
> > Hamilton, Ontario, Canada
> > Web: socialsciences.mcmaster.ca/jfox/
> >
> >
> >
> >> -----Original Message-----
> >> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-
> >> project.org] On Behalf Of Williamson, Michael via 
> >> R-sig-mixed-models
> >> Sent: Thursday, May 9, 2019 11:13 AM
> >> To: r-sig-mixed-models at r-project.org
> >> Subject: [R-sig-ME] Collinearity tests (e.g. VIF) for glmmTMB 
> >> package
> >>
> >> Good Afternoon,
> >>
> >> I've been running a few generalised linear mixed models on my data.
> >> Due to convergence issues, down to the size of the data set, I was 
> >> recommended to switch to the glmmTMB package from the glmer 
> >> function in lme4.. The models are running much better now with no 
> >> more convergence issues.
> >>
> >> I'm looking to test the collinearity of my models, but the VIF 
> >> function in the car package does not work with the glmmTMB package.
> >> Does anyone know of any packages or functions that can be used to 
> >> calculate collinearity from model outputs generated by glmmTMB?
> >>
> >> Many thanks,
> >>
> >> Mike Williamson
> >>
> >> Email:
> >> michael.williamson at kcl.ac.uk<mailto:michael.williamson at kcl.ac.uk>
> >>
> >>
> >>
> >>
> >> 	[[alternative HTML version deleted]]
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list 
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

--

_____________________________________________________________________

Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen Rechts; Gerichtsstand: Hamburg | www.uke.de
Vorstandsmitglieder: Prof. Dr. Burkhard G?ke (Vorsitzender), Prof. Dr. Dr. Uwe Koch-Gromus, Joachim Pr?l?, Marya Verdel
_____________________________________________________________________

SAVE PAPER - THINK BEFORE PRINTING


From d@r|zopou|o@ @end|ng |rom er@@mu@mc@n|  Tue May 14 12:32:57 2019
From: d@r|zopou|o@ @end|ng |rom er@@mu@mc@n| (D. Rizopoulos)
Date: Tue, 14 May 2019 10:32:57 +0000
Subject: [R-sig-ME] Collinearity tests (e.g. VIF) for glmmTMB package
In-Reply-To: <000001d50a3f$6befe940$43cfbbc0$@uke.de>
References: <9080_1557416206_x49Fajqo025294_DB7PR03MB4555314A110F206CE6E18603C2330@DB7PR03MB4555.eurprd03.prod.outlook.com>
 <ACD1644AA6C67E4FBD0C350625508EC836BA9E2C@FHSDB2D11-2.csu.mcmaster.ca>
 <cbe0dbea-871b-fa7d-2596-728bb3e1b079@gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC836BAA115@FHSDB2D11-2.csu.mcmaster.ca>
 <000001d50a3f$6befe940$43cfbbc0$@uke.de>
Message-ID: <ffd106dc-939e-f942-53b0-65bdc6f5a4dc@erasmusmc.nl>

Hi Daniel,

In the development version of GLMMadaptive 
(https://github.com/drizopoulos/GLMMadaptive) that can fit similar 
models as glmmTMB, I have put a VIF() method (based on car::vif) that 
can calculate VIFs also for zero-inflated models. E.g.,

library("GLMMadaptive")
fm <- mixed_model(y ~ time + sex, random = ~ 1 | id, data = <your_data>, 
family = zi.negative.binomial(), zi_fixed = ~ sex, zi_random = ~ 1 | id)

VIF(fm) # for the fixed effects of the non-zero part
VIF(fm, type = "zi_fixed") # fixed effects zero part


Best,
Dimitris


On 5/14/2019 12:25 PM, Daniel L?decke wrote:
> Hi John and Ben,
> 
> iirc, model.matrix() for glmmTMB objects returns an assign-attribute,
> however, I think you can only return the model matrix for the
> count-component, not for the zero-inflated component. I don't know if there
> might be situations where you have models that have different variables in
> the ZI-formula as compared to the count-formula, but in such cases, VIF
> can't be calculated.
> 
> Best
> Daniel
> 
> -----Urspr?ngliche Nachricht-----
> Von: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] Im
> Auftrag von Fox, John
> Gesendet: Freitag, 10. Mai 2019 00:31
> An: Ben Bolker <bbolker at gmail.com>; Williamson, Michael
> <michael.williamson at kcl.ac.uk>
> Cc: r-sig-mixed-models at r-project.org
> Betreff: Re: [R-sig-ME] Collinearity tests (e.g. VIF) for glmmTMB package
> 
> Hi Ben,
> 
> Take a look at the vif.merMod() method from the car package:
> 
>> car:::vif.merMod
> function(mod, ...) {
>    if (any(is.na(fixef(mod))))
>      stop ("there are aliased coefficients in the model")
>    v <- as.matrix(vcov(mod))
>    assign <- attr(model.matrix(mod), "assign")
>    if (names(fixef(mod)[1]) == "(Intercept)") {
>      v <- v[-1, -1]
>      assign <- assign[-1]
>    }
>    else warning("No intercept: vifs may not be sensible.")
>    terms <- labels(terms(mod))
>    n.terms <- length(terms)
>    if (n.terms < 2) stop("model contains fewer than 2 terms")
>    R <- cov2cor(v)
>    detR <- det(R)
>    result <- matrix(0, n.terms, 3)
>    rownames(result) <- terms
>    colnames(result) <- c("GVIF", "Df", "GVIF^(1/(2*Df))")
>    for (term in 1:n.terms) {
>      subs <- which(assign == term)
>      result[term, 1] <- det(as.matrix(R[subs, subs])) *
>        det(as.matrix(R[-subs, -subs])) / detR
>      result[term, 2] <- length(subs)
>    }
>    if (all(result[, 2] == 1)) result <- result[, 1]
>    else result[, 3] <- result[, 1]^(1/(2 * result[, 2]))
>    result
> }
> 
> So for each model component, I'd need the "assign" attribute from the model
> matrix. My relatively cursory examination of objects produced by glmmTMB()
> didn't turn up whether (or where) this information is stored.
> 
> I agree that for glmmTMB() VIFs could be computed componentwise, with the
> user specifying which component(s) and perhaps a default of "all".
> 
> Best,
>   John
> 
>> -----Original Message-----
>> From: Ben Bolker [mailto:bbolker at gmail.com]
>> Sent: Thursday, May 9, 2019 3:31 PM
>> To: Fox, John <jfox at mcmaster.ca>; Williamson, Michael
>> <michael.williamson at kcl.ac.uk>
>> Cc: r-sig-mixed-models at r-project.org
>> Subject: Re: Collinearity tests (e.g. VIF) for glmmTMB package
>>
>>
>>
>>    I'm not sure what you else need to know about the component
>> structures?
>>
>>>   but I don't see where to recover the necessary information about
>>> the
>> structures of the component models from the "glmmTMB" object.
>>
>>     I've been meaning to write a vif.glmmTMB method, but I was planning
>> to just add a "component" argument to make the user choose: the names
>> of the vcov() components are "cond" and "zi" (and there could be a "disp"
>> component if there's a non-trivial dispersion model ...)
>>
>>
>>
>>
>> On 2019-05-09 3:28 p.m., Fox, John wrote:
>>> Dear Mike,
>>>
>>> I'm not sufficiently familiar with the objects produced by glmmTMB()
>> to answer definitively, and I'm also not entirely sure why you want to
>> check for collinearity, but maybe the following would help:
>>>
>>> You can used vcov() to return the variances and covariances of
>> coefficients in the various parts of the "glmmTMB" model. For example:
>>>
>>> ---------------- snip ------------
>>>
>>>> library(glmmTMB)
>>>> example("glmmTMB")
>>>> v <- vcov(m3)
>>>> v
>>> Conditional model:
>>>              (Intercept)        sppPR        sppDM       sppEC-A
>> sppEC-L     sppDES-L       sppDF       minedno
>>> (Intercept)  0.04245503 -0.012754751 -0.013349646 -0.0125136751 -
>> 0.013436038 -0.013225977 -0.01391389 -0.0305911919
>>> sppPR       -0.01275475  0.077687602  0.011642383  0.0119168647
>> 0.011903658  0.011843477  0.01185466  0.0013084323
>>> sppDM       -0.01334965  0.011642383  0.020980164  0.0117137251
>> 0.011868129  0.011728938  0.01171587  0.0015986374
>>> sppEC-A     -0.01251368  0.011916865  0.011713725  0.0404883426
>> 0.011904829  0.011680709  0.01185958  0.0009042868
>>> sppEC-L     -0.01343604  0.011903658  0.011868129  0.0119048294
>> 0.017500122  0.011744878  0.01192195  0.0016761527
>>> sppDES-L    -0.01322598  0.011843477  0.011728938  0.0116807092
>> 0.011744878  0.016968986  0.01186668  0.0015556516
>>> sppDF       -0.01391389  0.011854661  0.011715873  0.0118595830
>> 0.011921947  0.011866683  0.02370581  0.0021442905
>>> minedno     -0.03059119  0.001308432  0.001598637  0.0009042868
>> 0.001676153  0.001555652  0.00214429  0.0350573728
>>>
>>> Zero-inflation model:
>>>                 zi~(Intercept)     zi~sppPR     zi~sppDM   zi~sppEC-A
>> zi~sppEC-L  zi~sppDES-L     zi~sppDF   zi~minedno
>>> zi~(Intercept)     0.08027669 -0.055011989 -0.064230942 -0.056164325 -
>> 0.064230942 -0.066122481 -0.064230942 -0.028881293
>>> zi~sppPR          -0.05501199  0.157151941  0.060172003  0.062766076
>> 0.060172003  0.059563719  0.060172003 -0.009287683
>>> zi~sppDM          -0.06423094  0.060172003  0.122669211  0.060357133
>> 0.061653087  0.061956976  0.061653087  0.004639967
>>> zi~sppEC-A        -0.05616432  0.062766076  0.060357133  0.135723657
>> 0.060357133  0.059862868  0.060357133 -0.007546778
>>> zi~sppEC-L        -0.06423094  0.060172003  0.061653087  0.060357133
>> 0.122669211  0.061956976  0.061653087  0.004639967
>>> zi~sppDES-L       -0.06612248  0.059563719  0.061956976  0.059862868
>> 0.061956976  0.123808814  0.061956976  0.007497634
>>> zi~sppDF          -0.06423094  0.060172003  0.061653087  0.060357133
>> 0.061653087  0.061956976  0.122669211  0.004639967
>>> zi~minedno        -0.02888129 -0.009287683  0.004639967 -0.007546778
>> 0.004639967  0.007497634  0.004639967  0.043632782
>>>
>>> ---------------- snip ------------
>>>
>>> In this case, there are two components to the model -- the
>>> conditional
>> model and the zero-inflation model -- and I believe that they are
>> independent, so you should be able to eliminate the intercept from
>> each and compute VIFs for the other coefficients:
>>>
>>> ---------------- snip ------------
>>>
>>>> diag(solve(cov2cor(v[[1]][-1, -1])))
>>>     sppPR    sppDM  sppEC-A  sppEC-L sppDES-L    sppDF  minedno
>>> 1.154418 1.918674 1.340247 2.317812 2.344363 1.767413 1.006961
>>>
>>>> diag(solve(cov2cor(v[[2]][-1, -1])))
>>>     zi~sppPR    zi~sppDM  zi~sppEC-A  zi~sppEC-L zi~sppDES-L
>> zi~sppDF  zi~minedno
>>>     1.503986    1.699895    1.614313    1.699895    1.707801
>> 1.699895    1.079338
>>>
>>> ---------------- snip ------------
>>>
>>> Of course, it would be nice to automate this and to compute
>> generalized VIFs for terms with more than one coefficient, but I don't
>> see where to recover the necessary information about the structures of
>> the component models from the "glmmTMB" object.
>>>
>>> I'm cc'ing Ben Bolker in case he has something to add (or correct).
>>>
>>> I hope this helps,
>>>   John
>>>
>>> --------------------------------------
>>> John Fox, Professor Emeritus
>>> McMaster University
>>> Hamilton, Ontario, Canada
>>> Web: socialsciences.mcmaster.ca/jfox/
>>>
>>>
>>>
>>>> -----Original Message-----
>>>> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-
>>>> project.org] On Behalf Of Williamson, Michael via
>>>> R-sig-mixed-models
>>>> Sent: Thursday, May 9, 2019 11:13 AM
>>>> To: r-sig-mixed-models at r-project.org
>>>> Subject: [R-sig-ME] Collinearity tests (e.g. VIF) for glmmTMB
>>>> package
>>>>
>>>> Good Afternoon,
>>>>
>>>> I've been running a few generalised linear mixed models on my data.
>>>> Due to convergence issues, down to the size of the data set, I was
>>>> recommended to switch to the glmmTMB package from the glmer
>>>> function in lme4.. The models are running much better now with no
>>>> more convergence issues.
>>>>
>>>> I'm looking to test the collinearity of my models, but the VIF
>>>> function in the car package does not work with the glmmTMB package.
>>>> Does anyone know of any packages or functions that can be used to
>>>> calculate collinearity from model outputs generated by glmmTMB?
>>>>
>>>> Many thanks,
>>>>
>>>> Mike Williamson
>>>>
>>>> Email:
>>>> michael.williamson at kcl.ac.uk<mailto:michael.williamson at kcl.ac.uk>
>>>>
>>>>
>>>>
>>>>
>>>> 	[[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=02%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C949964ad1c114eb5f8fd08d6d8568a0e%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C0%7C636934263533396201&amp;sdata=uSPgGHD4Kd%2FBi%2F%2BmCRYDeSzdKiHGaeqLxVuqzMlKbPU%3D&amp;reserved=0
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=02%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C949964ad1c114eb5f8fd08d6d8568a0e%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C0%7C636934263533396201&amp;sdata=uSPgGHD4Kd%2FBi%2F%2BmCRYDeSzdKiHGaeqLxVuqzMlKbPU%3D&amp;reserved=0
> 
> --
> 
> _____________________________________________________________________
> 
> Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen Rechts; Gerichtsstand: Hamburg | https://eur01.safelinks.protection.outlook.com/?url=www.uke.de&amp;data=02%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C949964ad1c114eb5f8fd08d6d8568a0e%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C0%7C636934263533396201&amp;sdata=7TTw4wZTddjd%2BvLuu3Lw1MpPzFI5CurHZiliTy10ke8%3D&amp;reserved=0
> Vorstandsmitglieder: Prof. Dr. Burkhard G?ke (Vorsitzender), Prof. Dr. Dr. Uwe Koch-Gromus, Joachim Pr?l?, Marya Verdel
> _____________________________________________________________________
> 
> SAVE PAPER - THINK BEFORE PRINTING
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=02%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C949964ad1c114eb5f8fd08d6d8568a0e%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C0%7C636934263533396201&amp;sdata=uSPgGHD4Kd%2FBi%2F%2BmCRYDeSzdKiHGaeqLxVuqzMlKbPU%3D&amp;reserved=0
> .
> 

-- 
Dimitris Rizopoulos
Professor of Biostatistics
Department of Biostatistics
Erasmus University Medical Center

Address: PO Box 2040, 3000 CA Rotterdam, the Netherlands
Tel: +31/(0)10/7043478
Fax: +31/(0)10/7043014
Web (personal): http://www.drizopoulos.com/
Web (work): http://www.erasmusmc.nl/biostatistiek/
Blog: http://iprogn.blogspot.nl/

From m|ch@e|@w||||@m@on @end|ng |rom kc|@@c@uk  Tue May 14 11:53:29 2019
From: m|ch@e|@w||||@m@on @end|ng |rom kc|@@c@uk (Williamson, Michael)
Date: Tue, 14 May 2019 09:53:29 +0000
Subject: [R-sig-ME] Collinearity tests (e.g. VIF) for glmmTMB package
In-Reply-To: <cbe0dbea-871b-fa7d-2596-728bb3e1b079@gmail.com>
References: <9080_1557416206_x49Fajqo025294_DB7PR03MB4555314A110F206CE6E18603C2330@DB7PR03MB4555.eurprd03.prod.outlook.com>
 <ACD1644AA6C67E4FBD0C350625508EC836BA9E2C@FHSDB2D11-2.csu.mcmaster.ca>
 <cbe0dbea-871b-fa7d-2596-728bb3e1b079@gmail.com>
Message-ID: <DB7PR03MB455579EA6F749DC4F4382D8DC2080@DB7PR03MB4555.eurprd03.prod.outlook.com>

Thanks for your input, and apologies for the delay in reply.

I just wanted to test to make sure there was no correlation between my explanatory variables.

That's really helpful much appreciated.

Mike

-----Original Message-----
From: Ben Bolker <bbolker at gmail.com> 
Sent: 09 May 2019 20:31
To: Fox, John <jfox at mcmaster.ca>; Williamson, Michael <michael.williamson at kcl.ac.uk>
Cc: r-sig-mixed-models at r-project.org
Subject: Re: Collinearity tests (e.g. VIF) for glmmTMB package



  I'm not sure what you else need to know about the component structures?

>  but I don't see where to recover the necessary information about the
structures of the component models from the "glmmTMB" object.

   I've been meaning to write a vif.glmmTMB method, but I was planning to just add a "component" argument to make the user choose: the names of the vcov() components are "cond" and "zi" (and there could be a "disp"
component if there's a non-trivial dispersion model ...)




On 2019-05-09 3:28 p.m., Fox, John wrote:
> Dear Mike,
> 
> I'm not sufficiently familiar with the objects produced by glmmTMB() to answer definitively, and I'm also not entirely sure why you want to check for collinearity, but maybe the following would help:
> 
> You can used vcov() to return the variances and covariances of coefficients in the various parts of the "glmmTMB" model. For example:
> 
> ---------------- snip ------------
> 
>> library(glmmTMB)
>> example("glmmTMB")
>> v <- vcov(m3)
>> v
> Conditional model:
>             (Intercept)        sppPR        sppDM       sppEC-A      sppEC-L     sppDES-L       sppDF       minedno
> (Intercept)  0.04245503 -0.012754751 -0.013349646 -0.0125136751 -0.013436038 -0.013225977 -0.01391389 -0.0305911919
> sppPR       -0.01275475  0.077687602  0.011642383  0.0119168647  0.011903658  0.011843477  0.01185466  0.0013084323
> sppDM       -0.01334965  0.011642383  0.020980164  0.0117137251  0.011868129  0.011728938  0.01171587  0.0015986374
> sppEC-A     -0.01251368  0.011916865  0.011713725  0.0404883426  0.011904829  0.011680709  0.01185958  0.0009042868
> sppEC-L     -0.01343604  0.011903658  0.011868129  0.0119048294  0.017500122  0.011744878  0.01192195  0.0016761527
> sppDES-L    -0.01322598  0.011843477  0.011728938  0.0116807092  0.011744878  0.016968986  0.01186668  0.0015556516
> sppDF       -0.01391389  0.011854661  0.011715873  0.0118595830  0.011921947  0.011866683  0.02370581  0.0021442905
> minedno     -0.03059119  0.001308432  0.001598637  0.0009042868  0.001676153  0.001555652  0.00214429  0.0350573728
> 
> Zero-inflation model:
>                zi~(Intercept)     zi~sppPR     zi~sppDM   zi~sppEC-A   zi~sppEC-L  zi~sppDES-L     zi~sppDF   zi~minedno
> zi~(Intercept)     0.08027669 -0.055011989 -0.064230942 -0.056164325 -0.064230942 -0.066122481 -0.064230942 -0.028881293
> zi~sppPR          -0.05501199  0.157151941  0.060172003  0.062766076  0.060172003  0.059563719  0.060172003 -0.009287683
> zi~sppDM          -0.06423094  0.060172003  0.122669211  0.060357133  0.061653087  0.061956976  0.061653087  0.004639967
> zi~sppEC-A        -0.05616432  0.062766076  0.060357133  0.135723657  0.060357133  0.059862868  0.060357133 -0.007546778
> zi~sppEC-L        -0.06423094  0.060172003  0.061653087  0.060357133  0.122669211  0.061956976  0.061653087  0.004639967
> zi~sppDES-L       -0.06612248  0.059563719  0.061956976  0.059862868  0.061956976  0.123808814  0.061956976  0.007497634
> zi~sppDF          -0.06423094  0.060172003  0.061653087  0.060357133  0.061653087  0.061956976  0.122669211  0.004639967
> zi~minedno        -0.02888129 -0.009287683  0.004639967 -0.007546778  0.004639967  0.007497634  0.004639967  0.043632782
> 
> ---------------- snip ------------
> 
> In this case, there are two components to the model -- the conditional model and the zero-inflation model -- and I believe that they are independent, so you should be able to eliminate the intercept from each and compute VIFs for the other coefficients:
> 
> ---------------- snip ------------
> 
>> diag(solve(cov2cor(v[[1]][-1, -1])))
>    sppPR    sppDM  sppEC-A  sppEC-L sppDES-L    sppDF  minedno 
> 1.154418 1.918674 1.340247 2.317812 2.344363 1.767413 1.006961
> 
>> diag(solve(cov2cor(v[[2]][-1, -1])))
>    zi~sppPR    zi~sppDM  zi~sppEC-A  zi~sppEC-L zi~sppDES-L    zi~sppDF  zi~minedno 
>    1.503986    1.699895    1.614313    1.699895    1.707801    1.699895    1.079338
> 
> ---------------- snip ------------
> 
> Of course, it would be nice to automate this and to compute generalized VIFs for terms with more than one coefficient, but I don't see where to recover the necessary information about the structures of the component models from the "glmmTMB" object.
> 
> I'm cc'ing Ben Bolker in case he has something to add (or correct).
> 
> I hope this helps,
>  John
> 
> --------------------------------------
> John Fox, Professor Emeritus
> McMaster University
> Hamilton, Ontario, Canada
> Web: socialsciences.mcmaster.ca/jfox/
> 
> 
> 
>> -----Original Message-----
>> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-
>> project.org] On Behalf Of Williamson, Michael via R-sig-mixed-models
>> Sent: Thursday, May 9, 2019 11:13 AM
>> To: r-sig-mixed-models at r-project.org
>> Subject: [R-sig-ME] Collinearity tests (e.g. VIF) for glmmTMB package
>>
>> Good Afternoon,
>>
>> I've been running a few generalised linear mixed models on my data. 
>> Due to convergence issues, down to the size of the data set, I was 
>> recommended to switch to the glmmTMB package from the glmer function 
>> in lme4.. The models are running much better now with no more 
>> convergence issues.
>>
>> I'm looking to test the collinearity of my models, but the VIF 
>> function in the car package does not work with the glmmTMB package. 
>> Does anyone know of any packages or functions that can be used to 
>> calculate collinearity from model outputs generated by glmmTMB?
>>
>> Many thanks,
>>
>> Mike Williamson
>>
>> Email: 
>> michael.williamson at kcl.ac.uk<mailto:michael.williamson at kcl.ac.uk>
>>
>>
>>
>>
>> 	[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://eur03.safelinks.protection.outlook.com/?url=https%3A%2F%2Fsta
>> t.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=01%7C01%
>> 7Cmichael.williamson%40kcl.ac.uk%7C7f9bad7bec9849815d3308d6d4b51df1%7
>> C8370cf1416f34c16b83c724071654356%7C0&amp;sdata=5SjBwoSih0U5h6yoZvbwE
>> ZyBf%2BLDiZqp75iboZuQzXc%3D&amp;reserved=0

From j|ox @end|ng |rom mcm@@ter@c@  Tue May 14 14:46:51 2019
From: j|ox @end|ng |rom mcm@@ter@c@ (Fox, John)
Date: Tue, 14 May 2019 12:46:51 +0000
Subject: [R-sig-ME] Collinearity tests (e.g. VIF) for glmmTMB package
In-Reply-To: <DB7PR03MB455579EA6F749DC4F4382D8DC2080@DB7PR03MB4555.eurprd03.prod.outlook.com>
References: <9080_1557416206_x49Fajqo025294_DB7PR03MB4555314A110F206CE6E18603C2330@DB7PR03MB4555.eurprd03.prod.outlook.com>
 <ACD1644AA6C67E4FBD0C350625508EC836BA9E2C@FHSDB2D11-2.csu.mcmaster.ca>
 <cbe0dbea-871b-fa7d-2596-728bb3e1b079@gmail.com>
 <DB7PR03MB455579EA6F749DC4F4382D8DC2080@DB7PR03MB4555.eurprd03.prod.outlook.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC836BB22B0@FHSDB2D11-2.csu.mcmaster.ca>

Dear Mike,

> -----Original Message-----
> From: Williamson, Michael [mailto:michael.williamson at kcl.ac.uk]
> Sent: Tuesday, May 14, 2019 5:53 AM
> To: Ben Bolker <bbolker at gmail.com>; Fox, John <jfox at mcmaster.ca>
> Cc: r-sig-mixed-models at r-project.org
> Subject: RE: Collinearity tests (e.g. VIF) for glmmTMB package
> 
> Thanks for your input, and apologies for the delay in reply.
> 
> I just wanted to test to make sure there was no correlation between my
> explanatory variables.

If that's all you want to do the you could just check directly, but "collinearity" in a mixed model is more complicated and vif() defines it using the correlations of the coefficients. In a linear model fit by OLS the two are the same but not more generally.

Best,
 John

> 
> That's really helpful much appreciated.
> 
> Mike
> 
> -----Original Message-----
> From: Ben Bolker <bbolker at gmail.com>
> Sent: 09 May 2019 20:31
> To: Fox, John <jfox at mcmaster.ca>; Williamson, Michael
> <michael.williamson at kcl.ac.uk>
> Cc: r-sig-mixed-models at r-project.org
> Subject: Re: Collinearity tests (e.g. VIF) for glmmTMB package
> 
> 
> 
>   I'm not sure what you else need to know about the component structures?
> 
> >  but I don't see where to recover the necessary information about the
> structures of the component models from the "glmmTMB" object.
> 
>    I've been meaning to write a vif.glmmTMB method, but I was planning to just
> add a "component" argument to make the user choose: the names of the
> vcov() components are "cond" and "zi" (and there could be a "disp"
> component if there's a non-trivial dispersion model ...)
> 
> 
> 
> 
> On 2019-05-09 3:28 p.m., Fox, John wrote:
> > Dear Mike,
> >
> > I'm not sufficiently familiar with the objects produced by glmmTMB() to
> answer definitively, and I'm also not entirely sure why you want to check for
> collinearity, but maybe the following would help:
> >
> > You can used vcov() to return the variances and covariances of coefficients
> in the various parts of the "glmmTMB" model. For example:
> >
> > ---------------- snip ------------
> >
> >> library(glmmTMB)
> >> example("glmmTMB")
> >> v <- vcov(m3)
> >> v
> > Conditional model:
> >             (Intercept)        sppPR        sppDM       sppEC-A      sppEC-L     sppDES-L
> sppDF       minedno
> > (Intercept)  0.04245503 -0.012754751 -0.013349646 -0.0125136751 -
> 0.013436038 -0.013225977 -0.01391389 -0.0305911919
> > sppPR       -0.01275475  0.077687602  0.011642383  0.0119168647
> 0.011903658  0.011843477  0.01185466  0.0013084323
> > sppDM       -0.01334965  0.011642383  0.020980164  0.0117137251
> 0.011868129  0.011728938  0.01171587  0.0015986374
> > sppEC-A     -0.01251368  0.011916865  0.011713725  0.0404883426
> 0.011904829  0.011680709  0.01185958  0.0009042868
> > sppEC-L     -0.01343604  0.011903658  0.011868129  0.0119048294
> 0.017500122  0.011744878  0.01192195  0.0016761527
> > sppDES-L    -0.01322598  0.011843477  0.011728938  0.0116807092
> 0.011744878  0.016968986  0.01186668  0.0015556516
> > sppDF       -0.01391389  0.011854661  0.011715873  0.0118595830
> 0.011921947  0.011866683  0.02370581  0.0021442905
> > minedno     -0.03059119  0.001308432  0.001598637  0.0009042868
> 0.001676153  0.001555652  0.00214429  0.0350573728
> >
> > Zero-inflation model:
> >                zi~(Intercept)     zi~sppPR     zi~sppDM   zi~sppEC-A   zi~sppEC-L
> zi~sppDES-L     zi~sppDF   zi~minedno
> > zi~(Intercept)     0.08027669 -0.055011989 -0.064230942 -0.056164325 -
> 0.064230942 -0.066122481 -0.064230942 -0.028881293
> > zi~sppPR          -0.05501199  0.157151941  0.060172003  0.062766076
> 0.060172003  0.059563719  0.060172003 -0.009287683
> > zi~sppDM          -0.06423094  0.060172003  0.122669211  0.060357133
> 0.061653087  0.061956976  0.061653087  0.004639967
> > zi~sppEC-A        -0.05616432  0.062766076  0.060357133  0.135723657
> 0.060357133  0.059862868  0.060357133 -0.007546778
> > zi~sppEC-L        -0.06423094  0.060172003  0.061653087  0.060357133
> 0.122669211  0.061956976  0.061653087  0.004639967
> > zi~sppDES-L       -0.06612248  0.059563719  0.061956976  0.059862868
> 0.061956976  0.123808814  0.061956976  0.007497634
> > zi~sppDF          -0.06423094  0.060172003  0.061653087  0.060357133
> 0.061653087  0.061956976  0.122669211  0.004639967
> > zi~minedno        -0.02888129 -0.009287683  0.004639967 -0.007546778
> 0.004639967  0.007497634  0.004639967  0.043632782
> >
> > ---------------- snip ------------
> >
> > In this case, there are two components to the model -- the conditional
> model and the zero-inflation model -- and I believe that they are independent,
> so you should be able to eliminate the intercept from each and compute VIFs
> for the other coefficients:
> >
> > ---------------- snip ------------
> >
> >> diag(solve(cov2cor(v[[1]][-1, -1])))
> >    sppPR    sppDM  sppEC-A  sppEC-L sppDES-L    sppDF  minedno
> > 1.154418 1.918674 1.340247 2.317812 2.344363 1.767413 1.006961
> >
> >> diag(solve(cov2cor(v[[2]][-1, -1])))
> >    zi~sppPR    zi~sppDM  zi~sppEC-A  zi~sppEC-L zi~sppDES-L    zi~sppDF
> zi~minedno
> >    1.503986    1.699895    1.614313    1.699895    1.707801    1.699895
> 1.079338
> >
> > ---------------- snip ------------
> >
> > Of course, it would be nice to automate this and to compute generalized
> VIFs for terms with more than one coefficient, but I don't see where to recover
> the necessary information about the structures of the component models
> from the "glmmTMB" object.
> >
> > I'm cc'ing Ben Bolker in case he has something to add (or correct).
> >
> > I hope this helps,
> >  John
> >
> > --------------------------------------
> > John Fox, Professor Emeritus
> > McMaster University
> > Hamilton, Ontario, Canada
> > Web: socialsciences.mcmaster.ca/jfox/
> >
> >
> >
> >> -----Original Message-----
> >> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-
> >> project.org] On Behalf Of Williamson, Michael via R-sig-mixed-models
> >> Sent: Thursday, May 9, 2019 11:13 AM
> >> To: r-sig-mixed-models at r-project.org
> >> Subject: [R-sig-ME] Collinearity tests (e.g. VIF) for glmmTMB package
> >>
> >> Good Afternoon,
> >>
> >> I've been running a few generalised linear mixed models on my data.
> >> Due to convergence issues, down to the size of the data set, I was
> >> recommended to switch to the glmmTMB package from the glmer function
> >> in lme4.. The models are running much better now with no more
> >> convergence issues.
> >>
> >> I'm looking to test the collinearity of my models, but the VIF
> >> function in the car package does not work with the glmmTMB package.
> >> Does anyone know of any packages or functions that can be used to
> >> calculate collinearity from model outputs generated by glmmTMB?
> >>
> >> Many thanks,
> >>
> >> Mike Williamson
> >>
> >> Email:
> >> michael.williamson at kcl.ac.uk<mailto:michael.williamson at kcl.ac.uk>
> >>
> >>
> >>
> >>
> >> 	[[alternative HTML version deleted]]
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://eur03.safelinks.protection.outlook.com/?url=https%3A%2F%2Fsta
> >> t.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-
> models&amp;data=01%7C01%
> >>
> 7Cmichael.williamson%40kcl.ac.uk%7C7f9bad7bec9849815d3308d6d4b51df
> 1%7
> >>
> C8370cf1416f34c16b83c724071654356%7C0&amp;sdata=5SjBwoSih0U5h6y
> oZvbwE
> >> ZyBf%2BLDiZqp75iboZuQzXc%3D&amp;reserved=0

From j|ox @end|ng |rom mcm@@ter@c@  Tue May 14 14:58:15 2019
From: j|ox @end|ng |rom mcm@@ter@c@ (Fox, John)
Date: Tue, 14 May 2019 12:58:15 +0000
Subject: [R-sig-ME] Collinearity tests (e.g. VIF) for glmmTMB package
In-Reply-To: <000001d50a3f$6befe940$43cfbbc0$@uke.de>
References: <9080_1557416206_x49Fajqo025294_DB7PR03MB4555314A110F206CE6E18603C2330@DB7PR03MB4555.eurprd03.prod.outlook.com>
 <ACD1644AA6C67E4FBD0C350625508EC836BA9E2C@FHSDB2D11-2.csu.mcmaster.ca>
 <cbe0dbea-871b-fa7d-2596-728bb3e1b079@gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC836BAA115@FHSDB2D11-2.csu.mcmaster.ca>
 <000001d50a3f$6befe940$43cfbbc0$@uke.de>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC836BB23D7@FHSDB2D11-2.csu.mcmaster.ca>

Dear Daniel,

> -----Original Message-----
> From: Daniel L?decke [mailto:d.luedecke at uke.de]
> Sent: Tuesday, May 14, 2019 6:26 AM
> To: Fox, John <jfox at mcmaster.ca>; 'Ben Bolker' <bbolker at gmail.com>;
> 'Williamson, Michael' <michael.williamson at kcl.ac.uk>
> Cc: r-sig-mixed-models at r-project.org
> Subject: AW: [R-sig-ME] Collinearity tests (e.g. VIF) for glmmTMB package
> 
> Hi John and Ben,
> 
> iirc, model.matrix() for glmmTMB objects returns an assign-attribute,
> however, I think you can only return the model matrix for the count-
> component, not for the zero-inflated component. I don't know if there might
> be situations where you have models that have different variables in the ZI-
> formula as compared to the count-formula, but in such cases, VIF can't be
> calculated.

There is no intrinsic reason why the predictors in the two parts of the model have to be the same.

As I mentioned in a related response, it's not the correlations among the columns of the model matrix but among the coefficients that figures in VIFs computed for models other than linear models fit by OLS. In glmmTMB, the correlations among the coefficients will differ in different parts of the model even if the model matrices are the same.

Best,
 John

> 
> Best
> Daniel
> 
> -----Urspr?ngliche Nachricht-----
> Von: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org]
> Im Auftrag von Fox, John
> Gesendet: Freitag, 10. Mai 2019 00:31
> An: Ben Bolker <bbolker at gmail.com>; Williamson, Michael
> <michael.williamson at kcl.ac.uk>
> Cc: r-sig-mixed-models at r-project.org
> Betreff: Re: [R-sig-ME] Collinearity tests (e.g. VIF) for glmmTMB package
> 
> Hi Ben,
> 
> Take a look at the vif.merMod() method from the car package:
> 
> > car:::vif.merMod
> function(mod, ...) {
>   if (any(is.na(fixef(mod))))
>     stop ("there are aliased coefficients in the model")
>   v <- as.matrix(vcov(mod))
>   assign <- attr(model.matrix(mod), "assign")
>   if (names(fixef(mod)[1]) == "(Intercept)") {
>     v <- v[-1, -1]
>     assign <- assign[-1]
>   }
>   else warning("No intercept: vifs may not be sensible.")
>   terms <- labels(terms(mod))
>   n.terms <- length(terms)
>   if (n.terms < 2) stop("model contains fewer than 2 terms")
>   R <- cov2cor(v)
>   detR <- det(R)
>   result <- matrix(0, n.terms, 3)
>   rownames(result) <- terms
>   colnames(result) <- c("GVIF", "Df", "GVIF^(1/(2*Df))")
>   for (term in 1:n.terms) {
>     subs <- which(assign == term)
>     result[term, 1] <- det(as.matrix(R[subs, subs])) *
>       det(as.matrix(R[-subs, -subs])) / detR
>     result[term, 2] <- length(subs)
>   }
>   if (all(result[, 2] == 1)) result <- result[, 1]
>   else result[, 3] <- result[, 1]^(1/(2 * result[, 2]))
>   result
> }
> 
> So for each model component, I'd need the "assign" attribute from the model
> matrix. My relatively cursory examination of objects produced by glmmTMB()
> didn't turn up whether (or where) this information is stored.
> 
> I agree that for glmmTMB() VIFs could be computed componentwise, with the
> user specifying which component(s) and perhaps a default of "all".
> 
> Best,
>  John
> 
> > -----Original Message-----
> > From: Ben Bolker [mailto:bbolker at gmail.com]
> > Sent: Thursday, May 9, 2019 3:31 PM
> > To: Fox, John <jfox at mcmaster.ca>; Williamson, Michael
> > <michael.williamson at kcl.ac.uk>
> > Cc: r-sig-mixed-models at r-project.org
> > Subject: Re: Collinearity tests (e.g. VIF) for glmmTMB package
> >
> >
> >
> >   I'm not sure what you else need to know about the component
> > structures?
> >
> > >  but I don't see where to recover the necessary information about
> > > the
> > structures of the component models from the "glmmTMB" object.
> >
> >    I've been meaning to write a vif.glmmTMB method, but I was planning
> > to just add a "component" argument to make the user choose: the names
> > of the vcov() components are "cond" and "zi" (and there could be a "disp"
> > component if there's a non-trivial dispersion model ...)
> >
> >
> >
> >
> > On 2019-05-09 3:28 p.m., Fox, John wrote:
> > > Dear Mike,
> > >
> > > I'm not sufficiently familiar with the objects produced by glmmTMB()
> > to answer definitively, and I'm also not entirely sure why you want to
> > check for collinearity, but maybe the following would help:
> > >
> > > You can used vcov() to return the variances and covariances of
> > coefficients in the various parts of the "glmmTMB" model. For example:
> > >
> > > ---------------- snip ------------
> > >
> > >> library(glmmTMB)
> > >> example("glmmTMB")
> > >> v <- vcov(m3)
> > >> v
> > > Conditional model:
> > >             (Intercept)        sppPR        sppDM       sppEC-A
> > sppEC-L     sppDES-L       sppDF       minedno
> > > (Intercept)  0.04245503 -0.012754751 -0.013349646 -0.0125136751 -
> > 0.013436038 -0.013225977 -0.01391389 -0.0305911919
> > > sppPR       -0.01275475  0.077687602  0.011642383  0.0119168647
> > 0.011903658  0.011843477  0.01185466  0.0013084323
> > > sppDM       -0.01334965  0.011642383  0.020980164  0.0117137251
> > 0.011868129  0.011728938  0.01171587  0.0015986374
> > > sppEC-A     -0.01251368  0.011916865  0.011713725  0.0404883426
> > 0.011904829  0.011680709  0.01185958  0.0009042868
> > > sppEC-L     -0.01343604  0.011903658  0.011868129  0.0119048294
> > 0.017500122  0.011744878  0.01192195  0.0016761527
> > > sppDES-L    -0.01322598  0.011843477  0.011728938  0.0116807092
> > 0.011744878  0.016968986  0.01186668  0.0015556516
> > > sppDF       -0.01391389  0.011854661  0.011715873  0.0118595830
> > 0.011921947  0.011866683  0.02370581  0.0021442905
> > > minedno     -0.03059119  0.001308432  0.001598637  0.0009042868
> > 0.001676153  0.001555652  0.00214429  0.0350573728
> > >
> > > Zero-inflation model:
> > >                zi~(Intercept)     zi~sppPR     zi~sppDM   zi~sppEC-A
> > zi~sppEC-L  zi~sppDES-L     zi~sppDF   zi~minedno
> > > zi~(Intercept)     0.08027669 -0.055011989 -0.064230942 -0.056164325 -
> > 0.064230942 -0.066122481 -0.064230942 -0.028881293
> > > zi~sppPR          -0.05501199  0.157151941  0.060172003  0.062766076
> > 0.060172003  0.059563719  0.060172003 -0.009287683
> > > zi~sppDM          -0.06423094  0.060172003  0.122669211  0.060357133
> > 0.061653087  0.061956976  0.061653087  0.004639967
> > > zi~sppEC-A        -0.05616432  0.062766076  0.060357133  0.135723657
> > 0.060357133  0.059862868  0.060357133 -0.007546778
> > > zi~sppEC-L        -0.06423094  0.060172003  0.061653087  0.060357133
> > 0.122669211  0.061956976  0.061653087  0.004639967
> > > zi~sppDES-L       -0.06612248  0.059563719  0.061956976  0.059862868
> > 0.061956976  0.123808814  0.061956976  0.007497634
> > > zi~sppDF          -0.06423094  0.060172003  0.061653087  0.060357133
> > 0.061653087  0.061956976  0.122669211  0.004639967
> > > zi~minedno        -0.02888129 -0.009287683  0.004639967 -0.007546778
> > 0.004639967  0.007497634  0.004639967  0.043632782
> > >
> > > ---------------- snip ------------
> > >
> > > In this case, there are two components to the model -- the
> > > conditional
> > model and the zero-inflation model -- and I believe that they are
> > independent, so you should be able to eliminate the intercept from
> > each and compute VIFs for the other coefficients:
> > >
> > > ---------------- snip ------------
> > >
> > >> diag(solve(cov2cor(v[[1]][-1, -1])))
> > >    sppPR    sppDM  sppEC-A  sppEC-L sppDES-L    sppDF  minedno
> > > 1.154418 1.918674 1.340247 2.317812 2.344363 1.767413 1.006961
> > >
> > >> diag(solve(cov2cor(v[[2]][-1, -1])))
> > >    zi~sppPR    zi~sppDM  zi~sppEC-A  zi~sppEC-L zi~sppDES-L
> > zi~sppDF  zi~minedno
> > >    1.503986    1.699895    1.614313    1.699895    1.707801
> > 1.699895    1.079338
> > >
> > > ---------------- snip ------------
> > >
> > > Of course, it would be nice to automate this and to compute
> > generalized VIFs for terms with more than one coefficient, but I don't
> > see where to recover the necessary information about the structures of
> > the component models from the "glmmTMB" object.
> > >
> > > I'm cc'ing Ben Bolker in case he has something to add (or correct).
> > >
> > > I hope this helps,
> > >  John
> > >
> > > --------------------------------------
> > > John Fox, Professor Emeritus
> > > McMaster University
> > > Hamilton, Ontario, Canada
> > > Web: socialsciences.mcmaster.ca/jfox/
> > >
> > >
> > >
> > >> -----Original Message-----
> > >> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-
> > >> project.org] On Behalf Of Williamson, Michael via
> > >> R-sig-mixed-models
> > >> Sent: Thursday, May 9, 2019 11:13 AM
> > >> To: r-sig-mixed-models at r-project.org
> > >> Subject: [R-sig-ME] Collinearity tests (e.g. VIF) for glmmTMB
> > >> package
> > >>
> > >> Good Afternoon,
> > >>
> > >> I've been running a few generalised linear mixed models on my data.
> > >> Due to convergence issues, down to the size of the data set, I was
> > >> recommended to switch to the glmmTMB package from the glmer
> > >> function in lme4.. The models are running much better now with no
> > >> more convergence issues.
> > >>
> > >> I'm looking to test the collinearity of my models, but the VIF
> > >> function in the car package does not work with the glmmTMB package.
> > >> Does anyone know of any packages or functions that can be used to
> > >> calculate collinearity from model outputs generated by glmmTMB?
> > >>
> > >> Many thanks,
> > >>
> > >> Mike Williamson
> > >>
> > >> Email:
> > >> michael.williamson at kcl.ac.uk<mailto:michael.williamson at kcl.ac.uk>
> > >>
> > >>
> > >>
> > >>
> > >> 	[[alternative HTML version deleted]]
> > >>
> > >> _______________________________________________
> > >> R-sig-mixed-models at r-project.org mailing list
> > >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> --
> 
> _________________________________________________________________
> ____
> 
> Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen
> Rechts; Gerichtsstand: Hamburg | www.uke.de
> Vorstandsmitglieder: Prof. Dr. Burkhard G?ke (Vorsitzender), Prof. Dr. Dr. Uwe
> Koch-Gromus, Joachim Pr?l?, Marya Verdel
> _________________________________________________________________
> ____
> 
> SAVE PAPER - THINK BEFORE PRINTING


From d@iuedecke m@iii@g oii uke@de  Tue May 14 16:18:50 2019
From: d@iuedecke m@iii@g oii uke@de (d@iuedecke m@iii@g oii uke@de)
Date: Tue, 14 May 2019 16:18:50 +0200
Subject: [R-sig-ME] Collinearity tests (e.g. VIF) for glmmTMB package
In-Reply-To: <ACD1644AA6C67E4FBD0C350625508EC836BB23D7@FHSDB2D11-2.csu.mcmaster.ca>
References: <9080_1557416206_x49Fajqo025294_DB7PR03MB4555314A110F206CE6E18603C2330@DB7PR03MB4555.eurprd03.prod.outlook.com>
 <ACD1644AA6C67E4FBD0C350625508EC836BA9E2C@FHSDB2D11-2.csu.mcmaster.ca>
 <cbe0dbea-871b-fa7d-2596-728bb3e1b079@gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC836BAA115@FHSDB2D11-2.csu.mcmaster.ca>
 <000001d50a3f$6befe940$43cfbbc0$@uke.de>
 <ACD1644AA6C67E4FBD0C350625508EC836BB23D7@FHSDB2D11-2.csu.mcmaster.ca>
Message-ID: <002701d50a5f$f4905c10$ddb11430$@uke.de>

Dear John,

sorry for confusion. I wasn't thinking of calculating correlations from the
model-matrix, but of the "assign"-attribute. That's what you use
model.matrix() for, and glmmTMB is missing the option to get the
model-matrix for the zero-inflated part, hence you need to workaround this
in order to get the assignments.

Best
Daniel

-----Urspr?ngliche Nachricht-----
Von: Fox, John <jfox at mcmaster.ca> 
Gesendet: Dienstag, 14. Mai 2019 14:58
An: Daniel L?decke <d.luedecke at uke.de>; 'Ben Bolker' <bbolker at gmail.com>;
'Williamson, Michael' <michael.williamson at kcl.ac.uk>
Cc: r-sig-mixed-models at r-project.org
Betreff: RE: [R-sig-ME] Collinearity tests (e.g. VIF) for glmmTMB package

Dear Daniel,

> -----Original Message-----
> From: Daniel L?decke [mailto:d.luedecke at uke.de]
> Sent: Tuesday, May 14, 2019 6:26 AM
> To: Fox, John <jfox at mcmaster.ca>; 'Ben Bolker' <bbolker at gmail.com>;
> 'Williamson, Michael' <michael.williamson at kcl.ac.uk>
> Cc: r-sig-mixed-models at r-project.org
> Subject: AW: [R-sig-ME] Collinearity tests (e.g. VIF) for glmmTMB package
> 
> Hi John and Ben,
> 
> iirc, model.matrix() for glmmTMB objects returns an assign-attribute,
> however, I think you can only return the model matrix for the count-
> component, not for the zero-inflated component. I don't know if there
might
> be situations where you have models that have different variables in the
ZI-
> formula as compared to the count-formula, but in such cases, VIF can't be
> calculated.

There is no intrinsic reason why the predictors in the two parts of the
model have to be the same.

As I mentioned in a related response, it's not the correlations among the
columns of the model matrix but among the coefficients that figures in VIFs
computed for models other than linear models fit by OLS. In glmmTMB, the
correlations among the coefficients will differ in different parts of the
model even if the model matrices are the same.

Best,
 John

> 
> Best
> Daniel
> 
> -----Urspr?ngliche Nachricht-----
> Von: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org]
> Im Auftrag von Fox, John
> Gesendet: Freitag, 10. Mai 2019 00:31
> An: Ben Bolker <bbolker at gmail.com>; Williamson, Michael
> <michael.williamson at kcl.ac.uk>
> Cc: r-sig-mixed-models at r-project.org
> Betreff: Re: [R-sig-ME] Collinearity tests (e.g. VIF) for glmmTMB package
> 
> Hi Ben,
> 
> Take a look at the vif.merMod() method from the car package:
> 
> > car:::vif.merMod
> function(mod, ...) {
>   if (any(is.na(fixef(mod))))
>     stop ("there are aliased coefficients in the model")
>   v <- as.matrix(vcov(mod))
>   assign <- attr(model.matrix(mod), "assign")
>   if (names(fixef(mod)[1]) == "(Intercept)") {
>     v <- v[-1, -1]
>     assign <- assign[-1]
>   }
>   else warning("No intercept: vifs may not be sensible.")
>   terms <- labels(terms(mod))
>   n.terms <- length(terms)
>   if (n.terms < 2) stop("model contains fewer than 2 terms")
>   R <- cov2cor(v)
>   detR <- det(R)
>   result <- matrix(0, n.terms, 3)
>   rownames(result) <- terms
>   colnames(result) <- c("GVIF", "Df", "GVIF^(1/(2*Df))")
>   for (term in 1:n.terms) {
>     subs <- which(assign == term)
>     result[term, 1] <- det(as.matrix(R[subs, subs])) *
>       det(as.matrix(R[-subs, -subs])) / detR
>     result[term, 2] <- length(subs)
>   }
>   if (all(result[, 2] == 1)) result <- result[, 1]
>   else result[, 3] <- result[, 1]^(1/(2 * result[, 2]))
>   result
> }
> 
> So for each model component, I'd need the "assign" attribute from the
model
> matrix. My relatively cursory examination of objects produced by glmmTMB()
> didn't turn up whether (or where) this information is stored.
> 
> I agree that for glmmTMB() VIFs could be computed componentwise, with the
> user specifying which component(s) and perhaps a default of "all".
> 
> Best,
>  John
> 
> > -----Original Message-----
> > From: Ben Bolker [mailto:bbolker at gmail.com]
> > Sent: Thursday, May 9, 2019 3:31 PM
> > To: Fox, John <jfox at mcmaster.ca>; Williamson, Michael
> > <michael.williamson at kcl.ac.uk>
> > Cc: r-sig-mixed-models at r-project.org
> > Subject: Re: Collinearity tests (e.g. VIF) for glmmTMB package
> >
> >
> >
> >   I'm not sure what you else need to know about the component
> > structures?
> >
> > >  but I don't see where to recover the necessary information about
> > > the
> > structures of the component models from the "glmmTMB" object.
> >
> >    I've been meaning to write a vif.glmmTMB method, but I was planning
> > to just add a "component" argument to make the user choose: the names
> > of the vcov() components are "cond" and "zi" (and there could be a
"disp"
> > component if there's a non-trivial dispersion model ...)
> >
> >
> >
> >
> > On 2019-05-09 3:28 p.m., Fox, John wrote:
> > > Dear Mike,
> > >
> > > I'm not sufficiently familiar with the objects produced by glmmTMB()
> > to answer definitively, and I'm also not entirely sure why you want to
> > check for collinearity, but maybe the following would help:
> > >
> > > You can used vcov() to return the variances and covariances of
> > coefficients in the various parts of the "glmmTMB" model. For example:
> > >
> > > ---------------- snip ------------
> > >
> > >> library(glmmTMB)
> > >> example("glmmTMB")
> > >> v <- vcov(m3)
> > >> v
> > > Conditional model:
> > >             (Intercept)        sppPR        sppDM       sppEC-A
> > sppEC-L     sppDES-L       sppDF       minedno
> > > (Intercept)  0.04245503 -0.012754751 -0.013349646 -0.0125136751 -
> > 0.013436038 -0.013225977 -0.01391389 -0.0305911919
> > > sppPR       -0.01275475  0.077687602  0.011642383  0.0119168647
> > 0.011903658  0.011843477  0.01185466  0.0013084323
> > > sppDM       -0.01334965  0.011642383  0.020980164  0.0117137251
> > 0.011868129  0.011728938  0.01171587  0.0015986374
> > > sppEC-A     -0.01251368  0.011916865  0.011713725  0.0404883426
> > 0.011904829  0.011680709  0.01185958  0.0009042868
> > > sppEC-L     -0.01343604  0.011903658  0.011868129  0.0119048294
> > 0.017500122  0.011744878  0.01192195  0.0016761527
> > > sppDES-L    -0.01322598  0.011843477  0.011728938  0.0116807092
> > 0.011744878  0.016968986  0.01186668  0.0015556516
> > > sppDF       -0.01391389  0.011854661  0.011715873  0.0118595830
> > 0.011921947  0.011866683  0.02370581  0.0021442905
> > > minedno     -0.03059119  0.001308432  0.001598637  0.0009042868
> > 0.001676153  0.001555652  0.00214429  0.0350573728
> > >
> > > Zero-inflation model:
> > >                zi~(Intercept)     zi~sppPR     zi~sppDM   zi~sppEC-A
> > zi~sppEC-L  zi~sppDES-L     zi~sppDF   zi~minedno
> > > zi~(Intercept)     0.08027669 -0.055011989 -0.064230942 -0.056164325 -
> > 0.064230942 -0.066122481 -0.064230942 -0.028881293
> > > zi~sppPR          -0.05501199  0.157151941  0.060172003  0.062766076
> > 0.060172003  0.059563719  0.060172003 -0.009287683
> > > zi~sppDM          -0.06423094  0.060172003  0.122669211  0.060357133
> > 0.061653087  0.061956976  0.061653087  0.004639967
> > > zi~sppEC-A        -0.05616432  0.062766076  0.060357133  0.135723657
> > 0.060357133  0.059862868  0.060357133 -0.007546778
> > > zi~sppEC-L        -0.06423094  0.060172003  0.061653087  0.060357133
> > 0.122669211  0.061956976  0.061653087  0.004639967
> > > zi~sppDES-L       -0.06612248  0.059563719  0.061956976  0.059862868
> > 0.061956976  0.123808814  0.061956976  0.007497634
> > > zi~sppDF          -0.06423094  0.060172003  0.061653087  0.060357133
> > 0.061653087  0.061956976  0.122669211  0.004639967
> > > zi~minedno        -0.02888129 -0.009287683  0.004639967 -0.007546778
> > 0.004639967  0.007497634  0.004639967  0.043632782
> > >
> > > ---------------- snip ------------
> > >
> > > In this case, there are two components to the model -- the
> > > conditional
> > model and the zero-inflation model -- and I believe that they are
> > independent, so you should be able to eliminate the intercept from
> > each and compute VIFs for the other coefficients:
> > >
> > > ---------------- snip ------------
> > >
> > >> diag(solve(cov2cor(v[[1]][-1, -1])))
> > >    sppPR    sppDM  sppEC-A  sppEC-L sppDES-L    sppDF  minedno
> > > 1.154418 1.918674 1.340247 2.317812 2.344363 1.767413 1.006961
> > >
> > >> diag(solve(cov2cor(v[[2]][-1, -1])))
> > >    zi~sppPR    zi~sppDM  zi~sppEC-A  zi~sppEC-L zi~sppDES-L
> > zi~sppDF  zi~minedno
> > >    1.503986    1.699895    1.614313    1.699895    1.707801
> > 1.699895    1.079338
> > >
> > > ---------------- snip ------------
> > >
> > > Of course, it would be nice to automate this and to compute
> > generalized VIFs for terms with more than one coefficient, but I don't
> > see where to recover the necessary information about the structures of
> > the component models from the "glmmTMB" object.
> > >
> > > I'm cc'ing Ben Bolker in case he has something to add (or correct).
> > >
> > > I hope this helps,
> > >  John
> > >
> > > --------------------------------------
> > > John Fox, Professor Emeritus
> > > McMaster University
> > > Hamilton, Ontario, Canada
> > > Web: socialsciences.mcmaster.ca/jfox/
> > >
> > >
> > >
> > >> -----Original Message-----
> > >> From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-
> > >> project.org] On Behalf Of Williamson, Michael via
> > >> R-sig-mixed-models
> > >> Sent: Thursday, May 9, 2019 11:13 AM
> > >> To: r-sig-mixed-models at r-project.org
> > >> Subject: [R-sig-ME] Collinearity tests (e.g. VIF) for glmmTMB
> > >> package
> > >>
> > >> Good Afternoon,
> > >>
> > >> I've been running a few generalised linear mixed models on my data.
> > >> Due to convergence issues, down to the size of the data set, I was
> > >> recommended to switch to the glmmTMB package from the glmer
> > >> function in lme4.. The models are running much better now with no
> > >> more convergence issues.
> > >>
> > >> I'm looking to test the collinearity of my models, but the VIF
> > >> function in the car package does not work with the glmmTMB package.
> > >> Does anyone know of any packages or functions that can be used to
> > >> calculate collinearity from model outputs generated by glmmTMB?
> > >>
> > >> Many thanks,
> > >>
> > >> Mike Williamson
> > >>
> > >> Email:
> > >> michael.williamson at kcl.ac.uk<mailto:michael.williamson at kcl.ac.uk>
> > >>
> > >>
> > >>
> > >>
> > >> 	[[alternative HTML version deleted]]
> > >>
> > >> _______________________________________________
> > >> R-sig-mixed-models at r-project.org mailing list
> > >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> --
> 
> _________________________________________________________________
> ____
> 
> Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen
> Rechts; Gerichtsstand: Hamburg | www.uke.de
> Vorstandsmitglieder: Prof. Dr. Burkhard G?ke (Vorsitzender), Prof. Dr. Dr.
Uwe
> Koch-Gromus, Joachim Pr?l?, Marya Verdel
> _________________________________________________________________
> ____
> 
> SAVE PAPER - THINK BEFORE PRINTING


--

_____________________________________________________________________

Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen Rechts; Gerichtsstand: Hamburg | www.uke.de
Vorstandsmitglieder: Prof. Dr. Burkhard G?ke (Vorsitzender), Prof. Dr. Dr. Uwe Koch-Gromus, Joachim Pr?l?, Marya Verdel
_____________________________________________________________________

SAVE PAPER - THINK BEFORE PRINTING


From gerr|t@e|chner @end|ng |rom m@th@un|-g|e@@en@de  Wed May 15 14:01:44 2019
From: gerr|t@e|chner @end|ng |rom m@th@un|-g|e@@en@de (Gerrit Eichner)
Date: Wed, 15 May 2019 14:01:44 +0200
Subject: [R-sig-ME] lme4: qqmath.ranef.mer fails for lmer model with more
 than one random-effects term for a given grouping factor
Message-ID: <782e39f3-811d-dd70-52db-3db651d2a456@math.uni-giessen.de>

Dear lme4-experts,

for an lmer model with more than one random-effects term for a
given grouping factor as in the following example taken from
qqmath.ranef.mer's help page

fm2 <- lmer(Reaction ~ Days + (1|Subject) + (0+Days|Subject),
             sleepstudy)

"caterpillar plots" of the random effects applying dotplot,
i.e., dotplot.ranef.mer, to the result of a call to ranef
with condVar = TRUE appear as expected:

dotplot(ranef(fm2, condVar = TRUE))


But trying the analogue for the respective Q-Q plots using qqmath,
i.e., qqmath.ranef.mer, throws an error:

qqmath(ranef(fm2, condVar = TRUE))

Error in seq_len(d[1]) :
   argument must be coercible to non-negative integer
In addition: Warning message:
In seq_len(d[1]) : first element used of 'length.out' argument


Does anyone happen to already have a work-around for this?

(It appears to me that the problem originates in the structure
of the postVar attribute of ranef(fm2, condVar = TRUE) in contrast
to its structure of ranef(fm1, condVar = TRUE) where fm1 <-
lmer(Reaction ~ Days + (Days|Subject), sleepstudy).)

Thanks for any hints.

  Best regards  --  Gerrit

PS: sessionInfo()

R version 3.5.3 (2019-03-11)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 10 x64 (build 17763)

Matrix products: default

locale:
[1] LC_COLLATE=German_Germany.1252  LC_CTYPE=German_Germany.1252
[3] LC_MONETARY=German_Germany.1252 LC_NUMERIC=C
[5] LC_TIME=German_Germany.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] ggplot2_3.1.1   lattice_0.20-38 lme4_1.1-21     Matrix_1.2-17

loaded via a namespace (and not attached):
  [1] Rcpp_1.0.1       magrittr_1.5     splines_3.5.3    MASS_7.3-51.3
  [5] tidyselect_0.2.5 munsell_0.5.0    colorspace_1.4-1 R6_2.4.0
  [9] rlang_0.3.4      minqa_1.2.4      plyr_1.8.4       dplyr_0.8.0.1
[13] tools_3.5.3      grid_3.5.3       gtable_0.3.0     nlme_3.1-137
[17] withr_2.1.2      assertthat_0.2.1 lazyeval_0.2.2   tibble_2.1.1
[21] crayon_1.3.4     purrr_0.3.2      nloptr_1.2.1     glue_1.3.1
[25] labeling_0.3     compiler_3.5.3   pillar_1.3.1     scales_1.0.0
[29] boot_1.3-20      pkgconfig_2.0.2


---------------------------------------------------------------------
Dr. Gerrit Eichner                   Mathematical Institute, Room 212
gerrit.eichner at math.uni-giessen.de   Justus-Liebig-University Giessen
Tel: +49-(0)641-99-32104          Arndtstr. 2, 35392 Giessen, Germany
http://www.uni-giessen.de/eichner


From M@@rten@Jung @end|ng |rom m@||box@tu-dre@den@de  Wed May 15 14:18:47 2019
From: M@@rten@Jung @end|ng |rom m@||box@tu-dre@den@de (Maarten Jung)
Date: Wed, 15 May 2019 14:18:47 +0200
Subject: [R-sig-ME] 
 lme4: qqmath.ranef.mer fails for lmer model with more
 than one random-effects term for a given grouping factor
In-Reply-To: <782e39f3-811d-dd70-52db-3db651d2a456@math.uni-giessen.de>
References: <782e39f3-811d-dd70-52db-3db651d2a456@math.uni-giessen.de>
Message-ID: <CAHr4Dyd=g=h6MoXnNdU42SXjOvw_hBuFsNjc4zuqRoMVbq-03A@mail.gmail.com>

Dear Gerrit,

I encountered the same problem a while ago and wrote a custom function
based on this [1] SO post that should work (see plot-Re.txt attached).

Best regards,
Maarten

[1] https://stackoverflow.com/a/16511206




On Wed, May 15, 2019 at 2:03 PM Gerrit Eichner
<gerrit.eichner at math.uni-giessen.de> wrote:
>
> Dear lme4-experts,
>
> for an lmer model with more than one random-effects term for a
> given grouping factor as in the following example taken from
> qqmath.ranef.mer's help page
>
> fm2 <- lmer(Reaction ~ Days + (1|Subject) + (0+Days|Subject),
>              sleepstudy)
>
> "caterpillar plots" of the random effects applying dotplot,
> i.e., dotplot.ranef.mer, to the result of a call to ranef
> with condVar = TRUE appear as expected:
>
> dotplot(ranef(fm2, condVar = TRUE))
>
>
> But trying the analogue for the respective Q-Q plots using qqmath,
> i.e., qqmath.ranef.mer, throws an error:
>
> qqmath(ranef(fm2, condVar = TRUE))
>
> Error in seq_len(d[1]) :
>    argument must be coercible to non-negative integer
> In addition: Warning message:
> In seq_len(d[1]) : first element used of 'length.out' argument
>
>
> Does anyone happen to already have a work-around for this?
>
> (It appears to me that the problem originates in the structure
> of the postVar attribute of ranef(fm2, condVar = TRUE) in contrast
> to its structure of ranef(fm1, condVar = TRUE) where fm1 <-
> lmer(Reaction ~ Days + (Days|Subject), sleepstudy).)
>
> Thanks for any hints.
>
>   Best regards  --  Gerrit
>
> PS: sessionInfo()
>
> R version 3.5.3 (2019-03-11)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows 10 x64 (build 17763)
>
> Matrix products: default
>
> locale:
> [1] LC_COLLATE=German_Germany.1252  LC_CTYPE=German_Germany.1252
> [3] LC_MONETARY=German_Germany.1252 LC_NUMERIC=C
> [5] LC_TIME=German_Germany.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] ggplot2_3.1.1   lattice_0.20-38 lme4_1.1-21     Matrix_1.2-17
>
> loaded via a namespace (and not attached):
>   [1] Rcpp_1.0.1       magrittr_1.5     splines_3.5.3    MASS_7.3-51.3
>   [5] tidyselect_0.2.5 munsell_0.5.0    colorspace_1.4-1 R6_2.4.0
>   [9] rlang_0.3.4      minqa_1.2.4      plyr_1.8.4       dplyr_0.8.0.1
> [13] tools_3.5.3      grid_3.5.3       gtable_0.3.0     nlme_3.1-137
> [17] withr_2.1.2      assertthat_0.2.1 lazyeval_0.2.2   tibble_2.1.1
> [21] crayon_1.3.4     purrr_0.3.2      nloptr_1.2.1     glue_1.3.1
> [25] labeling_0.3     compiler_3.5.3   pillar_1.3.1     scales_1.0.0
> [29] boot_1.3-20      pkgconfig_2.0.2
>
>
> ---------------------------------------------------------------------
> Dr. Gerrit Eichner                   Mathematical Institute, Room 212
> gerrit.eichner at math.uni-giessen.de   Justus-Liebig-University Giessen
> Tel: +49-(0)641-99-32104          Arndtstr. 2, 35392 Giessen, Germany
> http://www.uni-giessen.de/eichner
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: plot-RE.txt
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20190515/467ea7fa/attachment.txt>

From gerr|t@e|chner @end|ng |rom m@th@un|-g|e@@en@de  Thu May 16 08:46:30 2019
From: gerr|t@e|chner @end|ng |rom m@th@un|-g|e@@en@de (Gerrit Eichner)
Date: Thu, 16 May 2019 08:46:30 +0200
Subject: [R-sig-ME] 
 lme4: qqmath.ranef.mer fails for lmer model with more
 than one random-effects term for a given grouping factor
In-Reply-To: <CAHr4Dyd=g=h6MoXnNdU42SXjOvw_hBuFsNjc4zuqRoMVbq-03A@mail.gmail.com>
References: <782e39f3-811d-dd70-52db-3db651d2a456@math.uni-giessen.de>
 <CAHr4Dyd=g=h6MoXnNdU42SXjOvw_hBuFsNjc4zuqRoMVbq-03A@mail.gmail.com>
Message-ID: <f9fc08a0-af52-d842-0420-95d4fce7ad44@math.uni-giessen.de>

Thank you very much, Maarten!

It works like a charm (and saved me a a lot of time). :-)
Also thx for the reference to the SO post.

  Best regards  --  Gerrit

---------------------------------------------------------------------
Dr. Gerrit Eichner                   Mathematical Institute, Room 212
gerrit.eichner at math.uni-giessen.de   Justus-Liebig-University Giessen
Tel: +49-(0)641-99-32104          Arndtstr. 2, 35392 Giessen, Germany
http://www.uni-giessen.de/eichner
---------------------------------------------------------------------

Am 15.05.2019 um 14:18 schrieb Maarten Jung:
> Dear Gerrit,
> 
> I encountered the same problem a while ago and wrote a custom function
> based on this [1] SO post that should work (see plot-Re.txt attached).
> 
> Best regards,
> Maarten
> 
> [1] https://stackoverflow.com/a/16511206
> 
> 
> 
> 
> On Wed, May 15, 2019 at 2:03 PM Gerrit Eichner
> <gerrit.eichner at math.uni-giessen.de> wrote:
>>
>> Dear lme4-experts,
>>
>> for an lmer model with more than one random-effects term for a
>> given grouping factor as in the following example taken from
>> qqmath.ranef.mer's help page
>>
>> fm2 <- lmer(Reaction ~ Days + (1|Subject) + (0+Days|Subject),
>>               sleepstudy)
>>
>> "caterpillar plots" of the random effects applying dotplot,
>> i.e., dotplot.ranef.mer, to the result of a call to ranef
>> with condVar = TRUE appear as expected:
>>
>> dotplot(ranef(fm2, condVar = TRUE))
>>
>>
>> But trying the analogue for the respective Q-Q plots using qqmath,
>> i.e., qqmath.ranef.mer, throws an error:
>>
>> qqmath(ranef(fm2, condVar = TRUE))
>>
>> Error in seq_len(d[1]) :
>>     argument must be coercible to non-negative integer
>> In addition: Warning message:
>> In seq_len(d[1]) : first element used of 'length.out' argument
>>
>>
>> Does anyone happen to already have a work-around for this?
>>
>> (It appears to me that the problem originates in the structure
>> of the postVar attribute of ranef(fm2, condVar = TRUE) in contrast
>> to its structure of ranef(fm1, condVar = TRUE) where fm1 <-
>> lmer(Reaction ~ Days + (Days|Subject), sleepstudy).)
>>
>> Thanks for any hints.
>>
>>    Best regards  --  Gerrit
>>
>> PS: sessionInfo()
>>
>> R version 3.5.3 (2019-03-11)
>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>> Running under: Windows 10 x64 (build 17763)
>>
>> Matrix products: default
>>
>> locale:
>> [1] LC_COLLATE=German_Germany.1252  LC_CTYPE=German_Germany.1252
>> [3] LC_MONETARY=German_Germany.1252 LC_NUMERIC=C
>> [5] LC_TIME=German_Germany.1252
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> other attached packages:
>> [1] ggplot2_3.1.1   lattice_0.20-38 lme4_1.1-21     Matrix_1.2-17
>>
>> loaded via a namespace (and not attached):
>>    [1] Rcpp_1.0.1       magrittr_1.5     splines_3.5.3    MASS_7.3-51.3
>>    [5] tidyselect_0.2.5 munsell_0.5.0    colorspace_1.4-1 R6_2.4.0
>>    [9] rlang_0.3.4      minqa_1.2.4      plyr_1.8.4       dplyr_0.8.0.1
>> [13] tools_3.5.3      grid_3.5.3       gtable_0.3.0     nlme_3.1-137
>> [17] withr_2.1.2      assertthat_0.2.1 lazyeval_0.2.2   tibble_2.1.1
>> [21] crayon_1.3.4     purrr_0.3.2      nloptr_1.2.1     glue_1.3.1
>> [25] labeling_0.3     compiler_3.5.3   pillar_1.3.1     scales_1.0.0
>> [29] boot_1.3-20      pkgconfig_2.0.2
>>
>>
>> ---------------------------------------------------------------------
>> Dr. Gerrit Eichner                   Mathematical Institute, Room 212
>> gerrit.eichner at math.uni-giessen.de   Justus-Liebig-University Giessen
>> Tel: +49-(0)641-99-32104          Arndtstr. 2, 35392 Giessen, Germany
>> http://www.uni-giessen.de/eichner
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From m@p|no|@10 @end|ng |rom gm@||@com  Sat May 18 01:56:01 2019
From: m@p|no|@10 @end|ng |rom gm@||@com (=?UTF-8?Q?Manuel_Sp=C3=ADnola?=)
Date: Fri, 17 May 2019 17:56:01 -0600
Subject: [R-sig-ME] Mixed model parameterization
Message-ID: <CABkCotRU8z=OpntgwdBxw+c9G=SH1_KyCZwUUEZmr_Rn1Es2Ww@mail.gmail.com>

Dear list members,

I am measuring an index in plots, in different hours, different days, and
different months in 3 different "habitats".

12 plots by "habitats".

I would like to estimate the mean index in the 3 environments.

Is this model appropriate to achieve my goal?

model <- lmer(index ~  habitat + (1 | plot/hour/day/month), data = mydata,
REML = FALSE)

Best,

Manuel

-- 
*Manuel Sp?nola, Ph.D.*
Instituto Internacional en Conservaci?n y Manejo de Vida Silvestre
Universidad Nacional
Apartado 1350-3000
Heredia
COSTA RICA
mspinola at una.cr <mspinola at una.ac.cr>
mspinola10 at gmail.com
Tel?fono: (506) 8706 - 4662
Personal website: Lobito de r?o <https://sites.google.com/site/lobitoderio/>
Institutional website: ICOMVIS <http://www.icomvis.una.ac.cr/>

	[[alternative HTML version deleted]]


From th|erry@onke||nx @end|ng |rom |nbo@be  Mon May 20 10:00:03 2019
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Mon, 20 May 2019 10:00:03 +0200
Subject: [R-sig-ME] Mixed model parameterization
In-Reply-To: <CABkCotRU8z=OpntgwdBxw+c9G=SH1_KyCZwUUEZmr_Rn1Es2Ww@mail.gmail.com>
References: <CABkCotRU8z=OpntgwdBxw+c9G=SH1_KyCZwUUEZmr_Rn1Es2Ww@mail.gmail.com>
Message-ID: <CAJuCY5zxyaES-zCKBL_0szqiecfgw5NT8cao8DW1G1vpi9aL+w@mail.gmail.com>

Dear Manuel,

You'll need to think about the structure of your random effects. Your
current random effect structure is (1|plot) + (1|plot:hour) +
(1|plot:hour:day) + (1|plot:hour:day:month). Which might not be what you
had in mind.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op za 18 mei 2019 om 01:56 schreef Manuel Sp?nola <mspinola10 at gmail.com>:

> Dear list members,
>
> I am measuring an index in plots, in different hours, different days, and
> different months in 3 different "habitats".
>
> 12 plots by "habitats".
>
> I would like to estimate the mean index in the 3 environments.
>
> Is this model appropriate to achieve my goal?
>
> model <- lmer(index ~  habitat + (1 | plot/hour/day/month), data = mydata,
> REML = FALSE)
>
> Best,
>
> Manuel
>
> --
> *Manuel Sp?nola, Ph.D.*
> Instituto Internacional en Conservaci?n y Manejo de Vida Silvestre
> Universidad Nacional
> Apartado 1350-3000
> Heredia
> COSTA RICA
> mspinola at una.cr <mspinola at una.ac.cr>
> mspinola10 at gmail.com
> Tel?fono: (506) 8706 - 4662
> Personal website: Lobito de r?o <
> https://sites.google.com/site/lobitoderio/>
> Institutional website: ICOMVIS <http://www.icomvis.una.ac.cr/>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From m@p|no|@10 @end|ng |rom gm@||@com  Mon May 20 15:54:06 2019
From: m@p|no|@10 @end|ng |rom gm@||@com (=?UTF-8?Q?Manuel_Sp=C3=ADnola?=)
Date: Mon, 20 May 2019 07:54:06 -0600
Subject: [R-sig-ME] Mixed model parameterization
In-Reply-To: <CAJuCY5zxyaES-zCKBL_0szqiecfgw5NT8cao8DW1G1vpi9aL+w@mail.gmail.com>
References: <CABkCotRU8z=OpntgwdBxw+c9G=SH1_KyCZwUUEZmr_Rn1Es2Ww@mail.gmail.com>
 <CAJuCY5zxyaES-zCKBL_0szqiecfgw5NT8cao8DW1G1vpi9aL+w@mail.gmail.com>
Message-ID: <CABkCotSe6Z4zs3xYz1s5WCJaLD++FYtte_f-BYBoh6deh=u_3Q@mail.gmail.com>

Thank you very much Thierry.

I just only want to accomodate the nested repeated measure of my sampling.

I measure the index at the same plot, several times in an hour, several
days and during several month.

3 "habitats", within each habitat 12 plots, and on each plot I measured the
index several times, within hours, several days and several months.

I am not interested in the evolution of the index in time, just to account
for the repeated measure of my design (I measured the index hundreds of
time on each plot).

Maybe I don't need to worry about hour, day and month?

Manuel

El lun., 20 may. 2019 a las 2:00, Thierry Onkelinx (<
thierry.onkelinx at inbo.be>) escribi?:

> Dear Manuel,
>
> You'll need to think about the structure of your random effects. Your
> current random effect structure is (1|plot) + (1|plot:hour) +
> (1|plot:hour:day) + (1|plot:hour:day:month). Which might not be what you
> had in mind.
>
> Best regards,
>
> ir. Thierry Onkelinx
> Statisticus / Statistician
>
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
> FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Havenlaan 88 bus 73, 1000 Brussel
> www.inbo.be
>
>
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> ///////////////////////////////////////////////////////////////////////////////////////////
>
> <https://www.inbo.be>
>
>
> Op za 18 mei 2019 om 01:56 schreef Manuel Sp?nola <mspinola10 at gmail.com>:
>
>> Dear list members,
>>
>> I am measuring an index in plots, in different hours, different days, and
>> different months in 3 different "habitats".
>>
>> 12 plots by "habitats".
>>
>> I would like to estimate the mean index in the 3 environments.
>>
>> Is this model appropriate to achieve my goal?
>>
>> model <- lmer(index ~  habitat + (1 | plot/hour/day/month), data = mydata,
>> REML = FALSE)
>>
>> Best,
>>
>> Manuel
>>
>> --
>> *Manuel Sp?nola, Ph.D.*
>> Instituto Internacional en Conservaci?n y Manejo de Vida Silvestre
>> Universidad Nacional
>> Apartado 1350-3000
>> Heredia
>> COSTA RICA
>> mspinola at una.cr <mspinola at una.ac.cr>
>> mspinola10 at gmail.com
>> Tel?fono: (506) 8706 - 4662
>> Personal website: Lobito de r?o <
>> https://sites.google.com/site/lobitoderio/>
>> Institutional website: ICOMVIS <http://www.icomvis.una.ac.cr/>
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>

-- 
*Manuel Sp?nola, Ph.D.*
Instituto Internacional en Conservaci?n y Manejo de Vida Silvestre
Universidad Nacional
Apartado 1350-3000
Heredia
COSTA RICA
mspinola at una.cr <mspinola at una.ac.cr>
mspinola10 at gmail.com
Tel?fono: (506) 8706 - 4662
Personal website: Lobito de r?o <https://sites.google.com/site/lobitoderio/>
Institutional website: ICOMVIS <http://www.icomvis.una.ac.cr/>

	[[alternative HTML version deleted]]


From @@|v@dor@@nchezco|on @end|ng |rom prod|gy@net@mx  Mon May 20 16:07:40 2019
From: @@|v@dor@@nchezco|on @end|ng |rom prod|gy@net@mx (=?utf-8?Q?Salvador_S=C3=A1nchez-Col=C3=B3n?=)
Date: Mon, 20 May 2019 09:07:40 -0500
Subject: [R-sig-ME] Mixed model parameterization
In-Reply-To: <CABkCotSe6Z4zs3xYz1s5WCJaLD++FYtte_f-BYBoh6deh=u_3Q@mail.gmail.com>
References: <CABkCotRU8z=OpntgwdBxw+c9G=SH1_KyCZwUUEZmr_Rn1Es2Ww@mail.gmail.com>
 <CAJuCY5zxyaES-zCKBL_0szqiecfgw5NT8cao8DW1G1vpi9aL+w@mail.gmail.com>
 <CABkCotSe6Z4zs3xYz1s5WCJaLD++FYtte_f-BYBoh6deh=u_3Q@mail.gmail.com>
Message-ID: <8BD63A09-8957-43ED-A67F-FBC9A3AED7CA@prodigy.net.mx>

Hola Manuel:

If you are not interested in examining the between-hours or between-days variability, then you might consider analyzing the average of your hourly values and thus simplify the model. 

Best regards,

Salvador 

Salvador S?NCHEZ-COL?N 


> On May 20, 2019, at 8:54 AM, Manuel Sp?nola <mspinola10 at gmail.com> wrote:
> 
> Thank you very much Thierry.
> 
> I just only want to accomodate the nested repeated measure of my sampling.
> 
> I measure the index at the same plot, several times in an hour, several
> days and during several month.
> 
> 3 "habitats", within each habitat 12 plots, and on each plot I measured the
> index several times, within hours, several days and several months.
> 
> I am not interested in the evolution of the index in time, just to account
> for the repeated measure of my design (I measured the index hundreds of
> time on each plot).
> 
> Maybe I don't need to worry about hour, day and month?
> 
> Manuel
> 
> El lun., 20 may. 2019 a las 2:00, Thierry Onkelinx (<
> thierry.onkelinx at inbo.be>) escribi?:
> 
>> Dear Manuel,
>> 
>> You'll need to think about the structure of your random effects. Your
>> current random effect structure is (1|plot) + (1|plot:hour) +
>> (1|plot:hour:day) + (1|plot:hour:day:month). Which might not be what you
>> had in mind.
>> 
>> Best regards,
>> 
>> ir. Thierry Onkelinx
>> Statisticus / Statistician
>> 
>> Vlaamse Overheid / Government of Flanders
>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
>> FOREST
>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
>> thierry.onkelinx at inbo.be
>> Havenlaan 88 bus 73, 1000 Brussel
>> www.inbo.be
>> 
>> 
>> ///////////////////////////////////////////////////////////////////////////////////////////
>> To call in the statistician after the experiment is done may be no more
>> than asking him to perform a post-mortem examination: he may be able to say
>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does not
>> ensure that a reasonable answer can be extracted from a given body of data.
>> ~ John Tukey
>> 
>> ///////////////////////////////////////////////////////////////////////////////////////////
>> 
>> <https://www.inbo.be>
>> 
>> 
>> Op za 18 mei 2019 om 01:56 schreef Manuel Sp?nola <mspinola10 at gmail.com>:
>> 
>>> Dear list members,
>>> 
>>> I am measuring an index in plots, in different hours, different days, and
>>> different months in 3 different "habitats".
>>> 
>>> 12 plots by "habitats".
>>> 
>>> I would like to estimate the mean index in the 3 environments.
>>> 
>>> Is this model appropriate to achieve my goal?
>>> 
>>> model <- lmer(index ~  habitat + (1 | plot/hour/day/month), data = mydata,
>>> REML = FALSE)
>>> 
>>> Best,
>>> 
>>> Manuel
>>> 
>>> --
>>> *Manuel Sp?nola, Ph.D.*
>>> Instituto Internacional en Conservaci?n y Manejo de Vida Silvestre
>>> Universidad Nacional
>>> Apartado 1350-3000
>>> Heredia
>>> COSTA RICA
>>> mspinola at una.cr <mspinola at una.ac.cr>
>>> mspinola10 at gmail.com
>>> Tel?fono: (506) 8706 - 4662
>>> Personal website: Lobito de r?o <
>>> https://sites.google.com/site/lobitoderio/>
>>> Institutional website: ICOMVIS <http://www.icomvis.una.ac.cr/>
>>> 
>>>        [[alternative HTML version deleted]]
>>> 
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> 
>> 
> 
> -- 
> *Manuel Sp?nola, Ph.D.*
> Instituto Internacional en Conservaci?n y Manejo de Vida Silvestre
> Universidad Nacional
> Apartado 1350-3000
> Heredia
> COSTA RICA
> mspinola at una.cr <mspinola at una.ac.cr>
> mspinola10 at gmail.com
> Tel?fono: (506) 8706 - 4662
> Personal website: Lobito de r?o <https://sites.google.com/site/lobitoderio/>
> Institutional website: ICOMVIS <http://www.icomvis.una.ac.cr/>
> 
>    [[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From m@p|no|@10 @end|ng |rom gm@||@com  Mon May 20 16:18:46 2019
From: m@p|no|@10 @end|ng |rom gm@||@com (=?UTF-8?Q?Manuel_Sp=C3=ADnola?=)
Date: Mon, 20 May 2019 08:18:46 -0600
Subject: [R-sig-ME] Mixed model parameterization
In-Reply-To: <8BD63A09-8957-43ED-A67F-FBC9A3AED7CA@prodigy.net.mx>
References: <CABkCotRU8z=OpntgwdBxw+c9G=SH1_KyCZwUUEZmr_Rn1Es2Ww@mail.gmail.com>
 <CAJuCY5zxyaES-zCKBL_0szqiecfgw5NT8cao8DW1G1vpi9aL+w@mail.gmail.com>
 <CABkCotSe6Z4zs3xYz1s5WCJaLD++FYtte_f-BYBoh6deh=u_3Q@mail.gmail.com>
 <8BD63A09-8957-43ED-A67F-FBC9A3AED7CA@prodigy.net.mx>
Message-ID: <CABkCotQQAbekr+7snhNpbhxixwF=0gJQAeCWbMQxhfo3wij+QA@mail.gmail.com>

Thank you Salvador,

So, doing this:

model <- lmer(index ~  habitat + (1 | plot), data = mydata, REML = FALSE)

Manuel

El lun., 20 may. 2019 a las 8:08, Salvador S?nchez-Col?n (<
salvadorsanchezcolon at prodigy.net.mx>) escribi?:

> Hola Manuel:
>
> If you are not interested in examining the between-hours or between-days
> variability, then you might consider analyzing the average of your hourly
> values and thus simplify the model.
>
> Best regards,
>
> Salvador
>
> Salvador S?NCHEZ-COL?N
>
>
> > On May 20, 2019, at 8:54 AM, Manuel Sp?nola <mspinola10 at gmail.com>
> wrote:
> >
> > Thank you very much Thierry.
> >
> > I just only want to accomodate the nested repeated measure of my
> sampling.
> >
> > I measure the index at the same plot, several times in an hour, several
> > days and during several month.
> >
> > 3 "habitats", within each habitat 12 plots, and on each plot I measured
> the
> > index several times, within hours, several days and several months.
> >
> > I am not interested in the evolution of the index in time, just to
> account
> > for the repeated measure of my design (I measured the index hundreds of
> > time on each plot).
> >
> > Maybe I don't need to worry about hour, day and month?
> >
> > Manuel
> >
> > El lun., 20 may. 2019 a las 2:00, Thierry Onkelinx (<
> > thierry.onkelinx at inbo.be>) escribi?:
> >
> >> Dear Manuel,
> >>
> >> You'll need to think about the structure of your random effects. Your
> >> current random effect structure is (1|plot) + (1|plot:hour) +
> >> (1|plot:hour:day) + (1|plot:hour:day:month). Which might not be what you
> >> had in mind.
> >>
> >> Best regards,
> >>
> >> ir. Thierry Onkelinx
> >> Statisticus / Statistician
> >>
> >> Vlaamse Overheid / Government of Flanders
> >> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
> AND
> >> FOREST
> >> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> >> thierry.onkelinx at inbo.be
> >> Havenlaan 88 bus 73, 1000 Brussel
> >> www.inbo.be
> >>
> >>
> >>
> ///////////////////////////////////////////////////////////////////////////////////////////
> >> To call in the statistician after the experiment is done may be no more
> >> than asking him to perform a post-mortem examination: he may be able to
> say
> >> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> >> The plural of anecdote is not data. ~ Roger Brinner
> >> The combination of some data and an aching desire for an answer does not
> >> ensure that a reasonable answer can be extracted from a given body of
> data.
> >> ~ John Tukey
> >>
> >>
> ///////////////////////////////////////////////////////////////////////////////////////////
> >>
> >> <https://www.inbo.be>
> >>
> >>
> >> Op za 18 mei 2019 om 01:56 schreef Manuel Sp?nola <mspinola10 at gmail.com
> >:
> >>
> >>> Dear list members,
> >>>
> >>> I am measuring an index in plots, in different hours, different days,
> and
> >>> different months in 3 different "habitats".
> >>>
> >>> 12 plots by "habitats".
> >>>
> >>> I would like to estimate the mean index in the 3 environments.
> >>>
> >>> Is this model appropriate to achieve my goal?
> >>>
> >>> model <- lmer(index ~  habitat + (1 | plot/hour/day/month), data =
> mydata,
> >>> REML = FALSE)
> >>>
> >>> Best,
> >>>
> >>> Manuel
> >>>
> >>> --
> >>> *Manuel Sp?nola, Ph.D.*
> >>> Instituto Internacional en Conservaci?n y Manejo de Vida Silvestre
> >>> Universidad Nacional
> >>> Apartado 1350-3000
> >>> Heredia
> >>> COSTA RICA
> >>> mspinola at una.cr <mspinola at una.ac.cr>
> >>> mspinola10 at gmail.com
> >>> Tel?fono: (506) 8706 - 4662
> >>> Personal website: Lobito de r?o <
> >>> https://sites.google.com/site/lobitoderio/>
> >>> Institutional website: ICOMVIS <http://www.icomvis.una.ac.cr/>
> >>>
> >>>        [[alternative HTML version deleted]]
> >>>
> >>> _______________________________________________
> >>> R-sig-mixed-models at r-project.org mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>>
> >>
> >
> > --
> > *Manuel Sp?nola, Ph.D.*
> > Instituto Internacional en Conservaci?n y Manejo de Vida Silvestre
> > Universidad Nacional
> > Apartado 1350-3000
> > Heredia
> > COSTA RICA
> > mspinola at una.cr <mspinola at una.ac.cr>
> > mspinola10 at gmail.com
> > Tel?fono: (506) 8706 - 4662
> > Personal website: Lobito de r?o <
> https://sites.google.com/site/lobitoderio/>
> > Institutional website: ICOMVIS <http://www.icomvis.una.ac.cr/>
> >
> >    [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>

-- 
*Manuel Sp?nola, Ph.D.*
Instituto Internacional en Conservaci?n y Manejo de Vida Silvestre
Universidad Nacional
Apartado 1350-3000
Heredia
COSTA RICA
mspinola at una.cr <mspinola at una.ac.cr>
mspinola10 at gmail.com
Tel?fono: (506) 8706 - 4662
Personal website: Lobito de r?o <https://sites.google.com/site/lobitoderio/>
Institutional website: ICOMVIS <http://www.icomvis.una.ac.cr/>

	[[alternative HTML version deleted]]


From th|erry@onke||nx @end|ng |rom |nbo@be  Mon May 20 16:59:35 2019
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Mon, 20 May 2019 16:59:35 +0200
Subject: [R-sig-ME] Mixed model parameterization
In-Reply-To: <8BD63A09-8957-43ED-A67F-FBC9A3AED7CA@prodigy.net.mx>
References: <CABkCotRU8z=OpntgwdBxw+c9G=SH1_KyCZwUUEZmr_Rn1Es2Ww@mail.gmail.com>
 <CAJuCY5zxyaES-zCKBL_0szqiecfgw5NT8cao8DW1G1vpi9aL+w@mail.gmail.com>
 <CABkCotSe6Z4zs3xYz1s5WCJaLD++FYtte_f-BYBoh6deh=u_3Q@mail.gmail.com>
 <8BD63A09-8957-43ED-A67F-FBC9A3AED7CA@prodigy.net.mx>
Message-ID: <CAJuCY5wg74WGwxq_tvGua9jqyUpqDyYHfHfao0kK=w6KYOy9Kg@mail.gmail.com>

Aggregating the data will remove al lot of information. And might introduce
bias in case of an unbalanced design.

You need to think about the (combination of) variables which have a common
effect. (1|plot) + (1|plot:hour) assumes a plot effect and an effect of
each combination of plot and hour, but no common hour effect.

Days are nested in months. The corresponding random effect is (1|month) +
(1|month:day). You have (1|day) + (1|day:month) which is nonsense.

You really need to do some reading on mixed models. I recommend Zuur et al
(2009) Mixed Effects Models and Extensions in Ecology with R

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op ma 20 mei 2019 om 16:07 schreef Salvador S?nchez-Col?n <
salvadorsanchezcolon at prodigy.net.mx>:

> Hola Manuel:
>
> If you are not interested in examining the between-hours or between-days
> variability, then you might consider analyzing the average of your hourly
> values and thus simplify the model.
>
> Best regards,
>
> Salvador
>
> Salvador S?NCHEZ-COL?N
>
>
> > On May 20, 2019, at 8:54 AM, Manuel Sp?nola <mspinola10 at gmail.com>
> wrote:
> >
> > Thank you very much Thierry.
> >
> > I just only want to accomodate the nested repeated measure of my
> sampling.
> >
> > I measure the index at the same plot, several times in an hour, several
> > days and during several month.
> >
> > 3 "habitats", within each habitat 12 plots, and on each plot I measured
> the
> > index several times, within hours, several days and several months.
> >
> > I am not interested in the evolution of the index in time, just to
> account
> > for the repeated measure of my design (I measured the index hundreds of
> > time on each plot).
> >
> > Maybe I don't need to worry about hour, day and month?
> >
> > Manuel
> >
> > El lun., 20 may. 2019 a las 2:00, Thierry Onkelinx (<
> > thierry.onkelinx at inbo.be>) escribi?:
> >
> >> Dear Manuel,
> >>
> >> You'll need to think about the structure of your random effects. Your
> >> current random effect structure is (1|plot) + (1|plot:hour) +
> >> (1|plot:hour:day) + (1|plot:hour:day:month). Which might not be what you
> >> had in mind.
> >>
> >> Best regards,
> >>
> >> ir. Thierry Onkelinx
> >> Statisticus / Statistician
> >>
> >> Vlaamse Overheid / Government of Flanders
> >> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
> AND
> >> FOREST
> >> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> >> thierry.onkelinx at inbo.be
> >> Havenlaan 88 bus 73, 1000 Brussel
> >> www.inbo.be
> >>
> >>
> >>
> ///////////////////////////////////////////////////////////////////////////////////////////
> >> To call in the statistician after the experiment is done may be no more
> >> than asking him to perform a post-mortem examination: he may be able to
> say
> >> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> >> The plural of anecdote is not data. ~ Roger Brinner
> >> The combination of some data and an aching desire for an answer does not
> >> ensure that a reasonable answer can be extracted from a given body of
> data.
> >> ~ John Tukey
> >>
> >>
> ///////////////////////////////////////////////////////////////////////////////////////////
> >>
> >> <https://www.inbo.be>
> >>
> >>
> >> Op za 18 mei 2019 om 01:56 schreef Manuel Sp?nola <mspinola10 at gmail.com
> >:
> >>
> >>> Dear list members,
> >>>
> >>> I am measuring an index in plots, in different hours, different days,
> and
> >>> different months in 3 different "habitats".
> >>>
> >>> 12 plots by "habitats".
> >>>
> >>> I would like to estimate the mean index in the 3 environments.
> >>>
> >>> Is this model appropriate to achieve my goal?
> >>>
> >>> model <- lmer(index ~  habitat + (1 | plot/hour/day/month), data =
> mydata,
> >>> REML = FALSE)
> >>>
> >>> Best,
> >>>
> >>> Manuel
> >>>
> >>> --
> >>> *Manuel Sp?nola, Ph.D.*
> >>> Instituto Internacional en Conservaci?n y Manejo de Vida Silvestre
> >>> Universidad Nacional
> >>> Apartado 1350-3000
> >>> Heredia
> >>> COSTA RICA
> >>> mspinola at una.cr <mspinola at una.ac.cr>
> >>> mspinola10 at gmail.com
> >>> Tel?fono: (506) 8706 - 4662
> >>> Personal website: Lobito de r?o <
> >>> https://sites.google.com/site/lobitoderio/>
> >>> Institutional website: ICOMVIS <http://www.icomvis.una.ac.cr/>
> >>>
> >>>        [[alternative HTML version deleted]]
> >>>
> >>> _______________________________________________
> >>> R-sig-mixed-models at r-project.org mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>>
> >>
> >
> > --
> > *Manuel Sp?nola, Ph.D.*
> > Instituto Internacional en Conservaci?n y Manejo de Vida Silvestre
> > Universidad Nacional
> > Apartado 1350-3000
> > Heredia
> > COSTA RICA
> > mspinola at una.cr <mspinola at una.ac.cr>
> > mspinola10 at gmail.com
> > Tel?fono: (506) 8706 - 4662
> > Personal website: Lobito de r?o <
> https://sites.google.com/site/lobitoderio/>
> > Institutional website: ICOMVIS <http://www.icomvis.una.ac.cr/>
> >
> >    [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>

	[[alternative HTML version deleted]]


From r@ckerm@n27 @end|ng |rom gm@||@com  Tue May 21 17:07:35 2019
From: r@ckerm@n27 @end|ng |rom gm@||@com (Robert Ackerman)
Date: Tue, 21 May 2019 10:07:35 -0500
Subject: [R-sig-ME] False Convergence warning
Message-ID: <CADwBd8VwUriOBPyAQ-yZMwjeVfzHO=AVwyr2pJCAx71N+U7pTA@mail.gmail.com>

Hi everyone,

I have data from a speed-dating study, where groups of men and women
interacted with each other for five minutes and subsequently provided
ratings of the interaction and their partner.

These are the first lines of my data set:

   GROUPID MaleID FemaleID MF FM Agender AATTRACT

1        1      1        2  1  0       1     3.00

2        1      1        4  1  0       1     3.25

3        1      1        6  1  0       1     6.00

4        1      1        8  1  0       1     3.50

5        1      1       10  1  0       1     3.50

6        1      1        2  0  1      -1     5.00

7        1      3        2  0  1      -1     3.50

8        1      5        2  0  1      -1     5.00

9        1      7        2  0  1      -1     4.75

10       1      9        2  0  1      -1     2.25

11       1      3        2  1  0       1     1.25

12       1      3        4  1  0       1     3.25



Altogether, I have 904 observations (33 speed-dating groups comprised of
3-5 men and women each).

I?m trying to use glmmTMB to get a model with crossed random effects and an
unstructured covariance matrix for the residuals to run. Please note that I
was able to get this model to run in SPSS without problems (estimates of
fixed effects and random effects are also virtually identical). However, I
wanted to use R for its ease of checking multilevel modeling assumptions.

Here is the syntax for the model I tried to run in glmmTMB:

glmmTMB(AATTRACT ~ 1 + Agender+ (0 + MF + FM|GROUPID:MaleID) +

                   (0 + FM + MF|GROUPID:FemaleID)  + us(MF + FM + 0|
GROUPID:MaleID:FemaleID),

                    data = SD_data,  family = gaussian(link = "identity"),
dispformula=~0, REML = FALSE,

                   verbose = TRUE)

I received the following output and error message after running this model:

Formula: AATTRACT ~ 1 + Agender + (0 + MF + FM | GROUPID:MaleID) + (0 +

  FM + MF | GROUPID:FemaleID) + us(0 + MF + FM + 0 | GROUPID:MaleID:FemaleID)

Dispersion:                ~0

Data: SD_data

      AIC       BIC    logLik  df.resid

 2891.436  2944.311 -1434.718       893

Random-effects (co)variances:



Conditional model:

 Groups                  Name Std.Dev.  Corr

 GROUPID:MaleID          MF   0.5572656

                         FM   0.7916470 -0.02

 GROUPID:FemaleID        FM   0.6732786

                         MF   0.7529185 -0.16

 GROUPID:MaleID:FemaleID MF   0.8523621

                         FM   0.9419247 0.26

 Residual                     0.0001221



Number of obs: 904 / Conditional model: GROUPID:MaleID, 120;
GROUPID:FemaleID, 120; GROUPID:MaleID:FemaleID, 452



Fixed Effects:



Conditional model:

(Intercept)      Agender

     3.9048       0.1112

Warning message:

In fitTMB(TMBStruc) :

  Model convergence problem; false convergence (8). See
vignette('troubleshooting')



Because I used verbose = TRUE, I also received the following mgc values
(I?m only including the last few lines here).

mgc: 5.077952e-08

outer mgc:  0.544794

iter: 1  value: -5887.447 mgc: 0.003153025 ustep: 1

iter: 2  value: -5887.447 mgc: 6.546202e-08 ustep: 1

mgc: 9.447453e-08

outer mgc:  0.2579731

iter: 1  value: -5887.346 mgc: 0.003152465 ustep: 1

iter: 2  value: -5887.346 mgc: 5.733777e-08 ustep: 1

mgc: 7.849359e-08

outer mgc:  0.2594169



Does anyone have any insights into what might be going wrong?

Thanks!
Rob

	[[alternative HTML version deleted]]


From m|ch@e|@w||||@m@on @end|ng |rom kc|@@c@uk  Tue May 21 15:13:44 2019
From: m|ch@e|@w||||@m@on @end|ng |rom kc|@@c@uk (Williamson, Michael)
Date: Tue, 21 May 2019 13:13:44 +0000
Subject: [R-sig-ME] predict function for a glmm
Message-ID: <AM0PR03MB4548027673D47D7AE3C46554C2070@AM0PR03MB4548.eurprd03.prod.outlook.com>

Good Afternoon,

I am running a GLMM model using the glmmTMB function. I've been told I should run the model on 80% of my data, then test the outputs on the remaining 20% using the predict function in order to test the robustness of the model. I have a binomial response variable (off shore = 1 not offshore =0) for the model.

My code is this:

OffMod_80 <- glmmTMB(offshore ~ sex + log(size) + species*daynight+ species*season +
                    (1|code), family=binomial(), data=Off_80)

pred_Off20 <- as.data.frame(predict(OffMod_80, newdata = Off_20))

This spits out a table of values from the predict function.

My question is, considering my response variable is non-normal what method can I use to compare these predicted outputs with my observed values to test the robustness of the model? Is this even the correct way to go about things for this data and model type?

Any help appreciated.

Michael Williamson
London NERC DTP Candidate

Email: michael.williamson at kcl.ac.uk<mailto:michael.williamson at kcl.ac.uk> Phone: +447764836592 Skype: mikejwilliamson Twitter: @mjw_marine

Most recent paper:
Williamson, M. J., Tebbs, E., Dawson, T., Jacoby D. (2019) 'Satellite Remote Sensing in Shark and Ray Ecology, Conservation and Management', Frontiers in Marine Science, 6, 1-23. https://doi.org/10.3389/fmars.2019.00135<https://eur03.safelinks.protection.outlook.com/?url=https%3A%2F%2Fdoi.org%2F10.3389%2Ffmars.2019.00135&data=01%7C01%7Cmichael.williamson%40kcl.ac.uk%7Cebe89eb38f9f4638c3af08d6b381355f%7C8370cf1416f34c16b83c724071654356%7C0&sdata=RSgPw0Ar9R1JvA0YDYfJhDOdwUYfy7sh2vZs2t5tO94%3D&reserved=0>



	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Tue May 21 17:32:20 2019
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Tue, 21 May 2019 11:32:20 -0400
Subject: [R-sig-ME] predict function for a glmm
In-Reply-To: <AM0PR03MB4548027673D47D7AE3C46554C2070@AM0PR03MB4548.eurprd03.prod.outlook.com>
References: <AM0PR03MB4548027673D47D7AE3C46554C2070@AM0PR03MB4548.eurprd03.prod.outlook.com>
Message-ID: <a0468214-d301-fbef-6a02-0bb644b69c3a@gmail.com>


   A few choices:

 if you use predict(..., type="response") you will get predicted
probabilities for each element.  You can use any of the standard methods
for scoring the accuracy of a binomial model (e.g. pick a cutoff value,
most typically 0.5, for making predictions and count the number of
correct/incorrect predictions, *or* use area under the curve).

 For example,

ModelMatrix::auc.default(response_var, predict(fit, type="response"))

ought to do the trick.


On 2019-05-21 9:13 a.m., Williamson, Michael via R-sig-mixed-models wrote:
> Good Afternoon,
> 
> I am running a GLMM model using the glmmTMB function. I've been told I should run the model on 80% of my data, then test the outputs on the remaining 20% using the predict function in order to test the robustness of the model. I have a binomial response variable (off shore = 1 not offshore =0) for the model.
> 
> My code is this:
> 
> OffMod_80 <- glmmTMB(offshore ~ sex + log(size) + species*daynight+ species*season +
>                     (1|code), family=binomial(), data=Off_80)
> 
> pred_Off20 <- as.data.frame(predict(OffMod_80, newdata = Off_20))
> 
> This spits out a table of values from the predict function.
> 
> My question is, considering my response variable is non-normal what method can I use to compare these predicted outputs with my observed values to test the robustness of the model? Is this even the correct way to go about things for this data and model type?
> 
> Any help appreciated.
> 
> Michael Williamson
> London NERC DTP Candidate
> 
> Email: michael.williamson at kcl.ac.uk<mailto:michael.williamson at kcl.ac.uk> Phone: +447764836592 Skype: mikejwilliamson Twitter: @mjw_marine
> 
> Most recent paper:
> Williamson, M. J., Tebbs, E., Dawson, T., Jacoby D. (2019) 'Satellite Remote Sensing in Shark and Ray Ecology, Conservation and Management', Frontiers in Marine Science, 6, 1-23. https://doi.org/10.3389/fmars.2019.00135<https://eur03.safelinks.protection.outlook.com/?url=https%3A%2F%2Fdoi.org%2F10.3389%2Ffmars.2019.00135&data=01%7C01%7Cmichael.williamson%40kcl.ac.uk%7Cebe89eb38f9f4638c3af08d6b381355f%7C8370cf1416f34c16b83c724071654356%7C0&sdata=RSgPw0Ar9R1JvA0YDYfJhDOdwUYfy7sh2vZs2t5tO94%3D&reserved=0>
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From d@r|zopou|o@ @end|ng |rom er@@mu@mc@n|  Tue May 21 18:01:14 2019
From: d@r|zopou|o@ @end|ng |rom er@@mu@mc@n| (D. Rizopoulos)
Date: Tue, 21 May 2019 16:01:14 +0000
Subject: [R-sig-ME] predict function for a glmm
In-Reply-To: <AM0PR03MB4548027673D47D7AE3C46554C2070@AM0PR03MB4548.eurprd03.prod.outlook.com>
References: <AM0PR03MB4548027673D47D7AE3C46554C2070@AM0PR03MB4548.eurprd03.prod.outlook.com>
Message-ID: <7191AFC7255B4F49A30707E39BEAD05FDED4016C@EXCH-RX03.erasmusmc.nl>

You can have a look at proper scoring rules: https://en.m.wikipedia.org/wiki/Scoring_rule

These are, for example, calculated by the scoring_rules() function in the GLMMadaptive package (https://drizopoulos.github.io/GLMMadaptive/); for an example check here: https://drizopoulos.github.io/GLMMadaptive/articles/Dynamic_Predictions.html


Best,
Dimitris

From: Williamson, Michael via R-sig-mixed-models <r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>>
Date: Tuesday, 21 May 2019, 17:35
To: r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>>
Subject: [R-sig-ME] predict function for a glmm

Good Afternoon,

I am running a GLMM model using the glmmTMB function. I've been told I should run the model on 80% of my data, then test the outputs on the remaining 20% using the predict function in order to test the robustness of the model. I have a binomial response variable (off shore = 1 not offshore =0) for the model.

My code is this:

OffMod_80 <- glmmTMB(offshore ~ sex + log(size) + species*daynight+ species*season +
                    (1|code), family=binomial(), data=Off_80)

pred_Off20 <- as.data.frame(predict(OffMod_80, newdata = Off_20))

This spits out a table of values from the predict function.

My question is, considering my response variable is non-normal what method can I use to compare these predicted outputs with my observed values to test the robustness of the model? Is this even the correct way to go about things for this data and model type?

Any help appreciated.

Michael Williamson
London NERC DTP Candidate

Email: michael.williamson at kcl.ac.uk<mailto:michael.williamson at kcl.ac.uk> Phone: +447764836592 Skype: mikejwilliamson Twitter: @mjw_marine

Most recent paper:
Williamson, M. J., Tebbs, E., Dawson, T., Jacoby D. (2019) 'Satellite Remote Sensing in Shark and Ray Ecology, Conservation and Management', Frontiers in Marine Science, 6, 1-23. https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fdoi.org%2F10.3389%2Ffmars.2019.00135&amp;data=02%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C6efc655e1c334ec70e4308d6de01ea6c%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C0%7C636940497136772882&amp;sdata=xCAKq0gw%2BJVtvtWwIZX5WLPr2S3s%2FBrBin%2FDSz62rEk%3D&amp;reserved=0<https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fdoi.org%2F10.3389%2Ffmars.2019.00135&amp;data=02%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C6efc655e1c334ec70e4308d6de01ea6c%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C0%7C636940497136772882&amp;sdata=xCAKq0gw%2BJVtvtWwIZX5WLPr2S3s%2FBrBin%2FDSz62rEk%3D&amp;reserved=0>



        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=02%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C6efc655e1c334ec70e4308d6de01ea6c%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C0%7C636940497136772882&amp;sdata=JhSqa2R0rlRZ3e6KXFvoRAW8fg39tOUXWlsSyzrxmjg%3D&amp;reserved=0

	[[alternative HTML version deleted]]


From m@p|no|@10 @end|ng |rom gm@||@com  Tue May 21 19:01:21 2019
From: m@p|no|@10 @end|ng |rom gm@||@com (=?UTF-8?Q?Manuel_Sp=C3=ADnola?=)
Date: Tue, 21 May 2019 11:01:21 -0600
Subject: [R-sig-ME] Mixed model parameterization
In-Reply-To: <CAJuCY5wg74WGwxq_tvGua9jqyUpqDyYHfHfao0kK=w6KYOy9Kg@mail.gmail.com>
References: <CABkCotRU8z=OpntgwdBxw+c9G=SH1_KyCZwUUEZmr_Rn1Es2Ww@mail.gmail.com>
 <CAJuCY5zxyaES-zCKBL_0szqiecfgw5NT8cao8DW1G1vpi9aL+w@mail.gmail.com>
 <CABkCotSe6Z4zs3xYz1s5WCJaLD++FYtte_f-BYBoh6deh=u_3Q@mail.gmail.com>
 <8BD63A09-8957-43ED-A67F-FBC9A3AED7CA@prodigy.net.mx>
 <CAJuCY5wg74WGwxq_tvGua9jqyUpqDyYHfHfao0kK=w6KYOy9Kg@mail.gmail.com>
Message-ID: <CABkCotQF_7jEq4adaRy0iLb5g1jWgiqffh_vsbc-pKdOMgyX=w@mail.gmail.com>

Thank you very much Thierry.

Manuel

El lun., 20 may. 2019 a las 8:59, Thierry Onkelinx (<
thierry.onkelinx at inbo.be>) escribi?:

> Aggregating the data will remove al lot of information. And might
> introduce bias in case of an unbalanced design.
>
> You need to think about the (combination of) variables which have a common
> effect. (1|plot) + (1|plot:hour) assumes a plot effect and an effect of
> each combination of plot and hour, but no common hour effect.
>
> Days are nested in months. The corresponding random effect is (1|month) +
> (1|month:day). You have (1|day) + (1|day:month) which is nonsense.
>
> You really need to do some reading on mixed models. I recommend Zuur et al
> (2009) Mixed Effects Models and Extensions in Ecology with R
>
> ir. Thierry Onkelinx
> Statisticus / Statistician
>
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
> FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Havenlaan 88 bus 73, 1000 Brussel
> www.inbo.be
>
>
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> ///////////////////////////////////////////////////////////////////////////////////////////
>
> <https://www.inbo.be>
>
>
> Op ma 20 mei 2019 om 16:07 schreef Salvador S?nchez-Col?n <
> salvadorsanchezcolon at prodigy.net.mx>:
>
>> Hola Manuel:
>>
>> If you are not interested in examining the between-hours or between-days
>> variability, then you might consider analyzing the average of your hourly
>> values and thus simplify the model.
>>
>> Best regards,
>>
>> Salvador
>>
>> Salvador S?NCHEZ-COL?N
>>
>>
>> > On May 20, 2019, at 8:54 AM, Manuel Sp?nola <mspinola10 at gmail.com>
>> wrote:
>> >
>> > Thank you very much Thierry.
>> >
>> > I just only want to accomodate the nested repeated measure of my
>> sampling.
>> >
>> > I measure the index at the same plot, several times in an hour, several
>> > days and during several month.
>> >
>> > 3 "habitats", within each habitat 12 plots, and on each plot I measured
>> the
>> > index several times, within hours, several days and several months.
>> >
>> > I am not interested in the evolution of the index in time, just to
>> account
>> > for the repeated measure of my design (I measured the index hundreds of
>> > time on each plot).
>> >
>> > Maybe I don't need to worry about hour, day and month?
>> >
>> > Manuel
>> >
>> > El lun., 20 may. 2019 a las 2:00, Thierry Onkelinx (<
>> > thierry.onkelinx at inbo.be>) escribi?:
>> >
>> >> Dear Manuel,
>> >>
>> >> You'll need to think about the structure of your random effects. Your
>> >> current random effect structure is (1|plot) + (1|plot:hour) +
>> >> (1|plot:hour:day) + (1|plot:hour:day:month). Which might not be what
>> you
>> >> had in mind.
>> >>
>> >> Best regards,
>> >>
>> >> ir. Thierry Onkelinx
>> >> Statisticus / Statistician
>> >>
>> >> Vlaamse Overheid / Government of Flanders
>> >> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
>> AND
>> >> FOREST
>> >> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
>> >> thierry.onkelinx at inbo.be
>> >> Havenlaan 88 bus 73, 1000 Brussel
>> >> www.inbo.be
>> >>
>> >>
>> >>
>> ///////////////////////////////////////////////////////////////////////////////////////////
>> >> To call in the statistician after the experiment is done may be no more
>> >> than asking him to perform a post-mortem examination: he may be able
>> to say
>> >> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> >> The plural of anecdote is not data. ~ Roger Brinner
>> >> The combination of some data and an aching desire for an answer does
>> not
>> >> ensure that a reasonable answer can be extracted from a given body of
>> data.
>> >> ~ John Tukey
>> >>
>> >>
>> ///////////////////////////////////////////////////////////////////////////////////////////
>> >>
>> >> <https://www.inbo.be>
>> >>
>> >>
>> >> Op za 18 mei 2019 om 01:56 schreef Manuel Sp?nola <
>> mspinola10 at gmail.com>:
>> >>
>> >>> Dear list members,
>> >>>
>> >>> I am measuring an index in plots, in different hours, different days,
>> and
>> >>> different months in 3 different "habitats".
>> >>>
>> >>> 12 plots by "habitats".
>> >>>
>> >>> I would like to estimate the mean index in the 3 environments.
>> >>>
>> >>> Is this model appropriate to achieve my goal?
>> >>>
>> >>> model <- lmer(index ~  habitat + (1 | plot/hour/day/month), data =
>> mydata,
>> >>> REML = FALSE)
>> >>>
>> >>> Best,
>> >>>
>> >>> Manuel
>> >>>
>> >>> --
>> >>> *Manuel Sp?nola, Ph.D.*
>> >>> Instituto Internacional en Conservaci?n y Manejo de Vida Silvestre
>> >>> Universidad Nacional
>> >>> Apartado 1350-3000
>> >>> Heredia
>> >>> COSTA RICA
>> >>> mspinola at una.cr <mspinola at una.ac.cr>
>> >>> mspinola10 at gmail.com
>> >>> Tel?fono: (506) 8706 - 4662
>> >>> Personal website: Lobito de r?o <
>> >>> https://sites.google.com/site/lobitoderio/>
>> >>> Institutional website: ICOMVIS <http://www.icomvis.una.ac.cr/>
>> >>>
>> >>>        [[alternative HTML version deleted]]
>> >>>
>> >>> _______________________________________________
>> >>> R-sig-mixed-models at r-project.org mailing list
>> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >>>
>> >>
>> >
>> > --
>> > *Manuel Sp?nola, Ph.D.*
>> > Instituto Internacional en Conservaci?n y Manejo de Vida Silvestre
>> > Universidad Nacional
>> > Apartado 1350-3000
>> > Heredia
>> > COSTA RICA
>> > mspinola at una.cr <mspinola at una.ac.cr>
>> > mspinola10 at gmail.com
>> > Tel?fono: (506) 8706 - 4662
>> > Personal website: Lobito de r?o <
>> https://sites.google.com/site/lobitoderio/>
>> > Institutional website: ICOMVIS <http://www.icomvis.una.ac.cr/>
>> >
>> >    [[alternative HTML version deleted]]
>> >
>> > _______________________________________________
>> > R-sig-mixed-models at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>

-- 
*Manuel Sp?nola, Ph.D.*
Instituto Internacional en Conservaci?n y Manejo de Vida Silvestre
Universidad Nacional
Apartado 1350-3000
Heredia
COSTA RICA
mspinola at una.cr <mspinola at una.ac.cr>
mspinola10 at gmail.com
Tel?fono: (506) 8706 - 4662
Personal website: Lobito de r?o <https://sites.google.com/site/lobitoderio/>
Institutional website: ICOMVIS <http://www.icomvis.una.ac.cr/>

	[[alternative HTML version deleted]]


From jo@qu|n@@|d@be @end|ng |rom gm@||@com  Tue May 21 21:35:53 2019
From: jo@qu|n@@|d@be @end|ng |rom gm@||@com (=?UTF-8?Q?Joaqu=C3=ADn_Aldabe?=)
Date: Tue, 21 May 2019 16:35:53 -0300
Subject: [R-sig-ME] Mixed model parameterization
In-Reply-To: <CABkCotQF_7jEq4adaRy0iLb5g1jWgiqffh_vsbc-pKdOMgyX=w@mail.gmail.com>
References: <CABkCotRU8z=OpntgwdBxw+c9G=SH1_KyCZwUUEZmr_Rn1Es2Ww@mail.gmail.com>
 <CAJuCY5zxyaES-zCKBL_0szqiecfgw5NT8cao8DW1G1vpi9aL+w@mail.gmail.com>
 <CABkCotSe6Z4zs3xYz1s5WCJaLD++FYtte_f-BYBoh6deh=u_3Q@mail.gmail.com>
 <8BD63A09-8957-43ED-A67F-FBC9A3AED7CA@prodigy.net.mx>
 <CAJuCY5wg74WGwxq_tvGua9jqyUpqDyYHfHfao0kK=w6KYOy9Kg@mail.gmail.com>
 <CABkCotQF_7jEq4adaRy0iLb5g1jWgiqffh_vsbc-pKdOMgyX=w@mail.gmail.com>
Message-ID: <CAMM93=+GMxb7aJLdFAODZ6qjWpxsdhEWgYqVeDrt4NaLq067vg@mail.gmail.com>

I agree that using the mean you miss a lot of information. The simplest
case would be no interaction between random effects. Say,
(1|month)+(1|day)+(1|hour)+(1|plot). As far as I understand, if you think
that, for example, hour effect depends on the day, then you should consider
a nested structure of randoms effects.

Let us know your progress!

joaquin

<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
Libre
de virus. www.avast.com
<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
<#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>

El mar., 21 may. 2019 a las 14:01, Manuel Sp?nola (<mspinola10 at gmail.com>)
escribi?:

> Thank you very much Thierry.
>
> Manuel
>
> El lun., 20 may. 2019 a las 8:59, Thierry Onkelinx (<
> thierry.onkelinx at inbo.be>) escribi?:
>
> > Aggregating the data will remove al lot of information. And might
> > introduce bias in case of an unbalanced design.
> >
> > You need to think about the (combination of) variables which have a
> common
> > effect. (1|plot) + (1|plot:hour) assumes a plot effect and an effect of
> > each combination of plot and hour, but no common hour effect.
> >
> > Days are nested in months. The corresponding random effect is (1|month) +
> > (1|month:day). You have (1|day) + (1|day:month) which is nonsense.
> >
> > You really need to do some reading on mixed models. I recommend Zuur et
> al
> > (2009) Mixed Effects Models and Extensions in Ecology with R
> >
> > ir. Thierry Onkelinx
> > Statisticus / Statistician
> >
> > Vlaamse Overheid / Government of Flanders
> > INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
> AND
> > FOREST
> > Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> > thierry.onkelinx at inbo.be
> > Havenlaan 88 bus 73, 1000 Brussel
> > www.inbo.be
> >
> >
> >
> ///////////////////////////////////////////////////////////////////////////////////////////
> > To call in the statistician after the experiment is done may be no more
> > than asking him to perform a post-mortem examination: he may be able to
> say
> > what the experiment died of. ~ Sir Ronald Aylmer Fisher
> > The plural of anecdote is not data. ~ Roger Brinner
> > The combination of some data and an aching desire for an answer does not
> > ensure that a reasonable answer can be extracted from a given body of
> data.
> > ~ John Tukey
> >
> >
> ///////////////////////////////////////////////////////////////////////////////////////////
> >
> > <https://www.inbo.be>
> >
> >
> > Op ma 20 mei 2019 om 16:07 schreef Salvador S?nchez-Col?n <
> > salvadorsanchezcolon at prodigy.net.mx>:
> >
> >> Hola Manuel:
> >>
> >> If you are not interested in examining the between-hours or between-days
> >> variability, then you might consider analyzing the average of your
> hourly
> >> values and thus simplify the model.
> >>
> >> Best regards,
> >>
> >> Salvador
> >>
> >> Salvador S?NCHEZ-COL?N
> >>
> >>
> >> > On May 20, 2019, at 8:54 AM, Manuel Sp?nola <mspinola10 at gmail.com>
> >> wrote:
> >> >
> >> > Thank you very much Thierry.
> >> >
> >> > I just only want to accomodate the nested repeated measure of my
> >> sampling.
> >> >
> >> > I measure the index at the same plot, several times in an hour,
> several
> >> > days and during several month.
> >> >
> >> > 3 "habitats", within each habitat 12 plots, and on each plot I
> measured
> >> the
> >> > index several times, within hours, several days and several months.
> >> >
> >> > I am not interested in the evolution of the index in time, just to
> >> account
> >> > for the repeated measure of my design (I measured the index hundreds
> of
> >> > time on each plot).
> >> >
> >> > Maybe I don't need to worry about hour, day and month?
> >> >
> >> > Manuel
> >> >
> >> > El lun., 20 may. 2019 a las 2:00, Thierry Onkelinx (<
> >> > thierry.onkelinx at inbo.be>) escribi?:
> >> >
> >> >> Dear Manuel,
> >> >>
> >> >> You'll need to think about the structure of your random effects. Your
> >> >> current random effect structure is (1|plot) + (1|plot:hour) +
> >> >> (1|plot:hour:day) + (1|plot:hour:day:month). Which might not be what
> >> you
> >> >> had in mind.
> >> >>
> >> >> Best regards,
> >> >>
> >> >> ir. Thierry Onkelinx
> >> >> Statisticus / Statistician
> >> >>
> >> >> Vlaamse Overheid / Government of Flanders
> >> >> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR
> NATURE
> >> AND
> >> >> FOREST
> >> >> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> >> >> thierry.onkelinx at inbo.be
> >> >> Havenlaan 88 bus 73, 1000 Brussel
> >> >> www.inbo.be
> >> >>
> >> >>
> >> >>
> >>
> ///////////////////////////////////////////////////////////////////////////////////////////
> >> >> To call in the statistician after the experiment is done may be no
> more
> >> >> than asking him to perform a post-mortem examination: he may be able
> >> to say
> >> >> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> >> >> The plural of anecdote is not data. ~ Roger Brinner
> >> >> The combination of some data and an aching desire for an answer does
> >> not
> >> >> ensure that a reasonable answer can be extracted from a given body of
> >> data.
> >> >> ~ John Tukey
> >> >>
> >> >>
> >>
> ///////////////////////////////////////////////////////////////////////////////////////////
> >> >>
> >> >> <https://www.inbo.be>
> >> >>
> >> >>
> >> >> Op za 18 mei 2019 om 01:56 schreef Manuel Sp?nola <
> >> mspinola10 at gmail.com>:
> >> >>
> >> >>> Dear list members,
> >> >>>
> >> >>> I am measuring an index in plots, in different hours, different
> days,
> >> and
> >> >>> different months in 3 different "habitats".
> >> >>>
> >> >>> 12 plots by "habitats".
> >> >>>
> >> >>> I would like to estimate the mean index in the 3 environments.
> >> >>>
> >> >>> Is this model appropriate to achieve my goal?
> >> >>>
> >> >>> model <- lmer(index ~  habitat + (1 | plot/hour/day/month), data =
> >> mydata,
> >> >>> REML = FALSE)
> >> >>>
> >> >>> Best,
> >> >>>
> >> >>> Manuel
> >> >>>
> >> >>> --
> >> >>> *Manuel Sp?nola, Ph.D.*
> >> >>> Instituto Internacional en Conservaci?n y Manejo de Vida Silvestre
> >> >>> Universidad Nacional
> >> >>> Apartado 1350-3000
> >> >>> Heredia
> >> >>> COSTA RICA
> >> >>> mspinola at una.cr <mspinola at una.ac.cr>
> >> >>> mspinola10 at gmail.com
> >> >>> Tel?fono: (506) 8706 - 4662
> >> >>> Personal website: Lobito de r?o <
> >> >>> https://sites.google.com/site/lobitoderio/>
> >> >>> Institutional website: ICOMVIS <http://www.icomvis.una.ac.cr/>
> >> >>>
> >> >>>        [[alternative HTML version deleted]]
> >> >>>
> >> >>> _______________________________________________
> >> >>> R-sig-mixed-models at r-project.org mailing list
> >> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >> >>>
> >> >>
> >> >
> >> > --
> >> > *Manuel Sp?nola, Ph.D.*
> >> > Instituto Internacional en Conservaci?n y Manejo de Vida Silvestre
> >> > Universidad Nacional
> >> > Apartado 1350-3000
> >> > Heredia
> >> > COSTA RICA
> >> > mspinola at una.cr <mspinola at una.ac.cr>
> >> > mspinola10 at gmail.com
> >> > Tel?fono: (506) 8706 - 4662
> >> > Personal website: Lobito de r?o <
> >> https://sites.google.com/site/lobitoderio/>
> >> > Institutional website: ICOMVIS <http://www.icomvis.una.ac.cr/>
> >> >
> >> >    [[alternative HTML version deleted]]
> >> >
> >> > _______________________________________________
> >> > R-sig-mixed-models at r-project.org mailing list
> >> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>
> >>
>
> --
> *Manuel Sp?nola, Ph.D.*
> Instituto Internacional en Conservaci?n y Manejo de Vida Silvestre
> Universidad Nacional
> Apartado 1350-3000
> Heredia
> COSTA RICA
> mspinola at una.cr <mspinola at una.ac.cr>
> mspinola10 at gmail.com
> Tel?fono: (506) 8706 - 4662
> Personal website: Lobito de r?o <
> https://sites.google.com/site/lobitoderio/>
> Institutional website: ICOMVIS <http://www.icomvis.una.ac.cr/>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


-- 
*Joaqu?n Aldabe*

Departamento de Sistemas Agrarios y Paisajes Culturales
Centro Universitario de la Regi?n Este, Universidad de la Rep?blica, Uruguay
Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha

*https://sites.google.com/view/joaquin-aldabe
<https://sites.google.com/view/joaquin-aldabe>*


<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
Libre
de virus. www.avast.com
<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
<#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>

	[[alternative HTML version deleted]]


From d|egobe|ttr@n@ @end|ng |rom gm@||@com  Tue May 21 22:41:54 2019
From: d|egobe|ttr@n@ @end|ng |rom gm@||@com (Diego Beltran)
Date: Tue, 21 May 2019 15:41:54 -0500
Subject: [R-sig-ME] Prior for phylogenetic multi-response model MCMCglmm
Message-ID: <CAOe9Y1Cb=cgExU2w69NzU2te+ZAMZYZOBi=TvC037=mWhach-g@mail.gmail.com>

Dear List Members,

I'm trying to do a Phylogenetic multi-response model using MCMCglmm and
keep having trouble adjusting the priors.

Suppose I have a dataset composed of three continuous response variables
(H1,H2,H3) and a set of predictor variables composed of seven continuous
variables and two categorical variables (patch and sex), with five and two
levels, respectively. My random effects are phylogeny and individual (ID),
with a phylogeny of 150 species. Each name in 'animal' matches a tip in the
phylogeny (tree). All continuous variables are log transformed for
normality and standardised. Each row in the data frame is a patch of an
individual of a given species and I want to know if the predictor variables
have an effect on the response variables, given the phylogeny and the fact
that there is more than one individual per species, which belong to
different sexes.

Here is the code to an example of how my dataset looks like:

example <- data.frame(ID=rep(seq(1,4),each=5),
animal=rep(rep(seq(1,2),each=5),2),
Sex=factor(rep(c('Females','Males'),each=10)),
Patch=factor(rep(c('1','2','3','4','5'),4)), H1=rnorm(20,0,1),
H2=rnorm(20,0,1), H3=rnorm(20,0,1), A1=rnorm(20,0,1), A2=rnorm(20,0,1),
A3=rnorm(20,0,1), Di_chrom=rnorm(20,0,1), Di_achrom=rnorm(20,0,1),
Chrom_com=rnorm(20,0,1), Achrom_com=rnorm(20,0,1))


My priors:

prior1 <- list(R = list(V = diag(1), nu = 0.002),
              G = list(G1 = list(V = 1, nu = 0.002),
                       G2 = list(V = diag(2) * 0.02, nu = 4)))

My full model:

mod <- MCMCglmm(fixed= cbind(H1,H2,H3) ~
A1 + A2 + A3 + Di_chrom + Di_achrom + Chrom_com + Achrom_com + Sex + Patch
-1,
random= ~ us(trait):animal + us(Sex):ID,
rcov = ~ us(Sex):units,
family=rep('gaussian',3),
nitt = 60000, thin=200, burnin = 10000,
prior=prior1,
data=example, pedigree=tree,
DIC=TRUE, verbose=FALSE)


My attempts at running the model result in the following error:

Error in priorformat(if (NOpriorG) { :
  V is the wrong dimension for some prior$G/prior$R elements

Any help would be greatly appreciated. Thank you very much in advance!

Best,
Diego
-- 
---
Diego Beltr?n
Grupo Ecolog?a y Evoluci?n de Vertebrados
Universidad de Antioquia
Colombia

	[[alternative HTML version deleted]]


From @@|v@dor@@nchezco|on @end|ng |rom prod|gy@net@mx  Tue May 21 22:48:55 2019
From: @@|v@dor@@nchezco|on @end|ng |rom prod|gy@net@mx (Salvador SANCHEZ COLON)
Date: Tue, 21 May 2019 13:48:55 -0700
Subject: [R-sig-ME] Mixed model parameterization
Message-ID: <45GLRLFJK7U4.H03ITON1WDZI@mwweb10oc>

Apologies for my insistence:


"...I agree that using the mean you miss a lot of information. The simplest
case would be no interaction between random effects. Say,
(1|month)+(1|day)+(1|hour)+(1|plot).?..."


...and that also assumes that the only effect of random factors is on the intercept, but not on the slope of the relationship between the fixed factor(s) and the response. Overall, if you want to consider (isolate) all the possible random effects that might be involved in your design, you would need a very complex model. But you previously suggested that some of those factors might not be that important and perhaps may be dismissed; in my view, I wonder if some of your dat are actually pseudoreplicates (e.g., measurements at different times of the same day) and, if so, a parsimonious way to handle them is by averaging across them and analyzing the average values.


Best regards,


Salvador S?NCHEZ-COL?N


En Mar, 21 Mayo, 2019 en 14:37, Joaqu?n Aldabe <joaquin.aldabe at gmail.com> escribi?:
?

Para: Manuel Sp?nola; r-sig-mixed-models at r-project.org
I agree that using the mean you miss a lot of information. The simplest
case would be no interaction between random effects. Say,
(1|month)+(1|day)+(1|hour)+(1|plot). As far as I understand, if you think
that, for example, hour effect depends on the day, then you should consider
a nested structure of randoms effects.

Let us know your progress!

joaquin

<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
Libre
de virus. www.avast.com
<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
<#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>

El mar., 21 may. 2019 a las 14:01, Manuel Sp?nola (<mspinola10 at gmail.com>)
escribi?:

> Thank you very much Thierry.
>
> Manuel
>
> El lun., 20 may. 2019 a las 8:59, Thierry Onkelinx (<
> thierry.onkelinx at inbo.be>) escribi?:
>
> > Aggregating the data will remove al lot of information. And might
> > introduce bias in case of an unbalanced design.
> >
> > You need to think about the (combination of) variables which have a
> common
> > effect. (1|plot) + (1|plot:hour) assumes a plot effect and an effect of
> > each combination of plot and hour, but no common hour effect.
> >
> > Days are nested in months. The corresponding random effect is (1|month) +
> > (1|month:day). You have (1|day) + (1|day:month) which is nonsense.
> >
> > You really need to do some reading on mixed models. I recommend Zuur et
> al
> > (2009) Mixed Effects Models and Extensions in Ecology with R
> >
> > ir. Thierry Onkelinx
> > Statisticus / Statistician
> >
> > Vlaamse Overheid / Government of Flanders
> > INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
> AND
> > FOREST
> > Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> > thierry.onkelinx at inbo.be
> > Havenlaan 88 bus 73, 1000 Brussel
> > www.inbo.be
> >
> >
> >
> ///////////////////////////////////////////////////////////////////////////////////////////
> > To call in the statistician after the experiment is done may be no more
> > than asking him to perform a post-mortem examination: he may be able to
> say
> > what the experiment died of. ~ Sir Ronald Aylmer Fisher
> > The plural of anecdote is not data. ~ Roger Brinner
> > The combination of some data and an aching desire for an answer does not
> > ensure that a reasonable answer can be extracted from a given body of
> data.
> > ~ John Tukey
> >
> >
> ///////////////////////////////////////////////////////////////////////////////////////////
> >
> > <https://www.inbo.be>
> >
> >
> > Op ma 20 mei 2019 om 16:07 schreef Salvador S?nchez-Col?n <
> > salvadorsanchezcolon at prodigy.net.mx>:
> >
> >> Hola Manuel:
> >>
> >> If you are not interested in examining the between-hours or between-days
> >> variability, then you might consider analyzing the average of your
> hourly
> >> values and thus simplify the model.
> >>
> >> Best regards,
> >>
> >> Salvador
> >>
> >> Salvador S?NCHEZ-COL?N
> >>
> >>
> >> > On May 20, 2019, at 8:54 AM, Manuel Sp?nola <mspinola10 at gmail.com>
> >> wrote:
> >> >
> >> > Thank you very much Thierry.
> >> >
> >> > I just only want to accomodate the nested repeated measure of my
> >> sampling.
> >> >
> >> > I measure the index at the same plot, several times in an hour,
> several
> >> > days and during several month.
> >> >
> >> > 3 "habitats", within each habitat 12 plots, and on each plot I
> measured
> >> the
> >> > index several times, within hours, several days and several months.
> >> >
> >> > I am not interested in the evolution of the index in time, just to
> >> account
> >> > for the repeated measure of my design (I measured the index hundreds
> of
> >> > time on each plot).
> >> >
> >> > Maybe I don't need to worry about hour, day and month?
> >> >
> >> > Manuel
> >> >
> >> > El lun., 20 may. 2019 a las 2:00, Thierry Onkelinx (<
> >> > thierry.onkelinx at inbo.be>) escribi?:
> >> >
> >> >> Dear Manuel,
> >> >>
> >> >> You'll need to think about the structure of your random effects. Your
> >> >> current random effect structure is (1|plot) + (1|plot:hour) +
> >> >> (1|plot:hour:day) + (1|plot:hour:day:month). Which might not be what
> >> you
> >> >> had in mind.
> >> >>
> >> >> Best regards,
> >> >>
> >> >> ir. Thierry Onkelinx
> >> >> Statisticus / Statistician
> >> >>
> >> >> Vlaamse Overheid / Government of Flanders
> >> >> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR
> NATURE
> >> AND
> >> >> FOREST
> >> >> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> >> >> thierry.onkelinx at inbo.be
> >> >> Havenlaan 88 bus 73, 1000 Brussel
> >> >> www.inbo.be
> >> >>
> >> >>
> >> >>
> >>
> ///////////////////////////////////////////////////////////////////////////////////////////
> >> >> To call in the statistician after the experiment is done may be no
> more
> >> >> than asking him to perform a post-mortem examination: he may be able
> >> to say
> >> >> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> >> >> The plural of anecdote is not data. ~ Roger Brinner
> >> >> The combination of some data and an aching desire for an answer does
> >> not
> >> >> ensure that a reasonable answer can be extracted from a given body of
> >> data.
> >> >> ~ John Tukey
> >> >>
> >> >>
> >>
> ///////////////////////////////////////////////////////////////////////////////////////////
> >> >>
> >> >> <https://www.inbo.be>
> >> >>
> >> >>
> >> >> Op za 18 mei 2019 om 01:56 schreef Manuel Sp?nola <
> >> mspinola10 at gmail.com>:
> >> >>
> >> >>> Dear list members,
> >> >>>
> >> >>> I am measuring an index in plots, in different hours, different
> days,
> >> and
> >> >>> different months in 3 different "habitats".
> >> >>>
> >> >>> 12 plots by "habitats".
> >> >>>
> >> >>> I would like to estimate the mean index in the 3 environments.
> >> >>>
> >> >>> Is this model appropriate to achieve my goal?
> >> >>>
> >> >>> model <- lmer(index ~ habitat + (1 | plot/hour/day/month), data =
> >> mydata,
> >> >>> REML = FALSE)
> >> >>>
> >> >>> Best,
> >> >>>
> >> >>> Manuel
> >> >>>
> >> >>> --
> >> >>> *Manuel Sp?nola, Ph.D.*
> >> >>> Instituto Internacional en Conservaci?n y Manejo de Vida Silvestre
> >> >>> Universidad Nacional
> >> >>> Apartado 1350-3000
> >> >>> Heredia
> >> >>> COSTA RICA
> >> >>> mspinola at una.cr <mspinola at una.ac.cr>
> >> >>> mspinola10 at gmail.com
> >> >>> Tel?fono: (506) 8706 - 4662
> >> >>> Personal website: Lobito de r?o <
> >> >>> https://sites.google.com/site/lobitoderio/>
> >> >>> Institutional website: ICOMVIS <http://www.icomvis.una.ac.cr/>
> >> >>>
> >> >>> [[alternative HTML version deleted]]
> >> >>>
> >> >>> _______________________________________________
> >> >>> R-sig-mixed-models at r-project.org mailing list
> >> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >> >>>
> >> >>
> >> >
> >> > --
> >> > *Manuel Sp?nola, Ph.D.*
> >> > Instituto Internacional en Conservaci?n y Manejo de Vida Silvestre
> >> > Universidad Nacional
> >> > Apartado 1350-3000
> >> > Heredia
> >> > COSTA RICA
> >> > mspinola at una.cr <mspinola at una.ac.cr>
> >> > mspinola10 at gmail.com
> >> > Tel?fono: (506) 8706 - 4662
> >> > Personal website: Lobito de r?o <
> >> https://sites.google.com/site/lobitoderio/>
> >> > Institutional website: ICOMVIS <http://www.icomvis.una.ac.cr/>
> >> >
> >> > [[alternative HTML version deleted]]
> >> >
> >> > _______________________________________________
> >> > R-sig-mixed-models at r-project.org mailing list
> >> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>
> >>
>
> --
> *Manuel Sp?nola, Ph.D.*
> Instituto Internacional en Conservaci?n y Manejo de Vida Silvestre
> Universidad Nacional
> Apartado 1350-3000
> Heredia
> COSTA RICA
> mspinola at una.cr <mspinola at una.ac.cr>
> mspinola10 at gmail.com
> Tel?fono: (506) 8706 - 4662
> Personal website: Lobito de r?o <
> https://sites.google.com/site/lobitoderio/>
> Institutional website: ICOMVIS <http://www.icomvis.una.ac.cr/>
>
> [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


-- 
*Joaqu?n Aldabe*

Departamento de Sistemas Agrarios y Paisajes Culturales
Centro Universitario de la Regi?n Este, Universidad de la Rep?blica, Uruguay
Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha

*https://sites.google.com/view/joaquin-aldabe
<https://sites.google.com/view/joaquin-aldabe>*


<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
Libre
de virus. www.avast.com
<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
<#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>

[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
.
 
	[[alternative HTML version deleted]]


From jo@qu|n@@|d@be @end|ng |rom gm@||@com  Tue May 21 23:10:43 2019
From: jo@qu|n@@|d@be @end|ng |rom gm@||@com (=?UTF-8?Q?Joaqu=C3=ADn_Aldabe?=)
Date: Tue, 21 May 2019 18:10:43 -0300
Subject: [R-sig-ME] Mixed model parameterization
In-Reply-To: <45GLRLFJK7U4.H03ITON1WDZI@mwweb10oc>
References: <45GLRLFJK7U4.H03ITON1WDZI@mwweb10oc>
Message-ID: <CAMM93=+tA6+2LWUhE694mTaTR7i2Y8SkQTAKa5mgNBdLXW=XLQ@mail.gmail.com>

Hi, pseudoreplication is what random effects model by inducing correlation
among observations grouped by a categortical variable.
Ch?vere, Joaqu?n

El mar., 21 de may. de 2019 5:45 PM, Salvador SANCHEZ COLON <
salvadorsanchezcolon at prodigy.net.mx> escribi?:

> Apologies for my insistence:
>
>
> "...I agree that using the mean you miss a lot of information. The simplest
> case would be no interaction between random effects. Say,
> (1|month)+(1|day)+(1|hour)+(1|plot). ..."
>
>
> ...and that also assumes that the only effect of random factors is on the
> intercept, but not on the slope of the relationship between the fixed
> factor(s) and the response. Overall, if you want to consider (isolate) all
> the possible random effects that might be involved in your design, you
> would need a very complex model. But you previously suggested that some of
> those factors might not be that important and perhaps may be dismissed; in
> my view, I wonder if some of your dat are actually pseudoreplicates (e.g.,
> measurements at different times of the same day) and, if so, a parsimonious
> way to handle them is by averaging across them and analyzing the average
> values.
>
>
> Best regards,
>
>
> Salvador S?NCHEZ-COL?N
>
>
> En Mar, 21 Mayo, 2019 en 14:37, Joaqu?n Aldabe <joaquin.aldabe at gmail.com>
> escribi?:
>
> Para: Manuel Sp?nola; r-sig-mixed-models at r-project.org
> I agree that using the mean you miss a lot of information. The simplest
> case would be no interaction between random effects. Say,
> (1|month)+(1|day)+(1|hour)+(1|plot). As far as I understand, if you think
> that, for example, hour effect depends on the day, then you should consider
> a nested structure of randoms effects.
>
> Let us know your progress!
>
> joaquin
>
> <
> https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail
> >
> Libre
> de virus. www.avast.com
> <
> https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail
> >
> <#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>
>
> El mar., 21 may. 2019 a las 14:01, Manuel Sp?nola (<mspinola10 at gmail.com>)
> escribi?:
>
> > Thank you very much Thierry.
> >
> > Manuel
> >
> > El lun., 20 may. 2019 a las 8:59, Thierry Onkelinx (<
> > thierry.onkelinx at inbo.be>) escribi?:
> >
> > > Aggregating the data will remove al lot of information. And might
> > > introduce bias in case of an unbalanced design.
> > >
> > > You need to think about the (combination of) variables which have a
> > common
> > > effect. (1|plot) + (1|plot:hour) assumes a plot effect and an effect of
> > > each combination of plot and hour, but no common hour effect.
> > >
> > > Days are nested in months. The corresponding random effect is
> (1|month) +
> > > (1|month:day). You have (1|day) + (1|day:month) which is nonsense.
> > >
> > > You really need to do some reading on mixed models. I recommend Zuur et
> > al
> > > (2009) Mixed Effects Models and Extensions in Ecology with R
> > >
> > > ir. Thierry Onkelinx
> > > Statisticus / Statistician
> > >
> > > Vlaamse Overheid / Government of Flanders
> > > INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
> > AND
> > > FOREST
> > > Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> > > thierry.onkelinx at inbo.be
> > > Havenlaan 88 bus 73, 1000 Brussel
> > > www.inbo.be
> > >
> > >
> > >
> >
> ///////////////////////////////////////////////////////////////////////////////////////////
> > > To call in the statistician after the experiment is done may be no more
> > > than asking him to perform a post-mortem examination: he may be able to
> > say
> > > what the experiment died of. ~ Sir Ronald Aylmer Fisher
> > > The plural of anecdote is not data. ~ Roger Brinner
> > > The combination of some data and an aching desire for an answer does
> not
> > > ensure that a reasonable answer can be extracted from a given body of
> > data.
> > > ~ John Tukey
> > >
> > >
> >
> ///////////////////////////////////////////////////////////////////////////////////////////
> > >
> > > <https://www.inbo.be>
> > >
> > >
> > > Op ma 20 mei 2019 om 16:07 schreef Salvador S?nchez-Col?n <
> > > salvadorsanchezcolon at prodigy.net.mx>:
> > >
> > >> Hola Manuel:
> > >>
> > >> If you are not interested in examining the between-hours or
> between-days
> > >> variability, then you might consider analyzing the average of your
> > hourly
> > >> values and thus simplify the model.
> > >>
> > >> Best regards,
> > >>
> > >> Salvador
> > >>
> > >> Salvador S?NCHEZ-COL?N
> > >>
> > >>
> > >> > On May 20, 2019, at 8:54 AM, Manuel Sp?nola <mspinola10 at gmail.com>
> > >> wrote:
> > >> >
> > >> > Thank you very much Thierry.
> > >> >
> > >> > I just only want to accomodate the nested repeated measure of my
> > >> sampling.
> > >> >
> > >> > I measure the index at the same plot, several times in an hour,
> > several
> > >> > days and during several month.
> > >> >
> > >> > 3 "habitats", within each habitat 12 plots, and on each plot I
> > measured
> > >> the
> > >> > index several times, within hours, several days and several months.
> > >> >
> > >> > I am not interested in the evolution of the index in time, just to
> > >> account
> > >> > for the repeated measure of my design (I measured the index hundreds
> > of
> > >> > time on each plot).
> > >> >
> > >> > Maybe I don't need to worry about hour, day and month?
> > >> >
> > >> > Manuel
> > >> >
> > >> > El lun., 20 may. 2019 a las 2:00, Thierry Onkelinx (<
> > >> > thierry.onkelinx at inbo.be>) escribi?:
> > >> >
> > >> >> Dear Manuel,
> > >> >>
> > >> >> You'll need to think about the structure of your random effects.
> Your
> > >> >> current random effect structure is (1|plot) + (1|plot:hour) +
> > >> >> (1|plot:hour:day) + (1|plot:hour:day:month). Which might not be
> what
> > >> you
> > >> >> had in mind.
> > >> >>
> > >> >> Best regards,
> > >> >>
> > >> >> ir. Thierry Onkelinx
> > >> >> Statisticus / Statistician
> > >> >>
> > >> >> Vlaamse Overheid / Government of Flanders
> > >> >> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR
> > NATURE
> > >> AND
> > >> >> FOREST
> > >> >> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality
> Assurance
> > >> >> thierry.onkelinx at inbo.be
> > >> >> Havenlaan 88 bus 73, 1000 Brussel
> > >> >> www.inbo.be
> > >> >>
> > >> >>
> > >> >>
> > >>
> >
> ///////////////////////////////////////////////////////////////////////////////////////////
> > >> >> To call in the statistician after the experiment is done may be no
> > more
> > >> >> than asking him to perform a post-mortem examination: he may be
> able
> > >> to say
> > >> >> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> > >> >> The plural of anecdote is not data. ~ Roger Brinner
> > >> >> The combination of some data and an aching desire for an answer
> does
> > >> not
> > >> >> ensure that a reasonable answer can be extracted from a given body
> of
> > >> data.
> > >> >> ~ John Tukey
> > >> >>
> > >> >>
> > >>
> >
> ///////////////////////////////////////////////////////////////////////////////////////////
> > >> >>
> > >> >> <https://www.inbo.be>
> > >> >>
> > >> >>
> > >> >> Op za 18 mei 2019 om 01:56 schreef Manuel Sp?nola <
> > >> mspinola10 at gmail.com>:
> > >> >>
> > >> >>> Dear list members,
> > >> >>>
> > >> >>> I am measuring an index in plots, in different hours, different
> > days,
> > >> and
> > >> >>> different months in 3 different "habitats".
> > >> >>>
> > >> >>> 12 plots by "habitats".
> > >> >>>
> > >> >>> I would like to estimate the mean index in the 3 environments.
> > >> >>>
> > >> >>> Is this model appropriate to achieve my goal?
> > >> >>>
> > >> >>> model <- lmer(index ~ habitat + (1 | plot/hour/day/month), data =
> > >> mydata,
> > >> >>> REML = FALSE)
> > >> >>>
> > >> >>> Best,
> > >> >>>
> > >> >>> Manuel
> > >> >>>
> > >> >>> --
> > >> >>> *Manuel Sp?nola, Ph.D.*
> > >> >>> Instituto Internacional en Conservaci?n y Manejo de Vida Silvestre
> > >> >>> Universidad Nacional
> > >> >>> Apartado 1350-3000
> > >> >>> Heredia
> > >> >>> COSTA RICA
> > >> >>> mspinola at una.cr <mspinola at una.ac.cr>
> > >> >>> mspinola10 at gmail.com
> > >> >>> Tel?fono: (506) 8706 - 4662
> > >> >>> Personal website: Lobito de r?o <
> > >> >>> https://sites.google.com/site/lobitoderio/>
> > >> >>> Institutional website: ICOMVIS <http://www.icomvis.una.ac.cr/>
> > >> >>>
> > >> >>> [[alternative HTML version deleted]]
> > >> >>>
> > >> >>> _______________________________________________
> > >> >>> R-sig-mixed-models at r-project.org mailing list
> > >> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > >> >>>
> > >> >>
> > >> >
> > >> > --
> > >> > *Manuel Sp?nola, Ph.D.*
> > >> > Instituto Internacional en Conservaci?n y Manejo de Vida Silvestre
> > >> > Universidad Nacional
> > >> > Apartado 1350-3000
> > >> > Heredia
> > >> > COSTA RICA
> > >> > mspinola at una.cr <mspinola at una.ac.cr>
> > >> > mspinola10 at gmail.com
> > >> > Tel?fono: (506) 8706 - 4662
> > >> > Personal website: Lobito de r?o <
> > >> https://sites.google.com/site/lobitoderio/>
> > >> > Institutional website: ICOMVIS <http://www.icomvis.una.ac.cr/>
> > >> >
> > >> > [[alternative HTML version deleted]]
> > >> >
> > >> > _______________________________________________
> > >> > R-sig-mixed-models at r-project.org mailing list
> > >> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > >>
> > >>
> >
> > --
> > *Manuel Sp?nola, Ph.D.*
> > Instituto Internacional en Conservaci?n y Manejo de Vida Silvestre
> > Universidad Nacional
> > Apartado 1350-3000
> > Heredia
> > COSTA RICA
> > mspinola at una.cr <mspinola at una.ac.cr>
> > mspinola10 at gmail.com
> > Tel?fono: (506) 8706 - 4662
> > Personal website: Lobito de r?o <
> > https://sites.google.com/site/lobitoderio/>
> > Institutional website: ICOMVIS <http://www.icomvis.una.ac.cr/>
> >
> > [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
>
> --
> *Joaqu?n Aldabe*
>
> Departamento de Sistemas Agrarios y Paisajes Culturales
> Centro Universitario de la Regi?n Este, Universidad de la Rep?blica,
> Uruguay
> Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha
>
> *https://sites.google.com/view/joaquin-aldabe
> <https://sites.google.com/view/joaquin-aldabe>*
>
>
> <
> https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail
> >
> Libre
> de virus. www.avast.com
> <
> https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail
> >
> <#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>
>
> [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> .
>

	[[alternative HTML version deleted]]


From m@p|no|@10 @end|ng |rom gm@||@com  Wed May 22 00:15:46 2019
From: m@p|no|@10 @end|ng |rom gm@||@com (=?UTF-8?Q?Manuel_Sp=C3=ADnola?=)
Date: Tue, 21 May 2019 16:15:46 -0600
Subject: [R-sig-ME] Mixed model parameterization
In-Reply-To: <45GLRLFJK7U4.H03ITON1WDZI@mwweb10oc>
References: <45GLRLFJK7U4.H03ITON1WDZI@mwweb10oc>
Message-ID: <CABkCotQAfAwWxNDG99PWc=e_eSQU3pSr-AJJDMGXgDpVyfLvgw@mail.gmail.com>

Thank you very much Salvador.

Yes, I think most of my data are pseudoreplicates, the sampling unit was
the plot and there was several measurements through time at the plot. This
is why I was thinking in the mixed model to take into account the structure
of my data.

Maybe I don?t need to think in hour, day and month and use:

model <- lmer(index ~  habitat + (1 | plot), data = mydata, REML = FALSE)


Manuel

El mar., 21 may. 2019 a las 14:45, Salvador SANCHEZ COLON (<
salvadorsanchezcolon at prodigy.net.mx>) escribi?:

> Apologies for my insistence:
>
>
> "...I agree that using the mean you miss a lot of information. The simplest
> case would be no interaction between random effects. Say,
> (1|month)+(1|day)+(1|hour)+(1|plot). ..."
>
>
> ...and that also assumes that the only effect of random factors is on the
> intercept, but not on the slope of the relationship between the fixed
> factor(s) and the response. Overall, if you want to consider (isolate) all
> the possible random effects that might be involved in your design, you
> would need a very complex model. But you previously suggested that some of
> those factors might not be that important and perhaps may be dismissed; in
> my view, I wonder if some of your dat are actually pseudoreplicates (e.g.,
> measurements at different times of the same day) and, if so, a parsimonious
> way to handle them is by averaging across them and analyzing the average
> values.
>
>
> Best regards,
>
>
> Salvador S?NCHEZ-COL?N
>
>
> En Mar, 21 Mayo, 2019 en 14:37, Joaqu?n Aldabe <joaquin.aldabe at gmail.com>
> escribi?:
>
> Para: Manuel Sp?nola; r-sig-mixed-models at r-project.org
> I agree that using the mean you miss a lot of information. The simplest
> case would be no interaction between random effects. Say,
> (1|month)+(1|day)+(1|hour)+(1|plot). As far as I understand, if you think
> that, for example, hour effect depends on the day, then you should consider
> a nested structure of randoms effects.
>
> Let us know your progress!
>
> joaquin
>
> <
> https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail
> >
> Libre
> de virus. www.avast.com
> <
> https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail
> >
> <#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>
>
> El mar., 21 may. 2019 a las 14:01, Manuel Sp?nola (<mspinola10 at gmail.com>)
> escribi?:
>
> > Thank you very much Thierry.
> >
> > Manuel
> >
> > El lun., 20 may. 2019 a las 8:59, Thierry Onkelinx (<
> > thierry.onkelinx at inbo.be>) escribi?:
> >
> > > Aggregating the data will remove al lot of information. And might
> > > introduce bias in case of an unbalanced design.
> > >
> > > You need to think about the (combination of) variables which have a
> > common
> > > effect. (1|plot) + (1|plot:hour) assumes a plot effect and an effect of
> > > each combination of plot and hour, but no common hour effect.
> > >
> > > Days are nested in months. The corresponding random effect is
> (1|month) +
> > > (1|month:day). You have (1|day) + (1|day:month) which is nonsense.
> > >
> > > You really need to do some reading on mixed models. I recommend Zuur et
> > al
> > > (2009) Mixed Effects Models and Extensions in Ecology with R
> > >
> > > ir. Thierry Onkelinx
> > > Statisticus / Statistician
> > >
> > > Vlaamse Overheid / Government of Flanders
> > > INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
> > AND
> > > FOREST
> > > Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> > > thierry.onkelinx at inbo.be
> > > Havenlaan 88 bus 73, 1000 Brussel
> > > www.inbo.be
> > >
> > >
> > >
> >
> ///////////////////////////////////////////////////////////////////////////////////////////
> > > To call in the statistician after the experiment is done may be no more
> > > than asking him to perform a post-mortem examination: he may be able to
> > say
> > > what the experiment died of. ~ Sir Ronald Aylmer Fisher
> > > The plural of anecdote is not data. ~ Roger Brinner
> > > The combination of some data and an aching desire for an answer does
> not
> > > ensure that a reasonable answer can be extracted from a given body of
> > data.
> > > ~ John Tukey
> > >
> > >
> >
> ///////////////////////////////////////////////////////////////////////////////////////////
> > >
> > > <https://www.inbo.be>
> > >
> > >
> > > Op ma 20 mei 2019 om 16:07 schreef Salvador S?nchez-Col?n <
> > > salvadorsanchezcolon at prodigy.net.mx>:
> > >
> > >> Hola Manuel:
> > >>
> > >> If you are not interested in examining the between-hours or
> between-days
> > >> variability, then you might consider analyzing the average of your
> > hourly
> > >> values and thus simplify the model.
> > >>
> > >> Best regards,
> > >>
> > >> Salvador
> > >>
> > >> Salvador S?NCHEZ-COL?N
> > >>
> > >>
> > >> > On May 20, 2019, at 8:54 AM, Manuel Sp?nola <mspinola10 at gmail.com>
> > >> wrote:
> > >> >
> > >> > Thank you very much Thierry.
> > >> >
> > >> > I just only want to accomodate the nested repeated measure of my
> > >> sampling.
> > >> >
> > >> > I measure the index at the same plot, several times in an hour,
> > several
> > >> > days and during several month.
> > >> >
> > >> > 3 "habitats", within each habitat 12 plots, and on each plot I
> > measured
> > >> the
> > >> > index several times, within hours, several days and several months.
> > >> >
> > >> > I am not interested in the evolution of the index in time, just to
> > >> account
> > >> > for the repeated measure of my design (I measured the index hundreds
> > of
> > >> > time on each plot).
> > >> >
> > >> > Maybe I don't need to worry about hour, day and month?
> > >> >
> > >> > Manuel
> > >> >
> > >> > El lun., 20 may. 2019 a las 2:00, Thierry Onkelinx (<
> > >> > thierry.onkelinx at inbo.be>) escribi?:
> > >> >
> > >> >> Dear Manuel,
> > >> >>
> > >> >> You'll need to think about the structure of your random effects.
> Your
> > >> >> current random effect structure is (1|plot) + (1|plot:hour) +
> > >> >> (1|plot:hour:day) + (1|plot:hour:day:month). Which might not be
> what
> > >> you
> > >> >> had in mind.
> > >> >>
> > >> >> Best regards,
> > >> >>
> > >> >> ir. Thierry Onkelinx
> > >> >> Statisticus / Statistician
> > >> >>
> > >> >> Vlaamse Overheid / Government of Flanders
> > >> >> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR
> > NATURE
> > >> AND
> > >> >> FOREST
> > >> >> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality
> Assurance
> > >> >> thierry.onkelinx at inbo.be
> > >> >> Havenlaan 88 bus 73, 1000 Brussel
> > >> >> www.inbo.be
> > >> >>
> > >> >>
> > >> >>
> > >>
> >
> ///////////////////////////////////////////////////////////////////////////////////////////
> > >> >> To call in the statistician after the experiment is done may be no
> > more
> > >> >> than asking him to perform a post-mortem examination: he may be
> able
> > >> to say
> > >> >> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> > >> >> The plural of anecdote is not data. ~ Roger Brinner
> > >> >> The combination of some data and an aching desire for an answer
> does
> > >> not
> > >> >> ensure that a reasonable answer can be extracted from a given body
> of
> > >> data.
> > >> >> ~ John Tukey
> > >> >>
> > >> >>
> > >>
> >
> ///////////////////////////////////////////////////////////////////////////////////////////
> > >> >>
> > >> >> <https://www.inbo.be>
> > >> >>
> > >> >>
> > >> >> Op za 18 mei 2019 om 01:56 schreef Manuel Sp?nola <
> > >> mspinola10 at gmail.com>:
> > >> >>
> > >> >>> Dear list members,
> > >> >>>
> > >> >>> I am measuring an index in plots, in different hours, different
> > days,
> > >> and
> > >> >>> different months in 3 different "habitats".
> > >> >>>
> > >> >>> 12 plots by "habitats".
> > >> >>>
> > >> >>> I would like to estimate the mean index in the 3 environments.
> > >> >>>
> > >> >>> Is this model appropriate to achieve my goal?
> > >> >>>
> > >> >>> model <- lmer(index ~ habitat + (1 | plot/hour/day/month), data =
> > >> mydata,
> > >> >>> REML = FALSE)
> > >> >>>
> > >> >>> Best,
> > >> >>>
> > >> >>> Manuel
> > >> >>>
> > >> >>> --
> > >> >>> *Manuel Sp?nola, Ph.D.*
> > >> >>> Instituto Internacional en Conservaci?n y Manejo de Vida Silvestre
> > >> >>> Universidad Nacional
> > >> >>> Apartado 1350-3000
> > >> >>> Heredia
> > >> >>> COSTA RICA
> > >> >>> mspinola at una.cr <mspinola at una.ac.cr>
> > >> >>> mspinola10 at gmail.com
> > >> >>> Tel?fono: (506) 8706 - 4662
> > >> >>> Personal website: Lobito de r?o <
> > >> >>> https://sites.google.com/site/lobitoderio/>
> > >> >>> Institutional website: ICOMVIS <http://www.icomvis.una.ac.cr/>
> > >> >>>
> > >> >>> [[alternative HTML version deleted]]
> > >> >>>
> > >> >>> _______________________________________________
> > >> >>> R-sig-mixed-models at r-project.org mailing list
> > >> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > >> >>>
> > >> >>
> > >> >
> > >> > --
> > >> > *Manuel Sp?nola, Ph.D.*
> > >> > Instituto Internacional en Conservaci?n y Manejo de Vida Silvestre
> > >> > Universidad Nacional
> > >> > Apartado 1350-3000
> > >> > Heredia
> > >> > COSTA RICA
> > >> > mspinola at una.cr <mspinola at una.ac.cr>
> > >> > mspinola10 at gmail.com
> > >> > Tel?fono: (506) 8706 - 4662
> > >> > Personal website: Lobito de r?o <
> > >> https://sites.google.com/site/lobitoderio/>
> > >> > Institutional website: ICOMVIS <http://www.icomvis.una.ac.cr/>
> > >> >
> > >> > [[alternative HTML version deleted]]
> > >> >
> > >> > _______________________________________________
> > >> > R-sig-mixed-models at r-project.org mailing list
> > >> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > >>
> > >>
> >
> > --
> > *Manuel Sp?nola, Ph.D.*
> > Instituto Internacional en Conservaci?n y Manejo de Vida Silvestre
> > Universidad Nacional
> > Apartado 1350-3000
> > Heredia
> > COSTA RICA
> > mspinola at una.cr <mspinola at una.ac.cr>
> > mspinola10 at gmail.com
> > Tel?fono: (506) 8706 - 4662
> > Personal website: Lobito de r?o <
> > https://sites.google.com/site/lobitoderio/>
> > Institutional website: ICOMVIS <http://www.icomvis.una.ac.cr/>
> >
> > [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
>
> --
> *Joaqu?n Aldabe*
>
> Departamento de Sistemas Agrarios y Paisajes Culturales
> Centro Universitario de la Regi?n Este, Universidad de la Rep?blica,
> Uruguay
> Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha
>
> *https://sites.google.com/view/joaquin-aldabe
> <https://sites.google.com/view/joaquin-aldabe>*
>
>
> <
> https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail
> >
> Libre
> de virus. www.avast.com
> <
> https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail
> >
> <#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>
>
> [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> .
>


-- 
*Manuel Sp?nola, Ph.D.*
Instituto Internacional en Conservaci?n y Manejo de Vida Silvestre
Universidad Nacional
Apartado 1350-3000
Heredia
COSTA RICA
mspinola at una.cr <mspinola at una.ac.cr>
mspinola10 at gmail.com
Tel?fono: (506) 8706 - 4662
Personal website: Lobito de r?o <https://sites.google.com/site/lobitoderio/>
Institutional website: ICOMVIS <http://www.icomvis.una.ac.cr/>

	[[alternative HTML version deleted]]


From jo@qu|n@@|d@be @end|ng |rom gm@||@com  Wed May 22 00:43:52 2019
From: jo@qu|n@@|d@be @end|ng |rom gm@||@com (=?UTF-8?Q?Joaqu=C3=ADn_Aldabe?=)
Date: Tue, 21 May 2019 19:43:52 -0300
Subject: [R-sig-ME] Mixed model parameterization
In-Reply-To: <CABkCotQAfAwWxNDG99PWc=e_eSQU3pSr-AJJDMGXgDpVyfLvgw@mail.gmail.com>
References: <45GLRLFJK7U4.H03ITON1WDZI@mwweb10oc>
 <CABkCotQAfAwWxNDG99PWc=e_eSQU3pSr-AJJDMGXgDpVyfLvgw@mail.gmail.com>
Message-ID: <CAMM93=JOiZwshHyve-vRFXqhBtNXOM1c+vvTXiC078rT=48JUg@mail.gmail.com>

You can also try the function corr and assess the effect of diferent
correlation structures. And consider AIC or BIC for model selection.

El mar., 21 de may. de 2019 7:15 PM, Manuel Sp?nola <mspinola10 at gmail.com>
escribi?:

> Thank you very much Salvador.
>
> Yes, I think most of my data are pseudoreplicates, the sampling unit was
> the plot and there was several measurements through time at the plot. This
> is why I was thinking in the mixed model to take into account the structure
> of my data.
>
> Maybe I don?t need to think in hour, day and month and use:
>
> model <- lmer(index ~  habitat + (1 | plot), data = mydata, REML = FALSE)
>
>
> Manuel
>
> El mar., 21 may. 2019 a las 14:45, Salvador SANCHEZ COLON (<
> salvadorsanchezcolon at prodigy.net.mx>) escribi?:
>
>> Apologies for my insistence:
>>
>>
>> "...I agree that using the mean you miss a lot of information. The
>> simplest
>> case would be no interaction between random effects. Say,
>> (1|month)+(1|day)+(1|hour)+(1|plot). ..."
>>
>>
>> ...and that also assumes that the only effect of random factors is on the
>> intercept, but not on the slope of the relationship between the fixed
>> factor(s) and the response. Overall, if you want to consider (isolate) all
>> the possible random effects that might be involved in your design, you
>> would need a very complex model. But you previously suggested that some of
>> those factors might not be that important and perhaps may be dismissed; in
>> my view, I wonder if some of your dat are actually pseudoreplicates (e.g.,
>> measurements at different times of the same day) and, if so, a parsimonious
>> way to handle them is by averaging across them and analyzing the average
>> values.
>>
>>
>> Best regards,
>>
>>
>> Salvador S?NCHEZ-COL?N
>>
>>
>> En Mar, 21 Mayo, 2019 en 14:37, Joaqu?n Aldabe <joaquin.aldabe at gmail.com>
>> escribi?:
>>
>> Para: Manuel Sp?nola; r-sig-mixed-models at r-project.org
>> I agree that using the mean you miss a lot of information. The simplest
>> case would be no interaction between random effects. Say,
>> (1|month)+(1|day)+(1|hour)+(1|plot). As far as I understand, if you think
>> that, for example, hour effect depends on the day, then you should
>> consider
>> a nested structure of randoms effects.
>>
>> Let us know your progress!
>>
>> joaquin
>>
>> <
>> https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail
>> >
>> Libre
>> de virus. www.avast.com
>> <
>> https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail
>> >
>> <#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>
>>
>> El mar., 21 may. 2019 a las 14:01, Manuel Sp?nola (<mspinola10 at gmail.com
>> >)
>> escribi?:
>>
>> > Thank you very much Thierry.
>> >
>> > Manuel
>> >
>> > El lun., 20 may. 2019 a las 8:59, Thierry Onkelinx (<
>> > thierry.onkelinx at inbo.be>) escribi?:
>> >
>> > > Aggregating the data will remove al lot of information. And might
>> > > introduce bias in case of an unbalanced design.
>> > >
>> > > You need to think about the (combination of) variables which have a
>> > common
>> > > effect. (1|plot) + (1|plot:hour) assumes a plot effect and an effect
>> of
>> > > each combination of plot and hour, but no common hour effect.
>> > >
>> > > Days are nested in months. The corresponding random effect is
>> (1|month) +
>> > > (1|month:day). You have (1|day) + (1|day:month) which is nonsense.
>> > >
>> > > You really need to do some reading on mixed models. I recommend Zuur
>> et
>> > al
>> > > (2009) Mixed Effects Models and Extensions in Ecology with R
>> > >
>> > > ir. Thierry Onkelinx
>> > > Statisticus / Statistician
>> > >
>> > > Vlaamse Overheid / Government of Flanders
>> > > INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
>> > AND
>> > > FOREST
>> > > Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
>> > > thierry.onkelinx at inbo.be
>> > > Havenlaan 88 bus 73, 1000 Brussel
>> > > www.inbo.be
>> > >
>> > >
>> > >
>> >
>> ///////////////////////////////////////////////////////////////////////////////////////////
>> > > To call in the statistician after the experiment is done may be no
>> more
>> > > than asking him to perform a post-mortem examination: he may be able
>> to
>> > say
>> > > what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> > > The plural of anecdote is not data. ~ Roger Brinner
>> > > The combination of some data and an aching desire for an answer does
>> not
>> > > ensure that a reasonable answer can be extracted from a given body of
>> > data.
>> > > ~ John Tukey
>> > >
>> > >
>> >
>> ///////////////////////////////////////////////////////////////////////////////////////////
>> > >
>> > > <https://www.inbo.be>
>> > >
>> > >
>> > > Op ma 20 mei 2019 om 16:07 schreef Salvador S?nchez-Col?n <
>> > > salvadorsanchezcolon at prodigy.net.mx>:
>> > >
>> > >> Hola Manuel:
>> > >>
>> > >> If you are not interested in examining the between-hours or
>> between-days
>> > >> variability, then you might consider analyzing the average of your
>> > hourly
>> > >> values and thus simplify the model.
>> > >>
>> > >> Best regards,
>> > >>
>> > >> Salvador
>> > >>
>> > >> Salvador S?NCHEZ-COL?N
>> > >>
>> > >>
>> > >> > On May 20, 2019, at 8:54 AM, Manuel Sp?nola <mspinola10 at gmail.com>
>> > >> wrote:
>> > >> >
>> > >> > Thank you very much Thierry.
>> > >> >
>> > >> > I just only want to accomodate the nested repeated measure of my
>> > >> sampling.
>> > >> >
>> > >> > I measure the index at the same plot, several times in an hour,
>> > several
>> > >> > days and during several month.
>> > >> >
>> > >> > 3 "habitats", within each habitat 12 plots, and on each plot I
>> > measured
>> > >> the
>> > >> > index several times, within hours, several days and several months.
>> > >> >
>> > >> > I am not interested in the evolution of the index in time, just to
>> > >> account
>> > >> > for the repeated measure of my design (I measured the index
>> hundreds
>> > of
>> > >> > time on each plot).
>> > >> >
>> > >> > Maybe I don't need to worry about hour, day and month?
>> > >> >
>> > >> > Manuel
>> > >> >
>> > >> > El lun., 20 may. 2019 a las 2:00, Thierry Onkelinx (<
>> > >> > thierry.onkelinx at inbo.be>) escribi?:
>> > >> >
>> > >> >> Dear Manuel,
>> > >> >>
>> > >> >> You'll need to think about the structure of your random effects.
>> Your
>> > >> >> current random effect structure is (1|plot) + (1|plot:hour) +
>> > >> >> (1|plot:hour:day) + (1|plot:hour:day:month). Which might not be
>> what
>> > >> you
>> > >> >> had in mind.
>> > >> >>
>> > >> >> Best regards,
>> > >> >>
>> > >> >> ir. Thierry Onkelinx
>> > >> >> Statisticus / Statistician
>> > >> >>
>> > >> >> Vlaamse Overheid / Government of Flanders
>> > >> >> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR
>> > NATURE
>> > >> AND
>> > >> >> FOREST
>> > >> >> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality
>> Assurance
>> > >> >> thierry.onkelinx at inbo.be
>> > >> >> Havenlaan 88 bus 73, 1000 Brussel
>> > >> >> www.inbo.be
>> > >> >>
>> > >> >>
>> > >> >>
>> > >>
>> >
>> ///////////////////////////////////////////////////////////////////////////////////////////
>> > >> >> To call in the statistician after the experiment is done may be no
>> > more
>> > >> >> than asking him to perform a post-mortem examination: he may be
>> able
>> > >> to say
>> > >> >> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> > >> >> The plural of anecdote is not data. ~ Roger Brinner
>> > >> >> The combination of some data and an aching desire for an answer
>> does
>> > >> not
>> > >> >> ensure that a reasonable answer can be extracted from a given
>> body of
>> > >> data.
>> > >> >> ~ John Tukey
>> > >> >>
>> > >> >>
>> > >>
>> >
>> ///////////////////////////////////////////////////////////////////////////////////////////
>> > >> >>
>> > >> >> <https://www.inbo.be>
>> > >> >>
>> > >> >>
>> > >> >> Op za 18 mei 2019 om 01:56 schreef Manuel Sp?nola <
>> > >> mspinola10 at gmail.com>:
>> > >> >>
>> > >> >>> Dear list members,
>> > >> >>>
>> > >> >>> I am measuring an index in plots, in different hours, different
>> > days,
>> > >> and
>> > >> >>> different months in 3 different "habitats".
>> > >> >>>
>> > >> >>> 12 plots by "habitats".
>> > >> >>>
>> > >> >>> I would like to estimate the mean index in the 3 environments.
>> > >> >>>
>> > >> >>> Is this model appropriate to achieve my goal?
>> > >> >>>
>> > >> >>> model <- lmer(index ~ habitat + (1 | plot/hour/day/month), data =
>> > >> mydata,
>> > >> >>> REML = FALSE)
>> > >> >>>
>> > >> >>> Best,
>> > >> >>>
>> > >> >>> Manuel
>> > >> >>>
>> > >> >>> --
>> > >> >>> *Manuel Sp?nola, Ph.D.*
>> > >> >>> Instituto Internacional en Conservaci?n y Manejo de Vida
>> Silvestre
>> > >> >>> Universidad Nacional
>> > >> >>> Apartado 1350-3000
>> > >> >>> Heredia
>> > >> >>> COSTA RICA
>> > >> >>> mspinola at una.cr <mspinola at una.ac.cr>
>> > >> >>> mspinola10 at gmail.com
>> > >> >>> Tel?fono: (506) 8706 - 4662
>> > >> >>> Personal website: Lobito de r?o <
>> > >> >>> https://sites.google.com/site/lobitoderio/>
>> > >> >>> Institutional website: ICOMVIS <http://www.icomvis.una.ac.cr/>
>> > >> >>>
>> > >> >>> [[alternative HTML version deleted]]
>> > >> >>>
>> > >> >>> _______________________________________________
>> > >> >>> R-sig-mixed-models at r-project.org mailing list
>> > >> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> > >> >>>
>> > >> >>
>> > >> >
>> > >> > --
>> > >> > *Manuel Sp?nola, Ph.D.*
>> > >> > Instituto Internacional en Conservaci?n y Manejo de Vida Silvestre
>> > >> > Universidad Nacional
>> > >> > Apartado 1350-3000
>> > >> > Heredia
>> > >> > COSTA RICA
>> > >> > mspinola at una.cr <mspinola at una.ac.cr>
>> > >> > mspinola10 at gmail.com
>> > >> > Tel?fono: (506) 8706 - 4662
>> > >> > Personal website: Lobito de r?o <
>> > >> https://sites.google.com/site/lobitoderio/>
>> > >> > Institutional website: ICOMVIS <http://www.icomvis.una.ac.cr/>
>> > >> >
>> > >> > [[alternative HTML version deleted]]
>> > >> >
>> > >> > _______________________________________________
>> > >> > R-sig-mixed-models at r-project.org mailing list
>> > >> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> > >>
>> > >>
>> >
>> > --
>> > *Manuel Sp?nola, Ph.D.*
>> > Instituto Internacional en Conservaci?n y Manejo de Vida Silvestre
>> > Universidad Nacional
>> > Apartado 1350-3000
>> > Heredia
>> > COSTA RICA
>> > mspinola at una.cr <mspinola at una.ac.cr>
>> > mspinola10 at gmail.com
>> > Tel?fono: (506) 8706 - 4662
>> > Personal website: Lobito de r?o <
>> > https://sites.google.com/site/lobitoderio/>
>> > Institutional website: ICOMVIS <http://www.icomvis.una.ac.cr/>
>> >
>> > [[alternative HTML version deleted]]
>> >
>> > _______________________________________________
>> > R-sig-mixed-models at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >
>>
>>
>> --
>> *Joaqu?n Aldabe*
>>
>> Departamento de Sistemas Agrarios y Paisajes Culturales
>> Centro Universitario de la Regi?n Este, Universidad de la Rep?blica,
>> Uruguay
>> Ruta 15 (y Ruta 9), Km 28.500, Departamento de Rocha
>>
>> *https://sites.google.com/view/joaquin-aldabe
>> <https://sites.google.com/view/joaquin-aldabe>*
>>
>>
>> <
>> https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail
>> >
>> Libre
>> de virus. www.avast.com
>> <
>> https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail
>> >
>> <#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>
>>
>> [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> .
>>
>
>
> --
> *Manuel Sp?nola, Ph.D.*
> Instituto Internacional en Conservaci?n y Manejo de Vida Silvestre
> Universidad Nacional
> Apartado 1350-3000
> Heredia
> COSTA RICA
> mspinola at una.cr <mspinola at una.ac.cr>
> mspinola10 at gmail.com
> Tel?fono: (506) 8706 - 4662
> Personal website: Lobito de r?o
> <https://sites.google.com/site/lobitoderio/>
> Institutional website: ICOMVIS <http://www.icomvis.una.ac.cr/>
>

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Thu May 23 18:31:59 2019
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Thu, 23 May 2019 12:31:59 -0400
Subject: [R-sig-ME] False Convergence warning
In-Reply-To: <CADwBd8VwUriOBPyAQ-yZMwjeVfzHO=AVwyr2pJCAx71N+U7pTA@mail.gmail.com>
References: <CADwBd8VwUriOBPyAQ-yZMwjeVfzHO=AVwyr2pJCAx71N+U7pTA@mail.gmail.com>
Message-ID: <ed0ce052-3296-e5ff-b897-fdf336ed829f@gmail.com>


  Some quick points.

* the nlminb "false convergence" error is quite hard to troubleshoot
<https://stackoverflow.com/questions/40039114/r-nlminb-what-does-false-convergence-actually-mean>

* I would normally suggest scaling your variables as a cheap way to
improve robustness, but it looks like your variables are all effectively
binary/scaled anyway?

* the only part of your model that looks unusual/glmmTMB-specific is
dispformula=~0:  I assume you're doing this because otherwise some of
your variance terms are confounded with the residual variance?  You
could try fitting this model in blme::blmer, with the residual std dev
prior fixed to a small non-zero value (the std dev value below is
(.Machine$double.eps)^(0.25)), and see if you get the same results ...

* it should be possible, but isn't presently, to try glmmTMB with an
alternate optimizer (stay tuned) ...

On 2019-05-21 11:07 a.m., Robert Ackerman wrote:
> Hi everyone,
> 
> I have data from a speed-dating study, where groups of men and women
> interacted with each other for five minutes and subsequently provided
> ratings of the interaction and their partner.
> 
> These are the first lines of my data set:
> 
>    GROUPID MaleID FemaleID MF FM Agender AATTRACT
> 
> 1        1      1        2  1  0       1     3.00
> 
> 2        1      1        4  1  0       1     3.25
> 
> 3        1      1        6  1  0       1     6.00
> 
> 4        1      1        8  1  0       1     3.50
> 
> 5        1      1       10  1  0       1     3.50
> 
> 6        1      1        2  0  1      -1     5.00
> 
> 7        1      3        2  0  1      -1     3.50
> 
> 8        1      5        2  0  1      -1     5.00
> 
> 9        1      7        2  0  1      -1     4.75
> 
> 10       1      9        2  0  1      -1     2.25
> 
> 11       1      3        2  1  0       1     1.25
> 
> 12       1      3        4  1  0       1     3.25
> 
> 
> 
> Altogether, I have 904 observations (33 speed-dating groups comprised of
> 3-5 men and women each).
> 
> I?m trying to use glmmTMB to get a model with crossed random effects and an
> unstructured covariance matrix for the residuals to run. Please note that I
> was able to get this model to run in SPSS without problems (estimates of
> fixed effects and random effects are also virtually identical). However, I
> wanted to use R for its ease of checking multilevel modeling assumptions.
> 
> Here is the syntax for the model I tried to run in glmmTMB:
> 
> glmmTMB(AATTRACT ~ 1 + Agender+ (0 + MF + FM|GROUPID:MaleID) +
> 
>                    (0 + FM + MF|GROUPID:FemaleID)  + us(MF + FM + 0|
> GROUPID:MaleID:FemaleID),
> 
>                     data = SD_data,  family = gaussian(link = "identity"),
> dispformula=~0, REML = FALSE,
> 
>                    verbose = TRUE)
> 
> I received the following output and error message after running this model:
> 
> Formula: AATTRACT ~ 1 + Agender + (0 + MF + FM | GROUPID:MaleID) + (0 +
> 
>   FM + MF | GROUPID:FemaleID) + us(0 + MF + FM + 0 | GROUPID:MaleID:FemaleID)
> 
> Dispersion:                ~0
> 
> Data: SD_data
> 
>       AIC       BIC    logLik  df.resid
> 
>  2891.436  2944.311 -1434.718       893
> 
> Random-effects (co)variances:
> 
> 
> 
> Conditional model:
> 
>  Groups                  Name Std.Dev.  Corr
> 
>  GROUPID:MaleID          MF   0.5572656
> 
>                          FM   0.7916470 -0.02
> 
>  GROUPID:FemaleID        FM   0.6732786
> 
>                          MF   0.7529185 -0.16
> 
>  GROUPID:MaleID:FemaleID MF   0.8523621
> 
>                          FM   0.9419247 0.26
> 
>  Residual                     0.0001221
> 
> 
> 
> Number of obs: 904 / Conditional model: GROUPID:MaleID, 120;
> GROUPID:FemaleID, 120; GROUPID:MaleID:FemaleID, 452
> 
> 
> 
> Fixed Effects:
> 
> 
> 
> Conditional model:
> 
> (Intercept)      Agender
> 
>      3.9048       0.1112
> 
> Warning message:
> 
> In fitTMB(TMBStruc) :
> 
>   Model convergence problem; false convergence (8). See
> vignette('troubleshooting')
> 
> 
> 
> Because I used verbose = TRUE, I also received the following mgc values
> (I?m only including the last few lines here).
> 
> mgc: 5.077952e-08
> 
> outer mgc:  0.544794
> 
> iter: 1  value: -5887.447 mgc: 0.003153025 ustep: 1
> 
> iter: 2  value: -5887.447 mgc: 6.546202e-08 ustep: 1
> 
> mgc: 9.447453e-08
> 
> outer mgc:  0.2579731
> 
> iter: 1  value: -5887.346 mgc: 0.003152465 ustep: 1
> 
> iter: 2  value: -5887.346 mgc: 5.733777e-08 ustep: 1
> 
> mgc: 7.849359e-08
> 
> outer mgc:  0.2594169
> 
> 
> 
> Does anyone have any insights into what might be going wrong?
> 
> Thanks!
> Rob
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From bbo|ker @end|ng |rom gm@||@com  Thu May 23 19:31:19 2019
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Thu, 23 May 2019 13:31:19 -0400
Subject: [R-sig-ME] False Convergence warning
In-Reply-To: <CADwBd8VwUriOBPyAQ-yZMwjeVfzHO=AVwyr2pJCAx71N+U7pTA@mail.gmail.com>
References: <CADwBd8VwUriOBPyAQ-yZMwjeVfzHO=AVwyr2pJCAx71N+U7pTA@mail.gmail.com>
Message-ID: <2d6deeca-d1c9-d4c0-6c64-413dd95a03a4@gmail.com>


  Some quick points.

* the nlminb "false convergence" error is quite hard to troubleshoot
<https://stackoverflow.com/questions/40039114/r-nlminb-what-does-false-convergence-actually-mean>

* I would normally suggest scaling your variables as a cheap way to
improve robustness, but it looks like your variables are all effectively
binary/scaled anyway?

* the only part of your model that looks unusual/glmmTMB-specific is
dispformula=~0:  I assume you're doing this because otherwise some of
your variance terms are confounded with the residual variance?  You
could try fitting this model in blme::blmer, with the residual std dev
prior fixed to a small non-zero value (the std dev value below is
(.Machine$double.eps)^(0.25)), and see if you get the same results ...

* it should be possible, but isn't presently, to try glmmTMB with an
alternate optimizer (stay tuned: this is available on a development
branch https://github.com/glmmTMB/glmmTMB/tree/mapArgs at the moment ...)

On 2019-05-21 11:07 a.m., Robert Ackerman wrote:
> Hi everyone,
> 
> I have data from a speed-dating study, where groups of men and women
> interacted with each other for five minutes and subsequently provided
> ratings of the interaction and their partner.
> 
> These are the first lines of my data set:
> 
>    GROUPID MaleID FemaleID MF FM Agender AATTRACT
> 
> 1        1      1        2  1  0       1     3.00
> 
> 2        1      1        4  1  0       1     3.25
> 
> 3        1      1        6  1  0       1     6.00
> 
> 4        1      1        8  1  0       1     3.50
> 
> 5        1      1       10  1  0       1     3.50
> 
> 6        1      1        2  0  1      -1     5.00
> 
> 7        1      3        2  0  1      -1     3.50
> 
> 8        1      5        2  0  1      -1     5.00
> 
> 9        1      7        2  0  1      -1     4.75
> 
> 10       1      9        2  0  1      -1     2.25
> 
> 11       1      3        2  1  0       1     1.25
> 
> 12       1      3        4  1  0       1     3.25
> 
> 
> 
> Altogether, I have 904 observations (33 speed-dating groups comprised of
> 3-5 men and women each).
> 
> I?m trying to use glmmTMB to get a model with crossed random effects and an
> unstructured covariance matrix for the residuals to run. Please note that I
> was able to get this model to run in SPSS without problems (estimates of
> fixed effects and random effects are also virtually identical). However, I
> wanted to use R for its ease of checking multilevel modeling assumptions.
> 
> Here is the syntax for the model I tried to run in glmmTMB:
> 
> glmmTMB(AATTRACT ~ 1 + Agender+ (0 + MF + FM|GROUPID:MaleID) +
> 
>                    (0 + FM + MF|GROUPID:FemaleID)  + us(MF + FM + 0|
> GROUPID:MaleID:FemaleID),
> 
>                     data = SD_data,  family = gaussian(link = "identity"),
> dispformula=~0, REML = FALSE,
> 
>                    verbose = TRUE)
> 
> I received the following output and error message after running this model:
> 
> Formula: AATTRACT ~ 1 + Agender + (0 + MF + FM | GROUPID:MaleID) + (0 +
> 
>   FM + MF | GROUPID:FemaleID) + us(0 + MF + FM + 0 | GROUPID:MaleID:FemaleID)
> 
> Dispersion:                ~0
> 
> Data: SD_data
> 
>       AIC       BIC    logLik  df.resid
> 
>  2891.436  2944.311 -1434.718       893
> 
> Random-effects (co)variances:
> 
> 
> 
> Conditional model:
> 
>  Groups                  Name Std.Dev.  Corr
> 
>  GROUPID:MaleID          MF   0.5572656
> 
>                          FM   0.7916470 -0.02
> 
>  GROUPID:FemaleID        FM   0.6732786
> 
>                          MF   0.7529185 -0.16
> 
>  GROUPID:MaleID:FemaleID MF   0.8523621
> 
>                          FM   0.9419247 0.26
> 
>  Residual                     0.0001221
> 
> 
> 
> Number of obs: 904 / Conditional model: GROUPID:MaleID, 120;
> GROUPID:FemaleID, 120; GROUPID:MaleID:FemaleID, 452
> 
> 
> 
> Fixed Effects:
> 
> 
> 
> Conditional model:
> 
> (Intercept)      Agender
> 
>      3.9048       0.1112
> 
> Warning message:
> 
> In fitTMB(TMBStruc) :
> 
>   Model convergence problem; false convergence (8). See
> vignette('troubleshooting')
> 
> 
> 
> Because I used verbose = TRUE, I also received the following mgc values
> (I?m only including the last few lines here).
> 
> mgc: 5.077952e-08
> 
> outer mgc:  0.544794
> 
> iter: 1  value: -5887.447 mgc: 0.003153025 ustep: 1
> 
> iter: 2  value: -5887.447 mgc: 6.546202e-08 ustep: 1
> 
> mgc: 9.447453e-08
> 
> outer mgc:  0.2579731
> 
> iter: 1  value: -5887.346 mgc: 0.003152465 ustep: 1
> 
> iter: 2  value: -5887.346 mgc: 5.733777e-08 ustep: 1
> 
> mgc: 7.849359e-08
> 
> outer mgc:  0.2594169
> 
> 
> 
> Does anyone have any insights into what might be going wrong?
> 
> Thanks!
> Rob
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From bernd@|enzner @end|ng |rom un|v|e@@c@@t  Thu May 23 16:50:23 2019
From: bernd@|enzner @end|ng |rom un|v|e@@c@@t (Bernd Lenzner)
Date: Thu, 23 May 2019 16:50:23 +0200
Subject: [R-sig-ME] GLMER vs. MCMCglmm - difference in model results -
 Poisson model with offset term
Message-ID: <f737a33a-1346-2e77-f4eb-a722462ec79b@univie.ac.at>

Dear everyone,

I have a question regarding the comparison of Generalized Linear Mixed 
Models (GLMM - using the lme4 - package) and Markov-Chain Monte-Carlo 
Generalized Mixed Models (MCMCglmm - using the MCMCglmm-package).

I am running mixed models using both packages. While the estimates 
provided by each approach are relatively comparable, the significance 
levels differ strongly. My main questions are the following:

1. How can the divergence in results be explained and why doe both 
methods provide different results even though the model structure is the 
same? (Note: diagnostic plots for both models look fine)

2. I am aware that there is strong debate about the validity of p-values 
within GLMMs. Is there similar concern regarding MCMCglmm?

3. What would be a sensible interpretation of both model outputs 
especially with respect to PRED2 and the interaction term.


Below I provide a short description and example output:

I want to test the effect of 3 continuous predictors (PRED2, PRED3, 
PRED4) on a proportional response (RESP). PRED2 and PRED3 enter the 
model as an interaction effect (PRED2*PRED3). The response is modeled 
using a Poisson error structure with a log-link function and the 
nominator of the ratio is therefore included as an offset predictor 
(offset(log(PRED1))).


MODEL1 -? GLMM using the lme4-package:


MOD1 <- glmer(RESP ~ offset(log(PRED1)) + PRED2 * PRED3 + PRED4 + 
(1|RANEF), family = "poisson", data = data, 
control=glmerControl(optimizer="bobyqa", optCtrl=list(maxfun=100000)))

summary(MOD1)

Generalized linear mixed model fit by maximum likelihood (Laplace 
Approximation) ['glmerMod'] Family: poisson ( log ) Formula: RESP ~ 
offset(log(PRED1)) + PRED2 * PRED3 + PRED4 + (1 | RANEF) Data: data 
Control: glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 
1e+05)) AIC BIC logLik deviance df.resid 2451.3 2470.9 -1219.6 2439.3 
190 Scaled residuals: Min 1Q Median 3Q Max -10.8175 -1.2477 -0.1913 
1.1076 11.0389 Random effects: Groups Name Variance Std.Dev. RANEF 
(Intercept) 0.1519 0.3898 Number of obs: 196, groups: Order, 56 Fixed 
effects: Estimate Std. Error z value Pr(>|z|) (Intercept) -3.29896 
0.06250 -52.784 < 2e-16 *** PRED2 0.09089 0.01850 4.912 9.00e-07 *** 
PRED3 0.57262 0.02375 24.114 < 2e-16 *** PRED4 0.54726 0.01808 30.275 < 
2e-16 *** PRED2:PRED3 0.12190 0.01821 6.693 2.19e-11 *** --- Signif. 
codes: 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1 Correlation of 
Fixed Effects: (Intr) PRED2 PRED3 PRED4 PRED2 -0.142 PRED3 -0.056 0.102 
PRED4 -0.042 0.135 -0.155 PRED2:PRED3 0.001 0.017 -0.678 0.273


MODEL2 -? MCMCglmm using the lme4-package:

Now I build the same model using a MCMCglmm using weak informative 
priors. The offset term was implemented following the suggestion by 
Jarrod Hadfield in this post 
(https://stat.ethz.ch/pipermail/r-sig-mixed-models/2017q3/026016.html). 
See the model formula and summary below:


prior <- list(B=list(V=diag(6)*10, mu=c(0,1,0,0,0,0)),
 ???????????????????????? G =list(G1=list(V=1,nu=0.002)),
 ???????????????????????? R=list(V=1,nu=0.002))
prior$B$V[2,2] <- 1e-9 # set fixed effect prior for the offset variable to 1
prior


PGLMM.MOD1 <- MCMCglmm(RESP ~ log(PRED1) + PRED2 * PRED3 + PRED4,
 ??????????????????????????????????????? random = ~ RANEF,
 ??????????????????????????????????????? family="poisson",
 ??????????????????????????????????????? prior = prior,
 ??????????????????????????????????????? scale = T,
 ??????????????????????????????????????? pr=TRUE,
 ??????????????????????????????????????? data = data,
 ??????????????????????????????????????? nitt = 500000, burnin = 20000, 
thin = 200)


summary(PGLMM.MOD1)

Iterations = 20001:499801 Thinning interval = 200 Sample size = 2400 
DIC: 1164.591 G-structure: ~Order post.mean l-95% CI u-95% CI eff.samp 
RANEF 0.02264 0.0002387 0.0762 2400 R-structure: ~units post.mean l-95% 
CI u-95% CI eff.samp units 0.2788 0.1946 0.3705 2400 Location effects: 
RESP ~ log(PRED1) + PRED2 * PRED3 + PRED4 post.mean l-95% CI u-95% CI 
eff.samp pMCMC (Intercept) -3.40280 -3.50958 -3.28826 2400 <4e-04 *** 
log(PRED1) 1.00000 0.99994 1.00006 2257 <4e-04 *** PRED2 0.08369 
-0.01995 0.18120 2400 0.113 PRED3 0.63058 0.52164 0.73889 2400 <4e-04 
*** PRED4 0.60488 0.50565 0.69963 2400 <4e-04 *** PRED2:PRED3 0.06882 
-0.02363 0.17414 2258 0.167 --- Signif. codes: 0 ?***? 0.001 ?**? 0.01 
?*? 0.05 ?.? 0.1 ? ? 1


As you can see from the different summaries, the estimates are fairly 
similar with some divergence especially regarding PRED2 and the 
interaction term. Additionally the provided p-values differ 
dramatically, with the GLMM (lme4) being highly significant for PRED2 
and the interaction wheras non-significance for the MCMCglmm.

My questions now are:

1. How can the divergence in results be explained and why doe both 
methods provide different results even though the model structure is the 
same? (Note: diagnostic plots for both models look fine)

2. I am aware that there is strong debate about the validity of p-values 
within GLMMs. Is there similar concern regarding MCMCglmm?

3. What would be a sensible interpretation of both model outputs 
especially with respect to PRED2 and the interaction term.


Any insight and help on that matter would be highly appreciated.

Best regards,

Bernd


-- 
Bernd Lenzner PhD

Researcher
University of Vienna
Department of Botany and Biodiversity Research
Division of Conservation Biology, Vegetation and Landscape Ecology
Rennweg 14
A-1030 Vienna



	[[alternative HTML version deleted]]


From o||verhooker @end|ng |rom pr@t@t|@t|c@@com  Fri May 24 00:48:22 2019
From: o||verhooker @end|ng |rom pr@t@t|@t|c@@com (Oliver Hooker)
Date: Thu, 23 May 2019 23:48:22 +0100
Subject: [R-sig-ME] Introduction to Bayesian hierarchical modelling using R
 (IBHM03)
Message-ID: <CAEsSYzxiZF1uvRNs+H51zNuVmZbxU+=yz9VYi3WjFi7rJkmo+A@mail.gmail.com>

Introduction to Bayesian hierarchical modelling using R (IBHM03)

https://www.psstatistics.com/course/introduction-to-bayesian-hierarchical-modelling-using-r-ibhm03/

This course will be delivered by Dr. Andrew Parnell from the 8th - 12th
July in Glasgow City Centre.

Course Overview:
This course will cover introductory hierarchical modelling for real-world
data sets from a Bayesian perspective. These methods lie at the forefront
of statistics research and are a vital tool in the scientist?s toolbox. The
course focuses on introducing concepts and demonstrating good practice in
hierarchical models. All methods are demonstrated with data sets which
participants can run themselves. Participants will be taught how to fit
hierarchical models using the Bayesian modelling software Jags and Stan
through the R software interface. The course covers the full gamut from
simple regression models through to full generalised multivariate
hierarchical structures. A Bayesian approach is taken throughout, meaning
that participants can include all available information in their models and
estimates all unknown quantities with uncertainty. Participants are
encouraged to bring their own data sets for discussion with the course
tutors.

Course Programme
Monday 8th ? Classes from 09:00 to 17:00

Module 1: Introduction to Bayesian Statistics
Module 2: Linear and generalised linear models (GLMs)
Practical: Using R, Jags and Stan for fitting GLMs
Round table discussion: Understanding Bayesian models

Tuesday 9th ? Classes from 09:00 to 17:00

Module 3: Simple hierarchical regression models
Module 4: Hierarchical models for non-Gaussian data
Practical: Fitting hierarchical models
Round table discussion: Interpreting hierarchical model output

Wednesday 10th ? Classes from 09:00 to 17:00

Module 5: Hierarchical models vs mixed effects models
Module 6:  Multivariate and multi-layer hierarchical models
Practical: Advanced examples of hierarchical models
Round table discussion: Issues of continuous vs discrete time

Thursday 11th ? Classes from 09:00 to 16:00

Module 7: Shrinkage and variable selection
Module 8: Hierarchical models and partial pooling
Practical: Shrinkage modelling
Round table discussion Bring your own data set

Friday 12th ? Classes from 09:00 to 16:00
Email oliverhooker at psstatistics.com

Check out our sister sites,
www.PRstatistics.com (Ecology and Life Sciences)
www.PRstatistics.com/consultancy (Statistical and bioinformatics
consultancy in all fields)
www.PRinformatics.com (Bioinformatics and data science)
www.PSstatistics.com (Behaviour and cognition)


1. June 10th ? 14th 2019
STABLE ISOTOPE MIXING MODELS USING SIAR, SIBER AND MIXSIAR (SIMM04)
Glasgow, Scotland, Dr. Andrew Parnell, Dr. Andrew Jackson
www.prstatistics.com/course/stable-isotope-mixing-models-using-r-simm04/

2. June 10th ? 14th 2019
INTRODUCTION TO PYTHON FOR BIOLOGISTS (IPYB06)
Glasgow, Scotland, Dr. Martin Jones
http://www.prinformatics.com/course/introduction-to-python-for-biologists-ipyb06/

3. June 17th ? 21st 2019
ADVANCED PYTHON FOR BIOLOGISTS (APYB03)
Glasgow, Scotland, Dr. Martin Jones
www.prinformatics.com/course/advanced-python-biologists-apyb03/

4. June 24th ? 28th 2019
MICROBIOME DATA ANALYSIS USING QIIME2 (MBQM01)
Glasgow, Scotland, Dr. Yoshiki Vazquez Baeza, Dr. Antonio Gonzalez Pena
https://www.prinformatics.com/course/microbiome-data-analysis-using-qiime2-mbqm01/

5. July 1st ? 5th 2019
BIOACOUSTICS FOR ECOLOGISTS: HARDWARE, SURVEY DESIGN AND DATA ANALYSIS
(BIAC01)
Glasgow, Scotland, Dr. Paul Howden-Leach
https://www.prstatistics.com/course/bioacoustics-for-ecologists-hardware-survey-design-and-data-analysis-biac01/

6. July 8th ? 12th 2019
INTRODUCTION TO BAYESIAN HIERARCHICAL MODELLING USING R (IBHM03)
Glasgow, Scotland, Dr. Andrew Parnell
https://www.psstatistics.com/course/introduction-to-bayesian-hierarchical-modelling-using-r-ibhm03/

7. July 15th ? 19th 2019
ANALYSING ENVIRONMENTAL ADAPTATION USING LANDSCAPE GENETICS (EDAP01)
Glasgow, Dr. Matt Fitzpatrick
https://www.prstatistics.com/course/analysing-environmental-adaptation-using-landscape-genetics-edap01

8. July 29th ? August 2nd 2019
INTRODUCTION TO SPATIAL ANALYSIS OF ECOLOGICAL DATA USING R (ISPE01)
Glasgow, Scotland, Dr. Jakub Nowosad
https://www.prstatistics.com/course/introduction-to-spatial-analysis-of-ecological-data-using-r-ispe01/

9. September 2nd ? 6th 2019
APPLIED METHODS FOR ANALYSING CAPTURE-RECAPTURE (MARK-RECAPTURE) DATA USING
SPATIALLY EXPLICIT AND NON-SPATIAL TECHNIQUES (MARK01)
Glasgow, Scotland, Dr. Joanne Potts, Dr. David Borchers
https://www.prstatistics.com/course/applied-methods-for-analysing-capture-recapture-mark-recapture-data-using-spatially-explicit-and-non-spatial-techniques-mark01/

10. September 9th ? 13th 2019
DATA SCIENCE/ANALYTICS USING PYTHON (DSAP01)
Glasgow, Scotland, Dr. Mark Andrews
https://www.psstatistics.com/course/data-science-analytics-using-python-dsap01/

11. September 16th ? 20th 2019
R PACKAGE DESIGN AND DEVELOPMENT AND REPRODUCIBLE DATA SCIENCE FOR
BIOLOGISTS (RPKG01)
Glasgow, Scotland, Dr. Cory Merow, Dr. Andy Rominger
https://www.prstatistics.com/course/r-package-design-and-development-and-reproducible-data-science-for-biologists-rpkg01/

12. September 16th ? 20th 2019
STRUCTURAL EQUATION MODELLING AND PATH ANALYSIS (SMPA01)
Glasgow, Scotland, Dr. Mark Andrews
https://www.psstatistics.com/course/structural-equation-modelling-and-path-analysis-smpa01/

13. September 23rd ? 27th 2019
GENERALISED LINEAR (GLM), NONLINEAR (NLGLM) AND GENERAL ADDITIVE MODELS
(GAM?S) (GNAM01)
Glasgow, Scotland, Dr. Mark Andrews
https://www.psstatistics.com/course/generalised-linear-glm-nonlinear-nlglm-and-general-additive-models-gam-gnam01/

14. September 30th ? October 4th 2019
GEOMETRIC MORPHOMETRICS USING R (GMMR02)
Glasgow, Scotland, Prof. Dean Adams, Prof. Michael Collyer, Dr. Antigoni
Kaliontzopoulou
http://www.prstatistics.com/course/geometric-morphometrics-using-r-gmmr02/

15. October 7th ? 11th 2019
CONSERVATION PLANNING USING PRIORITIZR : FROM THEORY TO PRACTICE (PRTZ01)
Athens, GREECE, Dr Richard Schuster and Nina Morell
https://www.prstatistics.com/course/conservation-planning-using-prioritizr-from-theory-to-practice-prtz01/

16. October 14th ? 18th 2019
INTRODUCTION TO BEHAVIOURAL DATA ANALYSIS USINR R (IBDA01)
Glasgow, Scotland, Dr Will Hoppitt
https://www.psstatistics.com/course/introduction-to-behavioural-data-analysis-using-r-ibda01/

17. November 4th ? 8th 2019
Glasgow, Scotland, Dr. Mark Andrews
INTRODUCTION TO BAYESIAN DATA ANALYSIS FOR SOCIAL AND BEHAVIOURAL SCIENCES
USING R AND STAN (BDRS02)
https://www.psstatistics.com/course/introduction-to-bayesian-data-analysis-for-social-and-behavioural-sciences-using-r-and-stan-bdrs02/

18. November 4th ? 8th 2019
BEHAVIOURAL DATA ANALYSIS USING MAXIMUM LIKELIHOOD (BDML01)
Glasgow, Scotland, Dr Will Hoppitt
https://www.psstatistics.com/course/behavioural-data-analysis-using-maximum-likelihood-bdml02/

19. November 11th ? 15th 2019
APPLIED BAYESIAN MODELLING FOR ECOLOGISTS AND EPIDEMIOLOGISTS (ABME05)
Glasgow, Scotland, Dr Matt Denwood, Emma Howard
https://www.prstatistics.com/course/applied-bayesian-modelling-for-ecologists-and-epidemiologists-abme05/

20. November 18th ? 22nd 2019
INTRODUCTION TO STRUCTURED POPULATION MODELS AND DEMOGRAPHIC DISTRIBUTION
MODELS (IIPM01)
Athens, GREECE, Dr Cory Merow
https://www.prstatistics.com/course/introduction-to-structured-population-models-and-demographic-distribution-models-iipm01/

21. November 25th ? 29th 2019
ADVANCED RANGE, NICHE, AND DISTRIBUTION MODELING (ASDM01)
Athens, GREECE, Dr Cory Merow
https://www.prstatistics.com/course/advanced-range-niche-and-distribution

-- 
Oliver Hooker PhD.
PR statistics

2019 publications;

A way forward with eco evo devo: an extended theory of resource
polymorphism with postglacial fishes as model systems. Biological Reviews
(2019).

prstatistics.com
facebook.com/prstatistics/
twitter.com/PRstatistics
groups.google.com/d/forum/pr-statistics-post-course-forum
prstatistics.com/organiser/oliver-hooker/

6 Hope Park Crescent
Edinburgh
EH8 9NA
+44 (0) 7966500340

	[[alternative HTML version deleted]]


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Fri May 24 09:58:40 2019
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Fri, 24 May 2019 09:58:40 +0200
Subject: [R-sig-ME] GLMER vs. MCMCglmm - difference in model results -
 Poisson model with offset term
In-Reply-To: <f737a33a-1346-2e77-f4eb-a722462ec79b@univie.ac.at>
References: <f737a33a-1346-2e77-f4eb-a722462ec79b@univie.ac.at>
Message-ID: <23783.42032.196493.808135@stat.math.ethz.ch>

Dear Bernd,

can you please repost using "plain text" instead of "rich text"
/ "formatted text" or whatever your e-mail app calls what really
is HTML ?

See how almost unreadable your  R output  ends up in the post of
your e-mail :

>>>>> Bernd Lenzner 
>>>>>     on Thu, 23 May 2019 16:50:23 +0200 writes:

    > Dear everyone,
    > I have a question regarding the comparison of Generalized Linear Mixed 
    > Models (GLMM - using the lme4 - package) and Markov-Chain Monte-Carlo 
    > Generalized Mixed Models (MCMCglmm - using the MCMCglmm-package).

    > I am running mixed models using both packages. While the estimates 
    > provided by each approach are relatively comparable, the significance 
    > levels differ strongly. My main questions are the following:

    > 1. How can the divergence in results be explained and why doe both 
    > methods provide different results even though the model structure is the 
    > same? (Note: diagnostic plots for both models look fine)

    > 2. I am aware that there is strong debate about the validity of p-values 
    > within GLMMs. Is there similar concern regarding MCMCglmm?

    > 3. What would be a sensible interpretation of both model outputs 
    > especially with respect to PRED2 and the interaction term.


    > Below I provide a short description and example output:

    > I want to test the effect of 3 continuous predictors (PRED2, PRED3, 
    > PRED4) on a proportional response (RESP). PRED2 and PRED3 enter the 
    > model as an interaction effect (PRED2*PRED3). The response is modeled 
    > using a Poisson error structure with a log-link function and the 
    > nominator of the ratio is therefore included as an offset predictor 
    > (offset(log(PRED1))).


    > MODEL1 -? GLMM using the lme4-package:


    > MOD1 <- glmer(RESP ~ offset(log(PRED1)) + PRED2 * PRED3 + PRED4 + 
    > (1|RANEF), family = "poisson", data = data, 
    > control=glmerControl(optimizer="bobyqa", optCtrl=list(maxfun=100000)))

    > summary(MOD1)

    > Generalized linear mixed model fit by maximum likelihood (Laplace 
    > Approximation) ['glmerMod'] Family: poisson ( log ) Formula: RESP ~ 
    > offset(log(PRED1)) + PRED2 * PRED3 + PRED4 + (1 | RANEF) Data: data 
    > Control: glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 
    > 1e+05)) AIC BIC logLik deviance df.resid 2451.3 2470.9 -1219.6 2439.3 
    > 190 Scaled residuals: Min 1Q Median 3Q Max -10.8175 -1.2477 -0.1913 
    > 1.1076 11.0389 Random effects: Groups Name Variance Std.Dev. RANEF 
    > (Intercept) 0.1519 0.3898 Number of obs: 196, groups: Order, 56 Fixed 
    > effects: Estimate Std. Error z value Pr(>|z|) (Intercept) -3.29896 
    > 0.06250 -52.784 < 2e-16 *** PRED2 0.09089 0.01850 4.912 9.00e-07 *** 
    > PRED3 0.57262 0.02375 24.114 < 2e-16 *** PRED4 0.54726 0.01808 30.275 < 
    > 2e-16 *** PRED2:PRED3 0.12190 0.01821 6.693 2.19e-11 *** --- Signif. 
    > codes: 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1 Correlation of 
    > Fixed Effects: (Intr) PRED2 PRED3 PRED4 PRED2 -0.142 PRED3 -0.056 0.102 
    > PRED4 -0.042 0.135 -0.155 PRED2:PRED3 0.001 0.017 -0.678 0.273


    > MODEL2 -? MCMCglmm using the lme4-package:

    > Now I build the same model using a MCMCglmm using weak informative 
    > priors. The offset term was implemented following the suggestion by 
    > Jarrod Hadfield in this post 
    > (https://stat.ethz.ch/pipermail/r-sig-mixed-models/2017q3/026016.html). 
    > See the model formula and summary below:


    > prior <- list(B=list(V=diag(6)*10, mu=c(0,1,0,0,0,0)),
    > ???????????????????????? G =list(G1=list(V=1,nu=0.002)),
    > ???????????????????????? R=list(V=1,nu=0.002))
    > prior$B$V[2,2] <- 1e-9 # set fixed effect prior for the offset variable to 1
    > prior


    > PGLMM.MOD1 <- MCMCglmm(RESP ~ log(PRED1) + PRED2 * PRED3 + PRED4,
    > ??????????????????????????????????????? random = ~ RANEF,
    > ??????????????????????????????????????? family="poisson",
    > ??????????????????????????????????????? prior = prior,
    > ??????????????????????????????????????? scale = T,
    > ??????????????????????????????????????? pr=TRUE,
    > ??????????????????????????????????????? data = data,
    > ??????????????????????????????????????? nitt = 500000, burnin = 20000, 
    > thin = 200)


    > summary(PGLMM.MOD1)

    > Iterations = 20001:499801 Thinning interval = 200 Sample size = 2400 
    > DIC: 1164.591 G-structure: ~Order post.mean l-95% CI u-95% CI eff.samp 
    > RANEF 0.02264 0.0002387 0.0762 2400 R-structure: ~units post.mean l-95% 
    > CI u-95% CI eff.samp units 0.2788 0.1946 0.3705 2400 Location effects: 
    > RESP ~ log(PRED1) + PRED2 * PRED3 + PRED4 post.mean l-95% CI u-95% CI 
    > eff.samp pMCMC (Intercept) -3.40280 -3.50958 -3.28826 2400 <4e-04 *** 
    > log(PRED1) 1.00000 0.99994 1.00006 2257 <4e-04 *** PRED2 0.08369 
    > -0.01995 0.18120 2400 0.113 PRED3 0.63058 0.52164 0.73889 2400 <4e-04 
    > *** PRED4 0.60488 0.50565 0.69963 2400 <4e-04 *** PRED2:PRED3 0.06882 
    > -0.02363 0.17414 2258 0.167 --- Signif. codes: 0 ?***? 0.001 ?**? 0.01 
    > ?*? 0.05 ?.? 0.1 ? ? 1


    > As you can see from the different summaries, the estimates are fairly 
    > similar with some divergence especially regarding PRED2 and the 
    > interaction term. Additionally the provided p-values differ 
    > dramatically, with the GLMM (lme4) being highly significant for PRED2 
    > and the interaction wheras non-significance for the MCMCglmm.

    > My questions now are:

    > 1. How can the divergence in results be explained and why doe both 
    > methods provide different results even though the model structure is the 
    > same? (Note: diagnostic plots for both models look fine)

    > 2. I am aware that there is strong debate about the validity of p-values 
    > within GLMMs. Is there similar concern regarding MCMCglmm?

    > 3. What would be a sensible interpretation of both model outputs 
    > especially with respect to PRED2 and the interaction term.


    > Any insight and help on that matter would be highly appreciated.

    > Best regards,

    > Bernd


    > -- 
    > Bernd Lenzner PhD

    > Researcher
    > University of Vienna
    > Department of Botany and Biodiversity Research
    > Division of Conservation Biology, Vegetation and Landscape Ecology
    > Rennweg 14
    > A-1030 Vienna


    > [[alternative HTML version deleted]]

    > _______________________________________________
    > R-sig-mixed-models at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From c@c@voeten @end|ng |rom hum@|e|denun|v@n|  Sun May 26 17:55:59 2019
From: c@c@voeten @end|ng |rom hum@|e|denun|v@n| (Cesko Voeten)
Date: Sun, 26 May 2019 17:55:59 +0200
Subject: [R-sig-ME] R package buildmer for automatic stepwise selection of
 mixed-effects models and GAMMs
Message-ID: <a6dbc14e-f4b4-c534-5afc-6d6de016c56c@hum.leidenuniv.nl>

I?ve recently published version 1.1 of my package 'buildmer' on CRAN (version 1.0 was a beta release to solicit feedback from direct colleagues). I thought that the folks here on r-sig-mixed might also be interested, in case they have similar problems to my original use-case: term selection in models with many random effects where the 'maximal' model does not necessarily converge.

'buildmer' automates term ordering and stepwise selection/elimination in, primarily, mixed-effects models. By 'term ordering' is meant that the user can specify a desired maximal model, and the package will determine the largest random-effects structure that still achieves convergence. This is done by starting from the fixed-effects model, and adding r.e. terms one by one in order of importance (by default, 'importance' is the value of the LRT statistic) until convergence is no longer possible. Next, the package can do automatic forward or backward elimination of both fixed and random effects. The package takes care of fitting with ML versus REML and of dividing LRT p-values by 2 for random-effect tests. Thus, the user only needs to provide an intended maximal model and wait for the results (just call function 'buildmer' with an lme4 formula for your maximal model, plus any data= and family= argument). Possible criteria for term ordering and elimination are LRT (default), AIC, BIC, or change in log-likelihood; user-specified criteria are also possible.

I started work on this package as a small script two years ago, when lmerTest's step() function was not yet fully capable of handling convergence failures (this has been much improved in lmerTest version 3.0), and when I wanted to use stepwise elimination based on likelihood-ratio tests (for fixed effects step() only offers F tests). If you use lmer or glmer models, require only backward elimination, and are okay with using F tests, there is not much reason for you to try buildmer over lmerTest. If you require more flexibility, you may be interested in giving buildmer a try. There is no statistical model-fitting code in buildmer, it is simply a glorified formula parser and wrapper around logLik() and friends. This also made it easy to extend it to models such as GAMMs or glmmTMB models, which are also supported. For the same reasons, I unfortunately cannot fold buildmer into a pull request to lmerTest, as it takes a fundamentally different approach.

I have now come to rely on this package for most of my models where variable selection is required. I hope others may find it useful too, and if not, sorry for the noise! Any issue reports and points of discussion are always welcome, of course, especially since I also rely on this package for my own research.

Best,
Cesko Voeten

From bernd@|enzner @end|ng |rom un|v|e@@c@@t  Fri May 24 10:51:26 2019
From: bernd@|enzner @end|ng |rom un|v|e@@c@@t (Bernd Lenzner)
Date: Fri, 24 May 2019 10:51:26 +0200
Subject: [R-sig-ME] GLMER vs. MCMCglmm - difference in model results -
 Poisson model with offset term
In-Reply-To: <ebbe3aae-4e36-04b5-1d72-ac0f200707b2@univie.ac.at>
References: <ebbe3aae-4e36-04b5-1d72-ac0f200707b2@univie.ac.at>
Message-ID: <d74fa3e3-a67c-7ccd-c4ef-ec7d01846978@univie.ac.at>


Dear everyone,

I have a question regarding the comparison of Generalized Linear Mixed 
Models (GLMM - using the lme4 - package) and Markov-Chain Monte-Carlo 
Generalized Mixed Models (MCMCglmm - using the MCMCglmm-package).

I am running mixed models using both packages. While the estimates 
provided by each approach are relatively comparable, the significance 
levels differ strongly. My main questions are the following:

1. How can the divergence in results be explained and why doe both 
methods provide different results even though the model structure is the 
same? (Note: diagnostic plots for both models look fine)

2. I am aware that there is strong debate about the validity of p-values 
within GLMMs. Is there similar concern regarding MCMCglmm?

3. What would be a sensible interpretation of both model outputs 
especially with respect to PRED2 and the interaction term.


Below I provide a short description and example output:

I want to test the effect of 3 continuous predictors (PRED2, PRED3, 
PRED4) on a proportional response (RESP). PRED2 and PRED3 enter the 
model as an interaction effect (PRED2*PRED3). The response is modeled 
using a Poisson error structure with a log-link function and the 
nominator of the ratio is therefore included as an offset predictor 
(offset(log(PRED1))).


MODEL1 -  GLMM using the lme4-package:


MOD1 <- glmer(RESP ~ offset(log(PRED1)) + PRED2 * PRED3 + PRED4 + 
(1|RANEF), family = "poisson", data = data, 
control=glmerControl(optimizer="bobyqa", optCtrl=list(maxfun=100000)))

summary(MOD1)
Generalized linear mixed model fit by maximum likelihood (Laplace 
Approximation) ['glmerMod']
  Family: poisson  ( log )
Formula: RESP ~ offset(log(PRED1)) + PRED2 * PRED3 + PRED4 + (1 | RANEF)
    Data: data
Control: glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 1e+05))

      AIC      BIC   logLik deviance df.resid
   2451.3   2470.9  -1219.6   2439.3      190

Scaled residuals:
      Min       1Q   Median       3Q      Max
-10.8175  -1.2477  -0.1913   1.1076  11.0389

Random effects:
  Groups Name        Variance Std.Dev.
  RANEF  (Intercept) 0.1519   0.3898
Number of obs: 196, groups:  Order, 56

Fixed effects:
                   Estimate    Std. Error z value Pr(>|z|)
(Intercept)       -3.29896    0.06250    -52.784   < 2e-16 ***
PRED2              0.09089    0.01850     4.912     9.00e-07 ***
PRED3              0.57262    0.02375    24.114    < 2e-16 ***
PRED4              0.54726    0.01808    30.275    < 2e-16 ***
PRED2:PRED3        0.12190    0.01821     6.693     2.19e-11 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Correlation of Fixed Effects:
               (Intr)    PRED2     PRED3    PRED4
PRED2         -0.142
PRED3         -0.056    0.102
PRED4         -0.042    0.135    -0.155
PRED2:PRED3    0.001    0.017    -0.678     0.273


MODEL2 -  MCMCglmm using the lme4-package:

Now I build the same model using a MCMCglmm using weak informative 
priors. The offset term was implemented following the suggestion by 
Jarrod Hadfield in this post 
(https://stat.ethz.ch/pipermail/r-sig-mixed-models/2017q3/026016.html). 
See the model formula and summary below:


prior <- list(B=list(V=diag(6)*10, mu=c(0,1,0,0,0,0)),
                          G =list(G1=list(V=1,nu=0.002)),
                          R=list(V=1,nu=0.002))
prior$B$V[2,2] <- 1e-9 # set fixed effect prior for the offset variable to 1


PGLMM.MOD1 <- MCMCglmm(RESP ~ log(PRED1) + PRED2 * PRED3 + PRED4,
                                         random = ~ RANEF,
                                         family="poisson",
                                         prior = prior,
                                         scale = T,
                                         pr=TRUE,
                                         data = data,
                                         nitt = 500000, burnin = 20000, 
thin = 200)


summary(PGLMM.MOD1)

Iterations = 20001:499801
  Thinning interval  = 200
  Sample size  = 2400

  DIC: 1164.591

  G-structure:  ~Order

         post.mean  l-95% CI    u-95% CI   eff.samp
RANEF   0.02264    0.0002387   0.0762      2400

  R-structure:  ~units

          post.mean    l-95% CI     u-95% CI     eff.samp
units    0.2788       0.1946       0.3705        2400

  Location effects: RESP ~ log(PRED1) + PRED2 * PRED3 + PRED4

              post.mean   l-95% CI  u-95% CI   eff.samp   pMCMC
(Intercept)  -3.40280   -3.50958   -3.28826   2400       <4e-04 ***
log(PRED1)   1.00000    0.99994    1.00006    2257       <4e-04 ***
PRED2        0.08369    -0.01995   0.18120    2400       0.113
PRED3        0.63058    0.52164    0.73889    2400       <4e-04 ***
PRED4        0.60488    0.50565    0.69963    2400       <4e-04 ***
PRED2:PRED3  0.06882    -0.02363   0.17414    2258       0.167
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1


As you can see from the different summaries, the estimates are fairly 
similar with some divergence especially regarding PRED2 and the 
interaction term. Additionally the provided p-values differ 
dramatically, with the GLMM (lme4) being highly significant for PRED2 
and the interaction wheras non-significance for the MCMCglmm.

My questions now are:

1. How can the divergence in results be explained and why doe both 
methods provide different results even though the model structure is the 
same? (Note: diagnostic plots for both models look fine)

2. I am aware that there is strong debate about the validity of p-values 
within GLMMs. Is there similar concern regarding MCMCglmm?

3. What would be a sensible interpretation of both model outputs 
especially with respect to PRED2 and the interaction term.


Any insight and help on that matter would be highly appreciated.

Best regards,

Bernd


-- 
Bernd Lenzner PhD

Researcher
University of Vienna
Department of Botany and Biodiversity Research
Division of Conservation Biology, Vegetation and Landscape Ecology
Rennweg 14
A-1030 Vienna


From p@u|@john@on @end|ng |rom g|@@gow@@c@uk  Tue May 28 10:58:25 2019
From: p@u|@john@on @end|ng |rom g|@@gow@@c@uk (Paul Johnson)
Date: Tue, 28 May 2019 08:58:25 +0000
Subject: [R-sig-ME] GLMER vs. MCMCglmm - difference in model results -
 Poisson model with offset term
In-Reply-To: <d74fa3e3-a67c-7ccd-c4ef-ec7d01846978@univie.ac.at>
References: <ebbe3aae-4e36-04b5-1d72-ac0f200707b2@univie.ac.at>
 <d74fa3e3-a67c-7ccd-c4ef-ec7d01846978@univie.ac.at>
Message-ID: <6F66AAA2-97B0-4544-88C8-BEC051F2944D@glasgow.ac.uk>

Hi Bernd,

I think there are two problems. 

1. 
If your response is a number of successes (RESP) out of a number of trials (PRED1), it should be modelled with the binomial distribution. In glmer this would take the form cbind(RESP, PRED1 - RESP) ~ ? . (If the proportion is low, you?ll likely find this makes little difference.)

2. 
The two Poisson models aren?t comparable because your glmer Poisson model has no residual term, i.e. no random effect to mop up variation not explained by the fixed effects and the Poisson distribution, while MCMCglmm fits this by default. You can see this in the glmer output in the residual deviance being much larger than the residual df, and in the wide spread of the standardised residuals. The basic problem is that a pure Poisson GLMM assumes that all the variation in your model can be explained, except for the very limited degree of random variation allowed by the Poisson distribution. This is hardly ever a sensible starting assumption when modelling messy biological count data (which is what most of us are doing). It?s a very common error and quite dangerous because it tends to generate spuriously significant results, as you appear to have found. The same applies to comparing binomial models (provided n trials > 1) between glmer and MCMCglmm. If you add an observation-level random intercept to the glmer model (whether binomial or Poisson) then the two models will be comparable, i.e. (1 | obs) where obs is factor(1:nrow(data)). You can also model overdispersion with a negative binomial using glmer.nb, but there?s no comparable method in MCMCglmm.

Al the best,
Paul 

PS as an aside, you can spot overdispersion in the standard residuals-by-fitted diagnostic scatter plot by comparing it with a plot simulated from the fitted model:

library(devtools)
install_github("pcdjohnson/GLMMmisc")
library(GLMMmisc)
library(lme4)

# Poisson-lognormal model with random effect to model overdispersion (INDEX)
fit.poisln <-
  glmer(TICKS ~ YEAR + scale(HEIGHT) + (1 | BROOD) + (1 | LOCATION) + (1 | INDEX),
        family = "poisson", data = grouseticks)
# pure Poisson model with no random effect to model overdispersion
fit.pois <-
  glmer(TICKS ~ YEAR + scale(HEIGHT) + (1 | BROOD) + (1 | LOCATION),
        family = "poisson", data = grouseticks)

par(mfrow = c(1, 2))
sim.residplot(fit.pois)
title("Pure Poisson GLMM")
sim.residplot(fit.poisln)
title("Poisson-lognormal GLMM")

# if you run the plotting lines a few times you'll see that the simulated residuals 
# tend to look simular to the real residuals from the Poisson-lognormal GLMM
# (a good sign) but much less spread out than the real residuals from the 
# pure Poisson model, a sign that the latter model is failing to account for
# a substantial amount of variation in the responses.
# NB the DHARMa package does something similar but in a more formal and
# sophisticated way


> On 24 May 2019, at 09:51, Bernd Lenzner <bernd.lenzner at univie.ac.at> wrote:
> 
> 
> Dear everyone,
> 
> I have a question regarding the comparison of Generalized Linear Mixed Models (GLMM - using the lme4 - package) and Markov-Chain Monte-Carlo Generalized Mixed Models (MCMCglmm - using the MCMCglmm-package).
> 
> I am running mixed models using both packages. While the estimates provided by each approach are relatively comparable, the significance levels differ strongly. My main questions are the following:
> 
> 1. How can the divergence in results be explained and why doe both methods provide different results even though the model structure is the same? (Note: diagnostic plots for both models look fine)
> 
> 2. I am aware that there is strong debate about the validity of p-values within GLMMs. Is there similar concern regarding MCMCglmm?
> 
> 3. What would be a sensible interpretation of both model outputs especially with respect to PRED2 and the interaction term.
> 
> 
> Below I provide a short description and example output:
> 
> I want to test the effect of 3 continuous predictors (PRED2, PRED3, PRED4) on a proportional response (RESP). PRED2 and PRED3 enter the model as an interaction effect (PRED2*PRED3). The response is modeled using a Poisson error structure with a log-link function and the nominator of the ratio is therefore included as an offset predictor (offset(log(PRED1))).
> 
> 
> MODEL1 -  GLMM using the lme4-package:
> 
> 
> MOD1 <- glmer(RESP ~ offset(log(PRED1)) + PRED2 * PRED3 + PRED4 + (1|RANEF), family = "poisson", data = data, control=glmerControl(optimizer="bobyqa", optCtrl=list(maxfun=100000)))
> 
> summary(MOD1)
> Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) ['glmerMod']
> Family: poisson  ( log )
> Formula: RESP ~ offset(log(PRED1)) + PRED2 * PRED3 + PRED4 + (1 | RANEF)
>   Data: data
> Control: glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 1e+05))
> 
>     AIC      BIC   logLik deviance df.resid
>  2451.3   2470.9  -1219.6   2439.3      190
> 
> Scaled residuals:
>     Min       1Q   Median       3Q      Max
> -10.8175  -1.2477  -0.1913   1.1076  11.0389
> 
> Random effects:
> Groups Name        Variance Std.Dev.
> RANEF  (Intercept) 0.1519   0.3898
> Number of obs: 196, groups:  Order, 56
> 
> Fixed effects:
>                  Estimate    Std. Error z value Pr(>|z|)
> (Intercept)       -3.29896    0.06250    -52.784   < 2e-16 ***
> PRED2              0.09089    0.01850     4.912     9.00e-07 ***
> PRED3              0.57262    0.02375    24.114    < 2e-16 ***
> PRED4              0.54726    0.01808    30.275    < 2e-16 ***
> PRED2:PRED3        0.12190    0.01821     6.693     2.19e-11 ***
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> 
> Correlation of Fixed Effects:
>              (Intr)    PRED2     PRED3    PRED4
> PRED2         -0.142
> PRED3         -0.056    0.102
> PRED4         -0.042    0.135    -0.155
> PRED2:PRED3    0.001    0.017    -0.678     0.273
> 
> 
> MODEL2 -  MCMCglmm using the lme4-package:
> 
> Now I build the same model using a MCMCglmm using weak informative priors. The offset term was implemented following the suggestion by Jarrod Hadfield in this post (https://stat.ethz.ch/pipermail/r-sig-mixed-models/2017q3/026016.html). See the model formula and summary below:
> 
> 
> prior <- list(B=list(V=diag(6)*10, mu=c(0,1,0,0,0,0)),
>                         G =list(G1=list(V=1,nu=0.002)),
>                         R=list(V=1,nu=0.002))
> prior$B$V[2,2] <- 1e-9 # set fixed effect prior for the offset variable to 1
> 
> 
> PGLMM.MOD1 <- MCMCglmm(RESP ~ log(PRED1) + PRED2 * PRED3 + PRED4,
>                                        random = ~ RANEF,
>                                        family="poisson",
>                                        prior = prior,
>                                        scale = T,
>                                        pr=TRUE,
>                                        data = data,
>                                        nitt = 500000, burnin = 20000, thin = 200)
> 
> 
> summary(PGLMM.MOD1)
> 
> Iterations = 20001:499801
> Thinning interval  = 200
> Sample size  = 2400
> 
> DIC: 1164.591
> 
> G-structure:  ~Order
> 
>        post.mean  l-95% CI    u-95% CI   eff.samp
> RANEF   0.02264    0.0002387   0.0762      2400
> 
> R-structure:  ~units
> 
>         post.mean    l-95% CI     u-95% CI     eff.samp
> units    0.2788       0.1946       0.3705        2400
> 
> Location effects: RESP ~ log(PRED1) + PRED2 * PRED3 + PRED4
> 
>             post.mean   l-95% CI  u-95% CI   eff.samp   pMCMC
> (Intercept)  -3.40280   -3.50958   -3.28826   2400       <4e-04 ***
> log(PRED1)   1.00000    0.99994    1.00006    2257       <4e-04 ***
> PRED2        0.08369    -0.01995   0.18120    2400       0.113
> PRED3        0.63058    0.52164    0.73889    2400       <4e-04 ***
> PRED4        0.60488    0.50565    0.69963    2400       <4e-04 ***
> PRED2:PRED3  0.06882    -0.02363   0.17414    2258       0.167
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> 
> 
> As you can see from the different summaries, the estimates are fairly similar with some divergence especially regarding PRED2 and the interaction term. Additionally the provided p-values differ dramatically, with the GLMM (lme4) being highly significant for PRED2 and the interaction wheras non-significance for the MCMCglmm.
> 
> My questions now are:
> 
> 1. How can the divergence in results be explained and why doe both methods provide different results even though the model structure is the same? (Note: diagnostic plots for both models look fine)
> 
> 2. I am aware that there is strong debate about the validity of p-values within GLMMs. Is there similar concern regarding MCMCglmm?
> 
> 3. What would be a sensible interpretation of both model outputs especially with respect to PRED2 and the interaction term.
> 
> 
> Any insight and help on that matter would be highly appreciated.
> 
> Best regards,
> 
> Bernd
> 
> 
> -- 
> Bernd Lenzner PhD
> 
> Researcher
> University of Vienna
> Department of Botany and Biodiversity Research
> Division of Conservation Biology, Vegetation and Landscape Ecology
> Rennweg 14
> A-1030 Vienna
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From m|ch@e|@wh|tby @end|ng |rom gm@||@com  Wed May 29 20:38:57 2019
From: m|ch@e|@wh|tby @end|ng |rom gm@||@com (Michael Whitby)
Date: Wed, 29 May 2019 13:38:57 -0500
Subject: [R-sig-ME] GLMMTMB false convergence
Message-ID: <CAOgUSWGuLooBKO6tG_X_N-N9p-Cxj1_Q7FeNSS331v2zqN_9KA@mail.gmail.com>

Hello,

I have built a zero-inflated GLMM (truncated_nbinom2 distribution) with an
ar1 covariance structure using GLMMTMB (latest development version as of
yesterday) and MRAN 3.5.1 on a server running windows server 2016.

The model produces a warning about false convergence and points to the
troubleshooting vignette.
However, that page does not specifically mention false convergence. Is the
advice for handling this warning the same as another section in the
vignette?

There are no NA's in the parameter estimate, the AIC values are reported,
and sdr$pdhess is TRUE.

Is this model useable? If not, any advice on determining where the problem
exists? (I assume it is overparameterized despite a large dataset)

I apologize for not including a reproducible example, I haven't been able
to reproduce the false convergence warning with other datasets


Michael Whitby
michael.whitby at gmail.com

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Thu May 30 03:40:33 2019
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Wed, 29 May 2019 21:40:33 -0400
Subject: [R-sig-ME] GLMMTMB false convergence
In-Reply-To: <CAOgUSWGuLooBKO6tG_X_N-N9p-Cxj1_Q7FeNSS331v2zqN_9KA@mail.gmail.com>
References: <CAOgUSWGuLooBKO6tG_X_N-N9p-Cxj1_Q7FeNSS331v2zqN_9KA@mail.gmail.com>
Message-ID: <CABghstTdAQDfM1BR7Utx4TLNZtGs01mOzpFk_nvT-5APbB=X1g@mail.gmail.com>

   I don't know if I've included this in the troubleshooting vignette
yet, but: the "false convergence" message (ultimately from nlminb())
is pretty obscure.
https://stackoverflow.com/questions/40039114/r-nlminb-what-does-false-convergence-actually-mean

   I can think of the following strategies:

 * restart the fit from the optimized parameters (the false
convergence may not occur because nlminb can reset its iterative
procedure) and see if you get the same fit without the warning

* scale and center predictors (always worth a try)

* as of a *very* recent version of the glmmTMB master branch, you can
specify a different optimizer (see ?glmmTMBControl) and see if you get
the same answer.


On Wed, May 29, 2019 at 3:02 PM Michael Whitby <michael.whitby at gmail.com> wrote:
>
> Hello,
>
> I have built a zero-inflated GLMM (truncated_nbinom2 distribution) with an
> ar1 covariance structure using GLMMTMB (latest development version as of
> yesterday) and MRAN 3.5.1 on a server running windows server 2016.
>
> The model produces a warning about false convergence and points to the
> troubleshooting vignette.
> However, that page does not specifically mention false convergence. Is the
> advice for handling this warning the same as another section in the
> vignette?
>
> There are no NA's in the parameter estimate, the AIC values are reported,
> and sdr$pdhess is TRUE.
>
> Is this model useable? If not, any advice on determining where the problem
> exists? (I assume it is overparameterized despite a large dataset)
>
> I apologize for not including a reproducible example, I haven't been able
> to reproduce the false convergence warning with other datasets
>
>
> Michael Whitby
> michael.whitby at gmail.com
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From p@r|@m @end|ng |rom @t@n|ord@edu  Thu May 30 04:57:31 2019
From: p@r|@m @end|ng |rom @t@n|ord@edu (Pardis Miri)
Date: Thu, 30 May 2019 02:57:31 +0000
Subject: [R-sig-ME] Equivalent of covariance pattern model with a
 heterogeneous compound symmetric
Message-ID: <CA+WU=HBJNcWbyk6pDJuOqB0t0WjeUMQfK7VnFoTehEdfOh0jeA@mail.gmail.com>

Hi everyone,

I am trying to figure out how to replicate the results I've gotten from SPSS when using the Repeated Covariance Type : Compound Symmetry: Heterogeneous.  Can anyone help me figure this out?
So far I know the following does't produce the same results.

comsym <- gls(SC_slope~Bodysite+Pattern+Strength,data = df.na.removed.,
                   correlation=corCompSymm(form = ~ 1 |id), method="REML", na.action = na.omit)

summary(comsym)


	[[alternative HTML version deleted]]


From b@pe|zer @end|ng |rom m@w@ru@n|  Thu May 30 09:59:36 2019
From: b@pe|zer @end|ng |rom m@w@ru@n| (Ben Pelzer)
Date: Thu, 30 May 2019 09:59:36 +0200
Subject: [R-sig-ME] Equivalent of covariance pattern model with a
 heterogeneous compound symmetric
In-Reply-To: <CA+WU=HBJNcWbyk6pDJuOqB0t0WjeUMQfK7VnFoTehEdfOh0jeA@mail.gmail.com>
References: <CA+WU=HBJNcWbyk6pDJuOqB0t0WjeUMQfK7VnFoTehEdfOh0jeA@mail.gmail.com>
Message-ID: <d93b5fcf-0ea1-4289-55b5-357dd1f84cb9@maw.ru.nl>

Hi Pardis,

Four say 4 occasions you could use:

HCS.gls <- gls (read ~ 1+occ2+occ3+occ4, data=DA68, method="REML",

correlation = corCompSymm(form = ~ occasion|id ),

weights = varIdent (form = ~1 | occasion) )



Best regards, Ben.


On 30-5-2019 4:57, Pardis Miri wrote:
> Hi everyone,
>
> I am trying to figure out how to replicate the results I've gotten from SPSS when using the Repeated Covariance Type : Compound Symmetry: Heterogeneous.  Can anyone help me figure this out?
> So far I know the following does't produce the same results.
>
> comsym <- gls(SC_slope~Bodysite+Pattern+Strength,data = df.na.removed.,
>                     correlation=corCompSymm(form = ~ 1 |id), method="REML", na.action = na.omit)
>
> summary(comsym)
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


	[[alternative HTML version deleted]]


From p@r|@m @end|ng |rom @t@n|ord@edu  Thu May 30 11:25:13 2019
From: p@r|@m @end|ng |rom @t@n|ord@edu (Pardis Miri)
Date: Thu, 30 May 2019 09:25:13 +0000
Subject: [R-sig-ME] Equivalent of covariance pattern model with a
 heterogeneous compound symmetric
In-Reply-To: <d93b5fcf-0ea1-4289-55b5-357dd1f84cb9@maw.ru.nl>
References: <CA+WU=HBJNcWbyk6pDJuOqB0t0WjeUMQfK7VnFoTehEdfOh0jeA@mail.gmail.com>
 <d93b5fcf-0ea1-4289-55b5-357dd1f84cb9@maw.ru.nl>
Message-ID: <CA+WU=HDHUUhST46psGKv-SyhdftnP+h4hMCH8Zz1yESsyV9cvA@mail.gmail.com>

Hi Ben,

The example I am trying to construct is a 3 x 2 x 3 within-subject design.
I have the following column in my data set
 trial 1:18, Bodysite with 3 levels, Strength with 2 levels,  Pattern with 3 levels, and subject id.
I am interested in SC_slope as a DV.

I just contracted the following but I am not sure if I followed your example correctly. Is this correct?


comsym <- gls(SC_slope~Bodysite+Pattern+Strength,data = df.na.removed.,
                   correlation=corCompSymm(form = ~ trial |id), method="REML", na.action = na.omit,
              weights = varIdent (form = ~1 | trial))

summary(comsym)

Thank you again!
Paris


On Thu, May 30, 2019 at 12:59 AM Ben Pelzer <b.pelzer at maw.ru.nl<mailto:b.pelzer at maw.ru.nl>> wrote:
Hi Pardis,

Four say 4 occasions you could use:

HCS.gls <- gls (read ~ 1+occ2+occ3+occ4, data=DA68, method="REML",

correlation = corCompSymm(form = ~ occasion|id ),

weights = varIdent (form = ~1 | occasion) )



Best regards, Ben.


On 30-5-2019 4:57, Pardis Miri wrote:
> Hi everyone,
>
> I am trying to figure out how to replicate the results I've gotten from SPSS when using the Repeated Covariance Type : Compound Symmetry: Heterogeneous.  Can anyone help me figure this out?
> So far I know the following does't produce the same results.
>
> comsym <- gls(SC_slope~Bodysite+Pattern+Strength,data = df.na.removed.,
>                     correlation=corCompSymm(form = ~ 1 |id), method="REML", na.action = na.omit)
>
> summary(comsym)
>
>
>       [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From b@pe|zer @end|ng |rom m@w@ru@n|  Thu May 30 22:42:50 2019
From: b@pe|zer @end|ng |rom m@w@ru@n| (Ben Pelzer)
Date: Thu, 30 May 2019 22:42:50 +0200
Subject: [R-sig-ME] Equivalent of covariance pattern model with a
 heterogeneous compound symmetric
In-Reply-To: <CA+WU=HDHUUhST46psGKv-SyhdftnP+h4hMCH8Zz1yESsyV9cvA@mail.gmail.com>
References: <CA+WU=HBJNcWbyk6pDJuOqB0t0WjeUMQfK7VnFoTehEdfOh0jeA@mail.gmail.com>
 <d93b5fcf-0ea1-4289-55b5-357dd1f84cb9@maw.ru.nl>
 <CA+WU=HDHUUhST46psGKv-SyhdftnP+h4hMCH8Zz1yESsyV9cvA@mail.gmail.com>
Message-ID: <5CF0404A.4060805@maw.ru.nl>

Hi Pardis,

Seems ok to me. And if that is the model you wish, you could check if 
spss produces the same results. Best,

Ben.

On 30/05/2019 11:25, Pardis Miri wrote:
> Hi Ben,
>
> The example I am trying to construct is a 3 x 2 x 3 within-subject 
> design.
> I have the following column in my data set
>  trial 1:18, Bodysite with 3 levels, Strength with 2 levels,  Pattern 
> with 3 levels, and subject id.
> I am interested in SC_slope as a DV.
>
> I just contracted the following but I am not sure if I followed your 
> example correctly. Is this correct?
>
>
> comsym <- gls(SC_slope~Bodysite+Pattern+Strength,data = df.na.removed.,
>                    correlation=corCompSymm(form = ~ trial |id), 
> method="REML", na.action = na.omit,
>               weights = varIdent (form = ~1 | trial))
>
> summary(comsym)
>
> Thank you again!
> Paris
>
>
> On Thu, May 30, 2019 at 12:59 AM Ben Pelzer <b.pelzer at maw.ru.nl 
> <mailto:b.pelzer at maw.ru.nl>> wrote:
>
>     Hi Pardis,
>
>     Four say 4 occasions you could use:
>
>     HCS.gls <- gls (read ~ 1+occ2+occ3+occ4, data=DA68, method="REML",
>
>     correlation = corCompSymm(form = ~ occasion|id ),
>
>     weights = varIdent (form = ~1 | occasion) )
>
>
>
>     Best regards, Ben.
>
>
>     On 30-5-2019 4:57, Pardis Miri wrote:
>     > Hi everyone,
>     >
>     > I am trying to figure out how to replicate the results I've
>     gotten from SPSS when using the Repeated Covariance Type :
>     Compound Symmetry: Heterogeneous.  Can anyone help me figure this out?
>     > So far I know the following does't produce the same results.
>     >
>     > comsym <- gls(SC_slope~Bodysite+Pattern+Strength,data =
>     df.na.removed.,
>     >                     correlation=corCompSymm(form = ~ 1 |id),
>     method="REML", na.action = na.omit)
>     >
>     > summary(comsym)
>     >
>     >
>     >       [[alternative HTML version deleted]]
>     >
>     > _______________________________________________
>     > R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>     > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>
>
>             [[alternative HTML version deleted]]
>
>     _______________________________________________
>     R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


	[[alternative HTML version deleted]]


From p@rd|@@@t@n|ord @end|ng |rom gm@||@com  Thu May 30 01:55:57 2019
From: p@rd|@@@t@n|ord @end|ng |rom gm@||@com (Pardis Miri)
Date: Wed, 29 May 2019 16:55:57 -0700
Subject: [R-sig-ME] What is the equivalent of Compound Symmetry :
 Heterogeneous test in R?
Message-ID: <CA+WU=HBjjZhG7MXkeQ=Ob3SyozE+dpuczY74yRmnCM1d=G0Ysw@mail.gmail.com>

Hi everyone,

I am trying to figure out how to replicate the results I've gotten from
SPSS when using the Repeated Covariance Type : Compound Symmetry:
Heterogeneous.  Can anyone help me figure this out?
So far I know the following does't produce the same results.

comsym <- gls(SC_slope~Bodysite+Pattern+Strength,data = df.na.removed.,
                   correlation=corCompSymm(form = ~ 1 |id), method="REML",
na.action = na.omit)

summary(comsym)

	[[alternative HTML version deleted]]


From orch|dn @end|ng |rom ||ve@com  Mon Jun  3 01:50:05 2019
From: orch|dn @end|ng |rom ||ve@com (dani jones)
Date: Sun, 2 Jun 2019 23:50:05 +0000
Subject: [R-sig-ME] compare a neighbourhood value with the city mean - test
 of significance in presence of spatial autocorrelation
In-Reply-To: <BYAPR06MB38320311B0272A161B175372D61B0@BYAPR06MB3832.namprd06.prod.outlook.com>
References: <BYAPR06MB38320311B0272A161B175372D61B0@BYAPR06MB3832.namprd06.prod.outlook.com>
Message-ID: <BYAPR06MB3832B9139DE7D423FF0673F6D61B0@BYAPR06MB3832.namprd06.prod.outlook.com>

Hi everyone,


I have a dataset with all neighbourhoods in a city and a value for each neighbourhood (a rate). I would like to be able to create a vizualization that enables the user to select individual neighbourhoods and find out whether the value of that neighbourhood is significantly higher or lower than the city average across all neighbourhoods (I have a value that was calculated for the city). Given that the neighbourhoods are contiguous areas composing the city, there is spatial dependency, so I cannot use z scores or apply other classical statistics test since the observations are not independent and spatial autocorrelation might exist.

I am not sure what test to apply to achieve this. Any help and links to potential readings would be very much appreciated.

Thank you very much!

Dani

<http://aka.ms/weboutlook>

	[[alternative HTML version deleted]]


From th|erry@onke||nx @end|ng |rom |nbo@be  Mon Jun  3 09:23:31 2019
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Mon, 3 Jun 2019 09:23:31 +0200
Subject: [R-sig-ME] 
 compare a neighbourhood value with the city mean - test
 of significance in presence of spatial autocorrelation
In-Reply-To: <BYAPR06MB3832B9139DE7D423FF0673F6D61B0@BYAPR06MB3832.namprd06.prod.outlook.com>
References: <BYAPR06MB38320311B0272A161B175372D61B0@BYAPR06MB3832.namprd06.prod.outlook.com>
 <BYAPR06MB3832B9139DE7D423FF0673F6D61B0@BYAPR06MB3832.namprd06.prod.outlook.com>
Message-ID: <CAJuCY5zNMgTgwOSydYkBaHkHYr5rNPmyBLxMELRPb2zCYSvzsw@mail.gmail.com>

Dear Dani,

What I would do is create a graph indicating which neighbourhoods are
directly connected to each other (share a border). And use this information
to fit a Besag-York-Mollier model which takes care of the auto-correlation
among the neighbourhoods. For an example see
library(INLA)
demo("Bym")

You can find the INLA package at http://www.r-inla.org


Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////


<https://www.inbo.be>


Op ma 3 jun. 2019 om 01:50 schreef dani jones <orchidn at live.com>:

> Hi everyone,
>
>
> I have a dataset with all neighbourhoods in a city and a value for each
> neighbourhood (a rate). I would like to be able to create a vizualization
> that enables the user to select individual neighbourhoods and find out
> whether the value of that neighbourhood is significantly higher or lower
> than the city average across all neighbourhoods (I have a value that was
> calculated for the city). Given that the neighbourhoods are contiguous
> areas composing the city, there is spatial dependency, so I cannot use z
> scores or apply other classical statistics test since the observations are
> not independent and spatial autocorrelation might exist.
>
> I am not sure what test to apply to achieve this. Any help and links to
> potential readings would be very much appreciated.
>
> Thank you very much!
>
> Dani
>
> <http://aka.ms/weboutlook>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From h|gh@t@t @end|ng |rom h|gh@t@t@com  Mon Jun  3 10:35:25 2019
From: h|gh@t@t @end|ng |rom h|gh@t@t@com (Highland Statistics Ltd)
Date: Mon, 3 Jun 2019 09:35:25 +0100
Subject: [R-sig-ME] Stats course: Mixed effects modelling
Message-ID: <1632f85d-baf6-0913-d2b0-c9256e0542fe@highstat.com>

We would like to announce the following 3 statistics courses.

Course: Linear Mixed Effects Models and GLMM with R-INLA.
Where and when:

  * Northwest Atlantic Fisheries Centre, St John?s, Canada. 12-16 August
    2019
  * University of C?diz, C?diz, Spain. 2-6 September 2019
  * University of Ghent, Ghent, Belgium. 2-6 December 2019

Course website: http://highstat.com/index.php/courses-upcoming


Kind regards,


Alain Zuur


Other upcoming courses:

Introduction to regression models with spatial and temporal correlation 
using R-INLA
NIOZ, Texel, The Netherlands. 23-27 September 2019

Introduction to regression models with spatial and spatial-temporal 
correlation using R-INLA
Burlington (close to Toronto), ON, Canada. 28 October - 1 November 2019

Data exploration, regression, GLM & GAM with introduction to R
Lisbon, Portugal. 3 - 7 February 2020

Introduction to regression models with spatial correlation using R-INLA
IEO, Vigo, Spain. 10 - 13 February 2020




-- 

Dr. Alain F. Zuur
Highland Statistics Ltd.
9 St Clair Wynd
AB41 6DZ Newburgh, UK
Email: highstat at highstat.com
URL:   www.highstat.com

And:
NIOZ Royal Netherlands Institute for Sea Research,
Department of Coastal Systems, and Utrecht University,
P.O. Box 59, 1790 AB Den Burg,
Texel, The Netherlands



Author of:
1. Beginner's Guide to Spatial, Temporal and Spatial-Temporal Ecological Data Analysis with R-INLA. (2017).
2. Beginner's Guide to Zero-Inflated Models with R (2016).
3. Beginner's Guide to Data Exploration and Visualisation with R (2015).
4. Beginner's Guide to GAMM with R (2014).
5. Beginner's Guide to GLM and GLMM with R (2013).
6. Beginner's Guide to GAM with R (2012).
7. Zero Inflated Models and GLMM with R (2012).
8. A Beginner's Guide to R (2009).
9. Mixed effects models and extensions in ecology with R (2009).
10. Analysing Ecological Data (2007).


	[[alternative HTML version deleted]]


From becky@nneg||bert @end|ng |rom gm@||@com  Mon Jun  3 15:14:10 2019
From: becky@nneg||bert @end|ng |rom gm@||@com (Becky Gilbert)
Date: Mon, 3 Jun 2019 14:14:10 +0100
Subject: [R-sig-ME] chisq = 0 and p = 1 in glmer model comparison result
Message-ID: <CALWifgAOZH9D7mMfeBDkm_OaLj_2Td=CD-E4piCLpLv0LmLAWw@mail.gmail.com>

Dear list

I have two glmer models, one with a fixed factor (targetWordFactor) and one
without, and I am comparing them using the anova function to get the LRT
results for the fixed effect of targetWordFactor. The anova results are
showing a chi-square value of 0 and p value of 1. Is this result possible,
or is it perhaps a sign that I've done something wrong?

Here are the anova results:

anova(accModelNullWord,accModelWord)
#                                  Df    AIC    BIC logLik deviance Chisq
Chi Df Pr(>Chisq)
# accModelNullWord 13 977.59 1067.0 -475.8   951.59
# accModelWord       15 990.61 1093.8 -480.3   960.61     0      2
 1

The targetWordFactor fixed factor has 3 levels (2 contrasts), so the
degrees of freedom in the anova result look correct to me. Here are the
model specifications:

contrasts(pauseDetValidNoFillersExcluded$targetWordFactor)
#        WW NW
# W       0  0
# WW   1  0
# NW    0  1

accModelNullWord <- glmer(correct ~ 1 +
                            (1 + targetWordFactor|subject) +
                            (1 + targetWordFactor|item),
                            data = pauseDetValidNoFillersExcluded,
                            family = binomial(link = "logit"),
                            control = glmerControl(optimizer="bobyqa",
                                                 optCtrl =
list(maxfun=2e5)))

accModelWord <- glmer(correct ~ 1 + targetWordFactor +
                        (1 + targetWordFactor|subject) +
                        (1 + targetWordFactor|item),
                        data = pauseDetValidNoFillersExcluded,
                        family = binomial(link = "logit"),
                        control = glmerControl(optimizer="bobyqa",
                                             optCtrl = list(maxfun=2e5)))

Apologies if this question has been asked before - I did search the list
but couldn't find anything.

Many thanks,
Becky

	[[alternative HTML version deleted]]


From gu|||@ume@|mon@@2 @end|ng |rom gm@||@com  Mon Jun  3 15:25:04 2019
From: gu|||@ume@|mon@@2 @end|ng |rom gm@||@com (Guillaume Adeux)
Date: Mon, 3 Jun 2019 15:25:04 +0200
Subject: [R-sig-ME] chisq = 0 and p = 1 in glmer model comparison result
In-Reply-To: <CALWifgAOZH9D7mMfeBDkm_OaLj_2Td=CD-E4piCLpLv0LmLAWw@mail.gmail.com>
References: <CALWifgAOZH9D7mMfeBDkm_OaLj_2Td=CD-E4piCLpLv0LmLAWw@mail.gmail.com>
Message-ID: <CAENiVe88DCE2381_P5By+ZbvW8+n=AG6HcajoLSqcsqiP5yfGA@mail.gmail.com>

Hello Becky,

Even though I cannot directly answer your question... a Chisq of 0 with
such a difference in AIC seems indeed suspicious.

To test the effect of your predictor in a GLMM context through LRT tests,
you could (should?) consider using the test_terms function from the {monet}
package or its little brother function mixed() from the {afex} package.
These packages are specifically designed for such tests.

I hope this helps.

Sincerely,

Guillaume ADEUX



Le lun. 3 juin 2019 ? 15:14, Becky Gilbert <beckyannegilbert at gmail.com> a
?crit :

> Dear list
>
> I have two glmer models, one with a fixed factor (targetWordFactor) and one
> without, and I am comparing them using the anova function to get the LRT
> results for the fixed effect of targetWordFactor. The anova results are
> showing a chi-square value of 0 and p value of 1. Is this result possible,
> or is it perhaps a sign that I've done something wrong?
>
> Here are the anova results:
>
> anova(accModelNullWord,accModelWord)
> #                                  Df    AIC    BIC logLik deviance Chisq
> Chi Df Pr(>Chisq)
> # accModelNullWord 13 977.59 1067.0 -475.8   951.59
> # accModelWord       15 990.61 1093.8 -480.3   960.61     0      2
>  1
>
> The targetWordFactor fixed factor has 3 levels (2 contrasts), so the
> degrees of freedom in the anova result look correct to me. Here are the
> model specifications:
>
> contrasts(pauseDetValidNoFillersExcluded$targetWordFactor)
> #        WW NW
> # W       0  0
> # WW   1  0
> # NW    0  1
>
> accModelNullWord <- glmer(correct ~ 1 +
>                             (1 + targetWordFactor|subject) +
>                             (1 + targetWordFactor|item),
>                             data = pauseDetValidNoFillersExcluded,
>                             family = binomial(link = "logit"),
>                             control = glmerControl(optimizer="bobyqa",
>                                                  optCtrl =
> list(maxfun=2e5)))
>
> accModelWord <- glmer(correct ~ 1 + targetWordFactor +
>                         (1 + targetWordFactor|subject) +
>                         (1 + targetWordFactor|item),
>                         data = pauseDetValidNoFillersExcluded,
>                         family = binomial(link = "logit"),
>                         control = glmerControl(optimizer="bobyqa",
>                                              optCtrl = list(maxfun=2e5)))
>
> Apologies if this question has been asked before - I did search the list
> but couldn't find anything.
>
> Many thanks,
> Becky
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From o||verhooker @end|ng |rom pr@t@t|@t|c@@com  Mon Jun  3 19:32:17 2019
From: o||verhooker @end|ng |rom pr@t@t|@t|c@@com (Oliver Hooker)
Date: Mon, 3 Jun 2019 18:32:17 +0100
Subject: [R-sig-ME] Generalised Linear (MIXED) (GLMM),
 Nonlinear (NLGLM) And General Additive Models (MIXED)
 (GAMM) (GNAM01)
Message-ID: <CAEsSYzwKiVsmHchRD+7aXxx7HPbTD5AxqrV7akdkj0kibodGRA@mail.gmail.com>

Generalised Linear (MIXED) (GLMM), Nonlinear (NLGLM) And General Additive
Models (MIXED) (GAMM) (GNAM01)

https://www.psstatistics.com/course/generalised-linear-glm-nonlinear-nlglm-and-general-additive-models-gam-gnam01/

This course will be delivered by Dr. Mark Andrews from the 9th - 13th
September 2019 in Glasgow City Centre

Course Overview:
This course provides a general introduction to nonlinear regression
analysis, covering major topics including, but not limited to, general and
generalized linear models, generalized additive models, spline and radial
basis function regression, and Gaussian process regression. We approach the
general topic of nonlinear regression by showing how the powerful and
flexible statistical modelling framework of general and generalized linear
models, and their multilevel counterparts, can be extended to handle
nonlinear relationships between predictor and outcome variables. We begin
by providing a comprehensive practical and theoretical overview of
regression, including multilevel regression, using general and generalized
linear models. Here, we pay particular attention to the many variants of
general and generalized linear models, and how these provide a very widely
applicable set of tools for statistical modeling. After this introduction,
we then proceed to cover practically and conceptually simple extensions to
the general and generalized linear models framework using parametric
nonlinear models and polynomial regression. We will then cover more
powerful and flexible extensions of this modeling. framework by way of the
general concept of basis functions. We?ll begin our coverage of basis
function regression with the major topic of spline regression, and then
proceed to cover radial basis functions and the multilayer perceptron, both
of which are types of artificial neural networks. We then move on to the
major topic of generalized additive models (GAMs) and generalized additive
mixed models (GAMMs), which can be viewed as the generalization of all the
basis function regression topics, but cover a wider range of topic
including nonlinear spatial and temporal models and interaction models.
Finally, we will cover the powerful Bayesian nonlinear regression method of
Gaussian process regression.

Monday 9th ? Classes from 09:30 to 17:30

Module 1: General and generalized linear models, including multilevel
models. In order to provide a solid foundation for the remainder of the
course, we begin by providing a comprehensive practical and theoretical
overview of the principles of general and generalized linear models, also
covering their multilevel (or hierarchical) counterparts. General and
generalized linear models provide a powerful set of tools for statistical
modeling., which are extremely widely used and widely applicable. Their
underlying theoretical principles are quite simple and elegant, and once
understood, it becomes clear how these models can be extended in many
different ways to handle different statistical modeling. situations.

For this module, we will use the very commonly used R tools such as lm,
glm, lme4::lmer, lme4::glmer. In addition, we will also use the R based
brms package, which uses the Stan probabilistic programming language. This
package allows us to perform all the same analyses that are provided by lm,
glm, lmer, glmer, etc., using an almost identical syntax, but also us to
perform a much wider range of general and generalized linear model analyses.

Tuesday 10th ? Classes from 09:30 to 17:30

Having established a solid regression modeling. foundation, on the second
day we may cover a range of nonlinear modeling. extensions to the general
and generalized linear modeling. framework.

Module 2: Polynomial regression. Polynomial regression is both a
conceptually and practically simple extension of linear modeling. It be
easily accomplished using the poly function along with tools like lm,
glmer, lme4::lmer, lme4::glmer. Here, we will use cover piecewise linear
and polynomial regression, using R packages such as segmented.
?
Module 3: Parametric nonlinear regression. In some cases of nonlinear
regression, a bespoke parametric function for the relationship between the
predictors and outcome variable is used. These are often obtained from
scientific knowledge of the problem at hand. In R, we can use the package
nls to perform parametric nonlinear regression.
?
Module 4: Spline regression: Nonlinear regression using splines is a
powerful and flexible non-parametric or semi-parametric nonlinear
regression method. It is also an example of a basis function regression
method. Here, we will cover spline regression using the splines::bs and
splines::ns functions that can be used with lm, glm, lme4::lmer,
lme4::glmer, brms, etc.
?
Module 5: Radial basis functions. Regression using radial basis functions
is a set of methods that are closely related to spline regression. They
have a long history of usage in machine learning and can also be viewed as
a type of artificial neural network model. Here, we will explore radial
basis function models using the Stan programming language, which will allow
us to build powerful and flexible versions of the radial basis functions.
?
Module 6: Multilayer perceptron. Closely related to radial basis functions
are multilayer perceptrons. These and their variants and extensions are
major building block of deep learning (machine learning) methods. We will
explore multilayer perceptron in Stan, but we will also use the powerful
Keras library.

Wednesday 11th ? Classes from 09:30 to 17:30

Module 7: Generalized additive models. We now turn to the major module of
generalized additive models (GAMs). GAMs generalize many of concepts and
module covered so far and represent a powerful and flexible framework for
nonlinear modeling. In R, the mgcv package provides a extensive set of
tools for working with GAMs. Here, we will provide an in-depth coverage of
mgcv including choosing smooth terms, controlling overfitting and
complexity,
prediction, model evaluation, and so on.
?
Module 9: Generalized additive mixed models. GAMs can also be used in
linear mixed effects models where they are known as generalized additive
mixed mmodels (GAMMs). GAMMs can also be used with the mgcv package.

Thursday 12th ? Classes from 09:30 to 17:30

Module 10: Interaction nonlinear regression: A powerful feature of GAMs and
GAMMs is the ability to model nonlinear interactions, whether between two
continuous variables, or between one continuous and one categorical
variable. Amongst other things, interactions between continuous variables
allow us to do spatial and spatio-temporal modeling. Interactions between
categorical and continuous variables allow us to model how nonlinear
relationships between a predictor and outcome change as a function of the
value of different categorical variables.

Module 11: Nonlinear regression for time-series and forecasting. One major
application of nonlinear regression is for modeling. time-series and
forecasting. Here, we will explore the prophet library for time-series
forecasting. This library, available for both Python and R, gives us a
GAM-like framework for modeling. time-series and making forecasts.

Friday 13th ? Classes from 09:30 to 16:00

Module 12: Gaussian process regression. Our final module deals with a type
of Bayesian nonlinear regression known as Gaussian process regression.
Gaussian process regression can be viewed as a kind of basis function
regression, but with an infinite number of basis functions. In that sense,
it generalizes spline, radial basis functions, multilayer perceptron,
generalized additive models, and provides means to overcome some
practically challenging problems in nonlinear regression such as selecting
the number and type of smooth functions. Here, we will explore Gaussian
process regression using Stan.

Email oliverhookerpsstatistics.com

Check out our sister sites,
www.PRstatistics.com (Ecology and Life Sciences)
www.PRstatistics.com/consultancy (Statistical and bioinformatics
consultancy in all fields)
www.PRinformatics.com (Bioinformatics and data science)
www.PSstatistics.com (Behaviour and cognition)




1. June 10th ? 14th 2019
STABLE ISOTOPE MIXING MODELS USING SIAR, SIBER AND MIXSIAR (SIMM04)
Glasgow, Scotland, Dr. Andrew Parnell, Dr. Andrew Jackson
www.prstatistics.com/course/stable-isotope-mixing-models-using-r-simm04/

2. June 10th ? 14th 2019
INTRODUCTION TO PYTHON FOR BIOLOGISTS (IPYB06)
Glasgow, Scotland, Dr. Martin Jones
http://www.prinformatics.com/course/introduction-to-python-for-biologists-ipyb06/

3. June 17th ? 21st 2019
ADVANCED PYTHON FOR BIOLOGISTS (APYB03)
Glasgow, Scotland, Dr. Martin Jones
www.prinformatics.com/course/advanced-python-biologists-apyb03/

4. June 24th ? 28th 2019
MICROBIOME DATA ANALYSIS USING QIIME2 (MBQM01)
Glasgow, Scotland, Dr. Yoshiki Vazquez Baeza, Dr. Antonio Gonzalez Pena
https://www.prinformatics.com/course/microbiome-data-analysis-using-qiime2-mbqm01/

5. July 1st ? 5th 2019
BIOACOUSTICS FOR ECOLOGISTS: HARDWARE, SURVEY DESIGN AND DATA ANALYSIS
(BIAC01)
Glasgow, Scotland, Dr. Paul Howden-Leach
https://www.prstatistics.com/course/bioacoustics-for-ecologists-hardware-survey-design-and-data-analysis-biac01/

6. July 8th ? 12th 2019
INTRODUCTION TO BAYESIAN HIERARCHICAL MODELLING USING R (IBHM03)
Glasgow, Scotland, Dr. Andrew Parnell
https://www.psstatistics.com/course/introduction-to-bayesian-hierarchical-modelling-using-r-ibhm03/

7. July 15th ? 19th 2019
ANALYSING ENVIRONMENTAL ADAPTATION USING LANDSCAPE GENETICS (EDAP01)
Glasgow, Dr. Matt Fitzpatrick
https://www.prstatistics.com/course/analysing-environmental-adaptation-using-landscape-genetics-edap01

8. July 29th ? August 2nd 2019
INTRODUCTION TO SPATIAL ANALYSIS OF ECOLOGICAL DATA USING R (ISPE01)
Glasgow, Scotland, Dr. Jakub Nowosad
https://www.prstatistics.com/course/introduction-to-spatial-analysis-of-ecological-data-using-r-ispe01/

9. September 2nd ? 6th 2019
APPLIED METHODS FOR ANALYSING CAPTURE-RECAPTURE (MARK-RECAPTURE) DATA USING
SPATIALLY EXPLICIT AND NON-SPATIAL TECHNIQUES (MARK01)
Glasgow, Scotland, Dr. Joanne Potts, Dr. David Borchers
https://www.prstatistics.com/course/applied-methods-for-analysing-capture-recapture-mark-recapture-data-using-spatially-explicit-and-non-spatial-techniques-mark01/

10. September 9th ? 13th 2019
GENERALISED LINEAR (MIXED) (GLMM), NONLINEAR (NLGLM) AND GENERAL ADDITIVE
MODELS (MIXED) (GAMM) (GNAM01)
Glasgow, Scotland, Dr. Mark Andrews
https://www.psstatistics.com/course/generalised-linear-glm-nonlinear-nlglm-and-general-additive-models-gam-gnam01/

11. September 16th ? 20th 2019
R PACKAGE DESIGN AND DEVELOPMENT AND REPRODUCIBLE DATA SCIENCE FOR
BIOLOGISTS (RPKG01)
Glasgow, Scotland, Dr. Cory Merow, Dr. Andy Rominger
https://www.prstatistics.com/course/r-package-design-and-development-and-reproducible-data-science-for-biologists-rpkg01/

12. September 16th ? 20th 2019
STRUCTURAL EQUATION MODELLING AND PATH ANALYSIS (SMPA01)
Glasgow, Scotland, Dr. Mark Andrews
https://www.psstatistics.com/course/structural-equation-modelling-and-path-analysis-smpa01/

13. September 23rd ? 27th 2019
DATA SCIENCE/ANALYTICS USING PYTHON (DSAP01)
Glasgow, Scotland, Dr. Mark Andrews
https://www.psstatistics.com/course/data-science-analytics-using-python-dsap01/


14. September 30th ? October 4th 2019
GEOMETRIC MORPHOMETRICS USING R (GMMR02)
Glasgow, Scotland, Prof. Dean Adams, Prof. Michael Collyer, Dr. Antigoni
Kaliontzopoulou
http://www.prstatistics.com/course/geometric-morphometrics-using-r-gmmr02/

15. October 7th ? 11th 2019
CONSERVATION PLANNING USING PRIORITIZR : FROM THEORY TO PRACTICE (PRTZ01)
Athens, GREECE, Dr Richard Schuster and Nina Morell
https://www.prstatistics.com/course/conservation-planning-using-prioritizr-from-theory-to-practice-prtz01/

16. October 14th ? 18th 2019
INTRODUCTION TO BEHAVIOURAL DATA ANALYSIS USINR R (IBDA01)
Glasgow, Scotland, Dr Will Hoppitt
https://www.psstatistics.com/course/introduction-to-behavioural-data-analysis-using-r-ibda01/

17. October 21st ? 25th 2019
MULTIVARIATE ANALYSIS OF ECOLOGICAL COMMUNITIES USING THE VEGAN PACKAGE
(VGNR01)
Glasgow, Scotland, Dr. Guillaume Blanchet
www.prstatistics.com/course/multivariate-analysis-of-ecological-communities-in-r-with-the-vegan-package-vgnr01/

18. November 4th ? 8th 2019
Glasgow, Scotland, Dr. Mark Andrews
INTRODUCTION TO BAYESIAN DATA ANALYSIS FOR SOCIAL AND BEHAVIOURAL SCIENCES
USING R AND STAN (BDRS02)
https://www.psstatistics.com/course/introduction-to-bayesian-data-analysis-for-social-and-behavioural-sciences-using-r-and-stan-bdrs02/

19. November 4th ? 8th 2019
BEHAVIOURAL DATA ANALYSIS USING MAXIMUM LIKELIHOOD (BDML02)
Glasgow, Scotland, Dr Will Hoppitt
https://www.psstatistics.com/course/behavioural-data-analysis-using-maximum-likelihood-bdml02/

20. November 11th ? 15th 2019
APPLIED BAYESIAN MODELLING FOR ECOLOGISTS AND EPIDEMIOLOGISTS (ABME05)
Glasgow, Scotland, Dr Matt Denwood, Emma Howard
https://www.prstatistics.com/course/applied-bayesian-modelling-for-ecologists-and-epidemiologists-abme05/

21. November 18th ? 22nd 2019
INTRODUCTION TO STRUCTURED POPULATION MODELS AND DEMOGRAPHIC DISTRIBUTION
MODELS (IIPM01)
Athens, GREECE, Dr Cory Merow
https://www.prstatistics.com/course/introduction-to-structured-population-models-and-demographic-distribution-models-iipm01/

22. November 25th ? 29th 2019
ADVANCED RANGE, NICHE, AND DISTRIBUTION MODELING (ASDM01)
Athens, GREECE, Dr Cory Merow
https://www.prstatistics.com/course/advanced-range-niche-and-distribution-modeling-asdm01/

23. May 11th ? 15th 2020
FORMALIZING UNCERTAINTY: FUZZY LOGIC IN SPECIES DISTRIBUTION AND DIVERSITY
PATTERNS (FLDM01)
Glasgow, Scotland, Dr. Marcia Barbosa
https://www.prstatistics.com/course/formalizing-uncertainty-fuzzy-logic-in-species-distribution-and-diversity-patterns-fldm01/

24. May 18th ? 22nd 2020
STRUCTUAL EQUATION MODELLING FOR ECOLOGISTS AND EVOLUTIONARY BIOLOGISTS
(SEMR02)
Glasgow, Scotland, Dr. Jonathan Lefcheck, Dr. Jim (james) Grace
https://www.prstatistics.com/course/structural-equation-modelling-for-ecologists-and-evolutionary-biologists-semr02/

25. October 5th ? 9th 2020
ECOLOGICAL NICHE MODELLING USING R (ENMR04)
Glasgow, Scotland, Dr. Neftali Sillero
http://www.prstatistics.com/course/ecological-niche-modelling-using-r-enmr04/

26. October 11th ? 16th 2020
ADVANCED ECOLOGICAL NICHE MODELLING USING R (ABNMR01)
Glasgow, Scotland, Dr. Neftali Sillero
http://www.prstatistics.com/course/advanced-ecological-niche-modelling-using-r-anmr01/

-- 
Oliver Hooker PhD.
PR statistics

2019 publications;

A way forward with eco evo devo: an extended theory of resource
polymorphism with postglacial fishes as model systems. Biological Reviews
(2019).

prstatistics.com
facebook.com/prstatistics/
twitter.com/PRstatistics
groups.google.com/d/forum/pr-statistics-post-course-forum
prstatistics.com/organiser/oliver-hooker/

6 Hope Park Crescent
Edinburgh
EH8 9NA
+44 (0) 7966500340

	[[alternative HTML version deleted]]


From t|mothy@grego|re @end|ng |rom y@|e@edu  Mon Jun  3 20:10:06 2019
From: t|mothy@grego|re @end|ng |rom y@|e@edu (Gregoire, Timothy)
Date: Mon, 3 Jun 2019 18:10:06 +0000
Subject: [R-sig-ME] R-sig-mixed-models Digest, Vol 150, Issue 1
In-Reply-To: <mailman.17586.7.1559383202.37894.r-sig-mixed-models@r-project.org>
References: <mailman.17586.7.1559383202.37894.r-sig-mixed-models@r-project.org>
Message-ID: <BN7PR08MB4082E5213AC7493066264BF6E3140@BN7PR08MB4082.namprd08.prod.outlook.com>

Does SPSS also default to REML, as does gls?

Timothy G. Gregoire
J. P. Weyerhaeuser Professor of Forest Management
School of Forestry & Environmental Studies
Yale University
360 Prospect St, New Haven, CT, U.S.A. 06511
Ph: 1.203.432.9398 mob: 1.203.508.4014? fax:1.203.432.3809

-----Original Message-----
From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] On Behalf Of r-sig-mixed-models-request at r-project.org
Sent: Saturday, June 01, 2019 6:00 AM
To: r-sig-mixed-models at r-project.org
Subject: R-sig-mixed-models Digest, Vol 150, Issue 1

Send R-sig-mixed-models mailing list submissions to
	r-sig-mixed-models at r-project.org

To subscribe or unsubscribe via the World Wide Web, visit
	https://nam05.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=02%7C01%7Ctimothy.gregoire%40yale.edu%7Ce8152d45149f43f2c8a008d6e678322b%7Cdd8cbebb21394df8b4114e3e87abeb5c%7C0%7C0%7C636949801261386657&amp;sdata=bsXetmkjZuulyuz0E9GMmxX2lYzjZ0Asw5v3tJvJReA%3D&amp;reserved=0
or, via email, send a message with subject or body 'help' to
	r-sig-mixed-models-request at r-project.org

You can reach the person managing the list at
	r-sig-mixed-models-owner at r-project.org

When replying, please edit your Subject line so it is more specific than "Re: Contents of R-sig-mixed-models digest..."


Today's Topics:

   1. What is the equivalent of Compound Symmetry : Heterogeneous
      test in R? (Pardis Miri)

----------------------------------------------------------------------

Message: 1
Date: Wed, 29 May 2019 16:55:57 -0700
From: Pardis Miri <pardis.stanford at gmail.com>
To: "r-sig-mixed-models at r-project.org"
	<r-sig-mixed-models at r-project.org>
Subject: [R-sig-ME] What is the equivalent of Compound Symmetry :
	Heterogeneous test in R?
Message-ID:
	<CA+WU=HBjjZhG7MXkeQ=Ob3SyozE+dpuczY74yRmnCM1d=G0Ysw at mail.gmail.com>
Content-Type: text/plain; charset="utf-8"

Hi everyone,

I am trying to figure out how to replicate the results I've gotten from SPSS when using the Repeated Covariance Type : Compound Symmetry:
Heterogeneous.  Can anyone help me figure this out?
So far I know the following does't produce the same results.

comsym <- gls(SC_slope~Bodysite+Pattern+Strength,data = df.na.removed.,
                   correlation=corCompSymm(form = ~ 1 |id), method="REML", na.action = na.omit)

summary(comsym)

	[[alternative HTML version deleted]]




------------------------------

Subject: Digest Footer

_______________________________________________
R-sig-mixed-models mailing list
R-sig-mixed-models at r-project.org
https://nam05.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=02%7C01%7Ctimothy.gregoire%40yale.edu%7Ce8152d45149f43f2c8a008d6e678322b%7Cdd8cbebb21394df8b4114e3e87abeb5c%7C0%7C0%7C636949801261386657&amp;sdata=bsXetmkjZuulyuz0E9GMmxX2lYzjZ0Asw5v3tJvJReA%3D&amp;reserved=0


------------------------------

End of R-sig-mixed-models Digest, Vol 150, Issue 1


From p@u|@john@on @end|ng |rom g|@@gow@@c@uk  Tue Jun  4 00:46:35 2019
From: p@u|@john@on @end|ng |rom g|@@gow@@c@uk (Paul Johnson)
Date: Mon, 3 Jun 2019 22:46:35 +0000
Subject: [R-sig-ME] chisq = 0 and p = 1 in glmer model comparison result
In-Reply-To: <CAENiVe88DCE2381_P5By+ZbvW8+n=AG6HcajoLSqcsqiP5yfGA@mail.gmail.com>
References: <CALWifgAOZH9D7mMfeBDkm_OaLj_2Td=CD-E4piCLpLv0LmLAWw@mail.gmail.com>
 <CAENiVe88DCE2381_P5By+ZbvW8+n=AG6HcajoLSqcsqiP5yfGA@mail.gmail.com>
Message-ID: <C96CA5B9-7D2B-4241-BB65-E79F260AB4D2@glasgow.ac.uk>

Hi Becky,

The model with the two additional parameters has a lower log likelihood (-480.3, df=15) than the smaller model (-475.8, df=13). This shouldn?t be possible, because adding an unconstrained parameter makes the model more flexible, allowing a closer fit to the data. This anomalous difference in likelihoods has caused the chi-squared statistic in the LRT to be negative, giving a p-value of 1, because all of the chi-squared distribution is positive, i.e. P(chi-squared > test statistic) = 1 when the test statistic is <= 0. Either one or both of the models haven?t converged, or (less likely) there is missing data in the added variable so that the data differs between the two models.

In addition, it?s very unusual to fit random slopes without also including a fixed effect, as you?ve done for targetWordFactor. The null model allows the WW-W and NW-W differences in the log odds of being correct to differ randomly between subjects and between items, but forces the mean differences (across subjects and items) to be zero. You?d need a good reason to fit such a model.

Best wishes,
Paul


> On 3 Jun 2019, at 14:25, Guillaume Adeux <guillaumesimon.a2 at gmail.com> wrote:
> 
> Hello Becky,
> 
> Even though I cannot directly answer your question... a Chisq of 0 with
> such a difference in AIC seems indeed suspicious.
> 
> To test the effect of your predictor in a GLMM context through LRT tests,
> you could (should?) consider using the test_terms function from the {monet}
> package or its little brother function mixed() from the {afex} package.
> These packages are specifically designed for such tests.
> 
> I hope this helps.
> 
> Sincerely,
> 
> Guillaume ADEUX
> 
> 
> 
> Le lun. 3 juin 2019 ? 15:14, Becky Gilbert <beckyannegilbert at gmail.com> a
> ?crit :
> 
>> Dear list
>> 
>> I have two glmer models, one with a fixed factor (targetWordFactor) and one
>> without, and I am comparing them using the anova function to get the LRT
>> results for the fixed effect of targetWordFactor. The anova results are
>> showing a chi-square value of 0 and p value of 1. Is this result possible,
>> or is it perhaps a sign that I've done something wrong?
>> 
>> Here are the anova results:
>> 
>> anova(accModelNullWord,accModelWord)
>> #                                  Df    AIC    BIC logLik deviance Chisq
>> Chi Df Pr(>Chisq)
>> # accModelNullWord 13 977.59 1067.0 -475.8   951.59
>> # accModelWord       15 990.61 1093.8 -480.3   960.61     0      2
>> 1
>> 
>> The targetWordFactor fixed factor has 3 levels (2 contrasts), so the
>> degrees of freedom in the anova result look correct to me. Here are the
>> model specifications:
>> 
>> contrasts(pauseDetValidNoFillersExcluded$targetWordFactor)
>> #        WW NW
>> # W       0  0
>> # WW   1  0
>> # NW    0  1
>> 
>> accModelNullWord <- glmer(correct ~ 1 +
>>                            (1 + targetWordFactor|subject) +
>>                            (1 + targetWordFactor|item),
>>                            data = pauseDetValidNoFillersExcluded,
>>                            family = binomial(link = "logit"),
>>                            control = glmerControl(optimizer="bobyqa",
>>                                                 optCtrl =
>> list(maxfun=2e5)))
>> 
>> accModelWord <- glmer(correct ~ 1 + targetWordFactor +
>>                        (1 + targetWordFactor|subject) +
>>                        (1 + targetWordFactor|item),
>>                        data = pauseDetValidNoFillersExcluded,
>>                        family = binomial(link = "logit"),
>>                        control = glmerControl(optimizer="bobyqa",
>>                                             optCtrl = list(maxfun=2e5)))
>> 
>> Apologies if this question has been asked before - I did search the list
>> but couldn't find anything.
>> 
>> Many thanks,
>> Becky
>> 
>>        [[alternative HTML version deleted]]
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbo|ker @end|ng |rom gm@||@com  Tue Jun  4 01:32:54 2019
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Tue, 4 Jun 2019 09:32:54 +1000
Subject: [R-sig-ME] chisq = 0 and p = 1 in glmer model comparison result
In-Reply-To: <C96CA5B9-7D2B-4241-BB65-E79F260AB4D2@glasgow.ac.uk>
References: <CALWifgAOZH9D7mMfeBDkm_OaLj_2Td=CD-E4piCLpLv0LmLAWw@mail.gmail.com>
 <CAENiVe88DCE2381_P5By+ZbvW8+n=AG6HcajoLSqcsqiP5yfGA@mail.gmail.com>
 <C96CA5B9-7D2B-4241-BB65-E79F260AB4D2@glasgow.ac.uk>
Message-ID: <CABghstRyyQPU3oQi2DnmSWEq41QSy5Y_ZL-JHVtXJm9JS8jOcA@mail.gmail.com>

The reason might exactly be to test a NH of zero effect at the population
level. I agree about the rest though. If you provide data/reproducible
example, someone might take a look ...

On Tue, Jun 4, 2019, 8:46 AM Paul Johnson <paul.johnson at glasgow.ac.uk>
wrote:

> Hi Becky,
>
> The model with the two additional parameters has a lower log likelihood
> (-480.3, df=15) than the smaller model (-475.8, df=13). This shouldn?t be
> possible, because adding an unconstrained parameter makes the model more
> flexible, allowing a closer fit to the data. This anomalous difference in
> likelihoods has caused the chi-squared statistic in the LRT to be negative,
> giving a p-value of 1, because all of the chi-squared distribution is
> positive, i.e. P(chi-squared > test statistic) = 1 when the test statistic
> is <= 0. Either one or both of the models haven?t converged, or (less
> likely) there is missing data in the added variable so that the data
> differs between the two models.
>
> In addition, it?s very unusual to fit random slopes without also including
> a fixed effect, as you?ve done for targetWordFactor. The null model allows
> the WW-W and NW-W differences in the log odds of being correct to differ
> randomly between subjects and between items, but forces the mean
> differences (across subjects and items) to be zero. You?d need a good
> reason to fit such a model.
>
> Best wishes,
> Paul
>
>
> > On 3 Jun 2019, at 14:25, Guillaume Adeux <guillaumesimon.a2 at gmail.com>
> wrote:
> >
> > Hello Becky,
> >
> > Even though I cannot directly answer your question... a Chisq of 0 with
> > such a difference in AIC seems indeed suspicious.
> >
> > To test the effect of your predictor in a GLMM context through LRT tests,
> > you could (should?) consider using the test_terms function from the
> {monet}
> > package or its little brother function mixed() from the {afex} package.
> > These packages are specifically designed for such tests.
> >
> > I hope this helps.
> >
> > Sincerely,
> >
> > Guillaume ADEUX
> >
> >
> >
> > Le lun. 3 juin 2019 ? 15:14, Becky Gilbert <beckyannegilbert at gmail.com>
> a
> > ?crit :
> >
> >> Dear list
> >>
> >> I have two glmer models, one with a fixed factor (targetWordFactor) and
> one
> >> without, and I am comparing them using the anova function to get the LRT
> >> results for the fixed effect of targetWordFactor. The anova results are
> >> showing a chi-square value of 0 and p value of 1. Is this result
> possible,
> >> or is it perhaps a sign that I've done something wrong?
> >>
> >> Here are the anova results:
> >>
> >> anova(accModelNullWord,accModelWord)
> >> #                                  Df    AIC    BIC logLik deviance
> Chisq
> >> Chi Df Pr(>Chisq)
> >> # accModelNullWord 13 977.59 1067.0 -475.8   951.59
> >> # accModelWord       15 990.61 1093.8 -480.3   960.61     0      2
> >> 1
> >>
> >> The targetWordFactor fixed factor has 3 levels (2 contrasts), so the
> >> degrees of freedom in the anova result look correct to me. Here are the
> >> model specifications:
> >>
> >> contrasts(pauseDetValidNoFillersExcluded$targetWordFactor)
> >> #        WW NW
> >> # W       0  0
> >> # WW   1  0
> >> # NW    0  1
> >>
> >> accModelNullWord <- glmer(correct ~ 1 +
> >>                            (1 + targetWordFactor|subject) +
> >>                            (1 + targetWordFactor|item),
> >>                            data = pauseDetValidNoFillersExcluded,
> >>                            family = binomial(link = "logit"),
> >>                            control = glmerControl(optimizer="bobyqa",
> >>                                                 optCtrl =
> >> list(maxfun=2e5)))
> >>
> >> accModelWord <- glmer(correct ~ 1 + targetWordFactor +
> >>                        (1 + targetWordFactor|subject) +
> >>                        (1 + targetWordFactor|item),
> >>                        data = pauseDetValidNoFillersExcluded,
> >>                        family = binomial(link = "logit"),
> >>                        control = glmerControl(optimizer="bobyqa",
> >>                                             optCtrl = list(maxfun=2e5)))
> >>
> >> Apologies if this question has been asked before - I did search the list
> >> but couldn't find anything.
> >>
> >> Many thanks,
> >> Becky
> >>
> >>        [[alternative HTML version deleted]]
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From orch|dn @end|ng |rom ||ve@com  Tue Jun  4 02:25:43 2019
From: orch|dn @end|ng |rom ||ve@com (dani jones)
Date: Tue, 4 Jun 2019 00:25:43 +0000
Subject: [R-sig-ME] 
 compare a neighbourhood value with the city mean - test
 of significance in presence of spatial autocorrelation
In-Reply-To: <CAJuCY5zNMgTgwOSydYkBaHkHYr5rNPmyBLxMELRPb2zCYSvzsw@mail.gmail.com>
References: <BYAPR06MB38320311B0272A161B175372D61B0@BYAPR06MB3832.namprd06.prod.outlook.com>
 <BYAPR06MB3832B9139DE7D423FF0673F6D61B0@BYAPR06MB3832.namprd06.prod.outlook.com>,
 <CAJuCY5zNMgTgwOSydYkBaHkHYr5rNPmyBLxMELRPb2zCYSvzsw@mail.gmail.com>
Message-ID: <BYAPR06MB383277C8C3324C7B4E58EFDFD6150@BYAPR06MB3832.namprd06.prod.outlook.com>

Hi Thierry,

Thank you so much! I looked at the BYM model, which I have not used before. I need to be able to create a table with all the neighbourhoods in the dataset, indicating whether they are significantly over or under the city value. I am not sure how to test these differences.

Best regards,
Dani


________________________________
From: Thierry Onkelinx <thierry.onkelinx at inbo.be>
Sent: Monday, June 3, 2019 12:23 AM
To: dani jones
Cc: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] compare a neighbourhood value with the city mean - test of significance in presence of spatial autocorrelation

Dear Dani,

What I would do is create a graph indicating which neighbourhoods are directly connected to each other (share a border). And use this information to fit a Besag-York-Mollier model which takes care of the auto-correlation among the neighbourhoods. For an example see
library(INLA)
demo("Bym")

You can find the INLA package at http://www.r-inla.org<http://www.r-inla.org/>


Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be<mailto:thierry.onkelinx at inbo.be>
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be<http://www.inbo.be>

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

[https://inbo-website-prd-532750756126.s3-eu-west-1.amazonaws.com/inbologoleeuw_nl.png]
<https://www.inbo.be>


Op ma 3 jun. 2019 om 01:50 schreef dani jones <orchidn at live.com<mailto:orchidn at live.com>>:
Hi everyone,


I have a dataset with all neighbourhoods in a city and a value for each neighbourhood (a rate). I would like to be able to create a vizualization that enables the user to select individual neighbourhoods and find out whether the value of that neighbourhood is significantly higher or lower than the city average across all neighbourhoods (I have a value that was calculated for the city). Given that the neighbourhoods are contiguous areas composing the city, there is spatial dependency, so I cannot use z scores or apply other classical statistics test since the observations are not independent and spatial autocorrelation might exist.

I am not sure what test to apply to achieve this. Any help and links to potential readings would be very much appreciated.

Thank you very much!

Dani

<http://aka.ms/weboutlook>

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From th|erry@onke||nx @end|ng |rom |nbo@be  Tue Jun  4 09:41:04 2019
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Tue, 4 Jun 2019 09:41:04 +0200
Subject: [R-sig-ME] 
 compare a neighbourhood value with the city mean - test
 of significance in presence of spatial autocorrelation
In-Reply-To: <BYAPR06MB383277C8C3324C7B4E58EFDFD6150@BYAPR06MB3832.namprd06.prod.outlook.com>
References: <BYAPR06MB38320311B0272A161B175372D61B0@BYAPR06MB3832.namprd06.prod.outlook.com>
 <BYAPR06MB3832B9139DE7D423FF0673F6D61B0@BYAPR06MB3832.namprd06.prod.outlook.com>
 <CAJuCY5zNMgTgwOSydYkBaHkHYr5rNPmyBLxMELRPb2zCYSvzsw@mail.gmail.com>
 <BYAPR06MB383277C8C3324C7B4E58EFDFD6150@BYAPR06MB3832.namprd06.prod.outlook.com>
Message-ID: <CAJuCY5wei7FYEuwMetK724J+jmcDQaQa00n4tk_vWRNa085KjQ@mail.gmail.com>

You can calculate a linear combination of the iid and besag part of the the
bym model for each neighbourhood. This yields the effect of the
neighbourhood conditional on the other effects in the model. See FAQ 17 at
http://www.r-inla.org/faq on how to calculate linear combinations.

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op di 4 jun. 2019 om 02:25 schreef dani jones <orchidn at live.com>:

> Hi Thierry,
>
> Thank you so much! I looked at the BYM model, which I have not used
> before. I need to be able to create a table with all the neighbourhoods in
> the dataset, indicating whether they are significantly over or under the
> city value. I am not sure how to test these differences.
>
> Best regards,
> Dani
>
>
> ------------------------------
> *From:* Thierry Onkelinx <thierry.onkelinx at inbo.be>
> *Sent:* Monday, June 3, 2019 12:23 AM
> *To:* dani jones
> *Cc:* r-sig-mixed-models at r-project.org
> *Subject:* Re: [R-sig-ME] compare a neighbourhood value with the city
> mean - test of significance in presence of spatial autocorrelation
>
> Dear Dani,
>
> What I would do is create a graph indicating which neighbourhoods are
> directly connected to each other (share a border). And use this information
> to fit a Besag-York-Mollier model which takes care of the auto-correlation
> among the neighbourhoods. For an example see
> library(INLA)
> demo("Bym")
>
> You can find the INLA package at http://www.r-inla.org
>
>
> Best regards,
>
> ir. Thierry Onkelinx
> Statisticus / Statistician
>
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
> FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Havenlaan 88 bus 73, 1000 Brussel
> www.inbo.be
>
>
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> ///////////////////////////////////////////////////////////////////////////////////////////
>
>
> <https://www.inbo.be>
>
>
> Op ma 3 jun. 2019 om 01:50 schreef dani jones <orchidn at live.com>:
>
> Hi everyone,
>
>
> I have a dataset with all neighbourhoods in a city and a value for each
> neighbourhood (a rate). I would like to be able to create a vizualization
> that enables the user to select individual neighbourhoods and find out
> whether the value of that neighbourhood is significantly higher or lower
> than the city average across all neighbourhoods (I have a value that was
> calculated for the city). Given that the neighbourhoods are contiguous
> areas composing the city, there is spatial dependency, so I cannot use z
> scores or apply other classical statistics test since the observations are
> not independent and spatial autocorrelation might exist.
>
> I am not sure what test to apply to achieve this. Any help and links to
> potential readings would be very much appreciated.
>
> Thank you very much!
>
> Dani
>
> <http://aka.ms/weboutlook>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>

	[[alternative HTML version deleted]]


From cr|@@|e@@@ndro @end|ng |rom gm@||@com  Wed Jun  5 16:19:17 2019
From: cr|@@|e@@@ndro @end|ng |rom gm@||@com (Cristiano Alessandro)
Date: Wed, 5 Jun 2019 09:19:17 -0500
Subject: [R-sig-ME] denominator DOF in lme, inner-outer rule
Message-ID: <CAHhX7Wi1D1EOnR6pVT+zo6UNHBt6JbEqWO+VSN-zZb9UURdnzg@mail.gmail.com>

Dear all,

I have read in this
<https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#why-doesnt-lme4-display-denominator-degrees-of-freedomp-values-what-other-options-do-i-have>
blog, that the function lme (in the nlme package) provides inaccurate
denominator dof for random slope models according to the definition given
by Pinheiro and Bates. Is this only a visualization issue, or such "wrong"
denDOFs are actually those used if I run an anova on the fitted model. In
the latter case, I guess the p-values and F-statistics provided by anova
for random slope models should not be trusted, correct?

I know that the estimation of the denominator DOF is a controversial topic.
When I say "wrong" denDF I only mean that they do not reflect the
estimation based on inner and outer rule defined by Pinheiro and Bates
(which is used for random intercept only models).

Thanks a lot
Cristiano

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Thu Jun  6 01:35:32 2019
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Wed, 5 Jun 2019 19:35:32 -0400
Subject: [R-sig-ME] denominator DOF in lme, inner-outer rule
In-Reply-To: <CAHhX7Wi1D1EOnR6pVT+zo6UNHBt6JbEqWO+VSN-zZb9UURdnzg@mail.gmail.com>
References: <CAHhX7Wi1D1EOnR6pVT+zo6UNHBt6JbEqWO+VSN-zZb9UURdnzg@mail.gmail.com>
Message-ID: <8f4d6776-63bc-c384-d7bc-97b45bacd23e@gmail.com>


  Briefly, this is a "real" issue -- anova uses these "wrong" denDOFs.
(You can try an example and see for yourself!)

  Can you clarify your last paragraph?  As far as I remember (I'm not
looking at the details/code right now), PB define the "inner-outer" rule
fairly generally -- my understanding based on stuff I played around with
a few years ago is that it only *works* for random-intercept models, but
I don't remember seeing this clarified anywhere in the book? Maybe I
missed it ... in any case, IIRC the "inner-outer" rule implemented in
nlme, which is used in the anova method for lme objects, does not work
reliably for random-intercept models.


On 2019-06-05 10:19 a.m., Cristiano Alessandro wrote:
> Dear all,
> 
> I have read in this
> <https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#why-doesnt-lme4-display-denominator-degrees-of-freedomp-values-what-other-options-do-i-have>
> blog, that the function lme (in the nlme package) provides inaccurate
> denominator dof for random slope models according to the definition given
> by Pinheiro and Bates. Is this only a visualization issue, or such "wrong"
> denDOFs are actually those used if I run an anova on the fitted model. In
> the latter case, I guess the p-values and F-statistics provided by anova
> for random slope models should not be trusted, correct?
> 
> I know that the estimation of the denominator DOF is a controversial topic.
> When I say "wrong" denDF I only mean that they do not reflect the
> estimation based on inner and outer rule defined by Pinheiro and Bates
> (which is used for random intercept only models).
> 
> Thanks a lot
> Cristiano
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From p@tr|c|@@gr@|03 @end|ng |rom gm@||@com  Sun Jun  9 09:16:43 2019
From: p@tr|c|@@gr@|03 @end|ng |rom gm@||@com (Patricia Graf)
Date: Sun, 9 Jun 2019 09:16:43 +0200
Subject: [R-sig-ME] Mixed model interpretation with interaction
Message-ID: <CAPgMhDas57jLgRQg+n7d11ycDn_OXBGxUX7woaD4M4SvbhRzqQ@mail.gmail.com>

Hello,



I have a few questions concering the interpretation of a GLMM output table
when the model includes an interaction.



We want to analyse bear presence at feeding sites (bear_pres) related to
the year (two years: 2016, 2017) and the feed supplied at feeding sites
(carrion, maize). So the response is binary (0 = no bear present, 1 = bear
present within 5-min intervals over the whole day) and both predictors are
categorical, we include feeding site ID as random factor.



The model includes some other variables too but for simplicity I just use
those two variables for explanation.



1) As I understand, in a model without interaction, the interpretation of
the results would be as follows:



M1 <- glmer((bear_pres ~  feed + year + (1|Feeding.site), family=binomial,
data=df10)

Fixed effects:

           Estimate Std. Error z value Pr(>|z|)

(Intercept) -4.58524    0.08529 -53.76   <2e-16 ***the intercept is bear
presence at maize sites in 2016

feedcarrion    0.39178    0.02139   18.32  <2e-16 ***bear presence at
feeding sites in 2017 compared to 2016

year2017    0.23027    0.01978   11.64  <2e-16 ***bear presence at carrion
feeding sites compared to maize feeding sites



Is this interpretation right?





2) To my knowledge, the output changes when you include an interaction:



M2<- glmer(bear_pres ~  year*feed + (1|Feeding.site), family=binomial,
data=df10)

Fixed effects:

                  Estimate Std. Error z value Pr(>|z|)

(Intercept)       -4.36413    0.10730 -40.67  < 2e-16 ***the intercept is
bear presence at maize sites in 2016 (baseline)

year2017          -0.18010    0.05119  -3.52 0.000434 ***difference in bear
presence in 2017 compared to 2016 for maize

feedcarrion          -0.02933    0.05318  -0.55 0.581222    difference in
bear presence at carrion sites compared to maize sites in 2016

year2017:feedcarrion  0.85275   0.09953    8.57  < 2e-16 ***difference in
bear presence at carrion sites 2017 and the sum of ?0+ ?1+ ?2



So to my questions: Is this interpretation right? What is the coding of the
model so it does produce this output, e.g. why is the year not comparing
2016 to 2017 anymore as in the model without the interaction? Or why
doesn?t the model still use the two food types for comparison?



As I understand, when you include an intercation between the two binary
dummy-coded categorical variables, the interpretation of what was main
effects before (year, carrion) changes, and so do the betas (these are
called ?simple effects? afterwards).



In my group, there is a strong believe that in M2, the year still compares
the two years (and so does feed), it?s just the coefficient cannot be
interpreted anymore. Also, there is a believe that the interaction term
compares to feedmaize in the year 2016.



If my interpreation is correct, I need some background on how the algorithm
works, how simple effects evolve and why the interaction should be
interpreted as in the output table of M2.



Thank you for your help in advance!

	[[alternative HTML version deleted]]


From emm@nue|@cur|@ @end|ng |rom p@r|@de@c@rte@@|r  Sun Jun  9 09:59:14 2019
From: emm@nue|@cur|@ @end|ng |rom p@r|@de@c@rte@@|r (Emmanuel Curis)
Date: Sun, 9 Jun 2019 09:59:14 +0200
Subject: [R-sig-ME] Mixed model interpretation with interaction
In-Reply-To: <CAPgMhDas57jLgRQg+n7d11ycDn_OXBGxUX7woaD4M4SvbhRzqQ@mail.gmail.com>
References: <CAPgMhDas57jLgRQg+n7d11ycDn_OXBGxUX7woaD4M4SvbhRzqQ@mail.gmail.com>
Message-ID: <20190609075914.GA30055@info124.pharmacie.univ-paris5.fr>

Hello Patricia,

I think the interpretation of the fixed part is the same as for a
classical glm.  See below...

On Sun, Jun 09, 2019 at 09:16:43AM +0200, Patricia Graf wrote:
? Hello,
? 
? I have a few questions concering the interpretation of a GLMM output table
? when the model includes an interaction.
? 
? We want to analyse bear presence at feeding sites (bear_pres) related to
? the year (two years: 2016, 2017) and the feed supplied at feeding sites
? (carrion, maize). So the response is binary (0 = no bear present, 1 = bear
? present within 5-min intervals over the whole day) and both predictors are
? categorical, we include feeding site ID as random factor.
? 
? 1) As I understand, in a model without interaction, the interpretation of
? the results would be as follows:
? 
? M1 <- glmer((bear_pres ~  feed + year + (1|Feeding.site), family=binomial,
? data=df10)
? 
? Fixed effects:
? 
?            Estimate Std. Error z value Pr(>|z|)
? 
? (Intercept) -4.58524    0.08529 -53.76   <2e-16 ***the intercept is bear
? presence at maize sites in 2016

More exactly, it is the log-odds of bear presence for an average site
where maize is supplied in 2016

? feedcarrion    0.39178    0.02139   18.32  <2e-16 ***bear presence at
? feeding sites in 2017 compared to 2016
? 
? year2017    0.23027    0.01978   11.64  <2e-16 ***bear presence at carrion
? feeding sites compared to maize feeding sites
?

You have swapped the two lines. ? feedcarrion ? is the change in the
log-odds [that is, the log-odds ratio] when replacing maize by carrion
for a given site, both in 2017 and in 2016 since there is no
interaction; ? year2017 ?, the same for 2017 vs 2016.

? Is this interpretation right?
? 
? 2) To my knowledge, the output changes when you include an
? interaction:

Yes. Unless you have a perfectly null interaction in the sample, it
has to change, at least with default R coding for factors.

? M2<- glmer(bear_pres ~  year*feed + (1|Feeding.site), family=binomial,
? data=df10)
? 
? Fixed effects:
? 
?                   Estimate Std. Error z value Pr(>|z|)
? 
? (Intercept)       -4.36413    0.10730 -40.67  < 2e-16 ***the intercept is
? bear presence at maize sites in 2016 (baseline)

Same remark as above.

? 
? year2017          -0.18010    0.05119  -3.52 0.000434 ***difference in bear
? presence in 2017 compared to 2016 for maize
? 
? feedcarrion          -0.02933    0.05318  -0.55 0.581222    difference in
? bear presence at carrion sites compared to maize sites in 2016
? 
? year2017:feedcarrion  0.85275   0.09953    8.57  < 2e-16 ***difference in
? bear presence at carrion sites 2017 and the sum of ?0+ ?1+ ?2
? 
? So to my questions: Is this interpretation right?

Yes.

? What is the coding of the
? model so it does produce this output, e.g. why is the year not comparing
? 2016 to 2017 anymore as in the model without the interaction?

The model is, in the log-odds scale,
 y = ?0 + ?1 ? 1(year = 2017) + ?2 ? 1(feed = carrion)
        + ?3 ? 1(year = 2017) ? 1(feed = carrion)

where 1(x) is the ? indicatrice ? of x, that is the function equalling
1 if x is true, 0 otherwise.

? Or why
? doesn?t the model still use the two food types for comparison?

Because the interaction says that the comparison between years is
different for each food type, so a global comparison is (roughly
speaking) meaningless.

? As I understand, when you include an intercation between the two binary
? dummy-coded categorical variables, the interpretation of what was main
? effects before (year, carrion) changes, and so do the betas (these are
? called ?simple effects? afterwards).

The interpretation of what is a main effect does not really change,
but coefficients of the model do not correspond anymore to main
effects.  To have main effect evaluation, you should use suited
analysis of variance/deviance tables (see Type I, Type II, Type III
sums of squares and all these kind of things) or coefficients linear
combinations.

? In my group, there is a strong believe that in M2, the year still compares
? the two years (and so does feed), it?s just the coefficient cannot be
? interpreted anymore. Also, there is a believe that the interaction term
? compares to feedmaize in the year 2016.

Not sure to understand, but seems wrong.

? If my interpreation is correct, I need some background on how the algorithm
? works, how simple effects evolve and why the interaction should be
? interpreted as in the output table of M2.

Read more about two-ways, 2?2 crossed factors, analysis of variance:
this is the basic and most simple case to understand interaction. Or
may be, as an alternative, analysis of covariance. Interpretation is
basically the same afterthat for glm/logistic regression, and when
adding random effects. Just a little bit more abstract because of the
change of the modeling scale (log-odds for glm/glmer here, for
instance).

Hope this helps,
Best regards,

-- 
                                Emmanuel CURIS
                                emmanuel.curis at parisdescartes.fr

Page WWW: http://emmanuel.curis.online.fr/index.html


From hkubr@@eno| @end|ng |rom gm@||@com  Sun Jun  9 12:24:22 2019
From: hkubr@@eno| @end|ng |rom gm@||@com (HATICE T KUBRA AKDUR)
Date: Sun, 9 Jun 2019 13:24:22 +0300
Subject: [R-sig-ME] adaptive gaussian quadrature algorithm for unit-lindley
 glmm
Message-ID: <CA+_DO+x8D9DCRWGdXX6O8N1dTLOYNVLXSCAzxuu_jFRMWN9Ccg@mail.gmail.com>

Hello,

I recently have worked on a unit-lindley distribution and its mixed
regression model. There is no R library and ready function to obtain MLEs
of regression parameters. As far as I investigate, I should use adaptive
gaussian quadrature algorithm to obtain MLEs of regression parameters when
random effect included in the model.

However, I could not understand how to implement gaussian quadrature
algorithm for unit-lindley mixed regression model.


May you provide me gaussian quadrature algorithm source code for any mixed
model if you have it? Then I can adapt this algorithm to my case,
hopefully.


Thank you very much in advance,


Best Wishes,

-- 
Hatice Tul Kubra AKDUR, PhD
Department of Statistics, Faculty of Science
Gazi University
06500 Teknikokullar ANKARA, TURKEY
Phone: +90 553 324 5380
Email: hatice_senol at wsu.edu
Homepage: http://websitem.gazi.edu.tr/site/haticesenol

	[[alternative HTML version deleted]]


From d@iuedecke m@iii@g oii uke@de  Sun Jun  9 12:45:16 2019
From: d@iuedecke m@iii@g oii uke@de (d@iuedecke m@iii@g oii uke@de)
Date: Sun, 9 Jun 2019 12:45:16 +0200
Subject: [R-sig-ME] Mixed model interpretation with interaction
In-Reply-To: <CAPgMhDas57jLgRQg+n7d11ycDn_OXBGxUX7woaD4M4SvbhRzqQ@mail.gmail.com>
References: <CAPgMhDas57jLgRQg+n7d11ycDn_OXBGxUX7woaD4M4SvbhRzqQ@mail.gmail.com>
Message-ID: <001801d51eb0$6d30f4e0$4792dea0$@uke.de>

Dear Patricia,

when you include an interaction, your assumption is that the relationship between an independent X1 and the dependent variable Y varies *depending on the values of another independent variable X2*. Indeed, for logistic regression models (as well as for many models with non-Gaussian families), the interpretation of interaction terms can be tricky. In such cases, I would recommend to compute (at least additionally) marginal effects, which give you an intuitive output of your results.

You can do so e.g. with the "ggeffects" package (https://strengejacke.github.io/ggeffects/), and there is also an example for a logistic mixed effects model (https://strengejacke.github.io/ggeffects/articles/practical_logisticmixedmodel.html), which might help you.

In your case, the code would be
ggpredict(M1, c("feed", "year")) for the model with interaction. If you want to plot the results, simply call
me <- ggpredict(M1, c("feed", "year"))
plot(me)

A comment on your model: I'm not sure, but if you compare subjects (or feeding sites) at two time points, you might want to model the auto-correlation of subjects / feeding site ("repeated measure") using your time variable as random slope:

M1 <- glmer((bear_pres ~  feed * year + (1 + year | Feeding.site), family = binomial, data = df10)

Computing marginal effects than would be the same function call:
ggpredict(M1, c("feed", "year"))


Best
Daniel


-----Urspr?ngliche Nachricht-----
Von: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> Im Auftrag von Patricia Graf
Gesendet: Sonntag, 9. Juni 2019 09:17
An: r-sig-mixed-models at r-project.org
Betreff: [R-sig-ME] Mixed model interpretation with interaction

Hello,



I have a few questions concering the interpretation of a GLMM output table
when the model includes an interaction.

We want to analyse bear presence at feeding sites (bear_pres) related to
the year (two years: 2016, 2017) and the feed supplied at feeding sites
(carrion, maize). So the response is binary (0 = no bear present, 1 = bear
present within 5-min intervals over the whole day) and both predictors are
categorical, we include feeding site ID as random factor.



The model includes some other variables too but for simplicity I just use
those two variables for explanation.



1) As I understand, in a model without interaction, the interpretation of
the results would be as follows:



M1 <- glmer((bear_pres ~  feed + year + (1|Feeding.site), family=binomial,
data=df10)

Fixed effects:

           Estimate Std. Error z value Pr(>|z|)

(Intercept) -4.58524    0.08529 -53.76   <2e-16 ***the intercept is bear
presence at maize sites in 2016

feedcarrion    0.39178    0.02139   18.32  <2e-16 ***bear presence at
feeding sites in 2017 compared to 2016

year2017    0.23027    0.01978   11.64  <2e-16 ***bear presence at carrion
feeding sites compared to maize feeding sites



Is this interpretation right?





2) To my knowledge, the output changes when you include an interaction:



M2<- glmer(bear_pres ~  year*feed + (1|Feeding.site), family=binomial,
data=df10)

Fixed effects:

                  Estimate Std. Error z value Pr(>|z|)

(Intercept)       -4.36413    0.10730 -40.67  < 2e-16 ***the intercept is
bear presence at maize sites in 2016 (baseline)

year2017          -0.18010    0.05119  -3.52 0.000434 ***difference in bear
presence in 2017 compared to 2016 for maize

feedcarrion          -0.02933    0.05318  -0.55 0.581222    difference in
bear presence at carrion sites compared to maize sites in 2016

year2017:feedcarrion  0.85275   0.09953    8.57  < 2e-16 ***difference in
bear presence at carrion sites 2017 and the sum of ?0+ ?1+ ?2



So to my questions: Is this interpretation right? What is the coding of the
model so it does produce this output, e.g. why is the year not comparing
2016 to 2017 anymore as in the model without the interaction? Or why
doesn?t the model still use the two food types for comparison?



As I understand, when you include an intercation between the two binary
dummy-coded categorical variables, the interpretation of what was main
effects before (year, carrion) changes, and so do the betas (these are
called ?simple effects? afterwards).



In my group, there is a strong believe that in M2, the year still compares
the two years (and so does feed), it?s just the coefficient cannot be
interpreted anymore. Also, there is a believe that the interaction term
compares to feedmaize in the year 2016.



If my interpreation is correct, I need some background on how the algorithm
works, how simple effects evolve and why the interaction should be
interpreted as in the output table of M2.



Thank you for your help in advance!

	[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

--

_____________________________________________________________________

Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen Rechts; Gerichtsstand: Hamburg | www.uke.de
Vorstandsmitglieder: Prof. Dr. Burkhard G?ke (Vorsitzender), Prof. Dr. Dr. Uwe Koch-Gromus, Joachim Pr?l?, Marya Verdel
_____________________________________________________________________

SAVE PAPER - THINK BEFORE PRINTING

From d@r|zopou|o@ @end|ng |rom er@@mu@mc@n|  Sun Jun  9 16:23:01 2019
From: d@r|zopou|o@ @end|ng |rom er@@mu@mc@n| (D. Rizopoulos)
Date: Sun, 9 Jun 2019 14:23:01 +0000
Subject: [R-sig-ME] 
 adaptive gaussian quadrature algorithm for unit-lindley glmm
In-Reply-To: <CA+_DO+x8D9DCRWGdXX6O8N1dTLOYNVLXSCAzxuu_jFRMWN9Ccg@mail.gmail.com>
References: <CA+_DO+x8D9DCRWGdXX6O8N1dTLOYNVLXSCAzxuu_jFRMWN9Ccg@mail.gmail.com>
Message-ID: <7191AFC7255B4F49A30707E39BEAD05FDED5A72D@EXCH-HE03.erasmusmc.nl>

Have a look at the GLMMadaptive package that also allows you to define your own mixed model:

https://drizopoulos.github.io/GLMMadaptive/
https://drizopoulos.github.io/GLMMadaptive/articles/Custom_Models.html

Best,
Dimitris


From: HATICE T KUBRA AKDUR <hkubrasenol at gmail.com<mailto:hkubrasenol at gmail.com>>
Date: Sunday, 09 Jun 2019, 12:24
To: R-sig-mixed-models at r-project.org <R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org>>
Subject: [R-sig-ME] adaptive gaussian quadrature algorithm for unit-lindley glmm

Hello,

I recently have worked on a unit-lindley distribution and its mixed
regression model. There is no R library and ready function to obtain MLEs
of regression parameters. As far as I investigate, I should use adaptive
gaussian quadrature algorithm to obtain MLEs of regression parameters when
random effect included in the model.

However, I could not understand how to implement gaussian quadrature
algorithm for unit-lindley mixed regression model.


May you provide me gaussian quadrature algorithm source code for any mixed
model if you have it? Then I can adapt this algorithm to my case,
hopefully.


Thank you very much in advance,


Best Wishes,

--
Hatice Tul Kubra AKDUR, PhD
Department of Statistics, Faculty of Science
Gazi University
06500 Teknikokullar ANKARA, TURKEY
Phone: +90 553 324 5380
Email: hatice_senol at wsu.edu
Homepage: https://eur01.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwebsitem.gazi.edu.tr%2Fsite%2Fhaticesenol&amp;data=02%7C01%7Cd.rizopoulos%40erasmusmc.nl%7Ccb76a20bee22422154b208d6ecc4b455%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C0%7C636956726919237207&amp;sdata=LqgOO7SkfaXs0%2FJ8DqwFumwgTaf4ZIPLlk%2FeWsundzA%3D&amp;reserved=0

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=02%7C01%7Cd.rizopoulos%40erasmusmc.nl%7Ccb76a20bee22422154b208d6ecc4b455%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C0%7C636956726919237207&amp;sdata=VWgzu6wCCCaiqeYINcO6dc8jcGH1oD8l2sEWCnLYSu4%3D&amp;reserved=0

	[[alternative HTML version deleted]]


From b|mono@om @end|ng |rom gm@||@com  Sun Jun  9 16:57:06 2019
From: b|mono@om @end|ng |rom gm@||@com (=?UTF-8?B?UmVuw6k=?=)
Date: Sun, 9 Jun 2019 16:57:06 +0200
Subject: [R-sig-ME] Mixed model interpretation with interaction
In-Reply-To: <001801d51eb0$6d30f4e0$4792dea0$@uke.de>
References: <CAPgMhDas57jLgRQg+n7d11ycDn_OXBGxUX7woaD4M4SvbhRzqQ@mail.gmail.com>
 <001801d51eb0$6d30f4e0$4792dea0$@uke.de>
Message-ID: <CADcpBHOa0eLj8z3rdvaF9m5Pewj13Ztde=VV--wuZYjUTe40Dg@mail.gmail.com>

Hi,

I don't know if this adds anything new but the most direct answers that
come into my mind would be.
1) It seems you use dummy coding, and this defines the interpretation of
the estimated coefficients, which would be different from (often preferred
because more easy to interpret)  effect / or contrast coding (dummy coding
has some 'fitting' advantages which are mainly discussed with respected to
centered vs. non-centered likelihood (or least-square-mean) estimation
processes, which might be insightful for you to look up in the internet);
but any coding design you use will eventually simply try to estimate
cell-means (in your case on a log scale), and you need to check how to get
these cell means out of your coefficients (via back-transformation). One
way of doing this is by using marginal predictions, as Daniel points out.

2) For another (technical) illustration: a test-design matrix as yours with
(e.g.) 2 feeding sites and 2 years, then it would be a 2(site 1 vs. site 2)
by 2(year 1 vs year 2) independent measures design; or 2 x 2 for short,
which could be simply expressed by 4 probabilities or by using means on a
log scale, one mean for each of the design-cells, which would be the
"centered" variant of estimation; but usually dummy coding implies a
non-centered (but mathematically equivalent  - standard) coding:
If the model is:
y = site+year (ignoring random effects now), then
cellmean(site1:year1) = Model_Intercept
cellmean(site1:year2) = Model_Intercept + year2
cellmean(site2:year1) = Model_Intercept + site2
cellmean(site2:year2) = Model_Intercept + site2 + year2

mean(site1) = (2*Model_intercept + year2)/2
mean(site2) = ( 2(Model_intercept + site2)+year2))/2
and so on...
(Where intercept in most estimation methods is by default is defined in
reference to the first level of the first predictor in the equation; thus
site1 (+year1, which is 0 in this type of coding); but the reference point
can be changed manually)

If the model is:
y=site+year+site:year, then
cellmean(site1:year1) = Model_Intercept
cellmean(site1:year2) = Model_Intercept + year2
cellmean(site2:year1) = Model_Intercept + site2
cellmean(site2:year2) = Model_Intercept+site2+ year2 +   site2:year2

Where only the fourth equation changes, which nontheless can have a huge
impact on the estimation of the other parameters

(usually R outputs the reference levels for the intercept and the
coefficients, which you can easily identify)
In case there are more sites than two... e.g.. 4 of them, then:
cellmean(site1:year1) = Model_Intercept
cellmean(site2:year1) = Model_Intercept + site2
cellmean(site3:year1) = Model_Intercept + site3
cellmean(site4:year1) = Model_Intercept + site4

You might get the gist :)

Finally, if you actually want to test for an overall interaction in this
way (or main effects), looking at these coefficients is not meaningful,
which you can tell by just looking at the formulas above...,  So you might
want to do it differently (correctly), namely by using likelihood ratio
tests:
(in R like coding)

Model1<- y=site+year+site:year
vs
Model2<- y=site+year

with
anova(Model1,Model2)  (I think aov() should work as well)
If the interaction of both variables is significant (i.e. the anova()
output gives a * for the comparison between Model 1 and Model 2... :)))
then the interaction effect explains some 'significant' amount of variance.
(If there is no *, you can consider the models as equal in terms of
explained variance). Same for other effects (e.g. full model vs. model a
specific main effect).
Maybe Check whether the "afex::mixed" function which does this for you in a
sensible way (there are different ways of doing LRT tests...)
;))

Having done this in the first place, is often viewed as prerequisite for
'digging' into the model estimates (as discussed above) to find out, what
significant then actually means in terms of 'mean-changes' :)

Hope this helps,
Best, Ren?



Am So., 9. Juni 2019 um 12:45 Uhr schrieb <d.luedecke at uke.de>:

> Dear Patricia,
>
> when you include an interaction, your assumption is that the relationship
> between an independent X1 and the dependent variable Y varies *depending on
> the values of another independent variable X2*. Indeed, for logistic
> regression models (as well as for many models with non-Gaussian families),
> the interpretation of interaction terms can be tricky. In such cases, I
> would recommend to compute (at least additionally) marginal effects, which
> give you an intuitive output of your results.
>
> You can do so e.g. with the "ggeffects" package (
> https://strengejacke.github.io/ggeffects/), and there is also an example
> for a logistic mixed effects model (
> https://strengejacke.github.io/ggeffects/articles/practical_logisticmixedmodel.html),
> which might help you.
>
> In your case, the code would be
> ggpredict(M1, c("feed", "year")) for the model with interaction. If you
> want to plot the results, simply call
> me <- ggpredict(M1, c("feed", "year"))
> plot(me)
>
> A comment on your model: I'm not sure, but if you compare subjects (or
> feeding sites) at two time points, you might want to model the
> auto-correlation of subjects / feeding site ("repeated measure") using your
> time variable as random slope:
>
> M1 <- glmer((bear_pres ~  feed * year + (1 + year | Feeding.site), family
> = binomial, data = df10)
>
> Computing marginal effects than would be the same function call:
> ggpredict(M1, c("feed", "year"))
>
>
> Best
> Daniel
>
>
> -----Urspr?ngliche Nachricht-----
> Von: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> Im
> Auftrag von Patricia Graf
> Gesendet: Sonntag, 9. Juni 2019 09:17
> An: r-sig-mixed-models at r-project.org
> Betreff: [R-sig-ME] Mixed model interpretation with interaction
>
> Hello,
>
>
>
> I have a few questions concering the interpretation of a GLMM output table
> when the model includes an interaction.
>
> We want to analyse bear presence at feeding sites (bear_pres) related to
> the year (two years: 2016, 2017) and the feed supplied at feeding sites
> (carrion, maize). So the response is binary (0 = no bear present, 1 = bear
> present within 5-min intervals over the whole day) and both predictors are
> categorical, we include feeding site ID as random factor.
>
>
>
> The model includes some other variables too but for simplicity I just use
> those two variables for explanation.
>
>
>
> 1) As I understand, in a model without interaction, the interpretation of
> the results would be as follows:
>
>
>
> M1 <- glmer((bear_pres ~  feed + year + (1|Feeding.site), family=binomial,
> data=df10)
>
> Fixed effects:
>
>            Estimate Std. Error z value Pr(>|z|)
>
> (Intercept) -4.58524    0.08529 -53.76   <2e-16 ***the intercept is bear
> presence at maize sites in 2016
>
> feedcarrion    0.39178    0.02139   18.32  <2e-16 ***bear presence at
> feeding sites in 2017 compared to 2016
>
> year2017    0.23027    0.01978   11.64  <2e-16 ***bear presence at carrion
> feeding sites compared to maize feeding sites
>
>
>
> Is this interpretation right?
>
>
>
>
>
> 2) To my knowledge, the output changes when you include an interaction:
>
>
>
> M2<- glmer(bear_pres ~  year*feed + (1|Feeding.site), family=binomial,
> data=df10)
>
> Fixed effects:
>
>                   Estimate Std. Error z value Pr(>|z|)
>
> (Intercept)       -4.36413    0.10730 -40.67  < 2e-16 ***the intercept is
> bear presence at maize sites in 2016 (baseline)
>
> year2017          -0.18010    0.05119  -3.52 0.000434 ***difference in bear
> presence in 2017 compared to 2016 for maize
>
> feedcarrion          -0.02933    0.05318  -0.55 0.581222    difference in
> bear presence at carrion sites compared to maize sites in 2016
>
> year2017:feedcarrion  0.85275   0.09953    8.57  < 2e-16 ***difference in
> bear presence at carrion sites 2017 and the sum of ?0+ ?1+ ?2
>
>
>
> So to my questions: Is this interpretation right? What is the coding of the
> model so it does produce this output, e.g. why is the year not comparing
> 2016 to 2017 anymore as in the model without the interaction? Or why
> doesn?t the model still use the two food types for comparison?
>
>
>
> As I understand, when you include an intercation between the two binary
> dummy-coded categorical variables, the interpretation of what was main
> effects before (year, carrion) changes, and so do the betas (these are
> called ?simple effects? afterwards).
>
>
>
> In my group, there is a strong believe that in M2, the year still compares
> the two years (and so does feed), it?s just the coefficient cannot be
> interpreted anymore. Also, there is a believe that the interaction term
> compares to feedmaize in the year 2016.
>
>
>
> If my interpreation is correct, I need some background on how the algorithm
> works, how simple effects evolve and why the interaction should be
> interpreted as in the output table of M2.
>
>
>
> Thank you for your help in advance!
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> --
>
> _____________________________________________________________________
>
> Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen
> Rechts; Gerichtsstand: Hamburg | www.uke.de
> Vorstandsmitglieder: Prof. Dr. Burkhard G?ke (Vorsitzender), Prof. Dr. Dr.
> Uwe Koch-Gromus, Joachim Pr?l?, Marya Verdel
> _____________________________________________________________________
>
> SAVE PAPER - THINK BEFORE PRINTING
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From b|mono@om @end|ng |rom gm@||@com  Sun Jun  9 17:29:14 2019
From: b|mono@om @end|ng |rom gm@||@com (=?UTF-8?B?UmVuw6k=?=)
Date: Sun, 9 Jun 2019 17:29:14 +0200
Subject: [R-sig-ME] Mixed model interpretation with interaction
In-Reply-To: <CADcpBHOa0eLj8z3rdvaF9m5Pewj13Ztde=VV--wuZYjUTe40Dg@mail.gmail.com>
References: <CAPgMhDas57jLgRQg+n7d11ycDn_OXBGxUX7woaD4M4SvbhRzqQ@mail.gmail.com>
 <001801d51eb0$6d30f4e0$4792dea0$@uke.de>
 <CADcpBHOa0eLj8z3rdvaF9m5Pewj13Ztde=VV--wuZYjUTe40Dg@mail.gmail.com>
Message-ID: <CADcpBHO4PVEqztA2PuZ2YJ9dHNdgDfz9TjPrXkYUXUB56Gtp-w@mail.gmail.com>

Ps:

I also agree with Daniel to take care of repeated measurements of the same
bears coming to the sites in both years.
However, the main problem I guess, will be that not every bear comes back
in the second year. This means, having random slopes for bears that were
observed only once, will bias the effect estimate (i.e. the random slopes
for year will not be separable from the fixed effect of year).
A solution to this, however would be, to use an extra variable (lets call
it 'repeat') that codes, whether a bear has there in both years (=1) or not
(=0; numeric coding - not factored). Then you the following should work:

model<-(y~site*year+(0+repeat*year| bearID))
Which will estimate random slopes for year for all bears that were there at
least twice, but not for others, where the term before the | becomes 0 (and
nothing happens)).

Best, Ren?

Pps: You can tell your colleagues that:
the Model-intercept is the only direct mean that the model estimates
directly (i.e. the reference cell) and all other deviations (including
other means) are linear combinations from that intercept (for any factor)
...  And ... of course, the parameters still can be interpreted this way
(as illustrated above) ... but you need to know some details how to do so
:)) (you can impress them now...)

The easiest way to let a function reconstruct the model outputs is using
emmeans()
e.g.
emmeans(model1, ~Site) should give the marginal estimates of the - site
main effect - (site 1 and site 2 means) on the log scale
and
emmeans(model1, ~Site, type = "response") will give the estimates on the
actual response (probability) scale. I find this often very helpful (also
for plotting).



Am So., 9. Juni 2019 um 16:57 Uhr schrieb Ren? <bimonosom at gmail.com>:

> Hi,
>
> I don't know if this adds anything new but the most direct answers that
> come into my mind would be.
> 1) It seems you use dummy coding, and this defines the interpretation of
> the estimated coefficients, which would be different from (often preferred
> because more easy to interpret)  effect / or contrast coding (dummy coding
> has some 'fitting' advantages which are mainly discussed with respected to
> centered vs. non-centered likelihood (or least-square-mean) estimation
> processes, which might be insightful for you to look up in the internet);
> but any coding design you use will eventually simply try to estimate
> cell-means (in your case on a log scale), and you need to check how to get
> these cell means out of your coefficients (via back-transformation). One
> way of doing this is by using marginal predictions, as Daniel points out.
>
> 2) For another (technical) illustration: a test-design matrix as yours
> with (e.g.) 2 feeding sites and 2 years, then it would be a 2(site 1 vs.
> site 2) by 2(year 1 vs year 2) independent measures design; or 2 x 2 for
> short, which could be simply expressed by 4 probabilities or by using means
> on a log scale, one mean for each of the design-cells, which would be the
> "centered" variant of estimation; but usually dummy coding implies a
> non-centered (but mathematically equivalent  - standard) coding:
> If the model is:
> y = site+year (ignoring random effects now), then
> cellmean(site1:year1) = Model_Intercept
> cellmean(site1:year2) = Model_Intercept + year2
> cellmean(site2:year1) = Model_Intercept + site2
> cellmean(site2:year2) = Model_Intercept + site2 + year2
>
> mean(site1) = (2*Model_intercept + year2)/2
> mean(site2) = ( 2(Model_intercept + site2)+year2))/2
> and so on...
> (Where intercept in most estimation methods is by default is defined in
> reference to the first level of the first predictor in the equation; thus
> site1 (+year1, which is 0 in this type of coding); but the reference point
> can be changed manually)
>
> If the model is:
> y=site+year+site:year, then
> cellmean(site1:year1) = Model_Intercept
> cellmean(site1:year2) = Model_Intercept + year2
> cellmean(site2:year1) = Model_Intercept + site2
> cellmean(site2:year2) = Model_Intercept+site2+ year2 +   site2:year2
>
> Where only the fourth equation changes, which nontheless can have a huge
> impact on the estimation of the other parameters
>
> (usually R outputs the reference levels for the intercept and the
> coefficients, which you can easily identify)
> In case there are more sites than two... e.g.. 4 of them, then:
> cellmean(site1:year1) = Model_Intercept
> cellmean(site2:year1) = Model_Intercept + site2
> cellmean(site3:year1) = Model_Intercept + site3
> cellmean(site4:year1) = Model_Intercept + site4
>
> You might get the gist :)
>
> Finally, if you actually want to test for an overall interaction in this
> way (or main effects), looking at these coefficients is not meaningful,
> which you can tell by just looking at the formulas above...,  So you might
> want to do it differently (correctly), namely by using likelihood ratio
> tests:
> (in R like coding)
>
> Model1<- y=site+year+site:year
> vs
> Model2<- y=site+year
>
> with
> anova(Model1,Model2)  (I think aov() should work as well)
> If the interaction of both variables is significant (i.e. the anova()
> output gives a * for the comparison between Model 1 and Model 2... :)))
> then the interaction effect explains some 'significant' amount of variance.
> (If there is no *, you can consider the models as equal in terms of
> explained variance). Same for other effects (e.g. full model vs. model a
> specific main effect).
> Maybe Check whether the "afex::mixed" function which does this for you in
> a sensible way (there are different ways of doing LRT tests...)
> ;))
>
> Having done this in the first place, is often viewed as prerequisite for
> 'digging' into the model estimates (as discussed above) to find out, what
> significant then actually means in terms of 'mean-changes' :)
>
> Hope this helps,
> Best, Ren?
>
>
>
> Am So., 9. Juni 2019 um 12:45 Uhr schrieb <d.luedecke at uke.de>:
>
>> Dear Patricia,
>>
>> when you include an interaction, your assumption is that the relationship
>> between an independent X1 and the dependent variable Y varies *depending on
>> the values of another independent variable X2*. Indeed, for logistic
>> regression models (as well as for many models with non-Gaussian families),
>> the interpretation of interaction terms can be tricky. In such cases, I
>> would recommend to compute (at least additionally) marginal effects, which
>> give you an intuitive output of your results.
>>
>> You can do so e.g. with the "ggeffects" package (
>> https://strengejacke.github.io/ggeffects/), and there is also an example
>> for a logistic mixed effects model (
>> https://strengejacke.github.io/ggeffects/articles/practical_logisticmixedmodel.html),
>> which might help you.
>>
>> In your case, the code would be
>> ggpredict(M1, c("feed", "year")) for the model with interaction. If you
>> want to plot the results, simply call
>> me <- ggpredict(M1, c("feed", "year"))
>> plot(me)
>>
>> A comment on your model: I'm not sure, but if you compare subjects (or
>> feeding sites) at two time points, you might want to model the
>> auto-correlation of subjects / feeding site ("repeated measure") using your
>> time variable as random slope:
>>
>> M1 <- glmer((bear_pres ~  feed * year + (1 + year | Feeding.site), family
>> = binomial, data = df10)
>>
>> Computing marginal effects than would be the same function call:
>> ggpredict(M1, c("feed", "year"))
>>
>>
>> Best
>> Daniel
>>
>>
>> -----Urspr?ngliche Nachricht-----
>> Von: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> Im
>> Auftrag von Patricia Graf
>> Gesendet: Sonntag, 9. Juni 2019 09:17
>> An: r-sig-mixed-models at r-project.org
>> Betreff: [R-sig-ME] Mixed model interpretation with interaction
>>
>> Hello,
>>
>>
>>
>> I have a few questions concering the interpretation of a GLMM output table
>> when the model includes an interaction.
>>
>> We want to analyse bear presence at feeding sites (bear_pres) related to
>> the year (two years: 2016, 2017) and the feed supplied at feeding sites
>> (carrion, maize). So the response is binary (0 = no bear present, 1 = bear
>> present within 5-min intervals over the whole day) and both predictors are
>> categorical, we include feeding site ID as random factor.
>>
>>
>>
>> The model includes some other variables too but for simplicity I just use
>> those two variables for explanation.
>>
>>
>>
>> 1) As I understand, in a model without interaction, the interpretation of
>> the results would be as follows:
>>
>>
>>
>> M1 <- glmer((bear_pres ~  feed + year + (1|Feeding.site), family=binomial,
>> data=df10)
>>
>> Fixed effects:
>>
>>            Estimate Std. Error z value Pr(>|z|)
>>
>> (Intercept) -4.58524    0.08529 -53.76   <2e-16 ***the intercept is bear
>> presence at maize sites in 2016
>>
>> feedcarrion    0.39178    0.02139   18.32  <2e-16 ***bear presence at
>> feeding sites in 2017 compared to 2016
>>
>> year2017    0.23027    0.01978   11.64  <2e-16 ***bear presence at carrion
>> feeding sites compared to maize feeding sites
>>
>>
>>
>> Is this interpretation right?
>>
>>
>>
>>
>>
>> 2) To my knowledge, the output changes when you include an interaction:
>>
>>
>>
>> M2<- glmer(bear_pres ~  year*feed + (1|Feeding.site), family=binomial,
>> data=df10)
>>
>> Fixed effects:
>>
>>                   Estimate Std. Error z value Pr(>|z|)
>>
>> (Intercept)       -4.36413    0.10730 -40.67  < 2e-16 ***the intercept is
>> bear presence at maize sites in 2016 (baseline)
>>
>> year2017          -0.18010    0.05119  -3.52 0.000434 ***difference in
>> bear
>> presence in 2017 compared to 2016 for maize
>>
>> feedcarrion          -0.02933    0.05318  -0.55 0.581222    difference in
>> bear presence at carrion sites compared to maize sites in 2016
>>
>> year2017:feedcarrion  0.85275   0.09953    8.57  < 2e-16 ***difference in
>> bear presence at carrion sites 2017 and the sum of ?0+ ?1+ ?2
>>
>>
>>
>> So to my questions: Is this interpretation right? What is the coding of
>> the
>> model so it does produce this output, e.g. why is the year not comparing
>> 2016 to 2017 anymore as in the model without the interaction? Or why
>> doesn?t the model still use the two food types for comparison?
>>
>>
>>
>> As I understand, when you include an intercation between the two binary
>> dummy-coded categorical variables, the interpretation of what was main
>> effects before (year, carrion) changes, and so do the betas (these are
>> called ?simple effects? afterwards).
>>
>>
>>
>> In my group, there is a strong believe that in M2, the year still compares
>> the two years (and so does feed), it?s just the coefficient cannot be
>> interpreted anymore. Also, there is a believe that the interaction term
>> compares to feedmaize in the year 2016.
>>
>>
>>
>> If my interpreation is correct, I need some background on how the
>> algorithm
>> works, how simple effects evolve and why the interaction should be
>> interpreted as in the output table of M2.
>>
>>
>>
>> Thank you for your help in advance!
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>> --
>>
>> _____________________________________________________________________
>>
>> Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen
>> Rechts; Gerichtsstand: Hamburg | www.uke.de
>> Vorstandsmitglieder: Prof. Dr. Burkhard G?ke (Vorsitzender), Prof. Dr.
>> Dr. Uwe Koch-Gromus, Joachim Pr?l?, Marya Verdel
>> _____________________________________________________________________
>>
>> SAVE PAPER - THINK BEFORE PRINTING
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>

	[[alternative HTML version deleted]]


From juho@kr|@t|@n@ruohonen @end|ng |rom gm@||@com  Sun Jun  9 18:48:38 2019
From: juho@kr|@t|@n@ruohonen @end|ng |rom gm@||@com (Juho Kristian Ruohonen)
Date: Sun, 9 Jun 2019 19:48:38 +0300
Subject: [R-sig-ME] (lme4) Calculating variance component and random-effect
 shrinkage in a logistic random-intercept model
Message-ID: <CAG_dBVdOrLkmRm9aeFtg+F4Cx3FCZgqaq+8Vq_CjqUJr0adZEw@mail.gmail.com>

Hi,

I'm working with a simple, pedagogical dataset, trying to teach myself how
the random-effect SD is estimated and how the individual random effects are
shrunk towards zero.

The dataset is based on Agresti 2018 (*Introduction to Categorical Data
Analysis, 3rd ed*. pp. 278-281), but I've modified it to get rid of all 0%
and 100% proportions, since those would yield infinite logits and
complicate the calculus. There are just 20 binomial observations,
representing clusters with sample sizes varying from 5 to 20. And there are
only two parameters: a fixed intercept and a random intercept:



*set.seed(2019)d <- data.frame(id = letters[1:20], TrueLogit = rnorm(20), y
= NA, n = round(runif(20, min = 5, max = 20)))*
*d$y <- round(plogis(d$TrueLogit) * d$n) *#Create cluster-specific success
counts based on the "true" logits

Each cluster's sample proportion (on the logit scale) should be helpful in
estimating its random intercept:
*d$EmpiricalLogit <- qlogis(d$y / d$n) *

The fixed intercept should likewise be easy to calculate -- it is the
overall sample proportion on the logit scale, no? i.e:
*d$CommonLogit <- qlogis(sum(d$y) / sum(d$n)) *

The empirical, unshrunken "random effects" should be easy to calculate as
differences between the overall sample proportion and the cluster-specific
ones, all on the logit scale:
*d$Difference <- d$EmpiricalLogit - d$CommonLogit*

The empirical SD of the (as yet) unshrunken random effects should be easy
to calculate as the SD of the cluster-specific differences from the common
intercept, each weighted by the cluster size:
*sd(rep(d$Difference, times = d$n)) *#1.028238

This SD equals 1.03 logits. However, lme4 estimates it at only 0.77:
*require(lme4)*
*(mix <- glmer(y/n ~ (1|id) , weights = n, family = binomial, data = d))*

I thought shrinkage was only applied to the individual random effects, not
to their estimated variance. But the output of lme4 suggests that even the
estimated variance undergoes some shrinkage. How?

Secondly, Agresti (2018: 279), whose examples indeed use lme4, states that
in an example like ours, the fitted value of each cluster is "a weighted
average of the sample proportion for that area (cluster) alone and the
sample proportion after pooling all n (20) samples." (parentheticals mine).
If this is so, then at least the fitted probabilities should be easy to
calculate manually by using the aforementioned weighted-average approach:



*(d$fitted.manual <- sapply(1:nrow(d), function(i){  weighted.mean(c(d$y[i]
/ d$n[i], sum(d$y) / sum(d$n)), w = c(d$n[i], sum(d$n)))  }))*

Yet this misses the mark as well. The manually fitted values are way more
shrunken than the lme4-fitted values:


*d$fitted.lme4 <- fitted(mix)cbind(ManualFitted = d$fitted.manual,
SampleProp = d$y/d$n, lme4Fitted = d$fitted.lme4)*

Trying to calculate the random effects manually, as weighted averages
between 0 and the cluster-specific Difference from the fixed intercept,
fails equally. The manual calculation results in much more shrinkage than
that seen in the output of *ranef() *(not shown).

So, even though the principle behind the calculation of the variance
component and the individual intercepts in a GLMM sounds straightforward, I
cannot replicate even one step of the procedure, not even with a maximally
simple example dataset. This is demoralizing to someone who is trying to
gain a solid understanding of the method. Any pointers?

Best,

Juho

	[[alternative HTML version deleted]]


From tg369 @end|ng |rom c@m@@c@uk  Sun Jun  9 00:32:10 2019
From: tg369 @end|ng |rom c@m@@c@uk (Tanay Ghosh)
Date: Sat, 08 Jun 2019 23:32:10 +0100
Subject: [R-sig-ME] lme4 installation issue
Message-ID: <3b861ebc37d55b809dd99f76d8a74f05@cam.ac.uk>

Dear All,

I am using R version 3.5.1 in my Mac (macOS Mojave version 10.14.4).

However, I am unable to install "lme4" package.

I obtained the following:

> install.packages("lme4")
Installing package into ?/Users/tanayghosh/Library/R/3.5/library?
(as ?lib? is unspecified)
Warning: unable to access index for repository 
https://mirrors.ebi.ac.uk/CRAN/src/contrib:
   cannot open URL 'https://mirrors.ebi.ac.uk/CRAN/src/contrib/PACKAGES'
Warning: unable to access index for repository 
https://mirrors.ebi.ac.uk/CRAN/bin/macosx/el-capitan/contrib/3.5:
   cannot open URL 
'https://mirrors.ebi.ac.uk/CRAN/bin/macosx/el-capitan/contrib/3.5/PACKAGES'
Warning message:
package ?lme4? is not available (for R version 3.5.1)


> sessionInfo()
R version 3.5.1 (2018-07-02)
Platform: x86_64-apple-darwin15.6.0 (64-bit)
Running under: macOS  10.14.4

Matrix products: default
BLAS: 
/Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRblas.0.dylib
LAPACK: 
/Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRlapack.dylib

locale:
[1] en_GB.UTF-8/en_GB.UTF-8/en_GB.UTF-8/C/en_GB.UTF-8/en_GB.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] nlme_3.1-140

loaded via a namespace (and not attached):
[1] compiler_3.5.1  tools_3.5.1     grid_3.5.1      lattice_0.20-35



I am very much looking forward to your help.

Sincerely,

Tanay Ghosh

-- 
Dr. Tanay Ghosh, PhD
Research Associate
Department of Clinical Neurosciences,
Wellcome Trust-Medical Research Council Cambridge Stem Cell Institute,
Clifford Allbutt Building,
Cambridge Biomedical Campus,
University of Cambridge,
Cambridge CB2 0AH


From emm@nue|@cur|@ @end|ng |rom p@r|@de@c@rte@@|r  Sun Jun  9 19:59:58 2019
From: emm@nue|@cur|@ @end|ng |rom p@r|@de@c@rte@@|r (Emmanuel Curis)
Date: Sun, 9 Jun 2019 19:59:58 +0200
Subject: [R-sig-ME] Mixed model interpretation with interaction
In-Reply-To: <CADcpBHOa0eLj8z3rdvaF9m5Pewj13Ztde=VV--wuZYjUTe40Dg@mail.gmail.com>
References: <CAPgMhDas57jLgRQg+n7d11ycDn_OXBGxUX7woaD4M4SvbhRzqQ@mail.gmail.com>
 <001801d51eb0$6d30f4e0$4792dea0$@uke.de>
 <CADcpBHOa0eLj8z3rdvaF9m5Pewj13Ztde=VV--wuZYjUTe40Dg@mail.gmail.com>
Message-ID: <20190609175958.GA18554@info124.pharmacie.univ-paris5.fr>

A small comment on a specific point of the detailed explaination given
by Ren?. Reflecting my understanding, so comments on these are
wellcome especially if I'm wrong.

On Sun, Jun 09, 2019 at 04:57:06PM +0200, Ren? wrote:
? 2) For another (technical) illustration: a test-design matrix as yours with
? (e.g.) 2 feeding sites and 2 years, then it would be a 2(site 1 vs. site 2)
? by 2(year 1 vs year 2) independent measures design; or 2 x 2 for short,
? which could be simply expressed by 4 probabilities or by using means on a
? log scale, one mean for each of the design-cells, which would be the
? "centered" variant of estimation; but usually dummy coding implies a
? non-centered (but mathematically equivalent  - standard) coding:
? If the model is:
? y = site+year (ignoring random effects now), then
? cellmean(site1:year1) = Model_Intercept
? cellmean(site1:year2) = Model_Intercept + year2
? cellmean(site2:year1) = Model_Intercept + site2
? cellmean(site2:year2) = Model_Intercept + site2 + year2
? 
? mean(site1) = (2*Model_intercept + year2)/2
? mean(site2) = ( 2(Model_intercept + site2)+year2))/2
? and so on...

Note that these formula for means of each site assume either that
observed sample sizes are exactly the same for both years (if one
wants to obtain the empirical means) or that the two years are equally
probable in the population (if one wants to obtain estimations of the
theoretical mean ; on this specific context, that may seem a weird way
of saying things, but for other experimental designs it should apply).

That may, or may not, be sensible assumptions depending on the
context. For instance, if the bear population has increased between
the two years, it may be expected that more bears are observed on the
second year, so a weighted average may be more sounded. Or not...

? (Where intercept in most estimation methods is by default is defined in
? reference to the first level of the first predictor in the equation; thus
? site1 (+year1, which is 0 in this type of coding); but the reference point
? can be changed manually)

-- 
                                Emmanuel CURIS
                                emmanuel.curis at parisdescartes.fr

Page WWW: http://emmanuel.curis.online.fr/index.html


From d@iuedecke m@iii@g oii uke@de  Sun Jun  9 20:26:53 2019
From: d@iuedecke m@iii@g oii uke@de (d@iuedecke m@iii@g oii uke@de)
Date: Sun, 9 Jun 2019 20:26:53 +0200
Subject: [R-sig-ME] Mixed model interpretation with interaction
In-Reply-To: <CADcpBHO4PVEqztA2PuZ2YJ9dHNdgDfz9TjPrXkYUXUB56Gtp-w@mail.gmail.com>
References: <CAPgMhDas57jLgRQg+n7d11ycDn_OXBGxUX7woaD4M4SvbhRzqQ@mail.gmail.com>
 <001801d51eb0$6d30f4e0$4792dea0$@uke.de>
 <CADcpBHOa0eLj8z3rdvaF9m5Pewj13Ztde=VV--wuZYjUTe40Dg@mail.gmail.com>
 <CADcpBHO4PVEqztA2PuZ2YJ9dHNdgDfz9TjPrXkYUXUB56Gtp-w@mail.gmail.com>
Message-ID: <000601d51ef0$ea1e3450$be5a9cf0$@uke.de>

If you have multiple (repeated) measurements from both bears and feeding site, you may even have a nested or cross classified design. In such case, bears might be nested within feeding sites, and both bear and feeding site might be modelled as random intercept. Here?s a very short gist showing the difference between nested and cross classified design and how to write this in lme4-notation:

 

http://htmlpreview.github.io/?https://github.com/strengejacke/mixed-models-snippets/blob/master/nested_fully-crossed_cross-classified_models.html

 

Best

Daniel

 

Von: Ren? <bimonosom at gmail.com> 
Gesendet: Sonntag, 9. Juni 2019 17:29
An: d.luedecke at uke.de
Cc: Patricia Graf <patricia.graf03 at gmail.com>; r-sig-mixed-models <r-sig-mixed-models at r-project.org>
Betreff: Re: [R-sig-ME] Mixed model interpretation with interaction

 

Ps:

 

I also agree with Daniel to take care of repeated measurements of the same bears coming to the sites in both years.

However, the main problem I guess, will be that not every bear comes back in the second year. This means, having random slopes for bears that were observed only once, will bias the effect estimate (i.e. the random slopes for year will not be separable from the fixed effect of year). 

A solution to this, however would be, to use an extra variable (lets call it 'repeat') that codes, whether a bear has there in both years (=1) or not (=0; numeric coding - not factored). Then you the following should work:

 

model<-(y~site*year+(0+repeat*year| bearID))

Which will estimate random slopes for year for all bears that were there at least twice, but not for others, where the term before the | becomes 0 (and nothing happens)).

 

Best, Ren?

 

Pps: You can tell your colleagues that:

the Model-intercept is the only direct mean that the model estimates directly (i.e. the reference cell) and all other deviations (including other means) are linear combinations from that intercept (for any factor) ...  And ... of course, the parameters still can be interpreted this way (as illustrated above) ... but you need to know some details how to do so :)) (you can impress them now...)

 

The easiest way to let a function reconstruct the model outputs is using emmeans()

e.g.

emmeans(model1, ~Site) should give the marginal estimates of the - site main effect - (site 1 and site 2 means) on the log scale

and

emmeans(model1, ~Site, type = "response") will give the estimates on the actual response (probability) scale. I find this often very helpful (also for plotting).

 

 

 

Am So., 9. Juni 2019 um 16:57 Uhr schrieb Ren? <bimonosom at gmail.com <mailto:bimonosom at gmail.com> >:

Hi,

 

I don't know if this adds anything new but the most direct answers that come into my mind would be.

1) It seems you use dummy coding, and this defines the interpretation of the estimated coefficients, which would be different from (often preferred because more easy to interpret)  effect / or contrast coding (dummy coding has some 'fitting' advantages which are mainly discussed with respected to centered vs. non-centered likelihood (or least-square-mean) estimation processes, which might be insightful for you to look up in the internet); but any coding design you use will eventually simply try to estimate cell-means (in your case on a log scale), and you need to check how to get these cell means out of your coefficients (via back-transformation). One way of doing this is by using marginal predictions, as Daniel points out.

 

2) For another (technical) illustration: a test-design matrix as yours with (e.g.) 2 feeding sites and 2 years, then it would be a 2(site 1 vs. site 2) by 2(year 1 vs year 2) independent measures design; or 2 x 2 for short, which could be simply expressed by 4 probabilities or by using means on a log scale, one mean for each of the design-cells, which would be the "centered" variant of estimation; but usually dummy coding implies a non-centered (but mathematically equivalent  - standard) coding: 

If the model is:  

y = site+year (ignoring random effects now), then

cellmean(site1:year1) = Model_Intercept

cellmean(site1:year2) = Model_Intercept + year2

cellmean(site2:year1) = Model_Intercept + site2

cellmean(site2:year2) = Model_Intercept + site2 + year2

 

mean(site1) = (2*Model_intercept + year2)/2

mean(site2) = ( 2(Model_intercept + site2)+year2))/2

and so on...

(Where intercept in most estimation methods is by default is defined in reference to the first level of the first predictor in the equation; thus site1 (+year1, which is 0 in this type of coding); but the reference point can be changed manually)

 

If the model is:

y=site+year+site:year, then

cellmean(site1:year1) = Model_Intercept

cellmean(site1:year2) = Model_Intercept + year2

cellmean(site2:year1) = Model_Intercept + site2

cellmean(site2:year2) = Model_Intercept+site2+ year2 +   site2:year2

 

Where only the fourth equation changes, which nontheless can have a huge impact on the estimation of the other parameters

 

(usually R outputs the reference levels for the intercept and the coefficients, which you can easily identify)

In case there are more sites than two... e.g.. 4 of them, then:

cellmean(site1:year1) = Model_Intercept

cellmean(site2:year1) = Model_Intercept + site2

cellmean(site3:year1) = Model_Intercept + site3

cellmean(site4:year1) = Model_Intercept + site4

 

You might get the gist :)

 

Finally, if you actually want to test for an overall interaction in this way (or main effects), looking at these coefficients is not meaningful, which you can tell by just looking at the formulas above...,  So you might want to do it differently (correctly), namely by using likelihood ratio tests:

(in R like coding)

 

Model1<- y=site+year+site:year

vs

Model2<- y=site+year

 

with 

anova(Model1,Model2)  (I think aov() should work as well)

If the interaction of both variables is significant (i.e. the anova() output gives a * for the comparison between Model 1 and Model 2... :))) then the interaction effect explains some 'significant' amount of variance. (If there is no *, you can consider the models as equal in terms of explained variance). Same for other effects (e.g. full model vs. model a specific main effect). 

Maybe Check whether the "afex::mixed" function which does this for you in a sensible way (there are different ways of doing LRT tests...)  

;))

 

Having done this in the first place, is often viewed as prerequisite for 'digging' into the model estimates (as discussed above) to find out, what significant then actually means in terms of 'mean-changes' :)

 

Hope this helps,

Best, Ren?

 

 

 

Am So., 9. Juni 2019 um 12:45 Uhr schrieb <d.luedecke at uke.de <mailto:d.luedecke at uke.de> >:

Dear Patricia,

when you include an interaction, your assumption is that the relationship between an independent X1 and the dependent variable Y varies *depending on the values of another independent variable X2*. Indeed, for logistic regression models (as well as for many models with non-Gaussian families), the interpretation of interaction terms can be tricky. In such cases, I would recommend to compute (at least additionally) marginal effects, which give you an intuitive output of your results.

You can do so e.g. with the "ggeffects" package (https://strengejacke.github.io/ggeffects/), and there is also an example for a logistic mixed effects model (https://strengejacke.github.io/ggeffects/articles/practical_logisticmixedmodel.html), which might help you.

In your case, the code would be
ggpredict(M1, c("feed", "year")) for the model with interaction. If you want to plot the results, simply call
me <- ggpredict(M1, c("feed", "year"))
plot(me)

A comment on your model: I'm not sure, but if you compare subjects (or feeding sites) at two time points, you might want to model the auto-correlation of subjects / feeding site ("repeated measure") using your time variable as random slope:

M1 <- glmer((bear_pres ~  feed * year + (1 + year | Feeding.site), family = binomial, data = df10)

Computing marginal effects than would be the same function call:
ggpredict(M1, c("feed", "year"))


Best
Daniel


-----Urspr?ngliche Nachricht-----
Von: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org <mailto:r-sig-mixed-models-bounces at r-project.org> > Im Auftrag von Patricia Graf
Gesendet: Sonntag, 9. Juni 2019 09:17
An: r-sig-mixed-models at r-project.org <mailto:r-sig-mixed-models at r-project.org> 
Betreff: [R-sig-ME] Mixed model interpretation with interaction

Hello,



I have a few questions concering the interpretation of a GLMM output table
when the model includes an interaction.

We want to analyse bear presence at feeding sites (bear_pres) related to
the year (two years: 2016, 2017) and the feed supplied at feeding sites
(carrion, maize). So the response is binary (0 = no bear present, 1 = bear
present within 5-min intervals over the whole day) and both predictors are
categorical, we include feeding site ID as random factor.



The model includes some other variables too but for simplicity I just use
those two variables for explanation.



1) As I understand, in a model without interaction, the interpretation of
the results would be as follows:



M1 <- glmer((bear_pres ~  feed + year + (1|Feeding.site), family=binomial,
data=df10)

Fixed effects:

           Estimate Std. Error z value Pr(>|z|)

(Intercept) -4.58524    0.08529 -53.76   <2e-16 ***the intercept is bear
presence at maize sites in 2016

feedcarrion    0.39178    0.02139   18.32  <2e-16 ***bear presence at
feeding sites in 2017 compared to 2016

year2017    0.23027    0.01978   11.64  <2e-16 ***bear presence at carrion
feeding sites compared to maize feeding sites



Is this interpretation right?





2) To my knowledge, the output changes when you include an interaction:



M2<- glmer(bear_pres ~  year*feed + (1|Feeding.site), family=binomial,
data=df10)

Fixed effects:

                  Estimate Std. Error z value Pr(>|z|)

(Intercept)       -4.36413    0.10730 -40.67  < 2e-16 ***the intercept is
bear presence at maize sites in 2016 (baseline)

year2017          -0.18010    0.05119  -3.52 0.000434 ***difference in bear
presence in 2017 compared to 2016 for maize

feedcarrion          -0.02933    0.05318  -0.55 0.581222    difference in
bear presence at carrion sites compared to maize sites in 2016

year2017:feedcarrion  0.85275   0.09953    8.57  < 2e-16 ***difference in
bear presence at carrion sites 2017 and the sum of ?0+ ?1+ ?2



So to my questions: Is this interpretation right? What is the coding of the
model so it does produce this output, e.g. why is the year not comparing
2016 to 2017 anymore as in the model without the interaction? Or why
doesn?t the model still use the two food types for comparison?



As I understand, when you include an intercation between the two binary
dummy-coded categorical variables, the interpretation of what was main
effects before (year, carrion) changes, and so do the betas (these are
called ?simple effects? afterwards).



In my group, there is a strong believe that in M2, the year still compares
the two years (and so does feed), it?s just the coefficient cannot be
interpreted anymore. Also, there is a believe that the interaction term
compares to feedmaize in the year 2016.



If my interpreation is correct, I need some background on how the algorithm
works, how simple effects evolve and why the interaction should be
interpreted as in the output table of M2.



Thank you for your help in advance!

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org <mailto:R-sig-mixed-models at r-project.org>  mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

--

_____________________________________________________________________

Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen Rechts; Gerichtsstand: Hamburg | www.uke.de <http://www.uke.de> 
Vorstandsmitglieder: Prof. Dr. Burkhard G?ke (Vorsitzender), Prof. Dr. Dr. Uwe Koch-Gromus, Joachim Pr?l?, Marya Verdel
_____________________________________________________________________

SAVE PAPER - THINK BEFORE PRINTING
_______________________________________________
R-sig-mixed-models at r-project.org <mailto:R-sig-mixed-models at r-project.org>  mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

--

_____________________________________________________________________

Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen Rechts; Gerichtsstand: Hamburg | www.uke.de
Vorstandsmitglieder: Prof. Dr. Burkhard G?ke (Vorsitzender), Prof. Dr. Dr. Uwe Koch-Gromus, Joachim Pr?l?, Marya Verdel
_____________________________________________________________________

SAVE PAPER - THINK BEFORE PRINTING

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Sun Jun  9 23:56:48 2019
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Sun, 9 Jun 2019 17:56:48 -0400
Subject: [R-sig-ME] 
 (lme4) Calculating variance component and random-effect
 shrinkage in a logistic random-intercept model
In-Reply-To: <CAG_dBVdOrLkmRm9aeFtg+F4Cx3FCZgqaq+8Vq_CjqUJr0adZEw@mail.gmail.com>
References: <CAG_dBVdOrLkmRm9aeFtg+F4Cx3FCZgqaq+8Vq_CjqUJr0adZEw@mail.gmail.com>
Message-ID: <c785bd47-69f5-0fc0-4eba-73fbb6fc841c@gmail.com>


 Without going into detail at all: one important point is that
logit-transforming responses is not at all the way that GL(M)M works;
instead, it calculates the expected values on the logit scale,
transforms them to the response scale, and does calculations with
weights based on the variances computed from the variance function for
the specified family.

  If you're willing to take a step backward, it might be (much) easier
to understand the basics of shrinkage and SD estimation using a *linear*
mixed model example ...

  Ben Bolker

On 2019-06-09 12:48 p.m., Juho Kristian Ruohonen wrote:
> Hi,
> 
> I'm working with a simple, pedagogical dataset, trying to teach myself how
> the random-effect SD is estimated and how the individual random effects are
> shrunk towards zero.
> 
> The dataset is based on Agresti 2018 (*Introduction to Categorical Data
> Analysis, 3rd ed*. pp. 278-281), but I've modified it to get rid of all 0%
> and 100% proportions, since those would yield infinite logits and
> complicate the calculus. There are just 20 binomial observations,
> representing clusters with sample sizes varying from 5 to 20. And there are
> only two parameters: a fixed intercept and a random intercept:
> 
> 
> 
> *set.seed(2019)d <- data.frame(id = letters[1:20], TrueLogit = rnorm(20), y
> = NA, n = round(runif(20, min = 5, max = 20)))*
> *d$y <- round(plogis(d$TrueLogit) * d$n) *#Create cluster-specific success
> counts based on the "true" logits
> 
> Each cluster's sample proportion (on the logit scale) should be helpful in
> estimating its random intercept:
> *d$EmpiricalLogit <- qlogis(d$y / d$n) *
> 
> The fixed intercept should likewise be easy to calculate -- it is the
> overall sample proportion on the logit scale, no? i.e:
> *d$CommonLogit <- qlogis(sum(d$y) / sum(d$n)) *
> 
> The empirical, unshrunken "random effects" should be easy to calculate as
> differences between the overall sample proportion and the cluster-specific
> ones, all on the logit scale:
> *d$Difference <- d$EmpiricalLogit - d$CommonLogit*
> 
> The empirical SD of the (as yet) unshrunken random effects should be easy
> to calculate as the SD of the cluster-specific differences from the common
> intercept, each weighted by the cluster size:
> *sd(rep(d$Difference, times = d$n)) *#1.028238
> 
> This SD equals 1.03 logits. However, lme4 estimates it at only 0.77:
> *require(lme4)*
> *(mix <- glmer(y/n ~ (1|id) , weights = n, family = binomial, data = d))*
> 
> I thought shrinkage was only applied to the individual random effects, not
> to their estimated variance. But the output of lme4 suggests that even the
> estimated variance undergoes some shrinkage. How?
> 
> Secondly, Agresti (2018: 279), whose examples indeed use lme4, states that
> in an example like ours, the fitted value of each cluster is "a weighted
> average of the sample proportion for that area (cluster) alone and the
> sample proportion after pooling all n (20) samples." (parentheticals mine).
> If this is so, then at least the fitted probabilities should be easy to
> calculate manually by using the aforementioned weighted-average approach:
> 
> 
> 
> *(d$fitted.manual <- sapply(1:nrow(d), function(i){  weighted.mean(c(d$y[i]
> / d$n[i], sum(d$y) / sum(d$n)), w = c(d$n[i], sum(d$n)))  }))*
> 
> Yet this misses the mark as well. The manually fitted values are way more
> shrunken than the lme4-fitted values:
> 
> 
> *d$fitted.lme4 <- fitted(mix)cbind(ManualFitted = d$fitted.manual,
> SampleProp = d$y/d$n, lme4Fitted = d$fitted.lme4)*
> 
> Trying to calculate the random effects manually, as weighted averages
> between 0 and the cluster-specific Difference from the fixed intercept,
> fails equally. The manual calculation results in much more shrinkage than
> that seen in the output of *ranef() *(not shown).
> 
> So, even though the principle behind the calculation of the variance
> component and the individual intercepts in a GLMM sounds straightforward, I
> cannot replicate even one step of the procedure, not even with a maximally
> simple example dataset. This is demoralizing to someone who is trying to
> gain a solid understanding of the method. Any pointers?
> 
> Best,
> 
> Juho
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From b|mono@om @end|ng |rom gm@||@com  Mon Jun 10 10:17:19 2019
From: b|mono@om @end|ng |rom gm@||@com (=?UTF-8?B?UmVuw6k=?=)
Date: Mon, 10 Jun 2019 10:17:19 +0200
Subject: [R-sig-ME] Mixed model interpretation with interaction
In-Reply-To: <000601d51ef0$ea1e3450$be5a9cf0$@uke.de>
References: <CAPgMhDas57jLgRQg+n7d11ycDn_OXBGxUX7woaD4M4SvbhRzqQ@mail.gmail.com>
 <001801d51eb0$6d30f4e0$4792dea0$@uke.de>
 <CADcpBHOa0eLj8z3rdvaF9m5Pewj13Ztde=VV--wuZYjUTe40Dg@mail.gmail.com>
 <CADcpBHO4PVEqztA2PuZ2YJ9dHNdgDfz9TjPrXkYUXUB56Gtp-w@mail.gmail.com>
 <000601d51ef0$ea1e3450$be5a9cf0$@uke.de>
Message-ID: <CADcpBHMuCWZYz1SXJRgvCodVpZQzP=_RLG0w5uPqpKRfoiJYrA@mail.gmail.com>

@Emmanuel
Good point, and just to add some clarity from my side: these mean formulas
are, indeed, not a descriptive statistic, but estimated marginal means,
which reflect the assumption that there is a "true" population mean
regardless of the number of observations in the design cells (if they are
not weighted within the model, which might be worth thinking about in terms
of related problems of variance assumptions in likelihood ratio testing;
see internet discussions about type 1 vs. type 3 LRT's with unbalanced
sample sizes).

Am So., 9. Juni 2019 um 20:26 Uhr schrieb <d.luedecke at uke.de>:

> If you have multiple (repeated) measurements from both bears and feeding
> site, you may even have a nested or cross classified design. In such case,
> bears might be nested within feeding sites, and both bear and feeding site
> might be modelled as random intercept. Here?s a very short gist showing the
> difference between nested and cross classified design and how to write this
> in lme4-notation:
>
>
>
>
> http://htmlpreview.github.io/?https://github.com/strengejacke/mixed-models-snippets/blob/master/nested_fully-crossed_cross-classified_models.html
>
>
>
> Best
>
> Daniel
>
>
>
> *Von:* Ren? <bimonosom at gmail.com>
> *Gesendet:* Sonntag, 9. Juni 2019 17:29
> *An:* d.luedecke at uke.de
> *Cc:* Patricia Graf <patricia.graf03 at gmail.com>; r-sig-mixed-models <
> r-sig-mixed-models at r-project.org>
> *Betreff:* Re: [R-sig-ME] Mixed model interpretation with interaction
>
>
>
> Ps:
>
>
>
> I also agree with Daniel to take care of repeated measurements of the same
> bears coming to the sites in both years.
>
> However, the main problem I guess, will be that not every bear comes back
> in the second year. This means, having random slopes for bears that were
> observed only once, will bias the effect estimate (i.e. the random slopes
> for year will not be separable from the fixed effect of year).
>
> A solution to this, however would be, to use an extra variable (lets call
> it 'repeat') that codes, whether a bear has there in both years (=1) or not
> (=0; numeric coding - not factored). Then you the following should work:
>
>
>
> model<-(y~site*year+(0+repeat*year| bearID))
>
> Which will estimate random slopes for year for all bears that were there
> at least twice, but not for others, where the term before the | becomes 0
> (and nothing happens)).
>
>
>
> Best, Ren?
>
>
>
> Pps: You can tell your colleagues that:
>
> the Model-intercept is the only direct mean that the model estimates
> directly (i.e. the reference cell) and all other deviations (including
> other means) are linear combinations from that intercept (for any factor)
> ...  And ... of course, the parameters still can be interpreted this way
> (as illustrated above) ... but you need to know some details how to do so
> :)) (you can impress them now...)
>
>
>
> The easiest way to let a function reconstruct the model outputs is using
> emmeans()
>
> e.g.
>
> emmeans(model1, ~Site) should give the marginal estimates of the - site
> main effect - (site 1 and site 2 means) on the log scale
>
> and
>
> emmeans(model1, ~Site, type = "response") will give the estimates on the
> actual response (probability) scale. I find this often very helpful (also
> for plotting).
>
>
>
>
>
>
>
> Am So., 9. Juni 2019 um 16:57 Uhr schrieb Ren? <bimonosom at gmail.com>:
>
> Hi,
>
>
>
> I don't know if this adds anything new but the most direct answers that
> come into my mind would be.
>
> 1) It seems you use dummy coding, and this defines the interpretation of
> the estimated coefficients, which would be different from (often preferred
> because more easy to interpret)  effect / or contrast coding (dummy coding
> has some 'fitting' advantages which are mainly discussed with respected to
> centered vs. non-centered likelihood (or least-square-mean) estimation
> processes, which might be insightful for you to look up in the internet);
> but any coding design you use will eventually simply try to estimate
> cell-means (in your case on a log scale), and you need to check how to get
> these cell means out of your coefficients (via back-transformation). One
> way of doing this is by using marginal predictions, as Daniel points out.
>
>
>
> 2) For another (technical) illustration: a test-design matrix as yours
> with (e.g.) 2 feeding sites and 2 years, then it would be a 2(site 1 vs.
> site 2) by 2(year 1 vs year 2) independent measures design; or 2 x 2 for
> short, which could be simply expressed by 4 probabilities or by using means
> on a log scale, one mean for each of the design-cells, which would be the
> "centered" variant of estimation; but usually dummy coding implies a
> non-centered (but mathematically equivalent  - standard) coding:
>
> If the model is:
>
> y = site+year (ignoring random effects now), then
>
> cellmean(site1:year1) = Model_Intercept
>
> cellmean(site1:year2) = Model_Intercept + year2
>
> cellmean(site2:year1) = Model_Intercept + site2
>
> cellmean(site2:year2) = Model_Intercept + site2 + year2
>
>
>
> mean(site1) = (2*Model_intercept + year2)/2
>
> mean(site2) = ( 2(Model_intercept + site2)+year2))/2
>
> and so on...
>
> (Where intercept in most estimation methods is by default is defined in
> reference to the first level of the first predictor in the equation; thus
> site1 (+year1, which is 0 in this type of coding); but the reference point
> can be changed manually)
>
>
>
> If the model is:
>
> y=site+year+site:year, then
>
> cellmean(site1:year1) = Model_Intercept
>
> cellmean(site1:year2) = Model_Intercept + year2
>
> cellmean(site2:year1) = Model_Intercept + site2
>
> cellmean(site2:year2) = Model_Intercept+site2+ year2 +   site2:year2
>
>
>
> Where only the fourth equation changes, which nontheless can have a huge
> impact on the estimation of the other parameters
>
>
>
> (usually R outputs the reference levels for the intercept and the
> coefficients, which you can easily identify)
>
> In case there are more sites than two... e.g.. 4 of them, then:
>
> cellmean(site1:year1) = Model_Intercept
>
> cellmean(site2:year1) = Model_Intercept + site2
>
> cellmean(site3:year1) = Model_Intercept + site3
>
> cellmean(site4:year1) = Model_Intercept + site4
>
>
>
> You might get the gist :)
>
>
>
> Finally, if you actually want to test for an overall interaction in this
> way (or main effects), looking at these coefficients is not meaningful,
> which you can tell by just looking at the formulas above...,  So you might
> want to do it differently (correctly), namely by using likelihood ratio
> tests:
>
> (in R like coding)
>
>
>
> Model1<- y=site+year+site:year
>
> vs
>
> Model2<- y=site+year
>
>
>
> with
>
> anova(Model1,Model2)  (I think aov() should work as well)
>
> If the interaction of both variables is significant (i.e. the anova()
> output gives a * for the comparison between Model 1 and Model 2... :)))
> then the interaction effect explains some 'significant' amount of variance.
> (If there is no *, you can consider the models as equal in terms of
> explained variance). Same for other effects (e.g. full model vs. model a
> specific main effect).
>
> Maybe Check whether the "afex::mixed" function which does this for you in
> a sensible way (there are different ways of doing LRT tests...)
>
> ;))
>
>
>
> Having done this in the first place, is often viewed as prerequisite for
> 'digging' into the model estimates (as discussed above) to find out, what
> significant then actually means in terms of 'mean-changes' :)
>
>
>
> Hope this helps,
>
> Best, Ren?
>
>
>
>
>
>
>
> Am So., 9. Juni 2019 um 12:45 Uhr schrieb <d.luedecke at uke.de>:
>
> Dear Patricia,
>
> when you include an interaction, your assumption is that the relationship
> between an independent X1 and the dependent variable Y varies *depending on
> the values of another independent variable X2*. Indeed, for logistic
> regression models (as well as for many models with non-Gaussian families),
> the interpretation of interaction terms can be tricky. In such cases, I
> would recommend to compute (at least additionally) marginal effects, which
> give you an intuitive output of your results.
>
> You can do so e.g. with the "ggeffects" package (
> https://strengejacke.github.io/ggeffects/), and there is also an example
> for a logistic mixed effects model (
> https://strengejacke.github.io/ggeffects/articles/practical_logisticmixedmodel.html),
> which might help you.
>
> In your case, the code would be
> ggpredict(M1, c("feed", "year")) for the model with interaction. If you
> want to plot the results, simply call
> me <- ggpredict(M1, c("feed", "year"))
> plot(me)
>
> A comment on your model: I'm not sure, but if you compare subjects (or
> feeding sites) at two time points, you might want to model the
> auto-correlation of subjects / feeding site ("repeated measure") using your
> time variable as random slope:
>
> M1 <- glmer((bear_pres ~  feed * year + (1 + year | Feeding.site), family
> = binomial, data = df10)
>
> Computing marginal effects than would be the same function call:
> ggpredict(M1, c("feed", "year"))
>
>
> Best
> Daniel
>
>
> -----Urspr?ngliche Nachricht-----
> Von: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> Im
> Auftrag von Patricia Graf
> Gesendet: Sonntag, 9. Juni 2019 09:17
> An: r-sig-mixed-models at r-project.org
> Betreff: [R-sig-ME] Mixed model interpretation with interaction
>
> Hello,
>
>
>
> I have a few questions concering the interpretation of a GLMM output table
> when the model includes an interaction.
>
> We want to analyse bear presence at feeding sites (bear_pres) related to
> the year (two years: 2016, 2017) and the feed supplied at feeding sites
> (carrion, maize). So the response is binary (0 = no bear present, 1 = bear
> present within 5-min intervals over the whole day) and both predictors are
> categorical, we include feeding site ID as random factor.
>
>
>
> The model includes some other variables too but for simplicity I just use
> those two variables for explanation.
>
>
>
> 1) As I understand, in a model without interaction, the interpretation of
> the results would be as follows:
>
>
>
> M1 <- glmer((bear_pres ~  feed + year + (1|Feeding.site), family=binomial,
> data=df10)
>
> Fixed effects:
>
>            Estimate Std. Error z value Pr(>|z|)
>
> (Intercept) -4.58524    0.08529 -53.76   <2e-16 ***the intercept is bear
> presence at maize sites in 2016
>
> feedcarrion    0.39178    0.02139   18.32  <2e-16 ***bear presence at
> feeding sites in 2017 compared to 2016
>
> year2017    0.23027    0.01978   11.64  <2e-16 ***bear presence at carrion
> feeding sites compared to maize feeding sites
>
>
>
> Is this interpretation right?
>
>
>
>
>
> 2) To my knowledge, the output changes when you include an interaction:
>
>
>
> M2<- glmer(bear_pres ~  year*feed + (1|Feeding.site), family=binomial,
> data=df10)
>
> Fixed effects:
>
>                   Estimate Std. Error z value Pr(>|z|)
>
> (Intercept)       -4.36413    0.10730 -40.67  < 2e-16 ***the intercept is
> bear presence at maize sites in 2016 (baseline)
>
> year2017          -0.18010    0.05119  -3.52 0.000434 ***difference in bear
> presence in 2017 compared to 2016 for maize
>
> feedcarrion          -0.02933    0.05318  -0.55 0.581222    difference in
> bear presence at carrion sites compared to maize sites in 2016
>
> year2017:feedcarrion  0.85275   0.09953    8.57  < 2e-16 ***difference in
> bear presence at carrion sites 2017 and the sum of ?0+ ?1+ ?2
>
>
>
> So to my questions: Is this interpretation right? What is the coding of the
> model so it does produce this output, e.g. why is the year not comparing
> 2016 to 2017 anymore as in the model without the interaction? Or why
> doesn?t the model still use the two food types for comparison?
>
>
>
> As I understand, when you include an intercation between the two binary
> dummy-coded categorical variables, the interpretation of what was main
> effects before (year, carrion) changes, and so do the betas (these are
> called ?simple effects? afterwards).
>
>
>
> In my group, there is a strong believe that in M2, the year still compares
> the two years (and so does feed), it?s just the coefficient cannot be
> interpreted anymore. Also, there is a believe that the interaction term
> compares to feedmaize in the year 2016.
>
>
>
> If my interpreation is correct, I need some background on how the algorithm
> works, how simple effects evolve and why the interaction should be
> interpreted as in the output table of M2.
>
>
>
> Thank you for your help in advance!
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
> --
>
> _____________________________________________________________________
>
> Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen
> Rechts; Gerichtsstand: Hamburg | www.uke.de
> Vorstandsmitglieder: Prof. Dr. Burkhard G?ke (Vorsitzender), Prof. Dr. Dr.
> Uwe Koch-Gromus, Joachim Pr?l?, Marya Verdel
> _____________________________________________________________________
>
> SAVE PAPER - THINK BEFORE PRINTING
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
> ------------------------------
>
> Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen
> Rechts; Gerichtsstand: Hamburg | www.uke.de
> Vorstandsmitglieder: Prof. Dr. Burkhard G?ke (Vorsitzender), Prof. Dr. Dr.
> Uwe Koch-Gromus, Joachim Pr?l?, Marya Verdel
> ------------------------------
>
> SAVE PAPER - THINK BEFORE PRINTING
>

	[[alternative HTML version deleted]]


From tg369 @end|ng |rom c@m@@c@uk  Mon Jun 10 16:31:53 2019
From: tg369 @end|ng |rom c@m@@c@uk (Tanay Ghosh)
Date: Mon, 10 Jun 2019 15:31:53 +0100
Subject: [R-sig-ME] =?utf-8?q?lme4_analysis=5F2ANOVA_repeated_measure?=
Message-ID: <1905bdf79ddfa731ced2688ee1dbf1a2@cam.ac.uk>

Dear All,

I wonder if I can ask your advise to analyse this data (attached). 
Please note that some of the values are "NA" i.e. I do not have any 
measurement taken.

Here I have four different time (days) points. I measured expression of 
Abt3 gene at these time points in male and female.

I want to see if gender wise expression of Atg3 differ at any time 
point?

I further want to do a posttest to get p value for Male at time 7 vs 
female at time 7, Male at time 15 vs Female at time 15, and like wise 
all other time points.


Please could you advise me how to do this analysis using lmer function? 
I would very much appreciate if you please write the commands in R for 
this specific case.

Thank you in advance for your time.


Kind regards,

Tanay


-- 
Dr. Tanay Ghosh, PhD
Research Associate
Department of Clinical Neurosciences,
Wellcome Trust-Medical Research Council Cambridge Stem Cell Institute,
Clifford Allbutt Building,
Cambridge Biomedical Campus,
University of Cambridge,
Cambridge CB2 0AH
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: Ginez_data_Atg3.txt
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20190610/964afcfb/attachment.txt>

From @@m_cr@w|ey @end|ng |rom w@rpm@||@net  Mon Jun 10 10:35:51 2019
From: @@m_cr@w|ey @end|ng |rom w@rpm@||@net (Sam Crawley)
Date: Mon, 10 Jun 2019 20:35:51 +1200
Subject: [R-sig-ME] =?utf-8?q?Predicted_probabilites_with_CIs_for_multile?=
 =?utf-8?q?vel_logistic_regression_with_prior_weights?=
Message-ID: <e4431ad0-e1aa-47f5-a9aa-32556ca1d332@www.fastmail.com>

Hello all,

I am doing a multilevel binomial logistic regression using lme4, and the survey data I am using requires weights to be used. I would like to calculate various predicted probabilities with confidence intervals based on the estimated model. The predict function obviously doesn't give me standard errors, and the recommended method to get these is to use the bootMer function.

However, in my case, the weights provided are not integers, and the bootMer function exits with an error if the weights are not integers (I raised a GitHub issue about this, and was pointed to this list: https://github.com/lme4/lme4/issues/524 ).

So my question is, what is the best way to calculate the predicted probabilities (with confidence intervals) in my case?

I would appreciate any help you can give me, and I'm happy to provide more details if required.

Thanks,
Sam Crawley.


From d@iuedecke m@iii@g oii uke@de  Mon Jun 10 17:30:37 2019
From: d@iuedecke m@iii@g oii uke@de (d@iuedecke m@iii@g oii uke@de)
Date: Mon, 10 Jun 2019 17:30:37 +0200
Subject: [R-sig-ME] 
 Predicted probabilites with CIs for multilevel logistic
 regression with prior weights
In-Reply-To: <e4431ad0-e1aa-47f5-a9aa-32556ca1d332@www.fastmail.com>
References: <e4431ad0-e1aa-47f5-a9aa-32556ca1d332@www.fastmail.com>
Message-ID: <000e01d51fa1$74c85760$5e590620$@uke.de>

Hi Sam,

you could the "ggeffects" package
(https://strengejacke.github.io/ggeffects/), and there is also an example
for a logistic mixed effects model
(https://strengejacke.github.io/ggeffects/articles/practical_logisticmixedmo
del.html), which might help you.

For binomial models, using weights often results in the following warning:
#> non-integer #successes in a binomial glm!

However, CIs for the predicted probabilities can be calculated nevertheless
(at least in my quick example). Note that afaik, mixed models in R do
correctly not account for sampling weights. However, Thomas Lumley, author
of the survey-package, works on a survey-function for mixed models
(https://github.com/tslumley/svylme), probably the GitHub version is quite
stable (haven't tested yet).

An alternative would be the "scale_weights()" function from the
sjstats-package
(https://strengejacke.github.io/sjstats/articles/mixedmodels-statistics.html
#rescale-model-weights-for-complex-samples ), which rescales sampling
weights so they can be used as "weights" for the mixed models function you
have in R (lme4, lme, ...).

Based on that function, I have a small example that demonstrates how to
compute predicted probabilities for mixed models with (sampling) weights
(ignore the warnings, this is just for demonstration purposes):

library(lme4)
library(sjstats) # for scale_weights() and sample data
library(ggeffects) # for ggpredict()

data(nhanes_sample)
set.seed(123)
nhanes_sample$bin <- rbinom(nrow(nhanes_sample), 1, prob = .3)
nhanes_sample <- scale_weights(nhanes_sample, SDMVSTRA, WTINT2YR)

m <- glmer(
  bin ~ factor(RIAGENDR) * age + factor(RIDRETH1) + (1 | SDMVPSU),
  family = binomial(),
  data = nhanes_sample,
  weights = svywght_a
)

ggpredict(m, c("age", "RIAGENDR")) %>% plot()


Best
Daniel

-----Urspr?ngliche Nachricht-----
Von: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> Im
Auftrag von Sam Crawley
Gesendet: Montag, 10. Juni 2019 10:36
An: r-sig-mixed-models at r-project.org
Betreff: [R-sig-ME] Predicted probabilites with CIs for multilevel logistic
regression with prior weights

Hello all,

I am doing a multilevel binomial logistic regression using lme4, and the
survey data I am using requires weights to be used. I would like to
calculate various predicted probabilities with confidence intervals based on
the estimated model. The predict function obviously doesn't give me standard
errors, and the recommended method to get these is to use the bootMer
function.

However, in my case, the weights provided are not integers, and the bootMer
function exits with an error if the weights are not integers (I raised a
GitHub issue about this, and was pointed to this list:
https://github.com/lme4/lme4/issues/524 ).

So my question is, what is the best way to calculate the predicted
probabilities (with confidence intervals) in my case?

I would appreciate any help you can give me, and I'm happy to provide more
details if required.

Thanks,
Sam Crawley.

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

--

_____________________________________________________________________

Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen Rechts; Gerichtsstand: Hamburg | www.uke.de
Vorstandsmitglieder: Prof. Dr. Burkhard G?ke (Vorsitzender), Prof. Dr. Dr. Uwe Koch-Gromus, Joachim Pr?l?, Marya Verdel
_____________________________________________________________________

SAVE PAPER - THINK BEFORE PRINTING


From d@iuedecke m@iii@g oii uke@de  Mon Jun 10 17:33:40 2019
From: d@iuedecke m@iii@g oii uke@de (d@iuedecke m@iii@g oii uke@de)
Date: Mon, 10 Jun 2019 17:33:40 +0200
Subject: [R-sig-ME] 
 Predicted probabilites with CIs for multilevel logistic
 regression with prior weights
In-Reply-To: <000e01d51fa1$74c85760$5e590620$@uke.de>
References: <e4431ad0-e1aa-47f5-a9aa-32556ca1d332@www.fastmail.com>
 <000e01d51fa1$74c85760$5e590620$@uke.de>
Message-ID: <000f01d51fa1$e1bd8f70$a538ae50$@uke.de>

> mixed models in R do correctly not account for sampling weights

Should be: mixed models in R do *currently* not account for sampling weights

-----Urspr?ngliche Nachricht-----
Von: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> Im
Auftrag von d.luedecke at uke.de
Gesendet: Montag, 10. Juni 2019 17:31
An: 'Sam Crawley' <sam_crawley at warpmail.net>;
r-sig-mixed-models at r-project.org
Betreff: Re: [R-sig-ME] Predicted probabilites with CIs for multilevel
logistic regression with prior weights

Hi Sam,

you could the "ggeffects" package
(https://strengejacke.github.io/ggeffects/), and there is also an example
for a logistic mixed effects model
(https://strengejacke.github.io/ggeffects/articles/practical_logisticmixedmo
del.html), which might help you.

For binomial models, using weights often results in the following warning:
#> non-integer #successes in a binomial glm!

However, CIs for the predicted probabilities can be calculated nevertheless
(at least in my quick example). Note that afaik, mixed models in R do
correctly not account for sampling weights. However, Thomas Lumley, author
of the survey-package, works on a survey-function for mixed models
(https://github.com/tslumley/svylme), probably the GitHub version is quite
stable (haven't tested yet).

An alternative would be the "scale_weights()" function from the
sjstats-package
(https://strengejacke.github.io/sjstats/articles/mixedmodels-statistics.html
#rescale-model-weights-for-complex-samples ), which rescales sampling
weights so they can be used as "weights" for the mixed models function you
have in R (lme4, lme, ...).

Based on that function, I have a small example that demonstrates how to
compute predicted probabilities for mixed models with (sampling) weights
(ignore the warnings, this is just for demonstration purposes):

library(lme4)
library(sjstats) # for scale_weights() and sample data
library(ggeffects) # for ggpredict()

data(nhanes_sample)
set.seed(123)
nhanes_sample$bin <- rbinom(nrow(nhanes_sample), 1, prob = .3)
nhanes_sample <- scale_weights(nhanes_sample, SDMVSTRA, WTINT2YR)

m <- glmer(
  bin ~ factor(RIAGENDR) * age + factor(RIDRETH1) + (1 | SDMVPSU),
  family = binomial(),
  data = nhanes_sample,
  weights = svywght_a
)

ggpredict(m, c("age", "RIAGENDR")) %>% plot()


Best
Daniel

-----Urspr?ngliche Nachricht-----
Von: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> Im
Auftrag von Sam Crawley
Gesendet: Montag, 10. Juni 2019 10:36
An: r-sig-mixed-models at r-project.org
Betreff: [R-sig-ME] Predicted probabilites with CIs for multilevel logistic
regression with prior weights

Hello all,

I am doing a multilevel binomial logistic regression using lme4, and the
survey data I am using requires weights to be used. I would like to
calculate various predicted probabilities with confidence intervals based on
the estimated model. The predict function obviously doesn't give me standard
errors, and the recommended method to get these is to use the bootMer
function.

However, in my case, the weights provided are not integers, and the bootMer
function exits with an error if the weights are not integers (I raised a
GitHub issue about this, and was pointed to this list:
https://github.com/lme4/lme4/issues/524 ).

So my question is, what is the best way to calculate the predicted
probabilities (with confidence intervals) in my case?

I would appreciate any help you can give me, and I'm happy to provide more
details if required.

Thanks,
Sam Crawley.

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

--

_____________________________________________________________________

Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen
Rechts; Gerichtsstand: Hamburg | www.uke.de
Vorstandsmitglieder: Prof. Dr. Burkhard G?ke (Vorsitzender), Prof. Dr. Dr.
Uwe Koch-Gromus, Joachim Pr?l?, Marya Verdel
_____________________________________________________________________

SAVE PAPER - THINK BEFORE PRINTING

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

--

_____________________________________________________________________

Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen Rechts; Gerichtsstand: Hamburg | www.uke.de
Vorstandsmitglieder: Prof. Dr. Burkhard G?ke (Vorsitzender), Prof. Dr. Dr. Uwe Koch-Gromus, Joachim Pr?l?, Marya Verdel
_____________________________________________________________________

SAVE PAPER - THINK BEFORE PRINTING


From mo|||eebrook@ @end|ng |rom gm@||@com  Mon Jun 10 19:03:36 2019
From: mo|||eebrook@ @end|ng |rom gm@||@com (Mollie Brooks)
Date: Mon, 10 Jun 2019 19:03:36 +0200
Subject: [R-sig-ME] 
 Predicted probabilites with CIs for multilevel logistic
 regression with prior weights
In-Reply-To: <000f01d51fa1$e1bd8f70$a538ae50$@uke.de>
References: <e4431ad0-e1aa-47f5-a9aa-32556ca1d332@www.fastmail.com>
 <000e01d51fa1$74c85760$5e590620$@uke.de>
 <000f01d51fa1$e1bd8f70$a538ae50$@uke.de>
Message-ID: <609978FF-4C66-4568-BBF4-49F81201832E@gmail.com>



> On 10Jun 2019, at 17:33, <d.luedecke at uke.de> <d.luedecke at uke.de> wrote:
> 
>> mixed models in R do correctly not account for sampling weights
> 
> Should be: mixed models in R do *currently* not account for sampling weights

I?m still trying to get a handle of the different definitions of "weights" but I believe we implemented sampling weights in glmmTMB. We do this by weighting the log-likelihood contribution of each observation. I think this is different from prior weights if you mean Bayesian priors. There has been some discussion of the different implementations of "weights" in different R functions (link below) and we still need to update the documentation for glmmTMB 
https://github.com/glmmTMB/glmmTMB/issues/285

Here?s a binomial example:

library(glmmTMB)
set.seed(123)
n=100
dat=data.frame(trials=rpois(n, lambda=50), rownum=1:n)
dat$success=rbinom(n, dat$trials, prob=.3)
dat$rep=sample(1:5, size=n, replace=TRUE) #each observation is repeated 1 to 5 times
rows=rep(dat$rownum, each=1, times=dat$rep)
dat_disaggregated=dat[rows, ]

summary(glmmTMB(cbind(success, trials-success)~1, weights=rep, dat, family=binomial))
summary(glmmTMB(cbind(success, trials-success)~1, dat_disaggregated, family=binomial))

and it works with non-integer weights

summary(glmmTMB(cbind(success, trials-success)~1, weights=rep/5, dat, family=binomial))

cheers,
Mollie

> 
> -----Urspr?ngliche Nachricht-----
> Von: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> Im
> Auftrag von d.luedecke at uke.de
> Gesendet: Montag, 10. Juni 2019 17:31
> An: 'Sam Crawley' <sam_crawley at warpmail.net>;
> r-sig-mixed-models at r-project.org
> Betreff: Re: [R-sig-ME] Predicted probabilites with CIs for multilevel
> logistic regression with prior weights
> 
> Hi Sam,
> 
> you could the "ggeffects" package
> (https://strengejacke.github.io/ggeffects/), and there is also an example
> for a logistic mixed effects model
> (https://strengejacke.github.io/ggeffects/articles/practical_logisticmixedmo
> del.html), which might help you.
> 
> For binomial models, using weights often results in the following warning:
> #> non-integer #successes in a binomial glm!
> 
> However, CIs for the predicted probabilities can be calculated nevertheless
> (at least in my quick example). Note that afaik, mixed models in R do
> correctly not account for sampling weights. However, Thomas Lumley, author
> of the survey-package, works on a survey-function for mixed models
> (https://github.com/tslumley/svylme), probably the GitHub version is quite
> stable (haven't tested yet).
> 
> An alternative would be the "scale_weights()" function from the
> sjstats-package
> (https://strengejacke.github.io/sjstats/articles/mixedmodels-statistics.html
> #rescale-model-weights-for-complex-samples ), which rescales sampling
> weights so they can be used as "weights" for the mixed models function you
> have in R (lme4, lme, ...).
> 
> Based on that function, I have a small example that demonstrates how to
> compute predicted probabilities for mixed models with (sampling) weights
> (ignore the warnings, this is just for demonstration purposes):
> 
> library(lme4)
> library(sjstats) # for scale_weights() and sample data
> library(ggeffects) # for ggpredict()
> 
> data(nhanes_sample)
> set.seed(123)
> nhanes_sample$bin <- rbinom(nrow(nhanes_sample), 1, prob = .3)
> nhanes_sample <- scale_weights(nhanes_sample, SDMVSTRA, WTINT2YR)
> 
> m <- glmer(
>  bin ~ factor(RIAGENDR) * age + factor(RIDRETH1) + (1 | SDMVPSU),
>  family = binomial(),
>  data = nhanes_sample,
>  weights = svywght_a
> )
> 
> ggpredict(m, c("age", "RIAGENDR")) %>% plot()
> 
> 
> Best
> Daniel
> 
> -----Urspr?ngliche Nachricht-----
> Von: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> Im
> Auftrag von Sam Crawley
> Gesendet: Montag, 10. Juni 2019 10:36
> An: r-sig-mixed-models at r-project.org
> Betreff: [R-sig-ME] Predicted probabilites with CIs for multilevel logistic
> regression with prior weights
> 
> Hello all,
> 
> I am doing a multilevel binomial logistic regression using lme4, and the
> survey data I am using requires weights to be used. I would like to
> calculate various predicted probabilities with confidence intervals based on
> the estimated model. The predict function obviously doesn't give me standard
> errors, and the recommended method to get these is to use the bootMer
> function.
> 
> However, in my case, the weights provided are not integers, and the bootMer
> function exits with an error if the weights are not integers (I raised a
> GitHub issue about this, and was pointed to this list:
> https://github.com/lme4/lme4/issues/524 ).
> 
> So my question is, what is the best way to calculate the predicted
> probabilities (with confidence intervals) in my case?
> 
> I would appreciate any help you can give me, and I'm happy to provide more
> details if required.
> 
> Thanks,
> Sam Crawley.
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> --
> 
> _____________________________________________________________________
> 
> Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen
> Rechts; Gerichtsstand: Hamburg | www.uke.de
> Vorstandsmitglieder: Prof. Dr. Burkhard G?ke (Vorsitzender), Prof. Dr. Dr.
> Uwe Koch-Gromus, Joachim Pr?l?, Marya Verdel
> _____________________________________________________________________
> 
> SAVE PAPER - THINK BEFORE PRINTING
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> --
> 
> _____________________________________________________________________
> 
> Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen Rechts; Gerichtsstand: Hamburg | www.uke.de
> Vorstandsmitglieder: Prof. Dr. Burkhard G?ke (Vorsitzender), Prof. Dr. Dr. Uwe Koch-Gromus, Joachim Pr?l?, Marya Verdel
> _____________________________________________________________________
> 
> SAVE PAPER - THINK BEFORE PRINTING
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


	[[alternative HTML version deleted]]


From d@iuedecke m@iii@g oii uke@de  Mon Jun 10 19:40:52 2019
From: d@iuedecke m@iii@g oii uke@de (d@iuedecke m@iii@g oii uke@de)
Date: Mon, 10 Jun 2019 19:40:52 +0200
Subject: [R-sig-ME] 
 Predicted probabilites with CIs for multilevel logistic
 regression with prior weights
In-Reply-To: <609978FF-4C66-4568-BBF4-49F81201832E@gmail.com>
References: <e4431ad0-e1aa-47f5-a9aa-32556ca1d332@www.fastmail.com>
 <000e01d51fa1$74c85760$5e590620$@uke.de>
 <000f01d51fa1$e1bd8f70$a538ae50$@uke.de>
 <609978FF-4C66-4568-BBF4-49F81201832E@gmail.com>
Message-ID: <000001d51fb3$a72f2730$f58d7590$@uke.de>

I think that Sam is talking about ?sampling? or ?survey? weights (as compared to analytical or frequency weights, used by ?normal? regression models).

 

The issue you?re referring to is referenced by another issue (https://github.com/glmmTMB/glmmTMB/issues/440), which in turn shows an example from Cross Validated:

https://stats.stackexchange.com/questions/57107/use-of-weights-in-svyglm-vs-glm

 

If I use that example, and add a third model fitted with glmmTMB, I get following result when comparing the weights from the fitted objects:

 

library(glmmTMB)

glm2 <- glmmTMB(re78 ~ treat, weights = w , data = lalonde)

cbind(glm1$weights, glm11$weights, glm2$frame$`(weights)`)

#>        [,1]     [,2]     [,3]

#> 1 1.4682453 2.108394 2.108394

#> 2 0.9593877 1.377677 1.377677

#> 3 0.7489954 1.075554 1.075554

#> 4 0.7319955 1.051143 1.051143

#> 5 0.7283328 1.045883 1.045883

#> 6 0.7244569 1.040317 1.040317

 

As you can see, ?glm? and ?glmmTMB? produce the same weights, while the survey-package has different weights? I?m not sure that the weights implemented in glmmTMB are actually ?sampling? weights (for surveys, as implemented in the survey package), or how to reproduce such weights using glmmTMB.

 

Von: Mollie Brooks <mollieebrooks at gmail.com> 
Gesendet: Montag, 10. Juni 2019 19:04
An: Sam Crawley <sam_crawley at warpmail.net>; Help Mixed Models <r-sig-mixed-models at r-project.org>
Cc: d.luedecke at uke.de
Betreff: Re: [R-sig-ME] Predicted probabilites with CIs for multilevel logistic regression with prior weights

 

 





On 10Jun 2019, at 17:33, <d.luedecke at uke.de <mailto:d.luedecke at uke.de> > <d.luedecke at uke.de <mailto:d.luedecke at uke.de> > wrote:

 

mixed models in R do correctly not account for sampling weights


Should be: mixed models in R do *currently* not account for sampling weights

 

I?m still trying to get a handle of the different definitions of "weights" but I believe we implemented sampling weights in glmmTMB. We do this by weighting the log-likelihood contribution of each observation. I think this is different from prior weights if you mean Bayesian priors. There has been some discussion of the different implementations of "weights" in different R functions (link below) and we still need to update the documentation for glmmTMB 

https://github.com/glmmTMB/glmmTMB/issues/285

 

Here?s a binomial example:

 

library(glmmTMB)

set.seed(123)

n=100

dat=data.frame(trials=rpois(n, lambda=50), rownum=1:n)

dat$success=rbinom(n, dat$trials, prob=.3)

dat$rep=sample(1:5, size=n, replace=TRUE) #each observation is repeated 1 to 5 times

rows=rep(dat$rownum, each=1, times=dat$rep)

dat_disaggregated=dat[rows, ]





summary(glmmTMB(cbind(success, trials-success)~1, weights=rep, dat, family=binomial))

summary(glmmTMB(cbind(success, trials-success)~1, dat_disaggregated, family=binomial))





and it works with non-integer weights





summary(glmmTMB(cbind(success, trials-success)~1, weights=rep/5, dat, family=binomial))





cheers,

Mollie






-----Urspr?ngliche Nachricht-----
Von: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org <mailto:r-sig-mixed-models-bounces at r-project.org> > Im
Auftrag von d.luedecke at uke.de <mailto:d.luedecke at uke.de> 
Gesendet: Montag, 10. Juni 2019 17:31
An: 'Sam Crawley' <sam_crawley at warpmail.net <mailto:sam_crawley at warpmail.net> >;
r-sig-mixed-models at r-project.org <mailto:r-sig-mixed-models at r-project.org> 
Betreff: Re: [R-sig-ME] Predicted probabilites with CIs for multilevel
logistic regression with prior weights

Hi Sam,

you could the "ggeffects" package
(https://strengejacke.github.io/ggeffects/), and there is also an example
for a logistic mixed effects model
(https://strengejacke.github.io/ggeffects/articles/practical_logisticmixedmo
del.html), which might help you.

For binomial models, using weights often results in the following warning:
#> non-integer #successes in a binomial glm!

However, CIs for the predicted probabilities can be calculated nevertheless
(at least in my quick example). Note that afaik, mixed models in R do
correctly not account for sampling weights. However, Thomas Lumley, author
of the survey-package, works on a survey-function for mixed models
(https://github.com/tslumley/svylme), probably the GitHub version is quite
stable (haven't tested yet).

An alternative would be the "scale_weights()" function from the
sjstats-package
(https://strengejacke.github.io/sjstats/articles/mixedmodels-statistics.html
#rescale-model-weights-for-complex-samples ), which rescales sampling
weights so they can be used as "weights" for the mixed models function you
have in R (lme4, lme, ...).

Based on that function, I have a small example that demonstrates how to
compute predicted probabilities for mixed models with (sampling) weights
(ignore the warnings, this is just for demonstration purposes):

library(lme4)
library(sjstats) # for scale_weights() and sample data
library(ggeffects) # for ggpredict()

data(nhanes_sample)
set.seed(123)
nhanes_sample$bin <- rbinom(nrow(nhanes_sample), 1, prob = .3)
nhanes_sample <- scale_weights(nhanes_sample, SDMVSTRA, WTINT2YR)

m <- glmer(
 bin ~ factor(RIAGENDR) * age + factor(RIDRETH1) + (1 | SDMVPSU),
 family = binomial(),
 data = nhanes_sample,
 weights = svywght_a
)

ggpredict(m, c("age", "RIAGENDR")) %>% plot()


Best
Daniel

-----Urspr?ngliche Nachricht-----
Von: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org <mailto:r-sig-mixed-models-bounces at r-project.org> > Im
Auftrag von Sam Crawley
Gesendet: Montag, 10. Juni 2019 10:36
An: r-sig-mixed-models at r-project.org <mailto:r-sig-mixed-models at r-project.org> 
Betreff: [R-sig-ME] Predicted probabilites with CIs for multilevel logistic
regression with prior weights

Hello all,

I am doing a multilevel binomial logistic regression using lme4, and the
survey data I am using requires weights to be used. I would like to
calculate various predicted probabilities with confidence intervals based on
the estimated model. The predict function obviously doesn't give me standard
errors, and the recommended method to get these is to use the bootMer
function.

However, in my case, the weights provided are not integers, and the bootMer
function exits with an error if the weights are not integers (I raised a
GitHub issue about this, and was pointed to this list:
https://github.com/lme4/lme4/issues/524 ).

So my question is, what is the best way to calculate the predicted
probabilities (with confidence intervals) in my case?

I would appreciate any help you can give me, and I'm happy to provide more
details if required.

Thanks,
Sam Crawley.

_______________________________________________
R-sig-mixed-models at r-project.org <mailto:R-sig-mixed-models at r-project.org>  mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

--

_____________________________________________________________________

Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen
Rechts; Gerichtsstand: Hamburg | www.uke.de <http://www.uke.de> 
Vorstandsmitglieder: Prof. Dr. Burkhard G?ke (Vorsitzender), Prof. Dr. Dr.
Uwe Koch-Gromus, Joachim Pr?l?, Marya Verdel
_____________________________________________________________________

SAVE PAPER - THINK BEFORE PRINTING

_______________________________________________
R-sig-mixed-models at r-project.org <mailto:R-sig-mixed-models at r-project.org>  mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

--

_____________________________________________________________________

Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen Rechts; Gerichtsstand: Hamburg | www.uke.de <http://www.uke.de> 
Vorstandsmitglieder: Prof. Dr. Burkhard G?ke (Vorsitzender), Prof. Dr. Dr. Uwe Koch-Gromus, Joachim Pr?l?, Marya Verdel
_____________________________________________________________________

SAVE PAPER - THINK BEFORE PRINTING

_______________________________________________
R-sig-mixed-models at r-project.org <mailto:R-sig-mixed-models at r-project.org>  mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

 

--

_____________________________________________________________________

Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen Rechts; Gerichtsstand: Hamburg | www.uke.de
Vorstandsmitglieder: Prof. Dr. Burkhard G?ke (Vorsitzender), Prof. Dr. Dr. Uwe Koch-Gromus, Joachim Pr?l?, Marya Verdel
_____________________________________________________________________

SAVE PAPER - THINK BEFORE PRINTING

	[[alternative HTML version deleted]]


From d@iuedecke m@iii@g oii uke@de  Mon Jun 10 19:46:51 2019
From: d@iuedecke m@iii@g oii uke@de (d@iuedecke m@iii@g oii uke@de)
Date: Mon, 10 Jun 2019 19:46:51 +0200
Subject: [R-sig-ME] 
 Predicted probabilites with CIs for multilevel logistic
 regression with prior weights
In-Reply-To: <000001d51fb3$a72f2730$f58d7590$@uke.de>
References: <e4431ad0-e1aa-47f5-a9aa-32556ca1d332@www.fastmail.com>
 <000e01d51fa1$74c85760$5e590620$@uke.de>
 <000f01d51fa1$e1bd8f70$a538ae50$@uke.de>
 <609978FF-4C66-4568-BBF4-49F81201832E@gmail.com>
 <000001d51fb3$a72f2730$f58d7590$@uke.de>
Message-ID: <000001d51fb4$7cfe69c0$76fb3d40$@uke.de>

Short addition, I also fitted two more glmmTMB-models, using sjstats::scale_weights(), which seems to come close to survey-weights (not sure if this is always the case that results match that good)

library(sjstats)
lalonde$id <- 1
lalonde <- scale_weights(lalonde, cluster.id = id, pweight = w)

glm3 <- glmmTMB(re78 ~ treat, weights=svywght_a , data=lalonde)
glm4 <- glmmTMB(re78 ~ treat, weights=svywght_b , data=lalonde)

# glm3 with svywght_a are similar to survey-weights
 head(cbind(glm1$weights, glm11$weights, glm2$frame$`(weights)`, glm3$frame$`(weights)`, glm4$frame$`(weights)`))

       [,1]     [,2]     [,3]      [,4]      [,5]
1 1.4682453 2.108394 2.108394 1.4682453 0.7302372
2 0.9593877 1.377677 1.377677 0.9593877 0.4771550
3 0.7489954 1.075554 1.075554 0.7489954 0.3725156
4 0.7319955 1.051143 1.051143 0.7319955 0.3640607
5 0.7283328 1.045883 1.045883 0.7283328 0.3622390
6 0.7244569 1.040317 1.040317 0.7244569 0.3603113


-----Urspr?ngliche Nachricht-----
Von: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> Im Auftrag von d.luedecke at uke.de
Gesendet: Montag, 10. Juni 2019 19:41
An: 'Mollie Brooks' <mollieebrooks at gmail.com>; 'Sam Crawley' <sam_crawley at warpmail.net>; 'Help Mixed Models' <r-sig-mixed-models at r-project.org>
Betreff: Re: [R-sig-ME] Predicted probabilites with CIs for multilevel logistic regression with prior weights

I think that Sam is talking about ?sampling? or ?survey? weights (as compared to analytical or frequency weights, used by ?normal? regression models).

 The issue you?re referring to is referenced by another issue (https://github.com/glmmTMB/glmmTMB/issues/440), which in turn shows an example from Cross Validated:
https://stats.stackexchange.com/questions/57107/use-of-weights-in-svyglm-vs-glm

 If I use that example, and add a third model fitted with glmmTMB, I get following result when comparing the weights from the fitted objects:

 library(glmmTMB)

glm2 <- glmmTMB(re78 ~ treat, weights = w , data = lalonde)
cbind(glm1$weights, glm11$weights, glm2$frame$`(weights)`)

#>        [,1]     [,2]     [,3]
#> 1 1.4682453 2.108394 2.108394
#> 2 0.9593877 1.377677 1.377677
#> 3 0.7489954 1.075554 1.075554
#> 4 0.7319955 1.051143 1.051143
#> 5 0.7283328 1.045883 1.045883
#> 6 0.7244569 1.040317 1.040317

As you can see, ?glm? and ?glmmTMB? produce the same weights, while the survey-package has different weights? I?m not sure that the weights implemented in glmmTMB are actually ?sampling? weights (for surveys, as implemented in the survey package), or how to reproduce such weights using glmmTMB.
 

Von: Mollie Brooks <mollieebrooks at gmail.com> 
Gesendet: Montag, 10. Juni 2019 19:04
An: Sam Crawley <sam_crawley at warpmail.net>; Help Mixed Models <r-sig-mixed-models at r-project.org>
Cc: d.luedecke at uke.de
Betreff: Re: [R-sig-ME] Predicted probabilites with CIs for multilevel logistic regression with prior weights

 

 





On 10Jun 2019, at 17:33, <d.luedecke at uke.de <mailto:d.luedecke at uke.de> > <d.luedecke at uke.de <mailto:d.luedecke at uke.de> > wrote:

 

mixed models in R do correctly not account for sampling weights


Should be: mixed models in R do *currently* not account for sampling weights

 

I?m still trying to get a handle of the different definitions of "weights" but I believe we implemented sampling weights in glmmTMB. We do this by weighting the log-likelihood contribution of each observation. I think this is different from prior weights if you mean Bayesian priors. There has been some discussion of the different implementations of "weights" in different R functions (link below) and we still need to update the documentation for glmmTMB 

https://github.com/glmmTMB/glmmTMB/issues/285

 

Here?s a binomial example:

 

library(glmmTMB)

set.seed(123)

n=100

dat=data.frame(trials=rpois(n, lambda=50), rownum=1:n)

dat$success=rbinom(n, dat$trials, prob=.3)

dat$rep=sample(1:5, size=n, replace=TRUE) #each observation is repeated 1 to 5 times

rows=rep(dat$rownum, each=1, times=dat$rep)

dat_disaggregated=dat[rows, ]





summary(glmmTMB(cbind(success, trials-success)~1, weights=rep, dat, family=binomial))

summary(glmmTMB(cbind(success, trials-success)~1, dat_disaggregated, family=binomial))





and it works with non-integer weights





summary(glmmTMB(cbind(success, trials-success)~1, weights=rep/5, dat, family=binomial))





cheers,

Mollie






-----Urspr?ngliche Nachricht-----
Von: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org <mailto:r-sig-mixed-models-bounces at r-project.org> > Im
Auftrag von d.luedecke at uke.de <mailto:d.luedecke at uke.de> 
Gesendet: Montag, 10. Juni 2019 17:31
An: 'Sam Crawley' <sam_crawley at warpmail.net <mailto:sam_crawley at warpmail.net> >;
r-sig-mixed-models at r-project.org <mailto:r-sig-mixed-models at r-project.org> 
Betreff: Re: [R-sig-ME] Predicted probabilites with CIs for multilevel
logistic regression with prior weights

Hi Sam,

you could the "ggeffects" package
(https://strengejacke.github.io/ggeffects/), and there is also an example
for a logistic mixed effects model
(https://strengejacke.github.io/ggeffects/articles/practical_logisticmixedmo
del.html), which might help you.

For binomial models, using weights often results in the following warning:
#> non-integer #successes in a binomial glm!

However, CIs for the predicted probabilities can be calculated nevertheless
(at least in my quick example). Note that afaik, mixed models in R do
correctly not account for sampling weights. However, Thomas Lumley, author
of the survey-package, works on a survey-function for mixed models
(https://github.com/tslumley/svylme), probably the GitHub version is quite
stable (haven't tested yet).

An alternative would be the "scale_weights()" function from the
sjstats-package
(https://strengejacke.github.io/sjstats/articles/mixedmodels-statistics.html
#rescale-model-weights-for-complex-samples ), which rescales sampling
weights so they can be used as "weights" for the mixed models function you
have in R (lme4, lme, ...).

Based on that function, I have a small example that demonstrates how to
compute predicted probabilities for mixed models with (sampling) weights
(ignore the warnings, this is just for demonstration purposes):

library(lme4)
library(sjstats) # for scale_weights() and sample data
library(ggeffects) # for ggpredict()

data(nhanes_sample)
set.seed(123)
nhanes_sample$bin <- rbinom(nrow(nhanes_sample), 1, prob = .3)
nhanes_sample <- scale_weights(nhanes_sample, SDMVSTRA, WTINT2YR)

m <- glmer(
 bin ~ factor(RIAGENDR) * age + factor(RIDRETH1) + (1 | SDMVPSU),
 family = binomial(),
 data = nhanes_sample,
 weights = svywght_a
)

ggpredict(m, c("age", "RIAGENDR")) %>% plot()


Best
Daniel

-----Urspr?ngliche Nachricht-----
Von: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org <mailto:r-sig-mixed-models-bounces at r-project.org> > Im
Auftrag von Sam Crawley
Gesendet: Montag, 10. Juni 2019 10:36
An: r-sig-mixed-models at r-project.org <mailto:r-sig-mixed-models at r-project.org> 
Betreff: [R-sig-ME] Predicted probabilites with CIs for multilevel logistic
regression with prior weights

Hello all,

I am doing a multilevel binomial logistic regression using lme4, and the
survey data I am using requires weights to be used. I would like to
calculate various predicted probabilities with confidence intervals based on
the estimated model. The predict function obviously doesn't give me standard
errors, and the recommended method to get these is to use the bootMer
function.

However, in my case, the weights provided are not integers, and the bootMer
function exits with an error if the weights are not integers (I raised a
GitHub issue about this, and was pointed to this list:
https://github.com/lme4/lme4/issues/524 ).

So my question is, what is the best way to calculate the predicted
probabilities (with confidence intervals) in my case?

I would appreciate any help you can give me, and I'm happy to provide more
details if required.

Thanks,
Sam Crawley.

_______________________________________________
R-sig-mixed-models at r-project.org <mailto:R-sig-mixed-models at r-project.org>  mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

--

_____________________________________________________________________

Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen
Rechts; Gerichtsstand: Hamburg | www.uke.de <http://www.uke.de> 
Vorstandsmitglieder: Prof. Dr. Burkhard G?ke (Vorsitzender), Prof. Dr. Dr.
Uwe Koch-Gromus, Joachim Pr?l?, Marya Verdel
_____________________________________________________________________

SAVE PAPER - THINK BEFORE PRINTING

_______________________________________________
R-sig-mixed-models at r-project.org <mailto:R-sig-mixed-models at r-project.org>  mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

--

_____________________________________________________________________

Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen Rechts; Gerichtsstand: Hamburg | www.uke.de <http://www.uke.de> 
Vorstandsmitglieder: Prof. Dr. Burkhard G?ke (Vorsitzender), Prof. Dr. Dr. Uwe Koch-Gromus, Joachim Pr?l?, Marya Verdel
_____________________________________________________________________

SAVE PAPER - THINK BEFORE PRINTING

_______________________________________________
R-sig-mixed-models at r-project.org <mailto:R-sig-mixed-models at r-project.org>  mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

 

--

_____________________________________________________________________

Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen Rechts; Gerichtsstand: Hamburg | www.uke.de
Vorstandsmitglieder: Prof. Dr. Burkhard G?ke (Vorsitzender), Prof. Dr. Dr. Uwe Koch-Gromus, Joachim Pr?l?, Marya Verdel
_____________________________________________________________________

SAVE PAPER - THINK BEFORE PRINTING

	[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

--

_____________________________________________________________________

Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen Rechts; Gerichtsstand: Hamburg | www.uke.de
Vorstandsmitglieder: Prof. Dr. Burkhard G?ke (Vorsitzender), Prof. Dr. Dr. Uwe Koch-Gromus, Joachim Pr?l?, Marya Verdel
_____________________________________________________________________

SAVE PAPER - THINK BEFORE PRINTING

From mo|||eebrook@ @end|ng |rom gm@||@com  Mon Jun 10 19:46:21 2019
From: mo|||eebrook@ @end|ng |rom gm@||@com (Mollie Brooks)
Date: Mon, 10 Jun 2019 19:46:21 +0200
Subject: [R-sig-ME] 
 Predicted probabilites with CIs for multilevel logistic
 regression with prior weights
In-Reply-To: <000001d51fb3$a72f2730$f58d7590$@uke.de>
References: <e4431ad0-e1aa-47f5-a9aa-32556ca1d332@www.fastmail.com>
 <000e01d51fa1$74c85760$5e590620$@uke.de>
 <000f01d51fa1$e1bd8f70$a538ae50$@uke.de>
 <609978FF-4C66-4568-BBF4-49F81201832E@gmail.com>
 <000001d51fb3$a72f2730$f58d7590$@uke.de>
Message-ID: <E2865963-6C63-4B8F-A752-A4FEF61B41BA@gmail.com>


> On 10Jun 2019, at 19:40, <d.luedecke at uke.de> <d.luedecke at uke.de> wrote:
> 
> I think that Sam is talking about ?sampling? or ?survey? weights (as compared to analytical or frequency weights, used by ?normal? regression models).
>  
> The issue you?re referring to is referenced by another issue (https://github.com/glmmTMB/glmmTMB/issues/440 <https://github.com/glmmTMB/glmmTMB/issues/440>),

Yes, I (mebrooks) am the one who referenced it and the user (mmeierer) said it fit their needs for "sample weights".

> which in turn shows an example from Cross Validated:
> https://stats.stackexchange.com/questions/57107/use-of-weights-in-svyglm-vs-glm <https://stats.stackexchange.com/questions/57107/use-of-weights-in-svyglm-vs-glm>
>  
> If I use that example, and add a third model fitted with glmmTMB, I get following result when comparing the weights from the fitted objects:
>  
> library(glmmTMB)
> glm2 <- glmmTMB(re78 ~ treat, weights = w , data = lalonde)
> cbind(glm1$weights, glm11$weights, glm2$frame$`(weights)`)
> #>        [,1]     [,2]     [,3]
> #> 1 1.4682453 2.108394 2.108394
> #> 2 0.9593877 1.377677 1.377677
> #> 3 0.7489954 1.075554 1.075554
> #> 4 0.7319955 1.051143 1.051143
> #> 5 0.7283328 1.045883 1.045883
> #> 6 0.7244569 1.040317 1.040317
>  
> As you can see, ?glm? and ?glmmTMB? produce the same weights, while the survey-package has different weights? I?m not sure that the weights implemented in glmmTMB are actually ?sampling? weights (for surveys, as implemented in the survey package),

Ok. I don?t know the survey package and don?t have time to look into it now. Feel free to follow up on issue 285 if you have more insight. 

cheers,
Mollie

> or how to reproduce such weights using glmmTMB.
>  
> Von: Mollie Brooks <mollieebrooks at gmail.com> 
> Gesendet: Montag, 10. Juni 2019 19:04
> An: Sam Crawley <sam_crawley at warpmail.net>; Help Mixed Models <r-sig-mixed-models at r-project.org>
> Cc: d.luedecke at uke.de
> Betreff: Re: [R-sig-ME] Predicted probabilites with CIs for multilevel logistic regression with prior weights
>  
>  
> 
> 
>> On 10Jun 2019, at 17:33, <d.luedecke at uke.de <mailto:d.luedecke at uke.de>> <d.luedecke at uke.de <mailto:d.luedecke at uke.de>> wrote:
>>  
>>> mixed models in R do correctly not account for sampling weights
>> 
>> Should be: mixed models in R do *currently* not account for sampling weights
>  
> I?m still trying to get a handle of the different definitions of "weights" but I believe we implemented sampling weights in glmmTMB. We do this by weighting the log-likelihood contribution of each observation. I think this is different from prior weights if you mean Bayesian priors. There has been some discussion of the different implementations of "weights" in different R functions (link below) and we still need to update the documentation for glmmTMB 
> https://github.com/glmmTMB/glmmTMB/issues/285 <https://github.com/glmmTMB/glmmTMB/issues/285>
>  
> Here?s a binomial example:
>  
> library(glmmTMB)
> set.seed(123)
> n=100
> dat=data.frame(trials=rpois(n, lambda=50), rownum=1:n)
> dat$success=rbinom(n, dat$trials, prob=.3)
> dat$rep=sample(1:5, size=n, replace=TRUE) #each observation is repeated 1 to 5 times
> rows=rep(dat$rownum, each=1, times=dat$rep)
> dat_disaggregated=dat[rows, ]
> 
> 
> summary(glmmTMB(cbind(success, trials-success)~1, weights=rep, dat, family=binomial))
> summary(glmmTMB(cbind(success, trials-success)~1, dat_disaggregated, family=binomial))
> 
> 
> and it works with non-integer weights
> 
> 
> summary(glmmTMB(cbind(success, trials-success)~1, weights=rep/5, dat, family=binomial))
> 
> 
> cheers,
> Mollie
> 
> 
>> 
>> -----Urspr?ngliche Nachricht-----
>> Von: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org <mailto:r-sig-mixed-models-bounces at r-project.org>> Im
>> Auftrag von d.luedecke at uke.de <mailto:d.luedecke at uke.de>
>> Gesendet: Montag, 10. Juni 2019 17:31
>> An: 'Sam Crawley' <sam_crawley at warpmail.net <mailto:sam_crawley at warpmail.net>>;
>> r-sig-mixed-models at r-project.org <mailto:r-sig-mixed-models at r-project.org>
>> Betreff: Re: [R-sig-ME] Predicted probabilites with CIs for multilevel
>> logistic regression with prior weights
>> 
>> Hi Sam,
>> 
>> you could the "ggeffects" package
>> (https://strengejacke.github.io/ggeffects/ <https://strengejacke.github.io/ggeffects/>), and there is also an example
>> for a logistic mixed effects model
>> (https://strengejacke.github.io/ggeffects/articles/practical_logisticmixedmo <https://strengejacke.github.io/ggeffects/articles/practical_logisticmixedmo>
>> del.html), which might help you.
>> 
>> For binomial models, using weights often results in the following warning:
>> #> non-integer #successes in a binomial glm!
>> 
>> However, CIs for the predicted probabilities can be calculated nevertheless
>> (at least in my quick example). Note that afaik, mixed models in R do
>> correctly not account for sampling weights. However, Thomas Lumley, author
>> of the survey-package, works on a survey-function for mixed models
>> (https://github.com/tslumley/svylme <https://github.com/tslumley/svylme>), probably the GitHub version is quite
>> stable (haven't tested yet).
>> 
>> An alternative would be the "scale_weights()" function from the
>> sjstats-package
>> (https://strengejacke.github.io/sjstats/articles/mixedmodels-statistics.html <https://strengejacke.github.io/sjstats/articles/mixedmodels-statistics.html>
>> #rescale-model-weights-for-complex-samples ), which rescales sampling
>> weights so they can be used as "weights" for the mixed models function you
>> have in R (lme4, lme, ...).
>> 
>> Based on that function, I have a small example that demonstrates how to
>> compute predicted probabilities for mixed models with (sampling) weights
>> (ignore the warnings, this is just for demonstration purposes):
>> 
>> library(lme4)
>> library(sjstats) # for scale_weights() and sample data
>> library(ggeffects) # for ggpredict()
>> 
>> data(nhanes_sample)
>> set.seed(123)
>> nhanes_sample$bin <- rbinom(nrow(nhanes_sample), 1, prob = .3)
>> nhanes_sample <- scale_weights(nhanes_sample, SDMVSTRA, WTINT2YR)
>> 
>> m <- glmer(
>>  bin ~ factor(RIAGENDR) * age + factor(RIDRETH1) + (1 | SDMVPSU),
>>  family = binomial(),
>>  data = nhanes_sample,
>>  weights = svywght_a
>> )
>> 
>> ggpredict(m, c("age", "RIAGENDR")) %>% plot()
>> 
>> 
>> Best
>> Daniel
>> 
>> -----Urspr?ngliche Nachricht-----
>> Von: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org <mailto:r-sig-mixed-models-bounces at r-project.org>> Im
>> Auftrag von Sam Crawley
>> Gesendet: Montag, 10. Juni 2019 10:36
>> An: r-sig-mixed-models at r-project.org <mailto:r-sig-mixed-models at r-project.org>
>> Betreff: [R-sig-ME] Predicted probabilites with CIs for multilevel logistic
>> regression with prior weights
>> 
>> Hello all,
>> 
>> I am doing a multilevel binomial logistic regression using lme4, and the
>> survey data I am using requires weights to be used. I would like to
>> calculate various predicted probabilities with confidence intervals based on
>> the estimated model. The predict function obviously doesn't give me standard
>> errors, and the recommended method to get these is to use the bootMer
>> function.
>> 
>> However, in my case, the weights provided are not integers, and the bootMer
>> function exits with an error if the weights are not integers (I raised a
>> GitHub issue about this, and was pointed to this list:
>> https://github.com/lme4/lme4/issues/524 <https://github.com/lme4/lme4/issues/524> ).
>> 
>> So my question is, what is the best way to calculate the predicted
>> probabilities (with confidence intervals) in my case?
>> 
>> I would appreciate any help you can give me, and I'm happy to provide more
>> details if required.
>> 
>> Thanks,
>> Sam Crawley.
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org <mailto:R-sig-mixed-models at r-project.org> mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>> 
>> --
>> 
>> _____________________________________________________________________
>> 
>> Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen
>> Rechts; Gerichtsstand: Hamburg | www.uke.de <http://www.uke.de/>
>> Vorstandsmitglieder: Prof. Dr. Burkhard G?ke (Vorsitzender), Prof. Dr. Dr.
>> Uwe Koch-Gromus, Joachim Pr?l?, Marya Verdel
>> _____________________________________________________________________
>> 
>> SAVE PAPER - THINK BEFORE PRINTING
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org <mailto:R-sig-mixed-models at r-project.org> mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>> 
>> --
>> 
>> _____________________________________________________________________
>> 
>> Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen Rechts; Gerichtsstand: Hamburg | www.uke.de <http://www.uke.de/>
>> Vorstandsmitglieder: Prof. Dr. Burkhard G?ke (Vorsitzender), Prof. Dr. Dr. Uwe Koch-Gromus, Joachim Pr?l?, Marya Verdel
>> _____________________________________________________________________
>> 
>> SAVE PAPER - THINK BEFORE PRINTING
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org <mailto:R-sig-mixed-models at r-project.org> mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>  
> 
> Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen Rechts; Gerichtsstand: Hamburg | www.uke.de <http://www.uke.de/>
> Vorstandsmitglieder: Prof. Dr. Burkhard G?ke (Vorsitzender), Prof. Dr. Dr. Uwe Koch-Gromus, Joachim Pr?l?, Marya Verdel
> 
> SAVE PAPER - THINK BEFORE PRINTING
> 


	[[alternative HTML version deleted]]


From d@iuedecke m@iii@g oii uke@de  Mon Jun 10 20:15:44 2019
From: d@iuedecke m@iii@g oii uke@de (d@iuedecke m@iii@g oii uke@de)
Date: Mon, 10 Jun 2019 20:15:44 +0200
Subject: [R-sig-ME] 
 Predicted probabilites with CIs for multilevel logistic
 regression with prior weights
In-Reply-To: <E2865963-6C63-4B8F-A752-A4FEF61B41BA@gmail.com>
References: <e4431ad0-e1aa-47f5-a9aa-32556ca1d332@www.fastmail.com>
 <000e01d51fa1$74c85760$5e590620$@uke.de>
 <000f01d51fa1$e1bd8f70$a538ae50$@uke.de>
 <609978FF-4C66-4568-BBF4-49F81201832E@gmail.com>
 <000001d51fb3$a72f2730$f58d7590$@uke.de>
 <E2865963-6C63-4B8F-A752-A4FEF61B41BA@gmail.com>
Message-ID: <000001d51fb8$85d35200$9179f600$@uke.de>

> Feel free to follow up on issue 285 if you have more insight. 

 

At least from the technical side, I don?t have more insights, I guess. I already noticed the discussion in #285 some time ago, so I?m lurking, but not actively following ?

 

Terminology used in different papers or from method reports of different surveys also doesn?t seem always consistent to me. I think, ?post-stratification weights? were requested by Sam, which are weights based on group (or stratum) characteristics (like the distribution of age or gender proportions). Ben Bolker also mentioned sample weights in #285 (?in addition to these two cases, there's also the case of sampling weights, which is difficult/a mess for complex regression models but worth discussing at least ...?).

 

The difference between the weights-argument in typical regression model functions and the survey-package is ?The survey package not only allows for adjusting the composition of a sample to the characteristics of the general population. Most base packages would allow you to do that by specifying a weights argument. The survey package goes further by correcting the design effect introduced by the application of post-stratification weights.? (https://tophcito.blogspot.com/2014/04/social-science-goes-r-weighted-survey.html).

 

This of course only applies if you actually have survey-data.

 

Von: Mollie Brooks <mollieebrooks at gmail.com> 
Gesendet: Montag, 10. Juni 2019 19:46
An: d.luedecke at uke.de
Cc: Sam Crawley <sam_crawley at warpmail.net>; Help Mixed Models <r-sig-mixed-models at r-project.org>
Betreff: Re: [R-sig-ME] Predicted probabilites with CIs for multilevel logistic regression with prior weights

 

 

On 10Jun 2019, at 19:40, <d.luedecke at uke.de <mailto:d.luedecke at uke.de> > <d.luedecke at uke.de <mailto:d.luedecke at uke.de> > wrote:

 

I think that Sam is talking about ?sampling? or ?survey? weights (as compared to analytical or frequency weights, used by ?normal? regression models).

 

The issue you?re referring to is referenced by another issue ( <https://github.com/glmmTMB/glmmTMB/issues/440> https://github.com/glmmTMB/glmmTMB/issues/440), 

 

Yes, I (mebrooks) am the one who referenced it and the user (mmeierer) said it fit their needs for "sample weights".





which in turn shows an example from Cross Validated:

 <https://stats.stackexchange.com/questions/57107/use-of-weights-in-svyglm-vs-glm> https://stats.stackexchange.com/questions/57107/use-of-weights-in-svyglm-vs-glm

 

If I use that example, and add a third model fitted with glmmTMB, I get following result when comparing the weights from the fitted objects:

 

library(glmmTMB)

glm2 <- glmmTMB(re78 ~ treat, weights = w , data = lalonde)

cbind(glm1$weights, glm11$weights, glm2$frame$`(weights)`)

#>        [,1]     [,2]     [,3]

#> 1 1.4682453 2.108394 2.108394

#> 2 0.9593877 1.377677 1.377677

#> 3 0.7489954 1.075554 1.075554

#> 4 0.7319955 1.051143 1.051143

#> 5 0.7283328 1.045883 1.045883

#> 6 0.7244569 1.040317 1.040317

 

As you can see, ?glm? and ?glmmTMB? produce the same weights, while the survey-package has different weights? I?m not sure that the weights implemented in glmmTMB are actually ?sampling? weights (for surveys, as implemented in the survey package), 

 

Ok. I don?t know the survey package and don?t have time to look into it now. Feel free to follow up on issue 285 if you have more insight. 

 

cheers,

Mollie





or how to reproduce such weights using glmmTMB.

 

Von: Mollie Brooks <mollieebrooks at gmail.com <mailto:mollieebrooks at gmail.com> > 
Gesendet: Montag, 10. Juni 2019 19:04
An: Sam Crawley <sam_crawley at warpmail.net <mailto:sam_crawley at warpmail.net> >; Help Mixed Models <r-sig-mixed-models at r-project.org <mailto:r-sig-mixed-models at r-project.org> >
Cc: d.luedecke at uke.de <mailto:d.luedecke at uke.de> 
Betreff: Re: [R-sig-ME] Predicted probabilites with CIs for multilevel logistic regression with prior weights

 

 






On 10Jun 2019, at 17:33, < <mailto:d.luedecke at uke.de> d.luedecke at uke.de> < <mailto:d.luedecke at uke.de> d.luedecke at uke.de> wrote:

 

mixed models in R do correctly not account for sampling weights


Should be: mixed models in R do *currently* not account for sampling weights

 

I?m still trying to get a handle of the different definitions of "weights" but I believe we implemented sampling weights in glmmTMB. We do this by weighting the log-likelihood contribution of each observation. I think this is different from prior weights if you mean Bayesian priors. There has been some discussion of the different implementations of "weights" in different R functions (link below) and we still need to update the documentation for glmmTMB 

 <https://github.com/glmmTMB/glmmTMB/issues/285> https://github.com/glmmTMB/glmmTMB/issues/285

 

Here?s a binomial example:

 

library(glmmTMB)

set.seed(123)

n=100

dat=data.frame(trials=rpois(n, lambda=50), rownum=1:n)

dat$success=rbinom(n, dat$trials, prob=.3)

dat$rep=sample(1:5, size=n, replace=TRUE) #each observation is repeated 1 to 5 times

rows=rep(dat$rownum, each=1, times=dat$rep)

dat_disaggregated=dat[rows, ]






summary(glmmTMB(cbind(success, trials-success)~1, weights=rep, dat, family=binomial))

summary(glmmTMB(cbind(success, trials-success)~1, dat_disaggregated, family=binomial))






and it works with non-integer weights






summary(glmmTMB(cbind(success, trials-success)~1, weights=rep/5, dat, family=binomial))






cheers,

Mollie







-----Urspr?ngliche Nachricht-----
Von: R-sig-mixed-models < <mailto:r-sig-mixed-models-bounces at r-project.org> r-sig-mixed-models-bounces at r-project.org> Im
Auftrag von  <mailto:d.luedecke at uke.de> d.luedecke at uke.de
Gesendet: Montag, 10. Juni 2019 17:31
An: 'Sam Crawley' < <mailto:sam_crawley at warpmail.net> sam_crawley at warpmail.net>;
 <mailto:r-sig-mixed-models at r-project.org> r-sig-mixed-models at r-project.org
Betreff: Re: [R-sig-ME] Predicted probabilites with CIs for multilevel
logistic regression with prior weights

Hi Sam,

you could the "ggeffects" package
( <https://strengejacke.github.io/ggeffects/> https://strengejacke.github.io/ggeffects/), and there is also an example
for a logistic mixed effects model
( <https://strengejacke.github.io/ggeffects/articles/practical_logisticmixedmo> https://strengejacke.github.io/ggeffects/articles/practical_logisticmixedmo
del.html), which might help you.

For binomial models, using weights often results in the following warning:
#> non-integer #successes in a binomial glm!

However, CIs for the predicted probabilities can be calculated nevertheless
(at least in my quick example). Note that afaik, mixed models in R do
correctly not account for sampling weights. However, Thomas Lumley, author
of the survey-package, works on a survey-function for mixed models
( <https://github.com/tslumley/svylme> https://github.com/tslumley/svylme), probably the GitHub version is quite
stable (haven't tested yet).

An alternative would be the "scale_weights()" function from the
sjstats-package
( <https://strengejacke.github.io/sjstats/articles/mixedmodels-statistics.html> https://strengejacke.github.io/sjstats/articles/mixedmodels-statistics.html
#rescale-model-weights-for-complex-samples ), which rescales sampling
weights so they can be used as "weights" for the mixed models function you
have in R (lme4, lme, ...).

Based on that function, I have a small example that demonstrates how to
compute predicted probabilities for mixed models with (sampling) weights
(ignore the warnings, this is just for demonstration purposes):

library(lme4)
library(sjstats) # for scale_weights() and sample data
library(ggeffects) # for ggpredict()

data(nhanes_sample)
set.seed(123)
nhanes_sample$bin <- rbinom(nrow(nhanes_sample), 1, prob = .3)
nhanes_sample <- scale_weights(nhanes_sample, SDMVSTRA, WTINT2YR)

m <- glmer(
 bin ~ factor(RIAGENDR) * age + factor(RIDRETH1) + (1 | SDMVPSU),
 family = binomial(),
 data = nhanes_sample,
 weights = svywght_a
)

ggpredict(m, c("age", "RIAGENDR")) %>% plot()


Best
Daniel

-----Urspr?ngliche Nachricht-----
Von: R-sig-mixed-models < <mailto:r-sig-mixed-models-bounces at r-project.org> r-sig-mixed-models-bounces at r-project.org> Im
Auftrag von Sam Crawley
Gesendet: Montag, 10. Juni 2019 10:36
An:  <mailto:r-sig-mixed-models at r-project.org> r-sig-mixed-models at r-project.org
Betreff: [R-sig-ME] Predicted probabilites with CIs for multilevel logistic
regression with prior weights

Hello all,

I am doing a multilevel binomial logistic regression using lme4, and the
survey data I am using requires weights to be used. I would like to
calculate various predicted probabilities with confidence intervals based on
the estimated model. The predict function obviously doesn't give me standard
errors, and the recommended method to get these is to use the bootMer
function.

However, in my case, the weights provided are not integers, and the bootMer
function exits with an error if the weights are not integers (I raised a
GitHub issue about this, and was pointed to this list:
 <https://github.com/lme4/lme4/issues/524> https://github.com/lme4/lme4/issues/524 ).

So my question is, what is the best way to calculate the predicted
probabilities (with confidence intervals) in my case?

I would appreciate any help you can give me, and I'm happy to provide more
details if required.

Thanks,
Sam Crawley.

_______________________________________________
 <mailto:R-sig-mixed-models at r-project.org> R-sig-mixed-models at r-project.org mailing list
 <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

--

_____________________________________________________________________

Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen
Rechts; Gerichtsstand: Hamburg |  <http://www.uke.de/> www.uke.de
Vorstandsmitglieder: Prof. Dr. Burkhard G?ke (Vorsitzender), Prof. Dr. Dr.
Uwe Koch-Gromus, Joachim Pr?l?, Marya Verdel
_____________________________________________________________________

SAVE PAPER - THINK BEFORE PRINTING

_______________________________________________
 <mailto:R-sig-mixed-models at r-project.org> R-sig-mixed-models at r-project.org mailing list
 <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

--

_____________________________________________________________________

Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen Rechts; Gerichtsstand: Hamburg |  <http://www.uke.de/> www.uke.de
Vorstandsmitglieder: Prof. Dr. Burkhard G?ke (Vorsitzender), Prof. Dr. Dr. Uwe Koch-Gromus, Joachim Pr?l?, Marya Verdel
_____________________________________________________________________

SAVE PAPER - THINK BEFORE PRINTING

_______________________________________________
 <mailto:R-sig-mixed-models at r-project.org> R-sig-mixed-models at r-project.org mailing list
 <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

 

 


  _____  


Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen Rechts; Gerichtsstand: Hamburg |  <http://www.uke.de/> www.uke.de
Vorstandsmitglieder: Prof. Dr. Burkhard G?ke (Vorsitzender), Prof. Dr. Dr. Uwe Koch-Gromus, Joachim Pr?l?, Marya Verdel


  _____  


SAVE PAPER - THINK BEFORE PRINTING

 

--

_____________________________________________________________________

Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen Rechts; Gerichtsstand: Hamburg | www.uke.de
Vorstandsmitglieder: Prof. Dr. Burkhard G?ke (Vorsitzender), Prof. Dr. Dr. Uwe Koch-Gromus, Joachim Pr?l?, Marya Verdel
_____________________________________________________________________

SAVE PAPER - THINK BEFORE PRINTING

	[[alternative HTML version deleted]]


From cvr7 @end|ng |rom cdc@gov  Mon Jun 10 20:29:04 2019
From: cvr7 @end|ng |rom cdc@gov (Rose, Charles E. (CDC/DDNID/NCBDDD/OD))
Date: Mon, 10 Jun 2019 18:29:04 +0000
Subject: [R-sig-ME] 
 Predicted probabilites with CIs for multilevel logistic
 regression with prior weights
In-Reply-To: <000001d51fb4$7cfe69c0$76fb3d40$@uke.de>
References: <e4431ad0-e1aa-47f5-a9aa-32556ca1d332@www.fastmail.com>
 <000e01d51fa1$74c85760$5e590620$@uke.de>
 <000f01d51fa1$e1bd8f70$a538ae50$@uke.de>
 <609978FF-4C66-4568-BBF4-49F81201832E@gmail.com>
 <000001d51fb3$a72f2730$f58d7590$@uke.de>
 <000001d51fb4$7cfe69c0$76fb3d40$@uke.de>
Message-ID: <DM6PR09MB40101184B36DCE9169DE713F9E130@DM6PR09MB4010.namprd09.prod.outlook.com>

I don?t know the package glmmTMB but I'm wondering if the use of survey weights in the weight statement results in the appropriate SEs as one would expect from the Lumley survey package; any comments about this issue are appreciated, thanks, chuck


-----Original Message-----
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> On Behalf Of d.luedecke at uke.de
Sent: Monday, June 10, 2019 1:47 PM
To: 'Mollie Brooks' <mollieebrooks at gmail.com>; 'Sam Crawley' <sam_crawley at warpmail.net>; 'Help Mixed Models' <r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] Predicted probabilites with CIs for multilevel logistic regression with prior weights

Short addition, I also fitted two more glmmTMB-models, using sjstats::scale_weights(), which seems to come close to survey-weights (not sure if this is always the case that results match that good)

library(sjstats)
lalonde$id <- 1
lalonde <- scale_weights(lalonde, cluster.id = id, pweight = w)

glm3 <- glmmTMB(re78 ~ treat, weights=svywght_a , data=lalonde)
glm4 <- glmmTMB(re78 ~ treat, weights=svywght_b , data=lalonde)

# glm3 with svywght_a are similar to survey-weights  head(cbind(glm1$weights, glm11$weights, glm2$frame$`(weights)`, glm3$frame$`(weights)`, glm4$frame$`(weights)`))

       [,1]     [,2]     [,3]      [,4]      [,5]
1 1.4682453 2.108394 2.108394 1.4682453 0.7302372
2 0.9593877 1.377677 1.377677 0.9593877 0.4771550
3 0.7489954 1.075554 1.075554 0.7489954 0.3725156
4 0.7319955 1.051143 1.051143 0.7319955 0.3640607
5 0.7283328 1.045883 1.045883 0.7283328 0.3622390
6 0.7244569 1.040317 1.040317 0.7244569 0.3603113


-----Urspr?ngliche Nachricht-----
Von: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> Im Auftrag von d.luedecke at uke.de
Gesendet: Montag, 10. Juni 2019 19:41
An: 'Mollie Brooks' <mollieebrooks at gmail.com>; 'Sam Crawley' <sam_crawley at warpmail.net>; 'Help Mixed Models' <r-sig-mixed-models at r-project.org>
Betreff: Re: [R-sig-ME] Predicted probabilites with CIs for multilevel logistic regression with prior weights

I think that Sam is talking about ?sampling? or ?survey? weights (as compared to analytical or frequency weights, used by ?normal? regression models).

 The issue you?re referring to is referenced by another issue (https://github.com/glmmTMB/glmmTMB/issues/440), which in turn shows an example from Cross Validated:
https://stats.stackexchange.com/questions/57107/use-of-weights-in-svyglm-vs-glm

 If I use that example, and add a third model fitted with glmmTMB, I get following result when comparing the weights from the fitted objects:

 library(glmmTMB)

glm2 <- glmmTMB(re78 ~ treat, weights = w , data = lalonde) cbind(glm1$weights, glm11$weights, glm2$frame$`(weights)`)

#>        [,1]     [,2]     [,3]
#> 1 1.4682453 2.108394 2.108394
#> 2 0.9593877 1.377677 1.377677
#> 3 0.7489954 1.075554 1.075554
#> 4 0.7319955 1.051143 1.051143
#> 5 0.7283328 1.045883 1.045883
#> 6 0.7244569 1.040317 1.040317

As you can see, ?glm? and ?glmmTMB? produce the same weights, while the survey-package has different weights? I?m not sure that the weights implemented in glmmTMB are actually ?sampling? weights (for surveys, as implemented in the survey package), or how to reproduce such weights using glmmTMB.
 

Von: Mollie Brooks <mollieebrooks at gmail.com>
Gesendet: Montag, 10. Juni 2019 19:04
An: Sam Crawley <sam_crawley at warpmail.net>; Help Mixed Models <r-sig-mixed-models at r-project.org>
Cc: d.luedecke at uke.de
Betreff: Re: [R-sig-ME] Predicted probabilites with CIs for multilevel logistic regression with prior weights

 

 





On 10Jun 2019, at 17:33, <d.luedecke at uke.de <mailto:d.luedecke at uke.de> > <d.luedecke at uke.de <mailto:d.luedecke at uke.de> > wrote:

 

mixed models in R do correctly not account for sampling weights


Should be: mixed models in R do *currently* not account for sampling weights

 

I?m still trying to get a handle of the different definitions of "weights" but I believe we implemented sampling weights in glmmTMB. We do this by weighting the log-likelihood contribution of each observation. I think this is different from prior weights if you mean Bayesian priors. There has been some discussion of the different implementations of "weights" in different R functions (link below) and we still need to update the documentation for glmmTMB 

https://github.com/glmmTMB/glmmTMB/issues/285

 

Here?s a binomial example:

 

library(glmmTMB)

set.seed(123)

n=100

dat=data.frame(trials=rpois(n, lambda=50), rownum=1:n)

dat$success=rbinom(n, dat$trials, prob=.3)

dat$rep=sample(1:5, size=n, replace=TRUE) #each observation is repeated 1 to 5 times

rows=rep(dat$rownum, each=1, times=dat$rep)

dat_disaggregated=dat[rows, ]





summary(glmmTMB(cbind(success, trials-success)~1, weights=rep, dat, family=binomial))

summary(glmmTMB(cbind(success, trials-success)~1, dat_disaggregated, family=binomial))





and it works with non-integer weights





summary(glmmTMB(cbind(success, trials-success)~1, weights=rep/5, dat, family=binomial))





cheers,

Mollie






-----Urspr?ngliche Nachricht-----
Von: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org <mailto:r-sig-mixed-models-bounces at r-project.org> > Im Auftrag von d.luedecke at uke.de <mailto:d.luedecke at uke.de>
Gesendet: Montag, 10. Juni 2019 17:31
An: 'Sam Crawley' <sam_crawley at warpmail.net <mailto:sam_crawley at warpmail.net> >; r-sig-mixed-models at r-project.org <mailto:r-sig-mixed-models at r-project.org>
Betreff: Re: [R-sig-ME] Predicted probabilites with CIs for multilevel logistic regression with prior weights

Hi Sam,

you could the "ggeffects" package
(https://strengejacke.github.io/ggeffects/), and there is also an example for a logistic mixed effects model (https://strengejacke.github.io/ggeffects/articles/practical_logisticmixedmo
del.html), which might help you.

For binomial models, using weights often results in the following warning:
#> non-integer #successes in a binomial glm!

However, CIs for the predicted probabilities can be calculated nevertheless (at least in my quick example). Note that afaik, mixed models in R do correctly not account for sampling weights. However, Thomas Lumley, author of the survey-package, works on a survey-function for mixed models (https://github.com/tslumley/svylme), probably the GitHub version is quite stable (haven't tested yet).

An alternative would be the "scale_weights()" function from the sjstats-package (https://strengejacke.github.io/sjstats/articles/mixedmodels-statistics.html
#rescale-model-weights-for-complex-samples ), which rescales sampling weights so they can be used as "weights" for the mixed models function you have in R (lme4, lme, ...).

Based on that function, I have a small example that demonstrates how to compute predicted probabilities for mixed models with (sampling) weights (ignore the warnings, this is just for demonstration purposes):

library(lme4)
library(sjstats) # for scale_weights() and sample data
library(ggeffects) # for ggpredict()

data(nhanes_sample)
set.seed(123)
nhanes_sample$bin <- rbinom(nrow(nhanes_sample), 1, prob = .3) nhanes_sample <- scale_weights(nhanes_sample, SDMVSTRA, WTINT2YR)

m <- glmer(
 bin ~ factor(RIAGENDR) * age + factor(RIDRETH1) + (1 | SDMVPSU),  family = binomial(),  data = nhanes_sample,  weights = svywght_a
)

ggpredict(m, c("age", "RIAGENDR")) %>% plot()


Best
Daniel

-----Urspr?ngliche Nachricht-----
Von: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org <mailto:r-sig-mixed-models-bounces at r-project.org> > Im Auftrag von Sam Crawley
Gesendet: Montag, 10. Juni 2019 10:36
An: r-sig-mixed-models at r-project.org <mailto:r-sig-mixed-models at r-project.org>
Betreff: [R-sig-ME] Predicted probabilites with CIs for multilevel logistic regression with prior weights

Hello all,

I am doing a multilevel binomial logistic regression using lme4, and the survey data I am using requires weights to be used. I would like to calculate various predicted probabilities with confidence intervals based on the estimated model. The predict function obviously doesn't give me standard errors, and the recommended method to get these is to use the bootMer function.

However, in my case, the weights provided are not integers, and the bootMer function exits with an error if the weights are not integers (I raised a GitHub issue about this, and was pointed to this list:
https://github.com/lme4/lme4/issues/524 ).

So my question is, what is the best way to calculate the predicted probabilities (with confidence intervals) in my case?

I would appreciate any help you can give me, and I'm happy to provide more details if required.

Thanks,
Sam Crawley.

_______________________________________________
R-sig-mixed-models at r-project.org <mailto:R-sig-mixed-models at r-project.org>  mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

--

_____________________________________________________________________

Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen Rechts; Gerichtsstand: Hamburg | www.uke.de <http://www.uke.de>
Vorstandsmitglieder: Prof. Dr. Burkhard G?ke (Vorsitzender), Prof. Dr. Dr.
Uwe Koch-Gromus, Joachim Pr?l?, Marya Verdel _____________________________________________________________________

SAVE PAPER - THINK BEFORE PRINTING

_______________________________________________
R-sig-mixed-models at r-project.org <mailto:R-sig-mixed-models at r-project.org>  mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

--

_____________________________________________________________________

Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen Rechts; Gerichtsstand: Hamburg | www.uke.de <http://www.uke.de>
Vorstandsmitglieder: Prof. Dr. Burkhard G?ke (Vorsitzender), Prof. Dr. Dr. Uwe Koch-Gromus, Joachim Pr?l?, Marya Verdel _____________________________________________________________________

SAVE PAPER - THINK BEFORE PRINTING

_______________________________________________
R-sig-mixed-models at r-project.org <mailto:R-sig-mixed-models at r-project.org>  mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

 

--

_____________________________________________________________________

Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen Rechts; Gerichtsstand: Hamburg | www.uke.de
Vorstandsmitglieder: Prof. Dr. Burkhard G?ke (Vorsitzender), Prof. Dr. Dr. Uwe Koch-Gromus, Joachim Pr?l?, Marya Verdel _____________________________________________________________________

SAVE PAPER - THINK BEFORE PRINTING

	[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

--

_____________________________________________________________________

Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen Rechts; Gerichtsstand: Hamburg | www.uke.de
Vorstandsmitglieder: Prof. Dr. Burkhard G?ke (Vorsitzender), Prof. Dr. Dr. Uwe Koch-Gromus, Joachim Pr?l?, Marya Verdel _____________________________________________________________________

SAVE PAPER - THINK BEFORE PRINTING
_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

From th|erry@onke||nx @end|ng |rom |nbo@be  Tue Jun 11 10:13:01 2019
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Tue, 11 Jun 2019 10:13:01 +0200
Subject: [R-sig-ME] lme4 installation issue
In-Reply-To: <3b861ebc37d55b809dd99f76d8a74f05@cam.ac.uk>
References: <3b861ebc37d55b809dd99f76d8a74f05@cam.ac.uk>
Message-ID: <CAJuCY5zCOv8o0AW+04FosPCx4zfE12u1ApVeRLjCfVp8_ezh_Q@mail.gmail.com>

Dear Tanay,

Try using a different mirror. Pick one from
https://cran.r-project.org/mirrors.html

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op zo 9 jun. 2019 om 19:24 schreef Tanay Ghosh <tg369 at cam.ac.uk>:

> Dear All,
>
> I am using R version 3.5.1 in my Mac (macOS Mojave version 10.14.4).
>
> However, I am unable to install "lme4" package.
>
> I obtained the following:
>
> > install.packages("lme4")
> Installing package into ?/Users/tanayghosh/Library/R/3.5/library?
> (as ?lib? is unspecified)
> Warning: unable to access index for repository
> https://mirrors.ebi.ac.uk/CRAN/src/contrib:
>    cannot open URL 'https://mirrors.ebi.ac.uk/CRAN/src/contrib/PACKAGES'
> Warning: unable to access index for repository
> https://mirrors.ebi.ac.uk/CRAN/bin/macosx/el-capitan/contrib/3.5:
>    cannot open URL
> 'https://mirrors.ebi.ac.uk/CRAN/bin/macosx/el-capitan/contrib/3.5/PACKAGES
> '
> Warning message:
> package ?lme4? is not available (for R version 3.5.1)
>
>
> > sessionInfo()
> R version 3.5.1 (2018-07-02)
> Platform: x86_64-apple-darwin15.6.0 (64-bit)
> Running under: macOS  10.14.4
>
> Matrix products: default
> BLAS:
> /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRblas.0.dylib
> LAPACK:
> /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRlapack.dylib
>
> locale:
> [1] en_GB.UTF-8/en_GB.UTF-8/en_GB.UTF-8/C/en_GB.UTF-8/en_GB.UTF-8
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] nlme_3.1-140
>
> loaded via a namespace (and not attached):
> [1] compiler_3.5.1  tools_3.5.1     grid_3.5.1      lattice_0.20-35
>
>
>
> I am very much looking forward to your help.
>
> Sincerely,
>
> Tanay Ghosh
>
> --
> Dr. Tanay Ghosh, PhD
> Research Associate
> Department of Clinical Neurosciences,
> Wellcome Trust-Medical Research Council Cambridge Stem Cell Institute,
> Clifford Allbutt Building,
> Cambridge Biomedical Campus,
> University of Cambridge,
> Cambridge CB2 0AH
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From cr|@@|e@@@ndro @end|ng |rom gm@||@com  Tue Jun 11 16:38:48 2019
From: cr|@@|e@@@ndro @end|ng |rom gm@||@com (Cristiano Alessandro)
Date: Tue, 11 Jun 2019 09:38:48 -0500
Subject: [R-sig-ME] convergence issues on lme4 and incoherent error messages
Message-ID: <CAHhX7WjUM+g6-b9vYj7rY62USOAN+tXjKL-2zNGc=nPEsAszZw@mail.gmail.com>

Hi all,

I am having trouble fitting a mixed effect model. I keep getting the
following warning, independently on the optimizer that I use (I tried
almost all of them):

Warning messages:
1: 'rBind' is deprecated.
 Since R version 3.2.0, base's rbind() should work fine with S4 objects
2: In optimx.check(par, optcfg$ufn, optcfg$ugr, optcfg$uhess, lower,  :
  Parameters or bounds appear to have different scalings.
  This can cause poor performance in optimization.
  It is important for derivative free methods like BOBYQA, UOBYQA, NEWUOA.
3: Model failed to converge with 5 negative eigenvalues: -2.5e-01 -5.8e-01
-8.2e+01 -9.5e+02 -1.8e+03

This suggests that the optimization did not converge. On the other hand, if
I call summary() of the "fitted" model, I receive (among the other things)
a convergence code = 0, which according to the documentation means that the
optimization has indeed converged. Did the optimization converged or not?

convergence code: 0
Parameters or bounds appear to have different scalings.
  This can cause poor performance in optimization.
  It is important for derivative free methods like BOBYQA, UOBYQA, NEWUOA.

Note that I used 'optimx' ("L-BFGS-B") for this specific run of the
optimization. I also get other weird stuff that I do not understand:
negative entries in the var-cov matrix, which I could not get rid of even
if I simplify the model a lot (see
https://stats.stackexchange.com/questions/408504/variance-covariance-matrix-with-negative-entries-on-mixed-model-fit
, with data). I thought of further simplify the var-cov matrix making it
diagonal, but I am still struggling on how to do that in lme4 (see
https://stats.stackexchange.com/questions/412345/diagonal-var-cov-matrix-for-random-slope-in-lme4
).

Any help is highly appreciated. Thanks!

Cristiano

	[[alternative HTML version deleted]]


From c@c@voeten @end|ng |rom hum@|e|denun|v@n|  Tue Jun 11 19:07:16 2019
From: c@c@voeten @end|ng |rom hum@|e|denun|v@n| (Cesko Voeten)
Date: Tue, 11 Jun 2019 19:07:16 +0200
Subject: [R-sig-ME] 
 convergence issues on lme4 and incoherent error messages
In-Reply-To: <CAHhX7WjUM+g6-b9vYj7rY62USOAN+tXjKL-2zNGc=nPEsAszZw@mail.gmail.com>
References: <CAHhX7WjUM+g6-b9vYj7rY62USOAN+tXjKL-2zNGc=nPEsAszZw@mail.gmail.com>
Message-ID: <d9e1f118-eba6-82ee-1d27-42d1454e0ad4@hum.leidenuniv.nl>

Hi Cristiano,

With respect to your final point: lmer() does not currently support removing correlations between different levels of the same factor. A workaround is to convert your factor to a set of numeric columns, and then use the double-bar syntax ('(factor1+factor2+etc||grouping)'). The conversion from factor to numeric can be done automatically by function lmer_alt() from package afex, so that lmer_alt(y ~ factor + (factor||grouping)) would suffice.

Another option could be to try fitting your model in glmmTMB and use the 'diag(factor|grouping)' syntax.

HTH,
Cesko

Op 11-06-2019 om 16:38 schreef Cristiano Alessandro:
> Hi all,
> 
> I am having trouble fitting a mixed effect model. I keep getting the
> following warning, independently on the optimizer that I use (I tried
> almost all of them):
> 
> Warning messages:
> 1: 'rBind' is deprecated.
>   Since R version 3.2.0, base's rbind() should work fine with S4 objects
> 2: In optimx.check(par, optcfg$ufn, optcfg$ugr, optcfg$uhess, lower,  :
>    Parameters or bounds appear to have different scalings.
>    This can cause poor performance in optimization.
>    It is important for derivative free methods like BOBYQA, UOBYQA, NEWUOA.
> 3: Model failed to converge with 5 negative eigenvalues: -2.5e-01 -5.8e-01
> -8.2e+01 -9.5e+02 -1.8e+03
> 
> This suggests that the optimization did not converge. On the other hand, if
> I call summary() of the "fitted" model, I receive (among the other things)
> a convergence code = 0, which according to the documentation means that the
> optimization has indeed converged. Did the optimization converged or not?
> 
> convergence code: 0
> Parameters or bounds appear to have different scalings.
>    This can cause poor performance in optimization.
>    It is important for derivative free methods like BOBYQA, UOBYQA, NEWUOA.
> 
> Note that I used 'optimx' ("L-BFGS-B") for this specific run of the
> optimization. I also get other weird stuff that I do not understand:
> negative entries in the var-cov matrix, which I could not get rid of even
> if I simplify the model a lot (see
> https://stats.stackexchange.com/questions/408504/variance-covariance-matrix-with-negative-entries-on-mixed-model-fit
> , with data). I thought of further simplify the var-cov matrix making it
> diagonal, but I am still struggling on how to do that in lme4 (see
> https://stats.stackexchange.com/questions/412345/diagonal-var-cov-matrix-for-random-slope-in-lme4
> ).
> 
> Any help is highly appreciated. Thanks!
> 
> Cristiano
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From b|e|||@@|e@@@ndr@ @end|ng |rom gm@||@com  Wed Jun 12 19:16:39 2019
From: b|e|||@@|e@@@ndr@ @end|ng |rom gm@||@com (Alessandra Bielli)
Date: Wed, 12 Jun 2019 18:16:39 +0100
Subject: [R-sig-ME] singularity - differences in model output
Message-ID: <CA+6N3yXAGcZgkyo2zDGZ1-zQMX28ffEOQDu8b1doD5rpVyCcpw@mail.gmail.com>

Hi everyone,

I recently re-ran a model that I wrote about 5 months ago.
The model is a GLMM of the type :

m1 <- glmer(response ~ fixed  + random effect, data = d, family =
"binomial")

At that time, everything ran smoothly, with no error/warning messages.

However I have just run it again and I get a message saying the model is
singular.

1) The first question is, why didn't it happen then? Is it simply because
the package was updated?
I am asking because I need to justify my changes with the reviewers of the
journal where I'd like to publish my study.

2) I used the function isSIngular() to check my model, using the default
tolerance value. How do I decide the tolerance for detecting singularity?

Thank you so much for your help

Alessandra

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Thu Jun 13 06:19:01 2019
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Thu, 13 Jun 2019 14:19:01 +1000
Subject: [R-sig-ME] singularity - differences in model output
In-Reply-To: <CA+6N3yXAGcZgkyo2zDGZ1-zQMX28ffEOQDu8b1doD5rpVyCcpw@mail.gmail.com>
References: <CA+6N3yXAGcZgkyo2zDGZ1-zQMX28ffEOQDu8b1doD5rpVyCcpw@mail.gmail.com>
Message-ID: <CABghstSK2tt0sCbF_JAVxXKo6bTRgNuoDdsTDhb5KhyLDqQUKA@mail.gmail.com>

  This new warning could be due either to changes in reporting or to
slight changes in the optimization defaults. The NEWS file (run
news(package="lme4") from inside R, or see
<https://github.com/lme4/lme4/blob/master/inst/NEWS.Rd>) tells you
what's changed, and when, in the package.

  In the CRAN version (1.1-21) the default tolerances for the
singularity check are *either* 1e-5 (isSingular) or 1e-4 (in the
built-in check); both change to 1e-4 in the development version (see
https://github.com/lme4/lme4/commit/87caef382a784df322cd1f5b3a4b906ffe950cf9
). In principle singular fits only occur when the estimated variance
is *exactly* zero, which is possible in lme4 (because it uses a
box-constrained optimizer with a bound at zero), but checking with a
tolerance of 1e-4 should also identify models that are very close to
singular (and might "really" be singular if there were no numeric
'fuzz' from finite-precision computation).

  The GLMM FAQ has more discussion of singular fits:
http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#singular-models-random-effect-variances-estimated-as-zero-or-correlations-estimated-as---1

  cheers
   Ben Bolker


On Thu, Jun 13, 2019 at 3:17 AM Alessandra Bielli
<bielli.alessandra at gmail.com> wrote:
>
> Hi everyone,
>
> I recently re-ran a model that I wrote about 5 months ago.
> The model is a GLMM of the type :
>
> m1 <- glmer(response ~ fixed  + random effect, data = d, family =
> "binomial")
>
> At that time, everything ran smoothly, with no error/warning messages.
>
> However I have just run it again and I get a message saying the model is
> singular.
>
> 1) The first question is, why didn't it happen then? Is it simply because
> the package was updated?
> I am asking because I need to justify my changes with the reviewers of the
> journal where I'd like to publish my study.
>
> 2) I used the function isSIngular() to check my model, using the default
> tolerance value. How do I decide the tolerance for detecting singularity?
>
> Thank you so much for your help
>
> Alessandra
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbo|ker @end|ng |rom gm@||@com  Thu Jun 13 06:31:35 2019
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Thu, 13 Jun 2019 14:31:35 +1000
Subject: [R-sig-ME] 
 convergence issues on lme4 and incoherent error messages
In-Reply-To: <CAHhX7WjUM+g6-b9vYj7rY62USOAN+tXjKL-2zNGc=nPEsAszZw@mail.gmail.com>
References: <CAHhX7WjUM+g6-b9vYj7rY62USOAN+tXjKL-2zNGc=nPEsAszZw@mail.gmail.com>
Message-ID: <CABghstS51Q4Hc3nfDOLi1R_vG_kDLeRmYvqqCajzV0rMgj=GOw@mail.gmail.com>

  Details below

On Wed, Jun 12, 2019 at 12:38 AM Cristiano Alessandro
<cri.alessandro at gmail.com> wrote:
>
> Hi all,
>
> I am having trouble fitting a mixed effect model. I keep getting the
> following warning, independently on the optimizer that I use (I tried
> almost all of them):
>
> Warning messages:
> 1: 'rBind' is deprecated.
>  Since R version 3.2.0, base's rbind() should work fine with S4 objects

  This warning is harmless; it most likely comes from an outdated
version of lme4 (we fixed it in the devel branch 15 months ago:
https://github.com/lme4/lme4/commit/9d5d433d40408222b290d2780ab6e9e4cec553b9)

> 2: In optimx.check(par, optcfg$ufn, optcfg$ugr, optcfg$uhess, lower,  :
>   Parameters or bounds appear to have different scalings.
>   This can cause poor performance in optimization.
>   It is important for derivative free methods like BOBYQA, UOBYQA, NEWUOA.

   Have you tried scaling & centering the predictor variables?

> 3: Model failed to converge with 5 negative eigenvalues: -2.5e-01 -5.8e-01
> -8.2e+01 -9.5e+02 -1.8e+03
>
> This suggests that the optimization did not converge. On the other hand, if
> I call summary() of the "fitted" model, I receive (among the other things)
> a convergence code = 0, which according to the documentation means that the
> optimization has indeed converged. Did the optimization converged or not?
>
> convergence code: 0

   These do look large/worrying, but could be the result of bad
scaling (see above).  There are two levels of checking for convergence
in lme4: one at the level of the nonlinear optimizer itself (L-BFGS-B,
which gives a convergence code of zero) and a secondary attempt to
estimate the Hessian and scaled gradient at the reported optimum
(which is giving you the "model failed to converge" warning).
?convergence gives much more detail on this subject ...

> Parameters or bounds appear to have different scalings.
>   This can cause poor performance in optimization.
>   It is important for derivative free methods like BOBYQA, UOBYQA, NEWUOA.
>
> Note that I used 'optimx' ("L-BFGS-B") for this specific run of the
> optimization

  I would *not* generally recommend this.  We don't have
analytically/symbolically computed gradients for the mixed-model
likelihood, so derivative-based optimizers like L-BFGS-B will be using
finite differencing to estimate the gradients, which is generally slow
and numerically imprecise.  That's why the default choices are
derivative-free optimizers (BOBYQA, Nelder-Mead etc.).

  I see there's much more discussion at the SO question, I may or may
not have time to check that out.

. I also get other weird stuff that I do not understand:
> negative entries in the var-cov matrix, which I could not get rid of even
> if I simplify the model a lot (see
> https://stats.stackexchange.com/questions/408504/variance-covariance-matrix-with-negative-entries-on-mixed-model-fit
> , with data). I thought of further simplify the var-cov matrix making it
> diagonal, but I am still struggling on how to do that in lme4 (see
> https://stats.stackexchange.com/questions/412345/diagonal-var-cov-matrix-for-random-slope-in-lme4
> ).
>
> Any help is highly appreciated. Thanks!
>
> Cristiano
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From emm@nue|@cur|@ @end|ng |rom p@r|@de@c@rte@@|r  Thu Jun 13 14:45:45 2019
From: emm@nue|@cur|@ @end|ng |rom p@r|@de@c@rte@@|r (Emmanuel Curis)
Date: Thu, 13 Jun 2019 14:45:45 +0200
Subject: [R-sig-ME] lme4 analysis_2ANOVA repeated measure
In-Reply-To: <1905bdf79ddfa731ced2688ee1dbf1a2@cam.ac.uk>
References: <1905bdf79ddfa731ced2688ee1dbf1a2@cam.ac.uk>
Message-ID: <20190613124545.GA14758@info124.pharmacie.univ-paris5.fr>

Hi Tanay,

In your data file, there seems to be nothing like ? subject id ?, but
only time, sex and Atg3 (=Abt3 ?) measure so it's not possible to do
any random-effect modeling.

Besides, you should give more explaination about what is the Atg3
column, because the syntax will change if there are CTs or equivalent
measures [does not look like, except the atypical 31.355 value],
absolute quantities or relative quantities compared to a (set of)
reference genes.

Last, comparing all times to see a time effect is not a very powerful
method, because you quickly increase the number of comparisons, and at
the extreme, the more time you have, the more precise is your time
curve, the more difficult it is to detect anything...

Note however that looking ? by eye ? your data, you can't expect much
since you have a small dataser, huge outliers (31.355, 5.081, 4.804)
and a quite high intra-groupe variability (values ranging from 0.087
to 2.237 for the 3 males at t=7, for instance).

est regards,

On Mon, Jun 10, 2019 at 03:31:53PM +0100, Tanay Ghosh wrote:
? Dear All,
? 
? I wonder if I can ask your advise to analyse this data (attached). Please
? note that some of the values are "NA" i.e. I do not have any measurement
? taken.
? 
? Here I have four different time (days) points. I measured expression of Abt3
? gene at these time points in male and female.
? 
? I want to see if gender wise expression of Atg3 differ at any time point?
? 
? I further want to do a posttest to get p value for Male at time 7 vs female
? at time 7, Male at time 15 vs Female at time 15, and like wise all other
? time points.
? 
? 
? Please could you advise me how to do this analysis using lmer function? I
? would very much appreciate if you please write the commands in R for this
? specific case.
? 
? Thank you in advance for your time.
? 
? 
? Kind regards,
? 
? Tanay
? 
? 
? -- 
? Dr. Tanay Ghosh, PhD
? Research Associate
? Department of Clinical Neurosciences,
? Wellcome Trust-Medical Research Council Cambridge Stem Cell Institute,
? Clifford Allbutt Building,
? Cambridge Biomedical Campus,
? University of Cambridge,
? Cambridge CB2 0AH

? time	Gender	Atg37	Male	0.2127	Male	2.2377	Male	0.0877	Female	0.0927	Female	2.8057	Female	0.10315	Male	0.07115	Male	2.73315	Male	2.41415	Female	0.1515	Female	2.43815	Female	1.43424	Male	0.07924	Male	2.21224	Male	31.35524	Female	0.21124	Female	0.81224	Female	5.081231	Male	0.073231	Male	0.505231	Male	0.737231	Female	0.178231	Female	0.319231	Female	4.804420	Male	0.29420	Male	0.424420	Male	NA420	Female	0.337420	Female	0.966420	Female	NA

? _______________________________________________
? R-sig-mixed-models at r-project.org mailing list
? https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-- 
                                Emmanuel CURIS
                                emmanuel.curis at parisdescartes.fr

Page WWW: http://emmanuel.curis.online.fr/index.html


From cr|@@|e@@@ndro @end|ng |rom gm@||@com  Thu Jun 13 16:28:08 2019
From: cr|@@|e@@@ndro @end|ng |rom gm@||@com (Cristiano Alessandro)
Date: Thu, 13 Jun 2019 09:28:08 -0500
Subject: [R-sig-ME] 
 convergence issues on lme4 and incoherent error messages
In-Reply-To: <CABghstS51Q4Hc3nfDOLi1R_vG_kDLeRmYvqqCajzV0rMgj=GOw@mail.gmail.com>
References: <CAHhX7WjUM+g6-b9vYj7rY62USOAN+tXjKL-2zNGc=nPEsAszZw@mail.gmail.com>
 <CABghstS51Q4Hc3nfDOLi1R_vG_kDLeRmYvqqCajzV0rMgj=GOw@mail.gmail.com>
Message-ID: <CAHhX7WhEi4UvcmtpEPTMAUcJxO+pBWOD8qiscEL-6jP_PWmMFw@mail.gmail.com>

Thanks a lot for your help!

Regarding "centering and scaling". I am not familiar with this; I will
check this out. But the predictor variables are all categorical with "sum"
coding; I am not sure what it means to center and scale a categorical
variable. Is there a theory behind this or a text I could look at?

Best
Cristiano

On Wed, Jun 12, 2019 at 11:31 PM Ben Bolker <bbolker at gmail.com> wrote:

>   Details below
>
> On Wed, Jun 12, 2019 at 12:38 AM Cristiano Alessandro
> <cri.alessandro at gmail.com> wrote:
> >
> > Hi all,
> >
> > I am having trouble fitting a mixed effect model. I keep getting the
> > following warning, independently on the optimizer that I use (I tried
> > almost all of them):
> >
> > Warning messages:
> > 1: 'rBind' is deprecated.
> >  Since R version 3.2.0, base's rbind() should work fine with S4 objects
>
>   This warning is harmless; it most likely comes from an outdated
> version of lme4 (we fixed it in the devel branch 15 months ago:
>
> https://github.com/lme4/lme4/commit/9d5d433d40408222b290d2780ab6e9e4cec553b9
> )
>
> > 2: In optimx.check(par, optcfg$ufn, optcfg$ugr, optcfg$uhess, lower,  :
> >   Parameters or bounds appear to have different scalings.
> >   This can cause poor performance in optimization.
> >   It is important for derivative free methods like BOBYQA, UOBYQA,
> NEWUOA.
>
>    Have you tried scaling & centering the predictor variables?
>
> > 3: Model failed to converge with 5 negative eigenvalues: -2.5e-01
> -5.8e-01
> > -8.2e+01 -9.5e+02 -1.8e+03
> >
> > This suggests that the optimization did not converge. On the other hand,
> if
> > I call summary() of the "fitted" model, I receive (among the other
> things)
> > a convergence code = 0, which according to the documentation means that
> the
> > optimization has indeed converged. Did the optimization converged or not?
> >
> > convergence code: 0
>
>    These do look large/worrying, but could be the result of bad
> scaling (see above).  There are two levels of checking for convergence
> in lme4: one at the level of the nonlinear optimizer itself (L-BFGS-B,
> which gives a convergence code of zero) and a secondary attempt to
> estimate the Hessian and scaled gradient at the reported optimum
> (which is giving you the "model failed to converge" warning).
> ?convergence gives much more detail on this subject ...
>
> > Parameters or bounds appear to have different scalings.
> >   This can cause poor performance in optimization.
> >   It is important for derivative free methods like BOBYQA, UOBYQA,
> NEWUOA.
> >
> > Note that I used 'optimx' ("L-BFGS-B") for this specific run of the
> > optimization
>
>   I would *not* generally recommend this.  We don't have
> analytically/symbolically computed gradients for the mixed-model
> likelihood, so derivative-based optimizers like L-BFGS-B will be using
> finite differencing to estimate the gradients, which is generally slow
> and numerically imprecise.  That's why the default choices are
> derivative-free optimizers (BOBYQA, Nelder-Mead etc.).
>
>   I see there's much more discussion at the SO question, I may or may
> not have time to check that out.
>
> . I also get other weird stuff that I do not understand:
> > negative entries in the var-cov matrix, which I could not get rid of even
> > if I simplify the model a lot (see
> >
> https://stats.stackexchange.com/questions/408504/variance-covariance-matrix-with-negative-entries-on-mixed-model-fit
> > , with data). I thought of further simplify the var-cov matrix making it
> > diagonal, but I am still struggling on how to do that in lme4 (see
> >
> https://stats.stackexchange.com/questions/412345/diagonal-var-cov-matrix-for-random-slope-in-lme4
> > ).
> >
> > Any help is highly appreciated. Thanks!
> >
> > Cristiano
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From b|mono@om @end|ng |rom gm@||@com  Thu Jun 13 17:19:26 2019
From: b|mono@om @end|ng |rom gm@||@com (=?UTF-8?B?UmVuw6k=?=)
Date: Thu, 13 Jun 2019 17:19:26 +0200
Subject: [R-sig-ME] 
 convergence issues on lme4 and incoherent error messages
In-Reply-To: <CAHhX7WhEi4UvcmtpEPTMAUcJxO+pBWOD8qiscEL-6jP_PWmMFw@mail.gmail.com>
References: <CAHhX7WjUM+g6-b9vYj7rY62USOAN+tXjKL-2zNGc=nPEsAszZw@mail.gmail.com>
 <CABghstS51Q4Hc3nfDOLi1R_vG_kDLeRmYvqqCajzV0rMgj=GOw@mail.gmail.com>
 <CAHhX7WhEi4UvcmtpEPTMAUcJxO+pBWOD8qiscEL-6jP_PWmMFw@mail.gmail.com>
Message-ID: <CADcpBHNpQR6DHqCXu1Qh3fCYcoh-JCKrnyYVKZBvSFind893Rg@mail.gmail.com>

Hi, :)

"But the predictor variables are all categorical with "sum"
coding; I am not sure what it means to center and scale a categorical
variable."

Sure means nothing :))
If your predictors are actually categorical, then the model should care
about scaling at all (and should not come up with this).
The implies, that you might want to check, whether the categorical
predictors are actually factorized in the dataframe.
e.g.
dataframe$predictor1<-as.factor(dataframe$predictor1)
dataframe$predictor2<-as.factor(dataframe$predictor2)

or (the same but less affected by how the variable is coded beforehand... )
dataframe$predictor1<-as.factor(as.character(dataframe$predictor1))


Best, Ren?


Am Do., 13. Juni 2019 um 16:27 Uhr schrieb Cristiano Alessandro <
cri.alessandro at gmail.com>:

> Thanks a lot for your help!
>
> Regarding "centering and scaling". I am not familiar with this; I will
> check this out. But the predictor variables are all categorical with "sum"
> coding; I am not sure what it means to center and scale a categorical
> variable. Is there a theory behind this or a text I could look at?
>
> Best
> Cristiano
>
> On Wed, Jun 12, 2019 at 11:31 PM Ben Bolker <bbolker at gmail.com> wrote:
>
> >   Details below
> >
> > On Wed, Jun 12, 2019 at 12:38 AM Cristiano Alessandro
> > <cri.alessandro at gmail.com> wrote:
> > >
> > > Hi all,
> > >
> > > I am having trouble fitting a mixed effect model. I keep getting the
> > > following warning, independently on the optimizer that I use (I tried
> > > almost all of them):
> > >
> > > Warning messages:
> > > 1: 'rBind' is deprecated.
> > >  Since R version 3.2.0, base's rbind() should work fine with S4 objects
> >
> >   This warning is harmless; it most likely comes from an outdated
> > version of lme4 (we fixed it in the devel branch 15 months ago:
> >
> >
> https://github.com/lme4/lme4/commit/9d5d433d40408222b290d2780ab6e9e4cec553b9
> > )
> >
> > > 2: In optimx.check(par, optcfg$ufn, optcfg$ugr, optcfg$uhess, lower,  :
> > >   Parameters or bounds appear to have different scalings.
> > >   This can cause poor performance in optimization.
> > >   It is important for derivative free methods like BOBYQA, UOBYQA,
> > NEWUOA.
> >
> >    Have you tried scaling & centering the predictor variables?
> >
> > > 3: Model failed to converge with 5 negative eigenvalues: -2.5e-01
> > -5.8e-01
> > > -8.2e+01 -9.5e+02 -1.8e+03
> > >
> > > This suggests that the optimization did not converge. On the other
> hand,
> > if
> > > I call summary() of the "fitted" model, I receive (among the other
> > things)
> > > a convergence code = 0, which according to the documentation means that
> > the
> > > optimization has indeed converged. Did the optimization converged or
> not?
> > >
> > > convergence code: 0
> >
> >    These do look large/worrying, but could be the result of bad
> > scaling (see above).  There are two levels of checking for convergence
> > in lme4: one at the level of the nonlinear optimizer itself (L-BFGS-B,
> > which gives a convergence code of zero) and a secondary attempt to
> > estimate the Hessian and scaled gradient at the reported optimum
> > (which is giving you the "model failed to converge" warning).
> > ?convergence gives much more detail on this subject ...
> >
> > > Parameters or bounds appear to have different scalings.
> > >   This can cause poor performance in optimization.
> > >   It is important for derivative free methods like BOBYQA, UOBYQA,
> > NEWUOA.
> > >
> > > Note that I used 'optimx' ("L-BFGS-B") for this specific run of the
> > > optimization
> >
> >   I would *not* generally recommend this.  We don't have
> > analytically/symbolically computed gradients for the mixed-model
> > likelihood, so derivative-based optimizers like L-BFGS-B will be using
> > finite differencing to estimate the gradients, which is generally slow
> > and numerically imprecise.  That's why the default choices are
> > derivative-free optimizers (BOBYQA, Nelder-Mead etc.).
> >
> >   I see there's much more discussion at the SO question, I may or may
> > not have time to check that out.
> >
> > . I also get other weird stuff that I do not understand:
> > > negative entries in the var-cov matrix, which I could not get rid of
> even
> > > if I simplify the model a lot (see
> > >
> >
> https://stats.stackexchange.com/questions/408504/variance-covariance-matrix-with-negative-entries-on-mixed-model-fit
> > > , with data). I thought of further simplify the var-cov matrix making
> it
> > > diagonal, but I am still struggling on how to do that in lme4 (see
> > >
> >
> https://stats.stackexchange.com/questions/412345/diagonal-var-cov-matrix-for-random-slope-in-lme4
> > > ).
> > >
> > > Any help is highly appreciated. Thanks!
> > >
> > > Cristiano
> > >
> > >         [[alternative HTML version deleted]]
> > >
> > > _______________________________________________
> > > R-sig-mixed-models at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From b|mono@om @end|ng |rom gm@||@com  Thu Jun 13 17:20:27 2019
From: b|mono@om @end|ng |rom gm@||@com (=?UTF-8?B?UmVuw6k=?=)
Date: Thu, 13 Jun 2019 17:20:27 +0200
Subject: [R-sig-ME] 
 convergence issues on lme4 and incoherent error messages
In-Reply-To: <CADcpBHNpQR6DHqCXu1Qh3fCYcoh-JCKrnyYVKZBvSFind893Rg@mail.gmail.com>
References: <CAHhX7WjUM+g6-b9vYj7rY62USOAN+tXjKL-2zNGc=nPEsAszZw@mail.gmail.com>
 <CABghstS51Q4Hc3nfDOLi1R_vG_kDLeRmYvqqCajzV0rMgj=GOw@mail.gmail.com>
 <CAHhX7WhEi4UvcmtpEPTMAUcJxO+pBWOD8qiscEL-6jP_PWmMFw@mail.gmail.com>
 <CADcpBHNpQR6DHqCXu1Qh3fCYcoh-JCKrnyYVKZBvSFind893Rg@mail.gmail.com>
Message-ID: <CADcpBHMCMT5io+x1sfbfBUxQc-p70mBTujPiP13mX+c75s-xdA@mail.gmail.com>

sorry... "then the model should [not] care about scaling "

Am Do., 13. Juni 2019 um 17:19 Uhr schrieb Ren? <bimonosom at gmail.com>:

> Hi, :)
>
> "But the predictor variables are all categorical with "sum"
> coding; I am not sure what it means to center and scale a categorical
> variable."
>
> Sure means nothing :))
> If your predictors are actually categorical, then the model should care
> about scaling at all (and should not come up with this).
> The implies, that you might want to check, whether the categorical
> predictors are actually factorized in the dataframe.
> e.g.
> dataframe$predictor1<-as.factor(dataframe$predictor1)
> dataframe$predictor2<-as.factor(dataframe$predictor2)
>
> or (the same but less affected by how the variable is coded beforehand... )
> dataframe$predictor1<-as.factor(as.character(dataframe$predictor1))
>
>
> Best, Ren?
>
>
> Am Do., 13. Juni 2019 um 16:27 Uhr schrieb Cristiano Alessandro <
> cri.alessandro at gmail.com>:
>
>> Thanks a lot for your help!
>>
>> Regarding "centering and scaling". I am not familiar with this; I will
>> check this out. But the predictor variables are all categorical with "sum"
>> coding; I am not sure what it means to center and scale a categorical
>> variable. Is there a theory behind this or a text I could look at?
>>
>> Best
>> Cristiano
>>
>> On Wed, Jun 12, 2019 at 11:31 PM Ben Bolker <bbolker at gmail.com> wrote:
>>
>> >   Details below
>> >
>> > On Wed, Jun 12, 2019 at 12:38 AM Cristiano Alessandro
>> > <cri.alessandro at gmail.com> wrote:
>> > >
>> > > Hi all,
>> > >
>> > > I am having trouble fitting a mixed effect model. I keep getting the
>> > > following warning, independently on the optimizer that I use (I tried
>> > > almost all of them):
>> > >
>> > > Warning messages:
>> > > 1: 'rBind' is deprecated.
>> > >  Since R version 3.2.0, base's rbind() should work fine with S4
>> objects
>> >
>> >   This warning is harmless; it most likely comes from an outdated
>> > version of lme4 (we fixed it in the devel branch 15 months ago:
>> >
>> >
>> https://github.com/lme4/lme4/commit/9d5d433d40408222b290d2780ab6e9e4cec553b9
>> > )
>> >
>> > > 2: In optimx.check(par, optcfg$ufn, optcfg$ugr, optcfg$uhess, lower,
>> :
>> > >   Parameters or bounds appear to have different scalings.
>> > >   This can cause poor performance in optimization.
>> > >   It is important for derivative free methods like BOBYQA, UOBYQA,
>> > NEWUOA.
>> >
>> >    Have you tried scaling & centering the predictor variables?
>> >
>> > > 3: Model failed to converge with 5 negative eigenvalues: -2.5e-01
>> > -5.8e-01
>> > > -8.2e+01 -9.5e+02 -1.8e+03
>> > >
>> > > This suggests that the optimization did not converge. On the other
>> hand,
>> > if
>> > > I call summary() of the "fitted" model, I receive (among the other
>> > things)
>> > > a convergence code = 0, which according to the documentation means
>> that
>> > the
>> > > optimization has indeed converged. Did the optimization converged or
>> not?
>> > >
>> > > convergence code: 0
>> >
>> >    These do look large/worrying, but could be the result of bad
>> > scaling (see above).  There are two levels of checking for convergence
>> > in lme4: one at the level of the nonlinear optimizer itself (L-BFGS-B,
>> > which gives a convergence code of zero) and a secondary attempt to
>> > estimate the Hessian and scaled gradient at the reported optimum
>> > (which is giving you the "model failed to converge" warning).
>> > ?convergence gives much more detail on this subject ...
>> >
>> > > Parameters or bounds appear to have different scalings.
>> > >   This can cause poor performance in optimization.
>> > >   It is important for derivative free methods like BOBYQA, UOBYQA,
>> > NEWUOA.
>> > >
>> > > Note that I used 'optimx' ("L-BFGS-B") for this specific run of the
>> > > optimization
>> >
>> >   I would *not* generally recommend this.  We don't have
>> > analytically/symbolically computed gradients for the mixed-model
>> > likelihood, so derivative-based optimizers like L-BFGS-B will be using
>> > finite differencing to estimate the gradients, which is generally slow
>> > and numerically imprecise.  That's why the default choices are
>> > derivative-free optimizers (BOBYQA, Nelder-Mead etc.).
>> >
>> >   I see there's much more discussion at the SO question, I may or may
>> > not have time to check that out.
>> >
>> > . I also get other weird stuff that I do not understand:
>> > > negative entries in the var-cov matrix, which I could not get rid of
>> even
>> > > if I simplify the model a lot (see
>> > >
>> >
>> https://stats.stackexchange.com/questions/408504/variance-covariance-matrix-with-negative-entries-on-mixed-model-fit
>> > > , with data). I thought of further simplify the var-cov matrix making
>> it
>> > > diagonal, but I am still struggling on how to do that in lme4 (see
>> > >
>> >
>> https://stats.stackexchange.com/questions/412345/diagonal-var-cov-matrix-for-random-slope-in-lme4
>> > > ).
>> > >
>> > > Any help is highly appreciated. Thanks!
>> > >
>> > > Cristiano
>> > >
>> > >         [[alternative HTML version deleted]]
>> > >
>> > > _______________________________________________
>> > > R-sig-mixed-models at r-project.org mailing list
>> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>

	[[alternative HTML version deleted]]


From cr|@@|e@@@ndro @end|ng |rom gm@||@com  Thu Jun 13 19:02:35 2019
From: cr|@@|e@@@ndro @end|ng |rom gm@||@com (Cristiano Alessandro)
Date: Thu, 13 Jun 2019 12:02:35 -0500
Subject: [R-sig-ME] 
 convergence issues on lme4 and incoherent error messages
In-Reply-To: <CADcpBHMCMT5io+x1sfbfBUxQc-p70mBTujPiP13mX+c75s-xdA@mail.gmail.com>
References: <CAHhX7WjUM+g6-b9vYj7rY62USOAN+tXjKL-2zNGc=nPEsAszZw@mail.gmail.com>
 <CABghstS51Q4Hc3nfDOLi1R_vG_kDLeRmYvqqCajzV0rMgj=GOw@mail.gmail.com>
 <CAHhX7WhEi4UvcmtpEPTMAUcJxO+pBWOD8qiscEL-6jP_PWmMFw@mail.gmail.com>
 <CADcpBHNpQR6DHqCXu1Qh3fCYcoh-JCKrnyYVKZBvSFind893Rg@mail.gmail.com>
 <CADcpBHMCMT5io+x1sfbfBUxQc-p70mBTujPiP13mX+c75s-xdA@mail.gmail.com>
Message-ID: <CAHhX7WgGSh32+JpWD5YQXYrd_bqvqDvwAM2Wd0wDWTePDnQAKg@mail.gmail.com>

Thanks! I do have the call:

dataframe$predictor1<-as.factor(dataframe$predictor1)
dataframe$predictor2<-as.factor(dataframe$predictor2)

at the beginning of my code.
Cristiano

On Thu, Jun 13, 2019 at 10:20 AM Ren? <bimonosom at gmail.com> wrote:

> sorry... "then the model should [not] care about scaling "
>
> Am Do., 13. Juni 2019 um 17:19 Uhr schrieb Ren? <bimonosom at gmail.com>:
>
>> Hi, :)
>>
>> "But the predictor variables are all categorical with "sum"
>> coding; I am not sure what it means to center and scale a categorical
>> variable."
>>
>> Sure means nothing :))
>> If your predictors are actually categorical, then the model should care
>> about scaling at all (and should not come up with this).
>> The implies, that you might want to check, whether the categorical
>> predictors are actually factorized in the dataframe.
>> e.g.
>> dataframe$predictor1<-as.factor(dataframe$predictor1)
>> dataframe$predictor2<-as.factor(dataframe$predictor2)
>>
>> or (the same but less affected by how the variable is coded beforehand...
>> )
>> dataframe$predictor1<-as.factor(as.character(dataframe$predictor1))
>>
>>
>> Best, Ren?
>>
>>
>> Am Do., 13. Juni 2019 um 16:27 Uhr schrieb Cristiano Alessandro <
>> cri.alessandro at gmail.com>:
>>
>>> Thanks a lot for your help!
>>>
>>> Regarding "centering and scaling". I am not familiar with this; I will
>>> check this out. But the predictor variables are all categorical with
>>> "sum"
>>> coding; I am not sure what it means to center and scale a categorical
>>> variable. Is there a theory behind this or a text I could look at?
>>>
>>> Best
>>> Cristiano
>>>
>>> On Wed, Jun 12, 2019 at 11:31 PM Ben Bolker <bbolker at gmail.com> wrote:
>>>
>>> >   Details below
>>> >
>>> > On Wed, Jun 12, 2019 at 12:38 AM Cristiano Alessandro
>>> > <cri.alessandro at gmail.com> wrote:
>>> > >
>>> > > Hi all,
>>> > >
>>> > > I am having trouble fitting a mixed effect model. I keep getting the
>>> > > following warning, independently on the optimizer that I use (I tried
>>> > > almost all of them):
>>> > >
>>> > > Warning messages:
>>> > > 1: 'rBind' is deprecated.
>>> > >  Since R version 3.2.0, base's rbind() should work fine with S4
>>> objects
>>> >
>>> >   This warning is harmless; it most likely comes from an outdated
>>> > version of lme4 (we fixed it in the devel branch 15 months ago:
>>> >
>>> >
>>> https://github.com/lme4/lme4/commit/9d5d433d40408222b290d2780ab6e9e4cec553b9
>>> > )
>>> >
>>> > > 2: In optimx.check(par, optcfg$ufn, optcfg$ugr, optcfg$uhess,
>>> lower,  :
>>> > >   Parameters or bounds appear to have different scalings.
>>> > >   This can cause poor performance in optimization.
>>> > >   It is important for derivative free methods like BOBYQA, UOBYQA,
>>> > NEWUOA.
>>> >
>>> >    Have you tried scaling & centering the predictor variables?
>>> >
>>> > > 3: Model failed to converge with 5 negative eigenvalues: -2.5e-01
>>> > -5.8e-01
>>> > > -8.2e+01 -9.5e+02 -1.8e+03
>>> > >
>>> > > This suggests that the optimization did not converge. On the other
>>> hand,
>>> > if
>>> > > I call summary() of the "fitted" model, I receive (among the other
>>> > things)
>>> > > a convergence code = 0, which according to the documentation means
>>> that
>>> > the
>>> > > optimization has indeed converged. Did the optimization converged or
>>> not?
>>> > >
>>> > > convergence code: 0
>>> >
>>> >    These do look large/worrying, but could be the result of bad
>>> > scaling (see above).  There are two levels of checking for convergence
>>> > in lme4: one at the level of the nonlinear optimizer itself (L-BFGS-B,
>>> > which gives a convergence code of zero) and a secondary attempt to
>>> > estimate the Hessian and scaled gradient at the reported optimum
>>> > (which is giving you the "model failed to converge" warning).
>>> > ?convergence gives much more detail on this subject ...
>>> >
>>> > > Parameters or bounds appear to have different scalings.
>>> > >   This can cause poor performance in optimization.
>>> > >   It is important for derivative free methods like BOBYQA, UOBYQA,
>>> > NEWUOA.
>>> > >
>>> > > Note that I used 'optimx' ("L-BFGS-B") for this specific run of the
>>> > > optimization
>>> >
>>> >   I would *not* generally recommend this.  We don't have
>>> > analytically/symbolically computed gradients for the mixed-model
>>> > likelihood, so derivative-based optimizers like L-BFGS-B will be using
>>> > finite differencing to estimate the gradients, which is generally slow
>>> > and numerically imprecise.  That's why the default choices are
>>> > derivative-free optimizers (BOBYQA, Nelder-Mead etc.).
>>> >
>>> >   I see there's much more discussion at the SO question, I may or may
>>> > not have time to check that out.
>>> >
>>> > . I also get other weird stuff that I do not understand:
>>> > > negative entries in the var-cov matrix, which I could not get rid of
>>> even
>>> > > if I simplify the model a lot (see
>>> > >
>>> >
>>> https://stats.stackexchange.com/questions/408504/variance-covariance-matrix-with-negative-entries-on-mixed-model-fit
>>> > > , with data). I thought of further simplify the var-cov matrix
>>> making it
>>> > > diagonal, but I am still struggling on how to do that in lme4 (see
>>> > >
>>> >
>>> https://stats.stackexchange.com/questions/412345/diagonal-var-cov-matrix-for-random-slope-in-lme4
>>> > > ).
>>> > >
>>> > > Any help is highly appreciated. Thanks!
>>> > >
>>> > > Cristiano
>>> > >
>>> > >         [[alternative HTML version deleted]]
>>> > >
>>> > > _______________________________________________
>>> > > R-sig-mixed-models at r-project.org mailing list
>>> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> >
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Fri Jun 14 00:29:56 2019
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Thu, 13 Jun 2019 18:29:56 -0400
Subject: [R-sig-ME] 
 convergence issues on lme4 and incoherent error messages
In-Reply-To: <CAHhX7WgGSh32+JpWD5YQXYrd_bqvqDvwAM2Wd0wDWTePDnQAKg@mail.gmail.com>
References: <CAHhX7WjUM+g6-b9vYj7rY62USOAN+tXjKL-2zNGc=nPEsAszZw@mail.gmail.com>
 <CABghstS51Q4Hc3nfDOLi1R_vG_kDLeRmYvqqCajzV0rMgj=GOw@mail.gmail.com>
 <CAHhX7WhEi4UvcmtpEPTMAUcJxO+pBWOD8qiscEL-6jP_PWmMFw@mail.gmail.com>
 <CADcpBHNpQR6DHqCXu1Qh3fCYcoh-JCKrnyYVKZBvSFind893Rg@mail.gmail.com>
 <CADcpBHMCMT5io+x1sfbfBUxQc-p70mBTujPiP13mX+c75s-xdA@mail.gmail.com>
 <CAHhX7WgGSh32+JpWD5YQXYrd_bqvqDvwAM2Wd0wDWTePDnQAKg@mail.gmail.com>
Message-ID: <0c3d2338-6b4c-5daf-502c-688751bc0aec@gmail.com>


  The only other think I can think of is that you may have a *complete
separation* issue or near-complete separation, i.e. some combinations of
predictor variables may have responses that are all-zero or all-one ...

On 2019-06-13 1:02 p.m., Cristiano Alessandro wrote:
> Thanks! I do have the call:
> 
> dataframe$predictor1<-as.factor(dataframe$predictor1)
> dataframe$predictor2<-as.factor(dataframe$predictor2)
> 
> at the beginning of my code.
> Cristiano
> 
> On Thu, Jun 13, 2019 at 10:20 AM Ren? <bimonosom at gmail.com
> <mailto:bimonosom at gmail.com>> wrote:
> 
>     sorry... "then the model should [not] care about scaling "
> 
>     Am Do., 13. Juni 2019 um 17:19?Uhr schrieb Ren? <bimonosom at gmail.com
>     <mailto:bimonosom at gmail.com>>:
> 
>         Hi, :)
> 
>         "But the predictor variables are all categorical with "sum"
>         coding; I am not sure what it means to center and scale a
>         categorical
>         variable."
> 
>         Sure means nothing :))
>         If your predictors are actually categorical, then the model
>         should care about scaling at all (and should not come up with
>         this).?
>         The implies, that you might want to check, whether the
>         categorical predictors are actually factorized in the dataframe.
>         e.g.
>         dataframe$predictor1<-as.factor(dataframe$predictor1)
>         dataframe$predictor2<-as.factor(dataframe$predictor2)
> 
>         or (the same but less affected by how the variable is coded
>         beforehand... )
>         dataframe$predictor1<-as.factor(as.character(dataframe$predictor1))
> 
> 
>         Best, Ren?
> 
> 
>         Am Do., 13. Juni 2019 um 16:27?Uhr schrieb Cristiano Alessandro
>         <cri.alessandro at gmail.com <mailto:cri.alessandro at gmail.com>>:
> 
>             Thanks a lot for your help!
> 
>             Regarding "centering and scaling". I am not familiar with
>             this; I will
>             check this out. But the predictor variables are all
>             categorical with "sum"
>             coding; I am not sure what it means to center and scale a
>             categorical
>             variable. Is there a theory behind this or a text I could
>             look at?
> 
>             Best
>             Cristiano
> 
>             On Wed, Jun 12, 2019 at 11:31 PM Ben Bolker
>             <bbolker at gmail.com <mailto:bbolker at gmail.com>> wrote:
> 
>             >? ?Details below
>             >
>             > On Wed, Jun 12, 2019 at 12:38 AM Cristiano Alessandro
>             > <cri.alessandro at gmail.com
>             <mailto:cri.alessandro at gmail.com>> wrote:
>             > >
>             > > Hi all,
>             > >
>             > > I am having trouble fitting a mixed effect model. I keep
>             getting the
>             > > following warning, independently on the optimizer that I
>             use (I tried
>             > > almost all of them):
>             > >
>             > > Warning messages:
>             > > 1: 'rBind' is deprecated.
>             > >? Since R version 3.2.0, base's rbind() should work fine
>             with S4 objects
>             >
>             >? ?This warning is harmless; it most likely comes from an
>             outdated
>             > version of lme4 (we fixed it in the devel branch 15 months
>             ago:
>             >
>             >
>             https://github.com/lme4/lme4/commit/9d5d433d40408222b290d2780ab6e9e4cec553b9
>             > )
>             >
>             > > 2: In optimx.check(par, optcfg$ufn, optcfg$ugr,
>             optcfg$uhess, lower,? :
>             > >? ?Parameters or bounds appear to have different scalings.
>             > >? ?This can cause poor performance in optimization.
>             > >? ?It is important for derivative free methods like
>             BOBYQA, UOBYQA,
>             > NEWUOA.
>             >
>             >? ? Have you tried scaling & centering the predictor variables?
>             >
>             > > 3: Model failed to converge with 5 negative eigenvalues:
>             -2.5e-01
>             > -5.8e-01
>             > > -8.2e+01 -9.5e+02 -1.8e+03
>             > >
>             > > This suggests that the optimization did not converge. On
>             the other hand,
>             > if
>             > > I call summary() of the "fitted" model, I receive (among
>             the other
>             > things)
>             > > a convergence code = 0, which according to the
>             documentation means that
>             > the
>             > > optimization has indeed converged. Did the optimization
>             converged or not?
>             > >
>             > > convergence code: 0
>             >
>             >? ? These do look large/worrying, but could be the result
>             of bad
>             > scaling (see above).? There are two levels of checking for
>             convergence
>             > in lme4: one at the level of the nonlinear optimizer
>             itself (L-BFGS-B,
>             > which gives a convergence code of zero) and a secondary
>             attempt to
>             > estimate the Hessian and scaled gradient at the reported
>             optimum
>             > (which is giving you the "model failed to converge" warning).
>             > ?convergence gives much more detail on this subject ...
>             >
>             > > Parameters or bounds appear to have different scalings.
>             > >? ?This can cause poor performance in optimization.
>             > >? ?It is important for derivative free methods like
>             BOBYQA, UOBYQA,
>             > NEWUOA.
>             > >
>             > > Note that I used 'optimx' ("L-BFGS-B") for this specific
>             run of the
>             > > optimization
>             >
>             >? ?I would *not* generally recommend this.? We don't have
>             > analytically/symbolically computed gradients for the
>             mixed-model
>             > likelihood, so derivative-based optimizers like L-BFGS-B
>             will be using
>             > finite differencing to estimate the gradients, which is
>             generally slow
>             > and numerically imprecise.? That's why the default choices are
>             > derivative-free optimizers (BOBYQA, Nelder-Mead etc.).
>             >
>             >? ?I see there's much more discussion at the SO question, I
>             may or may
>             > not have time to check that out.
>             >
>             > . I also get other weird stuff that I do not understand:
>             > > negative entries in the var-cov matrix, which I could
>             not get rid of even
>             > > if I simplify the model a lot (see
>             > >
>             >
>             https://stats.stackexchange.com/questions/408504/variance-covariance-matrix-with-negative-entries-on-mixed-model-fit
>             > > , with data). I thought of further simplify the var-cov
>             matrix making it
>             > > diagonal, but I am still struggling on how to do that in
>             lme4 (see
>             > >
>             >
>             https://stats.stackexchange.com/questions/412345/diagonal-var-cov-matrix-for-random-slope-in-lme4
>             > > ).
>             > >
>             > > Any help is highly appreciated. Thanks!
>             > >
>             > > Cristiano
>             > >
>             > >? ? ? ? ?[[alternative HTML version deleted]]
>             > >
>             > > _______________________________________________
>             > > R-sig-mixed-models at r-project.org
>             <mailto:R-sig-mixed-models at r-project.org> mailing list
>             > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>             >
> 
>             ? ? ? ? [[alternative HTML version deleted]]
> 
>             _______________________________________________
>             R-sig-mixed-models at r-project.org
>             <mailto:R-sig-mixed-models at r-project.org> mailing list
>             https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From cr|@@|e@@@ndro @end|ng |rom gm@||@com  Fri Jun 14 00:58:04 2019
From: cr|@@|e@@@ndro @end|ng |rom gm@||@com (Cristiano Alessandro)
Date: Thu, 13 Jun 2019 17:58:04 -0500
Subject: [R-sig-ME] 
 convergence issues on lme4 and incoherent error messages
In-Reply-To: <0c3d2338-6b4c-5daf-502c-688751bc0aec@gmail.com>
References: <CAHhX7WjUM+g6-b9vYj7rY62USOAN+tXjKL-2zNGc=nPEsAszZw@mail.gmail.com>
 <CABghstS51Q4Hc3nfDOLi1R_vG_kDLeRmYvqqCajzV0rMgj=GOw@mail.gmail.com>
 <CAHhX7WhEi4UvcmtpEPTMAUcJxO+pBWOD8qiscEL-6jP_PWmMFw@mail.gmail.com>
 <CADcpBHNpQR6DHqCXu1Qh3fCYcoh-JCKrnyYVKZBvSFind893Rg@mail.gmail.com>
 <CADcpBHMCMT5io+x1sfbfBUxQc-p70mBTujPiP13mX+c75s-xdA@mail.gmail.com>
 <CAHhX7WgGSh32+JpWD5YQXYrd_bqvqDvwAM2Wd0wDWTePDnQAKg@mail.gmail.com>
 <0c3d2338-6b4c-5daf-502c-688751bc0aec@gmail.com>
Message-ID: <CAHhX7WiymVFe1JH79OHjthGMhZLbPPDxETq3h-4ECm9_w068tA@mail.gmail.com>

This does not happen. However, there are combinations of predictor
variables that *for some subjects* have no data on the response, as
explained here:
https://stats.stackexchange.com/questions/412703/zeroed-random-effects-after-fitting-a-mixed-effect-model?noredirect=1#comment770806_412703

Cristiano

On Thu, Jun 13, 2019 at 5:30 PM Ben Bolker <bbolker at gmail.com> wrote:

>
>   The only other think I can think of is that you may have a *complete
> separation* issue or near-complete separation, i.e. some combinations of
> predictor variables may have responses that are all-zero or all-one ...
>
> On 2019-06-13 1:02 p.m., Cristiano Alessandro wrote:
> > Thanks! I do have the call:
> >
> > dataframe$predictor1<-as.factor(dataframe$predictor1)
> > dataframe$predictor2<-as.factor(dataframe$predictor2)
> >
> > at the beginning of my code.
> > Cristiano
> >
> > On Thu, Jun 13, 2019 at 10:20 AM Ren? <bimonosom at gmail.com
> > <mailto:bimonosom at gmail.com>> wrote:
> >
> >     sorry... "then the model should [not] care about scaling "
> >
> >     Am Do., 13. Juni 2019 um 17:19 Uhr schrieb Ren? <bimonosom at gmail.com
> >     <mailto:bimonosom at gmail.com>>:
> >
> >         Hi, :)
> >
> >         "But the predictor variables are all categorical with "sum"
> >         coding; I am not sure what it means to center and scale a
> >         categorical
> >         variable."
> >
> >         Sure means nothing :))
> >         If your predictors are actually categorical, then the model
> >         should care about scaling at all (and should not come up with
> >         this).
> >         The implies, that you might want to check, whether the
> >         categorical predictors are actually factorized in the dataframe.
> >         e.g.
> >         dataframe$predictor1<-as.factor(dataframe$predictor1)
> >         dataframe$predictor2<-as.factor(dataframe$predictor2)
> >
> >         or (the same but less affected by how the variable is coded
> >         beforehand... )
> >
>  dataframe$predictor1<-as.factor(as.character(dataframe$predictor1))
> >
> >
> >         Best, Ren?
> >
> >
> >         Am Do., 13. Juni 2019 um 16:27 Uhr schrieb Cristiano Alessandro
> >         <cri.alessandro at gmail.com <mailto:cri.alessandro at gmail.com>>:
> >
> >             Thanks a lot for your help!
> >
> >             Regarding "centering and scaling". I am not familiar with
> >             this; I will
> >             check this out. But the predictor variables are all
> >             categorical with "sum"
> >             coding; I am not sure what it means to center and scale a
> >             categorical
> >             variable. Is there a theory behind this or a text I could
> >             look at?
> >
> >             Best
> >             Cristiano
> >
> >             On Wed, Jun 12, 2019 at 11:31 PM Ben Bolker
> >             <bbolker at gmail.com <mailto:bbolker at gmail.com>> wrote:
> >
> >             >   Details below
> >             >
> >             > On Wed, Jun 12, 2019 at 12:38 AM Cristiano Alessandro
> >             > <cri.alessandro at gmail.com
> >             <mailto:cri.alessandro at gmail.com>> wrote:
> >             > >
> >             > > Hi all,
> >             > >
> >             > > I am having trouble fitting a mixed effect model. I keep
> >             getting the
> >             > > following warning, independently on the optimizer that I
> >             use (I tried
> >             > > almost all of them):
> >             > >
> >             > > Warning messages:
> >             > > 1: 'rBind' is deprecated.
> >             > >  Since R version 3.2.0, base's rbind() should work fine
> >             with S4 objects
> >             >
> >             >   This warning is harmless; it most likely comes from an
> >             outdated
> >             > version of lme4 (we fixed it in the devel branch 15 months
> >             ago:
> >             >
> >             >
> >
> https://github.com/lme4/lme4/commit/9d5d433d40408222b290d2780ab6e9e4cec553b9
> >             > )
> >             >
> >             > > 2: In optimx.check(par, optcfg$ufn, optcfg$ugr,
> >             optcfg$uhess, lower,  :
> >             > >   Parameters or bounds appear to have different scalings.
> >             > >   This can cause poor performance in optimization.
> >             > >   It is important for derivative free methods like
> >             BOBYQA, UOBYQA,
> >             > NEWUOA.
> >             >
> >             >    Have you tried scaling & centering the predictor
> variables?
> >             >
> >             > > 3: Model failed to converge with 5 negative eigenvalues:
> >             -2.5e-01
> >             > -5.8e-01
> >             > > -8.2e+01 -9.5e+02 -1.8e+03
> >             > >
> >             > > This suggests that the optimization did not converge. On
> >             the other hand,
> >             > if
> >             > > I call summary() of the "fitted" model, I receive (among
> >             the other
> >             > things)
> >             > > a convergence code = 0, which according to the
> >             documentation means that
> >             > the
> >             > > optimization has indeed converged. Did the optimization
> >             converged or not?
> >             > >
> >             > > convergence code: 0
> >             >
> >             >    These do look large/worrying, but could be the result
> >             of bad
> >             > scaling (see above).  There are two levels of checking for
> >             convergence
> >             > in lme4: one at the level of the nonlinear optimizer
> >             itself (L-BFGS-B,
> >             > which gives a convergence code of zero) and a secondary
> >             attempt to
> >             > estimate the Hessian and scaled gradient at the reported
> >             optimum
> >             > (which is giving you the "model failed to converge"
> warning).
> >             > ?convergence gives much more detail on this subject ...
> >             >
> >             > > Parameters or bounds appear to have different scalings.
> >             > >   This can cause poor performance in optimization.
> >             > >   It is important for derivative free methods like
> >             BOBYQA, UOBYQA,
> >             > NEWUOA.
> >             > >
> >             > > Note that I used 'optimx' ("L-BFGS-B") for this specific
> >             run of the
> >             > > optimization
> >             >
> >             >   I would *not* generally recommend this.  We don't have
> >             > analytically/symbolically computed gradients for the
> >             mixed-model
> >             > likelihood, so derivative-based optimizers like L-BFGS-B
> >             will be using
> >             > finite differencing to estimate the gradients, which is
> >             generally slow
> >             > and numerically imprecise.  That's why the default choices
> are
> >             > derivative-free optimizers (BOBYQA, Nelder-Mead etc.).
> >             >
> >             >   I see there's much more discussion at the SO question, I
> >             may or may
> >             > not have time to check that out.
> >             >
> >             > . I also get other weird stuff that I do not understand:
> >             > > negative entries in the var-cov matrix, which I could
> >             not get rid of even
> >             > > if I simplify the model a lot (see
> >             > >
> >             >
> >
> https://stats.stackexchange.com/questions/408504/variance-covariance-matrix-with-negative-entries-on-mixed-model-fit
> >             > > , with data). I thought of further simplify the var-cov
> >             matrix making it
> >             > > diagonal, but I am still struggling on how to do that in
> >             lme4 (see
> >             > >
> >             >
> >
> https://stats.stackexchange.com/questions/412345/diagonal-var-cov-matrix-for-random-slope-in-lme4
> >             > > ).
> >             > >
> >             > > Any help is highly appreciated. Thanks!
> >             > >
> >             > > Cristiano
> >             > >
> >             > >         [[alternative HTML version deleted]]
> >             > >
> >             > > _______________________________________________
> >             > > R-sig-mixed-models at r-project.org
> >             <mailto:R-sig-mixed-models at r-project.org> mailing list
> >             > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >             >
> >
> >                     [[alternative HTML version deleted]]
> >
> >             _______________________________________________
> >             R-sig-mixed-models at r-project.org
> >             <mailto:R-sig-mixed-models at r-project.org> mailing list
> >             https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>

	[[alternative HTML version deleted]]


From D@v|d@Du||y @end|ng |rom q|mrbergho|er@edu@@u  Fri Jun 14 03:36:10 2019
From: D@v|d@Du||y @end|ng |rom q|mrbergho|er@edu@@u (David Duffy)
Date: Fri, 14 Jun 2019 01:36:10 +0000
Subject: [R-sig-ME] 
 convergence issues on lme4 and incoherent error messages
In-Reply-To: <CAHhX7WiymVFe1JH79OHjthGMhZLbPPDxETq3h-4ECm9_w068tA@mail.gmail.com>
References: <CAHhX7WjUM+g6-b9vYj7rY62USOAN+tXjKL-2zNGc=nPEsAszZw@mail.gmail.com>
 <CABghstS51Q4Hc3nfDOLi1R_vG_kDLeRmYvqqCajzV0rMgj=GOw@mail.gmail.com>
 <CAHhX7WhEi4UvcmtpEPTMAUcJxO+pBWOD8qiscEL-6jP_PWmMFw@mail.gmail.com>
 <CADcpBHNpQR6DHqCXu1Qh3fCYcoh-JCKrnyYVKZBvSFind893Rg@mail.gmail.com>
 <CADcpBHMCMT5io+x1sfbfBUxQc-p70mBTujPiP13mX+c75s-xdA@mail.gmail.com>
 <CAHhX7WgGSh32+JpWD5YQXYrd_bqvqDvwAM2Wd0wDWTePDnQAKg@mail.gmail.com>
 <0c3d2338-6b4c-5daf-502c-688751bc0aec@gmail.com>,
 <CAHhX7WiymVFe1JH79OHjthGMhZLbPPDxETq3h-4ECm9_w068tA@mail.gmail.com>
Message-ID: <4737E17E7C8C3C4A8B5C1CE5346371D4A8537724@EXCH06S.adqimr.ad.lan>

FWIW, on my machine, 

lmer(cc_marg ~  mPair*spd_des + (1|cycle) + (1|ratID), data=dat)

runs without complaint. It's only when I add in mPair as fixed and random that I get problems. I notice that cycle has a *lot* of levels,and the distribution of cc_marg is pretty skewed. I always have trouble understanding measurement models in a lmer formula - mPair are six different measures, is that right? If that is the case, you might cross-check your results by running in MCMCglmm as an explicit multivariate model, and getting the same answers.

Cheers, David Duffy.

From b|mono@om @end|ng |rom gm@||@com  Fri Jun 14 11:08:53 2019
From: b|mono@om @end|ng |rom gm@||@com (=?UTF-8?B?UmVuw6k=?=)
Date: Fri, 14 Jun 2019 11:08:53 +0200
Subject: [R-sig-ME] 
 convergence issues on lme4 and incoherent error messages
In-Reply-To: <4737E17E7C8C3C4A8B5C1CE5346371D4A8537724@EXCH06S.adqimr.ad.lan>
References: <CAHhX7WjUM+g6-b9vYj7rY62USOAN+tXjKL-2zNGc=nPEsAszZw@mail.gmail.com>
 <CABghstS51Q4Hc3nfDOLi1R_vG_kDLeRmYvqqCajzV0rMgj=GOw@mail.gmail.com>
 <CAHhX7WhEi4UvcmtpEPTMAUcJxO+pBWOD8qiscEL-6jP_PWmMFw@mail.gmail.com>
 <CADcpBHNpQR6DHqCXu1Qh3fCYcoh-JCKrnyYVKZBvSFind893Rg@mail.gmail.com>
 <CADcpBHMCMT5io+x1sfbfBUxQc-p70mBTujPiP13mX+c75s-xdA@mail.gmail.com>
 <CAHhX7WgGSh32+JpWD5YQXYrd_bqvqDvwAM2Wd0wDWTePDnQAKg@mail.gmail.com>
 <0c3d2338-6b4c-5daf-502c-688751bc0aec@gmail.com>
 <CAHhX7WiymVFe1JH79OHjthGMhZLbPPDxETq3h-4ECm9_w068tA@mail.gmail.com>
 <4737E17E7C8C3C4A8B5C1CE5346371D4A8537724@EXCH06S.adqimr.ad.lan>
Message-ID: <CADcpBHOZugo2+gvbM9VGnX4n5=cK9uvRfPs3XYhf6r6xagOHww@mail.gmail.com>

Ah now I think of the following:
Estimating by-subject random slopes necessarily requires that the random
slope (i.e. in all within-subject design cells) is measured on each
subject. If, as you say, there are measurements missing in some
design-cells for some subjects, then, actually, estimating the variance of
fixed effects between subjects (just another word for by-subject random
slopes) becomes partially the same as measuring the fixed effect itself,
which is 'bad'.  Furthermore, this might be similarly troubling when
estimating by-subject intercepts, but for a slightly different reason,
namely, (lets make it extreme) if half of the subjects have measures in all
design cells, while the other half has only measures in some-design cells,
then what would you expect how the intercepts are distributed (i.e. the
subjects average response deviation from the grand mean), if there are
systematic differences between the means in the design-cells? The a priori
answer is, "probably not Gaussian", which is again 'bad'  :))

I would suggest to adjust the model-definition to reflect the fact that
there are cell-measurements missing for some subjects (regardless of
whether a model converges or not, but just because, this would be the only
way to meaningfully interpret the model).
I think this should work:
Let's take the model from the last link you posted

cc_marg ~ mPair*spd_des + diag(mPair:spd_des|ratID)

Define a (-numeric-) variable (say "cell_exists") in the data frame which
codes whether a subject (for all observations by that subject) has
measurements in all cells (coded as 1), or not (coded as 0), such that all
subjects of which you speak have missing data in some cells are 0.
Then:

cc_marg ~ mPair*spd_des + diag(0+cell_exists:mPair:spd_des|ratID)

Will estimate (no intercepts and) only random slopes for subjects with
cell_exists=1
And to achieve the same for intercept (lets have a second variable which is
identically coded as cell_exists to be as clear as possible:
cell_exists_intercept)

cc_marg ~ mPair*spd_des + diag(0+ cell_exists_intercept
+cell_exists:mPair:spd_des|ratID)

And the intercept then would be the "cell_exists_intercept".
This should deal with the missing stuff :)
But don't ask me how to call the random effects in the end :)) (random
slopes for a sub-sample of subjects maybe), or the residuals (mixture
between individual level model errors, and random intercept and slope
variance for those subjects with incomplete data).

Hope this helps (I guess there will be a solution eventually, there is not
much left to do, except going Bayesian :))
Best, Ren?



Am Fr., 14. Juni 2019 um 03:36 Uhr schrieb David Duffy <
David.Duffy at qimrberghofer.edu.au>:

> FWIW, on my machine,
>
> lmer(cc_marg ~  mPair*spd_des + (1|cycle) + (1|ratID), data=dat)
>
> runs without complaint. It's only when I add in mPair as fixed and random
> that I get problems. I notice that cycle has a *lot* of levels,and the
> distribution of cc_marg is pretty skewed. I always have trouble
> understanding measurement models in a lmer formula - mPair are six
> different measures, is that right? If that is the case, you might
> cross-check your results by running in MCMCglmm as an explicit multivariate
> model, and getting the same answers.
>
> Cheers, David Duffy.
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From b@ud-bovy@g@br|e| @end|ng |rom h@r@|t  Fri Jun 14 12:08:30 2019
From: b@ud-bovy@g@br|e| @end|ng |rom h@r@|t (Baud-Bovy Gabriel)
Date: Fri, 14 Jun 2019 10:08:30 +0000
Subject: [R-sig-ME] names of interaction / consistency between ranef and
 fixef
Message-ID: <6a690593-a93f-588f-588e-a9f481e523cb@hsr.it>

Dear all,

I found that in some cases the name of the interaction for RE and FE are not
consistent even if they are specified in a consistent manner. The issue
appears
to be a lack of consistency about when the interaction names are reordered
alphabetically:

d <- expand.grid(a=1:10, b=1:10, su=1:10)
d$y <- with(d, rnorm(10)[su] + a*rnorm(10)[su] + b*rnorm(10)[su] +
a*b*rnorm(10)[su])
d$y <- d$y + rnorm(nrow(d))

# no reordering
x <- lmer(y ~ b*a + (b*a || su), d)
names(fixef(x))     # b + a + b:a
names(ranef(x)$su)  #  b + a + b:a

# reordering only for REs
x <- lmer(y ~ b*a + (a*b || su), d)
names(fixef(x))     # b + a + b:a
names(ranef(x)$su)  #  a + b + a:b  # <= ro

# consistent alphabetical reordering
x <- lmer(y ~ a + b + b:a + (a + b + b:a || su), d)
names(fixef(x))     # a b a:b
names(ranef(x)$su)  # a b a:b

# reordering only for FEs
x <- lmer(y ~ a +  b + b:a + (a + 0 | su) + (b + 0 | su) + (b:a + 0 |
su), d)
names(fixef(x) )   # b + a + a:b
names(ranef(x)$su) # a + b + b:a

# warning messageabout missing slope when interaction names are not
consistent
insight::get_variance(x)

I found the issue when using performance::r2, which calls
insight::get_variance(x) and checks
for consistency between names of RE and FE.  I am not sure if it is a bug.

Best,

Gabriel

--
---------------------------------------------------------------------
Gabriel Baud-Bovy               tel.: (+39) 348 172 4045     (mobile)
UHSR University                       (+39) 02 2643 3429 (laboratory)
via Olgettina, 58                     (+39) 02 9175 1540  (secretary)
20132 Milan, Italy              email:       gabriel.baud-bovy at hsr.it
---------------------------------------------------------------------

[5xmille]<http://www.5xmille.org/?utm_source=mail&utm_medium=web_link&utm_campaign=5xmille_2018>

5xmille. INSIEME POSSIAMO continuare a scoprire nuove cure.
CODICE FISCALE 07636600962


Rispetta l?ambiente: non stampare questa mail se non ? necessario.
Respect the environment: print this email only if necessary.

From bbo|ker @end|ng |rom gm@||@com  Fri Jun 14 12:34:17 2019
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Fri, 14 Jun 2019 20:34:17 +1000
Subject: [R-sig-ME] names of interaction / consistency between ranef and
 fixef
In-Reply-To: <6a690593-a93f-588f-588e-a9f481e523cb@hsr.it>
References: <6a690593-a93f-588f-588e-a9f481e523cb@hsr.it>
Message-ID: <CABghstQGYLFJRpc6CrhW+NhcuHJxb9e4rcM0wn=6Cs57Rg5jKQ@mail.gmail.com>

Can you please post this as an issue on the github repo?

On Fri, Jun 14, 2019, 8:08 PM Baud-Bovy Gabriel <baud-bovy.gabriel at hsr.it>
wrote:

> Dear all,
>
> I found that in some cases the name of the interaction for RE and FE are
> not
> consistent even if they are specified in a consistent manner. The issue
> appears
> to be a lack of consistency about when the interaction names are reordered
> alphabetically:
>
> d <- expand.grid(a=1:10, b=1:10, su=1:10)
> d$y <- with(d, rnorm(10)[su] + a*rnorm(10)[su] + b*rnorm(10)[su] +
> a*b*rnorm(10)[su])
> d$y <- d$y + rnorm(nrow(d))
>
> # no reordering
> x <- lmer(y ~ b*a + (b*a || su), d)
> names(fixef(x))     # b + a + b:a
> names(ranef(x)$su)  #  b + a + b:a
>
> # reordering only for REs
> x <- lmer(y ~ b*a + (a*b || su), d)
> names(fixef(x))     # b + a + b:a
> names(ranef(x)$su)  #  a + b + a:b  # <= ro
>
> # consistent alphabetical reordering
> x <- lmer(y ~ a + b + b:a + (a + b + b:a || su), d)
> names(fixef(x))     # a b a:b
> names(ranef(x)$su)  # a b a:b
>
> # reordering only for FEs
> x <- lmer(y ~ a +  b + b:a + (a + 0 | su) + (b + 0 | su) + (b:a + 0 |
> su), d)
> names(fixef(x) )   # b + a + a:b
> names(ranef(x)$su) # a + b + b:a
>
> # warning messageabout missing slope when interaction names are not
> consistent
> insight::get_variance(x)
>
> I found the issue when using performance::r2, which calls
> insight::get_variance(x) and checks
> for consistency between names of RE and FE.  I am not sure if it is a bug.
>
> Best,
>
> Gabriel
>
> --
> ---------------------------------------------------------------------
> Gabriel Baud-Bovy               tel.: (+39) 348 172 4045     (mobile)
> UHSR University                       (+39) 02 2643 3429 (laboratory)
> via Olgettina, 58                     (+39) 02 9175 1540  (secretary)
> 20132 Milan, Italy              email:       gabriel.baud-bovy at hsr.it
> ---------------------------------------------------------------------
>
> [5xmille]<
> http://www.5xmille.org/?utm_source=mail&utm_medium=web_link&utm_campaign=5xmille_2018
> >
>
> 5xmille. INSIEME POSSIAMO continuare a scoprire nuove cure.
> CODICE FISCALE 07636600962
>
>
> Rispetta l?ambiente: non stampare questa mail se non ? necessario.
> Respect the environment: print this email only if necessary.
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From b@ud-bovy@g@br|e| @end|ng |rom h@r@|t  Fri Jun 14 12:55:02 2019
From: b@ud-bovy@g@br|e| @end|ng |rom h@r@|t (Baud-Bovy Gabriel)
Date: Fri, 14 Jun 2019 10:55:02 +0000
Subject: [R-sig-ME] names of interaction / consistency between ranef and
 fixef
In-Reply-To: <CABghstQGYLFJRpc6CrhW+NhcuHJxb9e4rcM0wn=6Cs57Rg5jKQ@mail.gmail.com>
References: <6a690593-a93f-588f-588e-a9f481e523cb@hsr.it>
 <CABghstQGYLFJRpc6CrhW+NhcuHJxb9e4rcM0wn=6Cs57Rg5jKQ@mail.gmail.com>
Message-ID: <dd10217e-52db-e752-b236-36159815052a@hsr.it>

I have submitted a new issue.

inconsistent renaming of interactions between ranef and fixef #526
https://github.com/lme4/lme4/issues/526

G.

On 6/14/2019 12:34 PM, Ben Bolker wrote:
Can you please post this as an issue on the github repo?

On Fri, Jun 14, 2019, 8:08 PM Baud-Bovy Gabriel <baud-bovy.gabriel at hsr.it<mailto:baud-bovy.gabriel at hsr.it>> wrote:
Dear all,

I found that in some cases the name of the interaction for RE and FE are not
consistent even if they are specified in a consistent manner. The issue
appears
to be a lack of consistency about when the interaction names are reordered
alphabetically:

d <- expand.grid(a=1:10, b=1:10, su=1:10)
d$y <- with(d, rnorm(10)[su] + a*rnorm(10)[su] + b*rnorm(10)[su] +
a*b*rnorm(10)[su])
d$y <- d$y + rnorm(nrow(d))

# no reordering
x <- lmer(y ~ b*a + (b*a || su), d)
names(fixef(x))     # b + a + b:a
names(ranef(x)$su)  #  b + a + b:a

# reordering only for REs
x <- lmer(y ~ b*a + (a*b || su), d)
names(fixef(x))     # b + a + b:a
names(ranef(x)$su)  #  a + b + a:b  # <= ro

# consistent alphabetical reordering
x <- lmer(y ~ a + b + b:a + (a + b + b:a || su), d)
names(fixef(x))     # a b a:b
names(ranef(x)$su)  # a b a:b

# reordering only for FEs
x <- lmer(y ~ a +  b + b:a + (a + 0 | su) + (b + 0 | su) + (b:a + 0 |
su), d)
names(fixef(x) )   # b + a + a:b
names(ranef(x)$su) # a + b + b:a

# warning messageabout missing slope when interaction names are not
consistent
insight::get_variance(x)

I found the issue when using performance::r2, which calls
insight::get_variance(x) and checks
for consistency between names of RE and FE.  I am not sure if it is a bug.

Best,

Gabriel

--
---------------------------------------------------------------------
Gabriel Baud-Bovy               tel.: (+39) 348 172 4045     (mobile)
UHSR University                       (+39) 02 2643 3429 (laboratory)
via Olgettina, 58                     (+39) 02 9175 1540  (secretary)
20132 Milan, Italy              email:       gabriel.baud-bovy at hsr.it<mailto:gabriel.baud-bovy at hsr.it>
---------------------------------------------------------------------

[5xmille]<http://www.5xmille.org/?utm_source=mail&utm_medium=web_link&utm_campaign=5xmille_2018>

5xmille. INSIEME POSSIAMO continuare a scoprire nuove cure.
CODICE FISCALE 07636600962


Rispetta l?ambiente: non stampare questa mail se non ? necessario.
Respect the environment: print this email only if necessary.
_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


--
---------------------------------------------------------------------
Gabriel Baud-Bovy               tel.: (+39) 348 172 4045     (mobile)
UHSR University                       (+39) 02 2643 3429 (laboratory)
via Olgettina, 58                     (+39) 02 9175 1540  (secretary)
20132 Milan, Italy              email:       gabriel.baud-bovy at hsr.it<mailto:gabriel.baud-bovy at hsr.it>
---------------------------------------------------------------------


[5xmille]<http://www.5xmille.org/?utm_source=mail&utm_medium=web_link&utm_campaign=5xmille_2018>

5xmille. INSIEME POSSIAMO continuare a scoprire nuove cure.
CODICE FISCALE 07636600962

	[[alternative HTML version deleted]]


From cr|@@|e@@@ndro @end|ng |rom gm@||@com  Fri Jun 14 17:23:47 2019
From: cr|@@|e@@@ndro @end|ng |rom gm@||@com (Cristiano Alessandro)
Date: Fri, 14 Jun 2019 10:23:47 -0500
Subject: [R-sig-ME] 
 convergence issues on lme4 and incoherent error messages
In-Reply-To: <CADcpBHOZugo2+gvbM9VGnX4n5=cK9uvRfPs3XYhf6r6xagOHww@mail.gmail.com>
References: <CAHhX7WjUM+g6-b9vYj7rY62USOAN+tXjKL-2zNGc=nPEsAszZw@mail.gmail.com>
 <CABghstS51Q4Hc3nfDOLi1R_vG_kDLeRmYvqqCajzV0rMgj=GOw@mail.gmail.com>
 <CAHhX7WhEi4UvcmtpEPTMAUcJxO+pBWOD8qiscEL-6jP_PWmMFw@mail.gmail.com>
 <CADcpBHNpQR6DHqCXu1Qh3fCYcoh-JCKrnyYVKZBvSFind893Rg@mail.gmail.com>
 <CADcpBHMCMT5io+x1sfbfBUxQc-p70mBTujPiP13mX+c75s-xdA@mail.gmail.com>
 <CAHhX7WgGSh32+JpWD5YQXYrd_bqvqDvwAM2Wd0wDWTePDnQAKg@mail.gmail.com>
 <0c3d2338-6b4c-5daf-502c-688751bc0aec@gmail.com>
 <CAHhX7WiymVFe1JH79OHjthGMhZLbPPDxETq3h-4ECm9_w068tA@mail.gmail.com>
 <4737E17E7C8C3C4A8B5C1CE5346371D4A8537724@EXCH06S.adqimr.ad.lan>
 <CADcpBHOZugo2+gvbM9VGnX4n5=cK9uvRfPs3XYhf6r6xagOHww@mail.gmail.com>
Message-ID: <CAHhX7WhyYNc+8LT-U7Bb-ok6xy-J4q0PgaURGCR2nCpvvJgR2A@mail.gmail.com>

Hi all,

thanks a lot for all your help!

@Rene'. I am not sure I can follow all you said.
"If, as you say, there are measurements missing in some design-cells for
some subjects, then, actually, estimating the variance of fixed effects
between subjects (just another word for by-subject random slopes) becomes
partially the same as measuring the fixed effect itself"
Woundn't this be only true if for some cells there is no data for any
subject? In tat case, yes, there is no way of estimating the variance of
the corresponding random effects, and therefore it would be equivalent to
estimating the fixed effect only. But here there are data for some of the
subjects; the only random effects estimated as zero are those corresponding
to the subjects with no data. Also, it is important to note that I get zero
random effects only if I use a diagonal var-cov matrix. If I used, for
example, compound symmetry, that is not the case.

@David. That is right; the problem arises only when I introduce random
slopes on mPair (and I should do that), which is a factor with 6 levels as
you said. I am not interested in the 'cycle' variable, and therefore I am
not using it for fixed nor random effects.

Best
Cristiano

On Fri, Jun 14, 2019 at 4:09 AM Ren? <bimonosom at gmail.com> wrote:

> Ah now I think of the following:
> Estimating by-subject random slopes necessarily requires that the random
> slope (i.e. in all within-subject design cells) is measured on each
> subject. If, as you say, there are measurements missing in some
> design-cells for some subjects, then, actually, estimating the variance of
> fixed effects between subjects (just another word for by-subject random
> slopes) becomes partially the same as measuring the fixed effect itself,
> which is 'bad'.  Furthermore, this might be similarly troubling when
> estimating by-subject intercepts, but for a slightly different reason,
> namely, (lets make it extreme) if half of the subjects have measures in all
> design cells, while the other half has only measures in some-design cells,
> then what would you expect how the intercepts are distributed (i.e. the
> subjects average response deviation from the grand mean), if there are
> systematic differences between the means in the design-cells? The a priori
> answer is, "probably not Gaussian", which is again 'bad'  :))
>
> I would suggest to adjust the model-definition to reflect the fact that
> there are cell-measurements missing for some subjects (regardless of
> whether a model converges or not, but just because, this would be the only
> way to meaningfully interpret the model).
> I think this should work:
> Let's take the model from the last link you posted
>
> cc_marg ~ mPair*spd_des + diag(mPair:spd_des|ratID)
>
> Define a (-numeric-) variable (say "cell_exists") in the data frame which
> codes whether a subject (for all observations by that subject) has
> measurements in all cells (coded as 1), or not (coded as 0), such that all
> subjects of which you speak have missing data in some cells are 0.
> Then:
>
> cc_marg ~ mPair*spd_des + diag(0+cell_exists:mPair:spd_des|ratID)
>
> Will estimate (no intercepts and) only random slopes for subjects with
> cell_exists=1
> And to achieve the same for intercept (lets have a second variable which
> is identically coded as cell_exists to be as clear as possible:
> cell_exists_intercept)
>
> cc_marg ~ mPair*spd_des + diag(0+ cell_exists_intercept +cell_exists:mPair:spd_des|ratID)
>
> And the intercept then would be the "cell_exists_intercept".
> This should deal with the missing stuff :)
> But don't ask me how to call the random effects in the end :)) (random
> slopes for a sub-sample of subjects maybe), or the residuals (mixture
> between individual level model errors, and random intercept and slope
> variance for those subjects with incomplete data).
>
> Hope this helps (I guess there will be a solution eventually, there is not
> much left to do, except going Bayesian :))
> Best, Ren?
>
>
>
> Am Fr., 14. Juni 2019 um 03:36 Uhr schrieb David Duffy <
> David.Duffy at qimrberghofer.edu.au>:
>
>> FWIW, on my machine,
>>
>> lmer(cc_marg ~  mPair*spd_des + (1|cycle) + (1|ratID), data=dat)
>>
>> runs without complaint. It's only when I add in mPair as fixed and random
>> that I get problems. I notice that cycle has a *lot* of levels,and the
>> distribution of cc_marg is pretty skewed. I always have trouble
>> understanding measurement models in a lmer formula - mPair are six
>> different measures, is that right? If that is the case, you might
>> cross-check your results by running in MCMCglmm as an explicit multivariate
>> model, and getting the same answers.
>>
>> Cheers, David Duffy.
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>

	[[alternative HTML version deleted]]


From tg369 @end|ng |rom c@m@@c@uk  Thu Jun 13 23:16:27 2019
From: tg369 @end|ng |rom c@m@@c@uk (Tanay Ghosh)
Date: Thu, 13 Jun 2019 22:16:27 +0100
Subject: [R-sig-ME] =?utf-8?q?lme4_analysis=5F2ANOVA_repeated_measure?=
In-Reply-To: <20190613124545.GA14758@info124.pharmacie.univ-paris5.fr>
References: <1905bdf79ddfa731ced2688ee1dbf1a2@cam.ac.uk>
 <20190613124545.GA14758@info124.pharmacie.univ-paris5.fr>
Message-ID: <3e113de514a25416be0de6794e092080@cam.ac.uk>

Dear Emmanuel,

Many thanks for this reply.

I now added a column "subject id" (attached).

Atg3 is the name of a gene whose expression level was measured.

I know that we can not detect any difference here, also aware of the 
outlier.  However, using this data set as an example, I want to learn 
using lme4 for RM ANOVA specially when some values are NA.

Please do not hesitate to ask if anything is unclear and I am looking 
forward to hearing from you.

Kind regards,

Tanay

On 2019-06-13 13:45, Emmanuel Curis wrote:
> Hi Tanay,
> 
> In your data file, there seems to be nothing like ? subject id ?, but
> only time, sex and Atg3 (=Abt3 ?) measure so it's not possible to do
> any random-effect modeling.
> 
> Besides, you should give more explaination about what is the Atg3
> column, because the syntax will change if there are CTs or equivalent
> measures [does not look like, except the atypical 31.355 value],
> absolute quantities or relative quantities compared to a (set of)
> reference genes.
> 
> Last, comparing all times to see a time effect is not a very powerful
> method, because you quickly increase the number of comparisons, and at
> the extreme, the more time you have, the more precise is your time
> curve, the more difficult it is to detect anything...
> 
> Note however that looking ? by eye ? your data, you can't expect much
> since you have a small dataser, huge outliers (31.355, 5.081, 4.804)
> and a quite high intra-groupe variability (values ranging from 0.087
> to 2.237 for the 3 males at t=7, for instance).
> 
> est regards,
> 
> On Mon, Jun 10, 2019 at 03:31:53PM +0100, Tanay Ghosh wrote:
> ? Dear All,
> ?
> ? I wonder if I can ask your advise to analyse this data (attached). 
> Please
> ? note that some of the values are "NA" i.e. I do not have any 
> measurement
> ? taken.
> ?
> ? Here I have four different time (days) points. I measured expression 
> of Abt3
> ? gene at these time points in male and female.
> ?
> ? I want to see if gender wise expression of Atg3 differ at any time 
> point?
> ?
> ? I further want to do a posttest to get p value for Male at time 7 vs 
> female
> ? at time 7, Male at time 15 vs Female at time 15, and like wise all 
> other
> ? time points.
> ?
> ?
> ? Please could you advise me how to do this analysis using lmer 
> function? I
> ? would very much appreciate if you please write the commands in R for 
> this
> ? specific case.
> ?
> ? Thank you in advance for your time.
> ?
> ?
> ? Kind regards,
> ?
> ? Tanay
> ?
> ?
> ? --
> ? Dr. Tanay Ghosh, PhD
> ? Research Associate
> ? Department of Clinical Neurosciences,
> ? Wellcome Trust-Medical Research Council Cambridge Stem Cell 
> Institute,
> ? Clifford Allbutt Building,
> ? Cambridge Biomedical Campus,
> ? University of Cambridge,
> ? Cambridge CB2 0AH
> 
> ?
> time	Gender	Atg37	Male	0.2127	Male	2.2377	Male	0.0877	Female	0.0927	Female	2.8057	Female	0.10315	Male	0.07115	Male	2.73315	Male	2.41415	Female	0.1515	Female	2.43815	Female	1.43424	Male	0.07924	Male	2.21224	Male	31.35524	Female	0.21124	Female	0.81224	Female	5.081231	Male	0.073231	Male	0.505231	Male	0.737231	Female	0.178231	Female	0.319231	Female	4.804420	Male	0.29420	Male	0.424420	Male	NA420	Female	0.337420	Female	0.966420	Female	NA
> 
> ? _______________________________________________
> ? R-sig-mixed-models at r-project.org mailing list
> ? https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

-- 
Dr. Tanay Ghosh, PhD
Research Associate
Department of Clinical Neurosciences,
Wellcome Trust-Medical Research Council Cambridge Stem Cell Institute,
Clifford Allbutt Building,
Cambridge Biomedical Campus,
University of Cambridge,
Cambridge CB2 0AH
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: Ginez_data_Atg3.txt
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20190613/2c158520/attachment.txt>

From cr|@@|e@@@ndro @end|ng |rom gm@||@com  Fri Jun 14 20:53:18 2019
From: cr|@@|e@@@ndro @end|ng |rom gm@||@com (Cristiano Alessandro)
Date: Fri, 14 Jun 2019 13:53:18 -0500
Subject: [R-sig-ME] post-hoc tests warnings after fitting a linear mixed
 effect model
Message-ID: <CAHhX7WgrkMLtDPvfk8=e--V+MdBxPE4nNsep=VqYGot=5P7FVw@mail.gmail.com>

Hi all,

I fit a linear mixed effect model linM, and I am now running post-hoc tests
by definig specific contrasts in the variable ph_conditional.

> linM.ph <- glht(linM, linfct = ph_conditional);
> summary(linM.ph)

The code returns the results (with p-values adjusted with single-step
method), but also these warnings:

Warning messages:
1: In RET$pfunction("adjusted", ...) : Completion with error > abseps
2: In RET$pfunction("adjusted", ...) : Completion with error > abseps
3: In RET$pfunction("adjusted", ...) : Completion with error > abseps
4: In RET$pfunction("adjusted", ...) : Completion with error > abseps
5: In RET$pfunction("adjusted", ...) : Completion with error > abseps
6: In RET$pfunction("adjusted", ...) : Completion with error > abseps
7: In RET$pfunction("adjusted", ...) : Completion with error > abseps
8: In RET$pfunction("adjusted", ...) : Completion with error > abseps

What does this mean? Is it alarming?

Thanks
Cristiano

	[[alternative HTML version deleted]]


From b|mono@om @end|ng |rom gm@||@com  Sat Jun 15 14:22:31 2019
From: b|mono@om @end|ng |rom gm@||@com (=?UTF-8?B?UmVuw6k=?=)
Date: Sat, 15 Jun 2019 14:22:31 +0200
Subject: [R-sig-ME] 
 convergence issues on lme4 and incoherent error messages
In-Reply-To: <CAHhX7WhyYNc+8LT-U7Bb-ok6xy-J4q0PgaURGCR2nCpvvJgR2A@mail.gmail.com>
References: <CAHhX7WjUM+g6-b9vYj7rY62USOAN+tXjKL-2zNGc=nPEsAszZw@mail.gmail.com>
 <CABghstS51Q4Hc3nfDOLi1R_vG_kDLeRmYvqqCajzV0rMgj=GOw@mail.gmail.com>
 <CAHhX7WhEi4UvcmtpEPTMAUcJxO+pBWOD8qiscEL-6jP_PWmMFw@mail.gmail.com>
 <CADcpBHNpQR6DHqCXu1Qh3fCYcoh-JCKrnyYVKZBvSFind893Rg@mail.gmail.com>
 <CADcpBHMCMT5io+x1sfbfBUxQc-p70mBTujPiP13mX+c75s-xdA@mail.gmail.com>
 <CAHhX7WgGSh32+JpWD5YQXYrd_bqvqDvwAM2Wd0wDWTePDnQAKg@mail.gmail.com>
 <0c3d2338-6b4c-5daf-502c-688751bc0aec@gmail.com>
 <CAHhX7WiymVFe1JH79OHjthGMhZLbPPDxETq3h-4ECm9_w068tA@mail.gmail.com>
 <4737E17E7C8C3C4A8B5C1CE5346371D4A8537724@EXCH06S.adqimr.ad.lan>
 <CADcpBHOZugo2+gvbM9VGnX4n5=cK9uvRfPs3XYhf6r6xagOHww@mail.gmail.com>
 <CAHhX7WhyYNc+8LT-U7Bb-ok6xy-J4q0PgaURGCR2nCpvvJgR2A@mail.gmail.com>
Message-ID: <CADcpBHOSic_tqVFMS1w3vzQyxToNsogNwcEmwSWMtSVFgorMMQ@mail.gmail.com>

Hi Christiano,

"Woudn't this be only true if for some cells there is no data for any
subject?"
Counterquestion: Wouldn't this mean that the -cell- does not exist at all?
:)
Maybe for clarification, your statement on stats reads:
"However there are missing data, meaning that for some subject, I have no
data at all for certain combinations of mPair and spd_des."
Which I will continue to refer to in my best knowledge.

Maybe I should mention a related issue (often discussed is) whether the
missing cell-values are missing-by-random, or not (if not, one
recommendation is to predict the missing values in the model, or drop them
(which seems too costly in your case) otherwise there can be estimation
biases). As far as I know, single NA observations are dropped by default in
most ME functions I know, anyway. Which also -could- cause the 0 values you
speak of in the last stats post (idk).

But estimating random slopes of factor interactions -should- simply mean,
that you have some design coding formula like (in a 2x * 2y design defined
similar to yours) ... and dummy coding now  since dummy coding is often
default... (but maybe you used contrast coding?)
cellX1_Y1estimate=intercept + randomslopedeviationX1_Y1
cellX2_Y1estimate= intercept+x2_est + randomslopedeviationX1_Y
cellX1_Y2estimate=intercept+y2_est + randomslopedeviationX2_Y1
cellX2_Y2estimate= intercept+ x2_est +y2_est+ x2_est: y2_est +
 randomslopedeviationX2_Y2
(with an random intercept there should be another term on the right-hand
side, but I admit, I have never looked into the mechanics of e.g. lme4)

But importantly, by only dropping single cell-observations (e.g.
 cellX2_Y2) you can not estimate  x2_est: y2_est anymore, but you see,
x2_est: y2_est is only modeled as on-top deviation from the other
cell-estimates. Without these on-top deviation, the other cell-estimates
sure change. Thus, a deviation from (e.g.) intercept+x2_est just means
something different when x2_est: y2_est is present, than when it is
absent... And further, because y2_est  is supposed to reflect an estimate
for all participants, so is x2_est: y2_est, which means that the random
slope deviation in x1y2 for subjects with no data in x2y2 follow a
different distribution. Maybe more striking example: just assume that there
is no observation for a subject in cell x1y2, which defines the
intercept.... what then? So in my opinion (I do not know who might share
it, and maybe this applies only to specific model/design codings)... I
would rather drop the whole subject from the random slope (and random
intercept) estimation   (Arguments against it are appreciated, maybe I am
wrong. I seldom see those discussions actually.)

Best, Ren?

Ps.
Just for the record. I just ran a similar model over one of my own data
sets (which never produced error messages like yours; the design has
categorical factors only), but I removed the observations of -one- subject
(of about 200) in -one- cell of a 2x2 within desgin (otherwise data are
complete), and I suddenly get a never seen before error message:
" - Rescale variables?  "

To me this looks familiar :))
then a next model:  I "flagged" this one subject with 'cell_exists=0'
(otherwise 1) as described above, and voila, the 'rescale' message
disappeared :)

Am Fr., 14. Juni 2019 um 17:23 Uhr schrieb Cristiano Alessandro <
cri.alessandro at gmail.com>:

> Hi all,
>
> thanks a lot for all your help!
>
> @Rene'. I am not sure I can follow all you said.
> "If, as you say, there are measurements missing in some design-cells for
> some subjects, then, actually, estimating the variance of fixed effects
> between subjects (just another word for by-subject random slopes) becomes
> partially the same as measuring the fixed effect itself"
> Woundn't this be only true if for some cells there is no data for any
> subject? In tat case, yes, there is no way of estimating the variance of
> the corresponding random effects, and therefore it would be equivalent to
> estimating the fixed effect only. But here there are data for some of the
> subjects; the only random effects estimated as zero are those corresponding
> to the subjects with no data. Also, it is important to note that I get zero
> random effects only if I use a diagonal var-cov matrix. If I used, for
> example, compound symmetry, that is not the case.
>
> @David. That is right; the problem arises only when I introduce random
> slopes on mPair (and I should do that), which is a factor with 6 levels as
> you said. I am not interested in the 'cycle' variable, and therefore I am
> not using it for fixed nor random effects.
>
> Best
> Cristiano
>
> On Fri, Jun 14, 2019 at 4:09 AM Ren? <bimonosom at gmail.com> wrote:
>
>> Ah now I think of the following:
>> Estimating by-subject random slopes necessarily requires that the random
>> slope (i.e. in all within-subject design cells) is measured on each
>> subject. If, as you say, there are measurements missing in some
>> design-cells for some subjects, then, actually, estimating the variance of
>> fixed effects between subjects (just another word for by-subject random
>> slopes) becomes partially the same as measuring the fixed effect itself,
>> which is 'bad'.  Furthermore, this might be similarly troubling when
>> estimating by-subject intercepts, but for a slightly different reason,
>> namely, (lets make it extreme) if half of the subjects have measures in all
>> design cells, while the other half has only measures in some-design cells,
>> then what would you expect how the intercepts are distributed (i.e. the
>> subjects average response deviation from the grand mean), if there are
>> systematic differences between the means in the design-cells? The a priori
>> answer is, "probably not Gaussian", which is again 'bad'  :))
>>
>> I would suggest to adjust the model-definition to reflect the fact that
>> there are cell-measurements missing for some subjects (regardless of
>> whether a model converges or not, but just because, this would be the only
>> way to meaningfully interpret the model).
>> I think this should work:
>> Let's take the model from the last link you posted
>>
>> cc_marg ~ mPair*spd_des + diag(mPair:spd_des|ratID)
>>
>> Define a (-numeric-) variable (say "cell_exists") in the data frame which
>> codes whether a subject (for all observations by that subject) has
>> measurements in all cells (coded as 1), or not (coded as 0), such that all
>> subjects of which you speak have missing data in some cells are 0.
>> Then:
>>
>> cc_marg ~ mPair*spd_des + diag(0+cell_exists:mPair:spd_des|ratID)
>>
>> Will estimate (no intercepts and) only random slopes for subjects with
>> cell_exists=1
>> And to achieve the same for intercept (lets have a second variable which
>> is identically coded as cell_exists to be as clear as possible:
>> cell_exists_intercept)
>>
>> cc_marg ~ mPair*spd_des + diag(0+ cell_exists_intercept +cell_exists:mPair:spd_des|ratID)
>>
>> And the intercept then would be the "cell_exists_intercept".
>> This should deal with the missing stuff :)
>> But don't ask me how to call the random effects in the end :)) (random
>> slopes for a sub-sample of subjects maybe), or the residuals (mixture
>> between individual level model errors, and random intercept and slope
>> variance for those subjects with incomplete data).
>>
>> Hope this helps (I guess there will be a solution eventually, there is
>> not much left to do, except going Bayesian :))
>> Best, Ren?
>>
>>
>>
>> Am Fr., 14. Juni 2019 um 03:36 Uhr schrieb David Duffy <
>> David.Duffy at qimrberghofer.edu.au>:
>>
>>> FWIW, on my machine,
>>>
>>> lmer(cc_marg ~  mPair*spd_des + (1|cycle) + (1|ratID), data=dat)
>>>
>>> runs without complaint. It's only when I add in mPair as fixed and
>>> random that I get problems. I notice that cycle has a *lot* of levels,and
>>> the distribution of cc_marg is pretty skewed. I always have trouble
>>> understanding measurement models in a lmer formula - mPair are six
>>> different measures, is that right? If that is the case, you might
>>> cross-check your results by running in MCMCglmm as an explicit multivariate
>>> model, and getting the same answers.
>>>
>>> Cheers, David Duffy.
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>

	[[alternative HTML version deleted]]


From de@m|ch@|||dou @end|ng |rom gm@||@com  Sun Jun 16 21:12:56 2019
From: de@m|ch@|||dou @end|ng |rom gm@||@com (DESPINA MICHAILIDOU)
Date: Sun, 16 Jun 2019 15:12:56 -0400
Subject: [R-sig-ME] Mixed model and repeated measures in R
Message-ID: <CAGP99JGZsizcep7mH+iynK5xcictrjQeqGYuarRQsmw8sw5Jxg@mail.gmail.com>

Hi All,

I am trying to run regression analysis adjusted for repeated measures in R.
The imaging pathology finding defined as Vert_effect, CA_effect,
Vert_Intens etc is the outcome variable whereas the clinical symptom
defined as Comb_PH_tod, Comb_PNP_tod etc, is the predictor variable. Other
predictor variables that I am using are the daily prednisone use (Pred) and
the use of immunosuppresive therapy (Immune_Categorical) or not. As the
prednisone variable is being read as character in R i converted it to
numeric because it is a number. For example some patients are getting 2 mg
of prednisone but some others 40 mg.  I have two subset of diagnoses,  the
one is TAK and the second one is GCA. As some patients have either right
side posterior headache or left side posterior headache or both or none and
either right side vertebral intensity (imaging study pathology) or left
side vertebral intensity, or both or none vertebral intensity, for each
patient I created two rows per subject. The first row represents the right
sided symptoms and imaging pathology findings and the second row represents
the left sided symptoms and imaging findings. My repeated measures are the
side of the symptoms and imaging findings (had to create a separate
variable for the right and left side symptoms and right and left imaging
findings that I called it Side and put in there R, L, R, L etc), the ID of
the patients and the Scan_date visit. Some patients had one scan visit but
some other patients had multiple scan visits, and that is why I am
considering scan visit date as a repeated measure. *So this is the code
that i am using and for the subset of TAK i get this output*

> TAK_data <- subset(Despina, Diagnosis=="TAK")
> glmm_Vert_Intes <- glmer (Vert_Intes ~ Comb_PH_tod  + (1 |
ID/SCAN_DATE/Side) + Pred + Immune_Catagorical , data=TAK_data,
family=binomial(link = "logit"))
Error in length(value <- as.numeric(value)) == 1L :
  (maxstephalfit) PIRLS step-halvings failed to reduce deviance in
pwrssUpdate
> summary(glmm_Vert_Intes)

*whereas for the subset of GCA patients there are no issues.*
Generalized linear mixed model fit by maximum likelihood (Laplace
Approximation) ['glmerMod']
 Family: binomial  ( logit )
Formula: Vert_Intes ~ Comb_PH_tod + (1 | ID/SCAN_DATE/Side) + Pred +
Immune_Catagorical
   Data: GCA_data

     AIC      BIC   logLik deviance df.resid
    87.8    113.0    -36.9     73.8      263

Scaled residuals:
     Min       1Q   Median       3Q      Max
-0.98336 -0.00342 -0.00241 -0.00214  1.02148

Random effects:
 Groups              Name        Variance Std.Dev.
 Side:(SCAN_DATE:ID) (Intercept)   0.00    0.00
 SCAN_DATE:ID        (Intercept) 528.06   22.98
 ID                  (Intercept)  18.84    4.34
Number of obs: 270, groups:  Side:(SCAN_DATE:ID), 270; SCAN_DATE:ID, 135;
ID, 54

Fixed effects:
                    Estimate Std. Error z value Pr(>|z|)
(Intercept)        -10.63649    2.36017  -4.507 6.59e-06 ***
Comb_PH_tod         -8.53678    4.56601  -1.870   0.0615 .
Pred                -0.02353    0.09323  -0.252   0.8008
Immune_Catagorical  -1.41376    2.69420  -0.525   0.5998
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Correlation of Fixed Effects:
            (Intr) Cm_PH_ Pred
Comb_PH_tod  0.299
Pred        -0.289 -0.001
Immn_Ctgrcl -0.520 -0.068  0.041
convergence code: 0
boundary (singular) fit: see ?isSingular

*And this is the detailed code that I am using in R*
install.packages("lme4")
install.packages("readr")

library(readr)
library("lme4")

setwd("~/Desktop/Despina")
Despina <- read_csv("Despina.csv")
as.factor(Despina$ID)
as.factor(Despina$Diagnosis)
as.factor(Despina$SCAN_DATE)
as.factor(Despina$Side)
as.factor(Despina$Immune_Catagorical)
as.factor(Despina$LH_today)
as.factor(Despina$PLH_today)
as.factor(Despina$Dizz_today)
as.factor(Despina$P_Diz_today)
as.factor(Despina$CD_tod)
as.factor(Despina$Head_today)
as.factor(Despina$Vertig_today)
as.factor(Despina$FTH_tod)
as.factor(Despina$Comb_PH_tod)
as.factor(Despina$Comb_NP_tod)
as.factor(Despina$Comb_ANP_tod)
as.factor(Despina$Comb_PNP_tod)
as.factor(Despina$CNS_ever)
as.factor(Despina$ULC_today)
as.factor(Despina$Vert_effect)
as.factor(Despina$CA_effect)
as.factor(Despina$Sub_invol)
as.factor(Despina$Ax_involv)
as.factor(Despina$CA_intens)
as.factor(Despina$Sub_intens)
as.factor(Despina$Vert_Intes)
as.factor(Despina$Ax_intens)
as.factor(Despina$Comb_Vis_L_today)
Despina$Pred<-as.numeric(as.character(Despina$Pred))


TAK_data <- subset(Despina, Diagnosis=="TAK")

glmm_Vert_Intes <- glmer (Vert_Intes ~ Comb_PH_tod  + (1 |
ID/SCAN_DATE/Side) + Pred + Immune_Catagorical , data=TAK_data,
family=binomial(link = "logit"))
summary(glmm_Vert_Intes)

GCA_data <- subset(Despina, Diagnosis=="GCA")

glmm_Vert_Intes <- glmer (Vert_Intes ~ Comb_PH_tod  + (1 |
ID/SCAN_DATE/Side) + Pred + Immune_Catagorical , data=GCA_data,
family=binomial(link = "logit"))
summary(glmm_Vert_Intes)

*So my question is why i am getting this error in TAK patients and not in
GCA patients?*
Error in length(value <- as.numeric(value)) == 1L :
  (maxstephalfit) PIRLS step-halvings failed to reduce deviance in
pwrssUpdate

Thank you all for your time and consideration in advance.

Sincerely,
Despina

	[[alternative HTML version deleted]]


From th|erry@onke||nx @end|ng |rom |nbo@be  Mon Jun 17 08:38:25 2019
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Mon, 17 Jun 2019 08:38:25 +0200
Subject: [R-sig-ME] Mixed model and repeated measures in R
In-Reply-To: <CAGP99JGZsizcep7mH+iynK5xcictrjQeqGYuarRQsmw8sw5Jxg@mail.gmail.com>
References: <CAGP99JGZsizcep7mH+iynK5xcictrjQeqGYuarRQsmw8sw5Jxg@mail.gmail.com>
Message-ID: <CAJuCY5zf6CXK9-4v=7UJ-TqWQM+KqQBgS7raqGNQ1jXqWC+PZg@mail.gmail.com>

Dear Despina,

You have complete separation in your dataset. It shows in the output of the
GCA data. Extreme random intercept variances (SCAN_DATE:ID and ID), extreme
fixed effect parameters (intercept and Comb_PH_tod).

Your model is too complex for your data.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op zo 16 jun. 2019 om 21:13 schreef DESPINA MICHAILIDOU <
de.michailidou at gmail.com>:

> Hi All,
>
> I am trying to run regression analysis adjusted for repeated measures in R.
> The imaging pathology finding defined as Vert_effect, CA_effect,
> Vert_Intens etc is the outcome variable whereas the clinical symptom
> defined as Comb_PH_tod, Comb_PNP_tod etc, is the predictor variable. Other
> predictor variables that I am using are the daily prednisone use (Pred) and
> the use of immunosuppresive therapy (Immune_Categorical) or not. As the
> prednisone variable is being read as character in R i converted it to
> numeric because it is a number. For example some patients are getting 2 mg
> of prednisone but some others 40 mg.  I have two subset of diagnoses,  the
> one is TAK and the second one is GCA. As some patients have either right
> side posterior headache or left side posterior headache or both or none and
> either right side vertebral intensity (imaging study pathology) or left
> side vertebral intensity, or both or none vertebral intensity, for each
> patient I created two rows per subject. The first row represents the right
> sided symptoms and imaging pathology findings and the second row represents
> the left sided symptoms and imaging findings. My repeated measures are the
> side of the symptoms and imaging findings (had to create a separate
> variable for the right and left side symptoms and right and left imaging
> findings that I called it Side and put in there R, L, R, L etc), the ID of
> the patients and the Scan_date visit. Some patients had one scan visit but
> some other patients had multiple scan visits, and that is why I am
> considering scan visit date as a repeated measure. *So this is the code
> that i am using and for the subset of TAK i get this output*
>
> > TAK_data <- subset(Despina, Diagnosis=="TAK")
> > glmm_Vert_Intes <- glmer (Vert_Intes ~ Comb_PH_tod  + (1 |
> ID/SCAN_DATE/Side) + Pred + Immune_Catagorical , data=TAK_data,
> family=binomial(link = "logit"))
> Error in length(value <- as.numeric(value)) == 1L :
>   (maxstephalfit) PIRLS step-halvings failed to reduce deviance in
> pwrssUpdate
> > summary(glmm_Vert_Intes)
>
> *whereas for the subset of GCA patients there are no issues.*
> Generalized linear mixed model fit by maximum likelihood (Laplace
> Approximation) ['glmerMod']
>  Family: binomial  ( logit )
> Formula: Vert_Intes ~ Comb_PH_tod + (1 | ID/SCAN_DATE/Side) + Pred +
> Immune_Catagorical
>    Data: GCA_data
>
>      AIC      BIC   logLik deviance df.resid
>     87.8    113.0    -36.9     73.8      263
>
> Scaled residuals:
>      Min       1Q   Median       3Q      Max
> -0.98336 -0.00342 -0.00241 -0.00214  1.02148
>
> Random effects:
>  Groups              Name        Variance Std.Dev.
>  Side:(SCAN_DATE:ID) (Intercept)   0.00    0.00
>  SCAN_DATE:ID        (Intercept) 528.06   22.98
>  ID                  (Intercept)  18.84    4.34
> Number of obs: 270, groups:  Side:(SCAN_DATE:ID), 270; SCAN_DATE:ID, 135;
> ID, 54
>
> Fixed effects:
>                     Estimate Std. Error z value Pr(>|z|)
> (Intercept)        -10.63649    2.36017  -4.507 6.59e-06 ***
> Comb_PH_tod         -8.53678    4.56601  -1.870   0.0615 .
> Pred                -0.02353    0.09323  -0.252   0.8008
> Immune_Catagorical  -1.41376    2.69420  -0.525   0.5998
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Correlation of Fixed Effects:
>             (Intr) Cm_PH_ Pred
> Comb_PH_tod  0.299
> Pred        -0.289 -0.001
> Immn_Ctgrcl -0.520 -0.068  0.041
> convergence code: 0
> boundary (singular) fit: see ?isSingular
>
> *And this is the detailed code that I am using in R*
> install.packages("lme4")
> install.packages("readr")
>
> library(readr)
> library("lme4")
>
> setwd("~/Desktop/Despina")
> Despina <- read_csv("Despina.csv")
> as.factor(Despina$ID)
> as.factor(Despina$Diagnosis)
> as.factor(Despina$SCAN_DATE)
> as.factor(Despina$Side)
> as.factor(Despina$Immune_Catagorical)
> as.factor(Despina$LH_today)
> as.factor(Despina$PLH_today)
> as.factor(Despina$Dizz_today)
> as.factor(Despina$P_Diz_today)
> as.factor(Despina$CD_tod)
> as.factor(Despina$Head_today)
> as.factor(Despina$Vertig_today)
> as.factor(Despina$FTH_tod)
> as.factor(Despina$Comb_PH_tod)
> as.factor(Despina$Comb_NP_tod)
> as.factor(Despina$Comb_ANP_tod)
> as.factor(Despina$Comb_PNP_tod)
> as.factor(Despina$CNS_ever)
> as.factor(Despina$ULC_today)
> as.factor(Despina$Vert_effect)
> as.factor(Despina$CA_effect)
> as.factor(Despina$Sub_invol)
> as.factor(Despina$Ax_involv)
> as.factor(Despina$CA_intens)
> as.factor(Despina$Sub_intens)
> as.factor(Despina$Vert_Intes)
> as.factor(Despina$Ax_intens)
> as.factor(Despina$Comb_Vis_L_today)
> Despina$Pred<-as.numeric(as.character(Despina$Pred))
>
>
> TAK_data <- subset(Despina, Diagnosis=="TAK")
>
> glmm_Vert_Intes <- glmer (Vert_Intes ~ Comb_PH_tod  + (1 |
> ID/SCAN_DATE/Side) + Pred + Immune_Catagorical , data=TAK_data,
> family=binomial(link = "logit"))
> summary(glmm_Vert_Intes)
>
> GCA_data <- subset(Despina, Diagnosis=="GCA")
>
> glmm_Vert_Intes <- glmer (Vert_Intes ~ Comb_PH_tod  + (1 |
> ID/SCAN_DATE/Side) + Pred + Immune_Catagorical , data=GCA_data,
> family=binomial(link = "logit"))
> summary(glmm_Vert_Intes)
>
> *So my question is why i am getting this error in TAK patients and not in
> GCA patients?*
> Error in length(value <- as.numeric(value)) == 1L :
>   (maxstephalfit) PIRLS step-halvings failed to reduce deviance in
> pwrssUpdate
>
> Thank you all for your time and consideration in advance.
>
> Sincerely,
> Despina
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From |ongrob604 @end|ng |rom gm@||@com  Mon Jun 17 12:10:31 2019
From: |ongrob604 @end|ng |rom gm@||@com (Robert Long)
Date: Mon, 17 Jun 2019 11:10:31 +0100
Subject: [R-sig-ME] Mixed model and repeated measures in R
In-Reply-To: <CAGP99JGZsizcep7mH+iynK5xcictrjQeqGYuarRQsmw8sw5Jxg@mail.gmail.com>
References: <CAGP99JGZsizcep7mH+iynK5xcictrjQeqGYuarRQsmw8sw5Jxg@mail.gmail.com>
Message-ID: <CA+3TTkOAQh6DBiv6JBWGf8B3A_j_On5UfcnkVuzvdvXDkiBhEg@mail.gmail.com>

Hi Despina

According to your output, you have 270 observations in total, and 270
unique combinations of side, scan date and id. So there is a problem
straight away.

Side appears to have 2 levels : left and right, so I do not see much
justification for treating is as random, so as a first step I would reduce
the random structure to  (1 |
ID/SCAN_DATE) and include side as a fixed effect.

Regards
Rob



On Sun, Jun 16, 2019 at 8:13 PM DESPINA MICHAILIDOU <
de.michailidou at gmail.com> wrote:

> Hi All,
>
> I am trying to run regression analysis adjusted for repeated measures in R.
> The imaging pathology finding defined as Vert_effect, CA_effect,
> Vert_Intens etc is the outcome variable whereas the clinical symptom
> defined as Comb_PH_tod, Comb_PNP_tod etc, is the predictor variable. Other
> predictor variables that I am using are the daily prednisone use (Pred) and
> the use of immunosuppresive therapy (Immune_Categorical) or not. As the
> prednisone variable is being read as character in R i converted it to
> numeric because it is a number. For example some patients are getting 2 mg
> of prednisone but some others 40 mg.  I have two subset of diagnoses,  the
> one is TAK and the second one is GCA. As some patients have either right
> side posterior headache or left side posterior headache or both or none and
> either right side vertebral intensity (imaging study pathology) or left
> side vertebral intensity, or both or none vertebral intensity, for each
> patient I created two rows per subject. The first row represents the right
> sided symptoms and imaging pathology findings and the second row represents
> the left sided symptoms and imaging findings. My repeated measures are the
> side of the symptoms and imaging findings (had to create a separate
> variable for the right and left side symptoms and right and left imaging
> findings that I called it Side and put in there R, L, R, L etc), the ID of
> the patients and the Scan_date visit. Some patients had one scan visit but
> some other patients had multiple scan visits, and that is why I am
> considering scan visit date as a repeated measure. *So this is the code
> that i am using and for the subset of TAK i get this output*
>
> > TAK_data <- subset(Despina, Diagnosis=="TAK")
> > glmm_Vert_Intes <- glmer (Vert_Intes ~ Comb_PH_tod  + (1 |
> ID/SCAN_DATE/Side) + Pred + Immune_Catagorical , data=TAK_data,
> family=binomial(link = "logit"))
> Error in length(value <- as.numeric(value)) == 1L :
>   (maxstephalfit) PIRLS step-halvings failed to reduce deviance in
> pwrssUpdate
> > summary(glmm_Vert_Intes)
>
> *whereas for the subset of GCA patients there are no issues.*
> Generalized linear mixed model fit by maximum likelihood (Laplace
> Approximation) ['glmerMod']
>  Family: binomial  ( logit )
> Formula: Vert_Intes ~ Comb_PH_tod + (1 | ID/SCAN_DATE/Side) + Pred +
> Immune_Catagorical
>    Data: GCA_data
>
>      AIC      BIC   logLik deviance df.resid
>     87.8    113.0    -36.9     73.8      263
>
> Scaled residuals:
>      Min       1Q   Median       3Q      Max
> -0.98336 -0.00342 -0.00241 -0.00214  1.02148
>
> Random effects:
>  Groups              Name        Variance Std.Dev.
>  Side:(SCAN_DATE:ID) (Intercept)   0.00    0.00
>  SCAN_DATE:ID        (Intercept) 528.06   22.98
>  ID                  (Intercept)  18.84    4.34
> Number of obs: 270, groups:  Side:(SCAN_DATE:ID), 270; SCAN_DATE:ID, 135;
> ID, 54
>
> Fixed effects:
>                     Estimate Std. Error z value Pr(>|z|)
> (Intercept)        -10.63649    2.36017  -4.507 6.59e-06 ***
> Comb_PH_tod         -8.53678    4.56601  -1.870   0.0615 .
> Pred                -0.02353    0.09323  -0.252   0.8008
> Immune_Catagorical  -1.41376    2.69420  -0.525   0.5998
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Correlation of Fixed Effects:
>             (Intr) Cm_PH_ Pred
> Comb_PH_tod  0.299
> Pred        -0.289 -0.001
> Immn_Ctgrcl -0.520 -0.068  0.041
> convergence code: 0
> boundary (singular) fit: see ?isSingular
>
> *And this is the detailed code that I am using in R*
> install.packages("lme4")
> install.packages("readr")
>
> library(readr)
> library("lme4")
>
> setwd("~/Desktop/Despina")
> Despina <- read_csv("Despina.csv")
> as.factor(Despina$ID)
> as.factor(Despina$Diagnosis)
> as.factor(Despina$SCAN_DATE)
> as.factor(Despina$Side)
> as.factor(Despina$Immune_Catagorical)
> as.factor(Despina$LH_today)
> as.factor(Despina$PLH_today)
> as.factor(Despina$Dizz_today)
> as.factor(Despina$P_Diz_today)
> as.factor(Despina$CD_tod)
> as.factor(Despina$Head_today)
> as.factor(Despina$Vertig_today)
> as.factor(Despina$FTH_tod)
> as.factor(Despina$Comb_PH_tod)
> as.factor(Despina$Comb_NP_tod)
> as.factor(Despina$Comb_ANP_tod)
> as.factor(Despina$Comb_PNP_tod)
> as.factor(Despina$CNS_ever)
> as.factor(Despina$ULC_today)
> as.factor(Despina$Vert_effect)
> as.factor(Despina$CA_effect)
> as.factor(Despina$Sub_invol)
> as.factor(Despina$Ax_involv)
> as.factor(Despina$CA_intens)
> as.factor(Despina$Sub_intens)
> as.factor(Despina$Vert_Intes)
> as.factor(Despina$Ax_intens)
> as.factor(Despina$Comb_Vis_L_today)
> Despina$Pred<-as.numeric(as.character(Despina$Pred))
>
>
> TAK_data <- subset(Despina, Diagnosis=="TAK")
>
> glmm_Vert_Intes <- glmer (Vert_Intes ~ Comb_PH_tod  + (1 |
> ID/SCAN_DATE/Side) + Pred + Immune_Catagorical , data=TAK_data,
> family=binomial(link = "logit"))
> summary(glmm_Vert_Intes)
>
> GCA_data <- subset(Despina, Diagnosis=="GCA")
>
> glmm_Vert_Intes <- glmer (Vert_Intes ~ Comb_PH_tod  + (1 |
> ID/SCAN_DATE/Side) + Pred + Immune_Catagorical , data=GCA_data,
> family=binomial(link = "logit"))
> summary(glmm_Vert_Intes)
>
> *So my question is why i am getting this error in TAK patients and not in
> GCA patients?*
> Error in length(value <- as.numeric(value)) == 1L :
>   (maxstephalfit) PIRLS step-halvings failed to reduce deviance in
> pwrssUpdate
>
> Thank you all for your time and consideration in advance.
>
> Sincerely,
> Despina
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From de@m|ch@|||dou @end|ng |rom gm@||@com  Mon Jun 17 14:05:52 2019
From: de@m|ch@|||dou @end|ng |rom gm@||@com (DESPINA MICHAILIDOU)
Date: Mon, 17 Jun 2019 08:05:52 -0400
Subject: [R-sig-ME] Mixed model and repeated measures in R
In-Reply-To: <CA+3TTkOAQh6DBiv6JBWGf8B3A_j_On5UfcnkVuzvdvXDkiBhEg@mail.gmail.com>
References: <CAGP99JGZsizcep7mH+iynK5xcictrjQeqGYuarRQsmw8sw5Jxg@mail.gmail.com>
 <CA+3TTkOAQh6DBiv6JBWGf8B3A_j_On5UfcnkVuzvdvXDkiBhEg@mail.gmail.com>
Message-ID: <0BC34625-66A2-4C65-8A1C-E2ABF218FAAD@gmail.com>

Thank you so much for your reply. Appreciate it.
Despina

Sent from my iPhone

> On Jun 17, 2019, at 6:10 AM, Robert Long <longrob604 at gmail.com> wrote:
> 
> Hi Despina
> 
> According to your output, you have 270 observations in total, and 270
> unique combinations of side, scan date and id. So there is a problem
> straight away.
> 
> Side appears to have 2 levels : left and right, so I do not see much
> justification for treating is as random, so as a first step I would reduce
> the random structure to  (1 |
> ID/SCAN_DATE) and include side as a fixed effect.
> 
> Regards
> Rob
> 
> 
> 
> On Sun, Jun 16, 2019 at 8:13 PM DESPINA MICHAILIDOU <
> de.michailidou at gmail.com> wrote:
> 
>> Hi All,
>> 
>> I am trying to run regression analysis adjusted for repeated measures in R.
>> The imaging pathology finding defined as Vert_effect, CA_effect,
>> Vert_Intens etc is the outcome variable whereas the clinical symptom
>> defined as Comb_PH_tod, Comb_PNP_tod etc, is the predictor variable. Other
>> predictor variables that I am using are the daily prednisone use (Pred) and
>> the use of immunosuppresive therapy (Immune_Categorical) or not. As the
>> prednisone variable is being read as character in R i converted it to
>> numeric because it is a number. For example some patients are getting 2 mg
>> of prednisone but some others 40 mg.  I have two subset of diagnoses,  the
>> one is TAK and the second one is GCA. As some patients have either right
>> side posterior headache or left side posterior headache or both or none and
>> either right side vertebral intensity (imaging study pathology) or left
>> side vertebral intensity, or both or none vertebral intensity, for each
>> patient I created two rows per subject. The first row represents the right
>> sided symptoms and imaging pathology findings and the second row represents
>> the left sided symptoms and imaging findings. My repeated measures are the
>> side of the symptoms and imaging findings (had to create a separate
>> variable for the right and left side symptoms and right and left imaging
>> findings that I called it Side and put in there R, L, R, L etc), the ID of
>> the patients and the Scan_date visit. Some patients had one scan visit but
>> some other patients had multiple scan visits, and that is why I am
>> considering scan visit date as a repeated measure. *So this is the code
>> that i am using and for the subset of TAK i get this output*
>> 
>>> TAK_data <- subset(Despina, Diagnosis=="TAK")
>>> glmm_Vert_Intes <- glmer (Vert_Intes ~ Comb_PH_tod  + (1 |
>> ID/SCAN_DATE/Side) + Pred + Immune_Catagorical , data=TAK_data,
>> family=binomial(link = "logit"))
>> Error in length(value <- as.numeric(value)) == 1L :
>>  (maxstephalfit) PIRLS step-halvings failed to reduce deviance in
>> pwrssUpdate
>>> summary(glmm_Vert_Intes)
>> 
>> *whereas for the subset of GCA patients there are no issues.*
>> Generalized linear mixed model fit by maximum likelihood (Laplace
>> Approximation) ['glmerMod']
>> Family: binomial  ( logit )
>> Formula: Vert_Intes ~ Comb_PH_tod + (1 | ID/SCAN_DATE/Side) + Pred +
>> Immune_Catagorical
>>   Data: GCA_data
>> 
>>     AIC      BIC   logLik deviance df.resid
>>    87.8    113.0    -36.9     73.8      263
>> 
>> Scaled residuals:
>>     Min       1Q   Median       3Q      Max
>> -0.98336 -0.00342 -0.00241 -0.00214  1.02148
>> 
>> Random effects:
>> Groups              Name        Variance Std.Dev.
>> Side:(SCAN_DATE:ID) (Intercept)   0.00    0.00
>> SCAN_DATE:ID        (Intercept) 528.06   22.98
>> ID                  (Intercept)  18.84    4.34
>> Number of obs: 270, groups:  Side:(SCAN_DATE:ID), 270; SCAN_DATE:ID, 135;
>> ID, 54
>> 
>> Fixed effects:
>>                    Estimate Std. Error z value Pr(>|z|)
>> (Intercept)        -10.63649    2.36017  -4.507 6.59e-06 ***
>> Comb_PH_tod         -8.53678    4.56601  -1.870   0.0615 .
>> Pred                -0.02353    0.09323  -0.252   0.8008
>> Immune_Catagorical  -1.41376    2.69420  -0.525   0.5998
>> ---
>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>> 
>> Correlation of Fixed Effects:
>>            (Intr) Cm_PH_ Pred
>> Comb_PH_tod  0.299
>> Pred        -0.289 -0.001
>> Immn_Ctgrcl -0.520 -0.068  0.041
>> convergence code: 0
>> boundary (singular) fit: see ?isSingular
>> 
>> *And this is the detailed code that I am using in R*
>> install.packages("lme4")
>> install.packages("readr")
>> 
>> library(readr)
>> library("lme4")
>> 
>> setwd("~/Desktop/Despina")
>> Despina <- read_csv("Despina.csv")
>> as.factor(Despina$ID)
>> as.factor(Despina$Diagnosis)
>> as.factor(Despina$SCAN_DATE)
>> as.factor(Despina$Side)
>> as.factor(Despina$Immune_Catagorical)
>> as.factor(Despina$LH_today)
>> as.factor(Despina$PLH_today)
>> as.factor(Despina$Dizz_today)
>> as.factor(Despina$P_Diz_today)
>> as.factor(Despina$CD_tod)
>> as.factor(Despina$Head_today)
>> as.factor(Despina$Vertig_today)
>> as.factor(Despina$FTH_tod)
>> as.factor(Despina$Comb_PH_tod)
>> as.factor(Despina$Comb_NP_tod)
>> as.factor(Despina$Comb_ANP_tod)
>> as.factor(Despina$Comb_PNP_tod)
>> as.factor(Despina$CNS_ever)
>> as.factor(Despina$ULC_today)
>> as.factor(Despina$Vert_effect)
>> as.factor(Despina$CA_effect)
>> as.factor(Despina$Sub_invol)
>> as.factor(Despina$Ax_involv)
>> as.factor(Despina$CA_intens)
>> as.factor(Despina$Sub_intens)
>> as.factor(Despina$Vert_Intes)
>> as.factor(Despina$Ax_intens)
>> as.factor(Despina$Comb_Vis_L_today)
>> Despina$Pred<-as.numeric(as.character(Despina$Pred))
>> 
>> 
>> TAK_data <- subset(Despina, Diagnosis=="TAK")
>> 
>> glmm_Vert_Intes <- glmer (Vert_Intes ~ Comb_PH_tod  + (1 |
>> ID/SCAN_DATE/Side) + Pred + Immune_Catagorical , data=TAK_data,
>> family=binomial(link = "logit"))
>> summary(glmm_Vert_Intes)
>> 
>> GCA_data <- subset(Despina, Diagnosis=="GCA")
>> 
>> glmm_Vert_Intes <- glmer (Vert_Intes ~ Comb_PH_tod  + (1 |
>> ID/SCAN_DATE/Side) + Pred + Immune_Catagorical , data=GCA_data,
>> family=binomial(link = "logit"))
>> summary(glmm_Vert_Intes)
>> 
>> *So my question is why i am getting this error in TAK patients and not in
>> GCA patients?*
>> Error in length(value <- as.numeric(value)) == 1L :
>>  (maxstephalfit) PIRLS step-halvings failed to reduce deviance in
>> pwrssUpdate
>> 
>> Thank you all for your time and consideration in advance.
>> 
>> Sincerely,
>> Despina
>> 
>>        [[alternative HTML version deleted]]
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 
> 
>    [[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From @@m_cr@w|ey @end|ng |rom w@rpm@||@net  Tue Jun 18 03:44:25 2019
From: @@m_cr@w|ey @end|ng |rom w@rpm@||@net (Sam Crawley)
Date: Tue, 18 Jun 2019 13:44:25 +1200
Subject: [R-sig-ME] 
 =?utf-8?q?Predicted_probabilites_with_CIs_for_multile?=
 =?utf-8?q?vel_logistic_regression_with_prior_weights?=
In-Reply-To: <000e01d51fa1$74c85760$5e590620$@uke.de>
References: <e4431ad0-e1aa-47f5-a9aa-32556ca1d332@www.fastmail.com>
 <000e01d51fa1$74c85760$5e590620$@uke.de>
Message-ID: <54f9cf5d-a758-4906-a2eb-767cfd79f562@www.fastmail.com>

Hi again Daniel (and list),

Thanks again for the below. I have been using the ggpredict() function, and it works well. However, should I be using the type = "re" parameter? Or is this only required when attempting to predict values for each group? (I have read the ggeffects documentation on this, but it's still not entirely clear to me).

When adding type="re", the confidence intervals become very wide, which is obviously not ideal.

Thanks,
Sam Crawley.

On Tue, 11 Jun 2019, at 03:30, d.luedecke at uke.de wrote:
> Hi Sam,
> 
> you could the "ggeffects" package
> (https://strengejacke.github.io/ggeffects/), and there is also an example
> for a logistic mixed effects model
> (https://strengejacke.github.io/ggeffects/articles/practical_logisticmixedmo
> del.html), which might help you.
> 
> For binomial models, using weights often results in the following warning:
> #> non-integer #successes in a binomial glm!
> 
> However, CIs for the predicted probabilities can be calculated nevertheless
> (at least in my quick example). Note that afaik, mixed models in R do
> correctly not account for sampling weights. However, Thomas Lumley, author
> of the survey-package, works on a survey-function for mixed models
> (https://github.com/tslumley/svylme), probably the GitHub version is quite
> stable (haven't tested yet).
> 
> An alternative would be the "scale_weights()" function from the
> sjstats-package
> (https://strengejacke.github.io/sjstats/articles/mixedmodels-statistics.html
> #rescale-model-weights-for-complex-samples ), which rescales sampling
> weights so they can be used as "weights" for the mixed models function you
> have in R (lme4, lme, ...).
> 
> Based on that function, I have a small example that demonstrates how to
> compute predicted probabilities for mixed models with (sampling) weights
> (ignore the warnings, this is just for demonstration purposes):
> 
> library(lme4)
> library(sjstats) # for scale_weights() and sample data
> library(ggeffects) # for ggpredict()
> 
> data(nhanes_sample)
> set.seed(123)
> nhanes_sample$bin <- rbinom(nrow(nhanes_sample), 1, prob = .3)
> nhanes_sample <- scale_weights(nhanes_sample, SDMVSTRA, WTINT2YR)
> 
> m <- glmer(
>   bin ~ factor(RIAGENDR) * age + factor(RIDRETH1) + (1 | SDMVPSU),
>   family = binomial(),
>   data = nhanes_sample,
>   weights = svywght_a
> )
> 
> ggpredict(m, c("age", "RIAGENDR")) %>% plot()
> 
> 
> Best
> Daniel
> 
> -----Urspr?ngliche Nachricht-----
> Von: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> Im
> Auftrag von Sam Crawley
> Gesendet: Montag, 10. Juni 2019 10:36
> An: r-sig-mixed-models at r-project.org
> Betreff: [R-sig-ME] Predicted probabilites with CIs for multilevel logistic
> regression with prior weights
> 
> Hello all,
> 
> I am doing a multilevel binomial logistic regression using lme4, and the
> survey data I am using requires weights to be used. I would like to
> calculate various predicted probabilities with confidence intervals based on
> the estimated model. The predict function obviously doesn't give me standard
> errors, and the recommended method to get these is to use the bootMer
> function.
> 
> However, in my case, the weights provided are not integers, and the bootMer
> function exits with an error if the weights are not integers (I raised a
> GitHub issue about this, and was pointed to this list:
> https://github.com/lme4/lme4/issues/524 ).
> 
> So my question is, what is the best way to calculate the predicted
> probabilities (with confidence intervals) in my case?
> 
> I would appreciate any help you can give me, and I'm happy to provide more
> details if required.
> 
> Thanks,
> Sam Crawley.
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> --
> 
> _____________________________________________________________________
> 
> Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen 
> Rechts; Gerichtsstand: Hamburg | www.uke.de
> Vorstandsmitglieder: Prof. Dr. Burkhard G?ke (Vorsitzender), Prof. Dr. 
> Dr. Uwe Koch-Gromus, Joachim Pr?l?, Marya Verdel
> _____________________________________________________________________
> 
> SAVE PAPER - THINK BEFORE PRINTING
> 
>


From d@iuedecke m@iii@g oii uke@de  Tue Jun 18 08:30:16 2019
From: d@iuedecke m@iii@g oii uke@de (d@iuedecke m@iii@g oii uke@de)
Date: Tue, 18 Jun 2019 08:30:16 +0200
Subject: [R-sig-ME] 
 Predicted probabilites with CIs for multilevel logistic
 regression with prior weights
In-Reply-To: <54f9cf5d-a758-4906-a2eb-767cfd79f562@www.fastmail.com>
References: <e4431ad0-e1aa-47f5-a9aa-32556ca1d332@www.fastmail.com>
 <000e01d51fa1$74c85760$5e590620$@uke.de>
 <54f9cf5d-a758-4906-a2eb-767cfd79f562@www.fastmail.com>
Message-ID: <000001d5259f$4ba2dcd0$e2e89670$@uke.de>

> However, should I be using the type = "re" parameter?

This depends on whether you would like to have confidence or prediction intervals. I'm not sure if there's a clear definition, or a consensus on how to obtain prediction intervals. There's a section about this in Ben Bolker's GLMM-FAQ:
http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#predictions-andor-confidence-or-prediction-intervals-on-predictions

He states that you want to add the residual variance to compute prediction intervals. However, there are also some caveats: https://stackoverflow.com/questions/14358811/extract-prediction-band-from-lme-fit

Ben also has a comment in his examples: "## must be adapted for more complex models". I'm not sure if this refers only to make sure to compute sigma properly, or if you also need to take the random effect variances into account. ggeffects currently computes the standard error for type = "re" based on the *random effects variances* (see details here: https://easystats.github.io/insight/reference/get_variance.html). This seems to be even a bit more conservative than just taking the residual variance. But again, any comments on this are welcome. I've been in email exchange with Russell Lenth, maintainer of the emmeans-package, and we were also talking about if it's actually straightforward to obtain prediction intervals, or not. In the latest emmeans-release, there is a vignette on this topic (https://cran.r-project.org/web/packages/emmeans/vignettes/predictions.html).

In short: you don't need to specify type = "re" if you want to get predictions from your mixed models. Predictions for both type = "fe" and type = "re" are always on a population-level. However, you need type = "re" if you want to make predictions at each level of the random effects (group factor), see https://strengejacke.github.io/ggeffects/articles/randomeffects.html#marginal-effects-for-each-level-of-random-effects (though here you don't get any intervals).

Best
Daniel

-----Urspr?ngliche Nachricht-----
Von: Sam Crawley <sam_crawley at warpmail.net> 
Gesendet: Dienstag, 18. Juni 2019 03:44
An: d.luedecke <d.luedecke at uke.de>; r-sig-mixed-models at r-project.org
Betreff: Re: [R-sig-ME] Predicted probabilites with CIs for multilevel logistic regression with prior weights

Hi again Daniel (and list),

Thanks again for the below. I have been using the ggpredict() function, and it works well. However, should I be using the type = "re" parameter? Or is this only required when attempting to predict values for each group? (I have read the ggeffects documentation on this, but it's still not entirely clear to me).

When adding type="re", the confidence intervals become very wide, which is obviously not ideal.

Thanks,
Sam Crawley.

On Tue, 11 Jun 2019, at 03:30, d.luedecke at uke.de wrote:
> Hi Sam,
> 
> you could the "ggeffects" package
> (https://strengejacke.github.io/ggeffects/), and there is also an example
> for a logistic mixed effects model
> (https://strengejacke.github.io/ggeffects/articles/practical_logisticmixedmo
> del.html), which might help you.
> 
> For binomial models, using weights often results in the following warning:
> #> non-integer #successes in a binomial glm!
> 
> However, CIs for the predicted probabilities can be calculated nevertheless
> (at least in my quick example). Note that afaik, mixed models in R do
> correctly not account for sampling weights. However, Thomas Lumley, author
> of the survey-package, works on a survey-function for mixed models
> (https://github.com/tslumley/svylme), probably the GitHub version is quite
> stable (haven't tested yet).
> 
> An alternative would be the "scale_weights()" function from the
> sjstats-package
> (https://strengejacke.github.io/sjstats/articles/mixedmodels-statistics.html
> #rescale-model-weights-for-complex-samples ), which rescales sampling
> weights so they can be used as "weights" for the mixed models function you
> have in R (lme4, lme, ...).
> 
> Based on that function, I have a small example that demonstrates how to
> compute predicted probabilities for mixed models with (sampling) weights
> (ignore the warnings, this is just for demonstration purposes):
> 
> library(lme4)
> library(sjstats) # for scale_weights() and sample data
> library(ggeffects) # for ggpredict()
> 
> data(nhanes_sample)
> set.seed(123)
> nhanes_sample$bin <- rbinom(nrow(nhanes_sample), 1, prob = .3)
> nhanes_sample <- scale_weights(nhanes_sample, SDMVSTRA, WTINT2YR)
> 
> m <- glmer(
>   bin ~ factor(RIAGENDR) * age + factor(RIDRETH1) + (1 | SDMVPSU),
>   family = binomial(),
>   data = nhanes_sample,
>   weights = svywght_a
> )
> 
> ggpredict(m, c("age", "RIAGENDR")) %>% plot()
> 
> 
> Best
> Daniel
> 
> -----Urspr?ngliche Nachricht-----
> Von: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> Im
> Auftrag von Sam Crawley
> Gesendet: Montag, 10. Juni 2019 10:36
> An: r-sig-mixed-models at r-project.org
> Betreff: [R-sig-ME] Predicted probabilites with CIs for multilevel logistic
> regression with prior weights
> 
> Hello all,
> 
> I am doing a multilevel binomial logistic regression using lme4, and the
> survey data I am using requires weights to be used. I would like to
> calculate various predicted probabilities with confidence intervals based on
> the estimated model. The predict function obviously doesn't give me standard
> errors, and the recommended method to get these is to use the bootMer
> function.
> 
> However, in my case, the weights provided are not integers, and the bootMer
> function exits with an error if the weights are not integers (I raised a
> GitHub issue about this, and was pointed to this list:
> https://github.com/lme4/lme4/issues/524 ).
> 
> So my question is, what is the best way to calculate the predicted
> probabilities (with confidence intervals) in my case?
> 
> I would appreciate any help you can give me, and I'm happy to provide more
> details if required.
> 
> Thanks,
> Sam Crawley.
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> --
> 
> _____________________________________________________________________
> 
> Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen 
> Rechts; Gerichtsstand: Hamburg | www.uke.de
> Vorstandsmitglieder: Prof. Dr. Burkhard G?ke (Vorsitzender), Prof. Dr. 
> Dr. Uwe Koch-Gromus, Joachim Pr?l?, Marya Verdel
> _____________________________________________________________________
> 
> SAVE PAPER - THINK BEFORE PRINTING
> 
>

--

_____________________________________________________________________

Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen Rechts; Gerichtsstand: Hamburg | www.uke.de
Vorstandsmitglieder: Prof. Dr. Burkhard G?ke (Vorsitzender), Prof. Dr. Dr. Uwe Koch-Gromus, Joachim Pr?l?, Marya Verdel
_____________________________________________________________________

SAVE PAPER - THINK BEFORE PRINTING

From @@m_cr@w|ey @end|ng |rom w@rpm@||@net  Tue Jun 18 23:11:10 2019
From: @@m_cr@w|ey @end|ng |rom w@rpm@||@net (Sam Crawley)
Date: Wed, 19 Jun 2019 09:11:10 +1200
Subject: [R-sig-ME] 
 =?utf-8?q?Predicted_probabilites_with_CIs_for_multile?=
 =?utf-8?q?vel_logistic_regression_with_prior_weights?=
In-Reply-To: <000001d5259f$4ba2dcd0$e2e89670$@uke.de>
References: <e4431ad0-e1aa-47f5-a9aa-32556ca1d332@www.fastmail.com>
 <000e01d51fa1$74c85760$5e590620$@uke.de>
 <54f9cf5d-a758-4906-a2eb-767cfd79f562@www.fastmail.com>
 <000001d5259f$4ba2dcd0$e2e89670$@uke.de>
Message-ID: <54e549d1-e8b9-4c39-8b27-3979e1db2438@www.fastmail.com>

Hi Daniel,

Thanks very much, that clears it up.

Cheers,
Sam.

On Tue, 18 Jun 2019, at 18:30, d.luedecke at uke.de wrote:
> > However, should I be using the type = "re" parameter?
> 
> This depends on whether you would like to have confidence or prediction 
> intervals. I'm not sure if there's a clear definition, or a consensus 
> on how to obtain prediction intervals. There's a section about this in 
> Ben Bolker's GLMM-FAQ:
> http://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#predictions-andor-confidence-or-prediction-intervals-on-predictions
> 
> He states that you want to add the residual variance to compute 
> prediction intervals. However, there are also some caveats: 
> https://stackoverflow.com/questions/14358811/extract-prediction-band-from-lme-fit
> 
> Ben also has a comment in his examples: "## must be adapted for more 
> complex models". I'm not sure if this refers only to make sure to 
> compute sigma properly, or if you also need to take the random effect 
> variances into account. ggeffects currently computes the standard error 
> for type = "re" based on the *random effects variances* (see details 
> here: https://easystats.github.io/insight/reference/get_variance.html). 
> This seems to be even a bit more conservative than just taking the 
> residual variance. But again, any comments on this are welcome. I've 
> been in email exchange with Russell Lenth, maintainer of the 
> emmeans-package, and we were also talking about if it's actually 
> straightforward to obtain prediction intervals, or not. In the latest 
> emmeans-release, there is a vignette on this topic 
> (https://cran.r-project.org/web/packages/emmeans/vignettes/predictions.html).
> 
> In short: you don't need to specify type = "re" if you want to get 
> predictions from your mixed models. Predictions for both type = "fe" 
> and type = "re" are always on a population-level. However, you need 
> type = "re" if you want to make predictions at each level of the random 
> effects (group factor), see 
> https://strengejacke.github.io/ggeffects/articles/randomeffects.html#marginal-effects-for-each-level-of-random-effects (though here you don't get any intervals).
> 
> Best
> Daniel
> 
> -----Urspr?ngliche Nachricht-----
> Von: Sam Crawley <sam_crawley at warpmail.net> 
> Gesendet: Dienstag, 18. Juni 2019 03:44
> An: d.luedecke <d.luedecke at uke.de>; r-sig-mixed-models at r-project.org
> Betreff: Re: [R-sig-ME] Predicted probabilites with CIs for multilevel 
> logistic regression with prior weights
> 
> Hi again Daniel (and list),
> 
> Thanks again for the below. I have been using the ggpredict() function, 
> and it works well. However, should I be using the type = "re" 
> parameter? Or is this only required when attempting to predict values 
> for each group? (I have read the ggeffects documentation on this, but 
> it's still not entirely clear to me).
> 
> When adding type="re", the confidence intervals become very wide, which 
> is obviously not ideal.
> 
> Thanks,
> Sam Crawley.
> 
> On Tue, 11 Jun 2019, at 03:30, d.luedecke at uke.de wrote:
> > Hi Sam,
> > 
> > you could the "ggeffects" package
> > (https://strengejacke.github.io/ggeffects/), and there is also an example
> > for a logistic mixed effects model
> > (https://strengejacke.github.io/ggeffects/articles/practical_logisticmixedmo
> > del.html), which might help you.
> > 
> > For binomial models, using weights often results in the following warning:
> > #> non-integer #successes in a binomial glm!
> > 
> > However, CIs for the predicted probabilities can be calculated nevertheless
> > (at least in my quick example). Note that afaik, mixed models in R do
> > correctly not account for sampling weights. However, Thomas Lumley, author
> > of the survey-package, works on a survey-function for mixed models
> > (https://github.com/tslumley/svylme), probably the GitHub version is quite
> > stable (haven't tested yet).
> > 
> > An alternative would be the "scale_weights()" function from the
> > sjstats-package
> > (https://strengejacke.github.io/sjstats/articles/mixedmodels-statistics.html
> > #rescale-model-weights-for-complex-samples ), which rescales sampling
> > weights so they can be used as "weights" for the mixed models function you
> > have in R (lme4, lme, ...).
> > 
> > Based on that function, I have a small example that demonstrates how to
> > compute predicted probabilities for mixed models with (sampling) weights
> > (ignore the warnings, this is just for demonstration purposes):
> > 
> > library(lme4)
> > library(sjstats) # for scale_weights() and sample data
> > library(ggeffects) # for ggpredict()
> > 
> > data(nhanes_sample)
> > set.seed(123)
> > nhanes_sample$bin <- rbinom(nrow(nhanes_sample), 1, prob = .3)
> > nhanes_sample <- scale_weights(nhanes_sample, SDMVSTRA, WTINT2YR)
> > 
> > m <- glmer(
> >   bin ~ factor(RIAGENDR) * age + factor(RIDRETH1) + (1 | SDMVPSU),
> >   family = binomial(),
> >   data = nhanes_sample,
> >   weights = svywght_a
> > )
> > 
> > ggpredict(m, c("age", "RIAGENDR")) %>% plot()
> > 
> > 
> > Best
> > Daniel
> > 
> > -----Urspr?ngliche Nachricht-----
> > Von: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> Im
> > Auftrag von Sam Crawley
> > Gesendet: Montag, 10. Juni 2019 10:36
> > An: r-sig-mixed-models at r-project.org
> > Betreff: [R-sig-ME] Predicted probabilites with CIs for multilevel logistic
> > regression with prior weights
> > 
> > Hello all,
> > 
> > I am doing a multilevel binomial logistic regression using lme4, and the
> > survey data I am using requires weights to be used. I would like to
> > calculate various predicted probabilities with confidence intervals based on
> > the estimated model. The predict function obviously doesn't give me standard
> > errors, and the recommended method to get these is to use the bootMer
> > function.
> > 
> > However, in my case, the weights provided are not integers, and the bootMer
> > function exits with an error if the weights are not integers (I raised a
> > GitHub issue about this, and was pointed to this list:
> > https://github.com/lme4/lme4/issues/524 ).
> > 
> > So my question is, what is the best way to calculate the predicted
> > probabilities (with confidence intervals) in my case?
> > 
> > I would appreciate any help you can give me, and I'm happy to provide more
> > details if required.
> > 
> > Thanks,
> > Sam Crawley.
> > 
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > 
> > --
> > 
> > _____________________________________________________________________
> > 
> > Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen 
> > Rechts; Gerichtsstand: Hamburg | www.uke.de
> > Vorstandsmitglieder: Prof. Dr. Burkhard G?ke (Vorsitzender), Prof. Dr. 
> > Dr. Uwe Koch-Gromus, Joachim Pr?l?, Marya Verdel
> > _____________________________________________________________________
> > 
> > SAVE PAPER - THINK BEFORE PRINTING
> > 
> >
> 
> --
> 
> _____________________________________________________________________
> 
> Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen 
> Rechts; Gerichtsstand: Hamburg | www.uke.de
> Vorstandsmitglieder: Prof. Dr. Burkhard G?ke (Vorsitzender), Prof. Dr. 
> Dr. Uwe Koch-Gromus, Joachim Pr?l?, Marya Verdel
> _____________________________________________________________________
> 
> SAVE PAPER - THINK BEFORE PRINTING
>


From Ju||@n@G@v|r|@Lopez @end|ng |rom un|ge@ch  Thu Jun 20 17:54:55 2019
From: Ju||@n@G@v|r|@Lopez @end|ng |rom un|ge@ch (Julian Gaviria Lopez)
Date: Thu, 20 Jun 2019 15:54:55 +0000
Subject: [R-sig-ME] Is it possible to compute pairwise differences of
 LS-mean for all factors in a Generalized linear mixed model.
Message-ID: <c0473c5ac52e4d939de35e2dce39cd19@unige.ch>

Hi everyone,


I am fitting the next model with the glmm TMB package:

> fit_zipoisson2 <- glmmTMB(Observations ~ CAP * Time + (1|ID), data=mDATA,

ziformula=~ 1 , family=poisson)

and I obtain as output the next one:


> summary(fit_zipoisson2)

 Family: poisson  ( log )

Formula:          Observations ~ CAP * Time + (1 | ID)

Zero inflation:                ~1

Data: mDATA



     AIC      BIC   logLik deviance df.resid

  1252.8   1339.5   -604.4   1208.8      358



Random effects:



Conditional model:

 Groups Name        Variance Std.Dev.

 ID     (Intercept) 0.03325  0.1824

Number of obs: 380, groups:  ID, 19



Conditional model:

                Estimate Std. Error z value Pr(>|z|)

(Intercept)      1.29264    0.14364   8.999   <2e-16 ***

CAPinsC5        -0.70525    0.29149  -2.419   0.0155 *

CAPpreC1        -0.21058    0.21474  -0.981   0.3268

CAPpreC3        -0.14764    0.24991  -0.591   0.5547

Timem1          -0.06505    0.22609  -0.288   0.7736

Timem3          -0.11959    0.21359  -0.560   0.5755

Timem4          -0.37762    0.21934  -1.722   0.0851 .

Timem5          -0.31970    0.22905  -1.396   0.1628

CAPinsC5:Timem1  0.19259    0.47302   0.407   0.6839

CAPpreC1:Timem1 -0.73915    0.49687  -1.488   0.1368

CAPpreC3:Timem1 -1.02677    0.54285  -1.891   0.0586 .

CAPinsC5:Timem3  0.11425    0.43376   0.263   0.7923

CAPpreC1:Timem3 -0.42517    0.35701  -1.191   0.2337

CAPpreC3:Timem3 -0.14454    0.42445  -0.341   0.7335

CAPinsC5:Timem4  0.76611    0.39757   1.927   0.0440 *

CAPpreC1:Timem4  0.26068    0.32745   0.796   0.4260

CAPpreC3:Timem4 -0.06192    0.41907  -0.148   0.8825

CAPinsC5:Timem5  0.30779    0.50160   0.614   0.5395

CAPpreC1:Timem5  0.42848    0.37898   1.131   0.2582

CAPpreC3:Timem5  0.37346    0.35116   1.063   0.2876


Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1



Zero-inflation model:

            Estimate Std. Error z value Pr(>|z|)

(Intercept)  -0.2467     0.1282  -1.924   0.0543 .

---

Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

How can I observe the changes of the same CAP across time? Regardless if it is the intercept or not? E.g.:
preC5 m1 vs preC5 m2
preC5 m1 vs preC5 m3
preC5 m1 vs preC5 m4
preC5 m1 vs preC5 m4

preC1 m1 vs preC1 m2
? etc.

And how can I observe the changes
of the CAPs in relation to the predictor CAP (preC5) over time? E.g.:
preC1 m1 vs preC5 m1
preC1 m1 vs preC5 m2
preC1 m1 vs preC5 m3
preC1 m1 vs preC5 m4
preC1 m1 vs preC5 m5

I look for something similar to the Least-Square means and pairwise differences functions implemented in other packages for mixed models, such as
the lmerTest:
https://cran.r-project.org/web/packages/lmerTest/lmerTest.pdf


 Thanks a lot in advance

Julian Gaviria
Neurology and Imaging of cognition lab (Labnic)
University of Geneva. Campus Biotech.
9 Chemin des Mines, 1202 Geneva, CH
Tel: +41 22 379 0380
Email: Julian.GaviriaLopez at unige.ch

	[[alternative HTML version deleted]]


From gu|||@ume@|mon@@2 @end|ng |rom gm@||@com  Thu Jun 20 19:05:13 2019
From: gu|||@ume@|mon@@2 @end|ng |rom gm@||@com (Guillaume Adeux)
Date: Thu, 20 Jun 2019 19:05:13 +0200
Subject: [R-sig-ME] Is it possible to compute pairwise differences of
 LS-mean for all factors in a Generalized linear mixed model.
In-Reply-To: <c0473c5ac52e4d939de35e2dce39cd19@unige.ch>
References: <c0473c5ac52e4d939de35e2dce39cd19@unige.ch>
Message-ID: <CAENiVe8OhR69S-m3mQkL+pisJkyFszgKW+2B8eUpyn4y93rLFg@mail.gmail.com>

Hi Julian,

You should look into the {emmeans} package and the function emmeans. The
vignettes are very nice, the package has a lot of features and from what I
can remember, glmmTMB is handled. Maybe time should be treated as
continuous and you should test slopes between CAP (with the emtrends()
function)?

Nevertheless, you could try different contrasts like:
emmeans(fit_zipoisson2, CAP|time)
or
emmeans(fit_zipoisson2, time|CAP)
or
emmeans(fit_zipoisson2, time*CAP)

You could the wrap the call with cld() from the {multcomp} package to
obtain a compact letter display.

Cheers,

GA2



<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
Virus-free.
www.avast.com
<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
<#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>

Le jeu. 20 juin 2019 ? 17:55, Julian Gaviria Lopez <
Julian.GaviriaLopez at unige.ch> a ?crit :

> Hi everyone,
>
>
> I am fitting the next model with the glmm TMB package:
>
> > fit_zipoisson2 <- glmmTMB(Observations ~ CAP * Time + (1|ID), data=mDATA,
>
> ziformula=~ 1 , family=poisson)
>
> and I obtain as output the next one:
>
>
> > summary(fit_zipoisson2)
>
>  Family: poisson  ( log )
>
> Formula:          Observations ~ CAP * Time + (1 | ID)
>
> Zero inflation:                ~1
>
> Data: mDATA
>
>
>
>      AIC      BIC   logLik deviance df.resid
>
>   1252.8   1339.5   -604.4   1208.8      358
>
>
>
> Random effects:
>
>
>
> Conditional model:
>
>  Groups Name        Variance Std.Dev.
>
>  ID     (Intercept) 0.03325  0.1824
>
> Number of obs: 380, groups:  ID, 19
>
>
>
> Conditional model:
>
>                 Estimate Std. Error z value Pr(>|z|)
>
> (Intercept)      1.29264    0.14364   8.999   <2e-16 ***
>
> CAPinsC5        -0.70525    0.29149  -2.419   0.0155 *
>
> CAPpreC1        -0.21058    0.21474  -0.981   0.3268
>
> CAPpreC3        -0.14764    0.24991  -0.591   0.5547
>
> Timem1          -0.06505    0.22609  -0.288   0.7736
>
> Timem3          -0.11959    0.21359  -0.560   0.5755
>
> Timem4          -0.37762    0.21934  -1.722   0.0851 .
>
> Timem5          -0.31970    0.22905  -1.396   0.1628
>
> CAPinsC5:Timem1  0.19259    0.47302   0.407   0.6839
>
> CAPpreC1:Timem1 -0.73915    0.49687  -1.488   0.1368
>
> CAPpreC3:Timem1 -1.02677    0.54285  -1.891   0.0586 .
>
> CAPinsC5:Timem3  0.11425    0.43376   0.263   0.7923
>
> CAPpreC1:Timem3 -0.42517    0.35701  -1.191   0.2337
>
> CAPpreC3:Timem3 -0.14454    0.42445  -0.341   0.7335
>
> CAPinsC5:Timem4  0.76611    0.39757   1.927   0.0440 *
>
> CAPpreC1:Timem4  0.26068    0.32745   0.796   0.4260
>
> CAPpreC3:Timem4 -0.06192    0.41907  -0.148   0.8825
>
> CAPinsC5:Timem5  0.30779    0.50160   0.614   0.5395
>
> CAPpreC1:Timem5  0.42848    0.37898   1.131   0.2582
>
> CAPpreC3:Timem5  0.37346    0.35116   1.063   0.2876
>
>
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
>
>
> Zero-inflation model:
>
>             Estimate Std. Error z value Pr(>|z|)
>
> (Intercept)  -0.2467     0.1282  -1.924   0.0543 .
>
> ---
>
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> How can I observe the changes of the same CAP across time? Regardless if
> it is the intercept or not? E.g.:
> preC5 m1 vs preC5 m2
> preC5 m1 vs preC5 m3
> preC5 m1 vs preC5 m4
> preC5 m1 vs preC5 m4
>
> preC1 m1 vs preC1 m2
> ? etc.
>
> And how can I observe the changes
> of the CAPs in relation to the predictor CAP (preC5) over time? E.g.:
> preC1 m1 vs preC5 m1
> preC1 m1 vs preC5 m2
> preC1 m1 vs preC5 m3
> preC1 m1 vs preC5 m4
> preC1 m1 vs preC5 m5
>
> I look for something similar to the Least-Square means and pairwise
> differences functions implemented in other packages for mixed models, such
> as
> the lmerTest:
> https://cran.r-project.org/web/packages/lmerTest/lmerTest.pdf
>
>
>  Thanks a lot in advance
>
> Julian Gaviria
> Neurology and Imaging of cognition lab (Labnic)
> University of Geneva. Campus Biotech.
> 9 Chemin des Mines, 1202 Geneva, CH
> Tel: +41 22 379 0380
> Email: Julian.GaviriaLopez at unige.ch
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
Virus-free.
www.avast.com
<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
<#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>

	[[alternative HTML version deleted]]


From mrgu|||oy|e @end|ng |rom gm@||@com  Mon Jun 24 14:33:51 2019
From: mrgu|||oy|e @end|ng |rom gm@||@com (Mathew Guilfoyle)
Date: Mon, 24 Jun 2019 13:33:51 +0100
Subject: [R-sig-ME] Nested random effects in mgcv gam/bam
Message-ID: <CBAF1820-469C-4C0C-8BE0-111EF2006501@gmail.com>

I have a dataset comprising of subjects with a unique identifier ?ID? who are each in one of two groups ?G? .  I am looking to find the smooth relationship between numerical variables A and B that are both evaluated at multiple times in each subject.  

Ignoring the grouping for the moment, a GAM formula including random intercept and ?slope? for each subject would be:

m1 = bam(B ~ s(A, bs=?cr?, k=10) + s(ID, bs=?re?) + s(ID, A, bs=?re?))

Now, I believe the smooth is different in each group therefore I want to obtain separate smooths based on G, and also include random intercepts and ?slope? for each subject but nested within each group.

Which of the following constructions is correct? (G is a factor)?:

m2a = bam(B ~ G + s(A, bs=?cr?, k=10, by=G) + s(G, ID, bs=?re?) + s(G, ID, A, bs=?re?))

m2b = bam(B ~ G + s(A, bs=?cr?, k=10, by=G) + s(ID, bs=?re?, by=G) + s(ID, A, bs=?re?, by=G))


I have tried do this more explicitly using gamm:

m3 = gamm(B ~ G + s(A, bs=?cr?, k=10, by=G), random = list(G=~1+A, ID=~1+A)) 

but this takes a lot longer (hours) to run given the size of the dataset and as I don?t need/want to specify the correlation structure of the random effects I hoped that one of the bam calls above was equivalent.  I have tried the various models on a subset of the data and model m2a gives qualitatively very similar smooths to model m3.

Thanks.

From c@c@voeten @end|ng |rom hum@|e|denun|v@n|  Mon Jun 24 15:37:11 2019
From: c@c@voeten @end|ng |rom hum@|e|denun|v@n| (Voeten, C.C.)
Date: Mon, 24 Jun 2019 13:37:11 +0000
Subject: [R-sig-ME] R:  Nested random effects in mgcv gam/bam
In-Reply-To: <CBAF1820-469C-4C0C-8BE0-111EF2006501@gmail.com>
References: <CBAF1820-469C-4C0C-8BE0-111EF2006501@gmail.com>
Message-ID: <D14049CE02C4F54D95360EEC06CE45C50FA90E57@SPMXM08.VUW.leidenuniv.nl>

If the subjects are each in one group only, the 'by=G' in the two re smooths in m2b is redundant, and therefore m2a is correct. Note that this is not entirely equivalent to your gamm model, for two reasons. One is, as you note correctly, that gamm includes correlations between intercept and A which bam doesn't. The second reason is that nlme interprets subsequent grouping factors as nested, meaning that your model actually has random effects for G and G %in% ID, not for G and ID separately. (This could be overcome with a complicated pdBlocked() argument, or by using gamm4 instead of gamm.)

Good luck,
Cesko

-----Messaggio originale-----
Da: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> Per conto di Mathew Guilfoyle
Inviato: maandag 24 juni 2019 14:34
A: r-sig-mixed-models at r-project.org
Oggetto: [R-sig-ME] Nested random effects in mgcv gam/bam

I have a dataset comprising of subjects with a unique identifier ?ID? who are each in one of two groups ?G? .  I am looking to find the smooth relationship between numerical variables A and B that are both evaluated at multiple times in each subject.  

Ignoring the grouping for the moment, a GAM formula including random intercept and ?slope? for each subject would be:

m1 = bam(B ~ s(A, bs=?cr?, k=10) + s(ID, bs=?re?) + s(ID, A, bs=?re?))

Now, I believe the smooth is different in each group therefore I want to obtain separate smooths based on G, and also include random intercepts and ?slope? for each subject but nested within each group.

Which of the following constructions is correct? (G is a factor)?:

m2a = bam(B ~ G + s(A, bs=?cr?, k=10, by=G) + s(G, ID, bs=?re?) + s(G, ID, A, bs=?re?))

m2b = bam(B ~ G + s(A, bs=?cr?, k=10, by=G) + s(ID, bs=?re?, by=G) + s(ID, A, bs=?re?, by=G))


I have tried do this more explicitly using gamm:

m3 = gamm(B ~ G + s(A, bs=?cr?, k=10, by=G), random = list(G=~1+A, ID=~1+A)) 

but this takes a lot longer (hours) to run given the size of the dataset and as I don?t need/want to specify the correlation structure of the random effects I hoped that one of the bam calls above was equivalent.  I have tried the various models on a subset of the data and model m2a gives qualitatively very similar smooths to model m3.

Thanks.
_______________________________________________
R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

From mrgu|||oy|e @end|ng |rom gm@||@com  Mon Jun 24 18:07:52 2019
From: mrgu|||oy|e @end|ng |rom gm@||@com (Mathew Guilfoyle)
Date: Mon, 24 Jun 2019 17:07:52 +0100
Subject: [R-sig-ME] Nested random effects in mgcv gam/bam
In-Reply-To: <D14049CE02C4F54D95360EEC06CE45C50FA90E57@SPMXM08.VUW.leidenuniv.nl>
References: <CBAF1820-469C-4C0C-8BE0-111EF2006501@gmail.com>
 <D14049CE02C4F54D95360EEC06CE45C50FA90E57@SPMXM08.VUW.leidenuniv.nl>
Message-ID: <524AD1EA-2A2E-463D-A7C0-3158B8710E23@gmail.com>

Cesko, thanks for the reply.

> If the subjects are each in one group only, the 'by=G' in the two re smooths in m2b is redundant, and therefore m2a is correct.

Does the addition of a by-factor argument not allow different variance in the random effects for each group? (Incidentally each subject is in one group only)

> Note that this is not entirely equivalent to your gamm model, for two reasons. One is, as you note correctly, that gamm includes correlations between intercept and A which bam doesn't. The second reason is that nlme interprets subsequent grouping factors as nested, meaning that your model actually has random effects for G and G %in% ID, not for G and ID separately. (This could be overcome with a complicated pdBlocked() argument, or by using gamm4 instead of gamm.)

So does this imply that the random effects on intercept and slope will necessarily be uncorrelated in gam/bam, i.e. equivalent to a pdDiag() argument in lme/gamm? 

Secondly, does a random effect smooth with two factors [e.g. s(G, ID, A, bs=?re?)] not create a nested structure? - the mgcv random.effects documentation page implies that the random effect applies to the interaction of the two factors?

Thanks.
> 
> Good luck,
> Cesko
> 
> -----Messaggio originale-----
> Da: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> Per conto di Mathew Guilfoyle
> Inviato: maandag 24 juni 2019 14:34
> A: r-sig-mixed-models at r-project.org
> Oggetto: [R-sig-ME] Nested random effects in mgcv gam/bam
> 
> I have a dataset comprising of subjects with a unique identifier ?ID? who are each in one of two groups ?G? .  I am looking to find the smooth relationship between numerical variables A and B that are both evaluated at multiple times in each subject.  
> 
> Ignoring the grouping for the moment, a GAM formula including random intercept and ?slope? for each subject would be:
> 
> m1 = bam(B ~ s(A, bs=?cr?, k=10) + s(ID, bs=?re?) + s(ID, A, bs=?re?))
> 
> Now, I believe the smooth is different in each group therefore I want to obtain separate smooths based on G, and also include random intercepts and ?slope? for each subject but nested within each group.
> 
> Which of the following constructions is correct? (G is a factor)?:
> 
> m2a = bam(B ~ G + s(A, bs=?cr?, k=10, by=G) + s(G, ID, bs=?re?) + s(G, ID, A, bs=?re?))
> 
> m2b = bam(B ~ G + s(A, bs=?cr?, k=10, by=G) + s(ID, bs=?re?, by=G) + s(ID, A, bs=?re?, by=G))
> 
> 
> I have tried do this more explicitly using gamm:
> 
> m3 = gamm(B ~ G + s(A, bs=?cr?, k=10, by=G), random = list(G=~1+A, ID=~1+A)) 
> 
> but this takes a lot longer (hours) to run given the size of the dataset and as I don?t need/want to specify the correlation structure of the random effects I hoped that one of the bam calls above was equivalent.  I have tried the various models on a subset of the data and model m2a gives qualitatively very similar smooths to model m3.
> 
> Thanks.
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From c@c@voeten @end|ng |rom hum@|e|denun|v@n|  Mon Jun 24 19:23:28 2019
From: c@c@voeten @end|ng |rom hum@|e|denun|v@n| (Cesko Voeten)
Date: Mon, 24 Jun 2019 19:23:28 +0200
Subject: [R-sig-ME] Nested random effects in mgcv gam/bam
In-Reply-To: <524AD1EA-2A2E-463D-A7C0-3158B8710E23@gmail.com>
References: <CBAF1820-469C-4C0C-8BE0-111EF2006501@gmail.com>
 <D14049CE02C4F54D95360EEC06CE45C50FA90E57@SPMXM08.VUW.leidenuniv.nl>
 <524AD1EA-2A2E-463D-A7C0-3158B8710E23@gmail.com>
Message-ID: <f60dfd5c-7eea-1225-a4dc-2688e501d909@hum.leidenuniv.nl>

Replies inline.

Op 24-06-2019 om 18:07 schreef Mathew Guilfoyle:
> Cesko, thanks for the reply.
> 
>> If the subjects are each in one group only, the 'by=G' in the two re smooths in m2b is redundant, and therefore m2a is correct.
> 
> Does the addition of a by-factor argument not allow different variance in the random effects for each group? (Incidentally each subject is in one group only)

I believe it should, but I'm not sure if this would actually give you a different fit, given that the groups perfectly separate the subjects? I've tried both constructions on some toy data of my own and the fits are exactly the same up to rounding error (in which case the non-by version is more parsimonious). But I guess this question would be answered for your data by a likelihood-ratio test.

> 
>> Note that this is not entirely equivalent to your gamm model, for two reasons. One is, as you note correctly, that gamm includes correlations between intercept and A which bam doesn't. The second reason is that nlme interprets subsequent grouping factors as nested, meaning that your model actually has random effects for G and G %in% ID, not for G and ID separately. (This could be overcome with a complicated pdBlocked() argument, or by using gamm4 instead of gamm.)
> 
> So does this imply that the random effects on intercept and slope will necessarily be uncorrelated in gam/bam, i.e. equivalent to a pdDiag() argument in lme/gamm?

Yes, precisely.

> 
> Secondly, does a random effect smooth with two factors [e.g. s(G, ID, A, bs=?re?)] not create a nested structure? - the mgcv random.effects documentation page implies that the random effect applies to the interaction of the two factors?

Ahh, sorry, I mistakenly thought you did not want nesting in your gamm model (I usually write the %in% explicitly if I use lme). Yes, of course, this is completely correct.

> 
> Thanks.
>>
>> Good luck,
>> Cesko
>>
>> -----Messaggio originale-----
>> Da: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> Per conto di Mathew Guilfoyle
>> Inviato: maandag 24 juni 2019 14:34
>> A: r-sig-mixed-models at r-project.org
>> Oggetto: [R-sig-ME] Nested random effects in mgcv gam/bam
>>
>> I have a dataset comprising of subjects with a unique identifier ?ID? who are each in one of two groups ?G? .  I am looking to find the smooth relationship between numerical variables A and B that are both evaluated at multiple times in each subject.
>>
>> Ignoring the grouping for the moment, a GAM formula including random intercept and ?slope? for each subject would be:
>>
>> m1 = bam(B ~ s(A, bs=?cr?, k=10) + s(ID, bs=?re?) + s(ID, A, bs=?re?))
>>
>> Now, I believe the smooth is different in each group therefore I want to obtain separate smooths based on G, and also include random intercepts and ?slope? for each subject but nested within each group.
>>
>> Which of the following constructions is correct? (G is a factor)?:
>>
>> m2a = bam(B ~ G + s(A, bs=?cr?, k=10, by=G) + s(G, ID, bs=?re?) + s(G, ID, A, bs=?re?))
>>
>> m2b = bam(B ~ G + s(A, bs=?cr?, k=10, by=G) + s(ID, bs=?re?, by=G) + s(ID, A, bs=?re?, by=G))
>>
>>
>> I have tried do this more explicitly using gamm:
>>
>> m3 = gamm(B ~ G + s(A, bs=?cr?, k=10, by=G), random = list(G=~1+A, ID=~1+A))
>>
>> but this takes a lot longer (hours) to run given the size of the dataset and as I don?t need/want to specify the correlation structure of the random effects I hoped that one of the bam calls above was equivalent.  I have tried the various models on a subset of the data and model m2a gives qualitatively very similar smooths to model m3.
>>
>> Thanks.
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From m@rt@ @end|ng |rom v|g|er@@t  Fri Jun 28 11:02:34 2019
From: m@rt@ @end|ng |rom v|g|er@@t (Marta Vigier)
Date: Fri, 28 Jun 2019 11:02:34 +0200
Subject: [R-sig-ME] Dyadic growth curve
Message-ID: <CAPgY1xPRO85GkH1UEwLVQY=KU-Tz6_GFXHrrgCbJLU65iRPRnQ@mail.gmail.com>

Dear R Experts,

I fitted a dyadic growth curve (two intercept model) with stability and
influence model (R. Garcia) and found a lagged synchrony between doctors'
and patients' Heart Rate Variability (HRV).
I have been wondering if it would be possible to adapt the syntax in order
to see when do the doctors predict patients' HRV. In other words, if
patients follow their doctors when doctors' HRV is higher or lower.
Also, the patients are nested within doctors (18 doctors and 103 patients,
one with many design), thus I created a DocID for each doctor. How could I
include this into the syntax?
I would be very grateful for any help or advice.

log_RMSSDms.2 -patients' HRV
Doc_Pat.1 -string variable with role function DOC or PAT
Clog_RMSSDms.1_lag-centered and lagged doctors' HRV
Clog_RMSSDms.2_lag cantered and lagged patients' HRV

Here is my model:
library(dyadr)
library(dplyr)
library(nlme)


ctrl <- lmeControl(msMaxIter=10000,
                   MaxIter=100000,
                   msMaxEval=10000,
                   returnObject=TRUE,
                   niterEM=10000,
                   nlmStepMax=1000)

stab_infl_2int  <- lme(log_RMSSDms.2 ~ Doc_Pat.1 +
Doc_Pat.1:Clog_RMSSDms.2_lag
                       + Doc_Pat.1:Clog_RMSSDms.1_lag - 1,
                       data = Final_data_moderators_1,
                       random = ~ Doc_Pat.1 + Doc_Pat.1:Clog_RMSSDms.2_lag
                       + Doc_Pat.1:Clog_RMSSDms.1_lag - 1|Dyad_ID,
                       correlation = corCompSymm(form = ~1|Dyad_ID/obs_ID),

                       weights = varIdent(form = ~1|Doc_Pat.1),
                       na.action = na.omit,
                       control = ctrl)
smallsummary(stab_infl_2int)

Best regards,

Marta



<https://goo.gl/maps/Zssze>

	[[alternative HTML version deleted]]


From @@m_cr@w|ey @end|ng |rom w@rpm@||@net  Mon Jun 10 22:49:11 2019
From: @@m_cr@w|ey @end|ng |rom w@rpm@||@net (Sam Crawley)
Date: Mon, 10 Jun 2019 20:49:11 -0000
Subject: [R-sig-ME] 
 =?utf-8?q?Predicted_probabilites_with_CIs_for_multile?=
 =?utf-8?q?vel_logistic_regression_with_prior_weights?=
In-Reply-To: <000001d51fb8$85d35200$9179f600$@uke.de>
References: <e4431ad0-e1aa-47f5-a9aa-32556ca1d332@www.fastmail.com>
 <000e01d51fa1$74c85760$5e590620$@uke.de>
 <000f01d51fa1$e1bd8f70$a538ae50$@uke.de>
 <609978FF-4C66-4568-BBF4-49F81201832E@gmail.com>
 <000001d51fb3$a72f2730$f58d7590$@uke.de>
 <E2865963-6C63-4B8F-A752-A4FEF61B41BA@gmail.com>
 <000001d51fb8$85d35200$9179f600$@uke.de>
Message-ID: <8ab47192-3d04-47ec-9514-aa07041320cb@www.fastmail.com>

Yes, I am looking to apply post-stratification weights (the dataset I am using is from Eurobarometer, which provides the weights).

Thanks very much all for your help so far. It looks like I have a bit of reading to do, so I will continue to work on this and let you know if I have further questions.

Cheers,
Sam Crawley.

On Tue, 11 Jun 2019, at 06:15, d.luedecke at uke.de wrote:
> > Feel free to follow up on issue 285 if you have more insight. 

> 

> At least from the technical side, I don?t have more insights, I guess. I already noticed the discussion in #285 some time ago, so I?m lurking, but not actively following ?

> 

> Terminology used in different papers or from method reports of different surveys also doesn?t seem always consistent to me. I think, ?post-stratification weights? were requested by Sam, which are weights based on group (or stratum) characteristics (like the distribution of age or gender proportions). Ben Bolker also mentioned sample weights in #285 (?in addition to these two cases, there's also the case of sampling weights, which is difficult/a mess for complex regression models but worth discussing at least ...?).

> 

> The difference between the weights-argument in typical regression model functions and the survey-package is ?The survey package not only allows for adjusting the composition of a sample to the characteristics of the general population. Most base packages would allow you to do that by specifying a weights argument. The survey package goes further by correcting the design effect introduced by the application of post-stratification weights.? (https://tophcito.blogspot.com/2014/04/social-science-goes-r-weighted-survey.html).

> 

> This of course only applies if you actually have survey-data.

> 


> *Von:* Mollie Brooks <mollieebrooks at gmail.com> 
> *Gesendet:* Montag, 10. Juni 2019 19:46
> *An:* d.luedecke at uke.de
> *Cc:* Sam Crawley <sam_crawley at warpmail.net>; Help Mixed Models <r-sig-mixed-models at r-project.org>
> *Betreff:* Re: [R-sig-ME] Predicted probabilites with CIs for multilevel logistic regression with prior weights

> 

> 

>> On 10Jun 2019, at 19:40, <d.luedecke at uke.de> <d.luedecke at uke.de> wrote:

>> 

>> I think that Sam is talking about ?sampling? or ?survey? weights (as compared to analytical or frequency weights, used by ?normal? regression models).

>> 

>> The issue you?re referring to is referenced by another issue (https://github.com/glmmTMB/glmmTMB/issues/440),

> 

> Yes, I (mebrooks) am the one who referenced it and the user (mmeierer) said it fit their needs for "sample weights".


> 

>> which in turn shows an example from Cross Validated:

>> https://stats.stackexchange.com/questions/57107/use-of-weights-in-svyglm-vs-glm

>> 

>> If I use that example, and add a third model fitted with glmmTMB, I get following result when comparing the weights from the fitted objects:

>> 

>> library(glmmTMB)

>> glm2 <- glmmTMB(re78 ~ treat, weights = w , data = lalonde)

>> cbind(glm1$weights, glm11$weights, glm2$frame$`(weights)`)

>> #> [,1] [,2] [,3]

>> #> 1 1.4682453 2.108394 2.108394

>> #> 2 0.9593877 1.377677 1.377677

>> #> 3 0.7489954 1.075554 1.075554

>> #> 4 0.7319955 1.051143 1.051143

>> #> 5 0.7283328 1.045883 1.045883

>> #> 6 0.7244569 1.040317 1.040317

>> 

>> As you can see, ?glm? and ?glmmTMB? produce the same weights, while the survey-package has different weights? I?m not sure that the weights implemented in glmmTMB are actually ?sampling? weights (for surveys, as implemented in the survey package),

> 

> Ok. I don?t know the survey package and don?t have time to look into it now. Feel free to follow up on issue 285 if you have more insight. 

> 

> cheers,

> Mollie


> 

>> or how to reproduce such weights using glmmTMB.

>> 


>> *Von:* Mollie Brooks <mollieebrooks at gmail.com> 
>> *Gesendet:* Montag, 10. Juni 2019 19:04
>> *An:* Sam Crawley <sam_crawley at warpmail.net>; Help Mixed Models <r-sig-mixed-models at r-project.org>
>> *Cc:* d.luedecke at uke.de
>> *Betreff:* Re: [R-sig-ME] Predicted probabilites with CIs for multilevel logistic regression with prior weights

>> 

>> 


>> 
>> 

>>> On 10Jun 2019, at 17:33, <d.luedecke at uke.de> <d.luedecke at uke.de> wrote:

>>> 

>>>> mixed models in R do correctly not account for sampling weights


>>> 
>>> Should be: mixed models in R do *currently* not account for sampling weights

>> 

>> I?m still trying to get a handle of the different definitions of "weights" but I believe we implemented sampling weights in glmmTMB. We do this by weighting the log-likelihood contribution of each observation. I think this is different from prior weights if you mean Bayesian priors. There has been some discussion of the different implementations of "weights" in different R functions (link below) and we still need to update the documentation for glmmTMB 

>> https://github.com/glmmTMB/glmmTMB/issues/285

>> 

>> Here?s a binomial example:

>> 

>> library(glmmTMB)

>> set.seed(123)

>> n=100

>> dat=data.frame(trials=rpois(n, lambda=50), rownum=1:n)

>> dat$success=rbinom(n, dat$trials, prob=.3)

>> dat$rep=sample(1:5, size=n, replace=TRUE) #each observation is repeated 1 to 5 times

>> rows=rep(dat$rownum, each=1, times=dat$rep)

>> dat_disaggregated=dat[rows, ]

>> 
>> 

>> summary(glmmTMB(cbind(success, trials-success)~1, weights=rep, dat, family=binomial))

>> summary(glmmTMB(cbind(success, trials-success)~1, dat_disaggregated, family=binomial))

>> 
>> 

>> and it works with non-integer weights

>> 
>> 

>> summary(glmmTMB(cbind(success, trials-success)~1, weights=rep/5, dat, family=binomial))

>> 
>> 

>> cheers,

>> Mollie

>> 
>> 


>>> 
>>> -----Urspr?ngliche Nachricht-----
>>> Von: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> Im
>>> Auftrag von d.luedecke at uke.de
>>> Gesendet: Montag, 10. Juni 2019 17:31
>>> An: 'Sam Crawley' <sam_crawley at warpmail.net>;
>>> r-sig-mixed-models at r-project.org
>>> Betreff: Re: [R-sig-ME] Predicted probabilites with CIs for multilevel
>>> logistic regression with prior weights
>>> 
>>> Hi Sam,
>>> 
>>> you could the "ggeffects" package
>>> (https://strengejacke.github.io/ggeffects/), and there is also an example
>>> for a logistic mixed effects model
>>> (https://strengejacke.github.io/ggeffects/articles/practical_logisticmixedmo
>>> del.html), which might help you.
>>> 
>>> For binomial models, using weights often results in the following warning:
>>> #> non-integer #successes in a binomial glm!
>>> 
>>> However, CIs for the predicted probabilities can be calculated nevertheless
>>> (at least in my quick example). Note that afaik, mixed models in R do
>>> correctly not account for sampling weights. However, Thomas Lumley, author
>>> of the survey-package, works on a survey-function for mixed models
>>> (https://github.com/tslumley/svylme), probably the GitHub version is quite
>>> stable (haven't tested yet).
>>> 
>>> An alternative would be the "scale_weights()" function from the
>>> sjstats-package
>>> (https://strengejacke.github.io/sjstats/articles/mixedmodels-statistics.html
>>> #rescale-model-weights-for-complex-samples ), which rescales sampling
>>> weights so they can be used as "weights" for the mixed models function you
>>> have in R (lme4, lme, ...).
>>> 
>>> Based on that function, I have a small example that demonstrates how to
>>> compute predicted probabilities for mixed models with (sampling) weights
>>> (ignore the warnings, this is just for demonstration purposes):
>>> 
>>> library(lme4)
>>> library(sjstats) # for scale_weights() and sample data
>>> library(ggeffects) # for ggpredict()
>>> 
>>> data(nhanes_sample)
>>> set.seed(123)
>>> nhanes_sample$bin <- rbinom(nrow(nhanes_sample), 1, prob = .3)
>>> nhanes_sample <- scale_weights(nhanes_sample, SDMVSTRA, WTINT2YR)
>>> 
>>> m <- glmer(
>>>  bin ~ factor(RIAGENDR) * age + factor(RIDRETH1) + (1 | SDMVPSU),
>>>  family = binomial(),
>>>  data = nhanes_sample,
>>>  weights = svywght_a
>>> )
>>> 
>>> ggpredict(m, c("age", "RIAGENDR")) %>% plot()
>>> 
>>> 
>>> Best
>>> Daniel
>>> 
>>> -----Urspr?ngliche Nachricht-----
>>> Von: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> Im
>>> Auftrag von Sam Crawley
>>> Gesendet: Montag, 10. Juni 2019 10:36
>>> An: r-sig-mixed-models at r-project.org
>>> Betreff: [R-sig-ME] Predicted probabilites with CIs for multilevel logistic
>>> regression with prior weights
>>> 
>>> Hello all,
>>> 
>>> I am doing a multilevel binomial logistic regression using lme4, and the
>>> survey data I am using requires weights to be used. I would like to
>>> calculate various predicted probabilities with confidence intervals based on
>>> the estimated model. The predict function obviously doesn't give me standard
>>> errors, and the recommended method to get these is to use the bootMer
>>> function.
>>> 
>>> However, in my case, the weights provided are not integers, and the bootMer
>>> function exits with an error if the weights are not integers (I raised a
>>> GitHub issue about this, and was pointed to this list:
>>> https://github.com/lme4/lme4/issues/524 ).
>>> 
>>> So my question is, what is the best way to calculate the predicted
>>> probabilities (with confidence intervals) in my case?
>>> 
>>> I would appreciate any help you can give me, and I'm happy to provide more
>>> details if required.
>>> 
>>> Thanks,
>>> Sam Crawley.
>>> 
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> 
>>> --
>>> 
>>> _____________________________________________________________________
>>> 
>>> Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen
>>> Rechts; Gerichtsstand: Hamburg | www.uke.de
>>> Vorstandsmitglieder: Prof. Dr. Burkhard G?ke (Vorsitzender), Prof. Dr. Dr.
>>> Uwe Koch-Gromus, Joachim Pr?l?, Marya Verdel
>>> _____________________________________________________________________
>>> 
>>> SAVE PAPER - THINK BEFORE PRINTING
>>> 
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>> 
>>> --
>>> 
>>> _____________________________________________________________________
>>> 
>>> Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen Rechts; Gerichtsstand: Hamburg | www.uke.de
>>> Vorstandsmitglieder: Prof. Dr. Burkhard G?ke (Vorsitzender), Prof. Dr. Dr. Uwe Koch-Gromus, Joachim Pr?l?, Marya Verdel
>>> _____________________________________________________________________
>>> 
>>> SAVE PAPER - THINK BEFORE PRINTING
>>> 
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

>> 

>> 

>> 
>> Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen Rechts; Gerichtsstand: Hamburg | www.uke.de
>> Vorstandsmitglieder: Prof. Dr. Burkhard G?ke (Vorsitzender), Prof. Dr. Dr. Uwe Koch-Gromus, Joachim Pr?l?, Marya Verdel

>> 
>> SAVE PAPER - THINK BEFORE PRINTING

> 

> 
> 
> Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen Rechts; Gerichtsstand: Hamburg | www.uke.de
> Vorstandsmitglieder: Prof. Dr. Burkhard G?ke (Vorsitzender), Prof. Dr. Dr. Uwe Koch-Gromus, Joachim Pr?l?, Marya Verdel

> 
> SAVE PAPER - THINK BEFORE PRINTING


	[[alternative HTML version deleted]]


