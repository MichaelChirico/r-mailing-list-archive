From m@tthi@s@suter m@iii@g oii @groscope@@dmi@@ch  Wed Jan 13 09:16:45 2021
From: m@tthi@s@suter m@iii@g oii @groscope@@dmi@@ch (m@tthi@s@suter m@iii@g oii @groscope@@dmi@@ch)
Date: Wed, 13 Jan 2021 08:16:45 +0000
Subject: [R-sig-ME] glmmTMB: Get phi from dispersion model
Message-ID: <1a4f12dfabe7400394ec05a6c4aea861@agroscope.admin.ch>

When fitting a negative binomial model in glmmTMB() using "family=nbinom2", but without specifying the dispersion model, the summary() gives an estimate for the dispersion parameter as "Overdispersion parameter for nbinom2 family (): XX", which represents - as far I understand - the phi value described in the manual (also termed theta in other environments).


If a dispersion model is specified with "dispformula=~ ...", the summary() gives the estimates for the "Dispersion model". How do these relate to the phi value? I read in the manual that "phi=exp(eta) (where eta is the linear predictor from the dispersion model)". Does this indicate that these estimates of the Dispersion model appear on the log scale, and to get phi, they must be back-transformed?


	[[alternative HTML version deleted]]


From john@m@|ndon@|d @end|ng |rom @nu@edu@@u  Wed Jan 13 09:53:27 2021
From: john@m@|ndon@|d @end|ng |rom @nu@edu@@u (John Maindonald)
Date: Wed, 13 Jan 2021 08:53:27 +0000
Subject: [R-sig-ME] glmmTMB: Get phi from dispersion model
In-Reply-To: <1a4f12dfabe7400394ec05a6c4aea861@agroscope.admin.ch>
References: <1a4f12dfabe7400394ec05a6c4aea861@agroscope.admin.ch>
Message-ID: <EEE6CE32-60A3-487F-8D27-4EC13FE0CB2A@anu.edu.au>

If you specify  "dispformula=~1?, the output is the same as when a dispformula is not
specified.  Certainly, that is the case for models with a betabinomial error.  One can
extract phi as ?phi=sigma(obj)

If you specify
a dispformula with >1 coefficients, then calculate either

  coef(HCbb.cll)[['disp?]]  ## Gives the coefficients
or
  coef(summary(HCbb.cll))[['disp?]]  ## Adds SE, etc, information

In both cases a logarithmic link function is used.

The following is a function that I have found useful:

getRho <-
function (obj)
{
    mm <- model.matrix(obj$modelInfo$allForm$dispformula, data = obj$frame)
    fixdisp <- fixef(obj)[["disp"]]
    1/(1 + exp(mm %*% fixdisp))
}

If you just want phi, rather than the intra-class correlation rho (which makes more
intuitive sense to me), just set ?phi =  exp(mm %*% fixdisp)?.  I think this works
in just the same way with nbinom2 errors, but I have not checked the details.


John Maindonald             email: john.maindonald at anu.edu.au<mailto:john.maindonald at anu.edu.au>


On 13/01/2021, at 21:16, matthias.suter--- via R-sig-mixed-models <r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>> wrote:

When fitting a negative binomial model in glmmTMB() using "family=nbinom2", but without specifying the dispersion model, the summary() gives an estimate for the dispersion parameter as "Overdispersion parameter for nbinom2 family (): XX", which represents - as far I understand - the phi value described in the manual (also termed theta in other environments).


If a dispersion model is specified with "dispformula=~ ...", the summary() gives the estimates for the "Dispersion model". How do these relate to the phi value? I read in the manual that "phi=exp(eta) (where eta is the linear predictor from the dispersion model)". Does this indicate that these estimates of the Dispersion model appear on the log scale, and to get phi, they must be back-transformed?


[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Wed Jan 13 16:56:33 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Wed, 13 Jan 2021 10:56:33 -0500
Subject: [R-sig-ME] glmmTMB: Get phi from dispersion model
In-Reply-To: <EEE6CE32-60A3-487F-8D27-4EC13FE0CB2A@anu.edu.au>
References: <1a4f12dfabe7400394ec05a6c4aea861@agroscope.admin.ch>
 <EEE6CE32-60A3-487F-8D27-4EC13FE0CB2A@anu.edu.au>
Message-ID: <de2b9505-f51a-2099-5ad9-42e97aa660e0@gmail.com>

    predict(HCbb.cl,type="disp") might also be useful, or 
predict(HCbb.cl, type="disp", newdata= ...) where the 'newdata' 
represents sets of covariates for which you would like to get the 
predicted dispersion.  (The coefficients in the output for a non-trivial 
dispersion model represent effects on the log-phi scale -- they might be 
log-dispersion parameters for different groups, e.g. if you used 
dispformula=~f-1 where f was a factor, or they might represent 
differences in log-dispersion across groups, or per unit change in a 
continuous covariate, or ...)

On 1/13/21 3:53 AM, John Maindonald wrote:
> If you specify  "dispformula=~1?, the output is the same as when a dispformula is not
> specified.  Certainly, that is the case for models with a betabinomial error.  One can
> extract phi as ?phi=sigma(obj)
> 
> If you specify
> a dispformula with >1 coefficients, then calculate either
> 
>    coef(HCbb.cll)[['disp?]]  ## Gives the coefficients
> or
>    coef(summary(HCbb.cll))[['disp?]]  ## Adds SE, etc, information
> 
> In both cases a logarithmic link function is used.
> 
> The following is a function that I have found useful:
> 
> getRho <-
> function (obj)
> {
>      mm <- model.matrix(obj$modelInfo$allForm$dispformula, data = obj$frame)
>      fixdisp <- fixef(obj)[["disp"]]
>      1/(1 + exp(mm %*% fixdisp))
> }
> 
> If you just want phi, rather than the intra-class correlation rho (which makes more
> intuitive sense to me), just set ?phi =  exp(mm %*% fixdisp)?.  I think this works
> in just the same way with nbinom2 errors, but I have not checked the details.
> 
> 
> John Maindonald             email: john.maindonald at anu.edu.au<mailto:john.maindonald at anu.edu.au>
> 
> 
> On 13/01/2021, at 21:16, matthias.suter--- via R-sig-mixed-models <r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>> wrote:
> 
> When fitting a negative binomial model in glmmTMB() using "family=nbinom2", but without specifying the dispersion model, the summary() gives an estimate for the dispersion parameter as "Overdispersion parameter for nbinom2 family (): XX", which represents - as far I understand - the phi value described in the manual (also termed theta in other environments).
> 
> 
> If a dispersion model is specified with "dispformula=~ ...", the summary() gives the estimates for the "Dispersion model". How do these relate to the phi value? I read in the manual that "phi=exp(eta) (where eta is the linear predictor from the dispersion model)". Does this indicate that these estimates of the Dispersion model appear on the log scale, and to get phi, they must be back-transformed?
> 
> 
> [[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From jk|ng@tn @end|ng |rom um@@@@edu  Wed Jan 13 18:45:07 2021
From: jk|ng@tn @end|ng |rom um@@@@edu (John Kingston)
Date: Wed, 13 Jan 2021 12:45:07 -0500
Subject: [R-sig-ME] how to specify the response (dependent) variable in a
 logistic regression model
Message-ID: <CA+4gnfRxbo14Z8kCe52f0FYgWoJm3B-0Nb5+H2veMXhGuvLSvA@mail.gmail.com>

Dear colleagues,
I hope this is the right forum for asking this question.

I have data from an experiment in which participants were asked to give one
of four responses to stimuli. The responses could be characterized as
representing the possible value of two variables, such that:

Response Variable 1 Variable 2
1               0               0
2               1               0
3               0               1
4               1               1

The possible responses are therefore neither ordinal nor multinomial in
character.

I have run three separate logistic regressions in which the responses 2, 3,
and 4 were each compared to response 1. The results are all sensible and
interpretable in terms of the expected effects of the three independent
variables. But I'm worried that doing so has required taking subsets from
responses that were collected together, and that the model interpretation
is thereby compromised.

I can provide more information about the model specification if that would
be helpful

Any advice or a referral to the right forum would be greatly appreciated.
Best,
John

John Kingston
Professor
Linguistics Department
University of Massachusetts
N434 Integrative Learning Center
650 N. Pleasant Street
Amherst, MA 01003
1-413-545-6833, fax -2792
jkingstn at umass.edu
https://blogs.umass.edu/jkingstn
<https://blogs.umass.edu/jkingstn/wp-admin/>

	[[alternative HTML version deleted]]


From th|erry@onke||nx @end|ng |rom |nbo@be  Thu Jan 14 09:16:13 2021
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Thu, 14 Jan 2021 09:16:13 +0100
Subject: [R-sig-ME] 
 how to specify the response (dependent) variable in a
 logistic regression model
In-Reply-To: <CA+4gnfRxbo14Z8kCe52f0FYgWoJm3B-0Nb5+H2veMXhGuvLSvA@mail.gmail.com>
References: <CA+4gnfRxbo14Z8kCe52f0FYgWoJm3B-0Nb5+H2veMXhGuvLSvA@mail.gmail.com>
Message-ID: <CAJuCY5wr2+AO11gdZX1fM2CnbQgLNGOPABu3Z1kjJCDmprHcAg@mail.gmail.com>

Dear John,

I can understand that the responses are not ordinal. But why not
multinomial?

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op wo 13 jan. 2021 om 19:03 schreef John Kingston <jkingstn at umass.edu>:

> Dear colleagues,
> I hope this is the right forum for asking this question.
>
> I have data from an experiment in which participants were asked to give one
> of four responses to stimuli. The responses could be characterized as
> representing the possible value of two variables, such that:
>
> Response Variable 1 Variable 2
> 1               0               0
> 2               1               0
> 3               0               1
> 4               1               1
>
> The possible responses are therefore neither ordinal nor multinomial in
> character.
>
> I have run three separate logistic regressions in which the responses 2, 3,
> and 4 were each compared to response 1. The results are all sensible and
> interpretable in terms of the expected effects of the three independent
> variables. But I'm worried that doing so has required taking subsets from
> responses that were collected together, and that the model interpretation
> is thereby compromised.
>
> I can provide more information about the model specification if that would
> be helpful
>
> Any advice or a referral to the right forum would be greatly appreciated.
> Best,
> John
>
> John Kingston
> Professor
> Linguistics Department
> University of Massachusetts
> N434 Integrative Learning Center
> 650 N. Pleasant Street
> Amherst, MA 01003
> 1-413-545-6833, fax -2792
> jkingstn at umass.edu
> https://blogs.umass.edu/jkingstn
> <https://blogs.umass.edu/jkingstn/wp-admin/>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From john@m@|ndon@|d @end|ng |rom @nu@edu@@u  Thu Jan 14 09:30:25 2021
From: john@m@|ndon@|d @end|ng |rom @nu@edu@@u (John Maindonald)
Date: Thu, 14 Jan 2021 08:30:25 +0000
Subject: [R-sig-ME] glmmTMB: phi in betabinomial dispersion model
In-Reply-To: <c700227bf3c34af0a4d49b7b3cf1cd96@agroscope.admin.ch>
References: <1a4f12dfabe7400394ec05a6c4aea861@agroscope.admin.ch>
 <EEE6CE32-60A3-487F-8D27-4EC13FE0CB2A@anu.edu.au>
 <c700227bf3c34af0a4d49b7b3cf1cd96@agroscope.admin.ch>
Message-ID: <854AE092-EC99-4FE1-A65A-2C7A0CF94B3D@anu.edu.au>

This relates to the betabinomial error family.

Note that, in the way that the model is formulated in glmmTMB,
the binomial is a limiting case of the betabinomial as phi goes to
infinity, not a special case.  This seems to me somewhat unfortunate.
Was the parameterization used chosen in preference to other possibilities
for any particular reason?  The sigma parameter in the gamlss implementation
is 1/phi, with a log link as the default, where phi is the betabinomial sigma
parameter.  I am not sure what the limiting lower value of intra-class correlation
rho is, if the link is set as ?identity?, but in theory it might do mildly negative.

Is there any particular reason for the glmmTMB parameterization?

The theory, if the sigma parameter is suitable parameterized, allows the
intra-class correlation rho to go negative.  See:
  Prentice, RL. 1986. ?Binary Regression Using an Extended Beta-Binomial Distribution,
  with Discussion of Correlation Induced by Covariate Measurement Errors.? Journal of
  the American Statistical Association 81 (394): 321?27.
Does anyone know of a readily usable implementation of that more general
error model?


John Maindonald             email: john.maindonald at anu.edu.au<mailto:john.maindonald at anu.edu.au>


If you specify  "dispformula=~1?, the output is the same as when a dispformula is not
specified.  Certainly, that is the case for models with a betabinomial error.  One can
extract phi as ?phi=sigma(obj)

If you specify
a dispformula with >1 coefficients, then calculate either

  coef(HCbb.cll)[['disp?]]  ## Gives the coefficients
or
  coef(summary(HCbb.cll))[['disp?]]  ## Adds SE, etc, information

In both cases a logarithmic link function is used.

The following is a function that I have found useful:

getRho <-
function (obj)
{
    mm <- model.matrix(obj$modelInfo$allForm$dispformula, data = obj$frame)
    fixdisp <- fixef(obj)[["disp"]]
    1/(1 + exp(mm %*% fixdisp))
}

If you just want phi, rather than the intra-class correlation rho (which makes more
intuitive sense to me), just set ?phi =  exp(mm %*% fixdisp)?.  I think this works
in just the same way with nbinom2 errors, but I have not checked the details.

John Maindonald             email: john.maindonald at anu.edu.au<mailto:john.maindonald at anu.edu.au>

On 13/01/2021, at 21:16, matthias.suter--- via R-sig-mixed-models <r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>> wrote:

When fitting a negative binomial model in glmmTMB() using "family=nbinom2", but without specifying the dispersion model, the summary() gives an estimate for the dispersion parameter as "Overdispersion parameter for nbinom2 family (): XX", which represents - as far I understand - the phi value described in the manual (also termed theta in other environments).


If a dispersion model is specified with "dispformula=~ ...", the summary() gives the estimates for the "Dispersion model". How do these relate to the phi value? I read in the manual that "phi=exp(eta) (where eta is the linear predictor from the dispersion model)". Does this indicate that these estimates of the Dispersion model appear on the log scale, and to get phi, they must be back-transformed?


[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



	[[alternative HTML version deleted]]


From jk|ng@tn @end|ng |rom um@@@@edu  Thu Jan 14 16:40:47 2021
From: jk|ng@tn @end|ng |rom um@@@@edu (John Kingston)
Date: Thu, 14 Jan 2021 10:40:47 -0500
Subject: [R-sig-ME] how to specify the response (dependent) variable in a
 logistic regression model
Message-ID: <CA+4gnfQQd7x6BqVnMtgkXTYuMqgBqA5g=C6RbCWm9_hcTCReqA@mail.gmail.com>

Dear Thierry,
Thanks for your question. Here's the reason why I think the responses
aren't multinomial (or ordinal).

The listeners were presented with spoken strings of the form CVC, where C =
consonant and V = vowel. The rate at which the acoustics changed at the
beginning of the syllable was varied orthogonally with the duration of the
vowel. The rate of acoustic change conveyed the identity of the initial
consonant, which was expected to sound like "b" when the rate of change was
faster and like "w" when it was slower. The duration of the vowel conveyed
how many syllables the string consisted of, which was expected to be "1"
when the vowel was shorter and "2" when the vowel was longer. The listeners
were instructed to respond with "b" or "w" and "1" or "2" on every trial.
So, unlike a truly multinomial dependent variable, such as professions or
majors, the responses here are not unordered. They also cannot be arranged
into a single order sensibly, because even if "b1" and "w2" responses are
first and last in the order, there's no way of deciding *a priori* the
order of "b2" and "w1" responses.

Again, thanks for your reply.
Best,
John
John Kingston
Professor
Linguistics Department
University of Massachusetts
N434 Integrative Learning Center
650 N. Pleasant Street
Amherst, MA 01003
1-413-545-6833, fax -2792
jkingstn at umass.edu
https://blogs.umass.edu/jkingstn
<https://blogs.umass.edu/jkingstn/wp-admin/>

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Thu Jan 14 16:44:25 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Thu, 14 Jan 2021 10:44:25 -0500
Subject: [R-sig-ME] glmmTMB: phi in betabinomial dispersion model
In-Reply-To: <854AE092-EC99-4FE1-A65A-2C7A0CF94B3D@anu.edu.au>
References: <1a4f12dfabe7400394ec05a6c4aea861@agroscope.admin.ch>
 <EEE6CE32-60A3-487F-8D27-4EC13FE0CB2A@anu.edu.au>
 <c700227bf3c34af0a4d49b7b3cf1cd96@agroscope.admin.ch>
 <854AE092-EC99-4FE1-A65A-2C7A0CF94B3D@anu.edu.au>
Message-ID: <db6f2aed-c11e-47c0-e0c0-1f879461b84b@gmail.com>

   Honestly, the BB parameterization in glmmTMB was chosen because we 
(I) weren't aware of the other options. The one we use is the most 
"natural" way I can think of to construct the BB (compounding a binomial 
with its conjugate prior distribution, analogous to a 
Dirichlet-multinomial or negative binomial).

   Looking at the Prentice paper it seems useful; the two bits that 
would be hard would be (1) rather than a simple closed-form expression 
it is expressed as the combination of sums: for params p (prob) (q=1-p, 
I think) and gamma (dispersion), the log-likelihood of y out of n 
successes is

sum(i=0,y-1) log(p+gamma*i) + sum(i=0,n-y-1) log(q+gamma*i) - 
sum(i=0,n-1) log(1+gamma*i)

  This is not as bad as log-likelihoods that have to be computed via 
infinite sums, but it will presumably be a lot slower than a likelihood 
that involves only log-factorial and log-beta functions, sums and products	

  The other thing that looks potentially tricky is that the lower bound 
of the dispersion parameter is data-dependent:

  y >= max{ -p(n - 1)1, -q(n - 1)-1}

   Since p, q, n will vary across a given data set (and p and q will 
depend on the parameters of the model for the conditional mean), it's 
not immediately obvious to me how we would implement this (glmmTMB 
typically works by fitting parameters on an unconstrained space) ... 
(there are some cruder approaches that would involve penalization ...)

   Feel free to open an issue in the glmmTMB github repository ...


On 1/14/21 3:30 AM, John Maindonald wrote:
> This relates to the betabinomial error family.
> 
> Note that, in the way that the model is formulated in glmmTMB,
> the binomial is a limiting case of the betabinomial as phi goes to
> infinity, not a special case.  This seems to me somewhat unfortunate.
> Was the parameterization used chosen in preference to other possibilities
> for any particular reason?  The sigma parameter in the gamlss implementation
> is 1/phi, with a log link as the default, where phi is the betabinomial sigma
> parameter.  I am not sure what the limiting lower value of intra-class correlation
> rho is, if the link is set as ?identity?, but in theory it might do mildly negative.
> 
> Is there any particular reason for the glmmTMB parameterization?
> 
> The theory, if the sigma parameter is suitable parameterized, allows the
> intra-class correlation rho to go negative.  See:
>    Prentice, RL. 1986. ?Binary Regression Using an Extended Beta-Binomial Distribution,
>    with Discussion of Correlation Induced by Covariate Measurement Errors.? Journal of
>    the American Statistical Association 81 (394): 321?27.
> Does anyone know of a readily usable implementation of that more general
> error model?
> 
> 
> John Maindonald             email: john.maindonald at anu.edu.au<mailto:john.maindonald at anu.edu.au>
> 
> 
> If you specify  "dispformula=~1?, the output is the same as when a dispformula is not
> specified.  Certainly, that is the case for models with a betabinomial error.  One can
> extract phi as ?phi=sigma(obj)
> 
> If you specify
> a dispformula with >1 coefficients, then calculate either
> 
>    coef(HCbb.cll)[['disp?]]  ## Gives the coefficients
> or
>    coef(summary(HCbb.cll))[['disp?]]  ## Adds SE, etc, information
> 
> In both cases a logarithmic link function is used.
> 
> The following is a function that I have found useful:
> 
> getRho <-
> function (obj)
> {
>      mm <- model.matrix(obj$modelInfo$allForm$dispformula, data = obj$frame)
>      fixdisp <- fixef(obj)[["disp"]]
>      1/(1 + exp(mm %*% fixdisp))
> }
> 
> If you just want phi, rather than the intra-class correlation rho (which makes more
> intuitive sense to me), just set ?phi =  exp(mm %*% fixdisp)?.  I think this works
> in just the same way with nbinom2 errors, but I have not checked the details.
> 
> John Maindonald             email: john.maindonald at anu.edu.au<mailto:john.maindonald at anu.edu.au>
> 
> On 13/01/2021, at 21:16, matthias.suter--- via R-sig-mixed-models <r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>> wrote:
> 
> When fitting a negative binomial model in glmmTMB() using "family=nbinom2", but without specifying the dispersion model, the summary() gives an estimate for the dispersion parameter as "Overdispersion parameter for nbinom2 family (): XX", which represents - as far I understand - the phi value described in the manual (also termed theta in other environments).
> 
> 
> If a dispersion model is specified with "dispformula=~ ...", the summary() gives the estimates for the "Dispersion model". How do these relate to the phi value? I read in the manual that "phi=exp(eta) (where eta is the linear predictor from the dispersion model)". Does this indicate that these estimates of the Dispersion model appear on the log scale, and to get phi, they must be back-transformed?
> 
> 
> [[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From 538280 @end|ng |rom gm@||@com  Thu Jan 14 17:05:27 2021
From: 538280 @end|ng |rom gm@||@com (Greg Snow)
Date: Thu, 14 Jan 2021 09:05:27 -0700
Subject: [R-sig-ME] 
 how to specify the response (dependent) variable in a
 logistic regression model
In-Reply-To: <CA+4gnfQQd7x6BqVnMtgkXTYuMqgBqA5g=C6RbCWm9_hcTCReqA@mail.gmail.com>
References: <CA+4gnfQQd7x6BqVnMtgkXTYuMqgBqA5g=C6RbCWm9_hcTCReqA@mail.gmail.com>
Message-ID: <CAFEqCdx6r472qjhcoi_K4hjFjQk-S+uCK7YyNhs8bDKYz-ea7A@mail.gmail.com>

John,

I agree that ordering your responses does not make sense, but the
multinomial models are for unordered categorical data.  So you can
just treat your 4 possible outcomes as unordered categories.

Another option is to convert to a Poisson regression where the
response variable is the count (number of times each of the 4
combinations is selected) and then your categories become
explanitory/predictor variables.  You can either use a single
predictor with the 4 levels (and choose appropriate indicator
variables) or you can have 2 predictors (b vs w and 1 vs 2) as well as
their interaction.  That would give a different interpretation of the
model, but may be more what you are trying to accomplish.

On Thu, Jan 14, 2021 at 8:44 AM John Kingston <jkingstn at umass.edu> wrote:
>
> Dear Thierry,
> Thanks for your question. Here's the reason why I think the responses
> aren't multinomial (or ordinal).
>
> The listeners were presented with spoken strings of the form CVC, where C =
> consonant and V = vowel. The rate at which the acoustics changed at the
> beginning of the syllable was varied orthogonally with the duration of the
> vowel. The rate of acoustic change conveyed the identity of the initial
> consonant, which was expected to sound like "b" when the rate of change was
> faster and like "w" when it was slower. The duration of the vowel conveyed
> how many syllables the string consisted of, which was expected to be "1"
> when the vowel was shorter and "2" when the vowel was longer. The listeners
> were instructed to respond with "b" or "w" and "1" or "2" on every trial.
> So, unlike a truly multinomial dependent variable, such as professions or
> majors, the responses here are not unordered. They also cannot be arranged
> into a single order sensibly, because even if "b1" and "w2" responses are
> first and last in the order, there's no way of deciding *a priori* the
> order of "b2" and "w1" responses.
>
> Again, thanks for your reply.
> Best,
> John
> John Kingston
> Professor
> Linguistics Department
> University of Massachusetts
> N434 Integrative Learning Center
> 650 N. Pleasant Street
> Amherst, MA 01003
> 1-413-545-6833, fax -2792
> jkingstn at umass.edu
> https://blogs.umass.edu/jkingstn
> <https://blogs.umass.edu/jkingstn/wp-admin/>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From me @end|ng |rom ph||||p@|d@y@com  Thu Jan 14 17:40:57 2021
From: me @end|ng |rom ph||||p@|d@y@com (Phillip Alday)
Date: Thu, 14 Jan 2021 17:40:57 +0100
Subject: [R-sig-ME] 
 how to specify the response (dependent) variable in a
 logistic regression model
In-Reply-To: <CAFEqCdx6r472qjhcoi_K4hjFjQk-S+uCK7YyNhs8bDKYz-ea7A@mail.gmail.com>
References: <CA+4gnfQQd7x6BqVnMtgkXTYuMqgBqA5g=C6RbCWm9_hcTCReqA@mail.gmail.com>
 <CAFEqCdx6r472qjhcoi_K4hjFjQk-S+uCK7YyNhs8bDKYz-ea7A@mail.gmail.com>
Message-ID: <63ddf228-342c-8201-f31d-08cf4638b66f@phillipalday.com>

John,

How comfortable are you with mixed models software beyond lme4? This
seems like a perfect case for a multivariate mixed model (which you can
do with e.g. brms or MCMCglmm). The basic idea is that you do create a
single mixed model that can be thought of doing two GLMMs
simultaneously. Here's the basic syntax for doing this in brms:


brm(mvbind(Resp1, Resp2) ~ preds + ..., data=your_data, family=binomial)

You can also specify this as two formulae (which really highlights the
"two models simultaneously" intuition):


var1 = bf(Resp1 ~ preds + ....) + binomial()
var2 = bf(Resp2 ~ preds + ....) + binomial()

brm(var1 + var2, data=your_data)

The advantage to doing this as a multivariate model as opposed to
separate models is that you get simultaneous estimates across both
models, including correlation/covariance between those estimates.  See
e.g. the brms documentation
(https://paul-buerkner.github.io/brms/articles/brms_multivariate.html)
for more info. In particular, pay attention to the extra syntax for
computing shared correlation in the random effects across sub-models.

The cons for this approach are that [1] most reviewers in
(psycho)linguistics will not be familiar with it (and there was recent a
Twitter storm on this very problem) and [2] the computational costs are
noticeably higher.

Another alternative is to do something like "linked mixed models" (cf.
Hohenstein, Matuschek and Kliegl, PBR 2016). There are a few variants on
this, but the basic idea is that you use one response to predict the
other. Given the temporal ordering here, this might make sense, e.g.

mod1 = glmer(Resp1 ~ preds + ....)
mod2 = glmer(Resp2 ~ preds + YYY + ....)

where YYY is one of:
[a] Resp1
[b] fitted(mod1)
[c] fitted(mod1) + resid(mod1)

You can potentially omit mod1, in which case you have something like the
Davidson and Martin (Acta Psychologia, 2016) approach to the joint
analysis of reaction times and response accuracy.

The downside to this approach is that the variability that's in Resp1
can create problems in mod2, because standard GLMMs assume that the
predictors are measured without error/variability. Variants [b] and
especially [c] mitigate this a bit though. (And if you want to get even
more complicated, there are  "errors-within-variables" models, which can
handle this and are available in e.g. brms). I think the advantage to
the linked model approach relative to the multivariate approach is that
it's somewhat more accessible for a typical (psycho)linguistic reviewer.

Note that I am nominally originally from linguistics and do know a bit
about mixed models, so I'm a good usual suspect for a reviewer on these
things.

Best,
Phillip

PS: the multinomial models suggested by the others are also pretty good,
but again multinomial models are usually something that require getting
used to and doesn't reflect the potential covariance of Resp1 and Resp2
in an obvious way.



On 14/1/21 5:05 pm, Greg Snow wrote:
> John,
> 
> I agree that ordering your responses does not make sense, but the
> multinomial models are for unordered categorical data.  So you can
> just treat your 4 possible outcomes as unordered categories.
> 
> Another option is to convert to a Poisson regression where the
> response variable is the count (number of times each of the 4
> combinations is selected) and then your categories become
> explanitory/predictor variables.  You can either use a single
> predictor with the 4 levels (and choose appropriate indicator
> variables) or you can have 2 predictors (b vs w and 1 vs 2) as well as
> their interaction.  That would give a different interpretation of the
> model, but may be more what you are trying to accomplish.
> 
> On Thu, Jan 14, 2021 at 8:44 AM John Kingston <jkingstn at umass.edu> wrote:
>>
>> Dear Thierry,
>> Thanks for your question. Here's the reason why I think the responses
>> aren't multinomial (or ordinal).
>>
>> The listeners were presented with spoken strings of the form CVC, where C =
>> consonant and V = vowel. The rate at which the acoustics changed at the
>> beginning of the syllable was varied orthogonally with the duration of the
>> vowel. The rate of acoustic change conveyed the identity of the initial
>> consonant, which was expected to sound like "b" when the rate of change was
>> faster and like "w" when it was slower. The duration of the vowel conveyed
>> how many syllables the string consisted of, which was expected to be "1"
>> when the vowel was shorter and "2" when the vowel was longer. The listeners
>> were instructed to respond with "b" or "w" and "1" or "2" on every trial.
>> So, unlike a truly multinomial dependent variable, such as professions or
>> majors, the responses here are not unordered. They also cannot be arranged
>> into a single order sensibly, because even if "b1" and "w2" responses are
>> first and last in the order, there's no way of deciding *a priori* the
>> order of "b2" and "w1" responses.
>>
>> Again, thanks for your reply.
>> Best,
>> John
>> John Kingston
>> Professor
>> Linguistics Department
>> University of Massachusetts
>> N434 Integrative Learning Center
>> 650 N. Pleasant Street
>> Amherst, MA 01003
>> 1-413-545-6833, fax -2792
>> jkingstn at umass.edu
>> https://blogs.umass.edu/jkingstn
>> <https://blogs.umass.edu/jkingstn/wp-admin/>
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
>


From jb@echer @end|ng |rom u||@edu  Thu Jan 14 18:00:42 2021
From: jb@echer @end|ng |rom u||@edu (Baecher,Joseph Alex)
Date: Thu, 14 Jan 2021 17:00:42 +0000
Subject: [R-sig-ME] weights in mixed modelling
Message-ID: <BN6PR2201MB1106291A45BBB5BD001394E0CFA80@BN6PR2201MB1106.namprd22.prod.outlook.com>

Hi everyone,

I?m looking for advice and/or information about using weights in mixed modelling. My colleagues and I are conducting an analysis and we?ve attempted to use weights to solve two issues. As is likely obvious, I am not a statistician, so please excuse my ignorance! We?re using data gathered from several hundred studies. The studies represent a spectrum of quality and robustness and therefore we have created an standardized ?index of study quality? to rank each of the data sources. It was our (perhaps dubious) understanding that we could use such an index as model weights in our analysis. There are also instances in which studies? presented data in aggregate, and therefore we had to break data into multiple observations. We had hoped weights could mitigate any issues arising from pseudoreplication. For this, we created an ?observation weight?, in which each independent observation was assigned a weight of 1 and observations which were broken into multiple observations were given a weight = 1/(# of observations). We thought combining the ?index of study qualities? with the ?observation weight? via multiplication could give us a composite weight? The model we are using is a Beta-distributed mixed effects model, fitted using  ?glmmTMB?.

If you have any advice or suggestions or relevant reading materials, I would greatly appreciate it.

Thank you in advance for your time and patience,

All the Best,

-Alex B.
~~~~~~~~~~~~~~~~~~~~~~~~~~~
J. Alex Baecher (he, him, his)
PhD student, Research Assistant
School of Natural Resources and Environment
University of Florida
354 Newins-Ziegler Hall
Gainesville, Florida 34611 (USA)
--
phone: ?(352) 575-0454
e-mail: jbaecher at ufl.edu<mailto:jbaecher at ufl.edu>
website: www.alexbaecher.com<http://www.alexbaecher.com/>
~~~~~~~~~~~~~~~~~~~~~~~~~~~




	[[alternative HTML version deleted]]


From me @end|ng |rom ph||||p@|d@y@com  Thu Jan 14 18:11:31 2021
From: me @end|ng |rom ph||||p@|d@y@com (Phillip Alday)
Date: Thu, 14 Jan 2021 18:11:31 +0100
Subject: [R-sig-ME] weights in mixed modelling
In-Reply-To: <BN6PR2201MB1106291A45BBB5BD001394E0CFA80@BN6PR2201MB1106.namprd22.prod.outlook.com>
References: <BN6PR2201MB1106291A45BBB5BD001394E0CFA80@BN6PR2201MB1106.namprd22.prod.outlook.com>
Message-ID: <7c71ebca-3ac3-63ab-83e9-1c74427655ce@phillipalday.com>

Hi Alex,

to give you a generic answer that is hopefully nonetheless useful,
checkout this discussion of the different meanings of "weights" in
statistics:
https://blogs.sas.com/content/iml/2017/10/02/weight-variables-in-statistics-sas.html

I think that will be useful for further googling and/or understanding
what the `weights` argument does in various modelling functions.

Best,
Phillip

On 14/1/21 6:00 pm, Baecher,Joseph Alex wrote:
> Hi everyone,
> 
> I?m looking for advice and/or information about using weights in mixed modelling. My colleagues and I are conducting an analysis and we?ve attempted to use weights to solve two issues. As is likely obvious, I am not a statistician, so please excuse my ignorance! We?re using data gathered from several hundred studies. The studies represent a spectrum of quality and robustness and therefore we have created an standardized ?index of study quality? to rank each of the data sources. It was our (perhaps dubious) understanding that we could use such an index as model weights in our analysis. There are also instances in which studies? presented data in aggregate, and therefore we had to break data into multiple observations. We had hoped weights could mitigate any issues arising from pseudoreplication. For this, we created an ?observation weight?, in which each independent observation was assigned a weight of 1 and observations which were broken into multiple observations were given a weight = 1/(# of observations). We thought combining the ?index of study qualities? with the ?observation weight? via multiplication could give us a composite weight? The model we are using is a Beta-distributed mixed effects model, fitted using  ?glmmTMB?.
> 
> If you have any advice or suggestions or relevant reading materials, I would greatly appreciate it.
> 
> Thank you in advance for your time and patience,
> 
> All the Best,
> 
> -Alex B.
> ~~~~~~~~~~~~~~~~~~~~~~~~~~~
> J. Alex Baecher (he, him, his)
> PhD student, Research Assistant
> School of Natural Resources and Environment
> University of Florida
> 354 Newins-Ziegler Hall
> Gainesville, Florida 34611 (USA)
> --
> phone: ?(352) 575-0454
> e-mail: jbaecher at ufl.edu<mailto:jbaecher at ufl.edu>
> website: www.alexbaecher.com<http://www.alexbaecher.com/>
> ~~~~~~~~~~~~~~~~~~~~~~~~~~~
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

From mo|||eebrook@ @end|ng |rom gm@||@com  Thu Jan 14 18:19:48 2021
From: mo|||eebrook@ @end|ng |rom gm@||@com (Mollie Brooks)
Date: Thu, 14 Jan 2021 18:19:48 +0100
Subject: [R-sig-ME] weights in mixed modelling
In-Reply-To: <BN6PR2201MB1106291A45BBB5BD001394E0CFA80@BN6PR2201MB1106.namprd22.prod.outlook.com>
References: <BN6PR2201MB1106291A45BBB5BD001394E0CFA80@BN6PR2201MB1106.namprd22.prod.outlook.com>
Message-ID: <B0D404C1-8AAF-4C46-B78E-D0DAF7DB375E@gmail.com>

Hi Alex,

I was previously thinking about ways to do a meta-analysis on beta distributed data. The discussion here might be relevant to your problem https://github.com/glmmTMB/glmmTMB/issues/156#issuecomment-276046838 <https://github.com/glmmTMB/glmmTMB/issues/156#issuecomment-276046838>

You might want to use the dispersion formula instead of weights and transform the uncertainties to be on the right scale of the dispersion model.  In glmmTMB and betareg's formulation of beta regression, var = mu*(1-mu)/(1+phi). Solving that equation for phi gives phi = mu*(1-mu)/var -1.

So if you have a collection of estimated proportions (mu_hat) and variances (var_hat), where mu_hats are beta distributed, then it might make sense to use dispformula =~ mu_hat*(1-mu_hat)/var_hat -1 or dispformula =~ mu_hat*(1-mu_hat)/var_hat in a meta-analysis. As Ben says in comments further down the Github issue, you would want to simulation test this idea to make sure it works. 

I?m not sure about breaking up observations that you mention.

Cheers,
Mollie


> On 14Jan 2021, at 18:00, Baecher,Joseph Alex <jbaecher at ufl.edu> wrote:
> 
> Hi everyone,
> 
> I?m looking for advice and/or information about using weights in mixed modelling. My colleagues and I are conducting an analysis and we?ve attempted to use weights to solve two issues. As is likely obvious, I am not a statistician, so please excuse my ignorance! We?re using data gathered from several hundred studies. The studies represent a spectrum of quality and robustness and therefore we have created an standardized ?index of study quality? to rank each of the data sources. It was our (perhaps dubious) understanding that we could use such an index as model weights in our analysis. There are also instances in which studies? presented data in aggregate, and therefore we had to break data into multiple observations. We had hoped weights could mitigate any issues arising from pseudoreplication. For this, we created an ?observation weight?, in which each independent observation was assigned a weight of 1 and observations which were broken into multiple observations were given a weight = 1/(# of observations). We thought combining the ?index of study qualities? with the ?observation weight? via multiplication could give us a composite weight? The model we are using is a Beta-distributed mixed effects model, fitted using  ?glmmTMB?.
> 
> If you have any advice or suggestions or relevant reading materials, I would greatly appreciate it.
> 
> Thank you in advance for your time and patience,
> 
> All the Best,
> 
> -Alex B.
> ~~~~~~~~~~~~~~~~~~~~~~~~~~~
> J. Alex Baecher (he, him, his)
> PhD student, Research Assistant
> School of Natural Resources and Environment
> University of Florida
> 354 Newins-Ziegler Hall
> Gainesville, Florida 34611 (USA)
> --
> phone: ?(352) 575-0454
> e-mail: jbaecher at ufl.edu<mailto:jbaecher at ufl.edu>
> website: www.alexbaecher.com<http://www.alexbaecher.com/>
> ~~~~~~~~~~~~~~~~~~~~~~~~~~~
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


	[[alternative HTML version deleted]]


From jepu@to @end|ng |rom gm@||@com  Thu Jan 14 19:22:07 2021
From: jepu@to @end|ng |rom gm@||@com (James Pustejovsky)
Date: Thu, 14 Jan 2021 12:22:07 -0600
Subject: [R-sig-ME] weights in mixed modelling
In-Reply-To: <BN6PR2201MB1106291A45BBB5BD001394E0CFA80@BN6PR2201MB1106.namprd22.prod.outlook.com>
References: <BN6PR2201MB1106291A45BBB5BD001394E0CFA80@BN6PR2201MB1106.namprd22.prod.outlook.com>
Message-ID: <CAFUVuJwWpHH9NV9DFqGwkvthisvZ2TMw2S+-x-bToBpAGkq3Aw@mail.gmail.com>

Hi Alex,

The analysis that you're working on sounds like what would be called an
"individual participant data meta-analysis." You might find the literature
on that topic helpful in thinking about analytic approaches.

In the meta-analysis literature, there's been quite a bit of discussion
about the idea of using weighting as a means to address issues of variable
study quality. My sense of it is that the consensus in the meta-analysis
context is that weighting by study quality is not recommended. Two papers
to give you a flavor of the discussion:
https://doi.org/10.3102/1076998610393968
https://doi.org/10.1093/biostatistics/2.4.463

An alternative to using study-quality weights would be to use the study
quality index (or perhaps the sub-components of the index) as predictors in
your analysis. This would allow you to, for example, make predictions about
whatever the target quantity of interest would be in a (hypothetical) study
that had a perfect quality index.

Kind Regards,
James

On Thu, Jan 14, 2021 at 11:03 AM Baecher,Joseph Alex <jbaecher at ufl.edu>
wrote:

> Hi everyone,
>
> I?m looking for advice and/or information about using weights in mixed
> modelling. My colleagues and I are conducting an analysis and we?ve
> attempted to use weights to solve two issues. As is likely obvious, I am
> not a statistician, so please excuse my ignorance! We?re using data
> gathered from several hundred studies. The studies represent a spectrum of
> quality and robustness and therefore we have created an standardized ?index
> of study quality? to rank each of the data sources. It was our (perhaps
> dubious) understanding that we could use such an index as model weights in
> our analysis. There are also instances in which studies? presented data in
> aggregate, and therefore we had to break data into multiple observations.
> We had hoped weights could mitigate any issues arising from
> pseudoreplication. For this, we created an ?observation weight?, in which
> each independent observation was assigned a weight of 1 and observations
> which were broken into multiple observations were given a weight = 1/(# of
> observations). We thought combining the ?index of study qualities? with the
> ?observation weight? via multiplication could give us a composite weight?
> The model we are using is a Beta-distributed mixed effects model, fitted
> using  ?glmmTMB?.
>
> If you have any advice or suggestions or relevant reading materials, I
> would greatly appreciate it.
>
> Thank you in advance for your time and patience,
>
> All the Best,
>
> -Alex B.
> ~~~~~~~~~~~~~~~~~~~~~~~~~~~
> J. Alex Baecher (he, him, his)
> PhD student, Research Assistant
> School of Natural Resources and Environment
> University of Florida
> 354 Newins-Ziegler Hall
> Gainesville, Florida 34611 (USA)
> --
> phone: ?(352) 575-0454
> e-mail: jbaecher at ufl.edu<mailto:jbaecher at ufl.edu>
> website: www.alexbaecher.com<http://www.alexbaecher.com/>
> ~~~~~~~~~~~~~~~~~~~~~~~~~~~
>
>
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From jk|ng@tn @end|ng |rom um@@@@edu  Fri Jan 15 00:27:14 2021
From: jk|ng@tn @end|ng |rom um@@@@edu (John Kingston)
Date: Thu, 14 Jan 2021 18:27:14 -0500
Subject: [R-sig-ME] 
 how to specify the response (dependent) variable in a
 logistic regression model
In-Reply-To: <63ddf228-342c-8201-f31d-08cf4638b66f@phillipalday.com>
References: <CA+4gnfQQd7x6BqVnMtgkXTYuMqgBqA5g=C6RbCWm9_hcTCReqA@mail.gmail.com>
 <CAFEqCdx6r472qjhcoi_K4hjFjQk-S+uCK7YyNhs8bDKYz-ea7A@mail.gmail.com>
 <63ddf228-342c-8201-f31d-08cf4638b66f@phillipalday.com>
Message-ID: <CA+4gnfT7S5gwuZBdLpJeA9coDpA8Jr-i4oX_hTfUWL7nZiCd5A@mail.gmail.com>

Dear Phillip and Greg,
Thank you both very much.

I don't have experience yet beyond lme4, but you've both given me useful
directions to pursue.

I'll come back with results once they're in hand.
Best,
John

John Kingston
Professor
Linguistics Department
University of Massachusetts
N434 Integrative Learning Center
650 N. Pleasant Street
Amherst, MA 01003
1-413-545-6833, fax -2792
jkingstn at umass.edu
https://blogs.umass.edu/jkingstn
<https://blogs.umass.edu/jkingstn/wp-admin/>


On Thu, Jan 14, 2021 at 11:41 AM Phillip Alday <me at phillipalday.com> wrote:

> John,
>
> How comfortable are you with mixed models software beyond lme4? This
> seems like a perfect case for a multivariate mixed model (which you can
> do with e.g. brms or MCMCglmm). The basic idea is that you do create a
> single mixed model that can be thought of doing two GLMMs
> simultaneously. Here's the basic syntax for doing this in brms:
>
>
> brm(mvbind(Resp1, Resp2) ~ preds + ..., data=your_data, family=binomial)
>
> You can also specify this as two formulae (which really highlights the
> "two models simultaneously" intuition):
>
>
> var1 = bf(Resp1 ~ preds + ....) + binomial()
> var2 = bf(Resp2 ~ preds + ....) + binomial()
>
> brm(var1 + var2, data=your_data)
>
> The advantage to doing this as a multivariate model as opposed to
> separate models is that you get simultaneous estimates across both
> models, including correlation/covariance between those estimates.  See
> e.g. the brms documentation
> (https://paul-buerkner.github.io/brms/articles/brms_multivariate.html)
> for more info. In particular, pay attention to the extra syntax for
> computing shared correlation in the random effects across sub-models.
>
> The cons for this approach are that [1] most reviewers in
> (psycho)linguistics will not be familiar with it (and there was recent a
> Twitter storm on this very problem) and [2] the computational costs are
> noticeably higher.
>
> Another alternative is to do something like "linked mixed models" (cf.
> Hohenstein, Matuschek and Kliegl, PBR 2016). There are a few variants on
> this, but the basic idea is that you use one response to predict the
> other. Given the temporal ordering here, this might make sense, e.g.
>
> mod1 = glmer(Resp1 ~ preds + ....)
> mod2 = glmer(Resp2 ~ preds + YYY + ....)
>
> where YYY is one of:
> [a] Resp1
> [b] fitted(mod1)
> [c] fitted(mod1) + resid(mod1)
>
> You can potentially omit mod1, in which case you have something like the
> Davidson and Martin (Acta Psychologia, 2016) approach to the joint
> analysis of reaction times and response accuracy.
>
> The downside to this approach is that the variability that's in Resp1
> can create problems in mod2, because standard GLMMs assume that the
> predictors are measured without error/variability. Variants [b] and
> especially [c] mitigate this a bit though. (And if you want to get even
> more complicated, there are  "errors-within-variables" models, which can
> handle this and are available in e.g. brms). I think the advantage to
> the linked model approach relative to the multivariate approach is that
> it's somewhat more accessible for a typical (psycho)linguistic reviewer.
>
> Note that I am nominally originally from linguistics and do know a bit
> about mixed models, so I'm a good usual suspect for a reviewer on these
> things.
>
> Best,
> Phillip
>
> PS: the multinomial models suggested by the others are also pretty good,
> but again multinomial models are usually something that require getting
> used to and doesn't reflect the potential covariance of Resp1 and Resp2
> in an obvious way.
>
>
>
> On 14/1/21 5:05 pm, Greg Snow wrote:
> > John,
> >
> > I agree that ordering your responses does not make sense, but the
> > multinomial models are for unordered categorical data.  So you can
> > just treat your 4 possible outcomes as unordered categories.
> >
> > Another option is to convert to a Poisson regression where the
> > response variable is the count (number of times each of the 4
> > combinations is selected) and then your categories become
> > explanitory/predictor variables.  You can either use a single
> > predictor with the 4 levels (and choose appropriate indicator
> > variables) or you can have 2 predictors (b vs w and 1 vs 2) as well as
> > their interaction.  That would give a different interpretation of the
> > model, but may be more what you are trying to accomplish.
> >
> > On Thu, Jan 14, 2021 at 8:44 AM John Kingston <jkingstn at umass.edu>
> wrote:
> >>
> >> Dear Thierry,
> >> Thanks for your question. Here's the reason why I think the responses
> >> aren't multinomial (or ordinal).
> >>
> >> The listeners were presented with spoken strings of the form CVC, where
> C =
> >> consonant and V = vowel. The rate at which the acoustics changed at the
> >> beginning of the syllable was varied orthogonally with the duration of
> the
> >> vowel. The rate of acoustic change conveyed the identity of the initial
> >> consonant, which was expected to sound like "b" when the rate of change
> was
> >> faster and like "w" when it was slower. The duration of the vowel
> conveyed
> >> how many syllables the string consisted of, which was expected to be "1"
> >> when the vowel was shorter and "2" when the vowel was longer. The
> listeners
> >> were instructed to respond with "b" or "w" and "1" or "2" on every
> trial.
> >> So, unlike a truly multinomial dependent variable, such as professions
> or
> >> majors, the responses here are not unordered. They also cannot be
> arranged
> >> into a single order sensibly, because even if "b1" and "w2" responses
> are
> >> first and last in the order, there's no way of deciding *a priori* the
> >> order of "b2" and "w1" responses.
> >>
> >> Again, thanks for your reply.
> >> Best,
> >> John
> >> John Kingston
> >> Professor
> >> Linguistics Department
> >> University of Massachusetts
> >> N434 Integrative Learning Center
> >> 650 N. Pleasant Street
> >> Amherst, MA 01003
> >> 1-413-545-6833, fax -2792
> >> jkingstn at umass.edu
> >> https://blogs.umass.edu/jkingstn
> >> <https://blogs.umass.edu/jkingstn/wp-admin/>
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> >
> >
>

	[[alternative HTML version deleted]]


From juho@kr|@t|@n@ruohonen @end|ng |rom gm@||@com  Fri Jan 15 10:08:58 2021
From: juho@kr|@t|@n@ruohonen @end|ng |rom gm@||@com (Juho Kristian Ruohonen)
Date: Fri, 15 Jan 2021 11:08:58 +0200
Subject: [R-sig-ME] 
 how to specify the response (dependent) variable in a
 logistic regression model
In-Reply-To: <CA+4gnfT7S5gwuZBdLpJeA9coDpA8Jr-i4oX_hTfUWL7nZiCd5A@mail.gmail.com>
References: <CA+4gnfQQd7x6BqVnMtgkXTYuMqgBqA5g=C6RbCWm9_hcTCReqA@mail.gmail.com>
 <CAFEqCdx6r472qjhcoi_K4hjFjQk-S+uCK7YyNhs8bDKYz-ea7A@mail.gmail.com>
 <63ddf228-342c-8201-f31d-08cf4638b66f@phillipalday.com>
 <CA+4gnfT7S5gwuZBdLpJeA9coDpA8Jr-i4oX_hTfUWL7nZiCd5A@mail.gmail.com>
Message-ID: <CAG_dBVdm8rz=sij-VBPC34PyWjNVELx7BPjjb5FJt=2GX=66Xg@mail.gmail.com>

Another fellow linguist here, albeit a junior one.

It sounds to me like:

   1. You have two binary outcomes, the 1st always occurring before the 2nd.
   2. For each subject, you have exactly one response per binary outcome.

This being the case, I struggle to see why a complex model such as a
multinomial, multi-response or GLMM is even necessary.

If each subject makes the same number of responses, their idiosyncrasies
can be expected to cancel each other out overall, no?. Therefore, we don't
need random effects. We can fit a standard logistic fixed-effects model
whose interpretation is 'A random individual makes a binary choice'.

And since the binary responses have a fixed order, the first one can simply
be used as a covariate in the analysis of the second one.

Thus, I struggle to see why we could not simply:

   1. First fit a standard logistic regression for Response 1 with all
   covariates of interest.
   2. Then fit a standard logistic regression for Response 2 with all
   covariates of interest PLUS the subject's observed Response 1 as an added
   covariate. Its addition will address the question of possible correlation
   between the two responses.

Experts, please do tell me why I'm wrong.

Best,

Juho



pe 15. tammik. 2021 klo 1.27 John Kingston (jkingstn at umass.edu) kirjoitti:

> Dear Phillip and Greg,
> Thank you both very much.
>
> I don't have experience yet beyond lme4, but you've both given me useful
> directions to pursue.
>
> I'll come back with results once they're in hand.
> Best,
> John
>
> John Kingston
> Professor
> Linguistics Department
> University of Massachusetts
> N434 Integrative Learning Center
> 650 N. Pleasant Street
> Amherst, MA 01003
> 1-413-545-6833, fax -2792
> jkingstn at umass.edu
> https://blogs.umass.edu/jkingstn
> <https://blogs.umass.edu/jkingstn/wp-admin/>
>
>
> On Thu, Jan 14, 2021 at 11:41 AM Phillip Alday <me at phillipalday.com>
> wrote:
>
> > John,
> >
> > How comfortable are you with mixed models software beyond lme4? This
> > seems like a perfect case for a multivariate mixed model (which you can
> > do with e.g. brms or MCMCglmm). The basic idea is that you do create a
> > single mixed model that can be thought of doing two GLMMs
> > simultaneously. Here's the basic syntax for doing this in brms:
> >
> >
> > brm(mvbind(Resp1, Resp2) ~ preds + ..., data=your_data, family=binomial)
> >
> > You can also specify this as two formulae (which really highlights the
> > "two models simultaneously" intuition):
> >
> >
> > var1 = bf(Resp1 ~ preds + ....) + binomial()
> > var2 = bf(Resp2 ~ preds + ....) + binomial()
> >
> > brm(var1 + var2, data=your_data)
> >
> > The advantage to doing this as a multivariate model as opposed to
> > separate models is that you get simultaneous estimates across both
> > models, including correlation/covariance between those estimates.  See
> > e.g. the brms documentation
> > (https://paul-buerkner.github.io/brms/articles/brms_multivariate.html)
> > for more info. In particular, pay attention to the extra syntax for
> > computing shared correlation in the random effects across sub-models.
> >
> > The cons for this approach are that [1] most reviewers in
> > (psycho)linguistics will not be familiar with it (and there was recent a
> > Twitter storm on this very problem) and [2] the computational costs are
> > noticeably higher.
> >
> > Another alternative is to do something like "linked mixed models" (cf.
> > Hohenstein, Matuschek and Kliegl, PBR 2016). There are a few variants on
> > this, but the basic idea is that you use one response to predict the
> > other. Given the temporal ordering here, this might make sense, e.g.
> >
> > mod1 = glmer(Resp1 ~ preds + ....)
> > mod2 = glmer(Resp2 ~ preds + YYY + ....)
> >
> > where YYY is one of:
> > [a] Resp1
> > [b] fitted(mod1)
> > [c] fitted(mod1) + resid(mod1)
> >
> > You can potentially omit mod1, in which case you have something like the
> > Davidson and Martin (Acta Psychologia, 2016) approach to the joint
> > analysis of reaction times and response accuracy.
> >
> > The downside to this approach is that the variability that's in Resp1
> > can create problems in mod2, because standard GLMMs assume that the
> > predictors are measured without error/variability. Variants [b] and
> > especially [c] mitigate this a bit though. (And if you want to get even
> > more complicated, there are  "errors-within-variables" models, which can
> > handle this and are available in e.g. brms). I think the advantage to
> > the linked model approach relative to the multivariate approach is that
> > it's somewhat more accessible for a typical (psycho)linguistic reviewer.
> >
> > Note that I am nominally originally from linguistics and do know a bit
> > about mixed models, so I'm a good usual suspect for a reviewer on these
> > things.
> >
> > Best,
> > Phillip
> >
> > PS: the multinomial models suggested by the others are also pretty good,
> > but again multinomial models are usually something that require getting
> > used to and doesn't reflect the potential covariance of Resp1 and Resp2
> > in an obvious way.
> >
> >
> >
> > On 14/1/21 5:05 pm, Greg Snow wrote:
> > > John,
> > >
> > > I agree that ordering your responses does not make sense, but the
> > > multinomial models are for unordered categorical data.  So you can
> > > just treat your 4 possible outcomes as unordered categories.
> > >
> > > Another option is to convert to a Poisson regression where the
> > > response variable is the count (number of times each of the 4
> > > combinations is selected) and then your categories become
> > > explanitory/predictor variables.  You can either use a single
> > > predictor with the 4 levels (and choose appropriate indicator
> > > variables) or you can have 2 predictors (b vs w and 1 vs 2) as well as
> > > their interaction.  That would give a different interpretation of the
> > > model, but may be more what you are trying to accomplish.
> > >
> > > On Thu, Jan 14, 2021 at 8:44 AM John Kingston <jkingstn at umass.edu>
> > wrote:
> > >>
> > >> Dear Thierry,
> > >> Thanks for your question. Here's the reason why I think the responses
> > >> aren't multinomial (or ordinal).
> > >>
> > >> The listeners were presented with spoken strings of the form CVC,
> where
> > C =
> > >> consonant and V = vowel. The rate at which the acoustics changed at
> the
> > >> beginning of the syllable was varied orthogonally with the duration of
> > the
> > >> vowel. The rate of acoustic change conveyed the identity of the
> initial
> > >> consonant, which was expected to sound like "b" when the rate of
> change
> > was
> > >> faster and like "w" when it was slower. The duration of the vowel
> > conveyed
> > >> how many syllables the string consisted of, which was expected to be
> "1"
> > >> when the vowel was shorter and "2" when the vowel was longer. The
> > listeners
> > >> were instructed to respond with "b" or "w" and "1" or "2" on every
> > trial.
> > >> So, unlike a truly multinomial dependent variable, such as professions
> > or
> > >> majors, the responses here are not unordered. They also cannot be
> > arranged
> > >> into a single order sensibly, because even if "b1" and "w2" responses
> > are
> > >> first and last in the order, there's no way of deciding *a priori* the
> > >> order of "b2" and "w1" responses.
> > >>
> > >> Again, thanks for your reply.
> > >> Best,
> > >> John
> > >> John Kingston
> > >> Professor
> > >> Linguistics Department
> > >> University of Massachusetts
> > >> N434 Integrative Learning Center
> > >> 650 N. Pleasant Street
> > >> Amherst, MA 01003
> > >> 1-413-545-6833, fax -2792
> > >> jkingstn at umass.edu
> > >> https://blogs.umass.edu/jkingstn
> > >> <https://blogs.umass.edu/jkingstn/wp-admin/>
> > >>
> > >>         [[alternative HTML version deleted]]
> > >>
> > >> _______________________________________________
> > >> R-sig-mixed-models at r-project.org mailing list
> > >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > >
> > >
> > >
> >
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From th|erry@onke||nx @end|ng |rom |nbo@be  Fri Jan 15 10:43:12 2021
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Fri, 15 Jan 2021 10:43:12 +0100
Subject: [R-sig-ME] 
 how to specify the response (dependent) variable in a
 logistic regression model
In-Reply-To: <CAG_dBVdm8rz=sij-VBPC34PyWjNVELx7BPjjb5FJt=2GX=66Xg@mail.gmail.com>
References: <CA+4gnfQQd7x6BqVnMtgkXTYuMqgBqA5g=C6RbCWm9_hcTCReqA@mail.gmail.com>
 <CAFEqCdx6r472qjhcoi_K4hjFjQk-S+uCK7YyNhs8bDKYz-ea7A@mail.gmail.com>
 <63ddf228-342c-8201-f31d-08cf4638b66f@phillipalday.com>
 <CA+4gnfT7S5gwuZBdLpJeA9coDpA8Jr-i4oX_hTfUWL7nZiCd5A@mail.gmail.com>
 <CAG_dBVdm8rz=sij-VBPC34PyWjNVELx7BPjjb5FJt=2GX=66Xg@mail.gmail.com>
Message-ID: <CAJuCY5wc=5Mj8QxpOL48w05kGp=JOa1EoNwhWKocVd2pgC6ryw@mail.gmail.com>

Dear all,

IMHO, Phillip's suggestion matches best with the data generating model.
Greg's suggestions are simpler but usable models too.

Given that different subjects respond to the same questions and we can rule
out that one subject is more likely to respond "b" over "w" than another
subject, we need to add the subject as a random effect.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op vr 15 jan. 2021 om 10:09 schreef Juho Kristian Ruohonen <
juho.kristian.ruohonen at gmail.com>:

> Another fellow linguist here, albeit a junior one.
>
> It sounds to me like:
>
>    1. You have two binary outcomes, the 1st always occurring before the
> 2nd.
>    2. For each subject, you have exactly one response per binary outcome.
>
> This being the case, I struggle to see why a complex model such as a
> multinomial, multi-response or GLMM is even necessary.
>
> If each subject makes the same number of responses, their idiosyncrasies
> can be expected to cancel each other out overall, no?. Therefore, we don't
> need random effects. We can fit a standard logistic fixed-effects model
> whose interpretation is 'A random individual makes a binary choice'.
>
> And since the binary responses have a fixed order, the first one can simply
> be used as a covariate in the analysis of the second one.
>
> Thus, I struggle to see why we could not simply:
>
>    1. First fit a standard logistic regression for Response 1 with all
>    covariates of interest.
>    2. Then fit a standard logistic regression for Response 2 with all
>    covariates of interest PLUS the subject's observed Response 1 as an
> added
>    covariate. Its addition will address the question of possible
> correlation
>    between the two responses.
>
> Experts, please do tell me why I'm wrong.
>
> Best,
>
> Juho
>
>
>
> pe 15. tammik. 2021 klo 1.27 John Kingston (jkingstn at umass.edu) kirjoitti:
>
> > Dear Phillip and Greg,
> > Thank you both very much.
> >
> > I don't have experience yet beyond lme4, but you've both given me useful
> > directions to pursue.
> >
> > I'll come back with results once they're in hand.
> > Best,
> > John
> >
> > John Kingston
> > Professor
> > Linguistics Department
> > University of Massachusetts
> > N434 Integrative Learning Center
> > 650 N. Pleasant Street
> > Amherst, MA 01003
> > 1-413-545-6833, fax -2792
> > jkingstn at umass.edu
> > https://blogs.umass.edu/jkingstn
> > <https://blogs.umass.edu/jkingstn/wp-admin/>
> >
> >
> > On Thu, Jan 14, 2021 at 11:41 AM Phillip Alday <me at phillipalday.com>
> > wrote:
> >
> > > John,
> > >
> > > How comfortable are you with mixed models software beyond lme4? This
> > > seems like a perfect case for a multivariate mixed model (which you can
> > > do with e.g. brms or MCMCglmm). The basic idea is that you do create a
> > > single mixed model that can be thought of doing two GLMMs
> > > simultaneously. Here's the basic syntax for doing this in brms:
> > >
> > >
> > > brm(mvbind(Resp1, Resp2) ~ preds + ..., data=your_data,
> family=binomial)
> > >
> > > You can also specify this as two formulae (which really highlights the
> > > "two models simultaneously" intuition):
> > >
> > >
> > > var1 = bf(Resp1 ~ preds + ....) + binomial()
> > > var2 = bf(Resp2 ~ preds + ....) + binomial()
> > >
> > > brm(var1 + var2, data=your_data)
> > >
> > > The advantage to doing this as a multivariate model as opposed to
> > > separate models is that you get simultaneous estimates across both
> > > models, including correlation/covariance between those estimates.  See
> > > e.g. the brms documentation
> > > (https://paul-buerkner.github.io/brms/articles/brms_multivariate.html)
> > > for more info. In particular, pay attention to the extra syntax for
> > > computing shared correlation in the random effects across sub-models.
> > >
> > > The cons for this approach are that [1] most reviewers in
> > > (psycho)linguistics will not be familiar with it (and there was recent
> a
> > > Twitter storm on this very problem) and [2] the computational costs are
> > > noticeably higher.
> > >
> > > Another alternative is to do something like "linked mixed models" (cf.
> > > Hohenstein, Matuschek and Kliegl, PBR 2016). There are a few variants
> on
> > > this, but the basic idea is that you use one response to predict the
> > > other. Given the temporal ordering here, this might make sense, e.g.
> > >
> > > mod1 = glmer(Resp1 ~ preds + ....)
> > > mod2 = glmer(Resp2 ~ preds + YYY + ....)
> > >
> > > where YYY is one of:
> > > [a] Resp1
> > > [b] fitted(mod1)
> > > [c] fitted(mod1) + resid(mod1)
> > >
> > > You can potentially omit mod1, in which case you have something like
> the
> > > Davidson and Martin (Acta Psychologia, 2016) approach to the joint
> > > analysis of reaction times and response accuracy.
> > >
> > > The downside to this approach is that the variability that's in Resp1
> > > can create problems in mod2, because standard GLMMs assume that the
> > > predictors are measured without error/variability. Variants [b] and
> > > especially [c] mitigate this a bit though. (And if you want to get even
> > > more complicated, there are  "errors-within-variables" models, which
> can
> > > handle this and are available in e.g. brms). I think the advantage to
> > > the linked model approach relative to the multivariate approach is that
> > > it's somewhat more accessible for a typical (psycho)linguistic
> reviewer.
> > >
> > > Note that I am nominally originally from linguistics and do know a bit
> > > about mixed models, so I'm a good usual suspect for a reviewer on these
> > > things.
> > >
> > > Best,
> > > Phillip
> > >
> > > PS: the multinomial models suggested by the others are also pretty
> good,
> > > but again multinomial models are usually something that require getting
> > > used to and doesn't reflect the potential covariance of Resp1 and Resp2
> > > in an obvious way.
> > >
> > >
> > >
> > > On 14/1/21 5:05 pm, Greg Snow wrote:
> > > > John,
> > > >
> > > > I agree that ordering your responses does not make sense, but the
> > > > multinomial models are for unordered categorical data.  So you can
> > > > just treat your 4 possible outcomes as unordered categories.
> > > >
> > > > Another option is to convert to a Poisson regression where the
> > > > response variable is the count (number of times each of the 4
> > > > combinations is selected) and then your categories become
> > > > explanitory/predictor variables.  You can either use a single
> > > > predictor with the 4 levels (and choose appropriate indicator
> > > > variables) or you can have 2 predictors (b vs w and 1 vs 2) as well
> as
> > > > their interaction.  That would give a different interpretation of the
> > > > model, but may be more what you are trying to accomplish.
> > > >
> > > > On Thu, Jan 14, 2021 at 8:44 AM John Kingston <jkingstn at umass.edu>
> > > wrote:
> > > >>
> > > >> Dear Thierry,
> > > >> Thanks for your question. Here's the reason why I think the
> responses
> > > >> aren't multinomial (or ordinal).
> > > >>
> > > >> The listeners were presented with spoken strings of the form CVC,
> > where
> > > C =
> > > >> consonant and V = vowel. The rate at which the acoustics changed at
> > the
> > > >> beginning of the syllable was varied orthogonally with the duration
> of
> > > the
> > > >> vowel. The rate of acoustic change conveyed the identity of the
> > initial
> > > >> consonant, which was expected to sound like "b" when the rate of
> > change
> > > was
> > > >> faster and like "w" when it was slower. The duration of the vowel
> > > conveyed
> > > >> how many syllables the string consisted of, which was expected to be
> > "1"
> > > >> when the vowel was shorter and "2" when the vowel was longer. The
> > > listeners
> > > >> were instructed to respond with "b" or "w" and "1" or "2" on every
> > > trial.
> > > >> So, unlike a truly multinomial dependent variable, such as
> professions
> > > or
> > > >> majors, the responses here are not unordered. They also cannot be
> > > arranged
> > > >> into a single order sensibly, because even if "b1" and "w2"
> responses
> > > are
> > > >> first and last in the order, there's no way of deciding *a priori*
> the
> > > >> order of "b2" and "w1" responses.
> > > >>
> > > >> Again, thanks for your reply.
> > > >> Best,
> > > >> John
> > > >> John Kingston
> > > >> Professor
> > > >> Linguistics Department
> > > >> University of Massachusetts
> > > >> N434 Integrative Learning Center
> > > >> 650 N. Pleasant Street
> > > >> Amherst, MA 01003
> > > >> 1-413-545-6833, fax -2792
> > > >> jkingstn at umass.edu
> > > >> https://blogs.umass.edu/jkingstn
> > > >> <https://blogs.umass.edu/jkingstn/wp-admin/>
> > > >>
> > > >>         [[alternative HTML version deleted]]
> > > >>
> > > >> _______________________________________________
> > > >> R-sig-mixed-models at r-project.org mailing list
> > > >> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > > >
> > > >
> > > >
> > >
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Fri Jan 15 23:56:26 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Fri, 15 Jan 2021 17:56:26 -0500
Subject: [R-sig-ME] 
 how to specify the response (dependent) variable in a
 logistic regression model
In-Reply-To: <CA+4gnfT7S5gwuZBdLpJeA9coDpA8Jr-i4oX_hTfUWL7nZiCd5A@mail.gmail.com>
References: <CA+4gnfQQd7x6BqVnMtgkXTYuMqgBqA5g=C6RbCWm9_hcTCReqA@mail.gmail.com>
 <CAFEqCdx6r472qjhcoi_K4hjFjQk-S+uCK7YyNhs8bDKYz-ea7A@mail.gmail.com>
 <63ddf228-342c-8201-f31d-08cf4638b66f@phillipalday.com>
 <CA+4gnfT7S5gwuZBdLpJeA9coDpA8Jr-i4oX_hTfUWL7nZiCd5A@mail.gmail.com>
Message-ID: <9a69a75f-dd6f-ef2c-d201-e8595e735814@gmail.com>

    I think you can also do this in lme4 with a little bit more work, see

https://rpubs.com/bbolker/3336
https://mac-theobio.github.io/QMEE/lectures/MultivariateMixed.notes.html


On 1/14/21 6:27 PM, John Kingston wrote:
> Dear Phillip and Greg,
> Thank you both very much.
> 
> I don't have experience yet beyond lme4, but you've both given me useful
> directions to pursue.
> 
> I'll come back with results once they're in hand.
> Best,
> John
> 
> John Kingston
> Professor
> Linguistics Department
> University of Massachusetts
> N434 Integrative Learning Center
> 650 N. Pleasant Street
> Amherst, MA 01003
> 1-413-545-6833, fax -2792
> jkingstn at umass.edu
> https://blogs.umass.edu/jkingstn
> <https://blogs.umass.edu/jkingstn/wp-admin/>
> 
> 
> On Thu, Jan 14, 2021 at 11:41 AM Phillip Alday <me at phillipalday.com> wrote:
> 
>> John,
>>
>> How comfortable are you with mixed models software beyond lme4? This
>> seems like a perfect case for a multivariate mixed model (which you can
>> do with e.g. brms or MCMCglmm). The basic idea is that you do create a
>> single mixed model that can be thought of doing two GLMMs
>> simultaneously. Here's the basic syntax for doing this in brms:
>>
>>
>> brm(mvbind(Resp1, Resp2) ~ preds + ..., data=your_data, family=binomial)
>>
>> You can also specify this as two formulae (which really highlights the
>> "two models simultaneously" intuition):
>>
>>
>> var1 = bf(Resp1 ~ preds + ....) + binomial()
>> var2 = bf(Resp2 ~ preds + ....) + binomial()
>>
>> brm(var1 + var2, data=your_data)
>>
>> The advantage to doing this as a multivariate model as opposed to
>> separate models is that you get simultaneous estimates across both
>> models, including correlation/covariance between those estimates.  See
>> e.g. the brms documentation
>> (https://paul-buerkner.github.io/brms/articles/brms_multivariate.html)
>> for more info. In particular, pay attention to the extra syntax for
>> computing shared correlation in the random effects across sub-models.
>>
>> The cons for this approach are that [1] most reviewers in
>> (psycho)linguistics will not be familiar with it (and there was recent a
>> Twitter storm on this very problem) and [2] the computational costs are
>> noticeably higher.
>>
>> Another alternative is to do something like "linked mixed models" (cf.
>> Hohenstein, Matuschek and Kliegl, PBR 2016). There are a few variants on
>> this, but the basic idea is that you use one response to predict the
>> other. Given the temporal ordering here, this might make sense, e.g.
>>
>> mod1 = glmer(Resp1 ~ preds + ....)
>> mod2 = glmer(Resp2 ~ preds + YYY + ....)
>>
>> where YYY is one of:
>> [a] Resp1
>> [b] fitted(mod1)
>> [c] fitted(mod1) + resid(mod1)
>>
>> You can potentially omit mod1, in which case you have something like the
>> Davidson and Martin (Acta Psychologia, 2016) approach to the joint
>> analysis of reaction times and response accuracy.
>>
>> The downside to this approach is that the variability that's in Resp1
>> can create problems in mod2, because standard GLMMs assume that the
>> predictors are measured without error/variability. Variants [b] and
>> especially [c] mitigate this a bit though. (And if you want to get even
>> more complicated, there are  "errors-within-variables" models, which can
>> handle this and are available in e.g. brms). I think the advantage to
>> the linked model approach relative to the multivariate approach is that
>> it's somewhat more accessible for a typical (psycho)linguistic reviewer.
>>
>> Note that I am nominally originally from linguistics and do know a bit
>> about mixed models, so I'm a good usual suspect for a reviewer on these
>> things.
>>
>> Best,
>> Phillip
>>
>> PS: the multinomial models suggested by the others are also pretty good,
>> but again multinomial models are usually something that require getting
>> used to and doesn't reflect the potential covariance of Resp1 and Resp2
>> in an obvious way.
>>
>>
>>
>> On 14/1/21 5:05 pm, Greg Snow wrote:
>>> John,
>>>
>>> I agree that ordering your responses does not make sense, but the
>>> multinomial models are for unordered categorical data.  So you can
>>> just treat your 4 possible outcomes as unordered categories.
>>>
>>> Another option is to convert to a Poisson regression where the
>>> response variable is the count (number of times each of the 4
>>> combinations is selected) and then your categories become
>>> explanitory/predictor variables.  You can either use a single
>>> predictor with the 4 levels (and choose appropriate indicator
>>> variables) or you can have 2 predictors (b vs w and 1 vs 2) as well as
>>> their interaction.  That would give a different interpretation of the
>>> model, but may be more what you are trying to accomplish.
>>>
>>> On Thu, Jan 14, 2021 at 8:44 AM John Kingston <jkingstn at umass.edu>
>> wrote:
>>>>
>>>> Dear Thierry,
>>>> Thanks for your question. Here's the reason why I think the responses
>>>> aren't multinomial (or ordinal).
>>>>
>>>> The listeners were presented with spoken strings of the form CVC, where
>> C =
>>>> consonant and V = vowel. The rate at which the acoustics changed at the
>>>> beginning of the syllable was varied orthogonally with the duration of
>> the
>>>> vowel. The rate of acoustic change conveyed the identity of the initial
>>>> consonant, which was expected to sound like "b" when the rate of change
>> was
>>>> faster and like "w" when it was slower. The duration of the vowel
>> conveyed
>>>> how many syllables the string consisted of, which was expected to be "1"
>>>> when the vowel was shorter and "2" when the vowel was longer. The
>> listeners
>>>> were instructed to respond with "b" or "w" and "1" or "2" on every
>> trial.
>>>> So, unlike a truly multinomial dependent variable, such as professions
>> or
>>>> majors, the responses here are not unordered. They also cannot be
>> arranged
>>>> into a single order sensibly, because even if "b1" and "w2" responses
>> are
>>>> first and last in the order, there's no way of deciding *a priori* the
>>>> order of "b2" and "w1" responses.
>>>>
>>>> Again, thanks for your reply.
>>>> Best,
>>>> John
>>>> John Kingston
>>>> Professor
>>>> Linguistics Department
>>>> University of Massachusetts
>>>> N434 Integrative Learning Center
>>>> 650 N. Pleasant Street
>>>> Amherst, MA 01003
>>>> 1-413-545-6833, fax -2792
>>>> jkingstn at umass.edu
>>>> https://blogs.umass.edu/jkingstn
>>>> <https://blogs.umass.edu/jkingstn/wp-admin/>
>>>>
>>>>          [[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>>
>>>
>>
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From @|m@h@rme| @end|ng |rom gm@||@com  Sat Jan 16 06:42:00 2021
From: @|m@h@rme| @end|ng |rom gm@||@com (Simon Harmel)
Date: Fri, 15 Jan 2021 23:42:00 -0600
Subject: [R-sig-ME] Set two coefficients to be equal in lme()
Message-ID: <CACgv6yUxh24eqOpBjWq3CpeyFu0oUQJYR-w2KAXP1YYfBY55fg@mail.gmail.com>

Dear All,

I was wondering if it might be possible in my below model to set
"D1:Treat" and "D2:Treat" to be equal?

lme(value ~ 0 + D1 + D2 + D1:Treat + D2:Treat, random = ~0 + D1 + D2 |
Student, data = data)

Thank you,
Simon

	[[alternative HTML version deleted]]


From u@nhoro@1 @end|ng |rom buckeyem@||@o@u@edu  Sat Jan 16 07:10:05 2021
From: u@nhoro@1 @end|ng |rom buckeyem@||@o@u@edu (Uanhoro, James)
Date: Sat, 16 Jan 2021 06:10:05 +0000
Subject: [R-sig-ME] Set two coefficients to be equal in lme()
In-Reply-To: <CACgv6yUxh24eqOpBjWq3CpeyFu0oUQJYR-w2KAXP1YYfBY55fg@mail.gmail.com>
References: <CACgv6yUxh24eqOpBjWq3CpeyFu0oUQJYR-w2KAXP1YYfBY55fg@mail.gmail.com>
Message-ID: <156343a4db095c9bf47cb5de89d380574ba8ae85.camel@buckeyemail.osu.edu>

Dear Simon,

Create a variable that is the sum of D1 * Treat and D2 * Treat and place it in the model:

data$new_var <- (data$D1 + data$D2) * data$Treat
lme(value ~ 0 + D1 + D2 + new_var, random = ~0 + D1 + D2 | Student, data = data)

The coefficient of new_var in the model above is the coefficient for both variables if their coefficients were constrained equal.

James.

On Fri, 2021-01-15 at 23:42 -0600, Simon Harmel wrote:
Dear All,

I was wondering if it might be possible in my below model to set
"D1:Treat" and "D2:Treat" to be equal?

lme(value ~ 0 + D1 + D2 + D1:Treat + D2:Treat, random = ~0 + D1 + D2 |
Student, data = data)

Thank you,
Simon

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!KGKeukY!hQ3ckIWlyqLy5tBnCl95bnMNKolFrWnQRu6QTS9PccmzQxnbqcOShxhVL7FHXci3_siUHiNNAdM$


	[[alternative HTML version deleted]]


From u@nhoro@1 @end|ng |rom buckeyem@||@o@u@edu  Sat Jan 16 15:00:22 2021
From: u@nhoro@1 @end|ng |rom buckeyem@||@o@u@edu (Uanhoro, James)
Date: Sat, 16 Jan 2021 14:00:22 +0000
Subject: [R-sig-ME] Set two coefficients to be equal in lme()
In-Reply-To: <156343a4db095c9bf47cb5de89d380574ba8ae85.camel@buckeyemail.osu.edu>
References: <CACgv6yUxh24eqOpBjWq3CpeyFu0oUQJYR-w2KAXP1YYfBY55fg@mail.gmail.com>,
 <156343a4db095c9bf47cb5de89d380574ba8ae85.camel@buckeyemail.osu.edu>
Message-ID: <CH2PR01MB5734FBEE5E15772CE0E1647FF7A60@CH2PR01MB5734.prod.exchangelabs.com>

If D1 and D2 are coded {-.5, .5} as you suggested in a separate email, then D1+D2 = 0 if all cases either belong to group D1 or D2 and never both. Then read Treat * new_var = 0, a constant not a variable.

In that case, simply use Treat in the model by itself - again, this is the same as constraining both groups to have the same Treat coefficient.

lme(value ~ 0 + D1 + D2 + Treat, random = ~0 + D1 + D2 | Student, data = data)

Also, basic idea behind all this is: b * x1 + b * x2 = b * (x1 + x2).

James.

________________________________
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of Uanhoro, James <uanhoro.1 at buckeyemail.osu.edu>
Sent: Saturday, January 16, 2021, 01:10
To: r-sig-mixed-models at r-project.org
Subject: Re: [R-sig-ME] Set two coefficients to be equal in lme()

Dear Simon,

Create a variable that is the sum of D1 * Treat and D2 * Treat and place it in the model:

data$new_var <- (data$D1 + data$D2) * data$Treat
lme(value ~ 0 + D1 + D2 + new_var, random = ~0 + D1 + D2 | Student, data = data)

The coefficient of new_var in the model above is the coefficient for both variables if their coefficients were constrained equal.

James.

On Fri, 2021-01-15 at 23:42 -0600, Simon Harmel wrote:
Dear All,

I was wondering if it might be possible in my below model to set
"D1:Treat" and "D2:Treat" to be equal?

lme(value ~ 0 + D1 + D2 + D1:Treat + D2:Treat, random = ~0 + D1 + D2 |
Student, data = data)

Thank you,
Simon

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!KGKeukY!hQ3ckIWlyqLy5tBnCl95bnMNKolFrWnQRu6QTS9PccmzQxnbqcOShxhVL7FHXci3_siUHiNNAdM$


        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!KGKeukY!nTI9flHdl-yk8eCV0yW6MKuX9CpUt1ou2zObcnZPtbJwnD2foUvMOxLrBWzjyQRnZaJ8y6i-FWw$


	[[alternative HTML version deleted]]


From @|m@h@rme| @end|ng |rom gm@||@com  Sat Jan 16 17:37:00 2021
From: @|m@h@rme| @end|ng |rom gm@||@com (Simon Harmel)
Date: Sat, 16 Jan 2021 10:37:00 -0600
Subject: [R-sig-ME] Set two coefficients to be equal in lme()
In-Reply-To: <156343a4db095c9bf47cb5de89d380574ba8ae85.camel@buckeyemail.osu.edu>
References: <CACgv6yUxh24eqOpBjWq3CpeyFu0oUQJYR-w2KAXP1YYfBY55fg@mail.gmail.com>
 <156343a4db095c9bf47cb5de89d380574ba8ae85.camel@buckeyemail.osu.edu>
Message-ID: <CACgv6yWDVRdV8id1nO8b2migo0j3JkUO3NaRg396s7KSS+oBCQ@mail.gmail.com>

Dear James,

Thank you for your answer. I have a follow-up question. In my `dat` dataset
below, "Treat" is coded {-.5, .5}. D1 & D2 are simply dummy coded {0, 1} .

My question is: why when I recode "Treat" as a factor {-.5="C", .5="T"},
then the model fails? Below is a reproducible example:

library(nlme)

(dat <- read.csv("https://raw.githubusercontent.com/hkil/m/master/mv.l.csv
"))

model_works <- lme(value ~ 0 + D1 + D2+D1:Treat+D2:Treat, random = ~0 + D1
+ D2 | Student, data = dat)

(dat2 <- transform(dat, Treat = ifelse(Treat==.5,"T", "C")))  # recode
Treat as a factor

model_fails <- lme(value ~ 0 + D1 + D2+D1:Treat+D2:Treat, random = ~0 + D1
+ D2 | Student, data = dat2)

On Sat, Jan 16, 2021 at 12:10 AM Uanhoro, James <
uanhoro.1 at buckeyemail.osu.edu> wrote:

> Dear Simon,
>
> Create a variable that is the sum of D1 * Treat and D2 * Treat and place
> it in the model:
>
> data$new_var <- (data$D1 + data$D2) * data$Treat
> lme(value ~ 0 + D1 + D2 + new_var, random = ~0 + D1 + D2 | Student, data =
> data)
>
> The coefficient of new_var in the model above is the coefficient for both
> variables if their coefficients were constrained equal.
>
> James.
>
> On Fri, 2021-01-15 at 23:42 -0600, Simon Harmel wrote:
> Dear All,
>
> I was wondering if it might be possible in my below model to set
> "D1:Treat" and "D2:Treat" to be equal?
>
> lme(value ~ 0 + D1 + D2 + D1:Treat + D2:Treat, random = ~0 + D1 + D2 |
> Student, data = data)
>
> Thank you,
> Simon
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org>
> mailing list
>
> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!KGKeukY!hQ3ckIWlyqLy5tBnCl95bnMNKolFrWnQRu6QTS9PccmzQxnbqcOShxhVL7FHXci3_siUHiNNAdM$
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From Andre@Syvert@en @end|ng |rom u|b@no  Sun Jan 17 14:26:28 2021
From: Andre@Syvert@en @end|ng |rom u|b@no (Andre Syvertsen)
Date: Sun, 17 Jan 2021 13:26:28 +0000
Subject: [R-sig-ME] Help: Specifying truncation point in glmmTMB package
Message-ID: <AM6PR0102MB3174142C9779CF81D15C476E9EA50@AM6PR0102MB3174.eurprd01.prod.exchangelabs.com>

Hi,
I am working with a large dataset that contains longitudinal data on gambling behavior of 184,113 participants. The data is based on complete tracking of electronic gambling behavior within a gambling operator. Gambling behavior data is aggregated on a monthly level, a total of 70 months. I have an ID variable separating participants, a time variable (months), as well as numerous gambling behavior variables such as active days played for given month, bets placed for given month, total losses for given month, etc. Participants vary in when they have been active gambling. One participant may have gambled at month 2, 3, 4, and 7, another participant at 3, 5, and 7, and a third at 23, 24, 48, 65 etc.
I am attempting to run a negative binomial 2 truncated model in glmmTMB and I am wondering how the package handles lack of 0. I have longitudinal data on gambling behavior, days played for each month (for a total of 70 months). The variable can take values between 1-31 (depending on month), there are no 0. Participants? months with 0 are absent from dataset. Example of how data are structured with just two participants:
# Example variables and data frame in long form
  # Includes id variable, time variable and example variable
id <- c(1, 1, 1, 1, 2, 2, 2)
time <- c(2, 3, 4, 7, 3, 5, 7)
daysPlayed <- c(2, 2, 3, 3, 2, 2, 2)
dfLong <- data.frame(id = id, time = time, daysPlayed = daysPlayed)

My question: How do I specify where the truncation happens in glmmTMB? Does it default to 0? I want to truncate 0 and have run the following code (I am going to compare models, the first one is a simple unconditional one):
DaysPlayedUnconditional <- glmmTMB(daysPlayed ~ 1 + (1 | id), dfLong, family = truncated_nbinom2)
Will it do the trick?


Kind regards,
Andr? Syvertsen
PhD student, University of Bergen


	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Mon Jan 18 00:07:43 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Sun, 17 Jan 2021 18:07:43 -0500
Subject: [R-sig-ME] Help: Specifying truncation point in glmmTMB package
In-Reply-To: <AM6PR0102MB3174142C9779CF81D15C476E9EA50@AM6PR0102MB3174.eurprd01.prod.exchangelabs.com>
References: <AM6PR0102MB3174142C9779CF81D15C476E9EA50@AM6PR0102MB3174.eurprd01.prod.exchangelabs.com>
Message-ID: <d4469486-5b9b-8f20-9713-f8da55673909@gmail.com>


     I'm not 100% clear on your question, but: glmmTMB *only* does 
zero-truncation, not k-truncation with k>0, i.e. you can only specify 
the model

   Prob(x==0) = 0
   Prob(x>0) = Prob(NBinom(x))/Prob(NBinom(x>0))

(terrible notation, but hopefully you get the idea)



On 1/17/21 8:26 AM, Andre Syvertsen wrote:
> Hi,
> I am working with a large dataset that contains longitudinal data on gambling behavior of 184,113 participants. The data is based on complete tracking of electronic gambling behavior within a gambling operator. Gambling behavior data is aggregated on a monthly level, a total of 70 months. I have an ID variable separating participants, a time variable (months), as well as numerous gambling behavior variables such as active days played for given month, bets placed for given month, total losses for given month, etc. Participants vary in when they have been active gambling. One participant may have gambled at month 2, 3, 4, and 7, another participant at 3, 5, and 7, and a third at 23, 24, 48, 65 etc.
> I am attempting to run a negative binomial 2 truncated model in glmmTMB and I am wondering how the package handles lack of 0. I have longitudinal data on gambling behavior, days played for each month (for a total of 70 months). The variable can take values between 1-31 (depending on month), there are no 0. Participants? months with 0 are absent from dataset. Example of how data are structured with just two participants:
> # Example variables and data frame in long form
>    # Includes id variable, time variable and example variable
> id <- c(1, 1, 1, 1, 2, 2, 2)
> time <- c(2, 3, 4, 7, 3, 5, 7)
> daysPlayed <- c(2, 2, 3, 3, 2, 2, 2)
> dfLong <- data.frame(id = id, time = time, daysPlayed = daysPlayed)
> 
> My question: How do I specify where the truncation happens in glmmTMB? Does it default to 0? I want to truncate 0 and have run the following code (I am going to compare models, the first one is a simple unconditional one):
> DaysPlayedUnconditional <- glmmTMB(daysPlayed ~ 1 + (1 | id), dfLong, family = truncated_nbinom2)
> Will it do the trick?
> 
> 
> Kind regards,
> Andr? Syvertsen
> PhD student, University of Bergen
> 
> 
> 	[[alternative HTML version deleted]]
> 
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From @|m@h@rme| @end|ng |rom gm@||@com  Tue Jan 19 03:29:22 2021
From: @|m@h@rme| @end|ng |rom gm@||@com (Simon Harmel)
Date: Mon, 18 Jan 2021 20:29:22 -0600
Subject: [R-sig-ME] bivariate growth models using lme()
Message-ID: <CACgv6yXkwLBoPGjb6kUOyaaGwgOOpPxMVk13v3W4BSPjuhcfFA@mail.gmail.com>

Hello all,

In chapter 8 of this book (
https://www.guilford.com/books/Growth-Modeling/Grimm-Ram-Estabrook/9781462526062),
p. 172, script 8.2, there is a demonstration of a bivariate growth model
fit with `nlme()` function (see `m1` below).

I was wondering if the same model could be fit using the `lme()` function?
I have tried `lme()` (see `m2` below), but the output doesn't match. --
Thanks, Simon

multivariate <- read.csv('
https://raw.githubusercontent.com/hkil/m/master/bv.csv')


lmeCtlList <- lmeControl(maxIter = 200, msMaxIter = 200, niterEM = 50,
           msMaxEval = 400)

m1 <- nlme(var~d_math*(b_1i+b_2i*(grade-2))+
         d_hyp *(h_1i+h_2i*(grade-2)),
       data      = multivariate,
       fixed     = b_1i+b_2i+h_1i+h_2i~1,
       random    = b_1i+b_2i+h_1i+h_2i~1,
       group     = ~id,
       start     = c(35, 4, 1, -1),
       weights   = varIdent(c(hyp=.3), form = ~1|grp),
       na.action = na.omit,
       control=lmeCtlList)


m2 <- lme(var ~ 0 + d_math + d_hyp + d_math:grade + d_hyp:grade,
    random = ~ 0 + d_math + d_hyp + d_math:grade + d_hyp:grade | id, data =
multivariate,
    na.action = na.omit, weights  = varIdent(c(hyp=.3), form = ~1|grp),
    control = lmeCtlList)

# `m1` output:
coef(summary(m1))
           Value  Std.Error   DF   t-value       p-value
b_1i 35.25857425 0.35511071 3456 99.288962  0.000000e+00
b_2i  4.34307216 0.08737929 3456 49.703680  0.000000e+00
h_1i  1.90351659 0.05815329 3456 32.732739 6.143241e-205
h_2i -0.05663496 0.01422441 3456 -3.981533  6.988077e-05

  # `m2` output:
  coef(summary(m2))
                   Value  Std.Error   DF   t-value       p-value
d_math       26.57270335 0.47201444 3456 56.296378  0.000000e+00
d_hyp         2.01699310 0.07867055 3456 25.638478 7.225043e-133
d_math:grade  4.34308917 0.08740932 3456 49.686797  0.000000e+00
d_hyp:grade  -0.05670937 0.01414676 3456 -4.008647  6.235700e-05

	[[alternative HTML version deleted]]


From v|tor@v@v @end|ng |rom gm@||@com  Tue Jan 19 03:54:56 2021
From: v|tor@v@v @end|ng |rom gm@||@com (Vitor Vieira Vasconcelos)
Date: Mon, 18 Jan 2021 21:54:56 -0500
Subject: [R-sig-ME] P-values of averaged mixed model parameters in MuMIn
Message-ID: <CANAwtjuPtm5PSXQRQg1cvAb+t3-fyJ31d0yA1JbNCpQJPg3y6g@mail.gmail.com>

  Hi,
  Our research team is using the MuMIn package, and we got in doubt about
how it calculates probability values (p-values) for the averaged
coefficients of the respective resulting averaged models. In our case, we
are averaging generalized linear mixed models of the glmmTMB package. In
the details of the par.avg() function, I understood how the unconditional
standard errors are calculated, but I could not find there (neither in the
provided references) how the p-values are calculated.
    We are aware that p-values in generalized linear mixed models has been
a controversial topic, but we also noted that calculating p-values from
simulation or bootstrapping has becoming increasingly popular.
     We would be immensely grateful if anyone could provide us some
information about how the p-values are calculated in this context in MuMIn
package.

Best regards,
Vitor Vieira Vasconcelos
55-31-99331-1593

	[[alternative HTML version deleted]]


From hu@ng@jcc @end|ng |rom gm@||@com  Thu Jan 21 02:10:09 2021
From: hu@ng@jcc @end|ng |rom gm@||@com (Sijia Huang)
Date: Wed, 20 Jan 2021 17:10:09 -0800
Subject: [R-sig-ME] Impose equality constraints on regression coefficients
Message-ID: <CAPmBuzEOCbprtp+_Fth-UKbKRcNu3gNx7un_kZWk944tOzL4MA@mail.gmail.com>

Hi everyone,
I am trying to fit a mixed effect model with the lme4 package. I wonder
what syntax I can use to impose equality constraints on regression
coefficients.


Thank you in advance for your help!

Best,
Sijia

	[[alternative HTML version deleted]]


From me @end|ng |rom ph||||p@|d@y@com  Thu Jan 21 09:58:40 2021
From: me @end|ng |rom ph||||p@|d@y@com (Phillip Alday)
Date: Thu, 21 Jan 2021 09:58:40 +0100
Subject: [R-sig-ME] 
 Impose equality constraints on regression coefficients
In-Reply-To: <CAPmBuzEOCbprtp+_Fth-UKbKRcNu3gNx7un_kZWk944tOzL4MA@mail.gmail.com>
References: <CAPmBuzEOCbprtp+_Fth-UKbKRcNu3gNx7un_kZWk944tOzL4MA@mail.gmail.com>
Message-ID: <61614369-ba81-f0d1-a028-664dde7c9c4c@phillipalday.com>

This was discussed recently on the list in the context lme, but the same
solution works for lme4:

https://stat.ethz.ch/pipermail/r-sig-mixed-models/2021q1/029243.html

Phillip

On 21/01/2021 02:10, Sijia Huang wrote:
> Hi everyone,
> I am trying to fit a mixed effect model with the lme4 package. I wonder
> what syntax I can use to impose equality constraints on regression
> coefficients.
>
>
> Thank you in advance for your help!
>
> Best,
> Sijia
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbo|ker @end|ng |rom gm@||@com  Thu Jan 21 16:14:16 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Thu, 21 Jan 2021 10:14:16 -0500
Subject: [R-sig-ME] P-values of averaged mixed model parameters in MuMIn
In-Reply-To: <CANAwtjuPtm5PSXQRQg1cvAb+t3-fyJ31d0yA1JbNCpQJPg3y6g@mail.gmail.com>
References: <CANAwtjuPtm5PSXQRQg1cvAb+t3-fyJ31d0yA1JbNCpQJPg3y6g@mail.gmail.com>
Message-ID: <1359e3c1-dfca-8ba3-62dc-5781e1b6c021@gmail.com>

    (I've been meaning to respond to this for a few days ...)

    If you look at MuMin:::summary.coefTable you'll see code that looks 
like this:

tvalue <- object[, 1L]/object[, 2L]
     if (all(is.na(object[, 3L]))) {
         pvalue <- 2 * pnorm(-abs(tvalue))
         rval <- cbind(object, tvalue, pvalue)
         cn <- c("z value", "Pr(>|z|)")
     }
     else if (any(is.finite(tvalue))) {
         pvalue <- 2 * pt(-abs(tvalue), object[, 3L])
         cn <- c("t value", "Pr(>|t|)")
     }


   This shows that the p-values are simply calculated from Z/t 
statistics, which are in turn calculated from estimates and 
appropriately adjusted standard errors.

   My personal opinion is that you should be **very** cautious with 
inference/p-values on model-averaged coefficients:

   * some of the strongest proponents of information-theoretic/model 
averaging approaches  (White, Burnham, Anderson) are against mixing 
frequentist null-hypothesis testing with model averaging approaches

   * there's a medium-sized literature that suggests that _most_ (if not 
all) approaches to inference on model-averaged parameters are overly 
optimistic (= overly narrow confidence intervals = low coverage = overly 
low p-values = inflated type 1 error); one example is

Kabaila, Paul, A. H. Welsh, and Waruni Abeysekera. ?Model-Averaged 
Confidence Intervals.? Scandinavian Journal of Statistics 43, no. 1 
(March 1, 2016): 35?48. https://doi.org/10.1111/sjos.12163.


On 1/18/21 9:54 PM, Vitor Vieira Vasconcelos wrote:
>    Hi,
>    Our research team is using the MuMIn package, and we got in doubt about
> how it calculates probability values (p-values) for the averaged
> coefficients of the respective resulting averaged models. In our case, we
> are averaging generalized linear mixed models of the glmmTMB package. In
> the details of the par.avg() function, I understood how the unconditional
> standard errors are calculated, but I could not find there (neither in the
> provided references) how the p-values are calculated.
>      We are aware that p-values in generalized linear mixed models has been
> a controversial topic, but we also noted that calculating p-values from
> simulation or bootstrapping has becoming increasingly popular.
>       We would be immensely grateful if anyone could provide us some
> information about how the p-values are calculated in this context in MuMIn
> package.
> 
> Best regards,
> Vitor Vieira Vasconcelos
> 55-31-99331-1593
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From nt@rd||| @end|ng |rom @@@@upenn@edu  Thu Jan 21 17:54:58 2021
From: nt@rd||| @end|ng |rom @@@@upenn@edu (Nathan Tardiff)
Date: Thu, 21 Jan 2021 11:54:58 -0500
Subject: [R-sig-ME] addressing singularity in lme4 fits caused by subsets of
 contrasts
Message-ID: <CA+d67B5fWYyYAs3ke1NpGjWSGhHizEUfYJ9w1WpbH3=dECPEPQ@mail.gmail.com>

I have encountered an issue a couple times recently when fitting models in
lme4 that I have not seen addressed in commonly cited papers for dealing w/
boundary/singular fit issues.

Say I have a categorical variable representing a set of within-subject
contrasts, which is entered into the model as a set of effect coded
variables, e.g.

df$congruent.f <- factor(df$congruent,levels=c(1,0,-1),
                            labels=c("congruent","incongruent","none"))
contrasts(df$congruent.f) <- contr.sum(3)

which will produce two variables in the model (e.g. congruent.f1,
congruent.f2). When I fit the model w/ random intercepts and slopes for
these contrasts (along w/ other control variables), I get a boundary
(singular) fit warning.

Examining the correlations and variance components suggests that the
primary cause of the warning is in one of these contrast variables (e.g.
congruent.f2). So, would it ever be acceptable in this scenario to remove
the random effect term ONLY for congruent.f2, not the entire set of
congruent.f contrasts, where the goal is statistical inference and I do not
want the p-values/confidence intervals for congruent.f1 to be
anticonservative when it does in fact show variance across subjects?

I have to this point assumed that this would be a bad idea and tried to
simplify such models in other ways (i.e. setting correlations to zero or
removing other random effects), but this does not always work and seems a
roundabout method if you are not dealing with the primary problem.

Thanks,
Nathan

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Thu Jan 21 23:01:58 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Thu, 21 Jan 2021 17:01:58 -0500
Subject: [R-sig-ME] 
 addressing singularity in lme4 fits caused by subsets of contrasts
In-Reply-To: <CA+d67B5fWYyYAs3ke1NpGjWSGhHizEUfYJ9w1WpbH3=dECPEPQ@mail.gmail.com>
References: <CA+d67B5fWYyYAs3ke1NpGjWSGhHizEUfYJ9w1WpbH3=dECPEPQ@mail.gmail.com>
Message-ID: <4bb9b95b-d499-d2be-8e89-3666e3b8c3da@gmail.com>

   This is an interesting question ("interesting" means among other 
things "I don't know").

   If you get a variance estimate of zero for the second contrast then 
removing that term from the model should (I think) give you **exactly 
the same** model results (as an analogy: suppose you had the mean model 
y = a +b*x+c*z and for some reason got an estimate of c=0, then you said 
"can I drop z from the model?")

   More generally, in order to know whether this is OK you have to 
define what "OK" means.  Trying to avoid philosophical or subjective 
statements, you could ask whether following this process gives 'good' 
results (unbiased and/or low-error estimates and good coverage of 
whichever set of parameters you're interested in). In particular, if 
you're interested in inference on fixed effects only, then I'd say you 
can do anything to the random effects component of the model as long as 
it doesn't mess up your estimation and inference on the fixed effects.

   You could try some simulations to test your idea (note that your 
conclusions can only be for the range of parameters you've actually 
simulated: in particular Bates et al 2015 criticize the realism of the 
simulations from Barr et al 2013 "keep it maximal":

"First, the simulations implement a factorial contrast that is 
atypically large compared to what is found in natural data.  Second, and 
more importantly, the correlations in the random effects structure range 
from?0.8 to +0.8.  Such large correlation parameters are indicative of 
overparameterization.They hardly ever represent true correlations in the 
population.  As a consequence, these simulations  do  not  provide  a 
solid  foundation  for  recommendations  about  how  to  fit 
mixed-effects models to empirical data."

Bates, Douglas, Reinhold Kliegl, Shravan Vasishth, and Harald Baayen. 
?Parsimonious Mixed Models.? ArXiv:1506.04967 [Stat], June 16, 2015. 
http://arxiv.org/abs/1506.04967.


On 1/21/21 11:54 AM, Nathan Tardiff wrote:
> I have encountered an issue a couple times recently when fitting models in
> lme4 that I have not seen addressed in commonly cited papers for dealing w/
> boundary/singular fit issues.
> 
> Say I have a categorical variable representing a set of within-subject
> contrasts, which is entered into the model as a set of effect coded
> variables, e.g.
> 
> df$congruent.f <- factor(df$congruent,levels=c(1,0,-1),
>                              labels=c("congruent","incongruent","none"))
> contrasts(df$congruent.f) <- contr.sum(3)
> 
> which will produce two variables in the model (e.g. congruent.f1,
> congruent.f2). When I fit the model w/ random intercepts and slopes for
> these contrasts (along w/ other control variables), I get a boundary
> (singular) fit warning.
> 
> Examining the correlations and variance components suggests that the
> primary cause of the warning is in one of these contrast variables (e.g.
> congruent.f2). So, would it ever be acceptable in this scenario to remove
> the random effect term ONLY for congruent.f2, not the entire set of
> congruent.f contrasts, where the goal is statistical inference and I do not
> want the p-values/confidence intervals for congruent.f1 to be
> anticonservative when it does in fact show variance across subjects?
> 
> I have to this point assumed that this would be a bad idea and tried to
> simplify such models in other ways (i.e. setting correlations to zero or
> removing other random effects), but this does not always work and seems a
> roundabout method if you are not dealing with the primary problem.
> 
> Thanks,
> Nathan
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From me @end|ng |rom ph||||p@|d@y@com  Fri Jan 22 00:52:22 2021
From: me @end|ng |rom ph||||p@|d@y@com (Phillip Alday)
Date: Fri, 22 Jan 2021 00:52:22 +0100
Subject: [R-sig-ME] 
 addressing singularity in lme4 fits caused by subsets of contrasts
In-Reply-To: <4bb9b95b-d499-d2be-8e89-3666e3b8c3da@gmail.com>
References: <CA+d67B5fWYyYAs3ke1NpGjWSGhHizEUfYJ9w1WpbH3=dECPEPQ@mail.gmail.com>
 <4bb9b95b-d499-d2be-8e89-3666e3b8c3da@gmail.com>
Message-ID: <a473a171-1493-92ff-4669-f6d01280b365@phillipalday.com>

I agree with Ben here.

This is actually one of the things I'm working on in my rather limited
free time. I also suspect that it will generally give an equivalent
model BUT there are a few possible ways it might not:

1. You may have more power (and thus less variability in your estimates
and errors) because you have fewer parameters to estimate. This is
vaguely similar to some of the work in Matuscheck et al. 2017 on
controlling Type-I and complexity in mixed models. (a sort of spin-off
project of the Bates et al. Parsimonious Mixed Models)

2. Weird things happen at the boundary. One of the things that keeps
getting rediscovered is that singular fits are a strange attractor. This
is why the machinery for MCMC-based p-values in early lme4 ultimately
didn't work and this is something we've seen in MixedModels.jl in our
work on the parametric bootstrap -- bootstrapped estimates of the random
effects often look like a point mass around 0 mixed with a normal
distribution centered elsewhere. If you remove this one strange
attractor, it may allow some of the other slopes to move a bit
(especially if your correlation structure wasn't constrained to zero
previously). I expect they won't move much, but they might.


@Ben I've seen an example of this when using rePCA. Occasionally
estimates of the effective dimensionality of the RE change dramatically
just by adding or removing a single contrast and associated correlation
parameters. I wish I had had the good sense to save that example ...


Best,
Phillip

On 21/1/21 11:01 pm, Ben Bolker wrote:
> ? This is an interesting question ("interesting" means among other
> things "I don't know").
> 
> ? If you get a variance estimate of zero for the second contrast then
> removing that term from the model should (I think) give you **exactly
> the same** model results (as an analogy: suppose you had the mean model
> y = a +b*x+c*z and for some reason got an estimate of c=0, then you said
> "can I drop z from the model?")
> 
> ? More generally, in order to know whether this is OK you have to define
> what "OK" means.? Trying to avoid philosophical or subjective
> statements, you could ask whether following this process gives 'good'
> results (unbiased and/or low-error estimates and good coverage of
> whichever set of parameters you're interested in). In particular, if
> you're interested in inference on fixed effects only, then I'd say you
> can do anything to the random effects component of the model as long as
> it doesn't mess up your estimation and inference on the fixed effects.
> 
> ? You could try some simulations to test your idea (note that your
> conclusions can only be for the range of parameters you've actually
> simulated: in particular Bates et al 2015 criticize the realism of the
> simulations from Barr et al 2013 "keep it maximal":
> 
> "First, the simulations implement a factorial contrast that is
> atypically large compared to what is found in natural data.? Second, and
> more importantly, the correlations in the random effects structure range
> from?0.8 to +0.8.? Such large correlation parameters are indicative of
> overparameterization.They hardly ever represent true correlations in the
> population.? As a consequence, these simulations? do? not? provide? a
> solid? foundation? for? recommendations? about? how? to? fit
> mixed-effects models to empirical data."
> 
> Bates, Douglas, Reinhold Kliegl, Shravan Vasishth, and Harald Baayen.
> ?Parsimonious Mixed Models.? ArXiv:1506.04967 [Stat], June 16, 2015.
> http://arxiv.org/abs/1506.04967.
> 
> 
> On 1/21/21 11:54 AM, Nathan Tardiff wrote:
>> I have encountered an issue a couple times recently when fitting
>> models in
>> lme4 that I have not seen addressed in commonly cited papers for
>> dealing w/
>> boundary/singular fit issues.
>>
>> Say I have a categorical variable representing a set of within-subject
>> contrasts, which is entered into the model as a set of effect coded
>> variables, e.g.
>>
>> df$congruent.f <- factor(df$congruent,levels=c(1,0,-1),
>> ???????????????????????????? labels=c("congruent","incongruent","none"))
>> contrasts(df$congruent.f) <- contr.sum(3)
>>
>> which will produce two variables in the model (e.g. congruent.f1,
>> congruent.f2). When I fit the model w/ random intercepts and slopes for
>> these contrasts (along w/ other control variables), I get a boundary
>> (singular) fit warning.
>>
>> Examining the correlations and variance components suggests that the
>> primary cause of the warning is in one of these contrast variables (e.g.
>> congruent.f2). So, would it ever be acceptable in this scenario to remove
>> the random effect term ONLY for congruent.f2, not the entire set of
>> congruent.f contrasts, where the goal is statistical inference and I
>> do not
>> want the p-values/confidence intervals for congruent.f1 to be
>> anticonservative when it does in fact show variance across subjects?
>>
>> I have to this point assumed that this would be a bad idea and tried to
>> simplify such models in other ways (i.e. setting correlations to zero or
>> removing other random effects), but this does not always work and seems a
>> roundabout method if you are not dealing with the primary problem.
>>
>> Thanks,
>> Nathan
>>
>> ????[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From v||chuk @end|ng |rom @@er|g@@edu  Sat Jan 23 18:23:08 2021
From: v||chuk @end|ng |rom @@er|g@@edu (Vadym Ilchuk)
Date: Sat, 23 Jan 2021 19:23:08 +0200
Subject: [R-sig-ME] pgmm errors in R
Message-ID: <CADJdEasbm5=sKtLs1VT+DFa1Ejs_NX6X4soR936+FoP2FmMWnQ@mail.gmail.com>

Dear All,

I am a last-year student, currently working on my Bachelor's Thesis (so,
still learning R).

It has been a while I tried to find the solution to my problem, yet still
unsuccessfully. Thus, I decided to ask for help from people who know more
than me and potentially could suggest some solutions and ideas.

This is my main model:
[image: image.png]

Here is a dataset:
https://drive.google.com/file/d/1EDPnH2xRXZiPbUrD-sCUuIVdKUtWjojL/view?usp=sharing


So far I have created all the variables needed, and while *plm* works
perfectly, *pgmm *gives errors constantly.

This is my code (NB dataset already contains all the variables created),
furthermore, I tried to clean the needed variables from NAs, still, the
errors are present.
*******************************************************************************

#filtering dataset with NACE = A, and creating variables needed
LVData_A <- LVwin %>%
  filter(NACE == 'A') %>%
  filter(VAw > 0, FAw > 0, COGSw > 0, TURNw > 0, TFAw > 0) %>%
  mutate(ID = ID,
         Year = Year,
         va = log(VAw),
         tfa = log(TFAw),
         fa = log(FAw),
         cogs = log(COGSw),
         turn = log(TURNw),
         ta = log(TAw),
         ff1 = ((LTD + LOAN)/TAw)/median((LTD + LOAN)/TAw, na.rm = TRUE),
         ff2 = (CASHw/TAw)/median(CASHw/TAw, na.rm = TRUE),
         ff3 = (INT/dplyr::lag(LTD + LOAN))/median(INT/lag(LTD + LOAN),
na.rm = TRUE),
         ff4 = median(FAw)/SALEw,
         ff5 = TFAw/TAw)

summary(LVData_A)


##########################################################################################################################

#Estimation of the TFP by using ACF method
LV_ACF_A <-  prodest::prodestACF(LVData_A$turn, fX = LVData_A$cogs, sX =
LVData_A$tfa, pX = LVData_A$cogs, idvar = LVData_A$ID, timevar =
LVData_A$Year,
                                R = 100, cX = NULL, opt = 'DEoptim', theta0
= NULL, cluster = NULL)
summary(LV_ACF_A)

LVomegaACF_A <- prodest::omega(LV_ACF_A)
summary(LVomegaACF_A)

LVData_A$LVomegaACF_A <- prodest::omega(LV_ACF_A)

#########################################################################################################################

 #Estimation of the TFP by using WRDG method
LV_WRDG_A <-  prodest::prodestWRDG(LVData_A$turn, fX = LVData_A$cogs, sX =
LVData_A$tfa, pX = LVData_A$m, idvar = LVData_A$ID, timevar = LVData_A$Year,
                               cX = NULL)
summary(LV_WRDG_A)

LVomegaWRDG_A <- prodest::omega(LV_WRDG_A)
summary(LVomegaWRDG_A)

LVData_A$LVomegaWRDG_A <- as.xts(prodest::omega(LV_WRDG_A))

#########################################################################################################################

#Creating growth variables
LVData_A <- LVData_A %>%
  arrange(ID, Year) %>%
  group_by(ID) %>%
  mutate(domegaACF_A = LVomegaACF_A - dplyr::lag(LVomegaACF_A),
         #domegaWRDG_A = LVomegaWRDG_A - dplyr::lag(LVomegaWRDG_A),
         debt = LTD + LOAN,
         ddebt = debt - dplyr::lag(debt),
         dsales = SALEw - dplyr::lag(SALEw)) %>%
  ungroup

#Panel dataframe creation
PLVData_A <- pdata.frame(LVData_A, index = c("ID","Year"))

#GMM
z1 <- pgmm(domegaACF_A ~ plm::lag(domegaACF_A, 1) + ddebt + ff1 + log(Age)
+ ta + dsales | plm::lag(domegaACF_A, 2),
           data = PLVData_A, effect = "twoways", model = "twosteps",
transformation = "d", index = c("ID", "Year"), collapse = FALSE, lost.ts =
NULL)
summary(z1, robust = TRUE)

# | plm::lag(domegaACF_A, 2:3)
z1 <- pgmm(domegaACF_A ~ plm::lag(domegaACF_A, 1) + ddebt + ff1 + log(Age)
+ ta + dsales | plm::lag(domegaACF_A, 2:3),
           data = PLVData_A, effect = "twoways", model = "twosteps",
transformation = "d", index = c("ID", "Year"), collapse = FALSE, lost.ts =
NULL)
summary(z1, robust = TRUE)

# plm::lag(domegaACF_A, 1:2) AND plm::lag(domegaACF_A, 3)
z1 <- pgmm(domegaACF_A ~ plm::lag(domegaACF_A, 1:2) + ddebt + ff1 +
log(Age) + ta + dsales | plm::lag(domegaACF_A, 3),
           data = PLVData_A, effect = "twoways", model = "twosteps",
transformation = "d", index = c("ID", "Year"), collapse = FALSE, lost.ts =
NULL)
summary(z1, robust = TRUE)

#| plm::lag(domegaACF_A, 1:2)
z1 <- pgmm(domegaACF_A ~ ddebt + ff1 + log(Age) + ta + dsales |
plm::lag(domegaACF_A, 1:2),
           data = PLVData_A, effect = "twoways", model = "twosteps",
transformation = "d", index = c("ID", "Year"), collapse = FALSE, lost.ts =
NULL)
summary(z1, robust = TRUE)

# effect = "individual"
z1 <- pgmm(domegaACF_A ~ plm::lag(domegaACF_A, 1) + ddebt + ff1 + log(Age)
+ ta + dsales | plm::lag(domegaACF_A, 2:3),
           data = PLVData_A, effect = "individual", model = "twosteps",
transformation = "ld", index = c("ID", "Year"), collapse = FALSE, lost.ts =
NULL)
summary(z1, robust = TRUE)

#effect = "twoways", model = "onestep", transformation = "d"
z1 <- pgmm(domegaACF_A ~ plm::lag(domegaACF_A, 1) + ddebt + ff1 + log(Age)
+ ta + dsales | plm::lag(domegaACF_A, 1),
           data = PLVData_A, effect = "twoways", model = "onestep",
transformation = "d", index = c("ID", "Year"), collapse = FALSE, lost.ts =
NULL)
summary(z1, robust = TRUE)

#effect = "individual", model = "onestep", transformation = "ld"
z1 <- pgmm(domegaACF_A ~ plm::lag(domegaACF_A, 1) + ddebt + ff1 + log(Age)
+ ta + dsales | plm::lag(domegaACF_A, 1),
           data = PLVData_A, effect = "individual", model = "onestep",
transformation = "ld", index = c("ID", "Year"), collapse = FALSE, lost.ts =
NULL)
summary(z1, robust = TRUE)

#
z1 <- pgmm(domegaACF_A ~ plm::lag(domegaACF_A, 1) | plm::lag(domegaACF_A,
2:3),
           data = PLVData_A, effect = "twoways", model = "onestep",
transformation = "ld", index = c("ID", "Year"), collapse = FALSE, lost.ts =
NULL)
summary(z1, robust = TRUE)

#Check of the correlation
PLVData_A %>%
  select(domegaACF_A, ddebt, ff1, Age, ta, dsales) %>%
  cor(use = "complete.obs")

*******************************************************************************


Each GMM model specification yields different types of errors.

Thank you in advance for your devoted time.

Best,
Vadym

-------------- next part --------------
A non-text attachment was scrubbed...
Name: image.png
Type: image/png
Size: 53849 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20210123/1f95f2a6/attachment-0001.png>

From john@th@n@jone@ @end|ng |rom gm@||@com  Tue Jan 26 03:34:06 2021
From: john@th@n@jone@ @end|ng |rom gm@||@com (Johnathan Jones)
Date: Tue, 26 Jan 2021 02:34:06 +0000
Subject: [R-sig-ME] Linking a three level variable with a binary score to
 predict total score
Message-ID: <CAJB+otrUWdvYB+j=pY+xwCYqKM9BLzy2d71QkfJ174qnL0S1Tw@mail.gmail.com>

Hi all,

I am trying to analyse data from a listening perception experiment using
mixed models (suggested to me due to its ability to handle nested data).
New to mixed models, I have viewed several tutorials, but nothing quite
fits. I have a couple of things to work through, but the first is below.
I've tried numerous means of addressing the problem and have been going in
circles for longer than I'd like to admit. I'll avoid pasting the actual
data and results at this point as I expect less is more for clarity. Happy
to post more if it would help, however.



Explanation of the Problem

I have (what I'd like to be) a continuous dependent variable (DV = percent
correct of dichotomously scored items on a listening test, where 1 is
correct, 0 is incorrect) and several predictor variables. The key interest
is seeing how well listening accuracy with individual words (isolated
speech) predicts listening accuracy with sentences (connected speech).
Listening perception can be confounded by association (?Assn_status? in
Sample Data). If a word isn?t known or isn?t readily associated with the
context, it may be perceived as another word. Accurate perception is
further influenced by the listeners first language (L1). The equation would
be:

connected speech ~ isolated speech + association + L1 + 1|participant +
error

The snag is that association (categorical, three levels) is different for
each person, and I need to index the participants? individual associations
for each item with their score on that item. It is unclear to me how to do
this, though I've tried what seems an infinite number of equally futile
options. It may be that I have to toss the idea of the continuous DV and go
with a logistic regression.


Sample Data (data = perception)

Participants from three language groups listened to sentences and
transcribed what they heard. Each sentence heard could reasonably include
one of two ?target? words, as explained in the table notes under 1, 2 , and
3. The table below shows participant number (Participant), language (Lang),
item score (Score), the word that the participant associates with the
sentence (Assn), the actual word used in the audio (Key), whether the Assn
matches Key (Assn_status), overall performance on the isolated word task
(Isolated_prcnt)  and overall performance on sentence task (Cnncted_prcnt).
Assn and Key are included below for illustrative purposes to help explain
Assn_status.

*Partcpnt*

*Lang*

*Score*

*Assn*

*Key*

*Assn_status*

*Isolated_prcnt*

*Cnncted_prcnt*

1

Mandarin

1

beat

beat

same1

75

62.5

1

Mandarin

0

beat

bit

opposite2

75

62.5

1

Mandarin

1

beaten

beaten

same

75

62.5

1

Mandarin

0

beaten

bitten

opposite

75

62.5

1

Mandarin

1

meals

meals

same

75

62.5

1

Mandarin

0

meals

mills

opposite

75

62.5

1

Mandarin

1

none

risen

neither3

75

62.5

1

Mandarin

1

none

reason

neither

75

62.5

2

Mandarin

1

none

beat

neither

70

50

2

Mandarin

1

none

bit

neither

70

50

2

Mandarin

0

bitten

beaten

opposite

70

50

2

Mandarin

0

bitten

bitten

same

70

50

2

Mandarin

1

meals

meals

same

70

50

2

Mandarin

0

meals

mills

opposite

70

50

2

Mandarin

0

reason

risen

opposite

70

50

2

Mandarin

1

reason

reason

same

70

50

3

Mandarin

1

bit

beat

neither

85

75

3

Mandarin

1

bit

bit

neither

85

75

3

Mandarin

1

none

beaten

neither

85

75

3

Mandarin

1

none

bitten

neither

85

75

3

Mandarin

1

mills

meals

opposite

85

75

3

Mandarin

0

mills

mills

same

85

75

3

Mandarin

0

reason

risen

opposite

85

75

3

Mandarin

1

reason

reason

same

85

75

1The target word (key) is the same as the participant?s indicated
association with the sentence. For example, in ?The man was ____?, a
participant may associate the word *bitten* more than *beaten* to complete
the sentence. If the audio was ?The man was bitten?, the Assn_Status column
would indicate ?same?.

2The target word in the item was opposite of the word the participant
associated with the sentence. If a participant associates *bitten* with the
sentence context, ?The man was ___?, but the audio was, ?The man was
beaten?, Assn_Status would indicate ?opposite?.

3To the participant, both words have equal association to the given
context. There is no preference for one word over the other.


Attempts

Using the variables described in the Sample Data table and the nlme
package, I tried and failed with: model = lme(Cnnctd_prcnt ~ Language *
Isolated_prcnt, data = perception, random = ~ 1|Participant)
summary(model). While it ran and provided output, the resulting data
yielded different parameter estimates than the null model (LM), which
suggests failure somewhere, but I don't know where. My hope is that it will
seem obvious to someone here as is, but as noted previously, I'll happily
post the data if needed.

Related: Surprisingly (to me), the LM estimates were the same when using
either Score (a binary variable) or Cnnctd_prcnt (continuous) as the DV. It
seems R automatically aggregates the binary scores; am I accurate in
assuming this?  Would replacing Cnnctd_prcnt with Score be a suitable
workaround?


Thanks tremendously,


John Jones

	[[alternative HTML version deleted]]


From |upp @end|ng |rom uch|c@go@edu  Tue Jan 26 05:28:07 2021
From: |upp @end|ng |rom uch|c@go@edu (Stuart Luppescu)
Date: Tue, 26 Jan 2021 13:28:07 +0900
Subject: [R-sig-ME] 
 Linking a three level variable with a binary score to
 predict total score
In-Reply-To: <CAJB+otrUWdvYB+j=pY+xwCYqKM9BLzy2d71QkfJ174qnL0S1Tw@mail.gmail.com>
References: <CAJB+otrUWdvYB+j=pY+xwCYqKM9BLzy2d71QkfJ174qnL0S1Tw@mail.gmail.com>
Message-ID: <3aabb20710dde9e185aebf9ce6e81d75d3ce1e96.camel@uchicago.edu>

On Tue, 2021-01-26 at 02:34 +0000, Johnathan Jones wrote:
> I have (what I'd like to be) a continuous dependent variable (DV =
> percent correct of dichotomously scored items on a listening test,
> where 1 is correct, 0 is incorrect) and several predictor variables.
> The key interest is seeing how well listening accuracy with
> individual words (isolated speech) predicts listening accuracy with
> sentences (connected speech). Listening perception can be confounded
> by association (?Assn_status? in Sample Data). If a word isn?t known
> or isn?t readily associated with the context, it may be perceived as
> another word. Accurate perception is further influenced by the
> listeners first language (L1). The equation would be:
> 
> connected speech ~ isolated speech + association + L1 + 1|participant +
> error
> 
> The snag is that association (categorical, three levels) is different
> for each person, and I need to index the participants? individual
> associations for each item with their score on that item. It is
> unclear to me how to do this, though I've tried what seems an
> infinite number of equally futile options. It may be that I have to
> toss the idea of the continuous DV and go with a logistic regression.

I can't really comment on the model (it is outside my area of
expertise) but I really think using percent correct as an outcome
variable is not the way to go. I would analyze the individual responses
in an IRT model (I, personally, belong to the Church of Rasch) and then
take the person measures from that analysis and analyze them in your
lme model or whatever. 

I think you can also do something similar in lme or lmer by using the
individual item responses (0, 1) as the outcome with a logit link, and
include an item indicator for each response, nest them all within
individuals, add your other predictors, and model them that way.

If you don't want to do IRT or the other way I suggest, at least
convert the percent correct to log odds and use that as the outcome. 

-- 
Stuart Luppescu
Chief Psychometrician (ret.)
UChicago Consortium on School Research
http://consortium.uchicago.edu


From juho@kr|@t|@n@ruohonen @end|ng |rom gm@||@com  Sat Jan 30 15:23:20 2021
From: juho@kr|@t|@n@ruohonen @end|ng |rom gm@||@com (Juho Kristian Ruohonen)
Date: Sat, 30 Jan 2021 16:23:20 +0200
Subject: [R-sig-ME] Log likelihood of a glmer() binomial model .
In-Reply-To: <b41fc0d8-a841-fc55-985d-3457b703e8ce@gmail.com>
References: <306f44cf-a1f9-25d4-4f9f-3dd581698d23@auckland.ac.nz>
 <CABghstTKrwA9x5Xmk=ECwVzHawBp6OnRQCsymKA9DSpZPuATeg@mail.gmail.com>
 <33fd981f-d9db-b824-1c2b-40050b72993e@auckland.ac.nz>
 <CAG_dBVdTdwiSn=9SzR7ewWAqXdgy8sobxRYKE8xd4fJNeuCRJQ@mail.gmail.com>
 <b41fc0d8-a841-fc55-985d-3457b703e8ce@gmail.com>
Message-ID: <CAG_dBVdE34NXstq9shtyDvHOSS_84=UkduSOPTJ457Kbe6kyPA@mail.gmail.com>

Sorry to revive the thread after 21 months, but the topic has just become
highly relevant. My question concerns the following remark by Ben:

As far as what predict() does: depending on the value of re.form, it
> either gives a population-level prediction (R=0) or a conditional
> prediction (R set to its conditional mode).  You might be looking for
> *marginal* predictions (which Rizopoulous's GLMMadaptive package can do
> ...)
>

Does "marginal predictions" here mean predictions based exclusively on the
"population-averaged" fixed-effect estimates that are equivalent to ones
calculated by *gee()* from the *gee* library and *geeglm()* from the *geepack
*library? Or does it mean predictions calculated using the GLMM estimates
of the fixed effects and then averaged with respect to the estimated
random-effects distribution? If it means the former, aren't those
predictions easily obtainable through a standard GLM that ignores the
clustering? If it means the latter, could someone please point out how
exactly to calculate such marginal predictions using GLMMadaptive? I've
been trying to figure out how to manually calculate the marginal (latter
sense) LL for binomial GLMMs, with no success so far...

Best,

J

la 20. huhtik. 2019 klo 17.51 Ben Bolker (bbolker at gmail.com) kirjoitti:

>
>   I agree with Juho that there's a typo -- would be something like.
>
>  sum((y==1)*log(pred_prob) + (y==0)*log(1-pred_prob))
>
>   As far as what predict() does: depending on the value of re.form, it
> either gives a population-level prediction (R=0) or a conditional
> prediction (R set to its conditional mode).  You might be looking for
> *marginal* predictions (which Rizopoulous's GLMMadaptive package can do
> ...)
>
>
> On 2019-04-20 3:42 a.m., Juho Kristian Ruohonen wrote:
> > Rolf: Forgive my ignorance, but isn't the relevant log-likelihood here
> > the log-likelihood of the observed responses in the validation set given
> > the model-predicted probabilities? I.e. sum(dbinom(VS$y, size = VS$n,
> > prob = predict(fit, newdata = VS, type = "response"), log = TRUE))? Even
> > this would be somewhat off because dbinom() isn't aware of the
> > random-effects integral business. But it looks to me like your current
> > call is calculating the log-sum of the predicted probabilities of y = 1
> > in the validation set, not the loglikelihood of the observed responses
> > in the validation set.
> >
> > la 20. huhtik. 2019 klo 8.51 Rolf Turner (r.turner at auckland.ac.nz
> > <mailto:r.turner at auckland.ac.nz>) kirjoitti:
> >
> >
> >     On 20/04/19 12:44 PM, Ben Bolker wrote:
> >
> >     >    This seems wrong.
> >
> >     Yeah, that figures.
> >
> >     > The GLMM log-likelihood includes an integral over
> >     > the distribution of the random effects.
> >
> >     I was aware of this.  I guess what I was na?vely expecting was that
> >     predict.merMod() would handle this.  I.e. that this predict method
> >     (with type = "response") would return, for each observed y_i in the
> >     (new) data set
> >
> >        Pr(Y = y_i) = \int_0 Pr(Y = y_i | R = r) f(r) dr
> >
> >     where R is the vector of random effects and f(r) is its probability
> >     density function (multivariate normal, with mean 0 and some
> covariance
> >     matrix, which has been estimated in the fitting process.
> >
> >     I guess that this is *not* what predict.merMod() returns --- but I
> >     don't
> >     understand why not.  It seems to me that this is what it "should"
> >     return.
> >
> >     I'm probably misunderstanding something, possibly simple, possibly
> >     subtle.
> >
> >     Apropos of nothing much, what *does* predict.merMod() return?
> >     Maybe Pr(Y = y_i | R = 0) ???
> >
> >     <SNIP>
> >     >   Here is an **inefficient** method for computing the likelihood
> >     >
> >     >     coefs <- unlist(getME(fit,c("theta","beta"))
> >     >     newdev <- update(fit, data=VS, devFunOnly=TRUE)
> >     >     newdev(coefs)
> >     >
> >     > This is slow because it has to reconstruct all of the
> random-effects
> >     > matrices, do permutations to reorder the relevant matrices to be as
> >     > sparse as possible, etc. etc.
> >
> >     Thanks for this.  I'll give it a go.  I think that the slowness may
> not
> >     be an overwhelming drawback.  Anyhow I shall try to test it out.
> >
> >     Thanks again.
> >
> >     cheers,
> >
> >     Rolf
> >
> >     --
> >     Honorary Research Fellow
> >     Department of Statistics
> >     University of Auckland
> >     Phone: +64-9-373-7599 ext. 88276
> >
> >     _______________________________________________
> >     R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org> mailing list
> >     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Sat Jan 30 21:54:59 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Sat, 30 Jan 2021 15:54:59 -0500
Subject: [R-sig-ME] Log likelihood of a glmer() binomial model .
In-Reply-To: <CAG_dBVdE34NXstq9shtyDvHOSS_84=UkduSOPTJ457Kbe6kyPA@mail.gmail.com>
References: <306f44cf-a1f9-25d4-4f9f-3dd581698d23@auckland.ac.nz>
 <CABghstTKrwA9x5Xmk=ECwVzHawBp6OnRQCsymKA9DSpZPuATeg@mail.gmail.com>
 <33fd981f-d9db-b824-1c2b-40050b72993e@auckland.ac.nz>
 <CAG_dBVdTdwiSn=9SzR7ewWAqXdgy8sobxRYKE8xd4fJNeuCRJQ@mail.gmail.com>
 <b41fc0d8-a841-fc55-985d-3457b703e8ce@gmail.com>
 <CAG_dBVdE34NXstq9shtyDvHOSS_84=UkduSOPTJ457Kbe6kyPA@mail.gmail.com>
Message-ID: <0826b45e-01fb-df3c-c11f-272c6e5b7910@gmail.com>

   "marginal" is unfortunately a word that has different meanings in 
different contexts, I'm still trying to sort it out in my own mind.

   GLMMadaptive doesn't do marginal _predictions_ but it does do 
marginal _coefficients_.

   I put up some example workings at

http://bbolker.github.io/mixedmodels-misc/notes/marginal_ex.html?de49a7770f7

  (the hash at the end may be unnecessary for you).

  If you average across simulations with newdata= set that should give 
you marginal predictions ...

On 1/30/21 9:23 AM, Juho Kristian Ruohonen wrote:
> Sorry to revive the thread after 21 months, but the topic has just 
> become highly relevant. My question concerns the following remark by Ben:
> 
>     As far as what predict() does: depending on the value of re.form, it
>     either gives a population-level prediction (R=0) or a conditional
>     prediction (R set to its conditional mode).? You might be looking for
>     *marginal* predictions (which Rizopoulous's GLMMadaptive package can
>     do ...)
> 
> 
> Does "marginal predictions" here mean predictions based exclusively on 
> the "population-averaged" fixed-effect estimates that are equivalent to 
> onescalculated by *gee()* from the /gee/ library and *geeglm()* from the 
> /geepack /library? Or does it mean predictions calculated using the GLMM 
> estimates of the fixed effects and then averaged with respect to the 
> estimated random-effects distribution? If it means the former, aren't 
> those predictions easily obtainable through a standard GLM that ignores 
> the clustering? If it means the latter, could someone please point out 
> how exactly to calculate such marginal predictions using GLMMadaptive? 
> I've been trying to figure out how to manually calculate the marginal 
> (latter sense) LL for binomial GLMMs, with no success so far...
> 
> Best,
> 
> J
> 
> la 20. huhtik. 2019 klo 17.51 Ben Bolker (bbolker at gmail.com 
> <mailto:bbolker at gmail.com>) kirjoitti:
> 
> 
>      ? I agree with Juho that there's a typo -- would be something like.
> 
>      ?sum((y==1)*log(pred_prob) + (y==0)*log(1-pred_prob))
> 
>      ? As far as what predict() does: depending on the value of re.form, it
>     either gives a population-level prediction (R=0) or a conditional
>     prediction (R set to its conditional mode).? You might be looking for
>     *marginal* predictions (which Rizopoulous's GLMMadaptive package can
>     do ...)
> 
> 
>     On 2019-04-20 3:42 a.m., Juho Kristian Ruohonen wrote:
>      > Rolf: Forgive my ignorance, but isn't the relevant log-likelihood
>     here
>      > the log-likelihood of the observed responses in the validation
>     set given
>      > the model-predicted probabilities? I.e. sum(dbinom(VS$y, size = VS$n,
>      > prob = predict(fit, newdata = VS, type = "response"), log =
>     TRUE))? Even
>      > this would be somewhat off because dbinom() isn't aware of the
>      > random-effects integral business. But it looks to me like your
>     current
>      > call is calculating the log-sum of the predicted probabilities of
>     y = 1
>      > in the validation set, not the loglikelihood of the observed
>     responses
>      > in the validation set.
>      >
>      > la 20. huhtik. 2019 klo 8.51 Rolf Turner (r.turner at auckland.ac.nz
>     <mailto:r.turner at auckland.ac.nz>
>      > <mailto:r.turner at auckland.ac.nz
>     <mailto:r.turner at auckland.ac.nz>>) kirjoitti:
>      >
>      >
>      >? ? ?On 20/04/19 12:44 PM, Ben Bolker wrote:
>      >
>      >? ? ?>? ? This seems wrong.
>      >
>      >? ? ?Yeah, that figures.
>      >
>      >? ? ?> The GLMM log-likelihood includes an integral over
>      >? ? ?> the distribution of the random effects.
>      >
>      >? ? ?I was aware of this.? I guess what I was na?vely expecting
>     was that
>      >? ? ?predict.merMod() would handle this.? I.e. that this predict
>     method
>      >? ? ?(with type = "response") would return, for each observed y_i
>     in the
>      >? ? ?(new) data set
>      >
>      >? ? ?? ?Pr(Y = y_i) = \int_0 Pr(Y = y_i | R = r) f(r) dr
>      >
>      >? ? ?where R is the vector of random effects and f(r) is its
>     probability
>      >? ? ?density function (multivariate normal, with mean 0 and some
>     covariance
>      >? ? ?matrix, which has been estimated in the fitting process.
>      >
>      >? ? ?I guess that this is *not* what predict.merMod() returns ---
>     but I
>      >? ? ?don't
>      >? ? ?understand why not.? It seems to me that this is what it "should"
>      >? ? ?return.
>      >
>      >? ? ?I'm probably misunderstanding something, possibly simple,
>     possibly
>      >? ? ?subtle.
>      >
>      >? ? ?Apropos of nothing much, what *does* predict.merMod() return?
>      >? ? ?Maybe Pr(Y = y_i | R = 0) ???
>      >
>      >? ? ?<SNIP>
>      >? ? ?>? ?Here is an **inefficient** method for computing the
>     likelihood
>      >? ? ?>
>      >? ? ?>? ? ?coefs <- unlist(getME(fit,c("theta","beta"))
>      >? ? ?>? ? ?newdev <- update(fit, data=VS, devFunOnly=TRUE)
>      >? ? ?>? ? ?newdev(coefs)
>      >? ? ?>
>      >? ? ?> This is slow because it has to reconstruct all of the
>     random-effects
>      >? ? ?> matrices, do permutations to reorder the relevant matrices
>     to be as
>      >? ? ?> sparse as possible, etc. etc.
>      >
>      >? ? ?Thanks for this.? I'll give it a go.? I think that the
>     slowness may not
>      >? ? ?be an overwhelming drawback.? Anyhow I shall try to test it out.
>      >
>      >? ? ?Thanks again.
>      >
>      >? ? ?cheers,
>      >
>      >? ? ?Rolf
>      >
>      >? ? ?--
>      >? ? ?Honorary Research Fellow
>      >? ? ?Department of Statistics
>      >? ? ?University of Auckland
>      >? ? ?Phone: +64-9-373-7599 ext. 88276
>      >
>      >? ? ?_______________________________________________
>      > R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>
>      >? ? ?<mailto:R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org>> mailing list
>      > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>      >
>


From juho@kr|@t|@n@ruohonen @end|ng |rom gm@||@com  Sun Jan 31 09:10:37 2021
From: juho@kr|@t|@n@ruohonen @end|ng |rom gm@||@com (Juho Kristian Ruohonen)
Date: Sun, 31 Jan 2021 10:10:37 +0200
Subject: [R-sig-ME] Log likelihood of a glmer() binomial model .
In-Reply-To: <0826b45e-01fb-df3c-c11f-272c6e5b7910@gmail.com>
References: <306f44cf-a1f9-25d4-4f9f-3dd581698d23@auckland.ac.nz>
 <CABghstTKrwA9x5Xmk=ECwVzHawBp6OnRQCsymKA9DSpZPuATeg@mail.gmail.com>
 <33fd981f-d9db-b824-1c2b-40050b72993e@auckland.ac.nz>
 <CAG_dBVdTdwiSn=9SzR7ewWAqXdgy8sobxRYKE8xd4fJNeuCRJQ@mail.gmail.com>
 <b41fc0d8-a841-fc55-985d-3457b703e8ce@gmail.com>
 <CAG_dBVdE34NXstq9shtyDvHOSS_84=UkduSOPTJ457Kbe6kyPA@mail.gmail.com>
 <0826b45e-01fb-df3c-c11f-272c6e5b7910@gmail.com>
Message-ID: <CAG_dBVciU4VWKEYtQ1rnx_ZdR3S_Ugp-qdKXDqPu5XT8QUP_tg@mail.gmail.com>

Dear list/Ben,

GLMMadaptive doesn't do marginal _predictions_ but it does do
> marginal _coefficients_.
>

Thanks for clearing that up!


> If you average across simulations with newdata= set that should give
> you marginal predictions ...
>

With *newdata *set to what? I assume I'd have to use the original dataset
while somehow emulating the estimated RE distribution. However, I can't
seem to make anything work. A simple example with a simple dataset:


>
> *(cluster <- rep(LETTERS[1:8], each = 20))(x <- rep(rep(c(0,1), each =
> 10), times = 8))(y <- as.vector(sapply(2:9, function(x) c(rep(c(1,0), c(x,
> 10-x)) ,rep(c(1,0), c(x-1, 10-(x-1)))) )))*
> *glmm <- glmer(y ~ (1|cluster) + x, family = binomial, nAGQ = 10)*
> *deviance(glmm) *# "Conditional" deviance obtained by plugging in the
> BLUPs.
>
> [1] 185.4821
>
> *-2*logLik(glmm) *# "Marginal" deviance from averaging the fitted values
> w.r.t the estimated N(0, ?) distribution of the REs.
>
> 'log Lik.' 203.891 (df=3)
>
>
What I'm trying to learn is how to calculate or, failing that, simulate
this "marginal" deviance. My first impulse is to simply hand-calculate a
deviance from fitted values with all RE's set to their mean of 0. Given
that the assumed RE distribution is normal and hence symmetric, my
intuition is that the result should equal the result from integrating over
the estimated RE distribution. But that fails to happen:

*-2*sum(dbinom(y, size = 1, prob = predict(glmm, re.form = NA,   type =
> "response"), log = T))*
>
> [1] 220.2704
>
>
So my next avenue is to do as Ben seems to suggest, i.e. use the means of
simulated "marginal" responses from the model as fitted values. Indeed,
*simulate.merMod()* with *use.u = FALSE* should be exactly what we want,
given that its documentation says the following:

use.u
>
> (logical) if TRUE, generate a simulation conditional on the current
> random-effects estimates; if FALSE generate new Normally distributed
> random-effects values.
>

But alas:

*-2*sum(dbinom(y, 1, prob = rowMeans(simulate(glmm, nsim = 1e4, seed =
> 2021, use.u = FALSE)), log = T))*
>
> [1] 220.3949
>
>
The resulting deviance is off no matter what random seed I set. As a
sidenote, it seems to equal the deviance obtained by setting all random
effects to 0, just as my unreliable intuition suggested. But it's the wrong
result nonetheless.

Hence I'm at my wits' end. How does one calculate or simulate the marginal
deviance of a binary GLMM?

Best,

J

la 30. tammik. 2021 klo 22.55 Ben Bolker (bbolker at gmail.com) kirjoitti:

>    "marginal" is unfortunately a word that has different meanings in
> different contexts, I'm still trying to sort it out in my own mind.
>
>    GLMMadaptive doesn't do marginal _predictions_ but it does do
> marginal _coefficients_.
>
>    I put up some example workings at
>
>
> http://bbolker.github.io/mixedmodels-misc/notes/marginal_ex.html?de49a7770f7
>
>   (the hash at the end may be unnecessary for you).
>
>   If you average across simulations with newdata= set that should give
> you marginal predictions ...
>
> On 1/30/21 9:23 AM, Juho Kristian Ruohonen wrote:
> > Sorry to revive the thread after 21 months, but the topic has just
> > become highly relevant. My question concerns the following remark by Ben:
> >
> >     As far as what predict() does: depending on the value of re.form, it
> >     either gives a population-level prediction (R=0) or a conditional
> >     prediction (R set to its conditional mode).  You might be looking for
> >     *marginal* predictions (which Rizopoulous's GLMMadaptive package can
> >     do ...)
> >
> >
> > Does "marginal predictions" here mean predictions based exclusively on
> > the "population-averaged" fixed-effect estimates that are equivalent to
> > onescalculated by *gee()* from the /gee/ library and *geeglm()* from the
> > /geepack /library? Or does it mean predictions calculated using the GLMM
> > estimates of the fixed effects and then averaged with respect to the
> > estimated random-effects distribution? If it means the former, aren't
> > those predictions easily obtainable through a standard GLM that ignores
> > the clustering? If it means the latter, could someone please point out
> > how exactly to calculate such marginal predictions using GLMMadaptive?
> > I've been trying to figure out how to manually calculate the marginal
> > (latter sense) LL for binomial GLMMs, with no success so far...
> >
> > Best,
> >
> > J
> >
> > la 20. huhtik. 2019 klo 17.51 Ben Bolker (bbolker at gmail.com
> > <mailto:bbolker at gmail.com>) kirjoitti:
> >
> >
> >        I agree with Juho that there's a typo -- would be something like.
> >
> >       sum((y==1)*log(pred_prob) + (y==0)*log(1-pred_prob))
> >
> >        As far as what predict() does: depending on the value of re.form,
> it
> >     either gives a population-level prediction (R=0) or a conditional
> >     prediction (R set to its conditional mode).  You might be looking for
> >     *marginal* predictions (which Rizopoulous's GLMMadaptive package can
> >     do ...)
> >
> >
> >     On 2019-04-20 3:42 a.m., Juho Kristian Ruohonen wrote:
> >      > Rolf: Forgive my ignorance, but isn't the relevant log-likelihood
> >     here
> >      > the log-likelihood of the observed responses in the validation
> >     set given
> >      > the model-predicted probabilities? I.e. sum(dbinom(VS$y, size =
> VS$n,
> >      > prob = predict(fit, newdata = VS, type = "response"), log =
> >     TRUE))? Even
> >      > this would be somewhat off because dbinom() isn't aware of the
> >      > random-effects integral business. But it looks to me like your
> >     current
> >      > call is calculating the log-sum of the predicted probabilities of
> >     y = 1
> >      > in the validation set, not the loglikelihood of the observed
> >     responses
> >      > in the validation set.
> >      >
> >      > la 20. huhtik. 2019 klo 8.51 Rolf Turner (r.turner at auckland.ac.nz
> >     <mailto:r.turner at auckland.ac.nz>
> >      > <mailto:r.turner at auckland.ac.nz
> >     <mailto:r.turner at auckland.ac.nz>>) kirjoitti:
> >      >
> >      >
> >      >     On 20/04/19 12:44 PM, Ben Bolker wrote:
> >      >
> >      >     >    This seems wrong.
> >      >
> >      >     Yeah, that figures.
> >      >
> >      >     > The GLMM log-likelihood includes an integral over
> >      >     > the distribution of the random effects.
> >      >
> >      >     I was aware of this.  I guess what I was na?vely expecting
> >     was that
> >      >     predict.merMod() would handle this.  I.e. that this predict
> >     method
> >      >     (with type = "response") would return, for each observed y_i
> >     in the
> >      >     (new) data set
> >      >
> >      >        Pr(Y = y_i) = \int_0 Pr(Y = y_i | R = r) f(r) dr
> >      >
> >      >     where R is the vector of random effects and f(r) is its
> >     probability
> >      >     density function (multivariate normal, with mean 0 and some
> >     covariance
> >      >     matrix, which has been estimated in the fitting process.
> >      >
> >      >     I guess that this is *not* what predict.merMod() returns ---
> >     but I
> >      >     don't
> >      >     understand why not.  It seems to me that this is what it
> "should"
> >      >     return.
> >      >
> >      >     I'm probably misunderstanding something, possibly simple,
> >     possibly
> >      >     subtle.
> >      >
> >      >     Apropos of nothing much, what *does* predict.merMod() return?
> >      >     Maybe Pr(Y = y_i | R = 0) ???
> >      >
> >      >     <SNIP>
> >      >     >   Here is an **inefficient** method for computing the
> >     likelihood
> >      >     >
> >      >     >     coefs <- unlist(getME(fit,c("theta","beta"))
> >      >     >     newdev <- update(fit, data=VS, devFunOnly=TRUE)
> >      >     >     newdev(coefs)
> >      >     >
> >      >     > This is slow because it has to reconstruct all of the
> >     random-effects
> >      >     > matrices, do permutations to reorder the relevant matrices
> >     to be as
> >      >     > sparse as possible, etc. etc.
> >      >
> >      >     Thanks for this.  I'll give it a go.  I think that the
> >     slowness may not
> >      >     be an overwhelming drawback.  Anyhow I shall try to test it
> out.
> >      >
> >      >     Thanks again.
> >      >
> >      >     cheers,
> >      >
> >      >     Rolf
> >      >
> >      >     --
> >      >     Honorary Research Fellow
> >      >     Department of Statistics
> >      >     University of Auckland
> >      >     Phone: +64-9-373-7599 ext. 88276
> >      >
> >      >     _______________________________________________
> >      > R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>
> >      >     <mailto:R-sig-mixed-models at r-project.org
> >     <mailto:R-sig-mixed-models at r-project.org>> mailing list
> >      > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
> >      >
> >
>

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Mon Feb  1 20:54:11 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Mon, 1 Feb 2021 14:54:11 -0500
Subject: [R-sig-ME] PS, slight postponement?
Message-ID: <e75e3fa0-1008-b691-1141-d658ddac52dc@gmail.com>


  I'm chairing a master's defence that starts at 3:30, can we postpone 
by 15-30 mins? (I can update you with better estimates toward the end of 
the defence ...)

   thanks/sorry
    Ben


From @|m@h@rme| @end|ng |rom gm@||@com  Tue Feb  2 04:55:06 2021
From: @|m@h@rme| @end|ng |rom gm@||@com (Simon Harmel)
Date: Mon, 1 Feb 2021 21:55:06 -0600
Subject: [R-sig-ME] equivalent of lme4::rePCA() for lme models
Message-ID: <CACgv6yUcNWq2Ej9Kq2Z8WEPQ2JqgdYBndQ7wgBpnEy0m3+bhTw@mail.gmail.com>

Dear All,

I was wondering if there is any `lme4::rePCA()` equivalent for
`nlme::lme()` models (a reproducible example is below)?

--Thanks, Simon

library(nlme)

dat <- read.csv('https://raw.githubusercontent.com/hkil/m/master/mv.l.csv')

m22 <- lme(value ~0 + name, random = ~0 + name| Student, data = dat,
          correlation = corSymm(), weights = varIdent(form = ~1|name))

	[[alternative HTML version deleted]]


From d@r|zopou|o@ @end|ng |rom er@@mu@mc@n|  Tue Feb  2 08:31:08 2021
From: d@r|zopou|o@ @end|ng |rom er@@mu@mc@n| (D. Rizopoulos)
Date: Tue, 2 Feb 2021 07:31:08 +0000
Subject: [R-sig-ME] Log likelihood of a glmer() binomial model .
In-Reply-To: <CAG_dBVddKN0ZkHRjUrAF70ZTNDKH4aiVrnYyWec4LjYqyXc1fA@mail.gmail.com>
References: <306f44cf-a1f9-25d4-4f9f-3dd581698d23@auckland.ac.nz>
 <CABghstTKrwA9x5Xmk=ECwVzHawBp6OnRQCsymKA9DSpZPuATeg@mail.gmail.com>
 <33fd981f-d9db-b824-1c2b-40050b72993e@auckland.ac.nz>
 <CAG_dBVdTdwiSn=9SzR7ewWAqXdgy8sobxRYKE8xd4fJNeuCRJQ@mail.gmail.com>
 <b41fc0d8-a841-fc55-985d-3457b703e8ce@gmail.com>
 <CAG_dBVdE34NXstq9shtyDvHOSS_84=UkduSOPTJ457Kbe6kyPA@mail.gmail.com>
 <0826b45e-01fb-df3c-c11f-272c6e5b7910@gmail.com>
 <CAG_dBVciU4VWKEYtQ1rnx_ZdR3S_Ugp-qdKXDqPu5XT8QUP_tg@mail.gmail.com>
 <AM8PR04MB78438E75CA3B91A6F9FE1B18E8B79@AM8PR04MB7843.eurprd04.prod.outlook.com>
 <CAG_dBVddKN0ZkHRjUrAF70ZTNDKH4aiVrnYyWec4LjYqyXc1fA@mail.gmail.com>
Message-ID: <DBBPR04MB7850081C436D24C983366777E8B59@DBBPR04MB7850.eurprd04.prod.outlook.com>

Dear Juho,

The log-likelihood function in GLMMs does not have a closed-form. For example, see slides 345-347 in my notes. I.e., when we combine a Binomial probability mass function (pmf) for the response given the random effects, with the normal probability density function for the random effects, we do not get back a Binomial pmf.

Hence, AFAIK you cannot use dbinom() to calculate the marginal deviance in a mixed-effects logistic regression.

You could calculate the ?deviance? from the first term in slide 345, but this doesn?t correspond to a log-likelihood, to my view (i.e., the log-likelihood is typically calculated based on observed data alone).

Best,
Dimitris


From: Juho Kristian Ruohonen <juho.kristian.ruohonen at gmail.com>
Sent: Tuesday, February 2, 2021 8:13 AM
To: D. Rizopoulos <d.rizopoulos at erasmusmc.nl>
Cc: Ben Bolker <bbolker at gmail.com>; R-mixed models mailing list <r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] Log likelihood of a glmer() binomial model .

Dear Dimitris/List,

Slide 360 in Dimitris' teaching materials<https://eur01.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.drizopoulos.com%2Fcourses%2FEMC%2FCE08.pdf&data=04%7C01%7Cd.rizopoulos%40erasmusmc.nl%7Cd2d097e45e61476cd4fd08d8c749f2f8%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C0%7C637478467710678229%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&sdata=8SrRl9g%2FkefFyyERBIkVL%2F1T3Li7oyCqgRbKdonrarM%3D&reserved=0> appears to detail how to compute marginal LL, yet my attempts to manually reproduce the marginal LL/deviance reported by any GLMM software continue to fail.

The code below uses Dimitris' dataset with Ben's software. The software choice is because with Ben's software I can at least replicate the conditional deviance even though I cannot replicate the marginal deviance, as shown below:


data("pbc2", package = "JM")



pbc2$serCholD <- as.numeric(pbc2$serChol > 210)



lme4mod <- glmer(serCholD ~ (1|id) + year*drug + I(age-50)*sex, family = binomial, data = pbc2, nAGQ = 15)

deviance(lme4mod)

[1] 351.5973

-2*sum(dbinom(lme4mod at resp$y, size = 1, prob = predict(lme4mod, re.form = NULL, type = "response"), log = T))

[1] 351.5973

But I cannot replicate the marginal deviance, which is evidently not the same as the "mean-subject" deviance based on only the fixed effects:


-2*logLik(lme4mod)

'log Lik.' 702.6521 (df=8)

-2*sum(dbinom(lme4mod at resp$y, size = 1, prob = predict(lme4mod, re.form = NA, type = "response"), log = T))

[1] 1233.415

So, let's try calculating the marginal deviance from marginal probabilities created using the procedure detailed by Dimitris' Slide 360:


marginalFitted <- plogis( # On the probability scale,

  sapply(rownames(lme4mod at frame), function(i) # for each row of the dataset,

    # the "marginal" prediction is the average of 10,000 "mean-subject" predictions of which each has been augmented by a quantity randomly generated from the estimated N(0, lme4mod at theta) distribution:

    mean(

      predict(lme4mod, newdata = pbc2[i,], re.form = NA) + rnorm(10000, sd = lme4mod at theta)

      )))

marginalDeviance <- -2*sum(dbinom(lme4mod at resp$y, size = 1, prob = marginalFitted, log = T))

But the resulting quantity spectacularly fails to match the marginal likelihood reported by Ben's software:


-2*logLik(lme4mod)

'log Lik.' 702.6521 (df=8)

marginalDeviance

[1] 1232.663

Hence, I remain at my wits' end.

Best,

J

su 31. tammik. 2021 klo 11.57 D. Rizopoulos (d.rizopoulos at erasmusmc.nl<mailto:d.rizopoulos at erasmusmc.nl>) kirjoitti:
If I may add to this, GLMMadaptive does produce marginal predictions, i.e., predictions based on the marginal coefficients; for example, see below. These predictions will have the same interpretation as the one you would get from a GEE approach. You may find more information on this also in my slide (Chapter 5): http://www.drizopoulos.com/courses/EMC/CE08.pdf<https://eur01.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.drizopoulos.com%2Fcourses%2FEMC%2FCE08.pdf&data=04%7C01%7Cd.rizopoulos%40erasmusmc.nl%7Cd2d097e45e61476cd4fd08d8c749f2f8%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C0%7C637478467710678229%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&sdata=8SrRl9g%2FkefFyyERBIkVL%2F1T3Li7oyCqgRbKdonrarM%3D&reserved=0>

Also, a small comment on Ben's code: GLMMadaptive does not use a Monte Carlo simulation for calculating the marginal coefficients - this is in closed-form. The Monte Carlo simulation is used for calculating the standard errors of the marginalized coefficients.

Best,
Dimitris


library("GLMMadaptive")
library("lattice")
data("pbc2", package = "JM")

pbc2$serCholD <- as.numeric(pbc2$serChol > 210)

fm_s52_pbc <- mixed_model(fixed = serCholD ~ year * drug + I(age - 50) * sex,
                          random = ~ 1 | id,
                          family = binomial(), data = pbc2, nAGQ = 15)

summary(fm_s52_pbc)

# the data frame that contains the combination of values to
# create the plot
newDF <- with(pbc2, expand.grid(
    year = seq(0, 12, length.out = 15),
    age = 49,
    drug = levels(drug),
    sex = levels(sex)
))

# log odds for average/median subject
# note: you need to use the effectPlotData() function
# from the GLMMadaptive package (i.e., in case of problems use
# 'GLMMadaptive::effectPlotData')
xyplot(pred + low + upp ~ year | sex * drug,
       data = effectPlotData(fm_s52_pbc, newDF),
       type = "l", lty = c(1, 2, 2), col = c(2, 1, 1), lwd = 2,
       xlab = "Follow-up time (years)", ylab = "Conditional Log Odds")

# marginal probabilities and conditional probabilities corresponding to
# the average/median individual (i.e., the one with random effects value equal to zero)
plot_data_marg <- effectPlotData(fm_s52_pbc, newDF, marginal = TRUE)
plot_data_marg$pred0 <- effectPlotData(fm_s52_pbc, newDF)$pred

key <- simpleKey(c("marginal probabilities", "probabilities average patient"),
                 points = FALSE, lines = TRUE)
key$lines$col <- c("red", "blue")
key$lines$lwd <- c(2, 2)
key$lines$lty <- c(1, 1)
expit <- function (x) exp(x) / (1 + exp(x))
xyplot(expit(pred) + expit(pred0) + expit(low) + expit(upp) ~ year | sex * drug,
       data = plot_data_marg, key = key,
       type = "l", lty = c(1, 1, 2, 2), lwd = 2,
       col = c("red", "blue", "black", "black"),
       xlab = "Follow-up time (years)", ylab = "Probabilities")




-----Original Message-----
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org<mailto:r-sig-mixed-models-bounces at r-project.org>> On Behalf Of Juho Kristian Ruohonen
Sent: Sunday, January 31, 2021 9:11 AM
To: Ben Bolker <bbolker at gmail.com<mailto:bbolker at gmail.com>>
Cc: R-mixed models mailing list <r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>>
Subject: Re: [R-sig-ME] Log likelihood of a glmer() binomial model .

Dear list/Ben,

GLMMadaptive doesn't do marginal _predictions_ but it does do
> marginal _coefficients_.
>

Thanks for clearing that up!


> If you average across simulations with newdata= set that should give
> you marginal predictions ...
>

With *newdata *set to what? I assume I'd have to use the original dataset while somehow emulating the estimated RE distribution. However, I can't seem to make anything work. A simple example with a simple dataset:


>
> *(cluster <- rep(LETTERS[1:8], each = 20))(x <- rep(rep(c(0,1), each =
> 10), times = 8))(y <- as.vector(sapply(2:9, function(x) c(rep(c(1,0),
> c(x,
> 10-x)) ,rep(c(1,0), c(x-1, 10-(x-1)))) )))* *glmm <- glmer(y ~
> (1|cluster) + x, family = binomial, nAGQ = 10)*
> *deviance(glmm) *# "Conditional" deviance obtained by plugging in the
> BLUPs.
>
> [1] 185.4821
>
> *-2*logLik(glmm) *# "Marginal" deviance from averaging the fitted
> values w.r.t the estimated N(0, ?) distribution of the REs.
>
> 'log Lik.' 203.891 (df=3)
>
>
What I'm trying to learn is how to calculate or, failing that, simulate this "marginal" deviance. My first impulse is to simply hand-calculate a deviance from fitted values with all RE's set to their mean of 0. Given that the assumed RE distribution is normal and hence symmetric, my intuition is that the result should equal the result from integrating over the estimated RE distribution. But that fails to happen:

*-2*sum(dbinom(y, size = 1, prob = predict(glmm, re.form = NA,   type =
> "response"), log = T))*
>
> [1] 220.2704
>
>
So my next avenue is to do as Ben seems to suggest, i.e. use the means of simulated "marginal" responses from the model as fitted values. Indeed,
*simulate.merMod()* with *use.u = FALSE* should be exactly what we want, given that its documentation says the following:

use.u
>
> (logical) if TRUE, generate a simulation conditional on the current
> random-effects estimates; if FALSE generate new Normally distributed
> random-effects values.
>

But alas:

*-2*sum(dbinom(y, 1, prob = rowMeans(simulate(glmm, nsim = 1e4, seed =
> 2021, use.u = FALSE)), log = T))*
>
> [1] 220.3949
>
>
The resulting deviance is off no matter what random seed I set. As a sidenote, it seems to equal the deviance obtained by setting all random effects to 0, just as my unreliable intuition suggested. But it's the wrong result nonetheless.

Hence I'm at my wits' end. How does one calculate or simulate the marginal deviance of a binary GLMM?

Best,

J

la 30. tammik. 2021 klo 22.55 Ben Bolker (bbolker at gmail.com<mailto:bbolker at gmail.com>) kirjoitti:

>    "marginal" is unfortunately a word that has different meanings in
> different contexts, I'm still trying to sort it out in my own mind.
>
>    GLMMadaptive doesn't do marginal _predictions_ but it does do
> marginal _coefficients_.
>
>    I put up some example workings at
>
>
> https://eur01.safelinks.protection.outlook.com/?url=http%3A%2F%2Fbbolk
> er.github.io<https://eur01.safelinks.protection.outlook.com/?url=http%3A%2F%2Fer.github.io%2F&data=04%7C01%7Cd.rizopoulos%40erasmusmc.nl%7Cd2d097e45e61476cd4fd08d8c749f2f8%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C0%7C637478467710678229%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&sdata=B7ccPD%2FUqXJ7vHrl3QLedWIV9f1U%2FPial2nEIDUaLEM%3D&reserved=0>%2Fmixedmodels-misc%2Fnotes%2Fmarginal_ex.html%3Fde49a7770
> f7&amp;data=04%7C01%7Cd.rizopoulos%40erasmusmc.nl<https://eur01.safelinks.protection.outlook.com/?url=http%3A%2F%2F40erasmusmc.nl%2F&data=04%7C01%7Cd.rizopoulos%40erasmusmc.nl%7Cd2d097e45e61476cd4fd08d8c749f2f8%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C0%7C637478467710688175%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&sdata=EsCKF4EqxsgPfABTJd9LMrHeDw8bTBl4pGum9ordGMM%3D&reserved=0>%7C7d927fd8921241ae84
> 7108d8c5bfca57%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C0%7C6374767748
> 20847825%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiL
> CJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&amp;sdata=yBBei0xChbPMg0bwvw33t9K
> zYN0n0EISVRexB%2BGARtg%3D&amp;reserved=0
>
>   (the hash at the end may be unnecessary for you).
>
>   If you average across simulations with newdata= set that should give
> you marginal predictions ...
>
> On 1/30/21 9:23 AM, Juho Kristian Ruohonen wrote:
> > Sorry to revive the thread after 21 months, but the topic has just
> > become highly relevant. My question concerns the following remark by Ben:
> >
> >     As far as what predict() does: depending on the value of re.form, it
> >     either gives a population-level prediction (R=0) or a conditional
> >     prediction (R set to its conditional mode).  You might be looking for
> >     *marginal* predictions (which Rizopoulous's GLMMadaptive package can
> >     do ...)
> >
> >
> > Does "marginal predictions" here mean predictions based exclusively
> > on the "population-averaged" fixed-effect estimates that are
> > equivalent to onescalculated by *gee()* from the /gee/ library and
> > *geeglm()* from the /geepack /library? Or does it mean predictions
> > calculated using the GLMM estimates of the fixed effects and then
> > averaged with respect to the estimated random-effects distribution?
> > If it means the former, aren't those predictions easily obtainable
> > through a standard GLM that ignores the clustering? If it means the
> > latter, could someone please point out how exactly to calculate such marginal predictions using GLMMadaptive?
> > I've been trying to figure out how to manually calculate the
> > marginal (latter sense) LL for binomial GLMMs, with no success so far...
> >
> > Best,
> >
> > J
> >
> > la 20. huhtik. 2019 klo 17.51 Ben Bolker (bbolker at gmail.com<mailto:bbolker at gmail.com>
> > <mailto:bbolker at gmail.com<mailto:bbolker at gmail.com>>) kirjoitti:
> >
> >
> >        I agree with Juho that there's a typo -- would be something like.
> >
> >       sum((y==1)*log(pred_prob) + (y==0)*log(1-pred_prob))
> >
> >        As far as what predict() does: depending on the value of
> > re.form,
> it
> >     either gives a population-level prediction (R=0) or a conditional
> >     prediction (R set to its conditional mode).  You might be looking for
> >     *marginal* predictions (which Rizopoulous's GLMMadaptive package can
> >     do ...)
> >
> >
> >     On 2019-04-20 3:42 a.m., Juho Kristian Ruohonen wrote:
> >      > Rolf: Forgive my ignorance, but isn't the relevant log-likelihood
> >     here
> >      > the log-likelihood of the observed responses in the validation
> >     set given
> >      > the model-predicted probabilities? I.e. sum(dbinom(VS$y, size
> > =
> VS$n,
> >      > prob = predict(fit, newdata = VS, type = "response"), log =
> >     TRUE))? Even
> >      > this would be somewhat off because dbinom() isn't aware of the
> >      > random-effects integral business. But it looks to me like your
> >     current
> >      > call is calculating the log-sum of the predicted probabilities of
> >     y = 1
> >      > in the validation set, not the loglikelihood of the observed
> >     responses
> >      > in the validation set.
> >      >
> >      > la 20. huhtik. 2019 klo 8.51 Rolf Turner (r.turner at auckland.ac.nz<mailto:r.turner at auckland.ac.nz>
> >     <mailto:r.turner at auckland.ac.nz<mailto:r.turner at auckland.ac.nz>>
> >      > <mailto:r.turner at auckland.ac.nz<mailto:r.turner at auckland.ac.nz>
> >     <mailto:r.turner at auckland.ac.nz<mailto:r.turner at auckland.ac.nz>>>) kirjoitti:
> >      >
> >      >
> >      >     On 20/04/19 12:44 PM, Ben Bolker wrote:
> >      >
> >      >     >    This seems wrong.
> >      >
> >      >     Yeah, that figures.
> >      >
> >      >     > The GLMM log-likelihood includes an integral over
> >      >     > the distribution of the random effects.
> >      >
> >      >     I was aware of this.  I guess what I was na?vely expecting
> >     was that
> >      >     predict.merMod() would handle this.  I.e. that this predict
> >     method
> >      >     (with type = "response") would return, for each observed y_i
> >     in the
> >      >     (new) data set
> >      >
> >      >        Pr(Y = y_i) = \int_0 Pr(Y = y_i | R = r) f(r) dr
> >      >
> >      >     where R is the vector of random effects and f(r) is its
> >     probability
> >      >     density function (multivariate normal, with mean 0 and some
> >     covariance
> >      >     matrix, which has been estimated in the fitting process.
> >      >
> >      >     I guess that this is *not* what predict.merMod() returns ---
> >     but I
> >      >     don't
> >      >     understand why not.  It seems to me that this is what it
> "should"
> >      >     return.
> >      >
> >      >     I'm probably misunderstanding something, possibly simple,
> >     possibly
> >      >     subtle.
> >      >
> >      >     Apropos of nothing much, what *does* predict.merMod() return?
> >      >     Maybe Pr(Y = y_i | R = 0) ???
> >      >
> >      >     <SNIP>
> >      >     >   Here is an **inefficient** method for computing the
> >     likelihood
> >      >     >
> >      >     >     coefs <- unlist(getME(fit,c("theta","beta"))
> >      >     >     newdev <- update(fit, data=VS, devFunOnly=TRUE)
> >      >     >     newdev(coefs)
> >      >     >
> >      >     > This is slow because it has to reconstruct all of the
> >     random-effects
> >      >     > matrices, do permutations to reorder the relevant matrices
> >     to be as
> >      >     > sparse as possible, etc. etc.
> >      >
> >      >     Thanks for this.  I'll give it a go.  I think that the
> >     slowness may not
> >      >     be an overwhelming drawback.  Anyhow I shall try to test it
> out.
> >      >
> >      >     Thanks again.
> >      >
> >      >     cheers,
> >      >
> >      >     Rolf
> >      >
> >      >     --
> >      >     Honorary Research Fellow
> >      >     Department of Statistics
> >      >     University of Auckland
> >      >     Phone: +64-9-373-7599 ext. 88276
> >      >
> >      >     _______________________________________________
> >      > R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org>
> >     <mailto:R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org>>
> >      >     <mailto:R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org>
> >     <mailto:R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org>>> mailing list
> >      > https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=04%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C7d927fd8921241ae847108d8c5bfca57%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C0%7C637476774820847825%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&amp;sdata=BXuC6CVsrp3tlibaDkAnYC3BxFz%2Bfv3W85OMQn6Gjng%3D&amp;reserved=0<https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&data=04%7C01%7Cd.rizopoulos%40erasmusmc.nl%7Cd2d097e45e61476cd4fd08d8c749f2f8%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C0%7C637478467710688175%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&sdata=8Hg%2FlYRcCggPDya9X%2BGI0r0reWmQKpjdGj71eflNK34%3D&reserved=0>
> >     <https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=04%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C7d927fd8921241ae847108d8c5bfca57%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C0%7C637476774820847825%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&amp;sdata=BXuC6CVsrp3tlibaDkAnYC3BxFz%2Bfv3W85OMQn6Gjng%3D&amp;reserved=0<https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&data=04%7C01%7Cd.rizopoulos%40erasmusmc.nl%7Cd2d097e45e61476cd4fd08d8c749f2f8%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C0%7C637478467710698129%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&sdata=jfLIQQC79l0lr3qJTpGgX2Ucu8r%2FhWuDHKxlJZseAnU%3D&reserved=0>>
> >      >
> >
>

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=04%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C7d927fd8921241ae847108d8c5bfca57%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C0%7C637476774820847825%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&amp;sdata=BXuC6CVsrp3tlibaDkAnYC3BxFz%2Bfv3W85OMQn6Gjng%3D&amp;reserved=0<https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&data=04%7C01%7Cd.rizopoulos%40erasmusmc.nl%7Cd2d097e45e61476cd4fd08d8c749f2f8%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C0%7C637478467710698129%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&sdata=jfLIQQC79l0lr3qJTpGgX2Ucu8r%2FhWuDHKxlJZseAnU%3D&reserved=0>

	[[alternative HTML version deleted]]


From me @end|ng |rom ph||||p@|d@y@com  Tue Feb  2 14:00:42 2021
From: me @end|ng |rom ph||||p@|d@y@com (Phillip Alday)
Date: Tue, 2 Feb 2021 14:00:42 +0100
Subject: [R-sig-ME] equivalent of lme4::rePCA() for lme models
In-Reply-To: <CACgv6yUcNWq2Ej9Kq2Z8WEPQ2JqgdYBndQ7wgBpnEy0m3+bhTw@mail.gmail.com>
References: <CACgv6yUcNWq2Ej9Kq2Z8WEPQ2JqgdYBndQ7wgBpnEy0m3+bhTw@mail.gmail.com>
Message-ID: <75efd587-48a4-651b-632b-6015388d8db7@phillipalday.com>

No, but you can implement it yourself; it's literally just the PCA/SVD
of the random-effects matrices:

> lme4:::rePCA.merMod
function (x)
{
    chfs <- getME(x, "Tlist")
    nms <- names(chfs)
    unms <- unique(nms)
    names(unms) <- unms
    svals <- function(m) { # this is applied each of the RE matrices
        vv <- svd(m, nv = 0L)
        names(vv) <- c("sdev", "rotation")
        vv$center <- FALSE
        vv$scale <- FALSE
        class(vv) <- "prcomp"
        vv
    }
    structure(lapply(unms, function(m)
svals(Matrix::bdiag(chfs[which(nms ==
        m)]))), class = "prcomplist")
}

You'll have to look at the nlme documentation to see how those are
stored internally. I don't remember off the top of my head.

Phillip

On 2/2/21 4:55 am, Simon Harmel wrote:
> Dear All,
> 
> I was wondering if there is any `lme4::rePCA()` equivalent for
> `nlme::lme()` models (a reproducible example is below)?
> 
> --Thanks, Simon
> 
> library(nlme)
> 
> dat <- read.csv('https://raw.githubusercontent.com/hkil/m/master/mv.l.csv')
> 
> m22 <- lme(value ~0 + name, random = ~0 + name| Student, data = dat,
>           correlation = corSymm(), weights = varIdent(form = ~1|name))
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From merk|ee @end|ng |rom m|@@our|@edu  Tue Feb  2 18:08:14 2021
From: merk|ee @end|ng |rom m|@@our|@edu (Merkle, Edgar C.)
Date: Tue, 2 Feb 2021 17:08:14 +0000
Subject: [R-sig-ME] Log likelihood of a glmer() binomial model .
In-Reply-To: <DBBPR04MB7850081C436D24C983366777E8B59@DBBPR04MB7850.eurprd04.prod.outlook.com>
References: <306f44cf-a1f9-25d4-4f9f-3dd581698d23@auckland.ac.nz>
 <CABghstTKrwA9x5Xmk=ECwVzHawBp6OnRQCsymKA9DSpZPuATeg@mail.gmail.com>
 <33fd981f-d9db-b824-1c2b-40050b72993e@auckland.ac.nz>
 <CAG_dBVdTdwiSn=9SzR7ewWAqXdgy8sobxRYKE8xd4fJNeuCRJQ@mail.gmail.com>
 <b41fc0d8-a841-fc55-985d-3457b703e8ce@gmail.com>
 <CAG_dBVdE34NXstq9shtyDvHOSS_84=UkduSOPTJ457Kbe6kyPA@mail.gmail.com>
 <0826b45e-01fb-df3c-c11f-272c6e5b7910@gmail.com>
 <CAG_dBVciU4VWKEYtQ1rnx_ZdR3S_Ugp-qdKXDqPu5XT8QUP_tg@mail.gmail.com>
 <AM8PR04MB78438E75CA3B91A6F9FE1B18E8B79@AM8PR04MB7843.eurprd04.prod.outlook.com>
 <CAG_dBVddKN0ZkHRjUrAF70ZTNDKH4aiVrnYyWec4LjYqyXc1fA@mail.gmail.com>,
 <DBBPR04MB7850081C436D24C983366777E8B59@DBBPR04MB7850.eurprd04.prod.outlook.com>
Message-ID: <DM5PR0101MB3097121DA74B44AE1E6EDE8ED8B59@DM5PR0101MB3097.prod.exchangelabs.com>

Juho,

Sorry for the late reply, but we have made some progress here with package merDeriv; see for example

?merDeriv::llcont.glmerMod

We have a related paper that focuses on derivatives, but the same ideas apply to the likelihood/deviance:

https://arxiv.org/abs/2011.10414

You need a way to average over each cluster's posterior distribution of random effects; we use a quadrature method in merDeriv.

Best,
Ed



________________________________
From: D. Rizopoulos <d.rizopoulos at erasmusmc.nl>
Sent: Tuesday, February 2, 2021 1:31 AM
To: Juho Kristian Ruohonen <juho.kristian.ruohonen at gmail.com>
Cc: Ben Bolker <bbolker at gmail.com>; R-mixed models mailing list <r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] Log likelihood of a glmer() binomial model .

Dear Juho,

The log-likelihood function in GLMMs does not have a closed-form. For example, see slides 345-347 in my notes. I.e., when we combine a Binomial probability mass function (pmf) for the response given the random effects, with the normal probability density function for the random effects, we do not get back a Binomial pmf.

Hence, AFAIK you cannot use dbinom() to calculate the marginal deviance in a mixed-effects logistic regression.

You could calculate the ?deviance? from the first term in slide 345, but this doesn?t correspond to a log-likelihood, to my view (i.e., the log-likelihood is typically calculated based on observed data alone).

Best,
Dimitris


From: Juho Kristian Ruohonen <juho.kristian.ruohonen at gmail.com>
Sent: Tuesday, February 2, 2021 8:13 AM
To: D. Rizopoulos <d.rizopoulos at erasmusmc.nl>
Cc: Ben Bolker <bbolker at gmail.com>; R-mixed models mailing list <r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] Log likelihood of a glmer() binomial model .

Dear Dimitris/List,

Slide 360 in Dimitris' teaching materials<https://eur01.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.drizopoulos.com%2Fcourses%2FEMC%2FCE08.pdf&data=04%7C01%7Cd.rizopoulos%40erasmusmc.nl%7Cd2d097e45e61476cd4fd08d8c749f2f8%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C0%7C637478467710678229%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&sdata=8SrRl9g%2FkefFyyERBIkVL%2F1T3Li7oyCqgRbKdonrarM%3D&reserved=0> appears to detail how to compute marginal LL, yet my attempts to manually reproduce the marginal LL/deviance reported by any GLMM software continue to fail.

The code below uses Dimitris' dataset with Ben's software. The software choice is because with Ben's software I can at least replicate the conditional deviance even though I cannot replicate the marginal deviance, as shown below:


data("pbc2", package = "JM")



pbc2$serCholD <- as.numeric(pbc2$serChol > 210)



lme4mod <- glmer(serCholD ~ (1|id) + year*drug + I(age-50)*sex, family = binomial, data = pbc2, nAGQ = 15)

deviance(lme4mod)

[1] 351.5973

-2*sum(dbinom(lme4mod at resp$y, size = 1, prob = predict(lme4mod, re.form = NULL, type = "response"), log = T))

[1] 351.5973

But I cannot replicate the marginal deviance, which is evidently not the same as the "mean-subject" deviance based on only the fixed effects:


-2*logLik(lme4mod)

'log Lik.' 702.6521 (df=8)

-2*sum(dbinom(lme4mod at resp$y, size = 1, prob = predict(lme4mod, re.form = NA, type = "response"), log = T))

[1] 1233.415

So, let's try calculating the marginal deviance from marginal probabilities created using the procedure detailed by Dimitris' Slide 360:


marginalFitted <- plogis( # On the probability scale,

  sapply(rownames(lme4mod at frame), function(i) # for each row of the dataset,

    # the "marginal" prediction is the average of 10,000 "mean-subject" predictions of which each has been augmented by a quantity randomly generated from the estimated N(0, lme4mod at theta) distribution:

    mean(

      predict(lme4mod, newdata = pbc2[i,], re.form = NA) + rnorm(10000, sd = lme4mod at theta)

      )))

marginalDeviance <- -2*sum(dbinom(lme4mod at resp$y, size = 1, prob = marginalFitted, log = T))

But the resulting quantity spectacularly fails to match the marginal likelihood reported by Ben's software:


-2*logLik(lme4mod)

'log Lik.' 702.6521 (df=8)

marginalDeviance

[1] 1232.663

Hence, I remain at my wits' end.

Best,

J

su 31. tammik. 2021 klo 11.57 D. Rizopoulos (d.rizopoulos at erasmusmc.nl<mailto:d.rizopoulos at erasmusmc.nl>) kirjoitti:
If I may add to this, GLMMadaptive does produce marginal predictions, i.e., predictions based on the marginal coefficients; for example, see below. These predictions will have the same interpretation as the one you would get from a GEE approach. You may find more information on this also in my slide (Chapter 5): http://www.drizopoulos.com/courses/EMC/CE08.pdf<https://eur01.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.drizopoulos.com%2Fcourses%2FEMC%2FCE08.pdf&data=04%7C01%7Cd.rizopoulos%40erasmusmc.nl%7Cd2d097e45e61476cd4fd08d8c749f2f8%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C0%7C637478467710678229%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&sdata=8SrRl9g%2FkefFyyERBIkVL%2F1T3Li7oyCqgRbKdonrarM%3D&reserved=0>

Also, a small comment on Ben's code: GLMMadaptive does not use a Monte Carlo simulation for calculating the marginal coefficients - this is in closed-form. The Monte Carlo simulation is used for calculating the standard errors of the marginalized coefficients.

Best,
Dimitris


library("GLMMadaptive")
library("lattice")
data("pbc2", package = "JM")

pbc2$serCholD <- as.numeric(pbc2$serChol > 210)

fm_s52_pbc <- mixed_model(fixed = serCholD ~ year * drug + I(age - 50) * sex,
                          random = ~ 1 | id,
                          family = binomial(), data = pbc2, nAGQ = 15)

summary(fm_s52_pbc)

# the data frame that contains the combination of values to
# create the plot
newDF <- with(pbc2, expand.grid(
    year = seq(0, 12, length.out = 15),
    age = 49,
    drug = levels(drug),
    sex = levels(sex)
))

# log odds for average/median subject
# note: you need to use the effectPlotData() function
# from the GLMMadaptive package (i.e., in case of problems use
# 'GLMMadaptive::effectPlotData')
xyplot(pred + low + upp ~ year | sex * drug,
       data = effectPlotData(fm_s52_pbc, newDF),
       type = "l", lty = c(1, 2, 2), col = c(2, 1, 1), lwd = 2,
       xlab = "Follow-up time (years)", ylab = "Conditional Log Odds")

# marginal probabilities and conditional probabilities corresponding to
# the average/median individual (i.e., the one with random effects value equal to zero)
plot_data_marg <- effectPlotData(fm_s52_pbc, newDF, marginal = TRUE)
plot_data_marg$pred0 <- effectPlotData(fm_s52_pbc, newDF)$pred

key <- simpleKey(c("marginal probabilities", "probabilities average patient"),
                 points = FALSE, lines = TRUE)
key$lines$col <- c("red", "blue")
key$lines$lwd <- c(2, 2)
key$lines$lty <- c(1, 1)
expit <- function (x) exp(x) / (1 + exp(x))
xyplot(expit(pred) + expit(pred0) + expit(low) + expit(upp) ~ year | sex * drug,
       data = plot_data_marg, key = key,
       type = "l", lty = c(1, 1, 2, 2), lwd = 2,
       col = c("red", "blue", "black", "black"),
       xlab = "Follow-up time (years)", ylab = "Probabilities")




-----Original Message-----
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org<mailto:r-sig-mixed-models-bounces at r-project.org>> On Behalf Of Juho Kristian Ruohonen
Sent: Sunday, January 31, 2021 9:11 AM
To: Ben Bolker <bbolker at gmail.com<mailto:bbolker at gmail.com>>
Cc: R-mixed models mailing list <r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>>
Subject: Re: [R-sig-ME] Log likelihood of a glmer() binomial model .

Dear list/Ben,

GLMMadaptive doesn't do marginal _predictions_ but it does do
> marginal _coefficients_.
>

Thanks for clearing that up!


> If you average across simulations with newdata= set that should give
> you marginal predictions ...
>

With *newdata *set to what? I assume I'd have to use the original dataset while somehow emulating the estimated RE distribution. However, I can't seem to make anything work. A simple example with a simple dataset:


>
> *(cluster <- rep(LETTERS[1:8], each = 20))(x <- rep(rep(c(0,1), each =
> 10), times = 8))(y <- as.vector(sapply(2:9, function(x) c(rep(c(1,0),
> c(x,
> 10-x)) ,rep(c(1,0), c(x-1, 10-(x-1)))) )))* *glmm <- glmer(y ~
> (1|cluster) + x, family = binomial, nAGQ = 10)*
> *deviance(glmm) *# "Conditional" deviance obtained by plugging in the
> BLUPs.
>
> [1] 185.4821
>
> *-2*logLik(glmm) *# "Marginal" deviance from averaging the fitted
> values w.r.t the estimated N(0, ?) distribution of the REs.
>
> 'log Lik.' 203.891 (df=3)
>
>
What I'm trying to learn is how to calculate or, failing that, simulate this "marginal" deviance. My first impulse is to simply hand-calculate a deviance from fitted values with all RE's set to their mean of 0. Given that the assumed RE distribution is normal and hence symmetric, my intuition is that the result should equal the result from integrating over the estimated RE distribution. But that fails to happen:

*-2*sum(dbinom(y, size = 1, prob = predict(glmm, re.form = NA,   type =
> "response"), log = T))*
>
> [1] 220.2704
>
>
So my next avenue is to do as Ben seems to suggest, i.e. use the means of simulated "marginal" responses from the model as fitted values. Indeed,
*simulate.merMod()* with *use.u = FALSE* should be exactly what we want, given that its documentation says the following:

use.u
>
> (logical) if TRUE, generate a simulation conditional on the current
> random-effects estimates; if FALSE generate new Normally distributed
> random-effects values.
>

But alas:

*-2*sum(dbinom(y, 1, prob = rowMeans(simulate(glmm, nsim = 1e4, seed =
> 2021, use.u = FALSE)), log = T))*
>
> [1] 220.3949
>
>
The resulting deviance is off no matter what random seed I set. As a sidenote, it seems to equal the deviance obtained by setting all random effects to 0, just as my unreliable intuition suggested. But it's the wrong result nonetheless.

Hence I'm at my wits' end. How does one calculate or simulate the marginal deviance of a binary GLMM?

Best,

J

la 30. tammik. 2021 klo 22.55 Ben Bolker (bbolker at gmail.com<mailto:bbolker at gmail.com>) kirjoitti:

>    "marginal" is unfortunately a word that has different meanings in
> different contexts, I'm still trying to sort it out in my own mind.
>
>    GLMMadaptive doesn't do marginal _predictions_ but it does do
> marginal _coefficients_.
>
>    I put up some example workings at
>
>
> https://eur01.safelinks.protection.outlook.com/?url=http%3A%2F%2Fbbolk
> er.github.io<https://eur01.safelinks.protection.outlook.com/?url=http%3A%2F%2Fer.github.io%2F&data=04%7C01%7Cd.rizopoulos%40erasmusmc.nl%7Cd2d097e45e61476cd4fd08d8c749f2f8%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C0%7C637478467710678229%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&sdata=B7ccPD%2FUqXJ7vHrl3QLedWIV9f1U%2FPial2nEIDUaLEM%3D&reserved=0>%2Fmixedmodels-misc%2Fnotes%2Fmarginal_ex.html%3Fde49a7770
> f7&amp;data=04%7C01%7Cd.rizopoulos%40erasmusmc.nl<https://eur01.safelinks.protection.outlook.com/?url=http%3A%2F%2F40erasmusmc.nl%2F&data=04%7C01%7Cd.rizopoulos%40erasmusmc.nl%7Cd2d097e45e61476cd4fd08d8c749f2f8%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C0%7C637478467710688175%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&sdata=EsCKF4EqxsgPfABTJd9LMrHeDw8bTBl4pGum9ordGMM%3D&reserved=0>%7C7d927fd8921241ae84
> 7108d8c5bfca57%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C0%7C6374767748
> 20847825%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiL
> CJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&amp;sdata=yBBei0xChbPMg0bwvw33t9K
> zYN0n0EISVRexB%2BGARtg%3D&amp;reserved=0
>
>   (the hash at the end may be unnecessary for you).
>
>   If you average across simulations with newdata= set that should give
> you marginal predictions ...
>
> On 1/30/21 9:23 AM, Juho Kristian Ruohonen wrote:
> > Sorry to revive the thread after 21 months, but the topic has just
> > become highly relevant. My question concerns the following remark by Ben:
> >
> >     As far as what predict() does: depending on the value of re.form, it
> >     either gives a population-level prediction (R=0) or a conditional
> >     prediction (R set to its conditional mode).  You might be looking for
> >     *marginal* predictions (which Rizopoulous's GLMMadaptive package can
> >     do ...)
> >
> >
> > Does "marginal predictions" here mean predictions based exclusively
> > on the "population-averaged" fixed-effect estimates that are
> > equivalent to onescalculated by *gee()* from the /gee/ library and
> > *geeglm()* from the /geepack /library? Or does it mean predictions
> > calculated using the GLMM estimates of the fixed effects and then
> > averaged with respect to the estimated random-effects distribution?
> > If it means the former, aren't those predictions easily obtainable
> > through a standard GLM that ignores the clustering? If it means the
> > latter, could someone please point out how exactly to calculate such marginal predictions using GLMMadaptive?
> > I've been trying to figure out how to manually calculate the
> > marginal (latter sense) LL for binomial GLMMs, with no success so far...
> >
> > Best,
> >
> > J
> >
> > la 20. huhtik. 2019 klo 17.51 Ben Bolker (bbolker at gmail.com<mailto:bbolker at gmail.com>
> > <mailto:bbolker at gmail.com<mailto:bbolker at gmail.com>>) kirjoitti:
> >
> >
> >        I agree with Juho that there's a typo -- would be something like.
> >
> >       sum((y==1)*log(pred_prob) + (y==0)*log(1-pred_prob))
> >
> >        As far as what predict() does: depending on the value of
> > re.form,
> it
> >     either gives a population-level prediction (R=0) or a conditional
> >     prediction (R set to its conditional mode).  You might be looking for
> >     *marginal* predictions (which Rizopoulous's GLMMadaptive package can
> >     do ...)
> >
> >
> >     On 2019-04-20 3:42 a.m., Juho Kristian Ruohonen wrote:
> >      > Rolf: Forgive my ignorance, but isn't the relevant log-likelihood
> >     here
> >      > the log-likelihood of the observed responses in the validation
> >     set given
> >      > the model-predicted probabilities? I.e. sum(dbinom(VS$y, size
> > =
> VS$n,
> >      > prob = predict(fit, newdata = VS, type = "response"), log =
> >     TRUE))? Even
> >      > this would be somewhat off because dbinom() isn't aware of the
> >      > random-effects integral business. But it looks to me like your
> >     current
> >      > call is calculating the log-sum of the predicted probabilities of
> >     y = 1
> >      > in the validation set, not the loglikelihood of the observed
> >     responses
> >      > in the validation set.
> >      >
> >      > la 20. huhtik. 2019 klo 8.51 Rolf Turner (r.turner at auckland.ac.nz<mailto:r.turner at auckland.ac.nz>
> >     <mailto:r.turner at auckland.ac.nz<mailto:r.turner at auckland.ac.nz>>
> >      > <mailto:r.turner at auckland.ac.nz<mailto:r.turner at auckland.ac.nz>
> >     <mailto:r.turner at auckland.ac.nz<mailto:r.turner at auckland.ac.nz>>>) kirjoitti:
> >      >
> >      >
> >      >     On 20/04/19 12:44 PM, Ben Bolker wrote:
> >      >
> >      >     >    This seems wrong.
> >      >
> >      >     Yeah, that figures.
> >      >
> >      >     > The GLMM log-likelihood includes an integral over
> >      >     > the distribution of the random effects.
> >      >
> >      >     I was aware of this.  I guess what I was na?vely expecting
> >     was that
> >      >     predict.merMod() would handle this.  I.e. that this predict
> >     method
> >      >     (with type = "response") would return, for each observed y_i
> >     in the
> >      >     (new) data set
> >      >
> >      >        Pr(Y = y_i) = \int_0 Pr(Y = y_i | R = r) f(r) dr
> >      >
> >      >     where R is the vector of random effects and f(r) is its
> >     probability
> >      >     density function (multivariate normal, with mean 0 and some
> >     covariance
> >      >     matrix, which has been estimated in the fitting process.
> >      >
> >      >     I guess that this is *not* what predict.merMod() returns ---
> >     but I
> >      >     don't
> >      >     understand why not.  It seems to me that this is what it
> "should"
> >      >     return.
> >      >
> >      >     I'm probably misunderstanding something, possibly simple,
> >     possibly
> >      >     subtle.
> >      >
> >      >     Apropos of nothing much, what *does* predict.merMod() return?
> >      >     Maybe Pr(Y = y_i | R = 0) ???
> >      >
> >      >     <SNIP>
> >      >     >   Here is an **inefficient** method for computing the
> >     likelihood
> >      >     >
> >      >     >     coefs <- unlist(getME(fit,c("theta","beta"))
> >      >     >     newdev <- update(fit, data=VS, devFunOnly=TRUE)
> >      >     >     newdev(coefs)
> >      >     >
> >      >     > This is slow because it has to reconstruct all of the
> >     random-effects
> >      >     > matrices, do permutations to reorder the relevant matrices
> >     to be as
> >      >     > sparse as possible, etc. etc.
> >      >
> >      >     Thanks for this.  I'll give it a go.  I think that the
> >     slowness may not
> >      >     be an overwhelming drawback.  Anyhow I shall try to test it
> out.
> >      >
> >      >     Thanks again.
> >      >
> >      >     cheers,
> >      >
> >      >     Rolf
> >      >
> >      >     --
> >      >     Honorary Research Fellow
> >      >     Department of Statistics
> >      >     University of Auckland
> >      >     Phone: +64-9-373-7599 ext. 88276
> >      >
> >      >     _______________________________________________
> >      > R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org>
> >     <mailto:R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org>>
> >      >     <mailto:R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org>
> >     <mailto:R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org>>> mailing list
> >      > https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=04%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C7d927fd8921241ae847108d8c5bfca57%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C0%7C637476774820847825%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&amp;sdata=BXuC6CVsrp3tlibaDkAnYC3BxFz%2Bfv3W85OMQn6Gjng%3D&amp;reserved=0<https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&data=04%7C01%7Cd.rizopoulos%40erasmusmc.nl%7Cd2d097e45e61476cd4fd08d8c749f2f8%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C0%7C637478467710688175%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&sdata=8Hg%2FlYRcCggPDya9X%2BGI0r0reWmQKpjdGj71eflNK34%3D&reserved=0>
> >     <https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=04%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C7d927fd8921241ae847108d8c5bfca57%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C0%7C637476774820847825%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&amp;sdata=BXuC6CVsrp3tlibaDkAnYC3BxFz%2Bfv3W85OMQn6Gjng%3D&amp;reserved=0<https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&data=04%7C01%7Cd.rizopoulos%40erasmusmc.nl%7Cd2d097e45e61476cd4fd08d8c749f2f8%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C0%7C637478467710698129%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&sdata=jfLIQQC79l0lr3qJTpGgX2Ucu8r%2FhWuDHKxlJZseAnU%3D&reserved=0>>
> >      >
> >
>

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&amp;data=04%7C01%7Cd.rizopoulos%40erasmusmc.nl%7C7d927fd8921241ae847108d8c5bfca57%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C0%7C637476774820847825%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&amp;sdata=BXuC6CVsrp3tlibaDkAnYC3BxFz%2Bfv3W85OMQn6Gjng%3D&amp;reserved=0<https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-mixed-models&data=04%7C01%7Cd.rizopoulos%40erasmusmc.nl%7Cd2d097e45e61476cd4fd08d8c749f2f8%7C526638ba6af34b0fa532a1a511f4ac80%7C0%7C0%7C637478467710698129%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&sdata=jfLIQQC79l0lr3qJTpGgX2Ucu8r%2FhWuDHKxlJZseAnU%3D&reserved=0>

        [[alternative HTML version deleted]]


	[[alternative HTML version deleted]]


From @|m@h@rme| @end|ng |rom gm@||@com  Tue Feb  2 18:08:25 2021
From: @|m@h@rme| @end|ng |rom gm@||@com (Simon Harmel)
Date: Tue, 2 Feb 2021 11:08:25 -0600
Subject: [R-sig-ME] equivalent of lme4::rePCA() for lme models
In-Reply-To: <75efd587-48a4-651b-632b-6015388d8db7@phillipalday.com>
References: <CACgv6yUcNWq2Ej9Kq2Z8WEPQ2JqgdYBndQ7wgBpnEy0m3+bhTw@mail.gmail.com>
 <75efd587-48a4-651b-632b-6015388d8db7@phillipalday.com>
Message-ID: <CACgv6yW=XJZP4YRhek0bqg_85zY48QbEO5fa=FT=5AqP5GnOgw@mail.gmail.com>

Thanks, Phillip!

On Tue, Feb 2, 2021 at 7:00 AM Phillip Alday <me at phillipalday.com> wrote:

> No, but you can implement it yourself; it's literally just the PCA/SVD
> of the random-effects matrices:
>
> > lme4:::rePCA.merMod
> function (x)
> {
>     chfs <- getME(x, "Tlist")
>     nms <- names(chfs)
>     unms <- unique(nms)
>     names(unms) <- unms
>     svals <- function(m) { # this is applied each of the RE matrices
>         vv <- svd(m, nv = 0L)
>         names(vv) <- c("sdev", "rotation")
>         vv$center <- FALSE
>         vv$scale <- FALSE
>         class(vv) <- "prcomp"
>         vv
>     }
>     structure(lapply(unms, function(m)
> svals(Matrix::bdiag(chfs[which(nms ==
>         m)]))), class = "prcomplist")
> }
>
> You'll have to look at the nlme documentation to see how those are
> stored internally. I don't remember off the top of my head.
>
> Phillip
>
> On 2/2/21 4:55 am, Simon Harmel wrote:
> > Dear All,
> >
> > I was wondering if there is any `lme4::rePCA()` equivalent for
> > `nlme::lme()` models (a reproducible example is below)?
> >
> > --Thanks, Simon
> >
> > library(nlme)
> >
> > dat <- read.csv('
> https://raw.githubusercontent.com/hkil/m/master/mv.l.csv')
> >
> > m22 <- lme(value ~0 + name, random = ~0 + name| Student, data = dat,
> >           correlation = corSymm(), weights = varIdent(form = ~1|name))
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>

	[[alternative HTML version deleted]]


From obour@k| @end|ng |rom gm@||@com  Wed Feb  3 15:10:01 2021
From: obour@k| @end|ng |rom gm@||@com (=?UTF-8?B?0J7Qu9C10LMg0JHRg9GA0YHQutC40Lk=?=)
Date: Wed, 3 Feb 2021 17:10:01 +0300
Subject: [R-sig-ME] multilevel cross-correlation model
Message-ID: <CAFrjCMpBkap5z5a6sQCfEU3On3Y4HkXoph4-Xzf9FmX8eH7SoQ@mail.gmail.com>

Dear masters! I study the influence of climate change on the bird community
of 45 species over 31 years. Most species show a positive population trend,
which should be driven by two climatic factors, A and W, in two ways:
directly here and now and indirectly via broad ecosystem productivity with
~10-year lag. To prove that as the cause of the trends, I fit
log-transformed detrended standardized population abundance X with lmer
(lme4 R):

M <- lmer (X ~ 0 + (0 + Xo | S) + Xo : fRepr +
            (A0 + ? + A12 + W0 + ? + W12) : fGroup, data = data2, REML = F),

where Xo is previous year abundance, Xo | S is species-specific AR(1)-like
autocorrelation due to density dependence, Xo : fRepr is data dependence on
2-level representativeness of the study plot to the regional population
likely influencing density dependence, A0 ? W12 are detrended standardized
climatic variables A and W with lag 0 to 12 years each, and fGroup is
3-level grouping of species by life-history traits.

It works, but several problems still exist:
1.       Climate variables consume much df and yield odd beta estimates
depending on the number of A and W lags (i.e. lagged variables) in the
model:
No. of lags      AIC    Approx.aver. |beta|   Approx.aver. |t|
?                     ?                      ?                      ?
  8                    3670                 ~0.1                    ~2
  9                    3667                 ~0.1                    ~2
10                    3669                 ~0.1                   ~1.5
11                    3672                 ~0.1                    ~1
12                    3656                 ~0.8                   ~3.5
13                    3660                 ~1.2                   ~0.3
14                   Rank deficiency?

That is, long lags seem to be influential, but the model structure is
getting unstable.
2.       Species differ by mean abundance for two orders of magnitude, and
their contribution to the model should be weighted by square root of
abundance, which is incompatible with lmer.
3.       I am not sure with correctness of applying Xo|S term instead of
AR(1), though it is more supported by AIC and compatible with other terms
in lmer model.
4.       I doubt the overall model structure. There are 31 years of
observations on abundance (or 30 after Xo is subtracted) for each species,
though climate predictors of 40-50 years could influence. How can I arrange
them together without NAs? Perhaps there is a way to represent climatic
variables as something like ?A0 + W0 + A1 + W1 + crosscorrelation (A
lagged) + crosscorrelation (W lagged) in any package other than lme4, which
explores short multilevel time series.
Any advice would be highly appreciated. The DataFile is attached.
Oleg Bourski

From b|e|||@@|e@@@ndr@ @end|ng |rom gm@||@com  Sat Feb  6 01:25:19 2021
From: b|e|||@@|e@@@ndr@ @end|ng |rom gm@||@com (Alessandra Bielli)
Date: Fri, 5 Feb 2021 18:25:19 -0600
Subject: [R-sig-ME] including dispersion parameter in predictions
Message-ID: <CA+6N3yVDidPxnseRZrD4uEu4SttnV6T7UoRYZe=dLnvB3MQciw@mail.gmail.com>

Dear list,

I am fitting this model to predict the dependent variable at the population
mode:

m1.dczig <- glmmTMB(Res.dia.pers ~ Tipo + (1|ID) , data=all, zi=~ Tipo ,
dispformula=~ Tipo , family=ziGamma(link ="log"))

where Res.dia.pers is a continuous variable >= zero, and Tipo is a
categorical variable.

Is it possible to include the dispersion parameter when doing predictions?
I was using this code to predict at the population mode using a model
WITHOUT dispformula:

newdata0 = with(all,
                        expand.grid(
                            Tipo = c("1","2","3","4")))
X.cond = model.matrix(lme4::nobars(formula(m1.dczig)[-2]), newdata0)
beta.cond = fixef(m1.dczig)$cond
pred.cond = X.cond %*% beta.cond
ziformula = m1.dczig$modelInfo$allForm$ziformula
X.zi = model.matrix(lme4::nobars(ziformula), newdata0)
beta.zi = fixef(m1.dczig)$zi
pred.zi = X.zi %*% beta.zi

pred.ucount = exp(pred.cond)*(1-plogis(pred.zi))

set.seed(101)
pred.condpar.psim = mvrnorm(1000,mu=beta.cond,Sigma=vcov(m1.dczig)$cond)
pred.cond.psim = X.cond %*% t(pred.condpar.psim)
pred.zipar.psim = mvrnorm(1000,mu=beta.zi,Sigma=vcov(m1.dczig)$zi)
pred.zi.psim = X.zi %*% t(pred.zipar.psim)
pred.ucount.psim = exp(pred.cond.psim)*(1-plogis(pred.zi.psim))
ci.ucount = t(apply(pred.ucount.psim,1,quantile,c(0.025,0.975)))
ci.ucount = data.frame(ci.ucount)
names(ci.ucount) = c("ucount.low","ucount.high")
pred.ucount = data.frame(newdata0, pred.ucount, ci.ucount)

To include the dispersion parameter, I adapt it by adding

dispformula = m1.dczig$modelInfo$allForm$dispformula
X.disp = model.matrix(lme4::nobars(dispformula), newdata0)
beta.disp = fixef(m1.dczig)$disp
pred.disp = X.disp %*% beta.disp

pred.disppar.psim = mvrnorm(1000,mu=beta.disp,Sigma=vcov(m1.dczig)$disp)
pred.disp.psim = X.disp %*% t(pred.disppar.psim)

How do I include the dispersion parameter in the pred.ucount =
exp(pred.cond)*(1-plogis(pred.zi)) and pred.ucount.psim =
exp(pred.cond.psim)*(1-plogis(pred.zi.psim))? I have found some info here
<https://journal.r-project.org/archive/2017/RJ-2017-066/RJ-2017-066.pdf>,
equations 1 to 5, but I am not sure how to use this info for my case.

Thanks for your help,
Alessandra

PS: I am not using the predict function because I want to calculate CIs as
well.

	[[alternative HTML version deleted]]


From r@v|@v@r@dh@n @end|ng |rom jhu@edu  Fri Feb 12 02:30:33 2021
From: r@v|@v@r@dh@n @end|ng |rom jhu@edu (Ravi Varadhan)
Date: Fri, 12 Feb 2021 01:30:33 +0000
Subject: [R-sig-ME] Prediction of random effects in glmer()
Message-ID: <MW4PR01MB6212013F278FB02B3E3ED842F28B9@MW4PR01MB6212.prod.exchangelabs.com>

Hi,
I would like to know how the prediction of random effects is done in the GLMM modeling using the lme4::glmer function, i.e. how the BLUP-like predictions are made in the glmer() function?

Does it use frequentist prediction or empirical Bayes or full Bayes posterior?  Is there any documentation of the prediction methodology?

Thanks in advance.

Ravi

	[[alternative HTML version deleted]]


From juho@kr|@t|@n@ruohonen @end|ng |rom gm@||@com  Fri Feb 12 23:43:13 2021
From: juho@kr|@t|@n@ruohonen @end|ng |rom gm@||@com (Juho Kristian Ruohonen)
Date: Sat, 13 Feb 2021 00:43:13 +0200
Subject: [R-sig-ME] Prediction of random effects in glmer()
In-Reply-To: <MW4PR01MB6212013F278FB02B3E3ED842F28B9@MW4PR01MB6212.prod.exchangelabs.com>
References: <MW4PR01MB6212013F278FB02B3E3ED842F28B9@MW4PR01MB6212.prod.exchangelabs.com>
Message-ID: <CAG_dBVcYt=ZDX37SybkEfgo8yJwU6VF2VUuh5yQwyHiSY_eHZQ@mail.gmail.com>

Following. I'd like to know this as well.

J

pe 12. helmik. 2021 klo 3.37 Ravi Varadhan (ravi.varadhan at jhu.edu)
kirjoitti:

> Hi,
> I would like to know how the prediction of random effects is done in the
> GLMM modeling using the lme4::glmer function, i.e. how the BLUP-like
> predictions are made in the glmer() function?
>
> Does it use frequentist prediction or empirical Bayes or full Bayes
> posterior?  Is there any documentation of the prediction methodology?
>
> Thanks in advance.
>
> Ravi
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From |@brun@ @end|ng |rom udc@e@  Sun Feb 14 13:56:35 2021
From: |@brun@ @end|ng |rom udc@e@ (Fernando Pedro Bruna Quintas)
Date: Sun, 14 Feb 2021 12:56:35 +0000
Subject: [R-sig-ME] non-singularity with glmer() in a logit mixed model
Message-ID: <PR1PR02MB48897AAF0FE4ED21C84167F992899@PR1PR02MB4889.eurprd02.prod.outlook.com>


Hi. This is my first time in the list. I apologize if I make a mistake.

I am answering the comments of our reviewers after the submission of a paper. I mention this because the comments were positive, so the paper should be close to publication. However, one of the reviewers ask me to introduce two additional level-2 variables and the estimation becomes singular. I am a user of lme4 but my field is Economics, not Statistics.

The focus of the paper is to compare the results of two dependent variables, Y.A and Y.B for firms nested in 24 regions. I am estimating mixed logit models. The new level-2 variables suggested by the reviewer work fine for both dependent variables, with the expected signs and p-value close to zero (the journal uses p-values, so, please, ignore the debate about p-values here). However, the definition of Y.A is much more restrictive though more interesting than the definition of Y.B. Therefore, for Y.A there are far fewer ones for firms in the 24 regions. I know that 24 groups are not too many but, according to the literature, should be enough and they are enough for variable Y.B. However, the model of Y.A is non-singular when estimating with 6 lev-el-2 variables. 

Additionally, the reviewers ask me to write the tables of results for Y.A and Y.B with the same explanatory variables, even if some of them are non-significant. I might tell them that it would be better to avoid that. However, playing around to reduce the number of level-2 variables produce unclear results, as you can check in the following lines. I avoid the non-singular warning in the last column, but the deletion of variables is somewhat random. ICC goes from 0.12 when only level-1 variables are included, to the non-singular situation for 6 level-2 variables and to 0.01 after an arbitrary deletion of three level-2 variables.

Level 2 standardized group-centered predictors for the dependent variable Y.A
First column is the model only including level-1 variables
The rest of the columns are alternative models trying to avoid the non-singular warning									
		Odds	p	Odds 		p	Odds 		p		    Odds 		p			Odds 		p	Odds 	p	
X1					1.19		  0.034		1.32		<0.001		1.19		  0.035		1.37		<0.001	1.34		<0.001
X2					0.86		  0.003		0.86		  0.004		0.83		<0.001		0.84		<0.001		
X3					1.09		  0.134		1.14		  0.012						
X4					1.27		<0.001		1.28		<0.001		1.26		 <0.001	1.26		<0.001	1.27		<0.001
X5					3.79		<0.001		3.89		<0.001		3.79		 <0.001	3.92		<0.001	3.89		<0.001
X6					0.82		  0.090		0.77		  0.011				
Random Effects												
sigma2	3.29				3.29						3.29						3.29						3.29				3.29	
Tau00	0.44 region	0.00 region			0.00 region			0.00 region			0.00 region		0.03 region	
ICC	    0.12											0.01	
N			24 region		24 region				24 region				24 region				24 region		24 region	
Obs.		6122			6122					6122					6122					6122			6122	
Marg. R2	0.245 		0.490 					0.490 					0.490 					0.487 			0.488 
Cond. R2	0.333		NA						NA						NA						NA				0.492	
Devi.	4.797.692	3.895.819			3.900.349			3.899.897			3.906.505		3.915.146




As I mentioned before, data about variable Y.A may not contain enough information (variance) to discriminate between so many level-2 effects. However, now I should take decisions to finish the paper, summarize some useful technical explanations and derive possible economic explanations.

My questions are:
-	Is it possible to solve my non-singularity keeping all the explanatory variables? Below you can find the options I am using to estimate the model.
-	Should I ignore the non-singular warning? I understand that the cause of the problem is also that in a logit model adding more level-2 variables only reduces the level 2 variance, towards zero in my model. Indeed, one of the reviewers did not understand our explanation about the fixed lev-el-1 variance, so maybe it is better to avoid confusion about that.
-	In the same vein, should I avoid publishing ICC? I had thought that it was useful but some au-thors of papers with multilevel logit models do not publish ICC. 
-	If there is no solution, because of lack of information, do you have a suggestion or a reference with similar issues to provide some insights with this model in spite of the problem?

Thanks a lot,

Fernando

Appendix

> Mod.Y.A	<- glmer(update(eq2id, ~ . + (1 | region) ), family = binomial("logit"), data = inno, nAGQ = 9,  
+ control=glmerControl(optimizer="bobyqa", optCtrl=list(maxfun=100000), calc.derivs = FALSE))
> isSingular(Mod.Y.A)	
[1] TRUE

> require(optimx)
> library(dfoptim)			 
> Meq2id.allFit <- allFit(Mod.Y.A)
bobyqa : [OK]
Nelder_Mead : [OK]
nlminbwrap : [OK]
nmkbw : [OK]
optimx.L-BFGS-B : [OK]
nloptwrap.NLOPT_LN_NELDERMEAD : [OK]
nloptwrap.NLOPT_LN_BOBYQA : [OK]
> sapply(Meq2id.allFit,	logLik) 				## log-likelihoods
                       bobyqa                   Nelder_Mead 
                     -1947.91                      -1947.91 
                   nlminbwrap                         nmkbw 
                     -1947.91                      -1947.91 
              optimx.L-BFGS-B nloptwrap.NLOPT_LN_NELDERMEAD 
                     -1947.91                      -1947.91 
    nloptwrap.NLOPT_LN_BOBYQA 
                     -1947.91 
> sapply(Meq2id.allFit,	getME,"theta") 			## theta parameters
                       bobyqa.prov.(Intercept) 
                                  0.000000e+00 
                  Nelder_Mead.prov.(Intercept) 
                                  0.000000e+00 
                   nlminbwrap.prov.(Intercept) 
                                  0.000000e+00 
                        nmkbw.prov.(Intercept) 
                                  1.756646e-08 
              optimx.L-BFGS-B.prov.(Intercept) 
                                  0.000000e+00 
nloptwrap.NLOPT_LN_NELDERMEAD.prov.(Intercept) 
                                  0.000000e+00 
    nloptwrap.NLOPT_LN_BOBYQA.prov.(Intercept) 
                                  0.000000e+00 
> !sapply(Meq2id.allFit,	inherits,"try-error") 	## was fit OK?
                       bobyqa                   Nelder_Mead 
                         TRUE                          TRUE 
                   nlminbwrap                         nmkbw 
                         TRUE                          TRUE 
              optimx.L-BFGS-B nloptwrap.NLOPT_LN_NELDERMEAD 
                         TRUE                          TRUE 
    nloptwrap.NLOPT_LN_BOBYQA 
                         TRUE







From bbo|ker @end|ng |rom gm@||@com  Mon Feb 15 03:20:46 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Sun, 14 Feb 2021 21:20:46 -0500
Subject: [R-sig-ME] Prediction of random effects in glmer()
In-Reply-To: <CAG_dBVcYt=ZDX37SybkEfgo8yJwU6VF2VUuh5yQwyHiSY_eHZQ@mail.gmail.com>
References: <MW4PR01MB6212013F278FB02B3E3ED842F28B9@MW4PR01MB6212.prod.exchangelabs.com>
 <CAG_dBVcYt=ZDX37SybkEfgo8yJwU6VF2VUuh5yQwyHiSY_eHZQ@mail.gmail.com>
Message-ID: <5ffd04fc-fced-b046-6b47-a480936423dc@gmail.com>

   This follows an earlier private conversation that didn't quite get 
resolved.

   I'm interpreting "how the BLUP-like predictions are made" as "how do 
you estimate the conditional modes"?  "Conditional modes" is what we 
call the predicted deviations of each group's effects (intercept, slope, 
whatever) from the population mean (i.e. the fixed-effect estimate for 
that thing).  For classic LMMs, conditional modes==BLUPs, but not 
otherwise: see Doug Bates's comments here

https://stat.ethz.ch/pipermail/r-sig-mixed-models/2011q2/016047.html

   There is a long-neglected GLMM manuscript that builds on the 
Bates/Maechler/Bolker/Walker JSS paper which I should clean up at least 
enough to be able to post it publicly.  In the meantime, what it says is 
that the conditional modes are determined using a penalized iteratively 
reweighted least squares algorithm.

1. Given parameter values, ? and ?, and starting estimates, u0 , 
evaluate the linear predictor, ?, the corresponding conditional mean,
?_{Y|U} =u , and the conditional variance. Establish the weights as the 
inverse of the variance. We write these weights in the form
of a diagonal weight matrix, W , although they are stored and 
manipulated as a vector.


2. Solve the penalized, weighted, nonlinear least squares problem

    (arg min of [L2 norm of weighted residual vector] + [L2 norm of 
conditional modes])

3. Update the weights, W , and check for convergence. If not converged, 
go to step 2.

  Gauss-Newton, blah blah blah blah ...

   I'm happy to send the draft to anyone who asks for it.

  HOWEVER, when I sent Ravi the draft it seemed as though it didn't 
answer the question. So Ravi, maybe you could clarify?

   I would classify this as "empirical Bayes" since the ? parameters 
(the vector of elements of the Cholesky factors that define the 
covariance matrices of the random effects) are determined from data 
without an explicit prior.


On 2/12/21 5:43 PM, Juho Kristian Ruohonen wrote:
> Following. I'd like to know this as well.
> 
> J
> 
> pe 12. helmik. 2021 klo 3.37 Ravi Varadhan (ravi.varadhan at jhu.edu)
> kirjoitti:
> 
>> Hi,
>> I would like to know how the prediction of random effects is done in the
>> GLMM modeling using the lme4::glmer function, i.e. how the BLUP-like
>> predictions are made in the glmer() function?
>>
>> Does it use frequentist prediction or empirical Bayes or full Bayes
>> posterior?  Is there any documentation of the prediction methodology?
>>
>> Thanks in advance.
>>
>> Ravi
>>
>>          [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From D@v|d@Du||y @end|ng |rom q|mrbergho|er@edu@@u  Mon Feb 15 06:05:37 2021
From: D@v|d@Du||y @end|ng |rom q|mrbergho|er@edu@@u (David Duffy)
Date: Mon, 15 Feb 2021 05:05:37 +0000
Subject: [R-sig-ME] non-singularity with glmer() in a logit mixed model
In-Reply-To: <PR1PR02MB48897AAF0FE4ED21C84167F992899@PR1PR02MB4889.eurprd02.prod.outlook.com>
References: <PR1PR02MB48897AAF0FE4ED21C84167F992899@PR1PR02MB4889.eurprd02.prod.outlook.com>
Message-ID: <8657ac230ae8406dbd011f1ea43da875@qimrberghofer.edu.au>


________________________________________
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of Fernando Pedro Bruna Quintas <f.bruna at udc.es>
Sent: Sunday, 14 February 2021 10:56:35 PM
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] non-singularity with glmer() in a logit mixed model

Hi. This is my first time in the list. I apologize if I make a mistake.

I am answering the comments of our reviewers after the submission of a paper. I mention this because the comments were positive, so the paper should be close to publication. However, one of the reviewers ask me to introduce two additional level-2 variables and the estimation becomes singular. I am a user of lme4 but my field is Economics, not Statistics.

The focus of the paper is to compare the results of two dependent variables, Y.A and Y.B for firms nested in 24 regions. I am estimating mixed logit models. The new level-2 variables suggested by the reviewer work fine for both dependent variables, with the expected signs and p-value close to zero (the journal uses p-values, so, please, ignore the debate about p-values here). However, the definition of Y.A is much more restrictive though more interesting than the definition of Y.B. Therefore, for Y.A there are far fewer ones for firms in the 24 regions. I know that 24 groups are not too many but, according to the literature, should be enough and they are enough for variable Y.B. However, the model of Y.A is non-singular when estimating with 6 lev-el-2 variables.

Additionally, the reviewers ask me to write the tables of results for Y.A and Y.B with the same explanatory variables, even if some of them are non-significant. I might tell them that it would be better to avoid that. However, playing around to reduce the number of level-2 variables produce unclear results, as you can check in the following lines. I avoid the non-singular warning in the last column, but the deletion of variables is somewhat random. ICC goes from 0.12 when only level-1 variables are included, to the non-singular situation for 6 level-2 variables and to 0.01 after an arbitrary deletion of three level-2 variables.

Level 2 standardized group-centered predictors for the dependent variable Y.A
First column is the model only including level-1 variables
The rest of the columns are alternative models trying to avoid the non-singular warning
                Odds    p       Odds            p       Odds            p                   Odds                p                       Odds            p       Odds    p
X1                                      1.19              0.034         1.32            <0.001          1.19              0.035         1.37            <0.001  1.34            <0.001
X2                                      0.86              0.003         0.86              0.004         0.83            <0.001          0.84            <0.001
X3                                      1.09              0.134         1.14              0.012
X4                                      1.27            <0.001          1.28            <0.001          1.26             <0.001 1.26            <0.001  1.27            <0.001
X5                                      3.79            <0.001          3.89            <0.001          3.79             <0.001 3.92            <0.001  3.89            <0.001
X6                                      0.82              0.090         0.77              0.011
Random Effects
sigma2  3.29                            3.29                                            3.29                                            3.29                                            3.29                            3.29
Tau00   0.44 region     0.00 region                     0.00 region                     0.00 region                     0.00 region             0.03 region
ICC         0.12                                                                                        0.01
N                       24 region               24 region                               24 region                               24 region                               24 region               24 region
Obs.            6122                    6122                                    6122                                    6122                                    6122                    6122
Marg. R2        0.245           0.490                                   0.490                                   0.490                                   0.487                   0.488
Cond. R2        0.333           NA                                              NA                                              NA                                              NA                              0.492
Devi.   4.797.692       3.895.819                       3.900.349                       3.899.897                       3.906.505               3.915.146




As I mentioned before, data about variable Y.A may not contain enough information (variance) to discriminate between so many level-2 effects. However, now I should take decisions to finish the paper, summarize some useful technical explanations and derive possible economic explanations.

My questions are:
-       Is it possible to solve my non-singularity keeping all the explanatory variables? Below you can find the options I am using to estimate the model.
-       Should I ignore the non-singular warning? I understand that the cause of the problem is also that in a logit model adding more level-2 variables only reduces the level 2 variance, towards zero in my model. Indeed, one of the reviewers did not understand our explanation about the fixed lev-el-1 variance, so maybe it is better to avoid confusion about that.
-       In the same vein, should I avoid publishing ICC? I had thought that it was useful but some au-thors of papers with multilevel logit models do not publish ICC.
-       If there is no solution, because of lack of information, do you have a suggestion or a reference with similar issues to provide some insights with this model in spite of the problem?

Thanks a lot,

Fernando

Appendix

> Mod.Y.A       <- glmer(update(eq2id, ~ . + (1 | region) ), family = binomial("logit"), data = inno, nAGQ = 9,
+ control=glmerControl(optimizer="bobyqa", optCtrl=list(maxfun=100000), calc.derivs = FALSE))
> isSingular(Mod.Y.A)
[1] TRUE

> require(optimx)
> library(dfoptim)
> Meq2id.allFit <- allFit(Mod.Y.A)
bobyqa : [OK]
Nelder_Mead : [OK]
nlminbwrap : [OK]
nmkbw : [OK]
optimx.L-BFGS-B : [OK]
nloptwrap.NLOPT_LN_NELDERMEAD : [OK]
nloptwrap.NLOPT_LN_BOBYQA : [OK]
> sapply(Meq2id.allFit, logLik)                                 ## log-likelihoods
                       bobyqa                   Nelder_Mead
                     -1947.91                      -1947.91
                   nlminbwrap                         nmkbw
                     -1947.91                      -1947.91
              optimx.L-BFGS-B nloptwrap.NLOPT_LN_NELDERMEAD
                     -1947.91                      -1947.91
    nloptwrap.NLOPT_LN_BOBYQA
                     -1947.91
> sapply(Meq2id.allFit, getME,"theta")                  ## theta parameters
                       bobyqa.prov.(Intercept)
                                  0.000000e+00
                  Nelder_Mead.prov.(Intercept)
                                  0.000000e+00
                   nlminbwrap.prov.(Intercept)
                                  0.000000e+00
                        nmkbw.prov.(Intercept)
                                  1.756646e-08
              optimx.L-BFGS-B.prov.(Intercept)
                                  0.000000e+00
nloptwrap.NLOPT_LN_NELDERMEAD.prov.(Intercept)
                                  0.000000e+00
    nloptwrap.NLOPT_LN_BOBYQA.prov.(Intercept)
                                  0.000000e+00
> !sapply(Meq2id.allFit,        inherits,"try-error")   ## was fit OK?
                       bobyqa                   Nelder_Mead
                         TRUE                          TRUE
                   nlminbwrap                         nmkbw
                         TRUE                          TRUE
              optimx.L-BFGS-B nloptwrap.NLOPT_LN_NELDERMEAD
                         TRUE                          TRUE
    nloptwrap.NLOPT_LN_BOBYQA
                         TRUE






_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
[EXTERNAL EMAIL] This message originates from an external email address, please exercise caution when clicking any links or opening attachments. If you believe the sender is impersonating someone at QIMR Berghofer, please forward this message to phishing at qimrberghofer.edu.au.


From D@v|d@Du||y @end|ng |rom q|mrbergho|er@edu@@u  Mon Feb 15 06:14:13 2021
From: D@v|d@Du||y @end|ng |rom q|mrbergho|er@edu@@u (David Duffy)
Date: Mon, 15 Feb 2021 05:14:13 +0000
Subject: [R-sig-ME] non-singularity with glmer() in a logit mixed model
In-Reply-To: <PR1PR02MB48897AAF0FE4ED21C84167F992899@PR1PR02MB4889.eurprd02.prod.outlook.com>
References: <PR1PR02MB48897AAF0FE4ED21C84167F992899@PR1PR02MB4889.eurprd02.prod.outlook.com>
Message-ID: <6c51a8ae5c4b42bb8fde254752f38c2d@qimrberghofer.edu.au>

> The focus of the paper is to compare the results of two dependent variables, Y.A and Y.B for firms nested in 24 regions. 
> I am estimating mixed logit models [...] the definition of Y.A is much more restrictive though more interesting than the definition of Y.B. 
> Therefore, for Y.A there are far fewer ones for firms in the 24 regions.

I don't know if this is helpful, but you might try a multinomial (or even ordinal, if that is appropriate) outcome (no, y-loose, y-strict) GLMM. There are
a few suitable R packages (eg MCMCglmm). 

From |@brun@ @end|ng |rom udc@e@  Mon Feb 15 10:34:50 2021
From: |@brun@ @end|ng |rom udc@e@ (Fernando Pedro Bruna Quintas)
Date: Mon, 15 Feb 2021 09:34:50 +0000
Subject: [R-sig-ME] non-singularity with glmer() in a logit mixed model
In-Reply-To: <6c51a8ae5c4b42bb8fde254752f38c2d@qimrberghofer.edu.au>
References: <PR1PR02MB48897AAF0FE4ED21C84167F992899@PR1PR02MB4889.eurprd02.prod.outlook.com>,
 <6c51a8ae5c4b42bb8fde254752f38c2d@qimrberghofer.edu.au>
Message-ID: <PR1PR02MB48896B6565D2E170DD64CA1692889@PR1PR02MB4889.eurprd02.prod.outlook.com>

Hi, and thank you for your idea, David Duffy. I am sorry if I was not clear. My use of the expression "more restrictive definition" was not in the sense of three categories of the same variable. I tried to say that I have two dependent binomial variables and one  them has less ones. The reason I mentioned that is because they are about a similar phenomenon, that is why I want to compmare the results and the reviewer ask us to use the same explanatory variables even if they are not significant. Indeed, variable y.A is "R&D" and y.B is "process innovation". There is all possible combinations of values for the two variables in different firms: firms with 0-0 in both variables, 1-0, 0-1, or 1-1. Therefore, I need to estimate two models and compare the results. I am having troubles with the model for R&D (in a developing country!).

Best regards

Fernando

________________________________
De: David Duffy <David.Duffy at qimrberghofer.edu.au>
Enviado: lunes, 15 de febrero de 2021 6:14
Para: Fernando Pedro Bruna Quintas <f.bruna at udc.es>; r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>
Asunto: Re: non-singularity with glmer() in a logit mixed model

> The focus of the paper is to compare the results of two dependent variables, Y.A and Y.B for firms nested in 24 regions.
> I am estimating mixed logit models [...] the definition of Y.A is much more restrictive though more interesting than the definition of Y.B.
> Therefore, for Y.A there are far fewer ones for firms in the 24 regions.

I don't know if this is helpful, but you might try a multinomial (or even ordinal, if that is appropriate) outcome (no, y-loose, y-strict) GLMM. There are
a few suitable R packages (eg MCMCglmm).

	[[alternative HTML version deleted]]


From r@v|@v@r@dh@n @end|ng |rom jhu@edu  Mon Feb 15 21:24:30 2021
From: r@v|@v@r@dh@n @end|ng |rom jhu@edu (Ravi Varadhan)
Date: Mon, 15 Feb 2021 20:24:30 +0000
Subject: [R-sig-ME] Prediction of random effects in glmer()
In-Reply-To: <MW4PR01MB6212013F278FB02B3E3ED842F28B9@MW4PR01MB6212.prod.exchangelabs.com>
References: <MW4PR01MB6212013F278FB02B3E3ED842F28B9@MW4PR01MB6212.prod.exchangelabs.com>
Message-ID: <MW4PR01MB6212C126F2C009414E291953F2889@MW4PR01MB6212.prod.exchangelabs.com>

Dear Ben,
Thanks for your response. I went back and looked at the draft JSS paper you sent me.  It does describe how the random effects are predicted as conditional modes, using a penalized, iteratively weighted least squares. However, I still have some questions.  Why is the penalty term ||u||^2 added? What does this mean?  Does glmer then provide standard errors for the predicted random effects (I don't think it does)?

One more question: it would be nice to also have an option for conditional mean and conditional variance of the random effect, although conditional variance would underestimate the true variance of the prediction.

Thank you,
Ravi
________________________________
From: Ravi Varadhan
Sent: Thursday, February 11, 2021 8:30 PM
To: r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>
Subject: Prediction of random effects in glmer()

Hi,
I would like to know how the prediction of random effects is done in the GLMM modeling using the lme4::glmer function, i.e. how the BLUP-like predictions are made in the glmer() function?

Does it use frequentist prediction or empirical Bayes or full Bayes posterior?  Is there any documentation of the prediction methodology?

Thanks in advance.

Ravi

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Mon Feb 15 22:15:40 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Mon, 15 Feb 2021 16:15:40 -0500
Subject: [R-sig-ME] Prediction of random effects in glmer()
In-Reply-To: <MW4PR01MB6212C126F2C009414E291953F2889@MW4PR01MB6212.prod.exchangelabs.com>
References: <MW4PR01MB6212013F278FB02B3E3ED842F28B9@MW4PR01MB6212.prod.exchangelabs.com>
 <MW4PR01MB6212C126F2C009414E291953F2889@MW4PR01MB6212.prod.exchangelabs.com>
Message-ID: <6003e160-69ea-54fe-4936-a30a594af2b4@gmail.com>


   The penalty term ||u||^2 appears first in the likelihood expression 
(eq 11 in the paper),

   int exp( - (sum(d_i(y_obs,u)) + ||u||^2)/2) * C du

where C is a normalization constant I don't feel like writing out.

   The sum(d_i(.)) part is the deviance of the GLM part of the model. 
The other part would come out to exp(-||u||^2/2) if we factored it out; 
this expresses the idea that the u values (the 'spherized' random 
effects, i.e. on a scale where they are iid N(0,1) variables) are 
assumed to be drawn from a Normal distribution.

   This stuff is probably better explained in the original JSS lmer 
paper (where the same penalty term appears, for the same reason).

   An *analog* of standard errors is indeed available for the 
conditional modes (this is also explained in the JSS paper); we call 
these "conditional variances" and "conditional standard deviations" - we 
can't quite call them "standard errors" because the u values are not 
estimates in the technical sense (this is the same song-and-dance as 
when we call something a "BLUP" rather than an "estimate").

   When you call ranef(.) with condVar=TRUE (which is the default), the 
conditional covariance matrices are indeed computed and returned, albeit 
in a rather inconvenient form: attr(ranef(my_model)$grpvar,"postVar") is 
a 3D array of stacked covariance matrices, or a list of 3D arrays (see 
?ranef.merMod).  If you just want the conditional standard deviations 
for each random effect value, as.data.frame(ranef(my_model)) will 
probably be more convenient.

   (Again, the details behind this computation are explained in the JSS 
lmer paper ...)

    Note that these SDs **are not appropriate for testing hypotheses 
about individual levels of the random effect**: one of the tradeoffs of 
using REs in the first place is that you trade parsimony for the ability 
to do hypothesis testing on individual predictions.

   For your second question, I'm not sure what you mean by the 
"conditional mean and conditional variance of the random effect"; can 
you explain further/give an example?

   Ben



On 2/15/21 3:24 PM, Ravi Varadhan wrote:
> Dear Ben,
> Thanks for your response. I went back and looked at the draft JSS paper you sent me.  It does describe how the random effects are predicted as conditional modes, using a penalized, iteratively weighted least squares. However, I still have some questions.  Why is the penalty term ||u||^2 added? What does this mean?  Does glmer then provide standard errors for the predicted random effects (I don't think it does)?
> 
> One more question: it would be nice to also have an option for conditional mean and conditional variance of the random effect, although conditional variance would underestimate the true variance of the prediction.
> 
> Thank you,
> Ravi
> ________________________________
> From: Ravi Varadhan
> Sent: Thursday, February 11, 2021 8:30 PM
> To: r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>
> Subject: Prediction of random effects in glmer()
> 
> Hi,
> I would like to know how the prediction of random effects is done in the GLMM modeling using the lme4::glmer function, i.e. how the BLUP-like predictions are made in the glmer() function?
> 
> Does it use frequentist prediction or empirical Bayes or full Bayes posterior?  Is there any documentation of the prediction methodology?
> 
> Thanks in advance.
> 
> Ravi
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From @pro @end|ng |rom un|me|b@edu@@u  Mon Feb 15 22:25:23 2021
From: @pro @end|ng |rom un|me|b@edu@@u (Andrew Robinson)
Date: Mon, 15 Feb 2021 21:25:23 +0000
Subject: [R-sig-ME] Prediction of random effects in glmer()
In-Reply-To: <6003e160-69ea-54fe-4936-a30a594af2b4@gmail.com>
References: <MW4PR01MB6212013F278FB02B3E3ED842F28B9@MW4PR01MB6212.prod.exchangelabs.com>
 <MW4PR01MB6212C126F2C009414E291953F2889@MW4PR01MB6212.prod.exchangelabs.com>
 <6003e160-69ea-54fe-4936-a30a594af2b4@gmail.com>
Message-ID: <9d6930bc-efcc-4090-a08b-5656c5f2a12d@Spark>

Hi Ben,

I note with interest below:
Note that these SDs **are not appropriate for testing hypotheses
about individual levels of the random effect**: one of the tradeoffs of
using REs in the first place is that you trade parsimony for the ability
to do hypothesis testing on individual predictions.

Does this mean that they are also inappropriate for computing interval predictions for individual predictions?

Where might one read more about this observation?

Many thanks,

Andrew

--
Andrew Robinson
Director, CEBRA and Professor of Biosecurity,
School/s of BioSciences and Mathematics & Statistics
University of Melbourne, VIC 3010 Australia
Tel: (+61) 0403 138 955 Email: apro at unimelb.edu.au
Website: https://researchers.ms.unimelb.edu.au/~apro at unimelb/
I acknowledge the Traditional Owners of the land I inhabit, and pay my respects to their Elders.
On Feb 16, 2021, 8:16 AM +1100, Ben Bolker <bbolker at gmail.com>, wrote:

The penalty term ||u||^2 appears first in the likelihood expression
(eq 11 in the paper),

int exp( - (sum(d_i(y_obs,u)) + ||u||^2)/2) * C du

where C is a normalization constant I don't feel like writing out.

The sum(d_i(.)) part is the deviance of the GLM part of the model.
The other part would come out to exp(-||u||^2/2) if we factored it out;
this expresses the idea that the u values (the 'spherized' random
effects, i.e. on a scale where they are iid N(0,1) variables) are
assumed to be drawn from a Normal distribution.

This stuff is probably better explained in the original JSS lmer
paper (where the same penalty term appears, for the same reason).

An *analog* of standard errors is indeed available for the
conditional modes (this is also explained in the JSS paper); we call
these "conditional variances" and "conditional standard deviations" - we
can't quite call them "standard errors" because the u values are not
estimates in the technical sense (this is the same song-and-dance as
when we call something a "BLUP" rather than an "estimate").

When you call ranef(.) with condVar=TRUE (which is the default), the
conditional covariance matrices are indeed computed and returned, albeit
in a rather inconvenient form: attr(ranef(my_model)$grpvar,"postVar") is
a 3D array of stacked covariance matrices, or a list of 3D arrays (see
?ranef.merMod). If you just want the conditional standard deviations
for each random effect value, as.data.frame(ranef(my_model)) will
probably be more convenient.

(Again, the details behind this computation are explained in the JSS
lmer paper ...)

Note that these SDs **are not appropriate for testing hypotheses
about individual levels of the random effect**: one of the tradeoffs of
using REs in the first place is that you trade parsimony for the ability
to do hypothesis testing on individual predictions.

For your second question, I'm not sure what you mean by the
"conditional mean and conditional variance of the random effect"; can
you explain further/give an example?

Ben



On 2/15/21 3:24 PM, Ravi Varadhan wrote:
Dear Ben,
Thanks for your response. I went back and looked at the draft JSS paper you sent me. It does describe how the random effects are predicted as conditional modes, using a penalized, iteratively weighted least squares. However, I still have some questions. Why is the penalty term ||u||^2 added? What does this mean? Does glmer then provide standard errors for the predicted random effects (I don't think it does)?

One more question: it would be nice to also have an option for conditional mean and conditional variance of the random effect, although conditional variance would underestimate the true variance of the prediction.

Thank you,
Ravi
________________________________
From: Ravi Varadhan
Sent: Thursday, February 11, 2021 8:30 PM
To: r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>
Subject: Prediction of random effects in glmer()

Hi,
I would like to know how the prediction of random effects is done in the GLMM modeling using the lme4::glmer function, i.e. how the BLUP-like predictions are made in the glmer() function?

Does it use frequentist prediction or empirical Bayes or full Bayes posterior? Is there any documentation of the prediction methodology?

Thanks in advance.

Ravi

[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Mon Feb 15 22:39:57 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Mon, 15 Feb 2021 16:39:57 -0500
Subject: [R-sig-ME] Prediction of random effects in glmer()
In-Reply-To: <9d6930bc-efcc-4090-a08b-5656c5f2a12d@Spark>
References: <MW4PR01MB6212013F278FB02B3E3ED842F28B9@MW4PR01MB6212.prod.exchangelabs.com>
 <MW4PR01MB6212C126F2C009414E291953F2889@MW4PR01MB6212.prod.exchangelabs.com>
 <6003e160-69ea-54fe-4936-a30a594af2b4@gmail.com>
 <9d6930bc-efcc-4090-a08b-5656c5f2a12d@Spark>
Message-ID: <387f3855-7b2d-8098-7a99-424ecce24697@gmail.com>

   Good question.
   Going back to a previous answer in this thread; these are empirical 
Bayesian prediction intervals. That is, they may be well-calibrated but 
they don't have the same theoretical status as 'true' frequentist CIs.

   To be completely honest, I don't know what is or isn't known about 
the calibration properties of intervals based on the conditional SD (I 
would guess they're not bad but really don't know the theory).

    This looks like a good reference on EB confidence intervals:

Cox, D. R. ?Prediction Intervals and Empirical Bayes Confidence 
Intervals.? Journal of Applied Probability 12, no. S1 (ed 1975): 47?55. 
https://doi.org/10.1017/S0021900200047550.

   Based on a *very* quick read it seems as though constructing CIs for 
the conditional modes based on the SDs is OK subject to the assumption 
that we can plug in/condition on the 'theta'/variance estimates ...


On 2/15/21 4:25 PM, Andrew Robinson wrote:
> Hi Ben,
> 
> I note with interest below:
> 
>     Note that these SDs **are not appropriate for testing hypotheses
> 
>     about individual levels of the random effect**: one of the tradeoffs of
> 
>     using REs in the first place is that you trade parsimony for the ability
> 
>     to do hypothesis testing on individual predictions.
> 
> 
> Does this mean that they are also inappropriate for computing interval 
> predictions for individual predictions?
> 
> Where might one read more about this observation?
> 
> Many thanks,
> 
> Andrew
> 
> -- 
> Andrew Robinson
> Director, CEBRA and Professor of Biosecurity,
> School/s of BioSciences and Mathematics & Statistics
> University of Melbourne, VIC 3010 Australia
> Tel: (+61) 0403 138 955 Email:?apro at unimelb.edu.au
> Website:?https://researchers.ms.unimelb.edu.au/~apro at unimelb/
> I?acknowledge the Traditional Owners of the land I inhabit, and pay my 
> respects to their Elders.
> On Feb 16, 2021, 8:16 AM +1100, Ben Bolker <bbolker at gmail.com>, wrote:
>>
>> The penalty term ||u||^2 appears first in the likelihood expression
>> (eq 11 in the paper),
>>
>> int exp( - (sum(d_i(y_obs,u)) + ||u||^2)/2) * C du
>>
>> where C is a normalization constant I don't feel like writing out.
>>
>> The sum(d_i(.)) part is the deviance of the GLM part of the model.
>> The other part would come out to exp(-||u||^2/2) if we factored it out;
>> this expresses the idea that the u values (the 'spherized' random
>> effects, i.e. on a scale where they are iid N(0,1) variables) are
>> assumed to be drawn from a Normal distribution.
>>
>> This stuff is probably better explained in the original JSS lmer
>> paper (where the same penalty term appears, for the same reason).
>>
>> An *analog* of standard errors is indeed available for the
>> conditional modes (this is also explained in the JSS paper); we call
>> these "conditional variances" and "conditional standard deviations" - we
>> can't quite call them "standard errors" because the u values are not
>> estimates in the technical sense (this is the same song-and-dance as
>> when we call something a "BLUP" rather than an "estimate").
>>
>> When you call ranef(.) with condVar=TRUE (which is the default), the
>> conditional covariance matrices are indeed computed and returned, albeit
>> in a rather inconvenient form: attr(ranef(my_model)$grpvar,"postVar") is
>> a 3D array of stacked covariance matrices, or a list of 3D arrays (see
>> ?ranef.merMod). If you just want the conditional standard deviations
>> for each random effect value, as.data.frame(ranef(my_model)) will
>> probably be more convenient.
>>
>> (Again, the details behind this computation are explained in the JSS
>> lmer paper ...)
>>
>> Note that these SDs **are not appropriate for testing hypotheses
>> about individual levels of the random effect**: one of the tradeoffs of
>> using REs in the first place is that you trade parsimony for the ability
>> to do hypothesis testing on individual predictions.
>>
>> For your second question, I'm not sure what you mean by the
>> "conditional mean and conditional variance of the random effect"; can
>> you explain further/give an example?
>>
>> Ben
>>
>>
>>
>> On 2/15/21 3:24 PM, Ravi Varadhan wrote:
>>> Dear Ben,
>>> Thanks for your response. I went back and looked at the draft JSS 
>>> paper you sent me. It does describe how the random effects are 
>>> predicted as conditional modes, using a penalized, iteratively 
>>> weighted least squares. However, I still have some questions. Why is 
>>> the penalty term ||u||^2 added? What does this mean? Does glmer then 
>>> provide standard errors for the predicted random effects (I don't 
>>> think it does)?
>>>
>>> One more question: it would be nice to also have an option for 
>>> conditional mean and conditional variance of the random effect, 
>>> although conditional variance would underestimate the true variance 
>>> of the prediction.
>>>
>>> Thank you,
>>> Ravi
>>> ________________________________
>>> From: Ravi Varadhan
>>> Sent: Thursday, February 11, 2021 8:30 PM
>>> To: r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>
>>> Subject: Prediction of random effects in glmer()
>>>
>>> Hi,
>>> I would like to know how the prediction of random effects is done in 
>>> the GLMM modeling using the lme4::glmer function, i.e. how the 
>>> BLUP-like predictions are made in the glmer() function?
>>>
>>> Does it use frequentist prediction or empirical Bayes or full Bayes 
>>> posterior? Is there any documentation of the prediction methodology?
>>>
>>> Thanks in advance.
>>>
>>> Ravi
>>>
>>> [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models 
>>> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models 
>> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>


From @pro @end|ng |rom un|me|b@edu@@u  Mon Feb 15 22:58:19 2021
From: @pro @end|ng |rom un|me|b@edu@@u (Andrew Robinson)
Date: Mon, 15 Feb 2021 21:58:19 +0000
Subject: [R-sig-ME] Prediction of random effects in glmer()
In-Reply-To: <387f3855-7b2d-8098-7a99-424ecce24697@gmail.com>
References: <MW4PR01MB6212013F278FB02B3E3ED842F28B9@MW4PR01MB6212.prod.exchangelabs.com>
 <MW4PR01MB6212C126F2C009414E291953F2889@MW4PR01MB6212.prod.exchangelabs.com>
 <6003e160-69ea-54fe-4936-a30a594af2b4@gmail.com>
 <9d6930bc-efcc-4090-a08b-5656c5f2a12d@Spark>
 <387f3855-7b2d-8098-7a99-424ecce24697@gmail.com>
Message-ID: <4c7b45e2-4d43-418d-b4cd-90806acb693f@Spark>

Thanks Ben.

To be more specific, I want to infer from your comment that the intervals are not guaranteed to cover the true unknown value 95% of the time under an infinite sequence of experiments. Is there anything else?

Thanks very much for the Cox paper - I hadn't seen that.

Cheers,

Andrew

--
Andrew Robinson
Director, CEBRA and Professor of Biosecurity,
School/s of BioSciences and Mathematics & Statistics
University of Melbourne, VIC 3010 Australia
Tel: (+61) 0403 138 955 Email: apro at unimelb.edu.au
Website: https://researchers.ms.unimelb.edu.au/~apro at unimelb/
I acknowledge the Traditional Owners of the land I inhabit, and pay my respects to their Elders.
On Feb 16, 2021, 8:40 AM +1100, Ben Bolker <bbolker at gmail.com>, wrote:
Good question.
Going back to a previous answer in this thread; these are empirical
Bayesian prediction intervals. That is, they may be well-calibrated but
they don't have the same theoretical status as 'true' frequentist CIs.

To be completely honest, I don't know what is or isn't known about
the calibration properties of intervals based on the conditional SD (I
would guess they're not bad but really don't know the theory).

This looks like a good reference on EB confidence intervals:

Cox, D. R. ?Prediction Intervals and Empirical Bayes Confidence
Intervals.? Journal of Applied Probability 12, no. S1 (ed 1975): 47?55.
https://doi.org/10.1017/S0021900200047550.

Based on a *very* quick read it seems as though constructing CIs for
the conditional modes based on the SDs is OK subject to the assumption
that we can plug in/condition on the 'theta'/variance estimates ...


On 2/15/21 4:25 PM, Andrew Robinson wrote:
Hi Ben,

I note with interest below:

Note that these SDs **are not appropriate for testing hypotheses

about individual levels of the random effect**: one of the tradeoffs of

using REs in the first place is that you trade parsimony for the ability

to do hypothesis testing on individual predictions.


Does this mean that they are also inappropriate for computing interval
predictions for individual predictions?

Where might one read more about this observation?

Many thanks,

Andrew

--
Andrew Robinson
Director, CEBRA and Professor of Biosecurity,
School/s of BioSciences and Mathematics & Statistics
University of Melbourne, VIC 3010 Australia
Tel: (+61) 0403 138 955 Email: apro at unimelb.edu.au
Website: https://researchers.ms.unimelb.edu.au/~apro at unimelb/
I acknowledge the Traditional Owners of the land I inhabit, and pay my
respects to their Elders.
On Feb 16, 2021, 8:16 AM +1100, Ben Bolker <bbolker at gmail.com>, wrote:

The penalty term ||u||^2 appears first in the likelihood expression
(eq 11 in the paper),

int exp( - (sum(d_i(y_obs,u)) + ||u||^2)/2) * C du

where C is a normalization constant I don't feel like writing out.

The sum(d_i(.)) part is the deviance of the GLM part of the model.
The other part would come out to exp(-||u||^2/2) if we factored it out;
this expresses the idea that the u values (the 'spherized' random
effects, i.e. on a scale where they are iid N(0,1) variables) are
assumed to be drawn from a Normal distribution.

This stuff is probably better explained in the original JSS lmer
paper (where the same penalty term appears, for the same reason).

An *analog* of standard errors is indeed available for the
conditional modes (this is also explained in the JSS paper); we call
these "conditional variances" and "conditional standard deviations" - we
can't quite call them "standard errors" because the u values are not
estimates in the technical sense (this is the same song-and-dance as
when we call something a "BLUP" rather than an "estimate").

When you call ranef(.) with condVar=TRUE (which is the default), the
conditional covariance matrices are indeed computed and returned, albeit
in a rather inconvenient form: attr(ranef(my_model)$grpvar,"postVar") is
a 3D array of stacked covariance matrices, or a list of 3D arrays (see
?ranef.merMod). If you just want the conditional standard deviations
for each random effect value, as.data.frame(ranef(my_model)) will
probably be more convenient.

(Again, the details behind this computation are explained in the JSS
lmer paper ...)

Note that these SDs **are not appropriate for testing hypotheses
about individual levels of the random effect**: one of the tradeoffs of
using REs in the first place is that you trade parsimony for the ability
to do hypothesis testing on individual predictions.

For your second question, I'm not sure what you mean by the
"conditional mean and conditional variance of the random effect"; can
you explain further/give an example?

Ben



On 2/15/21 3:24 PM, Ravi Varadhan wrote:
Dear Ben,
Thanks for your response. I went back and looked at the draft JSS
paper you sent me. It does describe how the random effects are
predicted as conditional modes, using a penalized, iteratively
weighted least squares. However, I still have some questions. Why is
the penalty term ||u||^2 added? What does this mean? Does glmer then
provide standard errors for the predicted random effects (I don't
think it does)?

One more question: it would be nice to also have an option for
conditional mean and conditional variance of the random effect,
although conditional variance would underestimate the true variance
of the prediction.

Thank you,
Ravi
________________________________
From: Ravi Varadhan
Sent: Thursday, February 11, 2021 8:30 PM
To: r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>
Subject: Prediction of random effects in glmer()

Hi,
I would like to know how the prediction of random effects is done in
the GLMM modeling using the lme4::glmer function, i.e. how the
BLUP-like predictions are made in the glmer() function?

Does it use frequentist prediction or empirical Bayes or full Bayes
posterior? Is there any documentation of the prediction methodology?

Thanks in advance.

Ravi

[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>


_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>



	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Mon Feb 15 23:07:12 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Mon, 15 Feb 2021 17:07:12 -0500
Subject: [R-sig-ME] Prediction of random effects in glmer()
In-Reply-To: <4c7b45e2-4d43-418d-b4cd-90806acb693f@Spark>
References: <MW4PR01MB6212013F278FB02B3E3ED842F28B9@MW4PR01MB6212.prod.exchangelabs.com>
 <MW4PR01MB6212C126F2C009414E291953F2889@MW4PR01MB6212.prod.exchangelabs.com>
 <6003e160-69ea-54fe-4936-a30a594af2b4@gmail.com>
 <9d6930bc-efcc-4090-a08b-5656c5f2a12d@Spark>
 <387f3855-7b2d-8098-7a99-424ecce24697@gmail.com>
 <4c7b45e2-4d43-418d-b4cd-90806acb693f@Spark>
Message-ID: <a12f9865-af1e-3e0e-5c6c-87ec76708bb2@gmail.com>

    I don't know. I suspect that they *will* have nominal or 
close-to-nominal coverage (a restatement of your comment below) under 
reasonably weak asymptotic assumptions.
   It wouldn't be too hard to do some simulations to check the coverage 
for some simple examples, but I shouldn't succumb to the temptation 
right now.

   cheers
    Ben

On 2/15/21 4:58 PM, Andrew Robinson wrote:
> Thanks Ben.
> 
> To be more specific, I want to infer from your comment that the 
> intervals are not guaranteed to cover the true unknown value 95% of the 
> time under an infinite sequence of experiments. Is there anything else?
> 
> Thanks very much for the Cox paper - I hadn't seen that.
> 
> Cheers,
> 
> Andrew
> 
> -- 
> Andrew Robinson
> Director, CEBRA and Professor of Biosecurity,
> School/s of BioSciences and Mathematics & Statistics
> University of Melbourne, VIC 3010 Australia
> Tel: (+61) 0403 138 955 Email:?apro at unimelb.edu.au
> Website:?https://researchers.ms.unimelb.edu.au/~apro at unimelb/
> I?acknowledge the Traditional Owners of the land I inhabit, and pay my 
> respects to their Elders.
> On Feb 16, 2021, 8:40 AM +1100, Ben Bolker <bbolker at gmail.com>, wrote:
>> Good question.
>> Going back to a previous answer in this thread; these are empirical
>> Bayesian prediction intervals. That is, they may be well-calibrated but
>> they don't have the same theoretical status as 'true' frequentist CIs.
>>
>> To be completely honest, I don't know what is or isn't known about
>> the calibration properties of intervals based on the conditional SD (I
>> would guess they're not bad but really don't know the theory).
>>
>> This looks like a good reference on EB confidence intervals:
>>
>> Cox, D. R. ?Prediction Intervals and Empirical Bayes Confidence
>> Intervals.? Journal of Applied Probability 12, no. S1 (ed 1975): 47?55.
>> https://doi.org/10.1017/S0021900200047550.
>>
>> Based on a *very* quick read it seems as though constructing CIs for
>> the conditional modes based on the SDs is OK subject to the assumption
>> that we can plug in/condition on the 'theta'/variance estimates ...
>>
>>
>> On 2/15/21 4:25 PM, Andrew Robinson wrote:
>>> Hi Ben,
>>>
>>> I note with interest below:
>>>
>>> Note that these SDs **are not appropriate for testing hypotheses
>>>
>>> about individual levels of the random effect**: one of the tradeoffs of
>>>
>>> using REs in the first place is that you trade parsimony for the ability
>>>
>>> to do hypothesis testing on individual predictions.
>>>
>>>
>>> Does this mean that they are also inappropriate for computing interval
>>> predictions for individual predictions?
>>>
>>> Where might one read more about this observation?
>>>
>>> Many thanks,
>>>
>>> Andrew
>>>
>>> --
>>> Andrew Robinson
>>> Director, CEBRA and Professor of Biosecurity,
>>> School/s of BioSciences and Mathematics & Statistics
>>> University of Melbourne, VIC 3010 Australia
>>> Tel: (+61) 0403 138 955 Email:?apro at unimelb.edu.au
>>> Website:?https://researchers.ms.unimelb.edu.au/~apro at unimelb/
>>> I?acknowledge the Traditional Owners of the land I inhabit, and pay my
>>> respects to their Elders.
>>> On Feb 16, 2021, 8:16 AM +1100, Ben Bolker <bbolker at gmail.com>, wrote:
>>>>
>>>> The penalty term ||u||^2 appears first in the likelihood expression
>>>> (eq 11 in the paper),
>>>>
>>>> int exp( - (sum(d_i(y_obs,u)) + ||u||^2)/2) * C du
>>>>
>>>> where C is a normalization constant I don't feel like writing out.
>>>>
>>>> The sum(d_i(.)) part is the deviance of the GLM part of the model.
>>>> The other part would come out to exp(-||u||^2/2) if we factored it out;
>>>> this expresses the idea that the u values (the 'spherized' random
>>>> effects, i.e. on a scale where they are iid N(0,1) variables) are
>>>> assumed to be drawn from a Normal distribution.
>>>>
>>>> This stuff is probably better explained in the original JSS lmer
>>>> paper (where the same penalty term appears, for the same reason).
>>>>
>>>> An *analog* of standard errors is indeed available for the
>>>> conditional modes (this is also explained in the JSS paper); we call
>>>> these "conditional variances" and "conditional standard deviations" - we
>>>> can't quite call them "standard errors" because the u values are not
>>>> estimates in the technical sense (this is the same song-and-dance as
>>>> when we call something a "BLUP" rather than an "estimate").
>>>>
>>>> When you call ranef(.) with condVar=TRUE (which is the default), the
>>>> conditional covariance matrices are indeed computed and returned, albeit
>>>> in a rather inconvenient form: attr(ranef(my_model)$grpvar,"postVar") is
>>>> a 3D array of stacked covariance matrices, or a list of 3D arrays (see
>>>> ?ranef.merMod). If you just want the conditional standard deviations
>>>> for each random effect value, as.data.frame(ranef(my_model)) will
>>>> probably be more convenient.
>>>>
>>>> (Again, the details behind this computation are explained in the JSS
>>>> lmer paper ...)
>>>>
>>>> Note that these SDs **are not appropriate for testing hypotheses
>>>> about individual levels of the random effect**: one of the tradeoffs of
>>>> using REs in the first place is that you trade parsimony for the ability
>>>> to do hypothesis testing on individual predictions.
>>>>
>>>> For your second question, I'm not sure what you mean by the
>>>> "conditional mean and conditional variance of the random effect"; can
>>>> you explain further/give an example?
>>>>
>>>> Ben
>>>>
>>>>
>>>>
>>>> On 2/15/21 3:24 PM, Ravi Varadhan wrote:
>>>>> Dear Ben,
>>>>> Thanks for your response. I went back and looked at the draft JSS
>>>>> paper you sent me. It does describe how the random effects are
>>>>> predicted as conditional modes, using a penalized, iteratively
>>>>> weighted least squares. However, I still have some questions. Why is
>>>>> the penalty term ||u||^2 added? What does this mean? Does glmer then
>>>>> provide standard errors for the predicted random effects (I don't
>>>>> think it does)?
>>>>>
>>>>> One more question: it would be nice to also have an option for
>>>>> conditional mean and conditional variance of the random effect,
>>>>> although conditional variance would underestimate the true variance
>>>>> of the prediction.
>>>>>
>>>>> Thank you,
>>>>> Ravi
>>>>> ________________________________
>>>>> From: Ravi Varadhan
>>>>> Sent: Thursday, February 11, 2021 8:30 PM
>>>>> To: r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>
>>>>> Subject: Prediction of random effects in glmer()
>>>>>
>>>>> Hi,
>>>>> I would like to know how the prediction of random effects is done in
>>>>> the GLMM modeling using the lme4::glmer function, i.e. how the
>>>>> BLUP-like predictions are made in the glmer() function?
>>>>>
>>>>> Does it use frequentist prediction or empirical Bayes or full Bayes
>>>>> posterior? Is there any documentation of the prediction methodology?
>>>>>
>>>>> Thanks in advance.
>>>>>
>>>>> Ravi
>>>>>
>>>>> [[alternative HTML version deleted]]
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models 
>>>>> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>>> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models 
>>>>> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
>>>>>
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models 
>>>> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>>>> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models 
>>>> <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>
>>>>
>>


From @pro @end|ng |rom un|me|b@edu@@u  Mon Feb 15 23:29:26 2021
From: @pro @end|ng |rom un|me|b@edu@@u (Andrew Robinson)
Date: Mon, 15 Feb 2021 22:29:26 +0000
Subject: [R-sig-ME] Prediction of random effects in glmer()
In-Reply-To: <a12f9865-af1e-3e0e-5c6c-87ec76708bb2@gmail.com>
References: <MW4PR01MB6212013F278FB02B3E3ED842F28B9@MW4PR01MB6212.prod.exchangelabs.com>
 <MW4PR01MB6212C126F2C009414E291953F2889@MW4PR01MB6212.prod.exchangelabs.com>
 <6003e160-69ea-54fe-4936-a30a594af2b4@gmail.com>
 <9d6930bc-efcc-4090-a08b-5656c5f2a12d@Spark>
 <387f3855-7b2d-8098-7a99-424ecce24697@gmail.com>
 <4c7b45e2-4d43-418d-b4cd-90806acb693f@Spark>
 <a12f9865-af1e-3e0e-5c6c-87ec76708bb2@gmail.com>
Message-ID: <4751777e-066e-4811-928a-6e138b8790cd@Spark>

I was thinking the same two things!  Happy to discuss offline at some point if you like.

As a card-carrying sometime Frequentist, coverage is what I care about.

Cheers,

Andrew

--
Andrew Robinson
Director, CEBRA and Professor of Biosecurity,
School/s of BioSciences and Mathematics & Statistics
University of Melbourne, VIC 3010 Australia
Tel: (+61) 0403 138 955 Email: apro at unimelb.edu.au
Website: https://researchers.ms.unimelb.edu.au/~apro at unimelb/
I acknowledge the Traditional Owners of the land I inhabit, and pay my respects to their Elders.
On Feb 16, 2021, 9:07 AM +1100, Ben Bolker <bbolker at gmail.com>, wrote:
I don't know. I suspect that they *will* have nominal or
close-to-nominal coverage (a restatement of your comment below) under
reasonably weak asymptotic assumptions.
It wouldn't be too hard to do some simulations to check the coverage
for some simple examples, but I shouldn't succumb to the temptation
right now.

cheers
Ben

On 2/15/21 4:58 PM, Andrew Robinson wrote:
Thanks Ben.

To be more specific, I want to infer from your comment that the
intervals are not guaranteed to cover the true unknown value 95% of the
time under an infinite sequence of experiments. Is there anything else?

Thanks very much for the Cox paper - I hadn't seen that.

Cheers,

Andrew

--
Andrew Robinson
Director, CEBRA and Professor of Biosecurity,
School/s of BioSciences and Mathematics & Statistics
University of Melbourne, VIC 3010 Australia
Tel: (+61) 0403 138 955 Email: apro at unimelb.edu.au
Website: https://researchers.ms.unimelb.edu.au/~apro at unimelb/
I acknowledge the Traditional Owners of the land I inhabit, and pay my
respects to their Elders.
On Feb 16, 2021, 8:40 AM +1100, Ben Bolker <bbolker at gmail.com>, wrote:
Good question.
Going back to a previous answer in this thread; these are empirical
Bayesian prediction intervals. That is, they may be well-calibrated but
they don't have the same theoretical status as 'true' frequentist CIs.

To be completely honest, I don't know what is or isn't known about
the calibration properties of intervals based on the conditional SD (I
would guess they're not bad but really don't know the theory).

This looks like a good reference on EB confidence intervals:

Cox, D. R. ?Prediction Intervals and Empirical Bayes Confidence
Intervals.? Journal of Applied Probability 12, no. S1 (ed 1975): 47?55.
https://doi.org/10.1017/S0021900200047550.

Based on a *very* quick read it seems as though constructing CIs for
the conditional modes based on the SDs is OK subject to the assumption
that we can plug in/condition on the 'theta'/variance estimates ...


On 2/15/21 4:25 PM, Andrew Robinson wrote:
Hi Ben,

I note with interest below:

Note that these SDs **are not appropriate for testing hypotheses

about individual levels of the random effect**: one of the tradeoffs of

using REs in the first place is that you trade parsimony for the ability

to do hypothesis testing on individual predictions.


Does this mean that they are also inappropriate for computing interval
predictions for individual predictions?

Where might one read more about this observation?

Many thanks,

Andrew

--
Andrew Robinson
Director, CEBRA and Professor of Biosecurity,
School/s of BioSciences and Mathematics & Statistics
University of Melbourne, VIC 3010 Australia
Tel: (+61) 0403 138 955 Email: apro at unimelb.edu.au
Website: https://researchers.ms.unimelb.edu.au/~apro at unimelb/
I acknowledge the Traditional Owners of the land I inhabit, and pay my
respects to their Elders.
On Feb 16, 2021, 8:16 AM +1100, Ben Bolker <bbolker at gmail.com>, wrote:

The penalty term ||u||^2 appears first in the likelihood expression
(eq 11 in the paper),

int exp( - (sum(d_i(y_obs,u)) + ||u||^2)/2) * C du

where C is a normalization constant I don't feel like writing out.

The sum(d_i(.)) part is the deviance of the GLM part of the model.
The other part would come out to exp(-||u||^2/2) if we factored it out;
this expresses the idea that the u values (the 'spherized' random
effects, i.e. on a scale where they are iid N(0,1) variables) are
assumed to be drawn from a Normal distribution.

This stuff is probably better explained in the original JSS lmer
paper (where the same penalty term appears, for the same reason).

An *analog* of standard errors is indeed available for the
conditional modes (this is also explained in the JSS paper); we call
these "conditional variances" and "conditional standard deviations" - we
can't quite call them "standard errors" because the u values are not
estimates in the technical sense (this is the same song-and-dance as
when we call something a "BLUP" rather than an "estimate").

When you call ranef(.) with condVar=TRUE (which is the default), the
conditional covariance matrices are indeed computed and returned, albeit
in a rather inconvenient form: attr(ranef(my_model)$grpvar,"postVar") is
a 3D array of stacked covariance matrices, or a list of 3D arrays (see
?ranef.merMod). If you just want the conditional standard deviations
for each random effect value, as.data.frame(ranef(my_model)) will
probably be more convenient.

(Again, the details behind this computation are explained in the JSS
lmer paper ...)

Note that these SDs **are not appropriate for testing hypotheses
about individual levels of the random effect**: one of the tradeoffs of
using REs in the first place is that you trade parsimony for the ability
to do hypothesis testing on individual predictions.

For your second question, I'm not sure what you mean by the
"conditional mean and conditional variance of the random effect"; can
you explain further/give an example?

Ben



On 2/15/21 3:24 PM, Ravi Varadhan wrote:
Dear Ben,
Thanks for your response. I went back and looked at the draft JSS
paper you sent me. It does describe how the random effects are
predicted as conditional modes, using a penalized, iteratively
weighted least squares. However, I still have some questions. Why is
the penalty term ||u||^2 added? What does this mean? Does glmer then
provide standard errors for the predicted random effects (I don't
think it does)?

One more question: it would be nice to also have an option for
conditional mean and conditional variance of the random effect,
although conditional variance would underestimate the true variance
of the prediction.

Thank you,
Ravi
________________________________
From: Ravi Varadhan
Sent: Thursday, February 11, 2021 8:30 PM
To: r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>
Subject: Prediction of random effects in glmer()

Hi,
I would like to know how the prediction of random effects is done in
the GLMM modeling using the lme4::glmer function, i.e. how the
BLUP-like predictions are made in the glmer() function?

Does it use frequentist prediction or empirical Bayes or full Bayes
posterior? Is there any documentation of the prediction methodology?

Thanks in advance.

Ravi

[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>


_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
<https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>>




	[[alternative HTML version deleted]]


From r@v|@v@r@dh@n @end|ng |rom jhu@edu  Tue Feb 16 00:25:49 2021
From: r@v|@v@r@dh@n @end|ng |rom jhu@edu (Ravi Varadhan)
Date: Mon, 15 Feb 2021 23:25:49 +0000
Subject: [R-sig-ME] Prediction of random effects in glmer()
In-Reply-To: <MW4PR01MB6212C126F2C009414E291953F2889@MW4PR01MB6212.prod.exchangelabs.com>
References: <MW4PR01MB6212013F278FB02B3E3ED842F28B9@MW4PR01MB6212.prod.exchangelabs.com>,
 <MW4PR01MB6212C126F2C009414E291953F2889@MW4PR01MB6212.prod.exchangelabs.com>
Message-ID: <MW4PR01MB6212D7ED14224F8FF3949BAFF2889@MW4PR01MB6212.prod.exchangelabs.com>

Ben,
Thanks for explaining this.  It is quite obvious where the ||u||^2 comes from (after you pointed it out!).  I was looking at the paper by Booth and Hobert (JASA 1998) on computing the standard errors of predicted random effects.  Their Eqs. (6) and (8) are what I meant by conditional mean (E[u | y; \theta]) and conditional variance (Var[u | y; \theta]).
Best,
Ravi
________________________________
From: Ravi Varadhan <ravi.varadhan at jhu.edu>
Sent: Monday, February 15, 2021 3:24 PM
To: r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>
Cc: bolker at mcmaster.ca <bolker at mcmaster.ca>
Subject: Re: Prediction of random effects in glmer()

Dear Ben,
Thanks for your response. I went back and looked at the draft JSS paper you sent me.  It does describe how the random effects are predicted as conditional modes, using a penalized, iteratively weighted least squares. However, I still have some questions.  Why is the penalty term ||u||^2 added? What does this mean?  Does glmer then provide standard errors for the predicted random effects (I don't think it does)?

One more question: it would be nice to also have an option for conditional mean and conditional variance of the random effect, although conditional variance would underestimate the true variance of the prediction.

Thank you,
Ravi
________________________________
From: Ravi Varadhan
Sent: Thursday, February 11, 2021 8:30 PM
To: r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>
Subject: Prediction of random effects in glmer()

Hi,
I would like to know how the prediction of random effects is done in the GLMM modeling using the lme4::glmer function, i.e. how the BLUP-like predictions are made in the glmer() function?

Does it use frequentist prediction or empirical Bayes or full Bayes posterior?  Is there any documentation of the prediction methodology?

Thanks in advance.

Ravi

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Tue Feb 16 02:04:05 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Mon, 15 Feb 2021 20:04:05 -0500
Subject: [R-sig-ME] Prediction of random effects in glmer()
In-Reply-To: <MW4PR01MB6212D7ED14224F8FF3949BAFF2889@MW4PR01MB6212.prod.exchangelabs.com>
References: <MW4PR01MB6212013F278FB02B3E3ED842F28B9@MW4PR01MB6212.prod.exchangelabs.com>
 <MW4PR01MB6212C126F2C009414E291953F2889@MW4PR01MB6212.prod.exchangelabs.com>
 <MW4PR01MB6212D7ED14224F8FF3949BAFF2889@MW4PR01MB6212.prod.exchangelabs.com>
Message-ID: <b6f74d87-7f6d-017e-8b5c-93f2fdb0f0ef@gmail.com>

   Thanks for the reference.  It looks like Booth and Hobert's paper 
would give improved point and interval estimates for the random effects, 
and the components necessary to do the computations are probably all 
available, but it would take at least a little bit of effort to work 
through the paper in enough detail to do the actual implementation ... 
(anyone looking for a master's project in statistics ... ??)
   In the meantime you'll have to make do with the naive plug-in 
estimates provided by lme4. (Or use parametric bootstrapping if you're 
feeling very patient.)

   cheers
    Ben


On 2/15/21 6:25 PM, Ravi Varadhan wrote:
> Ben,
> Thanks for explaining this.  It is quite obvious where the ||u||^2 comes from (after you pointed it out!).  I was looking at the paper by Booth and Hobert (JASA 1998) on computing the standard errors of predicted random effects.  Their Eqs. (6) and (8) are what I meant by conditional mean (E[u | y; \theta]) and conditional variance (Var[u | y; \theta]).
> Best,
> Ravi
> ________________________________
> From: Ravi Varadhan <ravi.varadhan at jhu.edu>
> Sent: Monday, February 15, 2021 3:24 PM
> To: r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>
> Cc: bolker at mcmaster.ca <bolker at mcmaster.ca>
> Subject: Re: Prediction of random effects in glmer()
> 
> Dear Ben,
> Thanks for your response. I went back and looked at the draft JSS paper you sent me.  It does describe how the random effects are predicted as conditional modes, using a penalized, iteratively weighted least squares. However, I still have some questions.  Why is the penalty term ||u||^2 added? What does this mean?  Does glmer then provide standard errors for the predicted random effects (I don't think it does)?
> 
> One more question: it would be nice to also have an option for conditional mean and conditional variance of the random effect, although conditional variance would underestimate the true variance of the prediction.
> 
> Thank you,
> Ravi
> ________________________________
> From: Ravi Varadhan
> Sent: Thursday, February 11, 2021 8:30 PM
> To: r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>
> Subject: Prediction of random effects in glmer()
> 
> Hi,
> I would like to know how the prediction of random effects is done in the GLMM modeling using the lme4::glmer function, i.e. how the BLUP-like predictions are made in the glmer() function?
> 
> Does it use frequentist prediction or empirical Bayes or full Bayes posterior?  Is there any documentation of the prediction methodology?
> 
> Thanks in advance.
> 
> Ravi
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From pr|db @end|ng |rom protonm@||@com  Tue Feb 16 04:02:07 2021
From: pr|db @end|ng |rom protonm@||@com (Peter R Law)
Date: Tue, 16 Feb 2021 03:02:07 +0000
Subject: [R-sig-ME] lmer code for multiple random slopes
Message-ID: <34JKCz24u8awawkhTLmboO_cBRWW-m0XAb0frTUb9YqspQe1VeBBWUvfqKd3-QIMLeKpiDUyzhN0X6aqRlEqwX1LmBfg3gn9EB2XCa5v62s=@protonmail.com>

I am trying to fit a model with two covariates, x and z say, for response y, with a random factor g and want each of x and y to have a random slope. I expected

lmer(y ~ x + z + (x+z|g),...)

to fit a model with 6 random variance components, the intercept, two slopes and three correlations. But I got an error message saying there were 74 random variance components and my data was insufficient to fit the model. Yet

lmer(y ~ x + z + (x+z||g),...)

returned what I expected, a model with the random intercept and two slopes but no correlations. How is lmer interpreting the first line of code above and how I would code for what I want. I have not been able to find any examples in the literature or online that help me but I may have easily missed something so if anyone knows of a useful link that'd be great. The only examples of multiple random slopes I've seen take the form

lmer(y~x + z +(x|g) + (z|g),...)

specifically excluding correlations between the random slopes and intercept of the two predictors. Even if the latter is a more sensible approach I'd like to understand the coding issue.

Thanks.

Peter

Sent with [ProtonMail](https://protonmail.com) Secure Email.
	[[alternative HTML version deleted]]


From me @end|ng |rom ph||||p@|d@y@com  Tue Feb 16 14:18:11 2021
From: me @end|ng |rom ph||||p@|d@y@com (Phillip Alday)
Date: Tue, 16 Feb 2021 14:18:11 +0100
Subject: [R-sig-ME] lmer code for multiple random slopes
In-Reply-To: <34JKCz24u8awawkhTLmboO_cBRWW-m0XAb0frTUb9YqspQe1VeBBWUvfqKd3-QIMLeKpiDUyzhN0X6aqRlEqwX1LmBfg3gn9EB2XCa5v62s=@protonmail.com>
References: <34JKCz24u8awawkhTLmboO_cBRWW-m0XAb0frTUb9YqspQe1VeBBWUvfqKd3-QIMLeKpiDUyzhN0X6aqRlEqwX1LmBfg3gn9EB2XCa5v62s=@protonmail.com>
Message-ID: <1877a680-d190-7202-537d-90d51bc6574b@phillipalday.com>

I suspect we'll need to know a bit more about your data to answer this
question. Can you share it in any form (e.g. variables renamed and
levels of factors changed to something opaque) ?

Best,
Phillip

On 16/2/21 4:02 am, Peter R Law via R-sig-mixed-models wrote:
> I am trying to fit a model with two covariates, x and z say, for response y, with a random factor g and want each of x and y to have a random slope. I expected
> 
> lmer(y ~ x + z + (x+z|g),...)
> 
> to fit a model with 6 random variance components, the intercept, two slopes and three correlations. But I got an error message saying there were 74 random variance components and my data was insufficient to fit the model. Yet
> 
> lmer(y ~ x + z + (x+z||g),...)
> 
> returned what I expected, a model with the random intercept and two slopes but no correlations. How is lmer interpreting the first line of code above and how I would code for what I want. I have not been able to find any examples in the literature or online that help me but I may have easily missed something so if anyone knows of a useful link that'd be great. The only examples of multiple random slopes I've seen take the form
> 
> lmer(y~x + z +(x|g) + (z|g),...)
> 
> specifically excluding correlations between the random slopes and intercept of the two predictors. Even if the latter is a more sensible approach I'd like to understand the coding issue.
> 
> Thanks.
> 
> Peter
> 
> Sent with [ProtonMail](https://protonmail.com) Secure Email.
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From bbo|ker @end|ng |rom gm@||@com  Tue Feb 16 16:04:28 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Tue, 16 Feb 2021 10:04:28 -0500
Subject: [R-sig-ME] lmer code for multiple random slopes
In-Reply-To: <1877a680-d190-7202-537d-90d51bc6574b@phillipalday.com>
References: <34JKCz24u8awawkhTLmboO_cBRWW-m0XAb0frTUb9YqspQe1VeBBWUvfqKd3-QIMLeKpiDUyzhN0X6aqRlEqwX1LmBfg3gn9EB2XCa5v62s=@protonmail.com>
 <1877a680-d190-7202-537d-90d51bc6574b@phillipalday.com>
Message-ID: <de6401b0-6cac-65d8-cbc3-0f59ce79409d@gmail.com>

   I second Phillip's point.  The example below works as expected (gets 
a singular fit, but there are 6 covariance parameters as expected). 
Based on what you've told us so far, the most plausible explanation is 
that one or both of your covariates (x and/or z) are factors 
(categorical) rather than numeric.

   Ben Bolker



===========
set.seed(101)
dd <- data.frame(x=rnorm(500),z=rnorm(500),
                  g=factor(sample(1:6,size=500,replace=TRUE)))
form <- y ~ x + z + (x+z|g)
dd$y <- simulate(form[-2],
                  newdata=dd,
                  newparams=list(beta=rep(0,3),
                                 theta=rep(1,6),
                                 sigma=1))[[1]]


library(lme4)
m1 <- lmer(form, data=dd)
VarCorr(m1)


On 2/16/21 8:18 AM, Phillip Alday wrote:
> I suspect we'll need to know a bit more about your data to answer this
> question. Can you share it in any form (e.g. variables renamed and
> levels of factors changed to something opaque) ?
> 
> Best,
> Phillip
> 
> On 16/2/21 4:02 am, Peter R Law via R-sig-mixed-models wrote:
>> I am trying to fit a model with two covariates, x and z say, for response y, with a random factor g and want each of x and y to have a random slope. I expected
>>
>> lmer(y ~ x + z + (x+z|g),...)
>>
>> to fit a model with 6 random variance components, the intercept, two slopes and three correlations. But I got an error message saying there were 74 random variance components and my data was insufficient to fit the model. Yet
>>
>> lmer(y ~ x + z + (x+z||g),...)
>>
>> returned what I expected, a model with the random intercept and two slopes but no correlations. How is lmer interpreting the first line of code above and how I would code for what I want. I have not been able to find any examples in the literature or online that help me but I may have easily missed something so if anyone knows of a useful link that'd be great. The only examples of multiple random slopes I've seen take the form
>>
>> lmer(y~x + z +(x|g) + (z|g),...)
>>
>> specifically excluding correlations between the random slopes and intercept of the two predictors. Even if the latter is a more sensible approach I'd like to understand the coding issue.
>>
>> Thanks.
>>
>> Peter
>>
>> Sent with [ProtonMail](https://protonmail.com) Secure Email.
>> 	[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From w||@onLO1998 @end|ng |rom hotm@||@com  Thu Feb 18 13:46:39 2021
From: w||@onLO1998 @end|ng |rom hotm@||@com (wilson 1998)
Date: Thu, 18 Feb 2021 12:46:39 +0000
Subject: [R-sig-ME] vcov function in glmer or glmmTMB package
Message-ID: <SYBPR01MB505080E58DDF066EAD1A4896C5859@SYBPR01MB5050.ausprd01.prod.outlook.com>

Hi There,

I have some questions on this package. Basically, I would like to know how the package generate the vcov or variance covariance matrix of the betas while considering the random effects.
In my simulation, for example I am using count data ?Salamanders? which is incorporated in glmmTMB package, and for example I choose the poisson model. In the first case, I thought using the idea from generalized estimating equations to get the variance of beta would give the same answer, but it proves me that the idea has not been successfully replicating the vcov output produced by glmmTMB. Would you be able to explain how the package give the output for vcov output?

So here is my attempt:
fit0 = glmmTMB(count~spp + (1|site), family=poisson)
fit1 = glmer(count~spp + (1|site), family=poisson)


vcov(fit0)
vcov(fit1)


then the output is:
> vcov(fit0)
Conditional model:
             (Intercept)        sppPR        sppDM      sppEC-A      sppEC-L     sppDES-L        sppDF
(Intercept)  0.100414787 -0.009259333 -0.009259333 -0.009259333 -0.009259334 -0.009259334 -0.009259333
sppPR       -0.009259333  0.046295871  0.009259332  0.009259332  0.009259333  0.009259333  0.009259332
sppDM       -0.009259333  0.009259332  0.016612285  0.009259333  0.009259333  0.009259333  0.009259333
sppEC-A     -0.009259333  0.009259332  0.009259333  0.029259437  0.009259333  0.009259333  0.009259333
sppEC-L     -0.009259334  0.009259333  0.009259333  0.009259333  0.014234439  0.009259333  0.009259333
sppDES-L    -0.009259334  0.009259333  0.009259333  0.009259333  0.009259333  0.013954163  0.009259333
sppDF       -0.009259333  0.009259332  0.009259333  0.009259333  0.009259333  0.009259333  0.017806382

> vcov(fit1)
7 x 7 Matrix of class "dpoMatrix"
             (Intercept)        sppPR        sppDM      sppEC-A      sppEC-L     sppDES-L        sppDF
(Intercept)  0.099481765 -0.009148415 -0.009148235 -0.009148238 -0.009148235 -0.009148193 -0.009148190
sppPR       -0.009148415  0.045738988  0.009147988  0.009147896  0.009147974  0.009147959  0.009147990
sppDM       -0.009148235  0.009147988  0.016412580  0.009147989  0.009148018  0.009148012  0.009148022
sppEC-A     -0.009148238  0.009147896  0.009147989  0.028907530  0.009147995  0.009147994  0.009147998
sppEC-L     -0.009148235  0.009147974  0.009148018  0.009147995  0.014063315  0.009148014  0.009148020
sppDES-L    -0.009148193  0.009147959  0.009148012  0.009147994  0.009148014  0.013786369  0.009148015
sppDF       -0.009148190  0.009147990  0.009148022  0.009147998  0.009148020  0.009148015  0.017592178


I tried to reproduce using the idea of Generalized estimating equations for the vcov and found very similar entries, except for the entry (1,1)

          [,1]        [,2]        [,3]        [,4]        [,5]        [,6]        [,7]
[1,]  0.009265 -0.00926500 -0.00926500 -0.00926500 -0.00926500 -0.00926500 -0.00926500
[2,] -0.009265  0.04632422  0.00926500  0.00926500  0.00926500  0.00926500  0.00926500
[3,] -0.009265  0.00926500  0.01662246  0.00926500  0.00926500  0.00926500  0.00926500
[4,] -0.009265  0.00926500  0.00926500  0.02927735  0.00926500  0.00926500  0.00926500
[5,] -0.009265  0.00926500  0.00926500  0.00926500  0.01424315  0.00926500  0.00926500
[6,] -0.009265  0.00926500  0.00926500  0.00926500  0.00926500  0.01396271  0.00926500
[7,] -0.009265  0.00926500  0.00926500  0.00926500  0.00926500  0.00926500  0.01781728


So I would like to know how do glmmTMB / glmer produce the output for vcov please?

Thankyou.

Regards,
WIlson

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Fri Feb 19 02:48:37 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Thu, 18 Feb 2021 20:48:37 -0500
Subject: [R-sig-ME] vcov function in glmer or glmmTMB package
In-Reply-To: <SYBPR01MB505080E58DDF066EAD1A4896C5859@SYBPR01MB5050.ausprd01.prod.outlook.com>
References: <SYBPR01MB505080E58DDF066EAD1A4896C5859@SYBPR01MB5050.ausprd01.prod.outlook.com>
Message-ID: <ac498b63-625e-37a6-1638-09b5df9cf010@gmail.com>



   Short answer.
   I wouldn't expect GEE and GLMM approaches to give the same answers at 
all, they're solving different problems.  Agresti's book on categorical 
data analysis has one entire chapter on each approach (Chapters 11 and 12).


http://www.math.mcmaster.ca/bolker/misc/agresti_cond_marg.png

    Another reference (for ecologists):

Muff Stefanie, Held Leonhard, Keller Lukas F., and Matthiopoulos Jason. 
?Marginal or Conditional Regression Models for Correlated Non?normal 
Data?? Methods in Ecology and Evolution 7, no. 12 (August 30, 2016): 
1514?24. https://doi.org/10.1111/2041-210X.12623.

  Others may be able to suggest better references.

   As for the technical question:

* the details of the derivation of var-cov for lmer are in J Stat 
Software Bates et al. 2015
* glmmTMB uses general-purpose optimization  + Laplace approximation 
(which is exact in the LMM case)


On 2/18/21 7:46 AM, wilson 1998 wrote:
> Hi There,
> 
> I have some questions on this package. Basically, I would like to know how the package generate the vcov or variance covariance matrix of the betas while considering the random effects.
> In my simulation, for example I am using count data ?Salamanders? which is incorporated in glmmTMB package, and for example I choose the poisson model. In the first case, I thought using the idea from generalized estimating equations to get the variance of beta would give the same answer, but it proves me that the idea has not been successfully replicating the vcov output produced by glmmTMB. Would you be able to explain how the package give the output for vcov output?
> 
> So here is my attempt:
> fit0 = glmmTMB(count~spp + (1|site), family=poisson)
> fit1 = glmer(count~spp + (1|site), family=poisson)
> 
> 
> vcov(fit0)
> vcov(fit1)
> 
> 
> then the output is:
>> vcov(fit0)
> Conditional model:
>               (Intercept)        sppPR        sppDM      sppEC-A      sppEC-L     sppDES-L        sppDF
> (Intercept)  0.100414787 -0.009259333 -0.009259333 -0.009259333 -0.009259334 -0.009259334 -0.009259333
> sppPR       -0.009259333  0.046295871  0.009259332  0.009259332  0.009259333  0.009259333  0.009259332
> sppDM       -0.009259333  0.009259332  0.016612285  0.009259333  0.009259333  0.009259333  0.009259333
> sppEC-A     -0.009259333  0.009259332  0.009259333  0.029259437  0.009259333  0.009259333  0.009259333
> sppEC-L     -0.009259334  0.009259333  0.009259333  0.009259333  0.014234439  0.009259333  0.009259333
> sppDES-L    -0.009259334  0.009259333  0.009259333  0.009259333  0.009259333  0.013954163  0.009259333
> sppDF       -0.009259333  0.009259332  0.009259333  0.009259333  0.009259333  0.009259333  0.017806382
> 
>> vcov(fit1)
> 7 x 7 Matrix of class "dpoMatrix"
>               (Intercept)        sppPR        sppDM      sppEC-A      sppEC-L     sppDES-L        sppDF
> (Intercept)  0.099481765 -0.009148415 -0.009148235 -0.009148238 -0.009148235 -0.009148193 -0.009148190
> sppPR       -0.009148415  0.045738988  0.009147988  0.009147896  0.009147974  0.009147959  0.009147990
> sppDM       -0.009148235  0.009147988  0.016412580  0.009147989  0.009148018  0.009148012  0.009148022
> sppEC-A     -0.009148238  0.009147896  0.009147989  0.028907530  0.009147995  0.009147994  0.009147998
> sppEC-L     -0.009148235  0.009147974  0.009148018  0.009147995  0.014063315  0.009148014  0.009148020
> sppDES-L    -0.009148193  0.009147959  0.009148012  0.009147994  0.009148014  0.013786369  0.009148015
> sppDF       -0.009148190  0.009147990  0.009148022  0.009147998  0.009148020  0.009148015  0.017592178
> 
> 
> I tried to reproduce using the idea of Generalized estimating equations for the vcov and found very similar entries, except for the entry (1,1)
> 
>            [,1]        [,2]        [,3]        [,4]        [,5]        [,6]        [,7]
> [1,]  0.009265 -0.00926500 -0.00926500 -0.00926500 -0.00926500 -0.00926500 -0.00926500
> [2,] -0.009265  0.04632422  0.00926500  0.00926500  0.00926500  0.00926500  0.00926500
> [3,] -0.009265  0.00926500  0.01662246  0.00926500  0.00926500  0.00926500  0.00926500
> [4,] -0.009265  0.00926500  0.00926500  0.02927735  0.00926500  0.00926500  0.00926500
> [5,] -0.009265  0.00926500  0.00926500  0.00926500  0.01424315  0.00926500  0.00926500
> [6,] -0.009265  0.00926500  0.00926500  0.00926500  0.00926500  0.01396271  0.00926500
> [7,] -0.009265  0.00926500  0.00926500  0.00926500  0.00926500  0.00926500  0.01781728
> 
> 
> So I would like to know how do glmmTMB / glmer produce the output for vcov please?
> 
> Thankyou.
> 
> Regards,
> WIlson
> 
> 	[[alternative HTML version deleted]]
> 
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From @e|m@@rudert @end|ng |rom gm@||@com  Fri Feb 19 15:14:16 2021
From: @e|m@@rudert @end|ng |rom gm@||@com (Selma Rudert)
Date: Fri, 19 Feb 2021 15:14:16 +0100
Subject: [R-sig-ME] Partially nested/partially crossed structure in a mixed
 model
Message-ID: <CAM2P8mwfXS0P_JMHM2m+uzvVQ0rYc6oX8ZneKFAB8o20-9UkCQ@mail.gmail.com>

Hi,

I already apologize if this is a rather basic question, but I would really
appreciate some advice as I am unfamiliar with the particular design issues
here:

I am assessing cheating during exams depending on the type of exam (online
test vs. on-site test). Some of the students wrote only online exams,
others only on-site exams and some did both. We assessed cheating for both
types of exams, meaning that students who did both types of exams answered
the cheating questions twice (for each type of exam) and others who wrote
only one type answered them only once. So the data looks  like this:

Subject ExamType Cheating
1 online 2
1 on-site NA
2 online NA
2 on-site 1
3 online 4
3 on-site 3
...

I understood I am dealing with some sort of partially nested/partially
crossed fixed effect here. My question is, is it appropriate to analyze the
effect of online vs. offline testing within the same model if I just add a
random intercept for the subject? So far what I came up with would look
like this:

Cheating ~ ExamType +(1 | Subject), data = df

The model looks (too?) simple,  the model converges and the obtained
results look reasonable. But I cannot help the sense I may be overlooking
something, as of course there is a lot of data missing by design in the
dependent variable and I am not sure whether lme/lmer handles this
correctly? I would be happy for some expert to comment on this or
alternatively, any literatur advice on the topic. Thank you so much in
advance!

Best

Selma

	[[alternative HTML version deleted]]


From w@||dm@w@@@10 @end|ng |rom gm@||@com  Wed Feb 24 19:29:10 2021
From: w@||dm@w@@@10 @end|ng |rom gm@||@com (Walid Crampton-Mawass)
Date: Wed, 24 Feb 2021 13:29:10 -0500
Subject: [R-sig-ME] MCMCglmm covariance matrix specification
Message-ID: <CAJtCY7Um3EN+qod4nd0B0uJYtm0hhEXX8yFrc1rE9rGage9KEg@mail.gmail.com>

Hey all,

Hope you are doing well during this time!

I have been racking my brain for weeks on how to do model this issue but I
have found nothing other than one old answer by Jarrod Hadfield (
https://stat.ethz.ch/pipermail/r-sig-mixed-models/2015q4/024036.html) which
recommends using an antedepedence model. Here is the issue:

I have constructed a bivariate animal model (trait1, trait2) with a random
interaction with the additive genetic random effect and the residual
variance,i.e. (trait:env):animal. The interaction variable is a categorical
environmental variable of 3 levels (Low, Mid, High). So my
variance-covariance matrix has a 6x6 shape (2traitsx3env). Hence, the
matrix would include both among-trait covariances within the same env and
between env, and cross-env covariances for the same trait:

trait1:low trait1:mid trait1:high trait2:low trait2:mid trait2:high
1 0 0 0 0 0
0 1 0 0 0 0
0 0 1 0 0 0
0 0 0 1 0 0
0 0 0 0 1 0
0 0 0 0 0 1
(1 represent variances, 0 represent covariances)

I have already run the model with both the idh() and us() specification. In
the first case, no covariances are calculated at all, only variances are
calculated. In the second case, all types of covariances are calculated.

I need help figuring out how to specify the variance-covariance matrix in
MCMCglmm (and prior) in a way to tell the model not to estimate the
cross-env covariances, only the among-trait covariances should be
estimated:
trait1:low trait1:mid trait1:high trait2:low trait2:mid trait2:high
1 x x 0 x x
x 1 x x 0 x
x x 1 x x 0
0 x x 1 x x
x 0 x x 1 x
x x 0 x x 1
(1 represent variances, 0 represent covariances to be estimated, x
represent covariances fixed at 0, i.e. not estimated)

any help would be appreciated!
-- 
Walid Crampton-Mawass
Ph.D. candidate in Evolutionary Biology
Population Genetics Laboratory
University of Qu?bec at Trois-Rivi?res
3351, boul. des Forges, C.P. 500
Trois-Rivi?res (Qu?bec) G9A 5H7
Telephone: 819-376-5011 poste 3384

	[[alternative HTML version deleted]]


From @r|v@t@ch@r| @end|ng |rom gm@||@com  Wed Feb 24 19:54:38 2021
From: @r|v@t@ch@r| @end|ng |rom gm@||@com (Srivats Chari)
Date: Wed, 24 Feb 2021 18:54:38 +0000
Subject: [R-sig-ME] MCMCglmm covariance matrix specification
In-Reply-To: <CAJtCY7Um3EN+qod4nd0B0uJYtm0hhEXX8yFrc1rE9rGage9KEg@mail.gmail.com>
References: <CAJtCY7Um3EN+qod4nd0B0uJYtm0hhEXX8yFrc1rE9rGage9KEg@mail.gmail.com>
Message-ID: <CAFnkSc=nDaw3CUGffQrQd2OATh1v4DW6m7Ju6hbFD1V3F-O3Hw@mail.gmail.com>

Hey Walid,

I had a similar problem a few months ago, I didn't want 1 trait to have any
covariance. I was not able to find a solution to it but after reading
several articles, I figured out a way.

Instead of not calculating the covariances at all (which I am not sure if
it's possible), you can set the value to 0 in the prior.

Here is my example-
I have 9 traits and I do not want my last trait to covary with any other
trait. Hence I set it to a very low value (0.001) for the within individual
covariance and use the fix command to specify which trait it is (in this
instance  my 9th trait).

final_priorv1 <- list(R = list(V =diag(c(1,1,1,1,1,1,1,1,0.001),9,9), nu =
0.002, fix = 9),
                      G = list(G1 = list(V = diag(9), nu = 9,
                                         alpha.mu = rep(0, 9),
                                         alpha.V  = diag(25^2,9,9))))

Remember this is within individual variance set to 0.001, you will still be
calculating the among individual covariance.

Found this solution from Dr. Houslay's MCMCGlmm Tutorial page 14. Link
here-->
https://tomhouslay.files.wordpress.com/2017/02/indivvar_mv_tutorial_mcmcglmm.pdf
Something similar from his other tutorial page 31-->
https://tomhouslay.files.wordpress.com/2017/02/indivvar_plasticity_tutorial_mcmcglmm1.pdf

With this prior, I was able to use the unstructured (us) covariance matrix
and I was able to get what I needed.

I feel what you are looking for is fairly similar, and I believe this
solution might work for you.

 Happy coding!

Regards,
Srivats.

Srivats Chari
<https://sites.google.com/ucd.ie/wildl-ecol-behav-at-ucd/people#h.p_DyWP_UxHDqgq>
Post-Graduate Research Student
Twitter- @WildlifeVats <https://twitter.com/WildlifeVats>

Laboratory of Wildlife Ecology and Behaviour
<https://sites.google.com/ucd.ie/wildl-ecol-behav-at-ucd>
School of Biology and Environmental Science (SBES),
University College Dublin (UCD).


On Wed, Feb 24, 2021 at 6:29 PM Walid Crampton-Mawass <
walidmawass10 at gmail.com> wrote:

> Hey all,
>
> Hope you are doing well during this time!
>
> I have been racking my brain for weeks on how to do model this issue but I
> have found nothing other than one old answer by Jarrod Hadfield (
> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2015q4/024036.html)
> which
> recommends using an antedepedence model. Here is the issue:
>
> I have constructed a bivariate animal model (trait1, trait2) with a random
> interaction with the additive genetic random effect and the residual
> variance,i.e. (trait:env):animal. The interaction variable is a categorical
> environmental variable of 3 levels (Low, Mid, High). So my
> variance-covariance matrix has a 6x6 shape (2traitsx3env). Hence, the
> matrix would include both among-trait covariances within the same env and
> between env, and cross-env covariances for the same trait:
>
> trait1:low trait1:mid trait1:high trait2:low trait2:mid trait2:high
> 1 0 0 0 0 0
> 0 1 0 0 0 0
> 0 0 1 0 0 0
> 0 0 0 1 0 0
> 0 0 0 0 1 0
> 0 0 0 0 0 1
> (1 represent variances, 0 represent covariances)
>
> I have already run the model with both the idh() and us() specification. In
> the first case, no covariances are calculated at all, only variances are
> calculated. In the second case, all types of covariances are calculated.
>
> I need help figuring out how to specify the variance-covariance matrix in
> MCMCglmm (and prior) in a way to tell the model not to estimate the
> cross-env covariances, only the among-trait covariances should be
> estimated:
> trait1:low trait1:mid trait1:high trait2:low trait2:mid trait2:high
> 1 x x 0 x x
> x 1 x x 0 x
> x x 1 x x 0
> 0 x x 1 x x
> x 0 x x 1 x
> x x 0 x x 1
> (1 represent variances, 0 represent covariances to be estimated, x
> represent covariances fixed at 0, i.e. not estimated)
>
> any help would be appreciated!
> --
> Walid Crampton-Mawass
> Ph.D. candidate in Evolutionary Biology
> Population Genetics Laboratory
> University of Qu?bec at Trois-Rivi?res
> 3351, boul. des Forges, C.P. 500
> Trois-Rivi?res (Qu?bec) G9A 5H7
> Telephone: 819-376-5011 poste 3384
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From j@h@d||e|d @end|ng |rom ed@@c@uk  Wed Feb 24 22:05:02 2021
From: j@h@d||e|d @end|ng |rom ed@@c@uk (Jarrod Hadfield)
Date: Wed, 24 Feb 2021 21:05:02 +0000
Subject: [R-sig-ME] MCMCglmm covariance matrix specification
In-Reply-To: <CAJtCY7Um3EN+qod4nd0B0uJYtm0hhEXX8yFrc1rE9rGage9KEg@mail.gmail.com>
References: <CAJtCY7Um3EN+qod4nd0B0uJYtm0hhEXX8yFrc1rE9rGage9KEg@mail.gmail.com>
Message-ID: <7d2f4d34-183b-ef37-133c-8b61e99c609a@ed.ac.uk>

Hi,

As I understand it you have 3 2x2 covariance matrices to be estimated,
one for each environment?

~us(at.level(env, 1):trait):animal+us(at.level(env,
2):trait):animal+us(at.level(env, 3):trait):animal

should work. I presume you have no shared pedigree between the
envrionments hence the cross-env covariances are not estimable? In the
computation time is long, get back to me; there are ways to
reparameterise it to make it faster but it's a bit fiddly.

For harder problems (where the covariance matrix can't be permuted such
that the estimable bits fall in blocks along the diagonal, as here) then
fixing elements to zero is probably not a good idea even if you could do
it (for example in asreml). The zero elements will force patterns in the
estimable elements to ensure positive-defitness. The antedependence
solution I posted earlier gets round this issue I believe.

Cheers,

Jarrod


On 24/02/2021 18:29, Walid Crampton-Mawass wrote:
> This email was sent to you by someone outside the University.
> You should only click on links or attachments if you are certain that the email is genuine and the content is safe.
>
> Hey all,
>
> Hope you are doing well during this time!
>
> I have been racking my brain for weeks on how to do model this issue but I
> have found nothing other than one old answer by Jarrod Hadfield (
> https://stat.ethz.ch/pipermail/r-sig-mixed-models/2015q4/024036.html) which
> recommends using an antedepedence model. Here is the issue:
>
> I have constructed a bivariate animal model (trait1, trait2) with a random
> interaction with the additive genetic random effect and the residual
> variance,i.e. (trait:env):animal. The interaction variable is a categorical
> environmental variable of 3 levels (Low, Mid, High). So my
> variance-covariance matrix has a 6x6 shape (2traitsx3env). Hence, the
> matrix would include both among-trait covariances within the same env and
> between env, and cross-env covariances for the same trait:
>
> trait1:low trait1:mid trait1:high trait2:low trait2:mid trait2:high
> 1 0 0 0 0 0
> 0 1 0 0 0 0
> 0 0 1 0 0 0
> 0 0 0 1 0 0
> 0 0 0 0 1 0
> 0 0 0 0 0 1
> (1 represent variances, 0 represent covariances)
>
> I have already run the model with both the idh() and us() specification. In
> the first case, no covariances are calculated at all, only variances are
> calculated. In the second case, all types of covariances are calculated.
>
> I need help figuring out how to specify the variance-covariance matrix in
> MCMCglmm (and prior) in a way to tell the model not to estimate the
> cross-env covariances, only the among-trait covariances should be
> estimated:
> trait1:low trait1:mid trait1:high trait2:low trait2:mid trait2:high
> 1 x x 0 x x
> x 1 x x 0 x
> x x 1 x x 0
> 0 x x 1 x x
> x 0 x x 1 x
> x x 0 x x 1
> (1 represent variances, 0 represent covariances to be estimated, x
> represent covariances fixed at 0, i.e. not estimated)
>
> any help would be appreciated!
> --
> Walid Crampton-Mawass
> Ph.D. candidate in Evolutionary Biology
> Population Genetics Laboratory
> University of Qu?bec at Trois-Rivi?res
> 3351, boul. des Forges, C.P. 500
> Trois-Rivi?res (Qu?bec) G9A 5H7
> Telephone: 819-376-5011 poste 3384
>
>          [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
The University of Edinburgh is a charitable body, registered in Scotland, with registration number SC005336. Is e buidheann carthannais a th? ann an Oilthigh Dh?n ?ideann, cl?raichte an Alba, ?ireamh cl?raidh SC005336.


From w@||dm@w@@@10 @end|ng |rom gm@||@com  Wed Feb 24 22:22:48 2021
From: w@||dm@w@@@10 @end|ng |rom gm@||@com (Walid Crampton-Mawass)
Date: Wed, 24 Feb 2021 16:22:48 -0500
Subject: [R-sig-ME] MCMCglmm covariance matrix specification
In-Reply-To: <7d2f4d34-183b-ef37-133c-8b61e99c609a@ed.ac.uk>
References: <CAJtCY7Um3EN+qod4nd0B0uJYtm0hhEXX8yFrc1rE9rGage9KEg@mail.gmail.com>
 <7d2f4d34-183b-ef37-133c-8b61e99c609a@ed.ac.uk>
Message-ID: <CAJtCY7Xe2iDVWdeARYK0rC1F+YHccb+hKMu43qiJmn3KwT3jkQ@mail.gmail.com>

Hi Jarrod,

Actually, I do have a shared pedigree and the cross-env covariances were
estimable. The goal of this analysis is to see if precision improves in any
way if I can set cross-env covariances to zero using the initial way my
matrices were constructed which is simply: ~us(env:trait):animal - which
includes cross-env covariances

I will try your proposal and get back to you. Though, I am thinking that a
model that does include cross-env covariances in my covariance matrix would
be a better choice so as to analyse cross-env genetic correlations (unless
I can still do that with your approach)

Thanks!
-- 
Walid Crampton-Mawass
Ph.D. candidate in Evolutionary Biology
Population Genetics Laboratory
University of Qu?bec at Trois-Rivi?res
3351, boul. des Forges, C.P. 500
Trois-Rivi?res (Qu?bec) G9A 5H7
Telephone: 819-376-5011 poste 3384


On Wed, Feb 24, 2021 at 4:05 PM Jarrod Hadfield <j.hadfield at ed.ac.uk> wrote:

> Hi,
>
> As I understand it you have 3 2x2 covariance matrices to be estimated,
> one for each environment?
>
> ~us(at.level(env, 1):trait):animal+us(at.level(env,
> 2):trait):animal+us(at.level(env, 3):trait):animal
>
> should work. I presume you have no shared pedigree between the
> envrionments hence the cross-env covariances are not estimable? In the
> computation time is long, get back to me; there are ways to
> reparameterise it to make it faster but it's a bit fiddly.
>
> For harder problems (where the covariance matrix can't be permuted such
> that the estimable bits fall in blocks along the diagonal, as here) then
> fixing elements to zero is probably not a good idea even if you could do
> it (for example in asreml). The zero elements will force patterns in the
> estimable elements to ensure positive-defitness. The antedependence
> solution I posted earlier gets round this issue I believe.
>
> Cheers,
>
> Jarrod
>
>
> On 24/02/2021 18:29, Walid Crampton-Mawass wrote:
> > This email was sent to you by someone outside the University.
> > You should only click on links or attachments if you are certain that
> the email is genuine and the content is safe.
> >
> > Hey all,
> >
> > Hope you are doing well during this time!
> >
> > I have been racking my brain for weeks on how to do model this issue but
> I
> > have found nothing other than one old answer by Jarrod Hadfield (
> > https://stat.ethz.ch/pipermail/r-sig-mixed-models/2015q4/024036.html)
> which
> > recommends using an antedepedence model. Here is the issue:
> >
> > I have constructed a bivariate animal model (trait1, trait2) with a
> random
> > interaction with the additive genetic random effect and the residual
> > variance,i.e. (trait:env):animal. The interaction variable is a
> categorical
> > environmental variable of 3 levels (Low, Mid, High). So my
> > variance-covariance matrix has a 6x6 shape (2traitsx3env). Hence, the
> > matrix would include both among-trait covariances within the same env and
> > between env, and cross-env covariances for the same trait:
> >
> > trait1:low trait1:mid trait1:high trait2:low trait2:mid trait2:high
> > 1 0 0 0 0 0
> > 0 1 0 0 0 0
> > 0 0 1 0 0 0
> > 0 0 0 1 0 0
> > 0 0 0 0 1 0
> > 0 0 0 0 0 1
> > (1 represent variances, 0 represent covariances)
> >
> > I have already run the model with both the idh() and us() specification.
> In
> > the first case, no covariances are calculated at all, only variances are
> > calculated. In the second case, all types of covariances are calculated.
> >
> > I need help figuring out how to specify the variance-covariance matrix in
> > MCMCglmm (and prior) in a way to tell the model not to estimate the
> > cross-env covariances, only the among-trait covariances should be
> > estimated:
> > trait1:low trait1:mid trait1:high trait2:low trait2:mid trait2:high
> > 1 x x 0 x x
> > x 1 x x 0 x
> > x x 1 x x 0
> > 0 x x 1 x x
> > x 0 x x 1 x
> > x x 0 x x 1
> > (1 represent variances, 0 represent covariances to be estimated, x
> > represent covariances fixed at 0, i.e. not estimated)
> >
> > any help would be appreciated!
> > --
> > Walid Crampton-Mawass
> > Ph.D. candidate in Evolutionary Biology
> > Population Genetics Laboratory
> > University of Qu?bec at Trois-Rivi?res
> > 3351, boul. des Forges, C.P. 500
> > Trois-Rivi?res (Qu?bec) G9A 5H7
> > Telephone: 819-376-5011 poste 3384
> >
> >          [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> The University of Edinburgh is a charitable body, registered in Scotland,
> with registration number SC005336. Is e buidheann carthannais a th? ann an
> Oilthigh Dh?n ?ideann, cl?raichte an Alba, ?ireamh cl?raidh SC005336.
>

	[[alternative HTML version deleted]]


From w||@onLO1998 @end|ng |rom hotm@||@com  Thu Feb 25 02:30:28 2021
From: w||@onLO1998 @end|ng |rom hotm@||@com (wilson 1998)
Date: Thu, 25 Feb 2021 01:30:28 +0000
Subject: [R-sig-ME] lme4 to get a vcov for fixed-effects variance
Message-ID: <SYBPR01MB5050AEB69270578A8DCA91F7C59E9@SYBPR01MB5050.ausprd01.prod.outlook.com>

Following the previous email to make it just text only questions: I?ll restate my questions:

Hi Ben Bolker,

I would like to know about some mechanism about vcov output from glmer model from here<https://cran.r-project.org/web/packages/lme4/vignettes/lmer.pdf>

So I am running a model using glmer under poisson model
fit1 = glmer(count~spp + (1|site),data=Salamanders, family=poisson)
using Salamanders data<https://www.rdocumentation.org/packages/glmmTMB/versions/1.0.2.1/topics/Salamanders> from glmmTMB package in R Studio

Then it could produce the variance covariance matrix about the fixed effects given below:, also since full=T it also gives the extra column and extra row to account for the random effect as well.

vcov(fit1,full=T)


I noticed in page 26 in section 5.1 in lme4 documentation (equation 54 and equation 55) from this link: https://cran.r-project.org/web/packages/lme4/vignettes/lmer.pdf#page=14&zoom=100,568,614


However, How do I reproduce the output for vcov manually? I know that under equation (55) it says that they could reproduce using chol2inv(RX) to represent R_X^-1 (R^T_X)^-1

I don?t get it how to produce the R_X, L(theta) ,R_ZX as well? It is stated that there could be Cholesky decomposition, but what if I would like to get this manually for each component?
The main point is that I would like to know how could the lme4 package get the output for the vcov(fit1,full=T). And in this case, I also would like to know how to extract R_X and R_ZX from the fit1?

Thankyou.

Regards,
Wilson



Below is the previous email with the comment

Your request to the R-sig-mixed-models mailing list

    Posting of your message titled "lme4 to get a vcov for
fixed-effects variance"

has been rejected by the list moderator.  The moderator gave the
following reason for rejecting your request:

"Could you please resend without the embedded text from the JSS paper?
(The mailing list is very old-fashioned and only likes plain-text
messages.) You can point to the specific section in the JSS paper
(e.g. "in section 5.1 'Theory underlying the output module', in the
first subsection 'Covariance matrix of the fixed-effect
coefficients').

If you could also clarify your question that would be useful: do you
want to know how RX is computed during the estimation procedure (see
eq 51 of the JSS paper), or how to extract it from the fit [which is
stated in the text you quoted], or ... ?

  sincerely
   Ben Bolker"

Any questions or comments should be directed to the list administrator
at:

    r-sig-mixed-models-owner at r-project.org


	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Thu Feb 25 03:22:12 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Wed, 24 Feb 2021 21:22:12 -0500
Subject: [R-sig-ME] lme4 to get a vcov for fixed-effects variance
In-Reply-To: <SYBPR01MB5050AEB69270578A8DCA91F7C59E9@SYBPR01MB5050.ausprd01.prod.outlook.com>
References: <SYBPR01MB5050AEB69270578A8DCA91F7C59E9@SYBPR01MB5050.ausprd01.prod.outlook.com>
Message-ID: <7dd3cab7-52ec-277d-9eb2-98209cf648be@gmail.com>

There are still some aspects of your question that aren't clear to me, 
but I might be able to shed some light on some things.

(1) when fitting a GLMM (rather than a LMM), lme4 *doesn't* use the RX 
component as described in the JSS paper, except as a fallback solution; 
it instead directly uses the inverse of the Hessian of the objective 
(deviance) function (H^(-1)), unless there appear to be numeric problems 
with H (e.g. it is non-positive-definite). (See code below.)

(2) the full covariance matrix estimated this way is *approximately* the 
same as you get for glmmTMB, except that glmmTMB is estimating 
log(theta) rather than theta.  After adjusting for this, the estimated 
variances disagree by about 10% (too bad, but not shocking for this kind 
of calculation).

(3) As for the actual process of extracting RX (if you wanted to compute 
that way) - it's spelled out in the paper. I'm not at all sure what you 
mean by "get this manually for each component".  To extract R_X and 
R_ZX, use getME() (see ?getME)

library(glmmTMB)
library(lme4)
## use only three species, to make cov matrices smaller/easier to examine
ss <- subset(Salamanders,spp %in% levels(spp)[1:3])
fit1 <- glmer(count~spp + (1|site),data=ss, family=poisson)
fit2 <- glmmTMB(count~spp + (1|site),data=ss, family=poisson)

## glmmTMB "full" covariance matrix
V1 <- vcov(fit2,full=TRUE)

## default glmer covariance matrix, converted back to
## a regular base-R matrix (from a Matrix).
V2 <- as.matrix(vcov(fit1))

## glmer covariance matrix using RX as in JSS paper.
V3 <- as.matrix(vcov(fit1,use.hessian=FALSE))
## warning message

##
neword <- c(2:4,1) ## put theta param last to match glmmTMB
V4 <- 2*solve(fit1 at optinfo$derivs$Hessian)[neword,neword]

## RX-based computation from scratch
sigma2 <- 1  ## sigma==1 for Poisson model
RX <- getME(fit1, "RX")
V5 <- sigma2 * chol2inv(RX)

all.equal(unname(V3),V5,tol=1e-12)

th <- getME(fit1,"theta")
## var(log(theta)) = var(theta)*d(log(theta))/d theta = var(theta)/theta^2
all.equal(V4[4,4]/unname(th)^2,V1[4,4])


On 2/24/21 8:30 PM, wilson 1998 wrote:
> Following the previous email to make it just text only questions: I?ll restate my questions:
> 
> Hi Ben Bolker,
> 
> I would like to know about some mechanism about vcov output from glmer model from here<https://cran.r-project.org/web/packages/lme4/vignettes/lmer.pdf>
> 
> So I am running a model using glmer under poisson model
> fit1 = glmer(count~spp + (1|site),data=Salamanders, family=poisson)
> using Salamanders data<https://www.rdocumentation.org/packages/glmmTMB/versions/1.0.2.1/topics/Salamanders> from glmmTMB package in R Studio
> 
> Then it could produce the variance covariance matrix about the fixed effects given below:, also since full=T it also gives the extra column and extra row to account for the random effect as well.
> 
> vcov(fit1,full=T)
> 
> 
> I noticed in page 26 in section 5.1 in lme4 documentation (equation 54 and equation 55) from this link: https://cran.r-project.org/web/packages/lme4/vignettes/lmer.pdf#page=14&zoom=100,568,614
> 
> 
> However, How do I reproduce the output for vcov manually? I know that under equation (55) it says that they could reproduce using chol2inv(RX) to represent R_X^-1 (R^T_X)^-1
> 
> I don?t get it how to produce the R_X, L(theta) ,R_ZX as well? It is stated that there could be Cholesky decomposition, but what if I would like to get this manually for each component?
> The main point is that I would like to know how could the lme4 package get the output for the vcov(fit1,full=T). And in this case, I also would like to know how to extract R_X and R_ZX from the fit1?
> 
> Thankyou.
> 
> Regards,
> Wilson



> 
> 
> 
> Below is the previous email with the comment
> 
> Your request to the R-sig-mixed-models mailing list
> 
>      Posting of your message titled "lme4 to get a vcov for
> fixed-effects variance"
> 
> has been rejected by the list moderator.  The moderator gave the
> following reason for rejecting your request:
> 
> "Could you please resend without the embedded text from the JSS paper?
> (The mailing list is very old-fashioned and only likes plain-text
> messages.) You can point to the specific section in the JSS paper
> (e.g. "in section 5.1 'Theory underlying the output module', in the
> first subsection 'Covariance matrix of the fixed-effect
> coefficients').
> 
> If you could also clarify your question that would be useful: do you
> want to know how RX is computed during the estimation procedure (see
> eq 51 of the JSS paper), or how to extract it from the fit [which is
> stated in the text you quoted], or ... ?
> 
>    sincerely
>     Ben Bolker"
> 
> Any questions or comments should be directed to the list administrator
> at:
> 
>      r-sig-mixed-models-owner at r-project.org
> 
> 
> 	[[alternative HTML version deleted]]
> 
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From pr|db @end|ng |rom protonm@||@com  Thu Feb 25 05:16:13 2021
From: pr|db @end|ng |rom protonm@||@com (Peter R Law)
Date: Thu, 25 Feb 2021 04:16:13 +0000
Subject: [R-sig-ME] lmer code for multiple random slopes
In-Reply-To: <NCGF24lxdAy2bcOAoQsutEkYQ-ZIzb4e3xLenmSDhGyZN8a8sIcv-wHF0IEfLK8GQGccVE1hLTk-i1UPxFITTgLC9T929E6F4rQVMwVN8bg=@protonmail.com>
References: <34JKCz24u8awawkhTLmboO_cBRWW-m0XAb0frTUb9YqspQe1VeBBWUvfqKd3-QIMLeKpiDUyzhN0X6aqRlEqwX1LmBfg3gn9EB2XCa5v62s=@protonmail.com>
 <1877a680-d190-7202-537d-90d51bc6574b@phillipalday.com>
 <de6401b0-6cac-65d8-cbc3-0f59ce79409d@gmail.com>
 <NCGF24lxdAy2bcOAoQsutEkYQ-ZIzb4e3xLenmSDhGyZN8a8sIcv-wHF0IEfLK8GQGccVE1hLTk-i1UPxFITTgLC9T929E6F4rQVMwVN8bg=@protonmail.com>
Message-ID: <e2zoG5je3QHzcPl3dsttnLigMgzR8mqiUJAdgntQm9xPOX4j3SwlDytjMtbOFRj-vf5TjpHVRD7rzd54mvwMFm9OhW-ff4lfhR383lioPX4=@protonmail.com>

Alas I am still puzzled. I have extracted some data in trial.txt (no categorical variables) and attached some code in trial.R. I am only using this data to test code, which I hope to apply to a larger data set obtained from multiple populations, so with more structure. So the results themselves are not important, only whether the code does what I think it should. It occurred to me to test each model with lme and lmer.

For a model with only a random intercept plus fixed effects, lme and lmer returned the same results, except that lme returns estimates with more decimal places (so here lmer returned zero variance for the random intercpt and lme a very small number).

Adding a random slope, the main difference in the results is that lme and lmer returned very different estimates of the slope variance. Is that surprising?

For a model with two random slopes, lme returned results as expected but lmer still claims there are 78 variance components, which is the number one would get from a 12 x 12 covariance matrix. Where the number 12 comes from is a mystery to me, especially as lme does what I expected (I ran this model with both raw data and normalized predictor values to see if something fishy was happening there but no):

> M5n <- lme(Response~normP+normA, random=~normP+normA|Group,data=Trial, method="ML")
> summary(M2n)
Linear mixed-effects model fit by maximum likelihood
 Data: Trial
       AIC      BIC    logLik
  536.4562 559.4969 -258.2281

Random effects:
 Formula: ~P + A | Group
 Structure: General positive-definite, Log-Cholesky parametrization
            StdDev       Corr
(Intercept) 3.061144e-04 (Intr) P
P           1.535752e-09 0
A           8.517774e-13 0      0
Residual    7.929821e+00

Fixed effects: Response ~ P + A
                Value Std.Error DF    t-value p-value
(Intercept) 25.453398 10.828841 46  2.3505192  0.0231
P           -0.029307  0.035939 46 -0.8154787  0.4190
A            0.140819  0.282018 46  0.4993255  0.6199
 Correlation:
  (Intr) P
P -0.033
A -0.975 -0.173

Standardized Within-Group Residuals:
       Min         Q1        Med         Q3        Max
-1.8447131 -0.5563605 -0.2613520  0.2755547  5.5643551

Number of Observations: 74
Number of Groups: 26
> M5 <- lmer(Response~normP+normA+(normP+normA|Group), REML="False", data=Trial)
Error: number of observations (=74) <= number of random effects (=78) for term (normP + normA | Group); the random-effects parameters and the residual variance (or scale parameter) are probably unidentifiable.

It didn't matter which pair of the three predictors I used as far as the error message lmer returned but lme only returned results for P+A, not any pair involving PR, which apparently created computational issues, distinct to the interpretation of the code.

In lmer, replacing the code (x+y|Group) by either (x+y||Group) or (X|Group) + (Y|Group) returned the expected results (in that lme4 interpreted the code as expected). Is there lme code for either of these models?

Many thanks for any help.

Peter

P. S. I just noticed that responding to Ben's email sends my email to Ben, not to r-sig. I hope that sending my email to r-sig is the right thing to do and doesn't break the chain to my previous email.


Sent with ProtonMail Secure Email.

??????? Original Message ???????
On Wednesday, February 17, 2021 10:40 PM, Peter R Law <prldb at protonmail.com> wrote:

> Thanks for your quick response. I take it that the code should mean what I thought it would and that somehow lmer is not interpreting what I wrote in my actual example as intended. None of the variables are categorical but I'll give it some more thought and see if I can figure it out. If not, I'll provide more details.
>
> Peter
>
> Sent with ProtonMail Secure Email.
>
> ??????? Original Message ???????
> On Tuesday, February 16, 2021 10:04 AM, Ben Bolker bbolker at gmail.com wrote:
>
> > I second Phillip's point. The example below works as expected (gets
> > a singular fit, but there are 6 covariance parameters as expected).
> > Based on what you've told us so far, the most plausible explanation is
> > that one or both of your covariates (x and/or z) are factors
> > (categorical) rather than numeric.
> > Ben Bolker
> > ============================================================================================================================================================================================================================================================================================================================
> > set.seed(101)
> > dd <- data.frame(x=rnorm(500),z=rnorm(500),
> > g=factor(sample(1:6,size=500,replace=TRUE)))
> > form <- y ~ x + z + (x+z|g)
> > dd$y <- simulate(form[-2],
> > newdata=dd,
> > newparams=list(beta=rep(0,3),
> > theta=rep(1,6),
> > sigma=1))[[1]]
> > library(lme4)
> > m1 <- lmer(form, data=dd)
> > VarCorr(m1)
> > On 2/16/21 8:18 AM, Phillip Alday wrote:
> >
> > > I suspect we'll need to know a bit more about your data to answer this
> > > question. Can you share it in any form (e.g. variables renamed and
> > > levels of factors changed to something opaque) ?
> > > Best,
> > > Phillip
> > > On 16/2/21 4:02 am, Peter R Law via R-sig-mixed-models wrote:
> > >
> > > > I am trying to fit a model with two covariates, x and z say, for response y, with a random factor g and want each of x and y to have a random slope. I expected
> > > > lmer(y ~ x + z + (x+z|g),...)
> > > > to fit a model with 6 random variance components, the intercept, two slopes and three correlations. But I got an error message saying there were 74 random variance components and my data was insufficient to fit the model. Yet
> > > > lmer(y ~ x + z + (x+z||g),...)
> > > > returned what I expected, a model with the random intercept and two slopes but no correlations. How is lmer interpreting the first line of code above and how I would code for what I want. I have not been able to find any examples in the literature or online that help me but I may have easily missed something so if anyone knows of a useful link that'd be great. The only examples of multiple random slopes I've seen take the form
> > > > lmer(y~x + z +(x|g) + (z|g),...)
> > > > specifically excluding correlations between the random slopes and intercept of the two predictors. Even if the latter is a more sensible approach I'd like to understand the coding issue.
> > > > Thanks.
> > > > Peter
> > > > Sent with ProtonMail Secure Email.
> > > > [[alternative HTML version deleted]]
> > > > R-sig-mixed-models at r-project.org mailing list
> > > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > >
> > > R-sig-mixed-models at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: Trial.txt
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20210225/877b0eb9/attachment.txt>

From y@@hree19 @end|ng |rom gm@||@com  Thu Feb 25 16:16:08 2021
From: y@@hree19 @end|ng |rom gm@||@com (Yashree Mehta)
Date: Thu, 25 Feb 2021 16:16:08 +0100
Subject: [R-sig-ME] Residual Variance-Covariance matrix
Message-ID: <CAOE=hqKTTHxSChkLvxuO1USoCtk+ZmBbKtr6kDhxu=Xa438pZA@mail.gmail.com>

Hi,

I am using the following the code to extract the residual
variance-covariance matrix cov(Yi/Xi):

I first fit the model with the name lmemod_lme4. I have an unbalanced
cluster dataset.

Then, I extracted components with the following:

var.d <- crossprod(getME(lmemod_lme4,"Lambdat"))
Zt <- getME(lmemod_lme4,"Zt")
vr <- sigma(lmemod_lme4)^2

Then, I combine them with the following:

var.b <- t(Zt) %*% var.d %*% Zt
sI <- vr * Diagonal(nrow(Nameofdataset))
var.y <- var.b + sI

I have 2799 observations in my dataset. MY var.y matrix has dimension
2799 times 2799. Is there now a way to extract the

cov(Yi/Xi) for each observation? Also, I get a very large value for
the determinant of var.y.

I would be grateful to get further guidance on this.

Thank you very much.

Regards

	[[alternative HTML version deleted]]


From me @end|ng |rom ph||||p@|d@y@com  Thu Feb 25 16:26:25 2021
From: me @end|ng |rom ph||||p@|d@y@com (Phillip Alday)
Date: Thu, 25 Feb 2021 16:26:25 +0100
Subject: [R-sig-ME] lmer code for multiple random slopes
In-Reply-To: <e2zoG5je3QHzcPl3dsttnLigMgzR8mqiUJAdgntQm9xPOX4j3SwlDytjMtbOFRj-vf5TjpHVRD7rzd54mvwMFm9OhW-ff4lfhR383lioPX4=@protonmail.com>
References: <34JKCz24u8awawkhTLmboO_cBRWW-m0XAb0frTUb9YqspQe1VeBBWUvfqKd3-QIMLeKpiDUyzhN0X6aqRlEqwX1LmBfg3gn9EB2XCa5v62s=@protonmail.com>
 <1877a680-d190-7202-537d-90d51bc6574b@phillipalday.com>
 <de6401b0-6cac-65d8-cbc3-0f59ce79409d@gmail.com>
 <NCGF24lxdAy2bcOAoQsutEkYQ-ZIzb4e3xLenmSDhGyZN8a8sIcv-wHF0IEfLK8GQGccVE1hLTk-i1UPxFITTgLC9T929E6F4rQVMwVN8bg=@protonmail.com>
 <e2zoG5je3QHzcPl3dsttnLigMgzR8mqiUJAdgntQm9xPOX4j3SwlDytjMtbOFRj-vf5TjpHVRD7rzd54mvwMFm9OhW-ff4lfhR383lioPX4=@protonmail.com>
Message-ID: <f286a096-f420-c246-61ad-542eaa5dad44@phillipalday.com>



On 25/2/21 5:16 am, Peter R Law via R-sig-mixed-models wrote:
> Alas I am still puzzled. I have extracted some data in trial.txt (no categorical variables) and attached some code in trial.R. I am only using this data to test code, which I hope to apply to a larger data set obtained from multiple populations, so with more structure. So the results themselves are not important, only whether the code does what I think it should. It occurred to me to test each model with lme and lmer.
> 
> For a model with only a random intercept plus fixed effects, lme and lmer returned the same results, except that lme returns estimates with more decimal places (so here lmer returned zero variance for the random intercpt and lme a very small number).

This is to be expected: lme can't handle singular models (e.g. models
with an exactly zero variance component), but lmer can. So lme just gets
as close as it can.

> 
> Adding a random slope, the main difference in the results is that lme and lmer returned very different estimates of the slope variance. Is that surprising?

It depends on what's going wrong. Generally these should return
identical fits for converged models (with the fine print that there are
certain models that you can specify in one but not the other without a
lot of effort).


> 
> For a model with two random slopes, lme returned results as expected but lmer still claims there are 78 variance components, which is the number one would get from a 12 x 12 covariance matrix. Where the number 12 comes from is a mystery to me, especially as lme does what I expected (I ran this model with both raw data and normalized predictor values to see if something fishy was happening there but no):

The list strips most attachment types, so your script didn't make it
through. But just your data was enough for me to find a few problems

First, you're fitting and displaying two different models here:

> 
>> M5n <- lme(Response~normP+normA, random=~normP+normA|Group,data=Trial, method="ML")
>> summary(M2n)

Second, when I try to fit the model that's given by the summary here, I
get a numerical error in lme:

> lme(Response~P+A, random=~P+A|Group,data=Trial, method="ML")
Error in lme.formula(Response ~ P + A, random = ~P + A | Group, data =
Trial,  :
  nlminb problem, convergence error code = 1
  message = false convergence (8)


This makes me think that something is wrong wrong in both bits of
software, but maybe the versions on your local machine are catching it



> Linear mixed-effects model fit by maximum likelihood
>  Data: Trial
>        AIC      BIC    logLik
>   536.4562 559.4969 -258.2281
> 
> Random effects:
>  Formula: ~P + A | Group
>  Structure: General positive-definite, Log-Cholesky parametrization
>             StdDev       Corr
> (Intercept) 3.061144e-04 (Intr) P
> P           1.535752e-09 0
> A           8.517774e-13 0      0
> Residual    7.929821e+00
> 
> Fixed effects: Response ~ P + A
>                 Value Std.Error DF    t-value p-value
> (Intercept) 25.453398 10.828841 46  2.3505192  0.0231
> P           -0.029307  0.035939 46 -0.8154787  0.4190
> A            0.140819  0.282018 46  0.4993255  0.6199
>  Correlation:
>   (Intr) P
> P -0.033
> A -0.975 -0.173
> 
> Standardized Within-Group Residuals:
>        Min         Q1        Med         Q3        Max
> -1.8447131 -0.5563605 -0.2613520  0.2755547  5.5643551
> 
> Number of Observations: 74
> Number of Groups: 26
>> M5 <- lmer(Response~normP+normA+(normP+normA|Group), REML="False", data=Trial)
> Error: number of observations (=74) <= number of random effects (=78) for term (normP + normA | Group); the random-effects parameters and the residual variance (or scale parameter) are probably unidentifiable.

This screams that your normP and normA variables aren't being handled as
continuous but rather categorical/factors. This means that you have a
lot more slopes being estimated, which the model survives, but not the
extra correlation parameters (hence the success when you suppress them
with the two syntax variants you mention below).



> It didn't matter which pair of the three predictors I used as far as the error message lmer returned but lme only returned results for P+A, not any pair involving PR, which apparently created computational issues, distinct to the interpretation of the code.
> 
> In lmer, replacing the code (x+y|Group) by either (x+y||Group) or (X|Group) + (Y|Group) returned the expected results (in that lme4 interpreted the code as expected). Is there lme code for either of these models?
> 
> Many thanks for any help.
> 
> Peter
> 
> P. S. I just noticed that responding to Ben's email sends my email to Ben, not to r-sig. I hope that sending my email to r-sig is the right thing to do and doesn't break the chain to my previous email.

Yep! Frequently, we have the reverse problem: people forget to keep the
list in CC. So thanks! The matching in the threading is handled mostly
by the subject line.


> 
> 
> Sent with ProtonMail Secure Email.
> 
> ??????? Original Message ???????
> On Wednesday, February 17, 2021 10:40 PM, Peter R Law <prldb at protonmail.com> wrote:
> 
>> Thanks for your quick response. I take it that the code should mean what I thought it would and that somehow lmer is not interpreting what I wrote in my actual example as intended. None of the variables are categorical but I'll give it some more thought and see if I can figure it out. If not, I'll provide more details.
>>
>> Peter
>>
>> Sent with ProtonMail Secure Email.
>>
>> ??????? Original Message ???????
>> On Tuesday, February 16, 2021 10:04 AM, Ben Bolker bbolker at gmail.com wrote:
>>
>>> I second Phillip's point. The example below works as expected (gets
>>> a singular fit, but there are 6 covariance parameters as expected).
>>> Based on what you've told us so far, the most plausible explanation is
>>> that one or both of your covariates (x and/or z) are factors
>>> (categorical) rather than numeric.
>>> Ben Bolker
>>> ============================================================================================================================================================================================================================================================================================================================
>>> set.seed(101)
>>> dd <- data.frame(x=rnorm(500),z=rnorm(500),
>>> g=factor(sample(1:6,size=500,replace=TRUE)))
>>> form <- y ~ x + z + (x+z|g)
>>> dd$y <- simulate(form[-2],
>>> newdata=dd,
>>> newparams=list(beta=rep(0,3),
>>> theta=rep(1,6),
>>> sigma=1))[[1]]
>>> library(lme4)
>>> m1 <- lmer(form, data=dd)
>>> VarCorr(m1)
>>> On 2/16/21 8:18 AM, Phillip Alday wrote:
>>>
>>>> I suspect we'll need to know a bit more about your data to answer this
>>>> question. Can you share it in any form (e.g. variables renamed and
>>>> levels of factors changed to something opaque) ?
>>>> Best,
>>>> Phillip
>>>> On 16/2/21 4:02 am, Peter R Law via R-sig-mixed-models wrote:
>>>>
>>>>> I am trying to fit a model with two covariates, x and z say, for response y, with a random factor g and want each of x and y to have a random slope. I expected
>>>>> lmer(y ~ x + z + (x+z|g),...)
>>>>> to fit a model with 6 random variance components, the intercept, two slopes and three correlations. But I got an error message saying there were 74 random variance components and my data was insufficient to fit the model. Yet
>>>>> lmer(y ~ x + z + (x+z||g),...)
>>>>> returned what I expected, a model with the random intercept and two slopes but no correlations. How is lmer interpreting the first line of code above and how I would code for what I want. I have not been able to find any examples in the literature or online that help me but I may have easily missed something so if anyone knows of a useful link that'd be great. The only examples of multiple random slopes I've seen take the form
>>>>> lmer(y~x + z +(x|g) + (z|g),...)
>>>>> specifically excluding correlations between the random slopes and intercept of the two predictors. Even if the latter is a more sensible approach I'd like to understand the coding issue.
>>>>> Thanks.
>>>>> Peter
>>>>> Sent with ProtonMail Secure Email.
>>>>> [[alternative HTML version deleted]]
>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From |@ur@coco @end|ng |rom gm@||@com  Thu Feb 25 18:36:28 2021
From: |@ur@coco @end|ng |rom gm@||@com (Laura Coco)
Date: Thu, 25 Feb 2021 10:36:28 -0700
Subject: [R-sig-ME] question regarding time as a continuous factor in a
 linear mixed effects model
Message-ID: <CAKgKnP6Nx9Ee=vhPd6JtbUrzw4iyeXjh-=FZo9zCTo5RtcTjkQ@mail.gmail.com>

Hello,

I am interested in investigating the main effects of group, time, and group
by time interaction on survey outcomes using linear mixed effects models.
Time is considered as continuous (number of days since baseline), but isn't
it also categorical, since I want to compare Session 1 vs Session 4 (for
example)? How is that handled in the model? As of now, time (days since
baseline) is being treated as one unit, rather than four separate sessions.

Here is an example of my code: mdl.outcome <- lmer(outcome ~ time*Group +
(1 | PID), data = dta)

Thank you!!

	[[alternative HTML version deleted]]


From Andre@Syvert@en @end|ng |rom u|b@no  Fri Feb 26 11:20:18 2021
From: Andre@Syvert@en @end|ng |rom u|b@no (Andre Syvertsen)
Date: Fri, 26 Feb 2021 10:20:18 +0000
Subject: [R-sig-ME] Help: Interpreting unusual model fit results from
 generalized linear mixed model (glmmTMB/sjPlot)
Message-ID: <AM6PR0102MB31748BFF6EAF4FEA67D042809E9D9@AM6PR0102MB3174.eurprd01.prod.exchangelabs.com>

Hi,

I am working with a large dataset that contains longitudinal data on gambling behavior of 184,113 participants. The data is based on complete tracking of electronic gambling behavior within a gambling operator. Gambling behavior data is aggregated on a monthly level, a total of 70 months. I have an ID variable separating participants, a time variable (months), as well as numerous gambling behavior variables such as active days played for given month, bets placed for given month, total losses for given month, etc. I am investigating the role of age and gender in predicting active days gambling per month.

I have fitted a model with glmmTMB (see below for model code) and outputed the resulting statistics with sjPlot's tab_model function which I am having trouble interpreting. The full results can be found below. Notably, I appear to have gotten perfect intra-class correlation. While, I am sure variance in outcome responses (active days gambling) are likely to be heavily associated with subject and time, this seems excessive. Furthermore, the pseudo R2 suggests that 8.7% of the variance should be attributable to fixed effects which I would think would lower the variance attributable to individual/time? Are the results affected by the high number of observations, individuals and/or time points? Or maybe I have specified my model in an odd manner?

glmmTMB code for the model:

DaysPlayedConditionalAgeGenderTruncated <- glmmTMB(daysPlayed ~ 1 + time + ageCategory * gender + (time | id), dfLong, family = truncated_nbinom2)

Model summary:

Active Gambling Days Monthly
Predictors
Incidence Rate Ratios
CI
p
(Intercept)
1.18
1.16 ?C 1.20
<0.001
Time
0.99
0.99 ?C 0.99
<0.001
Age Category 30-39
1.29
1.26 ?C 1.32
<0.001
Age Category 40-49
1.81
1.78 ?C 1.85
<0.001
Age Category 50-59
2.47
2.41 ?C 2.53
<0.001
Age Category 60-69
3.08
2.99 ?C 3.17
<0.001
Age Category 70+
3.42
3.29 ?C 3.56
<0.001
Gender: Women
1.69
1.65 ?C 1.74
<0.001
Age Category 30-39:Women
0.90
0.86 ?C 0.94
<0.001
Age Category 40-49:Women
0.67
0.65 ?C 0.70
<0.001
Age Category 50-59:Women
0.53
0.50 ?C 0.55
<0.001
Age Category 60-69: Women
0.46
0.44 ?C 0.48
<0.001
Age Category 70+:Women
0.45
0.43 ?C 0.48
<0.001
Random Effects
??2
0.00
??00 id
1.63
??11 id.time
0.00
??01 id
-0.38
ICC
1.00
N id
184113
Observations
3231544
Marginal R2 / Conditional R2
0.087 / 1.000
Note. Intercept = Men, age 18-29 years, first time point (month 0 of 69).


Kind regards,
Andr??

	[[alternative HTML version deleted]]


From Andre@Syvert@en @end|ng |rom u|b@no  Fri Feb 26 12:35:11 2021
From: Andre@Syvert@en @end|ng |rom u|b@no (Andre Syvertsen)
Date: Fri, 26 Feb 2021 11:35:11 +0000
Subject: [R-sig-ME] Help: Interpreting unusual model fit results from
 generalized linear mixed model (glmmTMB/sjPlot) (Andre Syvertsen)
In-Reply-To: <mailman.18982.2981.1614334898.1405.r-sig-mixed-models@r-project.org>
References: <mailman.18982.2981.1614334898.1405.r-sig-mixed-models@r-project.org>
Message-ID: <AM6PR0102MB3174D49D6FB38503B27EA00E9E9D9@AM6PR0102MB3174.eurprd01.prod.exchangelabs.com>

Text version of table:

  Active Gambling Days Monthly
Predictors Incidence Rate Ratios, CI,  p
(Intercept):   1.18, 1.16 ? 1.20,  <0.001
Time : 0.99, 0.99 ? 0.99,  <0.001
Age Category 30-39:  1.29, 1.26 ? 1.32, <0.001
Age Category 40-49:  1.81, 1.78 ? 1.85, <0.001
Age Category 50-59:  2.47, 2.41 ? 2.53, <0.001
Age Category 60-69:  3.08, 2.99 ? 3.17, <0.001
Age Category 70+:  3.42, 3.29 ? 3.56, <0.001
Gender-Women:   1.69, 1.65 ? 1.74, <0.001
Age Category 30-39-Women: 0.90, 0.86 ? 0.94, <0.001
Age Category 40-49-Women: 0.67, 0.65 ? 0.70, <0.001
Age Category 50-59-Women: 0.53, 0.50 ? 0.55, <0.001
Age Category 60-69- Women: 0.46, 0.44 ? 0.48, <0.001
Age Category 70+-Women:  0.45, 0.43 ? 0.48, <0.001

Random Effects
?2 0.00
?00 id 1.63
?11 id.time 0.00
?01 id -0.38
ICC 1.00
N id 184113

Observations 3,231,544
Marginal R2 / Conditional R2 0.087 / 1.000
Note: Intercept = Men, age 18-29 years, first time point (month 0 of 69).


________________________________
Fra: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> p? vegne av r-sig-mixed-models-request at r-project.org <r-sig-mixed-models-request at r-project.org>
Sendt: fredag 26. februar 2021 11:21
Til: r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>
Emne: R-sig-mixed-models Digest, Vol 170, Issue 20

Send R-sig-mixed-models mailing list submissions to
        r-sig-mixed-models at r-project.org

To subscribe or unsubscribe via the World Wide Web, visit
        https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
or, via email, send a message with subject or body 'help' to
        r-sig-mixed-models-request at r-project.org

You can reach the person managing the list at
        r-sig-mixed-models-owner at r-project.org

When replying, please edit your Subject line so it is more specific
than "Re: Contents of R-sig-mixed-models digest..."


Today's Topics:

   1. Residual Variance-Covariance matrix (Yashree Mehta)
   2. Re: lmer code for multiple random slopes (Phillip Alday)
   3. question regarding time as a continuous factor in a linear
      mixed effects model (Laura Coco)
   4. Help: Interpreting unusual model fit results from generalized
      linear mixed model (glmmTMB/sjPlot) (Andre Syvertsen)

----------------------------------------------------------------------

Message: 1
Date: Thu, 25 Feb 2021 16:16:08 +0100
From: Yashree Mehta <yashree19 at gmail.com>
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] Residual Variance-Covariance matrix
Message-ID:
        <CAOE=hqKTTHxSChkLvxuO1USoCtk+ZmBbKtr6kDhxu=Xa438pZA at mail.gmail.com>
Content-Type: text/plain; charset="utf-8"

Hi,

I am using the following the code to extract the residual
variance-covariance matrix cov(Yi/Xi):

I first fit the model with the name lmemod_lme4. I have an unbalanced
cluster dataset.

Then, I extracted components with the following:

var.d <- crossprod(getME(lmemod_lme4,"Lambdat"))
Zt <- getME(lmemod_lme4,"Zt")
vr <- sigma(lmemod_lme4)^2

Then, I combine them with the following:

var.b <- t(Zt) %*% var.d %*% Zt
sI <- vr * Diagonal(nrow(Nameofdataset))
var.y <- var.b + sI

I have 2799 observations in my dataset. MY var.y matrix has dimension
2799 times 2799. Is there now a way to extract the

cov(Yi/Xi) for each observation? Also, I get a very large value for
the determinant of var.y.

I would be grateful to get further guidance on this.

Thank you very much.

Regards

        [[alternative HTML version deleted]]




------------------------------

Message: 2
Date: Thu, 25 Feb 2021 16:26:25 +0100
From: Phillip Alday <me at phillipalday.com>
To: Peter R Law <prldb at protonmail.com>,
        "r-sig-mixed-models at r-project.org" <r-sig-mixed-models at r-project.org>,
        Ben Bolker <bbolker at gmail.com>
Subject: Re: [R-sig-ME] lmer code for multiple random slopes
Message-ID: <f286a096-f420-c246-61ad-542eaa5dad44 at phillipalday.com>
Content-Type: text/plain; charset="utf-8"



On 25/2/21 5:16 am, Peter R Law via R-sig-mixed-models wrote:
> Alas I am still puzzled. I have extracted some data in trial.txt (no categorical variables) and attached some code in trial.R. I am only using this data to test code, which I hope to apply to a larger data set obtained from multiple populations, so with more structure. So the results themselves are not important, only whether the code does what I think it should. It occurred to me to test each model with lme and lmer.
>
> For a model with only a random intercept plus fixed effects, lme and lmer returned the same results, except that lme returns estimates with more decimal places (so here lmer returned zero variance for the random intercpt and lme a very small number).

This is to be expected: lme can't handle singular models (e.g. models
with an exactly zero variance component), but lmer can. So lme just gets
as close as it can.

>
> Adding a random slope, the main difference in the results is that lme and lmer returned very different estimates of the slope variance. Is that surprising?

It depends on what's going wrong. Generally these should return
identical fits for converged models (with the fine print that there are
certain models that you can specify in one but not the other without a
lot of effort).


>
> For a model with two random slopes, lme returned results as expected but lmer still claims there are 78 variance components, which is the number one would get from a 12 x 12 covariance matrix. Where the number 12 comes from is a mystery to me, especially as lme does what I expected (I ran this model with both raw data and normalized predictor values to see if something fishy was happening there but no):

The list strips most attachment types, so your script didn't make it
through. But just your data was enough for me to find a few problems

First, you're fitting and displaying two different models here:

>
>> M5n <- lme(Response~normP+normA, random=~normP+normA|Group,data=Trial, method="ML")
>> summary(M2n)

Second, when I try to fit the model that's given by the summary here, I
get a numerical error in lme:

> lme(Response~P+A, random=~P+A|Group,data=Trial, method="ML")
Error in lme.formula(Response ~ P + A, random = ~P + A | Group, data =
Trial,  :
  nlminb problem, convergence error code = 1
  message = false convergence (8)


This makes me think that something is wrong wrong in both bits of
software, but maybe the versions on your local machine are catching it



> Linear mixed-effects model fit by maximum likelihood
>  Data: Trial
>        AIC      BIC    logLik
>   536.4562 559.4969 -258.2281
>
> Random effects:
>  Formula: ~P + A | Group
>  Structure: General positive-definite, Log-Cholesky parametrization
>             StdDev       Corr
> (Intercept) 3.061144e-04 (Intr) P
> P           1.535752e-09 0
> A           8.517774e-13 0      0
> Residual    7.929821e+00
>
> Fixed effects: Response ~ P + A
>                 Value Std.Error DF    t-value p-value
> (Intercept) 25.453398 10.828841 46  2.3505192  0.0231
> P           -0.029307  0.035939 46 -0.8154787  0.4190
> A            0.140819  0.282018 46  0.4993255  0.6199
>  Correlation:
>   (Intr) P
> P -0.033
> A -0.975 -0.173
>
> Standardized Within-Group Residuals:
>        Min         Q1        Med         Q3        Max
> -1.8447131 -0.5563605 -0.2613520  0.2755547  5.5643551
>
> Number of Observations: 74
> Number of Groups: 26
>> M5 <- lmer(Response~normP+normA+(normP+normA|Group), REML="False", data=Trial)
> Error: number of observations (=74) <= number of random effects (=78) for term (normP + normA | Group); the random-effects parameters and the residual variance (or scale parameter) are probably unidentifiable.

This screams that your normP and normA variables aren't being handled as
continuous but rather categorical/factors. This means that you have a
lot more slopes being estimated, which the model survives, but not the
extra correlation parameters (hence the success when you suppress them
with the two syntax variants you mention below).



> It didn't matter which pair of the three predictors I used as far as the error message lmer returned but lme only returned results for P+A, not any pair involving PR, which apparently created computational issues, distinct to the interpretation of the code.
>
> In lmer, replacing the code (x+y|Group) by either (x+y||Group) or (X|Group) + (Y|Group) returned the expected results (in that lme4 interpreted the code as expected). Is there lme code for either of these models?
>
> Many thanks for any help.
>
> Peter
>
> P. S. I just noticed that responding to Ben's email sends my email to Ben, not to r-sig. I hope that sending my email to r-sig is the right thing to do and doesn't break the chain to my previous email.

Yep! Frequently, we have the reverse problem: people forget to keep the
list in CC. So thanks! The matching in the threading is handled mostly
by the subject line.


>
>
> Sent with ProtonMail Secure Email.
>
> ??????? Original Message ???????
> On Wednesday, February 17, 2021 10:40 PM, Peter R Law <prldb at protonmail.com> wrote:
>
>> Thanks for your quick response. I take it that the code should mean what I thought it would and that somehow lmer is not interpreting what I wrote in my actual example as intended. None of the variables are categorical but I'll give it some more thought and see if I can figure it out. If not, I'll provide more details.
>>
>> Peter
>>
>> Sent with ProtonMail Secure Email.
>>
>> ??????? Original Message ???????
>> On Tuesday, February 16, 2021 10:04 AM, Ben Bolker bbolker at gmail.com wrote:
>>
>>> I second Phillip's point. The example below works as expected (gets
>>> a singular fit, but there are 6 covariance parameters as expected).
>>> Based on what you've told us so far, the most plausible explanation is
>>> that one or both of your covariates (x and/or z) are factors
>>> (categorical) rather than numeric.
>>> Ben Bolker
>>> ============================================================================================================================================================================================================================================================================================================================
>>> set.seed(101)
>>> dd <- data.frame(x=rnorm(500),z=rnorm(500),
>>> g=factor(sample(1:6,size=500,replace=TRUE)))
>>> form <- y ~ x + z + (x+z|g)
>>> dd$y <- simulate(form[-2],
>>> newdata=dd,
>>> newparams=list(beta=rep(0,3),
>>> theta=rep(1,6),
>>> sigma=1))[[1]]
>>> library(lme4)
>>> m1 <- lmer(form, data=dd)
>>> VarCorr(m1)
>>> On 2/16/21 8:18 AM, Phillip Alday wrote:
>>>
>>>> I suspect we'll need to know a bit more about your data to answer this
>>>> question. Can you share it in any form (e.g. variables renamed and
>>>> levels of factors changed to something opaque) ?
>>>> Best,
>>>> Phillip
>>>> On 16/2/21 4:02 am, Peter R Law via R-sig-mixed-models wrote:
>>>>
>>>>> I am trying to fit a model with two covariates, x and z say, for response y, with a random factor g and want each of x and y to have a random slope. I expected
>>>>> lmer(y ~ x + z + (x+z|g),...)
>>>>> to fit a model with 6 random variance components, the intercept, two slopes and three correlations. But I got an error message saying there were 74 random variance components and my data was insufficient to fit the model. Yet
>>>>> lmer(y ~ x + z + (x+z||g),...)
>>>>> returned what I expected, a model with the random intercept and two slopes but no correlations. How is lmer interpreting the first line of code above and how I would code for what I want. I have not been able to find any examples in the literature or online that help me but I may have easily missed something so if anyone knows of a useful link that'd be great. The only examples of multiple random slopes I've seen take the form
>>>>> lmer(y~x + z +(x|g) + (z|g),...)
>>>>> specifically excluding correlations between the random slopes and intercept of the two predictors. Even if the latter is a more sensible approach I'd like to understand the coding issue.
>>>>> Thanks.
>>>>> Peter
>>>>> Sent with ProtonMail Secure Email.
>>>>> [[alternative HTML version deleted]]
>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>




------------------------------

Message: 3
Date: Thu, 25 Feb 2021 10:36:28 -0700
From: Laura Coco <lauracoco at gmail.com>
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] question regarding time as a continuous factor in
        a linear mixed effects model
Message-ID:
        <CAKgKnP6Nx9Ee=vhPd6JtbUrzw4iyeXjh-=FZo9zCTo5RtcTjkQ at mail.gmail.com>
Content-Type: text/plain; charset="utf-8"

Hello,

I am interested in investigating the main effects of group, time, and group
by time interaction on survey outcomes using linear mixed effects models.
Time is considered as continuous (number of days since baseline), but isn't
it also categorical, since I want to compare Session 1 vs Session 4 (for
example)? How is that handled in the model? As of now, time (days since
baseline) is being treated as one unit, rather than four separate sessions.

Here is an example of my code: mdl.outcome <- lmer(outcome ~ time*Group +
(1 | PID), data = dta)

Thank you!!

        [[alternative HTML version deleted]]




------------------------------

Message: 4
Date: Fri, 26 Feb 2021 10:20:18 +0000
From: Andre Syvertsen <Andre.Syvertsen at uib.no>
To: "r-sig-mixed-models at r-project.org"
        <r-sig-mixed-models at r-project.org>
Subject: [R-sig-ME] Help: Interpreting unusual model fit results from
        generalized linear mixed model (glmmTMB/sjPlot)
Message-ID:
        <AM6PR0102MB31748BFF6EAF4FEA67D042809E9D9 at AM6PR0102MB3174.eurprd01.prod.exchangelabs.com>

Content-Type: text/plain; charset="utf-8"

Hi,

I am working with a large dataset that contains longitudinal data on gambling behavior of 184,113 participants. The data is based on complete tracking of electronic gambling behavior within a gambling operator. Gambling behavior data is aggregated on a monthly level, a total of 70 months. I have an ID variable separating participants, a time variable (months), as well as numerous gambling behavior variables such as active days played for given month, bets placed for given month, total losses for given month, etc. I am investigating the role of age and gender in predicting active days gambling per month.

I have fitted a model with glmmTMB (see below for model code) and outputed the resulting statistics with sjPlot's tab_model function which I am having trouble interpreting. The full results can be found below. Notably, I appear to have gotten perfect intra-class correlation. While, I am sure variance in outcome responses (active days gambling) are likely to be heavily associated with subject and time, this seems excessive. Furthermore, the pseudo R2 suggests that 8.7% of the variance should be attributable to fixed effects which I would think would lower the variance attributable to individual/time? Are the results affected by the high number of observations, individuals and/or time points? Or maybe I have specified my model in an odd manner?

glmmTMB code for the model:

DaysPlayedConditionalAgeGenderTruncated <- glmmTMB(daysPlayed ~ 1 + time + ageCategory * gender + (time | id), dfLong, family = truncated_nbinom2)

Model summary:

Active Gambling Days Monthly
Predictors
Incidence Rate Ratios
CI
p
(Intercept)
1.18
1.16 ?C 1.20
<0.001
Time
0.99
0.99 ?C 0.99
<0.001
Age Category 30-39
1.29
1.26 ?C 1.32
<0.001
Age Category 40-49
1.81
1.78 ?C 1.85
<0.001
Age Category 50-59
2.47
2.41 ?C 2.53
<0.001
Age Category 60-69
3.08
2.99 ?C 3.17
<0.001
Age Category 70+
3.42
3.29 ?C 3.56
<0.001
Gender: Women
1.69
1.65 ?C 1.74
<0.001
Age Category 30-39:Women
0.90
0.86 ?C 0.94
<0.001
Age Category 40-49:Women
0.67
0.65 ?C 0.70
<0.001
Age Category 50-59:Women
0.53
0.50 ?C 0.55
<0.001
Age Category 60-69: Women
0.46
0.44 ?C 0.48
<0.001
Age Category 70+:Women
0.45
0.43 ?C 0.48
<0.001
Random Effects
??2
0.00
??00 id
1.63
??11 id.time
0.00
??01 id
-0.38
ICC
1.00
N id
184113
Observations
3231544
Marginal R2 / Conditional R2
0.087 / 1.000
Note. Intercept = Men, age 18-29 years, first time point (month 0 of 69).


Kind regards,
Andr??

        [[alternative HTML version deleted]]



------------------------------

Subject: Digest Footer

_______________________________________________
R-sig-mixed-models mailing list
R-sig-mixed-models at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


------------------------------

End of R-sig-mixed-models Digest, Vol 170, Issue 20
***************************************************

	[[alternative HTML version deleted]]


From p@u|@john@on @end|ng |rom g|@@gow@@c@uk  Fri Feb 26 15:21:55 2021
From: p@u|@john@on @end|ng |rom g|@@gow@@c@uk (Paul Johnson)
Date: Fri, 26 Feb 2021 14:21:55 +0000
Subject: [R-sig-ME] Help: Interpreting unusual model fit results from
 generalized linear mixed model (glmmTMB/sjPlot)
Message-ID: <AE8913F6-DEDA-4BC1-987E-667BBD793A28@glasgow.ac.uk>

Hi Andre,

I'm not very familiar with sjPlot, so these are partially guesses... 

On the technical question... I think the ICC in tab_model doesn't include fixed effects, so for your model it's the ID variance divided by the total (non-fixed) variance, which is the ID variance plus the distribution-specific variance. ICC = 1 and conditional R2 = 1, therefore the distribution-specific variance must be zero, or at most tiny relative to the ID variance. I'm not sure how tab_model calculates the distribution-specific variance for negative binomial, or how it accounts for zero-truncation (or zero-inflation), but digging into it a bit, it looks like it's log(1 + 1/lambda + 1/theta), where lambda is the mean and theta the dispersion parameter of the negative binomial (see the help for insight::get_variance, and Table 1 and Appendix S1 of Nakagawa et al.*). This will be close to zero when both parameters are very large. A very large theta implies that the distribution is not overdispersed relative to Poisson (it could of course be underdispersed). A very large lambda implies that the predicted mean of the (untruncated I think) NB distribution is large. If both of these match what you see in your model fit, that might help to explain what you're seeing. You could also calculate the random effect variance to compare with the distribution specific variance, but as you have random slopes this isn't straightforward.

Stepping back a bit from the technical question... tab_model outputs all of these numbers by default but which ones are actually useful to you? I guess the R2 value could be useful -- it's telling you that the variance of the fixed effects is about a tenth of the variance of the random effect, i.e. there's a lot of unexplained variation at the ID level. Interpretation is complicated though by the fact that the RE variance contains variation in one of the fixed effects, the time effect. Perhaps ICC and R2 just aren't useful here?

Stepping back a bit further, it looks like your response variable is capped at 28-31 active days per month depending on the month. Depending on how frequently the participants gamble, I can see why there might not be a great deal of overdispersion. I also wonder why the distribution needs to be zero-truncated. Did every participant gamble for at least one day per month? Or do you only get data for a participant when they gamble for at least one day? In which case shouldn't you create zeroes in the other months for these participants? Does NB fit well, or would a beta distribution work better, where the response is proportion of gambling days each month (with a small buffer to keep the extremes away from 0 and 1)? It'll depend on the distribution, I can also imagine why a count distribution might work here.

Hope that helps,
Paul

*Nakagawa et al. (2017). The coefficient of determination R2 and intra-class correlation coefficient from generalized linear mixed-effects models revisited and expanded. Journal of The Royal Society Interface, 14(134), 20170213. doi: 10.1098/rsif.2017.0213


?On 26/02/2021, 10:22, "R-sig-mixed-models on behalf of Andre Syvertsen" <r-sig-mixed-models-bounces at r-project.org on behalf of Andre.Syvertsen at uib.no> wrote:

    Hi,

    I am working with a large dataset that contains longitudinal data on gambling behavior of 184,113 participants. The data is based on complete tracking of electronic gambling behavior within a gambling operator. Gambling behavior data is aggregated on a monthly level, a total of 70 months. I have an ID variable separating participants, a time variable (months), as well as numerous gambling behavior variables such as active days played for given month, bets placed for given month, total losses for given month, etc. I am investigating the role of age and gender in predicting active days gambling per month.

    I have fitted a model with glmmTMB (see below for model code) and outputed the resulting statistics with sjPlot's tab_model function which I am having trouble interpreting. The full results can be found below. Notably, I appear to have gotten perfect intra-class correlation. While, I am sure variance in outcome responses (active days gambling) are likely to be heavily associated with subject and time, this seems excessive. Furthermore, the pseudo R2 suggests that 8.7% of the variance should be attributable to fixed effects which I would think would lower the variance attributable to individual/time? Are the results affected by the high number of observations, individuals and/or time points? Or maybe I have specified my model in an odd manner?

    glmmTMB code for the model:

    DaysPlayedConditionalAgeGenderTruncated <- glmmTMB(daysPlayed ~ 1 + time + ageCategory * gender + (time | id), dfLong, family = truncated_nbinom2)

    Model summary:

    Active Gambling Days Monthly
    Predictors
    Incidence Rate Ratios
    CI
    p
    (Intercept)
    1.18
    1.16 ?C 1.20
    <0.001
    Time
    0.99
    0.99 ?C 0.99
    <0.001
    Age Category 30-39
    1.29
    1.26 ?C 1.32
    <0.001
    Age Category 40-49
    1.81
    1.78 ?C 1.85
    <0.001
    Age Category 50-59
    2.47
    2.41 ?C 2.53
    <0.001
    Age Category 60-69
    3.08
    2.99 ?C 3.17
    <0.001
    Age Category 70+
    3.42
    3.29 ?C 3.56
    <0.001
    Gender: Women
    1.69
    1.65 ?C 1.74
    <0.001
    Age Category 30-39:Women
    0.90
    0.86 ?C 0.94
    <0.001
    Age Category 40-49:Women
    0.67
    0.65 ?C 0.70
    <0.001
    Age Category 50-59:Women
    0.53
    0.50 ?C 0.55
    <0.001
    Age Category 60-69: Women
    0.46
    0.44 ?C 0.48
    <0.001
    Age Category 70+:Women
    0.45
    0.43 ?C 0.48
    <0.001
    Random Effects
    ??2
    0.00
    ??00 id
    1.63
    ??11 id.time
    0.00
    ??01 id
    -0.38
    ICC
    1.00
    N id
    184113
    Observations
    3231544
    Marginal R2 / Conditional R2
    0.087 / 1.000
    Note. Intercept = Men, age 18-29 years, first time point (month 0 of 69).


    Kind regards,
    Andr??

    	[[alternative HTML version deleted]]



From d@|uedecke @end|ng |rom uke@de  Fri Feb 26 17:20:43 2021
From: d@|uedecke @end|ng |rom uke@de (=?UTF-8?Q?Daniel_L=C3=BCdecke?=)
Date: Fri, 26 Feb 2021 17:20:43 +0100
Subject: [R-sig-ME] Help: Interpreting unusual model fit results from
 generalized linear mixed model (glmmTMB/sjPlot) (Andre Syvertsen)
In-Reply-To: <AM6PR0102MB3174D49D6FB38503B27EA00E9E9D9@AM6PR0102MB3174.eurprd01.prod.exchangelabs.com>
References: <mailman.18982.2981.1614334898.1405.r-sig-mixed-models@r-project.org>
 <AM6PR0102MB3174D49D6FB38503B27EA00E9E9D9@AM6PR0102MB3174.eurprd01.prod.exchangelabs.com>
Message-ID: <004e01d70c5b$5512c650$ff3852f0$@uke.de>

Dear Andre,

the ICC is calculated by dividing the random effect variance by the total variance, i.e. the sum of the random effect variance and the residual variance. Usually, for longitudinal models, where you have a random slope and - due to the subject ID as group factor in the random effects - many groups, the proportion of the variance explained by this grouping structure is rather high. That means, for longitudinal designs, a high(er) ICC is often expected.

Additionally, in your case, the residual variance is almost 0 (see output), thus, the ICC is literally the random effect variance divided by the random effect variance - which is ~ 1.

Your question regarding the marginal R2 of 8.7% (i.e. ~ 8.7% explained variance of attributable to fixed effects) *could* probably due to computational issues. For random slope models, the ICC can be different for each level / value of the random slope. Thus, icc() reports a kind of "averaged" ICC (see ?icc and references), which might not exactly reflect the explained variance attributable to the random effects.

Best
Daniel

-----Urspr?ngliche Nachricht-----
Von: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> Im Auftrag von Andre Syvertsen
Gesendet: Freitag, 26. Februar 2021 12:35
An: r-sig-mixed-models at r-project.org
Betreff: Re: [R-sig-ME] Help: Interpreting unusual model fit results from generalized linear mixed model (glmmTMB/sjPlot) (Andre Syvertsen)

Text version of table:

  Active Gambling Days Monthly
Predictors Incidence Rate Ratios, CI,  p
(Intercept):   1.18, 1.16 ? 1.20,  <0.001
Time : 0.99, 0.99 ? 0.99,  <0.001
Age Category 30-39:  1.29, 1.26 ? 1.32, <0.001
Age Category 40-49:  1.81, 1.78 ? 1.85, <0.001
Age Category 50-59:  2.47, 2.41 ? 2.53, <0.001
Age Category 60-69:  3.08, 2.99 ? 3.17, <0.001
Age Category 70+:  3.42, 3.29 ? 3.56, <0.001
Gender-Women:   1.69, 1.65 ? 1.74, <0.001
Age Category 30-39-Women: 0.90, 0.86 ? 0.94, <0.001
Age Category 40-49-Women: 0.67, 0.65 ? 0.70, <0.001
Age Category 50-59-Women: 0.53, 0.50 ? 0.55, <0.001
Age Category 60-69- Women: 0.46, 0.44 ? 0.48, <0.001
Age Category 70+-Women:  0.45, 0.43 ? 0.48, <0.001

Random Effects
?2 0.00
?00 id 1.63
?11 id.time 0.00
?01 id -0.38
ICC 1.00
N id 184113

Observations 3,231,544
Marginal R2 / Conditional R2 0.087 / 1.000
Note: Intercept = Men, age 18-29 years, first time point (month 0 of 69).


________________________________
Fra: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> p? vegne av r-sig-mixed-models-request at r-project.org <r-sig-mixed-models-request at r-project.org>
Sendt: fredag 26. februar 2021 11:21
Til: r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>
Emne: R-sig-mixed-models Digest, Vol 170, Issue 20

Send R-sig-mixed-models mailing list submissions to
        r-sig-mixed-models at r-project.org

To subscribe or unsubscribe via the World Wide Web, visit
        https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
or, via email, send a message with subject or body 'help' to
        r-sig-mixed-models-request at r-project.org

You can reach the person managing the list at
        r-sig-mixed-models-owner at r-project.org

When replying, please edit your Subject line so it is more specific
than "Re: Contents of R-sig-mixed-models digest..."


Today's Topics:

   1. Residual Variance-Covariance matrix (Yashree Mehta)
   2. Re: lmer code for multiple random slopes (Phillip Alday)
   3. question regarding time as a continuous factor in a linear
      mixed effects model (Laura Coco)
   4. Help: Interpreting unusual model fit results from generalized
      linear mixed model (glmmTMB/sjPlot) (Andre Syvertsen)

----------------------------------------------------------------------

Message: 1
Date: Thu, 25 Feb 2021 16:16:08 +0100
From: Yashree Mehta <yashree19 at gmail.com>
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] Residual Variance-Covariance matrix
Message-ID:
        <CAOE=hqKTTHxSChkLvxuO1USoCtk+ZmBbKtr6kDhxu=Xa438pZA at mail.gmail.com>
Content-Type: text/plain; charset="utf-8"

Hi,

I am using the following the code to extract the residual
variance-covariance matrix cov(Yi/Xi):

I first fit the model with the name lmemod_lme4. I have an unbalanced
cluster dataset.

Then, I extracted components with the following:

var.d <- crossprod(getME(lmemod_lme4,"Lambdat"))
Zt <- getME(lmemod_lme4,"Zt")
vr <- sigma(lmemod_lme4)^2

Then, I combine them with the following:

var.b <- t(Zt) %*% var.d %*% Zt
sI <- vr * Diagonal(nrow(Nameofdataset))
var.y <- var.b + sI

I have 2799 observations in my dataset. MY var.y matrix has dimension
2799 times 2799. Is there now a way to extract the

cov(Yi/Xi) for each observation? Also, I get a very large value for
the determinant of var.y.

I would be grateful to get further guidance on this.

Thank you very much.

Regards

        [[alternative HTML version deleted]]




------------------------------

Message: 2
Date: Thu, 25 Feb 2021 16:26:25 +0100
From: Phillip Alday <me at phillipalday.com>
To: Peter R Law <prldb at protonmail.com>,
        "r-sig-mixed-models at r-project.org" <r-sig-mixed-models at r-project.org>,
        Ben Bolker <bbolker at gmail.com>
Subject: Re: [R-sig-ME] lmer code for multiple random slopes
Message-ID: <f286a096-f420-c246-61ad-542eaa5dad44 at phillipalday.com>
Content-Type: text/plain; charset="utf-8"



On 25/2/21 5:16 am, Peter R Law via R-sig-mixed-models wrote:
> Alas I am still puzzled. I have extracted some data in trial.txt (no categorical variables) and attached some code in trial.R. I am only using this data to test code, which I hope to apply to a larger data set obtained from multiple populations, so with more structure. So the results themselves are not important, only whether the code does what I think it should. It occurred to me to test each model with lme and lmer.
>
> For a model with only a random intercept plus fixed effects, lme and lmer returned the same results, except that lme returns estimates with more decimal places (so here lmer returned zero variance for the random intercpt and lme a very small number).

This is to be expected: lme can't handle singular models (e.g. models
with an exactly zero variance component), but lmer can. So lme just gets
as close as it can.

>
> Adding a random slope, the main difference in the results is that lme and lmer returned very different estimates of the slope variance. Is that surprising?

It depends on what's going wrong. Generally these should return
identical fits for converged models (with the fine print that there are
certain models that you can specify in one but not the other without a
lot of effort).


>
> For a model with two random slopes, lme returned results as expected but lmer still claims there are 78 variance components, which is the number one would get from a 12 x 12 covariance matrix. Where the number 12 comes from is a mystery to me, especially as lme does what I expected (I ran this model with both raw data and normalized predictor values to see if something fishy was happening there but no):

The list strips most attachment types, so your script didn't make it
through. But just your data was enough for me to find a few problems

First, you're fitting and displaying two different models here:

>
>> M5n <- lme(Response~normP+normA, random=~normP+normA|Group,data=Trial, method="ML")
>> summary(M2n)

Second, when I try to fit the model that's given by the summary here, I
get a numerical error in lme:

> lme(Response~P+A, random=~P+A|Group,data=Trial, method="ML")
Error in lme.formula(Response ~ P + A, random = ~P + A | Group, data =
Trial,  :
  nlminb problem, convergence error code = 1
  message = false convergence (8)


This makes me think that something is wrong wrong in both bits of
software, but maybe the versions on your local machine are catching it



> Linear mixed-effects model fit by maximum likelihood
>  Data: Trial
>        AIC      BIC    logLik
>   536.4562 559.4969 -258.2281
>
> Random effects:
>  Formula: ~P + A | Group
>  Structure: General positive-definite, Log-Cholesky parametrization
>             StdDev       Corr
> (Intercept) 3.061144e-04 (Intr) P
> P           1.535752e-09 0
> A           8.517774e-13 0      0
> Residual    7.929821e+00
>
> Fixed effects: Response ~ P + A
>                 Value Std.Error DF    t-value p-value
> (Intercept) 25.453398 10.828841 46  2.3505192  0.0231
> P           -0.029307  0.035939 46 -0.8154787  0.4190
> A            0.140819  0.282018 46  0.4993255  0.6199
>  Correlation:
>   (Intr) P
> P -0.033
> A -0.975 -0.173
>
> Standardized Within-Group Residuals:
>        Min         Q1        Med         Q3        Max
> -1.8447131 -0.5563605 -0.2613520  0.2755547  5.5643551
>
> Number of Observations: 74
> Number of Groups: 26
>> M5 <- lmer(Response~normP+normA+(normP+normA|Group), REML="False", data=Trial)
> Error: number of observations (=74) <= number of random effects (=78) for term (normP + normA | Group); the random-effects parameters and the residual variance (or scale parameter) are probably unidentifiable.

This screams that your normP and normA variables aren't being handled as
continuous but rather categorical/factors. This means that you have a
lot more slopes being estimated, which the model survives, but not the
extra correlation parameters (hence the success when you suppress them
with the two syntax variants you mention below).



> It didn't matter which pair of the three predictors I used as far as the error message lmer returned but lme only returned results for P+A, not any pair involving PR, which apparently created computational issues, distinct to the interpretation of the code.
>
> In lmer, replacing the code (x+y|Group) by either (x+y||Group) or (X|Group) + (Y|Group) returned the expected results (in that lme4 interpreted the code as expected). Is there lme code for either of these models?
>
> Many thanks for any help.
>
> Peter
>
> P. S. I just noticed that responding to Ben's email sends my email to Ben, not to r-sig. I hope that sending my email to r-sig is the right thing to do and doesn't break the chain to my previous email.

Yep! Frequently, we have the reverse problem: people forget to keep the
list in CC. So thanks! The matching in the threading is handled mostly
by the subject line.


>
>
> Sent with ProtonMail Secure Email.
>
> ??????? Original Message ???????
> On Wednesday, February 17, 2021 10:40 PM, Peter R Law <prldb at protonmail.com> wrote:
>
>> Thanks for your quick response. I take it that the code should mean what I thought it would and that somehow lmer is not interpreting what I wrote in my actual example as intended. None of the variables are categorical but I'll give it some more thought and see if I can figure it out. If not, I'll provide more details.
>>
>> Peter
>>
>> Sent with ProtonMail Secure Email.
>>
>> ??????? Original Message ???????
>> On Tuesday, February 16, 2021 10:04 AM, Ben Bolker bbolker at gmail.com wrote:
>>
>>> I second Phillip's point. The example below works as expected (gets
>>> a singular fit, but there are 6 covariance parameters as expected).
>>> Based on what you've told us so far, the most plausible explanation is
>>> that one or both of your covariates (x and/or z) are factors
>>> (categorical) rather than numeric.
>>> Ben Bolker
>>> ============================================================================================================================================================================================================================================================================================================================
>>> set.seed(101)
>>> dd <- data.frame(x=rnorm(500),z=rnorm(500),
>>> g=factor(sample(1:6,size=500,replace=TRUE)))
>>> form <- y ~ x + z + (x+z|g)
>>> dd$y <- simulate(form[-2],
>>> newdata=dd,
>>> newparams=list(beta=rep(0,3),
>>> theta=rep(1,6),
>>> sigma=1))[[1]]
>>> library(lme4)
>>> m1 <- lmer(form, data=dd)
>>> VarCorr(m1)
>>> On 2/16/21 8:18 AM, Phillip Alday wrote:
>>>
>>>> I suspect we'll need to know a bit more about your data to answer this
>>>> question. Can you share it in any form (e.g. variables renamed and
>>>> levels of factors changed to something opaque) ?
>>>> Best,
>>>> Phillip
>>>> On 16/2/21 4:02 am, Peter R Law via R-sig-mixed-models wrote:
>>>>
>>>>> I am trying to fit a model with two covariates, x and z say, for response y, with a random factor g and want each of x and y to have a random slope. I expected
>>>>> lmer(y ~ x + z + (x+z|g),...)
>>>>> to fit a model with 6 random variance components, the intercept, two slopes and three correlations. But I got an error message saying there were 74 random variance components and my data was insufficient to fit the model. Yet
>>>>> lmer(y ~ x + z + (x+z||g),...)
>>>>> returned what I expected, a model with the random intercept and two slopes but no correlations. How is lmer interpreting the first line of code above and how I would code for what I want. I have not been able to find any examples in the literature or online that help me but I may have easily missed something so if anyone knows of a useful link that'd be great. The only examples of multiple random slopes I've seen take the form
>>>>> lmer(y~x + z +(x|g) + (z|g),...)
>>>>> specifically excluding correlations between the random slopes and intercept of the two predictors. Even if the latter is a more sensible approach I'd like to understand the coding issue.
>>>>> Thanks.
>>>>> Peter
>>>>> Sent with ProtonMail Secure Email.
>>>>> [[alternative HTML version deleted]]
>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>




------------------------------

Message: 3
Date: Thu, 25 Feb 2021 10:36:28 -0700
From: Laura Coco <lauracoco at gmail.com>
To: r-sig-mixed-models at r-project.org
Subject: [R-sig-ME] question regarding time as a continuous factor in
        a linear mixed effects model
Message-ID:
        <CAKgKnP6Nx9Ee=vhPd6JtbUrzw4iyeXjh-=FZo9zCTo5RtcTjkQ at mail.gmail.com>
Content-Type: text/plain; charset="utf-8"

Hello,

I am interested in investigating the main effects of group, time, and group
by time interaction on survey outcomes using linear mixed effects models.
Time is considered as continuous (number of days since baseline), but isn't
it also categorical, since I want to compare Session 1 vs Session 4 (for
example)? How is that handled in the model? As of now, time (days since
baseline) is being treated as one unit, rather than four separate sessions.

Here is an example of my code: mdl.outcome <- lmer(outcome ~ time*Group +
(1 | PID), data = dta)

Thank you!!

        [[alternative HTML version deleted]]




------------------------------

Message: 4
Date: Fri, 26 Feb 2021 10:20:18 +0000
From: Andre Syvertsen <Andre.Syvertsen at uib.no>
To: "r-sig-mixed-models at r-project.org"
        <r-sig-mixed-models at r-project.org>
Subject: [R-sig-ME] Help: Interpreting unusual model fit results from
        generalized linear mixed model (glmmTMB/sjPlot)
Message-ID:
        <AM6PR0102MB31748BFF6EAF4FEA67D042809E9D9 at AM6PR0102MB3174.eurprd01.prod.exchangelabs.com>

Content-Type: text/plain; charset="utf-8"

Hi,

I am working with a large dataset that contains longitudinal data on gambling behavior of 184,113 participants. The data is based on complete tracking of electronic gambling behavior within a gambling operator. Gambling behavior data is aggregated on a monthly level, a total of 70 months. I have an ID variable separating participants, a time variable (months), as well as numerous gambling behavior variables such as active days played for given month, bets placed for given month, total losses for given month, etc. I am investigating the role of age and gender in predicting active days gambling per month.

I have fitted a model with glmmTMB (see below for model code) and outputed the resulting statistics with sjPlot's tab_model function which I am having trouble interpreting. The full results can be found below. Notably, I appear to have gotten perfect intra-class correlation. While, I am sure variance in outcome responses (active days gambling) are likely to be heavily associated with subject and time, this seems excessive. Furthermore, the pseudo R2 suggests that 8.7% of the variance should be attributable to fixed effects which I would think would lower the variance attributable to individual/time? Are the results affected by the high number of observations, individuals and/or time points? Or maybe I have specified my model in an odd manner?

glmmTMB code for the model:

DaysPlayedConditionalAgeGenderTruncated <- glmmTMB(daysPlayed ~ 1 + time + ageCategory * gender + (time | id), dfLong, family = truncated_nbinom2)

Model summary:

Active Gambling Days Monthly
Predictors
Incidence Rate Ratios
CI
p
(Intercept)
1.18
1.16 ?C 1.20
<0.001
Time
0.99
0.99 ?C 0.99
<0.001
Age Category 30-39
1.29
1.26 ?C 1.32
<0.001
Age Category 40-49
1.81
1.78 ?C 1.85
<0.001
Age Category 50-59
2.47
2.41 ?C 2.53
<0.001
Age Category 60-69
3.08
2.99 ?C 3.17
<0.001
Age Category 70+
3.42
3.29 ?C 3.56
<0.001
Gender: Women
1.69
1.65 ?C 1.74
<0.001
Age Category 30-39:Women
0.90
0.86 ?C 0.94
<0.001
Age Category 40-49:Women
0.67
0.65 ?C 0.70
<0.001
Age Category 50-59:Women
0.53
0.50 ?C 0.55
<0.001
Age Category 60-69: Women
0.46
0.44 ?C 0.48
<0.001
Age Category 70+:Women
0.45
0.43 ?C 0.48
<0.001
Random Effects
??2
0.00
??00 id
1.63
??11 id.time
0.00
??01 id
-0.38
ICC
1.00
N id
184113
Observations
3231544
Marginal R2 / Conditional R2
0.087 / 1.000
Note. Intercept = Men, age 18-29 years, first time point (month 0 of 69).


Kind regards,
Andr??

        [[alternative HTML version deleted]]



------------------------------

Subject: Digest Footer

_______________________________________________
R-sig-mixed-models mailing list
R-sig-mixed-models at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


------------------------------

End of R-sig-mixed-models Digest, Vol 170, Issue 20
***************************************************

	[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

--

_____________________________________________________________________

Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen Rechts; Gerichtsstand: Hamburg | www.uke.de
Vorstandsmitglieder: Prof. Dr. Burkhard G?ke (Vorsitzender), Joachim Pr?l?, Prof. Dr. Blanche Schwappach-Pignataro, Marya Verdel
_____________________________________________________________________

SAVE PAPER - THINK BEFORE PRINTING

From d@|uedecke @end|ng |rom uke@de  Fri Feb 26 17:25:24 2021
From: d@|uedecke @end|ng |rom uke@de (=?iso-8859-1?Q?Daniel_L=FCdecke?=)
Date: Fri, 26 Feb 2021 17:25:24 +0100
Subject: [R-sig-ME] question regarding time as a continuous factor in a
 linear mixed effects model
In-Reply-To: <CAKgKnP6Nx9Ee=vhPd6JtbUrzw4iyeXjh-=FZo9zCTo5RtcTjkQ@mail.gmail.com>
References: <CAKgKnP6Nx9Ee=vhPd6JtbUrzw4iyeXjh-=FZo9zCTo5RtcTjkQ@mail.gmail.com>
Message-ID: <004f01d70c5b$fca5cac0$f5f16040$@uke.de>

Dear Laura,
you could use a package like "effects" or "emmeans" to compute estimated
marginal means and compare the values for time = 1 and time = 4, or you
could even use pairwise comparisons, like:

library(emmeans)
mdl.outcome <- lmer(outcome ~ time*Group + (1 | PID), data = dta)
emm <- emmeans(mdl.outcome, c("time", "group"), at = list(time = c(1, 4)))
emm
pairs(emm)

Best
Daniel

-----Urspr?ngliche Nachricht-----
Von: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> Im
Auftrag von Laura Coco
Gesendet: Donnerstag, 25. Februar 2021 18:36
An: r-sig-mixed-models at r-project.org
Betreff: [R-sig-ME] question regarding time as a continuous factor in a
linear mixed effects model

Hello,

I am interested in investigating the main effects of group, time, and group
by time interaction on survey outcomes using linear mixed effects models.
Time is considered as continuous (number of days since baseline), but isn't
it also categorical, since I want to compare Session 1 vs Session 4 (for
example)? How is that handled in the model? As of now, time (days since
baseline) is being treated as one unit, rather than four separate sessions.

Here is an example of my code: mdl.outcome <- lmer(outcome ~ time*Group +
(1 | PID), data = dta)

Thank you!!

	[[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

--

_____________________________________________________________________

Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen Rechts; Gerichtsstand: Hamburg | www.uke.de
Vorstandsmitglieder: Prof. Dr. Burkhard G?ke (Vorsitzender), Joachim Pr?l?, Prof. Dr. Blanche Schwappach-Pignataro, Marya Verdel
_____________________________________________________________________

SAVE PAPER - THINK BEFORE PRINTING


From pr|db @end|ng |rom protonm@||@com  Mon Mar  1 23:34:11 2021
From: pr|db @end|ng |rom protonm@||@com (Peter R Law)
Date: Mon, 01 Mar 2021 22:34:11 +0000
Subject: [R-sig-ME] lmer code for multiple random slopes
In-Reply-To: <f286a096-f420-c246-61ad-542eaa5dad44@phillipalday.com>
References: <34JKCz24u8awawkhTLmboO_cBRWW-m0XAb0frTUb9YqspQe1VeBBWUvfqKd3-QIMLeKpiDUyzhN0X6aqRlEqwX1LmBfg3gn9EB2XCa5v62s=@protonmail.com>
 <1877a680-d190-7202-537d-90d51bc6574b@phillipalday.com>
 <de6401b0-6cac-65d8-cbc3-0f59ce79409d@gmail.com>
 <NCGF24lxdAy2bcOAoQsutEkYQ-ZIzb4e3xLenmSDhGyZN8a8sIcv-wHF0IEfLK8GQGccVE1hLTk-i1UPxFITTgLC9T929E6F4rQVMwVN8bg=@protonmail.com>
 <e2zoG5je3QHzcPl3dsttnLigMgzR8mqiUJAdgntQm9xPOX4j3SwlDytjMtbOFRj-vf5TjpHVRD7rzd54mvwMFm9OhW-ff4lfhR383lioPX4=@protonmail.com>
 <f286a096-f420-c246-61ad-542eaa5dad44@phillipalday.com>
Message-ID: <CIYTFe7RNWpkAwUyuCM71pFEfhP-gPVj0OcD-UjLX0LbfzrRbySwMeVxASDMGs6D3aOxqydPUAg1NbZJar32LOtM42U-ZY-03eCCB7JbkUg=@protonmail.com>


Thanks Phillip. Sorry about the goof in the summary code. It doesn't actually affect the behaviour that I described, however. Below is a more complete output from R. You will see the str output for the data file, which doesn't seem to indicate that R is treating any of the variables other than Group as a factor (by the way, I recently updated both nlme and lme4 packages but I haven't noticed any changes to their behaviour as a result. But I just noticed that when lme4 loads there is a warning that it was built under R 3.5.3 Is that a possible problem?). For Model 5n (random slopes for both normP and normA) lme returns an analysis but lmer complains about the 78 variance components. Same if one uses A and P instead (Model2ns and 2). If I use variable PR, however, I get the error message you got with lme (Model 7n for normA and normPR) or a different error message (Model 6n for normPR and normA).

Yet, lmer seems to behave properly for ~P+A+(P|Group)+(A|Group) (Model 4) and P+PR+(P+PR||Group) (model M3).  While these models remove the correlations between the random factors, if lmer is seeing variables as factors rather than numeric, wouldn't lmer still see the wrong number of random factors in these two models?

Finally, Models 1 and 1n compare lme and lmer on a model with a single random slope, showing the differences in parameter estimates but not log-likelihood or AIC.

I have attached the trial.txt and trial.r files again. I assume you will receive them directly if you want to open them.

R output:

> library(lme4)
Loading required package: Matrix
Warning message:
package ?lme4? was built under R version 3.5.3
> library(nlme)

Attaching package: ?nlme?

The following object is masked from ?package:lme4?:

    lmList

> Trial <- read.table(file="C:/PRL/R/RGFRRIBI/Trial.txt", header = TRUE)
> names(Trial)
[1] "Response" "P"        "A"        "PR"       "Group"
> str(Trial)
'data.frame':	74 obs. of  5 variables:
 $ Response: int  24 22 24 24 23 24 24 24 35 31 ...
 $ P       : int  15 82 95 71 88 77 93 91 13 82 ...
 $ A       : num  44.2 39.6 41.4 34.1 44.6 ...
 $ PR      : num  121 115 250 200 252 ...
 $ Group   : Factor w/ 26 levels "G1","G10","G11",..: 1 12 12 20 20 21 21 22 23 24 ...
> Trial$normP <- as.double(scale(Trial$P))
> Trial$normA <- as.double(scale(Trial$A))
> Trial$normPR <- as.double(scale(Trial$PR))
> names(Trial)
[1] "Response" "P"        "A"        "PR"       "Group"    "normP"    "normA"    "normPR"
> str(Trial)
'data.frame':	74 obs. of  8 variables:
 $ Response: int  24 22 24 24 23 24 24 24 35 31 ...
 $ P       : int  15 82 95 71 88 77 93 91 13 82 ...
 $ A       : num  44.2 39.6 41.4 34.1 44.6 ...
 $ PR      : num  121 115 250 200 252 ...
 $ Group   : Factor w/ 26 levels "G1","G10","G11",..: 1 12 12 20 20 21 21 22 23 24 ...
 $ normP   : num  -1.783 0.719 1.205 0.308 0.943 ...
 $ normA   : num  1.576 0.221 0.754 -1.38 1.708 ...
 $ normPR  : num  -1.415 -1.486 0.251 -0.385 0.281 ...

> M5n <- lme(Response~normP+normA, random=~normP+normA|Group,data=Trial, method="ML")
> summary(M5n)
Linear mixed-effects model fit by maximum likelihood
 Data: Trial
       AIC      BIC    logLik
  536.4562 559.4969 -258.2281

Random effects:
 Formula: ~normP + normA | Group
 Structure: General positive-definite, Log-Cholesky parametrization
            StdDev       Corr
(Intercept) 0.0002514711 (Intr) normP
normP       0.0002146005 0
normA       0.0001485695 0      0
Residual    7.9298211705

Fixed effects: Response ~ normP + normA
                Value Std.Error DF   t-value p-value
(Intercept) 29.081081 0.9410966 46 30.901270  0.0000
normP       -0.784566 0.9620920 46 -0.815479  0.4190
normA        0.480397 0.9620920 46  0.499326  0.6199
 Correlation:
      (Intr) normP
normP  0.000
normA  0.000 -0.173

Standardized Within-Group Residuals:
       Min         Q1        Med         Q3        Max
-1.8447131 -0.5563605 -0.2613520  0.2755547  5.5643551

Number of Observations: 74
Number of Groups: 26

> M5 <- lmer(Response~normP+normA+(normP+normA|Group), REML="False", data=Trial)
Error: number of observations (=74) <= number of random effects (=78) for term (normP + normA | Group); the random-effects parameters and the residual variance (or scale parameter) are probably unidentifiable

> M2n <- lme(Response~P+A, random=~P+A|Group,data=Trial, method="ML")
> summary(M2n)
Linear mixed-effects model fit by maximum likelihood
 Data: Trial
       AIC      BIC    logLik
  536.4562 559.4969 -258.2281

Random effects:
 Formula: ~P + A | Group
 Structure: General positive-definite, Log-Cholesky parametrization
            StdDev       Corr
(Intercept) 3.061144e-04 (Intr) P
P           1.535752e-09 0
A           8.517774e-13 0      0
Residual    7.929821e+00

Fixed effects: Response ~ P + A
                Value Std.Error DF    t-value p-value
(Intercept) 25.453398 10.828841 46  2.3505192  0.0231
P           -0.029307  0.035939 46 -0.8154787  0.4190
A            0.140819  0.282018 46  0.4993255  0.6199
 Correlation:
  (Intr) P
P -0.033
A -0.975 -0.173

Standardized Within-Group Residuals:
       Min         Q1        Med         Q3        Max
-1.8447131 -0.5563605 -0.2613520  0.2755547  5.5643551

Number of Observations: 74
Number of Groups: 26

> M2 <- lmer(Response~P+A+(P+A|Group), REML="False", data=Trial)
Error: number of observations (=74) <= number of random effects (=78) for term (P + A | Group); the random-effects parameters and the residual variance (or scale parameter) are probably unidentifiable

> M6n <- lme(Response~A+PR, random=~A+PR|Group,data=Trial, method="ML")
Error in logLik.lmeStructInt(lmeSt, lmePars) :
  NA/NaN/Inf in foreign function call (arg 3)
In addition: There were 50 or more warnings (use warnings() to see the first 50)
> summary(M6n)
Error in summary(M6n) : object 'M6n' not found

> M7n <- lme(Response~normA+normPR, random=~normA+normPR|Group,data=Trial, method="ML")
Error in lme.formula(Response ~ normA + normPR, random = ~normA + normPR |  :
  nlminb problem, convergence error code = 1
  message = iteration limit reached without convergence (10)
> summary(M7n)
Error in summary(M7n) : object 'M7n' not found

> M4 <-  lmer(Response~P+A+(P|Group)+(A|Group), REML="False", data=Trial)
boundary (singular) fit: see ?isSingular
> summary(M4)
Linear mixed model fit by maximum likelihood  ['lmerMod']
Formula: Response ~ P + A + (P | Group) + (A | Group)
   Data: Trial

     AIC      BIC   logLik deviance df.resid
   536.5    559.5   -258.2    516.5       64

Scaled residuals:
    Min      1Q  Median      3Q     Max
-1.8447 -0.5564 -0.2614  0.2756  5.5644

Random effects:
 Groups   Name        Variance  Std.Dev.  Corr
 Group    (Intercept) 1.035e-06 1.017e-03
          P           5.031e-09 7.093e-05 -1.00
 Group.1  (Intercept) 5.262e-07 7.254e-04
          A           1.941e-11 4.406e-06 -1.00
 Residual             6.288e+01 7.930e+00
Number of obs: 74, groups:  Group, 26

Fixed effects:
            Estimate Std. Error t value
(Intercept) 25.45340   10.60707   2.400
P           -0.02931    0.03520  -0.833
A            0.14082    0.27624   0.510

Correlation of Fixed Effects:
  (Intr) P
P -0.033
A -0.975 -0.173
convergence code: 0
boundary (singular) fit: see ?isSingular

> M3 <- lmer(Response~P+PR+(P+PR||Group), REML="False", data=Trial)
boundary (singular) fit: see ?isSingular
> summary(M3)
Linear mixed model fit by maximum likelihood  ['lmerMod']
Formula: Response ~ P + PR + ((1 | Group) + (0 + P | Group) + (0 + PR |      Group))
   Data: Trial

     AIC      BIC   logLik deviance df.resid
   530.5    546.7   -258.3    516.5       67

Scaled residuals:
    Min      1Q  Median      3Q     Max
-1.8106 -0.5567 -0.2981  0.2984  5.0950

Random effects:
 Groups   Name        Variance  Std.Dev.
 Group    (Intercept) 5.422e-04 0.023285
 Group.1  P           0.000e+00 0.000000
 Group.2  PR          7.239e-05 0.008508
 Residual             5.912e+01 7.688728
Number of obs: 74, groups:  Group, 26

Fixed effects:
             Estimate Std. Error t value
(Intercept) 29.265396   3.747575   7.809
P           -0.023208   0.035100  -0.661
PR           0.006151   0.012288   0.501

Correlation of Fixed Effects:
   (Intr) P
P  -0.633
PR -0.754  0.043
convergence code: 0
boundary (singular) fit: see ?isSingular

> M1 <- lmer(Response~P+A+(A|Group), REML="False", data=Trial)
boundary (singular) fit: see ?isSingular
> summary(M1)
Linear mixed model fit by maximum likelihood  ['lmerMod']
Formula: Response ~ P + A + (A | Group)
   Data: Trial

     AIC      BIC   logLik deviance df.resid
   530.5    546.6   -258.2    516.5       67

Scaled residuals:
    Min      1Q  Median      3Q     Max
-1.8447 -0.5564 -0.2614  0.2756  5.5644

Random effects:
 Groups   Name        Variance  Std.Dev.  Corr
 Group    (Intercept) 0.000e+00 0.000e+00
          A           1.657e-10 1.287e-05  NaN
 Residual             6.288e+01 7.930e+00
Number of obs: 74, groups:  Group, 26

Fixed effects:
            Estimate Std. Error t value
(Intercept) 25.45340   10.60707   2.400
P           -0.02931    0.03520  -0.833
A            0.14082    0.27624   0.510

Correlation of Fixed Effects:
  (Intr) P
P -0.033
A -0.975 -0.173
convergence code: 0
boundary (singular) fit: see ?isSingular

> M1n <- lme(Response~1+P+A, random=~1+A|Group,data=Trial, method="ML")
> summary(M1n)
Linear mixed-effects model fit by maximum likelihood
 Data: Trial
       AIC      BIC    logLik
  530.4562 546.5847 -258.2281

Random effects:
 Formula: ~1 + A | Group
 Structure: General positive-definite, Log-Cholesky parametrization
            StdDev       Corr
(Intercept) 5.277473e-04 (Intr)
A           1.487869e-18 0
Residual    7.929821e+00

Fixed effects: Response ~ 1 + P + A
                Value Std.Error DF    t-value p-value
(Intercept) 25.453398 10.828841 46  2.3505192  0.0231
P           -0.029307  0.035939 46 -0.8154787  0.4190
A            0.140819  0.282018 46  0.4993255  0.6199
 Correlation:
  (Intr) P
P -0.033
A -0.975 -0.173

Standardized Within-Group Residuals:
       Min         Q1        Med         Q3        Max
-1.8447131 -0.5563605 -0.2613520  0.2755547  5.5643551

Number of Observations: 74
Number of Groups: 26

Peter


Sent with ProtonMail Secure Email.

??????? Original Message ???????
On Thursday, February 25, 2021 10:26 AM, Phillip Alday <me at phillipalday.com> wrote:

> On 25/2/21 5:16 am, Peter R Law via R-sig-mixed-models wrote:
>
> > Alas I am still puzzled. I have extracted some data in trial.txt (no categorical variables) and attached some code in trial.R. I am only using this data to test code, which I hope to apply to a larger data set obtained from multiple populations, so with more structure. So the results themselves are not important, only whether the code does what I think it should. It occurred to me to test each model with lme and lmer.
> > For a model with only a random intercept plus fixed effects, lme and lmer returned the same results, except that lme returns estimates with more decimal places (so here lmer returned zero variance for the random intercpt and lme a very small number).
>
> This is to be expected: lme can't handle singular models (e.g. models
> with an exactly zero variance component), but lmer can. So lme just gets
> as close as it can.
>
> > Adding a random slope, the main difference in the results is that lme and lmer returned very different estimates of the slope variance. Is that surprising?
>
> It depends on what's going wrong. Generally these should return
> identical fits for converged models (with the fine print that there are
> certain models that you can specify in one but not the other without a
> lot of effort).
>
> > For a model with two random slopes, lme returned results as expected but lmer still claims there are 78 variance components, which is the number one would get from a 12 x 12 covariance matrix. Where the number 12 comes from is a mystery to me, especially as lme does what I expected (I ran this model with both raw data and normalized predictor values to see if something fishy was happening there but no):
>
> The list strips most attachment types, so your script didn't make it
> through. But just your data was enough for me to find a few problems
>
> First, you're fitting and displaying two different models here:
>
> > > M5n <- lme(Response~normP+normA, random=~normP+normA|Group,data=Trial, method="ML")
> > > summary(M2n)
>
> Second, when I try to fit the model that's given by the summary here, I
> get a numerical error in lme:
>
> > lme(Response~P+A, random=~P+A|Group,data=Trial, method="ML")
>
> Error in lme.formula(Response ~ P + A, random = ~P + A | Group, data =
> Trial, :
> nlminb problem, convergence error code = 1
> message = false convergence (8)
>
> This makes me think that something is wrong wrong in both bits of
> software, but maybe the versions on your local machine are catching it
>
> > Linear mixed-effects model fit by maximum likelihood
> > Data: Trial
> > AIC BIC logLik
> > 536.4562 559.4969 -258.2281
> > Random effects:
> > Formula: ~P + A | Group
> > Structure: General positive-definite, Log-Cholesky parametrization
> > StdDev Corr
> > (Intercept) 3.061144e-04 (Intr) P
> > P 1.535752e-09 0
> > A 8.517774e-13 0 0
> > Residual 7.929821e+00
> > Fixed effects: Response ~ P + A
> > Value Std.Error DF t-value p-value
> > (Intercept) 25.453398 10.828841 46 2.3505192 0.0231
> > P -0.029307 0.035939 46 -0.8154787 0.4190
> > A 0.140819 0.282018 46 0.4993255 0.6199
> > Correlation:
> > (Intr) P
> > P -0.033
> > A -0.975 -0.173
> > Standardized Within-Group Residuals:
> > Min Q1 Med Q3 Max
> > -1.8447131 -0.5563605 -0.2613520 0.2755547 5.5643551
> > Number of Observations: 74
> > Number of Groups: 26
> >
> > > M5 <- lmer(Response~normP+normA+(normP+normA|Group), REML="False", data=Trial)
> > > Error: number of observations (=74) <= number of random effects (=78) for term (normP + normA | Group); the random-effects parameters and the residual variance (or scale parameter) are probably unidentifiable.
>
> This screams that your normP and normA variables aren't being handled as
> continuous but rather categorical/factors. This means that you have a
> lot more slopes being estimated, which the model survives, but not the
> extra correlation parameters (hence the success when you suppress them
> with the two syntax variants you mention below).
>
> > It didn't matter which pair of the three predictors I used as far as the error message lmer returned but lme only returned results for P+A, not any pair involving PR, which apparently created computational issues, distinct to the interpretation of the code.
> > In lmer, replacing the code (x+y|Group) by either (x+y||Group) or (X|Group) + (Y|Group) returned the expected results (in that lme4 interpreted the code as expected). Is there lme code for either of these models?
> > Many thanks for any help.
> > Peter
> > P. S. I just noticed that responding to Ben's email sends my email to Ben, not to r-sig. I hope that sending my email to r-sig is the right thing to do and doesn't break the chain to my previous email.
>
> Yep! Frequently, we have the reverse problem: people forget to keep the
> list in CC. So thanks! The matching in the threading is handled mostly
> by the subject line.
>
> > Sent with ProtonMail Secure Email.
> > ??????? Original Message ???????
> > On Wednesday, February 17, 2021 10:40 PM, Peter R Law prldb at protonmail.com wrote:
> >
> > > Thanks for your quick response. I take it that the code should mean what I thought it would and that somehow lmer is not interpreting what I wrote in my actual example as intended. None of the variables are categorical but I'll give it some more thought and see if I can figure it out. If not, I'll provide more details.
> > > Peter
> > > Sent with ProtonMail Secure Email.
> > > ??????? Original Message ???????
> > > On Tuesday, February 16, 2021 10:04 AM, Ben Bolker bbolker at gmail.com wrote:
> > >
> > > > I second Phillip's point. The example below works as expected (gets
> > > > a singular fit, but there are 6 covariance parameters as expected).
> > > > Based on what you've told us so far, the most plausible explanation is
> > > > that one or both of your covariates (x and/or z) are factors
> > > > (categorical) rather than numeric.
> > > > Ben Bolker
> > > >
> > > > ==========================================================================================================================================================================================================================================================================================================================
> > > >
> > > > set.seed(101)
> > > > dd <- data.frame(x=rnorm(500),z=rnorm(500),
> > > > g=factor(sample(1:6,size=500,replace=TRUE)))
> > > > form <- y ~ x + z + (x+z|g)
> > > > dd$y <- simulate(form[-2],
> > > > newdata=dd,
> > > > newparams=list(beta=rep(0,3),
> > > > theta=rep(1,6),
> > > > sigma=1))[[1]]
> > > > library(lme4)
> > > > m1 <- lmer(form, data=dd)
> > > > VarCorr(m1)
> > > > On 2/16/21 8:18 AM, Phillip Alday wrote:
> > > >
> > > > > I suspect we'll need to know a bit more about your data to answer this
> > > > > question. Can you share it in any form (e.g. variables renamed and
> > > > > levels of factors changed to something opaque) ?
> > > > > Best,
> > > > > Phillip
> > > > > On 16/2/21 4:02 am, Peter R Law via R-sig-mixed-models wrote:
> > > > >
> > > > > > I am trying to fit a model with two covariates, x and z say, for response y, with a random factor g and want each of x and y to have a random slope. I expected
> > > > > > lmer(y ~ x + z + (x+z|g),...)
> > > > > > to fit a model with 6 random variance components, the intercept, two slopes and three correlations. But I got an error message saying there were 74 random variance components and my data was insufficient to fit the model. Yet
> > > > > > lmer(y ~ x + z + (x+z||g),...)
> > > > > > returned what I expected, a model with the random intercept and two slopes but no correlations. How is lmer interpreting the first line of code above and how I would code for what I want. I have not been able to find any examples in the literature or online that help me but I may have easily missed something so if anyone knows of a useful link that'd be great. The only examples of multiple random slopes I've seen take the form
> > > > > > lmer(y~x + z +(x|g) + (z|g),...)
> > > > > > specifically excluding correlations between the random slopes and intercept of the two predictors. Even if the latter is a more sensible approach I'd like to understand the coding issue.
> > > > > > Thanks.
> > > > > > Peter
> > > > > > Sent with ProtonMail Secure Email.
> > > > > > [[alternative HTML version deleted]]
> > > > > > R-sig-mixed-models at r-project.org mailing list
> > > > > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > > > >
> > > > > R-sig-mixed-models at r-project.org mailing list
> > > > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> > > >
> > > > R-sig-mixed-models at r-project.org mailing list
> > > > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: Trial.txt
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20210301/5e7bf7c6/attachment.txt>

From |@g|ne @end|ng |rom p@@jd@org  Wed Mar  3 13:11:12 2021
From: |@g|ne @end|ng |rom p@@jd@org (=?iso-8859-1?Q?IAGO_GIN=C9_V=C1ZQUEZ?=)
Date: Wed, 3 Mar 2021 12:11:12 +0000
Subject: [R-sig-ME] fixed-effect model matrix is rank deficient so dropping
 1 column / coefficient
Message-ID: <AM6PR02MB4423E1D67B1D632B6E723D7E92989@AM6PR02MB4423.eurprd02.prod.outlook.com>

Dear all,

I have 3 related questions, probably already answered, but which I cannot find:

When computing a model with lmer I get the message

fixed-effect model matrix is rank deficient so dropping 1 column / coefficient

Then, my questions are, first, how can I see/compute/get the rank deficient fixed-effect model matrix, second how is that matrix computed, and third (these actually are 2 questions), if my model is yet valid (is it?) how can the dropped fixed effect explained in the results of a paper.

In the example in ?fixef
fm2 <- lmer(Reaction ~ Days + Days2 + (1|Subject),
            data=transform(sleepstudy,Days2=Days))
fixef(fm2,add.dropped=TRUE)

the problem happens because 2 independent variables are equal, but in my model the numeric independent variables are not so highly correlated. In fact the problem happens with the interaction between a factor and a numeric variable, since it is one of the categories of the factor interacting with the numeric, which is dropped.

Thank you and stay safe!


Iago


	[[alternative HTML version deleted]]


From th|erry@onke||nx @end|ng |rom |nbo@be  Wed Mar  3 13:30:36 2021
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Wed, 3 Mar 2021 13:30:36 +0100
Subject: [R-sig-ME] 
 fixed-effect model matrix is rank deficient so dropping
 1 column / coefficient
In-Reply-To: <AM6PR02MB4423E1D67B1D632B6E723D7E92989@AM6PR02MB4423.eurprd02.prod.outlook.com>
References: <AM6PR02MB4423E1D67B1D632B6E723D7E92989@AM6PR02MB4423.eurprd02.prod.outlook.com>
Message-ID: <CAJuCY5xw3ziOtEz6jiiLjWR_UOCcq=PPnOjEc8hXrDZRGf05KA@mail.gmail.com>

Dear Iago,

We only have your description of the data. It would be easier for us to
help you if you provide a small dataset that illustrates the structure in
your data and how you use the data in your model.

Best regards,

Thierry

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op wo 3 mrt. 2021 om 13:11 schreef IAGO GIN? V?ZQUEZ <i.gine at pssjd.org>:

> Dear all,
>
> I have 3 related questions, probably already answered, but which I cannot
> find:
>
> When computing a model with lmer I get the message
>
> fixed-effect model matrix is rank deficient so dropping 1 column /
> coefficient
>
> Then, my questions are, first, how can I see/compute/get the rank
> deficient fixed-effect model matrix, second how is that matrix computed,
> and third (these actually are 2 questions), if my model is yet valid (is
> it?) how can the dropped fixed effect explained in the results of a paper.
>
> In the example in ?fixef
> fm2 <- lmer(Reaction ~ Days + Days2 + (1|Subject),
>             data=transform(sleepstudy,Days2=Days))
> fixef(fm2,add.dropped=TRUE)
>
> the problem happens because 2 independent variables are equal, but in my
> model the numeric independent variables are not so highly correlated. In
> fact the problem happens with the interaction between a factor and a
> numeric variable, since it is one of the categories of the factor
> interacting with the numeric, which is dropped.
>
> Thank you and stay safe!
>
>
> Iago
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From wo||g@ng@v|echtb@uer @end|ng |rom m@@@tr|chtun|ver@|ty@n|  Wed Mar  3 13:43:02 2021
From: wo||g@ng@v|echtb@uer @end|ng |rom m@@@tr|chtun|ver@|ty@n| (Viechtbauer, Wolfgang (SP))
Date: Wed, 3 Mar 2021 12:43:02 +0000
Subject: [R-sig-ME] lmer code for multiple random slopes
In-Reply-To: <CIYTFe7RNWpkAwUyuCM71pFEfhP-gPVj0OcD-UjLX0LbfzrRbySwMeVxASDMGs6D3aOxqydPUAg1NbZJar32LOtM42U-ZY-03eCCB7JbkUg=@protonmail.com>
References: <34JKCz24u8awawkhTLmboO_cBRWW-m0XAb0frTUb9YqspQe1VeBBWUvfqKd3-QIMLeKpiDUyzhN0X6aqRlEqwX1LmBfg3gn9EB2XCa5v62s=@protonmail.com>
 <1877a680-d190-7202-537d-90d51bc6574b@phillipalday.com>
 <de6401b0-6cac-65d8-cbc3-0f59ce79409d@gmail.com>
 <NCGF24lxdAy2bcOAoQsutEkYQ-ZIzb4e3xLenmSDhGyZN8a8sIcv-wHF0IEfLK8GQGccVE1hLTk-i1UPxFITTgLC9T929E6F4rQVMwVN8bg=@protonmail.com>
 <e2zoG5je3QHzcPl3dsttnLigMgzR8mqiUJAdgntQm9xPOX4j3SwlDytjMtbOFRj-vf5TjpHVRD7rzd54mvwMFm9OhW-ff4lfhR383lioPX4=@protonmail.com>
 <f286a096-f420-c246-61ad-542eaa5dad44@phillipalday.com>
 <CIYTFe7RNWpkAwUyuCM71pFEfhP-gPVj0OcD-UjLX0LbfzrRbySwMeVxASDMGs6D3aOxqydPUAg1NbZJar32LOtM42U-ZY-03eCCB7JbkUg=@protonmail.com>
Message-ID: <e0894da27f994e64863768033e5c4989@UM-MAIL3214.unimaas.nl>

Dear Peter, Dear All,

The error doesn't say 78 variance components, it says 78 random effects. There are 26 groups in this dataset and you are estimating random intercepts and two sets of random slopes. Hence, there are 3*26 = 78 random effects that are in this model. But the dataset has only 74 rows. This is a check built into lmer() to avoid fitting overly complex models for a given dataset. You can disable this check with (also, use REML=FALSE, not "False"):

M2 <- lmer(Response ~ P + A + (P + A | Group), REML=FALSE, data=Trial, control=lmerControl(check.nobs.vs.nRE="ignore"))

Then it will run and this is the same model as fitted with:

M2n <- lme( Response ~ P + A, random = ~ P + A | Group, data=Trial, method="ML")

The results differ somewhat though, because both packages handle such ill-defined problems in different ways.

Best,
Wolfgang

>-----Original Message-----
>From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] On
>Behalf Of Peter R Law via R-sig-mixed-models
>Sent: Monday, 01 March, 2021 23:34
>To: Phillip Alday; r-sig-mixed-models at r-project.org
>Subject: Re: [R-sig-ME] lmer code for multiple random slopes
>
>Thanks Phillip. Sorry about the goof in the summary code. It doesn't actually
>affect the behaviour that I described, however. Below is a more complete output
>from R. You will see the str output for the data file, which doesn't seem to
>indicate that R is treating any of the variables other than Group as a factor (by
>the way, I recently updated both nlme and lme4 packages but I haven't noticed any
>changes to their behaviour as a result. But I just noticed that when lme4 loads
>there is a warning that it was built under R 3.5.3 Is that a possible problem?).
>For Model 5n (random slopes for both normP and normA) lme returns an analysis but
>lmer complains about the 78 variance components. Same if one uses A and P instead
>(Model2ns and 2). If I use variable PR, however, I get the error message you got
>with lme (Model 7n for normA and normPR) or a different error message (Model 6n
>for normPR and normA).
>
>Yet, lmer seems to behave properly for ~P+A+(P|Group)+(A|Group) (Model 4) and
>P+PR+(P+PR||Group) (model M3).  While these models remove the correlations between
>the random factors, if lmer is seeing variables as factors rather than numeric,
>wouldn't lmer still see the wrong number of random factors in these two models?
>
>Finally, Models 1 and 1n compare lme and lmer on a model with a single random
>slope, showing the differences in parameter estimates but not log-likelihood or
>AIC.
>
>I have attached the trial.txt and trial.r files again. I assume you will receive
>them directly if you want to open them.
>
>R output:
>
>> library(lme4)
>Loading required package: Matrix
>Warning message:
>package ?lme4? was built under R version 3.5.3
>> library(nlme)
>
>Attaching package: ?nlme?
>
>The following object is masked from ?package:lme4?:
>
>    lmList
>
>> Trial <- read.table(file="C:/PRL/R/RGFRRIBI/Trial.txt", header = TRUE)
>> names(Trial)
>[1] "Response" "P"        "A"        "PR"       "Group"
>> str(Trial)
>'data.frame':	74 obs. of  5 variables:
> $ Response: int  24 22 24 24 23 24 24 24 35 31 ...
> $ P       : int  15 82 95 71 88 77 93 91 13 82 ...
> $ A       : num  44.2 39.6 41.4 34.1 44.6 ...
> $ PR      : num  121 115 250 200 252 ...
> $ Group   : Factor w/ 26 levels "G1","G10","G11",..: 1 12 12 20 20 21 21 22 23 24
>...
>> Trial$normP <- as.double(scale(Trial$P))
>> Trial$normA <- as.double(scale(Trial$A))
>> Trial$normPR <- as.double(scale(Trial$PR))
>> names(Trial)
>[1] "Response" "P"        "A"        "PR"       "Group"    "normP"    "normA"
>"normPR"
>> str(Trial)
>'data.frame':	74 obs. of  8 variables:
> $ Response: int  24 22 24 24 23 24 24 24 35 31 ...
> $ P       : int  15 82 95 71 88 77 93 91 13 82 ...
> $ A       : num  44.2 39.6 41.4 34.1 44.6 ...
> $ PR      : num  121 115 250 200 252 ...
> $ Group   : Factor w/ 26 levels "G1","G10","G11",..: 1 12 12 20 20 21 21 22 23 24
>...
> $ normP   : num  -1.783 0.719 1.205 0.308 0.943 ...
> $ normA   : num  1.576 0.221 0.754 -1.38 1.708 ...
> $ normPR  : num  -1.415 -1.486 0.251 -0.385 0.281 ...
>
>> M5n <- lme(Response~normP+normA, random=~normP+normA|Group,data=Trial,
>method="ML")
>> summary(M5n)
>Linear mixed-effects model fit by maximum likelihood
> Data: Trial
>       AIC      BIC    logLik
>  536.4562 559.4969 -258.2281
>
>Random effects:
> Formula: ~normP + normA | Group
> Structure: General positive-definite, Log-Cholesky parametrization
>            StdDev       Corr
>(Intercept) 0.0002514711 (Intr) normP
>normP       0.0002146005 0
>normA       0.0001485695 0      0
>Residual    7.9298211705
>
>Fixed effects: Response ~ normP + normA
>                Value Std.Error DF   t-value p-value
>(Intercept) 29.081081 0.9410966 46 30.901270  0.0000
>normP       -0.784566 0.9620920 46 -0.815479  0.4190
>normA        0.480397 0.9620920 46  0.499326  0.6199
> Correlation:
>      (Intr) normP
>normP  0.000
>normA  0.000 -0.173
>
>Standardized Within-Group Residuals:
>       Min         Q1        Med         Q3        Max
>-1.8447131 -0.5563605 -0.2613520  0.2755547  5.5643551
>
>Number of Observations: 74
>Number of Groups: 26
>
>> M5 <- lmer(Response~normP+normA+(normP+normA|Group), REML="False", data=Trial)
>Error: number of observations (=74) <= number of random effects (=78) for term
>(normP + normA | Group); the random-effects parameters and the residual variance
>(or scale parameter) are probably unidentifiable
>
>> M2n <- lme(Response~P+A, random=~P+A|Group,data=Trial, method="ML")
>> summary(M2n)
>Linear mixed-effects model fit by maximum likelihood
> Data: Trial
>       AIC      BIC    logLik
>  536.4562 559.4969 -258.2281
>
>Random effects:
> Formula: ~P + A | Group
> Structure: General positive-definite, Log-Cholesky parametrization
>            StdDev       Corr
>(Intercept) 3.061144e-04 (Intr) P
>P           1.535752e-09 0
>A           8.517774e-13 0      0
>Residual    7.929821e+00
>
>Fixed effects: Response ~ P + A
>                Value Std.Error DF    t-value p-value
>(Intercept) 25.453398 10.828841 46  2.3505192  0.0231
>P           -0.029307  0.035939 46 -0.8154787  0.4190
>A            0.140819  0.282018 46  0.4993255  0.6199
> Correlation:
>  (Intr) P
>P -0.033
>A -0.975 -0.173
>
>Standardized Within-Group Residuals:
>       Min         Q1        Med         Q3        Max
>-1.8447131 -0.5563605 -0.2613520  0.2755547  5.5643551
>
>Number of Observations: 74
>Number of Groups: 26
>
>> M2 <- lmer(Response~P+A+(P+A|Group), REML="False", data=Trial)
>Error: number of observations (=74) <= number of random effects (=78) for term (P
>+ A | Group); the random-effects parameters and the residual variance (or scale
>parameter) are probably unidentifiable
>
>> M6n <- lme(Response~A+PR, random=~A+PR|Group,data=Trial, method="ML")
>Error in logLik.lmeStructInt(lmeSt, lmePars) :
>  NA/NaN/Inf in foreign function call (arg 3)
>In addition: There were 50 or more warnings (use warnings() to see the first 50)
>> summary(M6n)
>Error in summary(M6n) : object 'M6n' not found
>
>> M7n <- lme(Response~normA+normPR, random=~normA+normPR|Group,data=Trial,
>method="ML")
>Error in lme.formula(Response ~ normA + normPR, random = ~normA + normPR |  :
>  nlminb problem, convergence error code = 1
>  message = iteration limit reached without convergence (10)
>> summary(M7n)
>Error in summary(M7n) : object 'M7n' not found
>
>> M4 <-  lmer(Response~P+A+(P|Group)+(A|Group), REML="False", data=Trial)
>boundary (singular) fit: see ?isSingular
>> summary(M4)
>Linear mixed model fit by maximum likelihood  ['lmerMod']
>Formula: Response ~ P + A + (P | Group) + (A | Group)
>   Data: Trial
>
>     AIC      BIC   logLik deviance df.resid
>   536.5    559.5   -258.2    516.5       64
>
>Scaled residuals:
>    Min      1Q  Median      3Q     Max
>-1.8447 -0.5564 -0.2614  0.2756  5.5644
>
>Random effects:
> Groups   Name        Variance  Std.Dev.  Corr
> Group    (Intercept) 1.035e-06 1.017e-03
>          P           5.031e-09 7.093e-05 -1.00
> Group.1  (Intercept) 5.262e-07 7.254e-04
>          A           1.941e-11 4.406e-06 -1.00
> Residual             6.288e+01 7.930e+00
>Number of obs: 74, groups:  Group, 26
>
>Fixed effects:
>            Estimate Std. Error t value
>(Intercept) 25.45340   10.60707   2.400
>P           -0.02931    0.03520  -0.833
>A            0.14082    0.27624   0.510
>
>Correlation of Fixed Effects:
>  (Intr) P
>P -0.033
>A -0.975 -0.173
>convergence code: 0
>boundary (singular) fit: see ?isSingular
>
>> M3 <- lmer(Response~P+PR+(P+PR||Group), REML="False", data=Trial)
>boundary (singular) fit: see ?isSingular
>> summary(M3)
>Linear mixed model fit by maximum likelihood  ['lmerMod']
>Formula: Response ~ P + PR + ((1 | Group) + (0 + P | Group) + (0 + PR |
>Group))
>   Data: Trial
>
>     AIC      BIC   logLik deviance df.resid
>   530.5    546.7   -258.3    516.5       67
>
>Scaled residuals:
>    Min      1Q  Median      3Q     Max
>-1.8106 -0.5567 -0.2981  0.2984  5.0950
>
>Random effects:
> Groups   Name        Variance  Std.Dev.
> Group    (Intercept) 5.422e-04 0.023285
> Group.1  P           0.000e+00 0.000000
> Group.2  PR          7.239e-05 0.008508
> Residual             5.912e+01 7.688728
>Number of obs: 74, groups:  Group, 26
>
>Fixed effects:
>             Estimate Std. Error t value
>(Intercept) 29.265396   3.747575   7.809
>P           -0.023208   0.035100  -0.661
>PR           0.006151   0.012288   0.501
>
>Correlation of Fixed Effects:
>   (Intr) P
>P  -0.633
>PR -0.754  0.043
>convergence code: 0
>boundary (singular) fit: see ?isSingular
>
>> M1 <- lmer(Response~P+A+(A|Group), REML="False", data=Trial)
>boundary (singular) fit: see ?isSingular
>> summary(M1)
>Linear mixed model fit by maximum likelihood  ['lmerMod']
>Formula: Response ~ P + A + (A | Group)
>   Data: Trial
>
>     AIC      BIC   logLik deviance df.resid
>   530.5    546.6   -258.2    516.5       67
>
>Scaled residuals:
>    Min      1Q  Median      3Q     Max
>-1.8447 -0.5564 -0.2614  0.2756  5.5644
>
>Random effects:
> Groups   Name        Variance  Std.Dev.  Corr
> Group    (Intercept) 0.000e+00 0.000e+00
>          A           1.657e-10 1.287e-05  NaN
> Residual             6.288e+01 7.930e+00
>Number of obs: 74, groups:  Group, 26
>
>Fixed effects:
>            Estimate Std. Error t value
>(Intercept) 25.45340   10.60707   2.400
>P           -0.02931    0.03520  -0.833
>A            0.14082    0.27624   0.510
>
>Correlation of Fixed Effects:
>  (Intr) P
>P -0.033
>A -0.975 -0.173
>convergence code: 0
>boundary (singular) fit: see ?isSingular
>
>> M1n <- lme(Response~1+P+A, random=~1+A|Group,data=Trial, method="ML")
>> summary(M1n)
>Linear mixed-effects model fit by maximum likelihood
> Data: Trial
>       AIC      BIC    logLik
>  530.4562 546.5847 -258.2281
>
>Random effects:
> Formula: ~1 + A | Group
> Structure: General positive-definite, Log-Cholesky parametrization
>            StdDev       Corr
>(Intercept) 5.277473e-04 (Intr)
>A           1.487869e-18 0
>Residual    7.929821e+00
>
>Fixed effects: Response ~ 1 + P + A
>                Value Std.Error DF    t-value p-value
>(Intercept) 25.453398 10.828841 46  2.3505192  0.0231
>P           -0.029307  0.035939 46 -0.8154787  0.4190
>A            0.140819  0.282018 46  0.4993255  0.6199
> Correlation:
>  (Intr) P
>P -0.033
>A -0.975 -0.173
>
>Standardized Within-Group Residuals:
>       Min         Q1        Med         Q3        Max
>-1.8447131 -0.5563605 -0.2613520  0.2755547  5.5643551
>
>Number of Observations: 74
>Number of Groups: 26
>
>Peter

From |@g|ne @end|ng |rom p@@jd@org  Wed Mar  3 14:23:37 2021
From: |@g|ne @end|ng |rom p@@jd@org (=?iso-8859-1?Q?IAGO_GIN=C9_V=C1ZQUEZ?=)
Date: Wed, 3 Mar 2021 13:23:37 +0000
Subject: [R-sig-ME] 
 fixed-effect model matrix is rank deficient so dropping
 1 column / coefficient
In-Reply-To: <CAJuCY5xw3ziOtEz6jiiLjWR_UOCcq=PPnOjEc8hXrDZRGf05KA@mail.gmail.com>
References: <AM6PR02MB4423E1D67B1D632B6E723D7E92989@AM6PR02MB4423.eurprd02.prod.outlook.com>,
 <CAJuCY5xw3ziOtEz6jiiLjWR_UOCcq=PPnOjEc8hXrDZRGf05KA@mail.gmail.com>
Message-ID: <AM6PR02MB4423D7435049AFAB38610B3E92989@AM6PR02MB4423.eurprd02.prod.outlook.com>

Dear Thierry,

Thank you for the ask. I send you the data attached. The model I am using is

lmer(outcome ~ YLD0 + YLD1 + YLD2 + YLD3 + YLD4 + SEV1 + SEV2 + SEV3 + SEV4 + SEV5 + SEV6 + x0*x1 + x2 + x0*x3 + year + (1|id), data=data2Sh).

The factor variable is x0. The dropped coefficient is x0==2 : x3

Let me know any other information I can give.

Thank you!


Iago

________________________________
De: Thierry Onkelinx <thierry.onkelinx at inbo.be>
Enviat el: dimecres, 3 de mar? de 2021 13:30
Per a: IAGO GIN? V?ZQUEZ <i.gine at pssjd.org>
A/c: r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>
Tema: Re: [R-sig-ME] fixed-effect model matrix is rank deficient so dropping 1 column / coefficient

Dear Iago,

We only have your description of the data. It would be easier for us to help you if you provide a small dataset that illustrates the structure in your data and how you use the data in your model.

Best regards,

Thierry

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be<mailto:thierry.onkelinx at inbo.be>
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be<http://www.inbo.be>

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

[https://inbo-website-prd-532750756126.s3-eu-west-1.amazonaws.com/inbologoleeuw_nl.png]<https://www.inbo.be>


Op wo 3 mrt. 2021 om 13:11 schreef IAGO GIN? V?ZQUEZ <i.gine at pssjd.org<mailto:i.gine at pssjd.org>>:
Dear all,

I have 3 related questions, probably already answered, but which I cannot find:

When computing a model with lmer I get the message

fixed-effect model matrix is rank deficient so dropping 1 column / coefficient

Then, my questions are, first, how can I see/compute/get the rank deficient fixed-effect model matrix, second how is that matrix computed, and third (these actually are 2 questions), if my model is yet valid (is it?) how can the dropped fixed effect explained in the results of a paper.

In the example in ?fixef
fm2 <- lmer(Reaction ~ Days + Days2 + (1|Subject),
            data=transform(sleepstudy,Days2=Days))
fixef(fm2,add.dropped=TRUE)

the problem happens because 2 independent variables are equal, but in my model the numeric independent variables are not so highly correlated. In fact the problem happens with the interaction between a factor and a numeric variable, since it is one of the categories of the factor interacting with the numeric, which is dropped.

Thank you and stay safe!


Iago


        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

From th|erry@onke||nx @end|ng |rom |nbo@be  Wed Mar  3 14:45:38 2021
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Wed, 3 Mar 2021 14:45:38 +0100
Subject: [R-sig-ME] 
 fixed-effect model matrix is rank deficient so dropping
 1 column / coefficient
In-Reply-To: <AM6PR02MB4423D7435049AFAB38610B3E92989@AM6PR02MB4423.eurprd02.prod.outlook.com>
References: <AM6PR02MB4423E1D67B1D632B6E723D7E92989@AM6PR02MB4423.eurprd02.prod.outlook.com>
 <CAJuCY5xw3ziOtEz6jiiLjWR_UOCcq=PPnOjEc8hXrDZRGf05KA@mail.gmail.com>
 <AM6PR02MB4423D7435049AFAB38610B3E92989@AM6PR02MB4423.eurprd02.prod.outlook.com>
Message-ID: <CAJuCY5wsRcT1cL4qZFXKC=DMQkGuQu2mnAUSn-qUXOzCzrJX9g@mail.gmail.com>

Dear Iago,

The reference category of x0 (x0 == "0") contains only zeros for x3. This
is why you get the rank deficiency. The solution is to create the
meaningful interactions as new variables.

data2Sh$x3_1 <- ifelse(data2Sh$x0 == "1", data2Sh$x3, 0)
data2Sh$x3_2 <- ifelse(data2Sh$x0 == "2", data2Sh$x3, 0)
lmer(outcome ~ YLD0 + YLD1 + YLD2 + YLD3 + YLD4 + SEV1 + SEV2 + SEV3 + SEV4
+ SEV5 + SEV6 + x0*x1 + x2 + x3 + x3_1 + x3_2 + year + (1|id), data =
data2Sh)

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op wo 3 mrt. 2021 om 14:23 schreef IAGO GIN? V?ZQUEZ <i.gine at pssjd.org>:

> Dear Thierry,
>
> Thank you for the ask. I send you the data attached. The model I am using
> is
>
> lmer(outcome ~ YLD0 + YLD1 + YLD2 + YLD3 + YLD4 + SEV1 + SEV2 + SEV3 +
> SEV4 + SEV5 + SEV6 + x0*x1 + x2 + x0*x3 + year + (1|id), data=data2Sh).
>
> The factor variable is x0. The dropped coefficient is x0==2 : x3
>
> Let me know any other information I can give.
>
> Thank you!
>
>
> *Iago *
> ------------------------------
> *De:* Thierry Onkelinx <thierry.onkelinx at inbo.be>
> *Enviat el:* dimecres, 3 de mar? de 2021 13:30
> *Per a:* IAGO GIN? V?ZQUEZ <i.gine at pssjd.org>
> *A/c:* r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>
> *Tema:* Re: [R-sig-ME] fixed-effect model matrix is rank deficient so
> dropping 1 column / coefficient
>
> Dear Iago,
>
> We only have your description of the data. It would be easier for us to
> help you if you provide a small dataset that illustrates the structure in
> your data and how you use the data in your model.
>
> Best regards,
>
> Thierry
>
> ir. Thierry Onkelinx
> Statisticus / Statistician
>
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
> FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Havenlaan 88 bus 73, 1000 Brussel
> www.inbo.be
>
>
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> ///////////////////////////////////////////////////////////////////////////////////////////
>
> <https://www.inbo.be>
>
>
> Op wo 3 mrt. 2021 om 13:11 schreef IAGO GIN? V?ZQUEZ <i.gine at pssjd.org>:
>
> Dear all,
>
> I have 3 related questions, probably already answered, but which I cannot
> find:
>
> When computing a model with lmer I get the message
>
> fixed-effect model matrix is rank deficient so dropping 1 column /
> coefficient
>
> Then, my questions are, first, how can I see/compute/get the rank
> deficient fixed-effect model matrix, second how is that matrix computed,
> and third (these actually are 2 questions), if my model is yet valid (is
> it?) how can the dropped fixed effect explained in the results of a paper.
>
> In the example in ?fixef
> fm2 <- lmer(Reaction ~ Days + Days2 + (1|Subject),
>             data=transform(sleepstudy,Days2=Days))
> fixef(fm2,add.dropped=TRUE)
>
> the problem happens because 2 independent variables are equal, but in my
> model the numeric independent variables are not so highly correlated. In
> fact the problem happens with the interaction between a factor and a
> numeric variable, since it is one of the categories of the factor
> interacting with the numeric, which is dropped.
>
> Thank you and stay safe!
>
>
> Iago
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>
>

	[[alternative HTML version deleted]]


From th|erry@onke||nx @end|ng |rom |nbo@be  Wed Mar  3 14:47:55 2021
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Wed, 3 Mar 2021 14:47:55 +0100
Subject: [R-sig-ME] 
 fixed-effect model matrix is rank deficient so dropping
 1 column / coefficient
In-Reply-To: <CAJuCY5wsRcT1cL4qZFXKC=DMQkGuQu2mnAUSn-qUXOzCzrJX9g@mail.gmail.com>
References: <AM6PR02MB4423E1D67B1D632B6E723D7E92989@AM6PR02MB4423.eurprd02.prod.outlook.com>
 <CAJuCY5xw3ziOtEz6jiiLjWR_UOCcq=PPnOjEc8hXrDZRGf05KA@mail.gmail.com>
 <AM6PR02MB4423D7435049AFAB38610B3E92989@AM6PR02MB4423.eurprd02.prod.outlook.com>
 <CAJuCY5wsRcT1cL4qZFXKC=DMQkGuQu2mnAUSn-qUXOzCzrJX9g@mail.gmail.com>
Message-ID: <CAJuCY5yn5jxJskvMPDi-1UjNAc=d2qziwKsgJpkH1cb2xb-piQ@mail.gmail.com>

Note that you should only use the new interaction variable to avoid the
rank deficiency (no x3).

lmer(outcome ~ YLD0 + YLD1 + YLD2 + YLD3 + YLD4 + SEV1 + SEV2 + SEV3 + SEV4
+ SEV5 + SEV6 + x0*x1 + x2 + x3_1 + x3_2 + year + (1|id), data = data2Sh)

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op wo 3 mrt. 2021 om 14:45 schreef Thierry Onkelinx <
thierry.onkelinx at inbo.be>:

> Dear Iago,
>
> The reference category of x0 (x0 == "0") contains only zeros for x3. This
> is why you get the rank deficiency. The solution is to create the
> meaningful interactions as new variables.
>
> data2Sh$x3_1 <- ifelse(data2Sh$x0 == "1", data2Sh$x3, 0)
> data2Sh$x3_2 <- ifelse(data2Sh$x0 == "2", data2Sh$x3, 0)
> lmer(outcome ~ YLD0 + YLD1 + YLD2 + YLD3 + YLD4 + SEV1 + SEV2 + SEV3 +
> SEV4 + SEV5 + SEV6 + x0*x1 + x2 + x3 + x3_1 + x3_2 + year + (1|id), data =
> data2Sh)
>
> Best regards,
>
> ir. Thierry Onkelinx
> Statisticus / Statistician
>
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
> FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Havenlaan 88 bus 73, 1000 Brussel
> www.inbo.be
>
>
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> ///////////////////////////////////////////////////////////////////////////////////////////
>
> <https://www.inbo.be>
>
>
> Op wo 3 mrt. 2021 om 14:23 schreef IAGO GIN? V?ZQUEZ <i.gine at pssjd.org>:
>
>> Dear Thierry,
>>
>> Thank you for the ask. I send you the data attached. The model I am using
>> is
>>
>> lmer(outcome ~ YLD0 + YLD1 + YLD2 + YLD3 + YLD4 + SEV1 + SEV2 + SEV3 +
>> SEV4 + SEV5 + SEV6 + x0*x1 + x2 + x0*x3 + year + (1|id), data=data2Sh).
>>
>> The factor variable is x0. The dropped coefficient is x0==2 : x3
>>
>> Let me know any other information I can give.
>>
>> Thank you!
>>
>>
>> *Iago *
>> ------------------------------
>> *De:* Thierry Onkelinx <thierry.onkelinx at inbo.be>
>> *Enviat el:* dimecres, 3 de mar? de 2021 13:30
>> *Per a:* IAGO GIN? V?ZQUEZ <i.gine at pssjd.org>
>> *A/c:* r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org
>> >
>> *Tema:* Re: [R-sig-ME] fixed-effect model matrix is rank deficient so
>> dropping 1 column / coefficient
>>
>> Dear Iago,
>>
>> We only have your description of the data. It would be easier for us to
>> help you if you provide a small dataset that illustrates the structure in
>> your data and how you use the data in your model.
>>
>> Best regards,
>>
>> Thierry
>>
>> ir. Thierry Onkelinx
>> Statisticus / Statistician
>>
>> Vlaamse Overheid / Government of Flanders
>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
>> AND FOREST
>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
>> thierry.onkelinx at inbo.be
>> Havenlaan 88 bus 73, 1000 Brussel
>> www.inbo.be
>>
>>
>> ///////////////////////////////////////////////////////////////////////////////////////////
>> To call in the statistician after the experiment is done may be no more
>> than asking him to perform a post-mortem examination: he may be able to say
>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does not
>> ensure that a reasonable answer can be extracted from a given body of data.
>> ~ John Tukey
>>
>> ///////////////////////////////////////////////////////////////////////////////////////////
>>
>> <https://www.inbo.be>
>>
>>
>> Op wo 3 mrt. 2021 om 13:11 schreef IAGO GIN? V?ZQUEZ <i.gine at pssjd.org>:
>>
>> Dear all,
>>
>> I have 3 related questions, probably already answered, but which I cannot
>> find:
>>
>> When computing a model with lmer I get the message
>>
>> fixed-effect model matrix is rank deficient so dropping 1 column /
>> coefficient
>>
>> Then, my questions are, first, how can I see/compute/get the rank
>> deficient fixed-effect model matrix, second how is that matrix computed,
>> and third (these actually are 2 questions), if my model is yet valid (is
>> it?) how can the dropped fixed effect explained in the results of a paper.
>>
>> In the example in ?fixef
>> fm2 <- lmer(Reaction ~ Days + Days2 + (1|Subject),
>>             data=transform(sleepstudy,Days2=Days))
>> fixef(fm2,add.dropped=TRUE)
>>
>> the problem happens because 2 independent variables are equal, but in my
>> model the numeric independent variables are not so highly correlated. In
>> fact the problem happens with the interaction between a factor and a
>> numeric variable, since it is one of the categories of the factor
>> interacting with the numeric, which is dropped.
>>
>> Thank you and stay safe!
>>
>>
>> Iago
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>>

	[[alternative HTML version deleted]]


From k@m@|@@tmeh @end|ng |rom hotm@||@com  Wed Mar  3 22:19:00 2021
From: k@m@|@@tmeh @end|ng |rom hotm@||@com (Kamal Atmeh)
Date: Wed, 3 Mar 2021 22:19:00 +0100
Subject: [R-sig-ME] MCMCglmm interaction and posterior mode
Message-ID: <PA4P189MB13438F732ADBB30695245606FE989@PA4P189MB1343.EURP189.PROD.OUTLOOK.COM>

Dear all,

I have some questions, which may sound trivial, pertaining to 
interaction models with MCMCglmm.

I am running the following model with a gaussian distribution and a 
3-way interaction between two categorical two-level variables (tactic: 
F/H and period PB/B) and one continuous variable (env):

model <- MCMCglmm(lD ~ tactic*period*env
 ???????????????????????????????????? , random = 
~sp_phylo+species2+phylo_pop+phylo_popY+phylo_pop_id
 ???????????????????????????????????? , family = "gaussian"
 ???????????????????????????????????? , ginverse = list(sp_phylo = 
inv.phylo$Ainv) # include a custom matrix for argument phylo
 ???????????????????????????????????? , prior = prior1
 ???????????????????????????????????? , data = Data
 ???????????????????????????????????? , nitt = 22e+04
 ???????????????????????????????????? , burnin = 20000
 ???????????????????????????????????? , thin = 100
 ???????????????????????????????????? , pr=TRUE)

After looking at the results, I found that the 2-way interaction 
tactic*env from the tactic*period*env interaction was not significant, 
however the 3-way interaction itself was, with the following output in 
the summary:

 >>>?? tacticH:periodB:env????? 0.17831? 0.05360 0.30512???? 5000? 
0.0052 ** (the intercept represents tactic F and period PB)

I tried to run the model again in order to simplify it using ":" and 
therefore remove the non-significant 2-way interaction:

model2 <- MCMCglmm(lD ~ tactic*period + period*env + *tactic:period:env*
 ???????????????????????????????????? , random = 
~sp_phylo+species2+phylo_pop+phylo_popY+phylo_pop_id
 ???????????????????????????????????? , family = "gaussian"
 ???????????????????????????????????? , ginverse = list(sp_phylo = 
inv.phylo$Ainv) # include a custom matrix for argument phylo
 ???????????????????????????????????? , prior = prior1
 ???????????????????????????????????? , data = Data
 ???????????????????????????????????? , nitt = 22e+04
 ???????????????????????????????????? , burnin = 20000
 ???????????????????????????????????? , thin = 100
 ???????????????????????????????????? , pr=TRUE)

When using ":", the output of my model returns the posterior mean for 
each level of the categorical variables instead of one level as before:

tacticF:periodPB:env -0.1668620 -0.3554264? 0.0005143??? 195.0 0.0923 .
tacticF:periodB:env? -0.2018706 -0.3783204 -0.0174366??? 195.0 0.0410 *
tacticH:periodPB:env -0.1561097 -0.2066183 -0.1093840??? 118.2 <0.005 **

How should I define the interaction in the model in order to obtain an 
output similar to the one when the "*" interaction was used 
(tacticH:periodB:env) while simplifying and removing the non-significant 
interaction from the 3-way interaction?

Finally, is there a way to automatically compute the posterior mean of 
the continuous variable for each modality of the interaction?

Thank you and stay safe!

Kamal


	[[alternative HTML version deleted]]


From w@||dm@w@@@10 @end|ng |rom gm@||@com  Wed Mar  3 23:17:21 2021
From: w@||dm@w@@@10 @end|ng |rom gm@||@com (Walid Crampton-Mawass)
Date: Wed, 3 Mar 2021 17:17:21 -0500
Subject: [R-sig-ME] MCMCglmm interaction and posterior mode
In-Reply-To: <PA4P189MB13438F732ADBB30695245606FE989@PA4P189MB1343.EURP189.PROD.OUTLOOK.COM>
References: <PA4P189MB13438F732ADBB30695245606FE989@PA4P189MB1343.EURP189.PROD.OUTLOOK.COM>
Message-ID: <CAJtCY7V92MjygOPt6L1Et8i=jYOkor3dmhWcc1H+K5qEgq-=Vw@mail.gmail.com>

Hello Kamal,

One way to do this with MCMCglmm is to use the at.level() function. You can
determine for which level of your categorical variable you want the
interaction, ex. at.level(tactic,2):a.level(period,2):env.

However, in doing so you are only estimating the coefficient for that
specific interaction and ignoring the rest. That to me would seem a bit odd
given that for the 2-way interactions you are still including the other
levels, but of course it depends on what assumptions you are making for
your model.

and regarding automating the computation of the posterior mean, I think
(not sure though) that the broom package offers some wrap functions for
MCMCglmm and computing posterior estimates.

Good luck
-- 
Walid Crampton-Mawass
Ph.D. candidate in Evolutionary Biology
Population Genetics Laboratory
University of Qu?bec at Trois-Rivi?res
3351, boul. des Forges, C.P. 500
Trois-Rivi?res (Qu?bec) G9A 5H7
Telephone: 819-376-5011 poste 3384


On Wed, Mar 3, 2021 at 4:19 PM Kamal Atmeh <kamal.atmeh at hotmail.com> wrote:

> Dear all,
>
> I have some questions, which may sound trivial, pertaining to
> interaction models with MCMCglmm.
>
> I am running the following model with a gaussian distribution and a
> 3-way interaction between two categorical two-level variables (tactic:
> F/H and period PB/B) and one continuous variable (env):
>
> model <- MCMCglmm(lD ~ tactic*period*env
>                                       , random =
> ~sp_phylo+species2+phylo_pop+phylo_popY+phylo_pop_id
>                                       , family = "gaussian"
>                                       , ginverse = list(sp_phylo =
> inv.phylo$Ainv) # include a custom matrix for argument phylo
>                                       , prior = prior1
>                                       , data = Data
>                                       , nitt = 22e+04
>                                       , burnin = 20000
>                                       , thin = 100
>                                       , pr=TRUE)
>
> After looking at the results, I found that the 2-way interaction
> tactic*env from the tactic*period*env interaction was not significant,
> however the 3-way interaction itself was, with the following output in
> the summary:
>
>  >>>   tacticH:periodB:env      0.17831  0.05360 0.30512     5000
> 0.0052 ** (the intercept represents tactic F and period PB)
>
> I tried to run the model again in order to simplify it using ":" and
> therefore remove the non-significant 2-way interaction:
>
> model2 <- MCMCglmm(lD ~ tactic*period + period*env + *tactic:period:env*
>                                       , random =
> ~sp_phylo+species2+phylo_pop+phylo_popY+phylo_pop_id
>                                       , family = "gaussian"
>                                       , ginverse = list(sp_phylo =
> inv.phylo$Ainv) # include a custom matrix for argument phylo
>                                       , prior = prior1
>                                       , data = Data
>                                       , nitt = 22e+04
>                                       , burnin = 20000
>                                       , thin = 100
>                                       , pr=TRUE)
>
> When using ":", the output of my model returns the posterior mean for
> each level of the categorical variables instead of one level as before:
>
> tacticF:periodPB:env -0.1668620 -0.3554264  0.0005143    195.0 0.0923 .
> tacticF:periodB:env  -0.2018706 -0.3783204 -0.0174366    195.0 0.0410 *
> tacticH:periodPB:env -0.1561097 -0.2066183 -0.1093840    118.2 <0.005 **
>
> How should I define the interaction in the model in order to obtain an
> output similar to the one when the "*" interaction was used
> (tacticH:periodB:env) while simplifying and removing the non-significant
> interaction from the 3-way interaction?
>
> Finally, is there a way to automatically compute the posterior mean of
> the continuous variable for each modality of the interaction?
>
> Thank you and stay safe!
>
> Kamal
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From pr|db @end|ng |rom protonm@||@com  Thu Mar  4 00:08:27 2021
From: pr|db @end|ng |rom protonm@||@com (Peter R Law)
Date: Wed, 03 Mar 2021 23:08:27 +0000
Subject: [R-sig-ME] lmer code for multiple random slopes
In-Reply-To: <e0894da27f994e64863768033e5c4989@UM-MAIL3214.unimaas.nl>
References: <34JKCz24u8awawkhTLmboO_cBRWW-m0XAb0frTUb9YqspQe1VeBBWUvfqKd3-QIMLeKpiDUyzhN0X6aqRlEqwX1LmBfg3gn9EB2XCa5v62s=@protonmail.com>
 <1877a680-d190-7202-537d-90d51bc6574b@phillipalday.com>
 <de6401b0-6cac-65d8-cbc3-0f59ce79409d@gmail.com>
 <NCGF24lxdAy2bcOAoQsutEkYQ-ZIzb4e3xLenmSDhGyZN8a8sIcv-wHF0IEfLK8GQGccVE1hLTk-i1UPxFITTgLC9T929E6F4rQVMwVN8bg=@protonmail.com>
 <e2zoG5je3QHzcPl3dsttnLigMgzR8mqiUJAdgntQm9xPOX4j3SwlDytjMtbOFRj-vf5TjpHVRD7rzd54mvwMFm9OhW-ff4lfhR383lioPX4=@protonmail.com>
 <f286a096-f420-c246-61ad-542eaa5dad44@phillipalday.com>
 <CIYTFe7RNWpkAwUyuCM71pFEfhP-gPVj0OcD-UjLX0LbfzrRbySwMeVxASDMGs6D3aOxqydPUAg1NbZJar32LOtM42U-ZY-03eCCB7JbkUg=@protonmail.com>
 <e0894da27f994e64863768033e5c4989@UM-MAIL3214.unimaas.nl>
Message-ID: <Ys_EWO7eMIPbh1nezv5C8Qd2cu51FF6MTNolLdBcuZcBgb8soEkJwTMl8QPDQKRCNqLEQQLJyqoVNkB2izRT13vOwKw_NIuBvK34uES4oJk=@protonmail.com>

Many thanks Wolfgang! That does clear up my confusion. That interpretation of 'random effects' didn't occur to me.

Thanks also for pointing out that the differences in the estimates provided by lme and lmer occur because they handle singular models differently and won't occur for non-singular examples.

When I have collected enough data, the model I am actually interested in will have two nested random factors, G1 within G2, and I only want random slopes (say for a covariate x) with respect to G2, but random intercepts for both factors. Am I right in thinking the code will take the form

response ~ x + (1|G2/G1) + (x|G2)?

Much appreciated,

Peter


Peter R Law
Research Associate
Center for African Conservation Ecology
Nelson Mandela University
South Africa

Sent with ProtonMail Secure Email.

??????? Original Message ???????
On Wednesday, March 3, 2021 7:43 AM, Viechtbauer, Wolfgang (SP) <wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:

> Dear Peter, Dear All,
>
> The error doesn't say 78 variance components, it says 78 random effects. There are 26 groups in this dataset and you are estimating random intercepts and two sets of random slopes. Hence, there are 3*26 = 78 random effects that are in this model. But the dataset has only 74 rows. This is a check built into lmer() to avoid fitting overly complex models for a given dataset. You can disable this check with (also, use REML=FALSE, not "False"):
>
> M2 <- lmer(Response ~ P + A + (P + A | Group), REML=FALSE, data=Trial, control=lmerControl(check.nobs.vs.nRE="ignore"))
>
> Then it will run and this is the same model as fitted with:
>
> M2n <- lme( Response ~ P + A, random = ~ P + A | Group, data=Trial, method="ML")
>
> The results differ somewhat though, because both packages handle such ill-defined problems in different ways.
>
> Best,
> Wolfgang
>
> > -----Original Message-----
> > From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] On
> > Behalf Of Peter R Law via R-sig-mixed-models
> > Sent: Monday, 01 March, 2021 23:34
> > To: Phillip Alday; r-sig-mixed-models at r-project.org
> > Subject: Re: [R-sig-ME] lmer code for multiple random slopes
> > Thanks Phillip. Sorry about the goof in the summary code. It doesn't actually
> > affect the behaviour that I described, however. Below is a more complete output
> > from R. You will see the str output for the data file, which doesn't seem to
> > indicate that R is treating any of the variables other than Group as a factor (by
> > the way, I recently updated both nlme and lme4 packages but I haven't noticed any
> > changes to their behaviour as a result. But I just noticed that when lme4 loads
> > there is a warning that it was built under R 3.5.3 Is that a possible problem?).
> > For Model 5n (random slopes for both normP and normA) lme returns an analysis but
> > lmer complains about the 78 variance components. Same if one uses A and P instead
> > (Model2ns and 2). If I use variable PR, however, I get the error message you got
> > with lme (Model 7n for normA and normPR) or a different error message (Model 6n
> > for normPR and normA).
> > Yet, lmer seems to behave properly for ~P+A+(P|Group)+(A|Group) (Model 4) and
> > P+PR+(P+PR||Group) (model M3). While these models remove the correlations between
> > the random factors, if lmer is seeing variables as factors rather than numeric,
> > wouldn't lmer still see the wrong number of random factors in these two models?
> > Finally, Models 1 and 1n compare lme and lmer on a model with a single random
> > slope, showing the differences in parameter estimates but not log-likelihood or
> > AIC.
> > I have attached the trial.txt and trial.r files again. I assume you will receive
> > them directly if you want to open them.
> > R output:
> >
> > > library(lme4)
> > > Loading required package: Matrix
> > > Warning message:
> > > package ?lme4? was built under R version 3.5.3
> > > library(nlme)
> >
> > Attaching package: ?nlme?
> > The following object is masked from ?package:lme4?:
> > lmList
> >
> > > Trial <- read.table(file="C:/PRL/R/RGFRRIBI/Trial.txt", header = TRUE)
> > > names(Trial)
> > > [1] "Response" "P" "A" "PR" "Group"
> > > str(Trial)
> > > 'data.frame': 74 obs. of 5 variables:
> > > $ Response: int 24 22 24 24 23 24 24 24 35 31 ...
> > > $ P : int 15 82 95 71 88 77 93 91 13 82 ...
> > > $ A : num 44.2 39.6 41.4 34.1 44.6 ...
> > > $ PR : num 121 115 250 200 252 ...
> > > $ Group : Factor w/ 26 levels "G1","G10","G11",..: 1 12 12 20 20 21 21 22 23 24
> > > ...
> > > Trial$normP <- as.double(scale(Trial$P))
> > > Trial$normA <- as.double(scale(Trial$A))
> > > Trial$normPR <- as.double(scale(Trial$PR))
> > > names(Trial)
> > > [1] "Response" "P" "A" "PR" "Group" "normP" "normA"
> > > "normPR"
> > > str(Trial)
> > > 'data.frame': 74 obs. of 8 variables:
> > > $ Response: int 24 22 24 24 23 24 24 24 35 31 ...
> > > $ P : int 15 82 95 71 88 77 93 91 13 82 ...
> > > $ A : num 44.2 39.6 41.4 34.1 44.6 ...
> > > $ PR : num 121 115 250 200 252 ...
> > > $ Group : Factor w/ 26 levels "G1","G10","G11",..: 1 12 12 20 20 21 21 22 23 24
> > > ...
> > > $ normP : num -1.783 0.719 1.205 0.308 0.943 ...
> > > $ normA : num 1.576 0.221 0.754 -1.38 1.708 ...
> > > $ normPR : num -1.415 -1.486 0.251 -0.385 0.281 ...
> >
> > > M5n <- lme(Response~normP+normA, random=~normP+normA|Group,data=Trial,
> > > method="ML")
> > > summary(M5n)
> > > Linear mixed-effects model fit by maximum likelihood
> > > Data: Trial
> > > AIC BIC logLik
> > > 536.4562 559.4969 -258.2281
> >
> > Random effects:
> > Formula: ~normP + normA | Group
> > Structure: General positive-definite, Log-Cholesky parametrization
> > StdDev Corr
> > (Intercept) 0.0002514711 (Intr) normP
> > normP 0.0002146005 0
> > normA 0.0001485695 0 0
> > Residual 7.9298211705
> > Fixed effects: Response ~ normP + normA
> > Value Std.Error DF t-value p-value
> > (Intercept) 29.081081 0.9410966 46 30.901270 0.0000
> > normP -0.784566 0.9620920 46 -0.815479 0.4190
> > normA 0.480397 0.9620920 46 0.499326 0.6199
> > Correlation:
> > (Intr) normP
> > normP 0.000
> > normA 0.000 -0.173
> > Standardized Within-Group Residuals:
> > Min Q1 Med Q3 Max
> > -1.8447131 -0.5563605 -0.2613520 0.2755547 5.5643551
> > Number of Observations: 74
> > Number of Groups: 26
> >
> > > M5 <- lmer(Response~normP+normA+(normP+normA|Group), REML="False", data=Trial)
> > > Error: number of observations (=74) <= number of random effects (=78) for term
> > > (normP + normA | Group); the random-effects parameters and the residual variance
> > > (or scale parameter) are probably unidentifiable
> >
> > > M2n <- lme(Response~P+A, random=~P+A|Group,data=Trial, method="ML")
> > > summary(M2n)
> > > Linear mixed-effects model fit by maximum likelihood
> > > Data: Trial
> > > AIC BIC logLik
> > > 536.4562 559.4969 -258.2281
> >
> > Random effects:
> > Formula: ~P + A | Group
> > Structure: General positive-definite, Log-Cholesky parametrization
> > StdDev Corr
> > (Intercept) 3.061144e-04 (Intr) P
> > P 1.535752e-09 0
> > A 8.517774e-13 0 0
> > Residual 7.929821e+00
> > Fixed effects: Response ~ P + A
> > Value Std.Error DF t-value p-value
> > (Intercept) 25.453398 10.828841 46 2.3505192 0.0231
> > P -0.029307 0.035939 46 -0.8154787 0.4190
> > A 0.140819 0.282018 46 0.4993255 0.6199
> > Correlation:
> > (Intr) P
> > P -0.033
> > A -0.975 -0.173
> > Standardized Within-Group Residuals:
> > Min Q1 Med Q3 Max
> > -1.8447131 -0.5563605 -0.2613520 0.2755547 5.5643551
> > Number of Observations: 74
> > Number of Groups: 26
> >
> > > M2 <- lmer(Response~P+A+(P+A|Group), REML="False", data=Trial)
> > > Error: number of observations (=74) <= number of random effects (=78) for term (P
> >
> > -   A | Group); the random-effects parameters and the residual variance (or scale
> >     parameter) are probably unidentifiable
> >
> >
> > > M6n <- lme(Response~A+PR, random=~A+PR|Group,data=Trial, method="ML")
> > > Error in logLik.lmeStructInt(lmeSt, lmePars) :
> > > NA/NaN/Inf in foreign function call (arg 3)
> > > In addition: There were 50 or more warnings (use warnings() to see the first 50)
> > > summary(M6n)
> > > Error in summary(M6n) : object 'M6n' not found
> >
> > > M7n <- lme(Response~normA+normPR, random=~normA+normPR|Group,data=Trial,
> > > method="ML")
> > > Error in lme.formula(Response ~ normA + normPR, random = ~normA + normPR | :
> > > nlminb problem, convergence error code = 1
> > > message = iteration limit reached without convergence (10)
> > > summary(M7n)
> > > Error in summary(M7n) : object 'M7n' not found
> >
> > > M4 <- lmer(Response~P+A+(P|Group)+(A|Group), REML="False", data=Trial)
> > > boundary (singular) fit: see ?isSingular
> > > summary(M4)
> > > Linear mixed model fit by maximum likelihood ['lmerMod']
> > > Formula: Response ~ P + A + (P | Group) + (A | Group)
> > > Data: Trial
> >
> >     AIC      BIC   logLik deviance df.resid
> >
> >
> > 536.5 559.5 -258.2 516.5 64
> > Scaled residuals:
> > Min 1Q Median 3Q Max
> > -1.8447 -0.5564 -0.2614 0.2756 5.5644
> > Random effects:
> > Groups Name Variance Std.Dev. Corr
> > Group (Intercept) 1.035e-06 1.017e-03
> > P 5.031e-09 7.093e-05 -1.00
> > Group.1 (Intercept) 5.262e-07 7.254e-04
> > A 1.941e-11 4.406e-06 -1.00
> > Residual 6.288e+01 7.930e+00
> > Number of obs: 74, groups: Group, 26
> > Fixed effects:
> > Estimate Std. Error t value
> > (Intercept) 25.45340 10.60707 2.400
> > P -0.02931 0.03520 -0.833
> > A 0.14082 0.27624 0.510
> > Correlation of Fixed Effects:
> > (Intr) P
> > P -0.033
> > A -0.975 -0.173
> > convergence code: 0
> > boundary (singular) fit: see ?isSingular
> >
> > > M3 <- lmer(Response~P+PR+(P+PR||Group), REML="False", data=Trial)
> > > boundary (singular) fit: see ?isSingular
> > > summary(M3)
> > > Linear mixed model fit by maximum likelihood ['lmerMod']
> > > Formula: Response ~ P + PR + ((1 | Group) + (0 + P | Group) + (0 + PR |
> > > Group))
> > > Data: Trial
> >
> >     AIC      BIC   logLik deviance df.resid
> >
> >
> > 530.5 546.7 -258.3 516.5 67
> > Scaled residuals:
> > Min 1Q Median 3Q Max
> > -1.8106 -0.5567 -0.2981 0.2984 5.0950
> > Random effects:
> > Groups Name Variance Std.Dev.
> > Group (Intercept) 5.422e-04 0.023285
> > Group.1 P 0.000e+00 0.000000
> > Group.2 PR 7.239e-05 0.008508
> > Residual 5.912e+01 7.688728
> > Number of obs: 74, groups: Group, 26
> > Fixed effects:
> > Estimate Std. Error t value
> > (Intercept) 29.265396 3.747575 7.809
> > P -0.023208 0.035100 -0.661
> > PR 0.006151 0.012288 0.501
> > Correlation of Fixed Effects:
> > (Intr) P
> > P -0.633
> > PR -0.754 0.043
> > convergence code: 0
> > boundary (singular) fit: see ?isSingular
> >
> > > M1 <- lmer(Response~P+A+(A|Group), REML="False", data=Trial)
> > > boundary (singular) fit: see ?isSingular
> > > summary(M1)
> > > Linear mixed model fit by maximum likelihood ['lmerMod']
> > > Formula: Response ~ P + A + (A | Group)
> > > Data: Trial
> >
> >     AIC      BIC   logLik deviance df.resid
> >
> >
> > 530.5 546.6 -258.2 516.5 67
> > Scaled residuals:
> > Min 1Q Median 3Q Max
> > -1.8447 -0.5564 -0.2614 0.2756 5.5644
> > Random effects:
> > Groups Name Variance Std.Dev. Corr
> > Group (Intercept) 0.000e+00 0.000e+00
> > A 1.657e-10 1.287e-05 NaN
> > Residual 6.288e+01 7.930e+00
> > Number of obs: 74, groups: Group, 26
> > Fixed effects:
> > Estimate Std. Error t value
> > (Intercept) 25.45340 10.60707 2.400
> > P -0.02931 0.03520 -0.833
> > A 0.14082 0.27624 0.510
> > Correlation of Fixed Effects:
> > (Intr) P
> > P -0.033
> > A -0.975 -0.173
> > convergence code: 0
> > boundary (singular) fit: see ?isSingular
> >
> > > M1n <- lme(Response~1+P+A, random=~1+A|Group,data=Trial, method="ML")
> > > summary(M1n)
> > > Linear mixed-effects model fit by maximum likelihood
> > > Data: Trial
> > > AIC BIC logLik
> > > 530.4562 546.5847 -258.2281
> >
> > Random effects:
> > Formula: ~1 + A | Group
> > Structure: General positive-definite, Log-Cholesky parametrization
> > StdDev Corr
> > (Intercept) 5.277473e-04 (Intr)
> > A 1.487869e-18 0
> > Residual 7.929821e+00
> > Fixed effects: Response ~ 1 + P + A
> > Value Std.Error DF t-value p-value
> > (Intercept) 25.453398 10.828841 46 2.3505192 0.0231
> > P -0.029307 0.035939 46 -0.8154787 0.4190
> > A 0.140819 0.282018 46 0.4993255 0.6199
> > Correlation:
> > (Intr) P
> > P -0.033
> > A -0.975 -0.173
> > Standardized Within-Group Residuals:
> > Min Q1 Med Q3 Max
> > -1.8447131 -0.5563605 -0.2613520 0.2755547 5.5643551
> > Number of Observations: 74
> > Number of Groups: 26
> > Peter


From wo||g@ng@v|echtb@uer @end|ng |rom m@@@tr|chtun|ver@|ty@n|  Thu Mar  4 11:45:33 2021
From: wo||g@ng@v|echtb@uer @end|ng |rom m@@@tr|chtun|ver@|ty@n| (Viechtbauer, Wolfgang (SP))
Date: Thu, 4 Mar 2021 10:45:33 +0000
Subject: [R-sig-ME] lmer code for multiple random slopes
In-Reply-To: <Ys_EWO7eMIPbh1nezv5C8Qd2cu51FF6MTNolLdBcuZcBgb8soEkJwTMl8QPDQKRCNqLEQQLJyqoVNkB2izRT13vOwKw_NIuBvK34uES4oJk=@protonmail.com>
References: <34JKCz24u8awawkhTLmboO_cBRWW-m0XAb0frTUb9YqspQe1VeBBWUvfqKd3-QIMLeKpiDUyzhN0X6aqRlEqwX1LmBfg3gn9EB2XCa5v62s=@protonmail.com>
 <1877a680-d190-7202-537d-90d51bc6574b@phillipalday.com>
 <de6401b0-6cac-65d8-cbc3-0f59ce79409d@gmail.com>
 <NCGF24lxdAy2bcOAoQsutEkYQ-ZIzb4e3xLenmSDhGyZN8a8sIcv-wHF0IEfLK8GQGccVE1hLTk-i1UPxFITTgLC9T929E6F4rQVMwVN8bg=@protonmail.com>
 <e2zoG5je3QHzcPl3dsttnLigMgzR8mqiUJAdgntQm9xPOX4j3SwlDytjMtbOFRj-vf5TjpHVRD7rzd54mvwMFm9OhW-ff4lfhR383lioPX4=@protonmail.com>
 <f286a096-f420-c246-61ad-542eaa5dad44@phillipalday.com>
 <CIYTFe7RNWpkAwUyuCM71pFEfhP-gPVj0OcD-UjLX0LbfzrRbySwMeVxASDMGs6D3aOxqydPUAg1NbZJar32LOtM42U-ZY-03eCCB7JbkUg=@protonmail.com>
 <e0894da27f994e64863768033e5c4989@UM-MAIL3214.unimaas.nl>
 <Ys_EWO7eMIPbh1nezv5C8Qd2cu51FF6MTNolLdBcuZcBgb8soEkJwTMl8QPDQKRCNqLEQQLJyqoVNkB2izRT13vOwKw_NIuBvK34uES4oJk=@protonmail.com>
Message-ID: <8bc0234f3e904300b84f7df721ef6534@UM-MAIL3214.unimaas.nl>

Hi Peter,

In:

response ~ x + (1|G2/G1) + (x|G2)?

the first () term adds random intercepts for each level of G2 and random intercepts for each level of G1 within G2. The second () term actually stands for (1+x|G2), so it again adds random intercepts for each level of G2, and random slopes for x for each level of G2 (and allows these random intercepts and slopes to be correlated). So, you are in essence adding random intercepts for G2 twice; probably not what you intended. Maybe you want:

response ~ x + (1|G2/G1) + (0+x|G2)?

but this implies that the random intercepts and slopes at the G2 level are uncorrelated. Or you could use:

response ~ x + (1|G1:G2) + (x|G2)?

which gives you correlated random intercepts and slopes for G2 and also adds random intercepts for the various G1-G2 level combinations (i.e., random intercepts for each level of G1 within G2).

Best,
Wolfgang

>-----Original Message-----
>From: Peter R Law [mailto:prldb at protonmail.com]
>Sent: Thursday, 04 March, 2021 0:08
>To: Viechtbauer, Wolfgang (SP); r-sig-mixed-models at r-project.org
>Subject: RE: [R-sig-ME] lmer code for multiple random slopes
>
>Many thanks Wolfgang! That does clear up my confusion. That interpretation of
>'random effects' didn't occur to me.
>
>Thanks also for pointing out that the differences in the estimates provided by lme
>and lmer occur because they handle singular models differently and won't occur for
>non-singular examples.
>
>When I have collected enough data, the model I am actually interested in will have
>two nested random factors, G1 within G2, and I only want random slopes (say for a
>covariate x) with respect to G2, but random intercepts for both factors. Am I
>right in thinking the code will take the form
>
>response ~ x + (1|G2/G1) + (x|G2)?
>
>Much appreciated,
>
>Peter
>
>Peter R Law
>Research Associate
>Center for African Conservation Ecology
>Nelson Mandela University
>South Africa
>
>??????? Original Message ???????
>On Wednesday, March 3, 2021 7:43 AM, Viechtbauer, Wolfgang (SP)
><wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:
>
>> Dear Peter, Dear All,
>>
>> The error doesn't say 78 variance components, it says 78 random effects. There
>are 26 groups in this dataset and you are estimating random intercepts and two
>sets of random slopes. Hence, there are 3*26 = 78 random effects that are in this
>model. But the dataset has only 74 rows. This is a check built into lmer() to
>avoid fitting overly complex models for a given dataset. You can disable this
>check with (also, use REML=FALSE, not "False"):
>>
>> M2 <- lmer(Response ~ P + A + (P + A | Group), REML=FALSE, data=Trial,
>control=lmerControl(check.nobs.vs.nRE="ignore"))
>>
>> Then it will run and this is the same model as fitted with:
>>
>> M2n <- lme( Response ~ P + A, random = ~ P + A | Group, data=Trial, method="ML")
>>
>> The results differ somewhat though, because both packages handle such ill-
>defined problems in different ways.
>>
>> Best,
>> Wolfgang

From k@m@|@@tmeh @end|ng |rom hotm@||@com  Thu Mar  4 16:26:15 2021
From: k@m@|@@tmeh @end|ng |rom hotm@||@com (Kamal Atmeh)
Date: Thu, 4 Mar 2021 16:26:15 +0100
Subject: [R-sig-ME] MCMCglmm interaction and posterior mode
In-Reply-To: <CAJtCY7V92MjygOPt6L1Et8i=jYOkor3dmhWcc1H+K5qEgq-=Vw@mail.gmail.com>
References: <PA4P189MB13438F732ADBB30695245606FE989@PA4P189MB1343.EURP189.PROD.OUTLOOK.COM>
 <CAJtCY7V92MjygOPt6L1Et8i=jYOkor3dmhWcc1H+K5qEgq-=Vw@mail.gmail.com>
Message-ID: <DBBP189MB1340AF00DE87BA59C8D41DAEFE979@DBBP189MB1340.EURP189.PROD.OUTLOOK.COM>

Hello Walid,

Thank you for your prompt response!

The at.level() function works perfectly and does exactly what I want. I 
have also modified the other 2-way interactions to only include the 
level of interest (H).

As for the broom package, even broom. mixed, it seems that it mostly 
gives a tidy version of the model's output. I haven't found a function 
that does the automatic computation though, but I will look more thoroughly.

Thanks again!

Cheers,

Kamal

Le 03/03/2021 ? 23:17, Walid Crampton-Mawass a ?crit?:
> Hello Kamal,
>
> One way to do this with MCMCglmm is to use the at.level() function. 
> You can determine for which level of your categorical variable you 
> want the interaction, ex. at.level(tactic,2):a.level(period,2):env.
>
> However, in doing so you are only estimating the coefficient for that 
> specific interaction and ignoring the rest. That to me would seem a 
> bit odd given that for the 2-way interactions you are still including 
> the other levels, but of course it depends on what assumptions?you are 
> making for your?model.
>
> and regarding automating the computation of the posterior mean, I 
> think (not sure though) that the broom package offers some wrap 
> functions for MCMCglmm and computing posterior estimates.
>
> Good luck
> -- 
> Walid Crampton-Mawass
> Ph.D. candidate in Evolutionary Biology
> Population Genetics Laboratory
> University of Qu?bec at Trois-Rivi?res
> 3351, boul. des Forges, C.P. 500
> Trois-Rivi?res (Qu?bec) G9A 5H7
> Telephone: 819-376-5011 poste 3384
>
>
> On Wed, Mar 3, 2021 at 4:19 PM Kamal Atmeh <kamal.atmeh at hotmail.com 
> <mailto:kamal.atmeh at hotmail.com>> wrote:
>
>     Dear all,
>
>     I have some questions, which may sound trivial, pertaining to
>     interaction models with MCMCglmm.
>
>     I am running the following model with a gaussian distribution and a
>     3-way interaction between two categorical two-level variables
>     (tactic:
>     F/H and period PB/B) and one continuous variable (env):
>
>     model <- MCMCglmm(lD ~ tactic*period*env
>     ????????????????????????????????????? , random =
>     ~sp_phylo+species2+phylo_pop+phylo_popY+phylo_pop_id
>     ????????????????????????????????????? , family = "gaussian"
>     ????????????????????????????????????? , ginverse = list(sp_phylo =
>     inv.phylo$Ainv) # include a custom matrix for argument phylo
>     ????????????????????????????????????? , prior = prior1
>     ????????????????????????????????????? , data = Data
>     ????????????????????????????????????? , nitt = 22e+04
>     ????????????????????????????????????? , burnin = 20000
>     ????????????????????????????????????? , thin = 100
>     ????????????????????????????????????? , pr=TRUE)
>
>     After looking at the results, I found that the 2-way interaction
>     tactic*env from the tactic*period*env interaction was not
>     significant,
>     however the 3-way interaction itself was, with the following
>     output in
>     the summary:
>
>     ?>>>?? tacticH:periodB:env????? 0.17831? 0.05360 0.30512???? 5000
>     0.0052 ** (the intercept represents tactic F and period PB)
>
>     I tried to run the model again in order to simplify it using ":" and
>     therefore remove the non-significant 2-way interaction:
>
>     model2 <- MCMCglmm(lD ~ tactic*period + period*env +
>     *tactic:period:env*
>     ????????????????????????????????????? , random =
>     ~sp_phylo+species2+phylo_pop+phylo_popY+phylo_pop_id
>     ????????????????????????????????????? , family = "gaussian"
>     ????????????????????????????????????? , ginverse = list(sp_phylo =
>     inv.phylo$Ainv) # include a custom matrix for argument phylo
>     ????????????????????????????????????? , prior = prior1
>     ????????????????????????????????????? , data = Data
>     ????????????????????????????????????? , nitt = 22e+04
>     ????????????????????????????????????? , burnin = 20000
>     ????????????????????????????????????? , thin = 100
>     ????????????????????????????????????? , pr=TRUE)
>
>     When using ":", the output of my model returns the posterior mean for
>     each level of the categorical variables instead of one level as
>     before:
>
>     tacticF:periodPB:env -0.1668620 -0.3554264? 0.0005143??? 195.0
>     0.0923 .
>     tacticF:periodB:env? -0.2018706 -0.3783204 -0.0174366??? 195.0
>     0.0410 *
>     tacticH:periodPB:env -0.1561097 -0.2066183 -0.1093840??? 118.2
>     <0.005 **
>
>     How should I define the interaction in the model in order to
>     obtain an
>     output similar to the one when the "*" interaction was used
>     (tacticH:periodB:env) while simplifying and removing the
>     non-significant
>     interaction from the 3-way interaction?
>
>     Finally, is there a way to automatically compute the posterior
>     mean of
>     the continuous variable for each modality of the interaction?
>
>     Thank you and stay safe!
>
>     Kamal
>
>
>     ? ? ? ? [[alternative HTML version deleted]]
>
>     _______________________________________________
>     R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>     https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models>
>

	[[alternative HTML version deleted]]


From w@||dm@w@@@10 @end|ng |rom gm@||@com  Thu Mar  4 16:33:29 2021
From: w@||dm@w@@@10 @end|ng |rom gm@||@com (Walid Crampton-Mawass)
Date: Thu, 4 Mar 2021 10:33:29 -0500
Subject: [R-sig-ME] MCMCglmm interaction and posterior mode
In-Reply-To: <DBBP189MB1340AF00DE87BA59C8D41DAEFE979@DBBP189MB1340.EURP189.PROD.OUTLOOK.COM>
References: <PA4P189MB13438F732ADBB30695245606FE989@PA4P189MB1343.EURP189.PROD.OUTLOOK.COM>
 <CAJtCY7V92MjygOPt6L1Et8i=jYOkor3dmhWcc1H+K5qEgq-=Vw@mail.gmail.com>
 <DBBP189MB1340AF00DE87BA59C8D41DAEFE979@DBBP189MB1340.EURP189.PROD.OUTLOOK.COM>
Message-ID: <CAJtCY7UihRbFYQQtD2m=syTAFwgKs1pNEF0E-XsHks4mf_i3_Q@mail.gmail.com>

Another option would be the QGglmm package by Pierre de Villemereuil
(2016), it has multiple functions to extract estimates but I wouldn't say
it is automatic as much as it is faster computationally to compute
estimates.

Good luck
-- 
Walid Crampton-Mawass
Ph.D. candidate in Evolutionary Biology
Population Genetics Laboratory
University of Qu?bec at Trois-Rivi?res
3351, boul. des Forges, C.P. 500
Trois-Rivi?res (Qu?bec) G9A 5H7
Telephone: 819-376-5011 poste 3384


On Thu, Mar 4, 2021 at 10:26 AM Kamal Atmeh <kamal.atmeh at hotmail.com> wrote:

> Hello Walid,
>
> Thank you for your prompt response!
>
> The at.level() function works perfectly and does exactly what I want. I
> have also modified the other 2-way interactions to only include the level
> of interest (H).
>
> As for the broom package, even broom. mixed, it seems that it mostly gives
> a tidy version of the model's output. I haven't found a function that does
> the automatic computation though, but I will look more thoroughly.
>
> Thanks again!
>
> Cheers,
>
> Kamal
> Le 03/03/2021 ? 23:17, Walid Crampton-Mawass a ?crit :
>
> Hello Kamal,
>
> One way to do this with MCMCglmm is to use the at.level() function. You
> can determine for which level of your categorical variable you want the
> interaction, ex. at.level(tactic,2):a.level(period,2):env.
>
> However, in doing so you are only estimating the coefficient for that
> specific interaction and ignoring the rest. That to me would seem a bit odd
> given that for the 2-way interactions you are still including the other
> levels, but of course it depends on what assumptions you are making for
> your model.
>
> and regarding automating the computation of the posterior mean, I think
> (not sure though) that the broom package offers some wrap functions for
> MCMCglmm and computing posterior estimates.
>
> Good luck
> --
> Walid Crampton-Mawass
> Ph.D. candidate in Evolutionary Biology
> Population Genetics Laboratory
> University of Qu?bec at Trois-Rivi?res
> 3351, boul. des Forges, C.P. 500
> Trois-Rivi?res (Qu?bec) G9A 5H7
> Telephone: 819-376-5011 poste 3384
>
>
> On Wed, Mar 3, 2021 at 4:19 PM Kamal Atmeh <kamal.atmeh at hotmail.com>
> wrote:
>
>> Dear all,
>>
>> I have some questions, which may sound trivial, pertaining to
>> interaction models with MCMCglmm.
>>
>> I am running the following model with a gaussian distribution and a
>> 3-way interaction between two categorical two-level variables (tactic:
>> F/H and period PB/B) and one continuous variable (env):
>>
>> model <- MCMCglmm(lD ~ tactic*period*env
>>                                       , random =
>> ~sp_phylo+species2+phylo_pop+phylo_popY+phylo_pop_id
>>                                       , family = "gaussian"
>>                                       , ginverse = list(sp_phylo =
>> inv.phylo$Ainv) # include a custom matrix for argument phylo
>>                                       , prior = prior1
>>                                       , data = Data
>>                                       , nitt = 22e+04
>>                                       , burnin = 20000
>>                                       , thin = 100
>>                                       , pr=TRUE)
>>
>> After looking at the results, I found that the 2-way interaction
>> tactic*env from the tactic*period*env interaction was not significant,
>> however the 3-way interaction itself was, with the following output in
>> the summary:
>>
>>  >>>   tacticH:periodB:env      0.17831  0.05360 0.30512     5000
>> 0.0052 ** (the intercept represents tactic F and period PB)
>>
>> I tried to run the model again in order to simplify it using ":" and
>> therefore remove the non-significant 2-way interaction:
>>
>> model2 <- MCMCglmm(lD ~ tactic*period + period*env + *tactic:period:env*
>>                                       , random =
>> ~sp_phylo+species2+phylo_pop+phylo_popY+phylo_pop_id
>>                                       , family = "gaussian"
>>                                       , ginverse = list(sp_phylo =
>> inv.phylo$Ainv) # include a custom matrix for argument phylo
>>                                       , prior = prior1
>>                                       , data = Data
>>                                       , nitt = 22e+04
>>                                       , burnin = 20000
>>                                       , thin = 100
>>                                       , pr=TRUE)
>>
>> When using ":", the output of my model returns the posterior mean for
>> each level of the categorical variables instead of one level as before:
>>
>> tacticF:periodPB:env -0.1668620 -0.3554264  0.0005143    195.0 0.0923 .
>> tacticF:periodB:env  -0.2018706 -0.3783204 -0.0174366    195.0 0.0410 *
>> tacticH:periodPB:env -0.1561097 -0.2066183 -0.1093840    118.2 <0.005 **
>>
>> How should I define the interaction in the model in order to obtain an
>> output similar to the one when the "*" interaction was used
>> (tacticH:periodB:env) while simplifying and removing the non-significant
>> interaction from the 3-way interaction?
>>
>> Finally, is there a way to automatically compute the posterior mean of
>> the continuous variable for each modality of the interaction?
>>
>> Thank you and stay safe!
>>
>> Kamal
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>

	[[alternative HTML version deleted]]


From pr|db @end|ng |rom protonm@||@com  Fri Mar  5 03:13:12 2021
From: pr|db @end|ng |rom protonm@||@com (Peter R Law)
Date: Fri, 05 Mar 2021 02:13:12 +0000
Subject: [R-sig-ME] lmer code for multiple random slopes
In-Reply-To: <8bc0234f3e904300b84f7df721ef6534@UM-MAIL3214.unimaas.nl>
References: <34JKCz24u8awawkhTLmboO_cBRWW-m0XAb0frTUb9YqspQe1VeBBWUvfqKd3-QIMLeKpiDUyzhN0X6aqRlEqwX1LmBfg3gn9EB2XCa5v62s=@protonmail.com>
 <1877a680-d190-7202-537d-90d51bc6574b@phillipalday.com>
 <de6401b0-6cac-65d8-cbc3-0f59ce79409d@gmail.com>
 <NCGF24lxdAy2bcOAoQsutEkYQ-ZIzb4e3xLenmSDhGyZN8a8sIcv-wHF0IEfLK8GQGccVE1hLTk-i1UPxFITTgLC9T929E6F4rQVMwVN8bg=@protonmail.com>
 <e2zoG5je3QHzcPl3dsttnLigMgzR8mqiUJAdgntQm9xPOX4j3SwlDytjMtbOFRj-vf5TjpHVRD7rzd54mvwMFm9OhW-ff4lfhR383lioPX4=@protonmail.com>
 <f286a096-f420-c246-61ad-542eaa5dad44@phillipalday.com>
 <CIYTFe7RNWpkAwUyuCM71pFEfhP-gPVj0OcD-UjLX0LbfzrRbySwMeVxASDMGs6D3aOxqydPUAg1NbZJar32LOtM42U-ZY-03eCCB7JbkUg=@protonmail.com>
 <e0894da27f994e64863768033e5c4989@UM-MAIL3214.unimaas.nl>
 <Ys_EWO7eMIPbh1nezv5C8Qd2cu51FF6MTNolLdBcuZcBgb8soEkJwTMl8QPDQKRCNqLEQQLJyqoVNkB2izRT13vOwKw_NIuBvK34uES4oJk=@protonmail.com>
 <8bc0234f3e904300b84f7df721ef6534@UM-MAIL3214.unimaas.nl>
Message-ID: <uE3jE1zXUjFp71_IDL14arC1sYdRmI86rrWgzVNBWIQd19Q42xVlC09lLsxR38Z7vGWSNAAdqtui3zs9Y24knhKn77WJlLJkwedvV2jGdlQ=@protonmail.com>

Many thanks Wolfgang.


Peter

Sent with ProtonMail Secure Email.

??????? Original Message ???????
On Thursday, March 4, 2021 5:45 AM, Viechtbauer, Wolfgang (SP) <wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:

> Hi Peter,
>
> In:
>
> response ~ x + (1|G2/G1) + (x|G2)?
>
> the first () term adds random intercepts for each level of G2 and random intercepts for each level of G1 within G2. The second () term actually stands for (1+x|G2), so it again adds random intercepts for each level of G2, and random slopes for x for each level of G2 (and allows these random intercepts and slopes to be correlated). So, you are in essence adding random intercepts for G2 twice; probably not what you intended. Maybe you want:
>
> response ~ x + (1|G2/G1) + (0+x|G2)?
>
> but this implies that the random intercepts and slopes at the G2 level are uncorrelated. Or you could use:
>
> response ~ x + (1|G1:G2) + (x|G2)?
>
> which gives you correlated random intercepts and slopes for G2 and also adds random intercepts for the various G1-G2 level combinations (i.e., random intercepts for each level of G1 within G2).
>
> Best,
> Wolfgang
>
> > -----Original Message-----
> > From: Peter R Law [mailto:prldb at protonmail.com]
> > Sent: Thursday, 04 March, 2021 0:08
> > To: Viechtbauer, Wolfgang (SP); r-sig-mixed-models at r-project.org
> > Subject: RE: [R-sig-ME] lmer code for multiple random slopes
> > Many thanks Wolfgang! That does clear up my confusion. That interpretation of
> > 'random effects' didn't occur to me.
> > Thanks also for pointing out that the differences in the estimates provided by lme
> > and lmer occur because they handle singular models differently and won't occur for
> > non-singular examples.
> > When I have collected enough data, the model I am actually interested in will have
> > two nested random factors, G1 within G2, and I only want random slopes (say for a
> > covariate x) with respect to G2, but random intercepts for both factors. Am I
> > right in thinking the code will take the form
> > response ~ x + (1|G2/G1) + (x|G2)?
> > Much appreciated,
> > Peter
> > Peter R Law
> > Research Associate
> > Center for African Conservation Ecology
> > Nelson Mandela University
> > South Africa
> > ??????? Original Message ???????
> > On Wednesday, March 3, 2021 7:43 AM, Viechtbauer, Wolfgang (SP)
> > wolfgang.viechtbauer at maastrichtuniversity.nl wrote:
> >
> > > Dear Peter, Dear All,
> > > The error doesn't say 78 variance components, it says 78 random effects. There
> > > are 26 groups in this dataset and you are estimating random intercepts and two
> > > sets of random slopes. Hence, there are 3*26 = 78 random effects that are in this
> > > model. But the dataset has only 74 rows. This is a check built into lmer() to
> > > avoid fitting overly complex models for a given dataset. You can disable this
> > > check with (also, use REML=FALSE, not "False"):
> > > M2 <- lmer(Response ~ P + A + (P + A | Group), REML=FALSE, data=Trial,
> > > control=lmerControl(check.nobs.vs.nRE="ignore"))
> > > Then it will run and this is the same model as fitted with:
> > > M2n <- lme( Response ~ P + A, random = ~ P + A | Group, data=Trial, method="ML")
> > > The results differ somewhat though, because both packages handle such ill-
> > > defined problems in different ways.
> > > Best,
> > > Wolfgang


From hedyeh@h @end|ng |rom u@c@edu  Fri Mar  5 21:27:04 2021
From: hedyeh@h @end|ng |rom u@c@edu (Hedyeh Ahmadi)
Date: Fri, 5 Mar 2021 20:27:04 +0000
Subject: [R-sig-ME] A three-level GLMM with binomial link in R
Message-ID: <BYAPR07MB50945A60AFDE467F317861ACD1969@BYAPR07MB5094.namprd07.prod.outlook.com>

Hi All,
I was wondering what would be a powerful package in R to run GLMM with logit link that can handle a data set with N=22945 and 3 nested random intercepts. So far, I have tried glmer() from lme4 and it's giving me a lot of estimation issues. Any other package I should try?

I am asking for another package as I am having the same issue with lmer() for similar LMM with continuous outcome, while lme() from nlme package runs the models with no problem.

Thank you in advance.

Best,

Hedyeh Ahmadi, Ph.D.
Statistician
Keck School of Medicine
Department of Preventive Medicine
University of Southern California

Postdoctoral Scholar
Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
University of California, Irvine

LinkedIn
www.linkedin.com/in/hedyeh-ahmadi<http://www.linkedin.com/in/hedyeh-ahmadi>
<http://www.linkedin.com/in/hedyeh-ahmadi><http://www.linkedin.com/in/hedyeh-ahmadi>





	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Fri Mar  5 22:01:39 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Fri, 5 Mar 2021 16:01:39 -0500
Subject: [R-sig-ME] A three-level GLMM with binomial link in R
In-Reply-To: <BYAPR07MB50945A60AFDE467F317861ACD1969@BYAPR07MB5094.namprd07.prod.outlook.com>
References: <BYAPR07MB50945A60AFDE467F317861ACD1969@BYAPR07MB5094.namprd07.prod.outlook.com>
Message-ID: <53f1986f-0898-e327-ba72-d6e69366b5c1@gmail.com>

    What kind of estimation issues?  As far as just data set size is 
concerned, I would consider this a "medium-to-large" problem for glmer, 
but not something I would expect to cause problems.

  * MASS::glmmPQL is built on top of lme(), so might work well for you
  * glmmTMB provides a more-or-less drop-in replacement for glmer you 
could try
  * GLMMadaptive::mixed_model is another possibility
  * if you really need speed, Doug Bates's MixedModels.jl in Julia 
usually beats everything else listed here

   But ... we could probably give much better advice if you say 
something about the specific kinds of "estimation issues" you're having.

   cheers
    Ben Bolker

On 3/5/21 3:27 PM, Hedyeh Ahmadi wrote:
> Hi All,
> I was wondering what would be a powerful package in R to run GLMM with logit link that can handle a data set with N=22945 and 3 nested random intercepts. So far, I have tried glmer() from lme4 and it's giving me a lot of estimation issues. Any other package I should try?
> 
> I am asking for another package as I am having the same issue with lmer() for similar LMM with continuous outcome, while lme() from nlme package runs the models with no problem.
> 
> Thank you in advance.
> 
> Best,
> 
> Hedyeh Ahmadi, Ph.D.
> Statistician
> Keck School of Medicine
> Department of Preventive Medicine
> University of Southern California
> 
> Postdoctoral Scholar
> Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
> University of California, Irvine
> 
> LinkedIn
> www.linkedin.com/in/hedyeh-ahmadi<http://www.linkedin.com/in/hedyeh-ahmadi>
> <http://www.linkedin.com/in/hedyeh-ahmadi><http://www.linkedin.com/in/hedyeh-ahmadi>
> 
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From dexter@|ocke @end|ng |rom gm@||@com  Fri Mar  5 22:01:42 2021
From: dexter@|ocke @end|ng |rom gm@||@com (Dexter Locke)
Date: Fri, 5 Mar 2021 16:01:42 -0500
Subject: [R-sig-ME] A three-level GLMM with binomial link in R
In-Reply-To: <BYAPR07MB50945A60AFDE467F317861ACD1969@BYAPR07MB5094.namprd07.prod.outlook.com>
References: <BYAPR07MB50945A60AFDE467F317861ACD1969@BYAPR07MB5094.namprd07.prod.outlook.com>
Message-ID: <CAA=SVwH2pE+EAtEqALjeRPT91tWz-HJegrQkz9mYqfj7pb_A1Q@mail.gmail.com>

Hi Hedyeh,

What is the problem you are having? Specifically, what is the estimation
issue with lmer and lme?

Can you provide a reproducible example? Can you provide the complete errors
you are seeing?

The current questions are vague, so it will be challenging for list members
to provide much guidance.

-Dexter


On Fri, Mar 5, 2021 at 3:27 PM Hedyeh Ahmadi <hedyehah at usc.edu> wrote:

> Hi All,
> I was wondering what would be a powerful package in R to run GLMM with
> logit link that can handle a data set with N=22945 and 3 nested random
> intercepts. So far, I have tried glmer() from lme4 and it's giving me a lot
> of estimation issues. Any other package I should try?
>
> I am asking for another package as I am having the same issue with lmer()
> for similar LMM with continuous outcome, while lme() from nlme package runs
> the models with no problem.
>
> Thank you in advance.
>
> Best,
>
> Hedyeh Ahmadi, Ph.D.
> Statistician
> Keck School of Medicine
> Department of Preventive Medicine
> University of Southern California
>
> Postdoctoral Scholar
> Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
> University of California, Irvine
>
> LinkedIn
> www.linkedin.com/in/hedyeh-ahmadi<http://www.linkedin.com/in/hedyeh-ahmadi
> >
> <http://www.linkedin.com/in/hedyeh-ahmadi><
> http://www.linkedin.com/in/hedyeh-ahmadi>
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From hedyeh@h @end|ng |rom u@c@edu  Fri Mar  5 22:18:12 2021
From: hedyeh@h @end|ng |rom u@c@edu (Hedyeh Ahmadi)
Date: Fri, 5 Mar 2021 21:18:12 +0000
Subject: [R-sig-ME] A three-level GLMM with binomial link in R
In-Reply-To: <CAA=SVwH2pE+EAtEqALjeRPT91tWz-HJegrQkz9mYqfj7pb_A1Q@mail.gmail.com>
References: <BYAPR07MB50945A60AFDE467F317861ACD1969@BYAPR07MB5094.namprd07.prod.outlook.com>,
 <CAA=SVwH2pE+EAtEqALjeRPT91tWz-HJegrQkz9mYqfj7pb_A1Q@mail.gmail.com>
Message-ID: <BYAPR07MB50947CD020DADA71CFF86407D1969@BYAPR07MB5094.namprd07.prod.outlook.com>

Hi - Thank you for the informative replies.

I will try those other packages. If MASS::glmmPQL uses lme() then this should work for me.

My data structure is complex so it's hard to give reproducible example but for example for two of my models I get the following errors in lmer() while lme() runs smoothly.

1- Error: cannot allocate vector of size 2.3 Gb.

2- Error: couldn't evaluate grouping factor id:(family:site) within model frame: try adding grouping factor to data frame explicitly if possible. (note that the id variable works for simpler lmer() models so the variable itself is not an issue)

My model looks like the following nested structure:
lmer(Y ~ 1 + X1 + X2 + X3 + (1|site/family/id), data=dd, REML = FALSE)

Best,

Hedyeh Ahmadi, Ph.D.
Statistician
Keck School of Medicine
Department of Preventive Medicine
University of Southern California

Postdoctoral Scholar
Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
University of California, Irvine

LinkedIn
www.linkedin.com/in/hedyeh-ahmadi<http://www.linkedin.com/in/hedyeh-ahmadi>
<http://www.linkedin.com/in/hedyeh-ahmadi><http://www.linkedin.com/in/hedyeh-ahmadi>




________________________________
From: Dexter Locke <dexter.locke at gmail.com>
Sent: Friday, March 5, 2021 1:01 PM
To: Hedyeh Ahmadi <hedyehah at usc.edu>
Cc: r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>; Megan M. Herting <herting at usc.edu>; Elisabeth Burnor <burnor at usc.edu>
Subject: Re: [R-sig-ME] A three-level GLMM with binomial link in R

Hi Hedyeh,

What is the problem you are having? Specifically, what is the estimation issue with lmer and lme?

Can you provide a reproducible example? Can you provide the complete errors you are seeing?

The current questions are vague, so it will be challenging for list members to provide much guidance.

-Dexter


On Fri, Mar 5, 2021 at 3:27 PM Hedyeh Ahmadi <hedyehah at usc.edu<mailto:hedyehah at usc.edu>> wrote:
Hi All,
I was wondering what would be a powerful package in R to run GLMM with logit link that can handle a data set with N=22945 and 3 nested random intercepts. So far, I have tried glmer() from lme4 and it's giving me a lot of estimation issues. Any other package I should try?

I am asking for another package as I am having the same issue with lmer() for similar LMM with continuous outcome, while lme() from nlme package runs the models with no problem.

Thank you in advance.

Best,

Hedyeh Ahmadi, Ph.D.
Statistician
Keck School of Medicine
Department of Preventive Medicine
University of Southern California

Postdoctoral Scholar
Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
University of California, Irvine

LinkedIn
www.linkedin.com/in/hedyeh-ahmadi<https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$><http://www.linkedin.com/in/hedyeh-ahmadi<https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$>>
<http://www.linkedin.com/in/hedyeh-ahmadi<https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$>><http://www.linkedin.com/in/hedyeh-ahmadi<https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$>>





        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models<https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQM6wKtNs$>

	[[alternative HTML version deleted]]


From |ongrob604 @end|ng |rom gm@||@com  Fri Mar  5 22:43:57 2021
From: |ongrob604 @end|ng |rom gm@||@com (Robert Long)
Date: Fri, 5 Mar 2021 21:43:57 +0000
Subject: [R-sig-ME] A three-level GLMM with binomial link in R
In-Reply-To: <BYAPR07MB50947CD020DADA71CFF86407D1969@BYAPR07MB5094.namprd07.prod.outlook.com>
References: <BYAPR07MB50945A60AFDE467F317861ACD1969@BYAPR07MB5094.namprd07.prod.outlook.com>
 <CAA=SVwH2pE+EAtEqALjeRPT91tWz-HJegrQkz9mYqfj7pb_A1Q@mail.gmail.com>
 <BYAPR07MB50947CD020DADA71CFF86407D1969@BYAPR07MB5094.namprd07.prod.outlook.com>
Message-ID: <CA+3TTkNL+JGE+pgfOqASfvJ+r5eHmbGt3v+FzazouVePs_=x9Q@mail.gmail.com>

You've run out of memory. Try running it on a machine with much larger RAM.

On Fri, 5 Mar 2021, 21:18 Hedyeh Ahmadi, <hedyehah at usc.edu> wrote:

> Hi - Thank you for the informative replies.
>
> I will try those other packages. If MASS::glmmPQL uses lme() then this
> should work for me.
>
> My data structure is complex so it's hard to give reproducible example but
> for example for two of my models I get the following errors in lmer() while
> lme() runs smoothly.
>
> 1- Error: cannot allocate vector of size 2.3 Gb.
>
> 2- Error: couldn't evaluate grouping factor id:(family:site) within model
> frame: try adding grouping factor to data frame explicitly if possible.
> (note that the id variable works for simpler lmer() models so the variable
> itself is not an issue)
>
> My model looks like the following nested structure:
> lmer(Y ~ 1 + X1 + X2 + X3 + (1|site/family/id), data=dd, REML = FALSE)
>
> Best,
>
> Hedyeh Ahmadi, Ph.D.
> Statistician
> Keck School of Medicine
> Department of Preventive Medicine
> University of Southern California
>
> Postdoctoral Scholar
> Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
> University of California, Irvine
>
> LinkedIn
> www.linkedin.com/in/hedyeh-ahmadi<http://www.linkedin.com/in/hedyeh-ahmadi
> >
> <http://www.linkedin.com/in/hedyeh-ahmadi><
> http://www.linkedin.com/in/hedyeh-ahmadi>
>
>
>
>
> ________________________________
> From: Dexter Locke <dexter.locke at gmail.com>
> Sent: Friday, March 5, 2021 1:01 PM
> To: Hedyeh Ahmadi <hedyehah at usc.edu>
> Cc: r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>;
> Megan M. Herting <herting at usc.edu>; Elisabeth Burnor <burnor at usc.edu>
> Subject: Re: [R-sig-ME] A three-level GLMM with binomial link in R
>
> Hi Hedyeh,
>
> What is the problem you are having? Specifically, what is the estimation
> issue with lmer and lme?
>
> Can you provide a reproducible example? Can you provide the complete
> errors you are seeing?
>
> The current questions are vague, so it will be challenging for list
> members to provide much guidance.
>
> -Dexter
>
>
> On Fri, Mar 5, 2021 at 3:27 PM Hedyeh Ahmadi <hedyehah at usc.edu<mailto:
> hedyehah at usc.edu>> wrote:
> Hi All,
> I was wondering what would be a powerful package in R to run GLMM with
> logit link that can handle a data set with N=22945 and 3 nested random
> intercepts. So far, I have tried glmer() from lme4 and it's giving me a lot
> of estimation issues. Any other package I should try?
>
> I am asking for another package as I am having the same issue with lmer()
> for similar LMM with continuous outcome, while lme() from nlme package runs
> the models with no problem.
>
> Thank you in advance.
>
> Best,
>
> Hedyeh Ahmadi, Ph.D.
> Statistician
> Keck School of Medicine
> Department of Preventive Medicine
> University of Southern California
>
> Postdoctoral Scholar
> Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
> University of California, Irvine
>
> LinkedIn
> www.linkedin.com/in/hedyeh-ahmadi<
> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$
> ><http://www.linkedin.com/in/hedyeh-ahmadi<
> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$
> >>
> <http://www.linkedin.com/in/hedyeh-ahmadi<
> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$
> >><http://www.linkedin.com/in/hedyeh-ahmadi<
> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$
> >>
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org>
> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models<
> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQM6wKtNs$
> >
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From hedyeh@h @end|ng |rom u@c@edu  Fri Mar  5 22:47:43 2021
From: hedyeh@h @end|ng |rom u@c@edu (Hedyeh Ahmadi)
Date: Fri, 5 Mar 2021 21:47:43 +0000
Subject: [R-sig-ME] A three-level GLMM with binomial link in R
In-Reply-To: <CA+3TTkNL+JGE+pgfOqASfvJ+r5eHmbGt3v+FzazouVePs_=x9Q@mail.gmail.com>
References: <BYAPR07MB50945A60AFDE467F317861ACD1969@BYAPR07MB5094.namprd07.prod.outlook.com>
 <CAA=SVwH2pE+EAtEqALjeRPT91tWz-HJegrQkz9mYqfj7pb_A1Q@mail.gmail.com>
 <BYAPR07MB50947CD020DADA71CFF86407D1969@BYAPR07MB5094.namprd07.prod.outlook.com>,
 <CA+3TTkNL+JGE+pgfOqASfvJ+r5eHmbGt3v+FzazouVePs_=x9Q@mail.gmail.com>
Message-ID: <BYAPR07MB509450F1132EEB7C41F60B4CD1969@BYAPR07MB5094.namprd07.prod.outlook.com>

Thank you for the reply Robert - If I am running out of memory in lmer(), do you know why lme() runs just fine?

Best,

Hedyeh Ahmadi, Ph.D.
Statistician
Keck School of Medicine
Department of Preventive Medicine
University of Southern California

Postdoctoral Scholar
Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
University of California, Irvine

LinkedIn
www.linkedin.com/in/hedyeh-ahmadi<http://www.linkedin.com/in/hedyeh-ahmadi>
<http://www.linkedin.com/in/hedyeh-ahmadi><http://www.linkedin.com/in/hedyeh-ahmadi>




________________________________
From: Robert Long <longrob604 at gmail.com>
Sent: Friday, March 5, 2021 1:43 PM
To: Hedyeh Ahmadi <hedyehah at usc.edu>
Cc: Dexter Locke <dexter.locke at gmail.com>; R-mixed models mailing list <r-sig-mixed-models at r-project.org>; Megan M. Herting <herting at usc.edu>; Elisabeth Burnor <burnor at usc.edu>
Subject: Re: [R-sig-ME] A three-level GLMM with binomial link in R

You've run out of memory. Try running it on a machine with much larger RAM.

On Fri, 5 Mar 2021, 21:18 Hedyeh Ahmadi, <hedyehah at usc.edu<mailto:hedyehah at usc.edu>> wrote:
Hi - Thank you for the informative replies.

I will try those other packages. If MASS::glmmPQL uses lme() then this should work for me.

My data structure is complex so it's hard to give reproducible example but for example for two of my models I get the following errors in lmer() while lme() runs smoothly.

1- Error: cannot allocate vector of size 2.3 Gb.

2- Error: couldn't evaluate grouping factor id:(family:site) within model frame: try adding grouping factor to data frame explicitly if possible. (note that the id variable works for simpler lmer() models so the variable itself is not an issue)

My model looks like the following nested structure:
lmer(Y ~ 1 + X1 + X2 + X3 + (1|site/family/id), data=dd, REML = FALSE)

Best,

Hedyeh Ahmadi, Ph.D.
Statistician
Keck School of Medicine
Department of Preventive Medicine
University of Southern California

Postdoctoral Scholar
Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
University of California, Irvine

LinkedIn
www.linkedin.com/in/hedyeh-ahmadi<https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$><http://www.linkedin.com/in/hedyeh-ahmadi<https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$>>
<http://www.linkedin.com/in/hedyeh-ahmadi<https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$>><http://www.linkedin.com/in/hedyeh-ahmadi<https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$>>




________________________________
From: Dexter Locke <dexter.locke at gmail.com<mailto:dexter.locke at gmail.com>>
Sent: Friday, March 5, 2021 1:01 PM
To: Hedyeh Ahmadi <hedyehah at usc.edu<mailto:hedyehah at usc.edu>>
Cc: r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org> <r-sig-mixed-models at r-project.org<mailto:r-sig-mixed-models at r-project.org>>; Megan M. Herting <herting at usc.edu<mailto:herting at usc.edu>>; Elisabeth Burnor <burnor at usc.edu<mailto:burnor at usc.edu>>
Subject: Re: [R-sig-ME] A three-level GLMM with binomial link in R

Hi Hedyeh,

What is the problem you are having? Specifically, what is the estimation issue with lmer and lme?

Can you provide a reproducible example? Can you provide the complete errors you are seeing?

The current questions are vague, so it will be challenging for list members to provide much guidance.

-Dexter


On Fri, Mar 5, 2021 at 3:27 PM Hedyeh Ahmadi <hedyehah at usc.edu<mailto:hedyehah at usc.edu><mailto:hedyehah at usc.edu<mailto:hedyehah at usc.edu>>> wrote:
Hi All,
I was wondering what would be a powerful package in R to run GLMM with logit link that can handle a data set with N=22945 and 3 nested random intercepts. So far, I have tried glmer() from lme4 and it's giving me a lot of estimation issues. Any other package I should try?

I am asking for another package as I am having the same issue with lmer() for similar LMM with continuous outcome, while lme() from nlme package runs the models with no problem.

Thank you in advance.

Best,

Hedyeh Ahmadi, Ph.D.
Statistician
Keck School of Medicine
Department of Preventive Medicine
University of Southern California

Postdoctoral Scholar
Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
University of California, Irvine

LinkedIn
www.linkedin.com/in/hedyeh-ahmadi<https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$><https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$><http://www.linkedin.com/in/hedyeh-ahmadi<https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$><https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$>>
<http://www.linkedin.com/in/hedyeh-ahmadi<https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$><https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$>><http://www.linkedin.com/in/hedyeh-ahmadi<https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$><https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$>>





        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org><mailto:R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org>> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models<https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKG8rJcsmY$><https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQM6wKtNs$>

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models<https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKG8rJcsmY$>

	[[alternative HTML version deleted]]


From |ongrob604 @end|ng |rom gm@||@com  Fri Mar  5 22:52:39 2021
From: |ongrob604 @end|ng |rom gm@||@com (Robert Long)
Date: Fri, 5 Mar 2021 21:52:39 +0000
Subject: [R-sig-ME] A three-level GLMM with binomial link in R
In-Reply-To: <BYAPR07MB509450F1132EEB7C41F60B4CD1969@BYAPR07MB5094.namprd07.prod.outlook.com>
References: <BYAPR07MB50945A60AFDE467F317861ACD1969@BYAPR07MB5094.namprd07.prod.outlook.com>
 <CAA=SVwH2pE+EAtEqALjeRPT91tWz-HJegrQkz9mYqfj7pb_A1Q@mail.gmail.com>
 <BYAPR07MB50947CD020DADA71CFF86407D1969@BYAPR07MB5094.namprd07.prod.outlook.com>
 <CA+3TTkNL+JGE+pgfOqASfvJ+r5eHmbGt3v+FzazouVePs_=x9Q@mail.gmail.com>
 <BYAPR07MB509450F1132EEB7C41F60B4CD1969@BYAPR07MB5094.namprd07.prod.outlook.com>
Message-ID: <CA+3TTkM-abt0u4Je03nnTBBKiZw4AFj-UdPfyP_JOLZbDiJEFA@mail.gmail.com>

Perhaps because of the different ways they store objects internally while
fitting the models.

On Fri, 5 Mar 2021, 21:47 Hedyeh Ahmadi, <hedyehah at usc.edu> wrote:

> Thank you for the reply Robert - If I am running out of memory in lmer(),
> do you know why lme() runs just fine?
>
> Best,
>
> Hedyeh Ahmadi, Ph.D.
> Statistician
> Keck School of Medicine
> Department of Preventive Medicine
> University of Southern California
>
> Postdoctoral Scholar
> Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
> University of California, Irvine
>
> LinkedIn
> www.linkedin.com/in/hedyeh-ahmadi
> <http://www.linkedin.com/in/hedyeh-ahmadi>
> <http://www.linkedin.com/in/hedyeh-ahmadi>
>
>
>
>
> ------------------------------
> *From:* Robert Long <longrob604 at gmail.com>
> *Sent:* Friday, March 5, 2021 1:43 PM
> *To:* Hedyeh Ahmadi <hedyehah at usc.edu>
> *Cc:* Dexter Locke <dexter.locke at gmail.com>; R-mixed models mailing list <
> r-sig-mixed-models at r-project.org>; Megan M. Herting <herting at usc.edu>;
> Elisabeth Burnor <burnor at usc.edu>
> *Subject:* Re: [R-sig-ME] A three-level GLMM with binomial link in R
>
> You've run out of memory. Try running it on a machine with much larger RAM.
>
> On Fri, 5 Mar 2021, 21:18 Hedyeh Ahmadi, <hedyehah at usc.edu> wrote:
>
> Hi - Thank you for the informative replies.
>
> I will try those other packages. If MASS::glmmPQL uses lme() then this
> should work for me.
>
> My data structure is complex so it's hard to give reproducible example but
> for example for two of my models I get the following errors in lmer() while
> lme() runs smoothly.
>
> 1- Error: cannot allocate vector of size 2.3 Gb.
>
> 2- Error: couldn't evaluate grouping factor id:(family:site) within model
> frame: try adding grouping factor to data frame explicitly if possible.
> (note that the id variable works for simpler lmer() models so the variable
> itself is not an issue)
>
> My model looks like the following nested structure:
> lmer(Y ~ 1 + X1 + X2 + X3 + (1|site/family/id), data=dd, REML = FALSE)
>
> Best,
>
> Hedyeh Ahmadi, Ph.D.
> Statistician
> Keck School of Medicine
> Department of Preventive Medicine
> University of Southern California
>
> Postdoctoral Scholar
> Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
> University of California, Irvine
>
> LinkedIn
> www.linkedin.com/in/hedyeh-ahmadi
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$>
> <http://www.linkedin.com/in/hedyeh-ahmadi
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$>
> >
> <http://www.linkedin.com/in/hedyeh-ahmadi
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$>
> ><http://www.linkedin.com/in/hedyeh-ahmadi
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$>
> >
>
>
>
>
> ________________________________
> From: Dexter Locke <dexter.locke at gmail.com>
> Sent: Friday, March 5, 2021 1:01 PM
> To: Hedyeh Ahmadi <hedyehah at usc.edu>
> Cc: r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>;
> Megan M. Herting <herting at usc.edu>; Elisabeth Burnor <burnor at usc.edu>
> Subject: Re: [R-sig-ME] A three-level GLMM with binomial link in R
>
> Hi Hedyeh,
>
> What is the problem you are having? Specifically, what is the estimation
> issue with lmer and lme?
>
> Can you provide a reproducible example? Can you provide the complete
> errors you are seeing?
>
> The current questions are vague, so it will be challenging for list
> members to provide much guidance.
>
> -Dexter
>
>
> On Fri, Mar 5, 2021 at 3:27 PM Hedyeh Ahmadi <hedyehah at usc.edu<mailto:
> hedyehah at usc.edu>> wrote:
> Hi All,
> I was wondering what would be a powerful package in R to run GLMM with
> logit link that can handle a data set with N=22945 and 3 nested random
> intercepts. So far, I have tried glmer() from lme4 and it's giving me a lot
> of estimation issues. Any other package I should try?
>
> I am asking for another package as I am having the same issue with lmer()
> for similar LMM with continuous outcome, while lme() from nlme package runs
> the models with no problem.
>
> Thank you in advance.
>
> Best,
>
> Hedyeh Ahmadi, Ph.D.
> Statistician
> Keck School of Medicine
> Department of Preventive Medicine
> University of Southern California
>
> Postdoctoral Scholar
> Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
> University of California, Irvine
>
> LinkedIn
> www.linkedin.com/in/hedyeh-ahmadi
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$>
> <
> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$
> ><http://www.linkedin.com/in/hedyeh-ahmadi
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$>
> <
> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$
> >>
> <http://www.linkedin.com/in/hedyeh-ahmadi
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$>
> <
> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$
> >><http://www.linkedin.com/in/hedyeh-ahmadi
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$>
> <
> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$
> >>
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org>
> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKG8rJcsmY$>
> <
> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQM6wKtNs$
> >
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKG8rJcsmY$>
>
>

	[[alternative HTML version deleted]]


From me @end|ng |rom ph||||p@|d@y@com  Sat Mar  6 01:57:44 2021
From: me @end|ng |rom ph||||p@|d@y@com (Phillip Alday)
Date: Sat, 6 Mar 2021 01:57:44 +0100
Subject: [R-sig-ME] A three-level GLMM with binomial link in R
In-Reply-To: <53f1986f-0898-e327-ba72-d6e69366b5c1@gmail.com>
References: <BYAPR07MB50945A60AFDE467F317861ACD1969@BYAPR07MB5094.namprd07.prod.outlook.com>
 <53f1986f-0898-e327-ba72-d6e69366b5c1@gmail.com>
Message-ID: <f06a3f5f-22d9-6b6f-d994-a084306bdeb8@phillipalday.com>

Since memory seems to be the issue, I would also second trying
MixedModels.jl, which has a somewhat more compact representation of
things that lme4.

If you have a minimal R script, we can get set up with the equivalent
minimal Julia script pretty quickly.

Phillip

On 5/3/21 10:01 pm, Ben Bolker wrote:
> ?? What kind of estimation issues?? As far as just data set size is
> concerned, I would consider this a "medium-to-large" problem for glmer,
> but not something I would expect to cause problems.
> 
> ?* MASS::glmmPQL is built on top of lme(), so might work well for you
> ?* glmmTMB provides a more-or-less drop-in replacement for glmer you
> could try
> ?* GLMMadaptive::mixed_model is another possibility
> ?* if you really need speed, Doug Bates's MixedModels.jl in Julia
> usually beats everything else listed here
> 
> ? But ... we could probably give much better advice if you say something
> about the specific kinds of "estimation issues" you're having.
> 
> ? cheers
> ?? Ben Bolker
> 
> On 3/5/21 3:27 PM, Hedyeh Ahmadi wrote:
>> Hi All,
>> I was wondering what would be a powerful package in R to run GLMM with
>> logit link that can handle a data set with N=22945 and 3 nested random
>> intercepts. So far, I have tried glmer() from lme4 and it's giving me
>> a lot of estimation issues. Any other package I should try?
>>
>> I am asking for another package as I am having the same issue with
>> lmer() for similar LMM with continuous outcome, while lme() from nlme
>> package runs the models with no problem.
>>
>> Thank you in advance.
>>
>> Best,
>>
>> Hedyeh Ahmadi, Ph.D.
>> Statistician
>> Keck School of Medicine
>> Department of Preventive Medicine
>> University of Southern California
>>
>> Postdoctoral Scholar
>> Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
>> University of California, Irvine
>>
>> LinkedIn
>> www.linkedin.com/in/hedyeh-ahmadi<http://www.linkedin.com/in/hedyeh-ahmadi>
>>
>> <http://www.linkedin.com/in/hedyeh-ahmadi><http://www.linkedin.com/in/hedyeh-ahmadi>
>>
>>
>>
>>
>>
>>
>> ????[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


From bbo|ker @end|ng |rom gm@||@com  Sat Mar  6 02:44:43 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Fri, 5 Mar 2021 20:44:43 -0500
Subject: [R-sig-ME] A three-level GLMM with binomial link in R
In-Reply-To: <CA+3TTkM-abt0u4Je03nnTBBKiZw4AFj-UdPfyP_JOLZbDiJEFA@mail.gmail.com>
References: <BYAPR07MB50945A60AFDE467F317861ACD1969@BYAPR07MB5094.namprd07.prod.outlook.com>
 <CAA=SVwH2pE+EAtEqALjeRPT91tWz-HJegrQkz9mYqfj7pb_A1Q@mail.gmail.com>
 <BYAPR07MB50947CD020DADA71CFF86407D1969@BYAPR07MB5094.namprd07.prod.outlook.com>
 <CA+3TTkNL+JGE+pgfOqASfvJ+r5eHmbGt3v+FzazouVePs_=x9Q@mail.gmail.com>
 <BYAPR07MB509450F1132EEB7C41F60B4CD1969@BYAPR07MB5094.namprd07.prod.outlook.com>
 <CA+3TTkM-abt0u4Je03nnTBBKiZw4AFj-UdPfyP_JOLZbDiJEFA@mail.gmail.com>
Message-ID: <9e903a9f-5bec-934c-0b50-b2fca97cd4f3@gmail.com>

   Here's an example that conforms approximately to the structure of 
your data: on my machine the peak RAM usage is 121 Mb, far short of your 
2.3 Gb ...  so I still suspect there is something going on that we don't 
know about/haven't guessed yet.

set.seed(101)
N <- 22945
ns <- 100
nf <- 100
nid <- 100
dd <- data.frame(X1=rnorm(N),
                  X2=rnorm(N),
                  X3=rnorm(N),
                  site=sample(ns, replace=TRUE, size=N),
                  family=sample(nf, replace=TRUE, size=N),
                  id=sample(nid, replace=TRUE, size=N))
form <- Y ~ 1 + X1 + X2 + X3 + (1|site/family/id)
dd$Y <- simulate(form[-2], newdata=dd, family=gaussian,
                  newparams=list(beta=rep(1,4),theta=rep(1,3),sigma=1))[[1]]
library(peakRAM)
mem <- peakRAM(
     m <- lmer(form, data=dd, REML=FALSE)
)

mem
                      Function_Call Elapsed_Time_sec Total_RAM_Used_MiB
1 m<-lmer(form,data=dd,REML=FALSE)            1.754               10.3
   Peak_RAM_Used_MiB
1             120.7


On 3/5/21 4:52 PM, Robert Long wrote:
> Perhaps because of the different ways they store objects internally while
> fitting the models.
> 
> On Fri, 5 Mar 2021, 21:47 Hedyeh Ahmadi, <hedyehah at usc.edu> wrote:
> 
>> Thank you for the reply Robert - If I am running out of memory in lmer(),
>> do you know why lme() runs just fine?
>>
>> Best,
>>
>> Hedyeh Ahmadi, Ph.D.
>> Statistician
>> Keck School of Medicine
>> Department of Preventive Medicine
>> University of Southern California
>>
>> Postdoctoral Scholar
>> Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
>> University of California, Irvine
>>
>> LinkedIn
>> www.linkedin.com/in/hedyeh-ahmadi
>> <http://www.linkedin.com/in/hedyeh-ahmadi>
>> <http://www.linkedin.com/in/hedyeh-ahmadi>
>>
>>
>>
>>
>> ------------------------------
>> *From:* Robert Long <longrob604 at gmail.com>
>> *Sent:* Friday, March 5, 2021 1:43 PM
>> *To:* Hedyeh Ahmadi <hedyehah at usc.edu>
>> *Cc:* Dexter Locke <dexter.locke at gmail.com>; R-mixed models mailing list <
>> r-sig-mixed-models at r-project.org>; Megan M. Herting <herting at usc.edu>;
>> Elisabeth Burnor <burnor at usc.edu>
>> *Subject:* Re: [R-sig-ME] A three-level GLMM with binomial link in R
>>
>> You've run out of memory. Try running it on a machine with much larger RAM.
>>
>> On Fri, 5 Mar 2021, 21:18 Hedyeh Ahmadi, <hedyehah at usc.edu> wrote:
>>
>> Hi - Thank you for the informative replies.
>>
>> I will try those other packages. If MASS::glmmPQL uses lme() then this
>> should work for me.
>>
>> My data structure is complex so it's hard to give reproducible example but
>> for example for two of my models I get the following errors in lmer() while
>> lme() runs smoothly.
>>
>> 1- Error: cannot allocate vector of size 2.3 Gb.
>>
>> 2- Error: couldn't evaluate grouping factor id:(family:site) within model
>> frame: try adding grouping factor to data frame explicitly if possible.
>> (note that the id variable works for simpler lmer() models so the variable
>> itself is not an issue)
>>
>> My model looks like the following nested structure:
>> lmer(Y ~ 1 + X1 + X2 + X3 + (1|site/family/id), data=dd, REML = FALSE)
>>
>> Best,
>>
>> Hedyeh Ahmadi, Ph.D.
>> Statistician
>> Keck School of Medicine
>> Department of Preventive Medicine
>> University of Southern California
>>
>> Postdoctoral Scholar
>> Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
>> University of California, Irvine
>>
>> LinkedIn
>> www.linkedin.com/in/hedyeh-ahmadi
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$>
>> <http://www.linkedin.com/in/hedyeh-ahmadi
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$>
>>>
>> <http://www.linkedin.com/in/hedyeh-ahmadi
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$>
>>> <http://www.linkedin.com/in/hedyeh-ahmadi
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$>
>>>
>>
>>
>>
>>
>> ________________________________
>> From: Dexter Locke <dexter.locke at gmail.com>
>> Sent: Friday, March 5, 2021 1:01 PM
>> To: Hedyeh Ahmadi <hedyehah at usc.edu>
>> Cc: r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>;
>> Megan M. Herting <herting at usc.edu>; Elisabeth Burnor <burnor at usc.edu>
>> Subject: Re: [R-sig-ME] A three-level GLMM with binomial link in R
>>
>> Hi Hedyeh,
>>
>> What is the problem you are having? Specifically, what is the estimation
>> issue with lmer and lme?
>>
>> Can you provide a reproducible example? Can you provide the complete
>> errors you are seeing?
>>
>> The current questions are vague, so it will be challenging for list
>> members to provide much guidance.
>>
>> -Dexter
>>
>>
>> On Fri, Mar 5, 2021 at 3:27 PM Hedyeh Ahmadi <hedyehah at usc.edu<mailto:
>> hedyehah at usc.edu>> wrote:
>> Hi All,
>> I was wondering what would be a powerful package in R to run GLMM with
>> logit link that can handle a data set with N=22945 and 3 nested random
>> intercepts. So far, I have tried glmer() from lme4 and it's giving me a lot
>> of estimation issues. Any other package I should try?
>>
>> I am asking for another package as I am having the same issue with lmer()
>> for similar LMM with continuous outcome, while lme() from nlme package runs
>> the models with no problem.
>>
>> Thank you in advance.
>>
>> Best,
>>
>> Hedyeh Ahmadi, Ph.D.
>> Statistician
>> Keck School of Medicine
>> Department of Preventive Medicine
>> University of Southern California
>>
>> Postdoctoral Scholar
>> Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
>> University of California, Irvine
>>
>> LinkedIn
>> www.linkedin.com/in/hedyeh-ahmadi
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$>
>> <
>> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$
>>> <http://www.linkedin.com/in/hedyeh-ahmadi
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$>
>> <
>> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$
>>>>
>> <http://www.linkedin.com/in/hedyeh-ahmadi
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$>
>> <
>> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$
>>>> <http://www.linkedin.com/in/hedyeh-ahmadi
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$>
>> <
>> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$
>>>>
>>
>>
>>
>>
>>
>>          [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org>
>> mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKG8rJcsmY$>
>> <
>> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQM6wKtNs$
>>>
>>
>>          [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKG8rJcsmY$>
>>
>>
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From hedyeh@h @end|ng |rom u@c@edu  Mon Mar  8 17:29:56 2021
From: hedyeh@h @end|ng |rom u@c@edu (Hedyeh Ahmadi)
Date: Mon, 8 Mar 2021 16:29:56 +0000
Subject: [R-sig-ME] A three-level GLMM with binomial link in R
In-Reply-To: <9e903a9f-5bec-934c-0b50-b2fca97cd4f3@gmail.com>
References: <BYAPR07MB50945A60AFDE467F317861ACD1969@BYAPR07MB5094.namprd07.prod.outlook.com>
 <CAA=SVwH2pE+EAtEqALjeRPT91tWz-HJegrQkz9mYqfj7pb_A1Q@mail.gmail.com>
 <BYAPR07MB50947CD020DADA71CFF86407D1969@BYAPR07MB5094.namprd07.prod.outlook.com>
 <CA+3TTkNL+JGE+pgfOqASfvJ+r5eHmbGt3v+FzazouVePs_=x9Q@mail.gmail.com>
 <BYAPR07MB509450F1132EEB7C41F60B4CD1969@BYAPR07MB5094.namprd07.prod.outlook.com>
 <CA+3TTkM-abt0u4Je03nnTBBKiZw4AFj-UdPfyP_JOLZbDiJEFA@mail.gmail.com>,
 <9e903a9f-5bec-934c-0b50-b2fca97cd4f3@gmail.com>
Message-ID: <BYAPR07MB5094069BFA432F89688D34DCD1939@BYAPR07MB5094.namprd07.prod.outlook.com>

Thank you for the toy example. This same example in my PC gives the following memory use output:

> mem
                     Function_Call                            Elapsed_Time_sec         Total_RAM_Used_MiB    Peak_RAM_Used_MiB
  m<-lmer(form,data=dd,REML=FALSE)             2.64                                     10.3                                       130.1

When I run peakRAM() for my actual data, it take one hour plus then my PC slows down, then I have to stop R to be able to use my PC.

Best,

Hedyeh Ahmadi, Ph.D.
Statistician
Keck School of Medicine
Department of Preventive Medicine
University of Southern California

Postdoctoral Scholar
Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
University of California, Irvine

LinkedIn
www.linkedin.com/in/hedyeh-ahmadi<http://www.linkedin.com/in/hedyeh-ahmadi>
<http://www.linkedin.com/in/hedyeh-ahmadi><http://www.linkedin.com/in/hedyeh-ahmadi>




________________________________
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of Ben Bolker <bbolker at gmail.com>
Sent: Friday, March 5, 2021 5:44 PM
To: r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] A three-level GLMM with binomial link in R

   Here's an example that conforms approximately to the structure of
your data: on my machine the peak RAM usage is 121 Mb, far short of your
2.3 Gb ...  so I still suspect there is something going on that we don't
know about/haven't guessed yet.

set.seed(101)
N <- 22945
ns <- 100
nf <- 100
nid <- 100
dd <- data.frame(X1=rnorm(N),
                  X2=rnorm(N),
                  X3=rnorm(N),
                  site=sample(ns, replace=TRUE, size=N),
                  family=sample(nf, replace=TRUE, size=N),
                  id=sample(nid, replace=TRUE, size=N))
form <- Y ~ 1 + X1 + X2 + X3 + (1|site/family/id)
dd$Y <- simulate(form[-2], newdata=dd, family=gaussian,
                  newparams=list(beta=rep(1,4),theta=rep(1,3),sigma=1))[[1]]
library(peakRAM)
mem <- peakRAM(
     m <- lmer(form, data=dd, REML=FALSE)
)

mem
                      Function_Call Elapsed_Time_sec Total_RAM_Used_MiB
1 m<-lmer(form,data=dd,REML=FALSE)            1.754               10.3
   Peak_RAM_Used_MiB
1             120.7


On 3/5/21 4:52 PM, Robert Long wrote:
> Perhaps because of the different ways they store objects internally while
> fitting the models.
>
> On Fri, 5 Mar 2021, 21:47 Hedyeh Ahmadi, <hedyehah at usc.edu> wrote:
>
>> Thank you for the reply Robert - If I am running out of memory in lmer(),
>> do you know why lme() runs just fine?
>>
>> Best,
>>
>> Hedyeh Ahmadi, Ph.D.
>> Statistician
>> Keck School of Medicine
>> Department of Preventive Medicine
>> University of Southern California
>>
>> Postdoctoral Scholar
>> Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
>> University of California, Irvine
>>
>> LinkedIn
>> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$ >
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$ >
>>
>>
>>
>>
>> ------------------------------
>> *From:* Robert Long <longrob604 at gmail.com>
>> *Sent:* Friday, March 5, 2021 1:43 PM
>> *To:* Hedyeh Ahmadi <hedyehah at usc.edu>
>> *Cc:* Dexter Locke <dexter.locke at gmail.com>; R-mixed models mailing list <
>> r-sig-mixed-models at r-project.org>; Megan M. Herting <herting at usc.edu>;
>> Elisabeth Burnor <burnor at usc.edu>
>> *Subject:* Re: [R-sig-ME] A three-level GLMM with binomial link in R
>>
>> You've run out of memory. Try running it on a machine with much larger RAM.
>>
>> On Fri, 5 Mar 2021, 21:18 Hedyeh Ahmadi, <hedyehah at usc.edu> wrote:
>>
>> Hi - Thank you for the informative replies.
>>
>> I will try those other packages. If MASS::glmmPQL uses lme() then this
>> should work for me.
>>
>> My data structure is complex so it's hard to give reproducible example but
>> for example for two of my models I get the following errors in lmer() while
>> lme() runs smoothly.
>>
>> 1- Error: cannot allocate vector of size 2.3 Gb.
>>
>> 2- Error: couldn't evaluate grouping factor id:(family:site) within model
>> frame: try adding grouping factor to data frame explicitly if possible.
>> (note that the id variable works for simpler lmer() models so the variable
>> itself is not an issue)
>>
>> My model looks like the following nested structure:
>> lmer(Y ~ 1 + X1 + X2 + X3 + (1|site/family/id), data=dd, REML = FALSE)
>>
>> Best,
>>
>> Hedyeh Ahmadi, Ph.D.
>> Statistician
>> Keck School of Medicine
>> Department of Preventive Medicine
>> University of Southern California
>>
>> Postdoctoral Scholar
>> Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
>> University of California, Irvine
>>
>> LinkedIn
>> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$>
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$>
>>>
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$>
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$>
>>>
>>
>>
>>
>>
>> ________________________________
>> From: Dexter Locke <dexter.locke at gmail.com>
>> Sent: Friday, March 5, 2021 1:01 PM
>> To: Hedyeh Ahmadi <hedyehah at usc.edu>
>> Cc: r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>;
>> Megan M. Herting <herting at usc.edu>; Elisabeth Burnor <burnor at usc.edu>
>> Subject: Re: [R-sig-ME] A three-level GLMM with binomial link in R
>>
>> Hi Hedyeh,
>>
>> What is the problem you are having? Specifically, what is the estimation
>> issue with lmer and lme?
>>
>> Can you provide a reproducible example? Can you provide the complete
>> errors you are seeing?
>>
>> The current questions are vague, so it will be challenging for list
>> members to provide much guidance.
>>
>> -Dexter
>>
>>
>> On Fri, Mar 5, 2021 at 3:27 PM Hedyeh Ahmadi <hedyehah at usc.edu<mailto:
>> hedyehah at usc.edu>> wrote:
>> Hi All,
>> I was wondering what would be a powerful package in R to run GLMM with
>> logit link that can handle a data set with N=22945 and 3 nested random
>> intercepts. So far, I have tried glmer() from lme4 and it's giving me a lot
>> of estimation issues. Any other package I should try?
>>
>> I am asking for another package as I am having the same issue with lmer()
>> for similar LMM with continuous outcome, while lme() from nlme package runs
>> the models with no problem.
>>
>> Thank you in advance.
>>
>> Best,
>>
>> Hedyeh Ahmadi, Ph.D.
>> Statistician
>> Keck School of Medicine
>> Department of Preventive Medicine
>> University of Southern California
>>
>> Postdoctoral Scholar
>> Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
>> University of California, Irvine
>>
>> LinkedIn
>> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$>
>> <
>> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$>
>> <
>> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$
>>>>
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$>
>> <
>> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$
>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$>
>> <
>> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$
>>>>
>>
>>
>>
>>
>>
>>          [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org>
>> mailing list
>> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$
>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKG8rJcsmY$>
>> <
>> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQM6wKtNs$
>>>
>>
>>          [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$
>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKG8rJcsmY$>
>>
>>
>
>        [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$
>

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$

	[[alternative HTML version deleted]]


From |ongrob604 @end|ng |rom gm@||@com  Mon Mar  8 20:00:57 2021
From: |ongrob604 @end|ng |rom gm@||@com (Robert Long)
Date: Mon, 8 Mar 2021 19:00:57 +0000
Subject: [R-sig-ME] A three-level GLMM with binomial link in R
In-Reply-To: <BYAPR07MB5094069BFA432F89688D34DCD1939@BYAPR07MB5094.namprd07.prod.outlook.com>
References: <BYAPR07MB50945A60AFDE467F317861ACD1969@BYAPR07MB5094.namprd07.prod.outlook.com>
 <CAA=SVwH2pE+EAtEqALjeRPT91tWz-HJegrQkz9mYqfj7pb_A1Q@mail.gmail.com>
 <BYAPR07MB50947CD020DADA71CFF86407D1969@BYAPR07MB5094.namprd07.prod.outlook.com>
 <CA+3TTkNL+JGE+pgfOqASfvJ+r5eHmbGt3v+FzazouVePs_=x9Q@mail.gmail.com>
 <BYAPR07MB509450F1132EEB7C41F60B4CD1969@BYAPR07MB5094.namprd07.prod.outlook.com>
 <CA+3TTkM-abt0u4Je03nnTBBKiZw4AFj-UdPfyP_JOLZbDiJEFA@mail.gmail.com>
 <9e903a9f-5bec-934c-0b50-b2fca97cd4f3@gmail.com>
 <BYAPR07MB5094069BFA432F89688D34DCD1939@BYAPR07MB5094.namprd07.prod.outlook.com>
Message-ID: <CA+3TTkMKDXy2zZYb09jUk2+hP+_XqV6GDgXioDhu9SUvovexKA@mail.gmail.com>

How many sites, families and Id's do you have?

Please also give us the output of str(dd)

On Mon, 8 Mar 2021, 16:30 Hedyeh Ahmadi, <hedyehah at usc.edu> wrote:

> Thank you for the toy example. This same example in my PC gives the
> following memory use output:
>
> > mem
>                      Function_Call
> Elapsed_Time_sec         Total_RAM_Used_MiB    Peak_RAM_Used_MiB
>   m<-lmer(form,data=dd,REML=FALSE)             2.64
>              10.3                                       130.1
>
> When I run peakRAM() for my actual data, it take one hour plus then my PC
> slows down, then I have to stop R to be able to use my PC.
>
> Best,
>
> Hedyeh Ahmadi, Ph.D.
> Statistician
> Keck School of Medicine
> Department of Preventive Medicine
> University of Southern California
>
> Postdoctoral Scholar
> Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
> University of California, Irvine
>
> LinkedIn
> www.linkedin.com/in/hedyeh-ahmadi<http://www.linkedin.com/in/hedyeh-ahmadi
> >
> <http://www.linkedin.com/in/hedyeh-ahmadi><
> http://www.linkedin.com/in/hedyeh-ahmadi>
>
>
>
>
> ________________________________
> From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on
> behalf of Ben Bolker <bbolker at gmail.com>
> Sent: Friday, March 5, 2021 5:44 PM
> To: r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>
> Subject: Re: [R-sig-ME] A three-level GLMM with binomial link in R
>
>    Here's an example that conforms approximately to the structure of
> your data: on my machine the peak RAM usage is 121 Mb, far short of your
> 2.3 Gb ...  so I still suspect there is something going on that we don't
> know about/haven't guessed yet.
>
> set.seed(101)
> N <- 22945
> ns <- 100
> nf <- 100
> nid <- 100
> dd <- data.frame(X1=rnorm(N),
>                   X2=rnorm(N),
>                   X3=rnorm(N),
>                   site=sample(ns, replace=TRUE, size=N),
>                   family=sample(nf, replace=TRUE, size=N),
>                   id=sample(nid, replace=TRUE, size=N))
> form <- Y ~ 1 + X1 + X2 + X3 + (1|site/family/id)
> dd$Y <- simulate(form[-2], newdata=dd, family=gaussian,
>
> newparams=list(beta=rep(1,4),theta=rep(1,3),sigma=1))[[1]]
> library(peakRAM)
> mem <- peakRAM(
>      m <- lmer(form, data=dd, REML=FALSE)
> )
>
> mem
>                       Function_Call Elapsed_Time_sec Total_RAM_Used_MiB
> 1 m<-lmer(form,data=dd,REML=FALSE)            1.754               10.3
>    Peak_RAM_Used_MiB
> 1             120.7
>
>
> On 3/5/21 4:52 PM, Robert Long wrote:
> > Perhaps because of the different ways they store objects internally while
> > fitting the models.
> >
> > On Fri, 5 Mar 2021, 21:47 Hedyeh Ahmadi, <hedyehah at usc.edu> wrote:
> >
> >> Thank you for the reply Robert - If I am running out of memory in
> lmer(),
> >> do you know why lme() runs just fine?
> >>
> >> Best,
> >>
> >> Hedyeh Ahmadi, Ph.D.
> >> Statistician
> >> Keck School of Medicine
> >> Department of Preventive Medicine
> >> University of Southern California
> >>
> >> Postdoctoral Scholar
> >> Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
> >> University of California, Irvine
> >>
> >> LinkedIn
> >>
> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$
> >> <
> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$
> >
> >> <
> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$
> >
> >>
> >>
> >>
> >>
> >> ------------------------------
> >> *From:* Robert Long <longrob604 at gmail.com>
> >> *Sent:* Friday, March 5, 2021 1:43 PM
> >> *To:* Hedyeh Ahmadi <hedyehah at usc.edu>
> >> *Cc:* Dexter Locke <dexter.locke at gmail.com>; R-mixed models mailing
> list <
> >> r-sig-mixed-models at r-project.org>; Megan M. Herting <herting at usc.edu>;
> >> Elisabeth Burnor <burnor at usc.edu>
> >> *Subject:* Re: [R-sig-ME] A three-level GLMM with binomial link in R
> >>
> >> You've run out of memory. Try running it on a machine with much larger
> RAM.
> >>
> >> On Fri, 5 Mar 2021, 21:18 Hedyeh Ahmadi, <hedyehah at usc.edu> wrote:
> >>
> >> Hi - Thank you for the informative replies.
> >>
> >> I will try those other packages. If MASS::glmmPQL uses lme() then this
> >> should work for me.
> >>
> >> My data structure is complex so it's hard to give reproducible example
> but
> >> for example for two of my models I get the following errors in lmer()
> while
> >> lme() runs smoothly.
> >>
> >> 1- Error: cannot allocate vector of size 2.3 Gb.
> >>
> >> 2- Error: couldn't evaluate grouping factor id:(family:site) within
> model
> >> frame: try adding grouping factor to data frame explicitly if possible.
> >> (note that the id variable works for simpler lmer() models so the
> variable
> >> itself is not an issue)
> >>
> >> My model looks like the following nested structure:
> >> lmer(Y ~ 1 + X1 + X2 + X3 + (1|site/family/id), data=dd, REML = FALSE)
> >>
> >> Best,
> >>
> >> Hedyeh Ahmadi, Ph.D.
> >> Statistician
> >> Keck School of Medicine
> >> Department of Preventive Medicine
> >> University of Southern California
> >>
> >> Postdoctoral Scholar
> >> Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
> >> University of California, Irvine
> >>
> >> LinkedIn
> >>
> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$
> >> <
> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$
> >
> >> <
> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$
> >> <
> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$
> >
> >>>
> >> <
> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$
> >> <
> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$
> >
> >>> <
> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$
> >> <
> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$
> >
> >>>
> >>
> >>
> >>
> >>
> >> ________________________________
> >> From: Dexter Locke <dexter.locke at gmail.com>
> >> Sent: Friday, March 5, 2021 1:01 PM
> >> To: Hedyeh Ahmadi <hedyehah at usc.edu>
> >> Cc: r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org
> >;
> >> Megan M. Herting <herting at usc.edu>; Elisabeth Burnor <burnor at usc.edu>
> >> Subject: Re: [R-sig-ME] A three-level GLMM with binomial link in R
> >>
> >> Hi Hedyeh,
> >>
> >> What is the problem you are having? Specifically, what is the estimation
> >> issue with lmer and lme?
> >>
> >> Can you provide a reproducible example? Can you provide the complete
> >> errors you are seeing?
> >>
> >> The current questions are vague, so it will be challenging for list
> >> members to provide much guidance.
> >>
> >> -Dexter
> >>
> >>
> >> On Fri, Mar 5, 2021 at 3:27 PM Hedyeh Ahmadi <hedyehah at usc.edu<mailto:
> >> hedyehah at usc.edu>> wrote:
> >> Hi All,
> >> I was wondering what would be a powerful package in R to run GLMM with
> >> logit link that can handle a data set with N=22945 and 3 nested random
> >> intercepts. So far, I have tried glmer() from lme4 and it's giving me a
> lot
> >> of estimation issues. Any other package I should try?
> >>
> >> I am asking for another package as I am having the same issue with
> lmer()
> >> for similar LMM with continuous outcome, while lme() from nlme package
> runs
> >> the models with no problem.
> >>
> >> Thank you in advance.
> >>
> >> Best,
> >>
> >> Hedyeh Ahmadi, Ph.D.
> >> Statistician
> >> Keck School of Medicine
> >> Department of Preventive Medicine
> >> University of Southern California
> >>
> >> Postdoctoral Scholar
> >> Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
> >> University of California, Irvine
> >>
> >> LinkedIn
> >>
> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$
> >> <
> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$
> >
> >> <
> >>
> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$
> >>> <
> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$
> >> <
> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$
> >
> >> <
> >>
> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$
> >>>>
> >> <
> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$
> >> <
> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$
> >
> >> <
> >>
> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$
> >>>> <
> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$
> >> <
> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$
> >
> >> <
> >>
> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$
> >>>>
> >>
> >>
> >>
> >>
> >>
> >>          [[alternative HTML version deleted]]
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org<mailto:
> R-sig-mixed-models at r-project.org>
> >> mailing list
> >>
> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$
> >> <
> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKG8rJcsmY$
> >
> >> <
> >>
> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQM6wKtNs$
> >>>
> >>
> >>          [[alternative HTML version deleted]]
> >>
> >> _______________________________________________
> >> R-sig-mixed-models at r-project.org mailing list
> >>
> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$
> >> <
> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKG8rJcsmY$
> >
> >>
> >>
> >
> >        [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> >
> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$
> >
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
>
> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Wed Mar 10 01:12:54 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Tue, 9 Mar 2021 19:12:54 -0500
Subject: [R-sig-ME] A three-level GLMM with binomial link in R
In-Reply-To: <BYAPR07MB5094069BFA432F89688D34DCD1939@BYAPR07MB5094.namprd07.prod.outlook.com>
References: <BYAPR07MB50945A60AFDE467F317861ACD1969@BYAPR07MB5094.namprd07.prod.outlook.com>
 <CAA=SVwH2pE+EAtEqALjeRPT91tWz-HJegrQkz9mYqfj7pb_A1Q@mail.gmail.com>
 <BYAPR07MB50947CD020DADA71CFF86407D1969@BYAPR07MB5094.namprd07.prod.outlook.com>
 <CA+3TTkNL+JGE+pgfOqASfvJ+r5eHmbGt3v+FzazouVePs_=x9Q@mail.gmail.com>
 <BYAPR07MB509450F1132EEB7C41F60B4CD1969@BYAPR07MB5094.namprd07.prod.outlook.com>
 <CA+3TTkM-abt0u4Je03nnTBBKiZw4AFj-UdPfyP_JOLZbDiJEFA@mail.gmail.com>
 <9e903a9f-5bec-934c-0b50-b2fca97cd4f3@gmail.com>
 <BYAPR07MB5094069BFA432F89688D34DCD1939@BYAPR07MB5094.namprd07.prod.outlook.com>
Message-ID: <a8005560-3957-e814-df74-604d9cb857bb@gmail.com>

   OK, then it would be very helpful to have more details about your 
data set. Are one or more of X1, X2, X3 categorical predictors with many 
levels ... ?  Any chance we can see str() or summary() ?  Are you using 
exactly the formula you told us about, or something slightly different?

   The computational burden of a large number of fixed effect parameters 
will be much worse for glmer than for lmer, unless you use nAGQ=0. 
glmmTMB would be able to help in two ways: (1) it doesn't scale as badly 
for large numbers of fixed effects; (2) it allows sparse fixed-effect 
model matrices (something we keep meaning to (re)implement in lme4) ...

  Making X1 into a 1000-level factor brings the required memory up by 
about a factor of 10 and increases the run time from seconds to minutes.


Base model:

                      Function_Call Elapsed_Time_sec Total_RAM_Used_MiB
1 m<-lmer(form,data=dd,REML=FALSE)            1.903               10.4
   Peak_RAM_Used_MiB
1             107.7

With X=1000-level factor (no derivative calculations):
 
  Function_Call
1 
m2<-lmer(form,data=dd2,REML=FALSE,control=lmerControl(calc.derivs=FALSE),verbose=10)
   Elapsed_Time_sec Total_RAM_Used_MiB Peak_RAM_Used_MiB
1          559.735              608.8             984.5


With derivative calculation at the end:

                                  Function_Call Elapsed_Time_sec
1 m3<-lmer(form,data=dd2,REML=FALSE,verbose=10)          677.975
   Total_RAM_Used_MiB Peak_RAM_Used_MiB
1              608.7            1148.7
 >
 >

---
ibrary(lme4)
set.seed(101)
N <- 22945
ns <- 100
nf <- 100
nid <- 100
dd <- data.frame(X1=rnorm(N),
                  X2=rnorm(N),
                  X3=rnorm(N),
                  site=sample(ns, replace=TRUE, size=N),
                  family=sample(nf, replace=TRUE, size=N),
                  id=sample(nid, replace=TRUE, size=N))
form <- Y ~ 1 + X1 + X2 + X3 + (1|site/family/id)
dd$Y <- simulate(form[-2], newdata=dd, family=gaussian,
                  newparams=list(beta=rep(1,4),theta=rep(1,3),sigma=1))[[1]]
library(peakRAM)
system.time(mem <- peakRAM(
     m <- lmer(form, data=dd, REML=FALSE)
     ))
print(mem)

dd2 <- transform(dd,
         X1=factor(sample(1000,size=N,replace=TRUE)))

system.time(mem2 <- peakRAM(
     m2 <- lmer(form, data=dd2, REML=FALSE, 
control=lmerControl(calc.derivs=FALSE), verbose=10)
))
print(mem2)

system.time(mem3 <- peakRAM(
     m3 <- lmer(form, data=dd2, REML=FALSE, verbose=10)
))
print(mem3)


On 3/8/21 11:29 AM, Hedyeh Ahmadi wrote:
> Thank you for the toy example. This same example in my PC gives the 
> following memory use output:
> 
> 
>  > mem
>  ? ? ? ? ? ? ? ? ? ? ?Function_Call                            
> Elapsed_Time_sec ? ? ? ? Total_RAM_Used_MiB ?? Peak_RAM_Used_MiB
>  ? m<-lmer(form,data=dd,REML=FALSE) ? ? ? ? ? ? 2.64                     
>  ? ? ? ? ? ? ? ? 10.3 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 130.1
> 
> When I run peakRAM() for my actual data, it take one hour plus then my 
> PC slows down, then I have to stop R to be able to use my PC.
> 
> Best,
> 
> Hedyeh Ahmadi, Ph.D.
> Statistician
> Keck School of Medicine
> Department of Preventive Medicine
> University of Southern California
> 
> Postdoctoral Scholar
> Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
> University of California, Irvine
> 
> LinkedIn
> www.linkedin.com/in/hedyeh-ahmadi <http://www.linkedin.com/in/hedyeh-ahmadi>
> <http://www.linkedin.com/in/hedyeh-ahmadi><http://www.linkedin.com/in/hedyeh-ahmadi>
> 
> 
> 
> 
> ------------------------------------------------------------------------
> *From:* R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on 
> behalf of Ben Bolker <bbolker at gmail.com>
> *Sent:* Friday, March 5, 2021 5:44 PM
> *To:* r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>
> *Subject:* Re: [R-sig-ME] A three-level GLMM with binomial link in R
>  ?? Here's an example that conforms approximately to the structure of
> your data: on my machine the peak RAM usage is 121 Mb, far short of your
> 2.3 Gb ...? so I still suspect there is something going on that we don't
> know about/haven't guessed yet.
> 
> set.seed(101)
> N <- 22945
> ns <- 100
> nf <- 100
> nid <- 100
> dd <- data.frame(X1=rnorm(N),
>  ????????????????? X2=rnorm(N),
>  ????????????????? X3=rnorm(N),
>  ????????????????? site=sample(ns, replace=TRUE, size=N),
>  ????????????????? family=sample(nf, replace=TRUE, size=N),
>  ????????????????? id=sample(nid, replace=TRUE, size=N))
> form <- Y ~ 1 + X1 + X2 + X3 + (1|site/family/id)
> dd$Y <- simulate(form[-2], newdata=dd, family=gaussian,
>                    
> newparams=list(beta=rep(1,4),theta=rep(1,3),sigma=1))[[1]]
> library(peakRAM)
> mem <- peakRAM(
>  ???? m <- lmer(form, data=dd, REML=FALSE)
> )
> 
> mem
>  ????????????????????? Function_Call Elapsed_Time_sec Total_RAM_Used_MiB
> 1 m<-lmer(form,data=dd,REML=FALSE)??????????? 1.754?????????????? 10.3
>  ?? Peak_RAM_Used_MiB
> 1???????????? 120.7
> 
> 
> On 3/5/21 4:52 PM, Robert Long wrote:
>> Perhaps because of the different ways they store objects internally while
>> fitting the models.
>> 
>> On Fri, 5 Mar 2021, 21:47 Hedyeh Ahmadi, <hedyehah at usc.edu> wrote:
>> 
>>> Thank you for the reply Robert - If I am running out of memory in lmer(),
>>> do you know why lme() runs just fine?
>>>
>>> Best,
>>>
>>> Hedyeh Ahmadi, Ph.D.
>>> Statistician
>>> Keck School of Medicine
>>> Department of Preventive Medicine
>>> University of Southern California
>>>
>>> Postdoctoral Scholar
>>> Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
>>> University of California, Irvine
>>>
>>> LinkedIn
>>> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$> 
> 
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$ 
>  >
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$ 
>  >
>>>
>>>
>>>
>>>
>>> ------------------------------
>>> *From:* Robert Long <longrob604 at gmail.com>
>>> *Sent:* Friday, March 5, 2021 1:43 PM
>>> *To:* Hedyeh Ahmadi <hedyehah at usc.edu>
>>> *Cc:* Dexter Locke <dexter.locke at gmail.com>; R-mixed models mailing list <
>>> r-sig-mixed-models at r-project.org>; Megan M. Herting <herting at usc.edu>;
>>> Elisabeth Burnor <burnor at usc.edu>
>>> *Subject:* Re: [R-sig-ME] A three-level GLMM with binomial link in R
>>>
>>> You've run out of memory. Try running it on a machine with much larger RAM.
>>>
>>> On Fri, 5 Mar 2021, 21:18 Hedyeh Ahmadi, <hedyehah at usc.edu> wrote:
>>>
>>> Hi - Thank you for the informative replies.
>>>
>>> I will try those other packages. If MASS::glmmPQL uses lme() then this
>>> should work for me.
>>>
>>> My data structure is complex so it's hard to give reproducible example but
>>> for example for two of my models I get the following errors in lmer() while
>>> lme() runs smoothly.
>>>
>>> 1- Error: cannot allocate vector of size 2.3 Gb.
>>>
>>> 2- Error: couldn't evaluate grouping factor id:(family:site) within model
>>> frame: try adding grouping factor to data frame explicitly if possible.
>>> (note that the id variable works for simpler lmer() models so the variable
>>> itself is not an issue)
>>>
>>> My model looks like the following nested structure:
>>> lmer(Y ~ 1 + X1 + X2 + X3 + (1|site/family/id), data=dd, REML = FALSE)
>>>
>>> Best,
>>>
>>> Hedyeh Ahmadi, Ph.D.
>>> Statistician
>>> Keck School of Medicine
>>> Department of Preventive Medicine
>>> University of Southern California
>>>
>>> Postdoctoral Scholar
>>> Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
>>> University of California, Irvine
>>>
>>> LinkedIn
>>> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$> 
> 
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$>>
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$ 
> 
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$>>
>>>>
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$ 
> 
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$>>
>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$ 
> 
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$>>
>>>>
>>>
>>>
>>>
>>>
>>> ________________________________
>>> From: Dexter Locke <dexter.locke at gmail.com>
>>> Sent: Friday, March 5, 2021 1:01 PM
>>> To: Hedyeh Ahmadi <hedyehah at usc.edu>
>>> Cc: r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>;
>>> Megan M. Herting <herting at usc.edu>; Elisabeth Burnor <burnor at usc.edu>
>>> Subject: Re: [R-sig-ME] A three-level GLMM with binomial link in R
>>>
>>> Hi Hedyeh,
>>>
>>> What is the problem you are having? Specifically, what is the estimation
>>> issue with lmer and lme?
>>>
>>> Can you provide a reproducible example? Can you provide the complete
>>> errors you are seeing?
>>>
>>> The current questions are vague, so it will be challenging for list
>>> members to provide much guidance.
>>>
>>> -Dexter
>>>
>>>
>>> On Fri, Mar 5, 2021 at 3:27 PM Hedyeh Ahmadi <hedyehah at usc.edu<mailto:
>>> hedyehah at usc.edu>> wrote:
>>> Hi All,
>>> I was wondering what would be a powerful package in R to run GLMM with
>>> logit link that can handle a data set with N=22945 and 3 nested random
>>> intercepts. So far, I have tried glmer() from lme4 and it's giving me a lot
>>> of estimation issues. Any other package I should try?
>>>
>>> I am asking for another package as I am having the same issue with lmer()
>>> for similar LMM with continuous outcome, while lme() from nlme package runs
>>> the models with no problem.
>>>
>>> Thank you in advance.
>>>
>>> Best,
>>>
>>> Hedyeh Ahmadi, Ph.D.
>>> Statistician
>>> Keck School of Medicine
>>> Department of Preventive Medicine
>>> University of Southern California
>>>
>>> Postdoctoral Scholar
>>> Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
>>> University of California, Irvine
>>>
>>> LinkedIn
>>> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$> 
> 
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$>>
>>> <
>>> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$>
>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$ 
> 
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$>>
>>> <
>>> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$>
>>>>>
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$ 
> 
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$>>
>>> <
>>> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$>
>>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$ 
> 
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$>>
>>> <
>>> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$>
>>>>>
>>>
>>>
>>>
>>>
>>>
>>>????????? [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org>
>>> mailing list
>>> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$ 
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$> 
> 
>>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKG8rJcsmY$ 
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKG8rJcsmY$>>
>>> <
>>> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQM6wKtNs$ 
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQM6wKtNs$>
>>>>
>>>
>>>????????? [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$ 
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$> 
> 
>>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKG8rJcsmY$ 
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKG8rJcsmY$>>
>>>
>>>
>> 
>>??????? [[alternative HTML version deleted]]
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$ 
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$> 
> 
>>
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$ 
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$> 
>


From g@rc|@mj @end|ng |rom tcd@|e  Wed Mar 10 05:58:04 2021
From: g@rc|@mj @end|ng |rom tcd@|e (Jorge Garcia Molinos)
Date: Wed, 10 Mar 2021 13:58:04 +0900
Subject: [R-sig-ME] glmmPQL: Temporal correlation structure for grouped data
 with observation gaps
In-Reply-To: <CACuLAKOL+6uq26U+Lz=FR8pyJ-SmMhMTKwaU_rPN8Wkiu450RQ@mail.gmail.com>
References: <CACuLAKOL+6uq26U+Lz=FR8pyJ-SmMhMTKwaU_rPN8Wkiu450RQ@mail.gmail.com>
Message-ID: <CACuLAKOKAh9BbXTm6gkzy4wu-sdiOybd-Pw75eot_cqxSseAOw@mail.gmail.com>

Dear list members,

I have a question regarding the implementation of a temporal correlation
structure in a GLMM context in R. This is my first time posting here so I
hope the question is suitable for this forum.

I have a data set that comprises summer (June-September) paired daily air
and water temperatures measured at 83 monitoring sites over a period of 3
years. The purpose is to predict water temperatures based on air
temperatures and a suite of environmental variables related to the
characteristics of the rivers and contributing catchment (land use, slope,
elevation and so on). The number of observations among sites differ somehow
(the series at some sites started at slightly different dates and some
sites have missing values within the series).

My approach so far has been as follows:

1. Fit a GLMM on water temperatures (WT) with air temperature (AT) and the
different environmental variables as fixed factors and site as random
factor (random intercept).

model <- glmmPQL(WT ~ AT + H2OArea + avEleE + RipB60_fdec + RipB60_fev,
random = ~1|Site, data = t_d, family = Gamma(link = "log"))

The reason for using glmmPQL is because of the need to incorporate a
temporal correlation structure (see point 2)

2. Given the nature of the data, temporal correlation is to be expected. A
check of acf and pacf functions on the model residuals by site shows
consistently a gradually decaying acf, and a sharp drop of the pacf below
the significance threshold after lag 1 (for which the pacf equals approx..
0.8), suggesting an AR1 process is suitable. Considering the different
observation gaps in the temperature series by station and the seasonal gaps
between years (only summer data), I decided to try with a corCAR1 structure
of the form:

modelAR <- update(m5, correlation = corCAR1(0.8, form = ~days|Site))

Where days correspond to the day number since the start of the series
across all sites (the first day an observation was made across all series).
That is:

t_d$days <- difftime(t_d$date, min(t_d$date), units = "days")

3. However, the acf and pacf plots for the residuals in the updated model
look nearly identical from those of the original model, which makes me
think that I have not specified the correlation structure or the time
variable correctly or that I?m missing something else?

An extract of the data set for a few stations can be downloaded here:

https://drive.google.com/file/d/1iMaXSSYvCJ1Xo09ZoJjbLdzmc0gjfJKy/view?usp=sharing

Any help/suggestions will be greatly appreciated!

Many thanks,
Jorge

	[[alternative HTML version deleted]]


From no@mt@|perry @end|ng |rom gm@||@com  Wed Mar 10 08:57:43 2021
From: no@mt@|perry @end|ng |rom gm@||@com (Noam Tal-Perry)
Date: Wed, 10 Mar 2021 09:57:43 +0200
Subject: [R-sig-ME] Modelling a variable that is continuous and constant
 under different conditions
Message-ID: <CA+bKFQR2rqtL4jKqEbCfNnQ6fSaZoZVfQHa1-TdNv=pjeJQ8FA@mail.gmail.com>

Hey everyone,

Need some assistance in thinking out a model that includes a variable that
is continuous under one condition, but constant under a different
condition.

Basically, participants in my task are given a cue, and after some time
(let's call this the foreperiod, FP), a target appears and they need to
respond to it. Under one distribution (random distribution), the foreperiod
varies between trials, say 0.5-1.5 seconds drawn from a
uniform distribution. Under a separate distribution (fixed distribution),
the foreperiod is constant, say 1 s. In both distributions, there are both
valid and invalid trials, and all participants are exposed to all
distributions and validity conditions (i.e. within-subject design).

I intend to measure RT, and usually what I do is to use polynomial (1st and
2nd order) contrasts on FP to describe the relation between FP and RT. Now
that obviously can't work under the fixed distribution, since there is only
a single value to FP.

To solve this issue, I was thinking perhaps to center the FP at the fixed
distribution's value, and then use treatment contrasts for distribution and
validity, with the fixed and valid levels set as the base levels. This way
the intercept will describe the RT at the fixed interval in the valid
condition. I plan to add FP and FP^2, but only as interaction terms with
the 2nd level of distribution (random distribution) since they make no
sense under the base level in this case. Other than that, I'll add validity
(effect of invalid trials in fixed distribution) and its interaction with
FP:Distribution (RT-FP slopes at random distribution in invalid trials).

In short, the model I have in mind looks like this:
RT ~ 1 + (FP + FP^2):Distribution +  Validity + (FP +
FP^2):Distribution:Validity + (1|subject)

Since I never quite did something like this, I wanted to run it by you guys
to make sure I am not overseeing something important or just plain wrong in
my reasoning.

Alternatively, I was also thinking perhaps to have the fixed FP changing
between blocks, such that it is always constant within a block, but has
several levels overall, which can then be modeled using polynomials.
However that would mean the FP polynomials will be fitted with numerous
datapoints at a few time points for the fixed distribution, and with few
datapoints in numerous time points for the random distribution, and I have
no idea whether that could be problematic or cause any bias in results.

Sorry for the long post, thanks in advance for your input!
Cheers,
Noam


Noam Tal-Perry
PhD student
Shlomit Yuval-Greenberg's Cognitive Neuroscience Lab
School of Psychological Sciences, Tel-Aviv University

	[[alternative HTML version deleted]]


From th|erry@onke||nx @end|ng |rom |nbo@be  Wed Mar 10 12:21:15 2021
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Wed, 10 Mar 2021 12:21:15 +0100
Subject: [R-sig-ME] 
 glmmPQL: Temporal correlation structure for grouped data
 with observation gaps
In-Reply-To: <CACuLAKOKAh9BbXTm6gkzy4wu-sdiOybd-Pw75eot_cqxSseAOw@mail.gmail.com>
References: <CACuLAKOL+6uq26U+Lz=FR8pyJ-SmMhMTKwaU_rPN8Wkiu450RQ@mail.gmail.com>
 <CACuLAKOKAh9BbXTm6gkzy4wu-sdiOybd-Pw75eot_cqxSseAOw@mail.gmail.com>
Message-ID: <CAJuCY5zKgqp0ydrWYhcmRzo9QeMwf9xSppSa4wqTb=Dyz=ZNFg@mail.gmail.com>

Dear Jorge,

glmmPQL is not the only option if you need a correlation structure. glmmTMB
and INLA allow for correlated random effects. That is IMHO superior to
correlated residuals within the most detailed levels of the random effect
(what nlme does).

Furthermore you need the normalised residuals, as they take the correlation
structure into account.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op wo 10 mrt. 2021 om 05:58 schreef Jorge Garcia Molinos <garciamj at tcd.ie>:

> Dear list members,
>
> I have a question regarding the implementation of a temporal correlation
> structure in a GLMM context in R. This is my first time posting here so I
> hope the question is suitable for this forum.
>
> I have a data set that comprises summer (June-September) paired daily air
> and water temperatures measured at 83 monitoring sites over a period of 3
> years. The purpose is to predict water temperatures based on air
> temperatures and a suite of environmental variables related to the
> characteristics of the rivers and contributing catchment (land use, slope,
> elevation and so on). The number of observations among sites differ somehow
> (the series at some sites started at slightly different dates and some
> sites have missing values within the series).
>
> My approach so far has been as follows:
>
> 1. Fit a GLMM on water temperatures (WT) with air temperature (AT) and the
> different environmental variables as fixed factors and site as random
> factor (random intercept).
>
> model <- glmmPQL(WT ~ AT + H2OArea + avEleE + RipB60_fdec + RipB60_fev,
> random = ~1|Site, data = t_d, family = Gamma(link = "log"))
>
> The reason for using glmmPQL is because of the need to incorporate a
> temporal correlation structure (see point 2)
>
> 2. Given the nature of the data, temporal correlation is to be expected. A
> check of acf and pacf functions on the model residuals by site shows
> consistently a gradually decaying acf, and a sharp drop of the pacf below
> the significance threshold after lag 1 (for which the pacf equals approx..
> 0.8), suggesting an AR1 process is suitable. Considering the different
> observation gaps in the temperature series by station and the seasonal gaps
> between years (only summer data), I decided to try with a corCAR1 structure
> of the form:
>
> modelAR <- update(m5, correlation = corCAR1(0.8, form = ~days|Site))
>
> Where days correspond to the day number since the start of the series
> across all sites (the first day an observation was made across all series).
> That is:
>
> t_d$days <- difftime(t_d$date, min(t_d$date), units = "days")
>
> 3. However, the acf and pacf plots for the residuals in the updated model
> look nearly identical from those of the original model, which makes me
> think that I have not specified the correlation structure or the time
> variable correctly or that I?m missing something else?
>
> An extract of the data set for a few stations can be downloaded here:
>
>
> https://drive.google.com/file/d/1iMaXSSYvCJ1Xo09ZoJjbLdzmc0gjfJKy/view?usp=sharing
>
> Any help/suggestions will be greatly appreciated!
>
> Many thanks,
> Jorge
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From ybe||o @end|ng |rom |udut@|nm@@edu@ng  Wed Mar 10 17:45:13 2021
From: ybe||o @end|ng |rom |udut@|nm@@edu@ng (BELLO YUSUF)
Date: Wed, 10 Mar 2021 17:45:13 +0100
Subject: [R-sig-ME] Comparison of conditional AIC (cAIC) from two or more
 LMMs
Message-ID: <CAKf-Z26M1uNKq9f_mW8yzZT3o3CGy9yKK4S+AGftxuRdpv6pAg@mail.gmail.com>

a) Can I compare the AICs obtained from lm and lmer modeled from the same
data set?

b) I want to see if models (lmer) from the correlations (similarities) of
observations obtained from classifications by means of cluster analysis
performed better than models from correlations of observations obtained
from natural (initial) clustering.

I have a crime data of 300 local divisions (level 1 units) unevenly
distributed across 40 districts (level 2 units). I call it Data1. I decided
to use cluster analysis to reclassify the level 1 units to obtain 40 new
clusters of similar crime concentrations, and so new cluster membership was
obtained differently from Data1. I call the second classification as Data2.
Note that the same level 1 units and size were maintained in the two data
sets, but with differences in cluster membership. I used lmer to model the
two data sets.

?         Data 1 & 2 have 40 clusters each, same level 1 size, same level 1
units and same df. residuals, but with differences in cluster membership.

1.       If the conditional AIC (cAIC) for model1 {Data1) is 1032.4 and the
cAIC for model2 {Data2)  is 872.1, can I say model2 better fit the data
than model1?

2.       I reclassify the initial data set and got 30 new optimal clusters
by similarity and named it Data3,

?         such that Data3 has 30 clusters and Data 1 & 2 have 40 clusters
each;

?         All have the same level 1 sizes, same level 1 units and same df.
residuals but with differences in cluster membership. If the cAIC is 903.7
from model3, can I say model2 is better than model3?

	[[alternative HTML version deleted]]


From hedyeh@h @end|ng |rom u@c@edu  Thu Mar 11 19:11:59 2021
From: hedyeh@h @end|ng |rom u@c@edu (Hedyeh Ahmadi)
Date: Thu, 11 Mar 2021 18:11:59 +0000
Subject: [R-sig-ME] A three-level GLMM with binomial link in R
In-Reply-To: <a8005560-3957-e814-df74-604d9cb857bb@gmail.com>
References: <BYAPR07MB50945A60AFDE467F317861ACD1969@BYAPR07MB5094.namprd07.prod.outlook.com>
 <CAA=SVwH2pE+EAtEqALjeRPT91tWz-HJegrQkz9mYqfj7pb_A1Q@mail.gmail.com>
 <BYAPR07MB50947CD020DADA71CFF86407D1969@BYAPR07MB5094.namprd07.prod.outlook.com>
 <CA+3TTkNL+JGE+pgfOqASfvJ+r5eHmbGt3v+FzazouVePs_=x9Q@mail.gmail.com>
 <BYAPR07MB509450F1132EEB7C41F60B4CD1969@BYAPR07MB5094.namprd07.prod.outlook.com>
 <CA+3TTkM-abt0u4Je03nnTBBKiZw4AFj-UdPfyP_JOLZbDiJEFA@mail.gmail.com>
 <9e903a9f-5bec-934c-0b50-b2fca97cd4f3@gmail.com>
 <BYAPR07MB5094069BFA432F89688D34DCD1939@BYAPR07MB5094.namprd07.prod.outlook.com>,
 <a8005560-3957-e814-df74-604d9cb857bb@gmail.com>
Message-ID: <BYAPR07MB5094DD4608A0B5DB96A52EB5D1909@BYAPR07MB5094.namprd07.prod.outlook.com>

Hi Ben,
Thank you for all the help and informative replies. Here is some info about my data and my answers:

  *   Yes, I am running the exact model however this is just my toy model to get the code to work.
  *   Reminder, I am trying to get lmer with a continuous outcome (but same data structure, with 3 random intercept) work before moving to glmer() with a logit link with a categorical 0/1 outcome.
  *   Here are some information about my data:
     *   X1: num [1:22945] 9.25 NA 9.22 NA 9.22 NA 9.42 NA 9.25 NA ...
     *   X2: int [1:22945] 117 140 128 125 113 138 126 130 120 121 ...
     *   X3: chr [1:22945] "Female" "Male" "Male" "Male" "Male"
     *   site: chr [1:22945] "site15" "site15" "site15" "site15" "site15" ... (I have 21 sites)
     *   family: int [1:22945] 0 1 1 1 1 3 3 4 4 5 ...
     *   id: chr [1:22945] "id1" "id2" "id2" "id3" "id3"...
  *   The following model gives me the error that "Error: couldn't evaluate grouping factor id:(family:site) within model frame: try adding grouping factor to data frame explicitly if possible" - I ran this same model on a supercomputer and it gave me the same error, so this is not a memory limit issue.
     *   m2 <- lmer(cbcl_scr_syn_internal_r ~ 1 + X1 + X2 + X3 + (1|site/family/id),  data=dd, REML = FALSE)
  *   The following model ran on a supercomputer.  This is the model that previously would give me the error "Error: cannot allocate vector of size 2.3 Gb". Here I am reducing the number of sites to see if it runs, and it did run on a supercomputer.
     *   m11 <- lmer(cbcl_scr_syn_internal_r ~ 1 + X1 +X2 + X3 +(1|site/family/id) ,
    data=dd[-which(dd$abcd_site %in% c("site01","site02", "site04", "site05", "site06", "site07", "site08","site09")),],  na.action=na.exclude, REML=FALSE)

Questions:

  1.  What I don't understand is that in m2, why lmer() does not recognizes the grouping factor that it does recognize in m11?
  2.  At this point I don't think this is a memory issue as m2 did not run on a supercomputer and it's giving me the same error as my personal computer. However, in m11, the same grouping structure is being recognized when I reduce the number of sites from 21 to 13 - could this be because of severe imbalance in my family/id nesting, meaning most families have only one kid but some have 2 and a few have 3 kids?

Sorry about the long email and thank you for your help in advance.

Best,

Hedyeh Ahmadi, Ph.D.
Statistician
Keck School of Medicine
Department of Preventive Medicine
University of Southern California

Postdoctoral Scholar
Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
University of California, Irvine

LinkedIn
www.linkedin.com/in/hedyeh-ahmadi<http://www.linkedin.com/in/hedyeh-ahmadi>
<http://www.linkedin.com/in/hedyeh-ahmadi><http://www.linkedin.com/in/hedyeh-ahmadi>




________________________________
From: Ben Bolker <bbolker at gmail.com>
Sent: Tuesday, March 9, 2021 4:12 PM
To: Hedyeh Ahmadi <hedyehah at usc.edu>; r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] A three-level GLMM with binomial link in R

   OK, then it would be very helpful to have more details about your
data set. Are one or more of X1, X2, X3 categorical predictors with many
levels ... ?  Any chance we can see str() or summary() ?  Are you using
exactly the formula you told us about, or something slightly different?

   The computational burden of a large number of fixed effect parameters
will be much worse for glmer than for lmer, unless you use nAGQ=0.
glmmTMB would be able to help in two ways: (1) it doesn't scale as badly
for large numbers of fixed effects; (2) it allows sparse fixed-effect
model matrices (something we keep meaning to (re)implement in lme4) ...

  Making X1 into a 1000-level factor brings the required memory up by
about a factor of 10 and increases the run time from seconds to minutes.


Base model:

                      Function_Call Elapsed_Time_sec Total_RAM_Used_MiB
1 m<-lmer(form,data=dd,REML=FALSE)            1.903               10.4
   Peak_RAM_Used_MiB
1             107.7

With X=1000-level factor (no derivative calculations):

  Function_Call
1
m2<-lmer(form,data=dd2,REML=FALSE,control=lmerControl(calc.derivs=FALSE),verbose=10)
   Elapsed_Time_sec Total_RAM_Used_MiB Peak_RAM_Used_MiB
1          559.735              608.8             984.5


With derivative calculation at the end:

                                  Function_Call Elapsed_Time_sec
1 m3<-lmer(form,data=dd2,REML=FALSE,verbose=10)          677.975
   Total_RAM_Used_MiB Peak_RAM_Used_MiB
1              608.7            1148.7
 >
 >

---
ibrary(lme4)
set.seed(101)
N <- 22945
ns <- 100
nf <- 100
nid <- 100
dd <- data.frame(X1=rnorm(N),
                  X2=rnorm(N),
                  X3=rnorm(N),
                  site=sample(ns, replace=TRUE, size=N),
                  family=sample(nf, replace=TRUE, size=N),
                  id=sample(nid, replace=TRUE, size=N))
form <- Y ~ 1 + X1 + X2 + X3 + (1|site/family/id)
dd$Y <- simulate(form[-2], newdata=dd, family=gaussian,
                  newparams=list(beta=rep(1,4),theta=rep(1,3),sigma=1))[[1]]
library(peakRAM)
system.time(mem <- peakRAM(
     m <- lmer(form, data=dd, REML=FALSE)
     ))
print(mem)

dd2 <- transform(dd,
         X1=factor(sample(1000,size=N,replace=TRUE)))

system.time(mem2 <- peakRAM(
     m2 <- lmer(form, data=dd2, REML=FALSE,
control=lmerControl(calc.derivs=FALSE), verbose=10)
))
print(mem2)

system.time(mem3 <- peakRAM(
     m3 <- lmer(form, data=dd2, REML=FALSE, verbose=10)
))
print(mem3)


On 3/8/21 11:29 AM, Hedyeh Ahmadi wrote:
> Thank you for the toy example. This same example in my PC gives the
> following memory use output:
>
>
>  > mem
>                       Function_Call
> Elapsed_Time_sec         Total_RAM_Used_MiB    Peak_RAM_Used_MiB
>    m<-lmer(form,data=dd,REML=FALSE)             2.64
>                  10.3                                       130.1
>
> When I run peakRAM() for my actual data, it take one hour plus then my
> PC slows down, then I have to stop R to be able to use my PC.
>
> Best,
>
> Hedyeh Ahmadi, Ph.D.
> Statistician
> Keck School of Medicine
> Department of Preventive Medicine
> University of Southern California
>
> Postdoctoral Scholar
> Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
> University of California, Irvine
>
> LinkedIn
> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5O8KlsAUILt44__IHSzbCUgVs7dWxAB8FS9wiKC3j5P6hGrnuJSGckmCIR91AZs$  <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5O8KlsAUILt44__IHSzbCUgVs7dWxAB8FS9wiKC3j5P6hGrnuJSGckmCIR91AZs$ >
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5O8KlsAUILt44__IHSzbCUgVs7dWxAB8FS9wiKC3j5P6hGrnuJSGckmCIR91AZs$ ><https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5O8KlsAUILt44__IHSzbCUgVs7dWxAB8FS9wiKC3j5P6hGrnuJSGckmCIR91AZs$ >
>
>
>
>
> ------------------------------------------------------------------------
> *From:* R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on
> behalf of Ben Bolker <bbolker at gmail.com>
> *Sent:* Friday, March 5, 2021 5:44 PM
> *To:* r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>
> *Subject:* Re: [R-sig-ME] A three-level GLMM with binomial link in R
>     Here's an example that conforms approximately to the structure of
> your data: on my machine the peak RAM usage is 121 Mb, far short of your
> 2.3 Gb ...  so I still suspect there is something going on that we don't
> know about/haven't guessed yet.
>
> set.seed(101)
> N <- 22945
> ns <- 100
> nf <- 100
> nid <- 100
> dd <- data.frame(X1=rnorm(N),
>                    X2=rnorm(N),
>                    X3=rnorm(N),
>                    site=sample(ns, replace=TRUE, size=N),
>                    family=sample(nf, replace=TRUE, size=N),
>                    id=sample(nid, replace=TRUE, size=N))
> form <- Y ~ 1 + X1 + X2 + X3 + (1|site/family/id)
> dd$Y <- simulate(form[-2], newdata=dd, family=gaussian,
>
> newparams=list(beta=rep(1,4),theta=rep(1,3),sigma=1))[[1]]
> library(peakRAM)
> mem <- peakRAM(
>       m <- lmer(form, data=dd, REML=FALSE)
> )
>
> mem
>                        Function_Call Elapsed_Time_sec Total_RAM_Used_MiB
> 1 m<-lmer(form,data=dd,REML=FALSE)            1.754               10.3
>     Peak_RAM_Used_MiB
> 1             120.7
>
>
> On 3/5/21 4:52 PM, Robert Long wrote:
>> Perhaps because of the different ways they store objects internally while
>> fitting the models.
>>
>> On Fri, 5 Mar 2021, 21:47 Hedyeh Ahmadi, <hedyehah at usc.edu> wrote:
>>
>>> Thank you for the reply Robert - If I am running out of memory in lmer(),
>>> do you know why lme() runs just fine?
>>>
>>> Best,
>>>
>>> Hedyeh Ahmadi, Ph.D.
>>> Statistician
>>> Keck School of Medicine
>>> Department of Preventive Medicine
>>> University of Southern California
>>>
>>> Postdoctoral Scholar
>>> Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
>>> University of California, Irvine
>>>
>>> LinkedIn
>>> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$>
>
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$
>  >
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$
>  >
>>>
>>>
>>>
>>>
>>> ------------------------------
>>> *From:* Robert Long <longrob604 at gmail.com>
>>> *Sent:* Friday, March 5, 2021 1:43 PM
>>> *To:* Hedyeh Ahmadi <hedyehah at usc.edu>
>>> *Cc:* Dexter Locke <dexter.locke at gmail.com>; R-mixed models mailing list <
>>> r-sig-mixed-models at r-project.org>; Megan M. Herting <herting at usc.edu>;
>>> Elisabeth Burnor <burnor at usc.edu>
>>> *Subject:* Re: [R-sig-ME] A three-level GLMM with binomial link in R
>>>
>>> You've run out of memory. Try running it on a machine with much larger RAM.
>>>
>>> On Fri, 5 Mar 2021, 21:18 Hedyeh Ahmadi, <hedyehah at usc.edu> wrote:
>>>
>>> Hi - Thank you for the informative replies.
>>>
>>> I will try those other packages. If MASS::glmmPQL uses lme() then this
>>> should work for me.
>>>
>>> My data structure is complex so it's hard to give reproducible example but
>>> for example for two of my models I get the following errors in lmer() while
>>> lme() runs smoothly.
>>>
>>> 1- Error: cannot allocate vector of size 2.3 Gb.
>>>
>>> 2- Error: couldn't evaluate grouping factor id:(family:site) within model
>>> frame: try adding grouping factor to data frame explicitly if possible.
>>> (note that the id variable works for simpler lmer() models so the variable
>>> itself is not an issue)
>>>
>>> My model looks like the following nested structure:
>>> lmer(Y ~ 1 + X1 + X2 + X3 + (1|site/family/id), data=dd, REML = FALSE)
>>>
>>> Best,
>>>
>>> Hedyeh Ahmadi, Ph.D.
>>> Statistician
>>> Keck School of Medicine
>>> Department of Preventive Medicine
>>> University of Southern California
>>>
>>> Postdoctoral Scholar
>>> Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
>>> University of California, Irvine
>>>
>>> LinkedIn
>>> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$>
>
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$>>
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$
>
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$>>
>>>>
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$
>
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$>>
>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$
>
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$>>
>>>>
>>>
>>>
>>>
>>>
>>> ________________________________
>>> From: Dexter Locke <dexter.locke at gmail.com>
>>> Sent: Friday, March 5, 2021 1:01 PM
>>> To: Hedyeh Ahmadi <hedyehah at usc.edu>
>>> Cc: r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>;
>>> Megan M. Herting <herting at usc.edu>; Elisabeth Burnor <burnor at usc.edu>
>>> Subject: Re: [R-sig-ME] A three-level GLMM with binomial link in R
>>>
>>> Hi Hedyeh,
>>>
>>> What is the problem you are having? Specifically, what is the estimation
>>> issue with lmer and lme?
>>>
>>> Can you provide a reproducible example? Can you provide the complete
>>> errors you are seeing?
>>>
>>> The current questions are vague, so it will be challenging for list
>>> members to provide much guidance.
>>>
>>> -Dexter
>>>
>>>
>>> On Fri, Mar 5, 2021 at 3:27 PM Hedyeh Ahmadi <hedyehah at usc.edu<mailto:
>>> hedyehah at usc.edu>> wrote:
>>> Hi All,
>>> I was wondering what would be a powerful package in R to run GLMM with
>>> logit link that can handle a data set with N=22945 and 3 nested random
>>> intercepts. So far, I have tried glmer() from lme4 and it's giving me a lot
>>> of estimation issues. Any other package I should try?
>>>
>>> I am asking for another package as I am having the same issue with lmer()
>>> for similar LMM with continuous outcome, while lme() from nlme package runs
>>> the models with no problem.
>>>
>>> Thank you in advance.
>>>
>>> Best,
>>>
>>> Hedyeh Ahmadi, Ph.D.
>>> Statistician
>>> Keck School of Medicine
>>> Department of Preventive Medicine
>>> University of Southern California
>>>
>>> Postdoctoral Scholar
>>> Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
>>> University of California, Irvine
>>>
>>> LinkedIn
>>> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$>
>
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$>>
>>> <
>>> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$>
>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$
>
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$>>
>>> <
>>> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$>
>>>>>
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$
>
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$>>
>>> <
>>> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$>
>>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$
>
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$>>
>>> <
>>> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$>
>>>>>
>>>
>>>
>>>
>>>
>>>
>>>          [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org>
>>> mailing list
>>> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$>
>
>>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKG8rJcsmY$
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKG8rJcsmY$>>
>>> <
>>> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQM6wKtNs$
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQM6wKtNs$>
>>>>
>>>
>>>          [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$>
>
>>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKG8rJcsmY$
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKG8rJcsmY$>>
>>>
>>>
>>
>>        [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$>
>
>>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$>
>

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Fri Mar 12 00:55:54 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Thu, 11 Mar 2021 18:55:54 -0500
Subject: [R-sig-ME] A three-level GLMM with binomial link in R
In-Reply-To: <BYAPR07MB5094DD4608A0B5DB96A52EB5D1909@BYAPR07MB5094.namprd07.prod.outlook.com>
References: <BYAPR07MB50945A60AFDE467F317861ACD1969@BYAPR07MB5094.namprd07.prod.outlook.com>
 <CAA=SVwH2pE+EAtEqALjeRPT91tWz-HJegrQkz9mYqfj7pb_A1Q@mail.gmail.com>
 <BYAPR07MB50947CD020DADA71CFF86407D1969@BYAPR07MB5094.namprd07.prod.outlook.com>
 <CA+3TTkNL+JGE+pgfOqASfvJ+r5eHmbGt3v+FzazouVePs_=x9Q@mail.gmail.com>
 <BYAPR07MB509450F1132EEB7C41F60B4CD1969@BYAPR07MB5094.namprd07.prod.outlook.com>
 <CA+3TTkM-abt0u4Je03nnTBBKiZw4AFj-UdPfyP_JOLZbDiJEFA@mail.gmail.com>
 <9e903a9f-5bec-934c-0b50-b2fca97cd4f3@gmail.com>
 <BYAPR07MB5094069BFA432F89688D34DCD1939@BYAPR07MB5094.namprd07.prod.outlook.com>
 <a8005560-3957-e814-df74-604d9cb857bb@gmail.com>
 <BYAPR07MB5094DD4608A0B5DB96A52EB5D1909@BYAPR07MB5094.namprd07.prod.outlook.com>
Message-ID: <971aa7fc-a424-154d-c451-3027988f3c55@gmail.com>



On 3/11/21 1:11 PM, Hedyeh Ahmadi wrote:
> Hi Ben,
> Thank you for all the help and informative replies. Here is some info 
> about my data and my answers:
> 
>   * Yes, I am running the exact model however this is just my toy model
>     to get the code to work.
>   * Reminder, I am trying to get lmer with a continuous outcome (but
>     same data structure, with 3 random intercept) work before moving to
>     glmer() with a logit link with a categorical 0/1 outcome.
>   * Here are some information about my data:
>       o X1: num [1:22945] 9.25 NA 9.22 NA 9.22 NA 9.42 NA 9.25 NA ...
>       o X2: int [1:22945] 117 140 128 125 113 138 126 130 120 121 ...
>       o X3: chr [1:22945] "Female" "Male" "Male" "Male" "Male"
>       o site: chr [1:22945] "site15" "site15" "site15" "site15" "site15"
>         ... (I have 21 sites)
>       o family: int [1:22945] 0 1 1 1 1 3 3 4 4 5 ...
>       o id: chr [1:22945] "id1" "id2" "id2" "id3" "id3"...
>   * The following model gives me the error that "Error: couldn't
>     evaluate grouping factor id:(family:site) within model frame: try
>     adding grouping factor to data frame explicitly if possible" - I ran
>     this same model on a supercomputer and it *gave me the same error*,
>     so this is not a memory limit issue.

So far I can't replicate this.  It seemed fishy to me that family was an 
integer (I would try explicitly converting it to a factor), but doesn't 
actually cause any problems in my example.

  (This differs from your example but not in ways I would expect to be 
important: in particular, the types of the grouping variables are the 
same [chr, int, chr]

n <- 10000
set.seed(101)
dd <- data.frame(y=rnorm(n),
                  x1=rnorm(n),
                  x2=rnorm(n),
                  x3=rnorm(n),
                  site=sample(paste0("s",1:15),size=n,replace=TRUE),
                  family=sample(1:100,size=n,replace=TRUE),
                  id=sample(paste0("id",1:20),size=n,replace=TRUE))
library(lme4)
lmer(y~1 + x1 + x2 + x3 + (1|site/family/id), data=dd)

###

What is meant by "adding grouping factor to data frame explicitly" would 
be in this case expanding out the nested terms:

  dd <- within(dd,
{
     site_family <- interaction(site,family)
     site_family_id <- interaction(site,family,id)
})

lmer(y~1 + x1 + x2 + x3 + (1|site) + (1|site_family) + 
(1|site_family_id), data =dd)



>       o m2 <- lmer(cbcl_scr_syn_internal_r ~ 1 + X1 + X2 + X3 +
>         (1|site/family/id), data=dd, REML = FALSE)
>   * The following *model ran on a supercomputer*.? This is the model
>     that previously would give me the error "Error: cannot allocate
>     vector of size 2.3 Gb". Here I am*reducing the number of sites to
>     see if it runs, and it did* run on a supercomputer.
>       o m11 <- lmer(cbcl_scr_syn_internal_r ~ 1 + X1 +X2 + X3
>         +(1|site/family/id) ,
>          ? ? data=dd[-which(dd$abcd_site %in% c("site01","site02",
>         "site04", "site05", "site06", "site07", "site08","site09")),],
>         na.action=na.exclude, REML=FALSE)
> 
> Questions:
> 
>  1. What I don't understand is that in m2, why lmer() does not
>     recognizes the grouping factor that it does recognize in m11?

  I'm not sure either.

>  2. At this point I don't think this is a memory issue as *m2 did not
>     run on a supercompute*r and it's giving me *the same error as my
>     personal computer*. However, in m11, the same grouping structure is
>     being recognized when I reduce the number of sites from 21 to 13 -
>     could this be because of severe imbalance in my family/id nesting,
>     meaning most families have only one kid but some have 2 and a few
>     have 3 kids?

   It seems surprising.
   Is there any way we can get a reproducible example?  For example, 
suppose you randomize your X1, X2, X3 and anonymize all of your grouping 
variables: would you then be able to share the data set?

   Does the problem (let's say just the first problem) still occur if 
you leave out the fixed effects? (I would expect so, and that would 
simplify things somewhat - we're trying to get to the *simplest* example 
that still demonstrates the problem.)


> 
> Sorry about the long email and thank you for your help in advance.
> 
> Best,
> 
> Hedyeh Ahmadi, Ph.D.
> Statistician
> Keck School of Medicine
> Department of Preventive Medicine
> University of Southern California
> 
> Postdoctoral Scholar
> Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
> University of California, Irvine
> 
> LinkedIn
> www.linkedin.com/in/hedyeh-ahmadi <http://www.linkedin.com/in/hedyeh-ahmadi>
> <http://www.linkedin.com/in/hedyeh-ahmadi><http://www.linkedin.com/in/hedyeh-ahmadi>
> 
> 
> 
> 
> ------------------------------------------------------------------------
> *From:* Ben Bolker <bbolker at gmail.com>
> *Sent:* Tuesday, March 9, 2021 4:12 PM
> *To:* Hedyeh Ahmadi <hedyehah at usc.edu>; r-sig-mixed-models at r-project.org 
> <r-sig-mixed-models at r-project.org>
> *Subject:* Re: [R-sig-ME] A three-level GLMM with binomial link in R
>  ?? OK, then it would be very helpful to have more details about your
> data set. Are one or more of X1, X2, X3 categorical predictors with many
> levels ... ?? Any chance we can see str() or summary() ?? Are you using
> exactly the formula you told us about, or something slightly different?
> 
>  ?? The computational burden of a large number of fixed effect parameters
> will be much worse for glmer than for lmer, unless you use nAGQ=0.
> glmmTMB would be able to help in two ways: (1) it doesn't scale as badly
> for large numbers of fixed effects; (2) it allows sparse fixed-effect
> model matrices (something we keep meaning to (re)implement in lme4) ...
> 
>  ? Making X1 into a 1000-level factor brings the required memory up by
> about a factor of 10 and increases the run time from seconds to minutes.
> 
> 
> Base model:
> 
>  ????????????????????? Function_Call Elapsed_Time_sec Total_RAM_Used_MiB
> 1 m<-lmer(form,data=dd,REML=FALSE)??????????? 1.903?????????????? 10.4
>  ?? Peak_RAM_Used_MiB
> 1???????????? 107.7
> 
> With X=1000-level factor (no derivative calculations):
> 
>  ? Function_Call
> 1
> m2<-lmer(form,data=dd2,REML=FALSE,control=lmerControl(calc.derivs=FALSE),verbose=10)
>  ?? Elapsed_Time_sec Total_RAM_Used_MiB Peak_RAM_Used_MiB
> 1????????? 559.735????????????? 608.8???????????? 984.5
> 
> 
> With derivative calculation at the end:
> 
>  ????????????????????????????????? Function_Call Elapsed_Time_sec
> 1 m3<-lmer(form,data=dd2,REML=FALSE,verbose=10)????????? 677.975
>  ?? Total_RAM_Used_MiB Peak_RAM_Used_MiB
> 1????????????? 608.7??????????? 1148.7
>  ?>
>  ?>
> 
> ---
> ibrary(lme4)
> set.seed(101)
> N <- 22945
> ns <- 100
> nf <- 100
> nid <- 100
> dd <- data.frame(X1=rnorm(N),
>  ????????????????? X2=rnorm(N),
>  ????????????????? X3=rnorm(N),
>  ????????????????? site=sample(ns, replace=TRUE, size=N),
>  ????????????????? family=sample(nf, replace=TRUE, size=N),
>  ????????????????? id=sample(nid, replace=TRUE, size=N))
> form <- Y ~ 1 + X1 + X2 + X3 + (1|site/family/id)
> dd$Y <- simulate(form[-2], newdata=dd, family=gaussian,
>                    
> newparams=list(beta=rep(1,4),theta=rep(1,3),sigma=1))[[1]]
> library(peakRAM)
> system.time(mem <- peakRAM(
>  ???? m <- lmer(form, data=dd, REML=FALSE)
>  ???? ))
> print(mem)
> 
> dd2 <- transform(dd,
>  ???????? X1=factor(sample(1000,size=N,replace=TRUE)))
> 
> system.time(mem2 <- peakRAM(
>  ???? m2 <- lmer(form, data=dd2, REML=FALSE,
> control=lmerControl(calc.derivs=FALSE), verbose=10)
> ))
> print(mem2)
> 
> system.time(mem3 <- peakRAM(
>  ???? m3 <- lmer(form, data=dd2, REML=FALSE, verbose=10)
> ))
> print(mem3)
> 
> 
> On 3/8/21 11:29 AM, Hedyeh Ahmadi wrote:
>> Thank you for the toy example. This same example in my PC gives the 
>> following memory use output:
>> 
>> 
>>? > mem
>>? ? ? ? ? ? ? ? ? ? ? ?Function_Call                            
>> Elapsed_Time_sec ? ? ? ? Total_RAM_Used_MiB ?? Peak_RAM_Used_MiB
>>? ? m<-lmer(form,data=dd,REML=FALSE) ? ? ? ? ? ? 2.64                     
>>? ? ? ? ? ? ? ? ? 10.3 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 130.1
>> 
>> When I run peakRAM() for my actual data, it take one hour plus then my 
>> PC slows down, then I have to stop R to be able to use my PC.
>> 
>> Best,
>> 
>> Hedyeh Ahmadi, Ph.D.
>> Statistician
>> Keck School of Medicine
>> Department of Preventive Medicine
>> University of Southern California
>> 
>> Postdoctoral Scholar
>> Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
>> University of California, Irvine
>> 
>> LinkedIn
>> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5O8KlsAUILt44__IHSzbCUgVs7dWxAB8FS9wiKC3j5P6hGrnuJSGckmCIR91AZs$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5O8KlsAUILt44__IHSzbCUgVs7dWxAB8FS9wiKC3j5P6hGrnuJSGckmCIR91AZs$>  
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5O8KlsAUILt44__IHSzbCUgVs7dWxAB8FS9wiKC3j5P6hGrnuJSGckmCIR91AZs$ 
>  >
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5O8KlsAUILt44__IHSzbCUgVs7dWxAB8FS9wiKC3j5P6hGrnuJSGckmCIR91AZs$ 
>  ><https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5O8KlsAUILt44__IHSzbCUgVs7dWxAB8FS9wiKC3j5P6hGrnuJSGckmCIR91AZs$ >
>> 
>> 
>> 
>> 
>> ------------------------------------------------------------------------
>> *From:* R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on 
>> behalf of Ben Bolker <bbolker at gmail.com>
>> *Sent:* Friday, March 5, 2021 5:44 PM
>> *To:* r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>
>> *Subject:* Re: [R-sig-ME] A three-level GLMM with binomial link in R
>>? ?? Here's an example that conforms approximately to the structure of
>> your data: on my machine the peak RAM usage is 121 Mb, far short of your
>> 2.3 Gb ...? so I still suspect there is something going on that we don't
>> know about/haven't guessed yet.
>> 
>> set.seed(101)
>> N <- 22945
>> ns <- 100
>> nf <- 100
>> nid <- 100
>> dd <- data.frame(X1=rnorm(N),
>>? ????????????????? X2=rnorm(N),
>>? ????????????????? X3=rnorm(N),
>>? ????????????????? site=sample(ns, replace=TRUE, size=N),
>>? ????????????????? family=sample(nf, replace=TRUE, size=N),
>>? ????????????????? id=sample(nid, replace=TRUE, size=N))
>> form <- Y ~ 1 + X1 + X2 + X3 + (1|site/family/id)
>> dd$Y <- simulate(form[-2], newdata=dd, family=gaussian,
>>                    
>> newparams=list(beta=rep(1,4),theta=rep(1,3),sigma=1))[[1]]
>> library(peakRAM)
>> mem <- peakRAM(
>>? ???? m <- lmer(form, data=dd, REML=FALSE)
>> )
>> 
>> mem
>>? ????????????????????? Function_Call Elapsed_Time_sec Total_RAM_Used_MiB
>> 1 m<-lmer(form,data=dd,REML=FALSE)??????????? 1.754?????????????? 10.3
>>? ?? Peak_RAM_Used_MiB
>> 1???????????? 120.7
>> 
>> 
>> On 3/5/21 4:52 PM, Robert Long wrote:
>>> Perhaps because of the different ways they store objects internally while
>>> fitting the models.
>>> 
>>> On Fri, 5 Mar 2021, 21:47 Hedyeh Ahmadi, <hedyehah at usc.edu> wrote:
>>> 
>>>> Thank you for the reply Robert - If I am running out of memory in lmer(),
>>>> do you know why lme() runs just fine?
>>>>
>>>> Best,
>>>>
>>>> Hedyeh Ahmadi, Ph.D.
>>>> Statistician
>>>> Keck School of Medicine
>>>> Department of Preventive Medicine
>>>> University of Southern California
>>>>
>>>> Postdoctoral Scholar
>>>> Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
>>>> University of California, Irvine
>>>>
>>>> LinkedIn
>>>> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$> 
> 
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$>> 
> 
>> 
>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$ 
> 
>>? >
>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$ 
> 
>>? >
>>>>
>>>>
>>>>
>>>>
>>>> ------------------------------
>>>> *From:* Robert Long <longrob604 at gmail.com>
>>>> *Sent:* Friday, March 5, 2021 1:43 PM
>>>> *To:* Hedyeh Ahmadi <hedyehah at usc.edu>
>>>> *Cc:* Dexter Locke <dexter.locke at gmail.com>; R-mixed models mailing list <
>>>> r-sig-mixed-models at r-project.org>; Megan M. Herting <herting at usc.edu>;
>>>> Elisabeth Burnor <burnor at usc.edu>
>>>> *Subject:* Re: [R-sig-ME] A three-level GLMM with binomial link in R
>>>>
>>>> You've run out of memory. Try running it on a machine with much larger RAM.
>>>>
>>>> On Fri, 5 Mar 2021, 21:18 Hedyeh Ahmadi, <hedyehah at usc.edu> wrote:
>>>>
>>>> Hi - Thank you for the informative replies.
>>>>
>>>> I will try those other packages. If MASS::glmmPQL uses lme() then this
>>>> should work for me.
>>>>
>>>> My data structure is complex so it's hard to give reproducible example but
>>>> for example for two of my models I get the following errors in lmer() while
>>>> lme() runs smoothly.
>>>>
>>>> 1- Error: cannot allocate vector of size 2.3 Gb.
>>>>
>>>> 2- Error: couldn't evaluate grouping factor id:(family:site) within model
>>>> frame: try adding grouping factor to data frame explicitly if possible.
>>>> (note that the id variable works for simpler lmer() models so the variable
>>>> itself is not an issue)
>>>>
>>>> My model looks like the following nested structure:
>>>> lmer(Y ~ 1 + X1 + X2 + X3 + (1|site/family/id), data=dd, REML = FALSE)
>>>>
>>>> Best,
>>>>
>>>> Hedyeh Ahmadi, Ph.D.
>>>> Statistician
>>>> Keck School of Medicine
>>>> Department of Preventive Medicine
>>>> University of Southern California
>>>>
>>>> Postdoctoral Scholar
>>>> Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
>>>> University of California, Irvine
>>>>
>>>> LinkedIn
>>>> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$> 
> 
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$>> 
> 
>> 
>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$ 
> 
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$>>>
>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$ 
> 
>> 
>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$ 
> 
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$>>>
>>>>>
>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$ 
> 
>> 
>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$ 
> 
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$>>>
>>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$ 
> 
>> 
>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$ 
> 
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$>>>
>>>>>
>>>>
>>>>
>>>>
>>>>
>>>> ________________________________
>>>> From: Dexter Locke <dexter.locke at gmail.com>
>>>> Sent: Friday, March 5, 2021 1:01 PM
>>>> To: Hedyeh Ahmadi <hedyehah at usc.edu>
>>>> Cc: r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>;
>>>> Megan M. Herting <herting at usc.edu>; Elisabeth Burnor <burnor at usc.edu>
>>>> Subject: Re: [R-sig-ME] A three-level GLMM with binomial link in R
>>>>
>>>> Hi Hedyeh,
>>>>
>>>> What is the problem you are having? Specifically, what is the estimation
>>>> issue with lmer and lme?
>>>>
>>>> Can you provide a reproducible example? Can you provide the complete
>>>> errors you are seeing?
>>>>
>>>> The current questions are vague, so it will be challenging for list
>>>> members to provide much guidance.
>>>>
>>>> -Dexter
>>>>
>>>>
>>>> On Fri, Mar 5, 2021 at 3:27 PM Hedyeh Ahmadi <hedyehah at usc.edu<mailto:
>>>> hedyehah at usc.edu>> wrote:
>>>> Hi All,
>>>> I was wondering what would be a powerful package in R to run GLMM with
>>>> logit link that can handle a data set with N=22945 and 3 nested random
>>>> intercepts. So far, I have tried glmer() from lme4 and it's giving me a lot
>>>> of estimation issues. Any other package I should try?
>>>>
>>>> I am asking for another package as I am having the same issue with lmer()
>>>> for similar LMM with continuous outcome, while lme() from nlme package runs
>>>> the models with no problem.
>>>>
>>>> Thank you in advance.
>>>>
>>>> Best,
>>>>
>>>> Hedyeh Ahmadi, Ph.D.
>>>> Statistician
>>>> Keck School of Medicine
>>>> Department of Preventive Medicine
>>>> University of Southern California
>>>>
>>>> Postdoctoral Scholar
>>>> Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
>>>> University of California, Irvine
>>>>
>>>> LinkedIn
>>>> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$> 
> 
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$>> 
> 
>> 
>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$ 
> 
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$>>>
>>>> <
>>>> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$> 
> 
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$>>
>>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$ 
> 
>> 
>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$ 
> 
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$>>>
>>>> <
>>>> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$> 
> 
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$>>
>>>>>>
>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$ 
> 
>> 
>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$ 
> 
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$>>>
>>>> <
>>>> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$> 
> 
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$>>
>>>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$ 
> 
>> 
>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$ 
> 
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$>>>
>>>> <
>>>> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$> 
> 
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$>>
>>>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>????????? [[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org>
>>>> mailing list
>>>> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$ 
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$> 
> 
>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$ 
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$>> 
> 
>> 
>>>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKG8rJcsmY$ 
> 
>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKG8rJcsmY$ 
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKG8rJcsmY$>>>
>>>> <
>>>> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQM6wKtNs$ 
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQM6wKtNs$> 
> 
>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQM6wKtNs$ 
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQM6wKtNs$>>
>>>>>
>>>>
>>>>????????? [[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$ 
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$> 
> 
>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$ 
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$>> 
> 
>> 
>>>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKG8rJcsmY$ 
> 
>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKG8rJcsmY$ 
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKG8rJcsmY$>>>
>>>>
>>>>
>>> 
>>>??????? [[alternative HTML version deleted]]
>>> 
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$ 
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$> 
> 
>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$ 
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$>> 
> 
>> 
>>>
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$ 
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$> 
> 
>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$ 
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$>> 
> 
>>


From M@rco@Z@n|n @end|ng |rom b@thrugby@com  Fri Mar 12 15:43:05 2021
From: M@rco@Z@n|n @end|ng |rom b@thrugby@com (Marco Zanin)
Date: Fri, 12 Mar 2021 14:43:05 +0000
Subject: [R-sig-ME] Testing Significance of Random Effects
Message-ID: <LO2P123MB374497B4F368AFE7C6538511FF6F9@LO2P123MB3744.GBRP123.PROD.OUTLOOK.COM>

To whom it may concern,

My name is Marco Zanin, I am a PhD candidate in Sport & Exercise Physiology at Leeds Beckett University (Leeds, UK) and I work as Sport Scientist at Bath Rugby (Bath, UK).

I am relatively new to lme4, but I was wondering whether you might help me to find a way to test the significance of the random effects in a model, whether the random effects improve/reduce the fit of the model and are thus necessary or if they could be removed from the model.

I look forward to hearing from you.

Kind regards,

Marco Zanin

______________________________________________________________________
This email has been scanned by the Symantec Email Security.cloud service.
For more information please visit http://www.symanteccloud.com
______________________________________________________________________
	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Fri Mar 12 15:59:54 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Fri, 12 Mar 2021 09:59:54 -0500
Subject: [R-sig-ME] Testing Significance of Random Effects
In-Reply-To: <LO2P123MB374497B4F368AFE7C6538511FF6F9@LO2P123MB3744.GBRP123.PROD.OUTLOOK.COM>
References: <LO2P123MB374497B4F368AFE7C6538511FF6F9@LO2P123MB3744.GBRP123.PROD.OUTLOOK.COM>
Message-ID: <4893b7fc-8b5a-451d-0d00-23ea19c47d0b@gmail.com>

   I wouldn't generally recommend removing random effects on the basis 
of null-hypothesis significance testing ... but others on this list 
might, e.g. Matuschek et al. https://arxiv.org/pdf/1511.01864.pdf 
(section 2.4) suggest backward stepwise removal with an alpha-level of 0.2.

   Also see 
https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#testing-significance-of-random-effects


On 3/12/21 9:43 AM, Marco Zanin wrote:
> To whom it may concern,
> 
> My name is Marco Zanin, I am a PhD candidate in Sport & Exercise Physiology at Leeds Beckett University (Leeds, UK) and I work as Sport Scientist at Bath Rugby (Bath, UK).
> 
> I am relatively new to lme4, but I was wondering whether you might help me to find a way to test the significance of the random effects in a model, whether the random effects improve/reduce the fit of the model and are thus necessary or if they could be removed from the model.
> 
> I look forward to hearing from you.
> 
> Kind regards,
> 
> Marco Zanin
> 
> ______________________________________________________________________
> This email has been scanned by the Symantec Email Security.cloud service.
> For more information please visit http://www.symanteccloud.com
> ______________________________________________________________________
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From hedyeh@h @end|ng |rom u@c@edu  Fri Mar 12 18:13:57 2021
From: hedyeh@h @end|ng |rom u@c@edu (Hedyeh Ahmadi)
Date: Fri, 12 Mar 2021 17:13:57 +0000
Subject: [R-sig-ME] A three-level GLMM with binomial link in R
In-Reply-To: <971aa7fc-a424-154d-c451-3027988f3c55@gmail.com>
References: <BYAPR07MB50945A60AFDE467F317861ACD1969@BYAPR07MB5094.namprd07.prod.outlook.com>
 <CAA=SVwH2pE+EAtEqALjeRPT91tWz-HJegrQkz9mYqfj7pb_A1Q@mail.gmail.com>
 <BYAPR07MB50947CD020DADA71CFF86407D1969@BYAPR07MB5094.namprd07.prod.outlook.com>
 <CA+3TTkNL+JGE+pgfOqASfvJ+r5eHmbGt3v+FzazouVePs_=x9Q@mail.gmail.com>
 <BYAPR07MB509450F1132EEB7C41F60B4CD1969@BYAPR07MB5094.namprd07.prod.outlook.com>
 <CA+3TTkM-abt0u4Je03nnTBBKiZw4AFj-UdPfyP_JOLZbDiJEFA@mail.gmail.com>
 <9e903a9f-5bec-934c-0b50-b2fca97cd4f3@gmail.com>
 <BYAPR07MB5094069BFA432F89688D34DCD1939@BYAPR07MB5094.namprd07.prod.outlook.com>
 <a8005560-3957-e814-df74-604d9cb857bb@gmail.com>
 <BYAPR07MB5094DD4608A0B5DB96A52EB5D1909@BYAPR07MB5094.namprd07.prod.outlook.com>,
 <971aa7fc-a424-154d-c451-3027988f3c55@gmail.com>
Message-ID: <BYAPR07MB5094B054FF44075722E4C378D16F9@BYAPR07MB5094.namprd07.prod.outlook.com>

Here are my comments/questions:

  1.  I have tried changing the site, family, and id to factor and I get the same results.
  2.  Unfortunately, I can't share my data due to privacy issues but if you tell me what other information you need, I can provide it.
  3.  Note that when I run the three-way interaction code in my PC it again runs out of memory and the error says the following. When I tried to run it on interactive HPC, it kicks me out as it takes too much memory/time so I will have to submit a batch script.
"Error: cannot allocate vector of size 18.1 Gb
In addition: Warning message:
In ans * length(l) :
Error: cannot allocate vector of size 18.1 Gb"
  4.  When I take out all the fixed effects, the problem still exists.
  5.  Question: Also note that my data has 22945 rows, and some individuals have only baseline measurement only, some individuals have baseline and 1 year measurement. A variable called eventname is the indicator of that. I am now confused as my "id" variable does not have this information (i.e. the order of measurement). How would the model recognize that which repeated measure is measurment1 (i.e. baseline) and which one is measurment2(i.e. 1 year)?  Or maybe because I don't have a random slope, I don't need to define the repeated measure structure and adding eventname as a fixed effect is sufficient?

Thanks again for all your help on this.

Best,

Hedyeh Ahmadi, Ph.D.
Statistician
Keck School of Medicine
Department of Preventive Medicine
University of Southern California

Postdoctoral Scholar
Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
University of California, Irvine

LinkedIn
www.linkedin.com/in/hedyeh-ahmadi<http://www.linkedin.com/in/hedyeh-ahmadi>
<http://www.linkedin.com/in/hedyeh-ahmadi><http://www.linkedin.com/in/hedyeh-ahmadi>




________________________________
From: Ben Bolker <bbolker at gmail.com>
Sent: Thursday, March 11, 2021 3:55 PM
To: Hedyeh Ahmadi <hedyehah at usc.edu>; r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>; Megan M. Herting <herting at usc.edu>; Elisabeth Burnor <burnor at usc.edu>
Subject: Re: [R-sig-ME] A three-level GLMM with binomial link in R



On 3/11/21 1:11 PM, Hedyeh Ahmadi wrote:
> Hi Ben,
> Thank you for all the help and informative replies. Here is some info
> about my data and my answers:
>
>   * Yes, I am running the exact model however this is just my toy model
>     to get the code to work.
>   * Reminder, I am trying to get lmer with a continuous outcome (but
>     same data structure, with 3 random intercept) work before moving to
>     glmer() with a logit link with a categorical 0/1 outcome.
>   * Here are some information about my data:
>       o X1: num [1:22945] 9.25 NA 9.22 NA 9.22 NA 9.42 NA 9.25 NA ...
>       o X2: int [1:22945] 117 140 128 125 113 138 126 130 120 121 ...
>       o X3: chr [1:22945] "Female" "Male" "Male" "Male" "Male"
>       o site: chr [1:22945] "site15" "site15" "site15" "site15" "site15"
>         ... (I have 21 sites)
>       o family: int [1:22945] 0 1 1 1 1 3 3 4 4 5 ...
>       o id: chr [1:22945] "id1" "id2" "id2" "id3" "id3"...
>   * The following model gives me the error that "Error: couldn't
>     evaluate grouping factor id:(family:site) within model frame: try
>     adding grouping factor to data frame explicitly if possible" - I ran
>     this same model on a supercomputer and it *gave me the same error*,
>     so this is not a memory limit issue.

So far I can't replicate this.  It seemed fishy to me that family was an
integer (I would try explicitly converting it to a factor), but doesn't
actually cause any problems in my example.

  (This differs from your example but not in ways I would expect to be
important: in particular, the types of the grouping variables are the
same [chr, int, chr]

n <- 10000
set.seed(101)
dd <- data.frame(y=rnorm(n),
                  x1=rnorm(n),
                  x2=rnorm(n),
                  x3=rnorm(n),
                  site=sample(paste0("s",1:15),size=n,replace=TRUE),
                  family=sample(1:100,size=n,replace=TRUE),
                  id=sample(paste0("id",1:20),size=n,replace=TRUE))
library(lme4)
lmer(y~1 + x1 + x2 + x3 + (1|site/family/id), data=dd)

###

What is meant by "adding grouping factor to data frame explicitly" would
be in this case expanding out the nested terms:

  dd <- within(dd,
{
     site_family <- interaction(site,family)
     site_family_id <- interaction(site,family,id)
})

lmer(y~1 + x1 + x2 + x3 + (1|site) + (1|site_family) +
(1|site_family_id), data =dd)



>       o m2 <- lmer(cbcl_scr_syn_internal_r ~ 1 + X1 + X2 + X3 +
>         (1|site/family/id), data=dd, REML = FALSE)
>   * The following *model ran on a supercomputer*.  This is the model
>     that previously would give me the error "Error: cannot allocate
>     vector of size 2.3 Gb". Here I am*reducing the number of sites to
>     see if it runs, and it did* run on a supercomputer.
>       o m11 <- lmer(cbcl_scr_syn_internal_r ~ 1 + X1 +X2 + X3
>         +(1|site/family/id) ,
>              data=dd[-which(dd$abcd_site %in% c("site01","site02",
>         "site04", "site05", "site06", "site07", "site08","site09")),],
>         na.action=na.exclude, REML=FALSE)
>
> Questions:
>
>  1. What I don't understand is that in m2, why lmer() does not
>     recognizes the grouping factor that it does recognize in m11?

  I'm not sure either.

>  2. At this point I don't think this is a memory issue as *m2 did not
>     run on a supercompute*r and it's giving me *the same error as my
>     personal computer*. However, in m11, the same grouping structure is
>     being recognized when I reduce the number of sites from 21 to 13 -
>     could this be because of severe imbalance in my family/id nesting,
>     meaning most families have only one kid but some have 2 and a few
>     have 3 kids?

   It seems surprising.
   Is there any way we can get a reproducible example?  For example,
suppose you randomize your X1, X2, X3 and anonymize all of your grouping
variables: would you then be able to share the data set?

   Does the problem (let's say just the first problem) still occur if
you leave out the fixed effects? (I would expect so, and that would
simplify things somewhat - we're trying to get to the *simplest* example
that still demonstrates the problem.)


>
> Sorry about the long email and thank you for your help in advance.
>
> Best,
>
> Hedyeh Ahmadi, Ph.D.
> Statistician
> Keck School of Medicine
> Department of Preventive Medicine
> University of Southern California
>
> Postdoctoral Scholar
> Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
> University of California, Irvine
>
> LinkedIn
> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!51-zg2ISp-lS-4HEW0ZNNEVE1ZD8ujdJZYx90xVOnZ-x6A7l6eu2KhSgMhYCJq4$  <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!51-zg2ISp-lS-4HEW0ZNNEVE1ZD8ujdJZYx90xVOnZ-x6A7l6eu2KhSgMhYCJq4$ >
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!51-zg2ISp-lS-4HEW0ZNNEVE1ZD8ujdJZYx90xVOnZ-x6A7l6eu2KhSgMhYCJq4$ ><https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!51-zg2ISp-lS-4HEW0ZNNEVE1ZD8ujdJZYx90xVOnZ-x6A7l6eu2KhSgMhYCJq4$ >
>
>
>
>
> ------------------------------------------------------------------------
> *From:* Ben Bolker <bbolker at gmail.com>
> *Sent:* Tuesday, March 9, 2021 4:12 PM
> *To:* Hedyeh Ahmadi <hedyehah at usc.edu>; r-sig-mixed-models at r-project.org
> <r-sig-mixed-models at r-project.org>
> *Subject:* Re: [R-sig-ME] A three-level GLMM with binomial link in R
>     OK, then it would be very helpful to have more details about your
> data set. Are one or more of X1, X2, X3 categorical predictors with many
> levels ... ?  Any chance we can see str() or summary() ?  Are you using
> exactly the formula you told us about, or something slightly different?
>
>     The computational burden of a large number of fixed effect parameters
> will be much worse for glmer than for lmer, unless you use nAGQ=0.
> glmmTMB would be able to help in two ways: (1) it doesn't scale as badly
> for large numbers of fixed effects; (2) it allows sparse fixed-effect
> model matrices (something we keep meaning to (re)implement in lme4) ...
>
>    Making X1 into a 1000-level factor brings the required memory up by
> about a factor of 10 and increases the run time from seconds to minutes.
>
>
> Base model:
>
>                        Function_Call Elapsed_Time_sec Total_RAM_Used_MiB
> 1 m<-lmer(form,data=dd,REML=FALSE)            1.903               10.4
>     Peak_RAM_Used_MiB
> 1             107.7
>
> With X=1000-level factor (no derivative calculations):
>
>    Function_Call
> 1
> m2<-lmer(form,data=dd2,REML=FALSE,control=lmerControl(calc.derivs=FALSE),verbose=10)
>     Elapsed_Time_sec Total_RAM_Used_MiB Peak_RAM_Used_MiB
> 1          559.735              608.8             984.5
>
>
> With derivative calculation at the end:
>
>                                    Function_Call Elapsed_Time_sec
> 1 m3<-lmer(form,data=dd2,REML=FALSE,verbose=10)          677.975
>     Total_RAM_Used_MiB Peak_RAM_Used_MiB
> 1              608.7            1148.7
>   >
>   >
>
> ---
> ibrary(lme4)
> set.seed(101)
> N <- 22945
> ns <- 100
> nf <- 100
> nid <- 100
> dd <- data.frame(X1=rnorm(N),
>                    X2=rnorm(N),
>                    X3=rnorm(N),
>                    site=sample(ns, replace=TRUE, size=N),
>                    family=sample(nf, replace=TRUE, size=N),
>                    id=sample(nid, replace=TRUE, size=N))
> form <- Y ~ 1 + X1 + X2 + X3 + (1|site/family/id)
> dd$Y <- simulate(form[-2], newdata=dd, family=gaussian,
>
> newparams=list(beta=rep(1,4),theta=rep(1,3),sigma=1))[[1]]
> library(peakRAM)
> system.time(mem <- peakRAM(
>       m <- lmer(form, data=dd, REML=FALSE)
>       ))
> print(mem)
>
> dd2 <- transform(dd,
>           X1=factor(sample(1000,size=N,replace=TRUE)))
>
> system.time(mem2 <- peakRAM(
>       m2 <- lmer(form, data=dd2, REML=FALSE,
> control=lmerControl(calc.derivs=FALSE), verbose=10)
> ))
> print(mem2)
>
> system.time(mem3 <- peakRAM(
>       m3 <- lmer(form, data=dd2, REML=FALSE, verbose=10)
> ))
> print(mem3)
>
>
> On 3/8/21 11:29 AM, Hedyeh Ahmadi wrote:
>> Thank you for the toy example. This same example in my PC gives the
>> following memory use output:
>>
>>
>>  > mem
>>                       Function_Call
>> Elapsed_Time_sec         Total_RAM_Used_MiB    Peak_RAM_Used_MiB
>>    m<-lmer(form,data=dd,REML=FALSE)             2.64
>>                  10.3                                       130.1
>>
>> When I run peakRAM() for my actual data, it take one hour plus then my
>> PC slows down, then I have to stop R to be able to use my PC.
>>
>> Best,
>>
>> Hedyeh Ahmadi, Ph.D.
>> Statistician
>> Keck School of Medicine
>> Department of Preventive Medicine
>> University of Southern California
>>
>> Postdoctoral Scholar
>> Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
>> University of California, Irvine
>>
>> LinkedIn
>> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5O8KlsAUILt44__IHSzbCUgVs7dWxAB8FS9wiKC3j5P6hGrnuJSGckmCIR91AZs$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5O8KlsAUILt44__IHSzbCUgVs7dWxAB8FS9wiKC3j5P6hGrnuJSGckmCIR91AZs$>
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5O8KlsAUILt44__IHSzbCUgVs7dWxAB8FS9wiKC3j5P6hGrnuJSGckmCIR91AZs$
>  >
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5O8KlsAUILt44__IHSzbCUgVs7dWxAB8FS9wiKC3j5P6hGrnuJSGckmCIR91AZs$
>  ><https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5O8KlsAUILt44__IHSzbCUgVs7dWxAB8FS9wiKC3j5P6hGrnuJSGckmCIR91AZs$ >
>>
>>
>>
>>
>> ------------------------------------------------------------------------
>> *From:* R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on
>> behalf of Ben Bolker <bbolker at gmail.com>
>> *Sent:* Friday, March 5, 2021 5:44 PM
>> *To:* r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>
>> *Subject:* Re: [R-sig-ME] A three-level GLMM with binomial link in R
>>     Here's an example that conforms approximately to the structure of
>> your data: on my machine the peak RAM usage is 121 Mb, far short of your
>> 2.3 Gb ...  so I still suspect there is something going on that we don't
>> know about/haven't guessed yet.
>>
>> set.seed(101)
>> N <- 22945
>> ns <- 100
>> nf <- 100
>> nid <- 100
>> dd <- data.frame(X1=rnorm(N),
>>                    X2=rnorm(N),
>>                    X3=rnorm(N),
>>                    site=sample(ns, replace=TRUE, size=N),
>>                    family=sample(nf, replace=TRUE, size=N),
>>                    id=sample(nid, replace=TRUE, size=N))
>> form <- Y ~ 1 + X1 + X2 + X3 + (1|site/family/id)
>> dd$Y <- simulate(form[-2], newdata=dd, family=gaussian,
>>
>> newparams=list(beta=rep(1,4),theta=rep(1,3),sigma=1))[[1]]
>> library(peakRAM)
>> mem <- peakRAM(
>>       m <- lmer(form, data=dd, REML=FALSE)
>> )
>>
>> mem
>>                        Function_Call Elapsed_Time_sec Total_RAM_Used_MiB
>> 1 m<-lmer(form,data=dd,REML=FALSE)            1.754               10.3
>>     Peak_RAM_Used_MiB
>> 1             120.7
>>
>>
>> On 3/5/21 4:52 PM, Robert Long wrote:
>>> Perhaps because of the different ways they store objects internally while
>>> fitting the models.
>>>
>>> On Fri, 5 Mar 2021, 21:47 Hedyeh Ahmadi, <hedyehah at usc.edu> wrote:
>>>
>>>> Thank you for the reply Robert - If I am running out of memory in lmer(),
>>>> do you know why lme() runs just fine?
>>>>
>>>> Best,
>>>>
>>>> Hedyeh Ahmadi, Ph.D.
>>>> Statistician
>>>> Keck School of Medicine
>>>> Department of Preventive Medicine
>>>> University of Southern California
>>>>
>>>> Postdoctoral Scholar
>>>> Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
>>>> University of California, Irvine
>>>>
>>>> LinkedIn
>>>> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$>
>
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$>>
>
>>
>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$
>
>>  >
>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$
>
>>  >
>>>>
>>>>
>>>>
>>>>
>>>> ------------------------------
>>>> *From:* Robert Long <longrob604 at gmail.com>
>>>> *Sent:* Friday, March 5, 2021 1:43 PM
>>>> *To:* Hedyeh Ahmadi <hedyehah at usc.edu>
>>>> *Cc:* Dexter Locke <dexter.locke at gmail.com>; R-mixed models mailing list <
>>>> r-sig-mixed-models at r-project.org>; Megan M. Herting <herting at usc.edu>;
>>>> Elisabeth Burnor <burnor at usc.edu>
>>>> *Subject:* Re: [R-sig-ME] A three-level GLMM with binomial link in R
>>>>
>>>> You've run out of memory. Try running it on a machine with much larger RAM.
>>>>
>>>> On Fri, 5 Mar 2021, 21:18 Hedyeh Ahmadi, <hedyehah at usc.edu> wrote:
>>>>
>>>> Hi - Thank you for the informative replies.
>>>>
>>>> I will try those other packages. If MASS::glmmPQL uses lme() then this
>>>> should work for me.
>>>>
>>>> My data structure is complex so it's hard to give reproducible example but
>>>> for example for two of my models I get the following errors in lmer() while
>>>> lme() runs smoothly.
>>>>
>>>> 1- Error: cannot allocate vector of size 2.3 Gb.
>>>>
>>>> 2- Error: couldn't evaluate grouping factor id:(family:site) within model
>>>> frame: try adding grouping factor to data frame explicitly if possible.
>>>> (note that the id variable works for simpler lmer() models so the variable
>>>> itself is not an issue)
>>>>
>>>> My model looks like the following nested structure:
>>>> lmer(Y ~ 1 + X1 + X2 + X3 + (1|site/family/id), data=dd, REML = FALSE)
>>>>
>>>> Best,
>>>>
>>>> Hedyeh Ahmadi, Ph.D.
>>>> Statistician
>>>> Keck School of Medicine
>>>> Department of Preventive Medicine
>>>> University of Southern California
>>>>
>>>> Postdoctoral Scholar
>>>> Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
>>>> University of California, Irvine
>>>>
>>>> LinkedIn
>>>> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$>
>
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$>>
>
>>
>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$
>
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$>>>
>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$
>
>>
>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$
>
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$>>>
>>>>>
>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$
>
>>
>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$
>
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$>>>
>>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$
>
>>
>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$
>
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$>>>
>>>>>
>>>>
>>>>
>>>>
>>>>
>>>> ________________________________
>>>> From: Dexter Locke <dexter.locke at gmail.com>
>>>> Sent: Friday, March 5, 2021 1:01 PM
>>>> To: Hedyeh Ahmadi <hedyehah at usc.edu>
>>>> Cc: r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>;
>>>> Megan M. Herting <herting at usc.edu>; Elisabeth Burnor <burnor at usc.edu>
>>>> Subject: Re: [R-sig-ME] A three-level GLMM with binomial link in R
>>>>
>>>> Hi Hedyeh,
>>>>
>>>> What is the problem you are having? Specifically, what is the estimation
>>>> issue with lmer and lme?
>>>>
>>>> Can you provide a reproducible example? Can you provide the complete
>>>> errors you are seeing?
>>>>
>>>> The current questions are vague, so it will be challenging for list
>>>> members to provide much guidance.
>>>>
>>>> -Dexter
>>>>
>>>>
>>>> On Fri, Mar 5, 2021 at 3:27 PM Hedyeh Ahmadi <hedyehah at usc.edu<mailto:
>>>> hedyehah at usc.edu>> wrote:
>>>> Hi All,
>>>> I was wondering what would be a powerful package in R to run GLMM with
>>>> logit link that can handle a data set with N=22945 and 3 nested random
>>>> intercepts. So far, I have tried glmer() from lme4 and it's giving me a lot
>>>> of estimation issues. Any other package I should try?
>>>>
>>>> I am asking for another package as I am having the same issue with lmer()
>>>> for similar LMM with continuous outcome, while lme() from nlme package runs
>>>> the models with no problem.
>>>>
>>>> Thank you in advance.
>>>>
>>>> Best,
>>>>
>>>> Hedyeh Ahmadi, Ph.D.
>>>> Statistician
>>>> Keck School of Medicine
>>>> Department of Preventive Medicine
>>>> University of Southern California
>>>>
>>>> Postdoctoral Scholar
>>>> Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
>>>> University of California, Irvine
>>>>
>>>> LinkedIn
>>>> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$>
>
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$>>
>
>>
>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$
>
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$>>>
>>>> <
>>>> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$>
>
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$>>
>>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$
>
>>
>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$
>
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$>>>
>>>> <
>>>> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$>
>
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$>>
>>>>>>
>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$
>
>>
>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$
>
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$>>>
>>>> <
>>>> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$>
>
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$>>
>>>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$
>
>>
>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$
>
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$>>>
>>>> <
>>>> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$>
>
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$>>
>>>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>          [[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org>
>>>> mailing list
>>>> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$>
>
>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$>>
>
>>
>>>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKG8rJcsmY$
>
>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKG8rJcsmY$
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKG8rJcsmY$>>>
>>>> <
>>>> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQM6wKtNs$
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQM6wKtNs$>
>
>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQM6wKtNs$
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQM6wKtNs$>>
>>>>>
>>>>
>>>>          [[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$>
>
>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$>>
>
>>
>>>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKG8rJcsmY$
>
>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKG8rJcsmY$
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKG8rJcsmY$>>>
>>>>
>>>>
>>>
>>>        [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$>
>
>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$>>
>
>>
>>>
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$>
>
>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$>>
>
>>

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Fri Mar 12 20:45:10 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Fri, 12 Mar 2021 14:45:10 -0500
Subject: [R-sig-ME] A three-level GLMM with binomial link in R
In-Reply-To: <BYAPR07MB5094B054FF44075722E4C378D16F9@BYAPR07MB5094.namprd07.prod.outlook.com>
References: <BYAPR07MB50945A60AFDE467F317861ACD1969@BYAPR07MB5094.namprd07.prod.outlook.com>
 <CAA=SVwH2pE+EAtEqALjeRPT91tWz-HJegrQkz9mYqfj7pb_A1Q@mail.gmail.com>
 <BYAPR07MB50947CD020DADA71CFF86407D1969@BYAPR07MB5094.namprd07.prod.outlook.com>
 <CA+3TTkNL+JGE+pgfOqASfvJ+r5eHmbGt3v+FzazouVePs_=x9Q@mail.gmail.com>
 <BYAPR07MB509450F1132EEB7C41F60B4CD1969@BYAPR07MB5094.namprd07.prod.outlook.com>
 <CA+3TTkM-abt0u4Je03nnTBBKiZw4AFj-UdPfyP_JOLZbDiJEFA@mail.gmail.com>
 <9e903a9f-5bec-934c-0b50-b2fca97cd4f3@gmail.com>
 <BYAPR07MB5094069BFA432F89688D34DCD1939@BYAPR07MB5094.namprd07.prod.outlook.com>
 <a8005560-3957-e814-df74-604d9cb857bb@gmail.com>
 <BYAPR07MB5094DD4608A0B5DB96A52EB5D1909@BYAPR07MB5094.namprd07.prod.outlook.com>
 <971aa7fc-a424-154d-c451-3027988f3c55@gmail.com>
 <BYAPR07MB5094B054FF44075722E4C378D16F9@BYAPR07MB5094.namprd07.prod.outlook.com>
Message-ID: <c70f39ad-dbb4-5f3a-3e9d-9baa6e4c9da6@gmail.com>



On 3/12/21 12:13 PM, Hedyeh Ahmadi wrote:
> Here are my comments/questions:
> 
>  1. I have tried changing the site, family, and id to factor and I get
>     the same results.
>  2. Unfortunately, I can't share my data due to privacy issues but if
>     you tell me what other information you need, I can provide it.

   We know you can't share the data.  Part of the art of getting 
software help is figuring out how you can create a shareable version of 
your data set, *or* a shareable version of something that will generate 
the same errors you're experiencing.  We need to do a bisection search 
between the private data you have, which causes problems with factor 
expansion in the grouping variables and is surprisingly memory-hungry, 
and the reproducible examples that I have constructed that mimic some 
aspects of your data set but don't show either problem.  Since we can't 
look at your data, the burden falls on you to create a 
reproducible/shareable example we can work with.

    Assuming that

lmer(y ~ 1  +(1|site/family/id) , data =dd)

does show problems with your actual data set, can you anonymize the 
levels of site, family, and id, something like

   anon_fac <- function(x, prefix="S") {
       factor(x, levels=levels(x), labels=paste0(prefix, 
seq(length(levels(x))))
   }

   anon_dd <- transform(dd, select=c(family, site, id))
   anon_dd <- transform(anon_dd,
           site=anon_fac(site,"S"),
           family=anon_fac(family,"F"),
           id=anon_fac(id,"I")
   )

This should provide a data set that contains *no* information other than 
the pattern of co-occurrence of grouping levels. I don't know who's in 
charge of data privacy for your group, but it's hard to imagine how 
sharing this would present a risk of personal identification ...

https://stackoverflow.com/questions/10454973/how-to-create-example-data-set-from-private-data-replacing-variable-names-and-l

https://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example/6699112#6699112


>  3. Note that when I run the three-way interaction code in my PC it
>     again runs out of memory and the error says the following. When I
>     tried to run it on interactive HPC, it kicks me out as it takes too
>     much memory/time so I will have to submit a batch script.
>     "Error: cannot allocate vector of size 18.1 Gb
>     In addition: Warning message:
>     In ans * length(l) :
>     Error: cannot allocate vector of size 18.1 Gb"
>  4. When I take out all the fixed effects, the problem still exists.


   That's good in one sense, as it simplifies the problem.

>  5. *Question:* Also note that my data has 22945 rows, and some
>     individuals have only baseline measurement only, some individuals
>     have baseline and 1 year measurement. A variable called eventname is
>     the indicator of that. I am now confused as my "id" variable does
>     not have this information (i.e. the order of measurement). How would
>     the model recognize that which repeated measure is measurment1 (i.e.
>     baseline) and which one is measurment2(i.e. 1 year)?? Or maybe
>     because I don't have a random slope, I don't need to define the
>     repeated measure structure and adding eventname as a fixed effect is
>     sufficient?

    Let's deal with this after we have the basic problems sorted.  If 
you want to account for the possible effects of ordering, then you'd 
need to add this variable ...

> 
> Thanks again for all your help on this.
> 
> Best,
> 
> Hedyeh Ahmadi, Ph.D.
> Statistician
> Keck School of Medicine
> Department of Preventive Medicine
> University of Southern California
> 
> Postdoctoral Scholar
> Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
> University of California, Irvine
> 
> LinkedIn
> www.linkedin.com/in/hedyeh-ahmadi <http://www.linkedin.com/in/hedyeh-ahmadi>
> <http://www.linkedin.com/in/hedyeh-ahmadi><http://www.linkedin.com/in/hedyeh-ahmadi>
> 
> 
> 
> 
> ------------------------------------------------------------------------
> *From:* Ben Bolker <bbolker at gmail.com>
> *Sent:* Thursday, March 11, 2021 3:55 PM
> *To:* Hedyeh Ahmadi <hedyehah at usc.edu>; r-sig-mixed-models at r-project.org 
> <r-sig-mixed-models at r-project.org>; Megan M. Herting <herting at usc.edu>; 
> Elisabeth Burnor <burnor at usc.edu>
> *Subject:* Re: [R-sig-ME] A three-level GLMM with binomial link in R
> 
> 
> On 3/11/21 1:11 PM, Hedyeh Ahmadi wrote:
>> Hi Ben,
>> Thank you for all the help and informative replies. Here is some info 
>> about my data and my answers:
>> 
>>?? * Yes, I am running the exact model however this is just my toy model
>>???? to get the code to work.
>>?? * Reminder, I am trying to get lmer with a continuous outcome (but
>>???? same data structure, with 3 random intercept) work before moving to
>>???? glmer() with a logit link with a categorical 0/1 outcome.
>>?? * Here are some information about my data:
>>?????? o X1: num [1:22945] 9.25 NA 9.22 NA 9.22 NA 9.42 NA 9.25 NA ...
>>?????? o X2: int [1:22945] 117 140 128 125 113 138 126 130 120 121 ...
>>?????? o X3: chr [1:22945] "Female" "Male" "Male" "Male" "Male"
>>?????? o site: chr [1:22945] "site15" "site15" "site15" "site15" "site15"
>>???????? ... (I have 21 sites)
>>?????? o family: int [1:22945] 0 1 1 1 1 3 3 4 4 5 ...
>>?????? o id: chr [1:22945] "id1" "id2" "id2" "id3" "id3"...
>>?? * The following model gives me the error that "Error: couldn't
>>???? evaluate grouping factor id:(family:site) within model frame: try
>>???? adding grouping factor to data frame explicitly if possible" - I ran
>>???? this same model on a supercomputer and it *gave me the same error*,
>>???? so this is not a memory limit issue.
> 
> So far I can't replicate this.? It seemed fishy to me that family was an
> integer (I would try explicitly converting it to a factor), but doesn't
> actually cause any problems in my example.
> 
>  ? (This differs from your example but not in ways I would expect to be
> important: in particular, the types of the grouping variables are the
> same [chr, int, chr]
> 
> n <- 10000
> set.seed(101)
> dd <- data.frame(y=rnorm(n),
>  ????????????????? x1=rnorm(n),
>  ????????????????? x2=rnorm(n),
>  ????????????????? x3=rnorm(n),
>  ????????????????? site=sample(paste0("s",1:15),size=n,replace=TRUE),
>  ????????????????? family=sample(1:100,size=n,replace=TRUE),
>  ????????????????? id=sample(paste0("id",1:20),size=n,replace=TRUE))
> library(lme4)
> lmer(y~1 + x1 + x2 + x3 + (1|site/family/id), data=dd)
> 
> ###
> 
> What is meant by "adding grouping factor to data frame explicitly" would
> be in this case expanding out the nested terms:
> 
>  ? dd <- within(dd,
> {
>  ???? site_family <- interaction(site,family)
>  ???? site_family_id <- interaction(site,family,id)
> })
> 
> lmer(y~1 + x1 + x2 + x3 + (1|site) + (1|site_family) +
> (1|site_family_id), data =dd)
> 
> 
> 
>>?????? o m2 <- lmer(cbcl_scr_syn_internal_r ~ 1 + X1 + X2 + X3 +
>>???????? (1|site/family/id), data=dd, REML = FALSE)
>>?? * The following *model ran on a supercomputer*.? This is the model
>>???? that previously would give me the error "Error: cannot allocate
>>???? vector of size 2.3 Gb". Here I am*reducing the number of sites to
>>???? see if it runs, and it did* run on a supercomputer.
>>?????? o m11 <- lmer(cbcl_scr_syn_internal_r ~ 1 + X1 +X2 + X3
>>???????? +(1|site/family/id) ,
>>????????? ? ? data=dd[-which(dd$abcd_site %in% c("site01","site02",
>>???????? "site04", "site05", "site06", "site07", "site08","site09")),],
>>???????? na.action=na.exclude, REML=FALSE)
>> 
>> Questions:
>> 
>>? 1. What I don't understand is that in m2, why lmer() does not
>>???? recognizes the grouping factor that it does recognize in m11?
> 
>  ? I'm not sure either.
> 
>>? 2. At this point I don't think this is a memory issue as *m2 did not
>>???? run on a supercompute*r and it's giving me *the same error as my
>>???? personal computer*. However, in m11, the same grouping structure is
>>???? being recognized when I reduce the number of sites from 21 to 13 -
>>???? could this be because of severe imbalance in my family/id nesting,
>>???? meaning most families have only one kid but some have 2 and a few
>>???? have 3 kids?
> 
>  ?? It seems surprising.
>  ?? Is there any way we can get a reproducible example?? For example,
> suppose you randomize your X1, X2, X3 and anonymize all of your grouping
> variables: would you then be able to share the data set?
> 
>  ?? Does the problem (let's say just the first problem) still occur if
> you leave out the fixed effects? (I would expect so, and that would
> simplify things somewhat - we're trying to get to the *simplest* example
> that still demonstrates the problem.)
> 
> 
>> 
>> Sorry about the long email and thank you for your help in advance.
>> 
>> Best,
>> 
>> Hedyeh Ahmadi, Ph.D.
>> Statistician
>> Keck School of Medicine
>> Department of Preventive Medicine
>> University of Southern California
>> 
>> Postdoctoral Scholar
>> Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
>> University of California, Irvine
>> 
>> LinkedIn
>> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!51-zg2ISp-lS-4HEW0ZNNEVE1ZD8ujdJZYx90xVOnZ-x6A7l6eu2KhSgMhYCJq4$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!51-zg2ISp-lS-4HEW0ZNNEVE1ZD8ujdJZYx90xVOnZ-x6A7l6eu2KhSgMhYCJq4$>  
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!51-zg2ISp-lS-4HEW0ZNNEVE1ZD8ujdJZYx90xVOnZ-x6A7l6eu2KhSgMhYCJq4$ 
>  >
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!51-zg2ISp-lS-4HEW0ZNNEVE1ZD8ujdJZYx90xVOnZ-x6A7l6eu2KhSgMhYCJq4$ 
>  ><https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!51-zg2ISp-lS-4HEW0ZNNEVE1ZD8ujdJZYx90xVOnZ-x6A7l6eu2KhSgMhYCJq4$ >
>> 
>> 
>> 
>> 
>> ------------------------------------------------------------------------
>> *From:* Ben Bolker <bbolker at gmail.com>
>> *Sent:* Tuesday, March 9, 2021 4:12 PM
>> *To:* Hedyeh Ahmadi <hedyehah at usc.edu>; r-sig-mixed-models at r-project.org 
>> <r-sig-mixed-models at r-project.org>
>> *Subject:* Re: [R-sig-ME] A three-level GLMM with binomial link in R
>>? ?? OK, then it would be very helpful to have more details about your
>> data set. Are one or more of X1, X2, X3 categorical predictors with many
>> levels ... ?? Any chance we can see str() or summary() ?? Are you using
>> exactly the formula you told us about, or something slightly different?
>> 
>>? ?? The computational burden of a large number of fixed effect parameters
>> will be much worse for glmer than for lmer, unless you use nAGQ=0.
>> glmmTMB would be able to help in two ways: (1) it doesn't scale as badly
>> for large numbers of fixed effects; (2) it allows sparse fixed-effect
>> model matrices (something we keep meaning to (re)implement in lme4) ...
>> 
>>? ? Making X1 into a 1000-level factor brings the required memory up by
>> about a factor of 10 and increases the run time from seconds to minutes.
>> 
>> 
>> Base model:
>> 
>>? ????????????????????? Function_Call Elapsed_Time_sec Total_RAM_Used_MiB
>> 1 m<-lmer(form,data=dd,REML=FALSE)??????????? 1.903?????????????? 10.4
>>? ?? Peak_RAM_Used_MiB
>> 1???????????? 107.7
>> 
>> With X=1000-level factor (no derivative calculations):
>> 
>>? ? Function_Call
>> 1
>> m2<-lmer(form,data=dd2,REML=FALSE,control=lmerControl(calc.derivs=FALSE),verbose=10)
>>? ?? Elapsed_Time_sec Total_RAM_Used_MiB Peak_RAM_Used_MiB
>> 1????????? 559.735????????????? 608.8???????????? 984.5
>> 
>> 
>> With derivative calculation at the end:
>> 
>>? ????????????????????????????????? Function_Call Elapsed_Time_sec
>> 1 m3<-lmer(form,data=dd2,REML=FALSE,verbose=10)????????? 677.975
>>? ?? Total_RAM_Used_MiB Peak_RAM_Used_MiB
>> 1????????????? 608.7??????????? 1148.7
>>? ?>
>>? ?>
>> 
>> ---
>> ibrary(lme4)
>> set.seed(101)
>> N <- 22945
>> ns <- 100
>> nf <- 100
>> nid <- 100
>> dd <- data.frame(X1=rnorm(N),
>>? ????????????????? X2=rnorm(N),
>>? ????????????????? X3=rnorm(N),
>>? ????????????????? site=sample(ns, replace=TRUE, size=N),
>>? ????????????????? family=sample(nf, replace=TRUE, size=N),
>>? ????????????????? id=sample(nid, replace=TRUE, size=N))
>> form <- Y ~ 1 + X1 + X2 + X3 + (1|site/family/id)
>> dd$Y <- simulate(form[-2], newdata=dd, family=gaussian,
>>                    
>> newparams=list(beta=rep(1,4),theta=rep(1,3),sigma=1))[[1]]
>> library(peakRAM)
>> system.time(mem <- peakRAM(
>>? ???? m <- lmer(form, data=dd, REML=FALSE)
>>? ???? ))
>> print(mem)
>> 
>> dd2 <- transform(dd,
>>? ???????? X1=factor(sample(1000,size=N,replace=TRUE)))
>> 
>> system.time(mem2 <- peakRAM(
>>? ???? m2 <- lmer(form, data=dd2, REML=FALSE,
>> control=lmerControl(calc.derivs=FALSE), verbose=10)
>> ))
>> print(mem2)
>> 
>> system.time(mem3 <- peakRAM(
>>? ???? m3 <- lmer(form, data=dd2, REML=FALSE, verbose=10)
>> ))
>> print(mem3)
>> 
>> 
>> On 3/8/21 11:29 AM, Hedyeh Ahmadi wrote:
>>> Thank you for the toy example. This same example in my PC gives the 
>>> following memory use output:
>>> 
>>> 
>>>? > mem
>>>? ? ? ? ? ? ? ? ? ? ? ?Function_Call                            
>>> Elapsed_Time_sec ? ? ? ? Total_RAM_Used_MiB ?? Peak_RAM_Used_MiB
>>>? ? m<-lmer(form,data=dd,REML=FALSE) ? ? ? ? ? ? 2.64                     
>>>? ? ? ? ? ? ? ? ? 10.3 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 130.1
>>> 
>>> When I run peakRAM() for my actual data, it take one hour plus then my 
>>> PC slows down, then I have to stop R to be able to use my PC.
>>> 
>>> Best,
>>> 
>>> Hedyeh Ahmadi, Ph.D.
>>> Statistician
>>> Keck School of Medicine
>>> Department of Preventive Medicine
>>> University of Southern California
>>> 
>>> Postdoctoral Scholar
>>> Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
>>> University of California, Irvine
>>> 
>>> LinkedIn
>>> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5O8KlsAUILt44__IHSzbCUgVs7dWxAB8FS9wiKC3j5P6hGrnuJSGckmCIR91AZs$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5O8KlsAUILt44__IHSzbCUgVs7dWxAB8FS9wiKC3j5P6hGrnuJSGckmCIR91AZs$> 
> 
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5O8KlsAUILt44__IHSzbCUgVs7dWxAB8FS9wiKC3j5P6hGrnuJSGckmCIR91AZs$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5O8KlsAUILt44__IHSzbCUgVs7dWxAB8FS9wiKC3j5P6hGrnuJSGckmCIR91AZs$>> 
> 
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5O8KlsAUILt44__IHSzbCUgVs7dWxAB8FS9wiKC3j5P6hGrnuJSGckmCIR91AZs$ 
> 
>>? >
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5O8KlsAUILt44__IHSzbCUgVs7dWxAB8FS9wiKC3j5P6hGrnuJSGckmCIR91AZs$ 
> 
>>? ><https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5O8KlsAUILt44__IHSzbCUgVs7dWxAB8FS9wiKC3j5P6hGrnuJSGckmCIR91AZs$ 
>  >
>>> 
>>> 
>>> 
>>> 
>>> ------------------------------------------------------------------------
>>> *From:* R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on 
>>> behalf of Ben Bolker <bbolker at gmail.com>
>>> *Sent:* Friday, March 5, 2021 5:44 PM
>>> *To:* r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>
>>> *Subject:* Re: [R-sig-ME] A three-level GLMM with binomial link in R
>>>? ?? Here's an example that conforms approximately to the structure of
>>> your data: on my machine the peak RAM usage is 121 Mb, far short of your
>>> 2.3 Gb ...? so I still suspect there is something going on that we don't
>>> know about/haven't guessed yet.
>>> 
>>> set.seed(101)
>>> N <- 22945
>>> ns <- 100
>>> nf <- 100
>>> nid <- 100
>>> dd <- data.frame(X1=rnorm(N),
>>>? ????????????????? X2=rnorm(N),
>>>? ????????????????? X3=rnorm(N),
>>>? ????????????????? site=sample(ns, replace=TRUE, size=N),
>>>? ????????????????? family=sample(nf, replace=TRUE, size=N),
>>>? ????????????????? id=sample(nid, replace=TRUE, size=N))
>>> form <- Y ~ 1 + X1 + X2 + X3 + (1|site/family/id)
>>> dd$Y <- simulate(form[-2], newdata=dd, family=gaussian,
>>>                    
>>> newparams=list(beta=rep(1,4),theta=rep(1,3),sigma=1))[[1]]
>>> library(peakRAM)
>>> mem <- peakRAM(
>>>? ???? m <- lmer(form, data=dd, REML=FALSE)
>>> )
>>> 
>>> mem
>>>? ????????????????????? Function_Call Elapsed_Time_sec Total_RAM_Used_MiB
>>> 1 m<-lmer(form,data=dd,REML=FALSE)??????????? 1.754?????????????? 10.3
>>>? ?? Peak_RAM_Used_MiB
>>> 1???????????? 120.7
>>> 
>>> 
>>> On 3/5/21 4:52 PM, Robert Long wrote:
>>>> Perhaps because of the different ways they store objects internally while
>>>> fitting the models.
>>>> 
>>>> On Fri, 5 Mar 2021, 21:47 Hedyeh Ahmadi, <hedyehah at usc.edu> wrote:
>>>> 
>>>>> Thank you for the reply Robert - If I am running out of memory in lmer(),
>>>>> do you know why lme() runs just fine?
>>>>>
>>>>> Best,
>>>>>
>>>>> Hedyeh Ahmadi, Ph.D.
>>>>> Statistician
>>>>> Keck School of Medicine
>>>>> Department of Preventive Medicine
>>>>> University of Southern California
>>>>>
>>>>> Postdoctoral Scholar
>>>>> Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
>>>>> University of California, Irvine
>>>>>
>>>>> LinkedIn
>>>>> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$> 
> 
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$>> 
> 
>> 
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$ 
> 
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$>>> 
> 
>> 
>>> 
>>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$ 
> 
>> 
>>>? >
>>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$ 
> 
>> 
>>>? >
>>>>>
>>>>>
>>>>>
>>>>>
>>>>> ------------------------------
>>>>> *From:* Robert Long <longrob604 at gmail.com>
>>>>> *Sent:* Friday, March 5, 2021 1:43 PM
>>>>> *To:* Hedyeh Ahmadi <hedyehah at usc.edu>
>>>>> *Cc:* Dexter Locke <dexter.locke at gmail.com>; R-mixed models mailing list <
>>>>> r-sig-mixed-models at r-project.org>; Megan M. Herting <herting at usc.edu>;
>>>>> Elisabeth Burnor <burnor at usc.edu>
>>>>> *Subject:* Re: [R-sig-ME] A three-level GLMM with binomial link in R
>>>>>
>>>>> You've run out of memory. Try running it on a machine with much larger RAM.
>>>>>
>>>>> On Fri, 5 Mar 2021, 21:18 Hedyeh Ahmadi, <hedyehah at usc.edu> wrote:
>>>>>
>>>>> Hi - Thank you for the informative replies.
>>>>>
>>>>> I will try those other packages. If MASS::glmmPQL uses lme() then this
>>>>> should work for me.
>>>>>
>>>>> My data structure is complex so it's hard to give reproducible example but
>>>>> for example for two of my models I get the following errors in lmer() while
>>>>> lme() runs smoothly.
>>>>>
>>>>> 1- Error: cannot allocate vector of size 2.3 Gb.
>>>>>
>>>>> 2- Error: couldn't evaluate grouping factor id:(family:site) within model
>>>>> frame: try adding grouping factor to data frame explicitly if possible.
>>>>> (note that the id variable works for simpler lmer() models so the variable
>>>>> itself is not an issue)
>>>>>
>>>>> My model looks like the following nested structure:
>>>>> lmer(Y ~ 1 + X1 + X2 + X3 + (1|site/family/id), data=dd, REML = FALSE)
>>>>>
>>>>> Best,
>>>>>
>>>>> Hedyeh Ahmadi, Ph.D.
>>>>> Statistician
>>>>> Keck School of Medicine
>>>>> Department of Preventive Medicine
>>>>> University of Southern California
>>>>>
>>>>> Postdoctoral Scholar
>>>>> Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
>>>>> University of California, Irvine
>>>>>
>>>>> LinkedIn
>>>>> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$> 
> 
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$>> 
> 
>> 
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$ 
> 
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$>>> 
> 
>> 
>>> 
>>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$ 
> 
>> 
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$ 
> 
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$>>>>
>>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$ 
> 
>> 
>>> 
>>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$ 
> 
>> 
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$ 
> 
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$>>>>
>>>>>>
>>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$ 
> 
>> 
>>> 
>>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$ 
> 
>> 
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$ 
> 
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$>>>>
>>>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$ 
> 
>> 
>>> 
>>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$ 
> 
>> 
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$ 
> 
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$>>>>
>>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>> ________________________________
>>>>> From: Dexter Locke <dexter.locke at gmail.com>
>>>>> Sent: Friday, March 5, 2021 1:01 PM
>>>>> To: Hedyeh Ahmadi <hedyehah at usc.edu>
>>>>> Cc: r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>;
>>>>> Megan M. Herting <herting at usc.edu>; Elisabeth Burnor <burnor at usc.edu>
>>>>> Subject: Re: [R-sig-ME] A three-level GLMM with binomial link in R
>>>>>
>>>>> Hi Hedyeh,
>>>>>
>>>>> What is the problem you are having? Specifically, what is the estimation
>>>>> issue with lmer and lme?
>>>>>
>>>>> Can you provide a reproducible example? Can you provide the complete
>>>>> errors you are seeing?
>>>>>
>>>>> The current questions are vague, so it will be challenging for list
>>>>> members to provide much guidance.
>>>>>
>>>>> -Dexter
>>>>>
>>>>>
>>>>> On Fri, Mar 5, 2021 at 3:27 PM Hedyeh Ahmadi <hedyehah at usc.edu<mailto:
>>>>> hedyehah at usc.edu>> wrote:
>>>>> Hi All,
>>>>> I was wondering what would be a powerful package in R to run GLMM with
>>>>> logit link that can handle a data set with N=22945 and 3 nested random
>>>>> intercepts. So far, I have tried glmer() from lme4 and it's giving me a lot
>>>>> of estimation issues. Any other package I should try?
>>>>>
>>>>> I am asking for another package as I am having the same issue with lmer()
>>>>> for similar LMM with continuous outcome, while lme() from nlme package runs
>>>>> the models with no problem.
>>>>>
>>>>> Thank you in advance.
>>>>>
>>>>> Best,
>>>>>
>>>>> Hedyeh Ahmadi, Ph.D.
>>>>> Statistician
>>>>> Keck School of Medicine
>>>>> Department of Preventive Medicine
>>>>> University of Southern California
>>>>>
>>>>> Postdoctoral Scholar
>>>>> Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
>>>>> University of California, Irvine
>>>>>
>>>>> LinkedIn
>>>>> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$> 
> 
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$>> 
> 
>> 
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$ 
> 
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$>>> 
> 
>> 
>>> 
>>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$ 
> 
>> 
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$ 
> 
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$>>>>
>>>>> <
>>>>> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$> 
> 
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$>> 
> 
>> 
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$ 
> 
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$>>>
>>>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$ 
> 
>> 
>>> 
>>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$ 
> 
>> 
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$ 
> 
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$>>>>
>>>>> <
>>>>> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$> 
> 
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$>> 
> 
>> 
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$ 
> 
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$>>>
>>>>>>>
>>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$ 
> 
>> 
>>> 
>>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$ 
> 
>> 
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$ 
> 
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$>>>>
>>>>> <
>>>>> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$> 
> 
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$>> 
> 
>> 
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$ 
> 
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$>>>
>>>>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$ 
> 
>> 
>>> 
>>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$ 
> 
>> 
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$ 
> 
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$>>>>
>>>>> <
>>>>> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$> 
> 
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$>> 
> 
>> 
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$ 
> 
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$>>>
>>>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>????????? [[alternative HTML version deleted]]
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org>
>>>>> mailing list
>>>>> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$ 
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$> 
> 
>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$ 
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$>> 
> 
>> 
>>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$ 
> 
>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$ 
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$>>> 
> 
>> 
>>> 
>>>>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKG8rJcsmY$ 
> 
>> 
>>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKG8rJcsmY$ 
> 
>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKG8rJcsmY$ 
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKG8rJcsmY$>>>>
>>>>> <
>>>>> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQM6wKtNs$ 
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQM6wKtNs$> 
> 
>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQM6wKtNs$ 
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQM6wKtNs$>> 
> 
>> 
>>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQM6wKtNs$ 
> 
>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQM6wKtNs$ 
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQM6wKtNs$>>>
>>>>>>
>>>>>
>>>>>????????? [[alternative HTML version deleted]]
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$ 
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$> 
> 
>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$ 
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$>> 
> 
>> 
>>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$ 
> 
>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$ 
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$>>> 
> 
>> 
>>> 
>>>>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKG8rJcsmY$ 
> 
>> 
>>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKG8rJcsmY$ 
> 
>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKG8rJcsmY$ 
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKG8rJcsmY$>>>>
>>>>>
>>>>>
>>>> 
>>>>??????? [[alternative HTML version deleted]]
>>>> 
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$ 
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$> 
> 
>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$ 
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$>> 
> 
>> 
>>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$ 
> 
>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$ 
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$>>> 
> 
>> 
>>> 
>>>>
>>> 
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$ 
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$> 
> 
>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$ 
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$>> 
> 
>> 
>>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$ 
> 
>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$ 
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$>>> 
> 
>> 
>>>


From hedyeh@h @end|ng |rom u@c@edu  Fri Mar 12 21:54:10 2021
From: hedyeh@h @end|ng |rom u@c@edu (Hedyeh Ahmadi)
Date: Fri, 12 Mar 2021 20:54:10 +0000
Subject: [R-sig-ME] A three-level GLMM with binomial link in R
In-Reply-To: <c70f39ad-dbb4-5f3a-3e9d-9baa6e4c9da6@gmail.com>
References: <BYAPR07MB50945A60AFDE467F317861ACD1969@BYAPR07MB5094.namprd07.prod.outlook.com>
 <CAA=SVwH2pE+EAtEqALjeRPT91tWz-HJegrQkz9mYqfj7pb_A1Q@mail.gmail.com>
 <BYAPR07MB50947CD020DADA71CFF86407D1969@BYAPR07MB5094.namprd07.prod.outlook.com>
 <CA+3TTkNL+JGE+pgfOqASfvJ+r5eHmbGt3v+FzazouVePs_=x9Q@mail.gmail.com>
 <BYAPR07MB509450F1132EEB7C41F60B4CD1969@BYAPR07MB5094.namprd07.prod.outlook.com>
 <CA+3TTkM-abt0u4Je03nnTBBKiZw4AFj-UdPfyP_JOLZbDiJEFA@mail.gmail.com>
 <9e903a9f-5bec-934c-0b50-b2fca97cd4f3@gmail.com>
 <BYAPR07MB5094069BFA432F89688D34DCD1939@BYAPR07MB5094.namprd07.prod.outlook.com>
 <a8005560-3957-e814-df74-604d9cb857bb@gmail.com>
 <BYAPR07MB5094DD4608A0B5DB96A52EB5D1909@BYAPR07MB5094.namprd07.prod.outlook.com>
 <971aa7fc-a424-154d-c451-3027988f3c55@gmail.com>
 <BYAPR07MB5094B054FF44075722E4C378D16F9@BYAPR07MB5094.namprd07.prod.outlook.com>,
 <c70f39ad-dbb4-5f3a-3e9d-9baa6e4c9da6@gmail.com>
Message-ID: <BYAPR07MB50942F7C5155017E7D847301D16F9@BYAPR07MB5094.namprd07.prod.outlook.com>

I'll think more about how to share a data set that would create the same error. Sorry, I am not very simulation savvy but I'll try harder next time.

On the bright side, I was able to run the following model by implicitly defining the group structure (slightly different from what was suggested in the previous email) and it does give me the same estimation as lme() with random = ~1|site/family/id random structure - so the memory issue resolved for this model! Thank you for the suggestion.

dd$site_family <- interaction(dd$site, dd$family)
m2.1 <- lmer(cbcl_scr_syn_internal_r ~ 1 + X1 + X2 + X3+ (1|site) +(1|site_family/id), data=dd,  REML = FALSE)

But now getting to my last question: My data has 22945 rows, and some individuals have only baseline measurement, some individuals have baseline and 1 year measurement. A variable called eventname is the indicator of that. I am now confused as my "id" variable does not have this information (i.e. the order of measurement). How would the model recognize that which repeated measure is measurment1 (i.e. baseline) and which one is measurment2 (i.e. 1 year)?  Or maybe because I don't have a random slope, I don't need to define the repeated measure structure and adding eventname as a fixed effect is sufficient?

OR do I need to run a model with additional random intercept of eventname but in doing so lme() gives me the number of observation equal to umber of grouping for eventname %in% id %in% family %in% site as follows. Would that be okay?

Number of Observations: 13388
Number of Groups:
                                                       site                                               family %in% site
                                                        21                                                       9393
                                              id %in% family %in% site                  eventname %in% id %in% family %in% abcd_site
                                                     11111                                                      13388

The model formula with eventname as random slope in lme() would be as follows but I have not been able to reproduce this in lmer() similar to implicit formatting of m2.1 shown above - any help would be appreciated here. Keep in mind created an implicit three-way and four-way interaction takes too much memory on my personal PC so I am trying to find a way around it as I did in m2.1.

m3 <- lme(cbcl_scr_syn_internal_r ~ 1 +X1+ X2 + X3, random = ~1|site/family/id//eventname ,
    data=dd, na.action=na.exclude,method="ML")

Again, thank you so much for your time.

Best,

Hedyeh Ahmadi, Ph.D.
Statistician
Keck School of Medicine
Department of Preventive Medicine
University of Southern California

Postdoctoral Scholar
Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
University of California, Irvine

LinkedIn
www.linkedin.com/in/hedyeh-ahmadi<http://www.linkedin.com/in/hedyeh-ahmadi>
<http://www.linkedin.com/in/hedyeh-ahmadi><http://www.linkedin.com/in/hedyeh-ahmadi>




________________________________
From: Ben Bolker <bbolker at gmail.com>
Sent: Friday, March 12, 2021 11:45 AM
To: Hedyeh Ahmadi <hedyehah at usc.edu>; r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] A three-level GLMM with binomial link in R



On 3/12/21 12:13 PM, Hedyeh Ahmadi wrote:
> Here are my comments/questions:
>
>  1. I have tried changing the site, family, and id to factor and I get
>     the same results.
>  2. Unfortunately, I can't share my data due to privacy issues but if
>     you tell me what other information you need, I can provide it.

   We know you can't share the data.  Part of the art of getting
software help is figuring out how you can create a shareable version of
your data set, *or* a shareable version of something that will generate
the same errors you're experiencing.  We need to do a bisection search
between the private data you have, which causes problems with factor
expansion in the grouping variables and is surprisingly memory-hungry,
and the reproducible examples that I have constructed that mimic some
aspects of your data set but don't show either problem.  Since we can't
look at your data, the burden falls on you to create a
reproducible/shareable example we can work with.

    Assuming that

lmer(y ~ 1  +(1|site/family/id) , data =dd)

does show problems with your actual data set, can you anonymize the
levels of site, family, and id, something like

   anon_fac <- function(x, prefix="S") {
       factor(x, levels=levels(x), labels=paste0(prefix,
seq(length(levels(x))))
   }

   anon_dd <- transform(dd, select=c(family, site, id))
   anon_dd <- transform(anon_dd,
           site=anon_fac(site,"S"),
           family=anon_fac(family,"F"),
           id=anon_fac(id,"I")
   )

This should provide a data set that contains *no* information other than
the pattern of co-occurrence of grouping levels. I don't know who's in
charge of data privacy for your group, but it's hard to imagine how
sharing this would present a risk of personal identification ...

https://urldefense.com/v3/__https://stackoverflow.com/questions/10454973/how-to-create-example-data-set-from-private-data-replacing-variable-names-and-l__;!!LIr3w8kk_Xxm!86i5mS45OmW-JeD4GGs4ZQyanE9ePtf5QzjgYVkL_Rg284MkmW9z-lQGP70cEP4$

https://urldefense.com/v3/__https://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example/6699112*6699112__;Iw!!LIr3w8kk_Xxm!86i5mS45OmW-JeD4GGs4ZQyanE9ePtf5QzjgYVkL_Rg284MkmW9z-lQGfDnxgGI$


>  3. Note that when I run the three-way interaction code in my PC it
>     again runs out of memory and the error says the following. When I
>     tried to run it on interactive HPC, it kicks me out as it takes too
>     much memory/time so I will have to submit a batch script.
>     "Error: cannot allocate vector of size 18.1 Gb
>     In addition: Warning message:
>     In ans * length(l) :
>     Error: cannot allocate vector of size 18.1 Gb"
>  4. When I take out all the fixed effects, the problem still exists.


   That's good in one sense, as it simplifies the problem.

>  5. *Question:* Also note that my data has 22945 rows, and some
>     individuals have only baseline measurement only, some individuals
>     have baseline and 1 year measurement. A variable called eventname is
>     the indicator of that. I am now confused as my "id" variable does
>     not have this information (i.e. the order of measurement). How would
>     the model recognize that which repeated measure is measurment1 (i.e.
>     baseline) and which one is measurment2(i.e. 1 year)?  Or maybe
>     because I don't have a random slope, I don't need to define the
>     repeated measure structure and adding eventname as a fixed effect is
>     sufficient?

    Let's deal with this after we have the basic problems sorted.  If
you want to account for the possible effects of ordering, then you'd
need to add this variable ...

>
> Thanks again for all your help on this.
>
> Best,
>
> Hedyeh Ahmadi, Ph.D.
> Statistician
> Keck School of Medicine
> Department of Preventive Medicine
> University of Southern California
>
> Postdoctoral Scholar
> Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
> University of California, Irvine
>
> LinkedIn
> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!86i5mS45OmW-JeD4GGs4ZQyanE9ePtf5QzjgYVkL_Rg284MkmW9z-lQGJrML1Sk$  <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!86i5mS45OmW-JeD4GGs4ZQyanE9ePtf5QzjgYVkL_Rg284MkmW9z-lQGJrML1Sk$ >
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!86i5mS45OmW-JeD4GGs4ZQyanE9ePtf5QzjgYVkL_Rg284MkmW9z-lQGJrML1Sk$ ><https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!86i5mS45OmW-JeD4GGs4ZQyanE9ePtf5QzjgYVkL_Rg284MkmW9z-lQGJrML1Sk$ >
>
>
>
>
> ------------------------------------------------------------------------
> *From:* Ben Bolker <bbolker at gmail.com>
> *Sent:* Thursday, March 11, 2021 3:55 PM
> *To:* Hedyeh Ahmadi <hedyehah at usc.edu>; r-sig-mixed-models at r-project.org
> <r-sig-mixed-models at r-project.org>; Megan M. Herting <herting at usc.edu>;
> Elisabeth Burnor <burnor at usc.edu>
> *Subject:* Re: [R-sig-ME] A three-level GLMM with binomial link in R
>
>
> On 3/11/21 1:11 PM, Hedyeh Ahmadi wrote:
>> Hi Ben,
>> Thank you for all the help and informative replies. Here is some info
>> about my data and my answers:
>>
>>   * Yes, I am running the exact model however this is just my toy model
>>     to get the code to work.
>>   * Reminder, I am trying to get lmer with a continuous outcome (but
>>     same data structure, with 3 random intercept) work before moving to
>>     glmer() with a logit link with a categorical 0/1 outcome.
>>   * Here are some information about my data:
>>       o X1: num [1:22945] 9.25 NA 9.22 NA 9.22 NA 9.42 NA 9.25 NA ...
>>       o X2: int [1:22945] 117 140 128 125 113 138 126 130 120 121 ...
>>       o X3: chr [1:22945] "Female" "Male" "Male" "Male" "Male"
>>       o site: chr [1:22945] "site15" "site15" "site15" "site15" "site15"
>>         ... (I have 21 sites)
>>       o family: int [1:22945] 0 1 1 1 1 3 3 4 4 5 ...
>>       o id: chr [1:22945] "id1" "id2" "id2" "id3" "id3"...
>>   * The following model gives me the error that "Error: couldn't
>>     evaluate grouping factor id:(family:site) within model frame: try
>>     adding grouping factor to data frame explicitly if possible" - I ran
>>     this same model on a supercomputer and it *gave me the same error*,
>>     so this is not a memory limit issue.
>
> So far I can't replicate this.  It seemed fishy to me that family was an
> integer (I would try explicitly converting it to a factor), but doesn't
> actually cause any problems in my example.
>
>    (This differs from your example but not in ways I would expect to be
> important: in particular, the types of the grouping variables are the
> same [chr, int, chr]
>
> n <- 10000
> set.seed(101)
> dd <- data.frame(y=rnorm(n),
>                    x1=rnorm(n),
>                    x2=rnorm(n),
>                    x3=rnorm(n),
>                    site=sample(paste0("s",1:15),size=n,replace=TRUE),
>                    family=sample(1:100,size=n,replace=TRUE),
>                    id=sample(paste0("id",1:20),size=n,replace=TRUE))
> library(lme4)
> lmer(y~1 + x1 + x2 + x3 + (1|site/family/id), data=dd)
>
> ###
>
> What is meant by "adding grouping factor to data frame explicitly" would
> be in this case expanding out the nested terms:
>
>    dd <- within(dd,
> {
>       site_family <- interaction(site,family)
>       site_family_id <- interaction(site,family,id)
> })
>
> lmer(y~1 + x1 + x2 + x3 + (1|site) + (1|site_family) +
> (1|site_family_id), data =dd)
>
>
>
>>       o m2 <- lmer(cbcl_scr_syn_internal_r ~ 1 + X1 + X2 + X3 +
>>         (1|site/family/id), data=dd, REML = FALSE)
>>   * The following *model ran on a supercomputer*.  This is the model
>>     that previously would give me the error "Error: cannot allocate
>>     vector of size 2.3 Gb". Here I am*reducing the number of sites to
>>     see if it runs, and it did* run on a supercomputer.
>>       o m11 <- lmer(cbcl_scr_syn_internal_r ~ 1 + X1 +X2 + X3
>>         +(1|site/family/id) ,
>>              data=dd[-which(dd$abcd_site %in% c("site01","site02",
>>         "site04", "site05", "site06", "site07", "site08","site09")),],
>>         na.action=na.exclude, REML=FALSE)
>>
>> Questions:
>>
>>  1. What I don't understand is that in m2, why lmer() does not
>>     recognizes the grouping factor that it does recognize in m11?
>
>    I'm not sure either.
>
>>  2. At this point I don't think this is a memory issue as *m2 did not
>>     run on a supercompute*r and it's giving me *the same error as my
>>     personal computer*. However, in m11, the same grouping structure is
>>     being recognized when I reduce the number of sites from 21 to 13 -
>>     could this be because of severe imbalance in my family/id nesting,
>>     meaning most families have only one kid but some have 2 and a few
>>     have 3 kids?
>
>     It seems surprising.
>     Is there any way we can get a reproducible example?  For example,
> suppose you randomize your X1, X2, X3 and anonymize all of your grouping
> variables: would you then be able to share the data set?
>
>     Does the problem (let's say just the first problem) still occur if
> you leave out the fixed effects? (I would expect so, and that would
> simplify things somewhat - we're trying to get to the *simplest* example
> that still demonstrates the problem.)
>
>
>>
>> Sorry about the long email and thank you for your help in advance.
>>
>> Best,
>>
>> Hedyeh Ahmadi, Ph.D.
>> Statistician
>> Keck School of Medicine
>> Department of Preventive Medicine
>> University of Southern California
>>
>> Postdoctoral Scholar
>> Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
>> University of California, Irvine
>>
>> LinkedIn
>> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!51-zg2ISp-lS-4HEW0ZNNEVE1ZD8ujdJZYx90xVOnZ-x6A7l6eu2KhSgMhYCJq4$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!51-zg2ISp-lS-4HEW0ZNNEVE1ZD8ujdJZYx90xVOnZ-x6A7l6eu2KhSgMhYCJq4$>
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!51-zg2ISp-lS-4HEW0ZNNEVE1ZD8ujdJZYx90xVOnZ-x6A7l6eu2KhSgMhYCJq4$
>  >
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!51-zg2ISp-lS-4HEW0ZNNEVE1ZD8ujdJZYx90xVOnZ-x6A7l6eu2KhSgMhYCJq4$
>  ><https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!51-zg2ISp-lS-4HEW0ZNNEVE1ZD8ujdJZYx90xVOnZ-x6A7l6eu2KhSgMhYCJq4$ >
>>
>>
>>
>>
>> ------------------------------------------------------------------------
>> *From:* Ben Bolker <bbolker at gmail.com>
>> *Sent:* Tuesday, March 9, 2021 4:12 PM
>> *To:* Hedyeh Ahmadi <hedyehah at usc.edu>; r-sig-mixed-models at r-project.org
>> <r-sig-mixed-models at r-project.org>
>> *Subject:* Re: [R-sig-ME] A three-level GLMM with binomial link in R
>>     OK, then it would be very helpful to have more details about your
>> data set. Are one or more of X1, X2, X3 categorical predictors with many
>> levels ... ?  Any chance we can see str() or summary() ?  Are you using
>> exactly the formula you told us about, or something slightly different?
>>
>>     The computational burden of a large number of fixed effect parameters
>> will be much worse for glmer than for lmer, unless you use nAGQ=0.
>> glmmTMB would be able to help in two ways: (1) it doesn't scale as badly
>> for large numbers of fixed effects; (2) it allows sparse fixed-effect
>> model matrices (something we keep meaning to (re)implement in lme4) ...
>>
>>    Making X1 into a 1000-level factor brings the required memory up by
>> about a factor of 10 and increases the run time from seconds to minutes.
>>
>>
>> Base model:
>>
>>                        Function_Call Elapsed_Time_sec Total_RAM_Used_MiB
>> 1 m<-lmer(form,data=dd,REML=FALSE)            1.903               10.4
>>     Peak_RAM_Used_MiB
>> 1             107.7
>>
>> With X=1000-level factor (no derivative calculations):
>>
>>    Function_Call
>> 1
>> m2<-lmer(form,data=dd2,REML=FALSE,control=lmerControl(calc.derivs=FALSE),verbose=10)
>>     Elapsed_Time_sec Total_RAM_Used_MiB Peak_RAM_Used_MiB
>> 1          559.735              608.8             984.5
>>
>>
>> With derivative calculation at the end:
>>
>>                                    Function_Call Elapsed_Time_sec
>> 1 m3<-lmer(form,data=dd2,REML=FALSE,verbose=10)          677.975
>>     Total_RAM_Used_MiB Peak_RAM_Used_MiB
>> 1              608.7            1148.7
>>   >
>>   >
>>
>> ---
>> ibrary(lme4)
>> set.seed(101)
>> N <- 22945
>> ns <- 100
>> nf <- 100
>> nid <- 100
>> dd <- data.frame(X1=rnorm(N),
>>                    X2=rnorm(N),
>>                    X3=rnorm(N),
>>                    site=sample(ns, replace=TRUE, size=N),
>>                    family=sample(nf, replace=TRUE, size=N),
>>                    id=sample(nid, replace=TRUE, size=N))
>> form <- Y ~ 1 + X1 + X2 + X3 + (1|site/family/id)
>> dd$Y <- simulate(form[-2], newdata=dd, family=gaussian,
>>
>> newparams=list(beta=rep(1,4),theta=rep(1,3),sigma=1))[[1]]
>> library(peakRAM)
>> system.time(mem <- peakRAM(
>>       m <- lmer(form, data=dd, REML=FALSE)
>>       ))
>> print(mem)
>>
>> dd2 <- transform(dd,
>>           X1=factor(sample(1000,size=N,replace=TRUE)))
>>
>> system.time(mem2 <- peakRAM(
>>       m2 <- lmer(form, data=dd2, REML=FALSE,
>> control=lmerControl(calc.derivs=FALSE), verbose=10)
>> ))
>> print(mem2)
>>
>> system.time(mem3 <- peakRAM(
>>       m3 <- lmer(form, data=dd2, REML=FALSE, verbose=10)
>> ))
>> print(mem3)
>>
>>
>> On 3/8/21 11:29 AM, Hedyeh Ahmadi wrote:
>>> Thank you for the toy example. This same example in my PC gives the
>>> following memory use output:
>>>
>>>
>>>  > mem
>>>                       Function_Call
>>> Elapsed_Time_sec         Total_RAM_Used_MiB    Peak_RAM_Used_MiB
>>>    m<-lmer(form,data=dd,REML=FALSE)             2.64
>>>                  10.3                                       130.1
>>>
>>> When I run peakRAM() for my actual data, it take one hour plus then my
>>> PC slows down, then I have to stop R to be able to use my PC.
>>>
>>> Best,
>>>
>>> Hedyeh Ahmadi, Ph.D.
>>> Statistician
>>> Keck School of Medicine
>>> Department of Preventive Medicine
>>> University of Southern California
>>>
>>> Postdoctoral Scholar
>>> Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
>>> University of California, Irvine
>>>
>>> LinkedIn
>>> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5O8KlsAUILt44__IHSzbCUgVs7dWxAB8FS9wiKC3j5P6hGrnuJSGckmCIR91AZs$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5O8KlsAUILt44__IHSzbCUgVs7dWxAB8FS9wiKC3j5P6hGrnuJSGckmCIR91AZs$>
>
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5O8KlsAUILt44__IHSzbCUgVs7dWxAB8FS9wiKC3j5P6hGrnuJSGckmCIR91AZs$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5O8KlsAUILt44__IHSzbCUgVs7dWxAB8FS9wiKC3j5P6hGrnuJSGckmCIR91AZs$>>
>
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5O8KlsAUILt44__IHSzbCUgVs7dWxAB8FS9wiKC3j5P6hGrnuJSGckmCIR91AZs$
>
>>  >
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5O8KlsAUILt44__IHSzbCUgVs7dWxAB8FS9wiKC3j5P6hGrnuJSGckmCIR91AZs$
>
>>  ><https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5O8KlsAUILt44__IHSzbCUgVs7dWxAB8FS9wiKC3j5P6hGrnuJSGckmCIR91AZs$
>  >
>>>
>>>
>>>
>>>
>>> ------------------------------------------------------------------------
>>> *From:* R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on
>>> behalf of Ben Bolker <bbolker at gmail.com>
>>> *Sent:* Friday, March 5, 2021 5:44 PM
>>> *To:* r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>
>>> *Subject:* Re: [R-sig-ME] A three-level GLMM with binomial link in R
>>>     Here's an example that conforms approximately to the structure of
>>> your data: on my machine the peak RAM usage is 121 Mb, far short of your
>>> 2.3 Gb ...  so I still suspect there is something going on that we don't
>>> know about/haven't guessed yet.
>>>
>>> set.seed(101)
>>> N <- 22945
>>> ns <- 100
>>> nf <- 100
>>> nid <- 100
>>> dd <- data.frame(X1=rnorm(N),
>>>                    X2=rnorm(N),
>>>                    X3=rnorm(N),
>>>                    site=sample(ns, replace=TRUE, size=N),
>>>                    family=sample(nf, replace=TRUE, size=N),
>>>                    id=sample(nid, replace=TRUE, size=N))
>>> form <- Y ~ 1 + X1 + X2 + X3 + (1|site/family/id)
>>> dd$Y <- simulate(form[-2], newdata=dd, family=gaussian,
>>>
>>> newparams=list(beta=rep(1,4),theta=rep(1,3),sigma=1))[[1]]
>>> library(peakRAM)
>>> mem <- peakRAM(
>>>       m <- lmer(form, data=dd, REML=FALSE)
>>> )
>>>
>>> mem
>>>                        Function_Call Elapsed_Time_sec Total_RAM_Used_MiB
>>> 1 m<-lmer(form,data=dd,REML=FALSE)            1.754               10.3
>>>     Peak_RAM_Used_MiB
>>> 1             120.7
>>>
>>>
>>> On 3/5/21 4:52 PM, Robert Long wrote:
>>>> Perhaps because of the different ways they store objects internally while
>>>> fitting the models.
>>>>
>>>> On Fri, 5 Mar 2021, 21:47 Hedyeh Ahmadi, <hedyehah at usc.edu> wrote:
>>>>
>>>>> Thank you for the reply Robert - If I am running out of memory in lmer(),
>>>>> do you know why lme() runs just fine?
>>>>>
>>>>> Best,
>>>>>
>>>>> Hedyeh Ahmadi, Ph.D.
>>>>> Statistician
>>>>> Keck School of Medicine
>>>>> Department of Preventive Medicine
>>>>> University of Southern California
>>>>>
>>>>> Postdoctoral Scholar
>>>>> Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
>>>>> University of California, Irvine
>>>>>
>>>>> LinkedIn
>>>>> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$>
>
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$>>
>
>>
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$
>
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$>>>
>
>>
>>>
>>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$
>
>>
>>>  >
>>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$
>
>>
>>>  >
>>>>>
>>>>>
>>>>>
>>>>>
>>>>> ------------------------------
>>>>> *From:* Robert Long <longrob604 at gmail.com>
>>>>> *Sent:* Friday, March 5, 2021 1:43 PM
>>>>> *To:* Hedyeh Ahmadi <hedyehah at usc.edu>
>>>>> *Cc:* Dexter Locke <dexter.locke at gmail.com>; R-mixed models mailing list <
>>>>> r-sig-mixed-models at r-project.org>; Megan M. Herting <herting at usc.edu>;
>>>>> Elisabeth Burnor <burnor at usc.edu>
>>>>> *Subject:* Re: [R-sig-ME] A three-level GLMM with binomial link in R
>>>>>
>>>>> You've run out of memory. Try running it on a machine with much larger RAM.
>>>>>
>>>>> On Fri, 5 Mar 2021, 21:18 Hedyeh Ahmadi, <hedyehah at usc.edu> wrote:
>>>>>
>>>>> Hi - Thank you for the informative replies.
>>>>>
>>>>> I will try those other packages. If MASS::glmmPQL uses lme() then this
>>>>> should work for me.
>>>>>
>>>>> My data structure is complex so it's hard to give reproducible example but
>>>>> for example for two of my models I get the following errors in lmer() while
>>>>> lme() runs smoothly.
>>>>>
>>>>> 1- Error: cannot allocate vector of size 2.3 Gb.
>>>>>
>>>>> 2- Error: couldn't evaluate grouping factor id:(family:site) within model
>>>>> frame: try adding grouping factor to data frame explicitly if possible.
>>>>> (note that the id variable works for simpler lmer() models so the variable
>>>>> itself is not an issue)
>>>>>
>>>>> My model looks like the following nested structure:
>>>>> lmer(Y ~ 1 + X1 + X2 + X3 + (1|site/family/id), data=dd, REML = FALSE)
>>>>>
>>>>> Best,
>>>>>
>>>>> Hedyeh Ahmadi, Ph.D.
>>>>> Statistician
>>>>> Keck School of Medicine
>>>>> Department of Preventive Medicine
>>>>> University of Southern California
>>>>>
>>>>> Postdoctoral Scholar
>>>>> Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
>>>>> University of California, Irvine
>>>>>
>>>>> LinkedIn
>>>>> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$>
>
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$>>
>
>>
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$
>
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$>>>
>
>>
>>>
>>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$
>
>>
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$
>
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$>>>>
>>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$
>
>>
>>>
>>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$
>
>>
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$
>
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$>>>>
>>>>>>
>>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$
>
>>
>>>
>>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$
>
>>
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$
>
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$>>>>
>>>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$
>
>>
>>>
>>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$
>
>>
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$
>
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$>>>>
>>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>> ________________________________
>>>>> From: Dexter Locke <dexter.locke at gmail.com>
>>>>> Sent: Friday, March 5, 2021 1:01 PM
>>>>> To: Hedyeh Ahmadi <hedyehah at usc.edu>
>>>>> Cc: r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>;
>>>>> Megan M. Herting <herting at usc.edu>; Elisabeth Burnor <burnor at usc.edu>
>>>>> Subject: Re: [R-sig-ME] A three-level GLMM with binomial link in R
>>>>>
>>>>> Hi Hedyeh,
>>>>>
>>>>> What is the problem you are having? Specifically, what is the estimation
>>>>> issue with lmer and lme?
>>>>>
>>>>> Can you provide a reproducible example? Can you provide the complete
>>>>> errors you are seeing?
>>>>>
>>>>> The current questions are vague, so it will be challenging for list
>>>>> members to provide much guidance.
>>>>>
>>>>> -Dexter
>>>>>
>>>>>
>>>>> On Fri, Mar 5, 2021 at 3:27 PM Hedyeh Ahmadi <hedyehah at usc.edu<mailto:
>>>>> hedyehah at usc.edu>> wrote:
>>>>> Hi All,
>>>>> I was wondering what would be a powerful package in R to run GLMM with
>>>>> logit link that can handle a data set with N=22945 and 3 nested random
>>>>> intercepts. So far, I have tried glmer() from lme4 and it's giving me a lot
>>>>> of estimation issues. Any other package I should try?
>>>>>
>>>>> I am asking for another package as I am having the same issue with lmer()
>>>>> for similar LMM with continuous outcome, while lme() from nlme package runs
>>>>> the models with no problem.
>>>>>
>>>>> Thank you in advance.
>>>>>
>>>>> Best,
>>>>>
>>>>> Hedyeh Ahmadi, Ph.D.
>>>>> Statistician
>>>>> Keck School of Medicine
>>>>> Department of Preventive Medicine
>>>>> University of Southern California
>>>>>
>>>>> Postdoctoral Scholar
>>>>> Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
>>>>> University of California, Irvine
>>>>>
>>>>> LinkedIn
>>>>> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$>
>
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$>>
>
>>
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$
>
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$>>>
>
>>
>>>
>>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$
>
>>
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$
>
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$>>>>
>>>>> <
>>>>> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$>
>
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$>>
>
>>
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$
>
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$>>>
>>>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$
>
>>
>>>
>>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$
>
>>
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$
>
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$>>>>
>>>>> <
>>>>> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$>
>
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$>>
>
>>
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$
>
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$>>>
>>>>>>>
>>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$
>
>>
>>>
>>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$
>
>>
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$
>
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$>>>>
>>>>> <
>>>>> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$>
>
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$>>
>
>>
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$
>
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$>>>
>>>>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$
>
>>
>>>
>>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$
>
>>
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$
>
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$>>>>
>>>>> <
>>>>> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$>
>
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$>>
>
>>
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$
>
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$>>>
>>>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>          [[alternative HTML version deleted]]
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org>
>>>>> mailing list
>>>>> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$>
>
>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$>>
>
>>
>>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$
>
>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$>>>
>
>>
>>>
>>>>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKG8rJcsmY$
>
>>
>>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKG8rJcsmY$
>
>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKG8rJcsmY$
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKG8rJcsmY$>>>>
>>>>> <
>>>>> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQM6wKtNs$
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQM6wKtNs$>
>
>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQM6wKtNs$
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQM6wKtNs$>>
>
>>
>>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQM6wKtNs$
>
>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQM6wKtNs$
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQM6wKtNs$>>>
>>>>>>
>>>>>
>>>>>          [[alternative HTML version deleted]]
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$>
>
>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$>>
>
>>
>>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$
>
>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$>>>
>
>>
>>>
>>>>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKG8rJcsmY$
>
>>
>>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKG8rJcsmY$
>
>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKG8rJcsmY$
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKG8rJcsmY$>>>>
>>>>>
>>>>>
>>>>
>>>>        [[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$>
>
>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$>>
>
>>
>>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$
>
>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$>>>
>
>>
>>>
>>>>
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$>
>
>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$>>
>
>>
>>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$
>
>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$>>>
>
>>
>>>

	[[alternative HTML version deleted]]


From |uc@@|oppo|| @end|ng |rom gm@||@com  Sat Mar 13 23:56:34 2021
From: |uc@@|oppo|| @end|ng |rom gm@||@com (Luca Foppoli)
Date: Sat, 13 Mar 2021 23:56:34 +0100
Subject: [R-sig-ME] Testing Significance of Random Effects
In-Reply-To: <4893b7fc-8b5a-451d-0d00-23ea19c47d0b@gmail.com>
References: <4893b7fc-8b5a-451d-0d00-23ea19c47d0b@gmail.com>
Message-ID: <1CF4A4AC-8653-4E87-A84D-DFEED20A2387@gmail.com>

Ciao Marco,

As your interest seems to lie in assessing whether the fit of the model has improved following the addition of a given random effect, I would suggest to look at the AIC or deviance, both (relative) measures of fit of the model on the underlying data; the smaller the AIC/deviance, the better the model fits, so you can evaluate the impact of the additional random effect by studying how these indexes change. 

I believe you can easily obtain these quantities with summary() or broom_mixed::glance() (amongst, I imagine, many other alternative methods). 

You could also check the lmerTest package, although I have not personally played with it. 
And here is another interesting source for similar needs of yours. 

On a more quasi-philosophical issue, I would make a point for NOT removing covariates merely because of a ?wrong? p-value: not only it?s a tricky subject in the setting of multi-level models (each level has a different sample size, which makes computing p-values tricky), but it is just too easy to ?turn off the brain? and blindly follow an arbitrarily set threshold. 
I do realize that this is going off-topic and we?re entering the realm of subjectivity though, so please consider this as a purely personal note. 

Happy modeling! 
Luca



> On 12 Mar 2021, at 16:06, Ben Bolker <bbolker at gmail.com> wrote:
> 
> ?  I wouldn't generally recommend removing random effects on the basis of null-hypothesis significance testing ... but others on this list might, e.g. Matuschek et al. https://arxiv.org/pdf/1511.01864.pdf (section 2.4) suggest backward stepwise removal with an alpha-level of 0.2.
> 
>  Also see https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html#testing-significance-of-random-effects
> 
> 
>> On 3/12/21 9:43 AM, Marco Zanin wrote:
>> To whom it may concern,
>> My name is Marco Zanin, I am a PhD candidate in Sport & Exercise Physiology at Leeds Beckett University (Leeds, UK) and I work as Sport Scientist at Bath Rugby (Bath, UK).
>> I am relatively new to lme4, but I was wondering whether you might help me to find a way to test the significance of the random effects in a model, whether the random effects improve/reduce the fit of the model and are thus necessary or if they could be removed from the model.
>> I look forward to hearing from you.
>> Kind regards,
>> Marco Zanin
>> ______________________________________________________________________
>> This email has been scanned by the Symantec Email Security.cloud service.
>> For more information please visit http://www.symanteccloud.com
>> ______________________________________________________________________
>>    [[alternative HTML version deleted]]
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> 
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

	[[alternative HTML version deleted]]


From |@w|@wt @end|ng |rom gm@||@com  Mon Mar 15 03:24:06 2021
From: |@w|@wt @end|ng |rom gm@||@com (Tip But)
Date: Sun, 14 Mar 2021 21:24:06 -0500
Subject: [R-sig-ME] Does corSymm() require balanced data?
Message-ID: <CADreqizRJ=U1ZhxvsgKTkktMWs_nfdvrpcZ-fG9EFX0DtCL+gA@mail.gmail.com>

Dear Members,

In my longitudinal data below, the first couple of subjects were measured 4
times but the rest of the subjects were measured 3 times (see data below).

We intend to use an unstructured residual correlation matrix in
`nlme::lme()`. But our model fails to converge.

Question: Given our data is unbalanced with respect to our grouping
variable (i.e., `id`), can we use ` corSymm()`? And if we do, what would be
the dimensions of the resultant unstructured residual correlation matrix
for our data; a 3x3 or a 4x4 matrix?

Thank you for your expertise,
Joe

# Data and R Code
dat <- read.csv("https://raw.githubusercontent.com/hkil/m/master/un.csv")

library(nlme)

fit <- lme(opp~time*ccog, random = ~1|id, correlation=corSymm(form = ~ 1 |
id),
           data=dat)

Error:
  nlminb problem, convergence error code = 1
  message = false convergence (8)

	[[alternative HTML version deleted]]


From th|erry@onke||nx @end|ng |rom |nbo@be  Mon Mar 15 08:37:01 2021
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Mon, 15 Mar 2021 08:37:01 +0100
Subject: [R-sig-ME] Does corSymm() require balanced data?
In-Reply-To: <CADreqizRJ=U1ZhxvsgKTkktMWs_nfdvrpcZ-fG9EFX0DtCL+gA@mail.gmail.com>
References: <CADreqizRJ=U1ZhxvsgKTkktMWs_nfdvrpcZ-fG9EFX0DtCL+gA@mail.gmail.com>
Message-ID: <CAJuCY5xKuSKDy5oMAR+CnXJ4ZNKvWv+HskreDu4dSL8Reepdyg@mail.gmail.com>

Dear Joe,

You have too few subjects with 4 observations. Either drop those fourth
observations. Or use a different correlation structure. E.g. an AR1

fit <- lme(
  opp ~ time * ccog, random = ~1 | id,
  correlation = corSymm(), data = dat, subset = time < 3
)

fit_alt <- lme(
  opp ~ time * ccog, random = ~1 | id,
  correlation = corAR1(form = ~ time), data = dat
)
Best regards,


ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op ma 15 mrt. 2021 om 03:27 schreef Tip But <fswfswt at gmail.com>:

> Dear Members,
>
> In my longitudinal data below, the first couple of subjects were measured 4
> times but the rest of the subjects were measured 3 times (see data below).
>
> We intend to use an unstructured residual correlation matrix in
> `nlme::lme()`. But our model fails to converge.
>
> Question: Given our data is unbalanced with respect to our grouping
> variable (i.e., `id`), can we use ` corSymm()`? And if we do, what would be
> the dimensions of the resultant unstructured residual correlation matrix
> for our data; a 3x3 or a 4x4 matrix?
>
> Thank you for your expertise,
> Joe
>
> # Data and R Code
> dat <- read.csv("https://raw.githubusercontent.com/hkil/m/master/un.csv")
>
> library(nlme)
>
> fit <- lme(opp~time*ccog, random = ~1|id, correlation=corSymm(form = ~ 1 |
> id),
>            data=dat)
>
> Error:
>   nlminb problem, convergence error code = 1
>   message = false convergence (8)
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From |@w|@wt @end|ng |rom gm@||@com  Mon Mar 15 15:56:03 2021
From: |@w|@wt @end|ng |rom gm@||@com (Tip But)
Date: Mon, 15 Mar 2021 09:56:03 -0500
Subject: [R-sig-ME] Does corSymm() require balanced data?
In-Reply-To: <CAJuCY5xKuSKDy5oMAR+CnXJ4ZNKvWv+HskreDu4dSL8Reepdyg@mail.gmail.com>
References: <CADreqizRJ=U1ZhxvsgKTkktMWs_nfdvrpcZ-fG9EFX0DtCL+gA@mail.gmail.com>
 <CAJuCY5xKuSKDy5oMAR+CnXJ4ZNKvWv+HskreDu4dSL8Reepdyg@mail.gmail.com>
Message-ID: <CADreqixHoCH8RJ0QRNZO_dSJsaqDQvJb+kYiXf64+rw79i-MMA@mail.gmail.com>

Dear Thierry,

Thank you so much for your insightful comments. May I follow-up on them
below in-line:


***"You have too few subjects with 4 observations. Either drop those fourth
observations."

>>>> Does the above mean that for an unstructured residual correlation
matrix, the unique number of measurements (e.g., 3 times, 4 times etc.)
must have relatively equal sizes (e.g., 9 subjects with 3 times, 7 subjects
with 4 times)?

***"Or use a different correlation structure. E.g. an AR1:

fit_alt <- lme(opp ~ time * ccog, random = ~1 | id,
  correlation = corAR1(form = ~ time), data = dat)
"

>>>> In your above R code, is it necessary to use `corAR1(form = ~ time)`?
It seems `corAR1(form = ~1 | id)` gives the same result?

On Mon, Mar 15, 2021 at 2:37 AM Thierry Onkelinx <thierry.onkelinx at inbo.be>
wrote:

> Dear Joe,
>
> You have too few subjects with 4 observations. Either drop those fourth
> observations. Or use a different correlation structure. E.g. an AR1
>
> fit <- lme(
>   opp ~ time * ccog, random = ~1 | id,
>   correlation = corSymm(), data = dat, subset = time < 3
> )
>
> fit_alt <- lme(
>   opp ~ time * ccog, random = ~1 | id,
>   correlation = corAR1(form = ~ time), data = dat
> )
> Best regards,
>
>
> ir. Thierry Onkelinx
> Statisticus / Statistician
>
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
> FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Havenlaan 88 bus 73, 1000 Brussel
> www.inbo.be
>
>
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> ///////////////////////////////////////////////////////////////////////////////////////////
>
> <https://www.inbo.be>
>
>
> Op ma 15 mrt. 2021 om 03:27 schreef Tip But <fswfswt at gmail.com>:
>
>> Dear Members,
>>
>> In my longitudinal data below, the first couple of subjects were measured
>> 4
>> times but the rest of the subjects were measured 3 times (see data below).
>>
>> We intend to use an unstructured residual correlation matrix in
>> `nlme::lme()`. But our model fails to converge.
>>
>> Question: Given our data is unbalanced with respect to our grouping
>> variable (i.e., `id`), can we use ` corSymm()`? And if we do, what would
>> be
>> the dimensions of the resultant unstructured residual correlation matrix
>> for our data; a 3x3 or a 4x4 matrix?
>>
>> Thank you for your expertise,
>> Joe
>>
>> # Data and R Code
>> dat <- read.csv("https://raw.githubusercontent.com/hkil/m/master/un.csv")
>>
>> library(nlme)
>>
>> fit <- lme(opp~time*ccog, random = ~1|id, correlation=corSymm(form = ~ 1 |
>> id),
>>            data=dat)
>>
>> Error:
>>   nlminb problem, convergence error code = 1
>>   message = false convergence (8)
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
>

	[[alternative HTML version deleted]]


From th|erry@onke||nx @end|ng |rom |nbo@be  Mon Mar 15 18:04:03 2021
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Mon, 15 Mar 2021 18:04:03 +0100
Subject: [R-sig-ME] Does corSymm() require balanced data?
In-Reply-To: <CADreqixHoCH8RJ0QRNZO_dSJsaqDQvJb+kYiXf64+rw79i-MMA@mail.gmail.com>
References: <CADreqizRJ=U1ZhxvsgKTkktMWs_nfdvrpcZ-fG9EFX0DtCL+gA@mail.gmail.com>
 <CAJuCY5xKuSKDy5oMAR+CnXJ4ZNKvWv+HskreDu4dSL8Reepdyg@mail.gmail.com>
 <CADreqixHoCH8RJ0QRNZO_dSJsaqDQvJb+kYiXf64+rw79i-MMA@mail.gmail.com>
Message-ID: <CAJuCY5xib4BL_KA2qwNvYX8absKVOTHSBgQ6rMc51T_21aZ3Bw@mail.gmail.com>

Dear Joe,

CorSymm() needs n * (n - 1) / 2 parameters with n the number of groups
(subjects). n = 4 implies 6 parameters for the correlation alone. So you'll
need plenty of data to fit such a model. I'd recommend that the data should
contain at least 20 subjects for every combination of time points. So 20
subjects with measurements for time 0 and time 1, ... In a balanced case
you'll need at least 20 subjects measured at every time point. If some
combinations are missing in subjects, you'll need extra subjects with those
combinations. 9 and 7 subjects in your data is simply not enough for such a
complex correlation structure.

corAR1(form = ~time) is equivalent to corAR1(form = ~time | id) if random =
~1|id.
I think that corAR1(form = ~1| id) will use the order of the data. So if,
and only if, your data is ordered along time, then it is
equivalent to corAR1(form = ~time | id). I recommend to use the
verbose corAR1(form = ~time | id), which is more clear about the structure
what you want.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op ma 15 mrt. 2021 om 15:56 schreef Tip But <fswfswt at gmail.com>:

> Dear Thierry,
>
> Thank you so much for your insightful comments. May I follow-up on them
> below in-line:
>
>
> ***"You have too few subjects with 4 observations. Either drop those fourth
> observations."
>
> >>>> Does the above mean that for an unstructured residual correlation
> matrix, the unique number of measurements (e.g., 3 times, 4 times etc.)
> must have relatively equal sizes (e.g., 9 subjects with 3 times, 7 subjects
> with 4 times)?
>
> ***"Or use a different correlation structure. E.g. an AR1:
>
> fit_alt <- lme(opp ~ time * ccog, random = ~1 | id,
>   correlation = corAR1(form = ~ time), data = dat)
> "
>
> >>>> In your above R code, is it necessary to use `corAR1(form = ~ time)`?
> It seems `corAR1(form = ~1 | id)` gives the same result?
>
> On Mon, Mar 15, 2021 at 2:37 AM Thierry Onkelinx <thierry.onkelinx at inbo.be>
> wrote:
>
>> Dear Joe,
>>
>> You have too few subjects with 4 observations. Either drop those fourth
>> observations. Or use a different correlation structure. E.g. an AR1
>>
>> fit <- lme(
>>   opp ~ time * ccog, random = ~1 | id,
>>   correlation = corSymm(), data = dat, subset = time < 3
>> )
>>
>> fit_alt <- lme(
>>   opp ~ time * ccog, random = ~1 | id,
>>   correlation = corAR1(form = ~ time), data = dat
>> )
>> Best regards,
>>
>>
>> ir. Thierry Onkelinx
>> Statisticus / Statistician
>>
>> Vlaamse Overheid / Government of Flanders
>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
>> AND FOREST
>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
>> thierry.onkelinx at inbo.be
>> Havenlaan 88 bus 73, 1000 Brussel
>> www.inbo.be
>>
>>
>> ///////////////////////////////////////////////////////////////////////////////////////////
>> To call in the statistician after the experiment is done may be no more
>> than asking him to perform a post-mortem examination: he may be able to say
>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does not
>> ensure that a reasonable answer can be extracted from a given body of data.
>> ~ John Tukey
>>
>> ///////////////////////////////////////////////////////////////////////////////////////////
>>
>> <https://www.inbo.be>
>>
>>
>> Op ma 15 mrt. 2021 om 03:27 schreef Tip But <fswfswt at gmail.com>:
>>
>>> Dear Members,
>>>
>>> In my longitudinal data below, the first couple of subjects were
>>> measured 4
>>> times but the rest of the subjects were measured 3 times (see data
>>> below).
>>>
>>> We intend to use an unstructured residual correlation matrix in
>>> `nlme::lme()`. But our model fails to converge.
>>>
>>> Question: Given our data is unbalanced with respect to our grouping
>>> variable (i.e., `id`), can we use ` corSymm()`? And if we do, what would
>>> be
>>> the dimensions of the resultant unstructured residual correlation matrix
>>> for our data; a 3x3 or a 4x4 matrix?
>>>
>>> Thank you for your expertise,
>>> Joe
>>>
>>> # Data and R Code
>>> dat <- read.csv("https://raw.githubusercontent.com/hkil/m/master/un.csv
>>> ")
>>>
>>> library(nlme)
>>>
>>> fit <- lme(opp~time*ccog, random = ~1|id, correlation=corSymm(form = ~ 1
>>> |
>>> id),
>>>            data=dat)
>>>
>>> Error:
>>>   nlminb problem, convergence error code = 1
>>>   message = false convergence (8)
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Mon Mar 15 18:05:12 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Mon, 15 Mar 2021 13:05:12 -0400
Subject: [R-sig-ME] Does corSymm() require balanced data?
In-Reply-To: <CADreqixHoCH8RJ0QRNZO_dSJsaqDQvJb+kYiXf64+rw79i-MMA@mail.gmail.com>
References: <CADreqizRJ=U1ZhxvsgKTkktMWs_nfdvrpcZ-fG9EFX0DtCL+gA@mail.gmail.com>
 <CAJuCY5xKuSKDy5oMAR+CnXJ4ZNKvWv+HskreDu4dSL8Reepdyg@mail.gmail.com>
 <CADreqixHoCH8RJ0QRNZO_dSJsaqDQvJb+kYiXf64+rw79i-MMA@mail.gmail.com>
Message-ID: <ad0ba29a-c53c-89fa-47df-ebc5fc8b4d46@gmail.com>



On 3/15/21 10:56 AM, Tip But wrote:
> Dear Thierry,
> 
> Thank you so much for your insightful comments. May I follow-up on them
> below in-line:
> 
> 
> ***"You have too few subjects with 4 observations. Either drop those fourth
> observations."
> 
>>>>> Does the above mean that for an unstructured residual correlation
> matrix, the unique number of measurements (e.g., 3 times, 4 times etc.)
> must have relatively equal sizes (e.g., 9 subjects with 3 times, 7 subjects
> with 4 times)?

  Balance is probably less important than the total number with 4 
observations.  If you had 100 subjects with 3 times and 20 subjects with 
4 times you'd probably be fine.

> 
> ***"Or use a different correlation structure. E.g. an AR1:
> 
> fit_alt <- lme(opp ~ time * ccog, random = ~1 | id,
>    correlation = corAR1(form = ~ time), data = dat)
> "
> 
>>>>> In your above R code, is it necessary to use `corAR1(form = ~ time)`?
> It seems `corAR1(form = ~1 | id)` gives the same result?

   I believe that form = ~1|id uses the order of the observations in the 
data set as the time index, and the grouping variable from the random 
effect as the grouping variable, so these should indeed be equivalent (I 
think the documentation should state this, but I haven't checked)

   If you **really** want an answer you can tell R to return it anyway: 
use control=lmeControl(returnObject=TRUE), but I wouldn't trust it.

   It's hard to find another mixed-model package in R that can handle 
this case (unstructured correlation, homogeneous variance).





> 
> On Mon, Mar 15, 2021 at 2:37 AM Thierry Onkelinx <thierry.onkelinx at inbo.be>
> wrote:
> 
>> Dear Joe,
>>
>> You have too few subjects with 4 observations. Either drop those fourth
>> observations. Or use a different correlation structure. E.g. an AR1
>>
>> fit <- lme(
>>    opp ~ time * ccog, random = ~1 | id,
>>    correlation = corSymm(), data = dat, subset = time < 3
>> )
>>
>> fit_alt <- lme(
>>    opp ~ time * ccog, random = ~1 | id,
>>    correlation = corAR1(form = ~ time), data = dat
>> )
>> Best regards,
>>
>>
>> ir. Thierry Onkelinx
>> Statisticus / Statistician
>>
>> Vlaamse Overheid / Government of Flanders
>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
>> FOREST
>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
>> thierry.onkelinx at inbo.be
>> Havenlaan 88 bus 73, 1000 Brussel
>> www.inbo.be
>>
>>
>> ///////////////////////////////////////////////////////////////////////////////////////////
>> To call in the statistician after the experiment is done may be no more
>> than asking him to perform a post-mortem examination: he may be able to say
>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does not
>> ensure that a reasonable answer can be extracted from a given body of data.
>> ~ John Tukey
>>
>> ///////////////////////////////////////////////////////////////////////////////////////////
>>
>> <https://www.inbo.be>
>>
>>
>> Op ma 15 mrt. 2021 om 03:27 schreef Tip But <fswfswt at gmail.com>:
>>
>>> Dear Members,
>>>
>>> In my longitudinal data below, the first couple of subjects were measured
>>> 4
>>> times but the rest of the subjects were measured 3 times (see data below).
>>>
>>> We intend to use an unstructured residual correlation matrix in
>>> `nlme::lme()`. But our model fails to converge.
>>>
>>> Question: Given our data is unbalanced with respect to our grouping
>>> variable (i.e., `id`), can we use ` corSymm()`? And if we do, what would
>>> be
>>> the dimensions of the resultant unstructured residual correlation matrix
>>> for our data; a 3x3 or a 4x4 matrix?
>>>
>>> Thank you for your expertise,
>>> Joe
>>>
>>> # Data and R Code
>>> dat <- read.csv("https://raw.githubusercontent.com/hkil/m/master/un.csv")
>>>
>>> library(nlme)
>>>
>>> fit <- lme(opp~time*ccog, random = ~1|id, correlation=corSymm(form = ~ 1 |
>>> id),
>>>             data=dat)
>>>
>>> Error:
>>>    nlminb problem, convergence error code = 1
>>>    message = false convergence (8)
>>>
>>>          [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>
>>
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From wo||g@ng@v|echtb@uer @end|ng |rom m@@@tr|chtun|ver@|ty@n|  Mon Mar 15 18:37:18 2021
From: wo||g@ng@v|echtb@uer @end|ng |rom m@@@tr|chtun|ver@|ty@n| (Viechtbauer, Wolfgang (SP))
Date: Mon, 15 Mar 2021 17:37:18 +0000
Subject: [R-sig-ME] Does corSymm() require balanced data?
In-Reply-To: <ad0ba29a-c53c-89fa-47df-ebc5fc8b4d46@gmail.com>
References: <CADreqizRJ=U1ZhxvsgKTkktMWs_nfdvrpcZ-fG9EFX0DtCL+gA@mail.gmail.com>
 <CAJuCY5xKuSKDy5oMAR+CnXJ4ZNKvWv+HskreDu4dSL8Reepdyg@mail.gmail.com>
 <CADreqixHoCH8RJ0QRNZO_dSJsaqDQvJb+kYiXf64+rw79i-MMA@mail.gmail.com>
 <ad0ba29a-c53c-89fa-47df-ebc5fc8b4d46@gmail.com>
Message-ID: <e6133c43882f48bd8f424a7488ae2c20@UM-MAIL3214.unimaas.nl>

Dear Joe,

At the risk of revealing something that could be misused (because I agree with Thierry that you are pushing things by trying to fit this model with these data), you can get the model to converge by switching to a different optimizer (i.e., BFGS):

fit <- lme(opp ~ time * ccog, random = ~ 1 | id, correlation = corSymm(form = ~ 1 | id), data = dat, control = list(opt = "optim"))

Whether this converges to the global maximum I have not attempted to check.

Maybe this is still useful to know because it might allow you to make a more informed decision about the use of a simpler model. For example:

fit2 <- lme(opp ~ time*ccog, random = ~ 1 | id, correlation = corAR1(form = ~ time), data = dat, control=list(opt="optim"))
anova(fit, fit2)

shows that the corSymm() model does not fit significantly better than the AR1 model.

Best,
Wolfgang

>-----Original Message-----
>From: R-sig-mixed-models [mailto:r-sig-mixed-models-bounces at r-project.org] On
>Behalf Of Ben Bolker
>Sent: Monday, 15 March, 2021 18:05
>To: r-sig-mixed-models at r-project.org
>Subject: Re: [R-sig-ME] Does corSymm() require balanced data?
>
>On 3/15/21 10:56 AM, Tip But wrote:
>> Dear Thierry,
>>
>> Thank you so much for your insightful comments. May I follow-up on them
>> below in-line:
>>
>>
>> ***"You have too few subjects with 4 observations. Either drop those fourth
>> observations."
>>
>>>>>> Does the above mean that for an unstructured residual correlation
>> matrix, the unique number of measurements (e.g., 3 times, 4 times etc.)
>> must have relatively equal sizes (e.g., 9 subjects with 3 times, 7 subjects
>> with 4 times)?
>
>  Balance is probably less important than the total number with 4
>observations.  If you had 100 subjects with 3 times and 20 subjects with
>4 times you'd probably be fine.
>
>>
>> ***"Or use a different correlation structure. E.g. an AR1:
>>
>> fit_alt <- lme(opp ~ time * ccog, random = ~1 | id,
>>    correlation = corAR1(form = ~ time), data = dat)
>> "
>>
>>>>>> In your above R code, is it necessary to use `corAR1(form = ~ time)`?
>> It seems `corAR1(form = ~1 | id)` gives the same result?
>
>   I believe that form = ~1|id uses the order of the observations in the
>data set as the time index, and the grouping variable from the random
>effect as the grouping variable, so these should indeed be equivalent (I
>think the documentation should state this, but I haven't checked)
>
>   If you **really** want an answer you can tell R to return it anyway:
>use control=lmeControl(returnObject=TRUE), but I wouldn't trust it.
>
>   It's hard to find another mixed-model package in R that can handle
>this case (unstructured correlation, homogeneous variance).
>
>> On Mon, Mar 15, 2021 at 2:37 AM Thierry Onkelinx <thierry.onkelinx at inbo.be>
>> wrote:
>>
>>> Dear Joe,
>>>
>>> You have too few subjects with 4 observations. Either drop those fourth
>>> observations. Or use a different correlation structure. E.g. an AR1
>>>
>>> fit <- lme(
>>>    opp ~ time * ccog, random = ~1 | id,
>>>    correlation = corSymm(), data = dat, subset = time < 3
>>> )
>>>
>>> fit_alt <- lme(
>>>    opp ~ time * ccog, random = ~1 | id,
>>>    correlation = corAR1(form = ~ time), data = dat
>>> )
>>> Best regards,
>>>
>>>
>>> ir. Thierry Onkelinx
>>> Statisticus / Statistician
>>>
>>> Vlaamse Overheid / Government of Flanders
>>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
>>> FOREST
>>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
>>> thierry.onkelinx at inbo.be
>>> Havenlaan 88 bus 73, 1000 Brussel
>>> www.inbo.be
>>>
>>> Op ma 15 mrt. 2021 om 03:27 schreef Tip But <fswfswt at gmail.com>:
>>>
>>>> Dear Members,
>>>>
>>>> In my longitudinal data below, the first couple of subjects were measured
>>>> 4
>>>> times but the rest of the subjects were measured 3 times (see data below).
>>>>
>>>> We intend to use an unstructured residual correlation matrix in
>>>> `nlme::lme()`. But our model fails to converge.
>>>>
>>>> Question: Given our data is unbalanced with respect to our grouping
>>>> variable (i.e., `id`), can we use ` corSymm()`? And if we do, what would
>>>> be
>>>> the dimensions of the resultant unstructured residual correlation matrix
>>>> for our data; a 3x3 or a 4x4 matrix?
>>>>
>>>> Thank you for your expertise,
>>>> Joe
>>>>
>>>> # Data and R Code
>>>> dat <- read.csv("https://raw.githubusercontent.com/hkil/m/master/un.csv")
>>>>
>>>> library(nlme)
>>>>
>>>> fit <- lme(opp~time*ccog, random = ~1|id, correlation=corSymm(form = ~ 1 |
>>>> id),
>>>>             data=dat)
>>>>
>>>> Error:
>>>>    nlminb problem, convergence error code = 1
>>>>    message = false convergence (8)


From |@w|@wt @end|ng |rom gm@||@com  Mon Mar 15 19:09:01 2021
From: |@w|@wt @end|ng |rom gm@||@com (Tip But)
Date: Mon, 15 Mar 2021 13:09:01 -0500
Subject: [R-sig-ME] Does corSymm() require balanced data?
In-Reply-To: <CAJuCY5xib4BL_KA2qwNvYX8absKVOTHSBgQ6rMc51T_21aZ3Bw@mail.gmail.com>
References: <CADreqizRJ=U1ZhxvsgKTkktMWs_nfdvrpcZ-fG9EFX0DtCL+gA@mail.gmail.com>
 <CAJuCY5xKuSKDy5oMAR+CnXJ4ZNKvWv+HskreDu4dSL8Reepdyg@mail.gmail.com>
 <CADreqixHoCH8RJ0QRNZO_dSJsaqDQvJb+kYiXf64+rw79i-MMA@mail.gmail.com>
 <CAJuCY5xib4BL_KA2qwNvYX8absKVOTHSBgQ6rMc51T_21aZ3Bw@mail.gmail.com>
Message-ID: <CADreqiz1Aq2ZUj737ii=3K3y3wCsKRirgnZP6P-kwQCWG=ms2A@mail.gmail.com>

Dear Thierry, Ben and Wolfgang,

Thank you all so much! My sense of `corSymm()` is that there needs to be
"enough" observations with respect to each unique time point index so that
the model can converge and/or be trusted.

However, we can't exactly say what constitutes "enough" observations (maybe
power analysis helps) other than by some kind of trial and error.

The other thing that I noticed was that for `corSymm()` we can NOT use
`corSymm(form = ~ time | id)`. Rather, it must be `corSymm(form = ~1| id)`
even though our goal is to allow observations under all unique `time` point
indices to be correlated with each other.

Is there a specific reason `corSymm(form = ~ time | id)` can not be used
(while `corAR1(form = ~ time | id)` works fine)?

Thanks a million,
Joe

On Mon, Mar 15, 2021 at 12:04 PM Thierry Onkelinx <thierry.onkelinx at inbo.be>
wrote:

> Dear Joe,
>
> CorSymm() needs n * (n - 1) / 2 parameters with n the number of groups
> (subjects). n = 4 implies 6 parameters for the correlation alone. So you'll
> need plenty of data to fit such a model. I'd recommend that the data should
> contain at least 20 subjects for every combination of time points. So 20
> subjects with measurements for time 0 and time 1, ... In a balanced case
> you'll need at least 20 subjects measured at every time point. If some
> combinations are missing in subjects, you'll need extra subjects with those
> combinations. 9 and 7 subjects in your data is simply not enough for such a
> complex correlation structure.
>
> corAR1(form = ~time) is equivalent to corAR1(form = ~time | id) if random
> = ~1|id.
> I think that corAR1(form = ~1| id) will use the order of the data. So if,
> and only if, your data is ordered along time, then it is
> equivalent to corAR1(form = ~time | id). I recommend to use the
> verbose corAR1(form = ~time | id), which is more clear about the structure
> what you want.
>
> Best regards,
>
> ir. Thierry Onkelinx
> Statisticus / Statistician
>
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
> FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Havenlaan 88 bus 73, 1000 Brussel
> www.inbo.be
>
>
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> ///////////////////////////////////////////////////////////////////////////////////////////
>
> <https://www.inbo.be>
>
>
> Op ma 15 mrt. 2021 om 15:56 schreef Tip But <fswfswt at gmail.com>:
>
>> Dear Thierry,
>>
>> Thank you so much for your insightful comments. May I follow-up on them
>> below in-line:
>>
>>
>> ***"You have too few subjects with 4 observations. Either drop those
>> fourth
>> observations."
>>
>> >>>> Does the above mean that for an unstructured residual correlation
>> matrix, the unique number of measurements (e.g., 3 times, 4 times etc.)
>> must have relatively equal sizes (e.g., 9 subjects with 3 times, 7 subjects
>> with 4 times)?
>>
>> ***"Or use a different correlation structure. E.g. an AR1:
>>
>> fit_alt <- lme(opp ~ time * ccog, random = ~1 | id,
>>   correlation = corAR1(form = ~ time), data = dat)
>> "
>>
>> >>>> In your above R code, is it necessary to use `corAR1(form = ~
>> time)`? It seems `corAR1(form = ~1 | id)` gives the same result?
>>
>> On Mon, Mar 15, 2021 at 2:37 AM Thierry Onkelinx <
>> thierry.onkelinx at inbo.be> wrote:
>>
>>> Dear Joe,
>>>
>>> You have too few subjects with 4 observations. Either drop those fourth
>>> observations. Or use a different correlation structure. E.g. an AR1
>>>
>>> fit <- lme(
>>>   opp ~ time * ccog, random = ~1 | id,
>>>   correlation = corSymm(), data = dat, subset = time < 3
>>> )
>>>
>>> fit_alt <- lme(
>>>   opp ~ time * ccog, random = ~1 | id,
>>>   correlation = corAR1(form = ~ time), data = dat
>>> )
>>> Best regards,
>>>
>>>
>>> ir. Thierry Onkelinx
>>> Statisticus / Statistician
>>>
>>> Vlaamse Overheid / Government of Flanders
>>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
>>> AND FOREST
>>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
>>> thierry.onkelinx at inbo.be
>>> Havenlaan 88 bus 73, 1000 Brussel
>>> www.inbo.be
>>>
>>>
>>> ///////////////////////////////////////////////////////////////////////////////////////////
>>> To call in the statistician after the experiment is done may be no more
>>> than asking him to perform a post-mortem examination: he may be able to say
>>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>>> The plural of anecdote is not data. ~ Roger Brinner
>>> The combination of some data and an aching desire for an answer does not
>>> ensure that a reasonable answer can be extracted from a given body of data.
>>> ~ John Tukey
>>>
>>> ///////////////////////////////////////////////////////////////////////////////////////////
>>>
>>> <https://www.inbo.be>
>>>
>>>
>>> Op ma 15 mrt. 2021 om 03:27 schreef Tip But <fswfswt at gmail.com>:
>>>
>>>> Dear Members,
>>>>
>>>> In my longitudinal data below, the first couple of subjects were
>>>> measured 4
>>>> times but the rest of the subjects were measured 3 times (see data
>>>> below).
>>>>
>>>> We intend to use an unstructured residual correlation matrix in
>>>> `nlme::lme()`. But our model fails to converge.
>>>>
>>>> Question: Given our data is unbalanced with respect to our grouping
>>>> variable (i.e., `id`), can we use ` corSymm()`? And if we do, what
>>>> would be
>>>> the dimensions of the resultant unstructured residual correlation matrix
>>>> for our data; a 3x3 or a 4x4 matrix?
>>>>
>>>> Thank you for your expertise,
>>>> Joe
>>>>
>>>> # Data and R Code
>>>> dat <- read.csv("https://raw.githubusercontent.com/hkil/m/master/un.csv
>>>> ")
>>>>
>>>> library(nlme)
>>>>
>>>> fit <- lme(opp~time*ccog, random = ~1|id, correlation=corSymm(form = ~
>>>> 1 |
>>>> id),
>>>>            data=dat)
>>>>
>>>> Error:
>>>>   nlminb problem, convergence error code = 1
>>>>   message = false convergence (8)
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>

	[[alternative HTML version deleted]]


From hedyeh@h @end|ng |rom u@c@edu  Tue Mar 16 17:44:43 2021
From: hedyeh@h @end|ng |rom u@c@edu (Hedyeh Ahmadi)
Date: Tue, 16 Mar 2021 16:44:43 +0000
Subject: [R-sig-ME] A three-level GLMM with binomial link in R
In-Reply-To: <BYAPR07MB50942F7C5155017E7D847301D16F9@BYAPR07MB5094.namprd07.prod.outlook.com>
References: <BYAPR07MB50945A60AFDE467F317861ACD1969@BYAPR07MB5094.namprd07.prod.outlook.com>
 <CAA=SVwH2pE+EAtEqALjeRPT91tWz-HJegrQkz9mYqfj7pb_A1Q@mail.gmail.com>
 <BYAPR07MB50947CD020DADA71CFF86407D1969@BYAPR07MB5094.namprd07.prod.outlook.com>
 <CA+3TTkNL+JGE+pgfOqASfvJ+r5eHmbGt3v+FzazouVePs_=x9Q@mail.gmail.com>
 <BYAPR07MB509450F1132EEB7C41F60B4CD1969@BYAPR07MB5094.namprd07.prod.outlook.com>
 <CA+3TTkM-abt0u4Je03nnTBBKiZw4AFj-UdPfyP_JOLZbDiJEFA@mail.gmail.com>
 <9e903a9f-5bec-934c-0b50-b2fca97cd4f3@gmail.com>
 <BYAPR07MB5094069BFA432F89688D34DCD1939@BYAPR07MB5094.namprd07.prod.outlook.com>
 <a8005560-3957-e814-df74-604d9cb857bb@gmail.com>
 <BYAPR07MB5094DD4608A0B5DB96A52EB5D1909@BYAPR07MB5094.namprd07.prod.outlook.com>
 <971aa7fc-a424-154d-c451-3027988f3c55@gmail.com>
 <BYAPR07MB5094B054FF44075722E4C378D16F9@BYAPR07MB5094.namprd07.prod.outlook.com>,
 <c70f39ad-dbb4-5f3a-3e9d-9baa6e4c9da6@gmail.com>,
 <BYAPR07MB50942F7C5155017E7D847301D16F9@BYAPR07MB5094.namprd07.prod.outlook.com>
Message-ID: <BYAPR07MB50949F06C713372A0E294B4ED16B9@BYAPR07MB5094.namprd07.prod.outlook.com>

Hello all,
I am just forwarding my previous email again just in case and taking out some parts that I already figured out - thank you for all your help:

I'll think more about how to share a data set that would create the same error. Sorry, I am not very simulation savvy, but I'll try harder next time.

On the bright side, I was able to run the following model by implicitly defining the group structure (slightly different from what was suggested in the previous email) and it does give me the same estimation as lme() with random = ~1|site/family/id random structure - so the memory issue resolved for this model! Thank you for the suggestion.

dd$site_family <- interaction(dd$site, dd$family)
m2.1 <- lmer(cbcl_scr_syn_internal_r ~ 1 + X1 + X2 + X3+ (1|site) +(1|site_family/id), data=dd,  REML = FALSE)

But now getting to my last question: My data has 22945 rows, and some individuals have only baseline measurement, some individuals have baseline and 1 year measurement. A variable called eventname is the indicator of that. I am now confused as my "id" variable does not have this information (i.e. the order of measurement). How would the model recognize that which repeated measure is measurment1 (i.e. baseline) and which one is measurment2 (i.e. 1 year)?  Or maybe because I don't have a random slope, I don't need to define the repeated measure structure and adding eventname as a fixed effect is sufficient?

OR do I need to run a model with additional random intercept of eventname (i.e. (1|site/family/id/eventname)) but in doing so lme() gives me the number of observation equal to number of grouping for eventname %in% id %in% family %in% site as follows. Would that be okay?

Number of Observations: 13388
Number of Groups:
                                                       site                                               family %in% site
                                                        21                                                       9393
                                              id %in% family %in% site                  eventname %in% id %in% family %in% abcd_site
                                                     11111                                                      13388

Again, thank you so much for your time.


Best,

Hedyeh Ahmadi, Ph.D.
Statistician
Keck School of Medicine
Department of Preventive Medicine
University of Southern California

Postdoctoral Scholar
Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
University of California, Irvine

LinkedIn
www.linkedin.com/in/hedyeh-ahmadi<http://www.linkedin.com/in/hedyeh-ahmadi>
<http://www.linkedin.com/in/hedyeh-ahmadi><http://www.linkedin.com/in/hedyeh-ahmadi>




________________________________
From: Hedyeh Ahmadi <hedyehah at usc.edu>
Sent: Friday, March 12, 2021 12:54 PM
To: r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>; Ben Bolker <bbolker at gmail.com>
Subject: Re: [R-sig-ME] A three-level GLMM with binomial link in R

I'll think more about how to share a data set that would create the same error. Sorry, I am not very simulation savvy but I'll try harder next time.

On the bright side, I was able to run the following model by implicitly defining the group structure (slightly different from what was suggested in the previous email) and it does give me the same estimation as lme() with random = ~1|site/family/id random structure - so the memory issue resolved for this model! Thank you for the suggestion.

dd$site_family <- interaction(dd$site, dd$family)
m2.1 <- lmer(cbcl_scr_syn_internal_r ~ 1 + X1 + X2 + X3+ (1|site) +(1|site_family/id), data=dd,  REML = FALSE)

But now getting to my last question: My data has 22945 rows, and some individuals have only baseline measurement, some individuals have baseline and 1 year measurement. A variable called eventname is the indicator of that. I am now confused as my "id" variable does not have this information (i.e. the order of measurement). How would the model recognize that which repeated measure is measurment1 (i.e. baseline) and which one is measurment2 (i.e. 1 year)?  Or maybe because I don't have a random slope, I don't need to define the repeated measure structure and adding eventname as a fixed effect is sufficient?

OR do I need to run a model with additional random intercept of eventname but in doing so lme() gives me the number of observation equal to umber of grouping for eventname %in% id %in% family %in% site as follows. Would that be okay?

Number of Observations: 13388
Number of Groups:
                                                       site                                               family %in% site
                                                        21                                                       9393
                                              id %in% family %in% site                  eventname %in% id %in% family %in% abcd_site
                                                     11111                                                      13388

The model formula with eventname as random slope in lme() would be as follows but I have not been able to reproduce this in lmer() similar to implicit formatting of m2.1 shown above - any help would be appreciated here. Keep in mind created an implicit three-way and four-way interaction takes too much memory on my personal PC so I am trying to find a way around it as I did in m2.1.

m3 <- lme(cbcl_scr_syn_internal_r ~ 1 +X1+ X2 + X3, random = ~1|site/family/id//eventname ,
    data=dd, na.action=na.exclude,method="ML")

Again, thank you so much for your time.

Best,

Hedyeh Ahmadi, Ph.D.
Statistician
Keck School of Medicine
Department of Preventive Medicine
University of Southern California

Postdoctoral Scholar
Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
University of California, Irvine

LinkedIn
www.linkedin.com/in/hedyeh-ahmadi<http://www.linkedin.com/in/hedyeh-ahmadi>
<http://www.linkedin.com/in/hedyeh-ahmadi><http://www.linkedin.com/in/hedyeh-ahmadi>




________________________________
From: Ben Bolker <bbolker at gmail.com>
Sent: Friday, March 12, 2021 11:45 AM
To: Hedyeh Ahmadi <hedyehah at usc.edu>; r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] A three-level GLMM with binomial link in R



On 3/12/21 12:13 PM, Hedyeh Ahmadi wrote:
> Here are my comments/questions:
>
>  1. I have tried changing the site, family, and id to factor and I get
>     the same results.
>  2. Unfortunately, I can't share my data due to privacy issues but if
>     you tell me what other information you need, I can provide it.

   We know you can't share the data.  Part of the art of getting
software help is figuring out how you can create a shareable version of
your data set, *or* a shareable version of something that will generate
the same errors you're experiencing.  We need to do a bisection search
between the private data you have, which causes problems with factor
expansion in the grouping variables and is surprisingly memory-hungry,
and the reproducible examples that I have constructed that mimic some
aspects of your data set but don't show either problem.  Since we can't
look at your data, the burden falls on you to create a
reproducible/shareable example we can work with.

    Assuming that

lmer(y ~ 1  +(1|site/family/id) , data =dd)

does show problems with your actual data set, can you anonymize the
levels of site, family, and id, something like

   anon_fac <- function(x, prefix="S") {
       factor(x, levels=levels(x), labels=paste0(prefix,
seq(length(levels(x))))
   }

   anon_dd <- transform(dd, select=c(family, site, id))
   anon_dd <- transform(anon_dd,
           site=anon_fac(site,"S"),
           family=anon_fac(family,"F"),
           id=anon_fac(id,"I")
   )

This should provide a data set that contains *no* information other than
the pattern of co-occurrence of grouping levels. I don't know who's in
charge of data privacy for your group, but it's hard to imagine how
sharing this would present a risk of personal identification ...

https://urldefense.com/v3/__https://stackoverflow.com/questions/10454973/how-to-create-example-data-set-from-private-data-replacing-variable-names-and-l__;!!LIr3w8kk_Xxm!86i5mS45OmW-JeD4GGs4ZQyanE9ePtf5QzjgYVkL_Rg284MkmW9z-lQGP70cEP4$

https://urldefense.com/v3/__https://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example/6699112*6699112__;Iw!!LIr3w8kk_Xxm!86i5mS45OmW-JeD4GGs4ZQyanE9ePtf5QzjgYVkL_Rg284MkmW9z-lQGfDnxgGI$


>  3. Note that when I run the three-way interaction code in my PC it
>     again runs out of memory and the error says the following. When I
>     tried to run it on interactive HPC, it kicks me out as it takes too
>     much memory/time so I will have to submit a batch script.
>     "Error: cannot allocate vector of size 18.1 Gb
>     In addition: Warning message:
>     In ans * length(l) :
>     Error: cannot allocate vector of size 18.1 Gb"
>  4. When I take out all the fixed effects, the problem still exists.


   That's good in one sense, as it simplifies the problem.

>  5. *Question:* Also note that my data has 22945 rows, and some
>     individuals have only baseline measurement only, some individuals
>     have baseline and 1 year measurement. A variable called eventname is
>     the indicator of that. I am now confused as my "id" variable does
>     not have this information (i.e. the order of measurement). How would
>     the model recognize that which repeated measure is measurment1 (i.e.
>     baseline) and which one is measurment2(i.e. 1 year)?  Or maybe
>     because I don't have a random slope, I don't need to define the
>     repeated measure structure and adding eventname as a fixed effect is
>     sufficient?

    Let's deal with this after we have the basic problems sorted.  If
you want to account for the possible effects of ordering, then you'd
need to add this variable ...

>
> Thanks again for all your help on this.
>
> Best,
>
> Hedyeh Ahmadi, Ph.D.
> Statistician
> Keck School of Medicine
> Department of Preventive Medicine
> University of Southern California
>
> Postdoctoral Scholar
> Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
> University of California, Irvine
>
> LinkedIn
> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!86i5mS45OmW-JeD4GGs4ZQyanE9ePtf5QzjgYVkL_Rg284MkmW9z-lQGJrML1Sk$  <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!86i5mS45OmW-JeD4GGs4ZQyanE9ePtf5QzjgYVkL_Rg284MkmW9z-lQGJrML1Sk$ >
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!86i5mS45OmW-JeD4GGs4ZQyanE9ePtf5QzjgYVkL_Rg284MkmW9z-lQGJrML1Sk$ ><https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!86i5mS45OmW-JeD4GGs4ZQyanE9ePtf5QzjgYVkL_Rg284MkmW9z-lQGJrML1Sk$ >
>
>
>
>
> ------------------------------------------------------------------------
> *From:* Ben Bolker <bbolker at gmail.com>
> *Sent:* Thursday, March 11, 2021 3:55 PM
> *To:* Hedyeh Ahmadi <hedyehah at usc.edu>; r-sig-mixed-models at r-project.org
> <r-sig-mixed-models at r-project.org>; Megan M. Herting <herting at usc.edu>;
> Elisabeth Burnor <burnor at usc.edu>
> *Subject:* Re: [R-sig-ME] A three-level GLMM with binomial link in R
>
>
> On 3/11/21 1:11 PM, Hedyeh Ahmadi wrote:
>> Hi Ben,
>> Thank you for all the help and informative replies. Here is some info
>> about my data and my answers:
>>
>>   * Yes, I am running the exact model however this is just my toy model
>>     to get the code to work.
>>   * Reminder, I am trying to get lmer with a continuous outcome (but
>>     same data structure, with 3 random intercept) work before moving to
>>     glmer() with a logit link with a categorical 0/1 outcome.
>>   * Here are some information about my data:
>>       o X1: num [1:22945] 9.25 NA 9.22 NA 9.22 NA 9.42 NA 9.25 NA ...
>>       o X2: int [1:22945] 117 140 128 125 113 138 126 130 120 121 ...
>>       o X3: chr [1:22945] "Female" "Male" "Male" "Male" "Male"
>>       o site: chr [1:22945] "site15" "site15" "site15" "site15" "site15"
>>         ... (I have 21 sites)
>>       o family: int [1:22945] 0 1 1 1 1 3 3 4 4 5 ...
>>       o id: chr [1:22945] "id1" "id2" "id2" "id3" "id3"...
>>   * The following model gives me the error that "Error: couldn't
>>     evaluate grouping factor id:(family:site) within model frame: try
>>     adding grouping factor to data frame explicitly if possible" - I ran
>>     this same model on a supercomputer and it *gave me the same error*,
>>     so this is not a memory limit issue.
>
> So far I can't replicate this.  It seemed fishy to me that family was an
> integer (I would try explicitly converting it to a factor), but doesn't
> actually cause any problems in my example.
>
>    (This differs from your example but not in ways I would expect to be
> important: in particular, the types of the grouping variables are the
> same [chr, int, chr]
>
> n <- 10000
> set.seed(101)
> dd <- data.frame(y=rnorm(n),
>                    x1=rnorm(n),
>                    x2=rnorm(n),
>                    x3=rnorm(n),
>                    site=sample(paste0("s",1:15),size=n,replace=TRUE),
>                    family=sample(1:100,size=n,replace=TRUE),
>                    id=sample(paste0("id",1:20),size=n,replace=TRUE))
> library(lme4)
> lmer(y~1 + x1 + x2 + x3 + (1|site/family/id), data=dd)
>
> ###
>
> What is meant by "adding grouping factor to data frame explicitly" would
> be in this case expanding out the nested terms:
>
>    dd <- within(dd,
> {
>       site_family <- interaction(site,family)
>       site_family_id <- interaction(site,family,id)
> })
>
> lmer(y~1 + x1 + x2 + x3 + (1|site) + (1|site_family) +
> (1|site_family_id), data =dd)
>
>
>
>>       o m2 <- lmer(cbcl_scr_syn_internal_r ~ 1 + X1 + X2 + X3 +
>>         (1|site/family/id), data=dd, REML = FALSE)
>>   * The following *model ran on a supercomputer*.  This is the model
>>     that previously would give me the error "Error: cannot allocate
>>     vector of size 2.3 Gb". Here I am*reducing the number of sites to
>>     see if it runs, and it did* run on a supercomputer.
>>       o m11 <- lmer(cbcl_scr_syn_internal_r ~ 1 + X1 +X2 + X3
>>         +(1|site/family/id) ,
>>              data=dd[-which(dd$abcd_site %in% c("site01","site02",
>>         "site04", "site05", "site06", "site07", "site08","site09")),],
>>         na.action=na.exclude, REML=FALSE)
>>
>> Questions:
>>
>>  1. What I don't understand is that in m2, why lmer() does not
>>     recognizes the grouping factor that it does recognize in m11?
>
>    I'm not sure either.
>
>>  2. At this point I don't think this is a memory issue as *m2 did not
>>     run on a supercompute*r and it's giving me *the same error as my
>>     personal computer*. However, in m11, the same grouping structure is
>>     being recognized when I reduce the number of sites from 21 to 13 -
>>     could this be because of severe imbalance in my family/id nesting,
>>     meaning most families have only one kid but some have 2 and a few
>>     have 3 kids?
>
>     It seems surprising.
>     Is there any way we can get a reproducible example?  For example,
> suppose you randomize your X1, X2, X3 and anonymize all of your grouping
> variables: would you then be able to share the data set?
>
>     Does the problem (let's say just the first problem) still occur if
> you leave out the fixed effects? (I would expect so, and that would
> simplify things somewhat - we're trying to get to the *simplest* example
> that still demonstrates the problem.)
>
>
>>
>> Sorry about the long email and thank you for your help in advance.
>>
>> Best,
>>
>> Hedyeh Ahmadi, Ph.D.
>> Statistician
>> Keck School of Medicine
>> Department of Preventive Medicine
>> University of Southern California
>>
>> Postdoctoral Scholar
>> Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
>> University of California, Irvine
>>
>> LinkedIn
>> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!51-zg2ISp-lS-4HEW0ZNNEVE1ZD8ujdJZYx90xVOnZ-x6A7l6eu2KhSgMhYCJq4$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!51-zg2ISp-lS-4HEW0ZNNEVE1ZD8ujdJZYx90xVOnZ-x6A7l6eu2KhSgMhYCJq4$>
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!51-zg2ISp-lS-4HEW0ZNNEVE1ZD8ujdJZYx90xVOnZ-x6A7l6eu2KhSgMhYCJq4$
>  >
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!51-zg2ISp-lS-4HEW0ZNNEVE1ZD8ujdJZYx90xVOnZ-x6A7l6eu2KhSgMhYCJq4$
>  ><https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!51-zg2ISp-lS-4HEW0ZNNEVE1ZD8ujdJZYx90xVOnZ-x6A7l6eu2KhSgMhYCJq4$ >
>>
>>
>>
>>
>> ------------------------------------------------------------------------
>> *From:* Ben Bolker <bbolker at gmail.com>
>> *Sent:* Tuesday, March 9, 2021 4:12 PM
>> *To:* Hedyeh Ahmadi <hedyehah at usc.edu>; r-sig-mixed-models at r-project.org
>> <r-sig-mixed-models at r-project.org>
>> *Subject:* Re: [R-sig-ME] A three-level GLMM with binomial link in R
>>     OK, then it would be very helpful to have more details about your
>> data set. Are one or more of X1, X2, X3 categorical predictors with many
>> levels ... ?  Any chance we can see str() or summary() ?  Are you using
>> exactly the formula you told us about, or something slightly different?
>>
>>     The computational burden of a large number of fixed effect parameters
>> will be much worse for glmer than for lmer, unless you use nAGQ=0.
>> glmmTMB would be able to help in two ways: (1) it doesn't scale as badly
>> for large numbers of fixed effects; (2) it allows sparse fixed-effect
>> model matrices (something we keep meaning to (re)implement in lme4) ...
>>
>>    Making X1 into a 1000-level factor brings the required memory up by
>> about a factor of 10 and increases the run time from seconds to minutes.
>>
>>
>> Base model:
>>
>>                        Function_Call Elapsed_Time_sec Total_RAM_Used_MiB
>> 1 m<-lmer(form,data=dd,REML=FALSE)            1.903               10.4
>>     Peak_RAM_Used_MiB
>> 1             107.7
>>
>> With X=1000-level factor (no derivative calculations):
>>
>>    Function_Call
>> 1
>> m2<-lmer(form,data=dd2,REML=FALSE,control=lmerControl(calc.derivs=FALSE),verbose=10)
>>     Elapsed_Time_sec Total_RAM_Used_MiB Peak_RAM_Used_MiB
>> 1          559.735              608.8             984.5
>>
>>
>> With derivative calculation at the end:
>>
>>                                    Function_Call Elapsed_Time_sec
>> 1 m3<-lmer(form,data=dd2,REML=FALSE,verbose=10)          677.975
>>     Total_RAM_Used_MiB Peak_RAM_Used_MiB
>> 1              608.7            1148.7
>>   >
>>   >
>>
>> ---
>> ibrary(lme4)
>> set.seed(101)
>> N <- 22945
>> ns <- 100
>> nf <- 100
>> nid <- 100
>> dd <- data.frame(X1=rnorm(N),
>>                    X2=rnorm(N),
>>                    X3=rnorm(N),
>>                    site=sample(ns, replace=TRUE, size=N),
>>                    family=sample(nf, replace=TRUE, size=N),
>>                    id=sample(nid, replace=TRUE, size=N))
>> form <- Y ~ 1 + X1 + X2 + X3 + (1|site/family/id)
>> dd$Y <- simulate(form[-2], newdata=dd, family=gaussian,
>>
>> newparams=list(beta=rep(1,4),theta=rep(1,3),sigma=1))[[1]]
>> library(peakRAM)
>> system.time(mem <- peakRAM(
>>       m <- lmer(form, data=dd, REML=FALSE)
>>       ))
>> print(mem)
>>
>> dd2 <- transform(dd,
>>           X1=factor(sample(1000,size=N,replace=TRUE)))
>>
>> system.time(mem2 <- peakRAM(
>>       m2 <- lmer(form, data=dd2, REML=FALSE,
>> control=lmerControl(calc.derivs=FALSE), verbose=10)
>> ))
>> print(mem2)
>>
>> system.time(mem3 <- peakRAM(
>>       m3 <- lmer(form, data=dd2, REML=FALSE, verbose=10)
>> ))
>> print(mem3)
>>
>>
>> On 3/8/21 11:29 AM, Hedyeh Ahmadi wrote:
>>> Thank you for the toy example. This same example in my PC gives the
>>> following memory use output:
>>>
>>>
>>>  > mem
>>>                       Function_Call
>>> Elapsed_Time_sec         Total_RAM_Used_MiB    Peak_RAM_Used_MiB
>>>    m<-lmer(form,data=dd,REML=FALSE)             2.64
>>>                  10.3                                       130.1
>>>
>>> When I run peakRAM() for my actual data, it take one hour plus then my
>>> PC slows down, then I have to stop R to be able to use my PC.
>>>
>>> Best,
>>>
>>> Hedyeh Ahmadi, Ph.D.
>>> Statistician
>>> Keck School of Medicine
>>> Department of Preventive Medicine
>>> University of Southern California
>>>
>>> Postdoctoral Scholar
>>> Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
>>> University of California, Irvine
>>>
>>> LinkedIn
>>> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5O8KlsAUILt44__IHSzbCUgVs7dWxAB8FS9wiKC3j5P6hGrnuJSGckmCIR91AZs$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5O8KlsAUILt44__IHSzbCUgVs7dWxAB8FS9wiKC3j5P6hGrnuJSGckmCIR91AZs$>
>
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5O8KlsAUILt44__IHSzbCUgVs7dWxAB8FS9wiKC3j5P6hGrnuJSGckmCIR91AZs$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5O8KlsAUILt44__IHSzbCUgVs7dWxAB8FS9wiKC3j5P6hGrnuJSGckmCIR91AZs$>>
>
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5O8KlsAUILt44__IHSzbCUgVs7dWxAB8FS9wiKC3j5P6hGrnuJSGckmCIR91AZs$
>
>>  >
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5O8KlsAUILt44__IHSzbCUgVs7dWxAB8FS9wiKC3j5P6hGrnuJSGckmCIR91AZs$
>
>>  ><https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5O8KlsAUILt44__IHSzbCUgVs7dWxAB8FS9wiKC3j5P6hGrnuJSGckmCIR91AZs$
>  >
>>>
>>>
>>>
>>>
>>> ------------------------------------------------------------------------
>>> *From:* R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on
>>> behalf of Ben Bolker <bbolker at gmail.com>
>>> *Sent:* Friday, March 5, 2021 5:44 PM
>>> *To:* r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>
>>> *Subject:* Re: [R-sig-ME] A three-level GLMM with binomial link in R
>>>     Here's an example that conforms approximately to the structure of
>>> your data: on my machine the peak RAM usage is 121 Mb, far short of your
>>> 2.3 Gb ...  so I still suspect there is something going on that we don't
>>> know about/haven't guessed yet.
>>>
>>> set.seed(101)
>>> N <- 22945
>>> ns <- 100
>>> nf <- 100
>>> nid <- 100
>>> dd <- data.frame(X1=rnorm(N),
>>>                    X2=rnorm(N),
>>>                    X3=rnorm(N),
>>>                    site=sample(ns, replace=TRUE, size=N),
>>>                    family=sample(nf, replace=TRUE, size=N),
>>>                    id=sample(nid, replace=TRUE, size=N))
>>> form <- Y ~ 1 + X1 + X2 + X3 + (1|site/family/id)
>>> dd$Y <- simulate(form[-2], newdata=dd, family=gaussian,
>>>
>>> newparams=list(beta=rep(1,4),theta=rep(1,3),sigma=1))[[1]]
>>> library(peakRAM)
>>> mem <- peakRAM(
>>>       m <- lmer(form, data=dd, REML=FALSE)
>>> )
>>>
>>> mem
>>>                        Function_Call Elapsed_Time_sec Total_RAM_Used_MiB
>>> 1 m<-lmer(form,data=dd,REML=FALSE)            1.754               10.3
>>>     Peak_RAM_Used_MiB
>>> 1             120.7
>>>
>>>
>>> On 3/5/21 4:52 PM, Robert Long wrote:
>>>> Perhaps because of the different ways they store objects internally while
>>>> fitting the models.
>>>>
>>>> On Fri, 5 Mar 2021, 21:47 Hedyeh Ahmadi, <hedyehah at usc.edu> wrote:
>>>>
>>>>> Thank you for the reply Robert - If I am running out of memory in lmer(),
>>>>> do you know why lme() runs just fine?
>>>>>
>>>>> Best,
>>>>>
>>>>> Hedyeh Ahmadi, Ph.D.
>>>>> Statistician
>>>>> Keck School of Medicine
>>>>> Department of Preventive Medicine
>>>>> University of Southern California
>>>>>
>>>>> Postdoctoral Scholar
>>>>> Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
>>>>> University of California, Irvine
>>>>>
>>>>> LinkedIn
>>>>> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$>
>
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$>>
>
>>
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$
>
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$>>>
>
>>
>>>
>>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$
>
>>
>>>  >
>>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$
>
>>
>>>  >
>>>>>
>>>>>
>>>>>
>>>>>
>>>>> ------------------------------
>>>>> *From:* Robert Long <longrob604 at gmail.com>
>>>>> *Sent:* Friday, March 5, 2021 1:43 PM
>>>>> *To:* Hedyeh Ahmadi <hedyehah at usc.edu>
>>>>> *Cc:* Dexter Locke <dexter.locke at gmail.com>; R-mixed models mailing list <
>>>>> r-sig-mixed-models at r-project.org>; Megan M. Herting <herting at usc.edu>;
>>>>> Elisabeth Burnor <burnor at usc.edu>
>>>>> *Subject:* Re: [R-sig-ME] A three-level GLMM with binomial link in R
>>>>>
>>>>> You've run out of memory. Try running it on a machine with much larger RAM.
>>>>>
>>>>> On Fri, 5 Mar 2021, 21:18 Hedyeh Ahmadi, <hedyehah at usc.edu> wrote:
>>>>>
>>>>> Hi - Thank you for the informative replies.
>>>>>
>>>>> I will try those other packages. If MASS::glmmPQL uses lme() then this
>>>>> should work for me.
>>>>>
>>>>> My data structure is complex so it's hard to give reproducible example but
>>>>> for example for two of my models I get the following errors in lmer() while
>>>>> lme() runs smoothly.
>>>>>
>>>>> 1- Error: cannot allocate vector of size 2.3 Gb.
>>>>>
>>>>> 2- Error: couldn't evaluate grouping factor id:(family:site) within model
>>>>> frame: try adding grouping factor to data frame explicitly if possible.
>>>>> (note that the id variable works for simpler lmer() models so the variable
>>>>> itself is not an issue)
>>>>>
>>>>> My model looks like the following nested structure:
>>>>> lmer(Y ~ 1 + X1 + X2 + X3 + (1|site/family/id), data=dd, REML = FALSE)
>>>>>
>>>>> Best,
>>>>>
>>>>> Hedyeh Ahmadi, Ph.D.
>>>>> Statistician
>>>>> Keck School of Medicine
>>>>> Department of Preventive Medicine
>>>>> University of Southern California
>>>>>
>>>>> Postdoctoral Scholar
>>>>> Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
>>>>> University of California, Irvine
>>>>>
>>>>> LinkedIn
>>>>> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$>
>
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$>>
>
>>
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$
>
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$>>>
>
>>
>>>
>>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$
>
>>
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$
>
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$>>>>
>>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$
>
>>
>>>
>>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$
>
>>
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$
>
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$>>>>
>>>>>>
>>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$
>
>>
>>>
>>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$
>
>>
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$
>
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$>>>>
>>>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$
>
>>
>>>
>>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$
>
>>
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$
>
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$>>>>
>>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>> ________________________________
>>>>> From: Dexter Locke <dexter.locke at gmail.com>
>>>>> Sent: Friday, March 5, 2021 1:01 PM
>>>>> To: Hedyeh Ahmadi <hedyehah at usc.edu>
>>>>> Cc: r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>;
>>>>> Megan M. Herting <herting at usc.edu>; Elisabeth Burnor <burnor at usc.edu>
>>>>> Subject: Re: [R-sig-ME] A three-level GLMM with binomial link in R
>>>>>
>>>>> Hi Hedyeh,
>>>>>
>>>>> What is the problem you are having? Specifically, what is the estimation
>>>>> issue with lmer and lme?
>>>>>
>>>>> Can you provide a reproducible example? Can you provide the complete
>>>>> errors you are seeing?
>>>>>
>>>>> The current questions are vague, so it will be challenging for list
>>>>> members to provide much guidance.
>>>>>
>>>>> -Dexter
>>>>>
>>>>>
>>>>> On Fri, Mar 5, 2021 at 3:27 PM Hedyeh Ahmadi <hedyehah at usc.edu<mailto:
>>>>> hedyehah at usc.edu>> wrote:
>>>>> Hi All,
>>>>> I was wondering what would be a powerful package in R to run GLMM with
>>>>> logit link that can handle a data set with N=22945 and 3 nested random
>>>>> intercepts. So far, I have tried glmer() from lme4 and it's giving me a lot
>>>>> of estimation issues. Any other package I should try?
>>>>>
>>>>> I am asking for another package as I am having the same issue with lmer()
>>>>> for similar LMM with continuous outcome, while lme() from nlme package runs
>>>>> the models with no problem.
>>>>>
>>>>> Thank you in advance.
>>>>>
>>>>> Best,
>>>>>
>>>>> Hedyeh Ahmadi, Ph.D.
>>>>> Statistician
>>>>> Keck School of Medicine
>>>>> Department of Preventive Medicine
>>>>> University of Southern California
>>>>>
>>>>> Postdoctoral Scholar
>>>>> Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
>>>>> University of California, Irvine
>>>>>
>>>>> LinkedIn
>>>>> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$>
>
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$>>
>
>>
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$
>
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$>>>
>
>>
>>>
>>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$
>
>>
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$
>
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$>>>>
>>>>> <
>>>>> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$>
>
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$>>
>
>>
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$
>
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$>>>
>>>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$
>
>>
>>>
>>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$
>
>>
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$
>
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$>>>>
>>>>> <
>>>>> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$>
>
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$>>
>
>>
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$
>
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$>>>
>>>>>>>
>>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$
>
>>
>>>
>>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$
>
>>
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$
>
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$>>>>
>>>>> <
>>>>> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$>
>
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$>>
>
>>
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$
>
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$>>>
>>>>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$
>
>>
>>>
>>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$
>
>>
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$
>
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$>>>>
>>>>> <
>>>>> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$>
>
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$>>
>
>>
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$
>
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$>>>
>>>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>          [[alternative HTML version deleted]]
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org>
>>>>> mailing list
>>>>> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$>
>
>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$>>
>
>>
>>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$
>
>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$>>>
>
>>
>>>
>>>>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKG8rJcsmY$
>
>>
>>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKG8rJcsmY$
>
>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKG8rJcsmY$
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKG8rJcsmY$>>>>
>>>>> <
>>>>> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQM6wKtNs$
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQM6wKtNs$>
>
>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQM6wKtNs$
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQM6wKtNs$>>
>
>>
>>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQM6wKtNs$
>
>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQM6wKtNs$
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQM6wKtNs$>>>
>>>>>>
>>>>>
>>>>>          [[alternative HTML version deleted]]
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$>
>
>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$>>
>
>>
>>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$
>
>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$>>>
>
>>
>>>
>>>>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKG8rJcsmY$
>
>>
>>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKG8rJcsmY$
>
>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKG8rJcsmY$
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKG8rJcsmY$>>>>
>>>>>
>>>>>
>>>>
>>>>        [[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$>
>
>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$>>
>
>>
>>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$
>
>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$>>>
>
>>
>>>
>>>>
>>>
>>> _______________________________________________
>>> R-sig-mixed-models at r-project.org mailing list
>>> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$>
>
>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$>>
>
>>
>>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$
>
>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$>>>
>
>>
>>>

	[[alternative HTML version deleted]]


From j@h@d||e|d @end|ng |rom ed@@c@uk  Wed Mar 17 06:49:59 2021
From: j@h@d||e|d @end|ng |rom ed@@c@uk (Jarrod Hadfield)
Date: Wed, 17 Mar 2021 05:49:59 +0000
Subject: [R-sig-ME] MCMCglmm and covu models
Message-ID: <b190b589-9fac-48b2-36c5-d047794ce8f4@ed.ac.uk>

Hi,

There was a bug in MCMCglmm when fitting covu models. covu models fit a
covariance between a set of random effects and a set of residuals
(usually in a multivariate model). Analyses of data sets where some
levels in the random term were not observed for the residual term will
need to be rerun with versions >=2.32. Analyses where some levels in the
residual term were not in the random term should be fine. All (2!)
currently published analyses using covu are correct.

I'm sorry if this affects you.

Jarrod



The University of Edinburgh is a charitable body, registered in Scotland, with registration number SC005336. Is e buidheann carthannais a th? ann an Oilthigh Dh?n ?ideann, cl?raichte an Alba, ?ireamh cl?raidh SC005336.


From P|erre@M@r|e @end|ng |rom un|ge@ch  Wed Mar 17 18:59:25 2021
From: P|erre@M@r|e @end|ng |rom un|ge@ch (Pierre Marle)
Date: Wed, 17 Mar 2021 17:59:25 +0000
Subject: [R-sig-ME] Lmer model drops one parameter
Message-ID: <A31A9364-BBDD-47ED-ADD7-80FEEC349D78@unige.ch>

Dear everyone,

I have a lmer model to predict [Hg] according to a categorical variable (7 parameters for 134 observations) as fixed effects and the species as random effect.

The issue that I have is that the summary of model dropped one parameter of the qualitative variable. This is not a problem of unsufficient data of the dropped parameter because it has a high number of observations comparing with other parameters. Moreover, I don?t have any warning message after the model processing.

lme <- lmer(Hg ~ Feeding_type + (1|Sp), data=sp, REML=T)

Fixed effects:
                                             Estimate    Std. Error       df t value Pr(>|t|)
(Intercept)                              0.08404    0.01344 28.13392   6.254 9.06e-07 ***
Feeding_typeGatherer          -0.06692    0.02261 27.57559  -2.960  0.00626 **
Feeding_typeGrazer             -0.06701    0.02084 20.31009  -3.216  0.00427 **
Feeding_typePiercer             -0.07752    0.03093 18.71971  -2.506  0.02161 *
Feeding_typePredator           -0.03889    0.02026 25.21664  -1.919  0.06634 .
Feeding_typeShredder          -0.04154    0.01722 27.41420  -2.413  0.02278 *
Feeding_typeSponge-feeder  0.01674    0.02157 23.04972   0.776  0.44566

As you can see I?m using the lme4 package with REML=T. Should I change something to have the coefficients of all the feeding types in the summary?

I will be very grateful if someone could help me.

Kind regards

Pierre Marle
Phd student / Research assistant
pierre.marle at unige.ch<mailto:pierre.marle at unige.ch> / +41 22 379 0487

D?partement F.-A. Forel des sciences de l?environnement et de l'eau
Laboratoire d?Ecologie et de Biologie Aquatique
Sciences de la Terre et de l?Environnement
Universit? de Gen?ve

ADRESSE POSTALE:
Universit? de Gen?ve
Carl-Vogt 66
CH-1211 Gen?ve 4
SWITZERLAND
__________________________________________



	[[alternative HTML version deleted]]


From rob@rob|n@on @end|ng |rom bto@org  Wed Mar 17 19:26:42 2021
From: rob@rob|n@on @end|ng |rom bto@org (Rob Robinson)
Date: Wed, 17 Mar 2021 18:26:42 +0000
Subject: [R-sig-ME] Lmer model drops one parameter
In-Reply-To: <A31A9364-BBDD-47ED-ADD7-80FEEC349D78@unige.ch>
References: <A31A9364-BBDD-47ED-ADD7-80FEEC349D78@unige.ch>
Message-ID: <CAGcXcEaAuxpk5=UPbuvoL0n4owurs8ow+USPFGnNRUEZW5FD_w@mail.gmail.com>

Pierre
 This is to be expected, you cannot estimate both an intercept and all
levels of a factor. The immediate answer to your question is to include a
"-1" in the formula, which will give you an estimate for all your
categories; but you probably also want to review how factors are treated in
linear models according to your favourite stats book so that you
understand what is actually happening here. In the meantime this post might
help a little?
https://anythingbutrbitrary.blogspot.com/2012/04/lm-function-with-categorical-predictors.html
Best wishes
Rob


*************** Learn about Britain's Birds at www.bto.org/birdfacts
  ******************

Dr Rob Robinson, Associate Director - Research (he/him)
Hon Reader: Univ East Anglia | Visiting Researcher: Swiss Ornithological
Institute
British Trust for Ornithology, The Nunnery, Thetford, Norfolk, IP24 2PU
Ph: +44 (0)1842 750050       T: @btorobrob
E: rob.robinson at bto.org      W: www.bto.org/about-bto/our-staff/rob-robinson

======== "How can anyone be enlightened, when truth is so poorly lit"
========


On Wed, 17 Mar 2021 at 17:59, Pierre Marle <Pierre.Marle at unige.ch> wrote:

> Dear everyone,
>
> I have a lmer model to predict [Hg] according to a categorical variable (7
> parameters for 134 observations) as fixed effects and the species as random
> effect.
>
> The issue that I have is that the summary of model dropped one parameter
> of the qualitative variable. This is not a problem of unsufficient data of
> the dropped parameter because it has a high number of observations
> comparing with other parameters. Moreover, I don?t have any warning message
> after the model processing.
>
> lme <- lmer(Hg ~ Feeding_type + (1|Sp), data=sp, REML=T)
>
> Fixed effects:
>                                              Estimate    Std. Error
>  df t value Pr(>|t|)
> (Intercept)                              0.08404    0.01344 28.13392
>  6.254 9.06e-07 ***
> Feeding_typeGatherer          -0.06692    0.02261 27.57559  -2.960
> 0.00626 **
> Feeding_typeGrazer             -0.06701    0.02084 20.31009  -3.216
> 0.00427 **
> Feeding_typePiercer             -0.07752    0.03093 18.71971  -2.506
> 0.02161 *
> Feeding_typePredator           -0.03889    0.02026 25.21664  -1.919
> 0.06634 .
> Feeding_typeShredder          -0.04154    0.01722 27.41420  -2.413
> 0.02278 *
> Feeding_typeSponge-feeder  0.01674    0.02157 23.04972   0.776  0.44566
>
> As you can see I?m using the lme4 package with REML=T. Should I change
> something to have the coefficients of all the feeding types in the summary?
>
> I will be very grateful if someone could help me.
>
> Kind regards
>
> Pierre Marle
> Phd student / Research assistant
> pierre.marle at unige.ch<mailto:pierre.marle at unige.ch> / +41 22 379 0487
>
> D?partement F.-A. Forel des sciences de l?environnement et de l'eau
> Laboratoire d?Ecologie et de Biologie Aquatique
> Sciences de la Terre et de l?Environnement
> Universit? de Gen?ve
>
> ADRESSE POSTALE:
> Universit? de Gen?ve
> Carl-Vogt 66
> CH-1211 Gen?ve 4
> SWITZERLAND
> __________________________________________
>
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Wed Mar 17 19:29:57 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Wed, 17 Mar 2021 14:29:57 -0400
Subject: [R-sig-ME] Lmer model drops one parameter
In-Reply-To: <A31A9364-BBDD-47ED-ADD7-80FEEC349D78@unige.ch>
References: <A31A9364-BBDD-47ED-ADD7-80FEEC349D78@unige.ch>
Message-ID: <d67d915d-289e-3ea6-694f-c5591fe3ccc0@gmail.com>


    This is a classic issue with any model based on linear models (LMs, 
GLMs, LMMs, GLMMs, ...).  When you have a categorical predictor (factor) 
with n levels in a model with an intercept, there are only (n-1) 
*independent* parameters that can be fitted. There are lots of ways 
these parameters can be organized (called "contrasts"). R's default is 
to make the intercept equal to the expected value for the first level in 
the factor (by default, the first category in alphabetical order) and to 
the make the other (n-1) parameters correspond to the differences 
between levels 2 and 1, 3 and 1, ... n and 1.

   If you want the model to estimate the means of each group, include -1 
or +0 in your formula - this will suppress the intercept (but make the 
parameters basically useless for statistical inference, as you'll be 
comparing against a null hypothesis that the mean response in each group 
is zero).

    The emmeans and effects packages are useful (so is Rob Robinson's 
answer).

On 3/17/21 1:59 PM, Pierre Marle wrote:
> Dear everyone,
> 
> I have a lmer model to predict [Hg] according to a categorical variable (7 parameters for 134 observations) as fixed effects and the species as random effect.
> 
> The issue that I have is that the summary of model dropped one parameter of the qualitative variable. This is not a problem of unsufficient data of the dropped parameter because it has a high number of observations comparing with other parameters. Moreover, I don?t have any warning message after the model processing.
> 
> lme <- lmer(Hg ~ Feeding_type + (1|Sp), data=sp, REML=T)
> 
> Fixed effects:
>                                               Estimate    Std. Error       df t value Pr(>|t|)
> (Intercept)                              0.08404    0.01344 28.13392   6.254 9.06e-07 ***
> Feeding_typeGatherer          -0.06692    0.02261 27.57559  -2.960  0.00626 **
> Feeding_typeGrazer             -0.06701    0.02084 20.31009  -3.216  0.00427 **
> Feeding_typePiercer             -0.07752    0.03093 18.71971  -2.506  0.02161 *
> Feeding_typePredator           -0.03889    0.02026 25.21664  -1.919  0.06634 .
> Feeding_typeShredder          -0.04154    0.01722 27.41420  -2.413  0.02278 *
> Feeding_typeSponge-feeder  0.01674    0.02157 23.04972   0.776  0.44566
> 
> As you can see I?m using the lme4 package with REML=T. Should I change something to have the coefficients of all the feeding types in the summary?
> 
> I will be very grateful if someone could help me.
> 
> Kind regards
> 
> Pierre Marle
> Phd student / Research assistant
> pierre.marle at unige.ch<mailto:pierre.marle at unige.ch> / +41 22 379 0487
> 
> D?partement F.-A. Forel des sciences de l?environnement et de l'eau
> Laboratoire d?Ecologie et de Biologie Aquatique
> Sciences de la Terre et de l?Environnement
> Universit? de Gen?ve
> 
> ADRESSE POSTALE:
> Universit? de Gen?ve
> Carl-Vogt 66
> CH-1211 Gen?ve 4
> SWITZERLAND
> __________________________________________
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From bbo|ker @end|ng |rom gm@||@com  Wed Mar 17 19:31:01 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Wed, 17 Mar 2021 14:31:01 -0400
Subject: [R-sig-ME] A three-level GLMM with binomial link in R
In-Reply-To: <BYAPR07MB50949F06C713372A0E294B4ED16B9@BYAPR07MB5094.namprd07.prod.outlook.com>
References: <BYAPR07MB50945A60AFDE467F317861ACD1969@BYAPR07MB5094.namprd07.prod.outlook.com>
 <BYAPR07MB50947CD020DADA71CFF86407D1969@BYAPR07MB5094.namprd07.prod.outlook.com>
 <CA+3TTkNL+JGE+pgfOqASfvJ+r5eHmbGt3v+FzazouVePs_=x9Q@mail.gmail.com>
 <BYAPR07MB509450F1132EEB7C41F60B4CD1969@BYAPR07MB5094.namprd07.prod.outlook.com>
 <CA+3TTkM-abt0u4Je03nnTBBKiZw4AFj-UdPfyP_JOLZbDiJEFA@mail.gmail.com>
 <9e903a9f-5bec-934c-0b50-b2fca97cd4f3@gmail.com>
 <BYAPR07MB5094069BFA432F89688D34DCD1939@BYAPR07MB5094.namprd07.prod.outlook.com>
 <a8005560-3957-e814-df74-604d9cb857bb@gmail.com>
 <BYAPR07MB5094DD4608A0B5DB96A52EB5D1909@BYAPR07MB5094.namprd07.prod.outlook.com>
 <971aa7fc-a424-154d-c451-3027988f3c55@gmail.com>
 <BYAPR07MB5094B054FF44075722E4C378D16F9@BYAPR07MB5094.namprd07.prod.outlook.com>
 <c70f39ad-dbb4-5f3a-3e9d-9baa6e4c9da6@gmail.com>
 <BYAPR07MB50942F7C5155017E7D847301D16F9@BYAPR07MB5094.namprd07.prod.outlook.com>
 <BYAPR07MB50949F06C713372A0E294B4ED16B9@BYAPR07MB5094.namprd07.prod.outlook.com>
Message-ID: <d7107c1c-4e8e-8b23-8974-621fb0a25c25@gmail.com>



On 3/16/21 12:44 PM, Hedyeh Ahmadi wrote:
> Hello all,
> I am just forwarding my previous email again just in case and taking out 
> some parts that I already figured out - thank you for all your help:
> 
> I'll think more about how to share a data set that would create the same 
> error. Sorry, I am not very simulation savvy, but I'll try harder next time.
> 
> On the bright side, I was able to run the following model by implicitly 
> defining the group structure (slightly different from what was suggested 
> in the previous email) and it does give me the same estimation as lme() 
> with *random = ~1|site/family/id***random structure - so the memory 
> issue resolved for this model! Thank you for the suggestion.
> 
> dd$site_family <- interaction(dd$site, dd$family)
> m2.1 <- lmer(cbcl_scr_syn_internal_r ~ 1 + X1 + X2 + X3+ (1|site) 
> +(1|site_family/id), data=dd,? REML = FALSE)

    I'm glad you solved the problem, although I'm still bothered by the 
fact that I don't understand it.
> 
> *But now getting to my last question: *My data has 22945 rows, and some 
> individuals have only baseline measurement, some individuals have 
> baseline and 1 year measurement. A variable called eventname is the 
> indicator of that. I am now confused as my "id" variable does not have 
> this information (i.e. the order of measurement). How would the model 
> recognize that which repeated measure is measurment1 (i.e. baseline) and 
> which one is measurment2 (i.e. 1 year)? *Or maybe because I don't have a 
> random slope, I don't need to define the repeated measure structure and 
> adding eventname as a fixed effect is sufficient? *

    It makes the most sense (to me) to add eventname as a fixed effect.
> 
> OR do I need to run a model with additional random intercept of 
> eventname (i.e. (1|site/family/id/eventname))but in doing so lme() gives 
> me the number of observation equal to number of grouping for *eventname 
> %in% id %in% family %in% site *as follows.**Would that be okay?
> 
> Number of Observations: 13388
> Number of Groups:
>  ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?site ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? family %in% site
>  ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 21 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 9393
>  ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ??id %in% family %in% site ? ? ? ? ? ? ? ? ?eventname %in% id %in% family %in% abcd_site
>  ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?11111 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?13388
> 
> 
> Again, thank you so much for your time.
> 
> 
> Best,
> 
> Hedyeh Ahmadi, Ph.D.
> Statistician
> Keck School of Medicine
> Department of Preventive Medicine
> University of Southern California
> 
> Postdoctoral Scholar
> Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
> University of California, Irvine
> 
> LinkedIn
> www.linkedin.com/in/hedyeh-ahmadi <http://www.linkedin.com/in/hedyeh-ahmadi>
> <http://www.linkedin.com/in/hedyeh-ahmadi><http://www.linkedin.com/in/hedyeh-ahmadi>
> 
> 
> 
> 
> ------------------------------------------------------------------------
> *From:* Hedyeh Ahmadi <hedyehah at usc.edu>
> *Sent:* Friday, March 12, 2021 12:54 PM
> *To:* r-sig-mixed-models at r-project.org 
> <r-sig-mixed-models at r-project.org>; Ben Bolker <bbolker at gmail.com>
> *Subject:* Re: [R-sig-ME] A three-level GLMM with binomial link in R
> I'll think more about how to share a data set that would create the same 
> error. Sorry, I am not very simulation savvy but I'll try harder next time.
> 
> On the bright side, I was able to run the following model by implicitly 
> defining the group structure (slightly different from what was suggested 
> in the previous email) and it does give me the same estimation as lme() 
> with *random = ~1|site/family/id**random* structure - so the memory 
> issue resolved for this model! Thank you for the suggestion.
> 
> dd$site_family <- interaction(dd$site, dd$family)
> m2.1 <- lmer(cbcl_scr_syn_internal_r ~ 1 + X1 + X2 + X3+ (1|site) 
> +(1|site_family/id), data=dd,? REML = FALSE)
> 
> *But now getting to my last question: *My data has 22945 rows, and some 
> individuals have only baseline measurement, some individuals have 
> baseline and 1 year measurement. A variable called eventname is the 
> indicator of that. I am now confused as my "id" variable does not have 
> this information (i.e. the order of measurement). How would the model 
> recognize that which repeated measure is measurment1 (i.e. baseline) and 
> which one is measurment2 (i.e. 1 year)? *Or maybe because I don't have a 
> random slope, I don't need to define the repeated measure structure and 
> adding eventname as a fixed effect is sufficient? *
> 
> OR do I need to run a model with additional random intercept of 
> eventname but in doing so lme() gives me the number of observation equal 
> to umber of grouping for *eventname %in% id %in% family %in% site *as 
> follows.**Would that be okay?
> 
> Number of Observations: 13388
> Number of Groups:
>  ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?      site ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?                 family %in% site
>  ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 21 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 9393
>  ? ? ? ? ? ? ?                                ?id %in% family %in% site                  eventname %in% id %in% family %in% abcd_site
>  ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?11111 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?13388
> 
> The model formula with eventname as random slope in lme() would be as 
> follows but I have not been able to reproduce this in lmer() similar to 
> implicit formatting of m2.1 shown above - any help would be appreciated 
> here. Keep in mind created an implicit three-way and four-way 
> interaction takes too much memory on my personal PC so I am trying to 
> find a way around it as I did in m2.1.
> 
> m3 <- lme(cbcl_scr_syn_internal_r ~ 1 +X1+ X2 + X3, random = 
> ~1|site/family/id//eventname,
>  ? ? data=dd, na.action=na.exclude,method="ML")
> 
> Again, thank you so much for your time.
> 
> Best,
> 
> Hedyeh Ahmadi, Ph.D.
> Statistician
> Keck School of Medicine
> Department of Preventive Medicine
> University of Southern California
> 
> Postdoctoral Scholar
> Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
> University of California, Irvine
> 
> LinkedIn
> www.linkedin.com/in/hedyeh-ahmadi <http://www.linkedin.com/in/hedyeh-ahmadi>
> <http://www.linkedin.com/in/hedyeh-ahmadi><http://www.linkedin.com/in/hedyeh-ahmadi>
> 
> 
> 
> 
> ------------------------------------------------------------------------
> *From:* Ben Bolker <bbolker at gmail.com>
> *Sent:* Friday, March 12, 2021 11:45 AM
> *To:* Hedyeh Ahmadi <hedyehah at usc.edu>; r-sig-mixed-models at r-project.org 
> <r-sig-mixed-models at r-project.org>
> *Subject:* Re: [R-sig-ME] A three-level GLMM with binomial link in R
> 
> 
> On 3/12/21 12:13 PM, Hedyeh Ahmadi wrote:
>> Here are my comments/questions:
>> 
>>? 1. I have tried changing the site, family, and id to factor and I get
>>???? the same results.
>>? 2. Unfortunately, I can't share my data due to privacy issues but if
>>???? you tell me what other information you need, I can provide it.
> 
>  ?? We know you can't share the data.? Part of the art of getting
> software help is figuring out how you can create a shareable version of
> your data set, *or* a shareable version of something that will generate
> the same errors you're experiencing.? We need to do a bisection search
> between the private data you have, which causes problems with factor
> expansion in the grouping variables and is surprisingly memory-hungry,
> and the reproducible examples that I have constructed that mimic some
> aspects of your data set but don't show either problem.? Since we can't
> look at your data, the burden falls on you to create a
> reproducible/shareable example we can work with.
> 
>  ??? Assuming that
> 
> lmer(y ~ 1? +(1|site/family/id) , data =dd)
> 
> does show problems with your actual data set, can you anonymize the
> levels of site, family, and id, something like
> 
>  ?? anon_fac <- function(x, prefix="S") {
>  ?????? factor(x, levels=levels(x), labels=paste0(prefix,
> seq(length(levels(x))))
>  ?? }
> 
>  ?? anon_dd <- transform(dd, select=c(family, site, id))
>  ?? anon_dd <- transform(anon_dd,
>  ?????????? site=anon_fac(site,"S"),
>  ?????????? family=anon_fac(family,"F"),
>  ?????????? id=anon_fac(id,"I")
>  ?? )
> 
> This should provide a data set that contains *no* information other than
> the pattern of co-occurrence of grouping levels. I don't know who's in
> charge of data privacy for your group, but it's hard to imagine how
> sharing this would present a risk of personal identification ...
> 
> https://urldefense.com/v3/__https://stackoverflow.com/questions/10454973/how-to-create-example-data-set-from-private-data-replacing-variable-names-and-l__;!!LIr3w8kk_Xxm!86i5mS45OmW-JeD4GGs4ZQyanE9ePtf5QzjgYVkL_Rg284MkmW9z-lQGP70cEP4$ 
> <https://urldefense.com/v3/__https://stackoverflow.com/questions/10454973/how-to-create-example-data-set-from-private-data-replacing-variable-names-and-l__;!!LIr3w8kk_Xxm!86i5mS45OmW-JeD4GGs4ZQyanE9ePtf5QzjgYVkL_Rg284MkmW9z-lQGP70cEP4$> 
> 
> 
> https://urldefense.com/v3/__https://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example/6699112*6699112__;Iw!!LIr3w8kk_Xxm!86i5mS45OmW-JeD4GGs4ZQyanE9ePtf5QzjgYVkL_Rg284MkmW9z-lQGfDnxgGI$ 
> <https://urldefense.com/v3/__https://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example/6699112*6699112__;Iw!!LIr3w8kk_Xxm!86i5mS45OmW-JeD4GGs4ZQyanE9ePtf5QzjgYVkL_Rg284MkmW9z-lQGfDnxgGI$> 
> 
> 
> 
>>? 3. Note that when I run the three-way interaction code in my PC it
>>???? again runs out of memory and the error says the following. When I
>>???? tried to run it on interactive HPC, it kicks me out as it takes too
>>???? much memory/time so I will have to submit a batch script.
>>???? "Error: cannot allocate vector of size 18.1 Gb
>>???? In addition: Warning message:
>>???? In ans * length(l) :
>>???? Error: cannot allocate vector of size 18.1 Gb"
>>? 4. When I take out all the fixed effects, the problem still exists.
> 
> 
>  ?? That's good in one sense, as it simplifies the problem.
> 
>>? 5. *Question:* Also note that my data has 22945 rows, and some
>>???? individuals have only baseline measurement only, some individuals
>>???? have baseline and 1 year measurement. A variable called eventname is
>>???? the indicator of that. I am now confused as my "id" variable does
>>???? not have this information (i.e. the order of measurement). How would
>>???? the model recognize that which repeated measure is measurment1 (i.e.
>>???? baseline) and which one is measurment2(i.e. 1 year)?? Or maybe
>>???? because I don't have a random slope, I don't need to define the
>>???? repeated measure structure and adding eventname as a fixed effect is
>>???? sufficient?
> 
>  ??? Let's deal with this after we have the basic problems sorted.? If
> you want to account for the possible effects of ordering, then you'd
> need to add this variable ...
> 
>> 
>> Thanks again for all your help on this.
>> 
>> Best,
>> 
>> Hedyeh Ahmadi, Ph.D.
>> Statistician
>> Keck School of Medicine
>> Department of Preventive Medicine
>> University of Southern California
>> 
>> Postdoctoral Scholar
>> Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
>> University of California, Irvine
>> 
>> LinkedIn
>> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!86i5mS45OmW-JeD4GGs4ZQyanE9ePtf5QzjgYVkL_Rg284MkmW9z-lQGJrML1Sk$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!86i5mS45OmW-JeD4GGs4ZQyanE9ePtf5QzjgYVkL_Rg284MkmW9z-lQGJrML1Sk$>  
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!86i5mS45OmW-JeD4GGs4ZQyanE9ePtf5QzjgYVkL_Rg284MkmW9z-lQGJrML1Sk$ 
>  >
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!86i5mS45OmW-JeD4GGs4ZQyanE9ePtf5QzjgYVkL_Rg284MkmW9z-lQGJrML1Sk$ 
>  ><https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!86i5mS45OmW-JeD4GGs4ZQyanE9ePtf5QzjgYVkL_Rg284MkmW9z-lQGJrML1Sk$ >
>> 
>> 
>> 
>> 
>> ------------------------------------------------------------------------
>> *From:* Ben Bolker <bbolker at gmail.com>
>> *Sent:* Thursday, March 11, 2021 3:55 PM
>> *To:* Hedyeh Ahmadi <hedyehah at usc.edu>; r-sig-mixed-models at r-project.org 
>> <r-sig-mixed-models at r-project.org>; Megan M. Herting <herting at usc.edu>; 
>> Elisabeth Burnor <burnor at usc.edu>
>> *Subject:* Re: [R-sig-ME] A three-level GLMM with binomial link in R
>> 
>> 
>> On 3/11/21 1:11 PM, Hedyeh Ahmadi wrote:
>>> Hi Ben,
>>> Thank you for all the help and informative replies. Here is some info 
>>> about my data and my answers:
>>> 
>>>?? * Yes, I am running the exact model however this is just my toy model
>>>???? to get the code to work.
>>>?? * Reminder, I am trying to get lmer with a continuous outcome (but
>>>???? same data structure, with 3 random intercept) work before moving to
>>>???? glmer() with a logit link with a categorical 0/1 outcome.
>>>?? * Here are some information about my data:
>>>?????? o X1: num [1:22945] 9.25 NA 9.22 NA 9.22 NA 9.42 NA 9.25 NA ...
>>>?????? o X2: int [1:22945] 117 140 128 125 113 138 126 130 120 121 ...
>>>?????? o X3: chr [1:22945] "Female" "Male" "Male" "Male" "Male"
>>>?????? o site: chr [1:22945] "site15" "site15" "site15" "site15" "site15"
>>>???????? ... (I have 21 sites)
>>>?????? o family: int [1:22945] 0 1 1 1 1 3 3 4 4 5 ...
>>>?????? o id: chr [1:22945] "id1" "id2" "id2" "id3" "id3"...
>>>?? * The following model gives me the error that "Error: couldn't
>>>???? evaluate grouping factor id:(family:site) within model frame: try
>>>???? adding grouping factor to data frame explicitly if possible" - I ran
>>>???? this same model on a supercomputer and it *gave me the same error*,
>>>???? so this is not a memory limit issue.
>> 
>> So far I can't replicate this.? It seemed fishy to me that family was an
>> integer (I would try explicitly converting it to a factor), but doesn't
>> actually cause any problems in my example.
>> 
>>? ? (This differs from your example but not in ways I would expect to be
>> important: in particular, the types of the grouping variables are the
>> same [chr, int, chr]
>> 
>> n <- 10000
>> set.seed(101)
>> dd <- data.frame(y=rnorm(n),
>>? ????????????????? x1=rnorm(n),
>>? ????????????????? x2=rnorm(n),
>>? ????????????????? x3=rnorm(n),
>>? ????????????????? site=sample(paste0("s",1:15),size=n,replace=TRUE),
>>? ????????????????? family=sample(1:100,size=n,replace=TRUE),
>>? ????????????????? id=sample(paste0("id",1:20),size=n,replace=TRUE))
>> library(lme4)
>> lmer(y~1 + x1 + x2 + x3 + (1|site/family/id), data=dd)
>> 
>> ###
>> 
>> What is meant by "adding grouping factor to data frame explicitly" would
>> be in this case expanding out the nested terms:
>> 
>>? ? dd <- within(dd,
>> {
>>? ???? site_family <- interaction(site,family)
>>? ???? site_family_id <- interaction(site,family,id)
>> })
>> 
>> lmer(y~1 + x1 + x2 + x3 + (1|site) + (1|site_family) +
>> (1|site_family_id), data =dd)
>> 
>> 
>> 
>>>?????? o m2 <- lmer(cbcl_scr_syn_internal_r ~ 1 + X1 + X2 + X3 +
>>>???????? (1|site/family/id), data=dd, REML = FALSE)
>>>?? * The following *model ran on a supercomputer*.? This is the model
>>>???? that previously would give me the error "Error: cannot allocate
>>>???? vector of size 2.3 Gb". Here I am*reducing the number of sites to
>>>???? see if it runs, and it did* run on a supercomputer.
>>>?????? o m11 <- lmer(cbcl_scr_syn_internal_r ~ 1 + X1 +X2 + X3
>>>???????? +(1|site/family/id) ,
>>>????????? ? ? data=dd[-which(dd$abcd_site %in% c("site01","site02",
>>>???????? "site04", "site05", "site06", "site07", "site08","site09")),],
>>>???????? na.action=na.exclude, REML=FALSE)
>>> 
>>> Questions:
>>> 
>>>? 1. What I don't understand is that in m2, why lmer() does not
>>>???? recognizes the grouping factor that it does recognize in m11?
>> 
>>? ? I'm not sure either.
>> 
>>>? 2. At this point I don't think this is a memory issue as *m2 did not
>>>???? run on a supercompute*r and it's giving me *the same error as my
>>>???? personal computer*. However, in m11, the same grouping structure is
>>>???? being recognized when I reduce the number of sites from 21 to 13 -
>>>???? could this be because of severe imbalance in my family/id nesting,
>>>???? meaning most families have only one kid but some have 2 and a few
>>>???? have 3 kids?
>> 
>>? ?? It seems surprising.
>>? ?? Is there any way we can get a reproducible example?? For example,
>> suppose you randomize your X1, X2, X3 and anonymize all of your grouping
>> variables: would you then be able to share the data set?
>> 
>>? ?? Does the problem (let's say just the first problem) still occur if
>> you leave out the fixed effects? (I would expect so, and that would
>> simplify things somewhat - we're trying to get to the *simplest* example
>> that still demonstrates the problem.)
>> 
>> 
>>> 
>>> Sorry about the long email and thank you for your help in advance.
>>> 
>>> Best,
>>> 
>>> Hedyeh Ahmadi, Ph.D.
>>> Statistician
>>> Keck School of Medicine
>>> Department of Preventive Medicine
>>> University of Southern California
>>> 
>>> Postdoctoral Scholar
>>> Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
>>> University of California, Irvine
>>> 
>>> LinkedIn
>>> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!51-zg2ISp-lS-4HEW0ZNNEVE1ZD8ujdJZYx90xVOnZ-x6A7l6eu2KhSgMhYCJq4$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!51-zg2ISp-lS-4HEW0ZNNEVE1ZD8ujdJZYx90xVOnZ-x6A7l6eu2KhSgMhYCJq4$> 
> 
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!51-zg2ISp-lS-4HEW0ZNNEVE1ZD8ujdJZYx90xVOnZ-x6A7l6eu2KhSgMhYCJq4$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!51-zg2ISp-lS-4HEW0ZNNEVE1ZD8ujdJZYx90xVOnZ-x6A7l6eu2KhSgMhYCJq4$>> 
> 
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!51-zg2ISp-lS-4HEW0ZNNEVE1ZD8ujdJZYx90xVOnZ-x6A7l6eu2KhSgMhYCJq4$ 
> 
>>? >
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!51-zg2ISp-lS-4HEW0ZNNEVE1ZD8ujdJZYx90xVOnZ-x6A7l6eu2KhSgMhYCJq4$ 
> 
>>? ><https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!51-zg2ISp-lS-4HEW0ZNNEVE1ZD8ujdJZYx90xVOnZ-x6A7l6eu2KhSgMhYCJq4$ 
>  >
>>> 
>>> 
>>> 
>>> 
>>> ------------------------------------------------------------------------
>>> *From:* Ben Bolker <bbolker at gmail.com>
>>> *Sent:* Tuesday, March 9, 2021 4:12 PM
>>> *To:* Hedyeh Ahmadi <hedyehah at usc.edu>; r-sig-mixed-models at r-project.org 
>>> <r-sig-mixed-models at r-project.org>
>>> *Subject:* Re: [R-sig-ME] A three-level GLMM with binomial link in R
>>>? ?? OK, then it would be very helpful to have more details about your
>>> data set. Are one or more of X1, X2, X3 categorical predictors with many
>>> levels ... ?? Any chance we can see str() or summary() ?? Are you using
>>> exactly the formula you told us about, or something slightly different?
>>> 
>>>? ?? The computational burden of a large number of fixed effect parameters
>>> will be much worse for glmer than for lmer, unless you use nAGQ=0.
>>> glmmTMB would be able to help in two ways: (1) it doesn't scale as badly
>>> for large numbers of fixed effects; (2) it allows sparse fixed-effect
>>> model matrices (something we keep meaning to (re)implement in lme4) ...
>>> 
>>>? ? Making X1 into a 1000-level factor brings the required memory up by
>>> about a factor of 10 and increases the run time from seconds to minutes.
>>> 
>>> 
>>> Base model:
>>> 
>>>? ????????????????????? Function_Call Elapsed_Time_sec Total_RAM_Used_MiB
>>> 1 m<-lmer(form,data=dd,REML=FALSE)??????????? 1.903?????????????? 10.4
>>>? ?? Peak_RAM_Used_MiB
>>> 1???????????? 107.7
>>> 
>>> With X=1000-level factor (no derivative calculations):
>>> 
>>>? ? Function_Call
>>> 1
>>> m2<-lmer(form,data=dd2,REML=FALSE,control=lmerControl(calc.derivs=FALSE),verbose=10)
>>>? ?? Elapsed_Time_sec Total_RAM_Used_MiB Peak_RAM_Used_MiB
>>> 1????????? 559.735????????????? 608.8???????????? 984.5
>>> 
>>> 
>>> With derivative calculation at the end:
>>> 
>>>? ????????????????????????????????? Function_Call Elapsed_Time_sec
>>> 1 m3<-lmer(form,data=dd2,REML=FALSE,verbose=10)????????? 677.975
>>>? ?? Total_RAM_Used_MiB Peak_RAM_Used_MiB
>>> 1????????????? 608.7??????????? 1148.7
>>>? ?>
>>>? ?>
>>> 
>>> ---
>>> ibrary(lme4)
>>> set.seed(101)
>>> N <- 22945
>>> ns <- 100
>>> nf <- 100
>>> nid <- 100
>>> dd <- data.frame(X1=rnorm(N),
>>>? ????????????????? X2=rnorm(N),
>>>? ????????????????? X3=rnorm(N),
>>>? ????????????????? site=sample(ns, replace=TRUE, size=N),
>>>? ????????????????? family=sample(nf, replace=TRUE, size=N),
>>>? ????????????????? id=sample(nid, replace=TRUE, size=N))
>>> form <- Y ~ 1 + X1 + X2 + X3 + (1|site/family/id)
>>> dd$Y <- simulate(form[-2], newdata=dd, family=gaussian,
>>>                    
>>> newparams=list(beta=rep(1,4),theta=rep(1,3),sigma=1))[[1]]
>>> library(peakRAM)
>>> system.time(mem <- peakRAM(
>>>? ???? m <- lmer(form, data=dd, REML=FALSE)
>>>? ???? ))
>>> print(mem)
>>> 
>>> dd2 <- transform(dd,
>>>? ???????? X1=factor(sample(1000,size=N,replace=TRUE)))
>>> 
>>> system.time(mem2 <- peakRAM(
>>>? ???? m2 <- lmer(form, data=dd2, REML=FALSE,
>>> control=lmerControl(calc.derivs=FALSE), verbose=10)
>>> ))
>>> print(mem2)
>>> 
>>> system.time(mem3 <- peakRAM(
>>>? ???? m3 <- lmer(form, data=dd2, REML=FALSE, verbose=10)
>>> ))
>>> print(mem3)
>>> 
>>> 
>>> On 3/8/21 11:29 AM, Hedyeh Ahmadi wrote:
>>>> Thank you for the toy example. This same example in my PC gives the 
>>>> following memory use output:
>>>> 
>>>> 
>>>>? > mem
>>>>? ? ? ? ? ? ? ? ? ? ? ?Function_Call                            
>>>> Elapsed_Time_sec ? ? ? ? Total_RAM_Used_MiB ?? Peak_RAM_Used_MiB
>>>>? ? m<-lmer(form,data=dd,REML=FALSE) ? ? ? ? ? ? 2.64                     
>>>>? ? ? ? ? ? ? ? ? 10.3 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 130.1
>>>> 
>>>> When I run peakRAM() for my actual data, it take one hour plus then my 
>>>> PC slows down, then I have to stop R to be able to use my PC.
>>>> 
>>>> Best,
>>>> 
>>>> Hedyeh Ahmadi, Ph.D.
>>>> Statistician
>>>> Keck School of Medicine
>>>> Department of Preventive Medicine
>>>> University of Southern California
>>>> 
>>>> Postdoctoral Scholar
>>>> Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
>>>> University of California, Irvine
>>>> 
>>>> LinkedIn
>>>> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5O8KlsAUILt44__IHSzbCUgVs7dWxAB8FS9wiKC3j5P6hGrnuJSGckmCIR91AZs$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5O8KlsAUILt44__IHSzbCUgVs7dWxAB8FS9wiKC3j5P6hGrnuJSGckmCIR91AZs$> 
> 
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5O8KlsAUILt44__IHSzbCUgVs7dWxAB8FS9wiKC3j5P6hGrnuJSGckmCIR91AZs$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5O8KlsAUILt44__IHSzbCUgVs7dWxAB8FS9wiKC3j5P6hGrnuJSGckmCIR91AZs$>> 
> 
>> 
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5O8KlsAUILt44__IHSzbCUgVs7dWxAB8FS9wiKC3j5P6hGrnuJSGckmCIR91AZs$ 
> 
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5O8KlsAUILt44__IHSzbCUgVs7dWxAB8FS9wiKC3j5P6hGrnuJSGckmCIR91AZs$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5O8KlsAUILt44__IHSzbCUgVs7dWxAB8FS9wiKC3j5P6hGrnuJSGckmCIR91AZs$>>> 
> 
>> 
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5O8KlsAUILt44__IHSzbCUgVs7dWxAB8FS9wiKC3j5P6hGrnuJSGckmCIR91AZs$ 
> 
>> 
>>>? >
>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5O8KlsAUILt44__IHSzbCUgVs7dWxAB8FS9wiKC3j5P6hGrnuJSGckmCIR91AZs$ 
> 
>> 
>>>? ><https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5O8KlsAUILt44__IHSzbCUgVs7dWxAB8FS9wiKC3j5P6hGrnuJSGckmCIR91AZs$ 
> 
>>? >
>>>> 
>>>> 
>>>> 
>>>> 
>>>> ------------------------------------------------------------------------
>>>> *From:* R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on 
>>>> behalf of Ben Bolker <bbolker at gmail.com>
>>>> *Sent:* Friday, March 5, 2021 5:44 PM
>>>> *To:* r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>
>>>> *Subject:* Re: [R-sig-ME] A three-level GLMM with binomial link in R
>>>>? ?? Here's an example that conforms approximately to the structure of
>>>> your data: on my machine the peak RAM usage is 121 Mb, far short of your
>>>> 2.3 Gb ...? so I still suspect there is something going on that we don't
>>>> know about/haven't guessed yet.
>>>> 
>>>> set.seed(101)
>>>> N <- 22945
>>>> ns <- 100
>>>> nf <- 100
>>>> nid <- 100
>>>> dd <- data.frame(X1=rnorm(N),
>>>>? ????????????????? X2=rnorm(N),
>>>>? ????????????????? X3=rnorm(N),
>>>>? ????????????????? site=sample(ns, replace=TRUE, size=N),
>>>>? ????????????????? family=sample(nf, replace=TRUE, size=N),
>>>>? ????????????????? id=sample(nid, replace=TRUE, size=N))
>>>> form <- Y ~ 1 + X1 + X2 + X3 + (1|site/family/id)
>>>> dd$Y <- simulate(form[-2], newdata=dd, family=gaussian,
>>>>                    
>>>> newparams=list(beta=rep(1,4),theta=rep(1,3),sigma=1))[[1]]
>>>> library(peakRAM)
>>>> mem <- peakRAM(
>>>>? ???? m <- lmer(form, data=dd, REML=FALSE)
>>>> )
>>>> 
>>>> mem
>>>>? ????????????????????? Function_Call Elapsed_Time_sec Total_RAM_Used_MiB
>>>> 1 m<-lmer(form,data=dd,REML=FALSE)??????????? 1.754?????????????? 10.3
>>>>? ?? Peak_RAM_Used_MiB
>>>> 1???????????? 120.7
>>>> 
>>>> 
>>>> On 3/5/21 4:52 PM, Robert Long wrote:
>>>>> Perhaps because of the different ways they store objects internally while
>>>>> fitting the models.
>>>>> 
>>>>> On Fri, 5 Mar 2021, 21:47 Hedyeh Ahmadi, <hedyehah at usc.edu> wrote:
>>>>> 
>>>>>> Thank you for the reply Robert - If I am running out of memory in lmer(),
>>>>>> do you know why lme() runs just fine?
>>>>>>
>>>>>> Best,
>>>>>>
>>>>>> Hedyeh Ahmadi, Ph.D.
>>>>>> Statistician
>>>>>> Keck School of Medicine
>>>>>> Department of Preventive Medicine
>>>>>> University of Southern California
>>>>>>
>>>>>> Postdoctoral Scholar
>>>>>> Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
>>>>>> University of California, Irvine
>>>>>>
>>>>>> LinkedIn
>>>>>> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$> 
> 
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$>> 
> 
>> 
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$ 
> 
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$>>> 
> 
>> 
>>> 
>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$ 
> 
>> 
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$ 
> 
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$>>>> 
> 
>> 
>>> 
>>>> 
>>>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$ 
> 
>> 
>>> 
>>>>? >
>>>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$ 
> 
>> 
>>> 
>>>>? >
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>> ------------------------------
>>>>>> *From:* Robert Long <longrob604 at gmail.com>
>>>>>> *Sent:* Friday, March 5, 2021 1:43 PM
>>>>>> *To:* Hedyeh Ahmadi <hedyehah at usc.edu>
>>>>>> *Cc:* Dexter Locke <dexter.locke at gmail.com>; R-mixed models mailing list <
>>>>>> r-sig-mixed-models at r-project.org>; Megan M. Herting <herting at usc.edu>;
>>>>>> Elisabeth Burnor <burnor at usc.edu>
>>>>>> *Subject:* Re: [R-sig-ME] A three-level GLMM with binomial link in R
>>>>>>
>>>>>> You've run out of memory. Try running it on a machine with much larger RAM.
>>>>>>
>>>>>> On Fri, 5 Mar 2021, 21:18 Hedyeh Ahmadi, <hedyehah at usc.edu> wrote:
>>>>>>
>>>>>> Hi - Thank you for the informative replies.
>>>>>>
>>>>>> I will try those other packages. If MASS::glmmPQL uses lme() then this
>>>>>> should work for me.
>>>>>>
>>>>>> My data structure is complex so it's hard to give reproducible example but
>>>>>> for example for two of my models I get the following errors in lmer() while
>>>>>> lme() runs smoothly.
>>>>>>
>>>>>> 1- Error: cannot allocate vector of size 2.3 Gb.
>>>>>>
>>>>>> 2- Error: couldn't evaluate grouping factor id:(family:site) within model
>>>>>> frame: try adding grouping factor to data frame explicitly if possible.
>>>>>> (note that the id variable works for simpler lmer() models so the variable
>>>>>> itself is not an issue)
>>>>>>
>>>>>> My model looks like the following nested structure:
>>>>>> lmer(Y ~ 1 + X1 + X2 + X3 + (1|site/family/id), data=dd, REML = FALSE)
>>>>>>
>>>>>> Best,
>>>>>>
>>>>>> Hedyeh Ahmadi, Ph.D.
>>>>>> Statistician
>>>>>> Keck School of Medicine
>>>>>> Department of Preventive Medicine
>>>>>> University of Southern California
>>>>>>
>>>>>> Postdoctoral Scholar
>>>>>> Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
>>>>>> University of California, Irvine
>>>>>>
>>>>>> LinkedIn
>>>>>> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$> 
> 
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$>> 
> 
>> 
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$ 
> 
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$>>> 
> 
>> 
>>> 
>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$ 
> 
>> 
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$ 
> 
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$>>>> 
> 
>> 
>>> 
>>>> 
>>>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$ 
> 
>> 
>>> 
>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$ 
> 
>> 
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$ 
> 
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$>>>>>
>>>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$ 
> 
>> 
>>> 
>>>> 
>>>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$ 
> 
>> 
>>> 
>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$ 
> 
>> 
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$ 
> 
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$>>>>>
>>>>>>>
>>>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$ 
> 
>> 
>>> 
>>>> 
>>>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$ 
> 
>> 
>>> 
>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$ 
> 
>> 
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$ 
> 
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$>>>>>
>>>>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$ 
> 
>> 
>>> 
>>>> 
>>>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$ 
> 
>> 
>>> 
>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$ 
> 
>> 
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$ 
> 
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$>>>>>
>>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>> ________________________________
>>>>>> From: Dexter Locke <dexter.locke at gmail.com>
>>>>>> Sent: Friday, March 5, 2021 1:01 PM
>>>>>> To: Hedyeh Ahmadi <hedyehah at usc.edu>
>>>>>> Cc: r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>;
>>>>>> Megan M. Herting <herting at usc.edu>; Elisabeth Burnor <burnor at usc.edu>
>>>>>> Subject: Re: [R-sig-ME] A three-level GLMM with binomial link in R
>>>>>>
>>>>>> Hi Hedyeh,
>>>>>>
>>>>>> What is the problem you are having? Specifically, what is the estimation
>>>>>> issue with lmer and lme?
>>>>>>
>>>>>> Can you provide a reproducible example? Can you provide the complete
>>>>>> errors you are seeing?
>>>>>>
>>>>>> The current questions are vague, so it will be challenging for list
>>>>>> members to provide much guidance.
>>>>>>
>>>>>> -Dexter
>>>>>>
>>>>>>
>>>>>> On Fri, Mar 5, 2021 at 3:27 PM Hedyeh Ahmadi <hedyehah at usc.edu<mailto:
>>>>>> hedyehah at usc.edu>> wrote:
>>>>>> Hi All,
>>>>>> I was wondering what would be a powerful package in R to run GLMM with
>>>>>> logit link that can handle a data set with N=22945 and 3 nested random
>>>>>> intercepts. So far, I have tried glmer() from lme4 and it's giving me a lot
>>>>>> of estimation issues. Any other package I should try?
>>>>>>
>>>>>> I am asking for another package as I am having the same issue with lmer()
>>>>>> for similar LMM with continuous outcome, while lme() from nlme package runs
>>>>>> the models with no problem.
>>>>>>
>>>>>> Thank you in advance.
>>>>>>
>>>>>> Best,
>>>>>>
>>>>>> Hedyeh Ahmadi, Ph.D.
>>>>>> Statistician
>>>>>> Keck School of Medicine
>>>>>> Department of Preventive Medicine
>>>>>> University of Southern California
>>>>>>
>>>>>> Postdoctoral Scholar
>>>>>> Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
>>>>>> University of California, Irvine
>>>>>>
>>>>>> LinkedIn
>>>>>> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$> 
> 
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$>> 
> 
>> 
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$ 
> 
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$>>> 
> 
>> 
>>> 
>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$ 
> 
>> 
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$ 
> 
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$>>>> 
> 
>> 
>>> 
>>>> 
>>>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$ 
> 
>> 
>>> 
>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$ 
> 
>> 
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$ 
> 
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$>>>>>
>>>>>> <
>>>>>> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$> 
> 
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$>> 
> 
>> 
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$ 
> 
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$>>> 
> 
>> 
>>> 
>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$ 
> 
>> 
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$ 
> 
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$>>>>
>>>>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$ 
> 
>> 
>>> 
>>>> 
>>>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$ 
> 
>> 
>>> 
>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$ 
> 
>> 
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$ 
> 
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$>>>>>
>>>>>> <
>>>>>> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$> 
> 
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$>> 
> 
>> 
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$ 
> 
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$>>> 
> 
>> 
>>> 
>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$ 
> 
>> 
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$ 
> 
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$>>>>
>>>>>>>>
>>>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$ 
> 
>> 
>>> 
>>>> 
>>>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$ 
> 
>> 
>>> 
>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$ 
> 
>> 
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$ 
> 
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$>>>>>
>>>>>> <
>>>>>> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$> 
> 
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$>> 
> 
>> 
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$ 
> 
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$>>> 
> 
>> 
>>> 
>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$ 
> 
>> 
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$ 
> 
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$>>>>
>>>>>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k70OXW4fU$ 
> 
>> 
>>> 
>>>> 
>>>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$ 
> 
>> 
>>> 
>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$ 
> 
>> 
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$ 
> 
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKGGuIvhag$>>>>>
>>>>>> <
>>>>>> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$> 
> 
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$>> 
> 
>> 
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$ 
> 
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$>>> 
> 
>> 
>>> 
>>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$ 
> 
>> 
>>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$ 
> 
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQdYkAXFg$>>>>
>>>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>????????? [[alternative HTML version deleted]]
>>>>>>
>>>>>> _______________________________________________
>>>>>> R-sig-mixed-models at r-project.org<mailto:R-sig-mixed-models at r-project.org>
>>>>>> mailing list
>>>>>> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$ 
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$> 
> 
>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$ 
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$>> 
> 
>> 
>>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$ 
> 
>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$ 
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$>>> 
> 
>> 
>>> 
>>>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$ 
> 
>> 
>>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$ 
> 
>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$ 
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$>>>> 
> 
>> 
>>> 
>>>> 
>>>>>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKG8rJcsmY$ 
> 
>> 
>>> 
>>>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKG8rJcsmY$ 
> 
>> 
>>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKG8rJcsmY$ 
> 
>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKG8rJcsmY$ 
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKG8rJcsmY$>>>>>
>>>>>> <
>>>>>> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQM6wKtNs$ 
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQM6wKtNs$> 
> 
>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQM6wKtNs$ 
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQM6wKtNs$>> 
> 
>> 
>>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQM6wKtNs$ 
> 
>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQM6wKtNs$ 
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQM6wKtNs$>>> 
> 
>> 
>>> 
>>>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQM6wKtNs$ 
> 
>> 
>>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQM6wKtNs$ 
> 
>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQM6wKtNs$ 
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!8UfGozITdR3cNo929aSVEsbVNgbIul9f91q4hA3PAf0ywits0jIKVDAQM6wKtNs$>>>>
>>>>>>>
>>>>>>
>>>>>>????????? [[alternative HTML version deleted]]
>>>>>>
>>>>>> _______________________________________________
>>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>>> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$ 
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$> 
> 
>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$ 
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$>> 
> 
>> 
>>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$ 
> 
>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$ 
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$>>> 
> 
>> 
>>> 
>>>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$ 
> 
>> 
>>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$ 
> 
>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$ 
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$>>>> 
> 
>> 
>>> 
>>>> 
>>>>>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKG8rJcsmY$ 
> 
>> 
>>> 
>>>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKG8rJcsmY$ 
> 
>> 
>>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKG8rJcsmY$ 
> 
>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKG8rJcsmY$ 
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!5uCe7IsPHtgAoEp8Qsbn8bXOUBLGi7pVfXIjHwMUHVDbmnOSRCu7OHKG8rJcsmY$>>>>>
>>>>>>
>>>>>>
>>>>> 
>>>>>??????? [[alternative HTML version deleted]]
>>>>> 
>>>>> _______________________________________________
>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$ 
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$> 
> 
>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$ 
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$>> 
> 
>> 
>>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$ 
> 
>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$ 
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$>>> 
> 
>> 
>>> 
>>>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$ 
> 
>> 
>>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$ 
> 
>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$ 
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$>>>> 
> 
>> 
>>> 
>>>> 
>>>>>
>>>> 
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$ 
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$> 
> 
>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$ 
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$>> 
> 
>> 
>>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$ 
> 
>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$ 
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$>>> 
> 
>> 
>>> 
>>>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$ 
> 
>> 
>>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$ 
> 
>> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$ 
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!7bcqr_mYJEwUBwSQ-hoyGUZPrR-Wz2RGDxVbFlFtbA0oveGsE7tg-2k7pcSE0ic$>>>> 
> 
>> 
>>> 
>>>>


From y@@hree19 @end|ng |rom gm@||@com  Thu Mar 18 16:23:10 2021
From: y@@hree19 @end|ng |rom gm@||@com (Yashree Mehta)
Date: Thu, 18 Mar 2021 16:23:10 +0100
Subject: [R-sig-ME] Log-likelihood for each datapoint
Message-ID: <CAOE=hq+3UUFqu29TzWThOLK0rVzBeVFXJusuexjoqMKafnToBA@mail.gmail.com>

Hi,

I have the following cluster dataset:

1050 Households who own multiple plots (2 on an average). Thus I have a
dataset of 2799 observations.

I am trying to calculate the log-likelihood value for each datapoint (Here,
for each household). I need this value because I have to compute a test
statistic for non-nested model comparison for comparing the lme model with
another model.

At present, I am using the logged value of the multivariate normal pdf. I
extracted the residual variance-covariance matrix, assigned the sigma
matrix (the dimension depending upon number of plots owned by the
household), and composed the following code for log likelihood value of
each household.

llk<-c()
for (i in unique(dataset$household_ID)){

  llk[i] <- log(

    (2*pi)^(- (# of plots/household)/2)*

      determinant^-0.5*

      exp(-0.5*t(as.matrix( dataset [ dataset $household_ID ==i,
"observedminusfitted"]))%*%as.matrix(inverse)%*% as.matrix( dataset [
dataset $ household_ID ==i,"observedminusfitted"]))
  )

However, the sum of individual likelihood values is not equal to the total
log likelihood value reported by logLik function.

Is this the correct path? If not, is there another way to calculate
loglikelihood value of a single datapoint?

Thank you,

Regards,
Yashree

	[[alternative HTML version deleted]]


From ||@n2010 @end|ng |rom gm@||@com  Fri Mar 19 04:11:04 2021
From: ||@n2010 @end|ng |rom gm@||@com (Fen)
Date: Thu, 18 Mar 2021 23:11:04 -0400
Subject: [R-sig-ME] help: newbies on fitting the simplest two-level GLMM
Message-ID: <CANgRuPKCGgkNNcMnHH2yY35dJWH=Erzeyio90VphcMdJsiPh9A@mail.gmail.com>

Hi dear all,

I am new to r mixed modeling using the lme4 package. I have a couple of
simple questions and I would appreciate it a lot if someone could help me
out with my questions. I have a (simplified) nested data set with items
produced by the same generating models, specifically I have 18 models,
under which each has 6 or 7 items, and each item has somewhat over 100
responses. I am trying to model the dependence in the data by fitting a
two-level GLM model with logit link function because my dependent variable
is binary. This is the model I used as shown in the output ( with some
explanations on the variable on the top) :
ID: item id
Model ID: generating model tied to the item id
summary(AIGresp1):
ID              ModelID          ScoredResponse
 Length:13628       Length:13628       Min.   :0.0000
 Class :character   Class :character   1st Qu.:1.0000
 Mode  :character   Mode  :character   Median :1.0000
                                       Mean   :0.7778
                                       3rd Qu.:1.0000
                                       Max.   :1.0000
**************************************************************************************************************************************************************
Generalized linear mixed model fit by maximum likelihood (Laplace
Approximation) ['glmerMod']
 Family: binomial  ( logit )
*Formula: ScoredResponse ~ 1 + (1 | ID) + (1 | ModelID)   --> Model fitted *
   Data: AIGresp1

     AIC      BIC   logLik deviance df.resid
 12242.9  12265.5  -6118.5  12236.9    13625

Scaled residuals:
    Min      1Q  Median      3Q     Max
-8.3534  0.1197  0.3266  0.5361  1.7977

Random effects:
 Groups  Name        Variance Std.Dev.
 ID      (Intercept) 0.3996   0.6322
 ModelID (Intercept) 1.3779   1.1738
Number of obs: 13628, groups:  ID, 119; ModelID, 18

Fixed effects:
            Estimate Std. Error z value Pr(>|z|)
(Intercept)   1.6555     0.2858   5.792 6.96e-09 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

More organized output as below:
> summ(m1)
MODEL INFO:
Observations: 13628
Dependent Variable: ScoredResponse
Type: Mixed effects generalized linear regression
Error Distribution: binomial
Link function: logit

MODEL FIT:
AIC = 12242.92, BIC = 12265.48
Pseudo-R? (fixed effects) = 0.00
Pseudo-R? (total) = 0.35

FIXED EFFECTS:
-----------------------------------------------
                    Est.   S.E.   z val.      p
----------------- ------ ------ -------- ------
(Intercept)         1.66   0.29     5.79   0.00
-----------------------------------------------

RANDOM EFFECTS:
-----------------------------------
  Group     Parameter    Std. Dev.
--------- ------------- -----------
   ID      (Intercept)     0.63
 ModelID   (Intercept)     1.17
-----------------------------------

Grouping variables:
---------------------------
  Group    # groups   ICC
--------- ---------- ------
   ID        119      0.08
 ModelID      18      0.27
---------------------------
***************************************************************************************************************************************************************************
So in the model, both the items and models are the random effects, while
the intercept is the fixed effect. I shared this output because this is the
only model that gave me an output. Here are my questions:
1. As my items are nested under item models, the grouping variable should
be Model, but then in the organized output, I also had items as a grouping
variable too, maybe the way I modeled the multilevel structure is wrong?! I
also tried to fit the model by treating model as fixed effect: m01 <-
glmer(ScoredResponse~0+ModelID+(1|ID), AIGresp1,family=binomial), but then
my grouping ID became the IDs of items. I am really not so clear about how
to fit a multilevel model in this package in r and how can I tell my level
1 variables are truly level 1, so are my level 2 variables. Or does the
hiercharchy all reflect in the data structure?
2. The model I want to estimate is this one: m11 <-
glmer(ScoredResponse~-1+ID+(1|ModelID),AIGresp1,family=binomial); however,
it was running forever. I have to kill it in the end. When things like this
occur, what problems do it indicate?
3. I want to get the standard error estimates for random coefficients. I
read in the manual that only the standard errors of the fixed coefficients
are computed, any suggestions on the quickest to get the standard error
estimates for the random effects? Is there any function in the most recent
version of lme4, like mcmcsamp, that I can use to bootstrap the standard
error estimates?

Any comments would be highly appreciated!
Fen

	[[alternative HTML version deleted]]


From |nk@@w|||m@ @end|ng |rom hotm@||@de  Fri Mar 19 07:34:00 2021
From: |nk@@w|||m@ @end|ng |rom hotm@||@de (Inka Willms)
Date: Fri, 19 Mar 2021 06:34:00 +0000
Subject: [R-sig-ME] Williams test from StatsCharrms package after linear
 mixed model with factors as explanatory variables (mixed anova)
Message-ID: <AM8P190MB0803F6A9409C3EDCD3884C408C689@AM8P190MB0803.EURP190.PROD.OUTLOOK.COM>



Hello, I am working on the analysis of studies that have to be analyzed exactly as described in an OECD Guideline. It is written, that after a mixed anova (lmer(as.numeric(fluorescence)~ as.factor(treatment) + (1|as.factor(replicate)) + (1|Replicate:Treatment))
a williams test like described in the StatsCharrms package has to be conducted, to receive Information about the influence of the chemical on the test subjects. 

It is not possible to use the williams option from the glht function of the multcomp package, as that is not the correct one ( not the one required for ecotoxicology). 
My problem is that I do not know on which output of the mixed anova I can conduct the williams test. I would really appreciate your help! 

From |@w|@wt @end|ng |rom gm@||@com  Fri Mar 19 07:41:55 2021
From: |@w|@wt @end|ng |rom gm@||@com (Tip But)
Date: Fri, 19 Mar 2021 01:41:55 -0500
Subject: [R-sig-ME] Adding Level for non-repeated measurements
Message-ID: <CADreqiz9-2OO1sfENFNyDP-wK9w5LZgcEFVdDVJBMxV23box=A@mail.gmail.com>

Hello All,

I have a cross-sectional (i.e., non-repeated measurements) dataset from
students ("stud_id") nested within many schools ("sch_id").

The "stud_id" is simply the same as the "row number" for each student (1,
..., n). We know the participating students have been in frequent contact
with each other in each school and thus their scores in their own schools
to varying degrees are correlated.

1- Given above, should we possibly add an additional random-effect for
"stud_id"? If yes, why?

2- Given above, should we also allow residuals in each school (e_ij) to
correlate? If yes, why? (I have a bit of a conceptual problem understanding
this part given the cross-sectional nature of our study.)

Thank you,
Joe

# Here is some toy data:

dd <- read.csv("https://raw.githubusercontent.com/hkil/m/master/hs.csv")

lme4::lmer(score ~ 1 + (1 | sch_id / stud_id), data = dd,
     control = lmerControl(check.nobs.vs.nRE = "ignore")) # I'm assuming in
lme4 adding  "stud_id" as a random-effect by default is not

	[[alternative HTML version deleted]]


From D@v|d@Du||y @end|ng |rom q|mrbergho|er@edu@@u  Fri Mar 19 08:57:37 2021
From: D@v|d@Du||y @end|ng |rom q|mrbergho|er@edu@@u (David Duffy)
Date: Fri, 19 Mar 2021 07:57:37 +0000
Subject: [R-sig-ME] Adding Level for non-repeated measurements
In-Reply-To: <CADreqiz9-2OO1sfENFNyDP-wK9w5LZgcEFVdDVJBMxV23box=A@mail.gmail.com>
References: <CADreqiz9-2OO1sfENFNyDP-wK9w5LZgcEFVdDVJBMxV23box=A@mail.gmail.com>
Message-ID: <378e91f7def24ad5adc8e65e143645ad@qimrberghofer.edu.au>

Joe wrote:

> I have a cross-sectional (i.e., non-repeated measurements) dataset from
> students ("stud_id") nested within many schools ("sch_id").
> 1- Given above, should we possibly add an additional random-effect for
> "stud_id"? If yes, why?
> 2- Given above, should we also allow residuals in each school (e_ij) to
> correlate? If yes, why? (I have a bit of a conceptual problem understanding
> this part given the cross-sectional nature of our study.)

I think this is more a slightly-harder-than-elementary stats question rather than a "technical" query. If this was some types of 
GLMM, then the answer to 1 would be yes eg poisson GLMM then an individual-specific random effect adds in one type of 
extra-poisson variation. This is not the case for the gaussian (hopefully you see why). As to 2, consider how the *variance* of your 
measurement could be different within each school. 


From |@w|@wt @end|ng |rom gm@||@com  Fri Mar 19 18:05:40 2021
From: |@w|@wt @end|ng |rom gm@||@com (Tip But)
Date: Fri, 19 Mar 2021 12:05:40 -0500
Subject: [R-sig-ME] Adding Level for non-repeated measurements
In-Reply-To: <378e91f7def24ad5adc8e65e143645ad@qimrberghofer.edu.au>
References: <CADreqiz9-2OO1sfENFNyDP-wK9w5LZgcEFVdDVJBMxV23box=A@mail.gmail.com>
 <378e91f7def24ad5adc8e65e143645ad@qimrberghofer.edu.au>
Message-ID: <CADreqiz+6fkzbx+vnxOgJ8hPuqK2Gxq1g7pFa2CwF8+_mtLKFw@mail.gmail.com>

Dear David,

Thank you for your response. As my toy example showed, we do have a
normally distributed response variable.

As to 1), I have seen (e.g., see variable `id` in:
https://stat.ethz.ch/pipermail/r-sig-meta-analysis/2018-July/000896.html)
that what you refer to as "individual-specific" random-effects are used in,
for example, multi-level meta-regression models with a normally distributed
response variable.

In the context of multi-level meta-regression models with a normally
distributed response variable, the addition of "effectSize-specific"
(="individual-specific") random-effects often account for the variation at
the level of individual estimates of effect size. That is: "effectSize ~ 1
+ (1 | studyID / effectSizeID)" where the data looks like:

studyID      effectSizeID       effectSize
1                   1                        .2
1                   2                        .1
2                   3                        .4
3                   4                        .3
3                   5                        .6
.                    .                          .
.                    .                          .
.                    .                          .

So, I reasoned if  "(1 | studyID / effectSizeID)" is possible in the
context of multi-level meta-regression models with a normally distributed
response variable, then,  "(1 | sch_id / stud_id)" is possible in the
context of multi-level models with a normally distributed response variable
where the data looks like:

sch_id       stud_id             score
1                   1                        9
1                   2                        6
2                   3                        8
3                   4                        5
3                   5                        3
.                    .                          .
.                    .                          .
.                    .                          .
### Is my reasoning flawed here?

As to 2), I can certainly allow the variances in each "sch_id" to be
different. But does this address the correlations among students in each
school, correct?

Many thanks,
Joe




On Fri, Mar 19, 2021 at 2:57 AM David Duffy <
David.Duffy at qimrberghofer.edu.au> wrote:

> Joe wrote:
>
> > I have a cross-sectional (i.e., non-repeated measurements) dataset from
> > students ("stud_id") nested within many schools ("sch_id").
> > 1- Given above, should we possibly add an additional random-effect for
> > "stud_id"? If yes, why?
> > 2- Given above, should we also allow residuals in each school (e_ij) to
> > correlate? If yes, why? (I have a bit of a conceptual problem
> understanding
> > this part given the cross-sectional nature of our study.)
>
> I think this is more a slightly-harder-than-elementary stats question
> rather than a "technical" query. If this was some types of
> GLMM, then the answer to 1 would be yes eg poisson GLMM then an
> individual-specific random effect adds in one type of
> extra-poisson variation. This is not the case for the gaussian (hopefully
> you see why). As to 2, consider how the *variance* of your
> measurement could be different within each school.
>

	[[alternative HTML version deleted]]


From wo||g@ng@v|echtb@uer @end|ng |rom m@@@tr|chtun|ver@|ty@n|  Fri Mar 19 18:46:29 2021
From: wo||g@ng@v|echtb@uer @end|ng |rom m@@@tr|chtun|ver@|ty@n| (Viechtbauer, Wolfgang (SP))
Date: Fri, 19 Mar 2021 17:46:29 +0000
Subject: [R-sig-ME] Adding Level for non-repeated measurements
In-Reply-To: <CADreqiz+6fkzbx+vnxOgJ8hPuqK2Gxq1g7pFa2CwF8+_mtLKFw@mail.gmail.com>
References: <CADreqiz9-2OO1sfENFNyDP-wK9w5LZgcEFVdDVJBMxV23box=A@mail.gmail.com>
 <378e91f7def24ad5adc8e65e143645ad@qimrberghofer.edu.au>
 <CADreqiz+6fkzbx+vnxOgJ8hPuqK2Gxq1g7pFa2CwF8+_mtLKFw@mail.gmail.com>
Message-ID: <499ba028e6904fa0bc6d03d820bb81c1@UM-MAIL3214.unimaas.nl>

Dear Joe,

Meta-analysis is different. In a meta-analysis, the sampling variances (one per estimate) are pre-specified and this allows us to add a random effect corresponding to each estimate to the model. In a multilevel model with a normally distributed response variable, you cannot do this. Well, you can do this, but this random effect is the same as the error term and hence completely confounded.

Best,
Wolfgang

>-----Original Message-----
>From: Tip But [mailto:fswfswt at gmail.com]
>Sent: Friday, 19 March, 2021 18:06
>To: David Duffy
>Cc: r-sig-mixed-models; Viechtbauer, Wolfgang (SP)
>Subject: Re: [R-sig-ME] Adding Level for non-repeated measurements
>
>Dear?David,
>
>Thank you for your response. As my toy example?showed, we do have a normally
>distributed response variable.
>
>As to 1), I have seen (e.g., see variable `id` in:
>https://stat.ethz.ch/pipermail/r-sig-meta-analysis/2018-July/000896.html) that
>what you refer to as "individual-specific" random-effects are used in, for
>example, multi-level meta-regression models with a normally distributed response
>variable.
>
>In the context of multi-level meta-regression models with a normally distributed
>response variable, the addition of "effectSize-specific" (="individual-specific")
>random-effects often account for the variation at the level of individual
>estimates of effect size. That is: "effectSize ~ 1 + (1 | studyID / effectSizeID)"
>where the data looks like:
>
>studyID? ? ? effectSizeID? ? ?? effectSize
>1? ? ? ? ? ? ? ? ? ?1? ? ? ? ? ? ? ? ? ? ? ? .2
>1? ? ? ? ? ? ? ? ? ?2? ? ? ? ? ? ? ? ? ? ? ? .1
>2? ? ? ? ? ? ? ? ? ?3? ? ? ? ? ? ? ? ? ? ? ? .4
>3? ? ? ? ? ? ? ? ? ?4? ? ? ? ? ? ? ? ? ? ? ? .3
>3? ? ? ? ? ? ? ? ? ?5? ? ? ? ? ? ? ? ? ? ? ? .6
>.? ? ? ? ? ? ? ? ? ? .? ? ? ? ? ? ? ? ? ? ? ? ? .
>.? ? ? ? ? ? ? ? ? ? .? ? ? ? ? ? ? ? ? ? ? ? ? .
>.? ? ? ? ? ? ? ? ? ? .? ? ? ? ? ? ? ? ? ? ? ? ? .
>
>So, I reasoned if? "(1 | studyID / effectSizeID)" is possible in the context of
>multi-level meta-regression models with a normally distributed response variable,
>then,? "(1 | sch_id / stud_id)" is possible in the context of multi-level models
>with a normally distributed response variable where the data looks like:
>
>sch_id ? ? ? stud_id? ? ? ? ? ? ?score
>1? ? ? ? ? ? ? ? ? ?1? ? ? ? ? ? ? ? ? ? ? ? 9
>1? ? ? ? ? ? ? ? ? ?2? ? ? ? ? ? ? ? ? ? ? ? 6
>2? ? ? ? ? ? ? ? ? ?3? ? ? ? ? ? ? ? ? ? ? ? 8
>3? ? ? ? ? ? ? ? ? ?4? ? ? ? ? ? ? ? ? ? ? ? 5
>3? ? ? ? ? ? ? ? ? ?5? ? ? ? ? ? ? ? ? ? ? ? 3
>.? ? ? ? ? ? ? ? ? ? .? ? ? ? ? ? ? ? ? ? ? ? ? .
>.? ? ? ? ? ? ? ? ? ? .? ? ? ? ? ? ? ? ? ? ? ? ? .
>.? ? ? ? ? ? ? ? ? ? .? ? ? ? ? ? ? ? ? ? ? ? ? .
>### Is my reasoning?flawed here?
>
>As to 2), I can certainly allow the variances in each "sch_id" to be different.
>But does this address the correlations among students in each school, correct?
>
>Many thanks,
>Joe
>
>On Fri, Mar 19, 2021 at 2:57 AM David Duffy <David.Duffy at qimrberghofer.edu.au>
>wrote:
>Joe wrote:
>
>> I have a cross-sectional (i.e., non-repeated measurements) dataset from
>> students ("stud_id") nested within many schools ("sch_id").
>> 1- Given above, should we possibly add an additional random-effect for
>> "stud_id"? If yes, why?
>> 2- Given above, should we also allow residuals in each school (e_ij) to
>> correlate? If yes, why? (I have a bit of a conceptual problem understanding
>> this part given the cross-sectional nature of our study.)
>
>I think this is more a slightly-harder-than-elementary stats question rather than
>a "technical" query. If this was some types of
>GLMM, then the answer to 1 would be yes eg poisson GLMM then an individual-
>specific random effect adds in one type of
>extra-poisson variation. This is not the case for the gaussian (hopefully you see
>why). As to 2, consider how the *variance* of your
>measurement could be different within each school.

From |@w|@wt @end|ng |rom gm@||@com  Fri Mar 19 19:01:02 2021
From: |@w|@wt @end|ng |rom gm@||@com (Tip But)
Date: Fri, 19 Mar 2021 13:01:02 -0500
Subject: [R-sig-ME] Adding Level for non-repeated measurements
In-Reply-To: <499ba028e6904fa0bc6d03d820bb81c1@UM-MAIL3214.unimaas.nl>
References: <CADreqiz9-2OO1sfENFNyDP-wK9w5LZgcEFVdDVJBMxV23box=A@mail.gmail.com>
 <378e91f7def24ad5adc8e65e143645ad@qimrberghofer.edu.au>
 <CADreqiz+6fkzbx+vnxOgJ8hPuqK2Gxq1g7pFa2CwF8+_mtLKFw@mail.gmail.com>
 <499ba028e6904fa0bc6d03d820bb81c1@UM-MAIL3214.unimaas.nl>
Message-ID: <CADreqizw5etXFjgPVfoxFr0VLkcGLJ+CfTTsEsz4M8wGic2kzQ@mail.gmail.com>

Oh! That clears up my confusion with respect to 1 (Thank you so much)!  Do
you have a link that gets into the details of that?

With respect to 2, I hopefully will receive some insight as to how to
handle the fact that my students in each school have been in frequent
contact via some form of treatment of residuals (my understanding is that
allowing residuals to correlate in a cross-sectional study is not an
option)?

Once again, thank you for your clarification regarding my first question!
Joe

On Fri, Mar 19, 2021 at 12:46 PM Viechtbauer, Wolfgang (SP) <
wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:

> Dear Joe,
>
> Meta-analysis is different. In a meta-analysis, the sampling variances
> (one per estimate) are pre-specified and this allows us to add a random
> effect corresponding to each estimate to the model. In a multilevel model
> with a normally distributed response variable, you cannot do this. Well,
> you can do this, but this random effect is the same as the error term and
> hence completely confounded.
>
> Best,
> Wolfgang
>
> >-----Original Message-----
> >From: Tip But [mailto:fswfswt at gmail.com]
> >Sent: Friday, 19 March, 2021 18:06
> >To: David Duffy
> >Cc: r-sig-mixed-models; Viechtbauer, Wolfgang (SP)
> >Subject: Re: [R-sig-ME] Adding Level for non-repeated measurements
> >
> >Dear David,
> >
> >Thank you for your response. As my toy example showed, we do have a
> normally
> >distributed response variable.
> >
> >As to 1), I have seen (e.g., see variable `id` in:
> >https://stat.ethz.ch/pipermail/r-sig-meta-analysis/2018-July/000896.html)
> that
> >what you refer to as "individual-specific" random-effects are used in, for
> >example, multi-level meta-regression models with a normally distributed
> response
> >variable.
> >
> >In the context of multi-level meta-regression models with a normally
> distributed
> >response variable, the addition of "effectSize-specific"
> (="individual-specific")
> >random-effects often account for the variation at the level of individual
> >estimates of effect size. That is: "effectSize ~ 1 + (1 | studyID /
> effectSizeID)"
> >where the data looks like:
> >
> >studyID      effectSizeID       effectSize
> >1                   1                        .2
> >1                   2                        .1
> >2                   3                        .4
> >3                   4                        .3
> >3                   5                        .6
> >.                    .                          .
> >.                    .                          .
> >.                    .                          .
> >
> >So, I reasoned if  "(1 | studyID / effectSizeID)" is possible in the
> context of
> >multi-level meta-regression models with a normally distributed response
> variable,
> >then,  "(1 | sch_id / stud_id)" is possible in the context of multi-level
> models
> >with a normally distributed response variable where the data looks like:
> >
> >sch_id       stud_id             score
> >1                   1                        9
> >1                   2                        6
> >2                   3                        8
> >3                   4                        5
> >3                   5                        3
> >.                    .                          .
> >.                    .                          .
> >.                    .                          .
> >### Is my reasoning flawed here?
> >
> >As to 2), I can certainly allow the variances in each "sch_id" to be
> different.
> >But does this address the correlations among students in each school,
> correct?
> >
> >Many thanks,
> >Joe
> >
> >On Fri, Mar 19, 2021 at 2:57 AM David Duffy <
> David.Duffy at qimrberghofer.edu.au>
> >wrote:
> >Joe wrote:
> >
> >> I have a cross-sectional (i.e., non-repeated measurements) dataset from
> >> students ("stud_id") nested within many schools ("sch_id").
> >> 1- Given above, should we possibly add an additional random-effect for
> >> "stud_id"? If yes, why?
> >> 2- Given above, should we also allow residuals in each school (e_ij) to
> >> correlate? If yes, why? (I have a bit of a conceptual problem
> understanding
> >> this part given the cross-sectional nature of our study.)
> >
> >I think this is more a slightly-harder-than-elementary stats question
> rather than
> >a "technical" query. If this was some types of
> >GLMM, then the answer to 1 would be yes eg poisson GLMM then an
> individual-
> >specific random effect adds in one type of
> >extra-poisson variation. This is not the case for the gaussian (hopefully
> you see
> >why). As to 2, consider how the *variance* of your
> >measurement could be different within each school.
>

	[[alternative HTML version deleted]]


From wo||g@ng@v|echtb@uer @end|ng |rom m@@@tr|chtun|ver@|ty@n|  Fri Mar 19 20:21:39 2021
From: wo||g@ng@v|echtb@uer @end|ng |rom m@@@tr|chtun|ver@|ty@n| (Viechtbauer, Wolfgang (SP))
Date: Fri, 19 Mar 2021 19:21:39 +0000
Subject: [R-sig-ME] Adding Level for non-repeated measurements
In-Reply-To: <CADreqizw5etXFjgPVfoxFr0VLkcGLJ+CfTTsEsz4M8wGic2kzQ@mail.gmail.com>
References: <CADreqiz9-2OO1sfENFNyDP-wK9w5LZgcEFVdDVJBMxV23box=A@mail.gmail.com>
 <378e91f7def24ad5adc8e65e143645ad@qimrberghofer.edu.au>
 <CADreqiz+6fkzbx+vnxOgJ8hPuqK2Gxq1g7pFa2CwF8+_mtLKFw@mail.gmail.com>
 <499ba028e6904fa0bc6d03d820bb81c1@UM-MAIL3214.unimaas.nl>
 <CADreqizw5etXFjgPVfoxFr0VLkcGLJ+CfTTsEsz4M8wGic2kzQ@mail.gmail.com>
Message-ID: <35db13c5df0b42fca5d89070aa311bc4@UM-MAIL3214.unimaas.nl>

See below.

Best,
Wolfgang

>-----Original Message-----
>From: Tip But [mailto:fswfswt at gmail.com]
>Sent: Friday, 19 March, 2021 19:01
>To: Viechtbauer, Wolfgang (SP)
>Cc: r-sig-mixed-models
>Subject: Re: [R-sig-ME] Adding Level for non-repeated measurements
>
>Oh! That clears up my confusion with?respect to 1 (Thank you so much)!? Do you
>have a link that gets into the details of that?

Sorry, no idea, but it's self-evident once you realize that such a random effect is identical to the error term.

>With respect to 2, I hopefully will receive some insight as to how to handle the
>fact that my students?in each school have been in frequent contact via some form
>of treatment of residuals (my understanding is that allowing residuals to
>correlate in a cross-sectional study is not an option)?

Adding a random effect at the school level in essence already fulfills this purpose. Such a model allows for the observations of pupils from the same school to be correlated (look into the intraclass correlation coefficient).

>Once again, thank you for your clarification regarding my first question!
>Joe
>
>On Fri, Mar 19, 2021 at 12:46 PM Viechtbauer, Wolfgang (SP)
><wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:
>Dear Joe,
>
>Meta-analysis is different. In a meta-analysis, the sampling variances (one per
>estimate) are pre-specified and this allows us to add a random effect
>corresponding to each estimate to the model. In a multilevel model with a normally
>distributed response variable, you cannot do this. Well, you can do this, but this
>random effect is the same as the error term and hence completely confounded.
>
>Best,
>Wolfgang
>
>>-----Original Message-----
>>From: Tip But [mailto:fswfswt at gmail.com]
>>Sent: Friday, 19 March, 2021 18:06
>>To: David Duffy
>>Cc: r-sig-mixed-models; Viechtbauer, Wolfgang (SP)
>>Subject: Re: [R-sig-ME] Adding Level for non-repeated measurements
>>
>>Dear?David,
>>
>>Thank you for your response. As my toy example?showed, we do have a normally
>>distributed response variable.
>>
>>As to 1), I have seen (e.g., see variable `id` in:
>>https://stat.ethz.ch/pipermail/r-sig-meta-analysis/2018-July/000896.html) that
>>what you refer to as "individual-specific" random-effects are used in, for
>>example, multi-level meta-regression models with a normally distributed response
>>variable.
>>
>>In the context of multi-level meta-regression models with a normally distributed
>>response variable, the addition of "effectSize-specific" (="individual-specific")
>>random-effects often account for the variation at the level of individual
>>estimates of effect size. That is: "effectSize ~ 1 + (1 | studyID /
>effectSizeID)"
>>where the data looks like:
>>
>>studyID? ? ? effectSizeID? ? ?? effectSize
>>1? ? ? ? ? ? ? ? ? ?1? ? ? ? ? ? ? ? ? ? ? ? .2
>>1? ? ? ? ? ? ? ? ? ?2? ? ? ? ? ? ? ? ? ? ? ? .1
>>2? ? ? ? ? ? ? ? ? ?3? ? ? ? ? ? ? ? ? ? ? ? .4
>>3? ? ? ? ? ? ? ? ? ?4? ? ? ? ? ? ? ? ? ? ? ? .3
>>3? ? ? ? ? ? ? ? ? ?5? ? ? ? ? ? ? ? ? ? ? ? .6
>>.? ? ? ? ? ? ? ? ? ? .? ? ? ? ? ? ? ? ? ? ? ? ? .
>>.? ? ? ? ? ? ? ? ? ? .? ? ? ? ? ? ? ? ? ? ? ? ? .
>>.? ? ? ? ? ? ? ? ? ? .? ? ? ? ? ? ? ? ? ? ? ? ? .
>>
>>So, I reasoned if? "(1 | studyID / effectSizeID)" is possible in the context of
>>multi-level meta-regression models with a normally distributed response variable,
>>then,? "(1 | sch_id / stud_id)" is possible in the context of multi-level models
>>with a normally distributed response variable where the data looks like:
>>
>>sch_id ? ? ? stud_id? ? ? ? ? ? ?score
>>1? ? ? ? ? ? ? ? ? ?1? ? ? ? ? ? ? ? ? ? ? ? 9
>>1? ? ? ? ? ? ? ? ? ?2? ? ? ? ? ? ? ? ? ? ? ? 6
>>2? ? ? ? ? ? ? ? ? ?3? ? ? ? ? ? ? ? ? ? ? ? 8
>>3? ? ? ? ? ? ? ? ? ?4? ? ? ? ? ? ? ? ? ? ? ? 5
>>3? ? ? ? ? ? ? ? ? ?5? ? ? ? ? ? ? ? ? ? ? ? 3
>>.? ? ? ? ? ? ? ? ? ? .? ? ? ? ? ? ? ? ? ? ? ? ? .
>>.? ? ? ? ? ? ? ? ? ? .? ? ? ? ? ? ? ? ? ? ? ? ? .
>>.? ? ? ? ? ? ? ? ? ? .? ? ? ? ? ? ? ? ? ? ? ? ? .
>>### Is my reasoning?flawed here?
>>
>>As to 2), I can certainly allow the variances in each "sch_id" to be different.
>>But does this address the correlations among students in each school, correct?
>>
>>Many thanks,
>>Joe
>>
>>On Fri, Mar 19, 2021 at 2:57 AM David Duffy <David.Duffy at qimrberghofer.edu.au>
>>wrote:
>>Joe wrote:
>>
>>> I have a cross-sectional (i.e., non-repeated measurements) dataset from
>>> students ("stud_id") nested within many schools ("sch_id").
>>> 1- Given above, should we possibly add an additional random-effect for
>>> "stud_id"? If yes, why?
>>> 2- Given above, should we also allow residuals in each school (e_ij) to
>>> correlate? If yes, why? (I have a bit of a conceptual problem understanding
>>> this part given the cross-sectional nature of our study.)
>>
>>I think this is more a slightly-harder-than-elementary stats question rather than
>>a "technical" query. If this was some types of
>>GLMM, then the answer to 1 would be yes eg poisson GLMM then an individual-
>>specific random effect adds in one type of
>>extra-poisson variation. This is not the case for the gaussian (hopefully you see
>>why). As to 2, consider how the *variance* of your
>>measurement could be different within each school.

From bbo|ker @end|ng |rom gm@||@com  Fri Mar 19 20:29:39 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Fri, 19 Mar 2021 15:29:39 -0400
Subject: [R-sig-ME] Adding Level for non-repeated measurements
In-Reply-To: <35db13c5df0b42fca5d89070aa311bc4@UM-MAIL3214.unimaas.nl>
References: <CADreqiz9-2OO1sfENFNyDP-wK9w5LZgcEFVdDVJBMxV23box=A@mail.gmail.com>
 <378e91f7def24ad5adc8e65e143645ad@qimrberghofer.edu.au>
 <CADreqiz+6fkzbx+vnxOgJ8hPuqK2Gxq1g7pFa2CwF8+_mtLKFw@mail.gmail.com>
 <499ba028e6904fa0bc6d03d820bb81c1@UM-MAIL3214.unimaas.nl>
 <CADreqizw5etXFjgPVfoxFr0VLkcGLJ+CfTTsEsz4M8wGic2kzQ@mail.gmail.com>
 <35db13c5df0b42fca5d89070aa311bc4@UM-MAIL3214.unimaas.nl>
Message-ID: <37c16b01-7f6d-954c-8d47-05b917b0b0e9@gmail.com>



On 3/19/21 3:21 PM, Viechtbauer, Wolfgang (SP) wrote:
> See below.
> 
> Best,
> Wolfgang
> 
>> -----Original Message-----
>> From: Tip But [mailto:fswfswt at gmail.com]
>> Sent: Friday, 19 March, 2021 19:01
>> To: Viechtbauer, Wolfgang (SP)
>> Cc: r-sig-mixed-models
>> Subject: Re: [R-sig-ME] Adding Level for non-repeated measurements
>>
>> Oh! That clears up my confusion with?respect to 1 (Thank you so much)!? Do you
>> have a link that gets into the details of that?
> 
> Sorry, no idea, but it's self-evident once you realize that such a random effect is identical to the error term.

   Not discussed in detail, but an example that mentions it in passing 
is here: https://ms.mcmaster.ca/~bolker/classes/uqam/mixedlab1.html (the 
"starlings" example)

> 
>> With respect to 2, I hopefully will receive some insight as to how to handle the
>> fact that my students?in each school have been in frequent contact via some form
>> of treatment of residuals (my understanding is that allowing residuals to
>> correlate in a cross-sectional study is not an option)?
> 
> Adding a random effect at the school level in essence already fulfills this purpose. Such a model allows for the observations of pupils from the same school to be correlated (look into the intraclass correlation coefficient).
> 
>> Once again, thank you for your clarification regarding my first question!
>> Joe
>>
>> On Fri, Mar 19, 2021 at 12:46 PM Viechtbauer, Wolfgang (SP)
>> <wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:
>> Dear Joe,
>>
>> Meta-analysis is different. In a meta-analysis, the sampling variances (one per
>> estimate) are pre-specified and this allows us to add a random effect
>> corresponding to each estimate to the model. In a multilevel model with a normally
>> distributed response variable, you cannot do this. Well, you can do this, but this
>> random effect is the same as the error term and hence completely confounded.
>>
>> Best,
>> Wolfgang
>>
>>> -----Original Message-----
>>> From: Tip But [mailto:fswfswt at gmail.com]
>>> Sent: Friday, 19 March, 2021 18:06
>>> To: David Duffy
>>> Cc: r-sig-mixed-models; Viechtbauer, Wolfgang (SP)
>>> Subject: Re: [R-sig-ME] Adding Level for non-repeated measurements
>>>
>>> Dear?David,
>>>
>>> Thank you for your response. As my toy example?showed, we do have a normally
>>> distributed response variable.
>>>
>>> As to 1), I have seen (e.g., see variable `id` in:
>>> https://stat.ethz.ch/pipermail/r-sig-meta-analysis/2018-July/000896.html) that
>>> what you refer to as "individual-specific" random-effects are used in, for
>>> example, multi-level meta-regression models with a normally distributed response
>>> variable.
>>>
>>> In the context of multi-level meta-regression models with a normally distributed
>>> response variable, the addition of "effectSize-specific" (="individual-specific")
>>> random-effects often account for the variation at the level of individual
>>> estimates of effect size. That is: "effectSize ~ 1 + (1 | studyID /
>> effectSizeID)"
>>> where the data looks like:
>>>
>>> studyID? ? ? effectSizeID? ? ?? effectSize
>>> 1? ? ? ? ? ? ? ? ? ?1? ? ? ? ? ? ? ? ? ? ? ? .2
>>> 1? ? ? ? ? ? ? ? ? ?2? ? ? ? ? ? ? ? ? ? ? ? .1
>>> 2? ? ? ? ? ? ? ? ? ?3? ? ? ? ? ? ? ? ? ? ? ? .4
>>> 3? ? ? ? ? ? ? ? ? ?4? ? ? ? ? ? ? ? ? ? ? ? .3
>>> 3? ? ? ? ? ? ? ? ? ?5? ? ? ? ? ? ? ? ? ? ? ? .6
>>> .? ? ? ? ? ? ? ? ? ? .? ? ? ? ? ? ? ? ? ? ? ? ? .
>>> .? ? ? ? ? ? ? ? ? ? .? ? ? ? ? ? ? ? ? ? ? ? ? .
>>> .? ? ? ? ? ? ? ? ? ? .? ? ? ? ? ? ? ? ? ? ? ? ? .
>>>
>>> So, I reasoned if? "(1 | studyID / effectSizeID)" is possible in the context of
>>> multi-level meta-regression models with a normally distributed response variable,
>>> then,? "(1 | sch_id / stud_id)" is possible in the context of multi-level models
>>> with a normally distributed response variable where the data looks like:
>>>
>>> sch_id ? ? ? stud_id? ? ? ? ? ? ?score
>>> 1? ? ? ? ? ? ? ? ? ?1? ? ? ? ? ? ? ? ? ? ? ? 9
>>> 1? ? ? ? ? ? ? ? ? ?2? ? ? ? ? ? ? ? ? ? ? ? 6
>>> 2? ? ? ? ? ? ? ? ? ?3? ? ? ? ? ? ? ? ? ? ? ? 8
>>> 3? ? ? ? ? ? ? ? ? ?4? ? ? ? ? ? ? ? ? ? ? ? 5
>>> 3? ? ? ? ? ? ? ? ? ?5? ? ? ? ? ? ? ? ? ? ? ? 3
>>> .? ? ? ? ? ? ? ? ? ? .? ? ? ? ? ? ? ? ? ? ? ? ? .
>>> .? ? ? ? ? ? ? ? ? ? .? ? ? ? ? ? ? ? ? ? ? ? ? .
>>> .? ? ? ? ? ? ? ? ? ? .? ? ? ? ? ? ? ? ? ? ? ? ? .
>>> ### Is my reasoning?flawed here?
>>>
>>> As to 2), I can certainly allow the variances in each "sch_id" to be different.
>>> But does this address the correlations among students in each school, correct?
>>>
>>> Many thanks,
>>> Joe
>>>
>>> On Fri, Mar 19, 2021 at 2:57 AM David Duffy <David.Duffy at qimrberghofer.edu.au>
>>> wrote:
>>> Joe wrote:
>>>
>>>> I have a cross-sectional (i.e., non-repeated measurements) dataset from
>>>> students ("stud_id") nested within many schools ("sch_id").
>>>> 1- Given above, should we possibly add an additional random-effect for
>>>> "stud_id"? If yes, why?
>>>> 2- Given above, should we also allow residuals in each school (e_ij) to
>>>> correlate? If yes, why? (I have a bit of a conceptual problem understanding
>>>> this part given the cross-sectional nature of our study.)
>>>
>>> I think this is more a slightly-harder-than-elementary stats question rather than
>>> a "technical" query. If this was some types of
>>> GLMM, then the answer to 1 would be yes eg poisson GLMM then an individual-
>>> specific random effect adds in one type of
>>> extra-poisson variation. This is not the case for the gaussian (hopefully you see
>>> why). As to 2, consider how the *variance* of your
>>> measurement could be different within each school.
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From |@w|@wt @end|ng |rom gm@||@com  Fri Mar 19 20:45:03 2021
From: |@w|@wt @end|ng |rom gm@||@com (Tip But)
Date: Fri, 19 Mar 2021 14:45:03 -0500
Subject: [R-sig-ME] Adding Level for non-repeated measurements
In-Reply-To: <35db13c5df0b42fca5d89070aa311bc4@UM-MAIL3214.unimaas.nl>
References: <CADreqiz9-2OO1sfENFNyDP-wK9w5LZgcEFVdDVJBMxV23box=A@mail.gmail.com>
 <378e91f7def24ad5adc8e65e143645ad@qimrberghofer.edu.au>
 <CADreqiz+6fkzbx+vnxOgJ8hPuqK2Gxq1g7pFa2CwF8+_mtLKFw@mail.gmail.com>
 <499ba028e6904fa0bc6d03d820bb81c1@UM-MAIL3214.unimaas.nl>
 <CADreqizw5etXFjgPVfoxFr0VLkcGLJ+CfTTsEsz4M8wGic2kzQ@mail.gmail.com>
 <35db13c5df0b42fca5d89070aa311bc4@UM-MAIL3214.unimaas.nl>
Message-ID: <CADreqiz6gpEzJZjpWq7Ck8u3dKHm2czcennz79X-FnFXzSb_ww@mail.gmail.com>

Dear Wolfgang,

Thanks, I meant a link that gets into the details of how taking the
sampling variances of effect sizes as known, allows to then add an
additional random-effect for the individual effect sizes themselves in
meta-regression? (which ordinary multilevel models can't do as I assume
scores can't come with their uncertainties).

On Fri, Mar 19, 2021 at 2:21 PM Viechtbauer, Wolfgang (SP) <
wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:

> See below.
>
> Best,
> Wolfgang
>
> >-----Original Message-----
> >From: Tip But [mailto:fswfswt at gmail.com]
> >Sent: Friday, 19 March, 2021 19:01
> >To: Viechtbauer, Wolfgang (SP)
> >Cc: r-sig-mixed-models
> >Subject: Re: [R-sig-ME] Adding Level for non-repeated measurements
> >
> >Oh! That clears up my confusion with respect to 1 (Thank you so much)!
> Do you
> >have a link that gets into the details of that?
>
> Sorry, no idea, but it's self-evident once you realize that such a random
> effect is identical to the error term.
>
> >With respect to 2, I hopefully will receive some insight as to how to
> handle the
> >fact that my students in each school have been in frequent contact via
> some form
> >of treatment of residuals (my understanding is that allowing residuals to
> >correlate in a cross-sectional study is not an option)?
>
> Adding a random effect at the school level in essence already fulfills
> this purpose. Such a model allows for the observations of pupils from the
> same school to be correlated (look into the intraclass correlation
> coefficient).
>
> >Once again, thank you for your clarification regarding my first question!
> >Joe
> >
> >On Fri, Mar 19, 2021 at 12:46 PM Viechtbauer, Wolfgang (SP)
> ><wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:
> >Dear Joe,
> >
> >Meta-analysis is different. In a meta-analysis, the sampling variances
> (one per
> >estimate) are pre-specified and this allows us to add a random effect
> >corresponding to each estimate to the model. In a multilevel model with a
> normally
> >distributed response variable, you cannot do this. Well, you can do this,
> but this
> >random effect is the same as the error term and hence completely
> confounded.
> >
> >Best,
> >Wolfgang
> >
> >>-----Original Message-----
> >>From: Tip But [mailto:fswfswt at gmail.com]
> >>Sent: Friday, 19 March, 2021 18:06
> >>To: David Duffy
> >>Cc: r-sig-mixed-models; Viechtbauer, Wolfgang (SP)
> >>Subject: Re: [R-sig-ME] Adding Level for non-repeated measurements
> >>
> >>Dear David,
> >>
> >>Thank you for your response. As my toy example showed, we do have a
> normally
> >>distributed response variable.
> >>
> >>As to 1), I have seen (e.g., see variable `id` in:
> >>https://stat.ethz.ch/pipermail/r-sig-meta-analysis/2018-July/000896.html)
> that
> >>what you refer to as "individual-specific" random-effects are used in,
> for
> >>example, multi-level meta-regression models with a normally distributed
> response
> >>variable.
> >>
> >>In the context of multi-level meta-regression models with a normally
> distributed
> >>response variable, the addition of "effectSize-specific"
> (="individual-specific")
> >>random-effects often account for the variation at the level of individual
> >>estimates of effect size. That is: "effectSize ~ 1 + (1 | studyID /
> >effectSizeID)"
> >>where the data looks like:
> >>
> >>studyID      effectSizeID       effectSize
> >>1                   1                        .2
> >>1                   2                        .1
> >>2                   3                        .4
> >>3                   4                        .3
> >>3                   5                        .6
> >>.                    .                          .
> >>.                    .                          .
> >>.                    .                          .
> >>
> >>So, I reasoned if  "(1 | studyID / effectSizeID)" is possible in the
> context of
> >>multi-level meta-regression models with a normally distributed response
> variable,
> >>then,  "(1 | sch_id / stud_id)" is possible in the context of
> multi-level models
> >>with a normally distributed response variable where the data looks like:
> >>
> >>sch_id       stud_id             score
> >>1                   1                        9
> >>1                   2                        6
> >>2                   3                        8
> >>3                   4                        5
> >>3                   5                        3
> >>.                    .                          .
> >>.                    .                          .
> >>.                    .                          .
> >>### Is my reasoning flawed here?
> >>
> >>As to 2), I can certainly allow the variances in each "sch_id" to be
> different.
> >>But does this address the correlations among students in each school,
> correct?
> >>
> >>Many thanks,
> >>Joe
> >>
> >>On Fri, Mar 19, 2021 at 2:57 AM David Duffy <
> David.Duffy at qimrberghofer.edu.au>
> >>wrote:
> >>Joe wrote:
> >>
> >>> I have a cross-sectional (i.e., non-repeated measurements) dataset from
> >>> students ("stud_id") nested within many schools ("sch_id").
> >>> 1- Given above, should we possibly add an additional random-effect for
> >>> "stud_id"? If yes, why?
> >>> 2- Given above, should we also allow residuals in each school (e_ij) to
> >>> correlate? If yes, why? (I have a bit of a conceptual problem
> understanding
> >>> this part given the cross-sectional nature of our study.)
> >>
> >>I think this is more a slightly-harder-than-elementary stats question
> rather than
> >>a "technical" query. If this was some types of
> >>GLMM, then the answer to 1 would be yes eg poisson GLMM then an
> individual-
> >>specific random effect adds in one type of
> >>extra-poisson variation. This is not the case for the gaussian
> (hopefully you see
> >>why). As to 2, consider how the *variance* of your
> >>measurement could be different within each school.
>

	[[alternative HTML version deleted]]


From |@w|@wt @end|ng |rom gm@||@com  Fri Mar 19 20:56:25 2021
From: |@w|@wt @end|ng |rom gm@||@com (Tip But)
Date: Fri, 19 Mar 2021 14:56:25 -0500
Subject: [R-sig-ME] Adding Level for non-repeated measurements
In-Reply-To: <37c16b01-7f6d-954c-8d47-05b917b0b0e9@gmail.com>
References: <CADreqiz9-2OO1sfENFNyDP-wK9w5LZgcEFVdDVJBMxV23box=A@mail.gmail.com>
 <378e91f7def24ad5adc8e65e143645ad@qimrberghofer.edu.au>
 <CADreqiz+6fkzbx+vnxOgJ8hPuqK2Gxq1g7pFa2CwF8+_mtLKFw@mail.gmail.com>
 <499ba028e6904fa0bc6d03d820bb81c1@UM-MAIL3214.unimaas.nl>
 <CADreqizw5etXFjgPVfoxFr0VLkcGLJ+CfTTsEsz4M8wGic2kzQ@mail.gmail.com>
 <35db13c5df0b42fca5d89070aa311bc4@UM-MAIL3214.unimaas.nl>
 <37c16b01-7f6d-954c-8d47-05b917b0b0e9@gmail.com>
Message-ID: <CADreqiwzbV1ZY8UUX0EYG6nhn4fQ9iYsm7pvXaLf1Y8hNLYEPQ@mail.gmail.com>

Thank you, Ben. The situation in your linked example is a bit different. In
your example, adding the random slope seems to be an overfit (as the
number of repeated measurements is limited) otherwise
theoretically possible.

But in my case, it seems adding a level is not theoretically possible. So,
there certainly is a gap in my knowledge resulting from a carryover from
mixed meta-regression models where we actually can have an
individual-specific random effects with the exact same data structure.

Thanks,

## data structure in mixed meta-regression:
studyID      effectSizeID       effectSize
1                   1                        .2
1                   2                        .1
2                   3                        .4
3                   4                        .3
3                   5                        .6
.                    .                          .
.                    .                          .
.                    .                          .
## data structure in ordinary mixed-models:
sch_id       stud_id             score
1                   1                        9
1                   2                        6
2                   3                        8
3                   4                        5
3                   5                        3
.                    .                          .
.                    .                          .
.                    .                          .

On Fri, Mar 19, 2021 at 2:32 PM Ben Bolker <bbolker at gmail.com> wrote:

>
>
> On 3/19/21 3:21 PM, Viechtbauer, Wolfgang (SP) wrote:
> > See below.
> >
> > Best,
> > Wolfgang
> >
> >> -----Original Message-----
> >> From: Tip But [mailto:fswfswt at gmail.com]
> >> Sent: Friday, 19 March, 2021 19:01
> >> To: Viechtbauer, Wolfgang (SP)
> >> Cc: r-sig-mixed-models
> >> Subject: Re: [R-sig-ME] Adding Level for non-repeated measurements
> >>
> >> Oh! That clears up my confusion with respect to 1 (Thank you so much)!
> Do you
> >> have a link that gets into the details of that?
> >
> > Sorry, no idea, but it's self-evident once you realize that such a
> random effect is identical to the error term.
>
>    Not discussed in detail, but an example that mentions it in passing
> is here: https://ms.mcmaster.ca/~bolker/classes/uqam/mixedlab1.html (the
> "starlings" example)
>
> >
> >> With respect to 2, I hopefully will receive some insight as to how to
> handle the
> >> fact that my students in each school have been in frequent contact via
> some form
> >> of treatment of residuals (my understanding is that allowing residuals
> to
> >> correlate in a cross-sectional study is not an option)?
> >
> > Adding a random effect at the school level in essence already fulfills
> this purpose. Such a model allows for the observations of pupils from the
> same school to be correlated (look into the intraclass correlation
> coefficient).
> >
> >> Once again, thank you for your clarification regarding my first
> question!
> >> Joe
> >>
> >> On Fri, Mar 19, 2021 at 12:46 PM Viechtbauer, Wolfgang (SP)
> >> <wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:
> >> Dear Joe,
> >>
> >> Meta-analysis is different. In a meta-analysis, the sampling variances
> (one per
> >> estimate) are pre-specified and this allows us to add a random effect
> >> corresponding to each estimate to the model. In a multilevel model with
> a normally
> >> distributed response variable, you cannot do this. Well, you can do
> this, but this
> >> random effect is the same as the error term and hence completely
> confounded.
> >>
> >> Best,
> >> Wolfgang
> >>
> >>> -----Original Message-----
> >>> From: Tip But [mailto:fswfswt at gmail.com]
> >>> Sent: Friday, 19 March, 2021 18:06
> >>> To: David Duffy
> >>> Cc: r-sig-mixed-models; Viechtbauer, Wolfgang (SP)
> >>> Subject: Re: [R-sig-ME] Adding Level for non-repeated measurements
> >>>
> >>> Dear David,
> >>>
> >>> Thank you for your response. As my toy example showed, we do have a
> normally
> >>> distributed response variable.
> >>>
> >>> As to 1), I have seen (e.g., see variable `id` in:
> >>>
> https://stat.ethz.ch/pipermail/r-sig-meta-analysis/2018-July/000896.html)
> that
> >>> what you refer to as "individual-specific" random-effects are used in,
> for
> >>> example, multi-level meta-regression models with a normally
> distributed response
> >>> variable.
> >>>
> >>> In the context of multi-level meta-regression models with a normally
> distributed
> >>> response variable, the addition of "effectSize-specific"
> (="individual-specific")
> >>> random-effects often account for the variation at the level of
> individual
> >>> estimates of effect size. That is: "effectSize ~ 1 + (1 | studyID /
> >> effectSizeID)"
> >>> where the data looks like:
> >>>
> >>> studyID      effectSizeID       effectSize
> >>> 1                   1                        .2
> >>> 1                   2                        .1
> >>> 2                   3                        .4
> >>> 3                   4                        .3
> >>> 3                   5                        .6
> >>> .                    .                          .
> >>> .                    .                          .
> >>> .                    .                          .
> >>>
> >>> So, I reasoned if  "(1 | studyID / effectSizeID)" is possible in the
> context of
> >>> multi-level meta-regression models with a normally distributed
> response variable,
> >>> then,  "(1 | sch_id / stud_id)" is possible in the context of
> multi-level models
> >>> with a normally distributed response variable where the data looks
> like:
> >>>
> >>> sch_id       stud_id             score
> >>> 1                   1                        9
> >>> 1                   2                        6
> >>> 2                   3                        8
> >>> 3                   4                        5
> >>> 3                   5                        3
> >>> .                    .                          .
> >>> .                    .                          .
> >>> .                    .                          .
> >>> ### Is my reasoning flawed here?
> >>>
> >>> As to 2), I can certainly allow the variances in each "sch_id" to be
> different.
> >>> But does this address the correlations among students in each school,
> correct?
> >>>
> >>> Many thanks,
> >>> Joe
> >>>
> >>> On Fri, Mar 19, 2021 at 2:57 AM David Duffy <
> David.Duffy at qimrberghofer.edu.au>
> >>> wrote:
> >>> Joe wrote:
> >>>
> >>>> I have a cross-sectional (i.e., non-repeated measurements) dataset
> from
> >>>> students ("stud_id") nested within many schools ("sch_id").
> >>>> 1- Given above, should we possibly add an additional random-effect for
> >>>> "stud_id"? If yes, why?
> >>>> 2- Given above, should we also allow residuals in each school (e_ij)
> to
> >>>> correlate? If yes, why? (I have a bit of a conceptual problem
> understanding
> >>>> this part given the cross-sectional nature of our study.)
> >>>
> >>> I think this is more a slightly-harder-than-elementary stats question
> rather than
> >>> a "technical" query. If this was some types of
> >>> GLMM, then the answer to 1 would be yes eg poisson GLMM then an
> individual-
> >>> specific random effect adds in one type of
> >>> extra-poisson variation. This is not the case for the gaussian
> (hopefully you see
> >>> why). As to 2, consider how the *variance* of your
> >>> measurement could be different within each school.
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From v|tor@v@v @end|ng |rom gm@||@com  Sun Mar 21 17:11:49 2021
From: v|tor@v@v @end|ng |rom gm@||@com (Vitor Vieira Vasconcelos)
Date: Sun, 21 Mar 2021 12:11:49 -0400
Subject: [R-sig-ME] Marginal effects plots with interactions of glmm model
 averaging
Message-ID: <CANAwtjv13PA0DYpwYSs7CoB_LxLtov3ta46jMdkYhu=U0=Xqug@mail.gmail.com>

Good morning!

    I was guessing if it would be possible to make marginal effects plots
with interaction terms (two way, three way, etc.) of model averaging
results of glmm, similar to interaction plots of a single glmm, such as in
the ggeffects, effects and sjPlot packages. I saw in the interplot package
that it would be possible to make these "ad hoc" effect plots if we provide
a dataframe with four columns: the scale of the conditioning variable, the
simulated interactive effect at each break of the conditioning variable,
and the simulated lower bound and upper bound of the confidence interval.
However, I am not sure about how could I calculate these values for a model
averaging. Right now I am using Mumin package for the model averaging of
glmm.
   I would be very grateful if anyone here could provide comments if this
approach would be possible or advisable, or if you happen to have an idea
about how to operationalize it.

Best regards,Vitor

	[[alternative HTML version deleted]]


From kj@j@o|omon @end|ng |rom gm@||@com  Mon Mar 22 00:10:15 2021
From: kj@j@o|omon @end|ng |rom gm@||@com (Jack Solomon)
Date: Sun, 21 Mar 2021 18:10:15 -0500
Subject: [R-sig-ME] A newbie: When to allow residuals to correlate?
Message-ID: <CA+sL+8Us5a2_YzpTJZmh-=0a3hB03RA7zoZTQt5o+BTRM=Tw6Q@mail.gmail.com>

Hello List Members,

I apologize in advance for the simplicity of my question. But I'm
struggling to understand the following in plain English:

What is the difference between the correlation among the random-effects and
the correlation among the residuals (i.e., lowest level errors within each
level of a grouping variable perhaps with respect to 'time')?

What type of correlation (dependency) in data is accounted for by
correlating the random-effects, and what type of correlation in data is
accounted for by correlating the residuals?

Here are two conceptual models to contextualize this discussion:

#== Correlation among random-effects (intercepts & time slopes) only:
nlme::lme(y ~ gender*time, random = ~ time | ID, data = data)

#== Correlation among random-effects + Unstructured correlation among
residuals:
nlme::lme(y ~ gender*time, random = ~ time | ID, data = data, correlation =
corSymm(form = ~ 1 | ID))

Many thanks for your consideration of my basic question,
Jack Solomon

	[[alternative HTML version deleted]]


From kj@j@o|omon @end|ng |rom gm@||@com  Mon Mar 22 00:13:32 2021
From: kj@j@o|omon @end|ng |rom gm@||@com (Jack Solomon)
Date: Sun, 21 Mar 2021 18:13:32 -0500
Subject: [R-sig-ME] A newbie: When to allow residuals to correlate?
In-Reply-To: <CA+sL+8Us5a2_YzpTJZmh-=0a3hB03RA7zoZTQt5o+BTRM=Tw6Q@mail.gmail.com>
References: <CA+sL+8Us5a2_YzpTJZmh-=0a3hB03RA7zoZTQt5o+BTRM=Tw6Q@mail.gmail.com>
Message-ID: <CA+sL+8VbbvLha0=hVcTc5bwCeNTSKpTAjWxNS1CMmopRXW6fVg@mail.gmail.com>

ps. To be clear, I understand that lowest level errors within each level of
a grouping variable with respect to 'time' are correlated due to repeated
measurements. But what I don't understand is why correlating random-effects
alone can't account for such correlation.

On Sun, Mar 21, 2021 at 6:10 PM Jack Solomon <kj.jsolomon at gmail.com> wrote:

> Hello List Members,
>
> I apologize in advance for the simplicity of my question. But I'm
> struggling to understand the following in plain English:
>
> What is the difference between the correlation among the random-effects
> and the correlation among the residuals (i.e., lowest level errors within
> each level of a grouping variable perhaps with respect to 'time')?
>
> What type of correlation (dependency) in data is accounted for by
> correlating the random-effects, and what type of correlation in data is
> accounted for by correlating the residuals?
>
> Here are two conceptual models to contextualize this discussion:
>
> #== Correlation among random-effects (intercepts & time slopes) only:
> nlme::lme(y ~ gender*time, random = ~ time | ID, data = data)
>
> #== Correlation among random-effects + Unstructured correlation among
> residuals:
> nlme::lme(y ~ gender*time, random = ~ time | ID, data = data, correlation
> = corSymm(form = ~ 1 | ID))
>
> Many thanks for your consideration of my basic question,
> Jack Solomon
>

	[[alternative HTML version deleted]]


From D@v|d@Du||y @end|ng |rom q|mrbergho|er@edu@@u  Mon Mar 22 06:15:09 2021
From: D@v|d@Du||y @end|ng |rom q|mrbergho|er@edu@@u (David Duffy)
Date: Mon, 22 Mar 2021 05:15:09 +0000
Subject: [R-sig-ME] Adding Level for non-repeated measurements
In-Reply-To: <CADreqiwzbV1ZY8UUX0EYG6nhn4fQ9iYsm7pvXaLf1Y8hNLYEPQ@mail.gmail.com>
References: <CADreqiz9-2OO1sfENFNyDP-wK9w5LZgcEFVdDVJBMxV23box=A@mail.gmail.com>
 <378e91f7def24ad5adc8e65e143645ad@qimrberghofer.edu.au>
 <CADreqiz+6fkzbx+vnxOgJ8hPuqK2Gxq1g7pFa2CwF8+_mtLKFw@mail.gmail.com>
 <499ba028e6904fa0bc6d03d820bb81c1@UM-MAIL3214.unimaas.nl>
 <CADreqizw5etXFjgPVfoxFr0VLkcGLJ+CfTTsEsz4M8wGic2kzQ@mail.gmail.com>
 <35db13c5df0b42fca5d89070aa311bc4@UM-MAIL3214.unimaas.nl>
 <37c16b01-7f6d-954c-8d47-05b917b0b0e9@gmail.com>,
 <CADreqiwzbV1ZY8UUX0EYG6nhn4fQ9iYsm7pvXaLf1Y8hNLYEPQ@mail.gmail.com>
Message-ID: <afc86ee4add64e38a428e05ca087f3ee@qimrberghofer.edu.au>

> But in my case, it seems adding a level is not theoretically possible. So,
> there certainly is a gap in my knowledge resulting from a carryover from
> mixed meta-regression models where we actually can have an
> individual-specific random effects with the exact same data structure.

A meta-regression is not that different from your setup, where schools replace studies,  which is where the meta-analysis 
variances are coming from (they are summary statistics which you estimate yourself if you have the study datasets).

Instead of correlated residuals, consider an interaction model, where the phenotype of student 1 is a cause of that in student 2 (recursively, rather than ordinary AR). This leads to increased (or decreased) within-school variance depending on the sign of the interaction, which you can 
detect by comparison to groups where you assume the interaction is zero. Such models are also relevant when there is rating contagion (student 1 is compared by the rater to peers). This could be in addition to the school effect, which is like a single factor with equal loadings for each pupil (there are path diagrams for all these different possible models, which may not make clear what data you need to make them estimable/identified). 

HTH, David Duffy.


From @b@rro@|b @end|ng |rom gm@||@com  Mon Mar 22 15:48:07 2021
From: @b@rro@|b @end|ng |rom gm@||@com (=?UTF-8?Q?Abra=C3=A3o_de_Barros_Leite?=)
Date: Mon, 22 Mar 2021 11:48:07 -0300
Subject: [R-sig-ME] effective sample size in MCMCglmm
Message-ID: <CAAQsOWWEjdHoCKTuTrW5h-dPj2yCe19jD9gG6WtjcEYRWQGp9w@mail.gmail.com>

Hello Mathew
 My name is Abra?o, I saw your answer aboute MCMCGLMM sample size.
So, please can you help me?
I am working with relation between brain mass and nest birds in my
doctorate.
My dataset has 250 species, but in my analysis MCMCGLMM with phylogenetic
control, I haven't convergence, with nitt=2000000, thin=3500, burnin=4000.
Please, can you help me?
How I can to improve my convergence?
Sample size=100 in the end it's ok?
Thanks!

	[[alternative HTML version deleted]]


From w@||dm@w@@@10 @end|ng |rom gm@||@com  Mon Mar 22 18:30:26 2021
From: w@||dm@w@@@10 @end|ng |rom gm@||@com (Walid Crampton-Mawass)
Date: Mon, 22 Mar 2021 13:30:26 -0400
Subject: [R-sig-ME] effective sample size in MCMCglmm
In-Reply-To: <CAAQsOWWEjdHoCKTuTrW5h-dPj2yCe19jD9gG6WtjcEYRWQGp9w@mail.gmail.com>
References: <CAAQsOWWEjdHoCKTuTrW5h-dPj2yCe19jD9gG6WtjcEYRWQGp9w@mail.gmail.com>
Message-ID: <CAJtCY7VqtxZTebupAWdDCU+3eC=QzsPHioHCrSn6wsUqvTHMtg@mail.gmail.com>

Hello,

One way to improve the convergence of your phylogenetic model would be to
increase the burn in iterations of the chain and take it into account in
your total number of iterations. So in your case, I would set nitt=2500000,
burnin= 500000 and nitt=2000, that way you would have a sample of 1000
iterations saved from the total chain iterations (of course you can
increase the thin interval based on the sample size of saved iterations you
want).

Good luck
-- 
Walid Crampton-Mawass
Ph.D. candidate in Evolutionary Biology
Population Genetics Laboratory
University of Qu?bec at Trois-Rivi?res
3351, boul. des Forges, C.P. 500
Trois-Rivi?res (Qu?bec) G9A 5H7
Telephone: 819-376-5011 poste 3384


On Mon, Mar 22, 2021 at 11:24 AM Abra?o de Barros Leite <abarrosib at gmail.com>
wrote:

> Hello Mathew
>  My name is Abra?o, I saw your answer aboute MCMCGLMM sample size.
> So, please can you help me?
> I am working with relation between brain mass and nest birds in my
> doctorate.
> My dataset has 250 species, but in my analysis MCMCGLMM with phylogenetic
> control, I haven't convergence, with nitt=2000000, thin=3500, burnin=4000.
> Please, can you help me?
> How I can to improve my convergence?
> Sample size=100 in the end it's ok?
> Thanks!
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>

	[[alternative HTML version deleted]]


From @b@rro@|b @end|ng |rom gm@||@com  Mon Mar 22 20:09:38 2021
From: @b@rro@|b @end|ng |rom gm@||@com (=?UTF-8?Q?Abra=C3=A3o_de_Barros_Leite?=)
Date: Mon, 22 Mar 2021 16:09:38 -0300
Subject: [R-sig-ME] effective sample size in MCMCglmm
In-Reply-To: <CAJtCY7WiHX1SuWF8EHQz_Oh7Vc3EDA=bsKpMYTScDWhwXfbz7g@mail.gmail.com>
References: <CAAQsOWWEjdHoCKTuTrW5h-dPj2yCe19jD9gG6WtjcEYRWQGp9w@mail.gmail.com>
 <CAJtCY7VqtxZTebupAWdDCU+3eC=QzsPHioHCrSn6wsUqvTHMtg@mail.gmail.com>
 <CAAQsOWWMWMGx8_mbx2FUj3AfOFOOpujUBuCAF8xw4-Pfwx_j=g@mail.gmail.com>
 <CAJtCY7WiHX1SuWF8EHQz_Oh7Vc3EDA=bsKpMYTScDWhwXfbz7g@mail.gmail.com>
Message-ID: <CAAQsOWWxdB_uo8+Rz8JjmxMkhaKAUZe-jEdo+jFr7OTo5OmKFg@mail.gmail.com>

Hello,  this is my script, and my dataset has 235 species.

prior3.1 <- list(G = list(G1 = list(nu=0.002, V=1),G2 = list(nu=0.002,
V=1)),#fatores de vari?ncias a priori#
                 R = list( V=1,nu=0.002, fix=1))
m1<-MCMCglmm(progofic~1+Dieta+trafic+log(massakg)+endg,data=databird,
family="categorical",pedigree=contree,random=~animal+measureID,verbose = F,
         nitt=2500000,burnin=250000,thin=10000,prior =prior3.1)
summary(m1)
acf(m1$Sol[,1],lag.max =100)

*Results:*
  Iterations = 250001:2490001
 Thinning interval  = 10000
 Sample size  = 225

 DIC: 6.619977

 G-structure:  ~animal

       post.mean l-95% CI u-95% CI eff.samp
animal      7713    999.2    15303    10.58

               ~measureID

          post.mean  l-95% CI u-95% CI eff.samp
measureID     319.5 0.0005769     1505    81.04

 R-structure:  ~units

      post.mean l-95% CI u-95% CI eff.samp
units         1        1        1        0

 Location effects: progofic ~ 1 + Dieta + trafic + log(massakg) + endg

                   post.mean l-95% CI u-95% CI eff.samp  pMCMC
(Intercept)          -32.757 -127.914   59.857  152.759 0.4889
DietaInvertebrate    -73.571 -153.500   -4.571    9.841 0.0356 *
DietaNectarivorous  -156.649 -527.852  191.174    4.441 0.6489
DietaOmnivore         -6.580  -43.869   33.693   83.293 0.7644
DietaVert            -13.890  -87.780   73.738   62.163 0.8000
traficyes             -1.761  -30.506   31.131  102.410 0.8711
log(massakg)          25.917    6.443   43.469   18.590 <0.004 **
endgEN                -3.139  -42.611   37.907   25.394 0.8889
endgVU               -35.510  -73.109    1.471   24.992 0.0444 *
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> acf(m1$Sol[,1],lag.max =100)
> autocorr(m1$VCV)
,* , animal*
               animal    measureID units
Lag 0      1.00000000 -0.022820572   NaN
Lag 10000  0.80567811 -0.045602281   NaN
Lag 50000  0.58800623  0.037466483   NaN
Lag 1e+05  0.37539889  0.221289380   NaN
Lag 5e+05 -0.08870539 -0.005622699   NaN
,* , measureID*
                animal    measureID units
Lag 0     -0.022820572  1.000000000   NaN
Lag 10000 -0.004848064  0.369835208   NaN
Lag 50000 -0.052249906  0.006497318   NaN
Lag 1e+05 -0.053667796 -0.001787120   NaN
Lag 5e+05 -0.015126358 -0.027780522   NaN
,* , units*
          animal measureID units
Lag 0        NaN       NaN   NaN
Lag 10000    NaN       NaN   NaN
Lag 50000    NaN       NaN   NaN
Lag 1e+05    NaN       NaN   NaN
Lag 5e+05    NaN       NaN   NaN

Thanks,
Abra?o
On Mon, Mar 22, 2021 at 3:32 PM Walid Crampton-Mawass <
walidmawass10 at gmail.com> wrote:

> Yes possibly, or the sample size is too small for the model structure you
> are attempting. It would help if you share your model structure and results
> of autocorr() to check if autocorrelation between chain iterations is high.
>
> Additionally, when replying in this thread, use the reply all option so
> our thread and discussion is included in the r-sig archives.
> --
> Walid Crampton-Mawass
> Ph.D. candidate in Evolutionary Biology
> Population Genetics Laboratory
> University of Qu?bec at Trois-Rivi?res
> 3351, boul. des Forges, C.P. 500
> Trois-Rivi?res (Qu?bec) G9A 5H7
> Telephone: 819-376-5011 poste 3384
>
>
> On Mon, Mar 22, 2021 at 2:14 PM Abra?o de Barros Leite <
> abarrosib at gmail.com> wrote:
>
>> Hello Walid, I used your thin, burnin, nitt values, the model arrived
>> sample size=1000, and there wasn't convergence still.
>> Do think if the problem is the priori values?
>>
>> Thanks,
>> Abra?o
>>
>>
>> Em seg, 22 de mar de 2021 14:30, Walid Crampton-Mawass <
>> walidmawass10 at gmail.com> escreveu:
>>
>>> Hello,
>>>
>>> One way to improve the convergence of your phylogenetic model would be
>>> to increase the burn in iterations of the chain and take it into account in
>>> your total number of iterations. So in your case, I would set nitt=2500000,
>>> burnin= 500000 and nitt=2000, that way you would have a sample of 1000
>>> iterations saved from the total chain iterations (of course you can
>>> increase the thin interval based on the sample size of saved iterations you
>>> want).
>>>
>>> Good luck
>>> --
>>> Walid Crampton-Mawass
>>> Ph.D. candidate in Evolutionary Biology
>>> Population Genetics Laboratory
>>> University of Qu?bec at Trois-Rivi?res
>>> 3351, boul. des Forges, C.P. 500
>>> Trois-Rivi?res (Qu?bec) G9A 5H7
>>> Telephone: 819-376-5011 poste 3384
>>>
>>>
>>> On Mon, Mar 22, 2021 at 11:24 AM Abra?o de Barros Leite <
>>> abarrosib at gmail.com> wrote:
>>>
>>>> Hello Mathew
>>>>  My name is Abra?o, I saw your answer aboute MCMCGLMM sample size.
>>>> So, please can you help me?
>>>> I am working with relation between brain mass and nest birds in my
>>>> doctorate.
>>>> My dataset has 250 species, but in my analysis MCMCGLMM with
>>>> phylogenetic
>>>> control, I haven't convergence, with nitt=2000000, thin=3500,
>>>> burnin=4000.
>>>> Please, can you help me?
>>>> How I can to improve my convergence?
>>>> Sample size=100 in the end it's ok?
>>>> Thanks!
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-sig-mixed-models at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>
>>>

-- 
Abra?o de Barros Leite
Universidade Federal de S?o Carlos (UFSCAR)
Programa de P?s-Gradua??o em Ecologia e Recursos Naturais- S?o Carlos
(PPGERN)

	[[alternative HTML version deleted]]


From hedyeh@h @end|ng |rom u@c@edu  Mon Mar 22 22:24:04 2021
From: hedyeh@h @end|ng |rom u@c@edu (Hedyeh Ahmadi)
Date: Mon, 22 Mar 2021 21:24:04 +0000
Subject: [R-sig-ME] glmer() Gamma distribution - constant coefficient of
 variation
Message-ID: <BYAPR07MB5094FBA38F1C25DB9C119D22D1659@BYAPR07MB5094.namprd07.prod.outlook.com>

Hi all,
I am running a glmer() with Gamma distribution and identity link. The R output is as follows. I would like to check the constant coefficient of variation assumption in R but I am not sure where to start. Any help would be appreciated.

Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) ['glmerMod']
 Family: Gamma  ( identity )
Formula: Y ~ 1 + pm252016aa + race +prnt.empl + overall.income +  (1 | site)
Data: Family
Control: glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 100000))

     AIC       BIC           logLik           deviance df.resid
 68781.7   68917.1 -34371.8     68743.7     9180

Scaled residuals:
    Min      1Q             Median      3Q        Max
-1.9286   -0.7314   -0.0598    0.6770    3.9599

Random effects:
 Groups    Name               Variance   Std.Dev.
 site (Intercept)      0.66157    0.8134
 Residual                            0.04502     0.2122
Number of obs: 9199,  groups:  site, 21

Fixed effects:
                                                               Estimate     Std. Error         t value             Pr(>|z|)
(Intercept)                                              52.3578               1.3102            39.962         < 0.0000000000000002 ***
pm252016aa                                         -0.1260                 0.1099           -1.147            0.251212
race_1                                                     1.0913                  0.7106         -1.536             0.124628
race_2                                                     -1.1787                  0.6870          3.171             0.001518 **
prnt.empl                                               2.8852                  0.4377            4.307            0.000016517 **
overall.income[>=100K]                      -1.8476                 0.3693          -5.003            0.000000566 ***
overall.income[>=50K & <100K]        -0.8644                0.3403             -2.540            0.011078 *
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1


Best,

Hedyeh Ahmadi, Ph.D.
Statistician
Keck School of Medicine
Department of Preventive Medicine
University of Southern California

Postdoctoral Scholar
Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
University of California, Irvine

LinkedIn
www.linkedin.com/in/hedyeh-ahmadi<http://www.linkedin.com/in/hedyeh-ahmadi>
<http://www.linkedin.com/in/hedyeh-ahmadi><http://www.linkedin.com/in/hedyeh-ahmadi>





	[[alternative HTML version deleted]]


From w@||dm@w@@@10 @end|ng |rom gm@||@com  Tue Mar 23 16:42:21 2021
From: w@||dm@w@@@10 @end|ng |rom gm@||@com (Walid Crampton-Mawass)
Date: Tue, 23 Mar 2021 11:42:21 -0400
Subject: [R-sig-ME] effective sample size in MCMCglmm
In-Reply-To: <CAAQsOWWxdB_uo8+Rz8JjmxMkhaKAUZe-jEdo+jFr7OTo5OmKFg@mail.gmail.com>
References: <CAAQsOWWEjdHoCKTuTrW5h-dPj2yCe19jD9gG6WtjcEYRWQGp9w@mail.gmail.com>
 <CAJtCY7VqtxZTebupAWdDCU+3eC=QzsPHioHCrSn6wsUqvTHMtg@mail.gmail.com>
 <CAAQsOWWMWMGx8_mbx2FUj3AfOFOOpujUBuCAF8xw4-Pfwx_j=g@mail.gmail.com>
 <CAJtCY7WiHX1SuWF8EHQz_Oh7Vc3EDA=bsKpMYTScDWhwXfbz7g@mail.gmail.com>
 <CAAQsOWWxdB_uo8+Rz8JjmxMkhaKAUZe-jEdo+jFr7OTo5OmKFg@mail.gmail.com>
Message-ID: <CAJtCY7X3_2djdRBWyaLw519R7pUnebB4K3-AVpd0jM_VLoQQ7g@mail.gmail.com>

Hello,

Indeed there is very high autocorrelation in your animal term. And your
scale seems to be quite large given the estimates and HPDs. A good step
would be to scale down your continuous variables to see if that helps with
convergence in any way. Another possible practice is to drop one of the
random terms in your model to see how that changes the behavior of your
model. A side note, in your prior, there is no need to add n=0.002 to your
residual term since you already fixed it to 1.

Good luck
-- 
Walid Crampton-Mawass
Ph.D. candidate in Evolutionary Biology
Population Genetics Laboratory
University of Qu?bec at Trois-Rivi?res
3351, boul. des Forges, C.P. 500
Trois-Rivi?res (Qu?bec) G9A 5H7
Telephone: 819-376-5011 poste 3384


On Mon, Mar 22, 2021 at 3:09 PM Abra?o de Barros Leite <abarrosib at gmail.com>
wrote:

> Hello,  this is my script, and my dataset has 235 species.
>
> prior3.1 <- list(G = list(G1 = list(nu=0.002, V=1),G2 = list(nu=0.002,
> V=1)),#fatores de vari?ncias a priori#
>                  R = list( V=1,nu=0.002, fix=1))
> m1<-MCMCglmm(progofic~1+Dieta+trafic+log(massakg)+endg,data=databird,
> family="categorical",pedigree=contree,random=~animal+measureID,verbose = F,
>          nitt=2500000,burnin=250000,thin=10000,prior =prior3.1)
> summary(m1)
> acf(m1$Sol[,1],lag.max =100)
>
> *Results:*
>   Iterations = 250001:2490001
>  Thinning interval  = 10000
>  Sample size  = 225
>
>  DIC: 6.619977
>
>  G-structure:  ~animal
>
>        post.mean l-95% CI u-95% CI eff.samp
> animal      7713    999.2    15303    10.58
>
>                ~measureID
>
>           post.mean  l-95% CI u-95% CI eff.samp
> measureID     319.5 0.0005769     1505    81.04
>
>  R-structure:  ~units
>
>       post.mean l-95% CI u-95% CI eff.samp
> units         1        1        1        0
>
>  Location effects: progofic ~ 1 + Dieta + trafic + log(massakg) + endg
>
>                    post.mean l-95% CI u-95% CI eff.samp  pMCMC
> (Intercept)          -32.757 -127.914   59.857  152.759 0.4889
> DietaInvertebrate    -73.571 -153.500   -4.571    9.841 0.0356 *
> DietaNectarivorous  -156.649 -527.852  191.174    4.441 0.6489
> DietaOmnivore         -6.580  -43.869   33.693   83.293 0.7644
> DietaVert            -13.890  -87.780   73.738   62.163 0.8000
> traficyes             -1.761  -30.506   31.131  102.410 0.8711
> log(massakg)          25.917    6.443   43.469   18.590 <0.004 **
> endgEN                -3.139  -42.611   37.907   25.394 0.8889
> endgVU               -35.510  -73.109    1.471   24.992 0.0444 *
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> > acf(m1$Sol[,1],lag.max =100)
> > autocorr(m1$VCV)
> ,* , animal*
>                animal    measureID units
> Lag 0      1.00000000 -0.022820572   NaN
> Lag 10000  0.80567811 -0.045602281   NaN
> Lag 50000  0.58800623  0.037466483   NaN
> Lag 1e+05  0.37539889  0.221289380   NaN
> Lag 5e+05 -0.08870539 -0.005622699   NaN
> ,* , measureID*
>                 animal    measureID units
> Lag 0     -0.022820572  1.000000000   NaN
> Lag 10000 -0.004848064  0.369835208   NaN
> Lag 50000 -0.052249906  0.006497318   NaN
> Lag 1e+05 -0.053667796 -0.001787120   NaN
> Lag 5e+05 -0.015126358 -0.027780522   NaN
> ,* , units*
>           animal measureID units
> Lag 0        NaN       NaN   NaN
> Lag 10000    NaN       NaN   NaN
> Lag 50000    NaN       NaN   NaN
> Lag 1e+05    NaN       NaN   NaN
> Lag 5e+05    NaN       NaN   NaN
>
> Thanks,
> Abra?o
> On Mon, Mar 22, 2021 at 3:32 PM Walid Crampton-Mawass <
> walidmawass10 at gmail.com> wrote:
>
>> Yes possibly, or the sample size is too small for the model structure you
>> are attempting. It would help if you share your model structure and results
>> of autocorr() to check if autocorrelation between chain iterations is high.
>>
>> Additionally, when replying in this thread, use the reply all option so
>> our thread and discussion is included in the r-sig archives.
>> --
>> Walid Crampton-Mawass
>> Ph.D. candidate in Evolutionary Biology
>> Population Genetics Laboratory
>> University of Qu?bec at Trois-Rivi?res
>> 3351, boul. des Forges, C.P. 500
>> Trois-Rivi?res (Qu?bec) G9A 5H7
>> Telephone: 819-376-5011 poste 3384
>>
>>
>> On Mon, Mar 22, 2021 at 2:14 PM Abra?o de Barros Leite <
>> abarrosib at gmail.com> wrote:
>>
>>> Hello Walid, I used your thin, burnin, nitt values, the model arrived
>>> sample size=1000, and there wasn't convergence still.
>>> Do think if the problem is the priori values?
>>>
>>> Thanks,
>>> Abra?o
>>>
>>>
>>> Em seg, 22 de mar de 2021 14:30, Walid Crampton-Mawass <
>>> walidmawass10 at gmail.com> escreveu:
>>>
>>>> Hello,
>>>>
>>>> One way to improve the convergence of your phylogenetic model would be
>>>> to increase the burn in iterations of the chain and take it into account in
>>>> your total number of iterations. So in your case, I would set nitt=2500000,
>>>> burnin= 500000 and nitt=2000, that way you would have a sample of 1000
>>>> iterations saved from the total chain iterations (of course you can
>>>> increase the thin interval based on the sample size of saved iterations you
>>>> want).
>>>>
>>>> Good luck
>>>> --
>>>> Walid Crampton-Mawass
>>>> Ph.D. candidate in Evolutionary Biology
>>>> Population Genetics Laboratory
>>>> University of Qu?bec at Trois-Rivi?res
>>>> 3351, boul. des Forges, C.P. 500
>>>> Trois-Rivi?res (Qu?bec) G9A 5H7
>>>> Telephone: 819-376-5011 poste 3384
>>>>
>>>>
>>>> On Mon, Mar 22, 2021 at 11:24 AM Abra?o de Barros Leite <
>>>> abarrosib at gmail.com> wrote:
>>>>
>>>>> Hello Mathew
>>>>>  My name is Abra?o, I saw your answer aboute MCMCGLMM sample size.
>>>>> So, please can you help me?
>>>>> I am working with relation between brain mass and nest birds in my
>>>>> doctorate.
>>>>> My dataset has 250 species, but in my analysis MCMCGLMM with
>>>>> phylogenetic
>>>>> control, I haven't convergence, with nitt=2000000, thin=3500,
>>>>> burnin=4000.
>>>>> Please, can you help me?
>>>>> How I can to improve my convergence?
>>>>> Sample size=100 in the end it's ok?
>>>>> Thanks!
>>>>>
>>>>>         [[alternative HTML version deleted]]
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>
>>>>
>
> --
> Abra?o de Barros Leite
> Universidade Federal de S?o Carlos (UFSCAR)
> Programa de P?s-Gradua??o em Ecologia e Recursos Naturais- S?o Carlos
> (PPGERN)
>

	[[alternative HTML version deleted]]


From @b@rro@|b @end|ng |rom gm@||@com  Tue Mar 23 17:21:39 2021
From: @b@rro@|b @end|ng |rom gm@||@com (=?UTF-8?Q?Abra=C3=A3o_de_Barros_Leite?=)
Date: Tue, 23 Mar 2021 13:21:39 -0300
Subject: [R-sig-ME] effective sample size in MCMCglmm
In-Reply-To: <CAJtCY7X3_2djdRBWyaLw519R7pUnebB4K3-AVpd0jM_VLoQQ7g@mail.gmail.com>
References: <CAAQsOWWEjdHoCKTuTrW5h-dPj2yCe19jD9gG6WtjcEYRWQGp9w@mail.gmail.com>
 <CAJtCY7VqtxZTebupAWdDCU+3eC=QzsPHioHCrSn6wsUqvTHMtg@mail.gmail.com>
 <CAAQsOWWMWMGx8_mbx2FUj3AfOFOOpujUBuCAF8xw4-Pfwx_j=g@mail.gmail.com>
 <CAJtCY7WiHX1SuWF8EHQz_Oh7Vc3EDA=bsKpMYTScDWhwXfbz7g@mail.gmail.com>
 <CAAQsOWWxdB_uo8+Rz8JjmxMkhaKAUZe-jEdo+jFr7OTo5OmKFg@mail.gmail.com>
 <CAJtCY7X3_2djdRBWyaLw519R7pUnebB4K3-AVpd0jM_VLoQQ7g@mail.gmail.com>
Message-ID: <CAAQsOWXMCPVPNPOdg8w9Cb78YWJ5sf31XvZi2uCjj5+CL4S=wg@mail.gmail.com>

Thanks, I will make these changes and monitor how the models will converge.

All the best,
Abra?o

Em ter, 23 de mar de 2021 12:42, Walid Crampton-Mawass <
walidmawass10 at gmail.com> escreveu:

> Hello,
>
> Indeed there is very high autocorrelation in your animal term. And your
> scale seems to be quite large given the estimates and HPDs. A good step
> would be to scale down your continuous variables to see if that helps with
> convergence in any way. Another possible practice is to drop one of the
> random terms in your model to see how that changes the behavior of your
> model. A side note, in your prior, there is no need to add n=0.002 to your
> residual term since you already fixed it to 1.
>
> Good luck
> --
> Walid Crampton-Mawass
> Ph.D. candidate in Evolutionary Biology
> Population Genetics Laboratory
> University of Qu?bec at Trois-Rivi?res
> 3351, boul. des Forges, C.P. 500
> Trois-Rivi?res (Qu?bec) G9A 5H7
> Telephone: 819-376-5011 poste 3384
>
>
> On Mon, Mar 22, 2021 at 3:09 PM Abra?o de Barros Leite <
> abarrosib at gmail.com> wrote:
>
>> Hello,  this is my script, and my dataset has 235 species.
>>
>> prior3.1 <- list(G = list(G1 = list(nu=0.002, V=1),G2 = list(nu=0.002,
>> V=1)),#fatores de vari?ncias a priori#
>>                  R = list( V=1,nu=0.002, fix=1))
>> m1<-MCMCglmm(progofic~1+Dieta+trafic+log(massakg)+endg,data=databird,
>> family="categorical",pedigree=contree,random=~animal+measureID,verbose = F,
>>          nitt=2500000,burnin=250000,thin=10000,prior =prior3.1)
>> summary(m1)
>> acf(m1$Sol[,1],lag.max =100)
>>
>> *Results:*
>>   Iterations = 250001:2490001
>>  Thinning interval  = 10000
>>  Sample size  = 225
>>
>>  DIC: 6.619977
>>
>>  G-structure:  ~animal
>>
>>        post.mean l-95% CI u-95% CI eff.samp
>> animal      7713    999.2    15303    10.58
>>
>>                ~measureID
>>
>>           post.mean  l-95% CI u-95% CI eff.samp
>> measureID     319.5 0.0005769     1505    81.04
>>
>>  R-structure:  ~units
>>
>>       post.mean l-95% CI u-95% CI eff.samp
>> units         1        1        1        0
>>
>>  Location effects: progofic ~ 1 + Dieta + trafic + log(massakg) + endg
>>
>>                    post.mean l-95% CI u-95% CI eff.samp  pMCMC
>> (Intercept)          -32.757 -127.914   59.857  152.759 0.4889
>> DietaInvertebrate    -73.571 -153.500   -4.571    9.841 0.0356 *
>> DietaNectarivorous  -156.649 -527.852  191.174    4.441 0.6489
>> DietaOmnivore         -6.580  -43.869   33.693   83.293 0.7644
>> DietaVert            -13.890  -87.780   73.738   62.163 0.8000
>> traficyes             -1.761  -30.506   31.131  102.410 0.8711
>> log(massakg)          25.917    6.443   43.469   18.590 <0.004 **
>> endgEN                -3.139  -42.611   37.907   25.394 0.8889
>> endgVU               -35.510  -73.109    1.471   24.992 0.0444 *
>> ---
>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>> > acf(m1$Sol[,1],lag.max =100)
>> > autocorr(m1$VCV)
>> ,* , animal*
>>                animal    measureID units
>> Lag 0      1.00000000 -0.022820572   NaN
>> Lag 10000  0.80567811 -0.045602281   NaN
>> Lag 50000  0.58800623  0.037466483   NaN
>> Lag 1e+05  0.37539889  0.221289380   NaN
>> Lag 5e+05 -0.08870539 -0.005622699   NaN
>> ,* , measureID*
>>                 animal    measureID units
>> Lag 0     -0.022820572  1.000000000   NaN
>> Lag 10000 -0.004848064  0.369835208   NaN
>> Lag 50000 -0.052249906  0.006497318   NaN
>> Lag 1e+05 -0.053667796 -0.001787120   NaN
>> Lag 5e+05 -0.015126358 -0.027780522   NaN
>> ,* , units*
>>           animal measureID units
>> Lag 0        NaN       NaN   NaN
>> Lag 10000    NaN       NaN   NaN
>> Lag 50000    NaN       NaN   NaN
>> Lag 1e+05    NaN       NaN   NaN
>> Lag 5e+05    NaN       NaN   NaN
>>
>> Thanks,
>> Abra?o
>> On Mon, Mar 22, 2021 at 3:32 PM Walid Crampton-Mawass <
>> walidmawass10 at gmail.com> wrote:
>>
>>> Yes possibly, or the sample size is too small for the model structure
>>> you are attempting. It would help if you share your model structure and
>>> results of autocorr() to check if autocorrelation between chain iterations
>>> is high.
>>>
>>> Additionally, when replying in this thread, use the reply all option so
>>> our thread and discussion is included in the r-sig archives.
>>> --
>>> Walid Crampton-Mawass
>>> Ph.D. candidate in Evolutionary Biology
>>> Population Genetics Laboratory
>>> University of Qu?bec at Trois-Rivi?res
>>> 3351, boul. des Forges, C.P. 500
>>> Trois-Rivi?res (Qu?bec) G9A 5H7
>>> Telephone: 819-376-5011 poste 3384
>>>
>>>
>>> On Mon, Mar 22, 2021 at 2:14 PM Abra?o de Barros Leite <
>>> abarrosib at gmail.com> wrote:
>>>
>>>> Hello Walid, I used your thin, burnin, nitt values, the model arrived
>>>> sample size=1000, and there wasn't convergence still.
>>>> Do think if the problem is the priori values?
>>>>
>>>> Thanks,
>>>> Abra?o
>>>>
>>>>
>>>> Em seg, 22 de mar de 2021 14:30, Walid Crampton-Mawass <
>>>> walidmawass10 at gmail.com> escreveu:
>>>>
>>>>> Hello,
>>>>>
>>>>> One way to improve the convergence of your phylogenetic model would be
>>>>> to increase the burn in iterations of the chain and take it into account in
>>>>> your total number of iterations. So in your case, I would set nitt=2500000,
>>>>> burnin= 500000 and nitt=2000, that way you would have a sample of 1000
>>>>> iterations saved from the total chain iterations (of course you can
>>>>> increase the thin interval based on the sample size of saved iterations you
>>>>> want).
>>>>>
>>>>> Good luck
>>>>> --
>>>>> Walid Crampton-Mawass
>>>>> Ph.D. candidate in Evolutionary Biology
>>>>> Population Genetics Laboratory
>>>>> University of Qu?bec at Trois-Rivi?res
>>>>> 3351, boul. des Forges, C.P. 500
>>>>> Trois-Rivi?res (Qu?bec) G9A 5H7
>>>>> Telephone: 819-376-5011 poste 3384
>>>>>
>>>>>
>>>>> On Mon, Mar 22, 2021 at 11:24 AM Abra?o de Barros Leite <
>>>>> abarrosib at gmail.com> wrote:
>>>>>
>>>>>> Hello Mathew
>>>>>>  My name is Abra?o, I saw your answer aboute MCMCGLMM sample size.
>>>>>> So, please can you help me?
>>>>>> I am working with relation between brain mass and nest birds in my
>>>>>> doctorate.
>>>>>> My dataset has 250 species, but in my analysis MCMCGLMM with
>>>>>> phylogenetic
>>>>>> control, I haven't convergence, with nitt=2000000, thin=3500,
>>>>>> burnin=4000.
>>>>>> Please, can you help me?
>>>>>> How I can to improve my convergence?
>>>>>> Sample size=100 in the end it's ok?
>>>>>> Thanks!
>>>>>>
>>>>>>         [[alternative HTML version deleted]]
>>>>>>
>>>>>> _______________________________________________
>>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>>
>>>>>
>>
>> --
>> Abra?o de Barros Leite
>> Universidade Federal de S?o Carlos (UFSCAR)
>> Programa de P?s-Gradua??o em Ecologia e Recursos Naturais- S?o Carlos
>> (PPGERN)
>>
>

	[[alternative HTML version deleted]]


From @b@rro@|b @end|ng |rom gm@||@com  Tue Mar 23 17:57:29 2021
From: @b@rro@|b @end|ng |rom gm@||@com (=?UTF-8?Q?Abra=C3=A3o_de_Barros_Leite?=)
Date: Tue, 23 Mar 2021 13:57:29 -0300
Subject: [R-sig-ME] effective sample size in MCMCglmm
In-Reply-To: <CAAQsOWXMCPVPNPOdg8w9Cb78YWJ5sf31XvZi2uCjj5+CL4S=wg@mail.gmail.com>
References: <CAAQsOWWEjdHoCKTuTrW5h-dPj2yCe19jD9gG6WtjcEYRWQGp9w@mail.gmail.com>
 <CAJtCY7VqtxZTebupAWdDCU+3eC=QzsPHioHCrSn6wsUqvTHMtg@mail.gmail.com>
 <CAAQsOWWMWMGx8_mbx2FUj3AfOFOOpujUBuCAF8xw4-Pfwx_j=g@mail.gmail.com>
 <CAJtCY7WiHX1SuWF8EHQz_Oh7Vc3EDA=bsKpMYTScDWhwXfbz7g@mail.gmail.com>
 <CAAQsOWWxdB_uo8+Rz8JjmxMkhaKAUZe-jEdo+jFr7OTo5OmKFg@mail.gmail.com>
 <CAJtCY7X3_2djdRBWyaLw519R7pUnebB4K3-AVpd0jM_VLoQQ7g@mail.gmail.com>
 <CAAQsOWXMCPVPNPOdg8w9Cb78YWJ5sf31XvZi2uCjj5+CL4S=wg@mail.gmail.com>
Message-ID: <CAAQsOWV=4F2Dx5nxZicSrAd8PAgiLp03hDW42ze+hLcL7AXQHA@mail.gmail.com>

Unfortunately, I am able to have convergence in my model just with sample
size = 200. This sample size is so bad?

Thanks,
Abra?o

Em ter, 23 de mar de 2021 13:21, Abra?o de Barros Leite <abarrosib at gmail.com>
escreveu:

> Thanks, I will make these changes and monitor how the models will converge.
>
> All the best,
> Abra?o
>
> Em ter, 23 de mar de 2021 12:42, Walid Crampton-Mawass <
> walidmawass10 at gmail.com> escreveu:
>
>> Hello,
>>
>> Indeed there is very high autocorrelation in your animal term. And your
>> scale seems to be quite large given the estimates and HPDs. A good step
>> would be to scale down your continuous variables to see if that helps with
>> convergence in any way. Another possible practice is to drop one of the
>> random terms in your model to see how that changes the behavior of your
>> model. A side note, in your prior, there is no need to add n=0.002 to your
>> residual term since you already fixed it to 1.
>>
>> Good luck
>> --
>> Walid Crampton-Mawass
>> Ph.D. candidate in Evolutionary Biology
>> Population Genetics Laboratory
>> University of Qu?bec at Trois-Rivi?res
>> 3351, boul. des Forges, C.P. 500
>> Trois-Rivi?res (Qu?bec) G9A 5H7
>> Telephone: 819-376-5011 poste 3384
>>
>>
>> On Mon, Mar 22, 2021 at 3:09 PM Abra?o de Barros Leite <
>> abarrosib at gmail.com> wrote:
>>
>>> Hello,  this is my script, and my dataset has 235 species.
>>>
>>> prior3.1 <- list(G = list(G1 = list(nu=0.002, V=1),G2 = list(nu=0.002,
>>> V=1)),#fatores de vari?ncias a priori#
>>>                  R = list( V=1,nu=0.002, fix=1))
>>> m1<-MCMCglmm(progofic~1+Dieta+trafic+log(massakg)+endg,data=databird,
>>> family="categorical",pedigree=contree,random=~animal+measureID,verbose = F,
>>>          nitt=2500000,burnin=250000,thin=10000,prior =prior3.1)
>>> summary(m1)
>>> acf(m1$Sol[,1],lag.max =100)
>>>
>>> *Results:*
>>>   Iterations = 250001:2490001
>>>  Thinning interval  = 10000
>>>  Sample size  = 225
>>>
>>>  DIC: 6.619977
>>>
>>>  G-structure:  ~animal
>>>
>>>        post.mean l-95% CI u-95% CI eff.samp
>>> animal      7713    999.2    15303    10.58
>>>
>>>                ~measureID
>>>
>>>           post.mean  l-95% CI u-95% CI eff.samp
>>> measureID     319.5 0.0005769     1505    81.04
>>>
>>>  R-structure:  ~units
>>>
>>>       post.mean l-95% CI u-95% CI eff.samp
>>> units         1        1        1        0
>>>
>>>  Location effects: progofic ~ 1 + Dieta + trafic + log(massakg) + endg
>>>
>>>                    post.mean l-95% CI u-95% CI eff.samp  pMCMC
>>> (Intercept)          -32.757 -127.914   59.857  152.759 0.4889
>>> DietaInvertebrate    -73.571 -153.500   -4.571    9.841 0.0356 *
>>> DietaNectarivorous  -156.649 -527.852  191.174    4.441 0.6489
>>> DietaOmnivore         -6.580  -43.869   33.693   83.293 0.7644
>>> DietaVert            -13.890  -87.780   73.738   62.163 0.8000
>>> traficyes             -1.761  -30.506   31.131  102.410 0.8711
>>> log(massakg)          25.917    6.443   43.469   18.590 <0.004 **
>>> endgEN                -3.139  -42.611   37.907   25.394 0.8889
>>> endgVU               -35.510  -73.109    1.471   24.992 0.0444 *
>>> ---
>>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>> > acf(m1$Sol[,1],lag.max =100)
>>> > autocorr(m1$VCV)
>>> ,* , animal*
>>>                animal    measureID units
>>> Lag 0      1.00000000 -0.022820572   NaN
>>> Lag 10000  0.80567811 -0.045602281   NaN
>>> Lag 50000  0.58800623  0.037466483   NaN
>>> Lag 1e+05  0.37539889  0.221289380   NaN
>>> Lag 5e+05 -0.08870539 -0.005622699   NaN
>>> ,* , measureID*
>>>                 animal    measureID units
>>> Lag 0     -0.022820572  1.000000000   NaN
>>> Lag 10000 -0.004848064  0.369835208   NaN
>>> Lag 50000 -0.052249906  0.006497318   NaN
>>> Lag 1e+05 -0.053667796 -0.001787120   NaN
>>> Lag 5e+05 -0.015126358 -0.027780522   NaN
>>> ,* , units*
>>>           animal measureID units
>>> Lag 0        NaN       NaN   NaN
>>> Lag 10000    NaN       NaN   NaN
>>> Lag 50000    NaN       NaN   NaN
>>> Lag 1e+05    NaN       NaN   NaN
>>> Lag 5e+05    NaN       NaN   NaN
>>>
>>> Thanks,
>>> Abra?o
>>> On Mon, Mar 22, 2021 at 3:32 PM Walid Crampton-Mawass <
>>> walidmawass10 at gmail.com> wrote:
>>>
>>>> Yes possibly, or the sample size is too small for the model structure
>>>> you are attempting. It would help if you share your model structure and
>>>> results of autocorr() to check if autocorrelation between chain iterations
>>>> is high.
>>>>
>>>> Additionally, when replying in this thread, use the reply all option so
>>>> our thread and discussion is included in the r-sig archives.
>>>> --
>>>> Walid Crampton-Mawass
>>>> Ph.D. candidate in Evolutionary Biology
>>>> Population Genetics Laboratory
>>>> University of Qu?bec at Trois-Rivi?res
>>>> 3351, boul. des Forges, C.P. 500
>>>> Trois-Rivi?res (Qu?bec) G9A 5H7
>>>> Telephone: 819-376-5011 poste 3384
>>>>
>>>>
>>>> On Mon, Mar 22, 2021 at 2:14 PM Abra?o de Barros Leite <
>>>> abarrosib at gmail.com> wrote:
>>>>
>>>>> Hello Walid, I used your thin, burnin, nitt values, the model arrived
>>>>> sample size=1000, and there wasn't convergence still.
>>>>> Do think if the problem is the priori values?
>>>>>
>>>>> Thanks,
>>>>> Abra?o
>>>>>
>>>>>
>>>>> Em seg, 22 de mar de 2021 14:30, Walid Crampton-Mawass <
>>>>> walidmawass10 at gmail.com> escreveu:
>>>>>
>>>>>> Hello,
>>>>>>
>>>>>> One way to improve the convergence of your phylogenetic model would
>>>>>> be to increase the burn in iterations of the chain and take it into account
>>>>>> in your total number of iterations. So in your case, I would set
>>>>>> nitt=2500000, burnin= 500000 and nitt=2000, that way you would have a
>>>>>> sample of 1000 iterations saved from the total chain iterations (of course
>>>>>> you can increase the thin interval based on the sample size of saved
>>>>>> iterations you want).
>>>>>>
>>>>>> Good luck
>>>>>> --
>>>>>> Walid Crampton-Mawass
>>>>>> Ph.D. candidate in Evolutionary Biology
>>>>>> Population Genetics Laboratory
>>>>>> University of Qu?bec at Trois-Rivi?res
>>>>>> 3351, boul. des Forges, C.P. 500
>>>>>> Trois-Rivi?res (Qu?bec) G9A 5H7
>>>>>> Telephone: 819-376-5011 poste 3384
>>>>>>
>>>>>>
>>>>>> On Mon, Mar 22, 2021 at 11:24 AM Abra?o de Barros Leite <
>>>>>> abarrosib at gmail.com> wrote:
>>>>>>
>>>>>>> Hello Mathew
>>>>>>>  My name is Abra?o, I saw your answer aboute MCMCGLMM sample size.
>>>>>>> So, please can you help me?
>>>>>>> I am working with relation between brain mass and nest birds in my
>>>>>>> doctorate.
>>>>>>> My dataset has 250 species, but in my analysis MCMCGLMM with
>>>>>>> phylogenetic
>>>>>>> control, I haven't convergence, with nitt=2000000, thin=3500,
>>>>>>> burnin=4000.
>>>>>>> Please, can you help me?
>>>>>>> How I can to improve my convergence?
>>>>>>> Sample size=100 in the end it's ok?
>>>>>>> Thanks!
>>>>>>>
>>>>>>>         [[alternative HTML version deleted]]
>>>>>>>
>>>>>>> _______________________________________________
>>>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>>>
>>>>>>
>>>
>>> --
>>> Abra?o de Barros Leite
>>> Universidade Federal de S?o Carlos (UFSCAR)
>>> Programa de P?s-Gradua??o em Ecologia e Recursos Naturais- S?o Carlos
>>> (PPGERN)
>>>
>>

	[[alternative HTML version deleted]]


From w@||dm@w@@@10 @end|ng |rom gm@||@com  Tue Mar 23 19:41:45 2021
From: w@||dm@w@@@10 @end|ng |rom gm@||@com (Walid Crampton-Mawass)
Date: Tue, 23 Mar 2021 14:41:45 -0400
Subject: [R-sig-ME] effective sample size in MCMCglmm
In-Reply-To: <CAAQsOWV=4F2Dx5nxZicSrAd8PAgiLp03hDW42ze+hLcL7AXQHA@mail.gmail.com>
References: <CAAQsOWWEjdHoCKTuTrW5h-dPj2yCe19jD9gG6WtjcEYRWQGp9w@mail.gmail.com>
 <CAJtCY7VqtxZTebupAWdDCU+3eC=QzsPHioHCrSn6wsUqvTHMtg@mail.gmail.com>
 <CAAQsOWWMWMGx8_mbx2FUj3AfOFOOpujUBuCAF8xw4-Pfwx_j=g@mail.gmail.com>
 <CAJtCY7WiHX1SuWF8EHQz_Oh7Vc3EDA=bsKpMYTScDWhwXfbz7g@mail.gmail.com>
 <CAAQsOWWxdB_uo8+Rz8JjmxMkhaKAUZe-jEdo+jFr7OTo5OmKFg@mail.gmail.com>
 <CAJtCY7X3_2djdRBWyaLw519R7pUnebB4K3-AVpd0jM_VLoQQ7g@mail.gmail.com>
 <CAAQsOWXMCPVPNPOdg8w9Cb78YWJ5sf31XvZi2uCjj5+CL4S=wg@mail.gmail.com>
 <CAAQsOWV=4F2Dx5nxZicSrAd8PAgiLp03hDW42ze+hLcL7AXQHA@mail.gmail.com>
Message-ID: <CAJtCY7UAM0JN1nh39pkDFp2F=h6Q8FP5O7pybCV2eU0t4LCj3g@mail.gmail.com>

Rechecking your model, I noticed you have set the burnin at 250000 and your
thin at 10000 which resulted in a very small sample size for your
estimates, meaning your posterior distribution is based on a very small
sample of saved iterations of the chain. The setting suggested is
burnin=2500000, thin=500000 (which means we end up with 2 million
iterations of the chain) and thin=2000 (this way we end up with a 1000
sample size which is acceptable, i.e. 2000000/2000).

Another suggestion would be to use expanded parameters for your priors to
better the convergence of the model. I can't specifically suggest to you
what prior to specify but reading the "Parameter-expanded priors" section
in the coursenotes of the MCMcglmm package by Hadfield (2010) would be a
good place to start.

Good luck
-- 
Walid Crampton-Mawass
Ph.D. candidate in Evolutionary Biology
Population Genetics Laboratory
University of Qu?bec at Trois-Rivi?res
3351, boul. des Forges, C.P. 500
Trois-Rivi?res (Qu?bec) G9A 5H7
Telephone: 819-376-5011 poste 3384


On Tue, Mar 23, 2021 at 12:57 PM Abra?o de Barros Leite <abarrosib at gmail.com>
wrote:

> Unfortunately, I am able to have convergence in my model just with sample
> size = 200. This sample size is so bad?
>
> Thanks,
> Abra?o
>
> Em ter, 23 de mar de 2021 13:21, Abra?o de Barros Leite <
> abarrosib at gmail.com> escreveu:
>
>> Thanks, I will make these changes and monitor how the models will
>> converge.
>>
>> All the best,
>> Abra?o
>>
>> Em ter, 23 de mar de 2021 12:42, Walid Crampton-Mawass <
>> walidmawass10 at gmail.com> escreveu:
>>
>>> Hello,
>>>
>>> Indeed there is very high autocorrelation in your animal term. And your
>>> scale seems to be quite large given the estimates and HPDs. A good step
>>> would be to scale down your continuous variables to see if that helps with
>>> convergence in any way. Another possible practice is to drop one of the
>>> random terms in your model to see how that changes the behavior of your
>>> model. A side note, in your prior, there is no need to add n=0.002 to your
>>> residual term since you already fixed it to 1.
>>>
>>> Good luck
>>> --
>>> Walid Crampton-Mawass
>>> Ph.D. candidate in Evolutionary Biology
>>> Population Genetics Laboratory
>>> University of Qu?bec at Trois-Rivi?res
>>> 3351, boul. des Forges, C.P. 500
>>> Trois-Rivi?res (Qu?bec) G9A 5H7
>>> Telephone: 819-376-5011 poste 3384
>>>
>>>
>>> On Mon, Mar 22, 2021 at 3:09 PM Abra?o de Barros Leite <
>>> abarrosib at gmail.com> wrote:
>>>
>>>> Hello,  this is my script, and my dataset has 235 species.
>>>>
>>>> prior3.1 <- list(G = list(G1 = list(nu=0.002, V=1),G2 = list(nu=0.002,
>>>> V=1)),#fatores de vari?ncias a priori#
>>>>                  R = list( V=1,nu=0.002, fix=1))
>>>> m1<-MCMCglmm(progofic~1+Dieta+trafic+log(massakg)+endg,data=databird,
>>>> family="categorical",pedigree=contree,random=~animal+measureID,verbose = F,
>>>>          nitt=2500000,burnin=250000,thin=10000,prior =prior3.1)
>>>> summary(m1)
>>>> acf(m1$Sol[,1],lag.max =100)
>>>>
>>>> *Results:*
>>>>   Iterations = 250001:2490001
>>>>  Thinning interval  = 10000
>>>>  Sample size  = 225
>>>>
>>>>  DIC: 6.619977
>>>>
>>>>  G-structure:  ~animal
>>>>
>>>>        post.mean l-95% CI u-95% CI eff.samp
>>>> animal      7713    999.2    15303    10.58
>>>>
>>>>                ~measureID
>>>>
>>>>           post.mean  l-95% CI u-95% CI eff.samp
>>>> measureID     319.5 0.0005769     1505    81.04
>>>>
>>>>  R-structure:  ~units
>>>>
>>>>       post.mean l-95% CI u-95% CI eff.samp
>>>> units         1        1        1        0
>>>>
>>>>  Location effects: progofic ~ 1 + Dieta + trafic + log(massakg) + endg
>>>>
>>>>                    post.mean l-95% CI u-95% CI eff.samp  pMCMC
>>>> (Intercept)          -32.757 -127.914   59.857  152.759 0.4889
>>>> DietaInvertebrate    -73.571 -153.500   -4.571    9.841 0.0356 *
>>>> DietaNectarivorous  -156.649 -527.852  191.174    4.441 0.6489
>>>> DietaOmnivore         -6.580  -43.869   33.693   83.293 0.7644
>>>> DietaVert            -13.890  -87.780   73.738   62.163 0.8000
>>>> traficyes             -1.761  -30.506   31.131  102.410 0.8711
>>>> log(massakg)          25.917    6.443   43.469   18.590 <0.004 **
>>>> endgEN                -3.139  -42.611   37.907   25.394 0.8889
>>>> endgVU               -35.510  -73.109    1.471   24.992 0.0444 *
>>>> ---
>>>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>>> > acf(m1$Sol[,1],lag.max =100)
>>>> > autocorr(m1$VCV)
>>>> ,* , animal*
>>>>                animal    measureID units
>>>> Lag 0      1.00000000 -0.022820572   NaN
>>>> Lag 10000  0.80567811 -0.045602281   NaN
>>>> Lag 50000  0.58800623  0.037466483   NaN
>>>> Lag 1e+05  0.37539889  0.221289380   NaN
>>>> Lag 5e+05 -0.08870539 -0.005622699   NaN
>>>> ,* , measureID*
>>>>                 animal    measureID units
>>>> Lag 0     -0.022820572  1.000000000   NaN
>>>> Lag 10000 -0.004848064  0.369835208   NaN
>>>> Lag 50000 -0.052249906  0.006497318   NaN
>>>> Lag 1e+05 -0.053667796 -0.001787120   NaN
>>>> Lag 5e+05 -0.015126358 -0.027780522   NaN
>>>> ,* , units*
>>>>           animal measureID units
>>>> Lag 0        NaN       NaN   NaN
>>>> Lag 10000    NaN       NaN   NaN
>>>> Lag 50000    NaN       NaN   NaN
>>>> Lag 1e+05    NaN       NaN   NaN
>>>> Lag 5e+05    NaN       NaN   NaN
>>>>
>>>> Thanks,
>>>> Abra?o
>>>> On Mon, Mar 22, 2021 at 3:32 PM Walid Crampton-Mawass <
>>>> walidmawass10 at gmail.com> wrote:
>>>>
>>>>> Yes possibly, or the sample size is too small for the model structure
>>>>> you are attempting. It would help if you share your model structure and
>>>>> results of autocorr() to check if autocorrelation between chain iterations
>>>>> is high.
>>>>>
>>>>> Additionally, when replying in this thread, use the reply all option
>>>>> so our thread and discussion is included in the r-sig archives.
>>>>> --
>>>>> Walid Crampton-Mawass
>>>>> Ph.D. candidate in Evolutionary Biology
>>>>> Population Genetics Laboratory
>>>>> University of Qu?bec at Trois-Rivi?res
>>>>> 3351, boul. des Forges, C.P. 500
>>>>> Trois-Rivi?res (Qu?bec) G9A 5H7
>>>>> Telephone: 819-376-5011 poste 3384
>>>>>
>>>>>
>>>>> On Mon, Mar 22, 2021 at 2:14 PM Abra?o de Barros Leite <
>>>>> abarrosib at gmail.com> wrote:
>>>>>
>>>>>> Hello Walid, I used your thin, burnin, nitt values, the model arrived
>>>>>> sample size=1000, and there wasn't convergence still.
>>>>>> Do think if the problem is the priori values?
>>>>>>
>>>>>> Thanks,
>>>>>> Abra?o
>>>>>>
>>>>>>
>>>>>> Em seg, 22 de mar de 2021 14:30, Walid Crampton-Mawass <
>>>>>> walidmawass10 at gmail.com> escreveu:
>>>>>>
>>>>>>> Hello,
>>>>>>>
>>>>>>> One way to improve the convergence of your phylogenetic model would
>>>>>>> be to increase the burn in iterations of the chain and take it into account
>>>>>>> in your total number of iterations. So in your case, I would set
>>>>>>> nitt=2500000, burnin= 500000 and nitt=2000, that way you would have a
>>>>>>> sample of 1000 iterations saved from the total chain iterations (of course
>>>>>>> you can increase the thin interval based on the sample size of saved
>>>>>>> iterations you want).
>>>>>>>
>>>>>>> Good luck
>>>>>>> --
>>>>>>> Walid Crampton-Mawass
>>>>>>> Ph.D. candidate in Evolutionary Biology
>>>>>>> Population Genetics Laboratory
>>>>>>> University of Qu?bec at Trois-Rivi?res
>>>>>>> 3351, boul. des Forges, C.P. 500
>>>>>>> Trois-Rivi?res (Qu?bec) G9A 5H7
>>>>>>> Telephone: 819-376-5011 poste 3384
>>>>>>>
>>>>>>>
>>>>>>> On Mon, Mar 22, 2021 at 11:24 AM Abra?o de Barros Leite <
>>>>>>> abarrosib at gmail.com> wrote:
>>>>>>>
>>>>>>>> Hello Mathew
>>>>>>>>  My name is Abra?o, I saw your answer aboute MCMCGLMM sample size.
>>>>>>>> So, please can you help me?
>>>>>>>> I am working with relation between brain mass and nest birds in my
>>>>>>>> doctorate.
>>>>>>>> My dataset has 250 species, but in my analysis MCMCGLMM with
>>>>>>>> phylogenetic
>>>>>>>> control, I haven't convergence, with nitt=2000000, thin=3500,
>>>>>>>> burnin=4000.
>>>>>>>> Please, can you help me?
>>>>>>>> How I can to improve my convergence?
>>>>>>>> Sample size=100 in the end it's ok?
>>>>>>>> Thanks!
>>>>>>>>
>>>>>>>>         [[alternative HTML version deleted]]
>>>>>>>>
>>>>>>>> _______________________________________________
>>>>>>>> R-sig-mixed-models at r-project.org mailing list
>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>>>>>>>
>>>>>>>
>>>>
>>>> --
>>>> Abra?o de Barros Leite
>>>> Universidade Federal de S?o Carlos (UFSCAR)
>>>> Programa de P?s-Gradua??o em Ecologia e Recursos Naturais- S?o Carlos
>>>> (PPGERN)
>>>>
>>>

	[[alternative HTML version deleted]]


From jungm@@rten @end|ng |rom gm@||@com  Wed Mar 24 21:49:03 2021
From: jungm@@rten @end|ng |rom gm@||@com (Maarten Jung)
Date: Wed, 24 Mar 2021 21:49:03 +0100
Subject: [R-sig-ME] Group-mean centering in linear mixed models
Message-ID: <e7340b74-7a01-6752-7527-c89efc4e331b@gmail.com>

Dear list,

My current understanding is that in order to get unbiased estimates of 
the within-group1 effects of the continuous predictors A, B, and the 
interaction effect A:B on the dependent variable Y in model m1, one has 
to mean-center A and B within each level of the random grouping factor 
group1 ("group-mean centering"). Is this correct?

Let's now consider a model m2 that describes a design with an additional 
random grouping factor group2 and assume that the by-group1 random 
effects and by-group2 random effects are crossed.
Is mean-centering A and B within each level of the random grouping 
factor group1 still valid to obtain unbiased estimates of the 
within-group1 effects in this case?

If A and B are categorical predictors (factors), is group-mean centering 
still useful? E.g., if A and B are 2-level factors, then group-mean 
centering in a balanced design would basically be the same as 
sum-contrast coding (up to a multiplicative constant); however, in case 
of missing data/an unbalanced design, group-mean centering and 
sum-contrast coding would differ.

m1: Y ~ 1 + A*B + (1 + A*B|group1)
m2: Y ~ 1 + A*B + (1 + A*B|group1) + (1 + A*B|group2)

Best,
Maarten


From Andre@Syvert@en @end|ng |rom u|b@no  Fri Mar 26 10:47:50 2021
From: Andre@Syvert@en @end|ng |rom u|b@no (Andre Syvertsen)
Date: Fri, 26 Mar 2021 09:47:50 +0000
Subject: [R-sig-ME] help: Fitting mixed model with continuous data that is
 non-normal
Message-ID: <AM6PR0102MB31743FD9A2FF22416E57AB709E619@AM6PR0102MB3174.eurprd01.prod.exchangelabs.com>

Hi,

Question in brief:

I have a question regarding fitting mixed models with continuous data that is non-normal. The data has very high kurtosis, is positively skewed, and shows heteroscedasticity at higher values. I believe this makes sense theoretically (see below). Is there a type of generalized linear model that is commonly used in these settings? Any specific distribution and way to determine this?



More information:

I have consulted with the mailing list a couple of times previously regarding modeling count data and want to extend my thanks for the valuable feedback I received then! The model I am trying now is part of the same study, but with an outcome variable that is continuous and non-negative. The basics of the study are the same:



I am working with a large dataset that contains longitudinal data on gambling behavior of 184,113 participants. The data is based on complete tracking of electronic gambling behavior within a gambling operator. Gambling behavior data is aggregated on a monthly level, a total of 70 months. I have an ID variable separating participants, a time variable (months), as well as numerous gambling behavior variables such as active days played for given month, total bet size for given month, total losses for given month, etc. I am investigating the role of age (categorized into 6 age groups, ageCategory) and gender in predicting gambling behavior outcomes. The outcome is relative bet size in each month. Participant monthly bet size is divided on number of active gambling days the person had in the given month, which we term "gambling intensity" (gamblingIntensity). For example, gambling 1 day in month and betting 100$ = 100, gambling 2 days in month and betting 200$ = 100, We only analyze months with any active gambling (active days gambling >=1)

I have fitted a linear mixed model with lme4, with the following code:



gamblingIntensityConditionalAgeGender <- lmer(gamblingIntensity ~ 1 + time + ageCategory * gender + (1 | id), REML = FALSE, data = ntDF)



I have checked the resulting model with a qqplot and the residuals are far from normally distributed. Descriptive analysis of the outcome variable also shows it to have high positive skewness (ranging between 2.6-7.4, most around 4) and extreme kurtosis (19.6-270.8, most around 40) depending on the month. Here are means based on percentiles:

.05, .10, .25, .50, .75, .90, .95

87.0, 173.0, 527.3, 1207.3, 2182.6, 3528.7, 4655.9



A few gamblers will spend a little money on gambling, most gamblers will spend a moderate amount, and a few gamblers will spend a very large amount of money and show higher variation. This pattern also fits other forms of risk behaviors, like alcohol, in which a small percentage of the population are responsible for most of the alcohol consumption in the population. Because of this, I am reluctant to do any data transformations to make it more normally distributed but rather use a model that actually reflects the real-world phenomenon.



I have tried to consult with the research literature but cannot seem to find any examples of mixed modeling of these types of data. Most studies either examine count data or they use other approaches, e.g., do group-based analyses based on grouping by percentiles.



Kind regards,

Andr?


	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Tue Mar 30 02:44:39 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Mon, 29 Mar 2021 20:44:39 -0400
Subject: [R-sig-ME] 
 help: Fitting mixed model with continuous data that is non-normal
In-Reply-To: <AM6PR0102MB31743FD9A2FF22416E57AB709E619@AM6PR0102MB3174.eurprd01.prod.exchangelabs.com>
References: <AM6PR0102MB31743FD9A2FF22416E57AB709E619@AM6PR0102MB3174.eurprd01.prod.exchangelabs.com>
Message-ID: <d3922451-1ce7-2cd8-b66e-1ea031dcb49a@gmail.com>

   The only continuous distributions in the standard exponential family are:

   Normal (of course)
   Gamma (good for positive response variables; mechanistically related 
to multi-stage survival)
   Inverse Gaussian (rarely used)

The Tweedie distribution is in the 'extended' exponential family (once 
the power parameter is known)

   You said "non-negative": do you have zero values?  In that case your 
typical choices would be (1) Tweedie or (2) hurdle-Gamma (i.e. 
equivalent to two separate models, one for zero vs >0, the other for the 
value of the positive observations)

  e.g. 
https://stats.stackexchange.com/questions/187824/how-to-model-non-negative-zero-inflated-continuous-data





On 3/26/21 5:47 AM, Andre Syvertsen wrote:
> Hi,
> 
> Question in brief:
> 
> I have a question regarding fitting mixed models with continuous data that is non-normal. The data has very high kurtosis, is positively skewed, and shows heteroscedasticity at higher values. I believe this makes sense theoretically (see below). Is there a type of generalized linear model that is commonly used in these settings? Any specific distribution and way to determine this?
> 
> 
> 
> More information:
> 
> I have consulted with the mailing list a couple of times previously regarding modeling count data and want to extend my thanks for the valuable feedback I received then! The model I am trying now is part of the same study, but with an outcome variable that is continuous and non-negative. The basics of the study are the same:
> 
> 
> 
> I am working with a large dataset that contains longitudinal data on gambling behavior of 184,113 participants. The data is based on complete tracking of electronic gambling behavior within a gambling operator. Gambling behavior data is aggregated on a monthly level, a total of 70 months. I have an ID variable separating participants, a time variable (months), as well as numerous gambling behavior variables such as active days played for given month, total bet size for given month, total losses for given month, etc. I am investigating the role of age (categorized into 6 age groups, ageCategory) and gender in predicting gambling behavior outcomes. The outcome is relative bet size in each month. Participant monthly bet size is divided on number of active gambling days the person had in the given month, which we term "gambling intensity" (gamblingIntensity). For example, gambling 1 day in month and betting 100$ = 100, gambling 2 days in month and betting 200$ = 100, We only analyze months with any active gambling (active days gambling >=1)
> 
> I have fitted a linear mixed model with lme4, with the following code:
> 
> 
> 
> gamblingIntensityConditionalAgeGender <- lmer(gamblingIntensity ~ 1 + time + ageCategory * gender + (1 | id), REML = FALSE, data = ntDF)
> 
> 
> 
> I have checked the resulting model with a qqplot and the residuals are far from normally distributed. Descriptive analysis of the outcome variable also shows it to have high positive skewness (ranging between 2.6-7.4, most around 4) and extreme kurtosis (19.6-270.8, most around 40) depending on the month. Here are means based on percentiles:
> 
> .05, .10, .25, .50, .75, .90, .95
> 
> 87.0, 173.0, 527.3, 1207.3, 2182.6, 3528.7, 4655.9
> 
> 
> 
> A few gamblers will spend a little money on gambling, most gamblers will spend a moderate amount, and a few gamblers will spend a very large amount of money and show higher variation. This pattern also fits other forms of risk behaviors, like alcohol, in which a small percentage of the population are responsible for most of the alcohol consumption in the population. Because of this, I am reluctant to do any data transformations to make it more normally distributed but rather use a model that actually reflects the real-world phenomenon.
> 
> 
> 
> I have tried to consult with the research literature but cannot seem to find any examples of mixed modeling of these types of data. Most studies either examine count data or they use other approaches, e.g., do group-based analyses based on grouping by percentiles.
> 
> 
> 
> Kind regards,
> 
> Andr?
> 
> 
> 	[[alternative HTML version deleted]]
> 
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> 

From bbo|ker @end|ng |rom gm@||@com  Tue Mar 30 02:54:02 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Mon, 29 Mar 2021 20:54:02 -0400
Subject: [R-sig-ME] glmer() Gamma distribution - constant coefficient of
 variation
In-Reply-To: <BYAPR07MB5094FBA38F1C25DB9C119D22D1659@BYAPR07MB5094.namprd07.prod.outlook.com>
References: <BYAPR07MB5094FBA38F1C25DB9C119D22D1659@BYAPR07MB5094.namprd07.prod.outlook.com>
Message-ID: <8a314601-0b43-4f66-55e1-46da89d5af36@gmail.com>


   I would start by checking the scale-location plot, i.e.

plot(fitted_model, sqrt(abs(resid(., type="pearson"))) ~ fitted(.))

if that's fairly flat, you should be OK.

    Not that important, but can you tell me why you're fitting an 
identity-link Gamma model?  I'm always curious (I've read Lo and Andrews 
[2015] but don't find their argument particularly convincing ...).  Do 
you have reasons to believe the relationships are linear rather than 
log-linear?

Lo, Steson, and Sally Andrews. ?To Transform or Not to Transform: Using 
Generalized Linear Mixed Models to Analyse Reaction Time Data.? 
Frontiers in Psychology 6 (August 7, 2015). 
https://doi.org/10.3389/fpsyg.2015.01171.




On 3/22/21 5:24 PM, Hedyeh Ahmadi wrote:
> Hi all,
> I am running a glmer() with Gamma distribution and identity link. The R output is as follows. I would like to check the constant coefficient of variation assumption in R but I am not sure where to start. Any help would be appreciated.
> 
> Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) ['glmerMod']
>   Family: Gamma  ( identity )
> Formula: Y ~ 1 + pm252016aa + race +prnt.empl + overall.income +  (1 | site)
> Data: Family
> Control: glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 100000))
> 
>       AIC       BIC           logLik           deviance df.resid
>   68781.7   68917.1 -34371.8     68743.7     9180
> 
> Scaled residuals:
>      Min      1Q             Median      3Q        Max
> -1.9286   -0.7314   -0.0598    0.6770    3.9599
> 
> Random effects:
>   Groups    Name               Variance   Std.Dev.
>   site (Intercept)      0.66157    0.8134
>   Residual                            0.04502     0.2122
> Number of obs: 9199,  groups:  site, 21
> 
> Fixed effects:
>                                                                 Estimate     Std. Error         t value             Pr(>|z|)
> (Intercept)                                              52.3578               1.3102            39.962         < 0.0000000000000002 ***
> pm252016aa                                         -0.1260                 0.1099           -1.147            0.251212
> race_1                                                     1.0913                  0.7106         -1.536             0.124628
> race_2                                                     -1.1787                  0.6870          3.171             0.001518 **
> prnt.empl                                               2.8852                  0.4377            4.307            0.000016517 **
> overall.income[>=100K]                      -1.8476                 0.3693          -5.003            0.000000566 ***
> overall.income[>=50K & <100K]        -0.8644                0.3403             -2.540            0.011078 *
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> 
> 
> Best,
> 
> Hedyeh Ahmadi, Ph.D.
> Statistician
> Keck School of Medicine
> Department of Preventive Medicine
> University of Southern California
> 
> Postdoctoral Scholar
> Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
> University of California, Irvine
> 
> LinkedIn
> www.linkedin.com/in/hedyeh-ahmadi<http://www.linkedin.com/in/hedyeh-ahmadi>
> <http://www.linkedin.com/in/hedyeh-ahmadi><http://www.linkedin.com/in/hedyeh-ahmadi>
> 
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From hedyeh@h @end|ng |rom u@c@edu  Tue Mar 30 20:26:53 2021
From: hedyeh@h @end|ng |rom u@c@edu (Hedyeh Ahmadi)
Date: Tue, 30 Mar 2021 18:26:53 +0000
Subject: [R-sig-ME] glmer() Gamma distribution - constant coefficient of
 variation
In-Reply-To: <8a314601-0b43-4f66-55e1-46da89d5af36@gmail.com>
References: <BYAPR07MB5094FBA38F1C25DB9C119D22D1659@BYAPR07MB5094.namprd07.prod.outlook.com>,
 <8a314601-0b43-4f66-55e1-46da89d5af36@gmail.com>
Message-ID: <BYAPR07MB50942E36273E4580A0E2C238D17D9@BYAPR07MB5094.namprd07.prod.outlook.com>

Thank you for the informative suggestion - please see my question/comments below in bold:

I would start by checking the scale-location plot, i.e.

plot(fitted_model, sqrt(abs(resid(., type="pearson"))) ~ fitted(.))

if that's fairly flat, you should be OK. I actually ended up doing this last week as one of my colleage suggested as well. I ran a slightly different version of what you suggested, with deviance residual and lowess; I got a straight line (see attached the plot of the left) but when I plot exactly what you suggest, I get the attached plot on the right which is kind of weird. I am leaning toward giving the deviance plot a pass since deviance residuals are suggested for GLMM. Any feedback would be appreciated here.

Additional question: I can't figure out the connection between constant coefficient of determination and scale-location plot. Do you mind elaborating here?

    Not that important, but can you tell me why you're fitting an
identity-link Gamma model?  I'm always curious (I've read Lo and Andrews
[2015] but don't find their argument particularly convincing ...).  Do
you have reasons to believe the relationships are linear rather than
log-linear? We originally hypothesized a linear relationship but then when we ran lmer() the residual diagnostic plots were highly skewed and log transformation did not help at all. Then we implemnted the Gamma distribution assumption in glmer() with identity link to keep the linearity part. After this, I have been asked the same question of "why identity link?" then I doubted my intuition and I ran the model with inverse and log link as ad hoc exploration; I could not get thes emodels to converge so we decided to keep Gamma with identity link.


Best,

Hedyeh Ahmadi, Ph.D.
Statistician
Keck School of Medicine
Department of Preventive Medicine
University of Southern California

Postdoctoral Scholar
Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
University of California, Irvine

LinkedIn
www.linkedin.com/in/hedyeh-ahmadi<http://www.linkedin.com/in/hedyeh-ahmadi>
<http://www.linkedin.com/in/hedyeh-ahmadi><http://www.linkedin.com/in/hedyeh-ahmadi>




________________________________
From: R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on behalf of Ben Bolker <bbolker at gmail.com>
Sent: Monday, March 29, 2021 5:54 PM
To: r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>
Subject: Re: [R-sig-ME] glmer() Gamma distribution - constant coefficient of variation


   I would start by checking the scale-location plot, i.e.

plot(fitted_model, sqrt(abs(resid(., type="pearson"))) ~ fitted(.))

if that's fairly flat, you should be OK.

    Not that important, but can you tell me why you're fitting an
identity-link Gamma model?  I'm always curious (I've read Lo and Andrews
[2015] but don't find their argument particularly convincing ...).  Do
you have reasons to believe the relationships are linear rather than
log-linear?

Lo, Steson, and Sally Andrews. ?To Transform or Not to Transform: Using
Generalized Linear Mixed Models to Analyse Reaction Time Data.?
Frontiers in Psychology 6 (August 7, 2015).
https://urldefense.com/v3/__https://doi.org/10.3389/fpsyg.2015.01171__;!!LIr3w8kk_Xxm!_Hr0ANVe7S49QG8nq1EQIqnN8L6onW_Ej2H41C7LDOubwInvN-KOjzKV5IDIz28$ .




On 3/22/21 5:24 PM, Hedyeh Ahmadi wrote:
> Hi all,
> I am running a glmer() with Gamma distribution and identity link. The R output is as follows. I would like to check the constant coefficient of variation assumption in R but I am not sure where to start. Any help would be appreciated.
>
> Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) ['glmerMod']
>   Family: Gamma  ( identity )
> Formula: Y ~ 1 + pm252016aa + race +prnt.empl + overall.income +  (1 | site)
> Data: Family
> Control: glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 100000))
>
>       AIC       BIC           logLik           deviance df.resid
>   68781.7   68917.1 -34371.8     68743.7     9180
>
> Scaled residuals:
>      Min      1Q             Median      3Q        Max
> -1.9286   -0.7314   -0.0598    0.6770    3.9599
>
> Random effects:
>   Groups    Name               Variance   Std.Dev.
>   site (Intercept)      0.66157    0.8134
>   Residual                            0.04502     0.2122
> Number of obs: 9199,  groups:  site, 21
>
> Fixed effects:
>                                                                 Estimate     Std. Error         t value             Pr(>|z|)
> (Intercept)                                              52.3578               1.3102            39.962         < 0.0000000000000002 ***
> pm252016aa                                         -0.1260                 0.1099           -1.147            0.251212
> race_1                                                     1.0913                  0.7106         -1.536             0.124628
> race_2                                                     -1.1787                  0.6870          3.171             0.001518 **
> prnt.empl                                               2.8852                  0.4377            4.307            0.000016517 **
> overall.income[>=100K]                      -1.8476                 0.3693          -5.003            0.000000566 ***
> overall.income[>=50K & <100K]        -0.8644                0.3403             -2.540            0.011078 *
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
>
> Best,
>
> Hedyeh Ahmadi, Ph.D.
> Statistician
> Keck School of Medicine
> Department of Preventive Medicine
> University of Southern California
>
> Postdoctoral Scholar
> Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
> University of California, Irvine
>
> LinkedIn
> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!_Hr0ANVe7S49QG8nq1EQIqnN8L6onW_Ej2H41C7LDOubwInvN-KOjzKVbeztxWs$ <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!_Hr0ANVe7S49QG8nq1EQIqnN8L6onW_Ej2H41C7LDOubwInvN-KOjzKVbeztxWs$ >
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!_Hr0ANVe7S49QG8nq1EQIqnN8L6onW_Ej2H41C7LDOubwInvN-KOjzKVbeztxWs$ ><https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!_Hr0ANVe7S49QG8nq1EQIqnN8L6onW_Ej2H41C7LDOubwInvN-KOjzKVbeztxWs$ >
>
>
>
>
>
>        [[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!_Hr0ANVe7S49QG8nq1EQIqnN8L6onW_Ej2H41C7LDOubwInvN-KOjzKV_JWfCpo$
>

_______________________________________________
R-sig-mixed-models at r-project.org mailing list
https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!_Hr0ANVe7S49QG8nq1EQIqnN8L6onW_Ej2H41C7LDOubwInvN-KOjzKV_JWfCpo$

-------------- next part --------------
A non-text attachment was scrubbed...
Name: resid plot.png
Type: image/png
Size: 109540 bytes
Desc: resid plot.png
URL: <https://stat.ethz.ch/pipermail/r-sig-mixed-models/attachments/20210330/95c06c3c/attachment-0001.png>

From bbo|ker @end|ng |rom gm@||@com  Wed Mar 31 03:02:08 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Tue, 30 Mar 2021 21:02:08 -0400
Subject: [R-sig-ME] glmer() Gamma distribution - constant coefficient of
 variation
In-Reply-To: <BYAPR07MB509440A0314610D504EC872AD17D9@BYAPR07MB5094.namprd07.prod.outlook.com>
References: <BYAPR07MB5094FBA38F1C25DB9C119D22D1659@BYAPR07MB5094.namprd07.prod.outlook.com>
 <8a314601-0b43-4f66-55e1-46da89d5af36@gmail.com>
 <BYAPR07MB509440A0314610D504EC872AD17D9@BYAPR07MB5094.namprd07.prod.outlook.com>
Message-ID: <5299bb31-1f9a-27f5-0d43-81911cc1d6ea@gmail.com>



On 3/30/21 2:23 PM, Hedyeh Ahmadi wrote:
> *Thank you for the informative suggestion - please see my 
> question/comments below in bold:*
> 
> I would start by checking the scale-location plot, i.e.
> 
> plot(fitted_model, sqrt(abs(resid(., type="pearson"))) ~ fitted(.))
> 
> if that's fairly flat, you should be OK. *I actually ended up doing this 
> last week as one of my colleage suggested as well. I ran a slightly 
> different version of what you suggested, with deviance residual and 
> lowess; I got a straight line (see below, the plot of the left) but when 
> I plot exactly what you suggest, I get the following plot on the right 
> which is kind of weird. I am leaning toward giving the deviance plot a 
> pass since deviance residuals are suggested for GLMM. _Any feedback 
> would be appreciated here._*
> 
> *_Additional question:_ I can't figure out the connection between 
> constant coefficient of determination and scale-location plot. Do you 
> mind elaborating here?*


    The scale-location plot is based on the Pearson residuals, which 
divide the residuals by their expected (theoretical) standard deviation. 
  If the variance model is correct (i.e. the mean-variance relationship 
in the data  matches that assumed by the model), then the expected 
magnitude of abs(Pearson resids) (or the square root thereof, which is 
applied to reduce skew) should be constant as a function of the 
predicted (fitted) mean.

> 
> 
>  ??? Not that important, but can you tell me why you're fitting an
> identity-link Gamma model?? I'm always curious (I've read Lo and Andrews
> [2015] but don't find their argument particularly convincing ...).? Do
> you have reasons to believe the relationships are linear rather than
> log-linear?


*We originally hypothesized a linear relationship but then
> when we * *ran lmer() the residual diagnostic plots were highly skewed 
> and log transformation did not help at all. Then we implemnted the Gamma 
> distribution assumption in glmer() with identity link to keep the 
> linearity part. After this, I have been asked the same question of "why 
> identity link?" then I doubted my intuition and I ran the model with 
> inverse and log link as ad hoc exploration; I could not get thes emodels 
> to converge so we decided to keep Gamma with identity link.

   Surprising that the log-link Gamma didn't converge (usually it works 
better than the identity link ...)

   From the diagnostic plots, it looks like your data are discrete. Is 
there a particular reason you're not using a discrete response 
distribution (like the [perhaps 0-truncated] negative binomial) ?


> *
> 
> Best,
> 
> Hedyeh Ahmadi, Ph.D.
> Statistician
> Keck School of Medicine
> Department of Preventive Medicine
> University of Southern California
> 
> Postdoctoral Scholar
> Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
> University of California, Irvine
> 
> LinkedIn
> www.linkedin.com/in/hedyeh-ahmadi <http://www.linkedin.com/in/hedyeh-ahmadi>
> <http://www.linkedin.com/in/hedyeh-ahmadi><http://www.linkedin.com/in/hedyeh-ahmadi>
> 
> 
> 
> 
> ------------------------------------------------------------------------
> *From:* R-sig-mixed-models <r-sig-mixed-models-bounces at r-project.org> on 
> behalf of Ben Bolker <bbolker at gmail.com>
> *Sent:* Monday, March 29, 2021 5:54 PM
> *To:* r-sig-mixed-models at r-project.org <r-sig-mixed-models at r-project.org>
> *Subject:* Re: [R-sig-ME] glmer() Gamma distribution - constant 
> coefficient of variation
> 
>  ?? I would start by checking the scale-location plot, i.e.
> 
> plot(fitted_model, sqrt(abs(resid(., type="pearson"))) ~ fitted(.))
> 
> if that's fairly flat, you should be OK.
> 
>  ??? Not that important, but can you tell me why you're fitting an
> identity-link Gamma model?? I'm always curious (I've read Lo and Andrews
> [2015] but don't find their argument particularly convincing ...).? Do
> you have reasons to believe the relationships are linear rather than
> log-linear?
> 
> Lo, Steson, and Sally Andrews. ?To Transform or Not to Transform: Using
> Generalized Linear Mixed Models to Analyse Reaction Time Data.?
> Frontiers in Psychology 6 (August 7, 2015).
> https://urldefense.com/v3/__https://doi.org/10.3389/fpsyg.2015.01171__;!!LIr3w8kk_Xxm!_Hr0ANVe7S49QG8nq1EQIqnN8L6onW_Ej2H41C7LDOubwInvN-KOjzKV5IDIz28$ 
> <https://urldefense.com/v3/__https://doi.org/10.3389/fpsyg.2015.01171__;!!LIr3w8kk_Xxm!_Hr0ANVe7S49QG8nq1EQIqnN8L6onW_Ej2H41C7LDOubwInvN-KOjzKV5IDIz28$> 
> .
> 
> 
> 
> 
> On 3/22/21 5:24 PM, Hedyeh Ahmadi wrote:
>> Hi all,
>> I am running a glmer() with Gamma distribution and identity link. The R output is as follows. I would like to check the constant coefficient of variation assumption in R but I am not sure where to start. Any help would be appreciated.
>> 
>> Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) ['glmerMod']
>>?? Family: Gamma? ( identity )
>> Formula: Y ~ 1 + pm252016aa + race +prnt.empl + overall.income +? (1 | site)
>> Data: Family
>> Control: glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 100000))
>> 
>>?????? AIC?????? BIC?????????? logLik?????????? deviance df.resid
>>?? 68781.7?? 68917.1 -34371.8???? 68743.7???? 9180
>> 
>> Scaled residuals:
>>????? Min????? 1Q???????????? Median????? 3Q??????? Max
>> -1.9286?? -0.7314?? -0.0598??? 0.6770??? 3.9599
>> 
>> Random effects:
>>?? Groups??? Name?????????????? Variance?? Std.Dev.
>>?? site (Intercept)????? 0.66157??? 0.8134
>>?? Residual??????????????????????????? 0.04502???? 0.2122
>> Number of obs: 9199,? groups:? site, 21
>> 
>> Fixed effects:
>>???????????????????????????????????????????????????????????????? Estimate???? Std. Error???????? t value???????????? Pr(>|z|)
>> (Intercept)????????????????????????????????????????????? 52.3578?????????????? 1.3102??????????? 39.962???????? < 0.0000000000000002 ***
>> pm252016aa???????????????????????????????????????? -0.1260???????????????? 0.1099?????????? -1.147??????????? 0.251212
>> race_1???????????????????????????????????????????????????? 1.0913????????????????? 0.7106???????? -1.536???????????? 0.124628
>> race_2???????????????????????????????????????????????????? -1.1787????????????????? 0.6870????????? 3.171???????????? 0.001518 **
>> prnt.empl?????????????????????????????????????????????? 2.8852????????????????? 0.4377??????????? 4.307??????????? 0.000016517 **
>> overall.income[>=100K]????????????????????? -1.8476???????????????? 0.3693????????? -5.003??????????? 0.000000566 ***
>> overall.income[>=50K & <100K]??????? -0.8644??????????????? 0.3403???????????? -2.540??????????? 0.011078 *
>> ---
>> Signif. codes:? 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>> 
>> 
>> Best,
>> 
>> Hedyeh Ahmadi, Ph.D.
>> Statistician
>> Keck School of Medicine
>> Department of Preventive Medicine
>> University of Southern California
>> 
>> Postdoctoral Scholar
>> Institute for Interdisciplinary Salivary Bioscience Research (IISBR)
>> University of California, Irvine
>> 
>> LinkedIn
>> https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!_Hr0ANVe7S49QG8nq1EQIqnN8L6onW_Ej2H41C7LDOubwInvN-KOjzKVbeztxWs$ 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!_Hr0ANVe7S49QG8nq1EQIqnN8L6onW_Ej2H41C7LDOubwInvN-KOjzKVbeztxWs$> 
> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!_Hr0ANVe7S49QG8nq1EQIqnN8L6onW_Ej2H41C7LDOubwInvN-KOjzKVbeztxWs$ 
>  >
>> <https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!_Hr0ANVe7S49QG8nq1EQIqnN8L6onW_Ej2H41C7LDOubwInvN-KOjzKVbeztxWs$ 
>  ><https://urldefense.com/v3/__http://www.linkedin.com/in/hedyeh-ahmadi__;!!LIr3w8kk_Xxm!_Hr0ANVe7S49QG8nq1EQIqnN8L6onW_Ej2H41C7LDOubwInvN-KOjzKVbeztxWs$ >
>> 
>> 
>> 
>> 
>> 
>>??????? [[alternative HTML version deleted]]
>> 
>> 
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!_Hr0ANVe7S49QG8nq1EQIqnN8L6onW_Ej2H41C7LDOubwInvN-KOjzKV_JWfCpo$ 
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!_Hr0ANVe7S49QG8nq1EQIqnN8L6onW_Ej2H41C7LDOubwInvN-KOjzKV_JWfCpo$> 
> 
>>
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!_Hr0ANVe7S49QG8nq1EQIqnN8L6onW_Ej2H41C7LDOubwInvN-KOjzKV_JWfCpo$ 
> <https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models__;!!LIr3w8kk_Xxm!_Hr0ANVe7S49QG8nq1EQIqnN8L6onW_Ej2H41C7LDOubwInvN-KOjzKV_JWfCpo$> 
>


From hedyeh@h @end|ng |rom u@c@edu  Wed Mar 31 19:34:32 2021
From: hedyeh@h @end|ng |rom u@c@edu (Hedyeh Ahmadi)
Date: Wed, 31 Mar 2021 17:34:32 +0000
Subject: [R-sig-ME] Hedyeh Ahmadi wants to share the file resid plot 1.png
 with you
Message-ID: <BYAPR07MB5094F2835EB7CE8800364B03D17C9@BYAPR07MB5094.namprd07.prod.outlook.com>

To view resid plot 1.png, sign in<https://uscedu-my.sharepoint.com/personal/hedyehah_usc_edu/_layouts/15/acceptinvite.aspx?invitation=%7B1B4C0663%2DF19A%2D42D5%2DA8DB%2DFECC4779F90B%7D&listId=0f2765b6%2D1d99%2D4bc1%2Daf3d%2D9906c588cfab&itemId=a4ccc02c%2D4b0d%2D4be6%2Da5d3%2D75959439a493> or create an account.

	[[alternative HTML version deleted]]


From @|m@h@rme| @end|ng |rom gm@||@com  Wed Mar 31 22:15:24 2021
From: @|m@h@rme| @end|ng |rom gm@||@com (Simon Harmel)
Date: Wed, 31 Mar 2021 15:15:24 -0500
Subject: [R-sig-ME] Random effects variances in R and SPSS not matching
Message-ID: <CACgv6yXjhONDiJqvJYTbT9MZobp0HtHZzavyJ1mfEnWq4vAOCA@mail.gmail.com>

Dear All,

For my reproducible model below, SPSS gives the variance component of
119.95 for Y1, and 127.90 for Y2.

But in `nlme::lme()` my variance components are 105.78 for Y1 and 113.73
for Y2.

Can we make the `lme()` reproduce the SPSS's variance components?

#======= Data and R code:
dat <- read.csv('https://raw.githubusercontent.com/hkil/m/master/mv.l.csv')

library(nlme)

m2 <- lme(value ~0 + name, random = ~0 + name| Student, data = dat, method
= "ML")

Random effects variance covariance matrix
             nameY1   nameY2
nameY1 105.780  60.869
nameY2  60.869 113.730

	[[alternative HTML version deleted]]


From me @end|ng |rom ph||||p@|d@y@com  Wed Mar 31 22:36:05 2021
From: me @end|ng |rom ph||||p@|d@y@com (Phillip Alday)
Date: Wed, 31 Mar 2021 22:36:05 +0200
Subject: [R-sig-ME] Random effects variances in R and SPSS not matching
In-Reply-To: <CACgv6yXjhONDiJqvJYTbT9MZobp0HtHZzavyJ1mfEnWq4vAOCA@mail.gmail.com>
References: <CACgv6yXjhONDiJqvJYTbT9MZobp0HtHZzavyJ1mfEnWq4vAOCA@mail.gmail.com>
Message-ID: <4ca98023-0453-c6f5-fabd-8aa9f322614f@phillipalday.com>

Without more information, we don't know for sure that the models are the
same in both languages.

It's too much of a time sink for a human to change model details
randomly until the output matches some expected output, but you could
probably do something with genetic programming or simulated annealing to
do that....

But if you can get more information, I would start by making sure
- that the contrasts are truly the same
- assumed covariance structures are the same
- that one language isn't dropping some observations that the other is
keeping (check the reporting number of observations levels of the
grouping var)
- the estimation method is the same across languages (ML,REML; hopefully
SPSS isn't using something like quasi-likelihood)
- different optimizers (if available) give the same  result across
languages (i.e. make sure you're not in a local optimum)
- cross checking the result against yet another software package

For example, cross-checking against lme4 immediately hints that this
model might not be advisable / have a well-defined optimum:

> m2.4 <- lmer(value ~0 + name + (0 + name| Student), data = dat,
REML=FALSE)
Error: number of observations (=1600) <= number of random effects
(=1600) for term (0 + name | Student); the random-effects parameters and
the residual variance (or scale parameter) are probably unidentifiable

Phillip

On 31/3/21 10:15 pm, Simon Harmel wrote:
> Dear All,
> 
> For my reproducible model below, SPSS gives the variance component of
> 119.95 for Y1, and 127.90 for Y2.
> 
> But in `nlme::lme()` my variance components are 105.78 for Y1 and 113.73
> for Y2.
> 
> Can we make the `lme()` reproduce the SPSS's variance components?
> 
> #======= Data and R code:
> dat <- read.csv('https://raw.githubusercontent.com/hkil/m/master/mv.l.csv')
> 
> library(nlme)
> 
> m2 <- lme(value ~0 + name, random = ~0 + name| Student, data = dat, method
> = "ML")
> 
> Random effects variance covariance matrix
>              nameY1   nameY2
> nameY1 105.780  60.869
> nameY2  60.869 113.730
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From @|m@h@rme| @end|ng |rom gm@||@com  Wed Mar 31 22:43:04 2021
From: @|m@h@rme| @end|ng |rom gm@||@com (Simon Harmel)
Date: Wed, 31 Mar 2021 15:43:04 -0500
Subject: [R-sig-ME] Random effects variances in R and SPSS not matching
In-Reply-To: <4ca98023-0453-c6f5-fabd-8aa9f322614f@phillipalday.com>
References: <CACgv6yXjhONDiJqvJYTbT9MZobp0HtHZzavyJ1mfEnWq4vAOCA@mail.gmail.com>
 <4ca98023-0453-c6f5-fabd-8aa9f322614f@phillipalday.com>
Message-ID: <CACgv6yUy0aW4wag8+-GkrUCVTPg9L=fCo5onDGahgxg1Qnq0yQ@mail.gmail.com>

Thank you. I'll be happy to give more info. SPSS model syntax is shown on
in Table 14.5, p. 585 (type `606` in page slot) of this book (
http://docshare02.docshare.tips/files/31719/317194846.pdf).

The SPSS output is shown on p. 588 (type `606` in page slot).

I should add the covariance between `Y1` and `Y2` exactly match. and the
log-likelihood seems to be almost identical. But variances differ by a lot.
SPSS is using "ML".

Please let me know if I can provide any further information.

Thank you for your prompt reply,
Simon




On Wed, Mar 31, 2021 at 3:36 PM Phillip Alday <me at phillipalday.com> wrote:

> Without more information, we don't know for sure that the models are the
> same in both languages.
>
> It's too much of a time sink for a human to change model details
> randomly until the output matches some expected output, but you could
> probably do something with genetic programming or simulated annealing to
> do that....
>
> But if you can get more information, I would start by making sure
> - that the contrasts are truly the same
> - assumed covariance structures are the same
> - that one language isn't dropping some observations that the other is
> keeping (check the reporting number of observations levels of the
> grouping var)
> - the estimation method is the same across languages (ML,REML; hopefully
> SPSS isn't using something like quasi-likelihood)
> - different optimizers (if available) give the same  result across
> languages (i.e. make sure you're not in a local optimum)
> - cross checking the result against yet another software package
>
> For example, cross-checking against lme4 immediately hints that this
> model might not be advisable / have a well-defined optimum:
>
> > m2.4 <- lmer(value ~0 + name + (0 + name| Student), data = dat,
> REML=FALSE)
> Error: number of observations (=1600) <= number of random effects
> (=1600) for term (0 + name | Student); the random-effects parameters and
> the residual variance (or scale parameter) are probably unidentifiable
>
> Phillip
>
> On 31/3/21 10:15 pm, Simon Harmel wrote:
> > Dear All,
> >
> > For my reproducible model below, SPSS gives the variance component of
> > 119.95 for Y1, and 127.90 for Y2.
> >
> > But in `nlme::lme()` my variance components are 105.78 for Y1 and 113.73
> > for Y2.
> >
> > Can we make the `lme()` reproduce the SPSS's variance components?
> >
> > #======= Data and R code:
> > dat <- read.csv('
> https://raw.githubusercontent.com/hkil/m/master/mv.l.csv')
> >
> > library(nlme)
> >
> > m2 <- lme(value ~0 + name, random = ~0 + name| Student, data = dat,
> method
> > = "ML")
> >
> > Random effects variance covariance matrix
> >              nameY1   nameY2
> > nameY1 105.780  60.869
> > nameY2  60.869 113.730
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-mixed-models at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
> >
>

	[[alternative HTML version deleted]]


From @|m@h@rme| @end|ng |rom gm@||@com  Wed Mar 31 22:46:35 2021
From: @|m@h@rme| @end|ng |rom gm@||@com (Simon Harmel)
Date: Wed, 31 Mar 2021 15:46:35 -0500
Subject: [R-sig-ME] Random effects variances in R and SPSS not matching
In-Reply-To: <CACgv6yUy0aW4wag8+-GkrUCVTPg9L=fCo5onDGahgxg1Qnq0yQ@mail.gmail.com>
References: <CACgv6yXjhONDiJqvJYTbT9MZobp0HtHZzavyJ1mfEnWq4vAOCA@mail.gmail.com>
 <4ca98023-0453-c6f5-fabd-8aa9f322614f@phillipalday.com>
 <CACgv6yUy0aW4wag8+-GkrUCVTPg9L=fCo5onDGahgxg1Qnq0yQ@mail.gmail.com>
Message-ID: <CACgv6yW9BZ6cKbk_geuGxL2F6JYf4kFaDjow862++KhU3MvfVw@mail.gmail.com>

ps. I should also add I tried to use manually created dummies (D1, D2
equivalent to SPSS's `index 1` and `index 2` dummies) to mimic SPSS syntax
but that didn't (as I expected) change anything.

lme(value ~ 0 + D1 + D2, random = ~0 + D1 + D2 | Student, data = dat,
           method = "ML")

On Wed, Mar 31, 2021 at 3:43 PM Simon Harmel <sim.harmel at gmail.com> wrote:

> Thank you. I'll be happy to give more info. SPSS model syntax is shown on
> in Table 14.5, p. 585 (type `606` in page slot) of this book (
> http://docshare02.docshare.tips/files/31719/317194846.pdf).
>
> The SPSS output is shown on p. 588 (type `606` in page slot).
>
> I should add the covariance between `Y1` and `Y2` exactly match. and the
> log-likelihood seems to be almost identical. But variances differ by a lot.
> SPSS is using "ML".
>
> Please let me know if I can provide any further information.
>
> Thank you for your prompt reply,
> Simon
>
>
>
>
> On Wed, Mar 31, 2021 at 3:36 PM Phillip Alday <me at phillipalday.com> wrote:
>
>> Without more information, we don't know for sure that the models are the
>> same in both languages.
>>
>> It's too much of a time sink for a human to change model details
>> randomly until the output matches some expected output, but you could
>> probably do something with genetic programming or simulated annealing to
>> do that....
>>
>> But if you can get more information, I would start by making sure
>> - that the contrasts are truly the same
>> - assumed covariance structures are the same
>> - that one language isn't dropping some observations that the other is
>> keeping (check the reporting number of observations levels of the
>> grouping var)
>> - the estimation method is the same across languages (ML,REML; hopefully
>> SPSS isn't using something like quasi-likelihood)
>> - different optimizers (if available) give the same  result across
>> languages (i.e. make sure you're not in a local optimum)
>> - cross checking the result against yet another software package
>>
>> For example, cross-checking against lme4 immediately hints that this
>> model might not be advisable / have a well-defined optimum:
>>
>> > m2.4 <- lmer(value ~0 + name + (0 + name| Student), data = dat,
>> REML=FALSE)
>> Error: number of observations (=1600) <= number of random effects
>> (=1600) for term (0 + name | Student); the random-effects parameters and
>> the residual variance (or scale parameter) are probably unidentifiable
>>
>> Phillip
>>
>> On 31/3/21 10:15 pm, Simon Harmel wrote:
>> > Dear All,
>> >
>> > For my reproducible model below, SPSS gives the variance component of
>> > 119.95 for Y1, and 127.90 for Y2.
>> >
>> > But in `nlme::lme()` my variance components are 105.78 for Y1 and 113.73
>> > for Y2.
>> >
>> > Can we make the `lme()` reproduce the SPSS's variance components?
>> >
>> > #======= Data and R code:
>> > dat <- read.csv('
>> https://raw.githubusercontent.com/hkil/m/master/mv.l.csv')
>> >
>> > library(nlme)
>> >
>> > m2 <- lme(value ~0 + name, random = ~0 + name| Student, data = dat,
>> method
>> > = "ML")
>> >
>> > Random effects variance covariance matrix
>> >              nameY1   nameY2
>> > nameY1 105.780  60.869
>> > nameY2  60.869 113.730
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> > _______________________________________________
>> > R-sig-mixed-models at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>> >
>>
>

	[[alternative HTML version deleted]]


From bbo|ker @end|ng |rom gm@||@com  Wed Mar 31 22:56:53 2021
From: bbo|ker @end|ng |rom gm@||@com (Ben Bolker)
Date: Wed, 31 Mar 2021 16:56:53 -0400
Subject: [R-sig-ME] Random effects variances in R and SPSS not matching
In-Reply-To: <4ca98023-0453-c6f5-fabd-8aa9f322614f@phillipalday.com>
References: <CACgv6yXjhONDiJqvJYTbT9MZobp0HtHZzavyJ1mfEnWq4vAOCA@mail.gmail.com>
 <4ca98023-0453-c6f5-fabd-8aa9f322614f@phillipalday.com>
Message-ID: <409c0d77-0735-b098-c722-1b1856fd4a0c@gmail.com>



On 3/31/21 4:36 PM, Phillip Alday wrote:
> Without more information, we don't know for sure that the models are the
> same in both languages.
> 
> It's too much of a time sink for a human to change model details
> randomly until the output matches some expected output, but you could
> probably do something with genetic programming or simulated annealing to
> do that....
> 
> But if you can get more information, I would start by making sure
> - that the contrasts are truly the same
> - assumed covariance structures are the same
> - that one language isn't dropping some observations that the other is
> keeping (check the reporting number of observations levels of the
> grouping var)
> - the estimation method is the same across languages (ML,REML; hopefully
> SPSS isn't using something like quasi-likelihood)
> - different optimizers (if available) give the same  result across
> languages (i.e. make sure you're not in a local optimum)
> - cross checking the result against yet another software package
> 
> For example, cross-checking against lme4 immediately hints that this
> model might not be advisable / have a well-defined optimum:
> 
>> m2.4 <- lmer(value ~0 + name + (0 + name| Student), data = dat,
> REML=FALSE)
> Error: number of observations (=1600) <= number of random effects
> (=1600) for term (0 + name | Student); the random-effects parameters and
> the residual variance (or scale parameter) are probably unidentifiable

   If you only have one observation per name per student, then this 
model will be overfitted.  You could use glmmTMB with dispformula = ~0, 
or blme::blmer with a tight/small prior on the residual variance

Based on this

https://journal.r-project.org/archive/2017/RJ-2017-010/RJ-2017-010.pdf

it looks like you can fix residual variance to  a small value (not 
exactly zero!) in lme, e.g.

control = lmerControl(sigma=1e-6)

   After experimenting with your example below, I can't set sigma to a 
value < 1 without a false convergence error.  Setting it to 1 gives 
values much closer to your report (118.9, 126.9).  Using opt="optim" in 
the lmerControl and sigma=1e-5 gives the results you're looking for; so 
does using returnObject=TRUE (which tells lme to give you the answer 
even though there was a convergence warning).

  There's also probably a way to rearrange this with a simpler random 
effect, but I haven't quite figured it out yet.


> Phillip
> 
> On 31/3/21 10:15 pm, Simon Harmel wrote:
>> Dear All,
>>
>> For my reproducible model below, SPSS gives the variance component of
>> 119.95 for Y1, and 127.90 for Y2.
>>
>> But in `nlme::lme()` my variance components are 105.78 for Y1 and 113.73
>> for Y2.
>>
>> Can we make the `lme()` reproduce the SPSS's variance components?
>>
>> #======= Data and R code:
>> dat <- read.csv('https://raw.githubusercontent.com/hkil/m/master/mv.l.csv')
>>
>> library(nlme)
>>
>> m2 <- lme(value ~0 + name, random = ~0 + name| Student, data = dat, method
>> = "ML")
>>
>> Random effects variance covariance matrix
>>               nameY1   nameY2
>> nameY1 105.780  60.869
>> nameY2  60.869 113.730
>>
>> 	[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-mixed-models at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>>
> 
> _______________________________________________
> R-sig-mixed-models at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>


From me @end|ng |rom ph||||p@|d@y@com  Wed Mar 31 23:18:33 2021
From: me @end|ng |rom ph||||p@|d@y@com (Phillip Alday)
Date: Wed, 31 Mar 2021 23:18:33 +0200
Subject: [R-sig-ME] Random effects variances in R and SPSS not matching
In-Reply-To: <CACgv6yUy0aW4wag8+-GkrUCVTPg9L=fCo5onDGahgxg1Qnq0yQ@mail.gmail.com>
References: <CACgv6yXjhONDiJqvJYTbT9MZobp0HtHZzavyJ1mfEnWq4vAOCA@mail.gmail.com>
 <4ca98023-0453-c6f5-fabd-8aa9f322614f@phillipalday.com>
 <CACgv6yUy0aW4wag8+-GkrUCVTPg9L=fCo5onDGahgxg1Qnq0yQ@mail.gmail.com>
Message-ID: <33215e2d-d3cf-bcc5-14c8-be4991269f47@phillipalday.com>

I don't think the optimum is well defined:

> library("lattice")
> library("lme4")
> m2.4 <- lmer(value ~0 + name + (0+name| Student), data = dat,
REML=FALSE,
control=lmerControl(optimizer="bobyqa",check.nobs.vs.nRE="warning"))
Warning messages:
1: number of observations (=1600) <= number of random effects (=1600)
for term (0 + name | Student); the random-effects parameters and the
residual variance (or scale parameter) are probably unidentifiable
2: In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
  Model is nearly unidentifiable: large eigenvalue ratio
 - Rescale variables?
> p <- profile(m2.4)
There were 50 or more warnings (use warnings() to see the first 50)
> xyplot(p)

Those are some very bad profiles! Also, this goes back to the lme4
safety-check that I had to disable. The fundamental problem is that
there isn't enough data to completely distinguish the residual variance
from the RE, so you get difference answers for the RE variance depending
on how much you attribute to the residual variance.

I also tried to do this with MCMC and flat priors (always a bad idea,
but...) and also ran into bad convergence issues.

Phillip



On 31/3/21 10:43 pm, Simon Harmel wrote:
> Thank you. I'll be happy to give more info.?SPSS model syntax is shown
> on in Table 14.5, p. 585 (type `606` in page slot) of this book
> (http://docshare02.docshare.tips/files/31719/317194846.pdf).
> 
> The SPSS output is shown on p. 588 (type `606` in page slot).
> 
> I should add the covariance between `Y1` and `Y2` exactly match. and the
> log-likelihood seems to be almost identical. But variances differ by a
> lot. SPSS is using "ML".
> 
> Please let me know if I can provide any further information.
> 
> Thank you for your prompt reply,
> Simon
> 
> 
> 
> 
> On Wed, Mar 31, 2021 at 3:36 PM Phillip Alday <me at phillipalday.com
> <mailto:me at phillipalday.com>> wrote:
> 
>     Without more information, we don't know for sure that the models are the
>     same in both languages.
> 
>     It's too much of a time sink for a human to change model details
>     randomly until the output matches some expected output, but you could
>     probably do something with genetic programming or simulated annealing to
>     do that....
> 
>     But if you can get more information, I would start by making sure
>     - that the contrasts are truly the same
>     - assumed covariance structures are the same
>     - that one language isn't dropping some observations that the other is
>     keeping (check the reporting number of observations levels of the
>     grouping var)
>     - the estimation method is the same across languages (ML,REML; hopefully
>     SPSS isn't using something like quasi-likelihood)
>     - different optimizers (if available) give the same? result across
>     languages (i.e. make sure you're not in a local optimum)
>     - cross checking the result against yet another software package
> 
>     For example, cross-checking against lme4 immediately hints that this
>     model might not be advisable / have a well-defined optimum:
> 
>     > m2.4 <- lmer(value ~0 + name + (0 + name| Student), data = dat,
>     REML=FALSE)
>     Error: number of observations (=1600) <= number of random effects
>     (=1600) for term (0 + name | Student); the random-effects parameters and
>     the residual variance (or scale parameter) are probably unidentifiable
> 
>     Phillip
> 
>     On 31/3/21 10:15 pm, Simon Harmel wrote:
>     > Dear All,
>     >
>     > For my reproducible model below, SPSS gives the variance component of
>     > 119.95 for Y1, and 127.90 for Y2.
>     >
>     > But in `nlme::lme()` my variance components are 105.78 for Y1 and
>     113.73
>     > for Y2.
>     >
>     > Can we make the `lme()` reproduce the SPSS's variance components?
>     >
>     > #======= Data and R code:
>     > dat <-
>     read.csv('https://raw.githubusercontent.com/hkil/m/master/mv.l.csv')
>     >
>     > library(nlme)
>     >
>     > m2 <- lme(value ~0 + name, random = ~0 + name| Student, data =
>     dat, method
>     > = "ML")
>     >
>     > Random effects variance covariance matrix
>     >? ? ? ? ? ? ? nameY1? ?nameY2
>     > nameY1 105.780? 60.869
>     > nameY2? 60.869 113.730
>     >
>     >? ? ? ?[[alternative HTML version deleted]]
>     >
>     > _______________________________________________
>     > R-sig-mixed-models at r-project.org
>     <mailto:R-sig-mixed-models at r-project.org> mailing list
>     > https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models
>     >
>


